#!/bin/bash

# MyCloset AI - M3 Max 128GB + Conda ì „ìš© í™˜ê²½ ì„¤ì •
# ì‹¤ì œ í•˜ë“œì›¨ì–´ ìŠ¤íŽ™ì— ìµœì í™”ëœ ì„¤ì •

set -e

echo "ðŸŽ M3 Max 128GB + Conda í™˜ê²½ ì„¤ì •"
echo "================================================"
echo "ðŸ–¥ï¸  Target: Apple M3 Max 128GB Unified Memory"
echo "ðŸ Package Manager: Conda (miniforge/mambaforge)"
echo "âš¡ Optimization: Metal Performance Shaders"
echo ""

# ìƒ‰ìƒ ì¶œë ¥ í•¨ìˆ˜ë“¤
log_info() { echo -e "\033[34m[INFO]\033[0m $1"; }
log_success() { echo -e "\033[32m[SUCCESS]\033[0m $1"; }
log_warning() { echo -e "\033[33m[WARNING]\033[0m $1"; }
log_error() { echo -e "\033[31m[ERROR]\033[0m $1"; }
log_header() { echo -e "\033[35m\n=== $1 ===\033[0m"; }

# M3 Max í™˜ê²½ í™•ì¸
check_m3_max_environment() {
    log_header "M3 Max 128GB í™˜ê²½ í™•ì¸"
    
    # macOS í™•ì¸
    if [[ "$OSTYPE" != "darwin"* ]]; then
        log_error "ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” macOS ì „ìš©ìž…ë‹ˆë‹¤."
        exit 1
    fi
    
    # M3 Max ì¹©ì…‹ í™•ì¸
    CHIP_INFO=$(sysctl -n machdep.cpu.brand_string 2>/dev/null || echo "Unknown")
    echo "ðŸ” CPU: $CHIP_INFO"
    
    # ë©”ëª¨ë¦¬ í™•ì¸
    MEMORY_GB=$(echo "$(sysctl -n hw.memsize) / 1024 / 1024 / 1024" | bc)
    echo "ðŸ’¾ ë©”ëª¨ë¦¬: ${MEMORY_GB}GB"
    
    if [[ $MEMORY_GB -lt 64 ]]; then
        log_warning "128GB ë©”ëª¨ë¦¬ê°€ ì•„ë‹Œ ê²ƒ ê°™ìŠµë‹ˆë‹¤. ê³„ì†í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/N)"
        read -r confirm
        if [[ ! $confirm =~ ^[Yy]$ ]]; then
            exit 1
        fi
    fi
    
    # Conda í™•ì¸
    if ! command -v conda &> /dev/null; then
        log_error "Condaê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
        echo "miniforgeë¥¼ ì„¤ì¹˜í•˜ì„¸ìš”: https://github.com/conda-forge/miniforge"
        exit 1
    fi
    
    CONDA_VERSION=$(conda --version)
    echo "ðŸ $CONDA_VERSION"
    
    log_success "M3 Max 128GB í™˜ê²½ í™•ì¸ ì™„ë£Œ"
}

# Conda í™˜ê²½ ìƒì„±
create_conda_environment() {
    log_header "Conda í™˜ê²½ ìƒì„± (M3 Max ìµœì í™”)"
    
    ENV_NAME="mycloset-m3max"
    PYTHON_VERSION="3.11"  # M3 Maxì—ì„œ ê°€ìž¥ ì•ˆì •ì 
    
    # ê¸°ì¡´ í™˜ê²½ í™•ì¸
    if conda env list | grep -q "$ENV_NAME"; then
        log_warning "í™˜ê²½ '$ENV_NAME'ì´ ì´ë¯¸ ì¡´ìž¬í•©ë‹ˆë‹¤. ìž¬ìƒì„±í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/N)"
        read -r recreate
        if [[ $recreate =~ ^[Yy]$ ]]; then
            log_info "ê¸°ì¡´ í™˜ê²½ ì œê±° ì¤‘..."
            conda env remove -n "$ENV_NAME" -y
        else
            log_info "ê¸°ì¡´ í™˜ê²½ì„ ì‚¬ìš©í•©ë‹ˆë‹¤."
            return 0
        fi
    fi
    
    log_info "Conda í™˜ê²½ ìƒì„±: $ENV_NAME (Python $PYTHON_VERSION)"
    
    # M3 Max ìµœì í™” í™˜ê²½ ìƒì„±
    conda create -n "$ENV_NAME" python="$PYTHON_VERSION" -y
    
    log_success "Conda í™˜ê²½ '$ENV_NAME' ìƒì„± ì™„ë£Œ"
    echo "ðŸ’¡ í™˜ê²½ í™œì„±í™”: conda activate $ENV_NAME"
}

# M3 Max ìµœì í™” íŒ¨í‚¤ì§€ ì„¤ì¹˜
install_m3_max_packages() {
    log_header "M3 Max 128GB ìµœì í™” íŒ¨í‚¤ì§€ ì„¤ì¹˜"
    
    ENV_NAME="mycloset-m3max"
    
    # í™˜ê²½ í™œì„±í™”
    source "$(conda info --base)/etc/profile.d/conda.sh"
    conda activate "$ENV_NAME"
    
    log_info "í™œì„± í™˜ê²½: $(conda info --envs | grep '*' | awk '{print $1}')"
    
    # 1. ê¸°ë³¸ ì‹œìŠ¤í…œ íŒ¨í‚¤ì§€ (conda-forge)
    log_info "ðŸ”§ ê¸°ë³¸ ì‹œìŠ¤í…œ íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì¤‘..."
    conda install -c conda-forge -y \
        numpy=1.24.3 \
        scipy=1.11.4 \
        matplotlib=3.7.2 \
        pillow=10.0.1 \
        opencv=4.8.1 \
        scikit-image=0.21.0 \
        psutil=5.9.5 \
        tqdm=4.66.1
    
    # 2. PyTorch ìƒíƒœê³„ (M3 Max MPS ì§€ì›)
    log_info "âš¡ PyTorch MPS ì§€ì› ë²„ì „ ì„¤ì¹˜ ì¤‘..."
    conda install -c pytorch -c nvidia -y \
        pytorch=2.1.0 \
        torchvision=0.16.0 \
        torchaudio=2.1.0
    
    # MPS ì§€ì› í™•ì¸
    python -c "
import torch
print(f'ðŸ” PyTorch ë²„ì „: {torch.__version__}')
if torch.backends.mps.is_available():
    print('âœ… Metal Performance Shaders (MPS) ì‚¬ìš© ê°€ëŠ¥')
    device = torch.device('mps')
    x = torch.randn(1000, 1000, device=device)
    y = torch.mm(x, x.T)
    print(f'âœ… M3 Max GPU ì—°ì‚° í…ŒìŠ¤íŠ¸ ì„±ê³µ: {y.shape}')
else:
    print('âŒ MPS ì‚¬ìš© ë¶ˆê°€')
    exit(1)
    "
    
    # 3. AI/ML íŒ¨í‚¤ì§€ë“¤
    log_info "ðŸ¤– AI/ML íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì¤‘..."
    
    # pipë¡œ ìµœì‹  ë²„ì „ ì„¤ì¹˜ (condaë³´ë‹¤ ë¹ ë¦„)
    pip install --upgrade pip
    
    # Transformers ìƒíƒœê³„
    pip install \
        transformers==4.35.0 \
        tokenizers==0.15.0 \
        safetensors==0.4.0 \
        accelerate==0.24.1 \
        datasets==2.14.6 \
        huggingface-hub==0.17.3
    
    # Diffusers (ê°€ìƒ í”¼íŒ…ìš©)
    pip install diffusers==0.21.4
    
    # 4. ì›¹ í”„ë ˆìž„ì›Œí¬
    log_info "ðŸŒ ì›¹ í”„ë ˆìž„ì›Œí¬ ì„¤ì¹˜ ì¤‘..."
    pip install \
        fastapi==0.104.1 \
        uvicorn[standard]==0.24.0 \
        python-multipart==0.0.6 \
        aiofiles==23.2.1 \
        websockets==11.0.3
    
    # 5. ë°ì´í„° ê²€ì¦ ë° ì„¤ì •
    pip install \
        pydantic==2.5.0 \
        pydantic-settings==2.1.0 \
        python-dotenv==1.0.0 \
        structlog==23.1.0
    
    # 6. M3 Max íŠ¹í™” íŒ¨í‚¤ì§€ë“¤
    log_info "ðŸŽ M3 Max íŠ¹í™” íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì¤‘..."
    
    # MediaPipe (M3 Max ìµœì í™” ë²„ì „)
    pip install mediapipe==0.10.7
    
    # Core ML Tools (Apple ì „ìš©)
    pip install coremltools==7.0
    
    # Metal Performance Shaders Python ë°”ì¸ë”© (ìžˆë‹¤ë©´)
    pip install metal-python || log_warning "metal-python ì„¤ì¹˜ ì‹¤íŒ¨ (ì„ íƒì )"
    
    log_success "M3 Max 128GB ìµœì í™” íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì™„ë£Œ"
}

# í™˜ê²½ ì„¤ì • íŒŒì¼ ìƒì„±
create_environment_config() {
    log_header "M3 Max í™˜ê²½ ì„¤ì • íŒŒì¼ ìƒì„±"
    
    # í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¡œ ì´ë™
    cd "$(dirname "$0")"
    
    # backend/.env íŒŒì¼ ìƒì„±
    mkdir -p backend
    cat > backend/.env << 'EOF'
# MyCloset AI - M3 Max 128GB ìµœì í™” ì„¤ì •
# Generated automatically for Conda environment

# ===========================================
# ì• í”Œë¦¬ì¼€ì´ì…˜ ê¸°ë³¸ ì„¤ì •
# ===========================================
APP_NAME=MyCloset AI Backend
APP_VERSION=1.0.0
DEBUG=true
HOST=0.0.0.0
PORT=8000

# ===========================================
# M3 Max 128GB í•˜ë“œì›¨ì–´ ìµœì í™”
# ===========================================
# GPU ì„¤ì •
USE_GPU=true
DEVICE=mps
GPU_TYPE=m3_max
MEMORY_GB=128
UNIFIED_MEMORY=true

# Neural Engine ì„¤ì •
NEURAL_ENGINE_ENABLED=true
METAL_PERFORMANCE_SHADERS=true

# ë©”ëª¨ë¦¬ ê´€ë¦¬
MAX_MEMORY_FRACTION=0.75
MEMORY_POOL_SIZE=32
AUTO_MEMORY_CLEANUP=true
MEMORY_THRESHOLD=0.85

# ===========================================
# AI ëª¨ë¸ ìµœì í™” ì„¤ì •
# ===========================================
# ë°°ì¹˜ í¬ê¸° (128GB ë©”ëª¨ë¦¬ í™œìš©)
DEFAULT_BATCH_SIZE=8
MAX_BATCH_SIZE=16
INFERENCE_BATCH_SIZE=4

# ëª¨ë¸ ì •ë°€ë„
MODEL_PRECISION=float32
ENABLE_MIXED_PRECISION=false

# íŒŒì´í”„ë¼ì¸ ì„¤ì •
PIPELINE_WORKERS=4
PARALLEL_PROCESSING=true
ASYNC_PROCESSING=true

# ===========================================
# PyTorch MPS ìµœì í™”
# ===========================================
PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0
PYTORCH_MPS_ALLOCATOR_POLICY=garbage_collection
PYTORCH_ENABLE_MPS_FALLBACK=1

# ===========================================
# ì„±ëŠ¥ ìµœì í™”
# ===========================================
# CPU ì„¤ì •
OMP_NUM_THREADS=12
MKL_NUM_THREADS=12
VECLIB_MAXIMUM_THREADS=12

# I/O ìµœì í™”
MAX_WORKERS=8
ASYNC_CONCURRENCY=16

# ===========================================
# íŒŒì¼ ì²˜ë¦¬ ì„¤ì •
# ===========================================
MAX_UPLOAD_SIZE=104857600
ALLOWED_EXTENSIONS=jpg,jpeg,png,webp,heic
TEMP_DIR=/tmp/mycloset_ai

# ì´ë¯¸ì§€ ì²˜ë¦¬
DEFAULT_IMAGE_SIZE=1024
MAX_IMAGE_SIZE=2048
IMAGE_QUALITY=95

# ===========================================
# AI ëª¨ë¸ ê²½ë¡œ
# ===========================================
MODELS_DIR=./ai_models
CACHE_DIR=./models_cache
RESULTS_DIR=./static/results
UPLOADS_DIR=./static/uploads

# ===========================================
# ë¡œê¹… ì„¤ì •
# ===========================================
LOG_LEVEL=INFO
LOG_FILE=logs/mycloset_m3max.log
LOG_ROTATION=true
LOG_MAX_SIZE=100MB

# ===========================================
# CORS ë° ë³´ì•ˆ
# ===========================================
CORS_ORIGINS=http://localhost:3000,http://localhost:5173,http://127.0.0.1:3000
CORS_ALLOW_CREDENTIALS=true

# ===========================================
# ê°œë°œ ë„êµ¬
# ===========================================
RELOAD=true
ACCESS_LOG=true
DEBUG_TOOLBAR=true
PROFILING=false
EOF

    # conda í™˜ê²½ í™œì„±í™” ìŠ¤í¬ë¦½íŠ¸
    cat > activate_m3max.sh << 'EOF'
#!/bin/bash
# M3 Max 128GB MyCloset AI í™˜ê²½ í™œì„±í™”

echo "ðŸŽ M3 Max 128GB MyCloset AI í™˜ê²½ í™œì„±í™” ì¤‘..."

# Conda í™˜ê²½ í™œì„±í™”
source "$(conda info --base)/etc/profile.d/conda.sh"
conda activate mycloset-m3max

# í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
export PYTORCH_ENABLE_MPS_FALLBACK=1
export PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0

# M3 Max ìµœì í™” í™•ì¸
echo "âœ… í™˜ê²½ í™œì„±í™” ì™„ë£Œ"
echo "ðŸ”§ Python: $(python --version)"
echo "âš¡ PyTorch: $(python -c 'import torch; print(torch.__version__)')"
echo "ðŸŽ MPS: $(python -c 'import torch; print("Available" if torch.backends.mps.is_available() else "Not Available")')"
echo "ðŸ’¾ ë©”ëª¨ë¦¬: $(python -c 'import psutil; print(f"{psutil.virtual_memory().total/1024**3:.0f}GB")')"
echo ""
echo "ðŸš€ ì‚¬ìš©ë²•:"
echo "  cd backend && python app/main.py"
echo "  ë˜ëŠ”"
echo "  ./run_m3max.sh"
EOF

    chmod +x activate_m3max.sh

    # ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
    cat > run_m3max.sh << 'EOF'
#!/bin/bash
# M3 Max MyCloset AI ê°œë°œ ì„œë²„ ì‹¤í–‰

# í™˜ê²½ í™œì„±í™”
source activate_m3max.sh

# ë°±ì—”ë“œ ë””ë ‰í† ë¦¬ë¡œ ì´ë™
cd backend

echo "ðŸš€ M3 Max MyCloset AI ë°±ì—”ë“œ ì‹œìž‘..."
echo "ðŸ“¡ ì„œë²„: http://localhost:8000"
echo "ðŸ“š API ë¬¸ì„œ: http://localhost:8000/docs"
echo "â¤ï¸ í—¬ìŠ¤ì²´í¬: http://localhost:8000/health"
echo ""

# ì„œë²„ ì‹¤í–‰
if [[ -f "app/main.py" ]]; then
    python app/main.py
else
    echo "âš ï¸ backend/app/main.pyê°€ ì—†ìŠµë‹ˆë‹¤."
    echo "FastAPI ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ë¨¼ì € ìƒì„±í•˜ì„¸ìš”."
fi
EOF

    chmod +x run_m3max.sh

    log_success "í™˜ê²½ ì„¤ì • íŒŒì¼ ìƒì„± ì™„ë£Œ"
}

# ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬
run_m3_max_benchmark() {
    log_header "M3 Max ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬"
    
    ENV_NAME="mycloset-m3max"
    source "$(conda info --base)/etc/profile.d/conda.sh"
    conda activate "$ENV_NAME"
    
    python -c "
import torch
import time
import numpy as np
import psutil

print('ðŸŽ M3 Max 128GB ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬')
print('=' * 50)

# ì‹œìŠ¤í…œ ì •ë³´
print(f'ðŸ’¾ ì´ ë©”ëª¨ë¦¬: {psutil.virtual_memory().total / 1024**3:.1f}GB')
print(f'ðŸ’¾ ì‚¬ìš© ê°€ëŠ¥: {psutil.virtual_memory().available / 1024**3:.1f}GB')
print(f'ðŸ”§ CPU ì½”ì–´: {psutil.cpu_count(logical=False)}ê°œ (ë…¼ë¦¬: {psutil.cpu_count()}ê°œ)')

# PyTorch ì •ë³´
print(f'âš¡ PyTorch: {torch.__version__}')
print(f'ðŸŽ MPS: {\"âœ… ì‚¬ìš© ê°€ëŠ¥\" if torch.backends.mps.is_available() else \"âŒ ì‚¬ìš© ë¶ˆê°€\"}')

if torch.backends.mps.is_available():
    device = torch.device('mps')
    print(f'ðŸŽ¯ ë””ë°”ì´ìŠ¤: {device}')
    
    # ë©”ëª¨ë¦¬ ëŒ€ì—­í­ í…ŒìŠ¤íŠ¸
    print('\\nðŸš€ ë©”ëª¨ë¦¬ ëŒ€ì—­í­ í…ŒìŠ¤íŠ¸...')
    sizes = [1000, 2000, 4000, 8000]
    
    for size in sizes:
        # CPU
        start = time.time()
        a_cpu = torch.randn(size, size)
        b_cpu = torch.randn(size, size)
        c_cpu = torch.mm(a_cpu, b_cpu)
        cpu_time = time.time() - start
        
        # MPS
        start = time.time()
        a_mps = torch.randn(size, size, device=device)
        b_mps = torch.randn(size, size, device=device)
        c_mps = torch.mm(a_mps, b_mps)
        torch.mps.synchronize()
        mps_time = time.time() - start
        
        speedup = cpu_time / mps_time
        print(f'  {size}x{size}: CPU {cpu_time:.3f}s vs MPS {mps_time:.3f}s (ê°€ì†: {speedup:.1f}x)')
    
    # ëŒ€ìš©ëŸ‰ ë°°ì¹˜ í…ŒìŠ¤íŠ¸ (128GB í™œìš©)
    print('\\nðŸ’ª ëŒ€ìš©ëŸ‰ ë°°ì¹˜ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸...')
    batch_sizes = [1, 4, 8, 16, 32]
    
    for batch in batch_sizes:
        try:
            start = time.time()
            images = torch.randn(batch, 3, 512, 512, device=device)
            # ê°„ë‹¨í•œ ì»¨ë³¼ë£¨ì…˜ ì—°ì‚°
            conv = torch.nn.Conv2d(3, 64, 3, padding=1).to(device)
            output = conv(images)
            torch.mps.synchronize()
            elapsed = time.time() - start
            
            memory_used = psutil.virtual_memory().percent
            print(f'  ë°°ì¹˜ {batch}: {elapsed:.3f}s (ë©”ëª¨ë¦¬: {memory_used:.1f}%)')
            
        except Exception as e:
            print(f'  ë°°ì¹˜ {batch}: ì‹¤íŒ¨ - {e}')
            break
    
    print('\\nâœ… M3 Max ë²¤ì¹˜ë§ˆí¬ ì™„ë£Œ')
    print(f'ðŸ’¡ ê¶Œìž¥ ë°°ì¹˜ í¬ê¸°: 8-16 (ë©”ëª¨ë¦¬ ì—¬ìœ ë¶„ ê³ ë ¤)')
    print(f'ðŸŽ 128GB í†µí•© ë©”ëª¨ë¦¬ì˜ ìž¥ì ì„ ìµœëŒ€í•œ í™œìš©í•˜ì„¸ìš”!')

else:
    print('âŒ MPSë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.')
    print('PyTorchì™€ macOS ë²„ì „ì„ í™•ì¸í•˜ì„¸ìš”.')
"
}

# íŒ¨í‚¤ì§€ ëª©ë¡ ì €ìž¥
save_conda_requirements() {
    log_header "íŒ¨í‚¤ì§€ ëª©ë¡ ì €ìž¥"
    
    ENV_NAME="mycloset-m3max"
    source "$(conda info --base)/etc/profile.d/conda.sh"
    conda activate "$ENV_NAME"
    
    # conda í™˜ê²½ export
    conda env export > environment_m3max.yml
    
    # pip requirements
    pip freeze > requirements_m3max.txt
    
    # ìš”ì•½ ì •ë³´
    cat > package_summary.md << 'EOF'
# MyCloset AI - M3 Max 128GB íŒ¨í‚¤ì§€ ëª©ë¡

## í™˜ê²½ ì •ë³´
- **í•˜ë“œì›¨ì–´**: Apple M3 Max 128GB
- **OS**: macOS (Apple Silicon)
- **Python**: 3.11
- **íŒ¨í‚¤ì§€ ê´€ë¦¬ìž**: Conda + pip

## í•µì‹¬ íŒ¨í‚¤ì§€
- **PyTorch**: 2.1.0 (MPS ì§€ì›)
- **Transformers**: 4.35.0
- **Diffusers**: 0.21.4
- **FastAPI**: 0.104.1
- **OpenCV**: 4.8.1

## ìž¬í˜„ ë°©ë²•
```bash
# 1. í™˜ê²½ ìƒì„±
conda env create -f environment_m3max.yml

# 2. í™˜ê²½ í™œì„±í™”
conda activate mycloset-m3max

# 3. ì„œë²„ ì‹¤í–‰
./run_m3max.sh
```

## ì„±ëŠ¥ ìµœì í™”
- Metal Performance Shaders (MPS) í™œì„±í™”
- 128GB í†µí•© ë©”ëª¨ë¦¬ ìµœëŒ€ í™œìš©
- Neural Engine ì—°ë™ ì¤€ë¹„
- ë°°ì¹˜ í¬ê¸°: 8-16 ê¶Œìž¥
EOF

    log_success "íŒ¨í‚¤ì§€ ëª©ë¡ ì €ìž¥ ì™„ë£Œ"
    echo "ðŸ“¦ environment_m3max.yml - Conda í™˜ê²½ íŒŒì¼"
    echo "ðŸ“¦ requirements_m3max.txt - pip íŒ¨í‚¤ì§€ ëª©ë¡"
    echo "ðŸ“¦ package_summary.md - ìš”ì•½ ì •ë³´"
}

# ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
main() {
    echo "ðŸŽ M3 Max 128GB + Conda í™˜ê²½ ì„¤ì •ì„ ì‹œìž‘í•©ë‹ˆë‹¤."
    echo ""
    echo "ë‹¤ìŒ ë‹¨ê³„ë“¤ì´ ì‹¤í–‰ë©ë‹ˆë‹¤:"
    echo "1. M3 Max 128GB í™˜ê²½ í™•ì¸"
    echo "2. Conda í™˜ê²½ ìƒì„± (mycloset-m3max)"
    echo "3. M3 Max ìµœì í™” íŒ¨í‚¤ì§€ ì„¤ì¹˜"
    echo "4. í™˜ê²½ ì„¤ì • íŒŒì¼ ìƒì„±"
    echo "5. ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰"
    echo "6. íŒ¨í‚¤ì§€ ëª©ë¡ ì €ìž¥"
    echo ""
    
    read -p "ê³„ì†í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/N): " confirm
    if [[ ! $confirm =~ ^[Yy]$ ]]; then
        echo "ì„¤ì •ì´ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤."
        exit 0
    fi
    
    # ë‹¨ê³„ë³„ ì‹¤í–‰
    check_m3_max_environment
    create_conda_environment
    install_m3_max_packages
    create_environment_config
    
    # ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰ ì—¬ë¶€ í™•ì¸
    echo ""
    read -p "ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ë¥¼ ì‹¤í–‰í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/N): " benchmark
    if [[ $benchmark =~ ^[Yy]$ ]]; then
        run_m3_max_benchmark
    fi
    
    save_conda_requirements
    
    # ì™„ë£Œ ë©”ì‹œì§€
    log_header "ðŸŽ‰ M3 Max 128GB í™˜ê²½ ì„¤ì • ì™„ë£Œ!"
    echo ""
    log_success "Conda í™˜ê²½ 'mycloset-m3max' ì¤€ë¹„ ì™„ë£Œ"
    log_success "M3 Max 128GB ìµœì í™” ì„¤ì • ì ìš©"
    log_success "Metal Performance Shaders (MPS) í™œì„±í™”"
    echo ""
    
    echo "ðŸš€ ë‹¤ìŒ ë‹¨ê³„:"
    echo "1. í™˜ê²½ í™œì„±í™”: source activate_m3max.sh"
    echo "2. ê°œë°œ ì„œë²„ ì‹¤í–‰: ./run_m3max.sh"
    echo "3. API ë¬¸ì„œ í™•ì¸: http://localhost:8000/docs"
    echo ""
    
    echo "ðŸ“‹ ìƒì„±ëœ íŒŒì¼ë“¤:"
    echo "- activate_m3max.sh: í™˜ê²½ í™œì„±í™” ìŠ¤í¬ë¦½íŠ¸"
    echo "- run_m3max.sh: ì„œë²„ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸"
    echo "- backend/.env: M3 Max ìµœì í™” í™˜ê²½ ë³€ìˆ˜"
    echo "- environment_m3max.yml: Conda í™˜ê²½ ë°±ì—…"
    echo "- requirements_m3max.txt: pip íŒ¨í‚¤ì§€ ëª©ë¡"
    echo ""
    
    echo "ðŸ’¡ ì‚¬ìš©ë²•:"
    echo "  source activate_m3max.sh && ./run_m3max.sh"
    echo ""
    
    log_info "M3 Max 128GB í™˜ê²½ ì„¤ì • ì™„ë£Œ! ðŸŽ‰"
}

# ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
main "$@"