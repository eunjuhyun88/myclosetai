#!/bin/bash

echo "ğŸ”¨ ëˆ„ë½ëœ íŒŒì´í”„ë¼ì¸ í´ë˜ìŠ¤ë“¤ ìƒì„± ì¤‘..."

cd backend

# 1. ë¨¼ì € í•„ìš”í•œ ìœ í‹¸ë¦¬í‹° í´ë˜ìŠ¤ë“¤ ìƒì„±
echo "ğŸ“¦ ê¸°ë³¸ ìœ í‹¸ë¦¬í‹° í´ë˜ìŠ¤ ìƒì„± ì¤‘..."

# ê°„ë‹¨í•œ ë©”ëª¨ë¦¬ ë§¤ë‹ˆì €
cat > app/ai_pipeline/utils/memory_manager.py << 'EOF'
"""ë©”ëª¨ë¦¬ ê´€ë¦¬ ìœ í‹¸ë¦¬í‹°"""
import psutil
import torch
import logging

logger = logging.getLogger(__name__)

class GPUMemoryManager:
    def __init__(self, device="mps", memory_limit_gb=16.0):
        self.device = device
        self.memory_limit_gb = memory_limit_gb
    
    def clear_cache(self):
        """ë©”ëª¨ë¦¬ ì •ë¦¬"""
        if torch.backends.mps.is_available():
            torch.mps.empty_cache()
        elif torch.cuda.is_available():
            torch.cuda.empty_cache()
    
    def check_memory_usage(self):
        """ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í™•ì¸"""
        memory = psutil.virtual_memory()
        used_gb = memory.used / (1024**3)
        if used_gb > self.memory_limit_gb * 0.9:
            logger.warning(f"ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë†’ìŒ: {used_gb:.1f}GB")
            self.clear_cache()
EOF

# ëª¨ë¸ ë¡œë”
cat > app/ai_pipeline/utils/model_loader.py << 'EOF'
"""ëª¨ë¸ ë¡œë”© ìœ í‹¸ë¦¬í‹°"""
import torch
import logging

logger = logging.getLogger(__name__)

class ModelLoader:
    def __init__(self, device="mps", use_fp16=True):
        self.device = torch.device(device)
        self.use_fp16 = use_fp16
        self.loaded_models = {}
    
    def load_model(self, model_name, model_path=None):
        """ë”ë¯¸ ëª¨ë¸ ë¡œë“œ"""
        logger.info(f"ë”ë¯¸ ëª¨ë¸ ë¡œë“œ: {model_name}")
        
        class DummyModel:
            def __init__(self, name):
                self.name = name
            
            def __call__(self, *args, **kwargs):
                return {"result": f"dummy_{self.name}", "success": True}
        
        model = DummyModel(model_name)
        self.loaded_models[model_name] = model
        return model
EOF

# ë°ì´í„° ë³€í™˜ê¸°
cat > app/ai_pipeline/utils/data_converter.py << 'EOF'
"""ë°ì´í„° ë³€í™˜ ìœ í‹¸ë¦¬í‹°"""
import torch
import numpy as np
from PIL import Image
import torchvision.transforms as transforms

class DataConverter:
    def __init__(self):
        self.transform = transforms.Compose([
            transforms.Resize((512, 512)),
            transforms.ToTensor(),
        ])
    
    def image_to_tensor(self, image, size=512):
        """PIL ì´ë¯¸ì§€ë¥¼ í…ì„œë¡œ ë³€í™˜"""
        if isinstance(image, Image.Image):
            image = image.resize((size, size))
            tensor = self.transform(image)
            return tensor.unsqueeze(0)  # ë°°ì¹˜ ì°¨ì› ì¶”ê°€
        return image
    
    def tensor_to_numpy(self, tensor):
        """í…ì„œë¥¼ numpy ë°°ì—´ë¡œ ë³€í™˜"""
        if torch.is_tensor(tensor):
            # ë°°ì¹˜ ì°¨ì› ì œê±°í•˜ê³  (C, H, W) -> (H, W, C)ë¡œ ë³€í™˜
            tensor = tensor.squeeze(0) if tensor.dim() == 4 else tensor
            if tensor.dim() == 3:
                tensor = tensor.permute(1, 2, 0)
            
            # [0, 1] ë²”ìœ„ë¥¼ [0, 255]ë¡œ ë³€í™˜
            array = tensor.cpu().numpy()
            if array.max() <= 1.0:
                array = (array * 255).astype(np.uint8)
            return array
        return tensor
EOF

# 2. ê° ë‹¨ê³„ë³„ ë”ë¯¸ í´ë˜ìŠ¤ë“¤ ìƒì„±
echo "ğŸ”§ 8ë‹¨ê³„ ë”ë¯¸ í´ë˜ìŠ¤ë“¤ ìƒì„± ì¤‘..."

for i in {1..8}; do
    step_names=(
        "human_parsing"
        "pose_estimation" 
        "cloth_segmentation"
        "geometric_matching"
        "cloth_warping"
        "virtual_fitting"
        "post_processing"
        "quality_assessment"
    )
    
    step_name=${step_names[$((i-1))]}
    file_name="step_0${i}_${step_name}.py"
    
    cat > "app/ai_pipeline/steps/$file_name" << EOF
"""Step $i: ${step_name^} ë‹¨ê³„"""

import asyncio
import torch
import numpy as np
from typing import Any, Dict

class ${step_name^}Step:
    def __init__(self, config=None, device="mps", model_loader=None):
        self.config = config
        self.device = device
        self.model_loader = model_loader
        self.name = "${step_name}"
    
    async def process(self, input_data: Any) -> Dict[str, Any]:
        """${step_name} ì²˜ë¦¬ (ë”ë¯¸)"""
        # ì²˜ë¦¬ ì‹œë®¬ë ˆì´ì…˜
        await asyncio.sleep(0.5)
        
        result = {
            "step": "${step_name}",
            "success": True,
            "data": f"processed_${step_name}",
            "confidence": 0.85 + (hash("${step_name}") % 100) / 1000.0
        }
        
        # íŠ¹ë³„í•œ ë°˜í™˜ê°’ë“¤
        if "${step_name}" == "human_parsing":
            result["body_measurements"] = {
                "chest": 88.0, "waist": 70.0, "hip": 92.0, "bmi": 22.5
            }
        elif "${step_name}" == "cloth_segmentation":
            result["cloth_type"] = "ìƒì˜"
            result["cloth_confidence"] = 0.9
        elif "${step_name}" == "quality_assessment":
            result = {
                "overall_score": 0.88,
                "fit_coverage": 0.85,
                "color_preservation": 0.92,
                "fit_overall": 0.87,
                "ssim": 0.89,
                "lpips": 0.85
            }
        
        return result
    
    async def warmup(self, dummy_input):
        """ì›Œë°ì—…"""
        await asyncio.sleep(0.1)
    
    def cleanup(self):
        """ì •ë¦¬"""
        pass
EOF

done

# 3. ë©”ì¸ pipeline_manager.py êµì²´ 
echo "ğŸ”„ pipeline_manager.py ì¬ìƒì„± ì¤‘..."

cat > app/ai_pipeline/pipeline_manager.py << 'EOF'
"""
MyCloset AI ê°€ìƒ í”¼íŒ… íŒŒì´í”„ë¼ì¸ ë©”ì¸ í´ë˜ìŠ¤
"""

import asyncio
import time
import logging
from typing import Dict, Any, Optional, Callable
import torch
import numpy as np
from PIL import Image
from dataclasses import dataclass

# ìœ í‹¸ë¦¬í‹° import
from .utils.memory_manager import GPUMemoryManager
from .utils.model_loader import ModelLoader
from .utils.data_converter import DataConverter

# ê° ë‹¨ê³„ import
from .steps.step_01_human_parsing import HumanParsingStep
from .steps.step_02_pose_estimation import PoseEstimationStep  
from .steps.step_03_cloth_segmentation import ClothSegmentationStep
from .steps.step_04_geometric_matching import GeometricMatchingStep
from .steps.step_05_cloth_warping import ClothWarpingStep
from .steps.step_06_virtual_fitting import VirtualFittingStep
from .steps.step_07_post_processing import PostProcessingStep
from .steps.step_08_quality_assessment import QualityAssessmentStep

logger = logging.getLogger(__name__)

@dataclass
class PipelineConfig:
    """íŒŒì´í”„ë¼ì¸ ì„¤ì •"""
    device: str = "mps"
    batch_size: int = 1
    image_size: int = 512
    use_fp16: bool = True
    enable_caching: bool = True
    parallel_steps: bool = True
    memory_limit_gb: float = 16.0
    quality_threshold: float = 0.8
    quality_mode: str = "balanced"

@dataclass 
class PipelineResult:
    """íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ê²°ê³¼"""
    success: bool
    fitted_image: Optional[np.ndarray] = None
    processing_time: float = 0.0
    step_times: Dict[str, float] = None
    quality_scores: Dict[str, float] = None
    intermediate_results: Dict[str, Any] = None
    memory_usage: Dict[str, float] = None
    error_message: Optional[str] = None
    
    def __post_init__(self):
        if self.step_times is None:
            self.step_times = {}
        if self.quality_scores is None:
            self.quality_scores = {}
        if self.intermediate_results is None:
            self.intermediate_results = {}
        if self.memory_usage is None:
            self.memory_usage = {}

class VirtualTryOnPipeline:
    """ë©”ì¸ ê°€ìƒ í”¼íŒ… íŒŒì´í”„ë¼ì¸ í´ë˜ìŠ¤"""
    
    def __init__(self, config: PipelineConfig = None):
        self.config = config or PipelineConfig()
        self.logger = logging.getLogger(__name__)
        
        # ë””ë°”ì´ìŠ¤ ì„¤ì •
        self.device = self._setup_device()
        
        # ìœ í‹¸ë¦¬í‹° ì´ˆê¸°í™”
        self.memory_manager = GPUMemoryManager(
            device=str(self.device), 
            memory_limit_gb=self.config.memory_limit_gb
        )
        self.model_loader = ModelLoader(device=str(self.device), use_fp16=self.config.use_fp16)
        self.data_converter = DataConverter()
        
        # ê° ë‹¨ê³„ ì´ˆê¸°í™”
        self._initialize_steps()
        
        # ì„±ëŠ¥ ì¶”ì 
        self.step_times = {}
        self.progress_callback: Optional[Callable] = None
        
        self.logger.info(f"âœ… VirtualTryOnPipeline ì´ˆê¸°í™” ì™„ë£Œ (device: {self.device})")

    def _setup_device(self):
        """ë””ë°”ì´ìŠ¤ ì„¤ì •"""
        if torch.backends.mps.is_available():
            return torch.device("mps")
        elif torch.cuda.is_available():
            return torch.device("cuda")
        else:
            return torch.device("cpu")
    
    def _initialize_steps(self):
        """8ë‹¨ê³„ ì´ˆê¸°í™”"""
        try:
            self.steps = {
                "human_parsing": HumanParsingStep(self.config, str(self.device), self.model_loader),
                "pose_estimation": PoseEstimationStep(self.config, str(self.device), self.model_loader),
                "cloth_segmentation": ClothSegmentationStep(self.config, str(self.device), self.model_loader),
                "geometric_matching": GeometricMatchingStep(self.config, str(self.device)),
                "cloth_warping": ClothWarpingStep(self.config, str(self.device)),
                "virtual_fitting": VirtualFittingStep(self.config, str(self.device), self.model_loader),
                "post_processing": PostProcessingStep(self.config, str(self.device)),
                "quality_assessment": QualityAssessmentStep(self.config, str(self.device))
            }
            self.logger.info("âœ… 8ë‹¨ê³„ íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” ì™„ë£Œ")
        except Exception as e:
            self.logger.error(f"âŒ ë‹¨ê³„ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.steps = {}

    async def process(
        self, 
        person_image: Image.Image,
        cloth_image: Image.Image, 
        user_measurements: Dict[str, float] = None
    ) -> PipelineResult:
        """ë©”ì¸ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
        start_time = time.time()
        
        try:
            self.logger.info("ğŸš€ 8ë‹¨ê³„ ê°€ìƒ í”¼íŒ… íŒŒì´í”„ë¼ì¸ ì‹œì‘")
            
            # ë©”ëª¨ë¦¬ ì •ë¦¬
            self.memory_manager.clear_cache()
            
            # ì´ë¯¸ì§€ ì „ì²˜ë¦¬
            person_tensor = self.data_converter.image_to_tensor(person_image, self.config.image_size)
            cloth_tensor = self.data_converter.image_to_tensor(cloth_image, self.config.image_size)
            
            # ê° ë‹¨ê³„ ì‹¤í–‰
            intermediate_results = {}
            step_names = list(self.steps.keys())
            
            current_data = {
                "person_image": person_tensor,
                "cloth_image": cloth_tensor,
                "user_measurements": user_measurements or {}
            }
            
            for i, (step_name, step) in enumerate(self.steps.items()):
                step_start = time.time()
                
                # ì§„í–‰ë¥  ì½œë°±
                if self.progress_callback:
                    await self.progress_callback(i, 0.0)
                
                self.logger.info(f"ğŸ“‹ ë‹¨ê³„ {i+1}/8: {step_name} ì²˜ë¦¬ ì¤‘...")
                
                # ë‹¨ê³„ ì‹¤í–‰
                step_result = await step.process(current_data)
                intermediate_results[step_name] = step_result
                
                # ë‹¤ìŒ ë‹¨ê³„ë¥¼ ìœ„í•´ ë°ì´í„° ì—…ë°ì´íŠ¸
                if isinstance(step_result, dict):
                    current_data.update(step_result)
                
                # ì‹œê°„ ê¸°ë¡
                step_time = time.time() - step_start
                self.step_times[step_name] = step_time
                
                # ì§„í–‰ë¥  ì™„ë£Œ
                if self.progress_callback:
                    await self.progress_callback(i, 1.0)
                
                self.logger.info(f"âœ… {step_name} ì™„ë£Œ ({step_time:.2f}s)")
            
            # ìµœì¢… ê²°ê³¼ ì´ë¯¸ì§€ ìƒì„± (ë”ë¯¸)
            final_image = self._generate_dummy_result_image()
            
            # í’ˆì§ˆ ì ìˆ˜ (ë”ë¯¸)
            quality_scores = intermediate_results.get('quality_assessment', {
                "overall_score": 0.88,
                "fit_coverage": 0.85, 
                "color_preservation": 0.92,
                "fit_overall": 0.87
            })
            
            processing_time = time.time() - start_time
            
            result = PipelineResult(
                success=True,
                fitted_image=final_image,
                processing_time=processing_time,
                step_times=self.step_times.copy(),
                quality_scores=quality_scores,
                intermediate_results=intermediate_results,
                memory_usage=self.memory_manager.get_usage() if hasattr(self.memory_manager, 'get_usage') else {}
            )
            
            self.logger.info(f"ğŸ‰ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ! ì´ ì‹œê°„: {processing_time:.2f}s")
            return result
            
        except Exception as e:
            self.logger.error(f"âŒ íŒŒì´í”„ë¼ì¸ ì˜¤ë¥˜: {e}")
            return PipelineResult(
                success=False,
                processing_time=time.time() - start_time,
                error_message=str(e)
            )
    
    def _generate_dummy_result_image(self) -> np.ndarray:
        """ë”ë¯¸ ê²°ê³¼ ì´ë¯¸ì§€ ìƒì„±"""
        # 512x512 ì»¬ëŸ¬í’€í•œ ë”ë¯¸ ì´ë¯¸ì§€
        image = np.zeros((512, 512, 3), dtype=np.uint8)
        
        # ê·¸ë¼ë°ì´ì…˜ íŒ¨í„´ ìƒì„±
        for i in range(512):
            for j in range(512):
                image[i, j] = [
                    int(128 + 127 * np.sin(i * 0.02)),
                    int(128 + 127 * np.cos(j * 0.02)), 
                    int(128 + 127 * np.sin((i + j) * 0.01))
                ]
        
        return image

    def get_pipeline_status(self) -> Dict[str, Any]:
        """íŒŒì´í”„ë¼ì¸ ìƒíƒœ ë°˜í™˜"""
        return {
            "device": str(self.device),
            "config": self.config.__dict__ if hasattr(self.config, '__dict__') else {},
            "steps_loaded": len(self.steps),
            "step_names": list(self.steps.keys()),
            "memory_usage": getattr(self.memory_manager, 'get_usage', lambda: {})()
        }
    
    async def warmup(self):
        """íŒŒì´í”„ë¼ì¸ ì›Œë°ì—…"""
        self.logger.info("ğŸ”¥ íŒŒì´í”„ë¼ì¸ ì›Œë°ì—… ì‹œì‘...")
        
        # ë”ë¯¸ ì´ë¯¸ì§€ë¡œ ì›Œë°ì—…
        dummy_person = Image.new('RGB', (512, 512), color=(255, 0, 0))
        dummy_cloth = Image.new('RGB', (512, 512), color=(0, 0, 255))
        
        try:
            result = await self.process(dummy_person, dummy_cloth)
            if result.success:
                self.logger.info("âœ… ì›Œë°ì—… ì™„ë£Œ")
            else:
                self.logger.warning(f"âš ï¸ ì›Œë°ì—… ì¤‘ ì˜¤ë¥˜: {result.error_message}")
        except Exception as e:
            self.logger.warning(f"âš ï¸ ì›Œë°ì—… ì‹¤íŒ¨: {e}")
    
    def cleanup(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        self.logger.info("ğŸ§¹ íŒŒì´í”„ë¼ì¸ ë¦¬ì†ŒìŠ¤ ì •ë¦¬...")
        
        for step in self.steps.values():
            if hasattr(step, 'cleanup'):
                step.cleanup()
        
        self.memory_manager.clear_cache()
        self.steps.clear()
        
        self.logger.info("âœ… ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì™„ë£Œ")

class PipelineFactory:
    """íŒŒì´í”„ë¼ì¸ íŒ©í† ë¦¬ í´ë˜ìŠ¤"""
    
    @staticmethod
    def create_optimized_pipeline(
        memory_gb: float = 16.0,
        quality_mode: str = "balanced"
    ) -> VirtualTryOnPipeline:
        """ìµœì í™”ëœ íŒŒì´í”„ë¼ì¸ ìƒì„±"""
        
        # í’ˆì§ˆ ëª¨ë“œë³„ ì„¤ì •
        if quality_mode == "fast":
            config = PipelineConfig(
                device="mps",
                image_size=256,
                use_fp16=True,
                parallel_steps=True,
                memory_limit_gb=memory_gb,
                quality_threshold=0.7,
                quality_mode="fast"
            )
        elif quality_mode == "quality":
            config = PipelineConfig(
                device="mps", 
                image_size=1024,
                use_fp16=False,
                parallel_steps=False,
                memory_limit_gb=memory_gb,
                quality_threshold=0.9,
                quality_mode="quality"
            )
        else:  # balanced
            config = PipelineConfig(
                device="mps",
                image_size=512,
                use_fp16=True,
                parallel_steps=True,
                memory_limit_gb=memory_gb,
                quality_threshold=0.8,
                quality_mode="balanced"
            )
        
        pipeline = VirtualTryOnPipeline(config)
        logger.info(f"âœ… {quality_mode} ëª¨ë“œ íŒŒì´í”„ë¼ì¸ ìƒì„± ì™„ë£Œ")
        
        return pipeline

# í•˜ìœ„ í˜¸í™˜ì„±ì„ ìœ„í•œ ë³„ì¹­
VirtualFittingPipeline = VirtualTryOnPipeline
EOF

echo "âœ… ëª¨ë“  íŒŒì´í”„ë¼ì¸ í´ë˜ìŠ¤ ìƒì„± ì™„ë£Œ!"

# 4. Python import í…ŒìŠ¤íŠ¸
echo "ğŸ§ª import í…ŒìŠ¤íŠ¸ ì¤‘..."

python -c "
import sys
sys.path.insert(0, '.')

try:
    from app.ai_pipeline.pipeline_manager import VirtualTryOnPipeline, PipelineFactory
    from app.core.pipeline_config import PipelineConfig
    print('âœ… ëª¨ë“  í´ë˜ìŠ¤ import ì„±ê³µ!')
    
    # ê°„ë‹¨í•œ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸
    pipeline = PipelineFactory.create_optimized_pipeline()
    print(f'âœ… PipelineFactory í…ŒìŠ¤íŠ¸ ì„±ê³µ: {type(pipeline).__name__}')
    
    status = pipeline.get_pipeline_status()
    print(f'âœ… Pipeline ìƒíƒœ ì¡°íšŒ ì„±ê³µ: {len(status)} í•­ëª©')
    
except Exception as e:
    print(f'âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}')
    import traceback
    traceback.print_exc()
    sys.exit(1)
"

if [ $? -eq 0 ]; then
    echo ""
    echo "ğŸ‰ íŒŒì´í”„ë¼ì¸ í´ë˜ìŠ¤ ìƒì„± ë° í…ŒìŠ¤íŠ¸ ì™„ë£Œ!"
    echo "================================================"
    echo "âœ… VirtualTryOnPipeline: 8ë‹¨ê³„ AI íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"
    echo "âœ… PipelineFactory: í’ˆì§ˆ ëª¨ë“œë³„ íŒŒì´í”„ë¼ì¸ ìƒì„±"
    echo "âœ… 8ê°œ ì²˜ë¦¬ ë‹¨ê³„: ë”ë¯¸ êµ¬í˜„ìœ¼ë¡œ í…ŒìŠ¤íŠ¸ ê°€ëŠ¥"
    echo "âœ… ë©”ëª¨ë¦¬ ê´€ë¦¬: M3 Max ìµœì í™”"
    echo ""
    echo "ğŸš€ ì´ì œ ì„œë²„ë¥¼ ì¬ì‹œì‘í•˜ì„¸ìš”:"
    echo "   python run_server.py"
else
    echo "âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨. ìˆ˜ë™ í™•ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤."
fi