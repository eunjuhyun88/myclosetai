#!/bin/bash
# ==============================================================================
# MyCloset AI - ê¸°ì¡´ í”„ë¡œì íŠ¸ìš© M3 Max ìµœì í™” Conda í™˜ê²½ ì„¤ì •
# ì´ë¯¸ ë§Œë“¤ì–´ì§„ ë””ë ‰í† ë¦¬ êµ¬ì¡°ë¥¼ í™œìš©í•˜ì—¬ í™˜ê²½ë§Œ ì„¤ì •
# ==============================================================================

set -e  # ì—ëŸ¬ ë°œìƒì‹œ ìŠ¤í¬ë¦½íŠ¸ ì¤‘ë‹¨

# ìƒ‰ìƒ ì •ì˜
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
PURPLE='\033[0;35m'
NC='\033[0m' # No Color

# ë¡œê·¸ í•¨ìˆ˜ë“¤
log_info() { echo -e "${BLUE}â„¹ï¸  $1${NC}"; }
log_success() { echo -e "${GREEN}âœ… $1${NC}"; }
log_warning() { echo -e "${YELLOW}âš ï¸  $1${NC}"; }
log_error() { echo -e "${RED}âŒ $1${NC}"; }
log_header() { echo -e "${PURPLE}ğŸš€ $1${NC}"; }

# í”„ë¡œì íŠ¸ ì •ë³´
PROJECT_NAME="mycloset-ai"
CONDA_ENV_NAME="mycloset-m3"
PYTHON_VERSION="3.11"

log_header "MyCloset AI - ê¸°ì¡´ í”„ë¡œì íŠ¸ M3 Max ìµœì í™” ì„¤ì •"
echo "=================================================================="
log_info "í”„ë¡œì íŠ¸: $(pwd)"
log_info "Python: $PYTHON_VERSION"
log_info "Conda í™˜ê²½ëª…: $CONDA_ENV_NAME"
echo ""

# 1. ì‹œìŠ¤í…œ ì²´í¬
log_header "Step 1: ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­ ì²´í¬"

# macOS ë° Apple Silicon ì²´í¬
if [[ "$(uname -s)" != "Darwin" ]]; then
    log_error "ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” macOS ì „ìš©ì…ë‹ˆë‹¤."
    exit 1
fi

if [[ "$(uname -m)" != "arm64" ]]; then
    log_error "Apple Silicon (M1/M2/M3) Macì´ í•„ìš”í•©ë‹ˆë‹¤."
    exit 1
fi

log_success "Apple Silicon Mac í™•ì¸ë¨"

# Conda ì„¤ì¹˜ ì²´í¬
if ! command -v conda &> /dev/null; then
    log_error "Condaê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤."
    log_info "Miniconda ì„¤ì¹˜: https://docs.conda.io/en/latest/miniconda.html"
    exit 1
fi

log_success "Conda ì„¤ì¹˜ í™•ì¸ë¨: $(conda --version)"

# ê¸°ì¡´ í”„ë¡œì íŠ¸ êµ¬ì¡° í™•ì¸
log_info "ê¸°ì¡´ í”„ë¡œì íŠ¸ êµ¬ì¡° í™•ì¸ ì¤‘..."

required_dirs=("backend" "backend/app" "backend/app/core")
missing_dirs=()

for dir in "${required_dirs[@]}"; do
    if [[ -d "$dir" ]]; then
        log_success "ë””ë ‰í† ë¦¬ í™•ì¸: $dir"
    else
        missing_dirs+=("$dir")
        log_warning "ë””ë ‰í† ë¦¬ ëˆ„ë½: $dir"
    fi
done

# ëˆ„ë½ëœ í•µì‹¬ ë””ë ‰í† ë¦¬ë§Œ ìƒì„±
if [[ ${#missing_dirs[@]} -gt 0 ]]; then
    log_info "ëˆ„ë½ëœ í•µì‹¬ ë””ë ‰í† ë¦¬ ìƒì„± ì¤‘..."
    for dir in "${missing_dirs[@]}"; do
        mkdir -p "$dir"
        log_info "ìƒì„±: $dir"
    done
fi

# 2. Conda í™˜ê²½ ìƒì„±
log_header "Step 2: Conda í™˜ê²½ ìƒì„± ë° ì„¤ì •"

# Conda ì´ˆê¸°í™”
source "$(conda info --base)/etc/profile.d/conda.sh"

# ê¸°ì¡´ í™˜ê²½ ì œê±° (ìˆë‹¤ë©´)
if conda env list | grep -q "$CONDA_ENV_NAME"; then
    log_warning "ê¸°ì¡´ í™˜ê²½ '$CONDA_ENV_NAME' ì œê±° ì¤‘..."
    conda env remove -n "$CONDA_ENV_NAME" -y
fi

# ìƒˆ í™˜ê²½ ìƒì„±
log_info "Conda í™˜ê²½ '$CONDA_ENV_NAME' ìƒì„± ì¤‘..."
conda create -n "$CONDA_ENV_NAME" python="$PYTHON_VERSION" -y

# í™˜ê²½ í™œì„±í™”
log_info "í™˜ê²½ í™œì„±í™” ì¤‘..."
conda activate "$CONDA_ENV_NAME"

log_success "Conda í™˜ê²½ '$CONDA_ENV_NAME' ìƒì„± ì™„ë£Œ"

# 3. M3 Max ìµœì í™” íŒ¨í‚¤ì§€ ì„¤ì¹˜
log_header "Step 3: M3 Max ìµœì í™” íŒ¨í‚¤ì§€ ì„¤ì¹˜"

# conda-forge ì±„ë„ ì¶”ê°€
conda config --add channels conda-forge
conda config --add channels pytorch
conda config --add channels apple

# PyTorch M3 Max ìµœì í™” ë²„ì „ ì„¤ì¹˜
log_info "PyTorch (M3 Max Metal ìµœì í™”) ì„¤ì¹˜ ì¤‘..."
conda install pytorch torchvision torchaudio -c pytorch -y

# ê¸°ë³¸ íŒ¨í‚¤ì§€ ì„¤ì¹˜
log_info "ê¸°ë³¸ íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì¤‘..."
conda install -y \
    numpy=1.24.3 \
    scipy=1.11.4 \
    pillow=10.1.0 \
    opencv=4.8.1 \
    scikit-image=0.22.0 \
    scikit-learn=1.3.2 \
    pydantic=2.5.0 \
    requests=2.31.0 \
    tqdm=4.66.1

# pipë¡œ ì¶”ê°€ íŒ¨í‚¤ì§€ ì„¤ì¹˜
log_info "FastAPI ë° ì›¹ ì„œë²„ íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì¤‘..."
pip install \
    fastapi==0.104.1 \
    uvicorn[standard]==0.24.0 \
    python-multipart==0.0.6 \
    aiofiles==23.2.1 \
    python-dotenv==1.0.0 \
    pydantic-settings==2.1.0

log_info "AI/ML íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì¤‘..."
pip install \
    transformers==4.35.0 \
    diffusers==0.21.4 \
    accelerate==0.24.1 \
    mediapipe==0.10.7

log_info "ê°œë°œ ë„êµ¬ ì„¤ì¹˜ ì¤‘..."
pip install \
    structlog==23.1.0 \
    pytest==7.4.3 \
    pytest-asyncio==0.21.1 \
    black==23.11.0 \
    isort==5.12.0

log_success "íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì™„ë£Œ"

# 4. í•„ìš”í•œ ë””ë ‰í† ë¦¬ ë³´ì™„ (ìˆëŠ” ê²ƒì€ ê±´ë“œë¦¬ì§€ ì•ŠìŒ)
log_header "Step 4: í”„ë¡œì íŠ¸ ë””ë ‰í† ë¦¬ ë³´ì™„"

# í•„ìš”í•œ í•˜ìœ„ ë””ë ‰í† ë¦¬ë“¤ ìƒì„± (ì—†ëŠ” ê²ƒë§Œ)
additional_dirs=(
    "backend/ai_models/checkpoints"
    "backend/ai_models/temp"
    "backend/static/uploads"
    "backend/static/results"
    "backend/logs"
    "backend/scripts"
    "backend/app/api"
    "backend/app/services"
    "backend/app/utils"
    "backend/app/models"
    "backend/tests"
)

for dir in "${additional_dirs[@]}"; do
    if [[ ! -d "$dir" ]]; then
        mkdir -p "$dir"
        log_info "ìƒì„±: $dir"
    fi
done

# .gitkeep íŒŒì¼ ìƒì„± (ë¹ˆ ë””ë ‰í† ë¦¬ ìœ ì§€)
gitkeep_dirs=(
    "backend/static/uploads"
    "backend/static/results"
    "backend/ai_models/checkpoints"
    "backend/ai_models/temp"
    "backend/logs"
)

for dir in "${gitkeep_dirs[@]}"; do
    if [[ -d "$dir" && ! -f "$dir/.gitkeep" ]]; then
        touch "$dir/.gitkeep"
        log_info ".gitkeep ìƒì„±: $dir"
    fi
done

log_success "í”„ë¡œì íŠ¸ ë””ë ‰í† ë¦¬ ë³´ì™„ ì™„ë£Œ"

# 5. M3 Max GPU í…ŒìŠ¤íŠ¸
log_header "Step 5: M3 Max GPU (Metal) í…ŒìŠ¤íŠ¸"

python3 -c "
import torch
import platform
import sys

print(f'Python ë²„ì „: {sys.version}')
print(f'PyTorch ë²„ì „: {torch.__version__}')
print(f'í”Œë«í¼: {platform.platform()}')
print(f'ì•„í‚¤í…ì²˜: {platform.machine()}')
print()

# MPS ì²´í¬
if torch.backends.mps.is_available():
    print('âœ… MPS (Metal Performance Shaders) ì‚¬ìš© ê°€ëŠ¥')
    device = torch.device('mps')
    
    # ê°„ë‹¨í•œ ì—°ì‚° í…ŒìŠ¤íŠ¸
    print('ğŸ§ª GPU ì—°ì‚° í…ŒìŠ¤íŠ¸ ì¤‘...')
    x = torch.randn(1000, 1000, device=device)
    y = torch.randn(1000, 1000, device=device)
    
    import time
    start = time.time()
    z = torch.mm(x, y)
    end = time.time()
    
    print(f'âœ… M3 Max GPU ì—°ì‚° ì„±ê³µ: {end-start:.4f}ì´ˆ')
    print(f'âœ… í…ì„œ í¬ê¸°: {z.shape}')
    print(f'âœ… ë””ë°”ì´ìŠ¤: {z.device}')
    
else:
    print('âš ï¸ MPS ì‚¬ìš© ë¶ˆê°€ - CPU ëª¨ë“œë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤')
    print('   macOS 12.3+ ë° PyTorch 1.12+ í•„ìš”')
"

# 6. í™˜ê²½ ì„¤ì • íŒŒì¼ ìƒì„±/ì—…ë°ì´íŠ¸
log_header "Step 6: í™˜ê²½ ì„¤ì • íŒŒì¼ ìƒì„±"

# backend/.env íŒŒì¼ ìƒì„± (ì—†ëŠ” ê²½ìš°ë§Œ)
if [[ ! -f "backend/.env" ]]; then
    log_info "backend/.env íŒŒì¼ ìƒì„± ì¤‘..."
    cat > backend/.env << 'EOF'
# MyCloset AI Backend - M3 Max ìµœì í™” ì„¤ì •
APP_NAME=MyCloset AI Backend
APP_VERSION=1.0.0
DEBUG=true
HOST=0.0.0.0
PORT=8000

# CORS Settings
CORS_ORIGINS=http://localhost:3000,http://localhost:3001

# M3 Max GPU ì„¤ì •
USE_GPU=true
DEVICE=mps
BATCH_SIZE=1
MAX_MEMORY_FRACTION=0.8

# File Upload Settings
MAX_UPLOAD_SIZE=52428800
ALLOWED_EXTENSIONS=jpg,jpeg,png,webp

# AI Model Settings
DEFAULT_MODEL=ootd
IMAGE_SIZE=512
NUM_INFERENCE_STEPS=20
GUIDANCE_SCALE=7.5

# Logging
LOG_LEVEL=INFO
LOG_FILE=logs/app.log
EOF
    log_success "backend/.env íŒŒì¼ ìƒì„± ì™„ë£Œ"
else
    log_info "backend/.env íŒŒì¼ì´ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤."
fi

# backend/requirements.txt ì—…ë°ì´íŠ¸ (ë°±ì—… í›„ ìƒì„±)
if [[ -f "backend/requirements.txt" ]]; then
    cp backend/requirements.txt backend/requirements.txt.backup
    log_info "ê¸°ì¡´ requirements.txt ë°±ì—… ìƒì„±"
fi

log_info "backend/requirements.txt ì—…ë°ì´íŠ¸ ì¤‘..."
cat > backend/requirements.txt << 'EOF'
# MyCloset AI - M3 Max ìµœì í™” íŒ¨í‚¤ì§€ ëª©ë¡
# Conda í™˜ê²½ì—ì„œ ì„¤ì¹˜ëœ íŒ¨í‚¤ì§€ë“¤ì˜ ì°¸ì¡°ìš©

# Core ML/AI
torch>=2.1.0
torchvision>=0.16.0
numpy==1.24.3
scipy==1.11.4

# FastAPI & Web
fastapi==0.104.1
uvicorn[standard]==0.24.0
python-multipart==0.0.6

# Image Processing
Pillow==10.1.0
opencv-python==4.8.1.78
scikit-image==0.22.0

# AI/ML
transformers==4.35.0
diffusers==0.21.4
accelerate==0.24.1
mediapipe==0.10.7

# Utils
pydantic==2.5.0
pydantic-settings==2.1.0
aiofiles==23.2.1
python-dotenv==1.0.0
structlog==23.1.0
requests==2.31.0
tqdm==4.66.1

# Development
pytest==7.4.3
pytest-asyncio==0.21.1
black==23.11.0
isort==5.12.0
EOF

log_success "requirements.txt ì—…ë°ì´íŠ¸ ì™„ë£Œ"

# 7. í™œì„±í™” ìŠ¤í¬ë¦½íŠ¸ ìƒì„±
log_header "Step 7: í¸ì˜ ìŠ¤í¬ë¦½íŠ¸ ìƒì„±"

# Conda í™˜ê²½ í™œì„±í™” ìŠ¤í¬ë¦½íŠ¸
cat > activate_env.sh << 'EOF'
#!/bin/bash
# MyCloset AI Conda í™˜ê²½ í™œì„±í™” ìŠ¤í¬ë¦½íŠ¸

source "$(conda info --base)/etc/profile.d/conda.sh"
conda activate mycloset-m3

echo "âœ… MyCloset AI M3 Max í™˜ê²½ í™œì„±í™”ë¨"
echo "ğŸ”§ Python: $(python --version)"
echo "âš¡ PyTorch: $(python -c 'import torch; print(torch.__version__)')"
echo "ğŸ–¥ï¸ GPU: $(python -c 'import torch; print("MPS" if torch.backends.mps.is_available() else "CPU")')"
echo ""
echo "ì‚¬ìš©ë²•:"
echo "  ê°œë°œ ì„œë²„ ì‹¤í–‰: cd backend && python app/main.py"
echo "  AI ëª¨ë¸ ë‹¤ìš´ë¡œë“œ: cd backend && python scripts/download_ai_models.py"
echo ""
EOF

chmod +x activate_env.sh

# ê°œë°œ ì„œë²„ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
cat > run_dev.sh << 'EOF'
#!/bin/bash
# MyCloset AI ê°œë°œ ì„œë²„ ì‹¤í–‰

# Conda í™˜ê²½ í™œì„±í™”
source "$(conda info --base)/etc/profile.d/conda.sh"
conda activate mycloset-m3

# ë°±ì—”ë“œ ë””ë ‰í† ë¦¬ë¡œ ì´ë™
cd backend

echo "ğŸš€ MyCloset AI ê°œë°œ ì„œë²„ ì‹œì‘..."
echo "ğŸ“ ì„œë²„ ì£¼ì†Œ: http://localhost:8000"
echo "ğŸ“š API ë¬¸ì„œ: http://localhost:8000/docs"
echo "â¤ï¸ í—¬ìŠ¤ì²´í¬: http://localhost:8000/health"
echo ""

# GPU ìƒíƒœ ì¶œë ¥
python -c "
import torch
if torch.backends.mps.is_available():
    print('âœ… M3 Max GPU (Metal) í™œì„±í™”ë¨')
else:
    print('âš ï¸ CPU ëª¨ë“œë¡œ ì‹¤í–‰')
print()
"

# ì„œë²„ ì‹¤í–‰ (main.pyê°€ ìˆìœ¼ë©´ ì‹¤í–‰, ì—†ìœ¼ë©´ ë©”ì‹œì§€ ì¶œë ¥)
if [[ -f "app/main.py" ]]; then
    python app/main.py
else
    echo "âš ï¸ backend/app/main.py íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤."
    echo "ë¨¼ì € FastAPI ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ìƒì„±í•˜ì„¸ìš”."
fi
EOF

chmod +x run_dev.sh

log_success "í¸ì˜ ìŠ¤í¬ë¦½íŠ¸ ìƒì„± ì™„ë£Œ"

# 8. ì™„ë£Œ ë©”ì‹œì§€
log_header "ğŸ‰ M3 Max ìµœì í™” í™˜ê²½ ì„¤ì • ì™„ë£Œ!"
echo ""
log_success "Conda í™˜ê²½ '$CONDA_ENV_NAME' ì¤€ë¹„ ì™„ë£Œ"
log_success "M3 Max GPU (Metal) ìµœì í™” ì ìš©ë¨"
log_success "ê¸°ì¡´ í”„ë¡œì íŠ¸ êµ¬ì¡° ë³´ì™„ ì™„ë£Œ"
echo ""

echo "ğŸš€ ë‹¤ìŒ ë‹¨ê³„:"
echo "1. í™˜ê²½ í™œì„±í™”: source activate_env.sh  (ë˜ëŠ” conda activate $CONDA_ENV_NAME)"
echo "2. GPU ì„¤ì • íŒŒì¼ ì¶”ê°€: backend/app/core/gpu_config.py"
echo "3. FastAPI ì•± ìƒì„±: backend/app/main.py"
echo "4. AI ëª¨ë¸ ë‹¤ìš´ë¡œë“œ: python backend/scripts/download_ai_models.py"
echo "5. ê°œë°œ ì„œë²„ ì‹¤í–‰: ./run_dev.sh"
echo ""

echo "ğŸ“š ìƒì„±ëœ íŒŒì¼:"
echo "- activate_env.sh : í™˜ê²½ í™œì„±í™”"
echo "- run_dev.sh : ê°œë°œ ì„œë²„ ì‹¤í–‰"
echo "- backend/.env : í™˜ê²½ë³€ìˆ˜ ì„¤ì •"
echo "- backend/requirements.txt : íŒ¨í‚¤ì§€ ëª©ë¡"
echo ""

echo "ğŸ“‹ í˜„ì¬ í™˜ê²½:"
echo "- Conda í™˜ê²½: $CONDA_ENV_NAME"
echo "- Python: $(python --version 2>/dev/null || echo 'í™˜ê²½ í™œì„±í™” í•„ìš”')"
echo "- í”„ë¡œì íŠ¸: $(pwd)"
echo ""

log_warning "í˜„ì¬ ì„¸ì…˜ì—ì„œ í™˜ê²½ì„ ì‚¬ìš©í•˜ë ¤ë©´:"
echo "conda activate $CONDA_ENV_NAME"