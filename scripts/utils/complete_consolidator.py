#!/usr/bin/env python3
"""
ğŸ”¥ ì™„ì „ ëª¨ë¸ í†µí•© ìŠ¤í¬ë¦½íŠ¸ v2.0 - ALL FORMATS
ëª¨ë“  AI ëª¨ë¸ í˜•ì‹ì„ backend/app/ai_pipeline/modelsë¡œ ì™„ì „ í†µí•©
âœ… .pth, .pt, .onnx, .safetensors, .mediapipe, .pkl, .bin ë“± ëª¨ë“  í˜•ì‹
âœ… HuggingFace ìºì‹œ + ì¼ë°˜ ëª¨ë¸ íŒŒì¼ ë™ì‹œ ì²˜ë¦¬
âœ… Stepë³„ ìë™ ë¶„ë¥˜ ë° ì¤‘ë³µ ì²˜ë¦¬
âœ… ì§„í–‰ë¥  í‘œì‹œ ë° ì•ˆì „í•œ ë³µì‚¬
"""

import os
import shutil
import json
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Set
import time
import re

class CompleteModelConsolidator:
    """ì™„ì „ ëª¨ë¸ í†µí•©ê¸° - ëª¨ë“  í˜•ì‹ ì§€ì›"""
    
    def __init__(self):
        self.project_root = Path("/Users/gimdudeul/MVP/mycloset-ai")
        self.search_paths = [
            self.project_root / "ai_models",
            self.project_root / "backend/ai_models"
        ]
        self.target_path = self.project_root / "backend/app/ai_pipeline/models"
        
        # ì§€ì›í•˜ëŠ” ëª¨ë“  ëª¨ë¸ í™•ì¥ì
        self.model_extensions = {
            '.pth': 'PyTorch ì²´í¬í¬ì¸íŠ¸',
            '.pt': 'PyTorch ëª¨ë¸',
            '.ckpt': 'ì²´í¬í¬ì¸íŠ¸ ëª¨ë¸',
            '.safetensors': 'SafeTensors (HuggingFace)',
            '.pkl': 'Pickle ëª¨ë¸',
            '.bin': 'Binary ëª¨ë¸',
            '.onnx': 'ONNX ëª¨ë¸',
            '.h5': 'Keras/TensorFlow',
            '.pb': 'TensorFlow SavedModel',
            '.mediapipe': 'MediaPipe ëª¨ë¸',
            '.pytorch': 'PyTorch ì €ì¥ ëª¨ë¸',
            '.tflite': 'TensorFlow Lite',
            '.mlmodel': 'Core ML (Apple)'
        }
        
        # Stepë³„ ë¶„ë¥˜ íŒ¨í„´ (ëª¨ë“  í™•ì¥ì ëŒ€ì‘)
        self.step_patterns = {
            "step_01_human_parsing": [
                r".*human.*parsing.*",
                r".*schp.*atr.*", r".*schp.*lip.*",
                r".*exp-schp.*", r".*graphonomy.*",
                r".*parsing.*atr.*", r".*parsing.*lip.*",
                r".*densepose.*", r".*atr.*model.*",
                r".*lip.*model.*"
            ],
            "step_02_pose_estimation": [
                r".*pose.*estimation.*", r".*openpose.*",
                r".*body.*pose.*", r".*hand.*pose.*",
                r".*mediapipe.*pose.*", r".*keypoint.*",
                r".*landmark.*"
            ],
            "step_03_cloth_segmentation": [
                r".*cloth.*seg.*", r".*u2net.*",
                r".*sam.*", r".*segment.*",
                r".*fashion.*clip.*", r".*rmbg.*",
                r".*background.*removal.*", r".*mask.*"
            ],
            "step_04_geometric_matching": [
                r".*geometric.*match.*", r".*gmm.*",
                r".*tps.*network.*", r".*warp.*network.*"
            ],
            "step_05_cloth_warping": [
                r".*cloth.*warp.*", r".*tom.*",
                r".*warping.*", r".*deformation.*"
            ],
            "step_06_virtual_fitting": [
                r".*virtual.*fitting.*", r".*oot.*diffusion.*",
                r".*idm.*vton.*", r".*hr.*viton.*",
                r".*stable.*diffusion.*", r".*diffusion.*pytorch.*",
                r".*unet.*", r".*vae.*", r".*text.*encoder.*"
            ],
            "step_07_post_processing": [
                r".*post.*process.*", r".*enhance.*",
                r".*super.*resolution.*", r".*sr.*",
                r".*upscale.*", r".*swinir.*",
                r".*real.*esrgan.*", r".*gfpgan.*",
                r".*codeformer.*"
            ],
            "step_08_quality_assessment": [
                r".*quality.*", r".*assessment.*",
                r".*clip.*vit.*", r".*score.*",
                r".*evaluation.*"
            ]
        }
        
        # ê²°ê³¼ ì¶”ì 
        self.results = {
            "found_files": [],
            "moved_files": [],
            "errors": [],
            "stats_by_extension": {},
            "stats_by_step": {}
        }
    
    def find_all_model_files(self) -> Dict[str, List[Path]]:
        """ëª¨ë“  ëª¨ë¸ íŒŒì¼ ì°¾ê¸° (ëª¨ë“  í™•ì¥ì)"""
        print("ğŸ” ëª¨ë“  í˜•ì‹ì˜ ëª¨ë¸ íŒŒì¼ ìŠ¤ìº” ì¤‘...")
        
        all_files = {}
        
        for search_path in self.search_paths:
            if not search_path.exists():
                continue
                
            print(f"ğŸ“‚ ìŠ¤ìº” ì¤‘: {search_path}")
            
            for ext in self.model_extensions.keys():
                files = list(search_path.rglob(f"*{ext}"))
                if files:
                    if ext not in all_files:
                        all_files[ext] = []
                    all_files[ext].extend(files)
        
        # ì¤‘ë³µ ì œê±° (ë™ì¼í•œ resolved path)
        for ext in all_files:
            unique_files = []
            seen_paths = set()
            
            for file_path in all_files[ext]:
                try:
                    resolved = file_path.resolve()
                    if resolved not in seen_paths:
                        seen_paths.add(resolved)
                        unique_files.append(file_path)
                except:
                    unique_files.append(file_path)
            
            all_files[ext] = unique_files
        
        # í†µê³„ ì¶œë ¥
        total_files = sum(len(files) for files in all_files.values())
        print(f"\nğŸ“Š ë°œê²¬ëœ ëª¨ë¸ íŒŒì¼: {total_files}ê°œ")
        
        for ext, files in sorted(all_files.items()):
            if files:
                desc = self.model_extensions[ext]
                print(f"  {ext}: {len(files)}ê°œ ({desc})")
                self.results["stats_by_extension"][ext] = len(files)
        
        return all_files
    
    def classify_model_file(self, file_path: Path) -> str:
        """ëª¨ë¸ íŒŒì¼ì„ Stepë³„ë¡œ ë¶„ë¥˜"""
        filename = file_path.name.lower()
        parent_dir = str(file_path.parent).lower()
        
        # HuggingFace ëª¨ë¸ íŠ¹ë³„ ì²˜ë¦¬
        if "huggingface" in parent_dir or "models--" in parent_dir:
            if "ootdiffusion" in parent_dir or "idm-vton" in parent_dir:
                return "step_06_virtual_fitting"
            elif "sam2" in parent_dir:
                return "step_03_cloth_segmentation"
            elif "clip" in parent_dir:
                return "step_08_quality_assessment"
        
        # Stepë³„ íŒ¨í„´ ë§¤ì¹­
        best_score = 0
        best_step = "misc"
        
        for step_name, patterns in self.step_patterns.items():
            score = 0
            for pattern in patterns:
                if re.search(pattern, filename):
                    score += 3
                elif re.search(pattern, parent_dir):
                    score += 1
            
            if score > best_score:
                best_score = score
                best_step = step_name
        
        return best_step if best_score > 0 else "misc"
    
    def get_file_size_mb(self, file_path: Path) -> float:
        """íŒŒì¼ í¬ê¸° (MB)"""
        try:
            return file_path.stat().st_size / (1024 * 1024)
        except:
            return 0.0
    
    def copy_file_safely(self, source: Path, target_dir: Path) -> bool:
        """ì•ˆì „í•œ íŒŒì¼ ë³µì‚¬"""
        try:
            target_dir.mkdir(parents=True, exist_ok=True)
            
            # íŒŒì¼ëª… ì¤‘ë³µ ì²˜ë¦¬
            target_path = target_dir / source.name
            counter = 1
            
            while target_path.exists():
                stem = source.stem
                suffix = source.suffix
                target_path = target_dir / f"{stem}_{counter:02d}{suffix}"
                counter += 1
            
            if counter > 1:
                print(f"    ğŸ”¢ ì´ë¦„ ë³€ê²½: {source.name} â†’ {target_path.name}")
            
            # íŒŒì¼ ì´ë™ (ì›ë³¸ ì‚­ì œ)
            shutil.move(source, target_path)
            
            # ê²€ì¦
            if target_path.exists() and target_path.stat().st_size > 0:
                size_mb = self.get_file_size_mb(target_path)
                self.results["moved_files"].append({
                    "source": str(source),
                    "target": str(target_path),
                    "size_mb": round(size_mb, 2),
                    "extension": source.suffix
                })
                return True
            else:
                raise Exception("ë³µì‚¬ ê²€ì¦ ì‹¤íŒ¨")
                
        except Exception as e:
            self.results["errors"].append({
                "file": str(source),
                "error": str(e)
            })
            return False
    
    def consolidate_all_models(self) -> bool:
        """ì™„ì „ ëª¨ë¸ í†µí•© ë©”ì¸ í”„ë¡œì„¸ìŠ¤"""
        print("ğŸ”¥ ì™„ì „ ëª¨ë¸ í†µí•© ì‹œì‘! (ëª¨ë“  í˜•ì‹)")
        print("=" * 60)
        
        # 1. ëª¨ë“  ëª¨ë¸ íŒŒì¼ ìŠ¤ìº”
        all_model_files = self.find_all_model_files()
        
        if not all_model_files:
            print("âŒ ì´ë™í•  ëª¨ë¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            return False
        
        # 2. ì´ íŒŒì¼ ìˆ˜ ë° í¬ê¸° ê³„ì‚°
        total_files = sum(len(files) for files in all_model_files.values())
        total_size_gb = 0
        
        for files in all_model_files.values():
            for file_path in files:
                total_size_gb += self.get_file_size_mb(file_path) / 1024
        
        print(f"\nğŸ“Š í†µí•© ëŒ€ìƒ: {total_files}ê°œ íŒŒì¼, ì•½ {total_size_gb:.1f}GB")
        
        # 3. ì‚¬ìš©ì í™•ì¸
        response = input("\nğŸšš ëª¨ë“  ëª¨ë¸ íŒŒì¼ì„ í†µí•©í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/N): ").strip().lower()
        if response not in ['y', 'yes']:
            print("âŒ ì‘ì—…ì´ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.")
            return False
        
        # 4. íŒŒì¼ë³„ ë¶„ë¥˜ ë° ì´ë™
        print(f"\nğŸ”„ ëª¨ë¸ íŒŒì¼ ì´ë™ ì¤‘... ({total_files}ê°œ)")
        
        processed = 0
        for ext, files in all_model_files.items():
            if not files:
                continue
                
            print(f"\nğŸ“¦ {ext} íŒŒì¼ ì²˜ë¦¬ ì¤‘... ({len(files)}ê°œ)")
            
            for file_path in files:
                try:
                    # Step ë¶„ë¥˜
                    step_name = self.classify_model_file(file_path)
                    
                    if step_name == "misc":
                        target_dir = self.target_path / "checkpoints" / "misc"
                        print(f"    â“ ë¶„ë¥˜ ë¶ˆê°€: {file_path.name}")
                    else:
                        target_dir = self.target_path / "checkpoints" / step_name
                        size_mb = self.get_file_size_mb(file_path)
                        print(f"    âœ… {step_name}: {file_path.name} ({size_mb:.1f}MB)")
                    
                    # íŒŒì¼ ë³µì‚¬
                    if self.copy_file_safely(file_path, target_dir):
                        # í†µê³„ ì—…ë°ì´íŠ¸
                        if step_name not in self.results["stats_by_step"]:
                            self.results["stats_by_step"][step_name] = 0
                        self.results["stats_by_step"][step_name] += 1
                    
                    processed += 1
                    
                    # ì§„í–‰ë¥  í‘œì‹œ
                    if processed % 10 == 0:
                        progress = (processed / total_files) * 100
                        print(f"    ğŸ“Š ì§„í–‰ë¥ : {progress:.1f}% ({processed}/{total_files})")
                        
                except Exception as e:
                    print(f"    âŒ ì²˜ë¦¬ ì‹¤íŒ¨ {file_path}: {e}")
        
        # 5. ê²°ê³¼ ìš”ì•½
        self.print_final_summary()
        self.save_consolidation_report()
        
        return len(self.results["errors"]) == 0
    
    def print_final_summary(self):
        """ìµœì¢… ê²°ê³¼ ìš”ì•½"""
        print("\n" + "=" * 60)
        print("ğŸ‰ ì™„ì „ ëª¨ë¸ í†µí•© ì™„ë£Œ!")
        print("=" * 60)
        
        total_moved = len(self.results["moved_files"])
        total_errors = len(self.results["errors"])
        total_size_moved = sum(item["size_mb"] for item in self.results["moved_files"]) / 1024
        
        print(f"âœ… ì„±ê³µ ì´ë™: {total_moved}ê°œ íŒŒì¼")
        print(f"ğŸ“¦ ì´ ì´ë™ í¬ê¸°: {total_size_moved:.1f}GB")
        print(f"âŒ ì˜¤ë¥˜: {total_errors}ê°œ")
        
        if self.results["stats_by_extension"]:
            print(f"\nğŸ“„ í™•ì¥ìë³„ í†µê³„:")
            for ext, count in sorted(self.results["stats_by_extension"].items()):
                moved_count = len([f for f in self.results["moved_files"] if f["extension"] == ext])
                print(f"  {ext}: {moved_count}ê°œ ì´ë™")
        
        if self.results["stats_by_step"]:
            print(f"\nğŸ“ Stepë³„ í†µê³„:")
            for step, count in sorted(self.results["stats_by_step"].items()):
                print(f"  {step}: {count}ê°œ")
        
        print(f"\nğŸ“ ìµœì¢… ìœ„ì¹˜:")
        print(f"  {self.target_path}/checkpoints/")
        for step in sorted(self.results["stats_by_step"].keys()):
            print(f"    â”œâ”€â”€ {step}/")
    
    def save_consolidation_report(self):
        """ìƒì„¸ ë¦¬í¬íŠ¸ ì €ì¥"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        report_path = self.target_path / f"complete_consolidation_report_{timestamp}.json"
        
        try:
            with open(report_path, 'w', encoding='utf-8') as f:
                json.dump(self.results, f, indent=2, ensure_ascii=False)
            print(f"\nğŸ“Š ìƒì„¸ ë¦¬í¬íŠ¸: {report_path}")
        except Exception as e:
            print(f"âš ï¸ ë¦¬í¬íŠ¸ ì €ì¥ ì‹¤íŒ¨: {e}")

def main():
    """ë©”ì¸ ì‹¤í–‰"""
    print("ğŸ”¥ ì™„ì „ ëª¨ë¸ í†µí•©ê¸° v2.0 - ALL FORMATS")
    print("=" * 60)
    
    consolidator = CompleteModelConsolidator()
    
    # ê²½ë¡œ í™•ì¸
    for path in consolidator.search_paths:
        if path.exists():
            print(f"âœ… ì†ŒìŠ¤ ê²½ë¡œ: {path}")
        else:
            print(f"âŒ ì†ŒìŠ¤ ê²½ë¡œ ì—†ìŒ: {path}")
    
    print(f"ğŸ“ í†µí•© ëŒ€ìƒ: {consolidator.target_path}")
    
    # ì§€ì› í˜•ì‹ í‘œì‹œ
    print(f"\nğŸ“¦ ì§€ì›í•˜ëŠ” ëª¨ë¸ í˜•ì‹: {len(consolidator.model_extensions)}ê°œ")
    for ext, desc in list(consolidator.model_extensions.items())[:5]:
        print(f"  {ext}: {desc}")
    print(f"  ... ì´ {len(consolidator.model_extensions)}ê°œ í˜•ì‹ ì§€ì›")
    
    # ì‹¤í–‰
    success = consolidator.consolidate_all_models()
    
    if success:
        print("\nğŸ‰ ëª¨ë“  ëª¨ë¸ì´ ì„±ê³µì ìœ¼ë¡œ í†µí•©ë˜ì—ˆìŠµë‹ˆë‹¤!")
        print("ğŸ’¡ ì´ì œ ëª¨ë“  í˜•ì‹ì˜ AI ëª¨ë¸ì„ í•œ ê³³ì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!")
    else:
        print("\nâš ï¸ ì¼ë¶€ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë¦¬í¬íŠ¸ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
    
    return success

if __name__ == "__main__":
    main()