#!/usr/bin/env python3
"""
ğŸ” MyCloset AI ì²´í¬í¬ì¸íŠ¸ ìë™ íƒì§€ ì‹¤í–‰
conda í™˜ê²½ì—ì„œ ì‹¤í–‰í•˜ì—¬ í˜„ì¬ ëª¨ë¸ ìœ„ì¹˜ë¥¼ íŒŒì•…
"""

import os
import sys
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python pathì— ì¶”ê°€
project_root = Path(__file__).parent.parent.parent.parent
sys.path.insert(0, str(project_root))
sys.path.insert(0, str(project_root / "backend"))

print("ğŸ” MyCloset AI ìë™ ëª¨ë¸ íƒì§€ ì‹œì‘...")
print(f"ğŸ“ í”„ë¡œì íŠ¸ ë£¨íŠ¸: {project_root}")
print(f"ğŸ Python ê²½ë¡œ: {sys.executable}")
print(f"ğŸ Conda í™˜ê²½: {os.environ.get('CONDA_DEFAULT_ENV', 'ì—†ìŒ')}")
print("=" * 60)

try:
    # auto_model_detector import ì‹œë„
    print("ğŸ“¦ auto_model_detector ëª¨ë“ˆ ë¡œë“œ ì¤‘...")
    
    try:
        from backend.app.ai_pipeline.utils.auto_model_detector import (
            RealWorldModelDetector,
            create_real_world_detector
        )
        print("âœ… auto_model_detector ë¡œë“œ ì„±ê³µ!")
    except ImportError as e:
        print(f"âŒ auto_model_detector ë¡œë“œ ì‹¤íŒ¨: {e}")
        print("ğŸ’¡ ê²½ë¡œ ë¬¸ì œì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ê²½ë¡œë¡œ ì‹œë„...")
        
        # ì§ì ‘ ê²½ë¡œ ì§€ì •í•´ì„œ ì‹œë„
        backend_path = project_root / "backend"
        if backend_path.exists():
            sys.path.insert(0, str(backend_path))
            from app.ai_pipeline.utils.auto_model_detector import (
                RealWorldModelDetector,
                create_real_world_detector
            )
            print("âœ… ì§ì ‘ ê²½ë¡œë¡œ ë¡œë“œ ì„±ê³µ!")
        else:
            raise ImportError("backend ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
    
    # ì‹¤ì œ íƒì§€ ì‹¤í–‰
    print("\nğŸ” ì‹¤ì œ AI ëª¨ë¸ íƒì§€ ì‹œì‘...")
    
    detector = create_real_world_detector(
        enable_pytorch_validation=True,
        enable_deep_scan=True,
        max_workers=2  # ì•ˆì „í•œ ë³‘ë ¬ ì²˜ë¦¬
    )
    
    print("ğŸ”„ ëª¨ë¸ ìŠ¤ìº” ì‹¤í–‰ ì¤‘... (ìµœëŒ€ 5ë¶„ ì†Œìš”)")
    detected_models = detector.detect_all_models(
        force_rescan=False,  # ìºì‹œ ì‚¬ìš©
        min_confidence=0.3,
        enable_detailed_analysis=False  # ë¹ ë¥¸ íƒì§€
    )
    
    print(f"\nâœ… íƒì§€ ì™„ë£Œ! {len(detected_models)}ê°œ ëª¨ë¸ ë°œê²¬")
    print("=" * 60)
    
    # íƒì§€ ê²°ê³¼ ìš”ì•½
    if detected_models:
        print("ğŸ“Š íƒì§€ëœ ëª¨ë¸ ìš”ì•½:")
        
        total_size_gb = 0
        pytorch_valid_count = 0
        
        for i, (name, model) in enumerate(detected_models.items(), 1):
            size_gb = model.file_size_mb / 1024
            total_size_gb += size_gb
            
            if model.pytorch_valid:
                pytorch_valid_count += 1
            
            status_icon = "âœ…" if model.pytorch_valid else "â“"
            
            print(f"  {i:2d}. {status_icon} {name}")
            print(f"      ğŸ“ {model.path}")
            print(f"      ğŸ“Š {size_gb:.2f}GB | Step: {model.step_name} | ì‹ ë¢°ë„: {model.confidence_score:.2f}")
            
            if i >= 10:  # ìƒìœ„ 10ê°œë§Œ ì¶œë ¥
                remaining = len(detected_models) - 10
                if remaining > 0:
                    print(f"      ... ê·¸ ì™¸ {remaining}ê°œ ëª¨ë¸")
                break
        
        print(f"\nğŸ“ˆ í†µê³„:")
        print(f"   â€¢ ì´ í¬ê¸°: {total_size_gb:.2f}GB")
        print(f"   â€¢ PyTorch ê²€ì¦: {pytorch_valid_count}/{len(detected_models)}ê°œ")
        print(f"   â€¢ í‰ê·  ì‹ ë¢°ë„: {sum(m.confidence_score for m in detected_models.values()) / len(detected_models):.3f}")
        
        # Stepë³„ ë¶„í¬
        step_counts = {}
        for model in detected_models.values():
            step = model.step_name
            if step not in step_counts:
                step_counts[step] = 0
            step_counts[step] += 1
        
        print(f"\nğŸ¯ Stepë³„ ë¶„í¬:")
        for step, count in sorted(step_counts.items()):
            print(f"   â€¢ {step}: {count}ê°œ")
    
    else:
        print("âš ï¸ íƒì§€ëœ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")
        print("ğŸ’¡ ë‹¤ìŒì„ í™•ì¸í•´ì£¼ì„¸ìš”:")
        print("   1. ai_models ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ëŠ”ì§€")
        print("   2. ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ë“¤ì´ ì˜¬ë°”ë¥¸ ìœ„ì¹˜ì— ìˆëŠ”ì§€")
        print("   3. íŒŒì¼ ê¶Œí•œì´ ì˜¬ë°”ë¥¸ì§€")
    
    print("\n" + "=" * 60)
    print("ğŸ¯ ë‹¤ìŒ ë‹¨ê³„:")
    print("   1. íƒì§€ëœ ëª¨ë¸ë“¤ì´ ì˜¬ë°”ë¥¸ì§€ í™•ì¸")
    print("   2. ModelLoader ì„¤ì • ì—…ë°ì´íŠ¸")
    print("   3. Stepë³„ ëª¨ë¸ ë§¤í•‘ í™•ì¸")
    print("   4. ì• í”Œë¦¬ì¼€ì´ì…˜ í…ŒìŠ¤íŠ¸")

except Exception as e:
    print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
    import traceback
    print(f"ğŸ“‹ ìƒì„¸ ì˜¤ë¥˜:")
    traceback.print_exc()
    
    print(f"\nğŸ’¡ í•´ê²° ë°©ë²•:")
    print(f"   1. conda í™˜ê²½ì´ í™œì„±í™”ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸")
    print(f"   2. í•„ìš”í•œ íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸: pip install torch")
    print(f"   3. í”„ë¡œì íŠ¸ ë””ë ‰í† ë¦¬ì—ì„œ ì‹¤í–‰í•˜ê³  ìˆëŠ”ì§€ í™•ì¸")

print("\nğŸ” íƒì§€ ì™„ë£Œ!")