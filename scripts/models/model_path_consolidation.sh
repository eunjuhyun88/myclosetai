#!/bin/bash

# =============================================================================
# MyCloset AI - Stepë³„ ëª¨ë¸ ê²½ë¡œ ì™„ì „ í†µí•© ìŠ¤í¬ë¦½íŠ¸ (macOS í˜¸í™˜)
# ê¸°ì¡´ ì¤‘ë³µ ëª¨ë¸ë“¤ì„ ë²ˆí˜¸ë¥¼ ë‹¬ì•„ ë³´ì¡´í•˜ë©´ì„œ Stepë³„ë¡œ ì²´ê³„ì  ì •ë¦¬
# =============================================================================

set -e

# ìƒ‰ìƒ ì¶œë ¥ í•¨ìˆ˜ë“¤
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
PURPLE='\033[0;35m'
CYAN='\033[0;36m'
NC='\033[0m'

log_info() { echo -e "${BLUE}â„¹ï¸  $1${NC}"; }
log_success() { echo -e "${GREEN}âœ… $1${NC}"; }
log_warning() { echo -e "${YELLOW}âš ï¸  $1${NC}"; }
log_error() { echo -e "${RED}âŒ $1${NC}"; }
log_header() { echo -e "${PURPLE}\nğŸš€ $1${NC}"; echo "=" | tr -d '\n' | head -c 80; echo; }
log_step() { echo -e "${CYAN}ğŸ“‹ $1${NC}"; }

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ í™•ì¸
PROJECT_ROOT=$(pwd)
AI_MODELS_ROOT="$PROJECT_ROOT/ai_models"
BACKEND_AI_MODELS="$PROJECT_ROOT/backend/ai_models"

log_header "MyCloset AI - Stepë³„ ëª¨ë¸ ê²½ë¡œ ì™„ì „ í†µí•© (macOS í˜¸í™˜)"
log_info "í”„ë¡œì íŠ¸ ë£¨íŠ¸: $PROJECT_ROOT"
log_info "íƒ€ê²Ÿ ë””ë ‰í† ë¦¬: $AI_MODELS_ROOT"
echo ""

# 1. í˜„ì¬ ìƒí™© ë¶„ì„
log_header "Step 1: í˜„ì¬ AI ëª¨ë¸ ìƒí™© ë¶„ì„"

log_step "í˜„ì¬ AI ëª¨ë¸ ë””ë ‰í† ë¦¬ êµ¬ì¡° ë¶„ì„ ì¤‘..."

# ê¸°ì¡´ ai_models ë””ë ‰í† ë¦¬ë“¤ ì°¾ê¸°
AI_MODEL_DIRS=(
    "$AI_MODELS_ROOT"
    "$BACKEND_AI_MODELS"
    "$PROJECT_ROOT/backend/app/ai_models"
    "$PROJECT_ROOT/backend/app/ai_pipeline/models"
)

echo "ğŸ“ ë°œê²¬ëœ AI ëª¨ë¸ ë””ë ‰í† ë¦¬ë“¤:"
for dir in "${AI_MODEL_DIRS[@]}"; do
    if [ -d "$dir" ]; then
        size=$(du -sh "$dir" 2>/dev/null | cut -f1 || echo "N/A")
        count=$(find "$dir" -type f \( -name "*.pth" -o -name "*.pt" -o -name "*.bin" -o -name "*.safetensors" \) 2>/dev/null | wc -l || echo 0)
        echo "  âœ… $dir (í¬ê¸°: $size, ëª¨ë¸íŒŒì¼: $countê°œ)"
    else
        echo "  âŒ $dir (ì—†ìŒ)"
    fi
done

# 2. íƒ€ê²Ÿ ë””ë ‰í† ë¦¬ êµ¬ì¡° ìƒì„±
log_header "Step 2: Stepë³„ íƒ€ê²Ÿ ë””ë ‰í† ë¦¬ êµ¬ì¡° ìƒì„±"

# í‘œì¤€ Stepë³„ ë””ë ‰í† ë¦¬ ìƒì„±
STEP_DIRS=(
    "step_01_human_parsing"
    "step_02_pose_estimation" 
    "step_03_cloth_segmentation"
    "step_04_geometric_matching"
    "step_05_cloth_warping"
    "step_06_virtual_fitting"
    "step_07_post_processing"
    "step_08_quality_assessment"
    "auxiliary_models"
    "huggingface_cache"
    "backup_models"
    "experimental_models"
)

log_step "Stepë³„ í‘œì¤€ ë””ë ‰í† ë¦¬ ìƒì„± ì¤‘..."

# ai_models ë£¨íŠ¸ ë””ë ‰í† ë¦¬ ìƒì„±
mkdir -p "$AI_MODELS_ROOT"

for step_dir in "${STEP_DIRS[@]}"; do
    target_dir="$AI_MODELS_ROOT/$step_dir"
    mkdir -p "$target_dir"
    
    # ì„¸ë¶€ ì¹´í…Œê³ ë¦¬ ë””ë ‰í† ë¦¬ë„ ìƒì„±
    case $step_dir in
        "step_01_human_parsing")
            mkdir -p "$target_dir/graphonomy" "$target_dir/schp" "$target_dir/densepose" "$target_dir/alternatives"
            ;;
        "step_02_pose_estimation")
            mkdir -p "$target_dir/openpose" "$target_dir/mediapipe" "$target_dir/hrnet" "$target_dir/alternatives"
            ;;
        "step_03_cloth_segmentation") 
            mkdir -p "$target_dir/u2net" "$target_dir/sam" "$target_dir/rembg" "$target_dir/alternatives"
            ;;
        "step_04_geometric_matching")
            mkdir -p "$target_dir/gmm" "$target_dir/tps" "$target_dir/alternatives"
            ;;
        "step_05_cloth_warping")
            mkdir -p "$target_dir/tom" "$target_dir/alternatives"
            ;;
        "step_06_virtual_fitting")
            mkdir -p "$target_dir/ootdiffusion" "$target_dir/stable_diffusion" "$target_dir/hrviton" "$target_dir/alternatives"
            ;;
        "step_07_post_processing")
            mkdir -p "$target_dir/super_resolution" "$target_dir/enhancement" "$target_dir/alternatives"
            ;;
        "step_08_quality_assessment")
            mkdir -p "$target_dir/clip" "$target_dir/alternatives"
            ;;
        "auxiliary_models")
            mkdir -p "$target_dir/clip" "$target_dir/sam" "$target_dir/vae" "$target_dir/text_encoders"
            ;;
        "huggingface_cache")
            mkdir -p "$target_dir/transformers" "$target_dir/diffusers" "$target_dir/models"
            ;;
    esac
    
    # .gitkeep íŒŒì¼ ìƒì„±
    touch "$target_dir/.gitkeep"
    
    log_info "ìƒì„±: $step_dir"
done

log_success "Stepë³„ ë””ë ‰í† ë¦¬ êµ¬ì¡° ìƒì„± ì™„ë£Œ"

# 3. ê¸°ì¡´ ëª¨ë¸ íŒŒì¼ íƒì§€ ë° ë¶„ë¥˜
log_header "Step 3: ê¸°ì¡´ ëª¨ë¸ íŒŒì¼ íƒì§€ ë° Stepë³„ ë¶„ë¥˜"

log_step "ëª¨ë“  AI ëª¨ë¸ íŒŒì¼ íƒì§€ ì¤‘..."

# ëª¨ë¸ íŒŒì¼ íƒì§€ í•¨ìˆ˜
detect_model_files() {
    local search_dir="$1"
    
    if [ ! -d "$search_dir" ]; then
        return 0
    fi
    
    find "$search_dir" -type f \( \
        -name "*.pth" -o \
        -name "*.pt" -o \
        -name "*.bin" -o \
        -name "*.safetensors" -o \
        -name "*.ckpt" -o \
        -name "*.onnx" -o \
        -name "*.pkl" \
    \) 2>/dev/null
}

# Stepë³„ íŒ¨í„´ ë§¤ì¹­ í•¨ìˆ˜ (macOS í˜¸í™˜ ë²„ì „)
classify_model_by_step() {
    local file_path="$1"
    local file_name=$(basename "$file_path")
    local file_lower=$(echo "$file_name" | tr '[:upper:]' '[:lower:]')
    local path_lower=$(echo "$file_path" | tr '[:upper:]' '[:lower:]')
    
    # Step 01: Human Parsing
    if echo "$file_lower" | grep -E "(human|parsing|schp|atr|graphonomy|densepose)" >/dev/null || \
       echo "$path_lower" | grep -E "(human.*parsing|step.*01|parsing)" >/dev/null; then
        echo "step_01_human_parsing"
        
    # Step 02: Pose Estimation  
    elif echo "$file_lower" | grep -E "(pose|openpose|body|keypoint|mediapipe|hrnet)" >/dev/null || \
         echo "$path_lower" | grep -E "(pose.*estimation|step.*02|openpose)" >/dev/null; then
        echo "step_02_pose_estimation"
        
    # Step 03: Cloth Segmentation
    elif echo "$file_lower" | grep -E "(u2net|segmentation|cloth.*seg|mask|rembg|sam)" >/dev/null || \
         echo "$path_lower" | grep -E "(cloth.*segmentation|step.*03|u2net)" >/dev/null; then
        echo "step_03_cloth_segmentation"
        
    # Step 04: Geometric Matching
    elif echo "$file_lower" | grep -E "(geometric|matching|gmm|tps)" >/dev/null || \
         echo "$path_lower" | grep -E "(geometric.*matching|step.*04)" >/dev/null; then
        echo "step_04_geometric_matching"
        
    # Step 05: Cloth Warping
    elif echo "$file_lower" | grep -E "(warping|warp|tom|cloth.*warp)" >/dev/null || \
         echo "$path_lower" | grep -E "(cloth.*warping|step.*05)" >/dev/null; then
        echo "step_05_cloth_warping"
        
    # Step 06: Virtual Fitting
    elif echo "$file_lower" | grep -E "(diffusion|ootd|viton|stable|unet|vae)" >/dev/null || \
         echo "$path_lower" | grep -E "(virtual.*fitting|step.*06|ootdiffusion|stable.*diffusion)" >/dev/null; then
        echo "step_06_virtual_fitting"
        
    # Step 07: Post Processing
    elif echo "$file_lower" | grep -E "(super|resolution|esrgan|sr|denoise|enhance|gfpgan|codeformer|swinir)" >/dev/null || \
         echo "$path_lower" | grep -E "(post.*processing|step.*07|super.*resolution)" >/dev/null; then
        echo "step_07_post_processing"
        
    # Step 08: Quality Assessment
    elif echo "$file_lower" | grep -E "(quality|assessment|clip|similarity)" >/dev/null || \
         echo "$path_lower" | grep -E "(quality.*assessment|step.*08)" >/dev/null; then
        echo "step_08_quality_assessment"
        
    # Auxiliary Models
    elif echo "$file_lower" | grep -E "(clip|text.*encoder|feature.*extract)" >/dev/null || \
         echo "$path_lower" | grep -E "(auxiliary|clip)" >/dev/null; then
        echo "auxiliary_models"
        
    # HuggingFace Cache
    elif echo "$path_lower" | grep -E "(huggingface|transformers|diffusers|models--)" >/dev/null; then
        echo "huggingface_cache"
        
    else
        echo "experimental_models"
    fi
}

# íƒì§€ ê²°ê³¼ë¥¼ ì„ì‹œ íŒŒì¼ë“¤ë¡œ ì €ì¥ (ì—°ê´€ ë°°ì—´ ëŒ€ì‹ )
TEMP_DIR=$(mktemp -d)
DETECTED_FILES_LIST="$TEMP_DIR/detected_files.txt"
STEP_COUNTS_FILE="$TEMP_DIR/step_counts.txt"

log_step "ì†ŒìŠ¤ë³„ ëª¨ë¸ íŒŒì¼ íƒì§€ ì§„í–‰ ì¤‘..."

# Step ì¹´ìš´í„° ì´ˆê¸°í™”
for step in "${STEP_DIRS[@]}"; do
    echo "$step:0" >> "$STEP_COUNTS_FILE"
done

for source_dir in "${AI_MODEL_DIRS[@]}"; do
    if [ -d "$source_dir" ]; then
        log_info "íƒì§€ ì¤‘: $source_dir"
        
        detect_model_files "$source_dir" | while IFS= read -r file_path; do
            if [ -f "$file_path" ]; then
                step=$(classify_model_by_step "$file_path")
                echo "$file_path|$step" >> "$DETECTED_FILES_LIST"
                
                # Step ì¹´ìš´íŠ¸ ì¦ê°€
                current_count=$(grep "^$step:" "$STEP_COUNTS_FILE" | cut -d: -f2)
                new_count=$((current_count + 1))
                sed -i '' "s/^$step:.*/$step:$new_count/" "$STEP_COUNTS_FILE" 2>/dev/null || \
                sed -i "s/^$step:.*/$step:$new_count/" "$STEP_COUNTS_FILE" 2>/dev/null
            fi
        done
    fi
done

# íƒì§€ ê²°ê³¼ ì¶œë ¥
echo ""
log_success "ëª¨ë¸ íŒŒì¼ íƒì§€ ì™„ë£Œ"
echo "ğŸ“Š Stepë³„ íƒì§€ëœ ëª¨ë¸ ìˆ˜:"

while IFS=: read -r step count; do
    if [ "$count" -gt 0 ]; then
        echo "  âœ… $step: $countê°œ"
    else
        echo "  âšª $step: 0ê°œ"
    fi
done < "$STEP_COUNTS_FILE"

# 4. ì¤‘ë³µ ì²´í¬ ë° ì´ë™ ê³„íš ìˆ˜ë¦½
log_header "Step 4: ì¤‘ë³µ ì²´í¬ ë° ì´ë™ ê³„íš ìˆ˜ë¦½"

log_step "ì¤‘ë³µ íŒŒì¼ ì²´í¬ ë° ë²ˆí˜¸ í• ë‹¹ ì¤‘..."

MOVE_PLAN_FILE="$TEMP_DIR/move_plan.txt"
FILE_REGISTRY_DIR="$TEMP_DIR/registry"
mkdir -p "$FILE_REGISTRY_DIR"

# íŒŒì¼ ì´ë¦„ ê¸°ë°˜ ì¤‘ë³µ ì²´í¬
while IFS='|' read -r file_path step; do
    if [ -f "$file_path" ]; then
        file_name=$(basename "$file_path")
        target_dir="$AI_MODELS_ROOT/$step"
        registry_file="$FILE_REGISTRY_DIR/${step}_${file_name}.count"
        
        if [ -f "$registry_file" ]; then
            # ì¤‘ë³µ íŒŒì¼ ë°œê²¬ - ë²ˆí˜¸ í• ë‹¹
            existing_count=$(cat "$registry_file")
            new_count=$((existing_count + 1))
            echo "$new_count" > "$registry_file"
            
            # í™•ì¥ì ë¶„ë¦¬
            file_base="${file_name%.*}"
            file_ext="${file_name##*.}"
            
            new_file_name="${file_base}_${new_count}.${file_ext}"
            target_path="$target_dir/$new_file_name"
            
            log_warning "ì¤‘ë³µ ë°œê²¬: $file_name â†’ $new_file_name"
        else
            # ì²˜ìŒ ë°œê²¬ëœ íŒŒì¼
            echo "1" > "$registry_file"
            target_path="$target_dir/$file_name"
        fi
        
        echo "$file_path|$target_path" >> "$MOVE_PLAN_FILE"
    fi
done < "$DETECTED_FILES_LIST"

# 5. ì‹¤ì œ íŒŒì¼ ì´ë™ ì‹¤í–‰
log_header "Step 5: ì‹¤ì œ íŒŒì¼ ì´ë™ ì‹¤í–‰"

total_moves=$(wc -l < "$MOVE_PLAN_FILE" 2>/dev/null || echo 0)
if [ "$total_moves" -eq 0 ]; then
    log_warning "ì´ë™í•  íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤."
    exit 0
fi

log_warning "ì´ $total_movesê°œ íŒŒì¼ì„ ì´ë™í•©ë‹ˆë‹¤. ì‹¤ì œ íŒŒì¼ ì´ë™ì„ ì‹¤í–‰í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/N)"
read -r confirm

if [[ ! $confirm =~ ^[Yy]$ ]]; then
    log_info "ì´ë™ ê³„íšë§Œ ì¶œë ¥í•˜ê³  ì¢…ë£Œí•©ë‹ˆë‹¤."
    
    echo ""
    echo "ğŸ“‹ ì´ë™ ê³„íš (ë¯¸ì‹¤í–‰):"
    while IFS='|' read -r source_path target_path; do
        file_size=$(du -h "$source_path" 2>/dev/null | cut -f1 || echo "N/A")
        echo "  ğŸ“ $source_path â†’ $target_path ($file_size)"
    done < "$MOVE_PLAN_FILE"
    
    # ì„ì‹œ íŒŒì¼ ì •ë¦¬
    rm -rf "$TEMP_DIR"
    exit 0
fi

log_step "íŒŒì¼ ì´ë™ ì‹¤í–‰ ì¤‘..."

moved_count=0
error_count=0

while IFS='|' read -r source_path target_path; do
    target_dir=$(dirname "$target_path")
    
    # íƒ€ê²Ÿ ë””ë ‰í† ë¦¬ ìƒì„± í™•ì¸
    mkdir -p "$target_dir"
    
    # íŒŒì¼ ì´ë™ (ë³µì‚¬ í›„ ì›ë³¸ ìœ ì§€)
    if cp "$source_path" "$target_path" 2>/dev/null; then
        file_size=$(du -h "$target_path" 2>/dev/null | cut -f1 || echo "N/A")
        log_info "âœ… $(basename "$source_path") â†’ $target_path ($file_size)"
        moved_count=$((moved_count + 1))
    else
        log_error "âŒ ì´ë™ ì‹¤íŒ¨: $source_path â†’ $target_path"
        error_count=$((error_count + 1))
    fi
done < "$MOVE_PLAN_FILE"

# 6. ê²°ê³¼ ìš”ì•½ ë° ê²€ì¦
log_header "Step 6: ê²°ê³¼ ìš”ì•½ ë° ê²€ì¦"

log_success "íŒŒì¼ ì´ë™ ì™„ë£Œ!"
echo "ğŸ“Š ì´ë™ ê²°ê³¼:"
echo "  âœ… ì„±ê³µ: $moved_countê°œ"
echo "  âŒ ì‹¤íŒ¨: $error_countê°œ"

# ê° Stepë³„ ìµœì¢… ìƒíƒœ í™•ì¸
echo ""
echo "ğŸ“ Stepë³„ ìµœì¢… ëª¨ë¸ í˜„í™©:"

for step_dir in "${STEP_DIRS[@]}"; do
    target_dir="$AI_MODELS_ROOT/$step_dir"
    if [ -d "$target_dir" ]; then
        count=$(find "$target_dir" -type f \( -name "*.pth" -o -name "*.pt" -o -name "*.bin" -o -name "*.safetensors" \) 2>/dev/null | wc -l)
        size=$(du -sh "$target_dir" 2>/dev/null | cut -f1 || echo "0B")
        
        if [ "$count" -gt 0 ]; then
            echo "  âœ… $step_dir: $countê°œ íŒŒì¼, $size"
        else
            echo "  âšª $step_dir: ë¹„ì–´ìˆìŒ"
        fi
    fi
done

# 7. ì„¤ì • íŒŒì¼ ìƒì„±
log_header "Step 7: ìµœì‹  ê²½ë¡œ ì„¤ì • íŒŒì¼ ìƒì„±"

log_step "í†µí•©ëœ ê²½ë¡œ ì„¤ì • íŒŒì¼ ìƒì„± ì¤‘..."

# backend/app/core ë””ë ‰í† ë¦¬ ìƒì„± í™•ì¸
mkdir -p "$PROJECT_ROOT/backend/app/core"

# Python ì„¤ì • íŒŒì¼ ìƒì„±
cat > "$PROJECT_ROOT/backend/app/core/unified_model_paths.py" << EOF
# app/core/unified_model_paths.py
"""
MyCloset AI - í†µí•©ëœ Stepë³„ ëª¨ë¸ ê²½ë¡œ ì„¤ì •
ìë™ ìƒì„±ë¨: $(date +'%Y-%m-%d %H:%M:%S')
"""

from pathlib import Path
from typing import Dict, List, Optional

# í”„ë¡œì íŠ¸ ë£¨íŠ¸
PROJECT_ROOT = Path(__file__).parent.parent.parent.parent
AI_MODELS_ROOT = PROJECT_ROOT / "ai_models"

# Stepë³„ í‘œì¤€ ê²½ë¡œ
STEP_MODEL_PATHS = {
    "step_01_human_parsing": AI_MODELS_ROOT / "step_01_human_parsing",
    "step_02_pose_estimation": AI_MODELS_ROOT / "step_02_pose_estimation", 
    "step_03_cloth_segmentation": AI_MODELS_ROOT / "step_03_cloth_segmentation",
    "step_04_geometric_matching": AI_MODELS_ROOT / "step_04_geometric_matching",
    "step_05_cloth_warping": AI_MODELS_ROOT / "step_05_cloth_warping",
    "step_06_virtual_fitting": AI_MODELS_ROOT / "step_06_virtual_fitting",
    "step_07_post_processing": AI_MODELS_ROOT / "step_07_post_processing",
    "step_08_quality_assessment": AI_MODELS_ROOT / "step_08_quality_assessment",
    "auxiliary_models": AI_MODELS_ROOT / "auxiliary_models",
    "huggingface_cache": AI_MODELS_ROOT / "huggingface_cache",
    "backup_models": AI_MODELS_ROOT / "backup_models",
    "experimental_models": AI_MODELS_ROOT / "experimental_models"
}

def get_step_path(step_name: str) -> Optional[Path]:
    """Step ì´ë¦„ìœ¼ë¡œ ê²½ë¡œ ë°˜í™˜"""
    return STEP_MODEL_PATHS.get(step_name)

def get_available_models(step_name: str) -> List[Path]:
    """íŠ¹ì • Stepì˜ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ íŒŒì¼ë“¤ ë°˜í™˜"""
    step_path = get_step_path(step_name)
    if not step_path or not step_path.exists():
        return []
    
    model_files = []
    for pattern in ["*.pth", "*.pt", "*.bin", "*.safetensors"]:
        model_files.extend(step_path.glob(f"**/{pattern}"))
    
    return sorted(model_files)

def get_all_model_files() -> Dict[str, List[Path]]:
    """ëª¨ë“  Stepì˜ ëª¨ë¸ íŒŒì¼ë“¤ ë°˜í™˜"""
    all_models = {}
    for step_name in STEP_MODEL_PATHS.keys():
        all_models[step_name] = get_available_models(step_name)
    
    return all_models

# í†µí•© ì •ë³´
INTEGRATION_INFO = {
    "integration_date": "$(date +'%Y-%m-%d %H:%M:%S')",
    "total_steps": len(STEP_MODEL_PATHS),
    "ai_models_root": str(AI_MODELS_ROOT),
    "integration_method": "step_based_classification"
}
EOF

log_success "í†µí•© ê²½ë¡œ ì„¤ì • íŒŒì¼ ìƒì„± ì™„ë£Œ: backend/app/core/unified_model_paths.py"

# 8. ê²€ì¦ ë° ìµœì¢… í™•ì¸
log_header "Step 8: ìµœì¢… ê²€ì¦"

log_step "í†µí•© ê²°ê³¼ ê²€ì¦ ì¤‘..."

# Pythonìœ¼ë¡œ ê²€ì¦ ì‹¤í–‰
python3 << 'EOF'
import sys
import os
sys.path.append(os.path.join(os.getcwd(), "backend", "app"))

try:
    from core.unified_model_paths import STEP_MODEL_PATHS, get_all_model_files
    
    print("ğŸ” í†µí•© ê²°ê³¼ ê²€ì¦:")
    all_models = get_all_model_files()
    
    total_files = 0
    for step_name, model_files in all_models.items():
        count = len(model_files)
        total_files += count
        if count > 0:
            print(f"  âœ… {step_name}: {count}ê°œ ëª¨ë¸")
        else:
            print(f"  âšª {step_name}: ë¹„ì–´ìˆìŒ")
    
    print(f"\nğŸ“Š ì´ ëª¨ë¸ íŒŒì¼: {total_files}ê°œ")
    print("âœ… í†µí•© ê²½ë¡œ ì„¤ì • ê²€ì¦ ì™„ë£Œ")
    
except Exception as e:
    print(f"âŒ ê²€ì¦ ì‹¤íŒ¨: {e}")
    import traceback
    traceback.print_exc()
EOF

# ì„ì‹œ íŒŒì¼ ì •ë¦¬
rm -rf "$TEMP_DIR"

echo ""
log_header "ğŸ‰ AI ëª¨ë¸ Stepë³„ ê²½ë¡œ í†µí•© ì™„ë£Œ!"

echo ""
log_success "âœ… ëª¨ë“  AI ëª¨ë¸ì´ Stepë³„ë¡œ ì²´ê³„ì ìœ¼ë¡œ ì •ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤"
log_success "âœ… ì¤‘ë³µ ëª¨ë¸ë“¤ì€ ë²ˆí˜¸ë¥¼ ë‹¬ì•„ ë³´ì¡´ë˜ì—ˆìŠµë‹ˆë‹¤"
log_success "âœ… í†µí•©ëœ ê²½ë¡œ ì„¤ì • íŒŒì¼ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤"

echo ""
echo "ğŸ“ í†µí•©ëœ êµ¬ì¡°:"
echo "  $AI_MODELS_ROOT/"
echo "  â”œâ”€â”€ step_01_human_parsing/     (Human Parsing ëª¨ë¸ë“¤)"
echo "  â”œâ”€â”€ step_02_pose_estimation/   (Pose Estimation ëª¨ë¸ë“¤)"
echo "  â”œâ”€â”€ step_03_cloth_segmentation/(Cloth Segmentation ëª¨ë¸ë“¤)"
echo "  â”œâ”€â”€ step_04_geometric_matching/ (Geometric Matching ëª¨ë¸ë“¤)"
echo "  â”œâ”€â”€ step_05_cloth_warping/     (Cloth Warping ëª¨ë¸ë“¤)"
echo "  â”œâ”€â”€ step_06_virtual_fitting/   (Virtual Fitting ëª¨ë¸ë“¤)"
echo "  â”œâ”€â”€ step_07_post_processing/   (Post Processing ëª¨ë¸ë“¤)"
echo "  â”œâ”€â”€ step_08_quality_assessment/(Quality Assessment ëª¨ë¸ë“¤)"
echo "  â”œâ”€â”€ auxiliary_models/          (ë³´ì¡° ëª¨ë¸ë“¤)"
echo "  â”œâ”€â”€ huggingface_cache/         (HuggingFace ìºì‹œ)"
echo "  â””â”€â”€ experimental_models/       (ë¶„ë¥˜ë˜ì§€ ì•Šì€ ëª¨ë¸ë“¤)"

echo ""
echo "ğŸš€ ë‹¤ìŒ ë‹¨ê³„:"
echo "1. backend/app/core/unified_model_paths.py ê²½ë¡œ ì„¤ì • í™•ì¸"
echo "2. ê° Stepì—ì„œ í†µí•©ëœ ê²½ë¡œ ì‚¬ìš©í•˜ë„ë¡ ì½”ë“œ ì—…ë°ì´íŠ¸"  
echo "3. ModelLoaderì—ì„œ ìƒˆ ê²½ë¡œ êµ¬ì¡° ì—°ë™"
echo "4. í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ë° ê²€ì¦"

echo ""
log_info "ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ì™„ë£Œ: $(date +'%Y-%m-%d %H:%M:%S')"