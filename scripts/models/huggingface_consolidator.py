#!/usr/bin/env python3
"""
ğŸ¤– HuggingFace ëª¨ë¸ ì™„ì „ í†µí•© ìŠ¤í¬ë¦½íŠ¸ v1.0
ì™¸ë¶€ ai_models/huggingface_cacheì˜ ëª¨ë“  ëª¨ë¸ì„ 
backend/app/ai_pipeline/modelsë¡œ ì•ˆì „í•˜ê²Œ ì´ë™
âœ… ì‹¤ì œ ëª¨ë¸ íŒŒì¼ë“¤ ì™„ì „ ë³µì‚¬
âœ… Stepë³„ ìë™ ë¶„ë¥˜  
âœ… ìš©ëŸ‰ ì²´í¬ ë° ì§„í–‰ë¥  í‘œì‹œ
âœ… ì•ˆì „í•œ ë³µì‚¬ (ì›ë³¸ ìœ ì§€)
"""

import os
import shutil
import json
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Tuple
import time

class HuggingFaceModelConsolidator:
    """HuggingFace ëª¨ë¸ ì™„ì „ í†µí•©ê¸°"""
    
    def __init__(self):
        self.project_root = Path("/Users/gimdudeul/MVP/mycloset-ai")
        self.source_path = self.project_root / "ai_models" / "huggingface_cache"
        self.target_path = self.project_root / "backend/app/ai_pipeline/models"
        
        # Stepë³„ HuggingFace ëª¨ë¸ ë§¤í•‘
        self.model_mappings = {
            "models--levihsu--OOTDiffusion": {
                "step": "step_06_virtual_fitting",
                "name": "ootdiffusion",
                "priority": "CRITICAL",
                "estimated_size_gb": 15.0,
                "description": "Out-Of-The-Box Diffusion for Virtual Try-On"
            },
            "models--yisol--IDM-VTON": {
                "step": "step_06_virtual_fitting", 
                "name": "idm_vton",
                "priority": "CRITICAL",
                "estimated_size_gb": 8.0,
                "description": "Improving Diffusion Models for Virtual Try-On"
            },
            "models--facebook--sam2-hiera-large": {
                "step": "step_03_cloth_segmentation",
                "name": "sam2_large",
                "priority": "HIGH",
                "estimated_size_gb": 2.0,
                "description": "Segment Anything Model 2 - Large"
            },
            "models--openai--clip-vit-large-patch14-336": {
                "step": "step_08_quality_assessment",
                "name": "clip_vit_large",
                "priority": "HIGH", 
                "estimated_size_gb": 1.5,
                "description": "CLIP Vision Transformer Large"
            },
            "models--patrickjohncyh--fashion-clip": {
                "step": "step_03_cloth_segmentation",
                "name": "fashion_clip",
                "priority": "MEDIUM",
                "estimated_size_gb": 1.0,
                "description": "Fashion-specific CLIP Model"
            },
            "models--stabilityai--stable-diffusion-xl-base-1.0": {
                "step": "step_06_virtual_fitting",
                "name": "stable_diffusion_xl",
                "priority": "HIGH",
                "estimated_size_gb": 5.0,
                "description": "Stable Diffusion XL Base Model"
            }
        }
        
        # ê²°ê³¼ ì¶”ì 
        self.results = {
            "moved_models": [],
            "errors": [],
            "total_size_moved": 0,
            "start_time": None,
            "end_time": None
        }
    
    def analyze_source_models(self) -> Dict[str, Dict]:
        """ì†ŒìŠ¤ ëª¨ë¸ ë¶„ì„"""
        print("ğŸ” HuggingFace ëª¨ë¸ ë¶„ì„ ì¤‘...")
        
        if not self.source_path.exists():
            print(f"âŒ ì†ŒìŠ¤ ê²½ë¡œê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {self.source_path}")
            return {}
        
        found_models = {}
        total_estimated_size = 0
        
        for model_dir in self.source_path.iterdir():
            if model_dir.is_dir() and model_dir.name.startswith("models--"):
                model_info = self.model_mappings.get(model_dir.name)
                
                if model_info:
                    # ì‹¤ì œ í¬ê¸° ê³„ì‚°
                    actual_size = self.get_directory_size(model_dir)
                    actual_size_gb = actual_size / (1024**3)
                    
                    found_models[model_dir.name] = {
                        **model_info,
                        "path": model_dir,
                        "actual_size_gb": actual_size_gb,
                        "actual_size_bytes": actual_size
                    }
                    total_estimated_size += actual_size_gb
                    
                    print(f"âœ… {model_info['name']}: {actual_size_gb:.1f}GB ({model_info['priority']})")
                else:
                    print(f"â“ ì•Œ ìˆ˜ ì—†ëŠ” ëª¨ë¸: {model_dir.name}")
        
        print(f"\nğŸ“Š ì´ {len(found_models)}ê°œ ëª¨ë¸, ì˜ˆìƒ í¬ê¸°: {total_estimated_size:.1f}GB")
        return found_models
    
    def get_directory_size(self, directory: Path) -> int:
        """ë””ë ‰í† ë¦¬ í¬ê¸° ê³„ì‚°"""
        total_size = 0
        try:
            for file_path in directory.rglob("*"):
                if file_path.is_file():
                    total_size += file_path.stat().st_size
        except Exception as e:
            print(f"âš ï¸ í¬ê¸° ê³„ì‚° ì‹¤íŒ¨ {directory.name}: {e}")
        return total_size
    
    def check_disk_space(self, required_gb: float) -> bool:
        """ë””ìŠ¤í¬ ê³µê°„ ì²´í¬"""
        try:
            stat = os.statvfs(self.target_path)
            available_gb = (stat.f_bavail * stat.f_frsize) / (1024**3)
            
            print(f"ğŸ’¾ ì‚¬ìš© ê°€ëŠ¥ ê³µê°„: {available_gb:.1f}GB")
            print(f"ğŸ“¦ í•„ìš”í•œ ê³µê°„: {required_gb:.1f}GB")
            
            if available_gb > required_gb * 1.2:  # 20% ì—¬ìœ  ê³µê°„
                print("âœ… ì¶©ë¶„í•œ ë””ìŠ¤í¬ ê³µê°„")
                return True
            else:
                print("âŒ ë””ìŠ¤í¬ ê³µê°„ ë¶€ì¡±")
                return False
        except Exception as e:
            print(f"âš ï¸ ë””ìŠ¤í¬ ê³µê°„ ì²´í¬ ì‹¤íŒ¨: {e}")
            return True  # ì—ëŸ¬ì‹œ ì§„í–‰
    
    def copy_model_with_progress(self, source: Path, target: Path, model_name: str, size_gb: float) -> bool:
        """ì§„í–‰ë¥  í‘œì‹œì™€ í•¨ê»˜ ëª¨ë¸ ë³µì‚¬"""
        try:
            target.mkdir(parents=True, exist_ok=True)
            
            print(f"\nğŸšš {model_name} ë³µì‚¬ ì¤‘... ({size_gb:.1f}GB)")
            start_time = time.time()
            
            # íŒŒì¼ë³„ ë³µì‚¬ (ì§„í–‰ë¥  í‘œì‹œ)
            total_files = sum(1 for _ in source.rglob("*") if _.is_file())
            copied_files = 0
            
            for file_path in source.rglob("*"):
                if file_path.is_file():
                    relative_path = file_path.relative_to(source)
                    target_file = target / relative_path
                    
                    # ë””ë ‰í† ë¦¬ ìƒì„±
                    target_file.parent.mkdir(parents=True, exist_ok=True)
                    
                    # íŒŒì¼ ë³µì‚¬
                    shutil.copy2(file_path, target_file)
                    
                    copied_files += 1
                    progress = (copied_files / total_files) * 100
                    
                    # ì§„í–‰ë¥  í‘œì‹œ (10% ë‹¨ìœ„)
                    if copied_files % max(1, total_files // 10) == 0:
                        elapsed = time.time() - start_time
                        print(f"  ğŸ“Š {progress:.0f}% ì™„ë£Œ ({copied_files}/{total_files} íŒŒì¼, {elapsed:.1f}ì´ˆ)")
            
            elapsed = time.time() - start_time
            print(f"  âœ… ì™„ë£Œ! ({elapsed:.1f}ì´ˆ)")
            
            return True
            
        except Exception as e:
            print(f"  âŒ ë³µì‚¬ ì‹¤íŒ¨: {e}")
            return False
    
    def consolidate_huggingface_models(self) -> bool:
        """ë©”ì¸ í†µí•© í”„ë¡œì„¸ìŠ¤"""
        print("ğŸ¤– HuggingFace ëª¨ë¸ ì™„ì „ í†µí•© ì‹œì‘!")
        print("=" * 60)
        
        self.results["start_time"] = datetime.now()
        
        # 1. ì†ŒìŠ¤ ëª¨ë¸ ë¶„ì„
        found_models = self.analyze_source_models()
        
        if not found_models:
            print("âŒ ì´ë™í•  HuggingFace ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")
            return False
        
        # 2. ë””ìŠ¤í¬ ê³µê°„ ì²´í¬
        total_size_gb = sum(model["actual_size_gb"] for model in found_models.values())
        
        if not self.check_disk_space(total_size_gb):
            print("âŒ ë””ìŠ¤í¬ ê³µê°„ ë¶€ì¡±ìœ¼ë¡œ ì¤‘ë‹¨ë©ë‹ˆë‹¤.")
            return False
        
        # 3. ì‚¬ìš©ì í™•ì¸
        print(f"\nğŸ“‹ ì´ë™í•  ëª¨ë¸ë“¤:")
        for model_dir, info in found_models.items():
            print(f"  ğŸ¤– {info['name']}: {info['actual_size_gb']:.1f}GB â†’ {info['step']}/")
        
        response = input(f"\nğŸšš ì´ {total_size_gb:.1f}GBì˜ ëª¨ë¸ì„ ì´ë™í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/N): ").strip().lower()
        if response not in ['y', 'yes']:
            print("âŒ ì‘ì—…ì´ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.")
            return False
        
        # 4. ëª¨ë¸ë³„ ì´ë™ ì‹¤í–‰
        success_count = 0
        
        for model_dir, info in found_models.items():
            try:
                # ëŒ€ìƒ ê²½ë¡œ ì„¤ì •
                target_model_dir = self.target_path / "downloads" / info["name"]
                
                # ëª¨ë¸ ë³µì‚¬
                if self.copy_model_with_progress(
                    info["path"], 
                    target_model_dir, 
                    info["name"], 
                    info["actual_size_gb"]
                ):
                    success_count += 1
                    self.results["moved_models"].append({
                        "name": info["name"],
                        "step": info["step"], 
                        "size_gb": info["actual_size_gb"],
                        "source": str(info["path"]),
                        "target": str(target_model_dir)
                    })
                    self.results["total_size_moved"] += info["actual_size_gb"]
                else:
                    self.results["errors"].append({
                        "model": info["name"],
                        "error": "ë³µì‚¬ ì‹¤íŒ¨"
                    })
                    
            except Exception as e:
                print(f"âŒ {info['name']} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                self.results["errors"].append({
                    "model": info["name"],
                    "error": str(e)
                })
        
        # 5. ê²°ê³¼ ìš”ì•½
        self.results["end_time"] = datetime.now()
        self.print_final_summary(success_count, len(found_models))
        self.save_consolidation_report()
        
        return success_count == len(found_models)
    
    def print_final_summary(self, success_count: int, total_count: int):
        """ìµœì¢… ê²°ê³¼ ìš”ì•½"""
        total_time = (self.results["end_time"] - self.results["start_time"]).total_seconds()
        
        print("\n" + "=" * 60)
        print("ğŸ‰ HuggingFace ëª¨ë¸ í†µí•© ì™„ë£Œ!")
        print("=" * 60)
        print(f"âœ… ì„±ê³µ: {success_count}/{total_count}ê°œ ëª¨ë¸")
        print(f"ğŸ“¦ ì´ë™ëœ ìš©ëŸ‰: {self.results['total_size_moved']:.1f}GB")
        print(f"â±ï¸ ì´ ì†Œìš” ì‹œê°„: {total_time:.1f}ì´ˆ")
        print(f"âŒ ì‹¤íŒ¨: {len(self.results['errors'])}ê°œ")
        
        if self.results["moved_models"]:
            print(f"\nğŸ“ ì´ë™ëœ ëª¨ë¸ë“¤:")
            for model in self.results["moved_models"]:
                print(f"  âœ… {model['name']}: {model['size_gb']:.1f}GB â†’ {model['step']}/")
        
        print(f"\nğŸ“ ìµœì¢… ìœ„ì¹˜:")
        print(f"  {self.target_path}/downloads/")
        for model in self.results["moved_models"]:
            print(f"    â”œâ”€â”€ {model['name']}/")
    
    def save_consolidation_report(self):
        """í†µí•© ë¦¬í¬íŠ¸ ì €ì¥"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        report_path = self.target_path / f"huggingface_consolidation_report_{timestamp}.json"
        
        # ì‹œê°„ ì •ë³´ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜
        report_data = {
            **self.results,
            "start_time": self.results["start_time"].isoformat(),
            "end_time": self.results["end_time"].isoformat()
        }
        
        try:
            with open(report_path, 'w', encoding='utf-8') as f:
                json.dump(report_data, f, indent=2, ensure_ascii=False)
            print(f"\nğŸ“Š ìƒì„¸ ë¦¬í¬íŠ¸: {report_path}")
        except Exception as e:
            print(f"âš ï¸ ë¦¬í¬íŠ¸ ì €ì¥ ì‹¤íŒ¨: {e}")

def main():
    """ë©”ì¸ ì‹¤í–‰"""
    print("ğŸ¤– HuggingFace ëª¨ë¸ ì™„ì „ í†µí•©ê¸° v1.0")
    print("=" * 60)
    
    consolidator = HuggingFaceModelConsolidator()
    
    # ê²½ë¡œ í™•ì¸
    if consolidator.source_path.exists():
        print(f"âœ… ì†ŒìŠ¤ ê²½ë¡œ: {consolidator.source_path}")
    else:
        print(f"âŒ ì†ŒìŠ¤ ê²½ë¡œ ì—†ìŒ: {consolidator.source_path}")
        return False
    
    print(f"ğŸ“ í†µí•© ëŒ€ìƒ: {consolidator.target_path}")
    
    # ì‹¤í–‰
    success = consolidator.consolidate_huggingface_models()
    
    if success:
        print("\nğŸ‰ ëª¨ë“  HuggingFace ëª¨ë¸ì´ ì„±ê³µì ìœ¼ë¡œ í†µí•©ë˜ì—ˆìŠµë‹ˆë‹¤!")
        print("ğŸ’¡ ì´ì œ íŒŒì´í”„ë¼ì¸ì—ì„œ ëª¨ë“  ëª¨ë¸ì„ ì§ì ‘ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!")
    else:
        print("\nâš ï¸ ì¼ë¶€ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë¦¬í¬íŠ¸ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
    
    return success

if __name__ == "__main__":
    main()