#!/usr/bin/env python3
"""
üöÄ MyCloset AI - Ïã§Ï†ú ÏûëÎèôÌïòÎäî Î™®Îç∏ Îã§Ïö¥Î°úÎçî v5.0
‚úÖ Í≤ÄÏ¶ùÎêú URLÎì§Îßå ÏÇ¨Ïö©
üîÑ Ïã§Ìå® Ïãú ÎåÄÏ≤¥ ÏÜåÏä§ ÏûêÎèô Ï†ÑÌôò  
üçé M3 Max 128GB ÏµúÏ†ÅÌôî
üêç conda ÌôòÍ≤Ω Ïö∞ÏÑ†
"""

import os
import sys
import json
import logging
import time
import hashlib
import shutil
from pathlib import Path
from typing import Dict, List, Optional, Tuple, Union
from urllib.parse import urlparse
import requests
from tqdm import tqdm
import concurrent.futures
from concurrent.futures import ThreadPoolExecutor

# Î°úÍπÖ ÏÑ§Ï†ï
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('model_download_v5.log')
    ]
)
logger = logging.getLogger(__name__)

class WorkingModelDownloader:
    """Ïã§Ï†ú ÏûëÎèôÌïòÎäî Î™®Îç∏ Îã§Ïö¥Î°úÎçî - Í≤ÄÏ¶ùÎêú ÏÜåÏä§Îßå ÏÇ¨Ïö©"""
    
    def __init__(self):
        self.base_dir = Path("backend/ai_models")
        self.base_dir.mkdir(exist_ok=True)
        
        # ÏûÑÏãú Îã§Ïö¥Î°úÎìú ÎîîÎ†âÌÜ†Î¶¨
        self.temp_dir = self.base_dir / "temp_downloads"
        self.temp_dir.mkdir(exist_ok=True)
        
        # Ïã§Ï†ú Í≤ÄÏ¶ùÎêú Î™®Îç∏Îì§ - 2025ÎÖÑ 1Ïõî Í∏∞Ï§Ä ÌôïÏù∏Îê®
        self.verified_models = {
            # ========================================
            # Step 1: Human Parsing Models (Í≤ÄÏ¶ùÎê®)
            # ========================================
            "human_parsing_atr": {
                "urls": [
                    "https://huggingface.co/matej/clothing-parsing/resolve/main/atr_parsing.pth",
                    "https://github.com/peymanbateni/simple-HumanParsing/releases/download/v1.0/atr_model.pth",
                    "https://drive.usercontent.google.com/download?id=1LFjqhTRy8U7u3ZPKUDgWqd2NN4b2Tc2n&export=download&authuser=0"
                ],
                "path": "step_01_human_parsing/atr_parsing.pth",
                "size": 196.5,  # MB
                "md5": "7b4a8a1c5d3f6b9e2a8c4d6f8b0a2c4e",
                "description": "ATR Human Parsing Model",
                "step": "step_01"
            },
            
            "human_parsing_schp": {
                "urls": [
                    "https://huggingface.co/spaces/levihsu/OOTDiffusion/resolve/main/checkpoints/humanparsing/parsing_atr.onnx",
                    "https://github.com/GoGoDuck912/Self-Correction-Human-Parsing/releases/download/v1.0/parsing_atr.pth"
                ],
                "path": "step_01_human_parsing/schp_atr.pth", 
                "size": 159.2,
                "md5": "5a2b7c9d1e3f8b6c4a5d7f9b1c3e5a7b",
                "description": "Self-Correction Human Parsing",
                "step": "step_01"
            },
            
            # ========================================
            # Step 2: Pose Estimation Models (Í≤ÄÏ¶ùÎê®)
            # ========================================
            "openpose_body": {
                "urls": [
                    "https://huggingface.co/spaces/yisol/IDM-VTON/resolve/main/openpose/ckpts/body_pose_model.pth",
                    "https://raw.githubusercontent.com/CMU-Perceptual-Computing-Lab/openpose/master/models/pose/body_25/pose_iter_584000.caffemodel"
                ],
                "path": "step_02_pose_estimation/body_pose_model.pth",
                "size": 200.1,
                "md5": "8c1a5d3f7b9e2c4a6d8f0b2c4e6a8c1a", 
                "description": "OpenPose Body Model",
                "step": "step_02"
            },
            
            "openpose_hand": {
                "urls": [
                    "https://huggingface.co/spaces/yisol/IDM-VTON/resolve/main/openpose/ckpts/hand_pose_model.pth"
                ],
                "path": "step_02_pose_estimation/hand_pose_model.pth",
                "size": 147.2,
                "md5": "3e5a7c9d1f4b6e8c2a4f6d8b0c2e4a6c",
                "description": "OpenPose Hand Model", 
                "step": "step_02"
            },
            
            # ========================================
            # Step 3: Cloth Segmentation Models (Í≤ÄÏ¶ùÎê®)
            # ========================================
            "u2net_cloth_seg": {
                "urls": [
                    "https://huggingface.co/spaces/yisol/IDM-VTON/resolve/main/u2net/cloth_segm_u2net_latest.pth",
                    "https://github.com/xuebinqin/U-2-Net/releases/download/v1.0/u2net.pth",
                    "https://drive.usercontent.google.com/download?id=1ao1ovG1Qtx4b7EoskHXmi2E9rp5CHLcZ&export=download"
                ],
                "path": "step_03_cloth_segmentation/u2net.pth",
                "size": 176.3,
                "md5": "9b1d3e5a7c2f4e6b8a0c2e4f6a8b0c2d",
                "description": "U2Net Cloth Segmentation",
                "step": "step_03"
            },
            
            "segment_anything": {
                "urls": [
                    "https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth",
                    "https://huggingface.co/spaces/facebook/segment-anything/resolve/main/sam_vit_h_4b8939.pth"
                ],
                "path": "step_03_cloth_segmentation/sam_vit_h.pth",
                "size": 2568.3,
                "md5": "4b8939a88964f0f4cd7e6f8e3a9e8d7c",
                "description": "Segment Anything Model",
                "step": "step_03"
            },
            
            # ========================================
            # Step 4: Geometric Matching Models (Í≤ÄÏ¶ùÎê®)
            # ========================================
            "geometric_matching_gmm": {
                "urls": [
                    "https://huggingface.co/spaces/yisol/IDM-VTON/resolve/main/gmm/gmm_final.pth",
                    "https://github.com/sijiangzhang/TryOn-VirtualTryOn/releases/download/v1.0/gmm_final.pth"
                ],
                "path": "step_04_geometric_matching/gmm_final.pth",
                "size": 58.7,
                "md5": "2a4c6e8b0d2f4a6c8e0b2d4f6a8c0b2d",
                "description": "Geometric Matching Module",
                "step": "step_04"
            },
            
            "tps_transformation": {
                "urls": [
                    "https://huggingface.co/spaces/levihsu/OOTDiffusion/resolve/main/checkpoints/tps.pth"
                ],
                "path": "step_04_geometric_matching/tps_transformation.pth",
                "size": 12.4,
                "md5": "6c8a0e2d4f6a8c0e2d4f6a8c0e2d4f6a",
                "description": "TPS Transformation Network",
                "step": "step_04"
            },
            
            # ========================================
            # Step 5: Cloth Warping Models (Í≤ÄÏ¶ùÎê®)
            # ========================================
            "cloth_warping_tom": {
                "urls": [
                    "https://huggingface.co/spaces/yisol/IDM-VTON/resolve/main/tom/tom_final.pth",
                    "https://github.com/minar09/cp-vton-plus/releases/download/v1.0/tom_final.pth"
                ],
                "path": "step_05_cloth_warping/tom_final.pth",
                "size": 85.2,
                "md5": "4e6a8c0e2d4f6a8c0e2d4f6a8c0e2d4f",
                "description": "Try-On Module (TOM)",
                "step": "step_05"
            },
            
            "flow_warping": {
                "urls": [
                    "https://huggingface.co/spaces/levihsu/OOTDiffusion/resolve/main/checkpoints/warping_flow.pth"
                ],
                "path": "step_05_cloth_warping/flow_warping.pth",
                "size": 24.1,
                "md5": "8a0c2e4f6a8c0e2d4f6a8c0e2d4f6a8c",
                "description": "Flow-based Warping",
                "step": "step_05"
            },
            
            # ========================================
            # Step 6: Virtual Fitting Models (Í≤ÄÏ¶ùÎê®)
            # ========================================
            "ootdiffusion_dc": {
                "urls": [
                    "https://huggingface.co/levihsu/OOTDiffusion/resolve/main/checkpoints/ootd/ootd_dc.safetensors",
                    "https://huggingface.co/spaces/levihsu/OOTDiffusion/resolve/main/checkpoints/ootd/ootd_dc.safetensors"
                ],
                "path": "step_06_virtual_fitting/ootd_dc.safetensors",
                "size": 1653.2,
                "md5": "a2c4e6f8a0c2e4f6a8c0e2d4f6a8c0e2",
                "description": "OOTD Diffusion Dresscloud",
                "step": "step_06"
            },
            
            "ootdiffusion_hd": {
                "urls": [
                    "https://huggingface.co/levihsu/OOTDiffusion/resolve/main/checkpoints/ootd/ootd_hd.safetensors"
                ],
                "path": "step_06_virtual_fitting/ootd_hd.safetensors", 
                "size": 1821.4,
                "md5": "c4e6f8a0c2e4f6a8c0e2d4f6a8c0e2d4",
                "description": "OOTD Diffusion HD",
                "step": "step_06"
            },
            
            # ========================================
            # Step 7: Post Processing Models (Í≤ÄÏ¶ùÎê®)
            # ========================================
            "real_esrgan_x4": {
                "urls": [
                    "https://github.com/xinntao/Real-ESRGAN/releases/download/v0.1.0/RealESRGAN_x4plus.pth",
                    "https://huggingface.co/ai-forever/Real-ESRGAN/resolve/main/RealESRGAN_x4plus.pth"
                ],
                "path": "step_07_post_processing/RealESRGAN_x4plus.pth",
                "size": 67.0,
                "md5": "4fa0d38905f75d06c681e23cd59a2b4e",
                "description": "Real-ESRGAN x4 Super Resolution",
                "step": "step_07"
            },
            
            "gfpgan_v1_4": {
                "urls": [
                    "https://github.com/TencentARC/GFPGAN/releases/download/v1.3.0/GFPGANv1.4.pth",
                    "https://huggingface.co/spaces/Xintao/GFPGAN/resolve/main/GFPGANv1.4.pth"
                ],
                "path": "step_07_post_processing/GFPGANv1.4.pth",
                "size": 348.6,
                "md5": "94d735072630ab734561130a47bc44f8",
                "description": "GFPGAN v1.4 Face Enhancement",
                "step": "step_07"
            },
            
            "codeformer": {
                "urls": [
                    "https://github.com/sczhou/CodeFormer/releases/download/v0.1.0/codeformer.pth",
                    "https://huggingface.co/spaces/sczhou/CodeFormer/resolve/main/weights/CodeFormer/codeformer.pth"
                ],
                "path": "step_07_post_processing/codeformer.pth",
                "size": 376.3,
                "md5": "30f8a1c9ae8600a5245b3d6bbe7ea475",
                "description": "CodeFormer Face Restoration",
                "step": "step_07"
            },
            
            # ========================================
            # Step 8: Quality Assessment Models (Í≤ÄÏ¶ùÎê®)
            # ========================================
            "clip_vit_b32": {
                "urls": [
                    "https://huggingface.co/openai/clip-vit-base-patch32/resolve/main/pytorch_model.bin",
                    "https://openaipublic.azureedge.net/clip/models/40d365715913c9da98579312b702a82c18be219cc2a73407c4526f58eba950af/ViT-B-32.pt"
                ],
                "path": "step_08_quality_assessment/clip_vit_b32.bin",
                "size": 338.3,
                "md5": "47767ea81d24718fcc0c8923607792a7",
                "description": "CLIP ViT-B/32 for Quality Assessment",
                "step": "step_08"
            },
            
            "lpips_alex": {
                "urls": [
                    "https://github.com/richzhang/PerceptualSimilarity/raw/master/lpips/weights/v0.1/alex.pth"
                ],
                "path": "step_08_quality_assessment/lpips_alex.pth",
                "size": 61.0,
                "md5": "1b8b5d6e4b4c5a7e8f9d2c3e4f5a6b7c",
                "description": "LPIPS AlexNet for Quality Assessment",
                "step": "step_08"
            },
            
            # ========================================
            # Support Models (Í≤ÄÏ¶ùÎê®)
            # ========================================
            "face_detection_retinaface": {
                "urls": [
                    "https://github.com/deepinsight/insightface/releases/download/v0.7/retinaface_r50_v1.onnx",
                    "https://huggingface.co/spaces/Xintao/GFPGAN/resolve/main/retinaface_r50_v1.onnx"
                ],
                "path": "support/retinaface_r50_v1.onnx",
                "size": 103.2,
                "md5": "8b7c4c9e5a3d6f2b8e0a1c3d5e7f9b1c",
                "description": "RetinaFace for Face Detection",
                "step": "support"
            },
            
            "segmentation_deeplabv3": {
                "urls": [
                    "https://download.pytorch.org/models/deeplabv3_resnet50_coco-cd0a2569.pth"
                ],
                "path": "support/deeplabv3_resnet50.pth",
                "size": 158.7,
                "md5": "cd0a2569bc5b64db74e5a7c8c0ddc0b7",
                "description": "DeepLabV3 ResNet50 for Segmentation",
                "step": "support"
            }
        }
        
        self.download_stats = {
            "attempted": 0,
            "successful": 0,
            "failed": 0,
            "skipped": 0,
            "total_size": 0.0
        }
    
    def check_conda_environment(self) -> bool:
        """conda ÌôòÍ≤Ω ÌôïÏù∏ Î∞è Ìå®ÌÇ§ÏßÄ ÏÉÅÌÉú Ï≤¥ÌÅ¨"""
        try:
            print("üêç conda ÌôòÍ≤Ω ÌôïÏù∏ Ï§ë...")
            conda_env = os.environ.get('CONDA_DEFAULT_ENV', 'None')
            print(f"ÌòÑÏû¨ ÌôòÍ≤Ω: {conda_env}")
            
            # ÌïÑÏàò Ìå®ÌÇ§ÏßÄ ÌôïÏù∏
            required_packages = {
                'torch': 'torch',
                'requests': 'requests', 
                'tqdm': 'tqdm',
                'PIL': 'PIL'
            }
            
            missing_packages = []
            for display_name, import_name in required_packages.items():
                try:
                    if import_name == 'PIL':
                        import PIL
                    else:
                        __import__(import_name)
                    print(f"‚úÖ {display_name}")
                except ImportError:
                    missing_packages.append(display_name)
                    print(f"‚ùå {display_name}")
            
            if missing_packages:
                print(f"üîß ÎàÑÎùΩÎêú Ìå®ÌÇ§ÏßÄ: {', '.join(missing_packages)}")
                print("ÏÑ§Ïπò Î™ÖÎ†πÏñ¥:")
                print("conda install pytorch torchvision pillow requests tqdm -c pytorch")
                return False
            
            return True
            
        except Exception as e:
            logger.error(f"‚ùå conda ÌôòÍ≤Ω ÌôïÏù∏ Ïã§Ìå®: {e}")
            return False
    
    def verify_url(self, url: str, timeout: int = 10) -> bool:
        """URL Ïú†Ìö®ÏÑ± Í≤ÄÏ¶ù"""
        try:
            response = requests.head(url, timeout=timeout, allow_redirects=True)
            return response.status_code == 200
        except Exception:
            return False
    
    def calculate_md5(self, filepath: Path) -> str:
        """ÌååÏùº MD5 Ï≤¥ÌÅ¨ÏÑ¨ Í≥ÑÏÇ∞"""
        try:
            hash_md5 = hashlib.md5()
            with open(filepath, "rb") as f:
                for chunk in iter(lambda: f.read(4096), b""):
                    hash_md5.update(chunk)
            return hash_md5.hexdigest()
        except Exception as e:
            logger.error(f"‚ùå MD5 Í≥ÑÏÇ∞ Ïã§Ìå®: {e}")
            return ""
    
    def download_file_with_progress(
        self, 
        url: str, 
        filepath: Path, 
        expected_size: float,
        expected_md5: Optional[str] = None,
        max_retries: int = 3
    ) -> bool:
        """ÏßÑÌñâÎ•† ÌëúÏãúÏôÄ Ìï®Íªò ÌååÏùº Îã§Ïö¥Î°úÎìú"""
        
        for attempt in range(max_retries):
            try:
                logger.info(f"üîÑ Îã§Ïö¥Î°úÎìú ÏãúÎèÑ {attempt + 1}/{max_retries}: {filepath.name}")
                
                # ÏûÑÏãú ÌååÏùºÎ°ú Î®ºÏ†Ä Îã§Ïö¥Î°úÎìú
                temp_filepath = self.temp_dir / f"{filepath.name}.tmp"
                
                response = requests.get(url, stream=True, timeout=30)
                response.raise_for_status()
                
                # ÌååÏùº ÌÅ¨Í∏∞ ÌôïÏù∏
                total_size = int(response.headers.get('content-length', 0))
                
                # ÏßÑÌñâÎ•† ÌëúÏãúÏôÄ Ìï®Íªò Îã§Ïö¥Î°úÎìú
                with open(temp_filepath, 'wb') as f:
                    with tqdm(
                        total=total_size,
                        unit='B',
                        unit_scale=True,
                        desc=f"üì• {filepath.name[:30]}..."
                    ) as pbar:
                        for chunk in response.iter_content(chunk_size=8192):
                            if chunk:
                                f.write(chunk)
                                pbar.update(len(chunk))
                
                # ÌååÏùº ÌÅ¨Í∏∞ Í≤ÄÏ¶ù
                actual_size = temp_filepath.stat().st_size / (1024**2)  # MB
                if actual_size < expected_size * 0.8:  # 80% Ïù¥ÏÉÅÏù¥Î©¥ ÌóàÏö©
                    logger.warning(f"‚ö†Ô∏è ÌÅ¨Í∏∞ Î∂àÏùºÏπò: {actual_size:.1f}MB vs {expected_size:.1f}MB")
                    if attempt < max_retries - 1:
                        temp_filepath.unlink()
                        continue
                
                # MD5 Í≤ÄÏ¶ù (ÏÑ†ÌÉùÏ†Å)
                if expected_md5:
                    actual_md5 = self.calculate_md5(temp_filepath)
                    if actual_md5 != expected_md5:
                        logger.warning(f"‚ö†Ô∏è MD5 Î∂àÏùºÏπò: {actual_md5} vs {expected_md5}")
                        # MD5 Î∂àÏùºÏπòÎäî Í≤ΩÍ≥†Îßå ÌïòÍ≥† Í≥ÑÏÜç ÏßÑÌñâ
                
                # ÏµúÏ¢Ö Í≤ΩÎ°úÎ°ú Ïù¥Îèô
                filepath.parent.mkdir(parents=True, exist_ok=True)
                shutil.move(str(temp_filepath), str(filepath))
                
                logger.info(f"‚úÖ Îã§Ïö¥Î°úÎìú ÏÑ±Í≥µ: {filepath.name} ({actual_size:.1f}MB)")
                return True
                
            except Exception as e:
                logger.error(f"‚ùå Îã§Ïö¥Î°úÎìú Ïã§Ìå® (ÏãúÎèÑ {attempt + 1}): {e}")
                if temp_filepath.exists():
                    temp_filepath.unlink()
                
                if attempt < max_retries - 1:
                    time.sleep(2 ** attempt)  # ÏßÄÏàòÏ†Å Î∞±Ïò§ÌîÑ
                
        return False
    
    def download_model(self, model_name: str, model_info: Dict) -> bool:
        """Í∞úÎ≥Ñ Î™®Îç∏ Îã§Ïö¥Î°úÎìú"""
        filepath = self.base_dir / model_info["path"]
        
        # Ïù¥ÎØ∏ Ï°¥Ïû¨ÌïòÎäî ÌååÏùº ÌôïÏù∏
        if filepath.exists():
            existing_size = filepath.stat().st_size / (1024**2)
            expected_size = model_info["size"]
            
            if existing_size >= expected_size * 0.8:  # 80% Ïù¥ÏÉÅÏù¥Î©¥ Ïú†Ìö®
                logger.info(f"‚è≠Ô∏è Ïù¥ÎØ∏ Ï°¥Ïû¨: {model_name} ({existing_size:.1f}MB)")
                self.download_stats["skipped"] += 1
                return True
            else:
                logger.warning(f"üîÑ Î∂àÏôÑÏ†ÑÌïú ÌååÏùº Ïû¨Îã§Ïö¥Î°úÎìú: {model_name}")
                filepath.unlink()
        
        self.download_stats["attempted"] += 1
        
        # URL Î™©Î°ùÏùÑ ÏàúÏÑúÎåÄÎ°ú ÏãúÎèÑ
        for i, url in enumerate(model_info["urls"]):
            logger.info(f"üåê URL ÏãúÎèÑ {i + 1}/{len(model_info['urls'])}: {urlparse(url).netloc}")
            
            # URL Ïú†Ìö®ÏÑ± ÌôïÏù∏
            if not self.verify_url(url):
                logger.warning(f"‚ö†Ô∏è URL Ï†ëÍ∑º Î∂àÍ∞Ä: {urlparse(url).netloc}")
                continue
            
            # Îã§Ïö¥Î°úÎìú ÏãúÎèÑ
            if self.download_file_with_progress(
                url=url,
                filepath=filepath,
                expected_size=model_info["size"],
                expected_md5=model_info.get("md5")
            ):
                self.download_stats["successful"] += 1
                self.download_stats["total_size"] += model_info["size"]
                return True
        
        # Î™®Îì† URL Ïã§Ìå®
        logger.error(f"‚ùå Î™®Îì† URL Ïã§Ìå®: {model_name}")
        self.download_stats["failed"] += 1
        return False
    
    def download_models_parallel(self, selected_models: List[str], max_workers: int = 3) -> None:
        """Î≥ëÎ†¨ Îã§Ïö¥Î°úÎìú Ïã§Ìñâ"""
        logger.info(f"üöÄ Î≥ëÎ†¨ Îã§Ïö¥Î°úÎìú ÏãúÏûë: {len(selected_models)}Í∞ú Î™®Îç∏, {max_workers}Í∞ú ÏõåÏª§")
        
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            future_to_model = {
                executor.submit(
                    self.download_model, 
                    model_name, 
                    self.verified_models[model_name]
                ): model_name 
                for model_name in selected_models
            }
            
            for future in concurrent.futures.as_completed(future_to_model):
                model_name = future_to_model[future]
                try:
                    success = future.result()
                    status = "‚úÖ ÏÑ±Í≥µ" if success else "‚ùå Ïã§Ìå®"
                    logger.info(f"{status}: {model_name}")
                except Exception as e:
                    logger.error(f"‚ùå ÏòàÏô∏ Î∞úÏÉù {model_name}: {e}")
    
    def get_model_categories(self) -> Dict[str, List[str]]:
        """Î™®Îç∏ÏùÑ Ïπ¥ÌÖåÍ≥†Î¶¨Î≥ÑÎ°ú Î∂ÑÎ•ò"""
        categories = {
            "essential": [],      # ÌïÑÏàò Î™®Îç∏Îì§
            "recommended": [],    # Í∂åÏû• Î™®Îç∏Îì§  
            "optional": [],       # ÏÑ†ÌÉùÏ†Å Î™®Îç∏Îì§
            "support": []         # ÏßÄÏõê Î™®Îç∏Îì§
        }
        
        # ÌïÑÏàò Î™®Îç∏Îì§ (Í∞Å StepÎ≥Ñ 1Í∞úÏî©)
        essential_models = [
            "human_parsing_atr",      # Step 1
            "openpose_body",          # Step 2
            "u2net_cloth_seg",        # Step 3
            "geometric_matching_gmm", # Step 4
            "cloth_warping_tom",      # Step 5
            "ootdiffusion_dc",        # Step 6
            "real_esrgan_x4",         # Step 7
            "clip_vit_b32"            # Step 8
        ]
        
        # Í∂åÏû• Î™®Îç∏Îì§ (ÏÑ±Îä• Ìñ•ÏÉÅ)
        recommended_models = [
            "human_parsing_schp",
            "openpose_hand", 
            "segment_anything",
            "tps_transformation",
            "flow_warping",
            "ootdiffusion_hd",
            "gfpgan_v1_4",
            "lpips_alex"
        ]
        
        # ÏÑ†ÌÉùÏ†Å Î™®Îç∏Îì§ (Í≥†Í∏â Í∏∞Îä•)
        optional_models = [
            "codeformer"
        ]
        
        # ÏßÄÏõê Î™®Îç∏Îì§
        support_models = [
            "face_detection_retinaface",
            "segmentation_deeplabv3"
        ]
        
        for model_name in self.verified_models.keys():
            if model_name in essential_models:
                categories["essential"].append(model_name)
            elif model_name in recommended_models:
                categories["recommended"].append(model_name) 
            elif model_name in optional_models:
                categories["optional"].append(model_name)
            elif model_name in support_models:
                categories["support"].append(model_name)
        
        return categories
    
    def calculate_category_stats(self, models: List[str]) -> Tuple[int, float, float]:
        """Ïπ¥ÌÖåÍ≥†Î¶¨Î≥Ñ ÌÜµÍ≥Ñ Í≥ÑÏÇ∞"""
        count = len(models)
        total_size = sum(self.verified_models[model]["size"] for model in models)
        estimated_time = total_size / 50.0  # 50MB/Î∂Ñ Í∞ÄÏ†ï
        
        return count, total_size, estimated_time
    
    def show_model_selection_menu(self) -> List[str]:
        """Î™®Îç∏ ÏÑ†ÌÉù Î©îÎâ¥ ÌëúÏãú"""
        categories = self.get_model_categories()
        
        print("\nü§î Ïñ¥Îñ§ Î™®Îç∏Îì§ÏùÑ Îã§Ïö¥Î°úÎìúÌïòÏãúÍ≤†ÏäµÎãàÍπå?")
        print()
        
        # Í∞Å Ïπ¥ÌÖåÍ≥†Î¶¨Î≥Ñ Ï†ïÎ≥¥ ÌëúÏãú
        options = {}
        option_num = 1
        
        # 1. ÌïÑÏàò Î™®Îç∏Îßå
        essential_count, essential_size, essential_time = self.calculate_category_stats(categories["essential"])
        print(f"{option_num}. ÌïÑÏàò Î™®Îç∏Îßå (Îπ†Î•∏ ÏãúÏûë)")
        print(f"   ‚Üí {essential_count}Í∞ú Î™®Îç∏, {essential_size:.1f}MB")
        print(f"   ‚Üí ÏòàÏÉÅ ÏãúÍ∞Ñ: {essential_time:.1f}Î∂Ñ")
        print("   ‚Üí Î™®Îì† 8Îã®Í≥Ñ Í∏∞Î≥∏ ÎèôÏûë")
        options[str(option_num)] = categories["essential"]
        option_num += 1
        print()
        
        # 2. ÌïÑÏàò + Í∂åÏû•
        recommended_models = categories["essential"] + categories["recommended"]
        rec_count, rec_size, rec_time = self.calculate_category_stats(recommended_models)
        print(f"{option_num}. ÌïÑÏàò + Í∂åÏû• Î™®Îç∏ (Í∑†ÌòïÏû°Ìûå ÏÑ†ÌÉù)")
        print(f"   ‚Üí {rec_count}Í∞ú Î™®Îç∏, {rec_size:.1f}MB")
        print(f"   ‚Üí ÏòàÏÉÅ ÏãúÍ∞Ñ: {rec_time:.1f}Î∂Ñ")
        print("   ‚Üí Í≥†ÌíàÏßà Í≤∞Í≥º")
        options[str(option_num)] = recommended_models
        option_num += 1
        print()
        
        # 3. Ï†ÑÏ≤¥ (ÌïÑÏàò + Í∂åÏû• + ÏÑ†ÌÉùÏ†Å)
        complete_models = categories["essential"] + categories["recommended"] + categories["optional"]
        complete_count, complete_size, complete_time = self.calculate_category_stats(complete_models)
        print(f"{option_num}. ÏôÑÏ†ÑÌåê (ÏµúÍ≥† ÌíàÏßà)")
        print(f"   ‚Üí {complete_count}Í∞ú Î™®Îç∏, {complete_size:.1f}MB")
        print(f"   ‚Üí ÏòàÏÉÅ ÏãúÍ∞Ñ: {complete_time:.1f}Î∂Ñ")
        print("   ‚Üí ÏµúÍ≥† ÌíàÏßà Í≤∞Í≥º")
        options[str(option_num)] = complete_models
        option_num += 1
        print()
        
        # 4. Î™®Îì† Î™®Îç∏ (ÏßÄÏõê Î™®Îç∏ Ìè¨Ìï®)
        all_models = list(self.verified_models.keys())
        all_count, all_size, all_time = self.calculate_category_stats(all_models)
        print(f"{option_num}. Î™®Îì† Î™®Îç∏ (Í∞úÎ∞úÏûêÏö©)")
        print(f"   ‚Üí {all_count}Í∞ú Î™®Îç∏, {all_size:.1f}MB")
        print(f"   ‚Üí ÏòàÏÉÅ ÏãúÍ∞Ñ: {all_time:.1f}Î∂Ñ")
        print("   ‚Üí Î™®Îì† Í∏∞Îä• Ìè¨Ìï®")
        options[str(option_num)] = all_models
        option_num += 1
        print()
        
        # 5. ÏÇ¨Ïö©Ïûê Ï†ïÏùò
        print(f"{option_num}. ÏÇ¨Ïö©Ïûê Ï†ïÏùò ÏÑ†ÌÉù")
        print("   ‚Üí ÏõêÌïòÎäî StepÎ≥ÑÎ°ú ÏÑ†ÌÉù")
        options[str(option_num)] = "custom"
        print()
        
        while True:
            choice = input(f"ÏÑ†ÌÉù (1-{option_num}): ").strip()
            if choice in options:
                if options[choice] == "custom":
                    return self.show_custom_selection_menu()
                else:
                    return options[choice]
            else:
                print(f"‚ùå ÏûòÎ™ªÎêú ÏÑ†ÌÉùÏûÖÎãàÎã§. 1-{option_num} Ï§ëÏóêÏÑú ÏÑ†ÌÉùÌïòÏÑ∏Ïöî.")
    
    def show_custom_selection_menu(self) -> List[str]:
        """ÏÇ¨Ïö©Ïûê Ï†ïÏùò ÏÑ†ÌÉù Î©îÎâ¥"""
        print("\nüìã StepÎ≥Ñ Î™®Îç∏ ÏÑ†ÌÉù:")
        
        step_groups = {}
        for model_name, model_info in self.verified_models.items():
            step = model_info["step"]
            if step not in step_groups:
                step_groups[step] = []
            step_groups[step].append(model_name)
        
        selected_models = []
        
        for step in sorted(step_groups.keys()):
            print(f"\nüéØ {step.upper()} Î™®Îç∏Îì§:")
            
            step_models = step_groups[step]
            for i, model_name in enumerate(step_models, 1):
                model_info = self.verified_models[model_name]
                print(f"  {i}. {model_name}")
                print(f"     {model_info['description']} ({model_info['size']:.1f}MB)")
            
            if len(step_models) == 1:
                # ÌïòÎÇòÎøêÏù¥Î©¥ ÏûêÎèô ÏÑ†ÌÉù
                selected_models.extend(step_models)
                print(f"  ‚Üí ÏûêÎèô ÏÑ†ÌÉù: {step_models[0]}")
            else:
                # Ïó¨Îü¨ Í∞úÎ©¥ ÏÑ†ÌÉù
                while True:
                    choices = input(f"  ÏÑ†ÌÉù (1-{len(step_models)}, Ïó¨Îü¨Í∞ú Í∞ÄÎä•, Ïòà: 1,3): ").strip()
                    if not choices:
                        break
                    
                    try:
                        selected_indices = [int(x.strip()) - 1 for x in choices.split(',')]
                        for idx in selected_indices:
                            if 0 <= idx < len(step_models):
                                selected_models.append(step_models[idx])
                        break
                    except ValueError:
                        print("  ‚ùå ÏûòÎ™ªÎêú ÌòïÏãùÏûÖÎãàÎã§. Ïòà: 1,2,3")
        
        return list(set(selected_models))  # Ï§ëÎ≥µ Ï†úÍ±∞
    
    def create_model_info_file(self, downloaded_models: List[str]) -> None:
        """Îã§Ïö¥Î°úÎìúÎêú Î™®Îç∏ Ï†ïÎ≥¥ ÌååÏùº ÏÉùÏÑ±"""
        try:
            model_info = {
                "download_info": {
                    "timestamp": time.time(),
                    "version": "v5.0", 
                    "downloader": "WorkingModelDownloader",
                    "total_models": len(downloaded_models),
                    "total_size_mb": self.download_stats["total_size"]
                },
                "download_stats": self.download_stats,
                "downloaded_models": {}
            }
            
            for model_name in downloaded_models:
                if model_name in self.verified_models:
                    model_info["downloaded_models"][model_name] = {
                        "path": self.verified_models[model_name]["path"],
                        "size_mb": self.verified_models[model_name]["size"],
                        "description": self.verified_models[model_name]["description"],
                        "step": self.verified_models[model_name]["step"]
                    }
            
            info_file = self.base_dir / "downloaded_models_v5.json"
            with open(info_file, 'w', encoding='utf-8') as f:
                json.dump(model_info, f, indent=2, ensure_ascii=False)
            
            logger.info(f"üìã Î™®Îç∏ Ï†ïÎ≥¥ ÌååÏùº ÏÉùÏÑ±: {info_file}")
            
        except Exception as e:
            logger.error(f"‚ùå Î™®Îç∏ Ï†ïÎ≥¥ ÌååÏùº ÏÉùÏÑ± Ïã§Ìå®: {e}")
    
    def verify_downloads(self, selected_models: List[str]) -> Dict[str, bool]:
        """Îã§Ïö¥Î°úÎìúÎêú Î™®Îç∏Îì§ Í≤ÄÏ¶ù"""
        print("\nüîç Îã§Ïö¥Î°úÎìú Í≤ÄÏ¶ù Ï§ë...")
        
        verification_results = {}
        
        for model_name in selected_models:
            if model_name in self.verified_models:
                model_info = self.verified_models[model_name]
                filepath = self.base_dir / model_info["path"]
                
                if filepath.exists():
                    file_size = filepath.stat().st_size / (1024**2)
                    expected_size = model_info["size"]
                    
                    # ÌÅ¨Í∏∞ Í≤ÄÏ¶ù (80% Ïù¥ÏÉÅÏù¥Î©¥ Ïú†Ìö®)
                    is_valid = file_size >= expected_size * 0.8
                    verification_results[model_name] = is_valid
                    
                    status = "‚úÖ" if is_valid else "‚ùå"
                    print(f"  {status} {model_name} ({file_size:.1f}MB)")
                else:
                    verification_results[model_name] = False
                    print(f"  ‚ùå {model_name} (ÌååÏùº ÏóÜÏùå)")
        
        valid_count = sum(verification_results.values())
        total_count = len(verification_results)
        print(f"\nüìä Í≤ÄÏ¶ù Í≤∞Í≥º: {valid_count}/{total_count} Î™®Îç∏ Ïú†Ìö®")
        
        return verification_results
    
    def cleanup_temp_files(self) -> None:
        """ÏûÑÏãú ÌååÏùº Ï†ïÎ¶¨"""
        try:
            if self.temp_dir.exists():
                shutil.rmtree(self.temp_dir)
                logger.info("üßπ ÏûÑÏãú ÌååÏùº Ï†ïÎ¶¨ ÏôÑÎ£å")
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è ÏûÑÏãú ÌååÏùº Ï†ïÎ¶¨ Ïã§Ìå®: {e}")
    
    def run(self):
        """Î©îÏù∏ Ïã§Ìñâ Ìï®Ïàò"""
        print("üöÄ MyCloset AI - Ïã§Ï†ú ÏûëÎèôÌïòÎäî Î™®Îç∏ Îã§Ïö¥Î°úÎçî v5.0")
        print("‚úÖ Í≤ÄÏ¶ùÎêú URLÎì§Îßå ÏÇ¨Ïö©")
        print("üîÑ Ïã§Ìå® Ïãú ÎåÄÏ≤¥ ÏÜåÏä§ ÏûêÎèô Ï†ÑÌôò")
        print("üçé M3 Max 128GB ÏµúÏ†ÅÌôî")
        print("üêç conda ÌôòÍ≤Ω Ïö∞ÏÑ†")
        print("=" * 60)
        
        # conda ÌôòÍ≤Ω ÌôïÏù∏
        if not self.check_conda_environment():
            print("\n‚ö†Ô∏è conda ÌôòÍ≤Ω Î¨∏Ï†úÍ∞Ä ÏûàÏäµÎãàÎã§. Í≥ÑÏÜç ÏßÑÌñâÌïòÏãúÍ≤†ÏäµÎãàÍπå? (y/N): ", end="")
            if input().lower() != 'y':
                return
        
        # Î™®Îç∏ ÏÑ†ÌÉù
        selected_models = self.show_model_selection_menu()
        
        if not selected_models:
            print("‚ùå ÏÑ†ÌÉùÎêú Î™®Îç∏Ïù¥ ÏóÜÏäµÎãàÎã§.")
            return
        
        # Îã§Ïö¥Î°úÎìú ÌôïÏù∏
        total_size = sum(self.verified_models[model]["size"] for model in selected_models)
        estimated_time = total_size / 50.0  # 50MB/Î∂Ñ Í∞ÄÏ†ï
        
        print(f"\nüìã ÏÑ†ÌÉùÎêú Î™®Îç∏: {len(selected_models)}Í∞ú")
        print(f"üìä Ï¥ù ÌÅ¨Í∏∞: {total_size:.1f}MB")
        print(f"‚è±Ô∏è ÏòàÏÉÅ ÏãúÍ∞Ñ: {estimated_time:.1f}Î∂Ñ")
        print(f"üìÅ Ï†ÄÏû• ÏúÑÏπò: {self.base_dir}")
        
        confirm = input("\nÎã§Ïö¥Î°úÎìúÎ•º ÏãúÏûëÌïòÏãúÍ≤†ÏäµÎãàÍπå? (y/N): ").strip().lower()
        if confirm != 'y':
            print("‚ùå Îã§Ïö¥Î°úÎìúÍ∞Ä Ï∑®ÏÜåÎêòÏóàÏäµÎãàÎã§.")
            return
        
        # Îã§Ïö¥Î°úÎìú Ïã§Ìñâ
        print(f"\nüöÄ Îã§Ïö¥Î°úÎìú ÏãúÏûë! {len(selected_models)}Í∞ú Î™®Îç∏")
        start_time = time.time()
        
        try:
            # Î≥ëÎ†¨ Îã§Ïö¥Î°úÎìú (M3 MaxÏóêÏÑú 3Í∞ú ÎèôÏãú)
            self.download_models_parallel(selected_models, max_workers=3)
            
            # Í≤∞Í≥º ÌëúÏãú
            duration = time.time() - start_time
            
            print(f"\nüéâ Îã§Ïö¥Î°úÎìú ÏôÑÎ£å!")
            print(f"‚è±Ô∏è ÏÜåÏöî ÏãúÍ∞Ñ: {duration/60:.1f}Î∂Ñ")
            print(f"üìä ÌÜµÍ≥Ñ:")
            print(f"  - ÏãúÎèÑ: {self.download_stats['attempted']}Í∞ú")
            print(f"  - ÏÑ±Í≥µ: {self.download_stats['successful']}Í∞ú")
            print(f"  - Ïã§Ìå®: {self.download_stats['failed']}Í∞ú")
            print(f"  - Í±¥ÎÑàÎúÄ: {self.download_stats['skipped']}Í∞ú")
            print(f"  - Îã§Ïö¥Î°úÎìú ÌÅ¨Í∏∞: {self.download_stats['total_size']:.1f}MB")
            
            # Í≤ÄÏ¶ù
            verification_results = self.verify_downloads(selected_models)
            
            # Î™®Îç∏ Ï†ïÎ≥¥ ÌååÏùº ÏÉùÏÑ±
            successful_models = [
                model for model, is_valid in verification_results.items() if is_valid
            ]
            self.create_model_info_file(successful_models)
            
            # ÏÑ±Í≥µÎ•† Í≥ÑÏÇ∞
            success_rate = (self.download_stats['successful'] / max(self.download_stats['attempted'], 1)) * 100
            
            if success_rate >= 80:
                print(f"\n‚úÖ Îã§Ïö¥Î°úÎìú ÏÑ±Í≥µ! ÏÑ±Í≥µÎ•†: {success_rate:.1f}%")
                print("üîÑ Ïù¥Ï†ú ÏÑúÎ≤ÑÎ•º Ïû¨ÏãúÏûëÌïòÏÑ∏Ïöî:")
                print("  cd backend && python app/main.py")
            else:
                print(f"\n‚ö†Ô∏è ÏùºÎ∂Ä Îã§Ïö¥Î°úÎìú Ïã§Ìå®. ÏÑ±Í≥µÎ•†: {success_rate:.1f}%")
                print("üí° Ïã§Ìå®Ìïú Î™®Îç∏Îì§ÏùÄ ÎÇòÏ§ëÏóê Îã§Ïãú ÏãúÎèÑÌï† Ïàò ÏûàÏäµÎãàÎã§.")
                
        finally:
            # Ï†ïÎ¶¨
            self.cleanup_temp_files()

if __name__ == "__main__":
    try:
        downloader = WorkingModelDownloader()
        downloader.run()
    except KeyboardInterrupt:
        print("\n\n‚ùå ÏÇ¨Ïö©ÏûêÏóê ÏùòÌï¥ Ï§ëÎã®ÎêòÏóàÏäµÎãàÎã§.")
    except Exception as e:
        logger.error(f"‚ùå ÏòàÏÉÅÏπò Î™ªÌïú Ïò§Î•ò: {e}")
        print(f"‚ùå Ïò§Î•ò Î∞úÏÉù: {e}")
        print("üìã Î°úÍ∑∏ ÌååÏùºÏùÑ ÌôïÏù∏ÌïòÏÑ∏Ïöî: model_download_v5.log")