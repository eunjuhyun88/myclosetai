#!/bin/bash

# =============================================================================
# MyCloset AI - ì™„ì „ ëª¨ë¸ ì •ë¦¬ ìŠ¤í¬ë¦½íŠ¸
# ë‚¨ì€ ëª¨ë¸ ë””ë ‰í† ë¦¬ë“¤ì„ Stepë³„ë¡œ ì™„ì „íˆ ì •ë¦¬
# =============================================================================

set -e

# ìƒ‰ìƒ ì¶œë ¥
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
RED='\033[0;31m'
BLUE='\033[0;34m'
NC='\033[0m'

log_info() { echo -e "${BLUE}â„¹ï¸  $1${NC}"; }
log_success() { echo -e "${GREEN}âœ… $1${NC}"; }
log_warning() { echo -e "${YELLOW}âš ï¸  $1${NC}"; }
log_error() { echo -e "${RED}âŒ $1${NC}"; }

PROJECT_ROOT=$(pwd)
AI_MODELS_ROOT="$PROJECT_ROOT/ai_models"

echo "ğŸš€ MyCloset AI - ì™„ì „ ëª¨ë¸ ì •ë¦¬"
echo "======================================"
log_info "í”„ë¡œì íŠ¸ ë£¨íŠ¸: $PROJECT_ROOT"
log_info "AI ëª¨ë¸ ë£¨íŠ¸: $AI_MODELS_ROOT"
echo ""

# 1. í˜„ì¬ ë‚¨ì€ ëª¨ë¸ ë””ë ‰í† ë¦¬ í™•ì¸
echo "ğŸ“‹ í˜„ì¬ ë‚¨ì€ ëª¨ë¸ ë””ë ‰í† ë¦¬ë“¤:"
cd "$AI_MODELS_ROOT"

remaining_dirs=(
    "openpose"
    "Self-Correction-Human-Parsing"
    "SAM2"
    "StableVITON"
    "IDM-VTON"
    "OOTDiffusion"
    "clip-vit-base-patch32"
    "cloth_warping"
    "temp_downloads"
)

existing_dirs=()
for dir in "${remaining_dirs[@]}"; do
    if [ -d "$dir" ]; then
        size=$(du -sh "$dir" 2>/dev/null | cut -f1 || echo "N/A")
        echo "  ğŸ“ $dir ($size)"
        existing_dirs+=("$dir")
    fi
done

if [ ${#existing_dirs[@]} -eq 0 ]; then
    log_success "ëª¨ë“  ëª¨ë¸ì´ ì´ë¯¸ ì •ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤!"
    exit 0
fi

echo ""
log_warning "ì´ ${#existing_dirs[@]}ê°œ ë””ë ‰í† ë¦¬ë¥¼ ì´ë™í•©ë‹ˆë‹¤. ê³„ì†í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/N)"
read -r confirm

if [[ ! $confirm =~ ^[Yy]$ ]]; then
    log_info "ì‘ì—…ì´ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤."
    exit 0
fi

# 2. Stepë³„ ì´ë™ ì‹¤í–‰
echo ""
echo "ğŸ”„ Stepë³„ ëª¨ë¸ ì´ë™ ì‹œì‘..."

# Step 02: Pose Estimation
if [ -d "openpose" ]; then
    log_info "OpenPose â†’ step_02_pose_estimation/openpose/"
    mv "openpose" "step_02_pose_estimation/openpose/"
    log_success "OpenPose ì´ë™ ì™„ë£Œ"
fi

# Step 01: Human Parsing
if [ -d "Self-Correction-Human-Parsing" ]; then
    log_info "Self-Correction-Human-Parsing â†’ step_01_human_parsing/schp/"
    mv "Self-Correction-Human-Parsing" "step_01_human_parsing/schp/"
    log_success "Human Parsing ì´ë™ ì™„ë£Œ"
fi

# Step 03: Cloth Segmentation
if [ -d "SAM2" ]; then
    log_info "SAM2 â†’ step_03_cloth_segmentation/sam/"
    mv "SAM2" "step_03_cloth_segmentation/sam/"
    log_success "SAM2 ì´ë™ ì™„ë£Œ"
fi

# Step 06: Virtual Fitting
if [ -d "StableVITON" ]; then
    log_info "StableVITON â†’ step_06_virtual_fitting/stable_diffusion/"
    mv "StableVITON" "step_06_virtual_fitting/stable_diffusion/"
    log_success "StableVITON ì´ë™ ì™„ë£Œ"
fi

if [ -d "IDM-VTON" ]; then
    log_info "IDM-VTON â†’ step_06_virtual_fitting/alternatives/"
    mv "IDM-VTON" "step_06_virtual_fitting/alternatives/"
    log_success "IDM-VTON ì´ë™ ì™„ë£Œ"
fi

if [ -d "OOTDiffusion" ]; then
    log_info "OOTDiffusion â†’ step_06_virtual_fitting/ootdiffusion/"
    mv "OOTDiffusion" "step_06_virtual_fitting/ootdiffusion/"
    log_success "OOTDiffusion ì´ë™ ì™„ë£Œ"
fi

# Step 05: Cloth Warping
if [ -d "cloth_warping" ]; then
    log_info "cloth_warping â†’ step_05_cloth_warping/tom/"
    mv "cloth_warping" "step_05_cloth_warping/tom/"
    log_success "Cloth Warping ì´ë™ ì™„ë£Œ"
fi

# Auxiliary Models
if [ -d "clip-vit-base-patch32" ]; then
    log_info "clip-vit-base-patch32 â†’ auxiliary_models/clip/"
    mv "clip-vit-base-patch32" "auxiliary_models/clip/"
    log_success "CLIP ëª¨ë¸ ì´ë™ ì™„ë£Œ"
fi

# ê°œë³„ íŒŒì¼ë“¤ ì •ë¦¬
if [ -f "mps_optimization.py" ]; then
    log_info "mps_optimization.py â†’ auxiliary_models/"
    mv "mps_optimization.py" "auxiliary_models/"
    log_success "MPS ìµœì í™” íŒŒì¼ ì´ë™ ì™„ë£Œ"
fi

# ì„ì‹œ íŒŒì¼ ì •ë¦¬
if [ -d "temp_downloads" ]; then
    log_warning "temp_downloads ë””ë ‰í† ë¦¬ ì •ë¦¬ ì¤‘..."
    
    if [ "$(ls -A temp_downloads)" ]; then
        # ë¹„ì–´ìˆì§€ ì•Šìœ¼ë©´ backupìœ¼ë¡œ ì´ë™
        mv "temp_downloads" "backup_models/temp_downloads_$(date +%Y%m%d_%H%M%S)"
        log_info "temp_downloads â†’ backup_models/ (ë°±ì—…ë¨)"
    else
        # ë¹„ì–´ìˆìœ¼ë©´ ì‚­ì œ
        rmdir "temp_downloads"
        log_info "ë¹ˆ temp_downloads ë””ë ‰í† ë¦¬ ì‚­ì œ"
    fi
fi

# 3. ì‹¬ë³¼ë¦­ ë§í¬ ì •ë¦¬
echo ""
echo "ğŸ”— ì‹¬ë³¼ë¦­ ë§í¬ ì •ë¦¬ ì¤‘..."

# ëŠì–´ì§„ ì‹¬ë³¼ë¦­ ë§í¬ ì°¾ê¸° ë° ìˆ˜ì •
find . -type l ! -exec test -e {} \; -print 2>/dev/null | while read -r broken_link; do
    log_warning "ëŠì–´ì§„ ë§í¬ ë°œê²¬: $broken_link"
    rm "$broken_link"
    log_info "ëŠì–´ì§„ ë§í¬ ì œê±°: $broken_link"
done

# 4. checkpoints ë””ë ‰í† ë¦¬ ë‚´ìš© ë¶„ë¥˜
echo ""
echo "ğŸ“¦ checkpoints ë””ë ‰í† ë¦¬ ë‚´ìš© ë¶„ë¥˜ ì¤‘..."

if [ -d "checkpoints" ]; then
    cd "checkpoints"
    
    # ê° ì„œë¸Œë””ë ‰í† ë¦¬ë¥¼ í•´ë‹¹ Stepìœ¼ë¡œ ì´ë™
    declare -A checkpoint_mapping=(
        ["human_parsing"]="step_01_human_parsing/alternatives"
        ["pose_estimation"]="step_02_pose_estimation/alternatives" 
        ["cloth_segmentation"]="step_03_cloth_segmentation/alternatives"
        ["geometric_matching"]="step_04_geometric_matching/alternatives"
        ["cloth_warping"]="step_05_cloth_warping/alternatives"
        ["virtual_fitting"]="step_06_virtual_fitting/alternatives"
        ["post_processing"]="step_07_post_processing/alternatives"
        ["quality_assessment"]="step_08_quality_assessment/alternatives"
        ["depth_estimation"]="auxiliary_models"
        ["feature_extraction"]="auxiliary_models"
        ["step_02"]="step_02_pose_estimation/alternatives"
        ["step_05"]="step_05_cloth_warping/alternatives"
        ["step_07"]="step_07_post_processing/alternatives"
    )
    
    for checkpoint_dir in */; do
        checkpoint_dir=${checkpoint_dir%/}  # ë’¤ì˜ / ì œê±°
        
        if [[ -v checkpoint_mapping["$checkpoint_dir"] ]]; then
            target_path="../${checkpoint_mapping[$checkpoint_dir]}/$checkpoint_dir"
            
            if [ -d "$checkpoint_dir" ]; then
                log_info "checkpoints/$checkpoint_dir â†’ ${checkpoint_mapping[$checkpoint_dir]}/"
                
                # íƒ€ê²Ÿ ë””ë ‰í† ë¦¬ ìƒì„±
                mkdir -p "../${checkpoint_mapping[$checkpoint_dir]}"
                
                # ì´ë™
                mv "$checkpoint_dir" "$target_path"
                log_success "$checkpoint_dir ì´ë™ ì™„ë£Œ"
            fi
        else
            log_warning "ë¶„ë¥˜ë˜ì§€ ì•Šì€ ì²´í¬í¬ì¸íŠ¸: $checkpoint_dir"
        fi
    done
    
    # ê°œë³„ íŒŒì¼ë“¤ ì²˜ë¦¬
    if [ -f "model_metadata.json" ]; then
        mv "model_metadata.json" "../auxiliary_models/"
        log_info "model_metadata.json â†’ auxiliary_models/"
    fi
    
    cd ..
    
    # checkpoints ë””ë ‰í† ë¦¬ê°€ ë¹„ì–´ìˆìœ¼ë©´ ì œê±°
    if [ ! "$(ls -A checkpoints)" ]; then
        rmdir "checkpoints"
        log_info "ë¹ˆ checkpoints ë””ë ‰í† ë¦¬ ì œê±°"
    fi
fi

# 5. ê¸°íƒ€ ì •ë¦¬
echo ""
echo "ğŸ§¹ ê¸°íƒ€ íŒŒì¼ ì •ë¦¬ ì¤‘..."

# JSON íŒŒì¼ë“¤ ì •ë¦¬
if [ -f "enhanced_model_registry.json" ]; then
    mv "enhanced_model_registry.json" "auxiliary_models/"
    log_info "enhanced_model_registry.json â†’ auxiliary_models/"
fi

if [ -f "environment_enhanced.yml" ]; then
    mv "environment_enhanced.yml" "backup_models/"
    log_info "environment_enhanced.yml â†’ backup_models/"
fi

# 6. ìµœì¢… ê²€ì¦
echo ""
echo "ğŸ” ìµœì¢… ì •ë¦¬ ê²°ê³¼ ê²€ì¦..."

cd "$AI_MODELS_ROOT"

# Stepë³„ ëª¨ë¸ ìˆ˜ í™•ì¸
for step_dir in step_*/; do
    if [ -d "$step_dir" ]; then
        step_name=${step_dir%/}
        model_count=$(find "$step_dir" -type f \( -name "*.pth" -o -name "*.pt" -o -name "*.bin" \) 2>/dev/null | wc -l)
        dir_count=$(find "$step_dir" -mindepth 1 -maxdepth 1 -type d | wc -l)
        size=$(du -sh "$step_dir" 2>/dev/null | cut -f1 || echo "0B")
        
        if [ "$model_count" -gt 0 ] || [ "$dir_count" -gt 0 ]; then
            echo "  âœ… $step_name: $model_countê°œ ëª¨ë¸, $dir_countê°œ ì„œë¸Œë””ë ‰í† ë¦¬ ($size)"
        else
            echo "  âšª $step_name: ë¹„ì–´ìˆìŒ"
        fi
    fi
done

# auxiliary_models í™•ì¸
if [ -d "auxiliary_models" ]; then
    aux_size=$(du -sh "auxiliary_models" 2>/dev/null | cut -f1 || echo "0B")
    aux_count=$(find "auxiliary_models" -type f | wc -l)
    echo "  ğŸ“¦ auxiliary_models: $aux_countê°œ íŒŒì¼ ($aux_size)"
fi

# huggingface_cache í™•ì¸
if [ -d "huggingface_cache" ]; then
    hf_size=$(du -sh "huggingface_cache" 2>/dev/null | cut -f1 || echo "0B")
    echo "  ğŸ¤— huggingface_cache: ($hf_size)"
fi

# backup_models í™•ì¸  
if [ -d "backup_models" ]; then
    backup_size=$(du -sh "backup_models" 2>/dev/null | cut -f1 || echo "0B")
    backup_count=$(find "backup_models" -type f | wc -l)
    echo "  ğŸ’¾ backup_models: $backup_countê°œ íŒŒì¼ ($backup_size)"
fi

# 7. ê²½ë¡œ ì„¤ì • íŒŒì¼ ì—…ë°ì´íŠ¸
echo ""
echo "âš™ï¸ ê²½ë¡œ ì„¤ì • íŒŒì¼ ì—…ë°ì´íŠ¸ ì¤‘..."

# Python ê²½ë¡œ ì„¤ì • íŒŒì¼ ì¬ìƒì„±
cat > "$PROJECT_ROOT/backend/app/core/unified_model_paths.py" << 'EOF'
# app/core/unified_model_paths.py
"""
MyCloset AI - í†µí•©ëœ Stepë³„ ëª¨ë¸ ê²½ë¡œ ì„¤ì • (ì™„ì „ ì •ë¦¬ ì™„ë£Œ)
ìµœì¢… ì—…ë°ì´íŠ¸: $(date +'%Y-%m-%d %H:%M:%S')
"""

from pathlib import Path
from typing import Dict, List, Optional

# í”„ë¡œì íŠ¸ ë£¨íŠ¸
PROJECT_ROOT = Path(__file__).parent.parent.parent.parent
AI_MODELS_ROOT = PROJECT_ROOT / "ai_models"

# Stepë³„ í‘œì¤€ ê²½ë¡œ
STEP_MODEL_PATHS = {
    "step_01_human_parsing": AI_MODELS_ROOT / "step_01_human_parsing",
    "step_02_pose_estimation": AI_MODELS_ROOT / "step_02_pose_estimation", 
    "step_03_cloth_segmentation": AI_MODELS_ROOT / "step_03_cloth_segmentation",
    "step_04_geometric_matching": AI_MODELS_ROOT / "step_04_geometric_matching",
    "step_05_cloth_warping": AI_MODELS_ROOT / "step_05_cloth_warping",
    "step_06_virtual_fitting": AI_MODELS_ROOT / "step_06_virtual_fitting",
    "step_07_post_processing": AI_MODELS_ROOT / "step_07_post_processing",
    "step_08_quality_assessment": AI_MODELS_ROOT / "step_08_quality_assessment",
    "auxiliary_models": AI_MODELS_ROOT / "auxiliary_models",
    "huggingface_cache": AI_MODELS_ROOT / "huggingface_cache",
    "backup_models": AI_MODELS_ROOT / "backup_models",
    "experimental_models": AI_MODELS_ROOT / "experimental_models"
}

# ì‹¤ì œ ëª¨ë¸ ìœ„ì¹˜ ë§¤í•‘ (ì™„ì „ ì •ë¦¬ ì™„ë£Œ ë²„ì „)
ACTUAL_MODEL_LOCATIONS = {
    # Step 01: Human Parsing
    "human_parsing": {
        "schp": STEP_MODEL_PATHS["step_01_human_parsing"] / "schp",
        "graphonomy": STEP_MODEL_PATHS["step_01_human_parsing"] / "graphonomy", 
        "densepose": STEP_MODEL_PATHS["step_01_human_parsing"] / "densepose"
    },
    
    # Step 02: Pose Estimation
    "pose_estimation": {
        "openpose": STEP_MODEL_PATHS["step_02_pose_estimation"] / "openpose",
        "mediapipe": STEP_MODEL_PATHS["step_02_pose_estimation"] / "mediapipe",
        "hrnet": STEP_MODEL_PATHS["step_02_pose_estimation"] / "hrnet"
    },
    
    # Step 03: Cloth Segmentation
    "cloth_segmentation": {
        "u2net": STEP_MODEL_PATHS["step_03_cloth_segmentation"] / "u2net",
        "sam": STEP_MODEL_PATHS["step_03_cloth_segmentation"] / "sam",
        "rembg": STEP_MODEL_PATHS["step_03_cloth_segmentation"] / "rembg"
    },
    
    # Step 04: Geometric Matching
    "geometric_matching": {
        "gmm": STEP_MODEL_PATHS["step_04_geometric_matching"] / "gmm",
        "tps": STEP_MODEL_PATHS["step_04_geometric_matching"] / "tps"
    },
    
    # Step 05: Cloth Warping
    "cloth_warping": {
        "tom": STEP_MODEL_PATHS["step_05_cloth_warping"] / "tom"
    },
    
    # Step 06: Virtual Fitting
    "virtual_fitting": {
        "ootdiffusion": STEP_MODEL_PATHS["step_06_virtual_fitting"] / "ootdiffusion",
        "stable_diffusion": STEP_MODEL_PATHS["step_06_virtual_fitting"] / "stable_diffusion",
        "hrviton": STEP_MODEL_PATHS["step_06_virtual_fitting"] / "hrviton",
        "idm_vton": STEP_MODEL_PATHS["step_06_virtual_fitting"] / "alternatives"
    },
    
    # Auxiliary Models  
    "auxiliary": {
        "clip": STEP_MODEL_PATHS["auxiliary_models"] / "clip",
        "sam": STEP_MODEL_PATHS["auxiliary_models"] / "sam",
        "vae": STEP_MODEL_PATHS["auxiliary_models"] / "vae",
        "text_encoders": STEP_MODEL_PATHS["auxiliary_models"] / "text_encoders"
    }
}

def get_step_path(step_name: str) -> Optional[Path]:
    """Step ì´ë¦„ìœ¼ë¡œ ê²½ë¡œ ë°˜í™˜"""
    return STEP_MODEL_PATHS.get(step_name)

def get_model_path(category: str, model_type: str) -> Optional[Path]:
    """ì¹´í…Œê³ ë¦¬ì™€ ëª¨ë¸ íƒ€ì…ìœ¼ë¡œ ì‹¤ì œ ê²½ë¡œ ë°˜í™˜"""
    if category in ACTUAL_MODEL_LOCATIONS:
        return ACTUAL_MODEL_LOCATIONS[category].get(model_type)
    return None

def get_available_models(step_name: str) -> List[Path]:
    """íŠ¹ì • Stepì˜ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ íŒŒì¼ë“¤ ë°˜í™˜"""
    step_path = get_step_path(step_name)
    if not step_path or not step_path.exists():
        return []
    
    model_files = []
    for pattern in ["*.pth", "*.pt", "*.bin", "*.safetensors"]:
        model_files.extend(step_path.glob(f"**/{pattern}"))
    
    return sorted(model_files)

def get_all_model_files() -> Dict[str, List[Path]]:
    """ëª¨ë“  Stepì˜ ëª¨ë¸ íŒŒì¼ë“¤ ë°˜í™˜"""
    all_models = {}
    for step_name in STEP_MODEL_PATHS.keys():
        all_models[step_name] = get_available_models(step_name)
    
    return all_models

# í†µí•© ì •ë³´ (ì™„ì „ ì •ë¦¬ ì™„ë£Œ)
INTEGRATION_INFO = {
    "integration_date": "$(date +'%Y-%m-%d %H:%M:%S')",
    "total_steps": len(STEP_MODEL_PATHS),
    "ai_models_root": str(AI_MODELS_ROOT),
    "integration_method": "step_based_classification_complete",
    "cleanup_status": "ì™„ì „ì •ë¦¬ì™„ë£Œ",
    "actual_model_locations": True
}
EOF

echo ""
echo "ğŸ‰ MyCloset AI ëª¨ë¸ ì™„ì „ ì •ë¦¬ ì™„ë£Œ!"
echo "====================================="
log_success "âœ… ëª¨ë“  ëª¨ë¸ì´ Stepë³„ë¡œ ì²´ê³„ì ìœ¼ë¡œ ì •ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤"
log_success "âœ… HuggingFace ìºì‹œëŠ” ê·¸ëŒ€ë¡œ ìœ ì§€ë˜ì—ˆìŠµë‹ˆë‹¤"
log_success "âœ… ì‹¬ë³¼ë¦­ ë§í¬ê°€ ì •ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤"  
log_success "âœ… ê²½ë¡œ ì„¤ì • íŒŒì¼ì´ ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤"

echo ""
echo "ğŸ“ ìµœì¢… ì •ë¦¬ëœ êµ¬ì¡°:"
echo "  ai_models/"
echo "  â”œâ”€â”€ step_01_human_parsing/schp/          (Self-Correction-Human-Parsing)"
echo "  â”œâ”€â”€ step_02_pose_estimation/openpose/    (OpenPose)" 
echo "  â”œâ”€â”€ step_03_cloth_segmentation/sam/      (SAM2)"
echo "  â”œâ”€â”€ step_05_cloth_warping/tom/           (cloth_warping)"
echo "  â”œâ”€â”€ step_06_virtual_fitting/"
echo "  â”‚   â”œâ”€â”€ ootdiffusion/                    (OOTDiffusion)"
echo "  â”‚   â”œâ”€â”€ stable_diffusion/                (StableVITON)"
echo "  â”‚   â””â”€â”€ alternatives/                    (IDM-VTON)"
echo "  â”œâ”€â”€ auxiliary_models/clip/               (clip-vit-base-patch32)"
echo "  â”œâ”€â”€ huggingface_cache/                   (ê¸°ì¡´ ìœ ì§€)"
echo "  â””â”€â”€ backup_models/                       (ë°±ì—… íŒŒì¼ë“¤)"

echo ""
echo "ğŸš€ ë‹¤ìŒ ë‹¨ê³„:"
echo "1. ModelLoaderì—ì„œ ìƒˆ ê²½ë¡œ êµ¬ì¡° ì‚¬ìš©"
echo "2. ê° Step í´ë˜ìŠ¤ ê²½ë¡œ ì—…ë°ì´íŠ¸"
echo "3. AI íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"

echo ""
log_info "ì™„ì „ ì •ë¦¬ ì™„ë£Œ: $(date +'%Y-%m-%d %H:%M:%S')"