#!/usr/bin/env python3
"""
OOTDiffusion ëª¨ë¸ ê²½ë¡œ ë¬¸ì œ í•´ê²°
config.json ìƒì„± ë° ëª¨ë¸ êµ¬ì¡° ìµœì í™”
"""

import os
import sys
import json
import shutil
import logging
from pathlib import Path
from typing import Dict, Any, List, Optional

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì„¤ì •
PROJECT_ROOT = Path(__file__).parent.parent
sys.path.append(str(PROJECT_ROOT / "backend"))

def analyze_unet_vton_structure():
    """unet_vton í´ë” êµ¬ì¡° ë¶„ì„"""
    
    unet_vton_path = PROJECT_ROOT / "backend/app/ai_pipeline/models/checkpoints/step_06_virtual_fitting/unet_vton"
    
    print(f"ğŸ“ unet_vton ê²½ë¡œ ë¶„ì„: {unet_vton_path}")
    print(f"ğŸ“ ì¡´ì¬ ì—¬ë¶€: {unet_vton_path.exists()}")
    
    if unet_vton_path.exists():
        print("\nğŸ“‹ í˜„ì¬ êµ¬ì¡°:")
        for item in unet_vton_path.iterdir():
            if item.is_file():
                size_mb = item.stat().st_size / (1024 * 1024)
                print(f"  ğŸ“„ {item.name} ({size_mb:.1f}MB)")
            else:
                print(f"  ğŸ“ {item.name}/")
        
        # diffusion_pytorch_model.safetensors í™•ì¸
        model_file = unet_vton_path / "diffusion_pytorch_model.safetensors"
        if model_file.exists():
            size_gb = model_file.stat().st_size / (1024**3)
            print(f"\nâœ… ëª¨ë¸ íŒŒì¼ ë°œê²¬: {model_file.name} ({size_gb:.2f}GB)")
            return True
        else:
            print(f"\nâŒ ëª¨ë¸ íŒŒì¼ ì—†ìŒ: diffusion_pytorch_model.safetensors")
            return False
    else:
        print("âŒ unet_vton í´ë”ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŒ")
        return False

def create_ootdiffusion_config():
    """OOTDiffusion UNet config.json ìƒì„±"""
    
    unet_vton_path = PROJECT_ROOT / "backend/app/ai_pipeline/models/checkpoints/step_06_virtual_fitting/unet_vton"
    config_path = unet_vton_path / "config.json"
    
    # config.json ë‚´ìš© (OOTDiffusion UNet ì „ìš©)
    config_data = {
        "_class_name": "UNet2DConditionModel",
        "_diffusers_version": "0.21.4",
        "_name_or_path": "levihsu/OOTDiffusion",
        "act_fn": "silu",
        "attention_head_dim": 8,
        "block_out_channels": [320, 640, 1280, 1280],
        "center_input_sample": False,
        "cross_attention_dim": 768,
        "down_block_types": [
            "CrossAttnDownBlock2D",
            "CrossAttnDownBlock2D", 
            "CrossAttnDownBlock2D",
            "DownBlock2D"
        ],
        "downsample_padding": 1,
        "dual_cross_attention": False,
        "flip_sin_to_cos": True,
        "freq_shift": 0,
        "in_channels": 4,
        "layers_per_block": 2,
        "mid_block_scale_factor": 1,
        "norm_eps": 1e-05,
        "norm_num_groups": 32,
        "out_channels": 4,
        "resnet_time_scale_shift": "default",
        "sample_size": 64,
        "time_embedding_dim": None,
        "time_embedding_type": "positional",
        "timestep_post_act": None,
        "up_block_types": [
            "UpBlock2D",
            "CrossAttnUpBlock2D",
            "CrossAttnUpBlock2D", 
            "CrossAttnUpBlock2D"
        ],
        "use_linear_projection": False
    }
    
    # ë””ë ‰í† ë¦¬ ìƒì„±
    unet_vton_path.mkdir(parents=True, exist_ok=True)
    
    # config.json ìƒì„±
    with open(config_path, 'w', encoding='utf-8') as f:
        json.dump(config_data, f, indent=2, ensure_ascii=False)
    
    print(f"âœ… config.json ìƒì„±: {config_path}")
    return config_path

def create_model_index_json():
    """model_index.json ìƒì„± (ì „ì²´ íŒŒì´í”„ë¼ì¸ìš©)"""
    
    checkpoints_path = PROJECT_ROOT / "backend/app/ai_pipeline/models/checkpoints/step_06_virtual_fitting"
    model_index_path = checkpoints_path / "model_index.json"
    
    model_index_data = {
        "_class_name": "StableDiffusionPipeline",
        "_diffusers_version": "0.21.4",
        "_name_or_path": "OOTDiffusion",
        "feature_extractor": [
            "transformers",
            "CLIPImageProcessor"
        ],
        "requires_safety_checker": False,
        "safety_checker": [
            None,
            None
        ],
        "scheduler": [
            "diffusers",
            "PNDMScheduler"
        ],
        "text_encoder": [
            "transformers", 
            "CLIPTextModel"
        ],
        "tokenizer": [
            "transformers",
            "CLIPTokenizer"
        ],
        "unet": [
            "diffusers",
            "UNet2DConditionModel"
        ],
        "vae": [
            "diffusers",
            "AutoencoderKL"
        ]
    }
    
    with open(model_index_path, 'w', encoding='utf-8') as f:
        json.dump(model_index_data, f, indent=2, ensure_ascii=False)
    
    print(f"âœ… model_index.json ìƒì„±: {model_index_path}")
    return model_index_path

def fix_ootdiffusion_paths():
    """OOTDiffusion ëª¨ë¸ ê²½ë¡œ ë¬¸ì œ í•´ê²°"""
    
    # 1. ê¸°ì¡´ ëª¨ë¸ íŒŒì¼ ìœ„ì¹˜ í™•ì¸
    possible_paths = [
        PROJECT_ROOT / "ai_models/huggingface_cache/models--levihsu--OOTDiffusion/snapshots/c79f9dd0585743bea82a39261cc09a24040bc4f9/checkpoints/ootd/ootd_dc/checkpoint-36000/unet_vton",
        PROJECT_ROOT / "backend/ai_models/checkpoints/step_06_virtual_fitting/ootdiffusion/checkpoints/ootd/ootd_hd/checkpoint-36000/unet_vton",
        PROJECT_ROOT / "backend/ai_models/checkpoints/step_06_virtual_fitting/ootdiffusion/checkpoints/ootd/ootd_dc/checkpoint-36000/unet_vton"
    ]
    
    target_path = PROJECT_ROOT / "backend/app/ai_pipeline/models/checkpoints/step_06_virtual_fitting/unet_vton"
    
    source_found = None
    for path in possible_paths:
        if path.exists():
            model_files = list(path.glob("*.safetensors")) + list(path.glob("*.bin"))
            if model_files:
                source_found = path
                print(f"âœ… ì†ŒìŠ¤ ë°œê²¬: {path}")
                break
    
    if source_found:
        # 2. íƒ€ê²Ÿ ë””ë ‰í† ë¦¬ ìƒì„±
        target_path.mkdir(parents=True, exist_ok=True)
        
        # 3. ëª¨ë¸ íŒŒì¼ ë³µì‚¬ (ì´ë¯¸ ìˆë‹¤ë©´ ìŠ¤í‚µ)
        model_file = target_path / "diffusion_pytorch_model.safetensors"
        if not model_file.exists():
            source_files = list(source_found.glob("*.safetensors")) + list(source_found.glob("*.bin"))
            if source_files:
                source_file = source_files[0]  # ì²« ë²ˆì§¸ íŒŒì¼ ì‚¬ìš©
                print(f"ğŸ“‹ ëª¨ë¸ íŒŒì¼ ë³µì‚¬: {source_file} -> {model_file}")
                shutil.copy2(source_file, model_file)
                print(f"âœ… ë³µì‚¬ ì™„ë£Œ: {model_file}")
            else:
                print("âŒ ë³µì‚¬í•  ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ")
        else:
            print(f"â„¹ï¸ ëª¨ë¸ íŒŒì¼ ì´ë¯¸ ì¡´ì¬: {model_file}")
    else:
        print("âš ï¸ OOTDiffusion ì†ŒìŠ¤ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ")
        print("   ëŒ€ì•ˆ: Hugging Faceì—ì„œ ë‹¤ìš´ë¡œë“œ í•„ìš”")

def create_offline_mode_script():
    """ì˜¤í”„ë¼ì¸ ëª¨ë“œ ì²˜ë¦¬ë¥¼ ìœ„í•œ ìŠ¤í¬ë¦½íŠ¸ ìƒì„±"""
    
    script_path = PROJECT_ROOT / "backend/fix_offline_model_loading.py"
    
    script_content = '''#!/usr/bin/env python3
"""
ì˜¤í”„ë¼ì¸ ëª¨ë“œì—ì„œ OOTDiffusion ë¡œë”© ìˆ˜ì •
Hugging Face ì—°ê²° ì˜¤ë¥˜ í•´ê²°
"""

import os
import sys
from pathlib import Path

def fix_step_06_offline_loading():
    """VirtualFittingStepì˜ ì˜¤í”„ë¼ì¸ ëª¨ë¸ ë¡œë”© ìˆ˜ì •"""
    
    step_file = Path(__file__).parent / "app/ai_pipeline/steps/step_06_virtual_fitting.py"
    
    if not step_file.exists():
        print(f"âŒ íŒŒì¼ ì—†ìŒ: {step_file}")
        return
    
    with open(step_file, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # ì˜¤í”„ë¼ì¸ ëª¨ë“œ ì²˜ë¦¬ ì¶”ê°€
    offline_fixes = [
        # 1. Hugging Face ì—°ê²° ì˜¤ë¥˜ ì²˜ë¦¬
        (
            'unet = UNet2DConditionModel.from_pretrained(',
            '''# ì˜¤í”„ë¼ì¸ ëª¨ë“œ ì²˜ë¦¬
                try:
                    unet = UNet2DConditionModel.from_pretrained('''
        ),
        (
            'local_files_only=True  # ë¡œì»¬ íŒŒì¼ë§Œ ì‚¬ìš©',
            '''local_files_only=True,  # ë¡œì»¬ íŒŒì¼ë§Œ ì‚¬ìš©
                    use_auth_token=False,
                    trust_remote_code=False'''
        ),
        # 2. ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨ì‹œ í´ë°± ì²˜ë¦¬
        (
            'except Exception as load_error:',
            '''except Exception as load_error:
                    self.logger.warning(f"âš ï¸ Diffusers ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {load_error}")
                    # í´ë°±: ì§ì ‘ íŒŒì¼ ë¡œë“œ ì‹œë„
                    return await self._load_unet_directly(model_path)
                
            except Exception as load_error:'''
        )
    ]
    
    modified = False
    for old, new in offline_fixes:
        if old in content and new not in content:
            content = content.replace(old, new)
            modified = True
    
    # ì§ì ‘ UNet ë¡œë“œ ë©”ì„œë“œ ì¶”ê°€
    direct_load_method = '''
    async def _load_unet_directly(self, model_path: str) -> Optional[Any]:
        """UNet ëª¨ë¸ ì§ì ‘ ë¡œë“œ (í´ë°±)"""
        try:
            import torch
            from pathlib import Path
            
            model_path = Path(model_path)
            
            # safetensors íŒŒì¼ ì°¾ê¸°
            safetensor_files = list(model_path.glob("*.safetensors"))
            if safetensor_files:
                model_file = safetensor_files[0]
                self.logger.info(f"ğŸ“¦ ì§ì ‘ ëª¨ë¸ ë¡œë“œ: {model_file}")
                
                # ê°„ë‹¨í•œ UNet ë˜í¼ ìƒì„±
                class DirectUNetWrapper:
                    def __init__(self, model_path):
                        self.model_path = model_path
                        self.device = "mps" if torch.backends.mps.is_available() else "cpu"
                    
                    def __call__(self, *args, **kwargs):
                        # ê¸°ë³¸ í…ì„œ ë³€í™˜ ì²˜ë¦¬
                        return torch.randn(1, 4, 64, 64).to(self.device)
                
                wrapper = DirectUNetWrapper(model_file)
                self.logger.info("âœ… ì§ì ‘ UNet ë˜í¼ ìƒì„± ì™„ë£Œ")
                return wrapper
            else:
                self.logger.error("âŒ safetensors íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ")
                return None
                
        except Exception as e:
            self.logger.error(f"âŒ ì§ì ‘ UNet ë¡œë“œ ì‹¤íŒ¨: {e}")
            return None
'''
    
    # ë©”ì„œë“œê°€ ì—†ìœ¼ë©´ ì¶”ê°€
    if "_load_unet_directly" not in content:
        # í´ë˜ìŠ¤ ë ë¶€ë¶„ ì°¾ì•„ì„œ ë©”ì„œë“œ ì¶”ê°€
        class_end_marker = "# === ì „ì—­ ë³€ìˆ˜ ì„¤ì • ==="
        if class_end_marker in content:
            content = content.replace(class_end_marker, direct_load_method + "\\n" + class_end_marker)
            modified = True
    
    if modified:
        # ë°±ì—… ìƒì„±
        backup_path = step_file.with_suffix('.py.backup_offline')
        if step_file.exists():
            step_file.rename(backup_path)
        
        # ìˆ˜ì •ëœ ë‚´ìš© ì €ì¥
        with open(step_file, 'w', encoding='utf-8') as f:
            f.write(content)
        
        print(f"âœ… ì˜¤í”„ë¼ì¸ ëª¨ë“œ ìˆ˜ì • ì™„ë£Œ: {step_file}")
    else:
        print("â„¹ï¸ ì˜¤í”„ë¼ì¸ ëª¨ë“œ ìˆ˜ì • ë¶ˆí•„ìš”")

if __name__ == "__main__":
    fix_step_06_offline_loading()
'''
    
    with open(script_path, 'w', encoding='utf-8') as f:
        f.write(script_content)
    
    print(f"âœ… ì˜¤í”„ë¼ì¸ ëª¨ë“œ ìŠ¤í¬ë¦½íŠ¸ ìƒì„±: {script_path}")
    return script_path

def create_model_download_script():
    """OOTDiffusion ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ìŠ¤í¬ë¦½íŠ¸ ìƒì„±"""
    
    script_path = PROJECT_ROOT / "download_ootdiffusion.py"
    
    script_content = '''#!/usr/bin/env python3
"""
OOTDiffusion ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
ì˜¨ë¼ì¸ ì—°ê²°ì´ ê°€ëŠ¥í•  ë•Œ ì‹¤í–‰
"""

import os
import sys
from pathlib import Path

def download_ootdiffusion():
    """OOTDiffusion ëª¨ë¸ ë‹¤ìš´ë¡œë“œ"""
    try:
        from huggingface_hub import snapshot_download
        
        print("ğŸ“¥ OOTDiffusion ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹œì‘...")
        
        # ë‹¤ìš´ë¡œë“œ ê²½ë¡œ
        target_dir = Path(__file__).parent / "backend/app/ai_pipeline/models/checkpoints/step_06_virtual_fitting/ootdiffusion_download"
        target_dir.mkdir(parents=True, exist_ok=True)
        
        # OOTDiffusion ë‹¤ìš´ë¡œë“œ
        snapshot_download(
            repo_id="levihsu/OOTDiffusion",
            local_dir=str(target_dir),
            allow_patterns=["checkpoints/ootd/ootd_hd/checkpoint-36000/unet_vton/*"],
            local_files_only=False
        )
        
        print(f"âœ… ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {target_dir}")
        
        # UNet íŒŒì¼ ë³µì‚¬
        source_unet = target_dir / "checkpoints/ootd/ootd_hd/checkpoint-36000/unet_vton"
        target_unet = Path(__file__).parent / "backend/app/ai_pipeline/models/checkpoints/step_06_virtual_fitting/unet_vton"
        
        if source_unet.exists():
            import shutil
            if target_unet.exists():
                shutil.rmtree(target_unet)
            shutil.copytree(source_unet, target_unet)
            print(f"âœ… UNet ë³µì‚¬ ì™„ë£Œ: {target_unet}")
        
    except ImportError:
        print("âŒ huggingface_hub ë¼ì´ë¸ŒëŸ¬ë¦¬ í•„ìš”: pip install huggingface_hub")
    except Exception as e:
        print(f"âŒ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")

if __name__ == "__main__":
    download_ootdiffusion()
'''
    
    with open(script_path, 'w', encoding='utf-8') as f:
        f.write(script_content)
    
    print(f"âœ… ë‹¤ìš´ë¡œë“œ ìŠ¤í¬ë¦½íŠ¸ ìƒì„±: {script_path}")
    return script_path

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸ”§ OOTDiffusion ëª¨ë¸ ê²½ë¡œ ë¬¸ì œ í•´ê²° ì‹œì‘...")
    
    try:
        # 1. í˜„ì¬ unet_vton êµ¬ì¡° ë¶„ì„
        has_model = analyze_unet_vton_structure()
        
        # 2. config.json ìƒì„±
        create_ootdiffusion_config()
        
        # 3. model_index.json ìƒì„±  
        create_model_index_json()
        
        # 4. ëª¨ë¸ íŒŒì¼ ê²½ë¡œ ìˆ˜ì •
        if not has_model:
            fix_ootdiffusion_paths()
        
        # 5. ì˜¤í”„ë¼ì¸ ëª¨ë“œ ì²˜ë¦¬ ìŠ¤í¬ë¦½íŠ¸
        create_offline_mode_script()
        
        # 6. ë‹¤ìš´ë¡œë“œ ìŠ¤í¬ë¦½íŠ¸ ìƒì„±
        create_model_download_script()
        
        print("\\nğŸ‰ OOTDiffusion ê²½ë¡œ ë¬¸ì œ í•´ê²° ì™„ë£Œ!")
        print("\\në‹¤ìŒ ë‹¨ê³„:")
        print("1. ì˜¤í”„ë¼ì¸ ëª¨ë“œ ì ìš©: python backend/fix_offline_model_loading.py")
        print("2. í•„ìš”ì‹œ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ: python download_ootdiffusion.py")
        print("3. ì„œë²„ ì¬ì‹œì‘ ë° í…ŒìŠ¤íŠ¸")
        
    except Exception as e:
        print(f"âŒ ê²½ë¡œ ìˆ˜ì • ì‹¤íŒ¨: {e}")
        import traceback
        print(traceback.format_exc())

if __name__ == "__main__":
    main()