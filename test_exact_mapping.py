#!/usr/bin/env python3
"""
ğŸ” Auto Detectorê°€ ê²½ë¡œë¥¼ ì •í™•íˆ ì°¾ì•„ì„œ ModelLoaderì— ì œëŒ€ë¡œ ì—°ë™í•˜ëŠ”ì§€ í™•ì¸
"""

import os
import sys
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì„¤ì •
project_root = Path(__file__).parent.parent.parent.parent
sys.path.insert(0, str(project_root))
sys.path.insert(0, str(project_root / "backend"))

print("ğŸ” Auto Detector ê²½ë¡œ ë§¤í•‘ ì •í™•ì„± í…ŒìŠ¤íŠ¸...")
print(f"ğŸ“ í”„ë¡œì íŠ¸ ë£¨íŠ¸: {project_root}")
print("=" * 60)

def test_step1_auto_detector_finds_models():
    """1ë‹¨ê³„: Auto Detectorê°€ ëª¨ë¸ë“¤ì„ ì°¾ëŠ”ì§€ í™•ì¸"""
    
    print("ğŸ” 1ë‹¨ê³„: Auto Detector ëª¨ë¸ íƒì§€ í…ŒìŠ¤íŠ¸...")
    
    try:
        from backend.app.ai_pipeline.utils.auto_model_detector import (
            create_real_world_detector
        )
        
        detector = create_real_world_detector(
            enable_pytorch_validation=True,
            max_workers=1  # ì•ˆì „í•œ ë‹¨ì¼ ì›Œì»¤
        )
        
        detected_models = detector.detect_all_models(
            force_rescan=True,  # ê°•ì œ ì¬ìŠ¤ìº”
            min_confidence=0.3
        )
        
        if detected_models:
            print(f"âœ… Auto Detector ì„±ê³µ: {len(detected_models)}ê°œ ëª¨ë¸ íƒì§€")
            
            # ê²½ë¡œ ì •í™•ì„± í™•ì¸
            print(f"\nğŸ“ íƒì§€ëœ ëª¨ë¸ ê²½ë¡œ í™•ì¸:")
            
            for i, (name, model) in enumerate(detected_models.items(), 1):
                path_exists = model.path.exists()
                path_readable = os.access(model.path, os.R_OK) if path_exists else False
                
                print(f"   {i}. {name}")
                print(f"      ğŸ“ ê²½ë¡œ: {model.path}")
                print(f"      âœ… ì¡´ì¬: {'YES' if path_exists else 'NO'}")
                print(f"      âœ… ì½ê¸°: {'YES' if path_readable else 'NO'}")
                print(f"      ğŸ“Š í¬ê¸°: {model.file_size_mb:.1f}MB")
                print(f"      ğŸ¯ Step: {model.step_name}")
                print(f"      ğŸ” ì‹ ë¢°ë„: {model.confidence_score:.2f}")
                print(f"      âœ… ê²€ì¦: {'YES' if model.pytorch_valid else 'NO'}")
                print("")
            
            return detected_models
        else:
            print("âŒ Auto Detector ì‹¤íŒ¨: ëª¨ë¸ì„ ì°¾ì§€ ëª»í•¨")
            return None
            
    except Exception as e:
        print(f"âŒ Auto Detector ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        return None

def test_step2_modelloader_integration(detected_models):
    """2ë‹¨ê³„: íƒì§€ëœ ëª¨ë¸ì´ ModelLoaderì— ì œëŒ€ë¡œ ì—°ë™ë˜ëŠ”ì§€ í™•ì¸"""
    
    print("ğŸ”§ 2ë‹¨ê³„: ModelLoader ì—°ë™ í…ŒìŠ¤íŠ¸...")
    
    if not detected_models:
        print("âŒ íƒì§€ëœ ëª¨ë¸ì´ ì—†ì–´ ì—°ë™ í…ŒìŠ¤íŠ¸ ë¶ˆê°€")
        return False
    
    try:
        from backend.app.ai_pipeline.utils.model_loader import ModelLoader
        
        # ModelLoader ì´ˆê¸°í™”
        loader = ModelLoader()
        print("âœ… ModelLoader ì´ˆê¸°í™” ì„±ê³µ")
        
        # íƒì§€ëœ ëª¨ë¸ë“¤ì„ ModelLoaderì— ë“±ë¡ ì‹œë„
        print(f"\nğŸ“ íƒì§€ëœ ëª¨ë¸ë“¤ ë“±ë¡ ì‹œë„...")
        
        registration_results = {}
        
        for model_name, detected_model in detected_models.items():
            try:
                # ModelLoader í˜•ì‹ìœ¼ë¡œ ë³€í™˜
                model_config = {
                    'name': model_name,
                    'type': str(detected_model.category.value),
                    'checkpoint_path': str(detected_model.path),
                    'device': 'auto',
                    'pytorch_validated': detected_model.pytorch_valid,
                    'file_size_mb': detected_model.file_size_mb,
                    'confidence_score': detected_model.confidence_score,
                    'step_name': detected_model.step_name,
                    'auto_detected': True
                }
                
                # ë“±ë¡ ì‹œë„
                success = loader.register_model(model_name, model_config)
                registration_results[model_name] = {
                    'success': success,
                    'config': model_config,
                    'detected_model': detected_model
                }
                
                status = "âœ…" if success else "âŒ"
                print(f"   {status} {model_name}: {'ì„±ê³µ' if success else 'ì‹¤íŒ¨'}")
                
            except Exception as e:
                registration_results[model_name] = {
                    'success': False,
                    'error': str(e),
                    'detected_model': detected_model
                }
                print(f"   âŒ {model_name}: ì˜¤ë¥˜ - {e}")
        
        # ë“±ë¡ ê²°ê³¼ í™•ì¸
        successful_registrations = sum(1 for r in registration_results.values() if r.get('success', False))
        print(f"\nğŸ“Š ë“±ë¡ ê²°ê³¼: {successful_registrations}/{len(detected_models)}ê°œ ì„±ê³µ")
        
        return registration_results
        
    except Exception as e:
        print(f"âŒ ModelLoader ì—°ë™ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        return None

def test_step3_step_mapping(registration_results):
    """3ë‹¨ê³„: Stepë³„ ëª¨ë¸ ë§¤í•‘ì´ ì œëŒ€ë¡œ ë˜ëŠ”ì§€ í™•ì¸"""
    
    print("ğŸ¯ 3ë‹¨ê³„: Stepë³„ ëª¨ë¸ ë§¤í•‘ í…ŒìŠ¤íŠ¸...")
    
    if not registration_results:
        print("âŒ ë“±ë¡ ê²°ê³¼ê°€ ì—†ì–´ ë§¤í•‘ í…ŒìŠ¤íŠ¸ ë¶ˆê°€")
        return False
    
    try:
        from backend.app.ai_pipeline.utils.model_loader import ModelLoader
        
        loader = ModelLoader()
        
        # Stepë³„ ëª¨ë¸ í™•ì¸
        step_mapping_results = {}
        
        required_steps = [
            'HumanParsingStep',
            'PoseEstimationStep', 
            'ClothSegmentationStep',
            'GeometricMatchingStep',
            'ClothWarpingStep',
            'VirtualFittingStep',
            'PostProcessingStep',
            'QualityAssessmentStep'
        ]
        
        print(f"\nğŸ¯ Stepë³„ ëª¨ë¸ ë§¤í•‘ í™•ì¸:")
        
        for step_name in required_steps:
            try:
                # Stepì— í•´ë‹¹í•˜ëŠ” ëª¨ë¸ë“¤ ì°¾ê¸°
                step_models = []
                
                for model_name, reg_result in registration_results.items():
                    if reg_result.get('success', False):
                        detected_model = reg_result['detected_model']
                        if detected_model.step_name == step_name:
                            step_models.append({
                                'name': model_name,
                                'path': str(detected_model.path),
                                'confidence': detected_model.confidence_score,
                                'validated': detected_model.pytorch_valid
                            })
                
                step_mapping_results[step_name] = step_models
                
                if step_models:
                    print(f"   âœ… {step_name}: {len(step_models)}ê°œ ëª¨ë¸")
                    for model in step_models:
                        status = "âœ…" if model['validated'] else "â“"
                        print(f"      {status} {model['name']} (ì‹ ë¢°ë„: {model['confidence']:.2f})")
                else:
                    print(f"   âŒ {step_name}: ëª¨ë¸ ì—†ìŒ")
                    
            except Exception as e:
                print(f"   âŒ {step_name}: ì˜¤ë¥˜ - {e}")
        
        # ë§¤í•‘ ê²°ê³¼ ìš”ì•½
        covered_steps = len([s for s, models in step_mapping_results.items() if models])
        coverage_percentage = (covered_steps / len(required_steps)) * 100
        
        print(f"\nğŸ“Š Step ë§¤í•‘ ê²°ê³¼:")
        print(f"   ğŸ¯ ì»¤ë²„ëœ Step: {covered_steps}/{len(required_steps)}ê°œ ({coverage_percentage:.1f}%)")
        
        return step_mapping_results
        
    except Exception as e:
        print(f"âŒ Step ë§¤í•‘ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        return None

def test_step4_actual_model_loading(step_mapping_results):
    """4ë‹¨ê³„: ì‹¤ì œë¡œ ëª¨ë¸ ë¡œë”©ì´ ê°€ëŠ¥í•œì§€ í™•ì¸"""
    
    print("ğŸ”¥ 4ë‹¨ê³„: ì‹¤ì œ ëª¨ë¸ ë¡œë”© í…ŒìŠ¤íŠ¸...")
    
    if not step_mapping_results:
        print("âŒ Step ë§¤í•‘ ê²°ê³¼ê°€ ì—†ì–´ ë¡œë”© í…ŒìŠ¤íŠ¸ ë¶ˆê°€")
        return False
    
    try:
        from backend.app.ai_pipeline.utils.model_loader import ModelLoader
        
        loader = ModelLoader()
        
        # ì‹¤ì œ ëª¨ë¸ ë¡œë”© ì‹œë„
        loading_results = {}
        
        # ê° Stepë³„ë¡œ ëª¨ë¸ ë¡œë”© ì‹œë„
        for step_name, models in step_mapping_results.items():
            if models:  # ëª¨ë¸ì´ ìˆëŠ” Stepë§Œ
                try:
                    print(f"\nğŸ”„ {step_name} ëª¨ë¸ ë¡œë”© ì‹œë„...")
                    
                    # ì²« ë²ˆì§¸ ëª¨ë¸ë¡œ ë¡œë”© ì‹œë„
                    first_model = models[0]
                    model_name = first_model['name']
                    
                    # ì‹¤ì œ ë¡œë”© ì‹œë„ (ì•ˆì „í•˜ê²Œ)
                    try:
                        loaded_model = loader.get_model(model_name)
                        if loaded_model:
                            loading_results[step_name] = {
                                'success': True,
                                'model_name': model_name,
                                'model_type': type(loaded_model).__name__
                            }
                            print(f"   âœ… {step_name}: {model_name} ë¡œë”© ì„±ê³µ")
                        else:
                            loading_results[step_name] = {
                                'success': False,
                                'model_name': model_name,
                                'error': 'None ë°˜í™˜ë¨'
                            }
                            print(f"   âŒ {step_name}: {model_name} ë¡œë”© ì‹¤íŒ¨ (None)")
                            
                    except Exception as load_error:
                        loading_results[step_name] = {
                            'success': False,
                            'model_name': model_name,
                            'error': str(load_error)
                        }
                        print(f"   âŒ {step_name}: {model_name} ë¡œë”© ì‹¤íŒ¨ - {load_error}")
                        
                except Exception as e:
                    loading_results[step_name] = {
                        'success': False,
                        'error': f"ì „ì²´ ì‹¤íŒ¨: {e}"
                    }
                    print(f"   âŒ {step_name}: ì „ì²´ ì‹¤íŒ¨ - {e}")
        
        # ë¡œë”© ê²°ê³¼ ìš”ì•½
        successful_loads = sum(1 for r in loading_results.values() if r.get('success', False))
        total_attempts = len(loading_results)
        
        print(f"\nğŸ“Š ëª¨ë¸ ë¡œë”© ê²°ê³¼:")
        print(f"   ğŸ”¥ ì„±ê³µí•œ ë¡œë”©: {successful_loads}/{total_attempts}ê°œ")
        
        if successful_loads > 0:
            print(f"   âœ… ì„±ê³µí•œ Stepë“¤:")
            for step_name, result in loading_results.items():
                if result.get('success', False):
                    print(f"      â€¢ {step_name}: {result['model_name']}")
        
        if successful_loads < total_attempts:
            print(f"   âŒ ì‹¤íŒ¨í•œ Stepë“¤:")
            for step_name, result in loading_results.items():
                if not result.get('success', False):
                    print(f"      â€¢ {step_name}: {result.get('error', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}")
        
        return loading_results
        
    except Exception as e:
        print(f"âŒ ëª¨ë¸ ë¡œë”© í…ŒìŠ¤íŠ¸ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        return None

def main():
    """ë©”ì¸ í…ŒìŠ¤íŠ¸ í•¨ìˆ˜"""
    
    print("ğŸ” Auto Detector â†’ ModelLoader ì™„ì „ ì—°ë™ í…ŒìŠ¤íŠ¸ ì‹œì‘...")
    print("=" * 60)
    
    # 1ë‹¨ê³„: Auto Detector ëª¨ë¸ íƒì§€
    detected_models = test_step1_auto_detector_finds_models()
    
    if not detected_models:
        print("\nâŒ 1ë‹¨ê³„ ì‹¤íŒ¨: Auto Detectorê°€ ëª¨ë¸ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤")
        return False
    
    # 2ë‹¨ê³„: ModelLoader ì—°ë™
    registration_results = test_step2_modelloader_integration(detected_models)
    
    if not registration_results:
        print("\nâŒ 2ë‹¨ê³„ ì‹¤íŒ¨: ModelLoader ì—°ë™ì´ ì•ˆë©ë‹ˆë‹¤")
        return False
    
    # 3ë‹¨ê³„: Step ë§¤í•‘
    step_mapping_results = test_step3_step_mapping(registration_results)
    
    if not step_mapping_results:
        print("\nâŒ 3ë‹¨ê³„ ì‹¤íŒ¨: Step ë§¤í•‘ì´ ì•ˆë©ë‹ˆë‹¤")
        return False
    
    # 4ë‹¨ê³„: ì‹¤ì œ ëª¨ë¸ ë¡œë”©
    loading_results = test_step4_actual_model_loading(step_mapping_results)
    
    # ìµœì¢… ê²°ê³¼
    print("\n" + "=" * 60)
    print("ğŸ¯ ìµœì¢… í…ŒìŠ¤íŠ¸ ê²°ê³¼:")
    
    if loading_results:
        successful_loads = sum(1 for r in loading_results.values() if r.get('success', False))
        
        if successful_loads > 0:
            print(f"âœ… Auto Detector â†’ ModelLoader ì—°ë™ ì„±ê³µ!")
            print(f"   ğŸ“¦ íƒì§€ëœ ëª¨ë¸: {len(detected_models)}ê°œ")
            print(f"   ğŸ”§ ë“±ë¡ëœ ëª¨ë¸: {sum(1 for r in registration_results.values() if r.get('success', False))}ê°œ")
            print(f"   ğŸ¯ ì»¤ë²„ëœ Step: {len([s for s, models in step_mapping_results.items() if models])}ê°œ")
            print(f"   ğŸ”¥ ë¡œë”© ê°€ëŠ¥í•œ ëª¨ë¸: {successful_loads}ê°œ")
            
            print(f"\nğŸš€ ê²°ë¡ : Auto Detectorê°€ ê²½ë¡œë¥¼ ì •í™•íˆ ì°¾ì•„ì„œ ModelLoaderì— ì œëŒ€ë¡œ ì—°ë™ë©ë‹ˆë‹¤!")
            return True
        else:
            print(f"âš ï¸ Auto DetectorëŠ” ëª¨ë¸ì„ ì°¾ì§€ë§Œ ModelLoader ë¡œë”©ì— ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤")
            return False
    else:
        print(f"âŒ Auto Detector â†’ ModelLoader ì—°ë™ì— ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤")
        return False

if __name__ == "__main__":
    success = main()
    
    if success:
        print(f"\nğŸ‰ í…ŒìŠ¤íŠ¸ ì™„ë£Œ: Auto Detectorê°€ ì œëŒ€ë¡œ ì‘ë™í•©ë‹ˆë‹¤!")
    else:
        print(f"\nğŸ’¡ ë¬¸ì œ í•´ê²°ì´ í•„ìš”í•©ë‹ˆë‹¤.")