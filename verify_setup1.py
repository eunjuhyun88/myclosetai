#!/usr/bin/env python3
"""
ğŸ” í˜„ì¬ ì„¤ì • ê²€ì¦ ë° ëˆ„ë½ ëª¨ë¸ í™•ì¸
"""

import os
import json
from pathlib import Path

def check_model_files():
    """íƒì§€ëœ ëª¨ë¸ íŒŒì¼ë“¤ì´ ì‹¤ì œë¡œ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸"""
    
    print("ğŸ” ëª¨ë¸ íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ ê²€ì¦...")
    
    # íƒì§€ ê²°ê³¼ ê¸°ë°˜ ê²½ë¡œë“¤
    model_paths = [
        # íƒì§€ëœ ì‹¤ì œ ê²½ë¡œë“¤
        "/Users/gimdudeul/MVP/mycloset-ai/backend/app/ai_pipeline/models/downloads/ootdiffusion/snapshots/c79f9dd0585743bea82a39261cc09a24040bc4f9/checkpoints/humanparsing/exp-schp-201908301523-atr.pth",
        "/Users/gimdudeul/MVP/mycloset-ai/backend/app/ai_pipeline/models/ai_models/checkpoints/step_03_cloth_segmentation/u2net.pth", 
        "/Users/gimdudeul/MVP/mycloset-ai/backend/app/ai_pipeline/models/ai_models/downloads/models--runwayml--stable-diffusion-v1-5/snapshots/451f4fe16113bff5a5d2269ed5ad43b0592e9a14/unet/diffusion_pytorch_model.bin",
        "/Users/gimdudeul/MVP/mycloset-ai/backend/app/ai_pipeline/models/ai_models/checkpoints/step_02_pose_estimation/openpose_body.pth"
    ]
    
    existing_files = []
    missing_files = []
    
    for model_path in model_paths:
        path = Path(model_path)
        if path.exists():
            size_mb = path.stat().st_size / (1024 * 1024)
            existing_files.append({
                'path': str(path),
                'name': path.name,
                'size_mb': size_mb,
                'step': get_step_from_path(str(path))
            })
            print(f"   âœ… {path.name} ({size_mb:.1f}MB)")
        else:
            missing_files.append(str(path))
            print(f"   âŒ {path.name} - íŒŒì¼ ì—†ìŒ")
    
    return existing_files, missing_files

def get_step_from_path(path_str):
    """ê²½ë¡œì—ì„œ Step ì¶”ì •"""
    path_lower = path_str.lower()
    
    if 'human' in path_lower or 'parsing' in path_lower or 'schp' in path_lower:
        return 'HumanParsingStep'
    elif 'pose' in path_lower or 'openpose' in path_lower:
        return 'PoseEstimationStep'
    elif 'cloth' in path_lower or 'segmentation' in path_lower or 'u2net' in path_lower:
        return 'ClothSegmentationStep'
    elif 'diffusion' in path_lower or 'stable' in path_lower or 'virtual' in path_lower:
        return 'VirtualFittingStep'
    elif 'geometric' in path_lower or 'matching' in path_lower:
        return 'GeometricMatchingStep'
    elif 'warping' in path_lower or 'warp' in path_lower:
        return 'ClothWarpingStep'
    else:
        return 'UnknownStep'

def find_additional_models():
    """ì¶”ê°€ë¡œ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ë“¤ ì°¾ê¸°"""
    
    print("ğŸ” ì¶”ê°€ ëª¨ë¸ íŒŒì¼ íƒìƒ‰...")
    
    base_dir = Path("/Users/gimdudeul/MVP/mycloset-ai/backend/app/ai_pipeline/models")
    
    additional_models = []
    
    if base_dir.exists():
        # .pth, .pt, .bin, .safetensors íŒŒì¼ë“¤ ì°¾ê¸°
        for ext in ['*.pth', '*.pt', '*.bin', '*.safetensors']:
            for file_path in base_dir.rglob(ext):
                if file_path.is_file():
                    size_mb = file_path.stat().st_size / (1024 * 1024)
                    if size_mb > 10:  # 10MB ì´ìƒë§Œ
                        additional_models.append({
                            'path': str(file_path),
                            'name': file_path.name,
                            'size_mb': size_mb,
                            'step': get_step_from_path(str(file_path))
                        })
    
    # í¬ê¸°ìˆœ ì •ë ¬
    additional_models.sort(key=lambda x: x['size_mb'], reverse=True)
    
    return additional_models

def check_step_coverage():
    """ê° Stepë³„ ëª¨ë¸ ì»¤ë²„ë¦¬ì§€ í™•ì¸"""
    
    print("ğŸ“Š Stepë³„ ëª¨ë¸ ì»¤ë²„ë¦¬ì§€ ë¶„ì„...")
    
    required_steps = {
        'HumanParsingStep': 'ì‚¬ëŒ íŒŒì‹±',
        'PoseEstimationStep': 'í¬ì¦ˆ ì¶”ì •', 
        'ClothSegmentationStep': 'ì˜· ë¶„í• ',
        'GeometricMatchingStep': 'ê¸°í•˜í•™ì  ë§¤ì¹­',
        'ClothWarpingStep': 'ì˜· ë³€í˜•',
        'VirtualFittingStep': 'ê°€ìƒ í”¼íŒ…',
        'PostProcessingStep': 'í›„ì²˜ë¦¬',
        'QualityAssessmentStep': 'í’ˆì§ˆ í‰ê°€'
    }
    
    existing_files, _ = check_model_files()
    additional_models = find_additional_models()
    
    all_models = existing_files + additional_models
    
    step_coverage = {}
    for step_name, step_desc in required_steps.items():
        models_for_step = [m for m in all_models if m['step'] == step_name]
        step_coverage[step_name] = {
            'description': step_desc,
            'models': models_for_step,
            'count': len(models_for_step),
            'covered': len(models_for_step) > 0
        }
    
    return step_coverage

def generate_download_guide():
    """ëˆ„ë½ëœ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ê°€ì´ë“œ ìƒì„±"""
    
    step_coverage = check_step_coverage()
    
    uncovered_steps = [
        step for step, info in step_coverage.items() 
        if not info['covered']
    ]
    
    if uncovered_steps:
        print(f"\nğŸ“‹ ëˆ„ë½ëœ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ê°€ì´ë“œ:")
        print("=" * 50)
        
        download_commands = {
            'GeometricMatchingStep': 'wget https://github.com/shadow2496/HR-VITON/releases/download/3.0.0/gmm_final.pth',
            'ClothWarpingStep': 'wget https://github.com/shadow2496/HR-VITON/releases/download/3.0.0/tom_final.pth', 
            'PostProcessingStep': 'wget https://github.com/xinntao/Real-ESRGAN/releases/download/v0.1.0/RealESRGAN_x4plus.pth',
            'QualityAssessmentStep': 'wget https://github.com/openai/CLIP/raw/main/clip/bpe_simple_vocab_16e6.txt'
        }
        
        for step in uncovered_steps:
            step_info = step_coverage[step]
            print(f"\nâŒ {step} ({step_info['description']})")
            
            if step in download_commands:
                print(f"   ğŸ’¾ ë‹¤ìš´ë¡œë“œ: {download_commands[step]}")
            else:
                print(f"   ğŸ’¡ ìˆ˜ë™ ì„¤ì¹˜ í•„ìš”")
    
    else:
        print(f"\nâœ… ëª¨ë“  Stepì— ëª¨ë¸ì´ ì¤€ë¹„ë˜ì–´ ìˆìŠµë‹ˆë‹¤!")

def main():
    """ë©”ì¸ ê²€ì¦ í•¨ìˆ˜"""
    
    print("ğŸ” MyCloset AI ëª¨ë¸ ì„¤ì • ê²€ì¦ ì‹œì‘...")
    print("=" * 60)
    
    # 1. ê¸°ë³¸ ëª¨ë¸ íŒŒì¼ í™•ì¸
    existing_files, missing_files = check_model_files()
    
    print(f"\nğŸ“Š ê¸°ë³¸ ê²€ì¦ ê²°ê³¼:")
    print(f"   âœ… ì¡´ì¬í•˜ëŠ” íŒŒì¼: {len(existing_files)}ê°œ")
    print(f"   âŒ ëˆ„ë½ëœ íŒŒì¼: {len(missing_files)}ê°œ")
    
    # 2. ì¶”ê°€ ëª¨ë¸ íƒìƒ‰
    additional_models = find_additional_models()
    
    print(f"\nğŸ” ì¶”ê°€ ëª¨ë¸ íƒìƒ‰ ê²°ê³¼:")
    print(f"   ğŸ“¦ ë°œê²¬ëœ ì¶”ê°€ ëª¨ë¸: {len(additional_models)}ê°œ")
    
    if additional_models:
        print("   ìƒìœ„ 5ê°œ (í¬ê¸°ìˆœ):")
        for model in additional_models[:5]:
            print(f"      ğŸ“„ {model['name']} ({model['size_mb']:.1f}MB) - {model['step']}")
    
    # 3. Step ì»¤ë²„ë¦¬ì§€ ë¶„ì„
    step_coverage = check_step_coverage()
    
    print(f"\nğŸ“‹ Stepë³„ ì»¤ë²„ë¦¬ì§€:")
    covered_count = 0
    for step_name, info in step_coverage.items():
        status = "âœ…" if info['covered'] else "âŒ"
        covered_count += 1 if info['covered'] else 0
        print(f"   {status} {step_name}: {info['count']}ê°œ ëª¨ë¸")
    
    print(f"\nğŸ“Š ì „ì²´ ìš”ì•½:")
    print(f"   ğŸ¯ ì»¤ë²„ëœ Step: {covered_count}/8ê°œ ({covered_count/8*100:.1f}%)")
    
    total_models = len(existing_files) + len(additional_models)
    total_size = sum(m['size_mb'] for m in existing_files + additional_models)
    print(f"   ğŸ“¦ ì´ ëª¨ë¸ ìˆ˜: {total_models}ê°œ")
    print(f"   ğŸ’¾ ì´ í¬ê¸°: {total_size/1024:.2f}GB")
    
    # 4. ë‹¤ìš´ë¡œë“œ ê°€ì´ë“œ
    generate_download_guide()
    
    print(f"\nğŸ¯ ê¶Œì¥ ë‹¤ìŒ ë‹¨ê³„:")
    print(f"   1. python update_model_config.py ì‹¤í–‰")
    print(f"   2. ëˆ„ë½ëœ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ (í•„ìš”ì‹œ)")
    print(f"   3. ModelLoader ì¬ì‹œì‘ í…ŒìŠ¤íŠ¸")

if __name__ == "__main__":
    main()