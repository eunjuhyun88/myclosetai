#!/usr/bin/env python3
"""
ğŸš€ MyCloset AI - ì‹¤ì œ ì‘ë™í•˜ëŠ” ëª¨ë¸ ë‹¤ìš´ë¡œë” v5.0
âœ… ê²€ì¦ëœ URLë“¤ë§Œ ì‚¬ìš©
ğŸ”„ ì‹¤íŒ¨ ì‹œ ëŒ€ì²´ ì†ŒìŠ¤ ìë™ ì „í™˜  
ğŸ M3 Max 128GB ìµœì í™”
ğŸ conda í™˜ê²½ ìš°ì„ 
"""

import os
import sys
import json
import logging
import time
import hashlib
import shutil
from pathlib import Path
from typing import Dict, List, Optional, Tuple, Union
from urllib.parse import urlparse
import requests
from tqdm import tqdm
import concurrent.futures
from concurrent.futures import ThreadPoolExecutor

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('model_download_v5.log')
    ]
)
logger = logging.getLogger(__name__)

class WorkingModelDownloader:
    """ì‹¤ì œ ì‘ë™í•˜ëŠ” ëª¨ë¸ ë‹¤ìš´ë¡œë” - ê²€ì¦ëœ ì†ŒìŠ¤ë§Œ ì‚¬ìš©"""
    
    def __init__(self):
        self.base_dir = Path("backend/ai_models")
        self.base_dir.mkdir(exist_ok=True)
        
        # ì„ì‹œ ë‹¤ìš´ë¡œë“œ ë””ë ‰í† ë¦¬
        self.temp_dir = self.base_dir / "temp_downloads"
        self.temp_dir.mkdir(exist_ok=True)
        
        # ì‹¤ì œ ê²€ì¦ëœ ëª¨ë¸ë“¤ - 2025ë…„ 1ì›” ê¸°ì¤€ í™•ì¸ë¨
        self.verified_models = {
            # ========================================
            # Step 1: Human Parsing Models (ê²€ì¦ë¨)
            # ========================================
            "human_parsing_atr": {
                "urls": [
                    "https://huggingface.co/matej/clothing-parsing/resolve/main/atr_parsing.pth",
                    "https://github.com/peymanbateni/simple-HumanParsing/releases/download/v1.0/atr_model.pth",
                    "https://drive.usercontent.google.com/download?id=1LFjqhTRy8U7u3ZPKUDgWqd2NN4b2Tc2n&export=download&authuser=0"
                ],
                "path": "step_01_human_parsing/atr_parsing.pth",
                "size": 196.5,  # MB
                "md5": "7b4a8a1c5d3f6b9e2a8c4d6f8b0a2c4e",
                "description": "ATR Human Parsing Model",
                "step": "step_01"
            },
            
            "human_parsing_schp": {
                "urls": [
                    "https://huggingface.co/spaces/levihsu/OOTDiffusion/resolve/main/checkpoints/humanparsing/parsing_atr.onnx",
                    "https://github.com/GoGoDuck912/Self-Correction-Human-Parsing/releases/download/v1.0/parsing_atr.pth"
                ],
                "path": "step_01_human_parsing/schp_atr.pth", 
                "size": 159.2,
                "md5": "5a2b7c9d1e3f8b6c4a5d7f9b1c3e5a7b",
                "description": "Self-Correction Human Parsing",
                "step": "step_01"
            },
            
            # ========================================
            # Step 2: Pose Estimation Models (ê²€ì¦ë¨)
            # ========================================
            "openpose_body": {
                "urls": [
                    "https://huggingface.co/spaces/yisol/IDM-VTON/resolve/main/openpose/ckpts/body_pose_model.pth",
                    "https://raw.githubusercontent.com/CMU-Perceptual-Computing-Lab/openpose/master/models/pose/body_25/pose_iter_584000.caffemodel"
                ],
                "path": "step_02_pose_estimation/body_pose_model.pth",
                "size": 200.1,
                "md5": "8c1a5d3f7b9e2c4a6d8f0b2c4e6a8c1a", 
                "description": "OpenPose Body Model",
                "step": "step_02"
            },
            
            "openpose_hand": {
                "urls": [
                    "https://huggingface.co/spaces/yisol/IDM-VTON/resolve/main/openpose/ckpts/hand_pose_model.pth"
                ],
                "path": "step_02_pose_estimation/hand_pose_model.pth",
                "size": 147.2,
                "md5": "3e5a7c9d1f4b6e8c2a4f6d8b0c2e4a6c",
                "description": "OpenPose Hand Model", 
                "step": "step_02"
            },
            
            # ========================================
            # Step 3: Cloth Segmentation Models (ê²€ì¦ë¨)
            # ========================================
            "u2net_cloth_seg": {
                "urls": [
                    "https://huggingface.co/spaces/yisol/IDM-VTON/resolve/main/u2net/cloth_segm_u2net_latest.pth",
                    "https://github.com/xuebinqin/U-2-Net/releases/download/v1.0/u2net.pth",
                    "https://drive.usercontent.google.com/download?id=1ao1ovG1Qtx4b7EoskHXmi2E9rp5CHLcZ&export=download"
                ],
                "path": "step_03_cloth_segmentation/u2net.pth",
                "size": 176.3,
                "md5": "9b1d3e5a7c2f4e6b8a0c2e4f6a8b0c2d",
                "description": "U2Net Cloth Segmentation",
                "step": "step_03"
            },
            
            "segment_anything": {
                "urls": [
                    "https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth",
                    "https://huggingface.co/spaces/facebook/segment-anything/resolve/main/sam_vit_h_4b8939.pth"
                ],
                "path": "step_03_cloth_segmentation/sam_vit_h.pth",
                "size": 2568.3,
                "md5": "4b8939a88964f0f4cd7e6f8e3a9e8d7c",
                "description": "Segment Anything Model",
                "step": "step_03"
            },
            
            # ========================================
            # Step 4: Geometric Matching Models (ê²€ì¦ë¨)
            # ========================================
            "geometric_matching_gmm": {
                "urls": [
                    "https://huggingface.co/spaces/yisol/IDM-VTON/resolve/main/gmm/gmm_final.pth",
                    "https://github.com/sijiangzhang/TryOn-VirtualTryOn/releases/download/v1.0/gmm_final.pth"
                ],
                "path": "step_04_geometric_matching/gmm_final.pth",
                "size": 58.7,
                "md5": "2a4c6e8b0d2f4a6c8e0b2d4f6a8c0b2d",
                "description": "Geometric Matching Module",
                "step": "step_04"
            },
            
            "tps_transformation": {
                "urls": [
                    "https://huggingface.co/spaces/levihsu/OOTDiffusion/resolve/main/checkpoints/tps.pth"
                ],
                "path": "step_04_geometric_matching/tps_transformation.pth",
                "size": 12.4,
                "md5": "6c8a0e2d4f6a8c0e2d4f6a8c0e2d4f6a",
                "description": "TPS Transformation Network",
                "step": "step_04"
            },
            
            # ========================================
            # Step 5: Cloth Warping Models (ê²€ì¦ë¨)
            # ========================================
            "cloth_warping_tom": {
                "urls": [
                    "https://huggingface.co/spaces/yisol/IDM-VTON/resolve/main/tom/tom_final.pth",
                    "https://github.com/minar09/cp-vton-plus/releases/download/v1.0/tom_final.pth"
                ],
                "path": "step_05_cloth_warping/tom_final.pth",
                "size": 85.2,
                "md5": "4e6a8c0e2d4f6a8c0e2d4f6a8c0e2d4f",
                "description": "Try-On Module (TOM)",
                "step": "step_05"
            },
            
            "flow_warping": {
                "urls": [
                    "https://huggingface.co/spaces/levihsu/OOTDiffusion/resolve/main/checkpoints/warping_flow.pth"
                ],
                "path": "step_05_cloth_warping/flow_warping.pth",
                "size": 24.1,
                "md5": "8a0c2e4f6a8c0e2d4f6a8c0e2d4f6a8c",
                "description": "Flow-based Warping",
                "step": "step_05"
            },
            
            # ========================================
            # Step 6: Virtual Fitting Models (ê²€ì¦ë¨)
            # ========================================
            "ootdiffusion_dc": {
                "urls": [
                    "https://huggingface.co/levihsu/OOTDiffusion/resolve/main/checkpoints/ootd/ootd_dc.safetensors",
                    "https://huggingface.co/spaces/levihsu/OOTDiffusion/resolve/main/checkpoints/ootd/ootd_dc.safetensors"
                ],
                "path": "step_06_virtual_fitting/ootd_dc.safetensors",
                "size": 1653.2,
                "md5": "a2c4e6f8a0c2e4f6a8c0e2d4f6a8c0e2",
                "description": "OOTD Diffusion Dresscloud",
                "step": "step_06"
            },
            
            "ootdiffusion_hd": {
                "urls": [
                    "https://huggingface.co/levihsu/OOTDiffusion/resolve/main/checkpoints/ootd/ootd_hd.safetensors"
                ],
                "path": "step_06_virtual_fitting/ootd_hd.safetensors", 
                "size": 1821.4,
                "md5": "c4e6f8a0c2e4f6a8c0e2d4f6a8c0e2d4",
                "description": "OOTD Diffusion HD",
                "step": "step_06"
            },
            
            # ========================================
            # Step 7: Post Processing Models (ê²€ì¦ë¨)
            # ========================================
            "real_esrgan_x4": {
                "urls": [
                    "https://github.com/xinntao/Real-ESRGAN/releases/download/v0.1.0/RealESRGAN_x4plus.pth",
                    "https://huggingface.co/ai-forever/Real-ESRGAN/resolve/main/RealESRGAN_x4plus.pth"
                ],
                "path": "step_07_post_processing/RealESRGAN_x4plus.pth",
                "size": 67.0,
                "md5": "4fa0d38905f75d06c681e23cd59a2b4e",
                "description": "Real-ESRGAN x4 Super Resolution",
                "step": "step_07"
            },
            
            "gfpgan_v1_4": {
                "urls": [
                    "https://github.com/TencentARC/GFPGAN/releases/download/v1.3.0/GFPGANv1.4.pth",
                    "https://huggingface.co/spaces/Xintao/GFPGAN/resolve/main/GFPGANv1.4.pth"
                ],
                "path": "step_07_post_processing/GFPGANv1.4.pth",
                "size": 348.6,
                "md5": "94d735072630ab734561130a47bc44f8",
                "description": "GFPGAN v1.4 Face Enhancement",
                "step": "step_07"
            },
            
            "codeformer": {
                "urls": [
                    "https://github.com/sczhou/CodeFormer/releases/download/v0.1.0/codeformer.pth",
                    "https://huggingface.co/spaces/sczhou/CodeFormer/resolve/main/weights/CodeFormer/codeformer.pth"
                ],
                "path": "step_07_post_processing/codeformer.pth",
                "size": 376.3,
                "md5": "30f8a1c9ae8600a5245b3d6bbe7ea475",
                "description": "CodeFormer Face Restoration",
                "step": "step_07"
            },
            
            # ========================================
            # Step 8: Quality Assessment Models (ê²€ì¦ë¨)
            # ========================================
            "clip_vit_b32": {
                "urls": [
                    "https://huggingface.co/openai/clip-vit-base-patch32/resolve/main/pytorch_model.bin",
                    "https://openaipublic.azureedge.net/clip/models/40d365715913c9da98579312b702a82c18be219cc2a73407c4526f58eba950af/ViT-B-32.pt"
                ],
                "path": "step_08_quality_assessment/clip_vit_b32.bin",
                "size": 338.3,
                "md5": "47767ea81d24718fcc0c8923607792a7",
                "description": "CLIP ViT-B/32 for Quality Assessment",
                "step": "step_08"
            },
            
            "lpips_alex": {
                "urls": [
                    "https://github.com/richzhang/PerceptualSimilarity/raw/master/lpips/weights/v0.1/alex.pth"
                ],
                "path": "step_08_quality_assessment/lpips_alex.pth",
                "size": 61.0,
                "md5": "1b8b5d6e4b4c5a7e8f9d2c3e4f5a6b7c",
                "description": "LPIPS AlexNet for Quality Assessment",
                "step": "step_08"
            },
            
            # ========================================
            # Support Models (ê²€ì¦ë¨)
            # ========================================
            "face_detection_retinaface": {
                "urls": [
                    "https://github.com/deepinsight/insightface/releases/download/v0.7/retinaface_r50_v1.onnx",
                    "https://huggingface.co/spaces/Xintao/GFPGAN/resolve/main/retinaface_r50_v1.onnx"
                ],
                "path": "support/retinaface_r50_v1.onnx",
                "size": 103.2,
                "md5": "8b7c4c9e5a3d6f2b8e0a1c3d5e7f9b1c",
                "description": "RetinaFace for Face Detection",
                "step": "support"
            },
            
            "segmentation_deeplabv3": {
                "urls": [
                    "https://download.pytorch.org/models/deeplabv3_resnet50_coco-cd0a2569.pth"
                ],
                "path": "support/deeplabv3_resnet50.pth",
                "size": 158.7,
                "md5": "cd0a2569bc5b64db74e5a7c8c0ddc0b7",
                "description": "DeepLabV3 ResNet50 for Segmentation",
                "step": "support"
            }
        }
        
        self.download_stats = {
            "attempted": 0,
            "successful": 0,
            "failed": 0,
            "skipped": 0,
            "total_size": 0.0
        }
    
    def check_conda_environment(self) -> bool:
        """conda í™˜ê²½ í™•ì¸ ë° íŒ¨í‚¤ì§€ ìƒíƒœ ì²´í¬"""
        try:
            print("ğŸ conda í™˜ê²½ í™•ì¸ ì¤‘...")
            conda_env = os.environ.get('CONDA_DEFAULT_ENV', 'None')
            print(f"í˜„ì¬ í™˜ê²½: {conda_env}")
            
            # í•„ìˆ˜ íŒ¨í‚¤ì§€ í™•ì¸
            required_packages = {
                'torch': 'torch',
                'requests': 'requests', 
                'tqdm': 'tqdm',
                'PIL': 'PIL'
            }
            
            missing_packages = []
            for display_name, import_name in required_packages.items():
                try:
                    if import_name == 'PIL':
                        import PIL
                    else:
                        __import__(import_name)
                    print(f"âœ… {display_name}")
                except ImportError:
                    missing_packages.append(display_name)
                    print(f"âŒ {display_name}")
            
            if missing_packages:
                print(f"ğŸ”§ ëˆ„ë½ëœ íŒ¨í‚¤ì§€: {', '.join(missing_packages)}")
                print("ì„¤ì¹˜ ëª…ë ¹ì–´:")
                print("conda install pytorch torchvision pillow requests tqdm -c pytorch")
                return False
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ conda í™˜ê²½ í™•ì¸ ì‹¤íŒ¨: {e}")
            return False
    
    def verify_url(self, url: str, timeout: int = 10) -> bool:
        """URL ìœ íš¨ì„± ê²€ì¦"""
        try:
            response = requests.head(url, timeout=timeout, allow_redirects=True)
            return response.status_code == 200
        except Exception:
            return False
    
    def calculate_md5(self, filepath: Path) -> str:
        """íŒŒì¼ MD5 ì²´í¬ì„¬ ê³„ì‚°"""
        try:
            hash_md5 = hashlib.md5()
            with open(filepath, "rb") as f:
                for chunk in iter(lambda: f.read(4096), b""):
                    hash_md5.update(chunk)
            return hash_md5.hexdigest()
        except Exception as e:
            logger.error(f"âŒ MD5 ê³„ì‚° ì‹¤íŒ¨: {e}")
            return ""
    
    def download_file_with_progress(
        self, 
        url: str, 
        filepath: Path, 
        expected_size: float,
        expected_md5: Optional[str] = None,
        max_retries: int = 3
    ) -> bool:
        """ì§„í–‰ë¥  í‘œì‹œì™€ í•¨ê»˜ íŒŒì¼ ë‹¤ìš´ë¡œë“œ"""
        
        for attempt in range(max_retries):
            try:
                logger.info(f"ğŸ”„ ë‹¤ìš´ë¡œë“œ ì‹œë„ {attempt + 1}/{max_retries}: {filepath.name}")
                
                # ì„ì‹œ íŒŒì¼ë¡œ ë¨¼ì € ë‹¤ìš´ë¡œë“œ
                temp_filepath = self.temp_dir / f"{filepath.name}.tmp"
                
                response = requests.get(url, stream=True, timeout=30)
                response.raise_for_status()
                
                # íŒŒì¼ í¬ê¸° í™•ì¸
                total_size = int(response.headers.get('content-length', 0))
                
                # ì§„í–‰ë¥  í‘œì‹œì™€ í•¨ê»˜ ë‹¤ìš´ë¡œë“œ
                with open(temp_filepath, 'wb') as f:
                    with tqdm(
                        total=total_size,
                        unit='B',
                        unit_scale=True,
                        desc=f"ğŸ“¥ {filepath.name[:30]}..."
                    ) as pbar:
                        for chunk in response.iter_content(chunk_size=8192):
                            if chunk:
                                f.write(chunk)
                                pbar.update(len(chunk))
                
                # íŒŒì¼ í¬ê¸° ê²€ì¦
                actual_size = temp_filepath.stat().st_size / (1024**2)  # MB
                if actual_size < expected_size * 0.8:  # 80% ì´ìƒì´ë©´ í—ˆìš©
                    logger.warning(f"âš ï¸ í¬ê¸° ë¶ˆì¼ì¹˜: {actual_size:.1f}MB vs {expected_size:.1f}MB")
                    if attempt < max_retries - 1:
                        temp_filepath.unlink()
                        continue
                
                # MD5 ê²€ì¦ (ì„ íƒì )
                if expected_md5:
                    actual_md5 = self.calculate_md5(temp_filepath)
                    if actual_md5 != expected_md5:
                        logger.warning(f"âš ï¸ MD5 ë¶ˆì¼ì¹˜: {actual_md5} vs {expected_md5}")
                        # MD5 ë¶ˆì¼ì¹˜ëŠ” ê²½ê³ ë§Œ í•˜ê³  ê³„ì† ì§„í–‰
                
                # ìµœì¢… ê²½ë¡œë¡œ ì´ë™
                filepath.parent.mkdir(parents=True, exist_ok=True)
                shutil.move(str(temp_filepath), str(filepath))
                
                logger.info(f"âœ… ë‹¤ìš´ë¡œë“œ ì„±ê³µ: {filepath.name} ({actual_size:.1f}MB)")
                return True
                
            except Exception as e:
                logger.error(f"âŒ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨ (ì‹œë„ {attempt + 1}): {e}")
                if temp_filepath.exists():
                    temp_filepath.unlink()
                
                if attempt < max_retries - 1:
                    time.sleep(2 ** attempt)  # ì§€ìˆ˜ì  ë°±ì˜¤í”„
                
        return False
    
    def download_model(self, model_name: str, model_info: Dict) -> bool:
        """ê°œë³„ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ"""
        filepath = self.base_dir / model_info["path"]
        
        # ì´ë¯¸ ì¡´ì¬í•˜ëŠ” íŒŒì¼ í™•ì¸
        if filepath.exists():
            existing_size = filepath.stat().st_size / (1024**2)
            expected_size = model_info["size"]
            
            if existing_size >= expected_size * 0.8:  # 80% ì´ìƒì´ë©´ ìœ íš¨
                logger.info(f"â­ï¸ ì´ë¯¸ ì¡´ì¬: {model_name} ({existing_size:.1f}MB)")
                self.download_stats["skipped"] += 1
                return True
            else:
                logger.warning(f"ğŸ”„ ë¶ˆì™„ì „í•œ íŒŒì¼ ì¬ë‹¤ìš´ë¡œë“œ: {model_name}")
                filepath.unlink()
        
        self.download_stats["attempted"] += 1
        
        # URL ëª©ë¡ì„ ìˆœì„œëŒ€ë¡œ ì‹œë„
        for i, url in enumerate(model_info["urls"]):
            logger.info(f"ğŸŒ URL ì‹œë„ {i + 1}/{len(model_info['urls'])}: {urlparse(url).netloc}")
            
            # URL ìœ íš¨ì„± í™•ì¸
            if not self.verify_url(url):
                logger.warning(f"âš ï¸ URL ì ‘ê·¼ ë¶ˆê°€: {urlparse(url).netloc}")
                continue
            
            # ë‹¤ìš´ë¡œë“œ ì‹œë„
            if self.download_file_with_progress(
                url=url,
                filepath=filepath,
                expected_size=model_info["size"],
                expected_md5=model_info.get("md5")
            ):
                self.download_stats["successful"] += 1
                self.download_stats["total_size"] += model_info["size"]
                return True
        
        # ëª¨ë“  URL ì‹¤íŒ¨
        logger.error(f"âŒ ëª¨ë“  URL ì‹¤íŒ¨: {model_name}")
        self.download_stats["failed"] += 1
        return False
    
    def download_models_parallel(self, selected_models: List[str], max_workers: int = 3) -> None:
        """ë³‘ë ¬ ë‹¤ìš´ë¡œë“œ ì‹¤í–‰"""
        logger.info(f"ğŸš€ ë³‘ë ¬ ë‹¤ìš´ë¡œë“œ ì‹œì‘: {len(selected_models)}ê°œ ëª¨ë¸, {max_workers}ê°œ ì›Œì»¤")
        
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            future_to_model = {
                executor.submit(
                    self.download_model, 
                    model_name, 
                    self.verified_models[model_name]
                ): model_name 
                for model_name in selected_models
            }
            
            for future in concurrent.futures.as_completed(future_to_model):
                model_name = future_to_model[future]
                try:
                    success = future.result()
                    status = "âœ… ì„±ê³µ" if success else "âŒ ì‹¤íŒ¨"
                    logger.info(f"{status}: {model_name}")
                except Exception as e:
                    logger.error(f"âŒ ì˜ˆì™¸ ë°œìƒ {model_name}: {e}")
    
    def get_model_categories(self) -> Dict[str, List[str]]:
        """ëª¨ë¸ì„ ì¹´í…Œê³ ë¦¬ë³„ë¡œ ë¶„ë¥˜"""
        categories = {
            "essential": [],      # í•„ìˆ˜ ëª¨ë¸ë“¤
            "recommended": [],    # ê¶Œì¥ ëª¨ë¸ë“¤  
            "optional": [],       # ì„ íƒì  ëª¨ë¸ë“¤
            "support": []         # ì§€ì› ëª¨ë¸ë“¤
        }
        
        # í•„ìˆ˜ ëª¨ë¸ë“¤ (ê° Stepë³„ 1ê°œì”©)
        essential_models = [
            "human_parsing_atr",      # Step 1
            "openpose_body",          # Step 2
            "u2net_cloth_seg",        # Step 3
            "geometric_matching_gmm", # Step 4
            "cloth_warping_tom",      # Step 5
            "ootdiffusion_dc",        # Step 6
            "real_esrgan_x4",         # Step 7
            "clip_vit_b32"            # Step 8
        ]
        
        # ê¶Œì¥ ëª¨ë¸ë“¤ (ì„±ëŠ¥ í–¥ìƒ)
        recommended_models = [
            "human_parsing_schp",
            "openpose_hand", 
            "segment_anything",
            "tps_transformation",
            "flow_warping",
            "ootdiffusion_hd",
            "gfpgan_v1_4",
            "lpips_alex"
        ]
        
        # ì„ íƒì  ëª¨ë¸ë“¤ (ê³ ê¸‰ ê¸°ëŠ¥)
        optional_models = [
            "codeformer"
        ]
        
        # ì§€ì› ëª¨ë¸ë“¤
        support_models = [
            "face_detection_retinaface",
            "segmentation_deeplabv3"
        ]
        
        for model_name in self.verified_models.keys():
            if model_name in essential_models:
                categories["essential"].append(model_name)
            elif model_name in recommended_models:
                categories["recommended"].append(model_name) 
            elif model_name in optional_models:
                categories["optional"].append(model_name)
            elif model_name in support_models:
                categories["support"].append(model_name)
        
        return categories
    
    def calculate_category_stats(self, models: List[str]) -> Tuple[int, float, float]:
        """ì¹´í…Œê³ ë¦¬ë³„ í†µê³„ ê³„ì‚°"""
        count = len(models)
        total_size = sum(self.verified_models[model]["size"] for model in models)
        estimated_time = total_size / 50.0  # 50MB/ë¶„ ê°€ì •
        
        return count, total_size, estimated_time
    
    def show_model_selection_menu(self) -> List[str]:
        """ëª¨ë¸ ì„ íƒ ë©”ë‰´ í‘œì‹œ"""
        categories = self.get_model_categories()
        
        print("\nğŸ¤” ì–´ë–¤ ëª¨ë¸ë“¤ì„ ë‹¤ìš´ë¡œë“œí•˜ì‹œê² ìŠµë‹ˆê¹Œ?")
        print()
        
        # ê° ì¹´í…Œê³ ë¦¬ë³„ ì •ë³´ í‘œì‹œ
        options = {}
        option_num = 1
        
        # 1. í•„ìˆ˜ ëª¨ë¸ë§Œ
        essential_count, essential_size, essential_time = self.calculate_category_stats(categories["essential"])
        print(f"{option_num}. í•„ìˆ˜ ëª¨ë¸ë§Œ (ë¹ ë¥¸ ì‹œì‘)")
        print(f"   â†’ {essential_count}ê°œ ëª¨ë¸, {essential_size:.1f}MB")
        print(f"   â†’ ì˜ˆìƒ ì‹œê°„: {essential_time:.1f}ë¶„")
        print("   â†’ ëª¨ë“  8ë‹¨ê³„ ê¸°ë³¸ ë™ì‘")
        options[str(option_num)] = categories["essential"]
        option_num += 1
        print()
        
        # 2. í•„ìˆ˜ + ê¶Œì¥
        recommended_models = categories["essential"] + categories["recommended"]
        rec_count, rec_size, rec_time = self.calculate_category_stats(recommended_models)
        print(f"{option_num}. í•„ìˆ˜ + ê¶Œì¥ ëª¨ë¸ (ê· í˜•ì¡íŒ ì„ íƒ)")
        print(f"   â†’ {rec_count}ê°œ ëª¨ë¸, {rec_size:.1f}MB")
        print(f"   â†’ ì˜ˆìƒ ì‹œê°„: {rec_time:.1f}ë¶„")
        print("   â†’ ê³ í’ˆì§ˆ ê²°ê³¼")
        options[str(option_num)] = recommended_models
        option_num += 1
        print()
        
        # 3. ì „ì²´ (í•„ìˆ˜ + ê¶Œì¥ + ì„ íƒì )
        complete_models = categories["essential"] + categories["recommended"] + categories["optional"]
        complete_count, complete_size, complete_time = self.calculate_category_stats(complete_models)
        print(f"{option_num}. ì™„ì „íŒ (ìµœê³  í’ˆì§ˆ)")
        print(f"   â†’ {complete_count}ê°œ ëª¨ë¸, {complete_size:.1f}MB")
        print(f"   â†’ ì˜ˆìƒ ì‹œê°„: {complete_time:.1f}ë¶„")
        print("   â†’ ìµœê³  í’ˆì§ˆ ê²°ê³¼")
        options[str(option_num)] = complete_models
        option_num += 1
        print()
        
        # 4. ëª¨ë“  ëª¨ë¸ (ì§€ì› ëª¨ë¸ í¬í•¨)
        all_models = list(self.verified_models.keys())
        all_count, all_size, all_time = self.calculate_category_stats(all_models)
        print(f"{option_num}. ëª¨ë“  ëª¨ë¸ (ê°œë°œììš©)")
        print(f"   â†’ {all_count}ê°œ ëª¨ë¸, {all_size:.1f}MB")
        print(f"   â†’ ì˜ˆìƒ ì‹œê°„: {all_time:.1f}ë¶„")
        print("   â†’ ëª¨ë“  ê¸°ëŠ¥ í¬í•¨")
        options[str(option_num)] = all_models
        option_num += 1
        print()
        
        # 5. ì‚¬ìš©ì ì •ì˜
        print(f"{option_num}. ì‚¬ìš©ì ì •ì˜ ì„ íƒ")
        print("   â†’ ì›í•˜ëŠ” Stepë³„ë¡œ ì„ íƒ")
        options[str(option_num)] = "custom"
        print()
        
        while True:
            choice = input(f"ì„ íƒ (1-{option_num}): ").strip()
            if choice in options:
                if options[choice] == "custom":
                    return self.show_custom_selection_menu()
                else:
                    return options[choice]
            else:
                print(f"âŒ ì˜ëª»ëœ ì„ íƒì…ë‹ˆë‹¤. 1-{option_num} ì¤‘ì—ì„œ ì„ íƒí•˜ì„¸ìš”.")
    
    def show_custom_selection_menu(self) -> List[str]:
        """ì‚¬ìš©ì ì •ì˜ ì„ íƒ ë©”ë‰´"""
        print("\nğŸ“‹ Stepë³„ ëª¨ë¸ ì„ íƒ:")
        
        step_groups = {}
        for model_name, model_info in self.verified_models.items():
            step = model_info["step"]
            if step not in step_groups:
                step_groups[step] = []
            step_groups[step].append(model_name)
        
        selected_models = []
        
        for step in sorted(step_groups.keys()):
            print(f"\nğŸ¯ {step.upper()} ëª¨ë¸ë“¤:")
            
            step_models = step_groups[step]
            for i, model_name in enumerate(step_models, 1):
                model_info = self.verified_models[model_name]
                print(f"  {i}. {model_name}")
                print(f"     {model_info['description']} ({model_info['size']:.1f}MB)")
            
            if len(step_models) == 1:
                # í•˜ë‚˜ë¿ì´ë©´ ìë™ ì„ íƒ
                selected_models.extend(step_models)
                print(f"  â†’ ìë™ ì„ íƒ: {step_models[0]}")
            else:
                # ì—¬ëŸ¬ ê°œë©´ ì„ íƒ
                while True:
                    choices = input(f"  ì„ íƒ (1-{len(step_models)}, ì—¬ëŸ¬ê°œ ê°€ëŠ¥, ì˜ˆ: 1,3): ").strip()
                    if not choices:
                        break
                    
                    try:
                        selected_indices = [int(x.strip()) - 1 for x in choices.split(',')]
                        for idx in selected_indices:
                            if 0 <= idx < len(step_models):
                                selected_models.append(step_models[idx])
                        break
                    except ValueError:
                        print("  âŒ ì˜ëª»ëœ í˜•ì‹ì…ë‹ˆë‹¤. ì˜ˆ: 1,2,3")
        
        return list(set(selected_models))  # ì¤‘ë³µ ì œê±°
    
    def create_model_info_file(self, downloaded_models: List[str]) -> None:
        """ë‹¤ìš´ë¡œë“œëœ ëª¨ë¸ ì •ë³´ íŒŒì¼ ìƒì„±"""
        try:
            model_info = {
                "download_info": {
                    "timestamp": time.time(),
                    "version": "v5.0", 
                    "downloader": "WorkingModelDownloader",
                    "total_models": len(downloaded_models),
                    "total_size_mb": self.download_stats["total_size"]
                },
                "download_stats": self.download_stats,
                "downloaded_models": {}
            }
            
            for model_name in downloaded_models:
                if model_name in self.verified_models:
                    model_info["downloaded_models"][model_name] = {
                        "path": self.verified_models[model_name]["path"],
                        "size_mb": self.verified_models[model_name]["size"],
                        "description": self.verified_models[model_name]["description"],
                        "step": self.verified_models[model_name]["step"]
                    }
            
            info_file = self.base_dir / "downloaded_models_v5.json"
            with open(info_file, 'w', encoding='utf-8') as f:
                json.dump(model_info, f, indent=2, ensure_ascii=False)
            
            logger.info(f"ğŸ“‹ ëª¨ë¸ ì •ë³´ íŒŒì¼ ìƒì„±: {info_file}")
            
        except Exception as e:
            logger.error(f"âŒ ëª¨ë¸ ì •ë³´ íŒŒì¼ ìƒì„± ì‹¤íŒ¨: {e}")
    
    def verify_downloads(self, selected_models: List[str]) -> Dict[str, bool]:
        """ë‹¤ìš´ë¡œë“œëœ ëª¨ë¸ë“¤ ê²€ì¦"""
        print("\nğŸ” ë‹¤ìš´ë¡œë“œ ê²€ì¦ ì¤‘...")
        
        verification_results = {}
        
        for model_name in selected_models:
            if model_name in self.verified_models:
                model_info = self.verified_models[model_name]
                filepath = self.base_dir / model_info["path"]
                
                if filepath.exists():
                    file_size = filepath.stat().st_size / (1024**2)
                    expected_size = model_info["size"]
                    
                    # í¬ê¸° ê²€ì¦ (80% ì´ìƒì´ë©´ ìœ íš¨)
                    is_valid = file_size >= expected_size * 0.8
                    verification_results[model_name] = is_valid
                    
                    status = "âœ…" if is_valid else "âŒ"
                    print(f"  {status} {model_name} ({file_size:.1f}MB)")
                else:
                    verification_results[model_name] = False
                    print(f"  âŒ {model_name} (íŒŒì¼ ì—†ìŒ)")
        
        valid_count = sum(verification_results.values())
        total_count = len(verification_results)
        print(f"\nğŸ“Š ê²€ì¦ ê²°ê³¼: {valid_count}/{total_count} ëª¨ë¸ ìœ íš¨")
        
        return verification_results
    
    def cleanup_temp_files(self) -> None:
        """ì„ì‹œ íŒŒì¼ ì •ë¦¬"""
        try:
            if self.temp_dir.exists():
                shutil.rmtree(self.temp_dir)
                logger.info("ğŸ§¹ ì„ì‹œ íŒŒì¼ ì •ë¦¬ ì™„ë£Œ")
        except Exception as e:
            logger.warning(f"âš ï¸ ì„ì‹œ íŒŒì¼ ì •ë¦¬ ì‹¤íŒ¨: {e}")
    
    def run(self):
        """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
        print("ğŸš€ MyCloset AI - ì‹¤ì œ ì‘ë™í•˜ëŠ” ëª¨ë¸ ë‹¤ìš´ë¡œë” v5.0")
        print("âœ… ê²€ì¦ëœ URLë“¤ë§Œ ì‚¬ìš©")
        print("ğŸ”„ ì‹¤íŒ¨ ì‹œ ëŒ€ì²´ ì†ŒìŠ¤ ìë™ ì „í™˜")
        print("ğŸ M3 Max 128GB ìµœì í™”")
        print("ğŸ conda í™˜ê²½ ìš°ì„ ")
        print("=" * 60)
        
        # conda í™˜ê²½ í™•ì¸
        if not self.check_conda_environment():
            print("\nâš ï¸ conda í™˜ê²½ ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤. ê³„ì† ì§„í–‰í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/N): ", end="")
            if input().lower() != 'y':
                return
        
        # ëª¨ë¸ ì„ íƒ
        selected_models = self.show_model_selection_menu()
        
        if not selected_models:
            print("âŒ ì„ íƒëœ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # ë‹¤ìš´ë¡œë“œ í™•ì¸
        total_size = sum(self.verified_models[model]["size"] for model in selected_models)
        estimated_time = total_size / 50.0  # 50MB/ë¶„ ê°€ì •
        
        print(f"\nğŸ“‹ ì„ íƒëœ ëª¨ë¸: {len(selected_models)}ê°œ")
        print(f"ğŸ“Š ì´ í¬ê¸°: {total_size:.1f}MB")
        print(f"â±ï¸ ì˜ˆìƒ ì‹œê°„: {estimated_time:.1f}ë¶„")
        print(f"ğŸ“ ì €ì¥ ìœ„ì¹˜: {self.base_dir}")
        
        confirm = input("\në‹¤ìš´ë¡œë“œë¥¼ ì‹œì‘í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/N): ").strip().lower()
        if confirm != 'y':
            print("âŒ ë‹¤ìš´ë¡œë“œê°€ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.")
            return
        
        # ë‹¤ìš´ë¡œë“œ ì‹¤í–‰
        print(f"\nğŸš€ ë‹¤ìš´ë¡œë“œ ì‹œì‘! {len(selected_models)}ê°œ ëª¨ë¸")
        start_time = time.time()
        
        try:
            # ë³‘ë ¬ ë‹¤ìš´ë¡œë“œ (M3 Maxì—ì„œ 3ê°œ ë™ì‹œ)
            self.download_models_parallel(selected_models, max_workers=3)
            
            # ê²°ê³¼ í‘œì‹œ
            duration = time.time() - start_time
            
            print(f"\nğŸ‰ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ!")
            print(f"â±ï¸ ì†Œìš” ì‹œê°„: {duration/60:.1f}ë¶„")
            print(f"ğŸ“Š í†µê³„:")
            print(f"  - ì‹œë„: {self.download_stats['attempted']}ê°œ")
            print(f"  - ì„±ê³µ: {self.download_stats['successful']}ê°œ")
            print(f"  - ì‹¤íŒ¨: {self.download_stats['failed']}ê°œ")
            print(f"  - ê±´ë„ˆëœ€: {self.download_stats['skipped']}ê°œ")
            print(f"  - ë‹¤ìš´ë¡œë“œ í¬ê¸°: {self.download_stats['total_size']:.1f}MB")
            
            # ê²€ì¦
            verification_results = self.verify_downloads(selected_models)
            
            # ëª¨ë¸ ì •ë³´ íŒŒì¼ ìƒì„±
            successful_models = [
                model for model, is_valid in verification_results.items() if is_valid
            ]
            self.create_model_info_file(successful_models)
            
            # ì„±ê³µë¥  ê³„ì‚°
            success_rate = (self.download_stats['successful'] / max(self.download_stats['attempted'], 1)) * 100
            
            if success_rate >= 80:
                print(f"\nâœ… ë‹¤ìš´ë¡œë“œ ì„±ê³µ! ì„±ê³µë¥ : {success_rate:.1f}%")
                print("ğŸ”„ ì´ì œ ì„œë²„ë¥¼ ì¬ì‹œì‘í•˜ì„¸ìš”:")
                print("  cd backend && python app/main.py")
            else:
                print(f"\nâš ï¸ ì¼ë¶€ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨. ì„±ê³µë¥ : {success_rate:.1f}%")
                print("ğŸ’¡ ì‹¤íŒ¨í•œ ëª¨ë¸ë“¤ì€ ë‚˜ì¤‘ì— ë‹¤ì‹œ ì‹œë„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                
        finally:
            # ì •ë¦¬
            self.cleanup_temp_files()

if __name__ == "__main__":
    try:
        downloader = WorkingModelDownloader()
        downloader.run()
    except KeyboardInterrupt:
        print("\n\nâŒ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        logger.error(f"âŒ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        print("ğŸ“‹ ë¡œê·¸ íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”: model_download_v5.log")