#!/usr/bin/env python3
"""
GeometricMatchingStep ì‹¤ì œ ì‚¬ìš© í…ŒìŠ¤íŠ¸ (torch.jit ì—†ì´)
"""

import torch
import os
import asyncio
from pathlib import Path

def test_geometric_matching_step():
    """GeometricMatchingStep í´ë˜ìŠ¤ ì‹¤ì œ í…ŒìŠ¤íŠ¸"""
    print("ğŸ”¥ GeometricMatchingStep ì‹¤ì œ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("="*60)
    
    # í™˜ê²½ ì„¤ì • í™•ì¸
    print(f"ğŸ conda í™˜ê²½: {os.environ.get('CONDA_DEFAULT_ENV', 'none')}")
    print(f"ğŸ”§ PyTorch: {torch.__version__}")
    print(f"âš¡ MPS ì‚¬ìš©ê°€ëŠ¥: {torch.backends.mps.is_available() if hasattr(torch.backends, 'mps') else False}")
    print(f"ğŸš« PYTORCH_JIT_DISABLE: {os.environ.get('PYTORCH_JIT_DISABLE', 'not_set')}")
    
    try:
        # GeometricMatchingStep import ë° ìƒì„±
        from backend.app.ai_pipeline.steps.step_04_geometric_matching import GeometricMatchingStep
        print("âœ… GeometricMatchingStep import ì„±ê³µ")
        
        # Step ì¸ìŠ¤í„´ìŠ¤ ìƒì„± (torch.jit ì—†ì´)
        step_04 = GeometricMatchingStep(
            step_id=4, 
            device="mps" if torch.backends.mps.is_available() else "cpu",
            config={"enable_jit_compile": False}  # torch.jit ëª…ì‹œì  ë¹„í™œì„±í™”
        )
        print("âœ… GeometricMatchingStep ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ì„±ê³µ")
        
        # ì´ˆê¸°í™” í…ŒìŠ¤íŠ¸
        if asyncio.iscoroutinefunction(step_04.initialize):
            # ë¹„ë™ê¸° í•¨ìˆ˜ì¸ ê²½ìš°
            success = asyncio.run(step_04.initialize())
        else:
            # ë™ê¸° í•¨ìˆ˜ì¸ ê²½ìš°
            success = step_04.initialize()
            
        print(f"{'âœ… ì´ˆê¸°í™” ì„±ê³µ' if success else 'âŒ ì´ˆê¸°í™” ì‹¤íŒ¨'}")
        
        # ëª¨ë¸ ìƒíƒœ í™•ì¸
        print("\nğŸ¤– ë¡œë”©ëœ AI ëª¨ë¸ë“¤:")
        if hasattr(step_04, 'gmm_model') and step_04.gmm_model is not None:
            print(f"  - GMM ëª¨ë¸: âœ… (íƒ€ì…: {type(step_04.gmm_model)})")
        else:
            print(f"  - GMM ëª¨ë¸: âŒ")
            
        if hasattr(step_04, 'tps_model') and step_04.tps_model is not None:
            print(f"  - TPS ëª¨ë¸: âœ… (íƒ€ì…: {type(step_04.tps_model)})")
        else:
            print(f"  - TPS ëª¨ë¸: âŒ")
            
        if hasattr(step_04, 'sam_model') and step_04.sam_model is not None:
            print(f"  - SAM ëª¨ë¸: âœ… (íƒ€ì…: {type(step_04.sam_model)})")
        else:
            print(f"  - SAM ëª¨ë¸: âŒ")
        
        # ê°„ë‹¨í•œ ì¶”ë¡  í…ŒìŠ¤íŠ¸ (ë”ë¯¸ ë°ì´í„°)
        print("\nğŸ§  ê°„ë‹¨í•œ ì¶”ë¡  í…ŒìŠ¤íŠ¸:")
        try:
            # ë”ë¯¸ ì´ë¯¸ì§€ í…ì„œ ìƒì„± (ì‘ì€ í¬ê¸°)
            dummy_person = torch.randn(1, 3, 64, 48)  # ì‘ì€ í¬ê¸°ë¡œ í…ŒìŠ¤íŠ¸
            dummy_cloth = torch.randn(1, 3, 64, 48)
            
            print(f"  - ë”ë¯¸ ë°ì´í„° ìƒì„±: âœ… (Person: {dummy_person.shape}, Cloth: {dummy_cloth.shape})")
            
            # GMM ëª¨ë¸ë¡œ ê°„ë‹¨í•œ ìˆœì „íŒŒ í…ŒìŠ¤íŠ¸
            if hasattr(step_04, 'gmm_model') and step_04.gmm_model is not None:
                try:
                    with torch.no_grad():
                        # GMM ëª¨ë¸ì€ person + cloth 6ì±„ë„ ì…ë ¥ì„ ë°›ìŒ
                        gmm_input = torch.cat([dummy_person, dummy_cloth], dim=1)
                        gmm_output = step_04.gmm_model(gmm_input)
                        print(f"  - GMM ì¶”ë¡ : âœ… (ì¶œë ¥ í¬ê¸°: {gmm_output.shape})")
                except Exception as e:
                    print(f"  - GMM ì¶”ë¡ : âš ï¸ (ì—ëŸ¬: {str(e)[:50]}...)")
            
            print("âœ… ê¸°ë³¸ ì¶”ë¡  í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
            
        except Exception as e:
            print(f"âš ï¸ ì¶”ë¡  í…ŒìŠ¤íŠ¸ ì¤‘ ì˜¤ë¥˜: {e}")
        
        # ìµœì¢… ê²°ê³¼
        print(f"\nğŸ ìµœì¢… ê²°ê³¼:")
        print(f"  ğŸ“¦ í´ë˜ìŠ¤ ë¡œë”©: âœ…")
        print(f"  ğŸ—ï¸ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±: âœ…") 
        print(f"  ğŸ”„ ì´ˆê¸°í™”: {'âœ…' if success else 'âŒ'}")
        print(f"  ğŸ§  AI ëª¨ë¸ ë¡œë”©: {'âœ…' if hasattr(step_04, 'gmm_model') and step_04.gmm_model else 'âŒ'}")
        print(f"  ğŸš« torch.jit ì‚¬ìš©: âŒ (ì™„ì „ ë¹„í™œì„±í™”)")
        
        if success and hasattr(step_04, 'gmm_model') and step_04.gmm_model:
            print(f"\nğŸ‰ GeometricMatchingStep ì™„ì „ ì„±ê³µ!")
            print(f"   torch.jit ì—†ì´ ìˆœìˆ˜ PyTorchë¡œ AI ëª¨ë¸ ë¡œë”© ë° ì‹¤í–‰ ê°€ëŠ¥!")
            return True
        else:
            print(f"\nâš ï¸ ì¼ë¶€ ë¬¸ì œê°€ ìˆì§€ë§Œ ê¸°ë³¸ êµ¬ì¡°ëŠ” ì‘ë™ ì¤‘")
            return False
            
    except Exception as e:
        print(f"âŒ GeometricMatchingStep í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_direct_model_usage():
    """ì§ì ‘ GMM ëª¨ë¸ ì‚¬ìš© í…ŒìŠ¤íŠ¸"""
    print("\n" + "="*60)
    print("ğŸ”¬ ì§ì ‘ GMM ëª¨ë¸ ì‚¬ìš© í…ŒìŠ¤íŠ¸")
    print("="*60)
    
    try:
        # ì§ì ‘ ëª¨ë¸ íŒŒì¼ ë¡œë”©
        model_path = "backend/ai_models/step_04_geometric_matching/gmm_final.pth"
        device = "mps" if torch.backends.mps.is_available() else "cpu"
        
        print(f"ğŸ“ ëª¨ë¸ ê²½ë¡œ: {model_path}")
        print(f"ğŸ–¥ï¸ ë””ë°”ì´ìŠ¤: {device}")
        
        # torch.jit ì—†ì´ ì§ì ‘ ë¡œë”©
        model_data = torch.load(model_path, map_location=device)
        print(f"âœ… ëª¨ë¸ ë¡œë”© ì„±ê³µ: {type(model_data)}")
        
        # ëª¨ë¸ ì •ë³´ ì¶œë ¥
        if isinstance(model_data, dict):
            print(f"ğŸ“‹ ë”•ì…”ë„ˆë¦¬ í‚¤ë“¤: {list(model_data.keys())[:5]}...")
            if 'state_dict' in model_data:
                print(f"ğŸ”§ state_dict í‚¤ ìˆ˜: {len(model_data['state_dict'])}")
        
        print("âœ… ì§ì ‘ ëª¨ë¸ ì‚¬ìš© ê°€ëŠ¥ í™•ì¸!")
        return True
        
    except Exception as e:
        print(f"âŒ ì§ì ‘ ëª¨ë¸ ì‚¬ìš© ì‹¤íŒ¨: {e}")
        return False

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("ğŸ M3 Max conda í™˜ê²½ì—ì„œ GMM torch.jit ì—†ì´ í…ŒìŠ¤íŠ¸")
    print("ğŸš« torch.jit ì™„ì „ ë¹„í™œì„±í™” ëª¨ë“œ")
    
    # 1. GeometricMatchingStep í´ë˜ìŠ¤ í…ŒìŠ¤íŠ¸
    step_test_ok = test_geometric_matching_step()
    
    # 2. ì§ì ‘ ëª¨ë¸ ì‚¬ìš© í…ŒìŠ¤íŠ¸  
    direct_test_ok = test_direct_model_usage()
    
    print(f"\nğŸ† ì „ì²´ í…ŒìŠ¤íŠ¸ ê²°ê³¼:")
    print(f"  ğŸ—ï¸ Step í´ë˜ìŠ¤: {'âœ…' if step_test_ok else 'âŒ'}")
    print(f"  ğŸ”¬ ì§ì ‘ ëª¨ë¸: {'âœ…' if direct_test_ok else 'âŒ'}")
    
    if step_test_ok and direct_test_ok:
        print(f"\nğŸ‰ ì™„ì „ ì„±ê³µ! torch.jit ì—†ì´ GMM ëª¨ë¸ ì™„ë²½ ì‘ë™!")
        print(f"ğŸš€ ì´ì œ ì‹¤ì œ ì„œë¹„ìŠ¤ì—ì„œ ë°”ë¡œ ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤!")
    elif direct_test_ok:
        print(f"\nğŸ”„ ë¶€ë¶„ ì„±ê³µ! ì§ì ‘ ëª¨ë¸ ë¡œë”©ì€ ì‘ë™í•˜ë¯€ë¡œ Step í´ë˜ìŠ¤ ê°œì„  í•„ìš”")
    else:
        print(f"\nâš ï¸ ì¶”ê°€ ë””ë²„ê¹…ì´ í•„ìš”í•©ë‹ˆë‹¤.")

if __name__ == "__main__":
    main()  