#!/usr/bin/env python3
"""
ğŸ”§ MyCloset AI - ëª¨ë¸ ê²½ë¡œ ì„¤ì • ì—…ë°ì´íŠ¸ ìŠ¤í¬ë¦½íŠ¸
conda í™˜ê²½ì—ì„œ ì‹¤í–‰ ê¶Œì¥

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” ë‹¤ìŒì„ ìˆ˜í–‰í•©ë‹ˆë‹¤:
1. í˜„ì¬ ì¡´ì¬í•˜ëŠ” ëª¨ë¸ íŒŒì¼ ìŠ¤ìº”
2. auto_model_detector.py ê²½ë¡œ ì—…ë°ì´íŠ¸
3. ê° Step í´ë˜ìŠ¤ì˜ ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œ ìˆ˜ì •
4. DeviceManager conda_env ì†ì„± ì˜¤ë¥˜ ìˆ˜ì •
"""

import os
import sys
import shutil
from pathlib import Path
from typing import Dict, List, Optional
import re

def check_conda_env():
    """conda í™˜ê²½ í™•ì¸"""
    conda_env = os.environ.get('CONDA_DEFAULT_ENV')
    if conda_env != 'mycloset-ai':
        print(f"âš ï¸  ê¶Œì¥ conda í™˜ê²½: mycloset-ai")
        print(f"   í˜„ì¬ í™˜ê²½: {conda_env or 'None'}")
        print("   í™œì„±í™”: conda activate mycloset-ai")
        return False
    return True

def scan_existing_models(ai_models_root: Path) -> Dict[str, List[Path]]:
    """í˜„ì¬ ì¡´ì¬í•˜ëŠ” ëª¨ë¸ íŒŒì¼ë“¤ ìŠ¤ìº”"""
    print("ğŸ” í˜„ì¬ ëª¨ë¸ íŒŒì¼ ìŠ¤ìº” ì¤‘...")
    
    model_extensions = {'.pth', '.bin', '.ckpt', '.pt', '.safetensors'}
    found_models = {}
    
    for step_num in range(1, 9):
        step_name = f"step_{step_num:02d}"
        found_models[step_name] = []
        
        # ì—¬ëŸ¬ ê²½ë¡œì—ì„œ ëª¨ë¸ ì°¾ê¸°
        search_paths = [
            ai_models_root,
            ai_models_root / "checkpoints",
            ai_models_root / "organized",
        ]
        
        for search_path in search_paths:
            if not search_path.exists():
                continue
                
            for file_path in search_path.rglob("*"):
                if (file_path.suffix.lower() in model_extensions and 
                    file_path.is_file() and
                    step_name in str(file_path).lower()):
                    found_models[step_name].append(file_path)
    
    # ì „ì²´ ëª¨ë¸ë„ ìŠ¤ìº” (Step ë¶„ë¥˜ë˜ì§€ ì•Šì€ ê²ƒë“¤)
    found_models["general"] = []
    for file_path in ai_models_root.rglob("*"):
        if (file_path.suffix.lower() in model_extensions and 
            file_path.is_file() and
            not any(f"step_{i:02d}" in str(file_path).lower() for i in range(1, 9))):
            found_models["general"].append(file_path)
    
    return found_models

def update_auto_model_detector(backend_root: Path, found_models: Dict[str, List[Path]]):
    """auto_model_detector.py ê²½ë¡œ ì—…ë°ì´íŠ¸"""
    print("ğŸ”„ auto_model_detector.py ì—…ë°ì´íŠ¸ ì¤‘...")
    
    detector_file = backend_root / "app/ai_pipeline/utils/auto_model_detector.py"
    
    if not detector_file.exists():
        print(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {detector_file}")
        return False
    
    # ë°±ì—… ìƒì„±
    backup_file = detector_file.with_suffix('.py.backup')
    shutil.copy2(detector_file, backup_file)
    print(f"  ğŸ’¾ ë°±ì—… ìƒì„±: {backup_file}")
    
    # ìƒˆë¡œìš´ ê²½ë¡œ ì„¤ì • ìƒì„±
    organized_paths = []
    for step_name, model_files in found_models.items():
        if step_name != "general" and model_files:
            # ì²« ë²ˆì§¸ ëª¨ë¸ì˜ ë””ë ‰í† ë¦¬ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ê²½ë¡œ ìƒì„±
            model_dir = model_files[0].parent
            organized_paths.append(str(model_dir.resolve()))
    
    # íŒŒì¼ ë‚´ìš© ì½ê¸°
    with open(detector_file, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # ENHANCED_SEARCH_PATHS ì—…ë°ì´íŠ¸
    new_paths_code = f"""
# ==============================================
# ğŸ”§ MyCloset AI ì—…ë°ì´íŠ¸ëœ ëª¨ë¸ ê²½ë¡œ (ìë™ ìƒì„±)
# ==============================================

# ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ëª¨ë¸ ê²½ë¡œë“¤
UPDATED_MODEL_PATHS = [
{chr(10).join(f'    "{path}",' for path in organized_paths)}
]

# ê¸°ì¡´ ê²½ë¡œì™€ ë³‘í•©
if 'ENHANCED_SEARCH_PATHS' in locals():
    ENHANCED_SEARCH_PATHS.extend(UPDATED_MODEL_PATHS)
    # ì¤‘ë³µ ì œê±°
    ENHANCED_SEARCH_PATHS = list(set(ENHANCED_SEARCH_PATHS))
else:
    ENHANCED_SEARCH_PATHS = UPDATED_MODEL_PATHS
"""
    
    # íŒŒì¼ ëì— ì¶”ê°€
    with open(detector_file, 'w', encoding='utf-8') as f:
        f.write(content + new_paths_code)
    
    print(f"  âœ… {len(organized_paths)}ê°œ ê²½ë¡œ ì¶”ê°€ë¨")
    return True

def fix_device_manager_conda_env(backend_root: Path):
    """DeviceManager conda_env ì†ì„± ì˜¤ë¥˜ ìˆ˜ì •"""
    print("ğŸ”§ DeviceManager conda_env ì†ì„± ì˜¤ë¥˜ ìˆ˜ì • ì¤‘...")
    
    # ê°€ëŠ¥í•œ DeviceManager íŒŒì¼ë“¤
    device_manager_files = [
        backend_root / "app/core/gpu_config.py",
        backend_root / "app/ai_pipeline/utils/utils.py",
        backend_root / "app/ai_pipeline/utils/model_loader.py",
    ]
    
    fixed_count = 0
    
    for file_path in device_manager_files:
        if not file_path.exists():
            continue
            
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # conda_env ì†ì„± ê´€ë ¨ ì˜¤ë¥˜ ìˆ˜ì •
            original_content = content
            
            # íŒ¨í„´ 1: conda_env ì†ì„± ëˆ„ë½ ìˆ˜ì •
            if "class DeviceManager" in content:
                # __init__ ë©”ì„œë“œì— conda_env ì†ì„± ì¶”ê°€
                content = re.sub(
                    r'(class DeviceManager[^:]*:.*?def __init__\(self[^)]*\):.*?)(\n)',
                    r'\1\n        self.conda_env = os.environ.get("CONDA_DEFAULT_ENV", "none")\2',
                    content,
                    flags=re.DOTALL
                )
                
                # conda_env ì‚¬ìš© ë¶€ë¶„ ì•ˆì „í•˜ê²Œ ìˆ˜ì •
                content = re.sub(
                    r'(\w+)\.conda_env',
                    r'getattr(\1, "conda_env", os.environ.get("CONDA_DEFAULT_ENV", "none"))',
                    content
                )
            
            # íŒ¨í„´ 2: ì¼ë°˜ì ì¸ conda_env ì ‘ê·¼ ìˆ˜ì •
            content = re.sub(
                r'([a-zA-Z_][a-zA-Z0-9_]*)\.conda_env',
                r'getattr(\1, "conda_env", os.environ.get("CONDA_DEFAULT_ENV", "none"))',
                content
            )
            
            if content != original_content:
                # ë°±ì—… ìƒì„±
                backup_file = file_path.with_suffix(file_path.suffix + '.backup')
                shutil.copy2(file_path, backup_file)
                
                # ìˆ˜ì •ëœ ë‚´ìš© ì €ì¥
                with open(file_path, 'w', encoding='utf-8') as f:
                    f.write(content)
                
                print(f"  âœ… {file_path.name} ìˆ˜ì • ì™„ë£Œ")
                fixed_count += 1
        
        except Exception as e:
            print(f"  âš ï¸  {file_path.name} ìˆ˜ì • ì‹¤íŒ¨: {e}")
    
    return fixed_count

def update_step_checkpoint_paths(backend_root: Path, found_models: Dict[str, List[Path]]):
    """Step í´ë˜ìŠ¤ë“¤ì˜ ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œ ì—…ë°ì´íŠ¸"""
    print("ğŸ”„ Step í´ë˜ìŠ¤ ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œ ì—…ë°ì´íŠ¸ ì¤‘...")
    
    steps_dir = backend_root / "app/ai_pipeline/steps"
    
    if not steps_dir.exists():
        print(f"âŒ Steps ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ: {steps_dir}")
        return False
    
    updated_count = 0
    
    for step_num in range(1, 9):
        step_name = f"step_{step_num:02d}"
        step_file = steps_dir / f"{step_name}_*.py"
        
        # ì‹¤ì œ íŒŒì¼ ì°¾ê¸°
        step_files = list(steps_dir.glob(f"*{step_name}*.py"))
        
        for step_file in step_files:
            if not step_file.exists():
                continue
                
            try:
                with open(step_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                original_content = content
                
                # ì´ Stepì— í•´ë‹¹í•˜ëŠ” ëª¨ë¸ë“¤
                step_models = found_models.get(step_name, [])
                
                if step_models:
                    # ê°€ì¥ í° ëª¨ë¸ì„ ì£¼ ëª¨ë¸ë¡œ ì‚¬ìš©
                    primary_model = max(step_models, key=lambda x: x.stat().st_size)
                    
                    # ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œ íŒ¨í„´ ì—…ë°ì´íŠ¸
                    model_path_patterns = [
                        (r'DEFAULT_CHECKPOINT_PATH\s*=\s*["\'][^"\']*["\']', 
                         f'DEFAULT_CHECKPOINT_PATH = "{primary_model.resolve()}"'),
                        (r'self\.checkpoint_path\s*=\s*["\'][^"\']*["\']',
                         f'self.checkpoint_path = "{primary_model.resolve()}"'),
                        (r'checkpoint_path\s*=\s*["\'][^"\']*["\']',
                         f'checkpoint_path = "{primary_model.resolve()}"'),
                    ]
                    
                    for pattern, replacement in model_path_patterns:
                        content = re.sub(pattern, replacement, content)
                    
                    # ëª¨ë¸ ë¡œë”© ê´€ë ¨ ì˜¤ë¥˜ ì²˜ë¦¬ ê°œì„ 
                    if "ModelLoader" in content:
                        # ModelLoader ì¸í„°í˜ì´ìŠ¤ ì„¤ì • ì˜¤ë¥˜ ìˆ˜ì •
                        content = re.sub(
                            r'(self\.model_loader\.setup_interface\([^)]*\))',
                            r'try:\n            \1\n        except AttributeError as e:\n            self.logger.warning(f"ModelLoader ì¸í„°í˜ì´ìŠ¤ ì„¤ì • ì‹¤íŒ¨: {e}")',
                            content
                        )
                
                if content != original_content:
                    # ë°±ì—… ìƒì„±
                    backup_file = step_file.with_suffix('.py.backup')
                    shutil.copy2(step_file, backup_file)
                    
                    # ìˆ˜ì •ëœ ë‚´ìš© ì €ì¥
                    with open(step_file, 'w', encoding='utf-8') as f:
                        f.write(content)
                    
                    print(f"  âœ… {step_file.name} ì—…ë°ì´íŠ¸ ì™„ë£Œ")
                    updated_count += 1
                    
            except Exception as e:
                print(f"  âš ï¸  {step_file.name} ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
    
    return updated_count

def create_model_registry_file(ai_models_root: Path, found_models: Dict[str, List[Path]]):
    """ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬ íŒŒì¼ ìƒì„±"""
    print("ğŸ“ ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬ íŒŒì¼ ìƒì„± ì¤‘...")
    
    registry_file = ai_models_root / "model_registry.py"
    
    registry_content = '''#!/usr/bin/env python3
"""
ğŸ¤– MyCloset AI - ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬ (ìë™ ìƒì„±)
ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ëª¨ë¸ íŒŒì¼ë“¤ì˜ ê²½ë¡œë¥¼ ê´€ë¦¬í•©ë‹ˆë‹¤.
"""

from pathlib import Path
from typing import Dict, List, Optional

# í”„ë¡œì íŠ¸ ë£¨íŠ¸
PROJECT_ROOT = Path(__file__).parent.parent
AI_MODELS_ROOT = Path(__file__).parent

# ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ëª¨ë¸ë“¤
EXISTING_MODELS = {
'''
    
    total_size = 0
    total_count = 0
    
    for step_name, model_files in found_models.items():
        if not model_files:
            continue
            
        registry_content += f'    "{step_name}": [\n'
        
        for model_file in model_files:
            try:
                file_size = model_file.stat().st_size / (1024 * 1024)  # MB
                total_size += file_size
                total_count += 1
                
                registry_content += f'        {{\n'
                registry_content += f'            "name": "{model_file.name}",\n'
                registry_content += f'            "path": "{model_file.resolve()}",\n'
                registry_content += f'            "size_mb": {file_size:.1f},\n'
                registry_content += f'            "relative_path": "{model_file.relative_to(ai_models_root)}"\n'
                registry_content += f'        }},\n'
            except Exception as e:
                print(f"    âš ï¸  {model_file} ì •ë³´ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
                
        registry_content += '    ],\n'
    
    registry_content += f'''}}

# í†µê³„ ì •ë³´
REGISTRY_STATS = {{
    "total_models": {total_count},
    "total_size_mb": {total_size:.1f},
    "total_size_gb": {total_size / 1024:.1f},
    "steps_with_models": {len([k for k, v in found_models.items() if v])},
    "generated_on": "$(date +'%Y-%m-%d %H:%M:%S')"
}}

def get_model_path(step_name: str, model_name: Optional[str] = None) -> Optional[Path]:
    """ëª¨ë¸ ê²½ë¡œ ë°˜í™˜"""
    if step_name not in EXISTING_MODELS:
        return None
    
    step_models = EXISTING_MODELS[step_name]
    if not step_models:
        return None
    
    if model_name:
        for model in step_models:
            if model["name"] == model_name:
                return Path(model["path"])
    
    # ê°€ì¥ í° ëª¨ë¸ ë°˜í™˜ (ê¸°ë³¸ê°’)
    largest_model = max(step_models, key=lambda x: x["size_mb"])
    return Path(largest_model["path"])

def get_all_model_paths() -> Dict[str, str]:
    """ëª¨ë“  ëª¨ë¸ ê²½ë¡œ ë°˜í™˜"""
    all_paths = {{}}
    for step_name, models in EXISTING_MODELS.items():
        for model in models:
            all_paths[f"{{step_name}}_{{model['name']}}"] = model["path"]
    return all_paths

if __name__ == "__main__":
    print("ğŸ¤– MyCloset AI ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬")
    print(f"ğŸ“Š ì´ ëª¨ë¸: {{REGISTRY_STATS['total_models']}}ê°œ")
    print(f"ğŸ“¦ ì´ í¬ê¸°: {{REGISTRY_STATS['total_size_gb']:.1f}}GB")
    
    for step_name, models in EXISTING_MODELS.items():
        if models:
            print(f"  {{step_name}}: {{len(models)}}ê°œ ëª¨ë¸")
'''
    
    with open(registry_file, 'w', encoding='utf-8') as f:
        f.write(registry_content)
    
    print(f"  âœ… {registry_file} ìƒì„± ì™„ë£Œ")
    print(f"  ğŸ“Š ì´ {total_count}ê°œ ëª¨ë¸, {total_size/1024:.1f}GB")
    
    return registry_file

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸ”§ MyCloset AI ëª¨ë¸ ê²½ë¡œ ì„¤ì • ì—…ë°ì´íŠ¸ ì‹œì‘...")
    
    # conda í™˜ê²½ í™•ì¸
    if not check_conda_env():
        print("âš ï¸  conda í™˜ê²½ í™•ì¸ ê¶Œì¥")
    
    # í”„ë¡œì íŠ¸ ê²½ë¡œ ì„¤ì •
    project_root = Path("/Users/gimdudeul/MVP/mycloset-ai")
    backend_root = project_root / "backend"
    ai_models_root = backend_root / "ai_models"
    
    if not ai_models_root.exists():
        print(f"âŒ AI ëª¨ë¸ ë””ë ‰í† ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤: {ai_models_root}")
        return False
    
    print(f"ğŸ“ í”„ë¡œì íŠ¸ ë£¨íŠ¸: {project_root}")
    print(f"ğŸ§  AI ëª¨ë¸ ë£¨íŠ¸: {ai_models_root}")
    
    try:
        # 1. í˜„ì¬ ëª¨ë¸ ìŠ¤ìº”
        found_models = scan_existing_models(ai_models_root)
        
        total_models = sum(len(models) for models in found_models.values())
        print(f"ğŸ” ì´ {total_models}ê°œ ëª¨ë¸ íŒŒì¼ ë°œê²¬")
        
        for step_name, models in found_models.items():
            if models:
                print(f"  {step_name}: {len(models)}ê°œ")
        
        # 2. auto_model_detector ì—…ë°ì´íŠ¸
        if update_auto_model_detector(backend_root, found_models):
            print("âœ… auto_model_detector ì—…ë°ì´íŠ¸ ì™„ë£Œ")
        
        # 3. DeviceManager ì˜¤ë¥˜ ìˆ˜ì •
        fixed_count = fix_device_manager_conda_env(backend_root)
        print(f"âœ… DeviceManager ìˆ˜ì •: {fixed_count}ê°œ íŒŒì¼")
        
        # 4. Step í´ë˜ìŠ¤ ì—…ë°ì´íŠ¸
        step_count = update_step_checkpoint_paths(backend_root, found_models)
        print(f"âœ… Step í´ë˜ìŠ¤ ì—…ë°ì´íŠ¸: {step_count}ê°œ íŒŒì¼")
        
        # 5. ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬ ìƒì„±
        registry_file = create_model_registry_file(ai_models_root, found_models)
        print(f"âœ… ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬ ìƒì„±: {registry_file}")
        
        print("\nğŸ‰ ëª¨ë¸ ê²½ë¡œ ì„¤ì • ì—…ë°ì´íŠ¸ ì™„ë£Œ!")
        print("\nğŸ“‹ ë‹¤ìŒ ë‹¨ê³„:")
        print("  1. ì„œë²„ ì¬ì‹œì‘: cd backend && python app/main.py")
        print("  2. ëª¨ë¸ ê²€ì¦: python ai_models/model_registry.py")
        print("  3. API í…ŒìŠ¤íŠ¸: curl http://localhost:8000/api/ai/status")
        
        return True
        
    except KeyboardInterrupt:
        print("\nâ¹ï¸  ì‚¬ìš©ì ì¤‘ë‹¨")
        return False
    except Exception as e:
        print(f"\nâŒ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)