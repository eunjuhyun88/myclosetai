#!/usr/bin/env python3
"""
ğŸ”§ ModelLoader í•µì‹¬ ë©”ì„œë“œ ì¶”ê°€ íŒ¨ì¹˜
get_model(), get_model_for_step() ë“± í•„ìˆ˜ ë©”ì„œë“œ êµ¬í˜„
"""

import sys
from pathlib import Path
from typing import Optional, Any, Dict, List

# í”„ë¡œì íŠ¸ ê²½ë¡œ ì„¤ì •
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))
sys.path.insert(0, str(project_root / "backend"))

def patch_modelloader():
    """ModelLoaderì— ëˆ„ë½ëœ ë©”ì„œë“œë“¤ íŒ¨ì¹˜"""
    
    try:
        from backend.app.ai_pipeline.utils.model_loader import ModelLoader
        
        print("ğŸ”§ ModelLoader íŒ¨ì¹˜ ì ìš© ì¤‘...")
        
        # 1. get_model ë©”ì„œë“œ ì¶”ê°€
        def get_model(self, model_name: str) -> Optional[Any]:
            """ì´ë¯¸ ë¡œë”©ëœ ëª¨ë¸ ë°˜í™˜ (í•µì‹¬ ë©”ì„œë“œ!)"""
            try:
                # 1ë‹¨ê³„: ìºì‹œì—ì„œ ì°¾ê¸°
                if hasattr(self, 'model_cache'):
                    for cache_key, model in self.model_cache.items():
                        if model_name in cache_key:
                            self.logger.debug(f"âœ… ìºì‹œì—ì„œ ëª¨ë¸ ë°œê²¬: {model_name}")
                            return model
                
                # 2ë‹¨ê³„: SafeModelServiceì—ì„œ ì°¾ê¸°
                if hasattr(self, 'safe_model_service'):
                    model = self.safe_model_service.call_model(model_name)
                    if model:
                        self.logger.debug(f"âœ… SafeModelServiceì—ì„œ ëª¨ë¸ ë°œê²¬: {model_name}")
                        return model
                
                # 3ë‹¨ê³„: ìë™ ë¡œë”© ì‹œë„
                if hasattr(self, 'load_model_sync'):
                    model = self.load_model_sync(model_name)
                    if model:
                        self.logger.info(f"âœ… ìë™ ë¡œë”© ì„±ê³µ: {model_name}")
                        return model
                elif hasattr(self, 'load_model_async'):
                    # ë¹„ë™ê¸°ë¥¼ ë™ê¸°ë¡œ ë³€í™˜
                    import asyncio
                    try:
                        model = asyncio.run(self.load_model_async(model_name))
                        if model:
                            self.logger.info(f"âœ… ë¹„ë™ê¸° ë¡œë”© ì„±ê³µ: {model_name}")
                            return model
                    except Exception as e:
                        self.logger.warning(f"âš ï¸ ë¹„ë™ê¸° ë¡œë”© ì‹¤íŒ¨: {e}")
                
                self.logger.warning(f"âš ï¸ ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {model_name}")
                return None
                
            except Exception as e:
                self.logger.error(f"âŒ get_model ì‹¤íŒ¨ {model_name}: {e}")
                return None
        
        # 2. get_model_for_step ë©”ì„œë“œ ì¶”ê°€
        def get_model_for_step(self, step_name: str) -> Optional[Any]:
            """Stepë³„ ìµœì  ëª¨ë¸ ë°˜í™˜ (í•µì‹¬ ë©”ì„œë“œ!)"""
            try:
                # Stepë³„ íŒ¨í„´ ë§¤í•‘
                step_patterns = {
                    'HumanParsingStep': ['human_parsing', 'parsing', 'graphonomy', 'schp', 'atr'],
                    'PoseEstimationStep': ['pose', 'openpose', 'body_pose'],
                    'ClothSegmentationStep': ['cloth_segmentation', 'u2net', 'segmentation'],
                    'VirtualFittingStep': ['virtual_fitting', 'diffusion', 'ootd', 'viton', 'stable'],
                    'GeometricMatchingStep': ['geometric', 'matching', 'gmm'],
                    'ClothWarpingStep': ['cloth_warping', 'warping', 'tom'],
                    'PostProcessingStep': ['post_processing', 'esrgan', 'super_resolution'],
                    'QualityAssessmentStep': ['quality', 'assessment', 'clip']
                }
                
                if step_name not in step_patterns:
                    self.logger.warning(f"âš ï¸ ì•Œ ìˆ˜ ì—†ëŠ” Step: {step_name}")
                    return None
                
                patterns = step_patterns[step_name]
                
                # 1ë‹¨ê³„: step_model_mappingì—ì„œ ì°¾ê¸°
                if hasattr(self, 'step_model_mapping') and step_name in self.step_model_mapping:
                    step_models = self.step_model_mapping[step_name]
                    if step_models:
                        best_model_name = step_models[0] if isinstance(step_models, list) else step_models
                        model = self.get_model(best_model_name)
                        if model:
                            self.logger.info(f"âœ… Step ë§¤í•‘ì—ì„œ ëª¨ë¸ ë°œê²¬: {best_model_name}")
                            return model
                
                # 2ë‹¨ê³„: ë“±ë¡ëœ ëª¨ë¸ë“¤ì—ì„œ íŒ¨í„´ ë§¤ì¹­
                all_models = []
                if hasattr(self, 'model_configs'):
                    all_models.extend(self.model_configs.keys())
                if hasattr(self, 'detected_model_registry'):
                    all_models.extend(self.detected_model_registry.keys())
                if hasattr(self, 'model_cache'):
                    all_models.extend([key.split('_')[0] for key in self.model_cache.keys()])
                
                # íŒ¨í„´ ë§¤ì¹­ìœ¼ë¡œ ìµœì  ëª¨ë¸ ì°¾ê¸°
                for model_name in all_models:
                    model_name_lower = model_name.lower()
                    if any(pattern in model_name_lower for pattern in patterns):
                        model = self.get_model(model_name)
                        if model:
                            self.logger.info(f"âœ… íŒ¨í„´ ë§¤ì¹­ìœ¼ë¡œ ëª¨ë¸ ë°œê²¬: {model_name} for {step_name}")
                            return model
                
                self.logger.warning(f"âš ï¸ {step_name}ìš© ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ")
                return None
                
            except Exception as e:
                self.logger.error(f"âŒ get_model_for_step ì‹¤íŒ¨ {step_name}: {e}")
                return None
        
        # 3. list_available_models ë©”ì„œë“œ ì¶”ê°€
        def list_available_models(self) -> List[str]:
            """ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë“  ëª¨ë¸ ëª©ë¡ ë°˜í™˜"""
            try:
                models = set()
                
                # ìºì‹œëœ ëª¨ë¸ë“¤
                if hasattr(self, 'model_cache'):
                    for cache_key in self.model_cache.keys():
                        # cache_keyì—ì„œ ëª¨ë¸ëª… ì¶”ì¶œ
                        model_name = cache_key.split('_')[0]
                        models.add(model_name)
                
                # ë“±ë¡ëœ ëª¨ë¸ë“¤
                if hasattr(self, 'model_configs'):
                    models.update(self.model_configs.keys())
                
                # íƒì§€ëœ ëª¨ë¸ë“¤
                if hasattr(self, 'detected_model_registry'):
                    models.update(self.detected_model_registry.keys())
                
                # SafeModelServiceì˜ ëª¨ë¸ë“¤
                if hasattr(self, 'safe_model_service') and hasattr(self.safe_model_service, 'models'):
                    models.update(self.safe_model_service.models.keys())
                
                return sorted(list(models))
                
            except Exception as e:
                self.logger.error(f"âŒ list_available_models ì‹¤íŒ¨: {e}")
                return []
        
        # 4. load_model_sync ë©”ì„œë“œ ê°•í™” (ì´ë¯¸ ìˆë‹¤ë©´ íŒ¨ìŠ¤)
        def load_model_sync(self, model_name: str, **kwargs) -> Optional[Any]:
            """ë™ê¸° ëª¨ë¸ ë¡œë“œ (ê°•í™” ë²„ì „)"""
            try:
                # ê¸°ì¡´ load_modelì´ ìˆë‹¤ë©´ ì‚¬ìš©
                if hasattr(self, 'load_model') and hasattr(self.load_model, '__call__'):
                    return self.load_model(model_name, **kwargs)
                
                # ë¹„ë™ê¸°ë¥¼ ë™ê¸°ë¡œ ë³€í™˜
                if hasattr(self, 'load_model_async'):
                    import asyncio
                    try:
                        return asyncio.run(self.load_model_async(model_name, **kwargs))
                    except Exception as e:
                        self.logger.warning(f"âš ï¸ ë¹„ë™ê¸°->ë™ê¸° ë³€í™˜ ì‹¤íŒ¨: {e}")
                
                self.logger.error(f"âŒ ì‚¬ìš© ê°€ëŠ¥í•œ ë¡œë”© ë©”ì„œë“œ ì—†ìŒ: {model_name}")
                return None
                        
            except Exception as e:
                self.logger.error(f"âŒ load_model_sync ì‹¤íŒ¨ {model_name}: {e}")
                return None
        
        # ë©”ì„œë“œ ë™ì  ì¶”ê°€
        methods_added = []
        
        if not hasattr(ModelLoader, 'get_model'):
            ModelLoader.get_model = get_model
            methods_added.append('get_model')
        
        if not hasattr(ModelLoader, 'get_model_for_step'):
            ModelLoader.get_model_for_step = get_model_for_step
            methods_added.append('get_model_for_step')
        
        if not hasattr(ModelLoader, 'list_available_models'):
            ModelLoader.list_available_models = list_available_models
            methods_added.append('list_available_models')
        
        if not hasattr(ModelLoader, 'load_model_sync'):
            ModelLoader.load_model_sync = load_model_sync
            methods_added.append('load_model_sync')
        
        print(f"âœ… ModelLoader íŒ¨ì¹˜ ì™„ë£Œ! ì¶”ê°€ëœ ë©”ì„œë“œ: {', '.join(methods_added)}")
        return True
        
    except Exception as e:
        print(f"âŒ ModelLoader íŒ¨ì¹˜ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_patched_modelloader():
    """íŒ¨ì¹˜ëœ ModelLoader í…ŒìŠ¤íŠ¸"""
    
    print("\nğŸ§ª íŒ¨ì¹˜ëœ ModelLoader í…ŒìŠ¤íŠ¸...")
    
    try:
        from backend.app.ai_pipeline.utils.model_loader import ModelLoader
        
        loader = ModelLoader()
        
        # ë©”ì„œë“œ ì¡´ì¬ í™•ì¸
        required_methods = ['get_model', 'get_model_for_step', 'list_available_models', 'load_model_sync']
        
        for method in required_methods:
            if hasattr(loader, method):
                print(f"   âœ… {method}: ì¡´ì¬")
            else:
                print(f"   âŒ {method}: ì—†ìŒ")
        
        # ì‹¤ì œ ë™ì‘ í…ŒìŠ¤íŠ¸
        if hasattr(loader, 'list_available_models'):
            try:
                models = loader.list_available_models()
                print(f"   ğŸ“¦ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸: {len(models)}ê°œ")
                if models:
                    print(f"      ì˜ˆì‹œ: {models[:3]}")
            except Exception as e:
                print(f"   âš ï¸ list_available_models í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        
        if hasattr(loader, 'get_model_for_step'):
            test_steps = ['HumanParsingStep', 'VirtualFittingStep', 'ClothSegmentationStep']
            for step in test_steps:
                try:
                    model = loader.get_model_for_step(step)
                    status = "âœ…" if model else "â“"
                    model_type = type(model).__name__ if model else 'None'
                    print(f"   {status} {step}: {model_type}")
                except Exception as e:
                    print(f"   âŒ {step}: ì˜¤ë¥˜ - {e}")
        
        return True
        
    except Exception as e:
        print(f"âŒ íŒ¨ì¹˜ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        return False

def verify_auto_detector_integration():
    """Auto Detectorì™€ ModelLoader ì—°ë™ í™•ì¸"""
    
    print("\nğŸ” Auto Detector â†” ModelLoader ì—°ë™ ê²€ì¦...")
    
    try:
        from backend.app.ai_pipeline.utils.model_loader import ModelLoader
        
        # 1. ModelLoader ìƒì„±
        loader = ModelLoader()
        
        # 2. Auto Detectorì—ì„œ ë°œê²¬ëœ ëª¨ë¸ë“¤ì´ ModelLoaderì—ì„œ ì ‘ê·¼ ê°€ëŠ¥í•œì§€ í™•ì¸
        known_models = [
            'human_parsing_graphonomy',
            'cloth_segmentation_u2net', 
            'virtual_fitting_ootdiffusion',
            'pose_estimation_openpose'
        ]
        
        integration_results = {}
        
        for model_name in known_models:
            try:
                model = loader.get_model(model_name)
                integration_results[model_name] = {
                    'accessible': model is not None,
                    'type': type(model).__name__ if model else 'None'
                }
            except Exception as e:
                integration_results[model_name] = {
                    'accessible': False,
                    'error': str(e)
                }
        
        # ê²°ê³¼ ì¶œë ¥
        successful_integrations = 0
        for model_name, result in integration_results.items():
            if result['accessible']:
                print(f"   âœ… {model_name}: {result['type']}")
                successful_integrations += 1
            else:
                error_msg = result.get('error', 'No model found')
                print(f"   âŒ {model_name}: {error_msg}")
        
        print(f"\nğŸ“Š ì—°ë™ ê²°ê³¼: {successful_integrations}/{len(known_models)} ì„±ê³µ")
        
        return successful_integrations > 0
        
    except Exception as e:
        print(f"âŒ ì—°ë™ ê²€ì¦ ì‹¤íŒ¨: {e}")
        return False

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    
    print("ğŸ”§ ModelLoader í•µì‹¬ ë©”ì„œë“œ íŒ¨ì¹˜ ë° í…ŒìŠ¤íŠ¸...")
    print("=" * 60)
    
    # 1. íŒ¨ì¹˜ ì ìš©
    patch_success = patch_modelloader()
    
    if patch_success:
        # 2. íŒ¨ì¹˜ í…ŒìŠ¤íŠ¸
        test_success = test_patched_modelloader()
        
        if test_success:
            # 3. Auto Detector ì—°ë™ í™•ì¸
            integration_success = verify_auto_detector_integration()
            
            if integration_success:
                print("\nğŸ‰ ì™„ë²½! Auto Detector â†’ ModelLoader ì—°ë™ ì„±ê³µ!")
                print("\nğŸš€ ì´ì œ ì‚¬ìš© ê°€ëŠ¥í•œ ì½”ë“œ:")
                print("   from backend.app.ai_pipeline.utils.model_loader import ModelLoader")
                print("   loader = ModelLoader()")
                print("   model = loader.get_model_for_step('HumanParsingStep')")
                print("   models = loader.list_available_models()")
                
                return True
            else:
                print("\nâš ï¸ íŒ¨ì¹˜ëŠ” ì„±ê³µí–ˆì§€ë§Œ Auto Detector ì—°ë™ì— ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤")
        else:
            print("\nâš ï¸ íŒ¨ì¹˜ëŠ” ì„±ê³µí–ˆì§€ë§Œ í…ŒìŠ¤íŠ¸ì—ì„œ ë¬¸ì œê°€ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤")
    else:
        print("\nâŒ íŒ¨ì¹˜ ì ìš©ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤")
    
    return False

if __name__ == "__main__":
    success = main()
    
    if success:
        print("\nâœ… Auto Detectorê°€ ì°¾ì€ ê²½ë¡œë¥¼ ModelLoaderê°€ ì™„ë²½í•˜ê²Œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!")
    else:
        print("\nğŸ’¡ ì¶”ê°€ ë””ë²„ê¹…ì´ í•„ìš”í•©ë‹ˆë‹¤.")
        print("   ì‹¤í–‰í•´ë³´ì„¸ìš”: python patch_modelloader.py")