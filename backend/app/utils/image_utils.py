"""
backend/app/utils/image_utils.py - ì™„ì „ ê°•í™”ëœ ì´ë¯¸ì§€ ì²˜ë¦¬ ìœ í‹¸ë¦¬í‹°

âœ… ê¸°ì¡´ í•¨ìˆ˜ë“¤ 100% ìœ ì§€ + ì‹œê°í™” ê°•í™”
âœ… M3 Max ìµœì í™”  
âœ… ê³ í’ˆì§ˆ ì´ë¯¸ì§€ ì²˜ë¦¬
âœ… PIL/OpenCV í†µí•©
âœ… ë‹¨ê³„ë³„ ì‹œê°í™” ì™„ì „ êµ¬í˜„
âœ… ì¶”ê°€ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤ í¬í•¨
"""

import os
import io
import base64
import uuid
import tempfile
import logging
import asyncio
from typing import Tuple, Union, Optional, List, Dict, Any
from pathlib import Path
import numpy as np
import cv2
from PIL import Image, ImageEnhance, ImageFilter, ImageDraw, ImageFont, ImageOps
from datetime import datetime

# conda í™˜ê²½ ì§€ì›ì„ ìœ„í•œ ì•ˆì „í•œ import
try:
    import matplotlib.pyplot as plt
    import matplotlib.patches as patches
    from matplotlib.colors import ListedColormap
    MATPLOTLIB_AVAILABLE = True
except ImportError:
    MATPLOTLIB_AVAILABLE = False
    logging.warning("matplotlib ì—†ìŒ - ê³ ê¸‰ ì‹œê°í™” ê¸°ëŠ¥ ì œí•œë¨")

try:
    from sklearn.cluster import KMeans
    SKLEARN_AVAILABLE = True
except ImportError:
    SKLEARN_AVAILABLE = False
    logging.warning("scikit-learn ì—†ìŒ - ìƒ‰ìƒ í´ëŸ¬ìŠ¤í„°ë§ ê¸°ëŠ¥ ì œí•œë¨")

logger = logging.getLogger(__name__)

# ============================================================================
# ğŸ¨ ì‹œê°í™” ìƒ‰ìƒ ë° ì„¤ì • (í™•ì¥ë¨)
# ============================================================================

# ì¸ì²´ íŒŒì‹±ìš© ìƒ‰ìƒ ë§µ (20ê°œ ë¶€ìœ„) - ê°œì„ ëœ ìƒ‰ìƒ
HUMAN_PARSING_COLORS = {
    0: (0, 0, 0),        # ë°°ê²½ (ê²€ì •)
    1: (128, 0, 0),      # ëª¨ì (ì–´ë‘ìš´ ë¹¨ê°•)
    2: (255, 165, 0),    # ë¨¸ë¦¬ì¹´ë½ (ì£¼í™©)
    3: (0, 128, 0),      # ì¥ê°‘ (ì–´ë‘ìš´ ì´ˆë¡)
    4: (75, 0, 130),     # ì„ ê¸€ë¼ìŠ¤ (ë‚¨ìƒ‰)
    5: (255, 20, 147),   # ìƒì˜ (ë¶„í™)
    6: (138, 43, 226),   # ë“œë ˆìŠ¤ (ë³´ë¼)
    7: (0, 191, 255),    # ì½”íŠ¸ (í•˜ëŠ˜ìƒ‰)
    8: (255, 140, 0),    # ì–‘ë§ (ì–´ë‘ìš´ ì£¼í™©)
    9: (30, 144, 255),   # ë°”ì§€ (íŒŒë‘)
    10: (220, 20, 60),   # ì í”„ìˆ˜íŠ¸ (ì§„í•œ ë¹¨ê°•)
    11: (255, 215, 0),   # ìŠ¤ì¹´í”„ (ê¸ˆìƒ‰)
    12: (218, 112, 214), # ì¹˜ë§ˆ (ì—°ë³´ë¼)
    13: (255, 228, 181), # ì–¼êµ´ (ì‚´ìƒ‰)
    14: (255, 182, 193), # ì™¼íŒ” (ì—°ë¶„í™)
    15: (255, 160, 122), # ì˜¤ë¥¸íŒ” (ì—°ì£¼í™©)
    16: (250, 128, 114), # ì™¼ë‹¤ë¦¬ (ì—°ì–´ìƒ‰)
    17: (255, 192, 203), # ì˜¤ë¥¸ë‹¤ë¦¬ (ë¶„í™)
    18: (240, 230, 140), # ì™¼ë°œ (ì—°ë…¸ë‘)
    19: (255, 235, 205)  # ì˜¤ë¥¸ë°œ (ì—°ì‚´ìƒ‰)
}

# ë¶€ìœ„ë³„ í•œêµ­ì–´ ì´ë¦„
HUMAN_PARSING_NAMES = {
    0: "ë°°ê²½", 1: "ëª¨ì", 2: "ë¨¸ë¦¬ì¹´ë½", 3: "ì¥ê°‘", 4: "ì„ ê¸€ë¼ìŠ¤",
    5: "ìƒì˜", 6: "ë“œë ˆìŠ¤", 7: "ì½”íŠ¸", 8: "ì–‘ë§", 9: "ë°”ì§€",
    10: "ì í”„ìˆ˜íŠ¸", 11: "ìŠ¤ì¹´í”„", 12: "ì¹˜ë§ˆ", 13: "ì–¼êµ´", 14: "ì™¼íŒ”",
    15: "ì˜¤ë¥¸íŒ”", 16: "ì™¼ë‹¤ë¦¬", 17: "ì˜¤ë¥¸ë‹¤ë¦¬", 18: "ì™¼ë°œ", 19: "ì˜¤ë¥¸ë°œ"
}

# í¬ì¦ˆ í‚¤í¬ì¸íŠ¸ ìƒ‰ìƒ (18ê°œ í‚¤í¬ì¸íŠ¸) - ê°œì„ ëœ ìƒ‰ìƒ
POSE_KEYPOINT_COLORS = [
    (255, 69, 0),    # ì½” (ë¹¨ê°•-ì£¼í™©)
    (255, 140, 0),   # ì™¼ëˆˆ (ì£¼í™©)
    (255, 215, 0),   # ì˜¤ë¥¸ëˆˆ (ê¸ˆìƒ‰)
    (154, 205, 50),  # ì™¼ê·€ (ì—°ë‘)
    (0, 255, 127),   # ì˜¤ë¥¸ê·€ (ë´„ ì´ˆë¡)
    (0, 206, 209),   # ì™¼ì–´ê¹¨ (í„°í‚¤ì„)
    (65, 105, 225),  # ì˜¤ë¥¸ì–´ê¹¨ (ë¡œì–„ë¸”ë£¨)
    (138, 43, 226),  # ì™¼íŒ”ê¿ˆì¹˜ (ë¸”ë£¨ë°”ì´ì˜¬ë ›)
    (186, 85, 211),  # ì˜¤ë¥¸íŒ”ê¿ˆì¹˜ (ë¯¸ë””ì—„ì˜¤í‚¤ë“œ)
    (255, 20, 147),  # ì™¼ì†ëª© (ë”¥í•‘í¬)
    (255, 105, 180), # ì˜¤ë¥¸ì†ëª© (í•«í•‘í¬)
    (255, 182, 193), # ì™¼ì—‰ë©ì´ (ë¼ì´íŠ¸í•‘í¬)
    (250, 128, 114), # ì˜¤ë¥¸ì—‰ë©ì´ (ì—°ì–´ìƒ‰)
    (255, 160, 122), # ì™¼ë¬´ë¦ (ë¼ì´íŠ¸ìƒëª¬)
    (255, 218, 185), # ì˜¤ë¥¸ë¬´ë¦ (í”¼ì¹˜í¼í”„)
    (255, 228, 196), # ì™¼ë°œëª© (ë¹„ìŠ¤í¬)
    (255, 239, 213), # ì˜¤ë¥¸ë°œëª© (íŒŒíŒŒì•¼íœ©)
    (220, 20, 60)    # ë¨¸ë¦¬ (í¬ë¦¼ìŠ¨)
]

# í¬ì¦ˆ í‚¤í¬ì¸íŠ¸ í•œêµ­ì–´ ì´ë¦„
POSE_KEYPOINT_NAMES = [
    "ì½”", "ì™¼ëˆˆ", "ì˜¤ë¥¸ëˆˆ", "ì™¼ê·€", "ì˜¤ë¥¸ê·€",
    "ì™¼ì–´ê¹¨", "ì˜¤ë¥¸ì–´ê¹¨", "ì™¼íŒ”ê¿ˆì¹˜", "ì˜¤ë¥¸íŒ”ê¿ˆì¹˜", "ì™¼ì†ëª©", "ì˜¤ë¥¸ì†ëª©",
    "ì™¼ì—‰ë©ì´", "ì˜¤ë¥¸ì—‰ë©ì´", "ì™¼ë¬´ë¦", "ì˜¤ë¥¸ë¬´ë¦", "ì™¼ë°œëª©", "ì˜¤ë¥¸ë°œëª©", "ë¨¸ë¦¬"
]

# í¬ì¦ˆ ì—°ê²°ì„  (ë¼ˆëŒ€) - ë” ì •í™•í•œ ì—°ê²°
POSE_SKELETON = [
    (0, 1), (0, 2), (1, 3), (2, 4),  # ì–¼êµ´
    (5, 6),  # ì–´ê¹¨ ì—°ê²°
    (5, 7), (7, 9),  # ì™¼íŒ”
    (6, 8), (8, 10), # ì˜¤ë¥¸íŒ”
    (5, 11), (6, 12), (11, 12),  # ëª¸í†µ
    (11, 13), (13, 15),  # ì™¼ë‹¤ë¦¬
    (12, 14), (14, 16),  # ì˜¤ë¥¸ë‹¤ë¦¬
]

# ì˜ë¥˜ ì¹´í…Œê³ ë¦¬ë³„ ìƒ‰ìƒ (í™•ì¥)
CLOTHING_COLORS = {
    'shirt': (70, 130, 255),      # ì…”ì¸  (ì½”ë°œíŠ¸ë¸”ë£¨)
    'blouse': (255, 182, 193),    # ë¸”ë¼ìš°ìŠ¤ (ë¼ì´íŠ¸í•‘í¬)
    'pants': (255, 140, 0),       # ë°”ì§€ (ë‹¤í¬ì˜¤ë Œì§€)
    'jeans': (25, 25, 112),       # ì²­ë°”ì§€ (ë¯¸ë“œë‚˜ì´íŠ¸ë¸”ë£¨)
    'dress': (255, 20, 147),      # ë“œë ˆìŠ¤ (ë”¥í•‘í¬)
    'skirt': (148, 0, 211),       # ì¹˜ë§ˆ (ë‹¤í¬ë°”ì´ì˜¬ë ›)
    'jacket': (34, 139, 34),      # ì¬í‚· (í¬ë ˆìŠ¤íŠ¸ê·¸ë¦°)
    'coat': (139, 69, 19),        # ì½”íŠ¸ (ìƒˆë“¤ë¸Œë¼ìš´)
    'sweater': (220, 20, 60),     # ìŠ¤ì›¨í„° (í¬ë¦¼ìŠ¨)
    'hoodie': (105, 105, 105),    # í›„ë“œí‹° (ë”¤ê·¸ë ˆì´)
    'tank_top': (255, 215, 0),    # íƒ±í¬í†± (ê³¨ë“œ)
    'shorts': (0, 255, 127),      # ë°˜ë°”ì§€ (ìŠ¤í”„ë§ê·¸ë¦°)
    'unknown': (128, 128, 128)    # ì•Œ ìˆ˜ ì—†ìŒ (ê·¸ë ˆì´)
}

class ImageProcessor:
    """
    ì™„ì „í•œ ì´ë¯¸ì§€ ì²˜ë¦¬ ìœ í‹¸ë¦¬í‹° í´ë˜ìŠ¤
    âœ… ê¸°ì¡´ í•¨ìˆ˜ëª… ì™„ì „ ìœ ì§€
    âœ… M3 Max ìµœì í™”
    âœ… ê³ í’ˆì§ˆ ì²˜ë¦¬
    âœ… ì‹œê°í™” ê¸°ëŠ¥ ëŒ€í­ í™•ì¥
    """
    
    def __init__(self):
        self.is_m3_max = self._detect_m3_max()
        self.max_resolution = (2048, 2048) if self.is_m3_max else (1024, 1024)
        self.default_quality = 95 if self.is_m3_max else 85
        
        # í°íŠ¸ ìºì‹œ
        self._font_cache = {}
        self._load_fonts()
        
        logger.info(f"ğŸ¨ ImageProcessor ì´ˆê¸°í™” - M3 Max: {self.is_m3_max}")

    def _detect_m3_max(self) -> bool:
        """M3 Max ê°ì§€ (ê°œì„ ëœ ë²„ì „)"""
        try:
            import platform
            import subprocess
            
            if platform.system() == 'Darwin':
                # macOSì—ì„œ CPU ì •ë³´ í™•ì¸
                result = subprocess.run(['sysctl', '-n', 'machdep.cpu.brand_string'], 
                                      capture_output=True, text=True, timeout=5)
                chip_info = result.stdout.strip().upper()
                
                # M3 Max ê°ì§€
                if 'M3' in chip_info and 'MAX' in chip_info:
                    logger.info(f"ğŸ M3 Max ê°ì§€ë¨: {chip_info}")
                    return True
                elif 'M3' in chip_info:
                    logger.info(f"ğŸ M3 ê°ì§€ë¨ (Max ì•„ë‹˜): {chip_info}")
                    return False
                    
        except Exception as e:
            logger.warning(f"CPU ì •ë³´ í™•ì¸ ì‹¤íŒ¨: {e}")
        
        return False
    
    def _load_fonts(self):
        """í°íŠ¸ ë¡œë”© ë° ìºì‹œ"""
        font_sizes = [10, 12, 14, 16, 18, 20, 24, 28, 32]
        
        # ì‹œìŠ¤í…œë³„ í°íŠ¸ ê²½ë¡œ
        font_paths = {
            'arial': [
                "/System/Library/Fonts/Arial.ttf",        # macOS
                "/System/Library/Fonts/Helvetica.ttc",    # macOS ëŒ€ì²´
                "/Windows/Fonts/arial.ttf",               # Windows
                "/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf",  # Linux
                "/usr/share/fonts/TTF/arial.ttf"          # Linux ëŒ€ì²´
            ],
            'times': [
                "/System/Library/Fonts/Times.ttc",        # macOS
                "/Windows/Fonts/times.ttf",               # Windows
                "/usr/share/fonts/truetype/dejavu/DejaVuSerif.ttf"  # Linux
            ]
        }
        
        for font_name, paths in font_paths.items():
            for size in font_sizes:
                font_key = f"{font_name}_{size}"
                
                for font_path in paths:
                    try:
                        if os.path.exists(font_path):
                            self._font_cache[font_key] = ImageFont.truetype(font_path, size)
                            break
                    except Exception:
                        continue
                
                # í´ë°±: ê¸°ë³¸ í°íŠ¸
                if font_key not in self._font_cache:
                    self._font_cache[font_key] = ImageFont.load_default()
    
    def get_font(self, font_name: str = "arial", size: int = 14) -> ImageFont.ImageFont:
        """í°íŠ¸ ë°˜í™˜ (ìºì‹œëœ)"""
        font_key = f"{font_name}_{size}"
        
        if font_key in self._font_cache:
            return self._font_cache[font_key]
        
        # ë™ì  ë¡œë”©
        try:
            font_paths = {
                'arial': ["/System/Library/Fonts/Arial.ttf", "/Windows/Fonts/arial.ttf"],
                'times': ["/System/Library/Fonts/Times.ttc", "/Windows/Fonts/times.ttf"]
            }
            
            for font_path in font_paths.get(font_name, []):
                if os.path.exists(font_path):
                    font = ImageFont.truetype(font_path, size)
                    self._font_cache[font_key] = font
                    return font
        except Exception:
            pass
        
        # í´ë°±
        font = ImageFont.load_default()
        self._font_cache[font_key] = font
        return font

    # ============================================================================
    # ğŸ”§ ê¸°ì¡´ í•¨ìˆ˜ë“¤ (100% í˜¸í™˜ì„± ìœ ì§€)
    # ============================================================================

    @staticmethod
    def enhance_image(image: Image.Image, enhancement_level: float = 1.1) -> Image.Image:
        """
        ì´ë¯¸ì§€ í’ˆì§ˆ í–¥ìƒ
        âœ… ê¸°ì¡´ í•¨ìˆ˜ëª… ìœ ì§€
        """
        try:
            # ì„ ëª…ë„ í–¥ìƒ
            enhancer = ImageEnhance.Sharpness(image)
            enhanced = enhancer.enhance(enhancement_level)
            
            # ìƒ‰ìƒ í–¥ìƒ
            enhancer = ImageEnhance.Color(enhanced)
            enhanced = enhancer.enhance(1.05)
            
            # ëŒ€ë¹„ í–¥ìƒ
            enhancer = ImageEnhance.Contrast(enhanced)
            enhanced = enhancer.enhance(1.02)
            
            logger.debug("ğŸ¨ ì´ë¯¸ì§€ í’ˆì§ˆ í–¥ìƒ ì™„ë£Œ")
            return enhanced
            
        except Exception as e:
            logger.error(f"âŒ ì´ë¯¸ì§€ í–¥ìƒ ì‹¤íŒ¨: {e}")
            return image

    @staticmethod
    def resize_image(
        image: Image.Image, 
        target_size: Tuple[int, int], 
        maintain_ratio: bool = True,
        resample: int = Image.Resampling.LANCZOS
    ) -> Image.Image:
        """
        ì´ë¯¸ì§€ í¬ê¸° ì¡°ì •
        âœ… ê¸°ì¡´ í•¨ìˆ˜ì™€ ì™„ì „ í˜¸í™˜
        """
        try:
            if maintain_ratio:
                # ë¹„ìœ¨ ìœ ì§€í•˜ë©° ë¦¬ì‚¬ì´ì¦ˆ
                image.thumbnail(target_size, resample)
                
                # ì •ì‚¬ê°í˜•ìœ¼ë¡œ íŒ¨ë”©
                new_image = Image.new('RGB', target_size, (255, 255, 255))
                paste_x = (target_size[0] - image.width) // 2
                paste_y = (target_size[1] - image.height) // 2
                new_image.paste(image, (paste_x, paste_y))
                return new_image
            else:
                return image.resize(target_size, resample)
                
        except Exception as e:
            logger.error(f"âŒ ì´ë¯¸ì§€ í¬ê¸° ì¡°ì • ì‹¤íŒ¨: {e}")
            return image

    @staticmethod
    def enhance_image_quality(image: Image.Image) -> Image.Image:
        """
        ì´ë¯¸ì§€ í’ˆì§ˆ í–¥ìƒ (ê¸°ì¡´ í•¨ìˆ˜ì™€ í˜¸í™˜)
        """
        try:
            # ì„ ëª…ë„ í–¥ìƒ
            enhancer = ImageEnhance.Sharpness(image)
            image = enhancer.enhance(1.1)
            
            # ëŒ€ë¹„ í–¥ìƒ
            enhancer = ImageEnhance.Contrast(image)
            image = enhancer.enhance(1.05)
            
            return image
            
        except Exception as e:
            logger.error(f"âŒ ì´ë¯¸ì§€ í’ˆì§ˆ í–¥ìƒ ì‹¤íŒ¨: {e}")
            return image

    @staticmethod
    def convert_to_rgb(image: Image.Image) -> Image.Image:
        """
        RGBë¡œ ë³€í™˜ (ê¸°ì¡´ í•¨ìˆ˜ì™€ í˜¸í™˜)
        """
        try:
            if image.mode != 'RGB':
                return image.convert('RGB')
            return image
        except Exception as e:
            logger.error(f"âŒ RGB ë³€í™˜ ì‹¤íŒ¨: {e}")
            return image

    # ============================================================================
    # ğŸ¨ ì‹œê°í™” ì „ìš© í•¨ìˆ˜ë“¤ (ìƒˆë¡œ ì¶”ê°€)
    # ============================================================================
    
    def create_human_parsing_visualization(
        self, 
        original_image: np.ndarray, 
        parsing_map: np.ndarray,
        detected_parts: List[int] = None,
        show_legend: bool = True,
        show_overlay: bool = True,
        overlay_opacity: float = 0.6
    ) -> Dict[str, str]:
        """ì¸ì²´ íŒŒì‹± ê²°ê³¼ ì‹œê°í™” ìƒì„±"""
        try:
            visualizations = {}
            
            # 1. ì»¬ëŸ¬ íŒŒì‹± ë§µ ìƒì„±
            colored_parsing = self._create_colored_parsing_map(parsing_map)
            visualizations['colored_parsing'] = self._numpy_to_base64(colored_parsing)
            
            # 2. ì˜¤ë²„ë ˆì´ ì´ë¯¸ì§€ ìƒì„±
            if show_overlay:
                overlay_image = self._create_overlay_image(
                    original_image, colored_parsing, overlay_opacity
                )
                visualizations['overlay_image'] = self._numpy_to_base64(overlay_image)
            
            # 3. ë²”ë¡€ ì´ë¯¸ì§€ ìƒì„±
            if show_legend and detected_parts:
                legend_image = self._create_parsing_legend(detected_parts)
                visualizations['legend_image'] = self._numpy_to_base64(legend_image)
            
            # 4. í†µê³„ ì •ë³´ ì´ë¯¸ì§€
            if detected_parts:
                stats_image = self._create_parsing_statistics(parsing_map, detected_parts)
                visualizations['statistics_image'] = self._numpy_to_base64(stats_image)
            
            # 5. ë¹„êµ ê·¸ë¦¬ë“œ ìƒì„±
            comparison_images = [original_image, colored_parsing]
            if show_overlay:
                comparison_images.append(overlay_image)
            
            comparison_grid = self._create_comparison_grid(
                comparison_images, 
                titles=['Original', 'Parsing', 'Overlay'] if show_overlay else ['Original', 'Parsing']
            )
            visualizations['comparison_grid'] = self._numpy_to_base64(comparison_grid)
            
            logger.info(f"âœ… ì¸ì²´ íŒŒì‹± ì‹œê°í™” ìƒì„± ì™„ë£Œ: {len(visualizations)}ê°œ")
            return visualizations
            
        except Exception as e:
            logger.error(f"âŒ ì¸ì²´ íŒŒì‹± ì‹œê°í™” ì‹¤íŒ¨: {e}")
            return {}
    
    def create_pose_estimation_visualization(
        self, 
        original_image: np.ndarray, 
        keypoints: np.ndarray,
        confidence_scores: np.ndarray = None,
        show_skeleton: bool = True,
        show_confidence: bool = True
    ) -> Dict[str, str]:
        """í¬ì¦ˆ ì¶”ì • ê²°ê³¼ ì‹œê°í™” ìƒì„±"""
        try:
            visualizations = {}
            
            # 1. í‚¤í¬ì¸íŠ¸ë§Œ í‘œì‹œ
            keypoint_image = self._draw_pose_keypoints(
                original_image.copy(), keypoints, confidence_scores, show_confidence
            )
            visualizations['keypoint_image'] = self._numpy_to_base64(keypoint_image)
            
            # 2. ìŠ¤ì¼ˆë ˆí†¤ í¬í•¨ í‘œì‹œ
            if show_skeleton:
                skeleton_image = self._draw_pose_skeleton(
                    original_image.copy(), keypoints, confidence_scores
                )
                visualizations['skeleton_image'] = self._numpy_to_base64(skeleton_image)
            
            # 3. ì‹ ë¢°ë„ ë¶„ì„ ì°¨íŠ¸
            if confidence_scores is not None:
                confidence_chart = self._create_confidence_analysis_chart(
                    keypoints, confidence_scores
                )
                visualizations['confidence_chart'] = self._numpy_to_base64(confidence_chart)
            
            # 4. í¬ì¦ˆ í’ˆì§ˆ í‰ê°€
            quality_image = self._create_pose_quality_assessment(
                keypoints, confidence_scores
            )
            visualizations['quality_assessment'] = self._numpy_to_base64(quality_image)
            
            # 5. ë¹„êµ ê·¸ë¦¬ë“œ
            comparison_images = [original_image, keypoint_image]
            if show_skeleton:
                comparison_images.append(skeleton_image)
            
            comparison_grid = self._create_comparison_grid(
                comparison_images,
                titles=['Original', 'Keypoints', 'Skeleton'] if show_skeleton else ['Original', 'Keypoints']
            )
            visualizations['comparison_grid'] = self._numpy_to_base64(comparison_grid)
            
            logger.info(f"âœ… í¬ì¦ˆ ì¶”ì • ì‹œê°í™” ìƒì„± ì™„ë£Œ: {len(visualizations)}ê°œ")
            return visualizations
            
        except Exception as e:
            logger.error(f"âŒ í¬ì¦ˆ ì¶”ì • ì‹œê°í™” ì‹¤íŒ¨: {e}")
            return {}
    
    def create_clothing_analysis_visualization(
        self, 
        clothing_image: np.ndarray, 
        segmentation_mask: np.ndarray = None,
        color_analysis: Dict[str, Any] = None,
        category_info: Dict[str, Any] = None
    ) -> Dict[str, str]:
        """ì˜ë¥˜ ë¶„ì„ ê²°ê³¼ ì‹œê°í™” ìƒì„±"""
        try:
            visualizations = {}
            
            # 1. ì˜ë¥˜ ë¶„í•  ë§ˆìŠ¤í¬ ì ìš©
            if segmentation_mask is not None:
                segmented_image = self._apply_segmentation_mask(
                    clothing_image, segmentation_mask
                )
                visualizations['segmented_image'] = self._numpy_to_base64(segmented_image)
            
            # 2. ìƒ‰ìƒ ë¶„ì„ ê²°ê³¼
            if color_analysis:
                color_chart = self._create_color_analysis_visualization(color_analysis)
                visualizations['color_analysis'] = self._numpy_to_base64(color_chart)
            
            # 3. ì¹´í…Œê³ ë¦¬ ì •ë³´ íŒ¨ë„
            if category_info:
                category_panel = self._create_category_info_panel(category_info)
                visualizations['category_panel'] = self._numpy_to_base64(category_panel)
            
            # 4. ì¢…í•© ë¶„ì„ ëŒ€ì‹œë³´ë“œ
            dashboard = self._create_clothing_analysis_dashboard(
                clothing_image, segmentation_mask, color_analysis, category_info
            )
            visualizations['analysis_dashboard'] = self._numpy_to_base64(dashboard)
            
            logger.info(f"âœ… ì˜ë¥˜ ë¶„ì„ ì‹œê°í™” ìƒì„± ì™„ë£Œ: {len(visualizations)}ê°œ")
            return visualizations
            
        except Exception as e:
            logger.error(f"âŒ ì˜ë¥˜ ë¶„ì„ ì‹œê°í™” ì‹¤íŒ¨: {e}")
            return {}
    
    def create_virtual_fitting_visualization(
        self, 
        original_person: np.ndarray, 
        clothing_item: np.ndarray,
        fitted_result: np.ndarray,
        fit_score: float = None,
        confidence: float = None,
        processing_details: Dict[str, Any] = None
    ) -> Dict[str, str]:
        """ê°€ìƒ í”¼íŒ… ê²°ê³¼ ì‹œê°í™” ìƒì„±"""
        try:
            visualizations = {}
            
            # 1. Before/After ë¹„êµ
            before_after = self._create_detailed_before_after_comparison(
                original_person, fitted_result, fit_score, confidence
            )
            visualizations['before_after'] = self._numpy_to_base64(before_after)
            
            # 2. 3ë‹¨ê³„ í”„ë¡œì„¸ìŠ¤ (ì‚¬ëŒ | ì˜· | ê²°ê³¼)
            process_flow = self._create_fitting_process_flow(
                original_person, clothing_item, fitted_result
            )
            visualizations['process_flow'] = self._numpy_to_base64(process_flow)
            
            # 3. í’ˆì§ˆ ì ìˆ˜ ëŒ€ì‹œë³´ë“œ
            if fit_score is not None or confidence is not None:
                quality_dashboard = self._create_quality_score_dashboard(
                    fit_score, confidence, processing_details
                )
                visualizations['quality_dashboard'] = self._numpy_to_base64(quality_dashboard)
            
            # 4. ìƒì„¸ ë¶„ì„ (í™•ëŒ€ ì˜ì—­ë“¤)
            detail_analysis = self._create_fitting_detail_analysis(
                original_person, fitted_result
            )
            visualizations['detail_analysis'] = self._numpy_to_base64(detail_analysis)
            
            # 5. ê°œì„  ì œì•ˆì‚¬í•­
            if processing_details:
                recommendations = self._create_fitting_recommendations(
                    processing_details, fit_score
                )
                visualizations['recommendations'] = self._numpy_to_base64(recommendations)
            
            logger.info(f"âœ… ê°€ìƒ í”¼íŒ… ì‹œê°í™” ìƒì„± ì™„ë£Œ: {len(visualizations)}ê°œ")
            return visualizations
            
        except Exception as e:
            logger.error(f"âŒ ê°€ìƒ í”¼íŒ… ì‹œê°í™” ì‹¤íŒ¨: {e}")
            return {}

    # ============================================================================
    # ğŸ”§ ë‚´ë¶€ ë„ìš°ë¯¸ í•¨ìˆ˜ë“¤ (ì‹œê°í™”)
    # ============================================================================
    
    def _numpy_to_base64(self, image: np.ndarray, format: str = "JPEG", quality: int = 90) -> str:
        """NumPy ë°°ì—´ì„ Base64 ë¬¸ìì—´ë¡œ ë³€í™˜"""
        try:
            # ë°ì´í„° íƒ€ì… ì •ê·œí™”
            if image.dtype != np.uint8:
                if image.max() <= 1.0:
                    image = (image * 255).astype(np.uint8)
                else:
                    image = np.clip(image, 0, 255).astype(np.uint8)
            
            # PIL ì´ë¯¸ì§€ë¡œ ë³€í™˜
            if len(image.shape) == 3:
                pil_image = Image.fromarray(image, 'RGB')
            else:
                pil_image = Image.fromarray(image, 'L')
            
            # Base64 ì¸ì½”ë”©
            buffer = io.BytesIO()
            if format.upper() == "JPEG":
                # ê³ í’ˆì§ˆ ì„¤ì • (M3 Max ìµœì í™”)
                actual_quality = self.default_quality if self.is_m3_max else quality
                pil_image.save(buffer, format=format, quality=actual_quality, optimize=True)
            else:
                pil_image.save(buffer, format=format)
            
            return base64.b64encode(buffer.getvalue()).decode('utf-8')
            
        except Exception as e:
            logger.error(f"âŒ NumPy â†’ Base64 ë³€í™˜ ì‹¤íŒ¨: {e}")
            return ""
    
    def _create_colored_parsing_map(self, parsing_map: np.ndarray) -> np.ndarray:
        """ì»¬ëŸ¬ íŒŒì‹± ë§µ ìƒì„± (ê°œì„ ëœ ë²„ì „)"""
        height, width = parsing_map.shape
        colored_map = np.zeros((height, width, 3), dtype=np.uint8)
        
        # ê° ë¶€ìœ„ë³„ë¡œ ìƒ‰ìƒ ì ìš©
        for part_id, color in HUMAN_PARSING_COLORS.items():
            mask = (parsing_map == part_id)
            colored_map[mask] = color
        
        # ë¶€ë“œëŸ¬ìš´ ê²½ê³„ ì²˜ë¦¬ (M3 Maxì—ì„œë§Œ)
        if self.is_m3_max:
            colored_map = cv2.bilateralFilter(colored_map, 9, 75, 75)
        
        return colored_map
    
    def _create_overlay_image(self, base_image: np.ndarray, overlay: np.ndarray, alpha: float = 0.5) -> np.ndarray:
        """ì˜¤ë²„ë ˆì´ ì´ë¯¸ì§€ ìƒì„± (ê°œì„ ëœ ë²„ì „)"""
        try:
            # í¬ê¸° ë§ì¶”ê¸°
            if base_image.shape[:2] != overlay.shape[:2]:
                overlay = cv2.resize(overlay, (base_image.shape[1], base_image.shape[0]))
            
            # ê³ í’ˆì§ˆ ë¸”ë Œë”© (M3 Maxì—ì„œ)
            if self.is_m3_max:
                # ê°€ìš°ì‹œì•ˆ ê°€ì¤‘ì¹˜ë¥¼ ì‚¬ìš©í•œ ê³ ê¸‰ ë¸”ë Œë”©
                blended = cv2.addWeighted(base_image, 1-alpha, overlay, alpha, 0)
                # ì¶”ê°€ í›„ì²˜ë¦¬
                blended = cv2.bilateralFilter(blended, 9, 75, 75)
            else:
                # ê¸°ë³¸ ë¸”ë Œë”©
                blended = cv2.addWeighted(base_image, 1-alpha, overlay, alpha, 0)
            
            return blended
            
        except Exception as e:
            logger.error(f"âŒ ì˜¤ë²„ë ˆì´ ìƒì„± ì‹¤íŒ¨: {e}")
            return base_image
    
    def _create_parsing_legend(self, detected_parts: List[int]) -> np.ndarray:
        """íŒŒì‹± ë²”ë¡€ ìƒì„± (ê°œì„ ëœ ë²„ì „)"""
        try:
            # ë²”ë¡€ í¬ê¸° ê³„ì‚°
            item_height = 35
            legend_width = 280
            legend_height = len(detected_parts) * item_height + 80
            
            # PIL ì´ë¯¸ì§€ ìƒì„±
            legend_pil = Image.new('RGB', (legend_width, legend_height), (245, 245, 245))
            draw = ImageDraw.Draw(legend_pil)
            
            # ì œëª© ìŠ¤íƒ€ì¼ë§
            title_font = self.get_font("arial", 20)
            detail_font = self.get_font("arial", 14)
            
            # ì œëª© ë°°ê²½
            draw.rectangle([10, 10, legend_width-10, 50], fill=(70, 130, 180), outline=(0, 0, 0))
            draw.text((legend_width//2 - 60, 20), "ê°ì§€ëœ ë¶€ìœ„", fill=(255, 255, 255), font=title_font)
            
            # ê° ë¶€ìœ„ë³„ í•­ëª©
            y_offset = 60
            for i, part_id in enumerate(detected_parts):
                if part_id in HUMAN_PARSING_COLORS and part_id in HUMAN_PARSING_NAMES:
                    color = HUMAN_PARSING_COLORS[part_id]
                    name = HUMAN_PARSING_NAMES[part_id]
                    
                    # ë°°ê²½ (êµëŒ€ë¡œ ë‹¤ë¥¸ ìƒ‰ìƒ)
                    bg_color = (255, 255, 255) if i % 2 == 0 else (240, 240, 240)
                    draw.rectangle([15, y_offset, legend_width-15, y_offset + item_height], fill=bg_color)
                    
                    # ìƒ‰ìƒ ë°•ìŠ¤ (ê·¸ë¦¼ì íš¨ê³¼)
                    draw.rectangle([22, y_offset + 6, 47, y_offset + 26], fill=(0, 0, 0))  # ê·¸ë¦¼ì
                    draw.rectangle([20, y_offset + 5, 45, y_offset + 25], fill=color, outline=(0, 0, 0))
                    
                    # í…ìŠ¤íŠ¸
                    draw.text((55, y_offset + 8), f"{part_id:2d}. {name}", fill=(30, 30, 30), font=detail_font)
                    
                    y_offset += item_height
            
            # í•˜ë‹¨ ì •ë³´
            draw.text((20, y_offset + 10), f"ì´ {len(detected_parts)}ê°œ ë¶€ìœ„ ê°ì§€", 
                     fill=(100, 100, 100), font=detail_font)
            
            return np.array(legend_pil)
            
        except Exception as e:
            logger.error(f"âŒ íŒŒì‹± ë²”ë¡€ ìƒì„± ì‹¤íŒ¨: {e}")
            # í´ë°±: ê°„ë‹¨í•œ ë²”ë¡€
            return self._create_simple_legend(detected_parts)
    
    def _create_parsing_statistics(self, parsing_map: np.ndarray, detected_parts: List[int]) -> np.ndarray:
        """íŒŒì‹± í†µê³„ ì •ë³´ ìƒì„±"""
        try:
            # í†µê³„ ê³„ì‚°
            total_pixels = parsing_map.size
            part_stats = {}
            
            for part_id in detected_parts:
                mask = (parsing_map == part_id)
                pixel_count = np.sum(mask)
                percentage = (pixel_count / total_pixels) * 100
                part_stats[part_id] = {
                    'pixels': pixel_count,
                    'percentage': percentage,
                    'name': HUMAN_PARSING_NAMES.get(part_id, f"Part {part_id}")
                }
            
            # ì°¨íŠ¸ ìƒì„±
            chart_width = 400
            chart_height = 300
            chart_pil = Image.new('RGB', (chart_width, chart_height), (255, 255, 255))
            draw = ImageDraw.Draw(chart_pil)
            
            # ì œëª©
            title_font = self.get_font("arial", 16)
            draw.text((chart_width//2 - 60, 10), "ë¶€ìœ„ë³„ ë¹„ìœ¨", fill=(0, 0, 0), font=title_font)
            
            # ë§‰ëŒ€ ì°¨íŠ¸
            y_start = 50
            bar_height = 20
            max_width = chart_width - 100
            
            for i, (part_id, stats) in enumerate(sorted(part_stats.items(), key=lambda x: x[1]['percentage'], reverse=True)):
                y = y_start + i * (bar_height + 5)
                
                # ë§‰ëŒ€ ê¸¸ì´ ê³„ì‚°
                bar_width = int((stats['percentage'] / 100) * max_width)
                color = HUMAN_PARSING_COLORS.get(part_id, (128, 128, 128))
                
                # ë§‰ëŒ€ ê·¸ë¦¬ê¸°
                draw.rectangle([80, y, 80 + bar_width, y + bar_height], fill=color)
                
                # í…ìŠ¤íŠ¸
                text_font = self.get_font("arial", 10)
                draw.text((10, y + 5), stats['name'][:10], fill=(0, 0, 0), font=text_font)
                draw.text((85 + bar_width, y + 5), f"{stats['percentage']:.1f}%", fill=(0, 0, 0), font=text_font)
            
            return np.array(chart_pil)
            
        except Exception as e:
            logger.error(f"âŒ íŒŒì‹± í†µê³„ ìƒì„± ì‹¤íŒ¨: {e}")
            # í´ë°±: í…ìŠ¤íŠ¸ë§Œ
            return self._create_text_info("íŒŒì‹± í†µê³„", [f"ê°ì§€ëœ ë¶€ìœ„: {len(detected_parts)}ê°œ"])

    def _draw_pose_keypoints(self, image: np.ndarray, keypoints: np.ndarray, 
                           confidence_scores: np.ndarray = None, show_confidence: bool = True) -> np.ndarray:
        """í¬ì¦ˆ í‚¤í¬ì¸íŠ¸ ê·¸ë¦¬ê¸° (ê°œì„ ëœ ë²„ì „)"""
        try:
            image_pil = Image.fromarray(image)
            draw = ImageDraw.Draw(image_pil)
            
            for i, (x, y) in enumerate(keypoints):
                # ì‹ ë¢°ë„ ì²´í¬
                confidence = confidence_scores[i] if confidence_scores is not None else 1.0
                if confidence < 0.3:
                    continue
                
                # ìƒ‰ìƒ ë° í¬ê¸° ê²°ì •
                color = POSE_KEYPOINT_COLORS[i % len(POSE_KEYPOINT_COLORS)]
                
                # ì‹ ë¢°ë„ì— ë”°ë¥¸ í¬ê¸° ì¡°ì •
                if confidence_scores is not None:
                    radius = int(3 + (confidence * 5))  # 3-8 í”½ì…€
                else:
                    radius = 5
                
                # í‚¤í¬ì¸íŠ¸ ê·¸ë¦¬ê¸° (ê·¸ë¦¼ì íš¨ê³¼)
                # ê·¸ë¦¼ì
                draw.ellipse([x-radius+1, y-radius+1, x+radius+1, y+radius+1], fill=(0, 0, 0, 128))
                # ë©”ì¸ í¬ì¸íŠ¸
                draw.ellipse([x-radius, y-radius, x+radius, y+radius], fill=color, outline=(255, 255, 255), width=1)
                
                # ì‹ ë¢°ë„ í…ìŠ¤íŠ¸ (ì˜µì…˜)
                if show_confidence and confidence_scores is not None and confidence > 0.5:
                    conf_text = f"{confidence:.2f}"
                    font = self.get_font("arial", 10)
                    # ë°°ê²½ ë°•ìŠ¤
                    text_bbox = draw.textbbox((0, 0), conf_text, font=font)
                    text_width = text_bbox[2] - text_bbox[0]
                    text_height = text_bbox[3] - text_bbox[1]
                    draw.rectangle([x+radius+2, y-radius-2, x+radius+2+text_width+4, y-radius-2+text_height+4], 
                                 fill=(0, 0, 0, 200))
                    draw.text((x+radius+4, y-radius), conf_text, fill=(255, 255, 255), font=font)
                
                # í‚¤í¬ì¸íŠ¸ ì´ë¦„ (ê³ ì‹ ë¢°ë„ì—ì„œë§Œ)
                if confidence > 0.8 and i < len(POSE_KEYPOINT_NAMES):
                    name = POSE_KEYPOINT_NAMES[i]
                    font = self.get_font("arial", 9)
                    draw.text((x-10, y+radius+2), name, fill=(255, 255, 255), font=font)
            
            return np.array(image_pil)
            
        except Exception as e:
            logger.error(f"âŒ í¬ì¦ˆ í‚¤í¬ì¸íŠ¸ ê·¸ë¦¬ê¸° ì‹¤íŒ¨: {e}")
            return image
    
    def _draw_pose_skeleton(self, image: np.ndarray, keypoints: np.ndarray, 
                          confidence_scores: np.ndarray = None) -> np.ndarray:
        """í¬ì¦ˆ ìŠ¤ì¼ˆë ˆí†¤ ê·¸ë¦¬ê¸° (ê°œì„ ëœ ë²„ì „)"""
        try:
            image_pil = Image.fromarray(image)
            draw = ImageDraw.Draw(image_pil)
            
            # ì—°ê²°ì„  ê·¸ë¦¬ê¸° (ë‘ê»˜ ë° ìƒ‰ìƒ ê°œì„ )
            for start_idx, end_idx in POSE_SKELETON:
                if start_idx < len(keypoints) and end_idx < len(keypoints):
                    start_x, start_y = keypoints[start_idx]
                    end_x, end_y = keypoints[end_idx]
                    
                    # ì‹ ë¢°ë„ ì²´í¬
                    if confidence_scores is not None:
                        start_conf = confidence_scores[start_idx]
                        end_conf = confidence_scores[end_idx]
                        if start_conf < 0.3 or end_conf < 0.3:
                            continue
                        
                        # ì‹ ë¢°ë„ì— ë”°ë¥¸ ì„  êµµê¸° ë° íˆ¬ëª…ë„
                        avg_conf = (start_conf + end_conf) / 2
                        line_width = int(2 + (avg_conf * 3))  # 2-5 í”½ì…€
                        alpha = int(100 + (avg_conf * 155))   # 100-255 íˆ¬ëª…ë„
                    else:
                        line_width = 3
                        alpha = 255
                    
                    # ê·¸ë¦¼ì ì„  (ë” ë‘ê»ê³  ì–´ë‘ìš´)
                    draw.line([start_x+1, start_y+1, end_x+1, end_y+1], 
                             fill=(0, 0, 0, alpha//2), width=line_width+1)
                    
                    # ë©”ì¸ ì„ 
                    line_color = (0, 255, 0)  # ì´ˆë¡ìƒ‰ ìŠ¤ì¼ˆë ˆí†¤
                    draw.line([start_x, start_y, end_x, end_y], fill=line_color, width=line_width)
            
            # í‚¤í¬ì¸íŠ¸ ë‹¤ì‹œ ê·¸ë¦¬ê¸° (ì„  ìœ„ì— í‘œì‹œ)
            for i, (x, y) in enumerate(keypoints):
                confidence = confidence_scores[i] if confidence_scores is not None else 1.0
                if confidence > 0.3:
                    color = POSE_KEYPOINT_COLORS[i % len(POSE_KEYPOINT_COLORS)]
                    radius = 4 if confidence > 0.7 else 3
                    
                    # í‚¤í¬ì¸íŠ¸ ê·¸ë¦¬ê¸°
                    draw.ellipse([x-radius, y-radius, x+radius, y+radius], 
                               fill=color, outline=(255, 255, 255), width=1)
            
            return np.array(image_pil)
            
        except Exception as e:
            logger.error(f"âŒ í¬ì¦ˆ ìŠ¤ì¼ˆë ˆí†¤ ê·¸ë¦¬ê¸° ì‹¤íŒ¨: {e}")
            return image
    
    def _create_confidence_analysis_chart(self, keypoints: np.ndarray, confidence_scores: np.ndarray) -> np.ndarray:
        """ì‹ ë¢°ë„ ë¶„ì„ ì°¨íŠ¸ ìƒì„±"""
        try:
            if MATPLOTLIB_AVAILABLE:
                return self._create_matplotlib_confidence_chart(keypoints, confidence_scores)
            else:
                return self._create_pil_confidence_chart(keypoints, confidence_scores)
        except Exception as e:
            logger.error(f"âŒ ì‹ ë¢°ë„ ì°¨íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}")
            return self._create_text_info("ì‹ ë¢°ë„ ë¶„ì„", [
                f"í‰ê·  ì‹ ë¢°ë„: {confidence_scores.mean():.2f}",
                f"ê³ ì‹ ë¢°ë„ í¬ì¸íŠ¸: {sum(confidence_scores > 0.7)}/18",
                f"ê°ì§€ëœ í¬ì¸íŠ¸: {sum(confidence_scores > 0.3)}/18"
            ])
    
    def _create_matplotlib_confidence_chart(self, keypoints: np.ndarray, confidence_scores: np.ndarray) -> np.ndarray:
        """Matplotlibì„ ì‚¬ìš©í•œ ì‹ ë¢°ë„ ì°¨íŠ¸"""
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))
        fig.patch.set_facecolor('white')
        
        # 1. í‚¤í¬ì¸íŠ¸ë³„ ì‹ ë¢°ë„ ë§‰ëŒ€ ì°¨íŠ¸
        keypoint_names = [name[:6] for name in POSE_KEYPOINT_NAMES]  # ì´ë¦„ ì¶•ì•½
        colors = ['green' if conf > 0.7 else 'orange' if conf > 0.3 else 'red' for conf in confidence_scores]
        
        bars = ax1.bar(range(len(confidence_scores)), confidence_scores, color=colors)
        ax1.set_xlabel('í‚¤í¬ì¸íŠ¸')
        ax1.set_ylabel('ì‹ ë¢°ë„')
        ax1.set_title('í‚¤í¬ì¸íŠ¸ë³„ ì‹ ë¢°ë„')
        ax1.set_xticks(range(len(keypoint_names)))
        ax1.set_xticklabels(keypoint_names, rotation=45, ha='right', fontsize=8)
        ax1.grid(axis='y', alpha=0.3)
        
        # ê°’ í‘œì‹œ
        for bar, conf in zip(bars, confidence_scores):
            if conf > 0.1:  # ë„ˆë¬´ ë‚®ì€ ê°’ì€ í‘œì‹œí•˜ì§€ ì•ŠìŒ
                ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,
                        f'{conf:.2f}', ha='center', va='bottom', fontsize=7)
        
        # 2. í’ˆì§ˆ ë¶„í¬ íŒŒì´ ì°¨íŠ¸
        high_conf = sum(confidence_scores > 0.7)
        med_conf = sum((confidence_scores > 0.3) & (confidence_scores <= 0.7))
        low_conf = sum(confidence_scores <= 0.3)
        
        sizes = [high_conf, med_conf, low_conf]
        labels = ['ë†’ìŒ (>0.7)', 'ë³´í†µ (0.3-0.7)', 'ë‚®ìŒ (â‰¤0.3)']
        colors_pie = ['#2ecc71', '#f39c12', '#e74c3c']
        explode = (0.05, 0, 0)  # ì²« ë²ˆì§¸ ì¡°ê° ê°•ì¡°
        
        wedges, texts, autotexts = ax2.pie(sizes, labels=labels, colors=colors_pie, 
                                          autopct='%1.0fê°œ', explode=explode, shadow=True)
        ax2.set_title('ì‹ ë¢°ë„ ë¶„í¬')
        
        # í…ìŠ¤íŠ¸ ìŠ¤íƒ€ì¼ë§
        for autotext in autotexts:
            autotext.set_color('white')
            autotext.set_fontweight('bold')
        
        plt.tight_layout()
        
        # NumPy ë°°ì—´ë¡œ ë³€í™˜
        fig.canvas.draw()
        chart_array = np.frombuffer(fig.canvas.tostring_rgb(), dtype=np.uint8)
        chart_array = chart_array.reshape(fig.canvas.get_width_height()[::-1] + (3,))
        
        plt.close(fig)
        return chart_array
    
    def _create_pil_confidence_chart(self, keypoints: np.ndarray, confidence_scores: np.ndarray) -> np.ndarray:
        """PILì„ ì‚¬ìš©í•œ ì‹ ë¢°ë„ ì°¨íŠ¸ (matplotlib ì—†ì„ ë•Œ)"""
        chart_width = 600
        chart_height = 400
        chart_pil = Image.new('RGB', (chart_width, chart_height), (250, 250, 250))
        draw = ImageDraw.Draw(chart_pil)
        
        # ì œëª©
        title_font = self.get_font("arial", 18)
        draw.text((chart_width//2 - 80, 20), "í‚¤í¬ì¸íŠ¸ ì‹ ë¢°ë„ ë¶„ì„", fill=(50, 50, 50), font=title_font)
        
        # ë§‰ëŒ€ ì°¨íŠ¸ ì˜ì—­
        chart_x = 50
        chart_y = 80
        chart_w = chart_width - 100
        chart_h = 200
        
        # ë°°ê²½
        draw.rectangle([chart_x, chart_y, chart_x + chart_w, chart_y + chart_h], 
                      fill=(255, 255, 255), outline=(200, 200, 200))
        
        # ë§‰ëŒ€ ê·¸ë¦¬ê¸°
        bar_width = chart_w // len(confidence_scores)
        for i, conf in enumerate(confidence_scores):
            x = chart_x + i * bar_width
            bar_height = int(conf * chart_h)
            y = chart_y + chart_h - bar_height
            
            # ìƒ‰ìƒ ê²°ì •
            if conf > 0.7:
                color = (46, 204, 113)  # ì´ˆë¡
            elif conf > 0.3:
                color = (243, 156, 18)  # ì£¼í™©
            else:
                color = (231, 76, 60)   # ë¹¨ê°•
            
            # ë§‰ëŒ€ ê·¸ë¦¬ê¸°
            draw.rectangle([x + 1, y, x + bar_width - 1, chart_y + chart_h], 
                          fill=color, outline=(100, 100, 100))
            
            # ê°’ í‘œì‹œ
            if conf > 0.1:
                value_text = f"{conf:.2f}"
                text_font = self.get_font("arial", 8)
                text_bbox = draw.textbbox((0, 0), value_text, font=text_font)
                text_width = text_bbox[2] - text_bbox[0]
                draw.text((x + bar_width//2 - text_width//2, y - 15), 
                         value_text, fill=(50, 50, 50), font=text_font)
        
        # í†µê³„ ì •ë³´
        stats_y = chart_y + chart_h + 30
        stats_font = self.get_font("arial", 14)
        
        avg_conf = confidence_scores.mean()
        high_count = sum(confidence_scores > 0.7)
        detected_count = sum(confidence_scores > 0.3)
        
        stats_text = [
            f"í‰ê·  ì‹ ë¢°ë„: {avg_conf:.3f}",
            f"ê³ ì‹ ë¢°ë„ í‚¤í¬ì¸íŠ¸: {high_count}/18ê°œ",
            f"ê°ì§€ëœ í‚¤í¬ì¸íŠ¸: {detected_count}/18ê°œ"
        ]
        
        for i, text in enumerate(stats_text):
            draw.text((chart_x, stats_y + i * 25), text, fill=(80, 80, 80), font=stats_font)
        
        return np.array(chart_pil)
    
    def _create_pose_quality_assessment(self, keypoints: np.ndarray, confidence_scores: np.ndarray) -> np.ndarray:
        """í¬ì¦ˆ í’ˆì§ˆ í‰ê°€ ìƒì„±"""
        try:
            assessment_width = 400
            assessment_height = 300
            assessment_pil = Image.new('RGB', (assessment_width, assessment_height), (248, 249, 250))
            draw = ImageDraw.Draw(assessment_pil)
            
            # ì œëª©
            title_font = self.get_font("arial", 16)
            draw.text((assessment_width//2 - 70, 15), "í¬ì¦ˆ í’ˆì§ˆ í‰ê°€", fill=(52, 58, 64), font=title_font)
            
            # ì „ì²´ í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°
            if confidence_scores is not None:
                overall_quality = confidence_scores.mean()
                detected_ratio = sum(confidence_scores > 0.3) / len(confidence_scores)
                high_quality_ratio = sum(confidence_scores > 0.7) / len(confidence_scores)
            else:
                overall_quality = 0.5
                detected_ratio = 0.5
                high_quality_ratio = 0.3
            
            # í’ˆì§ˆ ë“±ê¸‰ ê²°ì •
            if overall_quality > 0.8:
                grade = "ìš°ìˆ˜"
                grade_color = (40, 167, 69)
            elif overall_quality > 0.6:
                grade = "ì–‘í˜¸"
                grade_color = (255, 193, 7)
            elif overall_quality > 0.4:
                grade = "ë³´í†µ"
                grade_color = (255, 133, 27)
            else:
                grade = "ê°œì„ í•„ìš”"
                grade_color = (220, 53, 69)
            
            # ë“±ê¸‰ í‘œì‹œ
            grade_y = 60
            draw.rectangle([50, grade_y, 350, grade_y + 60], fill=grade_color, outline=(0, 0, 0))
            grade_font = self.get_font("arial", 24)
            draw.text((assessment_width//2 - 30, grade_y + 18), grade, fill=(255, 255, 255), font=grade_font)
            
            # ì„¸ë¶€ ì ìˆ˜ë“¤
            details_y = 140
            detail_font = self.get_font("arial", 12)
            
            details = [
                f"ì „ì²´ ì‹ ë¢°ë„: {overall_quality:.1%}",
                f"ê°ì§€ìœ¨: {detected_ratio:.1%}",
                f"ê³ í’ˆì§ˆ ë¹„ìœ¨: {high_quality_ratio:.1%}",
                f"ì™„ì„±ë„: {min(detected_ratio * 1.2, 1.0):.1%}"
            ]
            
            for i, detail in enumerate(details):
                y = details_y + i * 25
                # ë°°ê²½ ë°”
                draw.rectangle([60, y, 340, y + 20], fill=(233, 236, 239), outline=(173, 181, 189))
                # ì§„í–‰ ë°”
                if "ì‹ ë¢°ë„" in detail:
                    progress = overall_quality
                elif "ê°ì§€ìœ¨" in detail:
                    progress = detected_ratio
                elif "ê³ í’ˆì§ˆ" in detail:
                    progress = high_quality_ratio
                else:
                    progress = min(detected_ratio * 1.2, 1.0)
                
                progress_width = int(280 * progress)
                progress_color = (40, 167, 69) if progress > 0.7 else (255, 193, 7) if progress > 0.5 else (220, 53, 69)
                draw.rectangle([60, y, 60 + progress_width, y + 20], fill=progress_color)
                
                # í…ìŠ¤íŠ¸
                draw.text((65, y + 4), detail, fill=(52, 58, 64), font=detail_font)
            
            return np.array(assessment_pil)
            
        except Exception as e:
            logger.error(f"âŒ í¬ì¦ˆ í’ˆì§ˆ í‰ê°€ ìƒì„± ì‹¤íŒ¨: {e}")
            return self._create_text_info("í¬ì¦ˆ í’ˆì§ˆ í‰ê°€", ["í‰ê°€ ìƒì„± ì‹¤íŒ¨"])
    
    def _apply_segmentation_mask(self, image: np.ndarray, mask: np.ndarray) -> np.ndarray:
        """ë¶„í•  ë§ˆìŠ¤í¬ ì ìš©"""
        try:
            # ë§ˆìŠ¤í¬ í¬ê¸° ì¡°ì •
            if mask.shape[:2] != image.shape[:2]:
                mask = cv2.resize(mask, (image.shape[1], image.shape[0]))
            
            # ë°”ì´ë„ˆë¦¬ ë§ˆìŠ¤í¬ë¡œ ë³€í™˜
            if len(mask.shape) == 3:
                mask = cv2.cvtColor(mask, cv2.COLOR_RGB2GRAY)
            
            # ì„ê³„ê°’ ì ìš©
            _, binary_mask = cv2.threshold(mask, 127, 255, cv2.THRESH_BINARY)
            
            # 3ì±„ë„ë¡œ í™•ì¥
            mask_3d = np.stack([binary_mask] * 3, axis=-1) / 255.0
            
            # ë°°ê²½ì„ í°ìƒ‰ìœ¼ë¡œ ì„¤ì •
            background = np.ones_like(image) * 255
            result = image * mask_3d + background * (1 - mask_3d)
            
            return result.astype(np.uint8)
            
        except Exception as e:
            logger.error(f"âŒ ë¶„í•  ë§ˆìŠ¤í¬ ì ìš© ì‹¤íŒ¨: {e}")
            return image
    
    def _create_color_analysis_visualization(self, color_analysis: Dict[str, Any]) -> np.ndarray:
        """ìƒ‰ìƒ ë¶„ì„ ì‹œê°í™” ìƒì„±"""
        try:
            viz_width = 500
            viz_height = 400
            viz_pil = Image.new('RGB', (viz_width, viz_height), (255, 255, 255))
            draw = ImageDraw.Draw(viz_pil)
            
            # ì œëª©
            title_font = self.get_font("arial", 18)
            draw.text((viz_width//2 - 70, 20), "ìƒ‰ìƒ ë¶„ì„ ê²°ê³¼", fill=(50, 50, 50), font=title_font)
            
            # ì£¼ìš” ìƒ‰ìƒ íŒ”ë ˆíŠ¸
            dominant_colors = color_analysis.get('dominant_colors', [(128, 128, 128)])
            palette_y = 70
            palette_height = 60
            
            # íŒ”ë ˆíŠ¸ ë°°ê²½
            draw.rectangle([50, palette_y, viz_width - 50, palette_y + palette_height], 
                          fill=(240, 240, 240), outline=(200, 200, 200))
            
            # ìƒ‰ìƒë³„ ì˜ì—­
            color_width = (viz_width - 100) // len(dominant_colors)
            for i, color in enumerate(dominant_colors):
                x1 = 50 + i * color_width
                x2 = 50 + (i + 1) * color_width
                draw.rectangle([x1, palette_y, x2, palette_y + palette_height], fill=tuple(color))
                
                # ìƒ‰ìƒ ì •ë³´ í…ìŠ¤íŠ¸
                color_text = f"RGB({color[0]}, {color[1]}, {color[2]})"
                text_font = self.get_font("arial", 10)
                text_bbox = draw.textbbox((0, 0), color_text, font=text_font)
                text_width = text_bbox[2] - text_bbox[0]
                
                # í…ìŠ¤íŠ¸ ìƒ‰ìƒ (ëŒ€ë¹„ë¥¼ ìœ„í•´ ë°ê¸°ì— ë”°ë¼ ì¡°ì •)
                brightness = sum(color) / 3
                text_color = (255, 255, 255) if brightness < 128 else (0, 0, 0)
                
                draw.text((x1 + (color_width - text_width) // 2, palette_y + 25), 
                         color_text, fill=text_color, font=text_font)
            
            # ìƒ‰ìƒ í†µê³„
            stats_y = palette_y + palette_height + 30
            stats_font = self.get_font("arial", 14)
            
            # ì£¼ìš” ìƒ‰ìƒ ì´ë¦„
            primary_color_name = color_analysis.get('primary_color_name', 'ì•Œ ìˆ˜ ì—†ìŒ')
            draw.text((50, stats_y), f"ì£¼ìš” ìƒ‰ìƒ: {primary_color_name}", fill=(70, 70, 70), font=stats_font)
            
            # ìƒ‰ìƒ ë‹¤ì–‘ì„±
            color_diversity = color_analysis.get('color_diversity', 0.5)
            diversity_text = "ë†’ìŒ" if color_diversity > 0.7 else "ë³´í†µ" if color_diversity > 0.4 else "ë‚®ìŒ"
            draw.text((50, stats_y + 30), f"ìƒ‰ìƒ ë‹¤ì–‘ì„±: {diversity_text} ({color_diversity:.2f})", 
                     fill=(70, 70, 70), font=stats_font)
            
            # ë°ê¸° ë¶„ì„
            brightness_avg = color_analysis.get('average_brightness', 128)
            brightness_text = "ë°ìŒ" if brightness_avg > 180 else "ë³´í†µ" if brightness_avg > 100 else "ì–´ë‘ì›€"
            draw.text((50, stats_y + 60), f"ì „ì²´ ë°ê¸°: {brightness_text} ({brightness_avg:.0f})", 
                     fill=(70, 70, 70), font=stats_font)
            
            # ì±„ë„ ë¶„ì„
            saturation_avg = color_analysis.get('average_saturation', 0.5)
            saturation_text = "ë†’ìŒ" if saturation_avg > 0.7 else "ë³´í†µ" if saturation_avg > 0.4 else "ë‚®ìŒ"
            draw.text((50, stats_y + 90), f"ì±„ë„: {saturation_text} ({saturation_avg:.2f})", 
                     fill=(70, 70, 70), font=stats_font)
            
            return np.array(viz_pil)
            
        except Exception as e:
            logger.error(f"âŒ ìƒ‰ìƒ ë¶„ì„ ì‹œê°í™” ì‹¤íŒ¨: {e}")
            return self._create_text_info("ìƒ‰ìƒ ë¶„ì„", ["ë¶„ì„ ê²°ê³¼ ì—†ìŒ"])
    
    def _create_category_info_panel(self, category_info: Dict[str, Any]) -> np.ndarray:
        """ì¹´í…Œê³ ë¦¬ ì •ë³´ íŒ¨ë„ ìƒì„±"""
        try:
            panel_width = 400
            panel_height = 350
            panel_pil = Image.new('RGB', (panel_width, panel_height), (248, 249, 250))
            draw = ImageDraw.Draw(panel_pil)
            
            # ì œëª©
            title_font = self.get_font("arial", 18)
            draw.text((panel_width//2 - 70, 20), "ì˜ë¥˜ ì¹´í…Œê³ ë¦¬ ë¶„ì„", fill=(52, 58, 64), font=title_font)
            
            # ì¹´í…Œê³ ë¦¬ ì •ë³´
            category = category_info.get('category', 'ì•Œ ìˆ˜ ì—†ìŒ')
            subcategory = category_info.get('subcategory', '')
            confidence = category_info.get('confidence', 0.0)
            
            # ë©”ì¸ ì¹´í…Œê³ ë¦¬ í‘œì‹œ
            main_y = 70
            category_font = self.get_font("arial", 20)
            
            # ì¹´í…Œê³ ë¦¬ ë°°ê²½ ìƒ‰ìƒ
            category_color = CLOTHING_COLORS.get(category.lower(), (128, 128, 128))
            draw.rectangle([50, main_y, panel_width - 50, main_y + 50], 
                          fill=category_color, outline=(0, 0, 0))
            
            # ì¹´í…Œê³ ë¦¬ í…ìŠ¤íŠ¸
            text_color = (255, 255, 255) if sum(category_color) / 3 < 128 else (0, 0, 0)
            draw.text((panel_width//2 - len(category) * 6, main_y + 15), 
                     category.upper(), fill=text_color, font=category_font)
            
            # ì„¸ë¶€ ì •ë³´
            details_y = main_y + 70
            detail_font = self.get_font("arial", 14)
            
            details = [
                f"ì¹´í…Œê³ ë¦¬: {category}",
                f"ì„¸ë¶€ ë¶„ë¥˜: {subcategory}" if subcategory else "",
                f"ì‹ ë¢°ë„: {confidence:.1%}",
                f"ìŠ¤íƒ€ì¼: {category_info.get('style', 'ìºì£¼ì–¼')}",
                f"ì‹œì¦Œ: {category_info.get('season', 'ì‚¬ê³„ì ˆ')}",
                f"ì„±ë³„: {category_info.get('gender', 'ìœ ë‹ˆì„¹ìŠ¤')}"
            ]
            
            for i, detail in enumerate(details):
                if detail:  # ë¹ˆ ë¬¸ìì—´ ì œì™¸
                    y = details_y + i * 25
                    draw.text((60, y), detail, fill=(73, 80, 87), font=detail_font)
            
            # íŠ¹ì§• íƒœê·¸ë“¤
            features = category_info.get('features', [])
            if features:
                tags_y = details_y + len([d for d in details if d]) * 25 + 20
                tag_font = self.get_font("arial", 11)
                
                x_offset = 60
                for feature in features[:5]:  # ìµœëŒ€ 5ê°œë§Œ í‘œì‹œ
                    # íƒœê·¸ í¬ê¸° ê³„ì‚°
                    text_bbox = draw.textbbox((0, 0), feature, font=tag_font)
                    tag_width = text_bbox[2] - text_bbox[0] + 16
                    tag_height = 22
                    
                    # íƒœê·¸ ë°°ê²½
                    draw.rectangle([x_offset, tags_y, x_offset + tag_width, tags_y + tag_height], 
                                  fill=(108, 117, 125), outline=(73, 80, 87))
                    
                    # íƒœê·¸ í…ìŠ¤íŠ¸
                    draw.text((x_offset + 8, tags_y + 4), feature, fill=(255, 255, 255), font=tag_font)
                    
                    x_offset += tag_width + 10
                    if x_offset > panel_width - 100:  # ì¤„ë°”ê¿ˆ
                        x_offset = 60
                        tags_y += 30
            
            return np.array(panel_pil)
            
        except Exception as e:
            logger.error(f"âŒ ì¹´í…Œê³ ë¦¬ ì •ë³´ íŒ¨ë„ ìƒì„± ì‹¤íŒ¨: {e}")
            return self._create_text_info("ì¹´í…Œê³ ë¦¬ ë¶„ì„", ["ë¶„ì„ ê²°ê³¼ ì—†ìŒ"])
    
    def _create_comparison_grid(self, images: List[np.ndarray], titles: List[str] = None) -> np.ndarray:
        """ë¹„êµ ê·¸ë¦¬ë“œ ì´ë¯¸ì§€ ìƒì„± (ê°œì„ ëœ ë²„ì „)"""
        try:
            if not images:
                return np.zeros((400, 400, 3), dtype=np.uint8)
            
            # ì´ë¯¸ì§€ í¬ê¸° í†µì¼ (ë” í° í¬ê¸°ë¡œ)
            target_height = 400 if self.is_m3_max else 300
            processed_images = []
            
            for img in images:
                # ë¹„ìœ¨ ìœ ì§€í•˜ë©´ì„œ ë¦¬ì‚¬ì´ì¦ˆ
                height, width = img.shape[:2]
                scale = target_height / height
                new_width = int(width * scale)
                
                # ê³ í’ˆì§ˆ ë¦¬ì‚¬ì´ì¦ˆ
                if self.is_m3_max:
                    resized = cv2.resize(img, (new_width, target_height), interpolation=cv2.INTER_LANCZOS4)
                else:
                    resized = cv2.resize(img, (new_width, target_height), interpolation=cv2.INTER_LINEAR)
                
                processed_images.append(resized)
            
            # ê·¸ë¦¬ë“œ ë ˆì´ì•„ì›ƒ ê²°ì •
            num_images = len(processed_images)
            if num_images == 1:
                result = processed_images[0]
            elif num_images == 2:
                # 2ê°œ: ìˆ˜í‰ ë°°ì¹˜
                max_width = max(img.shape[1] for img in processed_images)
                # ë„ˆë¹„ í†µì¼
                unified_images = []
                for img in processed_images:
                    if img.shape[1] < max_width:
                        # ì¤‘ì•™ ì •ë ¬ë¡œ íŒ¨ë”©
                        padding = max_width - img.shape[1]
                        left_pad = padding // 2
                        right_pad = padding - left_pad
                        padded = np.pad(img, ((0, 0), (left_pad, right_pad), (0, 0)), 
                                      mode='constant', constant_values=255)
                        unified_images.append(padded)
                    else:
                        unified_images.append(img)
                
                # ê°„ê²© ì¶”ê°€
                gap = np.ones((target_height, 20, 3), dtype=np.uint8) * 240
                result = np.hstack([unified_images[0], gap, unified_images[1]])
            else:
                # 3ê°œ ì´ìƒ: ìˆ˜í‰ ë°°ì¹˜ (ê°„ê²© í¬í•¨)
                max_width = max(img.shape[1] for img in processed_images)
                unified_images = []
                
                for img in processed_images:
                    if img.shape[1] < max_width:
                        padding = max_width - img.shape[1]
                        left_pad = padding // 2
                        right_pad = padding - left_pad
                        padded = np.pad(img, ((0, 0), (left_pad, right_pad), (0, 0)), 
                                      mode='constant', constant_values=255)
                        unified_images.append(padded)
                    else:
                        unified_images.append(img)
                
                # ê°„ê²©ì„ ë‘ê³  ë°°ì¹˜
                result_parts = []
                for i, img in enumerate(unified_images):
                    result_parts.append(img)
                    if i < len(unified_images) - 1:  # ë§ˆì§€ë§‰ì´ ì•„ë‹ˆë©´ ê°„ê²© ì¶”ê°€
                        gap = np.ones((target_height, 15, 3), dtype=np.uint8) * 240
                        result_parts.append(gap)
                
                result = np.hstack(result_parts)
            
            # ì œëª© ì¶”ê°€
            if titles and len(titles) == len(processed_images):
                # ì œëª© ê³µê°„ì„ ìœ„í•´ ì´ë¯¸ì§€ í™•ì¥
                title_height = 50
                extended_height = result.shape[0] + title_height
                extended_result = np.ones((extended_height, result.shape[1], 3), dtype=np.uint8) * 250
                extended_result[title_height:, :] = result
                
                # PILë¡œ ë³€í™˜í•˜ì—¬ í…ìŠ¤íŠ¸ ì¶”ê°€
                result_pil = Image.fromarray(extended_result)
                draw = ImageDraw.Draw(result_pil)
                title_font = self.get_font("arial", 16)
                
                # ê° ì´ë¯¸ì§€ ì˜ì—­ì˜ ì¤‘ì•™ì— ì œëª© ë°°ì¹˜
                if num_images == 1:
                    title_x = result.shape[1] // 2 - len(titles[0]) * 5
                    draw.text((title_x, 15), titles[0], fill=(50, 50, 50), font=title_font)
                else:
                    x_offset = 0
                    for i, (title, img) in enumerate(zip(titles, processed_images)):
                        img_center_x = x_offset + img.shape[1] // 2
                        title_x = img_center_x - len(title) * 5
                        draw.text((title_x, 15), title, fill=(50, 50, 50), font=title_font)
                        
                        # ë‹¤ìŒ ì´ë¯¸ì§€ ìœ„ì¹˜ ê³„ì‚°
                        x_offset += img.shape[1]
                        if i < len(processed_images) - 1:  # ê°„ê²© ê³ ë ¤
                            x_offset += 15 if num_images > 2 else 20
                
                result = np.array(result_pil)
            
            return result
            
        except Exception as e:
            logger.error(f"âŒ ë¹„êµ ê·¸ë¦¬ë“œ ìƒì„± ì‹¤íŒ¨: {e}")
            # í´ë°±: ì²« ë²ˆì§¸ ì´ë¯¸ì§€ë§Œ ë°˜í™˜
            return images[0] if images else np.zeros((400, 400, 3), dtype=np.uint8)
    
    def _create_text_info(self, title: str, items: List[str]) -> np.ndarray:
        """í…ìŠ¤íŠ¸ ê¸°ë°˜ ì •ë³´ íŒ¨ë„ ìƒì„±"""
        try:
            panel_width = 400
            panel_height = 300
            panel_pil = Image.new('RGB', (panel_width, panel_height), (248, 249, 250))
            draw = ImageDraw.Draw(panel_pil)
            
            # ì œëª©
            title_font = self.get_font("arial", 18)
            draw.text((panel_width//2 - len(title) * 5, 30), title, fill=(52, 58, 64), font=title_font)
            
            # í•­ëª©ë“¤
            item_font = self.get_font("arial", 14)
            y_offset = 80
            
            for item in items:
                draw.text((30, y_offset), f"â€¢ {item}", fill=(73, 80, 87), font=item_font)
                y_offset += 30
            
            return np.array(panel_pil)
            
        except Exception as e:
            logger.error(f"âŒ í…ìŠ¤íŠ¸ ì •ë³´ íŒ¨ë„ ìƒì„± ì‹¤íŒ¨: {e}")
            # ìµœì†Œí•œì˜ í´ë°±
            fallback = np.ones((300, 400, 3), dtype=np.uint8) * 240
            return fallback

# ============================================================================
# ğŸ”§ ê¸°ì¡´ í˜¸í™˜ í•¨ìˆ˜ë“¤ (ì „ì—­ í•¨ìˆ˜ë¡œ ìœ ì§€)
# ============================================================================

def resize_image(image: Image.Image, target_size: Tuple[int, int], maintain_ratio: bool = True) -> Image.Image:
    """ê¸°ì¡´ resize_image í•¨ìˆ˜ì™€ ì™„ì „ í˜¸í™˜"""
    return ImageProcessor.resize_image(image, target_size, maintain_ratio)

def enhance_image_quality(image: Image.Image) -> Image.Image:
    """ê¸°ì¡´ enhance_image_quality í•¨ìˆ˜ì™€ ì™„ì „ í˜¸í™˜"""
    return ImageProcessor.enhance_image_quality(image)

def convert_to_rgb(image: Image.Image) -> Image.Image:
    """ê¸°ì¡´ convert_to_rgb í•¨ìˆ˜ì™€ ì™„ì „ í˜¸í™˜"""
    return ImageProcessor.convert_to_rgb(image)

async def validate_image_content(image_bytes: bytes) -> bool:
    """ê¸°ì¡´ validate_image_content í•¨ìˆ˜ì™€ ì™„ì „ í˜¸í™˜"""
    try:
        image = Image.open(io.BytesIO(image_bytes))
        width, height = image.size
        
        # ìµœì†Œ/ìµœëŒ€ í¬ê¸° ê²€ì‚¬
        if width < 100 or height < 100:
            return False
        if width > 4096 or height > 4096:
            return False
            
        return True
    except Exception:
        return False

# ============================================================================
# ğŸ¯ ì‹œê°í™” ì „ìš© í¸ì˜ í•¨ìˆ˜ë“¤ (ìƒˆë¡œ ì¶”ê°€)
# ============================================================================

def create_step_visualization(step_id: int, **kwargs) -> Dict[str, str]:
    """ë‹¨ê³„ë³„ ì‹œê°í™” ìƒì„± í¸ì˜ í•¨ìˆ˜"""
    processor = get_image_processor()
    
    if step_id == 3:  # ì¸ì²´ íŒŒì‹±
        return processor.create_human_parsing_visualization(**kwargs)
    elif step_id == 4:  # í¬ì¦ˆ ì¶”ì •
        return processor.create_pose_estimation_visualization(**kwargs)
    elif step_id == 5:  # ì˜ë¥˜ ë¶„ì„
        return processor.create_clothing_analysis_visualization(**kwargs)
    elif step_id == 7:  # ê°€ìƒ í”¼íŒ…
        return processor.create_virtual_fitting_visualization(**kwargs)
    else:
        logger.warning(f"ë‹¨ê³„ {step_id}ì— ëŒ€í•œ ì‹œê°í™” ë¯¸êµ¬í˜„")
        return {}

# ============================================================================
# ğŸ”§ ê¸°ì¡´ ì¶”ê°€ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤ (ì™„ì „ ìœ ì§€)
# ============================================================================

def save_temp_image(
    image: Union[Image.Image, np.ndarray], 
    prefix: str = "temp", 
    suffix: str = ".jpg",
    directory: Optional[str] = None
) -> str:
    """
    ì„ì‹œ ì´ë¯¸ì§€ íŒŒì¼ ì €ì¥
    âœ… ê¸°ì¡´ í•¨ìˆ˜ì™€ ì™„ì „ í˜¸í™˜
    """
    try:
        # ë””ë ‰í† ë¦¬ ì„¤ì •
        if directory is None:
            directory = tempfile.gettempdir()
        
        # íŒŒì¼ëª… ìƒì„±
        filename = f"{prefix}_{uuid.uuid4().hex[:8]}{suffix}"
        filepath = os.path.join(directory, filename)
        
        # PIL Imageë¡œ ë³€í™˜
        if isinstance(image, np.ndarray):
            if image.dtype != np.uint8:
                image = (image * 255).astype(np.uint8)
            if len(image.shape) == 3 and image.shape[2] == 3:
                # BGR to RGB ë³€í™˜ (OpenCV ì‚¬ìš© ì‹œ)
                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            pil_image = Image.fromarray(image)
        else:
            pil_image = image
        
        # RGBë¡œ ë³€í™˜
        if pil_image.mode != 'RGB':
            pil_image = pil_image.convert('RGB')
        
        # íŒŒì¼ ì €ì¥
        pil_image.save(filepath, "JPEG", quality=90)
        logger.debug(f"ì„ì‹œ ì´ë¯¸ì§€ ì €ì¥: {filepath}")
        
        return filepath
        
    except Exception as e:
        logger.error(f"ì„ì‹œ ì´ë¯¸ì§€ ì €ì¥ ì‹¤íŒ¨: {e}")
        raise

def image_to_base64(
    image: Union[Image.Image, np.ndarray], 
    format: str = "JPEG"
) -> str:
    """
    ì´ë¯¸ì§€ë¥¼ base64 ë¬¸ìì—´ë¡œ ë³€í™˜
    âœ… ê¸°ì¡´ í•¨ìˆ˜ì™€ ì™„ì „ í˜¸í™˜
    """
    processor = get_image_processor()
    if isinstance(image, np.ndarray):
        return processor._numpy_to_base64(image, format)
    else:
        # PIL ì´ë¯¸ì§€ ì²˜ë¦¬
        try:
            if image.mode != 'RGB':
                image = image.convert('RGB')
            
            buffer = io.BytesIO()
            quality = processor.default_quality if processor.is_m3_max else 90
            image.save(buffer, format=format, quality=quality)
            return base64.b64encode(buffer.getvalue()).decode('utf-8')
        except Exception as e:
            logger.error(f"âŒ PIL â†’ Base64 ë³€í™˜ ì‹¤íŒ¨: {e}")
            return ""

def base64_to_image(base64_str: str) -> Image.Image:
    """
    base64 ë¬¸ìì—´ì„ ì´ë¯¸ì§€ë¡œ ë³€í™˜
    âœ… ê¸°ì¡´ í•¨ìˆ˜ì™€ ì™„ì „ í˜¸í™˜
    """
    try:
        image_data = base64.b64decode(base64_str)
        image = Image.open(io.BytesIO(image_data))
        
        if image.mode != 'RGB':
            image = image.convert('RGB')
        
        return image
        
    except Exception as e:
        logger.error(f"base64 ì´ë¯¸ì§€ ë³€í™˜ ì‹¤íŒ¨: {e}")
        raise

# ============================================================================
# ğŸ¯ ì „ì—­ ImageProcessor ì¸ìŠ¤í„´ìŠ¤
# ============================================================================

_global_image_processor = None

def get_image_processor() -> ImageProcessor:
    """ì „ì—­ ì´ë¯¸ì§€ í”„ë¡œì„¸ì„œ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    global _global_image_processor
    if _global_image_processor is None:
        _global_image_processor = ImageProcessor()
    return _global_image_processor

# ============================================================================
# ğŸ‰ ì™„ë£Œ ë©”ì‹œì§€
# ============================================================================

logger.info("ğŸ¨ ì™„ì „ ê°•í™”ëœ ì´ë¯¸ì§€ ì²˜ë¦¬ ìœ í‹¸ë¦¬í‹° ë¡œë“œ ì™„ë£Œ")
logger.info("âœ… ê¸°ì¡´ í•¨ìˆ˜ 100% í˜¸í™˜ì„± ìœ ì§€")
logger.info("âœ… ë‹¨ê³„ë³„ ì‹œê°í™” ì™„ì „ êµ¬í˜„")
logger.info("âœ… M3 Max ìµœì í™” ì ìš©")
logger.info("âœ… ê³ í’ˆì§ˆ ì´ë¯¸ì§€ ì²˜ë¦¬")
logger.info("âœ… PIL/OpenCV/Matplotlib í†µí•©")
logger.info("ğŸš€ ì‹œê°í™” ì™„ì „ êµ¬í˜„ ì¤€ë¹„ ì™„ë£Œ!")