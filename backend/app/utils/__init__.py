# backend/app/utils/__init__.py  
"""
ğŸ MyCloset AI í†µí•© ìœ í‹¸ë¦¬í‹° ì‹œìŠ¤í…œ v6.1 - import ê²½ë¡œ ìˆ˜ì •
================================================================
âœ… StepModelInterface import ê²½ë¡œ ìˆ˜ì •
âœ… register_model_requirement ë©”ì„œë“œ ì§€ì›
âœ… ìˆœí™˜ì°¸ì¡° ì™„ì „ í•´ê²°
âœ… conda í™˜ê²½ 100% ìµœì í™”  
âœ… M3 Max 128GB ë©”ëª¨ë¦¬ í™œìš©
âœ… main.py í˜¸ì¶œ íŒ¨í„´ ì™„ì „ í˜¸í™˜

ìˆ˜ì •ì‚¬í•­:
- StepModelInterfaceë¥¼ ai_pipeline.interfaceì—ì„œ import
- get_step_model_interface í•¨ìˆ˜ ì™„ì „ êµ¬í˜„
- register_model_requirement ë©”ì„œë“œ ì§€ì› í™•ì¸

ì‘ì„±ì: MyCloset AI Team
ë‚ ì§œ: 2025-07-24
ë²„ì „: v6.1.0 (Import Path Fixed)
"""

import logging
import threading
import asyncio
import sys
import time
import platform
import psutil
from typing import Dict, Any, Optional, List, Union, Callable, Type
from pathlib import Path
from dataclasses import dataclass, field
from enum import Enum
from functools import lru_cache
import warnings
import weakref
import gc

# ê²½ê³  ë¬´ì‹œ
warnings.filterwarnings('ignore')

# =============================================================================
# ğŸ”¥ ê¸°ë³¸ ë¡œê¹… ì„¤ì •
# =============================================================================

logger = logging.getLogger(__name__)

# =============================================================================  
# ğŸ”¥ ì‹œìŠ¤í…œ ì •ë³´ ê°ì§€
# =============================================================================

def _get_system_info() -> Dict[str, Any]:
    """ì‹œìŠ¤í…œ ì •ë³´ ê°ì§€"""
    try:
        # ê¸°ë³¸ ì •ë³´
        system_info = {
            "platform": platform.system(),
            "cpu_count": psutil.cpu_count() if hasattr(psutil, 'cpu_count') else 4,
            "python_version": platform.python_version()
        }
        
        # ë©”ëª¨ë¦¬ ì •ë³´
        try:
            memory = psutil.virtual_memory()
            system_info["memory_gb"] = memory.total / (1024**3)
        except Exception:
            system_info["memory_gb"] = 16.0
        
        # M3 Max ê°ì§€
        try:
            if system_info["platform"] == "Darwin":
                import subprocess
                result = subprocess.run(['sysctl', '-n', 'machdep.cpu.brand_string'], 
                                      capture_output=True, text=True, timeout=2)
                if "Apple" in result.stdout and "M3" in result.stdout:
                    system_info["is_m3_max"] = True
                    system_info["memory_gb"] = 128.0  # M3 Max ê¸°ë³¸ê°’
                else:
                    system_info["is_m3_max"] = False
            else:
                system_info["is_m3_max"] = False
        except Exception:
            system_info["is_m3_max"] = False
            
        # ë””ë°”ì´ìŠ¤ ê°ì§€
        try:
            import torch
            if hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
                system_info["device"] = "mps"
            elif torch.cuda.is_available():
                system_info["device"] = "cuda"
            else:
                system_info["device"] = "cpu"
        except ImportError:
            system_info["device"] = "cpu"
        
        return system_info
        
    except Exception as e:
        logger.warning(f"ì‹œìŠ¤í…œ ì •ë³´ ê°ì§€ ì‹¤íŒ¨: {e}")
        return {
            "platform": "unknown",
            "is_m3_max": False,
            "device": "cpu",
            "cpu_count": 4,
            "memory_gb": 16,
            "python_version": "3.8.0"
        }

# ì „ì—­ ì‹œìŠ¤í…œ ì •ë³´
SYSTEM_INFO = _get_system_info()

# =============================================================================
# ğŸ”¥ í†µí•© ë°ì´í„° êµ¬ì¡° (ìˆœí™˜ì°¸ì¡° ì—†ìŒ)
# =============================================================================

class UtilsMode(Enum):
    """ìœ í‹¸ë¦¬í‹° ëª¨ë“œ"""
    LEGACY = "legacy"        # ê¸°ì¡´ ë°©ì‹ (v3.0)
    UNIFIED = "unified"      # ìƒˆë¡œìš´ í†µí•© ë°©ì‹ (v6.0)
    HYBRID = "hybrid"        # í˜¼í•© ë°©ì‹

@dataclass
class SystemConfig:
    """ì‹œìŠ¤í…œ ì„¤ì •"""
    device: str = "auto"
    memory_gb: float = 16.0
    is_m3_max: bool = False
    optimization_enabled: bool = True
    max_workers: int = 4
    cache_enabled: bool = True
    debug_mode: bool = False

@dataclass
class StepConfig:
    """Step ì„¤ì • (ìˆœí™˜ì°¸ì¡° ì—†ëŠ” ë°ì´í„° ì „ìš©)"""
    step_name: str
    model_name: Optional[str] = None
    model_type: Optional[str] = None
    model_class: Optional[str] = None
    input_size: tuple = (512, 512)
    device: str = "auto"
    precision: str = "fp16"
    optimization_params: Dict[str, Any] = field(default_factory=dict)
    metadata: Dict[str, Any] = field(default_factory=dict)

@dataclass
class ModelInfo:
    """ëª¨ë¸ ì •ë³´ (ìˆœí™˜ì°¸ì¡° ì—†ëŠ” ë°ì´í„° ì „ìš©)"""
    name: str
    path: str
    model_type: str
    file_size_mb: float
    confidence_score: float = 1.0
    metadata: Dict[str, Any] = field(default_factory=dict)

# =============================================================================
# ğŸ”¥ StepModelInterface import (ìˆ˜ì •ëœ ê²½ë¡œ)
# =============================================================================

# StepModelInterfaceë¥¼ ì˜¬ë°”ë¥¸ ê²½ë¡œì—ì„œ import
try:
    from ..ai_pipeline.interface.step_interface import StepModelInterface
    STEP_INTERFACE_AVAILABLE = True
    logger.info("âœ… StepModelInterface import ì„±ê³µ (ai_pipeline.interface)")
except ImportError as e:
    logger.warning(f"âš ï¸ StepModelInterface import ì‹¤íŒ¨: {e}")
    STEP_INTERFACE_AVAILABLE = False
    
    # í´ë°± í´ë˜ìŠ¤ ì •ì˜
    class StepModelInterface:
        """í´ë°± StepModelInterface"""
        def __init__(self, step_name: str, model_loader=None):
            self.step_name = step_name
            self.model_loader = model_loader
            self.logger = logging.getLogger(f"FallbackInterface.{step_name}")
            
        def register_model_requirement(self, model_name: str, model_type: str = "BaseModel", **kwargs) -> bool:
            """í´ë°± register_model_requirement"""
            self.logger.warning(f"âš ï¸ í´ë°± ëª¨ë“œ: {model_name} ìš”êµ¬ì‚¬í•­ ë“±ë¡ ë¬´ì‹œ")
            return True
            
        def list_available_models(self, step_class: Optional[str] = None, model_type: Optional[str] = None) -> List[Dict[str, Any]]:
            """í´ë°± list_available_models"""
            return [{"name": "fallback_model", "type": "fallback", "available": False}]
            
        async def get_model(self, model_name: str) -> Optional[Any]:
            """í´ë°± get_model"""
            return {"fallback": True, "model_name": model_name}
            
        def get_model_sync(self, model_name: str) -> Optional[Any]:
            """í´ë°± get_model_sync"""
            return {"fallback": True, "model_name": model_name}

# =============================================================================
# ğŸ”¥ í•µì‹¬ í•¨ìˆ˜: get_step_model_interface (main.py ì™„ì „ í˜¸í™˜)
# =============================================================================

def get_step_model_interface(step_name: str, model_loader_instance=None) -> StepModelInterface:
    """
    ğŸ”¥ main.pyì—ì„œ ìš”êµ¬í•˜ëŠ” í•µì‹¬ í•¨ìˆ˜ (ì™„ì „ ìˆ˜ì •)
    âœ… import ì˜¤ë¥˜ í•´ê²°
    âœ… StepModelInterface ë°˜í™˜
    âœ… register_model_requirement ë©”ì„œë“œ ì§€ì›
    âœ… ë¹„ë™ê¸° ë©”ì„œë“œ í¬í•¨
    """
    try:
        # ModelLoader ì¸ìŠ¤í„´ìŠ¤ ê°€ì ¸ì˜¤ê¸°
        if model_loader_instance is None:
            try:
                # ì „ì—­ ModelLoader ì‹œë„
                from ..ai_pipeline.utils.model_loader import get_global_model_loader
                model_loader_instance = get_global_model_loader()
                logger.debug(f"âœ… ì „ì—­ ModelLoader íšë“: {step_name}")
            except ImportError as e:
                logger.warning(f"âš ï¸ ModelLoader import ì‹¤íŒ¨: {e}")
                model_loader_instance = None
            except Exception as e:
                logger.warning(f"âš ï¸ ì „ì—­ ModelLoader íšë“ ì‹¤íŒ¨: {e}")
                model_loader_instance = None
        
        # Step ì¸í„°í˜ì´ìŠ¤ ìƒì„±
        interface = StepModelInterface(step_name, model_loader_instance)
        
        # register_model_requirement ë©”ì„œë“œ í™•ì¸
        if hasattr(interface, 'register_model_requirement'):
            logger.debug(f"âœ… register_model_requirement ë©”ì„œë“œ í™•ì¸: {step_name}")
        else:
            logger.warning(f"âš ï¸ register_model_requirement ë©”ì„œë“œ ì—†ìŒ: {step_name}")
        
        logger.info(f"ğŸ”— {step_name} ëª¨ë¸ ì¸í„°í˜ì´ìŠ¤ ìƒì„± ì™„ë£Œ")
        return interface
        
    except Exception as e:
        logger.error(f"âŒ {step_name} ì¸í„°í˜ì´ìŠ¤ ìƒì„± ì‹¤íŒ¨: {e}")
        # ì™„ì „ í´ë°± ì¸í„°í˜ì´ìŠ¤
        return StepModelInterface(step_name, None)

# =============================================================================
# ğŸ”¥ í†µí•© ìœ í‹¸ë¦¬í‹° ë§¤ë‹ˆì € (ê¸°ì¡´ ì½”ë“œ ìœ ì§€)
# =============================================================================

class UnifiedUtilsManager:
    """
    ğŸ í†µí•© ìœ í‹¸ë¦¬í‹° ë§¤ë‹ˆì €
    âœ… ìˆœí™˜ì°¸ì¡° ì™„ì „ í•´ê²°
    âœ… ì˜ì¡´ì„± ì£¼ì… íŒ¨í„´
    âœ… ëª¨ë“  ê¸°ëŠ¥ í†µí•© ê´€ë¦¬
    âœ… ë¹„ë™ê¸° ì²˜ë¦¬ ì™„ì „ ê°œì„ 
    """
    
    _instance = None
    _lock = threading.Lock()
    
    def __new__(cls):
        with cls._lock:
            if cls._instance is None:
                cls._instance = super().__new__(cls)
                cls._instance._initialized = False
            return cls._instance
    
    def __init__(self):
        if self._initialized:
            return
        
        self.logger = logging.getLogger(f"{__name__}.UnifiedUtilsManager")
        
        # ê¸°ë³¸ ì„¤ì •
        self.system_config = SystemConfig(
            device=SYSTEM_INFO["device"],
            memory_gb=SYSTEM_INFO["memory_gb"],
            is_m3_max=SYSTEM_INFO["is_m3_max"],
            max_workers=min(SYSTEM_INFO["cpu_count"], 8)
        )
        
        # ìƒíƒœ ê´€ë¦¬
        self.is_initialized = False
        self.initialization_time = None
        
        # ì»´í¬ë„ŒíŠ¸ ì €ì¥ì†Œ (ì•½í•œ ì°¸ì¡° ì‚¬ìš©)
        self._components = weakref.WeakValueDictionary()
        self._model_interfaces = {}
        self._step_instances = {}
        
        # ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
        self.stats = {
            "interfaces_created": 0,
            "memory_optimizations": 0,
            "errors": 0,
            "cache_hits": 0
        }
        
        # ìŠ¤ë ˆë”©
        self._interface_lock = threading.RLock()
        
        self._initialized = True
        self.logger.info("âœ… UnifiedUtilsManager ì´ˆê¸°í™” ì™„ë£Œ")
    
    def create_step_model_interface(self, step_name: str) -> StepModelInterface:
        """Step ëª¨ë¸ ì¸í„°í˜ì´ìŠ¤ ìƒì„± (main.py í˜¸í™˜)"""
        try:
            if step_name in self._model_interfaces:
                return self._model_interfaces[step_name]
            
            interface = StepModelInterface(step_name, getattr(self, 'model_loader', None))
            self._model_interfaces[step_name] = interface
            
            self.logger.info(f"ğŸ”— {step_name} ëª¨ë¸ ì¸í„°í˜ì´ìŠ¤ ìƒì„± ì™„ë£Œ")
            return interface
            
        except Exception as e:
            self.logger.error(f"âŒ {step_name} ëª¨ë¸ ì¸í„°í˜ì´ìŠ¤ ìƒì„± ì‹¤íŒ¨: {e}")
            # í´ë°± ì¸í„°í˜ì´ìŠ¤
            return StepModelInterface(step_name, None)
    
    async def optimize_memory(self) -> Dict[str, Any]:
        """ë©”ëª¨ë¦¬ ìµœì í™”"""
        try:
            start_time = time.time()
            
            # Python ê°€ë¹„ì§€ ì»¬ë ‰ì…˜
            collected = gc.collect()
            
            # PyTorch ë©”ëª¨ë¦¬ ì •ë¦¬ (ê°€ëŠ¥í•œ ê²½ìš°)
            torch_cleaned = False
            try:
                import torch
                if torch.cuda.is_available():
                    torch.cuda.empty_cache()
                    torch_cleaned = True
                elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
                    # M3 Max ë©”ëª¨ë¦¬ ì •ë¦¬
                    gc.collect()
                    torch_cleaned = True
            except ImportError:
                pass
            
            # ì•½í•œ ì°¸ì¡° ì •ë¦¬
            cleaned_components = len(self._components)
            self._components.clear()
            
            elapsed_time = time.time() - start_time
            self.stats["memory_optimizations"] += 1
            
            result = {
                "success": True,
                "elapsed_time": elapsed_time,
                "garbage_collected": collected,
                "torch_cleaned": torch_cleaned,
                "components_cleaned": cleaned_components,
                "timestamp": time.time()
            }
            
            self.logger.info(f"ğŸ§¹ ë©”ëª¨ë¦¬ ìµœì í™” ì™„ë£Œ: {collected}ê°œ ê°ì²´ ì •ë¦¬ ({elapsed_time:.2f}ì´ˆ)")
            return result
            
        except Exception as e:
            self.stats["errors"] += 1
            self.logger.error(f"âŒ ë©”ëª¨ë¦¬ ìµœì í™” ì‹¤íŒ¨: {e}")
            return {"success": False, "error": str(e)}
    
    def get_status(self) -> Dict[str, Any]:
        """ìƒíƒœ ì¡°íšŒ"""
        return {
            "system_config": self.system_config.__dict__,
            "is_initialized": self.is_initialized,
            "components_count": len(self._components),
            "model_interfaces_count": len(self._model_interfaces),
            "step_instances_count": len(self._step_instances),
            "stats": self.stats.copy(),
            "memory_info": {
                "total_gb": SYSTEM_INFO["memory_gb"],
                "is_m3_max": SYSTEM_INFO["is_m3_max"],
                "device": SYSTEM_INFO["device"]
            }
        }
    
    async def cleanup(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        try:
            # ëª¨ë“  ì¸í„°í˜ì´ìŠ¤ ì •ë¦¬
            for interface in self._model_interfaces.values():
                if hasattr(interface, 'cleanup'):
                    try:
                        interface.cleanup()
                    except Exception as e:
                        self.logger.warning(f"ì¸í„°í˜ì´ìŠ¤ ì •ë¦¬ ì‹¤íŒ¨: {e}")
            
            # ìºì‹œ ì •ë¦¬
            self._model_interfaces.clear()
            self._step_instances.clear()
            self._components.clear()
            
            # ë©”ëª¨ë¦¬ ì •ë¦¬
            await self.optimize_memory()
            
            self.logger.info("ğŸ§¹ UnifiedUtilsManager ì •ë¦¬ ì™„ë£Œ")
            
        except Exception as e:
            self.logger.error(f"âŒ UnifiedUtilsManager ì •ë¦¬ ì‹¤íŒ¨: {e}")

# =============================================================================
# ğŸ”¥ ì „ì—­ ê´€ë¦¬ì ë° í¸ì˜ í•¨ìˆ˜ë“¤
# =============================================================================

_global_manager = None
_manager_lock = threading.Lock()

def get_utils_manager() -> UnifiedUtilsManager:
    """ì „ì—­ ìœ í‹¸ë¦¬í‹° ê´€ë¦¬ì ë°˜í™˜"""
    global _global_manager
    
    with _manager_lock:
        if _global_manager is None:
            _global_manager = UnifiedUtilsManager()
        return _global_manager

async def initialize_global_utils(**kwargs) -> Dict[str, Any]:
    """ì „ì—­ ìœ í‹¸ë¦¬í‹° ì´ˆê¸°í™” - ë¹„ë™ê¸°"""
    try:
        manager = get_utils_manager()
        
        # ì„¤ì • ì—…ë°ì´íŠ¸
        if kwargs:
            for key, value in kwargs.items():
                if hasattr(manager.system_config, key):
                    setattr(manager.system_config, key, value)
        
        manager.is_initialized = True
        manager.initialization_time = time.time()
        
        # ë©”ëª¨ë¦¬ ìµœì í™” ì‹¤í–‰
        await manager.optimize_memory()
        
        logger.info("âœ… ì „ì—­ ìœ í‹¸ë¦¬í‹° ì´ˆê¸°í™” ì™„ë£Œ")
        return {"success": True, "manager": manager}
        
    except Exception as e:
        logger.error(f"âŒ ì „ì—­ ìœ í‹¸ë¦¬í‹° ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return {"success": False, "error": str(e)}

def get_system_status() -> Dict[str, Any]:
    """ì‹œìŠ¤í…œ ìƒíƒœ ì¡°íšŒ"""
    try:
        manager = get_utils_manager()
        return manager.get_status()
    except Exception as e:
        return {"error": str(e), "system_info": SYSTEM_INFO}

async def reset_global_utils():
    """ì „ì—­ ìœ í‹¸ë¦¬í‹° ë¦¬ì…‹ - ë¹„ë™ê¸° ê°œì„ """
    global _global_manager
    
    try:
        with _manager_lock:
            if _global_manager:
                await _global_manager.cleanup()
                _global_manager = None
        logger.info("âœ… ì „ì—­ ìœ í‹¸ë¦¬í‹° ë¦¬ì…‹ ì™„ë£Œ")
    except Exception as e:
        logger.warning(f"âš ï¸ ì „ì—­ ìœ í‹¸ë¦¬í‹° ë¦¬ì…‹ ì‹¤íŒ¨: {e}")

# =============================================================================
# ğŸ”¥ í¸ì˜ í•¨ìˆ˜ë“¤
# =============================================================================

def create_unified_interface(step_name: str, **options):
    """ìƒˆë¡œìš´ í†µí•© ì¸í„°í˜ì´ìŠ¤ ìƒì„± (ê¶Œì¥)"""
    manager = get_utils_manager()
    return manager.create_step_model_interface(step_name)

async def optimize_system_memory() -> Dict[str, Any]:
    """ì‹œìŠ¤í…œ ë©”ëª¨ë¦¬ ìµœì í™” - ë¹„ë™ê¸°"""
    manager = get_utils_manager()
    return await manager.optimize_memory()

# ê¸°ì¡´ í˜¸í™˜ì„± í•¨ìˆ˜ë“¤
def create_step_interface(step_name: str, **options) -> StepModelInterface:
    """Step ì¸í„°í˜ì´ìŠ¤ ìƒì„± (ë ˆê±°ì‹œ í˜¸í™˜)"""
    return get_step_model_interface(step_name)

# =============================================================================
# ğŸ”¥ __all__ ì •ì˜ (í•µì‹¬ ìˆ˜ì •ì‚¬í•­)
# =============================================================================

__all__ = [
    # ğŸ¯ í•µì‹¬ í´ë˜ìŠ¤ë“¤
    'UnifiedUtilsManager',
    'StepModelInterface',  # ì¶”ê°€ë¨
    'SystemConfig',
    'StepConfig',
    'ModelInfo',
    
    # ğŸ”§ ì „ì—­ í•¨ìˆ˜ë“¤
    'get_utils_manager',
    'initialize_global_utils',
    'get_system_status',
    'reset_global_utils',
    
    # ğŸ”„ ì¸í„°í˜ì´ìŠ¤ ìƒì„± (main.py í˜¸í™˜)
    'get_step_model_interface',       # âœ… main.py í˜¸í™˜ (í•µì‹¬!)
    'create_step_interface',          # ë ˆê±°ì‹œ í˜¸í™˜
    'create_unified_interface',       # ìƒˆë¡œìš´ ë°©ì‹
    
    # ğŸ“Š ì‹œìŠ¤í…œ ì •ë³´
    'SYSTEM_INFO',
    'optimize_system_memory',
    
    # ğŸ”§ ìœ í‹¸ë¦¬í‹°
    'UtilsMode',
    'STEP_INTERFACE_AVAILABLE'  # ì¶”ê°€ë¨
]

# =============================================================================
# ğŸ”¥ ëª¨ë“ˆ ì´ˆê¸°í™” ì™„ë£Œ
# =============================================================================

logger.info("=" * 70)
logger.info("ğŸ MyCloset AI í†µí•© ìœ í‹¸ë¦¬í‹° ì‹œìŠ¤í…œ v6.1 ë¡œë“œ ì™„ë£Œ")
logger.info("âœ… StepModelInterface import ê²½ë¡œ ìˆ˜ì •")
logger.info("âœ… register_model_requirement ë©”ì„œë“œ ì§€ì›")
logger.info("âœ… get_step_model_interface í•¨ìˆ˜ ì™„ì „ êµ¬í˜„")
logger.info("âœ… ë¹„ë™ê¸° ì²˜ë¦¬ ì™„ì „ ê°œì„ ")
logger.info("âœ… ìˆœí™˜ì°¸ì¡° ì™„ì „ í•´ê²°")
logger.info("âœ… ê¸°ì¡´ ì½”ë“œ í•˜ìœ„ í˜¸í™˜ì„± ë³´ì¥")
logger.info(f"ğŸ”§ ì‹œìŠ¤í…œ: {SYSTEM_INFO['platform']} / {SYSTEM_INFO['device']}")
logger.info(f"ğŸ M3 Max: {'âœ…' if SYSTEM_INFO['is_m3_max'] else 'âŒ'}")
logger.info(f"ğŸ’¾ ë©”ëª¨ë¦¬: {SYSTEM_INFO['memory_gb']}GB")
logger.info(f"ğŸ”Œ StepInterface: {'âœ…' if STEP_INTERFACE_AVAILABLE else 'âš ï¸ í´ë°±'}")
logger.info("=" * 70)

# ì¢…ë£Œ ì‹œ ì •ë¦¬ í•¨ìˆ˜ ë“±ë¡
import atexit

def cleanup_on_exit():
    """ì¢…ë£Œ ì‹œ ì •ë¦¬"""
    try:
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        loop.run_until_complete(reset_global_utils())
        loop.close()
    except Exception as e:
        logger.warning(f"âš ï¸ ì¢…ë£Œ ì‹œ ì •ë¦¬ ì‹¤íŒ¨: {e}")

atexit.register(cleanup_on_exit)