# backend/app/api/system_routes.py
"""
ğŸ”¥ ì‹œìŠ¤í…œ ì •ë³´ API ë¼ìš°í„° - í”„ë¡ íŠ¸ì—”ë“œ í˜¸í™˜ì„± í™•ë³´
Central Hub DI Container v7.0 ê¸°ë°˜
"""

import platform
import time
import psutil
from datetime import datetime
from typing import Dict, Any, Optional

from fastapi import APIRouter, HTTPException, Query
from fastapi.responses import JSONResponse

from ..core.logging_config import get_logger

# ğŸ”¥ í†µí•©ëœ ì—ëŸ¬ ì²˜ë¦¬ ì‹œìŠ¤í…œ import
try:
    from ..core.exceptions import (
        get_error_summary,
        error_tracker
    )
    from ..core.mock_data_diagnostic import (
        get_diagnostic_summary
    )
    EXCEPTIONS_AVAILABLE = True
except ImportError:
    EXCEPTIONS_AVAILABLE = False

logger = get_logger(__name__)

# ë¼ìš°í„° ìƒì„±
router = APIRouter(prefix="/api/system", tags=["system"])

# ë£¨íŠ¸ health ì—”ë“œí¬ì¸íŠ¸ (í”„ë¡ íŠ¸ì—”ë“œ í˜¸í™˜ì„±)
@router.get("/health", include_in_schema=False)
async def root_health():
    """ë£¨íŠ¸ í—¬ìŠ¤ ì²´í¬ (í”„ë¡ íŠ¸ì—”ë“œ í˜¸í™˜ì„±)"""
    return {
        "status": "healthy",
        "timestamp": datetime.now().isoformat(),
        "version": "29.0.0",
        "service": "MyCloset AI Backend"
    }

# ì‹œìŠ¤í…œ ì •ë³´ ìºì‹œ (ì„±ëŠ¥ ìµœì í™”)
_system_info_cache: Optional[Dict[str, Any]] = None
_cache_timestamp: float = 0
CACHE_DURATION = 30  # 30ì´ˆ ìºì‹œ

def _detect_conda_env() -> Dict[str, Any]:
    """conda í™˜ê²½ ì •ë³´ ê°ì§€"""
    import os
    conda_env = os.environ.get('CONDA_DEFAULT_ENV', 'none')
    return {
        'conda_env': conda_env,
        'is_conda': conda_env != 'none',
        'is_mycloset_env': 'mycloset' in conda_env.lower()
    }

def _detect_hardware() -> Dict[str, Any]:
    """í•˜ë“œì›¨ì–´ ì •ë³´ ê°ì§€"""
    is_m3_max = False
    memory_gb = 16.0
    device = 'cpu'
    
    if platform.system() == 'Darwin':
        try:
            import subprocess
            result = subprocess.run(
                ['sysctl', '-n', 'machdep.cpu.brand_string'], 
                capture_output=True, text=True, timeout=5
            )
            chip_info = result.stdout.strip()
            is_m3_max = 'M3' in chip_info and 'Max' in chip_info
            
            if is_m3_max:
                memory_gb = 128.0
                # MPS ë””ë°”ì´ìŠ¤ ì²´í¬
                try:
                    import torch
                    if hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
                        device = 'mps'
                except ImportError:
                    pass
        except Exception:
            pass
    
    return {
        'is_m3_max': is_m3_max,
        'memory_gb': memory_gb,
        'device': device,
        'cpu_cores': psutil.cpu_count() if psutil else 4
    }

def _get_cached_system_info() -> Dict[str, Any]:
    """ìºì‹œëœ ì‹œìŠ¤í…œ ì •ë³´ ë°˜í™˜"""
    global _system_info_cache, _cache_timestamp
    
    current_time = time.time()
    
    # ìºì‹œê°€ ìœ íš¨í•œì§€ í™•ì¸
    if _system_info_cache and (current_time - _cache_timestamp) < CACHE_DURATION:
        return _system_info_cache
    
    # ìƒˆë¡œìš´ ì‹œìŠ¤í…œ ì •ë³´ ìˆ˜ì§‘
    conda_info = _detect_conda_env()
    hardware_info = _detect_hardware()
    
    # ë©”ëª¨ë¦¬ ì •ë³´
    memory_info = {}
    try:
        memory = psutil.virtual_memory()
        memory_info = {
            'total_gb': round(memory.total / (1024**3), 2),
            'available_gb': round(memory.available / (1024**3), 2),
            'used_percent': round(memory.percent, 1)
        }
    except Exception:
        memory_info = {
            'total_gb': hardware_info['memory_gb'],
            'available_gb': hardware_info['memory_gb'] * 0.7,
            'used_percent': 30.0
        }
    
    # CPU ì •ë³´
    cpu_info = {}
    try:
        cpu_info = {
            'usage_percent': psutil.cpu_percent(interval=0.1),
            'cores': psutil.cpu_count()
        }
    except Exception:
        cpu_info = {
            'usage_percent': 25.0,
            'cores': hardware_info['cpu_cores']
        }
    
    # PyTorch ì •ë³´
    pytorch_info = {'available': False}
    try:
        import torch
        pytorch_info = {
            'available': True,
            'version': torch.__version__,
            'mps_available': hasattr(torch.backends, 'mps') and torch.backends.mps.is_available(),
            'cuda_available': torch.cuda.is_available()
        }
    except ImportError:
        pass
    
    # í†µí•© ì‹œìŠ¤í…œ ì •ë³´
    _system_info_cache = {
        # ê¸°ë³¸ ì‹œìŠ¤í…œ ì •ë³´
        'platform': platform.system(),
        'machine': platform.machine(),
        'python_version': platform.python_version(),
        'timestamp': datetime.now().isoformat(),
        
        # conda í™˜ê²½
        **conda_info,
        
        # í•˜ë“œì›¨ì–´
        **hardware_info,
        
        # ë©”ëª¨ë¦¬
        'memory': memory_info,
        
        # CPU
        'cpu': cpu_info,
        
        # PyTorch
        'pytorch': pytorch_info,
        
        # AI íŒŒì´í”„ë¼ì¸ ìƒíƒœ
        'ai_pipeline_ready': True,
        'virtual_fitting_available': True,
        'models_loaded': True,
        
        # Central Hub ì •ë³´
        'central_hub_enabled': True,
        'central_hub_version': 'v7.0',
        'circular_reference_free': True
    }
    
    _cache_timestamp = current_time
    return _system_info_cache

@router.get("/info")
async def get_system_info():
    """
    ì‹œìŠ¤í…œ ì •ë³´ ì¡°íšŒ API
    í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ê²°ê³¼ í™”ë©´ í‘œì‹œë¥¼ ìœ„í•´ í˜¸ì¶œ
    """
    try:
        system_info = _get_cached_system_info()
        
        logger.info("âœ… ì‹œìŠ¤í…œ ì •ë³´ ì¡°íšŒ ì„±ê³µ")
        
        return JSONResponse(content={
            "success": True,
            "data": system_info,
            "message": "ì‹œìŠ¤í…œ ì •ë³´ ì¡°íšŒ ì™„ë£Œ",
            "timestamp": datetime.now().isoformat()
        })
        
    except Exception as e:
        error_msg = f"ì‹œìŠ¤í…œ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}"
        logger.error(error_msg)
        
        raise HTTPException(
            status_code=500,
            detail=error_msg
        )

@router.get("/health")
async def system_health():
    """ì‹œìŠ¤í…œ í—¬ìŠ¤ ì²´í¬"""
    try:
        # ê¸°ë³¸ í—¬ìŠ¤ ì²´í¬ (ì‹œìŠ¤í…œ ì •ë³´ ìˆ˜ì§‘ ì—†ì´)
        basic_health = {
            "success": True,
            "status": "healthy",
            "health_score": 100,
            "issues": [],
            "system_info": {
                "device": "mps",  # ê¸°ë³¸ê°’
                "is_m3_max": True,  # ê¸°ë³¸ê°’
                "memory_gb": 128.0,  # ê¸°ë³¸ê°’
                "conda_env": "myclosetlast"  # ê¸°ë³¸ê°’
            },
            "timestamp": datetime.now().isoformat()
        }
        
        # ì‹œìŠ¤í…œ ì •ë³´ ìˆ˜ì§‘ ì‹œë„ (ì˜¤ë¥˜ ë°œìƒ ì‹œ ê¸°ë³¸ê°’ ì‚¬ìš©)
        try:
            system_info = _get_cached_system_info()
            
            # í—¬ìŠ¤ ì ìˆ˜ ê³„ì‚°
            health_score = 100
            issues = []
            
            # ë©”ëª¨ë¦¬ ì²´í¬
            if 'memory' in system_info and 'used_percent' in system_info['memory']:
                memory_usage = system_info['memory']['used_percent']
                if memory_usage > 90:
                    health_score -= 30
                    issues.append("ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  ë†’ìŒ")
                elif memory_usage > 80:
                    health_score -= 15
                    issues.append("ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  ì£¼ì˜")
            
            # CPU ì²´í¬
            if 'cpu' in system_info and 'usage_percent' in system_info['cpu']:
                cpu_usage = system_info['cpu']['usage_percent']
                if cpu_usage > 90:
                    health_score -= 20
                    issues.append("CPU ì‚¬ìš©ë¥  ë†’ìŒ")
                elif cpu_usage > 80:
                    health_score -= 10
                    issues.append("CPU ì‚¬ìš©ë¥  ì£¼ì˜")
            
            # conda í™˜ê²½ ì²´í¬
            if not system_info.get('is_conda', False):
                health_score -= 10
                issues.append("conda í™˜ê²½ ë¯¸ì‚¬ìš©")
            
            status = "healthy"
            if health_score < 60:
                status = "critical"
            elif health_score < 80:
                status = "warning"
            
            basic_health.update({
                "status": status,
                "health_score": max(0, health_score),
                "issues": issues,
                "system_info": {
                    "device": system_info.get('device', 'mps'),
                    "is_m3_max": system_info.get('is_m3_max', True),
                    "memory_gb": system_info.get('memory_gb', 128.0),
                    "conda_env": system_info.get('conda_env', 'myclosetlast')
                }
            })
            
        except Exception as sys_error:
            logger.warning(f"ì‹œìŠ¤í…œ ì •ë³´ ìˆ˜ì§‘ ì‹¤íŒ¨, ê¸°ë³¸ê°’ ì‚¬ìš©: {str(sys_error)}")
            basic_health["issues"].append("ì‹œìŠ¤í…œ ì •ë³´ ìˆ˜ì§‘ ì‹¤íŒ¨")
        
        return JSONResponse(content=basic_health)
        
    except Exception as e:
        logger.error(f"ì‹œìŠ¤í…œ í—¬ìŠ¤ ì²´í¬ ì‹¤íŒ¨: {str(e)}")
        return JSONResponse(
            content={
                "success": False,
                "status": "error",
                "health_score": 0,
                "error": str(e),
                "timestamp": datetime.now().isoformat()
            },
            status_code=500
        )

@router.get("/status")
async def system_status():
    """ê°„ë‹¨í•œ ì‹œìŠ¤í…œ ìƒíƒœ ì¡°íšŒ"""
    try:
        system_info = _get_cached_system_info()
        
        return JSONResponse(content={
            "success": True,
            "online": True,
            "device": system_info['device'],
            "conda_env": system_info['conda_env'],
            "memory_available_gb": system_info['memory']['available_gb'],
            "ai_pipeline_ready": system_info['ai_pipeline_ready'],
            "timestamp": datetime.now().isoformat()
        })
        
    except Exception as e:
        logger.error(f"ì‹œìŠ¤í…œ ìƒíƒœ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
        return JSONResponse(
            content={
                "success": False,
                "online": False,
                "error": str(e),
                "timestamp": datetime.now().isoformat()
            },
            status_code=500
        )


@router.get("/diagnostic")
async def get_diagnostic_info():
    """ëª©ì—… ë°ì´í„° ì§„ë‹¨ ì •ë³´ ì¡°íšŒ"""
    try:
        diagnostic_info = {}
        
        if EXCEPTIONS_AVAILABLE:
            # ì—ëŸ¬ ìš”ì•½ ì •ë³´
            error_summary = get_error_summary()
            diagnostic_info['error_summary'] = error_summary
            
            # ëª©ì—… ë°ì´í„° ì§„ë‹¨ ìš”ì•½
            try:
                mock_diagnostic_summary = get_diagnostic_summary()
                diagnostic_info['mock_diagnostic_summary'] = mock_diagnostic_summary
            except Exception as e:
                diagnostic_info['mock_diagnostic_summary'] = {'error': str(e)}
            
            # ì—ëŸ¬ íŠ¸ë˜ì»¤ ìƒíƒœ
            if hasattr(error_tracker, 'get_mock_data_analysis'):
                try:
                    mock_analysis = error_tracker.get_mock_data_analysis()
                    diagnostic_info['mock_data_analysis'] = mock_analysis
                except Exception as e:
                    diagnostic_info['mock_data_analysis'] = {'error': str(e)}
        else:
            diagnostic_info['error'] = 'í†µí•© ì—ëŸ¬ ì²˜ë¦¬ ì‹œìŠ¤í…œì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤'
        
        return JSONResponse(content={
            'success': True,
            'timestamp': datetime.now().isoformat(),
            'diagnostic_info': diagnostic_info
        })
        
    except Exception as e:
        logger.error(f"ì§„ë‹¨ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return JSONResponse(
            content={
                "success": False,
                "error": f"ì§„ë‹¨ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}",
                "timestamp": datetime.now().isoformat()
            },
            status_code=500
        )


@router.get("/diagnostic/errors")
async def get_error_details():
    """ìƒì„¸ ì—ëŸ¬ ì •ë³´ ì¡°íšŒ"""
    try:
        if not EXCEPTIONS_AVAILABLE:
            return JSONResponse(
                content={
                    "success": False,
                    "error": "í†µí•© ì—ëŸ¬ ì²˜ë¦¬ ì‹œìŠ¤í…œì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤",
                    "timestamp": datetime.now().isoformat()
                },
                status_code=503
            )
        
        error_summary = get_error_summary()
        
        return JSONResponse(content={
            'success': True,
            'timestamp': datetime.now().isoformat(),
            'error_details': error_summary
        })
        
    except Exception as e:
        logger.error(f"ì—ëŸ¬ ìƒì„¸ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return JSONResponse(
            content={
                "success": False,
                "error": f"ì—ëŸ¬ ìƒì„¸ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}",
                "timestamp": datetime.now().isoformat()
            },
            status_code=500
        )


@router.get("/diagnostic/mock-data")
async def get_mock_data_analysis():
    """ëª©ì—… ë°ì´í„° ë¶„ì„ ì •ë³´ ì¡°íšŒ"""
    try:
        if not EXCEPTIONS_AVAILABLE:
            return JSONResponse(
                content={
                    "success": False,
                    "error": "í†µí•© ì—ëŸ¬ ì²˜ë¦¬ ì‹œìŠ¤í…œì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤",
                    "timestamp": datetime.now().isoformat()
                },
                status_code=503
            )
        
        # ëª©ì—… ë°ì´í„° ì§„ë‹¨ ìš”ì•½
        mock_diagnostic_summary = get_diagnostic_summary()
        
        # ì—ëŸ¬ íŠ¸ë˜ì»¤ì—ì„œ ëª©ì—… ë°ì´í„° ë¶„ì„
        mock_analysis = error_tracker.get_mock_data_analysis()
        
        return JSONResponse(content={
            'success': True,
            'timestamp': datetime.now().isoformat(),
            'mock_data_analysis': {
                'diagnostic_summary': mock_diagnostic_summary,
                'error_analysis': mock_analysis
            }
        })
        
    except Exception as e:
        logger.error(f"ëª©ì—… ë°ì´í„° ë¶„ì„ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return JSONResponse(
            content={
                "success": False,
                "error": f"ëª©ì—… ë°ì´í„° ë¶„ì„ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}",
                "timestamp": datetime.now().isoformat()
            },
            status_code=500
        ) 

@router.get("/cleanup-sessions")
async def cleanup_sessions(
    max_age_hours: int = Query(24, description="ìµœëŒ€ ë³´ê´€ ì‹œê°„ (ì‹œê°„)"),
    keep_count: int = Query(50, description="ë³´ê´€í•  ì„¸ì…˜ ìˆ˜"),
    mode: str = Query("stats", description="ì •ë¦¬ ëª¨ë“œ: stats, age, count"),
    dry_run: bool = Query(True, description="ì‹¤ì œ ì‚­ì œí•˜ì§€ ì•Šê³  ë¯¸ë¦¬ë³´ê¸°ë§Œ"),
    sessions_dir: str = Query("backend/sessions/data", description="ì„¸ì…˜ ë””ë ‰í† ë¦¬ ê²½ë¡œ")
):
    """ì„¸ì…˜ ì •ë¦¬ API"""
    try:
        from pathlib import Path
        import shutil
        import time
        import re
        from typing import List, Dict, Any
        
        class SessionCleaner:
            def __init__(self, sessions_dir: str, max_age_hours: int = 24):
                self.sessions_dir = Path(sessions_dir)
                self.max_age_hours = max_age_hours
                self.current_time = time.time()
            
            def get_file_session_info(self, file_path: Path) -> Dict[str, Any]:
                try:
                    filename = file_path.name
                    match = re.match(r'session_(\d+)_([a-f0-9]+)_', filename)
                    
                    if match:
                        timestamp = int(match.group(1))
                        session_id = match.group(2)
                        created_time = timestamp
                        
                        return {
                            'session_id': session_id,
                            'created_time': created_time,
                            'age_hours': (self.current_time - created_time) / 3600,
                            'size_mb': file_path.stat().st_size / (1024 * 1024),
                            'files_count': 1,
                            'file_path': file_path
                        }
                    else:
                        created_time = file_path.stat().st_ctime
                        return {
                            'session_id': file_path.stem,
                            'created_time': created_time,
                            'age_hours': (self.current_time - created_time) / 3600,
                            'size_mb': file_path.stat().st_size / (1024 * 1024),
                            'files_count': 1,
                            'file_path': file_path
                        }
                except Exception as e:
                    return None
            
            def get_all_sessions(self) -> List[Dict[str, Any]]:
                sessions = []
                
                if not self.sessions_dir.exists():
                    return sessions
                
                for file_path in self.sessions_dir.iterdir():
                    if file_path.is_file() and file_path.name.startswith('session_'):
                        session_info = self.get_file_session_info(file_path)
                        if session_info:
                            sessions.append(session_info)
                
                # ì„¸ì…˜ IDë³„ë¡œ ê·¸ë£¹í™”í•˜ì—¬ ì¤‘ë³µ ì œê±°
                session_groups = {}
                for session in sessions:
                    session_id = session['session_id']
                    if session_id not in session_groups:
                        session_groups[session_id] = session
                    else:
                        existing = session_groups[session_id]
                        existing['size_mb'] += session['size_mb']
                        existing['files_count'] += session['files_count']
                        if session['created_time'] < existing['created_time']:
                            existing['created_time'] = session['created_time']
                            existing['age_hours'] = session['age_hours']
                
                sessions = list(session_groups.values())
                sessions.sort(key=lambda x: x['age_hours'], reverse=True)
                return sessions
            
            def cleanup_old_sessions(self, dry_run: bool = True) -> Dict[str, Any]:
                sessions = self.get_all_sessions()
                
                if not sessions:
                    return {'cleaned': 0, 'total_size_mb': 0, 'sessions': []}
                
                sessions_to_clean = []
                total_size_to_clean = 0
                
                for session in sessions:
                    if session['age_hours'] > self.max_age_hours:
                        sessions_to_clean.append(session)
                        total_size_to_clean += session['size_mb']
                
                if not dry_run:
                    cleaned_count = 0
                    for session in sessions_to_clean:
                        try:
                            if 'file_path' in session:
                                file_path = session['file_path']
                                if file_path.exists():
                                    file_path.unlink()
                                    cleaned_count += 1
                        except Exception as e:
                            pass
                    
                    return {
                        'cleaned': cleaned_count,
                        'total_size_mb': total_size_to_clean,
                        'sessions': sessions_to_clean
                    }
                else:
                    return {
                        'cleaned': 0,
                        'total_size_mb': total_size_to_clean,
                        'sessions': sessions_to_clean
                    }
            
            def cleanup_by_count(self, keep_count: int = 50, dry_run: bool = True) -> Dict[str, Any]:
                sessions = self.get_all_sessions()
                
                if len(sessions) <= keep_count:
                    return {'cleaned': 0, 'total_size_mb': 0, 'sessions': []}
                
                sessions_to_clean = sessions[keep_count:]
                total_size_to_clean = sum(s['size_mb'] for s in sessions_to_clean)
                
                if not dry_run:
                    cleaned_count = 0
                    for session in sessions_to_clean:
                        try:
                            if 'file_path' in session:
                                file_path = session['file_path']
                                if file_path.exists():
                                    file_path.unlink()
                                    cleaned_count += 1
                        except Exception as e:
                            pass
                    
                    return {
                        'cleaned': cleaned_count,
                        'total_size_mb': total_size_to_clean,
                        'sessions': sessions_to_clean
                    }
                else:
                    return {
                        'cleaned': 0,
                        'total_size_mb': total_size_to_clean,
                        'sessions': sessions_to_clean
                    }
            
            def show_session_stats(self):
                sessions = self.get_all_sessions()
                
                if not sessions:
                    return {
                        'total_sessions': 0,
                        'total_size_mb': 0,
                        'avg_age_hours': 0,
                        'oldest_session_hours': 0,
                        'newest_session_hours': 0,
                        'age_distribution': {}
                    }
                
                total_size = sum(s['size_mb'] for s in sessions)
                avg_age = sum(s['age_hours'] for s in sessions) / len(sessions)
                
                age_groups = {
                    '1ì‹œê°„ ì´ë‚´': 0,
                    '1-6ì‹œê°„': 0,
                    '6-24ì‹œê°„': 0,
                    '24ì‹œê°„ ì´ìƒ': 0
                }
                
                for session in sessions:
                    age = session['age_hours']
                    if age <= 1:
                        age_groups['1ì‹œê°„ ì´ë‚´'] += 1
                    elif age <= 6:
                        age_groups['1-6ì‹œê°„'] += 1
                    elif age <= 24:
                        age_groups['6-24ì‹œê°„'] += 1
                    else:
                        age_groups['24ì‹œê°„ ì´ìƒ'] += 1
                
                return {
                    'total_sessions': len(sessions),
                    'total_size_mb': total_size,
                    'avg_age_hours': avg_age,
                    'oldest_session_hours': sessions[0]['age_hours'],
                    'newest_session_hours': sessions[-1]['age_hours'],
                    'age_distribution': age_groups
                }
        
        cleaner = SessionCleaner(sessions_dir, max_age_hours)
        
        if mode == "stats":
            stats = cleaner.show_session_stats()
            return {
                "status": "success",
                "message": "ì„¸ì…˜ í†µê³„ ì¡°íšŒ ì™„ë£Œ",
                "data": stats
            }
        elif mode == "age":
            result = cleaner.cleanup_old_sessions(dry_run=dry_run)
            return {
                "status": "success",
                "message": f"ë‚˜ì´ ê¸°ì¤€ ì„¸ì…˜ ì •ë¦¬ ì™„ë£Œ (dry_run={dry_run})",
                "data": result
            }
        elif mode == "count":
            result = cleaner.cleanup_by_count(keep_count, dry_run=dry_run)
            return {
                "status": "success",
                "message": f"ê°œìˆ˜ ê¸°ì¤€ ì„¸ì…˜ ì •ë¦¬ ì™„ë£Œ (dry_run={dry_run})",
                "data": result
            }
        else:
            return {
                "status": "error",
                "message": "ì˜ëª»ëœ ëª¨ë“œì…ë‹ˆë‹¤. stats, age, count ì¤‘ í•˜ë‚˜ë¥¼ ì„ íƒí•˜ì„¸ìš”."
            }
            
    except Exception as e:
        return {
            "status": "error",
            "message": f"ì„¸ì…˜ ì •ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
        } 