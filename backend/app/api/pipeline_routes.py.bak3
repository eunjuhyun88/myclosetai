"""
MyCloset AI 백엔드 API 라우트
프론트엔드와 8단계 파이프라인을 연결하는 FastAPI 엔드포인트
"""

from fastapi import APIRouter, File, UploadFile, Form, HTTPException, WebSocket, WebSocketDisconnect
from fastapi.responses import JSONResponse
from typing import Optional, Dict, Any, List  # ✅ List import 추가
import asyncio
import json
import logging
import time
from PIL import Image
import io
import base64
import numpy as np
import torch

# 조건부 import - 모델이 없어도 서버가 시작되도록
try:
    try:
    from ..ai_pipeline.pipeline_manager import VirtualTryOnPipeline, PipelineFactory
except ImportError:
    VirtualTryOnPipeline = None
    from ..core.pipeline_config import PipelineConfig
    PIPELINE_AVAILABLE = True
except ImportError:
    logging.warning("AI 파이프라인 모듈을 찾을 수 없습니다. 더미 모드로 실행됩니다.")
    PIPELINE_AVAILABLE = False

from ..models.schemas import (
    VirtualTryOnRequest, 
    VirtualTryOnResponse, 
    PipelineProgress, 
    QualityMetrics
)

router = APIRouter(prefix="/api", tags=["Virtual Try-On Pipeline"])

# 전역 파이프라인 인스턴스 (메모리 효율성을 위해)
pipeline_instance = None
active_connections: Dict[str, WebSocket] = {}

def get_pipeline_instance(quality_mode: str = "balanced") :
    """파이프라인 인스턴스 관리"""
    global pipeline_instance
    
    if not PIPELINE_AVAILABLE:
        raise HTTPException(status_code=503, detail="AI 파이프라인이 초기화되지 않았습니다.")
    
    if pipeline_instance is None:
        pipeline_instance = PipelineFactory.create_optimized_pipeline(
            memory_gb=16.0,
            quality_mode=quality_mode
        )
    
    return pipeline_instance

def image_to_base64(image_array: np.ndarray) -> str:
    """numpy 배열을 base64 문자열로 변환"""
    if image_array.max() <= 1.0:
        image_array = (image_array * 255).astype(np.uint8)
    
    image = Image.fromarray(image_array)
    buffer = io.BytesIO()
    image.save(buffer, format='PNG')
    buffer.seek(0)
    
    return base64.b64encode(buffer.getvalue()).decode()

async def send_progress_update(connection_id: str, step: int, progress: float, message: str):
    """WebSocket으로 진행 상황 전송"""
    if connection_id in active_connections:
        try:
            progress_data = {
                "step_id": step,
                "progress": progress,
                "message": message,
                "timestamp": time.time()
            }
            await active_connections[connection_id].send_text(json.dumps(progress_data))
        except Exception as e:
            logging.warning(f"WebSocket 전송 실패: {e}")

@router.websocket("/ws/pipeline-progress")
async def websocket_endpoint(websocket: WebSocket):
    """파이프라인 진행 상황을 위한 WebSocket 연결"""
    await websocket.accept()
    connection_id = str(id(websocket))
    active_connections[connection_id] = websocket
    
    try:
        while True:
            # 연결 유지를 위한 ping
            await websocket.receive_text()
    except WebSocketDisconnect:
        if connection_id in active_connections:
            del active_connections[connection_id]

@router.post("/virtual-tryon-pipeline", response_model=VirtualTryOnResponse)
async def process_virtual_tryon_pipeline(
    person_image: UploadFile = File(...),
    clothing_image: UploadFile = File(...),
    height: float = Form(170),
    weight: float = Form(65),
    quality_mode: str = Form("balanced"),
    connection_id: Optional[str] = Form(None)
):
    """
    8단계 가상 피팅 파이프라인 실행
    
    Args:
        person_image: 사용자 이미지 파일
        clothing_image: 의류 이미지 파일  
        height: 키 (cm)
        weight: 몸무게 (kg)
        quality_mode: 품질 모드 (fast/balanced/quality)
        connection_id: WebSocket 연결 ID (진행률 업데이트용)
    
    Returns:
        VirtualTryOnResponse: 처리 결과
    """
    
    try:
        # 개발 단계에서는 더미 프로세싱 사용
        if not PIPELINE_AVAILABLE:
            logging.info("더미 파이프라인 실행 중...")
            return await test_dummy_process(connection_id)
        
        # 파이프라인 인스턴스 가져오기
        pipeline = get_pipeline_instance(quality_mode)
        
        # 이미지 로드 및 전처리
        person_pil = Image.open(io.BytesIO(await person_image.read())).convert('RGB')
        cloth_pil = Image.open(io.BytesIO(await clothing_image.read())).convert('RGB')
        
        # 진행 상황 업데이트
        if connection_id:
            await send_progress_update(connection_id, 0, 0.1, "이미지 전처리 중...")
        
        # 사용자 측정 정보
        user_measurements = {
            "height": height,
            "weight": weight
        }
        
        # 8단계 파이프라인 실행 (각 단계별 진행률 업데이트)
        result = await process_pipeline_with_progress(
            pipeline, person_pil, cloth_pil, user_measurements, connection_id
        )
        
        if result.success:
            # 성공 응답
            response = VirtualTryOnResponse(
                success=True,
                fitted_image=image_to_base64(result.fitted_image),
                processing_time=result.processing_time,
                confidence=result.quality_scores.get("overall_score", 0.85),
                measurements=extract_measurements(result),
                clothing_analysis=extract_clothing_analysis(result),
                fit_score=result.quality_scores.get("fit_overall", 0.85),
                recommendations=generate_user_recommendations(result),
                quality_metrics=result.quality_scores,
                memory_usage=result.memory_usage,
                step_times=result.step_times
            )
            
            # 최종 진행률 업데이트
            if connection_id:
                await send_progress_update(connection_id, 8, 1.0, "처리 완료!")
            
            return response
        else:
            raise HTTPException(status_code=500, detail=result.error_message)
    
    except Exception as e:
        logging.error(f"파이프라인 처리 오류: {str(e)}")
        if connection_id:
            await send_progress_update(connection_id, -1, 0, f"오류 발생: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

async def process_pipeline_with_progress(
    pipeline: VirtualTryOnPipeline,
    person_image: Image.Image,
    cloth_image: Image.Image,
    user_measurements: Dict[str, float],
    connection_id: Optional[str]
) -> Any:
    """진행률 업데이트와 함께 파이프라인 실행"""
    
    step_names = [
        "인체 파싱 (20개 부위 분할)",
        "포즈 추정 (18개 키포인트)", 
        "의류 세그멘테이션",
        "기하학적 매칭 (TPS 변환)",
        "옷 워핑",
        "가상 피팅 생성",
        "후처리 (품질 향상)",
        "품질 평가"
    ]
    
    # 각 단계별 예상 소요 시간 (비율)
    step_weights = [0.15, 0.1, 0.1, 0.15, 0.15, 0.25, 0.05, 0.05]
    
    class ProgressTracker:
        def __init__(self):
            self.current_step = 0
            self.total_progress = 0.1  # 초기 전처리 10%
    
    tracker = ProgressTracker()
    
    # 파이프라인의 각 단계에 진행률 콜백 추가
    async def step_callback(step_id: int, progress: float):
        if connection_id:
            # 현재 단계의 진행률 계산
            step_progress = sum(step_weights[:step_id]) + step_weights[step_id] * progress
            total_progress = 0.1 + step_progress * 0.9  # 전처리 10% + 파이프라인 90%
            
            message = f"{step_names[step_id]} ({int(progress * 100)}%)"
            await send_progress_update(connection_id, step_id + 1, total_progress, message)
    
    # 파이프라인에 콜백 설정
    pipeline.progress_callback = step_callback
    
    # 실제 파이프라인 실행
    result = await pipeline.process(person_image, cloth_image, user_measurements)
    
    return result

def extract_measurements(result) -> Dict[str, float]:
    """결과에서 신체 측정 정보 추출"""
    measurements = {
        "chest": 88.0,
        "waist": 70.0,
        "hip": 92.0,
        "bmi": 22.5
    }
    
    # 실제 파이프라인 결과에서 측정값 추출
    if hasattr(result, 'intermediate_results'):
        human_parsing = result.intermediate_results.get('human_parsing', {})
        if 'body_measurements' in human_parsing:
            measurements.update(human_parsing['body_measurements'])
    
    return measurements

def extract_clothing_analysis(result) -> Dict[str, Any]:
    """의류 분석 정보 추출"""
    analysis = {
        "category": "상의",
        "style": "캐주얼",
        "dominant_color": [120, 150, 200],
        "material": "면"
    }
    
    # 실제 파이프라인 결과에서 의류 분석 추출
    if hasattr(result, 'intermediate_results'):
        cloth_seg = result.intermediate_results.get('cloth_segmentation', {})
        if 'cloth_type' in cloth_seg:
            analysis["category"] = cloth_seg['cloth_type']
            analysis["confidence"] = cloth_seg.get('cloth_confidence', 0.8)
    
    return analysis

def generate_user_recommendations(result) -> List[str]:  # ✅ List 타입 힌트 수정
    """사용자 친화적 추천사항 생성"""
    recommendations = []
    
    if hasattr(result, 'quality_scores'):
        overall_score = result.quality_scores.get('overall_score', 0.8)
        
        if overall_score >= 0.9:
            recommendations.append("🎉 완벽한 핏! 이 스타일이 매우 잘 어울립니다.")
        elif overall_score >= 0.8:
            recommendations.append("👍 좋은 핏입니다! 자신감 있게 착용하세요.")
        elif overall_score >= 0.6:
            recommendations.append("👌 괜찮은 핏이지만, 다른 사이즈도 고려해보세요.")
        else:
            recommendations.append("🤔 이 아이템은 맞지 않을 수 있습니다. 다른 스타일을 추천드립니다.")
        
        # 구체적인 피팅 조언
        fit_coverage = result.quality_scores.get('fit_coverage', 0.8)
        if fit_coverage < 0.7:
            recommendations.append("📏 사이즈를 한 치수 크게 고려해보세요.")
        
        color_preservation = result.quality_scores.get('color_preservation', 0.8)
        if color_preservation > 0.9:
            recommendations.append("🎨 색상이 피부톤과 잘 어울립니다!")
    
    if not recommendations:
        recommendations.append("✨ 멋진 선택입니다! 이 스타일을 추천드립니다.")
    
    return recommendations

@router.get("/pipeline/status")
async def get_pipeline_status():
    """파이프라인 상태 조회"""
    global pipeline_instance
    
    if not PIPELINE_AVAILABLE:
        return {
            "status": "development_mode",
            "message": "AI 모델들이 아직 설정되지 않았습니다.",
            "available_endpoints": ["test/dummy-process"]
        }
    
    if pipeline_instance is None:
        return {"status": "not_initialized"}
    
    status = pipeline_instance.get_pipeline_status()
    return {
        "status": "ready",
        "device": status["device"],
        "memory_usage": status["memory_usage"],
        "models_loaded": status["models_loaded"],
        "active_connections": len(active_connections)
    }

@router.post("/pipeline/warmup")
async def warmup_pipeline(quality_mode: str = "balanced"):
    """파이프라인 워밍업 (첫 실행 시 모델 로딩)"""
    try:
        if not PIPELINE_AVAILABLE:
            return {
                "success": False,
                "message": "개발 모드 - AI 모델 설정 필요"
            }
            
        pipeline = get_pipeline_instance(quality_mode)
        await pipeline.warmup()
        
        return {
            "success": True,
            "message": "파이프라인 워밍업 완료",
            "quality_mode": quality_mode
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"워밍업 실패: {str(e)}")

@router.delete("/pipeline/cleanup")
async def cleanup_pipeline():
    """파이프라인 리소스 정리"""
    global pipeline_instance
    
    try:
        if pipeline_instance:
            pipeline_instance.cleanup()
            pipeline_instance = None
        
        return {
            "success": True,
            "message": "파이프라인 리소스 정리 완료"
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"정리 실패: {str(e)}")

@router.get("/quality/metrics")
async def get_quality_metrics_info():
    """품질 메트릭 정보 조회"""
    return {
        "metrics": {
            "ssim": {
                "name": "구조적 유사성",
                "description": "원본과 결과 이미지의 구조적 유사도",
                "range": [0, 1],
                "higher_better": True
            },
            "lpips": {
                "name": "지각적 유사성", 
                "description": "인간의 시각 인지에 기반한 유사도",
                "range": [0, 1],
                "higher_better": True
            },
            "fit_overall": {
                "name": "전체 피팅 점수",
                "description": "의류 착용감의 종합 평가",
                "range": [0, 1],
                "higher_better": True
            }
        },
        "quality_grades": {
            "excellent": "90% 이상 - 완벽한 품질",
            "good": "80-89% - 우수한 품질", 
            "fair": "60-79% - 양호한 품질",
            "poor": "60% 미만 - 개선 필요"
        }
    }

@router.post("/test/dummy-process")
async def test_dummy_process(connection_id: Optional[str] = None):
    """테스트용 더미 처리 (개발용)"""
    step_names = [
        "인체 파싱", "포즈 추정", "의류 세그멘테이션", "기하학적 매칭",
        "옷 워핑", "가상 피팅", "후처리", "품질 평가"
    ]
    
    for i, step_name in enumerate(step_names):
        # 각 단계마다 0.5초 대기
        await asyncio.sleep(0.5)
        
        progress = (i + 1) / len(step_names)
        
        if connection_id:
            await send_progress_update(
                connection_id, i + 1, progress, f"{step_name} 완료"
            )
    
    # 더미 결과 생성 (512x512 랜덤 이미지)
    dummy_image = np.random.randint(0, 255, (512, 512, 3), dtype=np.uint8)
    
    return VirtualTryOnResponse(
        success=True,
        fitted_image=image_to_base64(dummy_image),
        processing_time=4.0,
        confidence=0.87,
        measurements={"chest": 88, "waist": 70, "hip": 92, "bmi": 22.5},
        clothing_analysis={
            "category": "상의",
            "style": "캐주얼", 
            "dominant_color": [120, 150, 200]
        },
        fit_score=0.85,
        recommendations=["완벽한 핏입니다!", "색상이 잘 어울립니다!"],
        quality_metrics={
            "ssim": 0.89,
            "lpips": 0.85,
            "fit_overall": 0.87
        }
    )