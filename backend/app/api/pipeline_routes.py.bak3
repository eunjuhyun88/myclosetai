"""
MyCloset AI ë°±ì—”ë“œ API ë¼ìš°íŠ¸
í”„ë¡ íŠ¸ì—”ë“œì™€ 8ë‹¨ê³„ íŒŒì´í”„ë¼ì¸ì„ ì—°ê²°í•˜ëŠ” FastAPI ì—”ë“œí¬ì¸íŠ¸
"""

from fastapi import APIRouter, File, UploadFile, Form, HTTPException, WebSocket, WebSocketDisconnect
from fastapi.responses import JSONResponse
from typing import Optional, Dict, Any, List  # âœ… List import ì¶”ê°€
import asyncio
import json
import logging
import time
from PIL import Image
import io
import base64
import numpy as np
import torch

# ì¡°ê±´ë¶€ import - ëª¨ë¸ì´ ì—†ì–´ë„ ì„œë²„ê°€ ì‹œì‘ë˜ë„ë¡
try:
    try:
    from ..ai_pipeline.pipeline_manager import VirtualTryOnPipeline, PipelineFactory
except ImportError:
    VirtualTryOnPipeline = None
    from ..core.pipeline_config import PipelineConfig
    PIPELINE_AVAILABLE = True
except ImportError:
    logging.warning("AI íŒŒì´í”„ë¼ì¸ ëª¨ë“ˆì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë”ë¯¸ ëª¨ë“œë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤.")
    PIPELINE_AVAILABLE = False

from ..models.schemas import (
    VirtualTryOnRequest, 
    VirtualTryOnResponse, 
    PipelineProgress, 
    QualityMetrics
)

router = APIRouter(prefix="/api", tags=["Virtual Try-On Pipeline"])

# ì „ì—­ íŒŒì´í”„ë¼ì¸ ì¸ìŠ¤í„´ìŠ¤ (ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±ì„ ìœ„í•´)
pipeline_instance = None
active_connections: Dict[str, WebSocket] = {}

def get_pipeline_instance(quality_mode: str = "balanced") :
    """íŒŒì´í”„ë¼ì¸ ì¸ìŠ¤í„´ìŠ¤ ê´€ë¦¬"""
    global pipeline_instance
    
    if not PIPELINE_AVAILABLE:
        raise HTTPException(status_code=503, detail="AI íŒŒì´í”„ë¼ì¸ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    if pipeline_instance is None:
        pipeline_instance = PipelineFactory.create_optimized_pipeline(
            memory_gb=16.0,
            quality_mode=quality_mode
        )
    
    return pipeline_instance

def image_to_base64(image_array: np.ndarray) -> str:
    """numpy ë°°ì—´ì„ base64 ë¬¸ìì—´ë¡œ ë³€í™˜"""
    if image_array.max() <= 1.0:
        image_array = (image_array * 255).astype(np.uint8)
    
    image = Image.fromarray(image_array)
    buffer = io.BytesIO()
    image.save(buffer, format='PNG')
    buffer.seek(0)
    
    return base64.b64encode(buffer.getvalue()).decode()

async def send_progress_update(connection_id: str, step: int, progress: float, message: str):
    """WebSocketìœ¼ë¡œ ì§„í–‰ ìƒí™© ì „ì†¡"""
    if connection_id in active_connections:
        try:
            progress_data = {
                "step_id": step,
                "progress": progress,
                "message": message,
                "timestamp": time.time()
            }
            await active_connections[connection_id].send_text(json.dumps(progress_data))
        except Exception as e:
            logging.warning(f"WebSocket ì „ì†¡ ì‹¤íŒ¨: {e}")

@router.websocket("/ws/pipeline-progress")
async def websocket_endpoint(websocket: WebSocket):
    """íŒŒì´í”„ë¼ì¸ ì§„í–‰ ìƒí™©ì„ ìœ„í•œ WebSocket ì—°ê²°"""
    await websocket.accept()
    connection_id = str(id(websocket))
    active_connections[connection_id] = websocket
    
    try:
        while True:
            # ì—°ê²° ìœ ì§€ë¥¼ ìœ„í•œ ping
            await websocket.receive_text()
    except WebSocketDisconnect:
        if connection_id in active_connections:
            del active_connections[connection_id]

@router.post("/virtual-tryon-pipeline", response_model=VirtualTryOnResponse)
async def process_virtual_tryon_pipeline(
    person_image: UploadFile = File(...),
    clothing_image: UploadFile = File(...),
    height: float = Form(170),
    weight: float = Form(65),
    quality_mode: str = Form("balanced"),
    connection_id: Optional[str] = Form(None)
):
    """
    8ë‹¨ê³„ ê°€ìƒ í”¼íŒ… íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
    
    Args:
        person_image: ì‚¬ìš©ì ì´ë¯¸ì§€ íŒŒì¼
        clothing_image: ì˜ë¥˜ ì´ë¯¸ì§€ íŒŒì¼  
        height: í‚¤ (cm)
        weight: ëª¸ë¬´ê²Œ (kg)
        quality_mode: í’ˆì§ˆ ëª¨ë“œ (fast/balanced/quality)
        connection_id: WebSocket ì—°ê²° ID (ì§„í–‰ë¥  ì—…ë°ì´íŠ¸ìš©)
    
    Returns:
        VirtualTryOnResponse: ì²˜ë¦¬ ê²°ê³¼
    """
    
    try:
        # ê°œë°œ ë‹¨ê³„ì—ì„œëŠ” ë”ë¯¸ í”„ë¡œì„¸ì‹± ì‚¬ìš©
        if not PIPELINE_AVAILABLE:
            logging.info("ë”ë¯¸ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì¤‘...")
            return await test_dummy_process(connection_id)
        
        # íŒŒì´í”„ë¼ì¸ ì¸ìŠ¤í„´ìŠ¤ ê°€ì ¸ì˜¤ê¸°
        pipeline = get_pipeline_instance(quality_mode)
        
        # ì´ë¯¸ì§€ ë¡œë“œ ë° ì „ì²˜ë¦¬
        person_pil = Image.open(io.BytesIO(await person_image.read())).convert('RGB')
        cloth_pil = Image.open(io.BytesIO(await clothing_image.read())).convert('RGB')
        
        # ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸
        if connection_id:
            await send_progress_update(connection_id, 0, 0.1, "ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì¤‘...")
        
        # ì‚¬ìš©ì ì¸¡ì • ì •ë³´
        user_measurements = {
            "height": height,
            "weight": weight
        }
        
        # 8ë‹¨ê³„ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ (ê° ë‹¨ê³„ë³„ ì§„í–‰ë¥  ì—…ë°ì´íŠ¸)
        result = await process_pipeline_with_progress(
            pipeline, person_pil, cloth_pil, user_measurements, connection_id
        )
        
        if result.success:
            # ì„±ê³µ ì‘ë‹µ
            response = VirtualTryOnResponse(
                success=True,
                fitted_image=image_to_base64(result.fitted_image),
                processing_time=result.processing_time,
                confidence=result.quality_scores.get("overall_score", 0.85),
                measurements=extract_measurements(result),
                clothing_analysis=extract_clothing_analysis(result),
                fit_score=result.quality_scores.get("fit_overall", 0.85),
                recommendations=generate_user_recommendations(result),
                quality_metrics=result.quality_scores,
                memory_usage=result.memory_usage,
                step_times=result.step_times
            )
            
            # ìµœì¢… ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
            if connection_id:
                await send_progress_update(connection_id, 8, 1.0, "ì²˜ë¦¬ ì™„ë£Œ!")
            
            return response
        else:
            raise HTTPException(status_code=500, detail=result.error_message)
    
    except Exception as e:
        logging.error(f"íŒŒì´í”„ë¼ì¸ ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")
        if connection_id:
            await send_progress_update(connection_id, -1, 0, f"ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

async def process_pipeline_with_progress(
    pipeline: VirtualTryOnPipeline,
    person_image: Image.Image,
    cloth_image: Image.Image,
    user_measurements: Dict[str, float],
    connection_id: Optional[str]
) -> Any:
    """ì§„í–‰ë¥  ì—…ë°ì´íŠ¸ì™€ í•¨ê»˜ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
    
    step_names = [
        "ì¸ì²´ íŒŒì‹± (20ê°œ ë¶€ìœ„ ë¶„í• )",
        "í¬ì¦ˆ ì¶”ì • (18ê°œ í‚¤í¬ì¸íŠ¸)", 
        "ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜",
        "ê¸°í•˜í•™ì  ë§¤ì¹­ (TPS ë³€í™˜)",
        "ì˜· ì›Œí•‘",
        "ê°€ìƒ í”¼íŒ… ìƒì„±",
        "í›„ì²˜ë¦¬ (í’ˆì§ˆ í–¥ìƒ)",
        "í’ˆì§ˆ í‰ê°€"
    ]
    
    # ê° ë‹¨ê³„ë³„ ì˜ˆìƒ ì†Œìš” ì‹œê°„ (ë¹„ìœ¨)
    step_weights = [0.15, 0.1, 0.1, 0.15, 0.15, 0.25, 0.05, 0.05]
    
    class ProgressTracker:
        def __init__(self):
            self.current_step = 0
            self.total_progress = 0.1  # ì´ˆê¸° ì „ì²˜ë¦¬ 10%
    
    tracker = ProgressTracker()
    
    # íŒŒì´í”„ë¼ì¸ì˜ ê° ë‹¨ê³„ì— ì§„í–‰ë¥  ì½œë°± ì¶”ê°€
    async def step_callback(step_id: int, progress: float):
        if connection_id:
            # í˜„ì¬ ë‹¨ê³„ì˜ ì§„í–‰ë¥  ê³„ì‚°
            step_progress = sum(step_weights[:step_id]) + step_weights[step_id] * progress
            total_progress = 0.1 + step_progress * 0.9  # ì „ì²˜ë¦¬ 10% + íŒŒì´í”„ë¼ì¸ 90%
            
            message = f"{step_names[step_id]} ({int(progress * 100)}%)"
            await send_progress_update(connection_id, step_id + 1, total_progress, message)
    
    # íŒŒì´í”„ë¼ì¸ì— ì½œë°± ì„¤ì •
    pipeline.progress_callback = step_callback
    
    # ì‹¤ì œ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
    result = await pipeline.process(person_image, cloth_image, user_measurements)
    
    return result

def extract_measurements(result) -> Dict[str, float]:
    """ê²°ê³¼ì—ì„œ ì‹ ì²´ ì¸¡ì • ì •ë³´ ì¶”ì¶œ"""
    measurements = {
        "chest": 88.0,
        "waist": 70.0,
        "hip": 92.0,
        "bmi": 22.5
    }
    
    # ì‹¤ì œ íŒŒì´í”„ë¼ì¸ ê²°ê³¼ì—ì„œ ì¸¡ì •ê°’ ì¶”ì¶œ
    if hasattr(result, 'intermediate_results'):
        human_parsing = result.intermediate_results.get('human_parsing', {})
        if 'body_measurements' in human_parsing:
            measurements.update(human_parsing['body_measurements'])
    
    return measurements

def extract_clothing_analysis(result) -> Dict[str, Any]:
    """ì˜ë¥˜ ë¶„ì„ ì •ë³´ ì¶”ì¶œ"""
    analysis = {
        "category": "ìƒì˜",
        "style": "ìºì£¼ì–¼",
        "dominant_color": [120, 150, 200],
        "material": "ë©´"
    }
    
    # ì‹¤ì œ íŒŒì´í”„ë¼ì¸ ê²°ê³¼ì—ì„œ ì˜ë¥˜ ë¶„ì„ ì¶”ì¶œ
    if hasattr(result, 'intermediate_results'):
        cloth_seg = result.intermediate_results.get('cloth_segmentation', {})
        if 'cloth_type' in cloth_seg:
            analysis["category"] = cloth_seg['cloth_type']
            analysis["confidence"] = cloth_seg.get('cloth_confidence', 0.8)
    
    return analysis

def generate_user_recommendations(result) -> List[str]:  # âœ… List íƒ€ì… íŒíŠ¸ ìˆ˜ì •
    """ì‚¬ìš©ì ì¹œí™”ì  ì¶”ì²œì‚¬í•­ ìƒì„±"""
    recommendations = []
    
    if hasattr(result, 'quality_scores'):
        overall_score = result.quality_scores.get('overall_score', 0.8)
        
        if overall_score >= 0.9:
            recommendations.append("ğŸ‰ ì™„ë²½í•œ í•! ì´ ìŠ¤íƒ€ì¼ì´ ë§¤ìš° ì˜ ì–´ìš¸ë¦½ë‹ˆë‹¤.")
        elif overall_score >= 0.8:
            recommendations.append("ğŸ‘ ì¢‹ì€ í•ì…ë‹ˆë‹¤! ìì‹ ê° ìˆê²Œ ì°©ìš©í•˜ì„¸ìš”.")
        elif overall_score >= 0.6:
            recommendations.append("ğŸ‘Œ ê´œì°®ì€ í•ì´ì§€ë§Œ, ë‹¤ë¥¸ ì‚¬ì´ì¦ˆë„ ê³ ë ¤í•´ë³´ì„¸ìš”.")
        else:
            recommendations.append("ğŸ¤” ì´ ì•„ì´í…œì€ ë§ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ìŠ¤íƒ€ì¼ì„ ì¶”ì²œë“œë¦½ë‹ˆë‹¤.")
        
        # êµ¬ì²´ì ì¸ í”¼íŒ… ì¡°ì–¸
        fit_coverage = result.quality_scores.get('fit_coverage', 0.8)
        if fit_coverage < 0.7:
            recommendations.append("ğŸ“ ì‚¬ì´ì¦ˆë¥¼ í•œ ì¹˜ìˆ˜ í¬ê²Œ ê³ ë ¤í•´ë³´ì„¸ìš”.")
        
        color_preservation = result.quality_scores.get('color_preservation', 0.8)
        if color_preservation > 0.9:
            recommendations.append("ğŸ¨ ìƒ‰ìƒì´ í”¼ë¶€í†¤ê³¼ ì˜ ì–´ìš¸ë¦½ë‹ˆë‹¤!")
    
    if not recommendations:
        recommendations.append("âœ¨ ë©‹ì§„ ì„ íƒì…ë‹ˆë‹¤! ì´ ìŠ¤íƒ€ì¼ì„ ì¶”ì²œë“œë¦½ë‹ˆë‹¤.")
    
    return recommendations

@router.get("/pipeline/status")
async def get_pipeline_status():
    """íŒŒì´í”„ë¼ì¸ ìƒíƒœ ì¡°íšŒ"""
    global pipeline_instance
    
    if not PIPELINE_AVAILABLE:
        return {
            "status": "development_mode",
            "message": "AI ëª¨ë¸ë“¤ì´ ì•„ì§ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.",
            "available_endpoints": ["test/dummy-process"]
        }
    
    if pipeline_instance is None:
        return {"status": "not_initialized"}
    
    status = pipeline_instance.get_pipeline_status()
    return {
        "status": "ready",
        "device": status["device"],
        "memory_usage": status["memory_usage"],
        "models_loaded": status["models_loaded"],
        "active_connections": len(active_connections)
    }

@router.post("/pipeline/warmup")
async def warmup_pipeline(quality_mode: str = "balanced"):
    """íŒŒì´í”„ë¼ì¸ ì›Œë°ì—… (ì²« ì‹¤í–‰ ì‹œ ëª¨ë¸ ë¡œë”©)"""
    try:
        if not PIPELINE_AVAILABLE:
            return {
                "success": False,
                "message": "ê°œë°œ ëª¨ë“œ - AI ëª¨ë¸ ì„¤ì • í•„ìš”"
            }
            
        pipeline = get_pipeline_instance(quality_mode)
        await pipeline.warmup()
        
        return {
            "success": True,
            "message": "íŒŒì´í”„ë¼ì¸ ì›Œë°ì—… ì™„ë£Œ",
            "quality_mode": quality_mode
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ì›Œë°ì—… ì‹¤íŒ¨: {str(e)}")

@router.delete("/pipeline/cleanup")
async def cleanup_pipeline():
    """íŒŒì´í”„ë¼ì¸ ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
    global pipeline_instance
    
    try:
        if pipeline_instance:
            pipeline_instance.cleanup()
            pipeline_instance = None
        
        return {
            "success": True,
            "message": "íŒŒì´í”„ë¼ì¸ ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì™„ë£Œ"
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ì •ë¦¬ ì‹¤íŒ¨: {str(e)}")

@router.get("/quality/metrics")
async def get_quality_metrics_info():
    """í’ˆì§ˆ ë©”íŠ¸ë¦­ ì •ë³´ ì¡°íšŒ"""
    return {
        "metrics": {
            "ssim": {
                "name": "êµ¬ì¡°ì  ìœ ì‚¬ì„±",
                "description": "ì›ë³¸ê³¼ ê²°ê³¼ ì´ë¯¸ì§€ì˜ êµ¬ì¡°ì  ìœ ì‚¬ë„",
                "range": [0, 1],
                "higher_better": True
            },
            "lpips": {
                "name": "ì§€ê°ì  ìœ ì‚¬ì„±", 
                "description": "ì¸ê°„ì˜ ì‹œê° ì¸ì§€ì— ê¸°ë°˜í•œ ìœ ì‚¬ë„",
                "range": [0, 1],
                "higher_better": True
            },
            "fit_overall": {
                "name": "ì „ì²´ í”¼íŒ… ì ìˆ˜",
                "description": "ì˜ë¥˜ ì°©ìš©ê°ì˜ ì¢…í•© í‰ê°€",
                "range": [0, 1],
                "higher_better": True
            }
        },
        "quality_grades": {
            "excellent": "90% ì´ìƒ - ì™„ë²½í•œ í’ˆì§ˆ",
            "good": "80-89% - ìš°ìˆ˜í•œ í’ˆì§ˆ", 
            "fair": "60-79% - ì–‘í˜¸í•œ í’ˆì§ˆ",
            "poor": "60% ë¯¸ë§Œ - ê°œì„  í•„ìš”"
        }
    }

@router.post("/test/dummy-process")
async def test_dummy_process(connection_id: Optional[str] = None):
    """í…ŒìŠ¤íŠ¸ìš© ë”ë¯¸ ì²˜ë¦¬ (ê°œë°œìš©)"""
    step_names = [
        "ì¸ì²´ íŒŒì‹±", "í¬ì¦ˆ ì¶”ì •", "ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜", "ê¸°í•˜í•™ì  ë§¤ì¹­",
        "ì˜· ì›Œí•‘", "ê°€ìƒ í”¼íŒ…", "í›„ì²˜ë¦¬", "í’ˆì§ˆ í‰ê°€"
    ]
    
    for i, step_name in enumerate(step_names):
        # ê° ë‹¨ê³„ë§ˆë‹¤ 0.5ì´ˆ ëŒ€ê¸°
        await asyncio.sleep(0.5)
        
        progress = (i + 1) / len(step_names)
        
        if connection_id:
            await send_progress_update(
                connection_id, i + 1, progress, f"{step_name} ì™„ë£Œ"
            )
    
    # ë”ë¯¸ ê²°ê³¼ ìƒì„± (512x512 ëœë¤ ì´ë¯¸ì§€)
    dummy_image = np.random.randint(0, 255, (512, 512, 3), dtype=np.uint8)
    
    return VirtualTryOnResponse(
        success=True,
        fitted_image=image_to_base64(dummy_image),
        processing_time=4.0,
        confidence=0.87,
        measurements={"chest": 88, "waist": 70, "hip": 92, "bmi": 22.5},
        clothing_analysis={
            "category": "ìƒì˜",
            "style": "ìºì£¼ì–¼", 
            "dominant_color": [120, 150, 200]
        },
        fit_score=0.85,
        recommendations=["ì™„ë²½í•œ í•ì…ë‹ˆë‹¤!", "ìƒ‰ìƒì´ ì˜ ì–´ìš¸ë¦½ë‹ˆë‹¤!"],
        quality_metrics={
            "ssim": 0.89,
            "lpips": 0.85,
            "fit_overall": 0.87
        }
    )