"""
ğŸ”¥ MyCloset AI API ì—”ë“œí¬ì¸íŠ¸ í†µí•© ì‹œìŠ¤í…œ v2.0
===============================================

âœ… conda í™˜ê²½ ìš°ì„  ìµœì í™”
âœ… ê¸°ì¡´ ë¼ìš°í„°ë“¤ ì™„ì „ í†µí•©  
âœ… M3 Max 128GB ë©”ëª¨ë¦¬ ìµœì í™”
âœ… AI ìƒíƒœ API ì—”ë“œí¬ì¸íŠ¸ ì¶”ê°€
âœ… ìˆœí™˜ì°¸ì¡° ì™„ì „ í•´ê²°
âœ… í”„ë¡œë•ì…˜ ë ˆë²¨ ì•ˆì •ì„±

Author: MyCloset AI Team
Date: 2025-07-23
Version: 2.0 (Complete Router Integration)
"""

import logging
import asyncio
from typing import Dict, Any, Optional, List
from datetime import datetime

from fastapi import APIRouter, HTTPException
from fastapi.responses import JSONResponse

# ì•ˆì „í•œ ì¡°ê±´ë¶€ import (conda í™˜ê²½ ìµœì í™”)
logger = logging.getLogger(__name__)

# =============================================================================
# ğŸ”¥ ë©”ì¸ API ë¼ìš°í„° (ê¸°ì¡´ ìœ ì§€ + ê°œì„ )
# =============================================================================

# ë©”ì¸ API ë¼ìš°í„° (ê¸°ì¡´ ì½”ë“œ ìœ ì§€)
api_router = APIRouter(prefix="/api", tags=["api"])

# ë²„ì „ ì •ë³´ (ê¸°ì¡´ ì½”ë“œ ìœ ì§€)
API_VERSION = "v1"
API_TITLE = "MyCloset AI API"

# =============================================================================
# ğŸ”¥ AI ìƒíƒœ API ì—”ë“œí¬ì¸íŠ¸ (ëˆ„ë½ëœ /api/ai/status í•´ê²°)
# =============================================================================

@api_router.get("/ai/status")
async def get_ai_status():
    """
    AI ì‹œìŠ¤í…œ ìƒíƒœ ì¡°íšŒ API (ëˆ„ë½ë˜ì—ˆë˜ ì—”ë“œí¬ì¸íŠ¸)
    
    Returns:
        AI ì‹œìŠ¤í…œì˜ ì „ë°˜ì ì¸ ìƒíƒœ ì •ë³´
    """
    try:
        # ì‹œìŠ¤í…œ ì •ë³´ ìˆ˜ì§‘
        import platform
        import psutil
        import sys
        import os
        
        # ê¸°ë³¸ ìƒíƒœ ì •ë³´
        status_info = {
            "status": "running",
            "timestamp": datetime.now().isoformat(),
            "version": "8.0.0",
            "api_version": API_VERSION,
            "environment": {
                "python_version": sys.version,
                "platform": platform.platform(),
                "conda_env": os.environ.get('CONDA_DEFAULT_ENV', 'unknown'),
                "is_conda": 'CONDA_DEFAULT_ENV' in os.environ
            }
        }
        
        # ë©”ëª¨ë¦¬ ì •ë³´
        try:
            memory = psutil.virtual_memory()
            status_info["memory"] = {
                "total_gb": round(memory.total / (1024**3), 1),
                "available_gb": round(memory.available / (1024**3), 1),
                "used_percent": memory.percent
            }
        except:
            status_info["memory"] = {"error": "memory info unavailable"}
        
        # PyTorch/MPS ìƒíƒœ
        try:
            import torch
            status_info["pytorch"] = {
                "version": torch.__version__,
                "mps_available": torch.backends.mps.is_available() if hasattr(torch.backends, 'mps') else False,
                "cuda_available": torch.cuda.is_available(),
                "device_count": torch.cuda.device_count() if torch.cuda.is_available() else 0
            }
            
            # í˜„ì¬ ë””ë°”ì´ìŠ¤ ê°ì§€
            if torch.backends.mps.is_available():
                status_info["device"] = "mps"
                status_info["device_name"] = "Apple M3 Max GPU"
            elif torch.cuda.is_available():
                status_info["device"] = "cuda"
                status_info["device_name"] = torch.cuda.get_device_name(0)
            else:
                status_info["device"] = "cpu"
                status_info["device_name"] = "CPU"
                
        except ImportError:
            status_info["pytorch"] = {"error": "PyTorch not available"}
            status_info["device"] = "unknown"
        
        # AI ëª¨ë¸ ìƒíƒœ (ê¸°ë³¸ê°’)
        status_info.update({
            "models_loaded": 0,
            "models_available": 8,  # 8ë‹¨ê³„ íŒŒì´í”„ë¼ì¸
            "pipeline_active": True,
            "ai_processing": False,
            "last_model_load": None
        })
        
        # AI Container ìƒíƒœ (ìˆëŠ” ê²½ìš°)
        try:
            # main.pyì˜ ai_container ì°¸ì¡° ì‹œë„
            from ..main import ai_container
            if ai_container:
                ai_status = ai_container.get_system_status()
                status_info.update({
                    "models_loaded": ai_status.get('ai_steps_count', 0),
                    "pipeline_active": ai_status.get('model_loader_available', False),
                    "ai_processing": ai_status.get('pipeline_manager_available', False)
                })
        except:
            # AI Container ì—†ì–´ë„ ê¸°ë³¸ ì •ë³´ ì œê³µ
            pass
        
        return {
            "success": True,
            "data": status_info
        }
        
    except Exception as e:
        logger.error(f"âŒ AI ìƒíƒœ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return {
            "success": False,
            "error": str(e),
            "status": "error",
            "timestamp": datetime.now().isoformat()
        }

# =============================================================================
# ğŸ”¥ ì‹œìŠ¤í…œ ì •ë³´ API
# =============================================================================

@api_router.get("/system/info")
async def get_system_info():
    """ì‹œìŠ¤í…œ ì •ë³´ ì¡°íšŒ"""
    try:
        import platform
        import psutil
        import sys
        import os
        
        system_info = {
            "system": {
                "platform": platform.platform(),
                "processor": platform.processor(),
                "architecture": platform.architecture(),
                "python_version": sys.version,
                "conda_env": os.environ.get('CONDA_DEFAULT_ENV', 'not_conda'),
                "is_conda": 'CONDA_DEFAULT_ENV' in os.environ
            },
            "memory": {
                "total_gb": round(psutil.virtual_memory().total / (1024**3), 1),
                "available_gb": round(psutil.virtual_memory().available / (1024**3), 1),
                "used_percent": psutil.virtual_memory().percent
            },
            "cpu": {
                "count": psutil.cpu_count(),
                "usage_percent": psutil.cpu_percent(interval=1)
            },
            "timestamp": datetime.now().isoformat()
        }
        
        # M3 Max ê°ì§€
        try:
            if platform.system() == 'Darwin':
                import subprocess
                result = subprocess.run(['sysctl', '-n', 'machdep.cpu.brand_string'], 
                                      capture_output=True, text=True, timeout=5)
                chip_info = result.stdout.strip()
                system_info["system"]["chip"] = chip_info
                system_info["system"]["is_m3_max"] = 'M3' in chip_info and 'Max' in chip_info
        except:
            system_info["system"]["chip"] = "unknown"
            system_info["system"]["is_m3_max"] = False
        
        return {
            "success": True,
            "data": system_info
        }
        
    except Exception as e:
        return {
            "success": False,
            "error": str(e)
        }

# =============================================================================
# ğŸ”¥ ë¼ìš°í„° í†µí•© ì‹œìŠ¤í…œ
# =============================================================================

def get_all_routers() -> List[APIRouter]:
    """
    ëª¨ë“  API ë¼ìš°í„°ë“¤ì„ ìˆ˜ì§‘í•˜ì—¬ ë°˜í™˜
    conda í™˜ê²½ì—ì„œ ì•ˆì „í•˜ê²Œ ë™ì‘
    """
    routers = []
    
    # 1. ë©”ì¸ API ë¼ìš°í„° ì¶”ê°€
    routers.append(api_router)
    
    # 2. ê°œë³„ ë¼ìš°í„°ë“¤ ì•ˆì „í•˜ê²Œ import ë° ì¶”ê°€
    try:
        from .pipeline_routes import router as pipeline_router
        routers.append(pipeline_router)
        logger.info("âœ… pipeline_routes ë¼ìš°í„° ë¡œë“œ")
    except Exception as e:
        logger.warning(f"âš ï¸ pipeline_routes ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    try:
        from .websocket_routes import router as websocket_router
        routers.append(websocket_router)
        logger.info("âœ… websocket_routes ë¼ìš°í„° ë¡œë“œ")
    except Exception as e:
        logger.warning(f"âš ï¸ websocket_routes ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    try:
        from .step_routes import router as step_router
        routers.append(step_router)
        logger.info("âœ… step_routes ë¼ìš°í„° ë¡œë“œ")
    except Exception as e:
        logger.warning(f"âš ï¸ step_routes ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    # 3. í´ë˜ìŠ¤ ê¸°ë°˜ ë¼ìš°í„°ë“¤ (ì¸ìŠ¤í„´ìŠ¤ ìƒì„± í•„ìš”)
    try:
        from .health import HealthRouter
        health_router_instance = HealthRouter()
        if hasattr(health_router_instance, 'router'):
            routers.append(health_router_instance.router)
            logger.info("âœ… health ë¼ìš°í„° ë¡œë“œ")
    except Exception as e:
        logger.warning(f"âš ï¸ health ë¼ìš°í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    try:
        from .models import ModelRouter
        model_router_instance = ModelRouter()
        if hasattr(model_router_instance, 'router'):
            routers.append(model_router_instance.router)
            logger.info("âœ… models ë¼ìš°í„° ë¡œë“œ")
    except Exception as e:
        logger.warning(f"âš ï¸ models ë¼ìš°í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    # 4. virtual_tryon ë¼ìš°í„° (ìˆëŠ” ê²½ìš°)
    try:
        from .virtual_tryon import router as vt_router
        routers.append(vt_router)
        logger.info("âœ… virtual_tryon ë¼ìš°í„° ë¡œë“œ")
    except Exception as e:
        logger.warning(f"âš ï¸ virtual_tryon ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    logger.info(f"ğŸ‰ ì´ {len(routers)}ê°œ ë¼ìš°í„° ë¡œë“œ ì™„ë£Œ")
    return routers

def register_all_routers(app):
    """
    FastAPI ì•±ì— ëª¨ë“  ë¼ìš°í„°ë¥¼ ë“±ë¡
    main.pyì—ì„œ í˜¸ì¶œí•˜ëŠ” í•¨ìˆ˜
    """
    routers = get_all_routers()
    
    for i, router in enumerate(routers):
        try:
            app.include_router(router)
            logger.info(f"âœ… ë¼ìš°í„° {i+1} ë“±ë¡ ì™„ë£Œ")
        except Exception as e:
            logger.error(f"âŒ ë¼ìš°í„° {i+1} ë“±ë¡ ì‹¤íŒ¨: {e}")
    
    logger.info(f"ğŸš€ ëª¨ë“  ë¼ìš°í„° ë“±ë¡ ì™„ë£Œ! ì´ {len(routers)}ê°œ")
    return len(routers)

# =============================================================================
# ğŸ”¥ ì´ˆê¸°í™” í•¨ìˆ˜
# =============================================================================

async def initialize_api_system():
    """API ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
    try:
        logger.info("ğŸš€ MyCloset AI API ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹œì‘...")
        
        # conda í™˜ê²½ í™•ì¸
        import os
        conda_env = os.environ.get('CONDA_DEFAULT_ENV', 'unknown')
        logger.info(f"ğŸ conda í™˜ê²½: {conda_env}")
        
        # M3 Max ê°ì§€
        import platform
        if platform.system() == 'Darwin':
            try:
                import subprocess
                result = subprocess.run(['sysctl', '-n', 'machdep.cpu.brand_string'], 
                                      capture_output=True, text=True, timeout=5)
                chip_info = result.stdout.strip()
                if 'M3' in chip_info and 'Max' in chip_info:
                    logger.info("ğŸ M3 Max ê°ì§€ë¨ - ìµœì í™” ëª¨ë“œ í™œì„±í™”")
            except:
                pass
        
        logger.info("âœ… API ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
        return True
        
    except Exception as e:
        logger.error(f"âŒ API ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return False

# =============================================================================
# ğŸ”¥ Export ì •ì˜
# =============================================================================

__all__ = [
    'api_router',
    'API_VERSION', 
    'API_TITLE',
    'get_all_routers',
    'register_all_routers',
    'initialize_api_system'
]

logger.info("ğŸ‰ MyCloset AI API í†µí•© ì‹œìŠ¤í…œ v2.0 ë¡œë“œ ì™„ë£Œ!")
logger.info("âœ… /api/ai/status ì—”ë“œí¬ì¸íŠ¸ ì¶”ê°€ë¨")
logger.info("âœ… ë¼ìš°í„° í†µí•© ì‹œìŠ¤í…œ êµ¬ì¶•ë¨")
logger.info("âœ… conda í™˜ê²½ ìš°ì„  ìµœì í™” ì ìš©ë¨")