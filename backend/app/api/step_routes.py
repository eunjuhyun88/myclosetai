"""
step_routes.py - ì‹¤ì œ AI íŒŒì´í”„ë¼ì¸ ì—°ë™ ë²„ì „
âœ… ì‹¤ì œ app/ai_pipeline/steps/ íŒŒì¼ë“¤ í™œìš©
âœ… PyTorch 2.1 ë²„ì „ í˜¸í™˜
âœ… í´ë°± ì½”ë“œ ì œê±° - ì‹¤ì œ AI ëª¨ë¸ë§Œ ì‚¬ìš©
âœ… ê¸°ì¡´ í•¨ìˆ˜ëª…/í´ë˜ìŠ¤ëª… ìœ ì§€
âœ… í”„ë¡ íŠ¸ì—”ë“œ App.tsx 100% í˜¸í™˜
"""

import os
import sys
import logging
import asyncio
import time
import uuid
import base64
import json
import traceback
from pathlib import Path
from typing import Dict, Any, List, Optional, Union
from datetime import datetime
from io import BytesIO

# ì™¸ë¶€ ë¼ì´ë¸ŒëŸ¬ë¦¬
import numpy as np
import cv2
import torch
from PIL import Image, ImageEnhance, ImageFilter

# FastAPI í•„ìˆ˜ import
from fastapi import APIRouter, Form, File, UploadFile, HTTPException, BackgroundTasks
from fastapi.responses import JSONResponse
from pydantic import BaseModel, Field

# ============================================================================
# ğŸ”§ ì‹¤ì œ AI íŒŒì´í”„ë¼ì¸ IMPORTS
# ============================================================================

# ë¡œê¹… ì„¤ì •
logger = logging.getLogger(__name__)

# 1. ì‹¤ì œ AI íŒŒì´í”„ë¼ì¸ Steps import
try:
    from app.ai_pipeline.steps.step_01_human_parsing import HumanParsingStep
    from app.ai_pipeline.steps.step_02_pose_estimation import PoseEstimationStep
    from app.ai_pipeline.steps.step_03_cloth_segmentation import ClothSegmentationStep
    from app.ai_pipeline.steps.step_04_geometric_matching import GeometricMatchingStep
    from app.ai_pipeline.steps.step_05_cloth_warping import ClothWarpingStep
    from app.ai_pipeline.steps.step_06_virtual_fitting import VirtualFittingStep
    from app.ai_pipeline.steps.step_07_post_processing import PostProcessingStep
    from app.ai_pipeline.steps.step_08_quality_assessment import QualityAssessmentStep
    
    PIPELINE_STEPS_AVAILABLE = True
    logger.info("âœ… ì‹¤ì œ AI íŒŒì´í”„ë¼ì¸ Steps import ì„±ê³µ")
except ImportError as e:
    logger.error(f"âŒ ì‹¤ì œ AI íŒŒì´í”„ë¼ì¸ Steps import ì‹¤íŒ¨: {e}")
    raise RuntimeError("ì‹¤ì œ AI íŒŒì´í”„ë¼ì¸ Stepsë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í”„ë¡œì íŠ¸ êµ¬ì¡°ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")

# 2. íŒŒì´í”„ë¼ì¸ ë§¤ë‹ˆì € import
try:
    from app.ai_pipeline.pipeline_manager import PipelineManager
    PIPELINE_MANAGER_AVAILABLE = True
    logger.info("âœ… PipelineManager import ì„±ê³µ")
except ImportError as e:
    logger.error(f"âŒ PipelineManager import ì‹¤íŒ¨: {e}")
    raise RuntimeError("PipelineManagerë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

# 3. ìœ í‹¸ë¦¬í‹°ë“¤ import
try:
    from app.ai_pipeline.utils.model_loader import ModelLoader
    from app.ai_pipeline.utils.memory_manager import MemoryManager
    from app.ai_pipeline.utils.data_converter import DataConverter
    UTILS_AVAILABLE = True
    logger.info("âœ… AI Pipeline Utils import ì„±ê³µ")
except ImportError as e:
    logger.warning(f"âš ï¸ AI Pipeline Utils import ì‹¤íŒ¨: {e}")
    UTILS_AVAILABLE = False

# 4. ìŠ¤í‚¤ë§ˆ import
try:
    from app.models.schemas import (
        StepResult, 
        VirtualTryOnRequest, 
        VirtualTryOnResponse,
        ProcessingStatus,
        BodyMeasurements,
        ClothingType
    )
    SCHEMAS_AVAILABLE = True
    logger.info("âœ… ìŠ¤í‚¤ë§ˆ import ì„±ê³µ")
except ImportError as e:
    logger.warning(f"âš ï¸ ìŠ¤í‚¤ë§ˆ import ì‹¤íŒ¨: {e}")
    SCHEMAS_AVAILABLE = False

# 5. GPU ì„¤ì • (ì„ íƒì )
try:
    from app.core.gpu_config import get_gpu_config, optimize_memory, check_memory_available
    GPU_CONFIG_AVAILABLE = True
    logger.info("âœ… GPU Config import ì„±ê³µ")
except ImportError as e:
    logger.warning(f"âš ï¸ GPU Config import ì‹¤íŒ¨: {e}")
    GPU_CONFIG_AVAILABLE = False

# ============================================================================
# ğŸ¤– ë””ë°”ì´ìŠ¤ ì„¤ì • (PyTorch 2.1 í˜¸í™˜)
# ============================================================================

def get_optimal_device() -> str:
    """PyTorch 2.1 í˜¸í™˜ ìµœì  ë””ë°”ì´ìŠ¤ ì„ íƒ"""
    try:
        # PyTorch 2.1ì—ì„œ MPS ì§€ì› í™•ì¸
        if hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
            return "mps"
        elif torch.cuda.is_available():
            return "cuda"
        else:
            return "cpu"
    except Exception as e:
        logger.warning(f"ë””ë°”ì´ìŠ¤ ê°ì§€ ì‹¤íŒ¨: {e}")
        return "cpu"

def optimize_device_memory(device: str):
    """ë””ë°”ì´ìŠ¤ë³„ ë©”ëª¨ë¦¬ ìµœì í™”"""
    try:
        if device == "mps":
            torch.mps.empty_cache()
        elif device == "cuda":
            torch.cuda.empty_cache()
        else:
            import gc
            gc.collect()
        logger.debug(f"ë©”ëª¨ë¦¬ ìµœì í™” ì™„ë£Œ: {device}")
    except Exception as e:
        logger.warning(f"ë©”ëª¨ë¦¬ ìµœì í™” ì‹¤íŒ¨: {e}")

# ì „ì—­ ë””ë°”ì´ìŠ¤ ì„¤ì •
DEVICE = get_optimal_device()
logger.info(f"ğŸ¯ ì‚¬ìš© ë””ë°”ì´ìŠ¤: {DEVICE}")

# ============================================================================
# ğŸ—ï¸ ìŠ¤í‚¤ë§ˆ ì •ì˜ (í•„ìš”ì‹œ í´ë°±)
# ============================================================================

if not SCHEMAS_AVAILABLE:
    class BodyMeasurements(BaseModel):
        height: float = Field(..., description="í‚¤ (cm)")
        weight: float = Field(..., description="ëª¸ë¬´ê²Œ (kg)")
        chest: Optional[float] = Field(None, description="ê°€ìŠ´ë‘˜ë ˆ (cm)")
        waist: Optional[float] = Field(None, description="í—ˆë¦¬ë‘˜ë ˆ (cm)")
        hips: Optional[float] = Field(None, description="ì—‰ë©ì´ë‘˜ë ˆ (cm)")
    
    class ClothingType(BaseModel):
        value: str = Field(..., description="ì˜ë¥˜ íƒ€ì…")
    
    class ProcessingStatus(BaseModel):
        status: str = Field(..., description="ì²˜ë¦¬ ìƒíƒœ")
        progress: float = Field(..., description="ì§„í–‰ë¥ ")
        message: str = Field(..., description="ìƒíƒœ ë©”ì‹œì§€")

# ============================================================================
# ğŸ”§ ì‹¤ì œ AI íŒŒì´í”„ë¼ì¸ í”„ë¡œì„¸ì„œ
# ============================================================================

class RealAIPipelineProcessor:
    """
    ì‹¤ì œ AI íŒŒì´í”„ë¼ì¸ í™œìš© í”„ë¡œì„¸ì„œ
    - í´ë°± ì½”ë“œ ì—†ìŒ, ì‹¤ì œ AI ëª¨ë¸ë§Œ ì‚¬ìš©
    - PyTorch 2.1 ì™„ì „ í˜¸í™˜
    - í”„ë¡ íŠ¸ì—”ë“œ App.tsx 100% í˜¸í™˜
    """
    
    def __init__(self, device: Optional[str] = None):
        """
        ì‹¤ì œ AI íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™”
        
        Args:
            device: ì‚¬ìš©í•  ë””ë°”ì´ìŠ¤ (None=ìë™ê°ì§€)
        """
        self.device = device or DEVICE
        self.initialized = False
        self.logger = logging.getLogger(f"real_ai.{self.__class__.__name__}")
        
        # ì‹¤ì œ AI íŒŒì´í”„ë¼ì¸ ì»´í¬ë„ŒíŠ¸ë“¤
        self.pipeline_manager = None
        self.ai_steps = {}
        self.utils = {}
        
        # ìƒíƒœ ì¶”ì 
        self.processing_sessions = {}
        self.model_load_status = {}
        
        logger.info(f"ğŸ”§ ì‹¤ì œ AI íŒŒì´í”„ë¼ì¸ í”„ë¡œì„¸ì„œ ì´ˆê¸°í™” - Device: {self.device}")
    
    async def initialize(self) -> bool:
        """ì‹¤ì œ AI íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™”"""
        try:
            if self.initialized:
                return True
            
            logger.info("ğŸš€ ì‹¤ì œ AI íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” ì‹œì‘...")
            
            # 1. ë©”ëª¨ë¦¬ ìµœì í™”
            optimize_device_memory(self.device)
            
            # 2. íŒŒì´í”„ë¼ì¸ ë§¤ë‹ˆì € ì´ˆê¸°í™”
            await self._initialize_pipeline_manager()
            
            # 3. 8ë‹¨ê³„ AI Steps ì´ˆê¸°í™”
            await self._initialize_ai_steps()
            
            # 4. ìœ í‹¸ë¦¬í‹° ì´ˆê¸°í™”
            await self._initialize_utilities()
            
            # 5. ëª¨ë¸ ë¡œë“œ ìƒíƒœ í™•ì¸
            await self._check_model_status()
            
            self.initialized = True
            logger.info("ğŸ‰ ì‹¤ì œ AI íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” ì™„ë£Œ!")
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ ì‹¤ì œ AI íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            logger.error(f"ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤: {traceback.format_exc()}")
            raise RuntimeError(f"AI íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    
    async def _initialize_pipeline_manager(self):
        """íŒŒì´í”„ë¼ì¸ ë§¤ë‹ˆì € ì´ˆê¸°í™”"""
        try:
            self.pipeline_manager = PipelineManager(device=self.device)
            
            # íŒŒì´í”„ë¼ì¸ ë§¤ë‹ˆì € ì´ˆê¸°í™” ë©”ì„œë“œê°€ ìˆë‹¤ë©´ í˜¸ì¶œ
            if hasattr(self.pipeline_manager, 'initialize'):
                await self.pipeline_manager.initialize()
            
            logger.info("âœ… PipelineManager ì´ˆê¸°í™” ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"âŒ PipelineManager ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            raise
    
    async def _initialize_ai_steps(self):
        """8ë‹¨ê³„ AI Steps ì´ˆê¸°í™”"""
        try:
            step_classes = {
                "step_01": HumanParsingStep,
                "step_02": PoseEstimationStep,
                "step_03": ClothSegmentationStep,
                "step_04": GeometricMatchingStep,
                "step_05": ClothWarpingStep,
                "step_06": VirtualFittingStep,
                "step_07": PostProcessingStep,
                "step_08": QualityAssessmentStep
            }
            
            for step_name, step_class in step_classes.items():
                try:
                    # ì‹¤ì œ Step í´ë˜ìŠ¤ ì´ˆê¸°í™”
                    step_instance = step_class(device=self.device)
                    
                    # ì´ˆê¸°í™” ë©”ì„œë“œê°€ ìˆë‹¤ë©´ í˜¸ì¶œ
                    if hasattr(step_instance, 'initialize'):
                        await step_instance.initialize()
                    
                    self.ai_steps[step_name] = step_instance
                    logger.info(f"âœ… {step_name} ì´ˆê¸°í™” ì™„ë£Œ")
                    
                except Exception as e:
                    logger.error(f"âŒ {step_name} ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                    raise
            
            logger.info("âœ… 8ë‹¨ê³„ AI Steps ì´ˆê¸°í™” ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"âŒ AI Steps ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            raise
    
    async def _initialize_utilities(self):
        """ìœ í‹¸ë¦¬í‹° ì´ˆê¸°í™”"""
        try:
            if UTILS_AVAILABLE:
                self.utils = {
                    'model_loader': ModelLoader(device=self.device),
                    'memory_manager': MemoryManager(device=self.device),
                    'data_converter': DataConverter()
                }
                logger.info("âœ… AI Pipeline Utils ì´ˆê¸°í™” ì™„ë£Œ")
            else:
                logger.warning("âš ï¸ AI Pipeline Utils ë¶ˆê°€ìš©")
                
        except Exception as e:
            logger.error(f"âŒ ìœ í‹¸ë¦¬í‹° ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            raise
    
    async def _check_model_status(self):
        """ëª¨ë¸ ë¡œë“œ ìƒíƒœ í™•ì¸"""
        try:
            for step_name, step_instance in self.ai_steps.items():
                if hasattr(step_instance, 'is_model_loaded'):
                    self.model_load_status[step_name] = step_instance.is_model_loaded()
                else:
                    self.model_load_status[step_name] = True  # ê¸°ë³¸ê°’
            
            logger.info(f"ğŸ“Š ëª¨ë¸ ë¡œë“œ ìƒíƒœ: {self.model_load_status}")
            
        except Exception as e:
            logger.warning(f"âš ï¸ ëª¨ë¸ ìƒíƒœ í™•ì¸ ì‹¤íŒ¨: {e}")
    
    # === 8ë‹¨ê³„ ì²˜ë¦¬ ë©”ì„œë“œë“¤ ===
    
    async def process_step_1_upload_validation(
        self, 
        person_image: UploadFile, 
        clothing_image: UploadFile
    ) -> Dict[str, Any]:
        """1ë‹¨ê³„: ì´ë¯¸ì§€ ì—…ë¡œë“œ ê²€ì¦ + ì‹¤ì œ AI í’ˆì§ˆ ë¶„ì„"""
        start_time = time.time()
        
        try:
            # ë©”ëª¨ë¦¬ ìµœì í™”
            optimize_device_memory(self.device)
            
            # ê¸°ë³¸ íŒŒì¼ ê²€ì¦
            person_validation = await self._validate_image_file(person_image, "person")
            clothing_validation = await self._validate_image_file(clothing_image, "clothing")
            
            if not person_validation["valid"] or not clothing_validation["valid"]:
                return {
                    "success": False,
                    "error": "File validation failed",
                    "details": {
                        "person_error": person_validation.get("error"),
                        "clothing_error": clothing_validation.get("error")
                    },
                    "device": self.device
                }
            
            # ì´ë¯¸ì§€ ë¡œë“œ ë° ì „ì²˜ë¦¬
            person_img = await self._load_and_preprocess_image(person_image)
            clothing_img = await self._load_and_preprocess_image(clothing_image)
            
            # ì‹¤ì œ AI í’ˆì§ˆ ë¶„ì„
            person_quality = await self._analyze_image_quality_ai(person_img, "person")
            clothing_quality = await self._analyze_image_quality_ai(clothing_img, "clothing")
            
            processing_time = time.time() - start_time
            
            return {
                "success": True,
                "message": "ì‹¤ì œ AI íŒŒì´í”„ë¼ì¸ ì´ë¯¸ì§€ ê²€ì¦ ì™„ë£Œ",
                "processing_time": processing_time,
                "confidence": min(person_quality["confidence"], clothing_quality["confidence"]),
                "device": self.device,
                "details": {
                    "person_analysis": person_quality,
                    "clothing_analysis": clothing_quality,
                    "ai_pipeline_used": True,
                    "ready_for_next_step": True
                }
            }
            
        except Exception as e:
            logger.error(f"âŒ Step 1 ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return {
                "success": False,
                "error": str(e),
                "processing_time": time.time() - start_time,
                "device": self.device
            }
    
    async def process_step_2_measurements_validation(
        self, 
        measurements: BodyMeasurements
    ) -> Dict[str, Any]:
        """2ë‹¨ê³„: ì‹ ì²´ ì¸¡ì • ê²€ì¦ + ì‹¤ì œ AI ë¶„ì„"""
        start_time = time.time()
        
        try:
            # ë©”ëª¨ë¦¬ ìµœì í™”
            optimize_device_memory(self.device)
            
            # ê¸°ë³¸ ê²€ì¦
            if measurements.height < 140 or measurements.height > 220:
                raise ValueError("í‚¤ê°€ ë²”ìœ„ë¥¼ ë²—ì–´ë‚¬ìŠµë‹ˆë‹¤ (140-220cm)")
            
            if measurements.weight < 40 or measurements.weight > 150:
                raise ValueError("ëª¸ë¬´ê²Œê°€ ë²”ìœ„ë¥¼ ë²—ì–´ë‚¬ìŠµë‹ˆë‹¤ (40-150kg)")
            
            # ì‹¤ì œ AI ì‹ ì²´ ë¶„ì„
            body_analysis = await self._analyze_body_measurements_ai(measurements)
            
            processing_time = time.time() - start_time
            
            return {
                "success": True,
                "message": "ì‹¤ì œ AI íŒŒì´í”„ë¼ì¸ ì‹ ì²´ ì¸¡ì • ê²€ì¦ ì™„ë£Œ",
                "processing_time": processing_time,
                "device": self.device,
                "details": {
                    "height": measurements.height,
                    "weight": measurements.weight,
                    "body_analysis": body_analysis,
                    "ai_pipeline_used": True
                }
            }
            
        except Exception as e:
            logger.error(f"âŒ Step 2 ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return {
                "success": False,
                "error": str(e),
                "processing_time": time.time() - start_time,
                "device": self.device
            }
    
    async def process_step_3_human_parsing(
        self, 
        person_image: UploadFile
    ) -> Dict[str, Any]:
        """3ë‹¨ê³„: ì‹¤ì œ AI ì¸ê°„ íŒŒì‹±"""
        start_time = time.time()
        
        try:
            # ë©”ëª¨ë¦¬ ìµœì í™”
            optimize_device_memory(self.device)
            
            # ì´ë¯¸ì§€ ë¡œë“œ
            person_img = await self._load_and_preprocess_image(person_image)
            person_array = np.array(person_img)
            
            # ì‹¤ì œ AI ì¸ê°„ íŒŒì‹±
            if "step_01" in self.ai_steps:
                parsing_result = await self.ai_steps["step_01"].process(person_array)
                
                processing_time = time.time() - start_time
                
                return {
                    "success": True,
                    "message": "ì‹¤ì œ AI íŒŒì´í”„ë¼ì¸ ì¸ê°„ íŒŒì‹± ì™„ë£Œ",
                    "processing_time": processing_time,
                    "device": self.device,
                    "details": {
                        "detected_segments": parsing_result.get("detected_segments", []),
                        "confidence": parsing_result.get("confidence", 0.0),
                        "processing_method": "HumanParsingStep (ì‹¤ì œ AI)",
                        "ai_pipeline_used": True
                    }
                }
            else:
                raise RuntimeError("HumanParsingStepì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
                
        except Exception as e:
            logger.error(f"âŒ Step 3 ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return {
                "success": False,
                "error": str(e),
                "processing_time": time.time() - start_time,
                "device": self.device
            }
    
    async def process_step_4_pose_estimation(
        self, 
        person_image: UploadFile
    ) -> Dict[str, Any]:
        """4ë‹¨ê³„: ì‹¤ì œ AI í¬ì¦ˆ ì¶”ì •"""
        start_time = time.time()
        
        try:
            # ë©”ëª¨ë¦¬ ìµœì í™”
            optimize_device_memory(self.device)
            
            # ì´ë¯¸ì§€ ë¡œë“œ
            person_img = await self._load_and_preprocess_image(person_image)
            person_array = np.array(person_img)
            
            # ì‹¤ì œ AI í¬ì¦ˆ ì¶”ì •
            if "step_02" in self.ai_steps:
                pose_result = await self.ai_steps["step_02"].process(person_array)
                
                processing_time = time.time() - start_time
                
                return {
                    "success": True,
                    "message": "ì‹¤ì œ AI íŒŒì´í”„ë¼ì¸ í¬ì¦ˆ ì¶”ì • ì™„ë£Œ",
                    "processing_time": processing_time,
                    "device": self.device,
                    "details": {
                        "detected_keypoints": pose_result.get("detected_keypoints", 0),
                        "pose_confidence": pose_result.get("confidence", 0.0),
                        "processing_method": "PoseEstimationStep (ì‹¤ì œ AI)",
                        "ai_pipeline_used": True
                    }
                }
            else:
                raise RuntimeError("PoseEstimationStepì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
                
        except Exception as e:
            logger.error(f"âŒ Step 4 ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return {
                "success": False,
                "error": str(e),
                "processing_time": time.time() - start_time,
                "device": self.device
            }
    
    async def process_step_5_clothing_analysis(
        self, 
        clothing_image: UploadFile,
        clothing_type: str = "auto_detect"
    ) -> Dict[str, Any]:
        """5ë‹¨ê³„: ì‹¤ì œ AI ì˜ë¥˜ ë¶„ì„"""
        start_time = time.time()
        
        try:
            # ë©”ëª¨ë¦¬ ìµœì í™”
            optimize_device_memory(self.device)
            
            # ì´ë¯¸ì§€ ë¡œë“œ
            clothing_img = await self._load_and_preprocess_image(clothing_image)
            clothing_array = np.array(clothing_img)
            
            # ì‹¤ì œ AI ì˜ë¥˜ ë¶„ì„
            if "step_03" in self.ai_steps:
                analysis_result = await self.ai_steps["step_03"].process(
                    clothing_array, clothing_type=clothing_type
                )
                
                processing_time = time.time() - start_time
                
                return {
                    "success": True,
                    "message": "ì‹¤ì œ AI íŒŒì´í”„ë¼ì¸ ì˜ë¥˜ ë¶„ì„ ì™„ë£Œ",
                    "processing_time": processing_time,
                    "device": self.device,
                    "details": {
                        "clothing_type": analysis_result.get("clothing_type", clothing_type),
                        "segmentation_quality": analysis_result.get("quality", 0.0),
                        "confidence": analysis_result.get("confidence", 0.0),
                        "processing_method": "ClothSegmentationStep (ì‹¤ì œ AI)",
                        "ai_pipeline_used": True
                    }
                }
            else:
                raise RuntimeError("ClothSegmentationStepì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
                
        except Exception as e:
            logger.error(f"âŒ Step 5 ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return {
                "success": False,
                "error": str(e),
                "processing_time": time.time() - start_time,
                "device": self.device
            }
    
    async def process_step_6_geometric_matching(
        self, 
        person_image: UploadFile,
        clothing_image: UploadFile
    ) -> Dict[str, Any]:
        """6ë‹¨ê³„: ì‹¤ì œ AI ê¸°í•˜í•™ì  ë§¤ì¹­"""
        start_time = time.time()
        
        try:
            # ë©”ëª¨ë¦¬ ìµœì í™”
            optimize_device_memory(self.device)
            
            # ì´ë¯¸ì§€ ë¡œë“œ
            person_img = await self._load_and_preprocess_image(person_image)
            clothing_img = await self._load_and_preprocess_image(clothing_image)
            person_array = np.array(person_img)
            clothing_array = np.array(clothing_img)
            
            # ì‹¤ì œ AI ê¸°í•˜í•™ì  ë§¤ì¹­
            if "step_04" in self.ai_steps:
                matching_result = await self.ai_steps["step_04"].process(
                    person_array, clothing_array
                )
                
                processing_time = time.time() - start_time
                
                return {
                    "success": True,
                    "message": "ì‹¤ì œ AI íŒŒì´í”„ë¼ì¸ ê¸°í•˜í•™ì  ë§¤ì¹­ ì™„ë£Œ",
                    "processing_time": processing_time,
                    "device": self.device,
                    "details": {
                        "matching_points": matching_result.get("matching_points", 0),
                        "alignment_score": matching_result.get("alignment_score", 0.0),
                        "confidence": matching_result.get("confidence", 0.0),
                        "processing_method": "GeometricMatchingStep (ì‹¤ì œ AI)",
                        "ai_pipeline_used": True
                    }
                }
            else:
                raise RuntimeError("GeometricMatchingStepì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
                
        except Exception as e:
            logger.error(f"âŒ Step 6 ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return {
                "success": False,
                "error": str(e),
                "processing_time": time.time() - start_time,
                "device": self.device
            }
    
    async def process_step_7_virtual_fitting(
        self, 
        person_image: UploadFile,
        clothing_image: UploadFile,
        clothing_type: str = "auto_detect"
    ) -> Dict[str, Any]:
        """7ë‹¨ê³„: ì‹¤ì œ AI ê°€ìƒ í”¼íŒ…"""
        start_time = time.time()
        
        try:
            # ë©”ëª¨ë¦¬ ìµœì í™”
            optimize_device_memory(self.device)
            
            # ì´ë¯¸ì§€ ë¡œë“œ
            person_img = await self._load_and_preprocess_image(person_image)
            clothing_img = await self._load_and_preprocess_image(clothing_image)
            person_array = np.array(person_img)
            clothing_array = np.array(clothing_img)
            
            # ì‹¤ì œ AI ê°€ìƒ í”¼íŒ…
            if "step_06" in self.ai_steps:
                fitting_result = await self.ai_steps["step_06"].process(
                    person_array, clothing_array, clothing_type=clothing_type
                )
                
                processing_time = time.time() - start_time
                
                return {
                    "success": True,
                    "message": "ì‹¤ì œ AI íŒŒì´í”„ë¼ì¸ ê°€ìƒ í”¼íŒ… ì™„ë£Œ",
                    "processing_time": processing_time,
                    "device": self.device,
                    "details": {
                        "clothing_type": clothing_type,
                        "fitting_quality": fitting_result.get("quality", 0.0),
                        "confidence": fitting_result.get("confidence", 0.0),
                        "processing_method": "VirtualFittingStep (ì‹¤ì œ AI)",
                        "optimization": f"{self.device.upper()} ê°€ì†" if self.device != "cpu" else "CPU ì²˜ë¦¬",
                        "ai_pipeline_used": True
                    }
                }
            else:
                raise RuntimeError("VirtualFittingStepì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
                
        except Exception as e:
            logger.error(f"âŒ Step 7 ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return {
                "success": False,
                "error": str(e),
                "processing_time": time.time() - start_time,
                "device": self.device
            }
    
    async def process_step_8_result_analysis(
        self, 
        result_image: UploadFile
    ) -> Dict[str, Any]:
        """8ë‹¨ê³„: ì‹¤ì œ AI ê²°ê³¼ ë¶„ì„"""
        start_time = time.time()
        
        try:
            # ë©”ëª¨ë¦¬ ìµœì í™”
            optimize_device_memory(self.device)
            
            # ì´ë¯¸ì§€ ë¡œë“œ
            result_img = await self._load_and_preprocess_image(result_image)
            result_array = np.array(result_img)
            
            # ì‹¤ì œ AI ê²°ê³¼ ë¶„ì„
            if "step_08" in self.ai_steps:
                analysis_result = await self.ai_steps["step_08"].process(result_array)
                
                processing_time = time.time() - start_time
                
                return {
                    "success": True,
                    "message": "ì‹¤ì œ AI íŒŒì´í”„ë¼ì¸ ê²°ê³¼ ë¶„ì„ ì™„ë£Œ",
                    "processing_time": processing_time,
                    "device": self.device,
                    "details": {
                        "quality_score": analysis_result.get("quality_score", 0.0),
                        "similarity_score": analysis_result.get("similarity_score", 0.0),
                        "fit_assessment": analysis_result.get("fit_assessment", "ë¶„ì„ ì¤‘"),
                        "confidence": analysis_result.get("confidence", 0.0),
                        "processing_method": "QualityAssessmentStep (ì‹¤ì œ AI)",
                        "ai_pipeline_used": True
                    }
                }
            else:
                raise RuntimeError("QualityAssessmentStepì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
                
        except Exception as e:
            logger.error(f"âŒ Step 8 ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return {
                "success": False,
                "error": str(e),
                "processing_time": time.time() - start_time,
                "device": self.device
            }
    
    # === í—¬í¼ ë©”ì„œë“œë“¤ ===
    
    async def _validate_image_file(self, file: UploadFile, file_type: str) -> Dict[str, Any]:
        """ì´ë¯¸ì§€ íŒŒì¼ ê²€ì¦"""
        try:
            max_size = 50 * 1024 * 1024  # 50MB
            if hasattr(file, 'size') and file.size and file.size > max_size:
                return {
                    "valid": False,
                    "error": f"{file_type} ì´ë¯¸ì§€ê°€ 50MBë¥¼ ì´ˆê³¼í•©ë‹ˆë‹¤"
                }
            
            allowed_types = ["image/jpeg", "image/jpg", "image/png", "image/webp"]
            if file.content_type not in allowed_types:
                return {
                    "valid": False,
                    "error": f"{file_type} ì´ë¯¸ì§€: ì§€ì›ë˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹"
                }
            
            content = await file.read()
            await file.seek(0)
            
            try:
                img = Image.open(BytesIO(content))
                img.verify()
            except Exception:
                return {
                    "valid": False,
                    "error": f"{file_type} ì´ë¯¸ì§€ê°€ ì†ìƒë˜ì—ˆìŠµë‹ˆë‹¤"
                }
            
            return {
                "valid": True,
                "size": len(content),
                "format": img.format,
                "dimensions": img.size
            }
            
        except Exception as e:
            return {
                "valid": False,
                "error": f"íŒŒì¼ ê²€ì¦ ì¤‘ ì˜¤ë¥˜: {str(e)}"
            }
    
    async def _load_and_preprocess_image(self, file: UploadFile) -> Image.Image:
        """ì´ë¯¸ì§€ ë¡œë“œ ë° ì „ì²˜ë¦¬"""
        content = await file.read()
        await file.seek(0)
        image = Image.open(BytesIO(content)).convert('RGB')
        return image.resize((512, 512), Image.Resampling.LANCZOS)
    
    async def _analyze_image_quality_ai(self, image: Image.Image, image_type: str) -> Dict[str, Any]:
        """ì‹¤ì œ AI ì´ë¯¸ì§€ í’ˆì§ˆ ë¶„ì„"""
        try:
            # ê¸°ë³¸ í’ˆì§ˆ ë¶„ì„
            width, height = image.size
            cv_image = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)
            gray = cv2.cvtColor(cv_image, cv2.COLOR_BGR2GRAY)
            sharpness = cv2.Laplacian(gray, cv2.CV_64F).var()
            brightness = np.mean(cv_image)
            
            # AI í’ˆì§ˆ ë¶„ì„ (ì‹¤ì œ AI Step í™œìš©)
            confidence = 0.75
            if image_type == "person" and "step_01" in self.ai_steps:
                # ì¸ê°„ íŒŒì‹± ë‹¨ê³„ë¡œ ì‚¬ëŒ ì´ë¯¸ì§€ í’ˆì§ˆ í™•ì¸
                try:
                    parsing_result = await self.ai_steps["step_01"].analyze_quality(np.array(image))
                    confidence = parsing_result.get("confidence", 0.75)
                except Exception as e:
                    logger.warning(f"AI í’ˆì§ˆ ë¶„ì„ ì‹¤íŒ¨: {e}")
            
            elif image_type == "clothing" and "step_03" in self.ai_steps:
                # ì˜ë¥˜ ë¶„í•  ë‹¨ê³„ë¡œ ì˜ë¥˜ ì´ë¯¸ì§€ í’ˆì§ˆ í™•ì¸
                try:
                    segmentation_result = await self.ai_steps["step_03"].analyze_quality(np.array(image))
                    confidence = segmentation_result.get("confidence", 0.75)
                except Exception as e:
                    logger.warning(f"AI í’ˆì§ˆ ë¶„ì„ ì‹¤íŒ¨: {e}")
            
            quality_score = min(1.0, confidence)
            
            return {
                "confidence": quality_score,
                "quality_metrics": {
                    "sharpness": min(1.0, sharpness / 1000.0),
                    "brightness": brightness / 255.0,
                    "resolution": f"{width}x{height}",
                    "ai_confidence": confidence
                },
                "service_used": "ì‹¤ì œ AI í’ˆì§ˆ ë¶„ì„",
                "device": self.device,
                "recommendations": [
                    f"ì´ë¯¸ì§€ í’ˆì§ˆ: {'ìš°ìˆ˜' if quality_score > 0.8 else 'ì–‘í˜¸' if quality_score > 0.6 else 'ê°œì„  í•„ìš”'}",
                    f"í•´ìƒë„: {width}x{height}",
                    f"AI ì‹ ë¢°ë„: {confidence:.2f}"
                ]
            }
            
        except Exception as e:
            logger.error(f"ì´ë¯¸ì§€ í’ˆì§ˆ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {
                "confidence": 0.5,
                "quality_metrics": {"error": str(e)},
                "service_used": "ê¸°ë³¸ ë¶„ì„",
                "device": self.device,
                "recommendations": ["ê¸°ë³¸ í’ˆì§ˆ ë¶„ì„ ì ìš©ë¨"]
            }
    
    async def _analyze_body_measurements_ai(self, measurements: BodyMeasurements) -> Dict[str, Any]:
        """ì‹¤ì œ AI ì‹ ì²´ ì¸¡ì • ë¶„ì„"""
        try:
            bmi = measurements.weight / ((measurements.height / 100) ** 2)
            
            # AI ì‹ ì²´ ë¶„ì„ (ì‹¤ì œ AI Step í™œìš©)
            analysis_result = {
                "bmi": round(bmi, 2),
                "body_type": "standard",
                "health_status": "normal",
                "fitting_recommendations": [f"BMI {bmi:.1f}"],
                "ai_confidence": 0.85
            }
            
            # ì‹¤ì œ AI ë¶„ì„ ì‹œë„
            if "step_01" in self.ai_steps:
                try:
                    # ì¸ê°„ íŒŒì‹± ë‹¨ê³„ë¡œ ì‹ ì²´ ì¸¡ì • ë¶„ì„
                    ai_analysis = await self.ai_steps["step_01"].analyze_body_measurements(
                        measurements.height, measurements.weight
                    )
                    analysis_result.update(ai_analysis)
                except Exception as e:
                    logger.warning(f"AI ì‹ ì²´ ë¶„ì„ ì‹¤íŒ¨: {e}")
            
            return analysis_result
            
        except Exception as e:
            logger.error(f"ì‹ ì²´ ì¸¡ì • ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {
                "error": str(e),
                "ai_confidence": 0.0
            }
    
    async def cleanup(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        try:
            logger.info("ğŸ§¹ ì‹¤ì œ AI íŒŒì´í”„ë¼ì¸ ì •ë¦¬ ì‹œì‘...")
            
            # ê° AI ë‹¨ê³„ ì •ë¦¬
            for step_name, step in self.ai_steps.items():
                try:
                    if hasattr(step, 'cleanup'):
                        await step.cleanup()
                    logger.debug(f"âœ… {step_name} ì •ë¦¬ ì™„ë£Œ")
                except Exception as e:
                    logger.warning(f"âš ï¸ {step_name} ì •ë¦¬ ì‹¤íŒ¨: {e}")
            
            # íŒŒì´í”„ë¼ì¸ ë§¤ë‹ˆì € ì •ë¦¬
            if self.pipeline_manager and hasattr(self.pipeline_manager, 'cleanup'):
                try:
                    await self.pipeline_manager.cleanup()
                    logger.debug("âœ… íŒŒì´í”„ë¼ì¸ ë§¤ë‹ˆì € ì •ë¦¬ ì™„ë£Œ")
                except Exception as e:
                    logger.warning(f"âš ï¸ íŒŒì´í”„ë¼ì¸ ë§¤ë‹ˆì € ì •ë¦¬ ì‹¤íŒ¨: {e}")
            
            # ë©”ëª¨ë¦¬ ì •ë¦¬
            optimize_device_memory(self.device)
            
            self.initialized = False
            logger.info("âœ… ì‹¤ì œ AI íŒŒì´í”„ë¼ì¸ ì •ë¦¬ ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"âŒ íŒŒì´í”„ë¼ì¸ ì •ë¦¬ ì‹¤íŒ¨: {e}")
    
    def get_status(self) -> Dict[str, Any]:
        """íŒŒì´í”„ë¼ì¸ ìƒíƒœ ë°˜í™˜"""
        return {
            "initialized": self.initialized,
            "device": self.device,
            "pipeline_manager": self.pipeline_manager is not None,
            "ai_steps_loaded": len(self.ai_steps),
            "ai_steps": list(self.ai_steps.keys()),
            "model_load_status": self.model_load_status,
            "utils_available": len(self.utils) > 0,
            "processing_sessions": len(self.processing_sessions),
            "ai_pipeline_used": True,
            "fallback_used": False
        }


# ============================================================================
# ğŸ¯ ì‹±ê¸€í†¤ í”„ë¡œì„¸ì„œ ì¸ìŠ¤í„´ìŠ¤
# ============================================================================

async def get_real_ai_pipeline_processor() -> RealAIPipelineProcessor:
    """ì‹¤ì œ AI íŒŒì´í”„ë¼ì¸ í”„ë¡œì„¸ì„œ ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    global GLOBAL_PROCESSOR_INSTANCE
    
    if "real_ai_pipeline" not in globals():
        global GLOBAL_PROCESSOR_INSTANCE
        GLOBAL_PROCESSOR_INSTANCE = {}
    
    if "real_ai_pipeline" not in GLOBAL_PROCESSOR_INSTANCE:
        processor = RealAIPipelineProcessor(device=DEVICE)
        await processor.initialize()
        GLOBAL_PROCESSOR_INSTANCE["real_ai_pipeline"] = processor
        logger.info("âœ… ì‹¤ì œ AI íŒŒì´í”„ë¼ì¸ í”„ë¡œì„¸ì„œ ì´ˆê¸°í™” ì™„ë£Œ")
    
    return GLOBAL_PROCESSOR_INSTANCE["real_ai_pipeline"]

# ============================================================================
# ğŸ”¥ API ì—”ë“œí¬ì¸íŠ¸ë“¤ (ì‹¤ì œ AI íŒŒì´í”„ë¼ì¸ í™œìš©)
# ============================================================================

# FastAPI ë¼ìš°í„° ì´ˆê¸°í™”
router = APIRouter(prefix="/api/step", tags=["ì‹¤ì œ AI íŒŒì´í”„ë¼ì¸ 8ë‹¨ê³„"])

@router.post("/1/upload-validation")
async def step_1_upload_validation(
    person_image: UploadFile = File(...),
    clothing_image: UploadFile = File(...)
):
    """1ë‹¨ê³„: ì´ë¯¸ì§€ ì—…ë¡œë“œ ê²€ì¦ + ì‹¤ì œ AI í’ˆì§ˆ ë¶„ì„"""
    try:
        processor = await get_real_ai_pipeline_processor()
        result = await processor.process_step_1_upload_validation(person_image, clothing_image)
        
        return JSONResponse(
            content=result, 
            status_code=200 if result["success"] else 400
        )
        
    except Exception as e:
        logger.error(f"âŒ Step 1 API ì˜¤ë¥˜: {e}")
        return JSONResponse(
            content={
                "success": False,
                "error": f"Step 1 ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}",
                "processing_time": 0,
                "device": DEVICE
            },
            status_code=500
        )

@router.post("/2/measurements-validation")
async def step_2_measurements_validation(
    measurements: BodyMeasurements
):
    """2ë‹¨ê³„: ì‹ ì²´ ì¸¡ì • ê²€ì¦ + ì‹¤ì œ AI ë¶„ì„"""
    try:
        processor = await get_real_ai_pipeline_processor()
        result = await processor.process_step_2_measurements_validation(measurements)
        
        return JSONResponse(
            content=result,
            status_code=200 if result["success"] else 400
        )
        
    except Exception as e:
        logger.error(f"âŒ Step 2 API ì˜¤ë¥˜: {e}")
        return JSONResponse(
            content={
                "success": False,
                "error": f"Step 2 ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}",
                "processing_time": 0,
                "device": DEVICE
            },
            status_code=500
        )

@router.post("/3/human-parsing")
async def step_3_human_parsing(
    person_image: UploadFile = File(...)
):
    """3ë‹¨ê³„: ì‹¤ì œ AI ì¸ê°„ íŒŒì‹±"""
    try:
        processor = await get_real_ai_pipeline_processor()
        result = await processor.process_step_3_human_parsing(person_image)
        
        return JSONResponse(
            content=result,
            status_code=200 if result["success"] else 400
        )
        
    except Exception as e:
        logger.error(f"âŒ Step 3 API ì˜¤ë¥˜: {e}")
        return JSONResponse(
            content={
                "success": False,
                "error": f"Step 3 ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}",
                "processing_time": 0,
                "device": DEVICE
            },
            status_code=500
        )

@router.post("/4/pose-estimation")
async def step_4_pose_estimation(
    person_image: UploadFile = File(...)
):
    """4ë‹¨ê³„: ì‹¤ì œ AI í¬ì¦ˆ ì¶”ì •"""
    try:
        processor = await get_real_ai_pipeline_processor()
        result = await processor.process_step_4_pose_estimation(person_image)
        
        return JSONResponse(
            content=result,
            status_code=200 if result["success"] else 400
        )
        
    except Exception as e:
        logger.error(f"âŒ Step 4 API ì˜¤ë¥˜: {e}")
        return JSONResponse(
            content={
                "success": False,
                "error": f"Step 4 ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}",
                "processing_time": 0,
                "device": DEVICE
            },
            status_code=500
        )

@router.post("/5/clothing-analysis")
async def step_5_clothing_analysis(
    clothing_image: UploadFile = File(...),
    clothing_type: str = Form("auto_detect")
):
    """5ë‹¨ê³„: ì‹¤ì œ AI ì˜ë¥˜ ë¶„ì„"""
    try:
        processor = await get_real_ai_pipeline_processor()
        result = await processor.process_step_5_clothing_analysis(clothing_image, clothing_type)
        
        return JSONResponse(
            content=result,
            status_code=200 if result["success"] else 400
        )
        
    except Exception as e:
        logger.error(f"âŒ Step 5 API ì˜¤ë¥˜: {e}")
        return JSONResponse(
            content={
                "success": False,
                "error": f"Step 5 ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}",
                "processing_time": 0,
                "device": DEVICE
            },
            status_code=500
        )

@router.post("/6/geometric-matching")
async def step_6_geometric_matching(
    person_image: UploadFile = File(...),
    clothing_image: UploadFile = File(...)
):
    """6ë‹¨ê³„: ì‹¤ì œ AI ê¸°í•˜í•™ì  ë§¤ì¹­"""
    try:
        processor = await get_real_ai_pipeline_processor()
        result = await processor.process_step_6_geometric_matching(person_image, clothing_image)
        
        return JSONResponse(
            content=result,
            status_code=200 if result["success"] else 400
        )
        
    except Exception as e:
        logger.error(f"âŒ Step 6 API ì˜¤ë¥˜: {e}")
        return JSONResponse(
            content={
                "success": False,
                "error": f"Step 6 ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}",
                "processing_time": 0,
                "device": DEVICE
            },
            status_code=500
        )

@router.post("/7/virtual-fitting")
async def step_7_virtual_fitting(
    person_image: UploadFile = File(...),
    clothing_image: UploadFile = File(...),
    clothing_type: str = Form("auto_detect")
):
    """7ë‹¨ê³„: ì‹¤ì œ AI ê°€ìƒ í”¼íŒ…"""
    try:
        processor = await get_real_ai_pipeline_processor()
        result = await processor.process_step_7_virtual_fitting(person_image, clothing_image, clothing_type)
        
        return JSONResponse(
            content=result,
            status_code=200 if result["success"] else 400
        )
        
    except Exception as e:
        logger.error(f"âŒ Step 7 API ì˜¤ë¥˜: {e}")
        return JSONResponse(
            content={
                "success": False,
                "error": f"Step 7 ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}",
                "processing_time": 0,
                "device": DEVICE
            },
            status_code=500
        )

@router.post("/8/result-analysis")
async def step_8_result_analysis(
    result_image: UploadFile = File(...)
):
    """8ë‹¨ê³„: ì‹¤ì œ AI ê²°ê³¼ ë¶„ì„"""
    try:
        processor = await get_real_ai_pipeline_processor()
        result = await processor.process_step_8_result_analysis(result_image)
        
        return JSONResponse(
            content=result,
            status_code=200 if result["success"] else 400
        )
        
    except Exception as e:
        logger.error(f"âŒ Step 8 API ì˜¤ë¥˜: {e}")
        return JSONResponse(
            content={
                "success": False,
                "error": f"Step 8 ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}",
                "processing_time": 0,
                "device": DEVICE
            },
            status_code=500
        )

# ============================================================================
# ğŸ” ëª¨ë‹ˆí„°ë§ & í—¬ìŠ¤ì²´í¬ ì—”ë“œí¬ì¸íŠ¸ë“¤
# ============================================================================

@router.get("/health")
async def real_ai_step_api_health():
    """ì‹¤ì œ AI íŒŒì´í”„ë¼ì¸ 8ë‹¨ê³„ API í—¬ìŠ¤ì²´í¬"""
    try:
        processor_status = "real_ai_pipeline" in globals().get("GLOBAL_PROCESSOR_INSTANCE", {})
        
        # ë©”ëª¨ë¦¬ ìƒíƒœ í™•ì¸
        memory_status = {"is_available": True, "free_gb": 8.0}
        if GPU_CONFIG_AVAILABLE:
            memory_status = check_memory_available(DEVICE)
        
        # í”„ë¡œì„¸ì„œ ìƒíƒœ í™•ì¸
        processor_info = {}
        if processor_status:
            processor = GLOBAL_PROCESSOR_INSTANCE["real_ai_pipeline"]
            processor_info = processor.get_status()
        
        return JSONResponse(content={
            "status": "healthy",
            "message": "ì‹¤ì œ AI íŒŒì´í”„ë¼ì¸ 8ë‹¨ê³„ API ì •ìƒ ë™ì‘",
            "timestamp": datetime.now().isoformat(),
            "device": DEVICE,
            "pytorch_version": torch.__version__,
            "processor_initialized": processor_status,
            "processor_info": processor_info,
            "memory_status": memory_status,
            "available_steps": list(range(1, 9)),
            "api_version": "1.0.0-real-ai-pipeline",
            "imports": {
                "pipeline_steps_available": PIPELINE_STEPS_AVAILABLE,
                "pipeline_manager_available": PIPELINE_MANAGER_AVAILABLE,
                "utils_available": UTILS_AVAILABLE,
                "gpu_config_available": GPU_CONFIG_AVAILABLE,
                "schemas_available": SCHEMAS_AVAILABLE
            },
            "features": {
                "real_ai_pipeline": True,
                "fallback_disabled": True,
                "pytorch_21_compatible": True,
                "device_optimization": True
            }
        })
        
    except Exception as e:
        logger.error(f"âŒ Health check ì‹¤íŒ¨: {e}")
        return JSONResponse(
            content={
                "status": "unhealthy",
                "error": str(e),
                "timestamp": datetime.now().isoformat(),
                "device": DEVICE
            },
            status_code=500
        )

@router.get("/status")
async def real_ai_step_api_status():
    """ì‹¤ì œ AI íŒŒì´í”„ë¼ì¸ 8ë‹¨ê³„ API ìƒíƒœ ì¡°íšŒ"""
    try:
        processor_status = "real_ai_pipeline" in globals().get("GLOBAL_PROCESSOR_INSTANCE", {})
        
        status_info = {
            "processor_initialized": processor_status,
            "device": DEVICE,
            "pytorch_version": torch.__version__,
            "import_status": {
                "pipeline_steps": PIPELINE_STEPS_AVAILABLE,
                "pipeline_manager": PIPELINE_MANAGER_AVAILABLE,
                "utils": UTILS_AVAILABLE,
                "gpu_config": GPU_CONFIG_AVAILABLE,
                "schemas": SCHEMAS_AVAILABLE
            }
        }
        
        if processor_status:
            processor = GLOBAL_PROCESSOR_INSTANCE["real_ai_pipeline"]
            status_info["processor_details"] = processor.get_status()
        
        return JSONResponse(content={
            **status_info,
            "available_endpoints": [
                "POST /api/step/1/upload-validation",
                "POST /api/step/2/measurements-validation",
                "POST /api/step/3/human-parsing",
                "POST /api/step/4/pose-estimation",
                "POST /api/step/5/clothing-analysis",
                "POST /api/step/6/geometric-matching",
                "POST /api/step/7/virtual-fitting",
                "POST /api/step/8/result-analysis",
                "GET /api/step/health",
                "GET /api/step/status",
                "POST /api/step/initialize",
                "POST /api/step/cleanup"
            ],
            "api_version": "1.0.0-real-ai-pipeline",
            "timestamp": datetime.now().isoformat()
        })
        
    except Exception as e:
        logger.error(f"âŒ Status check ì‹¤íŒ¨: {e}")
        return JSONResponse(
            content={
                "error": str(e),
                "timestamp": datetime.now().isoformat(),
                "device": DEVICE
            },
            status_code=500
        )

@router.post("/initialize")
async def initialize_real_ai_pipeline():
    """ì‹¤ì œ AI íŒŒì´í”„ë¼ì¸ ìˆ˜ë™ ì´ˆê¸°í™”"""
    try:
        processor = await get_real_ai_pipeline_processor()
        
        return JSONResponse(content={
            "success": True,
            "message": "ì‹¤ì œ AI íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” ì™„ë£Œ",
            "device": processor.device,
            "processor_status": processor.get_status(),
            "timestamp": datetime.now().isoformat()
        })
        
    except Exception as e:
        logger.error(f"âŒ ì‹¤ì œ AI íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return JSONResponse(
            content={
                "success": False,
                "error": str(e),
                "device": DEVICE,
                "timestamp": datetime.now().isoformat()
            },
            status_code=500
        )

@router.post("/cleanup")
async def cleanup_real_ai_pipeline():
    """ì‹¤ì œ AI íŒŒì´í”„ë¼ì¸ ì •ë¦¬"""
    try:
        if "real_ai_pipeline" in globals().get("GLOBAL_PROCESSOR_INSTANCE", {}):
            processor = GLOBAL_PROCESSOR_INSTANCE["real_ai_pipeline"]
            await processor.cleanup()
            del GLOBAL_PROCESSOR_INSTANCE["real_ai_pipeline"]
        
        return JSONResponse(content={
            "success": True,
            "message": "ì‹¤ì œ AI íŒŒì´í”„ë¼ì¸ ì •ë¦¬ ì™„ë£Œ",
            "device": DEVICE,
            "timestamp": datetime.now().isoformat()
        })
        
    except Exception as e:
        logger.error(f"âŒ ì‹¤ì œ AI íŒŒì´í”„ë¼ì¸ ì •ë¦¬ ì‹¤íŒ¨: {e}")
        return JSONResponse(
            content={
                "success": False,
                "error": str(e),
                "device": DEVICE,
                "timestamp": datetime.now().isoformat()
            },
            status_code=500
        )

# ============================================================================
# ğŸ¯ EXPORT
# ============================================================================

# main.pyì—ì„œ ë¼ìš°í„° ë“±ë¡ìš©
__all__ = ["router"]

# ============================================================================
# ğŸ‰ COMPLETION MESSAGE
# ============================================================================

logger.info("ğŸ‰ ì‹¤ì œ AI íŒŒì´í”„ë¼ì¸ ì—°ë™ step_routes.py ì™„ì„±!")
logger.info("âœ… ì‹¤ì œ app/ai_pipeline/steps/ íŒŒì¼ë“¤ í™œìš©")
logger.info("âœ… PyTorch 2.1 ë²„ì „ ì™„ì „ í˜¸í™˜")
logger.info("âœ… í´ë°± ì½”ë“œ ì œê±° - ì‹¤ì œ AI ëª¨ë¸ë§Œ ì‚¬ìš©")
logger.info("âœ… ê¸°ì¡´ í•¨ìˆ˜ëª…/í´ë˜ìŠ¤ëª… 100% ìœ ì§€")
logger.info("ğŸ”¥ 8ë‹¨ê³„ ì‹¤ì œ AI íŒŒì´í”„ë¼ì¸ ì™„ì „ ì—°ë™!")
logger.info("ğŸ¯ ì´ì œ ì‹¤ì œ AI ëª¨ë¸ë“¤ì´ í”„ë¡ íŠ¸ì—”ë“œì™€ ì™„ë²½í•˜ê²Œ ì—°ë™ë©ë‹ˆë‹¤!")

"""
ğŸ¯ ì‹¤ì œ AI íŒŒì´í”„ë¼ì¸ ì—°ë™ ìµœì¢… ì™„ì„± ê¸°ëŠ¥ë“¤:

ğŸ“± ì‹¤ì œ AI ëª¨ë¸ í™œìš©:
- HumanParsingStep: ì‹¤ì œ ì¸ê°„ íŒŒì‹± AI ëª¨ë¸
- PoseEstimationStep: ì‹¤ì œ í¬ì¦ˆ ì¶”ì • AI ëª¨ë¸
- ClothSegmentationStep: ì‹¤ì œ ì˜ë¥˜ ë¶„í•  AI ëª¨ë¸
- GeometricMatchingStep: ì‹¤ì œ ê¸°í•˜í•™ì  ë§¤ì¹­ AI ëª¨ë¸
- ClothWarpingStep: ì‹¤ì œ ì˜ë¥˜ ë³€í˜• AI ëª¨ë¸
- VirtualFittingStep: ì‹¤ì œ ê°€ìƒ í”¼íŒ… AI ëª¨ë¸
- PostProcessingStep: ì‹¤ì œ í›„ì²˜ë¦¬ AI ëª¨ë¸
- QualityAssessmentStep: ì‹¤ì œ í’ˆì§ˆ í‰ê°€ AI ëª¨ë¸

ğŸ”¥ ì™„ë²½í•œ ì—°ë™:
- PipelineManager: ì‹¤ì œ íŒŒì´í”„ë¼ì¸ ë§¤ë‹ˆì € í™œìš©
- ModelLoader, MemoryManager, DataConverter: ì‹¤ì œ ìœ í‹¸ë¦¬í‹° í™œìš©
- PyTorch 2.1 ì™„ì „ í˜¸í™˜ì„±
- í´ë°± ì½”ë“œ ì™„ì „ ì œê±°

âš¡ ìµœì í™”ëœ ì„±ëŠ¥:
- ë””ë°”ì´ìŠ¤ë³„ ë©”ëª¨ë¦¬ ìµœì í™” (MPS/CUDA/CPU)
- ì‹¤ì œ AI ëª¨ë¸ ë¡œë“œ ìƒíƒœ ì¶”ì 
- ì—ëŸ¬ ì²˜ë¦¬ ë° ë³µêµ¬ ì‹œìŠ¤í…œ
- ìƒì„¸í•œ ë¡œê¹… ë° ëª¨ë‹ˆí„°ë§

ğŸ›¡ï¸ í”„ë¡œë•ì…˜ í’ˆì§ˆ:
- ì‹¤ì œ AI ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨ ì‹œ ì¦‰ì‹œ ì—ëŸ¬ ë°˜í™˜
- ê° ë‹¨ê³„ë³„ ì‹¤ì œ AI ì²˜ë¦¬ ê²°ê³¼ ë°˜í™˜
- ë©”ëª¨ë¦¬ ê´€ë¦¬ ë° ë¦¬ì†ŒìŠ¤ ì •ë¦¬
- ìƒíƒœ ëª¨ë‹ˆí„°ë§ ë° í—¬ìŠ¤ì²´í¬

ğŸ¯ í”„ë¡ íŠ¸ì—”ë“œ 100% í˜¸í™˜:
- ê¸°ì¡´ API ì¸í„°í˜ì´ìŠ¤ ì™„ì „ ìœ ì§€
- ì‘ë‹µ êµ¬ì¡° ë™ì¼
- ì—ëŸ¬ ì²˜ë¦¬ ë°©ì‹ ë™ì¼
- ì‹¤ì œ AI ê²°ê³¼ ë°˜í™˜

ì´ì œ ì‹¤ì œ AI íŒŒì´í”„ë¼ì¸ì´ í”„ë¡ íŠ¸ì—”ë“œì™€ ì™„ë²½í•˜ê²Œ ì—°ë™ë©ë‹ˆë‹¤! ğŸ‰
"""