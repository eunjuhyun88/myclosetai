"""
ğŸ”¥ MyCloset AI ì»¤ìŠ¤í…€ ì˜ˆì™¸ í´ë˜ìŠ¤ ì •ì˜
Central Hub DI Container v7.0 ê¸°ë°˜ êµ¬ì²´ì  ì˜ˆì™¸ ì²˜ë¦¬
ëª©ì—… ë°ì´í„° ì§„ë‹¨ ë° í’ˆì§ˆ ê´€ë¦¬ ì‹œìŠ¤í…œ í¬í•¨
"""

import traceback
import threading
import json
import logging
from datetime import datetime
from typing import Dict, Any, Optional, List, Union
from dataclasses import dataclass, asdict
import numpy as np
import cv2


# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


@dataclass
class ErrorContext:
    """ì—ëŸ¬ ì»¨í…ìŠ¤íŠ¸ ì •ë³´"""
    step_name: str
    step_id: int
    session_id: str
    timestamp: str
    input_data_info: Dict[str, Any] = None
    model_info: Dict[str, Any] = None
    system_info: Dict[str, Any] = None
    performance_metrics: Dict[str, Any] = None


class MyClosetAIException(Exception):
    """MyCloset AI ê¸°ë³¸ ì˜ˆì™¸ í´ë˜ìŠ¤"""
    
    def __init__(self, message: str, error_code: str = None, context: dict = None):
        self.message = message
        self.error_code = error_code or self.__class__.__name__
        self.context = context or {}
        self.timestamp = datetime.now().isoformat()
        self.error_context: Optional[ErrorContext] = None
        super().__init__(self.message)
    
    def __str__(self):
        return f"[{self.error_code}] {self.message}"
    
    def to_dict(self) -> Dict[str, Any]:
        """ì˜ˆì™¸ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜"""
        result = {
            'error_code': self.error_code,
            'message': self.message,
            'context': self.context,
            'timestamp': self.timestamp,
            'exception_type': self.__class__.__name__
        }
        
        if self.error_context:
            result['error_context'] = asdict(self.error_context)
        
        return result


# ëª©ì—… ë°ì´í„° ì§„ë‹¨ ê´€ë ¨ ì˜ˆì™¸ í´ë˜ìŠ¤ë“¤
class MockDataDetectionError(MyClosetAIException):
    """ëª©ì—… ë°ì´í„° ê°ì§€ ì˜¤ë¥˜"""
    pass


class DataQualityError(MyClosetAIException):
    """ë°ì´í„° í’ˆì§ˆ ê´€ë ¨ ì˜¤ë¥˜"""
    pass


class ModelInferenceError(MyClosetAIException):
    """ëª¨ë¸ ì¶”ë¡  ê´€ë ¨ ì˜¤ë¥˜"""
    pass


class ModelLoadingError(MyClosetAIException):
    """AI ëª¨ë¸ ë¡œë”© ê´€ë ¨ ì˜¤ë¥˜"""
    pass


class ImageProcessingError(MyClosetAIException):
    """ì´ë¯¸ì§€ ì²˜ë¦¬ ê´€ë ¨ ì˜¤ë¥˜"""
    pass


class SessionError(MyClosetAIException):
    """ì„¸ì…˜ ê´€ë¦¬ ê´€ë ¨ ì˜¤ë¥˜"""
    pass


class DependencyInjectionError(MyClosetAIException):
    """ì˜ì¡´ì„± ì£¼ì… ê´€ë ¨ ì˜¤ë¥˜"""
    pass


class APIResponseError(MyClosetAIException):
    """API ì‘ë‹µ ìƒì„± ê´€ë ¨ ì˜¤ë¥˜"""
    pass


class VirtualFittingError(MyClosetAIException):
    """ê°€ìƒ í”¼íŒ… ì²˜ë¦¬ ê´€ë ¨ ì˜¤ë¥˜"""
    pass


class DataValidationError(MyClosetAIException):
    """ë°ì´í„° ê²€ì¦ ê´€ë ¨ ì˜¤ë¥˜"""
    pass


class MemoryError(MyClosetAIException):
    """ë©”ëª¨ë¦¬ ê´€ë ¨ ì˜¤ë¥˜"""
    pass


class FileOperationError(MyClosetAIException):
    """íŒŒì¼ ì‘ì—… ê´€ë ¨ ì˜¤ë¥˜"""
    pass


class NetworkError(MyClosetAIException):
    """ë„¤íŠ¸ì›Œí¬ ê´€ë ¨ ì˜¤ë¥˜"""
    pass


class ConfigurationError(MyClosetAIException):
    """ì„¤ì • ê´€ë ¨ ì˜¤ë¥˜"""
    pass


class AuthenticationError(MyClosetAIException):
    """ì¸ì¦ ê´€ë ¨ ì˜¤ë¥˜"""
    pass


class RateLimitError(MyClosetAIException):
    """ì†ë„ ì œí•œ ê´€ë ¨ ì˜¤ë¥˜"""
    pass


class TimeoutError(MyClosetAIException):
    """íƒ€ì„ì•„ì›ƒ ê´€ë ¨ ì˜¤ë¥˜"""
    pass


class DatabaseError(MyClosetAIException):
    """ë°ì´í„°ë² ì´ìŠ¤ ê´€ë ¨ ì˜¤ë¥˜"""
    pass


class CacheError(MyClosetAIException):
    """ìºì‹œ ê´€ë ¨ ì˜¤ë¥˜"""
    pass


class WebSocketError(MyClosetAIException):
    """WebSocket ê´€ë ¨ ì˜¤ë¥˜"""
    pass


class PipelineError(MyClosetAIException):
    """íŒŒì´í”„ë¼ì¸ ì²˜ë¦¬ ê´€ë ¨ ì˜¤ë¥˜"""
    pass


class QualityAssessmentError(MyClosetAIException):
    """í’ˆì§ˆ í‰ê°€ ê´€ë ¨ ì˜¤ë¥˜"""
    pass


class GeometricMatchingError(MyClosetAIException):
    """ê¸°í•˜í•™ì  ë§¤ì¹­ ê´€ë ¨ ì˜¤ë¥˜"""
    pass


class PoseEstimationError(MyClosetAIException):
    """í¬ì¦ˆ ì¶”ì • ê´€ë ¨ ì˜¤ë¥˜"""
    pass


class HumanParsingError(MyClosetAIException):
    """ì¸ê°„ íŒŒì‹± ê´€ë ¨ ì˜¤ë¥˜"""
    pass


class ClothingAnalysisError(MyClosetAIException):
    """ì˜ë¥˜ ë¶„ì„ ê´€ë ¨ ì˜¤ë¥˜"""
    pass


class MeasurementValidationError(MyClosetAIException):
    """ì¸¡ì •ê°’ ê²€ì¦ ê´€ë ¨ ì˜¤ë¥˜"""
    pass


class UploadValidationError(MyClosetAIException):
    """ì—…ë¡œë“œ ê²€ì¦ ê´€ë ¨ ì˜¤ë¥˜"""
    pass


class ResultAnalysisError(MyClosetAIException):
    """ê²°ê³¼ ë¶„ì„ ê´€ë ¨ ì˜¤ë¥˜"""
    pass


class MockDataDetector:
    """ëª©ì—… ë°ì´í„° ê°ì§€ ë° ì§„ë‹¨ ì‹œìŠ¤í…œ"""
    
    def __init__(self):
        self.mock_patterns = {
            'image': {
                'uniform_color': self._detect_uniform_color,
                'test_pattern': self._detect_test_pattern,
                'placeholder': self._detect_placeholder_image,
                'default_size': self._detect_default_size
            },
            'text': {
                'placeholder': self._detect_placeholder_text,
                'lorem_ipsum': self._detect_lorem_ipsum,
                'default_values': self._detect_default_values
            },
            'data': {
                'empty_arrays': self._detect_empty_arrays,
                'constant_values': self._detect_constant_values,
                'test_data': self._detect_test_data
            }
        }
    
    def detect_mock_data(self, data: Any, data_type: str = "auto") -> Dict[str, Any]:
        """ëª©ì—… ë°ì´í„° ê°ì§€"""
        detection_result = {
            'is_mock': False,
            'confidence': 0.0,
            'detected_patterns': [],
            'suggestions': [],
            'data_quality_score': 0.0
        }
        
        try:
            if data_type == "auto":
                data_type = self._infer_data_type(data)
            
            if data_type in self.mock_patterns:
                patterns = self.mock_patterns[data_type]
                detected_patterns = []
                total_confidence = 0.0
                
                for pattern_name, detector_func in patterns.items():
                    try:
                        result = detector_func(data)
                        if result['detected']:
                            detected_patterns.append({
                                'pattern': pattern_name,
                                'confidence': result['confidence'],
                                'description': result['description']
                            })
                            total_confidence += result['confidence']
                    except Exception as e:
                        logger.warning(f"íŒ¨í„´ ê°ì§€ ì¤‘ ì˜¤ë¥˜: {pattern_name} - {e}")
                
                detection_result['detected_patterns'] = detected_patterns
                detection_result['confidence'] = min(total_confidence, 1.0)
                detection_result['is_mock'] = total_confidence > 0.7
                detection_result['data_quality_score'] = 1.0 - total_confidence
                
                # ì œì•ˆì‚¬í•­ ìƒì„±
                if detection_result['is_mock']:
                    detection_result['suggestions'] = self._generate_suggestions(detected_patterns, data_type)
            
        except Exception as e:
            logger.error(f"ëª©ì—… ë°ì´í„° ê°ì§€ ì¤‘ ì˜¤ë¥˜: {e}")
            detection_result['error'] = str(e)
        
        return detection_result
    
    def _infer_data_type(self, data: Any) -> str:
        """ë°ì´í„° íƒ€ì… ì¶”ë¡ """
        if isinstance(data, (np.ndarray, list)) and len(data) > 0:
            if isinstance(data[0], (int, float)):
                return "data"
            elif isinstance(data[0], str):
                return "text"
        elif isinstance(data, str):
            return "text"
        elif isinstance(data, (np.ndarray, list)) and len(data) > 0:
            if hasattr(data[0], 'shape'):  # ì´ë¯¸ì§€ ë°°ì—´
                return "image"
        return "data"
    
    def _detect_uniform_color(self, image_data) -> Dict[str, Any]:
        """ê· ì¼í•œ ìƒ‰ìƒ ê°ì§€"""
        try:
            if isinstance(image_data, np.ndarray):
                # ì´ë¯¸ì§€ê°€ ê· ì¼í•œ ìƒ‰ìƒì¸ì§€ í™•ì¸
                std_dev = np.std(image_data)
                return {
                    'detected': std_dev < 5.0,
                    'confidence': max(0, (10.0 - std_dev) / 10.0),
                    'description': f"ê· ì¼í•œ ìƒ‰ìƒ ê°ì§€ (í‘œì¤€í¸ì°¨: {std_dev:.2f})"
                }
        except:
            pass
        return {'detected': False, 'confidence': 0.0, 'description': ''}
    
    def _detect_test_pattern(self, image_data) -> Dict[str, Any]:
        """í…ŒìŠ¤íŠ¸ íŒ¨í„´ ê°ì§€"""
        try:
            if isinstance(image_data, np.ndarray):
                # ì²´í¬ë³´ë“œ íŒ¨í„´ì´ë‚˜ í…ŒìŠ¤íŠ¸ íŒ¨í„´ ê°ì§€
                if image_data.shape[0] == image_data.shape[1] and image_data.shape[0] in [64, 128, 256]:
                    return {
                        'detected': True,
                        'confidence': 0.8,
                        'description': f"í…ŒìŠ¤íŠ¸ íŒ¨í„´ ê°ì§€ (í¬ê¸°: {image_data.shape})"
                    }
        except:
            pass
        return {'detected': False, 'confidence': 0.0, 'description': ''}
    
    def _detect_placeholder_image(self, image_data) -> Dict[str, Any]:
        """í”Œë ˆì´ìŠ¤í™€ë” ì´ë¯¸ì§€ ê°ì§€"""
        try:
            if isinstance(image_data, np.ndarray):
                # íŠ¹ì • í¬ê¸°ì˜ ê¸°ë³¸ ì´ë¯¸ì§€ íŒ¨í„´ ê°ì§€
                if image_data.shape in [(224, 224, 3), (256, 256, 3), (512, 512, 3)]:
                    return {
                        'detected': True,
                        'confidence': 0.6,
                        'description': f"í”Œë ˆì´ìŠ¤í™€ë” ì´ë¯¸ì§€ ê°ì§€ (í¬ê¸°: {image_data.shape})"
                    }
        except:
            pass
        return {'detected': False, 'confidence': 0.0, 'description': ''}
    
    def _detect_default_size(self, image_data) -> Dict[str, Any]:
        """ê¸°ë³¸ í¬ê¸° ê°ì§€"""
        try:
            if isinstance(image_data, np.ndarray):
                # ì¼ë°˜ì ì¸ ê¸°ë³¸ í¬ê¸°ë“¤
                default_sizes = [(64, 64), (128, 128), (224, 224), (256, 256), (512, 512)]
                if image_data.shape[:2] in default_sizes:
                    return {
                        'detected': True,
                        'confidence': 0.5,
                        'description': f"ê¸°ë³¸ í¬ê¸° ê°ì§€ (í¬ê¸°: {image_data.shape})"
                    }
        except:
            pass
        return {'detected': False, 'confidence': 0.0, 'description': ''}
    
    def _detect_placeholder_text(self, text_data) -> Dict[str, Any]:
        """í”Œë ˆì´ìŠ¤í™€ë” í…ìŠ¤íŠ¸ ê°ì§€"""
        placeholder_patterns = [
            'placeholder', 'test', 'sample', 'example', 'dummy', 'mock',
            'undefined', 'null', 'none', 'empty', 'temp', 'tmp'
        ]
        
        if isinstance(text_data, str):
            text_lower = text_data.lower()
            for pattern in placeholder_patterns:
                if pattern in text_lower:
                    return {
                        'detected': True,
                        'confidence': 0.8,
                        'description': f"í”Œë ˆì´ìŠ¤í™€ë” í…ìŠ¤íŠ¸ ê°ì§€: {pattern}"
                    }
        
        return {'detected': False, 'confidence': 0.0, 'description': ''}
    
    def _detect_lorem_ipsum(self, text_data) -> Dict[str, Any]:
        """Lorem ipsum í…ìŠ¤íŠ¸ ê°ì§€"""
        if isinstance(text_data, str):
            lorem_patterns = ['lorem ipsum', 'dolor sit', 'amet consectetur']
            text_lower = text_data.lower()
            for pattern in lorem_patterns:
                if pattern in text_lower:
                    return {
                        'detected': True,
                        'confidence': 0.9,
                        'description': "Lorem ipsum í…ìŠ¤íŠ¸ ê°ì§€"
                    }
        
        return {'detected': False, 'confidence': 0.0, 'description': ''}
    
    def _detect_default_values(self, text_data) -> Dict[str, Any]:
        """ê¸°ë³¸ê°’ ê°ì§€"""
        default_values = ['0', '1', 'true', 'false', 'null', 'undefined', 'none']
        
        if isinstance(text_data, str) and text_data.lower() in default_values:
            return {
                'detected': True,
                'confidence': 0.7,
                'description': f"ê¸°ë³¸ê°’ ê°ì§€: {text_data}"
            }
        
        return {'detected': False, 'confidence': 0.0, 'description': ''}
    
    def _detect_empty_arrays(self, data) -> Dict[str, Any]:
        """ë¹ˆ ë°°ì—´ ê°ì§€"""
        if isinstance(data, (list, np.ndarray)) and len(data) == 0:
            return {
                'detected': True,
                'confidence': 0.9,
                'description': "ë¹ˆ ë°°ì—´ ê°ì§€"
            }
        return {'detected': False, 'confidence': 0.0, 'description': ''}
    
    def _detect_constant_values(self, data) -> Dict[str, Any]:
        """ìƒìˆ˜ê°’ ê°ì§€"""
        try:
            if isinstance(data, (list, np.ndarray)) and len(data) > 1:
                if isinstance(data, list):
                    unique_values = set(data)
                else:
                    unique_values = set(data.flatten())
                
                if len(unique_values) == 1:
                    return {
                        'detected': True,
                        'confidence': 0.8,
                        'description': f"ìƒìˆ˜ê°’ ê°ì§€: {list(unique_values)[0]}"
                    }
        except:
            pass
        return {'detected': False, 'confidence': 0.0, 'description': ''}
    
    def _detect_test_data(self, data) -> Dict[str, Any]:
        """í…ŒìŠ¤íŠ¸ ë°ì´í„° ê°ì§€"""
        try:
            if isinstance(data, (list, np.ndarray)):
                # í…ŒìŠ¤íŠ¸ ë°ì´í„° íŒ¨í„´ë“¤
                if len(data) > 0:
                    first_item = data[0] if isinstance(data, list) else data.flatten()[0]
                    if first_item in [0, 1, -1, 255, 0.0, 1.0]:
                        return {
                            'detected': True,
                            'confidence': 0.6,
                            'description': f"í…ŒìŠ¤íŠ¸ ë°ì´í„° íŒ¨í„´ ê°ì§€: {first_item}"
                        }
        except:
            pass
        return {'detected': False, 'confidence': 0.0, 'description': ''}
    
    def _generate_suggestions(self, detected_patterns: List[Dict], data_type: str) -> List[str]:
        """ì œì•ˆì‚¬í•­ ìƒì„±"""
        suggestions = []
        
        for pattern in detected_patterns:
            if pattern['pattern'] == 'uniform_color':
                suggestions.append("ì‹¤ì œ ì´ë¯¸ì§€ ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”")
            elif pattern['pattern'] == 'test_pattern':
                suggestions.append("ì‹¤ì œ ì‚¬ìš©ì ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”")
            elif pattern['pattern'] == 'placeholder':
                suggestions.append("ì‹¤ì œ ë°ì´í„°ë¡œ êµì²´í•˜ì„¸ìš”")
            elif pattern['pattern'] == 'empty_arrays':
                suggestions.append("ë°ì´í„°ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. ì…ë ¥ì„ í™•ì¸í•˜ì„¸ìš”")
            elif pattern['pattern'] == 'constant_values':
                suggestions.append("ë‹¤ì–‘í•œ ê°’ì„ ê°€ì§„ ì‹¤ì œ ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”")
        
        return suggestions


class ErrorTracker:
    """ì—ëŸ¬ ì¶”ì  ë° í†µê³„ ê´€ë¦¬"""
    
    def __init__(self):
        self.error_counts = {}
        self.error_details = []
        self._lock = threading.RLock()
        self.max_error_details = 1000  # ìµœëŒ€ ì €ì¥í•  ì—ëŸ¬ ìƒì„¸ ì •ë³´ ìˆ˜
        self.mock_detector = MockDataDetector()
    
    def track_error(self, error: Exception, context: dict = None, step_id: int = None):
        """ì—ëŸ¬ ì¶”ì """
        with self._lock:
            error_type = type(error).__name__
            self.error_counts[error_type] = self.error_counts.get(error_type, 0) + 1
            
            error_detail = {
                'timestamp': datetime.now().isoformat(),
                'error_type': error_type,
                'message': str(error),
                'context': context or {},
                'step_id': step_id
            }
            
            if isinstance(error, MyClosetAIException):
                error_detail['error_code'] = error.error_code
                error_detail['custom_context'] = error.context
                error_detail['is_custom_exception'] = True
            else:
                error_detail['is_custom_exception'] = False
            
            # ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤ ì¶”ê°€ (ìµœëŒ€ 10ì¤„)
            try:
                tb_lines = traceback.format_exc().split('\n')
                error_detail['stack_trace'] = tb_lines[:10]
            except:
                error_detail['stack_trace'] = []
            
            self.error_details.append(error_detail)
            
            # ìµœëŒ€ ê°œìˆ˜ ìœ ì§€
            if len(self.error_details) > self.max_error_details:
                self.error_details = self.error_details[-self.max_error_details:]
    
    def detect_mock_data_in_context(self, context: dict) -> Dict[str, Any]:
        """ì»¨í…ìŠ¤íŠ¸ì—ì„œ ëª©ì—… ë°ì´í„° ê°ì§€"""
        mock_detection_results = {}
        
        if context:
            for key, value in context.items():
                if value is not None:
                    detection_result = self.mock_detector.detect_mock_data(value)
                    if detection_result['is_mock']:
                        mock_detection_results[key] = detection_result
        
        return mock_detection_results
    
    def get_error_summary(self) -> dict:
        """ì—ëŸ¬ ìš”ì•½ ì •ë³´"""
        with self._lock:
            total_errors = sum(self.error_counts.values())
            most_common = max(self.error_counts.items(), key=lambda x: x[1]) if self.error_counts else None
            
            # ìµœê·¼ ì—ëŸ¬ë“¤ (ìµœëŒ€ 20ê°œ)
            recent_errors = self.error_details[-20:] if self.error_details else []
            
            # ì»¤ìŠ¤í…€ ì˜ˆì™¸ í†µê³„
            custom_exceptions = [e for e in self.error_details if e.get('is_custom_exception', False)]
            custom_exception_count = len(custom_exceptions)
            
            # ëª©ì—… ë°ì´í„° ê´€ë ¨ ì—ëŸ¬ í†µê³„
            mock_related_errors = [e for e in self.error_details 
                                 if 'mock' in e.get('message', '').lower() or 
                                 'test' in e.get('message', '').lower()]
            
            return {
                'total_errors': total_errors,
                'error_types': dict(self.error_counts),
                'most_common_error': most_common,
                'recent_errors': recent_errors,
                'custom_exception_count': custom_exception_count,
                'custom_exception_ratio': custom_exception_count / total_errors if total_errors > 0 else 0,
                'mock_related_errors': len(mock_related_errors),
                'tracking_started': self.error_details[0]['timestamp'] if self.error_details else None,
                'last_error': self.error_details[-1] if self.error_details else None
            }
    
    def get_errors_by_step(self, step_id: int) -> list:
        """íŠ¹ì • ë‹¨ê³„ì˜ ì—ëŸ¬ë“¤ ì¡°íšŒ"""
        with self._lock:
            return [e for e in self.error_details if e.get('step_id') == step_id]
    
    def get_errors_by_type(self, error_type: str) -> list:
        """íŠ¹ì • íƒ€ì…ì˜ ì—ëŸ¬ë“¤ ì¡°íšŒ"""
        with self._lock:
            return [e for e in self.error_details if e['error_type'] == error_type]
    
    def get_mock_data_analysis(self) -> dict:
        """ëª©ì—… ë°ì´í„° ë¶„ì„ ê²°ê³¼"""
        with self._lock:
            mock_errors = []
            for error in self.error_details:
                if 'mock' in error.get('message', '').lower():
                    mock_errors.append(error)
            
            return {
                'total_mock_errors': len(mock_errors),
                'mock_error_details': mock_errors[-10:],  # ìµœê·¼ 10ê°œ
                'mock_error_types': list(set([e['error_type'] for e in mock_errors]))
            }
    
    def clear_old_errors(self, days: int = 7):
        """ì˜¤ë˜ëœ ì—ëŸ¬ë“¤ ì •ë¦¬"""
        with self._lock:
            cutoff_date = datetime.now().timestamp() - (days * 24 * 60 * 60)
            self.error_details = [
                e for e in self.error_details 
                if datetime.fromisoformat(e['timestamp']).timestamp() > cutoff_date
            ]
    
    def reset(self):
        """ì—ëŸ¬ ì¶”ì ê¸° ì´ˆê¸°í™”"""
        with self._lock:
            self.error_counts.clear()
            self.error_details.clear()


# ì „ì—­ ì—ëŸ¬ íŠ¸ë˜ì»¤ ì¸ìŠ¤í„´ìŠ¤
error_tracker = ErrorTracker()


def track_exception(error: Exception, context: dict = None, step_id: int = None):
    """ì „ì—­ ì—ëŸ¬ íŠ¸ë˜ì»¤ì— ì˜ˆì™¸ ë“±ë¡"""
    error_tracker.track_error(error, context, step_id)


def get_error_summary() -> dict:
    """ì „ì—­ ì—ëŸ¬ ìš”ì•½ ì¡°íšŒ"""
    return error_tracker.get_error_summary()


def detect_mock_data(data: Any, data_type: str = "auto") -> Dict[str, Any]:
    """ëª©ì—… ë°ì´í„° ê°ì§€"""
    return error_tracker.mock_detector.detect_mock_data(data, data_type)


def create_exception_response(
    error: Exception, 
    step_name: str = "Unknown", 
    step_id: int = None,
    session_id: str = "unknown"
) -> dict:
    """ì˜ˆì™¸ë¥¼ API ì‘ë‹µ í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
    
    # ì—ëŸ¬ ì¶”ì 
    track_exception(error, {
        'step_name': step_name,
        'step_id': step_id,
        'session_id': session_id
    }, step_id)
    
    # ì»¤ìŠ¤í…€ ì˜ˆì™¸ì¸ ê²½ìš°
    if isinstance(error, MyClosetAIException):
        return {
            'success': False,
            'message': error.message,
            'error': error.error_code,
            'error_details': error.context,
            'step_name': step_name,
            'step_id': step_id,
            'session_id': session_id,
            'timestamp': error.timestamp,
            'exception_type': 'custom'
        }
    
    # ì¼ë°˜ ì˜ˆì™¸ì¸ ê²½ìš°
    return {
        'success': False,
        'message': f"ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {type(error).__name__}",
        'error': type(error).__name__,
        'error_details': {
            'original_message': str(error),
            'exception_type': type(error).__name__
        },
        'step_name': step_name,
        'step_id': step_id,
        'session_id': session_id,
        'timestamp': datetime.now().isoformat(),
        'exception_type': 'system'
    }


def create_mock_data_diagnosis_response(
    data: Any,
    step_name: str = "Unknown",
    step_id: int = None,
    session_id: str = "unknown"
) -> dict:
    """ëª©ì—… ë°ì´í„° ì§„ë‹¨ ì‘ë‹µ ìƒì„±"""
    
    try:
        # ëª©ì—… ë°ì´í„° ê°ì§€
        detection_result = detect_mock_data(data)
        
        # ì—ëŸ¬ ì»¨í…ìŠ¤íŠ¸ ìƒì„±
        error_context = ErrorContext(
            step_name=step_name,
            step_id=step_id,
            session_id=session_id,
            timestamp=datetime.now().isoformat(),
            input_data_info={
                'data_type': type(data).__name__,
                'data_shape': getattr(data, 'shape', None) if hasattr(data, 'shape') else None,
                'data_length': len(data) if hasattr(data, '__len__') else None
            }
        )
        
        if detection_result['is_mock']:
            # ëª©ì—… ë°ì´í„° ê°ì§€ëœ ê²½ìš°
            mock_error = MockDataDetectionError(
                message="ëª©ì—… ë°ì´í„°ê°€ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤",
                error_code="MOCK_DATA_DETECTED",
                context={
                    'detection_result': detection_result,
                    'step_name': step_name,
                    'step_id': step_id,
                    'session_id': session_id
                }
            )
            mock_error.error_context = error_context
            
            # ì—ëŸ¬ ì¶”ì 
            track_exception(mock_error, {
                'step_name': step_name,
                'step_id': step_id,
                'session_id': session_id,
                'detection_result': detection_result
            }, step_id)
            
            return {
                'success': False,
                'message': "ëª©ì—… ë°ì´í„°ê°€ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤. ì‹¤ì œ ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.",
                'error': 'MOCK_DATA_DETECTED',
                'error_details': {
                    'detection_result': detection_result,
                    'suggestions': detection_result.get('suggestions', []),
                    'data_quality_score': detection_result.get('data_quality_score', 0.0)
                },
                'step_name': step_name,
                'step_id': step_id,
                'session_id': session_id,
                'timestamp': datetime.now().isoformat(),
                'exception_type': 'mock_detection'
            }
        else:
            # ì •ìƒ ë°ì´í„°ì¸ ê²½ìš°
            return {
                'success': True,
                'message': "ë°ì´í„° í’ˆì§ˆ ê²€ì¦ ì™„ë£Œ",
                'data_quality_score': detection_result.get('data_quality_score', 1.0),
                'step_name': step_name,
                'step_id': step_id,
                'session_id': session_id,
                'timestamp': datetime.now().isoformat()
            }
    
    except Exception as e:
        logger.error(f"ëª©ì—… ë°ì´í„° ì§„ë‹¨ ì¤‘ ì˜¤ë¥˜: {e}")
        return {
            'success': False,
            'message': f"ë°ì´í„° ì§„ë‹¨ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}",
            'error': 'DIAGNOSIS_ERROR',
            'step_name': step_name,
            'step_id': step_id,
            'session_id': session_id,
            'timestamp': datetime.now().isoformat()
        }


# ì˜ˆì™¸ ë³€í™˜ í—¬í¼ í•¨ìˆ˜ë“¤
def convert_to_mycloset_exception(error: Exception, context: dict = None) -> MyClosetAIException:
    """ì¼ë°˜ ì˜ˆì™¸ë¥¼ MyCloset AI ì˜ˆì™¸ë¡œ ë³€í™˜"""
    
    if isinstance(error, MyClosetAIException):
        return error
    
    error_message = str(error)
    error_type = type(error).__name__
    
    # ì˜ˆì™¸ íƒ€ì…ë³„ ë³€í™˜
    if isinstance(error, FileNotFoundError):
        return FileOperationError(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {error_message}", "FILE_NOT_FOUND", context)
    
    elif isinstance(error, PermissionError):
        return FileOperationError(f"íŒŒì¼ ì ‘ê·¼ ê¶Œí•œì´ ì—†ìŠµë‹ˆë‹¤: {error_message}", "PERMISSION_DENIED", context)
    
    elif isinstance(error, MemoryError):
        return MemoryError(f"ë©”ëª¨ë¦¬ ë¶€ì¡±: {error_message}", "MEMORY_INSUFFICIENT", context)
    
    elif isinstance(error, ValueError):
        return DataValidationError(f"ì˜ëª»ëœ ê°’: {error_message}", "INVALID_VALUE", context)
    
    elif isinstance(error, TypeError):
        return DataValidationError(f"ì˜ëª»ëœ íƒ€ì…: {error_message}", "INVALID_TYPE", context)
    
    elif isinstance(error, ImportError):
        return ConfigurationError(f"ëª¨ë“ˆ import ì‹¤íŒ¨: {error_message}", "IMPORT_FAILED", context)
    
    elif isinstance(error, TimeoutError):
        return TimeoutError(f"íƒ€ì„ì•„ì›ƒ: {error_message}", "TIMEOUT", context)
    
    elif isinstance(error, ConnectionError):
        return NetworkError(f"ë„¤íŠ¸ì›Œí¬ ì—°ê²° ì˜¤ë¥˜: {error_message}", "CONNECTION_FAILED", context)
    
    else:
        # ê¸°ë³¸ì ìœ¼ë¡œ VirtualFittingErrorë¡œ ë³€í™˜
        return VirtualFittingError(f"ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {error_message}", "UNEXPECTED_ERROR", context)


# ì—ëŸ¬ ì½”ë“œ ìƒìˆ˜ ì •ì˜
class ErrorCodes:
    """ì—ëŸ¬ ì½”ë“œ ìƒìˆ˜"""
    
    # ëª¨ë¸ ê´€ë ¨
    MODEL_LOADING_FAILED = "MODEL_LOADING_FAILED"
    MODEL_FILE_NOT_FOUND = "MODEL_FILE_NOT_FOUND"
    MODEL_CORRUPTED = "MODEL_CORRUPTED"
    MODEL_VERSION_MISMATCH = "MODEL_VERSION_MISMATCH"
    
    # ì´ë¯¸ì§€ ì²˜ë¦¬ ê´€ë ¨
    IMAGE_PROCESSING_FAILED = "IMAGE_PROCESSING_FAILED"
    IMAGE_FORMAT_INVALID = "IMAGE_FORMAT_INVALID"
    IMAGE_SIZE_INVALID = "IMAGE_SIZE_INVALID"
    BASE64_CONVERSION_FAILED = "BASE64_CONVERSION_FAILED"
    
    # ì„¸ì…˜ ê´€ë ¨
    SESSION_NOT_FOUND = "SESSION_NOT_FOUND"
    SESSION_EXPIRED = "SESSION_EXPIRED"
    SESSION_CREATION_FAILED = "SESSION_CREATION_FAILED"
    
    # ì˜ì¡´ì„± ì£¼ì… ê´€ë ¨
    DI_CONTAINER_ERROR = "DI_CONTAINER_ERROR"
    SERVICE_NOT_FOUND = "SERVICE_NOT_FOUND"
    DEPENDENCY_CIRCULAR = "DEPENDENCY_CIRCULAR"
    
    # API ê´€ë ¨
    API_RESPONSE_ERROR = "API_RESPONSE_ERROR"
    INVALID_REQUEST = "INVALID_REQUEST"
    RATE_LIMIT_EXCEEDED = "RATE_LIMIT_EXCEEDED"
    
    # ê°€ìƒ í”¼íŒ… ê´€ë ¨
    VIRTUAL_FITTING_FAILED = "VIRTUAL_FITTING_FAILED"
    AI_INFERENCE_FAILED = "AI_INFERENCE_FAILED"
    GPU_MEMORY_INSUFFICIENT = "GPU_MEMORY_INSUFFICIENT"
    MPS_ERROR = "MPS_ERROR"
    
    # íŒŒì¼ ê´€ë ¨
    FILE_UPLOAD_FAILED = "FILE_UPLOAD_FAILED"
    FILE_DOWNLOAD_FAILED = "FILE_DOWNLOAD_FAILED"
    FILE_PERMISSION_DENIED = "FILE_PERMISSION_DENIED"
    
    # ë©”ëª¨ë¦¬ ê´€ë ¨
    MEMORY_INSUFFICIENT = "MEMORY_INSUFFICIENT"
    CACHE_FULL = "CACHE_FULL"
    
    # ë„¤íŠ¸ì›Œí¬ ê´€ë ¨
    NETWORK_TIMEOUT = "NETWORK_TIMEOUT"
    CONNECTION_REFUSED = "CONNECTION_REFUSED"
    
    # ëª©ì—… ë°ì´í„° ê´€ë ¨
    MOCK_DATA_DETECTED = "MOCK_DATA_DETECTED"
    DATA_QUALITY_ISSUE = "DATA_QUALITY_ISSUE"
    TEST_DATA_USED = "TEST_DATA_USED"
    
    # ê¸°íƒ€
    UNEXPECTED_ERROR = "UNEXPECTED_ERROR"
    CONFIGURATION_ERROR = "CONFIGURATION_ERROR"
    AUTHENTICATION_FAILED = "AUTHENTICATION_FAILED"


# ì§„ë‹¨ í—¬í¼ í•¨ìˆ˜ë“¤
def diagnose_pipeline_issue(step_name: str, step_id: int, data: Any = None) -> dict:
    """íŒŒì´í”„ë¼ì¸ ë¬¸ì œ ì§„ë‹¨"""
    diagnosis = {
        'step_name': step_name,
        'step_id': step_id,
        'timestamp': datetime.now().isoformat(),
        'issues': [],
        'recommendations': []
    }
    
    try:
        # ì—ëŸ¬ ìš”ì•½ ì¡°íšŒ
        error_summary = get_error_summary()
        
        # í•´ë‹¹ ë‹¨ê³„ì˜ ì—ëŸ¬ë“¤ ì¡°íšŒ
        step_errors = error_tracker.get_errors_by_step(step_id)
        
        if step_errors:
            diagnosis['issues'].append({
                'type': 'step_errors',
                'count': len(step_errors),
                'details': step_errors[-5:]  # ìµœê·¼ 5ê°œ ì—ëŸ¬
            })
        
        # ëª©ì—… ë°ì´í„° ë¶„ì„
        if data is not None:
            mock_analysis = error_tracker.get_mock_data_analysis()
            if mock_analysis['total_mock_errors'] > 0:
                diagnosis['issues'].append({
                    'type': 'mock_data',
                    'count': mock_analysis['total_mock_errors'],
                    'details': mock_analysis['mock_error_details']
                })
        
        # ê¶Œì¥ì‚¬í•­ ìƒì„±
        if diagnosis['issues']:
            diagnosis['recommendations'].extend([
                "ë¡œê·¸ë¥¼ í™•ì¸í•˜ì—¬ êµ¬ì²´ì ì¸ ì—ëŸ¬ ì›ì¸ì„ íŒŒì•…í•˜ì„¸ìš”",
                "ëª¨ë¸ íŒŒì¼ë“¤ì´ ì˜¬ë°”ë¥´ê²Œ ë¡œë“œë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”",
                "ì…ë ¥ ë°ì´í„°ì˜ í˜•ì‹ê³¼ í¬ê¸°ë¥¼ í™•ì¸í•˜ì„¸ìš”"
            ])
        
    except Exception as e:
        logger.error(f"ì§„ë‹¨ ì¤‘ ì˜¤ë¥˜: {e}")
        diagnosis['error'] = str(e)
    
    return diagnosis


def log_detailed_error(error: Exception, context: dict = None, step_id: int = None):
    """ìƒì„¸í•œ ì—ëŸ¬ ë¡œê¹…"""
    try:
        error_info = {
            'timestamp': datetime.now().isoformat(),
            'error_type': type(error).__name__,
            'error_message': str(error),
            'step_id': step_id,
            'context': context or {}
        }
        
        if isinstance(error, MyClosetAIException):
            error_info['error_code'] = error.error_code
            error_info['custom_context'] = error.context
        
        # ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤ ì¶”ê°€
        error_info['stack_trace'] = traceback.format_exc()
        
        # ë¡œê·¸ íŒŒì¼ì— ì €ì¥
        logger.error(f"ìƒì„¸ ì—ëŸ¬ ì •ë³´: {json.dumps(error_info, indent=2, ensure_ascii=False)}")
        
        # ì—ëŸ¬ ì¶”ì 
        track_exception(error, context, step_id)
        
    except Exception as e:
        logger.error(f"ì—ëŸ¬ ë¡œê¹… ì¤‘ ì˜¤ë¥˜: {e}")


# ëª©ì—… ë°ì´í„° ê°ì§€ ë°ì½”ë ˆì´í„°
def detect_mock_data_decorator(func):
    """í•¨ìˆ˜ ì‹¤í–‰ ì „ ëª©ì—… ë°ì´í„° ê°ì§€ ë°ì½”ë ˆì´í„°"""
    def wrapper(*args, **kwargs):
        try:
            # ì…ë ¥ ë°ì´í„°ì—ì„œ ëª©ì—… ë°ì´í„° ê°ì§€
            for arg in args:
                if arg is not None:
                    detection_result = detect_mock_data(arg)
                    if detection_result['is_mock']:
                        logger.warning(f"ëª©ì—… ë°ì´í„° ê°ì§€ë¨: {detection_result}")
                        # ì—ëŸ¬ ë°œìƒ
                        raise MockDataDetectionError(
                            message="ëª©ì—… ë°ì´í„°ê°€ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤",
                            error_code="MOCK_DATA_DETECTED",
                            context={'detection_result': detection_result}
                        )
            
            # í•¨ìˆ˜ ì‹¤í–‰
            return func(*args, **kwargs)
            
        except MockDataDetectionError:
            raise
        except Exception as e:
            # ë‹¤ë¥¸ ì—ëŸ¬ëŠ” ì›ë˜ëŒ€ë¡œ ì²˜ë¦¬
            raise e
    
    return wrapper


# ==============================================
# ğŸ”¥ BaseStepMixin ì „ìš© ì—ëŸ¬ ì²˜ë¦¬ í—¬í¼ í•¨ìˆ˜ë“¤
# ==============================================

# ==============================================
# ğŸ”¥ Virtual Fitting ì „ìš© ì—ëŸ¬ ì²˜ë¦¬ í—¬í¼ í•¨ìˆ˜ë“¤
# ==============================================

# ==============================================
# ğŸ”¥ Human Parsing ì „ìš© ì—ëŸ¬ ì²˜ë¦¬ í—¬í¼ í•¨ìˆ˜ë“¤
# ==============================================

def handle_human_parsing_model_loading_error(model_name: str, error: Exception, checkpoint_path: str = None) -> dict:
    """Human Parsing ëª¨ë¸ ë¡œë”© ì—ëŸ¬ ì²˜ë¦¬"""
    error_context = {
        'model_name': model_name,
        'error_type': type(error).__name__,
        'error_message': str(error),
        'checkpoint_path': checkpoint_path,
        'timestamp': datetime.now().isoformat()
    }
    
    # ì—ëŸ¬ ì¶”ì 
    track_exception(error, error_context)
    
    # ì—ëŸ¬ íƒ€ì…ë³„ ì²˜ë¦¬
    if isinstance(error, (OSError, IOError)):
        return {
            'success': False,
            'error': 'PARSING_MODEL_FILE_ERROR',
            'message': f"{model_name} ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {str(error)}",
            'error_context': error_context,
            'suggestion': f'{model_name} ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ì´ ì˜¬ë°”ë¥¸ ê²½ë¡œì— ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”'
        }
    elif isinstance(error, (KeyError, ValueError)):
        return {
            'success': False,
            'error': 'PARSING_MODEL_FORMAT_ERROR',
            'message': f"{model_name} ì²´í¬í¬ì¸íŠ¸ í˜•ì‹ ì˜¤ë¥˜: {str(error)}",
            'error_context': error_context,
            'suggestion': f'{model_name} ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ì´ ì†ìƒë˜ì—ˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì¬ë‹¤ìš´ë¡œë“œë¥¼ ì‹œë„í•˜ì„¸ìš”'
        }
    elif isinstance(error, RuntimeError):
        return {
            'success': False,
            'error': 'PARSING_MODEL_LOADING_ERROR',
            'message': f"{model_name} ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {str(error)}",
            'error_context': error_context,
            'suggestion': f'{model_name} ëª¨ë¸ì´ í˜„ì¬ í™˜ê²½ê³¼ í˜¸í™˜ë˜ëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”'
        }
    else:
        return {
            'success': False,
            'error': 'PARSING_MODEL_ERROR',
            'message': f"{model_name} ëª¨ë¸ ì˜¤ë¥˜: {str(error)}",
            'error_context': error_context,
            'suggestion': 'ë¡œê·¸ë¥¼ í™•ì¸í•˜ì—¬ êµ¬ì²´ì ì¸ ì˜¤ë¥˜ ì›ì¸ì„ íŒŒì•…í•˜ì„¸ìš”'
        }


def handle_human_parsing_inference_error(model_name: str, error: Exception, inference_params: dict = None) -> dict:
    """Human Parsing ì¶”ë¡  ì—ëŸ¬ ì²˜ë¦¬"""
    error_context = {
        'model_name': model_name,
        'error_type': type(error).__name__,
        'error_message': str(error),
        'inference_params': inference_params or {},
        'timestamp': datetime.now().isoformat()
    }
    
    # ì—ëŸ¬ ì¶”ì 
    track_exception(error, error_context)
    
    # ì—ëŸ¬ íƒ€ì…ë³„ ì²˜ë¦¬
    if isinstance(error, (ValueError, TypeError)):
        return {
            'success': False,
            'error': 'PARSING_INFERENCE_INPUT_ERROR',
            'message': f"{model_name} ì¶”ë¡  ì…ë ¥ ë°ì´í„° ì˜¤ë¥˜: {str(error)}",
            'error_context': error_context,
            'suggestion': 'ì…ë ¥ ì´ë¯¸ì§€ì˜ í˜•ì‹ê³¼ í¬ê¸°ê°€ ì˜¬ë°”ë¥¸ì§€ í™•ì¸í•˜ì„¸ìš”'
        }
    elif isinstance(error, RuntimeError):
        return {
            'success': False,
            'error': 'PARSING_INFERENCE_RUNTIME_ERROR',
            'message': f"{model_name} ì¶”ë¡  ì‹¤í–‰ ì˜¤ë¥˜: {str(error)}",
            'error_context': error_context,
            'suggestion': 'GPU ë©”ëª¨ë¦¬ê°€ ì¶©ë¶„í•œì§€ í™•ì¸í•˜ê±°ë‚˜ CPU ëª¨ë“œë¡œ ì „í™˜í•˜ì„¸ìš”'
        }
    elif isinstance(error, MemoryError):
        return {
            'success': False,
            'error': 'PARSING_INFERENCE_MEMORY_ERROR',
            'message': f"{model_name} ì¶”ë¡  ë©”ëª¨ë¦¬ ë¶€ì¡±: {str(error)}",
            'error_context': error_context,
            'suggestion': 'ì…ë ¥ ì´ë¯¸ì§€ í¬ê¸°ë¥¼ ì¤„ì´ê±°ë‚˜ ë°°ì¹˜ í¬ê¸°ë¥¼ ì¤„ì—¬ë³´ì„¸ìš”'
        }
    else:
        return {
            'success': False,
            'error': 'PARSING_INFERENCE_ERROR',
            'message': f"{model_name} ì¶”ë¡  ì˜¤ë¥˜: {str(error)}",
            'error_context': error_context,
            'suggestion': 'ë¡œê·¸ë¥¼ í™•ì¸í•˜ì—¬ êµ¬ì²´ì ì¸ ì˜¤ë¥˜ ì›ì¸ì„ íŒŒì•…í•˜ì„¸ìš”'
        }


def handle_image_preprocessing_error(operation: str, error: Exception, image_info: dict = None) -> dict:
    """ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì—ëŸ¬ ì²˜ë¦¬"""
    error_context = {
        'operation': operation,
        'error_type': type(error).__name__,
        'error_message': str(error),
        'image_info': image_info or {},
        'timestamp': datetime.now().isoformat()
    }
    
    # ì—ëŸ¬ ì¶”ì 
    track_exception(error, error_context)
    
    # ì—ëŸ¬ íƒ€ì…ë³„ ì²˜ë¦¬
    if isinstance(error, (ValueError, TypeError)):
        return {
            'success': False,
            'error': 'IMAGE_PREPROCESSING_FORMAT_ERROR',
            'message': f"ì´ë¯¸ì§€ ì „ì²˜ë¦¬ {operation} í˜•ì‹ ì˜¤ë¥˜: {str(error)}",
            'error_context': error_context,
            'suggestion': 'ì´ë¯¸ì§€ íŒŒì¼ì´ ì†ìƒë˜ì§€ ì•Šì•˜ëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”'
        }
    elif isinstance(error, (OSError, IOError)):
        return {
            'success': False,
            'error': 'IMAGE_PREPROCESSING_IO_ERROR',
            'message': f"ì´ë¯¸ì§€ ì „ì²˜ë¦¬ {operation} ì…ì¶œë ¥ ì˜¤ë¥˜: {str(error)}",
            'error_context': error_context,
            'suggestion': 'ì´ë¯¸ì§€ íŒŒì¼ì— ì ‘ê·¼ ê¶Œí•œì´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”'
        }
    elif isinstance(error, MemoryError):
        return {
            'success': False,
            'error': 'IMAGE_PREPROCESSING_MEMORY_ERROR',
            'message': f"ì´ë¯¸ì§€ ì „ì²˜ë¦¬ {operation} ë©”ëª¨ë¦¬ ë¶€ì¡±: {str(error)}",
            'error_context': error_context,
            'suggestion': 'ì´ë¯¸ì§€ í¬ê¸°ë¥¼ ì¤„ì—¬ë³´ì„¸ìš”'
        }
    else:
        return {
            'success': False,
            'error': 'IMAGE_PREPROCESSING_ERROR',
            'message': f"ì´ë¯¸ì§€ ì „ì²˜ë¦¬ {operation} ì˜¤ë¥˜: {str(error)}",
            'error_context': error_context,
            'suggestion': 'ë¡œê·¸ë¥¼ í™•ì¸í•˜ì—¬ êµ¬ì²´ì ì¸ ì˜¤ë¥˜ ì›ì¸ì„ íŒŒì•…í•˜ì„¸ìš”'
        }


def create_human_parsing_error_response(step_name: str, error: Exception, operation: str = "unknown", context: dict = None) -> dict:
    """Human Parsing ì—ëŸ¬ ì‘ë‹µ ìƒì„±"""
    error_context = {
        'step_name': step_name,
        'operation': operation,
        'error_type': type(error).__name__,
        'error_message': str(error),
        'context': context or {},
        'timestamp': datetime.now().isoformat()
    }
    
    # ì—ëŸ¬ ì¶”ì 
    track_exception(error, error_context)
    
    # ì—ëŸ¬ íƒ€ì…ë³„ ì²˜ë¦¬
    if isinstance(error, (ImportError, ModuleNotFoundError)):
        return handle_step_initialization_error(step_name, error, {'operation': operation})
    elif isinstance(error, (OSError, IOError)):
        return handle_human_parsing_model_loading_error("Unknown", error)
    elif isinstance(error, (ValueError, TypeError)):
        return handle_human_parsing_inference_error("Unknown", error)
    elif isinstance(error, RuntimeError):
        return handle_human_parsing_inference_error("Unknown", error)
    elif isinstance(error, MemoryError):
        return handle_human_parsing_inference_error("Unknown", error)
    else:
        return {
            'success': False,
            'error': 'HUMAN_PARSING_ERROR',
            'message': f"{step_name} {operation} ì‹¤íŒ¨: {str(error)}",
            'error_context': error_context,
            'suggestion': 'ë¡œê·¸ë¥¼ í™•ì¸í•˜ì—¬ êµ¬ì²´ì ì¸ ì˜¤ë¥˜ ì›ì¸ì„ íŒŒì•…í•˜ì„¸ìš”'
        }


def validate_human_parsing_environment() -> dict:
    """Human Parsing í™˜ê²½ ê²€ì¦"""
    validation_result = {
        'success': True,
        'checks': {},
        'timestamp': datetime.now().isoformat()
    }
    
    # PyTorch ì‚¬ìš© ê°€ëŠ¥ì„± í™•ì¸
    try:
        import torch
        validation_result['checks']['pytorch_available'] = True
        validation_result['checks']['pytorch_version'] = torch.__version__
        
        # CUDA ì‚¬ìš© ê°€ëŠ¥ì„± í™•ì¸
        if torch.cuda.is_available():
            validation_result['checks']['cuda_available'] = True
            validation_result['checks']['cuda_device_count'] = torch.cuda.device_count()
        else:
            validation_result['checks']['cuda_available'] = False
            
        # MPS ì‚¬ìš© ê°€ëŠ¥ì„± í™•ì¸
        if hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
            validation_result['checks']['mps_available'] = True
        else:
            validation_result['checks']['mps_available'] = False
            
    except ImportError:
        validation_result['checks']['pytorch_available'] = False
        validation_result['success'] = False
    
    # PIL ì‚¬ìš© ê°€ëŠ¥ì„± í™•ì¸
    try:
        from PIL import Image
        validation_result['checks']['pil_available'] = True
    except ImportError:
        validation_result['checks']['pil_available'] = False
        validation_result['success'] = False
    
    # OpenCV ì‚¬ìš© ê°€ëŠ¥ì„± í™•ì¸
    try:
        import cv2
        validation_result['checks']['opencv_available'] = True
        validation_result['checks']['opencv_version'] = cv2.__version__
    except ImportError:
        validation_result['checks']['opencv_available'] = False
    
    # NumPy ì‚¬ìš© ê°€ëŠ¥ì„± í™•ì¸
    try:
        import numpy as np
        validation_result['checks']['numpy_available'] = True
        validation_result['checks']['numpy_version'] = np.__version__
    except ImportError:
        validation_result['checks']['numpy_available'] = False
        validation_result['success'] = False
    
    # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í™•ì¸
    try:
        import psutil
        memory = psutil.virtual_memory()
        validation_result['checks']['memory_available_gb'] = memory.available / (1024**3)
        validation_result['checks']['memory_total_gb'] = memory.total / (1024**3)
    except ImportError:
        validation_result['checks']['memory_info_available'] = False
    
    return validation_result


def log_human_parsing_performance(step_name: str, model_name: str, operation: str, start_time: float, success: bool, error: Exception = None, inference_params: dict = None) -> dict:
    """Human Parsing ì„±ëŠ¥ ë¡œê¹…"""
    end_time = time.time()
    duration = end_time - start_time
    
    performance_data = {
        'step_name': step_name,
        'model_name': model_name,
        'operation': operation,
        'duration_seconds': duration,
        'success': success,
        'inference_params': inference_params or {},
        'timestamp': datetime.now().isoformat()
    }
    
    if error:
        performance_data['error'] = {
            'type': type(error).__name__,
            'message': str(error)
        }
    
    # ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
    if success:
        logger.info(f"âœ… {step_name} {model_name} {operation} ì™„ë£Œ ({duration:.3f}ì´ˆ)")
    else:
        logger.error(f"âŒ {step_name} {model_name} {operation} ì‹¤íŒ¨ ({duration:.3f}ì´ˆ): {error}")
    
    return performance_data

def handle_virtual_fitting_model_loading_error(model_name: str, error: Exception, checkpoint_path: str = None) -> dict:
    """Virtual Fitting ëª¨ë¸ ë¡œë”© ì—ëŸ¬ ì²˜ë¦¬"""
    error_context = {
        'model_name': model_name,
        'error_type': type(error).__name__,
        'error_message': str(error),
        'checkpoint_path': checkpoint_path,
        'timestamp': datetime.now().isoformat()
    }
    
    # ì—ëŸ¬ ì¶”ì 
    track_exception(error, error_context)
    
    # ì—ëŸ¬ íƒ€ì…ë³„ ì²˜ë¦¬
    if isinstance(error, (OSError, IOError)):
        return {
            'success': False,
            'error': 'MODEL_FILE_ERROR',
            'message': f"{model_name} ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {str(error)}",
            'error_context': error_context,
            'suggestion': f'{model_name} ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ì´ ì˜¬ë°”ë¥¸ ê²½ë¡œì— ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”'
        }
    elif isinstance(error, (KeyError, ValueError)):
        return {
            'success': False,
            'error': 'MODEL_FORMAT_ERROR',
            'message': f"{model_name} ì²´í¬í¬ì¸íŠ¸ í˜•ì‹ ì˜¤ë¥˜: {str(error)}",
            'error_context': error_context,
            'suggestion': f'{model_name} ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ì´ ì†ìƒë˜ì—ˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì¬ë‹¤ìš´ë¡œë“œë¥¼ ì‹œë„í•˜ì„¸ìš”'
        }
    elif isinstance(error, RuntimeError):
        return {
            'success': False,
            'error': 'MODEL_LOADING_ERROR',
            'message': f"{model_name} ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {str(error)}",
            'error_context': error_context,
            'suggestion': f'{model_name} ëª¨ë¸ì´ í˜„ì¬ í™˜ê²½ê³¼ í˜¸í™˜ë˜ëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”'
        }
    else:
        return {
            'success': False,
            'error': 'MODEL_ERROR',
            'message': f"{model_name} ëª¨ë¸ ì˜¤ë¥˜: {str(error)}",
            'error_context': error_context,
            'suggestion': 'ë¡œê·¸ë¥¼ í™•ì¸í•˜ì—¬ êµ¬ì²´ì ì¸ ì˜¤ë¥˜ ì›ì¸ì„ íŒŒì•…í•˜ì„¸ìš”'
        }


def handle_virtual_fitting_inference_error(model_name: str, error: Exception, inference_params: dict = None) -> dict:
    """Virtual Fitting ì¶”ë¡  ì—ëŸ¬ ì²˜ë¦¬"""
    error_context = {
        'model_name': model_name,
        'error_type': type(error).__name__,
        'error_message': str(error),
        'inference_params': inference_params or {},
        'timestamp': datetime.now().isoformat()
    }
    
    # ì—ëŸ¬ ì¶”ì 
    track_exception(error, error_context)
    
    # ì—ëŸ¬ íƒ€ì…ë³„ ì²˜ë¦¬
    if isinstance(error, (ValueError, TypeError)):
        return {
            'success': False,
            'error': 'INFERENCE_INPUT_ERROR',
            'message': f"{model_name} ì¶”ë¡  ì…ë ¥ ë°ì´í„° ì˜¤ë¥˜: {str(error)}",
            'error_context': error_context,
            'suggestion': 'ì…ë ¥ ì´ë¯¸ì§€ì˜ í˜•ì‹ê³¼ í¬ê¸°ê°€ ì˜¬ë°”ë¥¸ì§€ í™•ì¸í•˜ì„¸ìš”'
        }
    elif isinstance(error, RuntimeError):
        return {
            'success': False,
            'error': 'INFERENCE_RUNTIME_ERROR',
            'message': f"{model_name} ì¶”ë¡  ì‹¤í–‰ ì˜¤ë¥˜: {str(error)}",
            'error_context': error_context,
            'suggestion': 'GPU ë©”ëª¨ë¦¬ê°€ ì¶©ë¶„í•œì§€ í™•ì¸í•˜ê±°ë‚˜ CPU ëª¨ë“œë¡œ ì „í™˜í•˜ì„¸ìš”'
        }
    elif isinstance(error, MemoryError):
        return {
            'success': False,
            'error': 'INFERENCE_MEMORY_ERROR',
            'message': f"{model_name} ì¶”ë¡  ë©”ëª¨ë¦¬ ë¶€ì¡±: {str(error)}",
            'error_context': error_context,
            'suggestion': 'ì…ë ¥ ì´ë¯¸ì§€ í¬ê¸°ë¥¼ ì¤„ì´ê±°ë‚˜ ë°°ì¹˜ í¬ê¸°ë¥¼ ì¤„ì—¬ë³´ì„¸ìš”'
        }
    else:
        return {
            'success': False,
            'error': 'INFERENCE_ERROR',
            'message': f"{model_name} ì¶”ë¡  ì˜¤ë¥˜: {str(error)}",
            'error_context': error_context,
            'suggestion': 'ë¡œê·¸ë¥¼ í™•ì¸í•˜ì—¬ êµ¬ì²´ì ì¸ ì˜¤ë¥˜ ì›ì¸ì„ íŒŒì•…í•˜ì„¸ìš”'
        }


def handle_session_data_error(operation: str, error: Exception, session_id: str = None) -> dict:
    """ì„¸ì…˜ ë°ì´í„° ì—ëŸ¬ ì²˜ë¦¬"""
    error_context = {
        'operation': operation,
        'error_type': type(error).__name__,
        'error_message': str(error),
        'session_id': session_id,
        'timestamp': datetime.now().isoformat()
    }
    
    # ì—ëŸ¬ ì¶”ì 
    track_exception(error, error_context)
    
    # ì—ëŸ¬ íƒ€ì…ë³„ ì²˜ë¦¬
    if isinstance(error, (KeyError, ValueError)):
        return {
            'success': False,
            'error': 'SESSION_DATA_ERROR',
            'message': f"ì„¸ì…˜ ë°ì´í„° {operation} ì˜¤ë¥˜: {str(error)}",
            'error_context': error_context,
            'suggestion': 'ì„¸ì…˜ IDê°€ ì˜¬ë°”ë¥¸ì§€ í™•ì¸í•˜ì„¸ìš”'
        }
    elif isinstance(error, TimeoutError):
        return {
            'success': False,
            'error': 'SESSION_TIMEOUT_ERROR',
            'message': f"ì„¸ì…˜ {operation} íƒ€ì„ì•„ì›ƒ: {str(error)}",
            'error_context': error_context,
            'suggestion': 'ë„¤íŠ¸ì›Œí¬ ì—°ê²°ì„ í™•ì¸í•˜ê³  ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”'
        }
    elif isinstance(error, RuntimeError):
        return {
            'success': False,
            'error': 'SESSION_RUNTIME_ERROR',
            'message': f"ì„¸ì…˜ {operation} ì‹¤í–‰ ì˜¤ë¥˜: {str(error)}",
            'error_context': error_context,
            'suggestion': 'ì„¸ì…˜ ë§¤ë‹ˆì €ê°€ ì˜¬ë°”ë¥´ê²Œ ì´ˆê¸°í™”ë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”'
        }
    else:
        return {
            'success': False,
            'error': 'SESSION_ERROR',
            'message': f"ì„¸ì…˜ {operation} ì˜¤ë¥˜: {str(error)}",
            'error_context': error_context,
            'suggestion': 'ë¡œê·¸ë¥¼ í™•ì¸í•˜ì—¬ êµ¬ì²´ì ì¸ ì˜¤ë¥˜ ì›ì¸ì„ íŒŒì•…í•˜ì„¸ìš”'
        }


def handle_image_processing_error(operation: str, error: Exception, image_info: dict = None) -> dict:
    """ì´ë¯¸ì§€ ì²˜ë¦¬ ì—ëŸ¬ ì²˜ë¦¬"""
    error_context = {
        'operation': operation,
        'error_type': type(error).__name__,
        'error_message': str(error),
        'image_info': image_info or {},
        'timestamp': datetime.now().isoformat()
    }
    
    # ì—ëŸ¬ ì¶”ì 
    track_exception(error, error_context)
    
    # ì—ëŸ¬ íƒ€ì…ë³„ ì²˜ë¦¬
    if isinstance(error, (ValueError, TypeError)):
        return {
            'success': False,
            'error': 'IMAGE_FORMAT_ERROR',
            'message': f"ì´ë¯¸ì§€ {operation} í˜•ì‹ ì˜¤ë¥˜: {str(error)}",
            'error_context': error_context,
            'suggestion': 'ì´ë¯¸ì§€ íŒŒì¼ì´ ì†ìƒë˜ì§€ ì•Šì•˜ëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”'
        }
    elif isinstance(error, (OSError, IOError)):
        return {
            'success': False,
            'error': 'IMAGE_IO_ERROR',
            'message': f"ì´ë¯¸ì§€ {operation} ì…ì¶œë ¥ ì˜¤ë¥˜: {str(error)}",
            'error_context': error_context,
            'suggestion': 'ì´ë¯¸ì§€ íŒŒì¼ì— ì ‘ê·¼ ê¶Œí•œì´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”'
        }
    elif isinstance(error, MemoryError):
        return {
            'success': False,
            'error': 'IMAGE_MEMORY_ERROR',
            'message': f"ì´ë¯¸ì§€ {operation} ë©”ëª¨ë¦¬ ë¶€ì¡±: {str(error)}",
            'error_context': error_context,
            'suggestion': 'ì´ë¯¸ì§€ í¬ê¸°ë¥¼ ì¤„ì—¬ë³´ì„¸ìš”'
        }
    else:
        return {
            'success': False,
            'error': 'IMAGE_PROCESSING_ERROR',
            'message': f"ì´ë¯¸ì§€ {operation} ì˜¤ë¥˜: {str(error)}",
            'error_context': error_context,
            'suggestion': 'ë¡œê·¸ë¥¼ í™•ì¸í•˜ì—¬ êµ¬ì²´ì ì¸ ì˜¤ë¥˜ ì›ì¸ì„ íŒŒì•…í•˜ì„¸ìš”'
        }


def create_virtual_fitting_error_response(step_name: str, error: Exception, operation: str = "unknown", context: dict = None) -> dict:
    """Virtual Fitting ì—ëŸ¬ ì‘ë‹µ ìƒì„±"""
    error_context = {
        'step_name': step_name,
        'operation': operation,
        'error_type': type(error).__name__,
        'error_message': str(error),
        'context': context or {},
        'timestamp': datetime.now().isoformat()
    }
    
    # ì—ëŸ¬ ì¶”ì 
    track_exception(error, error_context)
    
    # ì—ëŸ¬ íƒ€ì…ë³„ ì²˜ë¦¬
    if isinstance(error, (ImportError, ModuleNotFoundError)):
        return handle_step_initialization_error(step_name, error, {'operation': operation})
    elif isinstance(error, (OSError, IOError)):
        return handle_virtual_fitting_model_loading_error("Unknown", error)
    elif isinstance(error, (ValueError, TypeError)):
        return handle_virtual_fitting_inference_error("Unknown", error)
    elif isinstance(error, RuntimeError):
        return handle_virtual_fitting_inference_error("Unknown", error)
    elif isinstance(error, MemoryError):
        return handle_virtual_fitting_inference_error("Unknown", error)
    elif isinstance(error, TimeoutError):
        return handle_session_data_error(operation, error)
    else:
        return {
            'success': False,
            'error': 'VIRTUAL_FITTING_ERROR',
            'message': f"{step_name} {operation} ì‹¤íŒ¨: {str(error)}",
            'error_context': error_context,
            'suggestion': 'ë¡œê·¸ë¥¼ í™•ì¸í•˜ì—¬ êµ¬ì²´ì ì¸ ì˜¤ë¥˜ ì›ì¸ì„ íŒŒì•…í•˜ì„¸ìš”'
        }


def validate_virtual_fitting_environment() -> dict:
    """Virtual Fitting í™˜ê²½ ê²€ì¦"""
    validation_result = {
        'success': True,
        'checks': {},
        'timestamp': datetime.now().isoformat()
    }
    
    # PyTorch ì‚¬ìš© ê°€ëŠ¥ì„± í™•ì¸
    try:
        import torch
        validation_result['checks']['pytorch_available'] = True
        validation_result['checks']['pytorch_version'] = torch.__version__
        
        # CUDA ì‚¬ìš© ê°€ëŠ¥ì„± í™•ì¸
        if torch.cuda.is_available():
            validation_result['checks']['cuda_available'] = True
            validation_result['checks']['cuda_device_count'] = torch.cuda.device_count()
        else:
            validation_result['checks']['cuda_available'] = False
            
        # MPS ì‚¬ìš© ê°€ëŠ¥ì„± í™•ì¸
        if hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
            validation_result['checks']['mps_available'] = True
        else:
            validation_result['checks']['mps_available'] = False
            
    except ImportError:
        validation_result['checks']['pytorch_available'] = False
        validation_result['success'] = False
    
    # Diffusers ì‚¬ìš© ê°€ëŠ¥ì„± í™•ì¸
    try:
        import diffusers
        validation_result['checks']['diffusers_available'] = True
        validation_result['checks']['diffusers_version'] = diffusers.__version__
    except ImportError:
        validation_result['checks']['diffusers_available'] = False
    
    # PIL ì‚¬ìš© ê°€ëŠ¥ì„± í™•ì¸
    try:
        from PIL import Image
        validation_result['checks']['pil_available'] = True
    except ImportError:
        validation_result['checks']['pil_available'] = False
        validation_result['success'] = False
    
    # OpenCV ì‚¬ìš© ê°€ëŠ¥ì„± í™•ì¸
    try:
        import cv2
        validation_result['checks']['opencv_available'] = True
        validation_result['checks']['opencv_version'] = cv2.__version__
    except ImportError:
        validation_result['checks']['opencv_available'] = False
    
    # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í™•ì¸
    try:
        import psutil
        memory = psutil.virtual_memory()
        validation_result['checks']['memory_available_gb'] = memory.available / (1024**3)
        validation_result['checks']['memory_total_gb'] = memory.total / (1024**3)
    except ImportError:
        validation_result['checks']['memory_info_available'] = False
    
    return validation_result


def log_virtual_fitting_performance(step_name: str, model_name: str, operation: str, start_time: float, success: bool, error: Exception = None, inference_params: dict = None) -> dict:
    """Virtual Fitting ì„±ëŠ¥ ë¡œê¹…"""
    end_time = time.time()
    duration = end_time - start_time
    
    performance_data = {
        'step_name': step_name,
        'model_name': model_name,
        'operation': operation,
        'duration_seconds': duration,
        'success': success,
        'inference_params': inference_params or {},
        'timestamp': datetime.now().isoformat()
    }
    
    if error:
        performance_data['error'] = {
            'type': type(error).__name__,
            'message': str(error)
        }
    
    # ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
    if success:
        logger.info(f"âœ… {step_name} {model_name} {operation} ì™„ë£Œ ({duration:.3f}ì´ˆ)")
    else:
        logger.error(f"âŒ {step_name} {model_name} {operation} ì‹¤íŒ¨ ({duration:.3f}ì´ˆ): {error}")
    
    return performance_data


# ==============================================
# ğŸ”¥ BaseStepMixin ì „ìš© ì—ëŸ¬ ì²˜ë¦¬ í—¬í¼ í•¨ìˆ˜ë“¤
# ==============================================

def handle_step_initialization_error(step_name: str, error: Exception, context: dict = None) -> dict:
    """Step ì´ˆê¸°í™” ì—ëŸ¬ ì²˜ë¦¬"""
    error_context = {
        'step_name': step_name,
        'error_type': type(error).__name__,
        'error_message': str(error),
        'context': context or {},
        'timestamp': datetime.now().isoformat()
    }
    
    # ì—ëŸ¬ ì¶”ì 
    track_exception(error, error_context)
    
    # ì—ëŸ¬ íƒ€ì…ë³„ ì²˜ë¦¬
    if isinstance(error, ImportError):
        return {
            'success': False,
            'error': 'IMPORT_ERROR',
            'message': f"{step_name} ëª¨ë“ˆ import ì‹¤íŒ¨: {str(error)}",
            'error_context': error_context,
            'suggestion': 'í•„ìš”í•œ íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”'
        }
    elif isinstance(error, AttributeError):
        return {
            'success': False,
            'error': 'ATTRIBUTE_ERROR',
            'message': f"{step_name} ì†ì„± ì ‘ê·¼ ì‹¤íŒ¨: {str(error)}",
            'error_context': error_context,
            'suggestion': 'Step í´ë˜ìŠ¤ì˜ í•„ìˆ˜ ì†ì„±ì´ ì •ì˜ë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”'
        }
    elif isinstance(error, TypeError):
        return {
            'success': False,
            'error': 'TYPE_ERROR',
            'message': f"{step_name} íƒ€ì… ì˜¤ë¥˜: {str(error)}",
            'error_context': error_context,
            'suggestion': 'ë©”ì„œë“œ í˜¸ì¶œ ì‹œ ì˜¬ë°”ë¥¸ íƒ€ì…ì˜ ì¸ìë¥¼ ì „ë‹¬í–ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”'
        }
    else:
        return {
            'success': False,
            'error': 'INITIALIZATION_ERROR',
            'message': f"{step_name} ì´ˆê¸°í™” ì‹¤íŒ¨: {str(error)}",
            'error_context': error_context,
            'suggestion': 'ë¡œê·¸ë¥¼ í™•ì¸í•˜ì—¬ êµ¬ì²´ì ì¸ ì˜¤ë¥˜ ì›ì¸ì„ íŒŒì•…í•˜ì„¸ìš”'
        }


def handle_dependency_injection_error(step_name: str, service_name: str, error: Exception) -> dict:
    """ì˜ì¡´ì„± ì£¼ì… ì—ëŸ¬ ì²˜ë¦¬"""
    error_context = {
        'step_name': step_name,
        'service_name': service_name,
        'error_type': type(error).__name__,
        'error_message': str(error),
        'timestamp': datetime.now().isoformat()
    }
    
    # ì—ëŸ¬ ì¶”ì 
    track_exception(error, error_context)
    
    return {
        'success': False,
        'error': 'DEPENDENCY_INJECTION_ERROR',
        'message': f"{step_name} {service_name} ì˜ì¡´ì„± ì£¼ì… ì‹¤íŒ¨: {str(error)}",
        'error_context': error_context,
        'suggestion': f'{service_name} ì„œë¹„ìŠ¤ê°€ Central Hub Containerì— ë“±ë¡ë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”'
    }


def handle_data_conversion_error(step_name: str, conversion_type: str, error: Exception, data_info: dict = None) -> dict:
    """ë°ì´í„° ë³€í™˜ ì—ëŸ¬ ì²˜ë¦¬"""
    error_context = {
        'step_name': step_name,
        'conversion_type': conversion_type,
        'error_type': type(error).__name__,
        'error_message': str(error),
        'data_info': data_info or {},
        'timestamp': datetime.now().isoformat()
    }
    
    # ì—ëŸ¬ ì¶”ì 
    track_exception(error, error_context)
    
    return {
        'success': False,
        'error': 'DATA_CONVERSION_ERROR',
        'message': f"{step_name} {conversion_type} ë³€í™˜ ì‹¤íŒ¨: {str(error)}",
        'error_context': error_context,
        'suggestion': 'ì…ë ¥ ë°ì´í„°ì˜ í˜•ì‹ê³¼ í¬ê¸°ê°€ ì˜¬ë°”ë¥¸ì§€ í™•ì¸í•˜ì„¸ìš”'
    }


def handle_central_hub_error(step_name: str, operation: str, error: Exception) -> dict:
    """Central Hub ì—°ë™ ì—ëŸ¬ ì²˜ë¦¬"""
    error_context = {
        'step_name': step_name,
        'operation': operation,
        'error_type': type(error).__name__,
        'error_message': str(error),
        'timestamp': datetime.now().isoformat()
    }
    
    # ì—ëŸ¬ ì¶”ì 
    track_exception(error, error_context)
    
    return {
        'success': False,
        'error': 'CENTRAL_HUB_ERROR',
        'message': f"{step_name} Central Hub {operation} ì‹¤íŒ¨: {str(error)}",
        'error_context': error_context,
        'suggestion': 'Central Hub DI Containerê°€ ì˜¬ë°”ë¥´ê²Œ ì´ˆê¸°í™”ë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”'
    }


def create_step_error_response(step_name: str, error: Exception, operation: str = "unknown") -> dict:
    """Step ì—ëŸ¬ ì‘ë‹µ ìƒì„±"""
    error_context = {
        'step_name': step_name,
        'operation': operation,
        'error_type': type(error).__name__,
        'error_message': str(error),
        'timestamp': datetime.now().isoformat()
    }
    
    # ì—ëŸ¬ ì¶”ì 
    track_exception(error, error_context)
    
    # ì—ëŸ¬ íƒ€ì…ë³„ ì²˜ë¦¬
    if isinstance(error, (ImportError, ModuleNotFoundError)):
        return handle_step_initialization_error(step_name, error, {'operation': operation})
    elif isinstance(error, AttributeError):
        return handle_step_initialization_error(step_name, error, {'operation': operation})
    elif isinstance(error, TypeError):
        return handle_step_initialization_error(step_name, error, {'operation': operation})
    elif isinstance(error, ValueError):
        return handle_data_conversion_error(step_name, "validation", error)
    elif isinstance(error, (FileNotFoundError, OSError)):
        return {
            'success': False,
            'error': 'FILE_OPERATION_ERROR',
            'message': f"{step_name} íŒŒì¼ ì‘ì—… ì‹¤íŒ¨: {str(error)}",
            'error_context': error_context,
            'suggestion': 'í•„ìš”í•œ íŒŒì¼ì´ ì˜¬ë°”ë¥¸ ê²½ë¡œì— ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”'
        }
    else:
        return {
            'success': False,
            'error': 'STEP_ERROR',
            'message': f"{step_name} {operation} ì‹¤íŒ¨: {str(error)}",
            'error_context': error_context,
            'suggestion': 'ë¡œê·¸ë¥¼ í™•ì¸í•˜ì—¬ êµ¬ì²´ì ì¸ ì˜¤ë¥˜ ì›ì¸ì„ íŒŒì•…í•˜ì„¸ìš”'
        }


def validate_step_environment(step_name: str) -> dict:
    """Step í™˜ê²½ ê²€ì¦"""
    validation_result = {
        'success': True,
        'step_name': step_name,
        'checks': {},
        'timestamp': datetime.now().isoformat()
    }
    
    # PyTorch ì‚¬ìš© ê°€ëŠ¥ì„± í™•ì¸
    try:
        import torch
        validation_result['checks']['pytorch_available'] = True
        validation_result['checks']['pytorch_version'] = torch.__version__
        
        # MPS ì‚¬ìš© ê°€ëŠ¥ì„± í™•ì¸
        if hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
            validation_result['checks']['mps_available'] = True
        else:
            validation_result['checks']['mps_available'] = False
            
    except ImportError:
        validation_result['checks']['pytorch_available'] = False
        validation_result['success'] = False
    
    # NumPy ì‚¬ìš© ê°€ëŠ¥ì„± í™•ì¸
    try:
        import numpy as np
        validation_result['checks']['numpy_available'] = True
        validation_result['checks']['numpy_version'] = np.__version__
    except ImportError:
        validation_result['checks']['numpy_available'] = False
        validation_result['success'] = False
    
    # PIL ì‚¬ìš© ê°€ëŠ¥ì„± í™•ì¸
    try:
        from PIL import Image
        validation_result['checks']['pil_available'] = True
    except ImportError:
        validation_result['checks']['pil_available'] = False
        validation_result['success'] = False
    
    # OpenCV ì‚¬ìš© ê°€ëŠ¥ì„± í™•ì¸
    try:
        import cv2
        validation_result['checks']['opencv_available'] = True
        validation_result['checks']['opencv_version'] = cv2.__version__
    except ImportError:
        validation_result['checks']['opencv_available'] = False
    
    # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í™•ì¸
    try:
        import psutil
        memory = psutil.virtual_memory()
        validation_result['checks']['memory_available_gb'] = memory.available / (1024**3)
        validation_result['checks']['memory_total_gb'] = memory.total / (1024**3)
    except ImportError:
        validation_result['checks']['memory_info_available'] = False
    
    return validation_result


def log_step_performance(step_name: str, operation: str, start_time: float, success: bool, error: Exception = None) -> dict:
    """Step ì„±ëŠ¥ ë¡œê¹…"""
    end_time = time.time()
    duration = end_time - start_time
    
    performance_data = {
        'step_name': step_name,
        'operation': operation,
        'duration_seconds': duration,
        'success': success,
        'timestamp': datetime.now().isoformat()
    }
    
    if error:
        performance_data['error'] = {
            'type': type(error).__name__,
            'message': str(error)
        }
    
    # ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
    if success:
        logger.info(f"âœ… {step_name} {operation} ì™„ë£Œ ({duration:.3f}ì´ˆ)")
    else:
        logger.error(f"âŒ {step_name} {operation} ì‹¤íŒ¨ ({duration:.3f}ì´ˆ): {error}")
    
    return performance_data 