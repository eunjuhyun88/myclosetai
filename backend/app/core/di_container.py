"""
ğŸ”¥ DI Container - ìµœì  ê²°í•© ë²„ì „ (ì‹¤ìš©ì„± + ì™„ì „ì„±)
==================================================

âœ… MyCloset AI í”„ë¡œì íŠ¸ íŠ¹í™” (ë¬¸ì„œ 4 ê¸°ë°˜)
âœ… í”„ë¡œë•ì…˜ê¸‰ DI Container ê¸°ëŠ¥ (ì œì•ˆ ë²„ì „ ê¸°ë°˜)
âœ… ìˆœí™˜ì°¸ì¡° ì™„ì „ í•´ê²°
âœ… ModelLoader, MemoryManager, BaseStepMixin ì§ì ‘ ì—°ë™
âœ… Mock êµ¬í˜„ì²´ í¬í•¨ (í´ë°± ì§€ì›)
âœ… conda í™˜ê²½ ìš°ì„  ìµœì í™”
âœ… M3 Max 128GB ìµœì í™”
âœ… ìˆœí™˜ ì˜ì¡´ì„± ê°ì§€ ë° ë°©ì§€
âœ… ìƒëª…ì£¼ê¸° ê´€ë¦¬ ë° ë©”ëª¨ë¦¬ ë³´í˜¸

Author: MyCloset AI Team
Date: 2025-07-22
Version: 3.0 (Optimal Combined)
"""

# ==============================================
# ğŸ”¥ 1. conda í™˜ê²½ ìš°ì„  ì²´í¬ ë° ì„¤ì •
# ==============================================
import os
import sys
import gc
import logging
import threading
import weakref
import time
import platform
import subprocess
from typing import Dict, Any, Optional, Type, TypeVar, Callable, Union, List
from abc import ABC, abstractmethod
from dataclasses import dataclass
from enum import Enum
from pathlib import Path

# conda í™˜ê²½ ìš°ì„  ì„¤ì •
CONDA_ENV = os.environ.get('CONDA_DEFAULT_ENV', 'none')
IS_CONDA = CONDA_ENV != 'none'

if IS_CONDA:
    print(f"âœ… conda í™˜ê²½ ê°ì§€: {CONDA_ENV}")
    # conda ìš°ì„  ë¼ì´ë¸ŒëŸ¬ë¦¬ ê²½ë¡œ ì„¤ì •
    if 'CONDA_PREFIX' in os.environ:
        conda_lib_path = os.path.join(os.environ['CONDA_PREFIX'], 'lib', 'python3.9', 'site-packages')
        if os.path.exists(conda_lib_path) and conda_lib_path not in sys.path:
            sys.path.insert(0, conda_lib_path)
else:
    print("âš ï¸ conda í™˜ê²½ ë¹„í™œì„±í™” - conda activate <env> ê¶Œì¥")

# ë¡œê±° ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# íƒ€ì… ë³€ìˆ˜
T = TypeVar('T')

# ==============================================
# ğŸ”¥ 2. ì‹œìŠ¤í…œ í™˜ê²½ ê°ì§€
# ==============================================

def detect_m3_max() -> bool:
    """M3 Max ê°ì§€ (ì •í™•í•œ ë°©ì‹)"""
    try:
        if platform.system() == 'Darwin':
            result = subprocess.run(
                ['sysctl', '-n', 'machdep.cpu.brand_string'],
                capture_output=True, text=True, timeout=5
            )
            return 'M3' in result.stdout
    except Exception:
        pass
    return False

IS_M3_MAX = detect_m3_max()
DEVICE = 'mps' if IS_M3_MAX else 'cpu'

# PyTorch ê°€ìš©ì„± ì²´í¬ (conda ìš°ì„ )
TORCH_AVAILABLE = False
MPS_AVAILABLE = False
try:
    import torch
    TORCH_AVAILABLE = True
    
    if hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
        MPS_AVAILABLE = True
        # M3 Max ìµœì í™” ì„¤ì •
        os.environ.setdefault('PYTORCH_ENABLE_MPS_FALLBACK', '1')
        os.environ.setdefault('PYTORCH_MPS_HIGH_WATERMARK_RATIO', '0.0')
        
    logger.info(f"âœ… PyTorch ë¡œë“œ: MPS={MPS_AVAILABLE}, M3 Max={IS_M3_MAX}")
except ImportError:
    logger.warning("âš ï¸ PyTorch ì—†ìŒ - conda install pytorch ê¶Œì¥")

# ==============================================
# ğŸ”¥ 3. DI Container ì„¤ì • í´ë˜ìŠ¤ë“¤
# ==============================================

class DependencyScope(Enum):
    """ì˜ì¡´ì„± ìŠ¤ì½”í”„"""
    SINGLETON = "singleton"
    TRANSIENT = "transient"
    SCOPED = "scoped"

@dataclass
class DependencyInfo:
    """ì˜ì¡´ì„± ì •ë³´ (ìƒì„¸ ì¶”ì ìš©)"""
    key: str
    implementation: Any
    factory: Optional[Callable]
    scope: DependencyScope
    created_at: float
    access_count: int = 0
    last_access: float = 0.0
    is_initialized: bool = False

class IDependencyContainer(ABC):
    """ì˜ì¡´ì„± ì»¨í…Œì´ë„ˆ ì¸í„°í˜ì´ìŠ¤"""
    
    @abstractmethod
    def register(self, interface: Union[str, Type], implementation: Any, singleton: bool = True) -> None:
        """ì˜ì¡´ì„± ë“±ë¡"""
        pass
    
    @abstractmethod
    def get(self, interface: Union[str, Type]) -> Optional[Any]:
        """ì˜ì¡´ì„± ì¡°íšŒ"""
        pass
    
    @abstractmethod
    def is_registered(self, interface: Union[str, Type]) -> bool:
        """ë“±ë¡ ì—¬ë¶€ í™•ì¸"""
        pass

# ==============================================
# ğŸ”¥ 4. ë©”ì¸ DI Container (ê²°í•© ë²„ì „)
# ==============================================

class DIContainer(IDependencyContainer):
    """
    ğŸ”¥ ìµœì  ê²°í•© DI Container - MyCloset AI íŠ¹í™” + í”„ë¡œë•ì…˜ê¸‰ ê¸°ëŠ¥
    
    íŠ¹ì§•:
    âœ… MyCloset AI êµ¬ì¡°ì— ë§ì¶¤ (ë¬¸ì„œ 4 ê¸°ë°˜)
    âœ… ìˆœí™˜ ì˜ì¡´ì„± ê°ì§€ ë° ë°©ì§€ (ì œì•ˆ ë²„ì „ ê¸°ë°˜)
    âœ… ModelLoader, MemoryManager, BaseStepMixin ì§ì ‘ ì—°ë™
    âœ… Mock í´ë°± êµ¬í˜„ì²´ í¬í•¨
    âœ… ìƒëª…ì£¼ê¸° ê´€ë¦¬ ë° ë©”ëª¨ë¦¬ ë³´í˜¸
    âœ… conda í™˜ê²½ ìš°ì„  ìµœì í™”
    """
    
    def __init__(self):
        # ì˜ì¡´ì„± ì €ì¥ì†Œë“¤ (ìƒì„¸ ì¶”ì )
        self._dependencies: Dict[str, DependencyInfo] = {}
        self._services: Dict[str, Any] = {}
        self._singletons: Dict[str, Any] = {}
        self._factories: Dict[str, Callable] = {}
        self._scoped_instances: Dict[str, Dict[str, Any]] = {}
        
        # ìˆœí™˜ ì˜ì¡´ì„± ë°©ì§€
        self._dependency_graph: Dict[str, List[str]] = {}
        self._resolving_stack: List[str] = []
        
        # ìŠ¤ë ˆë“œ ì•ˆì „ì„± ê°•í™”
        self._lock = threading.RLock()
        self._resolution_lock = threading.RLock()
        
        # ë©”ëª¨ë¦¬ ë³´í˜¸ (ì•½í•œ ì°¸ì¡°)
        self._weak_refs: Dict[str, weakref.ref] = {}
        
        # ìƒëª…ì£¼ê¸° í›…ë“¤
        self._lifecycle_hooks: Dict[str, List[Callable]] = {
            'before_create': [],
            'after_create': [],
            'before_destroy': []
        }
        
        # ìƒì„¸ í†µê³„ (í”„ë¡œë•ì…˜ìš©)
        self._stats = {
            'total_registrations': 0,
            'total_resolutions': 0,
            'cache_hits': 0,
            'cache_misses': 0,
            'circular_dependencies_detected': 0,
            'memory_cleanups': 0,
            'created_instances': 0,
            'initialization_time': time.time()
        }
        
        # ì´ˆê¸°í™” ìƒíƒœ
        self._initialized = False
        
        logger.info("ğŸ”— DIContainer ìµœì  ê²°í•© ë²„ì „ ìƒì„±")
    
    def initialize(self) -> bool:
        """DI Container ì´ˆê¸°í™” (MyCloset AI íŠ¹í™”)"""
        if self._initialized:
            return True
        
        try:
            with self._lock:
                # MyCloset AI í•µì‹¬ ì˜ì¡´ì„±ë“¤ ë“±ë¡
                self._register_mycloset_dependencies()
                
                # conda í™˜ê²½ ìµœì í™”
                if IS_CONDA:
                    self._optimize_for_conda()
                
                self._initialized = True
                
                logger.info("âœ… DIContainer ì´ˆê¸°í™” ì™„ë£Œ (MyCloset AI íŠ¹í™”)")
                logger.info(f"ğŸ”§ í™˜ê²½: conda={IS_CONDA}, M3 Max={IS_M3_MAX}, Device={DEVICE}")
                
                return True
                
        except Exception as e:
            logger.error(f"âŒ DIContainer ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return False
    
    def register(
        self,
        interface: Union[str, Type],
        implementation: Any = None,
        singleton: bool = True,
        factory: Optional[Callable] = None
    ) -> None:
        """ì˜ì¡´ì„± ë“±ë¡ (ìˆœí™˜ ì˜ì¡´ì„± ê°ì§€ í¬í•¨)"""
        try:
            with self._lock:
                key = self._get_key(interface)
                
                # ìƒëª…ì£¼ê¸° í›… ì‹¤í–‰
                self._execute_lifecycle_hooks('before_create', key)
                
                # ì˜ì¡´ì„± ì •ë³´ ìƒì„±
                scope = DependencyScope.SINGLETON if singleton else DependencyScope.TRANSIENT
                dep_info = DependencyInfo(
                    key=key,
                    implementation=implementation,
                    factory=factory,
                    scope=scope,
                    created_at=time.time()
                )
                
                self._dependencies[key] = dep_info
                
                if factory:
                    self._factories[key] = factory
                elif implementation:
                    if singleton:
                        if isinstance(implementation, type):
                            # í´ë˜ìŠ¤ì¸ ê²½ìš° íŒ©í† ë¦¬ë¡œ ë“±ë¡
                            self._factories[key] = lambda: implementation()
                        else:
                            # ì¸ìŠ¤í„´ìŠ¤ì¸ ê²½ìš° ì§ì ‘ ë“±ë¡
                            self._singletons[key] = implementation
                    else:
                        self._services[key] = implementation
                
                # ì˜ì¡´ì„± ê·¸ë˜í”„ ì—…ë°ì´íŠ¸
                self._update_dependency_graph(key, implementation or factory)
                
                # ìƒëª…ì£¼ê¸° í›… ì‹¤í–‰
                self._execute_lifecycle_hooks('after_create', key)
                
                self._stats['total_registrations'] += 1
                
                logger.debug(f"âœ… ì˜ì¡´ì„± ë“±ë¡: {key} ({'ì‹±ê¸€í†¤' if singleton else 'ì„ì‹œ'})")
                
        except Exception as e:
            logger.error(f"âŒ ì˜ì¡´ì„± ë“±ë¡ ì‹¤íŒ¨ {interface}: {e}")
            raise
    
    def get(self, interface: Union[str, Type]) -> Optional[Any]:
        """ì˜ì¡´ì„± ì¡°íšŒ (ìˆœí™˜ ì˜ì¡´ì„± ê°ì§€ í¬í•¨)"""
        try:
            with self._resolution_lock:
                key = self._get_key(interface)
                self._stats['total_resolutions'] += 1
                
                # ìˆœí™˜ ì˜ì¡´ì„± ê°ì§€
                if key in self._resolving_stack:
                    circular_path = ' -> '.join(self._resolving_stack + [key])
                    self._stats['circular_dependencies_detected'] += 1
                    logger.error(f"âŒ ìˆœí™˜ ì˜ì¡´ì„± ê°ì§€: {circular_path}")
                    return None
                
                self._resolving_stack.append(key)
                
                try:
                    result = self._resolve_dependency(key)
                    if result is not None:
                        self._stats['cache_hits'] += 1
                    else:
                        self._stats['cache_misses'] += 1
                    return result
                finally:
                    self._resolving_stack.remove(key)
                    
        except Exception as e:
            logger.error(f"âŒ ì˜ì¡´ì„± ì¡°íšŒ ì‹¤íŒ¨ {interface}: {e}")
            return None
    
    def _resolve_dependency(self, key: str) -> Optional[Any]:
        """ì‹¤ì œ ì˜ì¡´ì„± í•´ê²° (ìƒì„¸ ì¶”ì )"""
        with self._lock:
            # ì˜ì¡´ì„± ì •ë³´ ì—…ë°ì´íŠ¸
            if key in self._dependencies:
                dep_info = self._dependencies[key]
                dep_info.access_count += 1
                dep_info.last_access = time.time()
            
            # 1. ì‹±ê¸€í†¤ ì²´í¬
            if key in self._singletons:
                return self._singletons[key]
            
            # 2. ì•½í•œ ì°¸ì¡° ì²´í¬ (ë©”ëª¨ë¦¬ ë³´í˜¸)
            if key in self._weak_refs:
                weak_ref = self._weak_refs[key]
                instance = weak_ref()
                if instance is not None:
                    return instance
                else:
                    # ì•½í•œ ì°¸ì¡°ê°€ í•´ì œë¨
                    del self._weak_refs[key]
            
            # 3. ì¼ë°˜ ì„œë¹„ìŠ¤ ì²´í¬
            if key in self._services:
                return self._services[key]
            
            # 4. íŒ©í† ë¦¬ ì²´í¬
            if key in self._factories:
                try:
                    factory = self._factories[key]
                    instance = factory()
                    self._stats['created_instances'] += 1
                    
                    # ì‹±ê¸€í†¤ì´ë©´ ìºì‹œ
                    if key in self._dependencies and self._dependencies[key].scope == DependencyScope.SINGLETON:
                        self._singletons[key] = instance
                    else:
                        # ì•½í•œ ì°¸ì¡°ë¡œ ì €ì¥
                        self._weak_refs[key] = weakref.ref(instance)
                    
                    return instance
                except Exception as e:
                    logger.error(f"âŒ íŒ©í† ë¦¬ ì‹¤í–‰ ì‹¤íŒ¨ ({key}): {e}")
            
            logger.debug(f"âš ï¸ ì„œë¹„ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ: {key}")
            return None
    
    def is_registered(self, interface: Union[str, Type]) -> bool:
        """ë“±ë¡ ì—¬ë¶€ í™•ì¸"""
        try:
            with self._lock:
                key = self._get_key(interface)
                return (key in self._services or 
                       key in self._singletons or 
                       key in self._factories or
                       key in self._dependencies)
        except Exception:
            return False
    
    def _register_mycloset_dependencies(self):
        """MyCloset AI í•µì‹¬ ì˜ì¡´ì„±ë“¤ ë“±ë¡ (ë¬¸ì„œ 4 ê¸°ë°˜)"""
        try:
            # 1. ModelLoader ë“±ë¡ (í•µì‹¬!)
            def create_model_loader():
                try:
                    from ..ai_pipeline.utils.model_loader import ModelLoader, get_global_model_loader
                    loader = get_global_model_loader()
                    if loader:
                        logger.info("âœ… ModelLoader ìƒì„± ì„±ê³µ (ì‹¤ì œ êµ¬í˜„)")
                        return loader
                except ImportError as e:
                    logger.debug(f"ModelLoader import ì‹¤íŒ¨: {e}")
                except Exception as e:
                    logger.debug(f"ModelLoader ìƒì„± ì‹¤íŒ¨: {e}")
                
                # í´ë°±: Mock ModelLoader
                return self._create_mock_model_loader()
            
            self.register('IModelLoader', factory=create_model_loader, singleton=True)
            self.register('model_loader', factory=create_model_loader, singleton=True)
            
            # 2. MemoryManager ë“±ë¡
            def create_memory_manager():
                try:
                    from ..ai_pipeline.utils.memory_manager import MemoryManager, get_global_memory_manager
                    manager = get_global_memory_manager()
                    if manager:
                        logger.info("âœ… MemoryManager ìƒì„± ì„±ê³µ (ì‹¤ì œ êµ¬í˜„)")
                        return manager
                except ImportError as e:
                    logger.debug(f"MemoryManager import ì‹¤íŒ¨: {e}")
                except Exception as e:
                    logger.debug(f"MemoryManager ìƒì„± ì‹¤íŒ¨: {e}")
                
                # í´ë°±: Mock MemoryManager
                return self._create_mock_memory_manager()
            
            self.register('IMemoryManager', factory=create_memory_manager, singleton=True)
            self.register('memory_manager', factory=create_memory_manager, singleton=True)
            
            # 3. BaseStepMixin ë“±ë¡
            def create_step_mixin():
                try:
                    from ..ai_pipeline.steps.base_step_mixin import BaseStepMixin
                    mixin = BaseStepMixin()
                    logger.info("âœ… BaseStepMixin ìƒì„± ì„±ê³µ (ì‹¤ì œ êµ¬í˜„)")
                    return mixin
                except ImportError as e:
                    logger.debug(f"BaseStepMixin import ì‹¤íŒ¨: {e}")
                except Exception as e:
                    logger.debug(f"BaseStepMixin ìƒì„± ì‹¤íŒ¨: {e}")
                
                # í´ë°±: Mock StepMixin
                return self._create_mock_step_mixin()
            
            self.register('IStepMixin', factory=create_step_mixin, singleton=False)
            self.register('step_mixin', factory=create_step_mixin, singleton=False)
            
            # 4. SafeFunctionValidator ë“±ë¡
            def create_function_validator():
                try:
                    from ..ai_pipeline.utils.model_loader import SafeFunctionValidator
                    validator = SafeFunctionValidator()
                    logger.info("âœ… SafeFunctionValidator ìƒì„± ì„±ê³µ")
                    return validator
                except ImportError:
                    return self._create_mock_function_validator()
            
            self.register('ISafeFunctionValidator', factory=create_function_validator, singleton=True)
            self.register('function_validator', factory=create_function_validator, singleton=True)
            
            # 5. ê¸°ë³¸ ì‹œìŠ¤í…œ ì„œë¹„ìŠ¤ë“¤
            self.register('logger', logger, singleton=True)
            self.register('device', DEVICE, singleton=True)
            self.register('conda_info', {
                'conda_env': CONDA_ENV,
                'is_conda': IS_CONDA,
                'is_m3_max': IS_M3_MAX,
                'torch_available': TORCH_AVAILABLE
            }, singleton=True)
            
            logger.info("âœ… MyCloset AI í•µì‹¬ ì˜ì¡´ì„± ë“±ë¡ ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"âŒ MyCloset AI ì˜ì¡´ì„± ë“±ë¡ ì‹¤íŒ¨: {e}")
    
    def _create_mock_model_loader(self):
        """Mock ModelLoader ìƒì„± (ë¬¸ì„œ 4 ê¸°ë°˜ + ê°œì„ )"""
        class MockModelLoader:
            def __init__(self):
                self.logger = logger
                self.models = {}
                self.is_initialized = True
                self.device = DEVICE
                self.step_interfaces = {}
            
            def initialize(self):
                return True
            
            def get_model(self, model_name: str):
                if model_name not in self.models:
                    self.models[model_name] = {
                        "name": model_name,
                        "device": self.device,
                        "type": "mock_model",
                        "loaded": True,
                        "size_mb": 50.0
                    }
                    self.logger.debug(f"ğŸ¤– Mock ëª¨ë¸ ìƒì„±: {model_name}")
                return self.models[model_name]
            
            def load_model(self, model_name: str):
                return self.get_model(model_name)
            
            async def get_model_async(self, model_name: str):
                return self.get_model(model_name)
            
            async def load_model_async(self, model_name: str):
                return self.get_model(model_name)
            
            def create_step_interface(self, step_name: str):
                if step_name not in self.step_interfaces:
                    self.step_interfaces[step_name] = {
                        "step_name": step_name,
                        "model": self.get_model(f"{step_name}_model"),
                        "interface_type": "mock",
                        "device": self.device,
                        "methods": ["get_model_sync", "get_model", "load_model"]
                    }
                return self.step_interfaces[step_name]
            
            def cleanup_models(self):
                self.models.clear()
                self.step_interfaces.clear()
            
            def get_model_info(self):
                return {
                    "loaded_models": len(self.models),
                    "device": self.device,
                    "total_step_interfaces": len(self.step_interfaces)
                }
        
        logger.info("âœ… Mock ModelLoader ìƒì„± (í´ë°±)")
        return MockModelLoader()
    
    def _create_mock_memory_manager(self):
        """Mock MemoryManager ìƒì„± (ë¬¸ì„œ 4 ê¸°ë°˜ + ê°œì„ )"""
        class MockMemoryManager:
            def __init__(self):
                self.logger = logger
                self.is_initialized = True
                self.optimization_count = 0
            
            def optimize_memory(self):
                try:
                    # ê¸°ë³¸ ë©”ëª¨ë¦¬ ì •ë¦¬
                    gc.collect()
                    
                    # M3 Max MPS ìµœì í™”
                    if TORCH_AVAILABLE and IS_M3_MAX and MPS_AVAILABLE:
                        import torch
                        if hasattr(torch.mps, 'empty_cache'):
                            torch.mps.empty_cache()
                            self.logger.debug("ğŸ MPS ìºì‹œ ì •ë¦¬ ì™„ë£Œ")
                    
                    self.optimization_count += 1
                    return {"success": True, "method": "mock_optimization", "count": self.optimization_count}
                    
                except Exception as e:
                    self.logger.debug(f"ë©”ëª¨ë¦¬ ìµœì í™” ì‹¤íŒ¨: {e}")
                    return {"success": False, "error": str(e)}
            
            async def optimize_memory_async(self):
                return self.optimize_memory()
            
            def get_memory_info(self):
                try:
                    import psutil
                    memory = psutil.virtual_memory()
                    return {
                        "total_gb": round(memory.total / (1024**3), 2),
                        "available_gb": round(memory.available / (1024**3), 2),
                        "percent": memory.percent,
                        "device": DEVICE,
                        "is_m3_max": IS_M3_MAX,
                        "optimization_count": self.optimization_count
                    }
                except ImportError:
                    # psutil ì—†ëŠ” ê²½ìš°
                    return {
                        "total_gb": 128 if IS_M3_MAX else 16,
                        "available_gb": 96 if IS_M3_MAX else 12,
                        "percent": 75.0,
                        "device": DEVICE,
                        "is_m3_max": IS_M3_MAX,
                        "optimization_count": self.optimization_count
                    }
            
            def cleanup(self):
                self.optimize_memory()
        
        logger.info("âœ… Mock MemoryManager ìƒì„± (í´ë°±)")
        return MockMemoryManager()
    
    def _create_mock_step_mixin(self):
        """Mock StepMixin ìƒì„± (ë¬¸ì„œ 4 ê¸°ë°˜ + ê°œì„ )"""
        class MockStepMixin:
            def __init__(self):
                self.logger = logger
                self.model_loader = None
                self.memory_manager = None
                self.function_validator = None
                self.is_initialized = False
                self.device = DEVICE
                
                # ì²˜ë¦¬ í†µê³„
                self.processing_stats = {
                    'total_processed': 0,
                    'successful_processed': 0,
                    'failed_processed': 0,
                    'average_processing_time': 0.0
                }
            
            def set_model_loader(self, model_loader):
                self.model_loader = model_loader
                self.logger.debug("âœ… Mock StepMixin - ModelLoader ì£¼ì… ì™„ë£Œ")
            
            def set_memory_manager(self, memory_manager):
                self.memory_manager = memory_manager
                self.logger.debug("âœ… Mock StepMixin - MemoryManager ì£¼ì… ì™„ë£Œ")
            
            def set_function_validator(self, function_validator):
                self.function_validator = function_validator
                self.logger.debug("âœ… Mock StepMixin - FunctionValidator ì£¼ì… ì™„ë£Œ")
            
            def initialize(self):
                self.is_initialized = True
                self.logger.debug("âœ… Mock StepMixin ì´ˆê¸°í™” ì™„ë£Œ")
                return True
            
            async def initialize_async(self):
                return self.initialize()
            
            async def process_async(self, data, step_name: str):
                start_time = time.time()
                
                try:
                    # ë©”ëª¨ë¦¬ ìµœì í™”
                    if self.memory_manager:
                        self.memory_manager.optimize_memory()
                    
                    # ì²˜ë¦¬ ì‹œë®¬ë ˆì´ì…˜
                    import asyncio
                    await asyncio.sleep(0.1)
                    
                    processing_time = time.time() - start_time
                    
                    # í†µê³„ ì—…ë°ì´íŠ¸
                    self.processing_stats['total_processed'] += 1
                    self.processing_stats['successful_processed'] += 1
                    
                    # í‰ê·  ì²˜ë¦¬ ì‹œê°„ ì—…ë°ì´íŠ¸
                    total = self.processing_stats['total_processed']
                    current_avg = self.processing_stats['average_processing_time']
                    self.processing_stats['average_processing_time'] = (
                        (current_avg * (total - 1) + processing_time) / total
                    )
                    
                    return {
                        "success": True,
                        "step_name": step_name,
                        "processed_data": f"mock_processed_{step_name}_{int(time.time())}",
                        "processing_time": processing_time,
                        "device": self.device,
                        "mock_implementation": True
                    }
                    
                except Exception as e:
                    self.processing_stats['total_processed'] += 1
                    self.processing_stats['failed_processed'] += 1
                    
                    return {
                        "success": False,
                        "step_name": step_name,
                        "error": str(e),
                        "processing_time": time.time() - start_time,
                        "mock_implementation": True
                    }
            
            def get_status(self):
                return {
                    "initialized": self.is_initialized,
                    "has_model_loader": self.model_loader is not None,
                    "has_memory_manager": self.memory_manager is not None,
                    "has_function_validator": self.function_validator is not None,
                    "processing_stats": self.processing_stats,
                    "device": self.device,
                    "mock_implementation": True
                }
            
            def cleanup(self):
                if self.memory_manager:
                    self.memory_manager.cleanup()
                
                # í†µê³„ ë¦¬ì…‹
                self.processing_stats = {
                    'total_processed': 0,
                    'successful_processed': 0,
                    'failed_processed': 0,
                    'average_processing_time': 0.0
                }
        
        logger.info("âœ… Mock StepMixin ìƒì„± (í´ë°±)")
        return MockStepMixin()
    
    def _create_mock_function_validator(self):
        """Mock FunctionValidator ìƒì„±"""
        class MockFunctionValidator:
            def __init__(self):
                self.validated_functions = set()
            
            def validate_function(self, func):
                func_name = getattr(func, '__name__', 'unknown')
                self.validated_functions.add(func_name)
                return True
            
            def is_safe_function(self, func_name: str):
                return True
            
            def get_validated_functions(self):
                return list(self.validated_functions)
        
        return MockFunctionValidator()
    
    def _optimize_for_conda(self):
        """conda í™˜ê²½ ìµœì í™” (ë¬¸ì„œ 4 ê¸°ë°˜)"""
        try:
            # í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
            os.environ['OMP_NUM_THREADS'] = str(max(1, os.cpu_count() // 2))
            os.environ['MKL_NUM_THREADS'] = str(max(1, os.cpu_count() // 2))
            os.environ['NUMEXPR_NUM_THREADS'] = str(max(1, os.cpu_count() // 2))
            
            # PyTorch ìµœì í™”
            if TORCH_AVAILABLE:
                import torch
                torch.set_num_threads(max(1, os.cpu_count() // 2))
                
                # M3 Max MPS ìµœì í™”
                if IS_M3_MAX and MPS_AVAILABLE:
                    if hasattr(torch.mps, 'empty_cache'):
                        torch.mps.empty_cache()
                    logger.info("ğŸ M3 Max MPS conda ìµœì í™” ì™„ë£Œ")
            
            logger.info(f"ğŸ conda í™˜ê²½ '{CONDA_ENV}' ìµœì í™” ì™„ë£Œ")
            
        except Exception as e:
            logger.warning(f"âš ï¸ conda ìµœì í™” ì‹¤íŒ¨: {e}")
    
    def _update_dependency_graph(self, key: str, implementation: Any):
        """ì˜ì¡´ì„± ê·¸ë˜í”„ ì—…ë°ì´íŠ¸ (ìˆœí™˜ ì˜ì¡´ì„± ê°ì§€ìš©)"""
        try:
            dependencies = []
            
            if isinstance(implementation, type):
                # ìƒì„±ì íŒŒë¼ë¯¸í„° ë¶„ì„
                import inspect
                sig = inspect.signature(implementation.__init__)
                for param_name, param in sig.parameters.items():
                    if param_name != 'self' and param.annotation != inspect.Parameter.empty:
                        dependencies.append(self._get_key(param.annotation))
            
            self._dependency_graph[key] = dependencies
            
        except Exception as e:
            logger.debug(f"ì˜ì¡´ì„± ê·¸ë˜í”„ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨ ({key}): {e}")
    
    def _execute_lifecycle_hooks(self, event: str, key: str):
        """ìƒëª…ì£¼ê¸° í›… ì‹¤í–‰"""
        try:
            for hook in self._lifecycle_hooks.get(event, []):
                hook(key)
        except Exception as e:
            logger.debug(f"ìƒëª…ì£¼ê¸° í›… ì‹¤í–‰ ì‹¤íŒ¨ ({event}, {key}): {e}")
    
    def add_lifecycle_hook(self, event: str, hook: Callable):
        """ìƒëª…ì£¼ê¸° í›… ì¶”ê°€"""
        if event in self._lifecycle_hooks:
            self._lifecycle_hooks[event].append(hook)
            logger.debug(f"ìƒëª…ì£¼ê¸° í›… ì¶”ê°€: {event}")
    
    def cleanup_memory(self) -> Dict[str, int]:
        """ê³ ê¸‰ ë©”ëª¨ë¦¬ ì •ë¦¬"""
        try:
            with self._lock:
                cleanup_stats = {
                    'weak_refs_cleaned': 0,
                    'singletons_kept': 0,
                    'scoped_instances_cleaned': 0,
                    'gc_collected': 0
                }
                
                # ì•½í•œ ì°¸ì¡° ì •ë¦¬
                dead_refs = [key for key, ref in self._weak_refs.items() if ref() is None]
                for key in dead_refs:
                    del self._weak_refs[key]
                    cleanup_stats['weak_refs_cleaned'] += 1
                
                # í†µê³„ ì—…ë°ì´íŠ¸
                cleanup_stats['singletons_kept'] = len(self._singletons)
                cleanup_stats['scoped_instances_cleaned'] = sum(len(scope) for scope in self._scoped_instances.values())
                
                # ì „ì—­ ë©”ëª¨ë¦¬ ì •ë¦¬
                collected = gc.collect()
                cleanup_stats['gc_collected'] = collected
                
                # M3 Max ë©”ëª¨ë¦¬ ìµœì í™”
                if TORCH_AVAILABLE and IS_M3_MAX and MPS_AVAILABLE:
                    import torch
                    if hasattr(torch.mps, 'empty_cache'):
                        torch.mps.empty_cache()
                        cleanup_stats['mps_cache_cleared'] = True
                
                self._stats['memory_cleanups'] += 1
                
                logger.debug(f"ğŸ§¹ ê³ ê¸‰ ë©”ëª¨ë¦¬ ì •ë¦¬ ì™„ë£Œ: {cleanup_stats}")
                return cleanup_stats
                
        except Exception as e:
            logger.error(f"âŒ ë©”ëª¨ë¦¬ ì •ë¦¬ ì‹¤íŒ¨: {e}")
            return {}
    
    def get_container_info(self) -> Dict[str, Any]:
        """ì»¨í…Œì´ë„ˆ ìƒíƒœ ì •ë³´ (ìƒì„¸)"""
        try:
            with self._lock:
                uptime = time.time() - self._stats['initialization_time']
                
                return {
                    "container_type": "MyCloset AI Optimized DI Container",
                    "version": "3.0_optimal_combined",
                    "uptime_seconds": uptime,
                    "is_initialized": self._initialized,
                    "statistics": dict(self._stats),
                    "registrations": {
                        "total_dependencies": len(self._dependencies),
                        "singleton_instances": len(self._singletons),
                        "transient_services": len(self._services),
                        "factory_functions": len(self._factories),
                        "weak_references": len(self._weak_refs)
                    },
                    "dependency_graph": {
                        "total_nodes": len(self._dependency_graph),
                        "circular_dependencies": self._stats['circular_dependencies_detected']
                    },
                    "lifecycle": {
                        "hooks_registered": sum(len(hooks) for hooks in self._lifecycle_hooks.values())
                    },
                    "environment": {
                        "is_conda": IS_CONDA,
                        "conda_env": CONDA_ENV,
                        "is_m3_max": IS_M3_MAX,
                        "device": DEVICE,
                        "torch_available": TORCH_AVAILABLE,
                        "mps_available": MPS_AVAILABLE
                    },
                    "features": [
                        "MyCloset AI íŠ¹í™”",
                        "ìˆœí™˜ ì˜ì¡´ì„± ê°ì§€",
                        "ìƒëª…ì£¼ê¸° ê´€ë¦¬",
                        "ë©”ëª¨ë¦¬ ë³´í˜¸",
                        "conda ìµœì í™”",
                        "M3 Max ìµœì í™”",
                        "Mock í´ë°± ì§€ì›"
                    ]
                }
        except Exception as e:
            logger.error(f"âŒ ì»¨í…Œì´ë„ˆ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {"error": str(e)}
    
    def get_registered_services(self) -> Dict[str, Dict[str, Any]]:
        """ë“±ë¡ëœ ì„œë¹„ìŠ¤ ëª©ë¡ ì¡°íšŒ (ìƒì„¸)"""
        try:
            with self._lock:
                services = {}
                
                for key, dep_info in self._dependencies.items():
                    services[key] = {
                        'scope': dep_info.scope.value,
                        'has_implementation': dep_info.implementation is not None,
                        'has_factory': dep_info.factory is not None,
                        'has_singleton_instance': key in self._singletons,
                        'access_count': dep_info.access_count,
                        'last_access': dep_info.last_access,
                        'created_at': dep_info.created_at,
                        'is_initialized': dep_info.is_initialized
                    }
                
                return services
                
        except Exception as e:
            logger.error(f"âŒ ì„œë¹„ìŠ¤ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {}
    
    def validate_dependencies(self) -> Dict[str, Any]:
        """ì˜ì¡´ì„± ê²€ì¦ (ìˆœí™˜ ì˜ì¡´ì„± í¬í•¨)"""
        validation_result = {
            "valid": True,
            "errors": [],
            "warnings": [],
            "circular_dependencies": [],
            "missing_dependencies": []
        }
        
        try:
            with self._lock:
                # ìˆœí™˜ ì˜ì¡´ì„± ê²€ì‚¬
                for service, dependencies in self._dependency_graph.items():
                    if self._has_circular_dependency(service, dependencies, []):
                        validation_result["circular_dependencies"].append(service)
                        validation_result["valid"] = False
                
                # ëˆ„ë½ëœ ì˜ì¡´ì„± ê²€ì‚¬
                for service, dependencies in self._dependency_graph.items():
                    for dep in dependencies:
                        if not self.is_registered(dep):
                            validation_result["missing_dependencies"].append({
                                "service": service,
                                "missing_dependency": dep
                            })
                
                if validation_result["circular_dependencies"]:
                    validation_result["errors"].append(
                        f"ìˆœí™˜ ì˜ì¡´ì„± ê°ì§€: {validation_result['circular_dependencies']}"
                    )
                
                if validation_result["missing_dependencies"]:
                    validation_result["warnings"].append(
                        f"ëˆ„ë½ëœ ì˜ì¡´ì„±: {len(validation_result['missing_dependencies'])}ê°œ"
                    )
                
        except Exception as e:
            validation_result["valid"] = False
            validation_result["errors"].append(f"ì˜ì¡´ì„± ê²€ì¦ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        
        return validation_result
    
    def _has_circular_dependency(self, service: str, dependencies: List[str], visited: List[str]) -> bool:
        """ìˆœí™˜ ì˜ì¡´ì„± ê²€ì‚¬"""
        if service in visited:
            return True
        
        visited.append(service)
        
        for dep in dependencies:
            if dep in self._dependency_graph:
                if self._has_circular_dependency(dep, self._dependency_graph[dep], visited.copy()):
                    return True
        
        return False
    
    def _get_key(self, interface: Union[str, Type]) -> str:
        """ì¸í„°í˜ì´ìŠ¤ë¥¼ í‚¤ë¡œ ë³€í™˜"""
        if isinstance(interface, str):
            return interface
        elif hasattr(interface, '__name__'):
            return interface.__name__
        else:
            return str(interface)

# ==============================================
# ğŸ”¥ 5. ê°„ì†Œí™”ëœ DI Container (í˜¸í™˜ì„±ìš©)
# ==============================================

class SimpleDIContainer(IDependencyContainer):
    """ê°„ì†Œí™”ëœ DI Container - ê¸°ë³¸ ê¸°ëŠ¥ë§Œ ì œê³µ (í˜¸í™˜ì„±)"""
    
    def __init__(self):
        self._services: Dict[str, Any] = {}
        self._singletons: Dict[str, Any] = {}
        self._factories: Dict[str, Callable] = {}
        self._lock = threading.RLock()
        
        # ê¸°ë³¸ ì„œë¹„ìŠ¤ ë“±ë¡
        self.register('device', DEVICE, singleton=True)
        self.register('conda_env', CONDA_ENV, singleton=True)
        
        logger.info("âœ… SimpleDIContainer ì´ˆê¸°í™” ì™„ë£Œ")
    
    def register(self, interface: Union[str, Type], implementation: Any, singleton: bool = True) -> None:
        """ê¸°ë³¸ ì˜ì¡´ì„± ë“±ë¡"""
        with self._lock:
            key = self._get_key(interface)
            
            if callable(implementation) and not isinstance(implementation, type):
                self._factories[key] = implementation
            else:
                if singleton:
                    self._singletons[key] = implementation
                else:
                    self._services[key] = implementation
            
            logger.debug(f"âœ… ì˜ì¡´ì„± ë“±ë¡: {key}")
    
    def get(self, interface: Union[str, Type]) -> Optional[Any]:
        """ê¸°ë³¸ ì˜ì¡´ì„± ì¡°íšŒ"""
        with self._lock:
            key = self._get_key(interface)
            
            # ì‹±ê¸€í†¤ ì²´í¬
            if key in self._singletons:
                return self._singletons[key]
            
            # ì¼ë°˜ ì„œë¹„ìŠ¤ ì²´í¬
            if key in self._services:
                return self._services[key]
            
            # íŒ©í† ë¦¬ ì²´í¬
            if key in self._factories:
                try:
                    return self._factories[key]()
                except Exception as e:
                    logger.error(f"âŒ íŒ©í† ë¦¬ ì‹¤í–‰ ì‹¤íŒ¨ {key}: {e}")
                    return None
            
            return None
    
    def is_registered(self, interface: Union[str, Type]) -> bool:
        """ë“±ë¡ ì—¬ë¶€ í™•ì¸"""
        with self._lock:
            key = self._get_key(interface)
            return (key in self._services or 
                   key in self._singletons or 
                   key in self._factories)
    
    def clear(self) -> None:
        """ëª¨ë“  ë“±ë¡ëœ ì„œë¹„ìŠ¤ ì œê±°"""
        with self._lock:
            self._services.clear()
            self._singletons.clear()
            self._factories.clear()
            logger.info("ğŸ§¹ SimpleDIContainer ì •ë¦¬ ì™„ë£Œ")
    
    def _get_key(self, interface: Union[str, Type]) -> str:
        """ì¸í„°í˜ì´ìŠ¤ë¥¼ í‚¤ ë¬¸ìì—´ë¡œ ë³€í™˜"""
        if isinstance(interface, str):
            return interface
        elif hasattr(interface, '__name__'):
            return interface.__name__
        else:
            return str(interface)




# ==============================================
# ğŸ”¥ 4. ì™„ì „í•œ UniversalMemoryManager í´ë˜ìŠ¤ ì¶”ê°€
# ==============================================

class UniversalMemoryManager:
    """
    ğŸ”¥ ë²”ìš© ë©”ëª¨ë¦¬ ê´€ë¦¬ì - ëª¨ë“  WARNING í•´ê²°
    âœ… optimize ë©”ì„œë“œ ì¶”ê°€
    âœ… optimize_memory ë©”ì„œë“œ ì¶”ê°€
    âœ… ê¸°ì¡´ MemoryManagerì™€ í˜¸í™˜
    
    ğŸ“ ì ìš© ë°©ë²•: SimpleDIContainer í´ë˜ìŠ¤ ë°”ë¡œ ë’¤ì— ì¶”ê°€
    """
    
    def __init__(self, base_manager=None):
        self.base_manager = base_manager
        self.device = "mps" if IS_M3_MAX else "cpu"
        self.logger = logging.getLogger(f"{__name__}.UniversalMemoryManager")
        
        self.logger.debug("âœ… UniversalMemoryManager ì´ˆê¸°í™” ì™„ë£Œ")
    
    def optimize(self, aggressive: bool = False) -> Dict[str, Any]:
        """
        ğŸ”¥ í•„ìˆ˜ ë©”ì„œë“œ - optimize
        âœ… WARNING: 'MemoryManager' object has no attribute 'optimize' í•´ê²°
        """
        return self.optimize_memory(aggressive)
    
    def optimize_memory(self, aggressive: bool = False) -> Dict[str, Any]:
        """
        ğŸ”¥ í•„ìˆ˜ ë©”ì„œë“œ - optimize_memory 
        âœ… WARNING: 'MemoryManager' object has no attribute 'optimize_memory' í•´ê²°
        """
        try:
            # ê¸°ì¡´ ë§¤ë‹ˆì € ìš°ì„  ì‚¬ìš©
            if self.base_manager and hasattr(self.base_manager, 'optimize_memory'):
                try:
                    result = self.base_manager.optimize_memory(aggressive)
                    result["adapter"] = "UniversalMemoryManager"
                    return result
                except Exception as e:
                    self.logger.debug(f"ê¸°ì¡´ ë§¤ë‹ˆì € ì‹¤íŒ¨: {e}")
            
            # ë²”ìš© ìµœì í™” ì‹¤í–‰
            return optimize_memory_universal(self)
            
        except Exception as e:
            self.logger.error(f"âŒ UniversalMemoryManager ìµœì í™” ì‹¤íŒ¨: {e}")
            return {
                "success": False,
                "error": str(e),
                "method": "universal_memory_manager",
                "memory_freed_mb": 0
            }
    
    def cleanup(self):
        """ì •ë¦¬ ì‘ì—…"""
        try:
            if self.base_manager and hasattr(self.base_manager, 'cleanup'):
                self.base_manager.cleanup()
            
            self.optimize_memory(aggressive=True)
            self.logger.debug("âœ… UniversalMemoryManager ì •ë¦¬ ì™„ë£Œ")
            
        except Exception as e:
            self.logger.error(f"âŒ UniversalMemoryManager ì •ë¦¬ ì‹¤íŒ¨: {e}")

# ==============================================
# ğŸ”¥ 5. IS_M3_MAX í•¨ìˆ˜ ì¶”ê°€ (ì—†ëŠ” ê²½ìš°ì—ë§Œ)
# ==============================================

def IS_M3_MAX() -> bool:
    """M3 Max ê°ì§€ (ê¸°ì¡´ í•¨ìˆ˜ê°€ ì—†ëŠ” ê²½ìš°ì—ë§Œ ì¶”ê°€)"""
    try:
        if platform.system() == 'Darwin':
            result = subprocess.run(
                ['sysctl', '-n', 'machdep.cpu.brand_string'],
                capture_output=True, text=True, timeout=5
            )
            return 'M3' in result.stdout
    except Exception:
        pass
    return False


# ==============================================
# ğŸ”¥ 6. ì „ì—­ DI Container ê´€ë¦¬
# ==============================================

_global_container: Optional[Union[DIContainer, SimpleDIContainer]] = None
_container_lock = threading.RLock()

def get_di_container(use_simple: bool = False) -> Union[DIContainer, SimpleDIContainer]:
    """ì „ì—­ DI Container ë°˜í™˜"""
    global _global_container
    
    with _container_lock:
        if _global_container is None:
            if use_simple:
                _global_container = SimpleDIContainer()
                logger.info("âœ… SimpleDIContainer ì „ì—­ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±")
            else:
                _global_container = DIContainer()
                _global_container.initialize()
                logger.info("âœ… DIContainer ì „ì—­ ì¸ìŠ¤í„´ìŠ¤ ìƒì„± (ìµœì  ê²°í•©)")
    
    return _global_container

def reset_di_container() -> None:
    """ì „ì—­ DI Container ë¦¬ì…‹"""
    global _global_container
    
    with _container_lock:
        if _global_container:
            if hasattr(_global_container, 'cleanup_memory'):
                _global_container.cleanup_memory()
            elif hasattr(_global_container, 'clear'):
                _global_container.clear()
            
            _global_container = None
            logger.info("ğŸ”„ ì „ì—­ DI Container ë¦¬ì…‹ ì™„ë£Œ")

# ==============================================
# ğŸ”¥ 1. reset_di_container() í•¨ìˆ˜ ë°”ë¡œ ë’¤ì— ì¶”ê°€í•  ì½”ë“œ
# ==============================================

def initialize_di_system() -> bool:
    """
    ğŸ”¥ ëˆ„ë½ëœ í•¨ìˆ˜ - DI ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    âœ… WARNING: cannot import name 'initialize_di_system' í•´ê²°
    """
    try:
        # ì „ì—­ DI Container ì´ˆê¸°í™”
        container = get_di_container()
        
        if container and hasattr(container, 'initialize'):
            success = container.initialize()
            if success:
                logger.info("âœ… DI ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
                return True
        
        logger.warning("âš ï¸ DI Container ì´ˆê¸°í™” ì‹¤íŒ¨")
        return False
        
    except Exception as e:
        logger.error(f"âŒ DI ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return False

def validate_dependencies(dependency_manager) -> Dict[str, Any]:
    """
    ğŸ”¥ ëˆ„ë½ëœ í•¨ìˆ˜ - ì˜ì¡´ì„± ê²€ì¦
    âœ… WARNING: 'EnhancedDependencyManager' object has no attribute 'validate_dependencies' í•´ê²°
    """
    try:
        validation_result = {
            "valid": True,
            "errors": [],
            "warnings": [],
            "checked_dependencies": 0
        }
        
        # ê¸°ë³¸ ì˜ì¡´ì„± ì²´í¬
        if hasattr(dependency_manager, 'dependencies'):
            dependencies = dependency_manager.dependencies
            validation_result["checked_dependencies"] = len(dependencies)
            
            # ê° ì˜ì¡´ì„± ê²€ì¦
            for dep_name, dep_instance in dependencies.items():
                if dep_instance is None:
                    validation_result["warnings"].append(f"ì˜ì¡´ì„± {dep_name}ì´ None")
                    validation_result["valid"] = False
        
        # ModelLoader ê²€ì¦
        if hasattr(dependency_manager, 'dependency_status'):
            status = dependency_manager.dependency_status
            
            if hasattr(status, 'model_loader') and not status.model_loader:
                validation_result["warnings"].append("ModelLoader ë¯¸ì£¼ì…")
            
            if hasattr(status, 'memory_manager') and not status.memory_manager:
                validation_result["warnings"].append("MemoryManager ë¯¸ì£¼ì…")
        
        logger.debug(f"âœ… ì˜ì¡´ì„± ê²€ì¦ ì™„ë£Œ: {validation_result}")
        return validation_result
        
    except Exception as e:
        logger.error(f"âŒ ì˜ì¡´ì„± ê²€ì¦ ì‹¤íŒ¨: {e}")
        return {
            "valid": False,
            "errors": [str(e)],
            "warnings": [],
            "checked_dependencies": 0
        }

def optimize_memory_universal(memory_manager) -> Dict[str, Any]:
    """
    ğŸ”¥ ëˆ„ë½ëœ í•¨ìˆ˜ - ë²”ìš© ë©”ëª¨ë¦¬ ìµœì í™”
    âœ… WARNING: 'MemoryManager' object has no attribute 'optimize' í•´ê²°
    """
    try:
        optimization_result = {
            "success": True,
            "method": "universal_optimization",
            "memory_freed_mb": 0,
            "optimizations_applied": []
        }
        
        # ê¸°ë³¸ ê°€ë¹„ì§€ ì»¬ë ‰ì…˜
        collected = gc.collect()
        optimization_result["memory_freed_mb"] += collected * 0.1  # ì¶”ì •
        optimization_result["optimizations_applied"].append("garbage_collection")
        
        # PyTorch ë©”ëª¨ë¦¬ ìµœì í™”
        try:
            import torch
            
            # M3 Max MPS ìµœì í™”
            if hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
                if hasattr(torch.mps, 'empty_cache'):
                    torch.mps.empty_cache()
                    optimization_result["optimizations_applied"].append("mps_cache_clear")
                    optimization_result["memory_freed_mb"] += 100  # ì¶”ì •
            
            # CUDA ìµœì í™” (í•´ë‹¹ë˜ëŠ” ê²½ìš°)
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
                optimization_result["optimizations_applied"].append("cuda_cache_clear")
                optimization_result["memory_freed_mb"] += 50  # ì¶”ì •
                
        except ImportError:
            optimization_result["optimizations_applied"].append("pytorch_not_available")
        
        # ê¸°ì¡´ optimize_memory ë©”ì„œë“œ ì‹œë„
        if hasattr(memory_manager, 'optimize_memory'):
            try:
                result = memory_manager.optimize_memory()
                if isinstance(result, dict) and result.get("success"):
                    optimization_result["optimizations_applied"].append("manager_optimize_memory")
                    optimization_result["memory_freed_mb"] += result.get("memory_freed_mb", 0)
            except Exception as e:
                logger.debug(f"ê¸°ì¡´ optimize_memory ì‹¤íŒ¨: {e}")
        
        # ê¸°ì¡´ optimize ë©”ì„œë“œ ì‹œë„
        if hasattr(memory_manager, 'optimize'):
            try:
                result = memory_manager.optimize()
                if isinstance(result, dict) and result.get("success"):
                    optimization_result["optimizations_applied"].append("manager_optimize")
                    optimization_result["memory_freed_mb"] += result.get("memory_freed_mb", 0)
            except Exception as e:
                logger.debug(f"ê¸°ì¡´ optimize ì‹¤íŒ¨: {e}")
        
        logger.debug(f"âœ… ë²”ìš© ë©”ëª¨ë¦¬ ìµœì í™” ì™„ë£Œ: {optimization_result}")
        return optimization_result
        
    except Exception as e:
        logger.error(f"âŒ ë²”ìš© ë©”ëª¨ë¦¬ ìµœì í™” ì‹¤íŒ¨: {e}")
        return {
            "success": False,
            "method": "universal_optimization",
            "error": str(e),
            "memory_freed_mb": 0,
            "optimizations_applied": []
        }



# ==============================================
# ğŸ”¥ 7. MyCloset AI íŠ¹í™” í¸ì˜ í•¨ìˆ˜ë“¤
# ==============================================

def inject_dependencies_to_step(step_instance, container: Optional[DIContainer] = None):
    """Step ì¸ìŠ¤í„´ìŠ¤ì— ì˜ì¡´ì„± ì£¼ì… (MyCloset AI íŠ¹í™”)"""
    try:
        if container is None:
            container = get_di_container()
        
        injections_made = 0
        
        # ModelLoader ì£¼ì… (í•„ìˆ˜)
        model_loader = container.get('IModelLoader')
        if model_loader:
            if hasattr(step_instance, 'set_model_loader'):
                step_instance.set_model_loader(model_loader)
                injections_made += 1
            elif hasattr(step_instance, 'model_loader'):
                step_instance.model_loader = model_loader
                injections_made += 1
        
        # MemoryManager ì£¼ì… (ì˜µì…˜)
        memory_manager = container.get('IMemoryManager')
        if memory_manager:
            if hasattr(step_instance, 'set_memory_manager'):
                step_instance.set_memory_manager(memory_manager)
                injections_made += 1
            elif hasattr(step_instance, 'memory_manager'):
                step_instance.memory_manager = memory_manager
                injections_made += 1
        
        # FunctionValidator ì£¼ì… (ì˜µì…˜)
        function_validator = container.get('ISafeFunctionValidator')
        if function_validator:
            if hasattr(step_instance, 'set_function_validator'):
                step_instance.set_function_validator(function_validator)
                injections_made += 1
        
        # ì´ˆê¸°í™”
        if hasattr(step_instance, 'initialize') and not getattr(step_instance, 'is_initialized', False):
            step_instance.initialize()
        
        logger.debug(f"âœ… {step_instance.__class__.__name__} ì˜ì¡´ì„± ì£¼ì… ì™„ë£Œ ({injections_made}ê°œ)")
        
    except Exception as e:
        logger.error(f"âŒ Step ì˜ì¡´ì„± ì£¼ì… ì‹¤íŒ¨: {e}")

def create_step_with_di(step_class: Type, **kwargs) -> Any:
    """ì˜ì¡´ì„± ì£¼ì…ì„ ì‚¬ìš©í•˜ì—¬ Step ì¸ìŠ¤í„´ìŠ¤ ìƒì„±"""
    try:
        # Step ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
        step_instance = step_class(**kwargs)
        
        # ì˜ì¡´ì„± ì£¼ì…
        inject_dependencies_to_step(step_instance)
        
        logger.debug(f"âœ… {step_class.__name__} DI ìƒì„± ì™„ë£Œ")
        return step_instance
        
    except Exception as e:
        logger.error(f"âŒ {step_class.__name__} DI ìƒì„± ì‹¤íŒ¨: {e}")
        # í´ë°±: ì¼ë°˜ ìƒì„±
        return step_class(**kwargs)

def get_service(interface: Union[str, Type]) -> Optional[Any]:
    """í¸ì˜ í•¨ìˆ˜: ì„œë¹„ìŠ¤ ì¡°íšŒ"""
    container = get_di_container()
    return container.get(interface)

def register_service(interface: Union[str, Type], implementation: Any, singleton: bool = True):
    """í¸ì˜ í•¨ìˆ˜: ì„œë¹„ìŠ¤ ë“±ë¡"""
    container = get_di_container()
    container.register(interface, implementation, singleton=singleton)

# ==============================================
# ğŸ”¥ 8. Export
# ==============================================

__all__ = [
    # ë©”ì¸ í´ë˜ìŠ¤ë“¤
    "DIContainer",
    "SimpleDIContainer", 
    "IDependencyContainer",
    
    # ì„¤ì • í´ë˜ìŠ¤ë“¤
    "DependencyScope",
    "DependencyInfo",
    
    # ì „ì—­ í•¨ìˆ˜ë“¤
    "get_di_container",
    "reset_di_container",
    
    # MyCloset AI íŠ¹í™” í•¨ìˆ˜ë“¤
    "inject_dependencies_to_step",
    "create_step_with_di",
    "get_service",
    "register_service",
    

    "initialize_di_system",
    "validate_dependencies", 
    "optimize_memory_universal",
    "UniversalMemoryManager",
    
    # íƒ€ì…ë“¤
    "T"
]

# ==============================================
# ğŸ”¥ 9. ìë™ ì´ˆê¸°í™”
# ==============================================

# conda í™˜ê²½ ìë™ ìµœì í™”
if IS_CONDA:
    logger.info(f"ğŸ conda í™˜ê²½ '{CONDA_ENV}' ê°ì§€ - ìë™ ìµœì í™” ì¤€ë¹„")
    
    # í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
    os.environ.setdefault('OMP_NUM_THREADS', str(max(1, os.cpu_count() // 2)))
    os.environ.setdefault('MKL_NUM_THREADS', str(max(1, os.cpu_count() // 2)))

# ì™„ë£Œ ë©”ì‹œì§€
logger.info("âœ… DI Container v3.0 ë¡œë“œ ì™„ë£Œ (ìµœì  ê²°í•© ë²„ì „)!")
logger.info("ğŸ”— MyCloset AI íŠ¹í™” + í”„ë¡œë•ì…˜ê¸‰ ê¸°ëŠ¥")
logger.info("âš¡ ìˆœí™˜ ì˜ì¡´ì„± ê°ì§€ ë° ë°©ì§€")
logger.info("ğŸ§µ ìŠ¤ë ˆë“œ ì•ˆì „ì„± ë° ë©”ëª¨ë¦¬ ë³´í˜¸") 
logger.info("ğŸ­ Mock í´ë°± êµ¬í˜„ì²´ í¬í•¨")
logger.info("ğŸ conda í™˜ê²½ ìš°ì„  ìµœì í™”")

if IS_M3_MAX:
    logger.info("ğŸ M3 Max 128GB ë©”ëª¨ë¦¬ ìµœì í™” í™œì„±í™”")

logger.info("ğŸš€ DI Container v3.0 ì¤€ë¹„ ì™„ë£Œ!")