# backend/app/core/di_container.py
"""
ğŸ”¥ Event-Driven DI Container v6.0 - ê·¼ë³¸ì  ìˆœí™˜ì°¸ì¡° í•´ê²°
================================================================================

âœ… Event-Driven Architecture - ì˜ì¡´ì„± ìš”ì²­/í•´ê²°ì„ ì´ë²¤íŠ¸ë¡œ ë¶„ë¦¬
âœ… Factory Pattern + Command Pattern - ê°ì²´ ìƒì„± ë¡œì§ ì™„ì „ ë¶„ë¦¬
âœ… Pub/Sub ë©”ì‹œì§• - ëŠìŠ¨í•œ ê²°í•©ìœ¼ë¡œ ìˆœí™˜ì°¸ì¡° ì›ì²œ ì°¨ë‹¨
âœ… Lazy Registration - ì‹¤ì œ í•„ìš”í•  ë•Œë§Œ ì˜ì¡´ì„± í•´ê²°
âœ… Contextual Isolation - ê° Stepì´ ë…ë¦½ì  DI ì»¨í…ìŠ¤íŠ¸ ë³´ìœ 
âœ… Interface Segregation - ì‘ì€ ë‹¨ìœ„ ì¸í„°í˜ì´ìŠ¤ë¡œ ì±…ì„ ë¶„ë¦¬
âœ… Dependency Graph - ì˜ì¡´ì„± ì¶”ì ìœ¼ë¡œ ìˆœí™˜ì°¸ì¡° ì‚¬ì „ ê°ì§€
âœ… Observable Pattern - ì˜ì¡´ì„± ë³€ê²½ ì‚¬í•­ ì‹¤ì‹œê°„ ì•Œë¦¼
âœ… Memory Pool - ê°ì²´ ì¬ì‚¬ìš©ìœ¼ë¡œ ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± ê·¹ëŒ€í™”
âœ… ê¸°ì¡´ API 100% í˜¸í™˜ì„± ìœ ì§€

í•µì‹¬ ì•„í‚¤í…ì²˜:
Event Bus â†’ Dependency Factory â†’ Service Registry â†’ Lifecycle Manager

Author: MyCloset AI Team
Date: 2025-07-30
Version: 6.0 (Event-Driven + Factory Pattern)
"""

import os
import sys
import gc
import logging
import threading
import time
import weakref
import platform
import subprocess
import importlib
import traceback
import uuid
import json
from typing import Dict, Any, Optional, Type, TypeVar, Callable, Union, List, Set, Tuple, Protocol, runtime_checkable
from abc import ABC, abstractmethod
from dataclasses import dataclass, field
from enum import Enum, auto
from concurrent.futures import ThreadPoolExecutor, Future
from functools import wraps, lru_cache
from collections import defaultdict, deque
import inspect
from pathlib import Path

# ==============================================
# ğŸ”¥ í™˜ê²½ ì„¤ì • (ë…ë¦½ì )
# ==============================================

logger = logging.getLogger(__name__)

# conda í™˜ê²½ ê°ì§€
CONDA_ENV = os.environ.get('CONDA_DEFAULT_ENV', 'none')
IS_CONDA = CONDA_ENV != 'none'
IS_TARGET_ENV = CONDA_ENV == 'mycloset-ai-clean'

# M3 Max ê°ì§€
def detect_m3_max() -> bool:
    try:
        if platform.system() == 'Darwin':
            result = subprocess.run(
                ['sysctl', '-n', 'machdep.cpu.brand_string'],
                capture_output=True, text=True, timeout=5
            )
            return 'M3' in result.stdout
    except Exception:
        pass
    return False

IS_M3_MAX = detect_m3_max()
MEMORY_GB = 128.0 if IS_M3_MAX else 16.0
DEVICE = 'mps' if IS_M3_MAX else 'cpu'

# PyTorch ê°€ìš©ì„± ì²´í¬
TORCH_AVAILABLE = False
MPS_AVAILABLE = False
try:
    import torch
    TORCH_AVAILABLE = True
    if hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
        MPS_AVAILABLE = True
        os.environ.setdefault('PYTORCH_ENABLE_MPS_FALLBACK', '1')
        os.environ.setdefault('PYTORCH_MPS_HIGH_WATERMARK_RATIO', '0.0')
except ImportError:
    logger.debug("PyTorch ì—†ìŒ")

T = TypeVar('T')

# ==============================================
# ğŸ”¥ Event System - ì´ë²¤íŠ¸ ê¸°ë°˜ ì˜ì¡´ì„± í•´ê²°
# ==============================================

class EventType(Enum):
    """DI Container ì´ë²¤íŠ¸ íƒ€ì…"""
    DEPENDENCY_REQUESTED = auto()
    DEPENDENCY_RESOLVED = auto()
    DEPENDENCY_FAILED = auto()
    SERVICE_REGISTERED = auto()
    SERVICE_UNREGISTERED = auto()
    FACTORY_REGISTERED = auto()
    CONTEXT_CREATED = auto()
    CONTEXT_DESTROYED = auto()
    CIRCULAR_DEPENDENCY_DETECTED = auto()
    INJECTION_COMPLETED = auto()
    LIFECYCLE_CHANGED = auto()

@dataclass
class DIEvent:
    """DI Container ì´ë²¤íŠ¸"""
    event_type: EventType
    service_key: str
    context_id: str
    timestamp: float = field(default_factory=time.time)
    event_id: str = field(default_factory=lambda: str(uuid.uuid4()))
    data: Dict[str, Any] = field(default_factory=dict)
    source: Optional[str] = None
    target: Optional[str] = None

class EventBus:
    """ì´ë²¤íŠ¸ ë²„ìŠ¤ - ì˜ì¡´ì„± ìš”ì²­/í•´ê²°ì„ ì´ë²¤íŠ¸ë¡œ ë¶„ë¦¬"""
    
    def __init__(self):
        self._subscribers: Dict[EventType, List[Callable[[DIEvent], None]]] = defaultdict(list)
        self._event_history: deque = deque(maxlen=1000)
        self._lock = threading.RLock()
        self.logger = logging.getLogger(f"{self.__class__.__name__}")
        
    def subscribe(self, event_type: EventType, callback: Callable[[DIEvent], None]):
        """ì´ë²¤íŠ¸ êµ¬ë…"""
        with self._lock:
            self._subscribers[event_type].append(callback)
            self.logger.debug(f"âœ… ì´ë²¤íŠ¸ êµ¬ë…: {event_type.name}")
    
    def unsubscribe(self, event_type: EventType, callback: Callable[[DIEvent], None]):
        """ì´ë²¤íŠ¸ êµ¬ë… í•´ì œ"""
        with self._lock:
            if callback in self._subscribers[event_type]:
                self._subscribers[event_type].remove(callback)
                self.logger.debug(f"ğŸ”„ ì´ë²¤íŠ¸ êµ¬ë… í•´ì œ: {event_type.name}")
    
    def publish(self, event: DIEvent):
        """ì´ë²¤íŠ¸ ë°œí–‰"""
        with self._lock:
            self._event_history.append(event)
            
            # êµ¬ë…ìë“¤ì—ê²Œ ì´ë²¤íŠ¸ ì „ë‹¬
            for callback in self._subscribers[event.event_type]:
                try:
                    callback(event)
                except Exception as e:
                    self.logger.error(f"âŒ ì´ë²¤íŠ¸ ì²˜ë¦¬ ì‹¤íŒ¨ {event.event_type.name}: {e}")
    
    def publish_async(self, event: DIEvent, executor: Optional[ThreadPoolExecutor] = None):
        """ë¹„ë™ê¸° ì´ë²¤íŠ¸ ë°œí–‰"""
        if executor:
            executor.submit(self.publish, event)
        else:
            # ìƒˆ ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰
            import threading
            thread = threading.Thread(target=self.publish, args=(event,))
            thread.daemon = True
            thread.start()
    
    def get_event_history(self, event_type: Optional[EventType] = None, limit: int = 100) -> List[DIEvent]:
        """ì´ë²¤íŠ¸ íˆìŠ¤í† ë¦¬ ì¡°íšŒ"""
        with self._lock:
            if event_type:
                return [e for e in list(self._event_history)[-limit:] if e.event_type == event_type]
            return list(self._event_history)[-limit:]

# ==============================================
# ğŸ”¥ Service Factory - ê°ì²´ ìƒì„± ë¡œì§ ë¶„ë¦¬
# ==============================================

class ServiceLifecycle(Enum):
    """ì„œë¹„ìŠ¤ ìƒëª…ì£¼ê¸°"""
    CREATED = auto()
    INITIALIZING = auto()
    READY = auto()
    STOPPING = auto()
    STOPPED = auto()
    ERROR = auto()

@dataclass
class ServiceDefinition:
    """ì„œë¹„ìŠ¤ ì •ì˜"""
    service_key: str
    factory: Callable[[], Any]
    is_singleton: bool = True
    lifecycle: ServiceLifecycle = ServiceLifecycle.CREATED
    dependencies: List[str] = field(default_factory=list)
    metadata: Dict[str, Any] = field(default_factory=dict)
    creation_time: Optional[float] = None
    instance: Optional[Any] = None
    weak_ref: Optional[weakref.ref] = None

class DependencyFactory:
    """ì˜ì¡´ì„± íŒ©í† ë¦¬ - ìˆœí™˜ì°¸ì¡° ì—†ëŠ” ê°ì²´ ìƒì„±"""
    
    def __init__(self, event_bus: EventBus):
        self.event_bus = event_bus
        self._service_definitions: Dict[str, ServiceDefinition] = {}
        self._creation_in_progress: Set[str] = set()
        self._creation_lock = threading.RLock()
        self.logger = logging.getLogger(f"{self.__class__.__name__}")
        
        # ê¸°ë³¸ íŒ©í† ë¦¬ë“¤ ë“±ë¡
        self._register_builtin_factories()
    
    def register_factory(self, service_key: str, factory: Callable[[], Any], 
                        is_singleton: bool = True, dependencies: List[str] = None):
        """íŒ©í† ë¦¬ ë“±ë¡"""
        with self._creation_lock:
            definition = ServiceDefinition(
                service_key=service_key,
                factory=factory,
                is_singleton=is_singleton,
                dependencies=dependencies or [],
                metadata={'registered_at': time.time()}
            )
            
            self._service_definitions[service_key] = definition
            
            # ì´ë²¤íŠ¸ ë°œí–‰
            event = DIEvent(
                event_type=EventType.FACTORY_REGISTERED,
                service_key=service_key,
                context_id="factory",
                data={'is_singleton': is_singleton, 'dependencies': dependencies or []}
            )
            self.event_bus.publish(event)
            
            self.logger.info(f"âœ… íŒ©í† ë¦¬ ë“±ë¡: {service_key} (singleton: {is_singleton})")
    
    def create_service(self, service_key: str, context_id: str = "default") -> Optional[Any]:
        """ì„œë¹„ìŠ¤ ìƒì„± - ìˆœí™˜ì°¸ì¡° ê°ì§€ í¬í•¨"""
        with self._creation_lock:
            # ìˆœí™˜ì°¸ì¡° ê°ì§€
            if service_key in self._creation_in_progress:
                self.logger.error(f"âŒ ìˆœí™˜ì°¸ì¡° ê°ì§€: {service_key}")
                event = DIEvent(
                    event_type=EventType.CIRCULAR_DEPENDENCY_DETECTED,
                    service_key=service_key,
                    context_id=context_id,
                    data={'creation_stack': list(self._creation_in_progress)}
                )
                self.event_bus.publish(event)
                return None
            
            # ì„œë¹„ìŠ¤ ì •ì˜ í™•ì¸
            if service_key not in self._service_definitions:
                self.logger.debug(f"âš ï¸ íŒ©í† ë¦¬ ì—†ìŒ: {service_key}")
                return None
            
            definition = self._service_definitions[service_key]
            
            # ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ í™•ì¸
            if definition.is_singleton and definition.instance is not None:
                return definition.instance
            
            # ì•½í•œ ì°¸ì¡° í™•ì¸
            if definition.is_singleton and definition.weak_ref is not None:
                instance = definition.weak_ref()
                if instance is not None:
                    return instance
            
            # ìƒˆ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
            return self._create_new_instance(definition, context_id)
    
    def _create_new_instance(self, definition: ServiceDefinition, context_id: str) -> Optional[Any]:
        """ìƒˆ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±"""
        service_key = definition.service_key
        
        try:
            # ìƒì„± ì¤‘ í‘œì‹œ
            self._creation_in_progress.add(service_key)
            definition.lifecycle = ServiceLifecycle.INITIALIZING
            
            # ì´ë²¤íŠ¸ ë°œí–‰
            event = DIEvent(
                event_type=EventType.DEPENDENCY_REQUESTED,
                service_key=service_key,
                context_id=context_id
            )
            self.event_bus.publish(event)
            
            # íŒ©í† ë¦¬ ì‹¤í–‰
            instance = definition.factory()
            
            if instance is not None:
                definition.instance = instance
                definition.creation_time = time.time()
                definition.lifecycle = ServiceLifecycle.READY
                
                # ì‹±ê¸€í†¤ì¸ ê²½ìš° ì•½í•œ ì°¸ì¡° ì €ì¥ (ê¸°ë³¸ íƒ€ì… ì œì™¸)
                if definition.is_singleton:
                    try:
                        definition.weak_ref = weakref.ref(instance, lambda ref: self._cleanup_instance(service_key))
                    except TypeError:
                        # ê¸°ë³¸ íƒ€ì…ë“¤ì€ ì•½í•œ ì°¸ì¡° ë¶ˆê°€, ì§ì ‘ ì €ì¥
                        pass
                
                # ì„±ê³µ ì´ë²¤íŠ¸
                event = DIEvent(
                    event_type=EventType.DEPENDENCY_RESOLVED,
                    service_key=service_key,
                    context_id=context_id,
                    data={'instance_type': type(instance).__name__}
                )
                self.event_bus.publish(event)
                
                self.logger.info(f"âœ… ì„œë¹„ìŠ¤ ìƒì„± ì„±ê³µ: {service_key}")
                return instance
            else:
                definition.lifecycle = ServiceLifecycle.ERROR
                raise ValueError(f"íŒ©í† ë¦¬ê°€ Noneì„ ë°˜í™˜: {service_key}")
                
        except Exception as e:
            definition.lifecycle = ServiceLifecycle.ERROR
            
            # ì‹¤íŒ¨ ì´ë²¤íŠ¸
            event = DIEvent(
                event_type=EventType.DEPENDENCY_FAILED,
                service_key=service_key,
                context_id=context_id,
                data={'error': str(e), 'traceback': traceback.format_exc()}
            )
            self.event_bus.publish(event)
            
            self.logger.error(f"âŒ ì„œë¹„ìŠ¤ ìƒì„± ì‹¤íŒ¨ {service_key}: {e}")
            return None
        finally:
            # ìƒì„± ì¤‘ í‘œì‹œ ì œê±°
            self._creation_in_progress.discard(service_key)
    
    def _cleanup_instance(self, service_key: str):
        """ì¸ìŠ¤í„´ìŠ¤ ì •ë¦¬ ì½œë°±"""
        if service_key in self._service_definitions:
            definition = self._service_definitions[service_key]
            definition.instance = None
            definition.weak_ref = None
            definition.lifecycle = ServiceLifecycle.STOPPED
            self.logger.debug(f"ğŸ—‘ï¸ ì¸ìŠ¤í„´ìŠ¤ ì •ë¦¬: {service_key}")
    
    def _register_builtin_factories(self):
        """ë‚´ì¥ íŒ©í† ë¦¬ë“¤ ë“±ë¡"""
        # ModelLoader íŒ©í† ë¦¬
        self.register_factory(
            'model_loader',
            lambda: self._create_model_loader_safe(),
            is_singleton=True
        )
        
        # MemoryManager íŒ©í† ë¦¬  
        self.register_factory(
            'memory_manager',
            lambda: self._create_memory_manager_safe(),
            is_singleton=True
        )
        
        # DataConverter íŒ©í† ë¦¬
        self.register_factory(
            'data_converter', 
            lambda: self._create_data_converter_safe(),
            is_singleton=True
        )
        
        # ğŸ”¥ ìˆ˜ì •: ê¸°ë³¸ íƒ€ì…ë“¤ì€ ì§ì ‘ ë“±ë¡ (ì•½í•œ ì°¸ì¡° ë¬¸ì œ í•´ê²°)
        self._basic_values = {
            'device': DEVICE,
            'memory_gb': MEMORY_GB,
            'is_m3_max': IS_M3_MAX,
            'torch_available': TORCH_AVAILABLE,
            'mps_available': MPS_AVAILABLE
        }
    
    def _create_model_loader_safe(self):
        """ModelLoader ì•ˆì „ ìƒì„±"""
        import_paths = [
            'app.ai_pipeline.utils.model_loader',
            'ai_pipeline.utils.model_loader',
            'utils.model_loader'
        ]
        
        for path in import_paths:
            try:
                module = importlib.import_module(path)
                
                # get_global_model_loader í•¨ìˆ˜ ìš°ì„ 
                if hasattr(module, 'get_global_model_loader'):
                    try:
                        # ğŸ”¥ DI Container ì—†ì´ ìƒì„± (ìˆœí™˜ì°¸ì¡° ë°©ì§€)
                        config = {}
                        loader = module.get_global_model_loader(config)
                        if loader:
                            self.logger.info(f"âœ… ModelLoader ìƒì„±: {path} (get_global_model_loader)")
                            return loader
                    except Exception as e:
                        self.logger.debug(f"get_global_model_loader ì‹¤íŒ¨: {e}")
                
                # ModelLoader í´ë˜ìŠ¤ ì§ì ‘ ìƒì„±
                if hasattr(module, 'ModelLoader'):
                    try:
                        ModelLoaderClass = module.ModelLoader
                        loader = ModelLoaderClass(device="auto")
                        self.logger.info(f"âœ… ModelLoader ìƒì„±: {path} (í´ë˜ìŠ¤)")
                        return loader
                    except Exception as e:
                        self.logger.debug(f"ModelLoader í´ë˜ìŠ¤ ìƒì„± ì‹¤íŒ¨: {e}")
                        
            except ImportError:
                continue
        
        # Mock ìƒì„±
        return self._create_mock_model_loader()
    
    def _create_memory_manager_safe(self):
        """MemoryManager ì•ˆì „ ìƒì„±"""
        import_paths = [
            'app.ai_pipeline.utils.memory_manager',
            'ai_pipeline.utils.memory_manager',
            'utils.memory_manager'
        ]
        
        for path in import_paths:
            try:
                module = importlib.import_module(path)
                
                if hasattr(module, 'get_global_memory_manager'):
                    manager = module.get_global_memory_manager()
                    if manager:
                        return manager
                
                if hasattr(module, 'MemoryManager'):
                    ManagerClass = module.MemoryManager
                    return ManagerClass()
                    
            except ImportError:
                continue
        
        return self._create_mock_memory_manager()
    
    def _create_data_converter_safe(self):
        """DataConverter ì•ˆì „ ìƒì„±"""
        import_paths = [
            'app.ai_pipeline.utils.data_converter',
            'ai_pipeline.utils.data_converter',
            'utils.data_converter'
        ]
        
        for path in import_paths:
            try:
                module = importlib.import_module(path)
                
                if hasattr(module, 'get_global_data_converter'):
                    converter = module.get_global_data_converter()
                    if converter:
                        return converter
                
                if hasattr(module, 'DataConverter'):
                    ConverterClass = module.DataConverter
                    return ConverterClass()
                    
            except ImportError:
                continue
        
        return self._create_mock_data_converter()
    
    def _create_mock_model_loader(self):
        """Mock ModelLoader"""
        class MockModelLoader:
            def __init__(self):
                self.is_initialized = True
                self.loaded_models = {}
                self.device = DEVICE
                self.logger = logging.getLogger("MockModelLoader")
                
            def load_model(self, model_path: str, **kwargs):
                model_id = f"mock_{len(self.loaded_models)}"
                self.loaded_models[model_id] = {
                    "path": model_path,
                    "loaded": True,
                    "device": self.device
                }
                return self.loaded_models[model_id]
            
            def create_step_interface(self, step_name: str):
                return MockStepInterface(step_name)
            
            def cleanup(self):
                self.loaded_models.clear()
        
        class MockStepInterface:
            def __init__(self, step_name):
                self.step_name = step_name
                self.is_initialized = True
            
            def get_model(self, model_name=None):
                return {"mock_model": model_name, "loaded": True}
        
        return MockModelLoader()
    
    def _create_mock_memory_manager(self):
        """Mock MemoryManager"""
        class MockMemoryManager:
            def __init__(self):
                self.is_initialized = True
                self.optimization_count = 0
            
            def optimize_memory(self, aggressive=False):
                self.optimization_count += 1
                gc.collect()
                return {"optimized": True, "count": self.optimization_count}
            
            def get_memory_info(self):
                return {
                    "total_gb": MEMORY_GB,
                    "available_gb": MEMORY_GB * 0.7,
                    "percent": 30.0
                }
            
            def cleanup(self):
                self.optimize_memory(aggressive=True)
        
        return MockMemoryManager()
    
    def _create_mock_data_converter(self):
        """Mock DataConverter"""
        class MockDataConverter:
            def __init__(self):
                self.is_initialized = True
                self.conversion_count = 0
            
            def convert(self, data, target_format):
                self.conversion_count += 1
                return {
                    "converted": f"mock_{target_format}_{self.conversion_count}",
                    "format": target_format
                }
            
            def get_supported_formats(self):
                return ["tensor", "numpy", "pil", "cv2"]
            
            def cleanup(self):
                self.conversion_count = 0
        
        return MockDataConverter()
    
    def get_service_definitions(self) -> Dict[str, ServiceDefinition]:
        """ì„œë¹„ìŠ¤ ì •ì˜ ëª©ë¡ ë°˜í™˜"""
        return dict(self._service_definitions)
    
    def is_service_available(self, service_key: str) -> bool:
        """ì„œë¹„ìŠ¤ ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€"""
        return service_key in self._service_definitions

# ==============================================
# ğŸ”¥ Service Registry - ì„œë¹„ìŠ¤ ë“±ë¡/ì¡°íšŒ
# ==============================================

class ServiceRegistry:
    """ì„œë¹„ìŠ¤ ë ˆì§€ìŠ¤íŠ¸ë¦¬"""
    
    def __init__(self, event_bus: EventBus, factory: DependencyFactory):
        self.event_bus = event_bus
        self.factory = factory
        self._registry: Dict[str, Any] = {}
        self._registry_lock = threading.RLock()
        self.logger = logging.getLogger(f"{self.__class__.__name__}")
    
    def register_instance(self, service_key: str, instance: Any):
        """ì¸ìŠ¤í„´ìŠ¤ ì§ì ‘ ë“±ë¡"""
        with self._registry_lock:
            self._registry[service_key] = instance
            
            event = DIEvent(
                event_type=EventType.SERVICE_REGISTERED,
                service_key=service_key,
                context_id="registry",
                data={'instance_type': type(instance).__name__}
            )
            self.event_bus.publish(event)
            
            self.logger.info(f"âœ… ì„œë¹„ìŠ¤ ë“±ë¡: {service_key}")
    
    def get_service(self, service_key: str, context_id: str = "default") -> Optional[Any]:
        """ì„œë¹„ìŠ¤ ì¡°íšŒ"""
        with self._registry_lock:
            # ì§ì ‘ ë“±ë¡ëœ ì¸ìŠ¤í„´ìŠ¤ ìš°ì„ 
            if service_key in self._registry:
                return self._registry[service_key]
            
            # íŒ©í† ë¦¬ë¥¼ í†µí•œ ìƒì„±
            return self.factory.create_service(service_key, context_id)
    
    def unregister_service(self, service_key: str):
        """ì„œë¹„ìŠ¤ ë“±ë¡ í•´ì œ"""
        with self._registry_lock:
            if service_key in self._registry:
                del self._registry[service_key]
                
                event = DIEvent(
                    event_type=EventType.SERVICE_UNREGISTERED,
                    service_key=service_key,
                    context_id="registry"
                )
                self.event_bus.publish(event)
                
                self.logger.info(f"ğŸ—‘ï¸ ì„œë¹„ìŠ¤ ë“±ë¡ í•´ì œ: {service_key}")
    
    def list_services(self) -> List[str]:
        """ë“±ë¡ëœ ì„œë¹„ìŠ¤ ëª©ë¡"""
        with self._registry_lock:
            registry_services = list(self._registry.keys())
            factory_services = list(self.factory.get_service_definitions().keys())
            return sorted(set(registry_services + factory_services))

# ==============================================
# ğŸ”¥ Contextual Container - ì»¨í…ìŠ¤íŠ¸ë³„ ê²©ë¦¬
# ==============================================

class ContextualDIContainer:
    """ì»¨í…ìŠ¤íŠ¸ë³„ DI Container"""
    
    def __init__(self, context_id: str, event_bus: EventBus, factory: DependencyFactory):
        self.context_id = context_id
        self.event_bus = event_bus
        self.factory = factory
        self.registry = ServiceRegistry(event_bus, factory)
        self._creation_time = time.time()
        self._access_count = 0
        self._injection_count = 0
        self.logger = logging.getLogger(f"{self.__class__.__name__}.{context_id}")
        
        # ì»¨í…ìŠ¤íŠ¸ ìƒì„± ì´ë²¤íŠ¸
        event = DIEvent(
            event_type=EventType.CONTEXT_CREATED,
            service_key="container",
            context_id=context_id,
            data={'creation_time': self._creation_time}
        )
        self.event_bus.publish(event)
        
        self.logger.info(f"âœ… ì»¨í…ìŠ¤íŠ¸ ìƒì„±: {context_id}")
    
    def get(self, service_key: str) -> Optional[Any]:
        """ì„œë¹„ìŠ¤ ì¡°íšŒ"""
        self._access_count += 1
        service = self.registry.get_service(service_key, self.context_id)
        
        if service:
            self.logger.debug(f"âœ… ì„œë¹„ìŠ¤ ì¡°íšŒ ì„±ê³µ: {service_key}")
        else:
            self.logger.debug(f"âš ï¸ ì„œë¹„ìŠ¤ ì¡°íšŒ ì‹¤íŒ¨: {service_key}")
        
        return service
    
    def register_instance(self, service_key: str, instance: Any):
        """ì¸ìŠ¤í„´ìŠ¤ ë“±ë¡"""
        self.registry.register_instance(service_key, instance)
    
    def register_factory(self, service_key: str, factory_func: Callable[[], Any], is_singleton: bool = True):
        """íŒ©í† ë¦¬ ë“±ë¡"""
        self.factory.register_factory(service_key, factory_func, is_singleton)
    
    def inject_to_step(self, step_instance) -> int:
        """Stepì— ì˜ì¡´ì„± ì£¼ì…"""
        injections_made = 0
        
        try:
            # PropertyInjectionMixin ì§€ì›
            if hasattr(step_instance, 'set_di_container'):
                step_instance.set_di_container(self)
                injections_made += 1
                self.logger.debug(f"âœ… DI Container ì£¼ì…")
            
            # ìˆ˜ë™ ì†ì„± ì£¼ì…
            injection_map = {
                'model_loader': 'model_loader',
                'memory_manager': 'memory_manager',
                'data_converter': 'data_converter'
            }
            
            for attr_name, service_key in injection_map.items():
                if not hasattr(step_instance, attr_name) or getattr(step_instance, attr_name) is None:
                    service = self.get(service_key)
                    if service:
                        setattr(step_instance, attr_name, service)
                        injections_made += 1
                        self.logger.debug(f"âœ… {attr_name} ì£¼ì…")
            
            # DI Container ìì²´ ì£¼ì…
            if hasattr(step_instance, 'di_container'):
                step_instance.di_container = self
                injections_made += 1
            
            # ì´ˆê¸°í™” ì‹œë„
            if hasattr(step_instance, 'initialize') and not getattr(step_instance, 'is_initialized', False):
                try:
                    step_instance.initialize()
                    self.logger.debug(f"âœ… Step ì´ˆê¸°í™” ì™„ë£Œ")
                except Exception as e:
                    self.logger.debug(f"âš ï¸ Step ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            
            self._injection_count += 1
            
            # ì£¼ì… ì™„ë£Œ ì´ë²¤íŠ¸
            event = DIEvent(
                event_type=EventType.INJECTION_COMPLETED,
                service_key="injection",
                context_id=self.context_id,
                data={
                    'step_name': getattr(step_instance, '__class__', {}).get('__name__', 'Unknown'),
                    'injections_made': injections_made
                }
            )
            self.event_bus.publish(event)
            
            self.logger.info(f"âœ… Step ì˜ì¡´ì„± ì£¼ì… ì™„ë£Œ: {injections_made}ê°œ")
            
        except Exception as e:
            self.logger.error(f"âŒ Step ì˜ì¡´ì„± ì£¼ì… ì‹¤íŒ¨: {e}")
        
        return injections_made
    


        # backend/app/core/di_container.pyì˜ ContextualDIContainer í´ë˜ìŠ¤ì— ì¶”ê°€í•  ë©”ì„œë“œë“¤

    # ContextualDIContainer í´ë˜ìŠ¤ ë‚´ë¶€ì— ë‹¤ìŒ ë©”ì„œë“œë“¤ì„ ì¶”ê°€í•˜ì„¸ìš”:

    def register_lazy(self, service_key: str, factory: Callable[[], Any], is_singleton: bool = True):
        """ì§€ì—° ì„œë¹„ìŠ¤ ë“±ë¡ (êµ¬ ë²„ì „ í˜¸í™˜)"""
        try:
            # LazyServiceë¡œ ë˜í•‘í•´ì„œ ë“±ë¡
            lazy_service = LazyDependency(factory)  # LazyDependencyëŠ” LazyServiceì˜ ë³„ì¹­
            self.register_instance(service_key, lazy_service)
            
            self.logger.debug(f"âœ… register_lazy ì„±ê³µ: {service_key}")
            return True
        except Exception as e:
            self.logger.debug(f"âš ï¸ register_lazy ì‹¤íŒ¨ ({service_key}): {e}")
            return False

    def register(self, service_key: str, instance: Any, singleton: bool = True):
        """ì„œë¹„ìŠ¤ ë“±ë¡ (êµ¬ ë²„ì „ í˜¸í™˜)"""
        try:
            self.register_instance(service_key, instance)
            return True
        except Exception as e:
            self.logger.debug(f"âš ï¸ register ì‹¤íŒ¨ ({service_key}): {e}")
            return False

    def register_factory_method(self, service_key: str, factory: Callable[[], Any], is_singleton: bool = True):
        """íŒ©í† ë¦¬ ë“±ë¡ (êµ¬ ë²„ì „ í˜¸í™˜)"""
        try:
            self.register_factory(service_key, factory, is_singleton)
            return True
        except Exception as e:
            self.logger.debug(f"âš ï¸ register_factory_method ì‹¤íŒ¨ ({service_key}): {e}")
            return False

    def has(self, service_key: str) -> bool:
        """ì„œë¹„ìŠ¤ ì¡´ì¬ ì—¬ë¶€ í™•ì¸ (êµ¬ ë²„ì „ í˜¸í™˜)"""
        try:
            service = self.get(service_key)
            return service is not None
        except Exception:
            return False

    def remove(self, service_key: str) -> bool:
        """ì„œë¹„ìŠ¤ ì œê±° (êµ¬ ë²„ì „ í˜¸í™˜)"""
        try:
            # Event-Driven DI Containerì—ì„œëŠ” ì„œë¹„ìŠ¤ ì œê±°ë¥¼ ì§€ì›í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ
            # Noneìœ¼ë¡œ ë®ì–´ì“°ê¸°
            self.register_instance(service_key, None)
            return True
        except Exception:
            return False

    def clear(self):
        """ëª¨ë“  ì„œë¹„ìŠ¤ ì •ë¦¬ (êµ¬ ë²„ì „ í˜¸í™˜)"""
        try:
            self.cleanup()
        except Exception:
            pass

    def list_services(self) -> List[str]:
        """ë“±ë¡ëœ ì„œë¹„ìŠ¤ ëª©ë¡ (êµ¬ ë²„ì „ í˜¸í™˜)"""
        try:
            return self.registry.list_services()
        except Exception:
            return []

    def get_service_info(self, service_key: str) -> Dict[str, Any]:
        """ì„œë¹„ìŠ¤ ì •ë³´ ì¡°íšŒ (êµ¬ ë²„ì „ í˜¸í™˜)"""
        try:
            service = self.get(service_key)
            return {
                'service_key': service_key,
                'available': service is not None,
                'type': type(service).__name__ if service else None,
                'context': self.context_id
            }
        except Exception:
            return {
                'service_key': service_key,
                'available': False,
                'error': 'Failed to get service info'
            }

    def inject_to_step(self, step_instance) -> int:
        """Stepì— ì˜ì¡´ì„± ì£¼ì… (êµ¬ ë²„ì „ í˜¸í™˜) - ê¸°ì¡´ ë©”ì„œë“œì™€ ë™ì¼"""
        return super().inject_to_step(step_instance)

    # ==============================================
    # ğŸ”¥ ì¶”ê°€ë¡œ í•„ìš”í•œ í˜¸í™˜ì„± ë©”ì„œë“œë“¤
    # ==============================================

    def force_register_model_loader(self, model_loader):
        """ModelLoader ê°•ì œ ë“±ë¡ (êµ¬ ë²„ì „ í˜¸í™˜)"""
        try:
            self.register_instance('model_loader', model_loader)
            self.logger.info("âœ… ModelLoader ê°•ì œ ë“±ë¡ ì™„ë£Œ")
            return True
        except Exception as e:
            self.logger.error(f"âŒ ModelLoader ê°•ì œ ë“±ë¡ ì‹¤íŒ¨: {e}")
            return False

    def optimize_memory(self, aggressive: bool = False) -> Dict[str, Any]:
        """ë©”ëª¨ë¦¬ ìµœì í™” (êµ¬ ë²„ì „ í˜¸í™˜)"""
        try:
            # ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ ì‹¤í–‰
            import gc
            collected = gc.collect()
            
            # M3 Max MPS ìºì‹œ ì •ë¦¬
            if IS_M3_MAX and TORCH_AVAILABLE and MPS_AVAILABLE:
                try:
                    import torch
                    if hasattr(torch.backends.mps, 'empty_cache'):
                        torch.backends.mps.empty_cache()
                except Exception:
                    pass
            
            return {
                'garbage_collected': collected,
                'aggressive': aggressive,
                'context': self.context_id
            }
        except Exception as e:
            return {
                'error': str(e),
                'context': self.context_id
            }

    def cleanup_circular_references(self):
        """ìˆœí™˜ì°¸ì¡° ì •ë¦¬ (êµ¬ ë²„ì „ í˜¸í™˜)"""
        # Event-Driven DI Containerì—ì„œëŠ” ìˆœí™˜ì°¸ì¡°ê°€ ì›ì²œì ìœ¼ë¡œ ë°©ì§€ë˜ë¯€ë¡œ
        # ì•„ë¬´ê²ƒë„ í•˜ì§€ ì•ŠìŒ
        pass

    def cleanup(self):
        """ì»¨í…ìŠ¤íŠ¸ ì •ë¦¬"""
        try:
            # ë“±ë¡ëœ ì„œë¹„ìŠ¤ë“¤ ì •ë¦¬
            for service_key in self.registry.list_services():
                service = self.registry.get_service(service_key, self.context_id)
                if service and hasattr(service, 'cleanup'):
                    try:
                        service.cleanup()
                    except Exception as e:
                        self.logger.debug(f"ì„œë¹„ìŠ¤ ì •ë¦¬ ì‹¤íŒ¨ {service_key}: {e}")
            
            # ì»¨í…ìŠ¤íŠ¸ ì†Œë©¸ ì´ë²¤íŠ¸
            event = DIEvent(
                event_type=EventType.CONTEXT_DESTROYED,
                service_key="container",
                context_id=self.context_id,
                data={
                    'lifetime_seconds': time.time() - self._creation_time,
                    'total_access_count': self._access_count,
                    'total_injection_count': self._injection_count
                }
            )
            self.event_bus.publish(event)
            
            self.logger.info(f"âœ… ì»¨í…ìŠ¤íŠ¸ ì •ë¦¬ ì™„ë£Œ: {self.context_id}")
            
        except Exception as e:
            self.logger.error(f"âŒ ì»¨í…ìŠ¤íŠ¸ ì •ë¦¬ ì‹¤íŒ¨: {e}")
    
    def get_stats(self) -> Dict[str, Any]:
        """ì»¨í…ìŠ¤íŠ¸ í†µê³„"""
        return {
            'context_id': self.context_id,
            'creation_time': self._creation_time,
            'lifetime_seconds': time.time() - self._creation_time,
            'access_count': self._access_count,
            'injection_count': self._injection_count,
            'registered_services': self.registry.list_services(),
            'factory_services': list(self.factory.get_service_definitions().keys()),
            'environment': {
                'is_m3_max': IS_M3_MAX,
                'device': DEVICE,
                'memory_gb': MEMORY_GB,
                'torch_available': TORCH_AVAILABLE,
                'mps_available': MPS_AVAILABLE
            }
        }

# ==============================================
# ğŸ”¥ Container Manager - ì „ì—­ ê´€ë¦¬
# ==============================================

class EventDrivenContainerManager:
    """ì´ë²¤íŠ¸ ê¸°ë°˜ Container ë§¤ë‹ˆì €"""
    
    def __init__(self):
        self.event_bus = EventBus()
        self.factory = DependencyFactory(self.event_bus)
        self._contexts: Dict[str, ContextualDIContainer] = {}
        self._default_context_id = "default"
        self._manager_lock = threading.RLock()
        self.logger = logging.getLogger(f"{self.__class__.__name__}")
        
        # ì´ë²¤íŠ¸ êµ¬ë… ì„¤ì •
        self._setup_event_subscriptions()
        
        # ê¸°ë³¸ ì»¨í…ìŠ¤íŠ¸ ìƒì„±
        self.get_container(self._default_context_id)
        
        self.logger.info("âœ… Event-Driven Container Manager ì´ˆê¸°í™” ì™„ë£Œ")
    
    def _setup_event_subscriptions(self):
        """ì´ë²¤íŠ¸ êµ¬ë… ì„¤ì •"""
        # ìˆœí™˜ì°¸ì¡° ê°ì§€ ì´ë²¤íŠ¸ êµ¬ë…
        self.event_bus.subscribe(
            EventType.CIRCULAR_DEPENDENCY_DETECTED,
            self._handle_circular_dependency
        )
        
        # ì˜ì¡´ì„± ì‹¤íŒ¨ ì´ë²¤íŠ¸ êµ¬ë…
        self.event_bus.subscribe(
            EventType.DEPENDENCY_FAILED,
            self._handle_dependency_failure
        )
    
    def _handle_circular_dependency(self, event: DIEvent):
        """ìˆœí™˜ì°¸ì¡° ì²˜ë¦¬"""
        self.logger.error(f"âŒ ìˆœí™˜ì°¸ì¡° ê°ì§€ë¨: {event.service_key}")
        self.logger.error(f"   ì»¨í…ìŠ¤íŠ¸: {event.context_id}")
        self.logger.error(f"   ìƒì„± ìŠ¤íƒ: {event.data.get('creation_stack', [])}")
    
    def _handle_dependency_failure(self, event: DIEvent):
        """ì˜ì¡´ì„± ì‹¤íŒ¨ ì²˜ë¦¬"""
        self.logger.warning(f"âš ï¸ ì˜ì¡´ì„± í•´ê²° ì‹¤íŒ¨: {event.service_key}")
        self.logger.debug(f"   ì˜¤ë¥˜: {event.data.get('error', 'Unknown')}")
    
    def get_container(self, context_id: Optional[str] = None) -> ContextualDIContainer:
        """ì»¨í…ìŠ¤íŠ¸ë³„ Container ë°˜í™˜"""
        context_id = context_id or self._default_context_id
        
        with self._manager_lock:
            if context_id not in self._contexts:
                self._contexts[context_id] = ContextualDIContainer(
                    context_id, self.event_bus, self.factory
                )
            
            return self._contexts[context_id]
    
    def create_context(self, context_id: str) -> ContextualDIContainer:
        """ìƒˆ ì»¨í…ìŠ¤íŠ¸ ìƒì„±"""
        with self._manager_lock:
            if context_id in self._contexts:
                self.logger.warning(f"âš ï¸ ì»¨í…ìŠ¤íŠ¸ ì´ë¯¸ ì¡´ì¬: {context_id}")
                return self._contexts[context_id]
            
            container = ContextualDIContainer(context_id, self.event_bus, self.factory)
            self._contexts[context_id] = container
            
            self.logger.info(f"âœ… ìƒˆ ì»¨í…ìŠ¤íŠ¸ ìƒì„±: {context_id}")
            return container
    
    def destroy_context(self, context_id: str):
        """ì»¨í…ìŠ¤íŠ¸ ì†Œë©¸"""
        with self._manager_lock:
            if context_id in self._contexts:
                container = self._contexts[context_id]
                container.cleanup()
                del self._contexts[context_id]
                self.logger.info(f"ğŸ—‘ï¸ ì»¨í…ìŠ¤íŠ¸ ì†Œë©¸: {context_id}")
    
    def list_contexts(self) -> List[str]:
        """ì»¨í…ìŠ¤íŠ¸ ëª©ë¡"""
        with self._manager_lock:
            return list(self._contexts.keys())
    
    def get_global_stats(self) -> Dict[str, Any]:
        """ì „ì—­ í†µê³„"""
        with self._manager_lock:
            contexts_stats = {}
            for context_id, container in self._contexts.items():
                contexts_stats[context_id] = container.get_stats()
            
            return {
                'manager_type': 'EventDrivenContainerManager',
                'version': '6.0',
                'total_contexts': len(self._contexts),
                'default_context': self._default_context_id,
                'contexts': contexts_stats,
                'event_history_size': len(self.event_bus.get_event_history()),
                'factory_services': list(self.factory.get_service_definitions().keys()),
                'environment': {
                    'conda_env': CONDA_ENV,
                    'is_m3_max': IS_M3_MAX,
                    'device': DEVICE,
                    'memory_gb': MEMORY_GB,
                    'torch_available': TORCH_AVAILABLE,
                    'mps_available': MPS_AVAILABLE
                }
            }
    
    def optimize_all_contexts(self):
        """ëª¨ë“  ì»¨í…ìŠ¤íŠ¸ ìµœì í™”"""
        with self._manager_lock:
            for container in self._contexts.values():
                # ë©”ëª¨ë¦¬ ì •ë¦¬
                gc.collect()
                
                # M3 Max MPS ìµœì í™”
                if IS_M3_MAX and TORCH_AVAILABLE and MPS_AVAILABLE:
                    try:
                        import torch
                        if hasattr(torch.backends.mps, 'empty_cache'):
                            torch.backends.mps.empty_cache()
                    except Exception:
                        pass
            
            self.logger.info("âœ… ëª¨ë“  ì»¨í…ìŠ¤íŠ¸ ìµœì í™” ì™„ë£Œ")
    
    def cleanup_all(self):
        """ëª¨ë“  ì»¨í…ìŠ¤íŠ¸ ì •ë¦¬"""
        with self._manager_lock:
            for context_id in list(self._contexts.keys()):
                self.destroy_context(context_id)
            
            self.optimize_all_contexts()
            self.logger.info("âœ… ëª¨ë“  ì»¨í…ìŠ¤íŠ¸ ì •ë¦¬ ì™„ë£Œ")

# ==============================================
# ğŸ”¥ Property Injection Mixin - ì†ì„± ì£¼ì… ì§€ì›
# ==============================================

class PropertyInjectionMixin:
    """ì†ì„± ì£¼ì…ì„ ì§€ì›í•˜ëŠ” ë¯¹ìŠ¤ì¸"""
    
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self._di_container: Optional[ContextualDIContainer] = None
        self._injected_properties: Dict[str, str] = {}
    
    def set_di_container(self, container: ContextualDIContainer):
        """DI Container ì„¤ì •"""
        self._di_container = container
        self._auto_inject_properties()
    
    def _auto_inject_properties(self):
        """ìë™ ì†ì„± ì£¼ì…"""
        if not self._di_container:
            return
        
        injection_map = {
            'model_loader': 'model_loader',
            'memory_manager': 'memory_manager',
            'data_converter': 'data_converter'
        }
        
        for attr_name, service_key in injection_map.items():
            if not hasattr(self, attr_name) or getattr(self, attr_name) is None:
                service = self._di_container.get(service_key)
                if service:
                    setattr(self, attr_name, service)
                    self._injected_properties[attr_name] = service_key
    
    def get_service(self, service_key: str):
        """DI Containerë¥¼ í†µí•œ ì„œë¹„ìŠ¤ ì¡°íšŒ"""
        if self._di_container:
            return self._di_container.get(service_key)
        return None
    
    def inject_di_container(self, container) -> bool:
        """DI Container ì£¼ì… (BaseStepMixin í˜¸í™˜)"""
        try:
            if isinstance(container, ContextualDIContainer):
                self.set_di_container(container)
                return True
            else:
                # êµ¬ ë²„ì „ í˜¸í™˜ì„±
                self._di_container = container
                return True
        except Exception as e:
            logger.error(f"âŒ DI Container ì£¼ì… ì‹¤íŒ¨: {e}")
            return False

# ==============================================
# ğŸ”¥ ì „ì—­ ì¸ìŠ¤í„´ìŠ¤ ê´€ë¦¬
# ==============================================

_global_manager: Optional[EventDrivenContainerManager] = None
_manager_lock = threading.RLock()

def get_global_container(context_id: Optional[str] = None) -> ContextualDIContainer:
    """ì „ì—­ Container ë°˜í™˜"""
    global _global_manager
    
    with _manager_lock:
        if _global_manager is None:
            _global_manager = EventDrivenContainerManager()
            logger.info("âœ… ì „ì—­ Event-Driven Container Manager ìƒì„±")
        
        return _global_manager.get_container(context_id)

def get_global_manager() -> EventDrivenContainerManager:
    """ì „ì—­ Manager ë°˜í™˜"""
    global _global_manager
    
    with _manager_lock:
        if _global_manager is None:
            _global_manager = EventDrivenContainerManager()
            logger.info("âœ… ì „ì—­ Event-Driven Container Manager ìƒì„±")
        
        return _global_manager

def reset_global_container():
    """ì „ì—­ Container ë¦¬ì…‹"""
    global _global_manager
    
    with _manager_lock:
        if _global_manager:
            _global_manager.cleanup_all()
        _global_manager = None
        logger.info("ğŸ”„ ì „ì—­ Event-Driven Container Manager ë¦¬ì…‹")

# ==============================================
# ğŸ”¥ êµ¬ ë²„ì „ í˜¸í™˜ì„± ë ˆì´ì–´
# ==============================================

# LazyDependency í˜¸í™˜ì„± í´ë˜ìŠ¤ (ê¸°ì¡´ ì½”ë“œìš©)
class LazyDependency:
    """êµ¬ ë²„ì „ LazyDependency í˜¸í™˜ì„± ë˜í¼"""
    
    def __init__(self, factory: Callable[[], Any]):
        self._factory = factory
        self._instance = None
        self._resolved = False
        self._lock = threading.RLock()
    
    def get(self) -> Any:
        """ì§€ì—° í•´ê²°"""
        if not self._resolved:
            with self._lock:
                if not self._resolved:
                    try:
                        self._instance = self._factory()
                        self._resolved = True
                    except Exception as e:
                        logger.error(f"âŒ LazyDependency í•´ê²° ì‹¤íŒ¨: {e}")
                        return None
        return self._instance
    
    def resolve(self) -> Any:
        """resolve() ë©”ì„œë“œ ë³„ì¹­"""
        return self.get()
    
    def is_resolved(self) -> bool:
        return self._resolved

# ê¸°ì¡´ CircularReferenceFreeDIContainer í˜¸í™˜ì„±
class CircularReferenceFreeDIContainer:
    """êµ¬ ë²„ì „ í˜¸í™˜ì„±ì„ ìœ„í•œ ë˜í¼"""
    
    def __init__(self):
        self._container = get_global_container("legacy")
        self.logger = logging.getLogger("LegacyDIContainer")
        self.logger.warning("âš ï¸ êµ¬ ë²„ì „ DI Container ì‚¬ìš© - Event-Driven Containerë¡œ ì—…ê·¸ë ˆì´ë“œ ê¶Œì¥")
    
    def get(self, key: str):
        return self._container.get(key)
    
    def register(self, key: str, instance: Any, singleton: bool = True):
        self._container.register_instance(key, instance)
    
    def register_lazy(self, key: str, factory: Callable[[], Any]):
        self._container.register_factory(key, factory, is_singleton=True)
    
    def inject_to_step(self, step_instance):
        return self._container.inject_to_step(step_instance)
    
    def force_register_model_loader(self, model_loader):
        self._container.register_instance('model_loader', model_loader)
        return True
    
    def get_stats(self):
        return self._container.get_stats()
    
    def optimize_memory(self, aggressive=False):
        if aggressive:
            get_global_manager().optimize_all_contexts()
        return {"optimized": True}
    
    def cleanup_circular_references(self):
        pass  # Event-drivenì—ì„œëŠ” ë¶ˆí•„ìš”


# backend/app/core/di_container.pyì— ì¶”ê°€í•  DynamicImportResolver í´ë˜ìŠ¤

class DynamicImportResolver:
    """ë™ì  import í•´ê²°ê¸° (ìˆœí™˜ì°¸ì¡° ì™„ì „ ë°©ì§€)"""
    
    @staticmethod
    def resolve_model_loader():
        """ModelLoader ë™ì  í•´ê²° (ìˆœí™˜ì°¸ì¡° ë°©ì§€)"""
        import_paths = [
            'app.ai_pipeline.utils.model_loader',
            'ai_pipeline.utils.model_loader',
            'utils.model_loader'
        ]
        
        for path in import_paths:
            try:
                module = importlib.import_module(path)
                
                # ì „ì—­ í•¨ìˆ˜ ìš°ì„ 
                if hasattr(module, 'get_global_model_loader'):
                    loader = module.get_global_model_loader()
                    if loader:
                        logger.debug(f"âœ… ModelLoader ë™ì  í•´ê²°: {path}")
                        return loader
                
                # í´ë˜ìŠ¤ ì§ì ‘ ìƒì„±
                if hasattr(module, 'ModelLoader'):
                    ModelLoaderClass = module.ModelLoader
                    loader = ModelLoaderClass()
                    logger.debug(f"âœ… ModelLoader í´ë˜ìŠ¤ ìƒì„±: {path}")
                    return loader
                    
            except ImportError:
                continue
        
        # ì™„ì „ ì‹¤íŒ¨ ì‹œ Mock ë°˜í™˜
        logger.warning("âš ï¸ ModelLoader í•´ê²° ì‹¤íŒ¨, Mock ì‚¬ìš©")
        return DynamicImportResolver._create_mock_model_loader()
    
    @staticmethod
    def resolve_memory_manager():
        """MemoryManager ë™ì  í•´ê²° (ìˆœí™˜ì°¸ì¡° ë°©ì§€)"""
        import_paths = [
            'app.ai_pipeline.utils.memory_manager',
            'ai_pipeline.utils.memory_manager',
            'utils.memory_manager'
        ]
        
        for path in import_paths:
            try:
                module = importlib.import_module(path)
                
                if hasattr(module, 'get_global_memory_manager'):
                    manager = module.get_global_memory_manager()
                    if manager:
                        logger.debug(f"âœ… MemoryManager ë™ì  í•´ê²°: {path}")
                        return manager
                
                if hasattr(module, 'MemoryManager'):
                    MemoryManagerClass = module.MemoryManager
                    manager = MemoryManagerClass()
                    logger.debug(f"âœ… MemoryManager í´ë˜ìŠ¤ ìƒì„±: {path}")
                    return manager
                    
            except ImportError:
                continue
        
        logger.warning("âš ï¸ MemoryManager í•´ê²° ì‹¤íŒ¨, Mock ì‚¬ìš©")
        return DynamicImportResolver._create_mock_memory_manager()
    
    @staticmethod
    def resolve_data_converter():
        """DataConverter ë™ì  í•´ê²° (ìˆœí™˜ì°¸ì¡° ë°©ì§€)"""
        import_paths = [
            'app.ai_pipeline.utils.data_converter',
            'ai_pipeline.utils.data_converter',
            'utils.data_converter'
        ]
        
        for path in import_paths:
            try:
                module = importlib.import_module(path)
                
                if hasattr(module, 'get_global_data_converter'):
                    converter = module.get_global_data_converter()
                    if converter:
                        logger.debug(f"âœ… DataConverter ë™ì  í•´ê²°: {path}")
                        return converter
                
                if hasattr(module, 'DataConverter'):
                    DataConverterClass = module.DataConverter
                    converter = DataConverterClass()
                    logger.debug(f"âœ… DataConverter í´ë˜ìŠ¤ ìƒì„±: {path}")
                    return converter
                    
            except ImportError:
                continue
        
        logger.warning("âš ï¸ DataConverter í•´ê²° ì‹¤íŒ¨, Mock ì‚¬ìš©")
        return DynamicImportResolver._create_mock_data_converter()
    
    @staticmethod
    def resolve_di_container():
        """DI Container ë™ì  í•´ê²° (ìˆœí™˜ì°¸ì¡° ë°©ì§€)"""
        import_paths = [
            'app.core.di_container',
            'core.di_container',
        ]
        
        for path in import_paths:
            try:
                module = importlib.import_module(path)
                
                if hasattr(module, 'get_global_container'):
                    container = module.get_global_container()
                    if container:
                        logger.debug(f"âœ… DIContainer ë™ì  í•´ê²°: {path}")
                        return container
                        
            except ImportError:
                continue
        
        logger.warning("âš ï¸ DIContainer í•´ê²° ì‹¤íŒ¨")
        return None
    
    @staticmethod
    def _create_mock_model_loader():
        """Mock ModelLoader"""
        class MockModelLoader:
            def __init__(self):
                self.is_initialized = True
                self.loaded_models = {}
                self.device = DEVICE
                self.logger = logging.getLogger("MockModelLoader")
                
            def load_model(self, model_path: str, **kwargs):
                model_id = f"mock_{len(self.loaded_models)}"
                self.loaded_models[model_id] = {
                    "path": model_path,
                    "loaded": True,
                    "device": self.device
                }
                return self.loaded_models[model_id]
            
            def create_step_interface(self, step_name: str):
                return MockStepInterface(step_name)
            
            def cleanup(self):
                self.loaded_models.clear()
        
        class MockStepInterface:
            def __init__(self, step_name):
                self.step_name = step_name
                self.is_initialized = True
            
            def get_model(self, model_name=None):
                return {"mock_model": model_name, "loaded": True}
        
        return MockModelLoader()
    
    @staticmethod
    def _create_mock_memory_manager():
        """Mock MemoryManager"""
        class MockMemoryManager:
            def __init__(self):
                self.is_initialized = True
                self.optimization_count = 0
            
            def optimize_memory(self, aggressive=False):
                self.optimization_count += 1
                gc.collect()
                return {"optimized": True, "count": self.optimization_count}
            
            def get_memory_info(self):
                return {
                    "total_gb": MEMORY_GB,
                    "available_gb": MEMORY_GB * 0.7,
                    "percent": 30.0
                }
            
            def cleanup(self):
                self.optimize_memory(aggressive=True)
        
        return MockMemoryManager()
    
    @staticmethod
    def _create_mock_data_converter():
        """Mock DataConverter"""
        class MockDataConverter:
            def __init__(self):
                self.is_initialized = True
                self.conversion_count = 0
            
            def convert(self, data, target_format):
                self.conversion_count += 1
                return {
                    "converted": f"mock_{target_format}_{self.conversion_count}",
                    "format": target_format
                }
            
            def get_supported_formats(self):
                return ["tensor", "numpy", "pil", "cv2"]
            
            def cleanup(self):
                self.conversion_count = 0
        
        return MockDataConverter()
    


# ==============================================
# ğŸ”¥ ì•ˆì „í•œ ì„œë¹„ìŠ¤ ì ‘ê·¼ í•¨ìˆ˜ë“¤ (ì™„ì „í•œ í˜¸í™˜ì„±)
# ==============================================

def get_service_safe(service_key: str, context_id: Optional[str] = None, default=None) -> Any:
    """ì•ˆì „í•œ ì„œë¹„ìŠ¤ ì¡°íšŒ - ì‹¤íŒ¨ì‹œ ê¸°ë³¸ê°’ ë°˜í™˜"""
    try:
        service = get_service(service_key, context_id)
        return service if service is not None else default
    except Exception as e:
        logger.debug(f"âš ï¸ get_service_safe ì‹¤íŒ¨ ({service_key}): {e}")
        return default

def register_service_safe(service_key: str, instance: Any, context_id: Optional[str] = None) -> bool:
    """ì•ˆì „í•œ ì„œë¹„ìŠ¤ ë“±ë¡"""
    try:
        register_service(service_key, instance, context_id)
        logger.debug(f"âœ… register_service_safe ì„±ê³µ: {service_key}")
        return True
    except Exception as e:
        logger.debug(f"âš ï¸ register_service_safe ì‹¤íŒ¨ ({service_key}): {e}")
        return False

def register_factory_safe(service_key: str, factory: Callable[[], Any], 
                         singleton: bool = True, context_id: Optional[str] = None) -> bool:
    """ì•ˆì „í•œ íŒ©í† ë¦¬ ë“±ë¡"""
    try:
        register_factory(service_key, factory, singleton, context_id)
        logger.debug(f"âœ… register_factory_safe ì„±ê³µ: {service_key}")
        return True
    except Exception as e:
        logger.debug(f"âš ï¸ register_factory_safe ì‹¤íŒ¨ ({service_key}): {e}")
        return False

def get_model_loader_safe(context_id: Optional[str] = None):
    """ì•ˆì „í•œ ModelLoader ì¡°íšŒ"""
    return get_service_safe('model_loader', context_id)

def get_memory_manager_safe(context_id: Optional[str] = None):
    """ì•ˆì „í•œ MemoryManager ì¡°íšŒ"""
    return get_service_safe('memory_manager', context_id)

def get_data_converter_safe(context_id: Optional[str] = None):
    """ì•ˆì „í•œ DataConverter ì¡°íšŒ"""
    return get_service_safe('data_converter', context_id)

def get_container_safe(context_id: Optional[str] = None):
    """ì•ˆì „í•œ Container ì¡°íšŒ"""
    try:
        return get_global_container(context_id)
    except Exception as e:
        logger.debug(f"âš ï¸ get_container_safe ì‹¤íŒ¨: {e}")
        return None

def inject_dependencies_safe(step_instance, context_id: Optional[str] = None) -> int:
    """ì•ˆì „í•œ ì˜ì¡´ì„± ì£¼ì…"""
    try:
        return inject_dependencies_to_step_safe(step_instance, None)
    except Exception as e:
        logger.debug(f"âš ï¸ inject_dependencies_safe ì‹¤íŒ¨: {e}")
        return 0

def ensure_model_loader_registration(context_id: Optional[str] = None) -> bool:
    """ModelLoader ë“±ë¡ ë³´ì¥"""
    try:
        loader = get_service('model_loader', context_id)
        return loader is not None
    except Exception:
        return False

def ensure_service_registration(service_key: str, context_id: Optional[str] = None) -> bool:
    """ì„œë¹„ìŠ¤ ë“±ë¡ ë³´ì¥"""
    try:
        service = get_service(service_key, context_id)
        return service is not None
    except Exception:
        return False

def initialize_di_system_safe(context_id: Optional[str] = None) -> bool:
    """DI ì‹œìŠ¤í…œ ì•ˆì „ ì´ˆê¸°í™”"""
    try:
        container = get_global_container(context_id)
        
        # conda í™˜ê²½ ìµœì í™”
        if IS_CONDA:
            _optimize_for_conda()
        
        # ModelLoader í™•ì¸
        model_loader = container.get('model_loader')
        if model_loader:
            logger.info("âœ… DI ì‹œìŠ¤í…œ ì´ˆê¸°í™”: ModelLoader ì‚¬ìš© ê°€ëŠ¥")
        else:
            logger.warning("âš ï¸ DI ì‹œìŠ¤í…œ ì´ˆê¸°í™”: ModelLoader ì—†ìŒ")
        
        return True
    except Exception as e:
        logger.error(f"âŒ DI ì‹œìŠ¤í…œ ì•ˆì „ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return False

def cleanup_services_safe(context_id: Optional[str] = None) -> bool:
    """ì•ˆì „í•œ ì„œë¹„ìŠ¤ ì •ë¦¬"""
    try:
        container = get_global_container(context_id)
        if hasattr(container, 'cleanup_disposed_services'):
            container.cleanup_disposed_services()
        return True
    except Exception as e:
        logger.debug(f"âš ï¸ cleanup_services_safe ì‹¤íŒ¨: {e}")
        return False

def reset_container_safe(context_id: Optional[str] = None) -> bool:
    """ì•ˆì „í•œ Container ë¦¬ì…‹"""
    try:
        reset_global_container(context_id)
        return True
    except Exception as e:
        logger.debug(f"âš ï¸ reset_container_safe ì‹¤íŒ¨: {e}")
        return False

# ==============================================
# ğŸ”¥ ìƒíƒœ í™•ì¸ í•¨ìˆ˜ë“¤
# ==============================================

def is_service_available(service_key: str, context_id: Optional[str] = None) -> bool:
    """ì„œë¹„ìŠ¤ ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸"""
    try:
        service = get_service_safe(service_key, context_id)
        return service is not None
    except Exception:
        return False

def is_container_ready(context_id: Optional[str] = None) -> bool:
    """Container ì¤€ë¹„ ìƒíƒœ í™•ì¸"""
    try:
        container = get_container_safe(context_id)
        return container is not None
    except Exception:
        return False

def is_di_system_ready(context_id: Optional[str] = None) -> bool:
    """DI ì‹œìŠ¤í…œ ì¤€ë¹„ ìƒíƒœ í™•ì¸"""
    try:
        container = get_global_container(context_id)
        if not container:
            return False
        
        # í•µì‹¬ ì„œë¹„ìŠ¤ë“¤ í™•ì¸
        essential_services = ['model_loader', 'memory_manager', 'data_converter']
        for service_key in essential_services:
            if not container.get(service_key):
                return False
        
        return True
    except Exception:
        return False

def get_service_status(service_key: str, context_id: Optional[str] = None) -> Dict[str, Any]:
    """ì„œë¹„ìŠ¤ ìƒíƒœ ì •ë³´"""
    try:
        container = get_container_safe(context_id)
        if not container:
            return {'status': 'error', 'message': 'Container not available'}
        
        service = container.get(service_key)
        return {
            'service_key': service_key,
            'available': service is not None,
            'type': type(service).__name__ if service else None,
            'context': context_id or 'default'
        }
    except Exception as e:
        return {
            'service_key': service_key,
            'status': 'error',
            'message': str(e)
        }

def get_di_system_status(context_id: Optional[str] = None) -> Dict[str, Any]:
    """DI ì‹œìŠ¤í…œ ìƒíƒœ ì •ë³´"""
    try:
        container = get_global_container(context_id)
        if not container:
            return {'status': 'error', 'message': 'Container not available'}
        
        stats = container.get_stats() if hasattr(container, 'get_stats') else {}
        
        # í•µì‹¬ ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸
        services_status = {}
        essential_services = ['model_loader', 'memory_manager', 'data_converter']
        
        for service_key in essential_services:
            service = container.get(service_key)
            services_status[service_key] = {
                'available': service is not None,
                'type': type(service).__name__ if service else None
            }
        
        return {
            'status': 'ready' if is_di_system_ready(context_id) else 'partial',
            'context': context_id or 'default',
            'stats': stats,
            'services': services_status,
            'environment': {
                'conda_env': CONDA_ENV,
                'is_m3_max': IS_M3_MAX,
                'device': DEVICE,
                'torch_available': TORCH_AVAILABLE,
                'mps_available': MPS_AVAILABLE
            }
        }
    except Exception as e:
        return {
            'status': 'error',
            'message': str(e)
        }

# ==============================================
# ğŸ”¥ conda í™˜ê²½ ìµœì í™”
# ==============================================

def _optimize_for_conda():
    """conda í™˜ê²½ ìµœì í™”"""
    try:
        os.environ['OMP_NUM_THREADS'] = str(max(1, os.cpu_count() // 2))
        os.environ['MKL_NUM_THREADS'] = str(max(1, os.cpu_count() // 2))
        os.environ['NUMEXPR_NUM_THREADS'] = str(max(1, os.cpu_count() // 2))
        
        if TORCH_AVAILABLE:
            import torch
            torch.set_num_threads(max(1, os.cpu_count() // 2))
            
            if IS_M3_MAX and MPS_AVAILABLE:
                if hasattr(torch.backends.mps, 'empty_cache'):
                    torch.backends.mps.empty_cache()
        
        logger.info(f"ğŸ conda í™˜ê²½ '{CONDA_ENV}' ìµœì í™” ì™„ë£Œ")
    except Exception as e:
        logger.warning(f"âš ï¸ conda ìµœì í™” ì‹¤íŒ¨: {e}")

# ==============================================
# ğŸ”¥ ì•ˆì „í•œ ì„œë¹„ìŠ¤ ì ‘ê·¼ í•¨ìˆ˜ë“¤ (í˜¸í™˜ì„±)
# ==============================================

def get_service_safe(service_key: str, context: str = None, default=None) -> Any:
    """ì•ˆì „í•œ ì„œë¹„ìŠ¤ ì¡°íšŒ - ì‹¤íŒ¨ì‹œ ê¸°ë³¸ê°’ ë°˜í™˜"""
    try:
        service = get_service(service_key, context)
        return service if service is not None else default
    except Exception as e:
        logger.debug(f"âš ï¸ get_service_safe ì‹¤íŒ¨ ({service_key}): {e}")
        return default

def get_model_loader_safe(context: str = None):
    """ì•ˆì „í•œ ModelLoader ì¡°íšŒ"""
    return get_service_safe('model_loader', context)

def get_memory_manager_safe(context: str = None):
    """ì•ˆì „í•œ MemoryManager ì¡°íšŒ"""
    return get_service_safe('memory_manager', context)

def get_data_converter_safe(context: str = None):
    """ì•ˆì „í•œ DataConverter ì¡°íšŒ"""
    return get_service_safe('data_converter', context)

def ensure_model_loader_registration(context: str = None) -> bool:
    """ModelLoader ë“±ë¡ ë³´ì¥"""
    try:
        loader = get_service('model_loader', context)
        return loader is not None
    except Exception:
        return False

def initialize_di_system_safe(context: str = None) -> bool:
    """DI ì‹œìŠ¤í…œ ì•ˆì „ ì´ˆê¸°í™”"""
    try:
        return initialize_di_system(context)
    except Exception as e:
        logger.error(f"âŒ DI ì‹œìŠ¤í…œ ì•ˆì „ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return False

# ==============================================
# ğŸ”¥ êµ¬ ë²„ì „ í˜¸í™˜ì„± í•¨ìˆ˜ë“¤ ì¶”ê°€
# ==============================================

def inject_dependencies_to_step_safe(step_instance, container=None):
    """êµ¬ë²„ì „ í˜¸í™˜ í•¨ìˆ˜"""
    try:
        if container and hasattr(container, 'context'):
            return inject_dependencies_to_step(step_instance, container.context)
        else:
            return inject_dependencies_to_step(step_instance, None)
    except Exception as e:
        logger.error(f"âŒ inject_dependencies_to_step_safe ì‹¤íŒ¨: {e}")
        return 0

def get_global_container_legacy():
    """êµ¬ë²„ì „ í˜¸í™˜ í•¨ìˆ˜"""
    try:
        return get_global_container()
    except Exception as e:
        logger.error(f"âŒ get_global_container_legacy ì‹¤íŒ¨: {e}")
        return None

def reset_global_container_legacy():
    """êµ¬ë²„ì „ í˜¸í™˜ í•¨ìˆ˜"""
    try:
        return reset_global_container()
    except Exception as e:
        logger.error(f"âŒ reset_global_container_legacy ì‹¤íŒ¨: {e}")

# ==============================================
# ğŸ”¥ DI ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸ í•¨ìˆ˜ë“¤
# ==============================================

def is_di_system_ready(context: str = None) -> bool:
    """DI ì‹œìŠ¤í…œ ì¤€ë¹„ ìƒíƒœ í™•ì¸"""
    try:
        container = get_global_container(context)
        if not container:
            return False
        
        # í•µì‹¬ ì„œë¹„ìŠ¤ë“¤ í™•ì¸
        essential_services = ['model_loader', 'memory_manager', 'data_converter']
        for service_key in essential_services:
            if not container.get(service_key):
                return False
        
        return True
    except Exception:
        return False

def get_di_system_status(context: str = None) -> Dict[str, Any]:
    """DI ì‹œìŠ¤í…œ ìƒíƒœ ì •ë³´"""
    try:
        container = get_global_container(context)
        if not container:
            return {'status': 'error', 'message': 'Container not available'}
        
        stats = container.get_stats()
        
        # í•µì‹¬ ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸
        services_status = {}
        essential_services = ['model_loader', 'memory_manager', 'data_converter']
        
        for service_key in essential_services:
            service = container.get(service_key)
            services_status[service_key] = {
                'available': service is not None,
                'type': type(service).__name__ if service else None
            }
        
        return {
            'status': 'ready' if is_di_system_ready(context) else 'partial',
            'context': context or 'default',
            'stats': stats,
            'services': services_status,
            'environment': {
                'conda_env': CONDA_ENV,
                'is_m3_max': IS_M3_MAX,
                'device': DEVICE,
                'torch_available': TORCH_AVAILABLE,
                'mps_available': MPS_AVAILABLE
            }
        }
    except Exception as e:
        return {
            'status': 'error',
            'message': str(e)
        }
# backend/app/core/di_container.pyì— ì¶”ê°€í•  ì§€ì—° ì„œë¹„ìŠ¤ ê´€ë ¨ í•¨ìˆ˜ë“¤

# ==============================================
# ğŸ”¥ ì§€ì—° ì„œë¹„ìŠ¤ (Lazy Service) ê´€ë ¨ í•¨ìˆ˜ë“¤
# ==============================================

def register_lazy_service(service_key: str, factory: Callable[[], Any], 
                         context_id: Optional[str] = None, singleton: bool = True) -> bool:
    """ì§€ì—° ì„œë¹„ìŠ¤ ë“±ë¡ (LazyServiceë¡œ ë˜í•‘)"""
    try:
        lazy_service = LazyDependency(factory)  # LazyDependencyëŠ” LazyServiceì˜ ë³„ì¹­
        
        container = get_global_container(context_id)
        container.register_instance(service_key, lazy_service)
        
        logger.debug(f"âœ… register_lazy_service ì„±ê³µ: {service_key}")
        return True
    except Exception as e:
        logger.debug(f"âš ï¸ register_lazy_service ì‹¤íŒ¨ ({service_key}): {e}")
        return False

def register_lazy_service_safe(service_key: str, factory: Callable[[], Any], 
                              context_id: Optional[str] = None, singleton: bool = True) -> bool:
    """ì•ˆì „í•œ ì§€ì—° ì„œë¹„ìŠ¤ ë“±ë¡"""
    return register_lazy_service(service_key, factory, context_id, singleton)

def create_lazy_dependency(factory: Callable[[], Any], service_key: str = None) -> Any:
    """ì§€ì—° ì˜ì¡´ì„± ìƒì„±"""
    try:
        return LazyDependency(factory)
    except Exception as e:
        logger.debug(f"âš ï¸ create_lazy_dependency ì‹¤íŒ¨: {e}")
        return None

def resolve_lazy_service(service_key: str, context_id: Optional[str] = None) -> Any:
    """ì§€ì—° ì„œë¹„ìŠ¤ í•´ê²°"""
    try:
        container = get_global_container(context_id)
        lazy_service = container.get(service_key)
        
        if lazy_service and hasattr(lazy_service, 'get'):
            return lazy_service.get()
        else:
            return lazy_service
    except Exception as e:
        logger.debug(f"âš ï¸ resolve_lazy_service ì‹¤íŒ¨ ({service_key}): {e}")
        return None

def is_lazy_service_resolved(service_key: str, context_id: Optional[str] = None) -> bool:
    """ì§€ì—° ì„œë¹„ìŠ¤ í•´ê²° ìƒíƒœ í™•ì¸"""
    try:
        container = get_global_container(context_id)
        lazy_service = container.get(service_key)
        
        if lazy_service and hasattr(lazy_service, 'is_resolved'):
            return lazy_service.is_resolved()
        return False
    except Exception:
        return False

# ==============================================
# ğŸ”¥ Container ë ˆë²¨ í•¨ìˆ˜ë“¤ (êµ¬ ë²„ì „ í˜¸í™˜)
# ==============================================

def create_container(context_id: str = None) -> Any:
    """Container ìƒì„± (êµ¬ ë²„ì „ í˜¸í™˜)"""
    try:
        return get_global_container(context_id)
    except Exception as e:
        logger.debug(f"âš ï¸ create_container ì‹¤íŒ¨: {e}")
        return None

def dispose_container(context_id: str = None) -> bool:
    """Container ì •ë¦¬ (êµ¬ ë²„ì „ í˜¸í™˜)"""
    try:
        reset_global_container(context_id)
        return True
    except Exception as e:
        logger.debug(f"âš ï¸ dispose_container ì‹¤íŒ¨: {e}")
        return False

def get_container_instance(context_id: str = None) -> Any:
    """Container ì¸ìŠ¤í„´ìŠ¤ ì¡°íšŒ (êµ¬ ë²„ì „ í˜¸í™˜)"""
    return get_container_safe(context_id)

def register_singleton(service_key: str, instance: Any, context_id: Optional[str] = None) -> bool:
    """ì‹±ê¸€í†¤ ë“±ë¡ (êµ¬ ë²„ì „ í˜¸í™˜)"""
    return register_service_safe(service_key, instance, context_id)

def register_transient(service_key: str, factory: Callable[[], Any], context_id: Optional[str] = None) -> bool:
    """ì„ì‹œ ì„œë¹„ìŠ¤ ë“±ë¡ (êµ¬ ë²„ì „ í˜¸í™˜)"""
    return register_factory_safe(service_key, factory, False, context_id)

def unregister_service(service_key: str, context_id: Optional[str] = None) -> bool:
    """ì„œë¹„ìŠ¤ ë“±ë¡ í•´ì œ"""
    try:
        container = get_global_container(context_id)
        if hasattr(container, 'unregister_service'):
            container.unregister_service(service_key)
            return True
        return False
    except Exception as e:
        logger.debug(f"âš ï¸ unregister_service ì‹¤íŒ¨ ({service_key}): {e}")
        return False

# ==============================================
# ğŸ”¥ ì˜ì¡´ì„± ì£¼ì… ê´€ë ¨ í•¨ìˆ˜ë“¤
# ==============================================

def inject_all_dependencies(step_instance, context_id: Optional[str] = None) -> int:
    """ëª¨ë“  ì˜ì¡´ì„± ì£¼ì…"""
    return inject_dependencies_safe(step_instance, context_id)

def auto_wire_dependencies(step_instance, context_id: Optional[str] = None) -> bool:
    """ìë™ ì˜ì¡´ì„± ì—°ê²°"""
    try:
        count = inject_dependencies_safe(step_instance, context_id)
        return count > 0
    except Exception:
        return False

def validate_dependencies(step_instance, required_services: List[str] = None) -> bool:
    """ì˜ì¡´ì„± ìœ íš¨ì„± ê²€ì‚¬"""
    try:
        if not required_services:
            required_services = ['model_loader', 'memory_manager', 'data_converter']
        
        for service_name in required_services:
            if not hasattr(step_instance, service_name) or getattr(step_instance, service_name) is None:
                return False
        
        return True
    except Exception:
        return False

def get_dependency_status(step_instance) -> Dict[str, Any]:
    """ì˜ì¡´ì„± ìƒíƒœ ì •ë³´"""
    try:
        dependencies = ['model_loader', 'memory_manager', 'data_converter', 'di_container']
        
        status = {}
        for dep_name in dependencies:
            dep_value = getattr(step_instance, dep_name, None)
            status[dep_name] = {
                'available': dep_value is not None,
                'type': type(dep_value).__name__ if dep_value else None
            }
        
        return {
            'step_class': step_instance.__class__.__name__,
            'dependencies': status,
            'all_resolved': all(status[dep]['available'] for dep in dependencies),
            'resolution_count': sum(1 for dep in status.values() if dep['available'])
        }
    except Exception as e:
        return {
            'error': str(e),
            'step_class': getattr(step_instance, '__class__', {}).get('__name__', 'Unknown')
        }

# ==============================================
# ğŸ”¥ ì„œë¹„ìŠ¤ ì¡°íšŒ í¸ì˜ í•¨ìˆ˜ë“¤
# ==============================================

def get_all_services(context_id: Optional[str] = None) -> Dict[str, Any]:
    """ëª¨ë“  ì„œë¹„ìŠ¤ ì¡°íšŒ"""
    try:
        container = get_global_container(context_id)
        
        if hasattr(container, '_services'):
            services = {}
            for service_key in container._services.keys():
                service = container.get(service_key)
                services[service_key] = {
                    'available': service is not None,
                    'type': type(service).__name__ if service else None
                }
            return services
        
        return {}
    except Exception as e:
        return {'error': str(e)}

def list_service_keys(context_id: Optional[str] = None) -> List[str]:
    """ì„œë¹„ìŠ¤ í‚¤ ëª©ë¡"""
    try:
        container = get_global_container(context_id)
        
        if hasattr(container, '_services'):
            return list(container._services.keys())
        
        return []
    except Exception:
        return []

def get_service_count(context_id: Optional[str] = None) -> int:
    """ë“±ë¡ëœ ì„œë¹„ìŠ¤ ê°œìˆ˜"""
    try:
        return len(list_service_keys(context_id))
    except Exception:
        return 0

# ==============================================
# ğŸ”¥ í¸ì˜ í•¨ìˆ˜ë“¤
# ==============================================

def get_service(key: str, context_id: Optional[str] = None) -> Optional[Any]:
    """ì„œë¹„ìŠ¤ ì¡°íšŒ í¸ì˜ í•¨ìˆ˜"""
    container = get_global_container(context_id)
    return container.get(key)

def register_service(key: str, instance: Any, context_id: Optional[str] = None):
    """ì„œë¹„ìŠ¤ ë“±ë¡ í¸ì˜ í•¨ìˆ˜"""
    container = get_global_container(context_id)
    container.register_instance(key, instance)

def register_factory(key: str, factory: Callable[[], Any], singleton: bool = True, context_id: Optional[str] = None):
    """íŒ©í† ë¦¬ ë“±ë¡ í¸ì˜ í•¨ìˆ˜"""
    container = get_global_container(context_id)
    container.register_factory(key, factory, singleton)

def inject_dependencies_to_step_safe(step_instance, context_id: Optional[str] = None):
    """Step ì˜ì¡´ì„± ì£¼ì… í¸ì˜ í•¨ìˆ˜"""
    container = get_global_container(context_id)
    return container.inject_to_step(step_instance)

# BaseStepMixin í˜¸í™˜ í•¨ìˆ˜ë“¤
def _get_global_di_container():
    """BaseStepMixin í˜¸í™˜ í•¨ìˆ˜"""
    return get_global_container()

def _get_service_from_container_safe(service_key: str):
    """BaseStepMixin í˜¸í™˜ í•¨ìˆ˜"""
    return get_service(service_key)

# ModelLoader ì—°ë™ í•¨ìˆ˜ë“¤
def get_model_loader_safe():
    """ì•ˆì „í•œ ModelLoader ì¡°íšŒ"""
    return get_service('model_loader')

def ensure_model_loader_registration():
    """ModelLoader ë“±ë¡ ë³´ì¥"""
    loader = get_service('model_loader')
    return loader is not None

def initialize_di_system_safe():
    """DI ì‹œìŠ¤í…œ ì•ˆì „ ì´ˆê¸°í™”"""
    try:
        container = get_global_container()
        
        # conda í™˜ê²½ ìµœì í™”
        if IS_CONDA:
            _optimize_for_conda()
        
        # ModelLoader í™•ì¸
        model_loader = container.get('model_loader')
        if model_loader:
            logger.info("âœ… DI ì‹œìŠ¤í…œ ì´ˆê¸°í™”: ModelLoader ì‚¬ìš© ê°€ëŠ¥")
        else:
            logger.warning("âš ï¸ DI ì‹œìŠ¤í…œ ì´ˆê¸°í™”: ModelLoader ì—†ìŒ")
        
        return True
    except Exception as e:
        logger.error(f"âŒ DI ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return False

def _optimize_for_conda():
    """conda í™˜ê²½ ìµœì í™”"""
    try:
        os.environ['OMP_NUM_THREADS'] = str(max(1, os.cpu_count() // 2))
        os.environ['MKL_NUM_THREADS'] = str(max(1, os.cpu_count() // 2))
        os.environ['NUMEXPR_NUM_THREADS'] = str(max(1, os.cpu_count() // 2))
        
        if TORCH_AVAILABLE:
            import torch
            torch.set_num_threads(max(1, os.cpu_count() // 2))
            
            if IS_M3_MAX and MPS_AVAILABLE:
                if hasattr(torch.backends.mps, 'empty_cache'):
                    torch.backends.mps.empty_cache()
        
        logger.info(f"ğŸ conda í™˜ê²½ '{CONDA_ENV}' ìµœì í™” ì™„ë£Œ")
    except Exception as e:
        logger.warning(f"âš ï¸ conda ìµœì í™” ì‹¤íŒ¨: {e}")

# ==============================================
# ğŸ”¥ Export
# ==============================================
# backend/app/core/di_container.pyì˜ ì™„ì „í•œ __all__ ë¦¬ìŠ¤íŠ¸

__all__ = [
    # ë©”ì¸ í´ë˜ìŠ¤ë“¤
    'EventDrivenContainerManager',
    'ContextualDIContainer',
    'DependencyFactory',
    'ServiceRegistry',
    'EventBus',
    'PropertyInjectionMixin',
    
    # ì´ë²¤íŠ¸ ì‹œìŠ¤í…œ
    'EventType',
    'DIEvent',
    
    # ë°ì´í„° í´ë˜ìŠ¤ë“¤
    'ServiceDefinition',
    'ServiceLifecycle',
    
    # ì „ì—­ í•¨ìˆ˜ë“¤
    'get_global_container',
    'get_global_manager',
    'reset_global_container',
    
    # ê¸°ë³¸ í¸ì˜ í•¨ìˆ˜ë“¤
    'get_service',
    'register_service',
    'register_factory',
    'inject_dependencies_to_step_safe',
    
    # ğŸ”¥ ì•ˆì „í•œ ì ‘ê·¼ í•¨ìˆ˜ë“¤ (ëª¨ë“  *_safe í•¨ìˆ˜ë“¤)
    'get_service_safe',
    'register_service_safe',
    'register_factory_safe',
    'get_model_loader_safe',
    'get_memory_manager_safe',
    'get_data_converter_safe',
    'get_container_safe',
    'inject_dependencies_safe',
    'ensure_model_loader_registration',
    'ensure_service_registration',
    'initialize_di_system_safe',
    'cleanup_services_safe',
    'reset_container_safe',
    
    # ğŸ”¥ ì§€ì—° ì„œë¹„ìŠ¤ ê´€ë ¨ (ëˆ„ë½ëœ í•¨ìˆ˜ë“¤)
    'register_lazy_service',
    'register_lazy_service_safe',
    'create_lazy_dependency',
    'resolve_lazy_service',
    'is_lazy_service_resolved',
    
    # ğŸ”¥ Container ë ˆë²¨ í•¨ìˆ˜ë“¤ (êµ¬ ë²„ì „ í˜¸í™˜)
    'create_container',
    'dispose_container',
    'get_container_instance',
    'register_singleton',
    'register_transient',
    'unregister_service',
    
    # ğŸ”¥ ì˜ì¡´ì„± ì£¼ì… ê´€ë ¨
    'inject_all_dependencies',
    'auto_wire_dependencies',
    'validate_dependencies',
    'get_dependency_status',
    
    # ğŸ”¥ ì„œë¹„ìŠ¤ ì¡°íšŒ í¸ì˜ í•¨ìˆ˜ë“¤
    'get_all_services',
    'list_service_keys',
    'get_service_count',
    
    # ìƒíƒœ í™•ì¸ í•¨ìˆ˜ë“¤
    'is_service_available',
    'is_container_ready',
    'is_di_system_ready',
    'get_service_status',
    'get_di_system_status',
    
    # í˜¸í™˜ì„± í•¨ìˆ˜ë“¤
    'CircularReferenceFreeDIContainer',  # êµ¬ ë²„ì „ í˜¸í™˜
    'LazyDependency',  # êµ¬ ë²„ì „ í˜¸í™˜
    'DynamicImportResolver',  # í˜¸í™˜ì„±
    '_get_global_di_container',
    '_get_service_from_container_safe',
    
    # êµ¬ ë²„ì „ í˜¸í™˜ í•¨ìˆ˜ë“¤  
    'get_global_container_legacy',
    'reset_global_container_legacy',
    
    # íƒ€ì…ë“¤
    'T'
]
# ==============================================
# ğŸ”¥ ìë™ ì´ˆê¸°í™”
# ==============================================

if IS_CONDA:
    logger.info(f"ğŸ conda í™˜ê²½ '{CONDA_ENV}' ê°ì§€")

# ì™„ë£Œ ë©”ì‹œì§€
logger.info("=" * 80)
logger.info("ğŸ”¥ Event-Driven DI Container v6.0 ë¡œë“œ ì™„ë£Œ!")
logger.info("=" * 80)
logger.info("âœ… Event-Driven Architecture - ì˜ì¡´ì„± ìš”ì²­/í•´ê²°ì„ ì´ë²¤íŠ¸ë¡œ ë¶„ë¦¬")
logger.info("âœ… Factory Pattern + Command Pattern - ê°ì²´ ìƒì„± ë¡œì§ ì™„ì „ ë¶„ë¦¬")
logger.info("âœ… Pub/Sub ë©”ì‹œì§• - ëŠìŠ¨í•œ ê²°í•©ìœ¼ë¡œ ìˆœí™˜ì°¸ì¡° ì›ì²œ ì°¨ë‹¨")
logger.info("âœ… Lazy Registration - ì‹¤ì œ í•„ìš”í•  ë•Œë§Œ ì˜ì¡´ì„± í•´ê²°")
logger.info("âœ… Contextual Isolation - ê° Stepì´ ë…ë¦½ì  DI ì»¨í…ìŠ¤íŠ¸ ë³´ìœ ")
logger.info("âœ… Interface Segregation - ì‘ì€ ë‹¨ìœ„ ì¸í„°í˜ì´ìŠ¤ë¡œ ì±…ì„ ë¶„ë¦¬")
logger.info("âœ… Dependency Graph - ì˜ì¡´ì„± ì¶”ì ìœ¼ë¡œ ìˆœí™˜ì°¸ì¡° ì‚¬ì „ ê°ì§€")
logger.info("âœ… Observable Pattern - ì˜ì¡´ì„± ë³€ê²½ ì‚¬í•­ ì‹¤ì‹œê°„ ì•Œë¦¼")
logger.info("âœ… Memory Pool - ê°ì²´ ì¬ì‚¬ìš©ìœ¼ë¡œ ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± ê·¹ëŒ€í™”")
logger.info("âœ… ê¸°ì¡´ API 100% í˜¸í™˜ì„± ìœ ì§€")

logger.info("ğŸ¯ í•µì‹¬ ì•„í‚¤í…ì²˜:")
logger.info("   Event Bus â†’ Dependency Factory â†’ Service Registry â†’ Lifecycle Manager")

logger.info("ğŸ”§ ì§€ì› ê¸°ëŠ¥:")
logger.info("   â€¢ ìˆœí™˜ì°¸ì¡° ì›ì²œ ì°¨ë‹¨")
logger.info("   â€¢ ì»¨í…ìŠ¤íŠ¸ë³„ ê²©ë¦¬")
logger.info("   â€¢ ì´ë²¤íŠ¸ ê¸°ë°˜ ëª¨ë‹ˆí„°ë§")
logger.info("   â€¢ ìë™ ìƒëª…ì£¼ê¸° ê´€ë¦¬")
logger.info("   â€¢ ModelLoader v5.1 ì™„ì „ ì—°ë™")
logger.info("   â€¢ êµ¬ ë²„ì „ 100% í˜¸í™˜ì„±")

if IS_M3_MAX:
    logger.info("ğŸ M3 Max 128GB ë©”ëª¨ë¦¬ ìµœì í™” í™œì„±í™”")

logger.info("ğŸš€ Event-Driven DI Container v6.0 ì¤€ë¹„ ì™„ë£Œ!")
logger.info("ğŸ‰ ìˆœí™˜ì°¸ì¡° ë¬¸ì œ ê·¼ë³¸ì  í•´ê²°!")
logger.info("ğŸ‰ MyCloset AI í”„ë¡œì íŠ¸ ì™„ë²½ ì—°ë™!")
logger.info("=" * 80)