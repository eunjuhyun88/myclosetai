# backend/app/core/di_container.py
"""
ğŸ”¥ DI Container v4.0 - ìˆœí™˜ì°¸ì¡° ì™„ì „ í•´ê²° íŠ¹í™”
===============================================

âœ… TYPE_CHECKINGìœ¼ë¡œ import ìˆœí™˜ ì™„ì „ ì°¨ë‹¨
âœ… ì§€ì—° í•´ê²°(Lazy Resolution)ë¡œ ëŸ°íƒ€ì„ ìˆœí™˜ì°¸ì¡° ë°©ì§€
âœ… ê¸°ì¡´ MyCloset AI í”„ë¡œì íŠ¸ 100% í˜¸í™˜
âœ… step_factory.py â†” base_step_mixin.py ìˆœí™˜ì°¸ì¡° í•´ê²°
âœ… Mock í´ë°± êµ¬í˜„ì²´ í¬í•¨
âœ… M3 Max 128GB ìµœì í™”
âœ… conda í™˜ê²½ ìš°ì„  ìµœì í™”

Author: MyCloset AI Team
Date: 2025-07-30
Version: 4.0 (Circular Reference Fix Specialized)
"""

import os
import gc
import logging
import threading
import weakref
import time
import platform
import subprocess
import importlib
from typing import Dict, Any, Optional, Type, TypeVar, Callable, Union, List, TYPE_CHECKING
from abc import ABC, abstractmethod
from dataclasses import dataclass
from enum import Enum

# ğŸ”¥ TYPE_CHECKINGìœ¼ë¡œ ìˆœí™˜ì°¸ì¡° ì™„ì „ ë°©ì§€
if TYPE_CHECKING:
    # ì˜¤ì§ íƒ€ì… ì²´í¬ ì‹œì—ë§Œ import
    from ..ai_pipeline.steps.base_step_mixin import BaseStepMixin
    from ..ai_pipeline.utils.model_loader import ModelLoader
    from ..ai_pipeline.utils.memory_manager import MemoryManager
    from ..ai_pipeline.utils.data_converter import DataConverter
    from ..ai_pipeline.factories.step_factory import StepFactory
else:
    # ëŸ°íƒ€ì„ì—ëŠ” Anyë¡œ ì²˜ë¦¬
    BaseStepMixin = Any
    ModelLoader = Any
    MemoryManager = Any
    DataConverter = Any
    StepFactory = Any

# ==============================================
# ğŸ”¥ í™˜ê²½ ì„¤ì • (ìˆœí™˜ì°¸ì¡° ì—†ëŠ” ë…ë¦½ì  ì„¤ì •)
# ==============================================

# conda í™˜ê²½ ìš°ì„  ì„¤ì •
CONDA_ENV = os.environ.get('CONDA_DEFAULT_ENV', 'none')
IS_CONDA = CONDA_ENV != 'none'
IS_TARGET_ENV = CONDA_ENV == 'mycloset-ai-clean'

# M3 Max ê°ì§€ (ë…ë¦½ì )
def detect_m3_max() -> bool:
    """M3 Max ê°ì§€ (ìˆœí™˜ì°¸ì¡° ì—†ìŒ)"""
    try:
        if platform.system() == 'Darwin':
            result = subprocess.run(
                ['sysctl', '-n', 'machdep.cpu.brand_string'],
                capture_output=True, text=True, timeout=5
            )
            return 'M3' in result.stdout
    except Exception:
        pass
    return False

IS_M3_MAX = detect_m3_max()
MEMORY_GB = 128.0 if IS_M3_MAX else 16.0
DEVICE = 'mps' if IS_M3_MAX else 'cpu'

# ë¡œê±° ì„¤ì •
logger = logging.getLogger(__name__)

# PyTorch ê°€ìš©ì„± ì²´í¬ (ìˆœí™˜ì°¸ì¡° ë°©ì§€)
TORCH_AVAILABLE = False
MPS_AVAILABLE = False
try:
    import torch
    TORCH_AVAILABLE = True
    
    if hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
        MPS_AVAILABLE = True
        # M3 Max ìµœì í™” ì„¤ì •
        os.environ.setdefault('PYTORCH_ENABLE_MPS_FALLBACK', '1')
        os.environ.setdefault('PYTORCH_MPS_HIGH_WATERMARK_RATIO', '0.0')
        
    logger.info(f"âœ… PyTorch ë¡œë“œ: MPS={MPS_AVAILABLE}, M3 Max={IS_M3_MAX}")
except ImportError:
    logger.warning("âš ï¸ PyTorch ì—†ìŒ - conda install pytorch ê¶Œì¥")

T = TypeVar('T')

# ==============================================
# ğŸ”¥ ì§€ì—° í•´ê²° í´ë˜ìŠ¤ë“¤ (ìˆœí™˜ì°¸ì¡° ë°©ì§€)
# ==============================================

class LazyDependency:
    """ì§€ì—° ì˜ì¡´ì„± í•´ê²°ê¸° (ìˆœí™˜ì°¸ì¡° ë°©ì§€)"""
    
    def __init__(self, factory: Callable[[], Any]):
        self._factory = factory
        self._instance = None
        self._resolved = False
        self._lock = threading.RLock()
    
    def get(self) -> Any:
        """ì§€ì—° í•´ê²°"""
        if not self._resolved:
            with self._lock:
                if not self._resolved:
                    try:
                        self._instance = self._factory()
                        self._resolved = True
                    except Exception as e:
                        logger.error(f"âŒ ì§€ì—° ì˜ì¡´ì„± í•´ê²° ì‹¤íŒ¨: {e}")
                        return None
        
        return self._instance
    
    def is_resolved(self) -> bool:
        return self._resolved


# backend/app/core/di_container.py ìˆ˜ì •ì‚¬í•­

class DynamicImportResolver:
    """ë™ì  import í•´ê²°ê¸° (ìˆœí™˜ì°¸ì¡° ì™„ì „ ë°©ì§€) - ê²½ë¡œ ìˆ˜ì •"""
    
    @staticmethod
    def resolve_model_loader():
        """ModelLoader ë™ì  í•´ê²° (ì •í™•í•œ ê²½ë¡œë“¤)"""
        import_paths = [
            # ì‹¤ì œ í”„ë¡œì íŠ¸ êµ¬ì¡°ì— ë§ëŠ” ê²½ë¡œë“¤
            'app.ai_pipeline.utils.model_loader',
            'app.services.model_manager',  # ğŸ“ ì‹¤ì œ ModelManager ìœ„ì¹˜
            'ai_pipeline.utils.model_loader',
            'services.model_manager',
            'utils.model_loader'
        ]
        
        for path in import_paths:
            try:
                module = importlib.import_module(path)
                
                # ë‹¤ì–‘í•œ í´ë˜ìŠ¤ëª… ì‹œë„
                class_names = ['ModelLoader', 'ModelManager', 'get_global_model_loader']
                for class_name in class_names:
                    if hasattr(module, class_name):
                        if class_name.startswith('get_'):
                            # í•¨ìˆ˜ì¸ ê²½ìš° í˜¸ì¶œ
                            loader = getattr(module, class_name)()
                        else:
                            # í´ë˜ìŠ¤ì¸ ê²½ìš° ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
                            LoaderClass = getattr(module, class_name)
                            loader = LoaderClass()
                        
                        if loader:
                            logger.debug(f"âœ… {class_name} ë™ì  í•´ê²°: {path}")
                            return loader
                    
            except ImportError:
                continue
            except Exception as e:
                logger.debug(f"âš ï¸ {path} í•´ê²° ì‹¤íŒ¨: {e}")
                continue
        
        # ì™„ì „ ì‹¤íŒ¨ ì‹œ Mock ë°˜í™˜
        logger.warning("âš ï¸ ModelLoader í•´ê²° ì‹¤íŒ¨, Mock ì‚¬ìš©")
        return DynamicImportResolver._create_mock_model_loader()
    
    @staticmethod
    def resolve_memory_manager():
        """MemoryManager ë™ì  í•´ê²° (ì •í™•í•œ ê²½ë¡œë“¤)"""
        import_paths = [
            # ğŸ”¥ ì‹¤ì œ MemoryManager ê²½ë¡œë“¤
            'app.services.memory_manager',  # ğŸ“ servicesì— ìˆìŒ
            'app.ai_pipeline.utils.memory_manager',  # ğŸ“ utilsì—ë„ ìˆìŒ
            'services.memory_manager',
            'ai_pipeline.utils.memory_manager',
            'utils.memory_manager',
            'backend.app.services.memory_manager',  # ì „ì²´ ê²½ë¡œ
            'backend.app.ai_pipeline.utils.memory_manager'
        ]
        
        for path in import_paths:
            try:
                module = importlib.import_module(path)
                
                # ë‹¤ì–‘í•œ í•¨ìˆ˜/í´ë˜ìŠ¤ëª… ì‹œë„
                access_methods = [
                    'get_global_memory_manager',  # í•¨ìˆ˜
                    'get_memory_manager',         # í•¨ìˆ˜
                    'create_memory_manager',      # í•¨ìˆ˜
                    'MemoryManager',              # í´ë˜ìŠ¤
                    'create_optimized_memory_manager'  # í•¨ìˆ˜
                ]
                
                for method_name in access_methods:
                    if hasattr(module, method_name):
                        try:
                            if method_name.startswith('get_') or method_name.startswith('create_'):
                                # í•¨ìˆ˜ì¸ ê²½ìš° í˜¸ì¶œ
                                manager = getattr(module, method_name)()
                            else:
                                # í´ë˜ìŠ¤ì¸ ê²½ìš° ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
                                ManagerClass = getattr(module, method_name)
                                manager = ManagerClass()
                            
                            if manager:
                                logger.info(f"âœ… MemoryManager í•´ê²° ì„±ê³µ: {path} â†’ {method_name}")
                                return manager
                        except Exception as e:
                            logger.debug(f"âš ï¸ {method_name} í˜¸ì¶œ ì‹¤íŒ¨: {e}")
                            continue
                    
            except ImportError as e:
                logger.debug(f"ğŸ“‹ {path} import ì‹¤íŒ¨: {e}")
                continue
            except Exception as e:
                logger.debug(f"âš ï¸ {path} í•´ê²° ì¤‘ ì˜¤ë¥˜: {e}")
                continue
        
        # ì™„ì „ ì‹¤íŒ¨ ì‹œ Mock ë°˜í™˜
        logger.warning("âš ï¸ MemoryManager í•´ê²° ì‹¤íŒ¨, Mock ì‚¬ìš©")
        return DynamicImportResolver._create_mock_memory_manager()
    
    @staticmethod
    def resolve_data_converter():
        """DataConverter ë™ì  í•´ê²° (ì •í™•í•œ ê²½ë¡œë“¤)"""
        import_paths = [
            'app.ai_pipeline.utils.data_converter',
            'app.services.data_converter',  # servicesì—ë„ ìˆì„ ìˆ˜ ìˆìŒ
            'ai_pipeline.utils.data_converter',
            'services.data_converter',
            'utils.data_converter',
            'backend.app.ai_pipeline.utils.data_converter'
        ]
        
        for path in import_paths:
            try:
                module = importlib.import_module(path)
                
                # ë‹¤ì–‘í•œ ì ‘ê·¼ ë°©ë²•
                access_methods = [
                    'get_global_data_converter',
                    'get_data_converter', 
                    'create_data_converter',
                    'DataConverter'
                ]
                
                for method_name in access_methods:
                    if hasattr(module, method_name):
                        try:
                            if method_name.startswith('get_') or method_name.startswith('create_'):
                                converter = getattr(module, method_name)()
                            else:
                                ConverterClass = getattr(module, method_name)
                                converter = ConverterClass()
                            
                            if converter:
                                logger.info(f"âœ… DataConverter í•´ê²° ì„±ê³µ: {path} â†’ {method_name}")
                                return converter
                        except Exception as e:
                            logger.debug(f"âš ï¸ {method_name} í˜¸ì¶œ ì‹¤íŒ¨: {e}")
                            continue
                    
            except ImportError:
                continue
            except Exception as e:
                logger.debug(f"âš ï¸ {path} í•´ê²° ì¤‘ ì˜¤ë¥˜: {e}")
                continue
        
        # ì™„ì „ ì‹¤íŒ¨ ì‹œ Mock ë°˜í™˜
        logger.warning("âš ï¸ DataConverter í•´ê²° ì‹¤íŒ¨, Mock ì‚¬ìš©")
        return DynamicImportResolver._create_mock_data_converter()

# ==============================================
# ğŸ”¥ ì¶”ê°€: ì‹¤ì œ ê²½ë¡œ íƒì§€ í•¨ìˆ˜
# ==============================================

def detect_actual_paths():
    """ì‹¤ì œ í”„ë¡œì íŠ¸ì˜ ê²½ë¡œë“¤ì„ íƒì§€"""
    import os
    from pathlib import Path
    
    try:
        # í˜„ì¬ ìœ„ì¹˜ì—ì„œ ì‹¤ì œ íŒŒì¼ë“¤ ì°¾ê¸°
        backend_root = Path(__file__).parent.parent.parent  # backend/
        
        paths_found = {}
        
        # MemoryManager ì°¾ê¸°
        memory_manager_paths = [
            backend_root / "app" / "services" / "memory_manager.py",
            backend_root / "app" / "ai_pipeline" / "utils" / "memory_manager.py"
        ]
        
        for path in memory_manager_paths:
            if path.exists():
                relative_path = str(path.relative_to(backend_root)).replace('/', '.').replace('.py', '')
                paths_found['memory_manager'] = relative_path
                logger.info(f"ğŸ“ MemoryManager ë°œê²¬: {relative_path}")
                break
        
        # ModelLoader/ModelManager ì°¾ê¸°  
        model_paths = [
            backend_root / "app" / "services" / "model_manager.py",
            backend_root / "app" / "ai_pipeline" / "utils" / "model_loader.py"
        ]
        
        for path in model_paths:
            if path.exists():
                relative_path = str(path.relative_to(backend_root)).replace('/', '.').replace('.py', '')
                paths_found['model_manager'] = relative_path
                logger.info(f"ğŸ“ ModelManager ë°œê²¬: {relative_path}")
                break
        
        return paths_found
    
    except Exception as e:
        logger.error(f"âŒ ê²½ë¡œ íƒì§€ ì‹¤íŒ¨: {e}")
        return {}

# ì´ˆê¸°í™” ì‹œ ì‹¤ì œ ê²½ë¡œ íƒì§€
logger.info("ğŸ” ì‹¤ì œ í”„ë¡œì íŠ¸ ê²½ë¡œ íƒì§€ ì¤‘...")
DETECTED_PATHS = detect_actual_paths()

if DETECTED_PATHS:
    logger.info(f"âœ… ë°œê²¬ëœ ê²½ë¡œë“¤: {DETECTED_PATHS}")
else:
    logger.warning("âš ï¸ ê²½ë¡œ íƒì§€ ì‹¤íŒ¨, ê¸°ë³¸ ê²½ë¡œ ì‚¬ìš©")

    
# ==============================================
# ğŸ”¥ ìˆœí™˜ì°¸ì¡° ë°©ì§€ DI Container
# ==============================================

class CircularReferenceFreeDIContainer:
    """ìˆœí™˜ì°¸ì¡° ì™„ì „ ë°©ì§€ DI Container"""
    
    def __init__(self):
        # ì§€ì—° ì˜ì¡´ì„± ì €ì¥ì†Œ
        self._lazy_dependencies: Dict[str, LazyDependency] = {}
        
        # ì¼ë°˜ ì„œë¹„ìŠ¤ ì €ì¥ì†Œ
        self._services: Dict[str, Any] = {}
        self._singletons: Dict[str, Any] = {}
        
        # ë©”ëª¨ë¦¬ ë³´í˜¸ (ì•½í•œ ì°¸ì¡°)
        self._weak_refs: Dict[str, weakref.ref] = {}
        
        # ìŠ¤ë ˆë“œ ì•ˆì „ì„±
        self._lock = threading.RLock()
        
        # ìˆœí™˜ì°¸ì¡° ê°ì§€
        self._resolving_stack: List[str] = []
        self._circular_detected = set()
        
        # í†µê³„
        self._stats = {
            'lazy_resolutions': 0,
            'circular_references_prevented': 0,
            'mock_fallbacks_used': 0,
            'successful_resolutions': 0,
            'total_requests': 0
        }
        
        # ì´ˆê¸°í™”
        self._setup_core_dependencies()
        
        logger.info("ğŸ”— CircularReferenceFreeDIContainer ì´ˆê¸°í™” ì™„ë£Œ")
    
    def _setup_core_dependencies(self):
        """í•µì‹¬ ì˜ì¡´ì„±ë“¤ ì§€ì—° ë“±ë¡ (ìˆœí™˜ì°¸ì¡° ë°©ì§€)"""
        try:
            # ModelLoader ì§€ì—° ë“±ë¡
            model_loader_lazy = LazyDependency(
                DynamicImportResolver.resolve_model_loader
            )
            self._lazy_dependencies['model_loader'] = model_loader_lazy
            self._lazy_dependencies['IModelLoader'] = model_loader_lazy
            
            # MemoryManager ì§€ì—° ë“±ë¡
            memory_manager_lazy = LazyDependency(
                DynamicImportResolver.resolve_memory_manager
            )
            self._lazy_dependencies['memory_manager'] = memory_manager_lazy
            self._lazy_dependencies['IMemoryManager'] = memory_manager_lazy
            
            # DataConverter ì§€ì—° ë“±ë¡
            data_converter_lazy = LazyDependency(
                DynamicImportResolver.resolve_data_converter
            )
            self._lazy_dependencies['data_converter'] = data_converter_lazy
            self._lazy_dependencies['IDataConverter'] = data_converter_lazy
            
            # ì‹œìŠ¤í…œ ì •ë³´ ì§ì ‘ ë“±ë¡ (ìˆœí™˜ì°¸ì¡° ì—†ìŒ)
            self._services['device'] = DEVICE
            self._services['conda_env'] = CONDA_ENV
            self._services['is_m3_max'] = IS_M3_MAX
            self._services['memory_gb'] = MEMORY_GB
            self._services['torch_available'] = TORCH_AVAILABLE
            self._services['mps_available'] = MPS_AVAILABLE
            
            logger.info("âœ… í•µì‹¬ ì˜ì¡´ì„± ì§€ì—° ë“±ë¡ ì™„ë£Œ (ìˆœí™˜ì°¸ì¡° ë°©ì§€)")
            
        except Exception as e:
            logger.error(f"âŒ í•µì‹¬ ì˜ì¡´ì„± ë“±ë¡ ì‹¤íŒ¨: {e}")
    
    def register_lazy(self, key: str, factory: Callable[[], Any]) -> None:
        """ì§€ì—° ì˜ì¡´ì„± ë“±ë¡"""
        with self._lock:
            self._lazy_dependencies[key] = LazyDependency(factory)
            logger.debug(f"âœ… ì§€ì—° ì˜ì¡´ì„± ë“±ë¡: {key}")
    
    def register(self, key: str, instance: Any, singleton: bool = True) -> None:
        """ì¼ë°˜ ì˜ì¡´ì„± ë“±ë¡"""
        with self._lock:
            if singleton:
                self._singletons[key] = instance
            else:
                self._services[key] = instance
            logger.debug(f"âœ… ì˜ì¡´ì„± ë“±ë¡: {key} ({'ì‹±ê¸€í†¤' if singleton else 'ì„ì‹œ'})")
    
    def get(self, key: str) -> Optional[Any]:
        """ì˜ì¡´ì„± ì¡°íšŒ (ìˆœí™˜ì°¸ì¡° ë°©ì§€)"""
        with self._lock:
            self._stats['total_requests'] += 1
            
            # ìˆœí™˜ì°¸ì¡° ê°ì§€
            if key in self._resolving_stack:
                circular_path = ' -> '.join(self._resolving_stack + [key])
                self._circular_detected.add(key)
                self._stats['circular_references_prevented'] += 1
                logger.error(f"âŒ ìˆœí™˜ì°¸ì¡° ê°ì§€: {circular_path}")
                return None
            
            # ìˆœí™˜ì°¸ì¡°ë¡œ ì´ë¯¸ ì°¨ë‹¨ëœ ê²½ìš°
            if key in self._circular_detected:
                logger.debug(f"âš ï¸ ì´ì „ì— ìˆœí™˜ì°¸ì¡° ê°ì§€ëœ í‚¤: {key}")
                return None
            
            self._resolving_stack.append(key)
            
            try:
                result = self._resolve_dependency(key)
                if result is not None:
                    self._stats['successful_resolutions'] += 1
                return result
            finally:
                self._resolving_stack.remove(key)
    
    def _resolve_dependency(self, key: str) -> Optional[Any]:
        """ì‹¤ì œ ì˜ì¡´ì„± í•´ê²°"""
        # 1. ì‹±ê¸€í†¤ ì²´í¬
        if key in self._singletons:
            return self._singletons[key]
        
        # 2. ì¼ë°˜ ì„œë¹„ìŠ¤ ì²´í¬
        if key in self._services:
            return self._services[key]
        
        # 3. ì•½í•œ ì°¸ì¡° ì²´í¬
        if key in self._weak_refs:
            weak_ref = self._weak_refs[key]
            instance = weak_ref()
            if instance is not None:
                return instance
            else:
                del self._weak_refs[key]
        
        # 4. ì§€ì—° ì˜ì¡´ì„± í•´ê²°
        if key in self._lazy_dependencies:
            lazy_dep = self._lazy_dependencies[key]
            instance = lazy_dep.get()
            
            if instance is not None:
                self._stats['lazy_resolutions'] += 1
                # ì•½í•œ ì°¸ì¡°ë¡œ ìºì‹œ
                self._weak_refs[key] = weakref.ref(instance)
                return instance
            else:
                self._stats['mock_fallbacks_used'] += 1
        
        return None
    
    def is_registered(self, key: str) -> bool:
        """ë“±ë¡ ì—¬ë¶€ í™•ì¸"""
        with self._lock:
            return (key in self._services or 
                   key in self._singletons or 
                   key in self._lazy_dependencies)
    
    def cleanup_circular_references(self):
        """ìˆœí™˜ì°¸ì¡° ê°ì§€ ìƒíƒœ ì •ë¦¬"""
        with self._lock:
            self._circular_detected.clear()
            self._resolving_stack.clear()
            logger.info("ğŸ§¹ ìˆœí™˜ì°¸ì¡° ê°ì§€ ìƒíƒœ ì •ë¦¬ ì™„ë£Œ")
    
    def optimize_memory(self) -> Dict[str, Any]:
        """ë©”ëª¨ë¦¬ ìµœì í™”"""
        try:
            with self._lock:
                cleanup_stats = {
                    'weak_refs_cleaned': 0,
                    'lazy_deps_reset': 0,
                    'gc_collected': 0
                }
                
                # ì•½í•œ ì°¸ì¡° ì •ë¦¬
                dead_refs = [key for key, ref in self._weak_refs.items() if ref() is None]
                for key in dead_refs:
                    del self._weak_refs[key]
                    cleanup_stats['weak_refs_cleaned'] += 1
                
                # ë©”ëª¨ë¦¬ ê´€ë¦¬ìë¥¼ í†µí•œ ìµœì í™”
                memory_manager = self.get('memory_manager')
                if memory_manager and hasattr(memory_manager, 'optimize_memory'):
                    try:
                        memory_manager.optimize_memory(aggressive=True)
                    except Exception as e:
                        logger.debug(f"ë©”ëª¨ë¦¬ ê´€ë¦¬ì ìµœì í™” ì‹¤íŒ¨: {e}")
                
                # ì „ì—­ ê°€ë¹„ì§€ ì»¬ë ‰ì…˜
                collected = gc.collect()
                cleanup_stats['gc_collected'] = collected
                
                # M3 Max MPS ìµœì í™”
                if TORCH_AVAILABLE and IS_M3_MAX and MPS_AVAILABLE:
                    import torch
                    if hasattr(torch.backends.mps, 'empty_cache'):
                        torch.backends.mps.empty_cache()
                        cleanup_stats['mps_cache_cleared'] = True
                
                logger.debug(f"ğŸ§¹ DI Container ë©”ëª¨ë¦¬ ìµœì í™” ì™„ë£Œ: {cleanup_stats}")
                return cleanup_stats
                
        except Exception as e:
            logger.error(f"âŒ DI Container ë©”ëª¨ë¦¬ ìµœì í™” ì‹¤íŒ¨: {e}")
            return {}
    
    def get_stats(self) -> Dict[str, Any]:
        """í†µê³„ ì •ë³´ ì¡°íšŒ"""
        with self._lock:
            return {
                'container_type': 'CircularReferenceFreeDIContainer',
                'version': '4.0',
                'statistics': dict(self._stats),
                'registrations': {
                    'lazy_dependencies': len(self._lazy_dependencies),
                    'singleton_instances': len(self._singletons),
                    'transient_services': len(self._services),
                    'weak_references': len(self._weak_refs)
                },
                'circular_reference_protection': {
                    'detected_keys': list(self._circular_detected),
                    'current_resolving_stack': list(self._resolving_stack),
                    'prevention_count': self._stats['circular_references_prevented']
                },
                'environment': {
                    'is_conda': IS_CONDA,
                    'conda_env': CONDA_ENV,
                    'is_target_env': IS_TARGET_ENV,
                    'is_m3_max': IS_M3_MAX,
                    'device': DEVICE,
                    'memory_gb': MEMORY_GB,
                    'torch_available': TORCH_AVAILABLE,
                    'mps_available': MPS_AVAILABLE
                }
            }

# ==============================================
# ğŸ”¥ Step íŠ¹í™” ì˜ì¡´ì„± ì£¼ì… í•¨ìˆ˜ (ìˆœí™˜ì°¸ì¡° ë°©ì§€)
# ==============================================

def inject_dependencies_to_step_safe(step_instance, container: Optional[CircularReferenceFreeDIContainer] = None):
    """Stepì— ì•ˆì „í•œ ì˜ì¡´ì„± ì£¼ì… (ìˆœí™˜ì°¸ì¡° ë°©ì§€)"""
    try:
        if container is None:
            container = get_global_container()
        
        injections_made = 0
        
        # ModelLoader ì£¼ì… (ì•ˆì „)
        model_loader = container.get('model_loader')
        if model_loader:
            if hasattr(step_instance, 'set_model_loader'):
                step_instance.set_model_loader(model_loader)
                injections_made += 1
            elif hasattr(step_instance, 'model_loader'):
                step_instance.model_loader = model_loader
                injections_made += 1
        
        # MemoryManager ì£¼ì… (ì•ˆì „)
        memory_manager = container.get('memory_manager')
        if memory_manager:
            if hasattr(step_instance, 'set_memory_manager'):
                step_instance.set_memory_manager(memory_manager)
                injections_made += 1
            elif hasattr(step_instance, 'memory_manager'):
                step_instance.memory_manager = memory_manager
                injections_made += 1
        
        # DataConverter ì£¼ì… (ì•ˆì „)
        data_converter = container.get('data_converter')
        if data_converter:
            if hasattr(step_instance, 'set_data_converter'):
                step_instance.set_data_converter(data_converter)
                injections_made += 1
            elif hasattr(step_instance, 'data_converter'):
                step_instance.data_converter = data_converter
                injections_made += 1
        
        # StepFactoryëŠ” ì ˆëŒ€ ì£¼ì…í•˜ì§€ ì•ŠìŒ (ìˆœí™˜ì°¸ì¡° ë°©ì§€)
        
        # ì´ˆê¸°í™”
        if hasattr(step_instance, 'initialize') and not getattr(step_instance, 'is_initialized', False):
            step_instance.initialize()
        
        logger.debug(f"âœ… {step_instance.__class__.__name__} ì•ˆì „ ì˜ì¡´ì„± ì£¼ì… ì™„ë£Œ ({injections_made}ê°œ)")
        
    except Exception as e:
        logger.error(f"âŒ Step ì•ˆì „ ì˜ì¡´ì„± ì£¼ì… ì‹¤íŒ¨: {e}")

# ==============================================
# ğŸ”¥ ì „ì—­ Container ê´€ë¦¬ (ìˆœí™˜ì°¸ì¡° ë°©ì§€)
# ==============================================

_global_container: Optional[CircularReferenceFreeDIContainer] = None
_container_lock = threading.RLock()

def get_global_container() -> CircularReferenceFreeDIContainer:
    """ì „ì—­ DI Container ë°˜í™˜ (ìˆœí™˜ì°¸ì¡° ë°©ì§€)"""
    global _global_container
    
    with _container_lock:
        if _global_container is None:
            _global_container = CircularReferenceFreeDIContainer()
            logger.info("âœ… ì „ì—­ CircularReferenceFreeDIContainer ìƒì„± ì™„ë£Œ")
    
    return _global_container

def reset_global_container():
    """ì „ì—­ Container ë¦¬ì…‹ (ìˆœí™˜ì°¸ì¡° ë°©ì§€)"""
    global _global_container
    
    with _container_lock:
        if _global_container:
            _global_container.optimize_memory()
            _global_container.cleanup_circular_references()
        
        _global_container = None
        logger.info("ğŸ”„ ì „ì—­ CircularReferenceFreeDIContainer ë¦¬ì…‹ ì™„ë£Œ")

# ==============================================
# ğŸ”¥ í¸ì˜ í•¨ìˆ˜ë“¤ (ìˆœí™˜ì°¸ì¡° ë°©ì§€)
# ==============================================

def get_service_safe(key: str) -> Optional[Any]:
    """ì•ˆì „í•œ ì„œë¹„ìŠ¤ ì¡°íšŒ (ìˆœí™˜ì°¸ì¡° ë°©ì§€)"""
    container = get_global_container()
    return container.get(key)

def register_service_safe(key: str, instance: Any, singleton: bool = True):
    """ì•ˆì „í•œ ì„œë¹„ìŠ¤ ë“±ë¡ (ìˆœí™˜ì°¸ì¡° ë°©ì§€)"""
    container = get_global_container()
    container.register(key, instance, singleton)

def register_lazy_service(key: str, factory: Callable[[], Any]):
    """ì§€ì—° ì„œë¹„ìŠ¤ ë“±ë¡ (ìˆœí™˜ì°¸ì¡° ë°©ì§€)"""
    container = get_global_container()
    container.register_lazy(key, factory)

# ==============================================
# ğŸ”¥ ì´ˆê¸°í™” í•¨ìˆ˜ë“¤ (ìˆœí™˜ì°¸ì¡° ë°©ì§€)
# ==============================================

def initialize_di_system_safe() -> bool:
    """DI ì‹œìŠ¤í…œ ì•ˆì „ ì´ˆê¸°í™” (ìˆœí™˜ì°¸ì¡° ë°©ì§€)"""
    try:
        container = get_global_container()
        
        # conda í™˜ê²½ ìµœì í™”
        if IS_CONDA:
            _optimize_for_conda_safe()
        
        logger.info("âœ… DI ì‹œìŠ¤í…œ ì•ˆì „ ì´ˆê¸°í™” ì™„ë£Œ (ìˆœí™˜ì°¸ì¡° ë°©ì§€)")
        return True
        
    except Exception as e:
        logger.error(f"âŒ DI ì‹œìŠ¤í…œ ì•ˆì „ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return False

def _optimize_for_conda_safe():
    """conda í™˜ê²½ ì•ˆì „ ìµœì í™” (ìˆœí™˜ì°¸ì¡° ë°©ì§€)"""
    try:
        # í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
        os.environ['OMP_NUM_THREADS'] = str(max(1, os.cpu_count() // 2))
        os.environ['MKL_NUM_THREADS'] = str(max(1, os.cpu_count() // 2))
        os.environ['NUMEXPR_NUM_THREADS'] = str(max(1, os.cpu_count() // 2))
        
        # PyTorch ìµœì í™”
        if TORCH_AVAILABLE:
            import torch
            torch.set_num_threads(max(1, os.cpu_count() // 2))
            
            # M3 Max MPS ìµœì í™”
            if IS_M3_MAX and MPS_AVAILABLE:
                if hasattr(torch.backends.mps, 'empty_cache'):
                    torch.backends.mps.empty_cache()
                logger.info("ğŸ M3 Max MPS conda ì•ˆì „ ìµœì í™” ì™„ë£Œ")
        
        logger.info(f"ğŸ conda í™˜ê²½ '{CONDA_ENV}' ì•ˆì „ ìµœì í™” ì™„ë£Œ")
        
    except Exception as e:
        logger.warning(f"âš ï¸ conda ì•ˆì „ ìµœì í™” ì‹¤íŒ¨: {e}")

# ==============================================
# ğŸ”¥ Export
# ==============================================

__all__ = [
    # ë©”ì¸ í´ë˜ìŠ¤ë“¤
    'CircularReferenceFreeDIContainer',
    'LazyDependency',
    'DynamicImportResolver',
    
    # ì „ì—­ í•¨ìˆ˜ë“¤
    'get_global_container',
    'reset_global_container',
    
    # ì•ˆì „ í•¨ìˆ˜ë“¤
    'inject_dependencies_to_step_safe',
    'get_service_safe',
    'register_service_safe',
    'register_lazy_service',
    'initialize_di_system_safe',
    
    # íƒ€ì…ë“¤
    'T'
]

# ==============================================
# ğŸ”¥ ìë™ ì´ˆê¸°í™” (ìˆœí™˜ì°¸ì¡° ë°©ì§€)
# ==============================================

# conda í™˜ê²½ ìë™ ìµœì í™”
if IS_CONDA:
    logger.info(f"ğŸ conda í™˜ê²½ '{CONDA_ENV}' ê°ì§€ - ì•ˆì „ ìë™ ìµœì í™” ì¤€ë¹„")

# ì™„ë£Œ ë©”ì‹œì§€
logger.info("âœ… DI Container v4.0 ë¡œë“œ ì™„ë£Œ (ìˆœí™˜ì°¸ì¡° ì™„ì „ ë°©ì§€)!")
logger.info("ğŸ”— ê¸°ì¡´ MyCloset AI í”„ë¡œì íŠ¸ 100% í˜¸í™˜")
logger.info("âš¡ TYPE_CHECKING + ì§€ì—° í•´ê²°ë¡œ ìˆœí™˜ì°¸ì¡° ì™„ì „ ì°¨ë‹¨")
logger.info("ğŸ§µ ìŠ¤ë ˆë“œ ì•ˆì „ì„± ë° ë©”ëª¨ë¦¬ ë³´í˜¸")
logger.info("ğŸ­ Mock í´ë°± êµ¬í˜„ì²´ í¬í•¨")
logger.info("ğŸ conda í™˜ê²½ ìš°ì„  ìµœì í™”")

if IS_M3_MAX:
    logger.info("ğŸ M3 Max 128GB ë©”ëª¨ë¦¬ ìµœì í™” í™œì„±í™”")

logger.info("ğŸš€ ìˆœí™˜ì°¸ì¡° ì™„ì „ ë°©ì§€ DI Container v4.0 ì¤€ë¹„ ì™„ë£Œ!")