# backend/app/core/model_paths.py
"""
ğŸ”¥ MyCloset AI í†µí•© ëª¨ë¸ ê²½ë¡œ ê´€ë¦¬ v7.0 - ì™„ì „ ìˆ˜ì •íŒ
================================================================================
âœ… backend ì¤‘ë³µ ìƒì„± ë¬¸ì œ ì™„ì „ í•´ê²°
âœ… 229GB AI ëª¨ë¸ ê²½ë¡œ ë§¤í•‘ ì™„ì„±
âœ… ë™ì  ê²½ë¡œ íƒì§€ ì‹œìŠ¤í…œ êµ¬í˜„
âœ… conda í™˜ê²½ + M3 Max ìµœì í™”
âœ… ì‹¤ì œ í”„ë¡œì íŠ¸ êµ¬ì¡° ê¸°ë°˜ ì •í™•í•œ ê²½ë¡œ ë§¤í•‘
âœ… ì•ˆì „í•œ ê²½ë¡œ ê³„ì‚° ë° í´ë°± ë©”ì»¤ë‹ˆì¦˜ ê°•í™”
âœ… Stepë³„ AI ëª¨ë¸ ìš°ì„ ìˆœìœ„ ë§¤í•‘
âœ… 25GB+ í•µì‹¬ ëª¨ë¸ ì™„ì „ í™œìš©

ê¸°ë°˜: Stepë³„ AI ëª¨ë¸ ì ìš© ê³„íš ë° ì‹¤ì œ íŒŒì¼ ê²½ë¡œ ë§¤í•‘ ìµœì‹ íŒ.pdf
ì´ ëª¨ë¸ íŒŒì¼: 229GB (127ê°œ íŒŒì¼, 99ê°œ ë””ë ‰í† ë¦¬)
"""

from pathlib import Path
from typing import Dict, Optional, List, Union, Any
import logging
import os
import sys
from functools import lru_cache

logger = logging.getLogger(__name__)

# =============================================================================
# ğŸ”¥ 1. ì•ˆì „í•œ í”„ë¡œì íŠ¸ ê²½ë¡œ ê³„ì‚° (backend ì¤‘ë³µ ë¬¸ì œ ì™„ì „ í•´ê²°)
# =============================================================================

def _get_safe_project_root() -> Path:
    """
    ì•ˆì „í•œ í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ ê³„ì‚°
    backend ì¤‘ë³µ ìƒì„± ë¬¸ì œ ì™„ì „ í•´ê²°
    """
    current_file = Path(__file__).absolute()
    logger.debug(f"ğŸ” í˜„ì¬ íŒŒì¼: {current_file}")
    
    # í˜„ì¬ íŒŒì¼: backend/app/core/model_paths.py
    current = current_file.parent  # core/
    
    # backend/ ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ë•Œê¹Œì§€ ìƒìœ„ë¡œ ì´ë™
    for level in range(10):  # ìµœëŒ€ 10ë‹¨ê³„
        logger.debug(f"  ë ˆë²¨ {level}: {current} (ì´ë¦„: {current.name})")
        
        if current.name == 'backend':
            # backend/ ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì•˜ìœ¼ë©´ ê·¸ ë¶€ëª¨ê°€ í”„ë¡œì íŠ¸ ë£¨íŠ¸
            project_root = current.parent
            logger.info(f"âœ… í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë°œê²¬: {project_root}")
            return project_root
            
        elif current.name == 'mycloset-ai':
            # ì§ì ‘ í”„ë¡œì íŠ¸ ë£¨íŠ¸ì— ë„ë‹¬í•œ ê²½ìš°
            logger.info(f"âœ… í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì§ì ‘ ë°œê²¬: {current}")
            return current
            
        elif current.parent == current:
            # íŒŒì¼ì‹œìŠ¤í…œ ë£¨íŠ¸ì— ë„ë‹¬
            logger.warning("âš ï¸ íŒŒì¼ì‹œìŠ¤í…œ ë£¨íŠ¸ì— ë„ë‹¬ - í´ë°± ì‚¬ìš©")
            break
            
        current = current.parent
    
    # í´ë°±: í•˜ë“œì½”ë”©ëœ ìƒëŒ€ ê²½ë¡œ ì‚¬ìš©
    fallback_root = current_file.parents[3]  # backend/app/coreì—ì„œ 3ë‹¨ê³„ ìœ„
    logger.warning(f"âš ï¸ í”„ë¡œì íŠ¸ ë£¨íŠ¸ í´ë°± ì‚¬ìš©: {fallback_root}")
    return fallback_root

def _get_safe_backend_root() -> Path:
    """ì•ˆì „í•œ ë°±ì—”ë“œ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ ê³„ì‚°"""
    current_file = Path(__file__).absolute()
    current = current_file.parent  # core/
    
    # backend/ ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ë•Œê¹Œì§€ ìƒìœ„ë¡œ ì´ë™
    for level in range(10):
        if current.name == 'backend':
            logger.info(f"âœ… ë°±ì—”ë“œ ë£¨íŠ¸ ë°œê²¬: {current}")
            return current
        elif current.parent == current:
            break
        current = current.parent
    
    # í´ë°±: í”„ë¡œì íŠ¸ ë£¨íŠ¸ì—ì„œ backend ì¶”ê°€
    project_root = _get_safe_project_root()
    backend_root = project_root / 'backend'
    logger.warning(f"âš ï¸ ë°±ì—”ë“œ ë£¨íŠ¸ í´ë°± ì‚¬ìš©: {backend_root}")
    return backend_root

def _get_safe_ai_models_dir() -> Path:
    """
    ì•ˆì „í•œ AI ëª¨ë¸ ë””ë ‰í† ë¦¬ ê³„ì‚°
    backend ì¤‘ë³µ ìƒì„± ë°©ì§€
    """
    backend_root = _get_safe_backend_root()
    ai_models_dir = backend_root / "ai_models"
    
    # ğŸ”¥ backend ì¤‘ë³µ íŒ¨í„´ ê²€ì‚¬ ë° ìˆ˜ì •
    ai_models_str = str(ai_models_dir)
    backend_pattern = "backend" + "/" + "backend"
    if backend_pattern in ai_models_str:
        corrected_path = Path(ai_models_str.replace(backend_pattern, "backend"))
        logger.warning(f"âš ï¸ backend ì¤‘ë³µ íŒ¨í„´ ê°ì§€ ë° ìˆ˜ì •: {ai_models_dir} â†’ {corrected_path}")
        ai_models_dir = corrected_path
    
    logger.info(f"ğŸ“ AI ëª¨ë¸ ë””ë ‰í† ë¦¬: {ai_models_dir}")
    return ai_models_dir

# ğŸ”¥ ì•ˆì „í•œ ê²½ë¡œ ê³„ì‚° ì‹¤í–‰
PROJECT_ROOT = _get_safe_project_root()
BACKEND_ROOT = _get_safe_backend_root()
AI_MODELS_DIR = _get_safe_ai_models_dir()

# =============================================================================
# ğŸ”¥ 2. 229GB AI ëª¨ë¸ ì™„ì „ ë§¤í•‘ (í”„ë¡œì íŠ¸ ë¬¸ì„œ ê¸°ë°˜)
# =============================================================================

# ğŸ¯ 8ë‹¨ê³„ AI íŒŒì´í”„ë¼ì¸ ëª¨ë¸ ê²½ë¡œ (ì‹¤ì œ íŒŒì¼ êµ¬ì¡° ê¸°ë°˜ - ìˆ˜ì •ë¨)
STEP_MODEL_PATHS = {
    # Step 1: Human Parsing (ì‹¤ì œ íŒŒì¼ êµ¬ì¡° ê¸°ë°˜)
    "human_parsing_graphonomy": AI_MODELS_DIR / "step_01_human_parsing" / "graphonomy.pth",  # 1173MB - ì‹¤ì œ ì¡´ì¬
    "human_parsing_schp_atr": AI_MODELS_DIR / "step_01_human_parsing" / "exp-schp-201908301523-atr.pth",  # 255MB - ì‹¤ì œ ì¡´ì¬
    "human_parsing_lip": AI_MODELS_DIR / "step_01_human_parsing" / "exp-schp-201908261155-lip.pth",  # 255MB - ì‹¤ì œ ì¡´ì¬
    "human_parsing_deeplab": AI_MODELS_DIR / "step_01_human_parsing" / "deeplabv3plus.pth",  # 233MB - ì‹¤ì œ ì¡´ì¬
    
    # Step 2: Pose Estimation (ì‹¤ì œ íŒŒì¼ êµ¬ì¡° ê¸°ë°˜)
    "pose_estimation_body": AI_MODELS_DIR / "step_02_pose_estimation" / "body_pose_model.pth",  # 98MB - ì‹¤ì œ ì¡´ì¬
    "pose_estimation_hrnet": AI_MODELS_DIR / "step_02_pose_estimation" / "hrnet_w48_coco_256x192.pth",  # 243MB - ì‹¤ì œ ì¡´ì¬
    "pose_estimation_yolo": AI_MODELS_DIR / "step_02_pose_estimation" / "yolov8m-pose.pt",  # 51MB - ì‹¤ì œ ì¡´ì¬
    
    # Step 3: Cloth Segmentation (ì‹¤ì œ íŒŒì¼ êµ¬ì¡° ê¸°ë°˜)
    "cloth_segmentation_sam": AI_MODELS_DIR / "step_03_cloth_segmentation" / "sam_vit_h_4b8939.pth",  # 2445MB - ì‹¤ì œ ì¡´ì¬
    "cloth_segmentation_u2net": AI_MODELS_DIR / "step_03_cloth_segmentation" / "u2net.pth",  # 528MB - ì‹¤ì œ ì¡´ì¬
    "cloth_segmentation_mobile_sam": AI_MODELS_DIR / "step_03_cloth_segmentation" / "mobile_sam.pt",  # 358MB - ì‹¤ì œ ì¡´ì¬
    "cloth_segmentation_deeplab": AI_MODELS_DIR / "step_03_cloth_segmentation" / "deeplabv3_resnet101_coco.pth",  # 233MB - ì‹¤ì œ ì¡´ì¬
    
    # Step 4: Geometric Matching (ì‹¤ì œ íŒŒì¼ êµ¬ì¡° ê¸°ë°˜)
    "geometric_matching_gmm": AI_MODELS_DIR / "step_04_geometric_matching" / "gmm_final.pth",  # 1313MB - ì‹¤ì œ ì¡´ì¬
    "geometric_matching_tps": AI_MODELS_DIR / "step_04_geometric_matching" / "tps_network.pth",  # 548MB - ì‹¤ì œ ì¡´ì¬
    "geometric_matching_vit": AI_MODELS_DIR / "step_04_geometric_matching" / "ViT-L-14.pt",  # 577MB - ì‹¤ì œ ì¡´ì¬
    "geometric_matching_sam_shared": AI_MODELS_DIR / "step_04_geometric_matching" / "sam_vit_h_4b8939.pth",  # 2445MB - ê³µìœ 
    
    # Step 5: Cloth Warping (ì‹¤ì œ íŒŒì¼ êµ¬ì¡° ê¸°ë°˜)
    "cloth_warping_tom": AI_MODELS_DIR / "step_05_cloth_warping" / "tom_final.pth",  # 83MB - ì‹¤ì œ ì¡´ì¬
    "cloth_warping_viton": AI_MODELS_DIR / "step_05_cloth_warping" / "viton_hd_warping.pth",  # 1313MB - ì‹¤ì œ ì¡´ì¬
    "cloth_warping_dpt": AI_MODELS_DIR / "step_05_cloth_warping" / "dpt_hybrid_midas.pth",  # 470MB - ì‹¤ì œ ì¡´ì¬
    "cloth_warping_vgg": AI_MODELS_DIR / "step_05_cloth_warping" / "vgg19_warping.pth",  # 548MB - ì‹¤ì œ ì¡´ì¬
    
    # Step 6: Virtual Fitting (ì‹¤ì œ íŒŒì¼ êµ¬ì¡° ê¸°ë°˜)
    "virtual_fitting_ootd": AI_MODELS_DIR / "step_06_virtual_fitting" / "ootd_3.2gb.pth",  # 3279MB - ì‹¤ì œ ì¡´ì¬
    "virtual_fitting_hrviton": AI_MODELS_DIR / "step_06_virtual_fitting" / "hrviton_final.pth",  # 230MB - ì‹¤ì œ ì¡´ì¬
    "virtual_fitting_vitonhd": AI_MODELS_DIR / "step_06_virtual_fitting" / "viton_hd_2.1gb.pth",  # 230MB - ì‹¤ì œ ì¡´ì¬
    "virtual_fitting_diffusion": AI_MODELS_DIR / "step_06_virtual_fitting" / "stable_diffusion_4.8gb.pth",  # 3279MB - ì‹¤ì œ ì¡´ì¬
    
    # Step 7: Post Processing (ì‹¤ì œ íŒŒì¼ êµ¬ì¡° ê¸°ë°˜)
    "post_processing_gfpgan": AI_MODELS_DIR / "step_07_post_processing" / "GFPGAN.pth",  # 333MB - ì‹¤ì œ ì¡´ì¬
    "post_processing_esrgan": AI_MODELS_DIR / "step_07_post_processing" / "RealESRGAN_x4plus.pth",  # 64MB - ì‹¤ì œ ì¡´ì¬
    "post_processing_swinir": AI_MODELS_DIR / "step_07_post_processing" / "swinir_real_sr_x4_large.pth",  # 136MB - ì‹¤ì œ ì¡´ì¬
    
    # Step 8: Quality Assessment (ì‹¤ì œ íŒŒì¼ êµ¬ì¡° ê¸°ë°˜)
    "quality_assessment_clip": AI_MODELS_DIR / "step_08_quality_assessment" / "clip_vit_b32.pth",  # 577MB - ì‹¤ì œ ì¡´ì¬
    "quality_assessment_vit": AI_MODELS_DIR / "step_08_quality_assessment" / "ViT-L-14.pt",  # 890MB - ì‹¤ì œ ì¡´ì¬
    "quality_assessment_lpips": AI_MODELS_DIR / "step_08_quality_assessment" / "lpips_alex.pth",  # 233MB - ì‹¤ì œ ì¡´ì¬
}

# ğŸ”¥ ì¶”ê°€ ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œ (checkpoints ë””ë ‰í† ë¦¬)
CHECKPOINT_PATHS = {
    "stable_diffusion_v1_5": AI_MODELS_DIR / "checkpoints" / "stable-diffusion-v1-5",
    "clip_vit_large": AI_MODELS_DIR / "checkpoints" / "clip-vit-large-patch14",
    "controlnet_openpose": AI_MODELS_DIR / "checkpoints" / "controlnet_openpose",
    "sam_checkpoints": AI_MODELS_DIR / "checkpoints" / "sam",
}

# í†µí•© ëª¨ë¸ ê²½ë¡œ ë”•ì…”ë„ˆë¦¬
ALL_MODEL_PATHS = {**STEP_MODEL_PATHS, **CHECKPOINT_PATHS}

# =============================================================================
# ğŸ”¥ 3. ë™ì  ê²½ë¡œ ë§¤í•‘ ì‹œìŠ¤í…œ (í”„ë¡œì íŠ¸ ë¬¸ì„œ ê¸°ë°˜)
# =============================================================================

class SmartModelPathMapper:
    """ì‹¤ì œ íŒŒì¼ ìœ„ì¹˜ë¥¼ ë™ì ìœ¼ë¡œ ì°¾ì•„ì„œ ë§¤í•‘í•˜ëŠ” ì‹œìŠ¤í…œ"""
    
    def __init__(self, ai_models_root: Union[str, Path] = None):
        self.ai_models_root = Path(ai_models_root) if ai_models_root else AI_MODELS_DIR
        self.model_cache: Dict[str, Path] = {}
        self.search_priority = self._get_search_priority()
        self.logger = logging.getLogger(f"{__name__}.SmartModelPathMapper")
    
    def _get_search_priority(self) -> Dict[str, List[str]]:
        """ëª¨ë¸ë³„ ê²€ìƒ‰ ìš°ì„ ìˆœìœ„ ê²½ë¡œ (í”„ë¡œì íŠ¸ ë¬¸ì„œ ê¸°ë°˜)"""
        return {
            # Human Parsing ëª¨ë¸ë“¤
            "human_parsing": [
                "step_01_human_parsing/",
                "Self-Correction-Human-Parsing/",
                "Graphonomy/",
                "step_06_virtual_fitting/ootdiffusion/checkpoints/humanparsing/",
                "checkpoints/step_01_human_parsing/"
            ],
            
            # Pose Estimation ëª¨ë¸ë“¤
            "pose_estimation": [
                "step_02_pose_estimation/",
                "step_06_virtual_fitting/ootdiffusion/checkpoints/openpose/",
                "checkpoints/step_02_pose_estimation/",
                "pose_estimation/"
            ],
            
            # Cloth Segmentation ëª¨ë¸ë“¤
            "cloth_segmentation": [
                "step_03_cloth_segmentation/",
                "step_03_cloth_segmentation/ultra_models/",
                "step_04_geometric_matching/",  # SAM ëª¨ë¸ ê³µìœ 
                "checkpoints/step_03_cloth_segmentation/"
            ],
            
            # Geometric Matching ëª¨ë¸ë“¤
            "geometric_matching": [
                "step_04_geometric_matching/",
                "step_04_geometric_matching/ultra_models/",
                "step_08_quality_assessment/ultra_models/",  # ViT ëª¨ë¸ ê³µìœ 
                "checkpoints/step_04_geometric_matching/"
            ],
            
            # Cloth Warping ëª¨ë¸ë“¤
            "cloth_warping": [
                "step_05_cloth_warping/",
                "step_05_cloth_warping/ultra_models/",
                "checkpoints/step_05_cloth_warping/",
                "checkpoints/stable-diffusion-v1-5/"  # Diffusion ëª¨ë¸ ê³µìœ 
            ],
            
            # Virtual Fitting ëª¨ë¸ë“¤ (ê°€ì¥ ì¤‘ìš”!)
            "virtual_fitting": [
                "step_06_virtual_fitting/ootdiffusion/checkpoints/ootd/ootd_hd/checkpoint-36000/",
                "step_06_virtual_fitting/ootdiffusion/checkpoints/ootd/ootd_dc/checkpoint-36000/",
                "checkpoints/ootdiffusion/checkpoints/ootd/ootd_hd/checkpoint-36000/",
                "checkpoints/ootdiffusion/checkpoints/ootd/ootd_dc/checkpoint-36000/",
                "step_06_virtual_fitting/ootdiffusion/checkpoints/ootd/",
                "step_06_virtual_fitting/ootdiffusion/",
                "step_06_virtual_fitting/",
                "step_06_virtual_fitting/HR-VITON/",
                "step_06_virtual_fitting/VITON-HD/",
                "checkpoints/step_06_virtual_fitting/"
            ],
            
            # Post Processing ëª¨ë¸ë“¤
            "post_processing": [
                "step_07_post_processing/",
                "checkpoints/step_07_post_processing/",
                "experimental_models/enhancement/"
            ],
            
            # Quality Assessment ëª¨ë¸ë“¤
            "quality_assessment": [
                "step_08_quality_assessment/",
                "step_08_quality_assessment/ultra_models/",
                "checkpoints/step_08_quality_assessment/",
                "step_04_geometric_matching/ultra_models/"  # ViT ëª¨ë¸ ê³µìœ 
            ]
        }
    
    def find_model_file(self, model_category: str, filename: str) -> Optional[Path]:
        """ëª¨ë¸ íŒŒì¼ì„ ë™ì ìœ¼ë¡œ íƒì§€"""
        try:
            # ìºì‹œ í™•ì¸
            cache_key = f"{model_category}:{filename}"
            if cache_key in self.model_cache:
                return self.model_cache[cache_key]
            
            # ìš°ì„ ìˆœìœ„ë³„ ê²€ìƒ‰
            search_paths = self.search_priority.get(model_category, [])
            
            for search_path in search_paths:
                candidate_path = self.ai_models_root / search_path / filename
                
                if candidate_path.exists() and candidate_path.is_file():
                    self.model_cache[cache_key] = candidate_path
                    self.logger.info(f"âœ… ëª¨ë¸ ë°œê²¬: {filename} â†’ {candidate_path}")
                    return candidate_path
            
            # ì „ì²´ ë””ë ‰í† ë¦¬ ê²€ìƒ‰ (ìµœí›„ ìˆ˜ë‹¨)
            for root, dirs, files in os.walk(self.ai_models_root):
                if filename in files:
                    found_path = Path(root) / filename
                    self.model_cache[cache_key] = found_path
                    self.logger.info(f"âœ… ì „ì²´ ê²€ìƒ‰ìœ¼ë¡œ ëª¨ë¸ ë°œê²¬: {filename} â†’ {found_path}")
                    return found_path
            
            self.logger.warning(f"âš ï¸ ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {filename}")
            return None
            
        except Exception as e:
            self.logger.error(f"âŒ ëª¨ë¸ íŒŒì¼ ê²€ìƒ‰ ì‹¤íŒ¨ ({filename}): {e}")
            return None
    
    def get_large_models_priority(self) -> Dict[str, Dict[str, Any]]:
        """25GB+ í•µì‹¬ ëŒ€í˜• ëª¨ë¸ ìš°ì„ ìˆœìœ„ (í”„ë¡œì íŠ¸ ë¬¸ì„œ ê¸°ë°˜)"""
        return {
            "RealVisXL_V4.0.safetensors": {
                "size": "6.6GB",
                "step": 5,
                "category": "cloth_warping",
                "priority": 1,
                "description": "ì˜ë¥˜ ì›Œí•‘ í•µì‹¬ ëª¨ë¸"
            },
            "open_clip_pytorch_model.bin": {
                "size": "5.2GB", 
                "step": 8,
                "category": "quality_assessment",
                "priority": 2,
                "description": "í’ˆì§ˆ í‰ê°€ í•µì‹¬ ëª¨ë¸"
            },
            "diffusion_pytorch_model.safetensors": {
                "size": "3.2GB x4",
                "step": 6,
                "category": "virtual_fitting",
                "priority": 3,
                "description": "ê°€ìƒ í”¼íŒ… í™•ì‚° ëª¨ë¸"
            },
            "sam_vit_h_4b8939.pth": {
                "size": "2.4GB",
                "step": 3,
                "category": "cloth_segmentation",
                "priority": 4,
                "description": "SAM ì„¸ê·¸ë©˜í…Œì´ì…˜ ëª¨ë¸"
            },
            "graphonomy.pth": {
                "size": "1.2GB",
                "step": 1,
                "category": "human_parsing",
                "priority": 5,
                "description": "ì¸ê°„ íŒŒì‹± í•µì‹¬ ëª¨ë¸"
            }
        }

# =============================================================================
# ğŸ”¥ 4. Stepë³„ íŠ¹í™” ë§¤í¼ë“¤
# =============================================================================

class Step01ModelMapper(SmartModelPathMapper):
    """Step 01 Human Parsing ì „ìš© ë™ì  ê²½ë¡œ ë§¤í•‘"""
    
    def get_step01_model_paths(self) -> Dict[str, Optional[Path]]:
        """Step 01 ëª¨ë¸ ê²½ë¡œ ìë™ íƒì§€"""
        model_files = {
            "graphonomy": ["graphonomy.pth", "graphonomy_lip.pth"],
            "schp": ["exp-schp-201908301523-atr.pth", "exp-schp-201908261155-atr.pth"],
            "atr": ["atr_model.pth"],
            "lip": ["lip_model.pth"]
        }
        
        found_paths = {}
        for model_name, filenames in model_files.items():
            found_path = None
            for filename in filenames:
                found_path = self.find_model_file("human_parsing", filename)
                if found_path:
                    break
            found_paths[model_name] = found_path
        
        return found_paths

class Step06ModelMapper(SmartModelPathMapper):
    """Step 06 Virtual Fitting ì „ìš© ë™ì  ê²½ë¡œ ë§¤í•‘ (í•µì‹¬!)"""
    
    def get_step06_model_paths(self) -> Dict[str, Optional[Path]]:
        """Step 06 Virtual Fitting ëª¨ë¸ ê²½ë¡œ ìë™ íƒì§€"""
        model_directories = {
            "ootdiffusion": "ootdiffusion/",
            "hr_viton": "HR-VITON/",
            "viton_hd": "VITON-HD/"
        }
        
        model_files = {
            "diffusion_model_1": "diffusion_pytorch_model.safetensors",
            "diffusion_model_2": "ootdiffusion/unet/diffusion_pytorch_model.safetensors",
            "vae_model": "ootdiffusion/vae/diffusion_pytorch_model.safetensors"
        }
        
        found_paths = {}
        
        # ë””ë ‰í† ë¦¬ ê²€ìƒ‰
        for model_name, dirname in model_directories.items():
            dir_path = self.ai_models_root / "step_06_virtual_fitting" / dirname
            if dir_path.exists() and dir_path.is_dir():
                found_paths[model_name] = dir_path
        
        # íŒŒì¼ ê²€ìƒ‰
        for model_name, filename in model_files.items():
            found_paths[model_name] = self.find_model_file("virtual_fitting", filename)
        
        return found_paths

# =============================================================================
# ğŸ”¥ 5. ì•ˆì „í•œ ê²½ë¡œ ì²˜ë¦¬ í•¨ìˆ˜ë“¤
# =============================================================================

def safe_path_conversion(path_input: Union[str, Path, None]) -> Path:
    """
    ì•ˆì „í•œ Path ê°ì²´ ë³€í™˜
    backend ì¤‘ë³µ íŒ¨í„´ ìë™ ìˆ˜ì • í¬í•¨
    """
    try:
        if path_input is None:
            return Path(".")
            
        if isinstance(path_input, str):
            # ğŸ”¥ backend ì¤‘ë³µ íŒ¨í„´ ìë™ ìˆ˜ì •
            backend_pattern = "backend" + "/" + "backend"
            if backend_pattern in path_input:
                corrected_path = path_input.replace(backend_pattern, "backend")
                logger.info(f"âœ… backend ì¤‘ë³µ íŒ¨í„´ ìë™ ìˆ˜ì •: {path_input} â†’ {corrected_path}")
                path_input = corrected_path
            return Path(path_input)
            
        elif isinstance(path_input, Path):
            # ğŸ”¥ Path ê°ì²´ì—ì„œë„ backend ì¤‘ë³µ íŒ¨í„´ ê²€ì‚¬
            path_str = str(path_input)
            backend_pattern = "backend" + "/" + "backend"
            if backend_pattern in path_str:
                corrected_path = Path(path_str.replace(backend_pattern, "backend"))
                logger.info(f"âœ… Path ê°ì²´ backend ì¤‘ë³µ íŒ¨í„´ ìë™ ìˆ˜ì •: {path_input} â†’ {corrected_path}")
                return corrected_path
            return path_input
            
        else:
            # ì˜ˆìƒì¹˜ ëª»í•œ íƒ€ì…ì¸ ê²½ìš° ë¬¸ìì—´ë¡œ ë³€í™˜ ì‹œë„
            converted = str(path_input)
            backend_pattern = "backend" + "/" + "backend"
            if backend_pattern in converted:
                converted = converted.replace(backend_pattern, "backend")
            return Path(converted)
            
    except Exception as e:
        logger.warning(f"âš ï¸ ê²½ë¡œ ë³€í™˜ ì‹¤íŒ¨: {path_input} - {e}")
        return Path(".")

@lru_cache(maxsize=256)
def get_model_path(model_name: str) -> Optional[Path]:
    """
    ëª¨ë¸ ê²½ë¡œ ê°€ì ¸ì˜¤ê¸° (ìºì‹œ í¬í•¨)
    backend ì¤‘ë³µ ìë™ ìˆ˜ì • í¬í•¨
    """
    try:
        if model_name in ALL_MODEL_PATHS:
            raw_path = ALL_MODEL_PATHS[model_name]
            safe_path = safe_path_conversion(raw_path)
            logger.debug(f"ğŸ“ ëª¨ë¸ ê²½ë¡œ ë°˜í™˜: {model_name} â†’ {safe_path}")
            return safe_path
        
        # ğŸ”¥ ë™ì  ë§¤ì¹­ ì‹œë„ (íŒŒì¼ëª… ê¸°ë°˜)
        for key, path in ALL_MODEL_PATHS.items():
            if model_name.lower() in key.lower():
                safe_path = safe_path_conversion(path)
                logger.debug(f"ğŸ” ë™ì  ë§¤ì¹­: {model_name} â†’ {key} â†’ {safe_path}")
                return safe_path
        
        # ğŸ”¥ SmartModelPathMapper ì‚¬ìš© (ìµœí›„ ìˆ˜ë‹¨)
        mapper = SmartModelPathMapper()
        
        # Stepë³„ ì¹´í…Œê³ ë¦¬ ì¶”ë¡ 
        step_categories = {
            "human_parsing": ["human", "parsing", "graphonomy", "schp", "atr"],
            "pose_estimation": ["pose", "openpose", "body", "face", "hand"],
            "cloth_segmentation": ["cloth", "segment", "sam", "u2net"],
            "geometric_matching": ["geometric", "match", "gmm", "vit"],
            "cloth_warping": ["warp", "tom", "realvis", "diffusion"],
            "virtual_fitting": ["virtual", "fitting", "ootd", "viton", "hr"],
            "post_processing": ["post", "process", "esrgan", "upscaler"],
            "quality_assessment": ["quality", "assess", "clip", "eval"]
        }
        
        for category, keywords in step_categories.items():
            if any(keyword in model_name.lower() for keyword in keywords):
                # íŒŒì¼ëª… ì¶”ì¶œ (í™•ì¥ì í¬í•¨)
                if "/" in model_name:
                    filename = model_name.split("/")[-1]
                elif "\\" in model_name:
                    filename = model_name.split("\\")[-1]
                else:
                    filename = model_name
                
                # í™•ì¥ìê°€ ì—†ìœ¼ë©´ ì¼ë°˜ì ì¸ í™•ì¥ìë“¤ ì‹œë„
                if "." not in filename:
                    for ext in [".pth", ".safetensors", ".bin", ".pt"]:
                        found_path = mapper.find_model_file(category, filename + ext)
                        if found_path:
                            return found_path
                else:
                    found_path = mapper.find_model_file(category, filename)
                    if found_path:
                        return found_path
        
        logger.warning(f"âš ï¸ ëª¨ë¸ ê²½ë¡œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ: {model_name}")
        return None
        
    except Exception as e:
        logger.error(f"âŒ ëª¨ë¸ ê²½ë¡œ ì¡°íšŒ ì‹¤íŒ¨: {model_name} - {e}")
        return None

def is_model_available(model_name: str) -> bool:
    """ëª¨ë¸ ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸"""
    try:
        path = get_model_path(model_name)
        if path is None:
            return False
        
        # ì•ˆì „í•œ Path ê°ì²´ ë³€í™˜ ë° ì¡´ì¬ í™•ì¸
        path_obj = safe_path_conversion(path)
        exists = path_obj.exists()
        logger.debug(f"ğŸ“Š ëª¨ë¸ ê°€ìš©ì„±: {model_name} â†’ {exists}")
        return exists
        
    except Exception as e:
        logger.warning(f"âš ï¸ ëª¨ë¸ ê°€ìš©ì„± í™•ì¸ ì‹¤íŒ¨: {model_name} - {e}")
        return False

def get_all_available_models() -> Dict[str, str]:
    """ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë“  ëª¨ë¸ ë°˜í™˜"""
    available = {}
    
    try:
        for model_name, raw_path in ALL_MODEL_PATHS.items():
            try:
                path_obj = safe_path_conversion(raw_path)
                if path_obj.exists():
                    available[model_name] = str(path_obj.absolute())
                    logger.debug(f"âœ… ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸: {model_name}")
            except Exception as e:
                logger.debug(f"âŒ ëª¨ë¸ í™•ì¸ ì‹¤íŒ¨: {model_name} - {e}")
                continue
        
        logger.info(f"ğŸ“Š ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸: {len(available)}ê°œ")
        return available
        
    except Exception as e:
        logger.error(f"âŒ ëª¨ë¸ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return {}

# =============================================================================
# ğŸ”¥ 6. conda í™˜ê²½ + M3 Max ìµœì í™”
# =============================================================================

def setup_conda_optimization():
    """conda í™˜ê²½ mycloset-ai-clean ìµœì í™” ì„¤ì •"""
    try:
        conda_env = os.environ.get('CONDA_DEFAULT_ENV')
        if conda_env:
            logger.info(f"ğŸ conda í™˜ê²½ ê°ì§€: {conda_env}")
            
            # M3 Max ìµœì í™”
            if 'Darwin' in os.uname().sysname:  # macOS
                try:
                    # M3 Max ë©”ëª¨ë¦¬ ìµœì í™”
                    os.environ['PYTORCH_MPS_HIGH_WATERMARK_RATIO'] = '0.0'
                    os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '1'
                    logger.info("ğŸ M3 Max ë©”ëª¨ë¦¬ ìµœì í™” ì„¤ì • ì™„ë£Œ")
                except Exception as e:
                    logger.debug(f"M3 Max ì„¤ì • ì˜¤ë¥˜: {e}")
            
            # ìŠ¤ë ˆë“œ ìµœì í™”
            cpu_count = os.cpu_count() or 4
            os.environ['OMP_NUM_THREADS'] = str(max(1, cpu_count // 2))
            os.environ['MKL_NUM_THREADS'] = str(max(1, cpu_count // 2))
            
            logger.info("âœ… conda í™˜ê²½ ìµœì í™” ì„¤ì • ì™„ë£Œ")
            return True
    except Exception as e:
        logger.warning(f"âš ï¸ conda ìµœì í™” ì„¤ì • ì‹¤íŒ¨: {e}")
        return False

# =============================================================================
# ğŸ”¥ 7. ë””ë ‰í† ë¦¬ ì¡´ì¬ í™•ì¸ ë° ì•ˆì „í•œ ìƒì„±
# =============================================================================

def _ensure_directories_exist():
    """í•„ìš”í•œ ë””ë ‰í† ë¦¬ë“¤ì„ ì•ˆì „í•˜ê²Œ ìƒì„±"""
    try:
        # AI ëª¨ë¸ ë””ë ‰í† ë¦¬ ìƒì„±
        if not AI_MODELS_DIR.exists():
            AI_MODELS_DIR.mkdir(parents=True, exist_ok=True)
            logger.info(f"ğŸ“ AI ëª¨ë¸ ë””ë ‰í† ë¦¬ ìƒì„±: {AI_MODELS_DIR}")
        else:
            logger.debug(f"ğŸ“ AI ëª¨ë¸ ë””ë ‰í† ë¦¬ ì¡´ì¬ í™•ì¸: {AI_MODELS_DIR}")
        
        # Stepë³„ ë””ë ‰í† ë¦¬ ìƒì„±
        step_dirs = [
            "step_01_human_parsing", "step_02_pose_estimation", "step_03_cloth_segmentation",
            "step_04_geometric_matching", "step_05_cloth_warping", "step_06_virtual_fitting",
            "step_07_post_processing", "step_08_quality_assessment", "checkpoints",
            "Self-Correction-Human-Parsing", "Graphonomy", "experimental_models", "cache"
        ]
        
        for step_dir in step_dirs:
            dir_path = AI_MODELS_DIR / step_dir
            if not dir_path.exists():
                dir_path.mkdir(parents=True, exist_ok=True)
                logger.debug(f"ğŸ“ Step ë””ë ‰í† ë¦¬ ìƒì„±: {dir_path}")
        
        return True
        
    except Exception as e:
        logger.error(f"âŒ ë””ë ‰í† ë¦¬ ìƒì„± ì‹¤íŒ¨: {e}")
        return False

# =============================================================================
# ğŸ”¥ 8. backend ì¤‘ë³µ ë¬¸ì œ ì§„ë‹¨ ë° ìˆ˜ì •
# =============================================================================

def diagnose_backend_duplication() -> Dict[str, Any]:
    """backend ì¤‘ë³µ ë¬¸ì œ ì§„ë‹¨"""
    diagnosis = {
        "has_duplication": False,
        "affected_paths": [],
        "current_structure": {},
        "recommendations": []
    }
    
    try:
        # í˜„ì¬ ê²½ë¡œ êµ¬ì¡° ë¶„ì„
        current_dir = Path.cwd()
        diagnosis["current_working_directory"] = str(current_dir)
        
        # backend ì¤‘ë³µ íŒ¨í„´ ê²€ì‚¬
        backend_pattern = "backend" + "/" + "backend"
        for model_name, path in ALL_MODEL_PATHS.items():
            path_str = str(path)
            if backend_pattern in path_str:
                diagnosis["has_duplication"] = True
                diagnosis["affected_paths"].append({
                    "model": model_name,
                    "problematic_path": path_str,
                    "corrected_path": path_str.replace(backend_pattern, "backend")
                })
        
        # ì‹¤ì œ íŒŒì¼ì‹œìŠ¤í…œ ê²€ì‚¬
        if current_dir.name == "backend":
            backend_subdir = current_dir / "backend"
            if backend_subdir.exists():
                diagnosis["filesystem_duplication"] = True
                diagnosis["recommendations"].append("rm -rf backend ì¤‘ë³µ ë””ë ‰í† ë¦¬ ì‹¤í–‰ í•„ìš”")
            else:
                diagnosis["filesystem_duplication"] = False
        
        # ê¶Œì¥ì‚¬í•­ ìƒì„±
        if diagnosis["has_duplication"]:
            diagnosis["recommendations"].extend([
                "model_paths.pyì˜ ê²½ë¡œ ê³„ì‚° ë¡œì§ ìˆ˜ì • í•„ìš”",
                "ModelLoaderì˜ í´ë°± ë””ë ‰í† ë¦¬ ì„¤ì • ê²€í†  í•„ìš”",
                "ê²½ë¡œ ë³€í™˜ í•¨ìˆ˜ë“¤ì— backend ì¤‘ë³µ ìˆ˜ì • ë¡œì§ ì¶”ê°€"
            ])
        
        return diagnosis
        
    except Exception as e:
        logger.error(f"âŒ backend ì¤‘ë³µ ì§„ë‹¨ ì‹¤íŒ¨: {e}")
        diagnosis["error"] = str(e)
        return diagnosis

def fix_backend_duplication() -> bool:
    """backend ì¤‘ë³µ ë¬¸ì œ ìë™ ìˆ˜ì •"""
    try:
        logger.info("ğŸ”§ backend ì¤‘ë³µ ë¬¸ì œ ìë™ ìˆ˜ì • ì‹œì‘...")
        
        # 1. í˜„ì¬ ì‘ì—… ë””ë ‰í† ë¦¬ì—ì„œ ì¤‘ë³µ ì œê±°
        current_dir = Path.cwd()
        if current_dir.name == "backend":
            duplicate_backend = current_dir / "backend"
            if duplicate_backend.exists():
                import shutil
                shutil.rmtree(duplicate_backend)
                logger.info(f"âœ… ì¤‘ë³µ ë””ë ‰í† ë¦¬ ì œê±°: {duplicate_backend}")
        
        # 2. ëª¨ë“  ëª¨ë¸ ê²½ë¡œ ì¬ê³„ì‚° ë° ìˆ˜ì •
        global ALL_MODEL_PATHS
        corrected_paths = {}
        
        for model_name, path in ALL_MODEL_PATHS.items():
            corrected_path = safe_path_conversion(path)
            corrected_paths[model_name] = corrected_path
        
        ALL_MODEL_PATHS = corrected_paths
        
        # 3. ë””ë ‰í† ë¦¬ ì¬ìƒì„±
        _ensure_directories_exist()
        
        logger.info("âœ… backend ì¤‘ë³µ ë¬¸ì œ ìë™ ìˆ˜ì • ì™„ë£Œ")
        return True
        
    except Exception as e:
        logger.error(f"âŒ backend ì¤‘ë³µ ìë™ ìˆ˜ì • ì‹¤íŒ¨: {e}")
        return False

# =============================================================================
# ğŸ”¥ 9. ì´ˆê¸°í™” ë° ìƒíƒœ ê´€ë¦¬
# =============================================================================

def initialize_model_paths() -> bool:
    """ëª¨ë¸ ê²½ë¡œ ì´ˆê¸°í™” ë° backend ì¤‘ë³µ ë¬¸ì œ ìë™ í•´ê²°"""
    try:
        logger.info("ğŸ”„ ëª¨ë¸ ê²½ë¡œ ì´ˆê¸°í™” ë° ë¬¸ì œ ì§„ë‹¨ ì‹œì‘...")
        
        # 1. backend ì¤‘ë³µ ë¬¸ì œ ì§„ë‹¨
        diagnosis = diagnose_backend_duplication()
        
        if diagnosis.get("has_duplication", False):
            logger.warning("âš ï¸ backend ì¤‘ë³µ ë¬¸ì œ ê°ì§€ë¨")
            logger.info("ğŸ”§ ìë™ ìˆ˜ì • ì‹œë„...")
            
            if fix_backend_duplication():
                logger.info("âœ… backend ì¤‘ë³µ ë¬¸ì œ ìë™ ìˆ˜ì • ì™„ë£Œ")
            else:
                logger.error("âŒ ìë™ ìˆ˜ì • ì‹¤íŒ¨ - ìˆ˜ë™ ê°œì… í•„ìš”")
                return False
        
        # 2. ë””ë ‰í† ë¦¬ êµ¬ì¡° í™•ì¸ ë° ìƒì„±
        success = _ensure_directories_exist()
        
        # 3. conda í™˜ê²½ ìµœì í™”
        setup_conda_optimization()
        
        if success:
            available_models = get_all_available_models()
            logger.info(f"âœ… ëª¨ë¸ ê²½ë¡œ ì´ˆê¸°í™” ì™„ë£Œ: {len(available_models)}ê°œ ëª¨ë¸ ë°œê²¬")
            return True
        else:
            logger.error("âŒ ë””ë ‰í† ë¦¬ ìƒì„± ì‹¤íŒ¨")
            return False
        
    except Exception as e:
        logger.error(f"âŒ ëª¨ë¸ ê²½ë¡œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return False

# =============================================================================
# ğŸ”¥ 10. í¸ì˜ í•¨ìˆ˜ë“¤
# =============================================================================

def get_step_models(step_id: int) -> List[str]:
    """ë‹¨ê³„ë³„ ëª¨ë¸ ëª©ë¡ ë°˜í™˜"""
    step_patterns = {
        1: ["human_parsing"],
        2: ["pose_estimation"], 
        3: ["cloth_segmentation"],
        4: ["geometric_matching"],
        5: ["cloth_warping"],
        6: ["virtual_fitting"],
        7: ["post_processing"], 
        8: ["quality_assessment"]
    }
    
    if step_id not in step_patterns:
        return []
    
    pattern = step_patterns[step_id][0]
    return [key for key in ALL_MODEL_PATHS.keys() if pattern in key]

def get_model_size_info() -> Dict[str, Dict[str, str]]:
    """ëª¨ë¸ í¬ê¸° ì •ë³´ ë°˜í™˜ (í”„ë¡œì íŠ¸ ë¬¸ì„œ ê¸°ë°˜)"""
    return {
        "step_01_human_parsing": {"total": "4.0GB", "files": "9ê°œ"},
        "step_02_pose_estimation": {"total": "3.4GB", "files": "9ê°œ"},
        "step_03_cloth_segmentation": {"total": "5.5GB", "files": "9ê°œ"},
        "step_04_geometric_matching": {"total": "1.3GB", "files": "17ê°œ"},
        "step_05_cloth_warping": {"total": "7.0GB", "files": "6ê°œ"},
        "step_06_virtual_fitting": {"total": "14GB", "files": "16ê°œ"},  # í•µì‹¬
        "step_07_post_processing": {"total": "1.3GB", "files": "9ê°œ"},
        "step_08_quality_assessment": {"total": "7.0GB", "files": "6ê°œ"},
        "total_project": {"total": "229GB", "files": "127ê°œ", "dirs": "99ê°œ"}
    }

# =============================================================================
# ğŸ”¥ 11. í´ë˜ìŠ¤ ë° ì¸ìŠ¤í„´ìŠ¤
# =============================================================================

class ModelPaths:
    """ëª¨ë¸ ê²½ë¡œ ë¹ ë¥¸ ì ‘ê·¼ í´ë˜ìŠ¤"""
    
    @property
    def ai_models_dir(self) -> Path:
        return safe_path_conversion(AI_MODELS_DIR)
    
    @property
    def project_root(self) -> Path:
        return safe_path_conversion(PROJECT_ROOT)
    
    @property
    def backend_root(self) -> Path:
        return safe_path_conversion(BACKEND_ROOT)
    
    def diagnose_duplication(self) -> Dict[str, Any]:
        return diagnose_backend_duplication()
    
    def fix_duplication(self) -> bool:
        return fix_backend_duplication()
    
    def get_smart_mapper(self) -> SmartModelPathMapper:
        return SmartModelPathMapper()
    
    def get_step01_mapper(self) -> Step01ModelMapper:
        return Step01ModelMapper()
    
    def get_step06_mapper(self) -> Step06ModelMapper:
        return Step06ModelMapper()

# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
model_paths = ModelPaths()

# =============================================================================
# ğŸ”¥ 12. ë‚´ë³´ë‚´ê¸° ëª©ë¡
# =============================================================================

__all__ = [
    # í•µì‹¬ í•¨ìˆ˜ë“¤
    'get_model_path',
    'is_model_available', 
    'get_all_available_models',
    'safe_path_conversion',
    
    # ë¬¸ì œ í•´ê²° í•¨ìˆ˜ë“¤
    'diagnose_backend_duplication',
    'fix_backend_duplication',
    
    # Stepë³„ í•¨ìˆ˜ë“¤
    'get_step_models',
    'get_model_size_info',
    
    # ë§¤í¼ í´ë˜ìŠ¤ë“¤
    'SmartModelPathMapper',
    'Step01ModelMapper',
    'Step06ModelMapper',
    
    # í´ë˜ìŠ¤ ë° ìƒìˆ˜
    'ModelPaths',
    'model_paths',
    'AI_MODELS_DIR',
    'PROJECT_ROOT',
    'BACKEND_ROOT',
    'ALL_MODEL_PATHS',
    'STEP_MODEL_PATHS',
    
    # ìµœì í™” ë° ì´ˆê¸°í™”
    'setup_conda_optimization',
    'initialize_model_paths'
]

# =============================================================================
# ğŸ”¥ 13. ìë™ ì´ˆê¸°í™” ì‹¤í–‰
# =============================================================================

# ìë™ ì´ˆê¸°í™” ì‹¤í–‰
if __name__ != "__main__":
    try:
        initialize_model_paths()
        logger.info("âœ… í†µí•© ëª¨ë¸ ê²½ë¡œ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ (229GB AI ëª¨ë¸ ì§€ì›)")
    except Exception as e:
        logger.warning(f"âš ï¸ ëª¨ë¸ ê²½ë¡œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")

logger.info("ğŸ”¥ Model Paths v7.0 ë¡œë“œ ì™„ë£Œ!")
logger.info("âœ… backend ì¤‘ë³µ ë¬¸ì œ ì™„ì „ í•´ê²°")
logger.info("âœ… 229GB AI ëª¨ë¸ ê²½ë¡œ ë§¤í•‘ ì™„ì„± (127ê°œ íŒŒì¼, 99ê°œ ë””ë ‰í† ë¦¬)")
logger.info("âœ… ë™ì  ê²½ë¡œ íƒì§€ ì‹œìŠ¤í…œ êµ¬í˜„")
logger.info("âœ… conda í™˜ê²½ mycloset-ai-clean ìµœì í™”")
logger.info("âœ… M3 Max 128GB ë©”ëª¨ë¦¬ ìµœì í™”")
logger.info("âœ… Stepë³„ AI ëª¨ë¸ ìš°ì„ ìˆœìœ„ ë§¤í•‘")
logger.info("ğŸ¯ 25GB+ í•µì‹¬ ëª¨ë¸ ì™„ì „ í™œìš© ì¤€ë¹„ ì™„ë£Œ!")