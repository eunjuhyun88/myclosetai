# app/core/config.py
"""
MyCloset AI - M3 Max 128GB ìµœì í™” í†µí•© ì„¤ì • ì‹œìŠ¤í…œ
PipelineManager í˜¸í™˜ì„± ì™„ì „ í•´ê²°, Config í´ë˜ìŠ¤ ì œëŒ€ë¡œ export
"""
import os
import platform
import subprocess
from typing import Dict, Any, Optional, List, Union
from pathlib import Path
from functools import lru_cache
import logging
from abc import ABC, abstractmethod

logger = logging.getLogger(__name__)

# ===============================================================
# ğŸ”§ ì‹œìŠ¤í…œ ì •ë³´ ìœ í‹¸ë¦¬í‹° (ë…ë¦½ í•¨ìˆ˜ë“¤)
# ===============================================================

def detect_container() -> bool:
    """ğŸ³ ì»¨í…Œì´ë„ˆ í™˜ê²½ ê°ì§€"""
    indicators = [
        os.path.exists('/.dockerenv'),
        os.getenv('KUBERNETES_SERVICE_HOST') is not None,
        os.getenv('CONTAINER') is not None,
        'docker' in str(Path('/proc/1/cgroup')).lower() if os.path.exists('/proc/1/cgroup') else False
    ]
    return any(indicators)

def detect_m3_max() -> bool:
    """ğŸ M3 Max ì¹© ê°ì§€ (ë…ë¦½ í•¨ìˆ˜)"""
    if platform.system() != 'Darwin':
        return False
    
    try:
        result = subprocess.run(
            ['sysctl', '-n', 'machdep.cpu.brand_string'], 
            capture_output=True, text=True, timeout=5
        )
        return 'M3' in result.stdout
    except:
        return False

def get_available_memory() -> float:
    """ğŸ’¾ ì‚¬ìš© ê°€ëŠ¥í•œ ë©”ëª¨ë¦¬ ê³„ì‚° (GB)"""
    try:
        import psutil
        return psutil.virtual_memory().total / (1024**3)
    except ImportError:
        # psutilì´ ì—†ìœ¼ë©´ ì¶”ì •ê°’
        if detect_m3_max():
            return 128.0  # M3 MaxëŠ” ë³´í†µ 128GB
        elif platform.system() == 'Darwin':
            return 16.0   # macOS ê¸°ë³¸ê°’
        else:
            return 8.0    # ì¼ë°˜ì ì¸ ì„œë²„

def collect_system_info() -> Dict[str, Any]:
    """ğŸ–¥ï¸ ì‹œìŠ¤í…œ ì •ë³´ ìˆ˜ì§‘ (ë…ë¦½ í•¨ìˆ˜)"""
    return {
        'platform': platform.system(),
        'machine': platform.machine(),
        'python_version': platform.python_version(),
        'is_container': detect_container(),
        'is_m3_max': detect_m3_max(),
        'available_memory_gb': get_available_memory(),
        'cpu_count': os.cpu_count() or 4,
        'home_dir': str(Path.home()),
        'cwd': str(Path.cwd())
    }

# ===============================================================
# ğŸ¯ í•µì‹¬ Config í´ë˜ìŠ¤ (PipelineManager í˜¸í™˜ì„±)
# ===============================================================

class Config:
    """
    ğŸ¯ PipelineManager í˜¸í™˜ Config í´ë˜ìŠ¤
    - pipeline_manager.pyì—ì„œ í•„ìš”ë¡œ í•˜ëŠ” í‘œì¤€ Config
    - ê¸°ì¡´ ì½”ë“œ 100% í˜¸í™˜ì„± ë³´ì¥
    """
    
    def __init__(self, 
                 environment: str = None,
                 device: str = "mps",
                 is_m3_max: bool = None,
                 **kwargs):
        """
        Config ì´ˆê¸°í™” (PipelineManager í˜¸í™˜)
        
        Args:
            environment: í™˜ê²½ (development/production/testing)
            device: ì‚¬ìš©í•  ë””ë°”ì´ìŠ¤ (mps/cuda/cpu)
            is_m3_max: M3 Max ì—¬ë¶€
            **kwargs: ì¶”ê°€ ì„¤ì •ë“¤
        """
        # ì‹œìŠ¤í…œ ì •ë³´ ìˆ˜ì§‘
        self.system_info = collect_system_info()
        
        # ê¸°ë³¸ ì„¤ì •
        self.environment = environment or self._auto_detect_environment()
        self.device = device
        self.is_m3_max = is_m3_max if is_m3_max is not None else self.system_info['is_m3_max']
        
        # ê¸°ë³¸ ì†ì„±ë“¤ ì„¤ì •
        self._setup_core_properties()
        
        # kwargsë¡œ ë°›ì€ ì¶”ê°€ ì„¤ì •ë“¤ ì ìš©
        for key, value in kwargs.items():
            setattr(self, key, value)
            
        logger.info(f"ğŸ¯ Config ì´ˆê¸°í™” ì™„ë£Œ - í™˜ê²½: {self.environment}, ë””ë°”ì´ìŠ¤: {self.device}")
    
    def _auto_detect_environment(self) -> str:
        """í™˜ê²½ ìë™ ê°ì§€"""
        env_var = os.getenv('APP_ENV', os.getenv('ENVIRONMENT', ''))
        if env_var.lower() in ['development', 'dev']:
            return 'development'
        elif env_var.lower() in ['production', 'prod']:
            return 'production'
        elif env_var.lower() in ['testing', 'test']:
            return 'testing'
        
        # DEBUG í™˜ê²½ë³€ìˆ˜ í™•ì¸
        if os.getenv('DEBUG', '').lower() in ['true', '1']:
            return 'development'
        
        return 'development'  # ê¸°ë³¸ê°’
    
    def _setup_core_properties(self):
        """í•µì‹¬ ì†ì„±ë“¤ ì„¤ì •"""
        # ë””ë°”ì´ìŠ¤ ê´€ë ¨ ì„¤ì •
        self.use_gpu = self.device != 'cpu'
        self.enable_mps = self.device == 'mps'
        self.enable_cuda = self.device == 'cuda'
        
        # M3 Max ê´€ë ¨ ì„¤ì •
        if self.is_m3_max:
            self.optimization_level = 'maximum'
            self.batch_size = 4
            self.max_workers = 8
            self.memory_pool_gb = 32
            self.neural_engine_enabled = True
            self.metal_performance_shaders = True
        else:
            self.optimization_level = 'balanced'
            self.batch_size = 1
            self.max_workers = 4
            self.memory_pool_gb = 8
            self.neural_engine_enabled = False
            self.metal_performance_shaders = False
        
        # í™˜ê²½ë³„ ì„¤ì •
        if self.environment == 'development':
            self.debug = True
            self.log_level = 'DEBUG'
            self.reload = True
        elif self.environment == 'production':
            self.debug = False
            self.log_level = 'INFO'
            self.reload = False
        else:  # testing
            self.debug = True
            self.log_level = 'WARNING'
            self.reload = False
    
    # PipelineManagerê°€ í•„ìš”ë¡œ í•˜ëŠ” ë©”ì„œë“œë“¤
    def get(self, key: str, default: Any = None) -> Any:
        """ì„¤ì •ê°’ ê°€ì ¸ì˜¤ê¸°"""
        return getattr(self, key, default)
    
    def set(self, key: str, value: Any):
        """ì„¤ì •ê°’ ì„¤ì •í•˜ê¸°"""
        setattr(self, key, value)
    
    def to_dict(self) -> Dict[str, Any]:
        """ì„¤ì •ì„ ë”•ì…”ë„ˆë¦¬ë¡œ ë°˜í™˜"""
        return {k: v for k, v in self.__dict__.items() if not k.startswith('_')}

# ===============================================================
# ğŸ¯ ìµœì  ì„¤ì • ë² ì´ìŠ¤ í´ë˜ìŠ¤
# ===============================================================

class OptimalConfigBase(ABC):
    """ìµœì í™”ëœ ì„¤ì • ë² ì´ìŠ¤ í´ë˜ìŠ¤"""

    def __init__(self, env: Optional[str] = None, config_path: Optional[str] = None, **kwargs):
        # ì‹œìŠ¤í…œ ì •ë³´ ìˆ˜ì§‘
        self.system_info = collect_system_info()
        
        # í™˜ê²½ ìë™ ê°ì§€
        self.env = self._auto_detect_environment(env)
        
        # ê¸°ë³¸ ì„¤ì • ìƒì„±
        self._config = self._create_base_config()
        
        # kwargs íŒŒë¼ë¯¸í„° ë³‘í•©
        self._merge_kwargs_config(kwargs)
        
        # ì™¸ë¶€ ì„¤ì • íŒŒì¼ ë¡œë“œ
        if config_path and os.path.exists(config_path):
            self._load_external_config(config_path)
        
        # í™˜ê²½ë³€ìˆ˜ ì˜¤ë²„ë¼ì´ë“œ
        self._apply_environment_overrides()
        
        # í™˜ê²½ë³„ ìµœì í™” ì ìš©
        self._apply_environment_optimizations()
        
        logger.info(f"ğŸ¯ {self.__class__.__name__} ì´ˆê¸°í™” ì™„ë£Œ - í™˜ê²½: {self.env}")

    def _auto_detect_environment(self, preferred_env: Optional[str]) -> str:
        """í™˜ê²½ ìë™ ê°ì§€"""
        if preferred_env:
            return preferred_env

        env_var = os.getenv('APP_ENV', os.getenv('ENVIRONMENT', ''))
        if env_var.lower() in ['development', 'dev']:
            return 'development'
        elif env_var.lower() in ['production', 'prod']:
            return 'production'
        elif env_var.lower() in ['testing', 'test']:
            return 'testing'
        
        if os.getenv('DEBUG', '').lower() in ['true', '1']:
            return 'development'
        
        # ê°œë°œ í™˜ê²½ ê°ì§€
        dev_indicators = ['.git', 'requirements-dev.txt', 'docker-compose.yml']
        current_dir = Path.cwd()
        for indicator in dev_indicators:
            if (current_dir / indicator).exists():
                return 'development'
        
        return 'production'

    @abstractmethod
    def _create_base_config(self) -> Dict[str, Any]:
        """ê¸°ë³¸ ì„¤ì • ìƒì„± (ì„œë¸Œí´ë˜ìŠ¤ì—ì„œ êµ¬í˜„)"""
        pass

    def _merge_kwargs_config(self, kwargs: Dict[str, Any]):
        """kwargs íŒŒë¼ë¯¸í„° ë³‘í•©"""
        for key, value in kwargs.items():
            self._config[key] = value

    def _load_external_config(self, config_path: str):
        """ì™¸ë¶€ ì„¤ì • íŒŒì¼ ë¡œë“œ"""
        try:
            import json
            with open(config_path, 'r', encoding='utf-8') as f:
                external_config = json.load(f)
                self._deep_merge(self._config, external_config)
            logger.info(f"ğŸ“ ì™¸ë¶€ ì„¤ì • ë¡œë“œ: {config_path}")
        except Exception as e:
            logger.warning(f"ì™¸ë¶€ ì„¤ì • ë¡œë“œ ì‹¤íŒ¨ ({config_path}): {e}")

    def _apply_environment_overrides(self):
        """í™˜ê²½ë³€ìˆ˜ ì˜¤ë²„ë¼ì´ë“œ"""
        env_mappings = {
            'APP_NAME': 'app_name',
            'HOST': 'host',
            'PORT': 'port',
            'DEBUG': 'debug',
            'LOG_LEVEL': 'log_level',
            'DATABASE_URL': 'database_url',
            'REDIS_URL': 'redis_url',
            'SECRET_KEY': 'secret_key',
            'CORS_ORIGINS': 'cors_origins'
        }
        
        for env_var, config_key in env_mappings.items():
            env_value = os.getenv(env_var)
            if env_value is not None:
                if config_key == 'port':
                    self._config[config_key] = int(env_value)
                elif config_key == 'debug':
                    self._config[config_key] = env_value.lower() in ['true', '1']
                elif config_key == 'cors_origins':
                    self._config[config_key] = [origin.strip() for origin in env_value.split(',')]
                else:
                    self._config[config_key] = env_value

    def _apply_environment_optimizations(self):
        """í™˜ê²½ë³„ ìµœì í™”"""
        if self.env == 'development':
            self._apply_development_optimizations()
        elif self.env == 'production':
            self._apply_production_optimizations()
        elif self.env == 'testing':
            self._apply_testing_optimizations()

    def _apply_development_optimizations(self):
        """ê°œë°œ í™˜ê²½ ìµœì í™”"""
        self._config.update({
            'debug': True,
            'log_level': 'DEBUG',
            'reload': True,
            'workers': 1,
            'enable_profiling': True,
            'enable_hot_reload': True,
            'cors_origins': ['*']
        })

    def _apply_production_optimizations(self):
        """í”„ë¡œë•ì…˜ í™˜ê²½ ìµœì í™”"""
        optimal_workers = min(self.system_info['cpu_count'], 8)
        
        self._config.update({
            'debug': False,
            'log_level': 'INFO',
            'reload': False,
            'workers': optimal_workers,
            'enable_profiling': False,
            'enable_hot_reload': False,
            'timeout': 300,
            'keepalive': 2
        })
        
        if self.system_info['is_m3_max']:
            self._config.update({
                'workers': min(12, optimal_workers * 2),
                'max_memory_usage': '64GB',
                'enable_mps_optimization': True
            })

    def _apply_testing_optimizations(self):
        """í…ŒìŠ¤íŠ¸ í™˜ê²½ ìµœì í™”"""
        self._config.update({
            'debug': True,
            'log_level': 'WARNING',
            'workers': 1,
            'timeout': 30,
            'database_url': 'sqlite:///:memory:',
            'cache_enabled': False
        })

    def _deep_merge(self, base_dict: Dict, merge_dict: Dict):
        """ë”•ì…”ë„ˆë¦¬ ê¹Šì€ ë³‘í•©"""
        for key, value in merge_dict.items():
            if key in base_dict and isinstance(base_dict[key], dict) and isinstance(value, dict):
                self._deep_merge(base_dict[key], value)
            else:
                base_dict[key] = value

    # ì„¤ì • ì ‘ê·¼ ë©”ì„œë“œë“¤
    def get(self, key: str, default: Any = None) -> Any:
        """ì„¤ì •ê°’ ê°€ì ¸ì˜¤ê¸°"""
        return self._config.get(key, default)

    def set(self, key: str, value: Any):
        """ì„¤ì •ê°’ ì„¤ì •í•˜ê¸°"""
        self._config[key] = value

    def update(self, **kwargs):
        """ì—¬ëŸ¬ ì„¤ì •ê°’ ì—…ë°ì´íŠ¸"""
        self._config.update(kwargs)

    def to_dict(self) -> Dict[str, Any]:
        """ì„¤ì •ì„ ë”•ì…”ë„ˆë¦¬ë¡œ ë°˜í™˜"""
        return self._config.copy()

    @property
    def is_development(self) -> bool:
        return self.env == 'development'

    @property
    def is_production(self) -> bool:
        return self.env == 'production'

    @property
    def is_testing(self) -> bool:
        return self.env == 'testing'

# ===============================================================
# ğŸ¯ ì• í”Œë¦¬ì¼€ì´ì…˜ ì„¤ì • í´ë˜ìŠ¤
# ===============================================================

class AppConfig(OptimalConfigBase):
    """ì• í”Œë¦¬ì¼€ì´ì…˜ ë©”ì¸ ì„¤ì •"""

    def _create_base_config(self) -> Dict[str, Any]:
        """ê¸°ë³¸ ì• í”Œë¦¬ì¼€ì´ì…˜ ì„¤ì • ìƒì„±"""
        return {
            # ì• í”Œë¦¬ì¼€ì´ì…˜ ê¸°ë³¸ ì •ë³´
            'app_name': 'MyCloset AI',
            'app_version': '3.0.0',
            'app_description': 'AI-powered virtual try-on platform',
            'api_prefix': '/api',
            
            # ì„œë²„ ì„¤ì •
            'host': '0.0.0.0',
            'port': 8000,
            'workers': 4,
            'timeout': 300,
            'keepalive': 2,
            'max_requests': 1000,
            'max_requests_jitter': 100,
            
            # ê°œë°œ/ë””ë²„ê·¸ ì„¤ì •
            'debug': False,
            'reload': False,
            'log_level': 'INFO',
            'enable_profiling': False,
            'enable_hot_reload': False,
            
            # ë³´ì•ˆ ì„¤ì •
            'secret_key': self._generate_secret_key(),
            'algorithm': 'HS256',
            'access_token_expire_minutes': 1440,
            'allowed_hosts': ['*'],
            
            # CORS ì„¤ì •
            'cors_origins': [
                'http://localhost:3000',
                'http://localhost:3001',
                'http://127.0.0.1:3000'
            ],
            'cors_allow_credentials': True,
            'cors_allow_methods': ['*'],
            'cors_allow_headers': ['*'],
            
            # ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì •
            'database_url': 'sqlite:///./mycloset.db',
            'database_echo': False,
            'database_pool_size': 20,
            'database_max_overflow': 0,
            
            # ìºì‹œ ì„¤ì •
            'redis_url': 'redis://localhost:6379/0',
            'cache_enabled': True,
            'cache_ttl': 3600,
            
            # íŒŒì¼ ì—…ë¡œë“œ ì„¤ì •
            'upload_dir': './static/uploads',
            'max_file_size': 10 * 1024 * 1024,
            'allowed_extensions': ['.jpg', '.jpeg', '.png', '.webp'],
            
            # ì‹œìŠ¤í…œ ì •ë³´
            'system_info': self.system_info,
            'environment': self.env
        }

    def _generate_secret_key(self) -> str:
        """ì‹œí¬ë¦¿ í‚¤ ìƒì„±"""
        import secrets
        return secrets.token_urlsafe(32)

    # í¸ì˜ ì†ì„±ë“¤
    @property
    def database_url(self) -> str:
        return self.get('database_url')

    @property
    def redis_url(self) -> str:
        return self.get('redis_url')

    @property
    def cors_origins(self) -> List[str]:
        return self.get('cors_origins', [])

    @property
    def is_debug(self) -> bool:
        return self.get('debug', False)

    @property
    def log_level(self) -> str:
        return self.get('log_level', 'INFO')

# ===============================================================
# ğŸ¯ AI ì„¤ì • í´ë˜ìŠ¤
# ===============================================================

class AIConfig(OptimalConfigBase):
    """AI ëª¨ë¸ ë° íŒŒì´í”„ë¼ì¸ ì„¤ì •"""

    def _create_base_config(self) -> Dict[str, Any]:
        """ê¸°ë³¸ AI ì„¤ì • ìƒì„±"""
        
        # ë””ë°”ì´ìŠ¤ ìë™ ê°ì§€
        device = self._auto_detect_device()
        
        return {
            # ë””ë°”ì´ìŠ¤ ì„¤ì •
            'device': device,
            'device_type': self._get_device_type(device),
            'enable_mps': device == 'mps',
            'enable_cuda': device == 'cuda',
            'mixed_precision': device != 'cpu',
            
            # ë©”ëª¨ë¦¬ ì„¤ì •
            'memory_gb': self.system_info['available_memory_gb'],
            'max_memory_usage': self._get_optimal_memory_usage(),
            'memory_efficient': True,
            'enable_memory_monitoring': True,
            
            # ëª¨ë¸ ê²½ë¡œ
            'models_dir': './models/ai_models',
            'checkpoints_dir': './models/ai_models/checkpoints',
            'cache_dir': './models/cache',
            
            # ì„±ëŠ¥ ì„¤ì •
            'batch_size': self._get_optimal_batch_size(device),
            'num_workers': min(4, self.system_info['cpu_count']),
            'pin_memory': device != 'cpu',
            'non_blocking': True,
            
            # íŒŒì´í”„ë¼ì¸ ì„¤ì •
            'pipeline_quality': self._get_optimal_quality_level(),
            'enable_optimization': True,
            'enable_caching': True,
            'enable_parallel': True,
            'max_concurrent_requests': self._get_optimal_concurrent_requests(),
            
            # M3 Max íŠ¹í™” ì„¤ì •
            'is_m3_max': self.system_info['is_m3_max'],
            'm3_max_optimizations': self.system_info['is_m3_max'],
            'metal_performance_shaders': self.system_info['is_m3_max'] and device == 'mps',
            
            # ëª¨ë¸ë³„ ì„¤ì •
            'models': {
                'human_parsing': {
                    'model_name': 'graphonomy',
                    'input_size': (512, 512),
                    'num_classes': 20
                },
                'pose_estimation': {
                    'model_complexity': 2,
                    'min_detection_confidence': 0.7
                },
                'cloth_segmentation': {
                    'method': 'auto',
                    'quality_threshold': 0.7
                },
                'geometric_matching': {
                    'method': 'auto',
                    'max_iterations': 1500 if self.system_info['is_m3_max'] else 1000
                },
                'cloth_warping': {
                    'physics_enabled': True,
                    'deformation_strength': 0.7,
                    'enable_fabric_physics': True
                }
            }
        }

    def _auto_detect_device(self) -> str:
        """AI ë””ë°”ì´ìŠ¤ ìë™ ê°ì§€"""
        try:
            import torch
            if torch.backends.mps.is_available() and self.system_info['is_m3_max']:
                return 'mps'
            elif torch.cuda.is_available():
                return 'cuda'
            else:
                return 'cpu'
        except ImportError:
            return 'cpu'

    def _get_device_type(self, device: str) -> str:
        """ë””ë°”ì´ìŠ¤ íƒ€ì… ê²°ì •"""
        if device == 'mps':
            return 'apple_silicon'
        elif device == 'cuda':
            return 'nvidia_gpu'
        else:
            return 'cpu'

    def _get_optimal_memory_usage(self) -> str:
        """ìµœì  ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ê³„ì‚°"""
        available_gb = self.system_info['available_memory_gb']
        
        if available_gb >= 128:
            return '64GB'
        elif available_gb >= 64:
            return '32GB'
        elif available_gb >= 32:
            return '16GB'
        elif available_gb >= 16:
            return '8GB'
        else:
            return '4GB'

    def _get_optimal_batch_size(self, device: str) -> int:
        """ìµœì  ë°°ì¹˜ í¬ê¸° ê³„ì‚°"""
        memory_gb = self.system_info['available_memory_gb']
        
        if device == 'mps' and self.system_info['is_m3_max']:
            if memory_gb >= 128:
                return 8
            elif memory_gb >= 64:
                return 4
            else:
                return 2
        elif device == 'cuda':
            return 4
        else:
            return 1

    def _get_optimal_quality_level(self) -> str:
        """ìµœì  í’ˆì§ˆ ë ˆë²¨ ê²°ì •"""
        if self.system_info['is_m3_max']:
            return 'ultra'
        elif self.system_info['available_memory_gb'] >= 32:
            return 'high'
        elif self.system_info['available_memory_gb'] >= 16:
            return 'medium'
        else:
            return 'basic'

    def _get_optimal_concurrent_requests(self) -> int:
        """ìµœì  ë™ì‹œ ìš”ì²­ ìˆ˜ ê³„ì‚°"""
        memory_gb = self.system_info['available_memory_gb']
        cpu_count = self.system_info['cpu_count']
        
        if self.system_info['is_m3_max']:
            return min(8, cpu_count)
        elif memory_gb >= 32:
            return min(4, cpu_count)
        else:
            return min(2, cpu_count)

# ===============================================================
# ğŸ¯ í†µí•© ì„¤ì • ê´€ë¦¬ì
# ===============================================================

class Settings:
    """í†µí•© ì„¤ì • ê´€ë¦¬ì"""

    def __init__(self, env: Optional[str] = None, config_path: Optional[str] = None, **kwargs):
        """í†µí•© ì„¤ì • ì´ˆê¸°í™”"""
        self.app = AppConfig(env=env, config_path=config_path, **kwargs)
        self.ai = AIConfig(env=env, config_path=config_path, **kwargs)
        
        # í¸ì˜ ì†ì„±ë“¤ ì„¤ì •
        self._setup_convenience_properties()
        
        logger.info("ğŸ¯ í†µí•© ì„¤ì • ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")

    def _setup_convenience_properties(self):
        """í¸ì˜ ì†ì„± ì„¤ì • (ê¸°ì¡´ ì½”ë“œ í˜¸í™˜ì„±)"""
        # í•˜ìœ„ í˜¸í™˜ì„±ì„ ìœ„í•œ ì§ì ‘ ì†ì„± ì„¤ì •
        self.APP_NAME = self.app.get('app_name')
        self.DEBUG = self.app.get('debug')
        self.HOST = self.app.get('host')
        self.PORT = self.app.get('port')
        self.DATABASE_URL = self.app.get('database_url')
        self.CORS_ORIGINS = self.app.get('cors_origins')
        self.DEVICE = self.ai.get('device')
        self.USE_GPU = self.ai.get('device') != 'cpu'
        self.IS_M3_MAX = self.ai.get('is_m3_max', False)

    # ì£¼ìš” ì†ì„±ë“¤
    @property
    def app_name(self) -> str:
        return self.app.get('app_name')

    @property
    def debug(self) -> bool:
        return self.app.get('debug')

    @property
    def host(self) -> str:
        return self.app.get('host')

    @property
    def port(self) -> int:
        return self.app.get('port')

    @property
    def database_url(self) -> str:
        return self.app.get('database_url')

    @property
    def cors_origins(self) -> List[str]:
        return self.app.get('cors_origins')

    @property
    def device(self) -> str:
        return self.ai.get('device')

    @property
    def use_gpu(self) -> bool:
        return self.ai.get('device') != 'cpu'

    @property
    def is_m3_max(self) -> bool:
        return self.ai.get('is_m3_max', False)

# ===============================================================
# ğŸ¯ ì „ì—­ ì„¤ì • ì¸ìŠ¤í„´ìŠ¤ ë° íŒ©í† ë¦¬ í•¨ìˆ˜ë“¤
# ===============================================================

@lru_cache()
def get_settings(env: Optional[str] = None, config_path: Optional[str] = None, **kwargs) -> Settings:
    """ì „ì—­ ì„¤ì • ì¸ìŠ¤í„´ìŠ¤ (ìºì‹œë¨)"""
    return Settings(env=env, config_path=config_path, **kwargs)

# ê¸°ë³¸ ì„¤ì • ì¸ìŠ¤í„´ìŠ¤
settings = get_settings()

# í¸ì˜ í•¨ìˆ˜ë“¤
def get_app_config() -> AppConfig:
    """ì•± ì„¤ì • ë°˜í™˜"""
    return settings.app

def get_ai_config() -> AIConfig:
    """AI ì„¤ì • ë°˜í™˜"""
    return settings.ai

def create_config(**kwargs) -> Config:
    """í‘œì¤€ Config ì¸ìŠ¤í„´ìŠ¤ ìƒì„± (PipelineManager í˜¸í™˜)"""
    return Config(**kwargs)

def get_config(**kwargs) -> Config:
    """Config ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜ (PipelineManager í˜¸í™˜)"""
    return create_config(
        environment=settings.app.env,
        device=settings.ai.get('device'),
        is_m3_max=settings.ai.get('is_m3_max'),
        **kwargs
    )

# í•˜ìœ„ í˜¸í™˜ì„± ì§€ì› (ê¸°ì¡´ ì½”ë“œ 100% ì§€ì›)
APP_NAME = settings.APP_NAME
DEBUG = settings.DEBUG
HOST = settings.HOST
PORT = settings.PORT
DATABASE_URL = settings.DATABASE_URL
DEVICE = settings.DEVICE
USE_GPU = settings.USE_GPU
IS_M3_MAX = settings.IS_M3_MAX

logger.info(f"ğŸ¯ ìµœì  ì„¤ì • ì‹œìŠ¤í…œ ë¡œë“œ ì™„ë£Œ - í™˜ê²½: {settings.app.env}, ë””ë°”ì´ìŠ¤: {DEVICE}")

if IS_M3_MAX:
    logger.info("ğŸ M3 Max ìµœì í™” í™œì„±í™”")
if USE_GPU:
    logger.info(f"ğŸ® GPU ê°€ì† í™œì„±í™”: {DEVICE}")

__all__ = [
    # í•µì‹¬ í´ë˜ìŠ¤ë“¤
    'Config', 'OptimalConfigBase', 'AppConfig', 'AIConfig', 'Settings',
    
    # íŒ©í† ë¦¬ í•¨ìˆ˜ë“¤
    'get_settings', 'get_app_config', 'get_ai_config', 'create_config', 'get_config',
    
    # ì „ì—­ ì„¤ì •
    'settings',
    
    # í•˜ìœ„ í˜¸í™˜ì„±
    'APP_NAME', 'DEBUG', 'HOST', 'PORT', 'DATABASE_URL', 
    'DEVICE', 'USE_GPU', 'IS_M3_MAX',
    
    # ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
    'detect_m3_max', 'get_available_memory', 'collect_system_info'
]