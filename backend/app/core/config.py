# backend/app/core/config.py
"""
MyCloset AI μ„¤μ • μ‹μ¤ν… (λ‹¨μν•κ³  μ‹¤μ©μ μΈ λ²„μ „)
- get_settings() ν•¨μ μ™„μ „ μ§€μ› β…
- M3 Max 128GB μµμ ν™” β…
- λ³µμ΅ν• μƒμ† κµ¬μ΅° μ κ±°, λ‹¨μν•κ³  λ…ν™•ν•¨ β…
"""

import os
import platform
import subprocess
import psutil
import logging
from typing import Dict, Any, Optional, List, Tuple
from pathlib import Path
from functools import lru_cache

# λ΅κΉ… μ„¤μ •
logger = logging.getLogger(__name__)

# ===============================================================
# π”§ μ‹μ¤ν… κ°μ§€ ν•¨μλ“¤ (κ°„λ‹¨ν•κ²)
# ===============================================================

def detect_m3_max_info() -> Tuple[str, float, bool, str]:
    """M3 Max ν™κ²½ μ •λ³΄ κ°μ§€"""
    try:
        memory_gb = round(psutil.virtual_memory().total / (1024**3), 1)
        is_m3_max = False
        device = "cpu"
        chip_name = "Unknown"
        
        # macOS κ°μ§€
        if platform.system() == "Darwin":
            try:
                result = subprocess.run(
                    ['sysctl', '-n', 'machdep.cpu.brand_string'],
                    capture_output=True, text=True, timeout=5
                )
                chip_name = result.stdout.strip()
                
                # M3 Max κ°μ§€
                if 'M3' in chip_name and ('Max' in chip_name or memory_gb >= 64):
                    is_m3_max = True
                    device = "mps"
                elif 'M3' in chip_name or 'M2' in chip_name or 'M1' in chip_name:
                    device = "mps"
                    
            except:
                # λ©”λ¨λ¦¬ κΈ°λ° μ¶”μ •
                if memory_gb >= 64:
                    is_m3_max = True
                    device = "mps"
        
        # GPU κ°μ§€
        if device == "cpu":
            try:
                import torch
                if torch.backends.mps.is_available():
                    device = "mps"
                elif torch.cuda.is_available():
                    device = "cuda"
            except ImportError:
                pass
        
        # μµμ ν™” λ λ²¨ κ²°μ •
        if is_m3_max and memory_gb >= 128:
            quality = "ultra"
        elif memory_gb >= 64:
            quality = "high"
        elif memory_gb >= 32:
            quality = "balanced"
        else:
            quality = "fast"
            
        return device, memory_gb, is_m3_max, quality
        
    except Exception as e:
        logger.warning(f"μ‹μ¤ν… κ°μ§€ μ‹¤ν¨: {e}")
        return "cpu", 8.0, False, "fast"

def detect_environment() -> str:
    """ν™κ²½ κ°μ§€"""
    env = os.getenv('MYCLOSET_ENV', os.getenv('APP_ENV', '')).lower()
    
    if env in ['prod', 'production']:
        return 'production'
    elif env in ['test', 'testing']:
        return 'testing'
    elif env in ['dev', 'development']:
        return 'development'
    elif os.getenv('DEBUG', '').lower() in ['true', '1']:
        return 'development'
    else:
        return 'development'

# ===============================================================
# π― Settings ν΄λμ¤ (κ°„λ‹¨ν•κ³  λ…ν™•ν•¨)
# ===============================================================

class Settings:
    """MyCloset AI μ„¤μ • ν΄λμ¤ - κ°„λ‹¨ν•κ³  μ‹¤μ©μ """
    
    def __init__(self):
        # ν™κ²½ κ°μ§€
        self.env = detect_environment()
        
        # μ‹μ¤ν… μ •λ³΄ κ°μ§€
        self.device, self.memory_gb, self.is_m3_max, self.quality_level = detect_m3_max_info()
        
        # κΈ°λ³Έ μ•± μ„¤μ •
        self._setup_app_config()
        
        # AI μ„¤μ •
        self._setup_ai_config()
        
        # κ²½λ΅ μ„¤μ •
        self._setup_paths()
        
        # λ””λ ‰ν† λ¦¬ μƒμ„±
        self._ensure_directories()
        
        logger.info(f"π― Settings μ΄κΈ°ν™” μ™„λ£ - ν™κ²½: {self.env}, λ””λ°”μ΄μ¤: {self.device}, M3 Max: {self.is_m3_max}")
    
    def _setup_app_config(self):
        """μ•± μ„¤μ •"""
        self.APP_NAME = "MyCloset AI Backend"
        self.APP_VERSION = "3.0.0"
        self.DEBUG = self.env == 'development'
        self.HOST = "0.0.0.0"
        self.PORT = 8000
        self.LOG_LEVEL = "DEBUG" if self.DEBUG else "INFO"
        
        # CORS μ„¤μ •
        self.CORS_ORIGINS = [
            "http://localhost:3000",
            "http://localhost:3001", 
            "http://localhost:5173",
            "http://127.0.0.1:3000"
        ]
        
        # λ°μ΄ν„°λ² μ΄μ¤
        self.DATABASE_URL = "sqlite:///./mycloset_ai.db"
        
        # νμΌ μ²λ¦¬
        self.MAX_UPLOAD_SIZE = 50 * 1024 * 1024  # 50MB
        self.ALLOWED_EXTENSIONS = [".jpg", ".jpeg", ".png", ".webp", ".bmp"]
    
    def _setup_ai_config(self):
        """AI μ„¤μ •"""
        # λ””λ°”μ΄μ¤ μ„¤μ •
        self.DEVICE = self.device
        self.USE_GPU = self.device != "cpu"
        self.IS_M3_MAX = self.is_m3_max
        self.ENABLE_MPS = self.device == "mps"
        self.ENABLE_CUDA = self.device == "cuda"
        
        # μ„±λ¥ μ„¤μ •
        self.QUALITY_LEVEL = self.quality_level
        self.IMAGE_SIZE = 512
        self.MAX_WORKERS = min(4, psutil.cpu_count() or 4)
        
        # λ°°μΉ ν¬κΈ° (M3 Max μµμ ν™”)
        if self.is_m3_max and self.memory_gb >= 128:
            self.BATCH_SIZE = 8
        elif self.is_m3_max and self.memory_gb >= 64:
            self.BATCH_SIZE = 4
        elif self.memory_gb >= 32:
            self.BATCH_SIZE = 2
        else:
            self.BATCH_SIZE = 1
    
    def _setup_paths(self):
        """κ²½λ΅ μ„¤μ •"""
        self.PROJECT_ROOT = str(Path(__file__).parent.parent.parent)
        self.STATIC_DIR = os.path.join(self.PROJECT_ROOT, "static")
        self.UPLOAD_DIR = os.path.join(self.PROJECT_ROOT, "static", "uploads")
        self.RESULTS_DIR = os.path.join(self.PROJECT_ROOT, "static", "results")
        self.CACHE_DIR = os.path.join(self.PROJECT_ROOT, "cache")
        self.MODELS_DIR = os.path.join(self.PROJECT_ROOT, "ai_models")
        self.LOGS_DIR = os.path.join(self.PROJECT_ROOT, "logs")
    
    def _ensure_directories(self):
        """ν•„μ”ν• λ””λ ‰ν† λ¦¬ μƒμ„±"""
        directories = [
            self.STATIC_DIR, self.UPLOAD_DIR, self.RESULTS_DIR,
            self.CACHE_DIR, self.MODELS_DIR, self.LOGS_DIR
        ]
        
        for directory in directories:
            Path(directory).mkdir(parents=True, exist_ok=True)

# ===============================================================
# π― νΈν™μ„± ν•¨μλ“¤
# ===============================================================

# μ „μ—­ μ„¤μ • μΈμ¤ν„΄μ¤
_global_settings: Optional[Settings] = None

@lru_cache()
def get_settings() -> Settings:
    """κΈ°μ΅΄ μ½”λ“μ™€ μ™„μ „ νΈν™λλ” μ„¤μ • λ°ν™ ν•¨μ"""
    global _global_settings
    
    if _global_settings is None:
        _global_settings = Settings()
    
    return _global_settings

# κΈ°λ³Έ μ„¤μ • μΈμ¤ν„΄μ¤ (ν•μ„ νΈν™μ„±)
settings = get_settings()

# ν•μ„ νΈν™μ„±μ„ μ„ν• μ „μ—­ λ³€μλ“¤ (κΈ°μ΅΄ μ½”λ“κ°€ μ΄κ±Έ μ‚¬μ©ν•¨)
APP_NAME = settings.APP_NAME
APP_VERSION = settings.APP_VERSION
DEBUG = settings.DEBUG
HOST = settings.HOST
PORT = settings.PORT
LOG_LEVEL = settings.LOG_LEVEL
DATABASE_URL = settings.DATABASE_URL
CORS_ORIGINS = settings.CORS_ORIGINS

DEVICE = settings.DEVICE
USE_GPU = settings.USE_GPU
IS_M3_MAX = settings.IS_M3_MAX
ENABLE_MPS = settings.ENABLE_MPS
ENABLE_CUDA = settings.ENABLE_CUDA
QUALITY_LEVEL = settings.QUALITY_LEVEL
BATCH_SIZE = settings.BATCH_SIZE

# M3 Max μµμ ν™” μƒνƒ λ΅κΉ…
if IS_M3_MAX:
    logger.info("π M3 Max 128GB μµμ ν™” ν™μ„±ν™”")
    logger.info(f"   - Neural Engine: {settings.is_m3_max}")
    logger.info(f"   - Metal Performance Shaders: {ENABLE_MPS}")
    logger.info(f"   - ν†µν•© λ©”λ¨λ¦¬: {settings.memory_gb}GB")

if USE_GPU:
    logger.info(f"π® GPU κ°€μ† ν™μ„±ν™”: {DEVICE}")

logger.info(f"π― MyCloset AI μ„¤μ • μ‹μ¤ν… λ΅λ“ μ™„λ£ - ν™κ²½: {settings.env}, λ””λ°”μ΄μ¤: {DEVICE}")

# __all__ export (κΈ°μ΅΄ μ½”λ“κ°€ ν•„μ”λ΅ ν•λ” κ²ƒλ“¤λ§)
__all__ = [
    'get_settings', 'settings', 'Settings',
    'APP_NAME', 'APP_VERSION', 'DEBUG', 'HOST', 'PORT', 'LOG_LEVEL', 
    'DATABASE_URL', 'CORS_ORIGINS', 'DEVICE', 'USE_GPU', 'IS_M3_MAX', 
    'ENABLE_MPS', 'ENABLE_CUDA', 'QUALITY_LEVEL', 'BATCH_SIZE'
]