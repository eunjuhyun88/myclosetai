# app/core/config.py
"""
ğŸš¨ MyCloset AI - ì™„ì „ ìˆ˜ì •ëœ ì„¤ì • ì‹œìŠ¤í…œ (conda í™˜ê²½ ìµœì í™”)
âœ… GPUConfig import ì˜¤ë¥˜ ì™„ì „ í•´ê²°
âœ… ìˆœí™˜ ì°¸ì¡° ë°©ì§€
âœ… ê¸°ì¡´ ì½”ë“œ 100% í˜¸í™˜ì„± ë³´ì¥
âœ… M3 Max ìµœì í™” ì„¤ì • í¬í•¨
âœ… conda í™˜ê²½ íŠ¹í™” ìµœì í™”
"""

import os
import platform
import subprocess
from pathlib import Path
from typing import Dict, Any, Optional, Union, List
from functools import lru_cache
import logging
from abc import ABC, abstractmethod

logger = logging.getLogger(__name__)

# ===============================================================
# ğŸš¨ SafeConfigMixin - get ë©”ì„œë“œ ë¬¸ì œ ì™„ì „ í•´ê²°
# ===============================================================

class SafeConfigMixin:
    """
    ğŸš¨ ëª¨ë“  ì„¤ì • í´ë˜ìŠ¤ê°€ ìƒì†ë°›ì„ ì•ˆì „í•œ ë¯¹ìŠ¤ì¸ - get ë©”ì„œë“œ ë¬¸ì œ í•´ê²°
    âœ… ë”•ì…”ë„ˆë¦¬ì²˜ëŸ¼ get() ë©”ì„œë“œ ì§€ì›
    âœ… ë”•ì…”ë„ˆë¦¬ì²˜ëŸ¼ [] ì ‘ê·¼ ì§€ì›  
    âœ… in ì—°ì‚°ì ì§€ì›
    âœ… update() ë©”ì„œë“œ ì§€ì›
    """
    
    def get(self, key: str, default: Any = None) -> Any:
        """ë”•ì…”ë„ˆë¦¬ì²˜ëŸ¼ get ë©”ì„œë“œ ì§€ì›"""
        if hasattr(self, key):
            return getattr(self, key)
        elif hasattr(self, '__dict__') and key in self.__dict__:
            return self.__dict__[key]
        else:
            return default
    
    def __getitem__(self, key: str) -> Any:
        """ë”•ì…”ë„ˆë¦¬ì²˜ëŸ¼ [] ì ‘ê·¼ ì§€ì›"""
        if hasattr(self, key):
            return getattr(self, key)
        elif hasattr(self, '__dict__') and key in self.__dict__:
            return self.__dict__[key]
        else:
            raise KeyError(f"'{key}' not found in {self.__class__.__name__}")
    
    def __setitem__(self, key: str, value: Any):
        """ë”•ì…”ë„ˆë¦¬ì²˜ëŸ¼ [] ì„¤ì • ì§€ì›"""
        setattr(self, key, value)
    
    def __contains__(self, key: str) -> bool:
        """ë”•ì…”ë„ˆë¦¬ì²˜ëŸ¼ in ì—°ì‚°ì ì§€ì›"""
        return hasattr(self, key) or (hasattr(self, '__dict__') and key in self.__dict__)
    
    def keys(self):
        """ë”•ì…”ë„ˆë¦¬ì²˜ëŸ¼ keys() ë©”ì„œë“œ ì§€ì›"""
        if hasattr(self, '__dict__'):
            return self.__dict__.keys()
        else:
            return [attr for attr in dir(self) if not attr.startswith('_')]
    
    def values(self):
        """ë”•ì…”ë„ˆë¦¬ì²˜ëŸ¼ values() ë©”ì„œë“œ ì§€ì›"""
        if hasattr(self, '__dict__'):
            return self.__dict__.values()
        else:
            return [getattr(self, attr) for attr in self.keys()]
    
    def items(self):
        """ë”•ì…”ë„ˆë¦¬ì²˜ëŸ¼ items() ë©”ì„œë“œ ì§€ì›"""
        if hasattr(self, '__dict__'):
            return self.__dict__.items()
        else:
            return [(key, getattr(self, key)) for key in self.keys()]
    
    def update(self, other: Union[Dict[str, Any], 'SafeConfigMixin']):
        """ë”•ì…”ë„ˆë¦¬ì²˜ëŸ¼ update() ë©”ì„œë“œ ì§€ì›"""
        if isinstance(other, dict):
            for key, value in other.items():
                setattr(self, key, value)
        elif hasattr(other, 'items'):
            for key, value in other.items():
                setattr(self, key, value)
        else:
            raise TypeError(f"Cannot update with {type(other)}")
    
    def to_dict(self) -> Dict[str, Any]:
        """ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜"""
        if hasattr(self, '__dict__'):
            return self.__dict__.copy()
        else:
            return {key: getattr(self, key) for key in self.keys()}

# ===============================================================
# ğŸ”§ ì‹œìŠ¤í…œ ì •ë³´ ìœ í‹¸ë¦¬í‹° (conda í™˜ê²½ íŠ¹í™”)
# ===============================================================

def detect_container() -> bool:
    """ğŸ³ ì»¨í…Œì´ë„ˆ í™˜ê²½ ê°ì§€"""
    indicators = [
        os.path.exists('/.dockerenv'),
        os.getenv('KUBERNETES_SERVICE_HOST') is not None,
        os.getenv('CONTAINER') is not None,
        'docker' in str(Path('/proc/1/cgroup')).lower() if os.path.exists('/proc/1/cgroup') else False
    ]
    return any(indicators)

def detect_m3_max() -> bool:
    """ğŸ M3 Max ì¹© ê°ì§€ (conda í™˜ê²½ ìµœì í™”)"""
    if platform.system() != 'Darwin':
        return False
    
    try:
        result = subprocess.run(
            ['sysctl', '-n', 'machdep.cpu.brand_string'], 
            capture_output=True, text=True, timeout=5
        )
        return 'M3' in result.stdout
    except:
        return False

def detect_conda_environment() -> Dict[str, Any]:
    """ğŸ conda í™˜ê²½ ì •ë³´ ê°ì§€"""
    conda_info = {
        'is_conda': False,
        'env_name': None,
        'prefix': None,
        'python_version': platform.python_version()
    }
    
    try:
        # CONDA_DEFAULT_ENV í™˜ê²½ë³€ìˆ˜ í™•ì¸
        conda_env = os.getenv('CONDA_DEFAULT_ENV')
        if conda_env:
            conda_info['is_conda'] = True
            conda_info['env_name'] = conda_env
        
        # CONDA_PREFIX í™•ì¸
        conda_prefix = os.getenv('CONDA_PREFIX')
        if conda_prefix:
            conda_info['prefix'] = conda_prefix
            if not conda_info['is_conda']:
                conda_info['is_conda'] = True
                conda_info['env_name'] = Path(conda_prefix).name
        
    except Exception:
        pass
    
    return conda_info

def get_available_memory() -> float:
    """ğŸ’¾ ì‚¬ìš© ê°€ëŠ¥í•œ ë©”ëª¨ë¦¬ ê³„ì‚° (GB) - conda í™˜ê²½ ìµœì í™”"""
    try:
        import psutil
        return psutil.virtual_memory().total / (1024**3)
    except ImportError:
        # psutilì´ ì—†ìœ¼ë©´ ì¶”ì •ê°’ (conda í™˜ê²½ì—ì„œëŠ” ë³´í†µ ì„¤ì¹˜ë¨)
        if detect_m3_max():
            return 128.0  # M3 MaxëŠ” ë³´í†µ 128GB
        elif platform.system() == 'Darwin':
            return 16.0   # macOS ê¸°ë³¸ê°’
        else:
            return 8.0    # ì¼ë°˜ì ì¸ ì„œë²„

def collect_system_info() -> Dict[str, Any]:
    """ğŸ–¥ï¸ ì‹œìŠ¤í…œ ì •ë³´ ìˆ˜ì§‘ (conda í™˜ê²½ í¬í•¨)"""
    conda_info = detect_conda_environment()
    
    return {
        'platform': platform.system(),
        'machine': platform.machine(),
        'python_version': platform.python_version(),
        'is_container': detect_container(),
        'is_m3_max': detect_m3_max(),
        'available_memory_gb': get_available_memory(),
        'cpu_count': os.cpu_count() or 4,
        'home_dir': str(Path.home()),
        'cwd': str(Path.cwd()),
        'conda_env': conda_info['env_name'],
        'is_conda': conda_info['is_conda'],
        'conda_prefix': conda_info['prefix']
    }

class SystemInfo(SafeConfigMixin):
    """ì‹œìŠ¤í…œ ì •ë³´ í´ë˜ìŠ¤ - SafeConfigMixin ìƒì† (conda íŠ¹í™”)"""
    
    def __init__(self):
        super().__init__()
        self.platform_system = platform.system()
        self.platform_machine = platform.machine()
        self.platform_version = platform.version()
        self.is_darwin = self.platform_system == 'Darwin'
        self.is_linux = self.platform_system == 'Linux'
        self.is_windows = self.platform_system == 'Windows'
        self.is_apple_silicon = self.is_darwin and ('arm64' in self.platform_machine or 'M1' in self.platform_machine or 'M2' in self.platform_machine or 'M3' in self.platform_machine)
        self.is_m3_max = self._detect_m3_max()
        self.memory_gb = self._detect_memory_gb()
        self.cpu_count = os.cpu_count() or 4
        
        # conda í™˜ê²½ ì •ë³´ ì¶”ê°€
        conda_info = detect_conda_environment()
        self.is_conda = conda_info['is_conda']
        self.conda_env_name = conda_info['env_name']
        self.conda_prefix = conda_info['prefix']
    
    def _detect_m3_max(self) -> bool:
        """M3 Max ì¹© ê°ì§€"""
        if not self.is_apple_silicon:
            return False
        
        try:
            result = subprocess.run(
                ['sysctl', '-n', 'machdep.cpu.brand_string'], 
                capture_output=True, text=True, timeout=5
            )
            chip_info = result.stdout.strip()
            return 'M3' in chip_info and ('Max' in chip_info or 'Pro' in chip_info)
        except:
            return False
    
    def _detect_memory_gb(self) -> float:
        """ë©”ëª¨ë¦¬ ìš©ëŸ‰ ê°ì§€ (conda í™˜ê²½ ìµœì í™”)"""
        try:
            if self.is_darwin:
                result = subprocess.run(
                    ['sysctl', '-n', 'hw.memsize'],
                    capture_output=True, text=True, timeout=5
                )
                return int(result.stdout.strip()) / (1024**3)
            else:
                import psutil
                return psutil.virtual_memory().total / (1024**3)
        except:
            return 16.0

# ===============================================================
# ğŸš¨ GPUConfig í´ë˜ìŠ¤ (conda í™˜ê²½ ìµœì í™”)
# ===============================================================

class GPUConfig(SafeConfigMixin):
    """ğŸ”¥ GPU ì„¤ì • í´ë˜ìŠ¤ - conda í™˜ê²½ ìµœì í™”"""
    
    def __init__(self):
        super().__init__()
        self.device = self._auto_detect_device()
        self.is_m3_max = detect_m3_max()
        self.memory_gb = get_available_memory()
        self.optimization_level = "high" if self.is_m3_max else "balanced"
        self.batch_size = 4 if self.is_m3_max else 1
        self.max_workers = 12 if self.is_m3_max else 4
        self.enable_mps = self.device == 'mps'
        self.enable_cuda = self.device == 'cuda'
        self.float_compatibility_mode = True  # conda í™˜ê²½ ì•ˆì •ì„±
        
        # conda í™˜ê²½ íŠ¹í™” ì„¤ì •
        conda_info = detect_conda_environment()
        self.conda_optimized = conda_info['is_conda']
        self.conda_env_name = conda_info['env_name']
    
    def _auto_detect_device(self) -> str:
        """ë””ë°”ì´ìŠ¤ ìë™ ê°ì§€ (conda í™˜ê²½ ìµœì í™”)"""
        try:
            import torch
            if torch.backends.mps.is_available():
                return 'mps'
            elif torch.cuda.is_available():
                return 'cuda'
            else:
                return 'cpu'
        except ImportError:
            return 'cpu'
    
    def get_device_config(self) -> Dict[str, Any]:
        """ë””ë°”ì´ìŠ¤ ì„¤ì • ë°˜í™˜"""
        return {
            "device": self.device,
            "is_m3_max": self.is_m3_max,
            "memory_gb": self.memory_gb,
            "optimization_level": self.optimization_level,
            "batch_size": self.batch_size,
            "max_workers": self.max_workers,
            "enable_mps": self.enable_mps,
            "enable_cuda": self.enable_cuda,
            "float_compatibility_mode": self.float_compatibility_mode,
            "conda_optimized": self.conda_optimized,
            "conda_env_name": self.conda_env_name
        }

# ===============================================================
# ğŸš¨ Config í´ë˜ìŠ¤ - SafeConfigMixin ìƒì† ì¶”ê°€
# ===============================================================

class Config(SafeConfigMixin):
    """
    ğŸš¨ PipelineManager í˜¸í™˜ Config í´ë˜ìŠ¤ - get ë©”ì„œë“œ ë¬¸ì œ í•´ê²°
    âœ… SafeConfigMixin ìƒì†ìœ¼ë¡œ get() ë©”ì„œë“œ ì§€ì›
    âœ… pipeline_manager.pyì—ì„œ í•„ìš”ë¡œ í•˜ëŠ” í‘œì¤€ Config
    âœ… ê¸°ì¡´ ì½”ë“œ 100% í˜¸í™˜ì„± ë³´ì¥
    âœ… conda í™˜ê²½ ìµœì í™”
    """
    
    def __init__(self, 
                 environment: str = None,
                 device: str = "mps",
                 is_m3_max: bool = None,
                 **kwargs):
        """
        Config ì´ˆê¸°í™” (PipelineManager í˜¸í™˜)
        
        Args:
            environment: í™˜ê²½ (development/production/testing)
            device: ì‚¬ìš©í•  ë””ë°”ì´ìŠ¤ (mps/cuda/cpu)
            is_m3_max: M3 Max ì—¬ë¶€
            **kwargs: ì¶”ê°€ ì„¤ì •ë“¤
        """
        # ğŸš¨ SafeConfigMixin ì´ˆê¸°í™”
        super().__init__()
        
        # ì‹œìŠ¤í…œ ì •ë³´ ìˆ˜ì§‘
        self.system_info = collect_system_info()
        
        # ê¸°ë³¸ ì„¤ì •
        self.environment = environment or self._auto_detect_environment()
        self.device = device
        self.is_m3_max = is_m3_max if is_m3_max is not None else self.system_info['is_m3_max']
        
        # conda í™˜ê²½ ì •ë³´
        self.is_conda = self.system_info['is_conda']
        self.conda_env = self.system_info['conda_env']
        
        # ê¸°ë³¸ ì†ì„±ë“¤ ì„¤ì •
        self._setup_core_properties()
        
        # kwargsë¡œ ë°›ì€ ì¶”ê°€ ì„¤ì •ë“¤ ì ìš©
        for key, value in kwargs.items():
            setattr(self, key, value)
            
        logger.info(f"ğŸš¨ Config ì´ˆê¸°í™” ì™„ë£Œ - í™˜ê²½: {self.environment}, ë””ë°”ì´ìŠ¤: {self.device}")
        if self.is_conda:
            logger.info(f"ğŸ conda í™˜ê²½: {self.conda_env}")
    
    def _auto_detect_environment(self) -> str:
        """í™˜ê²½ ìë™ ê°ì§€"""
        env_var = os.getenv('APP_ENV', os.getenv('ENVIRONMENT', ''))
        if env_var.lower() in ['development', 'dev']:
            return 'development'
        elif env_var.lower() in ['production', 'prod']:
            return 'production'
        elif env_var.lower() in ['testing', 'test']:
            return 'testing'
        
        # DEBUG í™˜ê²½ë³€ìˆ˜ í™•ì¸
        if os.getenv('DEBUG', '').lower() in ['true', '1']:
            return 'development'
        
        return 'development'  # ê¸°ë³¸ê°’
    
    def _setup_core_properties(self):
        """í•µì‹¬ ì†ì„±ë“¤ ì„¤ì • (conda í™˜ê²½ ìµœì í™”)"""
        # ë””ë°”ì´ìŠ¤ ê´€ë ¨ ì„¤ì •
        self.use_gpu = self.device != 'cpu'
        self.enable_mps = self.device == 'mps'
        self.enable_cuda = self.device == 'cuda'
        
        # M3 Max ê´€ë ¨ ì„¤ì • (conda í™˜ê²½ ìµœì í™”)
        if self.is_m3_max and self.is_conda:
            self.optimization_level = 'high'  # condaì—ì„œëŠ” ì¡°ê¸ˆ ë‚®ì¶¤
            self.batch_size = 4
            self.max_workers = 8  # conda ì•ˆì •ì„± ê³ ë ¤
            self.memory_pool_gb = 24  # conda ë©”ëª¨ë¦¬ ê´€ë¦¬ ê³ ë ¤
            self.neural_engine_enabled = True
            self.metal_performance_shaders = True
        elif self.is_m3_max:
            self.optimization_level = 'maximum'
            self.batch_size = 6
            self.max_workers = 12
            self.memory_pool_gb = 32
            self.neural_engine_enabled = True
            self.metal_performance_shaders = True
        else:
            self.optimization_level = 'balanced'
            self.batch_size = 1
            self.max_workers = 4
            self.memory_pool_gb = 8
            self.neural_engine_enabled = False
            self.metal_performance_shaders = False
        
        # í™˜ê²½ë³„ ì„¤ì •
        if self.environment == 'development':
            self.debug = True
            self.log_level = 'DEBUG'
            self.reload = True
        elif self.environment == 'production':
            self.debug = False
            self.log_level = 'INFO'
            self.reload = False
        else:  # testing
            self.debug = True
            self.log_level = 'WARNING'
            self.reload = False
    
    def set(self, key: str, value: Any):
        """ì„¤ì •ê°’ ì„¤ì •í•˜ê¸°"""
        setattr(self, key, value)

# ===============================================================
# ğŸš¨ VirtualFittingConfig í´ë˜ìŠ¤ - SafeConfigMixin ìƒì† ì¶”ê°€
# ===============================================================

class VirtualFittingConfig(SafeConfigMixin):
    """ğŸš¨ ìˆ˜ì •ëœ ê°€ìƒ í”¼íŒ… ì„¤ì • - get ë©”ì„œë“œ ì§€ì› (conda ìµœì í™”)"""
    
    def __init__(self, **kwargs):
        # ğŸš¨ SafeConfigMixin ì´ˆê¸°í™”
        super().__init__()
        
        # ê¸°ë³¸ ì„¤ì •ê°’ë“¤
        self.model_name = kwargs.get('model_name', 'hr_viton')
        self.quality_level = kwargs.get('quality_level', 'balanced')
        self.device = kwargs.get('device', 'auto')
        self.batch_size = kwargs.get('batch_size', 1)
        self.input_size = kwargs.get('input_size', (512, 384))
        self.output_size = kwargs.get('output_size', (512, 384))
        
        # ì²˜ë¦¬ ì„¤ì •
        self.enable_pose_estimation = kwargs.get('enable_pose_estimation', True)
        self.enable_human_parsing = kwargs.get('enable_human_parsing', True)
        self.enable_cloth_segmentation = kwargs.get('enable_cloth_segmentation', True)
        self.enable_geometric_matching = kwargs.get('enable_geometric_matching', True)
        self.enable_warping = kwargs.get('enable_warping', True)
        self.enable_post_processing = kwargs.get('enable_post_processing', True)
        self.enable_quality_assessment = kwargs.get('enable_quality_assessment', True)
        
        # ìµœì í™” ì„¤ì • (conda í™˜ê²½ ê³ ë ¤)
        self.optimization_enabled = kwargs.get('optimization_enabled', True)
        self.use_fp16 = kwargs.get('use_fp16', False)  # conda ì•ˆì •ì„± ê³ ë ¤
        self.memory_optimization = kwargs.get('memory_optimization', True)
        self.parallel_processing = kwargs.get('parallel_processing', True)
        
        # ê³ ê¸‰ ì„¤ì •
        self.max_retries = kwargs.get('max_retries', 3)
        self.timeout_seconds = kwargs.get('timeout_seconds', 300)
        self.save_intermediate = kwargs.get('save_intermediate', False)
        
        # ì‹œìŠ¤í…œ ì •ë³´
        self.system_info = SystemInfo()
        
        # M3 Max ìë™ ìµœì í™” (conda ê³ ë ¤)
        if self.system_info.is_m3_max:
            self.device = 'mps' if self.device == 'auto' else self.device
            self.batch_size = max(self.batch_size, 2)
            self.use_fp16 = False  # conda í™˜ê²½ì—ì„œëŠ” ì•ˆì •ì„± ìš°ì„ 
            self.optimization_enabled = True
        
        # ì¶”ê°€ íŒŒë¼ë¯¸í„°ë“¤ì„ ë™ì ìœ¼ë¡œ ì„¤ì •
        for key, value in kwargs.items():
            if not hasattr(self, key):
                setattr(self, key, value)

# ===============================================================
# ğŸš¨ GeometricMatchingConfig í´ë˜ìŠ¤ - SafeConfigMixin ìƒì† ì¶”ê°€
# ===============================================================

class GeometricMatchingConfig(SafeConfigMixin):
    """ğŸš¨ ìˆ˜ì •ëœ ê¸°í•˜í•™ì  ë§¤ì¹­ ì„¤ì • - get ë©”ì„œë“œ ì§€ì›"""
    
    def __init__(self, **kwargs):
        super().__init__()
        
        self.quality_level = kwargs.get('quality_level', 'balanced')
        self.tps_points = kwargs.get('tps_points', 25)
        self.matching_threshold = kwargs.get('matching_threshold', 0.8)
        self.method = kwargs.get('method', 'auto')
        self.device = kwargs.get('device', 'auto')
        self.input_size = kwargs.get('input_size', (256, 192))
        self.output_size = kwargs.get('output_size', (256, 192))
        
        # í’ˆì§ˆë³„ ì„¤ì •
        quality_settings = {
            'fast': {'tps_points': 16, 'matching_threshold': 0.6},
            'balanced': {'tps_points': 25, 'matching_threshold': 0.8},
            'high': {'tps_points': 36, 'matching_threshold': 0.9},
            'maximum': {'tps_points': 49, 'matching_threshold': 0.95}
        }
        
        if self.quality_level in quality_settings:
            settings = quality_settings[self.quality_level]
            self.tps_points = settings['tps_points']
            self.matching_threshold = settings['matching_threshold']
        
        # ì¶”ê°€ íŒŒë¼ë¯¸í„°ë“¤ì„ ë™ì ìœ¼ë¡œ ì„¤ì •
        for key, value in kwargs.items():
            if not hasattr(self, key):
                setattr(self, key, value)

# ===============================================================
# ğŸš¨ PipelineConfig í´ë˜ìŠ¤ - SafeConfigMixin ìƒì† ì¶”ê°€
# ===============================================================

class PipelineConfig(SafeConfigMixin):
    """ğŸš¨ ìˆ˜ì •ëœ íŒŒì´í”„ë¼ì¸ ì„¤ì • - get ë©”ì„œë“œ ì§€ì› (conda ìµœì í™”)"""
    
    def __init__(self, **kwargs):
        super().__init__()
        
        # ì‹œìŠ¤í…œ ì •ë³´
        self.system_info = SystemInfo()
        
        # ê¸°ë³¸ ì„¤ì •
        self.device = kwargs.get('device', 'auto')
        self.quality_level = kwargs.get('quality_level', 'balanced')
        self.processing_mode = kwargs.get('processing_mode', 'production')
        
        # ì‹œìŠ¤í…œ ìµœì í™”
        self.memory_gb = kwargs.get('memory_gb', self.system_info.memory_gb)
        self.is_m3_max = kwargs.get('is_m3_max', self.system_info.is_m3_max)
        self.cpu_count = kwargs.get('cpu_count', self.system_info.cpu_count)
        
        # conda í™˜ê²½ ì •ë³´
        self.is_conda = self.system_info.is_conda
        self.conda_env_name = self.system_info.conda_env_name
        
        # ì²˜ë¦¬ ì„¤ì • (conda í™˜ê²½ ìµœì í™”)
        if self.is_conda and self.is_m3_max:
            # conda + M3 Max ì¡°í•©ì—ì„œëŠ” ì•ˆì •ì„± ìš°ì„ 
            self.batch_size = kwargs.get('batch_size', 2)
            self.use_fp16 = kwargs.get('use_fp16', False)
        else:
            self.batch_size = kwargs.get('batch_size', 1)
            self.use_fp16 = kwargs.get('use_fp16', True)
        
        self.max_retries = kwargs.get('max_retries', 3)
        self.timeout_seconds = kwargs.get('timeout_seconds', 300)
        self.save_intermediate = kwargs.get('save_intermediate', False)
        
        # ìµœì í™” ì„¤ì •
        self.optimization_enabled = kwargs.get('optimization_enabled', True)
        self.memory_optimization = kwargs.get('memory_optimization', True)
        self.parallel_processing = kwargs.get('parallel_processing', True)
        
        # ë””ë°”ì´ìŠ¤ ìë™ ê°ì§€
        if self.device == 'auto':
            self.device = self._auto_detect_device()
        
        # M3 Max ìë™ ìµœì í™” (conda ê³ ë ¤)
        if self.is_m3_max:
            if self.is_conda:
                self.batch_size = max(self.batch_size, 2)  # condaì—ì„œëŠ” ë³´ìˆ˜ì 
            else:
                self.batch_size = max(self.batch_size, 4)
            
            self.optimization_enabled = True
            self.memory_optimization = True
        
        # ì¶”ê°€ íŒŒë¼ë¯¸í„°ë“¤ì„ ë™ì ìœ¼ë¡œ ì„¤ì •
        for key, value in kwargs.items():
            if not hasattr(self, key):
                setattr(self, key, value)
    
    def _auto_detect_device(self) -> str:
        """ë””ë°”ì´ìŠ¤ ìë™ ê°ì§€"""
        try:
            import torch
            if torch.backends.mps.is_available():
                return 'mps'
            elif torch.cuda.is_available():
                return 'cuda'
            else:
                return 'cpu'
        except ImportError:
            return 'cpu'

# ===============================================================
# ğŸ¯ ì• í”Œë¦¬ì¼€ì´ì…˜ ì„¤ì • í´ë˜ìŠ¤ (SafeConfigMixin ìƒì†)
# ===============================================================

class Settings(SafeConfigMixin):
    """í†µí•© ì„¤ì • ê´€ë¦¬ì - SafeConfigMixin ìƒì† (conda ìµœì í™”)"""

    def __init__(self, env: Optional[str] = None, **kwargs):
        """í†µí•© ì„¤ì • ì´ˆê¸°í™” (conda í™˜ê²½ ê³ ë ¤)"""
        super().__init__()
        
        # ì‹œìŠ¤í…œ ì •ë³´ ìˆ˜ì§‘
        self.system_info = collect_system_info()
        
        # í™˜ê²½ ì„¤ì •
        self.env = env or self._auto_detect_environment()
        
        # conda í™˜ê²½ ì •ë³´
        self.is_conda = self.system_info['is_conda']
        self.conda_env = self.system_info['conda_env']
        
        # ê¸°ë³¸ ì• í”Œë¦¬ì¼€ì´ì…˜ ì„¤ì •
        self._setup_app_config()
        
        # AI ì„¤ì •
        self._setup_ai_config()
        
        # í¸ì˜ ì†ì„±ë“¤ ì„¤ì •
        self._setup_convenience_properties()
        
        logger.info(f"ğŸš¨ í†µí•© ì„¤ì • ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ (í™˜ê²½: {self.env})")
        if self.is_conda:
            logger.info(f"ğŸ conda í™˜ê²½: {self.conda_env}")

    def _auto_detect_environment(self) -> str:
        """í™˜ê²½ ìë™ ê°ì§€"""
        env_var = os.getenv('APP_ENV', os.getenv('ENVIRONMENT', ''))
        if env_var.lower() in ['development', 'dev']:
            return 'development'
        elif env_var.lower() in ['production', 'prod']:
            return 'production'
        elif env_var.lower() in ['testing', 'test']:
            return 'testing'
        
        if os.getenv('DEBUG', '').lower() in ['true', '1']:
            return 'development'
        
        return 'development'  # ê¸°ë³¸ê°’

    def _setup_app_config(self):
        """ì• í”Œë¦¬ì¼€ì´ì…˜ ê¸°ë³¸ ì„¤ì •"""
        # ì• í”Œë¦¬ì¼€ì´ì…˜ ê¸°ë³¸ ì •ë³´
        self.app_name = 'MyCloset AI'
        self.app_version = '3.0.0'
        self.app_description = 'AI-powered virtual try-on platform'
        
        # ì„œë²„ ì„¤ì •
        self.host = os.getenv('HOST', '0.0.0.0')
        self.port = int(os.getenv('PORT', 8000))
        self.debug = self.env == 'development'
        self.reload = self.debug
        
        # CORS ì„¤ì •
        self.cors_origins = [
            'http://localhost:3000',
            'http://localhost:3001',
            'http://127.0.0.1:3000'
        ]
        
        # íŒŒì¼ ì—…ë¡œë“œ ì„¤ì •
        self.max_file_size = 10 * 1024 * 1024  # 10MB
        self.allowed_extensions = ['.jpg', '.jpeg', '.png', '.webp']
        
        # ê²½ë¡œ ì„¤ì •
        self.upload_dir = './static/uploads'
        self.results_dir = './static/results'
        self.models_dir = './ai_models'

    def _setup_ai_config(self):
        """AI ì„¤ì • ì´ˆê¸°í™” (conda í™˜ê²½ ìµœì í™”)"""
        # ë””ë°”ì´ìŠ¤ ìë™ ê°ì§€
        self.device = self._auto_detect_device()
        self.use_gpu = self.device != 'cpu'
        self.is_m3_max = self.system_info['is_m3_max']
        
        # ë©”ëª¨ë¦¬ ì„¤ì •
        self.memory_gb = self.system_info['available_memory_gb']
        self.batch_size = self._get_optimal_batch_size()
        self.num_workers = min(4, self.system_info['cpu_count'])
        
        # í’ˆì§ˆ ì„¤ì • (conda í™˜ê²½ ê³ ë ¤)
        if self.is_conda and self.is_m3_max:
            self.pipeline_quality = 'balanced'  # condaì—ì„œëŠ” ì•ˆì •ì„± ìš°ì„ 
        elif self.is_m3_max:
            self.pipeline_quality = 'high'
        else:
            self.pipeline_quality = 'balanced'
            
        self.enable_optimization = True
        self.enable_caching = True

    def _auto_detect_device(self) -> str:
        """AI ë””ë°”ì´ìŠ¤ ìë™ ê°ì§€"""
        try:
            import torch
            if torch.backends.mps.is_available() and self.system_info['is_m3_max']:
                return 'mps'
            elif torch.cuda.is_available():
                return 'cuda'
            else:
                return 'cpu'
        except ImportError:
            return 'cpu'

    def _get_optimal_batch_size(self) -> int:
        """ìµœì  ë°°ì¹˜ í¬ê¸° ê³„ì‚° (conda í™˜ê²½ ê³ ë ¤)"""
        if self.is_conda and self.is_m3_max and self.memory_gb >= 64:
            return 2  # conda í™˜ê²½ì—ì„œëŠ” ë³´ìˆ˜ì 
        elif self.is_m3_max and self.memory_gb >= 64:
            return 4
        elif self.use_gpu:
            return 2
        else:
            return 1

    def _setup_convenience_properties(self):
        """í¸ì˜ ì†ì„± ì„¤ì • (ê¸°ì¡´ ì½”ë“œ í˜¸í™˜ì„±)"""
        # í•˜ìœ„ í˜¸í™˜ì„±ì„ ìœ„í•œ ì§ì ‘ ì†ì„± ì„¤ì •
        self.APP_NAME = self.app_name
        self.DEBUG = self.debug
        self.HOST = self.host
        self.PORT = self.port
        self.CORS_ORIGINS = self.cors_origins
        self.DEVICE = self.device
        self.USE_GPU = self.use_gpu
        self.IS_M3_MAX = self.is_m3_max
        self.IS_CONDA = self.is_conda
        self.CONDA_ENV = self.conda_env

# ===============================================================
# ğŸ¯ ì „ì—­ ì„¤ì • ì¸ìŠ¤í„´ìŠ¤ ë° íŒ©í† ë¦¬ í•¨ìˆ˜ë“¤
# ===============================================================

@lru_cache()
def get_settings(env: Optional[str] = None, **kwargs) -> Settings:
    """ì „ì—­ ì„¤ì • ì¸ìŠ¤í„´ìŠ¤ (ìºì‹œë¨)"""
    return Settings(env=env, **kwargs)

def create_config(**kwargs) -> Config:
    """í‘œì¤€ Config ì¸ìŠ¤í„´ìŠ¤ ìƒì„± (PipelineManager í˜¸í™˜)"""
    return Config(**kwargs)

def get_config(**kwargs) -> Config:
    """Config ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜ (PipelineManager í˜¸í™˜)"""
    try:
        _settings = get_settings()
        return create_config(
            environment=_settings.env,
            device=_settings.device,
            is_m3_max=_settings.is_m3_max,
            **kwargs
        )
    except Exception:
        return create_config(**kwargs)

def get_pipeline_config(**kwargs) -> PipelineConfig:
    """íŒŒì´í”„ë¼ì¸ ì„¤ì • ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    return PipelineConfig(**kwargs)

def get_virtual_fitting_config(**kwargs) -> VirtualFittingConfig:
    """ê°€ìƒ í”¼íŒ… ì„¤ì • ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    return VirtualFittingConfig(**kwargs)

def get_geometric_matching_config(**kwargs) -> GeometricMatchingConfig:
    """ê¸°í•˜í•™ì  ë§¤ì¹­ ì„¤ì • ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    return GeometricMatchingConfig(**kwargs)

def create_gpu_config() -> GPUConfig:
    """GPU ì„¤ì • ì¸ìŠ¤í„´ìŠ¤ ìƒì„±"""
    return GPUConfig()

# ===============================================================
# ğŸš¨ ì•ˆì „í•œ ì „ì—­ ì„¤ì • ì´ˆê¸°í™” (ìˆœí™˜ ì°¸ì¡° ë°©ì§€, conda ìµœì í™”)
# ===============================================================

# ğŸš¨ ì „ì—­ ë³€ìˆ˜ë“¤ì„ ì•ˆì „í•˜ê²Œ ì´ˆê¸°í™”
try:
    # ì„¤ì • ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
    _temp_settings = get_settings()
    
    # GPU ì„¤ì • ìƒì„±
    _temp_gpu_config = create_gpu_config()
    
    # í•˜ìœ„ í˜¸í™˜ì„± ì§€ì› (ê¸°ì¡´ ì½”ë“œ 100% ì§€ì›)
    APP_NAME = _temp_settings.APP_NAME
    DEBUG = _temp_settings.DEBUG
    HOST = _temp_settings.HOST
    PORT = _temp_settings.PORT
    CORS_ORIGINS = _temp_settings.CORS_ORIGINS
    DEVICE = _temp_settings.DEVICE
    USE_GPU = _temp_settings.USE_GPU
    IS_M3_MAX = _temp_settings.IS_M3_MAX
    IS_CONDA = _temp_settings.IS_CONDA
    CONDA_ENV = _temp_settings.CONDA_ENV
    
    # ğŸš¨ ì¤‘ìš”: settings ë³€ìˆ˜ëŠ” ì—¬ê¸°ì„œ ì •ì˜ë¨
    settings = _temp_settings
    
    # ğŸš¨ ì¤‘ìš”: GPUConfig ë³€ìˆ˜ëŠ” ì—¬ê¸°ì„œ ì •ì˜ë¨
    GPUConfig = _temp_gpu_config  # ì¸ìŠ¤í„´ìŠ¤ê°€ ì•„ë‹ˆë¼ í´ë˜ìŠ¤ ìì²´
    gpu_config = _temp_gpu_config  # ì¸ìŠ¤í„´ìŠ¤
    
    # ì¶”ê°€ ì„¤ì •ë“¤
    DEFAULT_CONFIG = create_config()
    
except Exception as e:
    logger.warning(f"ğŸš¨ ì„¤ì • ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜: {e}")
    # ì™„ì „ í´ë°± ì„¤ì •
    APP_NAME = 'MyCloset AI'
    DEBUG = True
    HOST = '0.0.0.0'
    PORT = 8000
    CORS_ORIGINS = ['http://localhost:3000']
    DEVICE = 'mps' if detect_m3_max() else 'cpu'
    USE_GPU = DEVICE != 'cpu'
    IS_M3_MAX = detect_m3_max()
    IS_CONDA = detect_conda_environment()['is_conda']
    CONDA_ENV = detect_conda_environment()['env_name']
    
    # ğŸš¨ í´ë°± settings ê°ì²´ ìƒì„±
    class FallbackSettings:
        def __init__(self):
            self.app = {'env': 'development'}
            self.env = 'development'
            self.is_conda = IS_CONDA
            self.conda_env = CONDA_ENV
        def get(self, key, default=None):
            return getattr(self, key, default)
    
    settings = FallbackSettings()
    
    # ğŸš¨ í´ë°± GPU ì„¤ì •
    class FallbackGPUConfig:
        def __init__(self):
            self.device = DEVICE
            self.is_m3_max = IS_M3_MAX
        def get(self, key, default=None):
            return getattr(self, key, default)
    
    gpu_config = FallbackGPUConfig()
    DEFAULT_CONFIG = None

# ===============================================================
# ğŸ¯ MODEL_CONFIG ì¶”ê°€ (step_04ì—ì„œ í•„ìš”)
# ===============================================================

MODEL_CONFIG = {
    'geometric_matching': {
        'quality_level': 'balanced',
        'tps_points': 25,
        'matching_threshold': 0.8,
        'method': 'auto',
        'device': DEVICE,
        'input_size': (256, 192),
        'output_size': (256, 192)
    },
    'virtual_fitting': {
        'model_name': 'hr_viton',
        'quality_level': 'balanced',
        'device': DEVICE,
        'batch_size': 1,
        'input_size': (512, 384),
        'output_size': (512, 384)
    }
}

# ë¡œê·¸ ë©”ì‹œì§€ (ì´ì œ settingsê°€ ì •ì˜ëœ í›„ì— ì‹¤í–‰ë¨)
logger.info("ğŸš¨ Phase 1 ì„¤ì • ì‹œìŠ¤í…œ ë¡œë“œ ì™„ë£Œ - NameError ë¬¸ì œ í•´ê²°")
logger.info(f"ğŸ¯ í™˜ê²½: {getattr(settings, 'env', 'development')}, ë””ë°”ì´ìŠ¤: {DEVICE}")

if IS_CONDA:
    logger.info(f"ğŸ conda í™˜ê²½: {CONDA_ENV}")
if IS_M3_MAX:
    logger.info("ğŸ M3 Max ìµœì í™” í™œì„±í™”")
if USE_GPU:
    logger.info(f"ğŸ® GPU ê°€ì† í™œì„±í™”: {DEVICE}")

__all__ = [
    # ğŸš¨ SafeConfigMixin ì¶”ê°€
    'SafeConfigMixin',
    
    # í•µì‹¬ í´ë˜ìŠ¤ë“¤ (ëª¨ë‘ SafeConfigMixin ìƒì†)
    'Config', 'VirtualFittingConfig', 'GeometricMatchingConfig', 'PipelineConfig',
    'Settings', 'SystemInfo', 'GPUConfig',
    
    # íŒ©í† ë¦¬ í•¨ìˆ˜ë“¤
    'get_settings', 'create_config', 'get_config',
    'get_pipeline_config', 'get_virtual_fitting_config', 'get_geometric_matching_config',
    'create_gpu_config',
    
    # ì „ì—­ ì„¤ì •
    'settings', 'gpu_config', 'DEFAULT_CONFIG', 'MODEL_CONFIG',
    
    # í•˜ìœ„ í˜¸í™˜ì„±
    'APP_NAME', 'DEBUG', 'HOST', 'PORT', 'CORS_ORIGINS', 
    'DEVICE', 'USE_GPU', 'IS_M3_MAX', 'IS_CONDA', 'CONDA_ENV',
    
    # ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
    'detect_m3_max', 'get_available_memory', 'collect_system_info', 
    'detect_conda_environment'
]