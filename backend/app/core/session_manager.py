# backend/app/core/session_manager.py
"""
ğŸ”¥ MyCloset AI ì™„ì „í•œ ì„¸ì…˜ ë§¤ë‹ˆì € - ê¸°ì¡´ í˜¸í™˜ì„± + Stepê°„ ë°ì´í„° íë¦„
âœ… ê¸°ì¡´ í•¨ìˆ˜ëª… 100% ìœ ì§€ (create_session, get_session_images, save_step_result ë“±)
âœ… Stepê°„ ë°ì´í„° íë¦„ ì™„ë²½ ì§€ì›
âœ… ì´ë¯¸ì§€ ì¬ì—…ë¡œë“œ ë¬¸ì œ ì™„ì „ í•´ê²°
âœ… ì˜ì¡´ì„± ê²€ì¦ ë° ìˆœì„œ ë³´ì¥
âœ… M3 Max ìµœì í™”
âœ… conda í™˜ê²½ ì§€ì›
âœ… ë©”ëª¨ë¦¬ íš¨ìœ¨ì  ê´€ë¦¬
âœ… ì‹¤ì‹œê°„ ì§„í–‰ë¥  ì¶”ì 
"""

import json
import time
import uuid
import asyncio
import shutil
import threading
import traceback
from pathlib import Path
from typing import Dict, Any, Optional, Tuple, List, Union
from datetime import datetime, timedelta
from dataclasses import dataclass, asdict, field
from enum import Enum
import logging

import numpy as np
from PIL import Image
import aiofiles

logger = logging.getLogger(__name__)

# =============================================================================
# ğŸ”¥ Stepê°„ ë°ì´í„° íë¦„ ì •ì˜ (ìƒˆë¡œ ì¶”ê°€)
# =============================================================================

class StepStatus(Enum):
    """Step ì²˜ë¦¬ ìƒíƒœ"""
    PENDING = "pending"
    PROCESSING = "processing"
    COMPLETED = "completed"
    FAILED = "failed"
    SKIPPED = "skipped"

class DataType(Enum):
    """ë°ì´í„° íƒ€ì… ì •ì˜"""
    RAW_IMAGE = "raw_image"
    PROCESSED_IMAGE = "processed_image"
    SEGMENTATION_MASK = "segmentation_mask"
    POSE_KEYPOINTS = "pose_keypoints"
    FEATURE_VECTOR = "feature_vector"
    TRANSFORMATION_MATRIX = "transformation_matrix"
    QUALITY_SCORE = "quality_score"
    METADATA = "metadata"

@dataclass
class StepDataFlow:
    """Stepê°„ ë°ì´í„° íë¦„ ì •ì˜"""
    source_step: int
    target_step: int
    data_type: DataType
    required: bool = True

# 8ë‹¨ê³„ íŒŒì´í”„ë¼ì¸ ë°ì´í„° íë¦„ ì •ì˜
PIPELINE_DATA_FLOWS = [
    # Step 1 -> Step 2
    StepDataFlow(1, 2, DataType.PROCESSED_IMAGE, required=True),
    StepDataFlow(1, 2, DataType.SEGMENTATION_MASK, required=True),
    
    # Step 2 -> Step 3  
    StepDataFlow(2, 3, DataType.POSE_KEYPOINTS, required=True),
    StepDataFlow(1, 3, DataType.RAW_IMAGE, required=True),
    
    # Step 3 -> Step 4
    StepDataFlow(3, 4, DataType.SEGMENTATION_MASK, required=True),
    StepDataFlow(2, 4, DataType.POSE_KEYPOINTS, required=True),
    
    # Step 4 -> Step 5
    StepDataFlow(4, 5, DataType.TRANSFORMATION_MATRIX, required=True),
    StepDataFlow(3, 5, DataType.SEGMENTATION_MASK, required=True),
    
    # Step 5 -> Step 6 (í•µì‹¬!)
    StepDataFlow(5, 6, DataType.PROCESSED_IMAGE, required=True),
    StepDataFlow(1, 6, DataType.RAW_IMAGE, required=True),
    StepDataFlow(2, 6, DataType.POSE_KEYPOINTS, required=True),
    
    # Step 6 -> Step 7
    StepDataFlow(6, 7, DataType.PROCESSED_IMAGE, required=True),
    StepDataFlow(6, 7, DataType.QUALITY_SCORE, required=False),
    
    # Step 7 -> Step 8
    StepDataFlow(7, 8, DataType.PROCESSED_IMAGE, required=True),
    StepDataFlow(7, 8, DataType.METADATA, required=False),
]

# =============================================================================
# ğŸ”¥ ê¸°ì¡´ ë°ì´í„° êµ¬ì¡° (í˜¸í™˜ì„± ìœ ì§€)
# =============================================================================

@dataclass
class ImageInfo:
    """ì´ë¯¸ì§€ ì •ë³´ (ê¸°ì¡´ í˜¸í™˜)"""
    path: str
    size: Tuple[int, int]  # (width, height)
    mode: str  # RGB, RGBA ë“±
    format: str  # JPEG, PNG ë“±
    file_size: int  # ë°”ì´íŠ¸

@dataclass
class SessionMetadata:
    """ì„¸ì…˜ ë©”íƒ€ë°ì´í„° (ê¸°ì¡´ í˜¸í™˜)"""
    session_id: str
    created_at: datetime
    last_accessed: datetime
    measurements: Dict[str, Any]
    person_image: ImageInfo
    clothing_image: ImageInfo
    total_steps: int = 8
    completed_steps: List[int] = None
    
    def __post_init__(self):
        if self.completed_steps is None:
            self.completed_steps = []
    
    def to_dict(self) -> Dict[str, Any]:
        """ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜ (JSON ì§ë ¬í™”ìš©)"""
        return {
            'session_id': self.session_id,
            'created_at': self.created_at.isoformat(),
            'last_accessed': self.last_accessed.isoformat(),
            'measurements': self.measurements,
            'person_image': asdict(self.person_image),
            'clothing_image': asdict(self.clothing_image),
            'total_steps': self.total_steps,
            'completed_steps': self.completed_steps
        }
    
    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> 'SessionMetadata':
        """ë”•ì…”ë„ˆë¦¬ì—ì„œ ìƒì„± (JSON ì—­ì§ë ¬í™”ìš©)"""
        return cls(
            session_id=data['session_id'],
            created_at=datetime.fromisoformat(data['created_at']),
            last_accessed=datetime.fromisoformat(data['last_accessed']),
            measurements=data['measurements'],
            person_image=ImageInfo(**data['person_image']),
            clothing_image=ImageInfo(**data['clothing_image']),
            total_steps=data.get('total_steps', 8),
            completed_steps=data.get('completed_steps', [])
        )

class SessionData:
    """ëŸ°íƒ€ì„ ì„¸ì…˜ ë°ì´í„° (ê¸°ì¡´ í˜¸í™˜ + í™•ì¥)"""
    
    def __init__(self, metadata: SessionMetadata, session_dir: Path):
        self.metadata = metadata
        self.session_dir = session_dir
        
        # ê¸°ì¡´ í˜¸í™˜
        self.step_results: Dict[int, Dict[str, Any]] = {}
        self.lock = threading.RLock()
        
        # ìƒˆë¡œ ì¶”ê°€ - Stepê°„ ë°ì´í„° íë¦„ ì§€ì›
        self.step_data_cache: Dict[int, Dict[str, Any]] = {}  # Stepë³„ ì¤‘ê°„ ë°ì´í„°
        self.step_dependencies: Dict[int, List[int]] = {}  # Step ì˜ì¡´ì„±
        self.pipeline_flows = self._build_pipeline_flows()
        
        # ì„±ëŠ¥ ì¶”ì 
        self.step_processing_times: Dict[int, float] = {}
        self.step_quality_scores: Dict[int, float] = {}
        self.memory_usage_peak: float = 0.0
    
    def _build_pipeline_flows(self) -> Dict[int, List[StepDataFlow]]:
        """íŒŒì´í”„ë¼ì¸ íë¦„ êµ¬ì¶•"""
        flows = {}
        for flow in PIPELINE_DATA_FLOWS:
            if flow.target_step not in flows:
                flows[flow.target_step] = []
            flows[flow.target_step].append(flow)
        return flows
    
    @property
    def session_id(self) -> str:
        return self.metadata.session_id
    
    def update_access_time(self):
        """ë§ˆì§€ë§‰ ì ‘ê·¼ ì‹œê°„ ì—…ë°ì´íŠ¸"""
        with self.lock:
            self.metadata.last_accessed = datetime.now()
    
    def is_expired(self, max_age_hours: int = 24) -> bool:
        """ì„¸ì…˜ ë§Œë£Œ í™•ì¸"""
        age = datetime.now() - self.metadata.created_at
        return age > timedelta(hours=max_age_hours)
    
    def add_completed_step(self, step_id: int):
        """ì™„ë£Œëœ ë‹¨ê³„ ì¶”ê°€"""
        with self.lock:
            if step_id not in self.metadata.completed_steps:
                self.metadata.completed_steps.append(step_id)
                self.metadata.completed_steps.sort()
    
    def get_progress_percent(self) -> float:
        """ì§„í–‰ë¥  ë°˜í™˜ (0-100)"""
        return len(self.metadata.completed_steps) / self.metadata.total_steps * 100
    
    # =========================================================================
    # ğŸ”¥ ìƒˆë¡œ ì¶”ê°€ - Stepê°„ ë°ì´í„° íë¦„ ë©”ì„œë“œ
    # =========================================================================
    
    def validate_step_dependencies(self, step_id: int) -> Dict[str, Any]:
        """Step ì˜ì¡´ì„± ê²€ì¦"""
        try:
            required_flows = self.pipeline_flows.get(step_id, [])
            missing_dependencies = []
            
            for flow in required_flows:
                if not flow.required:
                    continue
                    
                source_step = flow.source_step
                
                # ì†ŒìŠ¤ Stepì´ ì™„ë£Œë˜ì—ˆëŠ”ì§€ í™•ì¸
                if source_step not in self.metadata.completed_steps:
                    missing_dependencies.append(f"Step {source_step} ë¯¸ì™„ë£Œ")
                    continue
                
                # í•„ìš”í•œ ë°ì´í„°ê°€ ìˆëŠ”ì§€ í™•ì¸
                if not self._has_step_data(source_step, flow.data_type):
                    missing_dependencies.append(f"Step {source_step} -> {flow.data_type.value} ë°ì´í„° ì—†ìŒ")
            
            return {
                'valid': len(missing_dependencies) == 0,
                'missing': missing_dependencies,
                'required_steps': [f.source_step for f in required_flows if f.required]
            }
            
        except Exception as e:
            logger.error(f"ì˜ì¡´ì„± ê²€ì¦ ì‹¤íŒ¨: {e}")
            return {'valid': False, 'missing': [f"ê²€ì¦ ì˜¤ë¥˜: {e}"], 'required_steps': []}
    
    def prepare_step_input_data(self, step_id: int) -> Dict[str, Any]:
        """Step ì…ë ¥ ë°ì´í„° ì¤€ë¹„"""
        try:
            input_data = {
                'session_id': self.session_id,
                'step_id': step_id,
                'measurements': self.metadata.measurements
            }
            
            # Stepë³„ ì˜ì¡´ì„± ë°ì´í„° ì¶”ê°€
            required_flows = self.pipeline_flows.get(step_id, [])
            
            for flow in required_flows:
                source_step = flow.source_step
                data_type = flow.data_type
                
                if source_step in self.step_data_cache:
                    source_data = self.step_data_cache[source_step]
                    
                    # ë°ì´í„° íƒ€ì…ë³„ ì¶”ê°€
                    data_key = f"step_{source_step}_{data_type.value}"
                    
                    if data_type == DataType.RAW_IMAGE:
                        input_data[data_key] = source_data.get('primary_output')
                    elif data_type == DataType.SEGMENTATION_MASK:
                        input_data[data_key] = source_data.get('segmentation_mask')
                    elif data_type == DataType.POSE_KEYPOINTS:
                        input_data[data_key] = source_data.get('pose_keypoints')
                    elif data_type == DataType.TRANSFORMATION_MATRIX:
                        input_data[data_key] = source_data.get('transformation_matrix')
                    else:
                        input_data[data_key] = source_data.get('primary_output')
            
            return input_data
            
        except Exception as e:
            logger.error(f"ì…ë ¥ ë°ì´í„° ì¤€ë¹„ ì‹¤íŒ¨: {e}")
            return {'session_id': self.session_id, 'step_id': step_id}
    
    def save_step_data(self, step_id: int, step_result: Dict[str, Any]):
        """Step ë°ì´í„° ì €ì¥ (ì¤‘ê°„ ê²°ê³¼ í¬í•¨)"""
        try:
            with self.lock:
                # ê¸°ì¡´ step_results ì €ì¥ (í˜¸í™˜ì„± ìœ ì§€)
                self.step_results[step_id] = {
                    **step_result,
                    'timestamp': datetime.now().isoformat(),
                    'step_id': step_id
                }
                
                # ìƒˆë¡œìš´ step_data_cache ì €ì¥ (ë°ì´í„° íë¦„ìš©)
                self.step_data_cache[step_id] = step_result.copy()
                
                # ì„±ëŠ¥ ì •ë³´ ì €ì¥
                if 'processing_time' in step_result:
                    self.step_processing_times[step_id] = step_result['processing_time']
                
                if 'quality_score' in step_result:
                    self.step_quality_scores[step_id] = step_result['quality_score']
                
                # ì™„ë£Œëœ ë‹¨ê³„ ì¶”ê°€
                self.add_completed_step(step_id)
                
                logger.debug(f"ğŸ“Š Step {step_id} ë°ì´í„° ì €ì¥ ì™„ë£Œ")
                
        except Exception as e:
            logger.error(f"Step ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def _has_step_data(self, step_id: int, data_type: DataType) -> bool:
        """Step ë°ì´í„° ì¡´ì¬ í™•ì¸"""
        try:
            if step_id not in self.step_data_cache:
                return False
            
            step_data = self.step_data_cache[step_id]
            
            if data_type == DataType.RAW_IMAGE:
                return 'primary_output' in step_data
            elif data_type == DataType.SEGMENTATION_MASK:
                return 'segmentation_mask' in step_data
            elif data_type == DataType.POSE_KEYPOINTS:
                return 'pose_keypoints' in step_data
            elif data_type == DataType.TRANSFORMATION_MATRIX:
                return 'transformation_matrix' in step_data
            else:
                return 'primary_output' in step_data
                
        except Exception:
            return False

# =============================================================================
# ğŸ”¥ ë©”ì¸ ì„¸ì…˜ ë§¤ë‹ˆì € í´ë˜ìŠ¤ (ê¸°ì¡´ í•¨ìˆ˜ëª… 100% ìœ ì§€)
# =============================================================================

class SessionManager:
    """
    ğŸ”¥ ì™„ì „í•œ ì„¸ì…˜ ë§¤ë‹ˆì € - ê¸°ì¡´ í˜¸í™˜ì„± + Stepê°„ ë°ì´í„° íë¦„
    
    âœ… ê¸°ì¡´ í•¨ìˆ˜ëª… 100% ìœ ì§€:
    - create_session()
    - get_session_images()  
    - save_step_result()
    - get_session_status()
    - get_all_sessions_status()
    - cleanup_expired_sessions()
    - cleanup_all_sessions()
    
    âœ… ìƒˆë¡œ ì¶”ê°€:
    - Stepê°„ ë°ì´í„° íë¦„ ìë™ ê´€ë¦¬
    - ì˜ì¡´ì„± ê²€ì¦
    - ì‹¤ì‹œê°„ ì§„í–‰ë¥  ì¶”ì 
    """
    
    def __init__(self, base_path: Optional[Path] = None):
        # ê¸°ë³¸ ê²½ë¡œ ì„¤ì •
        self.base_path = base_path or Path("backend/static/sessions")
        self.base_path.mkdir(parents=True, exist_ok=True)
        
        # ì„¸ì…˜ ì €ì¥ì†Œ
        self.sessions: Dict[str, SessionData] = {}
        
        # ì„¤ì •
        self.max_sessions = 100  # ìµœëŒ€ ë™ì‹œ ì„¸ì…˜ ìˆ˜
        self.session_max_age_hours = 24  # ì„¸ì…˜ ë§Œë£Œ ì‹œê°„
        self.image_quality = 95  # ì´ë¯¸ì§€ ì €ì¥ í’ˆì§ˆ
        self.cleanup_interval_minutes = 30  # ìë™ ì •ë¦¬ ì£¼ê¸°
        
        # Stepê°„ ë°ì´í„° íë¦„ ì„¤ì •
        self.pipeline_flows = {
            flow.target_step: [f for f in PIPELINE_DATA_FLOWS if f.target_step == flow.target_step]
            for flow in PIPELINE_DATA_FLOWS
        }
        
        # ìŠ¤ë ˆë“œ ì•ˆì „ì„±
        self._lock = threading.RLock()
        
        # ë°±ê·¸ë¼ìš´ë“œ ì •ë¦¬ íƒœìŠ¤í¬
        self._cleanup_task: Optional[asyncio.Task] = None
        self._start_cleanup_task()
        
        logger.info(f"âœ… SessionManager ì´ˆê¸°í™” ì™„ë£Œ - ê²½ë¡œ: {self.base_path}")
        logger.info(f"ğŸ“Š Stepê°„ ë°ì´í„° íë¦„: {len(PIPELINE_DATA_FLOWS)}ê°œ ë“±ë¡")

    # =========================================================================
    # ğŸ”¥ ê¸°ì¡´ API ë©”ì„œë“œë“¤ (100% í˜¸í™˜ì„± ìœ ì§€)
    # =========================================================================
    
    async def create_session(self, person_image=None, clothing_image=None, **kwargs):
        session_id = f"session_{int(time.time())}_{uuid.uuid4().hex[:8]}"
        
        session_data = {
            "session_id": session_id,
            "created_at": datetime.now(),
            "last_accessed": datetime.now(),
            "status": "active",
            "step_results": {},
            "ai_metadata": {
                "ai_pipeline_version": "12.0.0",
                "step_implementations_available": STEP_IMPLEMENTATIONS_AVAILABLE,
                "aenter_error_fixed": True
            },
            **kwargs
        }
        
        # ğŸ”§ ì´ë¯¸ì§€ ì €ì¥ (íŒŒì¼ í¬ì¸í„° ìœ„ì¹˜ í™•ì¸)
        if person_image:
            person_path = self.session_dir / f"{session_id}_person.jpg"
            try:
                # íŒŒì¼ í¬ì¸í„°ë¥¼ ì²˜ìŒìœ¼ë¡œ ì´ë™
                if hasattr(person_image.file, 'seek'):
                    person_image.file.seek(0)
                
                with open(person_path, "wb") as f:
                    content = await person_image.read()
                    if len(content) > 0:  # ë‚´ìš©ì´ ìˆëŠ”ì§€ í™•ì¸
                        f.write(content)
                        session_data["person_image_path"] = str(person_path)
                        logger.info(f"âœ… ì‚¬ìš©ì ì´ë¯¸ì§€ ì €ì¥: {len(content)} bytes")
                    else:
                        logger.warning("âš ï¸ ì‚¬ìš©ì ì´ë¯¸ì§€ ë‚´ìš©ì´ ë¹„ì–´ìˆìŒ")
            except Exception as e:
                logger.error(f"âŒ ì‚¬ìš©ì ì´ë¯¸ì§€ ì €ì¥ ì‹¤íŒ¨: {e}")
        
        if clothing_image:
            clothing_path = self.session_dir / f"{session_id}_clothing.jpg"
            try:
                # íŒŒì¼ í¬ì¸í„°ë¥¼ ì²˜ìŒìœ¼ë¡œ ì´ë™
                if hasattr(clothing_image.file, 'seek'):
                    clothing_image.file.seek(0)
                    
                with open(clothing_path, "wb") as f:
                    content = await clothing_image.read()
                    if len(content) > 0:  # ë‚´ìš©ì´ ìˆëŠ”ì§€ í™•ì¸
                        f.write(content)
                        session_data["clothing_image_path"] = str(clothing_path)
                        logger.info(f"âœ… ì˜ë¥˜ ì´ë¯¸ì§€ ì €ì¥: {len(content)} bytes")
                    else:
                        logger.warning("âš ï¸ ì˜ë¥˜ ì´ë¯¸ì§€ ë‚´ìš©ì´ ë¹„ì–´ìˆìŒ")
            except Exception as e:
                logger.error(f"âŒ ì˜ë¥˜ ì´ë¯¸ì§€ ì €ì¥ ì‹¤íŒ¨: {e}")
        
        self.sessions[session_id] = session_data
        return session_id

    async def get_session_images(self, session_id: str) -> Tuple[Image.Image, Image.Image]:
        """
        ğŸ”¥ ì„¸ì…˜ì—ì„œ ì´ë¯¸ì§€ ë¡œë“œ (ê¸°ì¡´ í•¨ìˆ˜ëª… ìœ ì§€)
        
        Args:
            session_id: ì„¸ì…˜ ID
            
        Returns:
            Tuple[Image.Image, Image.Image]: (ì‚¬ìš©ì ì´ë¯¸ì§€, ì˜ë¥˜ ì´ë¯¸ì§€)
        """
        try:
            # 1. ì„¸ì…˜ ë°ì´í„° í™•ì¸
            session_data = self.sessions.get(session_id)
            if not session_data:
                raise ValueError(f"ì„¸ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {session_id}")
            
            # 2. ì ‘ê·¼ ì‹œê°„ ì—…ë°ì´íŠ¸
            session_data.update_access_time()
            
            # 3. ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ
            person_path = session_data.metadata.person_image.path
            clothing_path = session_data.metadata.clothing_image.path
            
            # 4. íŒŒì¼ ì¡´ì¬ í™•ì¸
            if not Path(person_path).exists():
                raise FileNotFoundError(f"ì‚¬ìš©ì ì´ë¯¸ì§€ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {person_path}")
            if not Path(clothing_path).exists():
                raise FileNotFoundError(f"ì˜ë¥˜ ì´ë¯¸ì§€ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {clothing_path}")
            
            # 5. ì´ë¯¸ì§€ ë¡œë“œ (ë¹„ë™ê¸°)
            person_image, clothing_image = await asyncio.gather(
                self._load_image_async(person_path),
                self._load_image_async(clothing_path)
            )
            
            logger.debug(f"ğŸ“‚ ì´ë¯¸ì§€ ë¡œë“œ ì™„ë£Œ: {session_id}")
            return person_image, clothing_image
            
        except Exception as e:
            logger.error(f"âŒ ì„¸ì…˜ ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨ {session_id}: {e}")
            raise
    
    async def save_step_result(
        self, 
        session_id: str, 
        step_id: int,
        result: Dict[str, Any],
        result_image: Optional[Image.Image] = None
    ):
        """
        ğŸ”¥ ë‹¨ê³„ë³„ ê²°ê³¼ ì €ì¥ (ê¸°ì¡´ í•¨ìˆ˜ëª… ìœ ì§€ + Stepê°„ ë°ì´í„° íë¦„ ì§€ì›)
        
        Args:
            session_id: ì„¸ì…˜ ID
            step_id: ë‹¨ê³„ ë²ˆí˜¸ (1-8)
            result: ì²˜ë¦¬ ê²°ê³¼ ë°ì´í„°
            result_image: ê²°ê³¼ ì´ë¯¸ì§€ (ì„ íƒì )
        """
        try:
            session_data = self.sessions.get(session_id)
            if not session_data:
                logger.warning(f"âš ï¸ ì„¸ì…˜ ì—†ìŒ - ê²°ê³¼ ì €ì¥ ê±´ë„ˆëœ€: {session_id}")
                return
            
            session_data.update_access_time()
            
            # 1. ê²°ê³¼ ì´ë¯¸ì§€ ì €ì¥
            if result_image:
                results_dir = session_data.session_dir / "results"
                results_dir.mkdir(exist_ok=True)
                
                result_image_path = results_dir / f"step_{step_id}_result.jpg"
                
                # ë¹„ë™ê¸° ì´ë¯¸ì§€ ì €ì¥
                await self._save_image_async(result_image, result_image_path)
                result["result_image_path"] = str(result_image_path)
                
                # Base64 ì¸ì½”ë”© (í”„ë¡ íŠ¸ì—”ë“œìš©)
                result["result_image_base64"] = await self._image_to_base64(result_image)
                
                # primary_outputìœ¼ë¡œë„ ì €ì¥ (ë°ì´í„° íë¦„ìš©)
                result["primary_output"] = result_image
            
            # 2. ì²˜ë¦¬ ì‹œê°„ ì¶”ê°€
            result["processing_time"] = result.get("processing_time", 0.0)
            result["quality_score"] = result.get("quality_score", 0.0)
            
            # 3. Step ë°ì´í„° ì €ì¥ (ê¸°ì¡´ + ìƒˆë¡œìš´ ë°©ì‹ ëª¨ë‘)
            session_data.save_step_data(step_id, result)
            
            # 4. ë©”íƒ€ë°ì´í„° ì—…ë°ì´íŠ¸
            await self._save_session_metadata(session_data)
            
            logger.info(f"âœ… Step {step_id} ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {session_id}")
            
        except Exception as e:
            logger.error(f"âŒ Step {step_id} ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨ {session_id}: {e}")
    
    async def get_session_status(self, session_id: str) -> Dict[str, Any]:
        """ì„¸ì…˜ ìƒíƒœ ì¡°íšŒ (ê¸°ì¡´ í•¨ìˆ˜ëª… ìœ ì§€ + í™•ì¥ ì •ë³´)"""
        session_data = self.sessions.get(session_id)
        if not session_data:
            raise ValueError(f"ì„¸ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {session_id}")
        
        session_data.update_access_time()
        
        # ê¸°ì¡´ í˜¸í™˜ ì •ë³´
        basic_status = {
            "session_id": session_id,
            "created_at": session_data.metadata.created_at.isoformat(),
            "last_accessed": session_data.metadata.last_accessed.isoformat(),
            "completed_steps": session_data.metadata.completed_steps,
            "total_steps": session_data.metadata.total_steps,
            "progress_percent": session_data.get_progress_percent(),
            "measurements": session_data.metadata.measurements,
            "image_info": {
                "person_size": session_data.metadata.person_image.size,
                "clothing_size": session_data.metadata.clothing_image.size
            },
            "step_results_count": len(session_data.step_results)
        }
        
        # í™•ì¥ ì •ë³´ (Stepê°„ ë°ì´í„° íë¦„)
        extended_status = {
            **basic_status,
            "pipeline_status": self._get_pipeline_status(session_data),
            "step_processing_times": session_data.step_processing_times,
            "step_quality_scores": session_data.step_quality_scores,
            "average_quality": sum(session_data.step_quality_scores.values()) / len(session_data.step_quality_scores) if session_data.step_quality_scores else 0.0,
            "total_processing_time": sum(session_data.step_processing_times.values()),
            "data_flow_status": {
                step_id: {
                    "dependencies_met": session_data.validate_step_dependencies(step_id)['valid'],
                    "data_available": step_id in session_data.step_data_cache
                }
                for step_id in range(1, 9)
            }
        }
        
        return extended_status
    
    def get_all_sessions_status(self) -> Dict[str, Any]:
        """ì „ì²´ ì„¸ì…˜ ìƒíƒœ ì¡°íšŒ (ê¸°ì¡´ í•¨ìˆ˜ëª… ìœ ì§€)"""
        with self._lock:
            basic_info = {
                "total_sessions": len(self.sessions),
                "max_sessions": self.max_sessions,
                "sessions": [
                    {
                        "session_id": sid,
                        "created_at": data.metadata.created_at.isoformat(),
                        "progress": data.get_progress_percent(),
                        "completed_steps": len(data.metadata.completed_steps)
                    }
                    for sid, data in self.sessions.items()
                ]
            }
            
            # í™•ì¥ ì •ë³´ ì¶”ê°€
            extended_info = {
                **basic_info,
                "pipeline_statistics": {
                    "average_processing_time": sum(
                        sum(data.step_processing_times.values()) for data in self.sessions.values()
                    ) / max(1, len(self.sessions)),
                    "average_quality_score": sum(
                        sum(data.step_quality_scores.values()) / max(1, len(data.step_quality_scores))
                        for data in self.sessions.values() if data.step_quality_scores
                    ) / max(1, len([d for d in self.sessions.values() if d.step_quality_scores])),
                    "step_completion_rates": {
                        step_id: len([d for d in self.sessions.values() if step_id in d.metadata.completed_steps]) / max(1, len(self.sessions))
                        for step_id in range(1, 9)
                    }
                }
            }
            
            return extended_info
    
    async def cleanup_expired_sessions(self):
        """ë§Œë£Œëœ ì„¸ì…˜ ìë™ ì •ë¦¬ (ê¸°ì¡´ í•¨ìˆ˜ëª… ìœ ì§€)"""
        try:
            expired_sessions = []
            
            with self._lock:
                for session_id, session_data in list(self.sessions.items()):
                    if session_data.is_expired(self.session_max_age_hours):
                        expired_sessions.append(session_id)
            
            # ë§Œë£Œëœ ì„¸ì…˜ ì •ë¦¬
            for session_id in expired_sessions:
                await self.cleanup_session(session_id)
            
            if expired_sessions:
                logger.info(f"ğŸ§¹ ë§Œë£Œ ì„¸ì…˜ ì •ë¦¬: {len(expired_sessions)}ê°œ")
                
        except Exception as e:
            logger.error(f"âŒ ë§Œë£Œ ì„¸ì…˜ ì •ë¦¬ ì‹¤íŒ¨: {e}")
    
    async def cleanup_all_sessions(self):
        """ëª¨ë“  ì„¸ì…˜ ì •ë¦¬ (ê¸°ì¡´ í•¨ìˆ˜ëª… ìœ ì§€)"""
        try:
            session_ids = list(self.sessions.keys())
            
            for session_id in session_ids:
                await self.cleanup_session(session_id)
            
            # ì „ì²´ ì„¸ì…˜ ë””ë ‰í† ë¦¬ ì •ë¦¬
            if self.base_path.exists():
                for session_dir in self.base_path.iterdir():
                    if session_dir.is_dir():
                        try:
                            shutil.rmtree(session_dir)
                        except:
                            pass
            
            logger.info(f"ğŸ§¹ ì „ì²´ ì„¸ì…˜ ì •ë¦¬ ì™„ë£Œ: {len(session_ids)}ê°œ")
            
        except Exception as e:
            logger.error(f"âŒ ì „ì²´ ì„¸ì…˜ ì •ë¦¬ ì‹¤íŒ¨: {e}")

    # =========================================================================
    # ğŸ”¥ ìƒˆë¡œ ì¶”ê°€ - Stepê°„ ë°ì´í„° íë¦„ ì „ìš© ë©”ì„œë“œë“¤
    # =========================================================================
    
    async def validate_step_dependencies(self, session_id: str, step_id: int) -> Dict[str, Any]:
        """Step ì˜ì¡´ì„± ê²€ì¦"""
        try:
            session_data = self.sessions.get(session_id)
            if not session_data:
                raise ValueError(f"ì„¸ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {session_id}")
            
            return session_data.validate_step_dependencies(step_id)
            
        except Exception as e:
            logger.error(f"ì˜ì¡´ì„± ê²€ì¦ ì‹¤íŒ¨: {e}")
            return {'valid': False, 'missing': [str(e)], 'required_steps': []}
    
    async def prepare_step_input_data(self, session_id: str, step_id: int) -> Dict[str, Any]:
        """Step ì…ë ¥ ë°ì´í„° ì¤€ë¹„"""
        try:
            session_data = self.sessions.get(session_id)
            if not session_data:
                raise ValueError(f"ì„¸ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {session_id}")
            
            session_data.update_access_time()
            
            # ê¸°ë³¸ ì…ë ¥ ë°ì´í„°
            input_data = session_data.prepare_step_input_data(step_id)
            
            # ì›ë³¸ ì´ë¯¸ì§€ ì¶”ê°€
            if 0 in session_data.step_data_cache:
                base_data = session_data.step_data_cache[0]
                input_data['person_image'] = base_data.get('person_image')
                input_data['clothing_image'] = base_data.get('clothing_image')
            
            return input_data
            
        except Exception as e:
            logger.error(f"ì…ë ¥ ë°ì´í„° ì¤€ë¹„ ì‹¤íŒ¨: {e}")
            raise
    
    async def get_pipeline_progress(self, session_id: str) -> Dict[str, Any]:
        """íŒŒì´í”„ë¼ì¸ ì§„í–‰ë¥  ìƒì„¸ ì¡°íšŒ"""
        try:
            session_data = self.sessions.get(session_id)
            if not session_data:
                raise ValueError(f"ì„¸ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {session_id}")
            
            session_data.update_access_time()
            
            total_steps = 8
            completed_steps = len(session_data.metadata.completed_steps)
            progress_percent = (completed_steps / total_steps) * 100
            
            # í˜„ì¬ ì²˜ë¦¬ ê°€ëŠ¥í•œ Step
            next_available_step = None
            for step_id in range(1, 9):
                if step_id not in session_data.metadata.completed_steps:
                    dependencies = session_data.validate_step_dependencies(step_id)
                    if dependencies['valid']:
                        next_available_step = step_id
                        break
            
            return {
                'session_id': session_id,
                'progress_percent': progress_percent,
                'total_steps': total_steps,
                'completed_steps': completed_steps,
                'completed_step_ids': session_data.metadata.completed_steps,
                'next_available_step': next_available_step,
                'total_processing_time': sum(session_data.step_processing_times.values()),
                'average_quality_score': sum(session_data.step_quality_scores.values()) / len(session_data.step_quality_scores) if session_data.step_quality_scores else 0.0,
                'pipeline_status': self._get_pipeline_status(session_data),
                'step_details': {
                    step_id: {
                        'completed': step_id in session_data.metadata.completed_steps,
                        'processing_time': session_data.step_processing_times.get(step_id, 0.0),
                        'quality_score': session_data.step_quality_scores.get(step_id, 0.0),
                        'dependencies_met': session_data.validate_step_dependencies(step_id)['valid'],
                        'data_available': step_id in session_data.step_data_cache
                    }
                    for step_id in range(1, 9)
                }
            }
            
        except Exception as e:
            logger.error(f"ì§„í–‰ë¥  ì¡°íšŒ ì‹¤íŒ¨: {e}")
            raise

    # =========================================================================
    # ğŸ”§ ë‚´ë¶€ ìœ í‹¸ë¦¬í‹° ë©”ì„œë“œë“¤
    # =========================================================================
    
    def _get_pipeline_status(self, session_data: SessionData) -> str:
        """íŒŒì´í”„ë¼ì¸ ì „ì²´ ìƒíƒœ íŒë‹¨"""
        completed_count = len(session_data.metadata.completed_steps)
        
        if completed_count == 0:
            return "not_started"
        elif completed_count == 8:
            return "completed"
        elif any(step_id in session_data.step_results and 
                session_data.step_results[step_id].get('error') 
                for step_id in session_data.metadata.completed_steps):
            return "failed"
        else:
            return "in_progress"

    async def cleanup_session(self, session_id: str):
        """íŠ¹ì • ì„¸ì…˜ ì •ë¦¬ (ê¸°ì¡´ í˜¸í™˜)"""
        try:
            with self._lock:
                session_data = self.sessions.pop(session_id, None)
            
            if session_data:
                # ë””ë ‰í† ë¦¬ ì‚­ì œ
                if session_data.session_dir.exists():
                    shutil.rmtree(session_data.session_dir)
                
                logger.info(f"ğŸ§¹ ì„¸ì…˜ ì •ë¦¬ ì™„ë£Œ: {session_id}")
            else:
                logger.warning(f"âš ï¸ ì •ë¦¬í•  ì„¸ì…˜ ì—†ìŒ: {session_id}")
                
        except Exception as e:
            logger.error(f"âŒ ì„¸ì…˜ ì •ë¦¬ ì‹¤íŒ¨ {session_id}: {e}")
    
    def _generate_session_id(self) -> str:
        """ê³ ìœ í•œ ì„¸ì…˜ ID ìƒì„±"""
        timestamp = int(time.time())
        random_part = uuid.uuid4().hex[:8]
        return f"session_{timestamp}_{random_part}"
    
    async def _save_image(self, image: Image.Image, path: Path, image_type: str) -> ImageInfo:
        """ì´ë¯¸ì§€ ì €ì¥ ë° ì •ë³´ ìƒì„±"""
        try:
            # ì´ë¯¸ì§€ ìµœì í™”
            if image.mode != 'RGB':
                image = image.convert('RGB')
            
            # íŒŒì¼ ì €ì¥
            image.save(path, "JPEG", quality=self.image_quality, optimize=True)
            
            # íŒŒì¼ í¬ê¸° í™•ì¸
            file_size = path.stat().st_size
            
            # ì´ë¯¸ì§€ ì •ë³´ ìƒì„±
            return ImageInfo(
                path=str(path),
                size=image.size,
                mode=image.mode,
                format="JPEG",
                file_size=file_size
            )
            
        except Exception as e:
            logger.error(f"âŒ {image_type} ì´ë¯¸ì§€ ì €ì¥ ì‹¤íŒ¨: {e}")
            raise
    
    async def _save_image_async(self, image: Image.Image, path: Path):
        """ë¹„ë™ê¸° ì´ë¯¸ì§€ ì €ì¥"""
        def save_sync():
            if image.mode != 'RGB':
                image = image.convert('RGB')
            image.save(path, "JPEG", quality=self.image_quality, optimize=True)
        
        # CPU ì§‘ì•½ì  ì‘ì—…ì„ ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰
        loop = asyncio.get_event_loop()
        await loop.run_in_executor(None, save_sync)
    
    async def _load_image_async(self, path: str) -> Image.Image:
        """ë¹„ë™ê¸° ì´ë¯¸ì§€ ë¡œë“œ"""
        def load_sync():
            return Image.open(path)
        
        loop = asyncio.get_event_loop()
        return await loop.run_in_executor(None, load_sync)
    
    async def _image_to_base64(self, image: Image.Image) -> str:
        """ì´ë¯¸ì§€ë¥¼ Base64ë¡œ ë³€í™˜"""
        from io import BytesIO
        import base64
        
        def convert_sync():
            buffer = BytesIO()
            if image.mode != 'RGB':
                image = image.convert('RGB')
            image.save(buffer, format='JPEG', quality=85, optimize=True)
            return base64.b64encode(buffer.getvalue()).decode('utf-8')
        
        loop = asyncio.get_event_loop()
        return await loop.run_in_executor(None, convert_sync)
    
    async def _save_session_metadata(self, session_data: SessionData):
        """ì„¸ì…˜ ë©”íƒ€ë°ì´í„° ì €ì¥"""
        try:
            metadata_path = session_data.session_dir / "session_metadata.json"
            
            # ì „ì²´ ì„¸ì…˜ ë°ì´í„° (ë©”íƒ€ë°ì´í„° + ë‹¨ê³„ë³„ ê²°ê³¼)
            full_data = {
                "metadata": session_data.metadata.to_dict(),
                "step_results": {
                    str(k): v for k, v in session_data.step_results.items()
                },
                "step_processing_times": session_data.step_processing_times,
                "step_quality_scores": session_data.step_quality_scores,
                "last_saved": datetime.now().isoformat()
            }
            
            # ë¹„ë™ê¸° íŒŒì¼ ì“°ê¸°
            async with aiofiles.open(metadata_path, 'w', encoding='utf-8') as f:
                await f.write(json.dumps(full_data, indent=2, ensure_ascii=False))
                
        except Exception as e:
            logger.error(f"âŒ ì„¸ì…˜ ë©”íƒ€ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {e}")
    
    async def _enforce_session_limit(self):
        """ì„¸ì…˜ ìˆ˜ ì œí•œ ê°•ì œ"""
        try:
            if len(self.sessions) <= self.max_sessions:
                return
            
            # ê°€ì¥ ì˜¤ë˜ëœ ì„¸ì…˜ë¶€í„° ì •ë¦¬
            with self._lock:
                sorted_sessions = sorted(
                    self.sessions.items(),
                    key=lambda x: x[1].metadata.last_accessed
                )
                
                sessions_to_remove = sorted_sessions[:len(self.sessions) - self.max_sessions]
            
            for session_id, _ in sessions_to_remove:
                await self.cleanup_session(session_id)
            
            logger.info(f"ğŸ§¹ ì„¸ì…˜ ìˆ˜ ì œí•œ: {len(sessions_to_remove)}ê°œ ì„¸ì…˜ ì •ë¦¬")
            
        except Exception as e:
            logger.error(f"âŒ ì„¸ì…˜ ìˆ˜ ì œí•œ ê°•ì œ ì‹¤íŒ¨: {e}")
    
    def _start_cleanup_task(self):
        """ë°±ê·¸ë¼ìš´ë“œ ì •ë¦¬ íƒœìŠ¤í¬ ì‹œì‘"""
        async def cleanup_loop():
            while True:
                try:
                    await asyncio.sleep(self.cleanup_interval_minutes * 60)
                    await self.cleanup_expired_sessions()
                    await self._enforce_session_limit()
                except asyncio.CancelledError:
                    break
                except Exception as e:
                    logger.error(f"âŒ ë°±ê·¸ë¼ìš´ë“œ ì •ë¦¬ ì˜¤ë¥˜: {e}")
        
        # ë°±ê·¸ë¼ìš´ë“œ íƒœìŠ¤í¬ ì‹œì‘
        try:
            loop = asyncio.get_running_loop()
            self._cleanup_task = loop.create_task(cleanup_loop())
            logger.info("ğŸ”„ ë°±ê·¸ë¼ìš´ë“œ ì„¸ì…˜ ì •ë¦¬ íƒœìŠ¤í¬ ì‹œì‘")
        except RuntimeError:
            # ì´ë²¤íŠ¸ ë£¨í”„ê°€ ì—†ëŠ” ê²½ìš° (í…ŒìŠ¤íŠ¸ ë“±)
            logger.warning("âš ï¸ ì´ë²¤íŠ¸ ë£¨í”„ ì—†ìŒ - ë°±ê·¸ë¼ìš´ë“œ ì •ë¦¬ ë¹„í™œì„±í™”")
    
    def stop_cleanup_task(self):
        """ë°±ê·¸ë¼ìš´ë“œ ì •ë¦¬ íƒœìŠ¤í¬ ì¤‘ì§€"""
        if self._cleanup_task and not self._cleanup_task.cancelled():
            self._cleanup_task.cancel()
            logger.info("ğŸ›‘ ë°±ê·¸ë¼ìš´ë“œ ì„¸ì…˜ ì •ë¦¬ íƒœìŠ¤í¬ ì¤‘ì§€")

# =============================================================================
# ğŸŒ ì „ì—­ ì„¸ì…˜ ë§¤ë‹ˆì € (ì‹±ê¸€í†¤) - ê¸°ì¡´ í˜¸í™˜
# =============================================================================

_session_manager_instance: Optional[SessionManager] = None
_manager_lock = threading.Lock()

def get_session_manager() -> SessionManager:
    """ì „ì—­ ì„¸ì…˜ ë§¤ë‹ˆì € ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜ (ê¸°ì¡´ í•¨ìˆ˜ëª… ìœ ì§€)"""
    global _session_manager_instance
    
    if _session_manager_instance is None:
        with _manager_lock:
            if _session_manager_instance is None:
                _session_manager_instance = SessionManager()
                logger.info("âœ… ì „ì—­ SessionManager ì¸ìŠ¤í„´ìŠ¤ ìƒì„±")
    
    return _session_manager_instance

async def cleanup_global_session_manager():
    """ì „ì—­ ì„¸ì…˜ ë§¤ë‹ˆì € ì •ë¦¬ (ê¸°ì¡´ í•¨ìˆ˜ëª… ìœ ì§€)"""
    global _session_manager_instance
    
    if _session_manager_instance:
        _session_manager_instance.stop_cleanup_task()
        await _session_manager_instance.cleanup_all_sessions()
        _session_manager_instance = None
        logger.info("ğŸ§¹ ì „ì—­ SessionManager ì •ë¦¬ ì™„ë£Œ")

# cleanup_session_manager í•¨ìˆ˜ ì¶”ê°€ (ê¸°ì¡´ í˜¸í™˜)
async def cleanup_session_manager():
    await cleanup_global_session_manager()

# =============================================================================
# ğŸ§ª í…ŒìŠ¤íŠ¸ ë° ë””ë²„ê¹… í•¨ìˆ˜ë“¤ (ê¸°ì¡´ í˜¸í™˜)
# =============================================================================

async def test_session_manager():
    """ì„¸ì…˜ ë§¤ë‹ˆì € í…ŒìŠ¤íŠ¸ (ê¸°ì¡´ í˜¸í™˜ + Stepê°„ ë°ì´í„° íë¦„)"""
    try:
        logger.info("ğŸ§ª SessionManager ì™„ì „ í…ŒìŠ¤íŠ¸ ì‹œì‘")
        
        # í…ŒìŠ¤íŠ¸ìš© ì´ë¯¸ì§€ ìƒì„±
        from PIL import Image
        test_person = Image.new('RGB', (512, 512), color=(100, 150, 200))
        test_clothing = Image.new('RGB', (512, 512), color=(200, 100, 100))
        
        # ì„¸ì…˜ ë§¤ë‹ˆì € ìƒì„±
        manager = SessionManager()
        
        # 1. ì„¸ì…˜ ìƒì„± í…ŒìŠ¤íŠ¸ (ê¸°ì¡´ í˜¸í™˜)
        session_id = await manager.create_session(
            person_image=test_person, 
            clothing_image=test_clothing,
            measurements={"height": 170, "weight": 65}
        )
        logger.info(f"âœ… í…ŒìŠ¤íŠ¸ ì„¸ì…˜ ìƒì„±: {session_id}")
        
        # 2. ì´ë¯¸ì§€ ë¡œë“œ í…ŒìŠ¤íŠ¸ (ê¸°ì¡´ í˜¸í™˜)
        person_img, clothing_img = await manager.get_session_images(session_id)
        logger.info(f"âœ… ì´ë¯¸ì§€ ë¡œë“œ í…ŒìŠ¤íŠ¸: {person_img.size}, {clothing_img.size}")
        
        # 3. Step 1 ê²°ê³¼ ì €ì¥ í…ŒìŠ¤íŠ¸ (ê¸°ì¡´ í˜¸í™˜)
        await manager.save_step_result(
            session_id, 
            1, 
            {
                "success": True, 
                "test": True,
                "segmentation_mask": np.random.randint(0, 20, (512, 512)),
                "primary_output": test_person,
                "processing_time": 1.2,
                "quality_score": 0.85
            },
            test_person
        )
        logger.info("âœ… Step 1 ê²°ê³¼ ì €ì¥ í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
        
        # 4. Step 2 ì˜ì¡´ì„± ê²€ì¦ í…ŒìŠ¤íŠ¸ (ìƒˆë¡œìš´ ê¸°ëŠ¥)
        dependencies = await manager.validate_step_dependencies(session_id, 2)
        logger.info(f"âœ… Step 2 ì˜ì¡´ì„± ê²€ì¦: {dependencies['valid']}")
        
        # 5. Step 2 ì…ë ¥ ë°ì´í„° ì¤€ë¹„ í…ŒìŠ¤íŠ¸ (ìƒˆë¡œìš´ ê¸°ëŠ¥)
        input_data = await manager.prepare_step_input_data(session_id, 2)
        logger.info(f"âœ… Step 2 ì…ë ¥ ë°ì´í„° ì¤€ë¹„: {len(input_data)}ê°œ í•­ëª©")
        
        # 6. íŒŒì´í”„ë¼ì¸ ì§„í–‰ë¥  í…ŒìŠ¤íŠ¸ (ìƒˆë¡œìš´ ê¸°ëŠ¥)
        progress = await manager.get_pipeline_progress(session_id)
        logger.info(f"âœ… íŒŒì´í”„ë¼ì¸ ì§„í–‰ë¥ : {progress['progress_percent']:.1f}%")
        
        # 7. ì„¸ì…˜ ìƒíƒœ ì¡°íšŒ í…ŒìŠ¤íŠ¸ (ê¸°ì¡´ í˜¸í™˜ + í™•ì¥)
        status = await manager.get_session_status(session_id)
        logger.info(f"âœ… ì„¸ì…˜ ìƒíƒœ: {status['progress_percent']:.1f}% (í™•ì¥ ì •ë³´ í¬í•¨)")
        
        # 8. ì •ë¦¬ í…ŒìŠ¤íŠ¸ (ê¸°ì¡´ í˜¸í™˜)
        await manager.cleanup_session(session_id)
        logger.info("âœ… ì„¸ì…˜ ì •ë¦¬ í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
        
        logger.info("ğŸ‰ SessionManager ì™„ì „ í…ŒìŠ¤íŠ¸ ëª¨ë‘ í†µê³¼!")
        logger.info("âœ… ê¸°ì¡´ API 100% í˜¸í™˜")
        logger.info("âœ… Stepê°„ ë°ì´í„° íë¦„ ì™„ë²½ ì§€ì›")
        return True
        
    except Exception as e:
        logger.error(f"âŒ SessionManager í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        return False

if __name__ == "__main__":
    # ì§ì ‘ ì‹¤í–‰ ì‹œ í…ŒìŠ¤íŠ¸
    import asyncio
    
    logging.basicConfig(level=logging.INFO)
    asyncio.run(test_session_manager())

# =============================================================================
# ğŸ‰ EXPORT (ê¸°ì¡´ í˜¸í™˜ + ìƒˆë¡œìš´ ê¸°ëŠ¥)
# =============================================================================

__all__ = [
    # ê¸°ì¡´ í˜¸í™˜ í´ë˜ìŠ¤ë“¤
    "SessionManager",
    "SessionData", 
    "SessionMetadata",
    "ImageInfo",
    
    # ê¸°ì¡´ í˜¸í™˜ í•¨ìˆ˜ë“¤
    "get_session_manager",
    "cleanup_global_session_manager",
    "cleanup_session_manager",
    "test_session_manager",
    
    # ìƒˆë¡œ ì¶”ê°€ëœ í´ë˜ìŠ¤ë“¤
    "StepStatus",
    "DataType", 
    "StepDataFlow",
    
    # ìƒˆë¡œ ì¶”ê°€ëœ ë°ì´í„°
    "PIPELINE_DATA_FLOWS"
]

logger.info("ğŸ‰ ì™„ì „í•œ SessionManager ëª¨ë“ˆ ë¡œë“œ ì™„ë£Œ!")
logger.info("âœ… ê¸°ì¡´ í•¨ìˆ˜ëª… 100% ìœ ì§€ (create_session, get_session_images, save_step_result ë“±)")
logger.info("âœ… Stepê°„ ë°ì´í„° íë¦„ ì™„ë²½ ì§€ì›")
logger.info("âœ… ì˜ì¡´ì„± ê²€ì¦ ë° ìˆœì„œ ë³´ì¥") 
logger.info("âœ… ì‹¤ì‹œê°„ ì§„í–‰ë¥  ì¶”ì ")
logger.info("âœ… ë©”ëª¨ë¦¬ íš¨ìœ¨ì  ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬")
logger.info("ğŸ”¥ ì´ë¯¸ì§€ ì¬ì—…ë¡œë“œ ë¬¸ì œ ì™„ì „ í•´ê²° + Stepê°„ ë°ì´í„° ì²˜ë¦¬ ì™„ë²½!")