"""
MyCloset AI Backend - ì•ˆì „í•œ ì‹¤í–‰ ë²„ì „
PyTorch segfault ë°©ì§€ë¥¼ ìœ„í•œ ì•ˆì „í•œ ì‹œì‘ì 
"""

import sys
import os
import logging
from pathlib import Path

# ì•ˆì „ í™˜ê²½ë³€ìˆ˜ ì„¤ì •
os.environ['OMP_NUM_THREADS'] = '1'
os.environ['MKL_NUM_THREADS'] = '1'
os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '1'

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from datetime import datetime
import platform

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# FastAPI ì•± ìƒì„±
app = FastAPI(
    title="MyCloset AI Backend (Safe Mode)",
    description="ì•ˆì „ ëª¨ë“œë¡œ ì‹¤í–‰ë˜ëŠ” AI ê°€ìƒ í”¼íŒ… ì‹œìŠ¤í…œ",
    version="1.0.0-safe"
)

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3000", "http://localhost:5173"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# PyTorch ì•ˆì „ ë¡œë“œ í•¨ìˆ˜
def safe_load_pytorch():
    """PyTorchë¥¼ ì•ˆì „í•˜ê²Œ ë¡œë“œ"""
    try:
        import torch
        logger.info(f"âœ… PyTorch ë¡œë“œ ì„±ê³µ: {torch.__version__}")
        
        # ë””ë°”ì´ìŠ¤ í™•ì¸ (ì•ˆì „ëª¨ë“œ)
        device = "cpu"  # ì•ˆì •ì„±ì„ ìœ„í•´ CPU ê°•ì œ ì‚¬ìš©
        
        return {
            "available": True,
            "version": torch.__version__,
            "device": device,
            "mode": "safe_cpu"
        }
    except Exception as e:
        logger.warning(f"âš ï¸ PyTorch ë¡œë“œ ì‹¤íŒ¨: {e}")
        return {
            "available": False,
            "error": str(e),
            "device": "none",
            "mode": "no_pytorch"
        }

# ì‹œì‘ì‹œ PyTorch ìƒíƒœ í™•ì¸
pytorch_status = safe_load_pytorch()

@app.get("/")
async def root():
    return {
        "message": "MyCloset AI Backend (Safe Mode) ğŸ›¡ï¸",
        "version": "1.0.0-safe",
        "status": "running",
        "environment": {
            "conda_env": os.getenv("CONDA_DEFAULT_ENV", "unknown"),
            "python_version": platform.python_version(),
            "platform": platform.system(),
            "architecture": platform.machine()
        },
        "pytorch": pytorch_status,
        "docs": "/docs",
        "health": "/api/health"
    }

@app.get("/api/health")
async def health_check():
    """ìƒì„¸ í—¬ìŠ¤ì²´í¬"""
    
    # í™˜ê²½ë³€ìˆ˜ í™•ì¸
    env_vars = {
        "OMP_NUM_THREADS": os.getenv("OMP_NUM_THREADS"),
        "MKL_NUM_THREADS": os.getenv("MKL_NUM_THREADS"),
        "PYTORCH_ENABLE_MPS_FALLBACK": os.getenv("PYTORCH_ENABLE_MPS_FALLBACK")
    }
    
    return {
        "status": "healthy",
        "timestamp": datetime.now().isoformat(),
        "mode": "safe",
        "pytorch": pytorch_status,
        "environment_variables": env_vars,
        "system": {
            "platform": platform.platform(),
            "python": platform.python_version(),
            "conda_env": os.getenv("CONDA_DEFAULT_ENV")
        }
    }

@app.get("/api/test-pytorch")
async def test_pytorch():
    """PyTorch í…ŒìŠ¤íŠ¸ ì—”ë“œí¬ì¸íŠ¸"""
    
    if not pytorch_status["available"]:
        raise HTTPException(
            status_code=503, 
            detail="PyTorchë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤"
        )
    
    try:
        import torch
        
        # ê°„ë‹¨í•œ í…ì„œ ì—°ì‚° í…ŒìŠ¤íŠ¸
        x = torch.tensor([1.0, 2.0, 3.0])
        y = x * 2
        
        return {
            "status": "success",
            "test_tensor": x.tolist(),
            "result": y.tolist(),
            "device": pytorch_status["device"],
            "message": "PyTorchê°€ ì •ìƒì ìœ¼ë¡œ ì‘ë™í•©ë‹ˆë‹¤"
        }
        
    except Exception as e:
        logger.error(f"PyTorch í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"PyTorch í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(e)}"
        )

@app.on_event("startup")
async def startup_event():
    logger.info("ğŸš€ MyCloset AI Backend (Safe Mode) ì‹œì‘ë¨")
    logger.info(f"ğŸ Conda í™˜ê²½: {os.getenv('CONDA_DEFAULT_ENV', 'unknown')}")
    logger.info(f"ğŸ”¥ PyTorch: {'ì‚¬ìš© ê°€ëŠ¥' if pytorch_status['available'] else 'ì‚¬ìš© ë¶ˆê°€'}")

if __name__ == "__main__":
    import uvicorn
    print("ğŸ›¡ï¸ ì•ˆì „ ëª¨ë“œë¡œ ì„œë²„ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")
    uvicorn.run(app, host="0.0.0.0", port=8000, reload=True)
