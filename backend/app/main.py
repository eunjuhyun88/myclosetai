"""
ê°œì„ ëœ ì™„ì „í•œ 8ë‹¨ê³„ ê°€ìƒ í”¼íŒ… íŒŒì´í”„ë¼ì¸
ê¸°ì¡´ app/ai_pipeline êµ¬ì¡°ë¥¼ ì™„ì „íˆ í™œìš©í•˜ë©´ì„œ í”„ë¡œë•ì…˜ ë ˆë²¨ ê¸°ëŠ¥ ì œê³µ
M3 Max ìµœì í™”, ìƒì„¸í•œ í’ˆì§ˆ ë¶„ì„, ì—ëŸ¬ ë³µêµ¬, ë©”ëª¨ë¦¬ ìµœì í™” í¬í•¨
"""
import os
import sys
import logging
import asyncio
import time
import traceback
from pathlib import Path
from typing import Dict, Any, Optional, Callable, Union, List, Tuple
import numpy as np
import torch
import torch.nn.functional as F
from PIL import Image, ImageEnhance, ImageFilter
import json
import gc
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor

# ê¸°ì¡´ ai_pipeline êµ¬ì¡°ì˜ step íŒŒì¼ë“¤ import
from app.ai_pipeline.steps.step_01_human_parsing import HumanParsingStep
from app.ai_pipeline.steps.step_02_pose_estimation import PoseEstimationStep
from app.ai_pipeline.steps.step_03_cloth_segmentation import ClothSegmentationStep
from app.ai_pipeline.steps.step_04_geometric_matching import GeometricMatchingStep
from app.ai_pipeline.steps.step_05_cloth_warping import ClothWarpingStep
from app.ai_pipeline.steps.step_06_virtual_fitting import VirtualFittingStep
from app.ai_pipeline.steps.step_07_post_processing import PostProcessingStep
from app.ai_pipeline.steps.step_08_quality_assessment import QualityAssessmentStep

# ê¸°ì¡´ ìœ í‹¸ë¦¬í‹°ë“¤ import
from app.ai_pipeline.utils.model_loader import ModelLoader
from app.ai_pipeline.utils.memory_manager import MemoryManager
from app.ai_pipeline.utils.data_converter import DataConverter

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('virtual_fitting_pipeline.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class PipelineManager:
    """
    ê°œì„ ëœ ì™„ì „í•œ 8ë‹¨ê³„ ê°€ìƒ í”¼íŒ… íŒŒì´í”„ë¼ì¸
    - ê¸°ì¡´ ai_pipeline êµ¬ì¡° ì™„ì „ í˜¸í™˜
    - í”„ë¡œë•ì…˜ ë ˆë²¨ í’ˆì§ˆê³¼ ì•ˆì •ì„±
    - M3 Max MPS ìµœì í™”
    - ìƒì„¸í•œ í’ˆì§ˆ ë¶„ì„ ë° ê°œì„  ì œì•ˆ
    - ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± ë° ì—ëŸ¬ ë³µêµ¬
    """
    
    def __init__(self, config_path: Optional[str] = None, device: Optional[str] = None):
        """
        íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™”
        
        Args:
            config_path: ì„¤ì • íŒŒì¼ ê²½ë¡œ (ì„ íƒì )
            device: ì‚¬ìš©í•  ë””ë°”ì´ìŠ¤ ('auto', 'cpu', 'cuda', 'mps')
        """
        # ê¸°ì¡´ ìœ í‹¸ë¦¬í‹°ë“¤ ì´ˆê¸°í™”
        self.model_loader = ModelLoader()
        self.memory_manager = MemoryManager()
        self.data_converter = DataConverter()
        
        # ë””ë°”ì´ìŠ¤ ìµœì í™”
        self.device = device or self._get_optimal_device()
        self._configure_device_optimizations()
        
        # ì„¤ì • ë¡œë“œ
        self.config = self._load_config(config_path)
        
        # íŒŒì´í”„ë¼ì¸ ì„¤ì •
        self.pipeline_config = self.config.get('pipeline', {
            'quality_level': 'high',  # low, medium, high, ultra
            'processing_mode': 'complete',  # fast, balanced, complete
            'enable_optimization': True,
            'enable_caching': True,
            'parallel_processing': True,
            'memory_optimization': True,
            'enable_intermediate_saving': False,
            'max_retries': 3,
            'timeout_seconds': 300
        })
        
        # 8ë‹¨ê³„ ì»´í¬ë„ŒíŠ¸
        self.steps = {}
        self.step_order = [
            'human_parsing',           # 1ë‹¨ê³„: ì¸ì²´ íŒŒì‹±
            'pose_estimation',         # 2ë‹¨ê³„: í¬ì¦ˆ ì¶”ì •
            'cloth_segmentation',      # 3ë‹¨ê³„: ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜
            'geometric_matching',      # 4ë‹¨ê³„: ê¸°í•˜í•™ì  ë§¤ì¹­
            'cloth_warping',          # 5ë‹¨ê³„: ì˜· ì›Œí•‘
            'virtual_fitting',        # 6ë‹¨ê³„: ê°€ìƒ í”¼íŒ… ìƒì„±
            'post_processing',        # 7ë‹¨ê³„: í›„ì²˜ë¦¬
            'quality_assessment'      # 8ë‹¨ê³„: í’ˆì§ˆ í‰ê°€
        ]
        
        # ìƒíƒœ ê´€ë¦¬
        self.is_initialized = False
        self.processing_stats = {}
        self.session_data = {}
        self.error_history = []
        
        # ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
        self.performance_metrics = {
            'total_sessions': 0,
            'successful_sessions': 0,
            'average_processing_time': 0.0,
            'average_quality_score': 0.0
        }
        
        # ìŠ¤ë ˆë“œ í’€ (ë³‘ë ¬ ì²˜ë¦¬ìš©)
        self.thread_pool = ThreadPoolExecutor(max_workers=4)
        
        logger.info(f"ğŸš€ ê°œì„ ëœ ê°€ìƒ í”¼íŒ… íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” - ë””ë°”ì´ìŠ¤: {self.device}")
        logger.info(f"ğŸ“Š íŒŒì´í”„ë¼ì¸ ëª¨ë“œ: {self.pipeline_config['processing_mode']}")
        logger.info(f"ğŸ¯ í’ˆì§ˆ ë ˆë²¨: {self.pipeline_config['quality_level']}")
    
    def _get_optimal_device(self) -> str:
        """ìµœì  ë””ë°”ì´ìŠ¤ ìë™ ì„ íƒ"""
        if torch.backends.mps.is_available():
            # M3 Max MPS ìš°ì„ 
            return 'mps'
        elif torch.cuda.is_available():
            # CUDA ì§€ì›
            return 'cuda'
        else:
            # CPU í´ë°±
            return 'cpu'
    
    def _configure_device_optimizations(self):
        """ë””ë°”ì´ìŠ¤ë³„ ìµœì í™” ì„¤ì •"""
        if self.device == 'mps':
            # M3 Max MPS ìµœì í™”
            os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '1'
            torch.backends.mps.empty_cache()
            logger.info("ğŸ”§ M3 Max MPS ìµœì í™” ì„¤ì • ì™„ë£Œ")
            
        elif self.device == 'cuda':
            # CUDA ìµœì í™”
            torch.backends.cudnn.benchmark = True
            torch.backends.cudnn.deterministic = False
            logger.info("ğŸ”§ CUDA ìµœì í™” ì„¤ì • ì™„ë£Œ")
        
        # í˜¼í•© ì •ë°€ë„ ì„¤ì •
        if self.device in ['cuda', 'mps']:
            self.use_amp = True
            logger.info("âš¡ í˜¼í•© ì •ë°€ë„ ì—°ì‚° í™œì„±í™”")
        else:
            self.use_amp = False
    
    async def initialize(self) -> bool:
        """ì „ì²´ íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™”"""
        try:
            logger.info("ğŸ”„ ê°œì„ ëœ 8ë‹¨ê³„ ê°€ìƒ í”¼íŒ… íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” ì‹œì‘...")
            start_time = time.time()
            
            # ë©”ëª¨ë¦¬ ì •ë¦¬
            self._cleanup_memory()
            
            # ê° ë‹¨ê³„ ìˆœì°¨ì  ì´ˆê¸°í™”
            await self._initialize_all_steps()
            
            # ì´ˆê¸°í™” ê²€ì¦
            initialization_success = await self._verify_initialization()
            
            if not initialization_success:
                raise RuntimeError("ì¼ë¶€ ë‹¨ê³„ ì´ˆê¸°í™” ì‹¤íŒ¨")
            
            initialization_time = time.time() - start_time
            self.processing_stats['initialization_time'] = initialization_time
            
            self.is_initialized = True
            logger.info(f"âœ… ì „ì²´ íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” ì™„ë£Œ - ì†Œìš”ì‹œê°„: {initialization_time:.2f}ì´ˆ")
            
            # ì‹œìŠ¤í…œ ìƒíƒœ ì¶œë ¥
            await self._print_system_status()
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            logger.error(f"ğŸ“‹ ì˜¤ë¥˜ ìƒì„¸: {traceback.format_exc()}")
            self.is_initialized = False
            return False
    
    async def _initialize_all_steps(self):
        """ëª¨ë“  ë‹¨ê³„ ì´ˆê¸°í™”"""
        
        # 1ë‹¨ê³„: ì¸ì²´ íŒŒì‹±
        logger.info("1ï¸âƒ£ ì¸ì²´ íŒŒì‹± ì´ˆê¸°í™”...")
        self.steps['human_parsing'] = HumanParsingStep()
        await self._safe_initialize_step('human_parsing')
        
        # 2ë‹¨ê³„: í¬ì¦ˆ ì¶”ì •
        logger.info("2ï¸âƒ£ í¬ì¦ˆ ì¶”ì • ì´ˆê¸°í™”...")
        self.steps['pose_estimation'] = PoseEstimationStep()
        await self._safe_initialize_step('pose_estimation')
        
        # 3ë‹¨ê³„: ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜
        logger.info("3ï¸âƒ£ ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ ì´ˆê¸°í™”...")
        self.steps['cloth_segmentation'] = ClothSegmentationStep()
        await self._safe_initialize_step('cloth_segmentation')
        
        # 4ë‹¨ê³„: ê¸°í•˜í•™ì  ë§¤ì¹­
        logger.info("4ï¸âƒ£ ê¸°í•˜í•™ì  ë§¤ì¹­ ì´ˆê¸°í™”...")
        self.steps['geometric_matching'] = GeometricMatchingStep()
        await self._safe_initialize_step('geometric_matching')
        
        # 5ë‹¨ê³„: ì˜· ì›Œí•‘
        logger.info("5ï¸âƒ£ ì˜· ì›Œí•‘ ì´ˆê¸°í™”...")
        self.steps['cloth_warping'] = ClothWarpingStep()
        await self._safe_initialize_step('cloth_warping')
        
        # 6ë‹¨ê³„: ê°€ìƒ í”¼íŒ…
        logger.info("6ï¸âƒ£ ê°€ìƒ í”¼íŒ… ìƒì„± ì´ˆê¸°í™”...")
        self.steps['virtual_fitting'] = VirtualFittingStep()
        await self._safe_initialize_step('virtual_fitting')
        
        # 7ë‹¨ê³„: í›„ì²˜ë¦¬
        logger.info("7ï¸âƒ£ í›„ì²˜ë¦¬ ì´ˆê¸°í™”...")
        self.steps['post_processing'] = PostProcessingStep()
        await self._safe_initialize_step('post_processing')
        
        # 8ë‹¨ê³„: í’ˆì§ˆ í‰ê°€
        logger.info("8ï¸âƒ£ í’ˆì§ˆ í‰ê°€ ì´ˆê¸°í™”...")
        self.steps['quality_assessment'] = QualityAssessmentStep()
        await self._safe_initialize_step('quality_assessment')
    
    async def _safe_initialize_step(self, step_name: str):
        """ì•ˆì „í•œ ë‹¨ê³„ ì´ˆê¸°í™”"""
        try:
            step = self.steps[step_name]
            if hasattr(step, 'initialize'):
                await step.initialize()
            logger.info(f"âœ… {step_name} ì´ˆê¸°í™” ì™„ë£Œ")
        except Exception as e:
            logger.warning(f"âš ï¸ {step_name} ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            # ê³„ì† ì§„í–‰ (ì¼ë¶€ ë‹¨ê³„ ì‹¤íŒ¨í•´ë„ ì „ì²´ ì¤‘ë‹¨í•˜ì§€ ì•ŠìŒ)
    
    async def _verify_initialization(self) -> bool:
        """ì´ˆê¸°í™” ê²€ì¦"""
        total_steps = len(self.step_order)
        initialized_steps = len(self.steps)
        
        success_rate = initialized_steps / total_steps
        logger.info(f"ğŸ“Š ì´ˆê¸°í™” ì„±ê³µë¥ : {success_rate:.1%} ({initialized_steps}/{total_steps})")
        
        return success_rate >= 0.8  # 80% ì´ìƒ ì„±ê³µí•˜ë©´ ì§„í–‰
    
    async def process_complete_virtual_fitting(
        self,
        person_image: Union[str, Image.Image, np.ndarray],
        clothing_image: Union[str, Image.Image, np.ndarray],
        body_measurements: Optional[Dict[str, float]] = None,
        clothing_type: str = "shirt",
        fabric_type: str = "cotton",
        style_preferences: Optional[Dict[str, Any]] = None,
        quality_target: float = 0.8,
        progress_callback: Optional[Callable] = None,
        save_intermediate: bool = False,
        enable_auto_retry: bool = True
    ) -> Dict[str, Any]:
        """
        ê°œì„ ëœ ì™„ì „í•œ 8ë‹¨ê³„ ê°€ìƒ í”¼íŒ… ì²˜ë¦¬
        
        Args:
            person_image: ì‚¬ìš©ì ì´ë¯¸ì§€ (ê²½ë¡œ, PIL, numpy ë°°ì—´)
            clothing_image: ì˜ë¥˜ ì´ë¯¸ì§€ (ê²½ë¡œ, PIL, numpy ë°°ì—´)
            body_measurements: ì‹ ì²´ ì¹˜ìˆ˜ {'height': 170, 'weight': 65, 'chest': 95, ...}
            clothing_type: ì˜ë¥˜ íƒ€ì… ('shirt', 'pants', 'dress', 'jacket', 'skirt')
            fabric_type: ì²œ ì¬ì§ˆ ('cotton', 'denim', 'silk', 'polyester', 'wool')
            style_preferences: ìŠ¤íƒ€ì¼ ì„ í˜¸ë„ {'fit': 'slim', 'color_preference': 'original'}
            quality_target: ëª©í‘œ í’ˆì§ˆ ì ìˆ˜ (0.0-1.0)
            progress_callback: ì§„í–‰ìƒí™© ì½œë°± í•¨ìˆ˜ async def callback(stage: str, percentage: int)
            save_intermediate: ì¤‘ê°„ ê²°ê³¼ ì €ì¥ ì—¬ë¶€
            enable_auto_retry: ìë™ ì¬ì‹œë„ í™œì„±í™”
            
        Returns:
            ì™„ì „í•œ ê°€ìƒ í”¼íŒ… ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        if not self.is_initialized:
            raise RuntimeError("íŒŒì´í”„ë¼ì¸ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. initialize()ë¥¼ ë¨¼ì € í˜¸ì¶œí•˜ì„¸ìš”.")
        
        start_time = time.time()
        session_id = f"vf_{int(time.time())}_{np.random.randint(1000, 9999)}"
        
        # ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
        self.performance_metrics['total_sessions'] += 1
        
        try:
            logger.info(f"ğŸ¯ ê°œì„ ëœ 8ë‹¨ê³„ ê°€ìƒ í”¼íŒ… ì‹œì‘ - ì„¸ì…˜ ID: {session_id}")
            logger.info(f"âš™ï¸ ì„¤ì •: {clothing_type} ({fabric_type}), í’ˆì§ˆëª©í‘œ: {quality_target}")
            
            # ì…ë ¥ ê²€ì¦ ë° ì „ì²˜ë¦¬
            person_tensor, clothing_tensor = await self._preprocess_inputs(
                person_image, clothing_image
            )
            
            # ì„¸ì…˜ ë°ì´í„° ì´ˆê¸°í™”
            self._initialize_session_data(session_id, start_time, {
                'clothing_type': clothing_type,
                'fabric_type': fabric_type,
                'quality_target': quality_target,
                'style_preferences': style_preferences or {},
                'processing_mode': self.pipeline_config['processing_mode']
            })
            
            if progress_callback:
                await progress_callback("ì…ë ¥ ì „ì²˜ë¦¬ ì™„ë£Œ", 5)
            
            # ë©”ëª¨ë¦¬ ìµœì í™”
            if self.pipeline_config['memory_optimization']:
                self._optimize_memory_usage()
            
            # ===========================================
            # 8ë‹¨ê³„ ìˆœì°¨ ì²˜ë¦¬
            # ===========================================
            
            # 1ë‹¨ê³„: ì¸ì²´ íŒŒì‹± (20ê°œ ë¶€ìœ„ ë¶„í• )
            parsing_result = await self._execute_step_with_retry(
                'human_parsing', 1, person_tensor, progress_callback, 18
            )
            
            # 2ë‹¨ê³„: í¬ì¦ˆ ì¶”ì • (18ê°œ í‚¤í¬ì¸íŠ¸)
            pose_result = await self._execute_step_with_retry(
                'pose_estimation', 2, person_tensor, progress_callback, 31
            )
            
            # 3ë‹¨ê³„: ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ (ë°°ê²½ ì œê±°)
            segmentation_result = await self._execute_step_with_retry(
                'cloth_segmentation', 3, clothing_tensor, progress_callback, 44,
                extra_args={'clothing_type': clothing_type}
            )
            
            # 4ë‹¨ê³„: ê¸°í•˜í•™ì  ë§¤ì¹­ (TPS ë³€í™˜)
            matching_result = await self._execute_step_with_retry(
                'geometric_matching', 4, 
                (segmentation_result, pose_result, parsing_result),
                progress_callback, 57
            )
            
            # 5ë‹¨ê³„: ì˜· ì›Œí•‘ (ë¬¼ë¦¬ ì‹œë®¬ë ˆì´ì…˜)
            warping_result = await self._execute_step_with_retry(
                'cloth_warping', 5,
                (matching_result, body_measurements, fabric_type),
                progress_callback, 70
            )
            
            # 6ë‹¨ê³„: ê°€ìƒ í”¼íŒ… ìƒì„± (ìµœì¢… í•©ì„±)
            fitting_result = await self._execute_step_with_retry(
                'virtual_fitting', 6,
                (person_tensor, warping_result, parsing_result, pose_result),
                progress_callback, 83
            )
            
            # 7ë‹¨ê³„: í›„ì²˜ë¦¬ (í’ˆì§ˆ í–¥ìƒ)
            post_processing_result = await self._execute_step_with_retry(
                'post_processing', 7, fitting_result, progress_callback, 91
            )
            
            # 8ë‹¨ê³„: í’ˆì§ˆ í‰ê°€ (ìë™ ìŠ¤ì½”ì–´ë§)
            quality_result = await self._execute_step_with_retry(
                'quality_assessment', 8,
                (post_processing_result, person_tensor, clothing_tensor, 
                 parsing_result, pose_result, warping_result, fitting_result),
                progress_callback, 96
            )
            
            # ===========================================
            # ìµœì¢… ê²°ê³¼ êµ¬ì„± ë° ë¶„ì„
            # ===========================================
            
            total_time = time.time() - start_time
            
            # ìµœì¢… ê²°ê³¼ ì´ë¯¸ì§€ ì¶”ì¶œ
            final_image_tensor = self._extract_final_image(
                post_processing_result, fitting_result, person_tensor
            )
            final_image_pil = self._tensor_to_pil(final_image_tensor)
            
            # ì¢…í•© í’ˆì§ˆ ë¶„ì„
            comprehensive_quality = await self._comprehensive_quality_analysis(
                quality_result, self.session_data[session_id]
            )
            
            # ì²˜ë¦¬ í†µê³„ ê³„ì‚°
            processing_statistics = self._calculate_detailed_statistics(session_id, total_time)
            
            # í’ˆì§ˆ ê°œì„  ë¶„ì„
            quality_improvement_analysis = self._analyze_quality_progression(session_id)
            
            # ê°œì„  ì œì•ˆ ìƒì„±
            improvement_suggestions = await self._generate_detailed_suggestions(
                comprehensive_quality, processing_statistics, clothing_type, fabric_type
            )
            
            # ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
            self.performance_metrics['successful_sessions'] += 1
            self._update_performance_metrics(total_time, comprehensive_quality['overall_score'])
            
            # ìµœì¢… ê²°ê³¼ ë”•ì…”ë„ˆë¦¬ êµ¬ì„±
            final_result = {
                # ê¸°ë³¸ ì •ë³´
                'success': True,
                'session_id': session_id,
                'processing_mode': self.pipeline_config['processing_mode'],
                'quality_level': self.pipeline_config['quality_level'],
                
                # ê²°ê³¼ ì´ë¯¸ì§€ë“¤
                'result_image': final_image_pil,
                'result_image_tensor': final_image_tensor,
                'original_person_image': self._tensor_to_pil(person_tensor),
                'original_clothing_image': self._tensor_to_pil(clothing_tensor),
                
                # í’ˆì§ˆ ë©”íŠ¸ë¦­ (ìƒì„¸)
                'final_quality_score': comprehensive_quality['overall_score'],
                'quality_grade': comprehensive_quality['quality_grade'],
                'quality_confidence': comprehensive_quality['confidence'],
                'quality_breakdown': comprehensive_quality['breakdown'],
                'quality_target_achieved': comprehensive_quality['overall_score'] >= quality_target,
                'quality_improvement_analysis': quality_improvement_analysis,
                
                # í• ë¶„ì„ (ìƒì„¸)
                'fit_analysis': {
                    'overall_fit_score': comprehensive_quality['breakdown'].get('fit_quality', 0.8),
                    'body_alignment': comprehensive_quality.get('body_alignment', 0.8),
                    'garment_deformation': comprehensive_quality.get('garment_deformation', 0.8),
                    'size_compatibility': self._analyze_size_compatibility(
                        body_measurements, clothing_type
                    ),
                    'style_match': self._analyze_style_match(
                        style_preferences, fitting_result
                    )
                },
                
                # ê°œì„  ì œì•ˆ (ì¹´í…Œê³ ë¦¬ë³„)
                'improvement_suggestions': improvement_suggestions,
                'next_steps': self._generate_next_steps(comprehensive_quality, quality_target),
                
                # ì²˜ë¦¬ í†µê³„ (ìƒì„¸)
                'processing_statistics': processing_statistics,
                'total_processing_time': total_time,
                'device_used': self.device,
                'memory_usage': self._get_detailed_memory_usage(),
                'performance_metrics': self.performance_metrics.copy(),
                
                # ë‹¨ê³„ë³„ ê²°ê³¼ (ìƒì„¸)
                'step_results_summary': self._create_detailed_step_summary(session_id),
                
                # ì¤‘ê°„ ê²°ê³¼ (ì„ íƒì )
                'intermediate_results': (
                    self.session_data[session_id]['intermediate_results'] 
                    if save_intermediate else {}
                ),
                
                # ë©”íƒ€ë°ì´í„° (í™•ì¥)
                'metadata': {
                    'timestamp': datetime.now().isoformat(),
                    'pipeline_version': '2.0.0',
                    'input_resolution': f"{person_tensor.shape[3]}x{person_tensor.shape[2]}",
                    'output_resolution': f"{final_image_pil.width}x{final_image_pil.height}",
                    'clothing_type': clothing_type,
                    'fabric_type': fabric_type,
                    'body_measurements_provided': body_measurements is not None,
                    'style_preferences_provided': bool(style_preferences),
                    'intermediate_results_saved': save_intermediate,
                    'device_optimization': self.device,
                    'memory_optimization_enabled': self.pipeline_config['memory_optimization'],
                    'parallel_processing_enabled': self.pipeline_config['parallel_processing']
                }
            }
            
            # ì„¸ì…˜ ë°ì´í„° ì •ë¦¬ (ë©”ëª¨ë¦¬ ì ˆì•½)
            if not save_intermediate:
                self._cleanup_session_data(session_id)
            
            if progress_callback:
                await progress_callback("ì²˜ë¦¬ ì™„ë£Œ", 100)
            
            logger.info(
                f"ğŸ‰ ê°œì„ ëœ 8ë‹¨ê³„ ê°€ìƒ í”¼íŒ… ì™„ë£Œ! "
                f"ì „ì²´ ì†Œìš”ì‹œê°„: {total_time:.2f}ì´ˆ, "
                f"ìµœì¢… í’ˆì§ˆ: {comprehensive_quality['overall_score']:.3f} ({comprehensive_quality['quality_grade']}), "
                f"ëª©í‘œ ë‹¬ì„±: {'âœ…' if comprehensive_quality['overall_score'] >= quality_target else 'âŒ'}"
            )
            
            return final_result
            
        except Exception as e:
            # ì—ëŸ¬ ì²˜ë¦¬ ë° ë³µêµ¬
            error_result = await self._handle_processing_error(
                e, session_id, start_time, person_image, clothing_image,
                enable_auto_retry
            )
            return error_result
    
    async def _execute_step_with_retry(
        self,
        step_name: str,
        step_number: int,
        input_data: Any,
        progress_callback: Optional[Callable],
        progress_percentage: int,
        extra_args: Optional[Dict] = None,
        max_retries: int = 3
    ) -> Dict[str, Any]:
        """ì¬ì‹œë„ ë¡œì§ì´ í¬í•¨ëœ ë‹¨ê³„ ì‹¤í–‰"""
        
        step_start = time.time()
        last_error = None
        
        for attempt in range(max_retries + 1):
            try:
                logger.info(f"{'ğŸ”„' if attempt > 0 else ''} {step_number}ë‹¨ê³„: {step_name} ì²˜ë¦¬ ì¤‘... {'(ì¬ì‹œë„ ' + str(attempt) + ')' if attempt > 0 else ''}")
                
                # ë©”ëª¨ë¦¬ ì •ë¦¬ (ì¬ì‹œë„ ì‹œ)
                if attempt > 0:
                    self._cleanup_memory()
                
                # ë‹¨ê³„ ì‹¤í–‰
                result = await self._execute_single_step(step_name, input_data, extra_args)
                
                # ê²°ê³¼ ê²€ì¦
                if self._validate_step_result(step_name, result):
                    step_time = time.time() - step_start
                    
                    # ì„¸ì…˜ ë°ì´í„° ì €ì¥
                    session_id = list(self.session_data.keys())[-1] if self.session_data else 'unknown'
                    if session_id in self.session_data:
                        self.session_data[session_id]['step_times'][step_name] = step_time
                        self.session_data[session_id]['step_results'][step_name] = result
                        
                        # ì¤‘ê°„ ê²°ê³¼ ì €ì¥ (ìš”ì²­ëœ ê²½ìš°)
                        if self.pipeline_config.get('enable_intermediate_saving', False):
                            self.session_data[session_id]['intermediate_results'][step_name] = result
                    
                    # í’ˆì§ˆ ì ìˆ˜ ë¡œê¹…
                    quality_score = result.get('confidence', result.get('quality_score', 0.8))
                    logger.info(f"âœ… {step_number}ë‹¨ê³„ ì™„ë£Œ - ì†Œìš”ì‹œê°„: {step_time:.2f}ì´ˆ, í’ˆì§ˆ: {quality_score:.3f}")
                    
                    # ì§„í–‰ë¥  ì½œë°±
                    if progress_callback:
                        await progress_callback(f"{step_name}_complete", progress_percentage)
                    
                    return result
                else:
                    raise ValueError(f"Step {step_name} result validation failed")
                    
            except Exception as e:
                last_error = e
                logger.warning(f"âš ï¸ {step_number}ë‹¨ê³„ ì‹œë„ {attempt + 1} ì‹¤íŒ¨: {e}")
                
                if attempt < max_retries:
                    wait_time = 2 ** attempt  # ì§€ìˆ˜ ë°±ì˜¤í”„
                    logger.info(f"ğŸ”„ {wait_time}ì´ˆ í›„ ì¬ì‹œë„...")
                    await asyncio.sleep(wait_time)
                else:
                    logger.error(f"âŒ {step_number}ë‹¨ê³„ ìµœì¢… ì‹¤íŒ¨: {e}")
        
        # ëª¨ë“  ì¬ì‹œë„ ì‹¤íŒ¨ ì‹œ í´ë°± ê²°ê³¼ ìƒì„±
        logger.warning(f"ğŸš¨ {step_name} í´ë°± ê²°ê³¼ ìƒì„± ì¤‘...")
        return self._create_fallback_step_result(step_name, input_data, last_error)
    
    async def _execute_single_step(
        self, 
        step_name: str, 
        input_data: Any, 
        extra_args: Optional[Dict] = None
    ) -> Dict[str, Any]:
        """ë‹¨ì¼ ë‹¨ê³„ ì‹¤í–‰"""
        
        step = self.steps.get(step_name)
        if not step:
            raise ValueError(f"Step {step_name} not found")
        
        # ë‹¨ê³„ë³„ ì‹¤í–‰ ë¡œì§
        if step_name == 'human_parsing':
            if hasattr(step, 'process'):
                return await step.process(input_data)
            else:
                return await step.parse_human(input_data)
                
        elif step_name == 'pose_estimation':
            if hasattr(step, 'process'):
                return await step.process(input_data)
            else:
                return await step.estimate_pose(input_data)
                
        elif step_name == 'cloth_segmentation':
            clothing_type = extra_args.get('clothing_type', 'shirt') if extra_args else 'shirt'
            if hasattr(step, 'process'):
                return await step.process(input_data, clothing_type)
            else:
                return await step.segment_cloth(input_data, clothing_type)
                
        elif step_name == 'geometric_matching':
            segmentation_result, pose_result, parsing_result = input_data
            if hasattr(step, 'process'):
                return await step.process(segmentation_result, pose_result, parsing_result)
            else:
                return await step.match_geometry(segmentation_result, pose_result, parsing_result)
                
        elif step_name == 'cloth_warping':
            matching_result, body_measurements, fabric_type = input_data
            if hasattr(step, 'process'):
                return await step.process(matching_result, body_measurements, fabric_type)
            else:
                return await step.warp_cloth(matching_result, body_measurements, fabric_type)
                
        elif step_name == 'virtual_fitting':
            person_tensor, warping_result, parsing_result, pose_result = input_data
            if hasattr(step, 'process'):
                return await step.process(person_tensor, warping_result, parsing_result, pose_result)
            else:
                return await step.generate_fitting(person_tensor, warping_result, parsing_result, pose_result)
                
        elif step_name == 'post_processing':
            if hasattr(step, 'process'):
                return await step.process(input_data)
            else:
                return await step.enhance_quality(input_data)
                
        elif step_name == 'quality_assessment':
            (post_processing_result, person_tensor, clothing_tensor, 
             parsing_result, pose_result, warping_result, fitting_result) = input_data
            if hasattr(step, 'process'):
                return await step.process(
                    post_processing_result, person_tensor, clothing_tensor,
                    parsing_result, pose_result, warping_result, fitting_result
                )
            else:
                return await step.assess_quality(
                    post_processing_result, person_tensor, clothing_tensor
                )
        
        else:
            raise ValueError(f"Unknown step: {step_name}")
    
    def _validate_step_result(self, step_name: str, result: Dict[str, Any]) -> bool:
        """ë‹¨ê³„ ê²°ê³¼ ê²€ì¦"""
        if not isinstance(result, dict):
            return False
        
        # ê¸°ë³¸ í•„ë“œ ê²€ì¦
        required_fields = {
            'human_parsing': ['confidence'],
            'pose_estimation': ['pose_confidence', 'keypoints'],
            'cloth_segmentation': ['confidence', 'segmented_clothing'],
            'geometric_matching': ['transform_quality'],
            'cloth_warping': ['quality_metrics'],
            'virtual_fitting': ['fitted_image'],
            'post_processing': ['enhanced_image'],
            'quality_assessment': ['overall_score']
        }
        
        step_required = required_fields.get(step_name, [])
        for field in step_required:
            if field not in result:
                logger.warning(f"âš ï¸ {step_name} ê²°ê³¼ì— í•„ìˆ˜ í•„ë“œ '{field}' ëˆ„ë½")
                return False
        
        return True
    
    def _create_fallback_step_result(
        self, 
        step_name: str, 
        input_data: Any, 
        error: Exception
    ) -> Dict[str, Any]:
        """í´ë°± ë‹¨ê³„ ê²°ê³¼ ìƒì„±"""
        
        base_result = {
            'success': False,
            'error': str(error),
            'fallback': True,
            'timestamp': datetime.now().isoformat()
        }
        
        # ë‹¨ê³„ë³„ ê¸°ë³¸ í´ë°± ê²°ê³¼
        if step_name == 'human_parsing':
            base_result.update({
                'confidence': 0.5,
                'body_parts_detected': [],
                'parsing_map': torch.zeros(1, 20, 512, 512) if torch.is_tensor(input_data) else np.zeros((512, 512))
            })
            
        elif step_name == 'pose_estimation':
            base_result.update({
                'pose_confidence': 0.5,
                'keypoints': np.zeros((18, 3)),
                'keypoints_18': np.zeros((18, 3))
            })
            
        elif step_name == 'cloth_segmentation':
            base_result.update({
                'confidence': 0.5,
                'segmented_clothing': input_data if torch.is_tensor(input_data) else torch.zeros(1, 3, 512, 512),
                'clothing_mask': torch.ones(1, 1, 512, 512)
            })
            
        elif step_name == 'geometric_matching':
            base_result.update({
                'transform_quality': {'overall_quality': 0.5},
                'matched_pairs': [],
                'transformation_matrix': np.eye(3)
            })
            
        elif step_name == 'cloth_warping':
            base_result.update({
                'quality_metrics': {'overall_quality': 0.5},
                'warped_clothing': input_data[0] if isinstance(input_data, tuple) else input_data,
                'simulation_details': {'physics_simulation': False}
            })
            
        elif step_name == 'virtual_fitting':
            base_result.update({
                'fitted_image': input_data[0] if isinstance(input_data, tuple) else input_data,
                'quality_metrics': {'overall_quality': 0.5},
                'fitting_analysis': {'fit_score': 0.5}
            })
            
        elif step_name == 'post_processing':
            base_result.update({
                'enhanced_image': input_data.get('fitted_image', input_data) if isinstance(input_data, dict) else input_data,
                'enhancement_score': 0.5,
                'improvements_applied': 0
            })
            
        elif step_name == 'quality_assessment':
            base_result.update({
                'overall_score': 0.5,
                'quality_grade': 'Poor',
                'detailed_metrics': {},
                'improvement_suggestions': ['ì‹œìŠ¤í…œ ì˜¤ë¥˜ë¡œ ì¸í•œ í’ˆì§ˆ ì €í•˜']
            })
        
        logger.warning(f"ğŸš¨ {step_name} í´ë°± ê²°ê³¼ ìƒì„±ë¨")
        return base_result
    
    async def _preprocess_inputs(
        self, 
        person_image: Union[str, Image.Image, np.ndarray],
        clothing_image: Union[str, Image.Image, np.ndarray]
    ) -> Tuple[torch.Tensor, torch.Tensor]:
        """ì…ë ¥ ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ë° ê²€ì¦"""
        
        try:
            # ë°ì´í„° ë³€í™˜ê¸° ì‚¬ìš©
            if hasattr(self.data_converter, 'preprocess_image'):
                person_tensor = self.data_converter.preprocess_image(person_image)
                clothing_tensor = self.data_converter.preprocess_image(clothing_image)
            else:
                person_tensor = self._manual_preprocess_image(person_image)
                clothing_tensor = self._manual_preprocess_image(clothing_image)
            
            # ì…ë ¥ ê²€ì¦
            self._validate_input_tensors(person_tensor, clothing_tensor)
            
            # ë””ë°”ì´ìŠ¤ë¡œ ì´ë™
            person_tensor = person_tensor.to(self.device)
            clothing_tensor = clothing_tensor.to(self.device)
            
            logger.info(f"âœ… ì…ë ¥ ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì™„ë£Œ - ì‚¬ëŒ: {person_tensor.shape}, ì˜ë¥˜: {clothing_tensor.shape}")
            
            return person_tensor, clothing_tensor
            
        except Exception as e:
            logger.error(f"âŒ ì…ë ¥ ì „ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            raise
    
    def _manual_preprocess_image(self, image_input: Union[str, Image.Image, np.ndarray]) -> torch.Tensor:
        """ìˆ˜ë™ ì´ë¯¸ì§€ ì „ì²˜ë¦¬"""
        
        # ì…ë ¥ íƒ€ì…ë³„ ì²˜ë¦¬
        if isinstance(image_input, str):
            if not os.path.exists(image_input):
                raise FileNotFoundError(f"ì´ë¯¸ì§€ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {image_input}")
            image = Image.open(image_input).convert('RGB')
        elif isinstance(image_input, Image.Image):
            image = image_input.convert('RGB')
        elif isinstance(image_input, np.ndarray):
            if image_input.dtype != np.uint8:
                image_input = (image_input * 255).astype(np.uint8)
            image = Image.fromarray(image_input).convert('RGB')
        else:
            raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì´ë¯¸ì§€ íƒ€ì…: {type(image_input)}")
        
        # í¬ê¸° ì¡°ì •
        target_size = self.config.get('input_size', (512, 512))
        if image.size != target_size:
            image = image.resize(target_size, Image.Resampling.LANCZOS)
        
        # í…ì„œ ë³€í™˜
        img_array = np.array(image)
        img_tensor = torch.from_numpy(img_array).permute(2, 0, 1).float() / 255.0
        img_tensor = img_tensor.unsqueeze(0)
        
        return img_tensor
    
    def _validate_input_tensors(self, person_tensor: torch.Tensor, clothing_tensor: torch.Tensor):
        """ì…ë ¥ í…ì„œ ê²€ì¦"""
        
        # ì°¨ì› ê²€ì¦
        if person_tensor.dim() != 4 or clothing_tensor.dim() != 4:
            raise ValueError("ì…ë ¥ í…ì„œëŠ” 4ì°¨ì›ì´ì–´ì•¼ í•©ë‹ˆë‹¤ (B, C, H, W)")
        
        # ì±„ë„ ê²€ì¦
        if person_tensor.shape[1] != 3 or clothing_tensor.shape[1] != 3:
            raise ValueError("ì…ë ¥ ì´ë¯¸ì§€ëŠ” RGB 3ì±„ë„ì´ì–´ì•¼ í•©ë‹ˆë‹¤")
        
        # ê°’ ë²”ìœ„ ê²€ì¦
        if (person_tensor.min() < 0 or person_tensor.max() > 1 or 
            clothing_tensor.min() < 0 or clothing_tensor.max() > 1):
            raise ValueError("í…ì„œ ê°’ì€ 0-1 ë²”ìœ„ì—¬ì•¼ í•©ë‹ˆë‹¤")
        
        logger.debug("âœ… ì…ë ¥ í…ì„œ ê²€ì¦ ì™„ë£Œ")
    
    def _initialize_session_data(self, session_id: str, start_time: float, config: Dict[str, Any]):
        """ì„¸ì…˜ ë°ì´í„° ì´ˆê¸°í™”"""
        
        self.session_data[session_id] = {
            'start_time': start_time,
            'config': config,
            'step_times': {},
            'step_results': {},
            'intermediate_results': {},
            'error_log': [],
            'memory_snapshots': [],
            'quality_progression': []
        }
    
    def _optimize_memory_usage(self):
        """ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ìµœì í™”"""
        
        # ê°€ë¹„ì§€ ì»¬ë ‰ì…˜
        gc.collect()
        
        # ë””ë°”ì´ìŠ¤ë³„ ë©”ëª¨ë¦¬ ì •ë¦¬
        if self.device == 'cuda':
            torch.cuda.empty_cache()
        elif self.device == 'mps':
            torch.mps.empty_cache()
        
        # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë¡œê¹…
        memory_usage = self._get_detailed_memory_usage()
        logger.debug(f"ğŸ§¹ ë©”ëª¨ë¦¬ ìµœì í™” ì™„ë£Œ - ì‚¬ìš©ëŸ‰: {memory_usage}")
    
    def _cleanup_memory(self):
        """ë©”ëª¨ë¦¬ ì •ë¦¬"""
        
        # Python ê°€ë¹„ì§€ ì»¬ë ‰ì…˜
        gc.collect()
        
        # PyTorch ìºì‹œ ì •ë¦¬
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
        
        if hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
            torch.mps.empty_cache()
    
    def _extract_final_image(
        self, 
        post_processing_result: Dict[str, Any],
        fitting_result: Dict[str, Any], 
        person_tensor: torch.Tensor
    ) -> torch.Tensor:
        """ìµœì¢… ê²°ê³¼ ì´ë¯¸ì§€ ì¶”ì¶œ"""
        
        # ìš°ì„ ìˆœìœ„: í›„ì²˜ë¦¬ ê²°ê³¼ > í”¼íŒ… ê²°ê³¼ > ì›ë³¸
        if 'enhanced_image' in post_processing_result:
            return post_processing_result['enhanced_image']
        elif 'fitted_image' in fitting_result:
            return fitting_result['fitted_image']
        else:
            logger.warning("âš ï¸ ìµœì¢… ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ ì›ë³¸ì„ ë°˜í™˜í•©ë‹ˆë‹¤")
            return person_tensor
    
    def _tensor_to_pil(self, tensor: torch.Tensor) -> Image.Image:
        """í…ì„œë¥¼ PIL ì´ë¯¸ì§€ë¡œ ë³€í™˜"""
        
        try:
            if tensor.dim() == 4:
                tensor = tensor.squeeze(0)
            
            if tensor.shape[0] == 3:
                tensor = tensor.permute(1, 2, 0)
            
            # 0-1 ë²”ìœ„ë¡œ í´ë¨í•‘
            tensor = torch.clamp(tensor, 0, 1)
            
            # CPUë¡œ ì´ë™
            tensor = tensor.cpu()
            
            # numpy ë°°ì—´ë¡œ ë³€í™˜
            array = (tensor.numpy() * 255).astype(np.uint8)
            
            return Image.fromarray(array)
            
        except Exception as e:
            logger.error(f"âŒ í…ì„œ-PIL ë³€í™˜ ì‹¤íŒ¨: {e}")
            # í´ë°±: ë¹ˆ ì´ë¯¸ì§€ ë°˜í™˜
            return Image.new('RGB', (512, 512), color='black')
    
    async def _comprehensive_quality_analysis(
        self, 
        quality_result: Dict[str, Any], 
        session_data: Dict[str, Any]
    ) -> Dict[str, Any]:
        """ì¢…í•©ì  í’ˆì§ˆ ë¶„ì„"""
        
        overall_score = quality_result.get('overall_score', 0.8)
        
        # í’ˆì§ˆ ë“±ê¸‰ ê²°ì •
        if overall_score >= 0.9:
            quality_grade = "Excellent"
            confidence = 0.95
        elif overall_score >= 0.8:
            quality_grade = "Good"
            confidence = 0.85
        elif overall_score >= 0.7:
            quality_grade = "Acceptable"
            confidence = 0.75
        elif overall_score >= 0.6:
            quality_grade = "Poor"
            confidence = 0.65
        else:
            quality_grade = "Very Poor"
            confidence = 0.5
        
        # ìƒì„¸ ë¶„ì„
        breakdown = quality_result.get('quality_breakdown', {})
        
        return {
            'overall_score': overall_score,
            'quality_grade': quality_grade,
            'confidence': confidence,
            'breakdown': breakdown,
            'analysis_timestamp': datetime.now().isoformat()
        }
    
    def _calculate_detailed_statistics(self, session_id: str, total_time: float) -> Dict[str, Any]:
        """ìƒì„¸ ì²˜ë¦¬ í†µê³„ ê³„ì‚°"""
        
        session_data = self.session_data[session_id]
        step_times = session_data['step_times']
        
        # ê¸°ë³¸ í†µê³„
        stats = {
            'total_time': total_time,
            'step_times': step_times.copy(),
            'steps_completed': len(step_times),
            'success_rate': len(step_times) / len(self.step_order),
        }
        
        if step_times:
            # ì‹œê°„ ë¶„ì„
            times = list(step_times.values())
            stats.update({
                'average_step_time': np.mean(times),
                'fastest_step': {'name': min(step_times, key=step_times.get), 'time': min(times)},
                'slowest_step': {'name': max(step_times, key=step_times.get), 'time': max(times)},
                'time_distribution': {step: time/total_time*100 for step, time in step_times.items()}
            })
        
        # ë©”ëª¨ë¦¬ ë° ì„±ëŠ¥
        stats.update({
            'memory_usage': self._get_detailed_memory_usage(),
            'device_utilization': self._get_device_utilization(),
            'efficiency_score': self._calculate_efficiency_score(total_time, len(step_times))
        })
        
        return stats
    
    def _analyze_quality_progression(self, session_id: str) -> Dict[str, Any]:
        """í’ˆì§ˆ ì§„í–‰ ë¶„ì„"""
        
        session_data = self.session_data[session_id]
        step_results = session_data['step_results']
        
        quality_progression = []
        
        for step_name in self.step_order:
            if step_name in step_results:
                result = step_results[step_name]
                # ê° ë‹¨ê³„ì˜ í’ˆì§ˆ ì ìˆ˜ ì¶”ì¶œ
                if 'confidence' in result:
                    quality_score = result['confidence']
                elif 'quality_score' in result:
                    quality_score = result['quality_score']
                elif 'overall_score' in result:
                    quality_score = result['overall_score']
                else:
                    quality_score = 0.8  # ê¸°ë³¸ê°’
                
                quality_progression.append({
                    'step': step_name,
                    'quality': quality_score,
                    'timestamp': result.get('timestamp', datetime.now().isoformat())
                })
        
        # í’ˆì§ˆ ê°œì„  ë¶„ì„
        improvements = []
        for i in range(1, len(quality_progression)):
            prev_quality = quality_progression[i-1]['quality']
            curr_quality = quality_progression[i]['quality']
            improvement = curr_quality - prev_quality
            
            improvements.append({
                'from_step': quality_progression[i-1]['step'],
                'to_step': quality_progression[i]['step'],
                'improvement': improvement,
                'improvement_percentage': (improvement / prev_quality * 100) if prev_quality > 0 else 0
            })
        
        return {
            'quality_progression': quality_progression,
            'improvements': improvements,
            'total_improvement': (quality_progression[-1]['quality'] - quality_progression[0]['quality']) if quality_progression else 0,
            'consistent_improvement': all(imp['improvement'] >= 0 for imp in improvements)
        }
    
    async def _generate_detailed_suggestions(
        self, 
        quality_analysis: Dict[str, Any], 
        statistics: Dict[str, Any],
        clothing_type: str,
        fabric_type: str
    ) -> Dict[str, List[str]]:
        """ìƒì„¸ ê°œì„  ì œì•ˆ ìƒì„±"""
        
        suggestions = {
            'quality_improvements': [],
            'performance_optimizations': [],
            'user_experience': [],
            'technical_adjustments': []
        }
        
        overall_score = quality_analysis['overall_score']
        breakdown = quality_analysis['breakdown']
        
        # í’ˆì§ˆ ê°œì„  ì œì•ˆ
        if overall_score < 0.8:
            suggestions['quality_improvements'].extend([
                "ğŸ¯ ì „ì²´ì ì¸ í’ˆì§ˆ í–¥ìƒì´ í•„ìš”í•©ë‹ˆë‹¤",
                "ğŸ“· ë” ë†’ì€ í•´ìƒë„ì˜ ì…ë ¥ ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í•´ë³´ì„¸ìš”",
                "ğŸ’¡ ì¡°ëª…ì´ ê· ë“±í•œ í™˜ê²½ì—ì„œ ì´¬ì˜ëœ ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”"
            ])
        
        if breakdown.get('fit_quality', 1.0) < 0.7:
            suggestions['quality_improvements'].extend([
                f"ğŸ‘” {clothing_type} í• ê°œì„ ì„ ìœ„í•´ ë” ì •í™•í•œ ì‹ ì²´ ì¹˜ìˆ˜ë¥¼ ì œê³µí•˜ì„¸ìš”",
                "ğŸ¤ ì˜ë¥˜ í¬ê¸°ê°€ ì²´í˜•ê³¼ ë§ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤",
                f"ğŸ§µ {fabric_type} ì¬ì§ˆ íŠ¹ì„±ì„ ê³ ë ¤í•œ ì¡°ì •ì´ í•„ìš”í•©ë‹ˆë‹¤"
            ])
        
        # ì„±ëŠ¥ ìµœì í™” ì œì•ˆ
        total_time = statistics['total_time']
        if total_time > 60:
            suggestions['performance_optimizations'].extend([
                "âš¡ ì²˜ë¦¬ ì‹œê°„ì´ ê¸´ í¸ì…ë‹ˆë‹¤. í’ˆì§ˆ ë ˆë²¨ì„ ì¡°ì •í•´ë³´ì„¸ìš”",
                "ğŸ–¥ï¸ ë” ë†’ì€ ì„±ëŠ¥ì˜ ë””ë°”ì´ìŠ¤ ì‚¬ìš©ì„ ê³ ë ¤í•˜ì„¸ìš”",
                "ğŸ§¹ ë¶ˆí•„ìš”í•œ ë°±ê·¸ë¼ìš´ë“œ í”„ë¡œì„¸ìŠ¤ë¥¼ ì¢…ë£Œí•˜ì„¸ìš”"
            ])
        
        if statistics['success_rate'] < 1.0:
            suggestions['performance_optimizations'].extend([
                "ğŸ”„ ì¼ë¶€ ë‹¨ê³„ê°€ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ì…ë ¥ ì´ë¯¸ì§€ í’ˆì§ˆì„ í™•ì¸í•˜ì„¸ìš”",
                "ğŸ’¾ ì¶©ë¶„í•œ ë©”ëª¨ë¦¬ê°€ í™•ë³´ë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”"
            ])
        
        # ì‚¬ìš©ì ê²½í—˜ ê°œì„ 
        suggestions['user_experience'].extend([
            "ğŸ“¸ ì •ë©´ì„ ë°”ë¼ë³´ëŠ” ìì„¸ì˜ ì‚¬ì§„ì´ ê°€ì¥ ì¢‹ì€ ê²°ê³¼ë¥¼ ì œê³µí•©ë‹ˆë‹¤",
            "ğŸ¨ ë‹¨ìƒ‰ ë°°ê²½ì˜ ì˜ë¥˜ ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í•˜ë©´ ë” ì •í™•í•œ ê²°ê³¼ë¥¼ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤",
            "ğŸ“ ì‹ ì²´ ì¹˜ìˆ˜ ì •ë³´ë¥¼ ì •í™•íˆ ì…ë ¥í•˜ë©´ í•ì´ ê°œì„ ë©ë‹ˆë‹¤"
        ])
        
        # ê¸°ìˆ ì  ì¡°ì •
        if self.device == 'cpu':
            suggestions['technical_adjustments'].append(
                "ğŸš€ GPUë‚˜ MPSë¥¼ ì‚¬ìš©í•˜ë©´ ì²˜ë¦¬ ì†ë„ê°€ í¬ê²Œ í–¥ìƒë©ë‹ˆë‹¤"
            )
        
        if breakdown.get('technical_quality', {}).get('sharpness', 1.0) < 0.7:
            suggestions['technical_adjustments'].extend([
                "ğŸ” ì´ë¯¸ì§€ ì„ ëª…ë„ ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤",
                "ğŸ“± ì¹´ë©”ë¼ í”ë“¤ë¦¼ ì—†ì´ ì´¬ì˜í•˜ì„¸ìš”"
            ])
        
        return suggestions
    
    def _generate_next_steps(self, quality_analysis: Dict[str, Any], quality_target: float) -> List[str]:
        """ë‹¤ìŒ ë‹¨ê³„ ì œì•ˆ"""
        
        overall_score = quality_analysis['overall_score']
        next_steps = []
        
        if overall_score >= quality_target:
            next_steps.extend([
                "âœ… ëª©í‘œ í’ˆì§ˆì— ë„ë‹¬í–ˆìŠµë‹ˆë‹¤!",
                "ğŸ’¾ ê²°ê³¼ë¥¼ ì €ì¥í•˜ê³  í™œìš©í•˜ì„¸ìš”",
                "ğŸ”„ ë‹¤ë¥¸ ì˜ë¥˜ë¡œ ì¶”ê°€ í”¼íŒ…ì„ ì‹œë„í•´ë³´ì„¸ìš”"
            ])
        else:
            gap = quality_target - overall_score
            next_steps.extend([
                f"ğŸ¯ ëª©í‘œ í’ˆì§ˆê¹Œì§€ {gap:.2f} ì  í–¥ìƒì´ í•„ìš”í•©ë‹ˆë‹¤",
                "ğŸ”§ ê°œì„  ì œì•ˆì‚¬í•­ì„ ì ìš©í•´ë³´ì„¸ìš”",
                "ğŸ“· ë” ì¢‹ì€ í’ˆì§ˆì˜ ì…ë ¥ ì´ë¯¸ì§€ë¥¼ ì¤€ë¹„í•˜ì„¸ìš”"
            ])
        
        return next_steps
    
    def _analyze_size_compatibility(
        self, 
        body_measurements: Optional[Dict[str, float]], 
        clothing_type: str
    ) -> Dict[str, Any]:
        """ì‚¬ì´ì¦ˆ í˜¸í™˜ì„± ë¶„ì„"""
        
        if not body_measurements:
            return {
                'compatibility_score': 0.5,
                'recommendation': 'ì‹ ì²´ ì¹˜ìˆ˜ ì •ë³´ê°€ ì—†ì–´ ì •í™•í•œ ë¶„ì„ì´ ì–´ë µìŠµë‹ˆë‹¤',
                'confidence': 'low'
            }
        
        # ì˜ë¥˜ íƒ€ì…ë³„ ì¤‘ìš” ì¹˜ìˆ˜
        key_measurements = {
            'shirt': ['chest', 'shoulder_width', 'waist'],
            'pants': ['waist', 'hip', 'inseam'],
            'dress': ['chest', 'waist', 'hip'],
            'jacket': ['chest', 'shoulder_width', 'arm_length'],
            'skirt': ['waist', 'hip']
        }
        
        relevant_measurements = key_measurements.get(clothing_type, ['chest', 'waist'])
        provided_measurements = [m for m in relevant_measurements if m in body_measurements]
        
        completeness = len(provided_measurements) / len(relevant_measurements)
        
        return {
            'compatibility_score': min(0.9, 0.5 + completeness * 0.4),
            'provided_measurements': provided_measurements,
            'missing_measurements': [m for m in relevant_measurements if m not in body_measurements],
            'recommendation': f"{clothing_type}ì— ì¤‘ìš”í•œ ì¹˜ìˆ˜ ì •ë³´ê°€ {completeness:.1%} ì œê³µë˜ì—ˆìŠµë‹ˆë‹¤",
            'confidence': 'high' if completeness > 0.8 else 'medium' if completeness > 0.5 else 'low'
        }
    
    def _analyze_style_match(
        self, 
        style_preferences: Optional[Dict[str, Any]], 
        fitting_result: Dict[str, Any]
    ) -> Dict[str, Any]:
        """ìŠ¤íƒ€ì¼ ë§¤ì¹­ ë¶„ì„"""
        
        if not style_preferences:
            return {
                'match_score': 0.8,
                'analysis': 'ìŠ¤íƒ€ì¼ ì„ í˜¸ë„ê°€ ì œê³µë˜ì§€ ì•Šì•„ ê¸°ë³¸ ìŠ¤íƒ€ì¼ì„ ì ìš©í–ˆìŠµë‹ˆë‹¤',
                'confidence': 'medium'
            }
        
        # ê¸°ë³¸ ìŠ¤íƒ€ì¼ ë¶„ì„
        match_factors = []
        
        # í• ìŠ¤íƒ€ì¼
        preferred_fit = style_preferences.get('fit', 'regular')
        match_factors.append({
            'factor': 'fit_style',
            'preferred': preferred_fit,
            'achieved': 'regular',  # ê¸°ë³¸ê°’
            'match': 0.8
        })
        
        # ìƒ‰ìƒ ì„ í˜¸ë„
        color_preference = style_preferences.get('color_preference', 'original')
        match_factors.append({
            'factor': 'color',
            'preferred': color_preference,
            'achieved': 'original',
            'match': 0.9 if color_preference == 'original' else 0.7
        })
        
        overall_match = np.mean([factor['match'] for factor in match_factors])
        
        return {
            'match_score': overall_match,
            'match_factors': match_factors,
            'analysis': f"ìŠ¤íƒ€ì¼ ë§¤ì¹­ë„: {overall_match:.1%}",
            'confidence': 'high'
        }
    
    def _create_detailed_step_summary(self, session_id: str) -> Dict[str, Dict[str, Any]]:
        """ìƒì„¸ ë‹¨ê³„ ìš”ì•½ ìƒì„±"""
        
        session_data = self.session_data[session_id]
        step_times = session_data['step_times']
        step_results = session_data['step_results']
        
        summary = {}
        
        for step_name in self.step_order:
            step_summary = {
                'completed': step_name in step_results,
                'processing_time': step_times.get(step_name, 0),
                'success': step_name in step_results and not step_results[step_name].get('error'),
                'fallback_used': step_results.get(step_name, {}).get('fallback', False)
            }
            
            # ë‹¨ê³„ë³„ íŠ¹í™” ì •ë³´
            if step_name in step_results:
                result = step_results[step_name]
                
                if step_name == 'human_parsing':
                    step_summary.update({
                        'confidence': result.get('confidence', 0),
                        'body_parts_detected': len(result.get('body_parts_detected', [])),
                        'parsing_accuracy': result.get('parsing_accuracy', 'unknown')
                    })
                    
                elif step_name == 'pose_estimation':
                    step_summary.update({
                        'pose_confidence': result.get('pose_confidence', 0),
                        'keypoints_detected': len(result.get('keypoints', [])),
                        'pose_stability': result.get('pose_stability', 'unknown')
                    })
                    
                elif step_name == 'quality_assessment':
                    step_summary.update({
                        'overall_score': result.get('overall_score', 0),
                        'quality_grade': result.get('quality_grade', 'Unknown'),
                        'metrics_computed': len(result.get('detailed_metrics', {}))
                    })
            
            summary[step_name] = step_summary
        
        return summary
    
    def _get_detailed_memory_usage(self) -> Dict[str, str]:
        """ìƒì„¸ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¡°íšŒ"""
        
        import psutil
        
        memory_info = {
            'system_memory': f"{psutil.virtual_memory().percent}%",
            'available_memory': f"{psutil.virtual_memory().available / 1024**3:.1f}GB"
        }
        
        if torch.cuda.is_available():
            memory_info.update({
                'gpu_memory_allocated': f"{torch.cuda.memory_allocated() / 1024**3:.1f}GB",
                'gpu_memory_reserved': f"{torch.cuda.memory_reserved() / 1024**3:.1f}GB"
            })
        
        if hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
            try:
                memory_info['mps_memory'] = f"{torch.mps.current_allocated_memory() / 1024**3:.1f}GB"
            except:
                memory_info['mps_memory'] = "N/A"
        
        return memory_info
    
    def _get_device_utilization(self) -> Dict[str, Any]:
        """ë””ë°”ì´ìŠ¤ í™œìš©ë„ ì¡°íšŒ"""
        
        utilization = {
            'device_type': self.device,
            'optimization_enabled': self.pipeline_config['enable_optimization']
        }
        
        if self.device == 'cuda' and torch.cuda.is_available():
            utilization.update({
                'gpu_name': torch.cuda.get_device_name(),
                'compute_capability': torch.cuda.get_device_capability()
            })
        elif self.device == 'mps':
            utilization.update({
                'mps_available': torch.backends.mps.is_available(),
                'mps_built': torch.backends.mps.is_built()
            })
        
        return utilization
    
    def _calculate_efficiency_score(self, total_time: float, completed_steps: int) -> float:
        """íš¨ìœ¨ì„± ì ìˆ˜ ê³„ì‚°"""
        
        expected_time_per_step = 5.0  # ì´ˆ
        expected_total_time = len(self.step_order) * expected_time_per_step
        
        time_efficiency = min(1.0, expected_total_time / total_time) if total_time > 0 else 0
        completion_efficiency = completed_steps / len(self.step_order)
        
        return (time_efficiency + completion_efficiency) / 2
    
    def _update_performance_metrics(self, processing_time: float, quality_score: float):
        """ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸"""
        
        # ì´ë™ í‰ê·  ê³„ì‚°
        total_sessions = self.performance_metrics['total_sessions']
        
        if total_sessions > 1:
            prev_avg_time = self.performance_metrics['average_processing_time']
            prev_avg_quality = self.performance_metrics['average_quality_score']
            
            # ì´ë™ í‰ê·  ì—…ë°ì´íŠ¸
            self.performance_metrics['average_processing_time'] = (
                (prev_avg_time * (total_sessions - 1) + processing_time) / total_sessions
            )
            self.performance_metrics['average_quality_score'] = (
                (prev_avg_quality * (total_sessions - 1) + quality_score) / total_sessions
            )
        else:
            self.performance_metrics['average_processing_time'] = processing_time
            self.performance_metrics['average_quality_score'] = quality_score
    
    def _cleanup_session_data(self, session_id: str):
        """ì„¸ì…˜ ë°ì´í„° ì •ë¦¬"""
        
        if session_id in self.session_data:
            # ì¤‘ìš”í•œ í†µê³„ë§Œ ë³´ì¡´
            session_summary = {
                'total_time': time.time() - self.session_data[session_id]['start_time'],
                'steps_completed': len(self.session_data[session_id]['step_times']),
                'final_quality': max(
                    [result.get('overall_score', result.get('confidence', 0)) 
                     for result in self.session_data[session_id]['step_results'].values()], 
                    default=0
                )
            }
            
            # ì „ì²´ ì„¸ì…˜ ë°ì´í„° ì‚­ì œ
            del self.session_data[session_id]
            
            # ìš”ì•½ë§Œ ë³´ì¡´ (ì„ íƒì )
            if hasattr(self, 'session_summaries'):
                self.session_summaries[session_id] = session_summary
            
            logger.debug(f"ğŸ§¹ ì„¸ì…˜ {session_id} ë°ì´í„° ì •ë¦¬ ì™„ë£Œ")
    
    async def _handle_processing_error(
        self,
        error: Exception,
        session_id: str,
        start_time: float,
        person_image: Union[str, Image.Image, np.ndarray],
        clothing_image: Union[str, Image.Image, np.ndarray],
        enable_auto_retry: bool = True
    ) -> Dict[str, Any]:
        """ì²˜ë¦¬ ì˜¤ë¥˜ í•¸ë“¤ë§ ë° ë³µêµ¬"""
        
        processing_time = time.time() - start_time
        error_msg = str(error)
        
        # ì˜¤ë¥˜ ê¸°ë¡
        self.error_history.append({
            'session_id': session_id,
            'error': error_msg,
            'error_type': type(error).__name__,
            'timestamp': datetime.now().isoformat(),
            'processing_time': processing_time
        })
        
        logger.error(f"âŒ ê°€ìƒ í”¼íŒ… ì²˜ë¦¬ ì‹¤íŒ¨ - ì„¸ì…˜ {session_id}: {error_msg}")
        logger.error(f"ğŸ“‹ ì˜¤ë¥˜ ìƒì„¸: {traceback.format_exc()}")
        
        # ìë™ ë³µêµ¬ ì‹œë„
        if enable_auto_retry and not hasattr(error, '_retry_attempted'):
            logger.info("ğŸ”„ ìë™ ë³µêµ¬ ì‹œë„ ì¤‘...")
            
            try:
                # ë©”ëª¨ë¦¬ ì •ë¦¬
                self._cleanup_memory()
                
                # ê°„ë‹¨í•œ ì¬ì‹œë„ (í•œ ë²ˆë§Œ)
                error._retry_attempted = True
                
                # ë‚®ì€ í’ˆì§ˆ ëª¨ë“œë¡œ ì¬ì‹œë„
                original_quality = self.pipeline_config['quality_level']
                self.pipeline_config['quality_level'] = 'medium'
                
                result = await self.process_complete_virtual_fitting(
                    person_image=person_image,
                    clothing_image=clothing_image,
                    quality_target=0.6,  # ë‚®ì€ ëª©í‘œ
                    enable_auto_retry=False  # ë¬´í•œ ë£¨í”„ ë°©ì§€
                )
                
                # ì›ë˜ í’ˆì§ˆ ë³µêµ¬
                self.pipeline_config['quality_level'] = original_quality
                
                if result['success']:
                    logger.info("âœ… ìë™ ë³µêµ¬ ì„±ê³µ!")
                    result['recovered'] = True
                    result['recovery_method'] = 'quality_downgrade'
                    return result
                    
            except Exception as retry_error:
                logger.warning(f"âš ï¸ ìë™ ë³µêµ¬ ì‹¤íŒ¨: {retry_error}")
        
        # í´ë°± ê²°ê³¼ ìƒì„±
        try:
            fallback_result = await self._create_comprehensive_fallback_result(
                person_image, clothing_image, session_id, error_msg, processing_time
            )
            return fallback_result
            
        except Exception as fallback_error:
            logger.error(f"âŒ í´ë°± ê²°ê³¼ ìƒì„±ë„ ì‹¤íŒ¨: {fallback_error}")
            
            # ìµœì†Œí•œì˜ ì˜¤ë¥˜ ê²°ê³¼
            return {
                'success': False,
                'session_id': session_id,
                'error': f"ì›ë³¸ ì˜¤ë¥˜: {error_msg}, í´ë°± ì˜¤ë¥˜: {str(fallback_error)}",
                'error_type': 'critical_failure',
                'processing_time': processing_time,
                'timestamp': datetime.now().isoformat(),
                'recovery_attempted': enable_auto_retry,
                'metadata': {
                    'pipeline_version': '2.0.0',
                    'device': self.device,
                    'critical_error': True
                }
            }
    
    async def _create_comprehensive_fallback_result(
        self,
        person_image: Union[str, Image.Image, np.ndarray],
        clothing_image: Union[str, Image.Image, np.ndarray],
        session_id: str,
        error_message: str,
        processing_time: float
    ) -> Dict[str, Any]:
        """ì¢…í•©ì ì¸ í´ë°± ê²°ê³¼ ìƒì„±"""
        
        try:
            # ê¸°ë³¸ ì´ë¯¸ì§€ ì²˜ë¦¬
            if isinstance(person_image, str):
                person_pil = Image.open(person_image).convert('RGB')
            elif isinstance(person_image, Image.Image):
                person_pil = person_image.convert('RGB')
            else:
                person_pil = Image.fromarray(person_image).convert('RGB')
            
            if isinstance(clothing_image, str):
                clothing_pil = Image.open(clothing_image).convert('RGB')
            elif isinstance(clothing_image, Image.Image):
                clothing_pil = clothing_image.convert('RGB')
            else:
                clothing_pil = Image.fromarray(clothing_image).convert('RGB')
            
            # ê°„ë‹¨í•œ í•©ì„± ì‹œë„ (ì˜¤ë¥˜ ë³µêµ¬ìš©)
            try:
                result_image = self._create_simple_composite(person_pil, clothing_pil)
            except:
                result_image = person_pil  # ìµœì•…ì˜ ê²½ìš° ì›ë³¸ ë°˜í™˜
            
            return {
                'success': False,
                'session_id': session_id,
                'error': error_message,
                'error_type': 'processing_failure',
                'fallback_used': True,
                
                # ê¸°ë³¸ ì´ë¯¸ì§€ë“¤
                'result_image': result_image,
                'original_person_image': person_pil,
                'original_clothing_image': clothing_pil,
                
                # ê¸°ë³¸ í’ˆì§ˆ ì •ë³´
                'final_quality_score': 0.3,
                'quality_grade': 'Error',
                'quality_target_achieved': False,
                
                # ì˜¤ë¥˜ ê´€ë ¨ ì •ë³´
                'error_details': {
                    'error_message': error_message,
                    'error_timestamp': datetime.now().isoformat(),
                    'session_duration': processing_time,
                    'fallback_method': 'simple_composite'
                },
                
                # ì²˜ë¦¬ í†µê³„ (ê¸°ë³¸)
                'processing_statistics': {
                    'total_time': processing_time,
                    'steps_completed': 0,
                    'success_rate': 0.0,
                    'error_occurred': True,
                    'device_used': self.device
                },
                
                # ê°œì„  ì œì•ˆ
                'improvement_suggestions': {
                    'quality_improvements': [
                        "âŒ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤",
                        "ğŸ”„ ë‹¤ì‹œ ì‹œë„í•˜ê±°ë‚˜ ë‹¤ë¥¸ ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í•´ë³´ì„¸ìš”",
                        "ğŸ“· ì´ë¯¸ì§€ í’ˆì§ˆì´ë‚˜ í˜•ì‹ì„ í™•ì¸í•´ë³´ì„¸ìš”"
                    ],
                    'technical_adjustments': [
                        "ğŸ§¹ ë©”ëª¨ë¦¬ë¥¼ ì •ë¦¬í•˜ê³  ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”",
                        "âš™ï¸ í’ˆì§ˆ ë ˆë²¨ì„ ë‚®ì¶°ì„œ ì‹œë„í•´ë³´ì„¸ìš”",
                        "ğŸ–¥ï¸ ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ë¥¼ í™•ì¸í•˜ì„¸ìš”"
                    ]
                },
                
                # ë©”íƒ€ë°ì´í„°
                'metadata': {
                    'timestamp': datetime.now().isoformat(),
                    'pipeline_version': '2.0.0',
                    'fallback_result': True,
                    'device': self.device,
                    'error_recovery': True
                }
            }
            
        except Exception as e:
            logger.error(f"âŒ í´ë°± ê²°ê³¼ ìƒì„± ì‹¤íŒ¨: {e}")
            raise
    
    def _create_simple_composite(self, person_image: Image.Image, clothing_image: Image.Image) -> Image.Image:
        """ê°„ë‹¨í•œ í•©ì„± ì´ë¯¸ì§€ ìƒì„± (ì˜¤ë¥˜ ë³µêµ¬ìš©)"""
        
        try:
            # í¬ê¸° ë§ì¶”ê¸°
            target_size = (512, 512)
            person_resized = person_image.resize(target_size, Image.Resampling.LANCZOS)
            clothing_resized = clothing_image.resize((256, 256), Image.Resampling.LANCZOS)
            
            # ë‹¨ìˆœ ì˜¤ë²„ë ˆì´ (ìš°ìƒë‹¨ì— ì˜ë¥˜ ì´ë¯¸ì§€)
            result = person_resized.copy()
            result.paste(clothing_resized, (256, 0), clothing_resized)
            
            # í…ìŠ¤íŠ¸ ì˜¤ë²„ë ˆì´ (ì˜¤ë¥˜ í‘œì‹œ)
            from PIL import ImageDraw, ImageFont
            draw = ImageDraw.Draw(result)
            try:
                font = ImageFont.truetype("arial.ttf", 20)
            except:
                font = ImageFont.load_default()
            
            draw.text((10, 10), "Preview Only - Error Occurred", fill=(255, 0, 0), font=font)
            
            return result
            
        except Exception as e:
            logger.warning(f"âš ï¸ ê°„ë‹¨í•œ í•©ì„±ë„ ì‹¤íŒ¨: {e}")
            return person_image
    
    def _load_config(self, config_path: Optional[str] = None) -> Dict[str, Any]:
        """ì„¤ì • íŒŒì¼ ë¡œë“œ"""
        
        # ê¸°ë³¸ ì„¤ì •
        default_config = {
            'input_size': (512, 512),
            'pipeline': {
                'quality_level': 'high',
                'processing_mode': 'complete',
                'enable_optimization': True,
                'enable_caching': True,
                'parallel_processing': True,
                'memory_optimization': True,
                'enable_intermediate_saving': False,
                'max_retries': 3,
                'timeout_seconds': 300
            },
            'quality_thresholds': {
                'excellent': 0.9,
                'good': 0.8,
                'acceptable': 0.7,
                'poor': 0.6
            },
            'device_optimization': {
                'enable_mps': True,
                'enable_cuda': True,
                'mixed_precision': True,
                'memory_efficient': True
            }
        }
        
        # ì„¤ì • íŒŒì¼ì—ì„œ ë¡œë“œ
        if config_path and os.path.exists(config_path):
            try:
                with open(config_path, 'r', encoding='utf-8') as f:
                    file_config = json.load(f)
                
                # ë”¥ ì—…ë°ì´íŠ¸
                def deep_update(base_dict, update_dict):
                    for key, value in update_dict.items():
                        if key in base_dict and isinstance(base_dict[key], dict) and isinstance(value, dict):
                            deep_update(base_dict[key], value)
                        else:
                            base_dict[key] = value
                
                deep_update(default_config, file_config)
                logger.info(f"âœ… ì„¤ì • íŒŒì¼ ë¡œë“œ ì™„ë£Œ: {config_path}")
                
            except Exception as e:
                logger.warning(f"âš ï¸ ì„¤ì • íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}, ê¸°ë³¸ ì„¤ì • ì‚¬ìš©")
        
        return default_config
    
    async def _print_system_status(self):
        """ì‹œìŠ¤í…œ ìƒíƒœ ì¶œë ¥"""
        
        logger.info("=" * 70)
        logger.info("ğŸ¥ ê°œì„ ëœ ê°€ìƒ í”¼íŒ… íŒŒì´í”„ë¼ì¸ ì‹œìŠ¤í…œ ìƒíƒœ")
        logger.info("=" * 70)
        
        # ë””ë°”ì´ìŠ¤ ì •ë³´
        logger.info(f"ğŸ–¥ï¸ ë””ë°”ì´ìŠ¤: {self.device}")
        if self.device == 'mps':
            logger.info(f"   - MPS ì‚¬ìš© ê°€ëŠ¥: {torch.backends.mps.is_available()}")
        elif self.device == 'cuda':
            logger.info(f"   - CUDA ë²„ì „: {torch.version.cuda}")
            logger.info(f"   - GPU ì´ë¦„: {torch.cuda.get_device_name()}")
        
        # ë‹¨ê³„ë³„ ìƒíƒœ
        logger.info("ğŸ“‹ ë‹¨ê³„ë³„ ì´ˆê¸°í™” ìƒíƒœ:")
        for i, step_name in enumerate(self.step_order, 1):
            if step_name in self.steps:
                status = "âœ… ì¤€ë¹„ë¨"
                step = self.steps[step_name]
                if hasattr(step, 'is_initialized'):
                    if not step.is_initialized:
                        status = "âš ï¸ ì´ˆê¸°í™” ë¯¸ì™„ë£Œ"
            else:
                status = "âŒ ë¡œë“œ ì•ˆë¨"
            
            logger.info(f"   {i}. {step_name}: {status}")
        
        # ì„±ëŠ¥ ì„¤ì •
        logger.info("âš™ï¸ íŒŒì´í”„ë¼ì¸ ì„¤ì •:")
        logger.info(f"   - í’ˆì§ˆ ë ˆë²¨: {self.pipeline_config['quality_level']}")
        logger.info(f"   - ì²˜ë¦¬ ëª¨ë“œ: {self.pipeline_config['processing_mode']}")
        logger.info(f"   - ë©”ëª¨ë¦¬ ìµœì í™”: {self.pipeline_config['memory_optimization']}")
        logger.info(f"   - ë³‘ë ¬ ì²˜ë¦¬: {self.pipeline_config['parallel_processing']}")
        
        # ë©”ëª¨ë¦¬ ì •ë³´
        memory_info = self._get_detailed_memory_usage()
        logger.info("ğŸ’¾ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰:")
        for key, value in memory_info.items():
            logger.info(f"   - {key}: {value}")
        
        # ì„±ëŠ¥ ë©”íŠ¸ë¦­
        logger.info("ğŸ“Š ì„±ëŠ¥ ë©”íŠ¸ë¦­:")
        logger.info(f"   - ì´ ì„¸ì…˜: {self.performance_metrics['total_sessions']}")
        logger.info(f"   - ì„±ê³µ ì„¸ì…˜: {self.performance_metrics['successful_sessions']}")
        if self.performance_metrics['total_sessions'] > 0:
            success_rate = (self.performance_metrics['successful_sessions'] / 
                          self.performance_metrics['total_sessions'] * 100)
            logger.info(f"   - ì„±ê³µë¥ : {success_rate:.1f}%")
        
        logger.info("=" * 70)
    
    async def get_pipeline_status(self) -> Dict[str, Any]:
        """íŒŒì´í”„ë¼ì¸ ìƒì„¸ ìƒíƒœ ì¡°íšŒ"""
        
        return {
            'initialized': self.is_initialized,
            'device': self.device,
            'pipeline_config': self.pipeline_config,
            'performance_metrics': self.performance_metrics.copy(),
            'memory_usage': self._get_detailed_memory_usage(),
            'device_utilization': self._get_device_utilization(),
            'active_sessions': len(self.session_data),
            'error_history_count': len(self.error_history),
            'steps_status': {
                step_name: {
                    'loaded': step_name in self.steps,
                    'type': type(self.steps[step_name]).__name__ if step_name in self.steps else None
                }
                for step_name in self.step_order
            },
            'system_health': {
                'initialization_success_rate': len(self.steps) / len(self.step_order),
                'recent_errors': self.error_history[-5:] if self.error_history else [],
                'uptime': time.time() - self.processing_stats.get('initialization_time', time.time())
            }
        }
    
    async def get_performance_report(self) -> Dict[str, Any]:
        """ì„±ëŠ¥ ë¦¬í¬íŠ¸ ìƒì„±"""
        
        return {
            'overall_performance': self.performance_metrics.copy(),
            'efficiency_metrics': {
                'average_time_per_step': (
                    self.performance_metrics['average_processing_time'] / len(self.step_order)
                    if self.performance_metrics['average_processing_time'] > 0 else 0
                ),
                'quality_per_time_ratio': (
                    self.performance_metrics['average_quality_score'] / 
                    self.performance_metrics['average_processing_time']
                    if self.performance_metrics['average_processing_time'] > 0 else 0
                )
            },
            'resource_utilization': {
                'device_type': self.device,
                'memory_usage': self._get_detailed_memory_usage(),
                'optimization_enabled': self.pipeline_config['enable_optimization']
            },
            'reliability_metrics': {
                'success_rate': (
                    self.performance_metrics['successful_sessions'] / 
                    self.performance_metrics['total_sessions']
                    if self.performance_metrics['total_sessions'] > 0 else 0
                ),
                'error_rate': (
                    len(self.error_history) / 
                    max(1, self.performance_metrics['total_sessions'])
                ),
                'average_retry_needed': len(self.error_history) / max(1, self.performance_metrics['total_sessions'])
            },
            'recommendations': self._generate_performance_recommendations()
        }
    
    def _generate_performance_recommendations(self) -> List[str]:
        """ì„±ëŠ¥ ê°œì„  ê¶Œì¥ì‚¬í•­ ìƒì„±"""
        
        recommendations = []
        
        # ì„±ê³µë¥  ê¸°ë°˜ ê¶Œì¥ì‚¬í•­
        if self.performance_metrics['total_sessions'] > 0:
            success_rate = (self.performance_metrics['successful_sessions'] / 
                          self.performance_metrics['total_sessions'])
            
            if success_rate < 0.8:
                recommendations.append("ğŸ”§ ì„±ê³µë¥ ì´ ë‚®ìŠµë‹ˆë‹¤. ì…ë ¥ ì´ë¯¸ì§€ í’ˆì§ˆì„ í™•ì¸í•˜ì„¸ìš”")
            
            if self.performance_metrics['average_processing_time'] > 60:
                recommendations.append("âš¡ ì²˜ë¦¬ ì‹œê°„ì´ ê¸´ í¸ì…ë‹ˆë‹¤. í’ˆì§ˆ ë ˆë²¨ ì¡°ì •ì„ ê³ ë ¤í•˜ì„¸ìš”")
        
        # ë””ë°”ì´ìŠ¤ ê¸°ë°˜ ê¶Œì¥ì‚¬í•­
        if self.device == 'cpu':
            recommendations.append("ğŸš€ GPU ë˜ëŠ” MPS ì‚¬ìš© ì‹œ ì„±ëŠ¥ì´ í¬ê²Œ í–¥ìƒë©ë‹ˆë‹¤")
        
        # ë©”ëª¨ë¦¬ ê¸°ë°˜ ê¶Œì¥ì‚¬í•­
        memory_info = self._get_detailed_memory_usage()
        if 'system_memory' in memory_info:
            memory_percent = float(memory_info['system_memory'].replace('%', ''))
            if memory_percent > 80:
                recommendations.append("ğŸ’¾ ì‹œìŠ¤í…œ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ ë†’ìŠµë‹ˆë‹¤. ë©”ëª¨ë¦¬ ìµœì í™”ë¥¼ í™œì„±í™”í•˜ì„¸ìš”")
        
        # ì—ëŸ¬ ê¸°ë°˜ ê¶Œì¥ì‚¬í•­
        if len(self.error_history) > 0:
            recent_errors = self.error_history[-5:]
            common_error_types = {}
            for error in recent_errors:
                error_type = error.get('error_type', 'unknown')
                common_error_types[error_type] = common_error_types.get(error_type, 0) + 1
            
            if common_error_types:
                most_common = max(common_error_types, key=common_error_types.get)
                recommendations.append(f"ğŸ› ìµœê·¼ '{most_common}' ì˜¤ë¥˜ê°€ ë¹ˆë²ˆí•©ë‹ˆë‹¤. ì‹œìŠ¤í…œ ì ê²€ì´ í•„ìš”í•©ë‹ˆë‹¤")
        
        if not recommendations:
            recommendations.append("âœ… ì‹œìŠ¤í…œì´ ìµœì  ìƒíƒœë¡œ ìš´ì˜ë˜ê³  ìˆìŠµë‹ˆë‹¤")
        
        return recommendations
    
    async def cleanup(self):
        """ì „ì²´ íŒŒì´í”„ë¼ì¸ ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        
        logger.info("ğŸ§¹ ê°œì„ ëœ ê°€ìƒ í”¼íŒ… íŒŒì´í”„ë¼ì¸ ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì¤‘...")
        
        try:
            # ê° ë‹¨ê³„ë³„ ì •ë¦¬
            for step_name, step in self.steps.items():
                try:
                    if hasattr(step, 'cleanup'):
                        await step.cleanup()
                    elif hasattr(step, 'close'):
                        step.close()
                    logger.info(f"âœ… {step_name} ì •ë¦¬ ì™„ë£Œ")
                except Exception as e:
                    logger.warning(f"âš ï¸ {step_name} ì •ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
            
            # ìœ í‹¸ë¦¬í‹° ì •ë¦¬
            if hasattr(self.model_loader, 'cleanup'):
                await self.model_loader.cleanup()
            
            if hasattr(self.memory_manager, 'cleanup'):
                await self.memory_manager.cleanup()
            
            # ìŠ¤ë ˆë“œ í’€ ì •ë¦¬
            if hasattr(self, 'thread_pool'):
                self.thread_pool.shutdown(wait=True)
            
            # ë©”ëª¨ë¦¬ ì •ë¦¬
            self._cleanup_memory()
            
            # ì„¸ì…˜ ë°ì´í„° ì •ë¦¬
            self.session_data.clear()
            
            # ìƒíƒœ ì´ˆê¸°í™”
            self.is_initialized = False
            
            logger.info("âœ… ì „ì²´ íŒŒì´í”„ë¼ì¸ ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"âŒ ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")


# ===================================
# ì‚¬ìš© ì˜ˆì‹œ ë° í…ŒìŠ¤íŠ¸ í•¨ìˆ˜ë“¤
# ===================================

async def demo_pipeline_manager():
    """íŒŒì´í”„ë¼ì¸ ë§¤ë‹ˆì € ë°ëª¨"""
    
    print("ğŸš€ ê°œì„ ëœ 8ë‹¨ê³„ ê°€ìƒ í”¼íŒ… íŒŒì´í”„ë¼ì¸ ë§¤ë‹ˆì € ë°ëª¨ ì‹œì‘")
    
    # íŒŒì´í”„ë¼ì¸ ë§¤ë‹ˆì € ì´ˆê¸°í™”
    pipeline = PipelineManager(
        config_path='config/pipeline_config.json',  # ì„ íƒì 
        device='auto'  # ìµœì  ë””ë°”ì´ìŠ¤ ìë™ ì„ íƒ
    )
    
    # ì´ˆê¸°í™”
    success = await pipeline.initialize()
    if not success:
        print("âŒ íŒŒì´í”„ë¼ì¸ ë§¤ë‹ˆì € ì´ˆê¸°í™” ì‹¤íŒ¨")
        return
    
    # ì§„í–‰ë¥  ì½œë°± í•¨ìˆ˜
    async def progress_callback(stage: str, percentage: int):
        print(f"ğŸ”„ ì§„í–‰ìƒí™©: {stage} - {percentage}%")
    
    # ê°€ìƒ í”¼íŒ… ì‹¤í–‰
    try:
        result = await pipeline.process_complete_virtual_fitting(
            person_image='test_images/person.jpg',  # ì‹¤ì œ ê²½ë¡œë¡œ ë³€ê²½
            clothing_image='test_images/shirt.jpg',  # ì‹¤ì œ ê²½ë¡œë¡œ ë³€ê²½
            body_measurements={
                'height': 175,
                'weight': 70,
                'chest': 95,
                'waist': 80,
                'shoulder_width': 45,
                'hip': 90
            },
            clothing_type='shirt',
            fabric_type='cotton',
            style_preferences={
                'fit': 'slim',
                'color_preference': 'original'
            },
            quality_target=0.85,
            progress_callback=progress_callback,
            save_intermediate=True,  # ì¤‘ê°„ ê²°ê³¼ ì €ì¥
            enable_auto_retry=True   # ìë™ ì¬ì‹œë„ í™œì„±í™”
        )
        
        if result['success']:
            print(f"\nğŸ‰ ê°€ìƒ í”¼íŒ… ì„±ê³µ!")
            print(f"ğŸ“Š ìµœì¢… í’ˆì§ˆ: {result['final_quality_score']:.3f} ({result['quality_grade']})")
            print(f"â±ï¸ ì´ ì²˜ë¦¬ ì‹œê°„: {result['total_processing_time']:.2f}ì´ˆ")
            print(f"ğŸ¯ ëª©í‘œ ë‹¬ì„±: {'âœ…' if result['quality_target_achieved'] else 'âŒ'}")
            print(f"ğŸ”§ ë³µêµ¬ë¨: {'âœ…' if result.get('recovered', False) else 'âŒ'}")
            
            # ê²°ê³¼ ì´ë¯¸ì§€ ì €ì¥
            os.makedirs('output', exist_ok=True)
            result['result_image'].save('output/pipeline_manager_result.jpg')
            print("ğŸ’¾ ê²°ê³¼ ì´ë¯¸ì§€ ì €ì¥ ì™„ë£Œ: output/pipeline_manager_result.jpg")
            
            # ìƒì„¸ ë¶„ì„ ì¶œë ¥
            print(f"\nğŸ“ˆ í’ˆì§ˆ ë¶„ì„:")
            for category, score in result['quality_breakdown'].items():
                print(f"  - {category}: {score:.3f}")
            
            print(f"\nğŸ’¡ ê°œì„  ì œì•ˆ:")
            for category, suggestions in result['improvement_suggestions'].items():
                print(f"  ğŸ“‹ {category}:")
                for suggestion in suggestions[:3]:  # ìƒìœ„ 3ê°œë§Œ
                    print(f"    - {suggestion}")
            
            print(f"\nâ±ï¸ ë‹¨ê³„ë³„ ì²˜ë¦¬ ì‹œê°„:")
            for step, summary in result['step_results_summary'].items():
                if summary['completed']:
                    print(f"  - {step}: {summary['processing_time']:.2f}ì´ˆ ({'âœ…' if summary['success'] else 'âš ï¸'})")
            
            # ì„±ëŠ¥ ë¦¬í¬íŠ¸
            performance_report = await pipeline.get_performance_report()
            print(f"\nğŸ“Š ì„±ëŠ¥ ë¦¬í¬íŠ¸:")
            print(f"  - ì „ì²´ ì„±ê³µë¥ : {performance_report['reliability_metrics']['success_rate']:.1%}")
            print(f"  - í‰ê·  ì²˜ë¦¬ ì‹œê°„: {performance_report['overall_performance']['average_processing_time']:.2f}ì´ˆ")
            print(f"  - í‰ê·  í’ˆì§ˆ ì ìˆ˜: {performance_report['overall_performance']['average_quality_score']:.3f}")
            
        else:
            print(f"âŒ ê°€ìƒ í”¼íŒ… ì‹¤íŒ¨: {result['error']}")
            if result.get('fallback_used'):
                print("ğŸš¨ í´ë°± ê²°ê³¼ê°€ ì œê³µë˜ì—ˆìŠµë‹ˆë‹¤")
            
            # ì˜¤ë¥˜ ìƒì„¸ ì •ë³´
            if 'error_details' in result:
                print(f"ğŸ“‹ ì˜¤ë¥˜ ìƒì„¸: {result['error_details']}")
    
    except Exception as e:
        print(f"ğŸ’¥ ì˜ˆì™¸ ë°œìƒ: {e}")
        print(f"ğŸ“‹ ìƒì„¸: {traceback.format_exc()}")
    
    finally:
        # ë¦¬ì†ŒìŠ¤ ì •ë¦¬
        await pipeline.cleanup()
        print("ğŸ§¹ ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì™„ë£Œ")


async def benchmark_pipeline_manager():
    """íŒŒì´í”„ë¼ì¸ ë§¤ë‹ˆì € ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬"""
    
    print("ğŸ“Š íŒŒì´í”„ë¼ì¸ ë§¤ë‹ˆì € ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ì‹œì‘")
    
    pipeline = PipelineManager(device='auto')
    await pipeline.initialize()
    
    # í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ë“¤ (ì‹¤ì œ ê²½ë¡œë¡œ ë³€ê²½ í•„ìš”)
    test_cases = [
        ('test_images/person1.jpg', 'test_images/shirt1.jpg', 'shirt'),
        ('test_images/person2.jpg', 'test_images/pants1.jpg', 'pants'),
        ('test_images/person3.jpg', 'test_images/dress1.jpg', 'dress')
    ]
    
    results = []
    
    for i, (person_path, clothing_path, clothing_type) in enumerate(test_cases):
        print(f"\nğŸ§ª í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ {i+1}/{len(test_cases)}: {clothing_type}")
        
        try:
            start_time = time.time()
            
            # ë”ë¯¸ ì´ë¯¸ì§€ ìƒì„± (ì‹¤ì œ íŒŒì¼ì´ ì—†ëŠ” ê²½ìš°)
            if not os.path.exists(person_path):
                person_image = Image.new('RGB', (512, 512), color='blue')
            else:
                person_image = person_path
                
            if not os.path.exists(clothing_path):
                clothing_image = Image.new('RGB', (512, 512), color='red')
            else:
                clothing_image = clothing_path
            
            result = await pipeline.process_complete_virtual_fitting(
                person_image=person_image,
                clothing_image=clothing_image,
                clothing_type=clothing_type,
                quality_target=0.8
            )
            
            processing_time = time.time() - start_time
            
            results.append({
                'test_case': i + 1,
                'clothing_type': clothing_type,
                'success': result['success'],
                'processing_time': processing_time,
                'quality_score': result.get('final_quality_score', 0),
                'memory_usage': result.get('memory_usage', {})
            })
            
            print(f"  âœ… ì™„ë£Œ - ì‹œê°„: {processing_time:.2f}ì´ˆ, í’ˆì§ˆ: {result.get('final_quality_score', 0):.3f}")
            
        except Exception as e:
            print(f"  âŒ ì‹¤íŒ¨: {e}")
            results.append({
                'test_case': i + 1,
                'clothing_type': clothing_type,
                'success': False,
                'error': str(e)
            })
    
    # ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ ìš”ì•½
    print(f"\nğŸ“ˆ ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ ìš”ì•½:")
    successful_tests = [r for r in results if r['success']]
    
    if successful_tests:
        avg_time = np.mean([r['processing_time'] for r in successful_tests])
        avg_quality = np.mean([r['quality_score'] for r in successful_tests])
        success_rate = len(successful_tests) / len(results)
        
        print(f"  - ì„±ê³µë¥ : {success_rate:.1%}")
        print(f"  - í‰ê·  ì²˜ë¦¬ ì‹œê°„: {avg_time:.2f}ì´ˆ")
        print(f"  - í‰ê·  í’ˆì§ˆ ì ìˆ˜: {avg_quality:.3f}")
        print(f"  - ìµœê³  ì„±ëŠ¥: {min(r['processing_time'] for r in successful_tests):.2f}ì´ˆ")
        print(f"  - ìµœê³  í’ˆì§ˆ: {max(r['quality_score'] for r in successful_tests):.3f}")
    
    await pipeline.cleanup()
    
    return results


# ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
if __name__ == "__main__":
    print("ğŸ½ ê°œì„ ëœ ì™„ì „í•œ 8ë‹¨ê³„ ê°€ìƒ í”¼íŒ… íŒŒì´í”„ë¼ì¸ ë§¤ë‹ˆì €")
    print("=" * 60)
    
    # ë°ëª¨ ì‹¤í–‰
    asyncio.run(demo_pipeline_manager())
    
    # ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰ (ì„ íƒì )
    # asyncio.run(benchmark_pipeline_manager())