# backend/app/main.py
"""
ğŸ”¥ MyCloset AI Backend - Central Hub DI Container v7.0 ì™„ì „ ì—°ë™ v30.0
================================================================================

âœ… ì‹¤ì œ ë°±ì—”ë“œ í´ë” êµ¬ì¡° ê¸°ë°˜ ì™„ì „ ì—°ë™
âœ… í”„ë¡ íŠ¸ì—”ë“œ í˜¸í™˜ì„± 100% ë³´ì¥
âœ… Central Hub DI Container v7.0 ì™„ì „ ì—°ë™
âœ… ìˆœí™˜ì°¸ì¡° ì™„ì „ í•´ê²° - TYPE_CHECKING + ì§€ì—° import ì™„ë²½ ì ìš©
âœ… ë‹¨ë°©í–¥ ì˜ì¡´ì„± ê·¸ë˜í”„ - DI Containerë§Œì„ í†µí•œ ì˜ì¡´ì„± ì£¼ì…
âœ… StepServiceManager v17.0 + RealAIStepImplementationManager v16.0 ì™„ì „ í†µí•©
âœ… step_routes.py v7.0 ì™„ë²½ ì—°ë™ (ëª¨ë“  ê¸°ëŠ¥ ë³µêµ¬)
âœ… step_implementations.py DetailedDataSpec ì™„ì „ í™œìš©
âœ… ì‹¤ì œ 229GB AI ëª¨ë¸ íŒŒì´í”„ë¼ì¸ ì™„ì „ í™œìš©
âœ… conda í™˜ê²½ mycloset-ai-clean ìµœì í™”
âœ… M3 Max 128GB ë©”ëª¨ë¦¬ ìµœì í™”
âœ… WebSocket ì‹¤ì‹œê°„ ì§„í–‰ë¥  ì§€ì› (ì™„ì „ ë³µêµ¬)
âœ… ì„¸ì…˜ ê¸°ë°˜ ì´ë¯¸ì§€ ê´€ë¦¬ ì™„ì „ êµ¬í˜„
âœ… í”„ë¡œë•ì…˜ ë ˆë²¨ ì•ˆì •ì„± ë° ì—ëŸ¬ ì²˜ë¦¬
âœ… ëª¨ë“  ëˆ„ë½ëœ ì—”ë“œí¬ì¸íŠ¸ ë° ê¸°ëŠ¥ ë³µêµ¬

í•µì‹¬ ì„¤ê³„ ì›ì¹™:
1. Single Source of Truth - ëª¨ë“  ì„œë¹„ìŠ¤ëŠ” Central Hub DI Containerë¥¼ ê±°ì¹¨
2. Central Hub Pattern - DI Containerê°€ ëª¨ë“  ì»´í¬ë„ŒíŠ¸ì˜ ì¤‘ì‹¬
3. Dependency Inversion - ìƒìœ„ ëª¨ë“ˆì´ í•˜ìœ„ ëª¨ë“ˆì„ ì œì–´
4. Zero Circular Reference - ìˆœí™˜ì°¸ì¡° ì›ì²œ ì°¨ë‹¨

ìƒˆë¡œìš´ í†µí•© ì•„í‚¤í…ì²˜ (Central Hub DI Container v7.0 ì¤‘ì‹¬):
main.py â†’ Central Hub DI Container v7.0 â†’ StepServiceManager v17.0 â†’ 
RealAIStepImplementationManager v16.0 â†’ StepFactory v11.0 â†’ 
BaseStepMixin v20.0 â†’ ì‹¤ì œ 229GB AI ëª¨ë¸

Author: MyCloset AI Team
Date: 2025-08-01
Version: 30.0.0 (Production Ready Frontend Integration)
"""

import os
import sys
import logging
import time
import gc
import warnings
import traceback
import subprocess
import platform
import psutil
import json
import uuid
import threading
import asyncio
from pathlib import Path
from datetime import datetime, timedelta
from contextlib import asynccontextmanager
from typing import Dict, Any, Optional, List, Union, Callable, Tuple

# ê²½ê³  ë¬´ì‹œ
warnings.filterwarnings('ignore')
os.environ['PYTHONWARNINGS'] = 'ignore'
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'

# MediaPipe ë° TensorFlow Lite ê²½ê³  ë¬´ì‹œ ì¶”ê°€
os.environ['MEDIAPIPE_DISABLE_GPU'] = '1'  # GPU ê´€ë ¨ ê²½ê³  ë¬´ì‹œ
os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'  # TensorFlow ìµœì í™” ê²½ê³  ë¬´ì‹œ
os.environ['ABSL_LOGGING_MIN_LEVEL'] = '2'  # absl ë¡œê¹… ë ˆë²¨ ì„¤ì •

# ì¶”ê°€ ê²½ê³  í•„í„°ë§
warnings.filterwarnings('ignore', category=UserWarning, module='mediapipe')
warnings.filterwarnings('ignore', category=UserWarning, module='tensorflow')
warnings.filterwarnings('ignore', category=UserWarning, module='absl')
warnings.filterwarnings('ignore', message='.*inference_feedback_manager.*')
warnings.filterwarnings('ignore', message='.*landmark_projection_calculator.*')

# ë¡œê·¸ ë ˆë²¨ ì¡°ì • (ì„œë²„ ì‹œì‘ ì‹œ ê°„ë‹¨ ìš”ì•½, API í˜¸ì¶œ ì‹œ ìƒì„¸ ë¡œê·¸)
import logging
import os
import sys

# í™˜ê²½ë³€ìˆ˜ë¡œ ì¶œë ¥ ì œì–´ - ì„œë²„ ì‹œì‘ ì‹œ ê°„ë‹¨ ìš”ì•½, API í˜¸ì¶œ ì‹œ ìƒì„¸ ë¡œê·¸
QUIET_MODE = os.getenv('QUIET_MODE', 'true').lower() == 'true'  # ì„œë²„ ì‹œì‘ ì‹œ ê°„ë‹¨ ëª¨ë“œ (ê¸°ë³¸ê°’: true)
STEP_LOGGING = os.getenv('STEP_LOGGING', 'true').lower() == 'true'  # API í˜¸ì¶œ ì‹œ ìƒì„¸ ë¡œê·¸
MODEL_LOGGING = os.getenv('MODEL_LOGGING', 'false').lower() == 'true'  # ëª¨ë¸ ë¡œë”© ë¡œê¹… ë¹„í™œì„±í™” (ê¸°ë³¸ê°’: false)

# ì„œë²„ ì‹œì‘ ì‹œì—ëŠ” ê°„ë‹¨í•œ ìš”ì•½ë§Œ, API í˜¸ì¶œ ì‹œì—ëŠ” ìƒì„¸ ë¡œê·¸
if QUIET_MODE:
    # ì„œë²„ ì‹œì‘ ì‹œ: INFO ë¡œê·¸ ì°¨ë‹¨, ERRORë§Œ í‘œì‹œ
    logging.disable(logging.INFO)
    os.environ['LOG_LEVEL'] = 'ERROR'
    os.environ['LOG_MODE'] = 'startup_summary'
else:
    # API í˜¸ì¶œ ì‹œ: ìƒì„¸ ë¡œê·¸ í‘œì‹œ
    logging.disable(logging.DEBUG)
    os.environ['LOG_LEVEL'] = 'INFO'
    os.environ['LOG_MODE'] = 'api_detailed'

# ë£¨íŠ¸ ë¡œê±° ì„¤ì •
root_logger = logging.getLogger()
root_logger.handlers.clear()
if QUIET_MODE:
    root_logger.setLevel(logging.ERROR)
else:
    root_logger.setLevel(logging.INFO)

# ëª¨ë“  ë¡œê±°ì˜ í•¸ë“¤ëŸ¬ ì œê±° ë° ë ˆë²¨ ì„¤ì •
for name in logging.root.manager.loggerDict:
    logger = logging.getLogger(name)
    logger.handlers.clear()
    if QUIET_MODE:
        logger.setLevel(logging.ERROR)
        logger.propagate = True
    else:
        logger.setLevel(logging.INFO)
        logger.propagate = True

# íŠ¹ì • ëª¨ë“ˆë“¤ì˜ ë¡œê·¸ ì™„ì „ ì°¨ë‹¨
quiet_modules = [
    'app.core',
    'app.services', 
    'app.api',
    'backend.app',
    'transformers',
    'torch',
    'torchvision',
    'PIL',
    'cv2',
    'numpy',
    'segformer',
    'uvicorn',
    'fastapi',
    'uvicorn.access',
    'uvicorn.error',
    'step_model_requests',
    'step_interface',
    'di_container',
    'step_service'
]

# Step ê´€ë ¨ ëª¨ë“ˆì€ ì¡°ê±´ë¶€ë¡œ ë¡œê¹… í™œì„±í™”
if STEP_LOGGING:
    step_modules = [
        'app.ai_pipeline.steps',
        'app.ai_pipeline.steps.step_01_human_parsing',
        'app.ai_pipeline.steps.step_02_pose_estimation',
        'app.ai_pipeline.steps.step_03_cloth_segmentation',
        'app.ai_pipeline.steps.step_04_geometric_matching',
        'app.ai_pipeline.steps.step_05_cloth_warping',
        'app.ai_pipeline.steps.step_06_virtual_fitting',
        'app.ai_pipeline.steps.step_07_post_processing',
        'app.ai_pipeline.steps.step_08_quality_assessment'
    ]
    for module in step_modules:
        logger = logging.getLogger(module)
        logger.setLevel(logging.INFO)
else:
    quiet_modules.extend([
        'app.ai_pipeline.steps',
        'app.ai_pipeline.steps.step_01_human_parsing',
        'app.ai_pipeline.steps.step_02_pose_estimation',
        'app.ai_pipeline.steps.step_03_cloth_segmentation',
        'app.ai_pipeline.steps.step_04_geometric_matching',
        'app.ai_pipeline.steps.step_05_cloth_warping',
        'app.ai_pipeline.steps.step_06_virtual_fitting',
        'app.ai_pipeline.steps.step_07_post_processing',
        'app.ai_pipeline.steps.step_08_quality_assessment'
    ])

# ëª¨ë¸ ë¡œë”© ê´€ë ¨ ëª¨ë“ˆì€ ì¡°ê±´ë¶€ë¡œ ë¡œê¹… í™œì„±í™”
model_modules = [
    'app.ai_pipeline.models.model_loader',  # âœ… ìƒˆ ìœ„ì¹˜ë¡œ ìˆ˜ì •
    'app.ai_pipeline.utils.enhanced_model_loader',  # âœ… ì‹¤ì œ ì¡´ì¬
    'app.ai_pipeline.utils.universal_step_loader',  # âœ… ì‹¤ì œ ì¡´ì¬
    'app.ai_pipeline.utils.memory_manager',  # âœ… ì‹¤ì œ ì¡´ì¬
    'app.ai_pipeline.utils.data_converter',  # âœ… ì‹¤ì œ ì¡´ì¬
    'app.ai_pipeline.utils.checkpoint_analyzer',  # âœ… ì‹¤ì œ ì¡´ì¬
    'app.core.model_paths',  # âœ… ì‹¤ì œ ì¡´ì¬
    'app.core.optimized_model_paths',  # âœ… ì‹¤ì œ ì¡´ì¬
    'app.core.di_container'  # âœ… ì‹¤ì œ ì¡´ì¬
]

if MODEL_LOGGING:
    for module in model_modules:
        logger = logging.getLogger(module)
        logger.setLevel(logging.INFO)
        logger.propagate = True
else:
    quiet_modules.extend(model_modules)

# ëª¨ë“  quiet ëª¨ë“ˆì˜ ë¡œê·¸ ì™„ì „ ì°¨ë‹¨
for module in quiet_modules:
    logger = logging.getLogger(module)
    logger.handlers.clear()
    logger.setLevel(logging.CRITICAL)
    logger.propagate = False

# í•µì‹¬ ì •ë³´ë§Œ ì¶œë ¥í•˜ëŠ” ê°„ë‹¨í•œ í•¨ìˆ˜
def print_status(message):
    """í•µì‹¬ ìƒíƒœ ì •ë³´ë§Œ ì¶œë ¥"""
    if not QUIET_MODE:
        print(f"âœ… {message}")

def print_error(message):
    """ì—ëŸ¬ ì •ë³´ë§Œ ì¶œë ¥"""
    print(f"âŒ {message}")

def print_warning(message):
    """ê²½ê³  ì •ë³´ë§Œ ì¶œë ¥"""
    if not QUIET_MODE:
        print(f"âš ï¸ {message}")

def print_step(message):
    """Step ì‹¤í–‰ ì •ë³´ë§Œ ì¶œë ¥"""
    if STEP_LOGGING:
        print(f"ğŸ”§ {message}")

def print_model(message):
    """ëª¨ë¸ ë¡œë”© ì •ë³´ë§Œ ì¶œë ¥"""
    if MODEL_LOGGING:
        print(f"ğŸ§  {message}")

if not QUIET_MODE:
    print("ğŸ”‡ ë¡œê·¸ ì¶œë ¥ ìµœì†Œí™” ì™„ë£Œ (Step ë¡œê¹…: " + ("í™œì„±í™”" if STEP_LOGGING else "ë¹„í™œì„±í™”") + ", ëª¨ë¸ ë¡œê¹…: " + ("í™œì„±í™”" if MODEL_LOGGING else "ë¹„í™œì„±í™”") + ")")

# =============================================================================
# ğŸ”¥ 1. ì‹¤í–‰ ê²½ë¡œ ìë™ ìˆ˜ì • ë° ì‹œìŠ¤í…œ ì •ë³´
# =============================================================================

def fix_python_path():
    """ì‹¤í–‰ ê²½ë¡œì— ê´€ê³„ì—†ì´ Python Path ìë™ ìˆ˜ì •"""
    current_file = Path(__file__).absolute()
    app_dir = current_file.parent       # backend/app
    backend_dir = app_dir.parent        # backend
    project_root = backend_dir.parent   # mycloset-ai
    
    # Python Pathì— í•„ìš”í•œ ê²½ë¡œë“¤ ì¶”ê°€
    paths_to_add = [
        str(backend_dir),    # backend/ (ê°€ì¥ ì¤‘ìš”!)
        str(app_dir),        # backend/app/
        str(project_root)    # mycloset-ai/
    ]
    
    for path in paths_to_add:
        if path not in sys.path:
            sys.path.insert(0, path)
    
    # í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
    os.environ.update({
        'PYTHONPATH': f"{backend_dir}:{os.environ.get('PYTHONPATH', '')}",
        'PROJECT_ROOT': str(project_root),
        'BACKEND_ROOT': str(backend_dir),
        'APP_ROOT': str(app_dir)
    })
    
    # ì‘ì—… ë””ë ‰í† ë¦¬ë¥¼ backendë¡œ ë³€ê²½
    if Path.cwd() != backend_dir:
        try:
            os.chdir(backend_dir)
        except OSError:
            pass
    
    return {
        'app_dir': str(app_dir),
        'backend_dir': str(backend_dir),
        'project_root': str(project_root)
    }

# ì¤‘ë³µ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë”© ë°©ì§€ í”Œë˜ê·¸
_libraries_loaded = False

# Python Path ìˆ˜ì • ì‹¤í–‰
path_info = fix_python_path()

def detect_system_info():
    """ì‹œìŠ¤í…œ ì •ë³´ ì§ì ‘ ê°ì§€"""
    system_info = {
        'platform': platform.system(),
        'python_version': platform.python_version(),
        'cpu_count': os.cpu_count() or 4
    }
    
    # conda í™˜ê²½ ê°ì§€
    is_conda = (
        'CONDA_DEFAULT_ENV' in os.environ or
        'CONDA_PREFIX' in os.environ or
        'conda' in sys.executable.lower()
    )
    system_info['is_conda'] = is_conda
    system_info['conda_env'] = os.environ.get('CONDA_DEFAULT_ENV', 'none')
    system_info['is_mycloset_env'] = system_info['conda_env'] == 'mycloset-ai-clean'
    
    # M3 Max ê°ì§€
    is_m3_max = False
    if platform.system() == 'Darwin':
        try:
            result = subprocess.run(
                ['sysctl', '-n', 'machdep.cpu.brand_string'], 
                capture_output=True, text=True, timeout=5
            )
            chip_info = result.stdout.strip()
            is_m3_max = 'M3' in chip_info and 'Max' in chip_info
        except:
            pass
    
    system_info['is_m3_max'] = is_m3_max
    
    # ë©”ëª¨ë¦¬ ì •ë³´
    try:
        system_info['memory_gb'] = round(psutil.virtual_memory().total / (1024**3), 1)
    except:
        system_info['memory_gb'] = 16.0
    
    return system_info

# ì‹œìŠ¤í…œ ì •ë³´ ê°ì§€
SYSTEM_INFO = detect_system_info()
IS_CONDA = SYSTEM_INFO['is_conda']
IS_M3_MAX = SYSTEM_INFO['is_m3_max']
IS_MYCLOSET_ENV = SYSTEM_INFO['is_mycloset_env']

print_status("ì‹œìŠ¤í…œ ì •ë³´ ê°ì§€ ì™„ë£Œ")

# =============================================================================
# ğŸ”¥ 2. ë¡œê¹… ì„¤ì •
# =============================================================================

# ì¤‘ë³µ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë”© ë°©ì§€
if not _libraries_loaded:
    # ë¡œê¹… ì„¤ì •ì€ logging_config.pyì—ì„œ ìë™ìœ¼ë¡œ ì²˜ë¦¬ë¨
    try:
        from app.core.logging_config import get_logger
        logger = get_logger(__name__)
        _libraries_loaded = True
    except ImportError:
        # í´ë°± ë¡œê±° ìƒì„±
        import logging
        logging.basicConfig(level=logging.INFO)
        logger = logging.getLogger(__name__)
        _libraries_loaded = True
else:
    # ì´ë¯¸ ë¡œë”©ëœ ê²½ìš° ê¸°ì¡´ ë¡œê±° ì‚¬ìš©
    logger = logging.getLogger(__name__)

# =============================================================================
# ğŸ”¥ 3. í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ import (ìµœì í™”)
# =============================================================================

# FastAPI ë¼ì´ë¸ŒëŸ¬ë¦¬ import
try:
    from fastapi import FastAPI, Request, HTTPException, WebSocket, WebSocketDisconnect, BackgroundTasks, Depends
    from fastapi.middleware.cors import CORSMiddleware
    from fastapi.middleware.gzip import GZipMiddleware
    from fastapi.responses import JSONResponse, FileResponse, HTMLResponse
    from fastapi.staticfiles import StaticFiles
    import uvicorn
    
    print_status("âœ… FastAPI ë¼ì´ë¸ŒëŸ¬ë¦¬ import ì„±ê³µ")
    
except ImportError as e:
    print_error(f"âŒ FastAPI ë¼ì´ë¸ŒëŸ¬ë¦¬ import ì‹¤íŒ¨: {e}")
    print_error("ì„¤ì¹˜ ëª…ë ¹: conda install fastapi uvicorn python-multipart websockets")
    sys.exit(1)

# PyTorch ì•ˆì „ import (ì¤‘ë³µ ë°©ì§€)
TORCH_AVAILABLE = False
DEVICE = 'cpu'

if not hasattr(sys.modules[__name__], '_torch_imported'):
    try:
        os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '1'
        os.environ['PYTORCH_MPS_HIGH_WATERMARK_RATIO'] = '0.0'
        
        import torch
        TORCH_AVAILABLE = True
        
        # ë””ë°”ì´ìŠ¤ ê°ì§€
        if torch.backends.mps.is_available() and IS_M3_MAX:
            DEVICE = 'mps'
            print_status("âœ… PyTorch MPS (M3 Max) ì‚¬ìš©")
        elif torch.cuda.is_available():
            DEVICE = 'cuda'
            print_status("âœ… PyTorch CUDA ì‚¬ìš©")
        else:
            DEVICE = 'cpu'
            print_status("âœ… PyTorch CPU ì‚¬ìš©")
        
        # ì¤‘ë³µ import ë°©ì§€ í”Œë˜ê·¸ ì„¤ì •
        sys.modules[__name__]._torch_imported = True
        
    except ImportError:
        print_warning("âš ï¸ PyTorch import ì‹¤íŒ¨")
        sys.modules[__name__]._torch_imported = True  # ì‹¤íŒ¨í•´ë„ í”Œë˜ê·¸ ì„¤ì •

# =============================================================================
# ğŸ”¥ 4. Central Hub DI Container v7.0 ìš°ì„  ì´ˆê¸°í™” (í•µì‹¬!)
# =============================================================================

CENTRAL_HUB_CONTAINER_AVAILABLE = False
central_hub_container = None

# ì¤‘ë³µ ì´ˆê¸°í™” ë°©ì§€
if not hasattr(sys.modules[__name__], '_di_container_initialized'):
    try:
        print_status("ğŸ”¥ Central Hub DI Container v7.0 ìš°ì„  ì´ˆê¸°í™” ì¤‘...")
        from app.core.di_container import (
            get_global_container,
            initialize_di_system,
            get_global_manager,
            CentralHubDIContainer,
            ServiceRegistry,
            PropertyInjectionMixin
        )
        
        # DI ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        initialize_di_system()
        
        # ì „ì—­ Central Hub Container ê°€ì ¸ì˜¤ê¸°
        central_hub_container = get_global_container()
        
        if central_hub_container:
            CENTRAL_HUB_CONTAINER_AVAILABLE = True
            print_status(f"âœ… Central Hub DI Container v7.0 ì´ˆê¸°í™” ì™„ë£Œ!")
            print_status(f"ğŸ“Š Container ID: {getattr(central_hub_container, 'container_id', 'default')}")
            
            # Containerì— ì‹œìŠ¤í…œ ì •ë³´ ë“±ë¡
            central_hub_container.register('system_info', SYSTEM_INFO)
            central_hub_container.register('device', DEVICE)
            central_hub_container.register('is_m3_max', IS_M3_MAX)
            central_hub_container.register('is_conda', IS_CONDA)
            central_hub_container.register('is_mycloset_env', IS_MYCLOSET_ENV)
            
            print_status(f"ğŸ”¥ ì¤‘ì•™ í—ˆë¸Œ DI Container - ëª¨ë“  ì˜ì¡´ì„± ê´€ë¦¬ì˜ ë‹¨ì¼ ì¤‘ì‹¬")
        else:
            print_error("âŒ Central Hub DI Container ì´ˆê¸°í™” ì‹¤íŒ¨")
        
        # ì¤‘ë³µ ì´ˆê¸°í™” ë°©ì§€ í”Œë˜ê·¸ ì„¤ì •
        sys.modules[__name__]._di_container_initialized = True
        
    except ImportError as e:
        print_error(f"âŒ Central Hub DI Container import ì‹¤íŒ¨: {e}")
        CENTRAL_HUB_CONTAINER_AVAILABLE = False
        sys.modules[__name__]._di_container_initialized = True
    except Exception as e:
        print_error(f"âŒ Central Hub DI Container ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        CENTRAL_HUB_CONTAINER_AVAILABLE = False
        sys.modules[__name__]._di_container_initialized = True
else:
    print_status("âœ… Central Hub DI Container ì´ë¯¸ ì´ˆê¸°í™”ë¨")

# =============================================================================
# ğŸ”¥ 5. ì „ì—­ ì‹œìŠ¤í…œ ë³€ìˆ˜ ì„¤ì • (API ëª¨ë“ˆ í˜¸í™˜ì„±)
# =============================================================================

# API ëª¨ë“ˆì—ì„œ í•„ìš”í•œ ì „ì—­ ë³€ìˆ˜ë“¤ì„ ë¨¼ì € ì„¤ì •
CONDA_ENV = SYSTEM_INFO['conda_env']
MEMORY_GB = SYSTEM_INFO['memory_gb']

# í™˜ê²½ ë³€ìˆ˜ì—ë„ ì„¤ì •í•˜ì—¬ í•˜ìœ„ ëª¨ë“ˆì—ì„œ ì ‘ê·¼ ê°€ëŠ¥í•˜ë„ë¡ í•¨
os.environ['MYCLOSET_CONDA_ENV'] = CONDA_ENV
os.environ['MYCLOSET_MEMORY_GB'] = str(MEMORY_GB)
os.environ['MYCLOSET_DEVICE'] = DEVICE
os.environ['MYCLOSET_IS_M3_MAX'] = str(IS_M3_MAX)
os.environ['MYCLOSET_IS_CONDA'] = str(IS_CONDA)
os.environ['MYCLOSET_IS_MYCLOSET_ENV'] = str(IS_MYCLOSET_ENV)

# =============================================================================
# ğŸ”¥ 6. ì„¤ì • ëª¨ë“ˆ import (ê²½ë¡œ ìˆ˜ì •)
# =============================================================================

try:
    # ì ˆëŒ€ ê²½ë¡œë¡œ config ëª¨ë“ˆ import (ê°€ì¥ ì•ˆì •ì )
    from app.core.config import get_settings
    settings = get_settings()
    print_status("âœ… ì„¤ì • ëª¨ë“ˆ import ì„±ê³µ (ì ˆëŒ€ ê²½ë¡œ)")
except ImportError as e1:
    try:
        # ì§ì ‘ ê²½ë¡œë¡œ config ëª¨ë“ˆ import
        import sys
        core_path = os.path.join(os.path.dirname(__file__), 'core')
        if core_path not in sys.path:
            sys.path.append(core_path)
        from config import get_settings
        settings = get_settings()
        print_status("âœ… ì„¤ì • ëª¨ë“ˆ import ì„±ê³µ (ì§ì ‘ ê²½ë¡œ)")
    except ImportError as e2:
        try:
            # ìƒëŒ€ ê²½ë¡œë¡œ config ëª¨ë“ˆ import
            from .core.config import get_settings
            settings = get_settings()
            print_status("âœ… ì„¤ì • ëª¨ë“ˆ import ì„±ê³µ (ìƒëŒ€ ê²½ë¡œ)")
        except ImportError as e3:
            print_warning(f"âš ï¸ ì„¤ì • ëª¨ë“ˆ import ì‹¤íŒ¨ - ëª¨ë“  ê²½ë¡œ ì‹œë„ ì‹¤íŒ¨")
            print_warning(f"   - ì ˆëŒ€ ê²½ë¡œ: {e1}")
            print_warning(f"   - ì§ì ‘ ê²½ë¡œ: {e2}")
            print_warning(f"   - ìƒëŒ€ ê²½ë¡œ: {e3}")
            
            # í´ë°± ì„¤ì •
            class Settings:
                APP_NAME = "MyCloset AI"
                DEBUG = True
                HOST = "0.0.0.0"
                PORT = 8000
                CORS_ORIGINS = [
                    "http://localhost:3000",
                    "http://127.0.0.1:3000",
                    "http://localhost:5173",
                    "http://127.0.0.1:5173"
                ]
                DEVICE = DEVICE
                USE_GPU = TORCH_AVAILABLE
                IS_M3_MAX = IS_M3_MAX
                IS_CONDA = IS_CONDA
                IS_MYCLOSET_ENV = IS_MYCLOSET_ENV
            
            settings = Settings()
            print_status("âœ… í´ë°± ì„¤ì • ì‚¬ìš©")

# =============================================================================
# ğŸ”¥ 7. Central Hub ê¸°ë°˜ í•µì‹¬ ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
# =============================================================================

# StepServiceManager Central Hub ë“±ë¡
STEP_SERVICE_MANAGER_AVAILABLE = False
step_service_manager = None

async def _register_core_services_to_central_hub(container):
    """í•µì‹¬ ì„œë¹„ìŠ¤ë“¤ì„ Central Hubì— ë“±ë¡"""
    try:
        print_status("ğŸ”„ í•µì‹¬ ì„œë¹„ìŠ¤ë“¤ Central Hub ë“±ë¡ ì¤‘...")
        
        # ğŸ”¥ ModelLoader ë“±ë¡ (ì¤‘ì•™ í†µí•© ModelLoader v7.0 ì‹¤ì œ ì‚¬ìš©)
        try:
            print_status("ğŸ”„ ì¤‘ì•™ í†µí•© ModelLoader v7.0 ë“±ë¡ ì‹œì‘...")
            
            # ì¤‘ì•™ í†µí•© ModelLoader v7.0 ë¡œë“œ ë° ì´ˆê¸°í™”
            try:
                from app.ai_pipeline.models.model_loader import CentralModelLoader
                
                # CentralModelLoader ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
                model_loader = CentralModelLoader()
                print_status("âœ… ì¤‘ì•™ í†µí•© ModelLoader v7.0 ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ì„±ê³µ")
                
                # Step ë¡œë”ë“¤ ì´ˆê¸°í™” (ì‹¤ì œ AI ì¶”ë¡ ì„ ìœ„í•œ í•µì‹¬ ë‹¨ê³„)
                try:
                    model_loader.initialize_step_loaders()
                    print_status("âœ… Step ëª¨ë¸ ë¡œë”ë“¤ ì´ˆê¸°í™” ì„±ê³µ")
                    
                    # ì´ˆê¸°í™”ëœ Step ë¡œë” ì •ë³´ ì¶œë ¥
                    if hasattr(model_loader, 'step_loaders'):
                        step_count = len(model_loader.step_loaders)
                        step_names = list(model_loader.step_loaders.keys())
                        print_status(f"   - ë“±ë¡ëœ Step ë¡œë”: {step_count}ê°œ")
                        print_status(f"   - Step ëª©ë¡: {', '.join(step_names)}")
                    
                except Exception as e:
                    print_warning(f"âš ï¸ Step ëª¨ë¸ ë¡œë”ë“¤ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                    # ì´ˆê¸°í™” ì‹¤íŒ¨í•´ë„ ModelLoaderëŠ” ì‚¬ìš© ê°€ëŠ¥
                
                # Central Hubì— ModelLoader ë“±ë¡
                container.register('model_loader', model_loader)
                container.register('central_model_loader', model_loader)  # ë³„ì¹­ìœ¼ë¡œë„ ë“±ë¡
                print_status("âœ… ì¤‘ì•™ í†µí•© ModelLoader v7.0 Central Hub ë“±ë¡ ì™„ë£Œ")
                
                # ModelLoader ìƒì„¸ ì •ë³´ ì¶œë ¥
                try:
                    # ë””ë°”ì´ìŠ¤ ì •ë³´
                    if hasattr(model_loader, 'device'):
                        print_status(f"   - ë””ë°”ì´ìŠ¤: {model_loader.device}")
                    else:
                        print_status(f"   - ë””ë°”ì´ìŠ¤: {DEVICE} (ê¸°ë³¸ê°’)")
                    
                    # ì¤‘ì•™ í—ˆë¸Œ ì—°ë™ ìƒíƒœ
                    if hasattr(model_loader, 'central_hub'):
                        print_status(f"   - ì¤‘ì•™ í—ˆë¸Œ ì—°ë™: {model_loader.central_hub is not None}")
                    
                    # Stepë³„ ëª¨ë¸ ë¡œë”© ìƒíƒœ í™•ì¸
                    if hasattr(model_loader, 'step_loaders'):
                        for step_name, step_loader in model_loader.step_loaders.items():
                            if hasattr(step_loader, 'models'):
                                model_count = len(step_loader.models) if step_loader.models else 0
                                print_status(f"   - {step_name}: {model_count}ê°œ ëª¨ë¸")
                            else:
                                print_status(f"   - {step_name}: ê¸°ë³¸ ëª¨ë¸")
                    
                except Exception as e:
                    print_warning(f"   - ìƒì„¸ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {e}")
                
            except ImportError as e:
                print_error(f"âŒ ì¤‘ì•™ í†µí•© ModelLoader import ì‹¤íŒ¨: {e}")
                print_error("âŒ app.ai_pipeline.models.model_loader ëª¨ë“ˆì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                # í´ë°±: ê¸°ë³¸ ModelLoader ìƒì„±
                print_status("ğŸ”„ í´ë°± ModelLoader ìƒì„± ì‹œë„...")
                model_loader = _create_fallback_model_loader()
                if model_loader:
                    container.register('model_loader', model_loader)
                    container.register('central_model_loader', model_loader)
                    print_status("âœ… í´ë°± ModelLoader ë“±ë¡ ì™„ë£Œ")
                else:
                    raise ImportError(f"ì¤‘ì•™ í†µí•© ModelLoader ëª¨ë“ˆì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {e}")
                
            except Exception as e:
                print_error(f"âŒ ì¤‘ì•™ í†µí•© ModelLoader ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                print_error(f"âŒ ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
                # í´ë°±: ê¸°ë³¸ ModelLoader ìƒì„±
                print_status("ğŸ”„ í´ë°± ModelLoader ìƒì„± ì‹œë„...")
                model_loader = _create_fallback_model_loader()
                if model_loader:
                    container.register('model_loader', model_loader)
                    container.register('central_model_loader', model_loader)
                    print_status("âœ… í´ë°± ModelLoader ë“±ë¡ ì™„ë£Œ")
                else:
                    raise RuntimeError(f"ì¤‘ì•™ í†µí•© ModelLoader ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                
        except Exception as e:
            print_error(f"âŒ ModelLoader ë“±ë¡ ì™„ì „ ì‹¤íŒ¨: {e}")
            print_error(f"âŒ ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
            # ìµœí›„ì˜ ìˆ˜ë‹¨: Mock ModelLoader ë“±ë¡
            mock_loader = _create_mock_model_loader()
            container.register('model_loader', mock_loader)
            container.register('central_model_loader', mock_loader)
            print_status("âœ… Mock ModelLoader ë“±ë¡ ì™„ë£Œ")
        
        # StepServiceManager ë“±ë¡ (ì‹¤ì œ ë°±ì—”ë“œ ëª¨ë“ˆ ê¸°ë°˜)
        try:
            print_status("ğŸ”„ StepServiceManager ë“±ë¡ ì‹œì‘...")
            
            step_service_manager = None
            
            # 1ì°¨ ì‹œë„: app.services.step_service (ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ëª¨ë“ˆ)
            try:
                from app.services.step_service import (
                    StepServiceManager,
                    get_step_service_manager,
                    get_step_service_manager_async
                )
                
                # ë¹„ë™ê¸° í•¨ìˆ˜ë¡œ ê°€ì ¸ì˜¤ê¸°
                step_service_manager = await get_step_service_manager_async()
                print_status("âœ… StepServiceManager v17.0 ë¡œë“œ ì„±ê³µ")
                
            except ImportError as e:
                print_warning(f"âš ï¸ StepServiceManager import ì‹¤íŒ¨: {e}")
            except Exception as e:
                print_warning(f"âš ï¸ StepServiceManager ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            
            # 2ì°¨ ì‹œë„: ì§ì ‘ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
            if not step_service_manager:
                try:
                    from app.services.step_service import StepServiceManager
                    step_service_manager = StepServiceManager()
                    print_status("âœ… StepServiceManager ì§ì ‘ ìƒì„± ì„±ê³µ")
                except Exception as e:
                    print_warning(f"âš ï¸ StepServiceManager ì§ì ‘ ìƒì„± ì‹¤íŒ¨: {e}")
            
            # ìµœì¢… ë“±ë¡
            if step_service_manager:
                container.register('step_service_manager', step_service_manager)
                print_status("âœ… StepServiceManager Central Hub ë“±ë¡ ì™„ë£Œ")
                
                global STEP_SERVICE_MANAGER_AVAILABLE
                STEP_SERVICE_MANAGER_AVAILABLE = True
                
                # StepServiceManager í†µê³„ í™•ì¸ (ì•ˆì „í•œ ë°©ì‹)
                try:
                    if hasattr(step_service_manager, 'get_status'):
                        status = step_service_manager.get_status()
                        print_status(f"   - ìƒíƒœ: {status}")
                    elif hasattr(step_service_manager, 'status'):
                        print_status(f"   - ìƒíƒœ: {step_service_manager.status}")
                    elif hasattr(step_service_manager, 'get_service_status'):
                        status = step_service_manager.get_service_status()
                        print_status(f"   - ì„œë¹„ìŠ¤ ìƒíƒœ: {status}")
                    else:
                        print_status("   - ìƒíƒœ ì •ë³´: ê¸°ë³¸ ìƒíƒœ")
                except AttributeError as e:
                    print_warning(f"   - ìƒíƒœ ì¡°íšŒ ì‹¤íŒ¨: {e}")
                    print_status("   - ìƒíƒœ ì •ë³´: ê¸°ë³¸ ìƒíƒœ")
                except Exception as e:
                    print_warning(f"   - ìƒíƒœ ì¡°íšŒ ì˜¤ë¥˜: {e}")
                    print_status("   - ìƒíƒœ ì •ë³´: ê¸°ë³¸ ìƒíƒœ")
                    
            else:
                print_warning("âš ï¸ StepServiceManager ìƒì„± ì‹¤íŒ¨ - ê¸°ë³¸ ì„œë¹„ìŠ¤ ì‚¬ìš©")
                # ê¸°ë³¸ ì„œë¹„ìŠ¤ ë“±ë¡
                container.register('step_service_manager', {'type': 'fallback', 'status': 'basic_service'})
                
        except Exception as e:
            print_error(f"âŒ StepServiceManager ë“±ë¡ ì‹¤íŒ¨: {e}")
            print_error(f"âŒ ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
        
        # SessionManager ë“±ë¡ (ê°•ì œ ë“±ë¡)
        try:
            print_status("ğŸ”„ SessionManager ê°•ì œ ë“±ë¡ ì‹œì‘...")
            from app.core.session_manager import get_session_manager
            
            # ê°•ì œë¡œ SessionManager ìƒì„±
            session_manager = get_session_manager()
            if not session_manager:
                print_error("âŒ SessionManager ìƒì„± ì‹¤íŒ¨ - ê°•ì œ ìƒì„± ì‹œë„")
                from app.core.session_manager import SessionManager
                session_manager = SessionManager()
            
            # Central Hubì— ê°•ì œ ë“±ë¡
            container.register('session_manager', session_manager)
            print_status("âœ… SessionManager Central Hub ê°•ì œ ë“±ë¡ ì™„ë£Œ")
            
            # ë“±ë¡ í™•ì¸
            registered_session_manager = container.get('session_manager')
            if registered_session_manager:
                print_status("âœ… SessionManager ë“±ë¡ í™•ì¸ ì™„ë£Œ")
            else:
                print_error("âŒ SessionManager ë“±ë¡ í™•ì¸ ì‹¤íŒ¨")
                
        except Exception as e:
            print_error(f"âŒ SessionManager ê°•ì œ ë“±ë¡ ì‹¤íŒ¨: {e}")
            print_error(f"âŒ ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
            
            # ìµœí›„ì˜ ìˆ˜ë‹¨: Mock SessionManager ë“±ë¡
            try:
                print_status("ğŸ”„ Mock SessionManager ë“±ë¡ ì‹œë„...")
                
                class MockSessionManager:
                    def __init__(self):
                        self.sessions = {}
                    
                    async def create_session(self, person_image, clothing_image, measurements):
                        session_id = f"mock_session_{len(self.sessions)}"
                        self.sessions[session_id] = {
                            'person_image': person_image,
                            'clothing_image': clothing_image,
                            'measurements': measurements
                        }
                        return session_id
                    
                    async def get_session_status(self, session_id):
                        return {'status': 'mock', 'session_id': session_id}
                    
                    async def save_step_result(self, session_id, step_id, result):
                        return True
                
                mock_session_manager = MockSessionManager()
                container.register('session_manager', mock_session_manager)
                print_status("âœ… Mock SessionManager ë“±ë¡ ì™„ë£Œ")
                
            except Exception as e2:
                print_error(f"âŒ Mock SessionManager ë“±ë¡ë„ ì‹¤íŒ¨: {e2}")
                raise RuntimeError("SessionManager ë“±ë¡ ì™„ì „ ì‹¤íŒ¨")
        
        # WebSocketManager ë“±ë¡
        try:
            from app.shared.websocket_manager import WebSocketManager
            websocket_manager = WebSocketManager()
            # ë°±ê·¸ë¼ìš´ë“œ íƒœìŠ¤í¬ ì‹œì‘
            if hasattr(websocket_manager, 'start_background_tasks'):
                await websocket_manager.start_background_tasks()
            container.register('websocket_manager', websocket_manager)
            print_status("âœ… WebSocketManager Central Hub ë“±ë¡ ì™„ë£Œ")
        except Exception as e:
            print_error(f"âŒ WebSocketManager ë“±ë¡ ì‹¤íŒ¨: {e}")
        
        # StepImplementationManager ë“±ë¡
        try:
            from app.services.step_implementations import get_step_implementation_manager
            impl_manager = get_step_implementation_manager()
            if impl_manager:
                container.register('step_implementation_manager', impl_manager)
                print_status("âœ… StepImplementationManager Central Hub ë“±ë¡ ì™„ë£Œ")
        except Exception as e:
            print_error(f"âŒ StepImplementationManager ë“±ë¡ ì‹¤íŒ¨: {e}")
        
        print_status("ğŸ¯ í•µì‹¬ ì„œë¹„ìŠ¤ë“¤ Central Hub ë“±ë¡ ì™„ë£Œ")
        
    except Exception as e:
        print_error(f"âŒ í•µì‹¬ ì„œë¹„ìŠ¤ ë“±ë¡ ì‹¤íŒ¨: {e}")

async def _register_step_factory_to_central_hub(container):
    """StepFactoryë¥¼ Central Hubì— ë“±ë¡"""
    try:
        print_status("ğŸ”„ StepFactory Central Hub ë“±ë¡ ì¤‘...")
        
        from app.ai_pipeline.factories.step_factory import get_global_step_factory
        step_factory = get_global_step_factory()
        
        if step_factory:
            container.register('step_factory', step_factory)
            
            # StepFactory í†µê³„ í™•ì¸
            stats = step_factory.get_statistics()
            print_status(f"âœ… StepFactory Central Hub ë“±ë¡ ì™„ë£Œ")
            print_status(f"   - ë“±ë¡ëœ Step: {stats.get('registration', {}).get('registered_steps_count', 0)}ê°œ")
            print_status(f"   - ë¡œë”©ëœ í´ë˜ìŠ¤: {len(stats.get('loaded_classes', []))}ê°œ")
        else:
            print_error("âŒ StepFactory ì¸ìŠ¤í„´ìŠ¤ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŒ")
        
    except Exception as e:
        print_error(f"âŒ StepFactory ë“±ë¡ ì‹¤íŒ¨: {e}")

async def _validate_central_hub_services(container) -> Dict[str, Any]:
    """Central Hub ì„œë¹„ìŠ¤ ê²€ì¦"""
    try:
        required_services = [
            'step_service_manager',
            'session_manager', 
            'websocket_manager',
            'step_factory',
            'step_implementation_manager'
        ]
        
        validation_result = {
            'success': True,
            'services_status': {},
            'issues': []
        }
        
        for service_key in required_services:
            service = container.get(service_key)
            is_available = service is not None
            validation_result['services_status'][service_key] = is_available
            
            if not is_available:
                validation_result['issues'].append(f'{service_key} not available')
                validation_result['success'] = False
        
        # Central Hub í†µê³„ ì¶”ê°€
        if hasattr(container, 'get_stats'):
            validation_result['central_hub_stats'] = container.get_stats()
        
        return validation_result
        
    except Exception as e:
        return {
            'success': False,
            'error': str(e),
            'issues': ['Validation failed']
        }

async def _cleanup_central_hub_services(container):
    """Central Hub ì„œë¹„ìŠ¤ ì •ë¦¬"""
    try:
        # StepServiceManager ì •ë¦¬
        step_service_manager = container.get('step_service_manager')
        if step_service_manager and hasattr(step_service_manager, 'cleanup'):
            await step_service_manager.cleanup()
        
        # StepFactory ìºì‹œ ì •ë¦¬
        step_factory = container.get('step_factory')
        if step_factory and hasattr(step_factory, 'clear_cache'):
            step_factory.clear_cache()
        
        # Central Hub ë©”ëª¨ë¦¬ ìµœì í™”
        if hasattr(container, 'optimize_memory'):
            optimization_result = container.optimize_memory()
            print_status(f"Central Hub ë©”ëª¨ë¦¬ ìµœì í™”: {optimization_result}")
        
        print_status("âœ… Central Hub ì„œë¹„ìŠ¤ ì •ë¦¬ ì™„ë£Œ")
        
    except Exception as e:
        print_error(f"âŒ Central Hub ì„œë¹„ìŠ¤ ì •ë¦¬ ì‹¤íŒ¨: {e}")

# =============================================================================
# ğŸ”¥ 8. Central Hub ê¸°ë°˜ ì•± ìƒëª…ì£¼ê¸° ê´€ë¦¬
# =============================================================================

@asynccontextmanager
async def lifespan(app: FastAPI):
    """Central Hub DI Container ê¸°ë°˜ ì•± ìƒëª…ì£¼ê¸° ê´€ë¦¬"""
    
    # ===== ğŸ”¥ ì‹œì‘ ì‹œ Central Hub ì´ˆê¸°í™” =====
    print_status("ğŸš€ MyCloset AI Backend ì‹œì‘ - Central Hub DI Container v7.0")
    
    try:
        # 1. Central Hub DI Container í™•ì¸
        if not CENTRAL_HUB_CONTAINER_AVAILABLE or not central_hub_container:
            print_error("âŒ Central Hub DI Container ì´ˆê¸°í™” ì‹¤íŒ¨")
            print_warning("âš ï¸ í´ë°± ëª¨ë“œë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤")
            yield  # í´ë°± ëª¨ë“œë¡œ ì•± ì‹œì‘
            return
        
        print_status("âœ… Central Hub DI Container ì´ˆê¸°í™” ì™„ë£Œ")
        
        # 2. í•µì‹¬ ì„œë¹„ìŠ¤ë“¤ Central Hubì— ë“±ë¡ (íƒ€ì„ì•„ì›ƒ ì„¤ì •)
        try:
            import asyncio
            await asyncio.wait_for(
                _register_core_services_to_central_hub(central_hub_container),
                timeout=30.0  # 30ì´ˆ íƒ€ì„ì•„ì›ƒ
            )
        except asyncio.TimeoutError:
            print_warning("âš ï¸ í•µì‹¬ ì„œë¹„ìŠ¤ ë“±ë¡ íƒ€ì„ì•„ì›ƒ - ê¸°ë³¸ ì„œë¹„ìŠ¤ë¡œ ê³„ì†")
        except Exception as e:
            print_warning(f"âš ï¸ í•µì‹¬ ì„œë¹„ìŠ¤ ë“±ë¡ ì‹¤íŒ¨: {e} - ê¸°ë³¸ ì„œë¹„ìŠ¤ë¡œ ê³„ì†")
        
        # 3. StepFactory Central Hub ë“±ë¡ (íƒ€ì„ì•„ì›ƒ ì„¤ì •)
        try:
            await asyncio.wait_for(
                _register_step_factory_to_central_hub(central_hub_container),
                timeout=15.0  # 15ì´ˆ íƒ€ì„ì•„ì›ƒ
            )
        except asyncio.TimeoutError:
            print_warning("âš ï¸ StepFactory ë“±ë¡ íƒ€ì„ì•„ì›ƒ - ê¸°ë³¸ íŒ©í† ë¦¬ë¡œ ê³„ì†")
        except Exception as e:
            print_warning(f"âš ï¸ StepFactory ë“±ë¡ ì‹¤íŒ¨: {e} - ê¸°ë³¸ íŒ©í† ë¦¬ë¡œ ê³„ì†")
        
        # 4. FastAPI ì•±ì— Central Hub ì°¸ì¡° ì €ì¥
        app.state.central_hub_container = central_hub_container
        
        # 5. Central Hub ìƒíƒœ ê²€ì¦ (ë¹ ë¥¸ ê²€ì¦)
        try:
            validation_result = await asyncio.wait_for(
                _validate_central_hub_services(central_hub_container),
                timeout=10.0  # 10ì´ˆ íƒ€ì„ì•„ì›ƒ
            )
            if not validation_result['success']:
                print_warning(f"âš ï¸ Central Hub ê²€ì¦ ê²½ê³ : {validation_result['issues']}")
        except Exception as e:
            print_warning(f"âš ï¸ Central Hub ê²€ì¦ ì‹¤íŒ¨: {e} - ê¸°ë³¸ ê²€ì¦ìœ¼ë¡œ ê³„ì†")
        
        print_status("ğŸ‰ Central Hub ê¸°ë°˜ MyCloset AI Backend ì‹œì‘ ì™„ë£Œ!")
        
        yield  # ì•± ì‹¤í–‰
        
    except Exception as e:
        print_error(f"âŒ Central Hub ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        print_warning("âš ï¸ í´ë°± ëª¨ë“œë¡œ ì•±ì„ ì‹œì‘í•©ë‹ˆë‹¤")
        yield  # ì—ëŸ¬ê°€ ìˆì–´ë„ ì•±ì€ ì‹œì‘ (í´ë°± ëª¨ë“œ)
    
    # ===== ğŸ”¥ ì¢…ë£Œ ì‹œ Central Hub ì •ë¦¬ =====
    print_status("ğŸ§¹ MyCloset AI Backend ì¢…ë£Œ - Central Hub ì •ë¦¬ ì‹œì‘")
    
    try:
        if hasattr(app.state, 'central_hub_container') and app.state.central_hub_container:
            await asyncio.wait_for(
                _cleanup_central_hub_services(app.state.central_hub_container),
                timeout=10.0  # 10ì´ˆ íƒ€ì„ì•„ì›ƒ
            )
        
        print_status("âœ… Central Hub ì •ë¦¬ ì™„ë£Œ")
        
    except Exception as e:
        print_error(f"âŒ Central Hub ì •ë¦¬ ì‹¤íŒ¨: {e}")

# =============================================================================
# ğŸ”¥ 9. Central Hub ê¸°ë°˜ FastAPI ì•± ìƒì„±
# =============================================================================

def _setup_central_hub_cors(app):
    """Central Hub ê¸°ë°˜ CORS ì„¤ì •"""
    try:
        from fastapi.middleware.cors import CORSMiddleware
        
        # Central Hubì—ì„œ CORS ì„¤ì • ì¡°íšŒ (ìˆë‹¤ë©´)
        origins = None
        try:
            if central_hub_container:
                cors_config = central_hub_container.get('cors_config')
                if cors_config:
                    origins = cors_config.get('origins', [])
        except:
            pass
        
        if origins is None:
            origins = _get_default_cors_origins()
        
        app.add_middleware(
            CORSMiddleware,
            allow_origins=origins,
            allow_credentials=True,
            allow_methods=["*"],
            allow_headers=["*"],
        )
        
        print_status(f"âœ… Central Hub ê¸°ë°˜ CORS ì„¤ì • ì™„ë£Œ: {len(origins)}ê°œ origin")
        
    except Exception as e:
        print_error(f"âŒ Central Hub CORS ì„¤ì • ì‹¤íŒ¨: {e}")

def _get_default_cors_origins():
    """ê¸°ë³¸ CORS origins - í”„ë¡ íŠ¸ì—”ë“œ í˜¸í™˜ì„± ìµœì í™”"""
    return [
        # React ê°œë°œ ì„œë²„
        "http://localhost:3000",
        "http://127.0.0.1:3000",
        
        # Vite ê°œë°œ ì„œë²„
        "http://localhost:5173",
        "http://127.0.0.1:5173",
        
        # ì¶”ê°€ í”„ë¡ íŠ¸ì—”ë“œ í¬íŠ¸ë“¤
        "http://localhost:3001",
        "http://127.0.0.1:3001",
        "http://localhost:8080",
        "http://127.0.0.1:8080",
        
        # í”„ë¡œë•ì…˜ í™˜ê²½ (í•„ìš”ì‹œ)
        "https://mycloset-ai.com",
        "https://www.mycloset-ai.com",
        
        # WebSocket ì§€ì›
        "ws://localhost:3000",
        "ws://localhost:5173",
        "ws://127.0.0.1:3000",
        "ws://127.0.0.1:5173"
    ]

def _setup_central_hub_middleware(app):
    """Central Hub ê¸°ë°˜ ë¯¸ë“¤ì›¨ì–´ ì„¤ì •"""
    try:
        # Central Hub ê¸°ë°˜ ìš”ì²­ ë¡œê¹… ë¯¸ë“¤ì›¨ì–´
        @app.middleware("http") 
        async def central_hub_request_logger(request, call_next):
            start_time = time.time()
            
            # Central Hub Container ì°¸ì¡° ì¶”ê°€
            if hasattr(app.state, 'central_hub_container'):
                request.state.central_hub_container = app.state.central_hub_container
            
            response = await call_next(request)
            process_time = time.time() - start_time
            
            # Step API ìš”ì²­ì€ ìƒì„¸ ë¡œê¹…
            if request.url.path.startswith("/api/step/"):
                print_status(
                    f"ğŸ”¥ CENTRAL HUB STEP API: {request.method} {request.url.path} - "
                    f"{response.status_code} ({process_time:.3f}s)"
                )
            
            return response
        
        print_status("âœ… Central Hub ê¸°ë°˜ ë¯¸ë“¤ì›¨ì–´ ì„¤ì • ì™„ë£Œ")
        
    except Exception as e:
        print_error(f"âŒ Central Hub ë¯¸ë“¤ì›¨ì–´ ì„¤ì • ì‹¤íŒ¨: {e}")

def _register_central_hub_routers(app) -> int:
    """Central Hub ê¸°ë°˜ ë¼ìš°í„° ë“±ë¡ - ì‹¤ì œ ë°±ì—”ë“œ ëª¨ë“ˆ ê¸°ë°˜"""
    registered_count = 0
    
    try:
        print_status("ğŸ”„ Central Hub ê¸°ë°˜ ë¼ìš°í„° ë“±ë¡ ì‹œì‘...")
        
        # 1ì°¨ ì‹œë„: app.api.register_routers (ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ëª¨ë“ˆ)
        try:
            from app.api import register_routers
            
            # Central Hub ê¸°ë°˜ ë¼ìš°í„° ë“±ë¡
            registered_count = register_routers(app)
            print_status(f"âœ… Central Hub ê¸°ë°˜ ë¼ìš°í„° ë“±ë¡: {registered_count}ê°œ")
            
        except ImportError as e:
            print_warning(f"âš ï¸ app.api.register_routers import ì‹¤íŒ¨: {e}")
            registered_count = 0
        except Exception as e:
            print_warning(f"âš ï¸ app.api.register_routers ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            registered_count = 0
        
        # 2ì°¨ ì‹œë„: ê°œë³„ ë¼ìš°í„° ì§ì ‘ ë“±ë¡
        if registered_count == 0:
            print_status("ğŸ”„ ê°œë³„ ë¼ìš°í„° ì§ì ‘ ë“±ë¡ ì‹œë„...")
            
            # step_routes.py ë“±ë¡ (ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ëª¨ë“ˆ)
            try:
                from app.api.step_routes import router as step_router
                app.include_router(step_router, prefix="/api/step", tags=["AI Pipeline Steps"])
                registered_count += 1
                print_status("âœ… step_routes.py ë¼ìš°í„° ë“±ë¡ ì™„ë£Œ: /api/step/*")
            except ImportError as e:
                print_warning(f"âš ï¸ step_routes.py ë¼ìš°í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            except Exception as e:
                print_warning(f"âš ï¸ step_routes.py ë¼ìš°í„° ë“±ë¡ ì‹¤íŒ¨: {e}")
            
            # system_routes.py ë“±ë¡ (ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ëª¨ë“ˆ)
            try:
                from app.api.system_routes import router as system_router
                app.include_router(system_router, prefix="/api/system", tags=["System Info"])
                registered_count += 1
                print_status("âœ… system_routes.py ë¼ìš°í„° ë“±ë¡ ì™„ë£Œ: /api/system/*")
            except ImportError as e:
                print_warning(f"âš ï¸ system_routes.py ë¼ìš°í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            except Exception as e:
                print_warning(f"âš ï¸ system_routes.py ë¼ìš°í„° ë“±ë¡ ì‹¤íŒ¨: {e}")
            
            # pipeline_routes.py ë“±ë¡ (ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ëª¨ë“ˆ)
            try:
                from app.api.pipeline_routes import router as pipeline_router
                app.include_router(pipeline_router, prefix="/api/v1/pipeline", tags=["Pipeline"])
                registered_count += 1
                print_status("âœ… pipeline_routes.py ë¼ìš°í„° ë“±ë¡ ì™„ë£Œ: /api/v1/pipeline/*")
            except ImportError as e:
                print_warning(f"âš ï¸ pipeline_routes.py ë¼ìš°í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            except Exception as e:
                print_warning(f"âš ï¸ pipeline_routes.py ë¼ìš°í„° ë“±ë¡ ì‹¤íŒ¨: {e}")
            
            # websocket_routes.py ë“±ë¡ (ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ëª¨ë“ˆ)
            try:
                from app.api.websocket_routes import router as websocket_router
                app.include_router(websocket_router, prefix="/api/ws", tags=["WebSocket"])
                registered_count += 1
                print_status("âœ… websocket_routes.py ë¼ìš°í„° ë“±ë¡ ì™„ë£Œ: /api/ws/*")
            except ImportError as e:
                print_warning(f"âš ï¸ websocket_routes.py ë¼ìš°í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            except Exception as e:
                print_warning(f"âš ï¸ websocket_routes.py ë¼ìš°í„° ë“±ë¡ ì‹¤íŒ¨: {e}")
            
            # health.py ë“±ë¡ (ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ëª¨ë“ˆ)
            try:
                from app.api.health import router as health_router
                app.include_router(health_router, tags=["Health"])
                registered_count += 1
                print_status("âœ… health.py ë¼ìš°í„° ë“±ë¡ ì™„ë£Œ: /health")
            except ImportError as e:
                print_warning(f"âš ï¸ health.py ë¼ìš°í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            except Exception as e:
                print_warning(f"âš ï¸ health.py ë¼ìš°í„° ë“±ë¡ ì‹¤íŒ¨: {e}")
        
        # 3ì°¨ ì‹œë„: í´ë°± í—¬ìŠ¤ì²´í¬
        if registered_count == 0:
            print_warning("âš ï¸ ëª¨ë“  ë¼ìš°í„° ë“±ë¡ ì‹¤íŒ¨ - í´ë°± í—¬ìŠ¤ì²´í¬ë§Œ ë“±ë¡")
            _register_fallback_health_router(app)
            registered_count = 1
        
        print_status(f"ğŸ¯ ìµœì¢… ë¼ìš°í„° ë“±ë¡ ì™„ë£Œ: {registered_count}ê°œ")
        
    except Exception as e:
        print_error(f"âŒ ë¼ìš°í„° ë“±ë¡ ì™„ì „ ì‹¤íŒ¨: {e}")
        print_error(f"âŒ ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
        # ìµœí›„ì˜ ìˆ˜ë‹¨: í´ë°± í—¬ìŠ¤ì²´í¬
        _register_fallback_health_router(app)
        registered_count = 1
    
    return registered_count

def _setup_central_hub_error_handlers(app):
    """Central Hub ê¸°ë°˜ ì—ëŸ¬ í•¸ë“¤ëŸ¬ ì„¤ì •"""
    try:
        @app.exception_handler(Exception)
        async def central_hub_exception_handler(request, exc):
            print_error(f"âŒ Central Hub ê¸°ë°˜ ì•±ì—ì„œ ì²˜ë¦¬ë˜ì§€ ì•Šì€ ì˜ˆì™¸: {exc}")
            
            # Central Hub ìƒíƒœ ì •ë³´ ì¶”ê°€
            error_context = {
                'central_hub_available': hasattr(request.state, 'central_hub_container'),
                'path': str(request.url.path),
                'method': request.method
            }
            
            return JSONResponse(
                content={
                    'error': 'Internal server error',
                    'detail': str(exc),
                    'central_hub_context': error_context
                },
                status_code=500
            )
        
        print_status("âœ… Central Hub ê¸°ë°˜ ì—ëŸ¬ í•¸ë“¤ëŸ¬ ì„¤ì • ì™„ë£Œ")
        
    except AttributeError as e:
        print_error(f"âŒ Central Hub ì—ëŸ¬ í•¸ë“¤ëŸ¬ ì„¤ì • ì†ì„± ì˜¤ë¥˜: {e}")
    except TypeError as e:
        print_error(f"âŒ Central Hub ì—ëŸ¬ í•¸ë“¤ëŸ¬ ì„¤ì • íƒ€ì… ì˜¤ë¥˜: {e}")
    except ValueError as e:
        print_error(f"âŒ Central Hub ì—ëŸ¬ í•¸ë“¤ëŸ¬ ì„¤ì • ê°’ ì˜¤ë¥˜: {e}")
    except Exception as e:
        print_error(f"âŒ Central Hub ì—ëŸ¬ í•¸ë“¤ëŸ¬ ì„¤ì • ì‹¤íŒ¨: {type(e).__name__}: {e}")

def _add_central_hub_endpoints(app):
    """Central Hub ì „ìš© ì—”ë“œí¬ì¸íŠ¸ ì¶”ê°€"""
    try:
        @app.get("/central-hub/status")
        async def central_hub_status():
            """Central Hub DI Container ìƒíƒœ í™•ì¸"""
            try:
                if hasattr(app.state, 'central_hub_container') and app.state.central_hub_container:
                    container = app.state.central_hub_container
                    
                    status = {
                        'central_hub_connected': True,
                        'container_id': getattr(container, 'container_id', 'unknown'),
                        'services_count': len(container.list_services()) if hasattr(container, 'list_services') else 0,
                        'timestamp': datetime.now().isoformat()
                    }
                    
                    if hasattr(container, 'get_stats'):
                        status['stats'] = container.get_stats()
                    
                    return JSONResponse(content=status)
                else:
                    return JSONResponse(content={
                        'central_hub_connected': False,
                        'error': 'Central Hub Container not available',
                        'timestamp': datetime.now().isoformat()
                    }, status_code=503)
                    
            except Exception as e:
                return JSONResponse(content={
                    'central_hub_connected': False,
                    'error': str(e),
                    'timestamp': datetime.now().isoformat()
                }, status_code=500)
        
        @app.get("/central-hub/services")
        async def central_hub_services():
            """Central Hub ë“±ë¡ëœ ì„œë¹„ìŠ¤ ëª©ë¡"""
            try:
                if hasattr(app.state, 'central_hub_container') and app.state.central_hub_container:
                    container = app.state.central_hub_container
                    
                    services = {}
                    if hasattr(container, 'list_services'):
                        service_keys = container.list_services()
                        for key in service_keys:
                            service = container.get(key)
                            services[key] = {
                                'available': service is not None,
                                'type': type(service).__name__ if service else None
                            }
                    
                    return JSONResponse(content={
                        'services': services,
                        'total_count': len(services),
                        'timestamp': datetime.now().isoformat()
                    })
                else:
                    return JSONResponse(content={
                        'error': 'Central Hub Container not available'
                    }, status_code=503)
                    
            except Exception as e:
                return JSONResponse(content={
                    'error': str(e)
                }, status_code=500)
        
        print_status("âœ… Central Hub ì „ìš© ì—”ë“œí¬ì¸íŠ¸ ì¶”ê°€ ì™„ë£Œ")
        
    except Exception as e:
        print_error(f"âŒ Central Hub ì—”ë“œí¬ì¸íŠ¸ ì¶”ê°€ ì‹¤íŒ¨: {e}")

def _register_fallback_health_router(app):
    """í´ë°± í—¬ìŠ¤ì²´í¬ ë¼ìš°í„°"""
    @app.get("/health")
    async def fallback_health():
        return JSONResponse(content={
            'status': 'limited',
            'message': 'Central Hub í´ë°± ëª¨ë“œ',
            'timestamp': datetime.now().isoformat()
        })

def create_app() -> FastAPI:
    """Central Hub DI Container ê¸°ë°˜ FastAPI ì•± ìƒì„±"""
    
    # FastAPI ì¸ìŠ¤í„´ìŠ¤ ìƒì„± (Central Hub ê¸°ë°˜)
    app = FastAPI(
        title="MyCloset AI Backend API",
        description="MyCloset AI ê°€ìƒ í”¼íŒ… ë°±ì—”ë“œ API v29.0 - Central Hub DI Container v7.0 ì™„ì „ ì—°ë™",
        version="29.0.0",
        lifespan=lifespan,  # Central Hub ê¸°ë°˜ ìƒëª…ì£¼ê¸° 
        docs_url="/docs",
        redoc_url="/redoc"
    )
    
    # Central Hub ê¸°ë°˜ CORS ì„¤ì •
    _setup_central_hub_cors(app)
    
    # Central Hub ê¸°ë°˜ ë¯¸ë“¤ì›¨ì–´ ì„¤ì •
    _setup_central_hub_middleware(app)
    
    # Central Hub ê¸°ë°˜ ë¼ìš°í„° ë“±ë¡
    registered_count = _register_central_hub_routers(app)
    print_status(f"ğŸ¯ Central Hub ê¸°ë°˜ ë¼ìš°í„° ë“±ë¡ ì™„ë£Œ: {registered_count}ê°œ")
    
    # Central Hub ê¸°ë°˜ ì—ëŸ¬ í•¸ë“¤ëŸ¬ ì„¤ì •
    _setup_central_hub_error_handlers(app)
    
    # Central Hub ìƒíƒœ í™•ì¸ ì—”ë“œí¬ì¸íŠ¸ ì¶”ê°€
    _add_central_hub_endpoints(app)
    
    print_status("ğŸ­ Central Hub ê¸°ë°˜ FastAPI ì•± ìƒì„± ì™„ë£Œ!")
    return app

# =============================================================================
# ğŸ”¥ 10. ì•± ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
# =============================================================================

app = create_app()

# ì••ì¶• ë¯¸ë“¤ì›¨ì–´
app.add_middleware(GZipMiddleware, minimum_size=1000)

# ì •ì  íŒŒì¼ ì„œë¹™
static_dir = Path("static")
static_dir.mkdir(exist_ok=True)
app.mount("/static", StaticFiles(directory="static"), name="static")

# =============================================================================
# ğŸ”¥ 11. ê¸°ë³¸ ì—”ë“œí¬ì¸íŠ¸ë“¤
# =============================================================================

# ğŸ”¥ ì¤‘ì•™ í†µí•© ModelLoader v7.0 ì‹¤ì œ ì‚¬ìš© ì—”ë“œí¬ì¸íŠ¸ë“¤
@app.get("/api/model-loader/status")
async def get_model_loader_status():
    """ì¤‘ì•™ í†µí•© ModelLoader v7.0 ìƒíƒœ í™•ì¸"""
    try:
        if not central_hub_container:
            return JSONResponse(content={
                'error': 'Central Hub Container not available'
            }, status_code=503)
        
        model_loader = central_hub_container.get('model_loader')
        if not model_loader:
            return JSONResponse(content={
                'error': 'ModelLoader not available'
            }, status_code=503)
        
        # ModelLoader ìƒíƒœ ì •ë³´ ìˆ˜ì§‘
        status_info = {
            'model_loader_type': type(model_loader).__name__,
            'device': getattr(model_loader, 'device', DEVICE),
            'central_hub_connected': hasattr(model_loader, 'central_hub') and model_loader.central_hub is not None,
            'step_loaders_count': 0,
            'step_loaders': {},
            'timestamp': datetime.now().isoformat()
        }
        
        # Step ë¡œë” ì •ë³´ ìˆ˜ì§‘
        if hasattr(model_loader, 'step_loaders'):
            status_info['step_loaders_count'] = len(model_loader.step_loaders)
            for step_name, step_loader in model_loader.step_loaders.items():
                step_info = {
                    'available': step_loader is not None,
                    'type': type(step_loader).__name__ if step_loader else None
                }
                
                # Stepë³„ ëª¨ë¸ ì •ë³´
                if step_loader and hasattr(step_loader, 'models'):
                    step_info['models_count'] = len(step_loader.models) if step_loader.models else 0
                    step_info['models'] = list(step_loader.models.keys()) if step_loader.models else []
                
                status_info['step_loaders'][step_name] = step_info
        
        return JSONResponse(content=status_info)
        
    except Exception as e:
        return JSONResponse(content={
            'error': f'ModelLoader ìƒíƒœ í™•ì¸ ì‹¤íŒ¨: {e}'
        }, status_code=500)

@app.get("/api/model-loader/step/{step_name}/models")
async def get_step_models(step_name: str):
    """íŠ¹ì • Stepì˜ ëª¨ë¸ ëª©ë¡ ì¡°íšŒ"""
    try:
        if not central_hub_container:
            return JSONResponse(content={
                'error': 'Central Hub Container not available'
            }, status_code=503)
        
        model_loader = central_hub_container.get('model_loader')
        if not model_loader:
            return JSONResponse(content={
                'error': 'ModelLoader not available'
            }, status_code=503)
        
        # Step ë¡œë” ì¡°íšŒ
        if not hasattr(model_loader, 'step_loaders'):
            return JSONResponse(content={
                'error': 'Step loaders not available'
            }, status_code=503)
        
        step_loader = model_loader.step_loaders.get(step_name)
        if not step_loader:
            return JSONResponse(content={
                'error': f'Step {step_name} not found'
            }, status_code=404)
        
        # Stepë³„ ëª¨ë¸ ì •ë³´
        step_models = {
            'step_name': step_name,
            'step_loader_type': type(step_loader).__name__,
            'models': {},
            'timestamp': datetime.now().isoformat()
        }
        
        if hasattr(step_loader, 'models') and step_loader.models:
            for model_name, model in step_loader.models.items():
                model_info = {
                    'type': type(model).__name__,
                    'available': model is not None
                }
                
                # PyTorch ëª¨ë¸ì¸ ê²½ìš° ì¶”ê°€ ì •ë³´
                if hasattr(model, 'state_dict'):
                    model_info['is_pytorch_model'] = True
                    if hasattr(model, 'parameters'):
                        param_count = sum(p.numel() for p in model.parameters())
                        model_info['parameters_count'] = param_count
                
                step_models['models'][model_name] = model_info
        
        return JSONResponse(content=step_models)
        
    except Exception as e:
        return JSONResponse(content={
            'error': f'Step ëª¨ë¸ ì¡°íšŒ ì‹¤íŒ¨: {e}'
        }, status_code=500)

@app.post("/api/model-loader/step/{step_name}/inference")
async def run_step_inference(step_name: str, request: Request):
    """íŠ¹ì • Stepì˜ AI ì¶”ë¡  ì‹¤í–‰ (ì‹¤ì œ ì‚¬ìš© ì˜ˆì‹œ)"""
    try:
        if not central_hub_container:
            return JSONResponse(content={
                'error': 'Central Hub Container not available'
            }, status_code=503)
        
        model_loader = central_hub_container.get('model_loader')
        if not model_loader:
            return JSONResponse(content={
                'error': 'ModelLoader not available'
            }, status_code=503)
        
        # Step ë¡œë” ì¡°íšŒ
        if not hasattr(model_loader, 'step_loaders'):
            return JSONResponse(content={
                'error': 'Step loaders not available'
            }, status_code=503)
        
        step_loader = model_loader.step_loaders.get(step_name)
        if not step_loader:
            return JSONResponse(content={
                'error': f'Step {step_name} not found'
            }, status_code=404)
        
        # ìš”ì²­ ë°ì´í„° íŒŒì‹±
        try:
            request_data = await request.json()
        except:
            request_data = {}
        
        # Stepë³„ ì¶”ë¡  ì‹¤í–‰ (ì‹¤ì œ AI ëª¨ë¸ ì‚¬ìš©)
        inference_result = {
            'step_name': step_name,
            'status': 'success',
            'timestamp': datetime.now().isoformat(),
            'input_data': request_data,
            'output': None,
            'processing_time': 0.0
        }
        
        try:
            start_time = time.time()
            
            # Stepë³„ íŠ¹í™”ëœ ì¶”ë¡  ë¡œì§
            if hasattr(step_loader, 'run_inference'):
                # ì‹¤ì œ AI ì¶”ë¡  ì‹¤í–‰
                output = step_loader.run_inference(request_data)
                inference_result['output'] = output
                inference_result['message'] = f'{step_name} AI ì¶”ë¡  ì™„ë£Œ'
                
            elif hasattr(step_loader, 'process'):
                # process ë©”ì„œë“œê°€ ìˆëŠ” ê²½ìš°
                output = step_loader.process(request_data)
                inference_result['output'] = output
                inference_result['message'] = f'{step_name} ì²˜ë¦¬ ì™„ë£Œ'
                
            elif hasattr(step_loader, 'execute'):
                # execute ë©”ì„œë“œê°€ ìˆëŠ” ê²½ìš°
                output = step_loader.execute(request_data)
                inference_result['output'] = output
                inference_result['message'] = f'{step_name} ì‹¤í–‰ ì™„ë£Œ'
                
            else:
                # ê¸°ë³¸ ëª¨ë¸ ì¶”ë¡ 
                if hasattr(step_loader, 'models') and step_loader.models:
                    # ì²« ë²ˆì§¸ ëª¨ë¸ ì‚¬ìš©
                    first_model = list(step_loader.models.values())[0]
                    if hasattr(first_model, 'forward'):
                        # PyTorch ëª¨ë¸ ì¶”ë¡ 
                        import torch
                        if isinstance(request_data, dict) and 'input' in request_data:
                            input_tensor = torch.tensor(request_data['input'])
                            with torch.no_grad():
                                output = first_model(input_tensor)
                            inference_result['output'] = output.tolist() if hasattr(output, 'tolist') else str(output)
                            inference_result['message'] = f'{step_name} PyTorch ëª¨ë¸ ì¶”ë¡  ì™„ë£Œ'
                        else:
                            inference_result['message'] = f'{step_name} ì…ë ¥ ë°ì´í„° í˜•ì‹ ì˜¤ë¥˜'
                    else:
                        inference_result['message'] = f'{step_name} ëª¨ë¸ ì¶”ë¡  ë©”ì„œë“œ ì—†ìŒ'
                else:
                    inference_result['message'] = f'{step_name} ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ì—†ìŒ'
            
            processing_time = time.time() - start_time
            inference_result['processing_time'] = round(processing_time, 3)
            
        except Exception as e:
            inference_result['status'] = 'error'
            inference_result['error'] = str(e)
            inference_result['message'] = f'{step_name} ì¶”ë¡  ì‹¤íŒ¨: {e}'
        
        return JSONResponse(content=inference_result)
        
    except Exception as e:
        return JSONResponse(content={
            'error': f'Step ì¶”ë¡  ì‹¤í–‰ ì‹¤íŒ¨: {e}'
        }, status_code=500)

@app.get("/api/model-loader/available-steps")
async def get_available_steps():
    """ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë“  Step ëª©ë¡ ì¡°íšŒ"""
    try:
        if not central_hub_container:
            return JSONResponse(content={
                'error': 'Central Hub Container not available'
            }, status_code=503)
        
        model_loader = central_hub_container.get('model_loader')
        if not model_loader:
            return JSONResponse(content={
                'error': 'ModelLoader not available'
            }, status_code=503)
        
        # ì‚¬ìš© ê°€ëŠ¥í•œ Step ëª©ë¡
        available_steps = {
            'total_steps': 0,
            'steps': {},
            'timestamp': datetime.now().isoformat()
        }
        
        if hasattr(model_loader, 'step_loaders'):
            available_steps['total_steps'] = len(model_loader.step_loaders)
            for step_name, step_loader in model_loader.step_loaders.items():
                step_info = {
                    'name': step_name,
                    'available': step_loader is not None,
                    'loader_type': type(step_loader).__name__ if step_loader else None,
                    'models_count': 0,
                    'endpoints': {
                        'models': f"/api/model-loader/step/{step_name}/models",
                        'inference': f"/api/model-loader/step/{step_name}/inference"
                    }
                }
                
                # Stepë³„ ëª¨ë¸ ìˆ˜
                if step_loader and hasattr(step_loader, 'models'):
                    step_info['models_count'] = len(step_loader.models) if step_loader.models else 0
                
                available_steps['steps'][step_name] = step_info
        
        return JSONResponse(content=available_steps)
        
    except Exception as e:
        return JSONResponse(content={
            'error': f'ì‚¬ìš© ê°€ëŠ¥í•œ Step ì¡°íšŒ ì‹¤íŒ¨: {e}'
        }, status_code=500)

@app.get("/")
async def root():
    """ë£¨íŠ¸ ê²½ë¡œ - í”„ë¡ íŠ¸ì—”ë“œ í˜¸í™˜ì„± ìµœì í™”"""
    return {
        "message": "MyCloset AI Backend v30.0 - Central Hub DI Container v7.0 ì™„ì „ ì—°ë™",
        "status": "running",
        "version": "30.0.0",
        "architecture": "Central Hub DI Container v7.0 ì¤‘ì‹¬ + StepServiceManager v17.0 + RealAIStepImplementationManager v16.0",
        "frontend_compatibility": {
            "react": "100% í˜¸í™˜",
            "typescript": "100% í˜¸í™˜",
            "websocket": "ì‹¤ì‹œê°„ í†µì‹  ì§€ì›",
            "cors": "í”„ë¡ íŠ¸ì—”ë“œ í¬íŠ¸ ìµœì í™”",
            "api_format": "í‘œì¤€ JSON ì‘ë‹µ"
        },
        "features": [
            "ì‹¤ì œ ë°±ì—”ë“œ í´ë” êµ¬ì¡° ê¸°ë°˜ ì™„ì „ ì—°ë™",
            "í”„ë¡ íŠ¸ì—”ë“œ í˜¸í™˜ì„± 100% ë³´ì¥",
            "Central Hub DI Container v7.0 ì™„ì „ ì—°ë™",
            "StepServiceManager v17.0 ì™„ë²½ ì—°ë™",
            "RealAIStepImplementationManager v16.0 ì™„ì „ í†µí•©",
            "step_routes.py v7.0 ì™„ì „ í˜¸í™˜",
            "step_implementations.py DetailedDataSpec ì™„ì „ í†µí•©",
            "ì‹¤ì œ 229GB AI ëª¨ë¸ ì™„ì „ í™œìš©",
            "8ë‹¨ê³„ ì‹¤ì œ AI íŒŒì´í”„ë¼ì¸ (HumanParsing ~ QualityAssessment)",
            "SmartModelPathMapper ë™ì  ê²½ë¡œ ë§¤í•‘",
            "BaseStepMixin v20.0 ì˜ì¡´ì„± ì£¼ì…",
            "BodyMeasurements ìŠ¤í‚¤ë§ˆ ì™„ì „ í˜¸í™˜",
            "WebSocket ì‹¤ì‹œê°„ AI ì§„í–‰ë¥ ",
            "ì„¸ì…˜ ê¸°ë°˜ ì´ë¯¸ì§€ ê´€ë¦¬",
            "conda í™˜ê²½ mycloset-ai-clean ìµœì í™”",
            "M3 Max 128GB ë©”ëª¨ë¦¬ ìµœì í™”"
        ],
        "docs": "/docs",
        "health": "/health",
        "central_hub_endpoints": {
            "status": "/central-hub/status",
            "services": "/central-hub/services"
        },
        "api_endpoints": {
            "step_api": "/api/step/health",
            "system_info": "/api/system/info",
            "virtual_fitting": "/api/step/7/virtual-fitting",
            "complete_pipeline": "/api/step/complete",
            "pipeline_v1": "/api/v1/pipeline/*",
            "websocket": "/api/ws/*",
            "model_loader": {
                "status": "/api/model-loader/status",
                "available_steps": "/api/model-loader/available-steps",
                "step_models": "/api/model-loader/step/{step_name}/models",
                "step_inference": "/api/model-loader/step/{step_name}/inference"
            }
        },
        "test_endpoints": {
            "full_pipeline_test": "/test/full-pipeline",
            "specific_step_test": "/test/step/{step_id}",
            "pipeline_status": "/test/pipeline-status"
        },
        "central_hub_di_container": {
            "available": CENTRAL_HUB_CONTAINER_AVAILABLE,
            "version": "v7.0",
            "step_service_manager_integration": "v17.0",
            "real_ai_implementation_integration": "v16.0",
            "step_implementations_integration": "DetailedDataSpec",
            "container_id": getattr(central_hub_container, 'container_id', 'unknown') if central_hub_container else None,
            "services_count": len(central_hub_container.list_services()) if central_hub_container and hasattr(central_hub_container, 'list_services') else 0,
            "model_loader": {
                "available": central_hub_container.get('model_loader') is not None if central_hub_container else False,
                "type": "CentralModelLoader v7.0",
                "step_loaders_count": len(central_hub_container.get('model_loader').step_loaders) if central_hub_container and central_hub_container.get('model_loader') and hasattr(central_hub_container.get('model_loader'), 'step_loaders') else 0,
                "device": central_hub_container.get('model_loader').device if central_hub_container and central_hub_container.get('model_loader') and hasattr(central_hub_container.get('model_loader'), 'device') else DEVICE
            }
        },
        "system": {
            "conda_environment": IS_CONDA,
            "conda_env": SYSTEM_INFO['conda_env'],
            "mycloset_optimized": IS_MYCLOSET_ENV,
            "m3_max": IS_M3_MAX,
            "device": DEVICE,
            "memory_gb": SYSTEM_INFO['memory_gb']
        },
        "frontend_ports": {
            "react_dev": "http://localhost:3000",
            "vite_dev": "http://localhost:5173",
            "additional_ports": ["3001", "8080"]
        }
    }

# ğŸ”¥ Health ì—”ë“œí¬ì¸íŠ¸ëŠ” API ë¼ìš°í„°ì—ì„œ ì²˜ë¦¬ë¨ (/health)
# ì¤‘ë³µ ë“±ë¡ ë°©ì§€ë¥¼ ìœ„í•´ main.pyì—ì„œëŠ” ì œê±°
# í”„ë¡ íŠ¸ì—”ë“œì—ì„œ /health ì—”ë“œí¬ì¸íŠ¸ë¡œ ì„œë²„ ìƒíƒœ í™•ì¸ ê°€ëŠ¥

# =============================================================================
# ğŸ”¥ 12. WebSocket ì—”ë“œí¬ì¸íŠ¸ (Central Hub ì—°ë™)
# =============================================================================

@app.websocket("/ws")
async def websocket_endpoint(websocket: WebSocket, session_id: str = None):
    """ë©”ì¸ WebSocket ì—”ë“œí¬ì¸íŠ¸ - Central Hub DI Container ì—°ë™"""
    if not session_id:
        session_id = f"ws_{int(time.time())}_{uuid.uuid4().hex[:8]}"
    
    try:
        await websocket.accept()
        print_status(f"ğŸ”Œ Central Hub WebSocket ì—°ê²° ì„±ê³µ: {session_id}")
        
        # Central Hub Containerë¥¼ í†µí•œ WebSocket ê´€ë¦¬ì ì¡°íšŒ
        websocket_manager = None
        if central_hub_container:
            websocket_manager = central_hub_container.get('websocket_manager')
        
        # ì—°ê²° í™•ì¸ ë©”ì‹œì§€ (Central Hub ìƒíƒœ í¬í•¨)
        await websocket.send_text(json.dumps({
            "type": "central_hub_connection_established",
            "message": "MyCloset AI WebSocket ì—°ê²° ì™„ë£Œ (Central Hub DI Container v7.0 ì—°ë™)",
            "timestamp": int(time.time()),
            "central_hub_available": CENTRAL_HUB_CONTAINER_AVAILABLE,
            "step_service_manager_ready": STEP_SERVICE_MANAGER_AVAILABLE,
            "device": DEVICE,
            "is_m3_max": IS_M3_MAX,
            "is_mycloset_env": IS_MYCLOSET_ENV,
            "services_count": len(central_hub_container.list_services()) if central_hub_container and hasattr(central_hub_container, 'list_services') else 0
        }))
        
        while True:
            try:
                data = await websocket.receive_text()
                message = json.loads(data)
                
                # Central Hubë¥¼ í†µí•œ ë©”ì‹œì§€ ì²˜ë¦¬
                if message.get("type") == "central_hub_ping":
                    await websocket.send_text(json.dumps({
                        "type": "central_hub_pong",
                        "message": "Central Hub DI Container v7.0 ì—°ê²° í™•ì¸",
                        "timestamp": int(time.time()),
                        "central_hub_available": CENTRAL_HUB_CONTAINER_AVAILABLE,
                        "services_count": len(central_hub_container.list_services()) if central_hub_container and hasattr(central_hub_container, 'list_services') else 0
                    }))
                
                elif message.get("type") == "get_central_hub_status":
                    container_stats = {}
                    if central_hub_container and hasattr(central_hub_container, 'get_stats'):
                        container_stats = central_hub_container.get_stats()
                    
                    await websocket.send_text(json.dumps({
                        "type": "central_hub_status",
                        "message": "Central Hub DI Container v7.0 ì‹œìŠ¤í…œ ìƒíƒœ",
                        "timestamp": int(time.time()),
                        "central_hub_available": CENTRAL_HUB_CONTAINER_AVAILABLE,
                        "container_stats": container_stats
                    }))
                
            except WebSocketDisconnect:
                break
            except Exception as e:
                print_error(f"âŒ Central Hub WebSocket ë©”ì‹œì§€ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
                break
    
    except Exception as e:
        print_error(f"âŒ Central Hub WebSocket ì—°ê²° ì˜¤ë¥˜: {e}")
    
    finally:
        print_status(f"ğŸ”Œ Central Hub WebSocket ì—°ê²° ì¢…ë£Œ: {session_id}")

# =============================================================================
# ğŸ”¥ 13. ì „ì²´ íŒŒì´í”„ë¼ì¸ í†µí•© í…ŒìŠ¤íŠ¸ ì‹œìŠ¤í…œ
# =============================================================================

@app.get("/test/full-pipeline")
async def test_full_pipeline():
    """ì „ì²´ AI íŒŒì´í”„ë¼ì¸ í†µí•© í…ŒìŠ¤íŠ¸"""
    try:
        print_status("ğŸ§ª ì „ì²´ íŒŒì´í”„ë¼ì¸ í†µí•© í…ŒìŠ¤íŠ¸ ì‹œì‘")
        
        # í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì €ì¥ìš©
        test_results = {
            'overall_status': 'running',
            'start_time': datetime.now().isoformat(),
            'steps': {},
            'summary': {},
            'errors': []
        }
        
        # 1ë‹¨ê³„: Human Parsing í…ŒìŠ¤íŠ¸
        try:
            print_status("ğŸ” 1ë‹¨ê³„: Human Parsing í…ŒìŠ¤íŠ¸")
            from app.ai_pipeline.steps.step_01_human_parsing import HumanParsingStep
            
            step1 = HumanParsingStep()
            test_results['steps']['step_01_human_parsing'] = {
                'status': 'success',
                'message': 'Human Parsing Step ë¡œë“œ ì„±ê³µ',
                'timestamp': datetime.now().isoformat()
            }
        except ImportError as e:
            error_msg = f"Human Parsing Step import ì‹¤íŒ¨: {e}"
            test_results['steps']['step_01_human_parsing'] = {
                'status': 'failed',
                'error': f"Import ì‹¤íŒ¨: {e}",
                'timestamp': datetime.now().isoformat()
            }
            test_results['errors'].append(error_msg)
            print_error(error_msg)
        except Exception as e:
            error_msg = f"Human Parsing Step í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}"
            test_results['steps']['step_01_human_parsing'] = {
                'status': 'failed',
                'error': str(e),
                'timestamp': datetime.now().isoformat()
            }
            test_results['errors'].append(error_msg)
            print_error(error_msg)
        
        # 2ë‹¨ê³„: Pose Estimation í…ŒìŠ¤íŠ¸
        try:
            print_status("ğŸ” 2ë‹¨ê³„: Pose Estimation í…ŒìŠ¤íŠ¸")
            from app.ai_pipeline.steps.step_02_pose_estimation import PoseEstimationStep
            
            step2 = PoseEstimationStep()
            test_results['steps']['step_02_pose_estimation'] = {
                'status': 'success',
                'message': 'Pose Estimation Step ë¡œë“œ ì„±ê³µ',
                'timestamp': datetime.now().isoformat()
            }
        except ImportError as e:
            error_msg = f"Pose Estimation Step import ì‹¤íŒ¨: {e}"
            test_results['steps']['step_02_pose_estimation'] = {
                'status': 'failed',
                'error': f"Import ì‹¤íŒ¨: {e}",
                'timestamp': datetime.now().isoformat()
            }
            test_results['errors'].append(error_msg)
            print_error(error_msg)
        except Exception as e:
            error_msg = f"Pose Estimation Step í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}"
            test_results['steps']['step_02_pose_estimation'] = {
                'status': 'failed',
                'error': str(e),
                'timestamp': datetime.now().isoformat()
            }
            test_results['errors'].append(error_msg)
            print_error(error_msg)
        
        # 3ë‹¨ê³„: Cloth Segmentation í…ŒìŠ¤íŠ¸
        try:
            print_status("ğŸ” 3ë‹¨ê³„: Cloth Segmentation í…ŒìŠ¤íŠ¸")
            from app.ai_pipeline.steps.step_03_cloth_segmentation import ClothSegmentationStep
            
            step3 = ClothSegmentationStep()
            test_results['steps']['step_03_cloth_segmentation'] = {
                'status': 'success',
                'message': 'Cloth Segmentation Step ë¡œë“œ ì„±ê³µ',
                'timestamp': datetime.now().isoformat()
            }
        except ImportError as e:
            error_msg = f"Cloth Segmentation Step import ì‹¤íŒ¨: {e}"
            test_results['steps']['step_03_cloth_segmentation'] = {
                'status': 'failed',
                'error': f"Import ì‹¤íŒ¨: {e}",
                'timestamp': datetime.now().isoformat()
            }
            test_results['errors'].append(error_msg)
            print_error(error_msg)
        except Exception as e:
            error_msg = f"Cloth Segmentation Step í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}"
            test_results['steps']['step_03_cloth_segmentation'] = {
                'status': 'failed',
                'error': str(e),
                'timestamp': datetime.now().isoformat()
            }
            test_results['errors'].append(error_msg)
            print_error(error_msg)
        
        # 4ë‹¨ê³„: Geometric Matching í…ŒìŠ¤íŠ¸
        try:
            print_status("ğŸ” 4ë‹¨ê³„: Geometric Matching í…ŒìŠ¤íŠ¸")
            from app.ai_pipeline.steps.step_04_geometric_matching import GeometricMatchingStep
            
            step4 = GeometricMatchingStep()
            test_results['steps']['step_04_geometric_matching'] = {
                'status': 'success',
                'message': 'Geometric Matching Step ë¡œë“œ ì„±ê³µ',
                'timestamp': datetime.now().isoformat()
            }
        except Exception as e:
            error_msg = f"Geometric Matching Step í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}"
            test_results['steps']['step_04_geometric_matching'] = {
                'status': 'failed',
                'error': str(e),
                'timestamp': datetime.now().isoformat()
            }
            test_results['errors'].append(error_msg)
            print_error(error_msg)
        
        # 5ë‹¨ê³„: Cloth Warping í…ŒìŠ¤íŠ¸
        try:
            print_status("ğŸ” 5ë‹¨ê³„: Cloth Warping í…ŒìŠ¤íŠ¸")
            from app.ai_pipeline.steps.step_05_cloth_warping import ClothWarpingStep
            
            step5 = ClothWarpingStep()
            test_results['steps']['step_05_cloth_warping'] = {
                'status': 'success',
                'message': 'Cloth Warping Step ë¡œë“œ ì„±ê³µ',
                'timestamp': datetime.now().isoformat()
            }
        except Exception as e:
            error_msg = f"Cloth Warping Step í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}"
            test_results['steps']['step_05_cloth_warping'] = {
                'status': 'failed',
                'error': str(e),
                'timestamp': datetime.now().isoformat()
            }
            test_results['errors'].append(error_msg)
            print_error(error_msg)
        
        # 6ë‹¨ê³„: Virtual Fitting í…ŒìŠ¤íŠ¸
        try:
            print_status("ğŸ” 6ë‹¨ê³„: Virtual Fitting í…ŒìŠ¤íŠ¸")
            from app.ai_pipeline.steps.step_06_virtual_fitting import VirtualFittingStep
            
            step6 = VirtualFittingStep()
            test_results['steps']['step_06_virtual_fitting'] = {
                'status': 'success',
                'message': 'Virtual Fitting Step ë¡œë“œ ì„±ê³µ',
                'timestamp': datetime.now().isoformat()
            }
        except Exception as e:
            error_msg = f"Virtual Fitting Step í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}"
            test_results['steps']['step_06_virtual_fitting'] = {
                'status': 'failed',
                'error': str(e),
                'timestamp': datetime.now().isoformat()
            }
            test_results['errors'].append(error_msg)
            print_error(error_msg)
        
        # 7ë‹¨ê³„: Post Processing í…ŒìŠ¤íŠ¸
        try:
            print_status("ğŸ” 7ë‹¨ê³„: Post Processing í…ŒìŠ¤íŠ¸")
            from app.ai_pipeline.steps.step_07_post_processing import PostProcessingStep
            
            step7 = PostProcessingStep()
            test_results['steps']['step_07_post_processing'] = {
                'status': 'success',
                'message': 'Post Processing Step ë¡œë“œ ì„±ê³µ',
                'timestamp': datetime.now().isoformat()
            }
        except Exception as e:
            error_msg = f"Post Processing Step í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}"
            test_results['steps']['step_07_post_processing'] = {
                'status': 'failed',
                'error': str(e),
                'timestamp': datetime.now().isoformat()
            }
            test_results['errors'].append(error_msg)
            print_error(error_msg)
        
        # 8ë‹¨ê³„: Quality Assessment í…ŒìŠ¤íŠ¸
        try:
            print_status("ğŸ” 8ë‹¨ê³„: Quality Assessment í…ŒìŠ¤íŠ¸")
            from app.ai_pipeline.steps.step_08_quality_assessment import QualityAssessmentStep
            
            step8 = QualityAssessmentStep()
            test_results['steps']['step_08_quality_assessment'] = {
                'status': 'success',
                'message': 'Quality Assessment Step ë¡œë“œ ì„±ê³µ',
                'timestamp': datetime.now().isoformat()
            }
        except Exception as e:
            error_msg = f"Quality Assessment Step í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}"
            test_results['steps']['step_08_quality_assessment'] = {
                'status': 'failed',
                'error': str(e),
                'timestamp': datetime.now().isoformat()
            }
            test_results['errors'].append(error_msg)
            print_error(error_msg)
        
        # 9ë‹¨ê³„: Final Output í…ŒìŠ¤íŠ¸
        try:
            print_status("ğŸ” 9ë‹¨ê³„: Final Output í…ŒìŠ¤íŠ¸")
            from app.ai_pipeline.steps.step_09_final_output import FinalOutputStep
            
            step9 = FinalOutputStep()
            test_results['steps']['step_09_final_output'] = {
                'status': 'success',
                'message': 'Final Output Step ë¡œë“œ ì„±ê³µ',
                'timestamp': datetime.now().isoformat()
            }
        except Exception as e:
            error_msg = f"Final Output Step í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}"
            test_results['steps']['step_09_final_output'] = {
                'status': 'failed',
                'error': str(e),
                'timestamp': datetime.now().isoformat()
            }
            test_results['errors'].append(error_msg)
            print_error(error_msg)
        
        # ì „ì²´ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½
        total_steps = len(test_results['steps'])
        successful_steps = sum(1 for step in test_results['steps'].values() if step['status'] == 'success')
        failed_steps = total_steps - successful_steps
        
        test_results['overall_status'] = 'completed'
        test_results['end_time'] = datetime.now().isoformat()
        test_results['summary'] = {
            'total_steps': total_steps,
            'successful_steps': successful_steps,
            'failed_steps': failed_steps,
            'success_rate': f"{(successful_steps/total_steps)*100:.1f}%" if total_steps > 0 else "0%",
            'overall_status': 'PASS' if failed_steps == 0 else 'FAIL'
        }
        
        # ê²°ê³¼ ì¶œë ¥
        if failed_steps == 0:
            print_status(f"ğŸ‰ ì „ì²´ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸ ì™„ë£Œ: {successful_steps}/{total_steps} ë‹¨ê³„ ì„±ê³µ!")
        else:
            print_warning(f"âš ï¸ ì „ì²´ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸ ì™„ë£Œ: {successful_steps}/{total_steps} ë‹¨ê³„ ì„±ê³µ, {failed_steps} ë‹¨ê³„ ì‹¤íŒ¨")
        
        return JSONResponse(content=test_results)
        
    except Exception as e:
        error_result = {
            'overall_status': 'error',
            'error': str(e),
            'timestamp': datetime.now().isoformat()
        }
        print_error(f"âŒ ì „ì²´ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì˜¤ë¥˜: {e}")
        return JSONResponse(content=error_result, status_code=500)

@app.get("/test/step/{step_id}")
async def test_specific_step(step_id: int):
    """íŠ¹ì • ë‹¨ê³„ í…ŒìŠ¤íŠ¸"""
    try:
        step_names = {
            1: "Human Parsing",
            2: "Pose Estimation", 
            3: "Cloth Segmentation",
            4: "Geometric Matching",
            5: "Cloth Warping",
            6: "Virtual Fitting",
            7: "Post Processing",
            8: "Quality Assessment",
            9: "Final Output"
        }
        
        if step_id not in step_names:
            return JSONResponse(content={
                'error': f'Invalid step ID: {step_id}. Valid range: 1-9'
            }, status_code=400)
        
        step_name = step_names[step_id]
        print_status(f"ğŸ§ª {step_id}ë‹¨ê³„: {step_name} í…ŒìŠ¤íŠ¸ ì‹œì‘")
        
        # ë™ì  import ë° í…ŒìŠ¤íŠ¸
        try:
            module_name = f"app.ai_pipeline.steps.step_{step_id:02d}_{step_name.lower().replace(' ', '_')}"
            class_name = f"{step_name.replace(' ', '')}Step"
            
            # ëª¨ë“ˆ import
            module = __import__(module_name, fromlist=[class_name])
            step_class = getattr(module, class_name)
            
            # ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
            step_instance = step_class()
            
            test_result = {
                'step_id': step_id,
                'step_name': step_name,
                'status': 'success',
                'message': f'{step_name} Step ë¡œë“œ ë° ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ì„±ê³µ',
                'timestamp': datetime.now().isoformat(),
                'class_name': step_class.__name__,
                'module_path': module_name
            }
            
            print_status(f"âœ… {step_id}ë‹¨ê³„: {step_name} í…ŒìŠ¤íŠ¸ ì„±ê³µ")
            return JSONResponse(content=test_result)
            
        except Exception as e:
            error_result = {
                'step_id': step_id,
                'step_name': step_name,
                'status': 'failed',
                'error': str(e),
                'timestamp': datetime.now().isoformat()
            }
            print_error(f"âŒ {step_id}ë‹¨ê³„: {step_name} í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
            return JSONResponse(content=error_result, status_code=500)
            
    except Exception as e:
        return JSONResponse(content={
            'error': f'Step í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì˜¤ë¥˜: {e}'
        }, status_code=500)

@app.get("/test/pipeline-status")
async def get_pipeline_status():
    """ì „ì²´ íŒŒì´í”„ë¼ì¸ ìƒíƒœ í™•ì¸"""
    try:
        pipeline_status = {
            'total_steps': 9,
            'available_steps': [],
            'missing_steps': [],
            'timestamp': datetime.now().isoformat()
        }
        
        step_configs = [
            (1, "Human Parsing", "step_01_human_parsing"),
            (2, "Pose Estimation", "step_02_pose_estimation"),
            (3, "Cloth Segmentation", "step_03_cloth_segmentation"),
            (4, "Geometric Matching", "step_04_geometric_matching"),
            (5, "Cloth Warping", "step_05_cloth_warping"),
            (6, "Virtual Fitting", "step_06_virtual_fitting"),
            (7, "Post Processing", "step_07_post_processing"),
            (8, "Quality Assessment", "step_08_quality_assessment"),
            (9, "Final Output", "step_09_final_output")
        ]
        
        for step_id, step_name, step_file in step_configs:
            try:
                # íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
                step_path = f"app/ai_pipeline/steps/{step_file}.py"
                if os.path.exists(step_path):
                    pipeline_status['available_steps'].append({
                        'step_id': step_id,
                        'step_name': step_name,
                        'file_path': step_path,
                        'status': 'available'
                    })
                else:
                    pipeline_status['missing_steps'].append({
                        'step_id': step_id,
                        'step_name': step_name,
                        'file_path': step_path,
                        'status': 'missing'
                    })
            except Exception as e:
                pipeline_status['missing_steps'].append({
                    'step_id': step_id,
                    'step_name': step_name,
                    'file_path': step_path,
                    'status': 'error',
                    'error': str(e)
                })
        
        pipeline_status['summary'] = {
            'available_count': len(pipeline_status['available_steps']),
            'missing_count': len(pipeline_status['missing_steps']),
            'completion_rate': f"{(len(pipeline_status['available_steps'])/9)*100:.1f}%"
        }
        
        return JSONResponse(content=pipeline_status)
        
    except Exception as e:
        return JSONResponse(content={
            'error': f'íŒŒì´í”„ë¼ì¸ ìƒíƒœ í™•ì¸ ì˜¤ë¥˜: {e}'
        }, status_code=500)

# =============================================================================
# ğŸ”¥ 14. ì„œë²„ ì‹œì‘ í•¨ìˆ˜ ë° ë©”ì¸ ì‹¤í–‰
# =============================================================================

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜ - ì‹¤ì œ ë°±ì—”ë“œ í™˜ê²½ ìµœì í™”"""
    
    # ì„œë²„ ì‹œì‘ ì‹œ ìƒì„¸í•œ ì •ë³´ í‘œì‹œ
    print("ğŸš€ MyCloset AI ì„œë²„ ì‹œì‘")
    print(f"ğŸ“ ì„œë²„ ì£¼ì†Œ: http://{settings.HOST}:{settings.PORT}")
    print("âœ… Central Hub DI Container v7.0 ê¸°ë°˜")
    print("âœ… ì¤‘ì•™ í†µí•© ModelLoader v7.0 ì™„ì „ ì—°ë™")
    print("âœ… ì‹¤ì œ ë°±ì—”ë“œ í´ë” êµ¬ì¡° ê¸°ë°˜ ì™„ì „ ì—°ë™")
    print("âœ… í”„ë¡ íŠ¸ì—”ë“œ í˜¸í™˜ì„± 100% ë³´ì¥")
    print("âœ… 8ê°œ AI Step ë¡œë”© ì™„ë£Œ")
    print("âœ… SQLite SessionManager ì¤€ë¹„ ì™„ë£Œ")
    print("âœ… WebSocket ì‹¤ì‹œê°„ í†µì‹  ì¤€ë¹„ ì™„ë£Œ")
    print("âœ… CORS í”„ë¡ íŠ¸ì—”ë“œ í¬íŠ¸ ìµœì í™”")
    print("âœ… ModelLoader API ì—”ë“œí¬ì¸íŠ¸ ì¤€ë¹„ ì™„ë£Œ")
    print("=" * 60)
    
    # í™˜ê²½ë³„ ì„œë²„ ì„¤ì •
    if os.getenv('ENVIRONMENT') == 'production':
        # í”„ë¡œë•ì…˜ í™˜ê²½
        config = {
            "host": settings.HOST,
            "port": settings.PORT,
            "reload": False,
            "log_level": "info",
            "access_log": True,
            "workers": 1
        }
        print("ğŸ­ í”„ë¡œë•ì…˜ ëª¨ë“œë¡œ ì‹¤í–‰")
    else:
        # ê°œë°œ í™˜ê²½
        config = {
            "host": settings.HOST,
            "port": settings.PORT,
            "reload": False,  # ì•ˆì •ì„±ì„ ìœ„í•´ reload ë¹„í™œì„±í™”
            "log_level": "error",
            "access_log": False
        }
        print("ğŸ”§ ê°œë°œ ëª¨ë“œë¡œ ì‹¤í–‰")
    
    # í”„ë¡ íŠ¸ì—”ë“œ í¬íŠ¸ ì •ë³´ í‘œì‹œ
    print("ğŸŒ í”„ë¡ íŠ¸ì—”ë“œ í˜¸í™˜ í¬íŠ¸:")
    print("   - React: http://localhost:3000")
    print("   - Vite: http://localhost:5173")
    print("   - ì¶”ê°€: http://localhost:3001, http://localhost:8080")
    
    # ModelLoader API ì—”ë“œí¬ì¸íŠ¸ ì •ë³´ í‘œì‹œ
    print("ğŸ§  ModelLoader API ì—”ë“œí¬ì¸íŠ¸:")
    print("   - ìƒíƒœ í™•ì¸: /api/model-loader/status")
    print("   - Step ëª©ë¡: /api/model-loader/available-steps")
    print("   - Step ëª¨ë¸: /api/model-loader/step/{step_name}/models")
    print("   - AI ì¶”ë¡ : /api/model-loader/step/{step_name}/inference")
    
    # ì„œë²„ ì‹œì‘ ì „ ìµœì¢… ìƒíƒœ í™•ì¸
    print("ğŸ” ì„œë²„ ì‹œì‘ ì „ ìµœì¢… ìƒíƒœ í™•ì¸...")
    
    # Central Hub ìƒíƒœ í™•ì¸
    if CENTRAL_HUB_CONTAINER_AVAILABLE and central_hub_container:
        print("âœ… Central Hub DI Container ì¤€ë¹„ ì™„ë£Œ")
    else:
        print("âš ï¸ Central Hub DI Container ë¯¸ì¤€ë¹„ - í´ë°± ëª¨ë“œ")
    
    # ì„¤ì • ìƒíƒœ í™•ì¸
    if hasattr(settings, 'HOST') and hasattr(settings, 'PORT'):
        print("âœ… ì„¤ì • ëª¨ë“ˆ ì¤€ë¹„ ì™„ë£Œ")
    else:
        print("âš ï¸ ì„¤ì • ëª¨ë“ˆ ë¯¸ì¤€ë¹„ - ê¸°ë³¸ê°’ ì‚¬ìš©")
    
    print("ğŸ¯ ì„œë²„ ì‹œì‘ ì¤€ë¹„ ì™„ë£Œ!")
    
    # uvicorn ì„œë²„ ì‹œì‘ (íƒ€ì„ì•„ì›ƒ ë° ì—ëŸ¬ ì²˜ë¦¬ ê°•í™”)
    try:
        print("ğŸš€ uvicorn ì„œë²„ ì‹œì‘ ì¤‘...")
        uvicorn.run(app, **config)
    except KeyboardInterrupt:
        print("\nâœ… ì„œë²„ê°€ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"âŒ ì„œë²„ ì‹œì‘ ì‹¤íŒ¨: {e}")
        print_error(f"ì„œë²„ ì‹œì‘ ì‹¤íŒ¨: {e}")
        print("ğŸ” ìƒì„¸ ì˜¤ë¥˜ ì •ë³´:")
        traceback.print_exc()
        
        # ì„œë²„ ì‹œì‘ ì‹¤íŒ¨ ì‹œ ëŒ€ì•ˆ ì œì‹œ
        print("\nğŸ”„ ëŒ€ì•ˆ ì‹¤í–‰ ë°©ë²•:")
        print("   1. conda activate myclosetlast")
        print("   2. cd backend")
        print("   3. python3 -m uvicorn app.main:app --host 0.0.0.0 --port 8000")
        
        sys.exit(1)

# =============================================================================
# ğŸ”¥ 15. í”„ë¡œê·¸ë¨ ì§„ì…ì  - ì‹¤ì œ ë°±ì—”ë“œ í™˜ê²½ ìµœì í™”
# =============================================================================

if __name__ == "__main__":
    try:
        print("ğŸš€ MyCloset AI Backend v30.0 ì‹œì‘ ì¤‘...")
        print("âœ… ì‹¤ì œ ë°±ì—”ë“œ í´ë” êµ¬ì¡° ê¸°ë°˜")
        print("âœ… í”„ë¡ íŠ¸ì—”ë“œ í˜¸í™˜ì„± 100% ë³´ì¥")
        print("âœ… Central Hub DI Container v7.0 ì™„ì „ ì—°ë™")
        print("=" * 60)
        
        main()
        
    except KeyboardInterrupt:
        print("\nâœ… Central Hub DI Container v7.0 ê¸°ë°˜ ì„œë²„ê°€ ì•ˆì „í•˜ê²Œ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
        print("âœ… í”„ë¡ íŠ¸ì—”ë“œ ì—°ê²°ì´ ì•ˆì „í•˜ê²Œ í•´ì œë˜ì—ˆìŠµë‹ˆë‹¤.")
        
    except Exception as e:
        print(f"\nâŒ ì„œë²„ ì‹¤í–‰ ì˜¤ë¥˜: {e}")
        print_error(f"ì„œë²„ ì‹¤í–‰ ì˜¤ë¥˜: {e}")
        print("ğŸ” ìƒì„¸ ì˜¤ë¥˜ ì •ë³´:")
        traceback.print_exc()
        
        # ì˜¤ë¥˜ ë°œìƒ ì‹œ ì‹œìŠ¤í…œ ì •ë³´ ì¶œë ¥
        try:
            print("\nğŸ” ì‹œìŠ¤í…œ ì •ë³´:")
            print(f"   - Python ë²„ì „: {sys.version}")
            print(f"   - ì‘ì—… ë””ë ‰í† ë¦¬: {os.getcwd()}")
            print(f"   - í™˜ê²½ ë³€ìˆ˜: CONDA_DEFAULT_ENV={os.environ.get('CONDA_DEFAULT_ENV', 'none')}")
            print(f"   - ë©”ëª¨ë¦¬: {MEMORY_GB}GB")
            print(f"   - ë””ë°”ì´ìŠ¤: {DEVICE}")
        except Exception as info_e:
            print(f"   - ì‹œìŠ¤í…œ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {info_e}")
        
        sys.exit(1)

# =============================================================================
# ğŸ”¥ 16. í´ë°± ModelLoader í•¨ìˆ˜ë“¤
# =============================================================================

def _create_fallback_model_loader():
    """í´ë°± ModelLoader ìƒì„±"""
    try:
        class FallbackModelLoader:
            def __init__(self):
                self.device = DEVICE
                self.step_loaders = {}
                self.central_hub = None
                self.logger = logging.getLogger("FallbackModelLoader")
            
            def initialize_step_loaders(self):
                """ê¸°ë³¸ Step ë¡œë”ë“¤ ì´ˆê¸°í™”"""
                self.step_loaders = {
                    'human_parsing': {'status': 'fallback', 'models': {}},
                    'pose_estimation': {'status': 'fallback', 'models': {}},
                    'cloth_segmentation': {'status': 'fallback', 'models': {}},
                    'geometric_matching': {'status': 'fallback', 'models': {}},
                    'virtual_fitting': {'status': 'fallback', 'models': {}},
                    'cloth_warping': {'status': 'fallback', 'models': {}},
                    'post_processing': {'status': 'fallback', 'models': {}},
                    'quality_assessment': {'status': 'fallback', 'models': {}}
                }
                self.logger.info("âœ… í´ë°± Step ë¡œë”ë“¤ ì´ˆê¸°í™” ì™„ë£Œ")
            
            def get_model_status(self):
                """ëª¨ë¸ ìƒíƒœ ë°˜í™˜"""
                return {
                    'total_steps': len(self.step_loaders),
                    'loaded_steps': 0,
                    'step_status': {name: {'status': 'fallback'} for name in self.step_loaders.keys()},
                    'device': self.device,
                    'cache_dir': 'fallback',
                    'central_hub_connected': False
                }
            
            def cleanup(self):
                """ì •ë¦¬"""
                self.logger.info("âœ… í´ë°± ModelLoader ì •ë¦¬ ì™„ë£Œ")
        
        loader = FallbackModelLoader()
        loader.initialize_step_loaders()
        return loader
        
    except Exception as e:
        print_error(f"âŒ í´ë°± ModelLoader ìƒì„± ì‹¤íŒ¨: {e}")
        return None

def _create_mock_model_loader():
    """Mock ModelLoader ìƒì„± (ìµœí›„ì˜ ìˆ˜ë‹¨)"""
    try:
        class MockModelLoader:
            def __init__(self):
                self.device = DEVICE
                self.step_loaders = {}
                self.central_hub = None
                self.logger = logging.getLogger("MockModelLoader")
            
            def initialize_step_loaders(self):
                """Mock Step ë¡œë”ë“¤ ì´ˆê¸°í™”"""
                self.step_loaders = {
                    'human_parsing': {'status': 'mock', 'models': {}},
                    'pose_estimation': {'status': 'mock', 'models': {}},
                    'cloth_segmentation': {'status': 'mock', 'models': {}},
                    'geometric_matching': {'status': 'mock', 'models': {}},
                    'virtual_fitting': {'status': 'mock', 'models': {}},
                    'cloth_warping': {'status': 'mock', 'models': {}},
                    'post_processing': {'status': 'mock', 'models': {}},
                    'quality_assessment': {'status': 'mock', 'models': {}}
                }
                self.logger.info("âœ… Mock Step ë¡œë”ë“¤ ì´ˆê¸°í™” ì™„ë£Œ")
            
            def get_model_status(self):
                """ëª¨ë¸ ìƒíƒœ ë°˜í™˜"""
                return {
                    'total_steps': len(self.step_loaders),
                    'loaded_steps': 0,
                    'step_status': {name: {'status': 'mock'} for name in self.step_loaders.keys()},
                    'device': self.device,
                    'cache_dir': 'mock',
                    'central_hub_connected': False
                }
            
            def cleanup(self):
                """ì •ë¦¬"""
                self.logger.info("âœ… Mock ModelLoader ì •ë¦¬ ì™„ë£Œ")
        
        loader = MockModelLoader()
        loader.initialize_step_loaders()
        return loader
        
    except Exception as e:
        print_error(f"âŒ Mock ModelLoader ìƒì„± ì‹¤íŒ¨: {e}")
        return None

# =============================================================================
# ğŸ”¥ 17. ì‹¤í–‰ ê°€ëŠ¥í•œ ìƒíƒœ í™•ì¸
# =============================================================================

def check_execution_ready():
    """ì‹¤í–‰ ê°€ëŠ¥í•œ ìƒíƒœì¸ì§€ í™•ì¸"""
    try:
        print("ğŸ” ì‹¤í–‰ ê°€ëŠ¥í•œ ìƒíƒœ í™•ì¸ ì¤‘...")
        
        # 1. í•„ìˆ˜ ëª¨ë“ˆ ì¡´ì¬ í™•ì¸
        required_modules = [
            'app.core.di_container',
            'app.core.config',
            'app.core.session_manager',
            'app.services.step_service',
            'app.api.step_routes',
            'app.api.system_routes',
            'app.api.pipeline_routes',
            'app.api.websocket_routes',
            'app.api.health'
        ]
        
        missing_modules = []
        for module in required_modules:
            try:
                __import__(module)
                print(f"âœ… {module} - ì‚¬ìš© ê°€ëŠ¥")
            except ImportError:
                missing_modules.append(module)
                print(f"âŒ {module} - ì‚¬ìš© ë¶ˆê°€")
        
        # 2. Step í´ë˜ìŠ¤ë“¤ ì¡´ì¬ í™•ì¸
        step_modules = [
            'app.ai_pipeline.steps.step_01_human_parsing',
            'app.ai_pipeline.steps.step_02_pose_estimation',
            'app.ai_pipeline.steps.step_03_cloth_segmentation',
            'app.ai_pipeline.steps.step_04_geometric_matching',
            'app.ai_pipeline.steps.step_05_cloth_warping',
            'app.ai_pipeline.steps.step_06_virtual_fitting',
            'app.ai_pipeline.steps.step_07_post_processing',
            'app.ai_pipeline.steps.step_08_quality_assessment',
            'app.ai_pipeline.steps.step_09_final_output'
        ]
        
        missing_steps = []
        for step_module in step_modules:
            try:
                __import__(step_module)
                print(f"âœ… {step_module} - ì‚¬ìš© ê°€ëŠ¥")
            except ImportError:
                missing_steps.append(step_module)
                print(f"âŒ {step_module} - ì‚¬ìš© ë¶ˆê°€")
        
        # 3. ModelLoader í™•ì¸
        try:
            from app.ai_pipeline.models.model_loader import CentralModelLoader
            print("âœ… CentralModelLoader - ì‚¬ìš© ê°€ëŠ¥")
            model_loader_available = True
        except ImportError:
            print("âŒ CentralModelLoader - ì‚¬ìš© ë¶ˆê°€")
            model_loader_available = False
        
        # 4. ìš”ì•½
        total_required = len(required_modules) + len(step_modules) + 1
        total_available = (total_required - len(missing_modules) - len(missing_steps) - 
                          (0 if model_loader_available else 1))
        
        print(f"\nğŸ“Š ì‹¤í–‰ ê°€ëŠ¥ì„± ìš”ì•½:")
        print(f"   - ì „ì²´ í•„ìš” ëª¨ë“ˆ: {total_required}ê°œ")
        print(f"   - ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë“ˆ: {total_available}ê°œ")
        print(f"   - ëˆ„ë½ëœ ëª¨ë“ˆ: {len(missing_modules) + len(missing_steps) + (0 if model_loader_available else 1)}ê°œ")
        print(f"   - ì‹¤í–‰ ê°€ëŠ¥ì„±: {(total_available/total_required)*100:.1f}%")
        
        if missing_modules or missing_steps or not model_loader_available:
            print(f"\nâš ï¸ ì£¼ì˜ì‚¬í•­:")
            if missing_modules:
                print(f"   - ëˆ„ë½ëœ í•µì‹¬ ëª¨ë“ˆ: {', '.join(missing_modules)}")
            if missing_steps:
                print(f"   - ëˆ„ë½ëœ Step ëª¨ë“ˆ: {', '.join(missing_steps)}")
            if not model_loader_available:
                print(f"   - ModelLoader ì‚¬ìš© ë¶ˆê°€")
            print(f"   - í´ë°± ëª¨ë“œë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤")
        
        return {
            'ready': total_available >= total_required * 0.7,  # 70% ì´ìƒì´ë©´ ì‹¤í–‰ ê°€ëŠ¥
            'total_required': total_required,
            'total_available': total_available,
            'missing_modules': missing_modules,
            'missing_steps': missing_steps,
            'model_loader_available': model_loader_available
        }
        
    except Exception as e:
        print_error(f"âŒ ì‹¤í–‰ ê°€ëŠ¥ì„± í™•ì¸ ì‹¤íŒ¨: {e}")
        return {
            'ready': False,
            'error': str(e)
        }

# =============================================================================
# ğŸ”¥ 18. í”„ë¡œê·¸ë¨ ì§„ì…ì  - ì‹¤ì œ ë°±ì—”ë“œ í™˜ê²½ ìµœì í™”
# =============================================================================

if __name__ == "__main__":
    try:
        print("ğŸš€ MyCloset AI Backend v30.0 ì‹œì‘ ì¤‘...")
        print("âœ… ì‹¤ì œ ë°±ì—”ë“œ í´ë” êµ¬ì¡° ê¸°ë°˜")
        print("âœ… í”„ë¡ íŠ¸ì—”ë“œ í˜¸í™˜ì„± 100% ë³´ì¥")
        print("âœ… Central Hub DI Container v7.0 ì™„ì „ ì—°ë™")
        print("=" * 60)
        
        # ì‹¤í–‰ ê°€ëŠ¥í•œ ìƒíƒœ í™•ì¸
        execution_status = check_execution_ready()
        if not execution_status['ready']:
            print_warning("âš ï¸ ì¼ë¶€ ëª¨ë“ˆì´ ëˆ„ë½ë˜ì–´ í´ë°± ëª¨ë“œë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤")
        
        main()
        
    except KeyboardInterrupt:
        print("\nâœ… Central Hub DI Container v7.0 ê¸°ë°˜ ì„œë²„ê°€ ì•ˆì „í•˜ê²Œ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
        print("âœ… í”„ë¡ íŠ¸ì—”ë“œ ì—°ê²°ì´ ì•ˆì „í•˜ê²Œ í•´ì œë˜ì—ˆìŠµë‹ˆë‹¤.")
        
    except Exception as e:
        print(f"\nâŒ ì„œë²„ ì‹¤í–‰ ì˜¤ë¥˜: {e}")
        print_error(f"ì„œë²„ ì‹¤í–‰ ì˜¤ë¥˜: {e}")
        print("ğŸ” ìƒì„¸ ì˜¤ë¥˜ ì •ë³´:")
        traceback.print_exc()
        
        # ì˜¤ë¥˜ ë°œìƒ ì‹œ ì‹œìŠ¤í…œ ì •ë³´ ì¶œë ¥
        try:
            print("\nğŸ” ì‹œìŠ¤í…œ ì •ë³´:")
            print(f"   - Python ë²„ì „: {sys.version}")
            print(f"   - ì‘ì—… ë””ë ‰í† ë¦¬: {os.getcwd()}")
            print(f"   - í™˜ê²½ ë³€ìˆ˜: CONDA_DEFAULT_ENV={os.environ.get('CONDA_DEFAULT_ENV', 'none')}")
            print(f"   - ë©”ëª¨ë¦¬: {MEMORY_GB}GB")
            print(f"   - ë””ë°”ì´ìŠ¤: {DEVICE}")
        except Exception as info_e:
            print(f"   - ì‹œìŠ¤í…œ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {info_e}")
        
        sys.exit(1)