# backend/app/main.py
"""
MyCloset AI Backend - FastAPI ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜
M3 Max ìµœì í™” ê°€ìƒ í”¼íŒ… ì‹œìŠ¤í…œ
"""

import os
import sys
import logging
from contextlib import asynccontextmanager
from pathlib import Path

from fastapi import FastAPI, HTTPException, Request, UploadFile, File, Form
from fastapi.middleware.cors import CORSMiddleware
from fastapi.middleware.gzip import GZipMiddleware
from fastapi.staticfiles import StaticFiles
from fastapi.responses import JSONResponse
from PIL import Image
import io
import base64
import time
import uvicorn

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì„¤ì •
PROJECT_ROOT = Path(__file__).parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
from dotenv import load_dotenv
load_dotenv(PROJECT_ROOT / ".env")

# ë¡œê¹… ì„¤ì •
from app.core.logging_config import setup_logging
setup_logging()
logger = logging.getLogger(__name__)

# GPU ì„¤ì • ì„í¬íŠ¸
from app.core.gpu_config import gpu_config, startup_gpu_check

# API ë¼ìš°í„° ì„í¬íŠ¸ (ì—ëŸ¬ê°€ ìˆì„ ìˆ˜ ìˆìœ¼ë‹ˆ try-exceptë¡œ ê°ìŒˆ)
from app.api.health import router as health_router
try:
    from app.api.virtual_tryon import router as virtual_tryon_router
    VIRTUAL_TRYON_ROUTER_AVAILABLE = True
except ImportError as e:
    logger.warning(f"âš ï¸ virtual_tryon ë¼ìš°í„° ì„í¬íŠ¸ ì‹¤íŒ¨: {e}")
    VIRTUAL_TRYON_ROUTER_AVAILABLE = False

try:
    from app.api.models import router as models_router
    MODELS_ROUTER_AVAILABLE = True
except ImportError as e:
    logger.warning(f"âš ï¸ models ë¼ìš°í„° ì„í¬íŠ¸ ì‹¤íŒ¨: {e}")
    MODELS_ROUTER_AVAILABLE = False

# ì„¤ì • ì„í¬íŠ¸
from app.core.config import settings


@asynccontextmanager
async def lifespan(app: FastAPI):
    """ì• í”Œë¦¬ì¼€ì´ì…˜ ë¼ì´í”„ì‚¬ì´í´ ê´€ë¦¬"""
    
    # ì‹œì‘ ì‹œ ì‹¤í–‰
    logger.info("ğŸš€ MyCloset AI Backend ì‹œì‘...")
    
    # í•„ìˆ˜ ë””ë ‰í† ë¦¬ ìƒì„±
    directories = [
        settings.UPLOAD_DIR,
        settings.RESULTS_DIR,
        settings.LOGS_DIR,
        PROJECT_ROOT / "ai_models" / "checkpoints",
        PROJECT_ROOT / "ai_models" / "temp",
    ]
    
    for directory in directories:
        Path(directory).mkdir(parents=True, exist_ok=True)
    
    # GPU ì„¤ì • ë° í…ŒìŠ¤íŠ¸
    startup_gpu_check()
    
    # AI ëª¨ë¸ ë¡œë“œ (ë°±ê·¸ë¼ìš´ë“œì—ì„œ)
    try:
        from app.services.model_manager import model_manager
        # ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡ ì—…ë°ì´íŠ¸
        model_manager.available_models = model_manager.get_available_models()
        logger.info(f"âœ… {sum(model_manager.available_models.values())}/{len(model_manager.available_models)} ëª¨ë¸ ê°ì§€ë¨")
        
        # ì„ íƒì  ëª¨ë¸ ë¡œë“œ (ë°±ê·¸ë¼ìš´ë“œì—ì„œ)
        await model_manager.load_models()
        logger.info("âœ… AI ëª¨ë¸ ë§¤ë‹ˆì € ì´ˆê¸°í™” ì™„ë£Œ")
    except Exception as e:
        logger.warning(f"âš ï¸ AI ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        logger.info("â„¹ï¸ ëª¨ë¸ì„ ë¨¼ì € ë‹¤ìš´ë¡œë“œí•˜ì„¸ìš”: python scripts/download_ai_models.py")

    logger.info("âœ… ì• í”Œë¦¬ì¼€ì´ì…˜ ì´ˆê¸°í™” ì™„ë£Œ")
    
    yield
    
    # ì¢…ë£Œ ì‹œ ì‹¤í–‰
    logger.info("ğŸ›‘ MyCloset AI Backend ì¢…ë£Œ...")
    
    # ë©”ëª¨ë¦¬ ì •ë¦¬
    gpu_config.optimize_memory()
    
    # ëª¨ë¸ ì–¸ë¡œë“œ
    try:
        await model_manager.unload_models()
        logger.info("âœ… ëª¨ë¸ ì–¸ë¡œë“œ ì™„ë£Œ")
    except:
        pass
    
    logger.info("ğŸ‘‹ ì• í”Œë¦¬ì¼€ì´ì…˜ ì¢…ë£Œ ì™„ë£Œ")


# FastAPI ì• í”Œë¦¬ì¼€ì´ì…˜ ìƒì„±
app = FastAPI(
    title="MyCloset AI Backend",
    description="M3 Max ìµœì í™” ê°€ìƒ í”¼íŒ… ì‹œìŠ¤í…œ API",
    version="1.0.0",
    docs_url="/docs",
    redoc_url="/redoc",
    lifespan=lifespan
)

# CORS ë¯¸ë“¤ì›¨ì–´ ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=settings.CORS_ORIGINS,
    allow_credentials=True,
    allow_methods=["GET", "POST", "PUT", "DELETE", "OPTIONS"],
    allow_headers=["*"],
)

# Gzip ì••ì¶• ë¯¸ë“¤ì›¨ì–´
app.add_middleware(GZipMiddleware, minimum_size=1000)

# ì •ì  íŒŒì¼ ì„œë¹™
app.mount("/static", StaticFiles(directory=settings.STATIC_DIR), name="static")


@app.middleware("http")
async def logging_middleware(request: Request, call_next):
    """ìš”ì²­ ë¡œê¹… ë¯¸ë“¤ì›¨ì–´"""
    
    import time
    
    # ìš”ì²­ ì‹œì‘ ì‹œê°„
    start_time = time.time()
    
    # ìš”ì²­ ì •ë³´ ë¡œê¹…
    logger.info(f"ğŸ“¥ {request.method} {request.url.path}")
    
    try:
        # ìš”ì²­ ì²˜ë¦¬
        response = await call_next(request)
        
        # ì²˜ë¦¬ ì‹œê°„ ê³„ì‚°
        process_time = time.time() - start_time
        
        # ì‘ë‹µ ë¡œê¹…
        logger.info(f"ğŸ“¤ {request.method} {request.url.path} - {response.status_code} ({process_time:.3f}s)")
        
        # ì‘ë‹µ í—¤ë”ì— ì²˜ë¦¬ ì‹œê°„ ì¶”ê°€
        response.headers["X-Process-Time"] = str(process_time)
        
        return response
        
    except Exception as e:
        # ì—ëŸ¬ ë¡œê¹…
        process_time = time.time() - start_time
        logger.error(f"âŒ {request.method} {request.url.path} - ERROR ({process_time:.3f}s): {e}")
        raise


@app.exception_handler(HTTPException)
async def http_exception_handler(request: Request, exc: HTTPException):
    """HTTP ì˜ˆì™¸ ì²˜ë¦¬"""
    
    logger.warning(f"âš ï¸ HTTP {exc.status_code}: {exc.detail}")
    
    return JSONResponse(
        status_code=exc.status_code,
        content={
            "success": False,
            "error": exc.detail,
            "status_code": exc.status_code,
            "path": request.url.path
        }
    )


@app.exception_handler(Exception)
async def general_exception_handler(request: Request, exc: Exception):
    """ì¼ë°˜ ì˜ˆì™¸ ì²˜ë¦¬"""
    
    logger.error(f"âŒ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ {request.url.path}: {exc}")
    
    return JSONResponse(
        status_code=500,
        content={
            "success": False,
            "error": "Internal server error" if not settings.DEBUG else str(exc),
            "status_code": 500,
            "path": request.url.path
        }
    )


# =============================================================================
# ì§ì ‘ êµ¬í˜„í•œ ê°€ìƒ í”¼íŒ… API ì—”ë“œí¬ì¸íŠ¸
# =============================================================================

@app.post("/api/virtual-tryon")
async def virtual_tryon_direct(
    person_image: UploadFile = File(..., description="ì‚¬ìš©ì ì´ë¯¸ì§€"),
    clothing_image: UploadFile = File(..., description="ì˜ë¥˜ ì´ë¯¸ì§€"),
    height: float = Form(..., description="í‚¤ (cm)"),
    weight: float = Form(..., description="ëª¸ë¬´ê²Œ (kg)"),
):
    """
    AI ê°€ìƒ í”¼íŒ… API (ì§ì ‘ êµ¬í˜„)
    """
    logger.info(f"ğŸ½ ê°€ìƒ í”¼íŒ… ìš”ì²­: height={height}cm, weight={weight}kg")
    
    try:
        # 1. ì´ë¯¸ì§€ íŒŒì¼ ê²€ì¦
        if not person_image.content_type.startswith('image/'):
            raise HTTPException(status_code=400, detail="ì‚¬ìš©ì ì´ë¯¸ì§€ê°€ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤")
        
        if not clothing_image.content_type.startswith('image/'):
            raise HTTPException(status_code=400, detail="ì˜ë¥˜ ì´ë¯¸ì§€ê°€ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤")
        
        # 2. ì´ë¯¸ì§€ ë¡œë“œ
        person_image_data = await person_image.read()
        clothing_image_data = await clothing_image.read()
        
        person_pil = Image.open(io.BytesIO(person_image_data))
        clothing_pil = Image.open(io.BytesIO(clothing_image_data))
        
        logger.info(f"ğŸ“¸ ì´ë¯¸ì§€ ë¡œë“œ ì™„ë£Œ: ì‚¬ìš©ì={person_pil.size}, ì˜ë¥˜={clothing_pil.size}")
        
        # 3. AI ê°€ìƒ í”¼íŒ… ì‹¤í–‰
        start_time = time.time()
        
        # ì‹¤ì œ AI ëª¨ë¸ ì‚¬ìš© ì‹œë„
        try:
            from app.services.virtual_fitter import virtual_fitter
            result_image, metadata = await virtual_fitter.complete_ai_fitting(
                person_pil, clothing_pil, height, weight
            )
            logger.info("âœ… ì‹¤ì œ AI ëª¨ë¸ ì‚¬ìš©")
        except Exception as e:
            logger.warning(f"âš ï¸ AI ëª¨ë¸ ì‚¬ìš© ì‹¤íŒ¨, ë°ëª¨ ëª¨ë“œë¡œ ì „í™˜: {e}")
            # ë°ëª¨ ëª¨ë“œ: ê¸°ë³¸ í•©ì„±
            result_image = create_demo_result(person_pil, clothing_pil)
            metadata = {"mode": "demo", "error": str(e)}
        
        processing_time = time.time() - start_time
        
        # 4. ê²°ê³¼ ì´ë¯¸ì§€ë¥¼ Base64ë¡œ ì¸ì½”ë”©
        result_buffer = io.BytesIO()
        result_image.save(result_buffer, format='JPEG', quality=85)
        result_base64 = base64.b64encode(result_buffer.getvalue()).decode()
        
        # 5. BMI ê³„ì‚°
        bmi = weight / ((height / 100) ** 2)
        
        # 6. ì‘ë‹µ ë°ì´í„° êµ¬ì„±
        response_data = {
            "success": True,
            "fitted_image": result_base64,
            "processing_time": round(processing_time, 2),
            "confidence": metadata.get("confidence", 0.85),
            "measurements": {
                "chest": 90,  # ì‹¤ì œë¡œëŠ” AIê°€ ì¸¡ì •
                "waist": 75,
                "hip": 95,
                "bmi": round(bmi, 1)
            },
            "clothing_analysis": {
                "category": "shirt",  # ì‹¤ì œë¡œëŠ” AIê°€ ë¶„ì„
                "style": "casual",
                "dominant_color": [120, 150, 200]  # RGB
            },
            "fit_score": metadata.get("fit_score", 0.88),
            "recommendations": [
                "ì´ ì˜·ì€ ë‹¹ì‹ ì˜ ì²´í˜•ì— ì˜ ì–´ìš¸ë¦½ë‹ˆë‹¤",
                "ì–´ê¹¨ ë¼ì¸ì´ ìì—°ìŠ¤ëŸ½ê²Œ ë§ìŠµë‹ˆë‹¤",
                "ì „ì²´ì ì¸ í•ì´ ìš°ìˆ˜í•©ë‹ˆë‹¤"
            ]
        }
        
        logger.info(f"âœ… ê°€ìƒ í”¼íŒ… ì™„ë£Œ: {processing_time:.2f}ì´ˆ")
        return JSONResponse(content=response_data)
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ ê°€ìƒ í”¼íŒ… ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=f"ê°€ìƒ í”¼íŒ… ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")


@app.get("/api/virtual-tryon/test")
async def virtual_tryon_test():
    """ê°€ìƒ í”¼íŒ… í…ŒìŠ¤íŠ¸ ì—”ë“œí¬ì¸íŠ¸"""
    return {
        "success": True,
        "message": "Virtual Try-On API is working!",
        "timestamp": time.time(),
        "endpoints": {
            "virtual_tryon": "/api/virtual-tryon",
            "test": "/api/virtual-tryon/test",
            "docs": "/docs"
        }
    }


def create_demo_result(person_image: Image.Image, clothing_image: Image.Image) -> Image.Image:
    """ë°ëª¨ìš© ê¸°ë³¸ í•©ì„±"""
    logger.info("ğŸ­ ë°ëª¨ ëª¨ë“œ: ê¸°ë³¸ ì´ë¯¸ì§€ í•©ì„±")
    
    # ì‚¬ìš©ì ì´ë¯¸ì§€ ë³µì‚¬
    result = person_image.copy()
    
    # ì˜ë¥˜ë¥¼ ì¶•ì†Œí•˜ì—¬ ì ì ˆí•œ ìœ„ì¹˜ì— ë°°ì¹˜
    clothing_resized = clothing_image.resize((200, 250))
    
    # ì´ë¯¸ì§€ ì¤‘ì•™ ìƒë‹¨ì— ì˜ë¥˜ ë°°ì¹˜
    person_width, person_height = result.size
    clothing_x = (person_width - 200) // 2
    clothing_y = person_height // 4
    
    # ê²½ê³„ ì²´í¬
    if clothing_x < 0:
        clothing_x = 0
    if clothing_y < 0:
        clothing_y = 0
    if clothing_x + 200 > person_width:
        clothing_x = person_width - 200
    if clothing_y + 250 > person_height:
        clothing_y = person_height - 250
    
    # ì˜ë¥˜ê°€ íˆ¬ëª…ë„ë¥¼ ì§€ì›í•˜ëŠ” ê²½ìš°
    if clothing_resized.mode == 'RGBA':
        result.paste(clothing_resized, (clothing_x, clothing_y), clothing_resized)
    else:
        result.paste(clothing_resized, (clothing_x, clothing_y))
    
    return result


# =============================================================================
# ê¸°ì¡´ ë¼ìš°í„° ë“±ë¡ (ì‚¬ìš© ê°€ëŠ¥í•œ ê²½ìš°ì—ë§Œ)
# =============================================================================

# API ë¼ìš°í„° ë“±ë¡
app.include_router(health_router, prefix="/health", tags=["Health"])

if VIRTUAL_TRYON_ROUTER_AVAILABLE:
    app.include_router(virtual_tryon_router, prefix="/api/virtual-tryon-router", tags=["Virtual Try-On Router"])
    logger.info("âœ… virtual_tryon ë¼ìš°í„° ë“±ë¡ë¨")
else:
    logger.info("â„¹ï¸ virtual_tryon ë¼ìš°í„°ë¥¼ ì§ì ‘ êµ¬í˜„ìœ¼ë¡œ ëŒ€ì²´")

if MODELS_ROUTER_AVAILABLE:
    app.include_router(models_router, prefix="/api/models", tags=["Models"])
    logger.info("âœ… models ë¼ìš°í„° ë“±ë¡ë¨")


@app.get("/")
async def root():
    """ë£¨íŠ¸ ì—”ë“œí¬ì¸íŠ¸"""
    
    return {
        "service": "MyCloset AI Backend",
        "version": "1.0.0",
        "status": "running",
        "gpu_device": gpu_config.device,
        "docs": "/docs",
        "health": "/health",
        "virtual_tryon_api": "/api/virtual-tryon",
        "test_api": "/api/virtual-tryon/test"
    }


@app.get("/routes")
async def list_routes():
    """ë“±ë¡ëœ ë¼ìš°í„° ëª©ë¡ í™•ì¸"""
    routes = []
    for route in app.routes:
        if hasattr(route, 'path') and hasattr(route, 'methods'):
            routes.append({
                "path": route.path,
                "methods": list(route.methods) if route.methods else [],
                "name": getattr(route, 'name', 'unknown')
            })
    return {"routes": routes}


@app.get("/info")
async def get_system_info():
    """ì‹œìŠ¤í…œ ì •ë³´ ì¡°íšŒ"""
    
    from app.core.gpu_config import DEVICE_INFO, MODEL_CONFIG
    import psutil
    import torch
    
    # ë©”ëª¨ë¦¬ ì •ë³´
    memory = psutil.virtual_memory()
    
    # GPU ì •ë³´
    gpu_info = {
        "device": gpu_config.device,
        "available": True,
        "details": DEVICE_INFO
    }
    
    if gpu_config.device == "mps":
        gpu_info["mps_available"] = torch.backends.mps.is_available()
        gpu_info["optimization"] = "Apple M3 Max Metal"
    elif gpu_config.device == "cuda":
        gpu_info["cuda_version"] = torch.version.cuda
        gpu_info["devices_count"] = torch.cuda.device_count()
    
    # ëª¨ë¸ ìƒíƒœ
    model_status = {}
    try:
        from app.services.model_manager import model_manager
        model_status = {
            "loaded_models": list(model_manager.loaded_models.keys()),
            "total_models": len(model_manager.available_models),
        }
    except:
        model_status = {"status": "model_manager_not_ready"}
    
    return {
        "system": {
            "platform": DEVICE_INFO["platform"],
            "machine": DEVICE_INFO["machine"],
            "python_version": DEVICE_INFO["python_version"],
            "pytorch_version": DEVICE_INFO["pytorch_version"],
        },
        "memory": {
            "total_gb": round(memory.total / (1024**3), 1),
            "available_gb": round(memory.available / (1024**3), 1),
            "used_percent": memory.percent,
        },
        "gpu": gpu_info,
        "models": model_status,
        "config": {
            "debug": settings.DEBUG,
            "max_upload_size_mb": settings.MAX_UPLOAD_SIZE // (1024*1024),
            "allowed_extensions": settings.ALLOWED_EXTENSIONS,
            "device": MODEL_CONFIG["device"],
            "batch_size": MODEL_CONFIG["batch_size"],
        },
        "api_status": {
            "virtual_tryon_router": VIRTUAL_TRYON_ROUTER_AVAILABLE,
            "models_router": MODELS_ROUTER_AVAILABLE,
            "direct_api": True
        }
    }


if __name__ == "__main__":
    # ì§ì ‘ ì‹¤í–‰ ì‹œ ì„œë²„ ì‹œì‘
    uvicorn.run(
        "app.main:app",
        host=settings.HOST,
        port=settings.PORT,
        reload=settings.DEBUG,
        log_level="info" if settings.DEBUG else "warning",
        access_log=settings.DEBUG,
    )