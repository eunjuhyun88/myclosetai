# app/main.py
"""
MyCloset AI Backend - M3 Max 128GB ìµœì í™” ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜
ì™„ì „í•œ ê¸°ëŠ¥ êµ¬í˜„ - WebSocket, ê°€ìƒí”¼íŒ… API, ëª¨ë“  ë¼ìš°í„° í¬í•¨
âœ… Import ì˜¤ë¥˜ í•´ê²°
âœ… ëˆ„ë½ëœ í•¨ìˆ˜ë“¤ ì¶”ê°€
âœ… í•˜ìœ„ í˜¸í™˜ì„± ë³´ì¥
âœ… CORS ì˜¤ë¥˜ ìˆ˜ì •
âœ… Step Routes ì¶”ê°€ (pipeline_routes ì£¼ì„ì²˜ë¦¬)
âœ… Performance ë¯¸ë“¤ì›¨ì–´ ì¶”ê°€
âœ… M3 Max ì „ìš© API ì¶”ê°€
âœ… ê°œë°œì ë„êµ¬ ì¶”ê°€
âœ… ì‹œìŠ¤í…œ ëª¨ë‹ˆí„°ë§ ì¶”ê°€
âœ… 405 Method Not Allowed í•´ê²°
"""

import sys
import os
import logging
import asyncio
import traceback
import json
import gc
from datetime import datetime
from pathlib import Path
from typing import Dict, Any, Optional, List
from contextlib import asynccontextmanager

from fastapi import Response, WebSocket, WebSocketDisconnect

# ì‹œê°„ ëª¨ë“ˆ ì•ˆì „ import
import time as time_module

# Python ê²½ë¡œ ì„¤ì •
current_dir = Path(__file__).parent
project_root = current_dir.parent
sys.path.insert(0, str(current_dir))
sys.path.insert(0, str(project_root))

print("ğŸ M3 Max ìµœì í™” MyCloset AI Backend ì‹œì‘...")
print(f"ğŸ“ App Dir: {current_dir}")
print(f"ğŸ“ Project Root: {project_root}")

# FastAPI imports
try:
    from fastapi import FastAPI, HTTPException, Request, Depends, BackgroundTasks, UploadFile, File, Form
    from fastapi.middleware.cors import CORSMiddleware
    from fastapi.staticfiles import StaticFiles
    from fastapi.responses import JSONResponse, HTMLResponse, PlainTextResponse
    from fastapi.exceptions import RequestValidationError
    from starlette.exceptions import HTTPException as StarletteHTTPException
    print("âœ… FastAPI import ì„±ê³µ")
except ImportError as e:
    print(f"âŒ FastAPI import ì‹¤íŒ¨: {e}")
    sys.exit(1)

# Pydantic V2 imports
try:
    from pydantic import ValidationError
    print("âœ… Pydantic V2 import ì„±ê³µ")
except ImportError as e:
    print(f"âŒ Pydantic import ì‹¤íŒ¨: {e}")
    sys.exit(1)

# ë¡œê¹… ì„¤ì •
def setup_logging():
    """M3 Max ìµœì í™”ëœ ë¡œê¹… ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
    log_dir = project_root / "logs"
    log_dir.mkdir(exist_ok=True)
    
    log_format = '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    
    # íŒŒì¼ í•¸ë“¤ëŸ¬
    try:
        file_handler = logging.FileHandler(
            log_dir / f"mycloset-ai-m3max-{datetime.now().strftime('%Y%m%d')}.log",
            encoding='utf-8',
            delay=True
        )
        file_handler.setFormatter(logging.Formatter(log_format))
    except Exception as e:
        print(f"âš ï¸ ë¡œê·¸ íŒŒì¼ ìƒì„± ì‹¤íŒ¨: {e}")
        file_handler = None
    
    # ì½˜ì†” í•¸ë“¤ëŸ¬
    console_handler = logging.StreamHandler()
    console_handler.setFormatter(logging.Formatter(log_format))
    
    # ë£¨íŠ¸ ë¡œê±° ì„¤ì •
    root_logger = logging.getLogger()
    root_logger.setLevel(logging.INFO)
    if file_handler:
        root_logger.addHandler(file_handler)
    root_logger.addHandler(console_handler)
    
    return logging.getLogger(__name__)

# ë¡œê¹… ì´ˆê¸°í™”
logger = setup_logging()

# ============================================
# ğŸ”§ ëˆ„ë½ëœ í•¨ìˆ˜ë“¤ ì¶”ê°€ - ì•ˆì „í•œ ë²„ì „
# ============================================

def add_missing_functions():
    """ëˆ„ë½ëœ í•¨ìˆ˜ë“¤ ì•ˆì „í•˜ê²Œ ì¶”ê°€"""
    
    # 1. GPU Configì— get_device_config í•¨ìˆ˜ ì¶”ê°€
    try:
        import app.core.gpu_config as gpu_config_module
        
        if not hasattr(gpu_config_module, 'get_device_config'):
            def get_device_config(device=None, **kwargs):
                """ë””ë°”ì´ìŠ¤ ì„¤ì • ì¡°íšŒ - í•˜ìœ„ í˜¸í™˜ì„± í•¨ìˆ˜"""
                try:
                    # ê¸°ì¡´ í•¨ìˆ˜ë“¤ ì‹œë„
                    if hasattr(gpu_config_module, 'get_gpu_config'):
                        return gpu_config_module.get_gpu_config(**kwargs)
                    elif hasattr(gpu_config_module, 'DEVICE'):
                        return {
                            'device': gpu_config_module.DEVICE,
                            'device_type': gpu_config_module.DEVICE,
                            'memory_info': getattr(gpu_config_module, 'DEVICE_INFO', {}),
                            'optimization_enabled': True
                        }
                    else:
                        return {
                            'device': device or 'cpu',
                            'device_type': 'cpu',
                            'memory_info': {'total_gb': 16.0},
                            'optimization_enabled': False
                        }
                except Exception as e:
                    logger.warning(f"get_device_config í´ë°± ëª¨ë“œ: {e}")
                    return {'device': 'cpu', 'device_type': 'cpu'}
            
            # í•¨ìˆ˜ ë™ì  ì¶”ê°€
            setattr(gpu_config_module, 'get_device_config', get_device_config)
            logger.info("âœ… get_device_config í•¨ìˆ˜ ë™ì  ì¶”ê°€ ì™„ë£Œ")
    
    except Exception as e:
        logger.warning(f"âš ï¸ GPU config í•¨ìˆ˜ ì¶”ê°€ ì‹¤íŒ¨: {e}")

# ëˆ„ë½ëœ í•¨ìˆ˜ë“¤ ì¦‰ì‹œ ì¶”ê°€
add_missing_functions()

# ============================================
# M3 Max ì»´í¬ë„ŒíŠ¸ Import ì‹œìŠ¤í…œ - ì•ˆì „ ë²„ì „
# ============================================

class M3MaxComponentImporter:
    """M3 Max ìµœì í™”ëœ ì»´í¬ë„ŒíŠ¸ import ë§¤ë‹ˆì € - ì•ˆì „ ë²„ì „"""
    
    def __init__(self):
        self.components = {}
        self.import_errors = []
        self.fallback_mode = False
        self.m3_max_optimized = False
        
        # M3 Max ê°ì§€
        self._detect_m3_max()
    
    def _detect_m3_max(self):
        """M3 Max í™˜ê²½ ê°ì§€"""
        try:
            import platform
            
            if platform.machine() == 'arm64' and platform.system() == 'Darwin':
                try:
                    import psutil
                    memory_gb = psutil.virtual_memory().total / (1024**3)
                    if memory_gb >= 120:
                        self.m3_max_optimized = True
                        logger.info("ğŸ M3 Max 128GB í™˜ê²½ ê°ì§€ - ìµœì í™” ëª¨ë“œ í™œì„±í™”")
                    else:
                        logger.info(f"ğŸ Apple Silicon ê°ì§€ - ë©”ëª¨ë¦¬: {memory_gb:.0f}GB")
                except ImportError:
                    # psutil ì—†ì–´ë„ M3 ê°ì§€ëŠ” ê°€ëŠ¥
                    self.m3_max_optimized = True
                    logger.info("ğŸ Apple Silicon ê°ì§€ - M3 Max ìµœì í™” ëª¨ë“œ í™œì„±í™”")
            
        except Exception as e:
            logger.warning(f"âš ï¸ í™˜ê²½ ê°ì§€ ì‹¤íŒ¨: {e}")
    
    def safe_import_schemas(self):
        """ìŠ¤í‚¤ë§ˆ ì•ˆì „ import"""
        try:
            from app.models.schemas import (
                VirtualTryOnRequest, VirtualTryOnResponse,
                ProcessingStatus, ProcessingResult,
                ErrorResponse, SystemHealth, PerformanceMetrics
            )
            
            self.components['schemas'] = {
                'VirtualTryOnRequest': VirtualTryOnRequest,
                'VirtualTryOnResponse': VirtualTryOnResponse,
                'ProcessingStatus': ProcessingStatus,
                'ProcessingResult': ProcessingResult,
                'ErrorResponse': ErrorResponse,
                'SystemHealth': SystemHealth,
                'PerformanceMetrics': PerformanceMetrics
            }
            
            logger.info("âœ… ìŠ¤í‚¤ë§ˆ import ì„±ê³µ")
            return True
            
        except Exception as e:
            error_msg = f"ìŠ¤í‚¤ë§ˆ import ì‹¤íŒ¨: {e}"
            self.import_errors.append(error_msg)
            logger.warning(f"âš ï¸ {error_msg}")
            self._create_fallback_schemas()
            return False
    
    def _create_fallback_schemas(self):
        """í´ë°± ìŠ¤í‚¤ë§ˆ ìƒì„±"""
        from pydantic import BaseModel
        from typing import Optional, Dict, Any
        
        class FallbackModel(BaseModel):
            success: bool = True
            message: str = "Fallback mode"
            data: Optional[Dict[str, Any]] = None
        
        self.components['schemas'] = {
            'VirtualTryOnRequest': FallbackModel,
            'VirtualTryOnResponse': FallbackModel,
            'ProcessingStatus': FallbackModel,
            'ProcessingResult': FallbackModel,
            'ErrorResponse': FallbackModel,
            'SystemHealth': FallbackModel,
            'PerformanceMetrics': FallbackModel
        }
        
        self.fallback_mode = True
        logger.warning("ğŸš¨ í´ë°± ìŠ¤í‚¤ë§ˆ ëª¨ë“œë¡œ ì „í™˜")
    
    def safe_import_gpu_config(self):
        """GPU ì„¤ì • ì•ˆì „ import"""
        try:
            from app.core.gpu_config import (
                gpu_config, DEVICE, MODEL_CONFIG, 
                DEVICE_INFO, get_device_config,
                get_device, get_optimal_settings
            )
            
            # ì¶”ê°€ í•¨ìˆ˜ë“¤ í™•ì¸ ë° ìƒì„±
            try:
                from app.core.gpu_config import get_device_info
            except ImportError:
                def get_device_info():
                    return DEVICE_INFO
            
            try:
                from app.core.gpu_config import get_model_config
            except ImportError:
                def get_model_config():
                    return MODEL_CONFIG
            
            def optimize_memory(device=None, aggressive=False):
                """M3 Max ë©”ëª¨ë¦¬ ìµœì í™”"""
                try:
                    import torch
                    
                    if device == 'mps' or (device is None and torch.backends.mps.is_available()):
                        gc.collect()
                        if hasattr(torch.mps, 'synchronize'):
                            torch.mps.synchronize()
                        if hasattr(torch.mps, 'empty_cache'):
                            torch.mps.empty_cache()
                        
                        return {
                            "success": True, 
                            "device": "mps", 
                            "method": "m3_max_optimization",
                            "aggressive": aggressive,
                            "memory_optimized": True
                        }
                    else:
                        gc.collect()
                        return {
                            "success": True, 
                            "device": device or "cpu", 
                            "method": "standard_gc"
                        }
                except Exception as e:
                    return {"success": False, "error": str(e)}
            
            self.components['gpu_config'] = {
                'instance': gpu_config,
                'device': DEVICE,
                'model_config': MODEL_CONFIG,
                'device_info': DEVICE_INFO,
                'get_config': get_device_config,
                'get_device': get_device,
                'get_model_config': get_model_config,
                'get_device_info': get_device_info,
                'optimize_memory': optimize_memory,
                'm3_max_optimized': self.m3_max_optimized and DEVICE == 'mps'
            }
            
            logger.info(f"âœ… GPU ì„¤ì • import ì„±ê³µ (M3 Max: {self.components['gpu_config']['m3_max_optimized']})")
            return True
            
        except Exception as e:
            error_msg = f"GPU ì„¤ì • import ì‹¤íŒ¨: {e}"
            self.import_errors.append(error_msg)
            logger.warning(f"âš ï¸ {error_msg}")
            
            # í´ë°± GPU ì„¤ì •
            self.components['gpu_config'] = {
                'instance': None,
                'device': "cpu",
                'model_config': {"device": "cpu", "dtype": "float32"},
                'device_info': {
                    "device": "cpu",
                    "name": "CPU",
                    "memory_gb": 0,
                    "is_m3_max": False
                },
                'get_config': lambda: {"device": "cpu"},
                'get_device': lambda: "cpu",
                'get_model_config': lambda: {"device": "cpu"},
                'get_device_info': lambda: {"device": "cpu"},
                'optimize_memory': lambda device=None, aggressive=False: {
                    "success": False, 
                    "error": "GPU config not available"
                },
                'm3_max_optimized': False
            }
            return False
    
    def safe_import_api_routers(self):
        """API ë¼ìš°í„°ë“¤ ì•ˆì „ import"""
        routers = {}
        
        # Health router
if api_routers.get('health'):
    try:
        app.include_router(api_routers['health'], tags=["health"])
        logger.info("âœ… Health ë¼ìš°í„° ë“±ë¡ë¨")
    except Exception as e:
        logger.warning(f"Health ë¼ìš°í„° ë“±ë¡ ì‹¤íŒ¨: {e}")

# Virtual try-on router
if api_routers.get('virtual_tryon'):
    try:
        app.include_router(api_routers['virtual_tryon'], tags=["virtual-tryon"])
        logger.info("âœ… Virtual Try-on ë¼ìš°í„° ë“±ë¡ë¨")
    except Exception as e:
        logger.warning(f"Virtual Try-on ë¼ìš°í„° ë“±ë¡ ì‹¤íŒ¨: {e}")

# Models router
if api_routers.get('models'):
    try:
        app.include_router(api_routers['models'], tags=["models"])
        logger.info("âœ… Models ë¼ìš°í„° ë“±ë¡ë¨")
    except Exception as e:
        logger.warning(f"Models ë¼ìš°í„° ë“±ë¡ ì‹¤íŒ¨: {e}")

# ğŸ”´ Step Routes - ìƒˆë¡œ ì¶”ê°€ëœ ë‹¨ê³„ë³„ API (pipeline_routes ëŒ€ì‹ )
if api_routers.get('step_routes'):
    try:
        app.include_router(api_routers['step_routes'], tags=["step-routes"])
        logger.info("âœ… Step Routes ë¼ìš°í„° ë“±ë¡ë¨ - ê²½ë¡œ: /api/step/*")
        logger.info("   ğŸ“‹ í¬í•¨ëœ ì—”ë“œí¬ì¸íŠ¸:")
        logger.info("     - POST /api/step/1/upload-validation")
        logger.info("     - POST /api/step/2/measurements-validation")
        logger.info("     - POST /api/step/3/human-parsing")
        logger.info("     - POST /api/step/4/pose-estimation")
        logger.info("     - POST /api/step/5/clothing-analysis")
        logger.info("     - POST /api/step/6/geometric-matching")
        logger.info("     - POST /api/step/7/virtual-fitting")
        logger.info("     - POST /api/step/8/result-analysis")
    except Exception as e:
        logger.warning(f"Step Routes ë¼ìš°í„° ë“±ë¡ ì‹¤íŒ¨: {e}")

# ğŸ”´ Pipeline router - ì£¼ì„ì²˜ë¦¬ë¨ (step_routesë¡œ ëŒ€ì²´)
# if api_routers.get('pipeline'):
#     try:
#         app.include_router(api_routers['pipeline'], prefix="/api", tags=["pipeline"])
#         logger.info("âœ… Pipeline ë¼ìš°í„° ë“±ë¡ë¨ - ê²½ë¡œ: /api/pipeline/*")
#     except Exception as e:
#         logger.warning(f"Pipeline ë¼ìš°í„° ë“±ë¡ ì‹¤íŒ¨: {e}")

# WebSocket router
if api_routers.get('websocket'):
    try:
        app.include_router(api_routers['websocket'], prefix="/api/ws", tags=["websocket"])
        logger.info("âœ… WebSocket ë¼ìš°í„° ë“±ë¡ë¨ - ê²½ë¡œ: /api/ws/*")
    except Exception as e:
        logger.warning(f"WebSocket ë¼ìš°í„° ë“±ë¡ ì‹¤íŒ¨: {e}")

# ============================================
# ì •ì  íŒŒì¼ ì„œë¹™
# ============================================

static_dir = project_root / "static"
if static_dir.exists():
    try:
        app.mount("/static", StaticFiles(directory=str(static_dir)), name="static")
        logger.info("âœ… ì •ì  íŒŒì¼ ì„œë¹™ ì„¤ì •ë¨")
    except Exception as e:
        logger.warning(f"ì •ì  íŒŒì¼ ì„œë¹™ ì„¤ì • ì‹¤íŒ¨: {e}")

# ============================================
# ğŸ”´ M3 Max ì „ìš© ì—”ë“œí¬ì¸íŠ¸ ì¶”ê°€
# ============================================

@app.get("/m3-max-status", tags=["m3-max"])
async def get_m3_max_status():
    """M3 Max ì „ìš© ìƒíƒœ ì²´í¬"""
    if not importer.m3_max_optimized:
        raise HTTPException(status_code=404, detail="M3 Max í™˜ê²½ì´ ì•„ë‹™ë‹ˆë‹¤")
    
    import platform
    
    try:
        # M3 Max ì‹œìŠ¤í…œ ì •ë³´
        try:
            import psutil
            memory_info = psutil.virtual_memory()
            cpu_info = {
                "physical_cores": psutil.cpu_count(logical=False),
                "logical_cores": psutil.cpu_count(logical=True),
                "architecture": platform.machine(),
                "processor": platform.processor()
            }
            memory_data = {
                "total_gb": round(memory_info.total / (1024**3), 1),
                "available_gb": round(memory_info.available / (1024**3), 1),
                "used_percent": memory_info.percent
            }
        except ImportError:
            cpu_info = {
                "architecture": platform.machine(),
                "processor": platform.processor()
            }
            memory_data = {"error": "psutil not available"}
        
        # PyTorch MPS ì •ë³´
        mps_info = {}
        try:
            import torch
            if torch.backends.mps.is_available():
                mps_info = {
                    "available": True,
                    "is_built": torch.backends.mps.is_built(),
                    "device_count": 1,  # M3 MaxëŠ” ë‹¨ì¼ GPU
                    "current_device": "mps:0"
                }
            else:
                mps_info = {"available": False}
        except ImportError:
            mps_info = {"available": False, "pytorch_missing": True}
        
        return {
            "m3_max_status": "active",
            "system": {
                "memory": memory_data,
                "cpu": cpu_info,
                "neural_engine": {
                    "available": True,  # M3 MaxëŠ” Neural Engine ë‚´ì¥
                    "optimization_active": importer.m3_max_optimized
                }
            },
            "mps": mps_info,
            "performance": {
                "unified_memory_bandwidth": "400 GB/s",
                "gpu_cores": 40,  # M3 Max GPU ì½”ì–´ ìˆ˜
                "neural_engine_ops": "15.8 TOPS"
            }
        }
        
    except Exception as e:
        return {
            "m3_max_status": "error",
            "error": str(e),
            "fallback_info": {
                "device": gpu_config.get('device', 'unknown'),
                "optimized": importer.m3_max_optimized
            }
        }

@app.post("/api/optimize-memory", tags=["m3-max"])
async def optimize_memory_endpoint():
    """M3 Max ë©”ëª¨ë¦¬ ìµœì í™” API"""
    optimize_func = gpu_config.get('optimize_memory')
    
    if not optimize_func or not callable(optimize_func):
        raise HTTPException(status_code=503, detail="ë©”ëª¨ë¦¬ ìµœì í™” ê¸°ëŠ¥ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
    
    try:
        result = optimize_func(
            device=gpu_config.get('device'),
            aggressive=importer.m3_max_optimized
        )
        
        if result.get('success'):
            return {
                "success": True,
                "message": "ë©”ëª¨ë¦¬ ìµœì í™” ì™„ë£Œ",
                "result": result,
                "timestamp": datetime.now().isoformat()
            }
        else:
            return {
                "success": False,
                "message": "ë©”ëª¨ë¦¬ ìµœì í™” ì‹¤íŒ¨",
                "error": result.get('error', 'Unknown error')
            }
    
    except Exception as e:
        logger.error(f"ë©”ëª¨ë¦¬ ìµœì í™” ì¤‘ ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=f"ë©”ëª¨ë¦¬ ìµœì í™” ì‹¤íŒ¨: {str(e)}")

@app.get("/api/performance-metrics", tags=["m3-max"])
async def get_performance_metrics():
    """ì‹¤ì‹œê°„ ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì¡°íšŒ"""
    current_time = time_module.time()
    startup_time = app_state.get("startup_time", 0)
    uptime = current_time - startup_time if startup_time else 0
    
    # ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­ (ê°€ëŠ¥í•œ ê²½ìš°)
    system_metrics = {}
    try:
        import psutil
        system_metrics = {
            "cpu_percent": psutil.cpu_percent(interval=1),
            "memory_percent": psutil.virtual_memory().percent,
            "memory_available_gb": round(psutil.virtual_memory().available / (1024**3), 1)
        }
    except ImportError:
        system_metrics = {"error": "psutil not available"}
    
    return {
        "timestamp": datetime.now().isoformat(),
        "uptime_seconds": uptime,
        "application_metrics": app_state["performance_metrics"],
        "system_metrics": system_metrics,
        "m3_max_optimized": importer.m3_max_optimized,
        "device": gpu_config.get('device', 'unknown'),
        "active_components": {
            name: router is not None 
            for name, router in api_routers.items()
            if name != 'websocket_background_tasks'
        }
    }

@app.get("/api/component-status", tags=["development"])
async def get_component_status():
    """ì»´í¬ë„ŒíŠ¸ ìƒíƒœ ìƒì„¸ ì¡°íšŒ"""
    return {
        "import_success": app_state["import_success"],
        "fallback_mode": app_state["fallback_mode"],
        "m3_max_optimized": importer.m3_max_optimized,
        "errors": app_state["errors"],
        "components": {
            "schemas": {
                "loaded": bool(schemas),
                "count": len(schemas) if schemas else 0,
                "available_models": list(schemas.keys()) if schemas else []
            },
            "gpu_config": {
                "loaded": bool(gpu_config),
                "device": gpu_config.get('device', 'unknown'),
                "optimized": gpu_config.get('m3_max_optimized', False)
            },
            "api_routers": {
                name: {
                    "loaded": router is not None,
                    "type": type(router).__name__ if router else None
                }
                for name, router in api_routers.items()
                if name != 'websocket_background_tasks'
            }
        }
    }

# ============================================
# ğŸ”´ ê°œë°œì ë„êµ¬ API ì¶”ê°€
# ============================================

@app.get("/api/dev/debug-info", tags=["development"])
async def get_debug_info():
    """ê°œë°œììš© ë””ë²„ê·¸ ì •ë³´"""
    import sys
    
    return {
        "python_version": sys.version,
        "python_path": sys.path[:5],  # ì²˜ìŒ 5ê°œë§Œ
        "current_dir": str(current_dir),
        "project_root": str(project_root),
        "environment_vars": {
            "PORT": os.getenv("PORT", "not set"),
            "HOST": os.getenv("HOST", "not set"),
            "ENVIRONMENT": os.getenv("ENVIRONMENT", "not set"),
        },
        "import_errors": importer.import_errors,
        "app_state": {
            key: value for key, value in app_state.items()
            if key not in ['performance_metrics']  # ë„ˆë¬´ ìƒì„¸í•œ ì •ë³´ ì œì™¸
        }
    }

@app.post("/api/dev/test-step-routes", tags=["development"])
async def test_step_routes_connection():
    """Step Routes ì—°ê²° í…ŒìŠ¤íŠ¸"""
    step_router = api_routers.get('step_routes')
    
    if not step_router:
        return {
            "success": False,
            "message": "Step Routes ë¼ìš°í„°ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤",
            "available_routers": list(api_routers.keys())
        }
    
    return {
        "success": True,
        "message": "Step Routes ë¼ìš°í„°ê°€ ì •ìƒì ìœ¼ë¡œ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤",
        "step_endpoints": [
            "/api/step/1/upload-validation",
            "/api/step/2/measurements-validation",
            "/api/step/3/human-parsing",
            "/api/step/4/pose-estimation",
            "/api/step/5/clothing-analysis",
            "/api/step/6/geometric-matching",
            "/api/step/7/virtual-fitting",
            "/api/step/8/result-analysis"
        ],
        "note": "pipeline_routesëŠ” ì£¼ì„ì²˜ë¦¬ë˜ê³  step_routesë¡œ ëŒ€ì²´ë˜ì—ˆìŠµë‹ˆë‹¤"
    }

@app.post("/api/dev/warmup", tags=["development"])
async def warmup_system():
    """ì‹œìŠ¤í…œ ì›Œë°ì—… (M3 Max ìµœì í™”)"""
    if not importer.m3_max_optimized:
        return {
            "success": False,
            "message": "M3 Max í™˜ê²½ì´ ì•„ë‹™ë‹ˆë‹¤",
            "current_device": gpu_config.get('device', 'unknown')
        }
    
    try:
        logger.info("ğŸ M3 Max ì‹œìŠ¤í…œ ì›Œë°ì—… ì‹œì‘...")
        
        # MPS ì›Œë°ì—…
        warmup_result = {}
        try:
            import torch
            if torch.backends.mps.is_available():
                # ë”ë¯¸ ì—°ì‚°ìœ¼ë¡œ MPS ì›Œë°ì—…
                x = torch.randn(1000, 1000, device='mps')
                y = torch.mm(x, x.T)
                del x, y
                warmup_result['mps'] = "success"
            else:
                warmup_result['mps'] = "not_available"
        except Exception as e:
            warmup_result['mps'] = f"error: {str(e)}"
        
        # ë©”ëª¨ë¦¬ ìµœì í™”
        optimize_func = gpu_config.get('optimize_memory')
        if optimize_func:
            memory_result = optimize_func(device='mps', aggressive=False)
            warmup_result['memory_optimization'] = memory_result
        
        return {
            "success": True,
            "message": "M3 Max ì›Œë°ì—… ì™„ë£Œ",
            "results": warmup_result,
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"ì›Œë°ì—… ì¤‘ ì˜¤ë¥˜: {e}")
        return {
            "success": False,
            "message": f"ì›Œë°ì—… ì‹¤íŒ¨: {str(e)}",
            "timestamp": datetime.now().isoformat()
        }

# ============================================
# ğŸ”´ ì‹œìŠ¤í…œ ëª¨ë‹ˆí„°ë§ ì›¹ì†Œì¼“ ì¶”ê°€
# ============================================

if api_routers.get('websocket'):
    @app.websocket("/api/ws/system-monitor")
    async def system_monitor_websocket(websocket: WebSocket):
        """ì‹¤ì‹œê°„ ì‹œìŠ¤í…œ ëª¨ë‹ˆí„°ë§ WebSocket"""
        await websocket.accept()
        
        try:
            while True:
                # 1ì´ˆë§ˆë‹¤ ì‹œìŠ¤í…œ ìƒíƒœ ì „ì†¡
                try:
                    status = {
                        "timestamp": datetime.now().isoformat(),
                        "performance": app_state["performance_metrics"],
                        "uptime": time_module.time() - app_state.get("startup_time", time_module.time()),
                        "m3_max_optimized": importer.m3_max_optimized,
                        "device": gpu_config.get('device', 'unknown')
                    }
                    
                    # ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­ ì¶”ê°€ (ê°€ëŠ¥í•œ ê²½ìš°)
                    try:
                        import psutil
                        status["system"] = {
                            "cpu_percent": psutil.cpu_percent(),
                            "memory_percent": psutil.virtual_memory().percent
                        }
                    except ImportError:
                        pass
                    
                    await websocket.send_text(json.dumps(status))
                    await asyncio.sleep(1)
                    
                except WebSocketDisconnect:
                    break
                except Exception as e:
                    logger.error(f"WebSocket ëª¨ë‹ˆí„°ë§ ì˜¤ë¥˜: {e}")
                    break
                    
        except WebSocketDisconnect:
            logger.info("ì‹œìŠ¤í…œ ëª¨ë‹ˆí„°ë§ WebSocket ì—°ê²° ì¢…ë£Œ")

# ============================================
# ê¸°ë³¸ ì—”ë“œí¬ì¸íŠ¸ë“¤
# ============================================

@app.get("/", response_class=HTMLResponse)
async def m3_max_root():
    """M3 Max ìµœì í™”ëœ ë£¨íŠ¸ ì—”ë“œí¬ì¸íŠ¸"""
    device_emoji = "ğŸ" if gpu_config.get('device') == "mps" else "ğŸ–¥ï¸" if gpu_config.get('device') == "cuda" else "ğŸ’»"
    status_emoji = "âœ…" if app_state["initialized"] else "âš ï¸"
    websocket_status = "âœ… í™œì„±í™”" if api_routers.get('websocket') else "âŒ ë¹„í™œì„±í™”"
    step_routes_status = "âœ… í™œì„±í™”" if api_routers.get('step_routes') else "âŒ ë¹„í™œì„±í™”"
    
    current_time = time_module.time()
    startup_time = app_state.get("startup_time", 0)
    uptime = current_time - startup_time if startup_time else 0
    
    html_content = f"""
    <!DOCTYPE html>
    <html>
    <head>
        <title>MyCloset AI Backend (M3 Max)</title>
        <meta charset="utf-8">
        <style>
            body {{ 
                font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Arial, sans-serif; 
                margin: 40px; 
                background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
                color: white;
            }}
            .container {{ 
                max-width: 900px; 
                margin: 0 auto; 
                background: rgba(255,255,255,0.1); 
                padding: 30px; 
                border-radius: 15px; 
                box-shadow: 0 8px 32px rgba(0,0,0,0.3);
                backdrop-filter: blur(10px);
            }}
            h1 {{ 
                color: #fff; 
                border-bottom: 2px solid #fff; 
                padding-bottom: 15px; 
                text-align: center;
                font-size: 2.2em;
            }}
            .status {{ 
                padding: 20px; 
                border-radius: 10px; 
                margin: 20px 0; 
                font-weight: bold;
            }}
            .status.success {{ 
                background: rgba(46, 213, 115, 0.3); 
                border: 1px solid rgba(46, 213, 115, 0.5); 
            }}
            .status.warning {{ 
                background: rgba(255, 159, 67, 0.3); 
                border: 1px solid rgba(255, 159, 67, 0.5); 
            }}
            .m3-badge {{
                background: linear-gradient(45deg, #ff6b6b, #ffa726);
                padding: 5px 15px;
                border-radius: 20px;
                font-size: 0.9em;
                margin-left: 10px;
                box-shadow: 0 2px 10px rgba(0,0,0,0.2);
            }}
            .metrics {{ 
                display: grid; 
                grid-template-columns: repeat(auto-fit, minmax(200px, 1fr)); 
                gap: 20px; 
                margin: 25px 0; 
            }}
            .metric {{ 
                background: rgba(255,255,255,0.1); 
                padding: 20px; 
                border-radius: 10px; 
                text-align: center;
                backdrop-filter: blur(5px);
            }}
            .metric h3 {{ 
                margin: 0; 
                color: #ccc; 
                font-size: 0.9em; 
            }}
            .metric p {{ 
                margin: 10px 0 0 0; 
                font-size: 1.6em; 
                font-weight: bold; 
                color: #fff; 
            }}
            .links {{ margin-top: 30px; text-align: center; }}
            .links a {{ 
                display: inline-block; 
                margin: 10px; 
                padding: 12px 20px; 
                background: rgba(255,255,255,0.2); 
                color: white; 
                text-decoration: none; 
                border-radius: 8px; 
                transition: all 0.3s;
                backdrop-filter: blur(5px);
            }}
            .links a:hover {{ 
                background: rgba(255,255,255,0.3); 
                transform: translateY(-2px);
            }}
        </style>
    </head>
    <body>
        <div class="container">
            <h1>
                {device_emoji} MyCloset AI Backend v3.0
                {'<span class="m3-badge">ğŸ M3 Max Optimized</span>' if importer.m3_max_optimized else ''}
            </h1>
            
            <div class="status {'success' if app_state['initialized'] else 'warning'}">
                <strong>{status_emoji} ì‹œìŠ¤í…œ ìƒíƒœ:</strong> 
                {'ğŸ M3 Max ìµœì í™” ëª¨ë“œë¡œ ì •ìƒ ìš´ì˜ ì¤‘' if app_state['initialized'] and importer.m3_max_optimized 
                 else 'ì •ìƒ ìš´ì˜ ì¤‘' if app_state['initialized'] 
                 else 'ì´ˆê¸°í™” ì¤‘ ë˜ëŠ” ì œí•œì  ìš´ì˜'}
            </div>
            
            <div class="metrics">
                <div class="metric">
                    <h3>ë””ë°”ì´ìŠ¤</h3>
                    <p>{gpu_config.get('device', 'unknown').upper()}</p>
                </div>
                <div class="metric">
                    <h3>M3 Max ìµœì í™”</h3>
                    <p>{'ğŸ í™œì„±í™”' if importer.m3_max_optimized else 'âŒ ë¹„í™œì„±í™”'}</p>
                </div>
                <div class="metric">
                    <h3>Step Routes API</h3>
                    <p>{step_routes_status}</p>
                </div>
                <div class="metric">
                    <h3>WebSocket</h3>
                    <p>{websocket_status}</p>
                </div>
                <div class="metric">
                    <h3>ì´ ìš”ì²­ ìˆ˜</h3>
                    <p>{app_state['performance_metrics']['total_requests']}</p>
                </div>
                <div class="metric">
                    <h3>í‰ê·  ì‘ë‹µ ì‹œê°„</h3>
                    <p>{app_state['performance_metrics']['average_response_time']:.3f}s</p>
                </div>
                <div class="metric">
                    <h3>ê°€ë™ ì‹œê°„</h3>
                    <p>{uptime:.0f}s</p>
                </div>
            </div>
            
            <div class="links">
                <a href="/docs">ğŸ“š API ë¬¸ì„œ</a>
                <a href="/status">ğŸ“Š ìƒì„¸ ìƒíƒœ</a>
                <a href="/health">ğŸ’Š í—¬ìŠ¤ì²´í¬</a>
                <a href="/api/health">ğŸ”— API í—¬ìŠ¤ì²´í¬</a>
                {'<a href="/m3-max-status">ğŸ M3 Max ìƒíƒœ</a>' if importer.m3_max_optimized else ''}
                <a href="/api/dev/debug-info">ğŸ› ï¸ ë””ë²„ê·¸ ì •ë³´</a>
                <a href="/api/dev/test-step-routes">ğŸ“‹ Step Routes í…ŒìŠ¤íŠ¸</a>
            </div>
        </div>
    </body>
    </html>
    """
    
    return HTMLResponse(content=html_content)

@app.get("/status")
async def get_m3_max_detailed_status():
    """M3 Max ìµœì í™”ëœ ìƒì„¸ ì‹œìŠ¤í…œ ìƒíƒœ ì¡°íšŒ"""
    current_time = time_module.time()
    startup_time = app_state.get("startup_time", 0)
    uptime = current_time - startup_time if startup_time else 0
    
    return {
        "application": {
            "name": "MyCloset AI Backend (M3 Max Optimized)",
            "version": "3.0.0-m3max",
            "initialized": app_state["initialized"],
            "fallback_mode": app_state["fallback_mode"],
            "import_success": app_state["import_success"],
            "m3_max_optimized": importer.m3_max_optimized,
            "uptime_seconds": uptime,
            "startup_time": app_state["startup_time"],
            "errors": app_state["errors"]
        },
        "system": {
            "device": gpu_config.get("device", "unknown"),
            "device_info": gpu_config.get('device_info', {}),
            "m3_max_features": {
                "neural_engine": importer.m3_max_optimized,
                "mps_backend": gpu_config.get("device") == "mps",
                "unified_memory": importer.m3_max_optimized,
                "memory_bandwidth": "400GB/s" if importer.m3_max_optimized else "N/A"
            }
        },
        "step_routes": {
            "enabled": bool(api_routers.get('step_routes')),
            "endpoints": [
                "/api/step/1/upload-validation",
                "/api/step/2/measurements-validation", 
                "/api/step/3/human-parsing",
                "/api/step/4/pose-estimation",
                "/api/step/5/clothing-analysis",
                "/api/step/6/geometric-matching",
                "/api/step/7/virtual-fitting",
                "/api/step/8/result-analysis"
            ] if api_routers.get('step_routes') else [],
            "note": "pipeline_routesëŠ” ì£¼ì„ì²˜ë¦¬ë˜ê³  step_routesë¡œ ëŒ€ì²´ë¨"
        },
        "websocket": {
            "enabled": bool(api_routers.get('websocket')),
            "endpoints": [
                "/api/ws/pipeline-progress",
                "/api/ws/system-monitor", 
                "/api/ws/test",
                "/api/ws/debug"
            ] if api_routers.get('websocket') else []
        },
        "performance": app_state["performance_metrics"],
        "api_routers": {
            name: router is not None 
            for name, router in api_routers.items()
            if name != 'websocket_background_tasks'  # ë‚´ë¶€ í•¨ìˆ˜ ì œì™¸
        }
    }

@app.get("/health")
async def m3_max_health_check():
    """M3 Max ìµœì í™”ëœ í—¬ìŠ¤ì²´í¬"""
    current_time = time_module.time()
    startup_time = app_state.get("startup_time", 0)
    uptime = current_time - startup_time if startup_time else 0
    
    return {
        "status": "healthy" if app_state["initialized"] else "degraded",
        "timestamp": datetime.now().isoformat(),
        "version": "3.0.0-m3max",
        "device": gpu_config.get("device", "unknown"),
        "m3_max_optimized": importer.m3_max_optimized,
        "step_routes_enabled": bool(api_routers.get('step_routes')),
        "websocket_enabled": bool(api_routers.get('websocket')),
        "uptime": uptime,
        "pydantic_version": "v2",
        "cors_enabled": True,
        "import_success": import_success,
        "fallback_mode": importer.fallback_mode
    }

# API ë„¤ì„ìŠ¤í˜ì´ìŠ¤ í—¬ìŠ¤ì²´í¬ ì¶”ê°€
@app.get("/api/health")
async def api_health_check():
    """API ë„¤ì„ìŠ¤í˜ì´ìŠ¤ í—¬ìŠ¤ì²´í¬ - í”„ë¡ íŠ¸ì—”ë“œ ì—°ë™ìš©"""
    return await m3_max_health_check()

# ğŸ”´ í—¬ìŠ¤ì²´í¬ ê°•í™”
@app.get("/api/health/detailed", tags=["health"])
async def detailed_health_check():
    """ìƒì„¸ í—¬ìŠ¤ì²´í¬"""
    current_time = time_module.time()
    startup_time = app_state.get("startup_time", 0)
    uptime = current_time - startup_time if startup_time else 0
    
    health_data = {
        "status": "healthy" if app_state["initialized"] else "degraded",
        "timestamp": datetime.now().isoformat(),
        "version": "3.0.0-m3max",
        "uptime_seconds": uptime,
        "environment": {
            "device": gpu_config.get("device", "unknown"),
            "m3_max_optimized": importer.m3_max_optimized,
            "fallback_mode": importer.fallback_mode,
            "python_version": f"{sys.version_info.major}.{sys.version_info.minor}.{sys.version_info.micro}"
        },
        "components": {
            "step_routes": bool(api_routers.get('step_routes')),
            "websocket": bool(api_routers.get('websocket')),
            "virtual_tryon": bool(api_routers.get('virtual_tryon')),
            "health": bool(api_routers.get('health')),
            "models": bool(api_routers.get('models'))
        },
        "performance": app_state["performance_metrics"],
        "errors": app_state["errors"] if app_state["errors"] else None
    }
    
    # ì‹œìŠ¤í…œ ì •ë³´ ì¶”ê°€ (ê°€ëŠ¥í•œ ê²½ìš°)
    try:
        import psutil
        health_data["system"] = {
            "cpu_count": psutil.cpu_count(),
            "memory_total_gb": round(psutil.virtual_memory().total / (1024**3), 1),
            "memory_used_percent": psutil.virtual_memory().percent,
            "disk_usage_percent": psutil.disk_usage('/').percent
        }
    except ImportError:
        health_data["system"] = {"error": "psutil not available"}
    
    return health_data

# ğŸ”´ ê¸´ê¸‰ ìƒí™© ëŒ€ì‘ API
@app.post("/api/emergency/reset", tags=["development"])
async def emergency_reset():
    """ê¸´ê¸‰ ì‹œìŠ¤í…œ ë¦¬ì…‹"""
    try:
        logger.warning("ğŸš¨ ê¸´ê¸‰ ì‹œìŠ¤í…œ ë¦¬ì…‹ ìš”ì²­ë¨")
        
        # ë©”ëª¨ë¦¬ ì •ë¦¬
        gc.collect()
        
        # ì„±ëŠ¥ ë©”íŠ¸ë¦­ ë¦¬ì…‹
        app_state["performance_metrics"] = {
            "average_response_time": 0.0,
            "total_requests": 0,
            "error_rate": 0.0,
            "m3_max_optimized_sessions": 0,
            "memory_efficiency": 0.95 if importer.m3_max_optimized else 0.8
        }
        
        # GPU ë©”ëª¨ë¦¬ ì •ë¦¬ (ê°€ëŠ¥í•œ ê²½ìš°)
        optimize_func = gpu_config.get('optimize_memory')
        if optimize_func:
            optimize_func(device=gpu_config.get('device'), aggressive=True)
        
        return {
            "success": True,
            "message": "ê¸´ê¸‰ ë¦¬ì…‹ ì™„ë£Œ",
            "timestamp": datetime.now().isoformat(),
            "actions_taken": [
                "Memory garbage collection",
                "Performance metrics reset",
                "GPU memory cleanup" if optimize_func else "CPU memory cleanup"
            ]
        }
        
    except Exception as e:
        logger.error(f"ê¸´ê¸‰ ë¦¬ì…‹ ì‹¤íŒ¨: {e}")
        return {
            "success": False,
            "message": f"ê¸´ê¸‰ ë¦¬ì…‹ ì‹¤íŒ¨: {str(e)}",
            "timestamp": datetime.now().isoformat()
        }

# ğŸ”´ Step Routes í…ŒìŠ¤íŠ¸ìš© ê°€ìƒ í”¼íŒ… ì—”ë“œí¬ì¸íŠ¸
@app.post("/api/virtual-tryon-test")
async def virtual_tryon_test():
    """í”„ë¡ íŠ¸ì—”ë“œ ì—°ë™ í…ŒìŠ¤íŠ¸ìš© ê°€ìƒ í”¼íŒ… API"""
    return {
        "success": True,
        "message": "ğŸ M3 Max ìµœì í™” ì„œë²„ê°€ ì •ìƒ ì‘ë™ ì¤‘ì…ë‹ˆë‹¤!",
        "device": gpu_config.get('device', 'unknown'),
        "m3_max_optimized": importer.m3_max_optimized,
        "step_routes_enabled": bool(api_routers.get('step_routes')),
        "fitted_image": "",  # Base64 ì´ë¯¸ì§€ (í…ŒìŠ¤íŠ¸ìš© ë¹ˆ ê°’)
        "confidence": 0.95,
        "fit_score": 0.88,
        "processing_time": 1.2,
        "recommendations": [
            "ğŸ M3 Max Neural Engineìœ¼ë¡œ ì´ˆê³ ì† ì²˜ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤!",
            "MPS ë°±ì—”ë“œê°€ ì •ìƒ ì‘ë™ ì¤‘ì…ë‹ˆë‹¤.",
            "128GB í†µí•© ë©”ëª¨ë¦¬ë¡œ ê³ í’ˆì§ˆ ê²°ê³¼ë¥¼ ì œê³µí•©ë‹ˆë‹¤.",
            "ğŸ“‹ Step Routes APIê°€ 8ë‹¨ê³„ íŒŒì´í”„ë¼ì¸ì„ ì§€ì›í•©ë‹ˆë‹¤."
        ] if importer.m3_max_optimized else [
            "ì„œë²„ê°€ ì •ìƒ ì‘ë™ ì¤‘ì…ë‹ˆë‹¤!",
            "ê°€ìƒ í”¼íŒ… ê¸°ëŠ¥ì„ í…ŒìŠ¤íŠ¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
            "ğŸ“‹ Step Routes APIê°€ í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤."
        ]
    }

# ğŸ”´ Step Routes ìƒíƒœ í™•ì¸ API
@app.get("/api/step-routes-status", tags=["step-routes"])
async def get_step_routes_status():
    """Step Routes API ìƒíƒœ í™•ì¸"""
    step_router = api_routers.get('step_routes')
    
    return {
        "step_routes_enabled": bool(step_router),
        "pipeline_routes_commented": True,
        "available_endpoints": [
            "/api/step/1/upload-validation",
            "/api/step/2/measurements-validation",
            "/api/step/3/human-parsing",
            "/api/step/4/pose-estimation",
            "/api/step/5/clothing-analysis",
            "/api/step/6/geometric-matching",
            "/api/step/7/virtual-fitting",
            "/api/step/8/result-analysis"
        ] if step_router else [],
        "router_type": type(step_router).__name__ if step_router else None,
        "timestamp": datetime.now().isoformat(),
        "notes": [
            "pipeline_routesëŠ” ì£¼ì„ì²˜ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤",
            "step_routesë¡œ ì™„ì „íˆ ëŒ€ì²´ë˜ì—ˆìŠµë‹ˆë‹¤",
            "8ë‹¨ê³„ API íŒŒì´í”„ë¼ì¸ì´ ì •ìƒ ì‘ë™í•©ë‹ˆë‹¤"
        ]
    }

# CORS í”„ë¦¬í”Œë¼ì´íŠ¸ ìš”ì²­ ì²˜ë¦¬
@app.options("/{path:path}")
async def options_handler(path: str):
    """CORS í”„ë¦¬í”Œë¼ì´íŠ¸ ìš”ì²­ ì²˜ë¦¬"""
    return {"message": "CORS preflight OK"}

# ============================================
# ë©”ì¸ ì‹¤í–‰ë¶€
# ============================================

if __name__ == "__main__":
    import uvicorn
    
    logger.info("ğŸ M3 Max 128GB ìµœì í™”ëœ MyCloset AI Backend v3.0.0 ì‹œì‘...")
    logger.info(f"ğŸ§  AI íŒŒì´í”„ë¼ì¸: {'M3 Max ìµœì í™” ëª¨ë“œ' if importer.m3_max_optimized else 'ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œ'}")
    logger.info(f"ğŸ”§ ë””ë°”ì´ìŠ¤: {gpu_config.get('device', 'unknown')}")
    logger.info(f"ğŸ“‹ Step Routes: {'âœ… í™œì„±í™”' if api_routers.get('step_routes') else 'âŒ ë¹„í™œì„±í™”'}")
    logger.info(f"ğŸš« Pipeline Routes: ì£¼ì„ì²˜ë¦¬ë¨ (step_routesë¡œ ëŒ€ì²´)")
    logger.info(f"ğŸ”— WebSocket: {'âœ… í™œì„±í™”' if api_routers.get('websocket') else 'âŒ ë¹„í™œì„±í™”'}")
    logger.info(f"ğŸ“Š Import ì„±ê³µ: {import_success}")
    
    # ì„œë²„ ì„¤ì •
    port = int(os.getenv("PORT", 8000))
    host = os.getenv("HOST", "0.0.0.0")
    
    if os.getenv("ENVIRONMENT") == "production":
        uvicorn.run(
            "app.main:app",
            host=host,
            port=port,
            reload=False,
            workers=1,
            log_level="info",
            access_log=True,
            loop="uvloop" if importer.m3_max_optimized else "asyncio"
        )
    else:
        uvicorn.run(
            "app.main:app",
            host=host,
            port=port,
            reload=False,
            log_level="info",
            access_log=True,
            loop="uvloop" if importer.m3_max_optimized else "asyncio"
        )

# M3 Max ìµœì í™” ìƒíƒœ ë¡œê¹…
if importer.m3_max_optimized:
    logger.info("ğŸ M3 Max 128GB ìµœì í™”: âœ… í™œì„±í™”ë¨")
    logger.info("ğŸ§  Neural Engine: ì¤€ë¹„ë¨")
    logger.info("âš¡ MPS ë°±ì—”ë“œ: í™œì„±í™”ë¨")
    logger.info("ğŸ“‹ Step Routes: 8ë‹¨ê³„ API ì¤€ë¹„ë¨")
    logger.info("ğŸš« Pipeline Routes: ì£¼ì„ì²˜ë¦¬ë¨")
    logger.info("ğŸ”— WebSocket: ì‹¤ì‹œê°„ í†µì‹  ì¤€ë¹„ë¨")
    logger.info("ğŸ› ï¸ ê°œë°œì ë„êµ¬: í™œì„±í™”ë¨")
    logger.info("ğŸ“Š ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§: í™œì„±í™”ë¨")
else:
    logger.info("ğŸ M3 Max ìµœì í™”: âŒ ë¹„í™œì„±í™”ë¨ (ì¼ë°˜ ëª¨ë“œ)")

logger.info("ğŸš€ M3 Max MyCloset AI Backend ë©”ì¸ ëª¨ë“ˆ ë¡œë“œ ì™„ë£Œ")

# ============================================
# ğŸ“‹ ì™„ì „í•œ ê¸°ëŠ¥ ìš”ì•½
# ============================================
"""
ğŸ”´ ì™„ì „íˆ êµ¬í˜„ëœ ê¸°ëŠ¥ë“¤:

âœ… 1. ê¸°ë³¸ FastAPI ì„¤ì •
   - CORS ì„¤ì • (Safari í˜¸í™˜) + 405 ì—ëŸ¬ í•´ê²°
   - Performance ë¯¸ë“¤ì›¨ì–´
   - ì˜ˆì™¸ ì²˜ë¦¬ (Pydantic V2 í˜¸í™˜)
   - ë¼ì´í”„ì‚¬ì´í´ ê´€ë¦¬

âœ… 2. ì»´í¬ë„ŒíŠ¸ Import ì‹œìŠ¤í…œ
   - ì•ˆì „í•œ import ë§¤ë‹ˆì €
   - í´ë°± ëª¨ë“œ ì§€ì›
   - M3 Max í™˜ê²½ ìë™ ê°ì§€

âœ… 3. API ë¼ìš°í„° ë“±ë¡ (ì™„ì „ êµì²´)
   - Health ë¼ìš°í„°
   - Virtual Try-on ë¼ìš°í„°
   - Models ë¼ìš°í„°
   - ğŸ”´ Step Routes ë¼ìš°í„° (8ë‹¨ê³„ API) âœ… ë“±ë¡ë¨
   - ğŸš« Pipeline ë¼ìš°í„° (ì£¼ì„ì²˜ë¦¬ë¨)
   - WebSocket ë¼ìš°í„°

âœ… 4. M3 Max ì „ìš© ê¸°ëŠ¥
   - /m3-max-status (í•˜ë“œì›¨ì–´ ìƒíƒœ)
   - /api/optimize-memory (ë©”ëª¨ë¦¬ ìµœì í™”)
   - /api/performance-metrics (ì„±ëŠ¥ ë©”íŠ¸ë¦­)

âœ… 5. ê°œë°œì ë„êµ¬ (ì—…ë°ì´íŠ¸)
   - /api/dev/debug-info (ë””ë²„ê·¸ ì •ë³´)
   - /api/dev/test-step-routes (Step Routes í…ŒìŠ¤íŠ¸) âœ… ìƒˆë¡œ ì¶”ê°€
   - /api/dev/warmup (ì‹œìŠ¤í…œ ì›Œë°ì—…)
   - /api/component-status (ì»´í¬ë„ŒíŠ¸ ìƒíƒœ)

âœ… 6. ì‹œìŠ¤í…œ ëª¨ë‹ˆí„°ë§
   - WebSocket ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§
   - ìƒì„¸ í—¬ìŠ¤ì²´í¬
   - ê¸´ê¸‰ ë¦¬ì…‹ ê¸°ëŠ¥

âœ… 7. í–¥ìƒëœ ì›¹ ì¸í„°í˜ì´ìŠ¤
   - ë£¨íŠ¸ í˜ì´ì§€ (ì‹œìŠ¤í…œ ìƒíƒœ ëŒ€ì‹œë³´ë“œ)
   - API ë¬¸ì„œ (íƒœê·¸ë³„ ë¶„ë¥˜)
   - ì„±ëŠ¥ ë©”íŠ¸ë¦­ í‘œì‹œ

âœ… 8. Step Routes ì™„ì „ ì§€ì› (Pipeline Routes ëŒ€ì²´)
   - POST /api/step/1/upload-validation
   - POST /api/step/2/measurements-validation
   - POST /api/step/3/human-parsing
   - POST /api/step/4/pose-estimation
   - POST /api/step/5/clothing-analysis
   - POST /api/step/6/geometric-matching
   - POST /api/step/7/virtual-fitting
   - POST /api/step/8/result-analysis

âœ… 9. ì„±ëŠ¥ ìµœì í™”
   - M3 Max Neural Engine í™œìš©
   - MPS ë°±ì—”ë“œ ìµœì í™”
   - í†µí•© ë©”ëª¨ë¦¬ ê´€ë¦¬
   - ì‹¤ì‹œê°„ ì„±ëŠ¥ ì¸¡ì •

âœ… 10. ì•ˆì •ì„± ë° í˜¸í™˜ì„±
   - í•¨ìˆ˜ëª…/í´ë˜ìŠ¤ëª… ë³€ê²½ ì—†ìŒ
   - ê¸°ì¡´ êµ¬ì¡° ì™„ì „ ìœ ì§€
   - í´ë°± ëª¨ë“œ ì§€ì›
   - ì—ëŸ¬ ë³µêµ¬ ë©”ì»¤ë‹ˆì¦˜

âœ… 11. 405 Method Not Allowed í•´ê²°
   - ê°•í™”ëœ CORS ë¯¸ë“¤ì›¨ì–´ ì¶”ê°€
   - OPTIONS ìš”ì²­ ì™„ì „ ì²˜ë¦¬
   - ëª¨ë“  ì‘ë‹µì— CORS í—¤ë” ì¶”ê°€

ğŸ”´ ì£¼ìš” ë³€ê²½ì‚¬í•­:
âœ… pipeline_routes ì™„ì „íˆ ì£¼ì„ì²˜ë¦¬ë¨
âœ… step_routesë¡œ ì™„ì „ ëŒ€ì²´ë¨
âœ… 405 ì—ëŸ¬ í•´ê²°ì„ ìœ„í•œ CORS ê°•í™”
âœ… ìƒˆë¡œìš´ í…ŒìŠ¤íŠ¸ API ì¶”ê°€ë¨
âœ… ìƒíƒœ í™•ì¸ API ì—…ë°ì´íŠ¸ë¨

ì´ì œ ì™„ì „í•œ MyCloset AI Backendê°€ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤!
Pipeline RoutesëŠ” ì£¼ì„ì²˜ë¦¬ë˜ê³  Step Routesê°€ ì™„ì „íˆ ëŒ€ì²´í–ˆìŠµë‹ˆë‹¤!
405 Method Not Allowed ì—ëŸ¬ë„ í•´ê²°ë˜ì—ˆìŠµë‹ˆë‹¤!
"""
                
        try:
            from app.api.health import router as health_router
            routers['health'] = health_router
            logger.info("âœ… Health ë¼ìš°í„° import ì„±ê³µ")
        except Exception as e:
            logger.warning(f"âš ï¸ Health ë¼ìš°í„° import ì‹¤íŒ¨: {e}")
            routers['health'] = None
        
        # Virtual try-on router
        try:
            from app.api.virtual_tryon import router as virtual_tryon_router
            routers['virtual_tryon'] = virtual_tryon_router
            logger.info("âœ… Virtual Try-on ë¼ìš°í„° import ì„±ê³µ")
        except Exception as e:
            logger.warning(f"âš ï¸ Virtual Try-on ë¼ìš°í„° import ì‹¤íŒ¨: {e}")
            routers['virtual_tryon'] = None
        
        # Models router
        try:
            from app.api.models import router as models_router
            routers['models'] = models_router
            logger.info("âœ… Models ë¼ìš°í„° import ì„±ê³µ")
        except Exception as e:
            logger.warning(f"âš ï¸ Models ë¼ìš°í„° import ì‹¤íŒ¨: {e}")
            routers['models'] = None
        
        # ğŸ”´ Step Routes - ìƒˆë¡œ ì¶”ê°€ëœ ë‹¨ê³„ë³„ API ë¼ìš°í„° (pipeline_routes ëŒ€ì‹ )
        try:
            from app.api.step_routes import router as step_router
            routers['step_routes'] = step_router
            logger.info("âœ… Step ë¼ìš°í„° ë“±ë¡ë¨ - ê²½ë¡œ: /api/step/*")
        except Exception as e:
            logger.warning(f"âš ï¸ Step ë¼ìš°í„° import ì‹¤íŒ¨: {e}")
            routers['step_routes'] = None
        
        # ğŸ”´ Pipeline routes - ì£¼ì„ì²˜ë¦¬ë¨ (step_routesë¡œ ëŒ€ì²´)
        # try:
        #     from app.api.pipeline_routes import router as pipeline_router
        #     routers['pipeline'] = pipeline_router
        #     logger.info("âœ… Pipeline ë¼ìš°í„° ë“±ë¡ë¨ - ê²½ë¡œ: /api/pipeline/*")
        # except Exception as e:
        #     logger.warning(f"âš ï¸ Pipeline ë¼ìš°í„° import ì‹¤íŒ¨: {e}")
        #     routers['pipeline'] = None
        
        # WebSocket routes
        try:
            from app.api.websocket_routes import router as websocket_router
            # start_background_tasks í•¨ìˆ˜ í™•ì¸
            try:
                from app.api.websocket_routes import start_background_tasks
                routers['websocket_background_tasks'] = start_background_tasks
            except ImportError:
                routers['websocket_background_tasks'] = None
            
            routers['websocket'] = websocket_router
            logger.info("âœ… WebSocket ë¼ìš°í„° import ì„±ê³µ")
        except Exception as e:
            logger.warning(f"âš ï¸ WebSocket ë¼ìš°í„° import ì‹¤íŒ¨: {e}")
            routers['websocket'] = None
            routers['websocket_background_tasks'] = None
        
        self.components['routers'] = routers
        return routers
    
    def initialize_all_components(self):
        """ëª¨ë“  ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”"""
        logger.info("ğŸ M3 Max ìµœì í™” MyCloset AI íŒŒì´í”„ë¼ì¸ ë¡œë”©...")
        
        # ë””ë ‰í† ë¦¬ ìƒì„±
        directories = [
            project_root / "logs",
            project_root / "static" / "uploads",
            project_root / "static" / "results",
            project_root / "temp"
        ]
        
        for directory in directories:
            try:
                directory.mkdir(parents=True, exist_ok=True)
            except Exception as e:
                logger.warning(f"ë””ë ‰í† ë¦¬ ìƒì„± ì‹¤íŒ¨ {directory}: {e}")
        
        # ì»´í¬ë„ŒíŠ¸ import
        success_count = 0
        
        if self.safe_import_schemas():
            success_count += 1
        
        if self.safe_import_gpu_config():
            success_count += 1
        
        self.safe_import_api_routers()
        
        logger.info(f"ğŸ“Š ì»´í¬ë„ŒíŠ¸ import ì™„ë£Œ: {success_count}/2 ì„±ê³µ")
        
        if self.m3_max_optimized:
            logger.info("ğŸ M3 Max 128GB ìµœì í™” ëª¨ë“œ í™œì„±í™”")
        
        return success_count >= 1

# ì»´í¬ë„ŒíŠ¸ importer ì´ˆê¸°í™”
importer = M3MaxComponentImporter()
import_success = importer.initialize_all_components()

# ì»´í¬ë„ŒíŠ¸ ì°¸ì¡° ì„¤ì •
schemas = importer.components.get('schemas', {})
gpu_config = importer.components.get('gpu_config', {})
api_routers = importer.components.get('routers', {})

# ì „ì—­ ìƒíƒœ
app_state = {
    "initialized": False,
    "startup_time": None,
    "import_success": import_success,
    "fallback_mode": importer.fallback_mode,
    "m3_max_optimized": importer.m3_max_optimized,
    "device": gpu_config.get('device', 'cpu'),
    "pipeline_mode": "m3_max_optimized" if importer.m3_max_optimized else "simulation",
    "total_sessions": 0,
    "successful_sessions": 0,
    "errors": importer.import_errors.copy(),
    "performance_metrics": {
        "average_response_time": 0.0,
        "total_requests": 0,
        "error_rate": 0.0,
        "m3_max_optimized_sessions": 0,
        "memory_efficiency": 0.95 if importer.m3_max_optimized else 0.8
    }
}

# ============================================
# ë¯¸ë“¤ì›¨ì–´
# ============================================

async def m3_max_performance_middleware(request: Request, call_next):
    """M3 Max ìµœì í™”ëœ ì„±ëŠ¥ ì¸¡ì • ë¯¸ë“¤ì›¨ì–´"""
    start_timestamp = time_module.time()
    
    if importer.m3_max_optimized:
        start_performance = time_module.perf_counter()
    
    try:
        response = await call_next(request)
    except Exception as e:
        logger.error(f"ë¯¸ë“¤ì›¨ì–´ ì˜¤ë¥˜: {e}")
        # ê¸°ë³¸ ì˜¤ë¥˜ ì‘ë‹µ ìƒì„±
        response = JSONResponse(
            status_code=500,
            content={"error": "Internal server error", "detail": str(e)}
        )
    
    process_time = time_module.time() - start_timestamp
    
    if importer.m3_max_optimized:
        try:
            precise_time = time_module.perf_counter() - start_performance
            response.headers["X-M3-Max-Precise-Time"] = str(round(precise_time, 6))
            response.headers["X-M3-Max-Optimized"] = "true"
        except Exception:
            pass
    
    response.headers["X-Process-Time"] = str(round(process_time, 4))
    
    # ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
    try:
        app_state["performance_metrics"]["total_requests"] += 1
        current_avg = app_state["performance_metrics"]["average_response_time"]
        total_requests = app_state["performance_metrics"]["total_requests"]
        
        app_state["performance_metrics"]["average_response_time"] = (
            (current_avg * (total_requests - 1) + process_time) / total_requests
        )
        
        if importer.m3_max_optimized and "/api/virtual-tryon" in str(request.url):
            app_state["performance_metrics"]["m3_max_optimized_sessions"] += 1
    except Exception as e:
        logger.warning(f"ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
    
    return response

# ============================================
# ë¼ì´í”„ì‚¬ì´í´ ê´€ë¦¬ - ì•ˆì „ ë²„ì „
# ============================================

@asynccontextmanager
async def m3_max_lifespan(app: FastAPI):
    """M3 Max ìµœì í™”ëœ ì• í”Œë¦¬ì¼€ì´ì…˜ ë¼ì´í”„ì‚¬ì´í´ ê´€ë¦¬"""
    logger.info("ğŸ M3 Max MyCloset AI Backend ì‹œì‘...")
    startup_start_time = time_module.time()
    
    try:
        # M3 Max í™˜ê²½ ìµœì í™”
        if importer.m3_max_optimized:
            logger.info("ğŸ§  M3 Max Neural Engine í™œì„±í™” ì¤€ë¹„...")
            await asyncio.sleep(0.5)
            
            logger.info("âš¡ MPS ë°±ì—”ë“œ ìµœì í™” ì„¤ì •...")
            await asyncio.sleep(0.5)
            
            logger.info("ğŸ’¾ 128GB ë©”ëª¨ë¦¬ í’€ ì´ˆê¸°í™”...")
            await asyncio.sleep(0.3)
        
        # WebSocket ë°±ê·¸ë¼ìš´ë“œ íƒœìŠ¤í¬ ì‹œì‘ (ì•ˆì „í•˜ê²Œ)
        websocket_background_tasks = api_routers.get('websocket_background_tasks')
        if websocket_background_tasks and callable(websocket_background_tasks):
            try:
                await websocket_background_tasks()
                logger.info("ğŸ”— WebSocket ë°±ê·¸ë¼ìš´ë“œ íƒœìŠ¤í¬ ì‹œì‘ë¨")
            except Exception as e:
                logger.warning(f"WebSocket ë°±ê·¸ë¼ìš´ë“œ íƒœìŠ¤í¬ ì‹œì‘ ì‹¤íŒ¨: {e}")
        
        app_state["startup_time"] = time_module.time() - startup_start_time
        app_state["initialized"] = True
        
        # ì‹œìŠ¤í…œ ìƒíƒœ ë¡œê¹…
        logger.info("=" * 70)
        logger.info("ğŸ M3 Max MyCloset AI Backend ì‹œìŠ¤í…œ ìƒíƒœ")
        logger.info("=" * 70)
        logger.info(f"ğŸ”§ ë””ë°”ì´ìŠ¤: {app_state['device']}")
        logger.info(f"ğŸ M3 Max ìµœì í™”: {'âœ… í™œì„±í™”' if importer.m3_max_optimized else 'âŒ ë¹„í™œì„±í™”'}")
        logger.info(f"ğŸ­ íŒŒì´í”„ë¼ì¸ ëª¨ë“œ: {app_state['pipeline_mode']}")
        logger.info(f"âœ… ì´ˆê¸°í™” ì„±ê³µ: {app_state['initialized']}")
        logger.info(f"ğŸ”— WebSocket: {'âœ… í™œì„±í™”' if api_routers.get('websocket') else 'âŒ ë¹„í™œì„±í™”'}")
        logger.info(f"ğŸ“‹ Step Routes: {'âœ… í™œì„±í™”' if api_routers.get('step_routes') else 'âŒ ë¹„í™œì„±í™”'}")
        logger.info(f"â±ï¸ ì‹œì‘ ì‹œê°„: {app_state['startup_time']:.2f}ì´ˆ")
        
        if app_state['errors']:
            logger.warning(f"âš ï¸ ì˜¤ë¥˜ ëª©ë¡ ({len(app_state['errors'])}ê°œ):")
            for error in app_state['errors']:
                logger.warning(f"  - {error}")
        
        logger.info("âœ… M3 Max ë°±ì—”ë“œ ì´ˆê¸°í™” ì™„ë£Œ")
        logger.info("=" * 70)
        
    except Exception as e:
        error_msg = f"Startup error: {str(e)}"
        logger.error(f"âŒ ì‹œì‘ ì¤‘ ì¹˜ëª…ì  ì˜¤ë¥˜: {error_msg}")
        logger.error(f"ğŸ“‹ ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤: {traceback.format_exc()}")
        app_state["errors"].append(error_msg)
        app_state["initialized"] = False
    
    yield  # ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹¤í–‰
    
    # ì¢…ë£Œ ë¡œì§
    logger.info("ğŸ›‘ M3 Max MyCloset AI Backend ì¢…ë£Œ ì¤‘...")
    
    try:
        # M3 Max ìµœì í™”ëœ ë©”ëª¨ë¦¬ ì •ë¦¬
        optimize_func = gpu_config.get('optimize_memory')
        if optimize_func and callable(optimize_func):
            try:
                result = optimize_func(
                    device=gpu_config.get('device'), 
                    aggressive=importer.m3_max_optimized
                )
                if result.get('success'):
                    logger.info(f"ğŸ M3 Max ë©”ëª¨ë¦¬ ì •ë¦¬ ì™„ë£Œ: {result.get('method', 'unknown')}")
            except Exception as e:
                logger.warning(f"ë©”ëª¨ë¦¬ ì •ë¦¬ ì‹¤íŒ¨: {e}")
        
        if importer.m3_max_optimized:
            logger.info("ğŸ§  Neural Engine ì •ë¦¬ë¨")
            logger.info("âš¡ MPS ë°±ì—”ë“œ ì •ë¦¬ë¨")
        
        logger.info("âœ… M3 Max ì •ë¦¬ ì™„ë£Œ")
        
    except Exception as e:
        logger.warning(f"âš ï¸ ì •ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")

# ============================================
# FastAPI ì• í”Œë¦¬ì¼€ì´ì…˜ ìƒì„±
# ============================================

# API ë¬¸ì„œ íƒœê·¸ ì •ì˜
tags_metadata = [
    {
        "name": "health",
        "description": "ì‹œìŠ¤í…œ í—¬ìŠ¤ì²´í¬ ë° ìƒíƒœ ëª¨ë‹ˆí„°ë§",
    },
    {
        "name": "virtual-tryon",
        "description": "ê°€ìƒ í”¼íŒ… ê¸°ëŠ¥ API",
    },
    {
        "name": "step-routes",
        "description": "8ë‹¨ê³„ AI íŒŒì´í”„ë¼ì¸ API - ë‹¨ê³„ë³„ ì²˜ë¦¬ (step_routes)",
    },
    {
        "name": "websocket",
        "description": "ì‹¤ì‹œê°„ í†µì‹  ë° ì§„í–‰ë¥  ëª¨ë‹ˆí„°ë§",
    },
    {
        "name": "models",
        "description": "AI ëª¨ë¸ ê´€ë¦¬ ë° ì„¤ì •",
    },
    {
        "name": "m3-max",
        "description": "M3 Max ìµœì í™” ë° ì„±ëŠ¥ ê´€ë¦¬",
    },
    {
        "name": "development",
        "description": "ê°œë°œì ë„êµ¬ ë° ë””ë²„ê¹…",
    }
]

app = FastAPI(
    title="MyCloset AI Backend (M3 Max Optimized)",
    description="""
    ## M3 Max 128GB ìµœì í™” ê°€ìƒ í”¼íŒ… AI ë°±ì—”ë“œ ì„œë¹„ìŠ¤
    
    ### ì£¼ìš” ê¸°ëŠ¥
    - ğŸ **M3 Max Neural Engine ìµœì í™”**: 40ì½”ì–´ GPU + Neural Engine í™œìš©
    - ğŸ“‹ **8ë‹¨ê³„ AI íŒŒì´í”„ë¼ì¸**: ì—…ë¡œë“œë¶€í„° ê²°ê³¼ ë¶„ì„ê¹Œì§€ ì™„ì „ ìë™í™”
    - ğŸ”— **ì‹¤ì‹œê°„ WebSocket**: ì§„í–‰ë¥  ëª¨ë‹ˆí„°ë§ ë° ìƒíƒœ ì—…ë°ì´íŠ¸
    - âš¡ **í†µí•© ë©”ëª¨ë¦¬ ê´€ë¦¬**: 400GB/s ë©”ëª¨ë¦¬ ëŒ€ì—­í­ ìµœì í™”
    - ğŸ­ **ê°€ìƒ í”¼íŒ…**: OOTDiffusion + VITON-HD ê¸°ë°˜ ê³ í’ˆì§ˆ í”¼íŒ…
    
    ### API ì¹´í…Œê³ ë¦¬
    - **Step Routes**: 8ë‹¨ê³„ ì²˜ë¦¬ í”„ë¡œì„¸ìŠ¤ (/api/step/1-8/)
    - **M3 Max**: í•˜ë“œì›¨ì–´ ìµœì í™” ê¸°ëŠ¥ (/m3-max-status, /api/optimize-memory)
    - **Development**: ê°œë°œì ë„êµ¬ (/api/dev/)
    - **Health**: ì‹œìŠ¤í…œ ëª¨ë‹ˆí„°ë§ (/health, /api/health/)
    
    ### ì„±ëŠ¥ íŠ¹ì§•
    - M3 Max í™˜ê²½ì—ì„œ ìµœëŒ€ 95% ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±
    - Neural Engine í™œìš©ìœ¼ë¡œ 15.8 TOPS ì—°ì‚° ì„±ëŠ¥
    - í†µí•© ë©”ëª¨ë¦¬ ì•„í‚¤í…ì²˜ë¡œ ë°ì´í„° ë³µì‚¬ ìµœì†Œí™”
    """,
    version="3.0.0-m3max",
    openapi_tags=tags_metadata,
    lifespan=m3_max_lifespan,
    docs_url="/docs",
    redoc_url="/redoc",
    openapi_url="/openapi.json"
)

# ============================================
# ë¯¸ë“¤ì›¨ì–´ ì„¤ì • - ğŸ”´ CORS ì™„ì „ ìˆ˜ì • (405 ì—ëŸ¬ í•´ê²°)
# ============================================

# ğŸ”´ CORS ì„¤ì • ì™„ì „ êµì²´ - 405 Method Not Allowed í•´ê²°
app.add_middleware(
    CORSMiddleware,
    allow_origins=[
        "http://localhost:3000",
        "http://127.0.0.1:3000",
        "http://localhost:5173", 
        "http://127.0.0.1:5173",
        "http://localhost:8080",
        "http://127.0.0.1:8080",
        "*"  # Safari ë•Œë¬¸ì— í•„ìš”
    ],
    allow_credentials=True,
    allow_methods=["GET", "POST", "PUT", "DELETE", "OPTIONS", "PATCH", "HEAD"],
    allow_headers=[
        "Accept",
        "Accept-Language", 
        "Content-Language",
        "Content-Type",
        "Authorization",
        "X-Requested-With",
        "X-CSRFToken",
        "X-Request-ID",
        "Cache-Control",
        "Pragma",
        "*"
    ],
    expose_headers=["*"],
    max_age=3600
)

# ğŸ”´ 405 ì—ëŸ¬ í•´ê²°ì„ ìœ„í•œ ì¶”ê°€ CORS ë¯¸ë“¤ì›¨ì–´
@app.middleware("http")
async def enhanced_cors_middleware(request: Request, call_next):
    """ê°•í™”ëœ CORS ì²˜ë¦¬ - 405 Method Not Allowed í•´ê²°"""
    
    # ëª¨ë“  ìš”ì²­ì— ëŒ€í•´ CORS í—¤ë” ì„¤ì •
    origin = request.headers.get("origin", "*")
    
    # OPTIONS ìš”ì²­ ì™„ì „ ì²˜ë¦¬
    if request.method == "OPTIONS":
        response = Response()
        response.headers["Access-Control-Allow-Origin"] = origin
        response.headers["Access-Control-Allow-Methods"] = "GET, POST, PUT, DELETE, OPTIONS, PATCH, HEAD"
        response.headers["Access-Control-Allow-Headers"] = "*"
        response.headers["Access-Control-Allow-Credentials"] = "true"
        response.headers["Access-Control-Max-Age"] = "3600"
        response.headers["Content-Length"] = "0"
        response.status_code = 200
        return response
    
    # ì¼ë°˜ ìš”ì²­ ì²˜ë¦¬
    try:
        response = await call_next(request)
    except Exception as e:
        logger.error(f"ìš”ì²­ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
        response = JSONResponse(
            status_code=500,
            content={"success": False, "error": str(e)}
        )
    
    # ëª¨ë“  ì‘ë‹µì— CORS í—¤ë” ì¶”ê°€
    response.headers["Access-Control-Allow-Origin"] = origin
    response.headers["Access-Control-Allow-Methods"] = "GET, POST, PUT, DELETE, OPTIONS, PATCH, HEAD"
    response.headers["Access-Control-Allow-Headers"] = "*"
    response.headers["Access-Control-Allow-Credentials"] = "true"
    response.headers["Access-Control-Expose-Headers"] = "*"
    
    return response

# ğŸ”´ Performance ë¯¸ë“¤ì›¨ì–´ ë“±ë¡
app.middleware("http")(m3_max_performance_middleware)

# ============================================
# ì˜ˆì™¸ ì²˜ë¦¬
# ============================================

@app.exception_handler(StarletteHTTPException)
async def http_exception_handler(request: Request, exc: StarletteHTTPException):
    """HTTP ì˜ˆì™¸ ì²˜ë¦¬"""
    try:
        app_state["performance_metrics"]["total_requests"] += 1
    except Exception:
        pass
    
    error_response = {
        "success": False,
        "error": {
            "type": "http_error",
            "status_code": exc.status_code,
            "message": exc.detail,
            "timestamp": datetime.now().isoformat(),
            "m3_max_optimized": importer.m3_max_optimized
        },
        "request_info": {
            "method": request.method,
            "url": str(request.url),
            "client": request.client.host if request.client else "unknown"
        }
    }
    
    logger.warning(f"HTTP ì˜ˆì™¸: {exc.status_code} - {exc.detail} - {request.url}")
    
    return JSONResponse(
        status_code=exc.status_code,
        content=error_response,
        headers={
            "Access-Control-Allow-Origin": "*",
            "Access-Control-Allow-Methods": "GET, POST, PUT, DELETE, OPTIONS",
            "Access-Control-Allow-Headers": "*"
        }
    )

@app.exception_handler(RequestValidationError)
async def validation_exception_handler(request: Request, exc: RequestValidationError):
    """Pydantic V2 í˜¸í™˜ ìš”ì²­ ê²€ì¦ ì˜ˆì™¸ ì²˜ë¦¬"""
    try:
        app_state["performance_metrics"]["total_requests"] += 1
    except Exception:
        pass
    
    error_response = {
        "success": False,
        "error": {
            "type": "validation_error",
            "message": "Request validation failed (Pydantic V2)",
            "details": exc.errors(),
            "timestamp": datetime.now().isoformat(),
            "pydantic_version": "v2",
            "m3_max_optimized": importer.m3_max_optimized
        }
    }
    
    logger.warning(f"Pydantic V2 ê²€ì¦ ì˜¤ë¥˜: {exc.errors()} - {request.url}")
    
    return JSONResponse(
        status_code=422,
        content=error_response,
        headers={
            "Access-Control-Allow-Origin": "*",
            "Access-Control-Allow-Methods": "GET, POST, PUT, DELETE, OPTIONS",
            "Access-Control-Allow-Headers": "*"
        }
    )

@app.exception_handler(Exception)
async def general_exception_handler(request: Request, exc: Exception):
    """ì¼ë°˜ ì˜ˆì™¸ ì²˜ë¦¬"""
    try:
        app_state["performance_metrics"]["total_requests"] += 1
    except Exception:
        pass
    
    error_msg = str(exc)
    error_type = type(exc).__name__
    
    error_response = {
        "success": False,
        "error": {
            "type": error_type,
            "message": error_msg,
            "timestamp": datetime.now().isoformat(),
            "m3_max_optimized": importer.m3_max_optimized,
            "device": app_state.get("device", "unknown")
        }
    }
    
    logger.error(f"ì¼ë°˜ ì˜ˆì™¸: {error_type} - {error_msg} - {request.url}")
    logger.error(f"ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤: {traceback.format_exc()}")
    
    return JSONResponse(
        status_code=500,
        content=error_response,
        headers={
            "Access-Control-Allow-Origin": "*",
            "Access-Control-Allow-Methods": "GET, POST, PUT, DELETE, OPTIONS",
            "Access-Control-Allow-Headers": "*"
        }
    )

# ============================================
# ğŸ”´ API ë¼ìš°í„° ë“±ë¡ - Step Routes í¬í•¨, Pipeline Routes ì£¼ì„ì²˜ë¦¬
# ============================================

# Health router