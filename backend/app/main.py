# app/main.py
"""
MyCloset AI Backend - ì™„ì „í•œ ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜
M3 Max 128GB ìµœì í™”, ì•ˆì •ì ì¸ import ì²˜ë¦¬, í”„ë¡œë•ì…˜ ë ˆë²¨ êµ¬í˜„
"""

import sys
import os
import logging
import time
import asyncio
import traceback
import json
from datetime import datetime
from pathlib import Path
from typing import Dict, Any, Optional, List
from contextlib import asynccontextmanager

# Python ê²½ë¡œ ì„¤ì •
current_dir = Path(__file__).parent
project_root = current_dir.parent
sys.path.insert(0, str(current_dir))
sys.path.insert(0, str(project_root))

print("ğŸ Python ê²½ë¡œ ì„¤ì •:")
print(f"  - App Dir: {current_dir}")
print(f"  - Project Root: {project_root}")

# FastAPI imports
try:
    from fastapi import FastAPI, HTTPException, Request, Depends
    from fastapi.middleware.cors import CORSMiddleware
    from fastapi.staticfiles import StaticFiles
    from fastapi.responses import JSONResponse, HTMLResponse
    from fastapi.exceptions import RequestValidationError
    from starlette.exceptions import HTTPException as StarletteHTTPException
    from pydantic import BaseModel
except ImportError as e:
    print(f"âŒ FastAPI import ì‹¤íŒ¨: {e}")
    sys.exit(1)

# ë¡œê¹… ì„¤ì •
def setup_logging():
    """ë¡œê¹… ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
    log_dir = project_root / "logs"
    log_dir.mkdir(exist_ok=True)
    
    log_format = '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    
    # íŒŒì¼ í•¸ë“¤ëŸ¬
    file_handler = logging.FileHandler(
        log_dir / f"mycloset-ai-{datetime.now().strftime('%Y%m%d')}.log",
        encoding='utf-8'
    )
    file_handler.setFormatter(logging.Formatter(log_format))
    
    # ì½˜ì†” í•¸ë“¤ëŸ¬
    console_handler = logging.StreamHandler()
    console_handler.setFormatter(logging.Formatter(log_format))
    
    # ë£¨íŠ¸ ë¡œê±° ì„¤ì •
    root_logger = logging.getLogger()
    root_logger.setLevel(logging.INFO)
    root_logger.addHandler(file_handler)
    root_logger.addHandler(console_handler)
    
    return logging.getLogger(__name__)

# ë¡œê¹… ì´ˆê¸°í™”
logger = setup_logging()

# ============================================
# ì•ˆì „í•œ ì»´í¬ë„ŒíŠ¸ Import ì‹œìŠ¤í…œ
# ============================================

class ComponentImporter:
    """ì•ˆì „í•œ ì»´í¬ë„ŒíŠ¸ import ë§¤ë‹ˆì €"""
    
    def __init__(self):
        self.components = {}
        self.import_errors = []
        self.fallback_mode = False
    
    def safe_import_gpu_config(self):
        """GPU ì„¤ì • ì•ˆì „ import"""
        try:
            from app.core.gpu_config import (
                gpu_config, DEVICE, MODEL_CONFIG, 
                DEVICE_INFO, get_device_config,
                get_device, get_model_config, get_device_info  # ì¶”ê°€ëœ í•¨ìˆ˜ë“¤
            )
            
            self.components['gpu_config'] = {
                'instance': gpu_config,
                'device': DEVICE,
                'model_config': MODEL_CONFIG,
                'device_info': DEVICE_INFO,
                'get_config': get_device_config,
                'get_device': get_device,
                'get_model_config': get_model_config,
                'get_device_info': get_device_info
            }
            
            logger.info("âœ… GPU ì„¤ì • import ì„±ê³µ")
            return True
            
        except ImportError as e:
            error_msg = f"GPU ì„¤ì • import ì‹¤íŒ¨: {e}"
            self.import_errors.append(error_msg)
            logger.warning(f"âš ï¸ {error_msg}")
            
            # í´ë°± ì„¤ì •
            self.components['gpu_config'] = {
                'instance': None,
                'device': "cpu",
                'model_config': {"device": "cpu", "dtype": "float32"},
                'device_info': {
                    "device": "cpu",
                    "name": "CPU",
                    "memory_gb": 0,
                    "is_m3_max": False,
                    "pytorch_version": "unknown",
                    "mps_available": False
                },
                'get_config': lambda: {"device": "cpu", "name": "CPU"},
                'get_device': lambda: "cpu",
                'get_model_config': lambda: {"device": "cpu"},
                'get_device_info': lambda: {"device": "cpu", "name": "CPU"}
            }
            return False
    
    def safe_import_memory_manager(self):
        """ë©”ëª¨ë¦¬ ë§¤ë‹ˆì € ì•ˆì „ import"""
        try:
            from app.ai_pipeline.utils.memory_manager import (
                get_memory_manager, 
                optimize_memory_usage,
                check_memory,
                MemoryManager,
                get_global_memory_manager,  # ì¶”ê°€ëœ í•¨ìˆ˜ë“¤
                create_memory_manager,
                get_default_memory_manager
            )
            
            self.components['memory_manager'] = {
                'get_manager': get_memory_manager,
                'optimize': optimize_memory_usage,
                'check': check_memory,
                'class': MemoryManager,
                'get_global': get_global_memory_manager,
                'create': create_memory_manager,
                'get_default': get_default_memory_manager
            }
            
            logger.info("âœ… ë©”ëª¨ë¦¬ ë§¤ë‹ˆì € import ì„±ê³µ")
            return True
            
        except ImportError as e:
            error_msg = f"ë©”ëª¨ë¦¬ ë§¤ë‹ˆì € import ì‹¤íŒ¨: {e}"
            self.import_errors.append(error_msg)
            logger.warning(f"âš ï¸ {error_msg}")
            
            # í´ë°± í•¨ìˆ˜ë“¤
            def fallback_get_memory_manager():
                return None
            
            def fallback_optimize_memory_usage(device=None, aggressive=False):
                return {
                    "success": False, 
                    "error": "Memory manager not available",
                    "device": device or "unknown"
                }
            
            def fallback_check_memory():
                return {
                    "status": "unknown", 
                    "error": "Memory manager not available"
                }
            
            self.components['memory_manager'] = {
                'get_manager': fallback_get_memory_manager,
                'optimize': fallback_optimize_memory_usage,
                'check': fallback_check_memory,
                'class': None,
                'get_global': fallback_get_memory_manager,
                'create': fallback_get_memory_manager,
                'get_default': fallback_get_memory_manager
            }
            return False
    
    def safe_import_m3_optimizer(self):
        """M3 Max ìµœì í™” ì•ˆì „ import"""
        try:
            from app.core.m3_optimizer import (
                get_m3_optimizer,
                is_m3_max_optimized,
                get_optimal_config,
                M3MaxOptimizer,
                create_m3_optimizer,  # ì¶”ê°€ëœ í•¨ìˆ˜ë“¤
                get_m3_config,
                optimize_for_m3_max
            )
            
            self.components['m3_optimizer'] = {
                'get_optimizer': get_m3_optimizer,
                'is_optimized': is_m3_max_optimized,
                'get_config': get_optimal_config,
                'class': M3MaxOptimizer,
                'create': create_m3_optimizer,
                'get_m3_config': get_m3_config,
                'optimize': optimize_for_m3_max
            }
            
            logger.info("âœ… M3 ìµœì í™” import ì„±ê³µ")
            return True
            
        except ImportError as e:
            error_msg = f"M3 ìµœì í™” import ì‹¤íŒ¨: {e}"
            self.import_errors.append(error_msg)
            logger.warning(f"âš ï¸ {error_msg}")
            
            # í´ë°± í•¨ìˆ˜ë“¤
            def fallback_get_m3_optimizer():
                class FallbackOptimizer:
                    def __init__(self):
                        self.is_m3_max = False
                        self.device = "cpu"
                return FallbackOptimizer()
            
            def fallback_is_m3_max_optimized():
                return False
            
            def fallback_get_optimal_config(model_type="diffusion"):
                return {"device": "cpu", "batch_size": 1}
            
            self.components['m3_optimizer'] = {
                'get_optimizer': fallback_get_m3_optimizer,
                'is_optimized': fallback_is_m3_max_optimized,
                'get_config': fallback_get_optimal_config,
                'class': None,
                'create': fallback_get_m3_optimizer,
                'get_m3_config': lambda: {"device": "cpu"},
                'optimize': fallback_is_m3_max_optimized
            }
            return False
    
    def safe_import_pipeline_manager(self):
        """íŒŒì´í”„ë¼ì¸ ë§¤ë‹ˆì € ì•ˆì „ import"""
        try:
            from app.ai_pipeline.pipeline_manager import (
                PipelineManager, PipelineMode,
                get_pipeline_manager,  # ì¶”ê°€ëœ í•¨ìˆ˜ë“¤  
                create_pipeline_manager,
                get_available_modes
            )
            
            self.components['pipeline_manager'] = {
                'class': PipelineManager,
                'modes': PipelineMode,
                'get_manager': get_pipeline_manager,
                'create': create_pipeline_manager,
                'get_modes': get_available_modes
            }
            
            logger.info("âœ… íŒŒì´í”„ë¼ì¸ ë§¤ë‹ˆì € import ì„±ê³µ")
            return True
            
        except ImportError as e:
            error_msg = f"íŒŒì´í”„ë¼ì¸ ë§¤ë‹ˆì € import ì‹¤íŒ¨: {e}"
            self.import_errors.append(error_msg)
            logger.warning(f"âš ï¸ {error_msg}")
            
            # ì‹œë®¬ë ˆì´ì…˜ íŒŒì´í”„ë¼ì¸ í´ë˜ìŠ¤
            class SimulationPipelineManager:
                def __init__(self, mode="simulation", **kwargs):
                    self.mode = mode
                    self.is_initialized = False
                    self.device = kwargs.get('device', 'cpu')
                
                async def initialize(self):
                    logger.info("ğŸ­ ì‹œë®¬ë ˆì´ì…˜ íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™”...")
                    await asyncio.sleep(1)  # ì´ˆê¸°í™” ì‹œë®¬ë ˆì´ì…˜
                    self.is_initialized = True
                    logger.info("âœ… ì‹œë®¬ë ˆì´ì…˜ íŒŒì´í”„ë¼ì¸ ì¤€ë¹„ ì™„ë£Œ")
                    return True
                
                async def cleanup(self):
                    logger.info("ğŸ­ ì‹œë®¬ë ˆì´ì…˜ íŒŒì´í”„ë¼ì¸ ì •ë¦¬ ì™„ë£Œ")
                    self.is_initialized = False
                
                def get_status(self):
                    return {
                        "mode": self.mode,
                        "initialized": self.is_initialized,
                        "device": self.device,
                        "simulation": True
                    }
            
            # ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œ enum
            class SimulationMode:
                SIMULATION = "simulation"
                PRODUCTION = "production"
                HYBRID = "hybrid"
            
            def fallback_get_pipeline_manager():
                return None
            
            def fallback_create_pipeline_manager(mode="simulation"):
                return SimulationPipelineManager(mode=mode)
            
            def fallback_get_available_modes():
                return {
                    "simulation": "simulation",
                    "production": "production", 
                    "hybrid": "hybrid"
                }
            
            self.components['pipeline_manager'] = {
                'class': SimulationPipelineManager,
                'modes': SimulationMode,
                'get_manager': fallback_get_pipeline_manager,
                'create': fallback_create_pipeline_manager,
                'get_modes': fallback_get_available_modes
            }
            self.fallback_mode = True
            return False
    
    def safe_import_api_routers(self):
        """API ë¼ìš°í„°ë“¤ ì•ˆì „ import"""
        routers = {}
        
        # Health router
        try:
            from app.api.health import router as health_router
            routers['health'] = health_router
            logger.info("âœ… Health ë¼ìš°í„° import ì„±ê³µ")
        except ImportError as e:
            logger.warning(f"âš ï¸ Health ë¼ìš°í„° import ì‹¤íŒ¨: {e}")
            routers['health'] = None
        
        # Virtual try-on router
        try:
            from app.api.virtual_tryon import router as virtual_tryon_router
            routers['virtual_tryon'] = virtual_tryon_router
            logger.info("âœ… Virtual Try-on ë¼ìš°í„° import ì„±ê³µ")
        except ImportError as e:
            logger.warning(f"âš ï¸ Virtual Try-on ë¼ìš°í„° import ì‹¤íŒ¨: {e}")
            routers['virtual_tryon'] = None
        
        # Models router
        try:
            from app.api.models import router as models_router
            routers['models'] = models_router
            logger.info("âœ… Models ë¼ìš°í„° import ì„±ê³µ")
        except ImportError as e:
            logger.warning(f"âš ï¸ Models ë¼ìš°í„° import ì‹¤íŒ¨: {e}")
            routers['models'] = None
        
        # Pipeline routes
        try:
            from app.api.pipeline_routes import router as pipeline_router
            routers['pipeline'] = pipeline_router
            logger.info("âœ… Pipeline ë¼ìš°í„° import ì„±ê³µ")
        except ImportError as e:
            logger.warning(f"âš ï¸ Pipeline ë¼ìš°í„° import ì‹¤íŒ¨: {e}")
            routers['pipeline'] = None
        
        # WebSocket routes - ì•ˆì „í•˜ê²Œ ì²˜ë¦¬
        try:
            # Pydantic V2 í˜¸í™˜ì„± ë¬¸ì œë¡œ ì¸í•´ ì¡°ê±´ë¶€ import
            import pydantic
            pydantic_version = pydantic.version.VERSION
            
            if pydantic_version.startswith('2.'):
                # Pydantic V2ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²½ìš°ì—ë§Œ import ì‹œë„
                from app.api.websocket_routes import router as websocket_router
                routers['websocket'] = websocket_router
                logger.info("âœ… WebSocket ë¼ìš°í„° import ì„±ê³µ")
            else:
                logger.warning("âš ï¸ Pydantic V1 ê°ì§€ - WebSocket ë¼ìš°í„° ë¹„í™œì„±í™”")
                routers['websocket'] = None
                
        except ImportError as e:
            logger.warning(f"âš ï¸ WebSocket ë¼ìš°í„° import ì‹¤íŒ¨: {e}")
            routers['websocket'] = None
        except Exception as e:
            logger.warning(f"âš ï¸ WebSocket ë¼ìš°í„° ì˜¤ë¥˜: {e}")
            routers['websocket'] = None
        
        self.components['routers'] = routers
        return routers
    
    def initialize_all_components(self):
        """ëª¨ë“  ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”"""
        logger.info("ğŸ”„ AI íŒŒì´í”„ë¼ì¸ ë¡œë”© ì‹œë„...")
        
        # AI íŒŒì´í”„ë¼ì¸ ë””ë ‰í† ë¦¬ í™•ì¸
        ai_pipeline_dir = current_dir / "ai_pipeline"
        if ai_pipeline_dir.exists():
            logger.info(f"âœ… AI íŒŒì´í”„ë¼ì¸ ë””ë ‰í† ë¦¬ ë°œê²¬: {ai_pipeline_dir}")
            
            # Step íŒŒì¼ë“¤ í™•ì¸
            steps_dir = ai_pipeline_dir / "steps"
            if steps_dir.exists():
                step_files = list(steps_dir.glob("step_*.py"))
                logger.info(f"ğŸ“Š Step íŒŒì¼ë“¤ ë°œê²¬: {len(step_files)}ê°œ")
        
        # í•„ìš”í•œ ë””ë ‰í† ë¦¬ ìƒì„±
        directories_to_create = [
            project_root / "logs",
            project_root / "static" / "uploads",
            project_root / "static" / "results",
            project_root / "temp",
            current_dir / "ai_pipeline" / "cache",
            current_dir / "ai_pipeline" / "models" / "checkpoints"
        ]
        
        created_count = 0
        for directory in directories_to_create:
            if not directory.exists():
                directory.mkdir(parents=True, exist_ok=True)
                created_count += 1
        
        if created_count > 0:
            print(f"âœ… í•„ìš”í•œ ë””ë ‰í† ë¦¬ ìƒì„± ì™„ë£Œ: {created_count}ê°œ")
        
        # ì»´í¬ë„ŒíŠ¸ë³„ import
        success_count = 0
        
        if self.safe_import_gpu_config():
            success_count += 1
        
        if self.safe_import_memory_manager():
            success_count += 1
        
        if self.safe_import_m3_optimizer():
            success_count += 1
        
        if self.safe_import_pipeline_manager():
            success_count += 1
        
        self.safe_import_api_routers()
        
        logger.info(f"ğŸ“Š ì»´í¬ë„ŒíŠ¸ import ì™„ë£Œ: {success_count}/4 ì„±ê³µ")
        
        if self.import_errors:
            logger.warning("âš ï¸ Import ì˜¤ë¥˜ ëª©ë¡:")
            for error in self.import_errors:
                logger.warning(f"  - {error}")
        
        return success_count >= 2  # ìµœì†Œ ì ˆë°˜ ì´ìƒ ì„±ê³µ

# ì»´í¬ë„ŒíŠ¸ importer ì´ˆê¸°í™”
importer = ComponentImporter()
import_success = importer.initialize_all_components()

# ì»´í¬ë„ŒíŠ¸ ì°¸ì¡° ì„¤ì •
gpu_config = importer.components['gpu_config']
memory_manager = importer.components['memory_manager']
m3_optimizer = importer.components['m3_optimizer']
pipeline_manager_info = importer.components['pipeline_manager']
api_routers = importer.components['routers']

# ì „ì—­ ë³€ìˆ˜ë“¤
pipeline_manager = None
app_state = {
    "initialized": False,
    "startup_time": None,
    "import_success": import_success,
    "fallback_mode": importer.fallback_mode,
    "device": gpu_config['device'],
    "pipeline_mode": "simulation",
    "total_sessions": 0,
    "successful_sessions": 0,
    "errors": importer.import_errors.copy(),
    "performance_metrics": {
        "average_response_time": 0.0,
        "total_requests": 0,
        "error_rate": 0.0
    }
}

# ============================================
# Pydantic ëª¨ë¸ë“¤
# ============================================

class SystemStatus(BaseModel):
    """ì‹œìŠ¤í…œ ìƒíƒœ ëª¨ë¸"""
    status: str
    initialized: bool
    device: str
    pipeline_mode: str
    fallback_mode: bool
    import_success: bool
    errors: List[str]

class VirtualTryOnRequest(BaseModel):
    """ê°€ìƒ í”¼íŒ… ìš”ì²­ ëª¨ë¸"""
    person_image_url: Optional[str] = None
    clothing_image_url: Optional[str] = None
    clothing_type: str = "shirt"
    fabric_type: str = "cotton"
    quality_target: float = 0.8

class PerformanceMetrics(BaseModel):
    """ì„±ëŠ¥ ë©”íŠ¸ë¦­ ëª¨ë¸"""
    total_requests: int
    successful_requests: int
    average_response_time: float
    error_rate: float
    uptime_seconds: float

# ============================================
# ë¯¸ë“¤ì›¨ì–´ ë° ì˜ˆì™¸ ì²˜ë¦¬
# ============================================

async def add_process_time_header(request: Request, call_next):
    """ìš”ì²­ ì²˜ë¦¬ ì‹œê°„ ì¶”ê°€ ë¯¸ë“¤ì›¨ì–´"""
    start_time = time.time()
    response = await call_next(request)
    process_time = time.time() - start_time
    
    response.headers["X-Process-Time"] = str(round(process_time, 4))
    
    # ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
    app_state["performance_metrics"]["total_requests"] += 1
    current_avg = app_state["performance_metrics"]["average_response_time"]
    total_requests = app_state["performance_metrics"]["total_requests"]
    
    # ì´ë™ í‰ê·  ê³„ì‚°
    app_state["performance_metrics"]["average_response_time"] = (
        (current_avg * (total_requests - 1) + process_time) / total_requests
    )
    
    return response

# ============================================
# ì• í”Œë¦¬ì¼€ì´ì…˜ ë¼ì´í”„ì‚¬ì´í´
# ============================================

@asynccontextmanager
async def lifespan(app: FastAPI):
    """ì• í”Œë¦¬ì¼€ì´ì…˜ ë¼ì´í”„ì‚¬ì´í´ ê´€ë¦¬"""
    global pipeline_manager, app_state
    
    # ==========================================
    # ì‹œì‘ ë¡œì§
    # ==========================================
    logger.info("ğŸš€ MyCloset AI Backend ì‹œì‘...")
    startup_start = time.time()
    
    try:
        # íŒŒì´í”„ë¼ì¸ ë§¤ë‹ˆì € ì´ˆê¸°í™”
        PipelineManagerClass = pipeline_manager_info['class']
        
        if PipelineManagerClass:
            logger.info("ğŸ­ ì‹œë®¬ë ˆì´ì…˜ íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” ì¤‘...")
            
            # ë””ë°”ì´ìŠ¤ ì„¤ì •
            device = gpu_config['device']
            
            # íŒŒì´í”„ë¼ì¸ ë§¤ë‹ˆì € ìƒì„±
            if importer.fallback_mode:
                logger.info("ğŸ­ ì‹œë®¬ë ˆì´ì…˜ íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™”...")
                pipeline_manager = PipelineManagerClass(mode="simulation", device=device)
            else:
                logger.info("ğŸ¤– ì‹¤ì œ íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” ì‹œë„...")
                pipeline_manager = PipelineManagerClass(mode="simulation", device=device)
            
            # ì´ˆê¸°í™” ì‹œë„
            initialization_success = await pipeline_manager.initialize()
            
            if initialization_success:
                app_state["initialized"] = True
                app_state["pipeline_mode"] = getattr(pipeline_manager, 'mode', 'simulation')
                logger.info("âœ… íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” ì™„ë£Œ")
            else:
                logger.warning("âš ï¸ íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” ë¶€ë¶„ ì‹¤íŒ¨")
                app_state["errors"].append("Pipeline initialization partially failed")
        
        else:
            logger.error("âŒ íŒŒì´í”„ë¼ì¸ ë§¤ë‹ˆì € í´ë˜ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
            app_state["errors"].append("Pipeline manager class not found")
        
        app_state["startup_time"] = time.time() - startup_start
        
        # ì‹œìŠ¤í…œ ìƒíƒœ ë¡œê¹…
        logger.info("=" * 60)
        logger.info("ğŸ¥ MyCloset AI Backend ì‹œìŠ¤í…œ ìƒíƒœ")
        logger.info("=" * 60)
        logger.info(f"ğŸ”§ ë””ë°”ì´ìŠ¤: {app_state['device']}")
        logger.info(f"ğŸ­ íŒŒì´í”„ë¼ì¸ ëª¨ë“œ: {app_state['pipeline_mode']}")
        logger.info(f"âœ… ì´ˆê¸°í™” ì„±ê³µ: {app_state['initialized']}")
        logger.info(f"ğŸš¨ í´ë°± ëª¨ë“œ: {app_state['fallback_mode']}")
        logger.info(f"â±ï¸ ì‹œì‘ ì‹œê°„: {app_state['startup_time']:.2f}ì´ˆ")
        
        if app_state['errors']:
            logger.warning(f"âš ï¸ ì˜¤ë¥˜ ëª©ë¡ ({len(app_state['errors'])}ê°œ):")
            for error in app_state['errors']:
                logger.warning(f"  - {error}")
        
        logger.info("âœ… ë°±ì—”ë“œ ì´ˆê¸°í™” ì™„ë£Œ")
        logger.info("=" * 60)
        
    except Exception as e:
        error_msg = f"Startup error: {str(e)}"
        logger.error(f"âŒ ì‹œì‘ ì¤‘ ì¹˜ëª…ì  ì˜¤ë¥˜: {error_msg}")
        logger.error(f"ğŸ“‹ ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤: {traceback.format_exc()}")
        app_state["errors"].append(error_msg)
        app_state["initialized"] = False
    
    yield  # ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹¤í–‰
    
    # ==========================================
    # ì¢…ë£Œ ë¡œì§
    # ==========================================
    logger.info("ğŸ›‘ MyCloset AI Backend ì¢…ë£Œ ì¤‘...")
    
    try:
        if pipeline_manager and hasattr(pipeline_manager, 'cleanup'):
            await pipeline_manager.cleanup()
            logger.info("âœ… íŒŒì´í”„ë¼ì¸ ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì™„ë£Œ")
        
        # ë©”ëª¨ë¦¬ ì •ë¦¬
        if memory_manager['optimize']:
            result = memory_manager['optimize'](aggressive=True)
            if result.get('success'):
                logger.info("âœ… ë©”ëª¨ë¦¬ ì •ë¦¬ ì™„ë£Œ")
        
        logger.info("âœ… ì •ë¦¬ ì™„ë£Œ")
        
    except Exception as e:
        logger.warning(f"âš ï¸ ì •ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")

# ============================================
# FastAPI ì• í”Œë¦¬ì¼€ì´ì…˜ ìƒì„±
# ============================================

app = FastAPI(
    title="MyCloset AI Backend",
    description="M3 Max ìµœì í™” ê°€ìƒ í”¼íŒ… AI ë°±ì—”ë“œ ì„œë¹„ìŠ¤",
    version="3.0.0",
    lifespan=lifespan,
    docs_url="/docs",
    redoc_url="/redoc",
    openapi_url="/openapi.json"
)

# ============================================
# ë¯¸ë“¤ì›¨ì–´ ì„¤ì •
# ============================================

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # í”„ë¡œë•ì…˜ì—ì„œëŠ” íŠ¹ì • ë„ë©”ì¸ìœ¼ë¡œ ì œí•œ
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ì„±ëŠ¥ ì¸¡ì • ë¯¸ë“¤ì›¨ì–´
app.middleware("http")(add_process_time_header)

# ============================================
# ì˜ˆì™¸ ì²˜ë¦¬
# ============================================

@app.exception_handler(StarletteHTTPException)
async def http_exception_handler(request: Request, exc: StarletteHTTPException):
    """HTTP ì˜ˆì™¸ ì²˜ë¦¬"""
    app_state["performance_metrics"]["total_requests"] += 1
    
    error_response = {
        "success": False,
        "error": {
            "type": "http_error",
            "status_code": exc.status_code,
            "message": exc.detail,
            "timestamp": datetime.now().isoformat()
        },
        "request_info": {
            "method": request.method,
            "url": str(request.url),
            "client": request.client.host if request.client else "unknown"
        }
    }
    
    logger.warning(f"HTTP ì˜ˆì™¸: {exc.status_code} - {exc.detail} - {request.url}")
    
    return JSONResponse(
        status_code=exc.status_code,
        content=error_response
    )

@app.exception_handler(RequestValidationError)
async def validation_exception_handler(request: Request, exc: RequestValidationError):
    """ìš”ì²­ ê²€ì¦ ì˜ˆì™¸ ì²˜ë¦¬"""
    app_state["performance_metrics"]["total_requests"] += 1
    
    error_response = {
        "success": False,
        "error": {
            "type": "validation_error",
            "message": "Request validation failed",
            "details": exc.errors(),
            "timestamp": datetime.now().isoformat()
        }
    }
    
    logger.warning(f"ê²€ì¦ ì˜¤ë¥˜: {exc.errors()} - {request.url}")
    
    return JSONResponse(
        status_code=422,
        content=error_response
    )

@app.exception_handler(Exception)
async def general_exception_handler(request: Request, exc: Exception):
    """ì¼ë°˜ ì˜ˆì™¸ ì²˜ë¦¬"""
    app_state["performance_metrics"]["total_requests"] += 1
    
    error_msg = str(exc)
    error_type = type(exc).__name__
    
    error_response = {
        "success": False,
        "error": {
            "type": error_type,
            "message": error_msg,
            "timestamp": datetime.now().isoformat()
        }
    }
    
    logger.error(f"ì¼ë°˜ ì˜ˆì™¸: {error_type} - {error_msg} - {request.url}")
    logger.error(f"ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤: {traceback.format_exc()}")
    
    return JSONResponse(
        status_code=500,
        content=error_response
    )

# ============================================
# API ë¼ìš°í„° ë“±ë¡
# ============================================

# Health router
if api_routers.get('health'):
    app.include_router(api_routers['health'], prefix="/health", tags=["health"])
    logger.info("âœ… Health ë¼ìš°í„° ë“±ë¡ë¨")

# Virtual try-on router
if api_routers.get('virtual_tryon'):
    app.include_router(api_routers['virtual_tryon'], prefix="/api", tags=["virtual-tryon"])
    logger.info("âœ… Virtual Try-on ë¼ìš°í„° ë“±ë¡ë¨")

# Models router
if api_routers.get('models'):
    app.include_router(api_routers['models'], prefix="/api", tags=["models"])
    logger.info("âœ… Models ë¼ìš°í„° ë“±ë¡ë¨")

# Pipeline router
if api_routers.get('pipeline'):
    app.include_router(api_routers['pipeline'], prefix="/api/pipeline", tags=["pipeline"])
    logger.info("âœ… Pipeline ë¼ìš°í„° ë“±ë¡ë¨")

# WebSocket router
if api_routers.get('websocket'):
    app.include_router(api_routers['websocket'], prefix="/api/ws", tags=["websocket"])
    logger.info("âœ… WebSocket ë¼ìš°í„° ë“±ë¡ë¨")

# ============================================
# ì •ì  íŒŒì¼ ì„œë¹™
# ============================================

# ì •ì  íŒŒì¼ ë””ë ‰í† ë¦¬ ì„¤ì •
static_dir = project_root / "static"
if static_dir.exists():
    app.mount("/static", StaticFiles(directory=str(static_dir)), name="static")
    logger.info("âœ… ì •ì  íŒŒì¼ ì„œë¹™ ì„¤ì •ë¨")

# ============================================
# í•µì‹¬ API ì—”ë“œí¬ì¸íŠ¸ë“¤
# ============================================

@app.get("/", response_class=HTMLResponse)
async def root():
    """ë£¨íŠ¸ ì—”ë“œí¬ì¸íŠ¸ - HTML ëŒ€ì‹œë³´ë“œ"""
    device_emoji = "ğŸ" if gpu_config['device'] == "mps" else "ğŸ–¥ï¸" if gpu_config['device'] == "cuda" else "ğŸ’»"
    status_emoji = "âœ…" if app_state["initialized"] else "âš ï¸"
    
    html_content = f"""
    <!DOCTYPE html>
    <html>
    <head>
        <title>MyCloset AI Backend</title>
        <meta charset="utf-8">
        <style>
            body {{ font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Arial, sans-serif; margin: 40px; background: #f5f5f5; }}
            .container {{ max-width: 800px; margin: 0 auto; background: white; padding: 30px; border-radius: 10px; box-shadow: 0 2px 10px rgba(0,0,0,0.1); }}
            h1 {{ color: #333; border-bottom: 2px solid #007acc; padding-bottom: 10px; }}
            .status {{ padding: 15px; border-radius: 5px; margin: 15px 0; }}
            .status.success {{ background: #d4edda; border: 1px solid #c3e6cb; color: #155724; }}
            .status.warning {{ background: #fff3cd; border: 1px solid #ffeaa7; color: #856404; }}
            .status.error {{ background: #f8d7da; border: 1px solid #f5c6cb; color: #721c24; }}
            .metrics {{ display: grid; grid-template-columns: repeat(auto-fit, minmax(200px, 1fr)); gap: 15px; margin: 20px 0; }}
            .metric {{ background: #f8f9fa; padding: 15px; border-radius: 5px; text-align: center; }}
            .metric h3 {{ margin: 0; color: #666; font-size: 0.9em; }}
            .metric p {{ margin: 5px 0 0 0; font-size: 1.4em; font-weight: bold; color: #333; }}
            .links {{ margin-top: 30px; }}
            .links a {{ display: inline-block; margin: 5px 10px 5px 0; padding: 10px 15px; background: #007acc; color: white; text-decoration: none; border-radius: 5px; }}
            .links a:hover {{ background: #005a9e; }}
        </style>
    </head>
    <body>
        <div class="container">
            <h1>{device_emoji} MyCloset AI Backend v3.0</h1>
            
            <div class="status {'success' if app_state['initialized'] else 'warning'}">
                <strong>{status_emoji} ì‹œìŠ¤í…œ ìƒíƒœ:</strong> 
                {'ì •ìƒ ìš´ì˜ ì¤‘' if app_state['initialized'] else 'ì´ˆê¸°í™” ì¤‘ ë˜ëŠ” ì œí•œì  ìš´ì˜'}
            </div>
            
            <div class="metrics">
                <div class="metric">
                    <h3>ë””ë°”ì´ìŠ¤</h3>
                    <p>{gpu_config['device'].upper()}</p>
                </div>
                <div class="metric">
                    <h3>íŒŒì´í”„ë¼ì¸ ëª¨ë“œ</h3>
                    <p>{app_state['pipeline_mode']}</p>
                </div>
                <div class="metric">
                    <h3>ì´ ìš”ì²­ ìˆ˜</h3>
                    <p>{app_state['performance_metrics']['total_requests']}</p>
                </div>
                <div class="metric">
                    <h3>í‰ê·  ì‘ë‹µ ì‹œê°„</h3>
                    <p>{app_state['performance_metrics']['average_response_time']:.3f}s</p>
                </div>
                <div class="metric">
                    <h3>ê°€ë™ ì‹œê°„</h3>
                    <p>{(time.time() - (app_state['startup_time'] or time.time())):.0f}s</p>
                </div>
                <div class="metric">
                    <h3>Import ì„±ê³µ</h3>
                    <p>{'âœ…' if app_state['import_success'] else 'âš ï¸'}</p>
                </div>
            </div>
            
            {f'<div class="status error"><strong>âš ï¸ ì˜¤ë¥˜:</strong><br>{"<br>".join(app_state["errors"][:3])}</div>' if app_state['errors'] else ''}
            
            <div class="links">
                <a href="/docs">ğŸ“š API ë¬¸ì„œ</a>
                <a href="/status">ğŸ“Š ìƒì„¸ ìƒíƒœ</a>
                <a href="/health">ğŸ’Š í—¬ìŠ¤ì²´í¬</a>
                <a href="/api/system/performance">ğŸ“ˆ ì„±ëŠ¥ ë©”íŠ¸ë¦­</a>
            </div>
        </div>
    </body>
    </html>
    """
    
    return HTMLResponse(content=html_content)

@app.get("/status", response_model=Dict[str, Any])
async def get_detailed_status():
    """ìƒì„¸ ì‹œìŠ¤í…œ ìƒíƒœ ì¡°íšŒ"""
    memory_status = memory_manager['check']()
    
    # íŒŒì´í”„ë¼ì¸ ìƒíƒœ
    pipeline_status = {}
    if pipeline_manager and hasattr(pipeline_manager, 'get_status'):
        try:
            pipeline_status = pipeline_manager.get_status()
        except Exception as e:
            pipeline_status = {"error": str(e)}
    
    # ë””ë°”ì´ìŠ¤ ì •ë³´
    device_info = gpu_config['device_info'].copy()
    
    # M3 ìµœì í™” ìƒíƒœ
    m3_status = {}
    if m3_optimizer['get_optimizer']:
        try:
            optimizer = m3_optimizer['get_optimizer']()
            m3_status = {
                "is_m3_max": getattr(optimizer, 'is_m3_max', False),
                "device": getattr(optimizer, 'device', 'unknown'),
                "optimized": m3_optimizer['is_optimized']()
            }
        except Exception as e:
            m3_status = {"error": str(e)}
    
    uptime = time.time() - (app_state['startup_time'] or time.time())
    
    return {
        "application": {
            "name": "MyCloset AI Backend",
            "version": "3.0.0",
            "initialized": app_state["initialized"],
            "fallback_mode": app_state["fallback_mode"],
            "import_success": app_state["import_success"],
            "uptime_seconds": uptime,
            "startup_time": app_state["startup_time"],
            "errors": app_state["errors"]
        },
        "system": {
            "device": gpu_config["device"],
            "device_info": device_info,
            "memory_status": memory_status,
            "m3_optimization": m3_status
        },
        "pipeline": {
            "mode": app_state["pipeline_mode"],
            "status": pipeline_status,
            "available": pipeline_manager is not None
        },
        "performance": app_state["performance_metrics"],
        "component_status": {
            "gpu_config": gpu_config['instance'] is not None,
            "memory_manager": memory_manager['class'] is not None,
            "m3_optimizer": m3_optimizer['class'] is not None,
            "pipeline_manager": pipeline_manager_info['class'] is not None
        },
        "api_routers": {
            name: router is not None 
            for name, router in api_routers.items()
        }
    }

@app.get("/health")
async def health_check():
    """ê°„ë‹¨í•œ í—¬ìŠ¤ì²´í¬"""
    return {
        "status": "healthy" if app_state["initialized"] else "degraded",
        "timestamp": datetime.now().isoformat(),
        "version": "3.0.0",
        "device": gpu_config["device"],
        "uptime": time.time() - (app_state["startup_time"] or time.time())
    }

# ============================================
# ì‹œìŠ¤í…œ ê´€ë¦¬ ì—”ë“œí¬ì¸íŠ¸ë“¤
# ============================================

@app.post("/api/system/optimize-memory")
async def optimize_memory_endpoint():
    """ë©”ëª¨ë¦¬ ìµœì í™” ì—”ë“œí¬ì¸íŠ¸"""
    try:
        start_time = time.time()
        result = memory_manager['optimize'](device=gpu_config['device'], aggressive=False)
        processing_time = time.time() - start_time
        
        return {
            "success": True,
            "optimization_result": result,
            "processing_time": processing_time,
            "timestamp": datetime.now().isoformat()
        }
    except Exception as e:
        logger.error(f"ë©”ëª¨ë¦¬ ìµœì í™” API ì˜¤ë¥˜: {e}")
        return {
            "success": False,
            "error": str(e),
            "timestamp": datetime.now().isoformat()
        }

@app.get("/api/system/performance")
async def get_performance_metrics():
    """ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì¡°íšŒ"""
    uptime = time.time() - (app_state["startup_time"] or time.time())
    
    return PerformanceMetrics(
        total_requests=app_state["performance_metrics"]["total_requests"],
        successful_requests=app_state["successful_sessions"],
        average_response_time=app_state["performance_metrics"]["average_response_time"],
        error_rate=app_state["performance_metrics"]["error_rate"],
        uptime_seconds=uptime
    )

@app.post("/api/system/restart-pipeline")
async def restart_pipeline():
    """íŒŒì´í”„ë¼ì¸ ì¬ì‹œì‘"""
    global pipeline_manager
    
    try:
        if pipeline_manager and hasattr(pipeline_manager, 'cleanup'):
            await pipeline_manager.cleanup()
        
        PipelineManagerClass = pipeline_manager_info['class']
        if PipelineManagerClass:
            pipeline_manager = PipelineManagerClass(
                mode="simulation", 
                device=gpu_config['device']
            )
            success = await pipeline_manager.initialize()
            
            if success:
                app_state["initialized"] = True
                return {
                    "success": True,
                    "message": "íŒŒì´í”„ë¼ì¸ ì¬ì‹œì‘ ì™„ë£Œ",
                    "timestamp": datetime.now().isoformat()
                }
            else:
                return {
                    "success": False,
                    "message": "íŒŒì´í”„ë¼ì¸ ì¬ì‹œì‘ ì‹¤íŒ¨",
                    "timestamp": datetime.now().isoformat()
                }
        else:
            return {
                "success": False,
                "message": "íŒŒì´í”„ë¼ì¸ ë§¤ë‹ˆì € í´ë˜ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ",
                "timestamp": datetime.now().isoformat()
            }
    
    except Exception as e:
        logger.error(f"íŒŒì´í”„ë¼ì¸ ì¬ì‹œì‘ ì˜¤ë¥˜: {e}")
        return {
            "success": False,
            "error": str(e),
            "timestamp": datetime.now().isoformat()
        }

@app.get("/api/system/logs")
async def get_recent_logs(lines: int = 50):
    """ìµœê·¼ ë¡œê·¸ ì¡°íšŒ"""
    try:
        log_file = project_root / "logs" / f"mycloset-ai-{datetime.now().strftime('%Y%m%d')}.log"
        
        if not log_file.exists():
            return {
                "success": False,
                "message": "ë¡œê·¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ"
            }
        
        with open(log_file, 'r', encoding='utf-8') as f:
            all_lines = f.readlines()
            recent_lines = all_lines[-lines:] if len(all_lines) > lines else all_lines
        
        return {
            "success": True,
            "logs": [line.strip() for line in recent_lines],
            "total_lines": len(all_lines),
            "returned_lines": len(recent_lines),
            "timestamp": datetime.now().isoformat()
        }
    
    except Exception as e:
        logger.error(f"ë¡œê·¸ ì¡°íšŒ ì˜¤ë¥˜: {e}")
        return {
            "success": False,
            "error": str(e),
            "timestamp": datetime.now().isoformat()
        }

# ============================================
# ë©”ì¸ ì‹¤í–‰ë¶€
# ============================================

if __name__ == "__main__":
    import uvicorn
    
    logger.info("ğŸ M3 Max ìµœì í™”ëœ MyCloset AI Backend v3.0.0 ì‹œì‘...")
    logger.info(f"ğŸ¤– AI íŒŒì´í”„ë¼ì¸: {'ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œ' if importer.fallback_mode else 'ì‹¤ì œ ëª¨ë“œ'}")
    logger.info(f"ğŸ”§ ë””ë°”ì´ìŠ¤: {gpu_config['device']}")
    logger.info(f"ğŸ“Š Import ì„±ê³µ: {import_success}")
    
    # í™˜ê²½ë³„ ì„¤ì •
    if os.getenv("ENVIRONMENT") == "production":
        # í”„ë¡œë•ì…˜ ì„¤ì •
        uvicorn.run(
            "app.main:app",
            host="0.0.0.0",
            port=8000,
            reload=False,
            workers=1,  # M3 Max í™˜ê²½ì—ì„œëŠ” ë‹¨ì¼ ì›Œì»¤ ê¶Œì¥
            log_level="info",
            access_log=True
        )
    else:
        # ê°œë°œ ì„¤ì •
        uvicorn.run(
            "app.main:app",
            host="0.0.0.0",
            port=8000,
            reload=False,  # import ë¬¸ì œë¡œ ì¸í•´ reload ë¹„í™œì„±í™”
            log_level="info",
            access_log=True
        )

# ============================================
# ì‹œì‘ ì‹œ ìë™ ì‹¤í–‰ ì½”ë“œ
# ============================================

# ì‹œì‘ ì‹œ ë©”ëª¨ë¦¬ ìƒíƒœ ë¡œê¹…
if memory_manager['check']:
    try:
        memory_status = memory_manager['check']()
        logger.info(f"ğŸ’¾ ì´ˆê¸° ë©”ëª¨ë¦¬ ìƒíƒœ: {memory_status['status']}")
    except Exception as e:
        logger.warning(f"ë©”ëª¨ë¦¬ ìƒíƒœ í™•ì¸ ì‹¤íŒ¨: {e}")

# M3 Max ìµœì í™” ìƒíƒœ ë¡œê¹…
if m3_optimizer['is_optimized']:
    try:
        is_optimized = m3_optimizer['is_optimized']()
        logger.info(f"ğŸ M3 Max ìµœì í™”: {'âœ… í™œì„±í™”ë¨' if is_optimized else 'âŒ ë¹„í™œì„±í™”ë¨'}")
    except Exception as e:
        logger.warning(f"M3 ìµœì í™” ìƒíƒœ í™•ì¸ ì‹¤íŒ¨: {e}")

logger.info("ğŸš€ MyCloset AI Backend ë©”ì¸ ëª¨ë“ˆ ë¡œë“œ ì™„ë£Œ")