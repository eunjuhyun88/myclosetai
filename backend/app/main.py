# backend/app/main.py
"""
ğŸ”¥ MyCloset AI FastAPI ë©”ì¸ ì„œë²„ - ì™„ì „ ìµœì í™” ëª¨ë“ˆì‹ êµ¬ì¡° v18.0
================================================================================

âœ… ê¸°ì¡´ ëª¨ë“ˆì‹ êµ¬ì¡° 100% í™œìš©
âœ… ì‹¤ì œ AI íŒŒì´í”„ë¼ì¸ ì™„ì „ ì—°ë™  
âœ… DI Container ê¸°ë°˜ ì˜ì¡´ì„± ê´€ë¦¬
âœ… conda í™˜ê²½ + M3 Max 128GB ìµœì í™”
âœ… React/TypeScript í”„ë¡ íŠ¸ì—”ë“œ 100% í˜¸í™˜
âœ… WebSocket ì‹¤ì‹œê°„ AI ì§„í–‰ë¥  ì¶”ì 
âœ… 8ë‹¨ê³„ ì‹¤ì œ AI íŒŒì´í”„ë¼ì¸ (Mock ì œê±°)
âœ… í”„ë¡œë•ì…˜ ë ˆë²¨ ì•ˆì •ì„± + ì—ëŸ¬ ì²˜ë¦¬
âœ… ì™„ì „í•œ ì˜¤ë¥˜ í•´ê²° ë³´ì¥

ğŸ”¥ ëª¨ë“ˆì‹ ì•„í‚¤í…ì²˜:
- API Layer: pipeline_routes.py, step_routes.py, health.py
- Service Layer: pipeline_service.py, step_service.py
- Core Layer: config.py, gpu_config.py, di_container.py
- AI Pipeline: 8ë‹¨ê³„ ì‹¤ì œ AI Steps ì™„ì „ ì—°ë™
- Utils Layer: í†µí•© ìœ í‹¸ë¦¬í‹° ë° í—¬í¼ í•¨ìˆ˜ë“¤

Author: MyCloset AI Team
Date: 2025-07-23
Version: 18.0.0 (Complete Modular Architecture)
"""

import os
import sys
import logging
import asyncio
import time
import gc
import uuid
import threading
import traceback
import subprocess
import platform
import psutil
from pathlib import Path
from datetime import datetime, timedelta
from contextlib import asynccontextmanager
from typing import Dict, Any, Optional, List, Union, Callable
import warnings

# ê²½ê³  ë¬´ì‹œ
warnings.filterwarnings('ignore')
os.environ['PYTHONWARNINGS'] = 'ignore'
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'

# =============================================================================
# ğŸ”¥ 1. ì‹¤í–‰ ê²½ë¡œ ìë™ ìˆ˜ì • (í”„ë¡ íŠ¸ì—”ë“œ í˜¸í™˜)
# =============================================================================

def fix_python_path():
    """ì‹¤í–‰ ê²½ë¡œì— ê´€ê³„ì—†ì´ Python Path ìë™ ìˆ˜ì •"""
    current_file = Path(__file__).absolute()
    app_dir = current_file.parent       # backend/app
    backend_dir = app_dir.parent        # backend
    project_root = backend_dir.parent   # mycloset-ai
    
    # Python Pathì— í•„ìš”í•œ ê²½ë¡œë“¤ ì¶”ê°€
    paths_to_add = [
        str(backend_dir),    # backend/ (ê°€ì¥ ì¤‘ìš”!)
        str(app_dir),        # backend/app/
        str(project_root)    # mycloset-ai/
    ]
    
    for path in paths_to_add:
        if path not in sys.path:
            sys.path.insert(0, path)
    
    # í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
    os.environ.update({
        'PYTHONPATH': f"{backend_dir}:{os.environ.get('PYTHONPATH', '')}",
        'PROJECT_ROOT': str(project_root),
        'BACKEND_ROOT': str(backend_dir),
        'APP_ROOT': str(app_dir)
    })
    
    # ì‘ì—… ë””ë ‰í† ë¦¬ë¥¼ backendë¡œ ë³€ê²½
    if Path.cwd() != backend_dir:
        try:
            os.chdir(backend_dir)
        except OSError:
            pass
    
    return {
        'app_dir': str(app_dir),
        'backend_dir': str(backend_dir),
        'project_root': str(project_root)
    }

# Python Path ìˆ˜ì • ì‹¤í–‰
path_info = fix_python_path()

# =============================================================================
# ğŸ”¥ 2. ì‹œìŠ¤í…œ ì •ë³´ ê°ì§€ ë° ìµœì í™”
# =============================================================================

def detect_system_info():
    """ì‹œìŠ¤í…œ ì •ë³´ ì§ì ‘ ê°ì§€"""
    system_info = {
        'platform': platform.system(),
        'python_version': platform.python_version(),
        'cpu_count': os.cpu_count() or 4
    }
    
    # conda í™˜ê²½ ê°ì§€
    is_conda = (
        'CONDA_DEFAULT_ENV' in os.environ or
        'CONDA_PREFIX' in os.environ or
        'conda' in sys.executable.lower()
    )
    system_info['is_conda'] = is_conda
    system_info['conda_env'] = os.environ.get('CONDA_DEFAULT_ENV', 'none')
    
    # M3 Max ê°ì§€
    is_m3_max = False
    if platform.system() == 'Darwin':
        try:
            result = subprocess.run(
                ['sysctl', '-n', 'machdep.cpu.brand_string'], 
                capture_output=True, text=True, timeout=5
            )
            chip_info = result.stdout.strip()
            is_m3_max = 'M3' in chip_info and 'Max' in chip_info
        except:
            pass
    
    system_info['is_m3_max'] = is_m3_max
    
    # ë©”ëª¨ë¦¬ ì •ë³´
    try:
        system_info['memory_gb'] = round(psutil.virtual_memory().total / (1024**3), 1)
    except:
        system_info['memory_gb'] = 16.0
    
    return system_info

# ì‹œìŠ¤í…œ ì •ë³´ ê°ì§€
SYSTEM_INFO = detect_system_info()
IS_CONDA = SYSTEM_INFO['is_conda']
IS_M3_MAX = SYSTEM_INFO['is_m3_max']

print(f"ğŸ”§ ì‹œìŠ¤í…œ ì •ë³´:")
print(f"  ğŸ conda: {'âœ…' if IS_CONDA else 'âŒ'} ({SYSTEM_INFO['conda_env']})")
print(f"  ğŸ M3 Max: {'âœ…' if IS_M3_MAX else 'âŒ'}")
print(f"  ğŸ’¾ ë©”ëª¨ë¦¬: {SYSTEM_INFO['memory_gb']}GB")

# =============================================================================
# ğŸ”¥ 3. í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ import
# =============================================================================

try:
    from fastapi import FastAPI, Request, HTTPException, WebSocket, WebSocketDisconnect
    from fastapi.middleware.cors import CORSMiddleware
    from fastapi.middleware.gzip import GZipMiddleware
    from fastapi.responses import JSONResponse, FileResponse
    from fastapi.staticfiles import StaticFiles
    import uvicorn
    
    print("âœ… FastAPI ë¼ì´ë¸ŒëŸ¬ë¦¬ import ì„±ê³µ")
    
except ImportError as e:
    print(f"âŒ FastAPI ë¼ì´ë¸ŒëŸ¬ë¦¬ import ì‹¤íŒ¨: {e}")
    print("ì„¤ì¹˜ ëª…ë ¹: conda install fastapi uvicorn python-multipart websockets")
    sys.exit(1)

# PyTorch ì•ˆì „ import
TORCH_AVAILABLE = False
DEVICE = 'cpu'
try:
    os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '1'
    os.environ['PYTORCH_MPS_HIGH_WATERMARK_RATIO'] = '0.0'
    
    import torch
    TORCH_AVAILABLE = True
    
    # ë””ë°”ì´ìŠ¤ ê°ì§€
    if torch.backends.mps.is_available() and IS_M3_MAX:
        DEVICE = 'mps'
        print("âœ… PyTorch MPS (M3 Max) ì‚¬ìš©")
    elif torch.cuda.is_available():
        DEVICE = 'cuda'
        print("âœ… PyTorch CUDA ì‚¬ìš©")
    else:
        DEVICE = 'cpu'
        print("âœ… PyTorch CPU ì‚¬ìš©")
    
    print("âœ… PyTorch import ì„±ê³µ")
except ImportError:
    print("âš ï¸ PyTorch import ì‹¤íŒ¨")

# =============================================================================
# ğŸ”¥ 4. í•µì‹¬ ëª¨ë“ˆ import (ì•ˆì „í•œ í´ë°±)
# =============================================================================

# Core ì„¤ì • ëª¨ë“ˆ
CONFIG_AVAILABLE = False
try:
    from app.core.config import get_settings, Settings
    from app.core.gpu_config import GPUConfig
    CONFIG_AVAILABLE = True
    print("âœ… Core config ëª¨ë“ˆ import ì„±ê³µ")
except ImportError as e:
    print(f"âš ï¸ Core config ëª¨ë“ˆ import ì‹¤íŒ¨: {e}")
    
    # í´ë°± ì„¤ì •
    class Settings:
        APP_NAME = "MyCloset AI"
        DEBUG = True
        HOST = "0.0.0.0"
        PORT = 8000
        CORS_ORIGINS = [
            "http://localhost:3000",
            "http://127.0.0.1:3000",
            "http://localhost:5173",
            "http://127.0.0.1:5173"
        ]
        DEVICE = DEVICE
        USE_GPU = TORCH_AVAILABLE
        IS_M3_MAX = IS_M3_MAX
        IS_CONDA = IS_CONDA
    
    def get_settings():
        return Settings()
    
    class GPUConfig:
        def __init__(self):
            self.device = DEVICE
            self.memory_gb = SYSTEM_INFO['memory_gb']
            self.is_m3_max = IS_M3_MAX

# API ë¼ìš°í„°ë“¤ import
ROUTERS_AVAILABLE = {}

# Pipeline Routes
try:
    from app.api.pipeline_routes import router as pipeline_router
    ROUTERS_AVAILABLE['pipeline'] = pipeline_router
    print("âœ… Pipeline Router import ì„±ê³µ")
except ImportError as e:
    print(f"âš ï¸ Pipeline Router import ì‹¤íŒ¨: {e}")
    ROUTERS_AVAILABLE['pipeline'] = None

# Step Routes  
try:
    from app.api.step_routes import router as step_router
    ROUTERS_AVAILABLE['step'] = step_router
    print("âœ… Step Router import ì„±ê³µ")
except ImportError as e:
    print(f"âš ï¸ Step Router import ì‹¤íŒ¨: {e}")
    ROUTERS_AVAILABLE['step'] = None

# Health Routes
try:
    from app.api.health import router as health_router
    ROUTERS_AVAILABLE['health'] = health_router
    print("âœ… Health Router import ì„±ê³µ")
except ImportError as e:
    print(f"âš ï¸ Health Router import ì‹¤íŒ¨: {e}")
    ROUTERS_AVAILABLE['health'] = None

# Models Routes (ì„ íƒì )
try:
    from app.api.models import router as models_router
    ROUTERS_AVAILABLE['models'] = models_router
    print("âœ… Models Router import ì„±ê³µ")
except ImportError as e:
    print(f"âš ï¸ Models Router import ì‹¤íŒ¨: {e}")
    ROUTERS_AVAILABLE['models'] = None

# ì„œë¹„ìŠ¤ ë ˆì´ì–´ import
SERVICES_AVAILABLE = {}

# Pipeline Service
try:
    from app.services.pipeline_service import (
        get_pipeline_service_manager,
        cleanup_pipeline_service_manager
    )
    SERVICES_AVAILABLE['pipeline'] = True
    print("âœ… Pipeline Service import ì„±ê³µ")
except ImportError as e:
    print(f"âš ï¸ Pipeline Service import ì‹¤íŒ¨: {e}")
    SERVICES_AVAILABLE['pipeline'] = False

# Step Service
try:
    from app.services.step_service import (
        get_step_service_manager_async,
        cleanup_step_service_manager
    )
    SERVICES_AVAILABLE['step'] = True
    print("âœ… Step Service import ì„±ê³µ")
except ImportError as e:
    print(f"âš ï¸ Step Service import ì‹¤íŒ¨: {e}")
    SERVICES_AVAILABLE['step'] = False

# =============================================================================
# ğŸ”¥ 5. ë¡œê¹… ì„¤ì •
# =============================================================================

def setup_logging():
    """ì‹¤ì œ AI ìµœì í™” ë¡œê¹… ì„¤ì •"""
    logging.basicConfig(
        level=logging.INFO,
        format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
        handlers=[logging.StreamHandler(sys.stdout)]
    )
    return logging.getLogger(__name__)

logger = setup_logging()

# =============================================================================
# ğŸ”¥ 6. í´ë°± ë¼ìš°í„° ìƒì„± (ëˆ„ë½ëœ ë¼ìš°í„° ëŒ€ì²´)
# =============================================================================

def create_fallback_router(router_name: str):
    """í´ë°± ë¼ìš°í„° ìƒì„±"""
    from fastapi import APIRouter
    
    fallback_router = APIRouter(
        prefix=f"/api/{router_name}",
        tags=[router_name.title()],
        responses={503: {"description": "Service Unavailable"}}
    )
    
    @fallback_router.get("/status")
    async def fallback_status():
        return {
            "status": "fallback",
            "router": router_name,
            "message": f"{router_name} ë¼ìš°í„°ê°€ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤",
            "timestamp": datetime.now().isoformat()
        }
    
    return fallback_router

# ëˆ„ë½ëœ ë¼ìš°í„°ë“¤ì„ í´ë°±ìœ¼ë¡œ ëŒ€ì²´
for router_name, router in ROUTERS_AVAILABLE.items():
    if router is None:
        ROUTERS_AVAILABLE[router_name] = create_fallback_router(router_name)
        logger.warning(f"âš ï¸ {router_name} ë¼ìš°í„°ë¥¼ í´ë°±ìœ¼ë¡œ ëŒ€ì²´")

# =============================================================================
# ğŸ”¥ 7. WebSocket ë§¤ë‹ˆì € (í´ë°± í¬í•¨)
# =============================================================================

class WebSocketManager:
    """WebSocket ì—°ê²° ê´€ë¦¬ - ì‹¤ì‹œê°„ AI ì§„í–‰ë¥ """
    
    def __init__(self):
        self.active_connections: Dict[str, WebSocket] = {}
        self.lock = threading.RLock()
        
    async def connect(self, websocket: WebSocket, session_id: str):
        """WebSocket ì—°ê²°"""
        await websocket.accept()
        
        with self.lock:
            self.active_connections[session_id] = websocket
        
        logger.info(f"ğŸ”Œ WebSocket ì—°ê²°: {session_id}")
        
        # ì—°ê²° í™•ì¸ ë©”ì‹œì§€
        await self.send_message(session_id, {
            "type": "connection_established",
            "message": "MyCloset AI WebSocket ì—°ê²° ì™„ë£Œ",
            "timestamp": int(time.time()),
            "ai_pipeline_ready": True
        })
    
    def disconnect(self, session_id: str):
        """WebSocket ì—°ê²° í•´ì œ"""
        with self.lock:
            if session_id in self.active_connections:
                del self.active_connections[session_id]
                logger.info(f"ğŸ”Œ WebSocket ì—°ê²° í•´ì œ: {session_id}")
    
    async def send_message(self, session_id: str, message: Dict[str, Any]):
        """ë©”ì‹œì§€ ì „ì†¡"""
        with self.lock:
            if session_id in self.active_connections:
                try:
                    websocket = self.active_connections[session_id]
                    import json
                    await websocket.send_text(json.dumps(message))
                except Exception as e:
                    logger.warning(f"âš ï¸ WebSocket ë©”ì‹œì§€ ì „ì†¡ ì‹¤íŒ¨: {e}")
                    self.disconnect(session_id)

# ì „ì—­ WebSocket ë§¤ë‹ˆì €
websocket_manager = WebSocketManager()

# =============================================================================
# ğŸ”¥ 8. ì•± ë¼ì´í”„ìŠ¤íŒ¬ (ëª¨ë“ˆì‹ êµ¬ì¡° ìµœì í™”)
# =============================================================================

@asynccontextmanager
async def lifespan(app: FastAPI):
    """ì•± ë¼ì´í”„ìŠ¤íŒ¬ - ëª¨ë“ˆì‹ êµ¬ì¡° ìµœì í™”"""
    try:
        logger.info("ğŸš€ MyCloset AI ì„œë²„ ì‹œì‘ (ëª¨ë“ˆì‹ êµ¬ì¡° v18.0)")
        
        # ì„œë¹„ìŠ¤ ë§¤ë‹ˆì € ì´ˆê¸°í™”
        service_managers = {}
        
        # Pipeline Service ì´ˆê¸°í™”
        if SERVICES_AVAILABLE['pipeline']:
            try:
                pipeline_manager = await get_pipeline_service_manager()
                service_managers['pipeline'] = pipeline_manager
                logger.info("âœ… Pipeline Service Manager ì´ˆê¸°í™” ì™„ë£Œ")
            except Exception as e:
                logger.warning(f"âš ï¸ Pipeline Service Manager ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        
        # Step Service ì´ˆê¸°í™”
        if SERVICES_AVAILABLE['step']:
            try:
                step_manager = await get_step_service_manager_async()
                service_managers['step'] = step_manager
                logger.info("âœ… Step Service Manager ì´ˆê¸°í™” ì™„ë£Œ")
            except Exception as e:
                logger.warning(f"âš ï¸ Step Service Manager ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        
        # ì£¼ê¸°ì  ì‘ì—… ì‹œì‘
        cleanup_task = asyncio.create_task(periodic_cleanup())
        status_task = asyncio.create_task(periodic_status_broadcast())
        
        logger.info(f"âœ… {len(service_managers)}ê°œ ì„œë¹„ìŠ¤ ë§¤ë‹ˆì € ì´ˆê¸°í™” ì™„ë£Œ")
        
        yield  # ì•± ì‹¤í–‰
        
    except Exception as e:
        logger.error(f"âŒ ë¼ì´í”„ìŠ¤íŒ¬ ì‹œì‘ ì˜¤ë¥˜: {e}")
        yield
    finally:
        logger.info("ğŸ”š MyCloset AI ì„œë²„ ì¢…ë£Œ ì¤‘...")
        
        # ì •ë¦¬ ì‘ì—…
        try:
            cleanup_task.cancel()
            status_task.cancel()
            
            # ì„œë¹„ìŠ¤ ë§¤ë‹ˆì €ë“¤ ì •ë¦¬
            if SERVICES_AVAILABLE['pipeline']:
                await cleanup_pipeline_service_manager()
            
            if SERVICES_AVAILABLE['step']:
                await cleanup_step_service_manager()
            
            gc.collect()
            
            # M3 Max MPS ìºì‹œ ì •ë¦¬
            if IS_M3_MAX and TORCH_AVAILABLE:
                if hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
                    if hasattr(torch.mps, 'empty_cache'):
                        torch.mps.empty_cache()
            
            logger.info("âœ… ì •ë¦¬ ì‘ì—… ì™„ë£Œ")
            
        except Exception as e:
            logger.warning(f"âš ï¸ ì •ë¦¬ ì‘ì—… ì‹¤íŒ¨: {e}")

async def periodic_cleanup():
    """ì£¼ê¸°ì  ì •ë¦¬ ì‘ì—…"""
    while True:
        try:
            await asyncio.sleep(3600)  # 1ì‹œê°„ë§ˆë‹¤
            gc.collect()
            
            # M3 Max ë©”ëª¨ë¦¬ ì •ë¦¬
            if IS_M3_MAX and TORCH_AVAILABLE:
                if hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
                    if hasattr(torch.mps, 'empty_cache'):
                        torch.mps.empty_cache()
                        
            logger.info("ğŸ§¹ ì£¼ê¸°ì  ì •ë¦¬ ì‘ì—… ì™„ë£Œ")
        except asyncio.CancelledError:
            break
        except Exception as e:
            logger.error(f"âŒ ì£¼ê¸°ì  ì •ë¦¬ ì‹¤íŒ¨: {e}")

async def periodic_status_broadcast():
    """ì£¼ê¸°ì  ìƒíƒœ ë¸Œë¡œë“œìºìŠ¤íŠ¸"""
    while True:
        try:
            await asyncio.sleep(300)  # 5ë¶„ë§ˆë‹¤
            
            status_data = {
                "type": "system_status",
                "message": "ì‹œìŠ¤í…œ ìƒíƒœ ì—…ë°ì´íŠ¸",
                "timestamp": int(time.time()),
                "services_available": SERVICES_AVAILABLE,
                "routers_available": {k: v is not None for k, v in ROUTERS_AVAILABLE.items()},
                "device": DEVICE,
                "conda": IS_CONDA,
                "m3_max": IS_M3_MAX
            }
            
            # ëª¨ë“  ì—°ê²°ì— ë¸Œë¡œë“œìºìŠ¤íŠ¸
            for session_id in list(websocket_manager.active_connections.keys()):
                await websocket_manager.send_message(session_id, status_data)
                
        except asyncio.CancelledError:
            break
        except Exception as e:
            logger.error(f"âŒ ìƒíƒœ ë¸Œë¡œë“œìºìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")

# =============================================================================
# ğŸ”¥ 9. FastAPI ì•± ìƒì„± (ëª¨ë“ˆì‹ êµ¬ì¡° ì™„ì „ í™œìš©)
# =============================================================================

# ì„¤ì • ë¡œë“œ
settings = get_settings()

app = FastAPI(
    title="MyCloset AI Backend - Modular Architecture",
    description="ì™„ì „í•œ ëª¨ë“ˆì‹ êµ¬ì¡° + ì‹¤ì œ AI íŒŒì´í”„ë¼ì¸ + í”„ë¡ íŠ¸ì—”ë“œ ì™„ë²½ í˜¸í™˜",
    version="18.0.0",
    lifespan=lifespan,
    docs_url="/docs",
    redoc_url="/redoc"
)

# CORS ì„¤ì • (í”„ë¡ íŠ¸ì—”ë“œ ì™„ì „ í˜¸í™˜)
app.add_middleware(
    CORSMiddleware,
    allow_origins=settings.CORS_ORIGINS,
    allow_credentials=True,
    allow_methods=["GET", "POST", "PUT", "DELETE", "OPTIONS"],
    allow_headers=["*"],
    expose_headers=["*"]
)

# ì••ì¶• ë¯¸ë“¤ì›¨ì–´
app.add_middleware(GZipMiddleware, minimum_size=1000)

# ì •ì  íŒŒì¼ ì„¤ì •
try:
    static_dir = Path(path_info['backend_dir']) / "static"
    static_dir.mkdir(exist_ok=True)
    app.mount("/static", StaticFiles(directory=str(static_dir)), name="static")
    logger.info(f"âœ… ì •ì  íŒŒì¼ ì„¤ì •: {static_dir}")
except Exception as e:
    logger.warning(f"âš ï¸ ì •ì  íŒŒì¼ ì„¤ì • ì‹¤íŒ¨: {e}")

# =============================================================================
# ğŸ”¥ 10. ë¼ìš°í„° ë“±ë¡ (ëª¨ë“ˆì‹ êµ¬ì¡°)
# =============================================================================

# ë©”ì¸ ë¼ìš°í„°ë“¤ ë“±ë¡
if ROUTERS_AVAILABLE['pipeline']:
    app.include_router(ROUTERS_AVAILABLE['pipeline'], tags=["Pipeline"])
    logger.info("âœ… Pipeline Router ë“±ë¡")

if ROUTERS_AVAILABLE['step']:
    app.include_router(ROUTERS_AVAILABLE['step'], tags=["Steps"])
    logger.info("âœ… Step Router ë“±ë¡")

if ROUTERS_AVAILABLE['health']:
    app.include_router(ROUTERS_AVAILABLE['health'], tags=["Health"])
    logger.info("âœ… Health Router ë“±ë¡")

if ROUTERS_AVAILABLE['models']:
    app.include_router(ROUTERS_AVAILABLE['models'], tags=["Models"])
    logger.info("âœ… Models Router ë“±ë¡")

# =============================================================================
# ğŸ”¥ 11. ê¸°ë³¸ ì—”ë“œí¬ì¸íŠ¸ (í”„ë¡ íŠ¸ì—”ë“œ í˜¸í™˜)
# =============================================================================

@app.get("/")
async def root():
    """ë£¨íŠ¸ ì—”ë“œí¬ì¸íŠ¸ - ëª¨ë“ˆì‹ êµ¬ì¡° ì •ë³´"""
    return {
        "message": "MyCloset AI Server v18.0 - ì™„ì „í•œ ëª¨ë“ˆì‹ êµ¬ì¡° + ì‹¤ì œ AI íŒŒì´í”„ë¼ì¸",
        "status": "running",
        "version": "18.0.0",
        "architecture": "modular",
        "features": [
            "ëª¨ë“ˆì‹ API ë¼ìš°í„° êµ¬ì¡°",
            "DI Container ê¸°ë°˜ ì„œë¹„ìŠ¤ ë ˆì´ì–´",
            "8ë‹¨ê³„ ì‹¤ì œ AI íŒŒì´í”„ë¼ì¸",
            "WebSocket ì‹¤ì‹œê°„ í†µì‹ ",
            "conda í™˜ê²½ + M3 Max ìµœì í™”",
            "React/TypeScript ì™„ì „ í˜¸í™˜"
        ],
        "system": {
            "conda_environment": IS_CONDA,
            "conda_env": SYSTEM_INFO['conda_env'],
            "m3_max": IS_M3_MAX,
            "device": DEVICE,
            "memory_gb": SYSTEM_INFO['memory_gb']
        },
        "modules": {
            "routers_available": {k: v is not None for k, v in ROUTERS_AVAILABLE.items()},
            "services_available": SERVICES_AVAILABLE,
            "config_available": CONFIG_AVAILABLE,
            "torch_available": TORCH_AVAILABLE
        },
        "endpoints": {
            "docs": "/docs",
            "health": "/api/health/status",
            "pipeline": "/api/pipeline/complete",
            "steps": "/api/steps/process",
            "websocket": "/ws"
        }
    }

@app.get("/health")
async def health():
    """í—¬ìŠ¤ì²´í¬ - ëª¨ë“ˆì‹ êµ¬ì¡° ìƒíƒœ"""
    return {
        "status": "healthy",
        "timestamp": datetime.now().isoformat(),
        "version": "18.0.0",
        "architecture": "modular",
        "uptime": time.time(),
        "system": {
            "conda": IS_CONDA,
            "m3_max": IS_M3_MAX,
            "device": DEVICE,
            "memory_gb": SYSTEM_INFO['memory_gb']
        },
        "modules": {
            "total_routers": len(ROUTERS_AVAILABLE),
            "active_routers": sum(1 for v in ROUTERS_AVAILABLE.values() if v is not None),
            "total_services": len(SERVICES_AVAILABLE),
            "active_services": sum(1 for v in SERVICES_AVAILABLE.values() if v),
            "websocket_connections": len(websocket_manager.active_connections)
        }
    }

@app.get("/api/system/info")
async def get_system_info():
    """ì‹œìŠ¤í…œ ì •ë³´ - ì™„ì „í•œ ëª¨ë“ˆ ìƒíƒœ"""
    return {
        "app_name": settings.APP_NAME,
        "app_version": "18.0.0",
        "timestamp": int(time.time()),
        "conda_environment": IS_CONDA,
        "m3_max_optimized": IS_M3_MAX,
        "device": DEVICE,
        "memory_gb": SYSTEM_INFO['memory_gb'],
        "modular_architecture": True,
        "modules_status": {
            "routers": ROUTERS_AVAILABLE,
            "services": SERVICES_AVAILABLE,
            "config": CONFIG_AVAILABLE,
            "torch": TORCH_AVAILABLE
        }
    }

# =============================================================================
# ğŸ”¥ 12. WebSocket ì—”ë“œí¬ì¸íŠ¸
# =============================================================================

@app.websocket("/ws")
async def websocket_endpoint(websocket: WebSocket, session_id: str = None):
    """WebSocket ì—”ë“œí¬ì¸íŠ¸ - ì‹¤ì‹œê°„ í†µì‹ """
    if not session_id:
        session_id = f"ws_{int(time.time())}_{uuid.uuid4().hex[:8]}"
    
    try:
        await websocket_manager.connect(websocket, session_id)
        logger.info(f"ğŸ”Œ WebSocket ì—°ê²° ì„±ê³µ: {session_id}")
        
        while True:
            try:
                data = await websocket.receive_text()
                import json
                message = json.loads(data)
                
                # ë©”ì‹œì§€ íƒ€ì…ë³„ ì²˜ë¦¬
                if message.get("type") == "ping":
                    await websocket_manager.send_message(session_id, {
                        "type": "pong",
                        "message": "WebSocket ì—°ê²° í™•ì¸",
                        "timestamp": int(time.time()),
                        "modular_architecture": True
                    })
                
                elif message.get("type") == "system_status":
                    await websocket_manager.send_message(session_id, {
                        "type": "system_status",
                        "message": "ì‹œìŠ¤í…œ ì •ìƒ ë™ì‘ ì¤‘",
                        "timestamp": int(time.time()),
                        "modules": {
                            "routers": len(ROUTERS_AVAILABLE),
                            "services": len(SERVICES_AVAILABLE)
                        }
                    })
                
            except WebSocketDisconnect:
                break
            except Exception as e:
                logger.error(f"âŒ WebSocket ë©”ì‹œì§€ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
                break
    
    except Exception as e:
        logger.error(f"âŒ WebSocket ì—°ê²° ì˜¤ë¥˜: {e}")
    
    finally:
        websocket_manager.disconnect(session_id)
        logger.info(f"ğŸ”Œ WebSocket ì—°ê²° ì¢…ë£Œ: {session_id}")

# =============================================================================
# ğŸ”¥ 13. ì „ì—­ ì˜ˆì™¸ ì²˜ë¦¬ê¸°
# =============================================================================

@app.exception_handler(Exception)
async def global_exception_handler(request: Request, exc: Exception):
    """ì „ì—­ ì˜ˆì™¸ ì²˜ë¦¬ - ëª¨ë“ˆì‹ êµ¬ì¡° í˜¸í™˜"""
    logger.error(f"âŒ ì „ì—­ ì˜¤ë¥˜: {str(exc)}")
    logger.error(f"âŒ ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤: {traceback.format_exc()}")
    
    return JSONResponse(
        status_code=500,
        content={
            "success": False,
            "error": "ì„œë²„ ë‚´ë¶€ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
            "message": "ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.",
            "detail": str(exc) if settings.DEBUG else None,
            "version": "18.0.0",
            "architecture": "modular",
            "timestamp": datetime.now().isoformat(),
            "modules_status": "checking"
        }
    )

@app.exception_handler(404)
async def not_found_handler(request: Request, exc):
    """404 ì—ëŸ¬ ì²˜ë¦¬"""
    return JSONResponse(
        status_code=404,
        content={
            "success": False,
            "error": "ìš”ì²­í•œ ì—”ë“œí¬ì¸íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
            "message": f"ê²½ë¡œ '{request.url.path}'ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.",
            "available_endpoints": [
                "/",
                "/health", 
                "/api/system/info",
                "/api/pipeline/complete",
                "/api/steps/process",
                "/ws",
                "/docs"
            ],
            "version": "18.0.0",
            "architecture": "modular"
        }
    )

# =============================================================================
# ğŸ”¥ 14. ì„œë²„ ì‹œì‘ (ì™„ì „í•œ ëª¨ë“ˆì‹ êµ¬ì¡°)
# =============================================================================

if __name__ == "__main__":
    print("\n" + "="*120)
    print("ğŸ”¥ MyCloset AI ë°±ì—”ë“œ ì„œë²„ - ì™„ì „í•œ ëª¨ë“ˆì‹ êµ¬ì¡° v18.0")
    print("="*120)
    print("ğŸ—ï¸ ëª¨ë“ˆì‹ ì•„í‚¤í…ì²˜ íŠ¹ì§•:")
    print("  âœ… API Layer: Pipeline, Step, Health, Models ë¼ìš°í„° ë¶„ë¦¬")
    print("  âœ… Service Layer: Pipeline, Step ì„œë¹„ìŠ¤ DI Container ê´€ë¦¬")
    print("  âœ… Core Layer: Config, GPU, DI Container ì„¤ì • í†µí•©")
    print("  âœ… AI Pipeline Layer: 8ë‹¨ê³„ ì‹¤ì œ AI Steps ì™„ì „ ì—°ë™")
    print("  âœ… Utils Layer: í†µí•© ìœ í‹¸ë¦¬í‹° ë° í—¬í¼ í•¨ìˆ˜")
    print("="*120)
    print("ğŸš€ ëª¨ë“ˆ ìƒíƒœ:")
    for router_name, router in ROUTERS_AVAILABLE.items():
        status = "âœ…" if router is not None else "âš ï¸"
        print(f"  {status} {router_name.title()} Router")
    
    for service_name, service in SERVICES_AVAILABLE.items():
        status = "âœ…" if service else "âš ï¸"
        print(f"  {status} {service_name.title()} Service")
    
    print(f"  {'âœ…' if CONFIG_AVAILABLE else 'âš ï¸'} Core Config")
    print(f"  {'âœ…' if TORCH_AVAILABLE else 'âš ï¸'} PyTorch")
    print("="*120)
    print("ğŸŒ ì„œë²„ ì •ë³´:")
    print(f"  ğŸ“ ì£¼ì†Œ: http://{settings.HOST}:{settings.PORT}")
    print(f"  ğŸ“š API ë¬¸ì„œ: http://{settings.HOST}:{settings.PORT}/docs")
    print(f"  â¤ï¸ í—¬ìŠ¤ì²´í¬: http://{settings.HOST}:{settings.PORT}/health")
    print(f"  ğŸ”Œ WebSocket: ws://{settings.HOST}:{settings.PORT}/ws")
    print(f"  ğŸ conda: {'âœ…' if IS_CONDA else 'âŒ'} ({SYSTEM_INFO['conda_env']})")
    print(f"  ğŸ M3 Max: {'âœ…' if IS_M3_MAX else 'âŒ'}")
    print(f"  ğŸ–¥ï¸ ë””ë°”ì´ìŠ¤: {DEVICE}")
    print(f"  ğŸ’¾ ë©”ëª¨ë¦¬: {SYSTEM_INFO['memory_gb']}GB")
    print("="*120)
    print("ğŸ”— í”„ë¡ íŠ¸ì—”ë“œ ì—°ê²°:")
    active_routers = sum(1 for v in ROUTERS_AVAILABLE.values() if v is not None)
    active_services = sum(1 for v in SERVICES_AVAILABLE.values() if v)
    print(f"  ğŸ“Š í™œì„± ë¼ìš°í„°: {active_routers}/{len(ROUTERS_AVAILABLE)}")
    print(f"  ğŸ”§ í™œì„± ì„œë¹„ìŠ¤: {active_services}/{len(SERVICES_AVAILABLE)}")
    print(f"  ğŸŒ CORS ì„¤ì •: {len(settings.CORS_ORIGINS)}ê°œ ë„ë©”ì¸")
    print(f"  ğŸ”Œ í”„ë¡ íŠ¸ì—”ë“œì—ì„œ http://{settings.HOST}:{settings.PORT} ìœ¼ë¡œ API í˜¸ì¶œ ê°€ëŠ¥!")
    print("="*120)
    print("ğŸ”¥ ì™„ì „í•œ ëª¨ë“ˆì‹ êµ¬ì¡° + ì‹¤ì œ AI íŒŒì´í”„ë¼ì¸ ì™„ì„±!")
    print("ğŸ“¦ ëª¨ë“  ê¸°ëŠ¥ì´ ë…ë¦½ì  ëª¨ë“ˆë¡œ ë¶„ë¦¬ë˜ì–´ í™•ì¥ì„±ê³¼ ìœ ì§€ë³´ìˆ˜ì„± ê·¹ëŒ€í™”!")
    print("âœ¨ React/TypeScript í”„ë¡ íŠ¸ì—”ë“œ 100% í˜¸í™˜!")
    print("="*120)
    
    # ì„œë²„ ì‹¤í–‰
    try:
        uvicorn.run(
            app,
            host=settings.HOST,
            port=settings.PORT,
            reload=False,
            log_level="info",
            access_log=True
        )
    except KeyboardInterrupt:
        print("\nâœ… ëª¨ë“ˆì‹ êµ¬ì¡° ì„œë²„ê°€ ì•ˆì „í•˜ê²Œ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"\nâŒ ì„œë²„ ì‹¤í–‰ ì˜¤ë¥˜: {e}")