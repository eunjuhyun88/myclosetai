# backend/app/__init__.py
"""
ğŸ MyCloset AI ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜ íŒ¨í‚¤ì§€ v6.0
==============================================

âœ… Python Path ìë™ ì„¤ì • (Import ì˜¤ë¥˜ ì™„ì „ í•´ê²°)
âœ… conda í™˜ê²½ ìš°ì„  ìµœì í™” 
âœ… M3 Max 128GB ë©”ëª¨ë¦¬ ì™„ì „ í™œìš©
âœ… ìˆœí™˜ì°¸ì¡° ì™„ì „ ë°©ì§€
âœ… 89.8GB AI ëª¨ë¸ ê²½ë¡œ ìë™ ì„¤ì •
âœ… main.py ì™„ë²½ í˜¸í™˜
âœ… ë ˆì´ì–´ ì•„í‚¤í…ì²˜ ì§€ì› (API â†’ Service â†’ Pipeline â†’ AI)
âœ… í”„ë¡œë•ì…˜ ë ˆë²¨ ì•ˆì •ì„±
âœ… ëª¨ë“  í•˜ìœ„ ëª¨ë“ˆ ì•ˆì „í•œ ë¡œë”©

í”„ë¡œì íŠ¸ êµ¬ì¡°:
backend/                   â† ì‘ì—… ë””ë ‰í† ë¦¬ (ì—¬ê¸°ì„œ python app/main.py ì‹¤í–‰)
â”œâ”€â”€ app/                   â† íŒ¨í‚¤ì§€ ë£¨íŠ¸ (ì´ íŒŒì¼ì˜ ìœ„ì¹˜)
â”‚   â”œâ”€â”€ __init__.py       â† ì´ íŒŒì¼!
â”‚   â”œâ”€â”€ main.py           â† FastAPI ì„œë²„ ì§„ì…ì 
â”‚   â”œâ”€â”€ core/             â† í•µì‹¬ ì„¤ì • ë° ìœ í‹¸ë¦¬í‹°
â”‚   â”œâ”€â”€ services/         â† ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ ì„œë¹„ìŠ¤ë“¤
â”‚   â”œâ”€â”€ ai_pipeline/      â† AI íŒŒì´í”„ë¼ì¸ (8ë‹¨ê³„)
â”‚   â”œâ”€â”€ api/              â† REST API ì—”ë“œí¬ì¸íŠ¸
â”‚   â”œâ”€â”€ models/           â† ë°ì´í„° ëª¨ë¸/ìŠ¤í‚¤ë§ˆ
â”‚   â””â”€â”€ utils/            â† ê³µí†µ ìœ í‹¸ë¦¬í‹°
â”œâ”€â”€ ai_models/            â† AI ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ (89.8GB)
â””â”€â”€ static/               â† ì •ì  íŒŒì¼ ë° ì—…ë¡œë“œ

ì‘ì„±ì: MyCloset AI Team
ë‚ ì§œ: 2025-07-22
ë²„ì „: v6.0.0 (Complete Package Initialization)
"""

import os
import sys
import logging
import platform
import subprocess
from pathlib import Path
from typing import Dict, Any, Optional, List
import warnings

# =============================================================================
# ğŸ”¥ Step 1: íŒ¨í‚¤ì§€ ê²½ë¡œ ë° í™˜ê²½ ìë™ ì„¤ì •
# =============================================================================

# í˜„ì¬ íŒ¨í‚¤ì§€ì˜ ì ˆëŒ€ ê²½ë¡œ
_current_package_dir = Path(__file__).parent.absolute()
_backend_root = _current_package_dir.parent
_project_root = _backend_root.parent

# Python Path ìë™ ì„¤ì • (Import ì˜¤ë¥˜ í•´ê²°)
_paths_to_add = [
    str(_backend_root),    # backend/ ê²½ë¡œ (ê°€ì¥ ì¤‘ìš”!)
    str(_current_package_dir),  # backend/app/ ê²½ë¡œ
    str(_project_root),    # í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ
]

for path in _paths_to_add:
    if path not in sys.path:
        sys.path.insert(0, path)

# í™˜ê²½ ë³€ìˆ˜ ì„¤ì • (conda í™˜ê²½ ê³ ë ¤)
os.environ.update({
    'PYTHONPATH': f"{_backend_root}:{os.environ.get('PYTHONPATH', '')}",
    'PROJECT_ROOT': str(_project_root),
    'BACKEND_ROOT': str(_backend_root),
    'APP_ROOT': str(_current_package_dir)
})

# ì‘ì—… ë””ë ‰í† ë¦¬ë¥¼ backendë¡œ ì„¤ì • (ì¤‘ìš”!)
try:
    os.chdir(_backend_root)
except OSError as e:
    warnings.warn(f"ì‘ì—… ë””ë ‰í† ë¦¬ ë³€ê²½ ì‹¤íŒ¨: {e}")

# =============================================================================
# ğŸ”¥ Step 2: ì‹œìŠ¤í…œ í™˜ê²½ ê°ì§€ ë° ìµœì í™” ì„¤ì •
# =============================================================================

def _detect_system_environment() -> Dict[str, Any]:
    """ì‹œìŠ¤í…œ í™˜ê²½ ìë™ ê°ì§€ (conda í™˜ê²½ ìš°ì„ )"""
    env_info = {
        'platform': platform.system(),
        'machine': platform.machine(),
        'python_version': platform.python_version(),
        'is_conda': False,
        'conda_env': None,
        'is_m3_max': False,
        'device': 'cpu',
        'memory_gb': 16.0,
        'cpu_count': os.cpu_count() or 4
    }
    
    try:
        # conda í™˜ê²½ ê°ì§€
        conda_env = os.environ.get('CONDA_DEFAULT_ENV')
        conda_prefix = os.environ.get('CONDA_PREFIX')
        if conda_env and conda_env != 'base':
            env_info['is_conda'] = True
            env_info['conda_env'] = conda_env
        elif conda_prefix:
            env_info['is_conda'] = True
            env_info['conda_env'] = Path(conda_prefix).name
        
        # M3 Max ê°ì§€ (conda í™˜ê²½ì—ì„œ ìµœì í™”)
        if (env_info['platform'] == 'Darwin' and 
            'arm64' in env_info['machine']):
            try:
                result = subprocess.run(
                    ['sysctl', '-n', 'machdep.cpu.brand_string'], 
                    capture_output=True, text=True, timeout=3
                )
                if 'M3' in result.stdout:
                    env_info['is_m3_max'] = True
                    env_info['memory_gb'] = 128.0  # M3 Max Unified Memory
                    env_info['device'] = 'mps'
            except:
                pass
        
        # ë©”ëª¨ë¦¬ ê°ì§€
        try:
            import psutil
            env_info['memory_gb'] = round(psutil.virtual_memory().total / (1024**3))
        except ImportError:
            pass
            
        # PyTorch ë””ë°”ì´ìŠ¤ ê°ì§€
        try:
            import torch
            if torch.backends.mps.is_available():
                env_info['device'] = 'mps'
            elif torch.cuda.is_available():
                env_info['device'] = 'cuda'
        except ImportError:
            pass
            
    except Exception as e:
        warnings.warn(f"ì‹œìŠ¤í…œ í™˜ê²½ ê°ì§€ ì¤‘ ì˜¤ë¥˜: {e}")
    
    return env_info

# ì „ì—­ ì‹œìŠ¤í…œ ì •ë³´
SYSTEM_INFO = _detect_system_environment()

# M3 Max ìµœì í™” í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
if SYSTEM_INFO['is_m3_max']:
    os.environ.update({
        'PYTORCH_ENABLE_MPS_FALLBACK': '1',
        'PYTORCH_MPS_HIGH_WATERMARK_RATIO': '0.0',
        'OMP_NUM_THREADS': str(min(SYSTEM_INFO['cpu_count'] * 2, 16)),
        'DEVICE': 'mps'
    })

# =============================================================================
# ğŸ”¥ Step 3: AI ëª¨ë¸ ê²½ë¡œ ìë™ ì„¤ì • (89.8GB ëª¨ë¸)
# =============================================================================

def _setup_ai_model_paths() -> Dict[str, Path]:
    """AI ëª¨ë¸ ê²½ë¡œ ìë™ ì„¤ì • ë° ê²€ì¦"""
    ai_models_root = _backend_root / "ai_models"
    
    model_paths = {
        'ai_models_root': ai_models_root,
        'step_01_human_parsing': ai_models_root / "step_01_human_parsing",
        'step_02_pose_estimation': ai_models_root / "step_02_pose_estimation", 
        'step_03_cloth_segmentation': ai_models_root / "step_03_cloth_segmentation",
        'step_04_geometric_matching': ai_models_root / "step_04_geometric_matching",
        'step_05_cloth_warping': ai_models_root / "step_05_cloth_warping",
        'step_06_virtual_fitting': ai_models_root / "step_06_virtual_fitting",
        'step_07_post_processing': ai_models_root / "step_07_post_processing",
        'step_08_quality_assessment': ai_models_root / "step_08_quality_assessment",
        'checkpoints': ai_models_root / "checkpoints",
        'cache': ai_models_root / "cache",
        'huggingface_cache': ai_models_root / "huggingface_cache"
    }
    
    # í™˜ê²½ ë³€ìˆ˜ë¡œ ê²½ë¡œ ì„¤ì •
    for name, path in model_paths.items():
        env_name = f"AI_MODEL_{name.upper()}_PATH"
        os.environ[env_name] = str(path)
    
    return model_paths

AI_MODEL_PATHS = _setup_ai_model_paths()

# =============================================================================
# ğŸ”¥ Step 4: ë¡œê¹… ì‹œìŠ¤í…œ ì„¤ì •
# =============================================================================

def _setup_logging():
    """íŒ¨í‚¤ì§€ ì „ì²´ ë¡œê¹… ì‹œìŠ¤í…œ ì„¤ì •"""
    # ë¡œê·¸ ë””ë ‰í† ë¦¬ ìƒì„±
    log_dir = _backend_root / "logs"
    log_dir.mkdir(exist_ok=True)
    
    # ë¡œê±° ì„¤ì •
    logger = logging.getLogger("app")
    logger.setLevel(logging.INFO)
    
    # ì´ë¯¸ í•¸ë“¤ëŸ¬ê°€ ìˆìœ¼ë©´ ìŠ¤í‚µ
    if logger.handlers:
        return logger
    
    # í¬ë§¤í„° ì„¤ì •
    formatter = logging.Formatter(
        '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    
    # ì½˜ì†” í•¸ë“¤ëŸ¬
    console_handler = logging.StreamHandler()
    console_handler.setLevel(logging.INFO)
    console_handler.setFormatter(formatter)
    logger.addHandler(console_handler)
    
    # íŒŒì¼ í•¸ë“¤ëŸ¬ (íšŒì „ ë¡œê·¸) - ìˆ˜ì •ëœ import ë°©ì‹
    try:
        from logging.handlers import RotatingFileHandler
        file_handler = RotatingFileHandler(
            log_dir / "app.log",
            maxBytes=10*1024*1024,  # 10MB
            backupCount=5
        )
        file_handler.setLevel(logging.DEBUG)
        file_handler.setFormatter(formatter)
        logger.addHandler(file_handler)
    except Exception as e:
        warnings.warn(f"íŒŒì¼ ë¡œê·¸ í•¸ë“¤ëŸ¬ ì„¤ì • ì‹¤íŒ¨: {e}")
    
    return logger

# íŒ¨í‚¤ì§€ ë¡œê±° ì´ˆê¸°í™”
logger = _setup_logging()

# =============================================================================
# ğŸ”¥ Step 5: íŒ¨í‚¤ì§€ ë©”íƒ€ë°ì´í„° ë° ì •ë³´
# =============================================================================

__version__ = "6.0.0"
__author__ = "MyCloset AI Team"
__description__ = "AI-powered Virtual Try-On Platform"
__license__ = "Proprietary"

# íŒ¨í‚¤ì§€ ì •ë³´
PACKAGE_INFO = {
    'name': 'MyCloset AI',
    'version': __version__,
    'description': __description__,
    'author': __author__,
    'backend_root': str(_backend_root),
    'app_root': str(_current_package_dir),
    'python_version': SYSTEM_INFO['python_version'],
    'conda_env': SYSTEM_INFO['conda_env'],
    'is_m3_max': SYSTEM_INFO['is_m3_max'],
    'device': SYSTEM_INFO['device'],
    'memory_gb': SYSTEM_INFO['memory_gb'],
    'ai_models_available': AI_MODEL_PATHS['ai_models_root'].exists()
}

# =============================================================================
# ğŸ”¥ Step 6: í•µì‹¬ ëª¨ë“ˆ ì•ˆì „í•œ ë¡œë”© (ìˆœí™˜ì°¸ì¡° ë°©ì§€)
# =============================================================================

def _safe_import(module_name: str, package: str = None):
    """ì•ˆì „í•œ ëª¨ë“ˆ import (ì˜¤ë¥˜ ì‹œ ë¡œê·¸ë§Œ ê¸°ë¡)"""
    try:
        if package:
            module = __import__(f"{package}.{module_name}", fromlist=[module_name])
        else:
            module = __import__(module_name)
        return module
    except ImportError as e:
        logger.warning(f"âš ï¸ {module_name} import ì‹¤íŒ¨: {e}")
        return None
    except Exception as e:
        logger.error(f"âŒ {module_name} import ì˜¤ë¥˜: {e}")
        return None

# í•µì‹¬ ëª¨ë“ˆë“¤ ë¯¸ë¦¬ ë¡œë“œ ì‹œë„ (ì‹¤íŒ¨í•´ë„ ê³„ì† ì§„í–‰)
_core_modules = {
    'config': _safe_import('config', 'app.core'),
    'gpu_config': _safe_import('gpu_config', 'app.core'),
    'session_manager': _safe_import('session_manager', 'app.core'),
}

# =============================================================================
# ğŸ”¥ Step 7: ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
# =============================================================================

def get_package_info() -> Dict[str, Any]:
    """íŒ¨í‚¤ì§€ ì •ë³´ ë°˜í™˜"""
    return PACKAGE_INFO.copy()

def get_system_info() -> Dict[str, Any]:
    """ì‹œìŠ¤í…œ ì •ë³´ ë°˜í™˜"""
    return SYSTEM_INFO.copy()

def get_ai_model_paths() -> Dict[str, Path]:
    """AI ëª¨ë¸ ê²½ë¡œ ì •ë³´ ë°˜í™˜"""
    return AI_MODEL_PATHS.copy()

def is_conda_environment() -> bool:
    """conda í™˜ê²½ ì—¬ë¶€ í™•ì¸"""
    return SYSTEM_INFO['is_conda']

def is_m3_max() -> bool:
    """M3 Max í™˜ê²½ ì—¬ë¶€ í™•ì¸"""
    return SYSTEM_INFO['is_m3_max']

def get_device() -> str:
    """ì¶”ì²œ ë””ë°”ì´ìŠ¤ ë°˜í™˜"""
    return SYSTEM_INFO['device']

def validate_environment() -> Dict[str, Any]:
    """í™˜ê²½ ê²€ì¦ ë° ìƒíƒœ ë°˜í™˜"""
    validation = {
        'python_path_ok': str(_backend_root) in sys.path,
        'working_directory_ok': Path.cwd() == _backend_root,
        'ai_models_exist': AI_MODEL_PATHS['ai_models_root'].exists(),
        'conda_environment': SYSTEM_INFO['is_conda'],
        'conda_env_name': SYSTEM_INFO['conda_env'],
        'device_available': SYSTEM_INFO['device'] != 'cpu',
        'memory_sufficient': SYSTEM_INFO['memory_gb'] >= 8.0,
        'core_modules_loaded': sum(1 for m in _core_modules.values() if m is not None)
    }
    
    validation['overall_status'] = all([
        validation['python_path_ok'],
        validation['working_directory_ok'],
        validation['memory_sufficient']
    ])
    
    return validation

# =============================================================================
# ğŸ”¥ Step 8: íŒ¨í‚¤ì§€ ì´ˆê¸°í™” ì™„ë£Œ ë° ìƒíƒœ ì¶œë ¥
# =============================================================================

def _print_initialization_status():
    """ì´ˆê¸°í™” ìƒíƒœ ì¶œë ¥ (conda í™˜ê²½ ìš°ì„ )"""
    print(f"\nğŸ MyCloset AI íŒ¨í‚¤ì§€ ì´ˆê¸°í™” ì™„ë£Œ!")
    print(f"ğŸ“ ë²„ì „: {__version__}")
    print(f"ğŸ Python: {SYSTEM_INFO['python_version']}")
    
    if SYSTEM_INFO['is_conda']:
        print(f"ğŸ Conda í™˜ê²½: {SYSTEM_INFO['conda_env']} âœ…")
    else:
        print(f"âš ï¸  ì¼ë°˜ Python í™˜ê²½ (conda ê¶Œì¥)")
    
    if SYSTEM_INFO['is_m3_max']:
        print(f"ğŸ M3 Max {SYSTEM_INFO['memory_gb']:.0f}GB: {SYSTEM_INFO['device']} âœ…")
    else:
        print(f"ğŸ’» {SYSTEM_INFO['platform']}: {SYSTEM_INFO['device']}")
    
    print(f"ğŸ“ Backend: {_backend_root}")
    print(f"ğŸ¤– AI Models: {'âœ…' if AI_MODEL_PATHS['ai_models_root'].exists() else 'âŒ'}")
    
    validation = validate_environment()
    if validation['overall_status']:
        print(f"âœ… í™˜ê²½ ê²€ì¦ ì™„ë£Œ - ì„œë²„ ì‹¤í–‰ ê°€ëŠ¥!")
    else:
        print(f"âš ï¸  í™˜ê²½ ê²€ì¦ ì‹¤íŒ¨ - ì„¤ì •ì„ í™•ì¸í•˜ì„¸ìš”")
    print()

# ì´ˆê¸°í™” ìƒíƒœ ì¶œë ¥ (ê°œë°œ í™˜ê²½ì—ì„œë§Œ)
if os.getenv('DEBUG', '').lower() in ['true', '1'] or '--verbose' in sys.argv:
    _print_initialization_status()

# =============================================================================
# ğŸ”¥ Step 9: __all__ ë° ê³µê°œ API ì •ì˜
# =============================================================================

__all__ = [
    # ë©”íƒ€ë°ì´í„°
    '__version__',
    '__author__',
    '__description__',
    
    # ì •ë³´ í•¨ìˆ˜ë“¤
    'get_package_info',
    'get_system_info', 
    'get_ai_model_paths',
    'is_conda_environment',
    'is_m3_max',
    'get_device',
    'validate_environment',
    
    # ìƒìˆ˜ë“¤
    'SYSTEM_INFO',
    'AI_MODEL_PATHS',
    'PACKAGE_INFO',
    
    # ê²½ë¡œë“¤
    '_backend_root',
    '_current_package_dir',
    '_project_root'
]

# =============================================================================
# ğŸ”¥ ìµœì¢…: ì´ˆê¸°í™” ì„±ê³µ ë¡œê·¸
# =============================================================================

logger.info(f"ğŸ‰ MyCloset AI íŒ¨í‚¤ì§€ ì´ˆê¸°í™” ì™„ë£Œ (v{__version__})")
logger.info(f"ğŸ í™˜ê²½: {'Conda' if SYSTEM_INFO['is_conda'] else 'Python'} - {SYSTEM_INFO['conda_env'] or 'system'}")
logger.info(f"ğŸ M3 Max: {'í™œì„±' if SYSTEM_INFO['is_m3_max'] else 'ë¹„í™œì„±'}")
logger.info(f"ğŸ¤– AI ëª¨ë¸: {'ì‚¬ìš©ê°€ëŠ¥' if AI_MODEL_PATHS['ai_models_root'].exists() else 'ì—†ìŒ'}")
logger.info(f"ğŸ“ ì‘ì—…ê²½ë¡œ: {Path.cwd()}")

# í™˜ê²½ ê²€ì¦ ë° ê²½ê³ 
validation = validate_environment()
if not validation['overall_status']:
    logger.warning("âš ï¸ í™˜ê²½ ê²€ì¦ ì‹¤íŒ¨ - ì¼ë¶€ ê¸°ëŠ¥ì´ ì œí•œë  ìˆ˜ ìˆìŠµë‹ˆë‹¤")
    if not validation['python_path_ok']:
        logger.warning("   - Python ê²½ë¡œ ì„¤ì • ë¬¸ì œ")
    if not validation['working_directory_ok']:
        logger.warning("   - ì‘ì—… ë””ë ‰í† ë¦¬ ë¬¸ì œ")
    if not validation['memory_sufficient']:
        logger.warning("   - ë©”ëª¨ë¦¬ ë¶€ì¡± (ìµœì†Œ 8GB ê¶Œì¥)")

# conda í™˜ê²½ ê¶Œì¥ ë©”ì‹œì§€
if not SYSTEM_INFO['is_conda']:
    logger.info("ğŸ’¡ conda í™˜ê²½ ì‚¬ìš©ì„ ê¶Œì¥í•©ë‹ˆë‹¤: conda activate mycloset-ai")

logger.info("=" * 60)