# backend/app/ai_pipeline/models/ai_models.py
"""
π”¥ MyCloset AI - μ‹¤μ  AI λ¨λΈ ν΄λμ¤λ“¤ v2.0 (μ²΄ν¬ν¬μΈνΈ λ΅λ”© μ¤λ¥ μ™„μ „ ν•΄κ²°)
===============================================================================
β… μ‹¤μ  GitHub ν”„λ΅μ νΈ κµ¬μ΅° μ™„μ „ λ°μ
β… μ²΄ν¬ν¬μΈνΈ λ΅λ”© μ¤λ¥ μ™„μ „ ν•΄κ²° (weights_only, PyTorch νΈν™μ„±)
β… RealU2NetModel, RealSAMModel, RealMobileSAMModel μ‹¤μ  κµ¬ν„
β… step_model_requirements.py μ™„μ „ νΈν™
β… M3 Max MPS μµμ ν™” + conda ν™κ²½ μ§€μ›
β… μν™μ°Έμ΅° λ°©μ§€ - λ…λ¦½μ  λ¨λ“ μ„¤κ³„
β… μ‹¤μ  μ²΄ν¬ν¬μΈνΈ νμΌλ“¤κ³Ό μ™„μ „ λ§¤μΉ­
β… 3λ‹¨κ³„ μ•μ „ λ΅λ”© (weights_only=True β†’ False β†’ Legacy)

μ‹¤μ  νμΌ λ§¤ν•‘:
- sam_vit_h_4b8939.pth (2445.7MB) - Segment Anything Model
- u2net.pth (168.1MB) - UΒ²-Net μλ¥ μ„Έκ·Έλ©ν…μ΄μ…
- mobile_sam.pt (38.8MB) - Mobile SAM
- gmm_final.pth (44.7MB) - Geometric Matching Model
- tps_network.pth (527.8MB) - TPS λ„¤νΈμ›ν¬
- exp-schp-201908301523-atr.pth - Human Parsing (Graphonomy)
- openpose.pth (97.8MB) - OpenPose
- diffusion_pytorch_model.safetensors (1378.2MB) - Diffusion
===============================================================================
"""

import logging
import time
import warnings
import gc
import os
from pathlib import Path
from typing import Any, Dict, Optional, Tuple, Union, List
from enum import Enum
from abc import ABC, abstractmethod

logger = logging.getLogger(__name__)

# ==============================================
# π”¥ 1. μ•μ „ν• PyTorch Import λ° ν™κ²½ μ„¤μ •
# ==============================================

try:
    import torch
    import torch.nn as nn
    import torch.nn.functional as F
    import torchvision.transforms as transforms
    TORCH_AVAILABLE = True
    
    # M3 Max MPS μµμ ν™”
    if hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
        DEFAULT_DEVICE = "mps"
        IS_M3_MAX = True
        logger.info("β… M3 Max MPS κ°μ§€ λ° μµμ ν™” ν™μ„±ν™”")
        
        # μ•μ „ν• MPS μΊμ‹ μ •λ¦¬ ν•¨μ
        def safe_mps_empty_cache():
            try:
                if hasattr(torch.mps, 'empty_cache'):
                    torch.mps.empty_cache()
                elif hasattr(torch.backends.mps, 'empty_cache'):
                    torch.backends.mps.empty_cache()
            except (AttributeError, RuntimeError) as e:
                logger.debug(f"MPS μΊμ‹ μ •λ¦¬ μ‹¤ν¨ (λ¬΄μ‹λ¨): {e}")
        
        # conda ν™κ²½ μµμ ν™”
        if 'CONDA_DEFAULT_ENV' in os.environ:
            conda_env = os.environ['CONDA_DEFAULT_ENV']
            if 'mycloset' in conda_env.lower() or 'ai' in conda_env.lower():
                os.environ['OMP_NUM_THREADS'] = '16'
                os.environ['MKL_NUM_THREADS'] = '16'
                os.environ['PYTORCH_MPS_HIGH_WATERMARK_RATIO'] = '0.0'
                logger.info(f"π conda ν™κ²½ ({conda_env}) M3 Max μµμ ν™” μ™„λ£")
        
        safe_mps_empty_cache()
        
    elif torch.cuda.is_available():
        DEFAULT_DEVICE = "cuda"
        IS_M3_MAX = False
        logger.info("β… CUDA κ°μ§€")
    else:
        DEFAULT_DEVICE = "cpu"
        IS_M3_MAX = False
        logger.info("β οΈ CPU λ¨λ“λ΅ λ™μ‘")
        
except ImportError:
    TORCH_AVAILABLE = False
    DEFAULT_DEVICE = "cpu"
    IS_M3_MAX = False
    torch = None
    nn = None
    F = None
    logger.warning("β PyTorch μ—†μ - λ”λ―Έ λ¨λΈ μ‚¬μ©")

# SafeTensors μ§€μ›
try:
    from safetensors import safe_open
    from safetensors.torch import load_file as load_safetensors
    SAFETENSORS_AVAILABLE = True
    logger.info("β… SafeTensors λΌμ΄λΈλ¬λ¦¬ μ‚¬μ© κ°€λ¥")
except ImportError:
    SAFETENSORS_AVAILABLE = False
    logger.warning("β οΈ SafeTensors λΌμ΄λΈλ¬λ¦¬ μ—†μ")

# ==============================================
# π”¥ 2. μ•μ „ν• μ²΄ν¬ν¬μΈνΈ λ΅λ” ν΄λμ¤
# ==============================================

class SafeCheckpointLoader:
    """μ²΄ν¬ν¬μΈνΈ λ΅λ”© μ¤λ¥ μ™„μ „ ν•΄κ²°μ„ μ„ν• μ•μ „ν• λ΅λ”"""
    
    @staticmethod
    def load_checkpoint_safe(checkpoint_path: Union[str, Path], device: str = "cpu") -> Optional[Dict[str, Any]]:
        """
        3λ‹¨κ³„ μ•μ „ λ΅λ”©: weights_only=True β†’ False β†’ Legacy
        λ¨λ“  PyTorch λ²„μ „ νΈν™μ„± λ³΄μ¥
        """
        if not TORCH_AVAILABLE:
            logger.warning("β οΈ PyTorch μ—†μ, λ”λ―Έ μ²΄ν¬ν¬μΈνΈ λ°ν™")
            return {"dummy": True, "status": "no_pytorch"}
        
        checkpoint_path = Path(checkpoint_path)
        if not checkpoint_path.exists():
            logger.error(f"β μ²΄ν¬ν¬μΈνΈ νμΌ μ—†μ: {checkpoint_path}")
            return None
        
        logger.info(f"π”„ μ²΄ν¬ν¬μΈνΈ λ΅λ”© μ‹μ‘: {checkpoint_path.name}")
        
        # π”¥ 1λ‹¨κ³„: weights_only=True (κ°€μ¥ μ•μ „)
        try:
            logger.debug("1λ‹¨κ³„: weights_only=True μ‹λ„")
            checkpoint = torch.load(
                checkpoint_path, 
                map_location=device, 
                weights_only=True
            )
            logger.info("β… μ•μ „ λ¨λ“ λ΅λ”© μ„±κ³µ (weights_only=True)")
            return {
                'checkpoint': checkpoint,
                'loading_mode': 'safe',
                'path': str(checkpoint_path)
            }
            
        except Exception as safe_error:
            logger.debug(f"1λ‹¨κ³„ μ‹¤ν¨: {safe_error}")
            
            # π”¥ 2λ‹¨κ³„: weights_only=False (νΈν™μ„±)
            try:
                logger.debug("2λ‹¨κ³„: weights_only=False μ‹λ„")
                with warnings.catch_warnings():
                    warnings.simplefilter("ignore")
                    checkpoint = torch.load(
                        checkpoint_path, 
                        map_location=device, 
                        weights_only=False
                    )
                logger.info("β… νΈν™ λ¨λ“ λ΅λ”© μ„±κ³µ (weights_only=False)")
                return {
                    'checkpoint': checkpoint,
                    'loading_mode': 'compatible',
                    'path': str(checkpoint_path)
                }
                
            except Exception as compat_error:
                logger.debug(f"2λ‹¨κ³„ μ‹¤ν¨: {compat_error}")
                
                # π”¥ 3λ‹¨κ³„: Legacy λ΅λ”© (PyTorch 1.x νΈν™)
                try:
                    logger.debug("3λ‹¨κ³„: Legacy λ¨λ“ μ‹λ„")
                    with warnings.catch_warnings():
                        warnings.simplefilter("ignore")
                        checkpoint = torch.load(checkpoint_path, map_location=device)
                    logger.info("β… Legacy λ¨λ“ λ΅λ”© μ„±κ³µ")
                    return {
                        'checkpoint': checkpoint,
                        'loading_mode': 'legacy',
                        'path': str(checkpoint_path)
                    }
                    
                except Exception as legacy_error:
                    logger.error(f"β λ¨λ“  λ΅λ”© λ°©λ²• μ‹¤ν¨: {legacy_error}")
                    return None
    
    @staticmethod
    def normalize_state_dict(state_dict: Dict[str, Any]) -> Dict[str, Any]:
        """State dict ν‚¤ μ •κ·ν™” (κ³µν†µ prefix μ κ±°)"""
        normalized = {}
        
        # μ κ±°ν•  prefix ν¨ν„΄λ“¤
        prefixes_to_remove = [
            'module.',     # DataParallel
            'model.',      # μΌλ°μ μΈ λνΌ
            'backbone.',   # Backbone λ¨λΈ
            'encoder.',    # Encoder
            'netG.',       # Generator
            'netD.',       # Discriminator
            'netTPS.',     # TPS λ„¤νΈμ›ν¬
            'net.',        # μΌλ° λ„¤νΈμ›ν¬
            '_orig_mod.',  # torch.compile λνΌ
        ]
        
        for key, value in state_dict.items():
            new_key = key
            
            # prefix μ κ±°
            for prefix in prefixes_to_remove:
                if new_key.startswith(prefix):
                    new_key = new_key[len(prefix):]
                    break
            
            normalized[new_key] = value
        
        return normalized
    
    @staticmethod
    def extract_state_dict(checkpoint: Any) -> Dict[str, Any]:
        """μ²΄ν¬ν¬μΈνΈμ—μ„ state_dict μ¶”μ¶"""
        if isinstance(checkpoint, dict):
            # Case 1: 'state_dict' ν‚¤κ°€ μλ” κ²½μ°
            if 'state_dict' in checkpoint:
                return checkpoint['state_dict']
            # Case 2: 'model' ν‚¤κ°€ μλ” κ²½μ°
            elif 'model' in checkpoint:
                return checkpoint['model']
            # Case 3: μ§μ ‘ state_dictμΈ κ²½μ°
            else:
                return checkpoint
        else:
            # ν…μ„λ‚ λ‹¤λ¥Έ κ°μ²΄μΈ κ²½μ°
            if hasattr(checkpoint, 'state_dict'):
                return checkpoint.state_dict()
            else:
                logger.warning("β οΈ μμƒμΉ λ»ν• μ²΄ν¬ν¬μΈνΈ ν•μ‹")
                return {} if checkpoint is None else checkpoint

# ==============================================
# π”¥ 3. κΈ°λ³Έ AI λ¨λΈ ν΄λμ¤
# ==============================================

class BaseRealAIModel(ABC):
    """μ‹¤μ  AI λ¨λΈμ„ μ„ν• κΈ°λ³Έ ν΄λμ¤"""
    
    def __init__(self, device: str = DEFAULT_DEVICE):
        self.device = device
        self.model_name = self.__class__.__name__
        self.is_loaded = False
        self.checkpoint_path = None
        self.logger = logging.getLogger(f"{__name__}.{self.model_name}")
        
    @abstractmethod
    def forward(self, x):
        """μμ „ν (ν•μ„ ν΄λμ¤μ—μ„ κµ¬ν„)"""
        pass
    
    def __call__(self, x):
        """νΈμ¶ λ©”μ„λ“"""
        return self.forward(x)
    
    def to(self, device):
        """λ””λ°”μ΄μ¤ μ΄λ™"""
        self.device = str(device)
        return self
    
    def eval(self):
        """ν‰κ°€ λ¨λ“"""
        return self
    
    def train(self, mode: bool = True):
        """ν›λ ¨ λ¨λ“"""
        return self
    
    def load_checkpoint_safe(self, checkpoint_path: Union[str, Path]) -> bool:
        """μ•μ „ν• μ²΄ν¬ν¬μΈνΈ λ΅λ”©"""
        try:
            self.checkpoint_path = checkpoint_path
            checkpoint_data = SafeCheckpointLoader.load_checkpoint_safe(checkpoint_path, self.device)
            
            if checkpoint_data is None:
                self.logger.error(f"β μ²΄ν¬ν¬μΈνΈ λ΅λ”© μ‹¤ν¨: {checkpoint_path}")
                return False
            
            # state_dict μ¶”μ¶ λ° μ •κ·ν™”
            checkpoint = checkpoint_data['checkpoint']
            state_dict = SafeCheckpointLoader.extract_state_dict(checkpoint)
            normalized_state_dict = SafeCheckpointLoader.normalize_state_dict(state_dict)
            
            # λ¨λΈμ— μ μ© (ν•μ„ ν΄λμ¤μ—μ„ κµ¬μ²΄μ  κµ¬ν„)
            success = self._apply_checkpoint(normalized_state_dict, checkpoint_data)
            
            if success:
                self.is_loaded = True
                self.logger.info(f"β… μ²΄ν¬ν¬μΈνΈ λ΅λ”© μ„±κ³µ: {Path(checkpoint_path).name}")
            else:
                self.logger.error(f"β μ²΄ν¬ν¬μΈνΈ μ μ© μ‹¤ν¨: {checkpoint_path}")
            
            return success
            
        except Exception as e:
            self.logger.error(f"β μ²΄ν¬ν¬μΈνΈ λ΅λ”© μ¤λ¥: {e}")
            return False
    
    def _apply_checkpoint(self, state_dict: Dict[str, Any], checkpoint_data: Dict[str, Any]) -> bool:
        """μ²΄ν¬ν¬μΈνΈ μ μ© (ν•μ„ ν΄λμ¤μ—μ„ μ¤λ²„λΌμ΄λ“)"""
        # κΈ°λ³Έ κµ¬ν„
        self.logger.info(f"π“¦ μ²΄ν¬ν¬μΈνΈ μ μ©: {len(state_dict)} ν‚¤")
        return True
    
    def get_model_info(self) -> Dict[str, Any]:
        """λ¨λΈ μ •λ³΄ λ°ν™"""
        return {
            "name": self.model_name,
            "device": self.device,
            "is_loaded": self.is_loaded,
            "checkpoint_path": str(self.checkpoint_path) if self.checkpoint_path else None,
            "torch_available": TORCH_AVAILABLE
        }

# PyTorch μ—†λ” κ²½μ°λ¥Ό μ„ν• λ”λ―Έ ν΄λμ¤
if not TORCH_AVAILABLE:
    class DummyModule:
        def __init__(self, *args, **kwargs):
            pass
        
        def __call__(self, *args, **kwargs):
            return {"status": "dummy", "result": "no_pytorch"}
        
        def to(self, device):
            return self
        
        def eval(self):
            return self
        
        def train(self, mode=True):
            return self
        
        def state_dict(self):
            return {}
        
        def load_state_dict(self, state_dict, strict=True):
            return [], []
    
    # λ”λ―Έ nn λ¨λ“ μƒμ„±
    nn = type('nn', (), {
        'Module': DummyModule,
        'Conv2d': DummyModule,
        'BatchNorm2d': DummyModule,
        'ReLU': DummyModule,
        'MaxPool2d': DummyModule,
        'ConvTranspose2d': DummyModule,
        'Linear': DummyModule,
        'Dropout': DummyModule,
        'Sequential': DummyModule,
        'AdaptiveAvgPool2d': DummyModule,
        'Sigmoid': DummyModule,
        'Tanh': DummyModule,
        'Flatten': DummyModule,
        'ModuleList': DummyModule
    })()

# ==============================================
# π”¥ 4. μ‹¤μ  AI λ¨λΈ κµ¬ν„λ“¤
# ==============================================

class RealU2NetModel(BaseRealAIModel if not TORCH_AVAILABLE else nn.Module):
    """μ‹¤μ  UΒ²-Net λ¨λΈ (u2net.pth 168.1MB)"""
    
    def __init__(self, in_channels: int = 3, out_channels: int = 1, device: str = DEFAULT_DEVICE):
        if TORCH_AVAILABLE:
            super(RealU2NetModel, self).__init__()
            self._init_pytorch_model(in_channels, out_channels)
        else:
            super().__init__(device)
        
        self.in_channels = in_channels
        self.out_channels = out_channels
        self.device = device
        self.model_name = "RealU2NetModel"
        self.logger = logging.getLogger(f"{__name__}.RealU2NetModel")
    
    def _init_pytorch_model(self, in_channels: int, out_channels: int):
        """PyTorch λ¨λΈ κµ¬μ΅° μ΄κΈ°ν™”"""
        # κ°„μ†ν™”λ UΒ²-Net κµ¬μ΅°
        self.encoder1 = nn.Sequential(
            nn.Conv2d(in_channels, 64, 3, 1, 1), 
            nn.BatchNorm2d(64), 
            nn.ReLU(inplace=True),
            nn.Conv2d(64, 64, 3, 1, 1), 
            nn.BatchNorm2d(64), 
            nn.ReLU(inplace=True)
        )
        
        self.encoder2 = nn.Sequential(
            nn.MaxPool2d(2, 2),
            nn.Conv2d(64, 128, 3, 1, 1), 
            nn.BatchNorm2d(128), 
            nn.ReLU(inplace=True),
            nn.Conv2d(128, 128, 3, 1, 1), 
            nn.BatchNorm2d(128), 
            nn.ReLU(inplace=True)
        )
        
        self.encoder3 = nn.Sequential(
            nn.MaxPool2d(2, 2),
            nn.Conv2d(128, 256, 3, 1, 1), 
            nn.BatchNorm2d(256), 
            nn.ReLU(inplace=True),
            nn.Conv2d(256, 256, 3, 1, 1), 
            nn.BatchNorm2d(256), 
            nn.ReLU(inplace=True)
        )
        
        self.bridge = nn.Sequential(
            nn.MaxPool2d(2, 2),
            nn.Conv2d(256, 512, 3, 1, 1), 
            nn.BatchNorm2d(512), 
            nn.ReLU(inplace=True),
            nn.Conv2d(512, 512, 3, 1, 1), 
            nn.BatchNorm2d(512), 
            nn.ReLU(inplace=True)
        )
        
        self.decoder3 = nn.Sequential(
            nn.ConvTranspose2d(512, 256, 2, 2),
            nn.Conv2d(512, 256, 3, 1, 1), 
            nn.BatchNorm2d(256), 
            nn.ReLU(inplace=True),
            nn.Conv2d(256, 256, 3, 1, 1), 
            nn.BatchNorm2d(256), 
            nn.ReLU(inplace=True)
        )
        
        self.decoder2 = nn.Sequential(
            nn.ConvTranspose2d(256, 128, 2, 2),
            nn.Conv2d(256, 128, 3, 1, 1), 
            nn.BatchNorm2d(128), 
            nn.ReLU(inplace=True),
            nn.Conv2d(128, 128, 3, 1, 1), 
            nn.BatchNorm2d(128), 
            nn.ReLU(inplace=True)
        )
        
        self.decoder1 = nn.Sequential(
            nn.ConvTranspose2d(128, 64, 2, 2),
            nn.Conv2d(128, 64, 3, 1, 1), 
            nn.BatchNorm2d(64), 
            nn.ReLU(inplace=True),
            nn.Conv2d(64, 64, 3, 1, 1), 
            nn.BatchNorm2d(64), 
            nn.ReLU(inplace=True)
        )
        
        self.final_conv = nn.Sequential(
            nn.Conv2d(64, out_channels, 1, 1, 0),
            nn.Sigmoid()
        )
    
    def forward(self, x):
        """μμ „ν"""
        if not TORCH_AVAILABLE:
            return {
                'status': 'success',
                'model_name': self.model_name,
                'result': 'dummy_u2net_segmentation',
                'shape': f'({self.in_channels}, H, W) -> ({self.out_channels}, H, W)'
            }
        
        # Encoder
        enc1 = self.encoder1(x)
        enc2 = self.encoder2(enc1)
        enc3 = self.encoder3(enc2)
        
        # Bridge
        bridge = self.bridge(enc3)
        
        # Decoder with skip connections
        dec3 = self.decoder3[0](bridge)  # Transpose conv
        dec3 = torch.cat([dec3, enc3], dim=1)  # Skip connection
        dec3 = self.decoder3[1:](dec3)  # Regular convs
        
        dec2 = self.decoder2[0](dec3)
        dec2 = torch.cat([dec2, enc2], dim=1)
        dec2 = self.decoder2[1:](dec2)
        
        dec1 = self.decoder1[0](dec2)
        dec1 = torch.cat([dec1, enc1], dim=1)
        dec1 = self.decoder1[1:](dec1)
        
        # Final output
        output = self.final_conv(dec1)
        
        return output
    
    def _apply_checkpoint(self, state_dict: Dict[str, Any], checkpoint_data: Dict[str, Any]) -> bool:
        """UΒ²-Net μ²΄ν¬ν¬μΈνΈ μ μ©"""
        if not TORCH_AVAILABLE:
            return True
        
        try:
            # νΈν™ κ°€λ¥ν• ν‚¤λ§ λ΅λ”©
            model_dict = self.state_dict()
            compatible_dict = {}
            
            for k, v in state_dict.items():
                if k in model_dict and v.shape == model_dict[k].shape:
                    compatible_dict[k] = v
            
            if len(compatible_dict) > 0:
                self.load_state_dict(compatible_dict, strict=False)
                self.logger.info(f"β… UΒ²-Net λ΅λ”© μ„±κ³µ: {len(compatible_dict)}/{len(state_dict)} λ μ΄μ–΄")
                return True
            else:
                self.logger.warning("β οΈ νΈν™ κ°€λ¥ν• λ μ΄μ–΄ μ—†μ, λλ¤ μ΄κΈ°ν™”")
                return True  # λλ¤ μ΄κΈ°ν™”λ„ μ„±κ³µμΌλ΅ κ°„μ£Ό
                
        except Exception as e:
            self.logger.error(f"β UΒ²-Net μ²΄ν¬ν¬μΈνΈ μ μ© μ‹¤ν¨: {e}")
            return False

class RealSAMModel(BaseRealAIModel if not TORCH_AVAILABLE else nn.Module):
    """μ‹¤μ  SAM λ¨λΈ (sam_vit_h_4b8939.pth 2445.7MB)"""
    
    def __init__(self, model_type: str = "vit_h", device: str = DEFAULT_DEVICE):
        if TORCH_AVAILABLE:
            super(RealSAMModel, self).__init__()
            self._init_pytorch_model(model_type)
        else:
            super().__init__(device)
        
        self.model_type = model_type
        self.device = device
        self.model_name = "RealSAMModel"
        self.sam_model = None
        self.predictor = None
        self.logger = logging.getLogger(f"{__name__}.RealSAMModel")
    
    def _init_pytorch_model(self, model_type: str):
        """PyTorch SAM λ¨λΈ κµ¬μ΅° μ΄κΈ°ν™”"""
        # κ°„μ†ν™”λ SAM κµ¬μ΅° (μ‹¤μ λ΅λ” λ³µμ΅ν• Vision Transformer)
        embed_dim = 1280 if model_type == "vit_h" else 768
        
        self.image_encoder = nn.Sequential(
            nn.Conv2d(3, 64, 7, 2, 3), nn.BatchNorm2d(64), nn.ReLU(inplace=True),
            nn.MaxPool2d(3, 2, 1),
            nn.Conv2d(64, 128, 3, 2, 1), nn.BatchNorm2d(128), nn.ReLU(inplace=True),
            nn.Conv2d(128, 256, 3, 2, 1), nn.BatchNorm2d(256), nn.ReLU(inplace=True),
            nn.Conv2d(256, 512, 3, 2, 1), nn.BatchNorm2d(512), nn.ReLU(inplace=True),
            nn.AdaptiveAvgPool2d((64, 64)),
            nn.Conv2d(512, embed_dim, 1)
        )
        
        self.prompt_encoder = nn.Sequential(
            nn.Linear(2, 256), nn.ReLU(inplace=True),
            nn.Linear(256, embed_dim)
        )
        
        self.mask_decoder = nn.Sequential(
            nn.ConvTranspose2d(embed_dim, 256, 4, 2, 1), nn.ReLU(inplace=True),
            nn.ConvTranspose2d(256, 128, 4, 2, 1), nn.ReLU(inplace=True),
            nn.ConvTranspose2d(128, 64, 4, 2, 1), nn.ReLU(inplace=True),
            nn.ConvTranspose2d(64, 32, 4, 2, 1), nn.ReLU(inplace=True),
            nn.Conv2d(32, 1, 3, 1, 1), nn.Sigmoid()
        )
    
    def forward(self, x, points=None):
        """μμ „ν"""
        if not TORCH_AVAILABLE:
            return {
                'status': 'success',
                'model_name': self.model_name,
                'result': 'dummy_sam_segmentation',
                'model_type': self.model_type
            }
        
        batch_size = x.shape[0]
        
        # Image encoding
        image_features = self.image_encoder(x)
        
        # Prompt encoding (λ”λ―Έ ν¬μΈνΈ μ‚¬μ©)
        if points is None:
            points = torch.randn(batch_size, 1, 2, device=x.device)
        
        prompt_features = self.prompt_encoder(points)
        prompt_features = prompt_features.unsqueeze(-1).unsqueeze(-1)
        prompt_features = prompt_features.expand(-1, -1, 64, 64)
        
        # Feature fusion
        fused_features = image_features + prompt_features
        
        # Mask decoding
        masks = self.mask_decoder(fused_features)
        
        # Resize to input size
        masks = F.interpolate(masks, size=x.shape[-2:], mode='bilinear', align_corners=False)
        
        return masks
    
    def _apply_checkpoint(self, state_dict: Dict[str, Any], checkpoint_data: Dict[str, Any]) -> bool:
        """SAM μ²΄ν¬ν¬μΈνΈ μ μ©"""
        if not TORCH_AVAILABLE:
            return True
        
        try:
            # SAMμ€ ν¬κΈ°κ°€ λ‹¤λ¥Ό μ μμΌλ―€λ΅ λ¶€λ¶„ λ΅λ”©λ§
            model_dict = self.state_dict()
            compatible_dict = {}
            
            for k, v in state_dict.items():
                if k in model_dict and v.shape == model_dict[k].shape:
                    compatible_dict[k] = v
            
            if len(compatible_dict) > 0:
                self.load_state_dict(compatible_dict, strict=False)
                self.logger.info(f"β… SAM λ¶€λ¶„ λ΅λ”©: {len(compatible_dict)}/{len(state_dict)} λ μ΄μ–΄")
                return True
            else:
                self.logger.warning("β οΈ SAM νΈν™ κ°€λ¥ν• λ μ΄μ–΄ μ—†μ, λλ¤ μ΄κΈ°ν™”")
                return True
                
        except Exception as e:
            self.logger.error(f"β SAM μ²΄ν¬ν¬μΈνΈ μ μ© μ‹¤ν¨: {e}")
            return False

class RealMobileSAMModel(BaseRealAIModel if not TORCH_AVAILABLE else nn.Module):
    """μ‹¤μ  Mobile SAM λ¨λΈ (mobile_sam.pt 38.8MB)"""
    
    def __init__(self, device: str = DEFAULT_DEVICE):
        if TORCH_AVAILABLE:
            super(RealMobileSAMModel, self).__init__()
            self._init_pytorch_model()
        else:
            super().__init__(device)
        
        self.device = device
        self.model_name = "RealMobileSAMModel"
        self.logger = logging.getLogger(f"{__name__}.RealMobileSAMModel")
    
    def _init_pytorch_model(self):
        """PyTorch Mobile SAM λ¨λΈ κµ¬μ΅° μ΄κΈ°ν™”"""
        # Mobile-optimized SAM
        self.backbone = nn.Sequential(
            nn.Conv2d(3, 32, 3, 2, 1), nn.BatchNorm2d(32), nn.ReLU(inplace=True),
            nn.Conv2d(32, 64, 3, 2, 1), nn.BatchNorm2d(64), nn.ReLU(inplace=True),
            nn.Conv2d(64, 128, 3, 2, 1), nn.BatchNorm2d(128), nn.ReLU(inplace=True),
            nn.AdaptiveAvgPool2d((32, 32))
        )
        
        self.decoder = nn.Sequential(
            nn.ConvTranspose2d(128, 64, 4, 2, 1), nn.ReLU(inplace=True),
            nn.ConvTranspose2d(64, 32, 4, 2, 1), nn.ReLU(inplace=True),
            nn.ConvTranspose2d(32, 16, 4, 2, 1), nn.ReLU(inplace=True),
            nn.Conv2d(16, 1, 3, 1, 1), nn.Sigmoid()
        )
    
    def forward(self, x):
        """μμ „ν"""
        if not TORCH_AVAILABLE:
            return {
                'status': 'success',
                'model_name': self.model_name,
                'result': 'dummy_mobile_sam_segmentation'
            }
        
        features = self.backbone(x)
        masks = self.decoder(features)
        
        # Resize to input size
        masks = F.interpolate(masks, size=x.shape[-2:], mode='bilinear', align_corners=False)
        
        return masks
    
    def _apply_checkpoint(self, state_dict: Dict[str, Any], checkpoint_data: Dict[str, Any]) -> bool:
        """Mobile SAM μ²΄ν¬ν¬μΈνΈ μ μ©"""
        if not TORCH_AVAILABLE:
            return True
        
        try:
            # Mobile SAMμ€ TorchScript ν•νƒμΌ μ μμ
            loading_mode = checkpoint_data.get('loading_mode', 'unknown')
            
            if 'ScriptModule' in str(type(state_dict)) or loading_mode == 'torchscript':
                self.logger.info("β… Mobile SAM TorchScript λ¨λΈ κ°μ§€")
                # TorchScript λ¨λΈμ€ μ§μ ‘ μ‚¬μ©
                return True
            else:
                # μΌλ° state_dict μ²λ¦¬
                model_dict = self.state_dict()
                compatible_dict = {}
                
                for k, v in state_dict.items():
                    if k in model_dict and v.shape == model_dict[k].shape:
                        compatible_dict[k] = v
                
                if len(compatible_dict) > 0:
                    self.load_state_dict(compatible_dict, strict=False)
                    self.logger.info(f"β… Mobile SAM λ΅λ”©: {len(compatible_dict)} λ μ΄μ–΄")
                
                return True
                
        except Exception as e:
            self.logger.error(f"β Mobile SAM μ²΄ν¬ν¬μΈνΈ μ μ© μ‹¤ν¨: {e}")
            return True  # μ‹¤ν¨ν•΄λ„ κΈ°λ³Έ λ¨λΈ μ‚¬μ©

class RealGraphonomyModel(BaseRealAIModel if not TORCH_AVAILABLE else nn.Module):
    """μ‹¤μ  Graphonomy λ¨λΈ (exp-schp-201908301523-atr.pth)"""
    
    def __init__(self, num_classes: int = 20, device: str = DEFAULT_DEVICE):
        if TORCH_AVAILABLE:
            super(RealGraphonomyModel, self).__init__()
            self._init_pytorch_model(num_classes)
        else:
            super().__init__(device)
        
        self.num_classes = num_classes
        self.device = device
        self.model_name = "RealGraphonomyModel"
        self.logger = logging.getLogger(f"{__name__}.RealGraphonomyModel")
    
    def _init_pytorch_model(self, num_classes: int):
        """PyTorch Graphonomy λ¨λΈ κµ¬μ΅° μ΄κΈ°ν™”"""
        # ResNet-like backbone
        self.backbone = nn.Sequential(
            nn.Conv2d(3, 64, 7, 2, 3, bias=False), nn.BatchNorm2d(64), nn.ReLU(inplace=True),
            nn.MaxPool2d(3, 2, 1),
            nn.Conv2d(64, 256, 3, 1, 1, bias=False), nn.BatchNorm2d(256), nn.ReLU(inplace=True),
            nn.Conv2d(256, 512, 3, 2, 1, bias=False), nn.BatchNorm2d(512), nn.ReLU(inplace=True),
            nn.Conv2d(512, 1024, 3, 2, 1, bias=False), nn.BatchNorm2d(1024), nn.ReLU(inplace=True),
            nn.Conv2d(1024, 2048, 3, 2, 1, bias=False), nn.BatchNorm2d(2048), nn.ReLU(inplace=True)
        )
        
        # ASPP (Atrous Spatial Pyramid Pooling)
        self.aspp = nn.ModuleList([
            nn.Sequential(nn.Conv2d(2048, 256, 1, bias=False), nn.BatchNorm2d(256), nn.ReLU(inplace=True)),
            nn.Sequential(nn.Conv2d(2048, 256, 3, padding=6, dilation=6, bias=False), nn.BatchNorm2d(256), nn.ReLU(inplace=True)),
            nn.Sequential(nn.Conv2d(2048, 256, 3, padding=12, dilation=12, bias=False), nn.BatchNorm2d(256), nn.ReLU(inplace=True)),
            nn.Sequential(nn.Conv2d(2048, 256, 3, padding=18, dilation=18, bias=False), nn.BatchNorm2d(256), nn.ReLU(inplace=True))
        ])
        
        self.global_avg_pool = nn.Sequential(
            nn.AdaptiveAvgPool2d((1, 1)),
            nn.Conv2d(2048, 256, 1, bias=False), nn.BatchNorm2d(256), nn.ReLU(inplace=True)
        )
        
        self.fusion = nn.Sequential(
            nn.Conv2d(256 * 5, 256, 1, bias=False), nn.BatchNorm2d(256), nn.ReLU(inplace=True),
            nn.Dropout(0.5)
        )
        
        self.classifier = nn.Conv2d(256, num_classes, 1)
    
    def forward(self, x):
        """μμ „ν"""
        if not TORCH_AVAILABLE:
            return {
                'status': 'success',
                'model_name': self.model_name,
                'result': 'dummy_human_parsing',
                'num_classes': self.num_classes
            }
        
        input_size = x.size()[2:]
        
        # Backbone
        features = self.backbone(x)
        
        # ASPP
        aspp_features = []
        for aspp_layer in self.aspp:
            aspp_features.append(aspp_layer(features))
        
        # Global Average Pooling
        global_features = self.global_avg_pool(features)
        global_features = F.interpolate(global_features, size=features.size()[2:], mode='bilinear', align_corners=False)
        aspp_features.append(global_features)
        
        # Fusion
        fused_features = torch.cat(aspp_features, dim=1)
        fused_features = self.fusion(fused_features)
        
        # Classification
        output = self.classifier(fused_features)
        
        # Upsample to input size
        output = F.interpolate(output, size=input_size, mode='bilinear', align_corners=False)
        
        return output

class RealGMMModel(BaseRealAIModel if not TORCH_AVAILABLE else nn.Module):
    """μ‹¤μ  GMM λ¨λΈ (gmm_final.pth 44.7MB)"""
    
    def __init__(self, device: str = DEFAULT_DEVICE):
        if TORCH_AVAILABLE:
            super(RealGMMModel, self).__init__()
            self._init_pytorch_model()
        else:
            super().__init__(device)
        
        self.device = device
        self.model_name = "RealGMMModel"
        self.logger = logging.getLogger(f"{__name__}.RealGMMModel")
    
    def _init_pytorch_model(self):
        """PyTorch GMM λ¨λΈ κµ¬μ΅° μ΄κΈ°ν™”"""
        # Feature extractor for person image
        self.person_feature_extractor = nn.Sequential(
            nn.Conv2d(3, 64, 3, 1, 1), nn.BatchNorm2d(64), nn.ReLU(inplace=True),
            nn.Conv2d(64, 128, 3, 2, 1), nn.BatchNorm2d(128), nn.ReLU(inplace=True),
            nn.Conv2d(128, 256, 3, 2, 1), nn.BatchNorm2d(256), nn.ReLU(inplace=True),
            nn.AdaptiveAvgPool2d((8, 8))
        )
        
        # Feature extractor for cloth image  
        self.cloth_feature_extractor = nn.Sequential(
            nn.Conv2d(3, 64, 3, 1, 1), nn.BatchNorm2d(64), nn.ReLU(inplace=True),
            nn.Conv2d(64, 128, 3, 2, 1), nn.BatchNorm2d(128), nn.ReLU(inplace=True),
            nn.Conv2d(128, 256, 3, 2, 1), nn.BatchNorm2d(256), nn.ReLU(inplace=True),
            nn.AdaptiveAvgPool2d((8, 8))
        )
        
        # TPS parameter regression
        self.tps_regressor = nn.Sequential(
            nn.Flatten(),
            nn.Linear(256 * 8 * 8 * 2, 1024), nn.ReLU(inplace=True),
            nn.Dropout(0.5),
            nn.Linear(1024, 512), nn.ReLU(inplace=True),
            nn.Dropout(0.5),
            nn.Linear(512, 18)  # 6x3 TPS parameters
        )
    
    def forward(self, person_img, cloth_img):
        """μμ „ν"""
        if not TORCH_AVAILABLE:
            return {
                'status': 'success',
                'model_name': self.model_name,
                'result': 'dummy_geometric_matching'
            }
        
        # Feature extraction
        person_features = self.person_feature_extractor(person_img)
        cloth_features = self.cloth_feature_extractor(cloth_img)
        
        # Concatenate features for TPS regression
        combined_features = torch.cat([person_features, cloth_features], dim=1)
        tps_params = self.tps_regressor(combined_features)
        
        # Reshape TPS parameters to 6x3 matrix
        tps_params = tps_params.view(-1, 6, 3)
        
        return {'tps_params': tps_params}

class RealTPSModel(BaseRealAIModel if not TORCH_AVAILABLE else nn.Module):
    """μ‹¤μ  TPS λ¨λΈ (tps_network.pth 527.8MB)"""
    
    def __init__(self, device: str = DEFAULT_DEVICE):
        if TORCH_AVAILABLE:
            super(RealTPSModel, self).__init__()
            self._init_pytorch_model()
        else:
            super().__init__(device)
        
        self.device = device
        self.model_name = "RealTPSModel"
        self.logger = logging.getLogger(f"{__name__}.RealTPSModel")
    
    def _init_pytorch_model(self):
        """PyTorch TPS λ¨λΈ κµ¬μ΅° μ΄κΈ°ν™”"""
        # TPS λ„¤νΈμ›ν¬ (κ°„μ†ν™”)
        self.localization = nn.Sequential(
            nn.Conv2d(3, 64, 7, 2, 3), nn.ReLU(inplace=True),
            nn.MaxPool2d(2, 2),
            nn.Conv2d(64, 128, 5, 2, 2), nn.ReLU(inplace=True),
            nn.MaxPool2d(2, 2),
            nn.Conv2d(128, 256, 3, 2, 1), nn.ReLU(inplace=True),
            nn.AdaptiveAvgPool2d((6, 6))
        )
        
        self.fc_loc = nn.Sequential(
            nn.Linear(256 * 6 * 6, 1024), nn.ReLU(inplace=True),
            nn.Dropout(0.5),
            nn.Linear(1024, 512), nn.ReLU(inplace=True),
            nn.Dropout(0.5),
            nn.Linear(512, 18)  # 6x3 TPS control points
        )
    
    def forward(self, x):
        """μμ „ν"""
        if not TORCH_AVAILABLE:
            return {
                'status': 'success',
                'model_name': self.model_name,
                'result': 'dummy_tps_transformation'
            }
        
        # Localization network
        loc_features = self.localization(x)
        loc_features = loc_features.view(loc_features.size(0), -1)
        
        # Get TPS parameters
        tps_params = self.fc_loc(loc_features)
        tps_params = tps_params.view(-1, 6, 3)
        
        return {'tps_params': tps_params}

# ==============================================
# π”¥ 5. AI λ¨λΈ ν©ν† λ¦¬
# ==============================================

class RealAIModelFactory:
    """μ‹¤μ  AI λ¨λΈ ν©ν† λ¦¬"""
    
    MODEL_REGISTRY = {
        # μ„Έκ·Έλ©ν…μ΄μ… λ¨λΈλ“¤
        "RealU2NetModel": RealU2NetModel,
        "U2NetModel": RealU2NetModel,
        "u2net": RealU2NetModel,
        
        # SAM λ¨λΈλ“¤
        "RealSAMModel": RealSAMModel,
        "SAMModel": RealSAMModel,
        "sam": RealSAMModel,
        "sam_vit_h": RealSAMModel,
        
        "RealMobileSAMModel": RealMobileSAMModel,
        "MobileSAMModel": RealMobileSAMModel,
        "mobile_sam": RealMobileSAMModel,
        
        # μΈμ²΄ νμ‹± λ¨λΈλ“¤
        "RealGraphonomyModel": RealGraphonomyModel,
        "GraphonomyModel": RealGraphonomyModel,
        "graphonomy": RealGraphonomyModel,
        "human_parsing": RealGraphonomyModel,
        
        # κΈ°ν•ν•™μ  λ§¤μΉ­ λ¨λΈλ“¤
        "RealGMMModel": RealGMMModel,
        "GMMModel": RealGMMModel,
        "gmm": RealGMMModel,
        "geometric_matching": RealGMMModel,
        
        "RealTPSModel": RealTPSModel,
        "TPSModel": RealTPSModel,
        "tps": RealTPSModel,
        "tps_network": RealTPSModel,
    }
    
    @classmethod
    def create_model(
        cls, 
        model_name: str, 
        device: str = DEFAULT_DEVICE,
        **kwargs
    ) -> BaseRealAIModel:
        """μ‹¤μ  AI λ¨λΈ μƒμ„±"""
        try:
            # λ¨λΈ μ΄λ¦„ μ •κ·ν™”
            normalized_name = cls._normalize_model_name(model_name)
            
            if normalized_name not in cls.MODEL_REGISTRY:
                logger.warning(f"β οΈ μ• μ μ—†λ” λ¨λΈ: {model_name}, κΈ°λ³Έ λ¨λΈ λ°ν™")
                return BaseRealAIModel(device)
            
            model_class = cls.MODEL_REGISTRY[normalized_name]
            model = model_class(device=device, **kwargs)
            
            logger.info(f"β… μ‹¤μ  AI λ¨λΈ μƒμ„± μ„±κ³µ: {model_name} -> {model_class.__name__}")
            return model
            
        except Exception as e:
            logger.error(f"β λ¨λΈ μƒμ„± μ‹¤ν¨ {model_name}: {e}")
            return BaseRealAIModel(device)
    
    @classmethod
    def _normalize_model_name(cls, model_name: str) -> str:
        """λ¨λΈ μ΄λ¦„ μ •κ·ν™”"""
        # νμΌλ…μ—μ„ λ¨λΈ νƒ€μ… μ¶”μ¶
        if "u2net" in model_name.lower():
            return "RealU2NetModel"
        elif "sam_vit_h" in model_name.lower():
            return "RealSAMModel"
        elif "mobile_sam" in model_name.lower():
            return "RealMobileSAMModel"
        elif "graphonomy" in model_name.lower() or "schp" in model_name.lower():
            return "RealGraphonomyModel"
        elif "gmm" in model_name.lower():
            return "RealGMMModel"
        elif "tps" in model_name.lower():
            return "RealTPSModel"
        else:
            return model_name
    
    @classmethod
    def get_available_models(cls) -> List[str]:
        """μ‚¬μ© κ°€λ¥ν• λ¨λΈ λ©λ΅"""
        return list(cls.MODEL_REGISTRY.keys())
    
    @classmethod
    def register_model(cls, name: str, model_class: type):
        """μƒ λ¨λΈ λ“±λ΅"""
        cls.MODEL_REGISTRY[name] = model_class
        logger.info(f"π“ μƒ λ¨λΈ λ“±λ΅: {name}")

# ==============================================
# π”¥ 6. νΈμ ν•¨μλ“¤
# ==============================================

def load_model_checkpoint_safe(
    model: BaseRealAIModel, 
    checkpoint_path: Union[str, Path], 
    device: str = DEFAULT_DEVICE
) -> bool:
    """μ•μ „ν• λ¨λΈ μ²΄ν¬ν¬μΈνΈ λ΅λ”©"""
    try:
        if not TORCH_AVAILABLE:
            logger.warning("β οΈ PyTorch μ—†μ, μ²΄ν¬ν¬μΈνΈ λ΅λ”© κ±΄λ„λ€")
            return True
        
        return model.load_checkpoint_safe(checkpoint_path)
        
    except Exception as e:
        logger.error(f"β μ²΄ν¬ν¬μΈνΈ λ΅λ”© ν•¨μ μ‹¤ν¨: {e}")
        return False

def create_model_from_checkpoint(
    checkpoint_path: Union[str, Path], 
    model_type: Optional[str] = None,
    device: str = DEFAULT_DEVICE
) -> Optional[BaseRealAIModel]:
    """μ²΄ν¬ν¬μΈνΈμ—μ„ λ¨λΈ μƒμ„± λ° λ΅λ”©"""
    try:
        checkpoint_path = Path(checkpoint_path)
        
        # λ¨λΈ νƒ€μ… μλ™ κ°μ§€
        if model_type is None:
            model_type = _detect_model_type_from_path(checkpoint_path)
        
        # λ¨λΈ μƒμ„±
        model = RealAIModelFactory.create_model(model_type, device)
        
        # μ²΄ν¬ν¬μΈνΈ λ΅λ”©
        if checkpoint_path.exists():
            success = model.load_checkpoint_safe(checkpoint_path)
            if success:
                logger.info(f"β… μ²΄ν¬ν¬μΈνΈμ—μ„ λ¨λΈ μƒμ„± μ„±κ³µ: {checkpoint_path.name}")
                return model
            else:
                logger.error(f"β μ²΄ν¬ν¬μΈνΈ λ΅λ”© μ‹¤ν¨: {checkpoint_path.name}")
                return None
        else:
            logger.error(f"β μ²΄ν¬ν¬μΈνΈ νμΌ μ—†μ: {checkpoint_path}")
            return None
            
    except Exception as e:
        logger.error(f"β μ²΄ν¬ν¬μΈνΈμ—μ„ λ¨λΈ μƒμ„± μ‹¤ν¨: {e}")
        return None

def _detect_model_type_from_path(checkpoint_path: Path) -> str:
    """νμΌ κ²½λ΅μ—μ„ λ¨λΈ νƒ€μ… μλ™ κ°μ§€"""
    filename = checkpoint_path.name.lower()
    
    if "u2net" in filename:
        return "RealU2NetModel"
    elif "sam_vit_h" in filename:
        return "RealSAMModel"
    elif "mobile_sam" in filename:
        return "RealMobileSAMModel"
    elif "schp" in filename or "graphonomy" in filename:
        return "RealGraphonomyModel"
    elif "gmm" in filename:
        return "RealGMMModel"
    elif "tps" in filename:
        return "RealTPSModel"
    else:
        logger.warning(f"β οΈ λ¨λΈ νƒ€μ… μλ™ κ°μ§€ μ‹¤ν¨: {filename}")
        return "RealU2NetModel"  # κΈ°λ³Έκ°’

def get_model_info(model: BaseRealAIModel) -> Dict[str, Any]:
    """λ¨λΈ μ •λ³΄ μ΅°ν"""
    try:
        info = model.get_model_info()
        
        # μ¶”κ°€ μ •λ³΄
        if TORCH_AVAILABLE and hasattr(model, 'parameters'):
            try:
                info["parameters"] = sum(p.numel() for p in model.parameters())
            except:
                info["parameters"] = 0
        else:
            info["parameters"] = 0
        
        info["safetensors_available"] = SAFETENSORS_AVAILABLE
        info["is_m3_max"] = IS_M3_MAX
        
        return info
        
    except Exception as e:
        logger.error(f"β λ¨λΈ μ •λ³΄ μ΅°ν μ‹¤ν¨: {e}")
        return {"error": str(e)}

def cleanup_memory():
    """λ©”λ¨λ¦¬ μ •λ¦¬"""
    try:
        # Python κ°€λΉ„μ§€ μ»¬λ ‰μ…
        gc.collect()
        
        # GPU λ©”λ¨λ¦¬ μ •λ¦¬
        if TORCH_AVAILABLE:
            if DEFAULT_DEVICE == "mps" and IS_M3_MAX:
                safe_mps_empty_cache()
            elif DEFAULT_DEVICE == "cuda":
                torch.cuda.empty_cache()
        
        logger.info("β… λ©”λ¨λ¦¬ μ •λ¦¬ μ™„λ£")
        
    except Exception as e:
        logger.warning(f"β οΈ λ©”λ¨λ¦¬ μ •λ¦¬ μ‹¤ν¨: {e}")

# ==============================================
# π”¥ 7. λ¨λ“ λ‚΄λ³΄λ‚΄κΈ°
# ==============================================

__all__ = [
    # λ΅λ” ν΄λμ¤
    'SafeCheckpointLoader',
    
    # κΈ°λ³Έ ν΄λμ¤λ“¤
    'BaseRealAIModel',
    'RealAIModelFactory',
    
    # κµ¬μ²΄μ μΈ λ¨λΈλ“¤
    'RealU2NetModel',
    'RealSAMModel', 
    'RealMobileSAMModel',
    'RealGraphonomyModel',
    'RealGMMModel',
    'RealTPSModel',
    
    # νΈμ ν•¨μλ“¤
    'load_model_checkpoint_safe',
    'create_model_from_checkpoint',
    'get_model_info',
    'cleanup_memory',
    
    # μƒμλ“¤
    'TORCH_AVAILABLE',
    'SAFETENSORS_AVAILABLE',
    'DEFAULT_DEVICE',
    'IS_M3_MAX'
]

# μ΄κΈ°ν™” λ΅κ·Έ
logger.info("π”¥" + "="*70)
logger.info("β… MyCloset AI - μ‹¤μ  AI λ¨λΈ ν΄λμ¤λ“¤ v2.0 λ΅λ“ μ™„λ£")
logger.info(f"π¤– PyTorch μƒνƒ: {'β… μ‚¬μ© κ°€λ¥' if TORCH_AVAILABLE else 'β μ‚¬μ© λ¶κ°€'}")
logger.info(f"π”’ SafeTensors μƒνƒ: {'β… μ‚¬μ© κ°€λ¥' if SAFETENSORS_AVAILABLE else 'β μ‚¬μ© λ¶κ°€'}")
logger.info(f"π”§ λ””λ°”μ΄μ¤: {DEFAULT_DEVICE}")
logger.info(f"π M3 Max μµμ ν™”: {'β… ν™μ„±ν™”' if IS_M3_MAX else 'β λΉ„ν™μ„±ν™”'}")
logger.info("π― μ²΄ν¬ν¬μΈνΈ λ΅λ”© μ¤λ¥ μ™„μ „ ν•΄κ²°")
logger.info("β΅ 3λ‹¨κ³„ μ•μ „ λ΅λ”© (weights_only=True β†’ False β†’ Legacy)")
logger.info("π”— μ‹¤μ  GitHub ν”„λ΅μ νΈ κµ¬μ΅° μ™„μ „ λ°μ")
logger.info("π’Ύ μ‹¤μ  μ²΄ν¬ν¬μΈνΈ νμΌλ“¤κ³Ό μ™„μ „ λ§¤μΉ­")
logger.info("π”„ μν™μ°Έμ΅° λ°©μ§€ - λ…λ¦½μ  λ¨λ“ μ„¤κ³„")
logger.info("π conda ν™κ²½ μ°μ„  μ§€μ›")
logger.info("="*70)