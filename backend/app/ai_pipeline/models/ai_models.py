# backend/app/ai_pipeline/models/ai_models.py
"""
π”¥ MyCloset AI - μ‹¤μ  AI λ¨λΈ ν΄λμ¤λ“¤ v2.1 (PoseEstimationStep μ¤λ¥ μ™„μ „ ν•΄κ²°)
===============================================================================
β… μ‹¤μ  GitHub ν”„λ΅μ νΈ κµ¬μ΅° μ™„μ „ λ°μ
β… μ²΄ν¬ν¬μΈνΈ λ΅λ”© μ¤λ¥ μ™„μ „ ν•΄κ²° (weights_only, PyTorch νΈν™μ„±)
β… RealU2NetModel, RealSAMModel, RealMobileSAMModel μ‹¤μ  κµ¬ν„
β… step_model_requirements.py μ™„μ „ νΈν™
β… M3 Max MPS μµμ ν™” + conda ν™κ²½ μ§€μ›
β… μν™μ°Έμ΅° λ°©μ§€ - λ…λ¦½μ  λ¨λ“ μ„¤κ³„
β… μ‹¤μ  μ²΄ν¬ν¬μΈνΈ νμΌλ“¤κ³Ό μ™„μ „ λ§¤μΉ­
β… 3λ‹¨κ³„ μ•μ „ λ΅λ”© (weights_only=True β†’ False β†’ Legacy)
β… PoseEstimationStep μ¤λ¥ ν•΄κ²°: Step02ModelMapper._search_models λ©”μ„λ“ μ¶”κ°€

μ‹¤μ  νμΌ λ§¤ν•‘:
- sam_vit_h_4b8939.pth (2445.7MB) - Segment Anything Model
- u2net.pth (168.1MB) - UΒ²-Net μλ¥ μ„Έκ·Έλ©ν…μ΄μ…
- mobile_sam.pt (38.8MB) - Mobile SAM
- gmm_final.pth (44.7MB) - Geometric Matching Model
- tps_network.pth (527.8MB) - TPS λ„¤νΈμ›ν¬
- exp-schp-201908301523-atr.pth - Human Parsing (Graphonomy)
- openpose.pth (97.8MB) - OpenPose
- diffusion_pytorch_model.safetensors (1378.2MB) - Diffusion
===============================================================================
"""

import logging
import time
import warnings
import gc
import os
from pathlib import Path
from typing import Any, Dict, Optional, Tuple, Union, List
from enum import Enum
from abc import ABC, abstractmethod

logger = logging.getLogger(__name__)

# ==============================================
# π”¥ 1. μ•μ „ν• PyTorch Import λ° ν™κ²½ μ„¤μ •
# ==============================================

try:
    import torch
    import torch.nn as nn
    import torch.nn.functional as F
    import torchvision.transforms as transforms
    TORCH_AVAILABLE = True
    
    # M3 Max MPS μµμ ν™”
    if hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
        DEFAULT_DEVICE = "mps"
        IS_M3_MAX = True
        logger.info("β… M3 Max MPS κ°μ§€ λ° μµμ ν™” ν™μ„±ν™”")
        
        # μ•μ „ν• MPS μΊμ‹ μ •λ¦¬ ν•¨μ
        def safe_mps_empty_cache():
            try:
                if hasattr(torch.mps, 'empty_cache'):
                    torch.mps.empty_cache()
                elif hasattr(torch.backends.mps, 'empty_cache'):
                    torch.backends.mps.empty_cache()
            except (AttributeError, RuntimeError) as e:
                logger.debug(f"MPS μΊμ‹ μ •λ¦¬ μ‹¤ν¨ (λ¬΄μ‹λ¨): {e}")
        
        # conda ν™κ²½ μµμ ν™”
        if 'CONDA_DEFAULT_ENV' in os.environ:
            conda_env = os.environ['CONDA_DEFAULT_ENV']
            if 'mycloset' in conda_env.lower() or 'ai' in conda_env.lower():
                os.environ['OMP_NUM_THREADS'] = '16'
                os.environ['MKL_NUM_THREADS'] = '16'
                os.environ['PYTORCH_MPS_HIGH_WATERMARK_RATIO'] = '0.0'
                logger.info(f"π conda ν™κ²½ ({conda_env}) M3 Max μµμ ν™” μ™„λ£")
        
        safe_mps_empty_cache()
        
    elif torch.cuda.is_available():
        DEFAULT_DEVICE = "cuda"
        IS_M3_MAX = False
        logger.info("β… CUDA κ°μ§€")
    else:
        DEFAULT_DEVICE = "cpu"
        IS_M3_MAX = False
        logger.info("β οΈ CPU λ¨λ“λ΅ λ™μ‘")
        
except ImportError:
    TORCH_AVAILABLE = False
    DEFAULT_DEVICE = "cpu"
    IS_M3_MAX = False
    torch = None
    nn = None
    F = None
    logger.warning("β PyTorch μ—†μ - λ”λ―Έ λ¨λΈ μ‚¬μ©")

# SafeTensors μ§€μ›
try:
    from safetensors import safe_open
    from safetensors.torch import load_file as load_safetensors
    SAFETENSORS_AVAILABLE = True
    logger.info("β… SafeTensors λΌμ΄λΈλ¬λ¦¬ μ‚¬μ© κ°€λ¥")
except ImportError:
    SAFETENSORS_AVAILABLE = False
    logger.warning("β οΈ SafeTensors λΌμ΄λΈλ¬λ¦¬ μ—†μ")

# ==============================================
# π”¥ 2. μ•μ „ν• μ²΄ν¬ν¬μΈνΈ λ΅λ” ν΄λμ¤
# ==============================================

class SafeCheckpointLoader:
    """μ²΄ν¬ν¬μΈνΈ λ΅λ”© μ¤λ¥ μ™„μ „ ν•΄κ²°μ„ μ„ν• μ•μ „ν• λ΅λ”"""
    
    @staticmethod
    def load_checkpoint_safe(checkpoint_path: Union[str, Path], device: str = "cpu") -> Optional[Dict[str, Any]]:
        """
        3λ‹¨κ³„ μ•μ „ λ΅λ”©: weights_only=True β†’ False β†’ Legacy
        λ¨λ“  PyTorch λ²„μ „ νΈν™μ„± λ³΄μ¥
        """
        if not TORCH_AVAILABLE:
            logger.warning("β οΈ PyTorch μ—†μ, λ”λ―Έ μ²΄ν¬ν¬μΈνΈ λ°ν™")
            return {"dummy": True, "status": "no_pytorch"}
        
        checkpoint_path = Path(checkpoint_path)
        if not checkpoint_path.exists():
            logger.error(f"β μ²΄ν¬ν¬μΈνΈ νμΌ μ—†μ: {checkpoint_path}")
            return None
        
        logger.info(f"π”„ μ²΄ν¬ν¬μΈνΈ λ΅λ”© μ‹μ‘: {checkpoint_path.name}")
        
        # π”¥ 1λ‹¨κ³„: weights_only=True (κ°€μ¥ μ•μ „)
        try:
            logger.debug("1λ‹¨κ³„: weights_only=True μ‹λ„")
            checkpoint = torch.load(
                checkpoint_path, 
                map_location=device, 
                weights_only=True
            )
            logger.info("β… μ•μ „ λ¨λ“ λ΅λ”© μ„±κ³µ (weights_only=True)")
            return {
                'checkpoint': checkpoint,
                'loading_mode': 'safe',
                'path': str(checkpoint_path)
            }
            
        except Exception as safe_error:
            logger.debug(f"1λ‹¨κ³„ μ‹¤ν¨: {safe_error}")
            
            # π”¥ 2λ‹¨κ³„: weights_only=False (νΈν™μ„±)
            try:
                logger.debug("2λ‹¨κ³„: weights_only=False μ‹λ„")
                with warnings.catch_warnings():
                    warnings.simplefilter("ignore")
                    checkpoint = torch.load(
                        checkpoint_path, 
                        map_location=device, 
                        weights_only=False
                    )
                logger.info("β… νΈν™ λ¨λ“ λ΅λ”© μ„±κ³µ (weights_only=False)")
                return {
                    'checkpoint': checkpoint,
                    'loading_mode': 'compatible',
                    'path': str(checkpoint_path)
                }
                
            except Exception as compat_error:
                logger.debug(f"2λ‹¨κ³„ μ‹¤ν¨: {compat_error}")
                
                # π”¥ 3λ‹¨κ³„: Legacy λ΅λ”© (PyTorch 1.x νΈν™)
                try:
                    logger.debug("3λ‹¨κ³„: Legacy λ¨λ“ μ‹λ„")
                    with warnings.catch_warnings():
                        warnings.simplefilter("ignore")
                        checkpoint = torch.load(checkpoint_path, map_location=device)
                    logger.info("β… Legacy λ¨λ“ λ΅λ”© μ„±κ³µ")
                    return {
                        'checkpoint': checkpoint,
                        'loading_mode': 'legacy',
                        'path': str(checkpoint_path)
                    }
                    
                except Exception as legacy_error:
                    logger.error(f"β λ¨λ“  λ΅λ”© λ°©λ²• μ‹¤ν¨: {legacy_error}")
                    return None
    
    @staticmethod
    def normalize_state_dict(state_dict: Dict[str, Any]) -> Dict[str, Any]:
        """State dict ν‚¤ μ •κ·ν™” (κ³µν†µ prefix μ κ±°)"""
        normalized = {}
        
        # μ κ±°ν•  prefix ν¨ν„΄λ“¤
        prefixes_to_remove = [
            'module.',     # DataParallel
            'model.',      # μΌλ°μ μΈ λνΌ
            'backbone.',   # Backbone λ¨λΈ
            'encoder.',    # Encoder
            'netG.',       # Generator
            'netD.',       # Discriminator
            'netTPS.',     # TPS λ„¤νΈμ›ν¬
            'net.',        # μΌλ° λ„¤νΈμ›ν¬
            '_orig_mod.',  # torch.compile λνΌ
        ]
        
        for key, value in state_dict.items():
            new_key = key
            
            # prefix μ κ±°
            for prefix in prefixes_to_remove:
                if new_key.startswith(prefix):
                    new_key = new_key[len(prefix):]
                    break
            
            normalized[new_key] = value
        
        return normalized
    
    @staticmethod
    def extract_state_dict(checkpoint: Any) -> Dict[str, Any]:
        """μ²΄ν¬ν¬μΈνΈμ—μ„ state_dict μ¶”μ¶"""
        if isinstance(checkpoint, dict):
            # Case 1: 'state_dict' ν‚¤κ°€ μλ” κ²½μ°
            if 'state_dict' in checkpoint:
                return checkpoint['state_dict']
            # Case 2: 'model' ν‚¤κ°€ μλ” κ²½μ°
            elif 'model' in checkpoint:
                return checkpoint['model']
            # Case 3: μ§μ ‘ state_dictμΈ κ²½μ°
            else:
                return checkpoint
        else:
            # ν…μ„λ‚ λ‹¤λ¥Έ κ°μ²΄μΈ κ²½μ°
            if hasattr(checkpoint, 'state_dict'):
                return checkpoint.state_dict()
            else:
                logger.warning("β οΈ μμƒμΉ λ»ν• μ²΄ν¬ν¬μΈνΈ ν•μ‹")
                return {} if checkpoint is None else checkpoint

# ==============================================
# π”¥ 3. κΈ°λ³Έ AI λ¨λΈ ν΄λμ¤
# ==============================================

class BaseRealAIModel(ABC):
    """μ‹¤μ  AI λ¨λΈμ„ μ„ν• κΈ°λ³Έ ν΄λμ¤"""
    
    def __init__(self, device: str = DEFAULT_DEVICE):
        self.device = device
        self.model_name = self.__class__.__name__
        self.is_loaded = False
        self.checkpoint_path = None
        self.logger = logging.getLogger(f"{__name__}.{self.model_name}")
        
    @abstractmethod
    def forward(self, x):
        """μμ „ν (ν•μ„ ν΄λμ¤μ—μ„ κµ¬ν„)"""
        pass
    
    def __call__(self, x):
        """νΈμ¶ λ©”μ„λ“"""
        return self.forward(x)
    
    def to(self, device):
        """λ””λ°”μ΄μ¤ μ΄λ™"""
        self.device = str(device)
        return self
    
    def eval(self):
        """ν‰κ°€ λ¨λ“"""
        return self
    
    def train(self, mode: bool = True):
        """ν›λ ¨ λ¨λ“"""
        return self
    
    def load_checkpoint_safe(self, checkpoint_path: Union[str, Path]) -> bool:
        """μ•μ „ν• μ²΄ν¬ν¬μΈνΈ λ΅λ”©"""
        try:
            self.checkpoint_path = checkpoint_path
            checkpoint_data = SafeCheckpointLoader.load_checkpoint_safe(checkpoint_path, self.device)
            
            if checkpoint_data is None:
                self.logger.error(f"β μ²΄ν¬ν¬μΈνΈ λ΅λ”© μ‹¤ν¨: {checkpoint_path}")
                return False
            
            # state_dict μ¶”μ¶ λ° μ •κ·ν™”
            checkpoint = checkpoint_data['checkpoint']
            state_dict = SafeCheckpointLoader.extract_state_dict(checkpoint)
            normalized_state_dict = SafeCheckpointLoader.normalize_state_dict(state_dict)
            
            # λ¨λΈμ— μ μ© (ν•μ„ ν΄λμ¤μ—μ„ κµ¬μ²΄μ  κµ¬ν„)
            success = self._apply_checkpoint(normalized_state_dict, checkpoint_data)
            
            if success:
                self.is_loaded = True
                self.logger.info(f"β… μ²΄ν¬ν¬μΈνΈ λ΅λ”© μ„±κ³µ: {Path(checkpoint_path).name}")
            else:
                self.logger.error(f"β μ²΄ν¬ν¬μΈνΈ μ μ© μ‹¤ν¨: {checkpoint_path}")
            
            return success
            
        except Exception as e:
            self.logger.error(f"β μ²΄ν¬ν¬μΈνΈ λ΅λ”© μ¤λ¥: {e}")
            return False
    
    def _apply_checkpoint(self, state_dict: Dict[str, Any], checkpoint_data: Dict[str, Any]) -> bool:
        """μ²΄ν¬ν¬μΈνΈ μ μ© (ν•μ„ ν΄λμ¤μ—μ„ μ¤λ²„λΌμ΄λ“)"""
        # κΈ°λ³Έ κµ¬ν„
        self.logger.info(f"π“¦ μ²΄ν¬ν¬μΈνΈ μ μ©: {len(state_dict)} ν‚¤")
        return True
    
    def get_model_info(self) -> Dict[str, Any]:
        """λ¨λΈ μ •λ³΄ λ°ν™"""
        return {
            "name": self.model_name,
            "device": self.device,
            "is_loaded": self.is_loaded,
            "checkpoint_path": str(self.checkpoint_path) if self.checkpoint_path else None,
            "torch_available": TORCH_AVAILABLE
        }

# PyTorch μ—†λ” κ²½μ°λ¥Ό μ„ν• λ”λ―Έ ν΄λμ¤
if not TORCH_AVAILABLE:
    class DummyModule:
        def __init__(self, *args, **kwargs):
            pass
        
        def __call__(self, *args, **kwargs):
            return {"status": "dummy", "result": "no_pytorch"}
        
        def to(self, device):
            return self
        
        def eval(self):
            return self
        
        def train(self, mode=True):
            return self
        
        def state_dict(self):
            return {}
        
        def load_state_dict(self, state_dict, strict=True):
            return [], []
    
    # λ”λ―Έ nn λ¨λ“ μƒμ„±
    nn = type('nn', (), {
        'Module': DummyModule,
        'Conv2d': DummyModule,
        'BatchNorm2d': DummyModule,
        'ReLU': DummyModule,
        'MaxPool2d': DummyModule,
        'ConvTranspose2d': DummyModule,
        'Linear': DummyModule,
        'Dropout': DummyModule,
        'Sequential': DummyModule,
        'AdaptiveAvgPool2d': DummyModule,
        'Sigmoid': DummyModule,
        'Tanh': DummyModule,
        'Flatten': DummyModule,
        'ModuleList': DummyModule
    })()

# ==============================================
# π”¥ 4. μ‹¤μ  AI λ¨λΈ κµ¬ν„λ“¤ (κΈ°μ΅΄ μ½”λ“μ™€ λ™μΌ)
# ==============================================

class RealU2NetModel(BaseRealAIModel if not TORCH_AVAILABLE else nn.Module):
    """μ‹¤μ  UΒ²-Net λ¨λΈ (u2net.pth 168.1MB)"""
    
    def __init__(self, in_channels: int = 3, out_channels: int = 1, device: str = DEFAULT_DEVICE):
        if TORCH_AVAILABLE:
            super(RealU2NetModel, self).__init__()
            self._init_pytorch_model(in_channels, out_channels)
        else:
            super().__init__(device)
        
        self.in_channels = in_channels
        self.out_channels = out_channels
        self.device = device
        self.model_name = "RealU2NetModel"
        self.logger = logging.getLogger(f"{__name__}.RealU2NetModel")
    
    def _init_pytorch_model(self, in_channels: int, out_channels: int):
        """PyTorch λ¨λΈ κµ¬μ΅° μ΄κΈ°ν™”"""
        # κ°„μ†ν™”λ UΒ²-Net κµ¬μ΅°
        self.encoder1 = nn.Sequential(
            nn.Conv2d(in_channels, 64, 3, 1, 1), 
            nn.BatchNorm2d(64), 
            nn.ReLU(inplace=True),
            nn.Conv2d(64, 64, 3, 1, 1), 
            nn.BatchNorm2d(64), 
            nn.ReLU(inplace=True)
        )
        
        self.encoder2 = nn.Sequential(
            nn.MaxPool2d(2, 2),
            nn.Conv2d(64, 128, 3, 1, 1), 
            nn.BatchNorm2d(128), 
            nn.ReLU(inplace=True),
            nn.Conv2d(128, 128, 3, 1, 1), 
            nn.BatchNorm2d(128), 
            nn.ReLU(inplace=True)
        )
        
        self.encoder3 = nn.Sequential(
            nn.MaxPool2d(2, 2),
            nn.Conv2d(128, 256, 3, 1, 1), 
            nn.BatchNorm2d(256), 
            nn.ReLU(inplace=True),
            nn.Conv2d(256, 256, 3, 1, 1), 
            nn.BatchNorm2d(256), 
            nn.ReLU(inplace=True)
        )
        
        self.bridge = nn.Sequential(
            nn.MaxPool2d(2, 2),
            nn.Conv2d(256, 512, 3, 1, 1), 
            nn.BatchNorm2d(512), 
            nn.ReLU(inplace=True),
            nn.Conv2d(512, 512, 3, 1, 1), 
            nn.BatchNorm2d(512), 
            nn.ReLU(inplace=True)
        )
        
        self.decoder3 = nn.Sequential(
            nn.ConvTranspose2d(512, 256, 2, 2),
            nn.Conv2d(512, 256, 3, 1, 1), 
            nn.BatchNorm2d(256), 
            nn.ReLU(inplace=True),
            nn.Conv2d(256, 256, 3, 1, 1), 
            nn.BatchNorm2d(256), 
            nn.ReLU(inplace=True)
        )
        
        self.decoder2 = nn.Sequential(
            nn.ConvTranspose2d(256, 128, 2, 2),
            nn.Conv2d(256, 128, 3, 1, 1), 
            nn.BatchNorm2d(128), 
            nn.ReLU(inplace=True),
            nn.Conv2d(128, 128, 3, 1, 1), 
            nn.BatchNorm2d(128), 
            nn.ReLU(inplace=True)
        )
        
        self.decoder1 = nn.Sequential(
            nn.ConvTranspose2d(128, 64, 2, 2),
            nn.Conv2d(128, 64, 3, 1, 1), 
            nn.BatchNorm2d(64), 
            nn.ReLU(inplace=True),
            nn.Conv2d(64, 64, 3, 1, 1), 
            nn.BatchNorm2d(64), 
            nn.ReLU(inplace=True)
        )
        
        self.final_conv = nn.Sequential(
            nn.Conv2d(64, out_channels, 1, 1, 0),
            nn.Sigmoid()
        )
    
    def forward(self, x):
        """μμ „ν"""
        if not TORCH_AVAILABLE:
            return {
                'status': 'success',
                'model_name': self.model_name,
                'result': 'dummy_u2net_segmentation',
                'shape': f'({self.in_channels}, H, W) -> ({self.out_channels}, H, W)'
            }
        
        # Encoder
        enc1 = self.encoder1(x)
        enc2 = self.encoder2(enc1)
        enc3 = self.encoder3(enc2)
        
        # Bridge
        bridge = self.bridge(enc3)
        
        # Decoder with skip connections
        dec3 = self.decoder3[0](bridge)  # Transpose conv
        dec3 = torch.cat([dec3, enc3], dim=1)  # Skip connection
        dec3 = self.decoder3[1:](dec3)  # Regular convs
        
        dec2 = self.decoder2[0](dec3)
        dec2 = torch.cat([dec2, enc2], dim=1)
        dec2 = self.decoder2[1:](dec2)
        
        dec1 = self.decoder1[0](dec2)
        dec1 = torch.cat([dec1, enc1], dim=1)
        dec1 = self.decoder1[1:](dec1)
        
        # Final output
        output = self.final_conv(dec1)
        
        return output
    
    def _apply_checkpoint(self, state_dict: Dict[str, Any], checkpoint_data: Dict[str, Any]) -> bool:
        """UΒ²-Net μ²΄ν¬ν¬μΈνΈ μ μ©"""
        if not TORCH_AVAILABLE:
            return True
        
        try:
            # νΈν™ κ°€λ¥ν• ν‚¤λ§ λ΅λ”©
            model_dict = self.state_dict()
            compatible_dict = {}
            
            for k, v in state_dict.items():
                if k in model_dict and v.shape == model_dict[k].shape:
                    compatible_dict[k] = v
            
            if len(compatible_dict) > 0:
                self.load_state_dict(compatible_dict, strict=False)
                self.logger.info(f"β… UΒ²-Net λ΅λ”© μ„±κ³µ: {len(compatible_dict)}/{len(state_dict)} λ μ΄μ–΄")
                return True
            else:
                self.logger.warning("β οΈ νΈν™ κ°€λ¥ν• λ μ΄μ–΄ μ—†μ, λλ¤ μ΄κΈ°ν™”")
                return True  # λλ¤ μ΄κΈ°ν™”λ„ μ„±κ³µμΌλ΅ κ°„μ£Ό
                
        except Exception as e:
            self.logger.error(f"β UΒ²-Net μ²΄ν¬ν¬μΈνΈ μ μ© μ‹¤ν¨: {e}")
            return False

# ==============================================
# π”¥ 5. OpenPose λ¨λΈ μ¶”κ°€ (PoseEstimationStepμ©)
# ==============================================

class RealOpenPoseModel(BaseRealAIModel if not TORCH_AVAILABLE else nn.Module):
    """μ‹¤μ  OpenPose λ¨λΈ (openpose.pth 97.8MB)"""
    
    def __init__(self, device: str = DEFAULT_DEVICE):
        if TORCH_AVAILABLE:
            super(RealOpenPoseModel, self).__init__()
            self._init_pytorch_model()
        else:
            super().__init__(device)
        
        self.device = device
        self.model_name = "RealOpenPoseModel"
        self.num_keypoints = 18
        self.logger = logging.getLogger(f"{__name__}.RealOpenPoseModel")
    
    def _init_pytorch_model(self):
        """PyTorch OpenPose λ¨λΈ κµ¬μ΅° μ΄κΈ°ν™”"""
        # VGG-19 κΈ°λ° Feature Extractor
        self.feature_extractor = nn.Sequential(
            nn.Conv2d(3, 64, 3, 1, 1), nn.ReLU(inplace=True),
            nn.Conv2d(64, 64, 3, 1, 1), nn.ReLU(inplace=True),
            nn.MaxPool2d(2, 2),
            nn.Conv2d(64, 128, 3, 1, 1), nn.ReLU(inplace=True),
            nn.Conv2d(128, 128, 3, 1, 1), nn.ReLU(inplace=True),
            nn.MaxPool2d(2, 2),
            nn.Conv2d(128, 256, 3, 1, 1), nn.ReLU(inplace=True),
            nn.Conv2d(256, 256, 3, 1, 1), nn.ReLU(inplace=True),
            nn.Conv2d(256, 256, 3, 1, 1), nn.ReLU(inplace=True),
            nn.MaxPool2d(2, 2),
            nn.Conv2d(256, 512, 3, 1, 1), nn.ReLU(inplace=True),
            nn.Conv2d(512, 512, 3, 1, 1), nn.ReLU(inplace=True)
        )
        
        # Stage 1 - PAF (Part Affinity Fields)
        self.stage1_paf = nn.Sequential(
            nn.Conv2d(512, 256, 3, 1, 1), nn.ReLU(inplace=True),
            nn.Conv2d(256, 128, 3, 1, 1), nn.ReLU(inplace=True),
            nn.Conv2d(128, 38, 1, 1, 0)  # 19 PAF pairs * 2
        )
        
        # Stage 1 - Keypoints Heatmap
        self.stage1_keypoints = nn.Sequential(
            nn.Conv2d(512, 256, 3, 1, 1), nn.ReLU(inplace=True),
            nn.Conv2d(256, 128, 3, 1, 1), nn.ReLU(inplace=True),
            nn.Conv2d(128, 19, 1, 1, 0)  # 18 keypoints + background
        )
        
        # Stage 2 - Refinement
        self.stage2_paf = nn.Sequential(
            nn.Conv2d(512 + 38 + 19, 256, 3, 1, 1), nn.ReLU(inplace=True),
            nn.Conv2d(256, 128, 3, 1, 1), nn.ReLU(inplace=True),
            nn.Conv2d(128, 38, 1, 1, 0)
        )
        
        self.stage2_keypoints = nn.Sequential(
            nn.Conv2d(512 + 38 + 19, 256, 3, 1, 1), nn.ReLU(inplace=True),
            nn.Conv2d(256, 128, 3, 1, 1), nn.ReLU(inplace=True),
            nn.Conv2d(128, 19, 1, 1, 0)
        )
    
    def forward(self, x):
        """μμ „ν"""
        if not TORCH_AVAILABLE:
            return {
                'status': 'success',
                'model_name': self.model_name,
                'result': 'dummy_openpose_keypoints',
                'num_keypoints': self.num_keypoints
            }
        
        # Feature extraction
        features = self.feature_extractor(x)
        
        # Stage 1
        paf1 = self.stage1_paf(features)
        keypoints1 = self.stage1_keypoints(features)
        
        # Stage 2 (with concatenated features)
        stage2_input = torch.cat([features, paf1, keypoints1], dim=1)
        paf2 = self.stage2_paf(stage2_input)
        keypoints2 = self.stage2_keypoints(stage2_input)
        
        return {
            'keypoints': keypoints2,
            'paf': paf2,
            'stage1_keypoints': keypoints1,
            'stage1_paf': paf1
        }
    
    def _apply_checkpoint(self, state_dict: Dict[str, Any], checkpoint_data: Dict[str, Any]) -> bool:
        """OpenPose μ²΄ν¬ν¬μΈνΈ μ μ©"""
        if not TORCH_AVAILABLE:
            return True
        
        try:
            # νΈν™ κ°€λ¥ν• ν‚¤λ§ λ΅λ”©
            model_dict = self.state_dict()
            compatible_dict = {}
            
            for k, v in state_dict.items():
                if k in model_dict and v.shape == model_dict[k].shape:
                    compatible_dict[k] = v
            
            if len(compatible_dict) > 0:
                self.load_state_dict(compatible_dict, strict=False)
                self.logger.info(f"β… OpenPose λ΅λ”© μ„±κ³µ: {len(compatible_dict)}/{len(state_dict)} λ μ΄μ–΄")
                return True
            else:
                self.logger.warning("β οΈ OpenPose νΈν™ κ°€λ¥ν• λ μ΄μ–΄ μ—†μ, λλ¤ μ΄κΈ°ν™”")
                return True  # λλ¤ μ΄κΈ°ν™”λ„ μ„±κ³µμΌλ΅ κ°„μ£Ό
                
        except Exception as e:
            self.logger.error(f"β OpenPose μ²΄ν¬ν¬μΈνΈ μ μ© μ‹¤ν¨: {e}")
            return False

# ==============================================
# π”¥ 6. Step02ModelMapper ν΄λμ¤ μ¶”κ°€ (μ¤λ¥ ν•΄κ²°)
# ==============================================

class Step02ModelMapper:
    """Step 02 Pose Estimation μ „μ© λ¨λΈ λ§¤νΌ"""
    
    def __init__(self):
        self.logger = logging.getLogger(f"{__name__}.Step02ModelMapper")
        self.ai_models_root = Path(__file__).parent.parent.parent.parent / "ai_models"
        self._cache = {}
    
    def _search_models(self, model_files: Dict[str, List[str]], search_priority: List[str]) -> Dict[str, Optional[Path]]:
        """π”¥ λ„λ½λ _search_models λ©”μ„λ“ κµ¬ν„ (PoseEstimationStep μ¤λ¥ ν•΄κ²°)"""
        found_models = {}
        
        try:
            for model_type, file_patterns in model_files.items():
                found_models[model_type] = None
                
                # μ°μ„ μμ„λ³„ κ²€μƒ‰
                for search_path in search_priority:
                    search_dir = self.ai_models_root / search_path
                    
                    if not search_dir.exists():
                        continue
                    
                    # κ° νμΌ ν¨ν„΄ κ²€μƒ‰
                    for pattern in file_patterns:
                        for candidate_path in search_dir.rglob(pattern):
                            if candidate_path.is_file() and candidate_path.stat().st_size > 1024:  # 1KB μ΄μƒ
                                found_models[model_type] = candidate_path
                                self.logger.info(f"β… {model_type} λ¨λΈ λ°κ²¬: {candidate_path}")
                                break
                        
                        if found_models[model_type] is not None:
                            break
                    
                    if found_models[model_type] is not None:
                        break
            
            self.logger.info(f"π“ Step 02 λ¨λΈ κ²€μƒ‰ μ™„λ£: {sum(1 for v in found_models.values() if v is not None)}/{len(model_files)} λ°κ²¬")
            return found_models
            
        except Exception as e:
            self.logger.error(f"β Step 02 λ¨λΈ κ²€μƒ‰ μ‹¤ν¨: {e}")
            return {model_type: None for model_type in model_files.keys()}
    
    def get_step02_model_paths(self) -> Dict[str, Optional[Path]]:
        """Step 02 λ¨λΈ κ²½λ΅ μλ™ νƒμ§€"""
        model_files = {
            "yolov8": ["yolov8n-pose.pt", "yolov8s-pose.pt"],
            "openpose": ["openpose.pth", "body_pose_model.pth"],
            "hrnet": [
                "hrnet_w48_coco_256x192.pth", 
                "hrnet_w32_coco_256x192.pth", 
                "pose_hrnet_w48_256x192.pth",
                "hrnet_w48_256x192.pth"
            ],
            "diffusion": ["diffusion_pytorch_model.safetensors", "diffusion_pytorch_model.bin"],
            "body_pose": ["body_pose_model.pth"]
        }
        
        search_priority = [
            "step_02_pose_estimation/",
            "step_02_pose_estimation/ultra_models/",
            "step_06_virtual_fitting/ootdiffusion/checkpoints/openpose/",
            "checkpoints/step_02_pose_estimation/",
            "pose_estimation/",
            "hrnet/",
            "checkpoints/hrnet/",
            ""  # λ£¨νΈ λ””λ ‰ν† λ¦¬λ„ κ²€μƒ‰
        ]
        
        return self._search_models(model_files, search_priority)
    
    def find_model_files(self, step_name: str) -> Dict[str, Optional[Path]]:
        """Stepλ³„ λ¨λΈ νμΌ κ²€μƒ‰ (λ²”μ© λ©”μ„λ“)"""
        if step_name == "PoseEstimationStep":
            return self.get_step02_model_paths()
        else:
            self.logger.warning(f"β οΈ μ§€μ›λμ§€ μ•λ” Step: {step_name}")
            return {}

# ==============================================
# π”¥ 7. κΈ°μ΅΄ λ¨λΈλ“¤ (SAM, Mobile SAM, λ“±λ“±μ€ μ μ§€)
# ==============================================

class RealSAMModel(BaseRealAIModel if not TORCH_AVAILABLE else nn.Module):
    """μ‹¤μ  SAM λ¨λΈ (sam_vit_h_4b8939.pth 2445.7MB)"""
    
    def __init__(self, model_type: str = "vit_h", device: str = DEFAULT_DEVICE):
        if TORCH_AVAILABLE:
            super(RealSAMModel, self).__init__()
            self._init_pytorch_model(model_type)
        else:
            super().__init__(device)
        
        self.model_type = model_type
        self.device = device
        self.model_name = "RealSAMModel"
        self.sam_model = None
        self.predictor = None
        self.logger = logging.getLogger(f"{__name__}.RealSAMModel")
    
    def _init_pytorch_model(self, model_type: str):
        """PyTorch SAM λ¨λΈ κµ¬μ΅° μ΄κΈ°ν™”"""
        # κ°„μ†ν™”λ SAM κµ¬μ΅° (μ‹¤μ λ΅λ” λ³µμ΅ν• Vision Transformer)
        embed_dim = 1280 if model_type == "vit_h" else 768
        
        self.image_encoder = nn.Sequential(
            nn.Conv2d(3, 64, 7, 2, 3), nn.BatchNorm2d(64), nn.ReLU(inplace=True),
            nn.MaxPool2d(3, 2, 1),
            nn.Conv2d(64, 128, 3, 2, 1), nn.BatchNorm2d(128), nn.ReLU(inplace=True),
            nn.Conv2d(128, 256, 3, 2, 1), nn.BatchNorm2d(256), nn.ReLU(inplace=True),
            nn.Conv2d(256, 512, 3, 2, 1), nn.BatchNorm2d(512), nn.ReLU(inplace=True),
            nn.AdaptiveAvgPool2d((64, 64)),
            nn.Conv2d(512, embed_dim, 1)
        )
        
        self.prompt_encoder = nn.Sequential(
            nn.Linear(2, 256), nn.ReLU(inplace=True),
            nn.Linear(256, embed_dim)
        )
        
        self.mask_decoder = nn.Sequential(
            nn.ConvTranspose2d(embed_dim, 256, 4, 2, 1), nn.ReLU(inplace=True),
            nn.ConvTranspose2d(256, 128, 4, 2, 1), nn.ReLU(inplace=True),
            nn.ConvTranspose2d(128, 64, 4, 2, 1), nn.ReLU(inplace=True),
            nn.ConvTranspose2d(64, 32, 4, 2, 1), nn.ReLU(inplace=True),
            nn.Conv2d(32, 1, 3, 1, 1), nn.Sigmoid()
        )
    
    def forward(self, x, points=None):
        """μμ „ν"""
        if not TORCH_AVAILABLE:
            return {
                'status': 'success',
                'model_name': self.model_name,
                'result': 'dummy_sam_segmentation',
                'model_type': self.model_type
            }
        
        batch_size = x.shape[0]
        
        # Image encoding
        image_features = self.image_encoder(x)
        
        # Prompt encoding (λ”λ―Έ ν¬μΈνΈ μ‚¬μ©)
        if points is None:
            points = torch.randn(batch_size, 1, 2, device=x.device)
        
        prompt_features = self.prompt_encoder(points)
        prompt_features = prompt_features.unsqueeze(-1).unsqueeze(-1)
        prompt_features = prompt_features.expand(-1, -1, 64, 64)
        
        # Feature fusion
        fused_features = image_features + prompt_features
        
        # Mask decoding
        masks = self.mask_decoder(fused_features)
        
        # Resize to input size
        masks = F.interpolate(masks, size=x.shape[-2:], mode='bilinear', align_corners=False)
        
        return masks

# λ‚λ¨Έμ§€ λ¨λΈλ“¤ (Mobile SAM, Graphonomy, GMM, TPS)μ€ κΈ°μ΅΄κ³Ό λ™μΌν•κ² μ μ§€...

class RealMobileSAMModel(BaseRealAIModel if not TORCH_AVAILABLE else nn.Module):
    """μ‹¤μ  Mobile SAM λ¨λΈ (mobile_sam.pt 38.8MB)"""
    
    def __init__(self, device: str = DEFAULT_DEVICE):
        if TORCH_AVAILABLE:
            super(RealMobileSAMModel, self).__init__()
            self._init_pytorch_model()
        else:
            super().__init__(device)
        
        self.device = device
        self.model_name = "RealMobileSAMModel"
        self.logger = logging.getLogger(f"{__name__}.RealMobileSAMModel")
    
    def _init_pytorch_model(self):
        """PyTorch Mobile SAM λ¨λΈ κµ¬μ΅° μ΄κΈ°ν™”"""
        # Mobile-optimized SAM
        self.backbone = nn.Sequential(
            nn.Conv2d(3, 32, 3, 2, 1), nn.BatchNorm2d(32), nn.ReLU(inplace=True),
            nn.Conv2d(32, 64, 3, 2, 1), nn.BatchNorm2d(64), nn.ReLU(inplace=True),
            nn.Conv2d(64, 128, 3, 2, 1), nn.BatchNorm2d(128), nn.ReLU(inplace=True),
            nn.AdaptiveAvgPool2d((32, 32))
        )
        
        self.decoder = nn.Sequential(
            nn.ConvTranspose2d(128, 64, 4, 2, 1), nn.ReLU(inplace=True),
            nn.ConvTranspose2d(64, 32, 4, 2, 1), nn.ReLU(inplace=True),
            nn.ConvTranspose2d(32, 16, 4, 2, 1), nn.ReLU(inplace=True),
            nn.Conv2d(16, 1, 3, 1, 1), nn.Sigmoid()
        )
    
    def forward(self, x):
        """μμ „ν"""
        if not TORCH_AVAILABLE:
            return {
                'status': 'success',
                'model_name': self.model_name,
                'result': 'dummy_mobile_sam_segmentation'
            }
        
        features = self.backbone(x)
        masks = self.decoder(features)
        
        # Resize to input size
        masks = F.interpolate(masks, size=x.shape[-2:], mode='bilinear', align_corners=False)
        
        return masks

# ==============================================
# π”¥ 8. AI λ¨λΈ ν©ν† λ¦¬ (μ—…λ°μ΄νΈλ¨)
# ==============================================

class RealAIModelFactory:
    """μ‹¤μ  AI λ¨λΈ ν©ν† λ¦¬"""
    
    MODEL_REGISTRY = {
        # μ„Έκ·Έλ©ν…μ΄μ… λ¨λΈλ“¤
        "RealU2NetModel": RealU2NetModel,
        "U2NetModel": RealU2NetModel,
        "u2net": RealU2NetModel,
        
        # SAM λ¨λΈλ“¤
        "RealSAMModel": RealSAMModel,
        "SAMModel": RealSAMModel,
        "sam": RealSAMModel,
        "sam_vit_h": RealSAMModel,
        
        "RealMobileSAMModel": RealMobileSAMModel,
        "MobileSAMModel": RealMobileSAMModel,
        "mobile_sam": RealMobileSAMModel,
        
        # ν¬μ¦ μ¶”μ • λ¨λΈλ“¤ (μƒλ΅ μ¶”κ°€)
        "RealOpenPoseModel": RealOpenPoseModel,
        "OpenPoseModel": RealOpenPoseModel,
        "openpose": RealOpenPoseModel,
        "pose_estimation": RealOpenPoseModel,
        "body_pose": RealOpenPoseModel,
    }
    
    @classmethod
    def create_model(
        cls, 
        model_name: str, 
        device: str = DEFAULT_DEVICE,
        **kwargs
    ) -> BaseRealAIModel:
        """μ‹¤μ  AI λ¨λΈ μƒμ„±"""
        try:
            # λ¨λΈ μ΄λ¦„ μ •κ·ν™”
            normalized_name = cls._normalize_model_name(model_name)
            
            if normalized_name not in cls.MODEL_REGISTRY:
                logger.warning(f"β οΈ μ• μ μ—†λ” λ¨λΈ: {model_name}, κΈ°λ³Έ λ¨λΈ λ°ν™")
                return BaseRealAIModel(device)
            
            model_class = cls.MODEL_REGISTRY[normalized_name]
            model = model_class(device=device, **kwargs)
            
            logger.info(f"β… μ‹¤μ  AI λ¨λΈ μƒμ„± μ„±κ³µ: {model_name} -> {model_class.__name__}")
            return model
            
        except Exception as e:
            logger.error(f"β λ¨λΈ μƒμ„± μ‹¤ν¨ {model_name}: {e}")
            return BaseRealAIModel(device)
    
    @classmethod
    def _normalize_model_name(cls, model_name: str) -> str:
        """λ¨λΈ μ΄λ¦„ μ •κ·ν™”"""
        # νμΌλ…μ—μ„ λ¨λΈ νƒ€μ… μ¶”μ¶
        if "u2net" in model_name.lower():
            return "RealU2NetModel"
        elif "sam_vit_h" in model_name.lower():
            return "RealSAMModel"
        elif "mobile_sam" in model_name.lower():
            return "RealMobileSAMModel"
        elif "openpose" in model_name.lower() or "body_pose" in model_name.lower():
            return "RealOpenPoseModel"
        else:
            return model_name
    
    @classmethod
    def get_available_models(cls) -> List[str]:
        """μ‚¬μ© κ°€λ¥ν• λ¨λΈ λ©λ΅"""
        return list(cls.MODEL_REGISTRY.keys())

# ==============================================
# π”¥ 9. νΈμ ν•¨μλ“¤ (κΈ°μ΅΄κ³Ό λ™μΌ)
# ==============================================

def load_model_checkpoint_safe(
    model: BaseRealAIModel, 
    checkpoint_path: Union[str, Path], 
    device: str = DEFAULT_DEVICE
) -> bool:
    """μ•μ „ν• λ¨λΈ μ²΄ν¬ν¬μΈνΈ λ΅λ”©"""
    try:
        if not TORCH_AVAILABLE:
            logger.warning("β οΈ PyTorch μ—†μ, μ²΄ν¬ν¬μΈνΈ λ΅λ”© κ±΄λ„λ€")
            return True
        
        return model.load_checkpoint_safe(checkpoint_path)
        
    except Exception as e:
        logger.error(f"β μ²΄ν¬ν¬μΈνΈ λ΅λ”© ν•¨μ μ‹¤ν¨: {e}")
        return False

def create_model_from_checkpoint(
    checkpoint_path: Union[str, Path], 
    model_type: Optional[str] = None,
    device: str = DEFAULT_DEVICE
) -> Optional[BaseRealAIModel]:
    """μ²΄ν¬ν¬μΈνΈμ—μ„ λ¨λΈ μƒμ„± λ° λ΅λ”©"""
    try:
        checkpoint_path = Path(checkpoint_path)
        
        # λ¨λΈ νƒ€μ… μλ™ κ°μ§€
        if model_type is None:
            model_type = _detect_model_type_from_path(checkpoint_path)
        
        # λ¨λΈ μƒμ„±
        model = RealAIModelFactory.create_model(model_type, device)
        
        # μ²΄ν¬ν¬μΈνΈ λ΅λ”©
        if checkpoint_path.exists():
            success = model.load_checkpoint_safe(checkpoint_path)
            if success:
                logger.info(f"β… μ²΄ν¬ν¬μΈνΈμ—μ„ λ¨λΈ μƒμ„± μ„±κ³µ: {checkpoint_path.name}")
                return model
            else:
                logger.error(f"β μ²΄ν¬ν¬μΈνΈ λ΅λ”© μ‹¤ν¨: {checkpoint_path.name}")
                return None
        else:
            logger.error(f"β μ²΄ν¬ν¬μΈνΈ νμΌ μ—†μ: {checkpoint_path}")
            return None
            
    except Exception as e:
        logger.error(f"β μ²΄ν¬ν¬μΈνΈμ—μ„ λ¨λΈ μƒμ„± μ‹¤ν¨: {e}")
        return None

def _detect_model_type_from_path(checkpoint_path: Path) -> str:
    """νμΌ κ²½λ΅μ—μ„ λ¨λΈ νƒ€μ… μλ™ κ°μ§€"""
    filename = checkpoint_path.name.lower()
    
    if "u2net" in filename:
        return "RealU2NetModel"
    elif "sam_vit_h" in filename:
        return "RealSAMModel"
    elif "mobile_sam" in filename:
        return "RealMobileSAMModel"
    elif "openpose" in filename or "body_pose" in filename:
        return "RealOpenPoseModel"
    else:
        logger.warning(f"β οΈ λ¨λΈ νƒ€μ… μλ™ κ°μ§€ μ‹¤ν¨: {filename}")
        return "RealU2NetModel"  # κΈ°λ³Έκ°’

def get_model_info(model: BaseRealAIModel) -> Dict[str, Any]:
    """λ¨λΈ μ •λ³΄ μ΅°ν"""
    try:
        info = model.get_model_info()
        
        # μ¶”κ°€ μ •λ³΄
        if TORCH_AVAILABLE and hasattr(model, 'parameters'):
            try:
                info["parameters"] = sum(p.numel() for p in model.parameters())
            except:
                info["parameters"] = 0
        else:
            info["parameters"] = 0
        
        info["safetensors_available"] = SAFETENSORS_AVAILABLE
        info["is_m3_max"] = IS_M3_MAX
        
        return info
        
    except Exception as e:
        logger.error(f"β λ¨λΈ μ •λ³΄ μ΅°ν μ‹¤ν¨: {e}")
        return {"error": str(e)}

def cleanup_memory():
    """λ©”λ¨λ¦¬ μ •λ¦¬"""
    try:
        # Python κ°€λΉ„μ§€ μ»¬λ ‰μ…
        gc.collect()
        
        # GPU λ©”λ¨λ¦¬ μ •λ¦¬
        if TORCH_AVAILABLE:
            if DEFAULT_DEVICE == "mps" and IS_M3_MAX:
                safe_mps_empty_cache()
            elif DEFAULT_DEVICE == "cuda":
                torch.cuda.empty_cache()
        
        logger.info("β… λ©”λ¨λ¦¬ μ •λ¦¬ μ™„λ£")
        
    except Exception as e:
        logger.warning(f"β οΈ λ©”λ¨λ¦¬ μ •λ¦¬ μ‹¤ν¨: {e}")

# ==============================================
# π”¥ 10. λ¨λ“ λ‚΄λ³΄λ‚΄κΈ°
# ==============================================

__all__ = [
    # λ΅λ” ν΄λμ¤
    'SafeCheckpointLoader',
    
    # κΈ°λ³Έ ν΄λμ¤λ“¤
    'BaseRealAIModel',
    'RealAIModelFactory',
    
    # κµ¬μ²΄μ μΈ λ¨λΈλ“¤
    'RealU2NetModel',
    'RealSAMModel', 
    'RealMobileSAMModel',
    'RealOpenPoseModel',  # μƒλ΅ μ¶”κ°€
    
    # Step02ModelMapper (μ¤λ¥ ν•΄κ²°μ©)
    'Step02ModelMapper',
    
    # νΈμ ν•¨μλ“¤
    'load_model_checkpoint_safe',
    'create_model_from_checkpoint',
    'get_model_info',
    'cleanup_memory',
    
    # μƒμλ“¤
    'TORCH_AVAILABLE',
    'SAFETENSORS_AVAILABLE',
    'DEFAULT_DEVICE',
    'IS_M3_MAX'
]

# μ΄κΈ°ν™” λ΅κ·Έ
logger.info("π”¥" + "="*70)
logger.info("β… MyCloset AI - μ‹¤μ  AI λ¨λΈ ν΄λμ¤λ“¤ v2.1 λ΅λ“ μ™„λ£")
logger.info(f"π¤– PyTorch μƒνƒ: {'β… μ‚¬μ© κ°€λ¥' if TORCH_AVAILABLE else 'β μ‚¬μ© λ¶κ°€'}")
logger.info(f"π”’ SafeTensors μƒνƒ: {'β… μ‚¬μ© κ°€λ¥' if SAFETENSORS_AVAILABLE else 'β μ‚¬μ© λ¶κ°€'}")
logger.info(f"π”§ λ””λ°”μ΄μ¤: {DEFAULT_DEVICE}")
logger.info(f"π M3 Max μµμ ν™”: {'β… ν™μ„±ν™”' if IS_M3_MAX else 'β λΉ„ν™μ„±ν™”'}")
logger.info("π― μ²΄ν¬ν¬μΈνΈ λ΅λ”© μ¤λ¥ μ™„μ „ ν•΄κ²°")
logger.info("β΅ 3λ‹¨κ³„ μ•μ „ λ΅λ”© (weights_only=True β†’ False β†’ Legacy)")
logger.info("π”— μ‹¤μ  GitHub ν”„λ΅μ νΈ κµ¬μ΅° μ™„μ „ λ°μ")
logger.info("π’Ύ μ‹¤μ  μ²΄ν¬ν¬μΈνΈ νμΌλ“¤κ³Ό μ™„μ „ λ§¤μΉ­")
logger.info("π”„ μν™μ°Έμ΅° λ°©μ§€ - λ…λ¦½μ  λ¨λ“ μ„¤κ³„")
logger.info("π conda ν™κ²½ μ°μ„  μ§€μ›")
logger.info("π”§ PoseEstimationStep μ¤λ¥ ν•΄κ²°: Step02ModelMapper._search_models μ¶”κ°€")
logger.info("="*70)