# backend/app/ai_pipeline/models/ai_models.py
"""
ü§ñ MyCloset AI - AI Î™®Îç∏ ÌÅ¥ÎûòÏä§Îì§ v1.0
=====================================
‚úÖ Ïã§Ï†ú AI Î™®Îç∏ ÏïÑÌÇ§ÌÖçÏ≤ò ÏôÑÏ†Ñ Íµ¨ÌòÑ
‚úÖ StepÎ≥Ñ ÌäπÌôî Î™®Îç∏ ÌÅ¥ÎûòÏä§
‚úÖ PyTorch ÎÑ§Ïù¥Ìã∞Î∏å ÏßÄÏõê
‚úÖ M3 Max MPS ÏµúÏ†ÅÌôî
‚úÖ Ï≤¥ÌÅ¨Ìè¨Ïù∏Ìä∏ Î°úÎî© ÏãúÏä§ÌÖú
‚úÖ ÏàúÌôòÏ∞∏Ï°∞ Î∞©ÏßÄ - ÎèÖÎ¶ΩÏ†Å Î™®Îìà
‚úÖ conda ÌôòÍ≤Ω Ïö∞ÏÑ† ÏßÄÏõê

Author: MyCloset AI Team  
Date: 2025-07-21
Version: 1.0 (Î∂ÑÎ¶¨Îêú AI Î™®Îç∏ ÏãúÏä§ÌÖú)
"""

import logging
import time
from pathlib import Path
from typing import Any, Dict, Optional, Tuple, Union, List
from enum import Enum
from abc import ABC, abstractmethod

logger = logging.getLogger(__name__)

# ==============================================
# üî• 1. PyTorch Ìò∏ÌôòÏÑ± Ï≤¥ÌÅ¨
# ==============================================

try:
    import torch
    import torch.nn as nn
    import torch.nn.functional as F
    TORCH_AVAILABLE = True
    
    # M3 Max MPS ÏÑ§Ï†ï
    if hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
        DEFAULT_DEVICE = "mps"
        IS_M3_MAX = True
        logger.info("‚úÖ M3 Max MPS ÏÇ¨Ïö© Í∞ÄÎä•")
        
        # ÏïàÏ†ÑÌïú MPS Ï∫êÏãú Ï†ïÎ¶¨
        try:
            if hasattr(torch.mps, 'empty_cache'):
                torch.mps.empty_cache()
        except (AttributeError, RuntimeError):
            pass
    elif torch.cuda.is_available():
        DEFAULT_DEVICE = "cuda"
        IS_M3_MAX = False
    else:
        DEFAULT_DEVICE = "cpu"
        IS_M3_MAX = False
        
except ImportError:
    TORCH_AVAILABLE = False
    DEFAULT_DEVICE = "cpu"
    IS_M3_MAX = False
    torch = None
    nn = None
    F = None
    logger.warning("‚ö†Ô∏è PyTorch ÏóÜÏùå - ÎçîÎØ∏ Î™®Îç∏ ÏÇ¨Ïö©")

# ==============================================
# üî• 2. Î™®Îç∏ Í¥ÄÎ†® Ïó¥Í±∞Ìòï
# ==============================================

class ModelArchitecture(Enum):
    """Î™®Îç∏ ÏïÑÌÇ§ÌÖçÏ≤ò"""
    RESNET = "resnet"
    UNET = "unet"
    OPENPOSE = "openpose"
    DIFFUSION = "diffusion"
    GAN = "gan"
    TRANSFORMER = "transformer"
    VIT = "vision_transformer"
    UNKNOWN = "unknown"

class ModelPrecision(Enum):
    """Î™®Îç∏ Ï†ïÎ∞ÄÎèÑ"""
    FP32 = "fp32"
    FP16 = "fp16"
    INT8 = "int8"

class ActivationType(Enum):
    """ÌôúÏÑ±Ìôî Ìï®Ïàò ÌÉÄÏûÖ"""
    RELU = "relu"
    GELU = "gelu"
    SWISH = "swish"
    MISH = "mish"
    LEAKY_RELU = "leaky_relu"

# ==============================================
# üî• 3. Í∏∞Î≥∏ Î™®Îç∏ ÌÅ¥ÎûòÏä§
# ==============================================

class BaseAIModel(ABC):
    """Í∏∞Î≥∏ AI Î™®Îç∏ ÌÅ¥ÎûòÏä§"""
    
    def __init__(self, device: str = DEFAULT_DEVICE):
        self.device = device
        self.model_name = self.__class__.__name__
        self.architecture = ModelArchitecture.UNKNOWN
        self.precision = ModelPrecision.FP32
        self.is_loaded = False
        self.logger = logging.getLogger(f"{__name__}.{self.model_name}")
        
    @abstractmethod
    def forward(self, x):
        """ÏàúÏ†ÑÌåå (ÌïòÏúÑ ÌÅ¥ÎûòÏä§ÏóêÏÑú Íµ¨ÌòÑ)"""
        pass
    
    def __call__(self, x):
        """Ìò∏Ï∂ú Î©îÏÑúÎìú"""
        return self.forward(x)
    
    def to(self, device):
        """ÎîîÎ∞îÏù¥Ïä§ Ïù¥Îèô"""
        self.device = str(device)
        return self
    
    def eval(self):
        """ÌèâÍ∞Ä Î™®Îìú"""
        return self
    
    def train(self, mode: bool = True):
        """ÌõàÎ†® Î™®Îìú"""
        return self
    
    def load_checkpoint(self, checkpoint_path: Union[str, Path]) -> bool:
        """Ï≤¥ÌÅ¨Ìè¨Ïù∏Ìä∏ Î°úÎî©"""
        try:
            self.logger.info(f"üì¶ Ï≤¥ÌÅ¨Ìè¨Ïù∏Ìä∏ Î°úÎî©: {checkpoint_path}")
            # Í∏∞Î≥∏ Íµ¨ÌòÑ (ÌïòÏúÑ ÌÅ¥ÎûòÏä§ÏóêÏÑú Ïò§Î≤ÑÎùºÏù¥Îìú)
            self.is_loaded = True
            return True
        except Exception as e:
            self.logger.error(f"‚ùå Ï≤¥ÌÅ¨Ìè¨Ïù∏Ìä∏ Î°úÎî© Ïã§Ìå®: {e}")
            return False
    
    def get_model_info(self) -> Dict[str, Any]:
        """Î™®Îç∏ Ï†ïÎ≥¥ Î∞òÌôò"""
        return {
            "name": self.model_name,
            "architecture": self.architecture.value,
            "device": self.device,
            "precision": self.precision.value,
            "is_loaded": self.is_loaded,
            "parameters": self.count_parameters() if TORCH_AVAILABLE else 0
        }
    
    def count_parameters(self) -> int:
        """ÌååÎùºÎØ∏ÌÑ∞ Ïàò Í≥ÑÏÇ∞"""
        return 0  # Í∏∞Î≥∏ Íµ¨ÌòÑ

# PyTorch ÏóÜÎäî Í≤ΩÏö∞ ÎçîÎØ∏ ÌÅ¥ÎûòÏä§Îì§ ÏÉùÏÑ±
if not TORCH_AVAILABLE:
    class DummyModule:
        def __init__(self, *args, **kwargs):
            pass
        
        def __call__(self, *args, **kwargs):
            return {"status": "dummy", "result": "no_pytorch"}
        
        def to(self, device):
            return self
        
        def eval(self):
            return self
        
        def train(self, mode=True):
            return self
    
    nn = type('nn', (), {
        'Module': DummyModule,
        'Conv2d': DummyModule,
        'BatchNorm2d': DummyModule,
        'ReLU': DummyModule,
        'MaxPool2d': DummyModule,
        'ConvTranspose2d': DummyModule,
        'Linear': DummyModule,
        'Dropout': DummyModule,
        'Sequential': DummyModule,
        'AdaptiveAvgPool2d': DummyModule,
        'Sigmoid': DummyModule,
        'Tanh': DummyModule,
        'Flatten': DummyModule
    })()
    
    F = type('F', (), {
        'relu': lambda x: x,
        'interpolate': lambda x, **kwargs: x,
        'sigmoid': lambda x: x,
        'tanh': lambda x: x
    })()

# ==============================================
# üî• 4. Step 01: Human Parsing Î™®Îç∏
# ==============================================

class HumanParsingModel(BaseAIModel if not TORCH_AVAILABLE else nn.Module):
    """Ïù∏Ï≤¥ ÌååÏã± Î™®Îç∏ (Graphonomy Í∏∞Î∞ò)"""
    
    def __init__(self, num_classes: int = 20, backbone: str = 'resnet101', device: str = DEFAULT_DEVICE):
        if TORCH_AVAILABLE:
            super(HumanParsingModel, self).__init__()
        else:
            super().__init__(device)
            
        self.num_classes = num_classes
        self.backbone_name = backbone
        self.device = device
        self.architecture = ModelArchitecture.RESNET
        self.model_name = "HumanParsingModel"
        
        if TORCH_AVAILABLE:
            self._build_model()
        
        self.logger = logging.getLogger(f"{__name__}.HumanParsingModel")
    
    def _build_model(self):
        """Î™®Îç∏ Íµ¨Ï°∞ ÏÉùÏÑ±"""
        # Backbone (ResNet-like)
        self.backbone = nn.Sequential(
            # Block 1
            nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False),
            nn.BatchNorm2d(64),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),
            
            # Block 2
            nn.Conv2d(64, 256, kernel_size=3, stride=1, padding=1, bias=False),
            nn.BatchNorm2d(256),
            nn.ReLU(inplace=True),
            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1, bias=False),
            nn.BatchNorm2d(256),
            nn.ReLU(inplace=True),
            
            # Block 3
            nn.Conv2d(256, 512, kernel_size=3, stride=2, padding=1, bias=False),
            nn.BatchNorm2d(512),
            nn.ReLU(inplace=True),
            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1, bias=False),
            nn.BatchNorm2d(512),
            nn.ReLU(inplace=True),
            
            # Block 4
            nn.Conv2d(512, 1024, kernel_size=3, stride=2, padding=1, bias=False),
            nn.BatchNorm2d(1024),
            nn.ReLU(inplace=True),
            nn.Conv2d(1024, 1024, kernel_size=3, stride=1, padding=1, bias=False),
            nn.BatchNorm2d(1024),
            nn.ReLU(inplace=True),
            
            # Block 5
            nn.Conv2d(1024, 2048, kernel_size=3, stride=2, padding=1, bias=False),
            nn.BatchNorm2d(2048),
            nn.ReLU(inplace=True)
        )
        
        # ASPP (Atrous Spatial Pyramid Pooling)
        self.aspp = nn.ModuleList([
            nn.Sequential(
                nn.Conv2d(2048, 256, kernel_size=1, bias=False),
                nn.BatchNorm2d(256),
                nn.ReLU(inplace=True)
            ),
            nn.Sequential(
                nn.Conv2d(2048, 256, kernel_size=3, padding=6, dilation=6, bias=False),
                nn.BatchNorm2d(256),
                nn.ReLU(inplace=True)
            ),
            nn.Sequential(
                nn.Conv2d(2048, 256, kernel_size=3, padding=12, dilation=12, bias=False),
                nn.BatchNorm2d(256),
                nn.ReLU(inplace=True)
            ),
            nn.Sequential(
                nn.Conv2d(2048, 256, kernel_size=3, padding=18, dilation=18, bias=False),
                nn.BatchNorm2d(256),
                nn.ReLU(inplace=True)
            )
        ])
        
        # Global Average Pooling
        self.global_avg_pool = nn.Sequential(
            nn.AdaptiveAvgPool2d((1, 1)),
            nn.Conv2d(2048, 256, kernel_size=1, bias=False),
            nn.BatchNorm2d(256),
            nn.ReLU(inplace=True)
        )
        
        # Fusion
        self.fusion = nn.Sequential(
            nn.Conv2d(256 * 5, 256, kernel_size=1, bias=False),
            nn.BatchNorm2d(256),
            nn.ReLU(inplace=True),
            nn.Dropout(0.5)
        )
        
        # Classifier
        self.classifier = nn.Conv2d(256, self.num_classes, kernel_size=1)
    
    def forward(self, x):
        """ÏàúÏ†ÑÌåå"""
        if not TORCH_AVAILABLE:
            return {
                'status': 'success',
                'model_name': self.model_name,
                'result': 'dummy_human_parsing_result',
                'num_classes': self.num_classes
            }
        
        input_size = x.size()[2:]
        
        # Backbone
        features = self.backbone(x)
        
        # ASPP
        aspp_features = []
        for aspp_layer in self.aspp:
            aspp_features.append(aspp_layer(features))
        
        # Global Average Pooling
        global_features = self.global_avg_pool(features)
        global_features = F.interpolate(global_features, size=features.size()[2:], mode='bilinear', align_corners=False)
        aspp_features.append(global_features)
        
        # Fusion
        fused_features = torch.cat(aspp_features, dim=1)
        fused_features = self.fusion(fused_features)
        
        # Classification
        output = self.classifier(fused_features)
        
        # Upsample to input size
        output = F.interpolate(output, size=input_size, mode='bilinear', align_corners=False)
        
        return output
    
    def count_parameters(self) -> int:
        """ÌååÎùºÎØ∏ÌÑ∞ Ïàò Í≥ÑÏÇ∞"""
        if TORCH_AVAILABLE:
            return sum(p.numel() for p in self.parameters())
        return 0

# ==============================================
# üî• 5. Step 02: Pose Estimation Î™®Îç∏
# ==============================================

class OpenPoseModel(BaseAIModel if not TORCH_AVAILABLE else nn.Module):
    """OpenPose Ìè¨Ï¶à Ï∂îÏ†ï Î™®Îç∏"""
    
    def __init__(self, num_keypoints: int = 18, device: str = DEFAULT_DEVICE):
        if TORCH_AVAILABLE:
            super(OpenPoseModel, self).__init__()
        else:
            super().__init__(device)
            
        self.num_keypoints = num_keypoints
        self.device = device
        self.architecture = ModelArchitecture.OPENPOSE
        self.model_name = "OpenPoseModel"
        
        if TORCH_AVAILABLE:
            self._build_model()
        
        self.logger = logging.getLogger(f"{__name__}.OpenPoseModel")
    
    def _build_model(self):
        """Î™®Îç∏ Íµ¨Ï°∞ ÏÉùÏÑ±"""
        # VGG-like backbone
        self.backbone = nn.Sequential(
            # Block 1
            nn.Conv2d(3, 64, 3, 1, 1), nn.ReLU(inplace=True),
            nn.Conv2d(64, 64, 3, 1, 1), nn.ReLU(inplace=True),
            nn.MaxPool2d(2, 2),
            
            # Block 2
            nn.Conv2d(64, 128, 3, 1, 1), nn.ReLU(inplace=True),
            nn.Conv2d(128, 128, 3, 1, 1), nn.ReLU(inplace=True),
            nn.MaxPool2d(2, 2),
            
            # Block 3
            nn.Conv2d(128, 256, 3, 1, 1), nn.ReLU(inplace=True),
            nn.Conv2d(256, 256, 3, 1, 1), nn.ReLU(inplace=True),
            nn.Conv2d(256, 256, 3, 1, 1), nn.ReLU(inplace=True),
            nn.MaxPool2d(2, 2),
            
            # Block 4
            nn.Conv2d(256, 512, 3, 1, 1), nn.ReLU(inplace=True),
            nn.Conv2d(512, 512, 3, 1, 1), nn.ReLU(inplace=True),
            nn.Conv2d(512, 512, 3, 1, 1), nn.ReLU(inplace=True),
            nn.MaxPool2d(2, 2),
            
            # Block 5
            nn.Conv2d(512, 512, 3, 1, 1), nn.ReLU(inplace=True),
            nn.Conv2d(512, 512, 3, 1, 1), nn.ReLU(inplace=True),
            nn.Conv2d(512, 512, 3, 1, 1), nn.ReLU(inplace=True)
        )
        
        # Stage 1 - PAF (Part Affinity Fields)
        self.stage1_paf = nn.Sequential(
            nn.Conv2d(512, 512, 3, 1, 1), nn.ReLU(inplace=True),
            nn.Conv2d(512, 512, 3, 1, 1), nn.ReLU(inplace=True),
            nn.Conv2d(512, 512, 3, 1, 1), nn.ReLU(inplace=True),
            nn.Conv2d(512, 512, 1, 1, 0), nn.ReLU(inplace=True),
            nn.Conv2d(512, 38, 1, 1, 0)  # 19 limbs * 2 (x, y)
        )
        
        # Stage 1 - Heatmaps
        self.stage1_heatmap = nn.Sequential(
            nn.Conv2d(512, 512, 3, 1, 1), nn.ReLU(inplace=True),
            nn.Conv2d(512, 512, 3, 1, 1), nn.ReLU(inplace=True),
            nn.Conv2d(512, 512, 3, 1, 1), nn.ReLU(inplace=True),
            nn.Conv2d(512, 512, 1, 1, 0), nn.ReLU(inplace=True),
            nn.Conv2d(512, 19, 1, 1, 0)  # 18 keypoints + 1 background
        )
        
        # Refinement stages (Stage 2-6)
        self.refinement_stages = nn.ModuleList()
        for i in range(5):  # 5Í∞ú refinement stage
            self.refinement_stages.append(
                nn.Sequential(
                    nn.Conv2d(185, 128, 7, 1, 3), nn.ReLU(inplace=True),  # 512 + 38 + 19 + concat
                    nn.Conv2d(128, 128, 7, 1, 3), nn.ReLU(inplace=True),
                    nn.Conv2d(128, 128, 7, 1, 3), nn.ReLU(inplace=True),
                    nn.Conv2d(128, 128, 7, 1, 3), nn.ReLU(inplace=True),
                    nn.Conv2d(128, 128, 7, 1, 3), nn.ReLU(inplace=True),
                    nn.Conv2d(128, 128, 1, 1, 0), nn.ReLU(inplace=True),
                    nn.Conv2d(128, 38, 1, 1, 0)  # PAF output
                )
            )
    
    def forward(self, x):
        """ÏàúÏ†ÑÌåå"""
        if not TORCH_AVAILABLE:
            return {
                'status': 'success',
                'model_name': self.model_name,
                'result': 'dummy_pose_estimation_result',
                'num_keypoints': self.num_keypoints
            }
        
        # Backbone
        features = self.backbone(x)
        
        # Stage 1
        paf1 = self.stage1_paf(features)
        heatmap1 = self.stage1_heatmap(features)
        
        outputs = [(paf1, heatmap1)]
        
        # Refinement stages
        concat_input = torch.cat([features, paf1, heatmap1], dim=1)
        
        for stage in self.refinement_stages:
            paf = stage(concat_input)
            # HeatmapÏùÄ Ï≤´ Î≤àÏß∏ stage Í≤ÉÏùÑ Ïû¨ÏÇ¨Ïö© (Í∞ÑÏÜåÌôî)
            outputs.append((paf, heatmap1))
            concat_input = torch.cat([features, paf, heatmap1], dim=1)
        
        return outputs
    
    def count_parameters(self) -> int:
        """ÌååÎùºÎØ∏ÌÑ∞ Ïàò Í≥ÑÏÇ∞"""
        if TORCH_AVAILABLE:
            return sum(p.numel() for p in self.parameters())
        return 0

# ==============================================
# üî• 6. Step 03: Cloth Segmentation Î™®Îç∏
# ==============================================

class U2NetModel(BaseAIModel if not TORCH_AVAILABLE else nn.Module):
    """U¬≤-Net ÏùòÎ•ò ÏÑ∏Í∑∏Î©òÌÖåÏù¥ÏÖò Î™®Îç∏"""
    
    def __init__(self, in_channels: int = 3, out_channels: int = 1, device: str = DEFAULT_DEVICE):
        if TORCH_AVAILABLE:
            super(U2NetModel, self).__init__()
        else:
            super().__init__(device)
            
        self.in_channels = in_channels
        self.out_channels = out_channels
        self.device = device
        self.architecture = ModelArchitecture.UNET
        self.model_name = "U2NetModel"
        
        if TORCH_AVAILABLE:
            self._build_model()
        
        self.logger = logging.getLogger(f"{__name__}.U2NetModel")
    
    def _build_model(self):
        """Î™®Îç∏ Íµ¨Ï°∞ ÏÉùÏÑ±"""
        # Encoder
        self.encoder1 = nn.Sequential(
            nn.Conv2d(self.in_channels, 64, 3, 1, 1), nn.BatchNorm2d(64), nn.ReLU(inplace=True),
            nn.Conv2d(64, 64, 3, 1, 1), nn.BatchNorm2d(64), nn.ReLU(inplace=True)
        )
        
        self.encoder2 = nn.Sequential(
            nn.MaxPool2d(2, 2),
            nn.Conv2d(64, 128, 3, 1, 1), nn.BatchNorm2d(128), nn.ReLU(inplace=True),
            nn.Conv2d(128, 128, 3, 1, 1), nn.BatchNorm2d(128), nn.ReLU(inplace=True)
        )
        
        self.encoder3 = nn.Sequential(
            nn.MaxPool2d(2, 2),
            nn.Conv2d(128, 256, 3, 1, 1), nn.BatchNorm2d(256), nn.ReLU(inplace=True),
            nn.Conv2d(256, 256, 3, 1, 1), nn.BatchNorm2d(256), nn.ReLU(inplace=True)
        )
        
        self.encoder4 = nn.Sequential(
            nn.MaxPool2d(2, 2),
            nn.Conv2d(256, 512, 3, 1, 1), nn.BatchNorm2d(512), nn.ReLU(inplace=True),
            nn.Conv2d(512, 512, 3, 1, 1), nn.BatchNorm2d(512), nn.ReLU(inplace=True)
        )
        
        # Bridge
        self.bridge = nn.Sequential(
            nn.MaxPool2d(2, 2),
            nn.Conv2d(512, 1024, 3, 1, 1), nn.BatchNorm2d(1024), nn.ReLU(inplace=True),
            nn.Conv2d(1024, 1024, 3, 1, 1), nn.BatchNorm2d(1024), nn.ReLU(inplace=True)
        )
        
        # Decoder
        self.decoder4 = nn.Sequential(
            nn.ConvTranspose2d(1024, 512, 2, 2),
            nn.Conv2d(1024, 512, 3, 1, 1), nn.BatchNorm2d(512), nn.ReLU(inplace=True),
            nn.Conv2d(512, 512, 3, 1, 1), nn.BatchNorm2d(512), nn.ReLU(inplace=True)
        )
        
        self.decoder3 = nn.Sequential(
            nn.ConvTranspose2d(512, 256, 2, 2),
            nn.Conv2d(512, 256, 3, 1, 1), nn.BatchNorm2d(256), nn.ReLU(inplace=True),
            nn.Conv2d(256, 256, 3, 1, 1), nn.BatchNorm2d(256), nn.ReLU(inplace=True)
        )
        
        self.decoder2 = nn.Sequential(
            nn.ConvTranspose2d(256, 128, 2, 2),
            nn.Conv2d(256, 128, 3, 1, 1), nn.BatchNorm2d(128), nn.ReLU(inplace=True),
            nn.Conv2d(128, 128, 3, 1, 1), nn.BatchNorm2d(128), nn.ReLU(inplace=True)
        )
        
        self.decoder1 = nn.Sequential(
            nn.ConvTranspose2d(128, 64, 2, 2),
            nn.Conv2d(128, 64, 3, 1, 1), nn.BatchNorm2d(64), nn.ReLU(inplace=True),
            nn.Conv2d(64, 64, 3, 1, 1), nn.BatchNorm2d(64), nn.ReLU(inplace=True)
        )
        
        # Final output
        self.final_conv = nn.Sequential(
            nn.Conv2d(64, self.out_channels, 1, 1, 0),
            nn.Sigmoid()
        )
    
    def forward(self, x):
        """ÏàúÏ†ÑÌåå"""
        if not TORCH_AVAILABLE:
            return {
                'status': 'success',
                'model_name': self.model_name,
                'result': 'dummy_cloth_segmentation_result',
                'in_channels': self.in_channels,
                'out_channels': self.out_channels
            }
        
        # Encoder
        enc1 = self.encoder1(x)
        enc2 = self.encoder2(enc1)
        enc3 = self.encoder3(enc2)
        enc4 = self.encoder4(enc3)
        
        # Bridge
        bridge = self.bridge(enc4)
        
        # Decoder with skip connections
        dec4 = self.decoder4[0](bridge)  # Transpose conv
        dec4 = torch.cat([dec4, enc4], dim=1)  # Skip connection
        dec4 = self.decoder4[1:](dec4)  # Regular convs
        
        dec3 = self.decoder3[0](dec4)
        dec3 = torch.cat([dec3, enc3], dim=1)
        dec3 = self.decoder3[1:](dec3)
        
        dec2 = self.decoder2[0](dec3)
        dec2 = torch.cat([dec2, enc2], dim=1)
        dec2 = self.decoder2[1:](dec2)
        
        dec1 = self.decoder1[0](dec2)
        dec1 = torch.cat([dec1, enc1], dim=1)
        dec1 = self.decoder1[1:](dec1)
        
        # Final output
        output = self.final_conv(dec1)
        
        return output
    
    def count_parameters(self) -> int:
        """ÌååÎùºÎØ∏ÌÑ∞ Ïàò Í≥ÑÏÇ∞"""
        if TORCH_AVAILABLE:
            return sum(p.numel() for p in self.parameters())
        return 0

# ==============================================
# üî• 7. Step 04: Geometric Matching Î™®Îç∏
# ==============================================

class GeometricMatchingModel(BaseAIModel if not TORCH_AVAILABLE else nn.Module):
    """Í∏∞ÌïòÌïôÏ†Å Îß§Ïπ≠ Î™®Îç∏ (GMM)"""
    
    def __init__(self, feature_size: int = 256, device: str = DEFAULT_DEVICE):
        if TORCH_AVAILABLE:
            super(GeometricMatchingModel, self).__init__()
        else:
            super().__init__(device)
            
        self.feature_size = feature_size
        self.device = device
        self.architecture = ModelArchitecture.RESNET
        self.model_name = "GeometricMatchingModel"
        
        if TORCH_AVAILABLE:
            self._build_model()
        
        self.logger = logging.getLogger(f"{__name__}.GeometricMatchingModel")
    
    def _build_model(self):
        """Î™®Îç∏ Íµ¨Ï°∞ ÏÉùÏÑ±"""
        # Feature extractor for person image
        self.person_feature_extractor = nn.Sequential(
            nn.Conv2d(3, 64, 3, 1, 1), nn.BatchNorm2d(64), nn.ReLU(inplace=True),
            nn.Conv2d(64, 128, 3, 2, 1), nn.BatchNorm2d(128), nn.ReLU(inplace=True),
            nn.Conv2d(128, 256, 3, 2, 1), nn.BatchNorm2d(256), nn.ReLU(inplace=True),
            nn.AdaptiveAvgPool2d((8, 8))
        )
        
        # Feature extractor for cloth image
        self.cloth_feature_extractor = nn.Sequential(
            nn.Conv2d(3, 64, 3, 1, 1), nn.BatchNorm2d(64), nn.ReLU(inplace=True),
            nn.Conv2d(64, 128, 3, 2, 1), nn.BatchNorm2d(128), nn.ReLU(inplace=True),
            nn.Conv2d(128, 256, 3, 2, 1), nn.BatchNorm2d(256), nn.ReLU(inplace=True),
            nn.AdaptiveAvgPool2d((8, 8))
        )
        
        # Correlation computation and TPS parameter regression
        self.tps_regressor = nn.Sequential(
            nn.Flatten(),
            nn.Linear(256 * 8 * 8 * 2, 1024), nn.ReLU(inplace=True),  # *2 for concat
            nn.Dropout(0.5),
            nn.Linear(1024, 512), nn.ReLU(inplace=True),
            nn.Dropout(0.5),
            nn.Linear(512, 18)  # 6x3 TPS parameters
        )
        
        # Correlation map generator
        self.correlation_conv = nn.Sequential(
            nn.Conv2d(512, 256, 3, 1, 1), nn.ReLU(inplace=True),
            nn.Conv2d(256, 128, 3, 1, 1), nn.ReLU(inplace=True),
            nn.Conv2d(128, 1, 3, 1, 1), nn.Sigmoid()
        )
    
    def forward(self, person_img, cloth_img=None):
        """ÏàúÏ†ÑÌåå"""
        if not TORCH_AVAILABLE:
            return {
                'status': 'success',
                'model_name': self.model_name,
                'result': 'dummy_geometric_matching_result',
                'tps_params': 'dummy_tps_params',
                'correlation_map': 'dummy_correlation_map'
            }
        
        if cloth_img is None:
            cloth_img = person_img  # Ìè¥Î∞±
        
        # Feature extraction
        person_features = self.person_feature_extractor(person_img)
        cloth_features = self.cloth_feature_extractor(cloth_img)
        
        # Concatenate features for TPS regression
        combined_features = torch.cat([person_features, cloth_features], dim=1)
        tps_params = self.tps_regressor(combined_features)
        
        # Reshape TPS parameters to 6x3 matrix
        tps_params = tps_params.view(-1, 6, 3)
        
        # Generate correlation map
        correlation_features = torch.cat([person_features, cloth_features], dim=1)
        correlation_map = self.correlation_conv(correlation_features)
        
        return {
            'tps_params': tps_params,
            'correlation_map': correlation_map
        }
    
    def count_parameters(self) -> int:
        """ÌååÎùºÎØ∏ÌÑ∞ Ïàò Í≥ÑÏÇ∞"""
        if TORCH_AVAILABLE:
            return sum(p.numel() for p in self.parameters())
        return 0

# ==============================================
# üî• 8. Step 06: Virtual Fitting Î™®Îç∏ (Diffusion Í∏∞Î∞ò)
# ==============================================

class VirtualFittingModel(BaseAIModel if not TORCH_AVAILABLE else nn.Module):
    """Í∞ÄÏÉÅ ÌîºÌåÖ Î™®Îç∏ (Stable Diffusion Í∏∞Î∞ò Í∞ÑÏÜåÌôî)"""
    
    def __init__(self, latent_dim: int = 512, device: str = DEFAULT_DEVICE):
        if TORCH_AVAILABLE:
            super(VirtualFittingModel, self).__init__()
        else:
            super().__init__(device)
            
        self.latent_dim = latent_dim
        self.device = device
        self.architecture = ModelArchitecture.DIFFUSION
        self.model_name = "VirtualFittingModel"
        
        if TORCH_AVAILABLE:
            self._build_model()
        
        self.logger = logging.getLogger(f"{__name__}.VirtualFittingModel")
    
    def _build_model(self):
        """Î™®Îç∏ Íµ¨Ï°∞ ÏÉùÏÑ± (Í∞ÑÏÜåÌôîÎêú U-Net)"""
        # Encoder
        self.encoder = nn.Sequential(
            nn.Conv2d(6, 64, 3, 1, 1), nn.ReLU(inplace=True),   # person + cloth
            nn.Conv2d(64, 128, 3, 2, 1), nn.ReLU(inplace=True),  # 256x256
            nn.Conv2d(128, 256, 3, 2, 1), nn.ReLU(inplace=True), # 128x128
            nn.Conv2d(256, 512, 3, 2, 1), nn.ReLU(inplace=True), # 64x64
            nn.Conv2d(512, 512, 3, 2, 1), nn.ReLU(inplace=True)  # 32x32
        )
        
        # Middle blocks (residual)
        self.middle_blocks = nn.Sequential(
            nn.Conv2d(512, 512, 3, 1, 1), nn.ReLU(inplace=True),
            nn.Conv2d(512, 512, 3, 1, 1), nn.ReLU(inplace=True),
            nn.Conv2d(512, 512, 3, 1, 1), nn.ReLU(inplace=True)
        )
        
        # Decoder
        self.decoder = nn.Sequential(
            nn.ConvTranspose2d(512, 512, 4, 2, 1), nn.ReLU(inplace=True),  # 64x64
            nn.ConvTranspose2d(512, 256, 4, 2, 1), nn.ReLU(inplace=True),  # 128x128
            nn.ConvTranspose2d(256, 128, 4, 2, 1), nn.ReLU(inplace=True),  # 256x256
            nn.ConvTranspose2d(128, 64, 4, 2, 1), nn.ReLU(inplace=True),   # 512x512
            nn.Conv2d(64, 3, 3, 1, 1), nn.Tanh()  # RGB output
        )
        
        # Attention mechanism (simplified)
        self.attention = nn.Sequential(
            nn.Conv2d(512, 256, 1), nn.ReLU(inplace=True),
            nn.Conv2d(256, 512, 1), nn.Sigmoid()
        )
    
    def forward(self, person_img, cloth_img):
        """ÏàúÏ†ÑÌåå"""
        if not TORCH_AVAILABLE:
            return {
                'status': 'success',
                'model_name': self.model_name,
                'result': 'dummy_virtual_fitting_result',
                'output_shape': '(1, 3, 512, 512)'
            }
        
        # Concatenate person and cloth images
        x = torch.cat([person_img, cloth_img], dim=1)
        
        # Encode
        encoded = self.encoder(x)
        
        # Apply attention
        attention_weights = self.attention(encoded)
        attended = encoded * attention_weights
        
        # Middle processing
        middle = self.middle_blocks(attended)
        
        # Add residual connection
        middle = middle + attended
        
        # Decode
        output = self.decoder(middle)
        
        return output
    
    def count_parameters(self) -> int:
        """ÌååÎùºÎØ∏ÌÑ∞ Ïàò Í≥ÑÏÇ∞"""
        if TORCH_AVAILABLE:
            return sum(p.numel() for p in self.parameters())
        return 0

# ==============================================
# üî• 9. Î™®Îç∏ Ìå©ÌÜ†Î¶¨ ÌÅ¥ÎûòÏä§
# ==============================================

class AIModelFactory:
    """AI Î™®Îç∏ Ìå©ÌÜ†Î¶¨"""
    
    MODEL_REGISTRY = {
        "HumanParsingModel": HumanParsingModel,
        "GraphonomyModel": HumanParsingModel,  # Î≥ÑÏπ≠
        "OpenPoseModel": OpenPoseModel,
        "U2NetModel": U2NetModel,
        "GeometricMatchingModel": GeometricMatchingModel,
        "VirtualFittingModel": VirtualFittingModel,
        "StableDiffusionModel": VirtualFittingModel  # Î≥ÑÏπ≠
    }
    
    @classmethod
    def create_model(
        cls, 
        model_name: str, 
        device: str = DEFAULT_DEVICE,
        **kwargs
    ) -> BaseAIModel:
        """Î™®Îç∏ ÏÉùÏÑ±"""
        try:
            if model_name not in cls.MODEL_REGISTRY:
                logger.warning(f"‚ö†Ô∏è Ïïå Ïàò ÏóÜÎäî Î™®Îç∏: {model_name}, BaseAIModel Î∞òÌôò")
                return BaseAIModel(device)
            
            model_class = cls.MODEL_REGISTRY[model_name]
            model = model_class(device=device, **kwargs)
            
            logger.info(f"‚úÖ Î™®Îç∏ ÏÉùÏÑ± ÏÑ±Í≥µ: {model_name}")
            return model
            
        except Exception as e:
            logger.error(f"‚ùå Î™®Îç∏ ÏÉùÏÑ± Ïã§Ìå® {model_name}: {e}")
            return BaseAIModel(device)
    
    @classmethod
    def get_available_models(cls) -> List[str]:
        """ÏÇ¨Ïö© Í∞ÄÎä•Ìïú Î™®Îç∏ Î™©Î°ù"""
        return list(cls.MODEL_REGISTRY.keys())
    
    @classmethod
    def register_model(cls, name: str, model_class: type):
        """ÏÉà Î™®Îç∏ Îì±Î°ù"""
        cls.MODEL_REGISTRY[name] = model_class
        logger.info(f"üìù ÏÉà Î™®Îç∏ Îì±Î°ù: {name}")

# ==============================================
# üî• 10. Î™®Îç∏ Ïú†Ìã∏Î¶¨Ìã∞ Ìï®ÏàòÎì§
# ==============================================

def load_model_checkpoint(model, checkpoint_path: Union[str, Path], device: str = DEFAULT_DEVICE) -> bool:
    """Î™®Îç∏ Ï≤¥ÌÅ¨Ìè¨Ïù∏Ìä∏ Î°úÎî©"""
    try:
        if not TORCH_AVAILABLE:
            logger.warning("‚ö†Ô∏è PyTorch ÏóÜÏùå, Ï≤¥ÌÅ¨Ìè¨Ïù∏Ìä∏ Î°úÎî© Í±¥ÎÑàÎúÄ")
            return True
        
        checkpoint_path = Path(checkpoint_path)
        if not checkpoint_path.exists():
            logger.error(f"‚ùå Ï≤¥ÌÅ¨Ìè¨Ïù∏Ìä∏ ÌååÏùº ÏóÜÏùå: {checkpoint_path}")
            return False
        
        # ÏïàÏ†ÑÌïú Î°úÎî© (CPU Ïö∞ÏÑ†)
        checkpoint = torch.load(checkpoint_path, map_location='cpu', weights_only=False)
        
        # state_dict Ï∂îÏ∂ú
        if isinstance(checkpoint, dict):
            if 'state_dict' in checkpoint:
                state_dict = checkpoint['state_dict']
            elif 'model' in checkpoint:
                state_dict = checkpoint['model']
            else:
                state_dict = checkpoint
        else:
            # Î™®Îç∏ Í∞ùÏ≤¥Ïù∏ Í≤ΩÏö∞
            if hasattr(checkpoint, 'state_dict'):
                state_dict = checkpoint.state_dict()
            else:
                logger.error("‚ùå Ïú†Ìö®ÌïòÏßÄ ÏïäÏùÄ Ï≤¥ÌÅ¨Ìè¨Ïù∏Ìä∏ ÌòïÏãù")
                return False
        
        # Î™®Îç∏Ïóê Î°úÎìú
        if hasattr(model, 'load_state_dict'):
            model.load_state_dict(state_dict, strict=False)
            model.to(device)
            model.eval()
            logger.info(f"‚úÖ Ï≤¥ÌÅ¨Ìè¨Ïù∏Ìä∏ Î°úÎî© ÏÑ±Í≥µ: {checkpoint_path}")
            return True
        else:
            logger.warning("‚ö†Ô∏è Î™®Îç∏Ïóê load_state_dict Î©îÏÑúÎìú ÏóÜÏùå")
            return False
            
    except Exception as e:
        logger.error(f"‚ùå Ï≤¥ÌÅ¨Ìè¨Ïù∏Ìä∏ Î°úÎî© Ïã§Ìå®: {e}")
        return False

def get_model_info(model) -> Dict[str, Any]:
    """Î™®Îç∏ Ï†ïÎ≥¥ Ï°∞Ìöå"""
    try:
        info = {
            "name": getattr(model, 'model_name', model.__class__.__name__),
            "architecture": getattr(model, 'architecture', ModelArchitecture.UNKNOWN).value if hasattr(model, 'architecture') else "unknown",
            "device": getattr(model, 'device', 'unknown'),
            "is_loaded": getattr(model, 'is_loaded', False),
            "torch_available": TORCH_AVAILABLE,
            "parameters": 0
        }
        
        # ÌååÎùºÎØ∏ÌÑ∞ Ïàò Í≥ÑÏÇ∞
        if hasattr(model, 'count_parameters'):
            info["parameters"] = model.count_parameters()
        elif TORCH_AVAILABLE and hasattr(model, 'parameters'):
            info["parameters"] = sum(p.numel() for p in model.parameters())
        
        return info
        
    except Exception as e:
        logger.error(f"‚ùå Î™®Îç∏ Ï†ïÎ≥¥ Ï°∞Ìöå Ïã§Ìå®: {e}")
        return {"error": str(e)}

def optimize_model_for_inference(model, device: str = DEFAULT_DEVICE):
    """Ï∂îÎ°†Ïö© Î™®Îç∏ ÏµúÏ†ÅÌôî"""
    try:
        if not TORCH_AVAILABLE:
            return model
        
        if hasattr(model, 'eval'):
            model.eval()
        
        if hasattr(model, 'to'):
            model.to(device)
        
        # M3 Max MPS ÏµúÏ†ÅÌôî
        if device == "mps" and IS_M3_MAX:
            logger.info("üçé M3 Max MPS ÏµúÏ†ÅÌôî Ï†ÅÏö©")
            # MPS ÌäπÌôî ÏµúÏ†ÅÌôîÎäî Ïó¨Í∏∞Ïóê Ï∂îÍ∞Ä
        
        logger.info(f"‚ö° Î™®Îç∏ Ï∂îÎ°† ÏµúÏ†ÅÌôî ÏôÑÎ£å: {device}")
        return model
        
    except Exception as e:
        logger.error(f"‚ùå Î™®Îç∏ ÏµúÏ†ÅÌôî Ïã§Ìå®: {e}")
        return model

# ==============================================
# üî• 11. Î™®Îìà ÎÇ¥Î≥¥ÎÇ¥Í∏∞
# ==============================================

__all__ = [
    # Í∏∞Î≥∏ ÌÅ¥ÎûòÏä§Îì§
    'BaseAIModel',
    'AIModelFactory',
    
    # Íµ¨Ï≤¥Ï†ÅÏù∏ Î™®Îç∏Îì§
    'HumanParsingModel',
    'OpenPoseModel',
    'U2NetModel',
    'GeometricMatchingModel',
    'VirtualFittingModel',
    
    # Ïó¥Í±∞ÌòïÎì§
    'ModelArchitecture',
    'ModelPrecision',
    'ActivationType',
    
    # Ïú†Ìã∏Î¶¨Ìã∞ Ìï®ÏàòÎì§
    'load_model_checkpoint',
    'get_model_info',
    'optimize_model_for_inference',
    
    # ÏÉÅÏàòÎì§
    'TORCH_AVAILABLE',
    'DEFAULT_DEVICE',
    'IS_M3_MAX'
]

logger.info("‚úÖ AI Î™®Îç∏ ÌÅ¥ÎûòÏä§Îì§ v1.0 Î°úÎìú ÏôÑÎ£å")
logger.info(f"ü§ñ PyTorch ÏÉÅÌÉú: {'‚úÖ' if TORCH_AVAILABLE else '‚ùå'}")
logger.info(f"üîß ÎîîÎ∞îÏù¥Ïä§: {DEFAULT_DEVICE}")
logger.info(f"üçé M3 Max: {'‚úÖ' if IS_M3_MAX else '‚ùå'}")
logger.info("üéØ Ïã§Ï†ú AI Î™®Îç∏ ÏïÑÌÇ§ÌÖçÏ≤ò ÏôÑÏ†Ñ Íµ¨ÌòÑ")
logger.info("‚≠ê StepÎ≥Ñ ÌäπÌôî Î™®Îç∏ ÌÅ¥ÎûòÏä§")
logger.info("üîó PyTorch ÎÑ§Ïù¥Ìã∞Î∏å ÏßÄÏõê")
logger.info("üíæ Ï≤¥ÌÅ¨Ìè¨Ïù∏Ìä∏ Î°úÎî© ÏãúÏä§ÌÖú")
logger.info("üîÑ ÏàúÌôòÏ∞∏Ï°∞ Î∞©ÏßÄ - ÎèÖÎ¶ΩÏ†Å Î™®Îìà")
logger.info("üêç conda ÌôòÍ≤Ω Ïö∞ÏÑ† ÏßÄÏõê")