# backend/app/ai_pipeline/factories/step_factory.py
"""
ğŸ”¥ StepFactory v11.0 - DetailedDataSpec ì™„ì „ í†µí•© (GitHub í”„ë¡œì íŠ¸ í‘œì¤€)
================================================================================

âœ… step_model_requirements.pyì˜ DetailedDataSpec ì™„ì „ í™œìš©
âœ… API ì…ì¶œë ¥ ë§¤í•‘ (api_input_mapping, api_output_mapping) ì²˜ë¦¬  
âœ… Step ê°„ ë°ì´í„° íë¦„ (provides_to_next_step, accepts_from_previous_step) ê´€ë¦¬
âœ… BaseStepMixin v19.0 ì™„ì „ í˜¸í™˜ - ìƒì„±ì ì‹œì  ì˜ì¡´ì„± ì£¼ì…
âœ… keyword argument repeated: is_m3_max ì˜¤ë¥˜ ì™„ì „ í•´ê²°
âœ… conda í™˜ê²½ ìš°ì„  ìµœì í™” (mycloset-ai-clean)
âœ… M3 Max 128GB ë©”ëª¨ë¦¬ ìµœì í™”
âœ… ì‹¤ì œ AI ëª¨ë¸ 229GB íŒŒì¼ ê²½ë¡œ ë§¤í•‘
âœ… ì „ì²˜ë¦¬/í›„ì²˜ë¦¬ ìš”êµ¬ì‚¬í•­ ìë™ ì ìš©
âœ… FastAPI ë¼ìš°í„° 100% í˜¸í™˜ì„± í™•ë³´

í•µì‹¬ ìˆ˜ì •ì‚¬í•­:
1. ğŸ¯ DetailedDataSpec ì™„ì „ í†µí•© - step_model_requirements.py í™œìš©
2. ğŸ”§ API ì…ì¶œë ¥ ë§¤í•‘ ìë™ ì²˜ë¦¬ (FastAPI â†” Step í´ë˜ìŠ¤)
3. ğŸš€ Step ê°„ ë°ì´í„° íë¦„ ìë™ ê´€ë¦¬ ë° ê²€ì¦
4. ğŸ§  ì „ì²˜ë¦¬/í›„ì²˜ë¦¬ ìš”êµ¬ì‚¬í•­ ìë™ ì ìš©
5. ğŸ conda í™˜ê²½ (mycloset-ai-clean) íŠ¹í™” ìµœì í™”
6. ğŸ M3 Max 128GB ë©”ëª¨ë¦¬ ìµœì í™”
7. ğŸ“‹ ì™„ì „í•œ ë°ì´í„° ë³€í™˜ íŒŒì´í”„ë¼ì¸ êµ¬í˜„

Author: MyCloset AI Team
Date: 2025-07-27
Version: 11.0 (Complete DetailedDataSpec Integration)
"""

import os
import sys
import logging
import threading
import time
import weakref
import gc
import traceback
import uuid
import asyncio
import concurrent.futures
from pathlib import Path
from typing import Dict, Any, Optional, List, Union, Type, Tuple, TYPE_CHECKING
from dataclasses import dataclass, field
from enum import Enum, IntEnum
from abc import ABC, abstractmethod
from concurrent.futures import ThreadPoolExecutor

# ì•ˆì „í•œ íƒ€ì… íŒíŒ… (ìˆœí™˜ì°¸ì¡° ë°©ì§€)
if TYPE_CHECKING:
    from ..steps.base_step_mixin import BaseStepMixin, GitHubDependencyManager
    from ..utils.model_loader import ModelLoader
    from ..utils.memory_manager import MemoryManager
    from ..utils.data_converter import DataConverter
    from ...core.di_container import DIContainer

# ==============================================
# ğŸ”¥ í™˜ê²½ ì„¤ì • ë° ì‹œìŠ¤í…œ ì •ë³´ (GitHub í‘œì¤€)
# ==============================================

logger = logging.getLogger(__name__)

# conda í™˜ê²½ ì •ë³´ (GitHub í”„ë¡œì íŠ¸ í‘œì¤€)
CONDA_INFO = {
    'conda_env': os.environ.get('CONDA_DEFAULT_ENV', 'none'),
    'conda_prefix': os.environ.get('CONDA_PREFIX', 'none'),
    'is_target_env': os.environ.get('CONDA_DEFAULT_ENV') == 'mycloset-ai-clean'
}

# M3 Max ê°ì§€ (GitHub í”„ë¡œì íŠ¸ í‘œì¤€)
IS_M3_MAX_DETECTED = False  # ğŸ”¥ í‚¤ì›Œë“œ ì¶©ëŒ ì™„ì „ í•´ê²°
MEMORY_GB = 16.0

try:
    import platform
    if platform.system() == 'Darwin' and platform.machine() == 'arm64':
        try:
            import subprocess
            result = subprocess.run(['sysctl', '-n', 'machdep.cpu.brand_string'], 
                                  capture_output=True, text=True, timeout=3)
            IS_M3_MAX_DETECTED = 'M3' in result.stdout
            
            memory_result = subprocess.run(['sysctl', '-n', 'hw.memsize'], 
                                         capture_output=True, text=True, timeout=3)
            if memory_result.stdout.strip():
                MEMORY_GB = int(memory_result.stdout.strip()) / 1024**3
        except:
            pass
except:
    pass

# step_model_requirements.py ë™ì  ë¡œë”©
def get_step_model_requirements():
    """step_model_requirements.py ë™ì  ë¡œë”©"""
    try:
        from app.ai_pipeline.utils.step_model_requirements import (
            get_enhanced_step_request,
            get_step_api_mapping,
            get_step_preprocessing_requirements,
            get_step_postprocessing_requirements,
            get_step_data_flow,
            REAL_STEP_MODEL_REQUESTS
        )
        return {
            'get_enhanced_step_request': get_enhanced_step_request,
            'get_step_api_mapping': get_step_api_mapping,
            'get_step_preprocessing_requirements': get_step_preprocessing_requirements,
            'get_step_postprocessing_requirements': get_step_postprocessing_requirements,
            'get_step_data_flow': get_step_data_flow,
            'REAL_STEP_MODEL_REQUESTS': REAL_STEP_MODEL_REQUESTS
        }
    except ImportError as e:
        logger.warning(f"âš ï¸ step_model_requirements.py ë¡œë”© ì‹¤íŒ¨: {e}")
        return None

# step_model_requirements ëª¨ë“ˆ ë¡œë”©
STEP_MODEL_REQUIREMENTS = get_step_model_requirements()

logger.info(f"ğŸ”§ StepFactory v11.0 DetailedDataSpec í†µí•©: {'âœ… ì„±ê³µ' if STEP_MODEL_REQUIREMENTS else 'âŒ ì‹¤íŒ¨'}")
logger.info(f"ğŸ”§ í™˜ê²½: conda={CONDA_INFO['conda_env']}, M3 Max={IS_M3_MAX_DETECTED}, ë©”ëª¨ë¦¬={MEMORY_GB:.1f}GB")

# ==============================================
# ğŸ”¥ GitHub í”„ë¡œì íŠ¸ í‘œì¤€ ë°ì´í„° êµ¬ì¡° (DetailedDataSpec í†µí•©)
# ==============================================

class StepType(Enum):
    """GitHub í”„ë¡œì íŠ¸ í‘œì¤€ Step íƒ€ì…"""
    HUMAN_PARSING = "human_parsing"
    POSE_ESTIMATION = "pose_estimation"
    CLOTH_SEGMENTATION = "cloth_segmentation"
    GEOMETRIC_MATCHING = "geometric_matching"
    CLOTH_WARPING = "cloth_warping"
    VIRTUAL_FITTING = "virtual_fitting"
    POST_PROCESSING = "post_processing"
    QUALITY_ASSESSMENT = "quality_assessment"

class StepPriority(IntEnum):
    """GitHub í”„ë¡œì íŠ¸ í‘œì¤€ Step ìš°ì„ ìˆœìœ„ (ì‹¤ì œ AI ëª¨ë¸ í¬ê¸° ê¸°ë°˜)"""
    CRITICAL = 1    # Virtual Fitting (14GB), Human Parsing (4GB)
    HIGH = 2        # Cloth Warping (7GB), Quality Assessment (7GB)
    NORMAL = 3      # Cloth Segmentation (5.5GB), Pose Estimation (3.4GB)
    LOW = 4         # Post Processing (1.3GB), Geometric Matching (1.3GB)

@dataclass
class DetailedDataSpecConfig:
    """DetailedDataSpec ì™„ì „ í†µí•© ì„¤ì •"""
    # API ë§¤í•‘ (FastAPI â†” Step í´ë˜ìŠ¤)
    api_input_mapping: Dict[str, Any] = field(default_factory=dict)
    api_output_mapping: Dict[str, Any] = field(default_factory=dict)
    
    # Step ê°„ ë°ì´í„° íë¦„
    accepts_from_previous_step: Dict[str, Any] = field(default_factory=dict)
    provides_to_next_step: Dict[str, Any] = field(default_factory=dict)
    step_input_schema: Dict[str, Any] = field(default_factory=dict)
    step_output_schema: Dict[str, Any] = field(default_factory=dict)
    
    # ì…ì¶œë ¥ ë°ì´í„° ì‚¬ì–‘
    input_data_types: List[str] = field(default_factory=list)
    output_data_types: List[str] = field(default_factory=list)
    input_shapes: Dict[str, List[int]] = field(default_factory=dict)
    output_shapes: Dict[str, List[int]] = field(default_factory=dict)
    input_value_ranges: Dict[str, Tuple[float, float]] = field(default_factory=dict)
    output_value_ranges: Dict[str, Tuple[float, float]] = field(default_factory=dict)
    
    # ì „ì²˜ë¦¬/í›„ì²˜ë¦¬
    preprocessing_required: bool = True
    postprocessing_required: bool = True
    preprocessing_steps: List[str] = field(default_factory=list)
    postprocessing_steps: List[str] = field(default_factory=list)
    normalization_mean: List[float] = field(default_factory=lambda: [0.485, 0.456, 0.406])
    normalization_std: List[float] = field(default_factory=lambda: [0.229, 0.224, 0.225])

@dataclass
class EnhancedGitHubStepConfig:
    """GitHub í”„ë¡œì íŠ¸ í‘œì¤€ Step ì„¤ì • + DetailedDataSpec í†µí•©"""
    # GitHub ê¸°ë³¸ Step ì •ë³´
    step_name: str
    step_id: int
    step_type: StepType
    class_name: str
    module_path: str
    priority: StepPriority = StepPriority.NORMAL
    
    # BaseStepMixin v19.0 í‘œì¤€ ì„¤ì •
    device: str = "auto"
    use_fp16: bool = True
    batch_size: int = 1
    confidence_threshold: float = 0.8
    
    # GitHub ìµœì í™” ì„¤ì •
    auto_memory_cleanup: bool = True
    auto_warmup: bool = True
    optimization_enabled: bool = True
    strict_mode: bool = False
    quality_level: str = "balanced"
    
    # GitHub ì˜ì¡´ì„± ì„¤ì • (v19.0 í‘œì¤€)
    auto_inject_dependencies: bool = True
    require_model_loader: bool = True
    require_memory_manager: bool = False
    require_data_converter: bool = False
    require_di_container: bool = False
    require_unified_dependency_manager: bool = True
    dependency_timeout: float = 30.0
    dependency_retry_count: int = 3
    
    # GitHub AI ëª¨ë¸ ì •ë³´ (ì‹¤ì œ 229GB íŒŒì¼ ê¸°ë°˜)
    ai_models: List[str] = field(default_factory=list)
    model_size_gb: float = 0.0
    
    # ğŸ”¥ conda/M3 Max ìµœì í™” (í‚¤ì›Œë“œ ì¶©ëŒ ì™„ì „ í•´ê²°)
    conda_optimized: bool = True
    m3_max_optimized: bool = True
    conda_env: Optional[str] = None
    memory_gb: float = 16.0
    
    # ğŸ”¥ í™˜ê²½ ê°ì§€ í”Œë˜ê·¸ë“¤ (í‚¤ì›Œë“œ ì¶©ëŒ ì™„ì „ í•´ê²°)
    is_m3_max_detected: bool = False  # ğŸ”¥ ë³€ê²½: is_m3_max â†’ is_m3_max_detected
    github_compatible: bool = True
    mycloset_optimized: bool = False
    memory_optimization: bool = False
    conda_target_env: bool = False
    ultra_optimization: bool = False
    performance_mode: str = "balanced"
    memory_pool_enabled: bool = False
    mps_available: bool = False
    mps_optimization: bool = False
    metal_performance_shaders: bool = False
    unified_memory_pool: bool = False
    cuda_optimization: bool = False
    tensor_cores: bool = False
    use_unified_memory: bool = False
    emergency_mode: bool = False
    error_message: Optional[str] = None
    
    # GitHub AI ëª¨ë¸ ê²½ë¡œ ë° ì„¤ì • (ì‹¤ì œ íŒŒì¼ êµ¬ì¡° ê¸°ë°˜)
    ai_model_paths: Dict[str, str] = field(default_factory=dict)
    alternative_path: Optional[str] = None
    real_ai_mode: bool = True
    basestepmixin_compatible: bool = True
    modelloader_required: bool = True
    disable_fallback: bool = True
    
    # ğŸ”¥ DetailedDataSpec ì™„ì „ í†µí•©
    detailed_data_spec: DetailedDataSpecConfig = field(default_factory=DetailedDataSpecConfig)

    def __post_init__(self):
        """GitHub í‘œì¤€ ì´ˆê¸°í™” í›„ ì„¤ì • ë³´ì • + DetailedDataSpec ë¡œë”©"""
        # conda_env ìë™ ì„¤ì •
        if self.conda_env is None:
            self.conda_env = CONDA_INFO['conda_env']
        
        # memory_gb ìë™ ì„¤ì •
        if self.memory_gb <= 0:
            self.memory_gb = MEMORY_GB
        
        # AI ëª¨ë¸ ë¦¬ìŠ¤íŠ¸ ì •ê·œí™”
        if not isinstance(self.ai_models, list):
            self.ai_models = []
        
        # AI ëª¨ë¸ ê²½ë¡œ ë”•ì…”ë„ˆë¦¬ ì •ê·œí™”
        if not isinstance(self.ai_model_paths, dict):
            self.ai_model_paths = {}
        
        # ğŸ”¥ M3 Max ê°ì§€ ë° ìë™ ì„¤ì • (í‚¤ì›Œë“œ ì¶©ëŒ ì—†ì´)
        if IS_M3_MAX_DETECTED:
            self.is_m3_max_detected = True  # ğŸ”¥ ë³€ê²½ëœ í”Œë˜ê·¸ ì‚¬ìš©
            self.mps_available = True
            self.metal_performance_shaders = True
            self.unified_memory_pool = True
            self.use_unified_memory = True
        
        # conda íƒ€ê²Ÿ í™˜ê²½ ê°ì§€
        if CONDA_INFO['is_target_env']:
            self.conda_target_env = True
            self.mycloset_optimized = True
            self.memory_optimization = True
        
        # GitHub ìš¸íŠ¸ë¼ ìµœì í™” ìë™ í™œì„±í™”
        if self.is_m3_max_detected and self.conda_target_env:
            self.ultra_optimization = True
            self.performance_mode = 'maximum'
            self.memory_pool_enabled = True
        
        # ğŸ”¥ DetailedDataSpec ìë™ ë¡œë”© (step_model_requirements.py í™œìš©)
        self._load_detailed_data_spec()
    
    def _load_detailed_data_spec(self):
        """step_model_requirements.pyì—ì„œ DetailedDataSpec ìë™ ë¡œë”©"""
        if not STEP_MODEL_REQUIREMENTS:
            logger.warning(f"âš ï¸ {self.step_name}: step_model_requirements.py ì—†ìŒ, ê¸°ë³¸ ì„¤ì • ì‚¬ìš©")
            return
        
        try:
            # Step ì´ë¦„ìœ¼ë¡œ enhanced step request ê°€ì ¸ì˜¤ê¸°
            enhanced_request = STEP_MODEL_REQUIREMENTS['get_enhanced_step_request'](self.step_name)
            if not enhanced_request:
                logger.warning(f"âš ï¸ {self.step_name}: step_model_requirementsì—ì„œ ì„¤ì • ì—†ìŒ")
                return
            
            # DetailedDataSpec ë°ì´í„° ë³µì‚¬
            data_spec = enhanced_request.data_spec
            
            self.detailed_data_spec.api_input_mapping = data_spec.api_input_mapping.copy()
            self.detailed_data_spec.api_output_mapping = data_spec.api_output_mapping.copy()
            self.detailed_data_spec.accepts_from_previous_step = data_spec.accepts_from_previous_step.copy()
            self.detailed_data_spec.provides_to_next_step = data_spec.provides_to_next_step.copy()
            self.detailed_data_spec.step_input_schema = data_spec.step_input_schema.copy()
            self.detailed_data_spec.step_output_schema = data_spec.step_output_schema.copy()
            
            self.detailed_data_spec.input_data_types = data_spec.input_data_types.copy()
            self.detailed_data_spec.output_data_types = data_spec.output_data_types.copy()
            self.detailed_data_spec.input_shapes = data_spec.input_shapes.copy()
            self.detailed_data_spec.output_shapes = data_spec.output_shapes.copy()
            self.detailed_data_spec.input_value_ranges = data_spec.input_value_ranges.copy()
            self.detailed_data_spec.output_value_ranges = data_spec.output_value_ranges.copy()
            
            self.detailed_data_spec.preprocessing_required = data_spec.preprocessing_required
            self.detailed_data_spec.postprocessing_required = data_spec.postprocessing_required
            self.detailed_data_spec.preprocessing_steps = data_spec.preprocessing_steps.copy()
            self.detailed_data_spec.postprocessing_steps = data_spec.postprocessing_steps.copy()
            self.detailed_data_spec.normalization_mean = data_spec.normalization_mean.copy()
            self.detailed_data_spec.normalization_std = data_spec.normalization_std.copy()
            
            logger.info(f"âœ… {self.step_name}: DetailedDataSpec ë¡œë”© ì™„ë£Œ")
            logger.debug(f"   - API ì…ë ¥ ë§¤í•‘: {len(self.detailed_data_spec.api_input_mapping)}ê°œ")
            logger.debug(f"   - API ì¶œë ¥ ë§¤í•‘: {len(self.detailed_data_spec.api_output_mapping)}ê°œ")
            logger.debug(f"   - ì „ì²˜ë¦¬ ë‹¨ê³„: {len(self.detailed_data_spec.preprocessing_steps)}ê°œ")
            logger.debug(f"   - í›„ì²˜ë¦¬ ë‹¨ê³„: {len(self.detailed_data_spec.postprocessing_steps)}ê°œ")
            
        except Exception as e:
            logger.error(f"âŒ {self.step_name}: DetailedDataSpec ë¡œë”© ì‹¤íŒ¨ - {e}")

@dataclass
class GitHubStepCreationResult:
    """GitHub í”„ë¡œì íŠ¸ í‘œì¤€ Step ìƒì„± ê²°ê³¼ + DetailedDataSpec í†µí•©"""
    success: bool
    step_instance: Optional['BaseStepMixin'] = None
    step_name: str = ""
    step_type: Optional[StepType] = None
    class_name: str = ""
    module_path: str = ""
    creation_time: float = 0.0
    error_message: Optional[str] = None
    warnings: List[str] = field(default_factory=list)
    
    # GitHub ì˜ì¡´ì„± ì£¼ì… ê²°ê³¼
    dependencies_injected: Dict[str, bool] = field(default_factory=dict)
    initialization_success: bool = False
    ai_models_loaded: List[str] = field(default_factory=list)
    
    # GitHub BaseStepMixin v19.0 í˜¸í™˜ì„± ê²€ì¦
    github_compatible: bool = True
    basestepmixin_v19_compatible: bool = True
    process_method_validated: bool = False
    dependency_injection_success: bool = False
    
    # ğŸ”¥ DetailedDataSpec í†µí•© ê²°ê³¼
    detailed_data_spec_loaded: bool = False
    api_mappings_applied: Dict[str, Any] = field(default_factory=dict)
    data_flow_configured: Dict[str, Any] = field(default_factory=dict)
    preprocessing_configured: bool = False
    postprocessing_configured: bool = False

# ==============================================
# ğŸ”¥ GitHub í”„ë¡œì íŠ¸ í‘œì¤€ Step ë§¤í•‘ (DetailedDataSpec í†µí•©)
# ==============================================

class EnhancedGitHubStepMapping:
    """GitHub í”„ë¡œì íŠ¸ í‘œì¤€ í˜¸í™˜ Step ë§¤í•‘ + DetailedDataSpec ì™„ì „ í†µí•©"""
    
    GITHUB_STEP_CONFIGS = {
        StepType.HUMAN_PARSING: EnhancedGitHubStepConfig(
            step_name="HumanParsingStep",
            step_id=1,
            step_type=StepType.HUMAN_PARSING,
            class_name="HumanParsingStep",
            module_path="app.ai_pipeline.steps.step_01_human_parsing",
            priority=StepPriority.CRITICAL,
            ai_models=["graphonomy", "atr_model", "human_parsing_schp"],
            model_size_gb=4.0,
            require_model_loader=True,
            require_memory_manager=True
        ),
        StepType.POSE_ESTIMATION: EnhancedGitHubStepConfig(
            step_name="PoseEstimationStep",
            step_id=2,
            step_type=StepType.POSE_ESTIMATION,
            class_name="PoseEstimationStep",
            module_path="app.ai_pipeline.steps.step_02_pose_estimation",
            priority=StepPriority.NORMAL,
            ai_models=["openpose", "yolov8_pose", "diffusion_pose"],
            model_size_gb=3.4,
            require_model_loader=True,
            require_memory_manager=True
        ),
        StepType.CLOTH_SEGMENTATION: EnhancedGitHubStepConfig(
            step_name="ClothSegmentationStep",
            step_id=3,
            step_type=StepType.CLOTH_SEGMENTATION,
            class_name="ClothSegmentationStep",
            module_path="app.ai_pipeline.steps.step_03_cloth_segmentation",
            priority=StepPriority.NORMAL,
            ai_models=["u2net", "sam_huge", "cloth_segmentation"],
            model_size_gb=5.5,
            require_model_loader=True,
            require_memory_manager=True
        ),
        StepType.GEOMETRIC_MATCHING: EnhancedGitHubStepConfig(
            step_name="GeometricMatchingStep",
            step_id=4,
            step_type=StepType.GEOMETRIC_MATCHING,
            class_name="GeometricMatchingStep",
            module_path="app.ai_pipeline.steps.step_04_geometric_matching",
            priority=StepPriority.LOW,
            ai_models=["gmm", "tps_network", "geometric_matching"],
            model_size_gb=1.3,
            require_model_loader=True
        ),
        StepType.CLOTH_WARPING: EnhancedGitHubStepConfig(
            step_name="ClothWarpingStep",
            step_id=5,
            step_type=StepType.CLOTH_WARPING,
            class_name="ClothWarpingStep",
            module_path="app.ai_pipeline.steps.step_05_cloth_warping",
            priority=StepPriority.HIGH,
            ai_models=["cloth_warping", "stable_diffusion", "hrviton"],
            model_size_gb=7.0,
            require_model_loader=True,
            require_memory_manager=True
        ),
        StepType.VIRTUAL_FITTING: EnhancedGitHubStepConfig(
            step_name="VirtualFittingStep",
            step_id=6,
            step_type=StepType.VIRTUAL_FITTING,
            class_name="VirtualFittingStep",
            module_path="app.ai_pipeline.steps.step_06_virtual_fitting",
            priority=StepPriority.CRITICAL,
            ai_models=["ootdiffusion", "hr_viton", "virtual_fitting"],
            model_size_gb=14.0,
            require_model_loader=True,
            require_memory_manager=True,
            require_data_converter=True
        ),
        StepType.POST_PROCESSING: EnhancedGitHubStepConfig(
            step_name="PostProcessingStep",
            step_id=7,
            step_type=StepType.POST_PROCESSING,
            class_name="PostProcessingStep",
            module_path="app.ai_pipeline.steps.step_07_post_processing",
            priority=StepPriority.LOW,
            ai_models=["super_resolution", "realesrgan", "enhancement"],
            model_size_gb=1.3,
            require_model_loader=True
        ),
        StepType.QUALITY_ASSESSMENT: EnhancedGitHubStepConfig(
            step_name="QualityAssessmentStep",
            step_id=8,
            step_type=StepType.QUALITY_ASSESSMENT,
            class_name="QualityAssessmentStep",
            module_path="app.ai_pipeline.steps.step_08_quality_assessment",
            priority=StepPriority.HIGH,
            ai_models=["clip", "quality_assessment", "perceptual_loss"],
            model_size_gb=7.0,
            require_model_loader=True,
            require_data_converter=True
        )
    }
    
    @classmethod
    def get_enhanced_github_config(cls, step_type: StepType, **overrides) -> EnhancedGitHubStepConfig:
        """GitHub í”„ë¡œì íŠ¸ í‘œì¤€ í˜¸í™˜ ì„¤ì • ë°˜í™˜ + DetailedDataSpec ìë™ ë¡œë”©"""
        base_config = cls.GITHUB_STEP_CONFIGS[step_type]
        
        # kwargsì— conda_envê°€ ì—†ìœ¼ë©´ ìë™ ì¶”ê°€
        if 'conda_env' not in overrides:
            overrides['conda_env'] = os.environ.get('CONDA_DEFAULT_ENV', 'none')
        
        # ğŸ”¥ í‚¤ì›Œë“œ ì¶©ëŒ ì™„ì „ ë°©ì§€ í•„í„°ë§
        filtered_overrides = {}
        config_fields = {f.name for f in base_config.__dataclass_fields__}
        
        for key, value in overrides.items():
            if key in config_fields:
                filtered_overrides[key] = value
            else:
                logger.debug(f"âš ï¸ ë¬´ì‹œëœ í‚¤ì›Œë“œ: {key} (EnhancedGitHubStepConfigì— ì—†ìŒ)")
        
        # ì»¤ìŠ¤í…€ ì„¤ì •ì´ ìˆìœ¼ë©´ ì ìš©
        if filtered_overrides:
            # ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜í•˜ì—¬ ì˜¤ë²„ë¼ì´ë“œ ì ìš©
            config_dict = {
                'step_name': base_config.step_name,
                'step_id': base_config.step_id,
                'step_type': base_config.step_type,
                'class_name': base_config.class_name,
                'module_path': base_config.module_path,
                'priority': base_config.priority,
                'device': base_config.device,
                'use_fp16': base_config.use_fp16,
                'batch_size': base_config.batch_size,
                'confidence_threshold': base_config.confidence_threshold,
                'auto_memory_cleanup': base_config.auto_memory_cleanup,
                'auto_warmup': base_config.auto_warmup,
                'optimization_enabled': base_config.optimization_enabled,
                'strict_mode': base_config.strict_mode,
                'quality_level': base_config.quality_level,
                'auto_inject_dependencies': base_config.auto_inject_dependencies,
                'require_model_loader': base_config.require_model_loader,
                'require_memory_manager': base_config.require_memory_manager,
                'require_data_converter': base_config.require_data_converter,
                'require_di_container': base_config.require_di_container,
                'require_unified_dependency_manager': base_config.require_unified_dependency_manager,
                'dependency_timeout': base_config.dependency_timeout,
                'dependency_retry_count': base_config.dependency_retry_count,
                'ai_models': base_config.ai_models.copy(),
                'model_size_gb': base_config.model_size_gb,
                'conda_optimized': base_config.conda_optimized,
                'm3_max_optimized': base_config.m3_max_optimized,
                'conda_env': base_config.conda_env,
                'memory_gb': base_config.memory_gb
            }
            # filtered_overridesë¥¼ ì ìš©
            config_dict.update(filtered_overrides)
            return EnhancedGitHubStepConfig(**config_dict)
        
        return base_config

# ==============================================
# ğŸ”¥ DetailedDataSpec ì™„ì „ í™œìš© ì˜ì¡´ì„± í•´ê²°ê¸°
# ==============================================

class EnhancedGitHubDependencyResolver:
    """DetailedDataSpec ì™„ì „ í™œìš© GitHub ì˜ì¡´ì„± í•´ê²°ê¸°"""
    
    def __init__(self):
        self.logger = logging.getLogger(f"{__name__}.EnhancedGitHubDependencyResolver")
        self._resolved_cache: Dict[str, Any] = {}
        self._lock = threading.RLock()
        self._resolution_attempts: Dict[str, int] = {}
        self._max_attempts = 3
    
    def resolve_enhanced_github_dependencies_for_constructor(self, config: EnhancedGitHubStepConfig) -> Dict[str, Any]:
        """DetailedDataSpec ì™„ì „ í™œìš© GitHub ì˜ì¡´ì„± í•´ê²° (ìƒì„±ììš©)"""
        try:
            self.logger.info(f"ğŸ”„ {config.step_name} DetailedDataSpec í†µí•© ì˜ì¡´ì„± í•´ê²° ì‹œì‘...")
            
            # ğŸ”¥ ê¸°ë³¸ dependency ë”•ì…”ë„ˆë¦¬ (í‚¤ì›Œë“œ ì¶©ëŒ ì™„ì „ ì—†ìŒ)
            dependencies = {}
            
            # 1. GitHub BaseStepMixin v19.0 í‘œì¤€ ì„¤ì •ë“¤
            dependencies.update({
                'step_name': config.step_name,
                'step_id': config.step_id,
                'device': self._resolve_github_device(config.device),
                'use_fp16': config.use_fp16,
                'batch_size': config.batch_size,
                'confidence_threshold': config.confidence_threshold,
                'auto_memory_cleanup': config.auto_memory_cleanup,
                'auto_warmup': config.auto_warmup,
                'optimization_enabled': config.optimization_enabled,
                'strict_mode': config.strict_mode,
                'github_compatibility_mode': config.github_compatible
            })
            
            # 2. conda í™˜ê²½ ì„¤ì • (GitHub í‘œì¤€)
            if config.conda_optimized:
                conda_env = getattr(config, 'conda_env', None) or CONDA_INFO['conda_env']
                
                dependencies.update({
                    'conda_optimized': True,
                    'conda_env': conda_env
                })
                
                # mycloset-ai-clean í™˜ê²½ íŠ¹ë³„ ìµœì í™”
                if conda_env == 'mycloset-ai-clean' or CONDA_INFO['is_target_env']:
                    dependencies.update({
                        'mycloset_optimized': True,
                        'memory_optimization': True,
                        'conda_target_env': True
                    })
                    self.logger.info(f"âœ… {config.step_name} mycloset-ai-clean í™˜ê²½ ìµœì í™” ì ìš©")
            
            # 3. ğŸ”¥ M3 Max í•˜ë“œì›¨ì–´ ìµœì í™” (í‚¤ì›Œë“œ ì¶©ëŒ ì™„ì „ í•´ê²°)
            if config.m3_max_optimized and IS_M3_MAX_DETECTED:
                dependencies.update({
                    'm3_max_optimized': True,
                    'memory_gb': MEMORY_GB,
                    'use_unified_memory': True,
                    'is_m3_max_detected': True,  # ğŸ”¥ ë³€ê²½ëœ í‚¤ì›Œë“œ ì‚¬ìš©
                    'mps_available': True if dependencies.get('device') == 'mps' else False
                })
                self.logger.info(f"âœ… {config.step_name} M3 Max ìµœì í™” ì ìš© ({MEMORY_GB}GB)")
            
            # 4. GitHub ì˜ì¡´ì„± ì»´í¬ë„ŒíŠ¸ë“¤ ì•ˆì „í•œ í•´ê²°
            self._inject_github_component_dependencies(config, dependencies)
            
            # 5. GitHub AI ëª¨ë¸ ì„¤ì • ë° ê²½ë¡œ ë§¤í•‘ (ì‹¤ì œ 229GB íŒŒì¼ ê¸°ë°˜)
            dependencies.update({
                'ai_models': config.ai_models.copy() if hasattr(config.ai_models, 'copy') else list(config.ai_models),
                'model_size_gb': config.model_size_gb,
                'real_ai_mode': config.real_ai_mode
            })
            
            # 6. ğŸ”¥ DetailedDataSpec ì™„ì „ í†µí•© (í•µì‹¬!)
            self._inject_detailed_data_spec_dependencies(config, dependencies)
            
            # 7. GitHub í™˜ê²½ë³„ ì„±ëŠ¥ ìµœì í™” ì„¤ì •
            self._apply_github_performance_optimizations(dependencies)
            
            # 8. ê²°ê³¼ ê²€ì¦ ë° ë¡œê¹…
            resolved_count = len([k for k, v in dependencies.items() if v is not None])
            total_items = len(dependencies)
            
            self.logger.info(f"âœ… {config.step_name} DetailedDataSpec í†µí•© ì˜ì¡´ì„± í•´ê²° ì™„ë£Œ:")
            self.logger.info(f"   - ì´ í•­ëª©: {total_items}ê°œ")
            self.logger.info(f"   - í•´ê²°ëœ í•­ëª©: {resolved_count}ê°œ")
            self.logger.info(f"   - conda í™˜ê²½: {dependencies.get('conda_env', 'none')}")
            self.logger.info(f"   - ë””ë°”ì´ìŠ¤: {dependencies.get('device', 'unknown')}")
            self.logger.info(f"   - API ë§¤í•‘: {len(dependencies.get('api_input_mapping', {}))}ê°œ ì…ë ¥, {len(dependencies.get('api_output_mapping', {}))}ê°œ ì¶œë ¥")
            self.logger.info(f"   - ë°ì´í„° íë¦„: {len(dependencies.get('step_data_flow', {}))}ê°œ ì—°ê²°")
            
            # GitHub í•„ìˆ˜ ì˜ì¡´ì„± ê²€ì¦ (strict_modeì¼ ë•Œ)
            if config.strict_mode:
                self._validate_github_critical_dependencies(dependencies)
            
            return dependencies
            
        except Exception as e:
            self.logger.error(f"âŒ {config.step_name} DetailedDataSpec í†µí•© ì˜ì¡´ì„± í•´ê²° ì‹¤íŒ¨: {e}")
            
            # ì‘ê¸‰ ëª¨ë“œ: ìµœì†Œí•œì˜ ì˜ì¡´ì„±ë§Œ ë°˜í™˜
            if not config.strict_mode:
                return self._create_github_emergency_dependencies(config, str(e))
            else:
                raise
    
    def _inject_detailed_data_spec_dependencies(self, config: EnhancedGitHubStepConfig, dependencies: Dict[str, Any]):
        """ğŸ”¥ DetailedDataSpec ì˜ì¡´ì„± ì£¼ì… (í•µì‹¬ ë©”ì„œë“œ)"""
        try:
            self.logger.info(f"ğŸ”„ {config.step_name} DetailedDataSpec ì˜ì¡´ì„± ì£¼ì… ì¤‘...")
            
            # DetailedDataSpec ë°ì´í„° ì¶”ì¶œ
            data_spec = config.detailed_data_spec
            
            # 1. API ë§¤í•‘ ì£¼ì… (FastAPI â†” Step í´ë˜ìŠ¤)
            dependencies.update({
                'api_input_mapping': data_spec.api_input_mapping.copy(),
                'api_output_mapping': data_spec.api_output_mapping.copy(),
                'fastapi_compatible': len(data_spec.api_input_mapping) > 0
            })
            
            # 2. Step ê°„ ë°ì´í„° íë¦„ ì£¼ì…
            dependencies.update({
                'accepts_from_previous_step': data_spec.accepts_from_previous_step.copy(),
                'provides_to_next_step': data_spec.provides_to_next_step.copy(),
                'step_input_schema': data_spec.step_input_schema.copy(),
                'step_output_schema': data_spec.step_output_schema.copy(),
                'step_data_flow': {
                    'accepts_from': list(data_spec.accepts_from_previous_step.keys()),
                    'provides_to': list(data_spec.provides_to_next_step.keys()),
                    'is_pipeline_start': len(data_spec.accepts_from_previous_step) == 0,
                    'is_pipeline_end': len(data_spec.provides_to_next_step) == 0
                }
            })
            
            # 3. ì…ì¶œë ¥ ë°ì´í„° ì‚¬ì–‘ ì£¼ì…
            dependencies.update({
                'input_data_types': data_spec.input_data_types.copy(),
                'output_data_types': data_spec.output_data_types.copy(),
                'input_shapes': data_spec.input_shapes.copy(),
                'output_shapes': data_spec.output_shapes.copy(),
                'input_value_ranges': data_spec.input_value_ranges.copy(),
                'output_value_ranges': data_spec.output_value_ranges.copy(),
                'data_validation_enabled': True
            })
            
            # 4. ì „ì²˜ë¦¬/í›„ì²˜ë¦¬ ì„¤ì • ì£¼ì…
            dependencies.update({
                'preprocessing_required': data_spec.preprocessing_required,
                'postprocessing_required': data_spec.postprocessing_required,
                'preprocessing_steps': data_spec.preprocessing_steps.copy(),
                'postprocessing_steps': data_spec.postprocessing_steps.copy(),
                'normalization_mean': data_spec.normalization_mean.copy(),
                'normalization_std': data_spec.normalization_std.copy(),
                'preprocessing_config': {
                    'steps': data_spec.preprocessing_steps,
                    'normalization': {
                        'mean': data_spec.normalization_mean,
                        'std': data_spec.normalization_std
                    },
                    'value_ranges': data_spec.input_value_ranges
                },
                'postprocessing_config': {
                    'steps': data_spec.postprocessing_steps,
                    'value_ranges': data_spec.output_value_ranges,
                    'output_shapes': data_spec.output_shapes
                }
            })
            
            # 5. DetailedDataSpec ë©”íƒ€ì •ë³´
            dependencies.update({
                'detailed_data_spec_loaded': True,
                'detailed_data_spec_version': 'v8.0',
                'step_model_requirements_integrated': STEP_MODEL_REQUIREMENTS is not None
            })
            
            self.logger.info(f"âœ… {config.step_name} DetailedDataSpec ì˜ì¡´ì„± ì£¼ì… ì™„ë£Œ")
            self.logger.debug(f"   - API ë§¤í•‘: {len(data_spec.api_input_mapping)}â†’{len(data_spec.api_output_mapping)}")
            self.logger.debug(f"   - ë°ì´í„° íë¦„: {len(data_spec.accepts_from_previous_step)}â†’{len(data_spec.provides_to_next_step)}")
            self.logger.debug(f"   - ì „ì²˜ë¦¬: {len(data_spec.preprocessing_steps)}ë‹¨ê³„")
            self.logger.debug(f"   - í›„ì²˜ë¦¬: {len(data_spec.postprocessing_steps)}ë‹¨ê³„")
            
        except Exception as e:
            self.logger.error(f"âŒ {config.step_name} DetailedDataSpec ì˜ì¡´ì„± ì£¼ì… ì‹¤íŒ¨: {e}")
            # ì‹¤íŒ¨í•´ë„ ê¸°ë³¸ ì„¤ì •ìœ¼ë¡œ ì§„í–‰
            dependencies.update({
                'detailed_data_spec_loaded': False,
                'detailed_data_spec_error': str(e)
            })
    
    def _inject_github_component_dependencies(self, config: EnhancedGitHubStepConfig, dependencies: Dict[str, Any]):
        """GitHub í”„ë¡œì íŠ¸ í‘œì¤€ ì»´í¬ë„ŒíŠ¸ ì˜ì¡´ì„± ì£¼ì…"""
        # ModelLoader ì˜ì¡´ì„± (GitHub í‘œì¤€)
        if config.require_model_loader:
            try:
                model_loader = self._resolve_github_model_loader()
                dependencies['model_loader'] = model_loader
                if model_loader:
                    self.logger.info(f"âœ… {config.step_name} GitHub ModelLoader ìƒì„±ì ì£¼ì… ì¤€ë¹„")
                else:
                    self.logger.warning(f"âš ï¸ {config.step_name} GitHub ModelLoader í•´ê²° ì‹¤íŒ¨")
            except Exception as e:
                self.logger.error(f"âŒ {config.step_name} GitHub ModelLoader í•´ê²° ì¤‘ ì˜¤ë¥˜: {e}")
                dependencies['model_loader'] = None
        
        # MemoryManager ì˜ì¡´ì„± (GitHub í‘œì¤€)
        if config.require_memory_manager:
            try:
                memory_manager = self._resolve_github_memory_manager()
                dependencies['memory_manager'] = memory_manager
                if memory_manager:
                    self.logger.info(f"âœ… {config.step_name} GitHub MemoryManager ìƒì„±ì ì£¼ì… ì¤€ë¹„")
            except Exception as e:
                self.logger.error(f"âŒ {config.step_name} GitHub MemoryManager í•´ê²° ì¤‘ ì˜¤ë¥˜: {e}")
                dependencies['memory_manager'] = None
        
        # DataConverter ì˜ì¡´ì„± (GitHub í‘œì¤€)
        if config.require_data_converter:
            try:
                data_converter = self._resolve_github_data_converter()
                dependencies['data_converter'] = data_converter
                if data_converter:
                    self.logger.info(f"âœ… {config.step_name} GitHub DataConverter ìƒì„±ì ì£¼ì… ì¤€ë¹„")
            except Exception as e:
                self.logger.error(f"âŒ {config.step_name} GitHub DataConverter í•´ê²° ì¤‘ ì˜¤ë¥˜: {e}")
                dependencies['data_converter'] = None
        
        # DIContainer ì˜ì¡´ì„± (GitHub í‘œì¤€)
        if config.require_di_container:
            try:
                di_container = self._resolve_github_di_container()
                dependencies['di_container'] = di_container
                if di_container:
                    self.logger.info(f"âœ… {config.step_name} GitHub DIContainer ìƒì„±ì ì£¼ì… ì¤€ë¹„")
            except Exception as e:
                self.logger.error(f"âŒ {config.step_name} GitHub DIContainer í•´ê²° ì¤‘ ì˜¤ë¥˜: {e}")
                dependencies['di_container'] = None
        
        # UnifiedDependencyManager ì˜ì¡´ì„± (GitHub í‘œì¤€)
        if config.require_unified_dependency_manager:
            try:
                unified_dep_manager = self._resolve_github_unified_dependency_manager()
                dependencies['unified_dependency_manager'] = unified_dep_manager
                if unified_dep_manager:
                    self.logger.info(f"âœ… {config.step_name} GitHub UnifiedDependencyManager ìƒì„±ì ì£¼ì… ì¤€ë¹„")
            except Exception as e:
                self.logger.error(f"âŒ {config.step_name} GitHub UnifiedDependencyManager í•´ê²° ì¤‘ ì˜¤ë¥˜: {e}")
                dependencies['unified_dependency_manager'] = None

    def _apply_github_performance_optimizations(self, dependencies: Dict[str, Any]):
        """GitHub í”„ë¡œì íŠ¸ í‘œì¤€ ì„±ëŠ¥ ìµœì í™” ì„¤ì • ì ìš©"""
        # conda + M3 Max ì¡°í•© ìµœì í™” (GitHub í‘œì¤€)
        if (dependencies.get('conda_target_env') and dependencies.get('is_m3_max_detected')):
            dependencies.update({
                'ultra_optimization': True,
                'performance_mode': 'maximum',
                'memory_pool_enabled': True
            })
            
        # ë””ë°”ì´ìŠ¤ë³„ ìµœì í™” (GitHub í‘œì¤€)
        device = dependencies.get('device', 'cpu')
        if device == 'mps' and dependencies.get('is_m3_max_detected'):
            dependencies.update({
                'mps_optimization': True,
                'metal_performance_shaders': True,
                'unified_memory_pool': True
            })
        elif device == 'cuda':
            dependencies.update({
                'cuda_optimization': True,
                'tensor_cores': True
            })

    def _validate_github_critical_dependencies(self, dependencies: Dict[str, Any]):
        """GitHub í•„ìˆ˜ ì˜ì¡´ì„± ê²€ì¦ + DetailedDataSpec ê²€ì¦"""
        critical_deps = ['step_name', 'step_id', 'device']
        missing_critical = [dep for dep in critical_deps if not dependencies.get(dep)]
        if missing_critical:
            raise RuntimeError(f"GitHub Strict Mode: í•„ìˆ˜ ì˜ì¡´ì„± ëˆ„ë½ - {missing_critical}")
        
        # DetailedDataSpec í•„ìˆ˜ ìš”ì†Œ ê²€ì¦
        if dependencies.get('detailed_data_spec_loaded'):
            required_data_spec_items = ['api_input_mapping', 'api_output_mapping']
            missing_data_spec = [item for item in required_data_spec_items if not dependencies.get(item)]
            if missing_data_spec and dependencies.get('fastapi_compatible'):
                raise RuntimeError(f"GitHub Strict Mode: DetailedDataSpec í•„ìˆ˜ í•­ëª© ëˆ„ë½ - {missing_data_spec}")

    def _create_github_emergency_dependencies(self, config: EnhancedGitHubStepConfig, error_msg: str) -> Dict[str, Any]:
        """GitHub ì‘ê¸‰ ëª¨ë“œ ìµœì†Œ ì˜ì¡´ì„± + DetailedDataSpec ê¸°ë³¸ê°’"""
        self.logger.warning(f"âš ï¸ {config.step_name} GitHub ì‘ê¸‰ ëª¨ë“œë¡œ ìµœì†Œ ì˜ì¡´ì„± ë°˜í™˜")
        return {
            'step_name': config.step_name,
            'step_id': config.step_id,
            'device': 'cpu',
            'conda_env': getattr(config, 'conda_env', CONDA_INFO['conda_env']),
            'github_compatibility_mode': True,
            'emergency_mode': True,
            'error_message': error_msg,
            # DetailedDataSpec ê¸°ë³¸ê°’
            'api_input_mapping': {},
            'api_output_mapping': {},
            'step_data_flow': {'accepts_from': [], 'provides_to': []},
            'preprocessing_required': False,
            'postprocessing_required': False,
            'detailed_data_spec_loaded': False
        }

    def _resolve_github_device(self, device: str) -> str:
        """GitHub í”„ë¡œì íŠ¸ í‘œì¤€ ë””ë°”ì´ìŠ¤ í•´ê²°"""
        if device != "auto":
            return device
        
        if IS_M3_MAX_DETECTED:
            return "mps"
        
        try:
            import torch
            if torch.cuda.is_available():
                return "cuda"
            elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
                return "mps"
        except ImportError:
            pass
        
        return "cpu"
    
    def _resolve_github_model_loader(self) -> Optional['ModelLoader']:
        """GitHub í”„ë¡œì íŠ¸ í‘œì¤€ ModelLoader í•´ê²°"""
        try:
            with self._lock:
                cache_key = "github_model_loader"
                if cache_key in self._resolved_cache:
                    return self._resolved_cache[cache_key]
                
                attempts = self._resolution_attempts.get(cache_key, 0)
                if attempts >= self._max_attempts:
                    self.logger.warning(f"GitHub ModelLoader í•´ê²° ì‹œë„ í•œê³„ ì´ˆê³¼: {attempts}")
                    return None
                
                self._resolution_attempts[cache_key] = attempts + 1
                
                try:
                    from app.ai_pipeline.utils.model_loader import get_global_model_loader
                    model_loader = get_global_model_loader()
                    
                    if model_loader:
                        # GitHub í”„ë¡œì íŠ¸ íŠ¹ë³„ ì„¤ì •
                        if CONDA_INFO['is_target_env'] and hasattr(model_loader, 'configure_github'):
                            github_config = {
                                'conda_optimized': True,
                                'conda_env': CONDA_INFO['conda_env'],
                                'm3_max_optimized': IS_M3_MAX_DETECTED,
                                'memory_gb': MEMORY_GB,
                                'github_mode': True,
                                'real_ai_pipeline': True,
                                'detailed_data_spec_support': True
                            }
                            model_loader.configure_github(github_config)
                        
                        self._resolved_cache[cache_key] = model_loader
                        self.logger.info("âœ… GitHub ModelLoader í•´ê²° ì™„ë£Œ")
                        return model_loader
                    
                except ImportError:
                    try:
                        from ..utils.model_loader import get_global_model_loader
                        model_loader = get_global_model_loader()
                        if model_loader:
                            self._resolved_cache[cache_key] = model_loader
                            self.logger.info("âœ… GitHub ModelLoader í•´ê²° ì™„ë£Œ (ìƒëŒ€ ê²½ë¡œ)")
                            return model_loader
                    except ImportError:
                        self.logger.debug("GitHub ModelLoader import ì‹¤íŒ¨")
                        return None
                    
        except Exception as e:
            self.logger.error(f"âŒ GitHub ModelLoader í•´ê²° ì‹¤íŒ¨: {e}")
            return None
    
    def _resolve_github_memory_manager(self) -> Optional['MemoryManager']:
        """GitHub í”„ë¡œì íŠ¸ í‘œì¤€ MemoryManager í•´ê²°"""
        try:
            with self._lock:
                cache_key = "github_memory_manager"
                if cache_key in self._resolved_cache:
                    return self._resolved_cache[cache_key]
                
                try:
                    from app.ai_pipeline.utils.memory_manager import get_global_memory_manager
                    memory_manager = get_global_memory_manager()
                    
                    if memory_manager:
                        # GitHub M3 Max íŠ¹ë³„ ì„¤ì •
                        if IS_M3_MAX_DETECTED and hasattr(memory_manager, 'configure_github_m3_max'):
                            memory_manager.configure_github_m3_max(memory_gb=MEMORY_GB)
                        
                        self._resolved_cache[cache_key] = memory_manager
                        self.logger.info("âœ… GitHub MemoryManager í•´ê²° ì™„ë£Œ")
                        return memory_manager
                        
                except ImportError:
                    try:
                        from ..utils.memory_manager import get_global_memory_manager
                        memory_manager = get_global_memory_manager()
                        if memory_manager:
                            self._resolved_cache[cache_key] = memory_manager
                            self.logger.info("âœ… GitHub MemoryManager í•´ê²° ì™„ë£Œ (ìƒëŒ€ ê²½ë¡œ)")
                            return memory_manager
                    except ImportError:
                        return None
                    
        except Exception as e:
            self.logger.debug(f"GitHub MemoryManager í•´ê²° ì‹¤íŒ¨: {e}")
            return None
    
    def _resolve_github_data_converter(self) -> Optional['DataConverter']:
        """GitHub í”„ë¡œì íŠ¸ í‘œì¤€ DataConverter í•´ê²°"""
        try:
            with self._lock:
                cache_key = "github_data_converter"
                if cache_key in self._resolved_cache:
                    return self._resolved_cache[cache_key]
                
                try:
                    from app.ai_pipeline.utils.data_converter import get_global_data_converter
                    data_converter = get_global_data_converter()
                    if data_converter:
                        self._resolved_cache[cache_key] = data_converter
                        self.logger.info("âœ… GitHub DataConverter í•´ê²° ì™„ë£Œ")
                        return data_converter
                        
                except ImportError:
                    try:
                        from ..utils.data_converter import get_global_data_converter
                        data_converter = get_global_data_converter()
                        if data_converter:
                            self._resolved_cache[cache_key] = data_converter
                            self.logger.info("âœ… GitHub DataConverter í•´ê²° ì™„ë£Œ (ìƒëŒ€ ê²½ë¡œ)")
                            return data_converter
                    except ImportError:
                        return None
                    
        except Exception as e:
            self.logger.debug(f"GitHub DataConverter í•´ê²° ì‹¤íŒ¨: {e}")
            return None
    
    def _resolve_github_di_container(self) -> Optional['DIContainer']:
        """GitHub í”„ë¡œì íŠ¸ í‘œì¤€ DI Container í•´ê²°"""
        try:
            with self._lock:
                cache_key = "github_di_container"
                if cache_key in self._resolved_cache:
                    return self._resolved_cache[cache_key]
                
                try:
                    from app.core.di_container import get_global_di_container
                    di_container = get_global_di_container()
                    if di_container:
                        self._resolved_cache[cache_key] = di_container
                        self.logger.info("âœ… GitHub DIContainer í•´ê²° ì™„ë£Œ")
                        return di_container
                        
                except ImportError:
                    try:
                        from ...core.di_container import get_global_di_container
                        di_container = get_global_di_container()
                        if di_container:
                            self._resolved_cache[cache_key] = di_container
                            self.logger.info("âœ… GitHub DIContainer í•´ê²° ì™„ë£Œ (ìƒëŒ€ ê²½ë¡œ)")
                            return di_container
                    except ImportError:
                        return None
                    
        except Exception as e:
            self.logger.debug(f"GitHub DIContainer í•´ê²° ì‹¤íŒ¨: {e}")
            return None
    
    def _resolve_github_unified_dependency_manager(self) -> Optional[Any]:
        """GitHub í”„ë¡œì íŠ¸ í‘œì¤€ UnifiedDependencyManager í•´ê²°"""
        try:
            with self._lock:
                cache_key = "github_unified_dependency_manager"
                if cache_key in self._resolved_cache:
                    return self._resolved_cache[cache_key]
                
                try:
                    try:
                        from app.ai_pipeline.steps.base_step_mixin import GitHubDependencyManager
                    except ImportError:
                        from ..steps.base_step_mixin import GitHubDependencyManager
                    
                    # ğŸ”¥ í‚¤ì›Œë“œ ì¶©ëŒ ì—†ì´ ìƒì„± (GitHub í‘œì¤€ + DetailedDataSpec ì§€ì›)
                    github_manager = GitHubDependencyManager(
                        step_name="GlobalStepFactory",
                        memory_gb=MEMORY_GB,
                        quality_level="balanced",
                        auto_inject_dependencies=True,
                        dependency_timeout=30.0,
                        dependency_retry_count=3,
                        is_m3_max_detected=IS_M3_MAX_DETECTED,  # ğŸ”¥ ë³€ê²½ëœ í‚¤ì›Œë“œ ì‚¬ìš©
                        mycloset_optimized=CONDA_INFO['is_target_env'],
                        memory_optimization=True,
                        conda_target_env=CONDA_INFO['is_target_env'],
                        ultra_optimization=IS_M3_MAX_DETECTED and CONDA_INFO['is_target_env'],
                        performance_mode="maximum" if IS_M3_MAX_DETECTED else "balanced",
                        memory_pool_enabled=IS_M3_MAX_DETECTED,
                        mps_available=IS_M3_MAX_DETECTED,
                        real_ai_mode=True,
                        basestepmixin_compatible=True,
                        modelloader_required=True,
                        disable_fallback=True,
                        conda_info=CONDA_INFO,
                        github_mode=True,
                        detailed_data_spec_support=True,  # ğŸ”¥ DetailedDataSpec ì§€ì›
                        step_model_requirements_integrated=STEP_MODEL_REQUIREMENTS is not None
                    )
                    
                    self._resolved_cache[cache_key] = github_manager
                    self.logger.info("âœ… GitHub UnifiedDependencyManager í•´ê²° ì™„ë£Œ")
                    return github_manager
                    
                except ImportError:
                    # í´ë°±: Mock ê°ì²´ ìƒì„± (GitHub í‘œì¤€ + DetailedDataSpec ì§€ì›)
                    class MockGitHubUnifiedDependencyManager:
                        def __init__(self, **kwargs):
                            for key, value in kwargs.items():
                                setattr(self, key, value)
                    
                    mock_manager = MockGitHubUnifiedDependencyManager(
                        step_name="GlobalStepFactory",
                        is_m3_max_detected=IS_M3_MAX_DETECTED,
                        memory_gb=MEMORY_GB,
                        conda_info=CONDA_INFO,
                        github_mode=True,
                        detailed_data_spec_support=True,
                        step_model_requirements_integrated=STEP_MODEL_REQUIREMENTS is not None
                    )
                    self._resolved_cache[cache_key] = mock_manager
                    self.logger.info("âœ… GitHub UnifiedDependencyManager í•´ê²° ì™„ë£Œ (Mock)")
                    return mock_manager
                    
        except Exception as e:
            self.logger.debug(f"GitHub UnifiedDependencyManager í•´ê²° ì‹¤íŒ¨: {e}")
            return None
    
    def clear_cache(self):
        """ìºì‹œ ì •ë¦¬"""
        with self._lock:
            self._resolved_cache.clear()
            self._resolution_attempts.clear()
            gc.collect()

# ==============================================
# ğŸ”¥ GitHub í˜¸í™˜ ë™ì  Step í´ë˜ìŠ¤ ë¡œë” (DetailedDataSpec ì§€ì›)
# ==============================================

class EnhancedGitHubStepClassLoader:
    """GitHub í”„ë¡œì íŠ¸ í˜¸í™˜ ë™ì  Step í´ë˜ìŠ¤ ë¡œë” + DetailedDataSpec ì§€ì›"""
    
    def __init__(self):
        self.logger = logging.getLogger(f"{__name__}.EnhancedGitHubStepClassLoader")
        self._loaded_classes: Dict[str, Type] = {}
        self._import_attempts: Dict[str, int] = {}
        self._lock = threading.RLock()
        self._max_attempts = 5
    
    def load_enhanced_github_step_class(self, config: EnhancedGitHubStepConfig) -> Optional[Type]:
        """GitHub í”„ë¡œì íŠ¸ í˜¸í™˜ Step í´ë˜ìŠ¤ ë¡œë”© + DetailedDataSpec ê²€ì¦"""
        try:
            with self._lock:
                cache_key = config.class_name
                if cache_key in self._loaded_classes:
                    return self._loaded_classes[cache_key]
                
                attempts = self._import_attempts.get(cache_key, 0)
                if attempts >= self._max_attempts:
                    self.logger.error(f"âŒ {config.class_name} GitHub import ì¬ì‹œë„ í•œê³„ ì´ˆê³¼")
                    return None
                
                self._import_attempts[cache_key] = attempts + 1
                
                self.logger.info(f"ğŸ”„ {config.class_name} GitHub ë™ì  ë¡œë”© ì‹œì‘ (ì‹œë„ {attempts + 1}/{self._max_attempts})...")
                
                step_class = self._dynamic_import_github_step_class(config)
                
                if step_class:
                    if self._validate_enhanced_github_step_compatibility(step_class, config):
                        self._loaded_classes[cache_key] = step_class
                        self.logger.info(f"âœ… {config.class_name} GitHub ë™ì  ë¡œë”© ì„±ê³µ (BaseStepMixin v19.0 + DetailedDataSpec í˜¸í™˜)")
                        return step_class
                    else:
                        self.logger.error(f"âŒ {config.class_name} GitHub BaseStepMixin v19.0 + DetailedDataSpec í˜¸í™˜ì„± ê²€ì¦ ì‹¤íŒ¨")
                        return None
                else:
                    self.logger.error(f"âŒ {config.class_name} GitHub ë™ì  import ì‹¤íŒ¨")
                    return None
                    
        except Exception as e:
            self.logger.error(f"âŒ {config.class_name} GitHub ë™ì  ë¡œë”© ì˜ˆì™¸: {e}")
            return None
    
    def _dynamic_import_github_step_class(self, config: EnhancedGitHubStepConfig) -> Optional[Type]:
        """GitHub í”„ë¡œì íŠ¸ í‘œì¤€ ë™ì  import ì‹¤í–‰"""
        import importlib
        
        base_module = config.module_path
        
        # GitHub í”„ë¡œì íŠ¸ í‘œì¤€ import ê²½ë¡œë“¤
        github_import_paths = [
            base_module,
            f"app.ai_pipeline.steps.{config.module_path.split('.')[-1]}",
            f"ai_pipeline.steps.{config.module_path.split('.')[-1]}",
            f"backend.{base_module}",
            f"..steps.{config.module_path.split('.')[-1]}",
            f"backend.app.ai_pipeline.steps.{config.module_path.split('.')[-1]}",
            f"app.ai_pipeline.steps.step_{config.step_id:02d}_{config.step_type.value}",
            f"steps.{config.class_name.lower()}"
        ]
        
        for import_path in github_import_paths:
            try:
                self.logger.debug(f"ğŸ” {config.class_name} GitHub import ì‹œë„: {import_path}")
                
                module = importlib.import_module(import_path)
                
                if hasattr(module, config.class_name):
                    step_class = getattr(module, config.class_name)
                    self.logger.info(f"âœ… {config.class_name} GitHub ë™ì  import ì„±ê³µ: {import_path}")
                    return step_class
                else:
                    self.logger.debug(f"âš ï¸ {import_path}ì— {config.class_name} í´ë˜ìŠ¤ ì—†ìŒ")
                    continue
                    
            except ImportError as e:
                self.logger.debug(f"âš ï¸ {import_path} GitHub import ì‹¤íŒ¨: {e}")
                continue
            except Exception as e:
                self.logger.warning(f"âš ï¸ {import_path} GitHub import ì˜ˆì™¸: {e}")
                continue
        
        self.logger.error(f"âŒ {config.class_name} ëª¨ë“  GitHub ê²½ë¡œì—ì„œ import ì‹¤íŒ¨")
        return None
    
    def _validate_enhanced_github_step_compatibility(self, step_class: Type, config: EnhancedGitHubStepConfig) -> bool:
        """GitHub BaseStepMixin v19.0 + DetailedDataSpec í˜¸í™˜ì„± ê²€ì¦"""
        try:
            if not step_class or step_class.__name__ != config.class_name:
                return False
            
            mro_names = [cls.__name__ for cls in step_class.__mro__]
            if 'BaseStepMixin' not in mro_names:
                self.logger.warning(f"âš ï¸ {config.class_name}ì´ BaseStepMixinì„ ìƒì†í•˜ì§€ ì•ŠìŒ")
            
            # GitHub í”„ë¡œì íŠ¸ í‘œì¤€ í•„ìˆ˜ ë©”ì„œë“œë“¤
            required_methods = ['process', 'initialize']
            missing_methods = []
            for method in required_methods:
                if not hasattr(step_class, method):
                    missing_methods.append(method)
            
            if missing_methods:
                self.logger.error(f"âŒ {config.class_name}ì— GitHub í•„ìˆ˜ ë©”ì„œë“œ ì—†ìŒ: {missing_methods}")
                return False
            
            # GitHub ìƒì„±ì í˜¸ì¶œ í…ŒìŠ¤íŠ¸ (BaseStepMixin v19.0 + DetailedDataSpec í‘œì¤€ kwargs)
            try:
                test_kwargs = {
                    'step_name': 'github_test',
                    'step_id': config.step_id,
                    'device': 'cpu',
                    'github_compatibility_mode': True,
                    'detailed_data_spec_loaded': True
                }
                test_instance = step_class(**test_kwargs)
                if test_instance:
                    self.logger.debug(f"âœ… {config.class_name} GitHub BaseStepMixin v19.0 + DetailedDataSpec ìƒì„±ì í…ŒìŠ¤íŠ¸ ì„±ê³µ")
                    if hasattr(test_instance, 'cleanup'):
                        try:
                            if asyncio.iscoroutinefunction(test_instance.cleanup):
                                pass
                            else:
                                test_instance.cleanup()
                        except:
                            pass
                    del test_instance
                    return True
            except Exception as e:
                self.logger.warning(f"âš ï¸ {config.class_name} GitHub ìƒì„±ì í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
                try:
                    test_instance = step_class()
                    if test_instance:
                        self.logger.debug(f"âœ… {config.class_name} GitHub ê¸°ë³¸ ìƒì„±ì í…ŒìŠ¤íŠ¸ ì„±ê³µ")
                        del test_instance
                        return True
                except Exception:
                    pass
                return True
            
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ {config.class_name} GitHub BaseStepMixin v19.0 + DetailedDataSpec í˜¸í™˜ì„± ê²€ì¦ ì‹¤íŒ¨: {e}")
            return False

# ==============================================
# ğŸ”¥ ë©”ì¸ StepFactory v11.0 (DetailedDataSpec ì™„ì „ í†µí•©)
# ==============================================

class StepFactory:
    """
    ğŸ”¥ StepFactory v11.0 - DetailedDataSpec ì™„ì „ í†µí•© (GitHub í”„ë¡œì íŠ¸ ì™„ì „ í˜¸í™˜)
    
    í•µì‹¬ ìˆ˜ì •ì‚¬í•­:
    âœ… step_model_requirements.pyì˜ DetailedDataSpec ì™„ì „ í™œìš©
    âœ… API ì…ì¶œë ¥ ë§¤í•‘ (api_input_mapping, api_output_mapping) ìë™ ì²˜ë¦¬
    âœ… Step ê°„ ë°ì´í„° íë¦„ (provides_to_next_step, accepts_from_previous_step) ê´€ë¦¬
    âœ… ì „ì²˜ë¦¬/í›„ì²˜ë¦¬ ìš”êµ¬ì‚¬í•­ ìë™ ì ìš©
    âœ… BaseStepMixin v19.0 í‘œì¤€ ì™„ì „ í˜¸í™˜
    âœ… ìƒì„±ì ì‹œì  ì˜ì¡´ì„± ì£¼ì… (constructor injection)
    âœ… keyword argument repeated: is_m3_max ì˜¤ë¥˜ ì™„ì „ í•´ê²°
    âœ… conda í™˜ê²½ ìš°ì„  ìµœì í™”
    âœ… register_step, unregister_step, is_step_registered, get_registered_steps ë©”ì„œë“œ ì™„ì „ êµ¬í˜„
    âœ… FastAPI ë¼ìš°í„° 100% í˜¸í™˜ì„± í™•ë³´
    """
    
    def __init__(self):
        self.logger = logging.getLogger("StepFactory.v11")
        
        # GitHub BaseStepMixin v19.0 + DetailedDataSpec í˜¸í™˜ ì»´í¬ë„ŒíŠ¸ë“¤
        self.class_loader = EnhancedGitHubStepClassLoader()
        self.dependency_resolver = EnhancedGitHubDependencyResolver()
        
        # GitHub ë“±ë¡ëœ Step í´ë˜ìŠ¤ë“¤ ê´€ë¦¬
        self._registered_steps: Dict[str, Type['BaseStepMixin']] = {}
        self._step_type_mapping: Dict[str, StepType] = {}
        
        # ìºì‹œ ê´€ë¦¬
        self._step_cache: Dict[str, weakref.ref] = {}
        self._lock = threading.RLock()
        
        # GitHub í†µê³„ + DetailedDataSpec í†µê³„
        self._stats = {
            'total_created': 0,
            'successful_creations': 0,
            'failed_creations': 0,
            'cache_hits': 0,
            'github_compatible_creations': 0,
            'dependency_injection_successes': 0,
            'detailed_data_spec_successes': 0,
            'api_mapping_successes': 0,
            'data_flow_successes': 0,
            'conda_optimized': CONDA_INFO['is_target_env'],
            'm3_max_optimized': IS_M3_MAX_DETECTED,
            'registered_steps': 0,
            'step_model_requirements_available': STEP_MODEL_REQUIREMENTS is not None
        }
        
        self.logger.info("ğŸ­ StepFactory v11.0 ì´ˆê¸°í™” ì™„ë£Œ (DetailedDataSpec ì™„ì „ í†µí•© + BaseStepMixin v19.0)")

    # ==============================================
    # ğŸ”¥ GitHub Step ë“±ë¡ ê´€ë¦¬ ë©”ì„œë“œë“¤
    # ==============================================
    
    def register_step(self, step_id: str, step_class: Type['BaseStepMixin']) -> bool:
        """GitHub Step í´ë˜ìŠ¤ë¥¼ íŒ©í† ë¦¬ì— ë“±ë¡"""
        try:
            with self._lock:
                self.logger.info(f"ğŸ“ {step_id} GitHub Step í´ë˜ìŠ¤ ë“±ë¡ ì‹œì‘...")
                
                if not step_id or not step_class:
                    self.logger.error(f"âŒ ì˜ëª»ëœ ì¸ì: step_id={step_id}, step_class={step_class}")
                    return False
                
                if not self._validate_github_step_class(step_class, step_id):
                    return False
                
                step_type = self._extract_step_type_from_id(step_id)
                
                self._registered_steps[step_id] = step_class
                if step_type:
                    self._step_type_mapping[step_id] = step_type
                
                class_name = step_class.__name__
                module_name = step_class.__module__
                
                self.logger.info(f"âœ… {step_id} GitHub Step í´ë˜ìŠ¤ ë“±ë¡ ì™„ë£Œ")
                self.logger.info(f"   - í´ë˜ìŠ¤: {class_name}")
                self.logger.info(f"   - ëª¨ë“ˆ: {module_name}")
                self.logger.info(f"   - StepType: {step_type.value if step_type else 'Unknown'}")
                
                self._stats['registered_steps'] = len(self._registered_steps)
                return True
                
        except Exception as e:
            self.logger.error(f"âŒ {step_id} GitHub Step ë“±ë¡ ì‹¤íŒ¨: {e}")
            return False
    
    def _validate_github_step_class(self, step_class: Type['BaseStepMixin'], step_id: str) -> bool:
        """GitHub Step í´ë˜ìŠ¤ ê¸°ë³¸ ê²€ì¦"""
        try:
            if not isinstance(step_class, type):
                self.logger.error(f"âŒ {step_id}: step_classê°€ í´ë˜ìŠ¤ íƒ€ì…ì´ ì•„ë‹™ë‹ˆë‹¤")
                return False
            
            required_methods = ['process']
            missing_methods = []
            
            for method_name in required_methods:
                if not hasattr(step_class, method_name):
                    missing_methods.append(method_name)
            
            if missing_methods:
                self.logger.error(f"âŒ {step_id}: GitHub í•„ìˆ˜ ë©”ì„œë“œ ì—†ìŒ - {missing_methods}")
                return False
            
            mro_names = [cls.__name__ for cls in step_class.__mro__]
            if 'BaseStepMixin' not in mro_names:
                self.logger.warning(f"âš ï¸ {step_id}: BaseStepMixinì„ ìƒì†í•˜ì§€ ì•ŠìŒ (ê³„ì† ì§„í–‰)")
            
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ {step_id} GitHub í´ë˜ìŠ¤ ê²€ì¦ ì‹¤íŒ¨: {e}")
            return False
    
    def _extract_step_type_from_id(self, step_id: str) -> Optional[StepType]:
        """Step IDì—ì„œ StepType ì¶”ì¶œ"""
        try:
            step_mapping = {
                'step_01': StepType.HUMAN_PARSING,
                'step_02': StepType.POSE_ESTIMATION,
                'step_03': StepType.CLOTH_SEGMENTATION,
                'step_04': StepType.GEOMETRIC_MATCHING,
                'step_05': StepType.CLOTH_WARPING,
                'step_06': StepType.VIRTUAL_FITTING,
                'step_07': StepType.POST_PROCESSING,
                'step_08': StepType.QUALITY_ASSESSMENT
            }
            
            return step_mapping.get(step_id.lower())
            
        except Exception as e:
            self.logger.debug(f"StepType ì¶”ì¶œ ì‹¤íŒ¨ ({step_id}): {e}")
            return None
    
    def unregister_step(self, step_id: str) -> bool:
        """GitHub Step ë“±ë¡ í•´ì œ"""
        try:
            with self._lock:
                if step_id in self._registered_steps:
                    del self._registered_steps[step_id]
                    self._step_type_mapping.pop(step_id, None)
                    
                    cache_keys_to_remove = [
                        key for key in self._step_cache.keys() 
                        if step_id in key
                    ]
                    for cache_key in cache_keys_to_remove:
                        del self._step_cache[cache_key]
                    
                    self.logger.info(f"âœ… {step_id} GitHub Step ë“±ë¡ í•´ì œ ì™„ë£Œ")
                    self._stats['registered_steps'] = len(self._registered_steps)
                    return True
                else:
                    self.logger.warning(f"âš ï¸ {step_id} GitHub Stepì´ ë“±ë¡ë˜ì–´ ìˆì§€ ì•ŠìŒ")
                    return False
                    
        except Exception as e:
            self.logger.error(f"âŒ {step_id} GitHub Step ë“±ë¡ í•´ì œ ì‹¤íŒ¨: {e}")
            return False
    
    def is_step_registered(self, step_id: str) -> bool:
        """GitHub Step ë“±ë¡ ì—¬ë¶€ í™•ì¸"""
        with self._lock:
            return step_id in self._registered_steps
    
    def get_registered_steps(self) -> Dict[str, str]:
        """GitHub ë“±ë¡ëœ Step ëª©ë¡ ë°˜í™˜ (step_id -> class_name)"""
        with self._lock:
            return {
                step_id: step_class.__name__ 
                for step_id, step_class in self._registered_steps.items()
            }
    
    def get_registered_step_class(self, step_id: str) -> Optional[Type['BaseStepMixin']]:
        """GitHub ë“±ë¡ëœ Step í´ë˜ìŠ¤ ë°˜í™˜"""
        with self._lock:
            return self._registered_steps.get(step_id)

    # ==============================================
    # ğŸ”¥ GitHub Step ìƒì„± ë©”ì„œë“œë“¤ (DetailedDataSpec ì™„ì „ í†µí•©)
    # ==============================================

    def create_step(
        self,
        step_type: Union[StepType, str],
        use_cache: bool = True,
        **kwargs
    ) -> GitHubStepCreationResult:
        """GitHub Step ìƒì„± ë©”ì¸ ë©”ì„œë“œ + DetailedDataSpec ì™„ì „ í†µí•©"""
        start_time = time.time()
        
        try:
            # Step íƒ€ì… ì •ê·œí™”
            if isinstance(step_type, str):
                try:
                    step_type = StepType(step_type.lower())
                except ValueError:
                    if self.is_step_registered(step_type):
                        return self._create_step_from_registered(step_type, use_cache, **kwargs)
                    
                    return GitHubStepCreationResult(
                        success=False,
                        error_message=f"ì§€ì›í•˜ì§€ ì•ŠëŠ” GitHub Step íƒ€ì…: {step_type}",
                        creation_time=time.time() - start_time
                    )
            
            step_id = self._get_step_id_from_type(step_type)
            
            # GitHub ë“±ë¡ëœ Stepì´ ìˆìœ¼ë©´ ìš°ì„  ì‚¬ìš©
            if step_id and self.is_step_registered(step_id):
                self.logger.info(f"ğŸ¯ {step_type.value} GitHub ë“±ë¡ëœ Step í´ë˜ìŠ¤ ì‚¬ìš©")
                return self._create_step_from_registered(step_id, use_cache, **kwargs)
            
            # ë“±ë¡ëœ Stepì´ ì—†ìœ¼ë©´ ê¸°ì¡´ ë°©ì‹ ì‚¬ìš©
            self.logger.info(f"ğŸ¯ {step_type.value} GitHub ë™ì  ë¡œë”© ë°©ì‹ ì‚¬ìš©")
            return self._create_step_legacy_way(step_type, use_cache, **kwargs)
            
        except Exception as e:
            with self._lock:
                self._stats['failed_creations'] += 1
            
            self.logger.error(f"âŒ GitHub Step ìƒì„± ì‹¤íŒ¨: {e}")
            return GitHubStepCreationResult(
                success=False,
                error_message=f"GitHub Step ìƒì„± ì˜ˆì™¸: {str(e)}",
                creation_time=time.time() - start_time
            )
    
    def _get_step_id_from_type(self, step_type: StepType) -> Optional[str]:
        """StepTypeì—ì„œ step_id ì°¾ê¸°"""
        type_to_id_mapping = {
            StepType.HUMAN_PARSING: 'step_01',
            StepType.POSE_ESTIMATION: 'step_02',
            StepType.CLOTH_SEGMENTATION: 'step_03',
            StepType.GEOMETRIC_MATCHING: 'step_04',
            StepType.CLOTH_WARPING: 'step_05',
            StepType.VIRTUAL_FITTING: 'step_06',
            StepType.POST_PROCESSING: 'step_07',
            StepType.QUALITY_ASSESSMENT: 'step_08'
        }
        return type_to_id_mapping.get(step_type)
    
    def _create_step_from_registered(
        self, 
        step_id: str, 
        use_cache: bool = True, 
        **kwargs
    ) -> GitHubStepCreationResult:
        """GitHub ë“±ë¡ëœ Step í´ë˜ìŠ¤ë¡œë¶€í„° ì¸ìŠ¤í„´ìŠ¤ ìƒì„± + DetailedDataSpec í†µí•©"""
        start_time = time.time()
        
        try:
            step_class = self.get_registered_step_class(step_id)
            if not step_class:
                return GitHubStepCreationResult(
                    success=False,
                    error_message=f"GitHub ë“±ë¡ëœ {step_id} Step í´ë˜ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ",
                    creation_time=time.time() - start_time
                )
            
            self.logger.info(f"ğŸ”„ {step_id} GitHub ë“±ë¡ëœ í´ë˜ìŠ¤ë¡œ ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ì¤‘...")
            
            # ìºì‹œ í™•ì¸
            if use_cache:
                cached_step = self._get_cached_step(step_id)
                if cached_step:
                    with self._lock:
                        self._stats['cache_hits'] += 1
                    self.logger.info(f"â™»ï¸ {step_id} GitHub ìºì‹œì—ì„œ ë°˜í™˜")
                    return GitHubStepCreationResult(
                        success=True,
                        step_instance=cached_step,
                        step_name=step_class.__name__,
                        class_name=step_class.__name__,
                        module_path=step_class.__module__,
                        creation_time=time.time() - start_time,
                        github_compatible=True,
                        basestepmixin_v19_compatible=True,
                        detailed_data_spec_loaded=True
                    )
            
            # StepType ì¶”ì¶œ
            step_type = self._step_type_mapping.get(step_id)
            if not step_type:
                step_type = self._extract_step_type_from_id(step_id)
            
            # GitHub BaseStepMixin v19.0 + DetailedDataSpec í˜¸í™˜ ì„¤ì • ìƒì„±
            if step_type:
                config = EnhancedGitHubStepMapping.get_enhanced_github_config(step_type, **kwargs)
            else:
                # ê¸°ë³¸ ì„¤ì • ìƒì„±
                config = self._create_default_enhanced_github_config(step_id, step_class, **kwargs)
            
            # GitHub ì˜ì¡´ì„± í•´ê²° ë° ì¸ìŠ¤í„´ìŠ¤ ìƒì„± + DetailedDataSpec í†µí•©
            constructor_dependencies = self.dependency_resolver.resolve_enhanced_github_dependencies_for_constructor(config)
            
            # GitHub Step ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
            self.logger.info(f"ğŸ”„ {step_id} GitHub ë“±ë¡ëœ í´ë˜ìŠ¤ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±...")
            step_instance = step_class(**constructor_dependencies)
            self.logger.info(f"âœ… {step_id} GitHub ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ì™„ë£Œ (ë“±ë¡ëœ í´ë˜ìŠ¤ + DetailedDataSpec)")
            
            # GitHub ì´ˆê¸°í™” ì‹¤í–‰
            initialization_success = self._initialize_github_step(step_instance, config)
            
            # DetailedDataSpec í›„ì²˜ë¦¬ ì„¤ì •
            detailed_data_spec_result = self._apply_detailed_data_spec_post_processing(step_instance, config)
            
            # ìºì‹œì— ì €ì¥
            if use_cache:
                self._cache_step(step_id, step_instance)
            
            # í†µê³„ ì—…ë°ì´íŠ¸
            with self._lock:
                self._stats['total_created'] += 1
                self._stats['successful_creations'] += 1
                self._stats['github_compatible_creations'] += 1
                self._stats['dependency_injection_successes'] += 1
                if detailed_data_spec_result['success']:
                    self._stats['detailed_data_spec_successes'] += 1
                    self._stats['api_mapping_successes'] += 1
                    self._stats['data_flow_successes'] += 1
            
            return GitHubStepCreationResult(
                success=True,
                step_instance=step_instance,
                step_name=config.step_name,
                step_type=step_type,
                class_name=config.class_name,
                module_path=config.module_path,
                creation_time=time.time() - start_time,
                dependencies_injected={'constructor_injection': True},
                initialization_success=initialization_success,
                github_compatible=True,
                basestepmixin_v19_compatible=True,
                dependency_injection_success=True,
                detailed_data_spec_loaded=detailed_data_spec_result['success'],
                api_mappings_applied=detailed_data_spec_result.get('api_mappings', {}),
                data_flow_configured=detailed_data_spec_result.get('data_flow', {}),
                preprocessing_configured=detailed_data_spec_result.get('preprocessing_configured', False),
                postprocessing_configured=detailed_data_spec_result.get('postprocessing_configured', False)
            )
            
        except Exception as e:
            with self._lock:
                self._stats['failed_creations'] += 1
            
            self.logger.error(f"âŒ {step_id} GitHub ë“±ë¡ëœ í´ë˜ìŠ¤ ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ì‹¤íŒ¨: {e}")
            return GitHubStepCreationResult(
                success=False,
                error_message=f"GitHub ë“±ë¡ëœ {step_id} ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ì‹¤íŒ¨: {str(e)}",
                creation_time=time.time() - start_time
            )
    
    def _create_default_enhanced_github_config(self, step_id: str, step_class: Type, **kwargs) -> EnhancedGitHubStepConfig:
        """GitHub ê¸°ë³¸ ì„¤ì • ìƒì„± (StepTypeì´ ì—†ì„ ë•Œ) + DetailedDataSpec ì§€ì›"""
        return EnhancedGitHubStepConfig(
            step_name=step_class.__name__,
            step_id=int(step_id.split('_')[1]) if '_' in step_id else 0,
            step_type=StepType.HUMAN_PARSING,  # ê¸°ë³¸ê°’
            class_name=step_class.__name__,
            module_path=step_class.__module__,
            conda_env=CONDA_INFO['conda_env'],
            memory_gb=MEMORY_GB,
            **kwargs
        )
    
    def _create_step_legacy_way(
        self, 
        step_type: StepType, 
        use_cache: bool = True, 
        **kwargs
    ) -> GitHubStepCreationResult:
        """GitHub ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ Step ìƒì„± (ë™ì  ë¡œë”©) + DetailedDataSpec í†µí•©"""
        config = EnhancedGitHubStepMapping.get_enhanced_github_config(step_type, **kwargs)
        
        self.logger.info(f"ğŸ¯ {config.step_name} GitHub ìƒì„± ì‹œì‘ (ë™ì  ë¡œë”© + DetailedDataSpec)...")
        
        # í†µê³„ ì—…ë°ì´íŠ¸
        with self._lock:
            self._stats['total_created'] += 1
        
        # ìºì‹œ í™•ì¸
        if use_cache:
            cached_step = self._get_cached_step(config.step_name)
            if cached_step:
                with self._lock:
                    self._stats['cache_hits'] += 1
                self.logger.info(f"â™»ï¸ {config.step_name} GitHub ìºì‹œì—ì„œ ë°˜í™˜")
                return GitHubStepCreationResult(
                    success=True,
                    step_instance=cached_step,
                    step_name=config.step_name,
                    step_type=step_type,
                    class_name=config.class_name,
                    module_path=config.module_path,
                    creation_time=0.0,
                    github_compatible=True,
                    basestepmixin_v19_compatible=True,
                    detailed_data_spec_loaded=True
                )
        
        # ì‹¤ì œ GitHub Step ìƒì„± (ê¸°ì¡´ ë¡œì§ + DetailedDataSpec í†µí•©)
        result = self._create_enhanced_github_step_instance(config)
        
        # ì„±ê³µ ì‹œ ìºì‹œì— ì €ì¥
        if result.success and result.step_instance and use_cache:
            self._cache_step(config.step_name, result.step_instance)
        
        # í†µê³„ ì—…ë°ì´íŠ¸
        with self._lock:
            if result.success:
                self._stats['successful_creations'] += 1
                if result.github_compatible:
                    self._stats['github_compatible_creations'] += 1
                if result.dependency_injection_success:
                    self._stats['dependency_injection_successes'] += 1
                if result.detailed_data_spec_loaded:
                    self._stats['detailed_data_spec_successes'] += 1
                if result.api_mappings_applied:
                    self._stats['api_mapping_successes'] += 1
                if result.data_flow_configured:
                    self._stats['data_flow_successes'] += 1
            else:
                self._stats['failed_creations'] += 1
        
        return result

    def _create_enhanced_github_step_instance(self, config: EnhancedGitHubStepConfig) -> GitHubStepCreationResult:
        """GitHub BaseStepMixin v19.0 + DetailedDataSpec ì™„ì „ í†µí•© Step ì¸ìŠ¤í„´ìŠ¤ ìƒì„± (í•µì‹¬ ë©”ì„œë“œ)"""
        try:
            self.logger.info(f"ğŸ”„ {config.step_name} GitHub BaseStepMixin v19.0 + DetailedDataSpec ì™„ì „ í†µí•© ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ì¤‘...")
            
            # 1. GitHub Step í´ë˜ìŠ¤ ë¡œë”©
            StepClass = self.class_loader.load_enhanced_github_step_class(config)
            if not StepClass:
                return GitHubStepCreationResult(
                    success=False,
                    step_name=config.step_name,
                    step_type=config.step_type,
                    class_name=config.class_name,
                    module_path=config.module_path,
                    error_message=f"{config.class_name} GitHub í´ë˜ìŠ¤ ë¡œë”© ì‹¤íŒ¨"
                )
            
            self.logger.info(f"âœ… {config.class_name} GitHub í´ë˜ìŠ¤ ë¡œë”© ì™„ë£Œ")
            
            # 2. GitHub ìƒì„±ììš© ì˜ì¡´ì„± í•´ê²° + DetailedDataSpec í†µí•© (í•µì‹¬: ìƒì„±ì ì‹œì  ì£¼ì…)
            constructor_dependencies = self.dependency_resolver.resolve_enhanced_github_dependencies_for_constructor(config)
            
            # 3. GitHub BaseStepMixin v19.0 + DetailedDataSpec í‘œì¤€ ìƒì„±ì í˜¸ì¶œ (**kwargs íŒ¨í„´)
            self.logger.info(f"ğŸ”„ {config.class_name} GitHub BaseStepMixin v19.0 + DetailedDataSpec ìƒì„±ì í˜¸ì¶œ ì¤‘...")
            step_instance = StepClass(**constructor_dependencies)
            self.logger.info(f"âœ… {config.class_name} GitHub ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ì™„ë£Œ (ìƒì„±ì ì˜ì¡´ì„± + DetailedDataSpec ì£¼ì…)")
            
            # 4. GitHub ì´ˆê¸°í™” ì‹¤í–‰ (ë™ê¸°/ë¹„ë™ê¸° ìë™ ê°ì§€)
            initialization_success = self._initialize_github_step(step_instance, config)
            
            # 5. DetailedDataSpec í›„ì²˜ë¦¬ ì ìš©
            detailed_data_spec_result = self._apply_detailed_data_spec_post_processing(step_instance, config)
            
            # 6. GitHub BaseStepMixin v19.0 + DetailedDataSpec í˜¸í™˜ì„± ìµœì¢… ê²€ì¦
            compatibility_result = self._verify_enhanced_github_compatibility(step_instance, config)
            
            # 7. GitHub AI ëª¨ë¸ ë¡œë”© í™•ì¸
            ai_models_loaded = self._check_github_ai_models(step_instance, config)
            
            self.logger.info(f"âœ… {config.step_name} GitHub BaseStepMixin v19.0 + DetailedDataSpec ì™„ì „ í†µí•© ìƒì„± ì™„ë£Œ")
            
            return GitHubStepCreationResult(
                success=True,
                step_instance=step_instance,
                step_name=config.step_name,
                step_type=config.step_type,
                class_name=config.class_name,
                module_path=config.module_path,
                dependencies_injected={'constructor_injection': True},
                initialization_success=initialization_success,
                ai_models_loaded=ai_models_loaded,
                github_compatible=compatibility_result['compatible'],
                basestepmixin_v19_compatible=compatibility_result['basestepmixin_v19_compatible'],
                process_method_validated=compatibility_result['process_method_valid'],
                dependency_injection_success=True,
                detailed_data_spec_loaded=detailed_data_spec_result['success'],
                api_mappings_applied=detailed_data_spec_result.get('api_mappings', {}),
                data_flow_configured=detailed_data_spec_result.get('data_flow', {}),
                preprocessing_configured=detailed_data_spec_result.get('preprocessing_configured', False),
                postprocessing_configured=detailed_data_spec_result.get('postprocessing_configured', False)
            )
            
        except Exception as e:
            self.logger.error(f"âŒ {config.step_name} GitHub BaseStepMixin v19.0 + DetailedDataSpec ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ì‹¤íŒ¨: {e}")
            self.logger.error(f"âŒ ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
            
            return GitHubStepCreationResult(
                success=False,
                step_name=config.step_name,
                step_type=config.step_type,
                class_name=config.class_name,
                module_path=config.module_path,
                error_message=f"GitHub BaseStepMixin v19.0 + DetailedDataSpec ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ì‹¤íŒ¨: {str(e)}",
                github_compatible=False,
                basestepmixin_v19_compatible=False,
                detailed_data_spec_loaded=False
            )
    
    def _apply_detailed_data_spec_post_processing(self, step_instance: 'BaseStepMixin', config: EnhancedGitHubStepConfig) -> Dict[str, Any]:
        """ğŸ”¥ DetailedDataSpec í›„ì²˜ë¦¬ ì ìš© (í•µì‹¬ ë©”ì„œë“œ)"""
        try:
            self.logger.info(f"ğŸ”„ {config.step_name} DetailedDataSpec í›„ì²˜ë¦¬ ì ìš© ì¤‘...")
            
            result = {
                'success': False,
                'api_mappings': {},
                'data_flow': {},
                'preprocessing_configured': False,
                'postprocessing_configured': False,
                'errors': []
            }
            
            data_spec = config.detailed_data_spec
            
            # 1. API ë§¤í•‘ ì„¤ì • ì ìš©
            try:
                if hasattr(step_instance, 'configure_api_mappings'):
                    api_mapping_config = {
                        'input_mapping': data_spec.api_input_mapping,
                        'output_mapping': data_spec.api_output_mapping,
                        'fastapi_compatible': len(data_spec.api_input_mapping) > 0
                    }
                    step_instance.configure_api_mappings(api_mapping_config)
                    result['api_mappings'] = api_mapping_config
                    self.logger.info(f"âœ… {config.step_name} API ë§¤í•‘ ì„¤ì • ì™„ë£Œ")
                else:
                    # ìˆ˜ë™ìœ¼ë¡œ ì†ì„± ì„¤ì •
                    if hasattr(step_instance, '__dict__'):
                        step_instance.api_input_mapping = data_spec.api_input_mapping
                        step_instance.api_output_mapping = data_spec.api_output_mapping
                        step_instance.fastapi_compatible = len(data_spec.api_input_mapping) > 0
                        result['api_mappings'] = {
                            'input_mapping': data_spec.api_input_mapping,
                            'output_mapping': data_spec.api_output_mapping
                        }
                        self.logger.debug(f"âœ… {config.step_name} API ë§¤í•‘ ìˆ˜ë™ ì„¤ì • ì™„ë£Œ")
            except Exception as e:
                result['errors'].append(f"API ë§¤í•‘ ì„¤ì • ì‹¤íŒ¨: {e}")
                self.logger.warning(f"âš ï¸ {config.step_name} API ë§¤í•‘ ì„¤ì • ì‹¤íŒ¨: {e}")
            
            # 2. Step ê°„ ë°ì´í„° íë¦„ ì„¤ì •
            try:
                if hasattr(step_instance, 'configure_data_flow'):
                    data_flow_config = {
                        'accepts_from_previous_step': data_spec.accepts_from_previous_step,
                        'provides_to_next_step': data_spec.provides_to_next_step,
                        'step_input_schema': data_spec.step_input_schema,
                        'step_output_schema': data_spec.step_output_schema
                    }
                    step_instance.configure_data_flow(data_flow_config)
                    result['data_flow'] = data_flow_config
                    self.logger.info(f"âœ… {config.step_name} ë°ì´í„° íë¦„ ì„¤ì • ì™„ë£Œ")
                else:
                    # ìˆ˜ë™ìœ¼ë¡œ ì†ì„± ì„¤ì •
                    if hasattr(step_instance, '__dict__'):
                        step_instance.accepts_from_previous_step = data_spec.accepts_from_previous_step
                        step_instance.provides_to_next_step = data_spec.provides_to_next_step
                        step_instance.step_input_schema = data_spec.step_input_schema
                        step_instance.step_output_schema = data_spec.step_output_schema
                        result['data_flow'] = {
                            'accepts_from': list(data_spec.accepts_from_previous_step.keys()),
                            'provides_to': list(data_spec.provides_to_next_step.keys())
                        }
                        self.logger.debug(f"âœ… {config.step_name} ë°ì´í„° íë¦„ ìˆ˜ë™ ì„¤ì • ì™„ë£Œ")
            except Exception as e:
                result['errors'].append(f"ë°ì´í„° íë¦„ ì„¤ì • ì‹¤íŒ¨: {e}")
                self.logger.warning(f"âš ï¸ {config.step_name} ë°ì´í„° íë¦„ ì„¤ì • ì‹¤íŒ¨: {e}")
            
            # 3. ì „ì²˜ë¦¬ ì„¤ì • ì ìš©
            try:
                if data_spec.preprocessing_required and hasattr(step_instance, 'configure_preprocessing'):
                    preprocessing_config = {
                        'steps': data_spec.preprocessing_steps,
                        'normalization_mean': data_spec.normalization_mean,
                        'normalization_std': data_spec.normalization_std,
                        'input_value_ranges': data_spec.input_value_ranges,
                        'input_shapes': data_spec.input_shapes
                    }
                    step_instance.configure_preprocessing(preprocessing_config)
                    result['preprocessing_configured'] = True
                    self.logger.info(f"âœ… {config.step_name} ì „ì²˜ë¦¬ ì„¤ì • ì™„ë£Œ")
                elif data_spec.preprocessing_required:
                    # ìˆ˜ë™ìœ¼ë¡œ ì „ì²˜ë¦¬ ì†ì„± ì„¤ì •
                    if hasattr(step_instance, '__dict__'):
                        step_instance.preprocessing_steps = data_spec.preprocessing_steps
                        step_instance.normalization_mean = data_spec.normalization_mean
                        step_instance.normalization_std = data_spec.normalization_std
                        step_instance.preprocessing_required = True
                        result['preprocessing_configured'] = True
                        self.logger.debug(f"âœ… {config.step_name} ì „ì²˜ë¦¬ ìˆ˜ë™ ì„¤ì • ì™„ë£Œ")
            except Exception as e:
                result['errors'].append(f"ì „ì²˜ë¦¬ ì„¤ì • ì‹¤íŒ¨: {e}")
                self.logger.warning(f"âš ï¸ {config.step_name} ì „ì²˜ë¦¬ ì„¤ì • ì‹¤íŒ¨: {e}")
            
            # 4. í›„ì²˜ë¦¬ ì„¤ì • ì ìš©
            try:
                if data_spec.postprocessing_required and hasattr(step_instance, 'configure_postprocessing'):
                    postprocessing_config = {
                        'steps': data_spec.postprocessing_steps,
                        'output_value_ranges': data_spec.output_value_ranges,
                        'output_shapes': data_spec.output_shapes,
                        'output_data_types': data_spec.output_data_types
                    }
                    step_instance.configure_postprocessing(postprocessing_config)
                    result['postprocessing_configured'] = True
                    self.logger.info(f"âœ… {config.step_name} í›„ì²˜ë¦¬ ì„¤ì • ì™„ë£Œ")
                elif data_spec.postprocessing_required:
                    # ìˆ˜ë™ìœ¼ë¡œ í›„ì²˜ë¦¬ ì†ì„± ì„¤ì •
                    if hasattr(step_instance, '__dict__'):
                        step_instance.postprocessing_steps = data_spec.postprocessing_steps
                        step_instance.output_value_ranges = data_spec.output_value_ranges
                        step_instance.postprocessing_required = True
                        result['postprocessing_configured'] = True
                        self.logger.debug(f"âœ… {config.step_name} í›„ì²˜ë¦¬ ìˆ˜ë™ ì„¤ì • ì™„ë£Œ")
            except Exception as e:
                result['errors'].append(f"í›„ì²˜ë¦¬ ì„¤ì • ì‹¤íŒ¨: {e}")
                self.logger.warning(f"âš ï¸ {config.step_name} í›„ì²˜ë¦¬ ì„¤ì • ì‹¤íŒ¨: {e}")
            
            # 5. DetailedDataSpec ë©”íƒ€ì •ë³´ ì„¤ì •
            try:
                if hasattr(step_instance, '__dict__'):
                    step_instance.detailed_data_spec_loaded = True
                    step_instance.detailed_data_spec_version = 'v8.0'
                    step_instance.step_model_requirements_integrated = STEP_MODEL_REQUIREMENTS is not None
            except Exception as e:
                result['errors'].append(f"ë©”íƒ€ì •ë³´ ì„¤ì • ì‹¤íŒ¨: {e}")
            
            # ê²°ê³¼ íŒì •
            result['success'] = len(result['errors']) == 0 or (
                result['api_mappings'] and 
                (result['preprocessing_configured'] or not data_spec.preprocessing_required) and
                (result['postprocessing_configured'] or not data_spec.postprocessing_required)
            )
            
            if result['success']:
                self.logger.info(f"âœ… {config.step_name} DetailedDataSpec í›„ì²˜ë¦¬ ì ìš© ì™„ë£Œ")
            else:
                self.logger.warning(f"âš ï¸ {config.step_name} DetailedDataSpec í›„ì²˜ë¦¬ ë¶€ë¶„ ì‹¤íŒ¨: {result['errors']}")
            
            return result
            
        except Exception as e:
            self.logger.error(f"âŒ {config.step_name} DetailedDataSpec í›„ì²˜ë¦¬ ì ìš© ì‹¤íŒ¨: {e}")
            return {
                'success': False,
                'api_mappings': {},
                'data_flow': {},
                'preprocessing_configured': False,
                'postprocessing_configured': False,
                'errors': [str(e)]
            }
    
    def _initialize_github_step(self, step_instance: 'BaseStepMixin', config: EnhancedGitHubStepConfig) -> bool:
        """GitHub BaseStepMixin v19.0 Step ì´ˆê¸°í™” (ë™ê¸°/ë¹„ë™ê¸° ìë™ ê°ì§€)"""
        try:
            # GitHub BaseStepMixin v19.0 initialize ë©”ì„œë“œ í˜¸ì¶œ
            if hasattr(step_instance, 'initialize'):
                initialize_method = step_instance.initialize
                
                # ë™ê¸°/ë¹„ë™ê¸° ìë™ ê°ì§€ ë° ì²˜ë¦¬
                if asyncio.iscoroutinefunction(initialize_method):
                    # ë¹„ë™ê¸° í•¨ìˆ˜ì¸ ê²½ìš°
                    try:
                        # í˜„ì¬ ì‹¤í–‰ ì¤‘ì¸ ì´ë²¤íŠ¸ ë£¨í”„ê°€ ìˆëŠ”ì§€ í™•ì¸
                        loop = asyncio.get_running_loop()
                        
                        # ì´ë¯¸ ì‹¤í–‰ ì¤‘ì¸ ë£¨í”„ì—ì„œëŠ” íƒœìŠ¤í¬ ìƒì„± í›„ ë¸”ë¡œí‚¹ ëŒ€ê¸°
                        if loop.is_running():
                            # ìƒˆë¡œìš´ ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰í•˜ê±°ë‚˜ ë™ê¸°ì ìœ¼ë¡œ ì²˜ë¦¬
                            import concurrent.futures
                            with concurrent.futures.ThreadPoolExecutor() as executor:
                                future = executor.submit(asyncio.run, initialize_method())
                                success = future.result(timeout=30)  # 30ì´ˆ íƒ€ì„ì•„ì›ƒ
                        else:
                            # ë£¨í”„ê°€ ì‹¤í–‰ ì¤‘ì´ ì•„ë‹ˆë©´ ì§ì ‘ ì‹¤í–‰
                            success = asyncio.run(initialize_method())
                    except RuntimeError:
                        # ì‹¤í–‰ ì¤‘ì¸ ë£¨í”„ê°€ ì—†ìœ¼ë©´ ìƒˆ ë£¨í”„ì—ì„œ ì‹¤í–‰
                        success = asyncio.run(initialize_method())
                    except Exception as e:
                        self.logger.warning(f"âš ï¸ {config.step_name} GitHub ë¹„ë™ê¸° ì´ˆê¸°í™” ì‹¤íŒ¨, ë™ê¸° ë°©ì‹ ì‹œë„: {e}")
                        # ë¹„ë™ê¸° ì´ˆê¸°í™” ì‹¤íŒ¨ ì‹œ í´ë°± (ë™ê¸° ë°©ì‹ìœ¼ë¡œ ì¬ì‹œë„)
                        success = self._fallback_github_sync_initialize(step_instance, config)
                else:
                    # ë™ê¸° í•¨ìˆ˜ì¸ ê²½ìš°
                    success = initialize_method()
                
                if success:
                    self.logger.info(f"âœ… {config.step_name} GitHub BaseStepMixin v19.0 ì´ˆê¸°í™” ì™„ë£Œ")
                    return True
                else:
                    self.logger.warning(f"âš ï¸ {config.step_name} GitHub BaseStepMixin v19.0 ì´ˆê¸°í™” ì‹¤íŒ¨")
                    return False
            else:
                self.logger.debug(f"â„¹ï¸ {config.step_name} GitHub initialize ë©”ì„œë“œ ì—†ìŒ")
                return True
                
        except Exception as e:
            self.logger.warning(f"âš ï¸ {config.step_name} GitHub ì´ˆê¸°í™” ì˜ˆì™¸: {e}")
            # ì˜ˆì™¸ ë°œìƒ ì‹œ í´ë°± ì´ˆê¸°í™” ì‹œë„
            return self._fallback_github_sync_initialize(step_instance, config)
    
    def _fallback_github_sync_initialize(self, step_instance: 'BaseStepMixin', config: EnhancedGitHubStepConfig) -> bool:
        """GitHub í´ë°± ë™ê¸° ì´ˆê¸°í™” (ë¹„ë™ê¸° ì´ˆê¸°í™” ì‹¤íŒ¨ ì‹œ)"""
        try:
            self.logger.info(f"ğŸ”„ {config.step_name} GitHub í´ë°± ë™ê¸° ì´ˆê¸°í™” ì‹œë„...")
            
            # GitHub ê¸°ë³¸ ì†ì„±ë“¤ ìˆ˜ë™ ì„¤ì •
            if hasattr(step_instance, 'is_initialized'):
                step_instance.is_initialized = True
            
            if hasattr(step_instance, 'is_ready'):
                step_instance.is_ready = True
            
            if hasattr(step_instance, 'github_compatible'):
                step_instance.github_compatible = True
                
            # GitHub ì˜ì¡´ì„±ì´ ì œëŒ€ë¡œ ì£¼ì…ë˜ì—ˆëŠ”ì§€ í™•ì¸
            dependencies_ok = True
            if config.require_model_loader and not hasattr(step_instance, 'model_loader'):
                dependencies_ok = False
                
            if dependencies_ok:
                self.logger.info(f"âœ… {config.step_name} GitHub í´ë°± ë™ê¸° ì´ˆê¸°í™” ì„±ê³µ")
                return True
            else:
                self.logger.warning(f"âš ï¸ {config.step_name} GitHub í´ë°± ì´ˆê¸°í™”: ì˜ì¡´ì„± ë¬¸ì œ ìˆìŒ")
                return not config.strict_mode  # strict_modeê°€ ì•„ë‹ˆë©´ ê³„ì† ì§„í–‰
                
        except Exception as e:
            self.logger.error(f"âŒ {config.step_name} GitHub í´ë°± ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return False
    
    def _verify_enhanced_github_compatibility(self, step_instance: 'BaseStepMixin', config: EnhancedGitHubStepConfig) -> Dict[str, Any]:
        """GitHub BaseStepMixin v19.0 + DetailedDataSpec í˜¸í™˜ì„± ìµœì¢… ê²€ì¦"""
        try:
            result = {
                'compatible': True,
                'basestepmixin_v19_compatible': True,
                'process_method_valid': False,
                'detailed_data_spec_compatible': False,
                'issues': []
            }
            
            # GitHub process ë©”ì„œë“œ ì¡´ì¬ í™•ì¸
            if not hasattr(step_instance, 'process'):
                result['compatible'] = False
                result['basestepmixin_v19_compatible'] = False
                result['issues'].append('GitHub process ë©”ì„œë“œ ì—†ìŒ')
            else:
                result['process_method_valid'] = True
            
            # GitHub BaseStepMixin v19.0 ì†ì„± í™•ì¸
            expected_attrs = ['step_name', 'step_id', 'device', 'is_initialized', 'github_compatible']
            for attr in expected_attrs:
                if not hasattr(step_instance, attr):
                    result['issues'].append(f'GitHub {attr} ì†ì„± ì—†ìŒ')
            
            # DetailedDataSpec í˜¸í™˜ì„± í™•ì¸
            detailed_data_spec_attrs = ['api_input_mapping', 'api_output_mapping']
            detailed_data_spec_found = 0
            for attr in detailed_data_spec_attrs:
                if hasattr(step_instance, attr):
                    detailed_data_spec_found += 1
            
            result['detailed_data_spec_compatible'] = detailed_data_spec_found > 0
            if not result['detailed_data_spec_compatible']:
                result['issues'].append('DetailedDataSpec API ë§¤í•‘ ì†ì„± ì—†ìŒ')
            
            # GitHub ì˜ì¡´ì„± ì£¼ì… ìƒíƒœ í™•ì¸
            if hasattr(step_instance, 'model_loader') and step_instance.model_loader:
                self.logger.debug(f"âœ… {config.step_name} GitHub ModelLoader ì£¼ì… í™•ì¸ë¨")
            
            if hasattr(step_instance, 'dependency_manager') and step_instance.dependency_manager:
                self.logger.debug(f"âœ… {config.step_name} GitHub DependencyManager ì£¼ì… í™•ì¸ë¨")
            
            if result['issues']:
                self.logger.warning(f"âš ï¸ {config.step_name} GitHub BaseStepMixin v19.0 + DetailedDataSpec í˜¸í™˜ì„± ì´ìŠˆ: {result['issues']}")
            else:
                self.logger.info(f"âœ… {config.step_name} GitHub BaseStepMixin v19.0 + DetailedDataSpec í˜¸í™˜ì„± ê²€ì¦ ì™„ë£Œ")
            
            return result
            
        except Exception as e:
            self.logger.error(f"âŒ {config.step_name} GitHub BaseStepMixin v19.0 + DetailedDataSpec í˜¸í™˜ì„± ê²€ì¦ ì‹¤íŒ¨: {e}")
            return {
                'compatible': False, 
                'basestepmixin_v19_compatible': False, 
                'process_method_valid': False, 
                'detailed_data_spec_compatible': False,
                'issues': [str(e)]
            }
    
    def _check_github_ai_models(self, step_instance: 'BaseStepMixin', config: EnhancedGitHubStepConfig) -> List[str]:
        """GitHub AI ëª¨ë¸ ë¡œë”© í™•ì¸ (BaseStepMixin v19.0 í˜¸í™˜)"""
        loaded_models = []
        
        try:
            # GitHub ModelLoader ë¥¼ í†µí•œ ëª¨ë¸ í™•ì¸
            if hasattr(step_instance, 'model_loader') and step_instance.model_loader:
                for model_name in config.ai_models:
                    try:
                        if hasattr(step_instance.model_loader, 'is_model_loaded'):
                            if step_instance.model_loader.is_model_loaded(model_name):
                                loaded_models.append(model_name)
                    except Exception:
                        pass
            
            # GitHub model_interface ë¥¼ í†µí•œ ëª¨ë¸ í™•ì¸
            if hasattr(step_instance, 'model_interface') and step_instance.model_interface:
                for model_name in config.ai_models:
                    try:
                        if hasattr(step_instance.model_interface, 'is_model_available'):
                            if step_instance.model_interface.is_model_available(model_name):
                                loaded_models.append(model_name)
                    except Exception:
                        pass
            
            if loaded_models:
                self.logger.info(f"ğŸ¤– {config.step_name} GitHub AI ëª¨ë¸ ë¡œë”© í™•ì¸: {loaded_models}")
            
            return loaded_models
            
        except Exception as e:
            self.logger.debug(f"GitHub AI ëª¨ë¸ í™•ì¸ ì‹¤íŒ¨: {e}")
            return []
    
    def _get_cached_step(self, step_name: str) -> Optional['BaseStepMixin']:
        """ìºì‹œëœ GitHub Step ë°˜í™˜"""
        try:
            with self._lock:
                if step_name in self._step_cache:
                    weak_ref = self._step_cache[step_name]
                    step_instance = weak_ref()
                    if step_instance is not None:
                        return step_instance
                    else:
                        del self._step_cache[step_name]
                return None
        except Exception:
            return None
    
    def _cache_step(self, step_name: str, step_instance: 'BaseStepMixin'):
        """GitHub Step ìºì‹œì— ì €ì¥"""
        try:
            with self._lock:
                self._step_cache[step_name] = weakref.ref(step_instance)
        except Exception:
            pass
    
    # ==============================================
    # ğŸ”¥ GitHub í¸ì˜ ë©”ì„œë“œë“¤ (DetailedDataSpec í†µí•©)
    # ==============================================
    
    def create_human_parsing_step(self, **kwargs) -> GitHubStepCreationResult:
        """GitHub Human Parsing Step ìƒì„± (DetailedDataSpec í†µí•©)"""
        return self.create_step(StepType.HUMAN_PARSING, **kwargs)
    
    def create_pose_estimation_step(self, **kwargs) -> GitHubStepCreationResult:
        """GitHub Pose Estimation Step ìƒì„± (DetailedDataSpec í†µí•©)"""
        return self.create_step(StepType.POSE_ESTIMATION, **kwargs)
    
    def create_cloth_segmentation_step(self, **kwargs) -> GitHubStepCreationResult:
        """GitHub Cloth Segmentation Step ìƒì„± (DetailedDataSpec í†µí•©)"""
        return self.create_step(StepType.CLOTH_SEGMENTATION, **kwargs)
    
    def create_geometric_matching_step(self, **kwargs) -> GitHubStepCreationResult:
        """GitHub Geometric Matching Step ìƒì„± (DetailedDataSpec í†µí•©)"""
        return self.create_step(StepType.GEOMETRIC_MATCHING, **kwargs)
    
    def create_cloth_warping_step(self, **kwargs) -> GitHubStepCreationResult:
        """GitHub Cloth Warping Step ìƒì„± (DetailedDataSpec í†µí•©)"""
        return self.create_step(StepType.CLOTH_WARPING, **kwargs)
    
    def create_virtual_fitting_step(self, **kwargs) -> GitHubStepCreationResult:
        """GitHub Virtual Fitting Step ìƒì„± (DetailedDataSpec í†µí•©)"""
        return self.create_step(StepType.VIRTUAL_FITTING, **kwargs)
    
    def create_post_processing_step(self, **kwargs) -> GitHubStepCreationResult:
        """GitHub Post Processing Step ìƒì„± (DetailedDataSpec í†µí•©)"""
        return self.create_step(StepType.POST_PROCESSING, **kwargs)
    
    def create_quality_assessment_step(self, **kwargs) -> GitHubStepCreationResult:
        """GitHub Quality Assessment Step ìƒì„± (DetailedDataSpec í†µí•©)"""
        return self.create_step(StepType.QUALITY_ASSESSMENT, **kwargs)
    
    def create_full_pipeline(self, device: str = "auto", **kwargs) -> Dict[str, GitHubStepCreationResult]:
        """GitHub ì „ì²´ íŒŒì´í”„ë¼ì¸ ìƒì„± (DetailedDataSpec í†µí•©) - ë™ê¸° ë©”ì„œë“œ"""
        try:
            self.logger.info("ğŸš€ GitHub ì „ì²´ AI íŒŒì´í”„ë¼ì¸ ìƒì„± ì‹œì‘ (DetailedDataSpec ì™„ì „ í†µí•©)...")
            
            pipeline_results = {}
            total_model_size = 0.0
            
            # ìš°ì„ ìˆœìœ„ë³„ë¡œ GitHub Step ìƒì„±
            sorted_steps = sorted(
                StepType,
                key=lambda x: EnhancedGitHubStepMapping.GITHUB_STEP_CONFIGS[x].priority.value
            )
            
            for step_type in sorted_steps:
                try:
                    result = self.create_step(step_type, device=device, **kwargs)
                    pipeline_results[step_type.value] = result
                    
                    if result.success:
                        config = EnhancedGitHubStepMapping.get_enhanced_github_config(step_type)
                        total_model_size += config.model_size_gb
                        self.logger.info(f"âœ… {result.step_name} GitHub íŒŒì´í”„ë¼ì¸ ìƒì„± ì„±ê³µ (DetailedDataSpec í†µí•©)")
                        
                        # DetailedDataSpec í†µí•© ê²°ê³¼ ë¡œê¹…
                        if result.detailed_data_spec_loaded:
                            api_mappings_count = len(result.api_mappings_applied.get('input_mapping', {}))
                            data_flow_count = len(result.data_flow_configured.get('accepts_from', []))
                            self.logger.info(f"   - API ë§¤í•‘: {api_mappings_count}ê°œ")
                            self.logger.info(f"   - ë°ì´í„° íë¦„: {data_flow_count}ê°œ")
                            self.logger.info(f"   - ì „ì²˜ë¦¬: {'âœ…' if result.preprocessing_configured else 'âŒ'}")
                            self.logger.info(f"   - í›„ì²˜ë¦¬: {'âœ…' if result.postprocessing_configured else 'âŒ'}")
                    else:
                        self.logger.warning(f"âš ï¸ {step_type.value} GitHub íŒŒì´í”„ë¼ì¸ ìƒì„± ì‹¤íŒ¨")
                        
                except Exception as e:
                    self.logger.error(f"âŒ {step_type.value} GitHub Step ìƒì„± ì˜ˆì™¸: {e}")
                    pipeline_results[step_type.value] = GitHubStepCreationResult(
                        success=False,
                        step_name=f"{step_type.value}Step",
                        step_type=step_type,
                        error_message=str(e)
                    )
            
            success_count = sum(1 for result in pipeline_results.values() if result.success)
            total_count = len(pipeline_results)
            detailed_data_spec_count = sum(1 for result in pipeline_results.values() if result.detailed_data_spec_loaded)
            
            self.logger.info(f"ğŸ GitHub DetailedDataSpec í†µí•© íŒŒì´í”„ë¼ì¸ ìƒì„± ì™„ë£Œ: {success_count}/{total_count} ì„±ê³µ")
            self.logger.info(f"ğŸ¯ DetailedDataSpec í†µí•©: {detailed_data_spec_count}/{success_count} ì„±ê³µ")
            self.logger.info(f"ğŸ¤– ì´ AI ëª¨ë¸ í¬ê¸°: {total_model_size:.1f}GB")
            
            return pipeline_results
            
        except Exception as e:
            self.logger.error(f"âŒ GitHub ì „ì²´ íŒŒì´í”„ë¼ì¸ ìƒì„± ì‹¤íŒ¨: {e}")
            return {}
    
    def get_statistics(self) -> Dict[str, Any]:
        """GitHub í†µê³„ ì •ë³´ ë°˜í™˜ (DetailedDataSpec í†µí•© ì •ë³´ í¬í•¨)"""
        with self._lock:
            total = self._stats['total_created']
            success_rate = (self._stats['successful_creations'] / max(1, total)) * 100
            github_compatibility_rate = (self._stats['github_compatible_creations'] / max(1, self._stats['successful_creations'])) * 100
            detailed_data_spec_rate = (self._stats['detailed_data_spec_successes'] / max(1, self._stats['successful_creations'])) * 100
            
            base_stats = {
                'version': 'StepFactory v11.0 (DetailedDataSpec Complete Integration + BaseStepMixin v19.0)',
                'total_created': total,
                'successful_creations': self._stats['successful_creations'],
                'failed_creations': self._stats['failed_creations'],
                'success_rate': round(success_rate, 2),
                'cache_hits': self._stats['cache_hits'],
                'cached_steps': len(self._step_cache),
                'active_cache_entries': len([
                    ref for ref in self._step_cache.values() if ref() is not None
                ]),
                'github_compatibility': {
                    'github_compatible_creations': self._stats['github_compatible_creations'],
                    'github_compatibility_rate': round(github_compatibility_rate, 2),
                    'dependency_injection_successes': self._stats['dependency_injection_successes']
                },
                'detailed_data_spec_integration': {
                    'detailed_data_spec_successes': self._stats['detailed_data_spec_successes'],
                    'detailed_data_spec_rate': round(detailed_data_spec_rate, 2),
                    'api_mapping_successes': self._stats['api_mapping_successes'],
                    'data_flow_successes': self._stats['data_flow_successes'],
                    'step_model_requirements_available': self._stats['step_model_requirements_available']
                },
                'environment': {
                    'conda_env': CONDA_INFO['conda_env'],
                    'conda_optimized': self._stats['conda_optimized'],
                    'is_m3_max_detected': IS_M3_MAX_DETECTED,
                    'm3_max_optimized': self._stats['m3_max_optimized'],
                    'memory_gb': MEMORY_GB
                },
                'loaded_classes': list(self.class_loader._loaded_classes.keys()),
                
                # GitHub ë“±ë¡ ì •ë³´
                'registration': {
                    'registered_steps_count': len(self._registered_steps),
                    'registered_steps': self.get_registered_steps(),
                    'step_type_mappings': {
                        step_id: step_type.value 
                        for step_id, step_type in self._step_type_mapping.items()
                    }
                }
            }
            
            return base_stats
    
    def clear_cache(self):
        """GitHub ìºì‹œ ì •ë¦¬"""
        try:
            with self._lock:
                self._step_cache.clear()
                self.dependency_resolver.clear_cache()
                
                # GitHub M3 Max ë©”ëª¨ë¦¬ ì •ë¦¬
                if IS_M3_MAX_DETECTED:
                    try:
                        import torch
                        if hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
                            if hasattr(torch.backends.mps, 'empty_cache'):
                                torch.backends.mps.empty_cache()
                    except:
                        pass
                
                gc.collect()
                self.logger.info("ğŸ§¹ StepFactory v11.0 GitHub + DetailedDataSpec ìºì‹œ ì •ë¦¬ ì™„ë£Œ")
        except Exception as e:
            self.logger.error(f"âŒ GitHub ìºì‹œ ì •ë¦¬ ì‹¤íŒ¨: {e}")
    
    # ==============================================
    # ğŸ”¥ DetailedDataSpec ì „ìš© ë©”ì„œë“œë“¤ 
    # ==============================================
    
    def get_step_api_mappings(self, step_type: Union[StepType, str]) -> Dict[str, Any]:
        """Stepë³„ API ë§¤í•‘ ì •ë³´ ì¡°íšŒ (step_model_requirements.py í™œìš©)"""
        try:
            if isinstance(step_type, str):
                step_type = StepType(step_type.lower())
            
            config = EnhancedGitHubStepMapping.get_enhanced_github_config(step_type)
            
            return {
                'step_name': config.step_name,
                'api_input_mapping': config.detailed_data_spec.api_input_mapping,
                'api_output_mapping': config.detailed_data_spec.api_output_mapping,
                'fastapi_compatible': len(config.detailed_data_spec.api_input_mapping) > 0,
                'supports_file_upload': any("UploadFile" in str(v) for v in config.detailed_data_spec.api_input_mapping.values()),
                'input_fields_count': len(config.detailed_data_spec.api_input_mapping),
                'output_fields_count': len(config.detailed_data_spec.api_output_mapping)
            }
        except Exception as e:
            self.logger.error(f"âŒ Step API ë§¤í•‘ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {}
    
    def get_step_data_flow(self, step_type: Union[StepType, str]) -> Dict[str, Any]:
        """Stepë³„ ë°ì´í„° íë¦„ ì •ë³´ ì¡°íšŒ (step_model_requirements.py í™œìš©)"""
        try:
            if isinstance(step_type, str):
                step_type = StepType(step_type.lower())
            
            config = EnhancedGitHubStepMapping.get_enhanced_github_config(step_type)
            data_spec = config.detailed_data_spec
            
            return {
                'step_name': config.step_name,
                'accepts_from_previous_step': data_spec.accepts_from_previous_step,
                'provides_to_next_step': data_spec.provides_to_next_step,
                'step_input_schema': data_spec.step_input_schema,
                'step_output_schema': data_spec.step_output_schema,
                'is_pipeline_start': len(data_spec.accepts_from_previous_step) == 0,
                'is_pipeline_end': len(data_spec.provides_to_next_step) == 0,
                'input_connections': list(data_spec.accepts_from_previous_step.keys()),
                'output_connections': list(data_spec.provides_to_next_step.keys())
            }
        except Exception as e:
            self.logger.error(f"âŒ Step ë°ì´í„° íë¦„ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {}
    
    def get_step_preprocessing_config(self, step_type: Union[StepType, str]) -> Dict[str, Any]:
        """Stepë³„ ì „ì²˜ë¦¬ ì„¤ì • ì¡°íšŒ (step_model_requirements.py í™œìš©)"""
        try:
            if isinstance(step_type, str):
                step_type = StepType(step_type.lower())
            
            config = EnhancedGitHubStepMapping.get_enhanced_github_config(step_type)
            data_spec = config.detailed_data_spec
            
            return {
                'step_name': config.step_name,
                'preprocessing_required': data_spec.preprocessing_required,
                'preprocessing_steps': data_spec.preprocessing_steps,
                'normalization_mean': data_spec.normalization_mean,
                'normalization_std': data_spec.normalization_std,
                'input_data_types': data_spec.input_data_types,
                'input_shapes': data_spec.input_shapes,
                'input_value_ranges': data_spec.input_value_ranges
            }
        except Exception as e:
            self.logger.error(f"âŒ Step ì „ì²˜ë¦¬ ì„¤ì • ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {}
    
    def get_step_postprocessing_config(self, step_type: Union[StepType, str]) -> Dict[str, Any]:
        """Stepë³„ í›„ì²˜ë¦¬ ì„¤ì • ì¡°íšŒ (step_model_requirements.py í™œìš©)"""
        try:
            if isinstance(step_type, str):
                step_type = StepType(step_type.lower())
            
            config = EnhancedGitHubStepMapping.get_enhanced_github_config(step_type)
            data_spec = config.detailed_data_spec
            
            return {
                'step_name': config.step_name,
                'postprocessing_required': data_spec.postprocessing_required,
                'postprocessing_steps': data_spec.postprocessing_steps,
                'output_data_types': data_spec.output_data_types,
                'output_shapes': data_spec.output_shapes,
                'output_value_ranges': data_spec.output_value_ranges
            }
        except Exception as e:
            self.logger.error(f"âŒ Step í›„ì²˜ë¦¬ ì„¤ì • ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {}
    
    def validate_step_data_compatibility(self, from_step: Union[StepType, str], to_step: Union[StepType, str]) -> Dict[str, Any]:
        """Step ê°„ ë°ì´í„° í˜¸í™˜ì„± ê²€ì¦"""
        try:
            if isinstance(from_step, str):
                from_step = StepType(from_step.lower())
            if isinstance(to_step, str):
                to_step = StepType(to_step.lower())
            
            from_config = EnhancedGitHubStepMapping.get_enhanced_github_config(from_step)
            to_config = EnhancedGitHubStepMapping.get_enhanced_github_config(to_step)
            
            from_outputs = from_config.detailed_data_spec.provides_to_next_step.get(to_config.step_name, {})
            to_inputs = to_config.detailed_data_spec.accepts_from_previous_step.get(from_config.step_name, {})
            
            common_keys = set(from_outputs.keys()) & set(to_inputs.keys())
            missing_keys = set(to_inputs.keys()) - set(from_outputs.keys())
            extra_keys = set(from_outputs.keys()) - set(to_inputs.keys())
            
            compatibility_score = len(common_keys) / max(1, len(to_inputs)) if to_inputs else 1.0
            
            return {
                'from_step': from_config.step_name,
                'to_step': to_config.step_name,
                'compatible': len(missing_keys) == 0,
                'compatibility_score': round(compatibility_score, 2),
                'common_data_keys': list(common_keys),
                'missing_data_keys': list(missing_keys),
                'extra_data_keys': list(extra_keys),
                'from_step_outputs': from_outputs,
                'to_step_inputs': to_inputs,
                'requires_data_transformation': len(missing_keys) > 0 or len(extra_keys) > 0
            }
        except Exception as e:
            self.logger.error(f"âŒ Step ë°ì´í„° í˜¸í™˜ì„± ê²€ì¦ ì‹¤íŒ¨: {e}")
            return {'compatible': False, 'error': str(e)}
    
    def get_pipeline_data_flow_analysis(self) -> Dict[str, Any]:
        """ì „ì²´ íŒŒì´í”„ë¼ì¸ ë°ì´í„° íë¦„ ë¶„ì„"""
        try:
            pipeline_order = [
                StepType.HUMAN_PARSING,
                StepType.POSE_ESTIMATION,
                StepType.CLOTH_SEGMENTATION,
                StepType.GEOMETRIC_MATCHING,
                StepType.CLOTH_WARPING,
                StepType.VIRTUAL_FITTING,
                StepType.POST_PROCESSING,
                StepType.QUALITY_ASSESSMENT
            ]
            
            flow_analysis = {
                'pipeline_sequence': [step.value for step in pipeline_order],
                'step_connections': {},
                'data_transformations': {},
                'compatibility_matrix': {},
                'bottlenecks': [],
                'optimization_opportunities': []
            }
            
            # Step ê°„ ì—°ê²° ë¶„ì„
            for i, current_step in enumerate(pipeline_order):
                if i < len(pipeline_order) - 1:
                    next_step = pipeline_order[i + 1]
                    compatibility = self.validate_step_data_compatibility(current_step, next_step)
                    
                    connection_key = f"{current_step.value} â†’ {next_step.value}"
                    flow_analysis['step_connections'][connection_key] = compatibility
                    
                    if not compatibility['compatible']:
                        flow_analysis['bottlenecks'].append({
                            'connection': connection_key,
                            'issue': 'Data compatibility mismatch',
                            'missing_keys': compatibility['missing_data_keys']
                        })
                    
                    if compatibility['requires_data_transformation']:
                        flow_analysis['data_transformations'][connection_key] = {
                            'transformation_needed': True,
                            'missing_keys': compatibility['missing_data_keys'],
                            'extra_keys': compatibility['extra_data_keys']
                        }
            
            # í˜¸í™˜ì„± ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„±
            for step in pipeline_order:
                config = EnhancedGitHubStepMapping.get_enhanced_github_config(step)
                flow_analysis['compatibility_matrix'][step.value] = {
                    'input_data_types': config.detailed_data_spec.input_data_types,
                    'output_data_types': config.detailed_data_spec.output_data_types,
                    'preprocessing_required': config.detailed_data_spec.preprocessing_required,
                    'postprocessing_required': config.detailed_data_spec.postprocessing_required,
                    'api_compatible': len(config.detailed_data_spec.api_input_mapping) > 0
                }
            
            # ìµœì í™” ê¸°íšŒ ì‹ë³„
            flow_analysis['optimization_opportunities'] = [
                "API ë§¤í•‘ ìë™ ì ìš©ìœ¼ë¡œ FastAPI í˜¸í™˜ì„± 100% í™•ë³´",
                "Step ê°„ ë°ì´í„° ë³€í™˜ ìë™í™”ë¡œ íŒŒì´í”„ë¼ì¸ ì•ˆì •ì„± í–¥ìƒ",
                "ì „ì²˜ë¦¬/í›„ì²˜ë¦¬ ìš”êµ¬ì‚¬í•­ ìë™ ì ìš©ìœ¼ë¡œ ê°œë°œ íš¨ìœ¨ì„± ì¦ëŒ€",
                "DetailedDataSpec ê¸°ë°˜ ë°ì´í„° ê²€ì¦ìœ¼ë¡œ ëŸ°íƒ€ì„ ì˜¤ë¥˜ ë°©ì§€"
            ]
            
            return flow_analysis
            
        except Exception as e:
            self.logger.error(f"âŒ íŒŒì´í”„ë¼ì¸ ë°ì´í„° íë¦„ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {'error': str(e)}

# ==============================================
# ğŸ”¥ ì „ì—­ StepFactory ê´€ë¦¬ (DetailedDataSpec í†µí•©)
# ==============================================

_global_step_factory: Optional[StepFactory] = None
_factory_lock = threading.Lock()

def get_global_step_factory() -> StepFactory:
    """ì „ì—­ StepFactory v11.0 ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜ (DetailedDataSpec ì™„ì „ í†µí•©)"""
    global _global_step_factory
    
    with _factory_lock:
        if _global_step_factory is None:
            _global_step_factory = StepFactory()
            logger.info("âœ… ì „ì—­ StepFactory v11.0 (DetailedDataSpec ì™„ì „ í†µí•© + BaseStepMixin v19.0 í˜¸í™˜) ìƒì„± ì™„ë£Œ")
        
        return _global_step_factory

def reset_global_step_factory():
    """ì „ì—­ GitHub StepFactory ë¦¬ì…‹"""
    global _global_step_factory
    
    with _factory_lock:
        if _global_step_factory:
            _global_step_factory.clear_cache()
        _global_step_factory = None
        logger.info("ğŸ”„ ì „ì—­ StepFactory v11.0 DetailedDataSpec í†µí•© ë¦¬ì…‹ ì™„ë£Œ")

# ==============================================
# ğŸ”¥ í¸ì˜ í•¨ìˆ˜ë“¤ (DetailedDataSpec í†µí•©)
# ==============================================

def create_step(step_type: Union[StepType, str], **kwargs) -> GitHubStepCreationResult:
    """ì „ì—­ GitHub Step ìƒì„± í•¨ìˆ˜ (DetailedDataSpec í†µí•©)"""
    factory = get_global_step_factory()
    return factory.create_step(step_type, **kwargs)

def create_human_parsing_step(**kwargs) -> GitHubStepCreationResult:
    """GitHub Human Parsing Step ìƒì„± (DetailedDataSpec í†µí•©)"""
    return create_step(StepType.HUMAN_PARSING, **kwargs)

def create_pose_estimation_step(**kwargs) -> GitHubStepCreationResult:
    """GitHub Pose Estimation Step ìƒì„± (DetailedDataSpec í†µí•©)"""
    return create_step(StepType.POSE_ESTIMATION, **kwargs)

def create_cloth_segmentation_step(**kwargs) -> GitHubStepCreationResult:
    """GitHub Cloth Segmentation Step ìƒì„± (DetailedDataSpec í†µí•©)"""
    return create_step(StepType.CLOTH_SEGMENTATION, **kwargs)

def create_geometric_matching_step(**kwargs) -> GitHubStepCreationResult:
    """GitHub Geometric Matching Step ìƒì„± (DetailedDataSpec í†µí•©)"""
    return create_step(StepType.GEOMETRIC_MATCHING, **kwargs)

def create_cloth_warping_step(**kwargs) -> GitHubStepCreationResult:
    """GitHub Cloth Warping Step ìƒì„± (DetailedDataSpec í†µí•©)"""
    return create_step(StepType.CLOTH_WARPING, **kwargs)

def create_virtual_fitting_step(**kwargs) -> GitHubStepCreationResult:
    """GitHub Virtual Fitting Step ìƒì„± (DetailedDataSpec í†µí•©)"""
    return create_step(StepType.VIRTUAL_FITTING, **kwargs)

def create_post_processing_step(**kwargs) -> GitHubStepCreationResult:
    """GitHub Post Processing Step ìƒì„± (DetailedDataSpec í†µí•©)"""
    return create_step(StepType.POST_PROCESSING, **kwargs)

def create_quality_assessment_step(**kwargs) -> GitHubStepCreationResult:
    """GitHub Quality Assessment Step ìƒì„± (DetailedDataSpec í†µí•©)"""
    return create_step(StepType.QUALITY_ASSESSMENT, **kwargs)

def create_full_pipeline(device: str = "auto", **kwargs) -> Dict[str, GitHubStepCreationResult]:
    """GitHub ì „ì²´ íŒŒì´í”„ë¼ì¸ ìƒì„± (DetailedDataSpec í†µí•©) - ë™ê¸° í•¨ìˆ˜"""
    factory = get_global_step_factory()
    return factory.create_full_pipeline(device, **kwargs)

def get_step_factory_statistics() -> Dict[str, Any]:
    """GitHub StepFactory í†µê³„ ì¡°íšŒ (DetailedDataSpec í†µí•© ì •ë³´ í¬í•¨)"""
    factory = get_global_step_factory()
    return factory.get_statistics()

def clear_step_factory_cache():
    """GitHub StepFactory ìºì‹œ ì •ë¦¬"""
    factory = get_global_step_factory()
    factory.clear_cache()

# ==============================================
# ğŸ”¥ í¸ì˜ í•¨ìˆ˜ë“¤ ê°œì„  (GitHub ë“±ë¡ ê¸°ëŠ¥ + DetailedDataSpec)
# ==============================================

def register_step_globally(step_id: str, step_class: Type['BaseStepMixin']) -> bool:
    """ì „ì—­ GitHub StepFactoryì— Step ë“±ë¡"""
    factory = get_global_step_factory()
    return factory.register_step(step_id, step_class)

def unregister_step_globally(step_id: str) -> bool:
    """ì „ì—­ GitHub StepFactoryì—ì„œ Step ë“±ë¡ í•´ì œ"""
    factory = get_global_step_factory()
    return factory.unregister_step(step_id)

def get_registered_steps_globally() -> Dict[str, str]:
    """ì „ì—­ GitHub StepFactory ë“±ë¡ëœ Step ëª©ë¡ ì¡°íšŒ"""
    factory = get_global_step_factory()
    return factory.get_registered_steps()

def is_step_registered_globally(step_id: str) -> bool:
    """ì „ì—­ GitHub StepFactory Step ë“±ë¡ ì—¬ë¶€ í™•ì¸"""
    factory = get_global_step_factory()
    return factory.is_step_registered(step_id)

# ==============================================
# ğŸ”¥ DetailedDataSpec ì „ìš© í¸ì˜ í•¨ìˆ˜ë“¤
# ==============================================

def get_step_api_mappings(step_type: Union[StepType, str]) -> Dict[str, Any]:
    """Stepë³„ API ë§¤í•‘ ì •ë³´ ì¡°íšŒ"""
    factory = get_global_step_factory()
    return factory.get_step_api_mappings(step_type)

def get_step_data_flow(step_type: Union[StepType, str]) -> Dict[str, Any]:
    """Stepë³„ ë°ì´í„° íë¦„ ì •ë³´ ì¡°íšŒ"""
    factory = get_global_step_factory()
    return factory.get_step_data_flow(step_type)

def get_step_preprocessing_config(step_type: Union[StepType, str]) -> Dict[str, Any]:
    """Stepë³„ ì „ì²˜ë¦¬ ì„¤ì • ì¡°íšŒ"""
    factory = get_global_step_factory()
    return factory.get_step_preprocessing_config(step_type)

def get_step_postprocessing_config(step_type: Union[StepType, str]) -> Dict[str, Any]:
    """Stepë³„ í›„ì²˜ë¦¬ ì„¤ì • ì¡°íšŒ"""
    factory = get_global_step_factory()
    return factory.get_step_postprocessing_config(step_type)

def validate_step_data_compatibility(from_step: Union[StepType, str], to_step: Union[StepType, str]) -> Dict[str, Any]:
    """Step ê°„ ë°ì´í„° í˜¸í™˜ì„± ê²€ì¦"""
    factory = get_global_step_factory()
    return factory.validate_step_data_compatibility(from_step, to_step)

def get_pipeline_data_flow_analysis() -> Dict[str, Any]:
    """ì „ì²´ íŒŒì´í”„ë¼ì¸ ë°ì´í„° íë¦„ ë¶„ì„"""
    factory = get_global_step_factory()
    return factory.get_pipeline_data_flow_analysis()

# ==============================================
# ğŸ”¥ GitHub conda í™˜ê²½ ìµœì í™” (DetailedDataSpec ì§€ì›)
# ==============================================

def optimize_conda_environment_for_github():
    """GitHub conda í™˜ê²½ ìµœì í™” (DetailedDataSpec ì§€ì›)"""
    try:
        if not CONDA_INFO['is_target_env']:
            logger.warning(f"âš ï¸ GitHub ê¶Œì¥ conda í™˜ê²½ì´ ì•„ë‹˜: {CONDA_INFO['conda_env']} (ê¶Œì¥: mycloset-ai-clean)")
            return False
        
        # GitHub PyTorch conda ìµœì í™”
        try:
            import torch
            if IS_M3_MAX_DETECTED and hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
                # GitHub MPS ìºì‹œ ì •ë¦¬
                if hasattr(torch.backends.mps, 'empty_cache'):
                    torch.backends.mps.empty_cache()
                logger.info("ğŸ GitHub M3 Max MPS ìµœì í™” í™œì„±í™” (DetailedDataSpec ì§€ì›)")
            
            # GitHub CPU ìŠ¤ë ˆë“œ ìµœì í™”
            cpu_count = os.cpu_count()
            torch.set_num_threads(max(1, cpu_count // 2))
            logger.info(f"ğŸ§µ GitHub PyTorch ìŠ¤ë ˆë“œ ìµœì í™”: {torch.get_num_threads()}/{cpu_count}")
            
        except ImportError:
            pass
        
        # GitHub í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
        os.environ['OMP_NUM_THREADS'] = str(max(1, os.cpu_count() // 2))
        os.environ['MKL_NUM_THREADS'] = str(max(1, os.cpu_count() // 2))
        
        logger.info("ğŸ GitHub conda í™˜ê²½ ìµœì í™” ì™„ë£Œ (DetailedDataSpec ì§€ì›)")
        return True
        
    except Exception as e:
        logger.warning(f"âš ï¸ GitHub conda í™˜ê²½ ìµœì í™” ì‹¤íŒ¨: {e}")
        return False

# ==============================================
# ğŸ”¥ GitHub DetailedDataSpec í˜¸í™˜ì„± ê²€ì¦ ë„êµ¬
# ==============================================

def validate_github_step_compatibility(step_instance: 'BaseStepMixin') -> Dict[str, Any]:
    """GitHub BaseStepMixin v19.0 + DetailedDataSpec Step í˜¸í™˜ì„± ê²€ì¦"""
    try:
        result = {
            'compatible': True,
            'version': 'StepFactory v11.0 GitHub + DetailedDataSpec',
            'basestepmixin_v19_compatible': True,
            'detailed_data_spec_compatible': True,
            'issues': [],
            'recommendations': []
        }
        
        # GitHub í•„ìˆ˜ ì†ì„± í™•ì¸
        required_attrs = ['step_name', 'step_id', 'device', 'is_initialized', 'github_compatible']
        for attr in required_attrs:
            if not hasattr(step_instance, attr):
                result['compatible'] = False
                result['basestepmixin_v19_compatible'] = False
                result['issues'].append(f'GitHub í•„ìˆ˜ ì†ì„± {attr} ì—†ìŒ')
        
        # GitHub í•„ìˆ˜ ë©”ì„œë“œ í™•ì¸
        required_methods = ['process', 'initialize']
        for method in required_methods:
            if not hasattr(step_instance, method):
                result['compatible'] = False
                result['basestepmixin_v19_compatible'] = False
                result['issues'].append(f'GitHub í•„ìˆ˜ ë©”ì„œë“œ {method} ì—†ìŒ')
        
        # DetailedDataSpec ê´€ë ¨ ì†ì„± í™•ì¸
        detailed_data_spec_attrs = ['api_input_mapping', 'api_output_mapping']
        detailed_data_spec_found = 0
        for attr in detailed_data_spec_attrs:
            if hasattr(step_instance, attr):
                detailed_data_spec_found += 1
        
        if detailed_data_spec_found == 0:
            result['detailed_data_spec_compatible'] = False
            result['issues'].append('DetailedDataSpec API ë§¤í•‘ ì†ì„± ì—†ìŒ')
            result['recommendations'].append('DetailedDataSpec API ë§¤í•‘ ì„¤ì • í•„ìš”')
        
        # GitHub BaseStepMixin v19.0 ìƒì† í™•ì¸
        mro_names = [cls.__name__ for cls in step_instance.__class__.__mro__]
        if 'BaseStepMixin' not in mro_names:
            result['recommendations'].append('GitHub BaseStepMixin v19.0 ìƒì† ê¶Œì¥')
        
        # GitHub ì˜ì¡´ì„± ì£¼ì… ìƒíƒœ í™•ì¸
        dependency_attrs = ['model_loader', 'memory_manager', 'data_converter', 'dependency_manager']
        injected_deps = []
        for attr in dependency_attrs:
            if hasattr(step_instance, attr) and getattr(step_instance, attr) is not None:
                injected_deps.append(attr)
        
        result['injected_dependencies'] = injected_deps
        result['dependency_injection_score'] = len(injected_deps) / len(dependency_attrs)
        
        # GitHub íŠ¹ë³„ ì†ì„± í™•ì¸
        if hasattr(step_instance, 'github_compatible') and getattr(step_instance, 'github_compatible'):
            result['github_mode'] = True
        else:
            result['recommendations'].append('github_compatible=True ì„¤ì • ê¶Œì¥')
        
        # DetailedDataSpec ë¡œë”© ìƒíƒœ í™•ì¸
        if hasattr(step_instance, 'detailed_data_spec_loaded') and getattr(step_instance, 'detailed_data_spec_loaded'):
            result['detailed_data_spec_loaded'] = True
        else:
            result['recommendations'].append('DetailedDataSpec ë¡œë”© ìƒíƒœ í™•ì¸ í•„ìš”')
        
        return result
        
    except Exception as e:
        return {
            'compatible': False,
            'basestepmixin_v19_compatible': False,
            'detailed_data_spec_compatible': False,
            'error': str(e),
            'version': 'StepFactory v11.0 GitHub + DetailedDataSpec'
        }

def get_github_step_info(step_instance: 'BaseStepMixin') -> Dict[str, Any]:
    """GitHub BaseStepMixin v19.0 + DetailedDataSpec Step ì •ë³´ ì¡°íšŒ"""
    try:
        info = {
            'step_name': getattr(step_instance, 'step_name', 'Unknown'),
            'step_id': getattr(step_instance, 'step_id', 0),
            'class_name': step_instance.__class__.__name__,
            'module': step_instance.__class__.__module__,
            'device': getattr(step_instance, 'device', 'Unknown'),
            'is_initialized': getattr(step_instance, 'is_initialized', False),
            'github_compatible': getattr(step_instance, 'github_compatible', False),
            'has_model': getattr(step_instance, 'has_model', False),
            'model_loaded': getattr(step_instance, 'model_loaded', False)
        }
        
        # GitHub ì˜ì¡´ì„± ìƒíƒœ
        dependencies = {}
        for dep_name in ['model_loader', 'memory_manager', 'data_converter', 'di_container', 'dependency_manager']:
            dependencies[dep_name] = hasattr(step_instance, dep_name) and getattr(step_instance, dep_name) is not None
        
        info['dependencies'] = dependencies
        
        # DetailedDataSpec ìƒíƒœ
        detailed_data_spec_info = {}
        for attr_name in ['api_input_mapping', 'api_output_mapping', 'preprocessing_steps', 'postprocessing_steps']:
            detailed_data_spec_info[attr_name] = hasattr(step_instance, attr_name)
        
        info['detailed_data_spec'] = detailed_data_spec_info
        info['detailed_data_spec_loaded'] = getattr(step_instance, 'detailed_data_spec_loaded', False)
        
        # GitHub BaseStepMixin v19.0 íŠ¹ì • ì†ì„±ë“¤
        if hasattr(step_instance, 'dependency_manager'):
            dep_manager = step_instance.dependency_manager
            if hasattr(dep_manager, 'get_github_status'):
                try:
                    info['github_dependency_manager_status'] = dep_manager.get_github_status()
                except:
                    info['github_dependency_manager_status'] = 'error'
        
        return info
        
    except Exception as e:
        return {'error': str(e)}

# ==============================================
# ğŸ”¥ Export
# ==============================================

__all__ = [
    # ë©”ì¸ í´ë˜ìŠ¤ë“¤
    'StepFactory',
    'EnhancedGitHubStepClassLoader', 
    'EnhancedGitHubDependencyResolver',
    'EnhancedGitHubStepMapping',
    
    # ë°ì´í„° êµ¬ì¡°ë“¤
    'StepType',
    'StepPriority', 
    'EnhancedGitHubStepConfig',
    'DetailedDataSpecConfig',
    'GitHubStepCreationResult',
    
    # ì „ì—­ í•¨ìˆ˜ë“¤
    'get_global_step_factory',
    'reset_global_step_factory',
    
    # Step ìƒì„± í•¨ìˆ˜ë“¤ (DetailedDataSpec í†µí•©)
    'create_step',
    'create_human_parsing_step',
    'create_pose_estimation_step', 
    'create_cloth_segmentation_step',
    'create_geometric_matching_step',
    'create_cloth_warping_step',
    'create_virtual_fitting_step',
    'create_post_processing_step',
    'create_quality_assessment_step',
    'create_full_pipeline',
    
    # ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
    'get_step_factory_statistics',
    'clear_step_factory_cache',
    'optimize_conda_environment_for_github',
    
    # GitHub BaseStepMixin v19.0 + DetailedDataSpec í˜¸í™˜ì„± ë„êµ¬ë“¤
    'validate_github_step_compatibility',
    'get_github_step_info',
    
    # Step ë“±ë¡ ê´€ë¦¬ í•¨ìˆ˜ë“¤
    'register_step_globally',
    'unregister_step_globally', 
    'get_registered_steps_globally',
    'is_step_registered_globally',
    
    # DetailedDataSpec ì „ìš© í•¨ìˆ˜ë“¤
    'get_step_api_mappings',
    'get_step_data_flow',
    'get_step_preprocessing_config',
    'get_step_postprocessing_config',
    'validate_step_data_compatibility',
    'get_pipeline_data_flow_analysis',
    
    # ìƒìˆ˜ë“¤
    'CONDA_INFO',
    'IS_M3_MAX_DETECTED', 
    'MEMORY_GB',
    'STEP_MODEL_REQUIREMENTS'
]

# ==============================================
# ğŸ”¥ ëª¨ë“ˆ ì´ˆê¸°í™” (DetailedDataSpec ì™„ì „ í†µí•©)
# ==============================================

logger.info("ğŸ”¥ StepFactory v11.0 - DetailedDataSpec ì™„ì „ í†µí•© + BaseStepMixin v19.0 ì™„ì „ í˜¸í™˜ ë¡œë“œ ì™„ë£Œ!")
logger.info("âœ… ì£¼ìš” ì‹ ê¸°ëŠ¥:")
logger.info("   - step_model_requirements.pyì˜ DetailedDataSpec ì™„ì „ í™œìš©")
logger.info("   - API ì…ì¶œë ¥ ë§¤í•‘ (api_input_mapping, api_output_mapping) ìë™ ì²˜ë¦¬")
logger.info("   - Step ê°„ ë°ì´í„° íë¦„ (provides_to_next_step, accepts_from_previous_step) ìë™ ê´€ë¦¬")
logger.info("   - ì „ì²˜ë¦¬/í›„ì²˜ë¦¬ ìš”êµ¬ì‚¬í•­ ìë™ ì ìš©")
logger.info("   - FastAPI ë¼ìš°í„° 100% í˜¸í™˜ì„± í™•ë³´")
logger.info("   - BaseStepMixin v19.0 í‘œì¤€ ì™„ì „ í˜¸í™˜")
logger.info("   - keyword argument repeated: is_m3_max ì˜¤ë¥˜ ì™„ì „ í•´ê²°")

logger.info(f"ğŸ”§ í˜„ì¬ í™˜ê²½:")
logger.info(f"   - conda í™˜ê²½: {CONDA_INFO['conda_env']} ({'âœ… ìµœì í™”ë¨' if CONDA_INFO['is_target_env'] else 'âš ï¸ ê¶Œì¥: mycloset-ai-clean'})")
logger.info(f"   - M3 Max: {'âœ…' if IS_M3_MAX_DETECTED else 'âŒ'}")
logger.info(f"   - ë©”ëª¨ë¦¬: {MEMORY_GB:.1f}GB")
logger.info(f"   - step_model_requirements.py: {'âœ… ë¡œë”©ë¨' if STEP_MODEL_REQUIREMENTS else 'âŒ ë¡œë”© ì‹¤íŒ¨'}")

logger.info("ğŸ¯ ì§€ì› Step í´ë˜ìŠ¤ (DetailedDataSpec ì™„ì „ í†µí•©):")
for step_type in StepType:
    config = EnhancedGitHubStepMapping.GITHUB_STEP_CONFIGS[step_type]
    api_input_count = len(config.detailed_data_spec.api_input_mapping)
    api_output_count = len(config.detailed_data_spec.api_output_mapping)
    logger.info(f"   - {config.class_name} (Step {config.step_id:02d}) - {config.model_size_gb}GB")
    logger.info(f"     API: {api_input_count}ì…ë ¥â†’{api_output_count}ì¶œë ¥, ì „ì²˜ë¦¬: {'âœ…' if config.detailed_data_spec.preprocessing_required else 'âŒ'}")

# conda í™˜ê²½ ìë™ ìµœì í™” (DetailedDataSpec ì§€ì›)
if CONDA_INFO['is_target_env']:
    optimize_conda_environment_for_github()
    logger.info("ğŸ GitHub conda í™˜ê²½ ìë™ ìµœì í™” ì™„ë£Œ! (DetailedDataSpec ì§€ì›)")
else:
    logger.warning(f"âš ï¸ conda í™˜ê²½ì„ í™•ì¸í•˜ì„¸ìš”: conda activate mycloset-ai-clean")

# ì´ˆê¸° ë©”ëª¨ë¦¬ ìµœì í™”
if IS_M3_MAX_DETECTED:
    try:
        import torch
        if hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
            if hasattr(torch.backends.mps, 'empty_cache'):
                torch.backends.mps.empty_cache()
        gc.collect()
        logger.info("ğŸ M3 Max ì´ˆê¸° ë©”ëª¨ë¦¬ ìµœì í™” ì™„ë£Œ! (DetailedDataSpec ì§€ì›)")
    except:
        pass

logger.info("ğŸš€ StepFactory v11.0 ì™„ì „ ì¤€ë¹„ ì™„ë£Œ! (DetailedDataSpec ì™„ì „ í†µí•© + BaseStepMixin v19.0) ğŸš€")
logger.info("ğŸ’¡ ì´ì œ step_model_requirements.pyì˜ DetailedDataSpecì„ ì™„ì „íˆ í™œìš©í•©ë‹ˆë‹¤!")
logger.info("ğŸ’¡ API ì…ì¶œë ¥ ë§¤í•‘, Step ê°„ ë°ì´í„° íë¦„, ì „ì²˜ë¦¬/í›„ì²˜ë¦¬ê°€ ìë™ìœ¼ë¡œ ì ìš©ë©ë‹ˆë‹¤!")
logger.info("ğŸ’¡ FastAPI ë¼ìš°í„°ì™€ 100% í˜¸í™˜ë˜ë©°, ëª¨ë“  ë°ì´í„° ë³€í™˜ì´ ìë™í™”ë˜ì—ˆìŠµë‹ˆë‹¤!")
logger.info("ğŸ’¡ ğŸ”¥ GitHub í”„ë¡œì íŠ¸ì™€ BaseStepMixin v19.0 ì™„ì „ í˜¸í™˜!")