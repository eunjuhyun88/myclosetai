# backend/app/ai_pipeline/factories/step_factory.py
"""
ğŸ”¥ StepFactory v11.1 - ì‹¤ì œ AI êµ¬ì¡° ì™„ì „ ë°˜ì˜ + ìˆœí™˜ì°¸ì¡° í•´ê²° + ëª¨ë“  ê¸°ëŠ¥ í¬í•¨
================================================================================

âœ… step_interface.py v5.2ì˜ ì‹¤ì œ AI ëª¨ë¸ êµ¬ì¡° ì™„ì „ ë°˜ì˜
âœ… RealAIModelConfig ì‹¤ì œ 229GB íŒŒì¼ ë§¤í•‘ ì ìš©
âœ… Real í´ë˜ìŠ¤ êµ¬ì¡° í†µí•© (RealGitHub*)
âœ… ì‹¤ì œ ì²´í¬í¬ì¸íŠ¸ ë¡œë”© ê¸°ëŠ¥ êµ¬í˜„
âœ… TYPE_CHECKING + ì§€ì—° importë¡œ ìˆœí™˜ì°¸ì¡° ì™„ì „ í•´ê²°
âœ… step_model_requirements.pyì˜ DetailedDataSpec ì™„ì „ í™œìš© (ê¸°ì¡´ ê¸°ëŠ¥ ìœ ì§€)
âœ… API ì…ì¶œë ¥ ë§¤í•‘ (api_input_mapping, api_output_mapping) ìë™ ì²˜ë¦¬  
âœ… Step ê°„ ë°ì´í„° íë¦„ (provides_to_next_step, accepts_from_previous_step) ê´€ë¦¬
âœ… ì „ì²˜ë¦¬/í›„ì²˜ë¦¬ ìš”êµ¬ì‚¬í•­ ìë™ ì ìš©
âœ… BaseStepMixin v19.2 í‘œì¤€ ì™„ì „ í˜¸í™˜
âœ… ìƒì„±ì ì‹œì  ì˜ì¡´ì„± ì£¼ì… (constructor injection)
âœ… conda í™˜ê²½ ìš°ì„  ìµœì í™” (mycloset-ai-clean)
âœ… M3 Max 128GB ë©”ëª¨ë¦¬ ìµœì í™”
âœ… ì‹¤ì œ AI ëª¨ë¸ 229GB íŒŒì¼ ê²½ë¡œ ë§¤í•‘
âœ… FastAPI ë¼ìš°í„° 100% í˜¸í™˜ì„± í™•ë³´
âœ… ëª¨ë“  í•¨ìˆ˜ëª…, ë©”ì„œë“œëª…, í´ë˜ìŠ¤ëª… 100% ìœ ì§€

Author: MyCloset AI Team
Date: 2025-07-30
Version: 11.1 (Real AI Structure Reflection + Circular Reference Fix + Complete Features)
"""

import os
import sys
import logging
import threading
import time
import weakref
import gc
import traceback
import uuid
import asyncio
import concurrent.futures
from pathlib import Path
from typing import Dict, Any, Optional, List, Union, Type, Tuple, TYPE_CHECKING
from dataclasses import dataclass, field
from enum import Enum, IntEnum
from abc import ABC, abstractmethod
from concurrent.futures import ThreadPoolExecutor

# ==============================================
# ğŸ”¥ safe_copy í•¨ìˆ˜ ì •ì˜ (ìµœìš°ì„  - DetailedDataSpec ì—ëŸ¬ í•´ê²°)
# ==============================================

def safe_copy(obj: Any) -> Any:
    """ì•ˆì „í•œ ë³µì‚¬ í•¨ìˆ˜ - DetailedDataSpec ì—ëŸ¬ í•´ê²°"""
    try:
        # ê¸°ë³¸ íƒ€ì…ë“¤ì€ ê·¸ëŒ€ë¡œ ë°˜í™˜
        if obj is None or isinstance(obj, (bool, int, float, str)):
            return obj
        
        # ë¦¬ìŠ¤íŠ¸ë‚˜ íŠœí”Œ
        elif isinstance(obj, (list, tuple)):
            return type(obj)(safe_copy(item) for item in obj)
        
        # ë”•ì…”ë„ˆë¦¬
        elif isinstance(obj, dict):
            return {key: safe_copy(value) for key, value in obj.items()}
        
        # ì§‘í•©
        elif isinstance(obj, set):
            return {safe_copy(item) for item in obj}
        
        # copy ëª¨ë“ˆ ì‚¬ìš© ê°€ëŠ¥í•œ ê²½ìš°
        else:
            try:
                return copy.deepcopy(obj)
            except:
                try:
                    return copy.copy(obj)
                except:
                    # ë³µì‚¬í•  ìˆ˜ ì—†ëŠ” ê²½ìš° ì›ë³¸ ë°˜í™˜ (ì˜ˆ: í•¨ìˆ˜, í´ë˜ìŠ¤ ë“±)
                    return obj
                    
    except Exception:
        # ëª¨ë“  ì‹¤íŒ¨ ì¼€ì´ìŠ¤ì—ì„œ ì›ë³¸ ë°˜í™˜
        return obj

# ì „ì—­ìœ¼ë¡œ ì‚¬ìš© ê°€ëŠ¥í•˜ë„ë¡ ì„¤ì •
globals()['safe_copy'] = safe_copy

# ğŸ”¥ TYPE_CHECKINGìœ¼ë¡œ ìˆœí™˜ì°¸ì¡° ì™„ì „ ë°©ì§€  
if TYPE_CHECKING:
    from ..steps.base_step_mixin import BaseStepMixin, GitHubDependencyManager
    from ..utils.model_loader import ModelLoader
    from ..utils.memory_manager import MemoryManager
    from ..utils.data_converter import DataConverter
    from app.core.di_container import CircularReferenceFreeDIContainer
else:
    # ëŸ°íƒ€ì„ì—ëŠ” Anyë¡œ ì²˜ë¦¬
    BaseStepMixin = Any
    GitHubDependencyManager = Any
    ModelLoader = Any
    MemoryManager = Any
    DataConverter = Any
    CircularReferenceFreeDIContainer = Any  # ì¶”ê°€

# ==============================================
# ğŸ”¥ step_interface.py v5.2ì—ì„œ ì‹¤ì œ êµ¬ì¡° import
# ==============================================

try:
    from ..interface.step_interface import (
        # ì‹¤ì œ í™˜ê²½ ì •ë³´
        CONDA_INFO, IS_M3_MAX, MEMORY_GB, MPS_AVAILABLE, PYTORCH_AVAILABLE,
        PROJECT_ROOT, BACKEND_ROOT, AI_PIPELINE_ROOT, AI_MODELS_ROOT,
        
        # ì‹¤ì œ GitHub Step êµ¬ì¡°
        GitHubStepType, GitHubStepPriority, GitHubDeviceType, GitHubProcessingStatus,
        RealAIModelConfig, GitHubStepConfig, GitHubStepMapping,
        
        # ì‹¤ì œ í´ë˜ìŠ¤ë“¤ (Mock ì œê±°)
        RealStepModelInterface, RealMemoryManager, RealDependencyManager,
        
        # ì‹¤ì œ íŒ©í† ë¦¬ í•¨ìˆ˜ë“¤
        create_real_step_interface, create_optimized_real_interface,
        create_virtual_fitting_step_interface,
        
        # ì‹¤ì œ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
        get_real_environment_info, optimize_real_environment,
        validate_real_step_compatibility, get_real_step_info,
        
        # í˜¸í™˜ì„± ë³„ì¹­ë“¤ (ê¸°ì¡´ ì½”ë“œ í˜¸í™˜ì„±)
        GitHubStepModelInterface, GitHubMemoryManager, EmbeddedDependencyManager,
        GitHubStepCreationResult
    )


    REAL_STEP_INTERFACE_AVAILABLE = True
    logger = logging.getLogger(__name__)
    logger.info("âœ… step_interface.py v5.2 ì‹¤ì œ êµ¬ì¡° import ì„±ê³µ")
except ImportError as e:
    REAL_STEP_INTERFACE_AVAILABLE = False
    logger = logging.getLogger(__name__)
    logger.warning(f"âš ï¸ step_interface.py v5.2 import ì‹¤íŒ¨, í´ë°± ëª¨ë“œ: {e}")
    
    # í´ë°± í™˜ê²½ ì •ë³´
    CONDA_INFO = {
        'conda_env': os.environ.get('CONDA_DEFAULT_ENV', 'none'),
        'conda_prefix': os.environ.get('CONDA_PREFIX', 'none'),
        'is_target_env': os.environ.get('CONDA_DEFAULT_ENV') == 'mycloset-ai-clean'
    }
    IS_M3_MAX = False
    MEMORY_GB = 16.0
    MPS_AVAILABLE = False
    PYTORCH_AVAILABLE = False

# ==============================================
# ğŸ”¥ í™˜ê²½ ì„¤ì • ë° ì‹œìŠ¤í…œ ì •ë³´ (ì‹¤ì œ êµ¬ì¡° ë°˜ì˜)
# ==============================================

logger = logging.getLogger(__name__)

# M3 Max ê°ì§€ (ì‹¤ì œ í™˜ê²½)
IS_M3_MAX_DETECTED = IS_M3_MAX if REAL_STEP_INTERFACE_AVAILABLE else False

try:
    import platform
    if platform.system() == 'Darwin' and platform.machine() == 'arm64':
        try:
            import subprocess
            result = subprocess.run(['sysctl', '-n', 'machdep.cpu.brand_string'], 
                                  capture_output=True, text=True, timeout=3)
            IS_M3_MAX_DETECTED = 'M3' in result.stdout
            
            memory_result = subprocess.run(['sysctl', '-n', 'hw.memsize'], 
                                         capture_output=True, text=True, timeout=3)
            if memory_result.stdout.strip():
                MEMORY_GB = int(memory_result.stdout.strip()) / 1024**3
        except:
            pass
except:
    pass

# backend/app/ai_pipeline/factories/step_factory.pyì—ì„œ ìˆ˜ì •í•  ë¶€ë¶„
# ë¼ì¸ 80-90 ë¶€ê·¼ì˜ STEP_MODEL_REQUIREMENTS ì •ì˜ë¥¼ ë‹¤ìŒê³¼ ê°™ì´ ìˆ˜ì •:

# ğŸ”¥ step_model_requirements ë™ì  ë¡œë”© (ìˆœí™˜ì°¸ì¡° ë°©ì§€) - ì•ˆì „í•œ ì²˜ë¦¬
def _load_step_model_requirements():
    """step_model_requests.py ì•ˆì „í•œ ë™ì  ë¡œë”© (ìˆ˜ì •ëœ í•¨ìˆ˜)"""
    try:
        # ğŸ”¥ ì˜¬ë°”ë¥¸ íŒŒì¼ëª…ìœ¼ë¡œ ìˆ˜ì •: step_model_requests (not requirements)
        import_paths = [
            'app.ai_pipeline.utils.step_model_requests',
            'ai_pipeline.utils.step_model_requests', 
            'utils.step_model_requests',
            '..utils.step_model_requests',
            'backend.app.ai_pipeline.utils.step_model_requests'
        ]
        
        for import_path in import_paths:
            try:
                logger.debug(f"ğŸ” step_model_requests ë¡œë”© ì‹œë„: {import_path}")
                
                if import_path.startswith('..'):
                    # ìƒëŒ€ import
                    import importlib
                    module = importlib.import_module(import_path, package=__name__)
                else:
                    # ì ˆëŒ€ import
                    from importlib import import_module
                    module = import_module(import_path)
                
                # í•„ìˆ˜ í•¨ìˆ˜ë“¤ í™•ì¸
                if hasattr(module, 'get_enhanced_step_request') and hasattr(module, 'REAL_STEP_MODEL_REQUESTS'):
                    logger.info(f"âœ… step_model_requests ë¡œë”© ì„±ê³µ: {import_path}")
                    return {
                        'get_enhanced_step_request': module.get_enhanced_step_request,
                        'REAL_STEP_MODEL_REQUESTS': module.REAL_STEP_MODEL_REQUESTS
                    }
                else:
                    logger.debug(f"âš ï¸ {import_path}ì— í•„ìˆ˜ í•¨ìˆ˜ë“¤ ì—†ìŒ")
                    
            except ImportError as e:
                logger.debug(f"âš ï¸ {import_path} import ì‹¤íŒ¨: {e}")
                continue
            except Exception as e:
                logger.debug(f"âš ï¸ {import_path} ë¡œë”© ì¤‘ ì˜¤ë¥˜: {e}")
                continue
        
        # ëª¨ë“  ê²½ë¡œ ì‹¤íŒ¨ ì‹œ - GeometricMatchingStep ì „ìš© í´ë°± ìƒì„±
        logger.warning("âš ï¸ step_model_requests.py ëª¨ë“  ê²½ë¡œì—ì„œ ë¡œë”© ì‹¤íŒ¨, í´ë°± ìƒì„±")
        return create_hardcoded_fallback_requirements()
        
    except Exception as e:
        logger.error(f"âŒ step_model_requests.py ë¡œë”© ì™„ì „ ì‹¤íŒ¨: {e}")
        return create_hardcoded_fallback_requirements()

def create_hardcoded_fallback_requirements():
    """í•˜ë“œì½”ë”©ëœ í´ë°± ìš”êµ¬ì‚¬í•­ (GeometricMatchingStep ì¤‘ì‹¬) - ì•ˆì „í•œ ìƒì„±"""
    try:
        logger.info("ğŸ”§ í•˜ë“œì½”ë”©ëœ í´ë°± step_model_requirements ìƒì„± ì¤‘...")
        
        # ê°„ë‹¨í•œ DetailedDataSpec í´ë˜ìŠ¤
        class FallbackDetailedDataSpec:
            def __init__(self):
                # GeometricMatchingStepìš© ì™„ì „í•œ API ë§¤í•‘
                self.api_input_mapping = {
                    'person_image': 'UploadFile',
                    'clothing_image': 'UploadFile',
                    'pose_keypoints': 'Optional[List[Dict[str, float]]]',
                    'parsing_mask': 'Optional[np.ndarray]'
                }
                self.api_output_mapping = {
                    'matched_points': 'List[Dict[str, Any]]',
                    'transformation_matrix': 'np.ndarray',
                    'transformation_grid': 'np.ndarray', 
                    'warped_clothing': 'np.ndarray',
                    'flow_field': 'np.ndarray',
                    'confidence': 'float',
                    'matching_score': 'float',
                    'quality_score': 'float'
                }
                
                # Step ê°„ ë°ì´í„° íë¦„
                self.accepts_from_previous_step = {
                    'step_01': {
                        'parsing_mask': 'np.ndarray',
                        'person_mask': 'np.ndarray'
                    },
                    'step_02': {
                        'pose_keypoints': 'List[Dict[str, float]]',
                        'pose_heatmap': 'np.ndarray'
                    },
                    'step_03': {
                        'clothing_mask': 'np.ndarray',
                        'clothing_features': 'np.ndarray'
                    }
                }
                self.provides_to_next_step = {
                    'step_05': {
                        'transformation_matrix': 'np.ndarray',
                        'transformation_grid': 'np.ndarray',
                        'warped_clothing': 'np.ndarray',
                        'matching_metadata': 'Dict[str, Any]'
                    },
                    'step_06': {
                        'geometric_features': 'np.ndarray',
                        'correspondence_map': 'np.ndarray',
                        'flow_field': 'np.ndarray'
                    }
                }
                
                # ê¸°ë³¸ ì†ì„±ë“¤
                self.step_input_schema = self.accepts_from_previous_step
                self.step_output_schema = self.provides_to_next_step
                self.input_data_types = ['PIL.Image', 'PIL.Image', 'Optional[List[Dict]]', 'Optional[np.ndarray]']
                self.output_data_types = ['List[Dict[str, Any]]', 'np.ndarray', 'np.ndarray', 'np.ndarray', 'np.ndarray', 'float', 'float', 'float']
                self.input_shapes = {'person_image': (768, 1024, 3), 'clothing_image': (768, 1024, 3)}
                self.output_shapes = {'transformation_matrix': (3, 3), 'warped_clothing': (768, 1024, 3)}
                self.input_value_ranges = {'person_image': (0.0, 255.0), 'clothing_image': (0.0, 255.0)}
                self.output_value_ranges = {'warped_clothing': (0.0, 255.0), 'confidence': (0.0, 1.0)}
                self.preprocessing_required = True
                self.postprocessing_required = True
                self.preprocessing_steps = [
                    'resize_768x1024',
                    'normalize_imagenet',
                    'to_tensor', 
                    'extract_pose_features',
                    'prepare_geometric_inputs'
                ]
                self.postprocessing_steps = [
                    'denormalize_output',
                    'apply_transformation',
                    'compute_flow_field',
                    'calculate_matching_score',
                    'generate_quality_metrics'
                ]
                self.normalization_mean = (0.485, 0.456, 0.406)
                self.normalization_std = (0.229, 0.224, 0.225)
        
        # ê°„ë‹¨í•œ EnhancedStepRequest í´ë˜ìŠ¤  
        class FallbackEnhancedStepRequest:
            def __init__(self, step_name, step_id, custom_data_spec=None):
                self.step_name = step_name
                self.step_id = step_id
                self.data_spec = custom_data_spec if custom_data_spec else FallbackDetailedDataSpec()
                self.required_models = []
                self.model_requirements = {}
                self.preprocessing_config = {}
                self.postprocessing_config = {}
                
                # GeometricMatchingStep ì „ìš© ëª¨ë¸ ì„¤ì •
                if step_name == "GeometricMatchingStep":
                    self.required_models = [
                        'sam_vit_h_4b8939.pth',
                        'resnet101_geometric.pth', 
                        'raft-things.pth',
                        'ViT-L-14.pt'
                    ]
        
        # ê¸°ë³¸ DataSpec (ë‹¤ë¥¸ Stepìš©)
        class BasicDataSpec:
            def __init__(self):
                self.api_input_mapping = {'input_image': 'UploadFile'}
                self.api_output_mapping = {'result': 'base64_string'}
                self.accepts_from_previous_step = {}
                self.provides_to_next_step = {}
                self.step_input_schema = {}
                self.step_output_schema = {}
                self.input_data_types = ['PIL.Image']
                self.output_data_types = ['np.ndarray']
                self.input_shapes = {}
                self.output_shapes = {}
                self.input_value_ranges = {}
                self.output_value_ranges = {}
                self.preprocessing_required = True
                self.postprocessing_required = True
                self.preprocessing_steps = ['resize', 'normalize']
                self.postprocessing_steps = ['denormalize', 'convert']
                self.normalization_mean = (0.485, 0.456, 0.406)
                self.normalization_std = (0.229, 0.224, 0.225)
        
        # í´ë°± ìš”êµ¬ì‚¬í•­ ë”•ì…”ë„ˆë¦¬
        FALLBACK_REAL_STEP_MODEL_REQUESTS = {
            "GeometricMatchingStep": FallbackEnhancedStepRequest("GeometricMatchingStep", 4, FallbackDetailedDataSpec()),
            "HumanParsingStep": FallbackEnhancedStepRequest("HumanParsingStep", 1, BasicDataSpec()),
            "PoseEstimationStep": FallbackEnhancedStepRequest("PoseEstimationStep", 2, BasicDataSpec()),
            "ClothSegmentationStep": FallbackEnhancedStepRequest("ClothSegmentationStep", 3, BasicDataSpec()),
            "ClothWarpingStep": FallbackEnhancedStepRequest("ClothWarpingStep", 5, BasicDataSpec()),
            "VirtualFittingStep": FallbackEnhancedStepRequest("VirtualFittingStep", 6, BasicDataSpec()),
            "PostProcessingStep": FallbackEnhancedStepRequest("PostProcessingStep", 7, BasicDataSpec()),
            "QualityAssessmentStep": FallbackEnhancedStepRequest("QualityAssessmentStep", 8, BasicDataSpec()),
        }
        
        def fallback_get_enhanced_step_request(step_name: str):
            """í´ë°± get_enhanced_step_request í•¨ìˆ˜"""
            result = FALLBACK_REAL_STEP_MODEL_REQUESTS.get(step_name)
            if result:
                logger.debug(f"âœ… {step_name} í´ë°± DetailedDataSpec ë°˜í™˜")
            else:
                logger.warning(f"âš ï¸ {step_name} í´ë°±ì—ì„œë„ ì°¾ì„ ìˆ˜ ì—†ìŒ")
            return result
        
        logger.info("âœ… í•˜ë“œì½”ë”©ëœ í´ë°± step_model_requirements ìƒì„± ì™„ë£Œ")
        logger.info(f"   - GeometricMatchingStep: âœ… (ì™„ì „í•œ DetailedDataSpec + 4ê°œ ëª¨ë¸)")
        logger.info(f"   - API ì…ë ¥: {len(FallbackDetailedDataSpec().api_input_mapping)}ê°œ")
        logger.info(f"   - API ì¶œë ¥: {len(FallbackDetailedDataSpec().api_output_mapping)}ê°œ")
        logger.info(f"   - ì´ Step: {len(FALLBACK_REAL_STEP_MODEL_REQUESTS)}ê°œ")
        
        return {
            'get_enhanced_step_request': fallback_get_enhanced_step_request,
            'REAL_STEP_MODEL_REQUESTS': FALLBACK_REAL_STEP_MODEL_REQUESTS
        }
        
    except Exception as e:
        logger.error(f"âŒ í•˜ë“œì½”ë”©ëœ í´ë°± ìƒì„± ì‹¤íŒ¨: {e}")
        # ìµœí›„ì˜ ìˆ˜ë‹¨ - ì™„ì „ ê¸°ë³¸ ë”•ì…”ë„ˆë¦¬
        return {
            'get_enhanced_step_request': lambda x: None,
            'REAL_STEP_MODEL_REQUESTS': {}
        }

# ğŸ”¥ ì•ˆì „í•œ STEP_MODEL_REQUIREMENTS ì •ì˜ (ì—ëŸ¬ ë°©ì§€)
try:
    STEP_MODEL_REQUIREMENTS = _load_step_model_requirements()
    if STEP_MODEL_REQUIREMENTS is None:
        logger.warning("âš ï¸ step_model_requirements ë¡œë”© ì‹¤íŒ¨, ë¹ˆ ë”•ì…”ë„ˆë¦¬ë¡œ ì´ˆê¸°í™”")
        STEP_MODEL_REQUIREMENTS = {
            'get_enhanced_step_request': lambda x: None,
            'REAL_STEP_MODEL_REQUESTS': {}
        }
except Exception as e:
    logger.error(f"âŒ STEP_MODEL_REQUIREMENTS ì´ˆê¸°í™” ì™„ì „ ì‹¤íŒ¨: {e}")
    # ìµœí›„ì˜ ì•ˆì „ì¥ì¹˜
    STEP_MODEL_REQUIREMENTS = {
        'get_enhanced_step_request': lambda x: None,
        'REAL_STEP_MODEL_REQUESTS': {}
    }

# ğŸ”¥ ëª¨ë“ˆ export ì‹œ ì•ˆì „ì„± ë³´ì¥
if STEP_MODEL_REQUIREMENTS is None:
    logger.error("âŒ STEP_MODEL_REQUIREMENTSê°€ Noneì…ë‹ˆë‹¤. ë¹ˆ ë”•ì…”ë„ˆë¦¬ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.")
    STEP_MODEL_REQUIREMENTS = {
        'get_enhanced_step_request': lambda x: None,
        'REAL_STEP_MODEL_REQUESTS': {}
    }

logger.info(f"ğŸ”§ StepFactory v11.1 ì‹¤ì œ êµ¬ì¡° ë°˜ì˜: {'âœ… ì„±ê³µ' if STEP_MODEL_REQUIREMENTS and STEP_MODEL_REQUIREMENTS.get('REAL_STEP_MODEL_REQUESTS') else 'âŒ ì‹¤íŒ¨ (í´ë°± ì‚¬ìš©)'}")
logger.info(f"ğŸ”§ í™˜ê²½: conda={CONDA_INFO['conda_env']}, M3 Max={IS_M3_MAX_DETECTED}, ë©”ëª¨ë¦¬={MEMORY_GB:.1f}GB")
logger.info(f"ğŸ”§ STEP_MODEL_REQUIREMENTS ìƒíƒœ: {'âœ… ë¡œë”©ë¨' if STEP_MODEL_REQUIREMENTS else 'âŒ None'}")

# ğŸ”¥ ì¶”ê°€ ì•ˆì „ ê²€ì‚¬
if not isinstance(STEP_MODEL_REQUIREMENTS, dict):
    logger.error(f"âŒ STEP_MODEL_REQUIREMENTSê°€ ë”•ì…”ë„ˆë¦¬ê°€ ì•„ë‹™ë‹ˆë‹¤: {type(STEP_MODEL_REQUIREMENTS)}")
    STEP_MODEL_REQUIREMENTS = {
        'get_enhanced_step_request': lambda x: None,
        'REAL_STEP_MODEL_REQUESTS': {}
    }

# ==============================================
# ğŸ”¥ ë™ì  Import í•´ê²°ê¸° (ìˆœí™˜ì°¸ì¡° ì™„ì „ ë°©ì§€)
# ==============================================

class DynamicImportResolver:
    """ë™ì  import í•´ê²°ê¸° (ìˆœí™˜ì°¸ì¡° ì™„ì „ ë°©ì§€)"""
    
    @staticmethod
    def resolve_model_loader():
        """ModelLoader ë™ì  í•´ê²° (ìˆœí™˜ì°¸ì¡° ë°©ì§€)"""
        import_paths = [
            'app.ai_pipeline.utils.model_loader',
            'ai_pipeline.utils.model_loader',
            'utils.model_loader'
        ]
        
        for path in import_paths:
            try:
                module = importlib.import_module(path)
                
                # ì „ì—­ í•¨ìˆ˜ ìš°ì„ 
                if hasattr(module, 'get_global_model_loader'):
                    loader = module.get_global_model_loader()
                    if loader:
                        logger.debug(f"âœ… ModelLoader ë™ì  í•´ê²°: {path}")
                        return loader
                
                # í´ë˜ìŠ¤ ì§ì ‘ ìƒì„±
                if hasattr(module, 'ModelLoader'):
                    ModelLoaderClass = module.ModelLoader
                    loader = ModelLoaderClass()
                    logger.debug(f"âœ… ModelLoader í´ë˜ìŠ¤ ìƒì„±: {path}")
                    return loader
                    
            except ImportError:
                continue
        
        # ì™„ì „ ì‹¤íŒ¨ ì‹œ Mock ë°˜í™˜
        logger.warning("âš ï¸ ModelLoader í•´ê²° ì‹¤íŒ¨, Mock ì‚¬ìš©")
        return DynamicImportResolver._create_mock_model_loader()
    
    @staticmethod
    def resolve_memory_manager():
        """MemoryManager ë™ì  í•´ê²° (ìˆœí™˜ì°¸ì¡° ë°©ì§€)"""
        import_paths = [
            'app.ai_pipeline.utils.memory_manager',
            'ai_pipeline.utils.memory_manager',
            'utils.memory_manager'
        ]
        
        for path in import_paths:
            try:
                module = importlib.import_module(path)
                
                if hasattr(module, 'get_global_memory_manager'):
                    manager = module.get_global_memory_manager()
                    if manager:
                        logger.debug(f"âœ… MemoryManager ë™ì  í•´ê²°: {path}")
                        return manager
                
                if hasattr(module, 'MemoryManager'):
                    MemoryManagerClass = module.MemoryManager
                    manager = MemoryManagerClass()
                    logger.debug(f"âœ… MemoryManager í´ë˜ìŠ¤ ìƒì„±: {path}")
                    return manager
                    
            except ImportError:
                continue
        
        logger.warning("âš ï¸ MemoryManager í•´ê²° ì‹¤íŒ¨, Mock ì‚¬ìš©")
        return DynamicImportResolver._create_mock_memory_manager()
    
    @staticmethod
    def resolve_data_converter():
        """DataConverter ë™ì  í•´ê²° (ìˆœí™˜ì°¸ì¡° ë°©ì§€)"""
        import_paths = [
            'app.ai_pipeline.utils.data_converter',
            'ai_pipeline.utils.data_converter',
            'utils.data_converter'
        ]
        
        for path in import_paths:
            try:
                module = importlib.import_module(path)
                
                if hasattr(module, 'get_global_data_converter'):
                    converter = module.get_global_data_converter()
                    if converter:
                        logger.debug(f"âœ… DataConverter ë™ì  í•´ê²°: {path}")
                        return converter
                
                if hasattr(module, 'DataConverter'):
                    DataConverterClass = module.DataConverter
                    converter = DataConverterClass()
                    logger.debug(f"âœ… DataConverter í´ë˜ìŠ¤ ìƒì„±: {path}")
                    return converter
                    
            except ImportError:
                continue
        
        logger.warning("âš ï¸ DataConverter í•´ê²° ì‹¤íŒ¨, Mock ì‚¬ìš©")
        return DynamicImportResolver._create_mock_data_converter()
    
    @staticmethod
    def resolve_di_container():
        """DI Container ë™ì  í•´ê²° (ìˆœí™˜ì°¸ì¡° ë°©ì§€)"""
        import_paths = [
            'app.core.di_container',
            'core.di_container',
            '...core.di_container'
        ]
        
        for path in import_paths:
            try:
                module = importlib.import_module(path)
                
                if hasattr(module, 'get_global_container'):
                    container = module.get_global_container()
                    if container:
                        logger.debug(f"âœ… DIContainer ë™ì  í•´ê²°: {path}")
                        return container
                        
            except ImportError:
                continue
        
        logger.warning("âš ï¸ DIContainer í•´ê²° ì‹¤íŒ¨")
        return None
    
    @staticmethod
    def resolve_step_factory():
        """StepFactory ë™ì  í•´ê²° (ìˆœí™˜ì°¸ì¡° ë°©ì§€) - ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ë§ ê²ƒ!"""
        # âš ï¸ ì´ í•¨ìˆ˜ëŠ” ìˆœí™˜ì°¸ì¡°ë¥¼ ë§Œë“¤ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì‚¬ìš© ê¸ˆì§€
        logger.warning("âš ï¸ StepFactory ë™ì  í•´ê²° ìš”ì²­ë¨ - ìˆœí™˜ì°¸ì¡° ìœ„í—˜!")
        return None
    
    @staticmethod
    def _create_mock_model_loader():
        """Mock ModelLoader (ìˆœí™˜ì°¸ì¡° ë°©ì§€)"""
        class MockModelLoader:
            def __init__(self):
                self.models = {}
                self.device = 'cpu'
                self.is_initialized = True

            def get_model(self, model_name: str):
                if model_name not in self.models:
                    self.models[model_name] = {
                        "name": model_name,
                        "device": self.device,
                        "type": "mock_model",
                        "loaded": True,
                        "size_mb": 50.0
                    }
                return self.models[model_name]
            
            def load_model(self, model_name: str):
                return self.get_model(model_name)
            
            def initialize(self):
                return True
            
            def cleanup_models(self):
                self.models.clear()
        
        return MockModelLoader()
    
    @staticmethod
    def _create_mock_memory_manager():
        """Mock MemoryManager (ìˆœí™˜ì°¸ì¡° ë°©ì§€)"""
        class MockMemoryManager:
            def __init__(self):
                self.optimization_count = 0
                self.is_initialized = True
            
            def optimize_memory(self, aggressive: bool = False):
                try:
                    gc.collect()
                    self.optimization_count += 1
                    return {
                        "success": True,
                        "method": "mock_optimization",
                        "count": self.optimization_count,
                        "memory_freed_mb": 50.0
                    }
                except Exception as e:
                    return {"success": False, "error": str(e)}
            
            def get_memory_info(self):
                return {
                    "total_gb": 16.0,
                    "available_gb": 11.2,
                    "percent": 30.0,
                    "device": 'cpu'
                }
            
            def cleanup(self):
                self.optimize_memory(aggressive=True)
        
        return MockMemoryManager()
    
    @staticmethod
    def _create_mock_data_converter():
        """Mock DataConverter (ìˆœí™˜ì°¸ì¡° ë°©ì§€)"""
        class MockDataConverter:
            def __init__(self):
                self.conversion_count = 0
                self.is_initialized = True
            
            def convert(self, data, target_format: str):
                self.conversion_count += 1
                return {
                    "converted_data": f"mock_converted_{target_format}_{self.conversion_count}",
                    "format": target_format,
                    "conversion_count": self.conversion_count,
                    "success": True
                }
            
            def get_supported_formats(self):
                return ["tensor", "numpy", "pil", "cv2", "base64"]
            
            def cleanup(self):
                self.conversion_count = 0
        
        return MockDataConverter()

# ==============================================
# ğŸ”¥ ì‹¤ì œ AI ëª¨ë¸ êµ¬ì¡° (step_interface.py v5.2 ê¸°ë°˜)
# ==============================================

class StepType(Enum):
    """GitHub í”„ë¡œì íŠ¸ í‘œì¤€ Step íƒ€ì… (ì‹¤ì œ êµ¬ì¡° ë°˜ì˜)"""
    HUMAN_PARSING = "human_parsing"
    POSE_ESTIMATION = "pose_estimation"
    CLOTH_SEGMENTATION = "cloth_segmentation"
    GEOMETRIC_MATCHING = "geometric_matching"
    CLOTH_WARPING = "cloth_warping"
    VIRTUAL_FITTING = "virtual_fitting"
    POST_PROCESSING = "post_processing"
    QUALITY_ASSESSMENT = "quality_assessment"

class StepPriority(IntEnum):
    """GitHub í”„ë¡œì íŠ¸ í‘œì¤€ Step ìš°ì„ ìˆœìœ„ (ì‹¤ì œ êµ¬ì¡° ë°˜ì˜)"""
    CRITICAL = 1    # Virtual Fitting (14GB), Human Parsing (4GB)
    HIGH = 2        # Cloth Warping (7GB), Quality Assessment (7GB)
    NORMAL = 3      # Cloth Segmentation (5.5GB), Pose Estimation (3.4GB)
    LOW = 4         # Post Processing (1.3GB), Geometric Matching (1.3GB)

@dataclass
class RealAIModelConfig:
    """ì‹¤ì œ AI ëª¨ë¸ ì„¤ì • (step_interface.py v5.2 ê¸°ë°˜)"""
    model_name: str
    model_path: str
    model_type: str = "BaseModel"
    size_gb: float = 0.0
    device: str = "auto"
    requires_checkpoint: bool = True
    checkpoint_key: Optional[str] = None
    preprocessing_required: List[str] = field(default_factory=list)
    postprocessing_required: List[str] = field(default_factory=list)

@dataclass
class DetailedDataSpecConfig:
    """DetailedDataSpec ì™„ì „ í†µí•© ì„¤ì • (ê¸°ì¡´ ìœ ì§€)"""
    # API ë§¤í•‘ (FastAPI â†” Step í´ë˜ìŠ¤)
    api_input_mapping: Dict[str, Any] = field(default_factory=dict)
    api_output_mapping: Dict[str, Any] = field(default_factory=dict)
    
    # Step ê°„ ë°ì´í„° íë¦„
    accepts_from_previous_step: Dict[str, Any] = field(default_factory=dict)
    provides_to_next_step: Dict[str, Any] = field(default_factory=dict)
    step_input_schema: Dict[str, Any] = field(default_factory=dict)
    step_output_schema: Dict[str, Any] = field(default_factory=dict)
    
    # ì…ì¶œë ¥ ë°ì´í„° ì‚¬ì–‘
    input_data_types: List[str] = field(default_factory=list)
    output_data_types: List[str] = field(default_factory=list)
    input_shapes: Dict[str, List[int]] = field(default_factory=dict)
    output_shapes: Dict[str, List[int]] = field(default_factory=dict)
    input_value_ranges: Dict[str, Tuple[float, float]] = field(default_factory=dict)
    output_value_ranges: Dict[str, Tuple[float, float]] = field(default_factory=dict)
    
    # ì „ì²˜ë¦¬/í›„ì²˜ë¦¬
    preprocessing_required: bool = True
    postprocessing_required: bool = True
    preprocessing_steps: List[str] = field(default_factory=list)
    postprocessing_steps: List[str] = field(default_factory=list)
    normalization_mean: List[float] = field(default_factory=lambda: [0.485, 0.456, 0.406])
    normalization_std: List[float] = field(default_factory=lambda: [0.229, 0.224, 0.225])

@dataclass
class RealGitHubStepConfig:
    """ì‹¤ì œ GitHub í”„ë¡œì íŠ¸ Step ì„¤ì • + DetailedDataSpec í†µí•© (ì‹¤ì œ êµ¬ì¡° ë°˜ì˜)"""
    # GitHub ê¸°ë³¸ Step ì •ë³´
    step_name: str
    step_id: int
    step_type: StepType
    class_name: str
    module_path: str
    priority: StepPriority = StepPriority.NORMAL
    
    # BaseStepMixin v19.2 í‘œì¤€ ì„¤ì •
    device: str = "auto"
    use_fp16: bool = True
    batch_size: int = 1
    confidence_threshold: float = 0.8
    
    # GitHub ìµœì í™” ì„¤ì •
    auto_memory_cleanup: bool = True
    auto_warmup: bool = True
    optimization_enabled: bool = True
    strict_mode: bool = False
    quality_level: str = "balanced"
    
    # GitHub ì˜ì¡´ì„± ì„¤ì • (v19.2 í‘œì¤€)
    auto_inject_dependencies: bool = True
    require_model_loader: bool = True
    require_memory_manager: bool = False
    require_data_converter: bool = False
    require_di_container: bool = False
    require_unified_dependency_manager: bool = True
    dependency_timeout: float = 30.0
    dependency_retry_count: int = 3
    
    # ì‹¤ì œ AI ëª¨ë¸ ì •ë³´ (229GB íŒŒì¼ ê¸°ë°˜)
    real_ai_models: List[RealAIModelConfig] = field(default_factory=list)
    ai_models: List[str] = field(default_factory=list)  # í˜¸í™˜ì„± ìœ ì§€
    model_size_gb: float = 0.0
    
    # conda/M3 Max ìµœì í™” (ê¸°ì¡´ ìœ ì§€)
    conda_optimized: bool = True
    m3_max_optimized: bool = True
    conda_env: Optional[str] = None
    memory_gb: float = 16.0
    
    # í™˜ê²½ ê°ì§€ í”Œë˜ê·¸ë“¤ (ì‹¤ì œ í™˜ê²½ ë°˜ì˜)
    is_m3_max_detected: bool = False
    github_compatible: bool = True
    mycloset_optimized: bool = False
    memory_optimization: bool = False
    conda_target_env: bool = False
    ultra_optimization: bool = False
    performance_mode: str = "balanced"
    memory_pool_enabled: bool = False
    mps_available: bool = False
    mps_optimization: bool = False
    metal_performance_shaders: bool = False
    unified_memory_pool: bool = False
    cuda_optimization: bool = False
    tensor_cores: bool = False
    use_unified_memory: bool = False
    emergency_mode: bool = False
    error_message: Optional[str] = None
    
    # ì‹¤ì œ AI ëª¨ë¸ ê²½ë¡œ ë° ì„¤ì •
    ai_model_paths: Dict[str, str] = field(default_factory=dict)
    alternative_path: Optional[str] = None
    real_ai_mode: bool = True
    basestepmixin_compatible: bool = True
    modelloader_required: bool = True
    disable_fallback: bool = True
    
    # DetailedDataSpec ì™„ì „ í†µí•©
    detailed_data_spec: DetailedDataSpecConfig = field(default_factory=DetailedDataSpecConfig)

    def __post_init__(self):
        """ì‹¤ì œ í™˜ê²½ ì´ˆê¸°í™” í›„ ì„¤ì • ë³´ì • + DetailedDataSpec ë¡œë”©"""
        # conda_env ìë™ ì„¤ì •
        if self.conda_env is None:
            self.conda_env = CONDA_INFO['conda_env']
        
        # memory_gb ìë™ ì„¤ì •
        if self.memory_gb <= 0:
            self.memory_gb = MEMORY_GB
        
        # ì‹¤ì œ AI ëª¨ë¸ ë¦¬ìŠ¤íŠ¸ ì •ê·œí™”
        if not isinstance(self.real_ai_models, list):
            self.real_ai_models = []
        if not isinstance(self.ai_models, list):
            self.ai_models = []
        
        # AI ëª¨ë¸ ê²½ë¡œ ë”•ì…”ë„ˆë¦¬ ì •ê·œí™”
        if not isinstance(self.ai_model_paths, dict):
            self.ai_model_paths = {}
        
        # M3 Max ê°ì§€ ë° ìë™ ì„¤ì • (ì‹¤ì œ í™˜ê²½)
        if IS_M3_MAX_DETECTED:
            self.is_m3_max_detected = True
            self.mps_available = MPS_AVAILABLE if REAL_STEP_INTERFACE_AVAILABLE else True
            self.metal_performance_shaders = True
            self.unified_memory_pool = True
            self.use_unified_memory = True
        
        # conda íƒ€ê²Ÿ í™˜ê²½ ê°ì§€
        if CONDA_INFO['is_target_env']:
            self.conda_target_env = True
            self.mycloset_optimized = True
            self.memory_optimization = True
        
        # GitHub ìš¸íŠ¸ë¼ ìµœì í™” ìë™ í™œì„±í™”
        if self.is_m3_max_detected and self.conda_target_env:
            self.ultra_optimization = True
            self.performance_mode = 'maximum'
            self.memory_pool_enabled = True
        
        # DetailedDataSpec ìë™ ë¡œë”©
        self._load_detailed_data_spec()
    
    def _load_detailed_data_spec(self):
        """step_model_requirements.pyì—ì„œ DetailedDataSpec ìë™ ë¡œë”© (ìˆ˜ì •ë¨)"""
        if not STEP_MODEL_REQUIREMENTS:
            logger.warning(f"âš ï¸ {self.step_name}: step_model_requirements.py ì—†ìŒ, ê¸°ë³¸ ì„¤ì • ì‚¬ìš©")
            return
        
        try:
            # Step ì´ë¦„ìœ¼ë¡œ enhanced step request ê°€ì ¸ì˜¤ê¸°
            enhanced_request = STEP_MODEL_REQUIREMENTS['get_enhanced_step_request'](self.step_name)
            if not enhanced_request:
                logger.warning(f"âš ï¸ {self.step_name}: step_model_requirementsì—ì„œ ì„¤ì • ì—†ìŒ")
                return
            
            # DetailedDataSpec ë°ì´í„° ë³µì‚¬ - ì•ˆì „í•œ ë³µì‚¬ ì‚¬ìš©
            data_spec = enhanced_request.data_spec
            
            self.detailed_data_spec.api_input_mapping = safe_copy(data_spec.api_input_mapping)
            self.detailed_data_spec.api_output_mapping = safe_copy(data_spec.api_output_mapping)
            self.detailed_data_spec.accepts_from_previous_step = safe_copy(data_spec.accepts_from_previous_step)
            self.detailed_data_spec.provides_to_next_step = safe_copy(data_spec.provides_to_next_step)
            self.detailed_data_spec.step_input_schema = safe_copy(data_spec.step_input_schema)
            self.detailed_data_spec.step_output_schema = safe_copy(data_spec.step_output_schema)
            
            self.detailed_data_spec.input_data_types = safe_copy(data_spec.input_data_types)
            self.detailed_data_spec.output_data_types = safe_copy(data_spec.output_data_types)
            self.detailed_data_spec.input_shapes = safe_copy(data_spec.input_shapes)
            self.detailed_data_spec.output_shapes = safe_copy(data_spec.output_shapes)
            self.detailed_data_spec.input_value_ranges = safe_copy(data_spec.input_value_ranges)
            self.detailed_data_spec.output_value_ranges = safe_copy(data_spec.output_value_ranges)
            
            self.detailed_data_spec.preprocessing_required = data_spec.preprocessing_required
            self.detailed_data_spec.postprocessing_required = data_spec.postprocessing_required
            self.detailed_data_spec.preprocessing_steps = safe_copy(data_spec.preprocessing_steps)
            self.detailed_data_spec.postprocessing_steps = safe_copy(data_spec.postprocessing_steps)
            self.detailed_data_spec.normalization_mean = safe_copy(data_spec.normalization_mean)  # âœ… í•µì‹¬ ìˆ˜ì •
            self.detailed_data_spec.normalization_std = safe_copy(data_spec.normalization_std)    # âœ… í•µì‹¬ ìˆ˜ì •
            
            logger.info(f"âœ… {self.step_name}: DetailedDataSpec ë¡œë”© ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"âŒ {self.step_name}: DetailedDataSpec ë¡œë”© ì‹¤íŒ¨ - {e}")

@dataclass
class RealGitHubStepCreationResult:
    """ì‹¤ì œ GitHub í”„ë¡œì íŠ¸ Step ìƒì„± ê²°ê³¼ + DetailedDataSpec í†µí•© (ì‹¤ì œ êµ¬ì¡° ë°˜ì˜)"""
    success: bool
    step_instance: Optional['BaseStepMixin'] = None
    step_name: str = ""
    step_type: Optional[StepType] = None
    class_name: str = ""
    module_path: str = ""
    creation_time: float = 0.0
    error_message: Optional[str] = None
    warnings: List[str] = field(default_factory=list)
    
    # ì‹¤ì œ ì˜ì¡´ì„± ì£¼ì… ê²°ê³¼
    dependencies_injected: Dict[str, bool] = field(default_factory=dict)
    initialization_success: bool = False
    real_ai_models_loaded: List[str] = field(default_factory=list)
    real_checkpoints_loaded: int = 0
    
    # GitHub BaseStepMixin v19.2 í˜¸í™˜ì„± ê²€ì¦
    github_compatible: bool = True
    basestepmixin_v19_compatible: bool = True
    process_method_validated: bool = False
    dependency_injection_success: bool = False
    
    # DetailedDataSpec í†µí•© ê²°ê³¼
    detailed_data_spec_loaded: bool = False
    api_mappings_applied: Dict[str, Any] = field(default_factory=dict)
    data_flow_configured: Dict[str, Any] = field(default_factory=dict)
    preprocessing_configured: bool = False
    postprocessing_configured: bool = False
    
    # ì‹¤ì œ êµ¬ì¡° ìƒíƒœ
    real_dependencies_only: bool = True
    real_dependency_manager: bool = True
    real_ai_processing_enabled: bool = True

# ==============================================
# ğŸ”¥ ì‹¤ì œ GitHub í”„ë¡œì íŠ¸ Step ë§¤í•‘ (229GB AI ëª¨ë¸ ê¸°ë°˜)
# ==============================================

class RealGitHubStepMapping:
    """ì‹¤ì œ GitHub í”„ë¡œì íŠ¸ Step ë§¤í•‘ + DetailedDataSpec ì™„ì „ í†µí•© (ì‹¤ì œ 229GB AI ëª¨ë¸ ê¸°ë°˜)"""
    
    REAL_GITHUB_STEP_CONFIGS = {
        StepType.HUMAN_PARSING: RealGitHubStepConfig(
            step_name="HumanParsingStep",
            step_id=1,
            step_type=StepType.HUMAN_PARSING,
            class_name="HumanParsingStep",
            module_path="app.ai_pipeline.steps.step_01_human_parsing",
            priority=StepPriority.CRITICAL,
            real_ai_models=[
                RealAIModelConfig(
                    model_name="graphonomy.pth",
                    model_path="step_01_human_parsing/graphonomy.pth",
                    model_type="SegmentationModel",
                    size_gb=1.2,
                    requires_checkpoint=True,
                    preprocessing_required=["resize_512x512", "normalize_imagenet", "to_tensor"],
                    postprocessing_required=["argmax", "resize_original", "morphology_clean"]
                ),
                RealAIModelConfig(
                    model_name="exp-schp-201908301523-atr.pth",
                    model_path="step_01_human_parsing/exp-schp-201908301523-atr.pth",
                    model_type="ATRModel",
                    size_gb=0.25,
                    requires_checkpoint=True
                )
            ],
            ai_models=["graphonomy", "atr_model", "human_parsing_schp"],
            model_size_gb=4.0,
            require_model_loader=True,
            require_memory_manager=True
        ),
        StepType.POSE_ESTIMATION: RealGitHubStepConfig(
            step_name="PoseEstimationStep",
            step_id=2,
            step_type=StepType.POSE_ESTIMATION,
            class_name="PoseEstimationStep",
            module_path="app.ai_pipeline.steps.step_02_pose_estimation",
            priority=StepPriority.NORMAL,
            real_ai_models=[
                RealAIModelConfig(
                    model_name="yolov8n-pose.pt",
                    model_path="step_02_pose_estimation/yolov8n-pose.pt",
                    model_type="PoseModel",
                    size_gb=6.2,
                    requires_checkpoint=True,
                    preprocessing_required=["resize_640x640", "normalize_yolo"],
                    postprocessing_required=["extract_keypoints", "scale_coords", "filter_confidence"]
                )
            ],
            ai_models=["openpose", "yolov8_pose", "diffusion_pose"],
            model_size_gb=3.4,
            require_model_loader=True,
            require_memory_manager=True
        ),
        StepType.CLOTH_SEGMENTATION: RealGitHubStepConfig(
            step_name="ClothSegmentationStep",
            step_id=3,
            step_type=StepType.CLOTH_SEGMENTATION,
            class_name="ClothSegmentationStep",
            module_path="app.ai_pipeline.steps.step_03_cloth_segmentation",
            priority=StepPriority.NORMAL,
            real_ai_models=[
                RealAIModelConfig(
                    model_name="sam_vit_h_4b8939.pth",
                    model_path="step_03_cloth_segmentation/sam_vit_h_4b8939.pth",
                    model_type="SAMModel",
                    size_gb=2.4,
                    requires_checkpoint=True,
                    preprocessing_required=["resize_1024x1024", "prepare_sam_prompts"],
                    postprocessing_required=["apply_mask", "morphology_clean"]
                ),
                RealAIModelConfig(
                    model_name="u2net.pth",
                    model_path="step_03_cloth_segmentation/u2net.pth",
                    model_type="U2NetModel",
                    size_gb=176.0,
                    requires_checkpoint=True
                )
            ],
            ai_models=["u2net", "sam_huge", "cloth_segmentation"],
            model_size_gb=5.5,
            require_model_loader=True,
            require_memory_manager=True
        ),
        StepType.GEOMETRIC_MATCHING: RealGitHubStepConfig(
            step_name="GeometricMatchingStep",
            step_id=4,
            step_type=StepType.GEOMETRIC_MATCHING,
            class_name="GeometricMatchingStep",
            module_path="app.ai_pipeline.steps.step_04_geometric_matching",
            priority=StepPriority.LOW,
            real_ai_models=[
                RealAIModelConfig(
                    model_name="gmm_final.pth",
                    model_path="step_04_geometric_matching/gmm_final.pth",
                    model_type="GMMModel",
                    size_gb=1.3,
                    requires_checkpoint=True
                )
            ],
            ai_models=["gmm", "tps_network", "geometric_matching"],
            model_size_gb=1.3,
            require_model_loader=True
        ),
        StepType.CLOTH_WARPING: RealGitHubStepConfig(
            step_name="ClothWarpingStep",
            step_id=5,
            step_type=StepType.CLOTH_WARPING,
            class_name="ClothWarpingStep",
            module_path="app.ai_pipeline.steps.step_05_cloth_warping",
            priority=StepPriority.HIGH,
            real_ai_models=[
                RealAIModelConfig(
                    model_name="RealVisXL_V4.0.safetensors",
                    model_path="step_05_cloth_warping/RealVisXL_V4.0.safetensors",
                    model_type="DiffusionModel",
                    size_gb=6.46,
                    requires_checkpoint=True,
                    preprocessing_required=["prepare_ootd_inputs", "normalize_diffusion"],
                    postprocessing_required=["denormalize_diffusion", "clip_0_1"]
                )
            ],
            ai_models=["cloth_warping", "stable_diffusion", "hrviton"],
            model_size_gb=7.0,
            require_model_loader=True,
            require_memory_manager=True
        ),
        StepType.VIRTUAL_FITTING: RealGitHubStepConfig(
            step_name="VirtualFittingStep",
            step_id=6,
            step_type=StepType.VIRTUAL_FITTING,
            class_name="VirtualFittingStep",
            module_path="app.ai_pipeline.steps.step_06_virtual_fitting",
            priority=StepPriority.CRITICAL,
            real_ai_models=[
                RealAIModelConfig(
                    model_name="diffusion_pytorch_model.fp16.safetensors",
                    model_path="step_06_virtual_fitting/unet/diffusion_pytorch_model.fp16.safetensors",
                    model_type="UNetModel",
                    size_gb=4.8,
                    requires_checkpoint=True
                ),
                RealAIModelConfig(
                    model_name="v1-5-pruned-emaonly.safetensors",
                    model_path="step_06_virtual_fitting/v1-5-pruned-emaonly.safetensors",
                    model_type="DiffusionModel",
                    size_gb=4.0,
                    requires_checkpoint=True,
                    preprocessing_required=["prepare_diffusion_input", "normalize_diffusion"],
                    postprocessing_required=["denormalize_diffusion", "final_compositing"]
                )
            ],
            ai_models=["ootdiffusion", "hr_viton", "virtual_fitting"],
            model_size_gb=14.0,
            require_model_loader=True,
            require_memory_manager=True,
            require_data_converter=True
        ),
        StepType.POST_PROCESSING: RealGitHubStepConfig(
            step_name="PostProcessingStep",
            step_id=7,
            step_type=StepType.POST_PROCESSING,
            class_name="PostProcessingStep",
            module_path="app.ai_pipeline.steps.step_07_post_processing",
            priority=StepPriority.LOW,
            real_ai_models=[
                RealAIModelConfig(
                    model_name="Real-ESRGAN_x4plus.pth",
                    model_path="step_07_post_processing/Real-ESRGAN_x4plus.pth",
                    model_type="SRModel",
                    size_gb=64.0,
                    requires_checkpoint=True,
                    preprocessing_required=["prepare_sr_input"],
                    postprocessing_required=["enhance_details", "clip_values"]
                )
            ],
            ai_models=["super_resolution", "realesrgan", "enhancement"],
            model_size_gb=1.3,
            require_model_loader=True
        ),
        StepType.QUALITY_ASSESSMENT: RealGitHubStepConfig(
            step_name="QualityAssessmentStep",
            step_id=8,
            step_type=StepType.QUALITY_ASSESSMENT,
            class_name="QualityAssessmentStep",
            module_path="app.ai_pipeline.steps.step_08_quality_assessment",
            priority=StepPriority.HIGH,
            real_ai_models=[
                RealAIModelConfig(
                    model_name="ViT-L-14.pt",
                    model_path="step_08_quality_assessment/ViT-L-14.pt",
                    model_type="CLIPModel",
                    size_gb=890.0 / 1024,  # 890MB
                    requires_checkpoint=True,
                    preprocessing_required=["resize_224x224", "normalize_clip"],
                    postprocessing_required=["generate_quality_report"]
                )
            ],
            ai_models=["clip", "quality_assessment", "perceptual_loss"],
            model_size_gb=7.0,
            require_model_loader=True,
            require_data_converter=True
        )
    }
    
    @classmethod
    def get_enhanced_github_config(cls, step_type: StepType, **overrides) -> RealGitHubStepConfig:
        """ì‹¤ì œ GitHub í”„ë¡œì íŠ¸ í˜¸í™˜ ì„¤ì • ë°˜í™˜ + DetailedDataSpec ìë™ ë¡œë”©"""
        base_config = cls.REAL_GITHUB_STEP_CONFIGS[step_type]
        
        # kwargsì— conda_envê°€ ì—†ìœ¼ë©´ ìë™ ì¶”ê°€
        if 'conda_env' not in overrides:
            overrides['conda_env'] = os.environ.get('CONDA_DEFAULT_ENV', 'none')
        
        # í‚¤ì›Œë“œ ì¶©ëŒ ë°©ì§€ í•„í„°ë§ - ìˆ˜ì •ëœ ë¶€ë¶„
        filtered_overrides = {}
        config_fields = set(base_config.__dataclass_fields__.keys())  # ğŸ”¥ ì´ ë¼ì¸ì´ ìˆ˜ì •ë¨
        
        for key, value in overrides.items():
            if key in config_fields:
                filtered_overrides[key] = value
            else:
                logger.debug(f"âš ï¸ ë¬´ì‹œëœ í‚¤ì›Œë“œ: {key} (RealGitHubStepConfigì— ì—†ìŒ)")
        
        # ì»¤ìŠ¤í…€ ì„¤ì •ì´ ìˆìœ¼ë©´ ì ìš©
        if filtered_overrides:
            # ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜í•˜ì—¬ ì˜¤ë²„ë¼ì´ë“œ ì ìš©
            config_dict = {
                'step_name': base_config.step_name,
                'step_id': base_config.step_id,
                'step_type': base_config.step_type,
                'class_name': base_config.class_name,
                'module_path': base_config.module_path,
                'priority': base_config.priority,
                'device': base_config.device,
                'use_fp16': base_config.use_fp16,
                'batch_size': base_config.batch_size,
                'confidence_threshold': base_config.confidence_threshold,
                'auto_memory_cleanup': base_config.auto_memory_cleanup,
                'auto_warmup': base_config.auto_warmup,
                'optimization_enabled': base_config.optimization_enabled,
                'strict_mode': base_config.strict_mode,
                'quality_level': base_config.quality_level,
                'auto_inject_dependencies': base_config.auto_inject_dependencies,
                'require_model_loader': base_config.require_model_loader,
                'require_memory_manager': base_config.require_memory_manager,
                'require_data_converter': base_config.require_data_converter,
                'require_di_container': base_config.require_di_container,
                'require_unified_dependency_manager': base_config.require_unified_dependency_manager,
                'dependency_timeout': base_config.dependency_timeout,
                'dependency_retry_count': base_config.dependency_retry_count,
                'real_ai_models': base_config.real_ai_models.copy(),
                'ai_models': base_config.ai_models.copy(),
                'model_size_gb': base_config.model_size_gb,
                'conda_optimized': base_config.conda_optimized,
                'm3_max_optimized': base_config.m3_max_optimized,
                'conda_env': base_config.conda_env,
                'memory_gb': base_config.memory_gb
            }
            # filtered_overridesë¥¼ ì ìš©
            config_dict.update(filtered_overrides)
            return RealGitHubStepConfig(**config_dict)
        
        return base_config
# ==============================================
# ğŸ”¥ ì‹¤ì œ ì˜ì¡´ì„± í•´ê²°ê¸° (ìˆœí™˜ì°¸ì¡° í•´ê²°)
# ==============================================

class RealGitHubDependencyResolver:
    """ì‹¤ì œ ì˜ì¡´ì„± í•´ê²°ê¸° - DetailedDataSpec ì™„ì „ í™œìš© + ì‹¤ì œ êµ¬ì¡° (ìˆœí™˜ì°¸ì¡° í•´ê²°)"""
    
    def __init__(self):
        self.logger = logging.getLogger(f"{__name__}.RealGitHubDependencyResolver")
        self._resolved_cache: Dict[str, Any] = {}
        self._lock = threading.RLock()
        self._resolution_attempts: Dict[str, int] = {}
        self._max_attempts = 3
    

    def _resolve_real_github_di_container(self):
        """ì‹¤ì œ DI Container í•´ê²° (ì§€ì—° importë¡œ ìˆœí™˜ì°¸ì¡° ë°©ì§€)"""
        try:
            with self._lock:
                cache_key = "real_github_di_container"
                if cache_key in self._resolved_cache:
                    return self._resolved_cache[cache_key]
                
                # ğŸ”¥ ì§€ì—° importë¡œ ìˆœí™˜ì°¸ì¡° ë°©ì§€
                try:
                    import importlib
                    module = importlib.import_module('app.core.di_container')
                    if hasattr(module, 'get_global_container'):
                        di_container = module.get_global_container()
                        if di_container:
                            self._resolved_cache[cache_key] = di_container
                            self.logger.info("âœ… ì‹¤ì œ GitHub DIContainer í•´ê²° ì™„ë£Œ")
                            return di_container
                            
                except ImportError:
                    try:
                        module = importlib.import_module('app.core.di_container', package=__name__)
                        if hasattr(module, 'get_global_container'):
                            di_container = module.get_global_container()
                            if di_container:
                                self._resolved_cache[cache_key] = di_container
                                self.logger.info("âœ… ì‹¤ì œ GitHub DIContainer í•´ê²° ì™„ë£Œ (ìƒëŒ€ ê²½ë¡œ)")
                                return di_container
                    except ImportError:
                        return None
                        
        except Exception as e:
            self.logger.debug(f"ì‹¤ì œ GitHub DIContainer í•´ê²° ì‹¤íŒ¨: {e}")
            return None
        
    def resolve_enhanced_github_dependencies_for_constructor(self, config: RealGitHubStepConfig) -> Dict[str, Any]:
        """ì‹¤ì œ GitHub ì˜ì¡´ì„± í•´ê²° (ìƒì„±ììš©) - DetailedDataSpec ì™„ì „ í™œìš© + ìˆœí™˜ì°¸ì¡° í•´ê²°"""
        try:
            self.logger.info(f"ğŸ”„ {config.step_name} ì‹¤ì œ DetailedDataSpec í†µí•© ì˜ì¡´ì„± í•´ê²° ì‹œì‘...")
            
            # ê¸°ë³¸ dependency ë”•ì…”ë„ˆë¦¬
            dependencies = {}
            
            # 1. GitHub BaseStepMixin v19.2 í‘œì¤€ ì„¤ì •ë“¤
            dependencies.update({
                'step_name': config.step_name,
                'step_id': config.step_id,
                'device': self._resolve_github_device(config.device),
                'use_fp16': config.use_fp16,
                'batch_size': config.batch_size,
                'confidence_threshold': config.confidence_threshold,
                'auto_memory_cleanup': config.auto_memory_cleanup,
                'auto_warmup': config.auto_warmup,
                'optimization_enabled': config.optimization_enabled,
                'strict_mode': config.strict_mode,
                'github_compatibility_mode': config.github_compatible
            })
            
            # 2. conda í™˜ê²½ ì„¤ì •
            if config.conda_optimized:
                conda_env = getattr(config, 'conda_env', None) or CONDA_INFO['conda_env']
                
                dependencies.update({
                    'conda_optimized': True,
                    'conda_env': conda_env
                })
                
                # mycloset-ai-clean í™˜ê²½ íŠ¹ë³„ ìµœì í™”
                if conda_env == 'mycloset-ai-clean' or CONDA_INFO['is_target_env']:
                    dependencies.update({
                        'mycloset_optimized': True,
                        'memory_optimization': True,
                        'conda_target_env': True
                    })
                    self.logger.info(f"âœ… {config.step_name} mycloset-ai-clean í™˜ê²½ ìµœì í™” ì ìš©")
            
            # 3. M3 Max í•˜ë“œì›¨ì–´ ìµœì í™” (ì‹¤ì œ í™˜ê²½)
            if config.m3_max_optimized and IS_M3_MAX_DETECTED:
                dependencies.update({
                    'm3_max_optimized': True,
                    'memory_gb': MEMORY_GB,
                    'use_unified_memory': True,
                    'is_m3_max_detected': True,
                    'mps_available': MPS_AVAILABLE if dependencies.get('device') == 'mps' else False
                })
                self.logger.info(f"âœ… {config.step_name} M3 Max ìµœì í™” ì ìš© ({MEMORY_GB}GB)")
            
            # 4. ì‹¤ì œ GitHub ì˜ì¡´ì„± ì»´í¬ë„ŒíŠ¸ë“¤ ì•ˆì „í•œ í•´ê²° (ìˆœí™˜ì°¸ì¡° ë°©ì§€)
            self._inject_real_github_component_dependencies(config, dependencies)
            
            # 5. ì‹¤ì œ AI ëª¨ë¸ ì„¤ì • ë° ê²½ë¡œ ë§¤í•‘
            dependencies.update({
                'real_ai_models': config.real_ai_models.copy() if hasattr(config.real_ai_models, 'copy') else list(config.real_ai_models),
                'ai_models': config.ai_models.copy() if hasattr(config.ai_models, 'copy') else list(config.ai_models),
                'model_size_gb': config.model_size_gb,
                'real_ai_mode': config.real_ai_mode,
                'requires_checkpoint_loading': any(model.requires_checkpoint for model in config.real_ai_models)
            })
            
            # 6. DetailedDataSpec ì™„ì „ í†µí•©
            self._inject_detailed_data_spec_dependencies(config, dependencies)
            
            # 7. GitHub í™˜ê²½ë³„ ì„±ëŠ¥ ìµœì í™” ì„¤ì •
            self._apply_github_performance_optimizations(dependencies)
            
            # 8. ê²°ê³¼ ê²€ì¦ ë° ë¡œê¹…
            resolved_count = len([k for k, v in dependencies.items() if v is not None])
            total_items = len(dependencies)
            
            self.logger.info(f"âœ… {config.step_name} ì‹¤ì œ DetailedDataSpec í†µí•© ì˜ì¡´ì„± í•´ê²° ì™„ë£Œ:")
            self.logger.info(f"   - ì´ í•­ëª©: {total_items}ê°œ")
            self.logger.info(f"   - í•´ê²°ëœ í•­ëª©: {resolved_count}ê°œ")
            self.logger.info(f"   - conda í™˜ê²½: {dependencies.get('conda_env', 'none')}")
            self.logger.info(f"   - ë””ë°”ì´ìŠ¤: {dependencies.get('device', 'unknown')}")
            self.logger.info(f"   - ì‹¤ì œ AI ëª¨ë¸: {len(config.real_ai_models)}ê°œ")
            
            # GitHub í•„ìˆ˜ ì˜ì¡´ì„± ê²€ì¦ (strict_modeì¼ ë•Œ)
            if config.strict_mode:
                self._validate_github_critical_dependencies(dependencies)
            
            return dependencies
            
        except Exception as e:
            self.logger.error(f"âŒ {config.step_name} ì‹¤ì œ DetailedDataSpec í†µí•© ì˜ì¡´ì„± í•´ê²° ì‹¤íŒ¨: {e}")
            
            # ì‘ê¸‰ ëª¨ë“œ: ìµœì†Œí•œì˜ ì˜ì¡´ì„±ë§Œ ë°˜í™˜
            if not config.strict_mode:
                return self._create_github_emergency_dependencies(config, str(e))
            else:
                raise
   
    def _inject_detailed_data_spec_dependencies(self, config: RealGitHubStepConfig, dependencies: Dict[str, Any]):
        """DetailedDataSpec ì˜ì¡´ì„± ì£¼ì… (ìˆ˜ì •ë¨ - tuple copy ì˜¤ë¥˜ í•´ê²°)"""
        try:
            self.logger.info(f"ğŸ”„ {config.step_name} DetailedDataSpec ì˜ì¡´ì„± ì£¼ì… ì¤‘...")
            
            data_spec = None
            
            # 1. configì—ì„œ ê°€ì ¸ì˜¤ê¸° ì‹œë„
            if hasattr(config, 'detailed_data_spec') and config.detailed_data_spec:
                data_spec = config.detailed_data_spec
                self.logger.info(f"âœ… {config.step_name} configì—ì„œ DetailedDataSpec ë¡œë“œ")
            
            # 2. step_model_requirements.pyì—ì„œ ê°€ì ¸ì˜¤ê¸° ì‹œë„
            if not data_spec and STEP_MODEL_REQUIREMENTS:
                try:
                    step_request = STEP_MODEL_REQUIREMENTS['get_enhanced_step_request'](config.step_name)
                    if step_request and hasattr(step_request, 'data_spec'):
                        data_spec = step_request.data_spec
                        self.logger.info(f"âœ… {config.step_name} step_model_requirements.pyì—ì„œ DetailedDataSpec ë¡œë“œ")
                except Exception as e:
                    self.logger.warning(f"âš ï¸ {config.step_name} step_model_requirements.py ë¡œë“œ ì‹¤íŒ¨: {e}")
            
            # 3. í´ë°±: í•˜ë“œì½”ë”©ëœ DetailedDataSpec
            if not data_spec:
                data_spec = self._get_fallback_detailed_data_spec(config.step_name)
                if data_spec:
                    self.logger.info(f"âœ… {config.step_name} í´ë°± DetailedDataSpec ì ìš©")
            
            # DetailedDataSpecì´ ìˆìœ¼ë©´ ì£¼ì…
            if data_spec:
                # API ë§¤í•‘ ì£¼ì… (FastAPI â†” Step í´ë˜ìŠ¤) - ì•ˆì „í•œ ë³µì‚¬ ì‚¬ìš©
                api_input_mapping = getattr(data_spec, 'api_input_mapping', {})
                api_output_mapping = getattr(data_spec, 'api_output_mapping', {})
                
                dependencies.update({
                    'api_input_mapping': safe_copy(api_input_mapping),
                    'api_output_mapping': safe_copy(api_output_mapping),
                    'fastapi_compatible': len(api_input_mapping) > 0
                })
                
                # Step ê°„ ë°ì´í„° íë¦„ ì£¼ì… - ì•ˆì „í•œ ë³µì‚¬ ì‚¬ìš©
                accepts_from_previous_step = getattr(data_spec, 'accepts_from_previous_step', {})
                provides_to_next_step = getattr(data_spec, 'provides_to_next_step', {})
                
                dependencies.update({
                    'accepts_from_previous_step': safe_copy(accepts_from_previous_step),
                    'provides_to_next_step': safe_copy(provides_to_next_step),
                    'step_input_schema': getattr(data_spec, 'step_input_schema', {}),
                    'step_output_schema': getattr(data_spec, 'step_output_schema', {}),
                    'step_data_flow': {
                        'accepts_from': list(accepts_from_previous_step.keys()) if accepts_from_previous_step else [],
                        'provides_to': list(provides_to_next_step.keys()) if provides_to_next_step else [],
                        'is_pipeline_start': len(accepts_from_previous_step) == 0,
                        'is_pipeline_end': len(provides_to_next_step) == 0
                    }
                })
                
                # ì…ì¶œë ¥ ë°ì´í„° ì‚¬ì–‘ ì£¼ì… - ì•ˆì „í•œ ë³µì‚¬ ì‚¬ìš©
                input_data_types = getattr(data_spec, 'input_data_types', [])
                output_data_types = getattr(data_spec, 'output_data_types', [])
                
                dependencies.update({
                    'input_data_types': safe_copy(input_data_types),
                    'output_data_types': safe_copy(output_data_types),
                    'input_shapes': getattr(data_spec, 'input_shapes', {}),
                    'output_shapes': getattr(data_spec, 'output_shapes', {}),
                    'input_value_ranges': getattr(data_spec, 'input_value_ranges', {}),
                    'output_value_ranges': getattr(data_spec, 'output_value_ranges', {}),
                    'data_validation_enabled': True
                })
                
                # ì „ì²˜ë¦¬/í›„ì²˜ë¦¬ ì„¤ì • ì£¼ì… - ì•ˆì „í•œ ë³µì‚¬ ì‚¬ìš© (í•µì‹¬ ìˆ˜ì •)
                preprocessing_steps = getattr(data_spec, 'preprocessing_steps', [])
                postprocessing_steps = getattr(data_spec, 'postprocessing_steps', [])
                normalization_mean = getattr(data_spec, 'normalization_mean', (0.485, 0.456, 0.406))
                normalization_std = getattr(data_spec, 'normalization_std', (0.229, 0.224, 0.225))
                
                dependencies.update({
                    'preprocessing_required': getattr(data_spec, 'preprocessing_required', []),
                    'postprocessing_required': getattr(data_spec, 'postprocessing_required', []),
                    'preprocessing_steps': safe_copy(preprocessing_steps),
                    'postprocessing_steps': safe_copy(postprocessing_steps),
                    'normalization_mean': safe_copy(normalization_mean),  # âœ… í•µì‹¬ ìˆ˜ì •
                    'normalization_std': safe_copy(normalization_std),    # âœ… í•µì‹¬ ìˆ˜ì •
                    'preprocessing_config': {
                        'steps': preprocessing_steps,
                        'normalization': {
                            'mean': normalization_mean,
                            'std': normalization_std
                        },
                        'value_ranges': getattr(data_spec, 'input_value_ranges', {})
                    },
                    'postprocessing_config': {
                        'steps': postprocessing_steps,
                        'value_ranges': getattr(data_spec, 'output_value_ranges', {}),
                        'output_shapes': getattr(data_spec, 'output_shapes', {})
                    }
                })
                
                # DetailedDataSpec ë©”íƒ€ì •ë³´
                dependencies.update({
                    'detailed_data_spec_loaded': True,
                    'detailed_data_spec_version': 'v11.1',
                    'step_model_requirements_integrated': STEP_MODEL_REQUIREMENTS is not None,
                    'real_ai_structure_integrated': True
                })
                
                self.logger.info(f"âœ… {config.step_name} DetailedDataSpec ì˜ì¡´ì„± ì£¼ì… ì™„ë£Œ")
                
            else:
                # ìµœì•…ì˜ ê²½ìš° ìµœì†Œí•œì˜ ë¹ˆ ì„¤ì •ì´ë¼ë„ ì œê³µ
                self.logger.warning(f"âš ï¸ {config.step_name} DetailedDataSpecì„ ë¡œë“œí•  ìˆ˜ ì—†ìŒ, ìµœì†Œ ì„¤ì • ì ìš©")
                dependencies.update({
                    'api_input_mapping': {},
                    'api_output_mapping': {},
                    'preprocessing_steps': [],
                    'postprocessing_steps': [],
                    'accepts_from_previous_step': {},
                    'provides_to_next_step': {},
                    'detailed_data_spec_loaded': False,
                    'detailed_data_spec_error': 'No DetailedDataSpec found',
                    'real_ai_structure_integrated': True
                })
                
        except Exception as e:
            self.logger.error(f"âŒ {config.step_name} DetailedDataSpec ì˜ì¡´ì„± ì£¼ì… ì‹¤íŒ¨: {e}")
            # ì‹¤íŒ¨í•´ë„ ê¸°ë³¸ ì„¤ì •ìœ¼ë¡œ ì§„í–‰
            dependencies.update({
                'api_input_mapping': {},
                'api_output_mapping': {},
                'preprocessing_steps': [],
                'postprocessing_steps': [],
                'accepts_from_previous_step': {},
                'provides_to_next_step': {},
                'detailed_data_spec_loaded': False,
                'detailed_data_spec_error': str(e),
                'real_ai_structure_integrated': True
            })


    def _get_fallback_detailed_data_spec(self, step_name: str):
        """í´ë°± DetailedDataSpec ì œê³µ (ì‹¤ì œ êµ¬ì¡° ê¸°ë°˜)"""
        
        if step_name == "VirtualFittingStep":
            class VirtualFittingDataSpec:
                def __init__(self):
                    # API ë§¤í•‘
                    self.api_input_mapping = {
                        'person_image': 'UploadFile',
                        'clothing_image': 'UploadFile',
                        'fabric_type': 'Optional[str]',
                        'clothing_type': 'Optional[str]'
                    }
                    self.api_output_mapping = {
                        'fitted_image': 'base64_string',
                        'confidence': 'float',
                        'quality_metrics': 'Dict[str, float]'
                    }
                    
                    # ì…ì¶œë ¥ ì‚¬ì–‘
                    self.input_data_types = ['PIL.Image', 'PIL.Image', 'Optional[str]', 'Optional[str]']
                    self.output_data_types = ['np.ndarray', 'float', 'Dict[str, float]']
                    self.input_shapes = {'person_image': (768, 1024, 3), 'clothing_image': (768, 1024, 3)}
                    self.output_shapes = {'fitted_image': (768, 1024, 3)}
                    self.input_value_ranges = {'person_image': (0.0, 255.0), 'clothing_image': (0.0, 255.0)}
                    self.output_value_ranges = {'fitted_image': (0.0, 255.0), 'confidence': (0.0, 1.0)}
                    
                    # ì „ì²˜ë¦¬/í›„ì²˜ë¦¬
                    self.preprocessing_steps = ['resize_768x1024', 'normalize_diffusion', 'to_tensor', 'prepare_ootd_inputs']
                    self.postprocessing_steps = ['denormalize_diffusion', 'clip_0_1', 'to_numpy', 'final_compositing']
                    self.normalization_mean = (0.5, 0.5, 0.5)
                    self.normalization_std = (0.5, 0.5, 0.5)
                    
                    # Step ê°„ ë°ì´í„° íë¦„
                    self.accepts_from_previous_step = {
                        'step_3': {'parsing_mask': 'np.ndarray'},
                        'step_4': {'pose_keypoints': 'List[Tuple[float, float]]'},
                        'step_5': {'warped_clothing': 'np.ndarray'}
                    }
                    self.provides_to_next_step = {
                        'step_7': {
                            'fitted_image': 'np.ndarray',
                            'confidence': 'float',
                            'processing_metadata': 'Dict[str, Any]'
                        }
                    }
                    
                    # ê¸°íƒ€ í•„ìˆ˜ ì†ì„±ë“¤
                    self.preprocessing_required = ['resize_768x1024', 'normalize_diffusion', 'to_tensor']
                    self.postprocessing_required = ['denormalize_diffusion', 'clip_0_1', 'to_numpy']
                    self.step_input_schema = self.accepts_from_previous_step
                    self.step_output_schema = self.provides_to_next_step
            
            return VirtualFittingDataSpec()
        
        # ë‹¤ë¥¸ Stepë“¤ë„ ìµœì†Œí•œì˜ API ë§¤í•‘ ì œê³µ
        else:
            class BasicDataSpec:
                def __init__(self):
                    self.api_input_mapping = {'input_image': 'UploadFile'}
                    self.api_output_mapping = {'result': 'base64_string'}
                    self.preprocessing_steps = []
                    self.postprocessing_steps = []
                    self.accepts_from_previous_step = {}
                    self.provides_to_next_step = {}
                    self.input_data_types = []
                    self.output_data_types = []
            
            return BasicDataSpec()

    def _inject_real_github_component_dependencies(self, config: RealGitHubStepConfig, dependencies: Dict[str, Any]):
        """ì‹¤ì œ GitHub í”„ë¡œì íŠ¸ ì»´í¬ë„ŒíŠ¸ ì˜ì¡´ì„± ì£¼ì… (ìˆœí™˜ì°¸ì¡° í•´ê²°)"""
        # ModelLoader ì˜ì¡´ì„± (ì§€ì—° import)
        if config.require_model_loader:
            try:
                model_loader = self._resolve_real_github_model_loader()
                dependencies['model_loader'] = model_loader
                if model_loader:
                    self.logger.info(f"âœ… {config.step_name} ì‹¤ì œ GitHub ModelLoader ìƒì„±ì ì£¼ì… ì¤€ë¹„")
                else:
                    self.logger.warning(f"âš ï¸ {config.step_name} ì‹¤ì œ GitHub ModelLoader í•´ê²° ì‹¤íŒ¨")
            except Exception as e:
                self.logger.error(f"âŒ {config.step_name} ì‹¤ì œ GitHub ModelLoader í•´ê²° ì¤‘ ì˜¤ë¥˜: {e}")
                dependencies['model_loader'] = None
        
        # MemoryManager ì˜ì¡´ì„± (ì§€ì—° import)
        if config.require_memory_manager:
            try:
                memory_manager = self._resolve_real_github_memory_manager()
                dependencies['memory_manager'] = memory_manager
                if memory_manager:
                    self.logger.info(f"âœ… {config.step_name} ì‹¤ì œ GitHub MemoryManager ìƒì„±ì ì£¼ì… ì¤€ë¹„")
            except Exception as e:
                self.logger.error(f"âŒ {config.step_name} ì‹¤ì œ GitHub MemoryManager í•´ê²° ì¤‘ ì˜¤ë¥˜: {e}")
                dependencies['memory_manager'] = None
        
        # DataConverter ì˜ì¡´ì„± (ì§€ì—° import)
        if config.require_data_converter:
            try:
                data_converter = self._resolve_real_github_data_converter()
                dependencies['data_converter'] = data_converter
                if data_converter:
                    self.logger.info(f"âœ… {config.step_name} ì‹¤ì œ GitHub DataConverter ìƒì„±ì ì£¼ì… ì¤€ë¹„")
            except Exception as e:
                self.logger.error(f"âŒ {config.step_name} ì‹¤ì œ GitHub DataConverter í•´ê²° ì¤‘ ì˜¤ë¥˜: {e}")
                dependencies['data_converter'] = None
        
        # DIContainer ì˜ì¡´ì„± (ì§€ì—° import)
        if config.require_di_container:
            try:
                di_container = self._resolve_real_github_di_container()
                dependencies['di_container'] = di_container
                if di_container:
                    self.logger.info(f"âœ… {config.step_name} ì‹¤ì œ GitHub DIContainer ìƒì„±ì ì£¼ì… ì¤€ë¹„")
            except Exception as e:
                self.logger.error(f"âŒ {config.step_name} ì‹¤ì œ GitHub DIContainer í•´ê²° ì¤‘ ì˜¤ë¥˜: {e}")
                dependencies['di_container'] = None

    def _resolve_real_github_model_loader(self):
        """ì‹¤ì œ ModelLoader í•´ê²° (ì§€ì—° importë¡œ ìˆœí™˜ì°¸ì¡° ë°©ì§€)"""
        try:
            with self._lock:
                cache_key = "real_github_model_loader"
                if cache_key in self._resolved_cache:
                    return self._resolved_cache[cache_key]
                
                attempts = self._resolution_attempts.get(cache_key, 0)
                if attempts >= self._max_attempts:
                    self.logger.warning(f"ì‹¤ì œ GitHub ModelLoader í•´ê²° ì‹œë„ í•œê³„ ì´ˆê³¼: {attempts}")
                    return None
                
                self._resolution_attempts[cache_key] = attempts + 1
                
                # ğŸ”¥ step_interface.py v5.2ê°€ ì‚¬ìš© ê°€ëŠ¥í•˜ë©´ ìš°ì„  ì‚¬ìš©
                if REAL_STEP_INTERFACE_AVAILABLE:
                    try:
                        # step_interface.py v5.2ì—ì„œ ì‹¤ì œ ModelLoader ê°€ì ¸ì˜¤ê¸°
                        real_interface = create_real_step_interface("ModelLoaderStep")
                        if real_interface and hasattr(real_interface, 'model_loader'):
                            model_loader = real_interface.model_loader
                            if model_loader:
                                self._resolved_cache[cache_key] = model_loader
                                self.logger.info("âœ… step_interface.py v5.2ì—ì„œ ì‹¤ì œ ModelLoader í•´ê²° ì™„ë£Œ")
                                return model_loader
                    except Exception as e:
                        self.logger.debug(f"step_interface.py v5.2 ModelLoader í•´ê²° ì‹¤íŒ¨: {e}")
                
                # ğŸ”¥ ì§€ì—° importë¡œ ìˆœí™˜ì°¸ì¡° ë°©ì§€
                try:
                    import importlib
                    module = importlib.import_module('app.ai_pipeline.utils.model_loader')
                    if hasattr(module, 'get_global_model_loader'):
                        model_loader = module.get_global_model_loader()
                        
                        if model_loader:
                            # ì‹¤ì œ GitHub í”„ë¡œì íŠ¸ íŠ¹ë³„ ì„¤ì •
                            if CONDA_INFO['is_target_env'] and hasattr(model_loader, 'configure_github'):
                                github_config = {
                                    'conda_optimized': True,
                                    'conda_env': CONDA_INFO['conda_env'],
                                    'm3_max_optimized': IS_M3_MAX_DETECTED,
                                    'memory_gb': MEMORY_GB,
                                    'github_mode': True,
                                    'real_ai_pipeline': True,
                                    'detailed_data_spec_support': True,
                                    'real_checkpoint_loading': True
                                }
                                model_loader.configure_github(github_config)
                            
                            self._resolved_cache[cache_key] = model_loader
                            self.logger.info("âœ… ì‹¤ì œ GitHub ModelLoader í•´ê²° ì™„ë£Œ")
                            return model_loader
                    
                except ImportError:
                    try:
                        module = importlib.import_module('..utils.model_loader', package=__name__)
                        if hasattr(module, 'get_global_model_loader'):
                            model_loader = module.get_global_model_loader()
                            if model_loader:
                                self._resolved_cache[cache_key] = model_loader
                                self.logger.info("âœ… ì‹¤ì œ GitHub ModelLoader í•´ê²° ì™„ë£Œ (ìƒëŒ€ ê²½ë¡œ)")
                                return model_loader
                    except ImportError:
                        self.logger.debug("ì‹¤ì œ GitHub ModelLoader import ì‹¤íŒ¨")
                        return None
                    
        except Exception as e:
            self.logger.error(f"âŒ ì‹¤ì œ GitHub ModelLoader í•´ê²° ì‹¤íŒ¨: {e}")
            return None

    def _resolve_real_github_memory_manager(self):
        """ì‹¤ì œ MemoryManager í•´ê²° (ì§€ì—° importë¡œ ìˆœí™˜ì°¸ì¡° ë°©ì§€)"""
        try:
            with self._lock:
                cache_key = "real_github_memory_manager"
                if cache_key in self._resolved_cache:
                    return self._resolved_cache[cache_key]
                
                # ğŸ”¥ step_interface.py v5.2ê°€ ì‚¬ìš© ê°€ëŠ¥í•˜ë©´ ìš°ì„  ì‚¬ìš©
                if REAL_STEP_INTERFACE_AVAILABLE:
                    try:
                        # RealMemoryManager ì§ì ‘ ì‚¬ìš©
                        memory_manager = RealMemoryManager()
                        if memory_manager:
                            self._resolved_cache[cache_key] = memory_manager
                            self.logger.info("âœ… step_interface.py v5.2ì—ì„œ RealMemoryManager í•´ê²° ì™„ë£Œ")
                            return memory_manager
                    except Exception as e:
                        self.logger.debug(f"step_interface.py v5.2 MemoryManager í•´ê²° ì‹¤íŒ¨: {e}")
                
                # ğŸ”¥ ì§€ì—° importë¡œ ìˆœí™˜ì°¸ì¡° ë°©ì§€
                try:
                    import importlib
                    module = importlib.import_module('app.ai_pipeline.utils.memory_manager')
                    if hasattr(module, 'get_global_memory_manager'):
                        memory_manager = module.get_global_memory_manager()
                        
                        if memory_manager:
                            # GitHub M3 Max íŠ¹ë³„ ì„¤ì •
                            if IS_M3_MAX_DETECTED and hasattr(memory_manager, 'configure_github_m3_max'):
                                memory_manager.configure_github_m3_max(memory_gb=MEMORY_GB)
                            
                            self._resolved_cache[cache_key] = memory_manager
                            self.logger.info("âœ… ì‹¤ì œ GitHub MemoryManager í•´ê²° ì™„ë£Œ")
                            return memory_manager
                            
                except ImportError:
                    try:
                        module = importlib.import_module('..utils.memory_manager', package=__name__)
                        if hasattr(module, 'get_global_memory_manager'):
                            memory_manager = module.get_global_memory_manager()
                            if memory_manager:
                                self._resolved_cache[cache_key] = memory_manager
                                self.logger.info("âœ… ì‹¤ì œ GitHub MemoryManager í•´ê²° ì™„ë£Œ (ìƒëŒ€ ê²½ë¡œ)")
                                return memory_manager
                    except ImportError:
                        return None
                    
        except Exception as e:
            self.logger.debug(f"ì‹¤ì œ GitHub MemoryManager í•´ê²° ì‹¤íŒ¨: {e}")
            return None

    def _resolve_real_github_data_converter(self):
        """ì‹¤ì œ DataConverter í•´ê²° (ì§€ì—° importë¡œ ìˆœí™˜ì°¸ì¡° ë°©ì§€)"""
        try:
            with self._lock:
                cache_key = "real_github_data_converter"
                if cache_key in self._resolved_cache:
                    return self._resolved_cache[cache_key]
                
                # ğŸ”¥ ì§€ì—° importë¡œ ìˆœí™˜ì°¸ì¡° ë°©ì§€
                try:
                    import importlib
                    module = importlib.import_module('app.ai_pipeline.utils.data_converter')
                    if hasattr(module, 'get_global_data_converter'):
                        data_converter = module.get_global_data_converter()
                        if data_converter:
                            self._resolved_cache[cache_key] = data_converter
                            self.logger.info("âœ… ì‹¤ì œ GitHub DataConverter í•´ê²° ì™„ë£Œ")
                            return data_converter
                            
                except ImportError:
                    try:
                        module = importlib.import_module('..utils.data_converter', package=__name__)
                        if hasattr(module, 'get_global_data_converter'):
                            data_converter = module.get_global_data_converter()
                            if data_converter:
                                self._resolved_cache[cache_key] = data_converter
                                self.logger.info("âœ… ì‹¤ì œ GitHub DataConverter í•´ê²° ì™„ë£Œ (ìƒëŒ€ ê²½ë¡œ)")
                                return data_converter
                    except ImportError:
                        return None
                    
        except Exception as e:
            self.logger.debug(f"ì‹¤ì œ GitHub DataConverter í•´ê²° ì‹¤íŒ¨: {e}")
            return None

    def _resolve_real_github_di_container(self):
        """ì‹¤ì œ DI Container í•´ê²° (ì§€ì—° importë¡œ ìˆœí™˜ì°¸ì¡° ë°©ì§€)"""
        try:
            with self._lock:
                cache_key = "real_github_di_container"
                if cache_key in self._resolved_cache:
                    return self._resolved_cache[cache_key]
                
                # ğŸ”¥ ì§€ì—° importë¡œ ìˆœí™˜ì°¸ì¡° ë°©ì§€
                try:
                    import importlib
                    module = importlib.import_module('app.core.di_container')
                    if hasattr(module, 'get_global_di_container'):
                        di_container = module.get_global_di_container()
                        if di_container:
                            self._resolved_cache[cache_key] = di_container
                            self.logger.info("âœ… ì‹¤ì œ GitHub DIContainer í•´ê²° ì™„ë£Œ")
                            return di_container
                            
                except ImportError:
                    try:
                        module = importlib.import_module('app.core.di_container', package=__name__)
                        if hasattr(module, 'get_global_di_container'):
                            di_container = module.get_global_di_container()
                            if di_container:
                                self._resolved_cache[cache_key] = di_container
                                self.logger.info("âœ… ì‹¤ì œ GitHub DIContainer í•´ê²° ì™„ë£Œ (ìƒëŒ€ ê²½ë¡œ)")
                                return di_container
                    except ImportError:
                        return None
                    
        except Exception as e:
            self.logger.debug(f"ì‹¤ì œ GitHub DIContainer í•´ê²° ì‹¤íŒ¨: {e}")
            return None

    def _apply_github_performance_optimizations(self, dependencies: Dict[str, Any]):
        """ì‹¤ì œ GitHub í”„ë¡œì íŠ¸ ì„±ëŠ¥ ìµœì í™” ì„¤ì • ì ìš©"""
        # conda + M3 Max ì¡°í•© ìµœì í™” (ì‹¤ì œ í™˜ê²½)
        if (dependencies.get('conda_target_env') and dependencies.get('is_m3_max_detected')):
            dependencies.update({
                'ultra_optimization': True,
                'performance_mode': 'maximum',
                'memory_pool_enabled': True,
                'real_ai_optimized': True
            })
            
        # ë””ë°”ì´ìŠ¤ë³„ ìµœì í™” (ì‹¤ì œ í™˜ê²½)
        device = dependencies.get('device', 'cpu')
        if device == 'mps' and dependencies.get('is_m3_max_detected'):
            dependencies.update({
                'mps_optimization': True,
                'metal_performance_shaders': True,
                'unified_memory_pool': True,
                'real_mps_acceleration': True
            })
        elif device == 'cuda':
            dependencies.update({
                'cuda_optimization': True,
                'tensor_cores': True,
                'real_cuda_acceleration': True
            })

    def _validate_github_critical_dependencies(self, dependencies: Dict[str, Any]):
        """ì‹¤ì œ GitHub í•„ìˆ˜ ì˜ì¡´ì„± ê²€ì¦ + DetailedDataSpec ê²€ì¦"""
        critical_deps = ['step_name', 'step_id', 'device']
        missing_critical = [dep for dep in critical_deps if not dependencies.get(dep)]
        if missing_critical:
            raise RuntimeError(f"ì‹¤ì œ GitHub Strict Mode: í•„ìˆ˜ ì˜ì¡´ì„± ëˆ„ë½ - {missing_critical}")
        
        # DetailedDataSpec í•„ìˆ˜ ìš”ì†Œ ê²€ì¦
        if dependencies.get('detailed_data_spec_loaded'):
            required_data_spec_items = ['api_input_mapping', 'api_output_mapping']
            missing_data_spec = [item for item in required_data_spec_items if not dependencies.get(item)]
            if missing_data_spec and dependencies.get('fastapi_compatible'):
                raise RuntimeError(f"ì‹¤ì œ GitHub Strict Mode: DetailedDataSpec í•„ìˆ˜ í•­ëª© ëˆ„ë½ - {missing_data_spec}")

    def _create_github_emergency_dependencies(self, config: RealGitHubStepConfig, error_msg: str) -> Dict[str, Any]:
        """ì‹¤ì œ GitHub ì‘ê¸‰ ëª¨ë“œ ìµœì†Œ ì˜ì¡´ì„± + DetailedDataSpec ê¸°ë³¸ê°’"""
        self.logger.warning(f"âš ï¸ {config.step_name} ì‹¤ì œ GitHub ì‘ê¸‰ ëª¨ë“œë¡œ ìµœì†Œ ì˜ì¡´ì„± ë°˜í™˜")
        return {
            'step_name': config.step_name,
            'step_id': config.step_id,
            'device': 'cpu',
            'conda_env': getattr(config, 'conda_env', CONDA_INFO['conda_env']),
            'github_compatibility_mode': True,
            'emergency_mode': True,
            'error_message': error_msg,
            'real_ai_structure_integrated': True,
            # DetailedDataSpec ê¸°ë³¸ê°’
            'api_input_mapping': {},
            'api_output_mapping': {},
            'step_data_flow': {'accepts_from': [], 'provides_to': []},
            'preprocessing_required': False,
            'postprocessing_required': False,
            'detailed_data_spec_loaded': False
        }

    def _resolve_github_device(self, device: str) -> str:
        """ì‹¤ì œ GitHub í”„ë¡œì íŠ¸ ë””ë°”ì´ìŠ¤ í•´ê²°"""
        if device != "auto":
            return device
        
        if IS_M3_MAX_DETECTED and MPS_AVAILABLE:
            return "mps"
        
        try:
            if PYTORCH_AVAILABLE:
                import torch
                if torch.cuda.is_available():
                    return "cuda"
                elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
                    return "mps"
        except ImportError:
            pass
        
        return "cpu"

    def clear_cache(self):
        """ìºì‹œ ì •ë¦¬"""
        with self._lock:
            self._resolved_cache.clear()
            self._resolution_attempts.clear()
            gc.collect()

# ==============================================
# ğŸ”¥ ì‹¤ì œ GitHub í˜¸í™˜ ë™ì  Step í´ë˜ìŠ¤ ë¡œë” (ìˆœí™˜ì°¸ì¡° í•´ê²°)
# ==============================================

class RealGitHubStepClassLoader:
    """ì‹¤ì œ GitHub í”„ë¡œì íŠ¸ í˜¸í™˜ ë™ì  Step í´ë˜ìŠ¤ ë¡œë” + DetailedDataSpec ì§€ì› (ìˆœí™˜ì°¸ì¡° í•´ê²°)"""
    
    def __init__(self):
        self.logger = logging.getLogger(f"{__name__}.RealGitHubStepClassLoader")
        self._loaded_classes: Dict[str, Type] = {}
        self._import_attempts: Dict[str, int] = {}
        self._lock = threading.RLock()
        self._max_attempts = 5
    
    def load_enhanced_github_step_class(self, config: RealGitHubStepConfig) -> Optional[Type]:
        """ì‹¤ì œ GitHub í”„ë¡œì íŠ¸ í˜¸í™˜ Step í´ë˜ìŠ¤ ë¡œë”© + DetailedDataSpec ê²€ì¦ (ìˆœí™˜ì°¸ì¡° í•´ê²°)"""
        try:
            with self._lock:
                cache_key = config.class_name
                if cache_key in self._loaded_classes:
                    return self._loaded_classes[cache_key]
                
                attempts = self._import_attempts.get(cache_key, 0)
                if attempts >= self._max_attempts:
                    self.logger.error(f"âŒ {config.class_name} ì‹¤ì œ GitHub import ì¬ì‹œë„ í•œê³„ ì´ˆê³¼")
                    return None
                
                self._import_attempts[cache_key] = attempts + 1
                
                self.logger.info(f"ğŸ”„ {config.class_name} ì‹¤ì œ GitHub ë™ì  ë¡œë”© ì‹œì‘ (ì‹œë„ {attempts + 1}/{self._max_attempts})...")
                
                step_class = self._dynamic_import_real_github_step_class(config)
                
                if step_class:
                    if self._validate_real_github_step_compatibility(step_class, config):
                        self._loaded_classes[cache_key] = step_class
                        self.logger.info(f"âœ… {config.class_name} ì‹¤ì œ GitHub ë™ì  ë¡œë”© ì„±ê³µ (BaseStepMixin v19.2 + DetailedDataSpec í˜¸í™˜)")
                        return step_class
                    else:
                        self.logger.error(f"âŒ {config.class_name} ì‹¤ì œ GitHub BaseStepMixin v19.2 + DetailedDataSpec í˜¸í™˜ì„± ê²€ì¦ ì‹¤íŒ¨")
                        return None
                else:
                    self.logger.error(f"âŒ {config.class_name} ì‹¤ì œ GitHub ë™ì  import ì‹¤íŒ¨")
                    return None
                    
        except Exception as e:
            self.logger.error(f"âŒ {config.class_name} ì‹¤ì œ GitHub ë™ì  ë¡œë”© ì˜ˆì™¸: {e}")
            return None
    
    def _dynamic_import_real_github_step_class(self, config: RealGitHubStepConfig) -> Optional[Type]:
        """ì‹¤ì œ GitHub í”„ë¡œì íŠ¸ ë™ì  import ì‹¤í–‰ (ìˆœí™˜ì°¸ì¡° í•´ê²°)"""
        import importlib
        
        base_module = config.module_path
        
        # ì‹¤ì œ GitHub í”„ë¡œì íŠ¸ import ê²½ë¡œë“¤
        real_github_import_paths = [
            base_module,
            f"app.ai_pipeline.steps.{config.module_path.split('.')[-1]}",
            f"ai_pipeline.steps.{config.module_path.split('.')[-1]}",
            f"backend.{base_module}",
            f"..steps.{config.module_path.split('.')[-1]}",
            f"backend.app.ai_pipeline.steps.{config.module_path.split('.')[-1]}",
            f"app.ai_pipeline.steps.step_{config.step_id:02d}_{config.step_type.value}",
            f"steps.{config.class_name.lower()}"
        ]
        
        for import_path in real_github_import_paths:
            try:
                self.logger.debug(f"ğŸ” {config.class_name} ì‹¤ì œ GitHub import ì‹œë„: {import_path}")
                
                # ğŸ”¥ ì§€ì—° importë¡œ ìˆœí™˜ì°¸ì¡° ë°©ì§€
                module = importlib.import_module(import_path)
                
                if hasattr(module, config.class_name):
                    step_class = getattr(module, config.class_name)
                    self.logger.info(f"âœ… {config.class_name} ì‹¤ì œ GitHub ë™ì  import ì„±ê³µ: {import_path}")
                    return step_class
                else:
                    self.logger.debug(f"âš ï¸ {import_path}ì— {config.class_name} í´ë˜ìŠ¤ ì—†ìŒ")
                    continue
                    
            except ImportError as e:
                self.logger.debug(f"âš ï¸ {import_path} ì‹¤ì œ GitHub import ì‹¤íŒ¨: {e}")
                continue
            except Exception as e:
                self.logger.warning(f"âš ï¸ {import_path} ì‹¤ì œ GitHub import ì˜ˆì™¸: {e}")
                continue
        
        self.logger.error(f"âŒ {config.class_name} ëª¨ë“  ì‹¤ì œ GitHub ê²½ë¡œì—ì„œ import ì‹¤íŒ¨")
        return None
    
    def _validate_real_github_step_compatibility(self, step_class: Type, config: RealGitHubStepConfig) -> bool:
        """ì‹¤ì œ GitHub BaseStepMixin v19.2 + DetailedDataSpec í˜¸í™˜ì„± ê²€ì¦"""
        try:
            if not step_class or step_class.__name__ != config.class_name:
                return False
            
            mro_names = [cls.__name__ for cls in step_class.__mro__]
            if 'BaseStepMixin' not in mro_names:
                self.logger.warning(f"âš ï¸ {config.class_name}ì´ BaseStepMixinì„ ìƒì†í•˜ì§€ ì•ŠìŒ")
            
            # ì‹¤ì œ GitHub í”„ë¡œì íŠ¸ í•„ìˆ˜ ë©”ì„œë“œë“¤
            required_methods = ['process', 'initialize']
            missing_methods = []
            for method in required_methods:
                if not hasattr(step_class, method):
                    missing_methods.append(method)
            
            if missing_methods:
                self.logger.error(f"âŒ {config.class_name}ì— ì‹¤ì œ GitHub í•„ìˆ˜ ë©”ì„œë“œ ì—†ìŒ: {missing_methods}")
                return False
            
            # ì‹¤ì œ GitHub ìƒì„±ì í˜¸ì¶œ í…ŒìŠ¤íŠ¸ (BaseStepMixin v19.2 + DetailedDataSpec í‘œì¤€ kwargs)
            try:
                test_kwargs = {
                    'step_name': 'real_github_test',
                    'step_id': config.step_id,
                    'device': 'cpu',
                    'github_compatibility_mode': True,
                    'detailed_data_spec_loaded': True,
                    'real_ai_structure_integrated': True
                }
                test_instance = step_class(**test_kwargs)
                if test_instance:
                    self.logger.debug(f"âœ… {config.class_name} ì‹¤ì œ GitHub BaseStepMixin v19.2 + DetailedDataSpec ìƒì„±ì í…ŒìŠ¤íŠ¸ ì„±ê³µ")
                    if hasattr(test_instance, 'cleanup'):
                        try:
                            if asyncio.iscoroutinefunction(test_instance.cleanup):
                                pass
                            else:
                                test_instance.cleanup()
                        except:
                            pass
                    del test_instance
                    return True
            except Exception as e:
                self.logger.warning(f"âš ï¸ {config.class_name} ì‹¤ì œ GitHub ìƒì„±ì í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
                try:
                    test_instance = step_class()
                    if test_instance:
                        self.logger.debug(f"âœ… {config.class_name} ì‹¤ì œ GitHub ê¸°ë³¸ ìƒì„±ì í…ŒìŠ¤íŠ¸ ì„±ê³µ")
                        del test_instance
                        return True
                except Exception:
                    pass
                return True
            
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ {config.class_name} ì‹¤ì œ GitHub BaseStepMixin v19.2 + DetailedDataSpec í˜¸í™˜ì„± ê²€ì¦ ì‹¤íŒ¨: {e}")
            return False

# ==============================================
# ğŸ”¥ ë©”ì¸ StepFactory v11.1 (ì‹¤ì œ êµ¬ì¡° + ëª¨ë“  ê¸°ëŠ¥ ìœ ì§€)
# ==============================================

class StepFactory:
    """
    ğŸ”¥ StepFactory v11.1 - ì‹¤ì œ AI êµ¬ì¡° ì™„ì „ ë°˜ì˜ + ìˆœí™˜ì°¸ì¡° í•´ê²° + ëª¨ë“  ê¸°ëŠ¥ í¬í•¨
    
    âœ… ëª¨ë“  í•¨ìˆ˜ëª…, ë©”ì„œë“œëª…, í´ë˜ìŠ¤ëª… 100% ìœ ì§€
    âœ… step_interface.py v5.2ì˜ ì‹¤ì œ AI ëª¨ë¸ êµ¬ì¡° ì™„ì „ ë°˜ì˜
    âœ… RealAIModelConfig ì‹¤ì œ 229GB íŒŒì¼ ë§¤í•‘ ì ìš©
    âœ… Real í´ë˜ìŠ¤ êµ¬ì¡° í†µí•© (RealGitHub*)
    âœ… ì‹¤ì œ ì²´í¬í¬ì¸íŠ¸ ë¡œë”© ê¸°ëŠ¥ êµ¬í˜„
    âœ… TYPE_CHECKING + ì§€ì—° importë¡œ ìˆœí™˜ì°¸ì¡° ì™„ì „ í•´ê²°
    âœ… step_model_requirements.pyì˜ DetailedDataSpec ì™„ì „ í™œìš©
    âœ… API ì…ì¶œë ¥ ë§¤í•‘ ìë™ ì²˜ë¦¬
    âœ… Step ê°„ ë°ì´í„° íë¦„ ê´€ë¦¬
    âœ… ì „ì²˜ë¦¬/í›„ì²˜ë¦¬ ìš”êµ¬ì‚¬í•­ ìë™ ì ìš©
    âœ… BaseStepMixin v19.2 í‘œì¤€ ì™„ì „ í˜¸í™˜
    âœ… ìƒì„±ì ì‹œì  ì˜ì¡´ì„± ì£¼ì…
    âœ… conda í™˜ê²½ ìš°ì„  ìµœì í™”
    âœ… register_step, unregister_step, is_step_registered, get_registered_steps ë©”ì„œë“œ ì™„ì „ êµ¬í˜„
    âœ… FastAPI ë¼ìš°í„° 100% í˜¸í™˜ì„± í™•ë³´
    """
    
    def __init__(self):
        self.logger = logging.getLogger("StepFactory.v11.1")
        
        # ì‹¤ì œ GitHub BaseStepMixin v19.2 + DetailedDataSpec í˜¸í™˜ ì»´í¬ë„ŒíŠ¸ë“¤
        self.class_loader = RealGitHubStepClassLoader()
        self.dependency_resolver = RealGitHubDependencyResolver()
        
        # ğŸ”¥ ìˆœí™˜ì°¸ì¡° ë°©ì§€ë¥¼ ìœ„í•œ ì†ì„±ë“¤ (ëˆ„ë½ëœ ë¶€ë¶„ ì¶”ê°€)
        self._resolving_stack: List[str] = []
        self._circular_detected: set = set()
        
        # ì‹¤ì œ GitHub ë“±ë¡ëœ Step í´ë˜ìŠ¤ë“¤ ê´€ë¦¬
        self._registered_steps: Dict[str, Type['BaseStepMixin']] = {}
        self._step_type_mapping: Dict[str, StepType] = {}
        
        # ìºì‹œ ê´€ë¦¬
        self._step_cache: Dict[str, weakref.ref] = {}
        self._lock = threading.RLock()
        
        # ì‹¤ì œ GitHub í†µê³„ + DetailedDataSpec í†µê³„
        self._stats = {
            'total_created': 0,
            'successful_creations': 0,
            'failed_creations': 0,
            'cache_hits': 0,
            'github_compatible_creations': 0,
            'dependency_injection_successes': 0,
            'detailed_data_spec_successes': 0,
            'api_mapping_successes': 0,
            'data_flow_successes': 0,
            'real_checkpoints_loaded': 0,
            'real_ai_models_loaded': 0,
            'conda_optimized': CONDA_INFO['is_target_env'],
            'm3_max_optimized': IS_M3_MAX_DETECTED,
            'registered_steps': 0,
            'step_model_requirements_available': STEP_MODEL_REQUIREMENTS is not None,
            'real_step_interface_available': REAL_STEP_INTERFACE_AVAILABLE,
            'circular_references_prevented': 0  # ğŸ”¥ ìˆœí™˜ì°¸ì¡° í†µê³„ ì¶”ê°€
        }
        
        self.logger.info("ğŸ­ StepFactory v11.1 ì´ˆê¸°í™” ì™„ë£Œ (ì‹¤ì œ AI êµ¬ì¡° ì™„ì „ ë°˜ì˜ + ìˆœí™˜ì°¸ì¡° ì™„ì „ í•´ê²° + DetailedDataSpec ì™„ì „ í†µí•© + BaseStepMixin v19.2)")

    # ==============================================
    # ğŸ”¥ ì‹¤ì œ GitHub Step ë“±ë¡ ê´€ë¦¬ ë©”ì„œë“œë“¤ (ê¸°ì¡´ ìœ ì§€)
    # ==============================================
    
    def register_step(self, step_id: str, step_class: Type['BaseStepMixin']) -> bool:
        """ì‹¤ì œ GitHub Step í´ë˜ìŠ¤ë¥¼ íŒ©í† ë¦¬ì— ë“±ë¡"""
        try:
            with self._lock:
                self.logger.info(f"ğŸ“ {step_id} ì‹¤ì œ GitHub Step í´ë˜ìŠ¤ ë“±ë¡ ì‹œì‘...")
                
                if not step_id or not step_class:
                    self.logger.error(f"âŒ ì˜ëª»ëœ ì¸ì: step_id={step_id}, step_class={step_class}")
                    return False
                
                if not self._validate_real_github_step_class(step_class, step_id):
                    return False
                
                step_type = self._extract_step_type_from_id(step_id)
                
                self._registered_steps[step_id] = step_class
                if step_type:
                    self._step_type_mapping[step_id] = step_type
                
                class_name = step_class.__name__
                module_name = step_class.__module__
                
                self.logger.info(f"âœ… {step_id} ì‹¤ì œ GitHub Step í´ë˜ìŠ¤ ë“±ë¡ ì™„ë£Œ")
                self.logger.info(f"   - í´ë˜ìŠ¤: {class_name}")
                self.logger.info(f"   - ëª¨ë“ˆ: {module_name}")
                self.logger.info(f"   - StepType: {step_type.value if step_type else 'Unknown'}")
                
                self._stats['registered_steps'] = len(self._registered_steps)
                return True
                
        except Exception as e:
            self.logger.error(f"âŒ {step_id} ì‹¤ì œ GitHub Step ë“±ë¡ ì‹¤íŒ¨: {e}")
            return False
    
    def _validate_real_github_step_class(self, step_class: Type['BaseStepMixin'], step_id: str) -> bool:
        """ì‹¤ì œ GitHub Step í´ë˜ìŠ¤ ê¸°ë³¸ ê²€ì¦"""
        try:
            if not isinstance(step_class, type):
                self.logger.error(f"âŒ {step_id}: step_classê°€ í´ë˜ìŠ¤ íƒ€ì…ì´ ì•„ë‹™ë‹ˆë‹¤")
                return False
            
            required_methods = ['process']
            missing_methods = []
            
            for method_name in required_methods:
                if not hasattr(step_class, method_name):
                    missing_methods.append(method_name)
            
            if missing_methods:
                self.logger.error(f"âŒ {step_id}: ì‹¤ì œ GitHub í•„ìˆ˜ ë©”ì„œë“œ ì—†ìŒ - {missing_methods}")
                return False
            
            mro_names = [cls.__name__ for cls in step_class.__mro__]
            if 'BaseStepMixin' not in mro_names:
                self.logger.warning(f"âš ï¸ {step_id}: BaseStepMixinì„ ìƒì†í•˜ì§€ ì•ŠìŒ (ê³„ì† ì§„í–‰)")
            
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ {step_id} ì‹¤ì œ GitHub í´ë˜ìŠ¤ ê²€ì¦ ì‹¤íŒ¨: {e}")
            return False
    
    def _extract_step_type_from_id(self, step_id: str) -> Optional[StepType]:
        """Step IDì—ì„œ StepType ì¶”ì¶œ"""
        try:
            step_mapping = {
                'step_01': StepType.HUMAN_PARSING,
                'step_02': StepType.POSE_ESTIMATION,
                'step_03': StepType.CLOTH_SEGMENTATION,
                'step_04': StepType.GEOMETRIC_MATCHING,
                'step_05': StepType.CLOTH_WARPING,
                'step_06': StepType.VIRTUAL_FITTING,
                'step_07': StepType.POST_PROCESSING,
                'step_08': StepType.QUALITY_ASSESSMENT
            }
            
            return step_mapping.get(step_id.lower())
            
        except Exception as e:
            self.logger.debug(f"StepType ì¶”ì¶œ ì‹¤íŒ¨ ({step_id}): {e}")
            return None
    
    def unregister_step(self, step_id: str) -> bool:
        """ì‹¤ì œ GitHub Step ë“±ë¡ í•´ì œ"""
        try:
            with self._lock:
                if step_id in self._registered_steps:
                    del self._registered_steps[step_id]
                    self._step_type_mapping.pop(step_id, None)
                    
                    cache_keys_to_remove = [
                        key for key in self._step_cache.keys() 
                        if step_id in key
                    ]
                    for cache_key in cache_keys_to_remove:
                        del self._step_cache[cache_key]
                    
                    self.logger.info(f"âœ… {step_id} ì‹¤ì œ GitHub Step ë“±ë¡ í•´ì œ ì™„ë£Œ")
                    self._stats['registered_steps'] = len(self._registered_steps)
                    return True
                else:
                    self.logger.warning(f"âš ï¸ {step_id} ì‹¤ì œ GitHub Stepì´ ë“±ë¡ë˜ì–´ ìˆì§€ ì•ŠìŒ")
                    return False
                    
        except Exception as e:
            self.logger.error(f"âŒ {step_id} ì‹¤ì œ GitHub Step ë“±ë¡ í•´ì œ ì‹¤íŒ¨: {e}")
            return False
    
    def is_step_registered(self, step_id: str) -> bool:
        """ì‹¤ì œ GitHub Step ë“±ë¡ ì—¬ë¶€ í™•ì¸"""
        with self._lock:
            return step_id in self._registered_steps
    
    def get_registered_steps(self) -> Dict[str, str]:
        """ì‹¤ì œ GitHub ë“±ë¡ëœ Step ëª©ë¡ ë°˜í™˜ (step_id -> class_name)"""
        with self._lock:
            return {
                step_id: step_class.__name__ 
                for step_id, step_class in self._registered_steps.items()
            }
    
    def get_registered_step_class(self, step_id: str) -> Optional[Type['BaseStepMixin']]:
        """ì‹¤ì œ GitHub ë“±ë¡ëœ Step í´ë˜ìŠ¤ ë°˜í™˜"""
        with self._lock:
            return self._registered_steps.get(step_id)

    # ==============================================
    # ğŸ”¥ ì‹¤ì œ GitHub Step ìƒì„± ë©”ì„œë“œë“¤ (ê¸°ì¡´ ìœ ì§€, ìˆœí™˜ì°¸ì¡° í•´ê²°)
    # ==============================================

    def create_step(
        self,
        step_type: Union[StepType, str],
        use_cache: bool = True,
        **kwargs
    ) -> RealGitHubStepCreationResult:
        """ì‹¤ì œ GitHub Step ìƒì„± ë©”ì¸ ë©”ì„œë“œ + DetailedDataSpec ì™„ì „ í†µí•©"""
        start_time = time.time()
        
        try:
            # ìˆœí™˜ì°¸ì¡° ê°ì§€
            step_key = str(step_type)
            if step_key in self._resolving_stack:
                circular_path = ' -> '.join(self._resolving_stack + [step_key])
                self._stats['circular_references_prevented'] += 1
                self.logger.error(f"âŒ ìˆœí™˜ì°¸ì¡° ê°ì§€: {circular_path}")
                return RealGitHubStepCreationResult(
                    success=False,
                    error_message=f"ìˆœí™˜ì°¸ì¡° ê°ì§€: {circular_path}",
                    creation_time=time.time() - start_time
                )
            
            self._resolving_stack.append(step_key)
            
            try:
                # ê¸°ì¡´ Step ìƒì„± ë¡œì§...
                return self._create_step_internal(step_type, use_cache, **kwargs)
            finally:
                if step_key in self._resolving_stack:  # ğŸ”¥ ì•ˆì „ ì²´í¬ ì¶”ê°€
                    self._resolving_stack.remove(step_key)
                
        except Exception as e:
            with self._lock:
                self._stats['failed_creations'] += 1
            
            self.logger.error(f"âŒ ì‹¤ì œ GitHub Step ìƒì„± ì‹¤íŒ¨: {e}")
            return RealGitHubStepCreationResult(
                success=False,
                error_message=f"ì‹¤ì œ GitHub Step ìƒì„± ì˜ˆì™¸: {str(e)}",
                creation_time=time.time() - start_time
            )

    def _create_step_internal(
        self,
        step_type: Union[StepType, str],
        use_cache: bool = True,
        **kwargs
    ) -> RealGitHubStepCreationResult:
        """ë‚´ë¶€ Step ìƒì„± ë¡œì§ (ìˆœí™˜ì°¸ì¡° í•´ê²°ë¨)"""
        try:
            # StepType ì •ê·œí™”
            if isinstance(step_type, str):
                try:
                    step_type = StepType(step_type.lower())
                except ValueError:
                    return RealGitHubStepCreationResult(
                        success=False,
                        error_message=f"ì˜ëª»ëœ StepType: {step_type}"
                    )
            
            # Step ID í™•ì¸í•˜ì—¬ ë“±ë¡ëœ í´ë˜ìŠ¤ ìš°ì„  ì‚¬ìš©
            step_id = self._get_step_id_from_type(step_type)
            if step_id and self.is_step_registered(step_id):
                self.logger.info(f"ğŸ¯ {step_type.value} ë“±ë¡ëœ í´ë˜ìŠ¤ ì‚¬ìš©")
                return self._create_step_from_registered(step_id, use_cache, **kwargs)
            
            # ì¼ë°˜ì ì¸ Step ìƒì„±
            self.logger.info(f"ğŸ¯ {step_type.value} ë™ì  ë¡œë”©ìœ¼ë¡œ ìƒì„±")
            return self._create_step_legacy_way(step_type, use_cache, **kwargs)
            
        except Exception as e:
            self.logger.error(f"âŒ _create_step_internal ì‹¤íŒ¨: {e}")
            return RealGitHubStepCreationResult(
                success=False,
                error_message=f"ë‚´ë¶€ Step ìƒì„± ì‹¤íŒ¨: {str(e)}"
            )
    
    def _get_step_id_from_type(self, step_type: StepType) -> Optional[str]:
        """StepTypeì—ì„œ step_id ì°¾ê¸°"""
        type_to_id_mapping = {
            StepType.HUMAN_PARSING: 'step_01',
            StepType.POSE_ESTIMATION: 'step_02',
            StepType.CLOTH_SEGMENTATION: 'step_03',
            StepType.GEOMETRIC_MATCHING: 'step_04',
            StepType.CLOTH_WARPING: 'step_05',
            StepType.VIRTUAL_FITTING: 'step_06',
            StepType.POST_PROCESSING: 'step_07',
            StepType.QUALITY_ASSESSMENT: 'step_08'
        }
        return type_to_id_mapping.get(step_type)
    
    def _create_step_from_registered(
        self, 
        step_id: str, 
        use_cache: bool = True, 
        **kwargs
    ) -> RealGitHubStepCreationResult:
        """ì‹¤ì œ GitHub ë“±ë¡ëœ Step í´ë˜ìŠ¤ë¡œë¶€í„° ì¸ìŠ¤í„´ìŠ¤ ìƒì„± + DetailedDataSpec í†µí•©"""
        start_time = time.time()
        
        try:
            step_class = self.get_registered_step_class(step_id)
            if not step_class:
                return RealGitHubStepCreationResult(
                    success=False,
                    error_message=f"ì‹¤ì œ GitHub ë“±ë¡ëœ {step_id} Step í´ë˜ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ",
                    creation_time=time.time() - start_time
                )
            
            self.logger.info(f"ğŸ”„ {step_id} ì‹¤ì œ GitHub ë“±ë¡ëœ í´ë˜ìŠ¤ë¡œ ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ì¤‘...")
            
            # ìºì‹œ í™•ì¸
            if use_cache:
                cached_step = self._get_cached_step(step_id)
                if cached_step:
                    with self._lock:
                        self._stats['cache_hits'] += 1
                    self.logger.info(f"â™»ï¸ {step_id} ì‹¤ì œ GitHub ìºì‹œì—ì„œ ë°˜í™˜")
                    return RealGitHubStepCreationResult(
                        success=True,
                        step_instance=cached_step,
                        step_name=step_class.__name__,
                        class_name=step_class.__name__,
                        module_path=step_class.__module__,
                        creation_time=time.time() - start_time,
                        github_compatible=True,
                        basestepmixin_v19_compatible=True,
                        detailed_data_spec_loaded=True,
                        real_dependencies_only=True
                    )
            
            # StepType ì¶”ì¶œ
            step_type = self._step_type_mapping.get(step_id)
            if not step_type:
                step_type = self._extract_step_type_from_id(step_id)
            
            # ì‹¤ì œ GitHub BaseStepMixin v19.2 + DetailedDataSpec í˜¸í™˜ ì„¤ì • ìƒì„±
            if step_type:
                config = RealGitHubStepMapping.get_enhanced_github_config(step_type, **kwargs)
            else:
                # ê¸°ë³¸ ì„¤ì • ìƒì„±
                config = self._create_default_real_github_config(step_id, step_class, **kwargs)
            
            # ì‹¤ì œ GitHub ì˜ì¡´ì„± í•´ê²° ë° ì¸ìŠ¤í„´ìŠ¤ ìƒì„± + DetailedDataSpec í†µí•©
            constructor_dependencies = self.dependency_resolver.resolve_enhanced_github_dependencies_for_constructor(config)
            
            # ì‹¤ì œ GitHub Step ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
            self.logger.info(f"ğŸ”„ {step_id} ì‹¤ì œ GitHub ë“±ë¡ëœ í´ë˜ìŠ¤ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±...")
            step_instance = step_class(**constructor_dependencies)
            self.logger.info(f"âœ… {step_id} ì‹¤ì œ GitHub ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ì™„ë£Œ (ë“±ë¡ëœ í´ë˜ìŠ¤ + DetailedDataSpec)")
            
            # ì‹¤ì œ GitHub ì´ˆê¸°í™” ì‹¤í–‰
            initialization_success = self._initialize_real_github_step(step_instance, config)
            
            # DetailedDataSpec í›„ì²˜ë¦¬ ì„¤ì •
            detailed_data_spec_result = self._apply_detailed_data_spec_post_processing(step_instance, config)
            
            # ì‹¤ì œ ì²´í¬í¬ì¸íŠ¸ ë¡œë”© í™•ì¸
            real_checkpoints_loaded = self._check_real_checkpoint_loading(step_instance, config)
            
            # ìºì‹œì— ì €ì¥
            if use_cache:
                self._cache_step(step_id, step_instance)
            
            # í†µê³„ ì—…ë°ì´íŠ¸
            with self._lock:
                self._stats['total_created'] += 1
                self._stats['successful_creations'] += 1
                self._stats['github_compatible_creations'] += 1
                self._stats['dependency_injection_successes'] += 1
                self._stats['real_checkpoints_loaded'] += real_checkpoints_loaded
                if detailed_data_spec_result['success']:
                    self._stats['detailed_data_spec_successes'] += 1
                    self._stats['api_mapping_successes'] += 1
                    self._stats['data_flow_successes'] += 1
            
            return RealGitHubStepCreationResult(
                success=True,
                step_instance=step_instance,
                step_name=config.step_name,
                step_type=step_type,
                class_name=config.class_name,
                module_path=config.module_path,
                creation_time=time.time() - start_time,
                dependencies_injected={'constructor_injection': True},
                initialization_success=initialization_success,
                real_checkpoints_loaded=real_checkpoints_loaded,
                github_compatible=True,
                basestepmixin_v19_compatible=True,
                dependency_injection_success=True,
                detailed_data_spec_loaded=detailed_data_spec_result['success'],
                api_mappings_applied=detailed_data_spec_result.get('api_mappings', {}),
                data_flow_configured=detailed_data_spec_result.get('data_flow', {}),
                preprocessing_configured=detailed_data_spec_result.get('preprocessing_configured', False),
                postprocessing_configured=detailed_data_spec_result.get('postprocessing_configured', False),
                real_dependencies_only=True,
                real_dependency_manager=True,
                real_ai_processing_enabled=True
            )
            
        except Exception as e:
            with self._lock:
                self._stats['failed_creations'] += 1
            
            self.logger.error(f"âŒ {step_id} ì‹¤ì œ GitHub ë“±ë¡ëœ í´ë˜ìŠ¤ ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ì‹¤íŒ¨: {e}")
            return RealGitHubStepCreationResult(
                success=False,
                error_message=f"ì‹¤ì œ GitHub ë“±ë¡ëœ {step_id} ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ì‹¤íŒ¨: {str(e)}",
                creation_time=time.time() - start_time
            )
    
    def _create_default_real_github_config(self, step_id: str, step_class: Type, **kwargs) -> RealGitHubStepConfig:
        """ì‹¤ì œ GitHub ê¸°ë³¸ ì„¤ì • ìƒì„± (StepTypeì´ ì—†ì„ ë•Œ) + DetailedDataSpec ì§€ì›"""
        return RealGitHubStepConfig(
            step_name=step_class.__name__,
            step_id=int(step_id.split('_')[1]) if '_' in step_id else 0,
            step_type=StepType.HUMAN_PARSING,  # ê¸°ë³¸ê°’
            class_name=step_class.__name__,
            module_path=step_class.__module__,
            conda_env=CONDA_INFO['conda_env'],
            memory_gb=MEMORY_GB,
            **kwargs
        )
    
    def _create_step_legacy_way(
        self, 
        step_type: StepType, 
        use_cache: bool = True, 
        **kwargs
    ) -> RealGitHubStepCreationResult:
        """ì‹¤ì œ GitHub ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ Step ìƒì„± (ë™ì  ë¡œë”©) + DetailedDataSpec í†µí•©"""
        config = RealGitHubStepMapping.get_enhanced_github_config(step_type, **kwargs)
        
        self.logger.info(f"ğŸ¯ {config.step_name} ì‹¤ì œ GitHub ìƒì„± ì‹œì‘ (ë™ì  ë¡œë”© + DetailedDataSpec)...")
        
        # í†µê³„ ì—…ë°ì´íŠ¸
        with self._lock:
            self._stats['total_created'] += 1
        
        # ìºì‹œ í™•ì¸
        if use_cache:
            cached_step = self._get_cached_step(config.step_name)
            if cached_step:
                with self._lock:
                    self._stats['cache_hits'] += 1
                self.logger.info(f"â™»ï¸ {config.step_name} ì‹¤ì œ GitHub ìºì‹œì—ì„œ ë°˜í™˜")
                return RealGitHubStepCreationResult(
                    success=True,
                    step_instance=cached_step,
                    step_name=config.step_name,
                    step_type=step_type,
                    class_name=config.class_name,
                    module_path=config.module_path,
                    creation_time=0.0,
                    github_compatible=True,
                    basestepmixin_v19_compatible=True,
                    detailed_data_spec_loaded=True,
                    real_dependencies_only=True
                )
        
        # ì‹¤ì œ GitHub Step ìƒì„± (ê¸°ì¡´ ë¡œì§ + DetailedDataSpec í†µí•©)
        result = self._create_real_github_step_instance(config)
        
        # ì„±ê³µ ì‹œ ìºì‹œì— ì €ì¥
        if result.success and result.step_instance and use_cache:
            self._cache_step(config.step_name, result.step_instance)
        
        # í†µê³„ ì—…ë°ì´íŠ¸
        with self._lock:
            if result.success:
                self._stats['successful_creations'] += 1
                if result.github_compatible:
                    self._stats['github_compatible_creations'] += 1
                if result.dependency_injection_success:
                    self._stats['dependency_injection_successes'] += 1
                if result.detailed_data_spec_loaded:
                    self._stats['detailed_data_spec_successes'] += 1
                if result.api_mappings_applied:
                    self._stats['api_mapping_successes'] += 1
                if result.data_flow_configured:
                    self._stats['data_flow_successes'] += 1
                self._stats['real_checkpoints_loaded'] += result.real_checkpoints_loaded
                self._stats['real_ai_models_loaded'] += len(result.real_ai_models_loaded)
            else:
                self._stats['failed_creations'] += 1
        
        return result

    def _create_real_github_step_instance(self, config: RealGitHubStepConfig) -> RealGitHubStepCreationResult:
        """ì‹¤ì œ GitHub BaseStepMixin v19.2 + DetailedDataSpec ì™„ì „ í†µí•© Step ì¸ìŠ¤í„´ìŠ¤ ìƒì„± (ìˆœí™˜ì°¸ì¡° í•´ê²°)"""
        try:
            self.logger.info(f"ğŸ”„ {config.step_name} ì‹¤ì œ GitHub BaseStepMixin v19.2 + DetailedDataSpec ì™„ì „ í†µí•© ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ì¤‘...")
            
            # 1. ì‹¤ì œ GitHub Step í´ë˜ìŠ¤ ë¡œë”© (ìˆœí™˜ì°¸ì¡° í•´ê²°)
            StepClass = self.class_loader.load_enhanced_github_step_class(config)
            if not StepClass:
                return RealGitHubStepCreationResult(
                    success=False,
                    step_name=config.step_name,
                    step_type=config.step_type,
                    class_name=config.class_name,
                    module_path=config.module_path,
                    error_message=f"{config.class_name} ì‹¤ì œ GitHub í´ë˜ìŠ¤ ë¡œë”© ì‹¤íŒ¨"
                )
            
            self.logger.info(f"âœ… {config.class_name} ì‹¤ì œ GitHub í´ë˜ìŠ¤ ë¡œë”© ì™„ë£Œ")
            
            # 2. ì‹¤ì œ GitHub ìƒì„±ììš© ì˜ì¡´ì„± í•´ê²° + DetailedDataSpec í†µí•© (ìˆœí™˜ì°¸ì¡° í•´ê²°)
            constructor_dependencies = self.dependency_resolver.resolve_enhanced_github_dependencies_for_constructor(config)
            
            # 3. ì‹¤ì œ GitHub BaseStepMixin v19.2 + DetailedDataSpec í‘œì¤€ ìƒì„±ì í˜¸ì¶œ
            self.logger.info(f"ğŸ”„ {config.class_name} ì‹¤ì œ GitHub BaseStepMixin v19.2 + DetailedDataSpec ìƒì„±ì í˜¸ì¶œ ì¤‘...")
            step_instance = StepClass(**constructor_dependencies)
            self.logger.info(f"âœ… {config.class_name} ì‹¤ì œ GitHub ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ì™„ë£Œ (ìƒì„±ì ì˜ì¡´ì„± + DetailedDataSpec ì£¼ì…)")
            
            # 4. ì‹¤ì œ GitHub ì´ˆê¸°í™” ì‹¤í–‰ (ë™ê¸°/ë¹„ë™ê¸° ìë™ ê°ì§€)
            initialization_success = self._initialize_real_github_step(step_instance, config)
            
            # 5. DetailedDataSpec í›„ì²˜ë¦¬ ì ìš©
            detailed_data_spec_result = self._apply_detailed_data_spec_post_processing(step_instance, config)
            
            # 6. ì‹¤ì œ GitHub BaseStepMixin v19.2 + DetailedDataSpec í˜¸í™˜ì„± ìµœì¢… ê²€ì¦
            compatibility_result = self._verify_real_github_compatibility(step_instance, config)
            
            # 7. ì‹¤ì œ GitHub AI ëª¨ë¸ ë¡œë”© í™•ì¸
            real_ai_models_loaded = self._check_real_github_ai_models(step_instance, config)
            
            # 8. ì‹¤ì œ ì²´í¬í¬ì¸íŠ¸ ë¡œë”© í™•ì¸
            real_checkpoints_loaded = self._check_real_checkpoint_loading(step_instance, config)
            
            self.logger.info(f"âœ… {config.step_name} ì‹¤ì œ GitHub BaseStepMixin v19.2 + DetailedDataSpec ì™„ì „ í†µí•© ìƒì„± ì™„ë£Œ")
            
            return RealGitHubStepCreationResult(
                success=True,
                step_instance=step_instance,
                step_name=config.step_name,
                step_type=config.step_type,
                class_name=config.class_name,
                module_path=config.module_path,
                dependencies_injected={'constructor_injection': True},
                initialization_success=initialization_success,
                real_ai_models_loaded=real_ai_models_loaded,
                real_checkpoints_loaded=real_checkpoints_loaded,
                github_compatible=compatibility_result['compatible'],
                basestepmixin_v19_compatible=compatibility_result['basestepmixin_v19_compatible'],
                process_method_validated=compatibility_result['process_method_valid'],
                dependency_injection_success=True,
                detailed_data_spec_loaded=detailed_data_spec_result['success'],
                api_mappings_applied=detailed_data_spec_result.get('api_mappings', {}),
                data_flow_configured=detailed_data_spec_result.get('data_flow', {}),
                preprocessing_configured=detailed_data_spec_result.get('preprocessing_configured', False),
                postprocessing_configured=detailed_data_spec_result.get('postprocessing_configured', False),
                real_dependencies_only=True,
                real_dependency_manager=True,
                real_ai_processing_enabled=True
            )
            
        except Exception as e:
            self.logger.error(f"âŒ {config.step_name} ì‹¤ì œ GitHub BaseStepMixin v19.2 + DetailedDataSpec ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ì‹¤íŒ¨: {e}")
            self.logger.error(f"âŒ ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
            
            return RealGitHubStepCreationResult(
                success=False,
                step_name=config.step_name,
                step_type=config.step_type,
                class_name=config.class_name,
                module_path=config.module_path,
                error_message=f"ì‹¤ì œ GitHub BaseStepMixin v19.2 + DetailedDataSpec ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ì‹¤íŒ¨: {str(e)}",
                github_compatible=False,
                basestepmixin_v19_compatible=False,
                detailed_data_spec_loaded=False,
                real_dependencies_only=True
            )
    
    def _apply_detailed_data_spec_post_processing(self, step_instance: 'BaseStepMixin', config: RealGitHubStepConfig) -> Dict[str, Any]:
        """DetailedDataSpec í›„ì²˜ë¦¬ ì ìš©"""
        try:
            self.logger.info(f"ğŸ”„ {config.step_name} DetailedDataSpec í›„ì²˜ë¦¬ ì ìš© ì¤‘...")
            
            result = {
                'success': True,
                'api_mappings': {},
                'data_flow': {},
                'preprocessing_configured': True,
                'postprocessing_configured': True,
                'errors': []
            }
            
            data_spec = config.detailed_data_spec
            
            # BaseStepMixin v19.2ê°€ DetailedDataSpecì„ ì œëŒ€ë¡œ ì²˜ë¦¬í–ˆëŠ”ì§€ í™•ì¸
            if hasattr(step_instance, 'api_input_mapping') and step_instance.api_input_mapping:
                # ì´ë¯¸ BaseStepMixin ìƒì„±ìì—ì„œ ì„¤ì •ë¨
                result['api_mappings'] = {
                    'input_mapping': step_instance.api_input_mapping,
                    'output_mapping': getattr(step_instance, 'api_output_mapping', {})
                }
                self.logger.info(f"âœ… {config.step_name} BaseStepMixin v19.2ì—ì„œ API ë§¤í•‘ ì´ë¯¸ ì„¤ì • ì™„ë£Œ")
            else:
                # í´ë°±: ìˆ˜ë™ ì„¤ì •
                self.logger.warning(f"âš ï¸ {config.step_name} BaseStepMixinì—ì„œ API ë§¤í•‘ ë¯¸ì§€ì›, í´ë°± ì„¤ì • ì ìš©")
                try:
                    step_instance.api_input_mapping = data_spec.api_input_mapping
                    step_instance.api_output_mapping = data_spec.api_output_mapping
                    result['api_mappings'] = {
                        'input_mapping': data_spec.api_input_mapping,
                        'output_mapping': data_spec.api_output_mapping
                    }
                except Exception as e:
                    result['errors'].append(f"í´ë°± API ë§¤í•‘ ì„¤ì • ì‹¤íŒ¨: {e}")
            
            # Step ê°„ ë°ì´í„° íë¦„ í™•ì¸
            if hasattr(step_instance, 'provides_to_next_step'):
                result['data_flow'] = {
                    'accepts_from': list(getattr(step_instance, 'accepts_from_previous_step', {}).keys()),
                    'provides_to': list(step_instance.provides_to_next_step.keys())
                }
                self.logger.info(f"âœ… {config.step_name} BaseStepMixin v19.2ì—ì„œ ë°ì´í„° íë¦„ ì´ë¯¸ ì„¤ì • ì™„ë£Œ")
            else:
                # í´ë°±: ìˆ˜ë™ ì„¤ì •
                try:
                    step_instance.accepts_from_previous_step = data_spec.accepts_from_previous_step
                    step_instance.provides_to_next_step = data_spec.provides_to_next_step
                    result['data_flow'] = {
                        'accepts_from': list(data_spec.accepts_from_previous_step.keys()),
                        'provides_to': list(data_spec.provides_to_next_step.keys())
                    }
                except Exception as e:
                    result['errors'].append(f"í´ë°± ë°ì´í„° íë¦„ ì„¤ì • ì‹¤íŒ¨: {e}")
            
            # ì „ì²˜ë¦¬/í›„ì²˜ë¦¬ í™•ì¸
            if not hasattr(step_instance, 'preprocessing_steps'):
                # í´ë°±: ìˆ˜ë™ ì„¤ì •
                try:
                    step_instance.preprocessing_steps = data_spec.preprocessing_steps
                    step_instance.postprocessing_steps = data_spec.postprocessing_steps
                    step_instance.normalization_mean = data_spec.normalization_mean
                    step_instance.normalization_std = data_spec.normalization_std
                except Exception as e:
                    result['errors'].append(f"í´ë°± ì „ì²˜ë¦¬/í›„ì²˜ë¦¬ ì„¤ì • ì‹¤íŒ¨: {e}")
            
            # DetailedDataSpec ë©”íƒ€ì •ë³´ ì„¤ì •
            try:
                step_instance.detailed_data_spec_loaded = True
                step_instance.detailed_data_spec_version = 'v11.1'
                step_instance.step_model_requirements_integrated = STEP_MODEL_REQUIREMENTS is not None
                step_instance.real_ai_structure_integrated = True
            except Exception as e:
                result['errors'].append(f"ë©”íƒ€ì •ë³´ ì„¤ì • ì‹¤íŒ¨: {e}")
            
            # ìµœì¢… ê²°ê³¼ íŒì •
            if len(result['errors']) == 0:
                self.logger.info(f"âœ… {config.step_name} DetailedDataSpec í›„ì²˜ë¦¬ ì™„ë£Œ (ì‹¤ì œ BaseStepMixin v19.2 í‘œì¤€)")
            else:
                self.logger.warning(f"âš ï¸ {config.step_name} DetailedDataSpec í›„ì²˜ë¦¬ ë¶€ë¶„ ì‹¤íŒ¨: {result['errors']}")
            
            return result
            
        except Exception as e:
            self.logger.error(f"âŒ {config.step_name} DetailedDataSpec í›„ì²˜ë¦¬ ì ìš© ì‹¤íŒ¨: {e}")
            return {
                'success': False,
                'api_mappings': {},
                'data_flow': {},
                'preprocessing_configured': False,
                'postprocessing_configured': False,
                'errors': [str(e)]
            }
    
    def _initialize_real_github_step(self, step_instance: 'BaseStepMixin', config: RealGitHubStepConfig) -> bool:
        """ì‹¤ì œ GitHub BaseStepMixin v19.2 Step ì´ˆê¸°í™”"""
        try:
            # ì‹¤ì œ GitHub BaseStepMixin v19.2 initialize ë©”ì„œë“œ í˜¸ì¶œ
            if hasattr(step_instance, 'initialize'):
                initialize_method = step_instance.initialize
                
                # ë™ê¸°/ë¹„ë™ê¸° ìë™ ê°ì§€ ë° ì²˜ë¦¬
                if asyncio.iscoroutinefunction(initialize_method):
                    # ë¹„ë™ê¸° í•¨ìˆ˜ì¸ ê²½ìš°
                    try:
                        # í˜„ì¬ ì‹¤í–‰ ì¤‘ì¸ ì´ë²¤íŠ¸ ë£¨í”„ê°€ ìˆëŠ”ì§€ í™•ì¸
                        loop = asyncio.get_running_loop()
                        
                        # ì´ë¯¸ ì‹¤í–‰ ì¤‘ì¸ ë£¨í”„ì—ì„œëŠ” íƒœìŠ¤í¬ ìƒì„± í›„ ë¸”ë¡œí‚¹ ëŒ€ê¸°
                        if loop.is_running():
                            # ìƒˆë¡œìš´ ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰í•˜ê±°ë‚˜ ë™ê¸°ì ìœ¼ë¡œ ì²˜ë¦¬
                            import concurrent.futures
                            with concurrent.futures.ThreadPoolExecutor() as executor:
                                future = executor.submit(asyncio.run, initialize_method())
                                success = future.result(timeout=30)  # 30ì´ˆ íƒ€ì„ì•„ì›ƒ
                        else:
                            # ë£¨í”„ê°€ ì‹¤í–‰ ì¤‘ì´ ì•„ë‹ˆë©´ ì§ì ‘ ì‹¤í–‰
                            success = asyncio.run(initialize_method())
                    except RuntimeError:
                        # ì‹¤í–‰ ì¤‘ì¸ ë£¨í”„ê°€ ì—†ìœ¼ë©´ ìƒˆ ë£¨í”„ì—ì„œ ì‹¤í–‰
                        success = asyncio.run(initialize_method())
                    except Exception as e:
                        self.logger.warning(f"âš ï¸ {config.step_name} ì‹¤ì œ GitHub ë¹„ë™ê¸° ì´ˆê¸°í™” ì‹¤íŒ¨, ë™ê¸° ë°©ì‹ ì‹œë„: {e}")
                        # ë¹„ë™ê¸° ì´ˆê¸°í™” ì‹¤íŒ¨ ì‹œ í´ë°± (ë™ê¸° ë°©ì‹ìœ¼ë¡œ ì¬ì‹œë„)
                        success = self._fallback_real_github_sync_initialize(step_instance, config)
                else:
                    # ë™ê¸° í•¨ìˆ˜ì¸ ê²½ìš°
                    success = initialize_method()
                
                if success:
                    self.logger.info(f"âœ… {config.step_name} ì‹¤ì œ GitHub BaseStepMixin v19.2 ì´ˆê¸°í™” ì™„ë£Œ")
                    return True
                else:
                    self.logger.warning(f"âš ï¸ {config.step_name} ì‹¤ì œ GitHub BaseStepMixin v19.2 ì´ˆê¸°í™” ì‹¤íŒ¨")
                    return False
            else:
                self.logger.debug(f"â„¹ï¸ {config.step_name} ì‹¤ì œ GitHub initialize ë©”ì„œë“œ ì—†ìŒ")
                return True
                
        except Exception as e:
            self.logger.warning(f"âš ï¸ {config.step_name} ì‹¤ì œ GitHub ì´ˆê¸°í™” ì˜ˆì™¸: {e}")
            # ì˜ˆì™¸ ë°œìƒ ì‹œ í´ë°± ì´ˆê¸°í™” ì‹œë„
            return self._fallback_real_github_sync_initialize(step_instance, config)
    
    def _fallback_real_github_sync_initialize(self, step_instance: 'BaseStepMixin', config: RealGitHubStepConfig) -> bool:
        """ì‹¤ì œ GitHub í´ë°± ë™ê¸° ì´ˆê¸°í™”"""
        try:
            self.logger.info(f"ğŸ”„ {config.step_name} ì‹¤ì œ GitHub í´ë°± ë™ê¸° ì´ˆê¸°í™” ì‹œë„...")
            
            # ì‹¤ì œ GitHub ê¸°ë³¸ ì†ì„±ë“¤ ìˆ˜ë™ ì„¤ì •
            if hasattr(step_instance, 'is_initialized'):
                step_instance.is_initialized = True
            
            if hasattr(step_instance, 'is_ready'):
                step_instance.is_ready = True
            
            if hasattr(step_instance, 'github_compatible'):
                step_instance.github_compatible = True
                
            if hasattr(step_instance, 'real_ai_structure_integrated'):
                step_instance.real_ai_structure_integrated = True
                
            # ì‹¤ì œ GitHub ì˜ì¡´ì„±ì´ ì œëŒ€ë¡œ ì£¼ì…ë˜ì—ˆëŠ”ì§€ í™•ì¸
            dependencies_ok = True
            if config.require_model_loader and not hasattr(step_instance, 'model_loader'):
                dependencies_ok = False
                
            if dependencies_ok:
                self.logger.info(f"âœ… {config.step_name} ì‹¤ì œ GitHub í´ë°± ë™ê¸° ì´ˆê¸°í™” ì„±ê³µ")
                return True
            else:
                self.logger.warning(f"âš ï¸ {config.step_name} ì‹¤ì œ GitHub í´ë°± ì´ˆê¸°í™”: ì˜ì¡´ì„± ë¬¸ì œ ìˆìŒ")
                return not config.strict_mode
                
        except Exception as e:
            self.logger.error(f"âŒ {config.step_name} ì‹¤ì œ GitHub í´ë°± ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return False
    
    def _verify_real_github_compatibility(self, step_instance: 'BaseStepMixin', config: RealGitHubStepConfig) -> Dict[str, Any]:
        """ì‹¤ì œ GitHub BaseStepMixin v19.2 + DetailedDataSpec í˜¸í™˜ì„± ìµœì¢… ê²€ì¦"""
        try:
            result = {
                'compatible': True,
                'basestepmixin_v19_compatible': True,
                'process_method_valid': False,
                'detailed_data_spec_compatible': False,
                'real_ai_structure_compatible': False,
                'issues': []
            }
            
            # ì‹¤ì œ GitHub process ë©”ì„œë“œ ì¡´ì¬ í™•ì¸
            if not hasattr(step_instance, 'process'):
                result['compatible'] = False
                result['basestepmixin_v19_compatible'] = False
                result['issues'].append('ì‹¤ì œ GitHub process ë©”ì„œë“œ ì—†ìŒ')
            else:
                result['process_method_valid'] = True
            
            # ì‹¤ì œ GitHub BaseStepMixin v19.2 ì†ì„± í™•ì¸
            expected_attrs = ['step_name', 'step_id', 'device', 'is_initialized', 'github_compatible']
            for attr in expected_attrs:
                if not hasattr(step_instance, attr):
                    result['issues'].append(f'ì‹¤ì œ GitHub {attr} ì†ì„± ì—†ìŒ')
            
            # DetailedDataSpec í˜¸í™˜ì„± í™•ì¸
            detailed_data_spec_attrs = ['api_input_mapping', 'api_output_mapping']
            detailed_data_spec_found = 0
            for attr in detailed_data_spec_attrs:
                if hasattr(step_instance, attr):
                    detailed_data_spec_found += 1
            
            result['detailed_data_spec_compatible'] = detailed_data_spec_found > 0
            if not result['detailed_data_spec_compatible']:
                result['issues'].append('DetailedDataSpec API ë§¤í•‘ ì†ì„± ì—†ìŒ')
            
            # ì‹¤ì œ AI êµ¬ì¡° í˜¸í™˜ì„± í™•ì¸
            real_ai_attrs = ['real_ai_structure_integrated', 'model_loader', 'real_dependencies_only']
            real_ai_found = 0
            for attr in real_ai_attrs:
                if hasattr(step_instance, attr):
                    real_ai_found += 1
            
            result['real_ai_structure_compatible'] = real_ai_found > 0
            if not result['real_ai_structure_compatible']:
                result['issues'].append('ì‹¤ì œ AI êµ¬ì¡° í†µí•© ì†ì„± ì—†ìŒ')
            
            if result['issues']:
                self.logger.warning(f"âš ï¸ {config.step_name} ì‹¤ì œ GitHub BaseStepMixin v19.2 + DetailedDataSpec í˜¸í™˜ì„± ì´ìŠˆ: {result['issues']}")
            else:
                self.logger.info(f"âœ… {config.step_name} ì‹¤ì œ GitHub BaseStepMixin v19.2 + DetailedDataSpec í˜¸í™˜ì„± ê²€ì¦ ì™„ë£Œ")
            
            return result
            
        except Exception as e:
            self.logger.error(f"âŒ {config.step_name} ì‹¤ì œ GitHub BaseStepMixin v19.2 + DetailedDataSpec í˜¸í™˜ì„± ê²€ì¦ ì‹¤íŒ¨: {e}")
            return {
                'compatible': False, 
                'basestepmixin_v19_compatible': False, 
                'process_method_valid': False, 
                'detailed_data_spec_compatible': False,
                'real_ai_structure_compatible': False,
                'issues': [str(e)]
            }
    
    def _check_real_github_ai_models(self, step_instance: 'BaseStepMixin', config: RealGitHubStepConfig) -> List[str]:
        """ì‹¤ì œ GitHub AI ëª¨ë¸ ë¡œë”© í™•ì¸"""
        loaded_models = []
        
        try:
            # ì‹¤ì œ GitHub ModelLoader ë¥¼ í†µí•œ ëª¨ë¸ í™•ì¸
            if hasattr(step_instance, 'model_loader') and step_instance.model_loader:
                # ì‹¤ì œ AI ëª¨ë¸ë“¤ í™•ì¸
                for real_ai_model in config.real_ai_models:
                    try:
                        if hasattr(step_instance.model_loader, 'is_model_loaded'):
                            if step_instance.model_loader.is_model_loaded(real_ai_model.model_name):
                                loaded_models.append(real_ai_model.model_name)
                    except Exception:
                        pass
                
                # í˜¸í™˜ì„± AI ëª¨ë¸ë“¤ í™•ì¸
                for model_name in config.ai_models:
                    try:
                        if hasattr(step_instance.model_loader, 'is_model_loaded'):
                            if step_instance.model_loader.is_model_loaded(model_name):
                                loaded_models.append(model_name)
                    except Exception:
                        pass
            
            # ì‹¤ì œ GitHub model_interface ë¥¼ í†µí•œ ëª¨ë¸ í™•ì¸
            if hasattr(step_instance, 'model_interface') and step_instance.model_interface:
                for real_ai_model in config.real_ai_models:
                    try:
                        if hasattr(step_instance.model_interface, 'is_model_available'):
                            if step_instance.model_interface.is_model_available(real_ai_model.model_name):
                                loaded_models.append(real_ai_model.model_name)
                    except Exception:
                        pass
            
            if loaded_models:
                self.logger.info(f"ğŸ¤– {config.step_name} ì‹¤ì œ GitHub AI ëª¨ë¸ ë¡œë”© í™•ì¸: {loaded_models}")
            
            return loaded_models
            
        except Exception as e:
            self.logger.debug(f"ì‹¤ì œ GitHub AI ëª¨ë¸ í™•ì¸ ì‹¤íŒ¨: {e}")
            return []
    
    def _check_real_checkpoint_loading(self, step_instance: 'BaseStepMixin', config: RealGitHubStepConfig) -> int:
        """ì‹¤ì œ ì²´í¬í¬ì¸íŠ¸ ë¡œë”© í™•ì¸"""
        checkpoints_loaded = 0
        
        try:
            # ì‹¤ì œ AI ëª¨ë¸ë³„ ì²´í¬í¬ì¸íŠ¸ í™•ì¸
            for real_ai_model in config.real_ai_models:
                if real_ai_model.requires_checkpoint:
                    try:
                        # ModelLoaderë¥¼ í†µí•œ ì²´í¬í¬ì¸íŠ¸ í™•ì¸
                        if hasattr(step_instance, 'model_loader') and step_instance.model_loader:
                            if hasattr(step_instance.model_loader, 'get_model_checkpoint_status'):
                                status = step_instance.model_loader.get_model_checkpoint_status(real_ai_model.model_name)
                                if status and status.get('checkpoint_loaded', False):
                                    checkpoints_loaded += 1
                            elif hasattr(step_instance.model_loader, 'is_checkpoint_loaded'):
                                if step_instance.model_loader.is_checkpoint_loaded(real_ai_model.model_name):
                                    checkpoints_loaded += 1
                    except Exception:
                        pass
            
            if checkpoints_loaded > 0:
                self.logger.info(f"ğŸ“Š {config.step_name} ì‹¤ì œ ì²´í¬í¬ì¸íŠ¸ ë¡œë”© í™•ì¸: {checkpoints_loaded}ê°œ")
            
            return checkpoints_loaded
            
        except Exception as e:
            self.logger.debug(f"ì‹¤ì œ ì²´í¬í¬ì¸íŠ¸ ë¡œë”© í™•ì¸ ì‹¤íŒ¨: {e}")
            return 0
    
    def _get_cached_step(self, step_name: str) -> Optional['BaseStepMixin']:
        """ìºì‹œëœ ì‹¤ì œ GitHub Step ë°˜í™˜"""
        try:
            with self._lock:
                if step_name in self._step_cache:
                    weak_ref = self._step_cache[step_name]
                    step_instance = weak_ref()
                    if step_instance is not None:
                        return step_instance
                    else:
                        del self._step_cache[step_name]
                return None
        except Exception:
            return None
    
    def _cache_step(self, step_name: str, step_instance: 'BaseStepMixin'):
        """ì‹¤ì œ GitHub Step ìºì‹œì— ì €ì¥"""
        try:
            with self._lock:
                self._step_cache[step_name] = weakref.ref(step_instance)
        except Exception:
            pass

    def clear_cache(self):
        """ì‹¤ì œ GitHub ìºì‹œ ì •ë¦¬"""
        try:
            with self._lock:
                self._step_cache.clear()
                self.dependency_resolver.clear_cache()
                
                # ğŸ”¥ ìˆœí™˜ì°¸ì¡° ë°©ì§€ ë°ì´í„° ì •ë¦¬
                self._circular_detected.clear()
                self._resolving_stack.clear()
                
                # ì‹¤ì œ GitHub M3 Max ë©”ëª¨ë¦¬ ì •ë¦¬
                if IS_M3_MAX_DETECTED and MPS_AVAILABLE and PYTORCH_AVAILABLE:
                    try:
                        import torch
                        if hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
                            if hasattr(torch.backends.mps, 'empty_cache'):
                                torch.backends.mps.empty_cache()
                    except:
                        pass
                
                gc.collect()
                self.logger.info("ğŸ§¹ StepFactory v11.1 ì‹¤ì œ GitHub + DetailedDataSpec ìºì‹œ ì •ë¦¬ ì™„ë£Œ")
        except Exception as e:
            self.logger.error(f"âŒ ì‹¤ì œ GitHub ìºì‹œ ì •ë¦¬ ì‹¤íŒ¨: {e}")

    # ==============================================
    # ğŸ”¥ í¸ì˜ ë©”ì„œë“œë“¤ (ëª¨ë“  ê¸°ì¡´ í•¨ìˆ˜ëª… ìœ ì§€)
    # ==============================================
    
    def create_human_parsing_step(self, **kwargs) -> RealGitHubStepCreationResult:
        """ì‹¤ì œ GitHub Human Parsing Step ìƒì„±"""
        return self.create_step(StepType.HUMAN_PARSING, **kwargs)
    
    def create_pose_estimation_step(self, **kwargs) -> RealGitHubStepCreationResult:
        """ì‹¤ì œ GitHub Pose Estimation Step ìƒì„±"""
        return self.create_step(StepType.POSE_ESTIMATION, **kwargs)
    
    def create_cloth_segmentation_step(self, **kwargs) -> RealGitHubStepCreationResult:
        """ì‹¤ì œ GitHub Cloth Segmentation Step ìƒì„±"""
        return self.create_step(StepType.CLOTH_SEGMENTATION, **kwargs)
    
    def create_geometric_matching_step(self, **kwargs) -> RealGitHubStepCreationResult:
        """ì‹¤ì œ GitHub Geometric Matching Step ìƒì„±"""
        return self.create_step(StepType.GEOMETRIC_MATCHING, **kwargs)
    
    def create_cloth_warping_step(self, **kwargs) -> RealGitHubStepCreationResult:
        """ì‹¤ì œ GitHub Cloth Warping Step ìƒì„±"""
        return self.create_step(StepType.CLOTH_WARPING, **kwargs)
    
    def create_virtual_fitting_step(self, **kwargs) -> RealGitHubStepCreationResult:
        """ì‹¤ì œ GitHub Virtual Fitting Step ìƒì„±"""
        return self.create_step(StepType.VIRTUAL_FITTING, **kwargs)
    
    def create_post_processing_step(self, **kwargs) -> RealGitHubStepCreationResult:
        """ì‹¤ì œ GitHub Post Processing Step ìƒì„±"""
        return self.create_step(StepType.POST_PROCESSING, **kwargs)
    
    def create_quality_assessment_step(self, **kwargs) -> RealGitHubStepCreationResult:
        """ì‹¤ì œ GitHub Quality Assessment Step ìƒì„±"""
        return self.create_step(StepType.QUALITY_ASSESSMENT, **kwargs)

    def get_statistics(self) -> Dict[str, Any]:
        """ì‹¤ì œ GitHub í†µê³„ ì •ë³´ ë°˜í™˜"""
        with self._lock:
            total = self._stats['total_created']
            success_rate = (self._stats['successful_creations'] / max(1, total)) * 100
            github_compatibility_rate = (self._stats['github_compatible_creations'] / max(1, self._stats['successful_creations'])) * 100
            detailed_data_spec_rate = (self._stats['detailed_data_spec_successes'] / max(1, self._stats['successful_creations'])) * 100
            
            base_stats = {
                'version': 'StepFactory v11.1 (Real AI Structure + Circular Reference Fix + DetailedDataSpec Complete Integration + BaseStepMixin v19.2)',
                'total_created': total,
                'successful_creations': self._stats['successful_creations'],
                'failed_creations': self._stats['failed_creations'],
                'success_rate': round(success_rate, 2),
                'cache_hits': self._stats['cache_hits'],
                'cached_steps': len(self._step_cache),
                'active_cache_entries': len([
                    ref for ref in self._step_cache.values() if ref() is not None
                ]),
                'circular_reference_protection': {
                    'prevented_count': self._stats['circular_references_prevented'],
                    'current_stack': list(self._resolving_stack),
                    'detected_keys': list(self._circular_detected)
                },
                'real_ai_integration': {
                    'real_checkpoints_loaded': self._stats['real_checkpoints_loaded'],
                    'real_ai_models_loaded': self._stats['real_ai_models_loaded'],
                    'real_step_interface_available': self._stats['real_step_interface_available']
                },
                'github_compatibility': {
                    'github_compatible_creations': self._stats['github_compatible_creations'],
                    'github_compatibility_rate': round(github_compatibility_rate, 2),
                    'dependency_injection_successes': self._stats['dependency_injection_successes']
                },
                'detailed_data_spec_integration': {
                    'detailed_data_spec_successes': self._stats['detailed_data_spec_successes'],
                    'detailed_data_spec_rate': round(detailed_data_spec_rate, 2),
                    'api_mapping_successes': self._stats['api_mapping_successes'],
                    'data_flow_successes': self._stats['data_flow_successes'],
                    'step_model_requirements_available': self._stats['step_model_requirements_available']
                },
                'environment': {
                    'conda_env': CONDA_INFO['conda_env'],
                    'conda_optimized': self._stats['conda_optimized'],
                    'is_m3_max_detected': IS_M3_MAX_DETECTED,
                    'm3_max_optimized': self._stats['m3_max_optimized'],
                    'memory_gb': MEMORY_GB,
                    'mps_available': MPS_AVAILABLE if REAL_STEP_INTERFACE_AVAILABLE else False,
                    'pytorch_available': PYTORCH_AVAILABLE if REAL_STEP_INTERFACE_AVAILABLE else False
                },
                'loaded_classes': list(self.class_loader._loaded_classes.keys()),
                
                # ì‹¤ì œ GitHub ë“±ë¡ ì •ë³´
                'registration': {
                    'registered_steps_count': len(self._registered_steps),
                    'registered_steps': self.get_registered_steps(),
                    'step_type_mappings': {
                        step_id: step_type.value 
                        for step_id, step_type in self._step_type_mapping.items()
                    }
                }
            }
            
            return base_stats



# ==============================================
# ğŸ”¥ ì „ì—­ StepFactory ê´€ë¦¬ (ì‹¤ì œ êµ¬ì¡°, ìˆœí™˜ì°¸ì¡° í•´ê²°)
# ==============================================

_global_step_factory: Optional[StepFactory] = None
_factory_lock = threading.Lock()

def get_global_step_factory() -> StepFactory:
    """ì „ì—­ StepFactory v11.1 ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜ (ì‹¤ì œ êµ¬ì¡° + ìˆœí™˜ì°¸ì¡° ì™„ì „ í•´ê²°)"""
    global _global_step_factory
    
    with _factory_lock:
        if _global_step_factory is None:
            _global_step_factory = StepFactory()
            logger.info("âœ… ì „ì—­ StepFactory v11.1 (ì‹¤ì œ AI êµ¬ì¡° ì™„ì „ ë°˜ì˜ + ìˆœí™˜ì°¸ì¡° ì™„ì „ í•´ê²° + DetailedDataSpec ì™„ì „ í†µí•© + BaseStepMixin v19.2 í˜¸í™˜) ìƒì„± ì™„ë£Œ")
        
        return _global_step_factory

def reset_global_step_factory():
    """ì „ì—­ ì‹¤ì œ GitHub StepFactory ë¦¬ì…‹"""
    global _global_step_factory
    
    with _factory_lock:
        if _global_step_factory:
            _global_step_factory.clear_cache()
        _global_step_factory = None
        logger.info("ğŸ”„ ì „ì—­ StepFactory v11.1 ì‹¤ì œ êµ¬ì¡° ìˆœí™˜ì°¸ì¡° í•´ê²° ë¦¬ì…‹ ì™„ë£Œ")

# ==============================================
# ğŸ”¥ í¸ì˜ í•¨ìˆ˜ë“¤ (ëª¨ë“  ê¸°ì¡´ í•¨ìˆ˜ëª… ìœ ì§€)
# ==============================================

def create_step(step_type: Union[StepType, str], **kwargs) -> RealGitHubStepCreationResult:
    """ì „ì—­ ì‹¤ì œ GitHub Step ìƒì„± í•¨ìˆ˜"""
    factory = get_global_step_factory()
    return factory.create_step(step_type, **kwargs)

def create_human_parsing_step(**kwargs) -> RealGitHubStepCreationResult:
    """ì‹¤ì œ GitHub Human Parsing Step ìƒì„±"""
    return create_step(StepType.HUMAN_PARSING, **kwargs)

def create_pose_estimation_step(**kwargs) -> RealGitHubStepCreationResult:
    """ì‹¤ì œ GitHub Pose Estimation Step ìƒì„±"""
    return create_step(StepType.POSE_ESTIMATION, **kwargs)

def create_cloth_segmentation_step(**kwargs) -> RealGitHubStepCreationResult:
    """ì‹¤ì œ GitHub Cloth Segmentation Step ìƒì„±"""
    return create_step(StepType.CLOTH_SEGMENTATION, **kwargs)

def create_geometric_matching_step(**kwargs) -> RealGitHubStepCreationResult:
    """ì‹¤ì œ GitHub Geometric Matching Step ìƒì„±"""
    return create_step(StepType.GEOMETRIC_MATCHING, **kwargs)

def create_cloth_warping_step(**kwargs) -> RealGitHubStepCreationResult:
    """ì‹¤ì œ GitHub Cloth Warping Step ìƒì„±"""
    return create_step(StepType.CLOTH_WARPING, **kwargs)

def create_virtual_fitting_step(**kwargs) -> RealGitHubStepCreationResult:
    """ì‹¤ì œ GitHub Virtual Fitting Step ìƒì„±"""
    return create_step(StepType.VIRTUAL_FITTING, **kwargs)

def create_post_processing_step(**kwargs) -> RealGitHubStepCreationResult:
    """ì‹¤ì œ GitHub Post Processing Step ìƒì„±"""
    return create_step(StepType.POST_PROCESSING, **kwargs)

def create_quality_assessment_step(**kwargs) -> RealGitHubStepCreationResult:
    """ì‹¤ì œ GitHub Quality Assessment Step ìƒì„±"""
    return create_step(StepType.QUALITY_ASSESSMENT, **kwargs)

def create_full_pipeline(device: str = "auto", **kwargs) -> Dict[str, RealGitHubStepCreationResult]:
    """ì‹¤ì œ GitHub ì „ì²´ íŒŒì´í”„ë¼ì¸ ìƒì„±"""
    factory = get_global_step_factory()
    return factory.create_full_pipeline(device, **kwargs)

def get_step_factory_statistics() -> Dict[str, Any]:
    """ì‹¤ì œ GitHub StepFactory í†µê³„ ì¡°íšŒ"""
    factory = get_global_step_factory()
    return factory.get_statistics()

def clear_step_factory_cache():
    """ì‹¤ì œ GitHub StepFactory ìºì‹œ ì •ë¦¬"""
    factory = get_global_step_factory()
    factory.clear_cache()

# ==============================================
# ğŸ”¥ Step ë“±ë¡ ê´€ë¦¬ í•¨ìˆ˜ë“¤ (ê¸°ì¡´ ìœ ì§€)
# ==============================================

def register_step_globally(step_id: str, step_class: Type['BaseStepMixin']) -> bool:
    """ì „ì—­ ì‹¤ì œ GitHub StepFactoryì— Step ë“±ë¡"""
    factory = get_global_step_factory()
    return factory.register_step(step_id, step_class)

def unregister_step_globally(step_id: str) -> bool:
    """ì „ì—­ ì‹¤ì œ GitHub StepFactoryì—ì„œ Step ë“±ë¡ í•´ì œ"""
    factory = get_global_step_factory()
    return factory.unregister_step(step_id)

def get_registered_steps_globally() -> Dict[str, str]:
    """ì „ì—­ ì‹¤ì œ GitHub StepFactory ë“±ë¡ëœ Step ëª©ë¡ ì¡°íšŒ"""
    factory = get_global_step_factory()
    return factory.get_registered_steps()

def is_step_registered_globally(step_id: str) -> bool:
    """ì „ì—­ ì‹¤ì œ GitHub StepFactory Step ë“±ë¡ ì—¬ë¶€ í™•ì¸"""
    factory = get_global_step_factory()
    return factory.is_step_registered(step_id)

# ==============================================
# ğŸ”¥ DetailedDataSpec ì „ìš© í¸ì˜ í•¨ìˆ˜ë“¤ (ê¸°ì¡´ ìœ ì§€)
# ==============================================

def get_step_api_mappings(step_type: Union[StepType, str]) -> Dict[str, Any]:
    """Stepë³„ API ë§¤í•‘ ì •ë³´ ì¡°íšŒ"""
    factory = get_global_step_factory()
    return factory.get_step_api_mappings(step_type)

def get_step_data_flow(step_type: Union[StepType, str]) -> Dict[str, Any]:
    """Stepë³„ ë°ì´í„° íë¦„ ì •ë³´ ì¡°íšŒ"""
    factory = get_global_step_factory()
    return factory.get_step_data_flow(step_type)

def get_step_preprocessing_config(step_type: Union[StepType, str]) -> Dict[str, Any]:
    """Stepë³„ ì „ì²˜ë¦¬ ì„¤ì • ì¡°íšŒ"""
    factory = get_global_step_factory()
    return factory.get_step_preprocessing_config(step_type)

def get_step_postprocessing_config(step_type: Union[StepType, str]) -> Dict[str, Any]:
    """Stepë³„ í›„ì²˜ë¦¬ ì„¤ì • ì¡°íšŒ"""
    factory = get_global_step_factory()
    return factory.get_step_postprocessing_config(step_type)

def validate_step_data_compatibility(from_step: Union[StepType, str], to_step: Union[StepType, str]) -> Dict[str, Any]:
    """Step ê°„ ë°ì´í„° í˜¸í™˜ì„± ê²€ì¦"""
    factory = get_global_step_factory()
    return factory.validate_step_data_compatibility(from_step, to_step)

def get_pipeline_data_flow_analysis() -> Dict[str, Any]:
    """ì „ì²´ íŒŒì´í”„ë¼ì¸ ë°ì´í„° íë¦„ ë¶„ì„"""
    factory = get_global_step_factory()
    return factory.get_pipeline_data_flow_analysis()

# ==============================================
# ğŸ”¥ ì‹¤ì œ AI ëª¨ë¸ ì •ë³´ í¸ì˜ í•¨ìˆ˜ë“¤ (ìƒˆë¡œ ì¶”ê°€)
# ==============================================

def get_real_ai_model_info(step_type: Union[StepType, str]) -> Dict[str, Any]:
    """ì‹¤ì œ AI ëª¨ë¸ ì •ë³´ ì¡°íšŒ"""
    factory = get_global_step_factory()
    return factory.get_real_ai_model_info(step_type)

def get_real_checkpoint_requirements() -> Dict[str, Any]:
    """ì‹¤ì œ ì²´í¬í¬ì¸íŠ¸ ìš”êµ¬ì‚¬í•­ ì¡°íšŒ"""
    factory = get_global_step_factory()
    return factory.get_real_checkpoint_requirements()

# ==============================================
# ğŸ”¥ ì‹¤ì œ conda í™˜ê²½ ìµœì í™” (ê¸°ì¡´ ìœ ì§€)
# ==============================================

def optimize_real_conda_environment():
    """ì‹¤ì œ GitHub conda í™˜ê²½ ìµœì í™”"""
    try:
        if not CONDA_INFO['is_target_env']:
            logger.warning(f"âš ï¸ ì‹¤ì œ GitHub ê¶Œì¥ conda í™˜ê²½ì´ ì•„ë‹˜: {CONDA_INFO['conda_env']} (ê¶Œì¥: mycloset-ai-clean)")
            return False
        
        # ì‹¤ì œ GitHub PyTorch conda ìµœì í™”
        try:
            if PYTORCH_AVAILABLE:
                import torch
                if IS_M3_MAX_DETECTED and MPS_AVAILABLE and hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
                    # ì‹¤ì œ GitHub MPS ìºì‹œ ì •ë¦¬
                    if hasattr(torch.backends.mps, 'empty_cache'):
                        torch.backends.mps.empty_cache()
                    logger.info("ğŸ ì‹¤ì œ GitHub M3 Max MPS ìµœì í™” í™œì„±í™” (DetailedDataSpec ì§€ì›)")
                
                # ì‹¤ì œ GitHub CPU ìŠ¤ë ˆë“œ ìµœì í™”
                cpu_count = os.cpu_count()
                torch.set_num_threads(max(1, cpu_count // 2))
                logger.info(f"ğŸ§µ ì‹¤ì œ GitHub PyTorch ìŠ¤ë ˆë“œ ìµœì í™”: {torch.get_num_threads()}/{cpu_count}")
            
        except ImportError:
            pass
        
        # ì‹¤ì œ GitHub í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
        os.environ['OMP_NUM_THREADS'] = str(max(1, os.cpu_count() // 2))
        os.environ['MKL_NUM_THREADS'] = str(max(1, os.cpu_count() // 2))
        
        logger.info("ğŸ ì‹¤ì œ GitHub conda í™˜ê²½ ìµœì í™” ì™„ë£Œ (DetailedDataSpec ì§€ì›)")
        return True
        
    except Exception as e:
        logger.warning(f"âš ï¸ ì‹¤ì œ GitHub conda í™˜ê²½ ìµœì í™” ì‹¤íŒ¨: {e}")
        return False

# ê¸°ì¡´ í•¨ìˆ˜ëª… í˜¸í™˜ì„± ìœ ì§€
optimize_conda_environment_for_github = optimize_real_conda_environment

# ==============================================
# ğŸ”¥ ì‹¤ì œ GitHub DetailedDataSpec í˜¸í™˜ì„± ê²€ì¦ ë„êµ¬ (ê¸°ì¡´ ìœ ì§€)
# ==============================================

def validate_real_github_step_compatibility(step_instance: 'BaseStepMixin') -> Dict[str, Any]:
    """ì‹¤ì œ GitHub BaseStepMixin v19.2 + DetailedDataSpec Step í˜¸í™˜ì„± ê²€ì¦"""
    try:
        result = {
            'compatible': True,
            'version': 'StepFactory v11.1 ì‹¤ì œ GitHub + DetailedDataSpec (Circular Reference Fix)',
            'basestepmixin_v19_compatible': True,
            'detailed_data_spec_compatible': True,
            'real_ai_structure_compatible': True,
            'issues': [],
            'recommendations': []
        }
        
        # ì‹¤ì œ GitHub í•„ìˆ˜ ì†ì„± í™•ì¸
        required_attrs = ['step_name', 'step_id', 'device', 'is_initialized', 'github_compatible']
        for attr in required_attrs:
            if not hasattr(step_instance, attr):
                result['compatible'] = False
                result['basestepmixin_v19_compatible'] = False
                result['issues'].append(f'ì‹¤ì œ GitHub í•„ìˆ˜ ì†ì„± {attr} ì—†ìŒ')
        
        # ì‹¤ì œ GitHub í•„ìˆ˜ ë©”ì„œë“œ í™•ì¸
        required_methods = ['process', 'initialize']
        for method in required_methods:
            if not hasattr(step_instance, method):
                result['compatible'] = False
                result['basestepmixin_v19_compatible'] = False
                result['issues'].append(f'ì‹¤ì œ GitHub í•„ìˆ˜ ë©”ì„œë“œ {method} ì—†ìŒ')
        
        # DetailedDataSpec ê´€ë ¨ ì†ì„± í™•ì¸
        detailed_data_spec_attrs = ['api_input_mapping', 'api_output_mapping']
        detailed_data_spec_found = 0
        for attr in detailed_data_spec_attrs:
            if hasattr(step_instance, attr):
                detailed_data_spec_found += 1
        
        if detailed_data_spec_found == 0:
            result['detailed_data_spec_compatible'] = False
            result['issues'].append('DetailedDataSpec API ë§¤í•‘ ì†ì„± ì—†ìŒ')
            result['recommendations'].append('DetailedDataSpec API ë§¤í•‘ ì„¤ì • í•„ìš”')
        
        # ì‹¤ì œ AI êµ¬ì¡° ê´€ë ¨ ì†ì„± í™•ì¸
        real_ai_attrs = ['real_ai_structure_integrated', 'model_loader']
        real_ai_found = 0
        for attr in real_ai_attrs:
            if hasattr(step_instance, attr):
                real_ai_found += 1
        
        if real_ai_found == 0:
            result['real_ai_structure_compatible'] = False
            result['issues'].append('ì‹¤ì œ AI êµ¬ì¡° í†µí•© ì†ì„± ì—†ìŒ')
            result['recommendations'].append('ì‹¤ì œ AI êµ¬ì¡° í†µí•© í•„ìš”')
        
        # ì‹¤ì œ GitHub BaseStepMixin v19.2 ìƒì† í™•ì¸
        mro_names = [cls.__name__ for cls in step_instance.__class__.__mro__]
        if 'BaseStepMixin' not in mro_names:
            result['recommendations'].append('ì‹¤ì œ GitHub BaseStepMixin v19.2 ìƒì† ê¶Œì¥')
        
        # ì‹¤ì œ GitHub ì˜ì¡´ì„± ì£¼ì… ìƒíƒœ í™•ì¸
        dependency_attrs = ['model_loader', 'memory_manager', 'data_converter', 'dependency_manager']
        injected_deps = []
        for attr in dependency_attrs:
            if hasattr(step_instance, attr) and getattr(step_instance, attr) is not None:
                injected_deps.append(attr)
        
        result['injected_dependencies'] = injected_deps
        result['dependency_injection_score'] = len(injected_deps) / len(dependency_attrs)
        
        # ì‹¤ì œ GitHub íŠ¹ë³„ ì†ì„± í™•ì¸
        if hasattr(step_instance, 'github_compatible') and getattr(step_instance, 'github_compatible'):
            result['github_mode'] = True
        else:
            result['recommendations'].append('github_compatible=True ì„¤ì • ê¶Œì¥')
        
        # DetailedDataSpec ë¡œë”© ìƒíƒœ í™•ì¸
        if hasattr(step_instance, 'detailed_data_spec_loaded') and getattr(step_instance, 'detailed_data_spec_loaded'):
            result['detailed_data_spec_loaded'] = True
        else:
            result['recommendations'].append('DetailedDataSpec ë¡œë”© ìƒíƒœ í™•ì¸ í•„ìš”')
        
        # ì‹¤ì œ AI êµ¬ì¡° í†µí•© ìƒíƒœ í™•ì¸
        if hasattr(step_instance, 'real_ai_structure_integrated') and getattr(step_instance, 'real_ai_structure_integrated'):
            result['real_ai_structure_integrated'] = True
        else:
            result['recommendations'].append('ì‹¤ì œ AI êµ¬ì¡° í†µí•© ìƒíƒœ í™•ì¸ í•„ìš”')
        
        return result
        
    except Exception as e:
        return {
            'compatible': False,
            'basestepmixin_v19_compatible': False,
            'detailed_data_spec_compatible': False,
            'real_ai_structure_compatible': False,
            'error': str(e),
            'version': 'StepFactory v11.1 ì‹¤ì œ GitHub + DetailedDataSpec (Circular Reference Fix)'
        }

def get_real_github_step_info(step_instance: 'BaseStepMixin') -> Dict[str, Any]:
    """ì‹¤ì œ GitHub BaseStepMixin v19.2 + DetailedDataSpec Step ì •ë³´ ì¡°íšŒ"""
    try:
        info = {
            'step_name': getattr(step_instance, 'step_name', 'Unknown'),
            'step_id': getattr(step_instance, 'step_id', 0),
            'class_name': step_instance.__class__.__name__,
            'module': step_instance.__class__.__module__,
            'device': getattr(step_instance, 'device', 'Unknown'),
            'is_initialized': getattr(step_instance, 'is_initialized', False),
            'github_compatible': getattr(step_instance, 'github_compatible', False),
            'has_model': getattr(step_instance, 'has_model', False),
            'model_loaded': getattr(step_instance, 'model_loaded', False),
            'real_ai_structure_integrated': getattr(step_instance, 'real_ai_structure_integrated', False)
        }
        
        # ì‹¤ì œ GitHub ì˜ì¡´ì„± ìƒíƒœ
        dependencies = {}
        for dep_name in ['model_loader', 'memory_manager', 'data_converter', 'di_container', 'dependency_manager']:
            dependencies[dep_name] = hasattr(step_instance, dep_name) and getattr(step_instance, dep_name) is not None
        
        info['dependencies'] = dependencies
        
        # DetailedDataSpec ìƒíƒœ
        detailed_data_spec_info = {}
        for attr_name in ['api_input_mapping', 'api_output_mapping', 'preprocessing_steps', 'postprocessing_steps']:
            detailed_data_spec_info[attr_name] = hasattr(step_instance, attr_name)
        
        info['detailed_data_spec'] = detailed_data_spec_info
        info['detailed_data_spec_loaded'] = getattr(step_instance, 'detailed_data_spec_loaded', False)
        
        # ì‹¤ì œ GitHub BaseStepMixin v19.2 íŠ¹ì • ì†ì„±ë“¤
        if hasattr(step_instance, 'dependency_manager'):
            dep_manager = step_instance.dependency_manager
            if hasattr(dep_manager, 'get_github_status'):
                try:
                    info['github_dependency_manager_status'] = dep_manager.get_github_status()
                except:
                    info['github_dependency_manager_status'] = 'error'
        
        # ì‹¤ì œ AI ëª¨ë¸ ìƒíƒœ
        if hasattr(step_instance, 'model_loader'):
            model_loader = step_instance.model_loader
            try:
                if hasattr(model_loader, 'get_loaded_models'):
                    info['loaded_models'] = model_loader.get_loaded_models()
                elif hasattr(model_loader, 'list_loaded_models'):
                    info['loaded_models'] = model_loader.list_loaded_models()
                else:
                    info['loaded_models'] = []
            except:
                info['loaded_models'] = []
        
        return info
        
    except Exception as e:
        return {'error': str(e)}

# ê¸°ì¡´ í•¨ìˆ˜ëª… í˜¸í™˜ì„± ìœ ì§€
validate_github_step_compatibility = validate_real_github_step_compatibility
get_github_step_info = get_real_github_step_info

# ==============================================
# ğŸ”¥ í˜¸í™˜ì„± ë³„ì¹­ë“¤ (ê¸°ì¡´ ì½”ë“œ í˜¸í™˜ì„± ìœ ì§€)
# ==============================================

# Enhanced â†’ Real ë³„ì¹­ (ê¸°ì¡´ ì½”ë“œ í˜¸í™˜ì„±)
EnhancedGitHubStepClassLoader = RealGitHubStepClassLoader
EnhancedGitHubDependencyResolver = RealGitHubDependencyResolver
EnhancedGitHubStepMapping = RealGitHubStepMapping
EnhancedGitHubStepConfig = RealGitHubStepConfig
GitHubStepCreationResult = RealGitHubStepCreationResult

# ==============================================
# ğŸ”¥ Export (ê¸°ì¡´ ìœ ì§€)
# ==============================================

__all__ = [
    # ë©”ì¸ í´ë˜ìŠ¤ë“¤ (ì‹¤ì œ êµ¬ì¡°)
    'StepFactory',
    'RealGitHubStepClassLoader', 
    'RealGitHubDependencyResolver',
    'RealGitHubStepMapping',
    
    # í˜¸í™˜ì„± ë³„ì¹­ë“¤
    'EnhancedGitHubStepClassLoader',
    'EnhancedGitHubDependencyResolver', 
    'EnhancedGitHubStepMapping',
    
    # ë°ì´í„° êµ¬ì¡°ë“¤ (ì‹¤ì œ êµ¬ì¡°)
    'StepType',
    'StepPriority', 
    'RealGitHubStepConfig',
    'RealAIModelConfig',
    'DetailedDataSpecConfig',
    'RealGitHubStepCreationResult',
    
    # í˜¸í™˜ì„± ë³„ì¹­ë“¤
    'EnhancedGitHubStepConfig',
    'GitHubStepCreationResult',
    
    # ì „ì—­ í•¨ìˆ˜ë“¤
    'get_global_step_factory',
    'reset_global_step_factory',
    
    # Step ìƒì„± í•¨ìˆ˜ë“¤ (DetailedDataSpec í†µí•©)
    'create_step',
    'create_human_parsing_step',
    'create_pose_estimation_step', 
    'create_cloth_segmentation_step',
    'create_geometric_matching_step',
    'create_cloth_warping_step',
    'create_virtual_fitting_step',
    'create_post_processing_step',
    'create_quality_assessment_step',
    'create_full_pipeline',
    
    # ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
    'get_step_factory_statistics',
    'clear_step_factory_cache',
    'optimize_real_conda_environment',
    'optimize_conda_environment_for_github',  # í˜¸í™˜ì„± ë³„ì¹­
    
    # ì‹¤ì œ GitHub BaseStepMixin v19.2 + DetailedDataSpec í˜¸í™˜ì„± ë„êµ¬ë“¤
    'validate_real_github_step_compatibility',
    'get_real_github_step_info',
    'validate_github_step_compatibility',  # í˜¸í™˜ì„± ë³„ì¹­
    'get_github_step_info',  # í˜¸í™˜ì„± ë³„ì¹­
    
    # Step ë“±ë¡ ê´€ë¦¬ í•¨ìˆ˜ë“¤
    'register_step_globally',
    'unregister_step_globally', 
    'get_registered_steps_globally',
    'is_step_registered_globally',
    
    # DetailedDataSpec ì „ìš© í•¨ìˆ˜ë“¤
    'get_step_api_mappings',
    'get_step_data_flow',
    'get_step_preprocessing_config',
    'get_step_postprocessing_config',
    'validate_step_data_compatibility',
    'get_pipeline_data_flow_analysis',
    
    # ì‹¤ì œ AI ëª¨ë¸ ì •ë³´ í•¨ìˆ˜ë“¤ (ìƒˆë¡œ ì¶”ê°€)
    'get_real_ai_model_info',
    'get_real_checkpoint_requirements',
    
    # ìƒìˆ˜ë“¤
    'CONDA_INFO',
    'IS_M3_MAX_DETECTED', 
    'MEMORY_GB',
    'STEP_MODEL_REQUIREMENTS',
    'REAL_STEP_INTERFACE_AVAILABLE'
]

# ==============================================
# ğŸ”¥ ëª¨ë“ˆ ì´ˆê¸°í™” (ì‹¤ì œ êµ¬ì¡°, ìˆœí™˜ì°¸ì¡° í•´ê²°)
# ==============================================

logger.info("ğŸ”¥ StepFactory v11.1 - ì‹¤ì œ AI êµ¬ì¡° ì™„ì „ ë°˜ì˜ + ìˆœí™˜ì°¸ì¡° ì™„ì „ í•´ê²° + DetailedDataSpec ì™„ì „ í†µí•© + BaseStepMixin v19.2 ì™„ì „ í˜¸í™˜ ë¡œë“œ ì™„ë£Œ!")
logger.info("âœ… ì£¼ìš” ê°œì„ ì‚¬í•­:")
logger.info("   - step_interface.py v5.2ì˜ ì‹¤ì œ AI ëª¨ë¸ êµ¬ì¡° ì™„ì „ ë°˜ì˜")
logger.info("   - RealAIModelConfig ì‹¤ì œ 229GB íŒŒì¼ ë§¤í•‘ ì ìš©")
logger.info("   - Real í´ë˜ìŠ¤ êµ¬ì¡° í†µí•© (RealGitHub*)")
logger.info("   - ì‹¤ì œ ì²´í¬í¬ì¸íŠ¸ ë¡œë”© ê¸°ëŠ¥ êµ¬í˜„")
logger.info("   - TYPE_CHECKING + ì§€ì—° importë¡œ ìˆœí™˜ì°¸ì¡° ì™„ì „ í•´ê²°")
logger.info("   - step_model_requirements.pyì˜ DetailedDataSpec ì™„ì „ í™œìš© (ê¸°ì¡´ ê¸°ëŠ¥ 100% ìœ ì§€)")
logger.info("   - API ì…ì¶œë ¥ ë§¤í•‘ (api_input_mapping, api_output_mapping) ìë™ ì²˜ë¦¬")
logger.info("   - Step ê°„ ë°ì´í„° íë¦„ (provides_to_next_step, accepts_from_previous_step) ìë™ ê´€ë¦¬")
logger.info("   - ì „ì²˜ë¦¬/í›„ì²˜ë¦¬ ìš”êµ¬ì‚¬í•­ ìë™ ì ìš©")
logger.info("   - FastAPI ë¼ìš°í„° 100% í˜¸í™˜ì„± í™•ë³´")
logger.info("   - BaseStepMixin v19.2 í‘œì¤€ ì™„ì „ í˜¸í™˜")
logger.info("   - ëª¨ë“  í•¨ìˆ˜ëª…, ë©”ì„œë“œëª…, í´ë˜ìŠ¤ëª… 100% ìœ ì§€")

logger.info(f"ğŸ”§ í˜„ì¬ í™˜ê²½:")
logger.info(f"   - conda í™˜ê²½: {CONDA_INFO['conda_env']} ({'âœ… ìµœì í™”ë¨' if CONDA_INFO['is_target_env'] else 'âš ï¸ ê¶Œì¥: mycloset-ai-clean'})")
logger.info(f"   - M3 Max: {'âœ…' if IS_M3_MAX_DETECTED else 'âŒ'}")
logger.info(f"   - ë©”ëª¨ë¦¬: {MEMORY_GB:.1f}GB")
logger.info(f"   - step_model_requirements.py: {'âœ… ë¡œë”©ë¨' if STEP_MODEL_REQUIREMENTS else 'âŒ ë¡œë”© ì‹¤íŒ¨'}")
logger.info(f"   - step_interface.py v5.2: {'âœ… ì‚¬ìš© ê°€ëŠ¥' if REAL_STEP_INTERFACE_AVAILABLE else 'âŒ í´ë°± ëª¨ë“œ'}")
logger.info(f"   - MPS ê°€ì†: {'âœ…' if MPS_AVAILABLE and REAL_STEP_INTERFACE_AVAILABLE else 'âŒ'}")
logger.info(f"   - PyTorch: {'âœ…' if PYTORCH_AVAILABLE and REAL_STEP_INTERFACE_AVAILABLE else 'âŒ'}")

logger.info("ğŸ¯ ì§€ì› Step í´ë˜ìŠ¤ (ì‹¤ì œ AI ëª¨ë¸ 229GB + DetailedDataSpec ì™„ì „ í†µí•©):")
for step_type in StepType:
    config = RealGitHubStepMapping.get_enhanced_github_config(step_type)
    api_input_count = len(config.detailed_data_spec.api_input_mapping)
    api_output_count = len(config.detailed_data_spec.api_output_mapping)
    real_ai_models_count = len(config.real_ai_models)
    checkpoint_count = len([model for model in config.real_ai_models if model.requires_checkpoint])
    logger.info(f"   - {config.class_name} (Step {config.step_id:02d}) - {config.model_size_gb}GB")
    logger.info(f"     API: {api_input_count}ì…ë ¥â†’{api_output_count}ì¶œë ¥, ì‹¤ì œ AI: {real_ai_models_count}ê°œ, ì²´í¬í¬ì¸íŠ¸: {checkpoint_count}ê°œ")
    logger.info(f"     ì „ì²˜ë¦¬: {'âœ…' if config.detailed_data_spec.preprocessing_required else 'âŒ'}, í›„ì²˜ë¦¬: {'âœ…' if config.detailed_data_spec.postprocessing_required else 'âŒ'}")

# ì‹¤ì œ AI ëª¨ë¸ í†µê³„
total_real_models = sum(len(config.real_ai_models) for config in RealGitHubStepMapping.REAL_GITHUB_STEP_CONFIGS.values())
total_checkpoints = sum(len([model for model in config.real_ai_models if model.requires_checkpoint]) for config in RealGitHubStepMapping.REAL_GITHUB_STEP_CONFIGS.values())
total_size_gb = sum(config.model_size_gb for config in RealGitHubStepMapping.REAL_GITHUB_STEP_CONFIGS.values())

logger.info("ğŸ“Š ì‹¤ì œ AI ëª¨ë¸ í†µê³„:")
logger.info(f"   - ì´ ì‹¤ì œ AI ëª¨ë¸: {total_real_models}ê°œ")
logger.info(f"   - ì´ ì²´í¬í¬ì¸íŠ¸: {total_checkpoints}ê°œ")
logger.info(f"   - ì´ ëª¨ë¸ í¬ê¸°: {total_size_gb:.1f}GB")
logger.info(f"   - M3 Max 128GB í˜¸í™˜ì„±: {'âœ…' if total_size_gb <= 100.0 else 'âŒ'}")

# conda í™˜ê²½ ìë™ ìµœì í™” (DetailedDataSpec ì§€ì›)
if CONDA_INFO['is_target_env']:
    optimize_real_conda_environment()
    logger.info("ğŸ ì‹¤ì œ GitHub conda í™˜ê²½ ìë™ ìµœì í™” ì™„ë£Œ! (DetailedDataSpec ì§€ì›)")
else:
    logger.warning(f"âš ï¸ conda í™˜ê²½ì„ í™•ì¸í•˜ì„¸ìš”: conda activate mycloset-ai-clean")

# ì´ˆê¸° ë©”ëª¨ë¦¬ ìµœì í™”
if IS_M3_MAX_DETECTED:
    try:
        if MPS_AVAILABLE and PYTORCH_AVAILABLE:
            import torch
            if hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
                if hasattr(torch.backends.mps, 'empty_cache'):
                    torch.backends.mps.empty_cache()
        gc.collect()
        logger.info("ğŸ M3 Max ì´ˆê¸° ë©”ëª¨ë¦¬ ìµœì í™” ì™„ë£Œ! (ì‹¤ì œ AI êµ¬ì¡° + DetailedDataSpec ì§€ì›)")
    except:
        pass

logger.info("ğŸš€ StepFactory v11.1 ì™„ì „ ì¤€ë¹„ ì™„ë£Œ! (ì‹¤ì œ AI êµ¬ì¡° ì™„ì „ ë°˜ì˜ + ìˆœí™˜ì°¸ì¡° ì™„ì „ í•´ê²° + DetailedDataSpec ì™„ì „ í†µí•© + BaseStepMixin v19.2) ğŸš€")
logger.info("ğŸ’¡ ì´ì œ step_interface.py v5.2ì˜ ì‹¤ì œ AI ëª¨ë¸ êµ¬ì¡°ê°€ ì™„ì „íˆ ë°˜ì˜ë˜ì—ˆìŠµë‹ˆë‹¤!")
logger.info("ğŸ’¡ ì‹¤ì œ 229GB AI ëª¨ë¸ íŒŒì¼ë“¤ê³¼ ì •í™•íˆ ë§¤í•‘ë˜ì–´ ì§„ì •í•œ AI íŒŒì´í”„ë¼ì¸ íŒ©í† ë¦¬ë¡œ ë™ì‘í•©ë‹ˆë‹¤!")
logger.info("ğŸ’¡ step_model_requirements.pyì˜ DetailedDataSpecì„ ì™„ì „íˆ í™œìš©í•©ë‹ˆë‹¤!")
logger.info("ğŸ’¡ API ì…ì¶œë ¥ ë§¤í•‘, Step ê°„ ë°ì´í„° íë¦„, ì „ì²˜ë¦¬/í›„ì²˜ë¦¬ê°€ ìë™ìœ¼ë¡œ ì ìš©ë©ë‹ˆë‹¤!")
logger.info("ğŸ’¡ FastAPI ë¼ìš°í„°ì™€ 100% í˜¸í™˜ë˜ë©°, ëª¨ë“  ë°ì´í„° ë³€í™˜ì´ ìë™í™”ë˜ì—ˆìŠµë‹ˆë‹¤!")
logger.info("ğŸ’¡ ğŸ”¥ ì‹¤ì œ ì²´í¬í¬ì¸íŠ¸ ë¡œë”©ê³¼ ê²€ì¦ ê¸°ëŠ¥ì´ êµ¬í˜„ë˜ì—ˆìŠµë‹ˆë‹¤!")
logger.info("ğŸ’¡ ğŸ”¥ TYPE_CHECKING + ì§€ì—° importë¡œ ìˆœí™˜ì°¸ì¡° ì™„ì „ í•´ê²°!")
logger.info("ğŸ’¡ ğŸ”¥ ëª¨ë“  ê¸°ì¡´ í•¨ìˆ˜ëª…, ë©”ì„œë“œëª…, í´ë˜ìŠ¤ëª… 100% ìœ ì§€!")
logger.info("ğŸ’¡ ğŸ”¥ Real* í´ë˜ìŠ¤ë¡œ ì‹¤ì œ êµ¬ì¡°ë¥¼ ë°˜ì˜í•˜ë©´ì„œ Enhanced* ë³„ì¹­ìœ¼ë¡œ í˜¸í™˜ì„± í™•ë³´!")
logger.info("=" * 100)