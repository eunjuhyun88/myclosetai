# backend/app/ai_pipeline/factories/step_factory.py
"""
ğŸ”¥ StepFactory v7.0 - ì‹¤ì œ Step í´ë˜ìŠ¤ ì—°ë™ ìˆ˜ì • (ë™ì‘ ë³´ì¥)
================================================================

âœ… ì‹¤ì œ Step í´ë˜ìŠ¤ ë§¤í•‘ ìˆ˜ì •: HumanParsingStep, PoseEstimationStep ë“±
âœ… ë™ì  import ë¡œì§ ì™„ì „ ê°œì„ 
âœ… BaseStepMixin ì˜ì¡´ì„± ì£¼ì… íŒ¨í„´ ì™„ì „ í˜¸í™˜
âœ… í´ë°± ì œê±° - ì‹¤ì œ ë™ì‘ë§Œ
âœ… ì—ëŸ¬ ì²˜ë¦¬ ê°•í™” ë° ë””ë²„ê¹… ë¡œì§ ì¶”ê°€
âœ… conda í™˜ê²½ ìš°ì„  ìµœì í™” (mycloset-ai-clean)
âœ… M3 Max 128GB ë©”ëª¨ë¦¬ ìµœì í™”
âœ… TYPE_CHECKING íŒ¨í„´ìœ¼ë¡œ ìˆœí™˜ì°¸ì¡° ì™„ì „ ë°©ì§€

í•µì‹¬ ìˆ˜ì •ì‚¬í•­:
1. Step í´ë˜ìŠ¤ ë§¤í•‘ ìˆ˜ì •: Mixin â†’ ì‹¤ì œ Step í´ë˜ìŠ¤
2. import ê²½ë¡œ ìˆ˜ì •: app.ai_pipeline.steps.step_XX_name
3. ë™ì  import ì¬ì‹œë„ ë¡œì§ ê°•í™”
4. BaseStepMixin ì˜ì¡´ì„± ì£¼ì… ê°œì„ 

Author: MyCloset AI Team
Date: 2025-07-25
Version: 7.0 (Real Step Class Connection Fix)
"""

import os
import logging
import asyncio
import threading
import time
import weakref
import gc
import subprocess
import platform
from pathlib import Path
from typing import Dict, Any, Optional, List, Union, Type, Callable, TYPE_CHECKING
from dataclasses import dataclass, field
from enum import Enum, IntEnum
from abc import ABC, abstractmethod
from concurrent.futures import ThreadPoolExecutor, as_completed

# ğŸ”¥ TYPE_CHECKINGìœ¼ë¡œ ìˆœí™˜ì°¸ì¡° ì™„ì „ ë°©ì§€
if TYPE_CHECKING:
    from ..steps.base_step_mixin import BaseStepMixin
    from ..utils.model_loader import ModelLoader
    from ..utils.memory_manager import MemoryManager
    from ..utils.data_converter import DataConverter
    from ..core.di_container import DIContainer

# ==============================================
# ğŸ”¥ í™˜ê²½ ì„¤ì • ë° ë¡œê¹…
# ==============================================

logger = logging.getLogger(__name__)

# conda í™˜ê²½ ì •ë³´
CONDA_INFO = {
    'conda_env': os.environ.get('CONDA_DEFAULT_ENV', 'none'),
    'conda_prefix': os.environ.get('CONDA_PREFIX', 'none'),
    'is_target_env': os.environ.get('CONDA_DEFAULT_ENV') == 'mycloset-ai-clean'
}

# M3 Max ê°ì§€
IS_M3_MAX = False
MEMORY_GB = 16.0

try:
    if platform.system() == 'Darwin':
        result = subprocess.run(
            ['sysctl', '-n', 'machdep.cpu.brand_string'],
            capture_output=True, text=True, timeout=5
        )
        IS_M3_MAX = 'M3' in result.stdout
        
        # ë©”ëª¨ë¦¬ ì •ë³´
        memory_result = subprocess.run(
            ['sysctl', '-n', 'hw.memsize'],
            capture_output=True, text=True, timeout=5
        )
        if memory_result.stdout.strip():
            MEMORY_GB = int(memory_result.stdout.strip()) / 1024**3
except:
    pass

# ==============================================
# ğŸ”¥ Step íƒ€ì… ë° ì„¤ì • ì •ì˜
# ==============================================

class StepType(Enum):
    """Step íƒ€ì… (ì‹¤ì œ íŒŒì¼ êµ¬ì¡° ê¸°ë°˜)"""
    HUMAN_PARSING = "human_parsing"
    POSE_ESTIMATION = "pose_estimation"
    CLOTH_SEGMENTATION = "cloth_segmentation"
    GEOMETRIC_MATCHING = "geometric_matching"
    CLOTH_WARPING = "cloth_warping"
    VIRTUAL_FITTING = "virtual_fitting"
    POST_PROCESSING = "post_processing"
    QUALITY_ASSESSMENT = "quality_assessment"

class StepPriority(IntEnum):
    """Step ìš°ì„ ìˆœìœ„"""
    CRITICAL = 1    # Human Parsing, Virtual Fitting
    HIGH = 2        # Pose Estimation, Cloth Segmentation
    MEDIUM = 3      # Geometric Matching, Cloth Warping
    LOW = 4         # Post Processing, Quality Assessment

@dataclass
class StepConfig:
    """Step ì„¤ì •"""
    step_name: str
    step_id: int
    step_type: StepType
    class_name: str  # ì‹¤ì œ í´ë˜ìŠ¤ëª…: HumanParsingStep, PoseEstimationStep ë“±
    module_path: str  # ì‹¤ì œ ëª¨ë“ˆ ê²½ë¡œ: app.ai_pipeline.steps.step_XX_name
    device: str = "auto"
    use_fp16: bool = True
    batch_size: int = 1
    confidence_threshold: float = 0.8
    auto_memory_cleanup: bool = True
    auto_warmup: bool = True
    optimization_enabled: bool = True
    strict_mode: bool = False
    priority: StepPriority = StepPriority.MEDIUM
    
    # ì˜ì¡´ì„± ì„¤ì •
    require_model_loader: bool = True
    require_memory_manager: bool = False
    require_data_converter: bool = False
    auto_inject_dependencies: bool = True
    
    # AI ëª¨ë¸ ì„¤ì •
    ai_models: List[str] = field(default_factory=list)
    model_size_gb: float = 0.0

@dataclass
class StepCreationResult:
    """Step ìƒì„± ê²°ê³¼"""
    success: bool
    step_instance: Optional['BaseStepMixin'] = None
    step_name: str = ""
    step_type: Optional[StepType] = None
    class_name: str = ""
    module_path: str = ""
    dependencies_injected: Dict[str, bool] = field(default_factory=dict)
    initialization_time: float = 0.0
    error_message: Optional[str] = None
    warnings: List[str] = field(default_factory=list)
    ai_models_loaded: List[str] = field(default_factory=list)

@dataclass
class DependencyBundle:
    """ì˜ì¡´ì„± ë²ˆë“¤"""
    model_loader: Optional['ModelLoader'] = None
    memory_manager: Optional['MemoryManager'] = None
    data_converter: Optional['DataConverter'] = None
    di_container: Optional['DIContainer'] = None

# ==============================================
# ğŸ”¥ ì‹¤ì œ Step í´ë˜ìŠ¤ ë§¤í•‘ í…Œì´ë¸” (ìˆ˜ì •ë¨)
# ==============================================

class RealStepMapping:
    """ì‹¤ì œ Step í´ë˜ìŠ¤ ë§¤í•‘ (ìˆ˜ì •ëœ ë²„ì „)"""
    
    # ğŸ”¥ í•µì‹¬ ìˆ˜ì •: ì‹¤ì œ í´ë˜ìŠ¤ëª…ìœ¼ë¡œ ë§¤í•‘
    STEP_MAPPING = {
        StepType.HUMAN_PARSING: {
            'step_id': 1,
            'class_name': 'HumanParsingStep',  # âœ… ì‹¤ì œ í´ë˜ìŠ¤ëª…
            'module_path': 'app.ai_pipeline.steps.step_01_human_parsing',
            'ai_models': ['human_parsing_schp_atr', 'graphonomy'],
            'model_size_gb': 4.0,
            'priority': StepPriority.CRITICAL,
            'description': 'ì¸ì²´ íŒŒì‹± ë° ì‹ ì²´ ë¶€ìœ„ ë¶„í• '
        },
        StepType.POSE_ESTIMATION: {
            'step_id': 2,
            'class_name': 'PoseEstimationStep',  # âœ… ì‹¤ì œ í´ë˜ìŠ¤ëª…
            'module_path': 'app.ai_pipeline.steps.step_02_pose_estimation',
            'ai_models': ['pose_estimation_openpose', 'yolov8_pose', 'diffusion_pose'],
            'model_size_gb': 3.4,
            'priority': StepPriority.HIGH,
            'description': 'ì¸ì²´ í¬ì¦ˆ ì¶”ì • ë° í‚¤í¬ì¸íŠ¸ íƒì§€'
        },
        StepType.CLOTH_SEGMENTATION: {
            'step_id': 3,
            'class_name': 'ClothSegmentationStep',  # âœ… ì‹¤ì œ í´ë˜ìŠ¤ëª…
            'module_path': 'app.ai_pipeline.steps.step_03_cloth_segmentation',
            'ai_models': ['cloth_segmentation_u2net', 'sam_huge', 'mobile_sam'],
            'model_size_gb': 5.5,
            'priority': StepPriority.HIGH,
            'description': 'ì˜ë¥˜ ë¶„í•  ë° ë°°ê²½ ì œê±°'
        },
        StepType.GEOMETRIC_MATCHING: {
            'step_id': 4,
            'class_name': 'GeometricMatchingStep',  # âœ… ì‹¤ì œ í´ë˜ìŠ¤ëª…
            'module_path': 'app.ai_pipeline.steps.step_04_geometric_matching',
            'ai_models': ['geometric_matching_gmm', 'tps_network'],
            'model_size_gb': 1.3,
            'priority': StepPriority.MEDIUM,
            'description': 'ê¸°í•˜í•™ì  ë§¤ì¹­ ë° ë³€í˜•'
        },
        StepType.CLOTH_WARPING: {
            'step_id': 5,
            'class_name': 'ClothWarpingStep',  # âœ… ì‹¤ì œ í´ë˜ìŠ¤ëª…
            'module_path': 'app.ai_pipeline.steps.step_05_cloth_warping',
            'ai_models': ['cloth_warping_tps', 'stable_diffusion'],
            'model_size_gb': 7.0,
            'priority': StepPriority.MEDIUM,
            'description': 'ì˜ë¥˜ ì›Œí•‘ ë° ë³€í˜•'
        },
        StepType.VIRTUAL_FITTING: {
            'step_id': 6,
            'class_name': 'VirtualFittingStep',  # âœ… ì‹¤ì œ í´ë˜ìŠ¤ëª…
            'module_path': 'app.ai_pipeline.steps.step_06_virtual_fitting',
            'ai_models': ['virtual_fitting_ootd', 'hr_viton', 'diffusion_xl'],
            'model_size_gb': 14.0,
            'priority': StepPriority.CRITICAL,
            'description': 'ê°€ìƒ í”¼íŒ… ë° ì´ë¯¸ì§€ í•©ì„±'
        },
        StepType.POST_PROCESSING: {
            'step_id': 7,
            'class_name': 'PostProcessingStep',  # âœ… ì‹¤ì œ í´ë˜ìŠ¤ëª…
            'module_path': 'app.ai_pipeline.steps.step_07_post_processing',
            'ai_models': ['super_resolution', 'denoising'],
            'model_size_gb': 1.3,
            'priority': StepPriority.LOW,
            'description': 'í›„ì²˜ë¦¬ ë° í’ˆì§ˆ ê°œì„ '
        },
        StepType.QUALITY_ASSESSMENT: {
            'step_id': 8,
            'class_name': 'QualityAssessmentStep',  # âœ… ì‹¤ì œ í´ë˜ìŠ¤ëª…
            'module_path': 'app.ai_pipeline.steps.step_08_quality_assessment',
            'ai_models': ['quality_assessment_vit', 'perceptual_loss'],
            'model_size_gb': 7.0,
            'priority': StepPriority.LOW,
            'description': 'í’ˆì§ˆ í‰ê°€ ë° ë¶„ì„'
        }
    }
    
    @classmethod
    def get_step_config(cls, step_type: StepType, **kwargs) -> StepConfig:
        """Step ì„¤ì • ìƒì„±"""
        mapping = cls.STEP_MAPPING.get(step_type)
        if not mapping:
            raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” Step íƒ€ì…: {step_type}")
        
        config = StepConfig(
            step_name=f"{mapping['class_name']}",
            step_id=mapping['step_id'],
            step_type=step_type,
            class_name=mapping['class_name'],
            module_path=mapping['module_path'],
            ai_models=mapping['ai_models'].copy(),
            model_size_gb=mapping['model_size_gb'],
            priority=mapping['priority'],
            **kwargs
        )
        
        return config
    
    @classmethod
    def get_all_step_configs(cls, **kwargs) -> Dict[StepType, StepConfig]:
        """ëª¨ë“  Step ì„¤ì • ë°˜í™˜"""
        configs = {}
        for step_type in StepType:
            configs[step_type] = cls.get_step_config(step_type, **kwargs)
        return configs

# ==============================================
# ğŸ”¥ ê°•í™”ëœ ì˜ì¡´ì„± í•´ê²°ê¸° v7.0
# ==============================================

class AdvancedDependencyResolver:
    """ê³ ê¸‰ ì˜ì¡´ì„± í•´ê²°ê¸° v7.0 (ì‹¤ì œ Step í´ë˜ìŠ¤ ì—°ë™)"""
    
    def __init__(self):
        self.logger = logging.getLogger("AdvancedDependencyResolver")
        self._resolved_cache: Dict[str, Any] = {}
        self._resolution_lock = threading.RLock()
        self._import_attempts: Dict[str, int] = {}
        self._max_attempts = 5  # ì¬ì‹œë„ íšŸìˆ˜ ì¦ê°€
    
    def resolve_step_class(self, step_config: StepConfig) -> Optional[Type]:
        """ì‹¤ì œ Step í´ë˜ìŠ¤ í•´ê²° (ê°•í™”ëœ ë™ì  import)"""
        cache_key = f"step_class_{step_config.class_name}"
        
        try:
            with self._resolution_lock:
                # ìºì‹œ í™•ì¸
                if cache_key in self._resolved_cache:
                    return self._resolved_cache[cache_key]
                
                # ì¬ì‹œë„ ì œí•œ í™•ì¸
                if self._import_attempts.get(cache_key, 0) >= self._max_attempts:
                    self.logger.error(f"âŒ {step_config.class_name} ì„í¬íŠ¸ ì¬ì‹œë„ í•œê³„ ì´ˆê³¼")
                    return None
                
                # ì„í¬íŠ¸ ì‹œë„ ì¹´ìš´íŠ¸ ì¦ê°€
                self._import_attempts[cache_key] = self._import_attempts.get(cache_key, 0) + 1
                
                self.logger.info(f"ğŸ”„ {step_config.class_name} í´ë˜ìŠ¤ í•´ê²° ì‹œë„ ({self._import_attempts[cache_key]}/{self._max_attempts})")
                
                # ğŸ”¥ ê°•í™”ëœ ë™ì  import ì‹¤í–‰
                StepClass = self._enhanced_import_step_class(step_config)
                
                if StepClass:
                    # í´ë˜ìŠ¤ ê²€ì¦
                    if self._validate_step_class(StepClass, step_config):
                        # ìºì‹œì— ì €ì¥
                        self._resolved_cache[cache_key] = StepClass
                        self.logger.info(f"âœ… {step_config.class_name} í´ë˜ìŠ¤ í•´ê²° ì™„ë£Œ")
                        return StepClass
                    else:
                        self.logger.error(f"âŒ {step_config.class_name} í´ë˜ìŠ¤ ê²€ì¦ ì‹¤íŒ¨")
                
                return None
                
        except Exception as e:
            self.logger.error(f"âŒ {step_config.class_name} í´ë˜ìŠ¤ í•´ê²° ì‹¤íŒ¨: {e}")
            return None
    
    def _enhanced_import_step_class(self, step_config: StepConfig) -> Optional[Type]:
        """ê°•í™”ëœ Step í´ë˜ìŠ¤ import"""
        try:
            self.logger.debug(f"ğŸ” ëª¨ë“ˆ import ì‹œë„: {step_config.module_path}")
            
            # ê¸°ë³¸ import ì‹œë„
            import importlib
            module = importlib.import_module(step_config.module_path)
            
            if module:
                self.logger.debug(f"âœ… ëª¨ë“ˆ import ì„±ê³µ: {step_config.module_path}")
                
                # í´ë˜ìŠ¤ ì¶”ì¶œ
                StepClass = getattr(module, step_config.class_name, None)
                if StepClass:
                    self.logger.debug(f"âœ… í´ë˜ìŠ¤ ì¶”ì¶œ ì„±ê³µ: {step_config.class_name}")
                    return StepClass
                else:
                    self.logger.error(f"âŒ í´ë˜ìŠ¤ë¥¼ ëª¨ë“ˆì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŒ: {step_config.class_name}")
                    
                    # ëª¨ë“ˆì˜ ëª¨ë“  ì†ì„± ë””ë²„ê·¸ ì¶œë ¥
                    available_attrs = [attr for attr in dir(module) if not attr.startswith('_')]
                    self.logger.debug(f"ğŸ” ëª¨ë“ˆ ë‚´ ì‚¬ìš© ê°€ëŠ¥í•œ ì†ì„±ë“¤: {available_attrs}")
            
            return None
                
        except ImportError as e:
            self.logger.warning(f"âš ï¸ ëª¨ë“ˆ import ì‹¤íŒ¨: {step_config.module_path} - {e}")
            
            # ëŒ€ì•ˆ import ê²½ë¡œ ì‹œë„
            alternative_paths = self._get_alternative_import_paths(step_config)
            for alt_path in alternative_paths:
                try:
                    self.logger.debug(f"ğŸ”„ ëŒ€ì•ˆ ê²½ë¡œ ì‹œë„: {alt_path}")
                    alt_module = importlib.import_module(alt_path)
                    StepClass = getattr(alt_module, step_config.class_name, None)
                    if StepClass:
                        self.logger.info(f"âœ… ëŒ€ì•ˆ ê²½ë¡œë¡œ í´ë˜ìŠ¤ ë¡œë“œ ì„±ê³µ: {alt_path}")
                        return StepClass
                except ImportError:
                    continue
            
            return None
        except Exception as e:
            self.logger.error(f"âŒ Step í´ë˜ìŠ¤ import ì˜ˆì™¸: {e}")
            return None
    
    def _get_alternative_import_paths(self, step_config: StepConfig) -> List[str]:
        """ëŒ€ì•ˆ import ê²½ë¡œë“¤ ìƒì„±"""
        alternatives = []
        
        # ê¸°ë³¸ ê²½ë¡œì—ì„œ ë³€í˜•ë“¤ ìƒì„±
        base_module = step_config.module_path
        
        # ì ˆëŒ€ ê²½ë¡œ ì‹œë„
        alternatives.append(f"backend.{base_module}")
        
        # ìƒëŒ€ ê²½ë¡œ ì‹œë„ë“¤
        alternatives.append(base_module.replace('app.ai_pipeline.steps.', ''))
        alternatives.append(f"ai_pipeline.steps.{base_module.split('.')[-1]}")
        
        # step_XX í˜•íƒœ ì‹œë„
        step_number = step_config.step_id
        alternatives.append(f"app.ai_pipeline.steps.step_{step_number:02d}")
        alternatives.append(f"steps.step_{step_number:02d}_{step_config.step_type.value}")
        
        return alternatives
    
    def _validate_step_class(self, StepClass: Type, step_config: StepConfig) -> bool:
        """Step í´ë˜ìŠ¤ ê²€ì¦ (ê°•í™”ë¨)"""
        try:
            # ê¸°ë³¸ í´ë˜ìŠ¤ ê²€ì‚¬
            if not StepClass:
                return False
            
            # í´ë˜ìŠ¤ ì´ë¦„ í™•ì¸
            if StepClass.__name__ != step_config.class_name:
                self.logger.warning(f"âš ï¸ í´ë˜ìŠ¤ ì´ë¦„ ë¶ˆì¼ì¹˜: ì˜ˆìƒ={step_config.class_name}, ì‹¤ì œ={StepClass.__name__}")
            
            # í•„ìˆ˜ ë©”ì„œë“œ í™•ì¸
            required_methods = ['initialize', 'process']
            missing_methods = []
            for method in required_methods:
                if not hasattr(StepClass, method):
                    missing_methods.append(method)
            
            if missing_methods:
                self.logger.warning(f"âš ï¸ {step_config.class_name}ì— í•„ìˆ˜ ë©”ì„œë“œ ì—†ìŒ: {missing_methods}")
            
            # BaseStepMixin ìƒì† í™•ì¸
            try:
                mro = [cls.__name__ for cls in StepClass.__mro__]
                if 'BaseStepMixin' not in mro:
                    self.logger.warning(f"âš ï¸ {step_config.class_name}ì´ BaseStepMixinì„ ìƒì†í•˜ì§€ ì•ŠìŒ")
                else:
                    self.logger.debug(f"âœ… {step_config.class_name} BaseStepMixin ìƒì† í™•ì¸")
            except:
                pass
            
            # ìƒì„±ì í˜¸ì¶œ ê°€ëŠ¥ì„± í…ŒìŠ¤íŠ¸
            try:
                test_instance = StepClass(
                    step_name="test",
                    step_id=step_config.step_id,
                    device="cpu"
                )
                if test_instance:
                    self.logger.debug(f"âœ… {step_config.class_name} ìƒì„±ì í…ŒìŠ¤íŠ¸ ì„±ê³µ")
                    # í…ŒìŠ¤íŠ¸ ì¸ìŠ¤í„´ìŠ¤ ì •ë¦¬
                    del test_instance
                    return True
            except Exception as e:
                self.logger.warning(f"âš ï¸ {step_config.class_name} ìƒì„±ì í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
                # ìƒì„±ì ì‹¤íŒ¨í•´ë„ í´ë˜ìŠ¤ ìì²´ëŠ” ìœ íš¨í•  ìˆ˜ ìˆìŒ
                return True
            
            self.logger.debug(f"âœ… {step_config.class_name} í´ë˜ìŠ¤ ê²€ì¦ ì™„ë£Œ")
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ {step_config.class_name} í´ë˜ìŠ¤ ê²€ì¦ ì‹¤íŒ¨: {e}")
            return False
    
    def resolve_model_loader(self, config: Optional[Dict[str, Any]] = None) -> Optional['ModelLoader']:
        """ModelLoader í•´ê²° (conda í™˜ê²½ ìµœì í™”)"""
        try:
            with self._resolution_lock:
                cache_key = "model_loader"
                if cache_key in self._resolved_cache:
                    return self._resolved_cache[cache_key]
                
                # conda í™˜ê²½ í™•ì¸
                if not CONDA_INFO['is_target_env']:
                    self.logger.warning(f"âš ï¸ ê¶Œì¥ conda í™˜ê²½ì´ ì•„ë‹˜: {CONDA_INFO['conda_env']} (ê¶Œì¥: mycloset-ai-clean)")
                
                # ë™ì  import
                import importlib
                model_loader_module = importlib.import_module('app.ai_pipeline.utils.model_loader')
                get_global_loader = getattr(model_loader_module, 'get_global_model_loader', None)
                
                if get_global_loader:
                    # conda í™˜ê²½ ìµœì í™” ì„¤ì •
                    optimized_config = self._get_conda_optimized_config(config)
                    model_loader = get_global_loader(optimized_config)
                    
                    # ì´ˆê¸°í™” í™•ì¸
                    if hasattr(model_loader, 'initialize'):
                        if not model_loader.is_initialized():
                            success = model_loader.initialize()
                            if not success:
                                self.logger.error("âŒ ModelLoader ì´ˆê¸°í™” ì‹¤íŒ¨")
                                return None
                    
                    self._resolved_cache[cache_key] = model_loader
                    self.logger.info("âœ… ModelLoader í•´ê²° ì™„ë£Œ (conda ìµœì í™”)")
                    return model_loader
                else:
                    self.logger.error("âŒ get_global_model_loader í•¨ìˆ˜ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
                    return None
                    
        except Exception as e:
            self.logger.error(f"âŒ ModelLoader í•´ê²° ì‹¤íŒ¨: {e}")
            return None
    
    def _get_conda_optimized_config(self, base_config: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
        """conda í™˜ê²½ ìµœì í™” ì„¤ì •"""
        config = base_config or {}
        
        # M3 Max ìµœì í™”
        if IS_M3_MAX:
            config.update({
                'device': 'mps',
                'memory_fraction': 0.8,  # 128GBì˜ 80% í™œìš©
                'enable_memory_mapping': True,
                'use_unified_memory': True,
                'batch_size_multiplier': 2.0
            })
        
        # conda í™˜ê²½ë³„ ìµœì í™”
        if CONDA_INFO['is_target_env']:
            config.update({
                'cache_dir': str(Path(CONDA_INFO['conda_prefix']) / 'ai_models_cache'),
                'temp_dir': str(Path(CONDA_INFO['conda_prefix']) / 'temp'),
                'enable_conda_optimization': True
            })
        
        # ë©”ëª¨ë¦¬ ìµœì í™”
        config.update({
            'total_memory_gb': MEMORY_GB,
            'memory_optimization_aggressive': MEMORY_GB < 32,
            'gc_frequency': 'high' if MEMORY_GB < 64 else 'medium'
        })
        
        return config
    
    def resolve_memory_manager(self) -> Optional['MemoryManager']:
        """MemoryManager í•´ê²° (M3 Max ìµœì í™”)"""
        try:
            with self._resolution_lock:
                cache_key = "memory_manager"
                if cache_key in self._resolved_cache:
                    return self._resolved_cache[cache_key]
                
                import importlib
                memory_module = importlib.import_module('app.ai_pipeline.utils.memory_manager')
                get_global_manager = getattr(memory_module, 'get_global_memory_manager', None)
                
                if get_global_manager:
                    memory_manager = get_global_manager()
                    
                    # M3 Max íŠ¹ë³„ ì„¤ì •
                    if IS_M3_MAX and hasattr(memory_manager, 'configure_m3_max'):
                        memory_manager.configure_m3_max(memory_gb=MEMORY_GB)
                    
                    self._resolved_cache[cache_key] = memory_manager
                    self.logger.info("âœ… MemoryManager í•´ê²° ì™„ë£Œ (M3 Max ìµœì í™”)")
                    return memory_manager
                    
        except Exception as e:
            self.logger.debug(f"MemoryManager í•´ê²° ì‹¤íŒ¨: {e}")
            return None
    
    def resolve_data_converter(self) -> Optional['DataConverter']:
        """DataConverter í•´ê²°"""
        try:
            with self._resolution_lock:
                cache_key = "data_converter"
                if cache_key in self._resolved_cache:
                    return self._resolved_cache[cache_key]
                
                import importlib
                converter_module = importlib.import_module('app.ai_pipeline.utils.data_converter')
                get_global_converter = getattr(converter_module, 'get_global_data_converter', None)
                
                if get_global_converter:
                    data_converter = get_global_converter()
                    self._resolved_cache[cache_key] = data_converter
                    self.logger.info("âœ… DataConverter í•´ê²° ì™„ë£Œ")
                    return data_converter
                    
        except Exception as e:
            self.logger.debug(f"DataConverter í•´ê²° ì‹¤íŒ¨: {e}")
            return None
    
    def resolve_di_container(self) -> Optional['DIContainer']:
        """DI Container í•´ê²°"""
        try:
            with self._resolution_lock:
                cache_key = "di_container"
                if cache_key in self._resolved_cache:
                    return self._resolved_cache[cache_key]
                
                import importlib
                di_module = importlib.import_module('app.core.di_container')
                get_global_container = getattr(di_module, 'get_global_di_container', None)
                
                if get_global_container:
                    di_container = get_global_container()
                    self._resolved_cache[cache_key] = di_container
                    self.logger.info("âœ… DI Container í•´ê²° ì™„ë£Œ")
                    return di_container
                    
        except Exception as e:
            self.logger.debug(f"DI Container í•´ê²° ì‹¤íŒ¨: {e}")
            return None
    
    def create_dependency_bundle(self, config: StepConfig) -> DependencyBundle:
        """ì˜ì¡´ì„± ë²ˆë“¤ ìƒì„± (ìµœì í™”)"""
        try:
            self.logger.info(f"ğŸ”„ {config.step_name} ì˜ì¡´ì„± ë²ˆë“¤ ìƒì„± ì‹œì‘...")
            
            bundle = DependencyBundle()
            
            # í•„ìˆ˜ ì˜ì¡´ì„±ë¶€í„° í•´ê²° (ìš°ì„ ìˆœìœ„)
            if config.require_model_loader:
                bundle.model_loader = self.resolve_model_loader()
                if bundle.model_loader:
                    self.logger.info(f"âœ… {config.step_name} ModelLoader í•´ê²° ì™„ë£Œ")
                else:
                    self.logger.warning(f"âš ï¸ {config.step_name} ModelLoader í•´ê²° ì‹¤íŒ¨")
            
            if config.require_memory_manager:
                bundle.memory_manager = self.resolve_memory_manager()
                if bundle.memory_manager:
                    self.logger.info(f"âœ… {config.step_name} MemoryManager í•´ê²° ì™„ë£Œ")
            
            if config.require_data_converter:
                bundle.data_converter = self.resolve_data_converter()
                if bundle.data_converter:
                    self.logger.info(f"âœ… {config.step_name} DataConverter í•´ê²° ì™„ë£Œ")
            
            # DI ContainerëŠ” í•­ìƒ ì‹œë„ (ì„ íƒì )
            bundle.di_container = self.resolve_di_container()
            
            resolved_count = sum(1 for dep in [bundle.model_loader, bundle.memory_manager, bundle.data_converter, bundle.di_container] if dep is not None)
            self.logger.info(f"ğŸ¯ {config.step_name} ì˜ì¡´ì„± ë²ˆë“¤ ìƒì„± ì™„ë£Œ: {resolved_count}/4 í•´ê²°")
            
            return bundle
            
        except Exception as e:
            self.logger.error(f"âŒ {config.step_name} ì˜ì¡´ì„± ë²ˆë“¤ ìƒì„± ì‹¤íŒ¨: {e}")
            return DependencyBundle()
    
    def clear_cache(self):
        """ìºì‹œ ì •ë¦¬"""
        with self._resolution_lock:
            self._resolved_cache.clear()
            self._import_attempts.clear()
            gc.collect()  # Python GC ê°•ì œ ì‹¤í–‰
            self.logger.info("ğŸ§¹ ê³ ê¸‰ ì˜ì¡´ì„± í•´ê²°ê¸° ìºì‹œ ì •ë¦¬ ì™„ë£Œ")

# ==============================================
# ğŸ”¥ ë©”ì¸ StepFactory v7.0 í´ë˜ìŠ¤
# ==============================================

class StepFactory:
    """
    ğŸ”¥ StepFactory v7.0 - ì‹¤ì œ Step í´ë˜ìŠ¤ ì—°ë™ ìˆ˜ì • (ë™ì‘ ë³´ì¥)
    
    í•µì‹¬ ìˆ˜ì •ì‚¬í•­:
    âœ… ì‹¤ì œ Step í´ë˜ìŠ¤ ë§¤í•‘ ìˆ˜ì •: HumanParsingStep, PoseEstimationStep ë“±
    âœ… ë™ì  import ë¡œì§ ì™„ì „ ê°œì„ 
    âœ… ì—ëŸ¬ ì²˜ë¦¬ ê°•í™” ë° ë””ë²„ê¹… ë¡œì§ ì¶”ê°€
    âœ… í´ë°± ì œê±° - ì‹¤ì œ ë™ì‘ë§Œ
    âœ… BaseStepMixin ì˜ì¡´ì„± ì£¼ì… ê°œì„ 
    """
    
    def __init__(self):
        self.logger = logging.getLogger("StepFactory")
        
        # ê°•í™”ëœ ì˜ì¡´ì„± í•´ê²°ê¸°
        self.dependency_resolver = AdvancedDependencyResolver()
        
        # ìºì‹œ ë° ìƒíƒœ ê´€ë¦¬
        self._step_cache: Dict[str, weakref.ref] = {}
        self._creation_stats = {
            'total_created': 0,
            'successful_creations': 0,
            'failed_creations': 0,
            'cache_hits': 0,
            'dependencies_resolved': 0,
            'conda_optimized': CONDA_INFO['is_target_env'],
            'm3_max_optimized': IS_M3_MAX,
            'memory_gb': MEMORY_GB
        }
        
        # ë™ê¸°í™”
        self._lock = threading.RLock()
        
        # ì‹œìŠ¤í…œ ì •ë³´ ë¡œê¹…
        self.logger.info("ğŸ­ StepFactory v7.0 ì´ˆê¸°í™” ì™„ë£Œ")
        self.logger.info(f"ğŸ”§ conda í™˜ê²½: {CONDA_INFO['conda_env']} (ìµœì í™”: {CONDA_INFO['is_target_env']})")
        self.logger.info(f"ğŸ–¥ï¸  ì‹œìŠ¤í…œ: M3 Max={IS_M3_MAX}, ë©”ëª¨ë¦¬={MEMORY_GB:.1f}GB")
    
    def create_step(
        self, 
        step_type: Union[StepType, str], 
        config: Optional[StepConfig] = None,
        use_cache: bool = True,
        **kwargs
    ) -> StepCreationResult:
        """í†µí•© Step ìƒì„± ë©”ì„œë“œ (v7.0 - ì‹¤ì œ ë™ì‘ ë³´ì¥)"""
        start_time = time.time()
        
        try:
            # Step íƒ€ì… ì •ê·œí™”
            if isinstance(step_type, str):
                try:
                    step_type = StepType(step_type.lower())
                except ValueError:
                    return StepCreationResult(
                        success=False,
                        error_message=f"ì§€ì›í•˜ì§€ ì•ŠëŠ” Step íƒ€ì…: {step_type}"
                    )
            
            # ì„¤ì • ìƒì„± (ì‹¤ì œ ë§¤í•‘ í…Œì´ë¸” ì‚¬ìš©)
            if config is None:
                config = RealStepMapping.get_step_config(step_type, **kwargs)
            
            self.logger.info(f"ğŸ¯ {config.step_name} ìƒì„± ì‹œì‘ (í´ë˜ìŠ¤: {config.class_name}, ëª¨ë“ˆ: {config.module_path})")
            
            # ìºì‹œ í™•ì¸
            if use_cache:
                cached_step = self._get_cached_step(config.step_name)
                if cached_step:
                    self._creation_stats['cache_hits'] += 1
                    self.logger.info(f"â™»ï¸ {config.step_name} ìºì‹œì—ì„œ ë°˜í™˜")
                    return StepCreationResult(
                        success=True,
                        step_instance=cached_step,
                        step_name=config.step_name,
                        step_type=step_type,
                        class_name=config.class_name,
                        module_path=config.module_path,
                        initialization_time=time.time() - start_time
                    )
            
            # ğŸ”¥ ì‹¤ì œ Step ìƒì„± ì‹¤í–‰ (í´ë°± ì—†ìŒ)
            result = self._create_step_instance_real(step_type, config)
            
            # ì„±ê³µ ì‹œ ìºì‹œì— ì €ì¥
            if result.success and result.step_instance and use_cache:
                self._cache_step(config.step_name, result.step_instance)
            
            # í†µê³„ ì—…ë°ì´íŠ¸
            self._creation_stats['total_created'] += 1
            if result.success:
                self._creation_stats['successful_creations'] += 1
            else:
                self._creation_stats['failed_creations'] += 1
            
            result.initialization_time = time.time() - start_time
            
            return result
            
        except Exception as e:
            self.logger.error(f"âŒ Step ìƒì„± ì‹¤íŒ¨: {e}")
            return StepCreationResult(
                success=False,
                error_message=f"Step ìƒì„± ì¤‘ ì˜ˆì™¸ ë°œìƒ: {str(e)}",
                initialization_time=time.time() - start_time
            )
    
    def _create_step_instance_real(self, step_type: StepType, config: StepConfig) -> StepCreationResult:
        """ì‹¤ì œ Step ì¸ìŠ¤í„´ìŠ¤ ìƒì„± (í´ë°± ì—†ìŒ - ì‹¤ì œ ë™ì‘ë§Œ)"""
        try:
            self.logger.info(f"ğŸ”„ {config.step_name} ì‹¤ì œ ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ì‹œì‘...")
            
            # 1. ğŸ”¥ ì‹¤ì œ Step í´ë˜ìŠ¤ í•´ê²° (ê°•í™”ëœ ë¡œì§)
            StepClass = self.dependency_resolver.resolve_step_class(config)
            if not StepClass:
                error_msg = f"âŒ {config.class_name} í´ë˜ìŠ¤ë¥¼ {config.module_path}ì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŒ"
                self.logger.error(error_msg)
                return StepCreationResult(
                    success=False,
                    step_name=config.step_name,
                    step_type=step_type,
                    class_name=config.class_name,
                    module_path=config.module_path,
                    error_message=error_msg
                )
            
            self.logger.info(f"âœ… {config.class_name} í´ë˜ìŠ¤ í•´ê²° ì™„ë£Œ")
            
            # 2. ì˜ì¡´ì„± ë²ˆë“¤ ìƒì„±
            dependency_bundle = self.dependency_resolver.create_dependency_bundle(config)
            
            # 3. Step ì¸ìŠ¤í„´ìŠ¤ ìƒì„± (ì‹¤ì œ í´ë˜ìŠ¤ ì‚¬ìš©)
            step_kwargs = self._create_step_kwargs(config)
            
            self.logger.info(f"ğŸ”„ {config.class_name} ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ì¤‘...")
            step_instance = StepClass(**step_kwargs)
            self.logger.info(f"âœ… {config.class_name} ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ì™„ë£Œ")
            
            # 4. ì˜ì¡´ì„± ì£¼ì… ì‹¤í–‰
            dependencies_injected = self._inject_dependencies(step_instance, dependency_bundle, config)
            
            # 5. ì´ˆê¸°í™” ì‹¤í–‰
            initialization_success = self._initialize_step(step_instance, config)
            
            if not initialization_success and config.strict_mode:
                return StepCreationResult(
                    success=False,
                    step_name=config.step_name,
                    step_type=step_type,
                    class_name=config.class_name,
                    module_path=config.module_path,
                    error_message="Step ì´ˆê¸°í™” ì‹¤íŒ¨ (Strict Mode)",
                    dependencies_injected=dependencies_injected
                )
            
            # 6. AI ëª¨ë¸ ë¡œë”© í™•ì¸
            ai_models_loaded = self._check_ai_models(step_instance, config)
            
            self.logger.info(f"âœ… {config.step_name} ì‹¤ì œ ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ì™„ë£Œ")
            
            return StepCreationResult(
                success=True,
                step_instance=step_instance,
                step_name=config.step_name,
                step_type=step_type,
                class_name=config.class_name,
                module_path=config.module_path,
                dependencies_injected=dependencies_injected,
                ai_models_loaded=ai_models_loaded
            )
            
        except Exception as e:
            self.logger.error(f"âŒ {config.step_name} ì‹¤ì œ ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ì‹¤íŒ¨: {e}")
            self.logger.error(f"âŒ ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
            return StepCreationResult(
                success=False,
                step_name=config.step_name,
                step_type=step_type,
                class_name=config.class_name,
                module_path=config.module_path,
                error_message=f"Step ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ì‹¤íŒ¨: {str(e)}"
            )
    
    def _create_step_kwargs(self, config: StepConfig) -> Dict[str, Any]:
        """Step ìƒì„±ì ì¸ìˆ˜ ìƒì„±"""
        step_kwargs = {
            'step_name': config.step_name,
            'step_id': config.step_id,
            'device': self._resolve_device(config.device),
            'use_fp16': config.use_fp16,
            'batch_size': config.batch_size,
            'confidence_threshold': config.confidence_threshold,
            'auto_memory_cleanup': config.auto_memory_cleanup,
            'auto_warmup': config.auto_warmup,
            'optimization_enabled': config.optimization_enabled,
            'strict_mode': config.strict_mode,
            'auto_inject_dependencies': config.auto_inject_dependencies,
            'require_model_loader': config.require_model_loader,
            'require_memory_manager': config.require_memory_manager,
            'require_data_converter': config.require_data_converter
        }
        
        # conda í™˜ê²½ ìµœì í™”
        if CONDA_INFO['is_target_env']:
            step_kwargs['conda_optimized'] = True
            step_kwargs['conda_env'] = CONDA_INFO['conda_env']
        
        # M3 Max ìµœì í™”
        if IS_M3_MAX:
            step_kwargs['m3_max_optimized'] = True
            step_kwargs['memory_gb'] = MEMORY_GB
            step_kwargs['use_unified_memory'] = True
        
        return step_kwargs
    
    def _resolve_device(self, device: str) -> str:
        """ë””ë°”ì´ìŠ¤ í•´ê²° (M3 Max ìµœì í™”)"""
        if device == "auto":
            if IS_M3_MAX:
                return "mps"
            try:
                import torch
                if torch.cuda.is_available():
                    return "cuda"
                elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
                    return "mps"
            except:
                pass
            return "cpu"
        return device
    
    def _inject_dependencies(
        self, 
        step_instance: 'BaseStepMixin', 
        dependency_bundle: DependencyBundle,
        config: StepConfig
    ) -> Dict[str, bool]:
        """ì˜ì¡´ì„± ì£¼ì… ì‹¤í–‰ (BaseStepMixin í˜¸í™˜)"""
        injection_results = {}
        
        try:
            # ModelLoader ì£¼ì…
            if dependency_bundle.model_loader and hasattr(step_instance, 'set_model_loader'):
                try:
                    step_instance.set_model_loader(dependency_bundle.model_loader)
                    injection_results['model_loader'] = True
                    self._creation_stats['dependencies_resolved'] += 1
                    self.logger.debug(f"âœ… {config.step_name} ModelLoader ì£¼ì… ì™„ë£Œ")
                except Exception as e:
                    self.logger.warning(f"âš ï¸ {config.step_name} ModelLoader ì£¼ì… ì‹¤íŒ¨: {e}")
                    injection_results['model_loader'] = False
            else:
                injection_results['model_loader'] = False
            
            # MemoryManager ì£¼ì…
            if dependency_bundle.memory_manager and hasattr(step_instance, 'set_memory_manager'):
                try:
                    step_instance.set_memory_manager(dependency_bundle.memory_manager)
                    injection_results['memory_manager'] = True
                    self._creation_stats['dependencies_resolved'] += 1
                    self.logger.debug(f"âœ… {config.step_name} MemoryManager ì£¼ì… ì™„ë£Œ")
                except Exception as e:
                    self.logger.warning(f"âš ï¸ {config.step_name} MemoryManager ì£¼ì… ì‹¤íŒ¨: {e}")
                    injection_results['memory_manager'] = False
            else:
                injection_results['memory_manager'] = False
            
            # DataConverter ì£¼ì…
            if dependency_bundle.data_converter and hasattr(step_instance, 'set_data_converter'):
                try:
                    step_instance.set_data_converter(dependency_bundle.data_converter)
                    injection_results['data_converter'] = True
                    self._creation_stats['dependencies_resolved'] += 1
                    self.logger.debug(f"âœ… {config.step_name} DataConverter ì£¼ì… ì™„ë£Œ")
                except Exception as e:
                    self.logger.warning(f"âš ï¸ {config.step_name} DataConverter ì£¼ì… ì‹¤íŒ¨: {e}")
                    injection_results['data_converter'] = False
            else:
                injection_results['data_converter'] = False
            
            # DI Container ì£¼ì…
            if dependency_bundle.di_container and hasattr(step_instance, 'set_di_container'):
                try:
                    step_instance.set_di_container(dependency_bundle.di_container)
                    injection_results['di_container'] = True
                    self._creation_stats['dependencies_resolved'] += 1
                    self.logger.debug(f"âœ… {config.step_name} DI Container ì£¼ì… ì™„ë£Œ")
                except Exception as e:
                    self.logger.warning(f"âš ï¸ {config.step_name} DI Container ì£¼ì… ì‹¤íŒ¨: {e}")
                    injection_results['di_container'] = False
            else:
                injection_results['di_container'] = False
            
            # í•„ìˆ˜ ì˜ì¡´ì„± ê²€ì¦
            required_dependencies = []
            if config.require_model_loader:
                required_dependencies.append('model_loader')
            if config.require_memory_manager:
                required_dependencies.append('memory_manager')
            if config.require_data_converter:
                required_dependencies.append('data_converter')
            
            missing_dependencies = [
                dep for dep in required_dependencies 
                if not injection_results.get(dep, False)
            ]
            
            if missing_dependencies and config.strict_mode:
                self.logger.error(f"âŒ {config.step_name} í•„ìˆ˜ ì˜ì¡´ì„± ëˆ„ë½: {missing_dependencies}")
                raise RuntimeError(f"í•„ìˆ˜ ì˜ì¡´ì„±ì´ ì£¼ì…ë˜ì§€ ì•ŠìŒ: {missing_dependencies}")
            
            success_count = sum(1 for success in injection_results.values() if success)
            total_count = len(injection_results)
            self.logger.info(f"ğŸ’‰ {config.step_name} ì˜ì¡´ì„± ì£¼ì… ì™„ë£Œ: {success_count}/{total_count} ì„±ê³µ")
            
            return injection_results
            
        except Exception as e:
            self.logger.error(f"âŒ {config.step_name} ì˜ì¡´ì„± ì£¼ì… ì‹¤íŒ¨: {e}")
            return injection_results
    
    def _initialize_step(self, step_instance: 'BaseStepMixin', config: StepConfig) -> bool:
        """Step ì´ˆê¸°í™” ì‹¤í–‰"""
        try:
            # BaseStepMixin ì´ˆê¸°í™”
            if hasattr(step_instance, 'initialize'):
                success = step_instance.initialize()
                if not success:
                    self.logger.error(f"âŒ {config.step_name} BaseStepMixin ì´ˆê¸°í™” ì‹¤íŒ¨")
                    return False
                else:
                    self.logger.debug(f"âœ… {config.step_name} BaseStepMixin ì´ˆê¸°í™” ì™„ë£Œ")
            
            # ì‚¬ìš©ì ì •ì˜ ì´ˆê¸°í™” (ìˆëŠ” ê²½ìš°)
            if hasattr(step_instance, 'custom_initialize'):
                try:
                    custom_success = step_instance.custom_initialize()
                    if custom_success:
                        self.logger.debug(f"âœ… {config.step_name} ì‚¬ìš©ì ì •ì˜ ì´ˆê¸°í™” ì™„ë£Œ")
                    else:
                        self.logger.warning(f"âš ï¸ {config.step_name} ì‚¬ìš©ì ì •ì˜ ì´ˆê¸°í™” ì‹¤íŒ¨")
                except Exception as custom_error:
                    self.logger.warning(f"âš ï¸ {config.step_name} ì‚¬ìš©ì ì •ì˜ ì´ˆê¸°í™” ì˜¤ë¥˜: {custom_error}")
            
            # ì›Œë°ì—… ì‹¤í–‰ (ì„¤ì •ëœ ê²½ìš°)
            if config.auto_warmup and hasattr(step_instance, 'warmup'):
                try:
                    warmup_result = step_instance.warmup()
                    if warmup_result.get('success', False):
                        self.logger.info(f"ğŸ”¥ {config.step_name} ì›Œë°ì—… ì™„ë£Œ")
                    else:
                        self.logger.warning(f"âš ï¸ {config.step_name} ì›Œë°ì—… ì‹¤íŒ¨")
                except Exception as warmup_error:
                    self.logger.warning(f"âš ï¸ {config.step_name} ì›Œë°ì—… ì˜¤ë¥˜: {warmup_error}")
            
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ {config.step_name} ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return False
    
    def _check_ai_models(self, step_instance: 'BaseStepMixin', config: StepConfig) -> List[str]:
        """AI ëª¨ë¸ ë¡œë”© í™•ì¸"""
        loaded_models = []
        
        try:
            # ModelLoaderë¥¼ í†µí•œ ëª¨ë¸ í™•ì¸
            if hasattr(step_instance, 'model_loader') and step_instance.model_loader:
                for model_name in config.ai_models:
                    try:
                        if hasattr(step_instance.model_loader, 'is_model_loaded'):
                            if step_instance.model_loader.is_model_loaded(model_name):
                                loaded_models.append(model_name)
                        elif hasattr(step_instance.model_loader, 'get_model'):
                            model = step_instance.model_loader.get_model(model_name)
                            if model is not None:
                                loaded_models.append(model_name)
                    except Exception as e:
                        self.logger.debug(f"ëª¨ë¸ {model_name} í™•ì¸ ì‹¤íŒ¨: {e}")
            
            if loaded_models:
                self.logger.info(f"ğŸ¤– {config.step_name} AI ëª¨ë¸ ë¡œë”© í™•ì¸: {loaded_models}")
            else:
                self.logger.warning(f"âš ï¸ {config.step_name} AI ëª¨ë¸ ë¡œë”© í™•ì¸ ë¶ˆê°€")
            
            return loaded_models
            
        except Exception as e:
            self.logger.debug(f"AI ëª¨ë¸ í™•ì¸ ì¤‘ ì˜¤ë¥˜: {e}")
            return []
    
    def _get_cached_step(self, step_name: str) -> Optional['BaseStepMixin']:
        """ìºì‹œëœ Step ì¡°íšŒ"""
        try:
            with self._lock:
                if step_name in self._step_cache:
                    weak_ref = self._step_cache[step_name]
                    step_instance = weak_ref()
                    if step_instance is not None:
                        self.logger.debug(f"â™»ï¸ ìºì‹œëœ Step ë°˜í™˜: {step_name}")
                        return step_instance
                    else:
                        # ì•½í•œ ì°¸ì¡°ê°€ í•´ì œë¨
                        del self._step_cache[step_name]
                return None
        except Exception as e:
            self.logger.debug(f"ìºì‹œ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return None
    
    def _cache_step(self, step_name: str, step_instance: 'BaseStepMixin'):
        """Step ìºì‹œì— ì €ì¥"""
        try:
            with self._lock:
                self._step_cache[step_name] = weakref.ref(step_instance)
                self.logger.debug(f"ğŸ’¾ Step ìºì‹œì— ì €ì¥: {step_name}")
        except Exception as e:
            self.logger.debug(f"ìºì‹œ ì €ì¥ ì‹¤íŒ¨: {e}")
    
    # ==============================================
    # ğŸ”¥ í¸ì˜ ë©”ì„œë“œë“¤ (ì‹¤ì œ í´ë˜ìŠ¤ ê¸°ë°˜)
    # ==============================================
    
    def create_human_parsing_step(self, **kwargs) -> StepCreationResult:
        """Human Parsing Step ìƒì„±"""
        return self.create_step(StepType.HUMAN_PARSING, **kwargs)
    
    def create_pose_estimation_step(self, **kwargs) -> StepCreationResult:
        """Pose Estimation Step ìƒì„±"""
        return self.create_step(StepType.POSE_ESTIMATION, **kwargs)
    
    def create_cloth_segmentation_step(self, **kwargs) -> StepCreationResult:
        """Cloth Segmentation Step ìƒì„±"""
        return self.create_step(StepType.CLOTH_SEGMENTATION, **kwargs)
    
    def create_geometric_matching_step(self, **kwargs) -> StepCreationResult:
        """Geometric Matching Step ìƒì„±"""
        return self.create_step(StepType.GEOMETRIC_MATCHING, **kwargs)
    
    def create_cloth_warping_step(self, **kwargs) -> StepCreationResult:
        """Cloth Warping Step ìƒì„±"""
        return self.create_step(StepType.CLOTH_WARPING, **kwargs)
    
    def create_virtual_fitting_step(self, **kwargs) -> StepCreationResult:
        """Virtual Fitting Step ìƒì„±"""
        return self.create_step(StepType.VIRTUAL_FITTING, **kwargs)
    
    def create_post_processing_step(self, **kwargs) -> StepCreationResult:
        """Post Processing Step ìƒì„±"""
        return self.create_step(StepType.POST_PROCESSING, **kwargs)
    
    def create_quality_assessment_step(self, **kwargs) -> StepCreationResult:
        """Quality Assessment Step ìƒì„±"""
        return self.create_step(StepType.QUALITY_ASSESSMENT, **kwargs)
    
    # ==============================================
    # ğŸ”¥ ì „ì²´ íŒŒì´í”„ë¼ì¸ ìƒì„± (ì‹¤ì œ í´ë˜ìŠ¤ ê¸°ë°˜)
    # ==============================================
    
    def create_full_pipeline(self, device: str = "auto", **kwargs) -> Dict[str, StepCreationResult]:
        """ì „ì²´ AI íŒŒì´í”„ë¼ì¸ ìƒì„± (ì‹¤ì œ í´ë˜ìŠ¤ ê¸°ë°˜)"""
        try:
            self.logger.info("ğŸš€ ì „ì²´ AI íŒŒì´í”„ë¼ì¸ ìƒì„± ì‹œì‘ (229GB AI ëª¨ë¸ í™œìš©)...")
            
            pipeline_results = {}
            total_model_size = 0.0
            
            # ìš°ì„ ìˆœìœ„ë³„ë¡œ Step ìƒì„± (CRITICAL -> HIGH -> MEDIUM -> LOW)
            sorted_steps = sorted(
                StepType, 
                key=lambda x: RealStepMapping.STEP_MAPPING[x]['priority']
            )
            
            for step_type in sorted_steps:
                try:
                    config_kwargs = {
                        'device': device,
                        **kwargs
                    }
                    
                    result = self.create_step(step_type, **config_kwargs)
                    pipeline_results[step_type.value] = result
                    
                    if result.success:
                        model_size = RealStepMapping.STEP_MAPPING[step_type]['model_size_gb']
                        total_model_size += model_size
                        self.logger.info(f"âœ… {result.step_name} íŒŒì´í”„ë¼ì¸ ìƒì„± ì„±ê³µ ({model_size}GB)")
                    else:
                        self.logger.error(f"âŒ {step_type.value} íŒŒì´í”„ë¼ì¸ ìƒì„± ì‹¤íŒ¨: {result.error_message}")
                        
                except Exception as step_error:
                    self.logger.error(f"âŒ {step_type.value} Step ìƒì„± ì¤‘ ì˜ˆì™¸: {step_error}")
                    pipeline_results[step_type.value] = StepCreationResult(
                        success=False,
                        step_name=f"{step_type.value}Step",
                        step_type=step_type,
                        error_message=str(step_error)
                    )
            
            success_count = sum(1 for result in pipeline_results.values() if result.success)
            total_count = len(pipeline_results)
            
            self.logger.info(f"ğŸ ì „ì²´ íŒŒì´í”„ë¼ì¸ ìƒì„± ì™„ë£Œ: {success_count}/{total_count} ì„±ê³µ")
            self.logger.info(f"ğŸ¤– ì´ AI ëª¨ë¸ í¬ê¸°: {total_model_size:.1f}GB / 229GB")
            
            return pipeline_results
            
        except Exception as e:
            self.logger.error(f"âŒ ì „ì²´ íŒŒì´í”„ë¼ì¸ ìƒì„± ì‹¤íŒ¨: {e}")
            return {}
    
    def get_creation_statistics(self) -> Dict[str, Any]:
        """ìƒì„± í†µê³„ ì¡°íšŒ (í™˜ê²½ ì •ë³´ í¬í•¨)"""
        try:
            with self._lock:
                total = self._creation_stats['total_created']
                success_rate = (
                    self._creation_stats['successful_creations'] / max(1, total) * 100
                )
                
                return {
                    'total_created': total,
                    'successful_creations': self._creation_stats['successful_creations'],
                    'failed_creations': self._creation_stats['failed_creations'],
                    'success_rate': round(success_rate, 2),
                    'cache_hits': self._creation_stats['cache_hits'],
                    'dependencies_resolved': self._creation_stats['dependencies_resolved'],
                    'cached_steps': len(self._step_cache),
                    'active_cache_entries': len([
                        ref for ref in self._step_cache.values() 
                        if ref() is not None
                    ]),
                    
                    # í™˜ê²½ ì •ë³´
                    'environment': {
                        'conda_env': CONDA_INFO['conda_env'],
                        'conda_optimized': self._creation_stats['conda_optimized'],
                        'is_m3_max': IS_M3_MAX,
                        'm3_max_optimized': self._creation_stats['m3_max_optimized'],
                        'memory_gb': MEMORY_GB,
                        'version': 'StepFactory v7.0'
                    },
                    
                    # Step ë§¤í•‘ ì •ë³´
                    'step_mapping': {
                        step_type.value: {
                            'class_name': mapping['class_name'],
                            'module_path': mapping['module_path'],
                            'model_size_gb': mapping['model_size_gb'],
                            'priority': mapping['priority'].name
                        }
                        for step_type, mapping in RealStepMapping.STEP_MAPPING.items()
                    }
                }
        except Exception as e:
            self.logger.error(f"âŒ í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {'error': str(e), 'version': 'StepFactory v7.0'}
    
    def clear_cache(self):
        """ìºì‹œ ì •ë¦¬ (ê³ ê¸‰ ì •ë¦¬)"""
        try:
            with self._lock:
                self._step_cache.clear()
                self.dependency_resolver.clear_cache()
                
                # M3 Max íŠ¹ë³„ ë©”ëª¨ë¦¬ ì •ë¦¬
                if IS_M3_MAX:
                    for _ in range(3):
                        gc.collect()
                else:
                    gc.collect()
                
                self.logger.info("ğŸ§¹ StepFactory v7.0 ìºì‹œ ì •ë¦¬ ì™„ë£Œ")
        except Exception as e:
            self.logger.error(f"âŒ ìºì‹œ ì •ë¦¬ ì‹¤íŒ¨: {e}")
    
    def validate_dependencies(self) -> Dict[str, bool]:
        """ì˜ì¡´ì„± ê²€ì¦ (ì‹¤ì œ í´ë˜ìŠ¤ ê¸°ë°˜)"""
        try:
            validation_results = {}
            
            # ModelLoader ê²€ì¦
            model_loader = self.dependency_resolver.resolve_model_loader()
            validation_results['model_loader'] = model_loader is not None
            
            # MemoryManager ê²€ì¦
            memory_manager = self.dependency_resolver.resolve_memory_manager()
            validation_results['memory_manager'] = memory_manager is not None
            
            # DataConverter ê²€ì¦
            data_converter = self.dependency_resolver.resolve_data_converter()
            validation_results['data_converter'] = data_converter is not None
            
            # DI Container ê²€ì¦
            di_container = self.dependency_resolver.resolve_di_container()
            validation_results['di_container'] = di_container is not None
            
            # ì‹¤ì œ Step í´ë˜ìŠ¤ë“¤ ê²€ì¦
            for step_type in StepType:
                config = RealStepMapping.get_step_config(step_type)
                step_class = self.dependency_resolver.resolve_step_class(config)
                validation_results[f'step_class_{step_type.value}'] = step_class is not None
            
            # í™˜ê²½ ê²€ì¦
            validation_results['conda_environment'] = CONDA_INFO['is_target_env']
            validation_results['m3_max_available'] = IS_M3_MAX
            validation_results['sufficient_memory'] = MEMORY_GB >= 16.0
            
            success_count = sum(1 for v in validation_results.values() if v)
            total_count = len(validation_results)
            
            self.logger.info(f"ğŸ” ì˜ì¡´ì„± ê²€ì¦ ì™„ë£Œ: {success_count}/{total_count} ì„±ê³µ")
            
            return validation_results
            
        except Exception as e:
            self.logger.error(f"âŒ ì˜ì¡´ì„± ê²€ì¦ ì‹¤íŒ¨: {e}")
            return {'error': str(e)}

# ==============================================
# ğŸ”¥ ì „ì—­ StepFactory ê´€ë¦¬ (v7.0)
# ==============================================

_global_step_factory: Optional[StepFactory] = None
_factory_lock = threading.Lock()

def get_global_step_factory() -> StepFactory:
    """ì „ì—­ StepFactory ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜ (v7.0)"""
    global _global_step_factory
    
    with _factory_lock:
        if _global_step_factory is None:
            _global_step_factory = StepFactory()
            logger.info("âœ… ì „ì—­ StepFactory v7.0 ìƒì„± ì™„ë£Œ")
        
        return _global_step_factory

def reset_global_step_factory():
    """ì „ì—­ StepFactory ë¦¬ì…‹"""
    global _global_step_factory
    
    with _factory_lock:
        if _global_step_factory:
            _global_step_factory.clear_cache()
        _global_step_factory = None
        logger.info("ğŸ”„ ì „ì—­ StepFactory ë¦¬ì…‹ ì™„ë£Œ")

# ==============================================
# ğŸ”¥ í¸ì˜ í•¨ìˆ˜ë“¤ (ì‹¤ì œ í´ë˜ìŠ¤ ê¸°ë°˜)
# ==============================================

def create_step(
    step_type: Union[StepType, str], 
    config: Optional[StepConfig] = None,
    **kwargs
) -> StepCreationResult:
    """ì „ì—­ Step ìƒì„± í•¨ìˆ˜ (ì‹¤ì œ í´ë˜ìŠ¤ ê¸°ë°˜)"""
    factory = get_global_step_factory()
    return factory.create_step(step_type, config, **kwargs)

async def create_step_async(
    step_type: Union[StepType, str], 
    config: Optional[StepConfig] = None,
    **kwargs
) -> StepCreationResult:
    """ì „ì—­ ë¹„ë™ê¸° Step ìƒì„± í•¨ìˆ˜"""
    factory = get_global_step_factory()
    # ë™ê¸° ë©”ì„œë“œë¥¼ ë¹„ë™ê¸°ë¡œ ì‹¤í–‰
    loop = asyncio.get_event_loop()
    return await loop.run_in_executor(None, factory.create_step, step_type, config, **kwargs)

def create_human_parsing_step(**kwargs) -> StepCreationResult:
    """Human Parsing Step ìƒì„± (HumanParsingStep í´ë˜ìŠ¤)"""
    return create_step(StepType.HUMAN_PARSING, **kwargs)

def create_pose_estimation_step(**kwargs) -> StepCreationResult:
    """Pose Estimation Step ìƒì„± (PoseEstimationStep í´ë˜ìŠ¤)"""
    return create_step(StepType.POSE_ESTIMATION, **kwargs)

def create_cloth_segmentation_step(**kwargs) -> StepCreationResult:
    """Cloth Segmentation Step ìƒì„± (ClothSegmentationStep í´ë˜ìŠ¤)"""
    return create_step(StepType.CLOTH_SEGMENTATION, **kwargs)

def create_geometric_matching_step(**kwargs) -> StepCreationResult:
    """Geometric Matching Step ìƒì„± (GeometricMatchingStep í´ë˜ìŠ¤)"""
    return create_step(StepType.GEOMETRIC_MATCHING, **kwargs)

def create_cloth_warping_step(**kwargs) -> StepCreationResult:
    """Cloth Warping Step ìƒì„± (ClothWarpingStep í´ë˜ìŠ¤)"""
    return create_step(StepType.CLOTH_WARPING, **kwargs)

def create_virtual_fitting_step(**kwargs) -> StepCreationResult:
    """Virtual Fitting Step ìƒì„± (VirtualFittingStep í´ë˜ìŠ¤)"""
    return create_step(StepType.VIRTUAL_FITTING, **kwargs)

def create_post_processing_step(**kwargs) -> StepCreationResult:
    """Post Processing Step ìƒì„± (PostProcessingStep í´ë˜ìŠ¤)"""
    return create_step(StepType.POST_PROCESSING, **kwargs)

def create_quality_assessment_step(**kwargs) -> StepCreationResult:
    """Quality Assessment Step ìƒì„± (QualityAssessmentStep í´ë˜ìŠ¤)"""
    return create_step(StepType.QUALITY_ASSESSMENT, **kwargs)

def create_full_pipeline(device: str = "auto", **kwargs) -> Dict[str, StepCreationResult]:
    """ì „ì²´ íŒŒì´í”„ë¼ì¸ ìƒì„± (229GB AI ëª¨ë¸ í™œìš©)"""
    factory = get_global_step_factory()
    return factory.create_full_pipeline(device, **kwargs)

async def create_full_pipeline_async(device: str = "auto", **kwargs) -> Dict[str, StepCreationResult]:
    """ë¹„ë™ê¸° ì „ì²´ íŒŒì´í”„ë¼ì¸ ìƒì„±"""
    factory = get_global_step_factory()
    loop = asyncio.get_event_loop()
    return await loop.run_in_executor(None, factory.create_full_pipeline, device, **kwargs)

def validate_step_dependencies() -> Dict[str, bool]:
    """Step ì˜ì¡´ì„± ê²€ì¦ (ì‹¤ì œ í´ë˜ìŠ¤ ê¸°ë°˜)"""
    factory = get_global_step_factory()
    return factory.validate_dependencies()

def get_step_factory_statistics() -> Dict[str, Any]:
    """StepFactory í†µê³„ ì¡°íšŒ"""
    factory = get_global_step_factory()
    return factory.get_creation_statistics()

def clear_step_factory_cache():
    """StepFactory ìºì‹œ ì •ë¦¬"""
    factory = get_global_step_factory()
    factory.clear_cache()

# ==============================================
# ğŸ”¥ í…ŒìŠ¤íŠ¸ ë° ë””ë²„ê¹… í•¨ìˆ˜ë“¤
# ==============================================

def test_step_creation(step_type: Union[StepType, str], **kwargs) -> Dict[str, Any]:
    """Step ìƒì„± í…ŒìŠ¤íŠ¸"""
    try:
        logger.info(f"ğŸ§ª {step_type} Step ìƒì„± í…ŒìŠ¤íŠ¸ ì‹œì‘...")
        
        start_time = time.time()
        result = create_step(step_type, **kwargs)
        creation_time = time.time() - start_time
        
        test_result = {
            'step_type': step_type.value if isinstance(step_type, StepType) else step_type,
            'success': result.success,
            'creation_time': creation_time,
            'step_name': result.step_name,
            'class_name': result.class_name,
            'module_path': result.module_path,
            'dependencies_injected': result.dependencies_injected,
            'ai_models_loaded': result.ai_models_loaded,
            'error_message': result.error_message,
            'warnings': result.warnings
        }
        
        if result.success:
            logger.info(f"âœ… {step_type} Step ìƒì„± í…ŒìŠ¤íŠ¸ ì„±ê³µ ({creation_time:.2f}ì´ˆ)")
            
            # ì¶”ê°€ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸
            if result.step_instance:
                try:
                    status = result.step_instance.get_status()
                    test_result['step_status'] = status
                except:
                    test_result['step_status'] = 'status_check_failed'
        else:
            logger.error(f"âŒ {step_type} Step ìƒì„± í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {result.error_message}")
        
        return test_result
        
    except Exception as e:
        logger.error(f"âŒ {step_type} Step ìƒì„± í…ŒìŠ¤íŠ¸ ì˜ˆì™¸: {e}")
        return {
            'step_type': step_type.value if isinstance(step_type, StepType) else step_type,
            'success': False,
            'error': str(e),
            'test_exception': True
        }

def test_all_steps(**kwargs) -> Dict[str, Dict[str, Any]]:
    """ëª¨ë“  Step ìƒì„± í…ŒìŠ¤íŠ¸"""
    logger.info("ğŸ§ª ëª¨ë“  Step ìƒì„± í…ŒìŠ¤íŠ¸ ì‹œì‘...")
    
    test_results = {}
    
    for step_type in StepType:
        test_results[step_type.value] = test_step_creation(step_type, **kwargs)
    
    success_count = sum(1 for result in test_results.values() if result.get('success', False))
    total_count = len(test_results)
    
    logger.info(f"ğŸ§ª ëª¨ë“  Step í…ŒìŠ¤íŠ¸ ì™„ë£Œ: {success_count}/{total_count} ì„±ê³µ")
    
    return {
        'test_summary': {
            'total_steps': total_count,
            'successful_steps': success_count,
            'failed_steps': total_count - success_count,
            'success_rate': round(success_count / total_count * 100, 2)
        },
        'step_results': test_results,
        'system_info': get_step_factory_statistics()
    }

def diagnose_step_factory() -> Dict[str, Any]:
    """StepFactory ì§„ë‹¨"""
    try:
        logger.info("ğŸ” StepFactory ì§„ë‹¨ ì‹œì‘...")
        
        diagnosis = {
            'timestamp': time.time(),
            'version': 'StepFactory v7.0',
            'system_info': get_step_factory_statistics(),
            'dependency_validation': validate_step_dependencies(),
            'step_mapping_info': {}
        }
        
        # Step ë§¤í•‘ ì •ë³´ ìƒì„¸ ì§„ë‹¨
        for step_type in StepType:
            config = RealStepMapping.get_step_config(step_type)
            diagnosis['step_mapping_info'][step_type.value] = {
                'class_name': config.class_name,
                'module_path': config.module_path,
                'ai_models': config.ai_models,
                'model_size_gb': config.model_size_gb,
                'priority': config.priority.name
            }
        
        # ë¬¸ì œì  ì§„ë‹¨
        issues = []
        if not CONDA_INFO['is_target_env']:
            issues.append(f"ê¶Œì¥ conda í™˜ê²½ì´ ì•„ë‹˜: {CONDA_INFO['conda_env']} (ê¶Œì¥: mycloset-ai-clean)")
        
        if MEMORY_GB < 16.0:
            issues.append(f"ë©”ëª¨ë¦¬ ë¶€ì¡±: {MEMORY_GB:.1f}GB (ê¶Œì¥: 16GB ì´ìƒ)")
        
        dependency_issues = [
            k for k, v in diagnosis['dependency_validation'].items() 
            if not v and k.startswith('step_class_')
        ]
        if dependency_issues:
            issues.append(f"Step í´ë˜ìŠ¤ ë¡œë”© ì‹¤íŒ¨: {dependency_issues}")
        
        diagnosis['issues'] = issues
        diagnosis['health_score'] = max(0, 100 - len(issues) * 20)
        
        logger.info(f"ğŸ” StepFactory ì§„ë‹¨ ì™„ë£Œ (ê±´ê°•ë„: {diagnosis['health_score']}%)")
        
        return diagnosis
        
    except Exception as e:
        logger.error(f"âŒ StepFactory ì§„ë‹¨ ì‹¤íŒ¨: {e}")
        return {'error': str(e), 'health_score': 0}

# ==============================================
# ğŸ”¥ Export
# ==============================================

__all__ = [
    # ë©”ì¸ í´ë˜ìŠ¤ë“¤
    'StepFactory',
    'AdvancedDependencyResolver',
    'RealStepMapping',
    
    # ë°ì´í„° êµ¬ì¡°ë“¤
    'StepType',
    'StepPriority',
    'StepConfig',
    'StepCreationResult',
    'DependencyBundle',
    
    # ì „ì—­ í•¨ìˆ˜ë“¤
    'get_global_step_factory',
    'reset_global_step_factory',
    
    # Step ìƒì„± í•¨ìˆ˜ë“¤ (ì‹¤ì œ í´ë˜ìŠ¤ ê¸°ë°˜)
    'create_step',
    'create_step_async',
    'create_human_parsing_step',        # HumanParsingStep
    'create_pose_estimation_step',      # PoseEstimationStep
    'create_cloth_segmentation_step',   # ClothSegmentationStep
    'create_geometric_matching_step',   # GeometricMatchingStep
    'create_cloth_warping_step',        # ClothWarpingStep
    'create_virtual_fitting_step',      # VirtualFittingStep
    'create_post_processing_step',      # PostProcessingStep
    'create_quality_assessment_step',   # QualityAssessmentStep
    'create_full_pipeline',
    'create_full_pipeline_async',
    
    # ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
    'validate_step_dependencies',
    'get_step_factory_statistics',
    'clear_step_factory_cache',
    
    # í…ŒìŠ¤íŠ¸ í•¨ìˆ˜ë“¤
    'test_step_creation',
    'test_all_steps',
    'diagnose_step_factory',
    
    # ìƒìˆ˜ë“¤
    'CONDA_INFO',
    'IS_M3_MAX',
    'MEMORY_GB'
]

# ==============================================
# ğŸ”¥ ëª¨ë“ˆ ë¡œë“œ ì™„ë£Œ ë¡œê·¸
# ==============================================

logger.info("=" * 80)
logger.info("ğŸ”¥ StepFactory v7.0 - ì‹¤ì œ Step í´ë˜ìŠ¤ ì—°ë™ ìˆ˜ì • (ë™ì‘ ë³´ì¥)")
logger.info("=" * 80)
logger.info("âœ… ì‹¤ì œ Step í´ë˜ìŠ¤ ë§¤í•‘ ìˆ˜ì •: HumanParsingStep, PoseEstimationStep ë“±")
logger.info("âœ… ë™ì  import ë¡œì§ ì™„ì „ ê°œì„  (ê°•í™”ëœ ì¬ì‹œë„)")
logger.info("âœ… ì—ëŸ¬ ì²˜ë¦¬ ê°•í™” ë° ìƒì„¸ ë””ë²„ê¹… ë¡œì§ ì¶”ê°€")
logger.info("âœ… í´ë°± ì œê±° - ì‹¤ì œ ë™ì‘ë§Œ (No Mock)")
logger.info("âœ… BaseStepMixin ì˜ì¡´ì„± ì£¼ì… íŒ¨í„´ ì™„ì „ í˜¸í™˜")
logger.info("âœ… conda í™˜ê²½ ìš°ì„  ìµœì í™” (mycloset-ai-clean)")
logger.info("âœ… M3 Max 128GB ë©”ëª¨ë¦¬ ìµœì í™”")
logger.info("âœ… TYPE_CHECKING íŒ¨í„´ìœ¼ë¡œ ìˆœí™˜ì°¸ì¡° ì™„ì „ ë°©ì§€")
logger.info("âœ… í”„ë¡œë•ì…˜ ë ˆë²¨ ì•ˆì •ì„± + ì§„ë‹¨ ë„êµ¬")
logger.info("=" * 80)
logger.info(f"ğŸ”§ í˜„ì¬ conda í™˜ê²½: {CONDA_INFO['conda_env']} (ìµœì í™”: {CONDA_INFO['is_target_env']})")
logger.info(f"ğŸ–¥ï¸  í˜„ì¬ ì‹œìŠ¤í…œ: M3 Max={IS_M3_MAX}, ë©”ëª¨ë¦¬={MEMORY_GB:.1f}GB")
logger.info("=" * 80)