# backend/app/ai_pipeline/factories/step_factory.py
"""
ğŸ”¥ StepFactory v10.0 - BaseStepMixin v19.0 ì™„ì „ í˜¸í™˜ (GitHub í”„ë¡œì íŠ¸ í‘œì¤€)
================================================================================

âœ… BaseStepMixin v19.0 GitHub í”„ë¡œì íŠ¸ ì™„ì „ í˜¸í™˜
âœ… keyword argument repeated: is_m3_max ì˜¤ë¥˜ ì™„ì „ í•´ê²°
âœ… conda í™˜ê²½ ìš°ì„  ìµœì í™” (mycloset-ai-clean)
âœ… M3 Max 128GB ë©”ëª¨ë¦¬ ìµœì í™”
âœ… ì‹¤ì œ AI ëª¨ë¸ 229GB íŒŒì¼ ê²½ë¡œ ë§¤í•‘
âœ… GitHub Step í´ë˜ìŠ¤ë“¤ê³¼ 100% í˜¸í™˜
âœ… UnifiedDependencyManager ì™„ì „ ì—°ë™
âœ… process() ë©”ì„œë“œ ì‹œê·¸ë‹ˆì²˜ í‘œì¤€í™”
âœ… ì˜ì¡´ì„± ì£¼ì… ì‹œìŠ¤í…œ ì „ë©´ ì¬ì„¤ê³„
âœ… ìƒì„±ì ì‹œì  ì˜ì¡´ì„± ì£¼ì… (constructor injection)
âœ… TYPE_CHECKING íŒ¨í„´ìœ¼ë¡œ ìˆœí™˜ì°¸ì¡° ì™„ì „ ë°©ì§€

í•µì‹¬ ìˆ˜ì •ì‚¬í•­:
1. ğŸ¯ BaseStepMixin v19.0 GitHub í‘œì¤€ ì™„ì „ í˜¸í™˜
2. ğŸ”§ is_m3_max â†’ is_m3_max_detected ë³€ê²½ìœ¼ë¡œ í‚¤ì›Œë“œ ì¶©ëŒ ì™„ì „ í•´ê²°
3. ğŸš€ GitHubDependencyManager ì—°ë™ìœ¼ë¡œ ì˜ì¡´ì„± ì£¼ì… ì™„ì „ ì¬ì„¤ê³„
4. ğŸ§  ì‹¤ì œ AI ëª¨ë¸ íŒŒì¼ ê²½ë¡œ ë™ì  ë§¤í•‘ ì‹œìŠ¤í…œ
5. ğŸ conda í™˜ê²½ (mycloset-ai-clean) íŠ¹í™” ìµœì í™”
6. ğŸ M3 Max 128GB ë©”ëª¨ë¦¬ ìµœì í™”
7. ğŸ“‹ register_step ë“± ëª¨ë“  í•„ìˆ˜ ë©”ì„œë“œ ì™„ì „ êµ¬í˜„

Author: MyCloset AI Team
Date: 2025-07-27
Version: 10.0 (GitHub Project Standard Compatibility)
"""

import os
import sys
import logging
import threading
import time
import weakref
import gc
import traceback
import uuid
import asyncio
import concurrent.futures
from pathlib import Path
from typing import Dict, Any, Optional, List, Union, Type, Tuple, TYPE_CHECKING
from dataclasses import dataclass, field
from enum import Enum, IntEnum
from abc import ABC, abstractmethod
from concurrent.futures import ThreadPoolExecutor

# ì•ˆì „í•œ íƒ€ì… íŒíŒ… (ìˆœí™˜ì°¸ì¡° ë°©ì§€)
if TYPE_CHECKING:
    from ..steps.base_step_mixin import BaseStepMixin, GitHubDependencyManager
    from ..utils.model_loader import ModelLoader
    from ..utils.memory_manager import MemoryManager
    from ..utils.data_converter import DataConverter
    from ...core.di_container import DIContainer

# ==============================================
# ğŸ”¥ í™˜ê²½ ì„¤ì • ë° ì‹œìŠ¤í…œ ì •ë³´ (GitHub í‘œì¤€)
# ==============================================

logger = logging.getLogger(__name__)

# conda í™˜ê²½ ì •ë³´ (GitHub í”„ë¡œì íŠ¸ í‘œì¤€)
CONDA_INFO = {
    'conda_env': os.environ.get('CONDA_DEFAULT_ENV', 'none'),
    'conda_prefix': os.environ.get('CONDA_PREFIX', 'none'),
    'is_target_env': os.environ.get('CONDA_DEFAULT_ENV') == 'mycloset-ai-clean'
}

# M3 Max ê°ì§€ (GitHub í”„ë¡œì íŠ¸ í‘œì¤€)
IS_M3_MAX_DETECTED = False  # ğŸ”¥ í‚¤ì›Œë“œ ì¶©ëŒ ì™„ì „ í•´ê²°
MEMORY_GB = 16.0

try:
    import platform
    if platform.system() == 'Darwin' and platform.machine() == 'arm64':
        try:
            import subprocess
            result = subprocess.run(['sysctl', '-n', 'machdep.cpu.brand_string'], 
                                  capture_output=True, text=True, timeout=3)
            IS_M3_MAX_DETECTED = 'M3' in result.stdout
            
            memory_result = subprocess.run(['sysctl', '-n', 'hw.memsize'], 
                                         capture_output=True, text=True, timeout=3)
            if memory_result.stdout.strip():
                MEMORY_GB = int(memory_result.stdout.strip()) / 1024**3
        except:
            pass
except:
    pass

logger.info(f"ğŸ”§ StepFactory v10.0 GitHub í‘œì¤€ í™˜ê²½: conda={CONDA_INFO['conda_env']}, M3 Max={IS_M3_MAX_DETECTED}, ë©”ëª¨ë¦¬={MEMORY_GB:.1f}GB")

# ==============================================
# ğŸ”¥ GitHub í”„ë¡œì íŠ¸ í‘œì¤€ ë°ì´í„° êµ¬ì¡°
# ==============================================

class StepType(Enum):
    """GitHub í”„ë¡œì íŠ¸ í‘œì¤€ Step íƒ€ì…"""
    HUMAN_PARSING = "human_parsing"
    POSE_ESTIMATION = "pose_estimation"
    CLOTH_SEGMENTATION = "cloth_segmentation"
    GEOMETRIC_MATCHING = "geometric_matching"
    CLOTH_WARPING = "cloth_warping"
    VIRTUAL_FITTING = "virtual_fitting"
    POST_PROCESSING = "post_processing"
    QUALITY_ASSESSMENT = "quality_assessment"

class StepPriority(IntEnum):
    """GitHub í”„ë¡œì íŠ¸ í‘œì¤€ Step ìš°ì„ ìˆœìœ„ (ì‹¤ì œ AI ëª¨ë¸ í¬ê¸° ê¸°ë°˜)"""
    CRITICAL = 1    # Virtual Fitting (14GB), Human Parsing (4GB)
    HIGH = 2        # Cloth Warping (7GB), Quality Assessment (7GB)
    NORMAL = 3      # Cloth Segmentation (5.5GB), Pose Estimation (3.4GB)
    LOW = 4         # Post Processing (1.3GB), Geometric Matching (1.3GB)

@dataclass
class GitHubStepConfig:
    """GitHub í”„ë¡œì íŠ¸ í‘œì¤€ Step ì„¤ì • (BaseStepMixin v19.0 í˜¸í™˜)"""
    # GitHub ê¸°ë³¸ Step ì •ë³´
    step_name: str
    step_id: int
    step_type: StepType
    class_name: str
    module_path: str
    priority: StepPriority = StepPriority.NORMAL
    
    # BaseStepMixin v19.0 í‘œì¤€ ì„¤ì •
    device: str = "auto"
    use_fp16: bool = True
    batch_size: int = 1
    confidence_threshold: float = 0.8
    
    # GitHub ìµœì í™” ì„¤ì •
    auto_memory_cleanup: bool = True
    auto_warmup: bool = True
    optimization_enabled: bool = True
    strict_mode: bool = False
    quality_level: str = "balanced"
    
    # GitHub ì˜ì¡´ì„± ì„¤ì • (v19.0 í‘œì¤€)
    auto_inject_dependencies: bool = True
    require_model_loader: bool = True
    require_memory_manager: bool = False
    require_data_converter: bool = False
    require_di_container: bool = False
    require_unified_dependency_manager: bool = True
    dependency_timeout: float = 30.0
    dependency_retry_count: int = 3
    
    # GitHub AI ëª¨ë¸ ì •ë³´ (ì‹¤ì œ 229GB íŒŒì¼ ê¸°ë°˜)
    ai_models: List[str] = field(default_factory=list)
    model_size_gb: float = 0.0
    
    # ğŸ”¥ conda/M3 Max ìµœì í™” (í‚¤ì›Œë“œ ì¶©ëŒ ì™„ì „ í•´ê²°)
    conda_optimized: bool = True
    m3_max_optimized: bool = True
    conda_env: Optional[str] = None
    memory_gb: float = 16.0
    
    # ğŸ”¥ í™˜ê²½ ê°ì§€ í”Œë˜ê·¸ë“¤ (í‚¤ì›Œë“œ ì¶©ëŒ ì™„ì „ í•´ê²°)
    is_m3_max_detected: bool = False  # ğŸ”¥ ë³€ê²½: is_m3_max â†’ is_m3_max_detected
    github_compatible: bool = True
    mycloset_optimized: bool = False
    memory_optimization: bool = False
    conda_target_env: bool = False
    ultra_optimization: bool = False
    performance_mode: str = "balanced"
    memory_pool_enabled: bool = False
    mps_available: bool = False
    mps_optimization: bool = False
    metal_performance_shaders: bool = False
    unified_memory_pool: bool = False
    cuda_optimization: bool = False
    tensor_cores: bool = False
    use_unified_memory: bool = False
    emergency_mode: bool = False
    error_message: Optional[str] = None
    
    # GitHub AI ëª¨ë¸ ê²½ë¡œ ë° ì„¤ì • (ì‹¤ì œ íŒŒì¼ êµ¬ì¡° ê¸°ë°˜)
    ai_model_paths: Dict[str, str] = field(default_factory=dict)
    alternative_path: Optional[str] = None
    real_ai_mode: bool = True
    basestepmixin_compatible: bool = True
    modelloader_required: bool = True
    disable_fallback: bool = True

    def __post_init__(self):
        """GitHub í‘œì¤€ ì´ˆê¸°í™” í›„ ì„¤ì • ë³´ì •"""
        # conda_env ìë™ ì„¤ì •
        if self.conda_env is None:
            self.conda_env = CONDA_INFO['conda_env']
        
        # memory_gb ìë™ ì„¤ì •
        if self.memory_gb <= 0:
            self.memory_gb = MEMORY_GB
        
        # AI ëª¨ë¸ ë¦¬ìŠ¤íŠ¸ ì •ê·œí™”
        if not isinstance(self.ai_models, list):
            self.ai_models = []
        
        # AI ëª¨ë¸ ê²½ë¡œ ë”•ì…”ë„ˆë¦¬ ì •ê·œí™”
        if not isinstance(self.ai_model_paths, dict):
            self.ai_model_paths = {}
        
        # ğŸ”¥ M3 Max ê°ì§€ ë° ìë™ ì„¤ì • (í‚¤ì›Œë“œ ì¶©ëŒ ì—†ì´)
        if IS_M3_MAX_DETECTED:
            self.is_m3_max_detected = True  # ğŸ”¥ ë³€ê²½ëœ í”Œë˜ê·¸ ì‚¬ìš©
            self.mps_available = True
            self.metal_performance_shaders = True
            self.unified_memory_pool = True
            self.use_unified_memory = True
        
        # conda íƒ€ê²Ÿ í™˜ê²½ ê°ì§€
        if CONDA_INFO['is_target_env']:
            self.conda_target_env = True
            self.mycloset_optimized = True
            self.memory_optimization = True
        
        # GitHub ìš¸íŠ¸ë¼ ìµœì í™” ìë™ í™œì„±í™”
        if self.is_m3_max_detected and self.conda_target_env:
            self.ultra_optimization = True
            self.performance_mode = 'maximum'
            self.memory_pool_enabled = True

@dataclass
class GitHubStepCreationResult:
    """GitHub í”„ë¡œì íŠ¸ í‘œì¤€ Step ìƒì„± ê²°ê³¼"""
    success: bool
    step_instance: Optional['BaseStepMixin'] = None
    step_name: str = ""
    step_type: Optional[StepType] = None
    class_name: str = ""
    module_path: str = ""
    creation_time: float = 0.0
    error_message: Optional[str] = None
    warnings: List[str] = field(default_factory=list)
    
    # GitHub ì˜ì¡´ì„± ì£¼ì… ê²°ê³¼
    dependencies_injected: Dict[str, bool] = field(default_factory=dict)
    initialization_success: bool = False
    ai_models_loaded: List[str] = field(default_factory=list)
    
    # GitHub BaseStepMixin v19.0 í˜¸í™˜ì„± ê²€ì¦
    github_compatible: bool = True
    basestepmixin_v19_compatible: bool = True
    process_method_validated: bool = False
    dependency_injection_success: bool = False

# ==============================================
# ğŸ”¥ GitHub í”„ë¡œì íŠ¸ í‘œì¤€ Step ë§¤í•‘ (ì‹¤ì œ íŒŒì¼ ê¸°ë°˜)
# ==============================================

class GitHubStepMapping:
    """GitHub í”„ë¡œì íŠ¸ í‘œì¤€ í˜¸í™˜ Step ë§¤í•‘ (ì‹¤ì œ AI ëª¨ë¸ 229GB ê¸°ë°˜)"""
    
    GITHUB_STEP_CONFIGS = {
        StepType.HUMAN_PARSING: GitHubStepConfig(
            step_name="HumanParsingStep",
            step_id=1,
            step_type=StepType.HUMAN_PARSING,
            class_name="HumanParsingStep",
            module_path="app.ai_pipeline.steps.step_01_human_parsing",
            priority=StepPriority.CRITICAL,
            ai_models=["graphonomy", "atr_model", "human_parsing_schp"],
            model_size_gb=4.0,
            require_model_loader=True,
            require_memory_manager=True
        ),
        StepType.POSE_ESTIMATION: GitHubStepConfig(
            step_name="PoseEstimationStep",
            step_id=2,
            step_type=StepType.POSE_ESTIMATION,
            class_name="PoseEstimationStep",
            module_path="app.ai_pipeline.steps.step_02_pose_estimation",
            priority=StepPriority.NORMAL,
            ai_models=["openpose", "yolov8_pose", "diffusion_pose"],
            model_size_gb=3.4,
            require_model_loader=True,
            require_memory_manager=True
        ),
        StepType.CLOTH_SEGMENTATION: GitHubStepConfig(
            step_name="ClothSegmentationStep",
            step_id=3,
            step_type=StepType.CLOTH_SEGMENTATION,
            class_name="ClothSegmentationStep",
            module_path="app.ai_pipeline.steps.step_03_cloth_segmentation",
            priority=StepPriority.NORMAL,
            ai_models=["u2net", "sam_huge", "cloth_segmentation"],
            model_size_gb=5.5,
            require_model_loader=True,
            require_memory_manager=True
        ),
        StepType.GEOMETRIC_MATCHING: GitHubStepConfig(
            step_name="GeometricMatchingStep",
            step_id=4,
            step_type=StepType.GEOMETRIC_MATCHING,
            class_name="GeometricMatchingStep",
            module_path="app.ai_pipeline.steps.step_04_geometric_matching",
            priority=StepPriority.LOW,
            ai_models=["gmm", "tps_network", "geometric_matching"],
            model_size_gb=1.3,
            require_model_loader=True
        ),
        StepType.CLOTH_WARPING: GitHubStepConfig(
            step_name="ClothWarpingStep",
            step_id=5,
            step_type=StepType.CLOTH_WARPING,
            class_name="ClothWarpingStep",
            module_path="app.ai_pipeline.steps.step_05_cloth_warping",
            priority=StepPriority.HIGH,
            ai_models=["cloth_warping", "stable_diffusion", "hrviton"],
            model_size_gb=7.0,
            require_model_loader=True,
            require_memory_manager=True
        ),
        StepType.VIRTUAL_FITTING: GitHubStepConfig(
            step_name="VirtualFittingStep",
            step_id=6,
            step_type=StepType.VIRTUAL_FITTING,
            class_name="VirtualFittingStep",
            module_path="app.ai_pipeline.steps.step_06_virtual_fitting",
            priority=StepPriority.CRITICAL,
            ai_models=["ootdiffusion", "hr_viton", "virtual_fitting"],
            model_size_gb=14.0,
            require_model_loader=True,
            require_memory_manager=True,
            require_data_converter=True
        ),
        StepType.POST_PROCESSING: GitHubStepConfig(
            step_name="PostProcessingStep",
            step_id=7,
            step_type=StepType.POST_PROCESSING,
            class_name="PostProcessingStep",
            module_path="app.ai_pipeline.steps.step_07_post_processing",
            priority=StepPriority.LOW,
            ai_models=["super_resolution", "realesrgan", "enhancement"],
            model_size_gb=1.3,
            require_model_loader=True
        ),
        StepType.QUALITY_ASSESSMENT: GitHubStepConfig(
            step_name="QualityAssessmentStep",
            step_id=8,
            step_type=StepType.QUALITY_ASSESSMENT,
            class_name="QualityAssessmentStep",
            module_path="app.ai_pipeline.steps.step_08_quality_assessment",
            priority=StepPriority.HIGH,
            ai_models=["clip", "quality_assessment", "perceptual_loss"],
            model_size_gb=7.0,
            require_model_loader=True,
            require_data_converter=True
        )
    }
    
    @classmethod
    def get_github_config(cls, step_type: StepType, **overrides) -> GitHubStepConfig:
        """GitHub í”„ë¡œì íŠ¸ í‘œì¤€ í˜¸í™˜ ì„¤ì • ë°˜í™˜ (í‚¤ì›Œë“œ ì¶©ëŒ ì™„ì „ ë°©ì§€)"""
        base_config = cls.GITHUB_STEP_CONFIGS[step_type]
        
        # kwargsì— conda_envê°€ ì—†ìœ¼ë©´ ìë™ ì¶”ê°€
        if 'conda_env' not in overrides:
            overrides['conda_env'] = os.environ.get('CONDA_DEFAULT_ENV', 'none')
        
        # ğŸ”¥ í‚¤ì›Œë“œ ì¶©ëŒ ì™„ì „ ë°©ì§€ í•„í„°ë§
        filtered_overrides = {}
        config_fields = {f.name for f in base_config.__dataclass_fields__}
        
        for key, value in overrides.items():
            if key in config_fields:
                filtered_overrides[key] = value
            else:
                logger.debug(f"âš ï¸ ë¬´ì‹œëœ í‚¤ì›Œë“œ: {key} (GitHubStepConfigì— ì—†ìŒ)")
        
        # ì»¤ìŠ¤í…€ ì„¤ì •ì´ ìˆìœ¼ë©´ ì ìš©
        if filtered_overrides:
            # ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜í•˜ì—¬ ì˜¤ë²„ë¼ì´ë“œ ì ìš©
            config_dict = {
                'step_name': base_config.step_name,
                'step_id': base_config.step_id,
                'step_type': base_config.step_type,
                'class_name': base_config.class_name,
                'module_path': base_config.module_path,
                'priority': base_config.priority,
                'device': base_config.device,
                'use_fp16': base_config.use_fp16,
                'batch_size': base_config.batch_size,
                'confidence_threshold': base_config.confidence_threshold,
                'auto_memory_cleanup': base_config.auto_memory_cleanup,
                'auto_warmup': base_config.auto_warmup,
                'optimization_enabled': base_config.optimization_enabled,
                'strict_mode': base_config.strict_mode,
                'quality_level': base_config.quality_level,
                'auto_inject_dependencies': base_config.auto_inject_dependencies,
                'require_model_loader': base_config.require_model_loader,
                'require_memory_manager': base_config.require_memory_manager,
                'require_data_converter': base_config.require_data_converter,
                'require_di_container': base_config.require_di_container,
                'require_unified_dependency_manager': base_config.require_unified_dependency_manager,
                'dependency_timeout': base_config.dependency_timeout,
                'dependency_retry_count': base_config.dependency_retry_count,
                'ai_models': base_config.ai_models.copy(),
                'model_size_gb': base_config.model_size_gb,
                'conda_optimized': base_config.conda_optimized,
                'm3_max_optimized': base_config.m3_max_optimized,
                'conda_env': base_config.conda_env,
                'memory_gb': base_config.memory_gb
            }
            # filtered_overridesë¥¼ ì ìš©
            config_dict.update(filtered_overrides)
            return GitHubStepConfig(**config_dict)
        
        return base_config

# ==============================================
# ğŸ”¥ GitHub í˜¸í™˜ ì˜ì¡´ì„± í•´ê²°ê¸° (v19.0 ì—°ë™)
# ==============================================

class GitHubDependencyResolver:
    """GitHub í”„ë¡œì íŠ¸ í˜¸í™˜ ì˜ì¡´ì„± í•´ê²°ê¸° (BaseStepMixin v19.0 ì—°ë™)"""
    
    def __init__(self):
        self.logger = logging.getLogger(f"{__name__}.GitHubDependencyResolver")
        self._resolved_cache: Dict[str, Any] = {}
        self._lock = threading.RLock()
        self._resolution_attempts: Dict[str, int] = {}
        self._max_attempts = 3
    
    def resolve_github_dependencies_for_constructor(self, config: GitHubStepConfig) -> Dict[str, Any]:
        """GitHub í”„ë¡œì íŠ¸ í‘œì¤€ ìƒì„±ììš© ì˜ì¡´ì„± í•´ê²° (í‚¤ì›Œë“œ ì¶©ëŒ ì™„ì „ ì œê±°)"""
        try:
            self.logger.info(f"ğŸ”„ {config.step_name} GitHub í‘œì¤€ ìƒì„±ì ì˜ì¡´ì„± í•´ê²° ì‹œì‘...")
            
            # ğŸ”¥ ê¸°ë³¸ dependency ë”•ì…”ë„ˆë¦¬ (í‚¤ì›Œë“œ ì¶©ëŒ ì™„ì „ ì—†ìŒ)
            dependencies = {}
            
            # 1. GitHub BaseStepMixin v19.0 í‘œì¤€ ì„¤ì •ë“¤
            dependencies.update({
                'step_name': config.step_name,
                'step_id': config.step_id,
                'device': self._resolve_github_device(config.device),
                'use_fp16': config.use_fp16,
                'batch_size': config.batch_size,
                'confidence_threshold': config.confidence_threshold,
                'auto_memory_cleanup': config.auto_memory_cleanup,
                'auto_warmup': config.auto_warmup,
                'optimization_enabled': config.optimization_enabled,
                'strict_mode': config.strict_mode,
                'github_compatibility_mode': config.github_compatible
            })
            
            # 2. conda í™˜ê²½ ì„¤ì • (GitHub í‘œì¤€)
            if config.conda_optimized:
                conda_env = getattr(config, 'conda_env', None) or CONDA_INFO['conda_env']
                
                dependencies.update({
                    'conda_optimized': True,
                    'conda_env': conda_env
                })
                
                # mycloset-ai-clean í™˜ê²½ íŠ¹ë³„ ìµœì í™”
                if conda_env == 'mycloset-ai-clean' or CONDA_INFO['is_target_env']:
                    dependencies.update({
                        'mycloset_optimized': True,
                        'memory_optimization': True,
                        'conda_target_env': True
                    })
                    self.logger.info(f"âœ… {config.step_name} mycloset-ai-clean í™˜ê²½ ìµœì í™” ì ìš©")
            
            # 3. ğŸ”¥ M3 Max í•˜ë“œì›¨ì–´ ìµœì í™” (í‚¤ì›Œë“œ ì¶©ëŒ ì™„ì „ í•´ê²°)
            if config.m3_max_optimized and IS_M3_MAX_DETECTED:
                dependencies.update({
                    'm3_max_optimized': True,
                    'memory_gb': MEMORY_GB,
                    'use_unified_memory': True,
                    'is_m3_max_detected': True,  # ğŸ”¥ ë³€ê²½ëœ í‚¤ì›Œë“œ ì‚¬ìš©
                    'mps_available': True if dependencies.get('device') == 'mps' else False
                })
                self.logger.info(f"âœ… {config.step_name} M3 Max ìµœì í™” ì ìš© ({MEMORY_GB}GB)")
            
            # 4. GitHub ì˜ì¡´ì„± ì»´í¬ë„ŒíŠ¸ë“¤ ì•ˆì „í•œ í•´ê²°
            self._inject_github_component_dependencies(config, dependencies)
            
            # 5. GitHub AI ëª¨ë¸ ì„¤ì • ë° ê²½ë¡œ ë§¤í•‘ (ì‹¤ì œ 229GB íŒŒì¼ ê¸°ë°˜)
            dependencies.update({
                'ai_models': config.ai_models.copy() if hasattr(config.ai_models, 'copy') else list(config.ai_models),
                'model_size_gb': config.model_size_gb,
                'real_ai_mode': config.real_ai_mode
            })
            
            # 6. GitHub í™˜ê²½ë³„ ì„±ëŠ¥ ìµœì í™” ì„¤ì •
            self._apply_github_performance_optimizations(dependencies)
            
            # 7. ê²°ê³¼ ê²€ì¦ ë° ë¡œê¹…
            resolved_count = len([k for k, v in dependencies.items() if v is not None])
            total_items = len(dependencies)
            
            self.logger.info(f"âœ… {config.step_name} GitHub í‘œì¤€ ìƒì„±ì ì˜ì¡´ì„± í•´ê²° ì™„ë£Œ:")
            self.logger.info(f"   - ì´ í•­ëª©: {total_items}ê°œ")
            self.logger.info(f"   - í•´ê²°ëœ í•­ëª©: {resolved_count}ê°œ")
            self.logger.info(f"   - conda í™˜ê²½: {dependencies.get('conda_env', 'none')}")
            self.logger.info(f"   - ë””ë°”ì´ìŠ¤: {dependencies.get('device', 'unknown')}")
            
            # GitHub í•„ìˆ˜ ì˜ì¡´ì„± ê²€ì¦ (strict_modeì¼ ë•Œ)
            if config.strict_mode:
                self._validate_github_critical_dependencies(dependencies)
            
            return dependencies
            
        except Exception as e:
            self.logger.error(f"âŒ {config.step_name} GitHub í‘œì¤€ ìƒì„±ì ì˜ì¡´ì„± í•´ê²° ì‹¤íŒ¨: {e}")
            
            # ì‘ê¸‰ ëª¨ë“œ: ìµœì†Œí•œì˜ ì˜ì¡´ì„±ë§Œ ë°˜í™˜
            if not config.strict_mode:
                return self._create_github_emergency_dependencies(config, str(e))
            else:
                raise

    def _inject_github_component_dependencies(self, config: GitHubStepConfig, dependencies: Dict[str, Any]):
        """GitHub í”„ë¡œì íŠ¸ í‘œì¤€ ì»´í¬ë„ŒíŠ¸ ì˜ì¡´ì„± ì£¼ì…"""
        # ModelLoader ì˜ì¡´ì„± (GitHub í‘œì¤€)
        if config.require_model_loader:
            try:
                model_loader = self._resolve_github_model_loader()
                dependencies['model_loader'] = model_loader
                if model_loader:
                    self.logger.info(f"âœ… {config.step_name} GitHub ModelLoader ìƒì„±ì ì£¼ì… ì¤€ë¹„")
                else:
                    self.logger.warning(f"âš ï¸ {config.step_name} GitHub ModelLoader í•´ê²° ì‹¤íŒ¨")
            except Exception as e:
                self.logger.error(f"âŒ {config.step_name} GitHub ModelLoader í•´ê²° ì¤‘ ì˜¤ë¥˜: {e}")
                dependencies['model_loader'] = None
        
        # MemoryManager ì˜ì¡´ì„± (GitHub í‘œì¤€)
        if config.require_memory_manager:
            try:
                memory_manager = self._resolve_github_memory_manager()
                dependencies['memory_manager'] = memory_manager
                if memory_manager:
                    self.logger.info(f"âœ… {config.step_name} GitHub MemoryManager ìƒì„±ì ì£¼ì… ì¤€ë¹„")
            except Exception as e:
                self.logger.error(f"âŒ {config.step_name} GitHub MemoryManager í•´ê²° ì¤‘ ì˜¤ë¥˜: {e}")
                dependencies['memory_manager'] = None
        
        # DataConverter ì˜ì¡´ì„± (GitHub í‘œì¤€)
        if config.require_data_converter:
            try:
                data_converter = self._resolve_github_data_converter()
                dependencies['data_converter'] = data_converter
                if data_converter:
                    self.logger.info(f"âœ… {config.step_name} GitHub DataConverter ìƒì„±ì ì£¼ì… ì¤€ë¹„")
            except Exception as e:
                self.logger.error(f"âŒ {config.step_name} GitHub DataConverter í•´ê²° ì¤‘ ì˜¤ë¥˜: {e}")
                dependencies['data_converter'] = None
        
        # DIContainer ì˜ì¡´ì„± (GitHub í‘œì¤€)
        if config.require_di_container:
            try:
                di_container = self._resolve_github_di_container()
                dependencies['di_container'] = di_container
                if di_container:
                    self.logger.info(f"âœ… {config.step_name} GitHub DIContainer ìƒì„±ì ì£¼ì… ì¤€ë¹„")
            except Exception as e:
                self.logger.error(f"âŒ {config.step_name} GitHub DIContainer í•´ê²° ì¤‘ ì˜¤ë¥˜: {e}")
                dependencies['di_container'] = None
        
        # UnifiedDependencyManager ì˜ì¡´ì„± (GitHub í‘œì¤€)
        if config.require_unified_dependency_manager:
            try:
                unified_dep_manager = self._resolve_github_unified_dependency_manager()
                dependencies['unified_dependency_manager'] = unified_dep_manager
                if unified_dep_manager:
                    self.logger.info(f"âœ… {config.step_name} GitHub UnifiedDependencyManager ìƒì„±ì ì£¼ì… ì¤€ë¹„")
            except Exception as e:
                self.logger.error(f"âŒ {config.step_name} GitHub UnifiedDependencyManager í•´ê²° ì¤‘ ì˜¤ë¥˜: {e}")
                dependencies['unified_dependency_manager'] = None

    def _apply_github_performance_optimizations(self, dependencies: Dict[str, Any]):
        """GitHub í”„ë¡œì íŠ¸ í‘œì¤€ ì„±ëŠ¥ ìµœì í™” ì„¤ì • ì ìš©"""
        # conda + M3 Max ì¡°í•© ìµœì í™” (GitHub í‘œì¤€)
        if (dependencies.get('conda_target_env') and dependencies.get('is_m3_max_detected')):
            dependencies.update({
                'ultra_optimization': True,
                'performance_mode': 'maximum',
                'memory_pool_enabled': True
            })
            
        # ë””ë°”ì´ìŠ¤ë³„ ìµœì í™” (GitHub í‘œì¤€)
        device = dependencies.get('device', 'cpu')
        if device == 'mps' and dependencies.get('is_m3_max_detected'):
            dependencies.update({
                'mps_optimization': True,
                'metal_performance_shaders': True,
                'unified_memory_pool': True
            })
        elif device == 'cuda':
            dependencies.update({
                'cuda_optimization': True,
                'tensor_cores': True
            })

    def _validate_github_critical_dependencies(self, dependencies: Dict[str, Any]):
        """GitHub í•„ìˆ˜ ì˜ì¡´ì„± ê²€ì¦"""
        critical_deps = ['step_name', 'step_id', 'device']
        missing_critical = [dep for dep in critical_deps if not dependencies.get(dep)]
        if missing_critical:
            raise RuntimeError(f"GitHub Strict Mode: í•„ìˆ˜ ì˜ì¡´ì„± ëˆ„ë½ - {missing_critical}")

    def _create_github_emergency_dependencies(self, config: GitHubStepConfig, error_msg: str) -> Dict[str, Any]:
        """GitHub ì‘ê¸‰ ëª¨ë“œ ìµœì†Œ ì˜ì¡´ì„±"""
        self.logger.warning(f"âš ï¸ {config.step_name} GitHub ì‘ê¸‰ ëª¨ë“œë¡œ ìµœì†Œ ì˜ì¡´ì„± ë°˜í™˜")
        return {
            'step_name': config.step_name,
            'step_id': config.step_id,
            'device': 'cpu',
            'conda_env': getattr(config, 'conda_env', CONDA_INFO['conda_env']),
            'github_compatibility_mode': True,
            'emergency_mode': True,
            'error_message': error_msg
        }

    def _resolve_github_device(self, device: str) -> str:
        """GitHub í”„ë¡œì íŠ¸ í‘œì¤€ ë””ë°”ì´ìŠ¤ í•´ê²°"""
        if device != "auto":
            return device
        
        if IS_M3_MAX_DETECTED:
            return "mps"
        
        try:
            import torch
            if torch.cuda.is_available():
                return "cuda"
            elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
                return "mps"
        except ImportError:
            pass
        
        return "cpu"
    
    def _resolve_github_model_loader(self) -> Optional['ModelLoader']:
        """GitHub í”„ë¡œì íŠ¸ í‘œì¤€ ModelLoader í•´ê²°"""
        try:
            with self._lock:
                cache_key = "github_model_loader"
                if cache_key in self._resolved_cache:
                    return self._resolved_cache[cache_key]
                
                attempts = self._resolution_attempts.get(cache_key, 0)
                if attempts >= self._max_attempts:
                    self.logger.warning(f"GitHub ModelLoader í•´ê²° ì‹œë„ í•œê³„ ì´ˆê³¼: {attempts}")
                    return None
                
                self._resolution_attempts[cache_key] = attempts + 1
                
                try:
                    from app.ai_pipeline.utils.model_loader import get_global_model_loader
                    model_loader = get_global_model_loader()
                    
                    if model_loader:
                        # GitHub í”„ë¡œì íŠ¸ íŠ¹ë³„ ì„¤ì •
                        if CONDA_INFO['is_target_env'] and hasattr(model_loader, 'configure_github'):
                            github_config = {
                                'conda_optimized': True,
                                'conda_env': CONDA_INFO['conda_env'],
                                'm3_max_optimized': IS_M3_MAX_DETECTED,
                                'memory_gb': MEMORY_GB,
                                'github_mode': True,
                                'real_ai_pipeline': True
                            }
                            model_loader.configure_github(github_config)
                        
                        self._resolved_cache[cache_key] = model_loader
                        self.logger.info("âœ… GitHub ModelLoader í•´ê²° ì™„ë£Œ")
                        return model_loader
                    
                except ImportError:
                    try:
                        from ..utils.model_loader import get_global_model_loader
                        model_loader = get_global_model_loader()
                        if model_loader:
                            self._resolved_cache[cache_key] = model_loader
                            self.logger.info("âœ… GitHub ModelLoader í•´ê²° ì™„ë£Œ (ìƒëŒ€ ê²½ë¡œ)")
                            return model_loader
                    except ImportError:
                        self.logger.debug("GitHub ModelLoader import ì‹¤íŒ¨")
                        return None
                    
        except Exception as e:
            self.logger.error(f"âŒ GitHub ModelLoader í•´ê²° ì‹¤íŒ¨: {e}")
            return None
    
    def _resolve_github_memory_manager(self) -> Optional['MemoryManager']:
        """GitHub í”„ë¡œì íŠ¸ í‘œì¤€ MemoryManager í•´ê²°"""
        try:
            with self._lock:
                cache_key = "github_memory_manager"
                if cache_key in self._resolved_cache:
                    return self._resolved_cache[cache_key]
                
                try:
                    from app.ai_pipeline.utils.memory_manager import get_global_memory_manager
                    memory_manager = get_global_memory_manager()
                    
                    if memory_manager:
                        # GitHub M3 Max íŠ¹ë³„ ì„¤ì •
                        if IS_M3_MAX_DETECTED and hasattr(memory_manager, 'configure_github_m3_max'):
                            memory_manager.configure_github_m3_max(memory_gb=MEMORY_GB)
                        
                        self._resolved_cache[cache_key] = memory_manager
                        self.logger.info("âœ… GitHub MemoryManager í•´ê²° ì™„ë£Œ")
                        return memory_manager
                        
                except ImportError:
                    try:
                        from ..utils.memory_manager import get_global_memory_manager
                        memory_manager = get_global_memory_manager()
                        if memory_manager:
                            self._resolved_cache[cache_key] = memory_manager
                            self.logger.info("âœ… GitHub MemoryManager í•´ê²° ì™„ë£Œ (ìƒëŒ€ ê²½ë¡œ)")
                            return memory_manager
                    except ImportError:
                        return None
                    
        except Exception as e:
            self.logger.debug(f"GitHub MemoryManager í•´ê²° ì‹¤íŒ¨: {e}")
            return None
    
    def _resolve_github_data_converter(self) -> Optional['DataConverter']:
        """GitHub í”„ë¡œì íŠ¸ í‘œì¤€ DataConverter í•´ê²°"""
        try:
            with self._lock:
                cache_key = "github_data_converter"
                if cache_key in self._resolved_cache:
                    return self._resolved_cache[cache_key]
                
                try:
                    from app.ai_pipeline.utils.data_converter import get_global_data_converter
                    data_converter = get_global_data_converter()
                    if data_converter:
                        self._resolved_cache[cache_key] = data_converter
                        self.logger.info("âœ… GitHub DataConverter í•´ê²° ì™„ë£Œ")
                        return data_converter
                        
                except ImportError:
                    try:
                        from ..utils.data_converter import get_global_data_converter
                        data_converter = get_global_data_converter()
                        if data_converter:
                            self._resolved_cache[cache_key] = data_converter
                            self.logger.info("âœ… GitHub DataConverter í•´ê²° ì™„ë£Œ (ìƒëŒ€ ê²½ë¡œ)")
                            return data_converter
                    except ImportError:
                        return None
                    
        except Exception as e:
            self.logger.debug(f"GitHub DataConverter í•´ê²° ì‹¤íŒ¨: {e}")
            return None
    
    def _resolve_github_di_container(self) -> Optional['DIContainer']:
        """GitHub í”„ë¡œì íŠ¸ í‘œì¤€ DI Container í•´ê²°"""
        try:
            with self._lock:
                cache_key = "github_di_container"
                if cache_key in self._resolved_cache:
                    return self._resolved_cache[cache_key]
                
                try:
                    from app.core.di_container import get_global_di_container
                    di_container = get_global_di_container()
                    if di_container:
                        self._resolved_cache[cache_key] = di_container
                        self.logger.info("âœ… GitHub DIContainer í•´ê²° ì™„ë£Œ")
                        return di_container
                        
                except ImportError:
                    try:
                        from ...core.di_container import get_global_di_container
                        di_container = get_global_di_container()
                        if di_container:
                            self._resolved_cache[cache_key] = di_container
                            self.logger.info("âœ… GitHub DIContainer í•´ê²° ì™„ë£Œ (ìƒëŒ€ ê²½ë¡œ)")
                            return di_container
                    except ImportError:
                        return None
                    
        except Exception as e:
            self.logger.debug(f"GitHub DIContainer í•´ê²° ì‹¤íŒ¨: {e}")
            return None
    
    def _resolve_github_unified_dependency_manager(self) -> Optional[Any]:
        """GitHub í”„ë¡œì íŠ¸ í‘œì¤€ UnifiedDependencyManager í•´ê²°"""
        try:
            with self._lock:
                cache_key = "github_unified_dependency_manager"
                if cache_key in self._resolved_cache:
                    return self._resolved_cache[cache_key]
                
                try:
                    try:
                        from app.ai_pipeline.steps.base_step_mixin import GitHubDependencyManager
                    except ImportError:
                        from ..steps.base_step_mixin import GitHubDependencyManager
                    
                    # ğŸ”¥ í‚¤ì›Œë“œ ì¶©ëŒ ì—†ì´ ìƒì„± (GitHub í‘œì¤€)
                    github_manager = GitHubDependencyManager(
                        step_name="GlobalStepFactory",
                        memory_gb=MEMORY_GB,
                        quality_level="balanced",
                        auto_inject_dependencies=True,
                        dependency_timeout=30.0,
                        dependency_retry_count=3,
                        is_m3_max_detected=IS_M3_MAX_DETECTED,  # ğŸ”¥ ë³€ê²½ëœ í‚¤ì›Œë“œ ì‚¬ìš©
                        mycloset_optimized=CONDA_INFO['is_target_env'],
                        memory_optimization=True,
                        conda_target_env=CONDA_INFO['is_target_env'],
                        ultra_optimization=IS_M3_MAX_DETECTED and CONDA_INFO['is_target_env'],
                        performance_mode="maximum" if IS_M3_MAX_DETECTED else "balanced",
                        memory_pool_enabled=IS_M3_MAX_DETECTED,
                        mps_available=IS_M3_MAX_DETECTED,
                        real_ai_mode=True,
                        basestepmixin_compatible=True,
                        modelloader_required=True,
                        disable_fallback=True,
                        conda_info=CONDA_INFO,
                        github_mode=True
                    )
                    
                    self._resolved_cache[cache_key] = github_manager
                    self.logger.info("âœ… GitHub UnifiedDependencyManager í•´ê²° ì™„ë£Œ")
                    return github_manager
                    
                except ImportError:
                    # í´ë°±: Mock ê°ì²´ ìƒì„± (GitHub í‘œì¤€)
                    class MockGitHubUnifiedDependencyManager:
                        def __init__(self, **kwargs):
                            for key, value in kwargs.items():
                                setattr(self, key, value)
                    
                    mock_manager = MockGitHubUnifiedDependencyManager(
                        step_name="GlobalStepFactory",
                        is_m3_max_detected=IS_M3_MAX_DETECTED,
                        memory_gb=MEMORY_GB,
                        conda_info=CONDA_INFO,
                        github_mode=True
                    )
                    self._resolved_cache[cache_key] = mock_manager
                    self.logger.info("âœ… GitHub UnifiedDependencyManager í•´ê²° ì™„ë£Œ (Mock)")
                    return mock_manager
                    
        except Exception as e:
            self.logger.debug(f"GitHub UnifiedDependencyManager í•´ê²° ì‹¤íŒ¨: {e}")
            return None
    
    def clear_cache(self):
        """ìºì‹œ ì •ë¦¬"""
        with self._lock:
            self._resolved_cache.clear()
            self._resolution_attempts.clear()
            gc.collect()

# ==============================================
# ğŸ”¥ GitHub í˜¸í™˜ ë™ì  Step í´ë˜ìŠ¤ ë¡œë”
# ==============================================

class GitHubStepClassLoader:
    """GitHub í”„ë¡œì íŠ¸ í˜¸í™˜ ë™ì  Step í´ë˜ìŠ¤ ë¡œë”"""
    
    def __init__(self):
        self.logger = logging.getLogger(f"{__name__}.GitHubStepClassLoader")
        self._loaded_classes: Dict[str, Type] = {}
        self._import_attempts: Dict[str, int] = {}
        self._lock = threading.RLock()
        self._max_attempts = 5
    
    def load_github_step_class(self, config: GitHubStepConfig) -> Optional[Type]:
        """GitHub í”„ë¡œì íŠ¸ í˜¸í™˜ Step í´ë˜ìŠ¤ ë¡œë”©"""
        try:
            with self._lock:
                cache_key = config.class_name
                if cache_key in self._loaded_classes:
                    return self._loaded_classes[cache_key]
                
                attempts = self._import_attempts.get(cache_key, 0)
                if attempts >= self._max_attempts:
                    self.logger.error(f"âŒ {config.class_name} GitHub import ì¬ì‹œë„ í•œê³„ ì´ˆê³¼")
                    return None
                
                self._import_attempts[cache_key] = attempts + 1
                
                self.logger.info(f"ğŸ”„ {config.class_name} GitHub ë™ì  ë¡œë”© ì‹œì‘ (ì‹œë„ {attempts + 1}/{self._max_attempts})...")
                
                step_class = self._dynamic_import_github_step_class(config)
                
                if step_class:
                    if self._validate_github_step_compatibility(step_class, config):
                        self._loaded_classes[cache_key] = step_class
                        self.logger.info(f"âœ… {config.class_name} GitHub ë™ì  ë¡œë”© ì„±ê³µ (BaseStepMixin v19.0 í˜¸í™˜)")
                        return step_class
                    else:
                        self.logger.error(f"âŒ {config.class_name} GitHub BaseStepMixin v19.0 í˜¸í™˜ì„± ê²€ì¦ ì‹¤íŒ¨")
                        return None
                else:
                    self.logger.error(f"âŒ {config.class_name} GitHub ë™ì  import ì‹¤íŒ¨")
                    return None
                    
        except Exception as e:
            self.logger.error(f"âŒ {config.class_name} GitHub ë™ì  ë¡œë”© ì˜ˆì™¸: {e}")
            return None
    
    def _dynamic_import_github_step_class(self, config: GitHubStepConfig) -> Optional[Type]:
        """GitHub í”„ë¡œì íŠ¸ í‘œì¤€ ë™ì  import ì‹¤í–‰"""
        import importlib
        
        base_module = config.module_path
        
        # GitHub í”„ë¡œì íŠ¸ í‘œì¤€ import ê²½ë¡œë“¤
        github_import_paths = [
            base_module,
            f"app.ai_pipeline.steps.{config.module_path.split('.')[-1]}",
            f"ai_pipeline.steps.{config.module_path.split('.')[-1]}",
            f"backend.{base_module}",
            f"..steps.{config.module_path.split('.')[-1]}",
            f"backend.app.ai_pipeline.steps.{config.module_path.split('.')[-1]}",
            f"app.ai_pipeline.steps.step_{config.step_id:02d}_{config.step_type.value}",
            f"steps.{config.class_name.lower()}"
        ]
        
        for import_path in github_import_paths:
            try:
                self.logger.debug(f"ğŸ” {config.class_name} GitHub import ì‹œë„: {import_path}")
                
                module = importlib.import_module(import_path)
                
                if hasattr(module, config.class_name):
                    step_class = getattr(module, config.class_name)
                    self.logger.info(f"âœ… {config.class_name} GitHub ë™ì  import ì„±ê³µ: {import_path}")
                    return step_class
                else:
                    self.logger.debug(f"âš ï¸ {import_path}ì— {config.class_name} í´ë˜ìŠ¤ ì—†ìŒ")
                    continue
                    
            except ImportError as e:
                self.logger.debug(f"âš ï¸ {import_path} GitHub import ì‹¤íŒ¨: {e}")
                continue
            except Exception as e:
                self.logger.warning(f"âš ï¸ {import_path} GitHub import ì˜ˆì™¸: {e}")
                continue
        
        self.logger.error(f"âŒ {config.class_name} ëª¨ë“  GitHub ê²½ë¡œì—ì„œ import ì‹¤íŒ¨")
        return None
    
    def _validate_github_step_compatibility(self, step_class: Type, config: GitHubStepConfig) -> bool:
        """GitHub BaseStepMixin v19.0 í˜¸í™˜ì„± ê²€ì¦"""
        try:
            if not step_class or step_class.__name__ != config.class_name:
                return False
            
            mro_names = [cls.__name__ for cls in step_class.__mro__]
            if 'BaseStepMixin' not in mro_names:
                self.logger.warning(f"âš ï¸ {config.class_name}ì´ BaseStepMixinì„ ìƒì†í•˜ì§€ ì•ŠìŒ")
            
            # GitHub í”„ë¡œì íŠ¸ í‘œì¤€ í•„ìˆ˜ ë©”ì„œë“œë“¤
            required_methods = ['process', 'initialize']
            missing_methods = []
            for method in required_methods:
                if not hasattr(step_class, method):
                    missing_methods.append(method)
            
            if missing_methods:
                self.logger.error(f"âŒ {config.class_name}ì— GitHub í•„ìˆ˜ ë©”ì„œë“œ ì—†ìŒ: {missing_methods}")
                return False
            
            # GitHub ìƒì„±ì í˜¸ì¶œ í…ŒìŠ¤íŠ¸ (BaseStepMixin v19.0 í‘œì¤€ kwargs)
            try:
                test_kwargs = {
                    'step_name': 'github_test',
                    'step_id': config.step_id,
                    'device': 'cpu',
                    'github_compatibility_mode': True
                }
                test_instance = step_class(**test_kwargs)
                if test_instance:
                    self.logger.debug(f"âœ… {config.class_name} GitHub BaseStepMixin v19.0 ìƒì„±ì í…ŒìŠ¤íŠ¸ ì„±ê³µ")
                    if hasattr(test_instance, 'cleanup'):
                        try:
                            if asyncio.iscoroutinefunction(test_instance.cleanup):
                                pass
                            else:
                                test_instance.cleanup()
                        except:
                            pass
                    del test_instance
                    return True
            except Exception as e:
                self.logger.warning(f"âš ï¸ {config.class_name} GitHub ìƒì„±ì í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
                try:
                    test_instance = step_class()
                    if test_instance:
                        self.logger.debug(f"âœ… {config.class_name} GitHub ê¸°ë³¸ ìƒì„±ì í…ŒìŠ¤íŠ¸ ì„±ê³µ")
                        del test_instance
                        return True
                except Exception:
                    pass
                return True
            
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ {config.class_name} GitHub BaseStepMixin v19.0 í˜¸í™˜ì„± ê²€ì¦ ì‹¤íŒ¨: {e}")
            return False

# ==============================================
# ğŸ”¥ ë©”ì¸ StepFactory v10.0 (GitHub í”„ë¡œì íŠ¸ ì™„ì „ í˜¸í™˜)
# ==============================================

class StepFactory:
    """
    ğŸ”¥ StepFactory v10.0 - GitHub í”„ë¡œì íŠ¸ ì™„ì „ í˜¸í™˜ (BaseStepMixin v19.0)
    
    í•µì‹¬ ìˆ˜ì •ì‚¬í•­:
    âœ… GitHub í”„ë¡œì íŠ¸ í‘œì¤€ ì™„ì „ í˜¸í™˜
    âœ… keyword argument repeated: is_m3_max ì˜¤ë¥˜ ì™„ì „ í•´ê²°
    âœ… BaseStepMixin v19.0 í‘œì¤€ ì™„ì „ í˜¸í™˜
    âœ… ìƒì„±ì ì‹œì  ì˜ì¡´ì„± ì£¼ì… (constructor injection)
    âœ… process() ë©”ì„œë“œ ì‹œê·¸ë‹ˆì²˜ í‘œì¤€í™”
    âœ… GitHubDependencyManager ì™„ì „ í™œìš©
    âœ… conda í™˜ê²½ ìš°ì„  ìµœì í™”
    âœ… register_step, unregister_step, is_step_registered, get_registered_steps ë©”ì„œë“œ ì™„ì „ êµ¬í˜„
    """
    
    def __init__(self):
        self.logger = logging.getLogger("StepFactory.v10")
        
        # GitHub BaseStepMixin v19.0 í˜¸í™˜ ì»´í¬ë„ŒíŠ¸ë“¤
        self.class_loader = GitHubStepClassLoader()
        self.dependency_resolver = GitHubDependencyResolver()
        
        # GitHub ë“±ë¡ëœ Step í´ë˜ìŠ¤ë“¤ ê´€ë¦¬
        self._registered_steps: Dict[str, Type['BaseStepMixin']] = {}
        self._step_type_mapping: Dict[str, StepType] = {}
        
        # ìºì‹œ ê´€ë¦¬
        self._step_cache: Dict[str, weakref.ref] = {}
        self._lock = threading.RLock()
        
        # GitHub í†µê³„
        self._stats = {
            'total_created': 0,
            'successful_creations': 0,
            'failed_creations': 0,
            'cache_hits': 0,
            'github_compatible_creations': 0,
            'dependency_injection_successes': 0,
            'conda_optimized': CONDA_INFO['is_target_env'],
            'm3_max_optimized': IS_M3_MAX_DETECTED,
            'registered_steps': 0
        }
        
        self.logger.info("ğŸ­ StepFactory v10.0 ì´ˆê¸°í™” ì™„ë£Œ (GitHub í”„ë¡œì íŠ¸ í‘œì¤€ + BaseStepMixin v19.0)")

    # ==============================================
    # ğŸ”¥ GitHub Step ë“±ë¡ ê´€ë¦¬ ë©”ì„œë“œë“¤
    # ==============================================
    
    def register_step(self, step_id: str, step_class: Type['BaseStepMixin']) -> bool:
        """GitHub Step í´ë˜ìŠ¤ë¥¼ íŒ©í† ë¦¬ì— ë“±ë¡"""
        try:
            with self._lock:
                self.logger.info(f"ğŸ“ {step_id} GitHub Step í´ë˜ìŠ¤ ë“±ë¡ ì‹œì‘...")
                
                if not step_id or not step_class:
                    self.logger.error(f"âŒ ì˜ëª»ëœ ì¸ì: step_id={step_id}, step_class={step_class}")
                    return False
                
                if not self._validate_github_step_class(step_class, step_id):
                    return False
                
                step_type = self._extract_step_type_from_id(step_id)
                
                self._registered_steps[step_id] = step_class
                if step_type:
                    self._step_type_mapping[step_id] = step_type
                
                class_name = step_class.__name__
                module_name = step_class.__module__
                
                self.logger.info(f"âœ… {step_id} GitHub Step í´ë˜ìŠ¤ ë“±ë¡ ì™„ë£Œ")
                self.logger.info(f"   - í´ë˜ìŠ¤: {class_name}")
                self.logger.info(f"   - ëª¨ë“ˆ: {module_name}")
                self.logger.info(f"   - StepType: {step_type.value if step_type else 'Unknown'}")
                
                self._stats['registered_steps'] = len(self._registered_steps)
                return True
                
        except Exception as e:
            self.logger.error(f"âŒ {step_id} GitHub Step ë“±ë¡ ì‹¤íŒ¨: {e}")
            return False
    
    def _validate_github_step_class(self, step_class: Type['BaseStepMixin'], step_id: str) -> bool:
        """GitHub Step í´ë˜ìŠ¤ ê¸°ë³¸ ê²€ì¦"""
        try:
            if not isinstance(step_class, type):
                self.logger.error(f"âŒ {step_id}: step_classê°€ í´ë˜ìŠ¤ íƒ€ì…ì´ ì•„ë‹™ë‹ˆë‹¤")
                return False
            
            required_methods = ['process']
            missing_methods = []
            
            for method_name in required_methods:
                if not hasattr(step_class, method_name):
                    missing_methods.append(method_name)
            
            if missing_methods:
                self.logger.error(f"âŒ {step_id}: GitHub í•„ìˆ˜ ë©”ì„œë“œ ì—†ìŒ - {missing_methods}")
                return False
            
            mro_names = [cls.__name__ for cls in step_class.__mro__]
            if 'BaseStepMixin' not in mro_names:
                self.logger.warning(f"âš ï¸ {step_id}: BaseStepMixinì„ ìƒì†í•˜ì§€ ì•ŠìŒ (ê³„ì† ì§„í–‰)")
            
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ {step_id} GitHub í´ë˜ìŠ¤ ê²€ì¦ ì‹¤íŒ¨: {e}")
            return False
    
    def _extract_step_type_from_id(self, step_id: str) -> Optional[StepType]:
        """Step IDì—ì„œ StepType ì¶”ì¶œ"""
        try:
            step_mapping = {
                'step_01': StepType.HUMAN_PARSING,
                'step_02': StepType.POSE_ESTIMATION,
                'step_03': StepType.CLOTH_SEGMENTATION,
                'step_04': StepType.GEOMETRIC_MATCHING,
                'step_05': StepType.CLOTH_WARPING,
                'step_06': StepType.VIRTUAL_FITTING,
                'step_07': StepType.POST_PROCESSING,
                'step_08': StepType.QUALITY_ASSESSMENT
            }
            
            return step_mapping.get(step_id.lower())
            
        except Exception as e:
            self.logger.debug(f"StepType ì¶”ì¶œ ì‹¤íŒ¨ ({step_id}): {e}")
            return None
    
    def unregister_step(self, step_id: str) -> bool:
        """GitHub Step ë“±ë¡ í•´ì œ"""
        try:
            with self._lock:
                if step_id in self._registered_steps:
                    del self._registered_steps[step_id]
                    self._step_type_mapping.pop(step_id, None)
                    
                    cache_keys_to_remove = [
                        key for key in self._step_cache.keys() 
                        if step_id in key
                    ]
                    for cache_key in cache_keys_to_remove:
                        del self._step_cache[cache_key]
                    
                    self.logger.info(f"âœ… {step_id} GitHub Step ë“±ë¡ í•´ì œ ì™„ë£Œ")
                    self._stats['registered_steps'] = len(self._registered_steps)
                    return True
                else:
                    self.logger.warning(f"âš ï¸ {step_id} GitHub Stepì´ ë“±ë¡ë˜ì–´ ìˆì§€ ì•ŠìŒ")
                    return False
                    
        except Exception as e:
            self.logger.error(f"âŒ {step_id} GitHub Step ë“±ë¡ í•´ì œ ì‹¤íŒ¨: {e}")
            return False
    
    def is_step_registered(self, step_id: str) -> bool:
        """GitHub Step ë“±ë¡ ì—¬ë¶€ í™•ì¸"""
        with self._lock:
            return step_id in self._registered_steps
    
    def get_registered_steps(self) -> Dict[str, str]:
        """GitHub ë“±ë¡ëœ Step ëª©ë¡ ë°˜í™˜ (step_id -> class_name)"""
        with self._lock:
            return {
                step_id: step_class.__name__ 
                for step_id, step_class in self._registered_steps.items()
            }
    
    def get_registered_step_class(self, step_id: str) -> Optional[Type['BaseStepMixin']]:
        """GitHub ë“±ë¡ëœ Step í´ë˜ìŠ¤ ë°˜í™˜"""
        with self._lock:
            return self._registered_steps.get(step_id)

    # ==============================================
    # ğŸ”¥ GitHub Step ìƒì„± ë©”ì„œë“œë“¤ (ë“±ë¡ëœ Step ìš°ì„  ì‚¬ìš©)
    # ==============================================

    def create_step(
        self,
        step_type: Union[StepType, str],
        use_cache: bool = True,
        **kwargs
    ) -> GitHubStepCreationResult:
        """GitHub Step ìƒì„± ë©”ì¸ ë©”ì„œë“œ (ë“±ë¡ëœ Step ìš°ì„  ì‚¬ìš©)"""
        start_time = time.time()
        
        try:
            # Step íƒ€ì… ì •ê·œí™”
            if isinstance(step_type, str):
                try:
                    step_type = StepType(step_type.lower())
                except ValueError:
                    if self.is_step_registered(step_type):
                        return self._create_step_from_registered(step_type, use_cache, **kwargs)
                    
                    return GitHubStepCreationResult(
                        success=False,
                        error_message=f"ì§€ì›í•˜ì§€ ì•ŠëŠ” GitHub Step íƒ€ì…: {step_type}",
                        creation_time=time.time() - start_time
                    )
            
            step_id = self._get_step_id_from_type(step_type)
            
            # GitHub ë“±ë¡ëœ Stepì´ ìˆìœ¼ë©´ ìš°ì„  ì‚¬ìš©
            if step_id and self.is_step_registered(step_id):
                self.logger.info(f"ğŸ¯ {step_type.value} GitHub ë“±ë¡ëœ Step í´ë˜ìŠ¤ ì‚¬ìš©")
                return self._create_step_from_registered(step_id, use_cache, **kwargs)
            
            # ë“±ë¡ëœ Stepì´ ì—†ìœ¼ë©´ ê¸°ì¡´ ë°©ì‹ ì‚¬ìš©
            self.logger.info(f"ğŸ¯ {step_type.value} GitHub ë™ì  ë¡œë”© ë°©ì‹ ì‚¬ìš©")
            return self._create_step_legacy_way(step_type, use_cache, **kwargs)
            
        except Exception as e:
            with self._lock:
                self._stats['failed_creations'] += 1
            
            self.logger.error(f"âŒ GitHub Step ìƒì„± ì‹¤íŒ¨: {e}")
            return GitHubStepCreationResult(
                success=False,
                error_message=f"GitHub Step ìƒì„± ì˜ˆì™¸: {str(e)}",
                creation_time=time.time() - start_time
            )
    
    def _get_step_id_from_type(self, step_type: StepType) -> Optional[str]:
        """StepTypeì—ì„œ step_id ì°¾ê¸°"""
        type_to_id_mapping = {
            StepType.HUMAN_PARSING: 'step_01',
            StepType.POSE_ESTIMATION: 'step_02',
            StepType.CLOTH_SEGMENTATION: 'step_03',
            StepType.GEOMETRIC_MATCHING: 'step_04',
            StepType.CLOTH_WARPING: 'step_05',
            StepType.VIRTUAL_FITTING: 'step_06',
            StepType.POST_PROCESSING: 'step_07',
            StepType.QUALITY_ASSESSMENT: 'step_08'
        }
        return type_to_id_mapping.get(step_type)
    
    def _create_step_from_registered(
        self, 
        step_id: str, 
        use_cache: bool = True, 
        **kwargs
    ) -> GitHubStepCreationResult:
        """GitHub ë“±ë¡ëœ Step í´ë˜ìŠ¤ë¡œë¶€í„° ì¸ìŠ¤í„´ìŠ¤ ìƒì„±"""
        start_time = time.time()
        
        try:
            step_class = self.get_registered_step_class(step_id)
            if not step_class:
                return GitHubStepCreationResult(
                    success=False,
                    error_message=f"GitHub ë“±ë¡ëœ {step_id} Step í´ë˜ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ",
                    creation_time=time.time() - start_time
                )
            
            self.logger.info(f"ğŸ”„ {step_id} GitHub ë“±ë¡ëœ í´ë˜ìŠ¤ë¡œ ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ì¤‘...")
            
            # ìºì‹œ í™•ì¸
            if use_cache:
                cached_step = self._get_cached_step(step_id)
                if cached_step:
                    with self._lock:
                        self._stats['cache_hits'] += 1
                    self.logger.info(f"â™»ï¸ {step_id} GitHub ìºì‹œì—ì„œ ë°˜í™˜")
                    return GitHubStepCreationResult(
                        success=True,
                        step_instance=cached_step,
                        step_name=step_class.__name__,
                        class_name=step_class.__name__,
                        module_path=step_class.__module__,
                        creation_time=time.time() - start_time,
                        github_compatible=True,
                        basestepmixin_v19_compatible=True
                    )
            
            # StepType ì¶”ì¶œ
            step_type = self._step_type_mapping.get(step_id)
            if not step_type:
                step_type = self._extract_step_type_from_id(step_id)
            
            # GitHub BaseStepMixin v19.0 í˜¸í™˜ ì„¤ì • ìƒì„±
            if step_type:
                config = GitHubStepMapping.get_github_config(step_type, **kwargs)
            else:
                # ê¸°ë³¸ ì„¤ì • ìƒì„±
                config = self._create_default_github_config(step_id, step_class, **kwargs)
            
            # GitHub ì˜ì¡´ì„± í•´ê²° ë° ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
            constructor_dependencies = self.dependency_resolver.resolve_github_dependencies_for_constructor(config)
            
            # GitHub Step ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
            self.logger.info(f"ğŸ”„ {step_id} GitHub ë“±ë¡ëœ í´ë˜ìŠ¤ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±...")
            step_instance = step_class(**constructor_dependencies)
            self.logger.info(f"âœ… {step_id} GitHub ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ì™„ë£Œ (ë“±ë¡ëœ í´ë˜ìŠ¤)")
            
            # GitHub ì´ˆê¸°í™” ì‹¤í–‰
            initialization_success = self._initialize_github_step(step_instance, config)
            
            # ìºì‹œì— ì €ì¥
            if use_cache:
                self._cache_step(step_id, step_instance)
            
            # í†µê³„ ì—…ë°ì´íŠ¸
            with self._lock:
                self._stats['total_created'] += 1
                self._stats['successful_creations'] += 1
                self._stats['github_compatible_creations'] += 1
                self._stats['dependency_injection_successes'] += 1
            
            return GitHubStepCreationResult(
                success=True,
                step_instance=step_instance,
                step_name=config.step_name,
                step_type=step_type,
                class_name=config.class_name,
                module_path=config.module_path,
                creation_time=time.time() - start_time,
                dependencies_injected={'constructor_injection': True},
                initialization_success=initialization_success,
                github_compatible=True,
                basestepmixin_v19_compatible=True,
                dependency_injection_success=True
            )
            
        except Exception as e:
            with self._lock:
                self._stats['failed_creations'] += 1
            
            self.logger.error(f"âŒ {step_id} GitHub ë“±ë¡ëœ í´ë˜ìŠ¤ ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ì‹¤íŒ¨: {e}")
            return GitHubStepCreationResult(
                success=False,
                error_message=f"GitHub ë“±ë¡ëœ {step_id} ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ì‹¤íŒ¨: {str(e)}",
                creation_time=time.time() - start_time
            )
    
    def _create_default_github_config(self, step_id: str, step_class: Type, **kwargs) -> GitHubStepConfig:
        """GitHub ê¸°ë³¸ ì„¤ì • ìƒì„± (StepTypeì´ ì—†ì„ ë•Œ)"""
        return GitHubStepConfig(
            step_name=step_class.__name__,
            step_id=int(step_id.split('_')[1]) if '_' in step_id else 0,
            step_type=StepType.HUMAN_PARSING,  # ê¸°ë³¸ê°’
            class_name=step_class.__name__,
            module_path=step_class.__module__,
            conda_env=CONDA_INFO['conda_env'],
            memory_gb=MEMORY_GB,
            **kwargs
        )
    
    def _create_step_legacy_way(
        self, 
        step_type: StepType, 
        use_cache: bool = True, 
        **kwargs
    ) -> GitHubStepCreationResult:
        """GitHub ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ Step ìƒì„± (ë™ì  ë¡œë”©)"""
        config = GitHubStepMapping.get_github_config(step_type, **kwargs)
        
        self.logger.info(f"ğŸ¯ {config.step_name} GitHub ìƒì„± ì‹œì‘ (ë™ì  ë¡œë”©)...")
        
        # í†µê³„ ì—…ë°ì´íŠ¸
        with self._lock:
            self._stats['total_created'] += 1
        
        # ìºì‹œ í™•ì¸
        if use_cache:
            cached_step = self._get_cached_step(config.step_name)
            if cached_step:
                with self._lock:
                    self._stats['cache_hits'] += 1
                self.logger.info(f"â™»ï¸ {config.step_name} GitHub ìºì‹œì—ì„œ ë°˜í™˜")
                return GitHubStepCreationResult(
                    success=True,
                    step_instance=cached_step,
                    step_name=config.step_name,
                    step_type=step_type,
                    class_name=config.class_name,
                    module_path=config.module_path,
                    creation_time=0.0,
                    github_compatible=True,
                    basestepmixin_v19_compatible=True
                )
        
        # ì‹¤ì œ GitHub Step ìƒì„± (ê¸°ì¡´ ë¡œì§)
        result = self._create_github_step_instance(config)
        
        # ì„±ê³µ ì‹œ ìºì‹œì— ì €ì¥
        if result.success and result.step_instance and use_cache:
            self._cache_step(config.step_name, result.step_instance)
        
        # í†µê³„ ì—…ë°ì´íŠ¸
        with self._lock:
            if result.success:
                self._stats['successful_creations'] += 1
                if result.github_compatible:
                    self._stats['github_compatible_creations'] += 1
                if result.dependency_injection_success:
                    self._stats['dependency_injection_successes'] += 1
            else:
                self._stats['failed_creations'] += 1
        
        return result

    def _create_github_step_instance(self, config: GitHubStepConfig) -> GitHubStepCreationResult:
        """GitHub BaseStepMixin v19.0 í˜¸í™˜ Step ì¸ìŠ¤í„´ìŠ¤ ìƒì„± (í•µì‹¬ ë©”ì„œë“œ)"""
        try:
            self.logger.info(f"ğŸ”„ {config.step_name} GitHub BaseStepMixin v19.0 í˜¸í™˜ ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ì¤‘...")
            
            # 1. GitHub Step í´ë˜ìŠ¤ ë¡œë”©
            StepClass = self.class_loader.load_github_step_class(config)
            if not StepClass:
                return GitHubStepCreationResult(
                    success=False,
                    step_name=config.step_name,
                    step_type=config.step_type,
                    class_name=config.class_name,
                    module_path=config.module_path,
                    error_message=f"{config.class_name} GitHub í´ë˜ìŠ¤ ë¡œë”© ì‹¤íŒ¨"
                )
            
            self.logger.info(f"âœ… {config.class_name} GitHub í´ë˜ìŠ¤ ë¡œë”© ì™„ë£Œ")
            
            # 2. GitHub ìƒì„±ììš© ì˜ì¡´ì„± í•´ê²° (í•µì‹¬: ìƒì„±ì ì‹œì  ì£¼ì…)
            constructor_dependencies = self.dependency_resolver.resolve_github_dependencies_for_constructor(config)
            
            # 3. GitHub BaseStepMixin v19.0 í‘œì¤€ ìƒì„±ì í˜¸ì¶œ (**kwargs íŒ¨í„´)
            self.logger.info(f"ğŸ”„ {config.class_name} GitHub BaseStepMixin v19.0 ìƒì„±ì í˜¸ì¶œ ì¤‘...")
            step_instance = StepClass(**constructor_dependencies)
            self.logger.info(f"âœ… {config.class_name} GitHub ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ì™„ë£Œ (ìƒì„±ì ì˜ì¡´ì„± ì£¼ì…)")
            
            # 4. GitHub ì´ˆê¸°í™” ì‹¤í–‰ (ë™ê¸°/ë¹„ë™ê¸° ìë™ ê°ì§€)
            initialization_success = self._initialize_github_step(step_instance, config)
            
            # 5. GitHub BaseStepMixin v19.0 í˜¸í™˜ì„± ìµœì¢… ê²€ì¦
            compatibility_result = self._verify_github_compatibility(step_instance, config)
            
            # 6. GitHub AI ëª¨ë¸ ë¡œë”© í™•ì¸
            ai_models_loaded = self._check_github_ai_models(step_instance, config)
            
            self.logger.info(f"âœ… {config.step_name} GitHub BaseStepMixin v19.0 í˜¸í™˜ ìƒì„± ì™„ë£Œ")
            
            return GitHubStepCreationResult(
                success=True,
                step_instance=step_instance,
                step_name=config.step_name,
                step_type=config.step_type,
                class_name=config.class_name,
                module_path=config.module_path,
                dependencies_injected={'constructor_injection': True},
                initialization_success=initialization_success,
                ai_models_loaded=ai_models_loaded,
                github_compatible=compatibility_result['compatible'],
                basestepmixin_v19_compatible=compatibility_result['basestepmixin_v19_compatible'],
                process_method_validated=compatibility_result['process_method_valid'],
                dependency_injection_success=True
            )
            
        except Exception as e:
            self.logger.error(f"âŒ {config.step_name} GitHub BaseStepMixin v19.0 ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ì‹¤íŒ¨: {e}")
            self.logger.error(f"âŒ ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
            
            return GitHubStepCreationResult(
                success=False,
                step_name=config.step_name,
                step_type=config.step_type,
                class_name=config.class_name,
                module_path=config.module_path,
                error_message=f"GitHub BaseStepMixin v19.0 ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ì‹¤íŒ¨: {str(e)}",
                github_compatible=False,
                basestepmixin_v19_compatible=False
            )
    
    def _initialize_github_step(self, step_instance: 'BaseStepMixin', config: GitHubStepConfig) -> bool:
        """GitHub BaseStepMixin v19.0 Step ì´ˆê¸°í™” (ë™ê¸°/ë¹„ë™ê¸° ìë™ ê°ì§€)"""
        try:
            # GitHub BaseStepMixin v19.0 initialize ë©”ì„œë“œ í˜¸ì¶œ
            if hasattr(step_instance, 'initialize'):
                initialize_method = step_instance.initialize
                
                # ë™ê¸°/ë¹„ë™ê¸° ìë™ ê°ì§€ ë° ì²˜ë¦¬
                if asyncio.iscoroutinefunction(initialize_method):
                    # ë¹„ë™ê¸° í•¨ìˆ˜ì¸ ê²½ìš°
                    try:
                        # í˜„ì¬ ì‹¤í–‰ ì¤‘ì¸ ì´ë²¤íŠ¸ ë£¨í”„ê°€ ìˆëŠ”ì§€ í™•ì¸
                        loop = asyncio.get_running_loop()
                        
                        # ì´ë¯¸ ì‹¤í–‰ ì¤‘ì¸ ë£¨í”„ì—ì„œëŠ” íƒœìŠ¤í¬ ìƒì„± í›„ ë¸”ë¡œí‚¹ ëŒ€ê¸°
                        if loop.is_running():
                            # ìƒˆë¡œìš´ ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰í•˜ê±°ë‚˜ ë™ê¸°ì ìœ¼ë¡œ ì²˜ë¦¬
                            import concurrent.futures
                            with concurrent.futures.ThreadPoolExecutor() as executor:
                                future = executor.submit(asyncio.run, initialize_method())
                                success = future.result(timeout=30)  # 30ì´ˆ íƒ€ì„ì•„ì›ƒ
                        else:
                            # ë£¨í”„ê°€ ì‹¤í–‰ ì¤‘ì´ ì•„ë‹ˆë©´ ì§ì ‘ ì‹¤í–‰
                            success = asyncio.run(initialize_method())
                    except RuntimeError:
                        # ì‹¤í–‰ ì¤‘ì¸ ë£¨í”„ê°€ ì—†ìœ¼ë©´ ìƒˆ ë£¨í”„ì—ì„œ ì‹¤í–‰
                        success = asyncio.run(initialize_method())
                    except Exception as e:
                        self.logger.warning(f"âš ï¸ {config.step_name} GitHub ë¹„ë™ê¸° ì´ˆê¸°í™” ì‹¤íŒ¨, ë™ê¸° ë°©ì‹ ì‹œë„: {e}")
                        # ë¹„ë™ê¸° ì´ˆê¸°í™” ì‹¤íŒ¨ ì‹œ í´ë°± (ë™ê¸° ë°©ì‹ìœ¼ë¡œ ì¬ì‹œë„)
                        success = self._fallback_github_sync_initialize(step_instance, config)
                else:
                    # ë™ê¸° í•¨ìˆ˜ì¸ ê²½ìš°
                    success = initialize_method()
                
                if success:
                    self.logger.info(f"âœ… {config.step_name} GitHub BaseStepMixin v19.0 ì´ˆê¸°í™” ì™„ë£Œ")
                    return True
                else:
                    self.logger.warning(f"âš ï¸ {config.step_name} GitHub BaseStepMixin v19.0 ì´ˆê¸°í™” ì‹¤íŒ¨")
                    return False
            else:
                self.logger.debug(f"â„¹ï¸ {config.step_name} GitHub initialize ë©”ì„œë“œ ì—†ìŒ")
                return True
                
        except Exception as e:
            self.logger.warning(f"âš ï¸ {config.step_name} GitHub ì´ˆê¸°í™” ì˜ˆì™¸: {e}")
            # ì˜ˆì™¸ ë°œìƒ ì‹œ í´ë°± ì´ˆê¸°í™” ì‹œë„
            return self._fallback_github_sync_initialize(step_instance, config)
    
    def _fallback_github_sync_initialize(self, step_instance: 'BaseStepMixin', config: GitHubStepConfig) -> bool:
        """GitHub í´ë°± ë™ê¸° ì´ˆê¸°í™” (ë¹„ë™ê¸° ì´ˆê¸°í™” ì‹¤íŒ¨ ì‹œ)"""
        try:
            self.logger.info(f"ğŸ”„ {config.step_name} GitHub í´ë°± ë™ê¸° ì´ˆê¸°í™” ì‹œë„...")
            
            # GitHub ê¸°ë³¸ ì†ì„±ë“¤ ìˆ˜ë™ ì„¤ì •
            if hasattr(step_instance, 'is_initialized'):
                step_instance.is_initialized = True
            
            if hasattr(step_instance, 'is_ready'):
                step_instance.is_ready = True
            
            if hasattr(step_instance, 'github_compatible'):
                step_instance.github_compatible = True
                
            # GitHub ì˜ì¡´ì„±ì´ ì œëŒ€ë¡œ ì£¼ì…ë˜ì—ˆëŠ”ì§€ í™•ì¸
            dependencies_ok = True
            if config.require_model_loader and not hasattr(step_instance, 'model_loader'):
                dependencies_ok = False
                
            if dependencies_ok:
                self.logger.info(f"âœ… {config.step_name} GitHub í´ë°± ë™ê¸° ì´ˆê¸°í™” ì„±ê³µ")
                return True
            else:
                self.logger.warning(f"âš ï¸ {config.step_name} GitHub í´ë°± ì´ˆê¸°í™”: ì˜ì¡´ì„± ë¬¸ì œ ìˆìŒ")
                return not config.strict_mode  # strict_modeê°€ ì•„ë‹ˆë©´ ê³„ì† ì§„í–‰
                
        except Exception as e:
            self.logger.error(f"âŒ {config.step_name} GitHub í´ë°± ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return False
    
    def _verify_github_compatibility(self, step_instance: 'BaseStepMixin', config: GitHubStepConfig) -> Dict[str, Any]:
        """GitHub BaseStepMixin v19.0 í˜¸í™˜ì„± ìµœì¢… ê²€ì¦"""
        try:
            result = {
                'compatible': True,
                'basestepmixin_v19_compatible': True,
                'process_method_valid': False,
                'issues': []
            }
            
            # GitHub process ë©”ì„œë“œ ì¡´ì¬ í™•ì¸
            if not hasattr(step_instance, 'process'):
                result['compatible'] = False
                result['basestepmixin_v19_compatible'] = False
                result['issues'].append('GitHub process ë©”ì„œë“œ ì—†ìŒ')
            else:
                result['process_method_valid'] = True
            
            # GitHub BaseStepMixin v19.0 ì†ì„± í™•ì¸
            expected_attrs = ['step_name', 'step_id', 'device', 'is_initialized', 'github_compatible']
            for attr in expected_attrs:
                if not hasattr(step_instance, attr):
                    result['issues'].append(f'GitHub {attr} ì†ì„± ì—†ìŒ')
            
            # GitHub ì˜ì¡´ì„± ì£¼ì… ìƒíƒœ í™•ì¸
            if hasattr(step_instance, 'model_loader') and step_instance.model_loader:
                self.logger.debug(f"âœ… {config.step_name} GitHub ModelLoader ì£¼ì… í™•ì¸ë¨")
            
            if hasattr(step_instance, 'dependency_manager') and step_instance.dependency_manager:
                self.logger.debug(f"âœ… {config.step_name} GitHub DependencyManager ì£¼ì… í™•ì¸ë¨")
            
            if result['issues']:
                self.logger.warning(f"âš ï¸ {config.step_name} GitHub BaseStepMixin v19.0 í˜¸í™˜ì„± ì´ìŠˆ: {result['issues']}")
            else:
                self.logger.info(f"âœ… {config.step_name} GitHub BaseStepMixin v19.0 í˜¸í™˜ì„± ê²€ì¦ ì™„ë£Œ")
            
            return result
            
        except Exception as e:
            self.logger.error(f"âŒ {config.step_name} GitHub BaseStepMixin v19.0 í˜¸í™˜ì„± ê²€ì¦ ì‹¤íŒ¨: {e}")
            return {'compatible': False, 'basestepmixin_v19_compatible': False, 'process_method_valid': False, 'issues': [str(e)]}
    
    def _check_github_ai_models(self, step_instance: 'BaseStepMixin', config: GitHubStepConfig) -> List[str]:
        """GitHub AI ëª¨ë¸ ë¡œë”© í™•ì¸ (BaseStepMixin v19.0 í˜¸í™˜)"""
        loaded_models = []
        
        try:
            # GitHub ModelLoader ë¥¼ í†µí•œ ëª¨ë¸ í™•ì¸
            if hasattr(step_instance, 'model_loader') and step_instance.model_loader:
                for model_name in config.ai_models:
                    try:
                        if hasattr(step_instance.model_loader, 'is_model_loaded'):
                            if step_instance.model_loader.is_model_loaded(model_name):
                                loaded_models.append(model_name)
                    except Exception:
                        pass
            
            # GitHub model_interface ë¥¼ í†µí•œ ëª¨ë¸ í™•ì¸
            if hasattr(step_instance, 'model_interface') and step_instance.model_interface:
                for model_name in config.ai_models:
                    try:
                        if hasattr(step_instance.model_interface, 'is_model_available'):
                            if step_instance.model_interface.is_model_available(model_name):
                                loaded_models.append(model_name)
                    except Exception:
                        pass
            
            if loaded_models:
                self.logger.info(f"ğŸ¤– {config.step_name} GitHub AI ëª¨ë¸ ë¡œë”© í™•ì¸: {loaded_models}")
            
            return loaded_models
            
        except Exception as e:
            self.logger.debug(f"GitHub AI ëª¨ë¸ í™•ì¸ ì‹¤íŒ¨: {e}")
            return []
    
    def _get_cached_step(self, step_name: str) -> Optional['BaseStepMixin']:
        """ìºì‹œëœ GitHub Step ë°˜í™˜"""
        try:
            with self._lock:
                if step_name in self._step_cache:
                    weak_ref = self._step_cache[step_name]
                    step_instance = weak_ref()
                    if step_instance is not None:
                        return step_instance
                    else:
                        del self._step_cache[step_name]
                return None
        except Exception:
            return None
    
    def _cache_step(self, step_name: str, step_instance: 'BaseStepMixin'):
        """GitHub Step ìºì‹œì— ì €ì¥"""
        try:
            with self._lock:
                self._step_cache[step_name] = weakref.ref(step_instance)
        except Exception:
            pass
    
    # ==============================================
    # ğŸ”¥ GitHub í¸ì˜ ë©”ì„œë“œë“¤ (BaseStepMixin v19.0 í˜¸í™˜)
    # ==============================================
    
    def create_human_parsing_step(self, **kwargs) -> GitHubStepCreationResult:
        """GitHub Human Parsing Step ìƒì„± (BaseStepMixin v19.0 í˜¸í™˜)"""
        return self.create_step(StepType.HUMAN_PARSING, **kwargs)
    
    def create_pose_estimation_step(self, **kwargs) -> GitHubStepCreationResult:
        """GitHub Pose Estimation Step ìƒì„± (BaseStepMixin v19.0 í˜¸í™˜)"""
        return self.create_step(StepType.POSE_ESTIMATION, **kwargs)
    
    def create_cloth_segmentation_step(self, **kwargs) -> GitHubStepCreationResult:
        """GitHub Cloth Segmentation Step ìƒì„± (BaseStepMixin v19.0 í˜¸í™˜)"""
        return self.create_step(StepType.CLOTH_SEGMENTATION, **kwargs)
    
    def create_geometric_matching_step(self, **kwargs) -> GitHubStepCreationResult:
        """GitHub Geometric Matching Step ìƒì„± (BaseStepMixin v19.0 í˜¸í™˜)"""
        return self.create_step(StepType.GEOMETRIC_MATCHING, **kwargs)
    
    def create_cloth_warping_step(self, **kwargs) -> GitHubStepCreationResult:
        """GitHub Cloth Warping Step ìƒì„± (BaseStepMixin v19.0 í˜¸í™˜)"""
        return self.create_step(StepType.CLOTH_WARPING, **kwargs)
    
    def create_virtual_fitting_step(self, **kwargs) -> GitHubStepCreationResult:
        """GitHub Virtual Fitting Step ìƒì„± (BaseStepMixin v19.0 í˜¸í™˜)"""
        return self.create_step(StepType.VIRTUAL_FITTING, **kwargs)
    
    def create_post_processing_step(self, **kwargs) -> GitHubStepCreationResult:
        """GitHub Post Processing Step ìƒì„± (BaseStepMixin v19.0 í˜¸í™˜)"""
        return self.create_step(StepType.POST_PROCESSING, **kwargs)
    
    def create_quality_assessment_step(self, **kwargs) -> GitHubStepCreationResult:
        """GitHub Quality Assessment Step ìƒì„± (BaseStepMixin v19.0 í˜¸í™˜)"""
        return self.create_step(StepType.QUALITY_ASSESSMENT, **kwargs)
    
    def create_full_pipeline(self, device: str = "auto", **kwargs) -> Dict[str, GitHubStepCreationResult]:
        """GitHub ì „ì²´ íŒŒì´í”„ë¼ì¸ ìƒì„± (BaseStepMixin v19.0 í˜¸í™˜) - ë™ê¸° ë©”ì„œë“œ"""
        try:
            self.logger.info("ğŸš€ GitHub ì „ì²´ AI íŒŒì´í”„ë¼ì¸ ìƒì„± ì‹œì‘ (BaseStepMixin v19.0 í˜¸í™˜)...")
            
            pipeline_results = {}
            total_model_size = 0.0
            
            # ìš°ì„ ìˆœìœ„ë³„ë¡œ GitHub Step ìƒì„±
            sorted_steps = sorted(
                StepType,
                key=lambda x: GitHubStepMapping.GITHUB_STEP_CONFIGS[x].priority.value
            )
            
            for step_type in sorted_steps:
                try:
                    result = self.create_step(step_type, device=device, **kwargs)
                    pipeline_results[step_type.value] = result
                    
                    if result.success:
                        config = GitHubStepMapping.get_github_config(step_type)
                        total_model_size += config.model_size_gb
                        self.logger.info(f"âœ… {result.step_name} GitHub íŒŒì´í”„ë¼ì¸ ìƒì„± ì„±ê³µ (BaseStepMixin v19.0 í˜¸í™˜)")
                    else:
                        self.logger.warning(f"âš ï¸ {step_type.value} GitHub íŒŒì´í”„ë¼ì¸ ìƒì„± ì‹¤íŒ¨")
                        
                except Exception as e:
                    self.logger.error(f"âŒ {step_type.value} GitHub Step ìƒì„± ì˜ˆì™¸: {e}")
                    pipeline_results[step_type.value] = GitHubStepCreationResult(
                        success=False,
                        step_name=f"{step_type.value}Step",
                        step_type=step_type,
                        error_message=str(e)
                    )
            
            success_count = sum(1 for result in pipeline_results.values() if result.success)
            total_count = len(pipeline_results)
            
            self.logger.info(f"ğŸ GitHub BaseStepMixin v19.0 í˜¸í™˜ íŒŒì´í”„ë¼ì¸ ìƒì„± ì™„ë£Œ: {success_count}/{total_count} ì„±ê³µ")
            self.logger.info(f"ğŸ¤– ì´ AI ëª¨ë¸ í¬ê¸°: {total_model_size:.1f}GB")
            
            return pipeline_results
            
        except Exception as e:
            self.logger.error(f"âŒ GitHub ì „ì²´ íŒŒì´í”„ë¼ì¸ ìƒì„± ì‹¤íŒ¨: {e}")
            return {}
    
    def get_statistics(self) -> Dict[str, Any]:
        """GitHub í†µê³„ ì •ë³´ ë°˜í™˜ (ë“±ë¡ ì •ë³´ í¬í•¨)"""
        with self._lock:
            total = self._stats['total_created']
            success_rate = (self._stats['successful_creations'] / max(1, total)) * 100
            github_compatibility_rate = (self._stats['github_compatible_creations'] / max(1, self._stats['successful_creations'])) * 100
            
            base_stats = {
                'version': 'StepFactory v10.0 (GitHub Project + BaseStepMixin v19.0 Complete Compatibility)',
                'total_created': total,
                'successful_creations': self._stats['successful_creations'],
                'failed_creations': self._stats['failed_creations'],
                'success_rate': round(success_rate, 2),
                'cache_hits': self._stats['cache_hits'],
                'cached_steps': len(self._step_cache),
                'active_cache_entries': len([
                    ref for ref in self._step_cache.values() if ref() is not None
                ]),
                'github_compatibility': {
                    'github_compatible_creations': self._stats['github_compatible_creations'],
                    'github_compatibility_rate': round(github_compatibility_rate, 2),
                    'dependency_injection_successes': self._stats['dependency_injection_successes']
                },
                'environment': {
                    'conda_env': CONDA_INFO['conda_env'],
                    'conda_optimized': self._stats['conda_optimized'],
                    'is_m3_max_detected': IS_M3_MAX_DETECTED,
                    'm3_max_optimized': self._stats['m3_max_optimized'],
                    'memory_gb': MEMORY_GB
                },
                'loaded_classes': list(self.class_loader._loaded_classes.keys()),
                
                # GitHub ë“±ë¡ ì •ë³´
                'registration': {
                    'registered_steps_count': len(self._registered_steps),
                    'registered_steps': self.get_registered_steps(),
                    'step_type_mappings': {
                        step_id: step_type.value 
                        for step_id, step_type in self._step_type_mapping.items()
                    }
                }
            }
            
            return base_stats
    
    def clear_cache(self):
        """GitHub ìºì‹œ ì •ë¦¬"""
        try:
            with self._lock:
                self._step_cache.clear()
                self.dependency_resolver.clear_cache()
                
                # GitHub M3 Max ë©”ëª¨ë¦¬ ì •ë¦¬
                if IS_M3_MAX_DETECTED:
                    try:
                        import torch
                        if hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
                            if hasattr(torch.backends.mps, 'empty_cache'):
                                torch.backends.mps.empty_cache()
                    except:
                        pass
                
                gc.collect()
                self.logger.info("ğŸ§¹ StepFactory v10.0 GitHub ìºì‹œ ì •ë¦¬ ì™„ë£Œ")
        except Exception as e:
            self.logger.error(f"âŒ GitHub ìºì‹œ ì •ë¦¬ ì‹¤íŒ¨: {e}")

# ==============================================
# ğŸ”¥ ì „ì—­ StepFactory ê´€ë¦¬ (GitHub í˜¸í™˜)
# ==============================================

_global_step_factory: Optional[StepFactory] = None
_factory_lock = threading.Lock()

def get_global_step_factory() -> StepFactory:
    """ì „ì—­ StepFactory v10.0 ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜ (GitHub í”„ë¡œì íŠ¸ í‘œì¤€)"""
    global _global_step_factory
    
    with _factory_lock:
        if _global_step_factory is None:
            _global_step_factory = StepFactory()
            logger.info("âœ… ì „ì—­ StepFactory v10.0 (GitHub í”„ë¡œì íŠ¸ í‘œì¤€ + BaseStepMixin v19.0 í˜¸í™˜) ìƒì„± ì™„ë£Œ")
        
        return _global_step_factory

def reset_global_step_factory():
    """ì „ì—­ GitHub StepFactory ë¦¬ì…‹"""
    global _global_step_factory
    
    with _factory_lock:
        if _global_step_factory:
            _global_step_factory.clear_cache()
        _global_step_factory = None
        logger.info("ğŸ”„ ì „ì—­ StepFactory v10.0 GitHub ë¦¬ì…‹ ì™„ë£Œ")

# ==============================================
# ğŸ”¥ í¸ì˜ í•¨ìˆ˜ë“¤ (GitHub í˜¸í™˜)
# ==============================================

def create_step(step_type: Union[StepType, str], **kwargs) -> GitHubStepCreationResult:
    """ì „ì—­ GitHub Step ìƒì„± í•¨ìˆ˜ (BaseStepMixin v19.0 í˜¸í™˜)"""
    factory = get_global_step_factory()
    return factory.create_step(step_type, **kwargs)

def create_human_parsing_step(**kwargs) -> GitHubStepCreationResult:
    """GitHub Human Parsing Step ìƒì„± (BaseStepMixin v19.0 í˜¸í™˜)"""
    return create_step(StepType.HUMAN_PARSING, **kwargs)

def create_pose_estimation_step(**kwargs) -> GitHubStepCreationResult:
    """GitHub Pose Estimation Step ìƒì„± (BaseStepMixin v19.0 í˜¸í™˜)"""
    return create_step(StepType.POSE_ESTIMATION, **kwargs)

def create_cloth_segmentation_step(**kwargs) -> GitHubStepCreationResult:
    """GitHub Cloth Segmentation Step ìƒì„± (BaseStepMixin v19.0 í˜¸í™˜)"""
    return create_step(StepType.CLOTH_SEGMENTATION, **kwargs)

def create_geometric_matching_step(**kwargs) -> GitHubStepCreationResult:
    """GitHub Geometric Matching Step ìƒì„± (BaseStepMixin v19.0 í˜¸í™˜)"""
    return create_step(StepType.GEOMETRIC_MATCHING, **kwargs)

def create_cloth_warping_step(**kwargs) -> GitHubStepCreationResult:
    """GitHub Cloth Warping Step ìƒì„± (BaseStepMixin v19.0 í˜¸í™˜)"""
    return create_step(StepType.CLOTH_WARPING, **kwargs)

def create_virtual_fitting_step(**kwargs) -> GitHubStepCreationResult:
    """GitHub Virtual Fitting Step ìƒì„± (BaseStepMixin v19.0 í˜¸í™˜)"""
    return create_step(StepType.VIRTUAL_FITTING, **kwargs)

def create_post_processing_step(**kwargs) -> GitHubStepCreationResult:
    """GitHub Post Processing Step ìƒì„± (BaseStepMixin v19.0 í˜¸í™˜)"""
    return create_step(StepType.POST_PROCESSING, **kwargs)

def create_quality_assessment_step(**kwargs) -> GitHubStepCreationResult:
    """GitHub Quality Assessment Step ìƒì„± (BaseStepMixin v19.0 í˜¸í™˜)"""
    return create_step(StepType.QUALITY_ASSESSMENT, **kwargs)

def create_full_pipeline(device: str = "auto", **kwargs) -> Dict[str, GitHubStepCreationResult]:
    """GitHub ì „ì²´ íŒŒì´í”„ë¼ì¸ ìƒì„± (BaseStepMixin v19.0 í˜¸í™˜) - ë™ê¸° í•¨ìˆ˜"""
    factory = get_global_step_factory()
    return factory.create_full_pipeline(device, **kwargs)

def get_step_factory_statistics() -> Dict[str, Any]:
    """GitHub StepFactory í†µê³„ ì¡°íšŒ (BaseStepMixin v19.0 í˜¸í™˜ì„± í¬í•¨)"""
    factory = get_global_step_factory()
    return factory.get_statistics()

def clear_step_factory_cache():
    """GitHub StepFactory ìºì‹œ ì •ë¦¬"""
    factory = get_global_step_factory()
    factory.clear_cache()

# ==============================================
# ğŸ”¥ í¸ì˜ í•¨ìˆ˜ë“¤ ê°œì„  (GitHub ë“±ë¡ ê¸°ëŠ¥ í¬í•¨)
# ==============================================

def register_step_globally(step_id: str, step_class: Type['BaseStepMixin']) -> bool:
    """ì „ì—­ GitHub StepFactoryì— Step ë“±ë¡"""
    factory = get_global_step_factory()
    return factory.register_step(step_id, step_class)

def unregister_step_globally(step_id: str) -> bool:
    """ì „ì—­ GitHub StepFactoryì—ì„œ Step ë“±ë¡ í•´ì œ"""
    factory = get_global_step_factory()
    return factory.unregister_step(step_id)

def get_registered_steps_globally() -> Dict[str, str]:
    """ì „ì—­ GitHub StepFactory ë“±ë¡ëœ Step ëª©ë¡ ì¡°íšŒ"""
    factory = get_global_step_factory()
    return factory.get_registered_steps()

def is_step_registered_globally(step_id: str) -> bool:
    """ì „ì—­ GitHub StepFactory Step ë“±ë¡ ì—¬ë¶€ í™•ì¸"""
    factory = get_global_step_factory()
    return factory.is_step_registered(step_id)

# ==============================================
# ğŸ”¥ GitHub conda í™˜ê²½ ìµœì í™” (BaseStepMixin v19.0 í˜¸í™˜)
# ==============================================

def optimize_conda_environment_for_github():
    """GitHub conda í™˜ê²½ ìµœì í™” (BaseStepMixin v19.0 í˜¸í™˜)"""
    try:
        if not CONDA_INFO['is_target_env']:
            logger.warning(f"âš ï¸ GitHub ê¶Œì¥ conda í™˜ê²½ì´ ì•„ë‹˜: {CONDA_INFO['conda_env']} (ê¶Œì¥: mycloset-ai-clean)")
            return False
        
        # GitHub PyTorch conda ìµœì í™”
        try:
            import torch
            if IS_M3_MAX_DETECTED and hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
                # GitHub MPS ìºì‹œ ì •ë¦¬
                if hasattr(torch.backends.mps, 'empty_cache'):
                    torch.backends.mps.empty_cache()
                logger.info("ğŸ GitHub M3 Max MPS ìµœì í™” í™œì„±í™” (BaseStepMixin v19.0 í˜¸í™˜)")
            
            # GitHub CPU ìŠ¤ë ˆë“œ ìµœì í™”
            cpu_count = os.cpu_count()
            torch.set_num_threads(max(1, cpu_count // 2))
            logger.info(f"ğŸ§µ GitHub PyTorch ìŠ¤ë ˆë“œ ìµœì í™”: {torch.get_num_threads()}/{cpu_count}")
            
        except ImportError:
            pass
        
        # GitHub í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
        os.environ['OMP_NUM_THREADS'] = str(max(1, os.cpu_count() // 2))
        os.environ['MKL_NUM_THREADS'] = str(max(1, os.cpu_count() // 2))
        
        logger.info("ğŸ GitHub conda í™˜ê²½ ìµœì í™” ì™„ë£Œ (BaseStepMixin v19.0 í˜¸í™˜)")
        return True
        
    except Exception as e:
        logger.warning(f"âš ï¸ GitHub conda í™˜ê²½ ìµœì í™” ì‹¤íŒ¨: {e}")
        return False

# ==============================================
# ğŸ”¥ GitHub BaseStepMixin v19.0 í˜¸í™˜ì„± ê²€ì¦ ë„êµ¬
# ==============================================

def validate_github_step_compatibility(step_instance: 'BaseStepMixin') -> Dict[str, Any]:
    """GitHub BaseStepMixin v19.0 Step í˜¸í™˜ì„± ê²€ì¦"""
    try:
        result = {
            'compatible': True,
            'version': 'StepFactory v10.0 GitHub',
            'basestepmixin_v19_compatible': True,
            'issues': [],
            'recommendations': []
        }
        
        # GitHub í•„ìˆ˜ ì†ì„± í™•ì¸
        required_attrs = ['step_name', 'step_id', 'device', 'is_initialized', 'github_compatible']
        for attr in required_attrs:
            if not hasattr(step_instance, attr):
                result['compatible'] = False
                result['basestepmixin_v19_compatible'] = False
                result['issues'].append(f'GitHub í•„ìˆ˜ ì†ì„± {attr} ì—†ìŒ')
        
        # GitHub í•„ìˆ˜ ë©”ì„œë“œ í™•ì¸
        required_methods = ['process', 'initialize']
        for method in required_methods:
            if not hasattr(step_instance, method):
                result['compatible'] = False
                result['basestepmixin_v19_compatible'] = False
                result['issues'].append(f'GitHub í•„ìˆ˜ ë©”ì„œë“œ {method} ì—†ìŒ')
        
        # GitHub BaseStepMixin v19.0 ìƒì† í™•ì¸
        mro_names = [cls.__name__ for cls in step_instance.__class__.__mro__]
        if 'BaseStepMixin' not in mro_names:
            result['recommendations'].append('GitHub BaseStepMixin v19.0 ìƒì† ê¶Œì¥')
        
        # GitHub ì˜ì¡´ì„± ì£¼ì… ìƒíƒœ í™•ì¸
        dependency_attrs = ['model_loader', 'memory_manager', 'data_converter', 'dependency_manager']
        injected_deps = []
        for attr in dependency_attrs:
            if hasattr(step_instance, attr) and getattr(step_instance, attr) is not None:
                injected_deps.append(attr)
        
        result['injected_dependencies'] = injected_deps
        result['dependency_injection_score'] = len(injected_deps) / len(dependency_attrs)
        
        # GitHub íŠ¹ë³„ ì†ì„± í™•ì¸
        if hasattr(step_instance, 'github_compatible') and getattr(step_instance, 'github_compatible'):
            result['github_mode'] = True
        else:
            result['recommendations'].append('github_compatible=True ì„¤ì • ê¶Œì¥')
        
        return result
        
    except Exception as e:
        return {
            'compatible': False,
            'basestepmixin_v19_compatible': False,
            'error': str(e),
            'version': 'StepFactory v10.0 GitHub'
        }

def get_github_step_info(step_instance: 'BaseStepMixin') -> Dict[str, Any]:
    """GitHub BaseStepMixin v19.0 Step ì •ë³´ ì¡°íšŒ"""
    try:
        info = {
            'step_name': getattr(step_instance, 'step_name', 'Unknown'),
            'step_id': getattr(step_instance, 'step_id', 0),
            'class_name': step_instance.__class__.__name__,
            'module': step_instance.__class__.__module__,
            'device': getattr(step_instance, 'device', 'Unknown'),
            'is_initialized': getattr(step_instance, 'is_initialized', False),
            'github_compatible': getattr(step_instance, 'github_compatible', False),
            'has_model': getattr(step_instance, 'has_model', False),
            'model_loaded': getattr(step_instance, 'model_loaded', False)
        }
        
        # GitHub ì˜ì¡´ì„± ìƒíƒœ
        dependencies = {}
        for dep_name in ['model_loader', 'memory_manager', 'data_converter', 'di_container', 'dependency_manager']:
            dependencies[dep_name] = hasattr(step_instance, dep_name) and getattr(step_instance, dep_name) is not None
        
        info['dependencies'] = dependencies
        
        # GitHub BaseStepMixin v19.0 íŠ¹ì • ì†ì„±ë“¤
        if hasattr(step_instance, 'dependency_manager'):
            dep_manager = step_instance.dependency_manager
            if hasattr(dep_manager, 'get_github_status'):
                try:
                    info['github_dependency_manager_status'] = dep_manager.get_github_status()
                except:
                    info['github_dependency_manager_status'] = 'error'
        
        return info
        
    except Exception as e:
        return {'error': str(e)}

# ==============================================
# ğŸ”¥ GitHub ë””ë²„ê¹… ë° í…ŒìŠ¤íŠ¸ ë„êµ¬
# ==============================================

async def test_github_step_creation_flow(step_type: StepType, **kwargs) -> Dict[str, Any]:
    """GitHub Step ìƒì„± í”Œë¡œìš° í…ŒìŠ¤íŠ¸ (ë™ê¸°/ë¹„ë™ê¸° í˜¸í™˜)"""
    try:
        test_result = {
            'step_type': step_type.value,
            'test_start_time': time.time(),
            'phases': {},
            'github_mode': True
        }
        
        factory = get_global_step_factory()
        
        # Phase 1: GitHub ì„¤ì • ìƒì„± í…ŒìŠ¤íŠ¸
        phase1_start = time.time()
        try:
            config = GitHubStepMapping.get_github_config(step_type, **kwargs)
            test_result['phases']['github_config_creation'] = {
                'success': True,
                'time': time.time() - phase1_start,
                'config_class': config.class_name,
                'github_compatible': config.github_compatible
            }
        except Exception as e:
            test_result['phases']['github_config_creation'] = {
                'success': False,
                'time': time.time() - phase1_start,
                'error': str(e)
            }
            return test_result
        
        # Phase 2: GitHub í´ë˜ìŠ¤ ë¡œë”© í…ŒìŠ¤íŠ¸
        phase2_start = time.time()
        try:
            step_class = factory.class_loader.load_github_step_class(config)
            test_result['phases']['github_class_loading'] = {
                'success': step_class is not None,
                'time': time.time() - phase2_start,
                'class_found': step_class.__name__ if step_class else None
            }
        except Exception as e:
            test_result['phases']['github_class_loading'] = {
                'success': False,
                'time': time.time() - phase2_start,
                'error': str(e)
            }
            if not step_class:
                return test_result
        
        # Phase 3: GitHub ì˜ì¡´ì„± í•´ê²° í…ŒìŠ¤íŠ¸
        phase3_start = time.time()
        try:
            dependencies = factory.dependency_resolver.resolve_github_dependencies_for_constructor(config)
            test_result['phases']['github_dependency_resolution'] = {
                'success': len(dependencies) > 0,
                'time': time.time() - phase3_start,
                'resolved_count': len(dependencies),
                'resolved_dependencies': list(dependencies.keys()),
                'github_optimized': dependencies.get('github_compatibility_mode', False)
            }
        except Exception as e:
            test_result['phases']['github_dependency_resolution'] = {
                'success': False,
                'time': time.time() - phase3_start,
                'error': str(e)
            }
        
        # Phase 4: GitHub ì¸ìŠ¤í„´ìŠ¤ ìƒì„± í…ŒìŠ¤íŠ¸ (ë™ê¸°)
        phase4_start = time.time()
        try:
            result = factory.create_step(step_type, **kwargs)
            test_result['phases']['github_instance_creation'] = {
                'success': result.success,
                'time': time.time() - phase4_start,
                'step_name': result.step_name,
                'github_compatible': result.github_compatible,
                'basestepmixin_v19_compatible': result.basestepmixin_v19_compatible,
                'error': result.error_message if not result.success else None
            }
        except Exception as e:
            test_result['phases']['github_instance_creation'] = {
                'success': False,
                'time': time.time() - phase4_start,
                'error': str(e)
            }
        
        test_result['total_time'] = time.time() - test_result['test_start_time']
        test_result['overall_success'] = all(
            phase.get('success', False) for phase in test_result['phases'].values()
        )
        
        return test_result
        
    except Exception as e:
        return {
            'step_type': step_type.value if step_type else 'unknown',
            'overall_success': False,
            'error': str(e),
            'github_mode': True
        }

def diagnose_github_step_factory_health() -> Dict[str, Any]:
    """GitHub StepFactory ìƒíƒœ ì§„ë‹¨"""
    try:
        factory = get_global_step_factory()
        health_report = {
            'factory_version': 'v10.0 (GitHub Project + BaseStepMixin v19.0 Complete Compatibility)',
            'timestamp': time.time(),
            'github_environment': {
                'conda_env': CONDA_INFO['conda_env'],
                'is_target_env': CONDA_INFO['is_target_env'],
                'is_m3_max_detected': IS_M3_MAX_DETECTED,
                'memory_gb': MEMORY_GB
            },
            'github_statistics': factory.get_statistics(),
            'github_cache_status': {
                'cached_steps': len(factory._step_cache),
                'active_references': len([
                    ref for ref in factory._step_cache.values() if ref() is not None
                ])
            },
            'github_component_status': {
                'class_loader': 'operational',
                'dependency_resolver': 'operational'
            },
            'github_recommendations': []
        }
        
        # GitHub í™˜ê²½ ì²´í¬
        if not CONDA_INFO['is_target_env']:
            health_report['github_recommendations'].append(
                f"GitHub conda í™˜ê²½ì„ mycloset-ai-cleanìœ¼ë¡œ ë³€ê²½ ê¶Œì¥ (í˜„ì¬: {CONDA_INFO['conda_env']})"
            )
        
        # GitHub ë©”ëª¨ë¦¬ ì²´í¬
        if MEMORY_GB < 16:
            health_report['github_recommendations'].append(
                f"GitHub ë©”ëª¨ë¦¬ ë¶€ì¡± ì£¼ì˜: {MEMORY_GB:.1f}GB (ê¶Œì¥: 16GB+)"
            )
        
        # GitHub ìºì‹œ ì²´í¬
        if len(factory._step_cache) > 10:
            health_report['github_recommendations'].append(
                "GitHub ìºì‹œëœ Stepì´ ë§ìŠµë‹ˆë‹¤. clear_cache() í˜¸ì¶œ ê³ ë ¤"
            )
        
        health_report['github_overall_health'] = 'good' if len(health_report['github_recommendations']) == 0 else 'warning'
        
        return health_report
        
    except Exception as e:
        return {
            'github_overall_health': 'error',
            'error': str(e)
        }

# ==============================================
# ğŸ”¥ Export
# ==============================================

__all__ = [
    # ë©”ì¸ í´ë˜ìŠ¤ë“¤
    'StepFactory',
    'GitHubStepClassLoader', 
    'GitHubDependencyResolver',
    'GitHubStepMapping',
    
    # ë°ì´í„° êµ¬ì¡°ë“¤
    'StepType',
    'StepPriority', 
    'GitHubStepConfig',
    'GitHubStepCreationResult',
    
    # ì „ì—­ í•¨ìˆ˜ë“¤
    'get_global_step_factory',
    'reset_global_step_factory',
    
    # Step ìƒì„± í•¨ìˆ˜ë“¤ (GitHub í˜¸í™˜)
    'create_step',
    'create_human_parsing_step',
    'create_pose_estimation_step', 
    'create_cloth_segmentation_step',
    'create_geometric_matching_step',
    'create_cloth_warping_step',
    'create_virtual_fitting_step',
    'create_post_processing_step',
    'create_quality_assessment_step',
    'create_full_pipeline',
    
    # ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
    'get_step_factory_statistics',
    'clear_step_factory_cache',
    'optimize_conda_environment_for_github',
    
    # GitHub BaseStepMixin v19.0 í˜¸í™˜ì„± ë„êµ¬ë“¤
    'validate_github_step_compatibility',
    'get_github_step_info',
    'test_github_step_creation_flow',
    'diagnose_github_step_factory_health',

    # Step ë“±ë¡ ê´€ë¦¬ í•¨ìˆ˜ë“¤
    'register_step_globally',
    'unregister_step_globally', 
    'get_registered_steps_globally',
    'is_step_registered_globally',
    
    # ìƒìˆ˜ë“¤
    'CONDA_INFO',
    'IS_M3_MAX_DETECTED', 
    'MEMORY_GB'
]

# ==============================================
# ğŸ”¥ ëª¨ë“ˆ ì´ˆê¸°í™” (GitHub í”„ë¡œì íŠ¸ í‘œì¤€ + BaseStepMixin v19.0 í˜¸í™˜)
# ==============================================

logger.info("ğŸ”¥ StepFactory v10.0 - GitHub í”„ë¡œì íŠ¸ í‘œì¤€ + BaseStepMixin v19.0 ì™„ì „ í˜¸í™˜ ë¡œë“œ ì™„ë£Œ!")
logger.info("âœ… ì£¼ìš” ìˆ˜ì •ì‚¬í•­:")
logger.info("   - keyword argument repeated: is_m3_max ì˜¤ë¥˜ ì™„ì „ í•´ê²°")
logger.info("   - is_m3_max â†’ is_m3_max_detected ë³€ê²½í•˜ì—¬ ì¶©ëŒ ë°©ì§€")
logger.info("   - GitHub í”„ë¡œì íŠ¸ í‘œì¤€ ì™„ì „ í˜¸í™˜")
logger.info("   - BaseStepMixin v19.0 í‘œì¤€ ì™„ì „ í˜¸í™˜")
logger.info("   - ìƒì„±ì ì‹œì  ì˜ì¡´ì„± ì£¼ì…")
logger.info("   - process() ë©”ì„œë“œ ì‹œê·¸ë‹ˆì²˜ í‘œì¤€í™”")
logger.info("   - GitHubDependencyManager ì™„ì „ í™œìš©")
logger.info("   - register_step ë“± ëª¨ë“  í•„ìˆ˜ ë©”ì„œë“œ ì™„ì „ êµ¬í˜„")

logger.info(f"ğŸ”§ í˜„ì¬ í™˜ê²½:")
logger.info(f"   - conda í™˜ê²½: {CONDA_INFO['conda_env']} ({'âœ… ìµœì í™”ë¨' if CONDA_INFO['is_target_env'] else 'âš ï¸ ê¶Œì¥: mycloset-ai-clean'})")
logger.info(f"   - M3 Max: {'âœ…' if IS_M3_MAX_DETECTED else 'âŒ'}")
logger.info(f"   - ë©”ëª¨ë¦¬: {MEMORY_GB:.1f}GB")

logger.info("ğŸ¯ ì§€ì› Step í´ë˜ìŠ¤ (GitHub í”„ë¡œì íŠ¸ í‘œì¤€):")
for step_type in StepType:
    config = GitHubStepMapping.GITHUB_STEP_CONFIGS[step_type]
    logger.info(f"   - {config.class_name} (Step {config.step_id:02d}) - {config.model_size_gb}GB")

# conda í™˜ê²½ ìë™ ìµœì í™” (GitHub í˜¸í™˜)
if CONDA_INFO['is_target_env']:
    optimize_conda_environment_for_github()
    logger.info("ğŸ GitHub conda í™˜ê²½ ìë™ ìµœì í™” ì™„ë£Œ! (BaseStepMixin v19.0 í˜¸í™˜)")
else:
    logger.warning(f"âš ï¸ conda í™˜ê²½ì„ í™•ì¸í•˜ì„¸ìš”: conda activate mycloset-ai-clean")

# ì´ˆê¸° ë©”ëª¨ë¦¬ ìµœì í™”
if IS_M3_MAX_DETECTED:
    try:
        import torch
        if hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
            if hasattr(torch.backends.mps, 'empty_cache'):
                torch.backends.mps.empty_cache()
        gc.collect()
        logger.info("ğŸ M3 Max ì´ˆê¸° ë©”ëª¨ë¦¬ ìµœì í™” ì™„ë£Œ! (GitHub í˜¸í™˜)")
    except:
        pass

logger.info("ğŸš€ StepFactory v10.0 ì™„ì „ ì¤€ë¹„ ì™„ë£Œ! (GitHub í”„ë¡œì íŠ¸ í‘œì¤€ + BaseStepMixin v19.0) ğŸš€")
logger.info("ğŸ’¡ ì´ì œ ì‹¤ì œ GitHub Step í´ë˜ìŠ¤ë“¤ê³¼ 100% í˜¸í™˜ë©ë‹ˆë‹¤!")
logger.info("ğŸ’¡ ìƒì„±ì ì‹œì  ì˜ì¡´ì„± ì£¼ì…ìœ¼ë¡œ ì•ˆì •ì„± ë³´ì¥!")
logger.info("ğŸ’¡ process() ë©”ì„œë“œ ì‹œê·¸ë‹ˆì²˜ í‘œì¤€í™” ì™„ë£Œ!")
logger.info("ğŸ’¡ ğŸ”¥ ëª¨ë“  í‚¤ì›Œë“œ ì¤‘ë³µ ì˜¤ë¥˜ í•´ê²° ë° ì™„ì „í•œ ê¸°ëŠ¥ ë³´ì¥!")
logger.info("ğŸ’¡ ğŸ¯ GitHub í”„ë¡œì íŠ¸ì™€ BaseStepMixin v19.0 ì™„ì „ í˜¸í™˜!")