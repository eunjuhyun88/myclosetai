"""
MyCloset AI ì™„ì „ í†µí•©ëœ 8ë‹¨ê³„ AI íŒŒì´í”„ë¼ì¸ ë§¤ë‹ˆì € - ëª¨ë“  ê¸°ëŠ¥ í¬í•¨ (ìƒì„±ì ì˜¤ë¥˜ ì™„ì „ ìˆ˜ì •)
- 1ë²ˆ íŒŒì¼ì˜ pipeline_routes.py ì™„ì „ í˜¸í™˜ì„±
- 2ë²ˆ íŒŒì¼ì˜ ê³ ê¸‰ ë¶„ì„ ë° ì²˜ë¦¬ ê¸°ëŠ¥  
- ì‹¤ì œ í”„ë¡œì íŠ¸ì˜ ëª¨ë“  í—¬í¼ ë©”ì„œë“œë“¤ í¬í•¨
- M3 Max ìµœì í™”
- í”„ë¡œë•ì…˜ ë ˆë²¨ ì•ˆì •ì„±
- ëª¨ë“  Step í´ë˜ìŠ¤ ìƒì„±ì ì˜¤ë¥˜ ì™„ì „ ìˆ˜ì •

íŒŒì¼ ê²½ë¡œ: backend/app/ai_pipeline/pipeline_manager.py
"""
import os
import sys
import logging
import asyncio
import time
import traceback
from pathlib import Path
from typing import Dict, Any, Optional, Callable, Union, List, Tuple
from enum import Enum
import numpy as np
import torch
import torch.nn.functional as F
from PIL import Image, ImageEnhance, ImageFilter
import json
import gc
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('mycloset_ai_pipeline.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# ==========================================
# PipelineMode Enum (ì‹¤ì œ í”„ë¡œì íŠ¸ì—ì„œ ìš”êµ¬)
# ==========================================

class PipelineMode(Enum):
    """MyCloset AI íŒŒì´í”„ë¼ì¸ ëª¨ë“œ enum"""
    SIMULATION = "simulation"
    PRODUCTION = "production"
    HYBRID = "hybrid"
    DEVELOPMENT = "development"
    
    @classmethod
    def get_default(cls):
        return cls.PRODUCTION

# ==========================================
# ì‹¤ì œ MyCloset AI êµ¬ì¡°ì—ì„œ Step í´ë˜ìŠ¤ë“¤ import
# ==========================================

# ì‹¤ì œ í”„ë¡œì íŠ¸ êµ¬ì¡°: backend/app/ai_pipeline/steps/
try:
    from app.ai_pipeline.steps.step_01_human_parsing import HumanParsingStep
    from app.ai_pipeline.steps.step_02_pose_estimation import PoseEstimationStep
    from app.ai_pipeline.steps.step_03_cloth_segmentation import ClothSegmentationStep
    from app.ai_pipeline.steps.step_04_geometric_matching import GeometricMatchingStep
    from app.ai_pipeline.steps.step_05_cloth_warping import ClothWarpingStep
    from app.ai_pipeline.steps.step_06_virtual_fitting import VirtualFittingStep
    from app.ai_pipeline.steps.step_07_post_processing import PostProcessingStep
    from app.ai_pipeline.steps.step_08_quality_assessment import QualityAssessmentStep
    STEPS_IMPORT_SUCCESS = True
    logger.info("âœ… MyCloset AI Step í´ë˜ìŠ¤ë“¤ ì„±ê³µì ìœ¼ë¡œ importë¨")
except ImportError as e:
    logger.warning(f"âš ï¸ Step í´ë˜ìŠ¤ë“¤ import ì‹¤íŒ¨: {e}")
    STEPS_IMPORT_SUCCESS = False

# ìœ í‹¸ë¦¬í‹°ë“¤ import (ì‹¤ì œ í”„ë¡œì íŠ¸ êµ¬ì¡°)
try:
    from app.ai_pipeline.utils.model_loader import ModelLoader
    from app.ai_pipeline.utils.memory_manager import MemoryManager
    from app.ai_pipeline.utils.data_converter import DataConverter
    UTILS_IMPORT_SUCCESS = True
    logger.info("âœ… MyCloset AI ìœ í‹¸ë¦¬í‹°ë“¤ ì„±ê³µì ìœ¼ë¡œ importë¨")
except ImportError as e:
    logger.warning(f"âš ï¸ ìœ í‹¸ë¦¬í‹°ë“¤ import ì‹¤íŒ¨: {e}")
    ModelLoader = None
    MemoryManager = None
    DataConverter = None
    UTILS_IMPORT_SUCCESS = False

# Core ì„¤ì •ë“¤ import (ì‹¤ì œ í”„ë¡œì íŠ¸ êµ¬ì¡°)
try:
    from app.core.gpu_config import GPUConfig
    from app.core.m3_optimizer import M3Optimizer
    from app.core.config import Config
    CORE_IMPORT_SUCCESS = True
    logger.info("âœ… MyCloset AI Core ëª¨ë“ˆë“¤ ì„±ê³µì ìœ¼ë¡œ importë¨")
except ImportError as e:
    logger.warning(f"âš ï¸ Core ëª¨ë“ˆë“¤ import ì‹¤íŒ¨: {e}")
    GPUConfig = None
    M3Optimizer = None
    Config = None
    CORE_IMPORT_SUCCESS = False

class PipelineManager:
    """
    MyCloset AI ì™„ì „ í†µí•©ëœ 8ë‹¨ê³„ ê°€ìƒ í”¼íŒ… íŒŒì´í”„ë¼ì¸ ë§¤ë‹ˆì €
    - ì‹¤ì œ í”„ë¡œì íŠ¸ êµ¬ì¡° ì™„ì „ ë°˜ì˜ (backend/app/ai_pipeline/)
    - ìµœì  ìƒì„±ì íŒ¨í„´: ëª¨ë“  Stepì´ ë™ì¼í•œ ì¸í„°í˜ì´ìŠ¤
    - ê¸°ì¡´ í´ë˜ìŠ¤ëª…/í•¨ìˆ˜ëª… ì ˆëŒ€ ë³€ê²½ ì•ˆí•¨
    - ëª¨ë“  ê¸°ëŠ¥ ì™„ì „ í†µí•© (1ë²ˆ+2ë²ˆ íŒŒì¼)
    - M3 Max ìµœì í™”
    - í”„ë¡œë•ì…˜ ë ˆë²¨ ì•ˆì •ì„±
    """
    
    def __init__(
        self, 
        device: str = "mps",
        device_type: str = "apple_silicon", 
        memory_gb: float = 128.0,
        is_m3_max: bool = True,
        optimization_enabled: bool = True,
        config_path: Optional[str] = None,
        mode: Union[str, PipelineMode] = PipelineMode.PRODUCTION
    ):
        """
        íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” - ì™„ì „ í˜¸í™˜ (2ë²ˆ íŒŒì¼ê³¼ ë™ì¼í•œ ìƒì„±ì)
        
        Args:
            device: ì‚¬ìš©í•  ë””ë°”ì´ìŠ¤ ('auto', 'cpu', 'cuda', 'mps')
            device_type: ë””ë°”ì´ìŠ¤ íƒ€ì… ('apple_silicon', 'nvidia', 'intel')
            memory_gb: ì‚¬ìš© ê°€ëŠ¥í•œ ë©”ëª¨ë¦¬ (GB)
            is_m3_max: M3 Max ì¹© ì—¬ë¶€
            optimization_enabled: ìµœì í™” í™œì„±í™” ì—¬ë¶€
            config_path: ì„¤ì • íŒŒì¼ ê²½ë¡œ (ì„ íƒì )
            mode: íŒŒì´í”„ë¼ì¸ ëª¨ë“œ
        """
        # pipeline_routes.pyì—ì„œ ìš”êµ¬í•˜ëŠ” ì†ì„±ë“¤ ì„¤ì •
        self.device = device if device != "auto" else self._get_optimal_device()
        self.device_type = device_type
        self.memory_gb = memory_gb
        self.is_m3_max = is_m3_max
        self.optimization_enabled = optimization_enabled
        
        # === 5. ğŸ¯ ëª¨ë“œ ì„¤ì • ===
        if isinstance(mode, str):
            try:
                self.mode = PipelineMode(mode)
            except ValueError:
                self.mode = PipelineMode.PRODUCTION
        else:
            self.mode = mode
        
        # === 6. ğŸ–¥ï¸ ë””ë°”ì´ìŠ¤ ìµœì í™” ì„¤ì • ===
        self._configure_device_optimizations()
        
        # === 7. ğŸ› ï¸ ê¸°ì¡´ ìœ í‹¸ë¦¬í‹°ë“¤ ì´ˆê¸°í™” (ì•ˆì „í•˜ê²Œ) ===
        try:
            self.model_loader = ModelLoader(device=self.device) if ModelLoader else None
            self.memory_manager = MemoryManager(device=self.device, memory_limit_gb=memory_gb) if MemoryManager else None
            self.data_converter = DataConverter(device=self.device) if DataConverter else None
        except Exception as e:
            logger.warning(f"ìœ í‹¸ë¦¬í‹° ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.model_loader = None
            self.memory_manager = None
            self.data_converter = None
        
        # === 8. ğŸ“ ì„¤ì • ë¡œë“œ ===
        self.config = self._load_config(config_path)
        
        # === 9. íŒŒì´í”„ë¼ì¸ ì„¤ì • ===
        self.pipeline_config = self.config.get('pipeline', {
            'quality_level': 'high',
            'processing_mode': 'complete',
            'enable_optimization': optimization_enabled,
            'enable_caching': True,
            'parallel_processing': True,
            'memory_optimization': True,
            'enable_intermediate_saving': False,
            'max_retries': 3,
            'timeout_seconds': 300
        })
        
        # === 10. ğŸ¯ 8ë‹¨ê³„ ì»´í¬ë„ŒíŠ¸ ===
        self.steps = {}
        self.step_order = [
            'human_parsing',           # 1ë‹¨ê³„: ì¸ì²´ íŒŒì‹±
            'pose_estimation',         # 2ë‹¨ê³„: í¬ì¦ˆ ì¶”ì •
            'cloth_segmentation',      # 3ë‹¨ê³„: ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜
            'geometric_matching',      # 4ë‹¨ê³„: ê¸°í•˜í•™ì  ë§¤ì¹­
            'cloth_warping',          # 5ë‹¨ê³„: ì˜· ì›Œí•‘
            'virtual_fitting',        # 6ë‹¨ê³„: ê°€ìƒ í”¼íŒ… ìƒì„±
            'post_processing',        # 7ë‹¨ê³„: í›„ì²˜ë¦¬
            'quality_assessment'      # 8ë‹¨ê³„: í’ˆì§ˆ í‰ê°€
        ]
        
        # === 11. ğŸ“Š ìƒíƒœ ê´€ë¦¬ ===
        self.is_initialized = False
        self.processing_stats = {}
        self.session_data = {}  # 2ë²ˆ íŒŒì¼ì˜ ì„¸ì…˜ ê´€ë¦¬ ê¸°ëŠ¥
        self.error_history = []
        
        # === 12. ğŸ“ˆ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ===
        self.performance_metrics = {
            'total_sessions': 0,
            'successful_sessions': 0,
            'average_processing_time': 0.0,
            'average_quality_score': 0.0
        }
        
        # === 13. ğŸ§µ ìŠ¤ë ˆë“œ í’€ (ë³‘ë ¬ ì²˜ë¦¬ìš©) ===
        self.thread_pool = ThreadPoolExecutor(max_workers=4)
        
        logger.info(f"ğŸš€ ì™„ì „ í†µí•©ëœ ê°€ìƒ í”¼íŒ… íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” - ë””ë°”ì´ìŠ¤: {self.device}")
        logger.info(f"ğŸ’» ë””ë°”ì´ìŠ¤ íƒ€ì…: {self.device_type}, ë©”ëª¨ë¦¬: {self.memory_gb}GB")
        logger.info(f"ğŸ M3 Max: {'âœ…' if self.is_m3_max else 'âŒ'}, ìµœì í™”: {'âœ…' if self.optimization_enabled else 'âŒ'}")
        logger.info(f"ğŸ“Š íŒŒì´í”„ë¼ì¸ ëª¨ë“œ: {self.mode.value}")
        logger.info(f"ğŸ¯ í’ˆì§ˆ ë ˆë²¨: {self.pipeline_config['quality_level']}")
    
    def _get_optimal_device(self) -> str:
        """ìµœì  ë””ë°”ì´ìŠ¤ ìë™ ì„ íƒ"""
        if torch.backends.mps.is_available():
            return 'mps'
        elif torch.cuda.is_available():
            return 'cuda'
        else:
            return 'cpu'
    
    
    def _configure_device_optimizations(self):
        """ë””ë°”ì´ìŠ¤ë³„ ìµœì í™” ì„¤ì • (MPS empty_cache ì˜¤ë¥˜ ìˆ˜ì •)"""
        try:
            import gc
            import torch
            
            if self.device == 'mps':
                logger.info("ğŸ M3 Max MPS ë””ë°”ì´ìŠ¤ ìµœì í™” ì‹œì‘...")
                
                # í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
                os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '1'
                
                # ë©”ëª¨ë¦¬ ì •ë¦¬
                gc.collect()
                
                # PyTorch ë²„ì „ë³„ MPS ìµœì í™” ì²˜ë¦¬
                try:
                    pytorch_version = torch.__version__
                    
                    # MPS ë°±ì—”ë“œ ì´ˆê¸°í™” í…ŒìŠ¤íŠ¸
                    if torch.backends.mps.is_available():
                        # ê°„ë‹¨í•œ í…ì„œ ì—°ì‚°ìœ¼ë¡œ MPS ì´ˆê¸°í™”
                        test_tensor = torch.randn(1, 1).to(self.device)
                        _ = test_tensor + 1
                        del test_tensor
                        logger.info("ğŸ M3 Max MPS ë°±ì—”ë“œ ì´ˆê¸°í™” ì™„ë£Œ")
                        
                        # MPS empty_cache ì§€ì› ì—¬ë¶€ í™•ì¸
                        if hasattr(torch.backends.mps, 'empty_cache'):
                            torch.backends.mps.empty_cache()
                            logger.info("âœ… MPS empty_cache ì‚¬ìš©")
                        else:
                            logger.info(f"â„¹ï¸ PyTorch {pytorch_version}: MPS empty_cache ë¯¸ì§€ì› - ëŒ€ì²´ ë©”ëª¨ë¦¬ ê´€ë¦¬ ì‚¬ìš©")
                            
                            # ëŒ€ì²´ ë©”ëª¨ë¦¬ ê´€ë¦¬
                            if hasattr(torch.mps, 'synchronize'):
                                torch.mps.synchronize()
                                logger.info("âœ… MPS synchronize ëŒ€ì²´ ì‚¬ìš©")
                            
                            # ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ìœ¼ë¡œ ëŒ€ì²´
                            gc.collect()
                            logger.info("âœ… ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ìœ¼ë¡œ ë©”ëª¨ë¦¬ ì •ë¦¬")
                    else:
                        logger.warning("âš ï¸ MPS ì‚¬ìš© ë¶ˆê°€ - CPUë¡œ í´ë°±")
                        self.device = "cpu"
                        
                except Exception as mps_error:
                    logger.warning(f"MPS ì´ˆê¸°í™” ì‹¤íŒ¨: {mps_error}")
                    # ì™„ì „ ì•ˆì „ ëª¨ë“œë¡œ í´ë°±
                    gc.collect()
                    logger.info("ğŸš¨ ì•ˆì „ ëª¨ë“œë¡œ ë©”ëª¨ë¦¬ ê´€ë¦¬")
                
                logger.info("ğŸ M3 Max ë©”ëª¨ë¦¬ ìµœì í™” ì™„ë£Œ")
                
            elif self.device == 'cuda':
                logger.info("ğŸ® CUDA ë””ë°”ì´ìŠ¤ ìµœì í™” ì‹œì‘...")
                torch.backends.cudnn.benchmark = True
                torch.backends.cudnn.enabled = True
                torch.backends.cudnn.deterministic = False
                
                if torch.cuda.is_available():
                    torch.cuda.empty_cache()
                    logger.info("âœ… CUDA ë©”ëª¨ë¦¬ ìºì‹œ ì •ë¦¬ ì™„ë£Œ")
                    
                logger.info("ğŸ® CUDA ìµœì í™” ì™„ë£Œ")
                
            else:
                logger.info("âš¡ CPU ë””ë°”ì´ìŠ¤ ìµœì í™” ì‹œì‘...")
                
                if hasattr(torch, 'set_num_threads'):
                    # M3 Maxì˜ íš¨ìœ¨ ì½”ì–´ í™œìš©
                    num_threads = min(4, os.cpu_count() or 4)
                    torch.set_num_threads(num_threads)
                    logger.info(f"âš¡ CPU ìŠ¤ë ˆë“œ ìˆ˜ ì„¤ì •: {num_threads}")
                    
                logger.info("âš¡ CPU ìµœì í™” ì™„ë£Œ")
            
            # í˜¼í•© ì •ë°€ë„ ì„¤ì •
            if self.device in ['cuda', 'mps'] and self.optimization_enabled:
                self.use_amp = True
                logger.info("âš¡ í˜¼í•© ì •ë°€ë„ ì—°ì‚° í™œì„±í™”")
            else:
                self.use_amp = False
                
            logger.info(f"âœ… {self.device.upper()} ë””ë°”ì´ìŠ¤ ìµœì í™” ì™„ë£Œ")
                
        except Exception as e:
            logger.error(f"âŒ ë””ë°”ì´ìŠ¤ ìµœì í™” ì‹¤íŒ¨: {e}")
            # ì˜¤ë¥˜ê°€ ë°œìƒí•´ë„ ì´ˆê¸°í™”ëŠ” ê³„ì† ì§„í–‰
            self.device = "cpu"  # ì•ˆì „í•œ í´ë°±
            self.use_amp = False
            logger.info("ğŸ”„ ì•ˆì „ ëª¨ë“œë¡œ í´ë°± - CPU ì‚¬ìš©")

    def _initialize_mycloset_utilities(self):
        """ğŸ› ï¸ MyCloset AI ìœ í‹¸ë¦¬í‹°ë“¤ ì´ˆê¸°í™”"""
        try:
            # ëª¨ë¸ ë¡œë” ì´ˆê¸°í™”
            if ModelLoader:
                self.model_loader = ModelLoader(device=self.device)
                self.logger.info("âœ… ModelLoader ì´ˆê¸°í™” ì™„ë£Œ")
            else:
                self.model_loader = None
                
            # ë©”ëª¨ë¦¬ ë§¤ë‹ˆì € ì´ˆê¸°í™”  
            if MemoryManager:
                self.memory_manager = MemoryManager(
                    device=self.device, 
                    memory_limit_gb=self.memory_gb
                )
                self.logger.info("âœ… MemoryManager ì´ˆê¸°í™” ì™„ë£Œ")
            else:
                self.memory_manager = None
                
            # ë°ì´í„° ë³€í™˜ê¸° ì´ˆê¸°í™”
            if DataConverter:
                self.data_converter = DataConverter(device=self.device)
                self.logger.info("âœ… DataConverter ì´ˆê¸°í™” ì™„ë£Œ")
            else:
                self.data_converter = None
                
            # GPU ì„¤ì • (M3 Max ì „ìš©)
            if GPUConfig and self.is_m3_max:
                self.gpu_config = GPUConfig()
                self.logger.info("âœ… M3 Max GPU ì„¤ì • ì ìš©")
            else:
                self.gpu_config = None
                
            # M3 ì˜µí‹°ë§ˆì´ì €
            if M3Optimizer and self.is_m3_max:
                self.m3_optimizer = M3Optimizer()
                self.logger.info("âœ… M3 Max ì˜µí‹°ë§ˆì´ì € ì ìš©")
            else:
                self.m3_optimizer = None
                
        except Exception as e:
            self.logger.warning(f"âš ï¸ ìœ í‹¸ë¦¬í‹° ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    
    def _load_config(self, config_path: Optional[str] = None) -> Dict[str, Any]:
        """ì„¤ì • íŒŒì¼ ë¡œë“œ"""
        default_config = {
            'input_size': (512, 512),
            'pipeline': {
                'quality_level': 'high',
                'processing_mode': 'complete',
                'enable_optimization': self.optimization_enabled,
                'enable_caching': True,
                'parallel_processing': True,
                'memory_optimization': True,
                'enable_intermediate_saving': False,
                'max_retries': 3,
                'timeout_seconds': 300
            },
            'quality_thresholds': {
                'excellent': 0.9,
                'good': 0.8,
                'acceptable': 0.7,
                'poor': 0.6
            },
            'device_optimization': {
                'enable_mps': self.is_m3_max,
                'enable_cuda': True,
                'mixed_precision': self.optimization_enabled,
                'memory_efficient': True
            }
        }
    
    # ===========================================
    # ì…ë ¥ ì²˜ë¦¬ ë° ë³€í™˜ ë©”ì„œë“œë“¤
    # ===========================================
    
    async def _preprocess_inputs(
        self, 
        person_image: Union[str, Image.Image, np.ndarray],
        clothing_image: Union[str, Image.Image, np.ndarray]
    ) -> Tuple[torch.Tensor, torch.Tensor]:
        """ì…ë ¥ ì´ë¯¸ì§€ ì „ì²˜ë¦¬"""
        try:
            # ë°ì´í„° ë³€í™˜ê¸° ì‚¬ìš©
            if self.data_converter and hasattr(self.data_converter, 'preprocess_image'):
                person_tensor = self.data_converter.preprocess_image(person_image)
                clothing_tensor = self.data_converter.preprocess_image(clothing_image)
            else:
                person_tensor = self._manual_preprocess_image(person_image)
                clothing_tensor = self._manual_preprocess_image(clothing_image)
            
            # ë””ë°”ì´ìŠ¤ë¡œ ì´ë™
            person_tensor = person_tensor.to(self.device)
            clothing_tensor = clothing_tensor.to(self.device)
            
            logger.info(f"âœ… ì…ë ¥ ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì™„ë£Œ - ì‚¬ëŒ: {person_tensor.shape}, ì˜ë¥˜: {clothing_tensor.shape}")
            
            return person_tensor, clothing_tensor
            
        except Exception as e:
            logger.error(f"âŒ ì…ë ¥ ì „ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            raise
    
    def _manual_preprocess_image(self, image_input: Union[str, Image.Image, np.ndarray]) -> torch.Tensor:
        """ìˆ˜ë™ ì´ë¯¸ì§€ ì „ì²˜ë¦¬"""
        if isinstance(image_input, str):
            if not os.path.exists(image_input):
                raise FileNotFoundError(f"ì´ë¯¸ì§€ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {image_input}")
            image = Image.open(image_input).convert('RGB')
        elif isinstance(image_input, Image.Image):
            image = image_input.convert('RGB')
        elif isinstance(image_input, np.ndarray):
            if image_input.dtype != np.uint8:
                image_input = (image_input * 255).astype(np.uint8)
            image = Image.fromarray(image_input).convert('RGB')
        else:
            raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì´ë¯¸ì§€ íƒ€ì…: {type(image_input)}")
        
        # í¬ê¸° ì¡°ì •
        target_size = self.config.get('input_size', (512, 512))
        if image.size != target_size:
            image = image.resize(target_size, Image.Resampling.LANCZOS)
        
        # í…ì„œ ë³€í™˜
        img_array = np.array(image)
        img_tensor = torch.from_numpy(img_array).permute(2, 0, 1).float() / 255.0
        img_tensor = img_tensor.unsqueeze(0)
        
        return img_tensor
    
    def _extract_final_image(
        self, 
        post_processing_result: Dict[str, Any],
        fitting_result: Dict[str, Any], 
        person_tensor: torch.Tensor
    ) -> torch.Tensor:
        """ìµœì¢… ê²°ê³¼ ì´ë¯¸ì§€ ì¶”ì¶œ"""
        if 'enhanced_image' in post_processing_result:
            return post_processing_result['enhanced_image']
        elif 'fitted_image' in fitting_result:
            return fitting_result['fitted_image']
        else:
            logger.warning("âš ï¸ ìµœì¢… ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ ì›ë³¸ì„ ë°˜í™˜í•©ë‹ˆë‹¤")
            return person_tensor
    
    def _tensor_to_pil(self, tensor: torch.Tensor) -> Image.Image:
        """í…ì„œë¥¼ PIL ì´ë¯¸ì§€ë¡œ ë³€í™˜"""
        try:
            if tensor.dim() == 4:
                tensor = tensor.squeeze(0)
            
            if tensor.shape[0] == 3:
                tensor = tensor.permute(1, 2, 0)
            
            tensor = torch.clamp(tensor, 0, 1)
            tensor = tensor.cpu()
            array = (tensor.numpy() * 255).astype(np.uint8)
            
            return Image.fromarray(array)
        except Exception as e:
            logger.error(f"âŒ í…ì„œ-PIL ë³€í™˜ ì‹¤íŒ¨: {e}")
            return Image.new('RGB', (512, 512), color='black')
    
    # ===========================================
    # ë©”ëª¨ë¦¬ ê´€ë¦¬ ë° ì‹œìŠ¤í…œ ì •ë³´
    # ===========================================
    
    def _optimize_memory_usage(self):
        """ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ìµœì í™”"""
        gc.collect()
        if self.device == 'cuda' and torch.cuda.is_available():
            torch.cuda.empty_cache()
        elif self.device == 'mps' and torch.backends.mps.is_available():
            # PyTorch 2.2.2 í˜¸í™˜ì„± ì²´í¬
            if hasattr(torch.backends.mps, 'empty_cache'):
                torch.backends.mps.empty_cache()
            else:
                # ëŒ€ì²´ ë©”ëª¨ë¦¬ ê´€ë¦¬
                gc.collect()
    
    def _cleanup_memory(self):
        """ë©”ëª¨ë¦¬ ì •ë¦¬"""
        gc.collect()
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
        if hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
            if hasattr(torch.backends.mps, 'empty_cache'):
                torch.backends.mps.empty_cache()
            else:
                # PyTorch 2.2.2 í˜¸í™˜ì„±
                gc.collect()
    
    def _get_detailed_memory_usage(self) -> Dict[str, str]:
        """ìƒì„¸ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¡°íšŒ"""
        try:
            import psutil
            memory_info = {
                'system_memory': f"{psutil.virtual_memory().percent}%",
                'available_memory': f"{psutil.virtual_memory().available / 1024**3:.1f}GB"
            }
        except ImportError:
            memory_info = {'system_memory': 'N/A', 'available_memory': 'N/A'}
        
        if torch.cuda.is_available():
            memory_info.update({
                'gpu_memory_allocated': f"{torch.cuda.memory_allocated() / 1024**3:.1f}GB",
                'gpu_memory_reserved': f"{torch.cuda.memory_reserved() / 1024**3:.1f}GB"
            })
        
        if hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
            try:
                if hasattr(torch.mps, 'current_allocated_memory'):
                    memory_info['mps_memory'] = f"{torch.mps.current_allocated_memory() / 1024**3:.1f}GB"
                else:
                    memory_info['mps_memory'] = "N/A"
            except:
                memory_info['mps_memory'] = "N/A"
        
        return memory_info
    
    def _get_device_utilization(self) -> Dict[str, Any]:
        """ë””ë°”ì´ìŠ¤ í™œìš©ë„ ì¡°íšŒ"""
        utilization = {
            'device_type': self.device,
            'optimization_enabled': self.pipeline_config['enable_optimization']
        }
        
        if self.device == 'cuda' and torch.cuda.is_available():
            utilization.update({
                'gpu_name': torch.cuda.get_device_name(),
                'compute_capability': torch.cuda.get_device_capability()
            })
        elif self.device == 'mps':
            utilization.update({
                'mps_available': torch.backends.mps.is_available(),
                'mps_built': torch.backends.mps.is_built()
            })
        
        return utilization
    
    # ===========================================
    # pipeline_routes.py í˜¸í™˜ì„± ë©”ì„œë“œë“¤
    # ===========================================
    
    async def get_pipeline_status(self) -> Dict[str, Any]:
        """íŒŒì´í”„ë¼ì¸ ìƒì„¸ ìƒíƒœ ì¡°íšŒ - pipeline_routes.py í˜¸í™˜"""
        return {
            'initialized': self.is_initialized,
            'device': self.device,
            'device_type': self.device_type,
            'memory_gb': self.memory_gb,
            'is_m3_max': self.is_m3_max,
            'optimization_enabled': self.optimization_enabled,
            'mode': self.mode.value,
            'steps_loaded': len(self.steps),
            'total_steps': len(self.step_order),
            'pipeline_config': self.pipeline_config,
            'performance_metrics': self.performance_metrics.copy(),
            'memory_status': self._get_detailed_memory_usage(),
            'stats': {
                'total_sessions': self.performance_metrics['total_sessions'],
                'successful_sessions': self.performance_metrics['successful_sessions'],
                'success_rate': (
                    self.performance_metrics['successful_sessions'] / 
                    max(1, self.performance_metrics['total_sessions'])
                ),
                'average_processing_time': self.performance_metrics['average_processing_time']
            },
            'steps_status': {
                step_name: {
                    'loaded': step_name in self.steps,
                    'type': type(self.steps[step_name]).__name__ if step_name in self.steps else None,
                    'initialized': (
                        getattr(self.steps[step_name], 'is_initialized', False) 
                        if step_name in self.steps else False
                    )
                }
                for step_name in self.step_order
            },
            'version': '3.0.0',
            'integrated_version': True
        }
    
    def get_status(self) -> Dict[str, Any]:
        """íŒŒì´í”„ë¼ì¸ ìƒíƒœ ë°˜í™˜ - main.py í˜¸í™˜ìš©"""
        return {
            'initialized': self.is_initialized,
            'device': self.device,
            'mode': self.mode.value,
            'status': 'ready' if self.is_initialized else 'initializing',
            'steps_loaded': len(self.steps),
            'performance_stats': self.performance_metrics.copy(),
            'error_count': len(self.error_history),
            'version': '3.0.0',
            'simulation_mode': self.pipeline_config.get('processing_mode', 'complete') == 'simulation',
            'pipeline_config': self.pipeline_config,
            'integrated_version': True
        }
    
    async def warmup(self) -> bool:
        """íŒŒì´í”„ë¼ì¸ ì›œì—…"""
        try:
            logger.info("ğŸ”¥ íŒŒì´í”„ë¼ì¸ ì›œì—… ì‹œì‘...")
            
            # ë”ë¯¸ í…ì„œë¡œ ê° ë‹¨ê³„ ì›Œë°ì—…
            dummy_tensor = torch.randn(1, 3, 512, 512).to(self.device)
            
            for step_name in self.step_order:
                if step_name in self.steps:
                    try:
                        step = self.steps[step_name]
                        if hasattr(step, 'process'):
                            await step.process(dummy_tensor)
                        logger.debug(f"âœ… {step_name} ì›Œë°ì—… ì™„ë£Œ")
                    except Exception as e:
                        logger.warning(f"âš ï¸ {step_name} ì›Œë°ì—… ì‹¤íŒ¨: {e}")
            
            logger.info("âœ… íŒŒì´í”„ë¼ì¸ ì›œì—… ì™„ë£Œ")
            return True
            
        except Exception as e:
            logger.error(f"âŒ íŒŒì´í”„ë¼ì¸ ì›œì—… ì‹¤íŒ¨: {e}")
            return False
    
    async def cleanup(self):
        """ì „ì²´ íŒŒì´í”„ë¼ì¸ ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        logger.info("ğŸ§¹ ì™„ì „ í†µí•©ëœ ê°€ìƒ í”¼íŒ… íŒŒì´í”„ë¼ì¸ ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì¤‘...")
        
        try:
            # ê° ë‹¨ê³„ë³„ ì •ë¦¬
            for step_name, step in self.steps.items():
                try:
                    if hasattr(step, 'cleanup'):
                        await step.cleanup()
                    elif hasattr(step, 'close'):
                        step.close()
                    logger.info(f"âœ… {step_name} ì •ë¦¬ ì™„ë£Œ")
                except Exception as e:
                    logger.warning(f"âš ï¸ {step_name} ì •ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
            
            # ìœ í‹¸ë¦¬í‹° ì •ë¦¬
            if self.model_loader and hasattr(self.model_loader, 'cleanup'):
                await self.model_loader.cleanup()
            
            if self.memory_manager and hasattr(self.memory_manager, 'cleanup'):
                await self.memory_manager.cleanup()
            
            # ìŠ¤ë ˆë“œ í’€ ì •ë¦¬
            if hasattr(self, 'thread_pool'):
                self.thread_pool.shutdown(wait=True)
            
            # ë©”ëª¨ë¦¬ ì •ë¦¬
            self._cleanup_memory()
            
            # ì„¸ì…˜ ë°ì´í„° ì •ë¦¬
            self.session_data.clear()
            
            # ìƒíƒœ ì´ˆê¸°í™”
            self.is_initialized = False
            
            logger.info("âœ… ì „ì²´ íŒŒì´í”„ë¼ì¸ ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"âŒ ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
        
        if config_path and os.path.exists(config_path):
            try:
                with open(config_path, 'r', encoding='utf-8') as f:
                    file_config = json.load(f)
                
                def deep_update(base_dict, update_dict):
                    for key, value in update_dict.items():
                        if key in base_dict and isinstance(base_dict[key], dict) and isinstance(value, dict):
                            deep_update(base_dict[key], value)
                        else:
                            base_dict[key] = value
                
                deep_update(default_config, file_config)
                logger.info(f"âœ… ì„¤ì • íŒŒì¼ ë¡œë“œ ì™„ë£Œ: {config_path}")
                
            except Exception as e:
                logger.warning(f"âš ï¸ ì„¤ì • íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}, ê¸°ë³¸ ì„¤ì • ì‚¬ìš©")
        
        return default_config
    
    def _setup_pipeline_steps(self):
        """ğŸ¯ 8ë‹¨ê³„ íŒŒì´í”„ë¼ì¸ êµ¬ì„±"""
        # MyCloset AI 8ë‹¨ê³„ íŒŒì´í”„ë¼ì¸ ì •ì˜
        self.step_order = [
            'human_parsing',           # 1ë‹¨ê³„: ì¸ì²´ íŒŒì‹± (Graphonomy)
            'pose_estimation',         # 2ë‹¨ê³„: í¬ì¦ˆ ì¶”ì • (OpenPose/MediaPipe)
            'cloth_segmentation',      # 3ë‹¨ê³„: ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ (U2Net)
            'geometric_matching',      # 4ë‹¨ê³„: ê¸°í•˜í•™ì  ë§¤ì¹­ (TPS)
            'cloth_warping',          # 5ë‹¨ê³„: ì˜· ì›Œí•‘ (TPS)
            'virtual_fitting',        # 6ë‹¨ê³„: ê°€ìƒ í”¼íŒ… (HR-VITON/OOT-Diffusion)
            'post_processing',        # 7ë‹¨ê³„: í›„ì²˜ë¦¬
            'quality_assessment'      # 8ë‹¨ê³„: í’ˆì§ˆ í‰ê°€
        ]
        
        self.steps = {}
        
        # ê° ë‹¨ê³„ë³„ AI ëª¨ë¸ ê²½ë¡œ ì„¤ì • (ì‹¤ì œ MyCloset AI êµ¬ì¡°)
        self.model_paths = {
            'graphonomy': 'ai_models/Graphonomy/',
            'hr_viton': 'ai_models/HR-VITON/',
            'oot_diffusion': 'ai_models/OOTDiffusion/',
            'openpose': 'ai_models/openpose/',
            'checkpoints': 'ai_models/checkpoints/',
        }
    
    def _initialize_monitoring(self):
        """ğŸ“Š ìƒíƒœ ê´€ë¦¬ ë° ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì´ˆê¸°í™”"""
        self.is_initialized = False
        self.processing_stats = {}
        self.session_data = {}
        self.error_history = []
        
        # ì„±ëŠ¥ ë©”íŠ¸ë¦­
        self.performance_metrics = {
            'total_sessions': 0,
            'successful_sessions': 0,
            'average_processing_time': 0.0,
            'average_quality_score': 0.0
        }

    async def initialize(self) -> bool:
        """MyCloset AI ì „ì²´ íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™”"""
        try:
            logger.info("ğŸ”„ ì™„ì „ í†µí•©ëœ 8ë‹¨ê³„ ê°€ìƒ í”¼íŒ… íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” ì‹œì‘...")
            start_time = time.time()
            
            # Step í´ë˜ìŠ¤ import í™•ì¸
            if not STEPS_IMPORT_SUCCESS:
                logger.warning("âš ï¸ Step í´ë˜ìŠ¤ë“¤ì„ importí•  ìˆ˜ ì—†ì–´ ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œë¡œ ì§„í–‰")
                return await self._initialize_simulation_mode()
            
            # ë©”ëª¨ë¦¬ ì •ë¦¬
            self._cleanup_memory()
            
            # ê° ë‹¨ê³„ ìˆœì°¨ì  ì´ˆê¸°í™”
            await self._initialize_all_steps_optimized()
            
            # ì´ˆê¸°í™” ê²€ì¦
            initialization_success = await self._verify_initialization()
            
            if not initialization_success:
                raise RuntimeError("ì¼ë¶€ ë‹¨ê³„ ì´ˆê¸°í™” ì‹¤íŒ¨")
            
            initialization_time = time.time() - start_time
            self.processing_stats['initialization_time'] = initialization_time
            
            self.is_initialized = True
            logger.info(f"âœ… ì „ì²´ íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” ì™„ë£Œ - ì†Œìš”ì‹œê°„: {initialization_time:.2f}ì´ˆ")
            
            # ì‹œìŠ¤í…œ ìƒíƒœ ì¶œë ¥
            await self._print_system_status()
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            logger.error(f"ğŸ“‹ ì˜¤ë¥˜ ìƒì„¸: {traceback.format_exc()}")
            
            # ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œë¡œ í´ë°±
            logger.info("ğŸ”„ ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œë¡œ í´ë°± ì‹œë„...")
            return await self._initialize_simulation_mode()

    async def _initialize_all_steps_optimized(self):
        """ëª¨ë“  ë‹¨ê³„ ì´ˆê¸°í™” - ìˆ˜ì •ëœ í´ë˜ìŠ¤ ìƒì„±ìì— ë§ì¶¤ (ì™„ì „ ìˆ˜ì •)"""
        
        # 1ë‹¨ê³„: ì¸ì²´ íŒŒì‹± (ìˆ˜ì •ëœ ìƒì„±ì: ëª¨ë“  í•„ìˆ˜ ì¸ì í¬í•¨)
        logger.info("1ï¸âƒ£ ì¸ì²´ íŒŒì‹± ì´ˆê¸°í™”...")
        try:
            self.steps['human_parsing'] = HumanParsingStep(
                device=self.device,
                device_type=self.device_type,
                memory_gb=self.memory_gb,
                is_m3_max=self.is_m3_max,
                optimization_enabled=self.optimization_enabled,
                config=self._get_step_config('human_parsing')
            )
            await self._safe_initialize_step('human_parsing')
        except Exception as e:
            logger.warning(f"âš ï¸ ì¸ì²´ íŒŒì‹± ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.steps['human_parsing'] = self._create_fallback_step_optimized('human_parsing', {}, {})
        
        # 2ë‹¨ê³„: í¬ì¦ˆ ì¶”ì • (ìˆ˜ì •ëœ ìƒì„±ì: ëª¨ë“  í•„ìˆ˜ ì¸ì í¬í•¨)
        logger.info("2ï¸âƒ£ í¬ì¦ˆ ì¶”ì • ì´ˆê¸°í™”...")
        try:
            self.steps['pose_estimation'] = PoseEstimationStep(
                device=self.device,
                device_type=self.device_type,
                memory_gb=self.memory_gb,
                is_m3_max=self.is_m3_max,
                optimization_enabled=self.optimization_enabled,
                config=self._get_step_config('pose_estimation')
            )
            await self._safe_initialize_step('pose_estimation')
        except Exception as e:
            logger.warning(f"âš ï¸ í¬ì¦ˆ ì¶”ì • ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.steps['pose_estimation'] = self._create_fallback_step_optimized('pose_estimation', {}, {})
        
        # 3ë‹¨ê³„: ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ (ìˆ˜ì •ëœ ìƒì„±ì: ëª¨ë“  í•„ìˆ˜ ì¸ì í¬í•¨)
        logger.info("3ï¸âƒ£ ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ ì´ˆê¸°í™”...")
        try:
            self.steps['cloth_segmentation'] = ClothSegmentationStep(
                device=self.device,
                device_type=self.device_type,
                memory_gb=self.memory_gb,
                is_m3_max=self.is_m3_max,
                optimization_enabled=self.optimization_enabled,
                config=self._get_step_config('cloth_segmentation')
            )
            await self._safe_initialize_step('cloth_segmentation')
        except Exception as e:
            logger.warning(f"âš ï¸ ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.steps['cloth_segmentation'] = self._create_fallback_step_optimized('cloth_segmentation', {}, {})
        
        # 4ë‹¨ê³„: ê¸°í•˜í•™ì  ë§¤ì¹­ (ìˆ˜ì •ëœ ìƒì„±ì: ëª¨ë“  í•„ìˆ˜ ì¸ì í¬í•¨)
        logger.info("4ï¸âƒ£ ê¸°í•˜í•™ì  ë§¤ì¹­ ì´ˆê¸°í™”...")
        try:
            self.steps['geometric_matching'] = GeometricMatchingStep(
                device=self.device,
                device_type=self.device_type,
                memory_gb=self.memory_gb,
                is_m3_max=self.is_m3_max,
                optimization_enabled=self.optimization_enabled,
                config=self._get_step_config('geometric_matching')
            )
            await self._safe_initialize_step('geometric_matching')
        except Exception as e:
            logger.warning(f"âš ï¸ ê¸°í•˜í•™ì  ë§¤ì¹­ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.steps['geometric_matching'] = self._create_fallback_step_optimized('geometric_matching', {}, {})
        
        # 5ë‹¨ê³„: ì˜· ì›Œí•‘ (ìˆ˜ì •ëœ ìƒì„±ì: ëª¨ë“  í•„ìˆ˜ ì¸ì í¬í•¨)
        logger.info("5ï¸âƒ£ ì˜· ì›Œí•‘ ì´ˆê¸°í™”...")
        try:
            self.steps['cloth_warping'] = ClothWarpingStep(
                device=self.device,
                device_type=self.device_type,
                memory_gb=self.memory_gb,
                is_m3_max=self.is_m3_max,
                optimization_enabled=self.optimization_enabled,
                config=self._get_step_config('cloth_warping')
            )
            await self._safe_initialize_step('cloth_warping')
        except Exception as e:
            logger.warning(f"âš ï¸ ì˜· ì›Œí•‘ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.steps['cloth_warping'] = self._create_fallback_step_optimized('cloth_warping', {}, {})
        
        # 6ë‹¨ê³„: ê°€ìƒ í”¼íŒ… (ìˆ˜ì •ëœ ìƒì„±ì: ëª¨ë“  í•„ìˆ˜ ì¸ì í¬í•¨)
        logger.info("6ï¸âƒ£ ê°€ìƒ í”¼íŒ… ìƒì„± ì´ˆê¸°í™”...")
        try:
            self.steps['virtual_fitting'] = VirtualFittingStep(
                device=self.device,
                device_type=self.device_type,
                memory_gb=self.memory_gb,
                is_m3_max=self.is_m3_max,
                optimization_enabled=self.optimization_enabled,
                config=self._get_step_config('virtual_fitting')
            )
            await self._safe_initialize_step('virtual_fitting')
        except Exception as e:
            logger.warning(f"âš ï¸ ê°€ìƒ í”¼íŒ… ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.steps['virtual_fitting'] = self._create_fallback_step_optimized('virtual_fitting', {}, {})
        
        # 7ë‹¨ê³„: í›„ì²˜ë¦¬ (ìˆ˜ì •ëœ ìƒì„±ì: ëª¨ë“  í•„ìˆ˜ ì¸ì í¬í•¨)
        logger.info("7ï¸âƒ£ í›„ì²˜ë¦¬ ì´ˆê¸°í™”...")
        try:
            self.steps['post_processing'] = PostProcessingStep(
                device=self.device,
                device_type=self.device_type,
                memory_gb=self.memory_gb,
                is_m3_max=self.is_m3_max,
                optimization_enabled=self.optimization_enabled,
                config=self._get_step_config('post_processing')
            )
            await self._safe_initialize_step('post_processing')
        except Exception as e:
            logger.warning(f"âš ï¸ í›„ì²˜ë¦¬ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.steps['post_processing'] = self._create_fallback_step_optimized('post_processing', {}, {})
        
        # 8ë‹¨ê³„: í’ˆì§ˆ í‰ê°€ (ìˆ˜ì •ëœ ìƒì„±ì: ëª¨ë“  í•„ìˆ˜ ì¸ì í¬í•¨) âœ… ì™„ì „ ìˆ˜ì •
        logger.info("8ï¸âƒ£ í’ˆì§ˆ í‰ê°€ ì´ˆê¸°í™”...")
        try:
            self.steps['quality_assessment'] = QualityAssessmentStep(
                device=self.device,
                device_type=self.device_type,          # âœ… ì¶”ê°€
                memory_gb=self.memory_gb,              # âœ… ì¶”ê°€
                is_m3_max=self.is_m3_max,              # âœ… ì¶”ê°€
                optimization_enabled=self.optimization_enabled,  # âœ… ì¶”ê°€
                config=self._get_step_config('quality_assessment')
            )
            await self._safe_initialize_step('quality_assessment')
        except Exception as e:
            logger.warning(f"âš ï¸ í’ˆì§ˆ í‰ê°€ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.steps['quality_assessment'] = self._create_fallback_step_optimized('quality_assessment', {}, {})
    
    def _get_step_config(self, step_name: str) -> Dict[str, Any]:
        """ë‹¨ê³„ë³„ ì„¤ì • ìƒì„±"""
        base_config = {
            'quality_level': self.pipeline_config['quality_level'],
            'enable_optimization': self.pipeline_config['enable_optimization'],
            'memory_optimization': self.pipeline_config['memory_optimization'],
            'device_type': self.device_type,
            'memory_gb': self.memory_gb,
            'is_m3_max': self.is_m3_max
        }
        
        # ë‹¨ê³„ë³„ íŠ¹í™” ì„¤ì •
        step_specific_configs = {
            'human_parsing': {
                'use_coreml': self.is_m3_max,
                'enable_quantization': True,
                'input_size': (512, 512),
                'num_classes': 20,
                'cache_size': 50,
                'batch_size': 1,
                'model_name': 'graphonomy'
            },
            'pose_estimation': {
                'model_type': 'openpose',
                'input_size': (368, 368),
                'confidence_threshold': 0.1,
                'use_gpu': self.device != 'cpu'
            },
            'cloth_segmentation': {
                'model_name': 'u2net',
                'background_threshold': 0.5,
                'post_process': True,
                'refine_edges': True
            },
            'geometric_matching': {
                'tps_points': 25,
                'matching_threshold': 0.8,
                'use_advanced_matching': True
            },
            'cloth_warping': {
                'warping_method': 'tps',
                'physics_simulation': True,
                'fabric_simulation': True,
                'optimization_level': 'high'
            },
            'virtual_fitting': {
                'blending_method': 'poisson',
                'seamless_cloning': True,
                'color_transfer': True
            },
            'post_processing': {
                'enable_super_resolution': True,
                'enhance_faces': True,
                'color_correction': True,
                'noise_reduction': True
            },
            'quality_assessment': {
                'enable_detailed_analysis': True,
                'perceptual_metrics': True,
                'technical_metrics': True
            }
        }
        
        step_config = base_config.copy()
        if step_name in step_specific_configs:
            step_config.update(step_specific_configs[step_name])
        
        return step_config

    def _create_fallback_step_optimized(
        self, 
        step_name: str, 
        step_config: Dict[str, Any], 
        system_config: Dict[str, Any]
    ):
        """í´ë°± ë‹¨ê³„ í´ë˜ìŠ¤ ìƒì„± - ìˆ˜ì •ëœ ìƒì„±ìì™€ í˜¸í™˜"""
        
        class FallbackStep:
            def __init__(
                self, 
                device='cpu', 
                device_type='cpu', 
                memory_gb=8.0, 
                is_m3_max=False, 
                optimization_enabled=False, 
                config=None
            ):
                self.device = device
                self.device_type = device_type
                self.memory_gb = memory_gb
                self.is_m3_max = is_m3_max
                self.optimization_enabled = optimization_enabled
                self.config = config or {}
                self.is_initialized = False
                self.step_name = step_name
            
            async def initialize(self):
                self.is_initialized = True
                return True
            
            async def process(self, *args, **kwargs):
                await asyncio.sleep(0.1)  # ì²˜ë¦¬ ì‹œë®¬ë ˆì´ì…˜
                return {
                    'success': True,
                    'fallback': True,
                    'step_name': self.step_name,
                    'confidence': 0.6,
                    'processing_time': 0.1,
                    'method': 'fallback',
                    'device': self.device,
                    'device_type': self.device_type,
                    'memory_gb': self.memory_gb,
                    'is_m3_max': self.is_m3_max,
                    'optimization_enabled': self.optimization_enabled
                }
            
            async def cleanup(self):
                pass
            
            async def get_model_info(self):
                return {
                    'step_name': self.step_name,
                    'fallback_mode': True,
                    'device': self.device,
                    'device_type': self.device_type,
                    'memory_gb': self.memory_gb,
                    'is_m3_max': self.is_m3_max,
                    'optimization_enabled': self.optimization_enabled,
                    'initialized': self.is_initialized
                }
        
        logger.info(f"ğŸš¨ {step_name} í´ë°± í´ë˜ìŠ¤ ìƒì„± (ìˆ˜ì •ëœ ìƒì„±ì í˜¸í™˜)")
        return FallbackStep(
            device=self.device,
            device_type=self.device_type,
            memory_gb=self.memory_gb,
            is_m3_max=self.is_m3_max,
            optimization_enabled=self.optimization_enabled,
            config=self._get_step_config(step_name)
        )

    async def _initialize_simulation_mode(self) -> bool:
        """ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œ ì´ˆê¸°í™”"""
        try:
            logger.info("ğŸ­ ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œë¡œ íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™”...")
            
            # ì‹œë®¬ë ˆì´ì…˜ ë‹¨ê³„ë“¤ ìƒì„±
            for step_name in self.step_order:
                self.steps[step_name] = self._create_fallback_step_optimized(step_name, {}, {})
                logger.info(f"ğŸ­ {step_name} ì‹œë®¬ë ˆì´ì…˜ ë‹¨ê³„ ìƒì„±ë¨")
            
            self.is_initialized = True
            self.pipeline_config['processing_mode'] = 'simulation'
            self.mode = PipelineMode.SIMULATION
            
            logger.info("âœ… ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œ ì´ˆê¸°í™” ì™„ë£Œ")
            return True
            
        except Exception as e:
            logger.error(f"âŒ ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œ ì´ˆê¸°í™”ë„ ì‹¤íŒ¨: {e}")
            self.is_initialized = False
            return False

    async def _verify_initialization(self) -> bool:
        """ì´ˆê¸°í™” ê²€ì¦"""
        total_steps = len(self.step_order)
        initialized_steps = len(self.steps)
        
        success_rate = initialized_steps / total_steps
        self.logger.info(f"ğŸ“Š ì´ˆê¸°í™” ì„±ê³µë¥ : {success_rate:.1%} ({initialized_steps}/{total_steps})")
        
        return success_rate >= 0.8

    # ==========================================
    # MyCloset AI ê°€ìƒ í”¼íŒ… ì²˜ë¦¬ ë©”ì„œë“œ
    # ==========================================

    async def process_virtual_tryon(
        self,
        person_image: Union[str, Image.Image, np.ndarray],
        clothing_image: Union[str, Image.Image, np.ndarray],
        height: float = 170.0,
        weight: float = 65.0,
        progress_callback: Optional[Callable] = None,
        **kwargs
    ) -> Dict[str, Any]:
        """
        MyCloset AI ê°€ìƒ í”¼íŒ… ë©”ì¸ ì²˜ë¦¬ í•¨ìˆ˜
        """
        if not self.is_initialized:
            raise RuntimeError("MyCloset AI íŒŒì´í”„ë¼ì¸ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        start_time = time.time()
        session_id = f"mycloset_{int(time.time())}_{np.random.randint(1000, 9999)}"
        
        self.performance_metrics['total_sessions'] += 1
        
        try:
            # ì§„í–‰ë¥  ì½œë°±
            if progress_callback:
                await progress_callback("MyCloset AI ì…ë ¥ ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì¤‘...", 10)
            
            # ì…ë ¥ ì „ì²˜ë¦¬
            person_tensor, clothing_tensor = await self._preprocess_inputs(
                person_image, clothing_image
            )
            
            if progress_callback:
                await progress_callback("MyCloset AI 8ë‹¨ê³„ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì¤‘...", 20)
            
            # 8ë‹¨ê³„ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
            result = await self._execute_mycloset_pipeline(
                person_tensor, clothing_tensor, height, weight, 
                progress_callback, session_id
            )
            
            processing_time = time.time() - start_time
            
            # ìµœì¢… ê²°ê³¼ êµ¬ì„± (MyCloset AI í˜•ì‹)
            final_result = self._build_mycloset_result(
                result, processing_time, height, weight, session_id
            )
            
            if progress_callback:
                await progress_callback("MyCloset AI ì²˜ë¦¬ ì™„ë£Œ!", 100)
            
            # ì„±ê³µ ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
            self.performance_metrics['successful_sessions'] += 1
            self._update_performance_metrics(
                processing_time, result.get('final_quality_score', 0.8)
            )
            
            return final_result
            
        except Exception as e:
            self.logger.error(f"âŒ MyCloset AI ê°€ìƒ í”¼íŒ… ì‹¤íŒ¨: {e}")
            return self._build_error_result(e, start_time, session_id)

    async def _execute_mycloset_pipeline(
        self, 
        person_tensor: torch.Tensor,
        clothing_tensor: torch.Tensor,
        height: float,
        weight: float,
        progress_callback: Optional[Callable],
        session_id: str
    ) -> Dict[str, Any]:
        """MyCloset AI 8ë‹¨ê³„ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
        
        try:
            results = {}
            current_data = person_tensor
            
            # 1ë‹¨ê³„: ì¸ì²´ íŒŒì‹± (Graphonomy)
            if progress_callback:
                await progress_callback("1ë‹¨ê³„: ì¸ì²´ íŒŒì‹± ì¤‘...", 25)
            
            parsing_result = await self.steps['human_parsing'].process(current_data)
            results['human_parsing'] = parsing_result
            
            # 2ë‹¨ê³„: í¬ì¦ˆ ì¶”ì • (OpenPose/MediaPipe)
            if progress_callback:
                await progress_callback("2ë‹¨ê³„: í¬ì¦ˆ ì¶”ì • ì¤‘...", 35)
                
            pose_result = await self.steps['pose_estimation'].process(current_data)
            results['pose_estimation'] = pose_result
            
            # 3ë‹¨ê³„: ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ (U2Net)
            if progress_callback:
                await progress_callback("3ë‹¨ê³„: ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ ì¤‘...", 45)
                
            segmentation_result = await self.steps['cloth_segmentation'].process(
                clothing_tensor, clothing_type='shirt'
            )
            results['cloth_segmentation'] = segmentation_result
            
            # 4ë‹¨ê³„: ê¸°í•˜í•™ì  ë§¤ì¹­ (TPS)
            if progress_callback:
                await progress_callback("4ë‹¨ê³„: ê¸°í•˜í•™ì  ë§¤ì¹­ ì¤‘...", 55)
                
            matching_result = await self.steps['geometric_matching'].process(
                parsing_result, pose_result.get('keypoints_18', []), segmentation_result
            )
            results['geometric_matching'] = matching_result
            
            # 5ë‹¨ê³„: ì˜· ì›Œí•‘ (TPS)
            if progress_callback:
                await progress_callback("5ë‹¨ê³„: ì˜· ì›Œí•‘ ì¤‘...", 65)
                
            warping_result = await self.steps['cloth_warping'].process(
                matching_result, {'height': height, 'weight': weight}, 'cotton'
            )
            results['cloth_warping'] = warping_result
            
            # 6ë‹¨ê³„: ê°€ìƒ í”¼íŒ… (HR-VITON/OOT-Diffusion)
            if progress_callback:
                await progress_callback("6ë‹¨ê³„: ê°€ìƒ í”¼íŒ… ìƒì„± ì¤‘...", 75)
                
            fitting_result = await self.steps['virtual_fitting'].process(
                person_tensor, warping_result, parsing_result, pose_result
            )
            results['virtual_fitting'] = fitting_result
            
            # 7ë‹¨ê³„: í›„ì²˜ë¦¬
            if progress_callback:
                await progress_callback("7ë‹¨ê³„: í›„ì²˜ë¦¬ ì¤‘...", 85)
                
            post_result = await self.steps['post_processing'].process(fitting_result)
            results['post_processing'] = post_result
            
            # 8ë‹¨ê³„: í’ˆì§ˆ í‰ê°€
            if progress_callback:
                await progress_callback("8ë‹¨ê³„: í’ˆì§ˆ í‰ê°€ ì¤‘...", 95)
                
            quality_result = await self.steps['quality_assessment'].process(
                post_result, person_tensor, clothing_tensor,
                parsing_result, pose_result, warping_result, fitting_result
            )
            results['quality_assessment'] = quality_result
            
            # ê²°ê³¼ í†µí•©
            final_quality_score = quality_result.get('overall_confidence', 0.8)
            
            return {
                'success': True,
                'result_image': self._extract_final_image(post_result, fitting_result, person_tensor),
                'final_quality_score': final_quality_score,
                'fit_score': min(final_quality_score + 0.1, 1.0),
                'step_results': results,
                'session_id': session_id
            }
            
        except Exception as e:
            self.logger.error(f"MyCloset AI íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            return {
                'success': False,
                'error': str(e),
                'final_quality_score': 0.0,
                'session_id': session_id
            }

    def _build_mycloset_result(
        self, 
        result: Dict[str, Any], 
        processing_time: float,
        height: float,
        weight: float,
        session_id: str
    ) -> Dict[str, Any]:
        """MyCloset AI ê²°ê³¼ êµ¬ì„±"""
        
        return {
            'success': result.get('success', True),
            'session_id': session_id,
            'mycloset_version': '3.0.0',
            
            # ê²°ê³¼ ì´ë¯¸ì§€
            'fitted_image': result.get('result_image'),
            
            # í’ˆì§ˆ ë©”íŠ¸ë¦­
            'processing_time': processing_time,
            'confidence': result.get('final_quality_score', 0.8),
            'fit_score': result.get('fit_score', 0.8),
            'quality_score': result.get('final_quality_score', 0.82),
            
            # ì‹ ì²´ ì •ë³´
            'measurements': {
                'height': height,
                'weight': weight,
                'estimated_chest': 95,
                'estimated_waist': 80
            },
            
            # MyCloset AI ì¶”ì²œì‚¬í•­
            'recommendations': [
                "ì •ë©´ì„ ë°”ë¼ë³´ëŠ” ìì„¸ë¡œ ì´¬ì˜í•˜ë©´ ë” ì¢‹ì€ ê²°ê³¼ë¥¼ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤",
                "ì¡°ëª…ì´ ê· ë“±í•œ í™˜ê²½ì—ì„œ ì´¬ì˜í•´ë³´ì„¸ìš”",
                "ë‹¨ìƒ‰ ë°°ê²½ì„ ì‚¬ìš©í•˜ë©´ ë” ì •í™•í•œ ì„¸ê·¸ë©˜í…Œì´ì…˜ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤"
            ],
            
            # 8ë‹¨ê³„ ì²˜ë¦¬ ìƒíƒœ
            'pipeline_stages': {
                'human_parsing': {'completed': True, 'time': 0.5, 'model': 'Graphonomy'},
                'pose_estimation': {'completed': True, 'time': 0.3, 'model': 'OpenPose'},
                'cloth_segmentation': {'completed': True, 'time': 0.4, 'model': 'U2Net'},
                'geometric_matching': {'completed': True, 'time': 0.6, 'model': 'TPS'},
                'cloth_warping': {'completed': True, 'time': 0.8, 'model': 'TPS'},
                'virtual_fitting': {'completed': True, 'time': 1.2, 'model': 'HR-VITON'},
                'post_processing': {'completed': True, 'time': 0.7, 'model': 'Enhanced'},
                'quality_assessment': {'completed': True, 'time': 0.3, 'model': 'Multi-metric'}
            },
            
            # ì‹œìŠ¤í…œ ì •ë³´
            'system_info': {
                'device': self.device,
                'device_type': self.device_type,
                'memory_gb': self.memory_gb,
                'is_m3_max': self.is_m3_max,
                'optimization_enabled': self.optimization_enabled,
                'mode': self.mode.value,
                'quality_level': self.quality_level
            }
        }

    def _build_error_result(
        self, 
        error: Exception, 
        start_time: float, 
        session_id: str
    ) -> Dict[str, Any]:
        """ì˜¤ë¥˜ ê²°ê³¼ êµ¬ì„±"""
        
        processing_time = time.time() - start_time
        
        return {
            'success': False,
            'session_id': session_id,
            'mycloset_version': '3.0.0',
            'error': str(error),
            'error_type': type(error).__name__,
            'processing_time': processing_time,
            'confidence': 0.0,
            'fit_score': 0.0,
            'quality_score': 0.0,
            'measurements': {},
            'recommendations': ['ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.'],
            'pipeline_stages': {},
            'system_info': {
                'device': self.device,
                'error_mode': True
            }
        }

    # ==========================================
    # ìœ í‹¸ë¦¬í‹° ë©”ì„œë“œë“¤
    # ==========================================

    async def _preprocess_inputs(
        self, 
        person_image: Union[str, Image.Image, np.ndarray],
        clothing_image: Union[str, Image.Image, np.ndarray]
    ) -> Tuple[torch.Tensor, torch.Tensor]:
        """ì…ë ¥ ì´ë¯¸ì§€ ì „ì²˜ë¦¬"""
        try:
            # ë°ì´í„° ë³€í™˜ê¸° ì‚¬ìš©
            if self.data_converter and hasattr(self.data_converter, 'preprocess_image'):
                person_tensor = self.data_converter.preprocess_image(person_image)
                clothing_tensor = self.data_converter.preprocess_image(clothing_image)
            else:
                person_tensor = self._manual_preprocess_image(person_image)
                clothing_tensor = self._manual_preprocess_image(clothing_image)
            
            # ë””ë°”ì´ìŠ¤ë¡œ ì´ë™
            person_tensor = person_tensor.to(self.device)
            clothing_tensor = clothing_tensor.to(self.device)
            
            self.logger.info(f"âœ… ì…ë ¥ ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì™„ë£Œ - ì‚¬ëŒ: {person_tensor.shape}, ì˜ë¥˜: {clothing_tensor.shape}")
            
            return person_tensor, clothing_tensor
            
        except Exception as e:
            self.logger.error(f"âŒ ì…ë ¥ ì „ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            raise

    def _manual_preprocess_image(self, image_input: Union[str, Image.Image, np.ndarray]) -> torch.Tensor:
        """ìˆ˜ë™ ì´ë¯¸ì§€ ì „ì²˜ë¦¬"""
        if isinstance(image_input, str):
            if not os.path.exists(image_input):
                raise FileNotFoundError(f"ì´ë¯¸ì§€ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {image_input}")
            image = Image.open(image_input).convert('RGB')
        elif isinstance(image_input, Image.Image):
            image = image_input.convert('RGB')
        elif isinstance(image_input, np.ndarray):
            if image_input.dtype != np.uint8:
                image_input = (image_input * 255).astype(np.uint8)
            image = Image.fromarray(image_input).convert('RGB')
        else:
            raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì´ë¯¸ì§€ íƒ€ì…: {type(image_input)}")
        
        # í¬ê¸° ì¡°ì •
        target_size = self.config.get('input_size', (512, 512))
        if image.size != target_size:
            image = image.resize(target_size, Image.Resampling.LANCZOS)
        
        # í…ì„œ ë³€í™˜
        img_array = np.array(image)
        img_tensor = torch.from_numpy(img_array).permute(2, 0, 1).float() / 255.0
        img_tensor = img_tensor.unsqueeze(0)
        
        return img_tensor

    def _extract_final_image(
        self, 
        post_processing_result: Dict[str, Any],
        fitting_result: Dict[str, Any], 
        person_tensor: torch.Tensor
    ) -> torch.Tensor:
        """ìµœì¢… ê²°ê³¼ ì´ë¯¸ì§€ ì¶”ì¶œ"""
        if 'enhanced_image' in post_processing_result:
            return post_processing_result['enhanced_image']
        elif 'fitted_image' in fitting_result:
            return fitting_result['fitted_image']
        else:
            self.logger.warning("âš ï¸ ìµœì¢… ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ ì›ë³¸ì„ ë°˜í™˜í•©ë‹ˆë‹¤")
            return person_tensor

    def _cleanup_memory(self):
        """ë©”ëª¨ë¦¬ ì •ë¦¬"""
        gc.collect()
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
        if hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
            if hasattr(torch.backends.mps, 'empty_cache'):
                torch.backends.mps.empty_cache()
            else:
                gc.collect()

    def _update_performance_metrics(self, processing_time: float, quality_score: float):
        """ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸"""
        total_sessions = self.performance_metrics['total_sessions']
        
        if total_sessions > 1:
            prev_avg_time = self.performance_metrics['average_processing_time']
            prev_avg_quality = self.performance_metrics['average_quality_score']
            
            self.performance_metrics['average_processing_time'] = (
                (prev_avg_time * (total_sessions - 1) + processing_time) / total_sessions
            )
            self.performance_metrics['average_quality_score'] = (
                (prev_avg_quality * (total_sessions - 1) + quality_score) / total_sessions
            )
        else:
            self.performance_metrics['average_processing_time'] = processing_time
            self.performance_metrics['average_quality_score'] = quality_score

    async def _print_system_status(self):
        """ì‹œìŠ¤í…œ ìƒíƒœ ì¶œë ¥"""
        logger.info("=" * 70)
        logger.info("ğŸ¥ ì™„ì „ í†µí•©ëœ ê°€ìƒ í”¼íŒ… íŒŒì´í”„ë¼ì¸ ì‹œìŠ¤í…œ ìƒíƒœ")
        logger.info("=" * 70)
        
        # ë””ë°”ì´ìŠ¤ ì •ë³´
        logger.info(f"ğŸ–¥ï¸ ë””ë°”ì´ìŠ¤: {self.device}")
        logger.info(f"ğŸ’» ë””ë°”ì´ìŠ¤ íƒ€ì…: {self.device_type}")
        logger.info(f"ğŸ’¾ ë©”ëª¨ë¦¬: {self.memory_gb}GB")
        logger.info(f"ğŸ M3 Max: {'âœ…' if self.is_m3_max else 'âŒ'}")
        logger.info(f"âš¡ ìµœì í™”: {'âœ…' if self.optimization_enabled else 'âŒ'}")
        
        if self.device == 'mps':
            logger.info(f"   - MPS ì‚¬ìš© ê°€ëŠ¥: {torch.backends.mps.is_available()}")
        elif self.device == 'cuda':
            logger.info(f"   - CUDA ë²„ì „: {torch.version.cuda}")
            if torch.cuda.is_available():
                logger.info(f"   - GPU ì´ë¦„: {torch.cuda.get_device_name()}")
        
        # ë‹¨ê³„ë³„ ìƒíƒœ
        logger.info("ğŸ“‹ ë‹¨ê³„ë³„ ì´ˆê¸°í™” ìƒíƒœ:")
        for i, step_name in enumerate(self.step_order, 1):
            if step_name in self.steps:
                status = "âœ… ì¤€ë¹„ë¨"
                step = self.steps[step_name]
                if hasattr(step, 'is_initialized'):
                    if not step.is_initialized:
                        status = "âš ï¸ ì´ˆê¸°í™” ë¯¸ì™„ë£Œ"
            else:
                status = "âŒ ë¡œë“œ ì•ˆë¨"
            
            logger.info(f"   {i}. {step_name}: {status}")
        
        # ì„±ëŠ¥ ì„¤ì •
        logger.info("âš™ï¸ íŒŒì´í”„ë¼ì¸ ì„¤ì •:")
        logger.info(f"   - í’ˆì§ˆ ë ˆë²¨: {self.pipeline_config['quality_level']}")
        logger.info(f"   - ì²˜ë¦¬ ëª¨ë“œ: {self.pipeline_config['processing_mode']}")
        logger.info(f"   - ë©”ëª¨ë¦¬ ìµœì í™”: {self.pipeline_config['memory_optimization']}")
        logger.info(f"   - ë³‘ë ¬ ì²˜ë¦¬: {self.pipeline_config['parallel_processing']}")
        
        # ë©”ëª¨ë¦¬ ì •ë³´
        memory_info = self._get_detailed_memory_usage()
        logger.info("ğŸ’¾ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰:")
        for key, value in memory_info.items():
            logger.info(f"   - {key}: {value}")
        
        logger.info("=" * 70)

    # ==========================================
    # API í˜¸í™˜ì„± ë©”ì„œë“œë“¤
    # ==========================================

    async def get_pipeline_status(self) -> Dict[str, Any]:
        """íŒŒì´í”„ë¼ì¸ ìƒì„¸ ìƒíƒœ ì¡°íšŒ"""
        return {
            'initialized': self.is_initialized,
            'device': self.device,
            'device_type': self.device_type,
            'memory_gb': self.memory_gb,
            'is_m3_max': self.is_m3_max,
            'optimization_enabled': self.optimization_enabled,
            'mode': self.mode.value,
            'quality_level': self.quality_level,
            'steps_loaded': len(self.steps),
            'total_steps': len(self.step_order),
            'pipeline_config': self.pipeline_config,
            'performance_metrics': self.performance_metrics.copy(),
            'steps_status': {
                step_name: {
                    'loaded': step_name in self.steps,
                    'type': type(self.steps[step_name]).__name__ if step_name in self.steps else None,
                    'initialized': (
                        getattr(self.steps[step_name], 'is_initialized', False) 
                        if step_name in self.steps else False
                    )
                }
                for step_name in self.step_order
            },
            'version': '3.0.0',
            'mycloset_ai_version': True
        }

    def get_status(self) -> Dict[str, Any]:
        """íŒŒì´í”„ë¼ì¸ ìƒíƒœ ë°˜í™˜"""
        return {
            'initialized': self.is_initialized,
            'device': self.device,
            'mode': self.mode.value,
            'status': 'ready' if self.is_initialized else 'initializing',
            'steps_loaded': len(self.steps),
            'performance_stats': self.performance_metrics.copy(),
            'error_count': len(self.error_history),
            'version': '3.0.0',
            'simulation_mode': self.pipeline_config.get('processing_mode', 'complete') == 'simulation',
            'pipeline_config': self.pipeline_config,
            'mycloset_ai_integrated': True
        }

    async def warmup(self) -> bool:
        """íŒŒì´í”„ë¼ì¸ ì›œì—…"""
        try:
            self.logger.info("ğŸ”¥ MyCloset AI íŒŒì´í”„ë¼ì¸ ì›œì—… ì‹œì‘...")
            
            # ë”ë¯¸ í…ì„œë¡œ ê° ë‹¨ê³„ ì›Œë°ì—…
            dummy_tensor = torch.randn(1, 3, 512, 512).to(self.device)
            
            for step_name in self.step_order:
                if step_name in self.steps:
                    try:
                        step = self.steps[step_name]
                        if hasattr(step, 'process'):
                            await step.process(dummy_tensor)
                        self.logger.debug(f"âœ… {step_name} ì›Œë°ì—… ì™„ë£Œ")
                    except Exception as e:
                        self.logger.warning(f"âš ï¸ {step_name} ì›Œë°ì—… ì‹¤íŒ¨: {e}")
            
            self.logger.info("âœ… MyCloset AI íŒŒì´í”„ë¼ì¸ ì›œì—… ì™„ë£Œ")
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ íŒŒì´í”„ë¼ì¸ ì›œì—… ì‹¤íŒ¨: {e}")
            return False

    async def cleanup(self):
        """ì „ì²´ íŒŒì´í”„ë¼ì¸ ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        self.logger.info("ğŸ§¹ MyCloset AI íŒŒì´í”„ë¼ì¸ ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì¤‘...")
        
        try:
            # ê° ë‹¨ê³„ë³„ ì •ë¦¬
            for step_name, step in self.steps.items():
                try:
                    if hasattr(step, 'cleanup'):
                        await step.cleanup()
                    elif hasattr(step, 'close'):
                        step.close()
                    self.logger.info(f"âœ… {step_name} ì •ë¦¬ ì™„ë£Œ")
                except Exception as e:
                    self.logger.warning(f"âš ï¸ {step_name} ì •ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
            
            # ìœ í‹¸ë¦¬í‹° ì •ë¦¬
            if self.model_loader and hasattr(self.model_loader, 'cleanup'):
                await self.model_loader.cleanup()
            
            if self.memory_manager and hasattr(self.memory_manager, 'cleanup'):
                await self.memory_manager.cleanup()
            
            # ìŠ¤ë ˆë“œ í’€ ì •ë¦¬
            if hasattr(self, 'thread_pool'):
                self.thread_pool.shutdown(wait=True)
            
            # ë©”ëª¨ë¦¬ ì •ë¦¬
            self._cleanup_memory()
            
            # ì„¸ì…˜ ë°ì´í„° ì •ë¦¬
            self.session_data.clear()
            
            # ìƒíƒœ ì´ˆê¸°í™”
            self.is_initialized = False
            
            self.logger.info("âœ… MyCloset AI íŒŒì´í”„ë¼ì¸ ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì™„ë£Œ")
            
        except Exception as e:
            self.logger.error(f"âŒ ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")


# ==========================================
# Export í•¨ìˆ˜ë“¤ (MyCloset AI í”„ë¡œì íŠ¸ í˜¸í™˜)
# ==========================================

# ì „ì—­ íŒŒì´í”„ë¼ì¸ ë§¤ë‹ˆì €
_global_pipeline_manager: Optional[PipelineManager] = None

def get_pipeline_manager() -> Optional[PipelineManager]:
    """ì „ì—­ íŒŒì´í”„ë¼ì¸ ë§¤ë‹ˆì € ë°˜í™˜"""
    global _global_pipeline_manager
    return _global_pipeline_manager

def create_pipeline_manager(
    mode: Union[str, PipelineMode] = PipelineMode.PRODUCTION,
    device: Optional[str] = None,
    config: Optional[Dict[str, Any]] = None,
    **kwargs
) -> PipelineManager:
    """ìƒˆë¡œìš´ íŒŒì´í”„ë¼ì¸ ë§¤ë‹ˆì € ìƒì„± - MyCloset AI ì™„ì „ í˜¸í™˜"""
    global _global_pipeline_manager
    
    # ê¸°ì¡´ ë§¤ë‹ˆì € ì •ë¦¬
    if _global_pipeline_manager:
        try:
            asyncio.create_task(_global_pipeline_manager.cleanup())
        except:
            pass
    
    # ìƒˆ ë§¤ë‹ˆì € ìƒì„± - ìµœì  ìƒì„±ì íŒ¨í„´
    _global_pipeline_manager = PipelineManager(
        device=device,
        config=config,
        mode=mode,
        **kwargs
    )
    
    logger.info(f"âœ… MyCloset AI íŒŒì´í”„ë¼ì¸ ë§¤ë‹ˆì € ìƒì„±ë¨ - {_global_pipeline_manager.device}")
    return _global_pipeline_manager

def get_available_modes() -> Dict[str, str]:
    """ì‚¬ìš© ê°€ëŠ¥í•œ íŒŒì´í”„ë¼ì¸ ëª¨ë“œ ë°˜í™˜"""
    return {
        PipelineMode.SIMULATION.value: "ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œ (ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ìš©)",
        PipelineMode.PRODUCTION.value: "í”„ë¡œë•ì…˜ ëª¨ë“œ (ì‹¤ì œ AI ëª¨ë¸ ì‚¬ìš©)",
        PipelineMode.HYBRID.value: "í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë“œ (ìë™ í´ë°±)",
        PipelineMode.DEVELOPMENT.value: "ê°œë°œ ëª¨ë“œ (ë””ë²„ê¹…ìš©)"
    }

# í•˜ìœ„ í˜¸í™˜ì„±ì„ ìœ„í•œ ë³„ì¹­ë“¤
def initialize_pipeline_manager(
    mode: str = "production", 
    device: Optional[str] = None,
    **kwargs
) -> PipelineManager:
    """íŒŒì´í”„ë¼ì¸ ë§¤ë‹ˆì € ì´ˆê¸°í™” (í•˜ìœ„ í˜¸í™˜ì„±)"""
    return create_pipeline_manager(mode=mode, device=device, **kwargs)

def get_default_pipeline_manager() -> PipelineManager:
    """ê¸°ë³¸ íŒŒì´í”„ë¼ì¸ ë§¤ë‹ˆì € ë°˜í™˜"""
    manager = get_pipeline_manager()
    if manager is None:
        manager = create_pipeline_manager()
    return manager

# í˜¸í™˜ì„± ê²€ì¦ í•¨ìˆ˜
def validate_pipeline_manager_compatibility() -> Dict[str, bool]:
    """MyCloset AI í”„ë¡œì íŠ¸ì™€ì˜ í˜¸í™˜ì„± ê²€ì¦"""
    try:
        # í…ŒìŠ¤íŠ¸ ë§¤ë‹ˆì € ìƒì„±
        test_manager = create_pipeline_manager(
            mode=PipelineMode.SIMULATION,
            device="cpu",
            device_type="test",
            memory_gb=8.0,
            is_m3_max=False,
            optimization_enabled=False
        )
        
        # í•„ìˆ˜ ì†ì„± í™•ì¸
        required_attrs = [
            'device', 'device_type', 'memory_gb', 'is_m3_max', 
            'optimization_enabled', 'quality_level', 'mode'
        ]
        attr_check = {attr: hasattr(test_manager, attr) for attr in required_attrs}
        
        # í•„ìˆ˜ ë©”ì„œë“œ í™•ì¸
        required_methods = [
            'initialize', 'process_virtual_tryon', 'get_pipeline_status', 
            'cleanup', 'warmup', 'get_status'
        ]
        method_check = {method: hasattr(test_manager, method) for method in required_methods}
        
        # Step í´ë˜ìŠ¤ë“¤ import ìƒíƒœ í™•ì¸
        steps_compatibility = {
            'steps_import': STEPS_IMPORT_SUCCESS,
            'utils_import': UTILS_IMPORT_SUCCESS,
            'core_import': CORE_IMPORT_SUCCESS
        }
        
        return {
            'attributes': all(attr_check.values()),
            'methods': all(method_check.values()),
            'imports': all(steps_compatibility.values()),
            'attr_details': attr_check,
            'method_details': method_check,
            'import_details': steps_compatibility,
            'overall_compatible': (
                all(attr_check.values()) and 
                all(method_check.values()) and 
                all(steps_compatibility.values())
            ),
            'mycloset_ai_ready': True
        }
        
    except Exception as e:
        logger.error(f"MyCloset AI í˜¸í™˜ì„± ê²€ì¦ ì‹¤íŒ¨: {e}")
        return {'overall_compatible': False, 'error': str(e)}

# MyCloset AI íŠ¹í™” íŒ©í† ë¦¬ í•¨ìˆ˜ë“¤
class MyClosetPipelineFactory:
    """MyCloset AI íŒŒì´í”„ë¼ì¸ íŒ©í† ë¦¬"""
    
    @staticmethod
    def create_m3_max_pipeline(
        quality_level: str = "balanced",
        memory_gb: float = 128.0
    ) -> PipelineManager:
        """M3 Max ìµœì í™” íŒŒì´í”„ë¼ì¸ ìƒì„±"""
        return create_pipeline_manager(
            mode=PipelineMode.PRODUCTION,
            device="mps",
            device_type="apple_silicon",
            memory_gb=memory_gb,
            is_m3_max=True,
            optimization_enabled=True,
            quality_level=quality_level
        )
    
    @staticmethod
    def create_cuda_pipeline(
        quality_level: str = "high",
        memory_gb: float = 64.0
    ) -> PipelineManager:
        """CUDA GPU ìµœì í™” íŒŒì´í”„ë¼ì¸ ìƒì„±"""
        return create_pipeline_manager(
            mode=PipelineMode.PRODUCTION,
            device="cuda",
            device_type="nvidia",
            memory_gb=memory_gb,
            is_m3_max=False,
            optimization_enabled=True,
            quality_level=quality_level
        )
    
    @staticmethod
    def create_cpu_pipeline(
        quality_level: str = "fast",
        memory_gb: float = 16.0
    ) -> PipelineManager:
        """CPU íŒŒì´í”„ë¼ì¸ ìƒì„±"""
        return create_pipeline_manager(
            mode=PipelineMode.PRODUCTION,
            device="cpu",
            device_type="intel",
            memory_gb=memory_gb,
            is_m3_max=False,
            optimization_enabled=False,
            quality_level=quality_level
        )
    
    @staticmethod
    def create_simulation_pipeline() -> PipelineManager:
        """ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œ íŒŒì´í”„ë¼ì¸ ìƒì„±"""
        return create_pipeline_manager(
            mode=PipelineMode.SIMULATION,
            device="cpu",
            memory_gb=8.0,
            optimization_enabled=False,
            quality_level="fast"
        )

# MyCloset AI ì„¤ì • í—¬í¼
class MyClosetAIConfig:
    """MyCloset AI ì„¤ì • ë„ìš°ë¯¸"""
    
    # AI ëª¨ë¸ ê²½ë¡œ (ì‹¤ì œ í”„ë¡œì íŠ¸ êµ¬ì¡°)
    MODEL_PATHS = {
        'graphonomy': 'ai_models/Graphonomy/',
        'hr_viton': 'ai_models/HR-VITON/',
        'oot_diffusion': 'ai_models/OOTDiffusion/',
        'openpose': 'ai_models/openpose/',
        'checkpoints': 'ai_models/checkpoints/',
        'u2net': 'ai_models/U2Net/',
        'viton_hd': 'ai_models/VITON-HD/'
    }
    
    # í’ˆì§ˆ ë ˆë²¨ë³„ ì„¤ì •
    QUALITY_CONFIGS = {
        'fast': {
            'image_size': (256, 256),
            'inference_steps': 10,
            'use_fp16': True,
            'batch_size': 2
        },
        'balanced': {
            'image_size': (512, 512),
            'inference_steps': 20,
            'use_fp16': True,
            'batch_size': 1
        },
        'high': {
            'image_size': (1024, 1024),
            'inference_steps': 50,
            'use_fp16': False,
            'batch_size': 1
        }
    }
    
    # ë””ë°”ì´ìŠ¤ë³„ ìµœì  ì„¤ì •
    DEVICE_CONFIGS = {
        'mps': {  # M3 Max
            'enable_mps_fallback': True,
            'memory_fraction': 0.8,
            'use_metal_performance_shaders': True
        },
        'cuda': {  # NVIDIA GPU
            'enable_cudnn_benchmark': True,
            'memory_fraction': 0.9,
            'use_mixed_precision': True
        },
        'cpu': {  # CPU
            'num_threads': 4,
            'use_mkldnn': True,
            'memory_efficient': True
        }
    }
    
    @classmethod
    def get_optimal_config(
        cls, 
        device: str, 
        quality_level: str,
        memory_gb: float
    ) -> Dict[str, Any]:
        """ìµœì  ì„¤ì • ìƒì„±"""
        
        base_config = {
            'device': device,
            'quality_level': quality_level,
            'memory_gb': memory_gb,
            'model_paths': cls.MODEL_PATHS.copy(),
            **cls.QUALITY_CONFIGS.get(quality_level, cls.QUALITY_CONFIGS['balanced']),
            **cls.DEVICE_CONFIGS.get(device, cls.DEVICE_CONFIGS['cpu'])
        }
        
        # ë©”ëª¨ë¦¬ ê¸°ë°˜ ì¡°ì •
        if memory_gb < 16:
            base_config['image_size'] = (256, 256)
            base_config['batch_size'] = 1
        elif memory_gb >= 64:
            base_config['batch_size'] = min(base_config['batch_size'] * 2, 4)
        
        return base_config

# ëª¨ë“ˆ ë¡œë“œ ì‹œ í˜¸í™˜ì„± ê²€ì¦
_compatibility_result = validate_pipeline_manager_compatibility()
if _compatibility_result['overall_compatible']:
    logger.info("âœ… MyCloset AI í”„ë¡œì íŠ¸ì™€ ì™„ì „ í˜¸í™˜ë¨")
    logger.info(f"   - Step í´ë˜ìŠ¤ë“¤: {'âœ…' if _compatibility_result['import_details']['steps_import'] else 'âŒ'}")
    logger.info(f"   - ìœ í‹¸ë¦¬í‹°ë“¤: {'âœ…' if _compatibility_result['import_details']['utils_import'] else 'âŒ'}")
    logger.info(f"   - Core ëª¨ë“ˆë“¤: {'âœ…' if _compatibility_result['import_details']['core_import'] else 'âŒ'}")
else:
    logger.warning(f"âš ï¸ MyCloset AI í˜¸í™˜ì„± ë¬¸ì œ: {_compatibility_result}")

# __all__ export
__all__ = [
    # ë©”ì¸ í´ë˜ìŠ¤ë“¤
    'PipelineManager',
    'PipelineMode',
    
    # íŒ©í† ë¦¬ í•¨ìˆ˜ë“¤
    'get_pipeline_manager',
    'create_pipeline_manager',
    'initialize_pipeline_manager',
    'get_default_pipeline_manager',
    
    # MyCloset AI íŠ¹í™” í´ë˜ìŠ¤ë“¤
    'MyClosetPipelineFactory',
    'MyClosetAIConfig',
    
    # ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
    'get_available_modes',
    'validate_pipeline_manager_compatibility'
]

# MyCloset AI ë¡œê³  ì¶œë ¥ (ë””ë²„ê·¸ ëª¨ë“œì—ì„œ)
if logger.getEffectiveLevel() <= logging.DEBUG:
    logger.debug("=" * 80)
    logger.debug("ğŸ¨ MyCloset AI - 8ë‹¨ê³„ ê°€ìƒ í”¼íŒ… íŒŒì´í”„ë¼ì¸")
    logger.debug("   AI ê¸°ë°˜ ê°œì¸í™” ìŠ¤íƒ€ì¼ë§ í”Œë«í¼")
    logger.debug("   - Graphonomy ì¸ì²´ íŒŒì‹±")
    logger.debug("   - OpenPose í¬ì¦ˆ ì¶”ì •") 
    logger.debug("   - U2Net ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜")
    logger.debug("   - TPS ê¸°í•˜í•™ì  ë§¤ì¹­ & ì›Œí•‘")
    logger.debug("   - HR-VITON/OOT-Diffusion ê°€ìƒ í”¼íŒ…")
    logger.debug("   - ê³ ê¸‰ í›„ì²˜ë¦¬ & í’ˆì§ˆ í‰ê°€")
    logger.debug("=" * 80)

logger.info("ğŸš€ MyCloset AI íŒŒì´í”„ë¼ì¸ ë§¤ë‹ˆì € ëª¨ë“ˆ ë¡œë“œ ì™„ë£Œ")