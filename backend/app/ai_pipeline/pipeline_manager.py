"""
8ë‹¨ê³„ AI íŒŒì´í”„ë¼ì¸ ë§¤ë‹ˆì € - ì‹¤ì œ ëª¨ë¸ ì—°ê²°
MyCloset AIì˜ í•µì‹¬ ì—”ì§„
"""
import os
import asyncio
import logging
import time
from typing import Dict, Any, Optional, List, Tuple
from pathlib import Path
from PIL import Image
import numpy as np
import torch
import cv2
from concurrent.futures import ThreadPoolExecutor
import gc

# 8ë‹¨ê³„ íŒŒì´í”„ë¼ì¸ ìŠ¤í…ë“¤ ì„í¬íŠ¸
from .steps.step_01_human_parsing import HumanParsingStep
from .steps.step_02_pose_estimation import PoseEstimationStep
from .steps.step_03_cloth_segmentation import ClothSegmentationStep
from .steps.step_04_geometric_matching import GeometricMatchingStep
from .steps.step_05_cloth_warping import ClothWarpingStep
from .steps.step_06_virtual_fitting import VirtualFittingStep
from .steps.step_07_post_processing import PostProcessingStep
from .steps.step_08_quality_assessment import QualityAssessmentStep

# ìœ í‹¸ë¦¬í‹° ì„í¬íŠ¸
from .utils.model_loader import ModelLoader
from .utils.memory_manager import MemoryManager
from .utils.data_converter import DataConverter

from ..core.gpu_config import GPUConfig
from ..core.pipeline_config import PipelineConfig

logger = logging.getLogger(__name__)

class PipelineManager:
    """8ë‹¨ê³„ AI íŒŒì´í”„ë¼ì¸ í†µí•© ë§¤ë‹ˆì €"""
    
    def __init__(self, config: Optional[PipelineConfig] = None):
        """
        Args:
            config: íŒŒì´í”„ë¼ì¸ ì„¤ì •
        """
        self.config = config or PipelineConfig()
        self.gpu_config = GPUConfig()
        
        # ë””ë°”ì´ìŠ¤ ì„¤ì •
        self.device = self.gpu_config.get_optimal_device()
        logger.info(f"ğŸ”§ íŒŒì´í”„ë¼ì¸ ë””ë°”ì´ìŠ¤: {self.device}")
        
        # ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
        self.model_loader = ModelLoader(device=self.device)
        self.memory_manager = MemoryManager(device=self.device)
        self.data_converter = DataConverter()
        
        # 8ë‹¨ê³„ íŒŒì´í”„ë¼ì¸ ìŠ¤í…ë“¤
        self.steps = {}
        self.is_initialized = False
        
        # ì²˜ë¦¬ í†µê³„
        self.stats = {
            "total_processed": 0,
            "successful_processes": 0,
            "average_time_per_step": {},
            "memory_usage": [],
            "error_counts": {}
        }
        
        # ìŠ¤ë ˆë“œ í’€
        self.executor = ThreadPoolExecutor(max_workers=self.config.max_workers)
        
        logger.info("ğŸ¤– PipelineManager ì´ˆê¸°í™” ì™„ë£Œ")
    
    async def initialize(self) -> bool:
        """íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” - ëª¨ë“  ëª¨ë¸ ë¡œë“œ"""
        try:
            logger.info("ğŸš€ 8ë‹¨ê³„ AI íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” ì‹œì‘...")
            
            # GPU ë©”ëª¨ë¦¬ ìµœì í™”
            await self.memory_manager.optimize_memory()
            
            # 1ë‹¨ê³„: ì¸ì²´ íŒŒì‹± (Graphonomy)
            logger.info("1ï¸âƒ£ ì¸ì²´ íŒŒì‹± ëª¨ë¸ ë¡œë“œ ì¤‘...")
            self.steps[1] = HumanParsingStep(
                model_loader=self.model_loader,
                device=self.device,
                config=self.config.step_configs.get('human_parsing', {})
            )
            await self.steps[1].initialize()
            
            # 2ë‹¨ê³„: í¬ì¦ˆ ì¶”ì • (OpenPose/MediaPipe)
            logger.info("2ï¸âƒ£ í¬ì¦ˆ ì¶”ì • ëª¨ë¸ ë¡œë“œ ì¤‘...")
            self.steps[2] = PoseEstimationStep(
                model_loader=self.model_loader,
                device=self.device,
                config=self.config.step_configs.get('pose_estimation', {})
            )
            await self.steps[2].initialize()
            
            # 3ë‹¨ê³„: ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ (UÂ²-Net)
            logger.info("3ï¸âƒ£ ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ ëª¨ë¸ ë¡œë“œ ì¤‘...")
            self.steps[3] = ClothSegmentationStep(
                model_loader=self.model_loader,
                device=self.device,
                config=self.config.step_configs.get('cloth_segmentation', {})
            )
            await self.steps[3].initialize()
            
            # 4ë‹¨ê³„: ê¸°í•˜í•™ì  ë§¤ì¹­ (TPS)
            logger.info("4ï¸âƒ£ ê¸°í•˜í•™ì  ë§¤ì¹­ ëª¨ë¸ ë¡œë“œ ì¤‘...")
            self.steps[4] = GeometricMatchingStep(
                model_loader=self.model_loader,
                device=self.device,
                config=self.config.step_configs.get('geometric_matching', {})
            )
            await self.steps[4].initialize()
            
            # 5ë‹¨ê³„: ì˜· ì›Œí•‘
            logger.info("5ï¸âƒ£ ì˜· ì›Œí•‘ ëª¨ë¸ ë¡œë“œ ì¤‘...")
            self.steps[5] = ClothWarpingStep(
                model_loader=self.model_loader,
                device=self.device,
                config=self.config.step_configs.get('cloth_warping', {})
            )
            await self.steps[5].initialize()
            
            # 6ë‹¨ê³„: ê°€ìƒ í”¼íŒ… (HR-VITON/ACGPN)
            logger.info("6ï¸âƒ£ ê°€ìƒ í”¼íŒ… ëª¨ë¸ ë¡œë“œ ì¤‘...")
            self.steps[6] = VirtualFittingStep(
                model_loader=self.model_loader,
                device=self.device,
                config=self.config.step_configs.get('virtual_fitting', {})
            )
            await self.steps[6].initialize()
            
            # 7ë‹¨ê³„: í›„ì²˜ë¦¬ (Super Resolution)
            logger.info("7ï¸âƒ£ í›„ì²˜ë¦¬ ëª¨ë¸ ë¡œë“œ ì¤‘...")
            self.steps[7] = PostProcessingStep(
                model_loader=self.model_loader,
                device=self.device,
                config=self.config.step_configs.get('post_processing', {})
            )
            await self.steps[7].initialize()
            
            # 8ë‹¨ê³„: í’ˆì§ˆ í‰ê°€
            logger.info("8ï¸âƒ£ í’ˆì§ˆ í‰ê°€ ëª¨ë¸ ë¡œë“œ ì¤‘...")
            self.steps[8] = QualityAssessmentStep(
                model_loader=self.model_loader,
                device=self.device,
                config=self.config.step_configs.get('quality_assessment', {})
            )
            await self.steps[8].initialize()
            
            self.is_initialized = True
            logger.info("âœ… 8ë‹¨ê³„ AI íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” ì™„ë£Œ!")
            
            # ë©”ëª¨ë¦¬ ìƒíƒœ ë¡œê·¸
            await self.memory_manager.log_memory_status()
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.is_initialized = False
            return False
    
    async def process_virtual_tryon(
        self,
        person_image: Image.Image,
        clothing_image: Image.Image,
        height: float = 170.0,
        weight: float = 65.0,
        progress_callback=None
    ) -> Dict[str, Any]:
        """
        8ë‹¨ê³„ ê°€ìƒ í”¼íŒ… íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
        
        Args:
            person_image: ì‚¬ìš©ì ì´ë¯¸ì§€
            clothing_image: ì˜ë¥˜ ì´ë¯¸ì§€  
            height: í‚¤ (cm)
            weight: ëª¸ë¬´ê²Œ (kg)
            progress_callback: ì§„í–‰ ìƒíƒœ ì½œë°± í•¨ìˆ˜
            
        Returns:
            ì²˜ë¦¬ ê²°ê³¼
        """
        if not self.is_initialized:
            raise RuntimeError("íŒŒì´í”„ë¼ì¸ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        start_time = time.time()
        process_id = f"process_{int(time.time() * 1000)}"
        
        result = {
            "success": False,
            "process_id": process_id,
            "fitted_image": None,
            "processing_time": 0.0,
            "confidence": 0.0,
            "fit_score": 0.0,
            "quality_score": 0.0,
            "measurements": {},
            "recommendations": [],
            "pipeline_stages": {},
            "debug_info": {}
        }
        
        try:
            logger.info(f"ğŸ¯ ê°€ìƒ í”¼íŒ… ì‹œì‘ - Process ID: {process_id}")
            
            # ì…ë ¥ ì´ë¯¸ì§€ ì „ì²˜ë¦¬
            person_tensor = self.data_converter.pil_to_tensor(person_image, self.device)
            clothing_tensor = self.data_converter.pil_to_tensor(clothing_image, self.device)
            
            # 8ë‹¨ê³„ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
            step_results = {}
            
            # 1ë‹¨ê³„: ì¸ì²´ íŒŒì‹± (20ê°œ ë¶€ìœ„ ë¶„í• )
            if progress_callback:
                await progress_callback(1, "ì¸ì²´ íŒŒì‹± ì‹¤í–‰ ì¤‘...", 0)
            
            step_1_result = await self._execute_step(
                1, "ì¸ì²´ íŒŒì‹±", 
                self.steps[1].process,
                person_tensor,
                progress_callback
            )
            step_results[1] = step_1_result
            result["pipeline_stages"]["step_1_human_parsing"] = step_1_result
            
            # 2ë‹¨ê³„: í¬ì¦ˆ ì¶”ì • (18ê°œ í‚¤í¬ì¸íŠ¸)
            if progress_callback:
                await progress_callback(2, "í¬ì¦ˆ ì¶”ì • ì‹¤í–‰ ì¤‘...", 12.5)
            
            step_2_result = await self._execute_step(
                2, "í¬ì¦ˆ ì¶”ì •",
                self.steps[2].process,
                person_tensor, height, weight,
                progress_callback
            )
            step_results[2] = step_2_result
            result["pipeline_stages"]["step_2_pose_estimation"] = step_2_result
            
            # 3ë‹¨ê³„: ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜
            if progress_callback:
                await progress_callback(3, "ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‹¤í–‰ ì¤‘...", 25)
            
            step_3_result = await self._execute_step(
                3, "ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜",
                self.steps[3].process,
                clothing_tensor,
                progress_callback
            )
            step_results[3] = step_3_result
            result["pipeline_stages"]["step_3_cloth_segmentation"] = step_3_result
            
            # 4ë‹¨ê³„: ê¸°í•˜í•™ì  ë§¤ì¹­
            if progress_callback:
                await progress_callback(4, "ê¸°í•˜í•™ì  ë§¤ì¹­ ì‹¤í–‰ ì¤‘...", 37.5)
            
            step_4_result = await self._execute_step(
                4, "ê¸°í•˜í•™ì  ë§¤ì¹­",
                self.steps[4].process,
                person_tensor, clothing_tensor, 
                step_1_result, step_2_result,
                progress_callback
            )
            step_results[4] = step_4_result
            result["pipeline_stages"]["step_4_geometric_matching"] = step_4_result
            
            # 5ë‹¨ê³„: ì˜· ì›Œí•‘
            if progress_callback:
                await progress_callback(5, "ì˜· ì›Œí•‘ ì‹¤í–‰ ì¤‘...", 50)
            
            step_5_result = await self._execute_step(
                5, "ì˜· ì›Œí•‘",
                self.steps[5].process,
                clothing_tensor, step_4_result, height, weight,
                progress_callback
            )
            step_results[5] = step_5_result
            result["pipeline_stages"]["step_5_cloth_warping"] = step_5_result
            
            # 6ë‹¨ê³„: ê°€ìƒ í”¼íŒ… ìƒì„±
            if progress_callback:
                await progress_callback(6, "ê°€ìƒ í”¼íŒ… ìƒì„± ì¤‘...", 62.5)
            
            step_6_result = await self._execute_step(
                6, "ê°€ìƒ í”¼íŒ… ìƒì„±",
                self.steps[6].process,
                person_tensor, step_5_result,
                step_1_result, step_2_result,
                progress_callback
            )
            step_results[6] = step_6_result
            result["pipeline_stages"]["step_6_virtual_fitting"] = step_6_result
            
            # 7ë‹¨ê³„: í›„ì²˜ë¦¬
            if progress_callback:
                await progress_callback(7, "í›„ì²˜ë¦¬ ì‹¤í–‰ ì¤‘...", 75)
            
            step_7_result = await self._execute_step(
                7, "í›„ì²˜ë¦¬",
                self.steps[7].process,
                step_6_result["fitted_image"],
                progress_callback
            )
            step_results[7] = step_7_result
            result["pipeline_stages"]["step_7_post_processing"] = step_7_result
            
            # 8ë‹¨ê³„: í’ˆì§ˆ í‰ê°€
            if progress_callback:
                await progress_callback(8, "í’ˆì§ˆ í‰ê°€ ì‹¤í–‰ ì¤‘...", 87.5)
            
            step_8_result = await self._execute_step(
                8, "í’ˆì§ˆ í‰ê°€",
                self.steps[8].process,
                step_7_result["enhanced_image"],
                person_tensor, clothing_tensor,
                progress_callback
            )
            step_results[8] = step_8_result
            result["pipeline_stages"]["step_8_quality_assessment"] = step_8_result
            
            # ìµœì¢… ê²°ê³¼ ì„¤ì •
            final_image = step_7_result["enhanced_image"]
            result.update({
                "success": True,
                "fitted_image": self.data_converter.tensor_to_base64(final_image),
                "processing_time": time.time() - start_time,
                "confidence": step_6_result.get("confidence", 0.85),
                "fit_score": step_8_result.get("fit_score", 0.80),
                "quality_score": step_8_result.get("quality_score", 0.82),
                "measurements": step_2_result.get("measurements", {}),
                "recommendations": step_8_result.get("recommendations", [])
            })
            
            if progress_callback:
                await progress_callback(8, "ì™„ë£Œ!", 100)
            
            # í†µê³„ ì—…ë°ì´íŠ¸
            self._update_stats(result["processing_time"], True, step_results)
            
            logger.info(f"âœ… ê°€ìƒ í”¼íŒ… ì™„ë£Œ - Process ID: {process_id}, ì‹œê°„: {result['processing_time']:.2f}ì´ˆ")
            
        except Exception as e:
            result.update({
                "processing_time": time.time() - start_time,
                "error": str(e),
                "error_step": getattr(e, 'step', 'unknown')
            })
            self._update_stats(result["processing_time"], False, {})
            logger.error(f"âŒ ê°€ìƒ í”¼íŒ… ì‹¤íŒ¨ - Process ID: {process_id}: {e}")
            
        finally:
            # ë©”ëª¨ë¦¬ ì •ë¦¬
            await self.memory_manager.cleanup_step()
        
        return result
    
    async def _execute_step(
        self, 
        step_num: int, 
        step_name: str, 
        step_func, 
        *args, 
        progress_callback=None
    ) -> Dict[str, Any]:
        """ê°œë³„ ìŠ¤í… ì‹¤í–‰"""
        step_start = time.time()
        
        try:
            logger.info(f"{step_num}ï¸âƒ£ {step_name} ì‹œì‘...")
            
            # ë¹„ë™ê¸° ì‹¤í–‰
            result = await asyncio.get_event_loop().run_in_executor(
                self.executor, step_func, *args
            )
            
            processing_time = time.time() - step_start
            result["processing_time"] = processing_time
            result["step_number"] = step_num
            result["step_name"] = step_name
            
            # í†µê³„ ì—…ë°ì´íŠ¸
            if step_name not in self.stats["average_time_per_step"]:
                self.stats["average_time_per_step"][step_name] = []
            self.stats["average_time_per_step"][step_name].append(processing_time)
            
            logger.info(f"âœ… {step_name} ì™„ë£Œ - {processing_time:.2f}ì´ˆ")
            return result
            
        except Exception as e:
            processing_time = time.time() - step_start
            logger.error(f"âŒ {step_name} ì‹¤íŒ¨: {e}")
            
            # ì—ëŸ¬ í†µê³„ ì—…ë°ì´íŠ¸
            if step_name not in self.stats["error_counts"]:
                self.stats["error_counts"][step_name] = 0
            self.stats["error_counts"][step_name] += 1
            
            # ì—ëŸ¬ë¥¼ step ì •ë³´ì™€ í•¨ê»˜ re-raise
            error = Exception(f"{step_name} ì‹¤íŒ¨: {str(e)}")
            error.step = step_num
            raise error
    
    def _update_stats(
        self, 
        processing_time: float, 
        success: bool, 
        step_results: Dict[int, Any]
    ):
        """ì²˜ë¦¬ í†µê³„ ì—…ë°ì´íŠ¸"""
        self.stats["total_processed"] += 1
        
        if success:
            self.stats["successful_processes"] += 1
        
        # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ê¸°ë¡
        if self.device == "cuda":
            memory_used = torch.cuda.memory_allocated() / 1024**3  # GB
        elif self.device == "mps":
            memory_used = torch.mps.current_allocated_memory() / 1024**3  # GB
        else:
            import psutil
            memory_used = psutil.virtual_memory().used / 1024**3  # GB
        
        self.stats["memory_usage"].append(memory_used)
        
        # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë¡œê·¸ ì œí•œ
        if len(self.stats["memory_usage"]) > 100:
            self.stats["memory_usage"] = self.stats["memory_usage"][-50:]
    
    async def get_pipeline_status(self) -> Dict[str, Any]:
        """íŒŒì´í”„ë¼ì¸ ìƒíƒœ ì¡°íšŒ"""
        return {
            "initialized": self.is_initialized,
            "device": self.device,
            "steps_loaded": len(self.steps),
            "total_steps": 8,
            "memory_status": await self.memory_manager.get_memory_status(),
            "stats": {
                "total_processed": self.stats["total_processed"],
                "success_rate": (
                    self.stats["successful_processes"] / self.stats["total_processed"] 
                    if self.stats["total_processed"] > 0 else 0
                ),
                "average_step_times": {
                    step: sum(times) / len(times) 
                    for step, times in self.stats["average_time_per_step"].items()
                },
                "error_counts": self.stats["error_counts"],
                "current_memory_gb": (
                    self.stats["memory_usage"][-1] 
                    if self.stats["memory_usage"] else 0
                )
            }
        }
    
    async def warmup(self) -> bool:
        """íŒŒì´í”„ë¼ì¸ ì›œì—… - ë”ë¯¸ ë°ì´í„°ë¡œ í…ŒìŠ¤íŠ¸"""
        try:
            logger.info("ğŸ”¥ íŒŒì´í”„ë¼ì¸ ì›œì—… ì‹œì‘...")
            
            # ë”ë¯¸ ì´ë¯¸ì§€ ìƒì„± (512x512)
            dummy_person = Image.fromarray(
                np.random.randint(0, 255, (512, 512, 3), dtype=np.uint8)
            )
            dummy_clothing = Image.fromarray(
                np.random.randint(0, 255, (512, 512, 3), dtype=np.uint8)
            )
            
            # ì›œì—… ì‹¤í–‰
            result = await self.process_virtual_tryon(
                dummy_person, dummy_clothing, 
                height=170, weight=65
            )
            
            if result["success"]:
                logger.info("âœ… íŒŒì´í”„ë¼ì¸ ì›œì—… ì™„ë£Œ")
                return True
            else:
                logger.warning("âš ï¸ íŒŒì´í”„ë¼ì¸ ì›œì—… ë¶€ë¶„ ì‹¤íŒ¨")
                return False
                
        except Exception as e:
            logger.error(f"âŒ íŒŒì´í”„ë¼ì¸ ì›œì—… ì‹¤íŒ¨: {e}")
            return False
    
    async def cleanup(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        logger.info("ğŸ§¹ íŒŒì´í”„ë¼ì¸ ë§¤ë‹ˆì € ì •ë¦¬ ì¤‘...")
        
        # ê° ìŠ¤í… ì •ë¦¬
        for step_num, step in self.steps.items():
            try:
                if hasattr(step, 'cleanup'):
                    await step.cleanup()
            except Exception as e:
                logger.warning(f"ìŠ¤í… {step_num} ì •ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
        
        # ë©”ëª¨ë¦¬ ë§¤ë‹ˆì € ì •ë¦¬
        await self.memory_manager.cleanup()
        
        # ìŠ¤ë ˆë“œ í’€ ì¢…ë£Œ
        self.executor.shutdown(wait=True)
        
        # ìŠ¤í… ë”•ì…”ë„ˆë¦¬ ì •ë¦¬
        self.steps.clear()
        self.is_initialized = False
        
        logger.info("âœ… íŒŒì´í”„ë¼ì¸ ë§¤ë‹ˆì € ì •ë¦¬ ì™„ë£Œ")

# ì „ì—­ íŒŒì´í”„ë¼ì¸ ë§¤ë‹ˆì € ì¸ìŠ¤í„´ìŠ¤
_pipeline_manager: Optional[PipelineManager] = None

def get_pipeline_manager() -> PipelineManager:
    """íŒŒì´í”„ë¼ì¸ ë§¤ë‹ˆì € ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    global _pipeline_manager
    if _pipeline_manager is None:
        _pipeline_manager = PipelineManager()
    return _pipeline_manager