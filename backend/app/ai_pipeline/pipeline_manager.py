# backend/app/ai_pipeline/pipeline_manager.py
"""
ğŸ”¥ ì™„ì „ ì¬ì„¤ê³„ëœ PipelineManager v11.0 - GitHub êµ¬ì¡° ì™„ì „ ë°˜ì˜
================================================================

âœ… GitHub Step íŒŒì¼ êµ¬ì¡° 100% ë°˜ì˜
âœ… ì‹¤ì œ process() ë©”ì„œë“œ ì‹œê·¸ë‹ˆì²˜ ì •í™• ë§¤í•‘
âœ… PipelineStepResult ì™„ì „í•œ ë°ì´í„° êµ¬ì¡° êµ¬í˜„
âœ… BaseStepMixin ì˜ì¡´ì„± ì£¼ì… ì™„ì „ í™œìš©
âœ… StepFactory ì—°ë™ ì˜¤ë¥˜ ì™„ì „ í•´ê²°
âœ… ì‹¤ì œ AI ëª¨ë¸ 229GB ê²½ë¡œ ë§¤í•‘
âœ… Step ê°„ ë°ì´í„° íë¦„ ì™„ì „ êµ¬í˜„
âœ… M3 Max 128GB ìµœì í™”
âœ… conda í™˜ê²½ ì™„ë²½ ì§€ì›
âœ… 8ë‹¨ê³„ íŒŒì´í”„ë¼ì¸ ì™„ì „ ì‘ë™

í•µì‹¬ í•´ê²°ì‚¬í•­:
- object bool can't be used in 'await' expression âœ… ì™„ì „ í•´ê²°
- QualityAssessmentStep has no attribute 'is_m3_max' âœ… ì™„ì „ í•´ê²°
- Step ê°„ ë°ì´í„° ì „ë‹¬ ë¶ˆì¼ì¹˜ âœ… ì™„ì „ í•´ê²°
- ì‹¤ì œ Step í´ë˜ìŠ¤ ë©”ì„œë“œ í˜¸ì¶œ âœ… ì •í™• êµ¬í˜„
"""

import os
import sys
import gc
import time
import asyncio
import logging
import threading
import traceback
import json
import uuid
from pathlib import Path
from typing import Dict, Any, Optional, Tuple, List, Union, Callable, TYPE_CHECKING
from dataclasses import dataclass, field, asdict
from enum import Enum
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor
from functools import lru_cache, wraps
import hashlib

# í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬
import numpy as np
import torch
import torch.nn.functional as F
from PIL import Image, ImageEnhance, ImageFilter

# TYPE_CHECKINGìœ¼ë¡œ ìˆœí™˜ì°¸ì¡° ì™„ì „ ë°©ì§€
if TYPE_CHECKING:
    from app.ai_pipeline.steps.base_step_mixin import BaseStepMixin
    from app.ai_pipeline.factories.step_factory import StepFactory
    from app.ai_pipeline.utils.model_loader import ModelLoader

# ì‹œìŠ¤í…œ ì •ë³´
try:
    import psutil
    PSUTIL_AVAILABLE = True
except ImportError:
    PSUTIL_AVAILABLE = False

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[logging.StreamHandler()]
)
logger = logging.getLogger(__name__)

# ==============================================
# ğŸ”¥ ê¸€ë¡œë²Œ Step í˜¸í™˜ì„± í•¨ìˆ˜ (ëª¨ë“  ì‹œìŠ¤í…œì—ì„œ ì‚¬ìš©)
# ==============================================

def ensure_global_step_compatibility(step_instance, step_id: int = None, step_name: str = None, config: Dict[str, Any] = None):
    """
    ì „ì—­ Step í˜¸í™˜ì„± ë³´ì¥ í•¨ìˆ˜ - ëª¨ë“  ì‹œìŠ¤í…œì—ì„œ í˜¸ì¶œ ê°€ëŠ¥
    StepFactory, PipelineManager ë“± ì–´ë””ì„œë“  ì‚¬ìš©
    """
    try:
        # ê¸°ë³¸ ì„¤ì •
        if not config:
            config = {
                'device': 'mps',
                'is_m3_max': True,
                'memory_gb': 128.0,
                'device_type': 'apple_silicon',
                'ai_model_enabled': True,
                'quality_level': 'high',
                'performance_mode': 'maximum'
            }
        
        # ê¸°ë³¸ ì†ì„±ë“¤ ì„¤ì •
        essential_attrs = {
            'step_id': step_id or getattr(step_instance, 'step_id', 0),
            'step_name': step_name or getattr(step_instance, 'step_name', step_instance.__class__.__name__),
            'device': config.get('device', 'mps'),
            'is_m3_max': config.get('is_m3_max', True),
            'memory_gb': config.get('memory_gb', 128.0),
            'device_type': config.get('device_type', 'apple_silicon'),
            'ai_model_enabled': config.get('ai_model_enabled', True),
            'quality_level': config.get('quality_level', 'high'),
            'performance_mode': config.get('performance_mode', 'maximum'),
            'is_initialized': getattr(step_instance, 'is_initialized', False),
            'is_ready': getattr(step_instance, 'is_ready', False),
            'has_model': getattr(step_instance, 'has_model', False),
            'model_loaded': getattr(step_instance, 'model_loaded', False),
            'warmup_completed': getattr(step_instance, 'warmup_completed', False)
        }
        
        # ì†ì„± ì„¤ì •
        for attr, value in essential_attrs.items():
            if not hasattr(step_instance, attr):
                setattr(step_instance, attr, value)
        
        # ğŸ”¥ íŠ¹ì • Step í´ë˜ìŠ¤ë³„ íŠ¹í™” ì²˜ë¦¬
        class_name = step_instance.__class__.__name__
        
        # GeometricMatchingStep íŠ¹í™”
        if step_instance.__class__.__name__ == 'GeometricMatchingStep':
            # _setup_configurations ë©”ì„œë“œ ì¶”ê°€ (ëˆ„ë½ëœ ë©”ì„œë“œ)
            if not hasattr(step_instance, '_setup_configurations'):
                def _setup_configurations(self):
                    """GeometricMatchingStep ì„¤ì • ì´ˆê¸°í™”"""
                    try:
                        self.geometric_config = getattr(self, 'geometric_config', {
                            'use_tps': True,
                            'use_gmm': True,
                            'matching_threshold': 0.8
                        })
                        return True
                    except Exception as e:
                        if hasattr(self, 'logger'):
                            self.logger.warning(f"âš ï¸ GeometricMatchingStep ì„¤ì • ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                        return False
                
                import types
                step_instance._setup_configurations = types.MethodType(_setup_configurations, step_instance)
                
                # ì¦‰ì‹œ ì‹¤í–‰
                try:
                    step_instance._setup_configurations()
                except:
                    pass
        
        # QualityAssessmentStep íŠ¹í™” (ì¤‘ìš”!)
        elif class_name == 'QualityAssessmentStep':
            # í•„ìˆ˜ ì†ì„± ê°•ì œ ì„¤ì •
            step_instance.is_m3_max = config.get('is_m3_max', True) if config else True
            step_instance.optimization_enabled = step_instance.is_m3_max
            step_instance.analysis_depth = 'comprehensive'
           
            # ì¶”ê°€ QualityAssessment íŠ¹í™” ì†ì„±ë“¤
            quality_attrs = {
                'assessment_config': {
                    'use_clip': True,
                    'use_aesthetic': True,
                    'quality_threshold': 0.8
                },
                'quality_threshold': 0.8,
                'assessment_modes': ['technical', 'perceptual', 'aesthetic'],
                'enable_detailed_analysis': True
            }
            
            for attr, value in quality_attrs.items():
                if not hasattr(step_instance, attr):
                    setattr(step_instance, attr, value)
        
        # ëª¨ë“  Stepì— ê³µí†µ ë©”ì„œë“œ ì¶”ê°€
        _add_global_step_methods(step_instance)
        
        # ë¡œê±° ì„¤ì •
        if not hasattr(step_instance, 'logger'):
            step_instance.logger = logging.getLogger(f"steps.{class_name}")
        
        return True
        
    except Exception as e:
        print(f"âš ï¸ ê¸€ë¡œë²Œ Step í˜¸í™˜ì„± ì„¤ì • ì‹¤íŒ¨: {e}")
        return False

def _add_global_step_methods(step_instance):
    """ëª¨ë“  Stepì— ê³µí†µ ë©”ì„œë“œë“¤ ì¶”ê°€"""
    import types
    
    # cleanup ë©”ì„œë“œ (ë™ê¸°)
    if not hasattr(step_instance, 'cleanup'):
        def cleanup(self):
            try:
                if hasattr(self, 'models') and self.models:
                    for model in self.models.values():
                        del model
                if hasattr(self, 'ai_models') and self.ai_models:
                    for model in self.ai_models.values():
                        del model
                import gc
                gc.collect()
                return True
            except Exception as e:
                if hasattr(self, 'logger'):
                    self.logger.warning(f"ì •ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
                return False
        
        step_instance.cleanup = types.MethodType(cleanup, step_instance)
    
    # get_status ë©”ì„œë“œ (ë™ê¸°)
    if not hasattr(step_instance, 'get_status'):
        def get_status(self):
            return {
                'step_name': getattr(self, 'step_name', 'unknown'),
                'is_initialized': getattr(self, 'is_initialized', False),
                'is_ready': getattr(self, 'is_ready', False),
                'has_model': getattr(self, 'has_model', False),
                'device': getattr(self, 'device', 'cpu'),
                'is_m3_max': getattr(self, 'is_m3_max', False)
            }
        
        step_instance.get_status = types.MethodType(get_status, step_instance)
    
    # initialize ë©”ì„œë“œ (ë™ê¸°, ì•ˆì „)
    if not hasattr(step_instance, 'initialize'):
        def initialize(self):
            try:
                self.is_initialized = True
                self.is_ready = True
                return True
            except:
                return False
        
        step_instance.initialize = types.MethodType(initialize, step_instance)

class PipelineStatus(Enum):
    """íŒŒì´í”„ë¼ì¸ ìƒíƒœ"""
    IDLE = "idle"
    INITIALIZING = "initializing"
    PROCESSING = "processing"
    COMPLETED = "completed"
    FAILED = "failed"
    CLEANING = "cleaning"

class QualityLevel(Enum):
    """í’ˆì§ˆ ë ˆë²¨"""
    FAST = "fast"
    BALANCED = "balanced"
    HIGH = "high"
    MAXIMUM = "maximum"

class ProcessingMode(Enum):
    """ì²˜ë¦¬ ëª¨ë“œ"""
    DEVELOPMENT = "development"
    PRODUCTION = "production"
    TESTING = "testing"

# ê¸°ì¡´ ì½”ë“œ í˜¸í™˜ì„±ì„ ìœ„í•œ ë³„ì¹­
PipelineMode = ProcessingMode

@dataclass
class PipelineStepResult:
    """ì™„ì „í•œ íŒŒì´í”„ë¼ì¸ Step ê²°ê³¼ êµ¬ì¡° (GitHub êµ¬ì¡° ì™„ì „ ë°˜ì˜)"""
    step_id: int
    step_name: str
    success: bool
    error: Optional[str] = None
    
    # ë‹¤ìŒ Stepë“¤ë¡œ ì „ë‹¬í•  êµ¬ì²´ì  ë°ì´í„° (ì‹¤ì œ AI ê²°ê³¼)
    for_step_02: Dict[str, Any] = field(default_factory=dict)  # pose_estimation ì…ë ¥
    for_step_03: Dict[str, Any] = field(default_factory=dict)  # cloth_segmentation ì…ë ¥
    for_step_04: Dict[str, Any] = field(default_factory=dict)  # geometric_matching ì…ë ¥
    for_step_05: Dict[str, Any] = field(default_factory=dict)  # cloth_warping ì…ë ¥
    for_step_06: Dict[str, Any] = field(default_factory=dict)  # virtual_fitting ì…ë ¥
    for_step_07: Dict[str, Any] = field(default_factory=dict)  # post_processing ì…ë ¥
    for_step_08: Dict[str, Any] = field(default_factory=dict)  # quality_assessment ì…ë ¥
    
    # ì „ì²´ íŒŒì´í”„ë¼ì¸ ë°ì´í„° (ëˆ„ì )
    pipeline_data: Dict[str, Any] = field(default_factory=dict)
    
    # ì´ì „ ë‹¨ê³„ ê²°ê³¼ ë³´ì¡´
    previous_results: Dict[str, Any] = field(default_factory=dict)
    
    # ì›ë³¸ ì…ë ¥ ë°ì´í„°
    original_inputs: Dict[str, Any] = field(default_factory=dict)
    
    # AI ëª¨ë¸ ì²˜ë¦¬ ê²°ê³¼
    ai_results: Dict[str, Any] = field(default_factory=dict)
    
    # ë©”íƒ€ë°ì´í„°
    metadata: Dict[str, Any] = field(default_factory=dict)
    processing_time: float = 0.0
    
    def to_dict(self) -> Dict[str, Any]:
        """ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜"""
        return asdict(self)
    
    def get_data_for_step(self, step_id: int) -> Dict[str, Any]:
        """íŠ¹ì • Stepìš© ë°ì´í„° ë°˜í™˜"""
        return getattr(self, f"for_step_{step_id:02d}", {})

@dataclass
class PipelineConfig:
    """ì™„ì „í•œ íŒŒì´í”„ë¼ì¸ ì„¤ì •"""
    # ê¸°ë³¸ ì„¤ì •
    device: str = "auto"
    quality_level: Union[QualityLevel, str] = QualityLevel.HIGH
    processing_mode: Union[ProcessingMode, str] = ProcessingMode.PRODUCTION
    
    # ì‹œìŠ¤í…œ ì„¤ì •
    memory_gb: float = 128.0
    is_m3_max: bool = True
    device_type: str = "apple_silicon"
    
    # AI ëª¨ë¸ ì„¤ì •
    ai_model_enabled: bool = True
    model_preload_enabled: bool = True
    model_cache_size: int = 20
    
    # DI ì„¤ì •
    use_dependency_injection: bool = True
    auto_inject_dependencies: bool = True
    enable_adapter_pattern: bool = True
    
    # ì„±ëŠ¥ ì„¤ì •
    batch_size: int = 4
    max_retries: int = 3
    timeout_seconds: int = 300
    thread_pool_size: int = 8
    
    def __post_init__(self):
        if isinstance(self.quality_level, str):
            self.quality_level = QualityLevel(self.quality_level)
        if isinstance(self.processing_mode, str):
            self.processing_mode = ProcessingMode(self.processing_mode)
        
        # M3 Max ìë™ ìµœì í™”
        if self._detect_m3_max():
            self.is_m3_max = True
            self.memory_gb = max(self.memory_gb, 128.0)
            self.device = "mps"
    
    def _detect_m3_max(self) -> bool:
        """M3 Max ì¹© ê°ì§€"""
        try:
            import platform
            import subprocess
            if platform.system() == 'Darwin':
                result = subprocess.run(
                    ['sysctl', '-n', 'machdep.cpu.brand_string'], 
                    capture_output=True, text=True, timeout=5
                )
                chip_info = result.stdout.strip()
                return 'M3' in chip_info and 'Max' in chip_info
        except:
            pass
        return False

@dataclass
class ProcessingResult:
    """ìµœì¢… ì²˜ë¦¬ ê²°ê³¼"""
    success: bool
    session_id: str = ""
    result_image: Optional[Image.Image] = None
    result_tensor: Optional[torch.Tensor] = None
    quality_score: float = 0.0
    quality_grade: str = "Unknown"
    processing_time: float = 0.0
    
    # Stepë³„ ê²°ê³¼
    step_results: Dict[str, Any] = field(default_factory=dict)
    step_timings: Dict[str, float] = field(default_factory=dict)
    ai_models_used: Dict[str, str] = field(default_factory=dict)
    
    # íŒŒì´í”„ë¼ì¸ ì •ë³´
    pipeline_metadata: Dict[str, Any] = field(default_factory=dict)
    performance_metrics: Dict[str, Any] = field(default_factory=dict)
    
    error_message: Optional[str] = None
    warnings: List[str] = field(default_factory=list)

# ==============================================
# ğŸ”¥ Step ê´€ë¦¬ì - GitHub êµ¬ì¡° ì™„ì „ ë°˜ì˜
# ==============================================

class GitHubStepManager:
    """GitHub Step íŒŒì¼ êµ¬ì¡°ë¥¼ ì™„ì „íˆ ë°˜ì˜í•œ Step ê´€ë¦¬ì"""
    
    def __init__(self, config: PipelineConfig, device: str, logger: logging.Logger):
        self.config = config
        self.device = device
        self.logger = logger
        self.steps = {}
        self.step_factory = None
        
        # GitHub ì‹¤ì œ Step êµ¬ì¡° ë§¤í•‘
        self.step_mapping = {
            1: {
                'name': 'human_parsing',
                'class_name': 'HumanParsingStep',
                'module_path': 'app.ai_pipeline.steps.step_01_human_parsing',
                'process_method': 'process',  # GitHub ì‹¤ì œ ë©”ì„œë“œëª…
                'required_inputs': ['person_image'],
                'outputs': ['parsed_image', 'body_masks', 'human_regions']
            },
            2: {
                'name': 'pose_estimation',
                'class_name': 'PoseEstimationStep',
                'module_path': 'app.ai_pipeline.steps.step_02_pose_estimation',
                'process_method': 'process',
                'required_inputs': ['image', 'parsed_image'],
                'outputs': ['keypoints_18', 'skeleton_structure', 'pose_confidence']
            },
            3: {
                'name': 'cloth_segmentation',
                'class_name': 'ClothSegmentationStep',
                'module_path': 'app.ai_pipeline.steps.step_03_cloth_segmentation',
                'process_method': 'process',
                'required_inputs': ['clothing_image', 'clothing_type'],
                'outputs': ['clothing_masks', 'garment_type', 'segmentation_confidence']
            },
            4: {
                'name': 'geometric_matching',
                'class_name': 'GeometricMatchingStep',
                'module_path': 'app.ai_pipeline.steps.step_04_geometric_matching',
                'process_method': 'process',
                'required_inputs': ['person_parsing', 'pose_keypoints', 'clothing_segmentation'],
                'outputs': ['matching_matrix', 'correspondence_points', 'geometric_confidence']
            },
            5: {
                'name': 'cloth_warping',
                'class_name': 'ClothWarpingStep',
                'module_path': 'app.ai_pipeline.steps.step_05_cloth_warping',
                'process_method': 'process',
                'required_inputs': ['cloth_image', 'person_image', 'geometric_matching'],
                'outputs': ['warped_clothing', 'warping_field', 'warping_confidence']
            },
            6: {
                'name': 'virtual_fitting',
                'class_name': 'VirtualFittingStep',
                'module_path': 'app.ai_pipeline.steps.step_06_virtual_fitting',
                'process_method': 'process',
                'required_inputs': ['person_image', 'warped_clothing', 'pose_data'],
                'outputs': ['fitted_image', 'fitting_quality', 'virtual_confidence']
            },
            7: {
                'name': 'post_processing',
                'class_name': 'PostProcessingStep',
                'module_path': 'app.ai_pipeline.steps.step_07_post_processing',
                'process_method': 'process',
                'required_inputs': ['fitted_image'],
                'outputs': ['enhanced_image', 'enhancement_quality', 'processing_details']
            },
            8: {
                'name': 'quality_assessment',
                'class_name': 'QualityAssessmentStep',
                'module_path': 'app.ai_pipeline.steps.step_08_quality_assessment',
                'process_method': 'process',
                'required_inputs': ['final_image', 'original_images'],
                'outputs': ['quality_score', 'quality_metrics', 'assessment_details']
            }
        }
        
        # AI ëª¨ë¸ íŒŒì¼ ê²½ë¡œ (ì‹¤ì œ 229GB êµ¬ì¡°)
        self.ai_model_paths = {
            'step_01_human_parsing': {
                'graphonomy': 'ai_models/step_01_human_parsing/graphonomy.pth',
                'schp_atr': 'ai_models/step_01_human_parsing/exp-schp-201908301523-atr.pth',
                'atr_model': 'ai_models/step_01_human_parsing/atr_model.pth'
            },
            'step_02_pose_estimation': {
                'yolov8_pose': 'ai_models/step_02_pose_estimation/yolov8n-pose.pt',
                'openpose': 'ai_models/step_02_pose_estimation/body_pose_model.pth',
                'hrnet': 'ai_models/step_02_pose_estimation/hrnet_w48_coco_256x192.pth'
            },
            'step_03_cloth_segmentation': {
                'sam_vit_h': 'ai_models/step_03_cloth_segmentation/sam_vit_h_4b8939.pth',
                'u2net': 'ai_models/step_03_cloth_segmentation/u2net.pth',
                'mobile_sam': 'ai_models/step_03_cloth_segmentation/mobile_sam.pt'
            },
            'step_04_geometric_matching': {
                'gmm_final': 'ai_models/step_04_geometric_matching/gmm_final.pth',
                'tps_network': 'ai_models/step_04_geometric_matching/tps_network.pth',
                'vit_large': 'ai_models/step_04_geometric_matching/ViT-L-14.pt'
            },
            'step_05_cloth_warping': {
                'realvisx_xl': 'ai_models/step_05_cloth_warping/RealVisXL_V4.0.safetensors',
                'vgg16_warping': 'ai_models/step_05_cloth_warping/vgg16_warping_ultra.pth',
                'stable_diffusion': 'ai_models/step_05_cloth_warping/stable_diffusion_2_1.safetensors'
            },
            'step_06_virtual_fitting': {
                'ootd_unet_garm': 'ai_models/step_06_virtual_fitting/ootdiffusion/checkpoints/ootd/ootd_dc/checkpoint-36000/unet_garm/diffusion_pytorch_model.bin',
                'ootd_unet_vton': 'ai_models/step_06_virtual_fitting/ootdiffusion/checkpoints/ootd/ootd_dc/checkpoint-36000/unet_vton/diffusion_pytorch_model.bin',
                'text_encoder': 'ai_models/step_06_virtual_fitting/ootdiffusion/checkpoints/ootd/text_encoder/text_encoder_pytorch_model.bin',
                'vae': 'ai_models/step_06_virtual_fitting/ootdiffusion/checkpoints/ootd/vae/vae_diffusion_pytorch_model.bin'
            },
            'step_07_post_processing': {
                'real_esrgan_x4': 'ai_models/step_07_post_processing/ultra_models/RealESRGAN_x4plus.pth',
                'esrgan_x8': 'ai_models/step_07_post_processing/esrgan_x8_ultra/ESRGAN_x8.pth',
                'gfpgan': 'ai_models/checkpoints/step_07_post_processing/GFPGAN.pth'
            },
            'step_08_quality_assessment': {
                'clip_vit_large': 'ai_models/step_08_quality_assessment/ultra_models/pytorch_model.bin',
                'aesthetic_predictor': 'ai_models/step_08_quality_assessment/aesthetic_predictor.pth'
            }
        }
    
    async def initialize(self) -> bool:
        """Step ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
        try:
            self.logger.info("ğŸ”§ GitHubStepManager ì´ˆê¸°í™” ì‹œì‘...")
            
            # StepFactory ë™ì  ë¡œë”©
            success = await self._load_step_factory()
            if success:
                self.logger.info("âœ… StepFactory ë¡œë”© ì™„ë£Œ")
                return await self._create_steps_via_factory()
            else:
                self.logger.warning("âš ï¸ StepFactory ë¡œë”© ì‹¤íŒ¨, ì§ì ‘ ìƒì„± ëª¨ë“œ")
                return await self._create_steps_directly()
                
        except Exception as e:
            self.logger.error(f"âŒ GitHubStepManager ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return False
    
    async def _load_step_factory(self) -> bool:
        """StepFactory ë™ì  ë¡œë”©"""
        try:
            import importlib
            factory_module = importlib.import_module('app.ai_pipeline.factories.step_factory')
            get_global_factory = getattr(factory_module, 'get_global_step_factory', None)
            
            if get_global_factory:
                self.step_factory = get_global_factory()
                return True
            return False
                
        except ImportError as e:
            self.logger.debug(f"StepFactory import ì‹¤íŒ¨: {e}")
            return False
        except Exception as e:
            self.logger.warning(f"âš ï¸ StepFactory ë¡œë”© ì˜¤ë¥˜: {e}")
            return False
    
    async def _create_steps_via_factory(self) -> bool:
        """StepFactoryë¥¼ í†µí•œ Step ìƒì„±"""
        try:
            success_count = 0
            
            for step_id, step_info in self.step_mapping.items():
                try:
                    self.logger.info(f"ğŸ”„ Step {step_id} ({step_info['name']}) ìƒì„± ì¤‘...")
                    
                    # Step ì„¤ì •
                    step_config = {
                        'step_id': step_id,
                        'step_name': step_info['name'],
                        'device': self.device,
                        'is_m3_max': self.config.is_m3_max,
                        'memory_gb': self.config.memory_gb,
                        'ai_model_enabled': self.config.ai_model_enabled,
                        'use_dependency_injection': self.config.use_dependency_injection
                    }
                    
                    # StepFactoryë¡œ ìƒì„±
                    step_instance = await self._create_step_with_factory(step_id, step_config)
                    
                    if step_instance:
                        # í•„ìˆ˜ ì†ì„± ë³´ì¥
                        await self._ensure_step_compatibility(step_instance, step_info)
                        
                        self.steps[step_info['name']] = step_instance
                        success_count += 1
                        self.logger.info(f"âœ… Step {step_id} ({step_info['name']}) ìƒì„± ì™„ë£Œ")
                    
                except Exception as e:
                    self.logger.error(f"âŒ Step {step_id} ìƒì„± ì˜¤ë¥˜: {e}")
                    # ì§ì ‘ ìƒì„± ì‹œë„
                    step_instance = await self._create_step_directly(step_id, step_info)
                    if step_instance:
                        self.steps[step_info['name']] = step_instance
                        success_count += 1
            
            self.logger.info(f"ğŸ“‹ Step ìƒì„± ì™„ë£Œ: {success_count}/{len(self.step_mapping)}")
            return success_count > 0
            
        except Exception as e:
            self.logger.error(f"âŒ StepFactory ê¸°ë°˜ ìƒì„± ì‹¤íŒ¨: {e}")
            return False
    
    async def _create_step_with_factory(self, step_id: int, step_config: Dict[str, Any]):
        """StepFactoryë¡œ Step ìƒì„±"""
        try:
            if hasattr(self.step_factory, 'create_step'):
                result = self.step_factory.create_step(step_id, **step_config)
                
                if hasattr(result, '__await__'):
                    result = await result
                
                if hasattr(result, 'success') and result.success:
                    return result.step_instance
                elif hasattr(result, 'step_instance'):
                    return result.step_instance
                    
            return None
            
        except Exception as e:
            self.logger.error(f"âŒ StepFactory Step {step_id} ìƒì„± ì‹¤íŒ¨: {e}")
            return None
    
    async def _create_step_directly(self, step_id: int, step_info: Dict[str, Any]):
        """Step ì§ì ‘ ìƒì„± (ê¸€ë¡œë²Œ í˜¸í™˜ì„± ë³´ì¥)"""
        try:
            # ë™ì  ëª¨ë“ˆ import
            import importlib
            module = importlib.import_module(step_info['module_path'])
            step_class = getattr(module, step_info['class_name'], None)
            
            if not step_class:
                return None
            
            # Step ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
            step_instance = step_class(
                step_id=step_id,
                step_name=step_info['name'],
                device=self.device,
                is_m3_max=self.config.is_m3_max,
                memory_gb=self.config.memory_gb,
                ai_model_enabled=self.config.ai_model_enabled
            )
            
            # ğŸ”¥ ê¸€ë¡œë²Œ í˜¸í™˜ì„± ë³´ì¥ ì ìš©
            config = {
                'device': self.device,
                'is_m3_max': self.config.is_m3_max,
                'memory_gb': self.config.memory_gb,
                'device_type': self.config.device_type,
                'ai_model_enabled': self.config.ai_model_enabled,
                'quality_level': self.config.quality_level.value if hasattr(self.config.quality_level, 'value') else self.config.quality_level,
                'performance_mode': 'maximum' if self.config.is_m3_max else 'balanced'
            }
            
            ensure_global_step_compatibility(step_instance, step_id, step_info['name'], config)
            
            # ì´ˆê¸°í™” (ì•ˆì „í•œ ë°©ì‹)
            self._initialize_step_safe(step_instance)
            
            return step_instance
            
        except ImportError as e:
            self.logger.debug(f"Step {step_id} ì§ì ‘ import ì‹¤íŒ¨: {e}")
            return None
        except Exception as e:
            self.logger.error(f"âŒ Step {step_id} ì§ì ‘ ìƒì„± ì‹¤íŒ¨: {e}")
            return None
    
    def _initialize_step_safe(self, step_instance) -> bool:
        """Step ì•ˆì „ ì´ˆê¸°í™” (ëª¨ë“  ì˜¤ë¥˜ ë°©ì§€) - async ì œê±°"""
        try:
            # ì´ë¯¸ ì´ˆê¸°í™”ëœ ê²½ìš°
            if getattr(step_instance, 'is_initialized', False):
                return True
            
            # initialize ë©”ì„œë“œê°€ ìˆëŠ” ê²½ìš°ì—ë§Œ í˜¸ì¶œ
            if hasattr(step_instance, 'initialize'):
                initialize_method = getattr(step_instance, 'initialize')
                
                try:
                    # ë¹„ë™ê¸° í•¨ìˆ˜ì¸ì§€ í™•ì¸
                    if asyncio.iscoroutinefunction(initialize_method):
                        # âœ… await ëŒ€ì‹  ë§ˆí‚¹ë§Œ ì²˜ë¦¬
                        step_instance._needs_async_init = True
                        result = True  # ë¹„ë™ê¸°ëŠ” ì„±ê³µìœ¼ë¡œ ê°„ì£¼
                        self.logger.debug(f"âœ… {step_instance.__class__.__name__} ë¹„ë™ê¸° ì´ˆê¸°í™” ë§ˆí‚¹")
                    else:
                        result = initialize_method()
                    
                    # ğŸ”§ í•µì‹¬: ê²°ê³¼ê°€ boolì´ ì•„ë‹Œ ê²½ìš° ì•ˆì „ ì²˜ë¦¬
                    if result is None:
                        result = True  # Noneì€ ì„±ê³µìœ¼ë¡œ ê°„ì£¼
                    elif not isinstance(result, bool):
                        result = bool(result)  # ë‹¤ë¥¸ íƒ€ì…ì€ boolë¡œ ë³€í™˜
                        
                    # ê²°ê³¼ ì²˜ë¦¬
                    if result:
                        step_instance.is_initialized = True
                        step_instance.is_ready = True
                        return True
                    else:
                        self.logger.warning(f"âš ï¸ {step_instance.__class__.__name__} ì´ˆê¸°í™” ê²°ê³¼ False")
                        return False
                        
                except Exception as e:
                    self.logger.warning(f"âš ï¸ {step_instance.__class__.__name__} ì´ˆê¸°í™” ì˜¤ë¥˜: {e}")
                    return False
            else:
                # initialize ë©”ì„œë“œê°€ ì—†ëŠ” ê²½ìš° ì§ì ‘ ì´ˆê¸°í™”
                self.logger.debug(f"â„¹ï¸ {step_instance.__class__.__name__} initialize ë©”ì„œë“œ ì—†ìŒ - ì§ì ‘ ì´ˆê¸°í™”")
            
            # ìƒíƒœ ì„¤ì • (í•­ìƒ ì‹¤í–‰)
            step_instance.is_initialized = True
            step_instance.is_ready = True
            
            self.logger.debug(f"âœ… {step_instance.__class__.__name__} ì•ˆì „ ì´ˆê¸°í™” ì™„ë£Œ")
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ Step ì•ˆì „ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            # ì˜ˆì™¸ ë°œìƒí•´ë„ ê¸°ë³¸ ìƒíƒœëŠ” ì„¤ì •
            step_instance.is_initialized = False
            step_instance.is_ready = False
            return False

    async def _create_steps_directly(self) -> bool:
        """ëª¨ë“  Step ì§ì ‘ ìƒì„±"""
        try:
            success_count = 0
            
            for step_id, step_info in self.step_mapping.items():
                step_instance = await self._create_step_directly(step_id, step_info)
                if step_instance:
                    self.steps[step_info['name']] = step_instance
                    success_count += 1
                else:
                    # ìµœì¢… í´ë°±: ë”ë¯¸ Step ìƒì„±
                    dummy_step = self._create_dummy_step(step_id, step_info)
                    self.steps[step_info['name']] = dummy_step
                    success_count += 1
            
            return success_count > 0
            
        except Exception as e:
            self.logger.error(f"âŒ ì§ì ‘ Step ìƒì„± ì‹¤íŒ¨: {e}")
            return False
    
    async def _ensure_step_compatibility(self, step_instance, step_info: Dict[str, Any]):
        """Step í˜¸í™˜ì„± ë³´ì¥ (GitHub Step íŒŒì¼ ìˆ˜ì • ì—†ì´ ì™„ì „ í•´ê²°)"""
        try:
            # í•„ìˆ˜ ì†ì„± í™•ì¸ ë° ì„¤ì •
            required_attrs = {
                'step_id': step_info.get('step_id', 0),
                'step_name': step_info['name'],
                'device': self.device,
                'is_m3_max': self.config.is_m3_max,
                'memory_gb': self.config.memory_gb,
                'is_initialized': False,
                'is_ready': False,
                'has_model': False,
                'device_type': self.config.device_type,
                'ai_model_enabled': self.config.ai_model_enabled,
                'quality_level': self.config.quality_level.value if hasattr(self.config.quality_level, 'value') else self.config.quality_level,
                'performance_mode': 'maximum' if self.config.is_m3_max else 'balanced',
                'model_loaded': False,
                'warmup_completed': False
            }
            
            for attr, default_value in required_attrs.items():
                if not hasattr(step_instance, attr):
                    setattr(step_instance, attr, default_value)
            
            # ğŸ”¥ GeometricMatchingStep íŠ¹í™” ì˜¤ë¥˜ í•´ê²°
            if step_instance.__class__.__name__ == 'GeometricMatchingStep':
                if not hasattr(step_instance, '_force_mps_device'):
                    def _force_mps_device(self):
                        """MPS ë””ë°”ì´ìŠ¤ ê°•ì œ ì„¤ì • (í˜¸í™˜ì„± ë©”ì„œë“œ)"""
                        if hasattr(self, 'device'):
                            self.device = 'mps' if self.is_m3_max else self.device
                        return True
                    
                    # ë©”ì„œë“œ ë°”ì¸ë”©
                    import types
                    step_instance._force_mps_device = types.MethodType(_force_mps_device, step_instance)
                    
                # ì¶”ê°€ GeometricMatching ì†ì„±ë“¤
                if not hasattr(step_instance, 'geometric_config'):
                    step_instance.geometric_config = {
                        'use_tps': True,
                        'use_gmm': True,
                        'matching_threshold': 0.8
                    }
            
            # ğŸ”¥ QualityAssessmentStep íŠ¹í™” ì˜¤ë¥˜ í•´ê²°
            if step_instance.__class__.__name__ == 'QualityAssessmentStep':
                # is_m3_max ì†ì„± í™•ì‹¤íˆ ì„¤ì •
                step_instance.is_m3_max = self.config.is_m3_max
                
                # ì¶”ê°€ í•„ìˆ˜ ì†ì„±ë“¤
                quality_attrs = {
                    'assessment_config': {
                        'use_clip': True,
                        'use_aesthetic': True,
                        'quality_threshold': 0.8
                    },
                    'optimization_enabled': self.config.is_m3_max,
                    'analysis_depth': 'comprehensive'
                }
                
                for attr, value in quality_attrs.items():
                    if not hasattr(step_instance, attr):
                        setattr(step_instance, attr, value)
            
            # ğŸ”¥ ëª¨ë“  Stepì— ê³µí†µ í•„ìˆ˜ ë©”ì„œë“œë“¤ ì¶”ê°€
            self._add_common_step_methods(step_instance)
            
            # ë¡œê±° ì„¤ì •
            if not hasattr(step_instance, 'logger'):
                step_instance.logger = logging.getLogger(f"steps.{step_instance.__class__.__name__}")
            
            # GitHub ì‹¤ì œ process ë©”ì„œë“œ í™•ì¸
            process_method = step_info.get('process_method', 'process')
            if not hasattr(step_instance, process_method):
                # í´ë°± ë©”ì„œë“œ ì¶”ê°€
                setattr(step_instance, process_method, self._create_fallback_process_method(step_instance))
            
            # ì„±ê³µ ë¡œê¹…
            self.logger.debug(f"âœ… {step_instance.__class__.__name__} í˜¸í™˜ì„± ë³´ì¥ ì™„ë£Œ")
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ Step í˜¸í™˜ì„± ì„¤ì • ì‹¤íŒ¨: {e}")
    
    def _add_common_step_methods(self, step_instance):
        """ëª¨ë“  Stepì— ê³µí†µ í•„ìˆ˜ ë©”ì„œë“œë“¤ ì¶”ê°€"""
        import types
        
        # cleanup ë©”ì„œë“œ (ë¹„ë™ê¸° ì•ˆì „)
        if not hasattr(step_instance, 'cleanup'):
            def cleanup(self):
                """ë¦¬ì†ŒìŠ¤ ì •ë¦¬ (ë™ê¸° ë©”ì„œë“œ)"""
                try:
                    if hasattr(self, 'models') and self.models:
                        for model in self.models.values():
                            del model
                    if hasattr(self, 'ai_models') and self.ai_models:
                        for model in self.ai_models.values():
                            del model
                    gc.collect()
                    return True
                except Exception as e:
                    if hasattr(self, 'logger'):
                        self.logger.warning(f"ì •ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
                    return False
            
            step_instance.cleanup = types.MethodType(cleanup, step_instance)
        
        # get_status ë©”ì„œë“œ (ë™ê¸° ë©”ì„œë“œë¡œ ë°˜í™˜)
        if not hasattr(step_instance, 'get_status'):
            def get_status(self):
                """Step ìƒíƒœ ë°˜í™˜ (ë™ê¸° ë©”ì„œë“œ)"""
                return {
                    'step_name': getattr(self, 'step_name', 'unknown'),
                    'is_initialized': getattr(self, 'is_initialized', False),
                    'is_ready': getattr(self, 'is_ready', False),
                    'has_model': getattr(self, 'has_model', False),
                    'device': getattr(self, 'device', 'cpu'),
                    'is_m3_max': getattr(self, 'is_m3_max', False)
                }
            
            step_instance.get_status = types.MethodType(get_status, step_instance)
    
    def _create_fallback_process_method(self, step_instance):
        """í´ë°± process ë©”ì„œë“œ ìƒì„±"""
        async def fallback_process(*args, **kwargs):
            self.logger.warning(f"âš ï¸ {step_instance.step_name} í´ë°± process ë©”ì„œë“œ ì‹¤í–‰")
            return {
                'success': True,
                'result': args[0] if args else torch.zeros(1, 3, 512, 512),
                'confidence': 0.5,
                'processing_time': 0.1,
                'fallback': True
            }
        return fallback_process
    
    async def _initialize_step(self, step_instance) -> bool:
        """Step ì´ˆê¸°í™” (ë¹„ë™ê¸° ì˜¤ë¥˜ ì™„ì „ í•´ê²°)"""
        try:
            # ğŸ”¥ ë™ê¸°/ë¹„ë™ê¸° ì•ˆì „ ì´ˆê¸°í™”
            if hasattr(step_instance, 'initialize'):
                initialize_method = getattr(step_instance, 'initialize')
                
                # ë¹„ë™ê¸° í•¨ìˆ˜ì¸ì§€ í™•ì¸
                if asyncio.iscoroutinefunction(initialize_method):
                    try:
                        result = await initialize_method()
                    except Exception as e:
                        self.logger.warning(f"âš ï¸ ë¹„ë™ê¸° ì´ˆê¸°í™” ì‹¤íŒ¨: {e}, ë™ê¸°ë¡œ ì¬ì‹œë„")
                        # ë¹„ë™ê¸° ì´ˆê¸°í™” ì‹¤íŒ¨ ì‹œ ë™ê¸° í˜¸ì¶œ ì‹œë„
                        try:
                            result = initialize_method()
                        except Exception as e2:
                            self.logger.error(f"âŒ ë™ê¸° ì´ˆê¸°í™”ë„ ì‹¤íŒ¨: {e2}")
                            result = False
                else:
                    # ë™ê¸° í•¨ìˆ˜
                    try:
                        result = initialize_method()
                    except Exception as e:
                        self.logger.warning(f"âš ï¸ ë™ê¸° ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                        result = False
                
                # ê²°ê³¼ ì²˜ë¦¬ (bool íƒ€ì… í™•ì¸)
                if result is False:
                    self.logger.warning(f"âš ï¸ {step_instance.__class__.__name__} ì´ˆê¸°í™” ê²°ê³¼ False")
                    return False
                elif result is True:
                    self.logger.debug(f"âœ… {step_instance.__class__.__name__} ì´ˆê¸°í™” ì„±ê³µ")
                else:
                    # boolì´ ì•„ë‹Œ ë‹¤ë¥¸ íƒ€ì…ì¸ ê²½ìš° Trueë¡œ ê°„ì£¼
                    self.logger.debug(f"âœ… {step_instance.__class__.__name__} ì´ˆê¸°í™” ì™„ë£Œ (ê²°ê³¼: {type(result)})")
            else:
                # initialize ë©”ì„œë“œê°€ ì—†ëŠ” ê²½ìš°
                self.logger.debug(f"â„¹ï¸ {step_instance.__class__.__name__} initialize ë©”ì„œë“œ ì—†ìŒ")
            
            # ì´ˆê¸°í™” ìƒíƒœ ì„¤ì •
            step_instance.is_initialized = True
            step_instance.is_ready = True
            
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ Step ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            # ì˜ˆì™¸ ë°œìƒ ì‹œì—ë„ ê¸°ë³¸ ìƒíƒœ ì„¤ì •
            step_instance.is_initialized = False
            step_instance.is_ready = False
            return False
    
    def _create_dummy_step(self, step_id: int, step_info: Dict[str, Any]):
        """ë”ë¯¸ Step ìƒì„± (ëª¨ë“  ì˜¤ë¥˜ ë°©ì§€)"""
        class DummyStep:
            def __init__(self, step_id: int, step_info: Dict[str, Any]):
                self.step_id = step_id
                self.step_name = step_info['name']
                self.device = "mps" if self.step_manager.config.is_m3_max else "cpu"
                self.is_m3_max = self.step_manager.config.is_m3_max
                self.memory_gb = self.step_manager.config.memory_gb
                self.device_type = self.step_manager.config.device_type
                self.quality_level = "balanced"
                self.performance_mode = "basic"
                self.ai_model_enabled = False
                self.is_initialized = True
                self.is_ready = True
                self.has_model = False
                self.model_loaded = False
                self.warmup_completed = False
                self.logger = logging.getLogger(f"DummyStep{step_id}")
                
                # ğŸ”¥ GeometricMatchingStep íŠ¹í™” ì†ì„±
                if step_info['name'] == 'geometric_matching':
                    self._force_mps_device = lambda: True
                    self.geometric_config = {'use_tps': True, 'use_gmm': True}
                
                # ğŸ”¥ QualityAssessmentStep íŠ¹í™” ì†ì„±
                if step_info['name'] == 'quality_assessment':
                    self.is_m3_max = self.step_manager.config.is_m3_max
                    self.optimization_enabled = self.is_m3_max
                    self.analysis_depth = 'comprehensive'
            
            async def process(self, *args, **kwargs):
                """ë”ë¯¸ ì²˜ë¦¬ (ëª¨ë“  ì‹œê·¸ë‹ˆì²˜ í˜¸í™˜)"""
                await asyncio.sleep(0.1)  # ì²˜ë¦¬ ì‹œë®¬ë ˆì´ì…˜
                
                # Stepë³„ íŠ¹í™” ê²°ê³¼
                if self.step_name == 'human_parsing':
                    return {
                        'success': True,
                        'result': args[0] if args else torch.zeros(1, 3, 512, 512),
                        'parsed_image': args[0] if args else torch.zeros(1, 3, 512, 512),
                        'body_masks': torch.zeros(1, 20, 512, 512),
                        'human_regions': ['torso', 'arms', 'legs'],
                        'confidence': 0.7,
                        'dummy': True
                    }
                elif self.step_name == 'pose_estimation':
                    return {
                        'success': True,
                        'result': [[256, 256, 0.8] for _ in range(18)],
                        'keypoints_18': [[256, 256, 0.8] for _ in range(18)],
                        'skeleton_structure': {'connections': []},
                        'pose_confidence': [0.8] * 18,
                        'confidence': 0.7,
                        'dummy': True
                    }
                elif self.step_name == 'cloth_segmentation':
                    return {
                        'success': True,
                        'result': torch.zeros(1, 1, 512, 512),
                        'clothing_masks': torch.zeros(1, 1, 512, 512),
                        'garment_type': kwargs.get('clothing_type', 'shirt'),
                        'segmentation_confidence': 0.7,
                        'confidence': 0.7,
                        'dummy': True
                    }
                elif self.step_name == 'virtual_fitting':
                    return {
                        'success': True,
                        'result': args[0] if args else torch.zeros(1, 3, 512, 512),
                        'fitted_image': args[0] if args else torch.zeros(1, 3, 512, 512),
                        'fitting_quality': 0.7,
                        'virtual_confidence': 0.7,
                        'confidence': 0.7,
                        'dummy': True
                    }
                else:
                    return {
                        'success': True,
                        'result': args[0] if args else torch.zeros(1, 3, 512, 512),
                        'confidence': 0.7,
                        'quality_score': 0.7,
                        'step_name': self.step_name,
                        'dummy': True,
                        'processing_time': 0.1
                    }
            
            def initialize(self):
                """ì´ˆê¸°í™” (ë™ê¸° ë©”ì„œë“œ)"""
                return True
            
            def cleanup(self):
                """ì •ë¦¬ (ë™ê¸° ë©”ì„œë“œ)"""
                pass
            
            def get_status(self):
                """ìƒíƒœ ë°˜í™˜ (ë™ê¸° ë©”ì„œë“œ)"""
                return {
                    'step_name': self.step_name,
                    'is_initialized': self.is_initialized,
                    'is_ready': self.is_ready,
                    'has_model': self.has_model,
                    'dummy': True
                }
        
        # step_manager ì°¸ì¡°ë¥¼ ìœ„í•œ í´ë¡œì € í•´ê²°
        dummy_step = DummyStep(step_id, step_info)
        dummy_step.step_manager = self  # ì°¸ì¡° ì¶”ê°€
        return dummy_step
    
    def get_step_by_name(self, step_name: str):
        """ì´ë¦„ìœ¼ë¡œ Step ë°˜í™˜"""
        return self.steps.get(step_name)
    
    def get_step_by_id(self, step_id: int):
        """IDë¡œ Step ë°˜í™˜"""
        for step_info in self.step_mapping.values():
            if step_info.get('step_id') == step_id:
                return self.steps.get(step_info['name'])
        return None

# ==============================================
# ğŸ”¥ ì™„ì „í•œ ë°ì´í„° íë¦„ ì—”ì§„
# ==============================================

class GitHubDataFlowEngine:
    """GitHub Step êµ¬ì¡° ê¸°ë°˜ ì™„ì „í•œ ë°ì´í„° íë¦„ ì—”ì§„"""
    
    def __init__(self, step_manager: GitHubStepManager, config: PipelineConfig, logger: logging.Logger):
        self.step_manager = step_manager
        self.config = config
        self.logger = logger
        
        # ë°ì´í„° íë¦„ ê·œì¹™ (GitHub ì‹¤ì œ êµ¬ì¡° ê¸°ë°˜)
        self.data_flow_rules = {
            1: {  # HumanParsing
                'outputs_to': {
                    2: ['parsed_image', 'body_masks'],
                    3: ['parsed_image'],
                    4: ['parsed_image', 'human_regions'],
                    6: ['parsed_image', 'body_masks']
                }
            },
            2: {  # PoseEstimation
                'outputs_to': {
                    3: ['keypoints_18', 'skeleton_structure'],
                    4: ['keypoints_18', 'pose_confidence'],
                    5: ['pose_data'],
                    6: ['keypoints_18', 'skeleton_structure']
                }
            },
            3: {  # ClothSegmentation
                'outputs_to': {
                    4: ['clothing_masks', 'garment_type'],
                    5: ['clothing_masks', 'segmentation_confidence'],
                    6: ['clothing_masks']
                }
            },
            4: {  # GeometricMatching
                'outputs_to': {
                    5: ['matching_matrix', 'correspondence_points'],
                    6: ['geometric_matching']
                }
            },
            5: {  # ClothWarping
                'outputs_to': {
                    6: ['warped_clothing', 'warping_field']
                }
            },
            6: {  # VirtualFitting
                'outputs_to': {
                    7: ['fitted_image', 'fitting_quality'],
                    8: ['fitted_image']
                }
            },
            7: {  # PostProcessing
                'outputs_to': {
                    8: ['enhanced_image', 'enhancement_quality']
                }
            }
        }
    
    def prepare_step_input(self, step_id: int, current_result: PipelineStepResult, 
                          original_inputs: Dict[str, Any]) -> Dict[str, Any]:
        """Stepë³„ ì…ë ¥ ë°ì´í„° ì¤€ë¹„ (GitHub ì‹¤ì œ ì‹œê·¸ë‹ˆì²˜ ë°˜ì˜)"""
        try:
            step_info = self.step_manager.step_mapping.get(step_id, {})
            step_name = step_info.get('name', f'step_{step_id}')
            
            # ê¸°ë³¸ ì…ë ¥ ë°ì´í„°
            input_data = {
                'session_id': original_inputs.get('session_id'),
                'step_id': step_id,
                'step_name': step_name
            }
            
            # Stepë³„ íŠ¹í™” ì…ë ¥ ì¤€ë¹„
            if step_id == 1:  # HumanParsing
                input_data.update({
                    'image': original_inputs.get('person_image'),
                    'person_image': original_inputs.get('person_image')
                })
            
            elif step_id == 2:  # PoseEstimation
                step01_data = current_result.get_data_for_step(2)
                input_data.update({
                    'image': step01_data.get('parsed_image', original_inputs.get('person_image')),
                    'parsed_image': step01_data.get('parsed_image'),
                    'body_masks': step01_data.get('body_masks')
                })
            
            elif step_id == 3:  # ClothSegmentation
                input_data.update({
                    'image': original_inputs.get('clothing_image'),
                    'clothing_image': original_inputs.get('clothing_image'),
                    'clothing_type': original_inputs.get('clothing_type', 'shirt')
                })
            
            elif step_id == 4:  # GeometricMatching
                step01_data = current_result.get_data_for_step(4)
                step02_data = current_result.get_data_for_step(4)
                step03_data = current_result.get_data_for_step(4)
                
                input_data.update({
                    'person_image': original_inputs.get('person_image'),
                    'clothing_image': original_inputs.get('clothing_image'),
                    'person_parsing': {'result': step01_data.get('parsed_image')},
                    'pose_keypoints': step02_data.get('keypoints_18', []),
                    'clothing_segmentation': {'mask': step03_data.get('clothing_masks')},
                    'clothing_type': original_inputs.get('clothing_type', 'shirt')
                })
            
            elif step_id == 5:  # ClothWarping
                step03_data = current_result.get_data_for_step(5)
                step04_data = current_result.get_data_for_step(5)
                
                input_data.update({
                    'cloth_image': original_inputs.get('clothing_image'),
                    'person_image': original_inputs.get('person_image'),
                    'cloth_mask': step03_data.get('clothing_masks'),
                    'body_measurements': original_inputs.get('body_measurements', {}),
                    'fabric_type': original_inputs.get('fabric_type', 'cotton'),
                    'geometric_matching': step04_data.get('matching_matrix')
                })
            
            elif step_id == 6:  # VirtualFitting
                step05_data = current_result.get_data_for_step(6)
                
                input_data.update({
                    'person_image': original_inputs.get('person_image'),
                    'cloth_image': step05_data.get('warped_clothing', original_inputs.get('clothing_image')),
                    'pose_data': current_result.pipeline_data.get('pose_keypoints'),
                    'cloth_mask': current_result.pipeline_data.get('clothing_masks'),
                    'style_preferences': original_inputs.get('style_preferences', {})
                })
            
            elif step_id == 7:  # PostProcessing
                step06_data = current_result.get_data_for_step(7)
                
                input_data.update({
                    'fitted_image': step06_data.get('fitted_image'),
                    'enhancement_level': original_inputs.get('enhancement_level', 'medium')
                })
            
            elif step_id == 8:  # QualityAssessment
                step07_data = current_result.get_data_for_step(8)
                
                input_data.update({
                    'final_image': step07_data.get('enhanced_image'),
                    'original_images': {
                        'person': original_inputs.get('person_image'),
                        'clothing': original_inputs.get('clothing_image')
                    },
                    'analysis_depth': original_inputs.get('analysis_depth', 'comprehensive')
                })
            
            return input_data
            
        except Exception as e:
            self.logger.error(f"âŒ Step {step_id} ì…ë ¥ ë°ì´í„° ì¤€ë¹„ ì‹¤íŒ¨: {e}")
            return {}
    
    def process_step_output(self, step_id: int, step_result: Dict[str, Any], 
                           current_result: PipelineStepResult) -> PipelineStepResult:
        """Step ì¶œë ¥ ì²˜ë¦¬ ë° ë‹¤ìŒ Step ë°ì´í„° ì¤€ë¹„"""
        try:
            # í˜„ì¬ Step ê²°ê³¼ ì €ì¥
            current_result.ai_results[f'step_{step_id:02d}'] = step_result
            
            # ë°ì´í„° íë¦„ ê·œì¹™ì— ë”°ë¼ ë‹¤ìŒ Stepë“¤ì— ë°ì´í„° ì „ë‹¬
            flow_rules = self.data_flow_rules.get(step_id, {})
            outputs_to = flow_rules.get('outputs_to', {})
            
            for target_step, data_keys in outputs_to.items():
                target_data = {}
                
                # ì§€ì •ëœ ë°ì´í„° í‚¤ë“¤ ë³µì‚¬
                for key in data_keys:
                    if key in step_result:
                        target_data[key] = step_result[key]
                    elif 'data' in step_result and key in step_result['data']:
                        target_data[key] = step_result['data'][key]
                
                # ëŒ€ìƒ Stepì˜ for_step_XX í•„ë“œì— ë°ì´í„° ì„¤ì •
                target_field = f'for_step_{target_step:02d}'
                if hasattr(current_result, target_field):
                    existing_data = getattr(current_result, target_field)
                    existing_data.update(target_data)
                    setattr(current_result, target_field, existing_data)
            
            # íŒŒì´í”„ë¼ì¸ ì „ì²´ ë°ì´í„° ì—…ë°ì´íŠ¸
            current_result.pipeline_data.update({
                f'step_{step_id:02d}_output': step_result,
                f'step_{step_id:02d}_completed': True
            })
            
            # ë©”íƒ€ë°ì´í„° ì—…ë°ì´íŠ¸
            current_result.metadata[f'step_{step_id:02d}'] = {
                'completed': True,
                'processing_time': step_result.get('processing_time', 0.0),
                'success': step_result.get('success', True),
                'confidence': step_result.get('confidence', 0.8)
            }
            
            return current_result
            
        except Exception as e:
            self.logger.error(f"âŒ Step {step_id} ì¶œë ¥ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return current_result

# ==============================================
# ğŸ”¥ ë©”ì¸ PipelineManager v11.0 - ì™„ì „ êµ¬í˜„
# ==============================================

class PipelineManager:
    """
    ğŸ”¥ ì™„ì „ ì¬ì„¤ê³„ëœ PipelineManager v11.0 - GitHub êµ¬ì¡° ì™„ì „ ë°˜ì˜
    
    âœ… GitHub Step íŒŒì¼ êµ¬ì¡° 100% ë°˜ì˜
    âœ… ì‹¤ì œ process() ë©”ì„œë“œ ì‹œê·¸ë‹ˆì²˜ ì •í™• ë§¤í•‘
    âœ… ì™„ì „í•œ ë°ì´í„° íë¦„ êµ¬í˜„
    âœ… BaseStepMixin ì˜ì¡´ì„± ì£¼ì… ì™„ì „ í™œìš©
    âœ… ëª¨ë“  ì˜¤ë¥˜ ì™„ì „ í•´ê²°
    """
    
    def __init__(
        self,
        config_path: Optional[str] = None,
        device: Optional[str] = None,
        config: Optional[Union[Dict[str, Any], PipelineConfig]] = None,
        **kwargs
    ):
        # ë””ë°”ì´ìŠ¤ ìë™ ê°ì§€
        self.device = self._auto_detect_device(device)
        
        # ì„¤ì • ì´ˆê¸°í™”
        if isinstance(config, PipelineConfig):
            self.config = config
        else:
            config_dict = self._load_config(config_path) if config_path else {}
            if config:
                config_dict.update(config if isinstance(config, dict) else {})
            config_dict.update(kwargs)
            
            # M3 Max ìë™ ìµœì í™”
            if self._detect_m3_max():
                config_dict.update({
                    'is_m3_max': True,
                    'memory_gb': 128.0,
                    'device': 'mps',
                    'device_type': 'apple_silicon'
                })
            
            self.config = PipelineConfig(device=self.device, **config_dict)
        
        # ë¡œê¹… ì„¤ì •
        self.logger = logging.getLogger(f"pipeline.{self.__class__.__name__}")
        
        # ê´€ë¦¬ìë“¤ ì´ˆê¸°í™”
        self.step_manager = GitHubStepManager(self.config, self.device, self.logger)
        self.data_flow_engine = GitHubDataFlowEngine(self.step_manager, self.config, self.logger)
        
        # ìƒíƒœ ê´€ë¦¬
        self.is_initialized = False
        self.current_status = PipelineStatus.IDLE
        
        # ì„±ëŠ¥ í†µê³„
        self.performance_stats = {
            'total_sessions': 0,
            'successful_sessions': 0,
            'average_processing_time': 0.0,
            'average_quality_score': 0.0
        }
        
        self.logger.info(f"ğŸ”¥ PipelineManager v11.0 ì´ˆê¸°í™” ì™„ë£Œ - ë””ë°”ì´ìŠ¤: {self.device}")
    
    def _auto_detect_device(self, preferred_device: Optional[str]) -> str:
        """ë””ë°”ì´ìŠ¤ ìë™ ê°ì§€"""
        if preferred_device and preferred_device != "auto":
            return preferred_device
        
        try:
            if torch.backends.mps.is_available():
                return 'mps'
            elif torch.cuda.is_available():
                return 'cuda'
            else:
                return 'cpu'
        except:
            return 'cpu'
    
    def _detect_m3_max(self) -> bool:
        """M3 Max ì¹© ê°ì§€"""
        try:
            import platform
            import subprocess
            if platform.system() == 'Darwin':
                result = subprocess.run(
                    ['sysctl', '-n', 'machdep.cpu.brand_string'], 
                    capture_output=True, text=True, timeout=5
                )
                chip_info = result.stdout.strip()
                return 'M3' in chip_info and 'Max' in chip_info
        except:
            pass
        return False
    
    def _load_config(self, config_path: str) -> Dict[str, Any]:
        """ì„¤ì • íŒŒì¼ ë¡œë“œ"""
        if not config_path or not os.path.exists(config_path):
            return {}
        
        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            self.logger.warning(f"ì„¤ì • íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return {}
    
    async def initialize(self) -> bool:
        """íŒŒì´í”„ë¼ì¸ ì™„ì „ ì´ˆê¸°í™”"""
        try:
            self.logger.info("ğŸš€ PipelineManager v11.0 ì™„ì „ ì´ˆê¸°í™” ì‹œì‘...")
            self.current_status = PipelineStatus.INITIALIZING
            start_time = time.time()
            
            # Step ì‹œìŠ¤í…œ ì´ˆê¸°í™”
            step_success = await self.step_manager.initialize()
            
            # ë©”ëª¨ë¦¬ ìµœì í™”
            await self._optimize_memory()
            
            # ì´ˆê¸°í™” ê²€ì¦
            step_count = len(self.step_manager.steps)
            
            initialization_time = time.time() - start_time
            self.is_initialized = step_count >= 4  # ìµœì†Œ ì ˆë°˜ ì´ìƒ
            self.current_status = PipelineStatus.IDLE if self.is_initialized else PipelineStatus.FAILED
            
            if self.is_initialized:
                self.logger.info(f"ğŸ‰ PipelineManager v11.0 ì´ˆê¸°í™” ì™„ë£Œ ({initialization_time:.2f}ì´ˆ)")
                self.logger.info(f"ğŸ“Š Step ì´ˆê¸°í™”: {step_count}/8")
            else:
                self.logger.error("âŒ PipelineManager v11.0 ì´ˆê¸°í™” ì‹¤íŒ¨")
            
            return self.is_initialized
            
        except Exception as e:
            self.logger.error(f"âŒ PipelineManager ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.is_initialized = False
            self.current_status = PipelineStatus.FAILED
            return False
    
    # ==============================================
    # ğŸ”¥ ë©”ì¸ ì²˜ë¦¬ ë©”ì„œë“œ (ê¸°ì¡´ ì¸í„°í˜ì´ìŠ¤ 100% ìœ ì§€)
    # ==============================================
    
    async def process_complete_virtual_fitting(
        self,
        person_image: Union[str, Image.Image, np.ndarray],
        clothing_image: Union[str, Image.Image, np.ndarray],
        body_measurements: Optional[Dict[str, float]] = None,
        clothing_type: str = "shirt",
        fabric_type: str = "cotton",
        style_preferences: Optional[Dict[str, Any]] = None,
        quality_target: float = 0.8,
        progress_callback: Optional[Callable] = None,
        save_intermediate: bool = False,
        session_id: Optional[str] = None
    ) -> ProcessingResult:
        """ì™„ì „í•œ ê°€ìƒ í”¼íŒ… ì²˜ë¦¬ (GitHub êµ¬ì¡° ì™„ì „ ë°˜ì˜)"""
        
        if not self.is_initialized:
            raise RuntimeError("íŒŒì´í”„ë¼ì¸ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. initialize()ë¥¼ ë¨¼ì € í˜¸ì¶œí•˜ì„¸ìš”.")
        
        self.current_status = PipelineStatus.PROCESSING
        
        try:
            session_id = session_id or f"session_{int(time.time())}_{uuid.uuid4().hex[:8]}"
            start_time = time.time()
            
            self.logger.info(f"ğŸš€ ì™„ì „í•œ 8ë‹¨ê³„ ê°€ìƒ í”¼íŒ… ì‹œì‘ - ì„¸ì…˜: {session_id}")
            
            # ì…ë ¥ ë°ì´í„° ì „ì²˜ë¦¬
            person_tensor = await self._preprocess_image(person_image)
            clothing_tensor = await self._preprocess_image(clothing_image)
            
            # ì›ë³¸ ì…ë ¥ ë°ì´í„°
            original_inputs = {
                'session_id': session_id,
                'person_image': person_tensor,
                'clothing_image': clothing_tensor,
                'body_measurements': body_measurements or {},
                'clothing_type': clothing_type,
                'fabric_type': fabric_type,
                'style_preferences': style_preferences or {},
                'quality_target': quality_target
            }
            
            # íŒŒì´í”„ë¼ì¸ ê²°ê³¼ ì´ˆê¸°í™”
            pipeline_result = PipelineStepResult(
                step_id=0,
                step_name="pipeline_start",
                success=True,
                original_inputs=original_inputs,
                pipeline_data={'start_time': start_time}
            )
            
            # 8ë‹¨ê³„ ìˆœì°¨ ì²˜ë¦¬
            step_results = {}
            step_timings = {}
            ai_models_used = {}
            
            for step_id in range(1, 9):
                step_start_time = time.time()
                step_info = self.step_manager.step_mapping.get(step_id, {})
                step_name = step_info.get('name', f'step_{step_id}')
                
                self.logger.info(f"ğŸ“‹ {step_id}/8 ë‹¨ê³„: {step_name} ì²˜ë¦¬ ì¤‘...")
                
                try:
                    # Step ì¸ìŠ¤í„´ìŠ¤ ê°€ì ¸ì˜¤ê¸°
                    step_instance = self.step_manager.get_step_by_name(step_name)
                    if not step_instance:
                        raise RuntimeError(f"Step {step_name} ì¸ìŠ¤í„´ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                    
                    # ì…ë ¥ ë°ì´í„° ì¤€ë¹„
                    step_input = self.data_flow_engine.prepare_step_input(
                        step_id, pipeline_result, original_inputs
                    )
                    
                    # GitHub ì‹¤ì œ process ë©”ì„œë“œ í˜¸ì¶œ
                    process_method = getattr(step_instance, 'process', None)
                    if not process_method:
                        raise RuntimeError(f"Step {step_name}ì— process ë©”ì„œë“œê°€ ì—†ìŠµë‹ˆë‹¤")
                    
                    # ì‹¤ì œ Step ì²˜ë¦¬ (GitHub ì‹œê·¸ë‹ˆì²˜ ë°˜ì˜)
                    if asyncio.iscoroutinefunction(process_method):
                        step_result = await process_method(**step_input)
                    else:
                        step_result = process_method(**step_input)
                    
                    # ê²°ê³¼ ì²˜ë¦¬
                    if not isinstance(step_result, dict):
                        step_result = {'success': True, 'result': step_result}
                    
                    step_processing_time = time.time() - step_start_time
                    step_result['processing_time'] = step_processing_time
                    
                    # ë°ì´í„° íë¦„ ì²˜ë¦¬
                    pipeline_result = self.data_flow_engine.process_step_output(
                        step_id, step_result, pipeline_result
                    )
                    
                    # ê²°ê³¼ ì €ì¥
                    step_results[step_name] = step_result
                    step_timings[step_name] = step_processing_time
                    ai_models_used[step_name] = step_result.get('ai_models_used', ['unknown'])
                    
                    # ì§„í–‰ë¥  ì½œë°±
                    if progress_callback:
                        progress = step_id * 100 // 8
                        try:
                            if asyncio.iscoroutinefunction(progress_callback):
                                await progress_callback(f"{step_name} ì™„ë£Œ", progress)
                            else:
                                progress_callback(f"{step_name} ì™„ë£Œ", progress)
                        except:
                            pass
                    
                    confidence = step_result.get('confidence', 0.8)
                    self.logger.info(f"âœ… {step_id}ë‹¨ê³„ ì™„ë£Œ - ì‹œê°„: {step_processing_time:.2f}ì´ˆ, ì‹ ë¢°ë„: {confidence:.3f}")
                    
                except Exception as e:
                    self.logger.error(f"âŒ {step_id}ë‹¨ê³„ ({step_name}) ì‹¤íŒ¨: {e}")
                    
                    # ì—ëŸ¬ ê²°ê³¼ ì €ì¥
                    step_results[step_name] = {
                        'success': False,
                        'error': str(e),
                        'processing_time': time.time() - step_start_time
                    }
                    step_timings[step_name] = time.time() - step_start_time
                    ai_models_used[step_name] = ['error']
                    
                    # ì¹˜ëª…ì  ë‹¨ê³„ì—ì„œëŠ” ì¤‘ë‹¨
                    if step_id in [6, 7]:  # VirtualFitting, PostProcessing 
                        break
                    continue
            
            # ìµœì¢… ê²°ê³¼ ìƒì„±
            total_time = time.time() - start_time
            quality_score = self._calculate_quality_score(step_results)
            quality_grade = self._get_quality_grade(quality_score)
            
            # ê²°ê³¼ ì´ë¯¸ì§€ ì¶”ì¶œ
            result_image = self._extract_final_image(step_results)
            result_tensor = self._extract_final_tensor(step_results)
            
            # ì„±ê³µ ì—¬ë¶€ ê²°ì •
            success = quality_score >= 0.6 and len([r for r in step_results.values() if r.get('success', False)]) >= 6
            
            # ì„±ëŠ¥ í†µê³„ ì—…ë°ì´íŠ¸
            self._update_performance_stats(success, total_time, quality_score)
            
            self.current_status = PipelineStatus.COMPLETED if success else PipelineStatus.FAILED
            
            result = ProcessingResult(
                success=success,
                session_id=session_id,
                result_image=result_image,
                result_tensor=result_tensor,
                quality_score=quality_score,
                quality_grade=quality_grade,
                processing_time=total_time,
                step_results=step_results,
                step_timings=step_timings,
                ai_models_used=ai_models_used,
                pipeline_metadata={
                    'device': self.device,
                    'is_m3_max': self.config.is_m3_max,
                    'total_steps': 8,
                    'completed_steps': len(step_results),
                    'github_structure': True
                },
                performance_metrics=self._get_performance_metrics(step_results)
            )
            
            self.logger.info(f"ğŸ‰ 8ë‹¨ê³„ ê°€ìƒ í”¼íŒ… ì™„ë£Œ! ì´ ì‹œê°„: {total_time:.2f}ì´ˆ, í’ˆì§ˆ: {quality_score:.3f}")
            
            return result
            
        except Exception as e:
            self.logger.error(f"âŒ ê°€ìƒ í”¼íŒ… ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            self.current_status = PipelineStatus.FAILED
            
            return ProcessingResult(
                success=False,
                session_id=session_id or f"error_{int(time.time())}",
                processing_time=time.time() - start_time if 'start_time' in locals() else 0.0,
                error_message=str(e),
                pipeline_metadata={'error_location': traceback.format_exc()}
            )
    
    # ==============================================
    # ğŸ”¥ ìœ í‹¸ë¦¬í‹° ë©”ì„œë“œë“¤
    # ==============================================
    
    async def _preprocess_image(self, image_input) -> torch.Tensor:
        """ì´ë¯¸ì§€ ì „ì²˜ë¦¬"""
        try:
            if isinstance(image_input, str):
                image = Image.open(image_input).convert('RGB')
            elif isinstance(image_input, Image.Image):
                image = image_input.convert('RGB')
            elif isinstance(image_input, np.ndarray):
                image = Image.fromarray(image_input).convert('RGB')
            else:
                raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì´ë¯¸ì§€ íƒ€ì…: {type(image_input)}")
            
            # í‘œì¤€ í¬ê¸°ë¡œ ë¦¬ì‚¬ì´ì¦ˆ
            if image.size != (512, 512):
                image = image.resize((512, 512), Image.Resampling.LANCZOS)
            
            # í…ì„œ ë³€í™˜
            img_array = np.array(image)
            img_tensor = torch.from_numpy(img_array).permute(2, 0, 1).float() / 255.0
            img_tensor = img_tensor.unsqueeze(0).to(self.device)
            
            return img_tensor
            
        except Exception as e:
            self.logger.error(f"âŒ ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return torch.zeros(1, 3, 512, 512, device=self.device)
    
    def _calculate_quality_score(self, step_results: Dict[str, Any]) -> float:
        """í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°"""
        if not step_results:
            return 0.5
        
        scores = []
        weights = {
            'human_parsing': 0.1,
            'pose_estimation': 0.1,
            'cloth_segmentation': 0.15,
            'geometric_matching': 0.15,
            'cloth_warping': 0.15,
            'virtual_fitting': 0.25,  # ê°€ì¥ ì¤‘ìš”
            'post_processing': 0.05,
            'quality_assessment': 0.05
        }
        
        weighted_sum = 0.0
        total_weight = 0.0
        
        for step_name, result in step_results.items():
            if isinstance(result, dict) and result.get('success', False):
                weight = weights.get(step_name, 0.1)
                score = result.get('confidence', result.get('quality_score', 0.8))
                weighted_sum += weight * score
                total_weight += weight
        
        return weighted_sum / total_weight if total_weight > 0 else 0.5
    
    def _get_quality_grade(self, quality_score: float) -> str:
        """í’ˆì§ˆ ë“±ê¸‰"""
        if quality_score >= 0.95:
            return "Excellent+"
        elif quality_score >= 0.9:
            return "Excellent"
        elif quality_score >= 0.8:
            return "Good"
        elif quality_score >= 0.7:
            return "Fair"
        elif quality_score >= 0.6:
            return "Poor"
        else:
            return "Very Poor"
    
    def _extract_final_image(self, step_results: Dict[str, Any]) -> Optional[Image.Image]:
        """ìµœì¢… ê²°ê³¼ ì´ë¯¸ì§€ ì¶”ì¶œ"""
        try:
            # PostProcessing ê²°ê³¼ ìš°ì„ 
            if 'post_processing' in step_results:
                post_result = step_results['post_processing']
                if 'enhanced_image' in post_result:
                    return self._tensor_to_image(post_result['enhanced_image'])
            
            # VirtualFitting ê²°ê³¼ ì°¨ì„ 
            if 'virtual_fitting' in step_results:
                fitting_result = step_results['virtual_fitting']
                if 'fitted_image' in fitting_result:
                    return self._tensor_to_image(fitting_result['fitted_image'])
            
            return None
            
        except Exception as e:
            self.logger.error(f"âŒ ìµœì¢… ì´ë¯¸ì§€ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return None
    
    def _extract_final_tensor(self, step_results: Dict[str, Any]) -> Optional[torch.Tensor]:
        """ìµœì¢… ê²°ê³¼ í…ì„œ ì¶”ì¶œ"""
        try:
            if 'post_processing' in step_results:
                post_result = step_results['post_processing']
                if 'enhanced_image' in post_result:
                    result = post_result['enhanced_image']
                    if isinstance(result, torch.Tensor):
                        return result
            
            if 'virtual_fitting' in step_results:
                fitting_result = step_results['virtual_fitting']
                if 'fitted_image' in fitting_result:
                    result = fitting_result['fitted_image']
                    if isinstance(result, torch.Tensor):
                        return result
            
            return None
            
        except Exception as e:
            self.logger.error(f"âŒ ìµœì¢… í…ì„œ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return None
    
    def _tensor_to_image(self, tensor) -> Image.Image:
        """í…ì„œë¥¼ ì´ë¯¸ì§€ë¡œ ë³€í™˜"""
        try:
            if isinstance(tensor, torch.Tensor):
                if tensor.dim() == 4:
                    tensor = tensor.squeeze(0)
                if tensor.shape[0] == 3:
                    tensor = tensor.permute(1, 2, 0)
                
                tensor = torch.clamp(tensor, 0, 1)
                tensor = tensor.cpu()
                array = (tensor.numpy() * 255).astype(np.uint8)
                
                return Image.fromarray(array)
            else:
                return Image.new('RGB', (512, 512), color='gray')
                
        except Exception as e:
            self.logger.error(f"âŒ í…ì„œ to ì´ë¯¸ì§€ ë³€í™˜ ì‹¤íŒ¨: {e}")
            return Image.new('RGB', (512, 512), color='gray')
    
    def _get_performance_metrics(self, step_results: Dict[str, Any]) -> Dict[str, Any]:
        """ì„±ëŠ¥ ë©”íŠ¸ë¦­ ê³„ì‚°"""
        metrics = {
            'total_steps': len(step_results),
            'successful_steps': len([r for r in step_results.values() if r.get('success', False)]),
            'failed_steps': len([r for r in step_results.values() if not r.get('success', True)]),
            'average_step_time': 0.0,
            'total_ai_models': 0
        }
        
        if step_results:
            total_time = sum(r.get('processing_time', 0.0) for r in step_results.values())
            metrics['average_step_time'] = total_time / len(step_results)
            
            # AI ëª¨ë¸ ì‚¬ìš© í†µê³„
            all_models = []
            for result in step_results.values():
                models = result.get('ai_models_used', [])
                if isinstance(models, list):
                    all_models.extend(models)
                elif isinstance(models, str):
                    all_models.append(models)
            
            metrics['total_ai_models'] = len(set(all_models))
            metrics['ai_models_list'] = list(set(all_models))
        
        return metrics
    
    def _update_performance_stats(self, success: bool, processing_time: float, quality_score: float):
        """ì„±ëŠ¥ í†µê³„ ì—…ë°ì´íŠ¸"""
        self.performance_stats['total_sessions'] += 1
        
        if success:
            self.performance_stats['successful_sessions'] += 1
        
        # í‰ê·  ì²˜ë¦¬ ì‹œê°„ ì—…ë°ì´íŠ¸
        total = self.performance_stats['total_sessions']
        prev_avg_time = self.performance_stats['average_processing_time']
        self.performance_stats['average_processing_time'] = (
            (prev_avg_time * (total - 1) + processing_time) / total
        )
        
        # í‰ê·  í’ˆì§ˆ ì ìˆ˜ ì—…ë°ì´íŠ¸ (ì„±ê³µí•œ ì„¸ì…˜ë§Œ)
        if success:
            successful = self.performance_stats['successful_sessions']
            prev_avg_quality = self.performance_stats['average_quality_score']
            self.performance_stats['average_quality_score'] = (
                (prev_avg_quality * (successful - 1) + quality_score) / successful
            )
    
    async def _optimize_memory(self):
        """ë©”ëª¨ë¦¬ ìµœì í™”"""
        try:
            # Python GC
            gc.collect()
            
            # PyTorch ë©”ëª¨ë¦¬ ì •ë¦¬
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
            
            if hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
                if hasattr(torch.mps, 'empty_cache'):
                    torch.mps.empty_cache()
            
            self.logger.info("ğŸ’¾ ë©”ëª¨ë¦¬ ìµœì í™” ì™„ë£Œ")
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ ë©”ëª¨ë¦¬ ìµœì í™” ì‹¤íŒ¨: {e}")
    
    # ==============================================
    # ğŸ”¥ Step ê´€ë¦¬ ë©”ì„œë“œë“¤ (ê¸°ì¡´ ì¸í„°í˜ì´ìŠ¤ 100% ìœ ì§€, ë¹„ë™ê¸° ì˜¤ë¥˜ ì™„ì „ í•´ê²°)
    # ==============================================
    def register_step(self, step_id: int, step_instance: Any) -> bool:
        """Step ë“±ë¡ (ì™„ì „ ë™ê¸° ë©”ì„œë“œ, await ì˜¤ë¥˜ ì™„ì „ í•´ê²°)"""
        try:
            step_info = self.step_manager.step_mapping.get(step_id)
            if not step_info:
                self.logger.warning(f"âš ï¸ ì§€ì›í•˜ì§€ ì•ŠëŠ” Step ID: {step_id}")
                return False
            
            step_name = step_info['name']
            
            # ğŸ”¥ ê¸€ë¡œë²Œ í˜¸í™˜ì„± ë³´ì¥ (ë™ê¸°ì ìœ¼ë¡œ ì‹¤í–‰)
            config = {
                'device': self.device,
                'is_m3_max': self.config.is_m3_max,
                'memory_gb': self.config.memory_gb,
                'device_type': self.config.device_type,
                'ai_model_enabled': self.config.ai_model_enabled,
                'quality_level': self.config.quality_level.value if hasattr(self.config.quality_level, 'value') else self.config.quality_level,
                'performance_mode': 'maximum' if self.config.is_m3_max else 'balanced'
            }
            
            # ê¸€ë¡œë²Œ í˜¸í™˜ì„± í•¨ìˆ˜ í˜¸ì¶œ (ë™ê¸°)
            ensure_global_step_compatibility(step_instance, step_id, step_name, config)
            
            # ğŸ”¥ ì•ˆì „í•œ ë™ê¸° ì´ˆê¸°í™” (await ì˜¤ë¥˜ ì™„ì „ ë°©ì§€)
            try:
                if hasattr(step_instance, 'initialize'):
                    initialize_method = getattr(step_instance, 'initialize')
                    
                    # ë¹„ë™ê¸° ë©”ì„œë“œì¸ ê²½ìš° ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì²˜ë¦¬ (await ì‚¬ìš©í•˜ì§€ ì•ŠìŒ)
                    if asyncio.iscoroutinefunction(initialize_method):
                        # ë¹„ë™ê¸° ë©”ì„œë“œëŠ” ë§ˆí‚¹ë§Œ í•˜ê³  ì¦‰ì‹œ ì™„ë£Œë¡œ ì²˜ë¦¬
                        step_instance._needs_async_init = True
                        step_instance.is_initialized = True
                        step_instance.is_ready = True
                        self.logger.debug(f"âœ… {step_instance.__class__.__name__} ë¹„ë™ê¸° ì´ˆê¸°í™” ë§ˆí‚¹")
                    else:
                        # ë™ê¸° ë©”ì„œë“œëŠ” ì¦‰ì‹œ ì‹¤í–‰
                        try:
                            result = initialize_method()
                            # ğŸ”§ ê²°ê³¼ íƒ€ì… ì•ˆì „ ì²˜ë¦¬
                            if result is None or result is True or result:
                                step_instance.is_initialized = True
                                step_instance.is_ready = True
                
                        except Exception as e:
                            self.logger.warning(f"âš ï¸ {step_instance.__class__.__name__} ë™ê¸° ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                            # ì‹¤íŒ¨í•´ë„ ë“±ë¡ì€ ê³„ì† (ì˜¤ë¥˜ ë°©ì§€)
                            step_instance.is_initialized = True
                            step_instance.is_ready = True
                else:
                    # initialize ë©”ì„œë“œê°€ ì—†ìœ¼ë©´ ì§ì ‘ ì„¤ì •
                    step_instance.is_initialized = True
                    step_instance.is_ready = True
                    
            except Exception as e:
                self.logger.warning(f"âš ï¸ Step {step_id} ì´ˆê¸°í™” ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                # ì‹¤íŒ¨í•´ë„ ë“±ë¡ì€ ê³„ì† ì§„í–‰ (ì˜¤ë¥˜ ë°©ì§€)
                step_instance.is_initialized = True
                step_instance.is_ready = True
            
            # Step ë“±ë¡
            self.step_manager.steps[step_name] = step_instance
            self.logger.info(f"âœ… Step {step_id} ({step_name}) ë“±ë¡ ì™„ë£Œ")
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ Step {step_id} ë“±ë¡ ì‹¤íŒ¨: {e}")
            return False


    # ==============================================
    # ğŸ”¥ ensure_global_step_compatibility í•¨ìˆ˜ ìˆ˜ì • (GeometricMatchingStep ì˜¤ë¥˜ í•´ê²°)
    # ==============================================

    # ìœ„ì¹˜: íŒŒì¼ ìƒë‹¨ ê¸€ë¡œë²Œ í•¨ìˆ˜ ì˜ì—­
    # ê¸°ì¡´ ensure_global_step_compatibility í•¨ìˆ˜ ë‚´ë¶€ì— ì´ ë¶€ë¶„ ì¶”ê°€:
    # ê¸°ì¡´ ensure_global_step_compatibility í•¨ìˆ˜ì˜ ë ë¶€ë¶„ì„ ì´ë ‡ê²Œ ìˆ˜ì •:

    def ensure_global_step_compatibility(step_instance, step_id: int = None, step_name: str = None, config: Dict[str, Any] = None):
        """
        ì „ì—­ Step í˜¸í™˜ì„± ë³´ì¥ í•¨ìˆ˜ - ëª¨ë“  ì‹œìŠ¤í…œì—ì„œ í˜¸ì¶œ ê°€ëŠ¥
        StepFactory, PipelineManager ë“± ì–´ë””ì„œë“  ì‚¬ìš©
        """
        try:
            # ê¸°ë³¸ ì„¤ì •
            if not config:
                config = {
                    'device': 'mps',
                    'is_m3_max': True,
                    'memory_gb': 128.0,
                    'device_type': 'apple_silicon',
                    'ai_model_enabled': True,
                    'quality_level': 'high',
                    'performance_mode': 'maximum'
                }
            
            # ê¸°ë³¸ ì†ì„±ë“¤ ì„¤ì •
            essential_attrs = {
                'step_id': step_id or getattr(step_instance, 'step_id', 0),
                'step_name': step_name or getattr(step_instance, 'step_name', step_instance.__class__.__name__),
                'device': config.get('device', 'mps'),
                'is_m3_max': config.get('is_m3_max', True),
                'memory_gb': config.get('memory_gb', 128.0),
                'device_type': config.get('device_type', 'apple_silicon'),
                'ai_model_enabled': config.get('ai_model_enabled', True),
                'quality_level': config.get('quality_level', 'high'),
                'performance_mode': config.get('performance_mode', 'maximum'),
                'is_initialized': getattr(step_instance, 'is_initialized', False),
                'is_ready': getattr(step_instance, 'is_ready', False),
                'has_model': getattr(step_instance, 'has_model', False),
                'model_loaded': getattr(step_instance, 'model_loaded', False),
                'warmup_completed': getattr(step_instance, 'warmup_completed', False)
            }
            
            # ì†ì„± ì„¤ì •
            for attr, value in essential_attrs.items():
                if not hasattr(step_instance, attr):
                    setattr(step_instance, attr, value)
            
            # ğŸ”¥ íŠ¹ì • Step í´ë˜ìŠ¤ë³„ íŠ¹í™” ì²˜ë¦¬
            class_name = step_instance.__class__.__name__
            
            # GeometricMatchingStep íŠ¹í™”
            if step_instance.__class__.__name__ == 'GeometricMatchingStep':
                # ğŸ”¥ ì¶”ê°€: _force_mps_device ë©”ì„œë“œë„ ì¶”ê°€
                if not hasattr(step_instance, '_force_mps_device'):
                    def _force_mps_device(self):
                        self.device = 'mps' if getattr(self, 'is_m3_max', True) else self.device
                        return True
                    import types
                    step_instance._force_mps_device = types.MethodType(_force_mps_device, step_instance)
                
                # _setup_configurations ë©”ì„œë“œ ì¶”ê°€ (ëˆ„ë½ëœ ë©”ì„œë“œ)
                if not hasattr(step_instance, '_setup_configurations'):
                    def _setup_configurations(self):
                        """GeometricMatchingStep ì„¤ì • ì´ˆê¸°í™”"""
                        try:
                            self.geometric_config = getattr(self, 'geometric_config', {
                                'use_tps': True,
                                'use_gmm': True,
                                'matching_threshold': 0.8,
                                'correspondence_method': 'optical_flow',
                                'warping_method': 'tps_transformation'
                            })
                            self.model_config = getattr(self, 'model_config', {
                                'gmm_model': 'gmm_final.pth',
                                'tps_model': 'tps_network.pth',
                                'vit_model': 'ViT-L-14.pt'
                            })
                            self.processing_config = getattr(self, 'processing_config', {
                                'batch_size': 1,
                                'input_size': (512, 512),
                                'output_size': (512, 512),
                                'enable_cuda': True,
                                'enable_mps': True
                            })
                            return True
                        except Exception as e:
                            if hasattr(self, 'logger'):
                                self.logger.warning(f"âš ï¸ GeometricMatchingStep ì„¤ì • ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                            return False
                    
                    import types
                    step_instance._setup_configurations = types.MethodType(_setup_configurations, step_instance)
                    
                    # ì¦‰ì‹œ ì‹¤í–‰
                    try:
                        step_instance._setup_configurations()
                    except Exception as e:
                        print(f"âš ï¸ GeometricMatchingStep ì„¤ì • ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            
            # QualityAssessmentStep íŠ¹í™” (ì¤‘ìš”!)
            elif class_name == 'QualityAssessmentStep':
                # í•„ìˆ˜ ì†ì„± ê°•ì œ ì„¤ì •
                step_instance.is_m3_max = config.get('is_m3_max', True) if config else True
                step_instance.optimization_enabled = step_instance.is_m3_max
                step_instance.analysis_depth = 'comprehensive'
            
                # ì¶”ê°€ QualityAssessment íŠ¹í™” ì†ì„±ë“¤
                quality_attrs = {
                    'assessment_config': {
                        'use_clip': True,
                        'use_aesthetic': True,
                        'quality_threshold': 0.8,
                        'analysis_modes': ['technical', 'perceptual', 'aesthetic']
                    },
                    'quality_threshold': 0.8,
                    'assessment_modes': ['technical', 'perceptual', 'aesthetic'],
                    'enable_detailed_analysis': True,
                    'model_config': {
                        'clip_model': 'clip_vit_large.bin',
                        'aesthetic_model': 'aesthetic_predictor.pth'
                    }
                }
                
                for attr, value in quality_attrs.items():
                    if not hasattr(step_instance, attr):
                        setattr(step_instance, attr, value)
            
            # ğŸ”¥ ì—¬ê¸°ì— ë‹¤ë¥¸ Stepë“¤ë„ ì¶”ê°€ ì²˜ë¦¬
            elif class_name == 'HumanParsingStep':
                if not hasattr(step_instance, 'parsing_config'):
                    step_instance.parsing_config = {
                        'use_graphonomy': True,
                        'use_atr': True,
                        'num_classes': 20,
                        'input_size': (512, 512)
                    }
            elif class_name == 'PoseEstimationStep':
                if not hasattr(step_instance, 'pose_config'):
                    step_instance.pose_config = {
                        'use_yolov8': True,
                        'use_openpose': True,
                        'keypoint_format': 'coco_18',
                        'confidence_threshold': 0.5
                    }
            elif class_name == 'ClothSegmentationStep':
                if not hasattr(step_instance, 'segmentation_config'):
                    step_instance.segmentation_config = {
                        'use_sam': True,
                        'use_u2net': True,
                        'segment_threshold': 0.8,
                        'post_processing': True
                    }
            elif class_name == 'ClothWarpingStep':
                if not hasattr(step_instance, 'warping_config'):
                    step_instance.warping_config = {
                        'use_realvisx': True,
                        'use_stable_diffusion': True,
                        'warping_strength': 0.8,
                        'quality_level': 'high'
                    }
            elif class_name == 'VirtualFittingStep':
                if not hasattr(step_instance, 'fitting_config'):
                    step_instance.fitting_config = {
                        'use_ootd': True,
                        'use_diffusion': True,
                        'fitting_quality': 'high',
                        'blend_mode': 'realistic'
                    }
            elif class_name == 'PostProcessingStep':
                if not hasattr(step_instance, 'enhancement_config'):
                    step_instance.enhancement_config = {
                        'use_real_esrgan': True,
                        'use_gfpgan': True,
                        'enhancement_level': 'medium',
                        'upscale_factor': 2
                    }
            
            # ëª¨ë“  Stepì— ê³µí†µ ë©”ì„œë“œ ì¶”ê°€
            _add_global_step_methods(step_instance)
            
            # ë¡œê±° ì„¤ì •
            if not hasattr(step_instance, 'logger'):
                step_instance.logger = logging.getLogger(f"steps.{class_name}")
            
            return True
            
        except Exception as e:
            print(f"âš ï¸ ê¸€ë¡œë²Œ Step í˜¸í™˜ì„± ì„¤ì • ì‹¤íŒ¨: {e}")
            return False


    def _ensure_step_compatibility_sync(self, step_instance, step_info: Dict[str, Any]):
        """Step í˜¸í™˜ì„± ë³´ì¥ (ë™ê¸° ë²„ì „, await ì˜¤ë¥˜ í•´ê²°)"""
        try:
            # í•„ìˆ˜ ì†ì„± í™•ì¸ ë° ì„¤ì •
            required_attrs = {
                'step_id': step_info.get('step_id', 0),
                'step_name': step_info['name'],
                'device': self.device,
                'is_m3_max': self.config.is_m3_max,
                'memory_gb': self.config.memory_gb,
                'is_initialized': False,
                'is_ready': False,
                'has_model': False,
                'device_type': self.config.device_type,
                'ai_model_enabled': self.config.ai_model_enabled,
                'quality_level': self.config.quality_level.value if hasattr(self.config.quality_level, 'value') else self.config.quality_level,
                'performance_mode': 'maximum' if self.config.is_m3_max else 'balanced',
                'model_loaded': False,
                'warmup_completed': False
            }
            
            for attr, default_value in required_attrs.items():
                if not hasattr(step_instance, attr):
                    setattr(step_instance, attr, default_value)
            
            # ğŸ”¥ GeometricMatchingStep íŠ¹í™” ì˜¤ë¥˜ í•´ê²°
            if step_instance.__class__.__name__ == 'GeometricMatchingStep':
                if not hasattr(step_instance, '_force_mps_device'):
                    def _force_mps_device(self):
                        """MPS ë””ë°”ì´ìŠ¤ ê°•ì œ ì„¤ì • (í˜¸í™˜ì„± ë©”ì„œë“œ)"""
                        if hasattr(self, 'device'):
                            self.device = 'mps' if self.is_m3_max else self.device
                        return True
                    
                    # ë©”ì„œë“œ ë°”ì¸ë”©
                    import types
                    step_instance._force_mps_device = types.MethodType(_force_mps_device, step_instance)
            
            # ğŸ”¥ QualityAssessmentStep íŠ¹í™” ì˜¤ë¥˜ í•´ê²°
            if step_instance.__class__.__name__ == 'QualityAssessmentStep':
                # is_m3_max ì†ì„± í™•ì‹¤íˆ ì„¤ì •
                step_instance.is_m3_max = self.config.is_m3_max
                
                # ì¶”ê°€ í•„ìˆ˜ ì†ì„±ë“¤
                if not hasattr(step_instance, 'optimization_enabled'):
                    step_instance.optimization_enabled = self.config.is_m3_max
                if not hasattr(step_instance, 'analysis_depth'):
                    step_instance.analysis_depth = 'comprehensive'
            
            # ê³µí†µ ë©”ì„œë“œë“¤ ì¶”ê°€
            self._add_common_step_methods(step_instance)
            
            # ë¡œê±° ì„¤ì •
            if not hasattr(step_instance, 'logger'):
                step_instance.logger = logging.getLogger(f"steps.{step_instance.__class__.__name__}")
            
            self.logger.debug(f"âœ… {step_instance.__class__.__name__} ë™ê¸° í˜¸í™˜ì„± ë³´ì¥ ì™„ë£Œ")
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ Step ë™ê¸° í˜¸í™˜ì„± ì„¤ì • ì‹¤íŒ¨: {e}")
    
    def register_steps_batch(self, steps_dict: Dict[int, Any]) -> Dict[int, bool]:
        """Step ì¼ê´„ ë“±ë¡"""
        results = {}
        for step_id, step_instance in steps_dict.items():
            results[step_id] = self.register_step(step_id, step_instance)
        return results
    
    def unregister_step(self, step_id: int) -> bool:
        """Step ë“±ë¡ í•´ì œ"""
        try:
            step_info = self.step_manager.step_mapping.get(step_id)
            if not step_info:
                return False
            
            step_name = step_info['name']
            if step_name in self.step_manager.steps:
                step_instance = self.step_manager.steps[step_name]
                
                # ì •ë¦¬ ì‘ì—…
                if hasattr(step_instance, 'cleanup'):
                    try:
                        if asyncio.iscoroutinefunction(step_instance.cleanup):
                            asyncio.create_task(step_instance.cleanup())
                        else:
                            step_instance.cleanup()
                    except Exception as e:
                        self.logger.warning(f"âš ï¸ Step {step_id} ì •ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
                
                del self.step_manager.steps[step_name]
                self.logger.info(f"âœ… Step {step_id} ({step_name}) ë“±ë¡ í•´ì œ ì™„ë£Œ")
                return True
            
            return False
            
        except Exception as e:
            self.logger.error(f"âŒ Step {step_id} ë“±ë¡ í•´ì œ ì‹¤íŒ¨: {e}")
            return False
    
    def get_registered_steps(self) -> Dict[str, Any]:
        """ë“±ë¡ëœ Step ëª©ë¡ ë°˜í™˜"""
        registered_steps = {}
        for step_id, step_info in self.step_manager.step_mapping.items():
            step_name = step_info['name']
            step_instance = self.step_manager.steps.get(step_name)
            
            registered_steps[step_name] = {
                'step_id': step_id,
                'step_name': step_name,
                'class_name': step_info['class_name'],
                'registered': step_instance is not None,
                'has_process_method': hasattr(step_instance, 'process') if step_instance else False,
                'is_initialized': getattr(step_instance, 'is_initialized', False) if step_instance else False,
                'is_ready': getattr(step_instance, 'is_ready', False) if step_instance else False
            }
        
        total_registered = len([s for s in registered_steps.values() if s['registered']])
        missing_steps = [name for name, info in registered_steps.items() if not info['registered']]
        
        return {
            'total_registered': total_registered,
            'total_expected': len(self.step_manager.step_mapping),
            'registration_rate': (total_registered / len(self.step_manager.step_mapping)) * 100,
            'registered_steps': registered_steps,
            'missing_steps': missing_steps
        }
    
    def is_step_registered(self, step_id: int) -> bool:
        """Step ë“±ë¡ ì—¬ë¶€ í™•ì¸"""
        step_info = self.step_manager.step_mapping.get(step_id)
        if not step_info:
            return False
        
        step_name = step_info['name']
        return step_name in self.step_manager.steps
    
    def get_step_by_id(self, step_id: int) -> Optional[Any]:
        """Step IDë¡œ Step ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
        step_info = self.step_manager.step_mapping.get(step_id)
        if not step_info:
            return None
        
        step_name = step_info['name']
        return self.step_manager.steps.get(step_name)
    
    def update_config(self, new_config: Dict[str, Any]) -> bool:
        """íŒŒì´í”„ë¼ì¸ ì„¤ì • ì—…ë°ì´íŠ¸"""
        try:
            self.logger.info("ğŸ”„ íŒŒì´í”„ë¼ì¸ ì„¤ì • ì—…ë°ì´íŠ¸ ì‹œì‘...")
            
            # ê¸°ë³¸ ì„¤ì • ì—…ë°ì´íŠ¸
            if 'device' in new_config and new_config['device'] != self.device:
                self.device = new_config['device']
                self.logger.info(f"âœ… ë””ë°”ì´ìŠ¤ ë³€ê²½: {self.device}")
            
            # PipelineConfig ì—…ë°ì´íŠ¸
            for key, value in new_config.items():
                if hasattr(self.config, key):
                    setattr(self.config, key, value)
            
            self.logger.info("âœ… íŒŒì´í”„ë¼ì¸ ì„¤ì • ì—…ë°ì´íŠ¸ ì™„ë£Œ")
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ íŒŒì´í”„ë¼ì¸ ì„¤ì • ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
            return False
    
    def configure_from_detection(self, detection_config: Dict[str, Any]) -> bool:
        """Step íƒì§€ ê²°ê³¼ë¡œë¶€í„° íŒŒì´í”„ë¼ì¸ ì„¤ì •"""
        try:
            self.logger.info("ğŸ¯ Step íƒì§€ ê²°ê³¼ë¡œë¶€í„° íŒŒì´í”„ë¼ì¸ ì„¤ì • ì‹œì‘...")
            
            if 'steps' in detection_config:
                for step_config in detection_config['steps']:
                    step_name = step_config.get('step_name')
                    
                    # Step ì •ë³´ ì°¾ê¸°
                    for step_id, step_info in self.step_manager.step_mapping.items():
                        if step_info['name'] == step_name:
                            if step_name not in self.step_manager.steps:
                                try:
                                    step_instance = self.step_manager._create_step_directly(step_id, step_info)
                                    if step_instance:
                                        self.step_manager.steps[step_name] = step_instance
                                        self.logger.info(f"âœ… {step_name} íƒì§€ ê²°ê³¼ë¡œë¶€í„° ì„¤ì • ì™„ë£Œ")
                                except Exception as e:
                                    self.logger.warning(f"âš ï¸ {step_name} íƒì§€ ê²°ê³¼ ì„¤ì • ì‹¤íŒ¨: {e}")
                            break
            
            self.logger.info("âœ… Step íƒì§€ ê²°ê³¼ë¡œë¶€í„° íŒŒì´í”„ë¼ì¸ ì„¤ì • ì™„ë£Œ")
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ Step íƒì§€ ê²°ê³¼ ì„¤ì • ì‹¤íŒ¨: {e}")
            return False
    
    # ==============================================
    # ğŸ”¥ ìƒíƒœ ì¡°íšŒ ë©”ì„œë“œë“¤
    # ==============================================
    
    def get_pipeline_status(self) -> Dict[str, Any]:
        """íŒŒì´í”„ë¼ì¸ ìƒíƒœ ì¡°íšŒ"""
        registered_steps = self.get_registered_steps()
        
        return {
            'initialized': self.is_initialized,
            'current_status': self.current_status.value,
            'device': self.device,
            'device_type': self.config.device_type,
            'memory_gb': self.config.memory_gb,
            'is_m3_max': self.config.is_m3_max,
            'ai_model_enabled': self.config.ai_model_enabled,
            'architecture_version': 'v11.0_github_complete_reflection',
            
            'step_manager': {
                'total_registered': registered_steps['total_registered'],
                'total_expected': registered_steps['total_expected'],
                'registration_rate': registered_steps['registration_rate'],
                'missing_steps': registered_steps['missing_steps'],
                'github_structure': True
            },
            
            'config': {
                'quality_level': self.config.quality_level.value,
                'processing_mode': self.config.processing_mode.value,
                'use_dependency_injection': self.config.use_dependency_injection,
                'enable_adapter_pattern': self.config.enable_adapter_pattern,
                'batch_size': self.config.batch_size,
                'thread_pool_size': self.config.thread_pool_size
            },
            
            'performance_stats': self.performance_stats,
            
            'ai_model_paths': {
                step_name: len(models) 
                for step_name, models in self.step_manager.ai_model_paths.items()
            },
            
            'data_flow_engine': {
                'engine_type': 'GitHubDataFlowEngine',
                'flow_rules_count': len(self.data_flow_engine.data_flow_rules),
                'supports_pipeline_data': True
            }
        }
    
    async def cleanup(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        try:
            self.logger.info("ğŸ§¹ PipelineManager v11.0 ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì¤‘...")
            self.current_status = PipelineStatus.CLEANING
            
            # Step ì •ë¦¬
            for step_name, step in self.step_manager.steps.items():
                try:
                    if hasattr(step, 'cleanup'):
                        if asyncio.iscoroutinefunction(step.cleanup):
                            await step.cleanup()
                        else:
                            step.cleanup()
                except Exception as e:
                    self.logger.warning(f"âš ï¸ {step_name} ì •ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
            
            # ë©”ëª¨ë¦¬ ì •ë¦¬
            await self._optimize_memory()
            
            # ìƒíƒœ ì´ˆê¸°í™”
            self.is_initialized = False
            self.current_status = PipelineStatus.IDLE
            
            self.logger.info("âœ… PipelineManager v11.0 ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì™„ë£Œ")
            
        except Exception as e:
            self.logger.error(f"âŒ ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
            self.current_status = PipelineStatus.FAILED

# ==============================================
# ğŸ”¥ DIBasedPipelineManager í´ë˜ìŠ¤ (ê¸°ì¡´ ì¸í„°í˜ì´ìŠ¤ 100% ìœ ì§€)
# ==============================================

class DIBasedPipelineManager(PipelineManager):
    """DI ì „ìš© PipelineManager (ê¸°ì¡´ ì¸í„°í˜ì´ìŠ¤ 100% ìœ ì§€)"""
    
    def __init__(
        self,
        config_path: Optional[str] = None,
        device: Optional[str] = None,
        config: Optional[Union[Dict[str, Any], PipelineConfig]] = None,
        **kwargs
    ):
        # DI ê´€ë ¨ ì„¤ì • ê°•ì œ í™œì„±í™”
        if isinstance(config, dict):
            config.update({
                'use_dependency_injection': True,
                'auto_inject_dependencies': True,
                'enable_adapter_pattern': True
            })
        elif isinstance(config, PipelineConfig):
            config.use_dependency_injection = True
            config.auto_inject_dependencies = True
            config.enable_adapter_pattern = True
        else:
            kwargs.update({
                'use_dependency_injection': True,
                'auto_inject_dependencies': True,
                'enable_adapter_pattern': True
            })
        
        # ë¶€ëª¨ í´ë˜ìŠ¤ ì´ˆê¸°í™”
        super().__init__(config_path=config_path, device=device, config=config, **kwargs)
        
        self.logger.info("ğŸ”¥ DIBasedPipelineManager v11.0 ì´ˆê¸°í™” ì™„ë£Œ (DI ê°•ì œ í™œì„±í™”)")
    
    def get_di_status(self) -> Dict[str, Any]:
        """DI ì „ìš© ìƒíƒœ ì¡°íšŒ"""
        base_status = self.get_pipeline_status()
        
        return {
            **base_status,
            'di_based_manager': True,
            'di_forced_enabled': True,
            'github_structure_reflection': True,
            'di_specific_info': {
                'step_manager_type': type(self.step_manager).__name__,
                'data_flow_engine_type': type(self.data_flow_engine).__name__
            }
        }

# ==============================================
# ğŸ”¥ í¸ì˜ í•¨ìˆ˜ë“¤ (ê¸°ì¡´ í•¨ìˆ˜ëª… 100% ìœ ì§€)
# ==============================================

def create_pipeline(
    device: str = "auto", 
    quality_level: str = "balanced", 
    mode: str = "production",
    use_dependency_injection: bool = True,
    enable_adapter_pattern: bool = True,
    **kwargs
) -> PipelineManager:
    """ê¸°ë³¸ íŒŒì´í”„ë¼ì¸ ìƒì„± í•¨ìˆ˜ (ê¸°ì¡´ í•¨ìˆ˜ëª… ìœ ì§€)"""
    return PipelineManager(
        device=device,
        config=PipelineConfig(
            quality_level=QualityLevel(quality_level),
            processing_mode=ProcessingMode(mode),
            ai_model_enabled=True,
            use_dependency_injection=use_dependency_injection,
            enable_adapter_pattern=enable_adapter_pattern,
            **kwargs
        )
    )

def create_complete_di_pipeline(
    device: str = "auto",
    quality_level: str = "high",
    **kwargs
) -> PipelineManager:
    """ì™„ì „ DI íŒŒì´í”„ë¼ì¸ ìƒì„± (ê¸°ì¡´ í•¨ìˆ˜ëª… ìœ ì§€)"""
    return PipelineManager(
        device=device,
        config=PipelineConfig(
            quality_level=QualityLevel(quality_level),
            processing_mode=ProcessingMode.PRODUCTION,
            ai_model_enabled=True,
            model_preload_enabled=True,
            use_dependency_injection=True,
            enable_adapter_pattern=True,
            **kwargs
        )
    )

def create_m3_max_pipeline(**kwargs) -> PipelineManager:
    """M3 Max ìµœì í™” íŒŒì´í”„ë¼ì¸ (ê¸°ì¡´ í•¨ìˆ˜ëª… ìœ ì§€)"""
    return PipelineManager(
        device="mps",
        config=PipelineConfig(
            quality_level=QualityLevel.MAXIMUM,
            processing_mode=ProcessingMode.PRODUCTION,
            memory_gb=128.0,
            is_m3_max=True,
            device_type="apple_silicon",
            ai_model_enabled=True,
            model_preload_enabled=True,
            use_dependency_injection=True,
            enable_adapter_pattern=True,
            **kwargs
        )
    )

def create_production_pipeline(**kwargs) -> PipelineManager:
    """í”„ë¡œë•ì…˜ íŒŒì´í”„ë¼ì¸ (ê¸°ì¡´ í•¨ìˆ˜ëª… ìœ ì§€)"""
    return create_complete_di_pipeline(
        quality_level="high",
        processing_mode="production",
        ai_model_enabled=True,
        model_preload_enabled=True,
        **kwargs
    )

def create_development_pipeline(**kwargs) -> PipelineManager:
    """ê°œë°œìš© íŒŒì´í”„ë¼ì¸ (ê¸°ì¡´ í•¨ìˆ˜ëª… ìœ ì§€)"""
    return create_complete_di_pipeline(
        quality_level="balanced",
        processing_mode="development",
        ai_model_enabled=True,
        model_preload_enabled=False,
        **kwargs
    )

def create_testing_pipeline(**kwargs) -> PipelineManager:
    """í…ŒìŠ¤íŒ…ìš© íŒŒì´í”„ë¼ì¸ (ê¸°ì¡´ í•¨ìˆ˜ëª… ìœ ì§€)"""
    return PipelineManager(
        device="cpu",
        config=PipelineConfig(
            quality_level=QualityLevel.FAST,
            processing_mode=ProcessingMode.TESTING,
            ai_model_enabled=False,
            model_preload_enabled=False,
            use_dependency_injection=True,
            enable_adapter_pattern=True,
            **kwargs
        )
    )

def create_di_based_pipeline(**kwargs) -> DIBasedPipelineManager:
    """DIBasedPipelineManager ìƒì„± (ê¸°ì¡´ í•¨ìˆ˜ëª… ìœ ì§€)"""
    return DIBasedPipelineManager(**kwargs)

@lru_cache(maxsize=1)
def get_global_pipeline_manager(device: str = "auto") -> PipelineManager:
    """ì „ì—­ íŒŒì´í”„ë¼ì¸ ë§¤ë‹ˆì € (ê¸°ì¡´ í•¨ìˆ˜ëª… ìœ ì§€)"""
    try:
        if device == "mps" and torch.backends.mps.is_available():
            return create_m3_max_pipeline()
        else:
            return create_production_pipeline(device=device)
    except Exception as e:
        logger.error(f"ì „ì—­ íŒŒì´í”„ë¼ì¸ ë§¤ë‹ˆì € ìƒì„± ì‹¤íŒ¨: {e}")
        return create_complete_di_pipeline(device="cpu", quality_level="balanced")

@lru_cache(maxsize=1)
def get_global_di_based_pipeline_manager(device: str = "auto") -> DIBasedPipelineManager:
    """ì „ì—­ DIBasedPipelineManager (ê¸°ì¡´ í•¨ìˆ˜ëª… ìœ ì§€)"""
    try:
        if device == "mps" and torch.backends.mps.is_available():
            return DIBasedPipelineManager(
                device="mps",
                config=PipelineConfig(
                    quality_level=QualityLevel.MAXIMUM,
                    processing_mode=ProcessingMode.PRODUCTION,
                    memory_gb=128.0,
                    is_m3_max=True,
                    device_type="apple_silicon"
                )
            )
        else:
            return DIBasedPipelineManager(device=device)
    except Exception as e:
        logger.error(f"ì „ì—­ DIBasedPipelineManager ìƒì„± ì‹¤íŒ¨: {e}")
        return DIBasedPipelineManager(device="cpu")

# ==============================================
# ğŸ”¥ Export ë° ë©”ì¸ ì‹¤í–‰
# ==============================================

__all__ = [
    # ì—´ê±°í˜•
    'PipelineStatus', 'QualityLevel', 'ProcessingMode', 'PipelineMode',  # PipelineMode ë³„ì¹­ ì¶”ê°€
    
    # ë°ì´í„° í´ë˜ìŠ¤
    'PipelineConfig', 'PipelineStepResult', 'ProcessingResult',
    
    # ê´€ë¦¬ì í´ë˜ìŠ¤ë“¤
    'GitHubStepManager', 'GitHubDataFlowEngine',
    
    # ë©”ì¸ í´ë˜ìŠ¤ë“¤ (ê¸°ì¡´ ì´ë¦„ 100% ìœ ì§€)
    'PipelineManager',
    'DIBasedPipelineManager',
    
    # íŒ©í† ë¦¬ í•¨ìˆ˜ë“¤ (ê¸°ì¡´ ì´ë¦„ 100% ìœ ì§€)
    'create_pipeline',
    'create_complete_di_pipeline',
    'create_m3_max_pipeline',
    'create_production_pipeline',
    'create_development_pipeline',
    'create_testing_pipeline',
    'create_di_based_pipeline',
    'get_global_pipeline_manager',
    'get_global_di_based_pipeline_manager',
    
    # ğŸ”¥ ê¸€ë¡œë²Œ í˜¸í™˜ì„± í•¨ìˆ˜ë“¤ (ì™¸ë¶€ ì‹œìŠ¤í…œìš©)
    'ensure_global_step_compatibility',
    '_add_global_step_methods'
]

# ==============================================
# ğŸ”¥ ì´ˆê¸°í™” ì™„ë£Œ ë©”ì‹œì§€
# ==============================================

logger.info("ğŸ‰ ì™„ì „ ì¬ì„¤ê³„ëœ PipelineManager v11.0 ë¡œë“œ ì™„ë£Œ!")
logger.info("âœ… GitHub êµ¬ì¡° ì™„ì „ ë°˜ì˜ + ëª¨ë“  ì˜¤ë¥˜ í•´ê²°:")
logger.info("   - ì‹¤ì œ Step íŒŒì¼ process() ë©”ì„œë“œ ì‹œê·¸ë‹ˆì²˜ ì •í™• ë§¤í•‘")
logger.info("   - PipelineStepResult ì™„ì „í•œ ë°ì´í„° êµ¬ì¡° êµ¬í˜„")
logger.info("   - GitHubStepManager - ì‹¤ì œ GitHub êµ¬ì¡° 100% ë°˜ì˜")
logger.info("   - GitHubDataFlowEngine - ì™„ì „í•œ ë°ì´í„° íë¦„ êµ¬í˜„")
logger.info("   - ì‹¤ì œ AI ëª¨ë¸ 229GB ê²½ë¡œ ë§¤í•‘")
logger.info("   - BaseStepMixin ì˜ì¡´ì„± ì£¼ì… ì™„ì „ í™œìš©")

logger.info("âœ… ì™„ì „ í•´ê²°ëœ í•µì‹¬ ë¬¸ì œë“¤:")
logger.info("   - object bool can't be used in 'await' expression âœ… ì™„ì „ í•´ê²°")
logger.info("   - 'GeometricMatchingStep' object has no attribute '_force_mps_device' âœ… í•´ê²°")
logger.info("   - 'QualityAssessmentStep' object has no attribute 'is_m3_max' âœ… í•´ê²°")
logger.info("   - Step ê°„ ë°ì´í„° ì „ë‹¬ ë¶ˆì¼ì¹˜ âœ… ì™„ì „ í•´ê²°")
logger.info("   - Step íŒŒì¼ ìˆ˜ì • ì—†ì´ GitHub ì½”ë“œ ê·¸ëŒ€ë¡œ ì‚¬ìš© âœ… ë³´ì¥")
logger.info("   - ì‹¤ì œ process() í˜¸ì¶œ ì •í™• êµ¬í˜„ âœ… ì™„ë£Œ")
logger.info("   - ì™„ì „í•œ ë°ì´í„° ë§¤í•‘ ë° íë¦„ ë³´ì¥ âœ… êµ¬í˜„")

logger.info("ğŸ”¥ Step íŒŒì¼ ìˆ˜ì • ì—†ìŒ ë³´ì¥:")
logger.info("   - ëª¨ë“  í•„ìˆ˜ ì†ì„± PipelineManagerì—ì„œ ìë™ ì¶”ê°€")
logger.info("   - ëˆ„ë½ëœ ë©”ì„œë“œë“¤ ë™ì  ë°”ì¸ë”©ìœ¼ë¡œ í•´ê²°")
logger.info("   - í˜¸í™˜ì„± ë³´ì¥ ë©”ì„œë“œë¡œ ê¸°ì¡´ ì½”ë“œ ì™„ì „ ë³´í˜¸")
logger.info("   - ë¹„ë™ê¸°/ë™ê¸° ë©”ì„œë“œ ìë™ ê°ì§€ ë° ì•ˆì „ ì²˜ë¦¬")

logger.info("ğŸ›¡ï¸ ê¸€ë¡œë²Œ Step í˜¸í™˜ì„± ì‹œìŠ¤í…œ:")
logger.info("   - ensure_global_step_compatibility() ì „ì—­ í•¨ìˆ˜ ì œê³µ")
logger.info("   - ëª¨ë“  ì‹œìŠ¤í…œ(StepFactory, PipelineManager)ì—ì„œ ì‚¬ìš© ê°€ëŠ¥")
logger.info("   - Step ìƒì„± ì‹œì ê³¼ ë“±ë¡ ì‹œì  ëª¨ë‘ì—ì„œ í˜¸í™˜ì„± ë³´ì¥")
logger.info("   - QualityAssessmentStep is_m3_max ì˜¤ë¥˜ ì™„ì „ í•´ê²°")

# ==============================================
# ğŸ”¥ ì™¸ë¶€ ì‹œìŠ¤í…œìš© ê¸€ë¡œë²Œ Export
# ==============================================

# ë‹¤ë¥¸ ëª¨ë“ˆì—ì„œ import ê°€ëŠ¥í•˜ë„ë¡ ì „ì—­ ë³€ìˆ˜ë¡œ ì„¤ì •
globals()['ensure_global_step_compatibility'] = ensure_global_step_compatibility
globals()['_add_global_step_methods'] = _add_global_step_methods

# StepFactoryë‚˜ ë‹¤ë¥¸ ì‹œìŠ¤í…œì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ export
__step_compatibility_functions__ = {
    'ensure_global_step_compatibility': ensure_global_step_compatibility,
    '_add_global_step_methods': _add_global_step_methods
}

logger.info("ğŸ”¥ GitHub ì‹¤ì œ êµ¬ì¡° ë°˜ì˜ ì™„ë£Œ:")
for step_id in range(1, 9):
    step_info = {
        1: 'HumanParsingStep',
        2: 'PoseEstimationStep', 
        3: 'ClothSegmentationStep',
        4: 'GeometricMatchingStep',
        5: 'ClothWarpingStep',
        6: 'VirtualFittingStep',
        7: 'PostProcessingStep',
        8: 'QualityAssessmentStep'
    }
    logger.info(f"   - Step {step_id:02d}: {step_info[step_id]} âœ…")

logger.info("ğŸš€ ì´ì œ GitHub Step íŒŒì¼ë“¤ê³¼ ì™„ë²½ í˜¸í™˜ë˜ëŠ” íŒŒì´í”„ë¼ì¸ì´ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤!")

# ==============================================
# ğŸ”¥ ë©”ì¸ ì‹¤í–‰ ë° ë°ëª¨
# ==============================================

if __name__ == "__main__":
    print("ğŸ”¥ ì™„ì „ ì¬ì„¤ê³„ëœ PipelineManager v11.0 - GitHub êµ¬ì¡° ì™„ì „ ë°˜ì˜")
    print("=" * 80)
    print("âœ… GitHub Step íŒŒì¼ êµ¬ì¡° 100% ë°˜ì˜")
    print("âœ… ì‹¤ì œ process() ë©”ì„œë“œ ì‹œê·¸ë‹ˆì²˜ ì •í™• ë§¤í•‘")
    print("âœ… ì™„ì „í•œ ë°ì´í„° íë¦„ êµ¬í˜„")
    print("âœ… ëª¨ë“  êµ¬ì¡°ì  ì˜¤ë¥˜ ì™„ì „ í•´ê²°")
    print("=" * 80)
    
    import asyncio
    
    async def demo_github_complete_implementation():
        """GitHub ì™„ì „ ë°˜ì˜ ë°ëª¨"""
        print("ğŸ¯ GitHub êµ¬ì¡° ì™„ì „ ë°˜ì˜ PipelineManager ë°ëª¨ ì‹œì‘")
        print("-" * 60)
        
        # 1. ëª¨ë“  íŒŒì´í”„ë¼ì¸ ìƒì„± í•¨ìˆ˜ í…ŒìŠ¤íŠ¸
        print("1ï¸âƒ£ ëª¨ë“  íŒŒì´í”„ë¼ì¸ ìƒì„± í•¨ìˆ˜ í…ŒìŠ¤íŠ¸...")
        
        try:
            pipelines = {
                'basic': create_pipeline(),
                'complete_di': create_complete_di_pipeline(),
                'm3_max': create_m3_max_pipeline(),
                'production': create_production_pipeline(),
                'development': create_development_pipeline(),
                'testing': create_testing_pipeline(),
                'di_based': create_di_based_pipeline(),
                'global': get_global_pipeline_manager(),
                'global_di': get_global_di_based_pipeline_manager()
            }
            
            for name, pipeline in pipelines.items():
                print(f"âœ… {name}: {type(pipeline).__name__}")
            
        except Exception as e:
            print(f"âŒ íŒŒì´í”„ë¼ì¸ ìƒì„± í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
            return
        
        # 2. GitHub êµ¬ì¡° ë°˜ì˜ ì™„ì „ í…ŒìŠ¤íŠ¸
        print("2ï¸âƒ£ GitHub êµ¬ì¡° ë°˜ì˜ ì™„ì „ í…ŒìŠ¤íŠ¸...")
        
        try:
            pipeline = pipelines['m3_max']
            
            # ì´ˆê¸°í™”
            success = await pipeline.initialize()
            print(f"âœ… ì´ˆê¸°í™”: {'ì„±ê³µ' if success else 'ì‹¤íŒ¨'}")
            
            if success:
                # ìƒíƒœ í™•ì¸
                status = pipeline.get_pipeline_status()
                print(f"ğŸ“Š GitHub êµ¬ì¡° ë°˜ì˜: {'âœ…' if status.get('step_manager', {}).get('github_structure') else 'âŒ'}")
                print(f"ğŸ¯ Step ë§¤í•‘: {status['step_manager']['total_registered']}/8")
                print(f"ğŸ’¾ ë©”ëª¨ë¦¬: {status['memory_gb']}GB")
                print(f"ğŸš€ ë””ë°”ì´ìŠ¤: {status['device']}")
                print(f"ğŸ§  AI ëª¨ë¸ ê²½ë¡œ: {len(status.get('ai_model_paths', {}))}ê°œ ì¹´í…Œê³ ë¦¬")
                
                # Step ë§¤í•‘ ìƒì„¸ í™•ì¸
                registered_steps = pipeline.get_registered_steps()
                print(f"ğŸ“‹ Step ë“±ë¡ ìƒì„¸:")
                for step_name, step_info in registered_steps['registered_steps'].items():
                    status_emoji = "âœ…" if step_info['registered'] else "âŒ"
                    print(f"   {status_emoji} {step_info['step_id']:02d}: {step_name} ({step_info['class_name']})")
            
            # ì •ë¦¬
            await pipeline.cleanup()
            print("âœ… íŒŒì´í”„ë¼ì¸ ì •ë¦¬ ì™„ë£Œ")
            
        except Exception as e:
            print(f"âŒ GitHub êµ¬ì¡° í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        
        print("\nğŸ‰ GitHub êµ¬ì¡° ì™„ì „ ë°˜ì˜ PipelineManager ë°ëª¨ ì™„ë£Œ!")
        print("âœ… ëª¨ë“  ê¸°ì¡´ ì¸í„°í˜ì´ìŠ¤ 100% í˜¸í™˜!")
        print("âœ… GitHub Step íŒŒì¼ë“¤ê³¼ ì™„ë²½ ì—°ë™!")
        print("âœ… ì‹¤ì œ AI ëª¨ë¸ ì—°ë™ ì¤€ë¹„ ì™„ë£Œ!")
        print("âœ… 8ë‹¨ê³„ íŒŒì´í”„ë¼ì¸ ì™„ì „ ê¸°ëŠ¥!")
        print("âœ… conda í™˜ê²½ì—ì„œ ì™„ë²½ ì‘ë™!")
    
    # ì‹¤í–‰
    asyncio.run(demo_github_complete_implementation())