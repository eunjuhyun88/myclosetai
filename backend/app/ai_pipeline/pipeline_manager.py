"""
ì‹¤ì œ ìˆ˜ì •ëœ í´ë˜ìŠ¤ë“¤ì— ë§ì¶˜ ì™„ì „í•œ 8ë‹¨ê³„ ê°€ìƒ í”¼íŒ… íŒŒì´í”„ë¼ì¸ ë§¤ë‹ˆì €
- ìˆ˜ì •ëœ step í´ë˜ìŠ¤ë“¤ê³¼ ì™„ë²½ í˜¸í™˜
- model_loader ì¸ì ë¬¸ì œ í•´ê²° ì ìš©
- M3 Max ìµœì í™” 
- í”„ë¡œë•ì…˜ ë ˆë²¨ ì•ˆì •ì„±
- main.pyì—ì„œ ìš”êµ¬í•˜ëŠ” PipelineMode enumê³¼ export í•¨ìˆ˜ë“¤ ì¶”ê°€
"""
import os
import sys
import logging
import asyncio
import time
import traceback
from pathlib import Path
from typing import Dict, Any, Optional, Callable, Union, List, Tuple
from enum import Enum
import numpy as np
import torch
import torch.nn.functional as F
from PIL import Image, ImageEnhance, ImageFilter
import json
import gc
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('virtual_fitting_pipeline.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# ==========================================
# main.pyì—ì„œ ìš”êµ¬í•˜ëŠ” ENUM ì¶”ê°€
# ==========================================

class PipelineMode(Enum):
    """íŒŒì´í”„ë¼ì¸ ëª¨ë“œ enum (main.pyì—ì„œ ìš”êµ¬)"""
    SIMULATION = "simulation"
    PRODUCTION = "production"
    HYBRID = "hybrid"
    DEVELOPMENT = "development"
    
    @classmethod
    def get_default(cls):
        return cls.SIMULATION

# ìˆ˜ì •ëœ ai_pipeline êµ¬ì¡°ì˜ step íŒŒì¼ë“¤ import
try:
    from app.ai_pipeline.steps.step_01_human_parsing import HumanParsingStep
    from app.ai_pipeline.steps.step_02_pose_estimation import PoseEstimationStep
    from app.ai_pipeline.steps.step_03_cloth_segmentation import ClothSegmentationStep
    from app.ai_pipeline.steps.step_04_geometric_matching import GeometricMatchingStep
    from app.ai_pipeline.steps.step_05_cloth_warping import ClothWarpingStep
    from app.ai_pipeline.steps.step_06_virtual_fitting import VirtualFittingStep
    from app.ai_pipeline.steps.step_07_post_processing import PostProcessingStep
    from app.ai_pipeline.steps.step_08_quality_assessment import QualityAssessmentStep
    STEPS_IMPORT_SUCCESS = True
except ImportError as e:
    logger.warning(f"Step í´ë˜ìŠ¤ë“¤ import ì‹¤íŒ¨: {e}")
    STEPS_IMPORT_SUCCESS = False

# ìœ í‹¸ë¦¬í‹°ë“¤ ì•ˆì „í•˜ê²Œ import
try:
    from app.ai_pipeline.utils.model_loader import ModelLoader
    from app.ai_pipeline.utils.memory_manager import MemoryManager
    from app.ai_pipeline.utils.data_converter import DataConverter
except ImportError as e:
    logger.warning(f"ì¼ë¶€ ìœ í‹¸ë¦¬í‹° import ì‹¤íŒ¨: {e}")
    ModelLoader = None
    MemoryManager = None
    DataConverter = None

class PipelineManager:
    """
    ìˆ˜ì •ëœ í´ë˜ìŠ¤ë“¤ê³¼ í˜¸í™˜ë˜ëŠ” ì™„ì „í•œ 8ë‹¨ê³„ ê°€ìƒ í”¼íŒ… íŒŒì´í”„ë¼ì¸
    - ìˆ˜ì •ëœ step í´ë˜ìŠ¤ ìƒì„±ì í˜¸í™˜ (device ì¸ì ë¬¸ì œ í•´ê²°)
    - í”„ë¡œë•ì…˜ ë ˆë²¨ í’ˆì§ˆê³¼ ì•ˆì •ì„±
    - M3 Max MPS ìµœì í™”
    - ìƒì„¸í•œ í’ˆì§ˆ ë¶„ì„ ë° ê°œì„  ì œì•ˆ
    - ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± ë° ì—ëŸ¬ ë³µêµ¬
    """
    
    def __init__(self, config_path: Optional[str] = None, device: Optional[str] = None):
        """
        íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™”
        
        Args:
            config_path: ì„¤ì • íŒŒì¼ ê²½ë¡œ (ì„ íƒì )
            device: ì‚¬ìš©í•  ë””ë°”ì´ìŠ¤ ('auto', 'cpu', 'cuda', 'mps')
        """
        # ê¸°ì¡´ ìœ í‹¸ë¦¬í‹°ë“¤ ì´ˆê¸°í™” (ì•ˆì „í•˜ê²Œ)
        self.model_loader = ModelLoader() if ModelLoader else None
        self.memory_manager = MemoryManager() if MemoryManager else None
        self.data_converter = DataConverter() if DataConverter else None
        
        # ë””ë°”ì´ìŠ¤ ìµœì í™”
        self.device = device or self._get_optimal_device()
        self._configure_device_optimizations()
        
        # ì„¤ì • ë¡œë“œ
        self.config = self._load_config(config_path)
        
        # íŒŒì´í”„ë¼ì¸ ì„¤ì •
        self.pipeline_config = self.config.get('pipeline', {
            'quality_level': 'high',
            'processing_mode': 'complete',
            'enable_optimization': True,
            'enable_caching': True,
            'parallel_processing': True,
            'memory_optimization': True,
            'enable_intermediate_saving': False,
            'max_retries': 3,
            'timeout_seconds': 300
        })
        
        # 8ë‹¨ê³„ ì»´í¬ë„ŒíŠ¸
        self.steps = {}
        self.step_order = [
            'human_parsing',           # 1ë‹¨ê³„: ì¸ì²´ íŒŒì‹±
            'pose_estimation',         # 2ë‹¨ê³„: í¬ì¦ˆ ì¶”ì •
            'cloth_segmentation',      # 3ë‹¨ê³„: ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜
            'geometric_matching',      # 4ë‹¨ê³„: ê¸°í•˜í•™ì  ë§¤ì¹­
            'cloth_warping',          # 5ë‹¨ê³„: ì˜· ì›Œí•‘
            'virtual_fitting',        # 6ë‹¨ê³„: ê°€ìƒ í”¼íŒ… ìƒì„±
            'post_processing',        # 7ë‹¨ê³„: í›„ì²˜ë¦¬
            'quality_assessment'      # 8ë‹¨ê³„: í’ˆì§ˆ í‰ê°€
        ]
        
        # ìƒíƒœ ê´€ë¦¬
        self.is_initialized = False
        self.processing_stats = {}
        self.session_data = {}
        self.error_history = []
        
        # ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
        self.performance_metrics = {
            'total_sessions': 0,
            'successful_sessions': 0,
            'average_processing_time': 0.0,
            'average_quality_score': 0.0
        }
        
        # ìŠ¤ë ˆë“œ í’€ (ë³‘ë ¬ ì²˜ë¦¬ìš©)
        self.thread_pool = ThreadPoolExecutor(max_workers=4)
        
        logger.info(f"ğŸš€ ìˆ˜ì •ëœ ê°€ìƒ í”¼íŒ… íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” - ë””ë°”ì´ìŠ¤: {self.device}")
        logger.info(f"ğŸ“Š íŒŒì´í”„ë¼ì¸ ëª¨ë“œ: {self.pipeline_config['processing_mode']}")
        logger.info(f"ğŸ¯ í’ˆì§ˆ ë ˆë²¨: {self.pipeline_config['quality_level']}")
    
    def _get_optimal_device(self) -> str:
        """ìµœì  ë””ë°”ì´ìŠ¤ ìë™ ì„ íƒ"""
        if torch.backends.mps.is_available():
            return 'mps'
        elif torch.cuda.is_available():
            return 'cuda'
        else:
            return 'cpu'
    
    def _configure_device_optimizations(self):
        """ë””ë°”ì´ìŠ¤ë³„ ìµœì í™” ì„¤ì • (MPS empty_cache ì˜¤ë¥˜ ìˆ˜ì •)"""
        try:
            import gc
            import torch
            
            if self.device == 'mps':
                logger.info("ğŸ M3 Max MPS ë””ë°”ì´ìŠ¤ ìµœì í™” ì‹œì‘...")
                
                # í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
                os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '1'
                
                # ë©”ëª¨ë¦¬ ì •ë¦¬
                gc.collect()
                
                # PyTorch ë²„ì „ë³„ MPS ìµœì í™” ì²˜ë¦¬
                try:
                    pytorch_version = torch.__version__
                    
                    # MPS ë°±ì—”ë“œ ì´ˆê¸°í™” í…ŒìŠ¤íŠ¸
                    if torch.backends.mps.is_available():
                        # ê°„ë‹¨í•œ í…ì„œ ì—°ì‚°ìœ¼ë¡œ MPS ì´ˆê¸°í™”
                        test_tensor = torch.randn(1, 1).to(self.device)
                        _ = test_tensor + 1
                        del test_tensor
                        logger.info("ğŸ M3 Max MPS ë°±ì—”ë“œ ì´ˆê¸°í™” ì™„ë£Œ")
                        
                        # MPS empty_cache ì§€ì› ì—¬ë¶€ í™•ì¸
                        if hasattr(torch.backends.mps, 'empty_cache'):
                            torch.backends.mps.empty_cache()
                            logger.info("âœ… MPS empty_cache ì‚¬ìš©")
                        else:
                            logger.info(f"â„¹ï¸ PyTorch {pytorch_version}: MPS empty_cache ë¯¸ì§€ì› - ëŒ€ì²´ ë©”ëª¨ë¦¬ ê´€ë¦¬ ì‚¬ìš©")
                            
                            # ëŒ€ì²´ ë©”ëª¨ë¦¬ ê´€ë¦¬
                            if hasattr(torch.mps, 'synchronize'):
                                torch.mps.synchronize()
                                logger.info("âœ… MPS synchronize ëŒ€ì²´ ì‚¬ìš©")
                            
                            # ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ìœ¼ë¡œ ëŒ€ì²´
                            gc.collect()
                            logger.info("âœ… ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ìœ¼ë¡œ ë©”ëª¨ë¦¬ ì •ë¦¬")
                    else:
                        logger.warning("âš ï¸ MPS ì‚¬ìš© ë¶ˆê°€ - CPUë¡œ í´ë°±")
                        self.device = "cpu"
                        
                except Exception as mps_error:
                    logger.warning(f"MPS ì´ˆê¸°í™” ì‹¤íŒ¨: {mps_error}")
                    # ì™„ì „ ì•ˆì „ ëª¨ë“œë¡œ í´ë°±
                    gc.collect()
                    logger.info("ğŸš¨ ì•ˆì „ ëª¨ë“œë¡œ ë©”ëª¨ë¦¬ ê´€ë¦¬")
                
                logger.info("ğŸ M3 Max ë©”ëª¨ë¦¬ ìµœì í™” ì™„ë£Œ")
                
            elif self.device == 'cuda':
                logger.info("ğŸ® CUDA ë””ë°”ì´ìŠ¤ ìµœì í™” ì‹œì‘...")
                torch.backends.cudnn.benchmark = True
                torch.backends.cudnn.enabled = True
                torch.backends.cudnn.deterministic = False
                
                if torch.cuda.is_available():
                    torch.cuda.empty_cache()
                    logger.info("âœ… CUDA ë©”ëª¨ë¦¬ ìºì‹œ ì •ë¦¬ ì™„ë£Œ")
                    
                logger.info("ğŸ® CUDA ìµœì í™” ì™„ë£Œ")
                
            else:
                logger.info("âš¡ CPU ë””ë°”ì´ìŠ¤ ìµœì í™” ì‹œì‘...")
                
                if hasattr(torch, 'set_num_threads'):
                    # M3 Maxì˜ íš¨ìœ¨ ì½”ì–´ í™œìš©
                    num_threads = 4
                    torch.set_num_threads(num_threads)
                    logger.info(f"âš¡ CPU ìŠ¤ë ˆë“œ ìˆ˜ ì„¤ì •: {num_threads}")
                    
                logger.info("âš¡ CPU ìµœì í™” ì™„ë£Œ")
            
            # í˜¼í•© ì •ë°€ë„ ì„¤ì •
            if self.device in ['cuda', 'mps']:
                self.use_amp = True
                logger.info("âš¡ í˜¼í•© ì •ë°€ë„ ì—°ì‚° í™œì„±í™”")
            else:
                self.use_amp = False
                
            logger.info(f"âœ… {self.device.upper()} ë””ë°”ì´ìŠ¤ ìµœì í™” ì™„ë£Œ")
                
        except Exception as e:
            logger.error(f"âŒ ë””ë°”ì´ìŠ¤ ìµœì í™” ì‹¤íŒ¨: {e}")
            # ì˜¤ë¥˜ê°€ ë°œìƒí•´ë„ ì´ˆê¸°í™”ëŠ” ê³„ì† ì§„í–‰
            self.device = "cpu"  # ì•ˆì „í•œ í´ë°±
            self.use_amp = False
            logger.info("ğŸ”„ ì•ˆì „ ëª¨ë“œë¡œ í´ë°± - CPU ì‚¬ìš©")

    async def initialize(self) -> bool:
        """ì „ì²´ íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” - ìˆ˜ì •ëœ í´ë˜ìŠ¤ë“¤ê³¼ í˜¸í™˜"""
        try:
            logger.info("ğŸ”„ ìˆ˜ì •ëœ 8ë‹¨ê³„ ê°€ìƒ í”¼íŒ… íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” ì‹œì‘...")
            start_time = time.time()
            
            # Step í´ë˜ìŠ¤ import í™•ì¸
            if not STEPS_IMPORT_SUCCESS:
                logger.warning("âš ï¸ Step í´ë˜ìŠ¤ë“¤ì„ importí•  ìˆ˜ ì—†ì–´ ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œë¡œ ì§„í–‰")
                return await self._initialize_simulation_mode()
            
            # ë©”ëª¨ë¦¬ ì •ë¦¬
            self._cleanup_memory()
            
            # ê° ë‹¨ê³„ ìˆœì°¨ì  ì´ˆê¸°í™” (ìˆ˜ì •ëœ ìƒì„±ì ì‹œê·¸ë‹ˆì²˜ ì ìš©)
            await self._initialize_all_steps()
            
            # ì´ˆê¸°í™” ê²€ì¦
            initialization_success = await self._verify_initialization()
            
            if not initialization_success:
                raise RuntimeError("ì¼ë¶€ ë‹¨ê³„ ì´ˆê¸°í™” ì‹¤íŒ¨")
            
            initialization_time = time.time() - start_time
            self.processing_stats['initialization_time'] = initialization_time
            
            self.is_initialized = True
            logger.info(f"âœ… ì „ì²´ íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” ì™„ë£Œ - ì†Œìš”ì‹œê°„: {initialization_time:.2f}ì´ˆ")
            
            # ì‹œìŠ¤í…œ ìƒíƒœ ì¶œë ¥
            await self._print_system_status()
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            logger.error(f"ğŸ“‹ ì˜¤ë¥˜ ìƒì„¸: {traceback.format_exc()}")
            
            # ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œë¡œ í´ë°±
            logger.info("ğŸ”„ ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œë¡œ í´ë°± ì‹œë„...")
            return await self._initialize_simulation_mode()

    async def _initialize_simulation_mode(self) -> bool:
        """ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œ ì´ˆê¸°í™”"""
        try:
            logger.info("ğŸ­ ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œë¡œ íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™”...")
            
            # ì‹œë®¬ë ˆì´ì…˜ ë‹¨ê³„ë“¤ ìƒì„±
            for step_name in self.step_order:
                self.steps[step_name] = self._create_fallback_step(step_name)
                logger.info(f"ğŸ­ {step_name} ì‹œë®¬ë ˆì´ì…˜ ë‹¨ê³„ ìƒì„±ë¨")
            
            self.is_initialized = True
            self.pipeline_config['processing_mode'] = 'simulation'
            
            logger.info("âœ… ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œ ì´ˆê¸°í™” ì™„ë£Œ")
            return True
            
        except Exception as e:
            logger.error(f"âŒ ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œ ì´ˆê¸°í™”ë„ ì‹¤íŒ¨: {e}")
            self.is_initialized = False
            return False
    
    async def _initialize_all_steps(self):
        """ëª¨ë“  ë‹¨ê³„ ì´ˆê¸°í™” - ìˆ˜ì •ëœ í´ë˜ìŠ¤ ìƒì„±ìì— ë§ì¶¤"""
        
        # 1ë‹¨ê³„: ì¸ì²´ íŒŒì‹± (ìˆ˜ì •ëœ ìƒì„±ì: device ì¸ì)
        logger.info("1ï¸âƒ£ ì¸ì²´ íŒŒì‹± ì´ˆê¸°í™”...")
        try:
            self.steps['human_parsing'] = HumanParsingStep(
                device=self.device,
                config=self._get_step_config('human_parsing')
            )
            await self._safe_initialize_step('human_parsing')
        except Exception as e:
            logger.warning(f"âš ï¸ ì¸ì²´ íŒŒì‹± ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.steps['human_parsing'] = self._create_fallback_step('human_parsing')
        
        # 2ë‹¨ê³„: í¬ì¦ˆ ì¶”ì • (ìˆ˜ì •ëœ ìƒì„±ì: device ì¸ì)
        logger.info("2ï¸âƒ£ í¬ì¦ˆ ì¶”ì • ì´ˆê¸°í™”...")
        try:
            self.steps['pose_estimation'] = PoseEstimationStep(
                device=self.device,
                config=self._get_step_config('pose_estimation')
            )
            await self._safe_initialize_step('pose_estimation')
        except Exception as e:
            logger.warning(f"âš ï¸ í¬ì¦ˆ ì¶”ì • ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.steps['pose_estimation'] = self._create_fallback_step('pose_estimation')
        
        # 3ë‹¨ê³„: ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ (ìˆ˜ì •ëœ ìƒì„±ì: device ì¸ì)
        logger.info("3ï¸âƒ£ ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ ì´ˆê¸°í™”...")
        try:
            self.steps['cloth_segmentation'] = ClothSegmentationStep(
                device=self.device,
                config=self._get_step_config('cloth_segmentation')
            )
            await self._safe_initialize_step('cloth_segmentation')
        except Exception as e:
            logger.warning(f"âš ï¸ ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.steps['cloth_segmentation'] = self._create_fallback_step('cloth_segmentation')
        
        # 4ë‹¨ê³„: ê¸°í•˜í•™ì  ë§¤ì¹­ (ìˆ˜ì •ëœ ìƒì„±ì: device ì¸ì)
        logger.info("4ï¸âƒ£ ê¸°í•˜í•™ì  ë§¤ì¹­ ì´ˆê¸°í™”...")
        try:
            self.steps['geometric_matching'] = GeometricMatchingStep(
                device=self.device,
                config=self._get_step_config('geometric_matching')
            )
            await self._safe_initialize_step('geometric_matching')
        except Exception as e:
            logger.warning(f"âš ï¸ ê¸°í•˜í•™ì  ë§¤ì¹­ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.steps['geometric_matching'] = self._create_fallback_step('geometric_matching')
        
        # 5ë‹¨ê³„: ì˜· ì›Œí•‘ (ìˆ˜ì •ëœ ìƒì„±ì: device ì¸ì)
        logger.info("5ï¸âƒ£ ì˜· ì›Œí•‘ ì´ˆê¸°í™”...")
        try:
            self.steps['cloth_warping'] = ClothWarpingStep(
                device=self.device,
                config=self._get_step_config('cloth_warping')
            )
            await self._safe_initialize_step('cloth_warping')
        except Exception as e:
            logger.warning(f"âš ï¸ ì˜· ì›Œí•‘ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.steps['cloth_warping'] = self._create_fallback_step('cloth_warping')
        
        # 6ë‹¨ê³„: ê°€ìƒ í”¼íŒ… (ìˆ˜ì •ëœ ìƒì„±ì: device ì¸ì)
        logger.info("6ï¸âƒ£ ê°€ìƒ í”¼íŒ… ìƒì„± ì´ˆê¸°í™”...")
        try:
            self.steps['virtual_fitting'] = VirtualFittingStep(
                device=self.device,
                config=self._get_step_config('virtual_fitting')
            )
            await self._safe_initialize_step('virtual_fitting')
        except Exception as e:
            logger.warning(f"âš ï¸ ê°€ìƒ í”¼íŒ… ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.steps['virtual_fitting'] = self._create_fallback_step('virtual_fitting')
        
        # 7ë‹¨ê³„: í›„ì²˜ë¦¬ (ìˆ˜ì •ëœ ìƒì„±ì: device ì¸ì)
        logger.info("7ï¸âƒ£ í›„ì²˜ë¦¬ ì´ˆê¸°í™”...")
        try:
            self.steps['post_processing'] = PostProcessingStep(
                device=self.device,
                config=self._get_step_config('post_processing')
            )
            await self._safe_initialize_step('post_processing')
        except Exception as e:
            logger.warning(f"âš ï¸ í›„ì²˜ë¦¬ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.steps['post_processing'] = self._create_fallback_step('post_processing')
        
        # 8ë‹¨ê³„: í’ˆì§ˆ í‰ê°€ (ìˆ˜ì •ëœ ìƒì„±ì: device ì¸ì)
        logger.info("8ï¸âƒ£ í’ˆì§ˆ í‰ê°€ ì´ˆê¸°í™”...")
        try:
            self.steps['quality_assessment'] = QualityAssessmentStep(
                device=self.device,
                config=self._get_step_config('quality_assessment')
            )
            await self._safe_initialize_step('quality_assessment')
        except Exception as e:
            logger.warning(f"âš ï¸ í’ˆì§ˆ í‰ê°€ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.steps['quality_assessment'] = self._create_fallback_step('quality_assessment')
    
    def _get_step_config(self, step_name: str) -> Dict[str, Any]:
        """ë‹¨ê³„ë³„ ì„¤ì • ìƒì„±"""
        base_config = {
            'quality_level': self.pipeline_config['quality_level'],
            'enable_optimization': self.pipeline_config['enable_optimization'],
            'memory_optimization': self.pipeline_config['memory_optimization']
        }
        
        # ë‹¨ê³„ë³„ íŠ¹í™” ì„¤ì •
        step_specific_configs = {
            'human_parsing': {
                'use_coreml': True,
                'enable_quantization': True,
                'input_size': (512, 512),
                'num_classes': 20,
                'cache_size': 50,
                'batch_size': 1,
                'model_name': 'graphonomy'
            },
            'pose_estimation': {
                'model_type': 'openpose',
                'input_size': (368, 368),
                'confidence_threshold': 0.1,
                'use_gpu': self.device != 'cpu'
            },
            'cloth_segmentation': {
                'model_name': 'u2net',
                'background_threshold': 0.5,
                'post_process': True,
                'refine_edges': True
            },
            'geometric_matching': {
                'tps_points': 25,
                'matching_threshold': 0.8,
                'use_advanced_matching': True
            },
            'cloth_warping': {
                'warping_method': 'tps',
                'physics_simulation': True,
                'fabric_simulation': True,
                'optimization_level': 'high'
            },
            'virtual_fitting': {
                'blending_method': 'poisson',
                'seamless_cloning': True,
                'color_transfer': True
            },
            'post_processing': {
                'enable_super_resolution': True,
                'enhance_faces': True,
                'color_correction': True,
                'noise_reduction': True
            },
            'quality_assessment': {
                'enable_detailed_analysis': True,
                'perceptual_metrics': True,
                'technical_metrics': True
            }
        }
        
        step_config = base_config.copy()
        if step_name in step_specific_configs:
            step_config.update(step_specific_configs[step_name])
        
        return step_config
    
    def _create_fallback_step(self, step_name: str):
        """í´ë°± ë‹¨ê³„ í´ë˜ìŠ¤ ìƒì„±"""
        
        class FallbackStep:
            def __init__(self, device='cpu', config=None):
                self.device = device
                self.config = config or {}
                self.is_initialized = False
                self.step_name = step_name
            
            async def initialize(self):
                self.is_initialized = True
                return True
            
            async def process(self, *args, **kwargs):
                await asyncio.sleep(0.1)  # ì²˜ë¦¬ ì‹œë®¬ë ˆì´ì…˜
                return {
                    'success': True,
                    'fallback': True,
                    'step_name': self.step_name,
                    'confidence': 0.6,
                    'processing_time': 0.1,
                    'method': 'fallback'
                }
            
            async def cleanup(self):
                pass
        
        logger.info(f"ğŸš¨ {step_name} í´ë°± í´ë˜ìŠ¤ ìƒì„±")
        return FallbackStep(device=self.device, config=self._get_step_config(step_name))
    
    async def _safe_initialize_step(self, step_name: str):
        """ì•ˆì „í•œ ë‹¨ê³„ ì´ˆê¸°í™”"""
        try:
            step = self.steps[step_name]
            if hasattr(step, 'initialize'):
                await step.initialize()
            logger.info(f"âœ… {step_name} ì´ˆê¸°í™” ì™„ë£Œ")
        except Exception as e:
            logger.warning(f"âš ï¸ {step_name} ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    
    async def _verify_initialization(self) -> bool:
        """ì´ˆê¸°í™” ê²€ì¦"""
        total_steps = len(self.step_order)
        initialized_steps = len(self.steps)
        
        success_rate = initialized_steps / total_steps
        logger.info(f"ğŸ“Š ì´ˆê¸°í™” ì„±ê³µë¥ : {success_rate:.1%} ({initialized_steps}/{total_steps})")
        
        return success_rate >= 0.8  # 80% ì´ìƒ ì„±ê³µí•˜ë©´ ì§„í–‰
    
    async def process_complete_virtual_fitting(
        self,
        person_image: Union[str, Image.Image, np.ndarray],
        clothing_image: Union[str, Image.Image, np.ndarray],
        body_measurements: Optional[Dict[str, float]] = None,
        clothing_type: str = "shirt",
        fabric_type: str = "cotton",
        style_preferences: Optional[Dict[str, Any]] = None,
        quality_target: float = 0.8,
        progress_callback: Optional[Callable] = None,
        save_intermediate: bool = False,
        enable_auto_retry: bool = True
    ) -> Dict[str, Any]:
        """
        ìˆ˜ì •ëœ í´ë˜ìŠ¤ë“¤ê³¼ í˜¸í™˜ë˜ëŠ” ì™„ì „í•œ 8ë‹¨ê³„ ê°€ìƒ í”¼íŒ… ì²˜ë¦¬
        """
        if not self.is_initialized:
            raise RuntimeError("íŒŒì´í”„ë¼ì¸ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. initialize()ë¥¼ ë¨¼ì € í˜¸ì¶œí•˜ì„¸ìš”.")
        
        start_time = time.time()
        session_id = f"vf_{int(time.time())}_{np.random.randint(1000, 9999)}"
        
        self.performance_metrics['total_sessions'] += 1
        
        try:
            logger.info(f"ğŸ¯ ìˆ˜ì •ëœ 8ë‹¨ê³„ ê°€ìƒ í”¼íŒ… ì‹œì‘ - ì„¸ì…˜ ID: {session_id}")
            logger.info(f"âš™ï¸ ì„¤ì •: {clothing_type} ({fabric_type}), í’ˆì§ˆëª©í‘œ: {quality_target}")
            
            # ì…ë ¥ ê²€ì¦ ë° ì „ì²˜ë¦¬
            person_tensor, clothing_tensor = await self._preprocess_inputs(
                person_image, clothing_image
            )
            
            # ì„¸ì…˜ ë°ì´í„° ì´ˆê¸°í™”
            self._initialize_session_data(session_id, start_time, {
                'clothing_type': clothing_type,
                'fabric_type': fabric_type,
                'quality_target': quality_target,
                'style_preferences': style_preferences or {},
                'processing_mode': self.pipeline_config['processing_mode']
            })
            
            if progress_callback:
                await progress_callback("ì…ë ¥ ì „ì²˜ë¦¬ ì™„ë£Œ", 5)
            
            # ë©”ëª¨ë¦¬ ìµœì í™”
            if self.pipeline_config['memory_optimization']:
                self._optimize_memory_usage()
            
            # ===========================================
            # 8ë‹¨ê³„ ìˆœì°¨ ì²˜ë¦¬ (ìˆ˜ì •ëœ í´ë˜ìŠ¤ë“¤ ì‚¬ìš©)
            # ===========================================
            
            # 1ë‹¨ê³„: ì¸ì²´ íŒŒì‹±
            parsing_result = await self._execute_step_with_retry(
                'human_parsing', 1, person_tensor, progress_callback, 18
            )
            
            # 2ë‹¨ê³„: í¬ì¦ˆ ì¶”ì •
            pose_result = await self._execute_step_with_retry(
                'pose_estimation', 2, person_tensor, progress_callback, 31
            )
            
            # 3ë‹¨ê³„: ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜
            segmentation_result = await self._execute_step_with_retry(
                'cloth_segmentation', 3, clothing_tensor, progress_callback, 44,
                extra_args={'clothing_type': clothing_type}
            )
            
            # 4ë‹¨ê³„: ê¸°í•˜í•™ì  ë§¤ì¹­
            matching_result = await self._execute_step_with_retry(
                'geometric_matching', 4, 
                (segmentation_result, pose_result, parsing_result),
                progress_callback, 57
            )
            
            # 5ë‹¨ê³„: ì˜· ì›Œí•‘
            warping_result = await self._execute_step_with_retry(
                'cloth_warping', 5,
                (matching_result, body_measurements, fabric_type),
                progress_callback, 70
            )
            
            # 6ë‹¨ê³„: ê°€ìƒ í”¼íŒ… ìƒì„±
            fitting_result = await self._execute_step_with_retry(
                'virtual_fitting', 6,
                (person_tensor, warping_result, parsing_result, pose_result),
                progress_callback, 83
            )
            
            # 7ë‹¨ê³„: í›„ì²˜ë¦¬
            post_processing_result = await self._execute_step_with_retry(
                'post_processing', 7, fitting_result, progress_callback, 91
            )
            
            # 8ë‹¨ê³„: í’ˆì§ˆ í‰ê°€
            quality_result = await self._execute_step_with_retry(
                'quality_assessment', 8,
                (post_processing_result, person_tensor, clothing_tensor, 
                 parsing_result, pose_result, warping_result, fitting_result),
                progress_callback, 96
            )
            
            # ===========================================
            # ìµœì¢… ê²°ê³¼ êµ¬ì„± ë° ë¶„ì„
            # ===========================================
            
            total_time = time.time() - start_time
            
            # ìµœì¢… ê²°ê³¼ ì´ë¯¸ì§€ ì¶”ì¶œ
            final_image_tensor = self._extract_final_image(
                post_processing_result, fitting_result, person_tensor
            )
            final_image_pil = self._tensor_to_pil(final_image_tensor)
            
            # ì¢…í•© í’ˆì§ˆ ë¶„ì„
            comprehensive_quality = await self._comprehensive_quality_analysis(
                quality_result, self.session_data[session_id]
            )
            
            # ì²˜ë¦¬ í†µê³„ ê³„ì‚°
            processing_statistics = self._calculate_detailed_statistics(session_id, total_time)
            
            # ê°œì„  ì œì•ˆ ìƒì„±
            improvement_suggestions = await self._generate_detailed_suggestions(
                comprehensive_quality, processing_statistics, clothing_type, fabric_type
            )
            
            # ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
            self.performance_metrics['successful_sessions'] += 1
            self._update_performance_metrics(total_time, comprehensive_quality['overall_score'])
            
            # ìµœì¢… ê²°ê³¼ êµ¬ì„±
            final_result = {
                'success': True,
                'session_id': session_id,
                'processing_mode': self.pipeline_config['processing_mode'],
                'quality_level': self.pipeline_config['quality_level'],
                
                # ê²°ê³¼ ì´ë¯¸ì§€ë“¤
                'result_image': final_image_pil,
                'result_image_tensor': final_image_tensor,
                'original_person_image': self._tensor_to_pil(person_tensor),
                'original_clothing_image': self._tensor_to_pil(clothing_tensor),
                
                # í’ˆì§ˆ ë©”íŠ¸ë¦­
                'final_quality_score': comprehensive_quality['overall_score'],
                'quality_grade': comprehensive_quality['quality_grade'],
                'quality_confidence': comprehensive_quality['confidence'],
                'quality_breakdown': comprehensive_quality['breakdown'],
                'quality_target_achieved': comprehensive_quality['overall_score'] >= quality_target,
                
                # ê°œì„  ì œì•ˆ
                'improvement_suggestions': improvement_suggestions,
                'next_steps': self._generate_next_steps(comprehensive_quality, quality_target),
                
                # ì²˜ë¦¬ í†µê³„
                'processing_statistics': processing_statistics,
                'total_processing_time': total_time,
                'device_used': self.device,
                'memory_usage': self._get_detailed_memory_usage(),
                'performance_metrics': self.performance_metrics.copy(),
                
                # ë‹¨ê³„ë³„ ê²°ê³¼
                'step_results_summary': self._create_detailed_step_summary(session_id),
                
                # ì¤‘ê°„ ê²°ê³¼ (ì„ íƒì )
                'intermediate_results': (
                    self.session_data[session_id]['intermediate_results'] 
                    if save_intermediate else {}
                ),
                
                # ë©”íƒ€ë°ì´í„°
                'metadata': {
                    'timestamp': datetime.now().isoformat(),
                    'pipeline_version': '3.0.0',
                    'input_resolution': f"{person_tensor.shape[3]}x{person_tensor.shape[2]}",
                    'output_resolution': f"{final_image_pil.width}x{final_image_pil.height}",
                    'clothing_type': clothing_type,
                    'fabric_type': fabric_type,
                    'body_measurements_provided': body_measurements is not None,
                    'style_preferences_provided': bool(style_preferences),
                    'intermediate_results_saved': save_intermediate,
                    'device_optimization': self.device,
                    'updated_classes_used': True  # ìˆ˜ì •ëœ í´ë˜ìŠ¤ë“¤ ì‚¬ìš© í‘œì‹œ
                }
            }
            
            # ì„¸ì…˜ ë°ì´í„° ì •ë¦¬
            if not save_intermediate:
                self._cleanup_session_data(session_id)
            
            if progress_callback:
                await progress_callback("ì²˜ë¦¬ ì™„ë£Œ", 100)
            
            logger.info(
                f"ğŸ‰ ìˆ˜ì •ëœ 8ë‹¨ê³„ ê°€ìƒ í”¼íŒ… ì™„ë£Œ! "
                f"ì „ì²´ ì†Œìš”ì‹œê°„: {total_time:.2f}ì´ˆ, "
                f"ìµœì¢… í’ˆì§ˆ: {comprehensive_quality['overall_score']:.3f} ({comprehensive_quality['quality_grade']}), "
                f"ëª©í‘œ ë‹¬ì„±: {'âœ…' if comprehensive_quality['overall_score'] >= quality_target else 'âŒ'}"
            )
            
            return final_result
            
        except Exception as e:
            # ì—ëŸ¬ ì²˜ë¦¬ ë° ë³µêµ¬
            error_result = await self._handle_processing_error(
                e, session_id, start_time, person_image, clothing_image,
                enable_auto_retry
            )
            return error_result
    
    async def _execute_step_with_retry(
        self,
        step_name: str,
        step_number: int,
        input_data: Any,
        progress_callback: Optional[Callable],
        progress_percentage: int,
        extra_args: Optional[Dict] = None,
        max_retries: int = 3
    ) -> Dict[str, Any]:
        """ì¬ì‹œë„ ë¡œì§ì´ í¬í•¨ëœ ë‹¨ê³„ ì‹¤í–‰"""
        
        step_start = time.time()
        last_error = None
        
        for attempt in range(max_retries + 1):
            try:
                logger.info(f"{'ğŸ”„' if attempt > 0 else ''} {step_number}ë‹¨ê³„: {step_name} ì²˜ë¦¬ ì¤‘... {'(ì¬ì‹œë„ ' + str(attempt) + ')' if attempt > 0 else ''}")
                
                # ë©”ëª¨ë¦¬ ì •ë¦¬ (ì¬ì‹œë„ ì‹œ)
                if attempt > 0:
                    self._cleanup_memory()
                
                # ë‹¨ê³„ ì‹¤í–‰
                result = await self._execute_single_step(step_name, input_data, extra_args)
                
                # ê²°ê³¼ ê²€ì¦
                if self._validate_step_result(step_name, result):
                    step_time = time.time() - step_start
                    
                    # ì„¸ì…˜ ë°ì´í„° ì €ì¥
                    session_id = list(self.session_data.keys())[-1] if self.session_data else 'unknown'
                    if session_id in self.session_data:
                        self.session_data[session_id]['step_times'][step_name] = step_time
                        self.session_data[session_id]['step_results'][step_name] = result
                        
                        if self.pipeline_config.get('enable_intermediate_saving', False):
                            self.session_data[session_id]['intermediate_results'][step_name] = result
                    
                    # í’ˆì§ˆ ì ìˆ˜ ë¡œê¹…
                    quality_score = result.get('confidence', result.get('quality_score', 0.8))
                    logger.info(f"âœ… {step_number}ë‹¨ê³„ ì™„ë£Œ - ì†Œìš”ì‹œê°„: {step_time:.2f}ì´ˆ, í’ˆì§ˆ: {quality_score:.3f}")
                    
                    # ì§„í–‰ë¥  ì½œë°±
                    if progress_callback:
                        await progress_callback(f"{step_name}_complete", progress_percentage)
                    
                    return result
                else:
                    raise ValueError(f"Step {step_name} result validation failed")
                    
            except Exception as e:
                last_error = e
                logger.warning(f"âš ï¸ {step_number}ë‹¨ê³„ ì‹œë„ {attempt + 1} ì‹¤íŒ¨: {e}")
                
                if attempt < max_retries:
                    wait_time = 2 ** attempt
                    logger.info(f"ğŸ”„ {wait_time}ì´ˆ í›„ ì¬ì‹œë„...")
                    await asyncio.sleep(wait_time)
                else:
                    logger.error(f"âŒ {step_number}ë‹¨ê³„ ìµœì¢… ì‹¤íŒ¨: {e}")
        
        # ëª¨ë“  ì¬ì‹œë„ ì‹¤íŒ¨ ì‹œ í´ë°± ê²°ê³¼ ìƒì„±
        logger.warning(f"ğŸš¨ {step_name} í´ë°± ê²°ê³¼ ìƒì„± ì¤‘...")
        return self._create_fallback_step_result(step_name, input_data, last_error)
    
    async def _execute_single_step(
        self, 
        step_name: str, 
        input_data: Any, 
        extra_args: Optional[Dict] = None
    ) -> Dict[str, Any]:
        """ë‹¨ì¼ ë‹¨ê³„ ì‹¤í–‰ - ìˆ˜ì •ëœ í´ë˜ìŠ¤ë“¤ê³¼ í˜¸í™˜"""
        
        step = self.steps.get(step_name)
        if not step:
            raise ValueError(f"Step {step_name} not found")
        
        # ìˆ˜ì •ëœ í´ë˜ìŠ¤ë“¤ì˜ process ë©”ì„œë“œ í˜¸ì¶œ
        if step_name == 'human_parsing':
            return await step.process(input_data)
                
        elif step_name == 'pose_estimation':
            return await step.process(input_data)
                
        elif step_name == 'cloth_segmentation':
            clothing_type = extra_args.get('clothing_type', 'shirt') if extra_args else 'shirt'
            return await step.process(input_data, clothing_type=clothing_type)
                
        elif step_name == 'geometric_matching':
            segmentation_result, pose_result, parsing_result = input_data
            return await step.process(segmentation_result, pose_result, parsing_result)
                
        elif step_name == 'cloth_warping':
            matching_result, body_measurements, fabric_type = input_data
            return await step.process(matching_result, body_measurements, fabric_type)
                
        elif step_name == 'virtual_fitting':
            person_tensor, warping_result, parsing_result, pose_result = input_data
            return await step.process(person_tensor, warping_result, parsing_result, pose_result)
                
        elif step_name == 'post_processing':
            return await step.process(input_data)
                
        elif step_name == 'quality_assessment':
            (post_processing_result, person_tensor, clothing_tensor, 
             parsing_result, pose_result, warping_result, fitting_result) = input_data
            return await step.process(
                post_processing_result, person_tensor, clothing_tensor,
                parsing_result, pose_result, warping_result, fitting_result
            )
        
        else:
            raise ValueError(f"Unknown step: {step_name}")
    
    # ========================================
    # í—¬í¼ ë©”ì„œë“œë“¤
    # ========================================
    
    def _validate_step_result(self, step_name: str, result: Dict[str, Any]) -> bool:
        """ë‹¨ê³„ ê²°ê³¼ ê²€ì¦"""
        if not isinstance(result, dict):
            return False
        return result.get('success', True)  # ê¸°ë³¸ì ìœ¼ë¡œ ì„±ê³µìœ¼ë¡œ ê°„ì£¼
    
    def _create_fallback_step_result(
        self, 
        step_name: str, 
        input_data: Any, 
        error: Exception
    ) -> Dict[str, Any]:
        """í´ë°± ë‹¨ê³„ ê²°ê³¼ ìƒì„±"""
        return {
            'success': False,
            'error': str(error),
            'fallback': True,
            'step_name': step_name,
            'confidence': 0.5,
            'processing_time': 0.1,
            'method': 'fallback',
            'timestamp': datetime.now().isoformat()
        }
    
    async def _preprocess_inputs(
        self, 
        person_image: Union[str, Image.Image, np.ndarray],
        clothing_image: Union[str, Image.Image, np.ndarray]
    ) -> Tuple[torch.Tensor, torch.Tensor]:
        """ì…ë ¥ ì´ë¯¸ì§€ ì „ì²˜ë¦¬"""
        try:
            # ë°ì´í„° ë³€í™˜ê¸° ì‚¬ìš©
            if self.data_converter and hasattr(self.data_converter, 'preprocess_image'):
                person_tensor = self.data_converter.preprocess_image(person_image)
                clothing_tensor = self.data_converter.preprocess_image(clothing_image)
            else:
                person_tensor = self._manual_preprocess_image(person_image)
                clothing_tensor = self._manual_preprocess_image(clothing_image)
            
            # ë””ë°”ì´ìŠ¤ë¡œ ì´ë™
            person_tensor = person_tensor.to(self.device)
            clothing_tensor = clothing_tensor.to(self.device)
            
            logger.info(f"âœ… ì…ë ¥ ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì™„ë£Œ - ì‚¬ëŒ: {person_tensor.shape}, ì˜ë¥˜: {clothing_tensor.shape}")
            
            return person_tensor, clothing_tensor
            
        except Exception as e:
            logger.error(f"âŒ ì…ë ¥ ì „ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            raise
    
    def _manual_preprocess_image(self, image_input: Union[str, Image.Image, np.ndarray]) -> torch.Tensor:
        """ìˆ˜ë™ ì´ë¯¸ì§€ ì „ì²˜ë¦¬"""
        if isinstance(image_input, str):
            if not os.path.exists(image_input):
                raise FileNotFoundError(f"ì´ë¯¸ì§€ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {image_input}")
            image = Image.open(image_input).convert('RGB')
        elif isinstance(image_input, Image.Image):
            image = image_input.convert('RGB')
        elif isinstance(image_input, np.ndarray):
            if image_input.dtype != np.uint8:
                image_input = (image_input * 255).astype(np.uint8)
            image = Image.fromarray(image_input).convert('RGB')
        else:
            raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì´ë¯¸ì§€ íƒ€ì…: {type(image_input)}")
        
        # í¬ê¸° ì¡°ì •
        target_size = self.config.get('input_size', (512, 512))
        if image.size != target_size:
            image = image.resize(target_size, Image.Resampling.LANCZOS)
        
        # í…ì„œ ë³€í™˜
        img_array = np.array(image)
        img_tensor = torch.from_numpy(img_array).permute(2, 0, 1).float() / 255.0
        img_tensor = img_tensor.unsqueeze(0)
        
        return img_tensor
    
    def _initialize_session_data(self, session_id: str, start_time: float, config: Dict[str, Any]):
        """ì„¸ì…˜ ë°ì´í„° ì´ˆê¸°í™”"""
        self.session_data[session_id] = {
            'start_time': start_time,
            'config': config,
            'step_times': {},
            'step_results': {},
            'intermediate_results': {},
            'error_log': [],
            'memory_snapshots': [],
            'quality_progression': []
        }
    
    def _optimize_memory_usage(self):
        """ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ìµœì í™”"""
        gc.collect()
        if self.device == 'cuda' and torch.cuda.is_available():
            torch.cuda.empty_cache()
        elif self.device == 'mps' and torch.backends.mps.is_available():
            # PyTorch 2.2.2 í˜¸í™˜ì„± ì²´í¬
            if hasattr(torch.backends.mps, 'empty_cache'):
                torch.backends.mps.empty_cache()
            else:
                # ëŒ€ì²´ ë©”ëª¨ë¦¬ ê´€ë¦¬
                gc.collect()
    
    def _cleanup_memory(self):
        """ë©”ëª¨ë¦¬ ì •ë¦¬"""
        gc.collect()
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
        if hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
            if hasattr(torch.backends.mps, 'empty_cache'):
                torch.backends.mps.empty_cache()
            else:
                # PyTorch 2.2.2 í˜¸í™˜ì„±
                gc.collect()
    
    def _extract_final_image(
        self, 
        post_processing_result: Dict[str, Any],
        fitting_result: Dict[str, Any], 
        person_tensor: torch.Tensor
    ) -> torch.Tensor:
        """ìµœì¢… ê²°ê³¼ ì´ë¯¸ì§€ ì¶”ì¶œ"""
        if 'enhanced_image' in post_processing_result:
            return post_processing_result['enhanced_image']
        elif 'fitted_image' in fitting_result:
            return fitting_result['fitted_image']
        else:
            logger.warning("âš ï¸ ìµœì¢… ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ ì›ë³¸ì„ ë°˜í™˜í•©ë‹ˆë‹¤")
            return person_tensor
    
    def _tensor_to_pil(self, tensor: torch.Tensor) -> Image.Image:
        """í…ì„œë¥¼ PIL ì´ë¯¸ì§€ë¡œ ë³€í™˜"""
        try:
            if tensor.dim() == 4:
                tensor = tensor.squeeze(0)
            
            if tensor.shape[0] == 3:
                tensor = tensor.permute(1, 2, 0)
            
            tensor = torch.clamp(tensor, 0, 1)
            tensor = tensor.cpu()
            array = (tensor.numpy() * 255).astype(np.uint8)
            
            return Image.fromarray(array)
        except Exception as e:
            logger.error(f"âŒ í…ì„œ-PIL ë³€í™˜ ì‹¤íŒ¨: {e}")
            return Image.new('RGB', (512, 512), color='black')
    
    async def _comprehensive_quality_analysis(
        self, 
        quality_result: Dict[str, Any], 
        session_data: Dict[str, Any]
    ) -> Dict[str, Any]:
        """ì¢…í•©ì  í’ˆì§ˆ ë¶„ì„"""
        overall_score = quality_result.get('overall_score', 0.8)
        
        if overall_score >= 0.9:
            quality_grade = "Excellent"
            confidence = 0.95
        elif overall_score >= 0.8:
            quality_grade = "Good"
            confidence = 0.85
        elif overall_score >= 0.7:
            quality_grade = "Acceptable"
            confidence = 0.75
        elif overall_score >= 0.6:
            quality_grade = "Poor"
            confidence = 0.65
        else:
            quality_grade = "Very Poor"
            confidence = 0.5
        
        breakdown = quality_result.get('quality_breakdown', {})
        
        return {
            'overall_score': overall_score,
            'quality_grade': quality_grade,
            'confidence': confidence,
            'breakdown': breakdown,
            'analysis_timestamp': datetime.now().isoformat()
        }
    
    def _calculate_detailed_statistics(self, session_id: str, total_time: float) -> Dict[str, Any]:
        """ìƒì„¸ ì²˜ë¦¬ í†µê³„ ê³„ì‚°"""
        session_data = self.session_data[session_id]
        step_times = session_data['step_times']
        
        stats = {
            'total_time': total_time,
            'step_times': step_times.copy(),
            'steps_completed': len(step_times),
            'success_rate': len(step_times) / len(self.step_order),
            'memory_usage': self._get_detailed_memory_usage(),
            'device_utilization': self._get_device_utilization(),
        }
        
        if step_times:
            times = list(step_times.values())
            stats.update({
                'average_step_time': np.mean(times),
                'fastest_step': {'name': min(step_times, key=step_times.get), 'time': min(times)},
                'slowest_step': {'name': max(step_times, key=step_times.get), 'time': max(times)},
            })
        
        return stats
    
    async def _generate_detailed_suggestions(
        self, 
        quality_analysis: Dict[str, Any], 
        statistics: Dict[str, Any],
        clothing_type: str,
        fabric_type: str
    ) -> Dict[str, List[str]]:
        """ìƒì„¸ ê°œì„  ì œì•ˆ ìƒì„±"""
        suggestions = {
            'quality_improvements': [],
            'performance_optimizations': [],
            'user_experience': [],
            'technical_adjustments': []
        }
        
        overall_score = quality_analysis['overall_score']
        
        if overall_score < 0.8:
            suggestions['quality_improvements'].extend([
                "ğŸ¯ ì „ì²´ì ì¸ í’ˆì§ˆ í–¥ìƒì´ í•„ìš”í•©ë‹ˆë‹¤",
                "ğŸ“· ë” ë†’ì€ í•´ìƒë„ì˜ ì…ë ¥ ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í•´ë³´ì„¸ìš”",
                "ğŸ’¡ ì¡°ëª…ì´ ê· ë“±í•œ í™˜ê²½ì—ì„œ ì´¬ì˜ëœ ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”"
            ])
        
        total_time = statistics['total_time']
        if total_time > 60:
            suggestions['performance_optimizations'].extend([
                "âš¡ ì²˜ë¦¬ ì‹œê°„ì´ ê¸´ í¸ì…ë‹ˆë‹¤. í’ˆì§ˆ ë ˆë²¨ì„ ì¡°ì •í•´ë³´ì„¸ìš”",
                "ğŸ–¥ï¸ ë” ë†’ì€ ì„±ëŠ¥ì˜ ë””ë°”ì´ìŠ¤ ì‚¬ìš©ì„ ê³ ë ¤í•˜ì„¸ìš”"
            ])
        
        suggestions['user_experience'].extend([
            "ğŸ“¸ ì •ë©´ì„ ë°”ë¼ë³´ëŠ” ìì„¸ì˜ ì‚¬ì§„ì´ ê°€ì¥ ì¢‹ì€ ê²°ê³¼ë¥¼ ì œê³µí•©ë‹ˆë‹¤",
            "ğŸ¨ ë‹¨ìƒ‰ ë°°ê²½ì˜ ì˜ë¥˜ ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í•˜ë©´ ë” ì •í™•í•œ ê²°ê³¼ë¥¼ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤"
        ])
        
        if self.device == 'cpu':
            suggestions['technical_adjustments'].append(
                "ğŸš€ GPUë‚˜ MPSë¥¼ ì‚¬ìš©í•˜ë©´ ì²˜ë¦¬ ì†ë„ê°€ í¬ê²Œ í–¥ìƒë©ë‹ˆë‹¤"
            )
        
        return suggestions
    
    def _generate_next_steps(self, quality_analysis: Dict[str, Any], quality_target: float) -> List[str]:
        """ë‹¤ìŒ ë‹¨ê³„ ì œì•ˆ"""
        overall_score = quality_analysis['overall_score']
        next_steps = []
        
        if overall_score >= quality_target:
            next_steps.extend([
                "âœ… ëª©í‘œ í’ˆì§ˆì— ë„ë‹¬í–ˆìŠµë‹ˆë‹¤!",
                "ğŸ’¾ ê²°ê³¼ë¥¼ ì €ì¥í•˜ê³  í™œìš©í•˜ì„¸ìš”",
                "ğŸ”„ ë‹¤ë¥¸ ì˜ë¥˜ë¡œ ì¶”ê°€ í”¼íŒ…ì„ ì‹œë„í•´ë³´ì„¸ìš”"
            ])
        else:
            gap = quality_target - overall_score
            next_steps.extend([
                f"ğŸ¯ ëª©í‘œ í’ˆì§ˆê¹Œì§€ {gap:.2f} ì  í–¥ìƒì´ í•„ìš”í•©ë‹ˆë‹¤",
                "ğŸ”§ ê°œì„  ì œì•ˆì‚¬í•­ì„ ì ìš©í•´ë³´ì„¸ìš”",
                "ğŸ“· ë” ì¢‹ì€ í’ˆì§ˆì˜ ì…ë ¥ ì´ë¯¸ì§€ë¥¼ ì¤€ë¹„í•˜ì„¸ìš”"
            ])
        
        return next_steps
    
    def _create_detailed_step_summary(self, session_id: str) -> Dict[str, Dict[str, Any]]:
        """ìƒì„¸ ë‹¨ê³„ ìš”ì•½ ìƒì„±"""
        session_data = self.session_data[session_id]
        step_times = session_data['step_times']
        step_results = session_data['step_results']
        
        summary = {}
        
        for step_name in self.step_order:
            step_summary = {
                'completed': step_name in step_results,
                'processing_time': step_times.get(step_name, 0),
                'success': step_name in step_results and not step_results[step_name].get('error'),
                'fallback_used': step_results.get(step_name, {}).get('fallback', False)
            }
            
            if step_name in step_results:
                result = step_results[step_name]
                step_summary.update({
                    'confidence': result.get('confidence', 0),
                    'method': result.get('method', 'unknown')
                })
            
            summary[step_name] = step_summary
        
        return summary
    
    def _get_detailed_memory_usage(self) -> Dict[str, str]:
        """ìƒì„¸ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¡°íšŒ"""
        try:
            import psutil
            memory_info = {
                'system_memory': f"{psutil.virtual_memory().percent}%",
                'available_memory': f"{psutil.virtual_memory().available / 1024**3:.1f}GB"
            }
        except ImportError:
            memory_info = {'system_memory': 'N/A', 'available_memory': 'N/A'}
        
        if torch.cuda.is_available():
            memory_info.update({
                'gpu_memory_allocated': f"{torch.cuda.memory_allocated() / 1024**3:.1f}GB",
                'gpu_memory_reserved': f"{torch.cuda.memory_reserved() / 1024**3:.1f}GB"
            })
        
        if hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
            try:
                if hasattr(torch.mps, 'current_allocated_memory'):
                    memory_info['mps_memory'] = f"{torch.mps.current_allocated_memory() / 1024**3:.1f}GB"
                else:
                    memory_info['mps_memory'] = "N/A"
            except:
                memory_info['mps_memory'] = "N/A"
        
        return memory_info
    
    def _get_device_utilization(self) -> Dict[str, Any]:
        """ë””ë°”ì´ìŠ¤ í™œìš©ë„ ì¡°íšŒ"""
        utilization = {
            'device_type': self.device,
            'optimization_enabled': self.pipeline_config['enable_optimization']
        }
        
        if self.device == 'cuda' and torch.cuda.is_available():
            utilization.update({
                'gpu_name': torch.cuda.get_device_name(),
                'compute_capability': torch.cuda.get_device_capability()
            })
        elif self.device == 'mps':
            utilization.update({
                'mps_available': torch.backends.mps.is_available(),
                'mps_built': torch.backends.mps.is_built()
            })
        
        return utilization
    
    def _update_performance_metrics(self, processing_time: float, quality_score: float):
        """ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸"""
        total_sessions = self.performance_metrics['total_sessions']
        
        if total_sessions > 1:
            prev_avg_time = self.performance_metrics['average_processing_time']
            prev_avg_quality = self.performance_metrics['average_quality_score']
            
            self.performance_metrics['average_processing_time'] = (
                (prev_avg_time * (total_sessions - 1) + processing_time) / total_sessions
            )
            self.performance_metrics['average_quality_score'] = (
                (prev_avg_quality * (total_sessions - 1) + quality_score) / total_sessions
            )
        else:
            self.performance_metrics['average_processing_time'] = processing_time
            self.performance_metrics['average_quality_score'] = quality_score
    
    def _cleanup_session_data(self, session_id: str):
        """ì„¸ì…˜ ë°ì´í„° ì •ë¦¬"""
        if session_id in self.session_data:
            del self.session_data[session_id]
            logger.debug(f"ğŸ§¹ ì„¸ì…˜ {session_id} ë°ì´í„° ì •ë¦¬ ì™„ë£Œ")
    
    async def _handle_processing_error(
        self,
        error: Exception,
        session_id: str,
        start_time: float,
        person_image: Union[str, Image.Image, np.ndarray],
        clothing_image: Union[str, Image.Image, np.ndarray],
        enable_auto_retry: bool = True
    ) -> Dict[str, Any]:
        """ì²˜ë¦¬ ì˜¤ë¥˜ í•¸ë“¤ë§ ë° ë³µêµ¬"""
        processing_time = time.time() - start_time
        error_msg = str(error)
        
        # ì˜¤ë¥˜ ê¸°ë¡
        self.error_history.append({
            'session_id': session_id,
            'error': error_msg,
            'error_type': type(error).__name__,
            'timestamp': datetime.now().isoformat(),
            'processing_time': processing_time
        })
        
        logger.error(f"âŒ ê°€ìƒ í”¼íŒ… ì²˜ë¦¬ ì‹¤íŒ¨ - ì„¸ì…˜ {session_id}: {error_msg}")
        
        # ìë™ ë³µêµ¬ ì‹œë„
        if enable_auto_retry and not hasattr(error, '_retry_attempted'):
            logger.info("ğŸ”„ ìë™ ë³µêµ¬ ì‹œë„ ì¤‘...")
            
            try:
                self._cleanup_memory()
                error._retry_attempted = True
                
                # ë‚®ì€ í’ˆì§ˆ ëª¨ë“œë¡œ ì¬ì‹œë„
                original_quality = self.pipeline_config['quality_level']
                self.pipeline_config['quality_level'] = 'medium'
                
                result = await self.process_complete_virtual_fitting(
                    person_image=person_image,
                    clothing_image=clothing_image,
                    quality_target=0.6,
                    enable_auto_retry=False
                )
                
                self.pipeline_config['quality_level'] = original_quality
                
                if result['success']:
                    logger.info("âœ… ìë™ ë³µêµ¬ ì„±ê³µ!")
                    result['recovered'] = True
                    result['recovery_method'] = 'quality_downgrade'
                    return result
                    
            except Exception as retry_error:
                logger.warning(f"âš ï¸ ìë™ ë³µêµ¬ ì‹¤íŒ¨: {retry_error}")
        
        # ê¸°ë³¸ ì˜¤ë¥˜ ê²°ê³¼ ë°˜í™˜
        return {
            'success': False,
            'session_id': session_id,
            'error': error_msg,
            'error_type': 'processing_failure',
            'processing_time': processing_time,
            'timestamp': datetime.now().isoformat(),
            'recovery_attempted': enable_auto_retry,
            'metadata': {
                'pipeline_version': '3.0.0',
                'device': self.device,
                'updated_classes_used': True
            }
        }
    
    def _load_config(self, config_path: Optional[str] = None) -> Dict[str, Any]:
        """ì„¤ì • íŒŒì¼ ë¡œë“œ"""
        default_config = {
            'input_size': (512, 512),
            'pipeline': {
                'quality_level': 'high',
                'processing_mode': 'complete',
                'enable_optimization': True,
                'enable_caching': True,
                'parallel_processing': True,
                'memory_optimization': True,
                'enable_intermediate_saving': False,
                'max_retries': 3,
                'timeout_seconds': 300
            },
            'quality_thresholds': {
                'excellent': 0.9,
                'good': 0.8,
                'acceptable': 0.7,
                'poor': 0.6
            },
            'device_optimization': {
                'enable_mps': True,
                'enable_cuda': True,
                'mixed_precision': True,
                'memory_efficient': True
            }
        }
        
        if config_path and os.path.exists(config_path):
            try:
                with open(config_path, 'r', encoding='utf-8') as f:
                    file_config = json.load(f)
                
                def deep_update(base_dict, update_dict):
                    for key, value in update_dict.items():
                        if key in base_dict and isinstance(base_dict[key], dict) and isinstance(value, dict):
                            deep_update(base_dict[key], value)
                        else:
                            base_dict[key] = value
                
                deep_update(default_config, file_config)
                logger.info(f"âœ… ì„¤ì • íŒŒì¼ ë¡œë“œ ì™„ë£Œ: {config_path}")
                
            except Exception as e:
                logger.warning(f"âš ï¸ ì„¤ì • íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}, ê¸°ë³¸ ì„¤ì • ì‚¬ìš©")
        
        return default_config
    
    async def _print_system_status(self):
        """ì‹œìŠ¤í…œ ìƒíƒœ ì¶œë ¥"""
        logger.info("=" * 70)
        logger.info("ğŸ¥ ìˆ˜ì •ëœ ê°€ìƒ í”¼íŒ… íŒŒì´í”„ë¼ì¸ ì‹œìŠ¤í…œ ìƒíƒœ")
        logger.info("=" * 70)
        
        # ë””ë°”ì´ìŠ¤ ì •ë³´
        logger.info(f"ğŸ–¥ï¸ ë””ë°”ì´ìŠ¤: {self.device}")
        if self.device == 'mps':
            logger.info(f"   - MPS ì‚¬ìš© ê°€ëŠ¥: {torch.backends.mps.is_available()}")
        elif self.device == 'cuda':
            logger.info(f"   - CUDA ë²„ì „: {torch.version.cuda}")
            if torch.cuda.is_available():
                logger.info(f"   - GPU ì´ë¦„: {torch.cuda.get_device_name()}")
        
        # ë‹¨ê³„ë³„ ìƒíƒœ
        logger.info("ğŸ“‹ ë‹¨ê³„ë³„ ì´ˆê¸°í™” ìƒíƒœ:")
        for i, step_name in enumerate(self.step_order, 1):
            if step_name in self.steps:
                status = "âœ… ì¤€ë¹„ë¨"
                step = self.steps[step_name]
                if hasattr(step, 'is_initialized'):
                    if not step.is_initialized:
                        status = "âš ï¸ ì´ˆê¸°í™” ë¯¸ì™„ë£Œ"
            else:
                status = "âŒ ë¡œë“œ ì•ˆë¨"
            
            logger.info(f"   {i}. {step_name}: {status}")
        
        # ì„±ëŠ¥ ì„¤ì •
        logger.info("âš™ï¸ íŒŒì´í”„ë¼ì¸ ì„¤ì •:")
        logger.info(f"   - í’ˆì§ˆ ë ˆë²¨: {self.pipeline_config['quality_level']}")
        logger.info(f"   - ì²˜ë¦¬ ëª¨ë“œ: {self.pipeline_config['processing_mode']}")
        logger.info(f"   - ë©”ëª¨ë¦¬ ìµœì í™”: {self.pipeline_config['memory_optimization']}")
        logger.info(f"   - ë³‘ë ¬ ì²˜ë¦¬: {self.pipeline_config['parallel_processing']}")
        
        # ë©”ëª¨ë¦¬ ì •ë³´
        memory_info = self._get_detailed_memory_usage()
        logger.info("ğŸ’¾ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰:")
        for key, value in memory_info.items():
            logger.info(f"   - {key}: {value}")
        
        logger.info("=" * 70)
    
    async def get_pipeline_status(self) -> Dict[str, Any]:
        """íŒŒì´í”„ë¼ì¸ ìƒì„¸ ìƒíƒœ ì¡°íšŒ"""
        return {
            'initialized': self.is_initialized,
            'device': self.device,
            'pipeline_config': self.pipeline_config,
            'performance_metrics': self.performance_metrics.copy(),
            'memory_usage': self._get_detailed_memory_usage(),
            'device_utilization': self._get_device_utilization(),
            'active_sessions': len(self.session_data),
            'error_history_count': len(self.error_history),
            'steps_status': {
                step_name: {
                    'loaded': step_name in self.steps,
                    'type': type(self.steps[step_name]).__name__ if step_name in self.steps else None
                }
                for step_name in self.step_order
            },
            'version': '3.0.0',
            'updated_classes_used': True
        }
    
    def get_status(self) -> Dict[str, Any]:
        """íŒŒì´í”„ë¼ì¸ ìƒíƒœ ë°˜í™˜ - main.py í˜¸í™˜ìš©"""
        return {
            'initialized': self.is_initialized,
            'device': self.device,
            'mode': 'production',  # main.py í˜¸í™˜ì„±
            'status': 'ready' if self.is_initialized else 'initializing',
            'steps_loaded': len(self.steps),
            'performance_stats': self.performance_metrics.copy(),
            'error_count': len(self.error_history),
            'version': '3.0.0',
            'simulation_mode': self.pipeline_config.get('processing_mode', 'complete') == 'simulation',
            'pipeline_config': self.pipeline_config
        }
    
    async def cleanup(self):
        """ì „ì²´ íŒŒì´í”„ë¼ì¸ ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        logger.info("ğŸ§¹ ìˆ˜ì •ëœ ê°€ìƒ í”¼íŒ… íŒŒì´í”„ë¼ì¸ ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì¤‘...")
        
        try:
            # ê° ë‹¨ê³„ë³„ ì •ë¦¬
            for step_name, step in self.steps.items():
                try:
                    if hasattr(step, 'cleanup'):
                        await step.cleanup()
                    elif hasattr(step, 'close'):
                        step.close()
                    logger.info(f"âœ… {step_name} ì •ë¦¬ ì™„ë£Œ")
                except Exception as e:
                    logger.warning(f"âš ï¸ {step_name} ì •ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
            
            # ìœ í‹¸ë¦¬í‹° ì •ë¦¬
            if self.model_loader and hasattr(self.model_loader, 'cleanup'):
                await self.model_loader.cleanup()
            
            if self.memory_manager and hasattr(self.memory_manager, 'cleanup'):
                await self.memory_manager.cleanup()
            
            # ìŠ¤ë ˆë“œ í’€ ì •ë¦¬
            if hasattr(self, 'thread_pool'):
                self.thread_pool.shutdown(wait=True)
            
            # ë©”ëª¨ë¦¬ ì •ë¦¬
            self._cleanup_memory()
            
            # ì„¸ì…˜ ë°ì´í„° ì •ë¦¬
            self.session_data.clear()
            
            # ìƒíƒœ ì´ˆê¸°í™”
            self.is_initialized = False
            
            logger.info("âœ… ì „ì²´ íŒŒì´í”„ë¼ì¸ ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"âŒ ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")


# ==========================================
# main.pyì—ì„œ ìš”êµ¬í•˜ëŠ” EXPORT í•¨ìˆ˜ë“¤ ì¶”ê°€
# ==========================================

# ì „ì—­ íŒŒì´í”„ë¼ì¸ ë§¤ë‹ˆì €
_global_pipeline_manager: Optional[PipelineManager] = None

def get_pipeline_manager() -> Optional[PipelineManager]:
    """ì „ì—­ íŒŒì´í”„ë¼ì¸ ë§¤ë‹ˆì € ë°˜í™˜ - main.pyì—ì„œ í•„ìˆ˜"""
    global _global_pipeline_manager
    return _global_pipeline_manager

def create_pipeline_manager(mode: Union[str, PipelineMode] = PipelineMode.SIMULATION,
                          device: str = "mps",
                          config: Optional[Dict[str, Any]] = None) -> PipelineManager:
    """ìƒˆë¡œìš´ íŒŒì´í”„ë¼ì¸ ë§¤ë‹ˆì € ìƒì„±"""
    global _global_pipeline_manager
    
    # ê¸°ì¡´ ë§¤ë‹ˆì € ì •ë¦¬
    if _global_pipeline_manager:
        try:
            asyncio.create_task(_global_pipeline_manager.cleanup())
        except:
            pass
    
    # ìƒˆ ë§¤ë‹ˆì € ìƒì„± (ì›ë³¸ì€ mode ì¸ìë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ ë¬´ì‹œ)
    _global_pipeline_manager = PipelineManager(device=device, config_path=None)
    return _global_pipeline_manager

def get_available_modes() -> Dict[str, str]:
    """ì‚¬ìš© ê°€ëŠ¥í•œ íŒŒì´í”„ë¼ì¸ ëª¨ë“œ ë°˜í™˜"""
    return {
        PipelineMode.SIMULATION.value: "ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œ (ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ìš©)",
        PipelineMode.PRODUCTION.value: "í”„ë¡œë•ì…˜ ëª¨ë“œ (ì‹¤ì œ AI ëª¨ë¸ ì‚¬ìš©)",
        PipelineMode.HYBRID.value: "í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë“œ (ìë™ í´ë°±)",
        PipelineMode.DEVELOPMENT.value: "ê°œë°œ ëª¨ë“œ (ë””ë²„ê¹…ìš©)"
    }

# í•˜ìœ„ í˜¸í™˜ì„±ì„ ìœ„í•œ ë³„ì¹­ë“¤
def initialize_pipeline_manager(mode: str = "simulation", device: str = "mps") -> PipelineManager:
    """íŒŒì´í”„ë¼ì¸ ë§¤ë‹ˆì € ì´ˆê¸°í™” (í•˜ìœ„ í˜¸í™˜ì„±)"""
    return create_pipeline_manager(mode=mode, device=device)

def get_default_pipeline_manager() -> PipelineManager:
    """ê¸°ë³¸ íŒŒì´í”„ë¼ì¸ ë§¤ë‹ˆì € ë°˜í™˜"""
    manager = get_pipeline_manager()
    if manager is None:
        manager = create_pipeline_manager()
    return manager

# ===================================
# ì‚¬ìš© ì˜ˆì‹œ ë° í…ŒìŠ¤íŠ¸ í•¨ìˆ˜ë“¤
# ===================================

async def demo_updated_pipeline_manager():
    """ìˆ˜ì •ëœ íŒŒì´í”„ë¼ì¸ ë§¤ë‹ˆì € ë°ëª¨"""
    
    print("ğŸš€ ìˆ˜ì •ëœ í´ë˜ìŠ¤ë“¤ê³¼ í˜¸í™˜ë˜ëŠ” 8ë‹¨ê³„ ê°€ìƒ í”¼íŒ… íŒŒì´í”„ë¼ì¸ ë°ëª¨ ì‹œì‘")
    
    # íŒŒì´í”„ë¼ì¸ ë§¤ë‹ˆì € ì´ˆê¸°í™”
    pipeline = PipelineManager(
        config_path=None,  # ê¸°ë³¸ ì„¤ì • ì‚¬ìš©
        device='auto'  # ìµœì  ë””ë°”ì´ìŠ¤ ìë™ ì„ íƒ
    )
    
    # ì´ˆê¸°í™”
    success = await pipeline.initialize()
    if not success:
        print("âŒ íŒŒì´í”„ë¼ì¸ ë§¤ë‹ˆì € ì´ˆê¸°í™” ì‹¤íŒ¨")
        return
    
    # ì§„í–‰ë¥  ì½œë°± í•¨ìˆ˜
    async def progress_callback(stage: str, percentage: int):
        print(f"ğŸ”„ ì§„í–‰ìƒí™©: {stage} - {percentage}%")
    
    # ê°€ìƒ í”¼íŒ… ì‹¤í–‰
    try:
        # ë”ë¯¸ ì´ë¯¸ì§€ ìƒì„± (ì‹¤ì œ íŒŒì¼ì´ ì—†ëŠ” ê²½ìš°)
        person_image = Image.new('RGB', (512, 512), color=(100, 150, 200))
        clothing_image = Image.new('RGB', (512, 512), color=(200, 100, 100))
        
        result = await pipeline.process_complete_virtual_fitting(
            person_image=person_image,
            clothing_image=clothing_image,
            body_measurements={
                'height': 175,
                'weight': 70,
                'chest': 95,
                'waist': 80,
                'shoulder_width': 45,
                'hip': 90
            },
            clothing_type='shirt',
            fabric_type='cotton',
            style_preferences={
                'fit': 'slim',
                'color_preference': 'original'
            },
            quality_target=0.85,
            progress_callback=progress_callback,
            save_intermediate=True,  # ì¤‘ê°„ ê²°ê³¼ ì €ì¥
            enable_auto_retry=True   # ìë™ ì¬ì‹œë„ í™œì„±í™”
        )
        
        if result['success']:
            print(f"\nğŸ‰ ìˆ˜ì •ëœ ê°€ìƒ í”¼íŒ… ì„±ê³µ!")
            print(f"ğŸ“Š ìµœì¢… í’ˆì§ˆ: {result['final_quality_score']:.3f} ({result['quality_grade']})")
            print(f"â±ï¸ ì´ ì²˜ë¦¬ ì‹œê°„: {result['total_processing_time']:.2f}ì´ˆ")
            print(f"ğŸ¯ ëª©í‘œ ë‹¬ì„±: {'âœ…' if result['quality_target_achieved'] else 'âŒ'}")
            print(f"ğŸ”§ ë³µêµ¬ë¨: {'âœ…' if result.get('recovered', False) else 'âŒ'}")
            print(f"ğŸ†• ìˆ˜ì •ëœ í´ë˜ìŠ¤ ì‚¬ìš©: {'âœ…' if result['metadata']['updated_classes_used'] else 'âŒ'}")
            
            # ê²°ê³¼ ì´ë¯¸ì§€ ì €ì¥
            os.makedirs('output', exist_ok=True)
            result['result_image'].save('output/updated_pipeline_result.jpg')
            print("ğŸ’¾ ê²°ê³¼ ì´ë¯¸ì§€ ì €ì¥ ì™„ë£Œ: output/updated_pipeline_result.jpg")
            
            # ìƒì„¸ ë¶„ì„ ì¶œë ¥
            print(f"\nğŸ“ˆ í’ˆì§ˆ ë¶„ì„:")
            for category, score in result['quality_breakdown'].items():
                print(f"  - {category}: {score:.3f}")
            
            print(f"\nğŸ’¡ ê°œì„  ì œì•ˆ:")
            for category, suggestions in result['improvement_suggestions'].items():
                print(f"  ğŸ“‹ {category}:")
                for suggestion in suggestions[:3]:  # ìƒìœ„ 3ê°œë§Œ
                    print(f"    - {suggestion}")
            
            print(f"\nâ±ï¸ ë‹¨ê³„ë³„ ì²˜ë¦¬ ì‹œê°„:")
            for step, summary in result['step_results_summary'].items():
                if summary['completed']:
                    fallback_indicator = " (í´ë°±)" if summary['fallback_used'] else ""
                    print(f"  - {step}: {summary['processing_time']:.2f}ì´ˆ ({'âœ…' if summary['success'] else 'âš ï¸'}){fallback_indicator}")
            
            # íŒŒì´í”„ë¼ì¸ ìƒíƒœ ì¡°íšŒ
            status = await pipeline.get_pipeline_status()
            print(f"\nğŸ“Š íŒŒì´í”„ë¼ì¸ ìƒíƒœ:")
            print(f"  - ì´ˆê¸°í™” ìƒíƒœ: {'âœ…' if status['initialized'] else 'âŒ'}")
            print(f"  - ë””ë°”ì´ìŠ¤: {status['device']}")
            print(f"  - í™œì„± ì„¸ì…˜: {status['active_sessions']}")
            print(f"  - ì „ì²´ ì„±ê³µë¥ : {status['performance_metrics']['successful_sessions']}/{status['performance_metrics']['total_sessions']}")
            print(f"  - ë²„ì „: {status['version']}")
            
        else:
            print(f"âŒ ê°€ìƒ í”¼íŒ… ì‹¤íŒ¨: {result['error']}")
            if result.get('fallback_used'):
                print("ğŸš¨ í´ë°± ê²°ê³¼ê°€ ì œê³µë˜ì—ˆìŠµë‹ˆë‹¤")
            
            # ì˜¤ë¥˜ ìƒì„¸ ì •ë³´
            if 'error_details' in result:
                print(f"ğŸ“‹ ì˜¤ë¥˜ ìƒì„¸: {result['error_details']}")
    
    except Exception as e:
        print(f"ğŸ’¥ ì˜ˆì™¸ ë°œìƒ: {e}")
        print(f"ğŸ“‹ ìƒì„¸: {traceback.format_exc()}")
    
    finally:
        # ë¦¬ì†ŒìŠ¤ ì •ë¦¬
        await pipeline.cleanup()
        print("ğŸ§¹ ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì™„ë£Œ")


async def test_individual_steps():
    """ê°œë³„ ë‹¨ê³„ í…ŒìŠ¤íŠ¸"""
    
    print("ğŸ”¬ ê°œë³„ ë‹¨ê³„ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    
    device = 'mps' if torch.backends.mps.is_available() else 'cpu'
    
    # ë”ë¯¸ ì´ë¯¸ì§€ ìƒì„±
    dummy_tensor = torch.randn(1, 3, 512, 512)
    
    # ê° ë‹¨ê³„ë³„ í…ŒìŠ¤íŠ¸ (import ê°€ëŠ¥í•œ ê²½ìš°ë§Œ)
    steps_to_test = []
    
    if STEPS_IMPORT_SUCCESS:
        steps_to_test = [
            ('Human Parsing', HumanParsingStep),
            ('Pose Estimation', PoseEstimationStep),
            ('Cloth Segmentation', ClothSegmentationStep),
            ('Geometric Matching', GeometricMatchingStep),
            ('Cloth Warping', ClothWarpingStep),
            ('Virtual Fitting', VirtualFittingStep),
            ('Post Processing', PostProcessingStep),
            ('Quality Assessment', QualityAssessmentStep)
        ]
    else:
        print("âš ï¸ Step í´ë˜ìŠ¤ë“¤ì„ importí•  ìˆ˜ ì—†ì–´ ì‹œë®¬ë ˆì´ì…˜ í…ŒìŠ¤íŠ¸ë§Œ ì§„í–‰")
        return {'simulation_mode': True, 'steps_tested': 0}
    
    results = {}
    
    for step_name, step_class in steps_to_test:
        print(f"\nğŸ§ª í…ŒìŠ¤íŠ¸ ì¤‘: {step_name}")
        
        try:
            # ìˆ˜ì •ëœ ìƒì„±ìë¡œ ë‹¨ê³„ ìƒì„±
            step = step_class(device=device, config={'test_mode': True})
            
            # ì´ˆê¸°í™”
            init_success = await step.initialize()
            print(f"  ì´ˆê¸°í™”: {'âœ…' if init_success else 'âŒ'}")
            
            # ì²˜ë¦¬ í…ŒìŠ¤íŠ¸
            start_time = time.time()
            
            if step_name == 'Human Parsing':
                result = await step.process(dummy_tensor)
            elif step_name == 'Pose Estimation':
                result = await step.process(dummy_tensor)
            elif step_name == 'Cloth Segmentation':
                result = await step.process(dummy_tensor, clothing_type='shirt')
            elif step_name == 'Geometric Matching':
                result = await step.process(dummy_tensor, dummy_tensor, dummy_tensor)
            elif step_name == 'Cloth Warping':
                result = await step.process(dummy_tensor, {'height': 175}, 'cotton')
            elif step_name == 'Virtual Fitting':
                result = await step.process(dummy_tensor, dummy_tensor, dummy_tensor, dummy_tensor)
            elif step_name == 'Post Processing':
                result = await step.process({'fitted_image': dummy_tensor})
            elif step_name == 'Quality Assessment':
                result = await step.process(
                    {'enhanced_image': dummy_tensor}, dummy_tensor, dummy_tensor,
                    dummy_tensor, dummy_tensor, dummy_tensor, dummy_tensor
                )
            
            processing_time = time.time() - start_time
            success = result.get('success', True)
            confidence = result.get('confidence', 0.0)
            fallback = result.get('fallback', False)
            
            print(f"  ì²˜ë¦¬: {'âœ…' if success else 'âŒ'}")
            print(f"  ì‹œê°„: {processing_time:.3f}ì´ˆ")
            print(f"  ì‹ ë¢°ë„: {confidence:.3f}")
            print(f"  í´ë°±: {'Yes' if fallback else 'No'}")
            
            results[step_name] = {
                'success': success,
                'processing_time': processing_time,
                'confidence': confidence,
                'fallback': fallback
            }
            
            # ì •ë¦¬
            if hasattr(step, 'cleanup'):
                await step.cleanup()
                
        except Exception as e:
            print(f"  âŒ ì˜¤ë¥˜: {e}")
            results[step_name] = {
                'success': False,
                'error': str(e)
            }
    
    # ê²°ê³¼ ìš”ì•½
    print(f"\nğŸ“Š ê°œë³„ ë‹¨ê³„ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½:")
    total_steps = len(steps_to_test)
    successful_steps = sum(1 for r in results.values() if r.get('success', False))
    
    print(f"  - ì „ì²´ ë‹¨ê³„: {total_steps}")
    print(f"  - ì„±ê³µ ë‹¨ê³„: {successful_steps}")
    print(f"  - ì„±ê³µë¥ : {successful_steps/total_steps:.1%}" if total_steps > 0 else "  - ì„±ê³µë¥ : 0%")
    
    if successful_steps > 0:
        avg_time = np.mean([r['processing_time'] for r in results.values() if 'processing_time' in r])
        avg_confidence = np.mean([r['confidence'] for r in results.values() if 'confidence' in r])
        fallback_count = sum(1 for r in results.values() if r.get('fallback', False))
        
        print(f"  - í‰ê·  ì²˜ë¦¬ ì‹œê°„: {avg_time:.3f}ì´ˆ")
        print(f"  - í‰ê·  ì‹ ë¢°ë„: {avg_confidence:.3f}")
        print(f"  - í´ë°± ì‚¬ìš©: {fallback_count}/{successful_steps}")
    
    return results


# ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
if __name__ == "__main__":
    print("ğŸ½ ìˆ˜ì •ëœ ì™„ì „í•œ 8ë‹¨ê³„ ê°€ìƒ í”¼íŒ… íŒŒì´í”„ë¼ì¸ ë§¤ë‹ˆì € v3.0")
    print("=" * 70)
    print("âœ¨ ìˆ˜ì •ëœ í´ë˜ìŠ¤ë“¤ê³¼ ì™„ë²½ í˜¸í™˜")
    print("ğŸ”§ device ì¸ì ë¬¸ì œ í•´ê²° ì ìš©")
    print("ğŸš€ M3 Max ìµœì í™”")
    print("ğŸ’ª í”„ë¡œë•ì…˜ ë ˆë²¨ ì•ˆì •ì„±")
    print("ğŸ†• main.pyì—ì„œ ìš”êµ¬í•˜ëŠ” PipelineMode enumê³¼ export í•¨ìˆ˜ë“¤ ì¶”ê°€")
    print("ğŸ­ Step import ì‹¤íŒ¨ ì‹œ ìë™ ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œ")
    print("=" * 70)
    
    async def main():
        # 1. ê°œë³„ ë‹¨ê³„ í…ŒìŠ¤íŠ¸
        print("\n1ï¸âƒ£ ê°œë³„ ë‹¨ê³„ í…ŒìŠ¤íŠ¸")
        individual_results = await test_individual_steps()
        
        # 2. ë°ëª¨ ì‹¤í–‰
        print("\n2ï¸âƒ£ íŒŒì´í”„ë¼ì¸ ë°ëª¨")
        await demo_updated_pipeline_manager()
        
        print("\nğŸ¯ ì „ì²´ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
        print(f"ğŸ“Š ìµœì¢… ê²°ê³¼:")
        if isinstance(individual_results, dict) and 'simulation_mode' in individual_results:
            print(f"  - ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œë¡œ ì‹¤í–‰ë¨")
        else:
            print(f"  - ê°œë³„ ë‹¨ê³„ ì„±ê³µë¥ : {sum(1 for r in individual_results.values() if r.get('success'))}/{len(individual_results)}")
        print(f"  - PipelineMode enum: âœ… ì¶”ê°€ë¨")
        print(f"  - get_pipeline_manager(): âœ… ì¶”ê°€ë¨")
        print(f"  - create_pipeline_manager(): âœ… ì¶”ê°€ë¨")
        print(f"  - main.py í˜¸í™˜ì„±: âœ… ì™„ë£Œë¨")
        print(f"  - MPS empty_cache í˜¸í™˜ì„±: âœ… PyTorch 2.2.2 ì§€ì›")
    
    # ì‹¤í–‰
    asyncio.run(main())