#!/usr/bin/env python3
#backend/app/ai_pipeline/__init__.py
#!/usr/bin/env python3
"""
ğŸ”¥ MyCloset AI Pipeline System v8.1 - DI Container v4.0 ì™„ì „ ì ìš© + ì˜¤ë¥˜ ìˆ˜ì •
================================================================

âœ… CircularReferenceFreeDIContainer ì™„ì „ í†µí•©
âœ… TYPE_CHECKINGìœ¼ë¡œ ìˆœí™˜ì°¸ì¡° ì™„ì „ ì°¨ë‹¨
âœ… ì§€ì—° í•´ê²°(Lazy Resolution) í™œì„±í™”
âœ… Step íŒ©í† ë¦¬ ìˆœí™˜ì°¸ì¡° ì™„ì „ í•´ê²°
âœ… ì•ˆì „í•œ ì˜ì¡´ì„± ì£¼ì… ì‹œìŠ¤í…œ
âœ… M3 Max 128GB + conda í™˜ê²½ ìµœì í™”
âœ… GitHub í”„ë¡œì íŠ¸ êµ¬ì¡° 100% í˜¸í™˜
âœ… SCIPY_AVAILABLE ì˜¤ë¥˜ ìˆ˜ì •
âœ… ìƒëŒ€ ì„í¬íŠ¸ ì˜¤ë¥˜ ìˆ˜ì •
âœ… DI Container í´ë°± ì‹œìŠ¤í…œ ì¶”ê°€

Author: MyCloset AI Team
Date: 2025-08-01
Version: 8.1 (Bug Fixes)
"""
import threading

import os
import gc
import logging
import sys
import time
import warnings
import platform
import asyncio
from typing import Dict, Any, Optional, List, Type, Callable, Union, TYPE_CHECKING
from pathlib import Path

# ê²½ê³  ë¬´ì‹œ (deprecated ê²½ë¡œ ê´€ë ¨)
warnings.filterwarnings('ignore', category=DeprecationWarning)
warnings.filterwarnings('ignore', message='.*deprecated.*')

# Logger ìµœìš°ì„  ì´ˆê¸°í™” (ì—ëŸ¬ ë°©ì§€)
logger = logging.getLogger(__name__)

# ==============================================
# ğŸ”¥ SCIPY_AVAILABLE ë³€ìˆ˜ ì •ì˜ (ì˜¤ë¥˜ ìˆ˜ì •)
# ==============================================

# SciPy ê°€ìš©ì„± í™•ì¸
try:
    import scipy
    SCIPY_AVAILABLE = True
    logger.debug("âœ… SciPy ì‚¬ìš© ê°€ëŠ¥")
except ImportError:
    SCIPY_AVAILABLE = False
    logger.debug("âš ï¸ SciPy ì‚¬ìš© ë¶ˆê°€ - ê¸°ë³¸ ê¸°ëŠ¥ìœ¼ë¡œ ë™ì‘")

# ==============================================
# ğŸ”¥ TYPE_CHECKINGìœ¼ë¡œ ìˆœí™˜ì°¸ì¡° ì™„ì „ ë°©ì§€
# ==============================================

if TYPE_CHECKING:
    # ì˜¤ì§ íƒ€ì… ì²´í¬ ì‹œì—ë§Œ import
    from .steps.base.core.base_step_mixin import BaseStepMixin
    from .models.model_loader import ModelLoader
    from .utils.memory_manager import MemoryManager
    from .utils.data_converter import DataConverter
    from .factories.step_factory import StepFactory
    from .pipeline_manager import PipelineManager
else:
    # ëŸ°íƒ€ì„ì—ëŠ” Anyë¡œ ì²˜ë¦¬ (ìˆœí™˜ì°¸ì¡° ë°©ì§€)
    BaseStepMixin = Any
    ModelLoader = Any
    MemoryManager = Any
    DataConverter = Any
    StepFactory = Any
    PipelineManager = Any

# ==============================================
# ğŸ”¥ DI Container v4.0 Core ì‹œìŠ¤í…œ Import (ì˜¤ë¥˜ ìˆ˜ì •)
# ==============================================

try:
    # ì ˆëŒ€ ì„í¬íŠ¸ ì‹œë„
    from app.core.di_container import (
        CircularReferenceFreeDIContainer,
        LazyDependency,
        DynamicImportResolver,
        get_global_container,
        reset_global_container,
        inject_dependencies_to_step_safe,
        get_service_safe,
        register_service_safe,
        register_lazy_service,
        initialize_di_system_safe
    )
    DI_CONTAINER_AVAILABLE = True
    logger.info("âœ… DI Container v4.0 Core ì‹œìŠ¤í…œ ë¡œë“œ ì„±ê³µ (ì ˆëŒ€ ì„í¬íŠ¸)")
except ImportError:
    try:
        # ìƒëŒ€ ì„í¬íŠ¸ ì‹œë„ (í´ë°±)
        from ..core.di_container import (
            CircularReferenceFreeDIContainer,
            LazyDependency,
            DynamicImportResolver,
            get_global_container,
            reset_global_container,
            inject_dependencies_to_step_safe,
            get_service_safe,
            register_service_safe,
            register_lazy_service,
            initialize_di_system_safe
        )
        DI_CONTAINER_AVAILABLE = True
        logger.info("âœ… DI Container v4.0 Core ì‹œìŠ¤í…œ ë¡œë“œ ì„±ê³µ (ìƒëŒ€ ì„í¬íŠ¸)")
    except ImportError as e:
        logger.error(f"âŒ DI Container v4.0 Core ì‹œìŠ¤í…œ ë¡œë“œ ì‹¤íŒ¨: {e}")
        DI_CONTAINER_AVAILABLE = False
        
        # í´ë°± ì²˜ë¦¬
        def inject_dependencies_to_step_safe(step_instance, container=None):
            logger.warning("âš ï¸ DI Container ì—†ìŒ - ì˜ì¡´ì„± ì£¼ì… ìŠ¤í‚µ")
        
        def get_service_safe(key: str):
            logger.warning(f"âš ï¸ DI Container ì—†ìŒ - ì„œë¹„ìŠ¤ ì¡°íšŒ ì‹¤íŒ¨: {key}")
            return None
        
        def register_service_safe(key: str, service):
            logger.warning(f"âš ï¸ DI Container ì—†ìŒ - ì„œë¹„ìŠ¤ ë“±ë¡ ìŠ¤í‚µ: {key}")
        
        def register_lazy_service(key: str, factory):
            logger.warning(f"âš ï¸ DI Container ì—†ìŒ - ì§€ì—° ì„œë¹„ìŠ¤ ë“±ë¡ ìŠ¤í‚µ: {key}")
        
        def initialize_di_system_safe():
            logger.warning("âš ï¸ DI Container ì—†ìŒ - ì‹œìŠ¤í…œ ì´ˆê¸°í™” ìŠ¤í‚µ")
        
        def get_global_container():
            logger.warning("âš ï¸ DI Container ì—†ìŒ - ê¸€ë¡œë²Œ ì»¨í…Œì´ë„ˆ ì—†ìŒ")
            return None

# ==============================================
# ğŸ”¥ í™˜ê²½ ì„¤ì • (DI Container í†µí•©) - ì˜¤ë¥˜ ìˆ˜ì •
# ==============================================

# ì‹œìŠ¤í…œ ì •ë³´ ê°€ì ¸ì˜¤ê¸° (ìƒìœ„ íŒ¨í‚¤ì§€) - ì˜¤ë¥˜ ìˆ˜ì •
try:
    # ì ˆëŒ€ ì„í¬íŠ¸ ì‹œë„
    from app import get_system_info, is_conda_environment, is_m3_max, get_device
    SYSTEM_INFO = get_system_info()
    IS_CONDA = is_conda_environment()
    IS_M3_MAX = is_m3_max()
    DEVICE = get_device()
    logger.info("âœ… ìƒìœ„ íŒ¨í‚¤ì§€ì—ì„œ ì‹œìŠ¤í…œ ì •ë³´ ë¡œë“œ ì„±ê³µ (ì ˆëŒ€ ì„í¬íŠ¸)")
except ImportError:
    try:
        # ìƒëŒ€ ì„í¬íŠ¸ ì‹œë„ (í´ë°±)
        from .. import get_system_info, is_conda_environment, is_m3_max, get_device
        SYSTEM_INFO = get_system_info()
        IS_CONDA = is_conda_environment()
        IS_M3_MAX = is_m3_max()
        DEVICE = get_device()
        logger.info("âœ… ìƒìœ„ íŒ¨í‚¤ì§€ì—ì„œ ì‹œìŠ¤í…œ ì •ë³´ ë¡œë“œ ì„±ê³µ (ìƒëŒ€ ì„í¬íŠ¸)")
    except ImportError as e:
        logger.warning(f"âš ï¸ ìƒìœ„ íŒ¨í‚¤ì§€ ë¡œë“œ ì‹¤íŒ¨, ê¸°ë³¸ê°’ ì‚¬ìš©: {e}")
        
        # ê¸°ë³¸ê°’ ì„¤ì •
        CONDA_ENV = os.environ.get('CONDA_DEFAULT_ENV', 'none')
        IS_CONDA = CONDA_ENV != 'none'
        IS_TARGET_ENV = CONDA_ENV == 'mycloset-ai-clean'
        
        # M3 Max ê°ì§€
        def _detect_m3_max() -> bool:
            try:
                if platform.system() == 'Darwin':
                    import subprocess
                    result = subprocess.run(
                        ['sysctl', '-n', 'machdep.cpu.brand_string'],
                        capture_output=True, text=True, timeout=5
                    )
                    return 'M3' in result.stdout and 'Max' in result.stdout
            except Exception:
                pass
            return False
        
        IS_M3_MAX = _detect_m3_max()
        MEMORY_GB = 128.0 if IS_M3_MAX else 16.0
        
        # ë””ë°”ì´ìŠ¤ ê°ì§€
        try:
            import torch
            if hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
                DEVICE = 'mps'
            else:
                DEVICE = 'cpu'
        except ImportError:
            DEVICE = 'cpu'
        
        SYSTEM_INFO = {
            'device': DEVICE,
            'is_m3_max': IS_M3_MAX,
            'memory_gb': MEMORY_GB,
            'is_conda': IS_CONDA,
            'conda_env': CONDA_ENV
        }

# PyTorch ìµœì í™” ì„¤ì • (ì˜¤ë¥˜ ìˆ˜ì •)
TORCH_AVAILABLE = False
MPS_AVAILABLE = False
try:
    import torch
    TORCH_AVAILABLE = True
    
    # PyTorch 2.7 weights_only í˜¸í™˜ì„± íŒ¨ì¹˜
    if hasattr(torch, 'load'):
        original_load = torch.load
        def patched_load(*args, **kwargs):
            if 'weights_only' not in kwargs:
                kwargs['weights_only'] = False
            return original_load(*args, **kwargs)
        torch.load = patched_load
        logger.info("âœ… PyTorch 2.7 weights_only í˜¸í™˜ì„± íŒ¨ì¹˜ ì ìš© ì™„ë£Œ")
    
    if hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
        MPS_AVAILABLE = True
        # M3 Max ìµœì í™” ì„¤ì •
        os.environ.setdefault('PYTORCH_ENABLE_MPS_FALLBACK', '1')
        os.environ.setdefault('PYTORCH_MPS_HIGH_WATERMARK_RATIO', '0.0')
        
    logger.info(f"âœ… PyTorch ë¡œë“œ: MPS={MPS_AVAILABLE}, M3 Max={IS_M3_MAX}")
except ImportError:
    logger.warning("âš ï¸ PyTorch ì—†ìŒ - conda install pytorch ê¶Œì¥")

# ==============================================
# ğŸ”¥ ì•ˆì „í•œ ì§€ì—° ì˜ì¡´ì„± í•´ê²° í´ë˜ìŠ¤ (ì˜¤ë¥˜ ìˆ˜ì •)
# ==============================================

class SafeLazyDependency:
    """ì•ˆì „í•œ ì§€ì—° ì˜ì¡´ì„± í•´ê²° (LazyDependency ì˜¤ë¥˜ ë°©ì§€)"""
    
    def __init__(self, resolver_func, fallback_value=None):
        self.resolver_func = resolver_func
        self.fallback_value = fallback_value
        self._resolved = False
        self._value = None
        self._lock = threading.Lock()
    
    def resolve(self):
        """ì˜ì¡´ì„± í•´ê²°"""
        if self._resolved:
            return self._value
        
        with self._lock:
            if self._resolved:
                return self._value
            
            try:
                self._value = self.resolver_func()
                self._resolved = True
                logger.debug(f"âœ… SafeLazyDependency í•´ê²° ì„±ê³µ")
                return self._value
            except Exception as e:
                logger.warning(f"âš ï¸ SafeLazyDependency í•´ê²° ì‹¤íŒ¨: {e}")
                self._value = self.fallback_value
                self._resolved = True
                return self._value

# ==============================================
# ğŸ”¥ DI Container ê¸°ë°˜ Step ë¡œë”© ì‹œìŠ¤í…œ
# ==============================================

class DIBasedStepLoader:
    """DI Container ê¸°ë°˜ Step ë¡œë” v4.1 (ì˜¤ë¥˜ ìˆ˜ì •)"""
    
    def __init__(self):
        self._container: Optional[CircularReferenceFreeDIContainer] = None
        self._loaded_steps = {}
        self._failed_steps = set()
        self._step_mapping = {}
        self.logger = logging.getLogger(f"{__name__}.DIBasedStepLoader")
        
        # DI Container ì´ˆê¸°í™”
        self._initialize_container()
        
        # Step ë§¤í•‘ ì„¤ì •
        self._setup_step_mapping()
    
    def _initialize_container(self):
        """DI Container ì´ˆê¸°í™” (ì˜¤ë¥˜ ìˆ˜ì •)"""
        try:
            if DI_CONTAINER_AVAILABLE:
                self._container = get_global_container()
                
                # ì‹œìŠ¤í…œ ì •ë³´ ë“±ë¡
                if self._container:
                    self._container.register('device', DEVICE)
                    self._container.register('is_m3_max', IS_M3_MAX)
                    self._container.register('memory_gb', SYSTEM_INFO.get('memory_gb', 16.0))
                    self._container.register('is_conda', IS_CONDA)
                    self._container.register('torch_available', TORCH_AVAILABLE)
                    self._container.register('mps_available', MPS_AVAILABLE)
                    self._container.register('scipy_available', SCIPY_AVAILABLE)  # ì¶”ê°€
                    
                    # DI ì‹œìŠ¤í…œ ì´ˆê¸°í™”
                    initialize_di_system_safe()
                    
                    self.logger.info("âœ… DI Container v4.0 ì´ˆê¸°í™” ì™„ë£Œ")
                else:
                    self.logger.warning("âš ï¸ DI Container ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨")
            else:
                self.logger.warning("âš ï¸ DI Container ì‚¬ìš© ë¶ˆê°€ - í´ë°± ëª¨ë“œ")
                
        except Exception as e:
            self.logger.error(f"âŒ DI Container ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    
    def _setup_step_mapping(self):
        """Step ë§¤í•‘ ì„¤ì • (GitHub êµ¬ì¡° ê¸°ì¤€)"""
        self._step_mapping = {
            'step_01': {
                'module': 'app.ai_pipeline.steps.step_01_human_parsing_models.step_01_human_parsing',
                'class': 'HumanParsingStep',
                'description': 'ì¸ì²´ íŒŒì‹± - Human Body Parsing',
                'models': ['SCHP', 'Graphonomy'],
                'priority': 2
            },
            'step_02': {
                'module': 'app.ai_pipeline.steps.step_02_pose_estimation_models.step_02_pose_estimation',
                'class': 'PoseEstimationStep',
                'description': 'í¬ì¦ˆ ì¶”ì • - Pose Estimation',
                'models': ['OpenPose', 'YOLO-Pose'],
                'priority': 4
            },
            'step_03': {
                'module': 'app.ai_pipeline.steps.step_03_cloth_segmentation_models.step_03_cloth_segmentation',
                'class': 'ClothSegmentationStep',
                'description': 'ì˜ë¥˜ ë¶„í•  - Cloth Segmentation',
                'models': ['U2Net', 'SAM'],
                'priority': 3
            },
            'step_04': {
                'module': 'app.ai_pipeline.steps.step_04_geometric_matching_models.step_04_geometric_matching',
                'class': 'GeometricMatchingStep',
                'description': 'ê¸°í•˜í•™ì  ë§¤ì¹­ - Geometric Matching',
                'models': ['TPS', 'GMM'],
                'priority': 7
            },
            'step_05': {
                'module': 'app.ai_pipeline.steps.step_05_cloth_warping_models.step_05_cloth_warping',
                'class': 'ClothWarpingStep',
                'description': 'ì˜ë¥˜ ë³€í˜• - Cloth Warping',
                'models': ['Advanced Warping'],
                'priority': 8
            },
            'step_06': {
                'module': 'app.ai_pipeline.steps.step_06_virtual_fitting_models.step_06_virtual_fitting',
                'class': 'VirtualFittingStep',
                'description': 'ê°€ìƒ í”¼íŒ… - Virtual Fitting',
                'models': ['OOTDiffusion', 'IDM-VTON'],
                'priority': 1  # ê°€ì¥ ì¤‘ìš”
            },
            'step_07': {
                'module': 'app.ai_pipeline.steps.post_processing.step_07_post_processing',
                'class': 'PostProcessingStep',
                'description': 'í›„ì²˜ë¦¬ - Post Processing',
                'models': ['RealESRGAN', 'Enhancement'],
                'priority': 5
            },
            'step_08': {
                'module': 'app.ai_pipeline.steps.step_08_quality_assessment_models.step_08_quality_assessment',
                'class': 'QualityAssessmentStep',
                'description': 'í’ˆì§ˆ í‰ê°€ - Quality Assessment',
                'models': ['CLIP', 'Quality Metrics'],
                'priority': 6
            }
        }
        
        # conda í™˜ê²½ì—ì„œ ìš°ì„ ìˆœìœ„ ì •ë ¬
        self._loading_priority = sorted(
            self._step_mapping.keys(), 
            key=lambda x: self._step_mapping[x]['priority']
        )
    
    def safe_import_step(self, step_id: str) -> Optional[Type]:
        """DI Container ê¸°ë°˜ ì•ˆì „í•œ Step import (ì˜¤ë¥˜ ìˆ˜ì •)"""
        if step_id in self._loaded_steps:
            return self._loaded_steps[step_id]
        
        if step_id in self._failed_steps:
            return None
        
        try:
            step_info = self._step_mapping.get(step_id)
            if not step_info:
                self.logger.warning(f"âš ï¸ ì•Œ ìˆ˜ ì—†ëŠ” Step ID: {step_id}")
                return None
            
            # DI Container ê¸°ë°˜ ë™ì  import
            if self._container:
                # ì•ˆì „í•œ ì§€ì—° ë¡œë”©ìœ¼ë¡œ Step í´ë˜ìŠ¤ ë“±ë¡
                def step_factory():
                    return self._dynamic_import_step(step_info['module'], step_info['class'])
                
                step_key = f"step_class_{step_id}"
                
                # SafeLazyDependency ì‚¬ìš©
                lazy_dep = SafeLazyDependency(step_factory)
                
                try:
                    self._container.register_lazy(step_key, step_factory)
                    step_class = self._container.get(step_key)
                except Exception:
                    # í´ë°±: SafeLazyDependency ì§ì ‘ ì‚¬ìš©
                    step_class = lazy_dep.resolve()
                
                if step_class:
                    self._loaded_steps[step_id] = step_class
                    self.logger.info(f"âœ… {step_id} ({step_info['class']}) DI ë¡œë“œ ì„±ê³µ")
                    return step_class
            else:
                # í´ë°±: ì§ì ‘ import
                step_class = self._dynamic_import_step(step_info['module'], step_info['class'])
                if step_class:
                    self._loaded_steps[step_id] = step_class
                    self.logger.info(f"âœ… {step_id} ({step_info['class']}) ì§ì ‘ ë¡œë“œ ì„±ê³µ")
                    return step_class
        
        except Exception as e:
            self.logger.error(f"âŒ {step_id} ë¡œë“œ ì‹¤íŒ¨: {e}")
        
        # ì‹¤íŒ¨ ê¸°ë¡
        self._failed_steps.add(step_id)
        self._loaded_steps[step_id] = None
        return None
    
    def _dynamic_import_step(self, module_name: str, class_name: str) -> Optional[Type]:
        """ë™ì  Step import (ìˆœí™˜ì°¸ì¡° ë°©ì§€, ì˜¤ë¥˜ ìˆ˜ì •)"""
        import_paths = [
            module_name,
            module_name.replace('app.', ''),
            f".{module_name.split('.')[-1]}"
        ]
        
        for path in import_paths:
            try:
                if path.startswith('.'):
                    # ìƒëŒ€ import
                    import importlib
                    module = importlib.import_module(path, package=__package__)
                else:
                    # ì ˆëŒ€ import
                    import importlib
                    module = importlib.import_module(path)
                
                step_class = getattr(module, class_name, None)
                if step_class:
                    self.logger.debug(f"âœ… {class_name} ë™ì  import ì„±ê³µ: {path}")
                    return step_class
                    
            except (ImportError, SyntaxError, AttributeError) as e:
                self.logger.debug(f"ğŸ“‹ {class_name} import ì‹œë„: {path} - {e}")
                continue
        
        return None
    
    def load_all_available_steps(self) -> Dict[str, Optional[Type]]:
        """ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë“  Step ë¡œë“œ (DI Container ê¸°ë°˜)"""
        loaded_steps = {}
        
        # conda í™˜ê²½ì´ë©´ ìš°ì„ ìˆœìœ„ ìˆœìœ¼ë¡œ ë¡œë“œ
        load_order = self._loading_priority if IS_CONDA else self._step_mapping.keys()
        
        for step_id in load_order:
            step_class = self.safe_import_step(step_id)
            loaded_steps[step_id] = step_class
        
        available_count = sum(1 for step in loaded_steps.values() if step is not None)
        total_count = len(self._step_mapping)
        
        self.logger.info(f"ğŸ“Š DI ê¸°ë°˜ Step ë¡œë”© ì™„ë£Œ: {available_count}/{total_count}ê°œ")
        
        if IS_CONDA:
            self.logger.info("ğŸ conda í™˜ê²½: ìš°ì„ ìˆœìœ„ ê¸°ë°˜ ë¡œë”© ì ìš©")
        
        return loaded_steps
    
    def create_step_instance(self, step_id: str, **kwargs) -> Optional[Any]:
        """DI Container ê¸°ë°˜ Step ì¸ìŠ¤í„´ìŠ¤ ìƒì„±"""
        step_class = self.safe_import_step(step_id)
        if step_class is None:
            self.logger.error(f"âŒ Step í´ë˜ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ: {step_id}")
            return None
        
        try:
            # ê¸°ë³¸ ì„¤ì • ì¶”ê°€
            default_config = {
                'device': DEVICE,
                'is_m3_max': IS_M3_MAX,
                'memory_gb': SYSTEM_INFO.get('memory_gb', 16.0),
                'conda_optimized': IS_CONDA,
                'scipy_available': SCIPY_AVAILABLE  # ì¶”ê°€
            }
            default_config.update(kwargs)
            
            # Step ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
            step_instance = step_class(**default_config)
            
            # DI Container ê¸°ë°˜ ì˜ì¡´ì„± ì£¼ì…
            if self._container:
                inject_dependencies_to_step_safe(step_instance, self._container)
            else:
                inject_dependencies_to_step_safe(step_instance)
            
            self.logger.info(f"âœ… {step_id} ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ì™„ë£Œ (DI ì£¼ì… í¬í•¨)")
            return step_instance
            
        except Exception as e:
            self.logger.error(f"âŒ {step_id} ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ì‹¤íŒ¨: {e}")
            return None
    
    def get_container_stats(self) -> Dict[str, Any]:
        """DI Container í†µê³„ ë°˜í™˜"""
        if self._container:
            try:
                return self._container.get_stats()
            except Exception as e:
                return {
                    'container_available': True,
                    'stats_error': str(e),
                    'loaded_steps': len(self._loaded_steps),
                    'failed_steps': len(self._failed_steps)
                }
        else:
            return {
                'container_available': False,
                'fallback_mode': True,
                'loaded_steps': len(self._loaded_steps),
                'failed_steps': len(self._failed_steps)
            }

# ==============================================
# ğŸ”¥ ì „ì—­ DI ê¸°ë°˜ Step ë¡œë” ì´ˆê¸°í™”
# ==============================================

# ì „ì—­ Step ë¡œë” ìƒì„± (DI Container ê¸°ë°˜)
_di_step_loader = DIBasedStepLoader()

# ==============================================
# ğŸ”¥ ìœ í‹¸ë¦¬í‹° ëª¨ë“ˆ ì•ˆì „í•œ ë¡œë”© (DI Container í†µí•©)
# ==============================================

def _safe_import_utils_with_di():
    """ìœ í‹¸ë¦¬í‹° ëª¨ë“ˆë“¤ ì•ˆì „í•˜ê²Œ import (DI Container í†µí•©)"""
    utils_status = {
        'model_loader': False,
        'memory_manager': False,
        'data_converter': False,
        'model_interface': False
    }
    
    try:
        # DI Container ê¸°ë°˜ ìœ í‹¸ë¦¬í‹° ë¡œë”©
        container = get_global_container() if DI_CONTAINER_AVAILABLE else None
        
        if container:
            # DI Containerì—ì„œ ìœ í‹¸ë¦¬í‹° ì„œë¹„ìŠ¤ ì¡°íšŒ
            model_loader = get_service_safe('model_loader')
            memory_manager = get_service_safe('memory_manager')
            data_converter = get_service_safe('data_converter')
            
            if model_loader:
                utils_status['model_loader'] = True
                globals()['get_step_model_interface'] = lambda: model_loader
            
            if memory_manager:
                utils_status['memory_manager'] = True
                globals()['get_step_memory_manager'] = lambda: memory_manager
            
            if data_converter:
                utils_status['data_converter'] = True
                globals()['get_step_data_converter'] = lambda: data_converter
            
            utils_status['model_interface'] = True
            logger.info("âœ… DI Container ê¸°ë°˜ ìœ í‹¸ë¦¬í‹° ë¡œë“œ ì„±ê³µ")
        else:
            # í´ë°±: ì§ì ‘ import
            try:
                from .utils import (
                    get_step_model_interface,
                    get_step_memory_manager, 
                    get_step_data_converter,
                    preprocess_image_for_step
                )
                utils_status.update({
                    'model_loader': True,
                    'memory_manager': True,
                    'data_converter': True,
                    'model_interface': True
                })
                logger.info("âœ… ì§ì ‘ ìœ í‹¸ë¦¬í‹° ëª¨ë“ˆ ë¡œë“œ ì„±ê³µ")
                
                # ì „ì—­ì— ì¶”ê°€
                globals().update({
                    'get_step_model_interface': get_step_model_interface,
                    'get_step_memory_manager': get_step_memory_manager,
                    'get_step_data_converter': get_step_data_converter,
                    'preprocess_image_for_step': preprocess_image_for_step
                })
                
            except ImportError as e:
                logger.warning(f"âš ï¸ ì§ì ‘ ìœ í‹¸ë¦¬í‹° ëª¨ë“ˆ ë¡œë“œ ì‹¤íŒ¨: {e}")
                raise
        
    except Exception as e:
        logger.warning(f"âš ï¸ ìœ í‹¸ë¦¬í‹° ëª¨ë“ˆ ë¡œë“œ ì‹¤íŒ¨: {e}")
        
        # í´ë°± í•¨ìˆ˜ë“¤
        def _fallback_function(name: str):
            def fallback(*args, **kwargs):
                logger.warning(f"âš ï¸ {name} í•¨ìˆ˜ ì‚¬ìš© ë¶ˆê°€ (ëª¨ë“ˆ ë¡œë“œ ì‹¤íŒ¨)")
                return None
            return fallback
        
        globals().update({
            'get_step_model_interface': _fallback_function('get_step_model_interface'),
            'get_step_memory_manager': _fallback_function('get_step_memory_manager'),
            'get_step_data_converter': _fallback_function('get_step_data_converter'),
            'preprocess_image_for_step': _fallback_function('preprocess_image_for_step')
        })
    
    return utils_status

# ìœ í‹¸ë¦¬í‹° ë¡œë”© (DI Container í†µí•©)
UTILS_STATUS = _safe_import_utils_with_di()

# ==============================================
# ğŸ”¥ íŒŒì´í”„ë¼ì¸ ê´€ë¦¬ í•¨ìˆ˜ë“¤ (DI Container ê¸°ë°˜)
# ==============================================

def get_pipeline_status() -> Dict[str, Any]:
    """íŒŒì´í”„ë¼ì¸ ì „ì²´ ìƒíƒœ ë°˜í™˜ (DI Container í¬í•¨)"""
    loaded_steps = _di_step_loader.load_all_available_steps()
    available_steps = [k for k, v in loaded_steps.items() if v is not None]
    container_stats = _di_step_loader.get_container_stats()
    
    return {
        'system_info': SYSTEM_INFO,
        'conda_optimized': IS_CONDA,
        'm3_max_optimized': IS_M3_MAX,
        'device': DEVICE,
        'scipy_available': SCIPY_AVAILABLE,  # ì¶”ê°€
        'total_steps': len(_di_step_loader._step_mapping),
        'available_steps': len(available_steps),
        'loaded_steps': available_steps,
        'failed_steps': [k for k, v in loaded_steps.items() if v is None],
        'success_rate': (len(available_steps) / len(_di_step_loader._step_mapping)) * 100,
        'utils_status': UTILS_STATUS,
        'loading_priority': _di_step_loader._loading_priority if IS_CONDA else None,
        'di_container_available': DI_CONTAINER_AVAILABLE,
        'di_container_stats': container_stats
    }

def get_step_class(step_name: str) -> Optional[Type]:
    """Step í´ë˜ìŠ¤ ë°˜í™˜ (DI Container ê¸°ë°˜)"""
    if step_name.startswith('step_'):
        return _di_step_loader.safe_import_step(step_name)
    else:
        # í´ë˜ìŠ¤ëª…ìœ¼ë¡œ ê²€ìƒ‰
        for step_id, step_info in _di_step_loader._step_mapping.items():
            if step_info['class'] == step_name:
                return _di_step_loader.safe_import_step(step_id)
    return None

def create_step_instance(step_name: str, **kwargs) -> Optional[Any]:
    """Step ì¸ìŠ¤í„´ìŠ¤ ìƒì„± (DI Container ê¸°ë°˜)"""
    if step_name.startswith('step_'):
        return _di_step_loader.create_step_instance(step_name, **kwargs)
    else:
        # í´ë˜ìŠ¤ëª…ìœ¼ë¡œ ê²€ìƒ‰
        for step_id, step_info in _di_step_loader._step_mapping.items():
            if step_info['class'] == step_name:
                return _di_step_loader.create_step_instance(step_id, **kwargs)
    
    logger.error(f"âŒ Stepì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {step_name}")
    return None

def list_available_steps() -> List[str]:
    """ì‚¬ìš© ê°€ëŠ¥í•œ Step ëª©ë¡ ë°˜í™˜"""
    loaded_steps = _di_step_loader.load_all_available_steps()
    return [step_id for step_id, step_class in loaded_steps.items() if step_class is not None]

def get_step_info(step_id: str) -> Dict[str, Any]:
    """Step ì •ë³´ ë°˜í™˜ (DI Container ê¸°ë°˜)"""
    step_config = _di_step_loader._step_mapping.get(step_id, {})
    step_class = _di_step_loader._loaded_steps.get(step_id)
    
    return {
        'step_id': step_id,
        'module': step_config.get('module', ''),
        'class': step_config.get('class', 'Unknown'),
        'description': step_config.get('description', ''),
        'models': step_config.get('models', []),
        'priority': step_config.get('priority', 10),
        'available': step_class is not None,
        'loaded': step_class is not None,
        'failed': step_id in _di_step_loader._failed_steps,
        'di_injected': DI_CONTAINER_AVAILABLE
    }

async def initialize_pipeline_system() -> bool:
    """íŒŒì´í”„ë¼ì¸ ì‹œìŠ¤í…œ ì´ˆê¸°í™” (DI Container ê¸°ë°˜)"""
    try:
        logger.info("ğŸš€ íŒŒì´í”„ë¼ì¸ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹œì‘ (DI Container v4.0)")
        
        # DI Container ì´ˆê¸°í™”
        if DI_CONTAINER_AVAILABLE:
            initialize_di_system_safe()
            logger.info("âœ… DI Container v4.0 ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
        
        # Step í´ë˜ìŠ¤ë“¤ ë¡œë“œ
        loaded_steps = _di_step_loader.load_all_available_steps()
        available_count = sum(1 for step in loaded_steps.values() if step is not None)
        
        logger.info(f"âœ… íŒŒì´í”„ë¼ì¸ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ: {available_count}/{len(_di_step_loader._step_mapping)}ê°œ Step")
        
        # ì¤‘ìš”í•œ Stepë“¤ ê°œë³„ ì²´í¬
        critical_steps = ['step_06', 'step_01', 'step_04']  # VirtualFitting, HumanParsing, GeometricMatching
        critical_available = 0
        
        for step_id in critical_steps:
            if loaded_steps.get(step_id):
                critical_available += 1
                logger.info(f"ğŸ‰ ì¤‘ìš” Step {step_id} ë¡œë“œ ì„±ê³µ!")
            else:
                logger.warning(f"âš ï¸ ì¤‘ìš” Step {step_id} ë¡œë“œ ì‹¤íŒ¨!")
        
        success = available_count > 0 and critical_available >= 1
        
        if success:
            logger.info("ğŸš€ íŒŒì´í”„ë¼ì¸ ì‹œìŠ¤í…œ ì¤€ë¹„ ì™„ë£Œ!")
        else:
            logger.warning("âš ï¸ íŒŒì´í”„ë¼ì¸ ì‹œìŠ¤í…œ ë¶€ë¶„ ì¤€ë¹„")
        
        return success
        
    except Exception as e:
        logger.error(f"âŒ íŒŒì´í”„ë¼ì¸ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return False

async def cleanup_pipeline_system() -> None:
    """íŒŒì´í”„ë¼ì¸ ì‹œìŠ¤í…œ ì •ë¦¬ (DI Container ê¸°ë°˜)"""
    try:
        logger.info("ğŸ§¹ íŒŒì´í”„ë¼ì¸ ì‹œìŠ¤í…œ ì •ë¦¬ ì‹œì‘ (DI Container v4.0)")
        
        # DI Container ë©”ëª¨ë¦¬ ìµœì í™”
        if DI_CONTAINER_AVAILABLE:
            container = get_global_container()
            if container and hasattr(container, 'optimize_memory'):
                try:
                    cleanup_stats = container.optimize_memory()
                    logger.info(f"ğŸ§¹ DI Container ë©”ëª¨ë¦¬ ìµœì í™”: {cleanup_stats}")
                except Exception as e:
                    logger.debug(f"DI Container ë©”ëª¨ë¦¬ ìµœì í™” ì‹¤íŒ¨: {e}")
        
        # Step ë¡œë” ìºì‹œ ì •ë¦¬
        _di_step_loader._loaded_steps.clear()
        _di_step_loader._failed_steps.clear()
        
        # GPU ë©”ëª¨ë¦¬ ì •ë¦¬ (ê°€ëŠ¥í•œ ê²½ìš°)
        if DEVICE in ['cuda', 'mps']:
            try:
                import torch
                if DEVICE == 'cuda' and torch.cuda.is_available():
                    torch.cuda.empty_cache()
                elif DEVICE == 'mps' and torch.backends.mps.is_available():
                    # M3 Max ë©”ëª¨ë¦¬ ì •ë¦¬ (ì•ˆì „í•˜ê²Œ)
                    import gc
                    gc.collect()
                    if hasattr(torch.backends.mps, 'empty_cache'):
                        torch.backends.mps.empty_cache()
            except Exception as e:
                logger.debug(f"GPU ë©”ëª¨ë¦¬ ì •ë¦¬ ì‹¤íŒ¨: {e}")
        
        logger.info("âœ… íŒŒì´í”„ë¼ì¸ ì‹œìŠ¤í…œ ì •ë¦¬ ì™„ë£Œ")
        
    except Exception as e:
        logger.warning(f"âš ï¸ íŒŒì´í”„ë¼ì¸ ì‹œìŠ¤í…œ ì •ë¦¬ ì‹¤íŒ¨: {e}")

# ==============================================
# ğŸ”¥ ìë™ Step í´ë˜ìŠ¤ ë¡œë”© (DI Container ê¸°ë°˜)
# ==============================================

# Step í´ë˜ìŠ¤ë“¤ì„ ì „ì—­ ë³€ìˆ˜ë¡œ ì„¤ì • (ì§€ì—° ë¡œë”©)
try:
    _loaded_steps = _di_step_loader.load_all_available_steps()
    
    # ê°œë³„ Step í´ë˜ìŠ¤ë“¤ì„ ì „ì—­ì— ì¶”ê°€
    for step_id, step_class in _loaded_steps.items():
        if step_class:
            step_info = _di_step_loader._step_mapping[step_id]
            class_name = step_info['class']
            globals()[class_name] = step_class
    
    logger.info("âœ… DI ê¸°ë°˜ Step í´ë˜ìŠ¤ë“¤ ì „ì—­ ì„¤ì • ì™„ë£Œ")
    
except Exception as e:
    logger.warning(f"âš ï¸ DI ê¸°ë°˜ Step í´ë˜ìŠ¤ ì „ì—­ ì„¤ì • ì‹¤íŒ¨: {e}")

# Step ë§¤í•‘ í˜¸í™˜ì„± (ê¸°ì¡´ ì½”ë“œ ì§€ì›)
STEP_MAPPING = _di_step_loader._step_mapping
LOADING_PRIORITY = _di_step_loader._loading_priority

# ê°€ìš©ì„± í”Œë˜ê·¸ ë§¤í•‘ (ì§€ì—° í‰ê°€)
def get_step_availability():
    loaded_steps = _di_step_loader._loaded_steps
    return {
        step_id: (loaded_steps.get(step_id) is not None)
        for step_id in _di_step_loader._step_mapping.keys()
    }

STEP_AVAILABILITY = get_step_availability()

# ì‚¬ìš© ê°€ëŠ¥í•œ Stepë§Œ í•„í„°ë§ (ì§€ì—° í‰ê°€)
def get_available_steps():
    loaded_steps = _di_step_loader._loaded_steps
    return {
        step_id: step_class 
        for step_id, step_class in loaded_steps.items() 
        if step_class is not None
    }

AVAILABLE_STEPS = get_available_steps()

# ==============================================
# ğŸ”¥ Export ëª©ë¡ (DI Container ê¸°ë°˜)
# ==============================================

__all__ = [
    # ğŸ¯ íŒŒì´í”„ë¼ì¸ ìƒìˆ˜
    'STEP_MAPPING',
    'LOADING_PRIORITY',
    'SYSTEM_INFO',
    'STEP_AVAILABILITY',
    'AVAILABLE_STEPS',
    'SCIPY_AVAILABLE',  # ì¶”ê°€
    
    # ğŸ”§ íŒŒì´í”„ë¼ì¸ ê´€ë¦¬ í•¨ìˆ˜ë“¤ (DI ê¸°ë°˜)
    'get_pipeline_status',
    'get_step_class',
    'create_step_instance',
    'list_available_steps',
    'get_step_info',
    'initialize_pipeline_system',
    'cleanup_pipeline_system',
    
    # ğŸ› ï¸ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤ (ì¡°ê±´ë¶€)
    'get_step_model_interface',
    'get_step_memory_manager',
    'get_step_data_converter', 
    'preprocess_image_for_step',
    
    # ğŸ”— DI Container ê´€ë ¨
    'DIBasedStepLoader',
    'SafeLazyDependency',  # ì¶”ê°€
    'inject_dependencies_to_step_safe',
    'get_service_safe',
    'register_service_safe',
    'register_lazy_service',
    'DI_CONTAINER_AVAILABLE',
    
    # ğŸ“Š ìƒíƒœ ì •ë³´
    'UTILS_STATUS',
    'IS_CONDA',
    'IS_M3_MAX',
    'DEVICE',
    'TORCH_AVAILABLE',
    'MPS_AVAILABLE'
]

# Step í´ë˜ìŠ¤ë“¤ë„ ë™ì ìœ¼ë¡œ ì¶”ê°€
for step_info in _di_step_loader._step_mapping.values():
    class_name = step_info['class']
    if class_name in globals():
        __all__.append(class_name)

# ==============================================
# ğŸ”¥ ì´ˆê¸°í™” ì™„ë£Œ ë©”ì‹œì§€ (DI Container í¬í•¨)
# ==============================================

def _print_initialization_summary():
    """ì´ˆê¸°í™” ìš”ì•½ ì¶œë ¥ (ê°„ë‹¨ ë²„ì „)"""
    status = get_pipeline_status()
    available_count = status['available_steps']
    total_count = status['total_steps']
    
    print(f"âœ… íŒŒì´í”„ë¼ì¸ ì‹œìŠ¤í…œ ì¤€ë¹„ ì™„ë£Œ ({available_count}/{total_count}ê°œ Step)")

# ì´ˆê¸°í™” ìƒíƒœ ì¶œë ¥ (í•œ ë²ˆë§Œ)
if not hasattr(sys, '_mycloset_pipeline_di_initialized'):
    _print_initialization_summary()
    sys._mycloset_pipeline_di_initialized = True

# conda í™˜ê²½ ìë™ ìµœì í™” (DI Container ê¸°ë°˜)
if IS_CONDA and DI_CONTAINER_AVAILABLE:
    try:
        # conda í™˜ê²½ ìµœì í™”
        os.environ.setdefault('OMP_NUM_THREADS', str(max(1, os.cpu_count() // 2)))
        os.environ.setdefault('MKL_NUM_THREADS', str(max(1, os.cpu_count() // 2)))
        os.environ.setdefault('NUMEXPR_NUM_THREADS', str(max(1, os.cpu_count() // 2)))
        
        if TORCH_AVAILABLE:
            import torch
            torch.set_num_threads(max(1, os.cpu_count() // 2))
            
            if IS_M3_MAX and MPS_AVAILABLE:
                if hasattr(torch.backends.mps, 'empty_cache'):
                    torch.backends.mps.empty_cache()
                logger.info("ğŸ M3 Max MPS conda ìµœì í™” ì™„ë£Œ")
        
        logger.info(f"ğŸ conda í™˜ê²½ ìë™ ìµœì í™” ì™„ë£Œ")
        
    except Exception as e:
        logger.warning(f"âš ï¸ conda ìë™ ìµœì í™” ì‹¤íŒ¨: {e}")

logger.info("ğŸ”¥ MyCloset AI Pipeline System v8.1 with DI Container v4.0 ì´ˆê¸°í™” ì™„ë£Œ! (Bug Fixed)")