# backend/app/ai_pipeline/__init__.py
"""
ğŸ MyCloset AI íŒŒì´í”„ë¼ì¸ ì‹œìŠ¤í…œ v7.0 - ë‹¨ìˆœí™”ëœ ì´ˆê¸°í™”
================================================================

âœ… ë‹¨ìˆœí•˜ê³  ì•ˆì •ì ì¸ ì´ˆê¸°í™”
âœ… ìˆœí™˜ì°¸ì¡° ì™„ì „ ë°©ì§€
âœ… conda í™˜ê²½ ìš°ì„  ìµœì í™”
âœ… M3 Max 128GB ë©”ëª¨ë¦¬ í™œìš©
âœ… 8ë‹¨ê³„ AI íŒŒì´í”„ë¼ì¸ ì§€ì›
âœ… ì§€ì—° ë¡œë”©ìœ¼ë¡œ ì„±ëŠ¥ ìµœì í™”
âœ… ì‹¤íŒ¨ í—ˆìš©ì  ì„¤ê³„ (Fault Tolerant)

8ë‹¨ê³„ AI íŒŒì´í”„ë¼ì¸:
Step 1: HumanParsingStep (SCHP/Graphonomy)
Step 2: PoseEstimationStep (OpenPose/YOLO)
Step 3: ClothSegmentationStep (U2Net/SAM)
Step 4: GeometricMatchingStep (TPS/GMM)
Step 5: ClothWarpingStep (Advanced Warping)
Step 6: VirtualFittingStep (OOTDiffusion/IDM-VTON)
Step 7: PostProcessingStep (Enhancement/SR)
Step 8: QualityAssessmentStep (CLIP/Quality)

ì‘ì„±ì: MyCloset AI Team
ë‚ ì§œ: 2025-07-23
ë²„ì „: v7.0.0 (Simplified Pipeline Initialization)
"""

import logging
import sys
import warnings
from typing import Dict, Any, Optional, List, Type
from pathlib import Path

# ê²½ê³  ë¬´ì‹œ
warnings.filterwarnings('ignore')

# =============================================================================
# ğŸ”¥ ê¸°ë³¸ ì„¤ì • ë° ë¡œê¹…
# =============================================================================

logger = logging.getLogger(__name__)

# ìƒìœ„ íŒ¨í‚¤ì§€ì—ì„œ ì‹œìŠ¤í…œ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
try:
    from .. import get_system_info, is_conda_environment, is_m3_max, get_device
    SYSTEM_INFO = get_system_info()
    IS_CONDA = is_conda_environment()
    IS_M3_MAX = is_m3_max()
    DEVICE = get_device()
    logger.info("âœ… ìƒìœ„ íŒ¨í‚¤ì§€ì—ì„œ ì‹œìŠ¤í…œ ì •ë³´ ë¡œë“œ ì„±ê³µ")
except ImportError as e:
    logger.warning(f"âš ï¸ ìƒìœ„ íŒ¨í‚¤ì§€ ë¡œë“œ ì‹¤íŒ¨, ê¸°ë³¸ê°’ ì‚¬ìš©: {e}")
    SYSTEM_INFO = {'device': 'cpu', 'is_m3_max': False, 'memory_gb': 16.0}
    IS_CONDA = False
    IS_M3_MAX = False
    DEVICE = 'cpu'

# =============================================================================
# ğŸ”¥ íŒŒì´í”„ë¼ì¸ ìƒìˆ˜ ì •ì˜
# =============================================================================

# 8ë‹¨ê³„ íŒŒì´í”„ë¼ì¸ ì •ì˜
PIPELINE_STEPS = {
    'step_01': {
        'name': 'HumanParsingStep',
        'description': 'ì¸ì²´ íŒŒì‹± - Human Body Parsing',
        'models': ['SCHP', 'Graphonomy'],
        'priority': 2
    },
    'step_02': {
        'name': 'PoseEstimationStep', 
        'description': 'í¬ì¦ˆ ì¶”ì • - Pose Estimation',
        'models': ['OpenPose', 'YOLO-Pose'],
        'priority': 4
    },
    'step_03': {
        'name': 'ClothSegmentationStep',
        'description': 'ì˜ë¥˜ ë¶„í•  - Cloth Segmentation', 
        'models': ['U2Net', 'SAM'],
        'priority': 3
    },
    'step_04': {
        'name': 'GeometricMatchingStep',
        'description': 'ê¸°í•˜í•™ì  ë§¤ì¹­ - Geometric Matching',
        'models': ['TPS', 'GMM'],
        'priority': 7
    },
    'step_05': {
        'name': 'ClothWarpingStep',
        'description': 'ì˜ë¥˜ ë³€í˜• - Cloth Warping',
        'models': ['Advanced Warping'],
        'priority': 8
    },
    'step_06': {
        'name': 'VirtualFittingStep',
        'description': 'ê°€ìƒ í”¼íŒ… - Virtual Fitting',
        'models': ['OOTDiffusion', 'IDM-VTON'],
        'priority': 1  # ê°€ì¥ ì¤‘ìš”
    },
    'step_07': {
        'name': 'PostProcessingStep',
        'description': 'í›„ì²˜ë¦¬ - Post Processing',
        'models': ['RealESRGAN', 'Enhancement'],
        'priority': 5
    },
    'step_08': {
        'name': 'QualityAssessmentStep',
        'description': 'í’ˆì§ˆ í‰ê°€ - Quality Assessment',
        'models': ['CLIP', 'Quality Metrics'],
        'priority': 6
    }
}

# conda í™˜ê²½ì—ì„œ ë¡œë”© ìš°ì„ ìˆœìœ„
LOADING_PRIORITY = sorted(PIPELINE_STEPS.keys(), 
                         key=lambda x: PIPELINE_STEPS[x]['priority'])

# =============================================================================
# ğŸ”¥ ì§€ì—° ë¡œë”© ë§¤ë‹ˆì € (ë‹¨ìˆœí™”)
# =============================================================================

class SimplePipelineLoader:
    """ë‹¨ìˆœí™”ëœ íŒŒì´í”„ë¼ì¸ ë¡œë”"""
    
    def __init__(self):
        self._loaded_modules = {}
        self._loaded_classes = {}
        self._failed_loads = set()
        self.logger = logging.getLogger(f"{__name__}.SimplePipelineLoader")
        
    def safe_import_step(self, step_id: str) -> Optional[Type]:
        """ì•ˆì „í•œ Step í´ë˜ìŠ¤ import"""
        if step_id in self._loaded_classes:
            return self._loaded_classes[step_id]
            
        if step_id in self._failed_loads:
            return None
            
        try:
            step_info = PIPELINE_STEPS.get(step_id)
            if not step_info:
                self.logger.warning(f"âš ï¸ ì•Œ ìˆ˜ ì—†ëŠ” Step ID: {step_id}")
                return None
                
            # ëª¨ë“ˆ ì´ë¦„ ìƒì„±
            module_name = f"app.ai_pipeline.steps.{step_id}_{step_info['description'].split(' - ')[1].lower().replace(' ', '_')}"
            class_name = step_info['name']
            
            # ë™ì  import ì‹œë„
            import importlib
            try:
                module = importlib.import_module(module_name)
                step_class = getattr(module, class_name, None)
                
                if step_class:
                    self._loaded_classes[step_id] = step_class
                    self.logger.info(f"âœ… {step_id} ({class_name}) ë¡œë“œ ì„±ê³µ")
                    return step_class
                else:
                    self.logger.warning(f"âš ï¸ {class_name} í´ë˜ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
                    
            except ImportError as e:
                self.logger.debug(f"ğŸ“‹ {step_id} ëª¨ë“ˆ ì—†ìŒ (ì •ìƒ): {e}")
                
        except Exception as e:
            self.logger.error(f"âŒ {step_id} ë¡œë“œ ì‹¤íŒ¨: {e}")
            
        # ì‹¤íŒ¨ ê¸°ë¡
        self._failed_loads.add(step_id)
        self._loaded_classes[step_id] = None
        return None
        
    def load_all_available_steps(self) -> Dict[str, Optional[Type]]:
        """ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë“  Step ë¡œë“œ"""
        loaded_steps = {}
        
        # conda í™˜ê²½ì´ë©´ ìš°ì„ ìˆœìœ„ ìˆœìœ¼ë¡œ ë¡œë“œ
        load_order = LOADING_PRIORITY if IS_CONDA else PIPELINE_STEPS.keys()
        
        for step_id in load_order:
            step_class = self.safe_import_step(step_id)
            loaded_steps[step_id] = step_class
            
        available_count = sum(1 for step in loaded_steps.values() if step is not None)
        total_count = len(PIPELINE_STEPS)
        
        self.logger.info(f"ğŸ“Š Step ë¡œë”© ì™„ë£Œ: {available_count}/{total_count}ê°œ")
        if IS_CONDA:
            self.logger.info("ğŸ conda í™˜ê²½: ìš°ì„ ìˆœìœ„ ê¸°ë°˜ ë¡œë”© ì ìš©")
            
        return loaded_steps
        
    def get_step_info(self, step_id: str) -> Dict[str, Any]:
        """Step ì •ë³´ ë°˜í™˜"""
        step_config = PIPELINE_STEPS.get(step_id, {})
        step_class = self._loaded_classes.get(step_id)
        
        return {
            'step_id': step_id,
            'name': step_config.get('name', 'Unknown'),
            'description': step_config.get('description', ''),
            'models': step_config.get('models', []),
            'priority': step_config.get('priority', 10),
            'available': step_class is not None,
            'loaded': step_class is not None,
            'failed': step_id in self._failed_loads
        }

# ì „ì—­ ë¡œë” ì¸ìŠ¤í„´ìŠ¤
_pipeline_loader = SimplePipelineLoader()

# =============================================================================
# ğŸ”¥ ìœ í‹¸ë¦¬í‹° ëª¨ë“ˆ ì•ˆì „í•œ ë¡œë”©
# =============================================================================

def _safe_import_utils():
    """ìœ í‹¸ë¦¬í‹° ëª¨ë“ˆë“¤ ì•ˆì „í•˜ê²Œ import"""
    utils_status = {
        'model_loader': False,
        'memory_manager': False,
        'data_converter': False,
        'model_interface': False
    }
    
    try:
        from .utils import (
            get_step_model_interface,
            get_step_memory_manager, 
            get_step_data_converter,
            preprocess_image_for_step
        )
        utils_status.update({
            'model_loader': True,
            'memory_manager': True,
            'data_converter': True,
            'model_interface': True
        })
        logger.info("âœ… íŒŒì´í”„ë¼ì¸ ìœ í‹¸ë¦¬í‹° ëª¨ë“ˆ ë¡œë“œ ì„±ê³µ")
        
        # ì „ì—­ì— ì¶”ê°€
        globals().update({
            'get_step_model_interface': get_step_model_interface,
            'get_step_memory_manager': get_step_memory_manager,
            'get_step_data_converter': get_step_data_converter,
            'preprocess_image_for_step': preprocess_image_for_step
        })
        
    except ImportError as e:
        logger.warning(f"âš ï¸ ìœ í‹¸ë¦¬í‹° ëª¨ë“ˆ ë¡œë“œ ì‹¤íŒ¨: {e}")
        
        # í´ë°± í•¨ìˆ˜ë“¤
        def _fallback_function(name: str):
            def fallback(*args, **kwargs):
                logger.warning(f"âš ï¸ {name} í•¨ìˆ˜ ì‚¬ìš© ë¶ˆê°€ (ëª¨ë“ˆ ë¡œë“œ ì‹¤íŒ¨)")
                return None
            return fallback
            
        globals().update({
            'get_step_model_interface': _fallback_function('get_step_model_interface'),
            'get_step_memory_manager': _fallback_function('get_step_memory_manager'),
            'get_step_data_converter': _fallback_function('get_step_data_converter'),
            'preprocess_image_for_step': _fallback_function('preprocess_image_for_step')
        })
    
    return utils_status

# ìœ í‹¸ë¦¬í‹° ë¡œë”©
UTILS_STATUS = _safe_import_utils()

# =============================================================================
# ğŸ”¥ íŒŒì´í”„ë¼ì¸ ê´€ë¦¬ í•¨ìˆ˜ë“¤
# =============================================================================

def get_pipeline_status() -> Dict[str, Any]:
    """íŒŒì´í”„ë¼ì¸ ì „ì²´ ìƒíƒœ ë°˜í™˜"""
    loaded_steps = _pipeline_loader.load_all_available_steps()
    available_steps = [k for k, v in loaded_steps.items() if v is not None]
    
    return {
        'system_info': SYSTEM_INFO,
        'conda_optimized': IS_CONDA,
        'm3_max_optimized': IS_M3_MAX,
        'device': DEVICE,
        'total_steps': len(PIPELINE_STEPS),
        'available_steps': len(available_steps),
        'loaded_steps': available_steps,
        'failed_steps': [k for k, v in loaded_steps.items() if v is None],
        'success_rate': (len(available_steps) / len(PIPELINE_STEPS)) * 100,
        'utils_status': UTILS_STATUS,
        'loading_priority': LOADING_PRIORITY if IS_CONDA else None
    }

def get_step_class(step_name: str) -> Optional[Type]:
    """Step í´ë˜ìŠ¤ ë°˜í™˜"""
    if step_name.startswith('step_'):
        return _pipeline_loader.safe_import_step(step_name)
    else:
        # í´ë˜ìŠ¤ëª…ìœ¼ë¡œ ê²€ìƒ‰
        for step_id, step_info in PIPELINE_STEPS.items():
            if step_info['name'] == step_name:
                return _pipeline_loader.safe_import_step(step_id)
    return None

def create_step_instance(step_name: str, **kwargs) -> Optional[Any]:
    """Step ì¸ìŠ¤í„´ìŠ¤ ìƒì„±"""
    step_class = get_step_class(step_name)
    if step_class is None:
        logger.error(f"âŒ Step í´ë˜ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ: {step_name}")
        return None
        
    try:
        # ê¸°ë³¸ ì„¤ì • ì¶”ê°€
        default_config = {
            'device': DEVICE,
            'is_m3_max': IS_M3_MAX,
            'memory_gb': SYSTEM_INFO.get('memory_gb', 16.0),
            'conda_optimized': IS_CONDA
        }
        default_config.update(kwargs)
        
        return step_class(**default_config)
        
    except Exception as e:
        logger.error(f"âŒ Step ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ì‹¤íŒ¨ {step_name}: {e}")
        return None

def list_available_steps() -> List[str]:
    """ì‚¬ìš© ê°€ëŠ¥í•œ Step ëª©ë¡ ë°˜í™˜"""
    loaded_steps = _pipeline_loader.load_all_available_steps()
    return [step_id for step_id, step_class in loaded_steps.items() if step_class is not None]

def get_step_info(step_id: str) -> Dict[str, Any]:
    """Step ì •ë³´ ë°˜í™˜"""
    return _pipeline_loader.get_step_info(step_id)

async def initialize_pipeline_system() -> bool:
    """íŒŒì´í”„ë¼ì¸ ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
    try:
        logger.info("ğŸš€ íŒŒì´í”„ë¼ì¸ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹œì‘")
        
        # Step í´ë˜ìŠ¤ë“¤ ë¡œë“œ
        loaded_steps = _pipeline_loader.load_all_available_steps()
        available_count = sum(1 for step in loaded_steps.values() if step is not None)
        
        logger.info(f"âœ… íŒŒì´í”„ë¼ì¸ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ: {available_count}/{len(PIPELINE_STEPS)}ê°œ Step")
        return available_count > 0
        
    except Exception as e:
        logger.error(f"âŒ íŒŒì´í”„ë¼ì¸ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return False

async def cleanup_pipeline_system() -> None:
    """íŒŒì´í”„ë¼ì¸ ì‹œìŠ¤í…œ ì •ë¦¬"""
    try:
        logger.info("ğŸ§¹ íŒŒì´í”„ë¼ì¸ ì‹œìŠ¤í…œ ì •ë¦¬ ì‹œì‘")
        
        # ìºì‹œ ì •ë¦¬
        _pipeline_loader._loaded_modules.clear()
        _pipeline_loader._loaded_classes.clear()
        _pipeline_loader._failed_loads.clear()
        
        # GPU ë©”ëª¨ë¦¬ ì •ë¦¬ (ê°€ëŠ¥í•œ ê²½ìš°)
        if DEVICE in ['cuda', 'mps']:
            try:
                import torch
                if DEVICE == 'cuda' and torch.cuda.is_available():
                    torch.cuda.empty_cache()
                elif DEVICE == 'mps' and torch.backends.mps.is_available():
                    # M3 Max ë©”ëª¨ë¦¬ ì •ë¦¬ (ì•ˆì „í•˜ê²Œ)
                    import gc
                    gc.collect()
            except:
                pass
                
        logger.info("âœ… íŒŒì´í”„ë¼ì¸ ì‹œìŠ¤í…œ ì •ë¦¬ ì™„ë£Œ")
        
    except Exception as e:
        logger.warning(f"âš ï¸ íŒŒì´í”„ë¼ì¸ ì‹œìŠ¤í…œ ì •ë¦¬ ì‹¤íŒ¨: {e}")

# =============================================================================
# ğŸ”¥ ìë™ Step í´ë˜ìŠ¤ ë¡œë”© (ì „ì—­ ë³€ìˆ˜)
# =============================================================================

# ì‚¬ìš© ê°€ëŠ¥í•œ Step í´ë˜ìŠ¤ë“¤ì„ ì „ì—­ ë³€ìˆ˜ë¡œ ì„¤ì •
try:
    _loaded_steps = _pipeline_loader.load_all_available_steps()
    
    # ê°œë³„ Step í´ë˜ìŠ¤ë“¤ì„ ì „ì—­ì— ì¶”ê°€
    for step_id, step_class in _loaded_steps.items():
        if step_class:
            step_info = PIPELINE_STEPS[step_id]
            class_name = step_info['name']
            globals()[class_name] = step_class
            
    logger.info("âœ… Step í´ë˜ìŠ¤ë“¤ ì „ì—­ ì„¤ì • ì™„ë£Œ")
    
except Exception as e:
    logger.warning(f"âš ï¸ Step í´ë˜ìŠ¤ ì „ì—­ ì„¤ì • ì‹¤íŒ¨: {e}")

# =============================================================================
# ğŸ”¥ Export ëª©ë¡
# =============================================================================

__all__ = [
    # ğŸ¯ íŒŒì´í”„ë¼ì¸ ìƒìˆ˜
    'PIPELINE_STEPS',
    'LOADING_PRIORITY',
    'SYSTEM_INFO',
    
    # ğŸ”§ íŒŒì´í”„ë¼ì¸ ê´€ë¦¬ í•¨ìˆ˜ë“¤
    'get_pipeline_status',
    'get_step_class',
    'create_step_instance',
    'list_available_steps',
    'get_step_info',
    'initialize_pipeline_system',
    'cleanup_pipeline_system',
    
    # ğŸ› ï¸ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤ (ì¡°ê±´ë¶€)
    'get_step_model_interface',
    'get_step_memory_manager',
    'get_step_data_converter', 
    'preprocess_image_for_step',
    
    # ğŸ“Š ìƒíƒœ ì •ë³´
    'UTILS_STATUS',
    'IS_CONDA',
    'IS_M3_MAX',
    'DEVICE'
]

# Step í´ë˜ìŠ¤ë“¤ë„ ë™ì ìœ¼ë¡œ ì¶”ê°€
for step_info in PIPELINE_STEPS.values():
    class_name = step_info['name']
    if class_name in globals():
        __all__.append(class_name)

# =============================================================================
# ğŸ”¥ ì´ˆê¸°í™” ì™„ë£Œ ë©”ì‹œì§€
# =============================================================================

def _print_initialization_summary():
    """ì´ˆê¸°í™” ìš”ì•½ ì¶œë ¥"""
    status = get_pipeline_status()
    available_count = status['available_steps']
    total_count = status['total_steps']
    success_rate = status['success_rate']
    
    print(f"\nğŸ MyCloset AI íŒŒì´í”„ë¼ì¸ ì‹œìŠ¤í…œ v7.0 ì´ˆê¸°í™” ì™„ë£Œ!")
    print(f"ğŸ“Š ì‚¬ìš© ê°€ëŠ¥í•œ Step: {available_count}/{total_count}ê°œ ({success_rate:.1f}%)")
    print(f"ğŸ conda í™˜ê²½: {'âœ…' if IS_CONDA else 'âŒ'}")
    print(f"ğŸ M3 Max: {'âœ…' if IS_M3_MAX else 'âŒ'}")
    print(f"ğŸ–¥ï¸ ë””ë°”ì´ìŠ¤: {DEVICE}")
    print(f"ğŸ› ï¸ ìœ í‹¸ë¦¬í‹°: {sum(UTILS_STATUS.values())}/4ê°œ ì‚¬ìš© ê°€ëŠ¥")
    
    if available_count > 0:
        print(f"âœ… ë¡œë“œëœ Steps: {', '.join(status['loaded_steps'])}")
    
    if status['failed_steps']:
        print(f"âš ï¸ ì‹¤íŒ¨í•œ Steps: {', '.join(status['failed_steps'])}")
        
    print("ğŸš€ íŒŒì´í”„ë¼ì¸ ì‹œìŠ¤í…œ ì¤€ë¹„ ì™„ë£Œ!\n")

# ì´ˆê¸°í™” ìƒíƒœ ì¶œë ¥ (í•œ ë²ˆë§Œ)
if not hasattr(sys, '_mycloset_pipeline_initialized'):
    _print_initialization_summary()
    sys._mycloset_pipeline_initialized = True

logger.info("ğŸ MyCloset AI íŒŒì´í”„ë¼ì¸ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")