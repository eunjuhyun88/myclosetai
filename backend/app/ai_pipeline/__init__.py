#app/ai_pipeline/__init__.py
# app/ai_pipeline/__init__.py
"""
ğŸ MyCloset AI íŒŒì´í”„ë¼ì¸ ë©”ì¸ ëª¨ë“ˆ v6.0
âœ… ì™„ì „í•œ ëª¨ë“ˆ êµ¬ì¡° ë° import ì‹œìŠ¤í…œ
âœ… ìˆœí™˜ì°¸ì¡° ì™„ì „ í•´ê²°
âœ… main.py ì™„ë²½ í˜¸í™˜
âœ… ë¹„ë™ê¸° ì²˜ë¦¬ ì™„ì „ ì§€ì›
âœ… M3 Max 128GB ìµœì í™”
âœ… conda í™˜ê²½ ì™„ë²½ ì§€ì›
âœ… í”„ë¡œë•ì…˜ ì•ˆì •ì„±

êµ¬ì¡°:
- steps/: 8ë‹¨ê³„ AI íŒŒì´í”„ë¼ì¸ í´ë˜ìŠ¤ë“¤
- utils/: ìœ í‹¸ë¦¬í‹° ë° í†µí•© ì‹œìŠ¤í…œ
- models/: AI ëª¨ë¸ ê´€ë ¨ í´ë˜ìŠ¤ë“¤
- pipeline_manager.py: íŒŒì´í”„ë¼ì¸ í†µí•© ê´€ë¦¬ì
"""

import os
import sys
import logging
import asyncio
import time
import threading
from typing import Dict, Any, Optional, List, Union, Callable, Type
from pathlib import Path
from dataclasses import dataclass, field
from enum import Enum
import weakref

# ê¸°ë³¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ë“¤
try:
    import torch
    import numpy as np
    from PIL import Image
    CORE_LIBS_AVAILABLE = True
except ImportError as e:
    logging.warning(f"í•µì‹¬ ë¼ì´ë¸ŒëŸ¬ë¦¬ import ì‹¤íŒ¨: {e}")
    CORE_LIBS_AVAILABLE = False

# ==============================================
# ğŸ”¥ ë²„ì „ ë° ê¸°ë³¸ ì •ë³´
# ==============================================

__version__ = "6.0.0"
__author__ = "MyCloset AI Team"
__description__ = "AI ê¸°ë°˜ ê°€ìƒ í”¼íŒ… íŒŒì´í”„ë¼ì¸ ì‹œìŠ¤í…œ"

# ë¡œê¹… ì„¤ì •
logger = logging.getLogger(__name__)

# ==============================================
# ğŸ”¥ ì‹œìŠ¤í…œ ì •ë³´ ê°ì§€
# ==============================================

def _detect_system_info() -> Dict[str, Any]:
    """ì‹œìŠ¤í…œ ì •ë³´ ìë™ ê°ì§€"""
    try:
        import platform
        
        system_info = {
            "platform": platform.system(),
            "machine": platform.machine(),
            "python_version": ".".join(map(str, sys.version_info[:3])),
            "cpu_count": os.cpu_count() or 4
        }
        
        # M3 Max ê°ì§€
        is_m3_max = False
        if platform.system() == 'Darwin' and platform.machine() == 'arm64':
            try:
                import subprocess
                result = subprocess.run(['sysctl', '-n', 'machdep.cpu.brand_string'], 
                                      capture_output=True, text=True, timeout=3)
                is_m3_max = 'M3' in result.stdout
            except:
                pass
        
        system_info["is_m3_max"] = is_m3_max
        
        # ë””ë°”ì´ìŠ¤ ê°ì§€
        device = "cpu"
        if CORE_LIBS_AVAILABLE and torch is not None:
            if torch.backends.mps.is_available():
                device = "mps"
            elif torch.cuda.is_available():
                device = "cuda"
        
        system_info["device"] = device
        
        # ë©”ëª¨ë¦¬ ê°ì§€
        try:
            import psutil
            system_info["memory_gb"] = round(psutil.virtual_memory().total / (1024**3))
        except ImportError:
            system_info["memory_gb"] = 128 if is_m3_max else 16
        
        return system_info
        
    except Exception as e:
        logger.warning(f"ì‹œìŠ¤í…œ ì •ë³´ ê°ì§€ ì‹¤íŒ¨: {e}")
        return {
            "platform": "unknown",
            "is_m3_max": False,
            "device": "cpu",
            "cpu_count": 4,
            "memory_gb": 16,
            "python_version": "3.8.0"
        }

# ì „ì—­ ì‹œìŠ¤í…œ ì •ë³´
SYSTEM_INFO = _detect_system_info()

# ==============================================
# ğŸ”¥ ì„¤ì • ë°ì´í„° í´ë˜ìŠ¤ë“¤
# ==============================================

class PipelineMode(Enum):
    """íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ëª¨ë“œ"""
    DEVELOPMENT = "development"
    PRODUCTION = "production"
    TESTING = "testing"
    SIMULATION = "simulation"

class QualityLevel(Enum):
    """í’ˆì§ˆ ë ˆë²¨"""
    FAST = "fast"
    BALANCED = "balanced"
    HIGH = "high"
    ULTRA = "ultra"

@dataclass
class PipelineConfig:
    """íŒŒì´í”„ë¼ì¸ ì„¤ì •"""
    mode: PipelineMode = PipelineMode.PRODUCTION
    quality_level: QualityLevel = QualityLevel.BALANCED
    device: str = "auto"
    batch_size: int = 1
    image_size: int = 512
    use_fp16: bool = True
    enable_caching: bool = True
    memory_limit_gb: float = 16.0
    max_workers: int = 4
    timeout_seconds: int = 300
    save_intermediate: bool = False
    optimization_enabled: bool = True
    
    def __post_init__(self):
        # auto ë””ë°”ì´ìŠ¤ í•´ì„
        if self.device == "auto":
            self.device = SYSTEM_INFO["device"]
        
        # M3 Max ìµœì í™”
        if SYSTEM_INFO["is_m3_max"]:
            self.memory_limit_gb = min(self.memory_limit_gb, 102.4)  # 128GBì˜ 80%
            self.max_workers = min(self.max_workers, 8)
            self.use_fp16 = True

@dataclass
class ProcessingResult:
    """ì²˜ë¦¬ ê²°ê³¼"""
    success: bool
    message: str
    processing_time: float
    confidence: float
    session_id: Optional[str] = None
    step_results: Dict[str, Any] = field(default_factory=dict)
    intermediate_data: Dict[str, Any] = field(default_factory=dict)
    memory_usage: Dict[str, float] = field(default_factory=dict)
    error: Optional[str] = None

# ==============================================
# ğŸ”¥ í†µí•© ìœ í‹¸ë¦¬í‹° ì‹œìŠ¤í…œ Import
# ==============================================

# 1. í†µí•© ìœ í‹¸ë¦¬í‹° ì‹œìŠ¤í…œ (ìµœìš°ì„ )
try:
    from .utils import (
        # í•µì‹¬ ê´€ë¦¬ìë“¤
        get_utils_manager,
        initialize_global_utils,
        get_system_status,
        reset_global_utils,
        
        # ì¸í„°í˜ì´ìŠ¤ ìƒì„± í•¨ìˆ˜ë“¤
        get_step_model_interface,
        create_step_interface,
        create_unified_interface,
        
        # ì‹œìŠ¤í…œ ì •ë³´
        SYSTEM_INFO as UTILS_SYSTEM_INFO,
        optimize_system_memory,
        
        # í´ë˜ìŠ¤ë“¤
        UnifiedUtilsManager,
        UnifiedStepInterface,
        StepModelInterface,
        SystemConfig,
        StepConfig,
        ModelInfo
    )
    UNIFIED_UTILS_AVAILABLE = True
    logger.info("âœ… í†µí•© ìœ í‹¸ë¦¬í‹° ì‹œìŠ¤í…œ ë¡œë“œ ì™„ë£Œ")
except ImportError as e:
    UNIFIED_UTILS_AVAILABLE = False
    logger.warning(f"âš ï¸ í†µí•© ìœ í‹¸ë¦¬í‹° ì‹œìŠ¤í…œ ì‚¬ìš© ë¶ˆê°€: {e}")
    
    # í´ë°± í•¨ìˆ˜ë“¤
    def get_step_model_interface(step_name: str, model_loader_instance=None):
        """í´ë°± í•¨ìˆ˜"""
        logger.warning(f"âš ï¸ í´ë°± ëª¨ë“œ: {step_name} ì¸í„°í˜ì´ìŠ¤")
        return {
            "step_name": step_name,
            "error": "í†µí•© ìœ í‹¸ë¦¬í‹° ì‹œìŠ¤í…œ ì‚¬ìš© ë¶ˆê°€",
            "get_model": lambda: None,
            "list_available_models": lambda: []
        }
    
    def initialize_global_utils(**kwargs):
        return {"success": False, "error": "í†µí•© ìœ í‹¸ë¦¬í‹° ì‹œìŠ¤í…œ ì‚¬ìš© ë¶ˆê°€"}

# 2. ModelLoader ì‹œìŠ¤í…œ
try:
    from .utils.model_loader import (
        ModelLoader,
        get_global_model_loader,
        initialize_global_model_loader,
        SafeModelService,
        StepModelConfig
    )
    MODEL_LOADER_AVAILABLE = True
    logger.info("âœ… ModelLoader ì‹œìŠ¤í…œ ë¡œë“œ ì™„ë£Œ")
except ImportError as e:
    MODEL_LOADER_AVAILABLE = False
    logger.warning(f"âš ï¸ ModelLoader ì‹œìŠ¤í…œ ì‚¬ìš© ë¶ˆê°€: {e}")
    
    # í´ë°± í´ë˜ìŠ¤
    class ModelLoader:
        def __init__(self, **kwargs):
            self.logger = logging.getLogger("fallback.ModelLoader")
        
        def get_model(self, model_name):
            return None

# 3. ë©”ëª¨ë¦¬ ê´€ë¦¬ ì‹œìŠ¤í…œ
try:
    from .utils.memory_manager import (
        MemoryManager,
        GPUMemoryManager,
        get_global_memory_manager
    )
    MEMORY_MANAGER_AVAILABLE = True
    logger.info("âœ… ë©”ëª¨ë¦¬ ê´€ë¦¬ ì‹œìŠ¤í…œ ë¡œë“œ ì™„ë£Œ")
except ImportError as e:
    MEMORY_MANAGER_AVAILABLE = False
    logger.warning(f"âš ï¸ ë©”ëª¨ë¦¬ ê´€ë¦¬ ì‹œìŠ¤í…œ ì‚¬ìš© ë¶ˆê°€: {e}")

# 4. ë°ì´í„° ë³€í™˜ ì‹œìŠ¤í…œ
try:
    from .utils.data_converter import (
        DataConverter,
        get_global_data_converter,
        ImageProcessor
    )
    DATA_CONVERTER_AVAILABLE = True
    logger.info("âœ… ë°ì´í„° ë³€í™˜ ì‹œìŠ¤í…œ ë¡œë“œ ì™„ë£Œ")
except ImportError as e:
    DATA_CONVERTER_AVAILABLE = False
    logger.warning(f"âš ï¸ ë°ì´í„° ë³€í™˜ ì‹œìŠ¤í…œ ì‚¬ìš© ë¶ˆê°€: {e}")

# ==============================================
# ğŸ”¥ AI íŒŒì´í”„ë¼ì¸ Steps Import
# ==============================================

# Step í´ë˜ìŠ¤ë“¤ Import
AI_STEPS_AVAILABLE = False
_step_classes = {}

try:
    from .steps.step_01_human_parsing import HumanParsingStep, create_human_parsing_step
    from .steps.step_02_pose_estimation import PoseEstimationStep, create_pose_estimation_step
    from .steps.step_03_cloth_segmentation import ClothSegmentationStep, create_cloth_segmentation_step
    from .steps.step_04_geometric_matching import GeometricMatchingStep, create_geometric_matching_step
    from .steps.step_05_cloth_warping import ClothWarpingStep, create_cloth_warping_step
    from .steps.step_06_virtual_fitting import VirtualFittingStep, create_virtual_fitting_step
    from .steps.step_07_post_processing import PostProcessingStep, create_post_processing_step
    from .steps.step_08_quality_assessment import QualityAssessmentStep, create_quality_assessment_step
    
    # Step í´ë˜ìŠ¤ ë§¤í•‘
    _step_classes = {
        "step_01": HumanParsingStep,
        "step_02": PoseEstimationStep,
        "step_03": ClothSegmentationStep,
        "step_04": GeometricMatchingStep,
        "step_05": ClothWarpingStep,
        "step_06": VirtualFittingStep,
        "step_07": PostProcessingStep,
        "step_08": QualityAssessmentStep,
        
        # ì´ë¦„ìœ¼ë¡œë„ ì ‘ê·¼ ê°€ëŠ¥
        "HumanParsingStep": HumanParsingStep,
        "PoseEstimationStep": PoseEstimationStep,
        "ClothSegmentationStep": ClothSegmentationStep,
        "GeometricMatchingStep": GeometricMatchingStep,
        "ClothWarpingStep": ClothWarpingStep,
        "VirtualFittingStep": VirtualFittingStep,
        "PostProcessingStep": PostProcessingStep,
        "QualityAssessmentStep": QualityAssessmentStep
    }
    
    AI_STEPS_AVAILABLE = True
    logger.info("âœ… 8ë‹¨ê³„ AI Steps ë¡œë“œ ì™„ë£Œ")
    
except ImportError as e:
    logger.warning(f"âš ï¸ AI Steps ì¼ë¶€ ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    # ê°œë³„ Stepë“¤ ì„ íƒì  ë¡œë“œ
    try:
        from .steps.step_01_human_parsing import HumanParsingStep, create_human_parsing_step
        _step_classes["step_01"] = HumanParsingStep
        _step_classes["HumanParsingStep"] = HumanParsingStep
        logger.info("âœ… Step 01 Human Parsing ë¡œë“œ ì™„ë£Œ")
    except ImportError:
        logger.warning("âš ï¸ Step 01 Human Parsing ë¡œë“œ ì‹¤íŒ¨")
    
    try:
        from .steps.step_02_pose_estimation import PoseEstimationStep, create_pose_estimation_step
        _step_classes["step_02"] = PoseEstimationStep
        _step_classes["PoseEstimationStep"] = PoseEstimationStep
        logger.info("âœ… Step 02 Pose Estimation ë¡œë“œ ì™„ë£Œ")
    except ImportError:
        logger.warning("âš ï¸ Step 02 Pose Estimation ë¡œë“œ ì‹¤íŒ¨")
    
    try:
        from .steps.step_03_cloth_segmentation import ClothSegmentationStep, create_cloth_segmentation_step
        _step_classes["step_03"] = ClothSegmentationStep
        _step_classes["ClothSegmentationStep"] = ClothSegmentationStep
        logger.info("âœ… Step 03 Cloth Segmentation ë¡œë“œ ì™„ë£Œ")
    except ImportError:
        logger.warning("âš ï¸ Step 03 Cloth Segmentation ë¡œë“œ ì‹¤íŒ¨")
    
    # ë‚˜ë¨¸ì§€ Stepë“¤ë„ ë™ì¼í•˜ê²Œ...
    for step_num in range(4, 9):
        step_names = {
            4: ("geometric_matching", "GeometricMatchingStep"),
            5: ("cloth_warping", "ClothWarpingStep"),
            6: ("virtual_fitting", "VirtualFittingStep"),
            7: ("post_processing", "PostProcessingStep"),
            8: ("quality_assessment", "QualityAssessmentStep")
        }
        
        step_module, step_class = step_names[step_num]
        try:
            module = __import__(f".steps.step_{step_num:02d}_{step_module}", fromlist=[step_class])
            step_cls = getattr(module, step_class)
            _step_classes[f"step_{step_num:02d}"] = step_cls
            _step_classes[step_class] = step_cls
            logger.info(f"âœ… Step {step_num:02d} {step_class} ë¡œë“œ ì™„ë£Œ")
        except ImportError:
            logger.warning(f"âš ï¸ Step {step_num:02d} {step_class} ë¡œë“œ ì‹¤íŒ¨")

# ==============================================
# ğŸ”¥ PipelineManager Import
# ==============================================

try:
    from .pipeline_manager import (
        PipelineManager,
        create_pipeline,
        create_m3_max_pipeline,
        create_production_pipeline,
        create_development_pipeline,
        create_testing_pipeline,
        get_global_pipeline_manager
    )
    PIPELINE_MANAGER_AVAILABLE = True
    logger.info("âœ… PipelineManager ë¡œë“œ ì™„ë£Œ")
except ImportError as e:
    PIPELINE_MANAGER_AVAILABLE = False
    logger.warning(f"âš ï¸ PipelineManager ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    # í´ë°± PipelineManager
    class PipelineManager:
        """í´ë°± PipelineManager"""
        def __init__(self, config: Optional[PipelineConfig] = None, **kwargs):
            self.config = config or PipelineConfig()
            self.logger = logging.getLogger("fallback.PipelineManager")
            self.is_initialized = False
        
        async def initialize(self) -> bool:
            self.is_initialized = True
            return True
        
        async def process_complete_pipeline(self, inputs: Dict[str, Any]) -> ProcessingResult:
            return ProcessingResult(
                success=False,
                message="PipelineManager í´ë°± ëª¨ë“œ",
                processing_time=0.0,
                confidence=0.0,
                error="ì‹¤ì œ PipelineManagerë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤"
            )
        
        async def cleanup(self):
            pass
    
    def create_m3_max_pipeline(**kwargs) -> PipelineManager:
        return PipelineManager(**kwargs)
    
    def create_production_pipeline(**kwargs) -> PipelineManager:
        return PipelineManager(**kwargs)

# ==============================================
# ğŸ”¥ íŒ©í† ë¦¬ í•¨ìˆ˜ë“¤
# ==============================================

def get_step_class(step_name: Union[str, int]) -> Optional[Type]:
    """Step í´ë˜ìŠ¤ ë°˜í™˜"""
    try:
        if isinstance(step_name, int):
            step_key = f"step_{step_name:02d}"
        else:
            step_key = step_name
        
        return _step_classes.get(step_key)
    except Exception as e:
        logger.error(f"Step í´ë˜ìŠ¤ ì¡°íšŒ ì‹¤íŒ¨ {step_name}: {e}")
        return None

def create_step_instance(step_name: Union[str, int], **kwargs) -> Optional[Any]:
    """Step ì¸ìŠ¤í„´ìŠ¤ ìƒì„±"""
    try:
        step_class = get_step_class(step_name)
        if step_class is None:
            logger.error(f"Step í´ë˜ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ: {step_name}")
            return None
        
        # ê¸°ë³¸ ì„¤ì • ì¶”ê°€
        default_config = {
            "device": SYSTEM_INFO["device"],
            "is_m3_max": SYSTEM_INFO["is_m3_max"],
            "memory_gb": SYSTEM_INFO["memory_gb"]
        }
        default_config.update(kwargs)
        
        return step_class(**default_config)
        
    except Exception as e:
        logger.error(f"Step ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ì‹¤íŒ¨ {step_name}: {e}")
        return None

def list_available_steps() -> List[str]:
    """ì‚¬ìš© ê°€ëŠ¥í•œ Step ëª©ë¡ ë°˜í™˜"""
    return list(_step_classes.keys())

def get_pipeline_status() -> Dict[str, Any]:
    """íŒŒì´í”„ë¼ì¸ ì‹œìŠ¤í…œ ìƒíƒœ ë°˜í™˜"""
    return {
        "version": __version__,
        "system_info": SYSTEM_INFO,
        "availability": {
            "unified_utils": UNIFIED_UTILS_AVAILABLE,
            "model_loader": MODEL_LOADER_AVAILABLE,
            "memory_manager": MEMORY_MANAGER_AVAILABLE,
            "data_converter": DATA_CONVERTER_AVAILABLE,
            "ai_steps": AI_STEPS_AVAILABLE,
            "pipeline_manager": PIPELINE_MANAGER_AVAILABLE,
            "core_libs": CORE_LIBS_AVAILABLE
        },
        "available_steps": list_available_steps(),
        "step_count": len(_step_classes)
    }

# ==============================================
# ğŸ”¥ ì´ˆê¸°í™” í•¨ìˆ˜ë“¤
# ==============================================

async def initialize_pipeline_system(**kwargs) -> Dict[str, Any]:
    """ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
    try:
        start_time = time.time()
        results = {}
        
        # 1. í†µí•© ìœ í‹¸ë¦¬í‹° ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        if UNIFIED_UTILS_AVAILABLE:
            try:
                utils_result = initialize_global_utils(**kwargs)
                results["unified_utils"] = utils_result
                logger.info("âœ… í†µí•© ìœ í‹¸ë¦¬í‹° ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
            except Exception as e:
                logger.error(f"âŒ í†µí•© ìœ í‹¸ë¦¬í‹° ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                results["unified_utils"] = {"success": False, "error": str(e)}
        
        # 2. ModelLoader ì´ˆê¸°í™”
        if MODEL_LOADER_AVAILABLE:
            try:
                model_loader_result = initialize_global_model_loader(**kwargs)
                results["model_loader"] = model_loader_result
                logger.info("âœ… ModelLoader ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
            except Exception as e:
                logger.error(f"âŒ ModelLoader ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                results["model_loader"] = {"success": False, "error": str(e)}
        
        # 3. íŒŒì´í”„ë¼ì¸ ë§¤ë‹ˆì € ì´ˆê¸°í™”
        if PIPELINE_MANAGER_AVAILABLE:
            try:
                pipeline = create_m3_max_pipeline(**kwargs)
                await pipeline.initialize()
                results["pipeline_manager"] = {"success": True, "initialized": True}
                logger.info("âœ… PipelineManager ì´ˆê¸°í™” ì™„ë£Œ")
            except Exception as e:
                logger.error(f"âŒ PipelineManager ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                results["pipeline_manager"] = {"success": False, "error": str(e)}
        
        initialization_time = time.time() - start_time
        
        return {
            "success": True,
            "initialization_time": initialization_time,
            "results": results,
            "system_status": get_pipeline_status()
        }
        
    except Exception as e:
        logger.error(f"âŒ íŒŒì´í”„ë¼ì¸ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return {
            "success": False,
            "error": str(e),
            "system_status": get_pipeline_status()
        }

async def cleanup_pipeline_system():
    """ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹œìŠ¤í…œ ì •ë¦¬"""
    try:
        # í†µí•© ìœ í‹¸ë¦¬í‹° ì‹œìŠ¤í…œ ì •ë¦¬
        if UNIFIED_UTILS_AVAILABLE:
            try:
                await reset_global_utils()
                logger.info("âœ… í†µí•© ìœ í‹¸ë¦¬í‹° ì‹œìŠ¤í…œ ì •ë¦¬ ì™„ë£Œ")
            except Exception as e:
                logger.error(f"âŒ í†µí•© ìœ í‹¸ë¦¬í‹° ì‹œìŠ¤í…œ ì •ë¦¬ ì‹¤íŒ¨: {e}")
        
        # ë©”ëª¨ë¦¬ ì •ë¦¬
        try:
            import gc
            gc.collect()
            
            if CORE_LIBS_AVAILABLE and torch is not None:
                if torch.backends.mps.is_available():
                    try:
                        if hasattr(torch.mps, 'empty_cache'):
                            safe_mps_empty_cache()
                    except:
                        pass
                elif torch.cuda.is_available():
                    torch.cuda.empty_cache()
            
            logger.info("âœ… ë©”ëª¨ë¦¬ ì •ë¦¬ ì™„ë£Œ")
        except Exception as e:
            logger.error(f"âŒ ë©”ëª¨ë¦¬ ì •ë¦¬ ì‹¤íŒ¨: {e}")
        
        logger.info("ğŸ‰ íŒŒì´í”„ë¼ì¸ ì‹œìŠ¤í…œ ì •ë¦¬ ì™„ë£Œ")
        
    except Exception as e:
        logger.error(f"âŒ íŒŒì´í”„ë¼ì¸ ì‹œìŠ¤í…œ ì •ë¦¬ ì‹¤íŒ¨: {e}")

# ==============================================
# ğŸ”¥ __all__ ì •ì˜
# ==============================================

__all__ = [
    # ğŸ¯ ë²„ì „ ì •ë³´
    "__version__",
    "__author__",
    "__description__",
    
    # ğŸ“Š ì‹œìŠ¤í…œ ì •ë³´
    "SYSTEM_INFO",
    "get_pipeline_status",
    
    # ğŸ”§ ì„¤ì • í´ë˜ìŠ¤ë“¤
    "PipelineConfig",
    "ProcessingResult",
    "PipelineMode",
    "QualityLevel",
    
    # ğŸ—ï¸ íŒ©í† ë¦¬ í•¨ìˆ˜ë“¤
    "get_step_class",
    "create_step_instance",
    "list_available_steps",
    
    # ğŸš€ ì´ˆê¸°í™” í•¨ìˆ˜ë“¤
    "initialize_pipeline_system",
    "cleanup_pipeline_system",
    
    # ğŸ“¦ Step í´ë˜ìŠ¤ë“¤ (ì‚¬ìš© ê°€ëŠ¥í•œ ê²ƒë“¤ë§Œ)
    *[class_name for class_name in _step_classes.keys() if not class_name.startswith("step_")]
]

# ì¡°ê±´ë¶€ export
if PIPELINE_MANAGER_AVAILABLE:
    __all__.extend([
        "PipelineManager",
        "create_pipeline",
        "create_m3_max_pipeline",
        "create_production_pipeline",
        "create_development_pipeline",
        "create_testing_pipeline",
        "get_global_pipeline_manager"
    ])

if UNIFIED_UTILS_AVAILABLE:
    __all__.extend([
        "get_utils_manager",
        "initialize_global_utils",
        "get_system_status",
        "reset_global_utils",
        "get_step_model_interface",
        "UnifiedUtilsManager",
        "UnifiedStepInterface",
        "StepModelInterface"
    ])

if MODEL_LOADER_AVAILABLE:
    __all__.extend([
        "ModelLoader",
        "get_global_model_loader",
        "initialize_global_model_loader"
    ])

# Step ìƒì„± í•¨ìˆ˜ë“¤ (ì‚¬ìš© ê°€ëŠ¥í•œ ê²ƒë“¤ë§Œ)
step_creators = []
if "create_human_parsing_step" in globals():
    step_creators.append("create_human_parsing_step")
if "create_pose_estimation_step" in globals():
    step_creators.append("create_pose_estimation_step")
if "create_cloth_segmentation_step" in globals():
    step_creators.append("create_cloth_segmentation_step")
if "create_geometric_matching_step" in globals():
    step_creators.append("create_geometric_matching_step")
if "create_cloth_warping_step" in globals():
    step_creators.append("create_cloth_warping_step")
if "create_virtual_fitting_step" in globals():
    step_creators.append("create_virtual_fitting_step")
if "create_post_processing_step" in globals():
    step_creators.append("create_post_processing_step")
if "create_quality_assessment_step" in globals():
    step_creators.append("create_quality_assessment_step")

__all__.extend(step_creators)

# ==============================================
# ğŸ”¥ ëª¨ë“ˆ ì´ˆê¸°í™” ì™„ë£Œ ë¡œê¹…
# ==============================================

logger.info("=" * 80)
logger.info("ğŸ MyCloset AI íŒŒì´í”„ë¼ì¸ ì‹œìŠ¤í…œ v6.0 ë¡œë“œ ì™„ë£Œ")
logger.info("=" * 80)
logger.info(f"ğŸ”§ ì‹œìŠ¤í…œ: {SYSTEM_INFO['platform']} / {SYSTEM_INFO['device']}")
logger.info(f"ğŸ M3 Max: {'âœ…' if SYSTEM_INFO['is_m3_max'] else 'âŒ'}")
logger.info(f"ğŸ’¾ ë©”ëª¨ë¦¬: {SYSTEM_INFO['memory_gb']}GB")
logger.info(f"ğŸ§  CPU ì½”ì–´: {SYSTEM_INFO['cpu_count']}ê°œ")
logger.info(f"ğŸ Python: {SYSTEM_INFO['python_version']}")
logger.info("=" * 80)
logger.info("ğŸ“¦ ëª¨ë“ˆ ê°€ìš©ì„±:")
logger.info(f"   - í†µí•© ìœ í‹¸ë¦¬í‹°: {'âœ…' if UNIFIED_UTILS_AVAILABLE else 'âŒ'}")
logger.info(f"   - ModelLoader: {'âœ…' if MODEL_LOADER_AVAILABLE else 'âŒ'}")
logger.info(f"   - ë©”ëª¨ë¦¬ ê´€ë¦¬: {'âœ…' if MEMORY_MANAGER_AVAILABLE else 'âŒ'}")
logger.info(f"   - ë°ì´í„° ë³€í™˜: {'âœ…' if DATA_CONVERTER_AVAILABLE else 'âŒ'}")
logger.info(f"   - AI Steps: {'âœ…' if AI_STEPS_AVAILABLE else 'âŒ'} ({len(_step_classes)}ê°œ)")
logger.info(f"   - PipelineManager: {'âœ…' if PIPELINE_MANAGER_AVAILABLE else 'âŒ'}")
logger.info(f"   - í•µì‹¬ ë¼ì´ë¸ŒëŸ¬ë¦¬: {'âœ…' if CORE_LIBS_AVAILABLE else 'âŒ'}")
logger.info("=" * 80)
logger.info("ğŸ¯ ì‚¬ìš© ê°€ëŠ¥í•œ Steps:")
for step_name in sorted([k for k in _step_classes.keys() if not k.startswith("step_")]):
    logger.info(f"   - {step_name}")
logger.info("=" * 80)
logger.info("ğŸš€ ì´ˆê¸°í™” ì¤€ë¹„ ì™„ë£Œ! initialize_pipeline_system() í˜¸ì¶œí•˜ì—¬ ì‹œì‘í•˜ì„¸ìš”.")
logger.info("=" * 80)

# ì¢…ë£Œ ì‹œ ì •ë¦¬ ë“±ë¡
import atexit

def _cleanup_on_exit():
    """ì¢…ë£Œ ì‹œ ì •ë¦¬"""
    try:
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        loop.run_until_complete(cleanup_pipeline_system())
        loop.close()
    except Exception as e:
        logger.warning(f"âš ï¸ ì¢…ë£Œ ì‹œ ì •ë¦¬ ì‹¤íŒ¨: {e}")

atexit.register(_cleanup_on_exit)