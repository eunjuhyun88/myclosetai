#!/usr/bin/env python3
"""
ğŸ”¥ MyCloset AI íŒŒì´í”„ë¼ì¸ ì‹œìŠ¤í…œ v7.1 - Step 01 ê²½ë¡œ ë¬¸ì œ ì™„ì „ í•´ê²°
================================================================

âœ… Step 01 ëª¨ë“ˆ ê²½ë¡œ ë¬¸ì œ í•´ê²° (human_body_parsing â†’ human_parsing)
âœ… ì •í™•í•œ íŒŒì¼ëª… ë§¤í•‘ ì‹œìŠ¤í…œ
âœ… ë³µì¡í•œ ë™ì  ìƒì„± ì œê±°
âœ… ì§ì ‘ ë§¤í•‘ìœ¼ë¡œ ë‹¨ìˆœí™”

ë¬¸ì œ í•´ê²°:
- ê¸°ì¡´: step_01_human_body_parsing (ì˜ëª»ëœ ê²½ë¡œ)
- ìˆ˜ì •: step_01_human_parsing (ì˜¬ë°”ë¥¸ ê²½ë¡œ)

Author: MyCloset AI Team
Date: 2025-07-25
Version: v7.1 (Step 01 Path Fix)
"""

import logging
import sys
import warnings
from typing import Dict, Any, Optional, List, Type
from pathlib import Path

# ê²½ê³  ë¬´ì‹œ
warnings.filterwarnings('ignore')

# =============================================================================
# ğŸ”¥ ê¸°ë³¸ ì„¤ì • ë° ë¡œê¹…
# =============================================================================

logger = logging.getLogger(__name__)

# ìƒìœ„ íŒ¨í‚¤ì§€ì—ì„œ ì‹œìŠ¤í…œ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
try:
    from .. import get_system_info, is_conda_environment, is_m3_max, get_device
    SYSTEM_INFO = get_system_info()
    IS_CONDA = is_conda_environment()
    IS_M3_MAX = is_m3_max()
    DEVICE = get_device()
    logger.info("âœ… ìƒìœ„ íŒ¨í‚¤ì§€ì—ì„œ ì‹œìŠ¤í…œ ì •ë³´ ë¡œë“œ ì„±ê³µ")
except ImportError as e:
    logger.warning(f"âš ï¸ ìƒìœ„ íŒ¨í‚¤ì§€ ë¡œë“œ ì‹¤íŒ¨, ê¸°ë³¸ê°’ ì‚¬ìš©: {e}")
    SYSTEM_INFO = {'device': 'cpu', 'is_m3_max': False, 'memory_gb': 16.0}
    IS_CONDA = False
    IS_M3_MAX = False
    DEVICE = 'cpu'

# =============================================================================
# ğŸ”¥ ì •í™•í•œ Step ë§¤í•‘ (íŒŒì¼ëª… ê¸°ë°˜)
# =============================================================================

# Stepë³„ ì •í™•í•œ ëª¨ë“ˆëª…ê³¼ í´ë˜ìŠ¤ëª… ë§¤í•‘
STEP_MAPPING = {
    'step_01': {
        'module': 'app.ai_pipeline.steps.step_01_human_parsing',  # ğŸ”¥ ì˜¬ë°”ë¥¸ ê²½ë¡œ
        'class': 'HumanParsingStep',
        'description': 'ì¸ì²´ íŒŒì‹± - Human Body Parsing',
        'models': ['SCHP', 'Graphonomy'],
        'priority': 2
    },
    'step_02': {
        'module': 'app.ai_pipeline.steps.step_02_pose_estimation',
        'class': 'PoseEstimationStep',
        'description': 'í¬ì¦ˆ ì¶”ì • - Pose Estimation',
        'models': ['OpenPose', 'YOLO-Pose'],
        'priority': 4
    },
    'step_03': {
        'module': 'app.ai_pipeline.steps.step_03_cloth_segmentation',
        'class': 'ClothSegmentationStep',
        'description': 'ì˜ë¥˜ ë¶„í•  - Cloth Segmentation',
        'models': ['U2Net', 'SAM'],
        'priority': 3
    },
    'step_04': {
        'module': 'app.ai_pipeline.steps.step_04_geometric_matching',
        'class': 'GeometricMatchingStep',
        'description': 'ê¸°í•˜í•™ì  ë§¤ì¹­ - Geometric Matching',
        'models': ['TPS', 'GMM'],
        'priority': 7
    },
    'step_05': {
        'module': 'app.ai_pipeline.steps.step_05_cloth_warping',
        'class': 'ClothWarpingStep',
        'description': 'ì˜ë¥˜ ë³€í˜• - Cloth Warping',
        'models': ['Advanced Warping'],
        'priority': 8
    },
    'step_06': {
        'module': 'app.ai_pipeline.steps.step_06_virtual_fitting',
        'class': 'VirtualFittingStep',
        'description': 'ê°€ìƒ í”¼íŒ… - Virtual Fitting',
        'models': ['OOTDiffusion', 'IDM-VTON'],
        'priority': 1  # ê°€ì¥ ì¤‘ìš”
    },
    'step_07': {
        'module': 'app.ai_pipeline.steps.step_07_post_processing',
        'class': 'PostProcessingStep',
        'description': 'í›„ì²˜ë¦¬ - Post Processing',
        'models': ['RealESRGAN', 'Enhancement'],
        'priority': 5
    },
    'step_08': {
        'module': 'app.ai_pipeline.steps.step_08_quality_assessment',
        'class': 'QualityAssessmentStep',
        'description': 'í’ˆì§ˆ í‰ê°€ - Quality Assessment',
        'models': ['CLIP', 'Quality Metrics'],
        'priority': 6
    }
}

# conda í™˜ê²½ì—ì„œ ë¡œë”© ìš°ì„ ìˆœìœ„
LOADING_PRIORITY = sorted(STEP_MAPPING.keys(), 
                         key=lambda x: STEP_MAPPING[x]['priority'])

# =============================================================================
# ğŸ”¥ ë‹¨ìˆœí™”ëœ íŒŒì´í”„ë¼ì¸ ë¡œë” (ì •í™•í•œ ê²½ë¡œ ì‚¬ìš©)
# =============================================================================

class FixedPipelineLoader:
    """ìˆ˜ì •ëœ íŒŒì´í”„ë¼ì¸ ë¡œë” - ì •í™•í•œ ê²½ë¡œ ì‚¬ìš©"""
    
    def __init__(self):
        self._loaded_classes = {}
        self._failed_loads = set()
        self.logger = logging.getLogger(f"{__name__}.FixedPipelineLoader")
        
    def safe_import_step(self, step_id: str) -> Optional[Type]:
        """ì•ˆì „í•œ Step í´ë˜ìŠ¤ import (ì •í™•í•œ ê²½ë¡œ ì‚¬ìš©)"""
        if step_id in self._loaded_classes:
            return self._loaded_classes[step_id]
            
        if step_id in self._failed_loads:
            return None
            
        try:
            step_info = STEP_MAPPING.get(step_id)
            if not step_info:
                self.logger.warning(f"âš ï¸ ì•Œ ìˆ˜ ì—†ëŠ” Step ID: {step_id}")
                return None
                
            # ğŸ”¥ ì •í™•í•œ ëª¨ë“ˆëª…ê³¼ í´ë˜ìŠ¤ëª… ì‚¬ìš©
            module_name = step_info['module']
            class_name = step_info['class']
            
            # ë™ì  import ì‹œë„
            import importlib
            try:
                self.logger.debug(f"ğŸ”„ {step_id} ë¡œë”© ì‹œë„: {module_name}")
                module = importlib.import_module(module_name)
                step_class = getattr(module, class_name, None)
                
                if step_class:
                    self._loaded_classes[step_id] = step_class
                    self.logger.info(f"âœ… {step_id} ({class_name}) ë¡œë“œ ì„±ê³µ")
                    return step_class
                else:
                    self.logger.warning(f"âš ï¸ {class_name} í´ë˜ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
                    
            except ImportError as e:
                self.logger.debug(f"ğŸ“‹ {step_id} ëª¨ë“ˆ ì—†ìŒ (ì •ìƒ): {e}")
                
        except Exception as e:
            self.logger.error(f"âŒ {step_id} ë¡œë“œ ì‹¤íŒ¨: {e}")
            
        # ì‹¤íŒ¨ ê¸°ë¡
        self._failed_loads.add(step_id)
        self._loaded_classes[step_id] = None
        return None
        
    def load_all_available_steps(self) -> Dict[str, Optional[Type]]:
        """ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë“  Step ë¡œë“œ"""
        loaded_steps = {}
        
        # conda í™˜ê²½ì´ë©´ ìš°ì„ ìˆœìœ„ ìˆœìœ¼ë¡œ ë¡œë“œ
        load_order = LOADING_PRIORITY if IS_CONDA else STEP_MAPPING.keys()
        
        for step_id in load_order:
            step_class = self.safe_import_step(step_id)
            loaded_steps[step_id] = step_class
            
        available_count = sum(1 for step in loaded_steps.values() if step is not None)
        total_count = len(STEP_MAPPING)
        
        self.logger.info(f"ğŸ“Š Step ë¡œë”© ì™„ë£Œ: {available_count}/{total_count}ê°œ")
        if IS_CONDA:
            self.logger.info("ğŸ conda í™˜ê²½: ìš°ì„ ìˆœìœ„ ê¸°ë°˜ ë¡œë”© ì ìš©")
            
        return loaded_steps

# ì „ì—­ ë¡œë” ì¸ìŠ¤í„´ìŠ¤
_pipeline_loader = FixedPipelineLoader()

# =============================================================================
# ğŸ”¥ ìœ í‹¸ë¦¬í‹° ëª¨ë“ˆ ì•ˆì „í•œ ë¡œë”©
# =============================================================================

def _safe_import_utils():
    """ìœ í‹¸ë¦¬í‹° ëª¨ë“ˆë“¤ ì•ˆì „í•˜ê²Œ import"""
    utils_status = {
        'model_loader': False,
        'memory_manager': False,
        'data_converter': False,
        'model_interface': False
    }
    
    try:
        from .utils import (
            get_step_model_interface,
            get_step_memory_manager, 
            get_step_data_converter,
            preprocess_image_for_step
        )
        utils_status.update({
            'model_loader': True,
            'memory_manager': True,
            'data_converter': True,
            'model_interface': True
        })
        logger.info("âœ… íŒŒì´í”„ë¼ì¸ ìœ í‹¸ë¦¬í‹° ëª¨ë“ˆ ë¡œë“œ ì„±ê³µ")
        
        # ì „ì—­ì— ì¶”ê°€
        globals().update({
            'get_step_model_interface': get_step_model_interface,
            'get_step_memory_manager': get_step_memory_manager,
            'get_step_data_converter': get_step_data_converter,
            'preprocess_image_for_step': preprocess_image_for_step
        })
        
    except ImportError as e:
        logger.warning(f"âš ï¸ ìœ í‹¸ë¦¬í‹° ëª¨ë“ˆ ë¡œë“œ ì‹¤íŒ¨: {e}")
        
        # í´ë°± í•¨ìˆ˜ë“¤
        def _fallback_function(name: str):
            def fallback(*args, **kwargs):
                logger.warning(f"âš ï¸ {name} í•¨ìˆ˜ ì‚¬ìš© ë¶ˆê°€ (ëª¨ë“ˆ ë¡œë“œ ì‹¤íŒ¨)")
                return None
            return fallback
            
        globals().update({
            'get_step_model_interface': _fallback_function('get_step_model_interface'),
            'get_step_memory_manager': _fallback_function('get_step_memory_manager'),
            'get_step_data_converter': _fallback_function('get_step_data_converter'),
            'preprocess_image_for_step': _fallback_function('preprocess_image_for_step')
        })
    
    return utils_status

# ìœ í‹¸ë¦¬í‹° ë¡œë”©
UTILS_STATUS = _safe_import_utils()

# =============================================================================
# ğŸ”¥ íŒŒì´í”„ë¼ì¸ ê´€ë¦¬ í•¨ìˆ˜ë“¤
# =============================================================================

def get_pipeline_status() -> Dict[str, Any]:
    """íŒŒì´í”„ë¼ì¸ ì „ì²´ ìƒíƒœ ë°˜í™˜"""
    loaded_steps = _pipeline_loader.load_all_available_steps()
    available_steps = [k for k, v in loaded_steps.items() if v is not None]
    
    return {
        'system_info': SYSTEM_INFO,
        'conda_optimized': IS_CONDA,
        'm3_max_optimized': IS_M3_MAX,
        'device': DEVICE,
        'total_steps': len(STEP_MAPPING),
        'available_steps': len(available_steps),
        'loaded_steps': available_steps,
        'failed_steps': [k for k, v in loaded_steps.items() if v is None],
        'success_rate': (len(available_steps) / len(STEP_MAPPING)) * 100,
        'utils_status': UTILS_STATUS,
        'loading_priority': LOADING_PRIORITY if IS_CONDA else None
    }

def get_step_class(step_name: str) -> Optional[Type]:
    """Step í´ë˜ìŠ¤ ë°˜í™˜"""
    if step_name.startswith('step_'):
        return _pipeline_loader.safe_import_step(step_name)
    else:
        # í´ë˜ìŠ¤ëª…ìœ¼ë¡œ ê²€ìƒ‰
        for step_id, step_info in STEP_MAPPING.items():
            if step_info['class'] == step_name:
                return _pipeline_loader.safe_import_step(step_id)
    return None

def create_step_instance(step_name: str, **kwargs) -> Optional[Any]:
    """Step ì¸ìŠ¤í„´ìŠ¤ ìƒì„±"""
    step_class = get_step_class(step_name)
    if step_class is None:
        logger.error(f"âŒ Step í´ë˜ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ: {step_name}")
        return None
        
    try:
        # ê¸°ë³¸ ì„¤ì • ì¶”ê°€
        default_config = {
            'device': DEVICE,
            'is_m3_max': IS_M3_MAX,
            'memory_gb': SYSTEM_INFO.get('memory_gb', 16.0),
            'conda_optimized': IS_CONDA
        }
        default_config.update(kwargs)
        
        return step_class(**default_config)
        
    except Exception as e:
        logger.error(f"âŒ Step ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ì‹¤íŒ¨ {step_name}: {e}")
        return None

def list_available_steps() -> List[str]:
    """ì‚¬ìš© ê°€ëŠ¥í•œ Step ëª©ë¡ ë°˜í™˜"""
    loaded_steps = _pipeline_loader.load_all_available_steps()
    return [step_id for step_id, step_class in loaded_steps.items() if step_class is not None]

def get_step_info(step_id: str) -> Dict[str, Any]:
    """Step ì •ë³´ ë°˜í™˜"""
    step_config = STEP_MAPPING.get(step_id, {})
    step_class = _pipeline_loader._loaded_classes.get(step_id)
    
    return {
        'step_id': step_id,
        'module': step_config.get('module', ''),
        'class': step_config.get('class', 'Unknown'),
        'description': step_config.get('description', ''),
        'models': step_config.get('models', []),
        'priority': step_config.get('priority', 10),
        'available': step_class is not None,
        'loaded': step_class is not None,
        'failed': step_id in _pipeline_loader._failed_loads
    }

async def initialize_pipeline_system() -> bool:
    """íŒŒì´í”„ë¼ì¸ ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
    try:
        logger.info("ğŸš€ íŒŒì´í”„ë¼ì¸ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹œì‘")
        
        # Step í´ë˜ìŠ¤ë“¤ ë¡œë“œ
        loaded_steps = _pipeline_loader.load_all_available_steps()
        available_count = sum(1 for step in loaded_steps.values() if step is not None)
        
        logger.info(f"âœ… íŒŒì´í”„ë¼ì¸ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ: {available_count}/{len(STEP_MAPPING)}ê°œ Step")
        return available_count > 0
        
    except Exception as e:
        logger.error(f"âŒ íŒŒì´í”„ë¼ì¸ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return False

async def cleanup_pipeline_system() -> None:
    """íŒŒì´í”„ë¼ì¸ ì‹œìŠ¤í…œ ì •ë¦¬"""
    try:
        logger.info("ğŸ§¹ íŒŒì´í”„ë¼ì¸ ì‹œìŠ¤í…œ ì •ë¦¬ ì‹œì‘")
        
        # ìºì‹œ ì •ë¦¬
        _pipeline_loader._loaded_classes.clear()
        _pipeline_loader._failed_loads.clear()
        
        # GPU ë©”ëª¨ë¦¬ ì •ë¦¬ (ê°€ëŠ¥í•œ ê²½ìš°)
        if DEVICE in ['cuda', 'mps']:
            try:
                import torch
                if DEVICE == 'cuda' and torch.cuda.is_available():
                    torch.cuda.empty_cache()
                elif DEVICE == 'mps' and torch.backends.mps.is_available():
                    # M3 Max ë©”ëª¨ë¦¬ ì •ë¦¬ (ì•ˆì „í•˜ê²Œ)
                    import gc
                    gc.collect()
            except:
                pass
                
        logger.info("âœ… íŒŒì´í”„ë¼ì¸ ì‹œìŠ¤í…œ ì •ë¦¬ ì™„ë£Œ")
        
    except Exception as e:
        logger.warning(f"âš ï¸ íŒŒì´í”„ë¼ì¸ ì‹œìŠ¤í…œ ì •ë¦¬ ì‹¤íŒ¨: {e}")

# =============================================================================
# ğŸ”¥ ìë™ Step í´ë˜ìŠ¤ ë¡œë”© (ì „ì—­ ë³€ìˆ˜)
# =============================================================================

# ì‚¬ìš© ê°€ëŠ¥í•œ Step í´ë˜ìŠ¤ë“¤ì„ ì „ì—­ ë³€ìˆ˜ë¡œ ì„¤ì •
try:
    _loaded_steps = _pipeline_loader.load_all_available_steps()
    
    # ê°œë³„ Step í´ë˜ìŠ¤ë“¤ì„ ì „ì—­ì— ì¶”ê°€
    for step_id, step_class in _loaded_steps.items():
        if step_class:
            step_info = STEP_MAPPING[step_id]
            class_name = step_info['class']
            globals()[class_name] = step_class
            
    logger.info("âœ… Step í´ë˜ìŠ¤ë“¤ ì „ì—­ ì„¤ì • ì™„ë£Œ")
    
except Exception as e:
    logger.warning(f"âš ï¸ Step í´ë˜ìŠ¤ ì „ì—­ ì„¤ì • ì‹¤íŒ¨: {e}")

# =============================================================================
# ğŸ”¥ Export ëª©ë¡
# =============================================================================

__all__ = [
    # ğŸ¯ íŒŒì´í”„ë¼ì¸ ìƒìˆ˜
    'STEP_MAPPING',
    'LOADING_PRIORITY',
    'SYSTEM_INFO',
    
    # ğŸ”§ íŒŒì´í”„ë¼ì¸ ê´€ë¦¬ í•¨ìˆ˜ë“¤
    'get_pipeline_status',
    'get_step_class',
    'create_step_instance',
    'list_available_steps',
    'get_step_info',
    'initialize_pipeline_system',
    'cleanup_pipeline_system',
    
    # ğŸ› ï¸ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤ (ì¡°ê±´ë¶€)
    'get_step_model_interface',
    'get_step_memory_manager',
    'get_step_data_converter', 
    'preprocess_image_for_step',
    
    # ğŸ“Š ìƒíƒœ ì •ë³´
    'UTILS_STATUS',
    'IS_CONDA',
    'IS_M3_MAX',
    'DEVICE'
]

# Step í´ë˜ìŠ¤ë“¤ë„ ë™ì ìœ¼ë¡œ ì¶”ê°€
for step_info in STEP_MAPPING.values():
    class_name = step_info['class']
    if class_name in globals():
        __all__.append(class_name)

# =============================================================================
# ğŸ”¥ ì´ˆê¸°í™” ì™„ë£Œ ë©”ì‹œì§€
# =============================================================================

def _print_initialization_summary():
    """ì´ˆê¸°í™” ìš”ì•½ ì¶œë ¥"""
    status = get_pipeline_status()
    available_count = status['available_steps']
    total_count = status['total_steps']
    success_rate = status['success_rate']
    
    print(f"\nğŸ MyCloset AI íŒŒì´í”„ë¼ì¸ ì‹œìŠ¤í…œ v7.0 ì´ˆê¸°í™” ì™„ë£Œ!")
    print(f"ğŸ“Š ì‚¬ìš© ê°€ëŠ¥í•œ Step: {available_count}/{total_count}ê°œ ({success_rate:.1f}%)")
    print(f"ğŸ conda í™˜ê²½: {'âœ…' if IS_CONDA else 'âŒ'}")
    print(f"ğŸ M3 Max: {'âœ…' if IS_M3_MAX else 'âŒ'}")
    print(f"ğŸ–¥ï¸ ë””ë°”ì´ìŠ¤: {DEVICE}")
    print(f"ğŸ› ï¸ ìœ í‹¸ë¦¬í‹°: {sum(UTILS_STATUS.values())}/4ê°œ ì‚¬ìš© ê°€ëŠ¥")
    
    if available_count > 0:
        print(f"âœ… ë¡œë“œëœ Steps: {', '.join(status['loaded_steps'])}")
    
    if status['failed_steps']:
        print(f"âš ï¸ ì‹¤íŒ¨í•œ Steps: {', '.join(status['failed_steps'])}")
        
    print("ğŸš€ íŒŒì´í”„ë¼ì¸ ì‹œìŠ¤í…œ ì¤€ë¹„ ì™„ë£Œ!\n")

# ì´ˆê¸°í™” ìƒíƒœ ì¶œë ¥ (í•œ ë²ˆë§Œ)
if not hasattr(sys, '_mycloset_pipeline_initialized'):
    _print_initialization_summary()
    sys._mycloset_pipeline_initialized = True

logger.info("ğŸ MyCloset AI íŒŒì´í”„ë¼ì¸ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")