
# ============================================================================
# ğŸ“ backend/app/ai_pipeline/__init__.py - AI íŒŒì´í”„ë¼ì¸ ëª¨ë“ˆ
# ============================================================================

"""
ğŸ¤– MyCloset AI Pipeline ëª¨ë“ˆ - conda í™˜ê²½ ìš°ì„  AI íŒŒì´í”„ë¼ì¸
===========================================================

âœ… conda í™˜ê²½ ìš°ì„  ìµœì í™”
âœ… ìˆœí™˜ì°¸ì¡° ì™„ì „ ë°©ì§€ (ì§€ì—° ë¡œë”© íŒ¨í„´) 
âœ… 8ë‹¨ê³„ AI íŒŒì´í”„ë¼ì¸ í†µí•© ê´€ë¦¬
âœ… Step í´ë˜ìŠ¤ë“¤ ì•ˆì „í•œ ë¡œë”©
âœ… ModelLoader, MemoryManager í†µí•©
âœ… M3 Max 128GB ë©”ëª¨ë¦¬ ìµœì í™”
âœ… ë™ì  AI ëª¨ë¸ ë¡œë”©

ì—­í• : AI íŒŒì´í”„ë¼ì¸ì˜ ì „ì²´ ë¼ì´í”„ì‚¬ì´í´ê³¼ Step ê´€ë¦¬ë¥¼ ë‹´ë‹¹
"""

import os
import sys
import logging
import threading
import time
from pathlib import Path
from typing import Dict, Any, Optional, List, Type, Union

# ìƒìœ„ íŒ¨í‚¤ì§€ì—ì„œ ì‹œìŠ¤í…œ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
try:
    from .. import SYSTEM_INFO, AI_MODEL_PATHS, IS_CONDA, CONDA_ENV, _lazy_loader
except ImportError:
    SYSTEM_INFO = {'device': 'cpu', 'is_m3_max': False, 'memory_gb': 16.0}
    AI_MODEL_PATHS = {'ai_models_root': Path(__file__).parent.parent.parent / 'ai_models'}
    IS_CONDA = 'CONDA_DEFAULT_ENV' in os.environ
    CONDA_ENV = os.environ.get('CONDA_DEFAULT_ENV', 'none')
    _lazy_loader = None

# ë¡œê±° ì„¤ì •
logger = logging.getLogger(__name__)

# =============================================================================
# ğŸ”¥ AI Pipeline ì •ë³´
# =============================================================================

__version__ = "4.0.0"
__author__ = "MyCloset AI Team"
__description__ = "AI Pipeline System with Conda Priority and Lazy Loading"

# Step ì •ë³´
STEP_MODULES = {
    'step_01': 'step_01_human_parsing',
    'step_02': 'step_02_pose_estimation',
    'step_03': 'step_03_cloth_segmentation',
    'step_04': 'step_04_geometric_matching',
    'step_05': 'step_05_cloth_warping',
    'step_06': 'step_06_virtual_fitting',
    'step_07': 'step_07_post_processing',
    'step_08': 'step_08_quality_assessment'
}

STEP_CLASSES = {
    'step_01': 'HumanParsingStep',
    'step_02': 'PoseEstimationStep',
    'step_03': 'ClothSegmentationStep',
    'step_04': 'GeometricMatchingStep',
    'step_05': 'ClothWarpingStep',
    'step_06': 'VirtualFittingStep',
    'step_07': 'PostProcessingStep',
    'step_08': 'QualityAssessmentStep'
}

# =============================================================================
# ğŸ”¥ ì§€ì—° ë¡œë”© í•¨ìˆ˜ë“¤ (ìˆœí™˜ì°¸ì¡° ë°©ì§€)
# =============================================================================

def get_pipeline_manager_class():
    """PipelineManager í´ë˜ìŠ¤ ì§€ì—° ë¡œë”©"""
    if _lazy_loader:
        return _lazy_loader.get_class('pipeline_manager', 'PipelineManager', 'app.ai_pipeline')
    
    try:
        from .pipeline_manager import PipelineManager
        return PipelineManager
    except ImportError as e:
        logger.warning(f"PipelineManager í´ë˜ìŠ¤ ë¡œë”© ì‹¤íŒ¨: {e}")
        return None

def get_model_loader_class():
    """ModelLoader í´ë˜ìŠ¤ ì§€ì—° ë¡œë”©"""
    if _lazy_loader:
        return _lazy_loader.get_class('model_loader', 'ModelLoader', 'app.ai_pipeline.utils')
    
    try:
        from .utils.model_loader import ModelLoader
        return ModelLoader
    except ImportError as e:
        logger.warning(f"ModelLoader í´ë˜ìŠ¤ ë¡œë”© ì‹¤íŒ¨: {e}")
        return None

def get_memory_manager_class():
    """MemoryManager í´ë˜ìŠ¤ ì§€ì—° ë¡œë”©"""
    if _lazy_loader:
        return _lazy_loader.get_class('memory_manager', 'MemoryManager', 'app.ai_pipeline.utils')
    
    try:
        from .utils.memory_manager import MemoryManager
        return MemoryManager
    except ImportError as e:
        logger.warning(f"MemoryManager í´ë˜ìŠ¤ ë¡œë”© ì‹¤íŒ¨: {e}")
        return None

def get_step_factory_class():
    """StepFactory í´ë˜ìŠ¤ ì§€ì—° ë¡œë”©"""
    if _lazy_loader:
        return _lazy_loader.get_class('step_factory', 'StepFactory', 'app.ai_pipeline.factories')
    
    try:
        from .factories.step_factory import StepFactory
        return StepFactory
    except ImportError as e:
        logger.warning(f"StepFactory í´ë˜ìŠ¤ ë¡œë”© ì‹¤íŒ¨: {e}")
        return None

# =============================================================================
# ğŸ”¥ Step í´ë˜ìŠ¤ ì§€ì—° ë¡œë”© (ìˆœí™˜ì°¸ì¡° ë°©ì§€)
# =============================================================================

def safe_import_step(step_id: str) -> Optional[Type[Any]]:
    """ì•ˆì „í•œ Step í´ë˜ìŠ¤ import (ì§€ì—° ë¡œë”©)"""
    try:
        module_name = STEP_MODULES.get(step_id)
        class_name = STEP_CLASSES.get(step_id)
        
        if not module_name or not class_name:
            logger.error(f"âŒ ì•Œ ìˆ˜ ì—†ëŠ” Step ID: {step_id}")
            return None
        
        if _lazy_loader:
            return _lazy_loader.get_class(module_name, class_name, 'app.ai_pipeline.steps')
        
        # ì§ì ‘ import (í´ë°±)
        try:
            import importlib
            full_module_name = f"app.ai_pipeline.steps.{module_name}"
            module = importlib.import_module(full_module_name)
            step_class = getattr(module, class_name, None)
            
            if step_class:
                logger.debug(f"âœ… {step_id} ({class_name}) import ì„±ê³µ")
                return step_class
            else:
                logger.error(f"âŒ {class_name} í´ë˜ìŠ¤ë¥¼ {module_name}ì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŒ")
                return None
                
        except ImportError as e:
            logger.warning(f"âŒ {step_id} import ì‹¤íŒ¨: {e}")
            return None
        
    except Exception as e:
        logger.error(f"âŒ {step_id} ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")
        return None

def load_all_steps() -> Dict[str, Optional[Type[Any]]]:
    """ëª¨ë“  Step í´ë˜ìŠ¤ ì§€ì—° ë¡œë”©"""
    loaded_steps = {}
    
    for step_id in STEP_MODULES.keys():
        step_class = safe_import_step(step_id)
        loaded_steps[step_id] = step_class
    
    available_count = sum(1 for step in loaded_steps.values() if step is not None)
    logger.info(f"âœ… Step ë¡œë”© ì™„ë£Œ: {available_count}/8ê°œ")
    
    return loaded_steps

# =============================================================================
# ğŸ”¥ íŒ©í† ë¦¬ í•¨ìˆ˜ë“¤ (conda í™˜ê²½ ìµœì í™”)
# =============================================================================

def create_pipeline_manager(**kwargs) -> Optional[Any]:
    """PipelineManager ì¸ìŠ¤í„´ìŠ¤ ìƒì„± (conda í™˜ê²½ ìµœì í™”)"""
    PipelineManager = get_pipeline_manager_class()
    if PipelineManager:
        # conda í™˜ê²½ ì„¤ì • ì¶”ê°€
        pipeline_config = {
            'device': SYSTEM_INFO.get('device', 'cpu'),
            'is_m3_max': SYSTEM_INFO.get('is_m3_max', False),
            'memory_gb': SYSTEM_INFO.get('memory_gb', 16.0),
            'conda_optimized': IS_CONDA,
            'conda_env': CONDA_ENV
        }
        pipeline_config.update(kwargs)
        
        try:
            return PipelineManager(**pipeline_config)
        except Exception as e:
            logger.error(f"PipelineManager ìƒì„± ì‹¤íŒ¨: {e}")
            return None
    return None

def create_model_loader(**kwargs) -> Optional[Any]:
    """ModelLoader ì¸ìŠ¤í„´ìŠ¤ ìƒì„± (conda í™˜ê²½ ìµœì í™”)"""
    ModelLoader = get_model_loader_class()
    if ModelLoader:
        # conda í™˜ê²½ ëª¨ë¸ ë¡œë”© ì„¤ì •
        loader_config = {
            'device': SYSTEM_INFO.get('device', 'cpu'),
            'models_path': str(AI_MODEL_PATHS.get('ai_models_root', '.')),
            'conda_optimized': IS_CONDA,
            'memory_efficient': SYSTEM_INFO.get('is_m3_max', False)
        }
        loader_config.update(kwargs)
        
        try:
            return ModelLoader(**loader_config)
        except Exception as e:
            logger.error(f"ModelLoader ìƒì„± ì‹¤íŒ¨: {e}")
            return None
    return None

def create_step_instance(step_name: Union[str, int], **kwargs) -> Optional[Any]:
    """Step ì¸ìŠ¤í„´ìŠ¤ ìƒì„± (conda í™˜ê²½ ìµœì í™”)"""
    try:
        if isinstance(step_name, int):
            step_key = f"step_{step_name:02d}"
        else:
            step_key = step_name
        
        step_class = safe_import_step(step_key)
        if step_class is None:
            logger.error(f"Step í´ë˜ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ: {step_name}")
            return None
        
        # conda í™˜ê²½ Step ì„¤ì •
        step_config = {
            'device': SYSTEM_INFO.get('device', 'cpu'),
            'is_m3_max': SYSTEM_INFO.get('is_m3_max', False),
            'memory_gb': SYSTEM_INFO.get('memory_gb', 16.0),
            'conda_optimized': IS_CONDA
        }
        step_config.update(kwargs)
        
        return step_class(**step_config)
        
    except Exception as e:
        logger.error(f"Step ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ì‹¤íŒ¨ {step_name}: {e}")
        return None

# =============================================================================
# ğŸ”¥ ì „ì—­ ì¸ìŠ¤í„´ìŠ¤ ê´€ë¦¬ (ì‹±ê¸€í†¤ íŒ¨í„´)
# =============================================================================

_global_instances = {}
_instance_lock = threading.RLock()

def get_global_pipeline_manager():
    """ì „ì—­ PipelineManager ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    with _instance_lock:
        if 'pipeline_manager' not in _global_instances:
            _global_instances['pipeline_manager'] = create_pipeline_manager()
        return _global_instances['pipeline_manager']

def get_global_model_loader():
    """ì „ì—­ ModelLoader ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    with _instance_lock:
        if 'model_loader' not in _global_instances:
            _global_instances['model_loader'] = create_model_loader()
        return _global_instances['model_loader']

# =============================================================================
# ğŸ”¥ íŒŒì´í”„ë¼ì¸ ìƒíƒœ ê´€ë¦¬
# =============================================================================

def get_pipeline_status() -> Dict[str, Any]:
    """íŒŒì´í”„ë¼ì¸ ì‹œìŠ¤í…œ ìƒíƒœ ë°˜í™˜"""
    loaded_steps = load_all_steps()
    available_steps = [k for k, v in loaded_steps.items() if v is not None]
    
    return {
        'version': __version__,
        'system_info': SYSTEM_INFO,
        'conda_environment': IS_CONDA,
        'conda_env_name': CONDA_ENV,
        'availability': {
            'pipeline_manager': get_pipeline_manager_class() is not None,
            'model_loader': get_model_loader_class() is not None,
            'memory_manager': get_memory_manager_class() is not None,
            'step_factory': get_step_factory_class() is not None,
        },
        'steps': {
            'total_steps': len(STEP_MODULES),
            'available_steps': len(available_steps),
            'loaded_steps': available_steps,
            'step_classes': {k: v is not None for k, v in loaded_steps.items()}
        },
        'ai_models': {
            'models_path': str(AI_MODEL_PATHS.get('ai_models_root', '')),
            'models_exist': AI_MODEL_PATHS.get('ai_models_root', Path('.')).exists()
        }
    }

def list_available_steps() -> List[str]:
    """ì‚¬ìš© ê°€ëŠ¥í•œ Step ëª©ë¡ ë°˜í™˜"""
    loaded_steps = load_all_steps()
    return [k for k, v in loaded_steps.items() if v is not None]

# =============================================================================
# ğŸ”¥ ì´ˆê¸°í™” í•¨ìˆ˜ë“¤
# =============================================================================

async def initialize_pipeline_system(**kwargs) -> Dict[str, Any]:
    """ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹œìŠ¤í…œ ì´ˆê¸°í™” (conda í™˜ê²½ ìµœì í™”)"""
    try:
        start_time = time.time()
        results = {}
        
        logger.info("ğŸš€ AI íŒŒì´í”„ë¼ì¸ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹œì‘...")
        
        # 1. ModelLoader ì´ˆê¸°í™”
        try:
            model_loader = create_model_loader(**kwargs)
            results['model_loader'] = {
                'success': model_loader is not None,
                'instance': model_loader
            }
            if model_loader:
                logger.info("âœ… ModelLoader ì´ˆê¸°í™” ì™„ë£Œ")
        except Exception as e:
            logger.error(f"âŒ ModelLoader ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            results['model_loader'] = {'success': False, 'error': str(e)}
        
        # 2. PipelineManager ì´ˆê¸°í™”
        try:
            pipeline_manager = create_pipeline_manager(**kwargs)
            results['pipeline_manager'] = {
                'success': pipeline_manager is not None,
                'instance': pipeline_manager
            }
            if pipeline_manager:
                logger.info("âœ… PipelineManager ì´ˆê¸°í™” ì™„ë£Œ")
        except Exception as e:
            logger.error(f"âŒ PipelineManager ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            results['pipeline_manager'] = {'success': False, 'error': str(e)}
        
        # 3. Step í´ë˜ìŠ¤ë“¤ ë¡œë”©
        try:
            loaded_steps = load_all_steps()
            results['steps'] = {
                'success': len(loaded_steps) > 0,
                'loaded_count': sum(1 for step in loaded_steps.values() if step is not None),
                'total_count': len(STEP_MODULES),
                'steps': loaded_steps
            }
            logger.info(f"âœ… Step í´ë˜ìŠ¤ ë¡œë”© ì™„ë£Œ: {results['steps']['loaded_count']}/8ê°œ")
        except Exception as e:
            logger.error(f"âŒ Step í´ë˜ìŠ¤ ë¡œë”© ì‹¤íŒ¨: {e}")
            results['steps'] = {'success': False, 'error': str(e)}
        
        # ì´ˆê¸°í™” ì™„ë£Œ
        initialization_time = time.time() - start_time
        results['overall'] = {
            'success': any(result.get('success', False) for result in results.values()),
            'initialization_time': initialization_time,
            'conda_optimized': IS_CONDA,
            'device': SYSTEM_INFO.get('device', 'cpu')
        }
        
        logger.info(f"ğŸ‰ AI íŒŒì´í”„ë¼ì¸ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ ({initialization_time:.2f}ì´ˆ)")
        return results
        
    except Exception as e:
        logger.error(f"âŒ AI íŒŒì´í”„ë¼ì¸ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return {'overall': {'success': False, 'error': str(e)}}

def cleanup_pipeline_system():
    """íŒŒì´í”„ë¼ì¸ ì‹œìŠ¤í…œ ì •ë¦¬"""
    try:
        logger.info("ğŸ§¹ AI íŒŒì´í”„ë¼ì¸ ì‹œìŠ¤í…œ ì •ë¦¬ ì‹œì‘...")
        
        # ì „ì—­ ì¸ìŠ¤í„´ìŠ¤ ì •ë¦¬
        with _instance_lock:
            for name, instance in _global_instances.items():
                try:
                    if hasattr(instance, 'cleanup'):
                        instance.cleanup()
                except Exception as e:
                    logger.warning(f"ì¸ìŠ¤í„´ìŠ¤ ì •ë¦¬ ì‹¤íŒ¨ {name}: {e}")
            
            _global_instances.clear()
        
        # ë©”ëª¨ë¦¬ ì •ë¦¬
        import gc
        gc.collect()
        
        # MPS ìºì‹œ ì •ë¦¬ (M3 Max)
        if SYSTEM_INFO.get('device') == 'mps':
            try:
                import torch
                if hasattr(torch.mps, 'empty_cache'):
                    torch.mps.empty_cache()
            except Exception as e:
                logger.warning(f"MPS ìºì‹œ ì •ë¦¬ ì‹¤íŒ¨: {e}")
        
        logger.info("âœ… AI íŒŒì´í”„ë¼ì¸ ì‹œìŠ¤í…œ ì •ë¦¬ ì™„ë£Œ")
        
    except Exception as e:
        logger.error(f"âŒ AI íŒŒì´í”„ë¼ì¸ ì‹œìŠ¤í…œ ì •ë¦¬ ì‹¤íŒ¨: {e}")

# =============================================================================
# ğŸ”¥ AI Pipeline ëª¨ë“ˆ Export
# =============================================================================

__all__ = [
    # ğŸ”¥ ë²„ì „ ì •ë³´
    '__version__',
    '__author__',
    '__description__',
    
    # ğŸ“Š Step ì •ë³´
    'STEP_MODULES',
    'STEP_CLASSES',
    
    # ğŸ”— ì§€ì—° ë¡œë”© í•¨ìˆ˜ë“¤
    'get_pipeline_manager_class',
    'get_model_loader_class',
    'get_memory_manager_class',
    'get_step_factory_class',
    
    # ğŸ”§ Step ê´€ë¦¬ í•¨ìˆ˜ë“¤
    'safe_import_step',
    'load_all_steps',
    'list_available_steps',
    
    # ğŸ­ íŒ©í† ë¦¬ í•¨ìˆ˜ë“¤
    'create_pipeline_manager',
    'create_model_loader',
    'create_step_instance',
    
    # ğŸŒ ì „ì—­ ì¸ìŠ¤í„´ìŠ¤ í•¨ìˆ˜ë“¤
    'get_global_pipeline_manager',
    'get_global_model_loader',
    
    # ğŸ”§ ìƒíƒœ ê´€ë¦¬ í•¨ìˆ˜ë“¤
    'get_pipeline_status',
    
    # ğŸš€ ì´ˆê¸°í™” í•¨ìˆ˜ë“¤
    'initialize_pipeline_system',
    'cleanup_pipeline_system',
]

# ì´ˆê¸°í™” ì •ë³´ ì¶œë ¥
logger.info("ğŸ¤– MyCloset AI Pipeline ëª¨ë“ˆ ì´ˆê¸°í™” ì™„ë£Œ")
logger.info(f"ğŸ conda ìµœì í™”: {IS_CONDA}")
logger.info(f"ğŸ M3 Max: {SYSTEM_INFO.get('is_m3_max', False)}")
logger.info(f"ğŸ“Š ì´ Step ìˆ˜: {len(STEP_MODULES)}")
logger.info(f"ğŸ”— ì§€ì—° ë¡œë”©: í™œì„±í™”")
