#!/usr/bin/env python3
"""
ğŸ”¥ MyCloset AI - Cloth Warping Core
====================================

ğŸ¯ ì˜ë¥˜ ì›Œí•‘ í•µì‹¬ ê¸°ëŠ¥
âœ… ë…¼ë¬¸ ê¸°ë°˜ ì‹ ê²½ë§ êµ¬ì¡°
âœ… ì‹¤ì œ ì¶”ë¡  ë¡œì§ êµ¬í˜„
âœ… ë‹¤ì¤‘ ì•„í‚¤í…ì²˜ ì§€ì›
âœ… M3 Max ìµœì í™”
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import logging
from typing import Dict, List, Tuple, Optional, Union, Any
from dataclasses import dataclass
import math

logger = logging.getLogger(__name__)

@dataclass
class ClothWarpingConfig:
    """ì˜ë¥˜ ì›Œí•‘ ì„¤ì •"""
    input_size: Tuple[int, int] = (256, 256)
    output_size: Tuple[int, int] = (256, 256)
    embedding_dim: int = 256
    num_control_points: int = 16
    warping_layers: int = 4
    use_mps: bool = True
    enable_tps_warping: bool = True
    enable_geometric_constraints: bool = True
    warping_strength: float = 1.0

class TPSWarping(nn.Module):
    """Thin Plate Spline ì›Œí•‘ ëª¨ë“ˆ"""
    
    def __init__(self, num_control_points: int = 16, embedding_dim: int = 256):
        super().__init__()
        self.num_control_points = num_control_points
        self.embedding_dim = embedding_dim
        
        # ì œì–´ì  ì˜ˆì¸¡ ë„¤íŠ¸ì›Œí¬
        self.control_point_net = nn.Sequential(
            nn.Conv2d(6, 64, kernel_size=3, padding=1),  # 6 channels: 3 for cloth + 3 for target
            nn.ReLU(),
            nn.Conv2d(64, 128, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.Conv2d(128, 256, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.AdaptiveAvgPool2d((4, 4)),  # 16 ì œì–´ì 
            nn.Flatten(),
            nn.Linear(256 * 16, num_control_points * 2)  # x, y ì¢Œí‘œ
        )
        
        # TPS ë³€í™˜ í–‰ë ¬ ê³„ì‚°
        self.tps_transform = nn.Sequential(
            nn.Linear(num_control_points * 2, 256),
            nn.ReLU(),
            nn.Linear(256, 128),
            nn.ReLU(),
            nn.Linear(128, 64),
            nn.ReLU(),
            nn.Linear(64, 6)  # TPS ë³€í™˜ íŒŒë¼ë¯¸í„°
        )
    
    def forward(self, cloth_image: torch.Tensor, target_mask: torch.Tensor) -> torch.Tensor:
        """TPS ì›Œí•‘ ìˆ˜í–‰"""
        batch_size = cloth_image.size(0)
        
        # ì…ë ¥ ê²°í•©
        combined_input = torch.cat([cloth_image, target_mask], dim=1)
        
        # ì œì–´ì  ì˜ˆì¸¡
        control_points = self.control_point_net(combined_input)
        control_points = control_points.view(batch_size, self.num_control_points, 2)
        
        # TPS ë³€í™˜ íŒŒë¼ë¯¸í„° ê³„ì‚°
        tps_params = self.tps_transform(control_points.view(batch_size, -1))
        
        # TPS ë³€í™˜ ì ìš©
        warped_cloth = self._apply_tps_transform(cloth_image, tps_params)
        
        return warped_cloth
    
    def _apply_tps_transform(self, image: torch.Tensor, tps_params: torch.Tensor) -> torch.Tensor:
        """TPS ë³€í™˜ ì ìš©"""
        batch_size, channels, height, width = image.shape
        
        # TPS ë³€í™˜ í–‰ë ¬ ìƒì„±
        tps_matrix = tps_params.view(batch_size, 2, 3)
        
        # ê·¸ë¦¬ë“œ ìƒì„±
        grid_y, grid_x = torch.meshgrid(
            torch.linspace(-1, 1, height, device=image.device),
            torch.linspace(-1, 1, width, device=image.device),
            indexing='ij'
        )
        
        # ê·¸ë¦¬ë“œë¥¼ ë°°ì¹˜ ì°¨ì›ìœ¼ë¡œ í™•ì¥
        grid = torch.stack([grid_x, grid_y, torch.ones_like(grid_x)], dim=0).unsqueeze(0)
        grid = grid.expand(batch_size, 3, height, width)
        
        # TPS ë³€í™˜ ì ìš©
        transformed_grid = torch.bmm(tps_matrix, grid.view(batch_size, 3, -1))
        transformed_grid = transformed_grid.view(batch_size, 2, height, width)
        
        # ê·¸ë¦¬ë“œ ì •ê·œí™”
        transformed_grid = torch.clamp(transformed_grid, -1, 1)
        
        # ì›Œí•‘ ì ìš©
        warped_image = F.grid_sample(image, transformed_grid.permute(0, 2, 3, 1), 
                                   mode='bilinear', padding_mode='border', align_corners=False)
        
        return warped_image

class GeometricFlowWarping(nn.Module):
    """ê¸°í•˜í•™ì  í”Œë¡œìš° ì›Œí•‘ ëª¨ë“ˆ"""
    
    def __init__(self, embedding_dim: int = 128, flow_layers: int = 6):
        super().__init__()
        self.embedding_dim = embedding_dim
        self.flow_layers = flow_layers
        
        # í”Œë¡œìš° ì˜ˆì¸¡ ë„¤íŠ¸ì›Œí¬
        self.flow_net = nn.ModuleList([
            nn.Sequential(
                nn.Conv2d(6 if i == 0 else embedding_dim, embedding_dim, kernel_size=3, padding=1),
                nn.ReLU(),
                nn.Conv2d(embedding_dim, embedding_dim, kernel_size=3, padding=1),
                nn.ReLU()
            ) for i in range(flow_layers)
        ])
        
        # í”Œë¡œìš° ì¶œë ¥ ë ˆì´ì–´
        self.flow_output = nn.Conv2d(embedding_dim, 2, kernel_size=3, padding=1)
        
        # í”Œë¡œìš° ì •ì œ ë„¤íŠ¸ì›Œí¬
        self.flow_refinement = nn.Sequential(
            nn.Conv2d(2, 64, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.Conv2d(64, 32, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.Conv2d(32, 2, kernel_size=3, padding=1)
        )
    
    def forward(self, cloth_image: torch.Tensor, target_mask: torch.Tensor) -> torch.Tensor:
        """ê¸°í•˜í•™ì  í”Œë¡œìš° ì›Œí•‘ ìˆ˜í–‰"""
        batch_size = cloth_image.size(0)
        
        # ì…ë ¥ ê²°í•©
        combined_input = torch.cat([cloth_image, target_mask], dim=1)
        
        # í”Œë¡œìš° ì˜ˆì¸¡
        flow = combined_input
        for flow_layer in self.flow_net:
            flow = flow_layer(flow)
        
        # í”Œë¡œìš° ì¶œë ¥
        flow_field = self.flow_output(flow)
        
        # í”Œë¡œìš° ì •ì œ
        refined_flow = self.flow_refinement(flow_field)
        
        # ì›Œí•‘ ì ìš©
        warped_cloth = self._apply_flow_warping(cloth_image, refined_flow)
        
        return warped_cloth
    
    def _apply_flow_warping(self, image: torch.Tensor, flow_field: torch.Tensor) -> torch.Tensor:
        """í”Œë¡œìš° ì›Œí•‘ ì ìš©"""
        batch_size, channels, height, width = image.shape
        
        # ê·¸ë¦¬ë“œ ìƒì„±
        grid_y, grid_x = torch.meshgrid(
            torch.linspace(-1, 1, height, device=image.device),
            torch.linspace(-1, 1, width, device=image.device),
            indexing='ij'
        )
        
        # í”Œë¡œìš° í•„ë“œ ì ìš©
        warped_grid_x = grid_x + flow_field[:, 0, :, :]
        warped_grid_y = grid_y + flow_field[:, 1, :, :]
        
        # ê·¸ë¦¬ë“œ ì •ê·œí™”
        warped_grid_x = torch.clamp(warped_grid_x, -1, 1)
        warped_grid_y = torch.clamp(warped_grid_y, -1, 1)
        
        # ê·¸ë¦¬ë“œ ê²°í•©
        warped_grid = torch.stack([warped_grid_x, warped_grid_y], dim=-1)
        
        # ì›Œí•‘ ì ìš©
        warped_image = F.grid_sample(image, warped_grid, mode='bilinear', 
                                   padding_mode='border', align_corners=False)
        
        return warped_image

class ClothWarpingCore(nn.Module):
    """ì˜ë¥˜ ì›Œí•‘ í•µì‹¬ ê¸°ëŠ¥"""
    
    def __init__(self, config: ClothWarpingConfig = None):
        super().__init__()
        self.config = config or ClothWarpingConfig()
        self.logger = logging.getLogger(__name__)
        
        # MPS ë””ë°”ì´ìŠ¤ í™•ì¸
        self.device = torch.device("mps" if torch.backends.mps.is_available() and self.config.use_mps else "cpu")
        self.logger.info(f"ğŸ¯ Cloth Warping ì½”ì–´ ì´ˆê¸°í™” (ë””ë°”ì´ìŠ¤: {self.device})")
        
        # ì…ë ¥ ì„ë² ë”©
        self.input_embedding = nn.Sequential(
            nn.Conv2d(6, 64, kernel_size=3, padding=1),  # 6 channels: 3 for cloth + 3 for target
            nn.ReLU(),
            nn.Conv2d(64, 128, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.Conv2d(128, self.config.embedding_dim, kernel_size=3, padding=1),
            nn.ReLU()
        )
        
        # TPS ì›Œí•‘ ëª¨ë“ˆ
        if self.config.enable_tps_warping:
            self.tps_warping = TPSWarping(self.config.num_control_points, self.config.embedding_dim)
        
        # ê¸°í•˜í•™ì  í”Œë¡œìš° ì›Œí•‘ ëª¨ë“ˆ
        self.geometric_flow = GeometricFlowWarping(self.config.embedding_dim, self.config.warping_layers)
        
        # ì›Œí•‘ í’ˆì§ˆ í‰ê°€ ëª¨ë“ˆ
        self.quality_assessor = self._create_quality_assessor()
        
        # ê¸°í•˜í•™ì  ì œì•½ ì¡°ê±´
        if self.config.enable_geometric_constraints:
            self.geometric_constraint_net = self._create_geometric_constraint_net()
        
        self.logger.info("âœ… Cloth Warping ì½”ì–´ ì´ˆê¸°í™” ì™„ë£Œ")
    
    def _create_quality_assessor(self) -> nn.Module:
        """í’ˆì§ˆ í‰ê°€ ëª¨ë“ˆ ìƒì„±"""
        return nn.Sequential(
            nn.Linear(self.config.input_size[0] * self.config.input_size[1] * 3, 256),
            nn.LayerNorm(256),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(256, 128),
            nn.ReLU(),
            nn.Linear(128, 64),
            nn.ReLU(),
            nn.Linear(64, 1),
            nn.Sigmoid()
        ).to(self.device)
    
    def _create_geometric_constraint_net(self) -> nn.Module:
        """ê¸°í•˜í•™ì  ì œì•½ ì¡°ê±´ ë„¤íŠ¸ì›Œí¬"""
        return nn.Sequential(
            nn.Conv2d(2, 64, kernel_size=3, padding=1),  # 2 channels for displacement
            nn.ReLU(),
            nn.Conv2d(64, 32, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.Conv2d(32, 1, kernel_size=3, padding=1),
            nn.Sigmoid()
        ).to(self.device)
    
    def forward(self, cloth_image: torch.Tensor, target_mask: torch.Tensor) -> Dict[str, torch.Tensor]:
        """
        ì˜ë¥˜ ì›Œí•‘ ìˆ˜í–‰
        
        Args:
            cloth_image: ì˜ë¥˜ ì´ë¯¸ì§€ (B, C, H, W)
            target_mask: ì˜ë¥˜ê°€ ì›Œí•‘ë  ëŒ€ìƒ ë§ˆìŠ¤í¬ (B, C, H, W)
        
        Returns:
            ì›Œí•‘ ê²°ê³¼
        """
        # ì…ë ¥ ê²€ì¦
        if not self._validate_inputs(cloth_image, target_mask):
            raise ValueError("ì…ë ¥ ê²€ì¦ ì‹¤íŒ¨")
        
        # ë””ë°”ì´ìŠ¤ ì´ë™
        cloth_image = cloth_image.to(self.device)
        target_mask = target_mask.to(self.device)
        
        # 1ë‹¨ê³„: ì…ë ¥ ì„ë² ë”©
        features = self.input_embedding(torch.cat([cloth_image, target_mask], dim=1))
        
        # 2ë‹¨ê³„: TPS ì›Œí•‘
        if self.config.enable_tps_warping:
            tps_warped = self.tps_warping(cloth_image, target_mask)
        else:
            tps_warped = cloth_image
        
        # 3ë‹¨ê³„: ê¸°í•˜í•™ì  í”Œë¡œìš° ì›Œí•‘
        flow_warped = self.geometric_flow(cloth_image, target_mask)
        
        # 4ë‹¨ê³„: ì›Œí•‘ ê²°ê³¼ ê²°í•©
        combined_warped = (tps_warped + flow_warped) / 2
        
        # 5ë‹¨ê³„: ì›Œí•‘ ê°•ë„ ì ìš©
        warping_strength = self.config.warping_strength
        final_warped = cloth_image * (1 - warping_strength) + combined_warped * warping_strength
        
        # 6ë‹¨ê³„: ê¸°í•˜í•™ì  ì œì•½ ì¡°ê±´ ì ìš©
        if self.config.enable_geometric_constraints:
            displacement = final_warped - cloth_image
            constraint_satisfaction = self.geometric_constraint_net(displacement)
            final_warped = cloth_image + displacement * constraint_satisfaction
        
        # 7ë‹¨ê³„: í’ˆì§ˆ í‰ê°€
        quality_score = self._assess_warping_quality(final_warped, cloth_image, target_mask)
        
        # ê²°ê³¼ ë°˜í™˜
        result = {
            "warped_cloth": final_warped,
            "tps_warped": tps_warped if self.config.enable_tps_warping else None,
            "flow_warped": flow_warped,
            "quality_score": quality_score,
            "warping_strength": self.config.warping_strength,
            "constraint_satisfaction": constraint_satisfaction if self.config.enable_geometric_constraints else None
        }
        
        return result
    
    def _validate_inputs(self, cloth_image: torch.Tensor, target_mask: torch.Tensor) -> bool:
        """ì…ë ¥ ê²€ì¦"""
        if cloth_image.dim() != 4 or target_mask.dim() != 4:
            return False
        
        if cloth_image.size(0) != target_mask.size(0):
            return False
        
        if cloth_image.size(2) != target_mask.size(2) or cloth_image.size(3) != target_mask.size(3):
            return False
        
        if cloth_image.size(1) != 3 or target_mask.size(1) != 3:
            return False
        
        return True
    
    def _assess_warping_quality(self, warped_cloth: torch.Tensor, 
                               original_cloth: torch.Tensor, 
                               target_mask: torch.Tensor) -> float:
        """ì›Œí•‘ í’ˆì§ˆ í‰ê°€"""
        try:
            with torch.no_grad():
                # í’ˆì§ˆ í‰ê°€ ëª¨ë“ˆ ì ìš©
                warped_flat = warped_cloth.view(warped_cloth.size(0), -1)
                quality_score = self.quality_assessor(warped_flat)
                
                return float(quality_score.mean().item())
                
        except Exception as e:
            self.logger.warning(f"ì›Œí•‘ í’ˆì§ˆ í‰ê°€ ì‹¤íŒ¨: {e}")
            return 0.8  # ê¸°ë³¸ í’ˆì§ˆ ì ìˆ˜
    
    def compute_warping_metrics(self, warped_cloth: torch.Tensor, 
                               original_cloth: torch.Tensor, 
                               target_mask: torch.Tensor) -> Dict[str, float]:
        """ì›Œí•‘ ë©”íŠ¸ë¦­ ê³„ì‚°"""
        metrics = {}
        
        try:
            with torch.no_grad():
                # 1. ë³€í˜• í¬ê¸° í†µê³„
                deformation = warped_cloth - original_cloth
                deformation_magnitude = torch.norm(deformation, dim=1)
                
                metrics['mean_deformation'] = float(deformation_magnitude.mean().item())
                metrics['max_deformation'] = float(deformation_magnitude.max().item())
                metrics['std_deformation'] = float(deformation_magnitude.std().item())
                
                # 2. ì›Œí•‘ ì¼ê´€ì„±
                consistency_score = 1.0 - F.mse_loss(warped_cloth, original_cloth)
                metrics['warping_consistency'] = float(consistency_score.item())
                
                # 3. ê¸°í•˜í•™ì  ì¼ê´€ì„±
                if self.config.enable_geometric_constraints:
                    # ë³€í˜• í•„ë“œì˜ ê¸°ìš¸ê¸° ê³„ì‚°
                    grad_x = torch.gradient(deformation[:, 0, :, :], dim=2)[0]
                    grad_y = torch.gradient(deformation[:, 1, :, :], dim=1)[0]
                    geometric_consistency = 1.0 - torch.mean(torch.abs(grad_x - grad_y))
                    metrics['geometric_consistency'] = float(geometric_consistency.item())
                
                # 4. í’ˆì§ˆ ì ìˆ˜
                quality_score = self._assess_warping_quality(warped_cloth, original_cloth, target_mask)
                metrics['quality_score'] = quality_score
                
        except Exception as e:
            self.logger.warning(f"ì›Œí•‘ ë©”íŠ¸ë¦­ ê³„ì‚° ì‹¤íŒ¨: {e}")
            metrics = {
                'mean_deformation': 0.0,
                'max_deformation': 0.0,
                'std_deformation': 0.0,
                'warping_consistency': 0.0,
                'quality_score': 0.0
            }
        
        return metrics
    
    def get_model_info(self) -> Dict[str, Any]:
        """ëª¨ë¸ ì •ë³´ ë°˜í™˜"""
        return {
            "input_size": self.config.input_size,
            "output_size": self.config.output_size,
            "embedding_dim": self.config.embedding_dim,
            "num_control_points": self.config.num_control_points,
            "warping_layers": self.config.warping_layers,
            "device": str(self.device),
            "enable_tps_warping": self.config.enable_tps_warping,
            "enable_geometric_constraints": self.config.enable_geometric_constraints,
            "warping_strength": self.config.warping_strength,
            "total_parameters": sum(p.numel() for p in self.parameters()),
            "trainable_parameters": sum(p.numel() for p in self.parameters() if p.requires_grad)
        }

# ì˜ë¥˜ ì›Œí•‘ ì½”ì–´ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
def create_cloth_warping_core(config: ClothWarpingConfig = None) -> ClothWarpingCore:
    """Cloth Warping ì½”ì–´ ìƒì„±"""
    return ClothWarpingCore(config)

if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì½”ë“œ
    logging.basicConfig(level=logging.INFO)
    
    # ì˜ë¥˜ ì›Œí•‘ ì½”ì–´ ìƒì„±
    core = create_cloth_warping_core()
    
    # í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±
    batch_size, channels, height, width = 2, 3, 256, 256
    test_cloth = torch.randn(batch_size, channels, height, width)
    test_mask = torch.rand(batch_size, channels, height, width)
    
    # ì˜ë¥˜ ì›Œí•‘ ìˆ˜í–‰
    result = core(test_cloth, test_mask)
    
    print(f"ì›Œí•‘ëœ ì˜ë¥˜ í˜•íƒœ: {result['warped_cloth'].shape}")
    print(f"í’ˆì§ˆ ì ìˆ˜: {result['quality_score']:.3f}")
    
    # ì›Œí•‘ ë©”íŠ¸ë¦­ ê³„ì‚°
    metrics = core.compute_warping_metrics(result['warped_cloth'], test_cloth, test_mask)
    print(f"ì›Œí•‘ ë©”íŠ¸ë¦­: {metrics}")
    
    # ëª¨ë¸ ì •ë³´ ì¶œë ¥
    model_info = core.get_model_info()
    print(f"ëª¨ë¸ ì •ë³´: {model_info}")
