"""
ğŸ”¥ Cloth Warping ì „ìš© ì „ì²˜ë¦¬ ì‹œìŠ¤í…œ
====================================

ì˜ë¥˜ ë³€í˜•ì— ìµœì í™”ëœ ì „ì²˜ë¦¬ ê¸°ëŠ¥ë“¤:
1. ì˜ë¥˜ ë©”ì‹œ ìƒì„± ë° ì •ê·œí™”
2. ë³€í˜• ë§µ ê³„ì‚° ë° ìµœì í™”
3. í…ìŠ¤ì²˜ ë³´ì¡´ ë° í–¥ìƒ
4. ê²½ê³„ ì²˜ë¦¬ ë° í’ˆì§ˆ í–¥ìƒ
5. ë³€í˜• í’ˆì§ˆ ìµœì í™”

Author: MyCloset AI Team
Date: 2025-01-27
Version: 1.0 (ì™„ì „ êµ¬í˜„)
"""

import cv2
import numpy as np
import torch
import torch.nn.functional as F
from typing import Dict, Any, Optional, Tuple, List
import logging
from PIL import Image
import matplotlib.pyplot as plt
import matplotlib.patches as patches

logger = logging.getLogger(__name__)

class ClothWarpingPreprocessor:
    """ì˜ë¥˜ ë³€í˜•ì— ìµœì í™”ëœ ì „ì²˜ë¦¬ ì‹œìŠ¤í…œ"""
    
    def __init__(self, target_size: Tuple[int, int] = (512, 512)):
        self.target_size = target_size
        self.logger = logging.getLogger(f"{__name__}.ClothWarpingPreprocessor")
        
        # ì˜ë¥˜ ë³€í˜•ìš© ì „ì²˜ë¦¬ íŒŒë¼ë¯¸í„°
        self.warping_params = {
            'mesh_generation': True,
            'deformation_mapping': True,
            'texture_preservation': True,
            'boundary_handling': True,
            'quality_enhancement': True
        }
        
        # ì²˜ë¦¬ í†µê³„
        self.processing_stats = {
            'images_processed': 0,
            'meshes_generated': 0,
            'deformations_mapped': 0,
            'textures_preserved': 0
        }
    
    def preprocess_image(self, image: np.ndarray, mode: str = 'advanced') -> Dict[str, Any]:
        """ì˜ë¥˜ ë³€í˜•ì„ ìœ„í•œ ì™„ì „í•œ ì „ì²˜ë¦¬"""
        try:
            self.processing_stats['images_processed'] += 1
            self.logger.info(f"ğŸ”¥ ì˜ë¥˜ ë³€í˜• ì „ì²˜ë¦¬ ì‹œì‘ (ëª¨ë“œ: {mode})")
            
            # 1. ì´ë¯¸ì§€ ê²€ì¦
            validated_image = self._validate_image(image)
            
            # 2. ì˜ë¥˜ ë©”ì‹œ ìƒì„±
            meshed_image, mesh_info = self._generate_clothing_mesh(validated_image)
            if mesh_info['mesh_generated']:
                self.processing_stats['meshes_generated'] += 1
            
            # 3. í•´ìƒë„ í‘œì¤€í™”
            resized_image = self._standardize_resolution(meshed_image)
            
            # 4. ì˜ë¥˜ ë³€í˜• ìµœì í™”
            if mode == 'advanced':
                optimized_image = self._optimize_for_cloth_warping(resized_image)
                self.processing_stats['deformations_mapped'] += 1
                self.processing_stats['textures_preserved'] += 1
            else:
                optimized_image = resized_image
            
            # 5. ì •ê·œí™” ë° í…ì„œ ë³€í™˜
            normalized_tensor = self._normalize_and_convert(optimized_image)
            
            # 6. ì „ì²˜ë¦¬ ê²°ê³¼ ìš”ì•½
            preprocessing_result = {
                'processed_image': optimized_image,
                'tensor': normalized_tensor,
                'mesh_info': mesh_info,
                'target_size': self.target_size,
                'mode': mode,
                'warping_params': self.warping_params,
                'success': True
            }
            
            self.logger.info("âœ… ì˜ë¥˜ ë³€í˜• ì „ì²˜ë¦¬ ì™„ë£Œ")
            return preprocessing_result
            
        except Exception as e:
            self.logger.error(f"âŒ ì˜ë¥˜ ë³€í˜• ì „ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return {
                'success': False,
                'error': str(e),
                'processed_image': image,
                'tensor': torch.randn(1, 3, *self.target_size)
            }
    
    def _validate_image(self, image: np.ndarray) -> np.ndarray:
        """ì´ë¯¸ì§€ ìœ íš¨ì„± ê²€ì¦ ë° ë³€í™˜"""
        try:
            # PIL Imageë¥¼ NumPyë¡œ ë³€í™˜
            if isinstance(image, Image.Image):
                image = np.array(image)
            
            # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ì„ RGBë¡œ ë³€í™˜
            if len(image.shape) == 2:
                image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)
            elif image.shape[2] == 4:  # RGBA
                image = cv2.cvtColor(image, cv2.COLOR_RGBA2RGB)
            
            # ë°ì´í„° íƒ€ì… ì •ê·œí™”
            if image.dtype != np.uint8:
                image = image.astype(np.uint8)
            
            return image
            
        except Exception as e:
            self.logger.warning(f"ì´ë¯¸ì§€ ê²€ì¦ ì‹¤íŒ¨: {e}")
            return image
    
    def _generate_clothing_mesh(self, image: np.ndarray) -> Tuple[np.ndarray, Dict[str, Any]]:
        """ì˜ë¥˜ ë©”ì‹œ ìƒì„±"""
        try:
            # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜
            gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
            
            # 1. ì—£ì§€ ê°ì§€
            edges = cv2.Canny(gray, 30, 100)
            
            # 2. ìœ¤ê³½ì„  ì°¾ê¸°
            contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            
            # 3. ì˜ë¥˜ ì˜ì—­ í•„í„°ë§ (ë©´ì  ê¸°ì¤€)
            clothing_contours = []
            for contour in contours:
                area = cv2.contourArea(contour)
                if area > 1000:  # ìµœì†Œ ë©´ì  ì„ê³„ê°’
                    clothing_contours.append(contour)
            
            # 4. ë©”ì‹œ ìƒì„±
            if clothing_contours:
                # ê°€ì¥ í° ì˜ë¥˜ ì˜ì—­ ì„ íƒ
                largest_contour = max(clothing_contours, key=cv2.contourArea)
                
                # ë©”ì‹œ ê·¸ë¦¬ë“œ ìƒì„±
                meshed_image = self._create_mesh_grid(image, largest_contour)
                
                mesh_info = {
                    'mesh_generated': True,
                    'contour_count': len(clothing_contours),
                    'largest_contour_area': cv2.contourArea(largest_contour),
                    'mesh_density': 'high',
                    'original_size': image.shape[:2],
                    'meshed_size': meshed_image.shape[:2]
                }
                
                return meshed_image, mesh_info
            else:
                # ë©”ì‹œë¥¼ ìƒì„±í•  ìˆ˜ ì—†ëŠ” ê²½ìš° ì›ë³¸ ë°˜í™˜
                return image, {
                    'mesh_generated': False,
                    'contour_count': 0,
                    'largest_contour_area': 0,
                    'mesh_density': 'none',
                    'original_size': image.shape[:2],
                    'meshed_size': image.shape[:2]
                }
                
        except Exception as e:
            self.logger.warning(f"ì˜ë¥˜ ë©”ì‹œ ìƒì„± ì‹¤íŒ¨: {e}")
            return image, {
                'mesh_generated': False,
                'contour_count': 0,
                'largest_contour_area': 0,
                'mesh_density': 'none',
                'original_size': image.shape[:2],
                'meshed_size': image.shape[:2]
            }
    
    def _create_mesh_grid(self, image: np.ndarray, contour: np.ndarray) -> np.ndarray:
        """ë©”ì‹œ ê·¸ë¦¬ë“œ ìƒì„±"""
        try:
            # ìœ¤ê³½ì„ ì„ í¬í•¨í•˜ëŠ” ê²½ê³„ ì‚¬ê°í˜•
            x, y, w, h = cv2.boundingRect(contour)
            
            # ë©”ì‹œ ê·¸ë¦¬ë“œ í¬ê¸°
            grid_size = 20
            
            # ë©”ì‹œ ì´ë¯¸ì§€ ìƒì„±
            meshed = image.copy()
            
            # ìˆ˜ì§ì„  ê·¸ë¦¬ê¸°
            for i in range(0, w, grid_size):
                cv2.line(meshed, (x + i, y), (x + i, y + h), (0, 255, 0), 1)
            
            # ìˆ˜í‰ì„  ê·¸ë¦¬ê¸°
            for j in range(0, h, grid_size):
                cv2.line(meshed, (x, y + j), (x + w, y + j), (0, 255, 0), 1)
            
            # ìœ¤ê³½ì„  ê·¸ë¦¬ê¸°
            cv2.drawContours(meshed, [contour], -1, (255, 0, 0), 2)
            
            return meshed
            
        except Exception as e:
            self.logger.warning(f"ë©”ì‹œ ê·¸ë¦¬ë“œ ìƒì„± ì‹¤íŒ¨: {e}")
            return image
    
    def _standardize_resolution(self, image: np.ndarray) -> np.ndarray:
        """í•´ìƒë„ í‘œì¤€í™”"""
        try:
            # ëª©í‘œ í•´ìƒë„ë¡œ ë¦¬ì‚¬ì´ì¦ˆ
            resized = cv2.resize(image, self.target_size, interpolation=cv2.INTER_LANCZOS4)
            return resized
            
        except Exception as e:
            self.logger.warning(f"í•´ìƒë„ í‘œì¤€í™” ì‹¤íŒ¨: {e}")
            return image
    
    def _optimize_for_cloth_warping(self, image: np.ndarray) -> np.ndarray:
        """ì˜ë¥˜ ë³€í˜• ìµœì í™”"""
        try:
            optimized = image.copy()
            
            # 1. ë©”ì‹œ ìƒì„±
            if self.warping_params['mesh_generation']:
                optimized = self._enhance_mesh_generation(optimized)
            
            # 2. ë³€í˜• ë§µí•‘
            if self.warping_params['deformation_mapping']:
                optimized = self._create_deformation_mapping(optimized)
            
            # 3. í…ìŠ¤ì²˜ ë³´ì¡´
            if self.warping_params['texture_preservation']:
                optimized = self._preserve_texture(optimized)
            
            # 4. ê²½ê³„ ì²˜ë¦¬
            if self.warping_params['boundary_handling']:
                optimized = self._handle_boundaries(optimized)
            
            # 5. í’ˆì§ˆ í–¥ìƒ
            if self.warping_params['quality_enhancement']:
                optimized = self._enhance_quality(optimized)
            
            return optimized
            
        except Exception as e:
            self.logger.warning(f"ì˜ë¥˜ ë³€í˜• ìµœì í™” ì‹¤íŒ¨: {e}")
            return image
    
    def _enhance_mesh_generation(self, image: np.ndarray) -> np.ndarray:
        """ë©”ì‹œ ìƒì„± í–¥ìƒ"""
        try:
            enhanced = image.copy()
            
            # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜
            gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
            
            # ì—£ì§€ ê°•í™”
            edges = cv2.Canny(gray, 20, 80)
            
            # ëª¨í´ë¡œì§€ ì—°ì‚°ìœ¼ë¡œ ì—£ì§€ ì •ì œ
            kernel = np.ones((3, 3), np.uint8)
            refined_edges = cv2.morphologyEx(edges, cv2.MORPH_CLOSE, kernel)
            
            # ì—£ì§€ë¥¼ RGBë¡œ ë³€í™˜
            edges_rgb = cv2.cvtColor(refined_edges, cv2.COLOR_GRAY2RGB)
            
            # ì›ë³¸ê³¼ ì—£ì§€ í•©ì„±
            enhanced = cv2.addWeighted(enhanced, 0.9, edges_rgb, 0.1, 0)
            
            return enhanced
            
        except Exception as e:
            self.logger.warning(f"ë©”ì‹œ ìƒì„± í–¥ìƒ ì‹¤íŒ¨: {e}")
            return image
    
    def _create_deformation_mapping(self, image: np.ndarray) -> np.ndarray:
        """ë³€í˜• ë§µí•‘ ìƒì„±"""
        try:
            mapped = image.copy()
            
            # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜
            gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
            
            # ë³€í˜• ë§µì„ ìœ„í•œ í•„í„°ë§
            # 1. ê°€ìš°ì‹œì•ˆ ë¸”ëŸ¬ë¡œ ë¶€ë“œëŸ¬ìš´ ë³€í˜•
            blurred = cv2.GaussianBlur(gray, (5, 5), 0)
            
            # 2. ë³€í˜• ê°•ë„ ê³„ì‚°
            deformation_strength = cv2.addWeighted(gray, 1.5, blurred, -0.5, 0)
            
            # 3. ë³€í˜• ë§µ ì •ê·œí™”
            deformation_map = cv2.normalize(deformation_strength, None, 0, 255, cv2.NORM_MINMAX)
            
            # 4. ë³€í˜• ë§µì„ RGBë¡œ ë³€í™˜
            deformation_rgb = cv2.cvtColor(deformation_map, cv2.COLOR_GRAY2RGB)
            
            # 5. ì›ë³¸ê³¼ ë³€í˜• ë§µ í•©ì„±
            mapped = cv2.addWeighted(mapped, 0.8, deformation_rgb, 0.2, 0)
            
            return mapped
            
        except Exception as e:
            self.logger.warning(f"ë³€í˜• ë§µí•‘ ìƒì„± ì‹¤íŒ¨: {e}")
            return image
    
    def _preserve_texture(self, image: np.ndarray) -> np.ndarray:
        """í…ìŠ¤ì²˜ ë³´ì¡´"""
        try:
            preserved = image.copy()
            
            # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜
            gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
            
            # 1. ë¡œì»¬ ì´ì§„ íŒ¨í„´ (LBP) ê³„ì‚°
            lbp = self._calculate_lbp(gray)
            
            # 2. í…ìŠ¤ì²˜ íŠ¹ì„± ë¶„ì„
            texture_features = self._analyze_texture_features(lbp)
            
            # 3. í…ìŠ¤ì²˜ ë³´ì¡´ í•„í„°ë§
            if texture_features['complexity'] > 0.5:
                # ë³µì¡í•œ í…ìŠ¤ì²˜ëŠ” ì–‘ë°©í–¥ í•„í„°ë¡œ ë³´ì¡´
                preserved = cv2.bilateralFilter(preserved, 9, 75, 75)
            else:
                # ë‹¨ìˆœí•œ í…ìŠ¤ì²˜ëŠ” ê°€ìš°ì‹œì•ˆ í•„í„°ë¡œ ë¶€ë“œëŸ½ê²Œ
                preserved = cv2.GaussianBlur(preserved, (3, 3), 0)
            
            return preserved
            
        except Exception as e:
            self.logger.warning(f"í…ìŠ¤ì²˜ ë³´ì¡´ ì‹¤íŒ¨: {e}")
            return image
    
    def _calculate_lbp(self, gray_image: np.ndarray) -> np.ndarray:
        """ë¡œì»¬ ì´ì§„ íŒ¨í„´ ê³„ì‚°"""
        try:
            h, w = gray_image.shape
            lbp = np.zeros((h-2, w-2), dtype=np.uint8)
            
            for i in range(1, h-1):
                for j in range(1, w-1):
                    center = gray_image[i, j]
                    code = 0
                    
                    # 8-ì´ì›ƒ í”½ì…€ ê²€ì‚¬
                    neighbors = [
                        gray_image[i-1, j-1], gray_image[i-1, j], gray_image[i-1, j+1],
                        gray_image[i, j+1], gray_image[i+1, j+1], gray_image[i+1, j],
                        gray_image[i+1, j-1], gray_image[i, j-1]
                    ]
                    
                    for k, neighbor in enumerate(neighbors):
                        if neighbor >= center:
                            code |= (1 << k)
                    
                    lbp[i-1, j-1] = code
            
            return lbp
            
        except Exception as e:
            self.logger.warning(f"LBP ê³„ì‚° ì‹¤íŒ¨: {e}")
            return np.zeros_like(gray_image)
    
    def _analyze_texture_features(self, lbp: np.ndarray) -> Dict[str, float]:
        """í…ìŠ¤ì²˜ íŠ¹ì„± ë¶„ì„"""
        try:
            # LBP íˆìŠ¤í† ê·¸ë¨ ê³„ì‚°
            hist = cv2.calcHist([lbp], [0], None, [256], [0, 256])
            
            # í…ìŠ¤ì²˜ ë³µì¡ë„ (ì—”íŠ¸ë¡œí”¼)
            hist_normalized = hist.ravel() / hist.sum()
            entropy = -np.sum(hist_normalized * np.log2(hist_normalized + 1e-10))
            
            # ë³µì¡ë„ ì •ê·œí™” (0~1)
            complexity = min(1.0, entropy / 8.0)
            
            return {
                'complexity': complexity,
                'entropy': entropy,
                'uniformity': 1.0 - complexity
            }
            
        except Exception as e:
            self.logger.warning(f"í…ìŠ¤ì²˜ íŠ¹ì„± ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {
                'complexity': 0.5,
                'entropy': 4.0,
                'uniformity': 0.5
            }
    
    def _handle_boundaries(self, image: np.ndarray) -> np.ndarray:
        """ê²½ê³„ ì²˜ë¦¬"""
        try:
            handled = image.copy()
            
            # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜
            gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
            
            # 1. ê²½ê³„ ê°ì§€
            edges = cv2.Canny(gray, 50, 150)
            
            # 2. ê²½ê³„ ì •ì œ
            kernel = np.ones((3, 3), np.uint8)
            refined_edges = cv2.morphologyEx(edges, cv2.MORPH_CLOSE, kernel)
            
            # 3. ê²½ê³„ ë¶€ë“œëŸ½ê²Œ ì²˜ë¦¬
            smoothed_edges = cv2.GaussianBlur(refined_edges, (3, 3), 0)
            
            # 4. ê²½ê³„ë¥¼ RGBë¡œ ë³€í™˜
            edges_rgb = cv2.cvtColor(smoothed_edges, cv2.COLOR_GRAY2RGB)
            
            # 5. ì›ë³¸ê³¼ ê²½ê³„ í•©ì„±
            handled = cv2.addWeighted(handled, 0.9, edges_rgb, 0.1, 0)
            
            return handled
            
        except Exception as e:
            self.logger.warning(f"ê²½ê³„ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return image
    
    def _enhance_quality(self, image: np.ndarray) -> np.ndarray:
        """í’ˆì§ˆ í–¥ìƒ"""
        try:
            enhanced = image.copy()
            
            # 1. ëŒ€ë¹„ í–¥ìƒ
            enhanced = cv2.convertScaleAbs(enhanced, alpha=1.1, beta=5)
            
            # 2. ì„ ëª…ë„ í–¥ìƒ
            kernel = np.array([[-1,-1,-1], [-1,9,-1], [-1,-1,-1]])
            enhanced = cv2.filter2D(enhanced, -1, kernel)
            
            # 3. ë…¸ì´ì¦ˆ ì œê±°
            enhanced = cv2.fastNlMeansDenoisingColored(enhanced, None, 10, 10, 7, 21)
            
            return enhanced
            
        except Exception as e:
            self.logger.warning(f"í’ˆì§ˆ í–¥ìƒ ì‹¤íŒ¨: {e}")
            return image
    
    def _normalize_and_convert(self, image: np.ndarray) -> torch.Tensor:
        """ì •ê·œí™” ë° í…ì„œ ë³€í™˜"""
        try:
            # 0-1 ë²”ìœ„ë¡œ ì •ê·œí™”
            normalized = image.astype(np.float32) / 255.0
            
            # ImageNet í‰ê· /í‘œì¤€í¸ì°¨ë¡œ ì •ê·œí™”
            mean = np.array([0.485, 0.456, 0.406])
            std = np.array([0.229, 0.224, 0.225])
            
            normalized = (normalized - mean) / std
            
            # í…ì„œë¡œ ë³€í™˜ [H, W, C] -> [C, H, W] -> [1, C, H, W]
            tensor = torch.from_numpy(normalized).permute(2, 0, 1).unsqueeze(0)
            
            return tensor
            
        except Exception as e:
            self.logger.warning(f"ì •ê·œí™” ë° ë³€í™˜ ì‹¤íŒ¨: {e}")
            return torch.randn(1, 3, *self.target_size)
    
    def get_processing_stats(self) -> Dict[str, Any]:
        """ì²˜ë¦¬ í†µê³„ ë°˜í™˜"""
        return self.processing_stats.copy()
    
    def reset_stats(self):
        """í†µê³„ ì´ˆê¸°í™”"""
        self.processing_stats = {
            'images_processed': 0,
            'meshes_generated': 0,
            'deformations_mapped': 0,
            'textures_preserved': 0
        }
    
    def update_warping_params(self, **kwargs):
        """ì˜ë¥˜ ë³€í˜• íŒŒë¼ë¯¸í„° ì—…ë°ì´íŠ¸"""
        for key, value in kwargs.items():
            if key in self.warping_params:
                self.warping_params[key] = value
                self.logger.info(f"ì˜ë¥˜ ë³€í˜• íŒŒë¼ë¯¸í„° ì—…ë°ì´íŠ¸: {key} = {value}")
