#!/usr/bin/env python3
"""
ğŸ”¥ MyCloset AI - Cloth Warping Testing Service
==============================================

ğŸ¯ ì˜ë¥˜ ì›Œí•‘ í…ŒìŠ¤íŒ… ì„œë¹„ìŠ¤
âœ… ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
âœ… í†µí•© í…ŒìŠ¤íŠ¸ ì‹¤í–‰
âœ… ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
âœ… M3 Max ìµœì í™”
"""

import logging
import torch
import time
from typing import Dict, List, Tuple, Optional, Union, Any
from dataclasses import dataclass

logger = logging.getLogger(__name__)

@dataclass
class TestingServiceConfig:
    """í…ŒìŠ¤íŒ… ì„œë¹„ìŠ¤ ì„¤ì •"""
    enable_unit_tests: bool = True
    enable_integration_tests: bool = True
    enable_performance_tests: bool = True
    test_batch_size: int = 2
    test_image_size: Tuple[int, int] = (256, 256)
    use_mps: bool = True

class ClothWarpingTestingService:
    """ì˜ë¥˜ ì›Œí•‘ í…ŒìŠ¤íŒ… ì„œë¹„ìŠ¤"""
    
    def __init__(self, config: TestingServiceConfig = None):
        self.config = config or TestingServiceConfig()
        self.logger = logging.getLogger(__name__)
        self.logger.info("ğŸ¯ Cloth Warping í…ŒìŠ¤íŒ… ì„œë¹„ìŠ¤ ì´ˆê¸°í™”")
        
        # MPS ë””ë°”ì´ìŠ¤ í™•ì¸
        self.device = torch.device("mps" if torch.backends.mps.is_available() and self.config.use_mps else "cpu")
        
        # í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì €ì¥
        self.test_results = {}
        
        self.logger.info("âœ… Cloth Warping í…ŒìŠ¤íŒ… ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ")
    
    def run_unit_tests(self) -> Dict[str, Any]:
        """ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤."""
        if not self.config.enable_unit_tests:
            return {'status': 'disabled'}
        
        self.logger.info("ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì‹œì‘")
        test_results = {}
        
        try:
            # í”„ë¡œì„¸ì„œ ëª¨ë“ˆ import í…ŒìŠ¤íŠ¸
            import sys
            import os
            sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'processors'))
            from advanced_post_processor import ClothWarpingAdvancedPostProcessor
            from high_resolution_processor import ClothWarpingHighResolutionProcessor
            from preprocessing import ClothWarpingPreprocessor
            from quality_enhancer import ClothWarpingQualityEnhancer
            from special_case_processor import ClothWarpingSpecialCaseProcessor
            
            test_results['import_test'] = 'success'
            
            # í”„ë¡œì„¸ì„œ ì¸ìŠ¤í„´ìŠ¤ ìƒì„± í…ŒìŠ¤íŠ¸
            processors = {
                'advanced_post_processor': ClothWarpingAdvancedPostProcessor(),
                'high_resolution_processor': ClothWarpingHighResolutionProcessor(),
                'preprocessor': ClothWarpingPreprocessor(),
                'quality_enhancer': ClothWarpingQualityEnhancer(),
                'special_case_processor': ClothWarpingSpecialCaseProcessor()
            }
            
            test_results['instantiation_test'] = 'success'
            test_results['processors_created'] = len(processors)
            
            # ê¸°ë³¸ forward pass í…ŒìŠ¤íŠ¸
            batch_size = self.config.test_batch_size
            channels = 3
            height, width = self.config.test_image_size
            
            test_image = torch.randn(batch_size, channels, height, width, device=self.device)
            
            for name, processor in processors.items():
                try:
                    with torch.no_grad():
                        if name == 'advanced_post_processor':
                            result = processor(test_image, test_image, test_image)
                        elif name == 'high_resolution_processor':
                            result = processor(test_image, test_image)
                        elif name == 'preprocessor':
                            result = processor(test_image, test_image)
                        else:
                            result = processor(test_image)
                        
                        test_results[f'{name}_forward_test'] = 'success'
                        
                except Exception as e:
                    test_results[f'{name}_forward_test'] = f'failed: {str(e)}'
            
            test_results['status'] = 'success'
            self.logger.info("ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
            
        except Exception as e:
            test_results['status'] = 'error'
            test_results['error'] = str(e)
            self.logger.error(f"ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        
        self.test_results['unit_tests'] = test_results
        return test_results
    
    def run_integration_tests(self) -> Dict[str, Any]:
        """í†µí•© í…ŒìŠ¤íŠ¸ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤."""
        if not self.config.enable_integration_tests:
            return {'status': 'disabled'}
        
        self.logger.info("í†µí•© í…ŒìŠ¤íŠ¸ ì‹œì‘")
        test_results = {}
        
        try:
            # ì „ì²´ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸
            import sys
            import os
            sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'processors'))
            from preprocessing import ClothWarpingPreprocessor
            from high_resolution_processor import ClothWarpingHighResolutionProcessor
            from advanced_post_processor import ClothWarpingAdvancedPostProcessor
            from quality_enhancer import ClothWarpingQualityEnhancer
            
            # í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±
            batch_size = self.config.test_batch_size
            channels = 3
            height, width = self.config.test_image_size
            
            cloth_image = torch.randn(batch_size, channels, height, width, device=self.device)
            person_image = torch.randn(batch_size, channels, height, width, device=self.device)
            
            # 1ë‹¨ê³„: ì „ì²˜ë¦¬
            preprocessor = ClothWarpingPreprocessor()
            preprocessed = preprocessor(cloth_image, person_image)
            test_results['preprocessing'] = 'success'
            
            # 2ë‹¨ê³„: ê³ í•´ìƒë„ ì²˜ë¦¬
            hr_processor = ClothWarpingHighResolutionProcessor()
            warped_result = hr_processor(cloth_image, person_image)
            test_results['high_resolution_processing'] = 'success'
            
            # 3ë‹¨ê³„: ê³ ê¸‰ í›„ì²˜ë¦¬
            post_processor = ClothWarpingAdvancedPostProcessor()
            post_processed = post_processor(
                warped_result['warped_cloth'], 
                cloth_image, 
                person_image
            )
            test_results['advanced_post_processing'] = 'success'
            
            # 4ë‹¨ê³„: í’ˆì§ˆ í–¥ìƒ
            quality_enhancer = ClothWarpingQualityEnhancer()
            enhanced = quality_enhancer(post_processed['optimized_warped_image'])
            test_results['quality_enhancement'] = 'success'
            
            test_results['status'] = 'success'
            test_results['pipeline_steps'] = 4
            self.logger.info("í†µí•© í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
            
        except Exception as e:
            test_results['status'] = 'error'
            test_results['error'] = str(e)
            self.logger.error(f"í†µí•© í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        
        self.test_results['integration_tests'] = test_results
        return test_results
    
    def run_performance_tests(self) -> Dict[str, Any]:
        """ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤."""
        if not self.config.enable_performance_tests:
            return {'status': 'disabled'}
        
        self.logger.info("ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹œì‘")
        test_results = {}
        
        try:
            import sys
            import os
            sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'processors'))
            from high_resolution_processor import ClothWarpingHighResolutionProcessor
            
            # ë‹¤ì–‘í•œ ë°°ì¹˜ í¬ê¸°ë¡œ í…ŒìŠ¤íŠ¸
            batch_sizes = [1, 2, 4]
            image_sizes = [(256, 256), (512, 512), (1024, 1024)]
            
            performance_data = {}
            
            for batch_size in batch_sizes:
                for height, width in image_sizes:
                    try:
                        # í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±
                        cloth_image = torch.randn(batch_size, 3, height, width, device=self.device)
                        person_image = torch.randn(batch_size, 3, height, width, device=self.device)
                        
                        # í”„ë¡œì„¸ì„œ ì´ˆê¸°í™”
                        processor = ClothWarpingHighResolutionProcessor()
                        
                        # ì›Œë°ì—…
                        with torch.no_grad():
                            _ = processor(cloth_image, person_image)
                        
                        # ì„±ëŠ¥ ì¸¡ì •
                        start_time = time.time()
                        
                        with torch.no_grad():
                            for _ in range(5):  # 5íšŒ ë°˜ë³µ
                                _ = processor(cloth_image, person_image)
                        
                        end_time = time.time()
                        avg_time = (end_time - start_time) / 5
                        
                        key = f"batch_{batch_size}_size_{height}x{width}"
                        performance_data[key] = {
                            'batch_size': batch_size,
                            'image_size': (height, width),
                            'average_time': avg_time,
                            'throughput': batch_size / avg_time
                        }
                        
                    except Exception as e:
                        key = f"batch_{batch_size}_size_{height}x{width}"
                        performance_data[key] = {
                            'error': str(e)
                        }
            
            test_results['performance_data'] = performance_data
            test_results['status'] = 'success'
            self.logger.info("ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
            
        except Exception as e:
            test_results['status'] = 'error'
            test_results['error'] = str(e)
            self.logger.error(f"ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        
        self.test_results['performance_tests'] = test_results
        return test_results
    
    def run_all_tests(self) -> Dict[str, Any]:
        """ëª¨ë“  í…ŒìŠ¤íŠ¸ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤."""
        self.logger.info("ì „ì²´ í…ŒìŠ¤íŠ¸ ì‹œì‘")
        
        all_results = {}
        
        # ë‹¨ìœ„ í…ŒìŠ¤íŠ¸
        all_results['unit_tests'] = self.run_unit_tests()
        
        # í†µí•© í…ŒìŠ¤íŠ¸
        all_results['integration_tests'] = self.run_integration_tests()
        
        # ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
        all_results['performance_tests'] = self.run_performance_tests()
        
        # ì „ì²´ ê²°ê³¼ ìš”ì•½
        total_tests = 0
        passed_tests = 0
        
        for test_type, results in all_results.items():
            if results.get('status') == 'success':
                passed_tests += 1
            total_tests += 1
        
        all_results['summary'] = {
            'total_test_types': total_tests,
            'passed_test_types': passed_tests,
            'overall_status': 'success' if passed_tests == total_tests else 'partial_success'
        }
        
        self.test_results = all_results
        self.logger.info(f"ì „ì²´ í…ŒìŠ¤íŠ¸ ì™„ë£Œ: {passed_tests}/{total_tests} í†µê³¼")
        
        return all_results
    
    def get_test_results(self) -> Dict[str, Any]:
        """í…ŒìŠ¤íŠ¸ ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
        return self.test_results
    
    def get_test_summary(self) -> Dict[str, Any]:
        """í…ŒìŠ¤íŠ¸ ìš”ì•½ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
        if not self.test_results:
            return {'status': 'no_tests_run'}
        
        summary = {}
        for test_type, results in self.test_results.items():
            if isinstance(results, dict):
                summary[test_type] = results.get('status', 'unknown')
        
        return summary

# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    # ì„¤ì •
    config = TestingServiceConfig(
        enable_unit_tests=True,
        enable_integration_tests=True,
        enable_performance_tests=True,
        test_batch_size=2,
        test_image_size=(256, 256),
        use_mps=True
    )
    
    # í…ŒìŠ¤íŒ… ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
    testing_service = ClothWarpingTestingService(config)
    
    # ëª¨ë“  í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    all_results = testing_service.run_all_tests()
    
    # ê²°ê³¼ ì¶œë ¥
    print("=== í…ŒìŠ¤íŠ¸ ê²°ê³¼ ===")
    for test_type, results in all_results.items():
        print(f"\n{test_type}:")
        if isinstance(results, dict):
            for key, value in results.items():
                print(f"  {key}: {value}")
    
    # í…ŒìŠ¤íŠ¸ ìš”ì•½
    summary = testing_service.get_test_summary()
    print(f"\n=== í…ŒìŠ¤íŠ¸ ìš”ì•½ ===")
    print(f"ì „ì²´ ìƒíƒœ: {summary}")
