#!/usr/bin/env python3
"""
ğŸ”¥ MyCloset AI - Cloth Warping Validation Service
================================================

ğŸ¯ ì˜ë¥˜ ì›Œí•‘ ê²€ì¦ ì„œë¹„ìŠ¤
âœ… ì…ë ¥ ë°ì´í„° ê²€ì¦
âœ… ì¶œë ¥ ê²°ê³¼ ê²€ì¦
âœ… í’ˆì§ˆ ë©”íŠ¸ë¦­ ê³„ì‚°
âœ… M3 Max ìµœì í™”
"""

import logging
import torch
import numpy as np
from typing import Dict, List, Tuple, Optional, Union, Any
from dataclasses import dataclass
import cv2
from PIL import Image

logger = logging.getLogger(__name__)

@dataclass
class ValidationServiceConfig:
    """ê²€ì¦ ì„œë¹„ìŠ¤ ì„¤ì •"""
    enable_input_validation: bool = True
    enable_output_validation: bool = True
    enable_quality_metrics: bool = True
    min_image_size: Tuple[int, int] = (64, 64)
    max_image_size: Tuple[int, int] = (4096, 4096)
    use_mps: bool = True

class ClothWarpingValidationService:
    """ì˜ë¥˜ ì›Œí•‘ ê²€ì¦ ì„œë¹„ìŠ¤"""
    
    def __init__(self, config: ValidationServiceConfig = None):
        self.config = config or ValidationServiceConfig()
        self.logger = logging.getLogger(__name__)
        self.logger.info("ğŸ¯ Cloth Warping ê²€ì¦ ì„œë¹„ìŠ¤ ì´ˆê¸°í™”")
        
        # MPS ë””ë°”ì´ìŠ¤ í™•ì¸
        self.device = torch.device("mps" if torch.backends.mps.is_available() and self.config.use_mps else "cpu")
        
        # ê²€ì¦ ê²°ê³¼ ì €ì¥
        self.validation_results = {}
        
        self.logger.info("âœ… Cloth Warping ê²€ì¦ ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ")
    
    def validate_input_data(self, cloth_image: torch.Tensor, 
                           person_image: torch.Tensor) -> Dict[str, Any]:
        """ì…ë ¥ ë°ì´í„°ë¥¼ ê²€ì¦í•©ë‹ˆë‹¤."""
        if not self.config.enable_input_validation:
            return {'status': 'disabled'}
        
        validation_results = {}
        
        try:
            # ê¸°ë³¸ í˜•íƒœ ê²€ì¦
            if not isinstance(cloth_image, torch.Tensor) or not isinstance(person_image, torch.Tensor):
                validation_results['tensor_type'] = 'failed'
                validation_results['error'] = 'ì…ë ¥ì´ torch.Tensorê°€ ì•„ë‹™ë‹ˆë‹¤.'
                return validation_results
            
            # ì°¨ì› ê²€ì¦
            if cloth_image.dim() != 4 or person_image.dim() != 4:
                validation_results['dimensions'] = 'failed'
                validation_results['error'] = 'ì…ë ¥ì´ 4ì°¨ì› í…ì„œê°€ ì•„ë‹™ë‹ˆë‹¤ (B, C, H, W).'
                return validation_results
            
            # ë°°ì¹˜ í¬ê¸° ê²€ì¦
            if cloth_image.shape[0] != person_image.shape[0]:
                validation_results['batch_size'] = 'failed'
                validation_results['error'] = 'ì˜ë¥˜ì™€ ì‚¬ëŒ ì´ë¯¸ì§€ì˜ ë°°ì¹˜ í¬ê¸°ê°€ ë‹¤ë¦…ë‹ˆë‹¤.'
                return validation_results
            
            # ì±„ë„ ìˆ˜ ê²€ì¦
            if cloth_image.shape[1] != 3 or person_image.shape[1] != 3:
                validation_results['channels'] = 'failed'
                validation_results['error'] = 'ì…ë ¥ì´ 3ì±„ë„(RGB)ì´ ì•„ë‹™ë‹ˆë‹¤.'
                return validation_results
            
            # ì´ë¯¸ì§€ í¬ê¸° ê²€ì¦
            cloth_height, cloth_width = cloth_image.shape[2], cloth_image.shape[3]
            person_height, person_width = person_image.shape[2], person_image.shape[3]
            
            min_height, min_width = self.config.min_image_size
            max_height, max_width = self.config.max_image_size
            
            if (cloth_height < min_height or cloth_width < min_width or
                cloth_height > max_height or cloth_width > max_width):
                validation_results['cloth_size'] = 'failed'
                validation_results['error'] = f'ì˜ë¥˜ ì´ë¯¸ì§€ í¬ê¸°ê°€ í—ˆìš© ë²”ìœ„ë¥¼ ë²—ì–´ë‚¬ìŠµë‹ˆë‹¤: {cloth_height}x{cloth_width}'
                return validation_results
            
            if (person_height < min_height or person_width < min_width or
                person_height > max_height or person_width > max_width):
                validation_results['person_size'] = 'failed'
                validation_results['error'] = 'ì‚¬ëŒ ì´ë¯¸ì§€ í¬ê¸°ê°€ í—ˆìš© ë²”ìœ„ë¥¼ ë²—ì–´ë‚¬ìŠµë‹ˆë‹¤.'
                return validation_results
            
            # ê°’ ë²”ìœ„ ê²€ì¦
            if torch.min(cloth_image) < -1.0 or torch.max(cloth_image) > 1.0:
                validation_results['cloth_value_range'] = 'warning'
                validation_results['warning'] = 'ì˜ë¥˜ ì´ë¯¸ì§€ ê°’ì´ [-1, 1] ë²”ìœ„ë¥¼ ë²—ì–´ë‚¬ìŠµë‹ˆë‹¤.'
            
            if torch.min(person_image) < -1.0 or torch.max(person_image) > 1.0:
                validation_results['person_value_range'] = 'warning'
                validation_results['warning'] = 'ì‚¬ëŒ ì´ë¯¸ì§€ ê°’ì´ [-1, 1] ë²”ìœ„ë¥¼ ë²—ì–´ë‚¬ìŠµë‹ˆë‹¤.'
            
            # ë””ë°”ì´ìŠ¤ ê²€ì¦
            if cloth_image.device != self.device or person_image.device != self.device:
                validation_results['device'] = 'warning'
                validation_results['warning'] = 'ì…ë ¥ ì´ë¯¸ì§€ê°€ ì˜ˆìƒ ë””ë°”ì´ìŠ¤ì— ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.'
            
            validation_results.update({
                'status': 'success',
                'cloth_shape': cloth_image.shape,
                'person_shape': person_image.shape,
                'batch_size': cloth_image.shape[0],
                'channels': cloth_image.shape[1],
                'cloth_size': (cloth_height, cloth_width),
                'person_size': (person_height, person_width)
            })
            
            self.logger.info("ì…ë ¥ ë°ì´í„° ê²€ì¦ ì™„ë£Œ")
            
        except Exception as e:
            validation_results['status'] = 'error'
            validation_results['error'] = str(e)
            self.logger.error(f"ì…ë ¥ ë°ì´í„° ê²€ì¦ ì‹¤íŒ¨: {e}")
        
        return validation_results
    
    def validate_output_data(self, output_data: Dict[str, torch.Tensor]) -> Dict[str, Any]:
        """ì¶œë ¥ ë°ì´í„°ë¥¼ ê²€ì¦í•©ë‹ˆë‹¤."""
        if not self.config.enable_output_validation:
            return {'status': 'disabled'}
        
        validation_results = {}
        
        try:
            # í•„ìˆ˜ í‚¤ ê²€ì¦
            required_keys = ['warped_cloth', 'quality_score', 'validation_score']
            missing_keys = [key for key in required_keys if key not in output_data]
            
            if missing_keys:
                validation_results['required_keys'] = 'failed'
                validation_results['error'] = f'í•„ìˆ˜ í‚¤ê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤: {missing_keys}'
                return validation_results
            
            # ì›Œí•‘ëœ ì˜ë¥˜ ì´ë¯¸ì§€ ê²€ì¦
            warped_cloth = output_data['warped_cloth']
            if not isinstance(warped_cloth, torch.Tensor) or warped_cloth.dim() != 4:
                validation_results['warped_cloth_format'] = 'failed'
                validation_results['error'] = 'ì›Œí•‘ëœ ì˜ë¥˜ ì´ë¯¸ì§€ê°€ ì˜¬ë°”ë¥¸ í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤.'
                return validation_results
            
            # í’ˆì§ˆ ì ìˆ˜ ê²€ì¦
            quality_score = output_data['quality_score']
            if not isinstance(quality_score, torch.Tensor):
                validation_results['quality_score_format'] = 'failed'
                validation_results['error'] = 'í’ˆì§ˆ ì ìˆ˜ê°€ í…ì„œê°€ ì•„ë‹™ë‹ˆë‹¤.'
                return validation_results
            
            if torch.min(quality_score) < 0.0 or torch.max(quality_score) > 1.0:
                validation_results['quality_score_range'] = 'warning'
                validation_results['warning'] = 'í’ˆì§ˆ ì ìˆ˜ê°€ [0, 1] ë²”ìœ„ë¥¼ ë²—ì–´ë‚¬ìŠµë‹ˆë‹¤.'
            
            # ê²€ì¦ ì ìˆ˜ ê²€ì¦
            validation_score = output_data['validation_score']
            if not isinstance(validation_score, torch.Tensor):
                validation_results['validation_score_format'] = 'failed'
                validation_results['error'] = 'ê²€ì¦ ì ìˆ˜ê°€ í…ì„œê°€ ì•„ë‹™ë‹ˆë‹¤.'
                return validation_results
            
            if torch.min(validation_score) < 0.0 or torch.max(validation_score) > 1.0:
                validation_results['validation_score_range'] = 'warning'
                validation_results['warning'] = 'ê²€ì¦ ì ìˆ˜ê°€ [0, 1] ë²”ìœ„ë¥¼ ë²—ì–´ë‚¬ìŠµë‹ˆë‹¤.'
            
            validation_results.update({
                'status': 'success',
                'warped_cloth_shape': warped_cloth.shape,
                'quality_score_shape': quality_score.shape,
                'validation_score_shape': validation_score.shape,
                'quality_score_range': (torch.min(quality_score).item(), torch.max(quality_score).item()),
                'validation_score_range': (torch.min(validation_score).item(), torch.max(validation_score).item())
            })
            
            self.logger.info("ì¶œë ¥ ë°ì´í„° ê²€ì¦ ì™„ë£Œ")
            
        except Exception as e:
            validation_results['status'] = 'error'
            validation_results['error'] = str(e)
            self.logger.error(f"ì¶œë ¥ ë°ì´í„° ê²€ì¦ ì‹¤íŒ¨: {e}")
        
        return validation_results
    
    def calculate_quality_metrics(self, original_cloth: torch.Tensor, 
                                 warped_cloth: torch.Tensor,
                                 target_person: torch.Tensor) -> Dict[str, Any]:
        """í’ˆì§ˆ ë©”íŠ¸ë¦­ì„ ê³„ì‚°í•©ë‹ˆë‹¤."""
        if not self.config.enable_quality_metrics:
            return {'status': 'disabled'}
        
        metrics = {}
        
        try:
            with torch.no_grad():
                # PSNR (Peak Signal-to-Noise Ratio) ê³„ì‚°
                mse = torch.mean((original_cloth - warped_cloth) ** 2)
                if mse > 0:
                    psnr = 20 * torch.log10(1.0 / torch.sqrt(mse))
                    metrics['psnr'] = psnr.item() if hasattr(psnr, 'item') else float(psnr)
                else:
                    metrics['psnr'] = float('inf')
                
                # SSIM (Structural Similarity Index) ê³„ì‚° (ê°„ë‹¨í•œ ë²„ì „)
                def simple_ssim(x, y, window_size=11):
                    # ê°„ë‹¨í•œ SSIM ê³„ì‚°
                    mu_x = torch.mean(x)
                    mu_y = torch.mean(y)
                    sigma_x = torch.std(x)
                    sigma_y = torch.std(y)
                    sigma_xy = torch.mean((x - mu_x) * (y - mu_y))
                    
                    c1 = 0.01 ** 2
                    c2 = 0.03 ** 2
                    
                    ssim = ((2 * mu_x * mu_y + c1) * (2 * sigma_xy + c2)) / \
                           ((mu_x ** 2 + mu_y ** 2 + c1) * (sigma_x ** 2 + sigma_y ** 2 + c2))
                    
                    return ssim
                
                ssim = simple_ssim(original_cloth, warped_cloth)
                metrics['ssim'] = ssim.item() if hasattr(ssim, 'item') else float(ssim)
                
                # LPIPS (Learned Perceptual Image Patch Similarity) ê³„ì‚° (ê°„ë‹¨í•œ ë²„ì „)
                def simple_lpips(x, y):
                    # ê°„ë‹¨í•œ LPIPS ê³„ì‚° (ì‹¤ì œë¡œëŠ” ì‚¬ì „ í›ˆë ¨ëœ ë„¤íŠ¸ì›Œí¬ ì‚¬ìš©)
                    diff = torch.abs(x - y)
                    lpips = torch.mean(diff)
                    return lpips
                
                lpips = simple_lpips(original_cloth, warped_cloth)
                metrics['lpips'] = lpips.item() if hasattr(lpips, 'item') else float(lpips)
                
                # ì›Œí•‘ í’ˆì§ˆ ì ìˆ˜ (ì˜ë¥˜ì™€ ì‚¬ëŒ ì´ë¯¸ì§€ ê°„ì˜ ì¼ê´€ì„±)
                cloth_person_similarity = torch.mean(torch.abs(warped_cloth - target_person))
                metrics['cloth_person_similarity'] = cloth_person_similarity.item() if hasattr(cloth_person_similarity, 'item') else float(cloth_person_similarity)
                
                # ì „ì²´ í’ˆì§ˆ ì ìˆ˜ (ì—¬ëŸ¬ ë©”íŠ¸ë¦­ì˜ ê°€ì¤‘ í‰ê· )
                quality_score = (
                    0.4 * (1.0 / (1.0 + metrics['lpips'])) +  # LPIPS (ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ)
                    0.3 * metrics['ssim'] +                     # SSIM (ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ)
                    0.2 * (metrics['psnr'] / 50.0) +           # PSNR (ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ)
                    0.1 * (1.0 / (1.0 + metrics['cloth_person_similarity']))  # ì¼ê´€ì„±
                )
                metrics['overall_quality_score'] = quality_score.item() if hasattr(quality_score, 'item') else float(quality_score)
                
                metrics['status'] = 'success'
                self.logger.info("í’ˆì§ˆ ë©”íŠ¸ë¦­ ê³„ì‚° ì™„ë£Œ")
                
        except Exception as e:
            metrics['status'] = 'error'
            metrics['error'] = str(e)
            self.logger.error(f"í’ˆì§ˆ ë©”íŠ¸ë¦­ ê³„ì‚° ì‹¤íŒ¨: {e}")
        
        return metrics
    
    def validate_entire_pipeline(self, cloth_image: torch.Tensor,
                                person_image: torch.Tensor,
                                output_data: Dict[str, torch.Tensor]) -> Dict[str, Any]:
        """ì „ì²´ íŒŒì´í”„ë¼ì¸ì„ ê²€ì¦í•©ë‹ˆë‹¤."""
        self.logger.info("ì „ì²´ íŒŒì´í”„ë¼ì¸ ê²€ì¦ ì‹œì‘")
        
        validation_results = {}
        
        # ì…ë ¥ ë°ì´í„° ê²€ì¦
        input_validation = self.validate_input_data(cloth_image, person_image)
        validation_results['input_validation'] = input_validation
        
        # ì¶œë ¥ ë°ì´í„° ê²€ì¦
        output_validation = self.validate_output_data(output_data)
        validation_results['output_validation'] = output_validation
        
        # í’ˆì§ˆ ë©”íŠ¸ë¦­ ê³„ì‚°
        if 'warped_cloth' in output_data:
            quality_metrics = self.calculate_quality_metrics(
                cloth_image, 
                output_data['warped_cloth'], 
                person_image
            )
            validation_results['quality_metrics'] = quality_metrics
        
        # ì „ì²´ ê²€ì¦ ìƒíƒœ ê²°ì •
        all_passed = True
        for validation_type, result in validation_results.items():
            if result.get('status') == 'failed':
                all_passed = False
                break
        
        validation_results['overall_status'] = 'success' if all_passed else 'failed'
        
        self.validation_results = validation_results
        self.logger.info(f"ì „ì²´ íŒŒì´í”„ë¼ì¸ ê²€ì¦ ì™„ë£Œ: {'ì„±ê³µ' if all_passed else 'ì‹¤íŒ¨'}")
        
        return validation_results
    
    def get_validation_results(self) -> Dict[str, Any]:
        """ê²€ì¦ ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
        return self.validation_results
    
    def get_validation_summary(self) -> Dict[str, Any]:
        """ê²€ì¦ ìš”ì•½ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
        if not self.validation_results:
            return {'status': 'no_validation_run'}
        
        summary = {}
        for validation_type, result in self.validation_results.items():
            if isinstance(result, dict):
                summary[validation_type] = result.get('status', 'unknown')
        
        return summary

# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    # ì„¤ì •
    config = ValidationServiceConfig(
        enable_input_validation=True,
        enable_output_validation=True,
        enable_quality_metrics=True,
        min_image_size=(64, 64),
        max_image_size=(4096, 4096),
        use_mps=True
    )
    
    # ê²€ì¦ ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
    validation_service = ClothWarpingValidationService(config)
    
    # í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±
    batch_size = 2
    channels = 3
    height = 256
    width = 256
    
    cloth_image = torch.randn(batch_size, channels, height, width)
    person_image = torch.randn(batch_size, channels, height, width)
    
    # ê°€ìƒì˜ ì¶œë ¥ ë°ì´í„° ìƒì„±
    output_data = {
        'warped_cloth': torch.randn(batch_size, channels, height, width),
        'quality_score': torch.rand(1, 1),
        'validation_score': torch.rand(1, 1)
    }
    
    # ì „ì²´ íŒŒì´í”„ë¼ì¸ ê²€ì¦
    validation_results = validation_service.validate_entire_pipeline(
        cloth_image, person_image, output_data
    )
    
    # ê²°ê³¼ ì¶œë ¥
    print("=== ê²€ì¦ ê²°ê³¼ ===")
    for validation_type, result in validation_results.items():
        print(f"\n{validation_type}:")
        if isinstance(result, dict):
            for key, value in result.items():
                print(f"  {key}: {value}")
    
    # ê²€ì¦ ìš”ì•½
    summary = validation_service.get_validation_summary()
    print(f"\n=== ê²€ì¦ ìš”ì•½ ===")
    print(f"ì „ì²´ ìƒíƒœ: {summary}")
