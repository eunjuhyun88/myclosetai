#!/usr/bin/env python3
"""
ğŸ”¥ MyCloset AI - Cloth Warping Preprocessing
============================================

ğŸ¯ ì˜ë¥˜ ì›Œí•‘ ì „ì²˜ë¦¬ ëª¨ë“ˆ
âœ… ì˜ë¥˜ ì´ë¯¸ì§€ ì •ê·œí™” ë° í‘œì¤€í™”
âœ… ì‚¬ëŒ ì´ë¯¸ì§€ ì „ì²˜ë¦¬
âœ… ì›Œí•‘ ì¤€ë¹„ ë°ì´í„° ìƒì„±
âœ… M3 Max ìµœì í™”
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import logging
from typing import Dict, List, Tuple, Optional, Union, Any
from dataclasses import dataclass
import cv2
from PIL import Image

logger = logging.getLogger(__name__)

@dataclass
class PreprocessingConfig:
    """ì „ì²˜ë¦¬ ì„¤ì •"""
    input_size: Tuple[int, int] = (256, 256)
    output_size: Tuple[int, int] = (256, 256)
    normalize_mean: Tuple[float, float, float] = (0.485, 0.456, 0.406)
    normalize_std: Tuple[float, float, float] = (0.229, 0.224, 0.225)
    enable_cloth_enhancement: bool = True
    enable_person_enhancement: bool = True
    enable_warping_preparation: bool = True
    use_mps: bool = True

class ClothEnhancementNetwork(nn.Module):
    """ì˜ë¥˜ í–¥ìƒ ë„¤íŠ¸ì›Œí¬"""
    
    def __init__(self, input_channels: int = 3):
        super().__init__()
        self.input_channels = input_channels
        
        # ì˜ë¥˜ í–¥ìƒì„ ìœ„í•œ ë„¤íŠ¸ì›Œí¬
        self.enhancement_net = nn.Sequential(
            nn.Conv2d(input_channels, 64, 3, padding=1),
            nn.ReLU(),
            nn.Conv2d(64, 128, 3, padding=1),
            nn.ReLU(),
            nn.Conv2d(128, 64, 3, padding=1),
            nn.ReLU(),
            nn.Conv2d(64, input_channels, 3, padding=1),
            nn.Tanh()
        )
        
    def forward(self, x):
        # ì˜ë¥˜ í–¥ìƒ
        enhanced = self.enhancement_net(x)
        return enhanced

class PersonEnhancementNetwork(nn.Module):
    """ì‚¬ëŒ í–¥ìƒ ë„¤íŠ¸ì›Œí¬"""
    
    def __init__(self, input_channels: int = 3):
        super().__init__()
        self.input_channels = input_channels
        
        # ì‚¬ëŒ í–¥ìƒì„ ìœ„í•œ ë„¤íŠ¸ì›Œí¬
        self.enhancement_net = nn.Sequential(
            nn.Conv2d(input_channels, 64, 3, padding=1),
            nn.ReLU(),
            nn.Conv2d(64, 128, 3, padding=1),
            nn.ReLU(),
            nn.Conv2d(128, 64, 3, padding=1),
            nn.ReLU(),
            nn.Conv2d(64, input_channels, 3, padding=1),
            nn.Tanh()
        )
        
    def forward(self, x):
        # ì‚¬ëŒ í–¥ìƒ
        enhanced = self.enhancement_net(x)
        return enhanced

class WarpingPreparationNetwork(nn.Module):
    """ì›Œí•‘ ì¤€ë¹„ ë„¤íŠ¸ì›Œí¬"""
    
    def __init__(self, input_channels: int = 6):  # 3 for cloth + 3 for person
        super().__init__()
        self.input_channels = input_channels
        
        # ì›Œí•‘ ì¤€ë¹„ë¥¼ ìœ„í•œ ë„¤íŠ¸ì›Œí¬
        self.preparation_net = nn.Sequential(
            nn.Conv2d(input_channels, 64, 3, padding=1),
            nn.ReLU(),
            nn.Conv2d(64, 128, 3, padding=1),
            nn.ReLU(),
            nn.Conv2d(128, 64, 3, padding=1),
            nn.ReLU(),
            nn.Conv2d(64, input_channels, 3, padding=1),
            nn.Tanh()
        )
        
    def forward(self, x):
        # ì›Œí•‘ ì¤€ë¹„
        prepared = self.preparation_net(x)
        return prepared

class ClothWarpingPreprocessor(nn.Module):
    """ì˜ë¥˜ ì›Œí•‘ ì „ì²˜ë¦¬ê¸°"""
    
    def __init__(self, config: PreprocessingConfig = None):
        super().__init__()
        self.config = config or PreprocessingConfig()
        self.logger = logging.getLogger(__name__)
        
        # MPS ë””ë°”ì´ìŠ¤ í™•ì¸
        self.device = torch.device("mps" if torch.backends.mps.is_available() and self.config.use_mps else "cpu")
        self.logger.info(f"ğŸ¯ Cloth Warping ì „ì²˜ë¦¬ê¸° ì´ˆê¸°í™” (ë””ë°”ì´ìŠ¤: {self.device})")
        
        # ì˜ë¥˜ í–¥ìƒ ë„¤íŠ¸ì›Œí¬
        if self.config.enable_cloth_enhancement:
            self.cloth_enhancer = ClothEnhancementNetwork(3).to(self.device)
        
        # ì‚¬ëŒ í–¥ìƒ ë„¤íŠ¸ì›Œí¬
        if self.config.enable_person_enhancement:
            self.person_enhancer = PersonEnhancementNetwork(3).to(self.device)
        
        # ì›Œí•‘ ì¤€ë¹„ ë„¤íŠ¸ì›Œí¬
        if self.config.enable_warping_preparation:
            self.warping_preparer = WarpingPreparationNetwork(6).to(self.device)
        
        # ì´ë¯¸ì§€ ì •ê·œí™”
        self.normalizer = nn.Parameter(
            torch.tensor([self.config.normalize_mean, self.config.normalize_std], dtype=torch.float32), 
            requires_grad=False
        ).to(self.device)
        
        self.logger.info("âœ… Cloth Warping ì „ì²˜ë¦¬ê¸° ì´ˆê¸°í™” ì™„ë£Œ")
    
    def forward(self, cloth_image: torch.Tensor, 
                person_image: torch.Tensor) -> Dict[str, torch.Tensor]:
        """
        ì˜ë¥˜ì™€ ì‚¬ëŒ ì´ë¯¸ì§€ë¥¼ ì „ì²˜ë¦¬í•©ë‹ˆë‹¤.
        
        Args:
            cloth_image: ì˜ë¥˜ ì´ë¯¸ì§€ (B, C, H, W)
            person_image: ì‚¬ëŒ ì´ë¯¸ì§€ (B, C, H, W)
            
        Returns:
            ì „ì²˜ë¦¬ëœ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        batch_size, channels, height, width = cloth_image.shape
        
        # ì…ë ¥ ê²€ì¦
        if channels != 3:
            raise ValueError(f"Expected 3 channels, got {channels}")
        
        # ì˜ë¥˜ í–¥ìƒ
        if self.config.enable_cloth_enhancement:
            enhanced_cloth = self.cloth_enhancer(cloth_image)
            self.logger.debug("ì˜ë¥˜ í–¥ìƒ ì™„ë£Œ")
        else:
            enhanced_cloth = cloth_image
        
        # ì‚¬ëŒ í–¥ìƒ
        if self.config.enable_person_enhancement:
            enhanced_person = self.person_enhancer(person_image)
            self.logger.debug("ì‚¬ëŒ í–¥ìƒ ì™„ë£Œ")
        else:
            enhanced_person = person_image
        
        # ì›Œí•‘ ì¤€ë¹„
        if self.config.enable_warping_preparation:
            combined_input = torch.cat([enhanced_cloth, enhanced_person], dim=1)
            prepared_input = self.warping_preparer(combined_input)
            self.logger.debug("ì›Œí•‘ ì¤€ë¹„ ì™„ë£Œ")
        else:
            prepared_input = torch.cat([enhanced_cloth, enhanced_person], dim=1)
        
        # ëª©í‘œ í•´ìƒë„ë¡œ ë¦¬ì‚¬ì´ì¦ˆ
        if prepared_input.shape[-2:] != self.config.output_size:
            prepared_input = F.interpolate(
                prepared_input, 
                size=self.config.output_size, 
                mode='bilinear', 
                align_corners=False
            )
        
        # ì •ê·œí™” ì ìš©
        mean = self.normalizer[0].view(1, 3, 1, 1)
        std = self.normalizer[1].view(1, 3, 1, 1)
        
        # ì˜ë¥˜ì™€ ì‚¬ëŒ ì´ë¯¸ì§€ ë¶„ë¦¬í•˜ì—¬ ì •ê·œí™”
        cloth_normalized = (enhanced_cloth - mean) / std
        person_normalized = (enhanced_person - mean) / std
        
        # ê²°ê³¼ ë°˜í™˜
        result = {
            'prepared_input': prepared_input,
            'enhanced_cloth': enhanced_cloth,
            'enhanced_person': enhanced_person,
            'cloth_normalized': cloth_normalized,
            'person_normalized': person_normalized,
            'output_size': self.config.output_size,
            'input_size': (height, width)
        }
        
        return result
    
    def process_batch(self, batch_cloth: List[torch.Tensor], 
                     batch_person: List[torch.Tensor]) -> List[Dict[str, torch.Tensor]]:
        """
        ë°°ì¹˜ ë‹¨ìœ„ë¡œ ì „ì²˜ë¦¬ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.
        
        Args:
            batch_cloth: ì˜ë¥˜ ì´ë¯¸ì§€ ë°°ì¹˜ ë¦¬ìŠ¤íŠ¸
            batch_person: ì‚¬ëŒ ì´ë¯¸ì§€ ë°°ì¹˜ ë¦¬ìŠ¤íŠ¸
            
        Returns:
            ì „ì²˜ë¦¬ëœ ê²°ê³¼ ë°°ì¹˜ ë¦¬ìŠ¤íŠ¸
        """
        results = []
        
        for i, (cloth, person) in enumerate(zip(batch_cloth, batch_person)):
            try:
                result = self.forward(cloth, person)
                results.append(result)
                self.logger.debug(f"ë°°ì¹˜ {i} ì „ì²˜ë¦¬ ì™„ë£Œ")
            except Exception as e:
                self.logger.error(f"ë°°ì¹˜ {i} ì „ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                # ì—ëŸ¬ ë°œìƒ ì‹œ ì›ë³¸ ì´ë¯¸ì§€ ë°˜í™˜
                results.append({
                    'prepared_input': torch.cat([cloth, person], dim=1),
                    'enhanced_cloth': cloth,
                    'enhanced_person': person,
                    'cloth_normalized': cloth,
                    'person_normalized': person,
                    'output_size': cloth.shape[-2:],
                    'input_size': cloth.shape[-2:]
                })
        
        return results
    
    def get_preprocessing_stats(self) -> Dict[str, Any]:
        """ì „ì²˜ë¦¬ í†µê³„ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
        return {
            'cloth_enhancement_enabled': self.config.enable_cloth_enhancement,
            'person_enhancement_enabled': self.config.enable_person_enhancement,
            'warping_preparation_enabled': self.config.enable_warping_preparation,
            'input_size': self.config.input_size,
            'output_size': self.config.output_size,
            'device': str(self.device),
            'config': self.config.__dict__
        }

# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    # ì„¤ì •
    config = PreprocessingConfig(
        input_size=(256, 256),
        output_size=(256, 256),
        enable_cloth_enhancement=True,
        enable_person_enhancement=True,
        enable_warping_preparation=True,
        use_mps=True
    )
    
    # ì „ì²˜ë¦¬ê¸° ì´ˆê¸°í™”
    preprocessor = ClothWarpingPreprocessor(config)
    
    # í…ŒìŠ¤íŠ¸ ì…ë ¥
    batch_size = 2
    channels = 3
    height = 256
    width = 256
    
    test_cloth = torch.randn(batch_size, channels, height, width)
    test_person = torch.randn(batch_size, channels, height, width)
    
    # ì „ì²˜ë¦¬ ìˆ˜í–‰
    with torch.no_grad():
        result = preprocessor(test_cloth, test_person)
        
        print("âœ… ì „ì²˜ë¦¬ ì™„ë£Œ!")
        print(f"ì˜ë¥˜ ì´ë¯¸ì§€ í˜•íƒœ: {test_cloth.shape}")
        print(f"ì‚¬ëŒ ì´ë¯¸ì§€ í˜•íƒœ: {test_person.shape}")
        print(f"ì¤€ë¹„ëœ ì…ë ¥ í˜•íƒœ: {result['prepared_input'].shape}")
        print(f"ì¶œë ¥ í¬ê¸°: {result['output_size']}")
        print(f"ì „ì²˜ë¦¬ í†µê³„: {preprocessor.get_preprocessing_stats()}")
