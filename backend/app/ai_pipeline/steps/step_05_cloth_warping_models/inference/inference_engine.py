#!/usr/bin/env python3
"""
ğŸ”¥ MyCloset AI - Cloth Warping Inference Engine
===============================================

ğŸ¯ ì˜ë¥˜ ì›Œí•‘ ì¶”ë¡  ì—”ì§„
âœ… ë‹¤ì¤‘ ëª¨ë¸ ì¶”ë¡  ê´€ë¦¬
âœ… M3 Max ìµœì í™”
âœ… ë©”ëª¨ë¦¬ íš¨ìœ¨ì  ì²˜ë¦¬
âœ… ì‹¤ì‹œê°„ ì›Œí•‘ ì§€ì›
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import logging
from typing import Dict, List, Tuple, Optional, Union, Any
from dataclasses import dataclass
import time
import cv2

# ë¡œê±° ì„¤ì •
logger = logging.getLogger(__name__)

@dataclass
class InferenceConfig:
    """ì¶”ë¡  ì„¤ì •"""
    batch_size: int = 1
    use_mps: bool = True
    memory_efficient: bool = True
    enable_ensemble: bool = True
    confidence_threshold: float = 0.5
    max_models: int = 8
    warp_resolution: Tuple[int, int] = (256, 256)

class ClothWarpingInferenceEngine(nn.Module):
    """
    ğŸ”¥ Cloth Warping ì¶”ë¡  ì—”ì§„
    
    ì˜ë¥˜ ì›Œí•‘ì„ ìœ„í•œ ê³ ì„±ëŠ¥ ì¶”ë¡  ì‹œìŠ¤í…œì…ë‹ˆë‹¤.
    """
    
    def __init__(self, config: InferenceConfig = None):
        super().__init__()
        self.config = config or InferenceConfig()
        self.logger = logging.getLogger(__name__)
        
        # MPS ë””ë°”ì´ìŠ¤ í™•ì¸
        self.device = torch.device("mps" if torch.backends.mps.is_available() and self.config.use_mps else "cpu")
        self.logger.info(f"ğŸ¯ Cloth Warping ì¶”ë¡  ì—”ì§„ ì´ˆê¸°í™” (ë””ë°”ì´ìŠ¤: {self.device})")
        
        # ëª¨ë¸ ì´ˆê¸°í™”
        self.models = {}
        self.model_weights = {}
        self.ensemble_system = None
        
        # ì¶”ë¡  í†µê³„
        self.inference_stats = {
            "total_inferences": 0,
            "total_time": 0.0,
            "avg_time": 0.0,
            "success_rate": 1.0
        }
        
        self.logger.info("âœ… Cloth Warping ì¶”ë¡  ì—”ì§„ ì´ˆê¸°í™” ì™„ë£Œ")
    
    def load_model(self, model_name: str, model_path: str, weight: float = 1.0):
        """ëª¨ë¸ ë¡œë“œ"""
        try:
            # ì‹¤ì œ ëª¨ë¸ ë¡œë“œ ë¡œì§ (ì—¬ê¸°ì„œëŠ” ë”ë¯¸ ëª¨ë¸ ìƒì„±)
            model = self._create_dummy_model(model_name)
            model.to(self.device)
            model.eval()
            
            self.models[model_name] = model
            self.model_weights[model_name] = weight
            
            self.logger.info(f"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {model_name} (ê°€ì¤‘ì¹˜: {weight})")
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {model_name} - {str(e)}")
            return False
    
    def _create_dummy_model(self, model_name: str) -> nn.Module:
        """ë”ë¯¸ ëª¨ë¸ ìƒì„± (ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ì‹¤ì œ ëª¨ë¸ ë¡œë“œ)"""
        class DummyClothWarpingModel(nn.Module):
            def __init__(self, name: str):
                super().__init__()
                self.name = name
                # ê°„ë‹¨í•œ CNN ê¸°ë°˜ ì›Œí•‘ ëª¨ë¸
                self.feature_extractor = nn.Sequential(
                    nn.Conv2d(6, 64, 3, padding=1),  # 3ì±„ë„ ì˜ë¥˜ + 3ì±„ë„ íƒ€ê²Ÿ
                    nn.ReLU(),
                    nn.Conv2d(64, 128, 3, padding=1),
                    nn.ReLU(),
                    nn.Conv2d(128, 256, 3, padding=1),
                    nn.ReLU()
                )
                
                self.warping_head = nn.Sequential(
                    nn.Conv2d(256, 128, 3, padding=1),
                    nn.ReLU(),
                    nn.Conv2d(128, 64, 3, padding=1),
                    nn.ReLU(),
                    nn.Conv2d(64, 2, 1),  # 2ì±„ë„ (x, y ë³€ìœ„)
                    nn.Tanh()  # -1 ~ 1 ë²”ìœ„
                )
            
            def forward(self, cloth_image, target_image):
                # ì˜ë¥˜ì™€ íƒ€ê²Ÿ ì´ë¯¸ì§€ ê²°í•©
                combined_input = torch.cat([cloth_image, target_image], dim=1)
                features = self.feature_extractor(combined_input)
                warping_field = self.warping_head(features)
                return warping_field
        
        return DummyClothWarpingModel(model_name)
    
    def set_ensemble_system(self, ensemble_system):
        """ì•™ìƒë¸” ì‹œìŠ¤í…œ ì„¤ì •"""
        self.ensemble_system = ensemble_system
        self.logger.info("âœ… ì•™ìƒë¸” ì‹œìŠ¤í…œ ì„¤ì • ì™„ë£Œ")
    
    def forward(self, cloth_image: torch.Tensor, target_image: torch.Tensor, 
                pose_keypoints: Optional[torch.Tensor] = None,
                body_shape: Optional[torch.Tensor] = None) -> Dict[str, torch.Tensor]:
        """
        ì¶”ë¡  ìˆ˜í–‰
        
        Args:
            cloth_image: ì˜ë¥˜ ì´ë¯¸ì§€ (B, C, H, W)
            target_image: íƒ€ê²Ÿ ì´ë¯¸ì§€ (B, C, H, W)
            pose_keypoints: í¬ì¦ˆ í‚¤í¬ì¸íŠ¸ (B, N, 2)
            body_shape: ì‹ ì²´ í˜•íƒœ ì •ë³´ (B, M)
        
        Returns:
            ì›Œí•‘ ê²°ê³¼
        """
        start_time = time.time()
        
        try:
            # ì…ë ¥ ê²€ì¦
            if not self._validate_inputs(cloth_image, target_image):
                raise ValueError("ì…ë ¥ ê²€ì¦ ì‹¤íŒ¨")
            
            # ë””ë°”ì´ìŠ¤ ì´ë™
            cloth_image = cloth_image.to(self.device)
            target_image = target_image.to(self.device)
            if pose_keypoints is not None:
                pose_keypoints = pose_keypoints.to(self.device)
            if body_shape is not None:
                body_shape = body_shape.to(self.device)
            
            # ê°œë³„ ëª¨ë¸ ì¶”ë¡ 
            model_outputs = []
            model_confidences = []
            
            for model_name, model in self.models.items():
                try:
                    with torch.no_grad():
                        # ëª¨ë¸ë³„ ì¶”ë¡ 
                        output = self._inference_single_model(model, cloth_image, target_image, pose_keypoints, body_shape)
                        confidence = self._calculate_confidence(output)
                        
                        model_outputs.append(output)
                        model_confidences.append(confidence)
                        
                except Exception as e:
                    self.logger.warning(f"ëª¨ë¸ {model_name} ì¶”ë¡  ì‹¤íŒ¨: {str(e)}")
                    continue
            
            if not model_outputs:
                raise RuntimeError("ëª¨ë“  ëª¨ë¸ ì¶”ë¡  ì‹¤íŒ¨")
            
            # ì•™ìƒë¸” ì¶”ë¡ 
            if self.ensemble_system and len(model_outputs) > 1:
                ensemble_output = self.ensemble_system(model_outputs, model_confidences)
            else:
                ensemble_output = model_outputs[0] if model_outputs else torch.zeros_like(cloth_image[:, :2, :, :])
            
            # í›„ì²˜ë¦¬
            final_output = self._postprocess_output(ensemble_output, cloth_image, target_image)
            
            # ì›Œí•‘ëœ ì˜ë¥˜ ìƒì„±
            warped_cloth = self._apply_warping(cloth_image, final_output)
            
            # ì¶”ë¡  í†µê³„ ì—…ë°ì´íŠ¸
            inference_time = time.time() - start_time
            self._update_inference_stats(inference_time, True)
            
            # ê²°ê³¼ ë°˜í™˜
            result = {
                "warping_field": final_output,
                "warped_cloth": warped_cloth,
                "model_outputs": model_outputs,
                "model_confidences": model_confidences,
                "ensemble_output": ensemble_output,
                "inference_time": inference_time,
                "success": True
            }
            
            self.logger.debug(f"âœ… ì›Œí•‘ ì¶”ë¡  ì™„ë£Œ - ì‹œê°„: {inference_time:.3f}ì´ˆ")
            return result
            
        except Exception as e:
            # ì¶”ë¡  ì‹¤íŒ¨ ì²˜ë¦¬
            inference_time = time.time() - start_time
            self._update_inference_stats(inference_time, False)
            
            self.logger.error(f"âŒ ì›Œí•‘ ì¶”ë¡  ì‹¤íŒ¨: {str(e)}")
            
            # ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ê°’ ë°˜í™˜
            return {
                "warping_field": torch.zeros_like(cloth_image[:, :2, :, :]),
                "warped_cloth": cloth_image,
                "model_outputs": [],
                "model_confidences": [],
                "ensemble_output": torch.zeros_like(cloth_image[:, :2, :, :]),
                "inference_time": inference_time,
                "success": False,
                "error": str(e)
            }
    
    def _validate_inputs(self, cloth_image: torch.Tensor, target_image: torch.Tensor) -> bool:
        """ì…ë ¥ ê²€ì¦"""
        if cloth_image.dim() != 4 or target_image.dim() != 4:
            return False
        
        if cloth_image.size(0) != target_image.size(0):
            return False
        
        if cloth_image.size(2) != target_image.size(2) or cloth_image.size(3) != target_image.size(3):
            return False
        
        return True
    
    def _inference_single_model(self, model: nn.Module, cloth_image: torch.Tensor, 
                               target_image: torch.Tensor, pose_keypoints: Optional[torch.Tensor],
                               body_shape: Optional[torch.Tensor]) -> torch.Tensor:
        """ë‹¨ì¼ ëª¨ë¸ ì¶”ë¡ """
        # ì´ë¯¸ì§€ ì „ì²˜ë¦¬
        processed_cloth = self._preprocess_image(cloth_image)
        processed_target = self._preprocess_image(target_image)
        
        # ëª¨ë¸ ì¶”ë¡ 
        if pose_keypoints is not None and body_shape is not None:
            # í¬ì¦ˆì™€ ì‹ ì²´ í˜•íƒœ ì •ë³´ê°€ ìˆëŠ” ê²½ìš°
            output = model(processed_cloth, processed_target, pose_keypoints, body_shape)
        else:
            # ê¸°ë³¸ ì›Œí•‘
            output = model(processed_cloth, processed_target)
        
        return output
    
    def _preprocess_image(self, image: torch.Tensor) -> torch.Tensor:
        """ì´ë¯¸ì§€ ì „ì²˜ë¦¬"""
        # ì •ê·œí™” (0-1 ë²”ìœ„)
        if image.max() > 1.0:
            image = image / 255.0
        
        # í¬ê¸° ì¡°ì • (í•„ìš”í•œ ê²½ìš°)
        target_size = self.config.warp_resolution
        if image.size(2) != target_size[0] or image.size(3) != target_size[1]:
            image = F.interpolate(image, size=target_size, mode='bilinear', align_corners=False)
        
        return image
    
    def _calculate_confidence(self, output: torch.Tensor) -> float:
        """ì¶œë ¥ ì‹ ë¢°ë„ ê³„ì‚°"""
        if output.numel() == 0:
            return 0.0
        
        # ì›Œí•‘ í•„ë“œì˜ í’ˆì§ˆ ê¸°ë°˜ ì‹ ë¢°ë„ ê³„ì‚°
        # ë³€ìœ„ì˜ í¬ê¸°ê°€ ì ì ˆí•œì§€ í™•ì¸
        displacement_magnitude = torch.sqrt(output[:, 0:1]**2 + output[:, 1:2]**2)
        avg_displacement = float(displacement_magnitude.mean().item())
        
        # ì ì ˆí•œ ë³€ìœ„ ë²”ìœ„ (0.1 ~ 0.5)ì—ì„œ ë†’ì€ ì‹ ë¢°ë„
        if 0.1 <= avg_displacement <= 0.5:
            confidence = 0.9
        elif 0.05 <= avg_displacement <= 0.8:
            confidence = 0.7
        else:
            confidence = 0.3
        
        return confidence
    
    def _postprocess_output(self, output: torch.Tensor, cloth_image: torch.Tensor, 
                           target_image: torch.Tensor) -> torch.Tensor:
        """ì¶œë ¥ í›„ì²˜ë¦¬"""
        # ì¶œë ¥ í¬ê¸°ë¥¼ ì›ë³¸ ì´ë¯¸ì§€ í¬ê¸°ë¡œ ì¡°ì •
        if output.size(2) != cloth_image.size(2) or output.size(3) != cloth_image.size(3):
            output = F.interpolate(output, size=(cloth_image.size(2), cloth_image.size(3)), 
                                 mode='bilinear', align_corners=False)
        
        # ì›Œí•‘ í•„ë“œ ìŠ¤ë¬´ë”©
        output = self._smooth_warping_field(output)
        
        # ì‹ ë¢°ë„ ì„ê³„ê°’ ì ìš©
        if self.config.confidence_threshold > 0:
            confidence_mask = self._calculate_warping_confidence(output) > self.config.confidence_threshold
            output = output * confidence_mask.float()
        
        return output
    
    def _smooth_warping_field(self, warping_field: torch.Tensor) -> torch.Tensor:
        """ì›Œí•‘ í•„ë“œ ìŠ¤ë¬´ë”©"""
        # ê°€ìš°ì‹œì•ˆ ìŠ¤ë¬´ë”© ì ìš©
        smoothed_field = warping_field.clone()
        
        for b in range(warping_field.size(0)):
            for c in range(warping_field.size(1)):
                channel = warping_field[b, c]
                if channel.numel() > 0:
                    smoothed_field[b, c] = self._gaussian_smooth_2d(channel)
        
        return smoothed_field
    
    def _gaussian_smooth_2d(self, channel: torch.Tensor) -> torch.Tensor:
        """2D ê°€ìš°ì‹œì•ˆ ìŠ¤ë¬´ë”©"""
        if channel.dim() != 2:
            return channel
        
        # ê°€ìš°ì‹œì•ˆ ì»¤ë„ ìƒì„±
        kernel_size = 3
        sigma = 0.5
        
        # 1D ê°€ìš°ì‹œì•ˆ ì»¤ë„
        x = torch.arange(-kernel_size // 2, kernel_size // 2 + 1, device=channel.device)
        gaussian_1d = torch.exp(-(x ** 2) / (2 * sigma ** 2))
        gaussian_1d = gaussian_1d / gaussian_1d.sum()
        
        # 2D ê°€ìš°ì‹œì•ˆ ì»¤ë„
        gaussian_2d = gaussian_1d.unsqueeze(0) * gaussian_1d.unsqueeze(1)
        
        # íŒ¨ë”© ì¶”ê°€
        padded_channel = F.pad(channel.unsqueeze(0).unsqueeze(0), 
                              (kernel_size // 2, kernel_size // 2, kernel_size // 2, kernel_size // 2), 
                              mode='reflect')
        
        # ì»¨ë³¼ë£¨ì…˜ ì ìš©
        smoothed_channel = F.conv2d(padded_channel, gaussian_2d.unsqueeze(0).unsqueeze(0))
        
        return smoothed_channel.squeeze()
    
    def _calculate_warping_confidence(self, warping_field: torch.Tensor) -> torch.Tensor:
        """ì›Œí•‘ ì‹ ë¢°ë„ ê³„ì‚°"""
        # ë³€ìœ„ì˜ í¬ê¸°ì™€ ë°©í–¥ ì¼ê´€ì„± ê¸°ë°˜ ì‹ ë¢°ë„
        displacement_magnitude = torch.sqrt(warping_field[:, 0:1]**2 + warping_field[:, 1:2]**2)
        
        # ì ì ˆí•œ ë³€ìœ„ ë²”ìœ„ì—ì„œ ë†’ì€ ì‹ ë¢°ë„
        confidence = torch.ones_like(displacement_magnitude)
        
        # ë„ˆë¬´ í° ë³€ìœ„ëŠ” ë‚®ì€ ì‹ ë¢°ë„
        confidence[displacement_magnitude > 0.8] = 0.3
        confidence[displacement_magnitude > 0.5] = 0.6
        
        # ë„ˆë¬´ ì‘ì€ ë³€ìœ„ë„ ë‚®ì€ ì‹ ë¢°ë„
        confidence[displacement_magnitude < 0.05] = 0.4
        
        return confidence
    
    def _apply_warping(self, cloth_image: torch.Tensor, warping_field: torch.Tensor) -> torch.Tensor:
        """ì›Œí•‘ ì ìš©"""
        batch_size, channels, height, width = cloth_image.shape
        
        # ê·¸ë¦¬ë“œ ìƒì„±
        grid_y, grid_x = torch.meshgrid(
            torch.linspace(-1, 1, height, device=self.device),
            torch.linspace(-1, 1, width, device=self.device),
            indexing='ij'
        )
        
        # ì›Œí•‘ í•„ë“œ ì ìš©
        warped_grid_x = grid_x + warping_field[:, 0] * 0.5  # -1 ~ 1 ë²”ìœ„ë¡œ ì œí•œ
        warped_grid_y = grid_y + warping_field[:, 1] * 0.5
        
        # ê·¸ë¦¬ë“œ ì •ê·œí™”
        warped_grid_x = torch.clamp(warped_grid_x, -1, 1)
        warped_grid_y = torch.clamp(warped_grid_y, -1, 1)
        
        # ê·¸ë¦¬ë“œ ê²°í•©
        warped_grid = torch.stack([warped_grid_x, warped_grid_y], dim=-1)
        
        # ì›Œí•‘ ì ìš©
        warped_cloth = F.grid_sample(cloth_image, warped_grid, mode='bilinear', 
                                    padding_mode='border', align_corners=False)
        
        return warped_cloth
    
    def _update_inference_stats(self, inference_time: float, success: bool):
        """ì¶”ë¡  í†µê³„ ì—…ë°ì´íŠ¸"""
        self.inference_stats["total_inferences"] += 1
        self.inference_stats["total_time"] += inference_time
        self.inference_stats["avg_time"] = self.inference_stats["total_time"] / self.inference_stats["total_inferences"]
        
        if not success:
            failed_count = int((1 - self.inference_stats["success_rate"]) * self.inference_stats["total_inferences"])
            self.inference_stats["success_rate"] = (self.inference_stats["total_inferences"] - failed_count - 1) / self.inference_stats["total_inferences"]
    
    def get_inference_stats(self) -> Dict[str, Any]:
        """ì¶”ë¡  í†µê³„ ë°˜í™˜"""
        return self.inference_stats.copy()
    
    def get_model_info(self) -> Dict[str, Any]:
        """ëª¨ë¸ ì •ë³´ ë°˜í™˜"""
        model_info = {}
        for model_name, model in self.models.items():
            model_info[model_name] = {
                "weight": self.model_weights.get(model_name, 1.0),
                "parameters": sum(p.numel() for p in model.parameters()),
                "device": str(next(model.parameters()).device)
            }
        return model_info
    
    def clear_cache(self):
        """ìºì‹œ ì •ë¦¬"""
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
        self.logger.info("âœ… ìºì‹œ ì •ë¦¬ ì™„ë£Œ")

# ì¶”ë¡  ì—”ì§„ ì¸ìŠ¤í„´ìŠ¤ ìƒì„± í•¨ìˆ˜
def create_cloth_warping_inference_engine(config: InferenceConfig = None) -> ClothWarpingInferenceEngine:
    """Cloth Warping ì¶”ë¡  ì—”ì§„ ìƒì„±"""
    return ClothWarpingInferenceEngine(config)

# ê¸°ë³¸ ì„¤ì •ìœ¼ë¡œ ì¶”ë¡  ì—”ì§„ ìƒì„±
def create_default_inference_engine() -> ClothWarpingInferenceEngine:
    """ê¸°ë³¸ ì„¤ì •ìœ¼ë¡œ ì¶”ë¡  ì—”ì§„ ìƒì„±"""
    config = InferenceConfig(
        batch_size=1,
        use_mps=True,
        memory_efficient=True,
        enable_ensemble=True,
        confidence_threshold=0.5,
        max_models=8,
        warp_resolution=(256, 256)
    )
    return ClothWarpingInferenceEngine(config)

if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì½”ë“œ
    logging.basicConfig(level=logging.INFO)
    
    # ì¶”ë¡  ì—”ì§„ ìƒì„±
    engine = create_default_inference_engine()
    
    # ë”ë¯¸ ëª¨ë¸ ë¡œë“œ
    engine.load_model("warping_model_1", "dummy_path_1", 1.0)
    engine.load_model("warping_model_2", "dummy_path_2", 0.8)
    
    # í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±
    batch_size, channels, height, width = 2, 3, 256, 256
    test_cloth = torch.randn(batch_size, channels, height, width)
    test_target = torch.randn(batch_size, channels, height, width)
    
    # ì¶”ë¡  ìˆ˜í–‰
    result = engine(test_cloth, test_target)
    print(f"ì›Œí•‘ ì¶”ë¡  ê²°ê³¼: {result['success']}")
    print(f"ì¶”ë¡  ì‹œê°„: {result['inference_time']:.3f}ì´ˆ")
    print(f"ì›Œí•‘ëœ ì˜ë¥˜ í˜•íƒœ: {result['warped_cloth'].shape}")
    print(f"ëª¨ë¸ ì •ë³´: {engine.get_model_info()}")
    print(f"ì¶”ë¡  í†µê³„: {engine.get_inference_stats()}")
