#!/usr/bin/env python3
"""
üî• MyCloset AI - Cloth Warping Inference Engine
===============================================

üéØ ÏùòÎ•ò ÏõåÌïë Ï∂îÎ°† ÏóîÏßÑ
‚úÖ Îã§Ï§ë Î™®Îç∏ Ï∂îÎ°† Í¥ÄÎ¶¨
‚úÖ M3 Max ÏµúÏ†ÅÌôî
‚úÖ Î©îÎ™®Î¶¨ Ìö®Ïú®Ï†Å Ï≤òÎ¶¨
‚úÖ Ïã§ÏãúÍ∞Ñ ÏõåÌïë ÏßÄÏõê
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import logging
from typing import Dict, List, Tuple, Optional, Union, Any
from dataclasses import dataclass
import time
import cv2

# Î°úÍ±∞ ÏÑ§Ï†ï
logger = logging.getLogger(__name__)

@dataclass
class InferenceConfig:
    """Ï∂îÎ°† ÏÑ§Ï†ï"""
    batch_size: int = 1
    use_mps: bool = True
    memory_efficient: bool = True
    enable_ensemble: bool = True
    confidence_threshold: float = 0.5
    max_models: int = 8
    warp_resolution: Tuple[int, int] = (256, 256)

class ClothWarpingInferenceEngine(nn.Module):
    """
    üî• Cloth Warping Ï∂îÎ°† ÏóîÏßÑ
    
    ÏùòÎ•ò ÏõåÌïëÏùÑ ÏúÑÌïú Í≥†ÏÑ±Îä• Ï∂îÎ°† ÏãúÏä§ÌÖúÏûÖÎãàÎã§.
    """
    
    def __init__(self, config: InferenceConfig = None):
        super().__init__()
        self.config = config or InferenceConfig()
        self.logger = logging.getLogger(__name__)
        
        # MPS ÎîîÎ∞îÏù¥Ïä§ ÌôïÏù∏
        self.device = torch.device("mps" if torch.backends.mps.is_available() and self.config.use_mps else "cpu")
        self.logger.info(f"üéØ Cloth Warping Ï∂îÎ°† ÏóîÏßÑ Ï¥àÍ∏∞Ìôî (ÎîîÎ∞îÏù¥Ïä§: {self.device})")
        
        # Î™®Îç∏ Ï¥àÍ∏∞Ìôî
        self.models = {}
        self.model_weights = {}
        self.ensemble_system = None
        
        # Ï∂îÎ°† ÌÜµÍ≥Ñ
        self.inference_stats = {
            "total_inferences": 0,
            "total_time": 0.0,
            "avg_time": 0.0,
            "success_rate": 1.0
        }
        
        self.logger.info("‚úÖ Cloth Warping Ï∂îÎ°† ÏóîÏßÑ Ï¥àÍ∏∞Ìôî ÏôÑÎ£å")
    
    def load_model(self, model_name: str, model_path: str, weight: float = 1.0):
        """Î™®Îç∏ Î°úÎìú"""
        try:
            # Ïã§Ï†ú Î™®Îç∏ Î°úÎìú Î°úÏßÅ (Ïó¨Í∏∞ÏÑúÎäî ÎçîÎØ∏ Î™®Îç∏ ÏÉùÏÑ±)
            model = self._create_dummy_model(model_name)
            model.to(self.device)
            model.eval()
            
            self.models[model_name] = model
            self.model_weights[model_name] = weight
            
            self.logger.info(f"‚úÖ Î™®Îç∏ Î°úÎìú ÏôÑÎ£å: {model_name} (Í∞ÄÏ§ëÏπò: {weight})")
            return True
            
        except Exception as e:
            self.logger.error(f"‚ùå Î™®Îç∏ Î°úÎìú Ïã§Ìå®: {model_name} - {str(e)}")
            return False
    
    def _create_dummy_model(self, model_name: str) -> nn.Module:
        """ÎçîÎØ∏ Î™®Îç∏ ÏÉùÏÑ± (Ïã§Ï†ú Íµ¨ÌòÑÏóêÏÑúÎäî Ïã§Ï†ú Î™®Îç∏ Î°úÎìú)"""
        class DummyClothWarpingModel(nn.Module):
            def __init__(self, name: str):
                super().__init__()
                self.name = name
                # Í∞ÑÎã®Ìïú CNN Í∏∞Î∞ò ÏõåÌïë Î™®Îç∏
                self.feature_extractor = nn.Sequential(
                    nn.Conv2d(6, 64, 3, padding=1),  # 3Ï±ÑÎÑê ÏùòÎ•ò + 3Ï±ÑÎÑê ÌÉÄÍ≤ü
                    nn.ReLU(),
                    nn.Conv2d(64, 128, 3, padding=1),
                    nn.ReLU(),
                    nn.Conv2d(128, 256, 3, padding=1),
                    nn.ReLU()
                )
                
                self.warping_head = nn.Sequential(
                    nn.Conv2d(256, 128, 3, padding=1),
                    nn.ReLU(),
                    nn.Conv2d(128, 64, 3, padding=1),
                    nn.ReLU(),
                    nn.Conv2d(64, 2, 1),  # 2Ï±ÑÎÑê (x, y Î≥ÄÏúÑ)
                    nn.Tanh()  # -1 ~ 1 Î≤îÏúÑ
                )
            
            def forward(self, cloth_image, target_image):
                # ÏùòÎ•òÏôÄ ÌÉÄÍ≤ü Ïù¥ÎØ∏ÏßÄ Í≤∞Ìï©
                combined_input = torch.cat([cloth_image, target_image], dim=1)
                features = self.feature_extractor(combined_input)
                warping_field = self.warping_head(features)
                return warping_field
        
        return DummyClothWarpingModel(model_name)
    
    def set_ensemble_system(self, ensemble_system):
        """ÏïôÏÉÅÎ∏î ÏãúÏä§ÌÖú ÏÑ§Ï†ï"""
        self.ensemble_system = ensemble_system
        self.logger.info("‚úÖ ÏïôÏÉÅÎ∏î ÏãúÏä§ÌÖú ÏÑ§Ï†ï ÏôÑÎ£å")
    
    def forward(self, cloth_image: torch.Tensor, target_image: torch.Tensor, 
                pose_keypoints: Optional[torch.Tensor] = None,
                body_shape: Optional[torch.Tensor] = None) -> Dict[str, torch.Tensor]:
        """
        Ï∂îÎ°† ÏàòÌñâ
        
        Args:
            cloth_image: ÏùòÎ•ò Ïù¥ÎØ∏ÏßÄ (B, C, H, W)
            target_image: ÌÉÄÍ≤ü Ïù¥ÎØ∏ÏßÄ (B, C, H, W)
            pose_keypoints: Ìè¨Ï¶à ÌÇ§Ìè¨Ïù∏Ìä∏ (B, N, 2)
            body_shape: Ïã†Ï≤¥ ÌòïÌÉú Ï†ïÎ≥¥ (B, M)
        
        Returns:
            ÏõåÌïë Í≤∞Í≥º
        """
        start_time = time.time()
        
        try:
            # ÏûÖÎ†• Í≤ÄÏ¶ù
            if not self._validate_inputs(cloth_image, target_image):
                raise ValueError("ÏûÖÎ†• Í≤ÄÏ¶ù Ïã§Ìå®")
            
            # ÎîîÎ∞îÏù¥Ïä§ Ïù¥Îèô
            cloth_image = cloth_image.to(self.device)
            target_image = target_image.to(self.device)
            if pose_keypoints is not None:
                pose_keypoints = pose_keypoints.to(self.device)
            if body_shape is not None:
                body_shape = body_shape.to(self.device)
            
            # Í∞úÎ≥Ñ Î™®Îç∏ Ï∂îÎ°†
            model_outputs = []
            model_confidences = []
            
            for model_name, model in self.models.items():
                try:
                    with torch.no_grad():
                        # Î™®Îç∏Î≥Ñ Ï∂îÎ°†
                        output = self._inference_single_model(model, cloth_image, target_image, pose_keypoints, body_shape)
                        confidence = self._calculate_confidence(output)
                        
                        model_outputs.append(output)
                        model_confidences.append(confidence)
                        
                except Exception as e:
                    self.logger.warning(f"Î™®Îç∏ {model_name} Ï∂îÎ°† Ïã§Ìå®: {str(e)}")
                    continue
            
            if not model_outputs:
                raise RuntimeError("Î™®Îì† Î™®Îç∏ Ï∂îÎ°† Ïã§Ìå®")
            
            # ÏïôÏÉÅÎ∏î Ï∂îÎ°†
            if self.ensemble_system and len(model_outputs) > 1:
                ensemble_output = self.ensemble_system(model_outputs, model_confidences)
            else:
                ensemble_output = model_outputs[0] if model_outputs else torch.zeros_like(cloth_image[:, :2, :, :])
            
            # ÌõÑÏ≤òÎ¶¨
            final_output = self._postprocess_output(ensemble_output, cloth_image, target_image)
            
            # ÏõåÌïëÎêú ÏùòÎ•ò ÏÉùÏÑ±
            warped_cloth = self._apply_warping(cloth_image, final_output)
            
            # Ï∂îÎ°† ÌÜµÍ≥Ñ ÏóÖÎç∞Ïù¥Ìä∏
            inference_time = time.time() - start_time
            self._update_inference_stats(inference_time, True)
            
            # Í≤∞Í≥º Î∞òÌôò
            result = {
                "warping_field": final_output,
                "warped_cloth": warped_cloth,
                "model_outputs": model_outputs,
                "model_confidences": model_confidences,
                "ensemble_output": ensemble_output,
                "inference_time": inference_time,
                "success": True
            }
            
            self.logger.debug(f"‚úÖ ÏõåÌïë Ï∂îÎ°† ÏôÑÎ£å - ÏãúÍ∞Ñ: {inference_time:.3f}Ï¥à")
            return result
            
        except Exception as e:
            # Ï∂îÎ°† Ïã§Ìå® Ï≤òÎ¶¨
            inference_time = time.time() - start_time
            self._update_inference_stats(inference_time, False)
            
            self.logger.error(f"‚ùå ÏõåÌïë Ï∂îÎ°† Ïã§Ìå®: {str(e)}")
            
            # Ïã§Ìå® Ïãú Í∏∞Î≥∏Í∞í Î∞òÌôò
            return {
                "warping_field": torch.zeros_like(cloth_image[:, :2, :, :]),
                "warped_cloth": cloth_image,
                "model_outputs": [],
                "model_confidences": [],
                "ensemble_output": torch.zeros_like(cloth_image[:, :2, :, :]),
                "inference_time": inference_time,
                "success": False,
                "error": str(e)
            }
    
    def _validate_inputs(self, cloth_image: torch.Tensor, target_image: torch.Tensor) -> bool:
        """ÏûÖÎ†• Í≤ÄÏ¶ù"""
        if cloth_image.dim() != 4 or target_image.dim() != 4:
            return False
        
        if cloth_image.size(0) != target_image.size(0):
            return False
        
        if cloth_image.size(2) != target_image.size(2) or cloth_image.size(3) != target_image.size(3):
            return False
        
        return True
    
    def _inference_single_model(self, model: nn.Module, cloth_image: torch.Tensor, 
                               target_image: torch.Tensor, pose_keypoints: Optional[torch.Tensor],
                               body_shape: Optional[torch.Tensor]) -> torch.Tensor:
        """Îã®Ïùº Î™®Îç∏ Ï∂îÎ°†"""
        # Ïù¥ÎØ∏ÏßÄ Ï†ÑÏ≤òÎ¶¨
        processed_cloth = self._preprocess_image(cloth_image)
        processed_target = self._preprocess_image(target_image)
        
        # Î™®Îç∏ Ï∂îÎ°†
        if pose_keypoints is not None and body_shape is not None:
            # Ìè¨Ï¶àÏôÄ Ïã†Ï≤¥ ÌòïÌÉú Ï†ïÎ≥¥Í∞Ä ÏûàÎäî Í≤ΩÏö∞
            output = model(processed_cloth, processed_target, pose_keypoints, body_shape)
        else:
            # Í∏∞Î≥∏ ÏõåÌïë
            output = model(processed_cloth, processed_target)
        
        return output
    
    def _preprocess_image(self, image: torch.Tensor) -> torch.Tensor:
        """Ïù¥ÎØ∏ÏßÄ Ï†ÑÏ≤òÎ¶¨"""
        # Ï†ïÍ∑úÌôî (0-1 Î≤îÏúÑ)
        if image.max() > 1.0:
            image = image / 255.0
        
        # ÌÅ¨Í∏∞ Ï°∞Ï†ï (ÌïÑÏöîÌïú Í≤ΩÏö∞)
        target_size = self.config.warp_resolution
        if image.size(2) != target_size[0] or image.size(3) != target_size[1]:
            image = F.interpolate(image, size=target_size, mode='bilinear', align_corners=False)
        
        return image
    
    def _calculate_confidence(self, output: torch.Tensor) -> float:
        """Ï∂úÎ†• Ïã†Î¢∞ÎèÑ Í≥ÑÏÇ∞"""
        if output.numel() == 0:
            return 0.0
        
        # ÏõåÌïë ÌïÑÎìúÏùò ÌíàÏßà Í∏∞Î∞ò Ïã†Î¢∞ÎèÑ Í≥ÑÏÇ∞
        # Î≥ÄÏúÑÏùò ÌÅ¨Í∏∞Í∞Ä Ï†ÅÏ†àÌïúÏßÄ ÌôïÏù∏
        displacement_magnitude = torch.sqrt(output[:, 0:1]**2 + output[:, 1:2]**2)
        avg_displacement = float(displacement_magnitude.mean().item())
        
        # Ï†ÅÏ†àÌïú Î≥ÄÏúÑ Î≤îÏúÑ (0.1 ~ 0.5)ÏóêÏÑú ÎÜíÏùÄ Ïã†Î¢∞ÎèÑ
        if 0.1 <= avg_displacement <= 0.5:
            confidence = 0.9
        elif 0.05 <= avg_displacement <= 0.8:
            confidence = 0.7
        else:
            confidence = 0.3
        
        return confidence
    
    def _postprocess_output(self, output: torch.Tensor, cloth_image: torch.Tensor, 
                           target_image: torch.Tensor) -> torch.Tensor:
        """Ï∂úÎ†• ÌõÑÏ≤òÎ¶¨"""
        # Ï∂úÎ†• ÌÅ¨Í∏∞Î•º ÏõêÎ≥∏ Ïù¥ÎØ∏ÏßÄ ÌÅ¨Í∏∞Î°ú Ï°∞Ï†ï
        if output.size(2) != cloth_image.size(2) or output.size(3) != cloth_image.size(3):
            output = F.interpolate(output, size=(cloth_image.size(2), cloth_image.size(3)), 
                                 mode='bilinear', align_corners=False)
        
        # ÏõåÌïë ÌïÑÎìú Ïä§Î¨¥Îî©
        output = self._smooth_warping_field(output)
        
        # Ïã†Î¢∞ÎèÑ ÏûÑÍ≥ÑÍ∞í Ï†ÅÏö©
        if self.config.confidence_threshold > 0:
            confidence_mask = self._calculate_warping_confidence(output) > self.config.confidence_threshold
            output = output * confidence_mask.float()
        
        return output
    
    def _smooth_warping_field(self, warping_field: torch.Tensor) -> torch.Tensor:
        """ÏõåÌïë ÌïÑÎìú Ïä§Î¨¥Îî©"""
        # Í∞ÄÏö∞ÏãúÏïà Ïä§Î¨¥Îî© Ï†ÅÏö©
        smoothed_field = warping_field.clone()
        
        for b in range(warping_field.size(0)):
            for c in range(warping_field.size(1)):
                channel = warping_field[b, c]
                if channel.numel() > 0:
                    smoothed_field[b, c] = self._gaussian_smooth_2d(channel)
        
        return smoothed_field
    
    def _gaussian_smooth_2d(self, channel: torch.Tensor) -> torch.Tensor:
        """2D Í∞ÄÏö∞ÏãúÏïà Ïä§Î¨¥Îî©"""
        if channel.dim() != 2:
            return channel
        
        # Í∞ÄÏö∞ÏãúÏïà Ïª§ÎÑê ÏÉùÏÑ±
        kernel_size = 3
        sigma = 0.5
        
        # 1D Í∞ÄÏö∞ÏãúÏïà Ïª§ÎÑê
        x = torch.arange(-kernel_size // 2, kernel_size // 2 + 1, device=channel.device)
        gaussian_1d = torch.exp(-(x ** 2) / (2 * sigma ** 2))
        gaussian_1d = gaussian_1d / gaussian_1d.sum()
        
        # 2D Í∞ÄÏö∞ÏãúÏïà Ïª§ÎÑê
        gaussian_2d = gaussian_1d.unsqueeze(0) * gaussian_1d.unsqueeze(1)
        
        # Ìå®Îî© Ï∂îÍ∞Ä
        padded_channel = F.pad(channel.unsqueeze(0).unsqueeze(0), 
                              (kernel_size // 2, kernel_size // 2, kernel_size // 2, kernel_size // 2), 
                              mode='reflect')
        
        # Ïª®Î≥ºÎ£®ÏÖò Ï†ÅÏö©
        smoothed_channel = F.conv2d(padded_channel, gaussian_2d.unsqueeze(0).unsqueeze(0))
        
        return smoothed_channel.squeeze()
    
    def _calculate_warping_confidence(self, warping_field: torch.Tensor) -> torch.Tensor:
        """ÏõåÌïë Ïã†Î¢∞ÎèÑ Í≥ÑÏÇ∞"""
        # Î≥ÄÏúÑÏùò ÌÅ¨Í∏∞ÏôÄ Î∞©Ìñ• ÏùºÍ¥ÄÏÑ± Í∏∞Î∞ò Ïã†Î¢∞ÎèÑ
        displacement_magnitude = torch.sqrt(warping_field[:, 0:1]**2 + warping_field[:, 1:2]**2)
        
        # Ï†ÅÏ†àÌïú Î≥ÄÏúÑ Î≤îÏúÑÏóêÏÑú ÎÜíÏùÄ Ïã†Î¢∞ÎèÑ
        confidence = torch.ones_like(displacement_magnitude)
        
        # ÎÑàÎ¨¥ ÌÅ∞ Î≥ÄÏúÑÎäî ÎÇÆÏùÄ Ïã†Î¢∞ÎèÑ
        confidence[displacement_magnitude > 0.8] = 0.3
        confidence[displacement_magnitude > 0.5] = 0.6
        
        # ÎÑàÎ¨¥ ÏûëÏùÄ Î≥ÄÏúÑÎèÑ ÎÇÆÏùÄ Ïã†Î¢∞ÎèÑ
        confidence[displacement_magnitude < 0.05] = 0.4
        
        return confidence
    
    def _apply_warping(self, cloth_image: torch.Tensor, warping_field: torch.Tensor) -> torch.Tensor:
        """ÏõåÌïë Ï†ÅÏö©"""
        batch_size, channels, height, width = cloth_image.shape
        
        # Í∑∏Î¶¨Îìú ÏÉùÏÑ±
        grid_y, grid_x = torch.meshgrid(
            torch.linspace(-1, 1, height, device=self.device),
            torch.linspace(-1, 1, width, device=self.device),
            indexing='ij'
        )
        
        # ÏõåÌïë ÌïÑÎìú Ï†ÅÏö©
        warped_grid_x = grid_x + warping_field[:, 0] * 0.5  # -1 ~ 1 Î≤îÏúÑÎ°ú Ï†úÌïú
        warped_grid_y = grid_y + warping_field[:, 1] * 0.5
        
        # Í∑∏Î¶¨Îìú Ï†ïÍ∑úÌôî
        warped_grid_x = torch.clamp(warped_grid_x, -1, 1)
        warped_grid_y = torch.clamp(warped_grid_y, -1, 1)
        
        # Í∑∏Î¶¨Îìú Í≤∞Ìï©
        warped_grid = torch.stack([warped_grid_x, warped_grid_y], dim=-1)
        
        # ÏõåÌïë Ï†ÅÏö©
        warped_cloth = F.grid_sample(cloth_image, warped_grid, mode='bilinear', 
                                    padding_mode='border', align_corners=False)
        
        return warped_cloth
    
    def _update_inference_stats(self, inference_time: float, success: bool):
        """Ï∂îÎ°† ÌÜµÍ≥Ñ ÏóÖÎç∞Ïù¥Ìä∏"""
        self.inference_stats["total_inferences"] += 1
        self.inference_stats["total_time"] += inference_time
        self.inference_stats["avg_time"] = self.inference_stats["total_time"] / self.inference_stats["total_inferences"]
        
        if not success:
            failed_count = int((1 - self.inference_stats["success_rate"]) * self.inference_stats["total_inferences"])
            self.inference_stats["success_rate"] = (self.inference_stats["total_inferences"] - failed_count - 1) / self.inference_stats["total_inferences"]
    
    def get_inference_stats(self) -> Dict[str, Any]:
        """Ï∂îÎ°† ÌÜµÍ≥Ñ Î∞òÌôò"""
        return self.inference_stats.copy()
    
    def get_model_info(self) -> Dict[str, Any]:
        """Î™®Îç∏ Ï†ïÎ≥¥ Î∞òÌôò"""
        model_info = {}
        for model_name, model in self.models.items():
            model_info[model_name] = {
                "weight": self.model_weights.get(model_name, 1.0),
                "parameters": sum(p.numel() for p in model.parameters()),
                "device": str(next(model.parameters()).device)
            }
        return model_info
    
    def clear_cache(self):
        """Ï∫êÏãú Ï†ïÎ¶¨"""
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
        self.logger.info("‚úÖ Ï∫êÏãú Ï†ïÎ¶¨ ÏôÑÎ£å")

# Ï∂îÎ°† ÏóîÏßÑ Ïù∏Ïä§ÌÑ¥Ïä§ ÏÉùÏÑ± Ìï®Ïàò
def create_cloth_warping_inference_engine(config: InferenceConfig = None) -> ClothWarpingInferenceEngine:
    """Cloth Warping Ï∂îÎ°† ÏóîÏßÑ ÏÉùÏÑ±"""
    return ClothWarpingInferenceEngine(config)

# Í∏∞Î≥∏ ÏÑ§Ï†ïÏúºÎ°ú Ï∂îÎ°† ÏóîÏßÑ ÏÉùÏÑ±
def create_default_inference_engine() -> ClothWarpingInferenceEngine:
    """Í∏∞Î≥∏ ÏÑ§Ï†ïÏúºÎ°ú Ï∂îÎ°† ÏóîÏßÑ ÏÉùÏÑ±"""
    config = InferenceConfig(
        batch_size=1,
        use_mps=True,
        memory_efficient=True,
        enable_ensemble=True,
        confidence_threshold=0.5,
        max_models=8,
        warp_resolution=(256, 256)
    )
    return ClothWarpingInferenceEngine(config)

if __name__ == "__main__":
    # ÌÖåÏä§Ìä∏ ÏΩîÎìú
    logging.basicConfig(level=logging.INFO)
    
    # Ï∂îÎ°† ÏóîÏßÑ ÏÉùÏÑ±
    engine = create_default_inference_engine()
    
    # ÎçîÎØ∏ Î™®Îç∏ Î°úÎìú
    engine.load_model("warping_model_1", "dummy_path_1", 1.0)
    engine.load_model("warping_model_2", "dummy_path_2", 0.8)
    
    # ÌÖåÏä§Ìä∏ Îç∞Ïù¥ÌÑ∞ ÏÉùÏÑ±
    batch_size, channels, height, width = 2, 3, 256, 256
    test_cloth = torch.randn(batch_size, channels, height, width)
    test_target = torch.randn(batch_size, channels, height, width)
    
    # Ï∂îÎ°† ÏàòÌñâ
    result = engine(test_cloth, test_target)
    print(f"ÏõåÌïë Ï∂îÎ°† Í≤∞Í≥º: {result['success']}")
    print(f"Ï∂îÎ°† ÏãúÍ∞Ñ: {result['inference_time']:.3f}Ï¥à")
    print(f"ÏõåÌïëÎêú ÏùòÎ•ò ÌòïÌÉú: {result['warped_cloth'].shape}")
    print(f"Î™®Îç∏ Ï†ïÎ≥¥: {engine.get_model_info()}")
    print(f"Ï∂îÎ°† ÌÜµÍ≥Ñ: {engine.get_inference_stats()}")
