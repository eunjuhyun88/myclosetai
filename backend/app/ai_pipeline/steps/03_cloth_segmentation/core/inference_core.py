#!/usr/bin/env python3
"""
ğŸ”¥ MyCloset AI - Step 03: ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ - Inference Core
=====================================================================

AI ì¶”ë¡  ì‹¤í–‰ ë° ê´€ë¦¬ í•µì‹¬ ê¸°ëŠ¥ë“¤

Author: MyCloset AI Team  
Date: 2025-08-01
Version: 1.0
"""

import logging
import time
import gc
from typing import Dict, Any, Optional, List, Tuple

try:
    import numpy as np
    import cv2
    NUMPY_AVAILABLE = True
    CV2_AVAILABLE = True
except ImportError:
    NUMPY_AVAILABLE = False
    CV2_AVAILABLE = False
    np = None
    cv2 = None

try:
    import torch
    TORCH_AVAILABLE = True
except ImportError:
    TORCH_AVAILABLE = False

from ..config import SegmentationMethod, ClothCategory, QualityLevel
from ..ensemble import _run_hybrid_ensemble_sync, _combine_ensemble_results

logger = logging.getLogger(__name__)

class InferenceCore:
    """
    ğŸ”¥ AI ì¶”ë¡  ì‹¤í–‰ ë° ê´€ë¦¬ í•µì‹¬ ê¸°ëŠ¥ë“¤
    
    ë¶„ë¦¬ëœ ê¸°ëŠ¥ë“¤:
    - AI ëª¨ë¸ ì¶”ë¡  ì‹¤í–‰
    - ì•™ìƒë¸” ì¶”ë¡  ê´€ë¦¬
    - ë©”ëª¨ë¦¬ ì•ˆì „ì„± ë³´ì¥
    - ê²°ê³¼ ê²€ì¦ ë° í›„ì²˜ë¦¬
    """
    
    def __init__(self, models: Dict[str, Any], device: str = "cpu"):
        """ì´ˆê¸°í™”"""
        self.models = models
        self.device = device
        self.logger = logging.getLogger(f"{__name__}.InferenceCore")
        self.inference_stats = {
            'total_inferences': 0,
            'successful_inferences': 0,
            'failed_inferences': 0,
            'average_inference_time': 0.0,
            'last_inference_time': 0.0
        }
        
    def run_ai_inference(self, 
                        image: np.ndarray, 
                        method: SegmentationMethod = SegmentationMethod.U2NET_CLOTH,
                        person_parsing: Optional[Dict[str, Any]] = None,
                        pose_info: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
        """AI ì¶”ë¡  ì‹¤í–‰"""
        try:
            start_time = time.time()
            self.logger.info(f"ğŸ”„ AI ì¶”ë¡  ì‹œì‘: {method.value}")
            
            # ì…ë ¥ ê²€ì¦
            if not self._validate_input(image):
                return self._create_error_result("ì…ë ¥ ì´ë¯¸ì§€ ê²€ì¦ ì‹¤íŒ¨")
            
            # ë©”ëª¨ë¦¬ ì•ˆì „ì„± ì²´í¬
            if not self._check_memory_safety():
                return self._create_error_result("ë©”ëª¨ë¦¬ ë¶€ì¡±")
            
            # ì¶”ë¡  ì‹¤í–‰
            if method == SegmentationMethod.HYBRID_AI:
                result = self._run_hybrid_inference(image, person_parsing, pose_info)
            else:
                result = self._run_single_model_inference(image, method, person_parsing, pose_info)
            
            # ê²°ê³¼ ê²€ì¦
            if not self._validate_result(result):
                return self._create_error_result("ì¶”ë¡  ê²°ê³¼ ê²€ì¦ ì‹¤íŒ¨")
            
            # í†µê³„ ì—…ë°ì´íŠ¸
            inference_time = time.time() - start_time
            self._update_inference_stats(True, inference_time)
            
            self.logger.info(f"âœ… AI ì¶”ë¡  ì™„ë£Œ: {method.value} ({inference_time:.2f}s)")
            return result
            
        except Exception as e:
            self.logger.error(f"âŒ AI ì¶”ë¡  ì‹¤íŒ¨: {e}")
            self._update_inference_stats(False, 0.0)
            return self._create_error_result(f"ì¶”ë¡  ì‹¤íŒ¨: {e}")

    def _run_single_model_inference(self, 
                                  image: np.ndarray, 
                                  method: SegmentationMethod,
                                  person_parsing: Optional[Dict[str, Any]] = None,
                                  pose_info: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
        """ë‹¨ì¼ ëª¨ë¸ ì¶”ë¡  ì‹¤í–‰"""
        try:
            model_key = method.value
            
            if model_key not in self.models:
                return self._create_error_result(f"ëª¨ë¸ì´ ë¡œë”©ë˜ì§€ ì•ŠìŒ: {model_key}")
            
            model = self.models[model_key]
            
            # ëª¨ë¸ë³„ ì¶”ë¡  ì‹¤í–‰
            if 'u2net' in model_key:
                result = self._run_u2net_inference(model, image, person_parsing, pose_info)
            elif 'sam' in model_key:
                result = self._run_sam_inference(model, image, person_parsing, pose_info)
            elif 'deeplabv3' in model_key:
                result = self._run_deeplabv3_inference(model, image, person_parsing, pose_info)
            else:
                return self._create_error_result(f"ì•Œ ìˆ˜ ì—†ëŠ” ëª¨ë¸ íƒ€ì…: {model_key}")
            
            return result
            
        except Exception as e:
            self.logger.error(f"âŒ ë‹¨ì¼ ëª¨ë¸ ì¶”ë¡  ì‹¤íŒ¨: {e}")
            return self._create_error_result(f"ë‹¨ì¼ ëª¨ë¸ ì¶”ë¡  ì‹¤íŒ¨: {e}")

    def _run_hybrid_inference(self, 
                            image: np.ndarray,
                            person_parsing: Optional[Dict[str, Any]] = None,
                            pose_info: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
        """í•˜ì´ë¸Œë¦¬ë“œ ì•™ìƒë¸” ì¶”ë¡  ì‹¤í–‰"""
        try:
            self.logger.info("ğŸ”„ í•˜ì´ë¸Œë¦¬ë“œ ì•™ìƒë¸” ì¶”ë¡  ì‹œì‘")
            
            # ì•™ìƒë¸” ì‹¤í–‰
            result = _run_hybrid_ensemble_sync(
                self, image, person_parsing or {}, pose_info or {}
            )
            
            return result
            
        except Exception as e:
            self.logger.error(f"âŒ í•˜ì´ë¸Œë¦¬ë“œ ì¶”ë¡  ì‹¤íŒ¨: {e}")
            return self._create_error_result(f"í•˜ì´ë¸Œë¦¬ë“œ ì¶”ë¡  ì‹¤íŒ¨: {e}")

    def _run_u2net_inference(self, 
                           model: Any, 
                           image: np.ndarray,
                           person_parsing: Optional[Dict[str, Any]] = None,
                           pose_info: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
        """U2Net ì¶”ë¡  ì‹¤í–‰"""
        try:
            # ì´ë¯¸ì§€ ì „ì²˜ë¦¬
            processed_image = self._preprocess_image_for_u2net(image)
            
            # ì¶”ë¡  ì‹¤í–‰
            with torch.no_grad():
                prediction = model.predict(processed_image)
            
            # ê²°ê³¼ í›„ì²˜ë¦¬
            result = self._postprocess_u2net_result(prediction, image)
            
            return result
            
        except Exception as e:
            self.logger.error(f"âŒ U2Net ì¶”ë¡  ì‹¤íŒ¨: {e}")
            return self._create_error_result(f"U2Net ì¶”ë¡  ì‹¤íŒ¨: {e}")

    def _run_sam_inference(self, 
                          model: Any, 
                          image: np.ndarray,
                          person_parsing: Optional[Dict[str, Any]] = None,
                          pose_info: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
        """SAM ì¶”ë¡  ì‹¤í–‰"""
        try:
            # í”„ë¡¬í”„íŠ¸ ìƒì„±
            prompts = self._generate_sam_prompts(image, person_parsing, pose_info)
            
            # ì¶”ë¡  ì‹¤í–‰
            with torch.no_grad():
                prediction = model.predict(image, prompts=prompts)
            
            # ê²°ê³¼ í›„ì²˜ë¦¬
            result = self._postprocess_sam_result(prediction, image)
            
            return result
            
        except Exception as e:
            self.logger.error(f"âŒ SAM ì¶”ë¡  ì‹¤íŒ¨: {e}")
            return self._create_error_result(f"SAM ì¶”ë¡  ì‹¤íŒ¨: {e}")

    def _run_deeplabv3_inference(self, 
                                model: Any, 
                                image: np.ndarray,
                                person_parsing: Optional[Dict[str, Any]] = None,
                                pose_info: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
        """DeepLabV3+ ì¶”ë¡  ì‹¤í–‰"""
        try:
            # ì´ë¯¸ì§€ ì „ì²˜ë¦¬
            processed_image = self._preprocess_image_for_deeplabv3(image)
            
            # ì¶”ë¡  ì‹¤í–‰
            with torch.no_grad():
                prediction = model.predict(processed_image)
            
            # ê²°ê³¼ í›„ì²˜ë¦¬
            result = self._postprocess_deeplabv3_result(prediction, image)
            
            return result
            
        except Exception as e:
            self.logger.error(f"âŒ DeepLabV3+ ì¶”ë¡  ì‹¤íŒ¨: {e}")
            return self._create_error_result(f"DeepLabV3+ ì¶”ë¡  ì‹¤íŒ¨: {e}")

    def _preprocess_image_for_u2net(self, image: np.ndarray) -> np.ndarray:
        """U2Netìš© ì´ë¯¸ì§€ ì „ì²˜ë¦¬"""
        try:
            # ì´ë¯¸ì§€ í¬ê¸° ì¡°ì •
            if image.shape[:2] != (512, 512):
                image = cv2.resize(image, (512, 512))
            
            # ì •ê·œí™”
            if image.dtype != np.float32:
                image = image.astype(np.float32) / 255.0
            
            return image
            
        except Exception as e:
            self.logger.error(f"âŒ U2Net ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return image

    def _preprocess_image_for_deeplabv3(self, image: np.ndarray) -> np.ndarray:
        """DeepLabV3+ìš© ì´ë¯¸ì§€ ì „ì²˜ë¦¬"""
        try:
            # ì´ë¯¸ì§€ í¬ê¸° ì¡°ì •
            if image.shape[:2] != (512, 512):
                image = cv2.resize(image, (512, 512))
            
            # ì •ê·œí™”
            if image.dtype != np.float32:
                image = image.astype(np.float32) / 255.0
            
            return image
            
        except Exception as e:
            self.logger.error(f"âŒ DeepLabV3+ ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return image

    def _generate_sam_prompts(self, 
                            image: np.ndarray,
                            person_parsing: Optional[Dict[str, Any]] = None,
                            pose_info: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
        """SAM í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        try:
            prompts = {
                'points': [],
                'boxes': [],
                'masks': []
            }
            
            # ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ ìƒì„± (ì´ë¯¸ì§€ ì¤‘ì‹¬ì )
            h, w = image.shape[:2]
            center_point = [w // 2, h // 2]
            prompts['points'].append(center_point)
            
            return prompts
            
        except Exception as e:
            self.logger.error(f"âŒ SAM í”„ë¡¬í”„íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}")
            return {'points': [], 'boxes': [], 'masks': []}

    def _postprocess_u2net_result(self, prediction: Dict[str, Any], original_image: np.ndarray) -> Dict[str, Any]:
        """U2Net ê²°ê³¼ í›„ì²˜ë¦¬"""
        try:
            # ë§ˆìŠ¤í¬ ì¶”ì¶œ
            masks = prediction.get('masks', {})
            
            # ê²°ê³¼ êµ¬ì„±
            result = {
                'success': True,
                'method': 'u2net_cloth',
                'masks': masks,
                'confidence': prediction.get('confidence', 0.0),
                'processing_time': prediction.get('processing_time', 0.0),
                'original_image_shape': original_image.shape
            }
            
            return result
            
        except Exception as e:
            self.logger.error(f"âŒ U2Net ê²°ê³¼ í›„ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return self._create_error_result(f"U2Net ê²°ê³¼ í›„ì²˜ë¦¬ ì‹¤íŒ¨: {e}")

    def _postprocess_sam_result(self, prediction: Dict[str, Any], original_image: np.ndarray) -> Dict[str, Any]:
        """SAM ê²°ê³¼ í›„ì²˜ë¦¬"""
        try:
            # ë§ˆìŠ¤í¬ ì¶”ì¶œ
            masks = prediction.get('masks', {})
            
            # ê²°ê³¼ êµ¬ì„±
            result = {
                'success': True,
                'method': 'sam_huge',
                'masks': masks,
                'confidence': prediction.get('confidence', 0.0),
                'processing_time': prediction.get('processing_time', 0.0),
                'original_image_shape': original_image.shape
            }
            
            return result
            
        except Exception as e:
            self.logger.error(f"âŒ SAM ê²°ê³¼ í›„ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return self._create_error_result(f"SAM ê²°ê³¼ í›„ì²˜ë¦¬ ì‹¤íŒ¨: {e}")

    def _postprocess_deeplabv3_result(self, prediction: Dict[str, Any], original_image: np.ndarray) -> Dict[str, Any]:
        """DeepLabV3+ ê²°ê³¼ í›„ì²˜ë¦¬"""
        try:
            # ë§ˆìŠ¤í¬ ì¶”ì¶œ
            masks = prediction.get('masks', {})
            
            # ê²°ê³¼ êµ¬ì„±
            result = {
                'success': True,
                'method': 'deeplabv3_plus',
                'masks': masks,
                'confidence': prediction.get('confidence', 0.0),
                'processing_time': prediction.get('processing_time', 0.0),
                'original_image_shape': original_image.shape
            }
            
            return result
            
        except Exception as e:
            self.logger.error(f"âŒ DeepLabV3+ ê²°ê³¼ í›„ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return self._create_error_result(f"DeepLabV3+ ê²°ê³¼ í›„ì²˜ë¦¬ ì‹¤íŒ¨: {e}")

    def _validate_input(self, image: np.ndarray) -> bool:
        """ì…ë ¥ ê²€ì¦"""
        try:
            if image is None:
                return False
            
            if not isinstance(image, np.ndarray):
                return False
            
            if len(image.shape) != 3:
                return False
            
            if image.shape[2] not in [1, 3]:
                return False
            
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ ì…ë ¥ ê²€ì¦ ì‹¤íŒ¨: {e}")
            return False

    def _validate_result(self, result: Dict[str, Any]) -> bool:
        """ê²°ê³¼ ê²€ì¦"""
        try:
            if not isinstance(result, dict):
                return False
            
            if 'success' not in result:
                return False
            
            if not result['success']:
                return False
            
            if 'masks' not in result:
                return False
            
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ ê²°ê³¼ ê²€ì¦ ì‹¤íŒ¨: {e}")
            return False

    def _check_memory_safety(self) -> bool:
        """ë©”ëª¨ë¦¬ ì•ˆì „ì„± ì²´í¬"""
        try:
            import psutil
            memory_usage = psutil.virtual_memory().percent
            return memory_usage < 90
        except ImportError:
            return True

    def _create_error_result(self, error_message: str) -> Dict[str, Any]:
        """ì—ëŸ¬ ê²°ê³¼ ìƒì„±"""
        return {
            'success': False,
            'error': error_message,
            'masks': {},
            'confidence': 0.0,
            'processing_time': 0.0
        }

    def _update_inference_stats(self, success: bool, inference_time: float):
        """ì¶”ë¡  í†µê³„ ì—…ë°ì´íŠ¸"""
        try:
            self.inference_stats['total_inferences'] += 1
            
            if success:
                self.inference_stats['successful_inferences'] += 1
            else:
                self.inference_stats['failed_inferences'] += 1
            
            # í‰ê·  ì¶”ë¡  ì‹œê°„ ì—…ë°ì´íŠ¸
            total_successful = self.inference_stats['successful_inferences']
            if total_successful > 0:
                current_avg = self.inference_stats['average_inference_time']
                new_avg = (current_avg * (total_successful - 1) + inference_time) / total_successful
                self.inference_stats['average_inference_time'] = new_avg
            
            self.inference_stats['last_inference_time'] = inference_time
            
        except Exception as e:
            self.logger.error(f"âŒ ì¶”ë¡  í†µê³„ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")

    def get_inference_stats(self) -> Dict[str, Any]:
        """ì¶”ë¡  í†µê³„ ë°˜í™˜"""
        return self.inference_stats.copy()

    def reset_inference_stats(self):
        """ì¶”ë¡  í†µê³„ ì´ˆê¸°í™”"""
        self.inference_stats = {
            'total_inferences': 0,
            'successful_inferences': 0,
            'failed_inferences': 0,
            'average_inference_time': 0.0,
            'last_inference_time': 0.0
        }
