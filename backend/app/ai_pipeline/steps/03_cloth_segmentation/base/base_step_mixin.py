#!/usr/bin/env python3
"""
ğŸ”¥ MyCloset AI - Step 03: ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ - Base Step Mixin
=====================================================================

BaseStepMixin í´ë˜ìŠ¤ì™€ ê´€ë ¨ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤ì„ ë¶„ë¦¬í•œ ëª¨ë“ˆ

Author: MyCloset AI Team  
Date: 2025-08-01
Version: 1.0
"""

import logging
import weakref
from abc import ABC, abstractmethod
from typing import Dict, Any, Optional, List, Tuple, TYPE_CHECKING

# ê³µí†µ imports ì‹œìŠ¤í…œ ì‚¬ìš©
try:
    from app.ai_pipeline.utils.common_imports import (
        os, gc, time, threading, math, hashlib, json, base64, warnings, np,
        Path, Dict, Any, Optional, Union, List, Tuple, TYPE_CHECKING,
        dataclass, field, Enum, BytesIO, ThreadPoolExecutor,
        MyClosetAIException, ModelLoadingError, ImageProcessingError, DataValidationError, ConfigurationError,
        error_tracker, track_exception, get_error_summary, create_exception_response, convert_to_mycloset_exception,
        ErrorCodes, EXCEPTIONS_AVAILABLE,
        detect_mock_data, diagnose_step_data, MOCK_DIAGNOSTIC_AVAILABLE,
        cv2, PIL_AVAILABLE, CV2_AVAILABLE, NUMPY_AVAILABLE, Image, ImageEnhance
    )
except ImportError:
    # í´ë°± imports
    import os
    import gc
    import time
    import logging
    import threading
    import math
    import hashlib
    import json
    import base64
    import warnings
    from typing import Dict, Any, Optional, List, Tuple, TYPE_CHECKING
    from dataclasses import dataclass, field
    from enum import Enum
    from io import BytesIO
    from concurrent.futures import ThreadPoolExecutor
    from pathlib import Path

# PIL Image import ì¶”ê°€
if 'PIL_AVAILABLE' in globals() and PIL_AVAILABLE:
    from PIL import Image as PILImage

# ê²½ê³  ë¬´ì‹œ ì„¤ì •
warnings.filterwarnings('ignore', category=DeprecationWarning)
warnings.filterwarnings('ignore', category=ImportWarning)

logger = logging.getLogger(__name__)

def detect_m3_max():
    """M3 Max ê°ì§€"""
    try:
        import platform
        import subprocess
        if platform.system() == 'Darwin':
            result = subprocess.run(
                ['sysctl', '-n', 'machdep.cpu.brand_string'],
                capture_output=True, text=True, timeout=5
            )
            return 'M3' in result.stdout
    except:
        pass
    return False

IS_M3_MAX = detect_m3_max()
MEMORY_GB = 16.0

class BaseStepMixin:
    """ClothSegmentationStepìš© BaseStepMixin í´ë˜ìŠ¤"""
    
    def __init__(self, **kwargs):
        print(f"ğŸ”¥ [ë””ë²„ê¹…] BaseStepMixin __init__ ì‹œì‘")
        
        # ê¸°ë³¸ ì†ì„±ë“¤ (ì•ˆì „í•œ ì´ˆê¸°í™”)
        try:
            print(f"ğŸ”¥ [ë””ë²„ê¹…] Logger ì´ˆê¸°í™” ì‹œì‘")
            self.logger = logging.getLogger(self.__class__.__name__)
            print(f"ğŸ”¥ [ë””ë²„ê¹…] Logger ì´ˆê¸°í™” ì™„ë£Œ")
        except Exception as e:
            print(f"ğŸ”¥ [ë””ë²„ê¹…] Logger ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.logger = None
        
        try:
            print(f"ğŸ”¥ [ë””ë²„ê¹…] ê¸°ë³¸ ì†ì„± ì„¤ì • ì‹œì‘")
            self.step_name = kwargs.get('step_name', 'ClothSegmentationStep')
            self.step_id = kwargs.get('step_id', 3)
            self.device = kwargs.get('device', 'cpu')
            print(f"ğŸ”¥ [ë””ë²„ê¹…] ê¸°ë³¸ ì†ì„± ì„¤ì • ì™„ë£Œ")
        except Exception as e:
            print(f"ğŸ”¥ [ë””ë²„ê¹…] ê¸°ë³¸ ì†ì„± ì„¤ì • ì‹¤íŒ¨: {e}")
            self.step_name = 'ClothSegmentationStep'
            self.step_id = 3
            self.device = 'cpu'
        
        # AI ëª¨ë¸ ê´€ë ¨ ì†ì„±ë“¤ (ClothSegmentationì´ í•„ìš”ë¡œ í•˜ëŠ”)
        try:
            print(f"ğŸ”¥ [ë””ë²„ê¹…] AI ëª¨ë¸ ì†ì„± ì´ˆê¸°í™” ì‹œì‘")
            self.ai_models = {}
            self.models_loading_status = {
                'deeplabv3plus': False,
                'maskrcnn': False,
                'sam_huge': False,
                'u2net_cloth': False,
                'total_loaded': 0,
                'loading_errors': []
            }
            self.model_interface = None
            self.loaded_models = {}
            print(f"ğŸ”¥ [ë””ë²„ê¹…] AI ëª¨ë¸ ì†ì„± ì´ˆê¸°í™” ì™„ë£Œ")
        except Exception as e:
            print(f"ğŸ”¥ [ë””ë²„ê¹…] AI ëª¨ë¸ ì†ì„± ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.ai_models = {}
            self.models_loading_status = {'loading_errors': []}
            self.model_interface = None
            self.loaded_models = {}
        
        # ClothSegmentation íŠ¹í™” ì†ì„±ë“¤
        try:
            print(f"ğŸ”¥ [ë””ë²„ê¹…] ClothSegmentation ì†ì„± ì´ˆê¸°í™” ì‹œì‘")
            self.segmentation_models = {}
            self.segmentation_ready = False
            self.cloth_cache = {}
            print(f"ğŸ”¥ [ë””ë²„ê¹…] ClothSegmentation ì†ì„± ì´ˆê¸°í™” ì™„ë£Œ")
        except Exception as e:
            print(f"ğŸ”¥ [ë””ë²„ê¹…] ClothSegmentation ì†ì„± ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.segmentation_models = {}
            self.segmentation_ready = False
            self.cloth_cache = {}
        
        # ì˜ë¥˜ ì¹´í…Œê³ ë¦¬ ì •ì˜
        try:
            print(f"ğŸ”¥ [ë””ë²„ê¹…] ì˜ë¥˜ ì¹´í…Œê³ ë¦¬ ì •ì˜ ì‹œì‘")
            self.cloth_categories = {
                0: 'background',
                1: 'shirt', 2: 't_shirt', 3: 'sweater', 4: 'hoodie',
                5: 'jacket', 6: 'coat', 7: 'dress', 8: 'skirt',
                9: 'pants', 10: 'jeans', 11: 'shorts',
                12: 'shoes', 13: 'boots', 14: 'sneakers',
                15: 'bag', 16: 'hat', 17: 'glasses', 18: 'scarf', 19: 'belt'
            }
            print(f"ğŸ”¥ [ë””ë²„ê¹…] ì˜ë¥˜ ì¹´í…Œê³ ë¦¬ ì •ì˜ ì™„ë£Œ")
        except Exception as e:
            print(f"ğŸ”¥ [ë””ë²„ê¹…] ì˜ë¥˜ ì¹´í…Œê³ ë¦¬ ì •ì˜ ì‹¤íŒ¨: {e}")
            self.cloth_categories = {}
        
        # ìƒíƒœ ê´€ë ¨ ì†ì„±ë“¤
        try:
            print(f"ğŸ”¥ [ë””ë²„ê¹…] ìƒíƒœ ì†ì„± ì´ˆê¸°í™” ì‹œì‘")
            self.is_initialized = False
            self.is_ready = False
            self.has_model = False
            self.model_loaded = False
            print(f"ğŸ”¥ [ë””ë²„ê¹…] ìƒíƒœ ì†ì„± ì´ˆê¸°í™” ì™„ë£Œ")
        except Exception as e:
            print(f"ğŸ”¥ [ë””ë²„ê¹…] ìƒíƒœ ì†ì„± ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.is_initialized = False
            self.is_ready = False
            self.has_model = False
            self.model_loaded = False

    def process(self, **kwargs) -> Dict[str, Any]:
        """ê¸°ë³¸ ì²˜ë¦¬ ë©”ì„œë“œ"""
        try:
            self.logger.info(f"ğŸ”¥ {self.step_name} ì²˜ë¦¬ ì‹œì‘")
            
            # ì…ë ¥ ê²€ì¦
            if not self._validate_input(kwargs):
                return self._create_error_response("ì…ë ¥ ê²€ì¦ ì‹¤íŒ¨")
            
            # AI ì¶”ë¡  ì‹¤í–‰
            result = self._run_ai_inference(kwargs)
            
            # ê²°ê³¼ ê²€ì¦
            if not self._validate_output(result):
                return self._create_error_response("ì¶œë ¥ ê²€ì¦ ì‹¤íŒ¨")
            
            self.logger.info(f"ğŸ”¥ {self.step_name} ì²˜ë¦¬ ì™„ë£Œ")
            return result
            
        except Exception as e:
            self.logger.error(f"âŒ {self.step_name} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return self._create_error_response(str(e))

    def initialize(self) -> bool:
        """ì´ˆê¸°í™” ë©”ì„œë“œ"""
        try:
            self.logger.info(f"ğŸ”¥ {self.step_name} ì´ˆê¸°í™” ì‹œì‘")
            
            # ê¸°ë³¸ ì´ˆê¸°í™”
            if not self._initialize_basic():
                return False
            
            # ëª¨ë¸ ë¡œë”©
            if not self._load_models():
                return False
            
            # ìƒíƒœ ì„¤ì •
            self.is_initialized = True
            self.is_ready = True
            
            self.logger.info(f"ğŸ”¥ {self.step_name} ì´ˆê¸°í™” ì™„ë£Œ")
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ {self.step_name} ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return False

    def cleanup(self):
        """ì •ë¦¬ ë©”ì„œë“œ"""
        try:
            self.logger.info(f"ğŸ”¥ {self.step_name} ì •ë¦¬ ì‹œì‘")
            
            # ëª¨ë¸ ì •ë¦¬
            self._cleanup_models()
            
            # ìºì‹œ ì •ë¦¬
            self._cleanup_cache()
            
            # ìƒíƒœ ì´ˆê¸°í™”
            self.is_initialized = False
            self.is_ready = False
            
            self.logger.info(f"ğŸ”¥ {self.step_name} ì •ë¦¬ ì™„ë£Œ")
            
        except Exception as e:
            self.logger.error(f"âŒ {self.step_name} ì •ë¦¬ ì‹¤íŒ¨: {e}")

    def get_status(self) -> Dict[str, Any]:
        """ìƒíƒœ ì¡°íšŒ ë©”ì„œë“œ"""
        return {
            'step_name': self.step_name,
            'step_id': self.step_id,
            'is_initialized': self.is_initialized,
            'is_ready': self.is_ready,
            'has_model': self.has_model,
            'model_loaded': self.model_loaded,
            'device': self.device,
            'models_loading_status': self.models_loading_status
        }

    def set_model_loader(self, model_loader):
        """ëª¨ë¸ ë¡œë” ì„¤ì •"""
        self.model_loader = model_loader

    def set_memory_manager(self, memory_manager):
        """ë©”ëª¨ë¦¬ ë§¤ë‹ˆì € ì„¤ì •"""
        self.memory_manager = memory_manager

    def set_data_converter(self, data_converter):
        """ë°ì´í„° ë³€í™˜ê¸° ì„¤ì •"""
        self.data_converter = data_converter

    def set_di_container(self, di_container):
        """DI ì»¨í…Œì´ë„ˆ ì„¤ì •"""
        self.di_container = di_container

    def _get_step_requirements(self) -> Dict[str, Any]:
        """ìŠ¤í… ìš”êµ¬ì‚¬í•­ ì¡°íšŒ"""
        return {
            'step_name': self.step_name,
            'step_id': self.step_id,
            'required_models': ['deeplabv3plus', 'u2net_cloth', 'sam_huge'],
            'required_memory': '8GB',
            'required_device': 'cpu'
        }

    def _validate_input(self, kwargs) -> bool:
        """ì…ë ¥ ê²€ì¦"""
        return True

    def _validate_output(self, result) -> bool:
        """ì¶œë ¥ ê²€ì¦"""
        return True

    def _create_error_response(self, message: str) -> Dict[str, Any]:
        """ì—ëŸ¬ ì‘ë‹µ ìƒì„±"""
        return {
            'success': False,
            'error': message,
            'step_name': self.step_name,
            'step_id': self.step_id
        }

    def _initialize_basic(self) -> bool:
        """ê¸°ë³¸ ì´ˆê¸°í™”"""
        return True

    def _load_models(self) -> bool:
        """ëª¨ë¸ ë¡œë”©"""
        return True

    def _cleanup_models(self):
        """ëª¨ë¸ ì •ë¦¬"""
        pass

    def _cleanup_cache(self):
        """ìºì‹œ ì •ë¦¬"""
        pass

    def _run_ai_inference(self, kwargs) -> Dict[str, Any]:
        """AI ì¶”ë¡  ì‹¤í–‰"""
        return {'success': True, 'message': 'ê¸°ë³¸ ì¶”ë¡  ì™„ë£Œ'}

def _get_central_hub_container():
    """ì¤‘ì•™ í—ˆë¸Œ ì»¨í…Œì´ë„ˆ ì¡°íšŒ"""
    try:
        from app.ai_pipeline.core.di_container import DIContainer
        return DIContainer.get_instance()
    except ImportError:
        return None

def _inject_dependencies_safe(step_instance):
    """ì˜ì¡´ì„± ì•ˆì „ ì£¼ì…"""
    try:
        container = _get_central_hub_container()
        if container:
            # ì˜ì¡´ì„± ì£¼ì… ë¡œì§
            pass
    except Exception as e:
        logger.warning(f"ì˜ì¡´ì„± ì£¼ì… ì‹¤íŒ¨: {e}")

def _get_service_from_central_hub(service_key: str):
    """ì¤‘ì•™ í—ˆë¸Œì—ì„œ ì„œë¹„ìŠ¤ ì¡°íšŒ"""
    try:
        container = _get_central_hub_container()
        if container:
            return container.get_service(service_key)
    except Exception as e:
        logger.warning(f"ì„œë¹„ìŠ¤ ì¡°íšŒ ì‹¤íŒ¨: {e}")
    return None
