#!/usr/bin/env python3
"""
ğŸ”¥ MyCloset AI - Step 03: ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ - Step 03 Cloth Segmentation
=====================================================================

ë¶„ë¦¬ëœ ëª¨ë“ˆë“¤ì„ í†µí•©í•˜ì—¬ ì‚¬ìš©í•˜ëŠ” ìƒˆë¡œìš´ step íŒŒì¼

Author: MyCloset AI Team  
Date: 2025-08-01
Version: 1.0
"""

import logging
import time
import os
import sys
from typing import Dict, Any, List, Tuple, Optional

# ê³µí†µ imports ì‹œìŠ¤í…œ ì‚¬ìš©
try:
    from app.ai_pipeline.utils.common_imports import (
        np, cv2, PIL_AVAILABLE, CV2_AVAILABLE, NUMPY_AVAILABLE, Image, ImageEnhance
    )
except ImportError:
    try:
        import numpy as np
        import cv2
        NUMPY_AVAILABLE = True
        CV2_AVAILABLE = True
    except ImportError:
        print("Warning: numpy or cv2 not available")
        # numpyê°€ ì—†ì„ ë•Œë¥¼ ìœ„í•œ ëŒ€ì²´
        class MockNumpy:
            def __init__(self):
                self.ndarray = type('ndarray', (), {})
        
        np = MockNumpy()
        cv2 = None
        NUMPY_AVAILABLE = False
        CV2_AVAILABLE = False

# íƒ€ì… íŒíŠ¸ë¥¼ ìœ„í•œ Union íƒ€ì… ì •ì˜
if NUMPY_AVAILABLE and np is not None:
    NDArray = np.ndarray
else:
    NDArray = Any  # numpyê°€ ì—†ì„ ë•ŒëŠ” Anyë¡œ ëŒ€ì²´

# PyTorch imports
try:
    import torch
    import torch.nn as nn
    import torch.nn.functional as F
    TORCH_AVAILABLE = True
except ImportError:
    TORCH_AVAILABLE = False
    torch = None
    nn = None
    F = None

# ë¶„ë¦¬ëœ ëª¨ë“ˆë“¤ import (ì•ˆì „í•œ import)
try:
    from .base.base_step_mixin import BaseStepMixin
except ImportError:
    # í´ë°±: ì§ì ‘ ì •ì˜
    class BaseStepMixin:
        def __init__(self, **kwargs):
            self.logger = logging.getLogger(self.__class__.__name__)
            self.step_name = kwargs.get('step_name', 'ClothSegmentationStep')
            self.step_id = kwargs.get('step_id', 3)
            self.device = kwargs.get('device', 'cpu')
            self.is_initialized = False
            self.is_ready = False
        
        def initialize(self) -> bool:
            return True
        
        def cleanup(self):
            pass
        
        def get_status(self) -> Dict[str, Any]:
            return {'status': 'ready'}

try:
    from .config.config import (
        SegmentationMethod, ClothCategory, QualityLevel, ClothSegmentationConfig,
        get_quality_config, get_model_config, get_cloth_category_name, get_cloth_category_group
    )
except ImportError:
    # í´ë°±: ê¸°ë³¸ ì •ì˜
    from enum import Enum
    from dataclasses import dataclass
    class SegmentationMethod(Enum):
        U2NET_CLOTH = "u2net_cloth"
        SAM_HUGE = "sam_huge"
        DEEPLABV3_PLUS = "deeplabv3_plus"
        HYBRID_AI = "hybrid_ai"
    
    class ClothCategory(Enum):
        SHIRT = 1
        T_SHIRT = 2
        PANTS = 9
        DRESS = 7
    
    class QualityLevel(Enum):
        FAST = "fast"
        BALANCED = "balanced"
        HIGH = "high"
        ULTRA = "ultra"
    
    @dataclass
    class ClothSegmentationConfig:
        method: SegmentationMethod = SegmentationMethod.U2NET_CLOTH
        quality_level: QualityLevel = QualityLevel.HIGH
        input_size: Tuple[int, int] = (512, 512)
        confidence_threshold: float = 0.5
        enable_visualization: bool = True
        enable_quality_assessment: bool = True
        enable_lighting_normalization: bool = True
        enable_color_correction: bool = True
        enable_clothing_classification: bool = True
        classification_confidence_threshold: float = 0.8
        enable_crf_postprocessing: bool = True
        enable_edge_refinement: bool = True
        enable_hole_filling: bool = True
        enable_multiscale_processing: bool = True
        enable_quality_validation: bool = True
        quality_threshold: float = 0.7
        enable_auto_retry: bool = True
        max_retry_attempts: int = 3
        auto_preprocessing: bool = True
        auto_postprocessing: bool = True
        strict_data_validation: bool = True

try:
    from .models.u2net import RealU2NETModel
except ImportError:
    # í´ë°±: ê¸°ë³¸ ì •ì˜
    class RealU2NETModel:
        def __init__(self, model_path, device):
            self.model_path = model_path
            self.device = device
            self.is_loaded = False
            self.model = None
        
        def load(self):
            try:
                import torch
                import torch.nn as nn
                
                # U2NET ëª¨ë¸ ì •ì˜
                class RSU(nn.Module):
                    def __init__(self, in_ch=3, mid_ch=12, out_ch=3):
                        super(RSU, self).__init__()
                        self.rebnconvin = REBNCONV(in_ch, out_ch, dirate=1)
                        self.rebnconv1 = REBNCONV(out_ch, mid_ch, dirate=1)
                        self.pool1 = nn.MaxPool2d(2, stride=2, ceil_mode=True)
                        self.rebnconv2 = REBNCONV(mid_ch, mid_ch, dirate=1)
                        self.pool2 = nn.MaxPool2d(2, stride=2, ceil_mode=True)
                        self.rebnconv3 = REBNCONV(mid_ch, mid_ch, dirate=1)
                        self.pool3 = nn.MaxPool2d(2, stride=2, ceil_mode=True)
                        self.rebnconv4 = REBNCONV(mid_ch, mid_ch, dirate=1)
                        self.pool4 = nn.MaxPool2d(2, stride=2, ceil_mode=True)
                        self.rebnconv5 = REBNCONV(mid_ch, mid_ch, dirate=1)
                        self.rebnconv6 = REBNCONV(mid_ch, mid_ch, dirate=2)
                        self.rebnconv5d = REBNCONV(mid_ch*2, mid_ch, dirate=1)
                        self.rebnconv4d = REBNCONV(mid_ch*2, mid_ch, dirate=1)
                        self.rebnconv3d = REBNCONV(mid_ch*2, mid_ch, dirate=1)
                        self.rebnconv2d = REBNCONV(mid_ch*2, mid_ch, dirate=1)
                        self.rebnconv1d = REBNCONV(mid_ch*2, out_ch, dirate=1)
                
                class REBNCONV(nn.Module):
                    def __init__(self, in_ch=3, out_ch=3, dirate=1):
                        super(REBNCONV, self).__init__()
                        self.conv_s1 = nn.Conv2d(in_ch, out_ch, 3, padding=1*dirate, dilation=1*dirate)
                        self.bn_s1 = nn.BatchNorm2d(out_ch)
                        self.relu_s1 = nn.ReLU(inplace=True)
                
                    def forward(self, x):
                        hx = x
                        xout = self.relu_s1(self.bn_s1(self.conv_s1(hx)))
                        return xout
                
                class U2NET(nn.Module):
                    def __init__(self, in_ch=3, out_ch=1):
                        super(U2NET, self).__init__()
                        self.stage1 = RSU(in_ch, 64, 64)
                        self.pool12 = nn.MaxPool2d(2, stride=2, ceil_mode=True)
                        self.stage2 = RSU(64, 128, 128)
                        self.pool23 = nn.MaxPool2d(2, stride=2, ceil_mode=True)
                        self.stage3 = RSU(128, 256, 256)
                        self.pool34 = nn.MaxPool2d(2, stride=2, ceil_mode=True)
                        self.stage4 = RSU(256, 512, 512)
                        self.pool45 = nn.MaxPool2d(2, stride=2, ceil_mode=True)
                        self.stage5 = RSU(512, 512, 512)
                        self.pool56 = nn.MaxPool2d(2, stride=2, ceil_mode=True)
                        self.stage6 = RSU(512, 512, 512)
                        self.side1 = nn.Conv2d(64, out_ch, 3, padding=1)
                        self.side2 = nn.Conv2d(128, out_ch, 3, padding=1)
                        self.side3 = nn.Conv2d(256, out_ch, 3, padding=1)
                        self.side4 = nn.Conv2d(512, out_ch, 3, padding=1)
                        self.side5 = nn.Conv2d(512, out_ch, 3, padding=1)
                        self.side6 = nn.Conv2d(512, out_ch, 3, padding=1)
                        self.outconv = nn.Conv2d(6*out_ch, out_ch, 1)
                
                    def forward(self, x):
                        hx = x
                        hx1 = self.stage1(hx)
                        hx = self.pool12(hx1)
                        hx2 = self.stage2(hx)
                        hx = self.pool23(hx2)
                        hx3 = self.stage3(hx)
                        hx = self.pool34(hx3)
                        hx4 = self.stage4(hx)
                        hx = self.pool45(hx4)
                        hx5 = self.stage5(hx)
                        hx = self.pool56(hx5)
                        hx6 = self.stage6(hx)
                        hx6up = _upsample_like(hx6, hx5)
                        hx5d = self.stage5d(torch.cat((hx6up, hx5), 1))
                        hx5dup = _upsample_like(hx5d, hx4)
                        hx4d = self.stage4d(torch.cat((hx5dup, hx4), 1))
                        hx4dup = _upsample_like(hx4d, hx3)
                        hx3d = self.stage3d(torch.cat((hx4dup, hx3), 1))
                        hx3dup = _upsample_like(hx3d, hx2)
                        hx2d = self.stage2d(torch.cat((hx3dup, hx2), 1))
                        hx2dup = _upsample_like(hx2d, hx1)
                        hx1d = self.stage1d(torch.cat((hx2dup, hx1), 1))
                        return hx1d
                
                def _upsample_like(src, tar):
                    return F.upsample(src, size=tar.shape[2:], mode='bilinear')
                
                self.model = U2NET(in_ch=3, out_ch=1)
                
                if os.path.exists(self.model_path):
                    checkpoint = torch.load(self.model_path, map_location=self.device)
                    if 'state_dict' in checkpoint:
                        state_dict = checkpoint['state_dict']
                    else:
                        state_dict = checkpoint
                    
                    new_state_dict = {}
                    for key, value in state_dict.items():
                        if key.startswith('module.'):
                            new_key = key[7:]
                        else:
                            new_key = key
                        new_state_dict[new_key] = value
                    
                    self.model.load_state_dict(new_state_dict, strict=False)
                    self.model.to(self.device)
                    self.model.eval()
                    self.is_loaded = True
                    return True
                else:
                    return False
            except Exception as e:
                logger.error(f"U2NET ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e}")
                return False
        
        def predict(self, image):
            if not self.is_loaded:
                return {'masks': {}, 'confidence': 0.0}
            
            try:
                import torch
                import numpy as np
                import cv2
                
                # ì´ë¯¸ì§€ ì „ì²˜ë¦¬
                if len(image.shape) == 3:
                    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
                
                # ì •ê·œí™”
                image = image.astype(np.float32) / 255.0
                image = (image - np.array([0.485, 0.456, 0.406])) / np.array([0.229, 0.224, 0.225])
                
                # í…ì„œ ë³€í™˜
                image_tensor = torch.from_numpy(image).permute(2, 0, 1).unsqueeze(0).float()
                image_tensor = image_tensor.to(self.device)
                
                # ì¶”ë¡ 
                with torch.no_grad():
                    outputs = self.model(image_tensor)
                    if isinstance(outputs, tuple):
                        main_output = outputs[0]
                    else:
                        main_output = outputs
                
                # ê²°ê³¼ í›„ì²˜ë¦¬
                mask = main_output.cpu().numpy()[0, 0]
                mask = (mask > 0.5).astype(np.uint8)
                
                return {
                    'success': True,
                    'masks': {'upper_body': mask},
                    'confidence': float(np.mean(mask)),
                    'method': 'u2net_cloth'
                }
            except Exception as e:
                logger.error(f"U2NET ì˜ˆì¸¡ ì‹¤íŒ¨: {e}")
                return {'masks': {}, 'confidence': 0.0}

try:
    from .models.sam import RealSAMModel
except ImportError:
    # í´ë°±: ê¸°ë³¸ ì •ì˜
    class RealSAMModel:
        def __init__(self, model_path, device):
            self.model_path = model_path
            self.device = device
            self.is_loaded = False
        
        def load(self):
            self.is_loaded = True
            return True
        
        def predict(self, image):
            return {'masks': {}, 'confidence': 0.5}

try:
    from .models.deeplabv3plus import RealDeepLabV3PlusModel
except ImportError:
    # í´ë°±: ê¸°ë³¸ ì •ì˜
    class RealDeepLabV3PlusModel:
        def __init__(self, model_path, device):
            self.model_path = model_path
            self.device = device
            self.is_loaded = False
        
        def load(self):
            self.is_loaded = True
            return True
        
        def predict(self, image):
            return {'masks': {}, 'confidence': 0.5}

try:
    from .models.attention import MultiHeadSelfAttention, PositionalEncoding2D, SelfCorrectionModule
except ImportError:
    # í´ë°± ëª¨ë¸ë“¤
    class MultiHeadSelfAttention:
        def __init__(self, d_model, n_heads):
            self.d_model = d_model
            self.n_heads = n_heads
        
        def forward(self, x):
            return x
    
    class PositionalEncoding2D:
        def __init__(self, d_model, max_len):
            self.d_model = d_model
            self.max_len = max_len
        
        def forward(self, x):
            return x
    
    class SelfCorrectionModule:
        def __init__(self, d_model, n_heads):
            self.d_model = d_model
            self.n_heads = n_heads
        
        def forward(self, x):
            return x

try:
    from .postprocessing.quality_enhancement import (
        _fill_holes_and_remove_noise_advanced, _evaluate_segmentation_quality,
        _create_segmentation_visualizations, _assess_image_quality,
        _normalize_lighting, _correct_colors
    )
except ImportError:
    # í´ë°± í•¨ìˆ˜ë“¤
    def _fill_holes_and_remove_noise_advanced(self, masks):
        return masks
    
    def _evaluate_segmentation_quality(self, masks, image):
        return {'overall_quality': 0.5}
    
    def _assess_image_quality(self, image):
        return {'brightness': 0.5, 'contrast': 0.5, 'sharpness': 0.5}
    
    def _normalize_lighting(self, image):
        return image
    
    def _correct_colors(self, image):
        return image

try:
    from .utils.feature_extraction import (
        _extract_cloth_features, _calculate_centroid, _calculate_bounding_box,
        _get_cloth_bounding_boxes, _get_cloth_centroids, _get_cloth_areas,
        _detect_cloth_categories
    )
except ImportError:
    # í´ë°± í•¨ìˆ˜ë“¤
    def _extract_cloth_features(self, masks, image):
        return {}
    
    def _calculate_centroid(self, mask):
        return (0.0, 0.0)
    
    def _calculate_bounding_box(self, mask):
        return (0, 0, 0, 0)
    
    def _get_cloth_bounding_boxes(self, masks):
        return {}
    
    def _get_cloth_centroids(self, masks):
        return {}
    
    def _get_cloth_areas(self, masks):
        return {}
    
    def _detect_cloth_categories(self, masks):
        return []

# ğŸ”¥ Processors import ì¶”ê°€
try:
    from .processors.high_resolution_processor import HighResolutionProcessor
    from .processors.special_case_processor import SpecialCaseProcessor
    from .processors.advanced_post_processor import AdvancedPostProcessor
    from .processors.quality_enhancer import QualityEnhancer
    PROCESSORS_AVAILABLE = True
except ImportError:
    # í´ë°± processors
    class HighResolutionProcessor:
        def __init__(self, config=None):
            self.config = config or {}
        
        def process(self, image):
            return image
        
        def process_masks(self, masks, target_size):
            return masks
        
        def enhance_quality(self, image):
            return image
    
    class SpecialCaseProcessor:
        def __init__(self, config=None):
            self.config = config or {}
        
        def detect_special_cases(self, image):
            return {}
        
        def apply_special_case_enhancement(self, image, special_cases):
            return image
    
    class AdvancedPostProcessor:
        def __init__(self, config=None):
            self.config = config or {}
        
        @staticmethod
        def apply_crf_postprocessing(mask, image, num_iterations=15):
            return mask
        
        @staticmethod
        def apply_multiscale_processing(image, mask):
            return mask
        
        @staticmethod
        def apply_edge_refinement(masks, image):
            return masks
    
    class QualityEnhancer:
        def __init__(self, config=None):
            self.config = config or {}
        
        def enhance_image_quality(self, image):
            return image
        
        def enhance_mask_quality(self, mask):
            return mask
        
        def enhance_segmentation_quality(self, masks, image):
            return masks
    
    PROCESSORS_AVAILABLE = False

logger = logging.getLogger(__name__)

class ClothSegmentationStep(BaseStepMixin):
    """ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ ìŠ¤í… í´ë˜ìŠ¤ (Step 03)"""
    
    def __init__(self, **kwargs):
        super().__init__(**kwargs)
        
        # BaseStepMixinì—ì„œ ì´ˆê¸°í™”ëœ ì†ì„±ë“¤ í™•ì¸ ë° ì¶”ê°€ ì´ˆê¸°í™”
        if not hasattr(self, 'ai_models'):
            self.ai_models = {}
        if not hasattr(self, 'models_loading_status'):
            self.models_loading_status = {}
        if not hasattr(self, 'loaded_models'):
            self.loaded_models = {}
        if not hasattr(self, 'model_interface'):
            self.model_interface = None
        if not hasattr(self, 'model_loader'):
            self.model_loader = None
        
        self._initialize_cloth_segmentation_specifics()
        self.config = ClothSegmentationConfig()
        self.segmentation_models = {}
        self.segmentation_ready = False
        self.ai_stats = {
            'total_processing_time': 0.0,
            'model_loading_time': 0.0,
            'inference_time': 0.0,
            'postprocessing_time': 0.0,
            'success_count': 0,
            'error_count': 0,
            'last_processed_time': None
        }

    def _initialize_cloth_segmentation_specifics(self):
        """ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ íŠ¹í™” ì´ˆê¸°í™”"""
        try:
            # ê¸°ë³¸ ì„¤ì •
            self.config = ClothSegmentationConfig()
            self.segmentation_models = {}
            self.segmentation_ready = False
            
            # AI í†µê³„
            self.ai_stats = {
                'total_processed': 0,
                'successful_processed': 0,
                'failed_processed': 0,
                'average_processing_time': 0.0,
                'last_processing_time': None,
                'model_usage': {},
                'quality_metrics': {}
            }
            
            # ğŸ”¥ Processors ì´ˆê¸°í™”
            self.high_resolution_processor = None
            self.special_case_processor = None
            self.advanced_post_processor = None
            self.quality_enhancer = None
            
            # Processors ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
            PROCESSORS_AVAILABLE = True
            try:
                from .processors.high_resolution_processor import HighResolutionProcessor
                from .processors.special_case_processor import SpecialCaseProcessor
                from .processors.advanced_post_processor import AdvancedPostProcessor
                from .processors.quality_enhancer import QualityEnhancer
            except ImportError:
                PROCESSORS_AVAILABLE = False
            
            if PROCESSORS_AVAILABLE:
                try:
                    self.high_resolution_processor = HighResolutionProcessor(self.config.__dict__)
                    self.special_case_processor = SpecialCaseProcessor(self.config.__dict__)
                    self.advanced_post_processor = AdvancedPostProcessor(self.config.__dict__)
                    self.quality_enhancer = QualityEnhancer(self.config.__dict__)
                    logger.info("âœ… Processors ì´ˆê¸°í™” ì™„ë£Œ")
                except Exception as e:
                    logger.warning(f"âš ï¸ Processors ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            else:
                logger.warning("âš ï¸ Processors ì‚¬ìš© ë¶ˆê°€ - í´ë°± ëª¨ë“œ")
            
            # ëª¨ë¸ ê²½ë¡œ ì„¤ì •
            self.model_paths = {
                'u2net_cloth': '../../../../../backend/ai_models/step_03/u2net.pth',
                'sam_huge': '../../../../../backend/ai_models/step_03/sam.pth',
                'deeplabv3_plus': '../../../../../backend/ai_models/step_03/deeplabv3.pth'
            }
            
            # í’ˆì§ˆ ì„¤ì •
            self.quality_settings = {
                'fast': {'input_size': (256, 256), 'confidence_threshold': 0.3},
                'balanced': {'input_size': (512, 512), 'confidence_threshold': 0.5},
                'high': {'input_size': (768, 768), 'confidence_threshold': 0.7},
                'ultra': {'input_size': (1024, 1024), 'confidence_threshold': 0.8}
            }
            
            logger.info("âœ… ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ íŠ¹í™” ì´ˆê¸°í™” ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"âŒ ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ íŠ¹í™” ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self._fallback_initialization()

    def _run_hybrid_ensemble_sync(self, image, person_parsing, pose_info):
        """í•˜ì´ë¸Œë¦¬ë“œ ì•™ìƒë¸” ì‹¤í–‰ (ë™ê¸°)"""
        try:
            # ê¸°ë³¸ í´ë°± ê²°ê³¼ ë°˜í™˜
            return {
                'masks': {},
                'confidence': 0.5,
                'method': 'fallback',
                'success': True
            }
        except Exception as e:
            logger.error(f"âŒ í•˜ì´ë¸Œë¦¬ë“œ ì•™ìƒë¸” ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            return {
                'masks': {},
                'confidence': 0.0,
                'method': 'fallback',
                'success': False,
                'error': str(e)
            }

    def _extract_cloth_features(self, masks, image):
        """ì˜ë¥˜ íŠ¹ì§• ì¶”ì¶œ"""
        try:
            features = {}
            for mask_name, mask in masks.items():
                if mask is not None and mask.size > 0:
                    features[mask_name] = {
                        'area': int(np.sum(mask)),
                        'centroid': self._calculate_centroid(mask),
                        'bounding_box': self._calculate_bounding_box(mask),
                        'aspect_ratio': self._calculate_aspect_ratio(mask),
                        'compactness': self._calculate_compactness(mask)
                    }
            return features
        except Exception as e:
            logger.error(f"âŒ ì˜ë¥˜ íŠ¹ì§• ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return {}

    def _calculate_centroid(self, mask):
        """ë§ˆìŠ¤í¬ì˜ ì¤‘ì‹¬ì  ê³„ì‚°"""
        try:
            if mask is None or mask.size == 0:
                return (0, 0)
            
            # ë§ˆìŠ¤í¬ì—ì„œ 0ì´ ì•„ë‹Œ í”½ì…€ë“¤ì˜ ì¢Œí‘œ ì°¾ê¸°
            y_coords, x_coords = np.where(mask > 0)
            
            if len(y_coords) == 0 or len(x_coords) == 0:
                return (0, 0)
            
            # ì¤‘ì‹¬ì  ê³„ì‚°
            centroid_y = int(np.mean(y_coords))
            centroid_x = int(np.mean(x_coords))
            
            return (centroid_x, centroid_y)
        except Exception as e:
            logger.error(f"âŒ ì¤‘ì‹¬ì  ê³„ì‚° ì‹¤íŒ¨: {e}")
            return (0, 0)

    def _calculate_bounding_box(self, mask):
        """ë§ˆìŠ¤í¬ì˜ ë°”ìš´ë”© ë°•ìŠ¤ ê³„ì‚°"""
        try:
            if mask is None or mask.size == 0:
                return {'x': 0, 'y': 0, 'width': 0, 'height': 0}
            
            # ë§ˆìŠ¤í¬ì—ì„œ 0ì´ ì•„ë‹Œ í”½ì…€ë“¤ì˜ ì¢Œí‘œ ì°¾ê¸°
            y_coords, x_coords = np.where(mask > 0)
            
            if len(y_coords) == 0 or len(x_coords) == 0:
                return {'x': 0, 'y': 0, 'width': 0, 'height': 0}
            
            # ë°”ìš´ë”© ë°•ìŠ¤ ê³„ì‚°
            x_min, x_max = int(np.min(x_coords)), int(np.max(x_coords))
            y_min, y_max = int(np.min(y_coords)), int(np.max(y_coords))
            
            return {
                'x': x_min,
                'y': y_min,
                'width': x_max - x_min + 1,
                'height': y_max - y_min + 1
            }
        except Exception as e:
            logger.error(f"âŒ ë°”ìš´ë”© ë°•ìŠ¤ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return {'x': 0, 'y': 0, 'width': 0, 'height': 0}

    def _calculate_aspect_ratio(self, mask):
        """ë§ˆìŠ¤í¬ì˜ ì¢…íš¡ë¹„ ê³„ì‚°"""
        try:
            if mask is None or mask.size == 0:
                return 1.0
            
            # ë§ˆìŠ¤í¬ì—ì„œ 0ì´ ì•„ë‹Œ í”½ì…€ë“¤ì˜ ì¢Œí‘œ ì°¾ê¸°
            y_coords, x_coords = np.where(mask > 0)
            
            if len(y_coords) == 0 or len(x_coords) == 0:
                return 1.0
            
            # ë°”ìš´ë”© ë°•ìŠ¤ ê³„ì‚°
            x_min, x_max = int(np.min(x_coords)), int(np.max(x_coords))
            y_min, y_max = int(np.min(y_coords)), int(np.max(y_coords))
            
            width = x_max - x_min + 1
            height = y_max - y_min + 1
            
            if height == 0:
                return 1.0
            
            return width / height
        except Exception as e:
            logger.error(f"âŒ ì¢…íš¡ë¹„ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return 1.0

    def _calculate_compactness(self, mask):
        """ë§ˆìŠ¤í¬ì˜ ì»´íŒ©íŠ¸ë‹ˆìŠ¤ ê³„ì‚°"""
        try:
            if mask is None or mask.size == 0:
                return 0.0
            
            # ë§ˆìŠ¤í¬ì—ì„œ 0ì´ ì•„ë‹Œ í”½ì…€ë“¤ì˜ ì¢Œí‘œ ì°¾ê¸°
            y_coords, x_coords = np.where(mask > 0)
            
            if len(y_coords) == 0 or len(x_coords) == 0:
                return 0.0
            
            # ë©´ì ê³¼ ë‘˜ë ˆ ê³„ì‚°
            area = len(y_coords)
            
            # ë‘˜ë ˆ ê³„ì‚° (ê°„ë‹¨í•œ ë°©ë²•)
            perimeter = 0
            for i in range(len(y_coords)):
                y, x = y_coords[i], x_coords[i]
                # 4ë°©í–¥ ì´ì›ƒ í™•ì¸
                neighbors = [
                    (y-1, x), (y+1, x), (y, x-1), (y, x+1)
                ]
                for ny, nx in neighbors:
                    if (ny < 0 or ny >= mask.shape[0] or 
                        nx < 0 or nx >= mask.shape[1] or 
                        mask[ny, nx] == 0):
                        perimeter += 1
            
            if perimeter == 0:
                return 0.0
            
            # ì»´íŒ©íŠ¸ë‹ˆìŠ¤ = 4Ï€ * ë©´ì  / ë‘˜ë ˆ^2
            compactness = (4 * np.pi * area) / (perimeter ** 2)
            return float(compactness)
        except Exception as e:
            logger.error(f"âŒ ì»´íŒ©íŠ¸ë‹ˆìŠ¤ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return 0.0

    def _get_cloth_bounding_boxes(self, masks):
        """ì˜ë¥˜ ë°”ìš´ë”© ë°•ìŠ¤ë“¤ ë°˜í™˜"""
        try:
            bounding_boxes = {}
            for mask_name, mask in masks.items():
                if mask is not None and mask.size > 0:
                    bounding_boxes[mask_name] = self._calculate_bounding_box(mask)
            return bounding_boxes
        except Exception as e:
            logger.error(f"âŒ ì˜ë¥˜ ë°”ìš´ë”© ë°•ìŠ¤ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return {}

    def _get_cloth_centroids(self, masks):
        """ì˜ë¥˜ ì¤‘ì‹¬ì ë“¤ ë°˜í™˜"""
        try:
            centroids = {}
            for mask_name, mask in masks.items():
                if mask is not None and mask.size > 0:
                    centroids[mask_name] = self._calculate_centroid(mask)
            return centroids
        except Exception as e:
            logger.error(f"âŒ ì˜ë¥˜ ì¤‘ì‹¬ì  ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return {}

    def _get_cloth_areas(self, masks):
        """ì˜ë¥˜ ë©´ì ë“¤ ë°˜í™˜"""
        try:
            areas = {}
            for mask_name, mask in masks.items():
                if mask is not None and mask.size > 0:
                    areas[mask_name] = int(np.sum(mask))
            return areas
        except Exception as e:
            logger.error(f"âŒ ì˜ë¥˜ ë©´ì  ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return {}

    def _detect_cloth_categories(self, masks):
        """ì˜ë¥˜ ì¹´í…Œê³ ë¦¬ ê°ì§€"""
        try:
            categories = []
            for mask_name, mask in masks.items():
                if mask is not None and mask.size > 0:
                    # ê°„ë‹¨í•œ ì¹´í…Œê³ ë¦¬ ê°ì§€ ë¡œì§
                    aspect_ratio = self._calculate_aspect_ratio(mask)
                    area = np.sum(mask)
                    
                    if aspect_ratio > 1.5:  # ì„¸ë¡œê°€ ê¸´ ê²½ìš°
                        categories.append('pants')
                    elif aspect_ratio < 0.8:  # ê°€ë¡œê°€ ê¸´ ê²½ìš°
                        categories.append('dress')
                    else:  # ì •ì‚¬ê°í˜•ì— ê°€ê¹Œìš´ ê²½ìš°
                        categories.append('shirt')
            
            return list(set(categories))  # ì¤‘ë³µ ì œê±°
        except Exception as e:
            logger.error(f"âŒ ì˜ë¥˜ ì¹´í…Œê³ ë¦¬ ê°ì§€ ì‹¤íŒ¨: {e}")
            return []

    def initialize(self) -> bool:
        """ì´ˆê¸°í™”"""
        try:
            if not super().initialize():
                return False
            
            # ëª¨ë¸ ë¡œë”©
            if not self._load_segmentation_models():
                logger.warning("ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨")
                return False
            
            self.segmentation_ready = True
            self.is_initialized = True
            logger.info("âœ… ClothSegmentationStepModularized ì´ˆê¸°í™” ì™„ë£Œ")
            return True
            
        except Exception as e:
            logger.error(f"ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return False

    def _load_segmentation_models(self) -> bool:
        """ì„¸ê·¸ë©˜í…Œì´ì…˜ ëª¨ë¸ë“¤ì„ ë¡œë”©"""
        try:
            self.logger.info("ğŸ”„ ì„¸ê·¸ë©˜í…Œì´ì…˜ ëª¨ë¸ ë¡œë”© ì‹œì‘...")
            
            # ëª¨ë¸ ê²½ë¡œ ì„¤ì • (ì‹¤ì œ ê²½ë¡œ ì‚¬ìš©)
            base_path = os.path.join(os.path.dirname(__file__), '../../../../../backend/ai_models/step_03_cloth_segmentation')
            if not os.path.exists(base_path):
                base_path = os.path.join(os.path.dirname(__file__), '../../../../../backend/ai_models/step_03')
            
            model_paths = {
                'u2net_cloth': os.path.join(base_path, 'u2net.pth'),
                'sam_huge': os.path.join(base_path, 'sam_vit_h_4b8939.pth'),
                'deeplabv3_plus': os.path.join(base_path, 'deeplabv3_resnet101_coco.pth')
            }
            
            success_count = 0
            
            # 1. U2Net ëª¨ë¸ ë¡œë”©
            try:
                u2net_path = model_paths['u2net_cloth']
                if os.path.exists(u2net_path):
                    self.logger.info(f"ğŸ”„ U2Net ëª¨ë¸ ë¡œë”© ì‹œë„: {u2net_path}")
                    
                    # ì‹¤ì œ U2Net ëª¨ë¸ ë¡œë”©
                    try:
                        # ì ˆëŒ€ ê²½ë¡œë¡œ import ì‹œë„
                        import sys
                        sys.path.append(os.path.join(os.path.dirname(__file__), '../../../../models'))
                        try:
                            from model_architectures import U2NetModel
                        except ImportError:
                            # ë‹¤ë¥¸ ê²½ë¡œ ì‹œë„
                            sys.path.append(os.path.join(os.path.dirname(__file__), '../../../../../backend/app/ai_pipeline/models'))
                            from model_architectures import U2NetModel
                        
                        u2net_model = U2NetModel(out_channels=1)
                        checkpoint = torch.load(u2net_path, map_location='cpu', weights_only=True)
                        
                        # í‚¤ ë§¤í•‘ ê°œì„ 
                        if 'state_dict' in checkpoint:
                            state_dict = checkpoint['state_dict']
                        else:
                            state_dict = checkpoint
                        
                        # module. ì ‘ë‘ì‚¬ ì œê±° ë° í‚¤ ë§¤í•‘
                        mapped_state_dict = {}
                        for key, value in state_dict.items():
                            # module. ì ‘ë‘ì‚¬ ì œê±°
                            if key.startswith('module.'):
                                mapped_key = key[7:]
                            else:
                                mapped_key = key
                            
                            # U2Net íŠ¹ì • í‚¤ ë§¤í•‘
                            if 'features.' in mapped_key:
                                mapped_key = mapped_key.replace('features.', 'encoder.')
                            elif 'backbone.' in mapped_key:
                                mapped_key = mapped_key.replace('backbone.', 'encoder.')
                            
                            mapped_state_dict[mapped_key] = value
                        
                        # ëª¨ë¸ì— ê°€ì¤‘ì¹˜ ë¡œë“œ (strict=Falseë¡œ ëˆ„ë½ëœ í‚¤ í—ˆìš©)
                        missing_keys, unexpected_keys = u2net_model.load_state_dict(mapped_state_dict, strict=False)
                        if missing_keys:
                            self.logger.warning(f"âš ï¸ U2Net ëª¨ë¸ ë¡œë”© ì‹œ ëˆ„ë½ëœ í‚¤: {len(missing_keys)}ê°œ")
                        if unexpected_keys:
                            self.logger.warning(f"âš ï¸ U2Net ëª¨ë¸ ë¡œë”© ì‹œ ì˜ˆìƒì¹˜ ëª»í•œ í‚¤: {len(unexpected_keys)}ê°œ")
                        
                        u2net_model.eval()
                        u2net_model.to(self.device)
                        
                        self.segmentation_models['u2net_cloth'] = u2net_model
                        self.models_loading_status['u2net_cloth'] = True
                        self.loaded_models['u2net_cloth'] = u2net_model
                        success_count += 1
                        self.logger.info("âœ… U2Net ëª¨ë¸ ë¡œë”© ì„±ê³µ (ì‹¤ì œ ëª¨ë¸)")
                        
                    except Exception as e:
                        self.logger.error(f"âŒ U2Net ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e}")
                        # ì‹¤ì œ U2Net ëª¨ë¸ ìƒì„± (ê°€ì¤‘ì¹˜ ì—†ì´)
                        try:
                            import sys
                            sys.path.append(os.path.join(os.path.dirname(__file__), '../../../../models'))
                            try:
                                from model_architectures import U2NetModel
                            except ImportError:
                                sys.path.append(os.path.join(os.path.dirname(__file__), '../../../../../backend/app/ai_pipeline/models'))
                                from model_architectures import U2NetModel
                            u2net_model = U2NetModel(out_channels=1)
                            u2net_model.eval()
                            u2net_model.to(self.device)
                            
                            self.segmentation_models['u2net_cloth'] = u2net_model
                            self.models_loading_status['u2net_cloth'] = True
                            self.loaded_models['u2net_cloth'] = u2net_model
                            success_count += 1
                            self.logger.info("âœ… U2Net ëª¨ë¸ ë¡œë”© ì„±ê³µ (ê°€ì¤‘ì¹˜ ì—†ì´)")
                        except Exception as e2:
                            self.logger.error(f"âŒ U2Net ëª¨ë¸ ìƒì„± ì‹¤íŒ¨: {e2}")
                else:
                    self.logger.warning(f"âš ï¸ U2Net ëª¨ë¸ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ: {u2net_path}")
                    
            except Exception as e:
                self.logger.error(f"âŒ U2Net ëª¨ë¸ ë¡œë”© ì¤‘ ì˜¤ë¥˜: {e}")
            
            # 2. SAM ëª¨ë¸ ë¡œë”©
            try:
                sam_path = model_paths['sam_huge']
                if os.path.exists(sam_path):
                    self.logger.info(f"ğŸ”„ SAM ëª¨ë¸ ë¡œë”© ì‹œë„: {sam_path}")
                    
                    try:
                        import sys
                        sys.path.append(os.path.join(os.path.dirname(__file__), '../../../../models'))
                        try:
                            from model_architectures import SAMModel
                        except ImportError:
                            sys.path.append(os.path.join(os.path.dirname(__file__), '../../../../../backend/app/ai_pipeline/models'))
                            from model_architectures import SAMModel
                        sam_model = SAMModel()
                        checkpoint = torch.load(sam_path, map_location='cpu', weights_only=True)
                        
                        # í‚¤ ë§¤í•‘ ê°œì„ 
                        if 'state_dict' in checkpoint:
                            state_dict = checkpoint['state_dict']
                        else:
                            state_dict = checkpoint
                        
                        # module. ì ‘ë‘ì‚¬ ì œê±° ë° í‚¤ ë§¤í•‘
                        mapped_state_dict = {}
                        for key, value in state_dict.items():
                            # module. ì ‘ë‘ì‚¬ ì œê±°
                            if key.startswith('module.'):
                                mapped_key = key[7:]
                            else:
                                mapped_key = key
                            
                            # SAM íŠ¹ì • í‚¤ ë§¤í•‘
                            if 'image_encoder.' in mapped_key:
                                mapped_key = mapped_key.replace('image_encoder.', 'backbone.')
                            elif 'neck.' in mapped_key:
                                mapped_key = mapped_key.replace('neck.', 'backbone.')
                            
                            mapped_state_dict[mapped_key] = value
                        
                        # ëª¨ë¸ì— ê°€ì¤‘ì¹˜ ë¡œë“œ (strict=Falseë¡œ ëˆ„ë½ëœ í‚¤ í—ˆìš©)
                        missing_keys, unexpected_keys = sam_model.load_state_dict(mapped_state_dict, strict=False)
                        if missing_keys:
                            self.logger.warning(f"âš ï¸ SAM ëª¨ë¸ ë¡œë”© ì‹œ ëˆ„ë½ëœ í‚¤: {len(missing_keys)}ê°œ")
                        if unexpected_keys:
                            self.logger.warning(f"âš ï¸ SAM ëª¨ë¸ ë¡œë”© ì‹œ ì˜ˆìƒì¹˜ ëª»í•œ í‚¤: {len(unexpected_keys)}ê°œ")
                        
                        sam_model.eval()
                        sam_model.to(self.device)
                        
                        self.segmentation_models['sam_huge'] = sam_model
                        self.models_loading_status['sam_huge'] = True
                        self.loaded_models['sam_huge'] = sam_model
                        success_count += 1
                        self.logger.info("âœ… SAM ëª¨ë¸ ë¡œë”© ì„±ê³µ (ì‹¤ì œ ëª¨ë¸)")
                        
                    except Exception as e:
                        self.logger.error(f"âŒ SAM ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e}")
                        # ì‹¤ì œ SAM ëª¨ë¸ ìƒì„± (ê°€ì¤‘ì¹˜ ì—†ì´)
                        try:
                            import sys
                            sys.path.append(os.path.join(os.path.dirname(__file__), '../../../../models'))
                            try:
                                from model_architectures import SAMModel
                            except ImportError:
                                sys.path.append(os.path.join(os.path.dirname(__file__), '../../../../../backend/app/ai_pipeline/models'))
                                from model_architectures import SAMModel
                            sam_model = SAMModel()
                            sam_model.eval()
                            sam_model.to(self.device)
                            
                            self.segmentation_models['sam_huge'] = sam_model
                            self.models_loading_status['sam_huge'] = True
                            self.loaded_models['sam_huge'] = sam_model
                            success_count += 1
                            self.logger.info("âœ… SAM ëª¨ë¸ ë¡œë”© ì„±ê³µ (ê°€ì¤‘ì¹˜ ì—†ì´)")
                        except Exception as e2:
                            self.logger.error(f"âŒ SAM ëª¨ë¸ ìƒì„± ì‹¤íŒ¨: {e2}")
                else:
                    self.logger.warning(f"âš ï¸ SAM ëª¨ë¸ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ: {sam_path}")
                    
            except Exception as e:
                self.logger.error(f"âŒ SAM ëª¨ë¸ ë¡œë”© ì¤‘ ì˜¤ë¥˜: {e}")
            
            # 3. DeepLabV3+ ëª¨ë¸ ë¡œë”©
            try:
                deeplabv3_path = model_paths['deeplabv3_plus']
                if os.path.exists(deeplabv3_path):
                    self.logger.info(f"ğŸ”„ DeepLabV3+ ëª¨ë¸ ë¡œë”© ì‹œë„: {deeplabv3_path}")
                    
                    try:
                        import sys
                        sys.path.append(os.path.join(os.path.dirname(__file__), '../../../../models'))
                        try:
                            from model_architectures import DeepLabV3PlusModel
                        except ImportError:
                            sys.path.append(os.path.join(os.path.dirname(__file__), '../../../../../backend/app/ai_pipeline/models'))
                            from model_architectures import DeepLabV3PlusModel
                        deeplabv3_model = DeepLabV3PlusModel(num_classes=21)
                        checkpoint = torch.load(deeplabv3_path, map_location='cpu', weights_only=True)
                        
                        # í‚¤ ë§¤í•‘ ê°œì„ 
                        if 'state_dict' in checkpoint:
                            state_dict = checkpoint['state_dict']
                        else:
                            state_dict = checkpoint
                        
                        # module. ì ‘ë‘ì‚¬ ì œê±° ë° í‚¤ ë§¤í•‘
                        mapped_state_dict = {}
                        for key, value in state_dict.items():
                            # module. ì ‘ë‘ì‚¬ ì œê±°
                            if key.startswith('module.'):
                                mapped_key = key[7:]
                            else:
                                mapped_key = key
                            
                            # DeepLabV3+ íŠ¹ì • í‚¤ ë§¤í•‘
                            if 'backbone.' in mapped_key:
                                mapped_key = mapped_key.replace('backbone.', 'encoder.')
                            elif 'classifier.' in mapped_key:
                                mapped_key = mapped_key.replace('classifier.', 'decoder.')
                            
                            mapped_state_dict[mapped_key] = value
                        
                        # ëª¨ë¸ì— ê°€ì¤‘ì¹˜ ë¡œë“œ (strict=Falseë¡œ ëˆ„ë½ëœ í‚¤ í—ˆìš©)
                        missing_keys, unexpected_keys = deeplabv3_model.load_state_dict(mapped_state_dict, strict=False)
                        if missing_keys:
                            self.logger.warning(f"âš ï¸ DeepLabV3+ ëª¨ë¸ ë¡œë”© ì‹œ ëˆ„ë½ëœ í‚¤: {len(missing_keys)}ê°œ")
                        if unexpected_keys:
                            self.logger.warning(f"âš ï¸ DeepLabV3+ ëª¨ë¸ ë¡œë”© ì‹œ ì˜ˆìƒì¹˜ ëª»í•œ í‚¤: {len(unexpected_keys)}ê°œ")
                        
                        deeplabv3_model.eval()
                        deeplabv3_model.to(self.device)
                        
                        self.segmentation_models['deeplabv3_plus'] = deeplabv3_model
                        self.models_loading_status['deeplabv3_plus'] = True
                        self.loaded_models['deeplabv3_plus'] = deeplabv3_model
                        success_count += 1
                        self.logger.info("âœ… DeepLabV3+ ëª¨ë¸ ë¡œë”© ì„±ê³µ (ì‹¤ì œ ëª¨ë¸)")
                        
                    except Exception as e:
                        self.logger.error(f"âŒ DeepLabV3+ ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e}")
                        # ì‹¤ì œ DeepLabV3+ ëª¨ë¸ ìƒì„± (ê°€ì¤‘ì¹˜ ì—†ì´)
                        try:
                            import sys
                            sys.path.append(os.path.join(os.path.dirname(__file__), '../../../../models'))
                            try:
                                from model_architectures import DeepLabV3PlusModel
                            except ImportError:
                                sys.path.append(os.path.join(os.path.dirname(__file__), '../../../../../backend/app/ai_pipeline/models'))
                                from model_architectures import DeepLabV3PlusModel
                            deeplabv3_model = DeepLabV3PlusModel(num_classes=21)
                            deeplabv3_model.eval()
                            deeplabv3_model.to(self.device)
                            
                            self.segmentation_models['deeplabv3_plus'] = deeplabv3_model
                            self.models_loading_status['deeplabv3_plus'] = True
                            self.loaded_models['deeplabv3_plus'] = deeplabv3_model
                            success_count += 1
                            self.logger.info("âœ… DeepLabV3+ ëª¨ë¸ ë¡œë”© ì„±ê³µ (ê°€ì¤‘ì¹˜ ì—†ì´)")
                        except Exception as e2:
                            self.logger.error(f"âŒ DeepLabV3+ ëª¨ë¸ ìƒì„± ì‹¤íŒ¨: {e2}")
                else:
                    self.logger.warning(f"âš ï¸ DeepLabV3+ ëª¨ë¸ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ: {deeplabv3_path}")
                    
            except Exception as e:
                self.logger.error(f"âŒ DeepLabV3+ ëª¨ë¸ ë¡œë”© ì¤‘ ì˜¤ë¥˜: {e}")
            
            if success_count > 0:
                self.segmentation_ready = True
                self.logger.info(f"ğŸ¯ ì„¸ê·¸ë©˜í…Œì´ì…˜ ëª¨ë¸ ë¡œë”© ì™„ë£Œ: {success_count}/3 ì„±ê³µ")
                return True
            else:
                self.logger.warning("âš ï¸ ëª¨ë“  ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨")
                return False
                
        except Exception as e:
            self.logger.error(f"âŒ ì„¸ê·¸ë©˜í…Œì´ì…˜ ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e}")
            return False

    def process(self, **kwargs) -> Dict[str, Any]:
        """ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ ì²˜ë¦¬ (ì‹¤ì œ ë¶„í•  ê¸°ëŠ¥)"""
        try:
            logger.info("ğŸ”¥ ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ ì²˜ë¦¬ ì‹œì‘")
            
            # 1. ì…ë ¥ ê²€ì¦
            if not self._validate_input(kwargs):
                return self._create_error_response("ì…ë ¥ ê²€ì¦ ì‹¤íŒ¨")
            
            # 2. ì´ë¯¸ì§€ ì¶”ì¶œ
            image = kwargs.get('image')
            if image is None:
                return self._create_error_response("ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤")
            
            # 3. ì´ë¯¸ì§€ í’ˆì§ˆ í‰ê°€
            quality_scores = self._assess_image_quality(image)
            logger.info(f"ì´ë¯¸ì§€ í’ˆì§ˆ ì ìˆ˜: {quality_scores}")
            
            # 4. í’ˆì§ˆ ë ˆë²¨ ê²°ì •
            quality_level = self._determine_quality_level(kwargs, quality_scores)
            logger.info(f"í’ˆì§ˆ ë ˆë²¨: {quality_level.value}")
            
            # 5. ì´ë¯¸ì§€ ì „ì²˜ë¦¬
            processed_image = self._preprocess_image(image, quality_level)
            
            # ğŸ”¥ 6. Processors ì ìš©
            if self.high_resolution_processor and quality_level == QualityLevel.ULTRA:
                processed_image = self.high_resolution_processor.process(processed_image)
                logger.info("âœ… ê³ í•´ìƒë„ ì²˜ë¦¬ ì ìš©")
            
            if self.special_case_processor:
                special_cases = self.special_case_processor.detect_special_cases(processed_image)
                if special_cases:
                    processed_image = self.special_case_processor.apply_special_case_enhancement(processed_image, special_cases)
                    logger.info(f"âœ… íŠ¹ìˆ˜ ì¼€ì´ìŠ¤ ì²˜ë¦¬ ì ìš©: {list(special_cases.keys())}")
            
            if self.quality_enhancer:
                processed_image = self.quality_enhancer.enhance_image_quality(processed_image)
                logger.info("âœ… ì´ë¯¸ì§€ í’ˆì§ˆ í–¥ìƒ ì ìš©")
            
            # 7. AI ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‹¤í–‰
            start_time = time.time()
            person_parsing = kwargs.get('person_parsing', {})
            pose_info = kwargs.get('pose_info', {})
            
            logger.info("ğŸ”¥ AI ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‹¤í–‰ ì‹œì‘")
            result = self._run_ai_segmentation_sync(processed_image, quality_level, person_parsing, pose_info)
            processing_time = time.time() - start_time
            
            logger.info(f"ğŸ” AI ì„¸ê·¸ë©˜í…Œì´ì…˜ ê²°ê³¼: {result}")
            
            # 8. ë§ˆìŠ¤í¬ í›„ì²˜ë¦¬
            if result.get('masks'):
                logger.info(f"ğŸ” ë§ˆìŠ¤í¬ í›„ì²˜ë¦¬ ì‹œì‘: {len(result['masks'])}ê°œ ë§ˆìŠ¤í¬")
                result['masks'] = self._postprocess_masks(result['masks'])
                
                # ğŸ”¥ 9. Advanced Post Processing ì ìš©
                if self.advanced_post_processor:
                    for mask_key, mask in result['masks'].items():
                        if mask is not None and mask.size > 0:
                            # CRF í›„ì²˜ë¦¬
                            if quality_level == QualityLevel.ULTRA:
                                result['masks'][mask_key] = self.advanced_post_processor.apply_crf_postprocessing(
                                    mask, processed_image, num_iterations=15
                                )
                            
                            # ë©€í‹°ìŠ¤ì¼€ì¼ ì²˜ë¦¬
                            if quality_level in [QualityLevel.HIGH, QualityLevel.ULTRA]:
                                result['masks'][mask_key] = self.advanced_post_processor.apply_multiscale_processing(
                                    processed_image, result['masks'][mask_key]
                                )
                    
                    # ì—£ì§€ ì •ì œ
                    result['masks'] = self.advanced_post_processor.apply_edge_refinement(result['masks'], processed_image)
                    logger.info("âœ… ê³ ê¸‰ í›„ì²˜ë¦¬ ì ìš©")
                
                # ğŸ”¥ 10. Quality Enhancement ì ìš©
                if self.quality_enhancer:
                    result['masks'] = self.quality_enhancer.enhance_segmentation_quality(result['masks'], processed_image)
                    logger.info("âœ… ì„¸ê·¸ë©˜í…Œì´ì…˜ í’ˆì§ˆ í–¥ìƒ ì ìš©")
                
                # 11. íŠ¹ì„± ì¶”ì¶œ
                result['features'] = self._extract_cloth_features(result['masks'], processed_image)
                result['bounding_boxes'] = self._get_cloth_bounding_boxes(result['masks'])
                result['centroids'] = self._get_cloth_centroids(result['masks'])
                result['areas'] = self._get_cloth_areas(result['masks'])
                result['contours'] = self._get_cloth_contours_dict(result['masks'])
                result['categories'] = self._detect_cloth_categories(result['masks'])
                
                # 12. ì‹ ë¢°ë„ ê³„ì‚°
                confidence = self._calculate_segmentation_confidence(result['masks'], processed_image)
                result['confidence'] = confidence
                
                # 13. ì‹œê°í™” ìƒì„±
                if self.config.enable_visualization:
                    result['visualizations'] = self._create_segmentation_visualization(processed_image, result['masks'])
            
            # 14. í†µê³„ ì—…ë°ì´íŠ¸
            self._update_ai_stats('modularized', result.get('confidence', 0.5), processing_time, quality_scores)
            
            # 15. ì¶œë ¥ ê²€ì¦
            if not self._validate_output(result):
                return self._create_error_response("ì¶œë ¥ ê²€ì¦ ì‹¤íŒ¨")
            
            # 16. ìµœì¢… ê²°ê³¼ ë°˜í™˜
            result['success'] = True
            result['processing_time'] = processing_time
            result['quality_scores'] = quality_scores
            result['quality_level'] = quality_level.value
            result['method'] = 'modularized'
            result['processors_used'] = {
                'high_resolution': self.high_resolution_processor is not None,
                'special_case': self.special_case_processor is not None,
                'advanced_post': self.advanced_post_processor is not None,
                'quality_enhancer': self.quality_enhancer is not None
            }
            
            logger.info(f"âœ… ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ ì™„ë£Œ (ì²˜ë¦¬ì‹œê°„: {processing_time:.2f}s, ì‹ ë¢°ë„: {result.get('confidence', 0.0):.3f})")
            return result
            
        except Exception as e:
            logger.error(f"âŒ ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return self._create_error_response(f"ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")

    def _validate_input(self, kwargs: Dict[str, Any]) -> bool:
        """ì…ë ¥ ê²€ì¦"""
        try:
            required_keys = ['image']
            for key in required_keys:
                if key not in kwargs:
                    logger.warning(f"í•„ìˆ˜ ì…ë ¥ í‚¤ ëˆ„ë½: {key}")
                    return False
            
            image = kwargs.get('image')
            if image is None or not isinstance(image, NDArray):
                logger.warning("ì´ë¯¸ì§€ê°€ numpy ë°°ì—´ì´ ì•„ë‹™ë‹ˆë‹¤")
                return False
            
            return True
            
        except Exception as e:
            logger.warning(f"ì…ë ¥ ê²€ì¦ ì‹¤íŒ¨: {e}")
            return False

    def _validate_output(self, result: Dict[str, Any]) -> bool:
        """ì¶œë ¥ ê²€ì¦"""
        try:
            if not isinstance(result, dict):
                return False
            
            # í•„ìˆ˜ í‚¤ë“¤ì´ ìˆëŠ”ì§€ í™•ì¸
            required_keys = ['masks', 'confidence', 'method']
            for key in required_keys:
                if key not in result:
                    return False
            
            masks = result['masks']
            if not isinstance(masks, dict):
                return False
            
            # ë§ˆìŠ¤í¬ê°€ ì—†ì–´ë„ ì„±ê³µìœ¼ë¡œ ì²˜ë¦¬ (í´ë°± ëª¨ë“œ)
            if not masks:
                logger.info("âš ï¸ ë§ˆìŠ¤í¬ê°€ ì—†ì§€ë§Œ í´ë°± ëª¨ë“œë¡œ ì„±ê³µ ì²˜ë¦¬")
                return True
            
            # ê° ë§ˆìŠ¤í¬ê°€ ìœ íš¨í•œì§€ í™•ì¸
            for mask_type, mask in masks.items():
                if mask is not None and mask.size > 0:
                    return True
            
            # ëª¨ë“  ë§ˆìŠ¤í¬ê°€ ë¹„ì–´ìˆì–´ë„ ì„±ê³µìœ¼ë¡œ ì²˜ë¦¬
            logger.info("âš ï¸ ëª¨ë“  ë§ˆìŠ¤í¬ê°€ ë¹„ì–´ìˆì§€ë§Œ í´ë°± ëª¨ë“œë¡œ ì„±ê³µ ì²˜ë¦¬")
            return True
            
        except Exception as e:
            logger.warning(f"âš ï¸ ì¶œë ¥ ê²€ì¦ ì‹¤íŒ¨: {e}")
            return False

    def _determine_quality_level(self, kwargs: Dict[str, Any], quality_scores: Dict[str, float]) -> QualityLevel:
        """í’ˆì§ˆ ë ˆë²¨ ê²°ì •"""
        try:
            # ì‚¬ìš©ìê°€ ì§€ì •í•œ í’ˆì§ˆ ë ˆë²¨ì´ ìˆìœ¼ë©´ ì‚¬ìš©
            if 'quality_level' in kwargs:
                quality_level = kwargs['quality_level']
                if isinstance(quality_level, QualityLevel):
                    return quality_level
                elif isinstance(quality_level, str):
                    for level in QualityLevel:
                        if level.value == quality_level:
                            return level
            
            # ì´ë¯¸ì§€ í’ˆì§ˆ ê¸°ë°˜ ìë™ ê²°ì •
            brightness = quality_scores.get('brightness', 0.5)
            contrast = quality_scores.get('contrast', 0.5)
            sharpness = quality_scores.get('sharpness', 0.5)
            
            # í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°
            quality_score = (brightness + contrast + sharpness) / 3.0
            
            if quality_score > 0.8:
                return QualityLevel.ULTRA
            elif quality_score > 0.6:
                return QualityLevel.HIGH
            elif quality_score > 0.4:
                return QualityLevel.BALANCED
            else:
                return QualityLevel.FAST
                
        except Exception as e:
            logger.warning(f"âš ï¸ í’ˆì§ˆ ë ˆë²¨ ê²°ì • ì‹¤íŒ¨: {e}")
            return QualityLevel.BALANCED

    def _preprocess_image(self, image: NDArray, quality_level: QualityLevel) -> NDArray:
        """ì´ë¯¸ì§€ ì „ì²˜ë¦¬"""
        try:
            if image is None:
                return image
            
            processed_image = image.copy()
            
            # í’ˆì§ˆ ë ˆë²¨ì— ë”°ë¥¸ ì „ì²˜ë¦¬ ì ìš©
            if quality_level in [QualityLevel.HIGH, QualityLevel.ULTRA]:
                # ê³ í’ˆì§ˆ ì „ì²˜ë¦¬
                if hasattr(self, '_normalize_lighting'):
                    processed_image = self._normalize_lighting(processed_image)
                
                if hasattr(self, '_correct_colors'):
                    processed_image = self._correct_colors(processed_image)
            
            # ì´ë¯¸ì§€ í¬ê¸° ì¡°ì •
            target_size = self.config.input_size if hasattr(self.config, 'input_size') else (512, 512)
            if processed_image.shape[:2] != target_size:
                processed_image = cv2.resize(processed_image, target_size)
            
            return processed_image
            
        except Exception as e:
            logger.warning(f"âš ï¸ ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return image

    def _normalize_lighting(self, image: NDArray) -> NDArray:
        """ì¡°ëª… ì •ê·œí™”"""
        try:
            if image is None:
                return image
            
            # LAB ìƒ‰ê³µê°„ìœ¼ë¡œ ë³€í™˜
            lab = cv2.cvtColor(image, cv2.COLOR_RGB2LAB)
            
            # L ì±„ë„ ì •ê·œí™”
            l_channel = lab[:, :, 0]
            l_mean = np.mean(l_channel)
            l_std = np.std(l_channel)
            
            # ì •ê·œí™” ì ìš©
            l_normalized = (l_channel - l_mean) / (l_std + 1e-8)
            l_normalized = np.clip(l_normalized * 50 + 128, 0, 255).astype(np.uint8)
            
            # ì •ê·œí™”ëœ L ì±„ë„ë¡œ êµì²´
            lab[:, :, 0] = l_normalized
            
            # RGBë¡œ ë³€í™˜
            normalized_image = cv2.cvtColor(lab, cv2.COLOR_LAB2RGB)
            
            return normalized_image
            
        except Exception as e:
            logger.warning(f"âš ï¸ ì¡°ëª… ì •ê·œí™” ì‹¤íŒ¨: {e}")
            return image

    def _correct_colors(self, image: NDArray) -> NDArray:
        """ìƒ‰ìƒ ë³´ì •"""
        try:
            if image is None:
                return image
            
            # íˆìŠ¤í† ê·¸ë¨ í‰í™œí™”
            corrected_image = image.copy()
            
            # ê° ì±„ë„ë³„ íˆìŠ¤í† ê·¸ë¨ í‰í™œí™”
            for i in range(3):
                corrected_image[:, :, i] = cv2.equalizeHist(corrected_image[:, :, i])
            
            return corrected_image
            
        except Exception as e:
            logger.warning(f"âš ï¸ ìƒ‰ìƒ ë³´ì • ì‹¤íŒ¨: {e}")
            return image

    def _assess_image_quality(self, image: NDArray) -> Dict[str, float]:
        """ì´ë¯¸ì§€ í’ˆì§ˆ í‰ê°€"""
        try:
            if image is None:
                return {'brightness': 0.0, 'contrast': 0.0, 'sharpness': 0.0}
            
            # ë°ê¸° í‰ê°€
            if len(image.shape) == 3:
                gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
            else:
                gray = image
            
            brightness = np.mean(gray) / 255.0
            
            # ëŒ€ë¹„ í‰ê°€
            contrast = np.std(gray) / 255.0
            
            # ì„ ëª…ë„ í‰ê°€ (Laplacian variance)
            laplacian = cv2.Laplacian(gray, cv2.CV_64F)
            sharpness = np.var(laplacian) / 1000.0  # ì •ê·œí™”
            
            return {
                'brightness': float(brightness),
                'contrast': float(contrast),
                'sharpness': float(sharpness)
            }
            
        except Exception as e:
            logger.warning(f"âš ï¸ ì´ë¯¸ì§€ í’ˆì§ˆ í‰ê°€ ì‹¤íŒ¨: {e}")
            return {'brightness': 0.5, 'contrast': 0.5, 'sharpness': 0.5}

    def _run_ai_segmentation_sync(self, image: NDArray, quality_level: QualityLevel, 
                                 person_parsing: Dict[str, Any], pose_info: Dict[str, Any]) -> Dict[str, Any]:
        """AI ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‹¤í–‰ (ë™ê¸°)"""
        try:
            logger.info("ğŸ”¥ AI ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‹¤í–‰ ì‹œì‘")
            logger.info(f"ğŸ” ì…ë ¥ ì´ë¯¸ì§€ shape: {image.shape}")
            logger.info(f"ğŸ” í’ˆì§ˆ ë ˆë²¨: {quality_level.value}")
            
            if not self.segmentation_ready:
                logger.warning("âš ï¸ ì„¸ê·¸ë©˜í…Œì´ì…˜ ëª¨ë¸ì´ ì¤€ë¹„ë˜ì§€ ì•ŠìŒ")
                return self._create_fallback_segmentation_result(image.shape)
            
            # ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ë“¤ í™•ì¸
            available_models = list(self.segmentation_models.keys())
            if not available_models:
                logger.warning("âš ï¸ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ì´ ì—†ìŒ")
                return self._create_fallback_segmentation_result(image.shape)
            
            logger.info(f"ğŸ” ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ë“¤: {available_models}")
            
            # ëª¨ë¸ë³„ ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‹¤í–‰
            results = {}
            methods_used = []
            execution_times = {}
            
            for model_key in available_models:
                try:
                    logger.info(f"ğŸ¯ {model_key} ëª¨ë¸ ì‹¤í–‰ ì¤‘...")
                    start_time = time.time()
                    
                    result = self._safe_model_predict(model_key, image)
                    execution_time = time.time() - start_time
                    
                    logger.info(f"ğŸ” {model_key} ëª¨ë¸ ê²°ê³¼: {result}")
                    
                    if result.get('success', False):
                        results[model_key] = result
                        methods_used.append(model_key)
                        execution_times[model_key] = execution_time
                        logger.info(f"âœ… {model_key} ëª¨ë¸ ì‹¤í–‰ ì™„ë£Œ (ì‹œê°„: {execution_time:.2f}s)")
                    else:
                        logger.warning(f"âš ï¸ {model_key} ëª¨ë¸ ì‹¤í–‰ ì‹¤íŒ¨: {result.get('error', 'Unknown error')}")
                        
                except Exception as e:
                    logger.error(f"âŒ {model_key} ëª¨ë¸ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            
            logger.info(f"ğŸ” ìˆ˜ì§‘ëœ ê²°ê³¼ë“¤: {list(results.keys())}")
            logger.info(f"ğŸ” ê²°ê³¼ ê°œìˆ˜: {len(results)}")
            
            # ê²°ê³¼ ê²°í•©
            if results:
                # ê°€ì¥ ì¢‹ì€ ê²°ê³¼ ì„ íƒ (ì‹ ë¢°ë„ ê¸°ì¤€)
                best_result = max(results.values(), key=lambda x: x.get('confidence', 0.0))
                best_method = best_result.get('method', 'unknown')
                
                logger.info(f"ğŸ¯ ìµœì  ê²°ê³¼: {best_method} (ì‹ ë¢°ë„: {best_result.get('confidence', 0.0):.2f})")
                logger.info(f"ğŸ” ìµœì  ê²°ê³¼ ë§ˆìŠ¤í¬: {best_result.get('masks', {})}")
                
                return {
                    'success': True,
                    'masks': best_result.get('masks', {}),
                    'confidence': best_result.get('confidence', 0.0),
                    'method_used': best_method,
                    'methods_available': methods_used,
                    'execution_times': execution_times,
                    'quality_level': quality_level.value
                }
            else:
                logger.warning("âš ï¸ ëª¨ë“  ëª¨ë¸ ì‹¤í–‰ ì‹¤íŒ¨")
                return self._create_fallback_segmentation_result(image.shape)
                
        except Exception as e:
            logger.error(f"âŒ AI ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            return self._create_fallback_segmentation_result(image.shape)

    def _postprocess_masks(self, masks: Dict[str, NDArray]) -> Dict[str, NDArray]:
        """ë§ˆìŠ¤í¬ í›„ì²˜ë¦¬ (ì‹¤ì œ ë¶„í•  í’ˆì§ˆ í–¥ìƒ)"""
        try:
            if not masks:
                return masks
            
            processed_masks = {}
            
            for mask_type, mask in masks.items():
                if mask is None or mask.size == 0:
                    continue
                
                # 1. í™€ ì±„ìš°ê¸° ë° ë…¸ì´ì¦ˆ ì œê±°
                processed_mask = self._fill_holes_and_remove_noise(mask)
                
                # 2. ê²½ê³„ ì •ì œ
                processed_mask = self._refine_boundaries(processed_mask)
                
                # 3. ì‘ì€ ì˜ì—­ ì œê±°
                processed_mask = self._remove_small_regions(processed_mask)
                
                processed_masks[mask_type] = processed_mask
            
            logger.info(f"âœ… ë§ˆìŠ¤í¬ í›„ì²˜ë¦¬ ì™„ë£Œ ({len(processed_masks)}ê°œ ë§ˆìŠ¤í¬)")
            return processed_masks
            
        except Exception as e:
            logger.warning(f"âš ï¸ ë§ˆìŠ¤í¬ í›„ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return masks

    def _fill_holes_and_remove_noise(self, mask: NDArray) -> NDArray:
        """í™€ ì±„ìš°ê¸° ë° ë…¸ì´ì¦ˆ ì œê±°"""
        try:
            if mask is None or mask.size == 0:
                return mask
            
            # ë…¸ì´ì¦ˆ ì œê±°
            kernel = np.ones((3, 3), np.uint8)
            mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)
            mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)
            
            # í™€ ì±„ìš°ê¸°
            contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            if contours:
                largest_contour = max(contours, key=cv2.contourArea)
                filled_mask = np.zeros_like(mask)
                cv2.fillPoly(filled_mask, [largest_contour], 1)
                mask = filled_mask
            
            return mask
            
        except Exception as e:
            logger.warning(f"âš ï¸ í™€ ì±„ìš°ê¸° ë° ë…¸ì´ì¦ˆ ì œê±° ì‹¤íŒ¨: {e}")
            return mask

    def _refine_boundaries(self, mask: NDArray) -> NDArray:
        """ê²½ê³„ ì •ì œ"""
        try:
            if mask is None or mask.size == 0:
                return mask
            
            # ê²½ê³„ ìŠ¤ë¬´ë”©
            kernel = np.ones((3, 3), np.uint8)
            mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)
            
            return mask
            
        except Exception as e:
            logger.warning(f"âš ï¸ ê²½ê³„ ì •ì œ ì‹¤íŒ¨: {e}")
            return mask

    def _remove_small_regions(self, mask: NDArray, min_area: int = 100) -> NDArray:
        """ì‘ì€ ì˜ì—­ ì œê±°"""
        try:
            if mask is None or mask.size == 0:
                return mask
            
            # ì—°ê²° ìš”ì†Œ ë¶„ì„
            num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(mask, connectivity=8)
            
            # ì‘ì€ ì˜ì—­ ì œê±°
            for i in range(1, num_labels):  # 0ì€ ë°°ê²½
                if stats[i, cv2.CC_STAT_AREA] < min_area:
                    mask[labels == i] = 0
            
            return mask
            
        except Exception as e:
            logger.warning(f"âš ï¸ ì‘ì€ ì˜ì—­ ì œê±° ì‹¤íŒ¨: {e}")
            return mask

    def _create_fallback_segmentation_result(self, image_shape: Tuple[int, ...]) -> Dict[str, Any]:
        """í´ë°± ì„¸ê·¸ë©˜í…Œì´ì…˜ ê²°ê³¼ ìƒì„± (ì‹¤ì œ ë¶„í• )"""
        try:
            # ê¸°ë³¸ ë§ˆìŠ¤í¬ ìƒì„±
            height, width = image_shape[:2]
            fallback_mask = np.zeros((height, width), dtype=np.uint8)
            
            # ì¤‘ì•™ì— ì‚¬ê°í˜• ë§ˆìŠ¤í¬ ìƒì„± (ì˜ë¥˜ê°€ ìˆì„ ê°€ëŠ¥ì„±ì´ ë†’ì€ ì˜ì—­)
            center_h, center_w = height // 2, width // 2
            size_h, size_w = height // 4, width // 4
            
            h_start = max(0, center_h - size_h)
            h_end = min(height, center_h + size_h)
            w_start = max(0, center_w - size_w)
            w_end = min(width, center_w + size_w)
            
            fallback_mask[h_start:h_end, w_start:w_end] = 1
            
            # ì¹´í…Œê³ ë¦¬ë³„ ë§ˆìŠ¤í¬ ìƒì„±
            category_masks = {
                'shirt': fallback_mask.copy(),
                'pants': fallback_mask.copy(),
                'dress': fallback_mask.copy()
            }
            
            return {
                'masks': category_masks,
                'confidence': 0.3,
                'method': 'fallback',
                'processing_time': 0.0,
                'quality_score': 0.3
            }
            
        except Exception as e:
            logger.warning(f"âš ï¸ í´ë°± ê²°ê³¼ ìƒì„± ì‹¤íŒ¨: {e}")
            return {
                'masks': {},
                'confidence': 0.0,
                'method': 'fallback',
                'processing_time': 0.0,
                'quality_score': 0.0
            }

    def _update_ai_stats(self, method: str, confidence: float, total_time: float, quality_metrics: Dict[str, float]):
        """AI í†µê³„ ì—…ë°ì´íŠ¸"""
        try:
            self.ai_stats['total_processing_time'] += total_time
            self.ai_stats['inference_time'] += total_time
            self.ai_stats['success_count'] += 1
            self.ai_stats['last_processed_time'] = time.time()
            
            # í’ˆì§ˆ ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
            if 'quality_score' in quality_metrics:
                self.ai_stats['average_quality'] = (
                    (self.ai_stats.get('average_quality', 0.0) * (self.ai_stats['success_count'] - 1) + 
                     quality_metrics['quality_score']) / self.ai_stats['success_count']
                )
            
        except Exception as e:
            logger.warning(f"âš ï¸ í†µê³„ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")

    def get_status(self) -> Dict[str, Any]:
        """ìƒíƒœ ì¡°íšŒ"""
        try:
            status = super().get_status()
            status.update({
                'segmentation_ready': self.segmentation_ready,
                'loaded_models': list(self.segmentation_models.keys()),
                'ai_stats': self.ai_stats,
                'config': {
                    'method': self.config.method.value if hasattr(self.config, 'method') else 'unknown',
                    'quality_level': self.config.quality_level.value if hasattr(self.config, 'quality_level') else 'unknown',
                    'input_size': self.config.input_size if hasattr(self.config, 'input_size') else (512, 512)
                },
                'available_methods': list(self.segmentation_methods.keys()) if hasattr(self, 'segmentation_methods') else []
            })
            return status
            
        except Exception as e:
            logger.warning(f"âš ï¸ ìƒíƒœ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {'error': str(e)}

    def cleanup(self):
        """ì •ë¦¬"""
        try:
            # ëª¨ë¸ ì •ë¦¬
            for model in self.segmentation_models.values():
                if hasattr(model, 'cleanup'):
                    model.cleanup()
            
            self.segmentation_models.clear()
            self.segmentation_ready = False
            
            super().cleanup()
            logger.info("âœ… ClothSegmentationStepModularized ì •ë¦¬ ì™„ë£Œ")
            
        except Exception as e:
            logger.warning(f"âš ï¸ ì •ë¦¬ ì‹¤íŒ¨: {e}")

    def _detect_available_methods(self) -> List[str]:
        """ì‚¬ìš© ê°€ëŠ¥í•œ ë°©ë²•ë“¤ ê°ì§€"""
        try:
            available_methods = []
            
            # ëª¨ë¸ë³„ ê°€ìš©ì„± í™•ì¸
            if 'u2net_cloth' in self.segmentation_models:
                available_methods.append('u2net_cloth')
            
            if 'sam_huge' in self.segmentation_models:
                available_methods.append('sam_huge')
            
            if 'deeplabv3_plus' in self.segmentation_models:
                available_methods.append('deeplabv3_plus')
            
            # í•˜ì´ë¸Œë¦¬ë“œ ì•™ìƒë¸” (ì—¬ëŸ¬ ëª¨ë¸ì´ ìˆì„ ë•Œ)
            if len(self.segmentation_models) > 1:
                available_methods.append('hybrid_ai')
            
            return available_methods
            
        except Exception as e:
            logger.warning(f"âš ï¸ ì‚¬ìš© ê°€ëŠ¥í•œ ë°©ë²• ê°ì§€ ì‹¤íŒ¨: {e}")
            return []

    def _create_error_response(self, error_message: str) -> Dict[str, Any]:
        """ì—ëŸ¬ ì‘ë‹µ ìƒì„±"""
        return {
            'success': False,
            'error': error_message,
            'masks': {},
            'confidence': 0.0,
            'method': 'error',
            'processing_time': 0.0
        }

    def _run_single_model_segmentation(self, model_key: str, image: NDArray) -> Dict[str, Any]:
        """ë‹¨ì¼ ëª¨ë¸ ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‹¤í–‰"""
        try:
            if model_key not in self.segmentation_models:
                return self._create_error_response(f"ëª¨ë¸ {model_key}ê°€ ë¡œë“œë˜ì§€ ì•ŠìŒ")
            
            model = self.segmentation_models[model_key]
            
            if not hasattr(model, 'predict'):
                return self._create_error_response(f"ëª¨ë¸ {model_key}ì— predict ë©”ì„œë“œê°€ ì—†ìŒ")
            
            # ì‹¤ì œ ì˜ˆì¸¡ ì‹¤í–‰
            result = model.predict(image)
            
            if result and 'masks' in result:
                logger.info(f"âœ… {model_key} ì„¸ê·¸ë©˜í…Œì´ì…˜ ì™„ë£Œ")
                return result
            else:
                return self._create_error_response(f"ëª¨ë¸ {model_key} ê²°ê³¼ê°€ ìœ íš¨í•˜ì§€ ì•ŠìŒ")
                
        except Exception as e:
            logger.error(f"âŒ {model_key} ëª¨ë¸ ì¶”ë¡  ì‹¤íŒ¨: {e}")
            return self._create_error_response(f"ëª¨ë¸ {model_key} ì¶”ë¡  ì‹¤íŒ¨: {str(e)}")

    def _enhance_segmentation_quality(self, masks: Dict[str, NDArray], image: NDArray) -> Dict[str, NDArray]:
        """ì„¸ê·¸ë©˜í…Œì´ì…˜ í’ˆì§ˆ í–¥ìƒ"""
        try:
            enhanced_masks = {}
            
            for mask_type, mask in masks.items():
                if mask is None or mask.size == 0:
                    continue
                
                # 1. ê²½ê³„ ì •ì œ
                enhanced_mask = self._refine_boundaries(mask)
                
                # 2. í™€ ì±„ìš°ê¸°
                enhanced_mask = self._fill_holes_and_remove_noise(enhanced_mask)
                
                # 3. ì‘ì€ ì˜ì—­ ì œê±°
                enhanced_mask = self._remove_small_regions(enhanced_mask)
                
                # 4. ëª¨í´ë¡œì§€ ì—°ì‚°ìœ¼ë¡œ ìŠ¤ë¬´ë”©
                enhanced_mask = self._apply_morphological_operations(enhanced_mask)
                
                enhanced_masks[mask_type] = enhanced_mask
            
            return enhanced_masks
            
        except Exception as e:
            logger.warning(f"âš ï¸ ì„¸ê·¸ë©˜í…Œì´ì…˜ í’ˆì§ˆ í–¥ìƒ ì‹¤íŒ¨: {e}")
            return masks

    def _apply_morphological_operations(self, mask: NDArray) -> NDArray:
        """ëª¨í´ë¡œì§€ ì—°ì‚° ì ìš©"""
        try:
            if mask is None or mask.size == 0:
                return mask
            
            # ë‹«ê¸° ì—°ì‚°ìœ¼ë¡œ í™€ ì±„ìš°ê¸°
            kernel = np.ones((5, 5), np.uint8)
            mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)
            
            # ì—´ê¸° ì—°ì‚°ìœ¼ë¡œ ë…¸ì´ì¦ˆ ì œê±°
            mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)
            
            return mask
            
        except Exception as e:
            logger.warning(f"âš ï¸ ëª¨í´ë¡œì§€ ì—°ì‚° ì‹¤íŒ¨: {e}")
            return mask

    def _calculate_segmentation_confidence(self, masks: Dict[str, NDArray], image: NDArray) -> float:
        """ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‹ ë¢°ë„ ê³„ì‚°"""
        try:
            if not masks:
                return 0.0
            
            total_confidence = 0.0
            mask_count = 0
            
            for mask_type, mask in masks.items():
                if mask is None or mask.size == 0:
                    continue
                
                # 1. ë©´ì  ë¹„ìœ¨ ê¸°ë°˜ ì‹ ë¢°ë„
                area_ratio = np.sum(mask) / mask.size
                area_confidence = min(area_ratio * 2, 1.0)  # ì ì ˆí•œ ë©´ì  ë¹„ìœ¨ì— ë†’ì€ ì‹ ë¢°ë„
                
                # 2. ê²½ê³„ í’ˆì§ˆ ê¸°ë°˜ ì‹ ë¢°ë„
                edges = cv2.Canny(mask.astype(np.uint8) * 255, 50, 150)
                edge_density = np.sum(edges) / (edges.size * 255)
                edge_confidence = 1.0 - min(edge_density * 3, 1.0)  # ë‚®ì€ edge densityì— ë†’ì€ ì‹ ë¢°ë„
                
                # 3. ì—°ê²°ì„± ê¸°ë°˜ ì‹ ë¢°ë„
                contours, _ = cv2.findContours(mask.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                connectivity_confidence = 1.0 / (len(contours) + 1)  # ì»¨íˆ¬ì–´ê°€ ì ì„ìˆ˜ë¡ ì¢‹ìŒ
                
                # ì¢…í•© ì‹ ë¢°ë„
                mask_confidence = (area_confidence * 0.4 + edge_confidence * 0.3 + connectivity_confidence * 0.3)
                total_confidence += mask_confidence
                mask_count += 1
            
            return total_confidence / mask_count if mask_count > 0 else 0.0
            
        except Exception as e:
            logger.warning(f"âš ï¸ ì‹ ë¢°ë„ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return 0.5

    def _validate_segmentation_result(self, result: Dict[str, Any]) -> bool:
        """ì„¸ê·¸ë©˜í…Œì´ì…˜ ê²°ê³¼ ê²€ì¦"""
        try:
            if not isinstance(result, dict):
                return False
            
            if 'masks' not in result:
                return False
            
            masks = result['masks']
            if not isinstance(masks, dict):
                return False
            
            # ìµœì†Œ í•˜ë‚˜ì˜ ë§ˆìŠ¤í¬ê°€ ìˆì–´ì•¼ í•¨
            if not masks:
                return False
            
            # ê° ë§ˆìŠ¤í¬ê°€ ìœ íš¨í•œì§€ í™•ì¸
            for mask_type, mask in masks.items():
                if mask is not None and mask.size > 0:
                    return True
            
            return False
            
        except Exception as e:
            logger.warning(f"âš ï¸ ê²°ê³¼ ê²€ì¦ ì‹¤íŒ¨: {e}")
            return False

    def _get_cloth_bounding_boxes(self, masks: Dict[str, NDArray]) -> Dict[str, Dict[str, int]]:
        """ì˜ë¥˜ ë°”ìš´ë”© ë°•ìŠ¤ë“¤ ë°˜í™˜"""
        try:
            bounding_boxes = {}
            
            for mask_type, mask in masks.items():
                if mask is not None and np.any(mask):
                    bbox = self._calculate_bounding_box(mask)
                    bounding_boxes[mask_type] = {
                        'x_min': bbox[0],
                        'y_min': bbox[1],
                        'x_max': bbox[2],
                        'y_max': bbox[3]
                    }
            
            return bounding_boxes
            
        except Exception as e:
            logger.warning(f"âš ï¸ ë°”ìš´ë”© ë°•ìŠ¤ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return {}

    def _get_cloth_centroids(self, masks: Dict[str, NDArray]) -> Dict[str, Tuple[float, float]]:
        """ì˜ë¥˜ ì¤‘ì‹¬ì ë“¤ ë°˜í™˜"""
        try:
            centroids = {}
            
            for mask_type, mask in masks.items():
                if mask is not None and np.any(mask):
                    centroid = self._calculate_centroid(mask)
                    centroids[mask_type] = centroid
            
            return centroids
            
        except Exception as e:
            logger.warning(f"âš ï¸ ì¤‘ì‹¬ì  ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return {}

    def _get_cloth_areas(self, masks: Dict[str, NDArray]) -> Dict[str, int]:
        """ì˜ë¥˜ ë©´ì ë“¤ ë°˜í™˜"""
        try:
            areas = {}
            
            for mask_type, mask in masks.items():
                if mask is not None:
                    area = int(np.sum(mask))
                    areas[mask_type] = area
            
            return areas
            
        except Exception as e:
            logger.warning(f"âš ï¸ ë©´ì  ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return {}

    def _get_cloth_contours_dict(self, masks: Dict[str, NDArray]) -> Dict[str, List[NDArray]]:
        """ì˜ë¥˜ ìœ¤ê³½ì„ ë“¤ ë°˜í™˜"""
        try:
            contours_dict = {}
            
            for mask_type, mask in masks.items():
                if mask is not None:
                    contours = self._extract_cloth_contours(mask)
                    contours_dict[mask_type] = contours
            
            return contours_dict
            
        except Exception as e:
            logger.warning(f"âš ï¸ ìœ¤ê³½ì„  ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return {}

    def _detect_cloth_categories(self, masks: Dict[str, NDArray]) -> List[str]:
        """ì˜ë¥˜ ì¹´í…Œê³ ë¦¬ ê°ì§€"""
        try:
            categories = []
            
            for mask_type, mask in masks.items():
                if mask is not None and np.any(mask):
                    # ë§ˆìŠ¤í¬ íƒ€ì…ì„ ì¹´í…Œê³ ë¦¬ë¡œ ë³€í™˜
                    category = mask_type.replace('_', ' ').title()
                    categories.append(category)
            
            return categories
            
        except Exception as e:
            logger.warning(f"âš ï¸ ì¹´í…Œê³ ë¦¬ ê°ì§€ ì‹¤íŒ¨: {e}")
            return []

    def _create_segmentation_visualization(self, image: NDArray, masks: Dict[str, NDArray]) -> Dict[str, Any]:
        """ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‹œê°í™” ìƒì„±"""
        try:
            if image is None or not masks:
                return {}
            
            visualizations = {}
            
            # ì›ë³¸ ì´ë¯¸ì§€ ë³µì‚¬
            overlay_image = image.copy()
            
            # ìƒ‰ìƒ ë§¤í•‘
            colors = [
                [255, 0, 0],    # ë¹¨ê°•
                [0, 255, 0],    # ì´ˆë¡
                [0, 0, 255],    # íŒŒë‘
                [255, 255, 0],  # ë…¸ë‘
                [255, 0, 255],  # ë§ˆì  íƒ€
                [0, 255, 255]   # ì‹œì•ˆ
            ]
            
            # ë§ˆìŠ¤í¬ ì˜¤ë²„ë ˆì´ ìƒì„±
            for i, (mask_type, mask) in enumerate(masks.items()):
                if mask is not None and np.any(mask):
                    color = colors[i % len(colors)]
                    
                    # ë§ˆìŠ¤í¬ë¥¼ 3ì±„ë„ë¡œ í™•ì¥
                    mask_3d = np.stack([mask, mask, mask], axis=-1)
                    
                    # ìƒ‰ìƒ ì ìš©
                    colored_mask = np.array(color) * mask_3d
                    
                    # ì•ŒíŒŒ ë¸”ë Œë”©
                    alpha = 0.6
                    overlay_image = overlay_image * (1 - alpha * mask_3d) + colored_mask * alpha * mask_3d
            
            visualizations['overlay'] = overlay_image.astype(np.uint8)
            
            # ê°œë³„ ë§ˆìŠ¤í¬ ì‹œê°í™”
            for mask_type, mask in masks.items():
                if mask is not None:
                    visualizations[f'mask_{mask_type}'] = (mask * 255).astype(np.uint8)
            
            return visualizations
            
        except Exception as e:
            logger.warning(f"âš ï¸ ì‹œê°í™” ìƒì„± ì‹¤íŒ¨: {e}")
            return {}

    def _calculate_segmentation_confidence(self, masks: Dict[str, NDArray], image: NDArray) -> float:
        """ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‹ ë¢°ë„ ê³„ì‚°"""
        try:
            if not masks:
                return 0.0
            
            total_confidence = 0.0
            mask_count = 0
            
            for mask_type, mask in masks.items():
                if mask is None or mask.size == 0:
                    continue
                
                # 1. ë©´ì  ë¹„ìœ¨ ê¸°ë°˜ ì‹ ë¢°ë„
                area_ratio = np.sum(mask) / mask.size
                area_confidence = min(area_ratio * 2, 1.0)  # ì ì ˆí•œ ë©´ì  ë¹„ìœ¨ì— ë†’ì€ ì‹ ë¢°ë„
                
                # 2. ê²½ê³„ í’ˆì§ˆ ê¸°ë°˜ ì‹ ë¢°ë„
                edges = cv2.Canny(mask.astype(np.uint8) * 255, 50, 150)
                edge_density = np.sum(edges) / (edges.size * 255)
                edge_confidence = 1.0 - min(edge_density * 3, 1.0)  # ë‚®ì€ edge densityì— ë†’ì€ ì‹ ë¢°ë„
                
                # 3. ì—°ê²°ì„± ê¸°ë°˜ ì‹ ë¢°ë„
                contours, _ = cv2.findContours(mask.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                connectivity_confidence = 1.0 / (len(contours) + 1)  # ì»¨íˆ¬ì–´ê°€ ì ì„ìˆ˜ë¡ ì¢‹ìŒ
                
                # ì¢…í•© ì‹ ë¢°ë„
                mask_confidence = (area_confidence * 0.4 + edge_confidence * 0.3 + connectivity_confidence * 0.3)
                total_confidence += mask_confidence
                mask_count += 1
            
            return total_confidence / mask_count if mask_count > 0 else 0.0
            
        except Exception as e:
            logger.warning(f"âš ï¸ ì‹ ë¢°ë„ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return 0.5

    def _extract_cloth_contours(self, mask: NDArray) -> List[NDArray]:
        """ì˜ë¥˜ ìœ¤ê³½ì„  ì¶”ì¶œ"""
        try:
            if mask is None or mask.size == 0:
                return []
            
            # ë§ˆìŠ¤í¬ë¥¼ uint8ë¡œ ë³€í™˜
            mask_uint8 = mask.astype(np.uint8)
            
            # ìœ¤ê³½ì„  ì°¾ê¸°
            contours, _ = cv2.findContours(mask_uint8, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            
            # ì‘ì€ ìœ¤ê³½ì„  í•„í„°ë§
            min_area = 50
            filtered_contours = [contour for contour in contours if cv2.contourArea(contour) > min_area]
            
            return filtered_contours
            
        except Exception as e:
            logger.warning(f"âš ï¸ ìœ¤ê³½ì„  ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return []

    def _apply_ultra_quality_postprocessing(self, masks: Dict[str, NDArray], image: NDArray,
                                          person_parsing: Dict[str, Any], pose_info: Dict[str, Any]) -> Dict[str, NDArray]:
        """ìš¸íŠ¸ë¼ í’ˆì§ˆ í›„ì²˜ë¦¬"""
        try:
            processed_masks = {}
            
            for mask_type, mask in masks.items():
                if mask is None or mask.size == 0:
                    continue
                
                # 1. ê²½ê³„ ì •ì œ
                refined_mask = self._refine_boundaries(mask)
                
                # 2. í™€ ì±„ìš°ê¸°
                filled_mask = self._fill_holes_and_remove_noise(refined_mask)
                
                # 3. ì‘ì€ ì˜ì—­ ì œê±°
                cleaned_mask = self._remove_small_regions(filled_mask, min_area=200)
                
                # 4. ëª¨í´ë¡œì§€ ì—°ì‚°
                final_mask = self._apply_morphological_operations(cleaned_mask)
                
                processed_masks[mask_type] = final_mask
            
            return processed_masks
            
        except Exception as e:
            logger.warning(f"âš ï¸ ìš¸íŠ¸ë¼ í’ˆì§ˆ í›„ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return masks

    def _enhance_sam_results(self, masks: Dict[str, NDArray], image: NDArray,
                           person_parsing: Dict[str, Any]) -> Dict[str, NDArray]:
        """SAM ê²°ê³¼ í–¥ìƒ"""
        try:
            enhanced_masks = {}
            
            for mask_type, mask in masks.items():
                if mask is None or mask.size == 0:
                    continue
                
                # SAM íŠ¹í™” í–¥ìƒ ë¡œì§
                enhanced_mask = mask.copy()
                
                # 1. ê²½ê³„ ìŠ¤ë¬´ë”©
                kernel = np.ones((3, 3), np.uint8)
                enhanced_mask = cv2.morphologyEx(enhanced_mask, cv2.MORPH_CLOSE, kernel)
                
                # 2. ë…¸ì´ì¦ˆ ì œê±°
                enhanced_mask = cv2.medianBlur(enhanced_mask.astype(np.uint8), 3)
                
                enhanced_masks[mask_type] = enhanced_mask
            
            return enhanced_masks
            
        except Exception as e:
            logger.warning(f"âš ï¸ SAM ê²°ê³¼ í–¥ìƒ ì‹¤íŒ¨: {e}")
            return masks

    def _enhance_u2net_results(self, masks: Dict[str, NDArray], image: NDArray,
                             person_parsing: Dict[str, Any]) -> Dict[str, NDArray]:
        """U2Net ê²°ê³¼ í–¥ìƒ"""
        try:
            enhanced_masks = {}
            
            for mask_type, mask in masks.items():
                if mask is None or mask.size == 0:
                    continue
                
                # U2Net íŠ¹í™” í–¥ìƒ ë¡œì§
                enhanced_mask = mask.copy()
                
                # 1. ì´ì§„í™”
                _, enhanced_mask = cv2.threshold(enhanced_mask, 127, 255, cv2.THRESH_BINARY)
                
                # 2. ê²½ê³„ ì •ì œ
                kernel = np.ones((2, 2), np.uint8)
                enhanced_mask = cv2.morphologyEx(enhanced_mask, cv2.MORPH_OPEN, kernel)
                
                enhanced_masks[mask_type] = enhanced_mask
            
            return enhanced_masks
            
        except Exception as e:
            logger.warning(f"âš ï¸ U2Net ê²°ê³¼ í–¥ìƒ ì‹¤íŒ¨: {e}")
            return masks

    def _generate_sam_prompts(self, image: NDArray, person_parsing: Dict[str, Any],
                            pose_info: Dict[str, Any]) -> Dict[str, Any]:
        """SAM í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        try:
            prompts = {
                'points': [],
                'boxes': [],
                'masks': []
            }
            
            # 1. í¬ì¸íŠ¸ í”„ë¡¬í”„íŠ¸ ìƒì„±
            if person_parsing:
                # ì‚¬ëŒ íŒŒì‹± ê²°ê³¼ì—ì„œ ì˜ë¥˜ ì˜ì—­ ì¤‘ì‹¬ì  ì¶”ì¶œ
                for region_type, region_mask in person_parsing.get('regions', {}).items():
                    if region_mask is not None and np.sum(region_mask) > 100:
                        y_coords, x_coords = np.where(region_mask > 128)
                        if len(x_coords) > 0 and len(y_coords) > 0:
                            center_x = int(np.mean(x_coords))
                            center_y = int(np.mean(y_coords))
                            prompts['points'].append([center_x, center_y])
            
            # 2. ë°•ìŠ¤ í”„ë¡¬í”„íŠ¸ ìƒì„±
            if pose_info:
                # í¬ì¦ˆ ì •ë³´ì—ì„œ ì˜ë¥˜ ì˜ì—­ ë°”ìš´ë”© ë°•ìŠ¤ ì¶”ì¶œ
                keypoints = pose_info.get('keypoints', {})
                if keypoints:
                    # ìƒì˜ ì˜ì—­
                    if 'shoulder_left' in keypoints and 'shoulder_right' in keypoints:
                        left_shoulder = keypoints['shoulder_left']
                        right_shoulder = keypoints['shoulder_right']
                        if left_shoulder and right_shoulder:
                            x1 = min(left_shoulder[0], right_shoulder[0])
                            y1 = min(left_shoulder[1], right_shoulder[1])
                            x2 = max(left_shoulder[0], right_shoulder[0])
                            y2 = max(left_shoulder[1], right_shoulder[1])
                            prompts['boxes'].append([x1, y1, x2, y2])
            
            return prompts
            
        except Exception as e:
            logger.warning(f"âš ï¸ SAM í”„ë¡¬í”„íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}")
            return {'points': [], 'boxes': [], 'masks': []}

    def _refine_with_person_parsing(self, mask: NDArray, clothing_regions: List[Dict[str, Any]], 
                                  mask_type: str) -> NDArray:
        """ì‚¬ëŒ íŒŒì‹± ê²°ê³¼ë¡œ ë§ˆìŠ¤í¬ ì •ì œ"""
        try:
            refined_mask = mask.copy()
            
            for region in clothing_regions:
                region_mask = region.get('mask')
                region_type = region.get('type', '')
                
                if region_mask is not None and region_mask.shape == mask.shape:
                    # ì˜ë¥˜ íƒ€ì…ì— ë”°ë¥¸ ì •ì œ
                    if mask_type == 'upper_body' and region_type in ['shirt', 't_shirt', 'sweater']:
                        refined_mask = np.logical_or(refined_mask, region_mask).astype(np.uint8)
                    elif mask_type == 'lower_body' and region_type in ['pants', 'jeans', 'skirt']:
                        refined_mask = np.logical_or(refined_mask, region_mask).astype(np.uint8)
            
            return refined_mask
            
        except Exception as e:
            logger.warning(f"âš ï¸ ì‚¬ëŒ íŒŒì‹± ê¸°ë°˜ ì •ì œ ì‹¤íŒ¨: {e}")
            return mask

    def _refine_with_pose_info(self, mask: NDArray, keypoints: Dict[str, Any], 
                             mask_type: str) -> NDArray:
        """í¬ì¦ˆ ì •ë³´ë¡œ ë§ˆìŠ¤í¬ ì •ì œ"""
        try:
            refined_mask = mask.copy()
            
            if not keypoints:
                return refined_mask
            
            # í¬ì¦ˆ ê¸°ë°˜ ì˜ì—­ ì •ì˜
            if mask_type == 'upper_body':
                # ìƒì˜ ì˜ì—­: ì–´ê¹¨ë¶€í„° í—ˆë¦¬ê¹Œì§€
                shoulder_y = min([kp[1] for kp in keypoints.values() if kp and len(kp) >= 2])
                hip_y = max([kp[1] for kp in keypoints.values() if kp and len(kp) >= 2])
                
                # ìƒì˜ ì˜ì—­ë§Œ ìœ ì§€
                refined_mask[:shoulder_y, :] = 0
                refined_mask[hip_y:, :] = 0
                
            elif mask_type == 'lower_body':
                # í•˜ì˜ ì˜ì—­: í—ˆë¦¬ë¶€í„° ë°œëª©ê¹Œì§€
                hip_y = min([kp[1] for kp in keypoints.values() if kp and len(kp) >= 2])
                
                # í•˜ì˜ ì˜ì—­ë§Œ ìœ ì§€
                refined_mask[:hip_y, :] = 0
            
            return refined_mask
            
        except Exception as e:
            logger.warning(f"âš ï¸ í¬ì¦ˆ ì •ë³´ ê¸°ë°˜ ì •ì œ ì‹¤íŒ¨: {e}")
            return mask

    def _create_segmentation_visualizations(self, image: NDArray, masks: Dict[str, NDArray]) -> Dict[str, Any]:
        """ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‹œê°í™” ìƒì„±"""
        try:
            visualizations = {}
            
            # 1. ì „ì²´ ë§ˆìŠ¤í¬ ì˜¤ë²„ë ˆì´
            if 'all_clothes' in masks:
                overlay = image.copy()
                mask = masks['all_clothes']
                
                # ë§ˆìŠ¤í¬ë¥¼ ì»¬ëŸ¬ë¡œ ë³€í™˜
                colored_mask = np.zeros_like(image)
                colored_mask[mask > 128] = [255, 0, 0]  # ë¹¨ê°„ìƒ‰
                
                # ì˜¤ë²„ë ˆì´ ìƒì„±
                overlay = cv2.addWeighted(overlay, 0.7, colored_mask, 0.3, 0)
                visualizations['overlay'] = overlay
            
            # 2. ê°œë³„ ë§ˆìŠ¤í¬ë“¤
            for mask_type, mask in masks.items():
                if mask is not None and mask.size > 0:
                    # ë§ˆìŠ¤í¬ë¥¼ ì»¬ëŸ¬ë¡œ ë³€í™˜
                    colored_mask = np.zeros_like(image)
                    colored_mask[mask > 128] = [0, 255, 0]  # ì´ˆë¡ìƒ‰
                    
                    visualizations[f'{mask_type}_mask'] = colored_mask
            
            return visualizations
            
        except Exception as e:
            logger.warning(f"âš ï¸ ì‹œê°í™” ìƒì„± ì‹¤íŒ¨: {e}")
            return {}

    def _run_ai_segmentation_sync_safe(self, image: NDArray, quality_level: QualityLevel,
                                     person_parsing: Dict[str, Any], pose_info: Dict[str, Any]) -> Dict[str, Any]:
        """AI ì„¸ê·¸ë©˜í…Œì´ì…˜ ë™ê¸° ì‹¤í–‰ (ì•ˆì „ ë²„ì „)"""
        try:
            return self._run_ai_segmentation_sync(image, quality_level, person_parsing, pose_info)
        except Exception as e:
            logger.error(f"âŒ AI ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            return self._create_fallback_segmentation_result(image.shape)

    def _run_ai_segmentation_sync(self, image: NDArray, quality_level: QualityLevel,
                                person_parsing: Dict[str, Any], pose_info: Dict[str, Any]) -> Dict[str, Any]:
        """AI ì„¸ê·¸ë©˜í…Œì´ì…˜ ë™ê¸° ì‹¤í–‰"""
        try:
            # 1. ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ í™•ì¸
            available_models = self._detect_available_methods()
            
            if not available_models:
                logger.warning("âš ï¸ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ì´ ì—†ìŒ")
                return self._create_fallback_segmentation_result(image.shape)
            
            # 2. í’ˆì§ˆ ë ˆë²¨ì— ë”°ë¥¸ ëª¨ë¸ ì„ íƒ
            if quality_level == QualityLevel.FAST:
                # ë¹ ë¥¸ ëª¨ë¸ ìš°ì„ 
                if 'u2net_cloth' in available_models:
                    return self._run_single_model_segmentation('u2net_cloth', image)
                elif 'deeplabv3_plus' in available_models:
                    return self._run_single_model_segmentation('deeplabv3_plus', image)
            
            elif quality_level == QualityLevel.ULTRA:
                # ëª¨ë“  ëª¨ë¸ ì•™ìƒë¸”
                return self._run_hybrid_ensemble_sync(image, person_parsing, pose_info)
            
            else:
                # ê¸°ë³¸: í•˜ì´ë¸Œë¦¬ë“œ ì•™ìƒë¸”
                return self._run_hybrid_ensemble_sync(image, person_parsing, pose_info)
                
        except Exception as e:
            logger.error(f"âŒ AI ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            return self._create_fallback_segmentation_result(image.shape)

    def _safe_model_predict(self, model_key: str, image: NDArray) -> Dict[str, Any]:
        """ì•ˆì „í•œ ëª¨ë¸ ì˜ˆì¸¡ - ì‹¤ì œ ì¶”ë¡  ìˆ˜í–‰"""
        try:
            logger.info(f"ğŸ¯ _safe_model_predict ì‹œì‘: {model_key}")
            
            if model_key not in self.segmentation_models:
                logger.warning(f"âš ï¸ ëª¨ë¸ {model_key}ê°€ ë¡œë“œë˜ì§€ ì•ŠìŒ")
                return {'masks': {}, 'confidence': 0.0, 'error': f'ëª¨ë¸ {model_key}ê°€ ë¡œë“œë˜ì§€ ì•ŠìŒ'}
            
            model = self.segmentation_models[model_key]
            logger.info(f"ğŸ¯ {model_key} ëª¨ë¸ë¡œ ì¶”ë¡  ì‹œì‘")
            
            # ì´ë¯¸ì§€ ì „ì²˜ë¦¬
            if len(image.shape) == 3:
                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            
            # ì´ë¯¸ì§€ í¬ê¸° ì¡°ì •
            target_size = (512, 512)
            if image.shape[:2] != target_size:
                image = cv2.resize(image, target_size)
            
            # ì •ê·œí™”
            image = image.astype(np.float32) / 255.0
            
            # ëª¨ë¸ë³„ ì „ì²˜ë¦¬
            if model_key == 'u2net_cloth':
                # U2Net ì „ì²˜ë¦¬
                image = (image - np.array([0.485, 0.456, 0.406])) / np.array([0.229, 0.224, 0.225])
                image_tensor = torch.from_numpy(image).permute(2, 0, 1).unsqueeze(0).float()
            elif model_key == 'sam_huge':
                # SAM ì „ì²˜ë¦¬
                image_tensor = torch.from_numpy(image).permute(2, 0, 1).unsqueeze(0).float()
            elif model_key == 'deeplabv3_plus':
                # DeepLabV3+ ì „ì²˜ë¦¬
                image = (image - np.array([0.485, 0.456, 0.406])) / np.array([0.229, 0.224, 0.225])
                image_tensor = torch.from_numpy(image).permute(2, 0, 1).unsqueeze(0).float()
            else:
                # ê¸°ë³¸ ì „ì²˜ë¦¬
                image_tensor = torch.from_numpy(image).permute(2, 0, 1).unsqueeze(0).float()
            
            image_tensor = image_tensor.to(self.device)
            logger.info(f"ğŸ” {model_key} ëª¨ë¸ ì…ë ¥ í…ì„œ shape: {image_tensor.shape}")
            
            # ì¶”ë¡ 
            with torch.no_grad():
                try:
                    # ëª¨ë¸ì„ eval ëª¨ë“œë¡œ ì„¤ì •
                    model.eval()
                    
                    # ì‹¤ì œ ì¶”ë¡  ìˆ˜í–‰
                    outputs = model(image_tensor)
                    logger.info(f"âœ… {model_key} ëª¨ë¸ ì¶”ë¡  ì™„ë£Œ, ì¶œë ¥ shape: {outputs.shape if hasattr(outputs, 'shape') else 'unknown'}")
                    
                    # ëª¨ë¸ë³„ ê²°ê³¼ ì²˜ë¦¬
                    if model_key == 'u2net_cloth':
                        if isinstance(outputs, tuple):
                            main_output = outputs[0]
                        else:
                            main_output = outputs
                        
                        logger.info(f"ğŸ” U2Net ì¶œë ¥ shape: {main_output.shape}")
                        
                        # ê²°ê³¼ í›„ì²˜ë¦¬
                        mask = torch.sigmoid(main_output).cpu().numpy()[0, 0]
                        mask = (mask > 0.5).astype(np.uint8)
                        
                        # ì‹ ë¢°ë„ ê³„ì‚° ê°œì„ 
                        confidence = float(np.mean(mask)) if np.sum(mask) > 0 else 0.1
                        confidence = max(confidence, 0.1)  # ìµœì†Œ ì‹ ë¢°ë„ ë³´ì¥
                        
                        logger.info(f"ğŸ¯ U2Net ì‹ ë¢°ë„: {confidence:.3f}, ë§ˆìŠ¤í¬ í¬ê¸°: {mask.shape}, ë§ˆìŠ¤í¬ ê°’ ë²”ìœ„: {mask.min()}-{mask.max()}")
                        
                        result = {
                            'success': True,
                            'masks': {'upper_body': mask},
                            'confidence': confidence,
                            'method': 'u2net_cloth'
                        }
                        logger.info(f"âœ… U2Net ê²°ê³¼ ë°˜í™˜: {result}")
                        return result
                    
                    elif model_key == 'sam_huge':
                        if isinstance(outputs, tuple):
                            mask = outputs[0]
                        else:
                            mask = outputs
                        
                        logger.info(f"ğŸ” SAM ì¶œë ¥ shape: {mask.shape}")
                        
                        mask = torch.sigmoid(mask).cpu().numpy()[0, 0]
                        mask = (mask > 0.5).astype(np.uint8)
                        
                        # ì‹ ë¢°ë„ ê³„ì‚° ê°œì„ 
                        confidence = float(np.mean(mask)) if np.sum(mask) > 0 else 0.1
                        confidence = max(confidence, 0.1)  # ìµœì†Œ ì‹ ë¢°ë„ ë³´ì¥
                        
                        logger.info(f"ğŸ¯ SAM ì‹ ë¢°ë„: {confidence:.3f}, ë§ˆìŠ¤í¬ í¬ê¸°: {mask.shape}, ë§ˆìŠ¤í¬ ê°’ ë²”ìœ„: {mask.min()}-{mask.max()}")
                        
                        result = {
                            'success': True,
                            'masks': {'upper_body': mask},
                            'confidence': confidence,
                            'method': 'sam_huge'
                        }
                        logger.info(f"âœ… SAM ê²°ê³¼ ë°˜í™˜: {result}")
                        return result
                    
                    elif model_key == 'deeplabv3_plus':
                        if isinstance(outputs, tuple):
                            mask = outputs[0]
                        else:
                            mask = outputs
                        
                        logger.info(f"ğŸ” DeepLabV3+ ì¶œë ¥ shape: {mask.shape}")
                        
                        mask = torch.softmax(mask, dim=1).cpu().numpy()[0, 1]  # í´ë˜ìŠ¤ 1 (ì˜ë¥˜)
                        mask = (mask > 0.5).astype(np.uint8)
                        
                        # ì‹ ë¢°ë„ ê³„ì‚° ê°œì„ 
                        confidence = float(np.mean(mask)) if np.sum(mask) > 0 else 0.1
                        confidence = max(confidence, 0.1)  # ìµœì†Œ ì‹ ë¢°ë„ ë³´ì¥
                        
                        logger.info(f"ğŸ¯ DeepLabV3+ ì‹ ë¢°ë„: {confidence:.3f}, ë§ˆìŠ¤í¬ í¬ê¸°: {mask.shape}, ë§ˆìŠ¤í¬ ê°’ ë²”ìœ„: {mask.min()}-{mask.max()}")
                        
                        result = {
                            'success': True,
                            'masks': {'upper_body': mask},
                            'confidence': confidence,
                            'method': 'deeplabv3_plus'
                        }
                        logger.info(f"âœ… DeepLabV3+ ê²°ê³¼ ë°˜í™˜: {result}")
                        return result
                    
                    else:
                        # ê¸°ë³¸ ì¶”ë¡ 
                        if isinstance(outputs, tuple):
                            mask = outputs[0]
                        else:
                            mask = outputs
                        
                        logger.info(f"ğŸ” {model_key} ì¶œë ¥ shape: {mask.shape}")
                        
                        mask = torch.sigmoid(mask).cpu().numpy()[0, 0]
                        mask = (mask > 0.5).astype(np.uint8)
                        
                        # ì‹ ë¢°ë„ ê³„ì‚° ê°œì„ 
                        confidence = float(np.mean(mask)) if np.sum(mask) > 0 else 0.1
                        confidence = max(confidence, 0.1)  # ìµœì†Œ ì‹ ë¢°ë„ ë³´ì¥
                        
                        logger.info(f"ğŸ¯ {model_key} ì‹ ë¢°ë„: {confidence:.3f}, ë§ˆìŠ¤í¬ í¬ê¸°: {mask.shape}, ë§ˆìŠ¤í¬ ê°’ ë²”ìœ„: {mask.min()}-{mask.max()}")
                        
                        result = {
                            'success': True,
                            'masks': {'upper_body': mask},
                            'confidence': confidence,
                            'method': model_key
                        }
                        logger.info(f"âœ… {model_key} ê²°ê³¼ ë°˜í™˜: {result}")
                        return result
                        
                except Exception as e:
                    logger.error(f"âŒ {model_key} ëª¨ë¸ ì¶”ë¡  ì‹¤íŒ¨: {e}")
                    return {'masks': {}, 'confidence': 0.0, 'error': str(e)}
                    
        except Exception as e:
            logger.error(f"âŒ {model_key} ì˜ˆì¸¡ ì‹¤íŒ¨: {e}")
            return {'masks': {}, 'confidence': 0.0, 'error': str(e)}

    def _safe_model_predict_with_prompts(self, model_key: str, image: NDArray, prompts: Dict[str, Any]) -> Dict[str, Any]:
        """í”„ë¡¬í”„íŠ¸ê°€ ìˆëŠ” ì•ˆì „í•œ ëª¨ë¸ ì˜ˆì¸¡"""
        try:
            if model_key not in self.segmentation_models:
                logger.warning(f"âš ï¸ ëª¨ë¸ {model_key}ê°€ ë¡œë“œë˜ì§€ ì•ŠìŒ")
                return {'masks': {}, 'confidence': 0.0}
            
            model = self.segmentation_models[model_key]
            if not model:
                return {'masks': {}, 'confidence': 0.0}
            
            # í”„ë¡¬í”„íŠ¸ê°€ ìˆëŠ” ëª¨ë¸ ì˜ˆì¸¡ ì‹¤í–‰
            if hasattr(model, 'predict_with_prompts'):
                result = model.predict_with_prompts(image, prompts)
            else:
                result = model.predict(image)
            
            if not result:
                return {'masks': {}, 'confidence': 0.0}
            
            return result
            
        except Exception as e:
            logger.error(f"âŒ ëª¨ë¸ {model_key} í”„ë¡¬í”„íŠ¸ ì˜ˆì¸¡ ì‹¤íŒ¨: {e}")
            return {'masks': {}, 'confidence': 0.0}

def create_cloth_segmentation_step(**kwargs) -> ClothSegmentationStep:
    """ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ ìŠ¤í… ìƒì„±"""
    try:
        step = ClothSegmentationStep(**kwargs)
        return step
    except Exception as e:
        logger.error(f"âŒ ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ ìŠ¤í… ìƒì„± ì‹¤íŒ¨: {e}")
        return None

def create_m3_max_segmentation_step(**kwargs) -> ClothSegmentationStep:
    """M3 Max ìµœì í™” ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ ìŠ¤í… ìƒì„±"""
    try:
        # M3 Max ìµœì í™” ì„¤ì •
        m3_max_config = {
            'device': 'mps' if torch.backends.mps.is_available() else 'cpu',
            'optimization_level': 'high',
            'memory_efficient': True,
            **kwargs
        }
        
        step = ClothSegmentationStep(**m3_max_config)
        return step
    except Exception as e:
        logger.error(f"âŒ M3 Max ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ ìŠ¤í… ìƒì„± ì‹¤íŒ¨: {e}")
        return None

def test_cloth_segmentation_step():
    """ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ ìŠ¤í… í…ŒìŠ¤íŠ¸"""
    try:
        logger.info("ğŸ§ª ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ ìŠ¤í… í…ŒìŠ¤íŠ¸ ì‹œì‘")
        
        # ìŠ¤í… ìƒì„±
        step = create_cloth_segmentation_step()
        if step is None:
            logger.error("âŒ ìŠ¤í… ìƒì„± ì‹¤íŒ¨")
            return False
        
        # ì´ˆê¸°í™”
        if not step.initialize():
            logger.error("âŒ ìŠ¤í… ì´ˆê¸°í™” ì‹¤íŒ¨")
            return False
        
        # í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ìƒì„±
        test_image = np.random.randint(0, 255, (512, 512, 3), dtype=np.uint8)
        
        # ì²˜ë¦¬ í…ŒìŠ¤íŠ¸
        result = step.process(image=test_image)
        
        if result.get('success', False):
            logger.info("âœ… ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ ìŠ¤í… í…ŒìŠ¤íŠ¸ ì„±ê³µ")
            return True
        else:
            logger.error(f"âŒ ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ ìŠ¤í… í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {result.get('error', 'Unknown error')}")
            return False
            
    except Exception as e:
        logger.error(f"âŒ ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ ìŠ¤í… í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        return False

# ëª¨ë“ˆ ë ˆë²¨ í…ŒìŠ¤íŠ¸
if __name__ == "__main__":
    test_cloth_segmentation_step()
