#!/usr/bin/env python3
"""
ğŸ”¥ MyCloset AI - Step 03: ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ - Integrated Step
=====================================================================

ê¸°ì¡´ step.pyì˜ ëª¨ë“  ê¸°ëŠ¥ì„ importí•´ì„œ ì‚¬ìš©í•˜ëŠ” í†µí•© íŒŒì¼
ê¸°ì¡´ step.pyëŠ” ìˆ˜ì •í•˜ì§€ ì•Šê³ , ì—¬ê¸°ì„œ ëª¨ë“  ê¸°ëŠ¥ì„ í†µí•©í•˜ì—¬ ì‚¬ìš©

Author: MyCloset AI Team  
Date: 2025-08-01
Version: 1.0
"""

import logging
import time
from typing import Dict, Any, List, Tuple, Optional

# ê¸°ì¡´ step.pyì—ì„œ ëª¨ë“  ê¸°ëŠ¥ì„ import
from .step import (
    # ê¸°ë³¸ í´ë˜ìŠ¤ë“¤
    BaseStepMixin, ClothSegmentationStep,
    
    # Enumê³¼ Config
    SegmentationMethod, ClothCategory, QualityLevel, ClothSegmentationConfig,
    
    # AI ëª¨ë¸ë“¤
    ASPPModule, SelfCorrectionModule, MultiHeadSelfAttention, PositionalEncoding2D,
    DeepLabV3PlusBackbone, DeepLabV3PlusDecoder, DeepLabV3PlusModel,
    RealDeepLabV3PlusModel, RealU2NETModel, RealSAMModel,
    
    # ì•™ìƒë¸” ê¸°ëŠ¥ë“¤
    _run_hybrid_ensemble_sync, _combine_ensemble_results,
    _calculate_adaptive_threshold, _apply_ensemble_postprocessing,
    
    # ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
    _get_central_hub_container, _inject_dependencies_safe, _get_service_from_central_hub,
    
    # íŒ©í† ë¦¬ í•¨ìˆ˜ë“¤
    create_cloth_segmentation_step, create_m3_max_segmentation_step
)

# ìƒˆë¡œ ë¶„ë¦¬ëœ ëª¨ë“ˆë“¤ import
from .postprocessing.quality_enhancement import (
    _fill_holes_and_remove_noise_advanced,
    _evaluate_segmentation_quality,
    _create_segmentation_visualizations,
    _assess_image_quality,
    _normalize_lighting,
    _correct_colors
)

from .utils.feature_extraction import (
    _extract_cloth_features,
    _calculate_centroid,
    _calculate_bounding_box,
    _extract_cloth_contours,
    _get_cloth_bounding_boxes,
    _get_cloth_centroids,
    _get_cloth_areas,
    _get_cloth_contours_dict,
    _detect_cloth_categories
)

logger = logging.getLogger(__name__)

class ClothSegmentationStepIntegrated(ClothSegmentationStep):
    """
    í†µí•©ëœ ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ ìŠ¤í… í´ë˜ìŠ¤
    ê¸°ì¡´ step.pyì˜ ëª¨ë“  ê¸°ëŠ¥ì„ ìƒì†ë°›ê³ , ìƒˆë¡œ ë¶„ë¦¬ëœ ëª¨ë“ˆë“¤ì˜ ê¸°ëŠ¥ë„ í†µí•©
    """
    
    def __init__(self, **kwargs):
        # ê¸°ì¡´ í´ë˜ìŠ¤ ì´ˆê¸°í™”
        super().__init__(**kwargs)
        
        # ìƒˆë¡œ ë¶„ë¦¬ëœ ëª¨ë“ˆë“¤ì˜ ê¸°ëŠ¥ë“¤ì„ í´ë˜ìŠ¤ ë©”ì„œë“œë¡œ ë°”ì¸ë”©
        self._fill_holes_and_remove_noise_advanced = _fill_holes_and_remove_noise_advanced.__get__(self, self.__class__)
        self._evaluate_segmentation_quality = _evaluate_segmentation_quality.__get__(self, self.__class__)
        self._create_segmentation_visualizations = _create_segmentation_visualizations.__get__(self, self.__class__)
        self._assess_image_quality = _assess_image_quality.__get__(self, self.__class__)
        self._normalize_lighting = _normalize_lighting.__get__(self, self.__class__)
        self._correct_colors = _correct_colors.__get__(self, self.__class__)
        
        self._extract_cloth_features = _extract_cloth_features.__get__(self, self.__class__)
        self._calculate_centroid = _calculate_centroid.__get__(self, self.__class__)
        self._calculate_bounding_box = _calculate_bounding_box.__get__(self, self.__class__)
        self._extract_cloth_contours = _extract_cloth_contours.__get__(self, self.__class__)
        self._get_cloth_bounding_boxes = _get_cloth_bounding_boxes.__get__(self, self.__class__)
        self._get_cloth_centroids = _get_cloth_centroids.__get__(self, self.__class__)
        self._get_cloth_areas = _get_cloth_areas.__get__(self, self.__class__)
        self._get_cloth_contours_dict = _get_cloth_contours_dict.__get__(self, self.__class__)
        self._detect_cloth_categories = _detect_cloth_categories.__get__(self, self.__class__)
        
        logger.info("ğŸ”¥ ClothSegmentationStepIntegrated ì´ˆê¸°í™” ì™„ë£Œ")
    
    def process(self, **kwargs) -> Dict[str, Any]:
        """
        í†µí•©ëœ ì²˜ë¦¬ ë©”ì„œë“œ
        ê¸°ì¡´ ê¸°ëŠ¥ + ìƒˆë¡œ ë¶„ë¦¬ëœ ëª¨ë“ˆë“¤ì˜ ê¸°ëŠ¥ì„ ëª¨ë‘ ì‚¬ìš©
        """
        try:
            # ê¸°ì¡´ process ë©”ì„œë“œ í˜¸ì¶œ
            result = super().process(**kwargs)
            
            # ìƒˆë¡œ ë¶„ë¦¬ëœ ëª¨ë“ˆë“¤ì˜ ê¸°ëŠ¥ë“¤ì„ ì¶”ê°€ë¡œ ì ìš©
            if 'masks' in result and result['masks']:
                # í’ˆì§ˆ í–¥ìƒ í›„ì²˜ë¦¬ ì ìš©
                enhanced_masks = self._fill_holes_and_remove_noise_advanced(result['masks'])
                result['masks'] = enhanced_masks
                
                # í’ˆì§ˆ í‰ê°€ ì¶”ê°€
                if 'image' in kwargs:
                    quality_metrics = self._evaluate_segmentation_quality(enhanced_masks, kwargs['image'])
                    result['quality_metrics'] = quality_metrics
                
                # íŠ¹ì„± ì¶”ì¶œ ì¶”ê°€
                if 'image' in kwargs:
                    features = self._extract_cloth_features(enhanced_masks, kwargs['image'])
                    result['features'] = features
                
                # ì‹œê°í™” ì¶”ê°€
                if 'image' in kwargs:
                    visualizations = self._create_segmentation_visualizations(kwargs['image'], enhanced_masks)
                    result['visualizations'] = visualizations
            
            return result
            
        except Exception as e:
            logger.error(f"í†µí•© ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return self._create_error_response(str(e))
    
    def _enhanced_postprocessing(self, masks: Dict[str, Any], image: np.ndarray) -> Dict[str, Any]:
        """
        í–¥ìƒëœ í›„ì²˜ë¦¬ ë©”ì„œë“œ
        ìƒˆë¡œ ë¶„ë¦¬ëœ ëª¨ë“ˆë“¤ì˜ ê¸°ëŠ¥ë“¤ì„ ëª¨ë‘ ì ìš©
        """
        try:
            # ê¸°ì¡´ í›„ì²˜ë¦¬
            processed_masks = self._postprocess_masks(masks)
            
            # ìƒˆë¡œ ë¶„ë¦¬ëœ ëª¨ë“ˆë“¤ì˜ ê¸°ëŠ¥ë“¤ ì ìš©
            # 1. í’ˆì§ˆ í–¥ìƒ
            enhanced_masks = self._fill_holes_and_remove_noise_advanced(processed_masks)
            
            # 2. í’ˆì§ˆ í‰ê°€
            quality_metrics = self._evaluate_segmentation_quality(enhanced_masks, image)
            
            # 3. íŠ¹ì„± ì¶”ì¶œ
            features = self._extract_cloth_features(enhanced_masks, image)
            
            # 4. ì‹œê°í™”
            visualizations = self._create_segmentation_visualizations(image, enhanced_masks)
            
            return {
                'masks': enhanced_masks,
                'quality_metrics': quality_metrics,
                'features': features,
                'visualizations': visualizations
            }
            
        except Exception as e:
            logger.error(f"í–¥ìƒëœ í›„ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return {'masks': masks}

def create_cloth_segmentation_step_integrated(**kwargs) -> ClothSegmentationStepIntegrated:
    """
    í†µí•©ëœ ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ ìŠ¤í… ìƒì„± íŒ©í† ë¦¬ í•¨ìˆ˜
    """
    try:
        step = ClothSegmentationStepIntegrated(**kwargs)
        logger.info("ğŸ”¥ í†µí•©ëœ ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ ìŠ¤í… ìƒì„± ì™„ë£Œ")
        return step
    except Exception as e:
        logger.error(f"í†µí•©ëœ ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ ìŠ¤í… ìƒì„± ì‹¤íŒ¨: {e}")
        raise

def create_m3_max_segmentation_step_integrated(**kwargs) -> ClothSegmentationStepIntegrated:
    """
    M3 Maxìš© í†µí•©ëœ ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ ìŠ¤í… ìƒì„± íŒ©í† ë¦¬ í•¨ìˆ˜
    """
    try:
        # M3 Max ìµœì í™” ì„¤ì • ì¶”ê°€
        m3_max_kwargs = {
            'device': 'mps' if hasattr(torch.backends, 'mps') and torch.backends.mps.is_available() else 'cpu',
            'memory_efficient': True,
            'batch_size': 1,
            **kwargs
        }
        
        step = ClothSegmentationStepIntegrated(**m3_max_kwargs)
        logger.info("ğŸ M3 Maxìš© í†µí•©ëœ ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ ìŠ¤í… ìƒì„± ì™„ë£Œ")
        return step
    except Exception as e:
        logger.error(f"M3 Maxìš© í†µí•©ëœ ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ ìŠ¤í… ìƒì„± ì‹¤íŒ¨: {e}")
        raise
