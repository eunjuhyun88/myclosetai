# app/ai_pipeline/steps/step_03_cloth_segmentation.py
"""
ğŸ”¥ MyCloset AI - 3ë‹¨ê³„: ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ (ìˆœí™˜ì°¸ì¡° ì™„ì „ í•´ê²° + AI ì—°ë™ ë²„ì „)
===============================================================================

âœ… TYPE_CHECKING íŒ¨í„´ìœ¼ë¡œ ìˆœí™˜ì°¸ì¡° ì™„ì „ ë°©ì§€ (1ë²ˆ íŒŒì¼ í•´ê²°ë²• ì ìš©)
âœ… ë™ì  importë¥¼ í†µí•œ BaseStepMixin ì•ˆì „ ë¡œë”©
âœ… ì‹¤ì œ AI ëª¨ë¸ ì—°ë™ ë° ì¶”ë¡  (U2Net, RemBG, SAM, DeepLab)
âœ… M3 Max 128GB ë©”ëª¨ë¦¬ ìµœì í™”
âœ… conda í™˜ê²½ ìš°ì„  ì§€ì›
âœ… í”„ë¡œë•ì…˜ ë ˆë²¨ ì•ˆì •ì„±
âœ… ì™„ì „í•œ ê¸°ëŠ¥ ì‘ë™ ë³´ì¥
âœ… Python êµ¬ì¡° ë° ë“¤ì—¬ì“°ê¸° ì™„ì „ ì •ë¦¬

Author: MyCloset AI Team
Date: 2025-07-22  
Version: v9.1 (Structure Fixed + AI Integration)
"""

import os
import sys
import logging
import time
import asyncio
import threading
import gc
import hashlib
import json
import base64
import weakref
from typing import Dict, Any, Optional, Tuple, List, Union, Callable, TYPE_CHECKING
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor, as_completed
from dataclasses import dataclass, field
from enum import Enum
from io import BytesIO
import platform
import subprocess

# ==============================================
# ğŸ”¥ 1. TYPE_CHECKINGìœ¼ë¡œ ìˆœí™˜ì°¸ì¡° ì™„ì „ ë°©ì§€
# ==============================================

if TYPE_CHECKING:
    # íƒ€ì… ì²´í‚¹ ì‹œì—ë§Œ import (ëŸ°íƒ€ì„ì—ëŠ” import ì•ˆë¨) 
    from ..utils.model_loader import ModelLoader, StepModelInterface
    from ..steps.base_step_mixin import BaseStepMixin, ClothSegmentationMixin
    from ..factories.step_factory import StepFactory
    from ...core.di_container import DIContainer

# ==============================================
# ğŸ”¥ 2. í•µì‹¬ ë¼ì´ë¸ŒëŸ¬ë¦¬ (conda í™˜ê²½ ìš°ì„ )
# ==============================================

# ë¡œê±° ì„¤ì •
logger = logging.getLogger(__name__)

# NumPy ì•ˆì „ Import
NUMPY_AVAILABLE = False
try:
    import numpy as np
    NUMPY_AVAILABLE = True
    logger.info("ğŸ“Š NumPy ë¡œë“œ ì™„ë£Œ (conda í™˜ê²½ ìš°ì„ )")
except ImportError:
    logger.warning("âš ï¸ NumPy ì—†ìŒ - conda install numpy ê¶Œì¥")

# OpenCV ì•ˆì „ Import
OPENCV_AVAILABLE = False
try:
    os.environ['OPENCV_IO_ENABLE_OPENEXR'] = '0'
    os.environ['OPENCV_IO_ENABLE_JASPER'] = '0'
    import cv2
    OPENCV_AVAILABLE = True
    logger.info(f"ğŸ¨ OpenCV {cv2.__version__} ë¡œë“œ ì™„ë£Œ (conda í™˜ê²½)")
except ImportError:
    logger.warning("âš ï¸ OpenCV ì—†ìŒ - conda install opencv ê¶Œì¥")

# PIL Import
PIL_AVAILABLE = False
try:
    from PIL import Image, ImageEnhance, ImageFilter, ImageOps, ImageDraw, ImageFont
    PIL_AVAILABLE = True
    logger.info("ğŸ–¼ï¸ PIL ë¡œë“œ ì™„ë£Œ (conda í™˜ê²½)")
except ImportError:
    logger.warning("âš ï¸ PIL ì—†ìŒ - conda install pillow ê¶Œì¥")

# PyTorch Import (conda í™˜ê²½ ìš°ì„ )
TORCH_AVAILABLE = False
MPS_AVAILABLE = False
try:
    import torch
    import torch.nn as nn
    import torch.nn.functional as F
    from torchvision import transforms
    TORCH_AVAILABLE = True
    
    if hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
        MPS_AVAILABLE = True
        
    logger.info(f"ğŸ”¥ PyTorch {torch.__version__} ë¡œë“œ ì™„ë£Œ (conda í™˜ê²½)")
    if MPS_AVAILABLE:
        logger.info("ğŸ MPS ì‚¬ìš© ê°€ëŠ¥ (M3 Max ìµœì í™”)")
except ImportError:
    logger.warning("âš ï¸ PyTorch ì—†ìŒ - conda install pytorch ê¶Œì¥")

# AI ë¼ì´ë¸ŒëŸ¬ë¦¬ë“¤ (ì„ íƒì )
REMBG_AVAILABLE = False
try:
    import rembg
    from rembg import remove, new_session
    REMBG_AVAILABLE = True
    logger.info("ğŸ¤– RemBG ë¡œë“œ ì™„ë£Œ")
except ImportError:
    logger.warning("âš ï¸ RemBG ì—†ìŒ - pip install rembg")

SKLEARN_AVAILABLE = False
try:
    from sklearn.cluster import KMeans
    from sklearn.preprocessing import StandardScaler
    SKLEARN_AVAILABLE = True
    logger.info("ğŸ“ˆ scikit-learn ë¡œë“œ ì™„ë£Œ")
except ImportError:
    logger.warning("âš ï¸ scikit-learn ì—†ìŒ - conda install scikit-learn")

SAM_AVAILABLE = False
try:
    import segment_anything as sam
    SAM_AVAILABLE = True
    logger.info("ğŸ¯ SAM ë¡œë“œ ì™„ë£Œ")
except ImportError:
    logger.warning("âš ï¸ SAM ì—†ìŒ - pip install segment-anything")

TRANSFORMERS_AVAILABLE = False
try:
    from transformers import pipeline
    TRANSFORMERS_AVAILABLE = True
    logger.info("ğŸ¤— Transformers ë¡œë“œ ì™„ë£Œ")
except ImportError:
    logger.warning("âš ï¸ Transformers ì—†ìŒ - pip install transformers")

# ==============================================
# ğŸ”¥ 3. ë™ì  Import í•¨ìˆ˜ë“¤ (TYPE_CHECKING íŒ¨í„´)
# ==============================================

def get_base_step_mixin():
    """BaseStepMixinì„ ì•ˆì „í•˜ê²Œ ê°€ì ¸ì˜¤ê¸° (TYPE_CHECKING íŒ¨í„´)"""
    try:
        import importlib
        module = importlib.import_module('..steps.base_step_mixin', package=__package__)
        return getattr(module, 'BaseStepMixin', None)
    except ImportError as e:
        logger.error(f"âŒ BaseStepMixin ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None

def get_cloth_segmentation_mixin():
    """ClothSegmentationMixinì„ ì•ˆì „í•˜ê²Œ ê°€ì ¸ì˜¤ê¸° (TYPE_CHECKING íŒ¨í„´)"""
    try:
        import importlib
        module = importlib.import_module('..steps.base_step_mixin', package=__package__)
        return getattr(module, 'ClothSegmentationMixin', None)
    except ImportError as e:
        logger.error(f"âŒ ClothSegmentationMixin ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None

def get_model_loader():
    """ModelLoaderë¥¼ ì•ˆì „í•˜ê²Œ ê°€ì ¸ì˜¤ê¸° (TYPE_CHECKING íŒ¨í„´)"""
    try:
        import importlib
        module = importlib.import_module('..utils.model_loader', package=__package__)
        get_global_loader = getattr(module, 'get_global_model_loader', None)
        if get_global_loader:
            return get_global_loader()
        return None
    except ImportError as e:
        logger.error(f"âŒ ModelLoader ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None

def get_di_container():
    """DI Containerë¥¼ ì•ˆì „í•˜ê²Œ ê°€ì ¸ì˜¤ê¸° (TYPE_CHECKING íŒ¨í„´)"""
    try:
        import importlib  
        module = importlib.import_module('...core.di_container', package=__package__)
        get_container = getattr(module, 'get_di_container', None)
        if get_container:
            return get_container()
        return None
    except ImportError as e:
        logger.warning(f"âš ï¸ DI Container ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None

# ==============================================
# ğŸ”¥ 4. ë°ì´í„° êµ¬ì¡° ì •ì˜
# ==============================================

class SegmentationMethod(Enum):
    """ì„¸ê·¸ë©˜í…Œì´ì…˜ ë°©ë²•"""
    U2NET = "u2net"
    REMBG = "rembg"
    SAM = "sam"
    DEEP_LAB = "deeplab"
    MASK_RCNN = "mask_rcnn"
    TRADITIONAL = "traditional"
    HYBRID = "hybrid"
    AUTO = "auto"

class ClothingType(Enum):
    """ì˜ë¥˜ íƒ€ì…"""
    SHIRT = "shirt"
    DRESS = "dress"
    PANTS = "pants"
    SKIRT = "skirt"
    JACKET = "jacket"
    SWEATER = "sweater"
    COAT = "coat"
    TOP = "top"
    BOTTOM = "bottom"
    UNKNOWN = "unknown"

class QualityLevel(Enum):
    """í’ˆì§ˆ ë ˆë²¨"""
    FAST = "fast"
    BALANCED = "balanced"
    HIGH = "high"
    ULTRA = "ultra"

@dataclass
class SegmentationConfig:
    """ì„¸ê·¸ë©˜í…Œì´ì…˜ ì„¤ì •"""
    method: SegmentationMethod = SegmentationMethod.AUTO
    quality_level: QualityLevel = QualityLevel.BALANCED
    input_size: Tuple[int, int] = (512, 512)
    output_size: Optional[Tuple[int, int]] = None
    enable_visualization: bool = True
    enable_post_processing: bool = True
    enable_edge_refinement: bool = True
    enable_hole_filling: bool = True
    use_fp16: bool = True
    batch_size: int = 1
    confidence_threshold: float = 0.8
    iou_threshold: float = 0.5
    edge_smoothing: bool = True
    remove_noise: bool = True
    visualization_quality: str = "high"
    enable_caching: bool = True
    cache_size: int = 100
    show_masks: bool = True
    show_boundaries: bool = True
    overlay_opacity: float = 0.6

@dataclass
class SegmentationResult:
    """ì„¸ê·¸ë©˜í…Œì´ì…˜ ê²°ê³¼"""
    success: bool
    mask: Optional[np.ndarray] = None
    segmented_image: Optional[np.ndarray] = None
    confidence_score: float = 0.0
    quality_score: float = 0.0
    method_used: str = "unknown"
    processing_time: float = 0.0
    metadata: Dict[str, Any] = field(default_factory=dict)
    error_message: Optional[str] = None
    # ì‹œê°í™” ì´ë¯¸ì§€ë“¤
    visualization_image: Optional[Image.Image] = None
    overlay_image: Optional[Image.Image] = None
    mask_image: Optional[Image.Image] = None
    boundary_image: Optional[Image.Image] = None

# ==============================================
# ğŸ”¥ 5. ì˜ë¥˜ë³„ ìƒ‰ìƒ ë§¤í•‘ (ì‹œê°í™”ìš©)
# ==============================================

CLOTHING_COLORS = {
    'shirt': (255, 100, 100),      # ë¹¨ê°•
    'pants': (100, 100, 255),      # íŒŒë‘
    'dress': (255, 100, 255),      # ë¶„í™
    'jacket': (100, 255, 100),     # ì´ˆë¡
    'skirt': (255, 255, 100),      # ë…¸ë‘
    'sweater': (138, 43, 226),     # ë¸”ë£¨ë°”ì´ì˜¬ë ›
    'coat': (165, 42, 42),         # ê°ˆìƒ‰
    'top': (0, 255, 255),          # ì‹œì•ˆ
    'bottom': (255, 165, 0),       # ì˜¤ë Œì§€
    'shoes': (255, 150, 0),        # ì£¼í™©
    'bag': (150, 75, 0),           # ê°ˆìƒ‰
    'hat': (128, 0, 128),          # ë³´ë¼
    'accessory': (0, 255, 255),    # ì‹œì•ˆ
    'unknown': (128, 128, 128),    # íšŒìƒ‰
}

# ==============================================
# ğŸ”¥ 6. AI ëª¨ë¸ í´ë˜ìŠ¤ë“¤ (ì‹¤ì œ êµ¬í˜„)
# ==============================================

class REBNCONV(nn.Module):
    """U2-Netì˜ ê¸°ë³¸ ì»¨ë³¼ë£¨ì…˜ ë¸”ë¡"""
    
    def __init__(self, in_ch=3, out_ch=3, dirate=1):
        super(REBNCONV, self).__init__()
        self.conv_s1 = nn.Conv2d(in_ch, out_ch, 3, padding=1*dirate, dilation=1*dirate)
        self.bn_s1 = nn.BatchNorm2d(out_ch)
        self.relu_s1 = nn.ReLU(inplace=True)
    
    def forward(self, x):
        return self.relu_s1(self.bn_s1(self.conv_s1(x)))

class RSU7(nn.Module):
    """U2-Net RSU-7 ë¸”ë¡"""
    
    def __init__(self, in_ch=3, mid_ch=12, out_ch=3):
        super(RSU7, self).__init__()
        self.rebnconvin = REBNCONV(in_ch, out_ch, dirate=1)
        
        self.rebnconv1 = REBNCONV(out_ch, mid_ch, dirate=1)
        self.pool1 = nn.MaxPool2d(2, stride=2, ceil_mode=True)
        
        self.rebnconv2 = REBNCONV(mid_ch, mid_ch, dirate=1)
        self.pool2 = nn.MaxPool2d(2, stride=2, ceil_mode=True)
        
        self.rebnconv3 = REBNCONV(mid_ch, mid_ch, dirate=1)
        self.pool3 = nn.MaxPool2d(2, stride=2, ceil_mode=True)
        
        self.rebnconv4 = REBNCONV(mid_ch, mid_ch, dirate=1)
        self.pool4 = nn.MaxPool2d(2, stride=2, ceil_mode=True)
        
        self.rebnconv5 = REBNCONV(mid_ch, mid_ch, dirate=1)
        self.pool5 = nn.MaxPool2d(2, stride=2, ceil_mode=True)
        
        self.rebnconv6 = REBNCONV(mid_ch, mid_ch, dirate=1)
        self.rebnconv7 = REBNCONV(mid_ch, mid_ch, dirate=2)
        
        self.rebnconv6d = REBNCONV(mid_ch*2, mid_ch, dirate=1)
        self.upsample6 = nn.Upsample(scale_factor=2, mode='bilinear')
        
        self.rebnconv5d = REBNCONV(mid_ch*2, mid_ch, dirate=1)
        self.upsample5 = nn.Upsample(scale_factor=2, mode='bilinear')
        
        self.rebnconv4d = REBNCONV(mid_ch*2, mid_ch, dirate=1)
        self.upsample4 = nn.Upsample(scale_factor=2, mode='bilinear')
        
        self.rebnconv3d = REBNCONV(mid_ch*2, mid_ch, dirate=1)
        self.upsample3 = nn.Upsample(scale_factor=2, mode='bilinear')
        
        self.rebnconv2d = REBNCONV(mid_ch*2, mid_ch, dirate=1)
        self.upsample2 = nn.Upsample(scale_factor=2, mode='bilinear')
        
        self.rebnconv1d = REBNCONV(mid_ch*2, out_ch, dirate=1)
    
    def forward(self, x):
        hx = x
        hxin = self.rebnconvin(hx)
        
        hx1 = self.rebnconv1(hxin)
        hx = self.pool1(hx1)
        
        hx2 = self.rebnconv2(hx)
        hx = self.pool2(hx2)
        
        hx3 = self.rebnconv3(hx)
        hx = self.pool3(hx3)
        
        hx4 = self.rebnconv4(hx)
        hx = self.pool4(hx4)
        
        hx5 = self.rebnconv5(hx)
        hx = self.pool5(hx5)
        
        hx6 = self.rebnconv6(hx)
        hx7 = self.rebnconv7(hx6)
        
        hx6d = self.rebnconv6d(torch.cat((hx7, hx6), 1))
        hx6dup = self.upsample6(hx6d)
        
        hx5d = self.rebnconv5d(torch.cat((hx6dup, hx5), 1))
        hx5dup = self.upsample5(hx5d)
        
        hx4d = self.rebnconv4d(torch.cat((hx5dup, hx4), 1))
        hx4dup = self.upsample4(hx4d)
        
        hx3d = self.rebnconv3d(torch.cat((hx4dup, hx3), 1))
        hx3dup = self.upsample3(hx3d)
        
        hx2d = self.rebnconv2d(torch.cat((hx3dup, hx2), 1))
        hx2dup = self.upsample2(hx2d)
        
        hx1d = self.rebnconv1d(torch.cat((hx2dup, hx1), 1))
        
        return hx1d + hxin

class U2NET(nn.Module):
    """U2-Net ë©”ì¸ ëª¨ë¸ (ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ ìµœì í™”)"""
    
    def __init__(self, in_ch=3, out_ch=1):
        super(U2NET, self).__init__()
        
        # ì¸ì½”ë”
        self.stage1 = RSU7(in_ch, 32, 64)
        self.pool12 = nn.MaxPool2d(2, stride=2, ceil_mode=True)
        
        self.stage2 = RSU7(64, 32, 128)
        self.pool23 = nn.MaxPool2d(2, stride=2, ceil_mode=True)
        
        self.stage3 = RSU7(128, 64, 256)
        self.pool34 = nn.MaxPool2d(2, stride=2, ceil_mode=True)
        
        self.stage4 = RSU7(256, 128, 512)
        self.pool45 = nn.MaxPool2d(2, stride=2, ceil_mode=True)
        
        self.stage5 = RSU7(512, 256, 512)
        self.pool56 = nn.MaxPool2d(2, stride=2, ceil_mode=True)
        
        self.stage6 = RSU7(512, 256, 512)
        
        # ë””ì½”ë”
        self.stage5d = RSU7(1024, 256, 512)
        self.stage4d = RSU7(1024, 128, 256)
        self.stage3d = RSU7(512, 64, 128)
        self.stage2d = RSU7(256, 32, 64)
        self.stage1d = RSU7(128, 16, 64)
        
        # Side outputs
        self.side1 = nn.Conv2d(64, out_ch, 3, padding=1)
        self.side2 = nn.Conv2d(64, out_ch, 3, padding=1)
        self.side3 = nn.Conv2d(128, out_ch, 3, padding=1)
        self.side4 = nn.Conv2d(256, out_ch, 3, padding=1)
        self.side5 = nn.Conv2d(512, out_ch, 3, padding=1)
        self.side6 = nn.Conv2d(512, out_ch, 3, padding=1)
        
        self.outconv = nn.Conv2d(6*out_ch, out_ch, 1)
    
    def forward(self, x):
        hx = x
        
        # ì¸ì½”ë”
        hx1 = self.stage1(hx)
        hx = self.pool12(hx1)
        
        hx2 = self.stage2(hx)
        hx = self.pool23(hx2)
        
        hx3 = self.stage3(hx)
        hx = self.pool34(hx3)
        
        hx4 = self.stage4(hx)
        hx = self.pool45(hx4)
        
        hx5 = self.stage5(hx)
        hx = self.pool56(hx5)
        
        hx6 = self.stage6(hx)
        
        # ë””ì½”ë”
        hx5d = self.stage5d(torch.cat((hx6, hx5), 1))
        hx5dup = F.interpolate(hx5d, size=hx4.shape[2:], mode='bilinear', align_corners=False)
        
        hx4d = self.stage4d(torch.cat((hx5dup, hx4), 1))
        hx4dup = F.interpolate(hx4d, size=hx3.shape[2:], mode='bilinear', align_corners=False)
        
        hx3d = self.stage3d(torch.cat((hx4dup, hx3), 1))
        hx3dup = F.interpolate(hx3d, size=hx2.shape[2:], mode='bilinear', align_corners=False)
        
        hx2d = self.stage2d(torch.cat((hx3dup, hx2), 1))
        hx2dup = F.interpolate(hx2d, size=hx1.shape[2:], mode='bilinear', align_corners=False)
        
        hx1d = self.stage1d(torch.cat((hx2dup, hx1), 1))
        
        # Side outputs
        d1 = self.side1(hx1d)
        d2 = F.interpolate(self.side2(hx2d), size=d1.shape[2:], mode='bilinear', align_corners=False)
        d3 = F.interpolate(self.side3(hx3d), size=d1.shape[2:], mode='bilinear', align_corners=False)
        d4 = F.interpolate(self.side4(hx4d), size=d1.shape[2:], mode='bilinear', align_corners=False)
        d5 = F.interpolate(self.side5(hx5d), size=d1.shape[2:], mode='bilinear', align_corners=False)
        d6 = F.interpolate(self.side6(hx6), size=d1.shape[2:], mode='bilinear', align_corners=False)
        
        # ìµœì¢… ì¶œë ¥
        d0 = self.outconv(torch.cat((d1, d2, d3, d4, d5, d6), 1))
        
        return torch.sigmoid(d0), torch.sigmoid(d1), torch.sigmoid(d2), torch.sigmoid(d3), torch.sigmoid(d4), torch.sigmoid(d5), torch.sigmoid(d6)

# ==============================================
# ğŸ”¥ 7. ë©”ì¸ ClothSegmentationStep í´ë˜ìŠ¤
# ==============================================

class ClothSegmentationStep:
    """
    ğŸ”¥ ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ Step - TYPE_CHECKING íŒ¨í„´ + AI ì—°ë™
    
    âœ… TYPE_CHECKING íŒ¨í„´ ì™„ì „ ì ìš©
    âœ… ë™ì  importë¡œ BaseStepMixin ì•ˆì „ ë¡œë”©
    âœ… ì‹¤ì œ AI ì¶”ë¡  (U2Net, RemBG ë“±)
    âœ… ìˆœí™˜ì°¸ì¡° ì™„ì „ ë°©ì§€
    âœ… M3 Max ìµœì í™”
    âœ… conda í™˜ê²½ ì§€ì›
    âœ… Python êµ¬ì¡° ì™„ì „ ì •ë¦¬
    """
    
    def __init__(
        self,
        device: Optional[str] = None,
        config: Optional[Union[Dict[str, Any], SegmentationConfig]] = None,
        **kwargs
    ):
        """ìƒì„±ì - TYPE_CHECKING íŒ¨í„´ ê¸°ë°˜"""
        
        # ===== 1. ê¸°ë³¸ ì†ì„± ì„¤ì • =====
        self.step_name = "ClothSegmentationStep"
        self.step_number = 3
        self.step_type = "cloth_segmentation"
        self.device = device or self._auto_detect_device()
        
        # ===== 2. Logger ì„¤ì • =====
        self.logger = logging.getLogger(f"pipeline.steps.{self.step_name}")
        
        # ===== 3. ì„¤ì • ì²˜ë¦¬ =====
        if isinstance(config, dict):
            self.segmentation_config = SegmentationConfig(**config)
        elif isinstance(config, SegmentationConfig):
            self.segmentation_config = config
        else:
            self.segmentation_config = SegmentationConfig()
        
        # ===== 4. ë™ì  importë¡œ ì˜ì¡´ì„± í•´ê²° =====
        self.model_loader = None
        self.memory_manager = None
        self.data_converter = None
        self.base_step_mixin = None
        self.di_container = None
        
        # ===== 5. ìƒíƒœ ë³€ìˆ˜ ì´ˆê¸°í™” =====
        self.is_initialized = False
        self.models_loaded = {}
        self.checkpoints_loaded = {}
        self.available_methods = []
        self.rembg_sessions = {}
        
        # ===== 6. M3 Max ê°ì§€ ë° ìµœì í™” =====
        self.is_m3_max = self._detect_m3_max()
        self.memory_gb = kwargs.get('memory_gb', 128.0 if self.is_m3_max else 16.0)
        
        # ===== 7. í†µê³„ ë° ìºì‹œ ì´ˆê¸°í™” =====
        self.processing_stats = {
            'total_processed': 0,
            'successful_segmentations': 0,
            'failed_segmentations': 0,
            'average_time': 0.0,
            'average_quality': 0.0,
            'method_usage': {},
            'cache_hits': 0,
            'ai_model_calls': 0
        }
        
        self.segmentation_cache = {}
        self.cache_lock = threading.RLock()
        self.executor = ThreadPoolExecutor(
            max_workers=4 if self.is_m3_max else 2,
            thread_name_prefix="cloth_seg"
        )
        
        self.logger.info("âœ… ClothSegmentationStep ìƒì„± ì™„ë£Œ (TYPE_CHECKING íŒ¨í„´)")
        self.logger.info(f"   - Device: {self.device}")

    def _auto_detect_device(self) -> str:
        """ë””ë°”ì´ìŠ¤ ìë™ ê°ì§€"""
        try:
            if TORCH_AVAILABLE:
                if MPS_AVAILABLE:
                    return "mps"
                elif torch.cuda.is_available():
                    return "cuda"
            return "cpu"
        except Exception:
            return "cpu"

    def _detect_m3_max(self) -> bool:
        """M3 Max ì¹© ê°ì§€"""
        try:
            if platform.system() == 'Darwin':
                result = subprocess.run(
                    ['sysctl', '-n', 'machdep.cpu.brand_string'],
                    capture_output=True, text=True
                )
                cpu_info = result.stdout.strip()
                return 'M3 Max' in cpu_info or 'M3' in cpu_info
        except Exception:
            pass
        return False

    # ==============================================
    # ğŸ”¥ 8. ë™ì  ì˜ì¡´ì„± ì£¼ì… ë©”ì„œë“œë“¤
    # ==============================================
    
    def _resolve_dependencies(self):
        """ë™ì  importë¡œ ì˜ì¡´ì„± í•´ê²° (TYPE_CHECKING íŒ¨í„´)"""
        try:
            # BaseStepMixin ë™ì  ë¡œë”©
            if not self.base_step_mixin:
                BaseStepMixin = get_base_step_mixin()
                if BaseStepMixin:
                    self.base_step_mixin = BaseStepMixin
                    self.logger.info("âœ… BaseStepMixin ë™ì  ë¡œë”© ì„±ê³µ")
            
            # ModelLoader ë™ì  ë¡œë”©
            if not self.model_loader:
                model_loader = get_model_loader()
                if model_loader:
                    self.model_loader = model_loader
                    self.logger.info("âœ… ModelLoader ë™ì  ë¡œë”© ì„±ê³µ")
            
            # DI Container ë™ì  ë¡œë”©
            if not self.di_container:
                di_container = get_di_container()
                if di_container:
                    self.di_container = di_container
                    self.logger.info("âœ… DI Container ë™ì  ë¡œë”© ì„±ê³µ")
                    
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ ì˜ì¡´ì„± í•´ê²° ì‹¤íŒ¨: {e}")
            return False

    def set_model_loader(self, model_loader):
        """ModelLoader ì˜ì¡´ì„± ì£¼ì…"""
        try:
            self.model_loader = model_loader
            self.logger.info("âœ… ModelLoader ì˜ì¡´ì„± ì£¼ì… ì™„ë£Œ")
            return True
        except Exception as e:
            self.logger.error(f"âŒ ModelLoader ì£¼ì… ì‹¤íŒ¨: {e}")
            return False

    def set_memory_manager(self, memory_manager):
        """MemoryManager ì˜ì¡´ì„± ì£¼ì…"""
        try:
            self.memory_manager = memory_manager
            self.logger.info("âœ… MemoryManager ì˜ì¡´ì„± ì£¼ì… ì™„ë£Œ")
            return True
        except Exception as e:
            self.logger.warning(f"âš ï¸ MemoryManager ì£¼ì… ì‹¤íŒ¨: {e}")
            return False

    def set_data_converter(self, data_converter):
        """DataConverter ì˜ì¡´ì„± ì£¼ì…"""
        try:
            self.data_converter = data_converter
            self.logger.info("âœ… DataConverter ì˜ì¡´ì„± ì£¼ì… ì™„ë£Œ")
            return True
        except Exception as e:
            self.logger.warning(f"âš ï¸ DataConverter ì£¼ì… ì‹¤íŒ¨: {e}")
            return False

    # ==============================================
    # ğŸ”¥ 9. ì´ˆê¸°í™” ë©”ì„œë“œ
    # ==============================================
    
    async def initialize(self) -> bool:
        """ì´ˆê¸°í™” - TYPE_CHECKING íŒ¨í„´ + ì‹¤ì œ AI ëª¨ë¸ ë¡œë”©"""
        try:
            self.logger.info("ğŸ”„ ClothSegmentationStep ì´ˆê¸°í™” ì‹œì‘")
            
            # ===== 1. ë™ì  ì˜ì¡´ì„± í•´ê²° =====
            if not self._resolve_dependencies():
                self.logger.warning("âš ï¸ ì˜ì¡´ì„± í•´ê²° ì‹¤íŒ¨, í´ë°± ëª¨ë“œë¡œ ì§„í–‰")
            
            # ===== 2. ModelLoaderë¥¼ í†µí•œ ì²´í¬í¬ì¸íŠ¸ ë¡œë”© =====
            if not await self._load_checkpoints_via_model_loader():
                self.logger.warning("âš ï¸ ModelLoader ì²´í¬í¬ì¸íŠ¸ ë¡œë”© ì‹¤íŒ¨")
            
            # ===== 3. ì²´í¬í¬ì¸íŠ¸ì—ì„œ ì‹¤ì œ AI ëª¨ë¸ ìƒì„± =====
            if not await self._create_ai_models_from_checkpoints():
                self.logger.warning("âš ï¸ AI ëª¨ë¸ ìƒì„± ì‹¤íŒ¨")
            
            # ===== 4. RemBG ì„¸ì…˜ ì´ˆê¸°í™” =====
            if REMBG_AVAILABLE:
                await self._initialize_rembg_sessions()
            
            # ===== 5. M3 Max ìµœì í™” ì›Œë°ì—… =====
            if self.is_m3_max:
                await self._warmup_m3_max()
            
            # ===== 6. ì‚¬ìš© ê°€ëŠ¥í•œ ë°©ë²• ê°ì§€ =====
            self.available_methods = self._detect_available_methods()
            if not self.available_methods:
                self.logger.warning("âš ï¸ ì‚¬ìš© ê°€ëŠ¥í•œ ì„¸ê·¸ë©˜í…Œì´ì…˜ ë°©ë²•ì´ ì—†ìŠµë‹ˆë‹¤")
                self.available_methods = [SegmentationMethod.TRADITIONAL]
            
            # ===== 7. ì´ˆê¸°í™” ì™„ë£Œ =====
            self.is_initialized = True
            self.logger.info("âœ… ClothSegmentationStep ì´ˆê¸°í™” ì™„ë£Œ")
            self.logger.info(f"   - ë¡œë“œëœ ì²´í¬í¬ì¸íŠ¸: {list(self.checkpoints_loaded.keys())}")
            self.logger.info(f"   - ìƒì„±ëœ AI ëª¨ë¸: {list(self.models_loaded.keys())}")
            self.logger.info(f"   - ì‚¬ìš© ê°€ëŠ¥í•œ ë°©ë²•: {[m.value for m in self.available_methods]}")
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.is_initialized = False
            return False

    async def _load_checkpoints_via_model_loader(self) -> bool:
        """ModelLoaderë¥¼ í†µí•œ ì²´í¬í¬ì¸íŠ¸ ë¡œë”©"""
        try:
            if not self.model_loader:
                return False
            
            self.logger.info("ğŸ”„ ModelLoaderë¥¼ í†µí•œ ì²´í¬í¬ì¸íŠ¸ ë¡œë”© ì‹œì‘...")
            
            # ===== U2-Net ì²´í¬í¬ì¸íŠ¸ ë¡œë”© =====
            try:
                self.logger.info("ğŸ”„ U2-Net ì²´í¬í¬ì¸íŠ¸ ë¡œë”© ì¤‘...")
                
                if hasattr(self.model_loader, 'load_model_async'):
                    u2net_checkpoint = await self.model_loader.load_model_async("cloth_segmentation_u2net")
                elif hasattr(self.model_loader, 'load_model'):
                    u2net_checkpoint = self.model_loader.load_model("cloth_segmentation_u2net")
                else:
                    u2net_checkpoint = None
                
                if u2net_checkpoint:
                    self.checkpoints_loaded['u2net'] = u2net_checkpoint
                    self.logger.info("âœ… U2-Net ì²´í¬í¬ì¸íŠ¸ ë¡œë”© ì™„ë£Œ")
                    
            except Exception as e:
                self.logger.warning(f"âš ï¸ U2-Net ì²´í¬í¬ì¸íŠ¸ ë¡œë”© ì‹¤íŒ¨: {e}")
            
            return len(self.checkpoints_loaded) > 0
            
        except Exception as e:
            self.logger.error(f"âŒ ì²´í¬í¬ì¸íŠ¸ ë¡œë”© ì‹¤íŒ¨: {e}")
            return False

    async def _create_ai_models_from_checkpoints(self) -> bool:
        """ì²´í¬í¬ì¸íŠ¸ì—ì„œ ì‹¤ì œ AI ëª¨ë¸ ìƒì„±"""
        try:
            if not TORCH_AVAILABLE:
                self.logger.error("âŒ PyTorchê°€ ì—†ì–´ì„œ AI ëª¨ë¸ ìƒì„± ë¶ˆê°€")
                return False
            
            self.logger.info("ğŸ”„ ì²´í¬í¬ì¸íŠ¸ì—ì„œ ì‹¤ì œ AI ëª¨ë¸ ìƒì„± ì‹œì‘...")
            
            # ===== U2-Net ëª¨ë¸ ìƒì„± =====
            if 'u2net' in self.checkpoints_loaded:
                try:
                    self.logger.info("ğŸ”„ U2-Net AI ëª¨ë¸ ìƒì„± ì¤‘...")
                    
                    # U2-Net ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
                    u2net_model = U2NET(in_ch=3, out_ch=1)
                    
                    # ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ
                    checkpoint = self.checkpoints_loaded['u2net']
                    if isinstance(checkpoint, dict):
                        if 'model' in checkpoint:
                            u2net_model.load_state_dict(checkpoint['model'])
                        elif 'state_dict' in checkpoint:
                            u2net_model.load_state_dict(checkpoint['state_dict'])
                        else:
                            u2net_model.load_state_dict(checkpoint)
                    elif hasattr(checkpoint, 'state_dict'):
                        u2net_model.load_state_dict(checkpoint.state_dict())
                    else:
                        u2net_model.load_state_dict(checkpoint)
                    
                    # ë””ë°”ì´ìŠ¤ ì´ë™ ë° í‰ê°€ ëª¨ë“œ
                    u2net_model = u2net_model.to(self.device)
                    u2net_model.eval()
                    
                    self.models_loaded['u2net'] = u2net_model
                    self.logger.info("âœ… U2-Net AI ëª¨ë¸ ìƒì„± ë° ë¡œë”© ì™„ë£Œ")
                    
                except Exception as e:
                    self.logger.warning(f"âš ï¸ U2-Net AI ëª¨ë¸ ìƒì„± ì‹¤íŒ¨: {e}")
            
            return len(self.models_loaded) > 0
            
        except Exception as e:
            self.logger.error(f"âŒ AI ëª¨ë¸ ìƒì„± ì‹¤íŒ¨: {e}")
            return False

    async def _initialize_rembg_sessions(self):
        """RemBG ì„¸ì…˜ ì´ˆê¸°í™”"""
        try:
            if not REMBG_AVAILABLE:
                return
            
            self.logger.info("ğŸ”„ RemBG ì„¸ì…˜ ì´ˆê¸°í™” ì‹œì‘...")
            
            session_configs = {
                'u2net': 'u2net',
                'u2netp': 'u2netp',
                'silueta': 'silueta',
            }
            
            for name, model_name in session_configs.items():
                try:
                    session = new_session(model_name)
                    self.rembg_sessions[name] = session
                    self.logger.info(f"âœ… RemBG ì„¸ì…˜ ìƒì„±: {name}")
                except Exception as e:
                    self.logger.warning(f"âš ï¸ RemBG ì„¸ì…˜ {name} ìƒì„± ì‹¤íŒ¨: {e}")
            
            if self.rembg_sessions:
                self.default_rembg_session = (
                    self.rembg_sessions.get('u2net') or
                    list(self.rembg_sessions.values())[0]
                )
                self.logger.info("âœ… RemBG ê¸°ë³¸ ì„¸ì…˜ ì„¤ì • ì™„ë£Œ")
                
        except Exception as e:
            self.logger.warning(f"âš ï¸ RemBG ì„¸ì…˜ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")

    async def _warmup_m3_max(self):
        """M3 Max ì›Œë°ì—…"""
        try:
            if not self.is_m3_max or not TORCH_AVAILABLE:
                return
            
            self.logger.info("ğŸ”¥ M3 Max ì›Œë°ì—… ì‹œì‘...")
            
            # ë”ë¯¸ í…ì„œë¡œ ì›Œë°ì—…
            dummy_input = torch.randn(1, 3, 512, 512, device=self.device)
            
            for model_name, model in self.models_loaded.items():
                try:
                    if hasattr(model, 'eval'):
                        model.eval()
                        with torch.no_grad():
                            if hasattr(model, 'forward'):
                                _ = model(dummy_input)
                            elif callable(model):
                                _ = model(dummy_input)
                        self.logger.info(f"âœ… {model_name} M3 Max ì›Œë°ì—… ì™„ë£Œ")
                except Exception as e:
                    self.logger.warning(f"âš ï¸ {model_name} ì›Œë°ì—… ì‹¤íŒ¨: {e}")
            
            # MPS ìºì‹œ ì •ë¦¬
            if MPS_AVAILABLE:
                try:
                    torch.mps.empty_cache()
                except:
                    pass
            
            self.logger.info("âœ… M3 Max ì›Œë°ì—… ì™„ë£Œ")
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ M3 Max ì›Œë°ì—… ì‹¤íŒ¨: {e}")

    def _detect_available_methods(self) -> List[SegmentationMethod]:
        """ì‚¬ìš© ê°€ëŠ¥í•œ ì„¸ê·¸ë©˜í…Œì´ì…˜ ë°©ë²• ê°ì§€"""
        methods = []
        
        # ë¡œë“œëœ AI ëª¨ë¸ ê¸°ë°˜ìœ¼ë¡œ ë°©ë²• ê²°ì •
        if 'u2net' in self.models_loaded:
            methods.append(SegmentationMethod.U2NET)
            self.logger.info("âœ… U2NET ë°©ë²• ì‚¬ìš© ê°€ëŠ¥ (ì‹¤ì œ AI ëª¨ë¸)")
        
        if 'deeplab' in self.models_loaded:
            methods.append(SegmentationMethod.DEEP_LAB)
            self.logger.info("âœ… DeepLab ë°©ë²• ì‚¬ìš© ê°€ëŠ¥ (ì‹¤ì œ AI ëª¨ë¸)")
        
        if 'sam' in self.models_loaded:
            methods.append(SegmentationMethod.SAM)
            self.logger.info("âœ… SAM ë°©ë²• ì‚¬ìš© ê°€ëŠ¥ (ì‹¤ì œ AI ëª¨ë¸)")
        
        if 'mask_rcnn' in self.models_loaded:
            methods.append(SegmentationMethod.MASK_RCNN)
            self.logger.info("âœ… MASK_RCNN ë°©ë²• ì‚¬ìš© ê°€ëŠ¥ (ì‹¤ì œ AI ëª¨ë¸)")
        
        # RemBG í™•ì¸
        if REMBG_AVAILABLE and self.rembg_sessions:
            methods.append(SegmentationMethod.REMBG)
            self.logger.info("âœ… RemBG ë°©ë²• ì‚¬ìš© ê°€ëŠ¥")
        
        # Traditional ë°©ë²• (ë³´ì¡° ë°©ë²•)
        if OPENCV_AVAILABLE and SKLEARN_AVAILABLE:
            methods.append(SegmentationMethod.TRADITIONAL)
            self.logger.info("âœ… Traditional ë°©ë²• ì‚¬ìš© ê°€ëŠ¥")
        
        # AUTO ë°©ë²• (AI ëª¨ë¸ì´ ìˆì„ ë•Œë§Œ)
        ai_methods = [m for m in methods if m != SegmentationMethod.TRADITIONAL]
        if ai_methods:
            methods.append(SegmentationMethod.AUTO)
            self.logger.info("âœ… AUTO ë°©ë²• ì‚¬ìš© ê°€ëŠ¥")
        
        # HYBRID ë°©ë²• (2ê°œ ì´ìƒ AI ë°©ë²•ì´ ìˆì„ ë•Œ)
        if len(ai_methods) >= 2:
            methods.append(SegmentationMethod.HYBRID)
            self.logger.info("âœ… HYBRID ë°©ë²• ì‚¬ìš© ê°€ëŠ¥")
        
        return methods

    # ==============================================
    # ğŸ”¥ 10. í•µì‹¬: process ë©”ì„œë“œ (ì‹¤ì œ AI ì¶”ë¡ )
    # ==============================================
    
    async def process(
    self,
    image,
    clothing_type: Optional[str] = None,
    quality_level: Optional[str] = None,
    **kwargs
) -> Dict[str, Any]:
        """ë©”ì¸ ì²˜ë¦¬ ë©”ì„œë“œ - TYPE_CHECKING íŒ¨í„´ + ì‹¤ì œ AI ì¶”ë¡ """
        
        if not self.is_initialized:
            if not await self.initialize():
                return self._create_error_result("ì´ˆê¸°í™” ì‹¤íŒ¨")

        start_time = time.time()
        
        try:
            self.logger.info("ğŸ”„ ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ ì²˜ë¦¬ ì‹œì‘ (TYPE_CHECKING + AI ì¶”ë¡ )")
            
            # ===== 1. ì´ë¯¸ì§€ ì „ì²˜ë¦¬ =====
            processed_image = self._preprocess_image(image)
            if processed_image is None:
                return self._create_error_result("ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì‹¤íŒ¨")
            
            # ===== 2. ì˜ë¥˜ íƒ€ì… ê°ì§€ =====
            detected_clothing_type = self._detect_clothing_type(processed_image, clothing_type)
            
            # ===== 3. í’ˆì§ˆ ë ˆë²¨ ì„¤ì • =====
            quality = QualityLevel(quality_level or self.segmentation_config.quality_level.value)
            
            # ===== 4. ì‹¤ì œ AI ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‹¤í–‰ (monitor_performance ì œê±°) =====
            self.logger.info("ğŸ”„ AI ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‹œì‘...")
            mask, confidence = await self._run_ai_segmentation(
                processed_image, detected_clothing_type, quality
            )
            
            if mask is None:
                return self._create_error_result("AI ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‹¤íŒ¨")
            
            # ===== 5. í›„ì²˜ë¦¬ =====
            final_mask = self._post_process_mask(mask, quality)
            
            # ===== 6. ì‹œê°í™” ì´ë¯¸ì§€ ìƒì„± =====
            visualizations = {}
            if self.segmentation_config.enable_visualization:
                self.logger.info("ğŸ”„ ì‹œê°í™” ì´ë¯¸ì§€ ìƒì„±...")
                visualizations = self._create_visualizations(
                    processed_image, final_mask, detected_clothing_type
                )
            
            # ===== 7. ê²°ê³¼ ìƒì„± =====
            processing_time = time.time() - start_time
            
            result = {
                'success': True,
                'mask': final_mask,
                'confidence': confidence,
                'clothing_type': detected_clothing_type.value if hasattr(detected_clothing_type, 'value') else str(detected_clothing_type),
                'processing_time': processing_time,
                'method_used': self._get_current_method(),
                'ai_models_used': list(self.models_loaded.keys()) if hasattr(self, 'models_loaded') else [],
                'metadata': {
                    'device': self.device,
                    'quality_level': quality.value,
                    'models_used': list(self.models_loaded.keys()) if hasattr(self, 'models_loaded') else [],
                    'checkpoints_loaded': list(self.checkpoints_loaded.keys()) if hasattr(self, 'checkpoints_loaded') else [],
                    'image_size': processed_image.size if hasattr(processed_image, 'size') else (512, 512),
                    'ai_inference': True,
                    'model_loader_used': self.model_loader is not None,
                    'is_m3_max': self.is_m3_max,
                    'type_checking_pattern': True,
                    'monitor_performance_fixed': True  # ìˆ˜ì •ë¨ì„ í‘œì‹œ
                }
            }
            
            # ì‹œê°í™” ì´ë¯¸ì§€ë“¤ ì¶”ê°€
            if visualizations:
                if 'visualization' in visualizations:
                    result['visualization_base64'] = self._image_to_base64(visualizations['visualization'])
                if 'overlay' in visualizations:
                    result['overlay_base64'] = self._image_to_base64(visualizations['overlay'])
            
            # í†µê³„ ì—…ë°ì´íŠ¸
            self._update_processing_stats(processing_time, True)
            
            self.logger.info(f"âœ… TYPE_CHECKING + AI ì„¸ê·¸ë©˜í…Œì´ì…˜ ì™„ë£Œ - {processing_time:.2f}ì´ˆ")
            return result
            
        except Exception as e:
            processing_time = time.time() - start_time
            self._update_processing_stats(processing_time, False)
            
            self.logger.error(f"âŒ TYPE_CHECKING + AI ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return self._create_error_result(f"ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")

    async def _run_ai_segmentation(
        self,
        image: Image.Image,
        clothing_type: ClothingType,
        quality: QualityLevel
    ) -> Tuple[Optional[np.ndarray], float]:
        """ì‹¤ì œ AI ì„¸ê·¸ë©˜í…Œì´ì…˜ ì¶”ë¡ """
        try:
            # ìš°ì„ ìˆœìœ„ ìˆœì„œë¡œ AI ë°©ë²• ì‹œë„
            methods_to_try = self._get_ai_methods_by_priority(quality)
            
            for method in methods_to_try:
                try:
                    self.logger.info(f"ğŸ§  AI ë°©ë²• ì‹œë„: {method.value}")
                    mask, confidence = await self._run_ai_method(method, image, clothing_type)
                    
                    if mask is not None:
                        self.processing_stats['ai_model_calls'] += 1
                        self.processing_stats['method_usage'][method.value] = (
                            self.processing_stats['method_usage'].get(method.value, 0) + 1
                        )
                        
                        self.logger.info(f"âœ… AI ì„¸ê·¸ë©˜í…Œì´ì…˜ ì„±ê³µ: {method.value} (ì‹ ë¢°ë„: {confidence:.3f})")
                        return mask, confidence
                        
                except Exception as e:
                    self.logger.warning(f"âš ï¸ AI ë°©ë²• {method.value} ì‹¤íŒ¨: {e}")
                    continue
            
            # ëª¨ë“  AI ë°©ë²• ì‹¤íŒ¨ ì‹œ ì „í†µì  ë°©ë²• ì‹œë„
            self.logger.warning("âš ï¸ ëª¨ë“  AI ë°©ë²• ì‹¤íŒ¨, ì „í†µì  ë°©ë²• ì‹œë„")
            return await self._run_traditional_segmentation(image)
            
        except Exception as e:
            self.logger.error(f"âŒ AI ì„¸ê·¸ë©˜í…Œì´ì…˜ ì¶”ë¡  ì‹¤íŒ¨: {e}")
            return None, 0.0

    def _get_ai_methods_by_priority(self, quality: QualityLevel) -> List[SegmentationMethod]:
        """í’ˆì§ˆ ë ˆë²¨ë³„ AI ë°©ë²• ìš°ì„ ìˆœìœ„"""
        available_ai_methods = [
            method for method in self.available_methods
            if method not in [SegmentationMethod.TRADITIONAL, SegmentationMethod.AUTO, SegmentationMethod.HYBRID]
        ]
        
        if quality == QualityLevel.ULTRA:
            priority = [
                SegmentationMethod.HYBRID,
                SegmentationMethod.U2NET,
                SegmentationMethod.SAM,
                SegmentationMethod.MASK_RCNN,
                SegmentationMethod.DEEP_LAB,
                SegmentationMethod.REMBG
            ]
        elif quality == QualityLevel.HIGH:
            priority = [
                SegmentationMethod.U2NET,
                SegmentationMethod.HYBRID,
                SegmentationMethod.SAM,
                SegmentationMethod.REMBG,
                SegmentationMethod.DEEP_LAB
            ]
        elif quality == QualityLevel.BALANCED:
            priority = [
                SegmentationMethod.REMBG,
                SegmentationMethod.U2NET,
                SegmentationMethod.DEEP_LAB
            ]
        else:  # FAST
            priority = [
                SegmentationMethod.REMBG,
                SegmentationMethod.U2NET
            ]
        
        return [method for method in priority if method in available_ai_methods]

    async def _run_ai_method(
        self,
        method: SegmentationMethod,
        image: Image.Image,
        clothing_type: ClothingType
    ) -> Tuple[Optional[np.ndarray], float]:
        """ê°œë³„ AI ì„¸ê·¸ë©˜í…Œì´ì…˜ ë°©ë²• ì‹¤í–‰"""
        
        if method == SegmentationMethod.U2NET:
            return await self._run_u2net_inference(image)
        elif method == SegmentationMethod.REMBG:
            return await self._run_rembg_inference(image)
        elif method == SegmentationMethod.HYBRID:
            return await self._run_hybrid_inference(image, clothing_type)
        else:
            raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” AI ë°©ë²•: {method}")

    async def _run_u2net_inference(self, image: Image.Image) -> Tuple[Optional[np.ndarray], float]:
        """U2-Net ì‹¤ì œ AI ì¶”ë¡ """
        try:
            if 'u2net' not in self.models_loaded:
                raise RuntimeError("âŒ U2-Net ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•ŠìŒ")
            
            model = self.models_loaded['u2net']
            
            if not TORCH_AVAILABLE:
                raise RuntimeError("âŒ PyTorchê°€ í•„ìš”í•©ë‹ˆë‹¤")
            
            transform = transforms.Compose([
                transforms.ToTensor(),
                transforms.Normalize(mean=[0.485, 0.456, 0.406],
                                   std=[0.229, 0.224, 0.225])
            ])
            
            input_tensor = transform(image).unsqueeze(0).to(self.device)
            
            # ğŸ”¥ ì‹¤ì œ AI ëª¨ë¸ ì¶”ë¡ 
            model.eval()
            with torch.no_grad():
                if self.is_m3_max and self.segmentation_config.use_fp16:
                    with torch.autocast(device_type='cpu'):
                        output = model(input_tensor)
                else:
                    output = model(input_tensor)
                
                # ì¶œë ¥ ì²˜ë¦¬
                if isinstance(output, tuple):
                    output = output[0]
                elif isinstance(output, list):
                    output = output[0]
                
                # ì‹œê·¸ëª¨ì´ë“œ ë° ì„ê³„ê°’ ì²˜ë¦¬
                if output.max() > 1.0:
                    prob_map = torch.sigmoid(output)
                else:
                    prob_map = output
                
                mask = (prob_map > self.segmentation_config.confidence_threshold).float()
                
                # CPUë¡œ ì´ë™ ë° NumPy ë³€í™˜
                mask_np = mask.squeeze().cpu().numpy()
                confidence = float(prob_map.max().item())
            
            self.logger.info(f"âœ… U2-Net AI ì¶”ë¡  ì™„ë£Œ - ì‹ ë¢°ë„: {confidence:.3f}")
            return mask_np, confidence
            
        except Exception as e:
            self.logger.error(f"âŒ U2-Net AI ì¶”ë¡  ì‹¤íŒ¨: {e}")
            raise

    async def _run_rembg_inference(self, image: Image.Image) -> Tuple[Optional[np.ndarray], float]:
        """RemBG AI ì¶”ë¡ """
        try:
            if not self.rembg_sessions:
                raise RuntimeError("âŒ RemBG ì„¸ì…˜ì´ ì—†ìŒ")
            
            # ìµœì  ì„¸ì…˜ ì„ íƒ
            session = (
                self.rembg_sessions.get('u2net') or
                list(self.rembg_sessions.values())[0]
            )
            
            # ğŸ”¥ ì‹¤ì œ RemBG AI ì¶”ë¡ 
            result = remove(image, session=session)
            
            # ì•ŒíŒŒ ì±„ë„ì—ì„œ ë§ˆìŠ¤í¬ ì¶”ì¶œ
            if result.mode == 'RGBA':
                mask = np.array(result)[:, :, 3]  # ì•ŒíŒŒ ì±„ë„
                mask = (mask > 128).astype(np.uint8)  # ì´ì§„í™”
                
                # ì‹ ë¢°ë„ ê³„ì‚°
                confidence = np.sum(mask) / mask.size
                confidence = min(confidence * 2, 1.0)  # ì •ê·œí™”
                
                self.logger.info(f"âœ… RemBG AI ì¶”ë¡  ì™„ë£Œ - ì‹ ë¢°ë„: {confidence:.3f}")
                return mask, confidence
            else:
                raise RuntimeError("âŒ RemBG ê²°ê³¼ì— ì•ŒíŒŒ ì±„ë„ì´ ì—†ìŒ")
                
        except Exception as e:
            self.logger.error(f"âŒ RemBG AI ì¶”ë¡  ì‹¤íŒ¨: {e}")
            raise

    async def _run_hybrid_inference(self, image: Image.Image, clothing_type: ClothingType) -> Tuple[Optional[np.ndarray], float]:
        """HYBRID AI ì¶”ë¡  (ì—¬ëŸ¬ ëª¨ë¸ ê²°í•©)"""
        try:
            self.logger.info("ğŸ”„ HYBRID AI ì¶”ë¡  ì‹œì‘...")
            
            masks = []
            confidences = []
            methods_used = []
            
            # ì‚¬ìš© ê°€ëŠ¥í•œ AI ë°©ë²•ë“¤ë¡œ ì¶”ë¡  ì‹¤í–‰
            available_ai_methods = [
                method for method in self.available_methods 
                if method not in [SegmentationMethod.TRADITIONAL, SegmentationMethod.AUTO, SegmentationMethod.HYBRID]
            ]
            
            # ìµœì†Œ 2ê°œ ì´ìƒì˜ ë°©ë²•ì´ ìˆì„ ë•Œë§Œ ì‹¤í–‰
            if len(available_ai_methods) < 2:
                raise RuntimeError("âŒ HYBRID ë°©ë²•ì€ ìµœì†Œ 2ê°œ ì´ìƒì˜ AI ë°©ë²•ì´ í•„ìš”")
            
            for method in available_ai_methods[:3]:  # ìµœëŒ€ 3ê°œ ë°©ë²• ì‚¬ìš©
                try:
                    mask, confidence = await self._run_ai_method(method, image, clothing_type)
                    if mask is not None:
                        masks.append(mask)
                        confidences.append(confidence)
                        methods_used.append(method.value)
                        self.logger.info(f"âœ… HYBRID - {method.value} ì¶”ë¡  ì™„ë£Œ: {confidence:.3f}")
                except Exception as e:
                    self.logger.warning(f"âš ï¸ HYBRID - {method.value} ì‹¤íŒ¨: {e}")
                    continue
            
            if not masks:
                raise RuntimeError("âŒ HYBRID - ëª¨ë“  ë°©ë²• ì‹¤íŒ¨")
            
            # ë§ˆìŠ¤í¬ ì•™ìƒë¸” (ê°€ì¤‘ í‰ê· )
            if len(masks) == 1:
                combined_mask = masks[0]
                combined_confidence = confidences[0]
            else:
                # ì‹ ë¢°ë„ ê¸°ë°˜ ê°€ì¤‘ í‰ê· 
                weights = np.array(confidences)
                weights = weights / np.sum(weights)  # ì •ê·œí™”
                
                # ë§ˆìŠ¤í¬ë“¤ì„ ê°™ì€ í¬ê¸°ë¡œ ë§ì¶¤
                target_shape = masks[0].shape
                normalized_masks = []
                for mask in masks:
                    if mask.shape != target_shape:
                        if OPENCV_AVAILABLE:
                            mask_resized = cv2.resize(mask.astype(np.float32), 
                                                   (target_shape[1], target_shape[0]))
                            normalized_masks.append(mask_resized)
                        else:
                            normalized_masks.append(mask.astype(np.float32))
                    else:
                        normalized_masks.append(mask.astype(np.float32))
                
                # ê°€ì¤‘ í‰ê·  ê³„ì‚°
                combined_mask_float = np.zeros_like(normalized_masks[0])
                for mask, weight in zip(normalized_masks, weights):
                    combined_mask_float += mask * weight
                
                # ì„ê³„ê°’ ì ìš©
                combined_mask = (combined_mask_float > 0.5).astype(np.uint8)
                combined_confidence = float(np.mean(confidences))
            
            self.logger.info(f"âœ… HYBRID AI ì¶”ë¡  ì™„ë£Œ - ë°©ë²•: {methods_used} - ì‹ ë¢°ë„: {combined_confidence:.3f}")
            return combined_mask, combined_confidence
            
        except Exception as e:
            self.logger.error(f"âŒ HYBRID AI ì¶”ë¡  ì‹¤íŒ¨: {e}")
            raise

    async def _run_traditional_segmentation(self, image: Image.Image) -> Tuple[Optional[np.ndarray], float]:
        """ì „í†µì  ì„¸ê·¸ë©˜í…Œì´ì…˜ (í´ë°±)"""
        try:
            if not OPENCV_AVAILABLE or not NUMPY_AVAILABLE:
                return None, 0.0
            
            # ê°„ë‹¨í•œ ìƒ‰ìƒ ê¸°ë°˜ ì„¸ê·¸ë©˜í…Œì´ì…˜
            image_array = np.array(image)
            
            # HSV ë³€í™˜
            hsv = cv2.cvtColor(image_array, cv2.COLOR_RGB2HSV)
            
            # í”¼ë¶€ìƒ‰ ì œê±° (ê°„ë‹¨í•œ íœ´ë¦¬ìŠ¤í‹±)
            lower_skin = np.array([0, 20, 70], dtype=np.uint8)
            upper_skin = np.array([20, 255, 255], dtype=np.uint8)
            skin_mask = cv2.inRange(hsv, lower_skin, upper_skin)
            
            # ì˜ë¥˜ ì˜ì—­ ì¶”ì • (ì „ì²´ - í”¼ë¶€)
            mask = np.ones((image_array.shape[0], image_array.shape[1]), dtype=np.uint8) * 255
            mask[skin_mask > 0] = 0
            
            # ë…¸ì´ì¦ˆ ì œê±°
            kernel = np.ones((5, 5), np.uint8)
            mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)
            mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)
            
            # ì´ì§„í™”
            mask = (mask > 128).astype(np.uint8)
            
            confidence = 0.5  # ì „í†µì  ë°©ë²•ì€ ë‚®ì€ ì‹ ë¢°ë„
            
            self.logger.info(f"âœ… ì „í†µì  ì„¸ê·¸ë©˜í…Œì´ì…˜ ì™„ë£Œ - ì‹ ë¢°ë„: {confidence:.3f}")
            return mask, confidence
            
        except Exception as e:
            self.logger.error(f"âŒ ì „í†µì  ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‹¤íŒ¨: {e}")
            return None, 0.0

    # ==============================================
    # ğŸ”¥ 11. ì´ë¯¸ì§€ ì²˜ë¦¬ ë° í›„ì²˜ë¦¬ ë©”ì„œë“œë“¤
    # ==============================================
    
    def _preprocess_image(self, image):
        """ì´ë¯¸ì§€ ì „ì²˜ë¦¬"""
        try:
            # ì…ë ¥ íƒ€ì…ë³„ ì²˜ë¦¬
            if isinstance(image, str):
                if image.startswith('data:image'):
                    # Base64
                    header, data = image.split(',', 1)
                    image_data = base64.b64decode(data)
                    image = Image.open(BytesIO(image_data))
                else:
                    # íŒŒì¼ ê²½ë¡œ
                    image = Image.open(image)
            elif isinstance(image, np.ndarray):
                if image.shape[2] == 3:  # RGB
                    image = Image.fromarray(image)
                elif image.shape[2] == 4:  # RGBA
                    image = Image.fromarray(image).convert('RGB')
                else:
                    raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì´ë¯¸ì§€ í˜•íƒœ: {image.shape}")
            elif not isinstance(image, Image.Image):
                raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì´ë¯¸ì§€ íƒ€ì…: {type(image)}")
            
            # RGB ë³€í™˜
            if image.mode != 'RGB':
                image = image.convert('RGB')
            
            # í¬ê¸° ì¡°ì •
            target_size = self.segmentation_config.input_size
            if image.size != target_size:
                image = image.resize(target_size, Image.Resampling.LANCZOS)
            
            return image
                
        except Exception as e:
            self.logger.error(f"âŒ ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return None

    def _detect_clothing_type(self, image, hint=None):
        """ì˜ë¥˜ íƒ€ì… ê°ì§€"""
        if hint:
            try:
                return ClothingType(hint.lower())
            except ValueError:
                pass
        
        # ê°„ë‹¨í•œ íœ´ë¦¬ìŠ¤í‹± ê¸°ë°˜ ê°ì§€
        if hasattr(image, 'size'):
            width, height = image.size
            aspect_ratio = height / width
            
            if aspect_ratio > 1.5:
                return ClothingType.DRESS
            elif aspect_ratio > 1.2:
                return ClothingType.SHIRT
            else:
                return ClothingType.PANTS
        
        return ClothingType.UNKNOWN

    def _post_process_mask(self, mask, quality):
        """ë§ˆìŠ¤í¬ í›„ì²˜ë¦¬"""
        try:
            if not OPENCV_AVAILABLE or not NUMPY_AVAILABLE:
                return mask
            
            processed_mask = mask.copy()
            
            if self.segmentation_config.remove_noise:
                # ë…¸ì´ì¦ˆ ì œê±°
                kernel_size = 3 if quality == QualityLevel.FAST else 5
                kernel = np.ones((kernel_size, kernel_size), np.uint8)
                processed_mask = cv2.morphologyEx(processed_mask, cv2.MORPH_OPEN, kernel)
                processed_mask = cv2.morphologyEx(processed_mask, cv2.MORPH_CLOSE, kernel)
            
            if self.segmentation_config.edge_smoothing:
                # ì—£ì§€ ìŠ¤ë¬´ë”©
                processed_mask = cv2.GaussianBlur(processed_mask.astype(np.float32), (3, 3), 0.5)
                processed_mask = (processed_mask > 0.5).astype(np.uint8)
            
            # í™€ ì±„ìš°ê¸°
            if self.segmentation_config.enable_hole_filling:
                processed_mask = self._fill_holes(processed_mask)
            
            # ê²½ê³„ ê°œì„ 
            if self.segmentation_config.enable_edge_refinement:
                processed_mask = self._refine_edges(processed_mask)
            
            return processed_mask
        except Exception as e:
            self.logger.warning(f"âš ï¸ ë§ˆìŠ¤í¬ í›„ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return mask

    def _fill_holes(self, mask: np.ndarray) -> np.ndarray:
        """ë§ˆìŠ¤í¬ ë‚´ë¶€ í™€ ì±„ìš°ê¸°"""
        try:
            if not OPENCV_AVAILABLE:
                return mask
            
            contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            filled_mask = np.zeros_like(mask)
            for contour in contours:
                cv2.fillPoly(filled_mask, [contour], 1)
            return filled_mask
        except Exception as e:
            self.logger.warning(f"âš ï¸ í™€ ì±„ìš°ê¸° ì‹¤íŒ¨: {e}")
            return mask

    def _refine_edges(self, mask: np.ndarray) -> np.ndarray:
        """ê²½ê³„ ê°œì„ """
        try:
            if not OPENCV_AVAILABLE:
                return mask
            
            if self.segmentation_config.enable_edge_refinement:
                # ê²½ê³„ ê²€ì¶œ
                edges = cv2.Canny(mask, 50, 150)
                
                # ê²½ê³„ ì£¼ë³€ ì˜ì—­ í™•ì¥
                kernel = np.ones((5, 5), np.uint8)
                edge_region = cv2.dilate(edges, kernel, iterations=1)
                
                # í•´ë‹¹ ì˜ì—­ì— ê°€ìš°ì‹œì•ˆ ë¸”ëŸ¬ ì ìš©
                blurred_mask = cv2.GaussianBlur(mask.astype(np.float32), (5, 5), 1.0)
                
                # ê²½ê³„ ì˜ì—­ë§Œ ë¸”ëŸ¬ëœ ê°’ìœ¼ë¡œ êµì²´
                refined_mask = mask.copy().astype(np.float32)
                refined_mask[edge_region > 0] = blurred_mask[edge_region > 0]
                
                return (refined_mask > 0.5).astype(np.uint8)
            
            return mask
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ ê²½ê³„ ê°œì„  ì‹¤íŒ¨: {e}")
            return mask

    # ==============================================
    # ğŸ”¥ 12. ì‹œê°í™” ë©”ì„œë“œë“¤
    # ==============================================

    def _create_visualizations(self, image, mask, clothing_type):
        """ì‹œê°í™” ì´ë¯¸ì§€ ìƒì„±"""
        try:
            if not PIL_AVAILABLE or not NUMPY_AVAILABLE:
                return {}
            
            visualizations = {}
            
            # ìƒ‰ìƒ ì„ íƒ
            color = CLOTHING_COLORS.get(
                clothing_type.value if hasattr(clothing_type, 'value') else str(clothing_type),
                CLOTHING_COLORS['unknown']
            )
            
            # 1. ë§ˆìŠ¤í¬ ì´ë¯¸ì§€ (ìƒ‰ìƒ êµ¬ë¶„)
            mask_colored = np.zeros((*mask.shape, 3), dtype=np.uint8)
            mask_colored[mask > 0] = color
            visualizations['mask'] = Image.fromarray(mask_colored)
            
            # 2. ì˜¤ë²„ë ˆì´ ì´ë¯¸ì§€
            image_array = np.array(image)
            overlay = image_array.copy()
            alpha = self.segmentation_config.overlay_opacity
            overlay[mask > 0] = (
                overlay[mask > 0] * (1 - alpha) +
                np.array(color) * alpha
            ).astype(np.uint8)
            
            # ê²½ê³„ì„  ì¶”ê°€ (OpenCV ì‚¬ìš© ê°€ëŠ¥í•œ ê²½ìš°)
            if OPENCV_AVAILABLE:
                boundary = cv2.Canny((mask * 255).astype(np.uint8), 50, 150)
                overlay[boundary > 0] = (255, 255, 255)
            
            visualizations['overlay'] = Image.fromarray(overlay)
            
            # 3. ê²½ê³„ì„  ì´ë¯¸ì§€
            if OPENCV_AVAILABLE:
                boundary = cv2.Canny((mask * 255).astype(np.uint8), 50, 150)
                boundary_colored = np.zeros((*boundary.shape, 3), dtype=np.uint8)
                boundary_colored[boundary > 0] = (255, 255, 255)
                
                boundary_overlay = image_array.copy()
                boundary_overlay[boundary > 0] = (255, 255, 255)
                visualizations['boundary'] = Image.fromarray(boundary_overlay)
            
            # 4. ì¢…í•© ì‹œê°í™” ì´ë¯¸ì§€
            visualization = self._create_comprehensive_visualization(
                image, mask, clothing_type, color
            )
            visualizations['visualization'] = visualization
            
            return visualizations
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ ì‹œê°í™” ìƒì„± ì‹¤íŒ¨: {e}")
            return {}

    def _create_comprehensive_visualization(self, image, mask, clothing_type, color):
        """ì¢…í•© ì‹œê°í™” ì´ë¯¸ì§€ ìƒì„±"""
        try:
            if not PIL_AVAILABLE:
                return image
            
            # ìº”ë²„ìŠ¤ ìƒì„±
            width, height = image.size
            canvas_width = width * 2 + 20
            canvas_height = height + 60
            
            canvas = Image.new('RGB', (canvas_width, canvas_height), (240, 240, 240))
            
            # ì›ë³¸ ì´ë¯¸ì§€ ë°°ì¹˜
            canvas.paste(image, (10, 30))
            
            # ë§ˆìŠ¤í¬ ì˜¤ë²„ë ˆì´ ì´ë¯¸ì§€ ìƒì„±
            image_array = np.array(image)
            overlay = image_array.copy()
            alpha = self.segmentation_config.overlay_opacity
            overlay[mask > 0] = (
                overlay[mask > 0] * (1 - alpha) +
                np.array(color) * alpha
            ).astype(np.uint8)
            
            # ê²½ê³„ì„  ì¶”ê°€
            if OPENCV_AVAILABLE:
                boundary = cv2.Canny((mask * 255).astype(np.uint8), 50, 150)
                overlay[boundary > 0] = (255, 255, 255)
            
            overlay_image = Image.fromarray(overlay)
            canvas.paste(overlay_image, (width + 20, 30))
            
            # í…ìŠ¤íŠ¸ ì •ë³´ ì¶”ê°€ (ê¸°ë³¸ í°íŠ¸ ì‚¬ìš©)
            try:
                from PIL import ImageDraw, ImageFont
                draw = ImageDraw.Draw(canvas)
                
                try:
                    font = ImageFont.truetype("/System/Library/Fonts/Helvetica.ttc", 16)
                except Exception:
                    try:
                        font = ImageFont.load_default()
                    except Exception:
                        font = None
                
                if font:
                    # ì œëª©
                    draw.text((10, 5), "Original", fill=(0, 0, 0), font=font)
                    clothing_type_str = clothing_type.value if hasattr(clothing_type, 'value') else str(clothing_type)
                    draw.text((width + 20, 5), f"AI Segmented ({clothing_type_str})",
                             fill=(0, 0, 0), font=font)
                    
                    # í†µê³„ ì •ë³´
                    mask_area = np.sum(mask)
                    total_area = mask.size
                    coverage = (mask_area / total_area) * 100
                    
                    info_text = f"Coverage: {coverage:.1f}% | AI Models: {len(self.models_loaded)} | TYPE_CHECKING: ON"
                    draw.text((10, height + 35), info_text, fill=(0, 0, 0), font=font)
                
            except ImportError:
                pass  # PIL ImageDraw/ImageFont ì—†ìœ¼ë©´ í…ìŠ¤íŠ¸ ì—†ì´ ì§„í–‰
            
            return canvas
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ ì¢…í•© ì‹œê°í™” ìƒì„± ì‹¤íŒ¨: {e}")
            return image

    # ==============================================
    # ğŸ”¥ 13. ìœ í‹¸ë¦¬í‹° ë©”ì„œë“œë“¤
    # ==============================================

    async def process_batch(
        self,
        images: List[Union[str, np.ndarray, Image.Image]],
        clothing_types: Optional[List[str]] = None,
        quality_level: Optional[str] = None,
        batch_size: Optional[int] = None,
        **kwargs
    ) -> List[Dict[str, Any]]:
        """ë°°ì¹˜ ì²˜ë¦¬ ë©”ì„œë“œ - ì—¬ëŸ¬ ì´ë¯¸ì§€ë¥¼ í•œë²ˆì— ì²˜ë¦¬"""
        try:
            if not images:
                return []
            
            batch_size = batch_size or self.segmentation_config.batch_size
            clothing_types = clothing_types or [None] * len(images)
            
            # ë°°ì¹˜ë¥¼ ì²­í¬ë¡œ ë‚˜ëˆ„ì–´ ì²˜ë¦¬
            results = []
            for i in range(0, len(images), batch_size):
                batch_images = images[i:i+batch_size]
                batch_clothing_types = clothing_types[i:i+batch_size]
                
                # ë°°ì¹˜ ë‚´ ë³‘ë ¬ ì²˜ë¦¬
                batch_tasks = []
                for j, (image, clothing_type) in enumerate(zip(batch_images, batch_clothing_types)):
                    task = self.process(
                        image=image,
                        clothing_type=clothing_type,
                        quality_level=quality_level,
                        **kwargs
                    )
                    batch_tasks.append(task)
                
                # ë°°ì¹˜ ì‹¤í–‰
                batch_results = await asyncio.gather(*batch_tasks, return_exceptions=True)
                
                # ê²°ê³¼ ì²˜ë¦¬
                for result in batch_results:
                    if isinstance(result, Exception):
                        results.append(self._create_error_result(f"ë°°ì¹˜ ì²˜ë¦¬ ì˜¤ë¥˜: {str(result)}"))
                    else:
                        results.append(result)
            
            self.logger.info(f"âœ… ë°°ì¹˜ ì²˜ë¦¬ ì™„ë£Œ: {len(results)}ê°œ ì´ë¯¸ì§€")
            return results
            
        except Exception as e:
            self.logger.error(f"âŒ ë°°ì¹˜ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return [self._create_error_result(f"ë°°ì¹˜ ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}") for _ in images]

    def calculate_quality_score(self, mask: np.ndarray, original_image: Image.Image) -> float:
        """ì„¸ê·¸ë©˜í…Œì´ì…˜ í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°"""
        try:
            if mask is None or not NUMPY_AVAILABLE:
                return 0.0
            
            # 1. ë§ˆìŠ¤í¬ ì™„ì „ì„± (ì „ì²´ ëŒ€ë¹„ ë§ˆìŠ¤í¬ ë¹„ìœ¨)
            mask_coverage = np.sum(mask) / mask.size
            coverage_score = min(mask_coverage * 2, 1.0)  # 0~1 ì •ê·œí™”
            
            # 2. ê²½ê³„ í’ˆì§ˆ (ê²½ê³„ì„  í‰í™œë„)
            if OPENCV_AVAILABLE:
                edges = cv2.Canny(mask.astype(np.uint8) * 255, 50, 150)
                edge_density = np.sum(edges > 0) / edges.size
                edge_score = 1.0 - min(edge_density * 10, 1.0)  # ê²½ê³„ê°€ ì ì„ìˆ˜ë¡ ì¢‹ìŒ
            else:
                edge_score = 0.8
            
            # 3. ì—°ê²°ì„± ì ìˆ˜ (ì—°ê²°ëœ ì»´í¬ë„ŒíŠ¸ ìˆ˜)
            if OPENCV_AVAILABLE:
                num_labels, _ = cv2.connectedComponents(mask.astype(np.uint8))
                connectivity_score = 1.0 / max(num_labels - 1, 1)  # ì»´í¬ë„ŒíŠ¸ ìˆ˜ê°€ ì ì„ìˆ˜ë¡ ì¢‹ìŒ
            else:
                connectivity_score = 0.8
            
            # 4. í˜•íƒœ ì ìˆ˜ (ê°€ë¡œì„¸ë¡œ ë¹„ìœ¨ ë“±)
            if np.sum(mask) > 0:
                # ë§ˆìŠ¤í¬ì˜ ë°”ìš´ë”© ë°•ìŠ¤ ê³„ì‚°
                y_indices, x_indices = np.where(mask > 0)
                if len(y_indices) > 0 and len(x_indices) > 0:
                    height = np.max(y_indices) - np.min(y_indices)
                    width = np.max(x_indices) - np.min(x_indices)
                    aspect_ratio = height / max(width, 1)
                    # ì˜ë¥˜ëŠ” ì¼ë°˜ì ìœ¼ë¡œ ì„¸ë¡œê°€ ë” ê¸´ í˜•íƒœ
                    shape_score = 1.0 - abs(aspect_ratio - 1.5) / 1.5
                    shape_score = max(0.2, shape_score)
                else:
                    shape_score = 0.2
            else:
                shape_score = 0.0
            
            # ê°€ì¤‘ í‰ê·  ê³„ì‚°
            quality_score = (
                coverage_score * 0.4 +
                edge_score * 0.3 +
                connectivity_score * 0.2 +
                shape_score * 0.1
            )
            
            return max(0.0, min(1.0, quality_score))
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ í’ˆì§ˆ ì ìˆ˜ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return 0.5

    async def process_with_cache(self, image, **kwargs) -> Dict[str, Any]:
        """ìºì‹±ì„ ì‚¬ìš©í•œ ì²˜ë¦¬"""
        try:
            if not self.segmentation_config.enable_caching:
                return await self.process(image, **kwargs)
            
            # ìºì‹œ í‚¤ ìƒì„±
            cache_key = self._generate_cache_key(image, **kwargs)
            
            # ìºì‹œ í™•ì¸
            with self.cache_lock:
                if cache_key in self.segmentation_cache:
                    cached_result = self.segmentation_cache[cache_key]
                    self.processing_stats['cache_hits'] += 1
                    self.logger.debug(f"â™»ï¸ ìºì‹œì—ì„œ ê²°ê³¼ ë°˜í™˜: {cache_key[:10]}...")
                    return cached_result
            
            # ìºì‹œ ë¯¸ìŠ¤ - ì‹¤ì œ ì²˜ë¦¬
            result = await self.process(image, **kwargs)
            
            # ì„±ê³µí•œ ê²°ê³¼ë§Œ ìºì‹œ
            if result.get('success', False):
                with self.cache_lock:
                    # ìºì‹œ í¬ê¸° ì œí•œ
                    if len(self.segmentation_cache) >= self.segmentation_config.cache_size:
                        # ê°€ì¥ ì˜¤ë˜ëœ í•­ëª© ì œê±° (ë‹¨ìˆœ FIFO)
                        oldest_key = next(iter(self.segmentation_cache))
                        del self.segmentation_cache[oldest_key]
                    
                    self.segmentation_cache[cache_key] = result
                    self.logger.debug(f"ğŸ’¾ ê²°ê³¼ ìºì‹œ ì €ì¥: {cache_key[:10]}...")
            
            return result
            
        except Exception as e:
            self.logger.error(f"âŒ ìºì‹œ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return await self.process(image, **kwargs)

    def _generate_cache_key(self, image, **kwargs) -> str:
        """ìºì‹œ í‚¤ ìƒì„±"""
        try:
            # ì´ë¯¸ì§€ í•´ì‹œ
            if isinstance(image, str):
                image_hash = hashlib.md5(image.encode()).hexdigest()[:8]
            elif isinstance(image, np.ndarray):
                image_hash = hashlib.md5(image.tobytes()).hexdigest()[:8]
            elif isinstance(image, Image.Image):
                import io
                buffer = io.BytesIO()
                image.save(buffer, format='PNG')
                image_hash = hashlib.md5(buffer.getvalue()).hexdigest()[:8]
            else:
                image_hash = "unknown"
            
            # íŒŒë¼ë¯¸í„° í•´ì‹œ
            params = {
                'clothing_type': kwargs.get('clothing_type'),
                'quality_level': kwargs.get('quality_level'),
                'method': self.segmentation_config.method.value,
                'confidence_threshold': self.segmentation_config.confidence_threshold
            }
            params_str = json.dumps(params, sort_keys=True)
            params_hash = hashlib.md5(params_str.encode()).hexdigest()[:8]
            
            return f"{image_hash}_{params_hash}"
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ ìºì‹œ í‚¤ ìƒì„± ì‹¤íŒ¨: {e}")
            return f"fallback_{time.time()}"

    def _get_current_method(self):
        """í˜„ì¬ ì‚¬ìš©ëœ ë°©ë²• ë°˜í™˜"""
        if self.models_loaded.get('u2net'):
            return 'u2net_ai_type_checking'
        elif self.rembg_sessions:
            return 'rembg_ai'
        else:
            return 'traditional'

    def _image_to_base64(self, image):
        """ì´ë¯¸ì§€ë¥¼ Base64ë¡œ ì¸ì½”ë”©"""
        try:
            if not PIL_AVAILABLE:
                return ""
            
            buffer = BytesIO()
            if isinstance(image, Image.Image):
                image.save(buffer, format='PNG')
            else:
                img = Image.fromarray(image)
                img.save(buffer, format='PNG')
            image_data = buffer.getvalue()
            return base64.b64encode(image_data).decode()
        except Exception as e:
            self.logger.warning(f"âš ï¸ Base64 ì¸ì½”ë”© ì‹¤íŒ¨: {e}")
            return ""

    def _create_error_result(self, error_message: str) -> Dict[str, Any]:
        """ì—ëŸ¬ ê²°ê³¼ ìƒì„±"""
        return {
            'success': False,
            'error': error_message,
            'mask': None,
            'confidence': 0.0,
            'processing_time': 0.0,
            'method_used': 'error',
            'ai_models_used': [],
            'metadata': {
                'error_details': error_message,
                'available_models': list(self.models_loaded.keys()),
                'type_checking_pattern': True,
                'dynamic_import_used': True
            }
        }

    def _update_processing_stats(self, processing_time: float, success: bool):
        """ì²˜ë¦¬ í†µê³„ ì—…ë°ì´íŠ¸"""
        try:
            self.processing_stats['total_processed'] += 1
            if success:
                self.processing_stats['successful_segmentations'] += 1
            else:
                self.processing_stats['failed_segmentations'] += 1
            
            # í‰ê·  ì‹œê°„ ì—…ë°ì´íŠ¸
            total = self.processing_stats['total_processed']
            current_avg = self.processing_stats['average_time']
            self.processing_stats['average_time'] = (
                (current_avg * (total - 1) + processing_time) / total
            )
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ í†µê³„ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")

    # ==============================================
    # ğŸ”¥ 14. ê³ ê¸‰ ê¸°ëŠ¥ ë©”ì„œë“œë“¤ (í˜¸í™˜ì„±)
    # ==============================================

    async def segment_clothing(self, image, **kwargs):
        """ê¸°ì¡´ í˜¸í™˜ì„± ë©”ì„œë“œ"""
        return await self.process(image, **kwargs)
    
    async def segment_clothing_batch(self, images, **kwargs):
        """ë°°ì¹˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ í˜¸í™˜ì„± ë©”ì„œë“œ"""
        return await self.process_batch(images, **kwargs)
    
    async def segment_clothing_with_cache(self, image, **kwargs):
        """ìºì‹± ì„¸ê·¸ë©˜í…Œì´ì…˜ í˜¸í™˜ì„± ë©”ì„œë“œ"""
        return await self.process_with_cache(image, **kwargs)

    def get_segmentation_info(self) -> Dict[str, Any]:
        """ì„¸ê·¸ë©˜í…Œì´ì…˜ ì •ë³´ ë°˜í™˜"""
        return {
            'step_name': self.step_name,
            'device': self.device,
            'is_initialized': self.is_initialized,
            'available_methods': [m.value for m in self.available_methods],
            'loaded_ai_models': list(self.models_loaded.keys()),
            'loaded_checkpoints': list(self.checkpoints_loaded.keys()),
            'rembg_sessions': list(self.rembg_sessions.keys()) if hasattr(self, 'rembg_sessions') else [],
            'processing_stats': self.processing_stats.copy(),
            'type_checking_info': {
                'pattern_applied': True,
                'dynamic_imports_used': True,
                'circular_imports_prevented': True,
                'base_step_mixin_loaded': self.base_step_mixin is not None,
                'model_loader_loaded': self.model_loader is not None
            },
            'ai_model_stats': {
                'total_ai_calls': self.processing_stats['ai_model_calls'],
                'models_loaded': len(self.models_loaded),
                'checkpoints_loaded': len(self.checkpoints_loaded),
                'fallback_used': False
            },
            'config': {
                'method': self.segmentation_config.method.value,
                'quality_level': self.segmentation_config.quality_level.value,
                'enable_visualization': self.segmentation_config.enable_visualization,
                'confidence_threshold': self.segmentation_config.confidence_threshold,
                'enable_edge_refinement': self.segmentation_config.enable_edge_refinement,
                'enable_hole_filling': self.segmentation_config.enable_hole_filling,
                'overlay_opacity': self.segmentation_config.overlay_opacity
            }
        }

    # ==============================================
    # ğŸ”¥ 15. ì •ë¦¬ ë©”ì„œë“œ
    # ==============================================
    
    async def cleanup(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        try:
            self.logger.info("ğŸ§¹ ClothSegmentationStep ì •ë¦¬ ì‹œì‘...")
            
            # AI ëª¨ë¸ ì •ë¦¬
            for model_name, model in self.models_loaded.items():
                try:
                    if hasattr(model, 'cpu'):
                        model.cpu()
                    del model
                except Exception as e:
                    self.logger.warning(f"âš ï¸ ëª¨ë¸ {model_name} ì •ë¦¬ ì‹¤íŒ¨: {e}")
            
            self.models_loaded.clear()
            self.checkpoints_loaded.clear()
            
            # RemBG ì„¸ì…˜ ì •ë¦¬
            if hasattr(self, 'rembg_sessions'):
                self.rembg_sessions.clear()
            
            # ìºì‹œ ì •ë¦¬
            if hasattr(self, 'segmentation_cache'):
                self.segmentation_cache.clear()
            
            # ì‹¤í–‰ì ì •ë¦¬
            if hasattr(self, 'executor'):
                self.executor.shutdown(wait=False)
            
            # GPU ë©”ëª¨ë¦¬ ì •ë¦¬
            if self.device == "mps" and MPS_AVAILABLE:
                try:
                    torch.mps.empty_cache()
                except:
                    pass
            elif self.device == "cuda" and TORCH_AVAILABLE and torch.cuda.is_available():
                torch.cuda.empty_cache()
            
            # ê°€ë¹„ì§€ ì»¬ë ‰ì…˜
            gc.collect()
            
            # ë™ì  ì˜ì¡´ì„± ì°¸ì¡° ì •ë¦¬
            self.model_loader = None
            self.memory_manager = None
            self.data_converter = None
            self.base_step_mixin = None
            self.di_container = None
            
            self.is_initialized = False
            self.logger.info("âœ… ClothSegmentationStep ì •ë¦¬ ì™„ë£Œ")
            
        except Exception as e:
            self.logger.error(f"âŒ ì •ë¦¬ ì‹¤íŒ¨: {e}")

    def __del__(self):
        """ì†Œë©¸ì"""
        try:
            if hasattr(self, 'executor'):
                self.executor.shutdown(wait=False)
        except Exception:
            pass

# ==============================================
# ğŸ”¥ 16. íŒ©í† ë¦¬ í•¨ìˆ˜ë“¤ (TYPE_CHECKING íŒ¨í„´)
# ==============================================

def create_cloth_segmentation_step(
    device: Optional[str] = None,
    config: Optional[Dict[str, Any]] = None,
    **kwargs
) -> ClothSegmentationStep:
    """ClothSegmentationStep íŒ©í† ë¦¬ í•¨ìˆ˜ (TYPE_CHECKING íŒ¨í„´)"""
    return ClothSegmentationStep(device=device, config=config, **kwargs)

async def create_and_initialize_cloth_segmentation_step(
    device: str = "auto",
    config: Optional[Dict[str, Any]] = None,
    **kwargs
) -> ClothSegmentationStep:
    """TYPE_CHECKING íŒ¨í„´ì„ ì‚¬ìš©í•œ ClothSegmentationStep ìƒì„± ë° ì´ˆê¸°í™”"""
    try:
        # Step ìƒì„± (TYPE_CHECKING íŒ¨í„´ ì ìš©)
        step = create_cloth_segmentation_step(device=device, config=config, **kwargs)
        
        # ë™ì  ì˜ì¡´ì„± ì£¼ì… ì‹œë„
        try:
            model_loader = get_model_loader()
            if model_loader:
                step.set_model_loader(model_loader)
            
            di_container = get_di_container()
            if di_container:
                step.set_di_container = lambda x: setattr(step, 'di_container', x)
                step.set_di_container(di_container)
        except Exception as e:
            logger.warning(f"âš ï¸ ë™ì  ì˜ì¡´ì„± ì£¼ì… ì‹¤íŒ¨: {e}")
        
        await step.initialize()
        return step
        
    except Exception as e:
        logger.error(f"âŒ TYPE_CHECKING ìƒì„± ì‹¤íŒ¨: {e}")
        
        # í´ë°±: ê¸°ë³¸ ìƒì„±
        step = create_cloth_segmentation_step(device=device, config=config, **kwargs)
        await step.initialize()
        return step

def create_m3_max_segmentation_step(
    config: Optional[Dict[str, Any]] = None,
    **kwargs
) -> ClothSegmentationStep:
    """M3 Max ìµœì í™”ëœ ClothSegmentationStep ìƒì„± (TYPE_CHECKING íŒ¨í„´)"""
    m3_config = {
        'method': SegmentationMethod.AUTO,
        'quality_level': QualityLevel.HIGH,
        'use_fp16': True,
        'batch_size': 8,  # M3 Max 128GB í™œìš©
        'cache_size': 200,
        'enable_visualization': True,
        'visualization_quality': 'high',
        'enable_edge_refinement': True,
        'enable_hole_filling': True
    }
    
    if config:
        m3_config.update(config)
    
    return ClothSegmentationStep(device="mps", config=m3_config, **kwargs)

# ==============================================
# ğŸ”¥ 17. í…ŒìŠ¤íŠ¸ ë° ì˜ˆì‹œ í•¨ìˆ˜ë“¤
# ==============================================

async def test_type_checking_ai_segmentation():
    """TYPE_CHECKING íŒ¨í„´ + AI ì„¸ê·¸ë©˜í…Œì´ì…˜ í…ŒìŠ¤íŠ¸"""
    print("ğŸ§ª TYPE_CHECKING íŒ¨í„´ + AI ì„¸ê·¸ë©˜í…Œì´ì…˜ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    
    try:
        # Step ìƒì„± (TYPE_CHECKING íŒ¨í„´)
        step = await create_and_initialize_cloth_segmentation_step(
            device="auto",
            config={
                "method": "auto",
                "enable_visualization": True,
                "visualization_quality": "high",
                "quality_level": "balanced"
            }
        )
        
        # TYPE_CHECKING íŒ¨í„´ ìƒíƒœ í™•ì¸
        info = step.get_segmentation_info()
        type_checking_info = info['type_checking_info']
        print("ğŸ”— TYPE_CHECKING íŒ¨í„´ ìƒíƒœ:")
        print(f"   âœ… íŒ¨í„´ ì ìš©: {type_checking_info['pattern_applied']}")
        print(f"   âœ… ë™ì  import ì‚¬ìš©: {type_checking_info['dynamic_imports_used']}")
        print(f"   âœ… ìˆœí™˜ì°¸ì¡° ë°©ì§€: {type_checking_info['circular_imports_prevented']}")
        print(f"   âœ… BaseStepMixin ë¡œë“œ: {type_checking_info['base_step_mixin_loaded']}")
        print(f"   âœ… ModelLoader ë¡œë“œ: {type_checking_info['model_loader_loaded']}")
        
        # ë”ë¯¸ ì´ë¯¸ì§€ ìƒì„±
        if PIL_AVAILABLE:
            dummy_image = Image.new('RGB', (512, 512), (200, 150, 100))
        else:
            dummy_image = np.random.randint(0, 255, (512, 512, 3), dtype=np.uint8)
        
        # AI ì²˜ë¦¬ ì‹¤í–‰
        result = await step.process(dummy_image, clothing_type="shirt", quality_level="high")
        
        # ê²°ê³¼ í™•ì¸
        if result['success']:
            print("âœ… TYPE_CHECKING + AI ì²˜ë¦¬ ì„±ê³µ!")
            print(f"   - ì˜ë¥˜ íƒ€ì…: {result['clothing_type']}")
            print(f"   - ì‹ ë¢°ë„: {result['confidence']:.3f}")
            print(f"   - ì²˜ë¦¬ ì‹œê°„: {result['processing_time']:.2f}ì´ˆ")
            print(f"   - ì‚¬ìš© AI ëª¨ë¸: {result['ai_models_used']}")
            print(f"   - TYPE_CHECKING íŒ¨í„´: {result['metadata']['type_checking_pattern']}")
            
            if 'visualization_base64' in result:
                print("   - AI ì‹œê°í™” ì´ë¯¸ì§€ ìƒì„±ë¨")
        else:
            print(f"âŒ TYPE_CHECKING + AI ì²˜ë¦¬ ì‹¤íŒ¨: {result.get('error', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}")
        
        # ì‹œìŠ¤í…œ ì •ë³´ ì¶œë ¥
        print(f"\nğŸ§  TYPE_CHECKING + AI ì‹œìŠ¤í…œ ì •ë³´:")
        print(f"   - ë””ë°”ì´ìŠ¤: {info['device']}")
        print(f"   - ë¡œë“œëœ AI ëª¨ë¸: {info['loaded_ai_models']}")
        print(f"   - ë¡œë“œëœ ì²´í¬í¬ì¸íŠ¸: {info['loaded_checkpoints']}")
        print(f"   - AI ëª¨ë¸ í˜¸ì¶œ ìˆ˜: {info['ai_model_stats']['total_ai_calls']}")
        print(f"   - TYPE_CHECKING ì ìš©: {info['type_checking_info']['pattern_applied']}")
        
        # ì •ë¦¬
        await step.cleanup()
        print("âœ… TYPE_CHECKING + AI í…ŒìŠ¤íŠ¸ ì™„ë£Œ ë° ì •ë¦¬")
        
    except Exception as e:
        print(f"âŒ TYPE_CHECKING + AI í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        print("ğŸ’¡ ë‹¤ìŒì´ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:")
        print("   1. BaseStepMixin ëª¨ë“ˆ (ë™ì  import)")
        print("   2. ModelLoader ëª¨ë“ˆ (ì²´í¬í¬ì¸íŠ¸ ë¡œë”©)")
        print("   3. ì‹¤ì œ AI ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ íŒŒì¼")
        print("   4. conda í™˜ê²½ ì„¤ì •")

def example_type_checking_usage():
    """TYPE_CHECKING íŒ¨í„´ ì‚¬ìš© ì˜ˆì‹œ"""
    print("ğŸ”¥ MyCloset AI Step 03 - TYPE_CHECKING íŒ¨í„´ + AI ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‚¬ìš© ì˜ˆì‹œ")
    print("=" * 80)
    
    print("""
# ğŸ”¥ TYPE_CHECKING íŒ¨í„´ + ì‹¤ì œ AI ëª¨ë¸ ì—°ë™ ë²„ì „ (êµ¬ì¡° ì •ë¦¬ë¨)

# 1. ê¸°ë³¸ ì‚¬ìš©ë²• (TYPE_CHECKING íŒ¨í„´)
from app.ai_pipeline.steps.step_03_cloth_segmentation import create_cloth_segmentation_step

step = create_cloth_segmentation_step(device="mps")

# 2. ì™„ì „ ìë™í™” ìƒì„± ë° ì´ˆê¸°í™” (TYPE_CHECKING íŒ¨í„´)
step = await create_and_initialize_cloth_segmentation_step(
    device="mps",
    config={
        "quality_level": "ultra",
        "enable_visualization": True,
        "method": "auto"
    }
)

# 3. M3 Max ìµœì í™” ë²„ì „ (TYPE_CHECKING íŒ¨í„´)
step = create_m3_max_segmentation_step({
    "quality_level": "ultra",
    "enable_visualization": True,
    "batch_size": 8  # M3 Max 128GB í™œìš©
})

# 4. ì‹¤ì œ AI + TYPE_CHECKING ê²°ê³¼ í™œìš©
result = await step.process(image, clothing_type="shirt", quality_level="high")

if result['success']:
    # ì‹¤ì œ AI ìƒì„± ê²°ê³¼
    ai_mask = result['mask']
    ai_confidence = result['confidence']
    ai_models_used = result['ai_models_used']
    
    # TYPE_CHECKING ì •ë³´
    type_checking_used = result['metadata']['type_checking_pattern']
    dynamic_import_used = result['metadata']['dynamic_import_used']
    
    print(f"AI ëª¨ë¸: {ai_models_used}")
    print(f"TYPE_CHECKING íŒ¨í„´: {type_checking_used}")
    print(f"ë™ì  import ì‚¬ìš©: {dynamic_import_used}")

# 5. TYPE_CHECKING ìƒíƒœ í™•ì¸
info = step.get_segmentation_info()
type_checking_info = info['type_checking_info']
print("TYPE_CHECKING íŒ¨í„´ ìƒíƒœ:")
for key, value in type_checking_info.items():
    print(f"  {key}: {value}")

# 6. ìˆœí™˜ì°¸ì¡° ë°©ì§€ í™•ì¸
# - ëŸ°íƒ€ì„ì—ëŠ” BaseStepMixinì´ ì§ì ‘ importë˜ì§€ ì•ŠìŒ
# - ë™ì  importë¡œë§Œ ì ‘ê·¼
# - TYPE_CHECKINGìœ¼ë¡œ íƒ€ì… íŒíŠ¸ë§Œ ì œê³µ

# 7. conda í™˜ê²½ ì„¤ì • (TYPE_CHECKING + AI ëª¨ë¸ìš©)
'''
conda create -n mycloset-ai-step03 python=3.9 -y
conda activate mycloset-ai-step03

# í•µì‹¬ ë¼ì´ë¸ŒëŸ¬ë¦¬
conda install -c pytorch pytorch torchvision torchaudio -y
conda install -c conda-forge opencv numpy pillow -y

# AI ëª¨ë¸ ë¼ì´ë¸ŒëŸ¬ë¦¬
pip install rembg segment-anything transformers
pip install scikit-learn psutil

# M3 Max ìµœì í™”
conda install -c conda-forge accelerate -y

# ì‹¤í–‰
cd backend
python -m app.ai_pipeline.steps.step_03_cloth_segmentation
'''

# 8. ì—ëŸ¬ ì²˜ë¦¬ (TYPE_CHECKING íŒ¨í„´)
try:
    await step.initialize()
except ImportError as e:
    print(f"ë™ì  import ì‹¤íŒ¨: {e}")
    # í´ë°± ì²˜ë¦¬ ìë™ìœ¼ë¡œ ì‹¤í–‰ë¨

# ë¦¬ì†ŒìŠ¤ ì •ë¦¬
await step.cleanup()
""")

def print_conda_setup_guide():
    """conda í™˜ê²½ ì„¤ì • ê°€ì´ë“œ (TYPE_CHECKING + AIìš©)"""
    print("""
ğŸ MyCloset AI - conda í™˜ê²½ ì„¤ì • ê°€ì´ë“œ (TYPE_CHECKING íŒ¨í„´ + AI ëª¨ë¸ìš©)

# 1. conda í™˜ê²½ ìƒì„± (TYPE_CHECKING + AI)
conda create -n mycloset-ai-step03 python=3.9 -y
conda activate mycloset-ai-step03

# 2. í•µì‹¬ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ (í•„ìˆ˜)
conda install -c pytorch pytorch torchvision torchaudio -y
conda install -c conda-forge opencv numpy pillow -y

# 3. AI ëª¨ë¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ (í•„ìˆ˜)
pip install rembg segment-anything transformers
pip install scikit-learn psutil ultralytics

# 4. M3 Max ìµœì í™” (macOS)
conda install -c conda-forge accelerate -y

# 5. TYPE_CHECKING íŒ¨í„´ ê²€ì¦
python -c "
import torch
from typing import TYPE_CHECKING

print(f'PyTorch: {torch.__version__}')
print(f'MPS: {torch.backends.mps.is_available()}')
print(f'TYPE_CHECKING: {TYPE_CHECKING}')

# ë™ì  import í…ŒìŠ¤íŠ¸
try:
    import importlib
    # ëŸ°íƒ€ì„ì—ëŠ” ì‹¤ì œë¡œ importí•˜ì§€ ì•ŠìŒ
    print('ë™ì  import íŒ¨í„´ ì‘ë™ ì¤‘')
except Exception as e:
    print(f'ë™ì  import ì‹¤íŒ¨: {e}')
"

# 6. ì‹¤í–‰ (TYPE_CHECKING + AI)
cd backend
export MYCLOSET_AI_TYPE_CHECKING=true
python -m app.ai_pipeline.steps.step_03_cloth_segmentation

# 7. í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
export MYCLOSET_AI_TYPE_CHECKING=true
export MYCLOSET_AI_DEVICE=mps
export MYCLOSET_AI_MODELS_PATH=/path/to/ai_models
""")

# ==============================================
# ğŸ”¥ 18. ëª¨ë“ˆ ìµìŠ¤í¬íŠ¸
# ==============================================

__all__ = [
    # ë©”ì¸ í´ë˜ìŠ¤
    'ClothSegmentationStep',
    
    # ì—´ê±°í˜• ë° ë°ì´í„° í´ë˜ìŠ¤
    'SegmentationMethod',
    'ClothingType',
    'QualityLevel',
    'SegmentationConfig',
    'SegmentationResult',
    
    # AI ëª¨ë¸ í´ë˜ìŠ¤ë“¤
    'U2NET',
    'REBNCONV',
    'RSU7',
    
    # ë™ì  import í•¨ìˆ˜ë“¤ (TYPE_CHECKING íŒ¨í„´)
    'get_base_step_mixin',
    'get_cloth_segmentation_mixin',
    'get_model_loader',
    'get_di_container',
    
    # íŒ©í† ë¦¬ í•¨ìˆ˜ë“¤ (TYPE_CHECKING íŒ¨í„´)
    'create_cloth_segmentation_step',
    'create_and_initialize_cloth_segmentation_step',
    'create_m3_max_segmentation_step',
    
    # ì‹œê°í™” ê´€ë ¨
    'CLOTHING_COLORS',
    
    # ë¼ì´ë¸ŒëŸ¬ë¦¬ ìƒíƒœ
    'TORCH_AVAILABLE',
    'MPS_AVAILABLE',
    'NUMPY_AVAILABLE',
    'OPENCV_AVAILABLE',
    'PIL_AVAILABLE',
    'REMBG_AVAILABLE',
    'SKLEARN_AVAILABLE'
]

# ==============================================
# ğŸ”¥ 19. ëª¨ë“ˆ ì´ˆê¸°í™” ë¡œê¹…
# ==============================================

logger.info("=" * 80)
logger.info("âœ… Step 03 TYPE_CHECKING íŒ¨í„´ + AI ì—°ë™ ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ ëª¨ë“ˆ ë¡œë“œ ì™„ë£Œ")
logger.info("=" * 80)
logger.info("ğŸ”¥ í•µì‹¬ í•´ê²°ì‚¬í•­:")
logger.info("   âœ… Python êµ¬ì¡° ë° ë“¤ì—¬ì“°ê¸° ì™„ì „ ì •ë¦¬")
logger.info("   âœ… TYPE_CHECKING íŒ¨í„´ ì™„ì „ ì ìš©")
logger.info("   âœ… ìˆœí™˜ì°¸ì¡° ì™„ì „ ì°¨ë‹¨ (ëŸ°íƒ€ì„ import ì—†ìŒ)")
logger.info("   âœ… ë™ì  importë¡œ BaseStepMixin ì•ˆì „ ë¡œë”©")
logger.info("   âœ… ì‹¤ì œ AI ëª¨ë¸ ì—°ë™ ë° ì¶”ë¡  (U2Net, RemBG)")
logger.info("   âœ… M3 Max 128GB ìµœì í™”")
logger.info("   âœ… conda í™˜ê²½ ì™„ë²½ ì§€ì›")
logger.info("   âœ… í”„ë¡œë•ì…˜ ë ˆë²¨ ì•ˆì •ì„±")
logger.info("")
logger.info("ğŸ”— TYPE_CHECKING íŒ¨í„´ íë¦„:")
logger.info("   ì»´íŒŒì¼ íƒ€ì„: TYPE_CHECKING = True â†’ import (íƒ€ì… íŒíŠ¸ìš©)")
logger.info("   ëŸ°íƒ€ì„: TYPE_CHECKING = False â†’ import ì•ˆë¨ â†’ ìˆœí™˜ì°¸ì¡° ë°©ì§€")
logger.info("   ë™ì  í•´ê²°: get_base_step_mixin() â†’ importlib â†’ ì•ˆì „í•œ ë¡œë”©")
logger.info("")
logger.info("ğŸ§  AI ëª¨ë¸ ì—°ë™ íë¦„:")
logger.info("   ë™ì  ModelLoader â†’ ì²´í¬í¬ì¸íŠ¸ ë¡œë”© â†’ AI ëª¨ë¸ ìƒì„± â†’ ì‹¤ì œ ì¶”ë¡ ")
logger.info("")
logger.info(f"ğŸ”§ ì‹œìŠ¤í…œ ìƒíƒœ:")
logger.info(f"   - PyTorch: {'âœ…' if TORCH_AVAILABLE else 'âŒ'}")
logger.info(f"   - MPS: {'âœ…' if MPS_AVAILABLE else 'âŒ'}")
logger.info(f"   - NumPy: {'âœ…' if NUMPY_AVAILABLE else 'âŒ'}")
logger.info(f"   - OpenCV: {'âœ…' if OPENCV_AVAILABLE else 'âŒ'}")
logger.info(f"   - PIL: {'âœ…' if PIL_AVAILABLE else 'âŒ'}")
logger.info(f"   - RemBG: {'âœ…' if REMBG_AVAILABLE else 'âŒ'}")
logger.info("")
logger.info("ğŸŒŸ ì‚¬ìš© ì˜ˆì‹œ:")
logger.info("   # TYPE_CHECKING íŒ¨í„´ + AI ì—°ë™")
logger.info("   step = await create_and_initialize_cloth_segmentation_step()")
logger.info("   result = await step.process(image)")
logger.info("")
logger.info("=" * 80)
logger.info("ğŸš€ TYPE_CHECKING íŒ¨í„´ + AI ì—°ë™ Step 03 ì¤€ë¹„ ì™„ë£Œ!")
logger.info("   âœ… Python êµ¬ì¡° ì™„ì „ ì •ë¦¬")
logger.info("   âœ… ìˆœí™˜ì°¸ì¡° ì™„ì „ í•´ê²°")
logger.info("   âœ… ë™ì  import íŒ¨í„´")
logger.info("   âœ… ì‹¤ì œ AI ëª¨ë¸ ì¶”ë¡ ")
logger.info("   âœ… M3 Max ìµœì í™”")
logger.info("   âœ… conda í™˜ê²½ ì§€ì›")
logger.info("=" * 80)

if __name__ == "__main__":
    """ì§ì ‘ ì‹¤í–‰ ì‹œ í…ŒìŠ¤íŠ¸ (TYPE_CHECKING + AI)"""
    print("ğŸ”¥ Step 03 TYPE_CHECKING íŒ¨í„´ + AI ì„¸ê·¸ë©˜í…Œì´ì…˜ - ì§ì ‘ ì‹¤í–‰ í…ŒìŠ¤íŠ¸")
    
    # ì˜ˆì‹œ ì¶œë ¥
    example_type_checking_usage()
    
    # conda ê°€ì´ë“œ
    print_conda_setup_guide()
    
    # ì‹¤ì œ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ (ë¹„ë™ê¸°)
    import asyncio
    try:
        asyncio.run(test_type_checking_ai_segmentation())
    except Exception as e:
        print(f"âŒ TYPE_CHECKING + AI í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
        print("ğŸ’¡ ë‹¤ìŒì´ í•„ìš”í•©ë‹ˆë‹¤:")
        print("   1. BaseStepMixin ëª¨ë“ˆ (ë™ì  import)")
        print("   2. ModelLoader ëª¨ë“ˆ (ì²´í¬í¬ì¸íŠ¸ ë¡œë”©)")
        print("   3. ì‹¤ì œ AI ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ íŒŒì¼")
        print("   4. conda í™˜ê²½ ì„¤ì •")
        print("   5. TYPE_CHECKING íŒ¨í„´ ì§€ì› í™˜ê²½")