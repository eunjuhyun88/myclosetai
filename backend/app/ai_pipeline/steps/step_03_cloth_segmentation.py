# app/ai_pipeline/steps/step_03_cloth_segmentation.py
"""
MyCloset AI - 3ë‹¨ê³„: ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ (Clothing Segmentation) + ì‹œê°í™”
ğŸ”¥ ì™„ì „ í†µí•© í”„ë¡œë•ì…˜ ë²„ì „ - M3 Max 128GB ìµœì í™” - ğŸ”¥ ëª¨ë“  ë¬¸ì œ ì™„ì „ í•´ê²°

âœ… logger ì†ì„± ëˆ„ë½ ë¬¸ì œ ì™„ì „ í•´ê²°
âœ… BaseStepMixin ì˜¬ë°”ë¥¸ ìƒì† ë° super() í˜¸ì¶œ
âœ… ModelLoader ì™„ë²½ ì—°ë™ (load_model_async, _setup_model_paths)
âœ… ì‹¤ì œ U2NET, RemBG AI ëª¨ë¸ ì‘ë™
âœ… ì‹œê°í™” ê¸°ëŠ¥ ì™„ì „ êµ¬í˜„
âœ… M3 Max Neural Engine + Metal Performance Shaders í™œìš©
âœ… Graceful Degradation + ì™„ë²½í•œ ì—ëŸ¬ ì²˜ë¦¬
âœ… ëª¨ë“  ê¸°ëŠ¥ í•œê°œë„ ë¹¼ë¨¹ì§€ ì•Šê³  ì™„ì „ êµ¬í˜„
"""

import os
import sys
import logging
import time
import asyncio
import threading
import gc
import hashlib
import json
import base64
from typing import Dict, Any, Optional, Tuple, List, Union, Callable
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor, as_completed
from dataclasses import dataclass, field
from enum import Enum
from io import BytesIO
import weakref

# í•µì‹¬ ë¼ì´ë¸ŒëŸ¬ë¦¬
import numpy as np
import cv2
from PIL import Image, ImageEnhance, ImageFilter, ImageOps, ImageDraw, ImageFont
import torch
import torch.nn as nn
import torch.nn.functional as F
from torchvision import transforms

# ì„ íƒì  AI ë¼ì´ë¸ŒëŸ¬ë¦¬ë“¤
try:
    import rembg
    from rembg import remove, new_session
    REMBG_AVAILABLE = True
except:
    REMBG_AVAILABLE = False

try:

    from sklearn.cluster import KMeans
    from sklearn.preprocessing import StandardScaler
    SKLEARN_AVAILABLE = True
except:
    SKLEARN_AVAILABLE = False

try:

    import segment_anything as sam
    SAM_AVAILABLE = True
except:
    SAM_AVAILABLE = False

try:

    from transformers import pipeline
    TRANSFORMERS_AVAILABLE = True
except:
    TRANSFORMERS_AVAILABLE = False

# ğŸ”¥ MyCloset AI í•µì‹¬ ìœ í‹¸ë¦¬í‹° ì—°ë™ - ì™„ì „ ìˆ˜ì •
try:
    from app.ai_pipeline.steps.base_step_mixin import BaseStepMixin
    BASE_STEP_MIXIN_AVAILABLE = True
except:
    BASE_STEP_MIXIN_AVAILABLE = False
    # ğŸ”¥ í´ë°±: ê¸°ë³¸ í´ë˜ìŠ¤ ì •ì˜
    
    def _setup_model_precision:
    
        """M3 Max í˜¸í™˜ ì •ë°€ë„ ì„¤ì •"""
        try:
            if self.device == "mps":
                # M3 Maxì—ì„œëŠ” Float32ê°€ ì•ˆì „
                return model.float()
            elif self.device == "cuda" and hasattr(model, 'half'):
                return model.half()
            else:
                return model.float()
        except:
            self.logger.warning(f"âš ï¸ ì •ë°€ë„ ì„¤ì • ì‹¤íŒ¨: {e}")
            return model.float()

class BaseStepMixin:

    def __init__(self, *args, **kwargs):
            # ğŸ”¥ logger ì†ì„± ë¬¸ì œ ì™„ì „ í•´ê²°
            if:
                class_name = self.__class__.__name__
                self.logger = logging.getLogger(f"pipeline.{class_name}")
            
            # ê¸°ë³¸ ì†ì„±ë“¤
            self.step_name = getattr(self, 'step_name', self.__class__.__name__)
            self.device = getattr(self, 'device', 'cpu')
            self.is_initialized = getattr(self, 'is_initialized', False)
            self.model_interface = getattr(self, 'model_interface', None)
            
            self.logger.info(f"ğŸ”¥ BaseStepMixin í´ë°± ì´ˆê¸°í™”: {class_name}")

try:

    from app.ai_pipeline.utils.model_loader import (
        ModelLoader, ModelConfig, ModelType,
        get_global_model_loader, create_model_loader
    )
    MODEL_LOADER_AVAILABLE = True
except:
    MODEL_LOADER_AVAILABLE = False

try:

    from app.ai_pipeline.utils.memory_manager import (
        MemoryManager, get_global_memory_manager, optimize_memory_usage
    )
    MEMORY_MANAGER_AVAILABLE = True
except:
    MEMORY_MANAGER_AVAILABLE = False

try:

    from app.ai_pipeline.utils.data_converter import (
        DataConverter, get_global_data_converter
    )
    DATA_CONVERTER_AVAILABLE = True
except:
    DATA_CONVERTER_AVAILABLE = False

# ğŸ”¥ ë¡œê¹… ì„¤ì • - ë°˜ë“œì‹œ ìµœìƒë‹¨ì—ì„œ ì„¤ì •
logger = logging.getLogger(__name__)

# ==============================================
# 1. ì—´ê±°í˜• ë° ë°ì´í„° í´ë˜ìŠ¤ ì •ì˜
# ==============================================

class SegmentationMethod:

    """ì„¸ê·¸ë©˜í…Œì´ì…˜ ë°©ë²•"""
    U2NET = "u2net"
    REMBG = "rembg"
    SAM = "sam"
    DEEP_LAB = "deeplab"
    MASK_RCNN = "mask_rcnn"
    TRADITIONAL = "traditional"
    HYBRID = "hybrid"
    AUTO = "auto"

class ClothingType:

    """ì˜ë¥˜ íƒ€ì…"""
    SHIRT = "shirt"
    DRESS = "dress"
    PANTS = "pants"
    SKIRT = "skirt"
    JACKET = "jacket"
    SWEATER = "sweater"
    COAT = "coat"
    TOP = "top"
    BOTTOM = "bottom"
    UNKNOWN = "unknown"

class QualityLevel:

    """í’ˆì§ˆ ë ˆë²¨"""
    FAST = "fast"
    BALANCED = "balanced"
    HIGH = "high"
    ULTRA = "ultra"

@dataclass
class SegmentationConfig:
    """ì„¸ê·¸ë©˜í…Œì´ì…˜ ì„¤ì •"""
    method: SegmentationMethod = SegmentationMethod.AUTO
    quality_level: QualityLevel = QualityLevel.BALANCED
    input_size: Tuple[int, int] = (512, 512)
    output_size: Optional[Tuple[int, int]] = None
    enable_post_processing: bool = True
    enable_edge_refinement: bool = True
    enable_hole_filling: bool = True
    confidence_threshold: float = 0.8
    iou_threshold: float = 0.5
    batch_size: int = 1
    use_fp16: bool = True
    enable_caching: bool = True
    cache_size: int = 100
    
    # ğŸ†• ì‹œê°í™” ì„¤ì •
    enable_visualization: bool = True
    visualization_quality: str = "high"  # low, medium, high
    show_masks: bool = True
    show_boundaries: bool = True
    overlay_opacity: float = 0.6

@dataclass
class SegmentationResult:
    """ì„¸ê·¸ë©˜í…Œì´ì…˜ ê²°ê³¼"""
    success: bool
    mask: Optional[np.ndarray] = None
    segmented_image: Optional[np.ndarray] = None
    confidence_score: float = 0.0
    quality_score: float = 0.0
    method_used: str = "unknown"
    processing_time: float = 0.0
    metadata: Dict[str, Any] = field(default_factory=dict)
    error_message: Optional[str] = None

# ğŸ†• ì‹œê°í™”ìš© ìƒ‰ìƒ íŒ”ë ˆíŠ¸
CLOTHING_COLORS = {
    'shirt': (0, 255, 128),      # ë°ì€ ì´ˆë¡
    'dress': (255, 105, 180),    # í•«í•‘í¬
    'pants': (30, 144, 255),     # ë„ì§€ë¸”ë£¨
    'skirt': (255, 20, 147),     # ë”¥í•‘í¬
    'jacket': (255, 165, 0),     # ì˜¤ë Œì§€
    'sweater': (138, 43, 226),   # ë¸”ë£¨ë°”ì´ì˜¬ë ›
    'coat': (165, 42, 42),       # ë¸Œë¼ìš´
    'top': (0, 255, 255),        # ì‚¬ì´ì•ˆ
    'bottom': (255, 255, 0),     # ì˜ë¡œìš°
    'unknown': (128, 128, 128)   # ê·¸ë ˆì´
}

# ==============================================
# 2. U2-Net ëª¨ë¸ ì •ì˜ (í”„ë¡œë•ì…˜ ìµœì í™”)
# ==============================================

class REBNCONV:

    """U2-Netì˜ ê¸°ë³¸ ì»¨ë³¼ë£¨ì…˜ ë¸”ë¡"""
    def __init__:
        super(REBNCONV, self).__init__()
        self.conv_s1 = nn.Conv2d(in_ch, out_ch, 3, padding=1*dirate, dilation=1*dirate)
        self.bn_s1 = nn.BatchNorm2d(out_ch)
        self.relu_s1 = nn.ReLU(inplace=True)
    
    def forward:
    
        hx = self.relu_s1(self.bn_s1(self.conv_s1(x)))
        return hx

class RSU7:

    """U2-Net RSU-7 ë¸”ë¡"""
    def __init__:
        super(RSU7, self).__init__()
        self.rebnconvin = REBNCONV(in_ch, out_ch, dirate=1)
        
        self.rebnconv1 = REBNCONV(out_ch, mid_ch, dirate=1)
        self.pool1 = nn.MaxPool2d(2, stride=2, ceil_mode=True)
        
        self.rebnconv2 = REBNCONV(mid_ch, mid_ch, dirate=1)
        self.pool2 = nn.MaxPool2d(2, stride=2, ceil_mode=True)
        
        self.rebnconv3 = REBNCONV(mid_ch, mid_ch, dirate=1)
        self.pool3 = nn.MaxPool2d(2, stride=2, ceil_mode=True)
        
        self.rebnconv4 = REBNCONV(mid_ch, mid_ch, dirate=1)
        self.pool4 = nn.MaxPool2d(2, stride=2, ceil_mode=True)
        
        self.rebnconv5 = REBNCONV(mid_ch, mid_ch, dirate=1)
        self.pool5 = nn.MaxPool2d(2, stride=2, ceil_mode=True)
        
        self.rebnconv6 = REBNCONV(mid_ch, mid_ch, dirate=1)
        self.rebnconv7 = REBNCONV(mid_ch, mid_ch, dirate=2)
        
        self.rebnconv6d = REBNCONV(mid_ch*2, mid_ch, dirate=1)
        self.upsample6 = nn.Upsample(scale_factor=2, mode='bilinear')
        
        self.rebnconv5d = REBNCONV(mid_ch*2, mid_ch, dirate=1)
        self.upsample5 = nn.Upsample(scale_factor=2, mode='bilinear')
        
        self.rebnconv4d = REBNCONV(mid_ch*2, mid_ch, dirate=1)
        self.upsample4 = nn.Upsample(scale_factor=2, mode='bilinear')
        
        self.rebnconv3d = REBNCONV(mid_ch*2, mid_ch, dirate=1)
        self.upsample3 = nn.Upsample(scale_factor=2, mode='bilinear')
        
        self.rebnconv2d = REBNCONV(mid_ch*2, mid_ch, dirate=1)
        self.upsample2 = nn.Upsample(scale_factor=2, mode='bilinear')
        
        self.rebnconv1d = REBNCONV(mid_ch*2, out_ch, dirate=1)
    
    def forward:
    
        hx = x
        hxin = self.rebnconvin(hx)
        
        hx1 = self.rebnconv1(hxin)
        hx = self.pool1(hx1)
        
        hx2 = self.rebnconv2(hx)
        hx = self.pool2(hx2)
        
        hx3 = self.rebnconv3(hx)
        hx = self.pool3(hx3)
        
        hx4 = self.rebnconv4(hx)
        hx = self.pool4(hx4)
        
        hx5 = self.rebnconv5(hx)
        hx = self.pool5(hx5)
        
        hx6 = self.rebnconv6(hx)
        hx7 = self.rebnconv7(hx6)
        
        hx6d = self.rebnconv6d(torch.cat((hx7, hx6), 1))
        hx6dup = self.upsample6(hx6d)
        
        hx5d = self.rebnconv5d(torch.cat((hx6dup, hx5), 1))
        hx5dup = self.upsample5(hx5d)
        
        hx4d = self.rebnconv4d(torch.cat((hx5dup, hx4), 1))
        hx4dup = self.upsample4(hx4d)
        
        hx3d = self.rebnconv3d(torch.cat((hx4dup, hx3), 1))
        hx3dup = self.upsample3(hx3d)
        
        hx2d = self.rebnconv2d(torch.cat((hx3dup, hx2), 1))
        hx2dup = self.upsample2(hx2d)
        
        hx1d = self.rebnconv1d(torch.cat((hx2dup, hx1), 1))
        
        return hx1d + hxin

class U2NET:

    """U2-Net ë©”ì¸ ëª¨ë¸ (ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ ìµœì í™”)"""
    def __init__:
        super(U2NET, self).__init__()
        
        self.stage1 = RSU7(in_ch, 32, 64)
        self.pool12 = nn.MaxPool2d(2, stride=2, ceil_mode=True)
        
        self.stage2 = RSU7(64, 32, 128)
        self.pool23 = nn.MaxPool2d(2, stride=2, ceil_mode=True)
        
        self.stage3 = RSU7(128, 64, 256)
        self.pool34 = nn.MaxPool2d(2, stride=2, ceil_mode=True)
        
        self.stage4 = RSU7(256, 128, 512)
        self.pool45 = nn.MaxPool2d(2, stride=2, ceil_mode=True)
        
        self.stage5 = RSU7(512, 256, 512)
        self.pool56 = nn.MaxPool2d(2, stride=2, ceil_mode=True)
        
        self.stage6 = RSU7(512, 256, 512)
        
        # ë””ì½”ë”
        self.stage5d = RSU7(1024, 256, 512)
        self.stage4d = RSU7(1024, 128, 256)
        self.stage3d = RSU7(512, 64, 128)
        self.stage2d = RSU7(256, 32, 64)
        self.stage1d = RSU7(128, 16, 64)
        
        self.side1 = nn.Conv2d(64, out_ch, 3, padding=1)
        self.side2 = nn.Conv2d(64, out_ch, 3, padding=1)
        self.side3 = nn.Conv2d(128, out_ch, 3, padding=1)
        self.side4 = nn.Conv2d(256, out_ch, 3, padding=1)
        self.side5 = nn.Conv2d(512, out_ch, 3, padding=1)
        self.side6 = nn.Conv2d(512, out_ch, 3, padding=1)
        
        self.outconv = nn.Conv2d(6*out_ch, out_ch, 1)
        
        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear')
    
    def forward:
    
        hx = x
        
        # ì¸ì½”ë”
        hx1 = self.stage1(hx)
        hx = self.pool12(hx1)
        
        hx2 = self.stage2(hx)
        hx = self.pool23(hx2)
        
        hx3 = self.stage3(hx)
        hx = self.pool34(hx3)
        
        hx4 = self.stage4(hx)
        hx = self.pool45(hx4)
        
        hx5 = self.stage5(hx)
        hx = self.pool56(hx5)
        
        hx6 = self.stage6(hx)
        hx6up = self.upsample(hx6)
        
        # ë””ì½”ë”
        hx5d = self.stage5d(torch.cat((hx6up, hx5), 1))
        hx5dup = self.upsample(hx5d)
        
        hx4d = self.stage4d(torch.cat((hx5dup, hx4), 1))
        hx4dup = self.upsample(hx4d)
        
        hx3d = self.stage3d(torch.cat((hx4dup, hx3), 1))
        hx3dup = self.upsample(hx3d)
        
        hx2d = self.stage2d(torch.cat((hx3dup, hx2), 1))
        hx2dup = self.upsample(hx2d)
        
        hx1d = self.stage1d(torch.cat((hx2dup, hx1), 1))
        
        # ì‚¬ì´ë“œ ì¶œë ¥
        side1 = self.side1(hx1d)
        
        side2 = self.side2(hx2d)
        side2 = F.interpolate(side2, size=side1.shape[2:], mode='bilinear')
        
        side3 = self.side3(hx3d)
        side3 = F.interpolate(side3, size=side1.shape[2:], mode='bilinear')
        
        side4 = self.side4(hx4d)
        side4 = F.interpolate(side4, size=side1.shape[2:], mode='bilinear')
        
        side5 = self.side5(hx5d)
        side5 = F.interpolate(side5, size=side1.shape[2:], mode='bilinear')
        
        side6 = self.side6(hx6)
        side6 = F.interpolate(side6, size=side1.shape[2:], mode='bilinear')
        
        out = self.outconv(torch.cat((side1, side2, side3, side4, side5, side6), 1))
        
        return torch.sigmoid(out), torch.sigmoid(side1), torch.sigmoid(side2), \
                torch.sigmoid(side3), torch.sigmoid(side4), torch.sigmoid(side5), torch.sigmoid(side6)

# ==============================================
# 3. ğŸ”¥ ì™„ì „ ìˆ˜ì •ëœ ClothSegmentationStep í´ë˜ìŠ¤
# ==============================================

class ClothSegmentationStep:

    """
    3ë‹¨ê³„: ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ - ğŸ”¥ ëª¨ë“  ë¬¸ì œ ì™„ì „ í•´ê²° ë²„ì „
    
    âœ… logger ì†ì„± ëˆ„ë½ ë¬¸ì œ ì™„ì „ í•´ê²°
    âœ… BaseStepMixin ì˜¬ë°”ë¥¸ ìƒì† ë° super() í˜¸ì¶œ
    âœ… ModelLoader ì™„ë²½ ì—°ë™
    âœ… ì‹¤ì œ AI ëª¨ë¸ ì‘ë™
    âœ… ì‹œê°í™” ê¸°ëŠ¥ ì™„ì „ êµ¬í˜„
    âœ… M3 Max 128GB ìµœì í™”
    âœ… Graceful Degradation
    """
    
    def __init__(
        self,
        device: Optional[str] = None,
        config: Optional[Dict[str, Any]] = None,
        **kwargs
    ):
        """ğŸ”¥ ì™„ì „ ìˆ˜ì •ëœ ìƒì„±ì - ëª¨ë“  ë¬¸ì œ í•´ê²°"""
        
        # ğŸ”¥ 1. logger ì†ì„± ë¨¼ì € ì„¤ì • (ê°€ì¥ ì¤‘ìš”!)
        if:
            self.logger = logging.getLogger(f"pipeline.{self.__class__.__name__}")
        
        # ğŸ”¥ 2. BaseStepMixin ì˜¬ë°”ë¥¸ í˜¸ì¶œ
        if:
            super().__init__(*[], **kwargs)  # ë¹ˆ argsë¡œ í˜¸ì¶œ
        else:
            # í´ë°± ì´ˆê¸°í™”
            self.step_name = self.__class__.__name__
            self.is_initialized = False
            self.model_interface = None
        
        # ğŸ”¥ 3. ê¸°ë³¸ ì†ì„± ì„¤ì •
        self.device = self._auto_detect_device(device)
        self.config = config or {}
        self.step_name = self.__class__.__name__
        
        # ğŸ”¥ 4. í‘œì¤€ ì‹œìŠ¤í…œ íŒŒë¼ë¯¸í„°
        self.device_type = kwargs.get('device_type', 'auto')
        self.memory_gb = kwargs.get('memory_gb', 16.0)
        self.is_m3_max = kwargs.get('is_m3_max', self._detect_m3_max())
        self.optimization_enabled = kwargs.get('optimization_enabled', True)
        self.quality_level = kwargs.get('quality_level', 'balanced')
        
        # ğŸ”¥ 5. Stepë³„ ì„¤ì • ë³‘í•©
        self._merge_step_specific_config(kwargs)
        
        # ğŸ”¥ 6. ì´ˆê¸°í™” ìƒíƒœ
        self.is_initialized = False
        self._initialization_lock = threading.RLock()
        
        # ğŸ”¥ 7. Model Loader ì—°ë™ ì‹œë„
        self._setup_model_interface()
        
        # ğŸ”¥ 8. Step íŠ¹í™” ì´ˆê¸°í™”
        self._initialize_step_specific()
        
        # ğŸ”¥ 9. ì™„ë£Œ ë¡œê¹…
        self.logger.info(f"ğŸ¯ {self.step_name} ì´ˆê¸°í™” ì™„ë£Œ - ë””ë°”ì´ìŠ¤: {self.device}")
        if:
            self.logger.info(f"ğŸ M3 Max ìµœì í™” ëª¨ë“œ (ë©”ëª¨ë¦¬: {self.memory_gb}GB)")
    
    def _setup_model_interface:
    
        """ğŸ”¥ ModelLoader ì¸í„°í˜ì´ìŠ¤ ì„¤ì • - ì™„ì „ ìˆ˜ì •"""
        try:
            if MODEL_LOADER_AVAILABLE:
                # ì „ì—­ ModelLoader ê°€ì ¸ì˜¤ê¸°
                self.model_loader = get_global_model_loader()
                
                # Stepë³„ ì¸í„°í˜ì´ìŠ¤ ìƒì„±
                self.model_interface = self.model_loader.create_step_interface("step_03_cloth_segmentation")
                
                self.logger.info("âœ… ModelLoader ì¸í„°í˜ì´ìŠ¤ ì—°ê²° ì„±ê³µ")
            else:
                self.logger.warning("âš ï¸ ModelLoader ì‚¬ìš© ë¶ˆê°€ - í´ë°± ëª¨ë“œ")
                self.model_loader = None
                self.model_interface = None
        
        except:
        
            self.logger.warning(f"ModelLoader ì—°ë™ ì‹¤íŒ¨: {e}")
            self.model_loader = None
            self.model_interface = None
    
    def _auto_detect_device:
    
        """ğŸ’¡ ì§€ëŠ¥ì  ë””ë°”ì´ìŠ¤ ìë™ ê°ì§€"""
        if:
            return preferred_device

        try:

            import torch
            if:
                return 'mps'  # M3 Max ìš°ì„ 
            elif torch.cuda.is_available():
                return 'cuda'  # NVIDIA GPU
            else:
                return 'cpu'  # í´ë°±
        except:
            return 'cpu'

    def _detect_m3_max:

        """ğŸ M3 Max ì¹© ìë™ ê°ì§€"""
        try:
            import platform
            import subprocess

            if platform.system() == 'Darwin':  # macOS
                result = subprocess.run(['sysctl', '-n', 'machdep.cpu.brand_string'], 
                                        capture_output=True, text=True)
                cpu_info = result.stdout.strip()
                return 'M3 Max' in cpu_info or 'M3' in cpu_info
        except:
            pass
        return False

    def _merge_step_specific_config:

        """3ë‹¨ê³„ íŠ¹í™” ì„¤ì • ë³‘í•©"""
        
        # ì„¸ê·¸ë©˜í…Œì´ì…˜ ì„¤ì •
        self.segmentation_config = SegmentationConfig()
        
        # ì„¤ì • ì—…ë°ì´íŠ¸
        if:
            self.segmentation_config.method = SegmentationMethod(kwargs['segmentation_method'])
        
        if:
        
            self.segmentation_config.input_size = kwargs['input_size']
        
        if:
        
            self.segmentation_config.quality_level = QualityLevel(self.config['quality_level'])
        
        # ğŸ†• ì‹œê°í™” ì„¤ì •
        if:
            self.segmentation_config.enable_visualization = kwargs['enable_visualization']
        
        if:
        
            self.segmentation_config.visualization_quality = kwargs['visualization_quality']
        
        # M3 Max íŠ¹í™” ì„¤ì •
        if:
            self.segmentation_config.use_fp16 = True
            self.segmentation_config.batch_size = min(8, max(1, int(self.memory_gb / 16)))
            self.segmentation_config.cache_size = min(200, max(50, int(self.memory_gb * 2)))
            self.segmentation_config.enable_visualization = True  # M3 Maxì—ì„œëŠ” ê¸°ë³¸ í™œì„±í™”
        
        # ì¶”ê°€ ì„¤ì •ë“¤
        self.enable_post_processing = kwargs.get('enable_post_processing', True)
        self.enable_edge_refinement = kwargs.get('enable_edge_refinement', True)
        self.confidence_threshold = kwargs.get('confidence_threshold', 0.8)

    def _initialize_step_specific:

        """3ë‹¨ê³„ íŠ¹í™” ì´ˆê¸°í™”"""
        
        # ìºì‹œ ë° ìƒíƒœ ê´€ë¦¬
        self.segmentation_cache: Dict[str, SegmentationResult] = {}
        self.model_cache: Dict[str, Any] = {}
        self.session_cache: Dict[str, Any] = {}
        
        # ì„±ëŠ¥ í†µê³„
        self.processing_stats = {
            'total_processed': 0,
            'successful_segmentations': 0,
            'average_quality': 0.0,
            'method_usage': {},
            'cache_hits': 0,
            'average_processing_time': 0.0
        }
        
        # ìŠ¤ë ˆë“œ í’€ (M3 Max ìµœì í™”)
        max_workers = 4 if self.is_m3_max else 2
        self.executor = ThreadPoolExecutor(
            max_workers=max_workers,
            thread_name_prefix=f"{self.step_name}_worker"
        )
        
        # ë©”ëª¨ë¦¬ ê´€ë¦¬ì ì—°ë™
        self._setup_memory_manager()
        
        # ë°ì´í„° ë³€í™˜ê¸° ì—°ë™
        self._setup_data_converter()
        
        # ëª¨ë¸ ê²½ë¡œ ì„¤ì •
        self._setup_model_paths()
        
        # ì§€ì›ë˜ëŠ” ë°©ë²•ë“¤ ì´ˆê¸°í™”
        self.available_methods = self._detect_available_methods()
        
        self.logger.info(f"ğŸ“¦ 3ë‹¨ê³„ íŠ¹í™” ì´ˆê¸°í™” ì™„ë£Œ - ì‚¬ìš© ê°€ëŠ¥í•œ ë°©ë²•: {len(self.available_methods)}ê°œ")

    def _setup_memory_manager:

        """ë©”ëª¨ë¦¬ ê´€ë¦¬ì ì„¤ì •"""
        if:
            try:
                self.memory_manager = get_global_memory_manager()
                if:
                    from app.ai_pipeline.utils.memory_manager import create_memory_manager
                    self.memory_manager = create_memory_manager(device=self.device)
                self.logger.info("âœ… Memory Manager ì—°ê²° ì„±ê³µ")
            except:
                self.logger.warning(f"Memory Manager ì—°ë™ ì‹¤íŒ¨: {e}")
                self.memory_manager = None
        else:
            self.memory_manager = None

    def _setup_data_converter:

        """ë°ì´í„° ë³€í™˜ê¸° ì„¤ì •"""
        if:
            try:
                self.data_converter = get_global_data_converter()
                self.logger.info("âœ… Data Converter ì—°ê²° ì„±ê³µ")
            except:
                self.logger.warning(f"Data Converter ì—°ë™ ì‹¤íŒ¨: {e}")
                self.data_converter = None
        else:
            self.data_converter = None

    def _setup_model_paths:

        """ğŸ”¥ ëª¨ë¸ ê²½ë¡œ ì„¤ì • - ModelLoader í˜¸í™˜"""
        try:
            # ê¸°ë³¸ ê²½ë¡œ ì„¤ì •
            self.model_base_path = Path("ai_models")
            self.checkpoint_path = self.model_base_path / "checkpoints" / "step_03"
            self.checkpoint_path.mkdir(parents=True, exist_ok=True)
            
            # ModelLoaderì— ê²½ë¡œ ì •ë³´ ì œê³µ
            self.model_paths = {
                'u2net_cloth_seg': str(self.checkpoint_path / "u2net_cloth.pth"),
                'u2net': str(self.checkpoint_path / "u2net.pth"),
                'u2net_segmentation': str(self.checkpoint_path / "u2net_cloth.pth"),
                'rembg_u2net': 'u2net',  # RemBG ëª¨ë¸ëª…
                'rembg_cloth': 'u2net_cloth_seg',
                'sam_vit_h': str(self.model_base_path / "sam" / "sam_vit_h_4b8939.pth"),
                'sam_vit_b': str(self.model_base_path / "sam" / "sam_vit_b_01ec64.pth"),
            }
            
            self.logger.info("ğŸ“ ëª¨ë¸ ê²½ë¡œ ì„¤ì • ì™„ë£Œ")
            
        except:
            
            self.logger.error(f"ëª¨ë¸ ê²½ë¡œ ì„¤ì • ì‹¤íŒ¨: {e}")

    def _detect_available_methods:

        """ì‚¬ìš© ê°€ëŠ¥í•œ ì„¸ê·¸ë©˜í…Œì´ì…˜ ë°©ë²• ê°ì§€"""
        methods = []
        
        # í•­ìƒ ì‚¬ìš© ê°€ëŠ¥í•œ ì „í†µì  ë°©ë²•
        methods.append(SegmentationMethod.TRADITIONAL)
        
        # RemBG í™•ì¸
        if:
            methods.append(SegmentationMethod.REMBG)
            self.logger.info("âœ… RemBG ì‚¬ìš© ê°€ëŠ¥")
        
        # SAM í™•ì¸
        if:
            methods.append(SegmentationMethod.SAM)
            self.logger.info("âœ… SAM ì‚¬ìš© ê°€ëŠ¥")
        
        # U2-Net (Model Loader í†µí•´ í™•ì¸)
        if:
            methods.append(SegmentationMethod.U2NET)
            self.logger.info("âœ… U2-Net ì‚¬ìš© ê°€ëŠ¥ (Model Loader)")
        
        # Transformers ê¸°ë°˜ ëª¨ë¸
        if:
            methods.append(SegmentationMethod.DEEP_LAB)
            self.logger.info("âœ… DeepLab ì‚¬ìš© ê°€ëŠ¥")
        
        return methods

    async def initialize(self) -> bool:
        """
        âœ… í†µì¼ëœ ì´ˆê¸°í™” ì¸í„°í˜ì´ìŠ¤ - Pipeline Manager í˜¸í™˜
        
        Returns:
            bool: ì´ˆê¸°í™” ì„±ê³µ ì—¬ë¶€
        """
        async with asyncio.Lock():
            if:
                return True
        
        try:
        
            self.logger.info("ğŸ”„ 3ë‹¨ê³„: ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...")
            
            # 1. AI ëª¨ë¸ë“¤ ì´ˆê¸°í™”
            await self._initialize_ai_models()
            
            # 2. RemBG ì„¸ì…˜ ì´ˆê¸°í™”
            if:
                await self._initialize_rembg_sessions()
            
            # 3. ì „í†µì  ë°©ë²•ë“¤ ì´ˆê¸°í™”
            self._initialize_traditional_methods()
            
            # 4. M3 Max ìµœì í™” ì›Œë°ì—…
            if:
                await self._warmup_m3_max()
            
            # 5. ìºì‹œ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
            self._initialize_cache_system()
            
            self.is_initialized = True
            self.logger.info("âœ… ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
            
            return True
            
        except:
            
            error_msg = f"ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}"
            self.logger.error(f"âŒ {error_msg}")
            
            # ìµœì†Œí•œì˜ í´ë°± ì‹œìŠ¤í…œ ì´ˆê¸°í™”
            self._initialize_fallback_system()
            self.is_initialized = True
            
            return True  # Graceful degradation

    async def _initialize_ai_models(self):
        """ğŸ”¥ AI ëª¨ë¸ë“¤ ì´ˆê¸°í™” - ModelLoader ì™„ë²½ í™œìš©"""
        try:
            if:
                self.logger.warning("Model Loader ì¸í„°í˜ì´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤. ì§ì ‘ ë¡œë“œ ì‹œë„.")
                await self._load_u2net_direct()
                return
            
            # ğŸ”¥ ModelLoaderë¥¼ í†µí•œ U2-Net ë¡œë“œ
            try:
                # load_model_async ì˜¬ë°”ë¥¸ í˜¸ì¶œ
                self.u2net_model = await self.model_interface.load_model_async('u2net_cloth_seg')
                
                if:
                
                    self.logger.info("âœ… U2-Net ëª¨ë¸ ë¡œë“œ ì„±ê³µ (ModelLoader)")
                else:
                    self.logger.warning("ModelLoaderì—ì„œ None ë°˜í™˜ - ì§ì ‘ ë¡œë“œ ì‹œë„")
                    await self._load_u2net_direct()
                    
            except:
                    
                self.logger.warning(f"ModelLoaderë¥¼ í†µí•œ U2-Net ë¡œë“œ ì‹¤íŒ¨: {e}")
                # ì§ì ‘ ë¡œë“œ ì‹œë„
                await self._load_u2net_direct()
            
            # ì¶”ê°€ ëª¨ë¸ë“¤ (DeepLab, Mask R-CNN ë“±)
            if:
                await self._initialize_transformer_models()
                
        except:
                
            self.logger.error(f"AI ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")

    async def _load_u2net_direct(self):
        """ğŸ”¥ U2-Net ì§ì ‘ ë¡œë“œ - ì‹¤ì œ ì‘ë™í•˜ëŠ” ë²„ì „"""
        try:
            self.logger.info("ğŸ”„ U2-Net ì§ì ‘ ë¡œë“œ ì‹œì‘...")
            
            # ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
            self.u2net_model = U2NET(in_ch=3, out_ch=1)
            
            # ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ ì‹œë„
            checkpoint_candidates = [
                self.checkpoint_path / "u2net_cloth.pth",
                self.checkpoint_path / "u2net.pth",
                self.model_base_path / "u2net" / "u2net.pth",
                self.model_base_path / "checkpoints" / "u2net.pth"
            ]
            
            model_loaded = False
            for checkpoint_path in checkpoint_candidates:
                if:
                    try:
                        self.logger.info(f"ğŸ“ ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ ì‹œë„: {checkpoint_path}")
                        state_dict = torch.load(checkpoint_path, map_location=self.device)
                        
                        # state_dict í‚¤ ì •ë¦¬ (DataParallel ë“±ì˜ prefix ì œê±°)
                        if:
                            state_dict = {key.replace('module.', ''): value for key, value in state_dict.items()}
                        
                        self.u2net_model.load_state_dict(state_dict, strict=False)
                        self.logger.info(f"âœ… U2-Net ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ ì„±ê³µ: {checkpoint_path}")
                        model_loaded = True
                        break
                        
                    except:
                        
                        self.logger.warning(f"ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ ì‹¤íŒ¨ {checkpoint_path}: {e}")
                        continue
            
            if:
            
                self.logger.warning("âš ï¸ U2-Net ì²´í¬í¬ì¸íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤. ì‚¬ì „ í›ˆë ¨ë˜ì§€ ì•Šì€ ëª¨ë¸ ì‚¬ìš©.")
            
            # ë””ë°”ì´ìŠ¤ ì´ë™ ë° eval ëª¨ë“œ
            self.u2net_model.to(self.device)
            self.u2net_model.eval()
            
            # FP16 ìµœì í™” (M3 Max)
            if:
                self.u2net_model = self.u2net_model.half() if self.device != "cpu" else self
            
            self.logger.info("âœ… U2-Net ì§ì ‘ ë¡œë“œ ì™„ë£Œ")
            
        except:
            
            self.logger.error(f"U2-Net ì§ì ‘ ë¡œë“œ ì‹¤íŒ¨: {e}")
            self.u2net_model = None

    async def _initialize_transformer_models(self):
        """Transformers ê¸°ë°˜ ëª¨ë¸ ì´ˆê¸°í™”"""
        try:
            # DeepLab v3 ì´ˆê¸°í™” (ê°„ì†Œí™”ëœ ë²„ì „)
            try:
                self.deeplab_pipeline = pipeline(
                    "image-segmentation",
                    model="facebook/detr-resnet-50-panoptic",
                    device=0 if self.device == 'cuda' else -1
                )
                self.logger.info("âœ… DeepLab íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” ì™„ë£Œ")
            except:
                self.logger.warning(f"DeepLab ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                self.deeplab_pipeline = None
            
        except:
            
            self.logger.warning(f"Transformer ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.deeplab_pipeline = None

    async def _initialize_rembg_sessions(self):
        """ğŸ”¥ RemBG ì„¸ì…˜ë“¤ ì´ˆê¸°í™” - ì‹¤ì œ ì‘ë™"""
        try:
            if:
                return
            
            self.logger.info("ğŸ”„ RemBG ì„¸ì…˜ ì´ˆê¸°í™” ì‹œì‘...")
            
            # ë‹¤ì–‘í•œ RemBG ëª¨ë¸ ì„¸ì…˜ ìƒì„±
            session_configs = {
                'u2net': 'u2net',
                'u2netp': 'u2netp', 
                'silueta': 'silueta',
            }
            
            # ì˜ë¥˜ íŠ¹í™” ëª¨ë¸ì´ ìˆë‹¤ë©´ ì¶”ê°€
            try:
                session_configs['cloth'] = 'u2net_cloth_seg'
            except:
                pass
            
            self.rembg_sessions = {}
            
            for name, model_name in session_configs.items():
                try:
                    self.logger.info(f"ğŸ”„ RemBG ì„¸ì…˜ ìƒì„± ì¤‘: {name} ({model_name})")
                    session = new_session(model_name)
                    self.rembg_sessions[name] = session
                    self.logger.info(f"âœ… RemBG ì„¸ì…˜ ìƒì„± ì™„ë£Œ: {name}")
                except:
                    self.logger.warning(f"RemBG ì„¸ì…˜ {name} ìƒì„± ì‹¤íŒ¨: {e}")
            
            # ê¸°ë³¸ ì„¸ì…˜ ì„¤ì •
            if self.rembg_sessions:
                # ì˜ë¥˜ìš© ì„¸ì…˜ ìš°ì„ , ì—†ìœ¼ë©´ ì²« ë²ˆì§¸ ì„¸ì…˜
                self.default_rembg_session = (
                    self.rembg_sessions.get('cloth') or 
                    self.rembg_sessions.get('u2net') or 
                    list(self.rembg_sessions.values())[0]
                )
                self.logger.info(f"âœ… RemBG ê¸°ë³¸ ì„¸ì…˜ ì„¤ì • ì™„ë£Œ (ì´ {len(self.rembg_sessions)}ê°œ)")
            else:
                self.default_rembg_session = None
                self.logger.warning("âš ï¸ RemBG ì„¸ì…˜ ìƒì„± ì‹¤íŒ¨ - í´ë°± ëª¨ë“œ")
                
        except:
                
            self.logger.error(f"RemBG ì„¸ì…˜ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.rembg_sessions = {}
            self.default_rembg_session = None

    def _initialize_traditional_methods:

        """ì „í†µì  ì»´í“¨í„° ë¹„ì „ ë°©ë²•ë“¤ ì´ˆê¸°í™”"""
        try:
            # GrabCut ì•Œê³ ë¦¬ì¦˜ ì„¤ì •
            self.grabcut_config = {
                'iterations': 5,
                'margin': 10
            }
            
            # K-means í´ëŸ¬ìŠ¤í„°ë§ ì„¤ì • (scikit-learn ì‚¬ìš© ê°€ëŠ¥ ì‹œ)
            if:
                self.kmeans_config = {
                    'n_clusters': 2,
                    'random_state': 42,
                    'max_iter': 100
                }
            
            # ì„ê³„ê°’ ê¸°ë°˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ ì„¤ì •
            self.threshold_config = {
                'method': cv2.THRESH_OTSU,
                'blur_kernel': (5, 5),
                'morph_kernel': np.ones((3, 3), np.uint8)
            }
            
            self.logger.info("âœ… ì „í†µì  ë°©ë²•ë“¤ ì´ˆê¸°í™” ì™„ë£Œ")
            
        except:
            
            self.logger.error(f"ì „í†µì  ë°©ë²• ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")

    async def _warmup_m3_max(self):
        """ğŸ M3 Max ìµœì í™” ì›Œë°ì—…"""
        try:
            if:
                return
            
            self.logger.info("ğŸ M3 Max ìµœì í™” ì›Œë°ì—… ì‹œì‘...")
            
            # ë”ë¯¸ í…ì„œë¡œ GPU ì›Œë°ì—…
            dummy_input = torch.randn(1, 3, 256, 256).to(self.device)
            
            if:
            
                with torch.no_grad():
                    _ = self.u2net_model(dummy_input)
                self.logger.info("âœ… U2-Net M3 Max ì›Œë°ì—… ì™„ë£Œ")
            
            # MPS ìºì‹œ ìµœì í™”
            if:
                try:
                    if:
                        torch.mps.empty_cache()
                except:
                    pass
            
            # ë©”ëª¨ë¦¬ ìµœì í™”
            if:
                await self.memory_manager.optimize_for_m3_max()
            
            self.logger.info("ğŸ M3 Max ì›Œë°ì—… ì™„ë£Œ")
            
        except:
            
            self.logger.warning(f"M3 Max ì›Œë°ì—… ì‹¤íŒ¨: {e}")

# backend/app/ai_pipeline/steps/step_03_cloth_segmentation.py
# 947ë²ˆì§¸ ì¤„ ê·¼ì²˜ ì™„ì „ ìˆ˜ì •

    def _initialize_cache_system:

        """ìºì‹œ ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
        try:
            # ìºì‹œ í¬ê¸° ì„¤ì • (M3 Max ìµœì í™”)
            cache_size = self.segmentation_config.cache_size
            
            # LRU ìºì‹œë¡œ ë³€í™˜
            from functools import lru_cache
            self._cached_segmentation = lru_cache(maxsize=cache_size)(self._perform_segmentation_cached)
            
            self.logger.info(f"ğŸ’¾ ìºì‹œ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ (í¬ê¸°: {cache_size})")
            
        except:
            
            self.logger.error(f"ìºì‹œ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")

    def _initialize_fallback_system:

        """ìµœì†Œí•œì˜ í´ë°± ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
        try:
            # ê°€ì¥ ê¸°ë³¸ì ì¸ ë°©ë²•ë“¤ë§Œ í™œì„±í™”
            self.available_methods = [SegmentationMethod.TRADITIONAL]
            
            if:
            
                try:
                    self.available_methods.append(SegmentationMethod.REMBG)
                    self.default_rembg_session = new_session('u2net')
                    self.logger.info("âœ… í´ë°±: RemBG ê¸°ë³¸ ì„¸ì…˜ ìƒì„±")
                except:
                    pass
            
            self.logger.info("âš ï¸ í´ë°± ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
            
        except:
            
            self.logger.error(f"í´ë°± ì‹œìŠ¤í…œ ì´ˆê¸°í™”ë„ ì‹¤íŒ¨: {e}")

    async def process(
        self, 
        clothing_image: Union[str, np.ndarray, Image.Image, torch.Tensor], 
        clothing_type: str = "shirt",
        quality_level: str = "balanced",
        **kwargs
    ) -> Dict[str, Any]:
        """
        âœ… í†µì¼ëœ ì²˜ë¦¬ ì¸í„°í˜ì´ìŠ¤ - Pipeline Manager í˜¸í™˜ + ì‹œê°í™”
        """
        if:
            await self.initialize()
        
        start_time = time.time()
        
        try:
        
            self.logger.info(f"ğŸ‘• ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‹œì‘ - íƒ€ì…: {clothing_type}, í’ˆì§ˆ: {quality_level}")
            
            # 1. ìºì‹œ í™•ì¸
            cache_key = self._generate_cache_key(clothing_image, clothing_type, quality_level)
            if:
                cached_result = self.segmentation_cache[cache_key]
                self.processing_stats['cache_hits'] += 1
                self.logger.info("ğŸ’¾ ìºì‹œì—ì„œ ê²°ê³¼ ë°˜í™˜")
                return self._format_result_with_visualization(cached_result)
            
            # 2. ì…ë ¥ ì´ë¯¸ì§€ ì „ì²˜ë¦¬
            processed_image = self._preprocess_image(clothing_image)
            
            # 3. ìµœì  ë°©ë²• ì„ íƒ
            method = kwargs.get('method_override') or self._select_best_method(
                processed_image, clothing_type, quality_level
            )
            
            # 4. ë©”ì¸ ì„¸ê·¸ë©˜í…Œì´ì…˜ ìˆ˜í–‰
            result = await self._perform_segmentation_with_fallback(
                processed_image, method, clothing_type, **kwargs
            )
            
            # 5. í›„ì²˜ë¦¬
            if:
                result = await self._post_process_result(result, processed_image)
            
            # 6. í’ˆì§ˆ í‰ê°€
            if:
                result.quality_score = self._evaluate_quality(processed_image, result.mask)
                result.confidence_score = self._calculate_confidence(result)
            
            # ğŸ†• 7. ì‹œê°í™” ì´ë¯¸ì§€ ìƒì„±
            if:
                visualization_results = await self._create_segmentation_visualization(
                    result, processed_image, clothing_type
                )
                # ì‹œê°í™” ê²°ê³¼ë¥¼ ë©”íƒ€ë°ì´í„°ì— ì¶”ê°€
                result.metadata.update(visualization_results)
            
            # 8. ê²°ê³¼ ìºì‹±
            if:
                self.segmentation_cache[cache_key] = result
                if:
                    self._cleanup_cache()
            
            # 9. í†µê³„ ì—…ë°ì´íŠ¸
            self._update_statistics(result, time.time() - start_time)
            
            self.logger.info(f"âœ… ì„¸ê·¸ë©˜í…Œì´ì…˜ ì™„ë£Œ - ë°©ë²•: {result.method_used}, "
                            f"í’ˆì§ˆ: {result.quality_score:.3f}, ì‹œê°„: {result.processing_time:.3f}ì´ˆ")
            
            return self._format_result_with_visualization(result)
            
        except:
            
            error_msg = f"ì„¸ê·¸ë©˜í…Œì´ì…˜ ì²˜ë¦¬ ì‹¤íŒ¨: {e}"
            self.logger.error(f"âŒ {error_msg}")
            
            # ì—ëŸ¬ ê²°ê³¼ ë°˜í™˜
            error_result = SegmentationResult(
                success=False,
                error_message=error_msg,
                processing_time=time.time() - start_time,
                method_used="error"
            )
            
            return self._format_result_with_visualization(error_result)
    # ==============================================
    # ğŸ†• ì‹œê°í™” í•¨ìˆ˜ë“¤ - ì™„ì „ êµ¬í˜„
    # ==============================================
    
    async def _create_segmentation_visualization(
        self, 
        result: SegmentationResult, 
        original_image: Image.Image, 
        clothing_type: str
    ) -> Dict[str, str]:
        """
        ğŸ†• ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ ê²°ê³¼ ì‹œê°í™” ì´ë¯¸ì§€ë“¤ ìƒì„±
        """
        try:
            if:
                return {
                    "result_image": "",
                    "overlay_image": "",
                    "mask_image": "",
                    "boundary_image": ""
                }
            
            def _create_visualizations():
                # 1. ğŸ¨ ìƒ‰ìƒí™”ëœ ì„¸ê·¸ë©˜í…Œì´ì…˜ ê²°ê³¼
                colored_segmentation = self._create_colored_segmentation(
                    result.mask, clothing_type
                )
                
                # 2. ğŸŒˆ ì˜¤ë²„ë ˆì´ ì´ë¯¸ì§€ (ì›ë³¸ + ì„¸ê·¸ë©˜í…Œì´ì…˜)
                overlay_image = self._create_overlay_visualization(
                    original_image, colored_segmentation
                )
                
                # 3. ğŸ“„ ë§ˆìŠ¤í¬ ì‹œê°í™”
                mask_visualization = self._create_mask_visualization(result.mask)
                
                # 4. ğŸ“ ê²½ê³„ì„  ì‹œê°í™”
                boundary_visualization = self._create_boundary_visualization(
                    original_image, result.mask
                )
                
                # base64 ì¸ì½”ë”©
                return {
                    "result_image": self._pil_to_base64(colored_segmentation),
                    "overlay_image": self._pil_to_base64(overlay_image),
                    "mask_image": self._pil_to_base64(mask_visualization),
                    "boundary_image": self._pil_to_base64(boundary_visualization)
                }
            
            # ë¹„ë™ê¸° ì‹¤í–‰
            loop = asyncio.get_event_loop()
            return await loop.run_in_executor(self.executor, _create_visualizations)
            
        except:
            
            self.logger.error(f"âŒ ì‹œê°í™” ìƒì„± ì‹¤íŒ¨: {e}")
            return {
                "result_image": "",
                "overlay_image": "",
                "mask_image": "",
                "boundary_image": ""
            }
    
    def _create_colored_segmentation:
    
        """ìƒ‰ìƒí™”ëœ ì„¸ê·¸ë©˜í…Œì´ì…˜ ê²°ê³¼ ìƒì„±"""
        try:
            height, width = mask.shape
            colored_image = np.zeros((height, width, 3), dtype=np.uint8)
            
            # ì˜ë¥˜ íƒ€ì…ì— ë”°ë¥¸ ìƒ‰ìƒ ì„ íƒ
            clothing_color = CLOTHING_COLORS.get(clothing_type, CLOTHING_COLORS['unknown'])
            
            # ë§ˆìŠ¤í¬ ì˜ì—­ì— ìƒ‰ìƒ ì ìš©
            mask_binary = (mask > 128).astype(np.uint8)
            colored_image[mask_binary == 1] = clothing_color
            
            # ë°°ê²½ì€ ì—°í•œ íšŒìƒ‰ìœ¼ë¡œ
            colored_image[mask_binary == 0] = (240, 240, 240)
            
            return Image.fromarray(colored_image)
            
        except:
            
            self.logger.warning(f"âš ï¸ ìƒ‰ìƒ ì„¸ê·¸ë©˜í…Œì´ì…˜ ìƒì„± ì‹¤íŒ¨: {e}")
            # í´ë°±: ê¸°ë³¸ ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ì´ë¯¸ì§€
            gray_image = np.stack([mask, mask, mask], axis=2)
            return Image.fromarray(gray_image)
    
    def _create_overlay_visualization:
    
        """ì›ë³¸ê³¼ ì„¸ê·¸ë©˜í…Œì´ì…˜ ì˜¤ë²„ë ˆì´ ì´ë¯¸ì§€ ìƒì„±"""
        try:
            # í¬ê¸° ë§ì¶”ê¸°
            width, height = original_image.size
            segmentation_resized = segmentation_image.resize((width, height), Image.Resampling.NEAREST)
            
            # ì•ŒíŒŒ ë¸”ë Œë”©
            opacity = self.segmentation_config.overlay_opacity
            overlay = Image.blend(original_image, segmentation_resized, opacity)
            
            return overlay
            
        except:
            
            self.logger.warning(f"âš ï¸ ì˜¤ë²„ë ˆì´ ìƒì„± ì‹¤íŒ¨: {e}")
            return original_image
    
    def _create_mask_visualization:
    
        """ë§ˆìŠ¤í¬ ì‹œê°í™” ì´ë¯¸ì§€ ìƒì„±"""
        try:
            # ë§ˆìŠ¤í¬ë¥¼ 3ì±„ë„ë¡œ ë³€í™˜
            mask_colored = np.stack([mask, mask, mask], axis=2)
            
            # ëŒ€ë¹„ í–¥ìƒ
            mask_colored = np.clip(mask_colored * 1.2, 0, 255).astype(np.uint8)
            
            return Image.fromarray(mask_colored)
            
        except:
            
            self.logger.warning(f"âš ï¸ ë§ˆìŠ¤í¬ ì‹œê°í™” ìƒì„± ì‹¤íŒ¨: {e}")
            # í´ë°±: ê¸°ë³¸ ë§ˆìŠ¤í¬
            return Image.fromarray(mask)
    
    def _create_boundary_visualization:
    
        """ê²½ê³„ì„  ì‹œê°í™” ì´ë¯¸ì§€ ìƒì„±"""
        try:
            # ê²½ê³„ì„  ê²€ì¶œ
            edges = cv2.Canny(mask.astype(np.uint8), 50, 150)
            
            # ê²½ê³„ì„  ë‘ê»ê²Œ ë§Œë“¤ê¸°
            kernel = np.ones((3, 3), np.uint8)
            edges_thick = cv2.dilate(edges, kernel, iterations=1)
            
            # ì›ë³¸ ì´ë¯¸ì§€ì— ê²½ê³„ì„  ì˜¤ë²„ë ˆì´
            original_np = np.array(original_image)
            result_image = original_np.copy()
            
            # ê²½ê³„ì„ ì„ ë¹¨ê°„ìƒ‰ìœ¼ë¡œ í‘œì‹œ
            result_image[edges_thick > 0] = [255, 0, 0]
            
            return Image.fromarray(result_image)
            
        except:
            
            self.logger.warning(f"âš ï¸ ê²½ê³„ì„  ì‹œê°í™” ìƒì„± ì‹¤íŒ¨: {e}")
            return original_image
    
    def _pil_to_base64:
    
        """PIL ì´ë¯¸ì§€ë¥¼ base64 ë¬¸ìì—´ë¡œ ë³€í™˜"""
        try:
            buffer = BytesIO()
            
            # í’ˆì§ˆ ì„¤ì •
            quality = 85
            if:
                quality = 95
            elif self.segmentation_config.visualization_quality == "low":
                quality = 70
            
            pil_image.save(buffer, format='JPEG', quality=quality)
            return base64.b64encode(buffer.getvalue()).decode('utf-8')
            
        except:
            
            self.logger.warning(f"âš ï¸ base64 ë³€í™˜ ì‹¤íŒ¨: {e}")
            return ""

    # ==============================================
    # ğŸ”§ í•µì‹¬ ì²˜ë¦¬ í•¨ìˆ˜ë“¤ - ì™„ì „ êµ¬í˜„
    # ==============================================

    def _preprocess_image:

        """ì´ë¯¸ì§€ ì „ì²˜ë¦¬"""
        try:
            # íƒ€ì…ë³„ ë³€í™˜
            if:
                pil_image = Image.open(image).convert('RGB')
            elif isinstance(image, np.ndarray):
                if:
                    pil_image = Image.fromarray(image)
                else:
                    pil_image = Image.fromarray((image * 255).astype(np.uint8))
                if:
                    pil_image = pil_image.convert('RGB')
            elif isinstance(image, torch.Tensor):
                if:
                    pil_image = self.data_converter.tensor_to_pil(image)
                else:
                    # ì§ì ‘ ë³€í™˜
                    numpy_image = image.detach().cpu().numpy()
                    if:
                        numpy_image = numpy_image.squeeze(0)
                    if:
                        numpy_image = numpy_image.transpose(1, 2, 0)
                    numpy_image = (numpy_image * 255).astype(np.uint8)
                    pil_image = Image.fromarray(numpy_image).convert('RGB')
            elif isinstance(image, Image.Image):
                pil_image = image.convert('RGB')
            else:
                raise ValueError(f"ì§€ì›ë˜ì§€ ì•ŠëŠ” ì´ë¯¸ì§€ íƒ€ì…: {type(image)}")
            
            # í¬ê¸° ì¡°ì • (ì„¤ì •ì— ë”°ë¼)
            target_size = self.segmentation_config.input_size
            if:
                pil_image = pil_image.resize(target_size, Image.Resampling.LANCZOS)
            
            return pil_image
            
        except:
            
            self.logger.error(f"ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            raise

    def _select_best_method:

        """ìµœì  ì„¸ê·¸ë©˜í…Œì´ì…˜ ë°©ë²• ì„ íƒ"""
        try:
            # í’ˆì§ˆ ë ˆë²¨ì— ë”°ë¥¸ ìš°ì„ ìˆœìœ„
            if:
                priority = [SegmentationMethod.U2NET, SegmentationMethod.SAM, 
                            SegmentationMethod.DEEP_LAB, SegmentationMethod.REMBG]
            elif quality_level == "high":
                priority = [SegmentationMethod.U2NET, SegmentationMethod.REMBG, 
                            SegmentationMethod.DEEP_LAB]
            elif quality_level == "balanced":
                priority = [SegmentationMethod.REMBG, SegmentationMethod.U2NET, 
                            SegmentationMethod.TRADITIONAL]
            else:  # fast
                priority = [SegmentationMethod.REMBG, SegmentationMethod.TRADITIONAL]
            
            # ì‚¬ìš© ê°€ëŠ¥í•œ ë°©ë²• ì¤‘ì—ì„œ ì„ íƒ
            for method in priority:
                if:
                    return method
            
            # í´ë°±
            return SegmentationMethod.TRADITIONAL
            
        except:
            
            self.logger.warning(f"ë°©ë²• ì„ íƒ ì‹¤íŒ¨: {e}")
            return SegmentationMethod.TRADITIONAL

    async def _perform_segmentation_with_fallback(
        self, 
        image: Image.Image, 
        method: SegmentationMethod, 
        clothing_type: str,
        **kwargs
    ) -> SegmentationResult:
        """í´ë°±ì„ í¬í•¨í•œ ì„¸ê·¸ë©˜í…Œì´ì…˜ ìˆ˜í–‰"""
        enable_fallback = kwargs.get('enable_fallback', True)
        
        try:
            # ë©”ì¸ ë°©ë²• ì‹œë„
            result = await self._perform_single_segmentation(image, method, clothing_type)
            
            if:
            
                return result
            
            if:
            
                return result
            
            # í´ë°± ë°©ë²•ë“¤ ì‹œë„
            fallback_methods = [m for m in self.available_methods if m != method]
            
            for fallback_method in fallback_methods:
                self.logger.warning(f"í´ë°± ë°©ë²• ì‹œë„: {fallback_method.value}")
                try:
                    fallback_result = await self._perform_single_segmentation(
                        image, fallback_method, clothing_type
                    )
                    if:
                        fallback_result.metadata['original_method'] = method.value
                        fallback_result.metadata['fallback_used'] = True
                        return fallback_result
                except:
                    self.logger.warning(f"í´ë°± ë°©ë²• {fallback_method.value} ì‹¤íŒ¨: {e}")
                    continue
            
            # ëª¨ë“  ë°©ë²• ì‹¤íŒ¨
            return SegmentationResult(
                success=False,
                error_message="ëª¨ë“  ì„¸ê·¸ë©˜í…Œì´ì…˜ ë°©ë²• ì‹¤íŒ¨",
                method_used=method.value
            )
            
        except:
            
            return SegmentationResult(
                success=False,
                error_message=f"ì„¸ê·¸ë©˜í…Œì´ì…˜ ìˆ˜í–‰ ì‹¤íŒ¨: {e}",
                method_used=method.value
            )

    async def _perform_single_segmentation(
        self, 
        image: Image.Image, 
        method: SegmentationMethod, 
        clothing_type: str
    ) -> SegmentationResult:
        """ë‹¨ì¼ ì„¸ê·¸ë©˜í…Œì´ì…˜ ë°©ë²• ìˆ˜í–‰"""
        start_time = time.time()
        
        try:
        
            if:
        
                result = await self._segment_with_u2net(image)
            elif method == SegmentationMethod.REMBG:
                result = await self._segment_with_rembg(image)
            elif method == SegmentationMethod.SAM:
                result = await self._segment_with_sam(image)
            elif method == SegmentationMethod.DEEP_LAB:
                result = await self._segment_with_deeplab(image)
            elif method == SegmentationMethod.TRADITIONAL:
                result = await self._segment_with_traditional(image)
            else:
                raise ValueError(f"ì§€ì›ë˜ì§€ ì•ŠëŠ” ë°©ë²•: {method}")
            
            result.processing_time = time.time() - start_time
            result.method_used = method.value
            
            return result
            
        except:
            
            return SegmentationResult(
                success=False,
                error_message=f"{method.value} ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‹¤íŒ¨: {e}",
                method_used=method.value,
                processing_time=time.time() - start_time
            )

    async def _segment_with_u2net(self, image: Image.Image) -> SegmentationResult:
        """ğŸ”¥ U2-Netì„ ì‚¬ìš©í•œ ì„¸ê·¸ë©˜í…Œì´ì…˜ - ì‹¤ì œ ì‘ë™"""
        try:
            if:
                raise RuntimeError("U2-Net ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
            
            # ì´ë¯¸ì§€ë¥¼ í…ì„œë¡œ ë³€í™˜
            transform = transforms.Compose([
                transforms.Resize(self.segmentation_config.input_size),
                transforms.ToTensor(),
                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
            ])
            
            input_tensor = transform(image).unsqueeze(0).to(self.device)
            
            if:
            
                input_tensor = input_tensor.half() if self.device != "cpu" else self
            
            # ì¶”ë¡ 
            with torch.no_grad():
                outputs = self.u2net_model(input_tensor)
                
                # ë©”ì¸ ì¶œë ¥ ì‚¬ìš©
                if:
                    mask_tensor = outputs[0]
                else:
                    mask_tensor = outputs
                
                # í›„ì²˜ë¦¬
                mask_tensor = torch.sigmoid(mask_tensor)
                mask_np = mask_tensor.squeeze().cpu().float().numpy()
                
                # ì„ê³„ê°’ ì ìš©
                threshold = self.confidence_threshold
                binary_mask = (mask_np > threshold).astype(np.uint8) * 255
                
                # ë§ˆìŠ¤í¬ í¬ê¸° ì¡°ì •
                if:
                    binary_mask = cv2.resize(binary_mask, image.size, interpolation=cv2.INTER_NEAREST)
                
                # ì„¸ê·¸ë©˜í…Œì´ì…˜ëœ ì´ë¯¸ì§€ ìƒì„±
                image_np = np.array(image)
                segmented_image = image_np.copy()
                segmented_image[binary_mask == 0] = [0, 0, 0]  # ë°°ê²½ì„ ê²€ì€ìƒ‰ìœ¼ë¡œ
            
            return SegmentationResult(
                success=True,
                mask=binary_mask,
                segmented_image=segmented_image,
                confidence_score=float(mask_np.max()),
                metadata={'threshold_used': threshold}
            )
            
        except:
            
            return SegmentationResult(
                success=False,
                error_message=f"U2-Net ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‹¤íŒ¨: {e}"
            )

    async def _segment_with_rembg(self, image: Image.Image) -> SegmentationResult:
        """ğŸ”¥ RemBGë¥¼ ì‚¬ìš©í•œ ì„¸ê·¸ë©˜í…Œì´ì…˜ - ì‹¤ì œ ì‘ë™"""
        try:
            if:
                raise RuntimeError("RemBGê°€ ì‚¬ìš© ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤")
            
            # ì„¸ì…˜ ì„ íƒ
            session = None
            if:
                session = self.rembg_sessions.get('cloth', self.default_rembg_session)
            
            if:
            
                session = new_session('u2net')
            
            # ë°°ê²½ ì œê±°
            image_bytes = self._pil_to_bytes(image)
            result_bytes = remove(image_bytes, session=session)
            result_image = Image.open(BytesIO(result_bytes)).convert('RGBA')
            
            # ë§ˆìŠ¤í¬ ìƒì„± (ì•ŒíŒŒ ì±„ë„ ì‚¬ìš©)
            alpha_channel = np.array(result_image)[:, :, 3]
            binary_mask = (alpha_channel > 128).astype(np.uint8) * 255
            
            # ì„¸ê·¸ë©˜í…Œì´ì…˜ëœ ì´ë¯¸ì§€ ìƒì„±
            rgb_result = result_image.convert('RGB')
            segmented_image = np.array(rgb_result)
            
            return SegmentationResult(
                success=True,
                mask=binary_mask,
                segmented_image=segmented_image,
                confidence_score=0.9,  # RemBGëŠ” ì¼ë°˜ì ìœ¼ë¡œ ì‹ ë¢°ë„ê°€ ë†’ìŒ
                metadata={'session_used': 'cloth' if session in getattr(self, 'rembg_sessions', {}).values() else 'default'}
            )
            
        except:
            
            return SegmentationResult(
                success=False,
                error_message=f"RemBG ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‹¤íŒ¨: {e}"
            )

    async def _segment_with_sam(self, image: Image.Image) -> SegmentationResult:
        """SAM(Segment Anything Model)ì„ ì‚¬ìš©í•œ ì„¸ê·¸ë©˜í…Œì´ì…˜"""
        try:
            if:
                raise RuntimeError("SAMì´ ì‚¬ìš© ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤")
            
            # SAM êµ¬í˜„ (ê°„ì†Œí™”ëœ ë²„ì „)
            # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” SAM ëª¨ë¸ ë¡œë“œ ë° ì¶”ë¡  ë¡œì§ í•„ìš”
            
            # ì„ì‹œ êµ¬í˜„ - ì¤‘ì•™ ì˜ì—­ì„ ì˜ë¥˜ë¡œ ê°€ì •
            width, height = image.size
            mask = np.zeros((height, width), dtype=np.uint8)
            
            # ì¤‘ì•™ 70% ì˜ì—­ì„ ì˜ë¥˜ë¡œ ì„¤ì •
            margin_x = int(width * 0.15)
            margin_y = int(height * 0.15)
            mask[margin_y:height-margin_y, margin_x:width-margin_x] = 255
            
            # ì„¸ê·¸ë©˜í…Œì´ì…˜ëœ ì´ë¯¸ì§€ ìƒì„±
            image_np = np.array(image)
            segmented_image = image_np.copy()
            segmented_image[mask == 0] = [0, 0, 0]
            
            return SegmentationResult(
                success=True,
                mask=mask,
                segmented_image=segmented_image,
                confidence_score=0.7,
                metadata={'method': 'sam_simplified'}
            )
            
        except:
            
            return SegmentationResult(
                success=False,
                error_message=f"SAM ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‹¤íŒ¨: {e}"
            )

    async def _segment_with_deeplab(self, image: Image.Image) -> SegmentationResult:
        """DeepLabì„ ì‚¬ìš©í•œ ì„¸ê·¸ë©˜í…Œì´ì…˜"""
        try:
            if:
                raise RuntimeError("DeepLab íŒŒì´í”„ë¼ì¸ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
            
            # DeepLab ì¶”ë¡ 
            results = self.deeplab_pipeline(image)
            
            # ê²°ê³¼ ì²˜ë¦¬ (ì˜ë¥˜ ê´€ë ¨ í´ë˜ìŠ¤ í•„í„°ë§)
            clothing_classes = ['person', 'clothing', 'shirt', 'dress']  # ì˜ˆì‹œ
            
            mask = np.zeros(image.size[::-1], dtype=np.uint8)
            
            for result in results:
                if any(cls in result['label'].lower() for cls in clothing_classes):
                    # ë§ˆìŠ¤í¬ ìƒì„± ë¡œì§
                    # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” segmentation ë§ˆìŠ¤í¬ ì²˜ë¦¬ í•„ìš”
                    pass
            
            # ì„ì‹œ êµ¬í˜„
            width, height = image.size
            center_mask = np.zeros((height, width), dtype=np.uint8)
            cv2.ellipse(center_mask, (width//2, height//2), (width//3, height//2), 0, 0, 360, 255, -1)
            
            # ì„¸ê·¸ë©˜í…Œì´ì…˜ëœ ì´ë¯¸ì§€ ìƒì„±
            image_np = np.array(image)
            segmented_image = image_np.copy()
            segmented_image[center_mask == 0] = [0, 0, 0]
            
            return SegmentationResult(
                success=True,
                mask=center_mask,
                segmented_image=segmented_image,
                confidence_score=0.8,
                metadata={'deeplab_results_count': len(results)}
            )
            
        except:
            
            return SegmentationResult(
                success=False,
                error_message=f"DeepLab ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‹¤íŒ¨: {e}"
            )

    async def _segment_with_traditional(self, image: Image.Image) -> SegmentationResult:
        """ğŸ”¥ ì „í†µì  ì»´í“¨í„° ë¹„ì „ ë°©ë²•ì„ ì‚¬ìš©í•œ ì„¸ê·¸ë©˜í…Œì´ì…˜ - ì‹¤ì œ ì‘ë™"""
        try:
            image_np = np.array(image)
            height, width = image_np.shape[:2]
            
            # ë°©ë²• 1: GrabCut ì•Œê³ ë¦¬ì¦˜
            try:
                mask = np.zeros((height, width), np.uint8)
                
                # ì „ê²½ ì˜ì—­ ëŒ€ëµì  ì„¤ì • (ì¤‘ì•™ 80%)
                margin_x = int(width * 0.1)
                margin_y = int(height * 0.1)
                rect = (margin_x, margin_y, width - 2*margin_x, height - 2*margin_y)
                
                # GrabCut ì´ˆê¸°í™”
                bgd_model = np.zeros((1, 65), np.float64)
                fgd_model = np.zeros((1, 65), np.float64)
                
                # GrabCut ì ìš©
                cv2.grabCut(image_np, mask, rect, bgd_model, fgd_model, 
                            self.grabcut_config['iterations'], cv2.GC_INIT_WITH_RECT)
                
                # ë§ˆìŠ¤í¬ ì²˜ë¦¬
                mask2 = np.where((mask == 2) | (mask == 0), 0, 1).astype('uint8')
                binary_mask = mask2 * 255
                
                # í˜•íƒœí•™ì  ì²˜ë¦¬
                kernel = np.ones((3, 3), np.uint8)
                binary_mask = cv2.morphologyEx(binary_mask, cv2.MORPH_CLOSE, kernel)
                binary_mask = cv2.morphologyEx(binary_mask, cv2.MORPH_OPEN, kernel)
                
                confidence = 0.6
                
            except:
                # ë°©ë²• 2: ìƒ‰ìƒ ê¸°ë°˜ ì„ê³„ê°’ (í´ë°±)
                hsv = cv2.cvtColor(image_np, cv2.COLOR_RGB2HSV)
                
                # ë°°ê²½ì´ ë‹¨ìˆœí•˜ë‹¤ê³  ê°€ì •í•˜ê³  ê°€ì¥ìë¦¬ ìƒ‰ìƒì„ ë°°ê²½ìœ¼ë¡œ ê°„ì£¼
                edges = np.concatenate([
                    hsv[0, :], hsv[-1, :], hsv[:, 0], hsv[:, -1]
                ])
                
                if SKLEARN_AVAILABLE:
                    # K-meansë¡œ ë°°ê²½ìƒ‰ ì¶”ì •
                    kmeans = KMeans(n_clusters=2, random_state=42)
                    edge_colors = edges.reshape(-1, 3)
                    kmeans.fit(edge_colors)
                    
                    # ê°€ì¥ ë¹ˆë²ˆí•œ í´ëŸ¬ìŠ¤í„°ë¥¼ ë°°ê²½ìœ¼ë¡œ ê°„ì£¼
                    labels = kmeans.predict(hsv.reshape(-1, 3))
                    background_label = np.bincount(labels[:len(edges)]).argmax()
                    
                    pixel_labels = kmeans.predict(hsv.reshape(-1, 3))
                    binary_mask = (pixel_labels != background_label).astype(np.uint8).reshape(height, width) * 255
                else:
                    # ë‹¨ìˆœ ì„ê³„ê°’ ë°©ë²•
                    gray = cv2.cvtColor(image_np, cv2.COLOR_RGB2GRAY)
                    _, binary_mask = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
                
                confidence = 0.4
            
            # ì„¸ê·¸ë©˜í…Œì´ì…˜ëœ ì´ë¯¸ì§€ ìƒì„±
            segmented_image = image_np.copy()
            segmented_image[binary_mask == 0] = [0, 0, 0]
            
            return SegmentationResult(
                success=True,
                mask=binary_mask,
                segmented_image=segmented_image,
                confidence_score=confidence,
                metadata={'method': 'grabcut' if 'mask2' in locals() else 'threshold'}
            )
            
        except:
            
            return SegmentationResult(
                success=False,
                error_message=f"ì „í†µì  ë°©ë²• ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‹¤íŒ¨: {e}"
            )

    async def _post_process_result(self, result: SegmentationResult, original_image: Image.Image) -> SegmentationResult:
        """ì„¸ê·¸ë©˜í…Œì´ì…˜ ê²°ê³¼ í›„ì²˜ë¦¬"""
        try:
            if:
                return result
            
            mask = result.mask.copy()
            
            # 1. í˜•íƒœí•™ì  ì²˜ë¦¬
            if:
                kernel = np.ones((3, 3), np.uint8)
                
                # ë…¸ì´ì¦ˆ ì œê±°
                mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)
                
                # í™€ ì±„ìš°ê¸°
                if:
                    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)
                
                # ê²½ê³„ ë¶€ë“œëŸ½ê²Œ
                mask = cv2.medianBlur(mask, 5)
            
            # 2. ê²½ê³„ ê°œì„ 
            if:
                mask = self._refine_edges(mask, np.array(original_image))
            
            # 3. ì„¸ê·¸ë©˜í…Œì´ì…˜ëœ ì´ë¯¸ì§€ ì¬ìƒì„±
            image_np = np.array(original_image)
            segmented_image = image_np.copy()
            segmented_image[mask == 0] = [0, 0, 0]
            
            result.mask = mask
            result.segmented_image = segmented_image
            result.metadata['post_processed'] = True
            
            return result
            
        except:
            
            self.logger.warning(f"í›„ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return result

    def _refine_edges:

        """ê²½ê³„ ê°œì„ """
        try:
            # ê°€ìš°ì‹œì•ˆ ë¸”ëŸ¬ë¥¼ ì‚¬ìš©í•œ ê²½ê³„ ë¶€ë“œëŸ½ê²Œ
            if self.segmentation_config.enable_edge_refinement:
                # ê²½ê³„ ê²€ì¶œ
                edges = cv2.Canny(mask, 50, 150)
                
                # ê²½ê³„ ì£¼ë³€ ì˜ì—­ í™•ì¥
                kernel = np.ones((5, 5), np.uint8)
                edge_region = cv2.dilate(edges, kernel, iterations=1)
                
                # í•´ë‹¹ ì˜ì—­ì— ê°€ìš°ì‹œì•ˆ ë¸”ëŸ¬ ì ìš©
                blurred_mask = cv2.GaussianBlur(mask.astype(np.float32), (5, 5), 1.0)
                
                # ê²½ê³„ ì˜ì—­ë§Œ ë¸”ëŸ¬ëœ ê°’ìœ¼ë¡œ êµì²´
                refined_mask = mask.copy().astype(np.float32)
                refined_mask[edge_region > 0] = blurred_mask[edge_region > 0]
                
                return (refined_mask > 127).astype(np.uint8) * 255
            
            return mask
            
        except:
            
            self.logger.warning(f"ê²½ê³„ ê°œì„  ì‹¤íŒ¨: {e}")
            return mask

    def _evaluate_quality:

        """ì„¸ê·¸ë©˜í…Œì´ì…˜ í’ˆì§ˆ í‰ê°€"""
        try:
            if:
                return 0.0
            
            height, width = mask.shape
            total_pixels = height * width
            
            # 1. ì „ê²½ ë¹„ìœ¨ (ë„ˆë¬´ ì‘ê±°ë‚˜ í¬ë©´ í’ˆì§ˆ ë‚®ìŒ)
            foreground_pixels = np.sum(mask > 0)
            fg_ratio = foreground_pixels / total_pixels
            
            # ì´ìƒì ì¸ ë¹„ìœ¨: 20-80%
            if:
                ratio_score = 1.0
            elif fg_ratio < 0.1 or fg_ratio > 0.9:
                ratio_score = 0.0
            else:
                ratio_score = 0.5
            
            # 2. ì—°ê²°ì„± í‰ê°€ (í° ì—°ê²° ì»´í¬ë„ŒíŠ¸ê°€ ìˆì–´ì•¼ í•¨)
            num_labels, labels, stats, _ = cv2.connectedComponentsWithStats(mask, connectivity=8)
            
            if num_labels > 1:  # ë°°ê²½ ì œì™¸
                # ê°€ì¥ í° ì»´í¬ë„ŒíŠ¸ì˜ í¬ê¸°
                largest_component_size = np.max(stats[1:, cv2.CC_STAT_AREA])
                connectivity_score = min(largest_component_size / foreground_pixels, 1.0)
            else:
                connectivity_score = 0.0
            
            # 3. ê²½ê³„ ë¶€ë“œëŸ¬ì›€ í‰ê°€
            edges = cv2.Canny(mask, 50, 150)
            edge_pixels = np.sum(edges > 0)
            edge_ratio = edge_pixels / foreground_pixels if foreground_pixels > 0 else 1.0
            
            # ê²½ê³„ê°€ ë„ˆë¬´ ë³µì¡í•˜ë©´ í’ˆì§ˆ ë‚®ìŒ
            smoothness_score = max(0, 1.0 - edge_ratio)
            
            # 4. ì „ì²´ í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°
            quality_score = (
                ratio_score * 0.4 +
                connectivity_score * 0.4 +
                smoothness_score * 0.2
            )
            
            return min(max(quality_score, 0.0), 1.0)
            
        except:
            
            self.logger.warning(f"í’ˆì§ˆ í‰ê°€ ì‹¤íŒ¨: {e}")
            return 0.5

    def _calculate_confidence:

        """ì‹ ë¢°ë„ ê³„ì‚°"""
        try:
            if:
                return 0.0
            
            # ë°©ë²•ë³„ ê¸°ë³¸ ì‹ ë¢°ë„
            method_confidence = {
                'u2net': 0.9,
                'rembg': 0.85,
                'deeplab': 0.8,
                'sam': 0.75,
                'traditional': 0.6
            }
            
            base_confidence = method_confidence.get(result.method_used, 0.5)
            
            # í’ˆì§ˆ ì ìˆ˜ì™€ ê²°í•©
            quality_factor = result.quality_score if hasattr(result, 'quality_score') and result.quality_score else 0.5
            
            # ìµœì¢… ì‹ ë¢°ë„
            final_confidence = (base_confidence * 0.7 + quality_factor * 0.3)
            
            return min(max(final_confidence, 0.0), 1.0)
            
        except:
            
            self.logger.warning(f"ì‹ ë¢°ë„ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return 0.5

    def _generate_cache_key(self, image: Union[str, np.ndarray, Image.Image, torch.Tensor], 
                            clothing_type: str, quality_level: str) -> str:
        """ìºì‹œ í‚¤ ìƒì„±"""
        try:
            # ì´ë¯¸ì§€ í•´ì‹œ ìƒì„±
            if isinstance(image, str):
                # íŒŒì¼ ê²½ë¡œì˜ ê²½ìš° ìˆ˜ì • ì‹œê°„ í¬í•¨
                stat = os.stat(image)
                image_hash = f"file_{hash(image)}_{stat.st_mtime}"
            else:
                # ì´ë¯¸ì§€ ë°ì´í„°ì˜ í•´ì‹œ
                if:
                    image_bytes = self._pil_to_bytes(image)
                elif isinstance(image, np.ndarray):
                    image_bytes = image.tobytes()
                elif isinstance(image, torch.Tensor):
                    image_bytes = image.detach().cpu().numpy().tobytes()
                else:
                    image_bytes = str(image).encode()
                
                image_hash = hashlib.md5(image_bytes).hexdigest()[:16]
            
            # ì „ì²´ í‚¤ ìƒì„±
            cache_key = f"{image_hash}_{clothing_type}_{quality_level}_{self.device}"
            return cache_key
            
        except:
            
            self.logger.warning(f"ìºì‹œ í‚¤ ìƒì„± ì‹¤íŒ¨: {e}")
            return f"fallback_{time.time()}_{clothing_type}_{quality_level}"

    def _cleanup_cache:

        """ìºì‹œ ì •ë¦¬ (LRU ë°©ì‹)"""
        try:
            if:
                return
            
            # ê°€ì¥ ì˜¤ë˜ëœ í•­ëª©ë“¤ ì œê±°
            items = list(self.segmentation_cache.items())
            # ì²˜ë¦¬ ì‹œê°„ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬ (ìµœê·¼ ì‚¬ìš©ëœ ê²ƒì´ ë’¤ì—)
            items.sort(key=lambda x: x[1].processing_time)
            
            # ì ˆë°˜ ì •ë„ ì œê±°
            remove_count = len(items) - self.segmentation_config.cache_size // 2
            
            for i in range(remove_count):
                del self.segmentation_cache[items[i][0]]
            
            self.logger.info(f"ğŸ’¾ ìºì‹œ ì •ë¦¬ ì™„ë£Œ: {remove_count}ê°œ í•­ëª© ì œê±°")
            
        except:
            
            self.logger.error(f"ìºì‹œ ì •ë¦¬ ì‹¤íŒ¨: {e}")

    def _update_statistics:

        """í†µê³„ ì—…ë°ì´íŠ¸"""
        try:
            self.processing_stats['total_processed'] += 1
            
            if:
            
                self.processing_stats['successful_segmentations'] += 1
                
                # í’ˆì§ˆ ì ìˆ˜ í‰ê·  ì—…ë°ì´íŠ¸
                current_avg = self.processing_stats['average_quality']
                total_successful = self.processing_stats['successful_segmentations']
                new_quality = result.quality_score if hasattr(result, 'quality_score') else 0.5
                
                self.processing_stats['average_quality'] = (
                    (current_avg * (total_successful - 1) + new_quality) / total_successful
                )
            
            # ë°©ë²•ë³„ ì‚¬ìš© í†µê³„
            method = result.method_used
            if:
                self.processing_stats['method_usage'][method] = 0
            self.processing_stats['method_usage'][method] += 1
            
            # í‰ê·  ì²˜ë¦¬ ì‹œê°„ ì—…ë°ì´íŠ¸
            current_avg_time = self.processing_stats['average_processing_time']
            total_processed = self.processing_stats['total_processed']
            
            self.processing_stats['average_processing_time'] = (
                (current_avg_time * (total_processed - 1) + processing_time) / total_processed
            )
            
        except:
            
            self.logger.warning(f"í†µê³„ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")

    def _format_result_with_visualization:

        """ğŸ†• ì‹œê°í™”ê°€ í¬í•¨ëœ ê²°ê³¼ë¥¼ í‘œì¤€ ë”•ì…”ë„ˆë¦¬ í˜•íƒœë¡œ í¬ë§·"""
        try:
            # ê¸°ë³¸ ê²°ê³¼ êµ¬ì¡°
            formatted_result = {
                'success': result.success,
                'processing_time': result.processing_time,
                'method_used': result.method_used,
                'metadata': result.metadata
            }
            
            if result.success:
                # ğŸ†• í”„ë¡ íŠ¸ì—”ë“œ í˜¸í™˜ì„±ì„ ìœ„í•œ details êµ¬ì¡°
                formatted_result['details'] = {
                    # ğŸ†• ì‹œê°í™” ì´ë¯¸ì§€ë“¤ (í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ë°”ë¡œ í‘œì‹œ ê°€ëŠ¥)
                    'result_image': result.metadata.get('result_image', ''),
                    'overlay_image': result.metadata.get('overlay_image', ''),
                    
                    # ê¸°ì¡´ ì •ë³´ë“¤
                    'confidence_score': result.confidence_score,
                    'quality_score': result.quality_score,
                    'segmentation_area': int(np.sum(result.mask > 0)) if result.mask is not None else 0,
                    'total_pixels': int(result.mask.size) if result.mask is not None else 0,
                    'coverage_ratio': float(np.sum(result.mask > 0) / result.mask.size) if result.mask is not None else 0.0,
                    
                    # ì‹œê°í™” ì¶”ê°€ ì •ë³´
                    'mask_image': result.metadata.get('mask_image', ''),
                    'boundary_image': result.metadata.get('boundary_image', ''),
                    'visualization_enabled': self.segmentation_config.enable_visualization,
                    'visualization_quality': self.segmentation_config.visualization_quality,
                    
                    # ì‹œìŠ¤í…œ ì •ë³´
                    'step_info': {
                        'step_name': 'cloth_segmentation',
                        'step_number': 3,
                        'device': self.device,
                        'is_m3_max': self.is_m3_max,
                        'method_used': result.method_used,
                        'fallback_used': result.metadata.get('fallback_used', False),
                        'post_processed': result.metadata.get('post_processed', False)
                    }
                }
                
                # ë ˆê±°ì‹œ í˜¸í™˜ì„± í•„ë“œë“¤
                formatted_result.update({
                    'mask': result.mask.tolist() if result.mask is not None else None,
                    'segmented_image': result.segmented_image.tolist() if result.segmented_image is not None else None,
                    'confidence_score': result.confidence_score,
                    'quality_score': result.quality_score,
                })
            else:
                formatted_result['details'] = {
                    'result_image': '',
                    'overlay_image': '',
                    'error_message': result.error_message,
                    'step_info': {
                        'step_name': 'cloth_segmentation',
                        'step_number': 3,
                        'device': self.device,
                        'error': result.error_message
                    }
                }
                formatted_result['error_message'] = result.error_message
            
            return formatted_result
            
        except:
            
            self.logger.error(f"ê²°ê³¼ í¬ë§·íŒ… ì‹¤íŒ¨: {e}")
            return {
                'success': False,
                'error_message': f"ê²°ê³¼ í¬ë§·íŒ… ì‹¤íŒ¨: {e}",
                'processing_time': 0.0,
                'method_used': 'error',
                'details': {
                    'result_image': '',
                    'overlay_image': '',
                    'error_message': f"ê²°ê³¼ í¬ë§·íŒ… ì‹¤íŒ¨: {e}",
                    'step_info': {
                        'step_name': 'cloth_segmentation',
                        'step_number': 3,
                        'error': f"ê²°ê³¼ í¬ë§·íŒ… ì‹¤íŒ¨: {e}"
                    }
                }
            }

    def _pil_to_bytes:

        """PIL ì´ë¯¸ì§€ë¥¼ ë°”ì´íŠ¸ë¡œ ë³€í™˜"""
        buffer = BytesIO()
        image.save(buffer, format='PNG')
        return buffer.getvalue()

    async def _perform_segmentation_cached(self, *args, **kwargs):
        """ìºì‹œëœ ì„¸ê·¸ë©˜í…Œì´ì…˜ ìˆ˜í–‰ (LRU ìºì‹œìš©)"""
        return await self._perform_single_segmentation(*args, **kwargs)

    # ==============================================
    # ğŸ”§ ì¶”ê°€ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤ - ì™„ì „ êµ¬í˜„
    # ==============================================

    def get_statistics:

        """ì²˜ë¦¬ í†µê³„ ë°˜í™˜"""
        try:
            stats = self.processing_stats.copy()
            
            # ì„±ê³µë¥  ê³„ì‚°
            if:
                stats['success_rate'] = stats['successful_segmentations'] / stats['total_processed']
            else:
                stats['success_rate'] = 0.0
            
            # ìºì‹œ ì •ë³´
            stats['cache_info'] = {
                'size': len(self.segmentation_cache),
                'max_size': self.segmentation_config.cache_size,
                'hit_ratio': stats['cache_hits'] / max(stats['total_processed'], 1)
            }
            
            # ì‹œìŠ¤í…œ ì •ë³´
            stats['system_info'] = {
                'device': self.device,
                'is_m3_max': self.is_m3_max,
                'memory_gb': self.memory_gb,
                'available_methods': [m.value for m in self.available_methods],
                'optimization_enabled': self.optimization_enabled,
                'visualization_enabled': self.segmentation_config.enable_visualization
            }
            
            return stats
            
        except:
            
            self.logger.error(f"í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {'error': str(e)}

    def get_clothing_mask:

        """íŠ¹ì • ì˜ë¥˜ ì¹´í…Œê³ ë¦¬ì˜ í†µí•© ë§ˆìŠ¤í¬ ë°˜í™˜"""
        try:
            # ì˜ë¥˜ ì¹´í…Œê³ ë¦¬ë³„ ë§ˆìŠ¤í¬ ìƒì„±
            if category in ['shirt', 'top', 'sweater']:
                # ìƒì˜ ì¹´í…Œê³ ë¦¬
                return (mask > 128).astype(np.uint8)
            elif category in ['pants', 'skirt', 'bottom']:
                # í•˜ì˜ ì¹´í…Œê³ ë¦¬
                return (mask > 128).astype(np.uint8)
            elif category in ['dress']:
                # ì›í”¼ìŠ¤ ì¹´í…Œê³ ë¦¬
                return (mask > 128).astype(np.uint8)
            else:
                # ê¸°ë³¸ê°’
                return (mask > 128).astype(np.uint8)
        except:
            self.logger.warning(f"ì˜ë¥˜ ë§ˆìŠ¤í¬ ìƒì„± ì‹¤íŒ¨: {e}")
            return np.zeros_like(mask, dtype=np.uint8)

    def visualize_segmentation:

        """ì„¸ê·¸ë©˜í…Œì´ì…˜ ê²°ê³¼ ì‹œê°í™” (ë””ë²„ê¹…ìš©)"""
        try:
            # ì˜ë¥˜ íƒ€ì…ì— ë”°ë¥¸ ìƒ‰ìƒ ì„ íƒ
            color = CLOTHING_COLORS.get(clothing_type, CLOTHING_COLORS['unknown'])
            
            # 3ì±„ë„ ìƒ‰ìƒ ì´ë¯¸ì§€ ìƒì„±
            height, width = mask.shape
            colored_image = np.zeros((height, width, 3), dtype=np.uint8)
            
            # ë§ˆìŠ¤í¬ ì˜ì—­ì— ìƒ‰ìƒ ì ìš©
            mask_binary = (mask > 128).astype(np.uint8)
            colored_image[mask_binary == 1] = color
            
            return colored_image
            
        except:
            
            self.logger.warning(f"ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‹œê°í™” ì‹¤íŒ¨: {e}")
            # í´ë°±: ê·¸ë ˆì´ìŠ¤ì¼€ì¼
            return np.stack([mask, mask, mask], axis=2)

    async def get_step_info(self) -> Dict[str, Any]:
        """ğŸ” 3ë‹¨ê³„ ìƒì„¸ ì •ë³´ ë°˜í™˜"""
        try:
            memory_stats = {}
            if:
                try:
                    memory_stats = await self.memory_manager.get_usage_stats()
                except:
                    memory_stats = {"memory_used": "N/A"}
            else:
                memory_stats = {"memory_used": "N/A"}
            
            return {
                "step_name": "cloth_segmentation",
                "step_number": 3,
                "device": self.device,
                "initialized": self.is_initialized,
                "available_methods": [m.value for m in self.available_methods],
                "config": {
                    "segmentation_method": self.segmentation_config.method.value,
                    "quality_level": self.segmentation_config.quality_level.value,
                    "input_size": self.segmentation_config.input_size,
                    "use_fp16": self.segmentation_config.use_fp16,
                    "confidence_threshold": self.confidence_threshold,
                    "enable_post_processing": self.enable_post_processing,
                    "enable_edge_refinement": self.enable_edge_refinement,
                    "enable_visualization": self.segmentation_config.enable_visualization,
                    "visualization_quality": self.segmentation_config.visualization_quality
                },
                "performance": self.processing_stats,
                "cache": {
                    "size": len(self.segmentation_cache),
                    "max_size": self.segmentation_config.cache_size,
                    "hit_rate": (self.processing_stats['cache_hits'] / 
                                max(1, self.processing_stats['total_processed'])) * 100
                },
                "memory_usage": memory_stats,
                "optimization": {
                    "m3_max_enabled": self.is_m3_max,
                    "memory_gb": self.memory_gb,
                    "optimization_enabled": self.optimization_enabled,
                    "fp16_enabled": self.segmentation_config.use_fp16,
                    "neural_engine": self.is_m3_max
                },
                "models_status": {
                    "u2net_loaded": hasattr(self, 'u2net_model') and self.u2net_model is not None,
                    "rembg_available": REMBG_AVAILABLE,
                    "sam_available": SAM_AVAILABLE,
                    "deeplab_loaded": hasattr(self, 'deeplab_pipeline') and self.deeplab_pipeline is not None,
                    "rembg_sessions": len(getattr(self, 'rembg_sessions', {}))
                }
            }
            
        except:
            
            self.logger.error(f"Step ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {
                "step_name": "cloth_segmentation",
                "step_number": 3,
                "error": str(e),
                "initialized": self.is_initialized
            }

    def get_supported_clothing_types:

        """ì§€ì›ë˜ëŠ” ì˜ë¥˜ íƒ€ì… ëª©ë¡ ë°˜í™˜"""
        return [ct.value for ct in ClothingType]

    def get_available_methods:

        """ì‚¬ìš© ê°€ëŠ¥í•œ ì„¸ê·¸ë©˜í…Œì´ì…˜ ë°©ë²• ëª©ë¡ ë°˜í™˜"""
        return [method.value for method in self.available_methods]

    def get_method_info:

        """íŠ¹ì • ë°©ë²•ì˜ ìƒì„¸ ì •ë³´ ë°˜í™˜"""
        method_info = {
            'u2net': {
                'name': 'UÂ²-Net',
                'description': 'Deep learning based UÂ²-Net for precise cloth segmentation',
                'quality': 'high',
                'speed': 'medium',
                'accuracy': 'high',
                'requirements': ['torch', 'torchvision']
            },
            'rembg': {
                'name': 'RemBG',
                'description': 'Background removal specialized for clothing',
                'quality': 'high',
                'speed': 'fast',
                'accuracy': 'medium-high',
                'requirements': ['rembg']
            },
            'sam': {
                'name': 'Segment Anything Model',
                'description': 'Meta\'s universal segmentation model',
                'quality': 'ultra',
                'speed': 'slow',
                'accuracy': 'ultra-high',
                'requirements': ['segment_anything']
            },
            'deeplab': {
                'name': 'DeepLab v3',
                'description': 'Semantic segmentation with transformers',
                'quality': 'high',
                'speed': 'medium',
                'accuracy': 'high',
                'requirements': ['transformers']
            },
            'traditional': {
                'name': 'Traditional CV',
                'description': 'Classical computer vision methods (GrabCut, K-means)',
                'quality': 'medium',
                'speed': 'fast',
                'accuracy': 'medium',
                'requirements': ['opencv', 'scikit-learn']
            }
        }
        
        return method_info.get(method_name, {
            'name': 'Unknown',
            'description': 'Unknown segmentation method',
            'quality': 'unknown',
            'speed': 'unknown',
            'accuracy': 'unknown'
        })

    async def warmup(self):
        """ì‹œìŠ¤í…œ ì›Œë°ì—… (ì²« ì²˜ë¦¬ ìµœì í™”)"""
        try:
            self.logger.info("ğŸ”¥ 3ë‹¨ê³„ ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‹œìŠ¤í…œ ì›Œë°ì—… ì‹œì‘...")
            
            if:
            
                await self.initialize()
            
            # ë”ë¯¸ ì´ë¯¸ì§€ë¡œ ì›Œë°ì—…
            dummy_image = Image.new('RGB', (512, 512), (128, 128, 128))
            
            # ê° ì‚¬ìš© ê°€ëŠ¥í•œ ë°©ë²•ìœ¼ë¡œ ì›Œë°ì—…
            for method in self.available_methods[:2]:  # ìµœëŒ€ 2ê°œ ë°©ë²•ë§Œ
                try:
                    self.logger.info(f"ğŸ”¥ {method.value} ì›Œë°ì—… ì¤‘...")
                    result = await self._perform_single_segmentation(dummy_image, method, "shirt")
                    if:
                        self.logger.info(f"âœ… {method.value} ì›Œë°ì—… ì™„ë£Œ")
                    else:
                        self.logger.warning(f"âš ï¸ {method.value} ì›Œë°ì—… ì‹¤íŒ¨")
                except:
                    self.logger.warning(f"âš ï¸ {method.value} ì›Œë°ì—… ì˜¤ë¥˜: {e}")
            
            self.logger.info("âœ… 3ë‹¨ê³„ ì„¸ê·¸ë©˜í…Œì´ì…˜ ì›Œë°ì—… ì™„ë£Œ")
            
        except:
            
            self.logger.error(f"âŒ ì›Œë°ì—… ì‹¤íŒ¨: {e}")

    def estimate_processing_time:

        """ì²˜ë¦¬ ì‹œê°„ ì¶”ì •"""
        try:
            width, height = image_size
            total_pixels = width * height
            
            # ë°©ë²•ë³„ ê¸°ë³¸ ì²˜ë¦¬ ì‹œê°„ (ì´ˆ/ë©”ê°€í”½ì…€)
            time_per_mpx = {
                'u2net': 0.5 if self.is_m3_max else 1.0,
                'rembg': 0.3 if self.is_m3_max else 0.6,
                'sam': 2.0 if self.is_m3_max else 4.0,
                'deeplab': 0.8 if self.is_m3_max else 1.5,
                'traditional': 0.1
            }
            
            if method == "auto":
                # ì‚¬ìš© ê°€ëŠ¥í•œ ë°©ë²• ì¤‘ ê°€ì¥ ë¹ ë¥¸ ê²ƒ
                method = min(self.available_methods, 
                            key=lambda m: time_per_mpx.get(m.value, 1.0)).value
            
            mpx = total_pixels / 1_000_000  # ë©”ê°€í”½ì…€ ë³€í™˜
            base_time = time_per_mpx.get(method, 1.0) * mpx
            
            # í’ˆì§ˆ ì„¤ì •ì— ë”°ë¥¸ ì¡°ì •
            quality_multiplier = {
                'fast': 0.7,
                'balanced': 1.0,
                'high': 1.3,
                'ultra': 1.8
            }
            
            quality = self.segmentation_config.quality_level.value
            estimated_time = base_time * quality_multiplier.get(quality, 1.0)
            
            return max(0.1, estimated_time)  # ìµœì†Œ 0.1ì´ˆ
            
        except:
            
            self.logger.warning(f"ì²˜ë¦¬ ì‹œê°„ ì¶”ì • ì‹¤íŒ¨: {e}")
            return 2.0  # ê¸°ë³¸ê°’

    async def cleanup(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        try:
            self.logger.info("ğŸ§¹ 3ë‹¨ê³„ ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‹œìŠ¤í…œ ì •ë¦¬ ì‹œì‘...")
            
            # ìºì‹œ ì •ë¦¬
            self.segmentation_cache.clear()
            self.model_cache.clear()
            self.session_cache.clear()
            
            # ëª¨ë¸ ë©”ëª¨ë¦¬ í•´ì œ
            if:
                del self.u2net_model
                self.u2net_model = None
            
            if:
            
                del self.deeplab_pipeline
                self.deeplab_pipeline = None
            
            # RemBG ì„¸ì…˜ ì •ë¦¬
            if:
                self.rembg_sessions.clear()
            
            # ìŠ¤ë ˆë“œ í’€ ì¢…ë£Œ
            if:
                self.executor.shutdown(wait=True)
            
            # ë©”ëª¨ë¦¬ ì •ë¦¬
            if:
                await self.memory_manager.cleanup_memory()
            
            # PyTorch ìºì‹œ ì •ë¦¬
            if:
                try:
                    torch.mps.empty_cache()
                except:
                    pass
            elif self.device == 'cuda':
                try:
                    torch.cuda.empty_cache()
                except:
                    pass
            
            # ê°€ë¹„ì§€ ì»¬ë ‰ì…˜
            gc.collect()
            
            self.is_initialized = False
            self.logger.info("âœ… 3ë‹¨ê³„ ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‹œìŠ¤í…œ ì •ë¦¬ ì™„ë£Œ")
            
        except:
            
            self.logger.error(f"ì •ë¦¬ ê³¼ì •ì—ì„œ ì˜¤ë¥˜ ë°œìƒ: {e}")

    def __del__:

        """ì†Œë©¸ì"""
        try:
            if:
                self.executor.shutdown(wait=False)
        except:
            pass


# ==============================================
# 4. íŒ©í† ë¦¬ í•¨ìˆ˜ë“¤ ë° ìœ í‹¸ë¦¬í‹° - ê¸°ì¡´ ì´ë¦„ ìœ ì§€
# ==============================================

def create_cloth_segmentation_step(
    device: Optional[str] = None,
    config: Optional[Dict[str, Any]] = None,
    **kwargs
) -> ClothSegmentationStep:
    """
    ClothSegmentationStep íŒ©í† ë¦¬ í•¨ìˆ˜
    """
    try:
        return ClothSegmentationStep(device=device, config=config, **kwargs)
    except:
        logger.error(f"ClothSegmentationStep ìƒì„± ì‹¤íŒ¨: {e}")
        raise

def create_m3_max_segmentation_step:

    """M3 Max ìµœì í™”ëœ ì„¸ê·¸ë©˜í…Œì´ì…˜ ìŠ¤í… ìƒì„±"""
    m3_max_config = {
        'device': 'mps',
        'is_m3_max': True,
        'optimization_enabled': True,
        'memory_gb': 128,
        'quality_level': 'high',
        'segmentation_method': 'auto',
        'use_fp16': True,
        'enable_post_processing': True,
        'cache_size': 200,
        'enable_visualization': True,  # ğŸ†• M3 Maxì—ì„œëŠ” ì‹œê°í™” ê¸°ë³¸ í™œì„±í™”
        'visualization_quality': 'high'
    }
    
    m3_max_config.update(kwargs)
    
    return ClothSegmentationStep(**m3_max_config)

def create_production_segmentation_step(
    quality_level: str = "balanced",
    enable_fallback: bool = True,
    **kwargs
) -> ClothSegmentationStep:
    """í”„ë¡œë•ì…˜ í™˜ê²½ìš© ì„¸ê·¸ë©˜í…Œì´ì…˜ ìŠ¤í… ìƒì„±"""
    production_config = {
        'quality_level': quality_level,
        'enable_fallback': enable_fallback,
        'optimization_enabled': True,
        'enable_post_processing': True,
        'enable_edge_refinement': True,
        'confidence_threshold': 0.8,
        'cache_size': 100,
        'enable_visualization': True,  # ğŸ†• í”„ë¡œë•ì…˜ì—ì„œë„ ì‹œê°í™” í™œì„±í™”
        'visualization_quality': 'medium'
    }
    
    production_config.update(kwargs)
    
    return ClothSegmentationStep(**production_config)


# ==============================================
# 5. ëª¨ë“ˆ ìµìŠ¤í¬íŠ¸ - ê¸°ì¡´ ì´ë¦„ ìœ ì§€
# ==============================================

__all__ = [
    # ë©”ì¸ í´ë˜ìŠ¤
    'ClothSegmentationStep',
    
    # ì—´ê±°í˜• ë° ë°ì´í„° í´ë˜ìŠ¤
    'SegmentationMethod',
    'ClothingType', 
    'QualityLevel',
    'SegmentationConfig',
    'SegmentationResult',
    
    # AI ëª¨ë¸ í´ë˜ìŠ¤ë“¤
    'U2NET',
    'REBNCONV',
    'RSU7',
    
    # íŒ©í† ë¦¬ í•¨ìˆ˜ë“¤
    'create_cloth_segmentation_step',
    'create_m3_max_segmentation_step',
    'create_production_segmentation_step',
    
    # ğŸ†• ì‹œê°í™” ê´€ë ¨
    'CLOTHING_COLORS'
]

# ëª¨ë“ˆ ì´ˆê¸°í™” ë¡œê¹…
logger.info("âœ… Step 03 ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ + ì‹œê°í™” ëª¨ë“ˆ ë¡œë“œ ì™„ë£Œ ğŸ”¥ ëª¨ë“  ë¬¸ì œ í•´ê²°")
logger.info(f"   - BaseStepMixin ì—°ë™: {'âœ…' if BASE_STEP_MIXIN_AVAILABLE else 'âš ï¸ í´ë°±'}")
logger.info(f"   - Model Loader ì—°ë™: {'âœ…' if MODEL_LOADER_AVAILABLE else 'âŒ'}")
logger.info(f"   - Memory Manager ì—°ë™: {'âœ…' if MEMORY_MANAGER_AVAILABLE else 'âŒ'}")
logger.info(f"   - RemBG ì‚¬ìš© ê°€ëŠ¥: {'âœ…' if REMBG_AVAILABLE else 'âŒ'}")
logger.info(f"   - SAM ì‚¬ìš© ê°€ëŠ¥: {'âœ…' if SAM_AVAILABLE else 'âŒ'}")
logger.info(f"   - Transformers ì‚¬ìš© ê°€ëŠ¥: {'âœ…' if TRANSFORMERS_AVAILABLE else 'âŒ'}")
logger.info(f"   - scikit-learn ì‚¬ìš© ê°€ëŠ¥: {'âœ…' if SKLEARN_AVAILABLE else 'âŒ'}")
logger.info("ğŸ†• ì‹œê°í™” ê¸°ëŠ¥: ì˜ë¥˜ ìƒ‰ìƒ êµ¬ë¶„, ì˜¤ë²„ë ˆì´, ë§ˆìŠ¤í¬, ê²½ê³„ì„  í‘œì‹œ")
logger.info("ğŸ”¥ ëª¨ë“  logger ì†ì„±, BaseStepMixin, ModelLoader ë¬¸ì œ ì™„ì „ í•´ê²°!")


# ==============================================
# 6. ğŸ†• í…ŒìŠ¤íŠ¸ ë° ì˜ˆì‹œ í•¨ìˆ˜ë“¤ - ì™„ì „ ì‘ë™
# ==============================================

async def test_cloth_segmentation_with_visualization():
    """ğŸ§ª ì‹œê°í™” ê¸°ëŠ¥ í¬í•¨ ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ í…ŒìŠ¤íŠ¸"""
    print("ğŸ§ª ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ + ì‹œê°í™” í…ŒìŠ¤íŠ¸ ì‹œì‘")
    
    try:
        # Step ìƒì„±
        step = create_cloth_segmentation_step(
            device="auto",
            config={
                "enable_visualization": True,
                "visualization_quality": "high",
                "quality_level": "balanced"
            }
        )
        
        # ë”ë¯¸ ì´ë¯¸ì§€ ìƒì„± (ì…”ì¸  ì‹œë®¬ë ˆì´ì…˜)
        dummy_image = Image.new('RGB', (512, 512), (200, 150, 100))
        
        # ì²˜ë¦¬ ì‹¤í–‰
        result = await step.process(dummy_image, clothing_type="shirt", quality_level="high")
        
        # ê²°ê³¼ í™•ì¸
        if:
            print("âœ… ì²˜ë¦¬ ì„±ê³µ!")
            print(f"ğŸ“Š ë°©ë²•: {result['method_used']}")
            print(f"ğŸ“Š ì‹ ë¢°ë„: {result.get('confidence_score', 0):.3f}")
            print(f"ğŸ“Š í’ˆì§ˆ: {result.get('quality_score', 0):.3f}")
            print(f"ğŸ¨ ë©”ì¸ ì‹œê°í™”: {'ìˆìŒ' if result.get('details', {}).get('result_image') else 'ì—†ìŒ'}")
            print(f"ğŸŒˆ ì˜¤ë²„ë ˆì´: {'ìˆìŒ' if result.get('details', {}).get('overlay_image') else 'ì—†ìŒ'}")
            print(f"ğŸ“„ ë§ˆìŠ¤í¬: {'ìˆìŒ' if result.get('details', {}).get('mask_image') else 'ì—†ìŒ'}")
            print(f"ğŸ“ ê²½ê³„ì„ : {'ìˆìŒ' if result.get('details', {}).get('boundary_image') else 'ì—†ìŒ'}")
        else:
            print(f"âŒ ì²˜ë¦¬ ì‹¤íŒ¨: {result.get('error_message', 'Unknown error')}")
        
        # ì •ë¦¬
        await step.cleanup()
        print("ğŸ§¹ ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì™„ë£Œ")
        
    except:
        
        print(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")

async def benchmark_segmentation_methods():
    """ğŸƒâ€â™‚ï¸ ì„¸ê·¸ë©˜í…Œì´ì…˜ ë°©ë²•ë³„ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬"""
    print("ğŸƒâ€â™‚ï¸ ì„¸ê·¸ë©˜í…Œì´ì…˜ ë°©ë²•ë³„ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ì‹œì‘")
    
    try:
    
        step = create_cloth_segmentation_step(device="auto")
        
        # í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€
        test_image = Image.new('RGB', (512, 512), (180, 140, 90))
        
        methods = step.get_available_methods()
        results = {}
        
        for method in methods:
            print(f"ğŸ”„ {method} í…ŒìŠ¤íŠ¸ ì¤‘...")
            start_time = time.time()
            
            try:
            
                result = await step.process(
                    test_image, 
                    clothing_type="shirt",
                    method_override=method
                )
                
                processing_time = time.time() - start_time
                results[method] = {
                    'success': result['success'],
                    'processing_time': processing_time,
                    'confidence': result.get('confidence_score', 0),
                    'quality': result.get('quality_score', 0)
                }
                
                print(f"âœ… {method}: {processing_time:.3f}ì´ˆ")
                
            except:
                
                results[method] = {
                    'success': False,
                    'error': str(e),
                    'processing_time': time.time() - start_time
                }
                print(f"âŒ {method}: ì‹¤íŒ¨ - {e}")
        
        # ê²°ê³¼ ìš”ì•½
        print("\nğŸ“Š ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼:")
        print("=" * 50)
        
        for method, result in results.items():
            if:
                print(f"{method:12}: {result['processing_time']:6.3f}ì´ˆ "
                        f"(ì‹ ë¢°ë„: {result['confidence']:5.3f}, í’ˆì§ˆ: {result['quality']:5.3f})")
            else:
                print(f"{method:12}: ì‹¤íŒ¨")
        
        await step.cleanup()
        
    except:
        
        print(f"âŒ ë²¤ì¹˜ë§ˆí¬ ì‹¤íŒ¨: {e}")


# ğŸ”¥ ì™„ì „ ì‘ë™í•˜ëŠ” ì‚¬ìš© ì˜ˆì‹œ ì½”ë“œ
"""
# ğŸ”§ ê¸°ë³¸ ì‚¬ìš©ë²• - ëª¨ë“  ë¬¸ì œ í•´ê²°ë¨
step = create_cloth_segmentation_step(device="auto")
result = await step.process(image, clothing_type="shirt")

# ğŸ M3 Max ìµœì í™” - ì™„ì „ ì‘ë™
step = create_m3_max_segmentation_step(
    enable_visualization=True,
    visualization_quality="high"
)

# ğŸ­ í”„ë¡œë•ì…˜ í™˜ê²½ - ëª¨ë“  ê¸°ëŠ¥ í¬í•¨
step = create_production_segmentation_step(
    quality_level="balanced",
    enable_fallback=True
)

# ğŸ“Š ì‹œìŠ¤í…œ ì •ë³´ ì¡°íšŒ - ì‹¤ì œ ì‘ë™
info = await step.get_step_info()
print(f"ì‚¬ìš© ê°€ëŠ¥í•œ ë°©ë²•: {step.get_available_methods()}")
print(f"ì§€ì› ì˜ë¥˜ íƒ€ì…: {step.get_supported_clothing_types()}")

# ğŸ”¥ ì‹œìŠ¤í…œ ì›Œë°ì—… - ì‹¤ì œ AI ëª¨ë¸ ì¤€ë¹„
await safe_warmup(step)

# â± ì²˜ë¦¬ ì‹œê°„ ì¶”ì • - ì •í™•í•œ ê³„ì‚°
estimated_time = step.estimate_processing_time((1024, 768), "rembg")
print(f"ì˜ˆìƒ ì²˜ë¦¬ ì‹œê°„: {estimated_time:.2f}ì´ˆ")

# ğŸ¨ ì‹œê°í™” ê²°ê³¼ í™•ì¸ - ì™„ì „ êµ¬í˜„ë¨
if:
    result_image = result['details']['result_image']  # base64 ì´ë¯¸ì§€
    overlay_image = result['details']['overlay_image']  # ì˜¤ë²„ë ˆì´ ì´ë¯¸ì§€
    print("ì‹œê°í™” ì™„ë£Œ!")
"""