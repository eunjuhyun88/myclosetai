# app/ai_pipeline/steps/step_03_cloth_segmentation.py
"""
MyCloset AI - 3ë‹¨ê³„: ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ (Clothing Segmentation)
ğŸ”¥ ì™„ì „ í†µí•© í”„ë¡œë•ì…˜ ë²„ì „ - M3 Max 128GB ìµœì í™”

âœ… í†µì¼ëœ ìƒì„±ì íŒ¨í„´ 100% ì ìš©
âœ… Model Loader + Memory Manager ì™„ì „ ì—°ë™  
âœ… Pipeline Manager ì™„ë²½ í˜¸í™˜
âœ… í”„ë¡œë•ì…˜ ë ˆë²¨ ì•ˆì •ì„± + ì„±ëŠ¥ ìµœì í™”
âœ… M3 Max Neural Engine + Metal Performance Shaders í™œìš©
âœ… ë‹¤ì¤‘ AI ëª¨ë¸ ì§€ì› (U2-Net, RemBG, SAM ë“±)
âœ… Graceful Degradation + ì™„ë²½í•œ ì—ëŸ¬ ì²˜ë¦¬
"""

import os
import sys
import logging
import time
import asyncio
import threading
import gc
import hashlib
import json
from typing import Dict, Any, Optional, Tuple, List, Union, Callable
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor, as_completed
from dataclasses import dataclass, field
from enum import Enum
import weakref

# í•µì‹¬ ë¼ì´ë¸ŒëŸ¬ë¦¬
import numpy as np
import cv2
from PIL import Image, ImageEnhance, ImageFilter, ImageOps
import torch
import torch.nn as nn
import torch.nn.functional as F
from torchvision import transforms

# ì„ íƒì  AI ë¼ì´ë¸ŒëŸ¬ë¦¬ë“¤
try:
    import rembg
    from rembg import remove, new_session
    REMBG_AVAILABLE = True
except ImportError:
    REMBG_AVAILABLE = False

try:
    from sklearn.cluster import KMeans
    from sklearn.preprocessing import StandardScaler
    SKLEARN_AVAILABLE = True
except ImportError:
    SKLEARN_AVAILABLE = False

try:
    import segment_anything as sam
    SAM_AVAILABLE = True
except ImportError:
    SAM_AVAILABLE = False

try:
    from transformers import pipeline
    TRANSFORMERS_AVAILABLE = True
except ImportError:
    TRANSFORMERS_AVAILABLE = False

# MyCloset AI í•µì‹¬ ìœ í‹¸ë¦¬í‹° ì—°ë™
try:
    from app.ai_pipeline.utils.model_loader import (
        BaseStepMixin, ModelLoader, ModelConfig, ModelType,
        get_global_model_loader, create_model_loader
    )
    MODEL_LOADER_AVAILABLE = True
except ImportError:
    MODEL_LOADER_AVAILABLE = False
    BaseStepMixin = object

try:
    from app.ai_pipeline.utils.memory_manager import (
        MemoryManager, get_global_memory_manager, optimize_memory_usage
    )
    MEMORY_MANAGER_AVAILABLE = True
except ImportError:
    MEMORY_MANAGER_AVAILABLE = False

try:
    from app.ai_pipeline.utils.data_converter import (
        DataConverter, get_global_data_converter
    )
    DATA_CONVERTER_AVAILABLE = True
except ImportError:
    DATA_CONVERTER_AVAILABLE = False

# ë¡œê¹… ì„¤ì •
logger = logging.getLogger(__name__)

# ==============================================
# 1. ì—´ê±°í˜• ë° ë°ì´í„° í´ë˜ìŠ¤ ì •ì˜
# ==============================================

class SegmentationMethod(Enum):
    """ì„¸ê·¸ë©˜í…Œì´ì…˜ ë°©ë²•"""
    U2NET = "u2net"
    REMBG = "rembg"
    SAM = "sam"
    DEEP_LAB = "deeplab"
    MASK_RCNN = "mask_rcnn"
    TRADITIONAL = "traditional"
    HYBRID = "hybrid"
    AUTO = "auto"

class ClothingType(Enum):
    """ì˜ë¥˜ íƒ€ì…"""
    SHIRT = "shirt"
    DRESS = "dress"
    PANTS = "pants"
    SKIRT = "skirt"
    JACKET = "jacket"
    SWEATER = "sweater"
    COAT = "coat"
    TOP = "top"
    BOTTOM = "bottom"
    UNKNOWN = "unknown"

class QualityLevel(Enum):
    """í’ˆì§ˆ ë ˆë²¨"""
    FAST = "fast"
    BALANCED = "balanced"
    HIGH = "high"
    ULTRA = "ultra"

@dataclass
class SegmentationConfig:
    """ì„¸ê·¸ë©˜í…Œì´ì…˜ ì„¤ì •"""
    method: SegmentationMethod = SegmentationMethod.AUTO
    quality_level: QualityLevel = QualityLevel.BALANCED
    input_size: Tuple[int, int] = (512, 512)
    output_size: Optional[Tuple[int, int]] = None
    enable_post_processing: bool = True
    enable_edge_refinement: bool = True
    enable_hole_filling: bool = True
    confidence_threshold: float = 0.8
    iou_threshold: float = 0.5
    batch_size: int = 1
    use_fp16: bool = True
    enable_caching: bool = True
    cache_size: int = 100

@dataclass
class SegmentationResult:
    """ì„¸ê·¸ë©˜í…Œì´ì…˜ ê²°ê³¼"""
    success: bool
    mask: Optional[np.ndarray] = None
    segmented_image: Optional[np.ndarray] = None
    confidence_score: float = 0.0
    quality_score: float = 0.0
    method_used: str = "unknown"
    processing_time: float = 0.0
    metadata: Dict[str, Any] = field(default_factory=dict)
    error_message: Optional[str] = None

# ==============================================
# 2. U2-Net ëª¨ë¸ ì •ì˜ (í”„ë¡œë•ì…˜ ìµœì í™”)
# ==============================================

class REBNCONV(nn.Module):
    """U2-Netì˜ ê¸°ë³¸ ì»¨ë³¼ë£¨ì…˜ ë¸”ë¡"""
    def __init__(self, in_ch=3, out_ch=3, dirate=1):
        super(REBNCONV, self).__init__()
        self.conv_s1 = nn.Conv2d(in_ch, out_ch, 3, padding=1*dirate, dilation=1*dirate)
        self.bn_s1 = nn.BatchNorm2d(out_ch)
        self.relu_s1 = nn.ReLU(inplace=True)
    
    def forward(self, x):
        hx = self.relu_s1(self.bn_s1(self.conv_s1(x)))
        return hx

class RSU7(nn.Module):
    """U2-Net RSU-7 ë¸”ë¡"""
    def __init__(self, in_ch=3, mid_ch=12, out_ch=3):
        super(RSU7, self).__init__()
        self.rebnconvin = REBNCONV(in_ch, out_ch, dirate=1)
        
        self.rebnconv1 = REBNCONV(out_ch, mid_ch, dirate=1)
        self.pool1 = nn.MaxPool2d(2, stride=2, ceil_mode=True)
        
        self.rebnconv2 = REBNCONV(mid_ch, mid_ch, dirate=1)
        self.pool2 = nn.MaxPool2d(2, stride=2, ceil_mode=True)
        
        self.rebnconv3 = REBNCONV(mid_ch, mid_ch, dirate=1)
        self.pool3 = nn.MaxPool2d(2, stride=2, ceil_mode=True)
        
        self.rebnconv4 = REBNCONV(mid_ch, mid_ch, dirate=1)
        self.pool4 = nn.MaxPool2d(2, stride=2, ceil_mode=True)
        
        self.rebnconv5 = REBNCONV(mid_ch, mid_ch, dirate=1)
        self.pool5 = nn.MaxPool2d(2, stride=2, ceil_mode=True)
        
        self.rebnconv6 = REBNCONV(mid_ch, mid_ch, dirate=1)
        self.rebnconv7 = REBNCONV(mid_ch, mid_ch, dirate=2)
        
        self.rebnconv6d = REBNCONV(mid_ch*2, mid_ch, dirate=1)
        self.upsample6 = nn.Upsample(scale_factor=2, mode='bilinear')
        
        self.rebnconv5d = REBNCONV(mid_ch*2, mid_ch, dirate=1)
        self.upsample5 = nn.Upsample(scale_factor=2, mode='bilinear')
        
        self.rebnconv4d = REBNCONV(mid_ch*2, mid_ch, dirate=1)
        self.upsample4 = nn.Upsample(scale_factor=2, mode='bilinear')
        
        self.rebnconv3d = REBNCONV(mid_ch*2, mid_ch, dirate=1)
        self.upsample3 = nn.Upsample(scale_factor=2, mode='bilinear')
        
        self.rebnconv2d = REBNCONV(mid_ch*2, mid_ch, dirate=1)
        self.upsample2 = nn.Upsample(scale_factor=2, mode='bilinear')
        
        self.rebnconv1d = REBNCONV(mid_ch*2, out_ch, dirate=1)
    
    def forward(self, x):
        hx = x
        hxin = self.rebnconvin(hx)
        
        hx1 = self.rebnconv1(hxin)
        hx = self.pool1(hx1)
        
        hx2 = self.rebnconv2(hx)
        hx = self.pool2(hx2)
        
        hx3 = self.rebnconv3(hx)
        hx = self.pool3(hx3)
        
        hx4 = self.rebnconv4(hx)
        hx = self.pool4(hx4)
        
        hx5 = self.rebnconv5(hx)
        hx = self.pool5(hx5)
        
        hx6 = self.rebnconv6(hx)
        hx7 = self.rebnconv7(hx6)
        
        hx6d = self.rebnconv6d(torch.cat((hx7, hx6), 1))
        hx6dup = self.upsample6(hx6d)
        
        hx5d = self.rebnconv5d(torch.cat((hx6dup, hx5), 1))
        hx5dup = self.upsample5(hx5d)
        
        hx4d = self.rebnconv4d(torch.cat((hx5dup, hx4), 1))
        hx4dup = self.upsample4(hx4d)
        
        hx3d = self.rebnconv3d(torch.cat((hx4dup, hx3), 1))
        hx3dup = self.upsample3(hx3d)
        
        hx2d = self.rebnconv2d(torch.cat((hx3dup, hx2), 1))
        hx2dup = self.upsample2(hx2d)
        
        hx1d = self.rebnconv1d(torch.cat((hx2dup, hx1), 1))
        
        return hx1d + hxin

class U2NET(nn.Module):
    """U2-Net ë©”ì¸ ëª¨ë¸ (ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ ìµœì í™”)"""
    def __init__(self, in_ch=3, out_ch=1):
        super(U2NET, self).__init__()
        
        self.stage1 = RSU7(in_ch, 32, 64)
        self.pool12 = nn.MaxPool2d(2, stride=2, ceil_mode=True)
        
        self.stage2 = RSU7(64, 32, 128)
        self.pool23 = nn.MaxPool2d(2, stride=2, ceil_mode=True)
        
        self.stage3 = RSU7(128, 64, 256)
        self.pool34 = nn.MaxPool2d(2, stride=2, ceil_mode=True)
        
        self.stage4 = RSU7(256, 128, 512)
        self.pool45 = nn.MaxPool2d(2, stride=2, ceil_mode=True)
        
        self.stage5 = RSU7(512, 256, 512)
        self.pool56 = nn.MaxPool2d(2, stride=2, ceil_mode=True)
        
        self.stage6 = RSU7(512, 256, 512)
        
        # ë””ì½”ë”
        self.stage5d = RSU7(1024, 256, 512)
        self.stage4d = RSU7(1024, 128, 256)
        self.stage3d = RSU7(512, 64, 128)
        self.stage2d = RSU7(256, 32, 64)
        self.stage1d = RSU7(128, 16, 64)
        
        self.side1 = nn.Conv2d(64, out_ch, 3, padding=1)
        self.side2 = nn.Conv2d(64, out_ch, 3, padding=1)
        self.side3 = nn.Conv2d(128, out_ch, 3, padding=1)
        self.side4 = nn.Conv2d(256, out_ch, 3, padding=1)
        self.side5 = nn.Conv2d(512, out_ch, 3, padding=1)
        self.side6 = nn.Conv2d(512, out_ch, 3, padding=1)
        
        self.outconv = nn.Conv2d(6*out_ch, out_ch, 1)
        
        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear')
    
    def forward(self, x):
        hx = x
        
        # ì¸ì½”ë”
        hx1 = self.stage1(hx)
        hx = self.pool12(hx1)
        
        hx2 = self.stage2(hx)
        hx = self.pool23(hx2)
        
        hx3 = self.stage3(hx)
        hx = self.pool34(hx3)
        
        hx4 = self.stage4(hx)
        hx = self.pool45(hx4)
        
        hx5 = self.stage5(hx)
        hx = self.pool56(hx5)
        
        hx6 = self.stage6(hx)
        hx6up = self.upsample(hx6)
        
        # ë””ì½”ë”
        hx5d = self.stage5d(torch.cat((hx6up, hx5), 1))
        hx5dup = self.upsample(hx5d)
        
        hx4d = self.stage4d(torch.cat((hx5dup, hx4), 1))
        hx4dup = self.upsample(hx4d)
        
        hx3d = self.stage3d(torch.cat((hx4dup, hx3), 1))
        hx3dup = self.upsample(hx3d)
        
        hx2d = self.stage2d(torch.cat((hx3dup, hx2), 1))
        hx2dup = self.upsample(hx2d)
        
        hx1d = self.stage1d(torch.cat((hx2dup, hx1), 1))
        
        # ì‚¬ì´ë“œ ì¶œë ¥
        side1 = self.side1(hx1d)
        
        side2 = self.side2(hx2d)
        side2 = F.interpolate(side2, size=side1.shape[2:], mode='bilinear')
        
        side3 = self.side3(hx3d)
        side3 = F.interpolate(side3, size=side1.shape[2:], mode='bilinear')
        
        side4 = self.side4(hx4d)
        side4 = F.interpolate(side4, size=side1.shape[2:], mode='bilinear')
        
        side5 = self.side5(hx5d)
        side5 = F.interpolate(side5, size=side1.shape[2:], mode='bilinear')
        
        side6 = self.side6(hx6)
        side6 = F.interpolate(side6, size=side1.shape[2:], mode='bilinear')
        
        out = self.outconv(torch.cat((side1, side2, side3, side4, side5, side6), 1))
        
        return torch.sigmoid(out), torch.sigmoid(side1), torch.sigmoid(side2), \
               torch.sigmoid(side3), torch.sigmoid(side4), torch.sigmoid(side5), torch.sigmoid(side6)

# ==============================================
# 3. ë©”ì¸ ClothSegmentationStep í´ë˜ìŠ¤
# ==============================================

class ClothSegmentationStep(BaseStepMixin):
    """
    3ë‹¨ê³„: ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ - ì™„ì „ í†µí•© í”„ë¡œë•ì…˜ ë²„ì „
    
    âœ… í†µì¼ëœ ìƒì„±ì íŒ¨í„´ ì ìš©
    âœ… Model Loader + Memory Manager ì™„ì „ ì—°ë™
    âœ… Pipeline Manager 100% í˜¸í™˜
    âœ… M3 Max 128GB ìµœì í™”
    âœ… ë‹¤ì¤‘ AI ëª¨ë¸ ì§€ì›
    âœ… Graceful Degradation
    """
    
    def __init__(
        self,
        device: Optional[str] = None,
        config: Optional[Dict[str, Any]] = None,
        **kwargs
    ):
        """âœ… ì™„ì „ í†µí•© ìƒì„±ì - í†µì¼ëœ íŒ¨í„´ ì ìš©"""
        
        # === 1. í†µì¼ëœ ê¸°ë³¸ ì´ˆê¸°í™” ===
        self.device = self._auto_detect_device(device)
        self.config = config or {}
        self.step_name = self.__class__.__name__
        self.logger = logging.getLogger(f"pipeline.{self.step_name}")
        
        # === 2. í‘œì¤€ ì‹œìŠ¤í…œ íŒŒë¼ë¯¸í„° ===
        self.device_type = kwargs.get('device_type', 'auto')
        self.memory_gb = kwargs.get('memory_gb', 16.0)
        self.is_m3_max = kwargs.get('is_m3_max', self._detect_m3_max())
        self.optimization_enabled = kwargs.get('optimization_enabled', True)
        self.quality_level = kwargs.get('quality_level', 'balanced')
        
        # === 3. Stepë³„ ì„¤ì • ë³‘í•© ===
        self._merge_step_specific_config(kwargs)
        
        # === 4. ì´ˆê¸°í™” ìƒíƒœ ===
        self.is_initialized = False
        self._initialization_lock = threading.RLock()
        
        # === 5. Model Loader ì—°ë™ (BaseStepMixin) ===
        if MODEL_LOADER_AVAILABLE:
            try:
                self._setup_model_interface()
            except Exception as e:
                self.logger.warning(f"Model Loader ì—°ë™ ì‹¤íŒ¨: {e}")
                self.model_interface = None
        else:
            self.model_interface = None
        
        # === 6. Step íŠ¹í™” ì´ˆê¸°í™” ===
        self._initialize_step_specific()
        
        # === 7. ì´ˆê¸°í™” ì™„ë£Œ ë¡œê¹… ===
        self.logger.info(f"ğŸ¯ {self.step_name} ì´ˆê¸°í™” ì™„ë£Œ - ë””ë°”ì´ìŠ¤: {self.device}")
        if self.is_m3_max:
            self.logger.info(f"ğŸ M3 Max ìµœì í™” ëª¨ë“œ (ë©”ëª¨ë¦¬: {self.memory_gb}GB)")
    
    def _auto_detect_device(self, preferred_device: Optional[str]) -> str:
        """ğŸ’¡ ì§€ëŠ¥ì  ë””ë°”ì´ìŠ¤ ìë™ ê°ì§€"""
        if preferred_device:
            return preferred_device

        try:
            import torch
            if torch.backends.mps.is_available():
                return 'mps'  # M3 Max ìš°ì„ 
            elif torch.cuda.is_available():
                return 'cuda'  # NVIDIA GPU
            else:
                return 'cpu'  # í´ë°±
        except ImportError:
            return 'cpu'

    def _detect_m3_max(self) -> bool:
        """ğŸ M3 Max ì¹© ìë™ ê°ì§€"""
        try:
            import platform
            import subprocess

            if platform.system() == 'Darwin':  # macOS
                result = subprocess.run(['sysctl', '-n', 'machdep.cpu.brand_string'], 
                                      capture_output=True, text=True)
                cpu_info = result.stdout.strip()
                return 'M3 Max' in cpu_info or 'M3' in cpu_info
        except:
            pass
        return False

    def _merge_step_specific_config(self, kwargs: Dict[str, Any]):
        """3ë‹¨ê³„ íŠ¹í™” ì„¤ì • ë³‘í•©"""
        
        # ì„¸ê·¸ë©˜í…Œì´ì…˜ ì„¤ì •
        self.segmentation_config = SegmentationConfig()
        
        # ì„¤ì • ì—…ë°ì´íŠ¸
        if 'segmentation_method' in kwargs:
            self.segmentation_config.method = SegmentationMethod(kwargs['segmentation_method'])
        
        if 'input_size' in kwargs:
            self.segmentation_config.input_size = kwargs['input_size']
        
        if 'quality_level' in self.config:
            self.segmentation_config.quality_level = QualityLevel(self.config['quality_level'])
        
        # M3 Max íŠ¹í™” ì„¤ì •
        if self.is_m3_max:
            self.segmentation_config.use_fp16 = True
            self.segmentation_config.batch_size = min(8, max(1, int(self.memory_gb / 16)))
            self.segmentation_config.cache_size = min(200, max(50, int(self.memory_gb * 2)))
        
        # ì¶”ê°€ ì„¤ì •ë“¤
        self.enable_post_processing = kwargs.get('enable_post_processing', True)
        self.enable_edge_refinement = kwargs.get('enable_edge_refinement', True)
        self.confidence_threshold = kwargs.get('confidence_threshold', 0.8)

    def _initialize_step_specific(self):
        """3ë‹¨ê³„ íŠ¹í™” ì´ˆê¸°í™”"""
        
        # ìºì‹œ ë° ìƒíƒœ ê´€ë¦¬
        self.segmentation_cache: Dict[str, SegmentationResult] = {}
        self.model_cache: Dict[str, Any] = {}
        self.session_cache: Dict[str, Any] = {}
        
        # ì„±ëŠ¥ í†µê³„
        self.processing_stats = {
            'total_processed': 0,
            'successful_segmentations': 0,
            'average_quality': 0.0,
            'method_usage': {},
            'cache_hits': 0,
            'average_processing_time': 0.0
        }
        
        # ìŠ¤ë ˆë“œ í’€ (M3 Max ìµœì í™”)
        max_workers = 4 if self.is_m3_max else 2
        self.executor = ThreadPoolExecutor(
            max_workers=max_workers,
            thread_name_prefix=f"{self.step_name}_worker"
        )
        
        # ë©”ëª¨ë¦¬ ê´€ë¦¬
        if MEMORY_MANAGER_AVAILABLE:
            try:
                self.memory_manager = get_global_memory_manager()
                if not self.memory_manager:
                    from app.ai_pipeline.utils.memory_manager import create_memory_manager
                    self.memory_manager = create_memory_manager(device=self.device)
            except Exception as e:
                self.logger.warning(f"Memory Manager ì—°ë™ ì‹¤íŒ¨: {e}")
                self.memory_manager = None
        else:
            self.memory_manager = None
        
        # ë°ì´í„° ë³€í™˜ê¸°
        if DATA_CONVERTER_AVAILABLE:
            try:
                self.data_converter = get_global_data_converter()
            except Exception as e:
                self.logger.warning(f"Data Converter ì—°ë™ ì‹¤íŒ¨: {e}")
                self.data_converter = None
        else:
            self.data_converter = None
        
        # ëª¨ë¸ ê²½ë¡œ ì„¤ì •
        self.model_base_path = Path("backend/app/ai_pipeline/models/ai_models")
        self.checkpoint_path = self.model_base_path / "checkpoints" / "step_03_cloth_segmentation"
        self.checkpoint_path.mkdir(parents=True, exist_ok=True)
        
        # ì§€ì›ë˜ëŠ” ë°©ë²•ë“¤ ì´ˆê¸°í™”
        self.available_methods = self._detect_available_methods()
        
        self.logger.info(f"ğŸ“¦ 3ë‹¨ê³„ íŠ¹í™” ì´ˆê¸°í™” ì™„ë£Œ - ì‚¬ìš© ê°€ëŠ¥í•œ ë°©ë²•: {len(self.available_methods)}ê°œ")

    def _detect_available_methods(self) -> List[SegmentationMethod]:
        """ì‚¬ìš© ê°€ëŠ¥í•œ ì„¸ê·¸ë©˜í…Œì´ì…˜ ë°©ë²• ê°ì§€"""
        methods = []
        
        # í•­ìƒ ì‚¬ìš© ê°€ëŠ¥í•œ ì „í†µì  ë°©ë²•
        methods.append(SegmentationMethod.TRADITIONAL)
        
        # RemBG í™•ì¸
        if REMBG_AVAILABLE:
            methods.append(SegmentationMethod.REMBG)
            self.logger.info("âœ… RemBG ì‚¬ìš© ê°€ëŠ¥")
        
        # SAM í™•ì¸
        if SAM_AVAILABLE:
            methods.append(SegmentationMethod.SAM)
            self.logger.info("âœ… SAM ì‚¬ìš© ê°€ëŠ¥")
        
        # U2-Net (Model Loader í†µí•´ í™•ì¸)
        if self.model_interface:
            methods.append(SegmentationMethod.U2NET)
            self.logger.info("âœ… U2-Net ì‚¬ìš© ê°€ëŠ¥ (Model Loader)")
        
        # Transformers ê¸°ë°˜ ëª¨ë¸
        if TRANSFORMERS_AVAILABLE:
            methods.append(SegmentationMethod.DEEP_LAB)
            self.logger.info("âœ… DeepLab ì‚¬ìš© ê°€ëŠ¥")
        
        return methods

    async def initialize(self) -> bool:
        """
        âœ… í†µì¼ëœ ì´ˆê¸°í™” ì¸í„°í˜ì´ìŠ¤ - Pipeline Manager í˜¸í™˜
        
        Returns:
            bool: ì´ˆê¸°í™” ì„±ê³µ ì—¬ë¶€
        """
        async with asyncio.Lock():
            if self.is_initialized:
                return True
        
        try:
            self.logger.info("ğŸ”„ 3ë‹¨ê³„: ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...")
            
            # 1. AI ëª¨ë¸ë“¤ ì´ˆê¸°í™”
            await self._initialize_ai_models()
            
            # 2. RemBG ì„¸ì…˜ ì´ˆê¸°í™”
            if REMBG_AVAILABLE:
                await self._initialize_rembg_sessions()
            
            # 3. ì „í†µì  ë°©ë²•ë“¤ ì´ˆê¸°í™”
            self._initialize_traditional_methods()
            
            # 4. M3 Max ìµœì í™” ì›Œë°ì—…
            if self.is_m3_max and self.optimization_enabled:
                await self._warmup_m3_max()
            
            # 5. ìºì‹œ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
            self._initialize_cache_system()
            
            self.is_initialized = True
            self.logger.info("âœ… ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
            
            return True
            
        except Exception as e:
            error_msg = f"ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}"
            self.logger.error(f"âŒ {error_msg}")
            
            # ìµœì†Œí•œì˜ í´ë°± ì‹œìŠ¤í…œ ì´ˆê¸°í™”
            self._initialize_fallback_system()
            self.is_initialized = True
            
            return True  # Graceful degradation

    async def _initialize_ai_models(self):
        """AI ëª¨ë¸ë“¤ ì´ˆê¸°í™” (Model Loader í™œìš©)"""
        try:
            if not self.model_interface:
                self.logger.warning("Model Loader ì¸í„°í˜ì´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤. ëŒ€ì•ˆ ë°©ë²• ì‚¬ìš©.")
                return
            
            # U2-Net ëª¨ë¸ ë¡œë“œ
            u2net_config = {
                'model_name': 'u2net_cloth_seg',
                'model_class': U2NET,
                'checkpoint_path': str(self.checkpoint_path / "u2net_cloth.pth"),
                'input_size': self.segmentation_config.input_size,
                'device': self.device,
                'use_fp16': self.segmentation_config.use_fp16
            }
            
            # Model Loaderë¥¼ í†µí•œ ë¡œë“œ ì‹œë„
            try:
                self.u2net_model = await self.model_interface.load_model_async('u2net_cloth_seg', u2net_config)
                self.logger.info("âœ… U2-Net ëª¨ë¸ ë¡œë“œ ì„±ê³µ (Model Loader)")
            except Exception as e:
                self.logger.warning(f"Model Loaderë¥¼ í†µí•œ U2-Net ë¡œë“œ ì‹¤íŒ¨: {e}")
                # ì§ì ‘ ë¡œë“œ ì‹œë„
                await self._load_u2net_direct()
            
            # ì¶”ê°€ ëª¨ë¸ë“¤ (DeepLab, Mask R-CNN ë“±)
            if TRANSFORMERS_AVAILABLE:
                await self._initialize_transformer_models()
                
        except Exception as e:
            self.logger.error(f"AI ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")

    async def _load_u2net_direct(self):
        """U2-Net ì§ì ‘ ë¡œë“œ (Model Loader ì—†ì´)"""
        try:
            self.u2net_model = U2NET(in_ch=3, out_ch=1)
            
            # ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ ì‹œë„
            checkpoint_path = self.checkpoint_path / "u2net_cloth.pth"
            if checkpoint_path.exists():
                state_dict = torch.load(checkpoint_path, map_location=self.device)
                self.u2net_model.load_state_dict(state_dict)
                self.logger.info("âœ… U2-Net ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ ì„±ê³µ")
            else:
                self.logger.warning("U2-Net ì²´í¬í¬ì¸íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤. ì‚¬ì „ í›ˆë ¨ë˜ì§€ ì•Šì€ ëª¨ë¸ ì‚¬ìš©.")
            
            # ë””ë°”ì´ìŠ¤ ì´ë™ ë° eval ëª¨ë“œ
            self.u2net_model.to(self.device)
            self.u2net_model.eval()
            
            # FP16 ìµœì í™” (M3 Max)
            if self.segmentation_config.use_fp16 and self.device != 'cpu':
                self.u2net_model = self.u2net_model.half()
            
        except Exception as e:
            self.logger.error(f"U2-Net ì§ì ‘ ë¡œë“œ ì‹¤íŒ¨: {e}")
            self.u2net_model = None

    async def _initialize_transformer_models(self):
        """Transformers ê¸°ë°˜ ëª¨ë¸ ì´ˆê¸°í™”"""
        try:
            # DeepLab v3 ì´ˆê¸°í™”
            self.deeplab_pipeline = pipeline(
                "image-segmentation",
                model="facebook/detr-resnet-50-panoptic",
                device=0 if self.device == 'cuda' else -1
            )
            self.logger.info("âœ… DeepLab íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” ì™„ë£Œ")
            
        except Exception as e:
            self.logger.warning(f"Transformer ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.deeplab_pipeline = None

    async def _initialize_rembg_sessions(self):
        """RemBG ì„¸ì…˜ë“¤ ì´ˆê¸°í™”"""
        try:
            if not REMBG_AVAILABLE:
                return
            
            # ë‹¤ì–‘í•œ RemBG ëª¨ë¸ ì„¸ì…˜ ìƒì„±
            session_configs = {
                'u2net': 'u2net',
                'u2netp': 'u2netp', 
                'silueta': 'silueta',
                'cloth': 'u2net_cloth_seg'
            }
            
            self.rembg_sessions = {}
            
            for name, model_name in session_configs.items():
                try:
                    session = new_session(model_name)
                    self.rembg_sessions[name] = session
                    self.logger.info(f"âœ… RemBG ì„¸ì…˜ ìƒì„±: {name}")
                except Exception as e:
                    self.logger.warning(f"RemBG ì„¸ì…˜ {name} ìƒì„± ì‹¤íŒ¨: {e}")
            
            # ê¸°ë³¸ ì„¸ì…˜ ì„¤ì •
            if self.rembg_sessions:
                self.default_rembg_session = list(self.rembg_sessions.values())[0]
            else:
                self.default_rembg_session = None
                
        except Exception as e:
            self.logger.error(f"RemBG ì„¸ì…˜ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.rembg_sessions = {}
            self.default_rembg_session = None

    def _initialize_traditional_methods(self):
        """ì „í†µì  ì»´í“¨í„° ë¹„ì „ ë°©ë²•ë“¤ ì´ˆê¸°í™”"""
        try:
            # GrabCut ì•Œê³ ë¦¬ì¦˜ ì„¤ì •
            self.grabcut_config = {
                'iterations': 5,
                'margin': 10
            }
            
            # K-means í´ëŸ¬ìŠ¤í„°ë§ ì„¤ì • (scikit-learn ì‚¬ìš© ê°€ëŠ¥ ì‹œ)
            if SKLEARN_AVAILABLE:
                self.kmeans_config = {
                    'n_clusters': 2,
                    'random_state': 42,
                    'max_iter': 100
                }
            
            # ì„ê³„ê°’ ê¸°ë°˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ ì„¤ì •
            self.threshold_config = {
                'method': cv2.THRESH_OTSU,
                'blur_kernel': (5, 5),
                'morph_kernel': np.ones((3, 3), np.uint8)
            }
            
            self.logger.info("âœ… ì „í†µì  ë°©ë²•ë“¤ ì´ˆê¸°í™” ì™„ë£Œ")
            
        except Exception as e:
            self.logger.error(f"ì „í†µì  ë°©ë²• ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")

    async def _warmup_m3_max(self):
        """M3 Max ìµœì í™” ì›Œë°ì—…"""
        try:
            if not self.is_m3_max:
                return
            
            self.logger.info("ğŸ M3 Max ìµœì í™” ì›Œë°ì—… ì‹œì‘...")
            
            # ë”ë¯¸ í…ì„œë¡œ GPU ì›Œë°ì—…
            dummy_input = torch.randn(1, 3, 256, 256).to(self.device)
            
            if hasattr(self, 'u2net_model') and self.u2net_model:
                with torch.no_grad():
                    _ = self.u2net_model(dummy_input)
                self.logger.info("âœ… U2-Net M3 Max ì›Œë°ì—… ì™„ë£Œ")
            
            # MPS ìºì‹œ ìµœì í™”
            if self.device == 'mps':
                try:
                    if hasattr(torch.mps, 'empty_cache'):
                        torch.mps.empty_cache()
                except:
                    pass
            
            # ë©”ëª¨ë¦¬ ìµœì í™”
            if self.memory_manager:
                await self.memory_manager.optimize_for_m3_max()
            
            self.logger.info("ğŸ M3 Max ì›Œë°ì—… ì™„ë£Œ")
            
        except Exception as e:
            self.logger.warning(f"M3 Max ì›Œë°ì—… ì‹¤íŒ¨: {e}")

    def _initialize_cache_system(self):
        """ìºì‹œ ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
        try:
            # ìºì‹œ í¬ê¸° ì„¤ì • (M3 Max ìµœì í™”)
            cache_size = self.segmentation_config.cache_size
            
            # LRU ìºì‹œë¡œ ë³€í™˜
            from functools import lru_cache
            self._cached_segmentation = lru_cache(maxsize=cache_size)(self._perform_segmentation_cached)
            
            self.logger.info(f"ğŸ’¾ ìºì‹œ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ (í¬ê¸°: {cache_size})")
            
        except Exception as e:
            self.logger.error(f"ìºì‹œ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")

    def _initialize_fallback_system(self):
        """ìµœì†Œí•œì˜ í´ë°± ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
        try:
            # ê°€ì¥ ê¸°ë³¸ì ì¸ ë°©ë²•ë“¤ë§Œ í™œì„±í™”
            self.available_methods = [SegmentationMethod.TRADITIONAL]
            
            if REMBG_AVAILABLE:
                self.available_methods.append(SegmentationMethod.REMBG)
                self.default_rembg_session = new_session('u2net')
            
            self.logger.info("âš ï¸ í´ë°± ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
            
        except Exception as e:
            self.logger.error(f"í´ë°± ì‹œìŠ¤í…œ ì´ˆê¸°í™”ë„ ì‹¤íŒ¨: {e}")

    async def process(
        self, 
        clothing_image: Union[str, np.ndarray, Image.Image, torch.Tensor], 
        clothing_type: str = "shirt",
        quality_level: str = "balanced",
        **kwargs
    ) -> Dict[str, Any]:
        """
        âœ… í†µì¼ëœ ì²˜ë¦¬ ì¸í„°í˜ì´ìŠ¤ - Pipeline Manager í˜¸í™˜
        
        Args:
            clothing_image: ì…ë ¥ ì˜ë¥˜ ì´ë¯¸ì§€
            clothing_type: ì˜ë¥˜ íƒ€ì… (shirt, dress, pants ë“±)
            quality_level: í’ˆì§ˆ ë ˆë²¨ (fast, balanced, high, ultra)
            **kwargs: ì¶”ê°€ ë§¤ê°œë³€ìˆ˜
                - method_override: ë°©ë²• ê°•ì œ ì§€ì •
                - enable_fallback: í´ë°± í—ˆìš© ì—¬ë¶€
                - cache_result: ê²°ê³¼ ìºì‹± ì—¬ë¶€
                - confidence_threshold: ì‹ ë¢°ë„ ì„ê³„ê°’
                
        Returns:
            Dict[str, Any]: ì„¸ê·¸ë©˜í…Œì´ì…˜ ê²°ê³¼
                - success: bool
                - mask: np.ndarray 
                - segmented_image: np.ndarray
                - confidence_score: float
                - quality_score: float
                - method_used: str
                - processing_time: float
                - metadata: dict
        """
        if not self.is_initialized:
            await self.initialize()
        
        start_time = time.time()
        
        try:
            self.logger.info(f"ğŸ‘• ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‹œì‘ - íƒ€ì…: {clothing_type}, í’ˆì§ˆ: {quality_level}")
            
            # 1. ìºì‹œ í™•ì¸
            cache_key = self._generate_cache_key(clothing_image, clothing_type, quality_level)
            if kwargs.get('cache_result', True) and cache_key in self.segmentation_cache:
                cached_result = self.segmentation_cache[cache_key]
                self.processing_stats['cache_hits'] += 1
                self.logger.info("ğŸ’¾ ìºì‹œì—ì„œ ê²°ê³¼ ë°˜í™˜")
                return self._format_result(cached_result)
            
            # 2. ì…ë ¥ ì´ë¯¸ì§€ ì „ì²˜ë¦¬
            processed_image = self._preprocess_image(clothing_image)
            
            # 3. ìµœì  ë°©ë²• ì„ íƒ
            method = kwargs.get('method_override') or self._select_best_method(
                processed_image, clothing_type, quality_level
            )
            
            # 4. ë©”ì¸ ì„¸ê·¸ë©˜í…Œì´ì…˜ ìˆ˜í–‰
            result = await self._perform_segmentation_with_fallback(
                processed_image, method, clothing_type, **kwargs
            )
            
            # 5. í›„ì²˜ë¦¬
            if self.enable_post_processing and result.success:
                result = await self._post_process_result(result, processed_image)
            
            # 6. í’ˆì§ˆ í‰ê°€
            if result.success:
                result.quality_score = self._evaluate_quality(processed_image, result.mask)
                result.confidence_score = self._calculate_confidence(result)
            
            # 7. ê²°ê³¼ ìºì‹±
            if kwargs.get('cache_result', True) and result.success:
                self.segmentation_cache[cache_key] = result
                if len(self.segmentation_cache) > self.segmentation_config.cache_size:
                    self._cleanup_cache()
            
            # 8. í†µê³„ ì—…ë°ì´íŠ¸
            self._update_statistics(result, time.time() - start_time)
            
            self.logger.info(f"âœ… ì„¸ê·¸ë©˜í…Œì´ì…˜ ì™„ë£Œ - ë°©ë²•: {result.method_used}, "
                           f"í’ˆì§ˆ: {result.quality_score:.3f}, ì‹œê°„: {result.processing_time:.3f}ì´ˆ")
            
            return self._format_result(result)
            
        except Exception as e:
            error_msg = f"ì„¸ê·¸ë©˜í…Œì´ì…˜ ì²˜ë¦¬ ì‹¤íŒ¨: {e}"
            self.logger.error(f"âŒ {error_msg}")
            
            # ì—ëŸ¬ ê²°ê³¼ ë°˜í™˜
            error_result = SegmentationResult(
                success=False,
                error_message=error_msg,
                processing_time=time.time() - start_time,
                method_used="error"
            )
            
            return self._format_result(error_result)

    def _preprocess_image(self, image: Union[str, np.ndarray, Image.Image, torch.Tensor]) -> Image.Image:
        """ì´ë¯¸ì§€ ì „ì²˜ë¦¬"""
        try:
            # íƒ€ì…ë³„ ë³€í™˜
            if isinstance(image, str):
                pil_image = Image.open(image).convert('RGB')
            elif isinstance(image, np.ndarray):
                if image.dtype == np.uint8:
                    pil_image = Image.fromarray(image)
                else:
                    pil_image = Image.fromarray((image * 255).astype(np.uint8))
                if pil_image.mode != 'RGB':
                    pil_image = pil_image.convert('RGB')
            elif isinstance(image, torch.Tensor):
                if self.data_converter:
                    pil_image = self.data_converter.tensor_to_pil(image)
                else:
                    # ì§ì ‘ ë³€í™˜
                    numpy_image = image.detach().cpu().numpy()
                    if numpy_image.ndim == 4:
                        numpy_image = numpy_image.squeeze(0)
                    if numpy_image.shape[0] in [1, 3]:
                        numpy_image = numpy_image.transpose(1, 2, 0)
                    numpy_image = (numpy_image * 255).astype(np.uint8)
                    pil_image = Image.fromarray(numpy_image).convert('RGB')
            elif isinstance(image, Image.Image):
                pil_image = image.convert('RGB')
            else:
                raise ValueError(f"ì§€ì›ë˜ì§€ ì•ŠëŠ” ì´ë¯¸ì§€ íƒ€ì…: {type(image)}")
            
            # í¬ê¸° ì¡°ì • (ì„¤ì •ì— ë”°ë¼)
            target_size = self.segmentation_config.input_size
            if pil_image.size != target_size:
                pil_image = pil_image.resize(target_size, Image.Resampling.LANCZOS)
            
            return pil_image
            
        except Exception as e:
            self.logger.error(f"ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            raise

    def _select_best_method(self, image: Image.Image, clothing_type: str, quality_level: str) -> SegmentationMethod:
        """ìµœì  ì„¸ê·¸ë©˜í…Œì´ì…˜ ë°©ë²• ì„ íƒ"""
        try:
            # í’ˆì§ˆ ë ˆë²¨ì— ë”°ë¥¸ ìš°ì„ ìˆœìœ„
            if quality_level == "ultra":
                priority = [SegmentationMethod.U2NET, SegmentationMethod.SAM, 
                           SegmentationMethod.DEEP_LAB, SegmentationMethod.REMBG]
            elif quality_level == "high":
                priority = [SegmentationMethod.U2NET, SegmentationMethod.REMBG, 
                           SegmentationMethod.DEEP_LAB]
            elif quality_level == "balanced":
                priority = [SegmentationMethod.REMBG, SegmentationMethod.U2NET, 
                           SegmentationMethod.TRADITIONAL]
            else:  # fast
                priority = [SegmentationMethod.REMBG, SegmentationMethod.TRADITIONAL]
            
            # ì‚¬ìš© ê°€ëŠ¥í•œ ë°©ë²• ì¤‘ì—ì„œ ì„ íƒ
            for method in priority:
                if method in self.available_methods:
                    return method
            
            # í´ë°±
            return SegmentationMethod.TRADITIONAL
            
        except Exception as e:
            self.logger.warning(f"ë°©ë²• ì„ íƒ ì‹¤íŒ¨: {e}")
            return SegmentationMethod.TRADITIONAL

    async def _perform_segmentation_with_fallback(
        self, 
        image: Image.Image, 
        method: SegmentationMethod, 
        clothing_type: str,
        **kwargs
    ) -> SegmentationResult:
        """í´ë°±ì„ í¬í•¨í•œ ì„¸ê·¸ë©˜í…Œì´ì…˜ ìˆ˜í–‰"""
        enable_fallback = kwargs.get('enable_fallback', True)
        
        try:
            # ë©”ì¸ ë°©ë²• ì‹œë„
            result = await self._perform_single_segmentation(image, method, clothing_type)
            
            if result.success:
                return result
            
            if not enable_fallback:
                return result
            
            # í´ë°± ë°©ë²•ë“¤ ì‹œë„
            fallback_methods = [m for m in self.available_methods if m != method]
            
            for fallback_method in fallback_methods:
                self.logger.warning(f"í´ë°± ë°©ë²• ì‹œë„: {fallback_method.value}")
                try:
                    fallback_result = await self._perform_single_segmentation(
                        image, fallback_method, clothing_type
                    )
                    if fallback_result.success:
                        fallback_result.metadata['original_method'] = method.value
                        fallback_result.metadata['fallback_used'] = True
                        return fallback_result
                except Exception as e:
                    self.logger.warning(f"í´ë°± ë°©ë²• {fallback_method.value} ì‹¤íŒ¨: {e}")
                    continue
            
            # ëª¨ë“  ë°©ë²• ì‹¤íŒ¨
            return SegmentationResult(
                success=False,
                error_message="ëª¨ë“  ì„¸ê·¸ë©˜í…Œì´ì…˜ ë°©ë²• ì‹¤íŒ¨",
                method_used=method.value
            )
            
        except Exception as e:
            return SegmentationResult(
                success=False,
                error_message=f"ì„¸ê·¸ë©˜í…Œì´ì…˜ ìˆ˜í–‰ ì‹¤íŒ¨: {e}",
                method_used=method.value
            )

    async def _perform_single_segmentation(
        self, 
        image: Image.Image, 
        method: SegmentationMethod, 
        clothing_type: str
    ) -> SegmentationResult:
        """ë‹¨ì¼ ì„¸ê·¸ë©˜í…Œì´ì…˜ ë°©ë²• ìˆ˜í–‰"""
        start_time = time.time()
        
        try:
            if method == SegmentationMethod.U2NET:
                result = await self._segment_with_u2net(image)
            elif method == SegmentationMethod.REMBG:
                result = await self._segment_with_rembg(image)
            elif method == SegmentationMethod.SAM:
                result = await self._segment_with_sam(image)
            elif method == SegmentationMethod.DEEP_LAB:
                result = await self._segment_with_deeplab(image)
            elif method == SegmentationMethod.TRADITIONAL:
                result = await self._segment_with_traditional(image)
            else:
                raise ValueError(f"ì§€ì›ë˜ì§€ ì•ŠëŠ” ë°©ë²•: {method}")
            
            result.processing_time = time.time() - start_time
            result.method_used = method.value
            
            return result
            
        except Exception as e:
            return SegmentationResult(
                success=False,
                error_message=f"{method.value} ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‹¤íŒ¨: {e}",
                method_used=method.value,
                processing_time=time.time() - start_time
            )

    async def _segment_with_u2net(self, image: Image.Image) -> SegmentationResult:
        """U2-Netì„ ì‚¬ìš©í•œ ì„¸ê·¸ë©˜í…Œì´ì…˜"""
        try:
            if not hasattr(self, 'u2net_model') or self.u2net_model is None:
                raise RuntimeError("U2-Net ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
            
            # ì´ë¯¸ì§€ë¥¼ í…ì„œë¡œ ë³€í™˜
            transform = transforms.Compose([
                transforms.Resize(self.segmentation_config.input_size),
                transforms.ToTensor(),
                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
            ])
            
            input_tensor = transform(image).unsqueeze(0).to(self.device)
            
            if self.segmentation_config.use_fp16 and self.device != 'cpu':
                input_tensor = input_tensor.half()
            
            # ì¶”ë¡ 
            with torch.no_grad():
                outputs = self.u2net_model(input_tensor)
                
                # ë©”ì¸ ì¶œë ¥ ì‚¬ìš©
                if isinstance(outputs, tuple):
                    mask_tensor = outputs[0]
                else:
                    mask_tensor = outputs
                
                # í›„ì²˜ë¦¬
                mask_tensor = torch.sigmoid(mask_tensor)
                mask_np = mask_tensor.squeeze().cpu().float().numpy()
                
                # ì„ê³„ê°’ ì ìš©
                threshold = self.confidence_threshold
                binary_mask = (mask_np > threshold).astype(np.uint8) * 255
                
                # ë§ˆìŠ¤í¬ í¬ê¸° ì¡°ì •
                if binary_mask.shape != image.size[::-1]:
                    binary_mask = cv2.resize(binary_mask, image.size, interpolation=cv2.INTER_NEAREST)
                
                # ì„¸ê·¸ë©˜í…Œì´ì…˜ëœ ì´ë¯¸ì§€ ìƒì„±
                image_np = np.array(image)
                segmented_image = image_np.copy()
                segmented_image[binary_mask == 0] = [0, 0, 0]  # ë°°ê²½ì„ ê²€ì€ìƒ‰ìœ¼ë¡œ
            
            return SegmentationResult(
                success=True,
                mask=binary_mask,
                segmented_image=segmented_image,
                confidence_score=float(mask_np.max()),
                metadata={'threshold_used': threshold}
            )
            
        except Exception as e:
            return SegmentationResult(
                success=False,
                error_message=f"U2-Net ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‹¤íŒ¨: {e}"
            )

    async def _segment_with_rembg(self, image: Image.Image) -> SegmentationResult:
        """RemBGë¥¼ ì‚¬ìš©í•œ ì„¸ê·¸ë©˜í…Œì´ì…˜"""
        try:
            if not REMBG_AVAILABLE:
                raise RuntimeError("RemBGê°€ ì‚¬ìš© ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤")
            
            # ì„¸ì…˜ ì„ íƒ
            session = self.rembg_sessions.get('cloth', self.default_rembg_session)
            if session is None:
                session = new_session('u2net')
            
            # ë°°ê²½ ì œê±°
            image_bytes = self._pil_to_bytes(image)
            result_bytes = remove(image_bytes, session=session)
            result_image = Image.open(BytesIO(result_bytes)).convert('RGBA')
            
            # ë§ˆìŠ¤í¬ ìƒì„± (ì•ŒíŒŒ ì±„ë„ ì‚¬ìš©)
            alpha_channel = np.array(result_image)[:, :, 3]
            binary_mask = (alpha_channel > 128).astype(np.uint8) * 255
            
            # ì„¸ê·¸ë©˜í…Œì´ì…˜ëœ ì´ë¯¸ì§€ ìƒì„±
            rgb_result = result_image.convert('RGB')
            segmented_image = np.array(rgb_result)
            
            return SegmentationResult(
                success=True,
                mask=binary_mask,
                segmented_image=segmented_image,
                confidence_score=0.9,  # RemBGëŠ” ì¼ë°˜ì ìœ¼ë¡œ ì‹ ë¢°ë„ê°€ ë†’ìŒ
                metadata={'session_used': 'cloth' if session in self.rembg_sessions.values() else 'default'}
            )
            
        except Exception as e:
            return SegmentationResult(
                success=False,
                error_message=f"RemBG ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‹¤íŒ¨: {e}"
            )

    async def _segment_with_sam(self, image: Image.Image) -> SegmentationResult:
        """SAM(Segment Anything Model)ì„ ì‚¬ìš©í•œ ì„¸ê·¸ë©˜í…Œì´ì…˜"""
        try:
            if not SAM_AVAILABLE:
                raise RuntimeError("SAMì´ ì‚¬ìš© ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤")
            
            # SAM êµ¬í˜„ (ê°„ì†Œí™”ëœ ë²„ì „)
            # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” SAM ëª¨ë¸ ë¡œë“œ ë° ì¶”ë¡  ë¡œì§ í•„ìš”
            
            # ì„ì‹œ êµ¬í˜„ - ì¤‘ì•™ ì˜ì—­ì„ ì˜ë¥˜ë¡œ ê°€ì •
            width, height = image.size
            mask = np.zeros((height, width), dtype=np.uint8)
            
            # ì¤‘ì•™ 70% ì˜ì—­ì„ ì˜ë¥˜ë¡œ ì„¤ì •
            margin_x = int(width * 0.15)
            margin_y = int(height * 0.15)
            mask[margin_y:height-margin_y, margin_x:width-margin_x] = 255
            
            # ì„¸ê·¸ë©˜í…Œì´ì…˜ëœ ì´ë¯¸ì§€ ìƒì„±
            image_np = np.array(image)
            segmented_image = image_np.copy()
            segmented_image[mask == 0] = [0, 0, 0]
            
            return SegmentationResult(
                success=True,
                mask=mask,
                segmented_image=segmented_image,
                confidence_score=0.7,
                metadata={'method': 'sam_simplified'}
            )
            
        except Exception as e:
            return SegmentationResult(
                success=False,
                error_message=f"SAM ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‹¤íŒ¨: {e}"
            )

    async def _segment_with_deeplab(self, image: Image.Image) -> SegmentationResult:
        """DeepLabì„ ì‚¬ìš©í•œ ì„¸ê·¸ë©˜í…Œì´ì…˜"""
        try:
            if not hasattr(self, 'deeplab_pipeline') or self.deeplab_pipeline is None:
                raise RuntimeError("DeepLab íŒŒì´í”„ë¼ì¸ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
            
            # DeepLab ì¶”ë¡ 
            results = self.deeplab_pipeline(image)
            
            # ê²°ê³¼ ì²˜ë¦¬ (ì˜ë¥˜ ê´€ë ¨ í´ë˜ìŠ¤ í•„í„°ë§)
            clothing_classes = ['person', 'clothing', 'shirt', 'dress']  # ì˜ˆì‹œ
            
            mask = np.zeros(image.size[::-1], dtype=np.uint8)
            
            for result in results:
                if any(cls in result['label'].lower() for cls in clothing_classes):
                    # ë§ˆìŠ¤í¬ ìƒì„± ë¡œì§
                    # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” segmentation ë§ˆìŠ¤í¬ ì²˜ë¦¬ í•„ìš”
                    pass
            
            # ì„ì‹œ êµ¬í˜„
            width, height = image.size
            center_mask = np.zeros((height, width), dtype=np.uint8)
            cv2.ellipse(center_mask, (width//2, height//2), (width//3, height//2), 0, 0, 360, 255, -1)
            
            # ì„¸ê·¸ë©˜í…Œì´ì…˜ëœ ì´ë¯¸ì§€ ìƒì„±
            image_np = np.array(image)
            segmented_image = image_np.copy()
            segmented_image[center_mask == 0] = [0, 0, 0]
            
            return SegmentationResult(
                success=True,
                mask=center_mask,
                segmented_image=segmented_image,
                confidence_score=0.8,
                metadata={'deeplab_results_count': len(results)}
            )
            
        except Exception as e:
            return SegmentationResult(
                success=False,
                error_message=f"DeepLab ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‹¤íŒ¨: {e}"
            )

    async def _segment_with_traditional(self, image: Image.Image) -> SegmentationResult:
        """ì „í†µì  ì»´í“¨í„° ë¹„ì „ ë°©ë²•ì„ ì‚¬ìš©í•œ ì„¸ê·¸ë©˜í…Œì´ì…˜"""
        try:
            image_np = np.array(image)
            height, width = image_np.shape[:2]
            
            # ë°©ë²• 1: GrabCut ì•Œê³ ë¦¬ì¦˜
            try:
                mask = np.zeros((height, width), np.uint8)
                
                # ì „ê²½ ì˜ì—­ ëŒ€ëµì  ì„¤ì • (ì¤‘ì•™ 80%)
                margin_x = int(width * 0.1)
                margin_y = int(height * 0.1)
                rect = (margin_x, margin_y, width - 2*margin_x, height - 2*margin_y)
                
                # GrabCut ì´ˆê¸°í™”
                bgd_model = np.zeros((1, 65), np.float64)
                fgd_model = np.zeros((1, 65), np.float64)
                
                # GrabCut ì ìš©
                cv2.grabCut(image_np, mask, rect, bgd_model, fgd_model, 
                           self.grabcut_config['iterations'], cv2.GC_INIT_WITH_RECT)
                
                # ë§ˆìŠ¤í¬ ì²˜ë¦¬
                mask2 = np.where((mask == 2) | (mask == 0), 0, 1).astype('uint8')
                binary_mask = mask2 * 255
                
                # í˜•íƒœí•™ì  ì²˜ë¦¬
                kernel = np.ones((3, 3), np.uint8)
                binary_mask = cv2.morphologyEx(binary_mask, cv2.MORPH_CLOSE, kernel)
                binary_mask = cv2.morphologyEx(binary_mask, cv2.MORPH_OPEN, kernel)
                
                confidence = 0.6
                
            except:
                # ë°©ë²• 2: ìƒ‰ìƒ ê¸°ë°˜ ì„ê³„ê°’ (í´ë°±)
                hsv = cv2.cvtColor(image_np, cv2.COLOR_RGB2HSV)
                
                # ë°°ê²½ì´ ë‹¨ìˆœí•˜ë‹¤ê³  ê°€ì •í•˜ê³  ê°€ì¥ìë¦¬ ìƒ‰ìƒì„ ë°°ê²½ìœ¼ë¡œ ê°„ì£¼
                edges = np.concatenate([
                    hsv[0, :], hsv[-1, :], hsv[:, 0], hsv[:, -1]
                ])
                
                if SKLEARN_AVAILABLE:
                    # K-meansë¡œ ë°°ê²½ìƒ‰ ì¶”ì •
                    kmeans = KMeans(n_clusters=2, random_state=42)
                    edge_colors = edges.reshape(-1, 3)
                    kmeans.fit(edge_colors)
                    
                    # ê°€ì¥ ë¹ˆë²ˆí•œ í´ëŸ¬ìŠ¤í„°ë¥¼ ë°°ê²½ìœ¼ë¡œ ê°„ì£¼
                    labels = kmeans.predict(hsv.reshape(-1, 3))
                    background_label = np.bincount(labels[:len(edges)]).argmax()
                    
                    pixel_labels = kmeans.predict(hsv.reshape(-1, 3))
                    binary_mask = (pixel_labels != background_label).astype(np.uint8).reshape(height, width) * 255
                else:
                    # ë‹¨ìˆœ ì„ê³„ê°’ ë°©ë²•
                    gray = cv2.cvtColor(image_np, cv2.COLOR_RGB2GRAY)
                    _, binary_mask = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
                
                confidence = 0.4
            
            # ì„¸ê·¸ë©˜í…Œì´ì…˜ëœ ì´ë¯¸ì§€ ìƒì„±
            segmented_image = image_np.copy()
            segmented_image[binary_mask == 0] = [0, 0, 0]
            
            return SegmentationResult(
                success=True,
                mask=binary_mask,
                segmented_image=segmented_image,
                confidence_score=confidence,
                metadata={'method': 'grabcut' if 'mask2' in locals() else 'threshold'}
            )
            
        except Exception as e:
            return SegmentationResult(
                success=False,
                error_message=f"ì „í†µì  ë°©ë²• ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‹¤íŒ¨: {e}"
            )

    async def _post_process_result(self, result: SegmentationResult, original_image: Image.Image) -> SegmentationResult:
        """ì„¸ê·¸ë©˜í…Œì´ì…˜ ê²°ê³¼ í›„ì²˜ë¦¬"""
        try:
            if not result.success or result.mask is None:
                return result
            
            mask = result.mask.copy()
            
            # 1. í˜•íƒœí•™ì  ì²˜ë¦¬
            if self.enable_post_processing:
                kernel = np.ones((3, 3), np.uint8)
                
                # ë…¸ì´ì¦ˆ ì œê±°
                mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)
                
                # í™€ ì±„ìš°ê¸°
                if self.segmentation_config.enable_hole_filling:
                    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)
                
                # ê²½ê³„ ë¶€ë“œëŸ½ê²Œ
                mask = cv2.medianBlur(mask, 5)
            
            # 2. ê²½ê³„ ê°œì„ 
            if self.enable_edge_refinement:
                mask = self._refine_edges(mask, np.array(original_image))
            
            # 3. ì„¸ê·¸ë©˜í…Œì´ì…˜ëœ ì´ë¯¸ì§€ ì¬ìƒì„±
            image_np = np.array(original_image)
            segmented_image = image_np.copy()
            segmented_image[mask == 0] = [0, 0, 0]
            
            result.mask = mask
            result.segmented_image = segmented_image
            result.metadata['post_processed'] = True
            
            return result
            
        except Exception as e:
            self.logger.warning(f"í›„ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return result

    def _refine_edges(self, mask: np.ndarray, image: np.ndarray) -> np.ndarray:
        """ê²½ê³„ ê°œì„ """
        try:
            # ê°€ìš°ì‹œì•ˆ ë¸”ëŸ¬ë¥¼ ì‚¬ìš©í•œ ê²½ê³„ ë¶€ë“œëŸ½ê²Œ
            if self.segmentation_config.enable_edge_refinement:
                # ê²½ê³„ ê²€ì¶œ
                edges = cv2.Canny(mask, 50, 150)
                
                # ê²½ê³„ ì£¼ë³€ ì˜ì—­ í™•ì¥
                kernel = np.ones((5, 5), np.uint8)
                edge_region = cv2.dilate(edges, kernel, iterations=1)
                
                # í•´ë‹¹ ì˜ì—­ì— ê°€ìš°ì‹œì•ˆ ë¸”ëŸ¬ ì ìš©
                blurred_mask = cv2.GaussianBlur(mask.astype(np.float32), (5, 5), 1.0)
                
                # ê²½ê³„ ì˜ì—­ë§Œ ë¸”ëŸ¬ëœ ê°’ìœ¼ë¡œ êµì²´
                refined_mask = mask.copy().astype(np.float32)
                refined_mask[edge_region > 0] = blurred_mask[edge_region > 0]
                
                return (refined_mask > 127).astype(np.uint8) * 255
            
            return mask
            
        except Exception as e:
            self.logger.warning(f"ê²½ê³„ ê°œì„  ì‹¤íŒ¨: {e}")
            return mask

    def _evaluate_quality(self, image: Image.Image, mask: np.ndarray) -> float:
        """ì„¸ê·¸ë©˜í…Œì´ì…˜ í’ˆì§ˆ í‰ê°€"""
        try:
            if mask is None:
                return 0.0
            
            height, width = mask.shape
            total_pixels = height * width
            
            # 1. ì „ê²½ ë¹„ìœ¨ (ë„ˆë¬´ ì‘ê±°ë‚˜ í¬ë©´ í’ˆì§ˆ ë‚®ìŒ)
            foreground_pixels = np.sum(mask > 0)
            fg_ratio = foreground_pixels / total_pixels
            
            # ì´ìƒì ì¸ ë¹„ìœ¨: 20-80%
            if 0.2 <= fg_ratio <= 0.8:
                ratio_score = 1.0
            elif fg_ratio < 0.1 or fg_ratio > 0.9:
                ratio_score = 0.0
            else:
                ratio_score = 0.5
            
            # 2. ì—°ê²°ì„± í‰ê°€ (í° ì—°ê²° ì»´í¬ë„ŒíŠ¸ê°€ ìˆì–´ì•¼ í•¨)
            num_labels, labels, stats, _ = cv2.connectedComponentsWithStats(mask, connectivity=8)
            
            if num_labels > 1:  # ë°°ê²½ ì œì™¸
                # ê°€ì¥ í° ì»´í¬ë„ŒíŠ¸ì˜ í¬ê¸°
                largest_component_size = np.max(stats[1:, cv2.CC_STAT_AREA])
                connectivity_score = min(largest_component_size / foreground_pixels, 1.0)
            else:
                connectivity_score = 0.0
            
            # 3. ê²½ê³„ ë¶€ë“œëŸ¬ì›€ í‰ê°€
            edges = cv2.Canny(mask, 50, 150)
            edge_pixels = np.sum(edges > 0)
            edge_ratio = edge_pixels / foreground_pixels if foreground_pixels > 0 else 1.0
            
            # ê²½ê³„ê°€ ë„ˆë¬´ ë³µì¡í•˜ë©´ í’ˆì§ˆ ë‚®ìŒ
            smoothness_score = max(0, 1.0 - edge_ratio)
            
            # 4. ì „ì²´ í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°
            quality_score = (
                ratio_score * 0.4 +
                connectivity_score * 0.4 +
                smoothness_score * 0.2
            )
            
            return min(max(quality_score, 0.0), 1.0)
            
        except Exception as e:
            self.logger.warning(f"í’ˆì§ˆ í‰ê°€ ì‹¤íŒ¨: {e}")
            return 0.5

    def _calculate_confidence(self, result: SegmentationResult) -> float:
        """ì‹ ë¢°ë„ ê³„ì‚°"""
        try:
            if not result.success or result.mask is None:
                return 0.0
            
            # ë°©ë²•ë³„ ê¸°ë³¸ ì‹ ë¢°ë„
            method_confidence = {
                'u2net': 0.9,
                'rembg': 0.85,
                'deeplab': 0.8,
                'sam': 0.75,
                'traditional': 0.6
            }
            
            base_confidence = method_confidence.get(result.method_used, 0.5)
            
            # í’ˆì§ˆ ì ìˆ˜ì™€ ê²°í•©
            quality_factor = result.quality_score if hasattr(result, 'quality_score') and result.quality_score else 0.5
            
            # ìµœì¢… ì‹ ë¢°ë„
            final_confidence = (base_confidence * 0.7 + quality_factor * 0.3)
            
            return min(max(final_confidence, 0.0), 1.0)
            
        except Exception as e:
            self.logger.warning(f"ì‹ ë¢°ë„ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return 0.5

    def _generate_cache_key(self, image: Union[str, np.ndarray, Image.Image, torch.Tensor], 
                          clothing_type: str, quality_level: str) -> str:
        """ìºì‹œ í‚¤ ìƒì„±"""
        try:
            # ì´ë¯¸ì§€ í•´ì‹œ ìƒì„±
            if isinstance(image, str):
                # íŒŒì¼ ê²½ë¡œì˜ ê²½ìš° ìˆ˜ì • ì‹œê°„ í¬í•¨
                stat = os.stat(image)
                image_hash = f"file_{hash(image)}_{stat.st_mtime}"
            else:
                # ì´ë¯¸ì§€ ë°ì´í„°ì˜ í•´ì‹œ
                if isinstance(image, Image.Image):
                    image_bytes = self._pil_to_bytes(image)
                elif isinstance(image, np.ndarray):
                    image_bytes = image.tobytes()
                elif isinstance(image, torch.Tensor):
                    image_bytes = image.detach().cpu().numpy().tobytes()
                else:
                    image_bytes = str(image).encode()
                
                image_hash = hashlib.md5(image_bytes).hexdigest()[:16]
            
            # ì „ì²´ í‚¤ ìƒì„±
            cache_key = f"{image_hash}_{clothing_type}_{quality_level}_{self.device}"
            return cache_key
            
        except Exception as e:
            self.logger.warning(f"ìºì‹œ í‚¤ ìƒì„± ì‹¤íŒ¨: {e}")
            return f"fallback_{time.time()}_{clothing_type}_{quality_level}"

    def _cleanup_cache(self):
        """ìºì‹œ ì •ë¦¬ (LRU ë°©ì‹)"""
        try:
            if len(self.segmentation_cache) <= self.segmentation_config.cache_size:
                return
            
            # ê°€ì¥ ì˜¤ë˜ëœ í•­ëª©ë“¤ ì œê±°
            items = list(self.segmentation_cache.items())
            # ì²˜ë¦¬ ì‹œê°„ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬ (ìµœê·¼ ì‚¬ìš©ëœ ê²ƒì´ ë’¤ì—)
            items.sort(key=lambda x: x[1].processing_time)
            
            # ì ˆë°˜ ì •ë„ ì œê±°
            remove_count = len(items) - self.segmentation_config.cache_size // 2
            
            for i in range(remove_count):
                del self.segmentation_cache[items[i][0]]
            
            self.logger.info(f"ğŸ’¾ ìºì‹œ ì •ë¦¬ ì™„ë£Œ: {remove_count}ê°œ í•­ëª© ì œê±°")
            
        except Exception as e:
            self.logger.error(f"ìºì‹œ ì •ë¦¬ ì‹¤íŒ¨: {e}")

    def _update_statistics(self, result: SegmentationResult, processing_time: float):
        """í†µê³„ ì—…ë°ì´íŠ¸"""
        try:
            self.processing_stats['total_processed'] += 1
            
            if result.success:
                self.processing_stats['successful_segmentations'] += 1
                
                # í’ˆì§ˆ ì ìˆ˜ í‰ê·  ì—…ë°ì´íŠ¸
                current_avg = self.processing_stats['average_quality']
                total_successful = self.processing_stats['successful_segmentations']
                new_quality = result.quality_score if hasattr(result, 'quality_score') else 0.5
                
                self.processing_stats['average_quality'] = (
                    (current_avg * (total_successful - 1) + new_quality) / total_successful
                )
            
            # ë°©ë²•ë³„ ì‚¬ìš© í†µê³„
            method = result.method_used
            if method not in self.processing_stats['method_usage']:
                self.processing_stats['method_usage'][method] = 0
            self.processing_stats['method_usage'][method] += 1
            
            # í‰ê·  ì²˜ë¦¬ ì‹œê°„ ì—…ë°ì´íŠ¸
            current_avg_time = self.processing_stats['average_processing_time']
            total_processed = self.processing_stats['total_processed']
            
            self.processing_stats['average_processing_time'] = (
                (current_avg_time * (total_processed - 1) + processing_time) / total_processed
            )
            
        except Exception as e:
            self.logger.warning(f"í†µê³„ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")

    def _format_result(self, result: SegmentationResult) -> Dict[str, Any]:
        """ê²°ê³¼ë¥¼ í‘œì¤€ ë”•ì…”ë„ˆë¦¬ í˜•íƒœë¡œ í¬ë§·"""
        try:
            formatted_result = {
                'success': result.success,
                'processing_time': result.processing_time,
                'method_used': result.method_used,
                'metadata': result.metadata
            }
            
            if result.success:
                formatted_result.update({
                    'mask': result.mask.tolist() if result.mask is not None else None,
                    'segmented_image': result.segmented_image.tolist() if result.segmented_image is not None else None,
                    'confidence_score': result.confidence_score,
                    'quality_score': result.quality_score,
                })
            else:
                formatted_result['error_message'] = result.error_message
            
            return formatted_result
            
        except Exception as e:
            self.logger.error(f"ê²°ê³¼ í¬ë§·íŒ… ì‹¤íŒ¨: {e}")
            return {
                'success': False,
                'error_message': f"ê²°ê³¼ í¬ë§·íŒ… ì‹¤íŒ¨: {e}",
                'processing_time': 0.0,
                'method_used': 'error'
            }

    def _pil_to_bytes(self, image: Image.Image) -> bytes:
        """PIL ì´ë¯¸ì§€ë¥¼ ë°”ì´íŠ¸ë¡œ ë³€í™˜"""
        buffer = BytesIO()
        image.save(buffer, format='PNG')
        return buffer.getvalue()

    async def _perform_segmentation_cached(self, *args, **kwargs):
        """ìºì‹œëœ ì„¸ê·¸ë©˜í…Œì´ì…˜ ìˆ˜í–‰ (LRU ìºì‹œìš©)"""
        return await self._perform_single_segmentation(*args, **kwargs)

    def get_statistics(self) -> Dict[str, Any]:
        """ì²˜ë¦¬ í†µê³„ ë°˜í™˜"""
        try:
            stats = self.processing_stats.copy()
            
            # ì„±ê³µë¥  ê³„ì‚°
            if stats['total_processed'] > 0:
                stats['success_rate'] = stats['successful_segmentations'] / stats['total_processed']
            else:
                stats['success_rate'] = 0.0
            
            # ìºì‹œ ì •ë³´
            stats['cache_info'] = {
                'size': len(self.segmentation_cache),
                'max_size': self.segmentation_config.cache_size,
                'hit_ratio': stats['cache_hits'] / max(stats['total_processed'], 1)
            }
            
            # ì‹œìŠ¤í…œ ì •ë³´
            stats['system_info'] = {
                'device': self.device,
                'is_m3_max': self.is_m3_max,
                'memory_gb': self.memory_gb,
                'available_methods': [m.value for m in self.available_methods],
                'optimization_enabled': self.optimization_enabled
            }
            
            return stats
            
        except Exception as e:
            self.logger.error(f"í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {'error': str(e)}

    async def cleanup(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        try:
            self.logger.info("ğŸ§¹ 3ë‹¨ê³„ ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‹œìŠ¤í…œ ì •ë¦¬ ì‹œì‘...")
            
            # ìºì‹œ ì •ë¦¬
            self.segmentation_cache.clear()
            self.model_cache.clear()
            self.session_cache.clear()
            
            # ëª¨ë¸ ë©”ëª¨ë¦¬ í•´ì œ
            if hasattr(self, 'u2net_model') and self.u2net_model:
                del self.u2net_model
                self.u2net_model = None
            
            if hasattr(self, 'deeplab_pipeline') and self.deeplab_pipeline:
                del self.deeplab_pipeline
                self.deeplab_pipeline = None
            
            # RemBG ì„¸ì…˜ ì •ë¦¬
            if hasattr(self, 'rembg_sessions'):
                self.rembg_sessions.clear()
            
            # ìŠ¤ë ˆë“œ í’€ ì¢…ë£Œ
            if hasattr(self, 'executor'):
                self.executor.shutdown(wait=True)
            
            # ë©”ëª¨ë¦¬ ì •ë¦¬
            if self.memory_manager:
                await self.memory_manager.cleanup_memory()
            
            # PyTorch ìºì‹œ ì •ë¦¬
            if self.device == 'mps' and hasattr(torch.mps, 'empty_cache'):
                try:
                    torch.mps.empty_cache()
                except:
                    pass
            elif self.device == 'cuda':
                try:
                    torch.cuda.empty_cache()
                except:
                    pass
            
            # ê°€ë¹„ì§€ ì»¬ë ‰ì…˜
            gc.collect()
            
            self.is_initialized = False
            self.logger.info("âœ… 3ë‹¨ê³„ ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‹œìŠ¤í…œ ì •ë¦¬ ì™„ë£Œ")
            
        except Exception as e:
            self.logger.error(f"ì •ë¦¬ ê³¼ì •ì—ì„œ ì˜¤ë¥˜ ë°œìƒ: {e}")

    def __del__(self):
        """ì†Œë©¸ì"""
        try:
            if hasattr(self, 'executor'):
                self.executor.shutdown(wait=False)
        except:
            pass

# ==============================================
# 4. íŒ©í† ë¦¬ í•¨ìˆ˜ë“¤ ë° ìœ í‹¸ë¦¬í‹°
# ==============================================

def create_cloth_segmentation_step(
    device: Optional[str] = None,
    config: Optional[Dict[str, Any]] = None,
    **kwargs
) -> ClothSegmentationStep:
    """
    ClothSegmentationStep íŒ©í† ë¦¬ í•¨ìˆ˜
    
    Args:
        device: ì‚¬ìš©í•  ë””ë°”ì´ìŠ¤ ('auto', 'cpu', 'cuda', 'mps')
        config: ì„¤ì • ë”•ì…”ë„ˆë¦¬
        **kwargs: ì¶”ê°€ ì„¤ì •
        
    Returns:
        ClothSegmentationStep: ì´ˆê¸°í™”ëœ ì¸ìŠ¤í„´ìŠ¤
    """
    try:
        return ClothSegmentationStep(device=device, config=config, **kwargs)
    except Exception as e:
        logger.error(f"ClothSegmentationStep ìƒì„± ì‹¤íŒ¨: {e}")
        raise

def create_m3_max_segmentation_step(**kwargs) -> ClothSegmentationStep:
    """M3 Max ìµœì í™”ëœ ì„¸ê·¸ë©˜í…Œì´ì…˜ ìŠ¤í… ìƒì„±"""
    m3_max_config = {
        'device': 'mps',
        'is_m3_max': True,
        'optimization_enabled': True,
        'memory_gb': 128,
        'quality_level': 'high',
        'segmentation_method': 'auto',
        'use_fp16': True,
        'enable_post_processing': True,
        'cache_size': 200
    }
    
    m3_max_config.update(kwargs)
    
    return ClothSegmentationStep(**m3_max_config)

def create_production_segmentation_step(
    quality_level: str = "balanced",
    enable_fallback: bool = True,
    **kwargs
) -> ClothSegmentationStep:
    """í”„ë¡œë•ì…˜ í™˜ê²½ìš© ì„¸ê·¸ë©˜í…Œì´ì…˜ ìŠ¤í… ìƒì„±"""
    production_config = {
        'quality_level': quality_level,
        'enable_fallback': enable_fallback,
        'optimization_enabled': True,
        'enable_post_processing': True,
        'enable_edge_refinement': True,
        'confidence_threshold': 0.8,
        'cache_size': 100
    }
    
    production_config.update(kwargs)
    
    return ClothSegmentationStep(**production_config)

# ==============================================
# 5. ëª¨ë“ˆ ìµìŠ¤í¬íŠ¸
# ==============================================

__all__ = [
    # ë©”ì¸ í´ë˜ìŠ¤
    'ClothSegmentationStep',
    
    # ì—´ê±°í˜• ë° ë°ì´í„° í´ë˜ìŠ¤
    'SegmentationMethod',
    'ClothingType', 
    'QualityLevel',
    'SegmentationConfig',
    'SegmentationResult',
    
    # AI ëª¨ë¸ í´ë˜ìŠ¤ë“¤
    'U2NET',
    'REBNCONV',
    'RSU7',
    
    # íŒ©í† ë¦¬ í•¨ìˆ˜ë“¤
    'create_cloth_segmentation_step',
    'create_m3_max_segmentation_step',
    'create_production_segmentation_step'
]

# ëª¨ë“ˆ ì´ˆê¸°í™” ë¡œê¹…
logger.info("âœ… Step 03 ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ ëª¨ë“ˆ ë¡œë“œ ì™„ë£Œ")
logger.info(f"   - Model Loader ì—°ë™: {'âœ…' if MODEL_LOADER_AVAILABLE else 'âŒ'}")
logger.info(f"   - Memory Manager ì—°ë™: {'âœ…' if MEMORY_MANAGER_AVAILABLE else 'âŒ'}")
logger.info(f"   - RemBG ì‚¬ìš© ê°€ëŠ¥: {'âœ…' if REMBG_AVAILABLE else 'âŒ'}")
logger.info(f"   - SAM ì‚¬ìš© ê°€ëŠ¥: {'âœ…' if SAM_AVAILABLE else 'âŒ'}")
logger.info(f"   - Transformers ì‚¬ìš© ê°€ëŠ¥: {'âœ…' if TRANSFORMERS_AVAILABLE else 'âŒ'}")
logger.info(f"   - scikit-learn ì‚¬ìš© ê°€ëŠ¥: {'âœ…' if SKLEARN_AVAILABLE else 'âŒ'}")

# ìë™ ì •ë¦¬ ë“±ë¡
import atexit

def _cleanup_on_exit():
    """í”„ë¡œê·¸ë¨ ì¢…ë£Œ ì‹œ ì •ë¦¬"""
    try:
        # ì „ì—­ ì¸ìŠ¤í„´ìŠ¤ë“¤ ì •ë¦¬
        gc.collect()
    except:
        pass

atexit.register(_cleanup_on_exit)