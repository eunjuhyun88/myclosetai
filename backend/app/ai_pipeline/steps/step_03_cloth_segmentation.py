# app/ai_pipeline/steps/step_03_cloth_segmentation.py
"""
ğŸ”¥ MyCloset AI - 3ë‹¨ê³„: ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ (ì™„ì „ ì˜ì¡´ì„± ì£¼ì… + AI ì—°ë™ ë²„ì „)
===============================================================================

âœ… ì˜ì¡´ì„± ì£¼ì… íŒ¨í„´ ì™„ì „ ì ìš© (StepFactory â†’ ModelLoader â†’ BaseStepMixin)
âœ… AI ëª¨ë¸ ì—°ë™ ë° ì‹¤ì œ ì¶”ë¡  (ì²´í¬í¬ì¸íŠ¸ â†’ ì‹¤ì œ AI ëª¨ë¸ â†’ ì¶”ë¡ )
âœ… ìˆœí™˜ì°¸ì¡° ì™„ì „ ë°©ì§€ (í•œë°©í–¥ ì°¸ì¡° êµ¬ì¡°)
âœ… BaseStepMixin ì™„ì „ í˜¸í™˜ (logger, ë©”ëª¨ë¦¬ ê´€ë¦¬, ì˜ì¡´ì„± ì£¼ì…)
âœ… ModelLoader ì—°ë™ (ì²´í¬í¬ì¸íŠ¸ ë¡œë”© ë‹´ë‹¹)
âœ… StepFactory ì˜ì¡´ì„± ì£¼ì… (ëª¨ë“  ì˜ì¡´ì„± ìë™ ì£¼ì…)
âœ… ì‹¤ì œ AI ì¶”ë¡  (U2Net, RemBG, SAM, DeepLab)
âœ… M3 Max 128GB ìµœì í™”
âœ… conda í™˜ê²½ ì™„ë²½ ì§€ì›
âœ… í”„ë¡œë•ì…˜ ë ˆë²¨ ì•ˆì •ì„±

ì˜ì¡´ì„± ì£¼ì… íë¦„:
ğŸ—ï¸ StepFactory â†’ ModelLoader ìƒì„± â†’ BaseStepMixin ìƒì„± â†’ ì˜ì¡´ì„± ì£¼ì… â†’ ClothSegmentationStep ì™„ì„±
â†“
ğŸ”— ModelLoader.load_model() â†’ ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ ë¡œë”© â†’ AI ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ ë°˜í™˜
â†“
ğŸ§  ClothSegmentationStep.initialize() â†’ AI ëª¨ë¸ ìƒì„± ë° ì´ˆê¸°í™” â†’ ì‹¤ì œ ì¶”ë¡  ì¤€ë¹„
â†“
ğŸ¯ ClothSegmentationStep.process() â†’ ì‹¤ì œ AI ì¶”ë¡  ì‹¤í–‰ â†’ ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ ê²°ê³¼ ë°˜í™˜

Author: MyCloset AI Team
Date: 2025-07-22
Version: v8.0 (Complete DI + AI Integration)
"""

import os
import sys
import logging
import time
import asyncio
import threading
import gc
import hashlib
import json
import base64
import weakref
from typing import Dict, Any, Optional, Tuple, List, Union, Callable, TYPE_CHECKING
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor, as_completed
from dataclasses import dataclass, field
from enum import Enum
from io import BytesIO
# íŒŒì¼ ìƒë‹¨ import ì„¹ì…˜ì—
from ..utils.pytorch_safe_ops import (
    safe_max, safe_amax, safe_argmax,
    extract_keypoints_from_heatmaps,
    tensor_to_pil_conda_optimized
)
# ==============================================
# ğŸ”¥ 1. TYPE_CHECKINGìœ¼ë¡œ ìˆœí™˜ì°¸ì¡° ì™„ì „ ë°©ì§€
# ==============================================

if TYPE_CHECKING:
    from ..utils.model_loader import ModelLoader, StepModelInterface
    from ..steps.base_step_mixin import BaseStepMixin
    from ..factories.step_factory import StepFactory
    from ...core.di_container import DIContainer

# ==============================================
# ğŸ”¥ 2. í•µì‹¬ ë¼ì´ë¸ŒëŸ¬ë¦¬ (conda í™˜ê²½ ìš°ì„ )
# ==============================================

# NumPy ì•ˆì „ Import (conda í™˜ê²½ ìš°ì„ )
NUMPY_AVAILABLE = False
try:
    import numpy as np
    NUMPY_AVAILABLE = True
    logging.info("ğŸ“Š NumPy ë¡œë“œ ì™„ë£Œ (conda í™˜ê²½ ìš°ì„ )")
except ImportError:
    logging.warning("âš ï¸ NumPy ì—†ìŒ - conda install numpy ê¶Œì¥")

# OpenCV ì•ˆì „ Import (conda í™˜ê²½ ìš°ì„ )
OPENCV_AVAILABLE = False
try:
    os.environ['OPENCV_IO_ENABLE_OPENEXR'] = '0'
    os.environ['OPENCV_IO_ENABLE_JASPER'] = '0'
    import cv2
    OPENCV_AVAILABLE = True
    logging.info(f"ğŸ¨ OpenCV {cv2.__version__} ë¡œë“œ ì™„ë£Œ (conda í™˜ê²½)")
except ImportError:
    logging.warning("âš ï¸ OpenCV ì—†ìŒ - conda install opencv ê¶Œì¥")
    # OpenCV í´ë°± (ìµœì†Œ ê¸°ëŠ¥)
    class OpenCVFallback:
        def resize(self, img, size, interpolation=1):
            try:
                from PIL import Image
                if hasattr(img, 'shape'):
                    pil_img = Image.fromarray(img)
                    return np.array(pil_img.resize(size))
                return img
            except: return img
        
        def cvtColor(self, img, code):
            if hasattr(img, 'shape') and len(img.shape) == 3:
                if code in [3, 4]: return img[:, :, ::-1]
            return img
            
        def __getattr__(self, name):
            def dummy(*args, **kwargs): return None
            return dummy
    
    cv2 = OpenCVFallback()

# PIL Import (conda í™˜ê²½ ìš°ì„ )
PIL_AVAILABLE = False
try:
    from PIL import Image, ImageEnhance, ImageFilter, ImageOps, ImageDraw, ImageFont
    PIL_AVAILABLE = True
    logging.info("ğŸ–¼ï¸ PIL ë¡œë“œ ì™„ë£Œ (conda í™˜ê²½)")
except ImportError:
    logging.warning("âš ï¸ PIL ì—†ìŒ - conda install pillow ê¶Œì¥")

# PyTorch Import (conda í™˜ê²½ ìš°ì„ )
TORCH_AVAILABLE = False
MPS_AVAILABLE = False
try:
    import torch
    import torch.nn as nn
    import torch.nn.functional as F
    from torchvision import transforms
    TORCH_AVAILABLE = True
    
    if hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
        MPS_AVAILABLE = True
        
    logging.info(f"ğŸ”¥ PyTorch {torch.__version__} ë¡œë“œ ì™„ë£Œ (conda í™˜ê²½)")
    if MPS_AVAILABLE:
        logging.info("ğŸ MPS ì‚¬ìš© ê°€ëŠ¥ (M3 Max ìµœì í™”)")
except ImportError:
    logging.warning("âš ï¸ PyTorch ì—†ìŒ - conda install pytorch ê¶Œì¥")

# AI ë¼ì´ë¸ŒëŸ¬ë¦¬ë“¤ (ì„ íƒì )
REMBG_AVAILABLE = False
try:
    import rembg
    from rembg import remove, new_session
    REMBG_AVAILABLE = True
    logging.info("ğŸ¤– RemBG ë¡œë“œ ì™„ë£Œ")
except ImportError:
    logging.warning("âš ï¸ RemBG ì—†ìŒ - pip install rembg")

SKLEARN_AVAILABLE = False
try:
    from sklearn.cluster import KMeans
    from sklearn.preprocessing import StandardScaler
    SKLEARN_AVAILABLE = True
    logging.info("ğŸ“ˆ scikit-learn ë¡œë“œ ì™„ë£Œ")
except ImportError:
    logging.warning("âš ï¸ scikit-learn ì—†ìŒ - conda install scikit-learn")

SAM_AVAILABLE = False
try:
    import segment_anything as sam
    SAM_AVAILABLE = True
    logging.info("ğŸ¯ SAM ë¡œë“œ ì™„ë£Œ")
except ImportError:
    logging.warning("âš ï¸ SAM ì—†ìŒ - pip install segment-anything")

TRANSFORMERS_AVAILABLE = False
try:
    from transformers import pipeline
    TRANSFORMERS_AVAILABLE = True
    logging.info("ğŸ¤— Transformers ë¡œë“œ ì™„ë£Œ")
except ImportError:
    logging.warning("âš ï¸ Transformers ì—†ìŒ - pip install transformers")

# ==============================================
# ğŸ”¥ 3. ì˜ì¡´ì„± ì£¼ì… ì•ˆì „ Import (ëŸ°íƒ€ì„)
# ==============================================

def safe_import_base_step_mixin():
    """BaseStepMixin ì•ˆì „ Import (ì˜ì¡´ì„± ì£¼ì…ìš©)"""
    try:
        from ..steps.base_step_mixin import BaseStepMixin
        return BaseStepMixin
    except ImportError as e:
        logging.error(f"âŒ BaseStepMixin import ì‹¤íŒ¨: {e}")
        raise ImportError("BaseStepMixinì´ í•„ìš”í•©ë‹ˆë‹¤. ì˜ì¡´ì„± ì£¼ì… íŒ¨í„´ì„ í™•ì¸í•˜ì„¸ìš”.")

def safe_import_model_loader():
    """ModelLoader ì•ˆì „ Import (ì˜ì¡´ì„± ì£¼ì…ìš©)"""
    try:
        from ..utils.model_loader import ModelLoader, get_global_model_loader
        return ModelLoader, get_global_model_loader
    except ImportError as e:
        logging.error(f"âŒ ModelLoader import ì‹¤íŒ¨: {e}")
        raise ImportError("ModelLoaderê°€ í•„ìš”í•©ë‹ˆë‹¤. ì˜ì¡´ì„± ì£¼ì… íŒ¨í„´ì„ í™•ì¸í•˜ì„¸ìš”.")

def safe_import_step_requests():
    """StepModelRequestAnalyzer ì•ˆì „ Import (ì˜ì¡´ì„± ì£¼ì…ìš©)"""
    try:
        from ..utils.step_model_requirements import get_step_request, StepModelRequestAnalyzer
        return get_step_request, StepModelRequestAnalyzer
    except ImportError as e:
        logging.error(f"âŒ StepModelRequestAnalyzer import ì‹¤íŒ¨: {e}")
        return None, None

def safe_import_di_container():
    """DI Container ì•ˆì „ Import (ì˜ì¡´ì„± ì£¼ì…ìš©)"""
    try:
        from ...core.di_container import get_di_container, inject_dependencies_to_step
        return get_di_container, inject_dependencies_to_step
    except ImportError as e:
        logging.warning(f"âš ï¸ DI Container import ì‹¤íŒ¨: {e}")
        return None, None

# ë¡œê¹… ì„¤ì •
logger = logging.getLogger(__name__)

# ==============================================
# ğŸ”¥ 4. ë°ì´í„° êµ¬ì¡° ì •ì˜
# ==============================================

class SegmentationMethod(Enum):
    """ì„¸ê·¸ë©˜í…Œì´ì…˜ ë°©ë²•"""
    U2NET = "u2net"
    REMBG = "rembg" 
    SAM = "sam"
    DEEP_LAB = "deeplab"
    MASK_RCNN = "mask_rcnn"
    TRADITIONAL = "traditional"
    HYBRID = "hybrid"
    AUTO = "auto"

class ClothingType(Enum):
    """ì˜ë¥˜ íƒ€ì…"""
    SHIRT = "shirt"
    DRESS = "dress"
    PANTS = "pants"
    SKIRT = "skirt"
    JACKET = "jacket"
    SWEATER = "sweater"
    COAT = "coat"
    TOP = "top"
    BOTTOM = "bottom"
    UNKNOWN = "unknown"

class QualityLevel(Enum):
    """í’ˆì§ˆ ë ˆë²¨"""
    FAST = "fast"
    BALANCED = "balanced"
    HIGH = "high"
    ULTRA = "ultra"

@dataclass
class SegmentationConfig:
    """ì„¸ê·¸ë©˜í…Œì´ì…˜ ì„¤ì •"""
    method: SegmentationMethod = SegmentationMethod.AUTO
    quality_level: QualityLevel = QualityLevel.BALANCED
    input_size: Tuple[int, int] = (512, 512)
    output_size: Optional[Tuple[int, int]] = None
    enable_visualization: bool = True
    enable_post_processing: bool = True
    enable_edge_refinement: bool = True
    enable_hole_filling: bool = True
    use_fp16: bool = True
    batch_size: int = 1
    confidence_threshold: float = 0.8
    iou_threshold: float = 0.5
    edge_smoothing: bool = True
    remove_noise: bool = True
    visualization_quality: str = "high"
    enable_caching: bool = True
    cache_size: int = 100
    show_masks: bool = True
    show_boundaries: bool = True
    overlay_opacity: float = 0.6
    strict_mode: bool = True
    # ì˜ì¡´ì„± ì£¼ì… ê´€ë ¨
    enable_dependency_injection: bool = True
    use_step_factory: bool = True

@dataclass
class SegmentationResult:
    """ì„¸ê·¸ë©˜í…Œì´ì…˜ ê²°ê³¼"""
    success: bool
    mask: Optional[np.ndarray] = None
    segmented_image: Optional[np.ndarray] = None
    confidence_score: float = 0.0
    quality_score: float = 0.0
    method_used: str = "unknown"
    processing_time: float = 0.0
    metadata: Dict[str, Any] = field(default_factory=dict)
    error_message: Optional[str] = None
    # ì‹œê°í™” ì´ë¯¸ì§€ë“¤
    visualization_image: Optional[Image.Image] = None
    overlay_image: Optional[Image.Image] = None
    mask_image: Optional[Image.Image] = None
    boundary_image: Optional[Image.Image] = None
    # ì˜ì¡´ì„± ì£¼ì… ì •ë³´
    dependency_injection_info: Dict[str, Any] = field(default_factory=dict)

# ==============================================
# ğŸ”¥ 5. ì˜ë¥˜ë³„ ìƒ‰ìƒ ë§¤í•‘ (ì‹œê°í™”ìš©)
# ==============================================

CLOTHING_COLORS = {
    'shirt': (255, 100, 100),      # ë¹¨ê°•
    'pants': (100, 100, 255),      # íŒŒë‘
    'dress': (255, 100, 255),      # ë¶„í™
    'jacket': (100, 255, 100),     # ì´ˆë¡
    'skirt': (255, 255, 100),      # ë…¸ë‘
    'sweater': (138, 43, 226),     # ë¸”ë£¨ë°”ì´ì˜¬ë ›
    'coat': (165, 42, 42),         # ê°ˆìƒ‰
    'top': (0, 255, 255),          # ì‹œì•ˆ
    'bottom': (255, 165, 0),       # ì˜¤ë Œì§€
    'shoes': (255, 150, 0),        # ì£¼í™©
    'bag': (150, 75, 0),           # ê°ˆìƒ‰
    'hat': (128, 0, 128),          # ë³´ë¼
    'accessory': (0, 255, 255),    # ì‹œì•ˆ
    'unknown': (128, 128, 128),    # íšŒìƒ‰
}

# ==============================================
# ğŸ”¥ 6. AI ëª¨ë¸ í´ë˜ìŠ¤ë“¤ (ì‹¤ì œ êµ¬í˜„)
# ==============================================

class REBNCONV(nn.Module):
    """U2-Netì˜ ê¸°ë³¸ ì»¨ë³¼ë£¨ì…˜ ë¸”ë¡"""
    def __init__(self, in_ch=3, out_ch=3, dirate=1):
        super(REBNCONV, self).__init__()
        self.conv_s1 = nn.Conv2d(in_ch, out_ch, 3, padding=1*dirate, dilation=1*dirate)
        self.bn_s1 = nn.BatchNorm2d(out_ch)
        self.relu_s1 = nn.ReLU(inplace=True)
    
    def forward(self, x):
        return self.relu_s1(self.bn_s1(self.conv_s1(x)))

class RSU7(nn.Module):
    """U2-Net RSU-7 ë¸”ë¡"""
    def __init__(self, in_ch=3, mid_ch=12, out_ch=3):
        super(RSU7, self).__init__()
        self.rebnconvin = REBNCONV(in_ch, out_ch, dirate=1)
        
        self.rebnconv1 = REBNCONV(out_ch, mid_ch, dirate=1)
        self.pool1 = nn.MaxPool2d(2, stride=2, ceil_mode=True)
        
        self.rebnconv2 = REBNCONV(mid_ch, mid_ch, dirate=1)
        self.pool2 = nn.MaxPool2d(2, stride=2, ceil_mode=True)
        
        self.rebnconv3 = REBNCONV(mid_ch, mid_ch, dirate=1)
        self.pool3 = nn.MaxPool2d(2, stride=2, ceil_mode=True)
        
        self.rebnconv4 = REBNCONV(mid_ch, mid_ch, dirate=1)
        self.pool4 = nn.MaxPool2d(2, stride=2, ceil_mode=True)
        
        self.rebnconv5 = REBNCONV(mid_ch, mid_ch, dirate=1)
        self.pool5 = nn.MaxPool2d(2, stride=2, ceil_mode=True)
        
        self.rebnconv6 = REBNCONV(mid_ch, mid_ch, dirate=1)
        self.rebnconv7 = REBNCONV(mid_ch, mid_ch, dirate=2)
        
        self.rebnconv6d = REBNCONV(mid_ch*2, mid_ch, dirate=1)
        self.upsample6 = nn.Upsample(scale_factor=2, mode='bilinear')
        
        self.rebnconv5d = REBNCONV(mid_ch*2, mid_ch, dirate=1)
        self.upsample5 = nn.Upsample(scale_factor=2, mode='bilinear')
        
        self.rebnconv4d = REBNCONV(mid_ch*2, mid_ch, dirate=1)
        self.upsample4 = nn.Upsample(scale_factor=2, mode='bilinear')
        
        self.rebnconv3d = REBNCONV(mid_ch*2, mid_ch, dirate=1)
        self.upsample3 = nn.Upsample(scale_factor=2, mode='bilinear')
        
        self.rebnconv2d = REBNCONV(mid_ch*2, mid_ch, dirate=1)
        self.upsample2 = nn.Upsample(scale_factor=2, mode='bilinear')
        
        self.rebnconv1d = REBNCONV(mid_ch*2, out_ch, dirate=1)
    
    def forward(self, x):
        hx = x
        hxin = self.rebnconvin(hx)
        
        hx1 = self.rebnconv1(hxin)
        hx = self.pool1(hx1)
        
        hx2 = self.rebnconv2(hx)
        hx = self.pool2(hx2)
        
        hx3 = self.rebnconv3(hx)
        hx = self.pool3(hx3)
        
        hx4 = self.rebnconv4(hx)
        hx = self.pool4(hx4)
        
        hx5 = self.rebnconv5(hx)
        hx = self.pool5(hx5)
        
        hx6 = self.rebnconv6(hx)
        hx7 = self.rebnconv7(hx6)
        
        hx6d = self.rebnconv6d(torch.cat((hx7, hx6), 1))
        hx6dup = self.upsample6(hx6d)
        
        hx5d = self.rebnconv5d(torch.cat((hx6dup, hx5), 1))
        hx5dup = self.upsample5(hx5d)
        
        hx4d = self.rebnconv4d(torch.cat((hx5dup, hx4), 1))
        hx4dup = self.upsample4(hx4d)
        
        hx3d = self.rebnconv3d(torch.cat((hx4dup, hx3), 1))
        hx3dup = self.upsample3(hx3d)
        
        hx2d = self.rebnconv2d(torch.cat((hx3dup, hx2), 1))
        hx2dup = self.upsample2(hx2d)
        
        hx1d = self.rebnconv1d(torch.cat((hx2dup, hx1), 1))
        
        return hx1d + hxin

class U2NET(nn.Module):
    """U2-Net ë©”ì¸ ëª¨ë¸ (ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ ìµœì í™”)"""
    def __init__(self, in_ch=3, out_ch=1):
        super(U2NET, self).__init__()
        
        # ì¸ì½”ë”
        self.stage1 = RSU7(in_ch, 32, 64)
        self.pool12 = nn.MaxPool2d(2, stride=2, ceil_mode=True)
        
        self.stage2 = RSU7(64, 32, 128)
        self.pool23 = nn.MaxPool2d(2, stride=2, ceil_mode=True)
        
        self.stage3 = RSU7(128, 64, 256)
        self.pool34 = nn.MaxPool2d(2, stride=2, ceil_mode=True)
        
        self.stage4 = RSU7(256, 128, 512)
        self.pool45 = nn.MaxPool2d(2, stride=2, ceil_mode=True)
        
        self.stage5 = RSU7(512, 256, 512)
        self.pool56 = nn.MaxPool2d(2, stride=2, ceil_mode=True)
        
        self.stage6 = RSU7(512, 256, 512)
        
        # ë””ì½”ë”
        self.stage5d = RSU7(1024, 256, 512)
        self.stage4d = RSU7(1024, 128, 256)
        self.stage3d = RSU7(512, 64, 128)
        self.stage2d = RSU7(256, 32, 64)
        self.stage1d = RSU7(128, 16, 64)
        
        # Side outputs
        self.side1 = nn.Conv2d(64, out_ch, 3, padding=1)
        self.side2 = nn.Conv2d(64, out_ch, 3, padding=1)
        self.side3 = nn.Conv2d(128, out_ch, 3, padding=1)
        self.side4 = nn.Conv2d(256, out_ch, 3, padding=1)
        self.side5 = nn.Conv2d(512, out_ch, 3, padding=1)
        self.side6 = nn.Conv2d(512, out_ch, 3, padding=1)
        
        self.outconv = nn.Conv2d(6*out_ch, out_ch, 1)
    
    def forward(self, x):
        hx = x
        
        # ì¸ì½”ë”
        hx1 = self.stage1(hx)
        hx = self.pool12(hx1)
        
        hx2 = self.stage2(hx)
        hx = self.pool23(hx2)
        
        hx3 = self.stage3(hx)
        hx = self.pool34(hx3)
        
        hx4 = self.stage4(hx)
        hx = self.pool45(hx4)
        
        hx5 = self.stage5(hx)
        hx = self.pool56(hx5)
        
        hx6 = self.stage6(hx)
        
        # ë””ì½”ë”
        hx5d = self.stage5d(torch.cat((hx6, hx5), 1))
        hx5dup = F.interpolate(hx5d, size=hx4.shape[2:], mode='bilinear', align_corners=False)
        
        hx4d = self.stage4d(torch.cat((hx5dup, hx4), 1))
        hx4dup = F.interpolate(hx4d, size=hx3.shape[2:], mode='bilinear', align_corners=False)
        
        hx3d = self.stage3d(torch.cat((hx4dup, hx3), 1))
        hx3dup = F.interpolate(hx3d, size=hx2.shape[2:], mode='bilinear', align_corners=False)
        
        hx2d = self.stage2d(torch.cat((hx3dup, hx2), 1))
        hx2dup = F.interpolate(hx2d, size=hx1.shape[2:], mode='bilinear', align_corners=False)
        
        hx1d = self.stage1d(torch.cat((hx2dup, hx1), 1))
        
        # Side outputs
        d1 = self.side1(hx1d)
        d2 = F.interpolate(self.side2(hx2d), size=d1.shape[2:], mode='bilinear', align_corners=False)
        d3 = F.interpolate(self.side3(hx3d), size=d1.shape[2:], mode='bilinear', align_corners=False)
        d4 = F.interpolate(self.side4(hx4d), size=d1.shape[2:], mode='bilinear', align_corners=False)
        d5 = F.interpolate(self.side5(hx5d), size=d1.shape[2:], mode='bilinear', align_corners=False)
        d6 = F.interpolate(self.side6(hx6), size=d1.shape[2:], mode='bilinear', align_corners=False)
        
        # ìµœì¢… ì¶œë ¥
        d0 = self.outconv(torch.cat((d1, d2, d3, d4, d5, d6), 1))
        
        return torch.sigmoid(d0), torch.sigmoid(d1), torch.sigmoid(d2), torch.sigmoid(d3), torch.sigmoid(d4), torch.sigmoid(d5), torch.sigmoid(d6)

# ==============================================
# ğŸ”¥ 7. ë©”ì¸ ClothSegmentationStep í´ë˜ìŠ¤ (ì˜ì¡´ì„± ì£¼ì… + AI ì—°ë™)
# ==============================================

class ClothSegmentationStep:
    """
    ğŸ”¥ ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ Step - ì™„ì „ ì˜ì¡´ì„± ì£¼ì… + AI ì—°ë™
    
    âœ… ì˜ì¡´ì„± ì£¼ì… íŒ¨í„´ ì™„ì „ ì ìš©
    âœ… ModelLoader ì—°ë™ìœ¼ë¡œ ì‹¤ì œ AI ëª¨ë¸ ë¡œë”©
    âœ… BaseStepMixin ì™„ì „ í˜¸í™˜
    âœ… ì‹¤ì œ AI ì¶”ë¡  (U2Net, RemBG, SAM ë“±)
    âœ… ìˆœí™˜ì°¸ì¡° ì™„ì „ ë°©ì§€
    âœ… M3 Max 128GB ìµœì í™”
    âœ… conda í™˜ê²½ ì™„ë²½ ì§€ì›
    """
    
    def __init__(
        self,
        device: Optional[str] = None,
        config: Optional[Union[Dict[str, Any], SegmentationConfig]] = None,
        **kwargs
    ):
        """
        ğŸ”¥ ìƒì„±ì - ì˜ì¡´ì„± ì£¼ì… íŒ¨í„´ ì ìš©
        """
        
        # ===== 1. ê¸°ë³¸ ì†ì„± ì„¤ì • =====
        self.step_name = "ClothSegmentationStep"
        self.step_number = 3
        self.step_type = "cloth_segmentation"
        self.device = device or self._auto_detect_device()
        
        # ===== 2. Logger ì„¤ì • (BaseStepMixin í˜¸í™˜) =====
        self.logger = logging.getLogger(f"pipeline.steps.{self.step_name}")
        
        # ===== 3. ì„¤ì • ì²˜ë¦¬ =====
        if isinstance(config, dict):
            self.segmentation_config = SegmentationConfig(**config)
        elif isinstance(config, SegmentationConfig):
            self.segmentation_config = config
        else:
            self.segmentation_config = SegmentationConfig()
        
        # ===== 4. ì˜ì¡´ì„± ì£¼ì…ìš© ì†ì„± ì´ˆê¸°í™” =====
        self.model_loader = None
        self.memory_manager = None
        self.data_converter = None
        self.di_container = None
        self.step_factory = None
        
        # ===== 5. ìƒíƒœ ë³€ìˆ˜ ì´ˆê¸°í™” =====
        self.is_initialized = False
        self.models_loaded = {}  # ì‹¤ì œ AI ëª¨ë¸ë“¤
        self.checkpoints_loaded = {}  # ì²´í¬í¬ì¸íŠ¸ë“¤
        self.available_methods = []
        self.model_interface = None
        self.rembg_sessions = {}
        
        # ===== 6. M3 Max ê°ì§€ ë° ìµœì í™” =====
        self.is_m3_max = self._detect_m3_max()
        self.memory_gb = kwargs.get('memory_gb', 128.0 if self.is_m3_max else 16.0)
        
        # ===== 7. í†µê³„ ë° ìºì‹œ ì´ˆê¸°í™” =====
        self.processing_stats = {
            'total_processed': 0,
            'successful_segmentations': 0,
            'failed_segmentations': 0,
            'average_time': 0.0,
            'average_quality': 0.0,
            'method_usage': {},
            'cache_hits': 0,
            'ai_model_calls': 0,
            'dependency_injection_calls': 0
        }
        
        self.segmentation_cache = {}
        self.cache_lock = threading.RLock()
        self.executor = ThreadPoolExecutor(
            max_workers=4 if self.is_m3_max else 2, 
            thread_name_prefix="cloth_seg_di"
        )
        
        self.logger.info("âœ… ClothSegmentationStep ìƒì„± ì™„ë£Œ (ì˜ì¡´ì„± ì£¼ì… íŒ¨í„´)")
        self.logger.info(f"   - Device: {self.device}")
        self.logger.info(f"   - DI í™œì„±í™”: {self.segmentation_config.enable_dependency_injection}")

    def _auto_detect_device(self) -> str:
        """ë””ë°”ì´ìŠ¤ ìë™ ê°ì§€ - M3 Max ìµœì í™”"""
        try:
            if TORCH_AVAILABLE:
                if MPS_AVAILABLE:
                    return "mps"
                elif torch.cuda.is_available():
                    return "cuda"
            return "cpu"
        except Exception:
            return "cpu"

    def _detect_m3_max(self) -> bool:
        """M3 Max ì¹© ê°ì§€"""
        try:
            import platform
            import subprocess
            if platform.system() == 'Darwin':
                result = subprocess.run(
                    ['sysctl', '-n', 'machdep.cpu.brand_string'], 
                    capture_output=True, text=True
                )
                cpu_info = result.stdout.strip()
                return 'M3 Max' in cpu_info or 'M3' in cpu_info
        except Exception:
            pass
        return False

    # ==============================================
    # ğŸ”¥ 8. ì˜ì¡´ì„± ì£¼ì… ë©”ì„œë“œë“¤ (BaseStepMixin íŒ¨í„´)
    # ==============================================
    
    def set_model_loader(self, model_loader):
        """ModelLoader ì˜ì¡´ì„± ì£¼ì… (BaseStepMixin íŒ¨í„´)"""
        try:
            self.model_loader = model_loader
            self.processing_stats['dependency_injection_calls'] += 1
            self.logger.info("âœ… ModelLoader ì˜ì¡´ì„± ì£¼ì… ì™„ë£Œ")
            return True
        except Exception as e:
            self.logger.error(f"âŒ ModelLoader ì£¼ì… ì‹¤íŒ¨: {e}")
            return False
    
    def set_memory_manager(self, memory_manager):
        """MemoryManager ì˜ì¡´ì„± ì£¼ì… (BaseStepMixin íŒ¨í„´)"""
        try:
            self.memory_manager = memory_manager
            self.processing_stats['dependency_injection_calls'] += 1
            self.logger.info("âœ… MemoryManager ì˜ì¡´ì„± ì£¼ì… ì™„ë£Œ")
            return True
        except Exception as e:
            self.logger.warning(f"âš ï¸ MemoryManager ì£¼ì… ì‹¤íŒ¨: {e}")
            return False
    
    def set_data_converter(self, data_converter):
        """DataConverter ì˜ì¡´ì„± ì£¼ì… (BaseStepMixin íŒ¨í„´)"""
        try:
            self.data_converter = data_converter
            self.processing_stats['dependency_injection_calls'] += 1
            self.logger.info("âœ… DataConverter ì˜ì¡´ì„± ì£¼ì… ì™„ë£Œ")
            return True
        except Exception as e:
            self.logger.warning(f"âš ï¸ DataConverter ì£¼ì… ì‹¤íŒ¨: {e}")
            return False
    
    def set_di_container(self, di_container):
        """DI Container ì˜ì¡´ì„± ì£¼ì…"""
        try:
            self.di_container = di_container
            self.processing_stats['dependency_injection_calls'] += 1
            self.logger.info("âœ… DI Container ì˜ì¡´ì„± ì£¼ì… ì™„ë£Œ")
            return True
        except Exception as e:
            self.logger.warning(f"âš ï¸ DI Container ì£¼ì… ì‹¤íŒ¨: {e}")
            return False
    
    def set_step_factory(self, step_factory):
        """StepFactory ì˜ì¡´ì„± ì£¼ì…"""
        try:
            self.step_factory = step_factory
            self.processing_stats['dependency_injection_calls'] += 1
            self.logger.info("âœ… StepFactory ì˜ì¡´ì„± ì£¼ì… ì™„ë£Œ")
            return True
        except Exception as e:
            self.logger.warning(f"âš ï¸ StepFactory ì£¼ì… ì‹¤íŒ¨: {e}")
            return False
    
    def set_step_interface(self, step_interface):
        """ğŸ”¥ Step ì¸í„°í˜ì´ìŠ¤ ì˜ì¡´ì„± ì£¼ì… (ModelLoader.create_step_interfaceìš©)"""
        try:
            self.step_interface = step_interface
            self.model_interface = step_interface  # í˜¸í™˜ì„±
            self.processing_stats['dependency_injection_calls'] += 1
            self.logger.info("âœ… Step ì¸í„°í˜ì´ìŠ¤ ì˜ì¡´ì„± ì£¼ì… ì™„ë£Œ")
            return True
        except Exception as e:
            self.logger.warning(f"âš ï¸ Step ì¸í„°í˜ì´ìŠ¤ ì£¼ì… ì‹¤íŒ¨: {e}")
            return False

    def inject_dependencies(
        self, 
        model_loader=None, 
        memory_manager=None, 
        data_converter=None, 
        di_container=None,
        **kwargs
    ):
        """í†µí•© ì˜ì¡´ì„± ì£¼ì… ë©”ì„œë“œ (DI Container íŒ¨í„´)"""
        try:
            injected_count = 0
            
            if model_loader and self.set_model_loader(model_loader):
                injected_count += 1
            
            if memory_manager and self.set_memory_manager(memory_manager):
                injected_count += 1
            
            if data_converter and self.set_data_converter(data_converter):
                injected_count += 1
            
            if di_container and self.set_di_container(di_container):
                injected_count += 1
            
            self.logger.info(f"âœ… í†µí•© ì˜ì¡´ì„± ì£¼ì… ì™„ë£Œ: {injected_count}ê°œ")
            return injected_count > 0
            
        except Exception as e:
            self.logger.error(f"âŒ í†µí•© ì˜ì¡´ì„± ì£¼ì… ì‹¤íŒ¨: {e}")
            return False

    # ==============================================
    # ğŸ”¥ 9. í•µì‹¬: ì´ˆê¸°í™” ë©”ì„œë“œ (ì˜ì¡´ì„± ì£¼ì… + AI ëª¨ë¸ ë¡œë”©)
    # ==============================================
    
    async def initialize(self) -> bool:
        """
        ğŸ”¥ ì´ˆê¸°í™” - ì˜ì¡´ì„± ì£¼ì… + ì‹¤ì œ AI ëª¨ë¸ ë¡œë”©
        """
        try:
            self.logger.info("ğŸ”„ ClothSegmentationStep ì´ˆê¸°í™” ì‹œì‘ (ì˜ì¡´ì„± ì£¼ì… + AI ì—°ë™)")
            
            # ===== 1. ì˜ì¡´ì„± ê²€ì¦ =====
            if not self._validate_dependencies():
                self.logger.error("âŒ í•„ìˆ˜ ì˜ì¡´ì„±ì´ ì£¼ì…ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
                self.logger.error("ğŸ’¡ StepFactoryë¥¼ í†µí•œ ì˜ì¡´ì„± ì£¼ì…ì´ í•„ìš”í•©ë‹ˆë‹¤")
                return False
            
            # ===== 2. ModelLoader ì¸í„°í˜ì´ìŠ¤ ì„¤ì • =====
            await self._setup_model_interface()
            # ===== 3. ModelLoaderë¥¼ í†µí•œ ì²´í¬í¬ì¸íŠ¸ ë¡œë”© =====
            if not await self._load_checkpoints_via_model_loader():
                self.logger.error("âŒ ì²´í¬í¬ì¸íŠ¸ ë¡œë”© ì‹¤íŒ¨")
                return False
            
            # ===== 4. ì²´í¬í¬ì¸íŠ¸ì—ì„œ ì‹¤ì œ AI ëª¨ë¸ ìƒì„± =====
            if not await self._create_ai_models_from_checkpoints():
                self.logger.error("âŒ AI ëª¨ë¸ ìƒì„± ì‹¤íŒ¨")
                return False
            
            # ===== 5. RemBG ì„¸ì…˜ ì´ˆê¸°í™” =====
            if REMBG_AVAILABLE:
                await self._initialize_rembg_sessions()
            
            # ===== 6. ëª¨ë¸ ê²€ì¦ =====
            self._validate_loaded_models()
            
            # ===== 7. M3 Max ìµœì í™” ì›Œë°ì—… =====
            if self.is_m3_max:
                await self._warmup_m3_max()
            
            # ===== 8. ì‹œê°í™” ì‹œìŠ¤í…œ ì´ˆê¸°í™” =====
            self._initialize_visualization_system()
            
            # ===== 9. ì‚¬ìš© ê°€ëŠ¥í•œ ë°©ë²• ê°ì§€ =====
            self.available_methods = self._detect_available_methods()
            if not self.available_methods:
                self.logger.warning("âš ï¸ ì‚¬ìš© ê°€ëŠ¥í•œ ì„¸ê·¸ë©˜í…Œì´ì…˜ ë°©ë²•ì´ ì—†ìŠµë‹ˆë‹¤")
                return False
            
            # ===== 10. ì´ˆê¸°í™” ì™„ë£Œ =====
            self.is_initialized = True
            self.logger.info("âœ… ClothSegmentationStep ì´ˆê¸°í™” ì™„ë£Œ (ì˜ì¡´ì„± ì£¼ì… + AI ì—°ë™)")
            self.logger.info(f"   - ë¡œë“œëœ ì²´í¬í¬ì¸íŠ¸: {list(self.checkpoints_loaded.keys())}")
            self.logger.info(f"   - ìƒì„±ëœ AI ëª¨ë¸: {list(self.models_loaded.keys())}")
            self.logger.info(f"   - ì‚¬ìš© ê°€ëŠ¥í•œ ë°©ë²•: {[m.value for m in self.available_methods]}")
            self.logger.info(f"   - ì˜ì¡´ì„± ì£¼ì… íšŸìˆ˜: {self.processing_stats['dependency_injection_calls']}")
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.is_initialized = False
            return False

    def _validate_dependencies(self) -> bool:
        """ì˜ì¡´ì„± ê²€ì¦"""
        try:
            required_dependencies = []
            missing_dependencies = []
            
            if not self.model_loader:
                missing_dependencies.append("ModelLoader")
            else:
                required_dependencies.append("ModelLoader")
            
            if missing_dependencies:
                self.logger.error(f"âŒ í•„ìˆ˜ ì˜ì¡´ì„± ëˆ„ë½: {missing_dependencies}")
                self.logger.error("ğŸ’¡ StepFactoryë¥¼ í†µí•œ ì˜ì¡´ì„± ì£¼ì…ì´ í•„ìš”í•©ë‹ˆë‹¤.")
                return False
            
            self.logger.info(f"âœ… ì˜ì¡´ì„± ê²€ì¦ ì™„ë£Œ: {required_dependencies}")
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ ì˜ì¡´ì„± ê²€ì¦ ì‹¤íŒ¨: {e}")
            return False

    async def _load_checkpoints_via_model_loader(self) -> bool:
        """ModelLoaderë¥¼ í†µí•œ ì²´í¬í¬ì¸íŠ¸ ë¡œë”©"""
        try:
            if not self.model_interface:
                self.logger.error("âŒ ModelLoader ì¸í„°í˜ì´ìŠ¤ê°€ ì—†ì–´ì„œ ì²´í¬í¬ì¸íŠ¸ ë¡œë”© ë¶ˆê°€")
                return False
            
            self.logger.info("ğŸ”„ ModelLoaderë¥¼ í†µí•œ ì²´í¬í¬ì¸íŠ¸ ë¡œë”© ì‹œì‘...")
            
            # Step ìš”ì²­ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            get_step_request, StepModelRequestAnalyzer = safe_import_step_requests()
            if get_step_request:
                step_request = get_step_request(self.step_name)
                if step_request:
                    self.logger.info(f"ğŸ“‹ Step ëª¨ë¸ ìš”ì²­: {step_request.model_name}")
            
            # ===== U2-Net ì²´í¬í¬ì¸íŠ¸ ë¡œë”© =====
            try:
                self.logger.info("ğŸ”„ U2-Net ì²´í¬í¬ì¸íŠ¸ ë¡œë”© ì¤‘...")
                u2net_checkpoint = None
                
                # ModelInterfaceë¥¼ í†µí•œ ë¡œë”© ì‹œë„
                if hasattr(self.model_interface, 'get_model'):
                    u2net_checkpoint = await self.model_interface.get_model("cloth_segmentation_u2net")
                elif hasattr(self.model_interface, 'get_model_sync'):
                    u2net_checkpoint = self.model_interface.get_model_sync("cloth_segmentation_u2net")
                
                # í´ë°±: ModelLoader ì§ì ‘ í˜¸ì¶œ
                if not u2net_checkpoint and self.model_loader:
                    if hasattr(self.model_loader, 'load_model_async'):
                        u2net_checkpoint = await self.model_loader.load_model_async("cloth_segmentation_u2net")
                    elif hasattr(self.model_loader, 'load_model'):
                        u2net_checkpoint = self.model_loader.load_model("cloth_segmentation_u2net")
                
                if u2net_checkpoint:
                    self.checkpoints_loaded['u2net'] = u2net_checkpoint
                    self.logger.info("âœ… U2-Net ì²´í¬í¬ì¸íŠ¸ ë¡œë”© ì™„ë£Œ")
                else:
                    self.logger.warning("âš ï¸ U2-Net ì²´í¬í¬ì¸íŠ¸ ë¡œë”© ì‹¤íŒ¨")
                
            except Exception as e:
                self.logger.warning(f"âš ï¸ U2-Net ì²´í¬í¬ì¸íŠ¸ ë¡œë”© ì‹¤íŒ¨: {e}")
            
            # ===== DeepLab ì²´í¬í¬ì¸íŠ¸ ë¡œë”© (ì„ íƒì ) =====
            try:
                self.logger.info("ğŸ”„ DeepLab ì²´í¬í¬ì¸íŠ¸ ë¡œë”© ì¤‘...")
                deeplab_checkpoint = None
                
                if hasattr(self.model_interface, 'get_model'):
                    deeplab_checkpoint = await self.model_interface.get_model("cloth_segmentation_deeplab")
                elif hasattr(self.model_interface, 'get_model_sync'):
                    deeplab_checkpoint = self.model_interface.get_model_sync("cloth_segmentation_deeplab")
                
                if not deeplab_checkpoint and self.model_loader:
                    if hasattr(self.model_loader, 'load_model_async'):
                        deeplab_checkpoint = await self.model_loader.load_model_async("cloth_segmentation_deeplab")
                    elif hasattr(self.model_loader, 'load_model'):
                        deeplab_checkpoint = self.model_loader.load_model("cloth_segmentation_deeplab")
                
                if deeplab_checkpoint:
                    self.checkpoints_loaded['deeplab'] = deeplab_checkpoint
                    self.logger.info("âœ… DeepLab ì²´í¬í¬ì¸íŠ¸ ë¡œë”© ì™„ë£Œ")
                
            except Exception as e:
                self.logger.warning(f"âš ï¸ DeepLab ì²´í¬í¬ì¸íŠ¸ ë¡œë”© ì‹¤íŒ¨: {e}")
            
            # ===== SAM ì²´í¬í¬ì¸íŠ¸ ë¡œë”© (ì„ íƒì ) =====
            try:
                self.logger.info("ğŸ”„ SAM ì²´í¬í¬ì¸íŠ¸ ë¡œë”© ì¤‘...")
                sam_checkpoint = None
                
                if hasattr(self.model_interface, 'get_model'):
                    sam_checkpoint = await self.model_interface.get_model("cloth_segmentation_sam")
                elif hasattr(self.model_interface, 'get_model_sync'):
                    sam_checkpoint = self.model_interface.get_model_sync("cloth_segmentation_sam")
                
                if not sam_checkpoint and self.model_loader:
                    if hasattr(self.model_loader, 'load_model_async'):
                        sam_checkpoint = await self.model_loader.load_model_async("cloth_segmentation_sam")
                    elif hasattr(self.model_loader, 'load_model'):
                        sam_checkpoint = self.model_loader.load_model("cloth_segmentation_sam")
                
                if sam_checkpoint:
                    self.checkpoints_loaded['sam'] = sam_checkpoint
                    self.logger.info("âœ… SAM ì²´í¬í¬ì¸íŠ¸ ë¡œë”© ì™„ë£Œ")
                
            except Exception as e:
                self.logger.warning(f"âš ï¸ SAM ì²´í¬í¬ì¸íŠ¸ ë¡œë”© ì‹¤íŒ¨: {e}")
            
            # ===== ë¡œë”© ê²°ê³¼ ê²€ì¦ =====
            if not self.checkpoints_loaded:
                self.logger.error("âŒ ì–´ë–¤ ì²´í¬í¬ì¸íŠ¸ë„ ë¡œë”©ë˜ì§€ ì•ŠìŒ")
                return False
            
            self.logger.info(f"ğŸ§  ì²´í¬í¬ì¸íŠ¸ ë¡œë”© ì™„ë£Œ: {list(self.checkpoints_loaded.keys())}")
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ ì²´í¬í¬ì¸íŠ¸ ë¡œë”© ì‹¤íŒ¨: {e}")
            return False

    async def _create_ai_models_from_checkpoints(self) -> bool:
        """ì²´í¬í¬ì¸íŠ¸ì—ì„œ ì‹¤ì œ AI ëª¨ë¸ ìƒì„±"""
        try:
            if not TORCH_AVAILABLE:
                self.logger.error("âŒ PyTorchê°€ ì—†ì–´ì„œ AI ëª¨ë¸ ìƒì„± ë¶ˆê°€")
                return False
            
            self.logger.info("ğŸ”„ ì²´í¬í¬ì¸íŠ¸ì—ì„œ ì‹¤ì œ AI ëª¨ë¸ ìƒì„± ì‹œì‘...")
            
            # ===== U2-Net ëª¨ë¸ ìƒì„± =====
            if 'u2net' in self.checkpoints_loaded:
                try:
                    self.logger.info("ğŸ”„ U2-Net AI ëª¨ë¸ ìƒì„± ì¤‘...")
                    
                    # U2-Net ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
                    u2net_model = U2NET(in_ch=3, out_ch=1)
                    
                    # ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ
                    checkpoint = self.checkpoints_loaded['u2net']
                    if isinstance(checkpoint, dict):
                        # state_dict í˜•íƒœ
                        if 'model' in checkpoint:
                            u2net_model.load_state_dict(checkpoint['model'])
                        elif 'state_dict' in checkpoint:
                            u2net_model.load_state_dict(checkpoint['state_dict'])
                        else:
                            u2net_model.load_state_dict(checkpoint)
                    elif hasattr(checkpoint, 'state_dict'):
                        # PyTorch ëª¨ë¸ í˜•íƒœ
                        u2net_model.load_state_dict(checkpoint.state_dict())
                    else:
                        # ì§ì ‘ state_dict í˜•íƒœ
                        u2net_model.load_state_dict(checkpoint)
                    
                    # ë””ë°”ì´ìŠ¤ ì´ë™ ë° í‰ê°€ ëª¨ë“œ
                    u2net_model = u2net_model.to(self.device)
                    u2net_model.eval()
                    
                    self.models_loaded['u2net'] = u2net_model
                    self.logger.info("âœ… U2-Net AI ëª¨ë¸ ìƒì„± ë° ë¡œë”© ì™„ë£Œ")
                    
                except Exception as e:
                    self.logger.warning(f"âš ï¸ U2-Net AI ëª¨ë¸ ìƒì„± ì‹¤íŒ¨: {e}")
            
            # ===== DeepLab ëª¨ë¸ ìƒì„± (ì„ íƒì ) =====
            if 'deeplab' in self.checkpoints_loaded:
                try:
                    self.logger.info("ğŸ”„ DeepLab AI ëª¨ë¸ ìƒì„± ì¤‘...")
                    
                    # DeepLab ëª¨ë¸ì€ transformers ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš©
                    if TRANSFORMERS_AVAILABLE:
                        from transformers import DeepLabV3ForSemanticSegmentation
                        deeplab_model = DeepLabV3ForSemanticSegmentation.from_pretrained(
                            "facebook/detr-resnet-50-panoptic"
                        )
                        deeplab_model = deeplab_model.to(self.device)
                        deeplab_model.eval()
                        
                        self.models_loaded['deeplab'] = deeplab_model
                        self.logger.info("âœ… DeepLab AI ëª¨ë¸ ìƒì„± ì™„ë£Œ")
                    
                except Exception as e:
                    self.logger.warning(f"âš ï¸ DeepLab AI ëª¨ë¸ ìƒì„± ì‹¤íŒ¨: {e}")
            
            # ===== SAM ëª¨ë¸ ìƒì„± (ì„ íƒì ) =====
            if 'sam' in self.checkpoints_loaded:
                try:
                    self.logger.info("ğŸ”„ SAM AI ëª¨ë¸ ìƒì„± ì¤‘...")
                    
                    if SAM_AVAILABLE:
                        checkpoint = self.checkpoints_loaded['sam']
                        # SAM ëª¨ë¸ ìƒì„± ë¡œì§ (ì‹¤ì œ êµ¬í˜„ ì‹œ ì ì ˆíˆ ìˆ˜ì •)
                        # sam_model = sam.sam_model_registry["vit_h"](checkpoint=checkpoint)
                        # sam_model = sam_model.to(self.device)
                        # sam_model.eval()
                        
                        # ì„ì‹œë¡œ ì²´í¬í¬ì¸íŠ¸ë¥¼ ëª¨ë¸ë¡œ ì‚¬ìš©
                        self.models_loaded['sam'] = checkpoint
                        self.logger.info("âœ… SAM AI ëª¨ë¸ ìƒì„± ì™„ë£Œ")
                    
                except Exception as e:
                    self.logger.warning(f"âš ï¸ SAM AI ëª¨ë¸ ìƒì„± ì‹¤íŒ¨: {e}")
            
            # ===== ìƒì„± ê²°ê³¼ ê²€ì¦ =====
            if not self.models_loaded:
                self.logger.error("âŒ ì–´ë–¤ AI ëª¨ë¸ë„ ìƒì„±ë˜ì§€ ì•ŠìŒ")
                return False
            
            self.logger.info(f"ğŸ§  ì‹¤ì œ AI ëª¨ë¸ ìƒì„± ì™„ë£Œ: {list(self.models_loaded.keys())}")
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ AI ëª¨ë¸ ìƒì„± ì‹¤íŒ¨: {e}")
            return False

    def _validate_loaded_models(self):
        """ë¡œë“œëœ ëª¨ë¸ ê²€ì¦"""
        try:
            for model_name, model in self.models_loaded.items():
                if model is None:
                    raise RuntimeError(f"âŒ {model_name} ëª¨ë¸ì´ Noneì…ë‹ˆë‹¤")
                
                # PyTorch ëª¨ë¸ ê²€ì¦
                if hasattr(model, 'forward') or callable(model):
                    self.logger.info(f"âœ… {model_name} ëª¨ë¸ ì¶”ë¡  ê°€ëŠ¥")
                else:
                    self.logger.warning(f"âš ï¸ {model_name} ëª¨ë¸ ì¶”ë¡  ë¶ˆê°€ëŠ¥")
                
                # ë””ë°”ì´ìŠ¤ ê²€ì¦
                if hasattr(model, 'device'):
                    model_device = str(model.device)
                    if self.device not in model_device:
                        self.logger.warning(f"âš ï¸ {model_name} ëª¨ë¸ ë””ë°”ì´ìŠ¤ ë¶ˆì¼ì¹˜: {model_device} vs {self.device}")
                
                self.logger.info(f"âœ… {model_name} ëª¨ë¸ ê²€ì¦ ì™„ë£Œ")
            
            self.logger.info("âœ… ëª¨ë“  ë¡œë“œëœ AI ëª¨ë¸ ê²€ì¦ ì™„ë£Œ")
            
        except Exception as e:
            self.logger.error(f"âŒ ëª¨ë¸ ê²€ì¦ ì‹¤íŒ¨: {e}")
            raise

    async def _initialize_rembg_sessions(self):
        """RemBG ì„¸ì…˜ ì´ˆê¸°í™”"""
        try:
            if not REMBG_AVAILABLE:
                return
            
            self.logger.info("ğŸ”„ RemBG ì„¸ì…˜ ì´ˆê¸°í™” ì‹œì‘...")
            
            session_configs = {
                'u2net': 'u2net',
                'u2netp': 'u2netp', 
                'silueta': 'silueta',
            }
            
            for name, model_name in session_configs.items():
                try:
                    session = new_session(model_name)
                    self.rembg_sessions[name] = session
                    self.logger.info(f"âœ… RemBG ì„¸ì…˜ ìƒì„±: {name}")
                except Exception as e:
                    self.logger.warning(f"âš ï¸ RemBG ì„¸ì…˜ {name} ìƒì„± ì‹¤íŒ¨: {e}")
            
            if self.rembg_sessions:
                self.default_rembg_session = (
                    self.rembg_sessions.get('u2net') or 
                    list(self.rembg_sessions.values())[0]
                )
                self.logger.info("âœ… RemBG ê¸°ë³¸ ì„¸ì…˜ ì„¤ì • ì™„ë£Œ")
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ RemBG ì„¸ì…˜ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")

    async def _warmup_m3_max(self):
        """M3 Max ì›Œë°ì—…"""
        try:
            if not self.is_m3_max or not TORCH_AVAILABLE:
                return
            
            self.logger.info("ğŸ”¥ M3 Max ì›Œë°ì—… ì‹œì‘...")
            
            # ë”ë¯¸ í…ì„œë¡œ ì›Œë°ì—…
            dummy_input = torch.randn(1, 3, 512, 512, device=self.device)
            
            for model_name, model in self.models_loaded.items():
                try:
                    if hasattr(model, 'eval'):
                        model.eval()
                        with torch.no_grad():
                            if hasattr(model, 'forward'):
                                _ = model(dummy_input)
                            elif callable(model):
                                _ = model(dummy_input)
                        self.logger.info(f"âœ… {model_name} M3 Max ì›Œë°ì—… ì™„ë£Œ")
                except Exception as e:
                    self.logger.warning(f"âš ï¸ {model_name} ì›Œë°ì—… ì‹¤íŒ¨: {e}")
            
            # MPS ìºì‹œ ì •ë¦¬
            if MPS_AVAILABLE:
                try:
                    torch.mps.empty_cache()
                except:
                    pass
            
            self.logger.info("âœ… M3 Max ì›Œë°ì—… ì™„ë£Œ")
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ M3 Max ì›Œë°ì—… ì‹¤íŒ¨: {e}")

    def _initialize_visualization_system(self):
        """ì‹œê°í™” ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
        try:
            self.visualization_config = {
                'mask_alpha': 0.7,
                'overlay_alpha': 0.5,
                'boundary_thickness': 2,
                'color_intensity': 200
            }
            
            # í°íŠ¸ ì„¤ì •
            if PIL_AVAILABLE:
                try:
                    self.font = ImageFont.truetype("/System/Library/Fonts/Helvetica.ttc", 16)
                except Exception:
                    try:
                        self.font = ImageFont.load_default()
                    except Exception:
                        self.font = None
            else:
                self.font = None
            
            self.logger.info("âœ… ì‹œê°í™” ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ ì‹œê°í™” ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")

    def _detect_available_methods(self) -> List[SegmentationMethod]:
        """ì‚¬ìš© ê°€ëŠ¥í•œ ì„¸ê·¸ë©˜í…Œì´ì…˜ ë°©ë²• ê°ì§€ (ì‹¤ì œ AI ê¸°ë°˜)"""
        methods = []
        
        # ë¡œë“œëœ AI ëª¨ë¸ ê¸°ë°˜ìœ¼ë¡œ ë°©ë²• ê²°ì •
        if 'u2net' in self.models_loaded:
            methods.append(SegmentationMethod.U2NET)
            self.logger.info("âœ… U2NET ë°©ë²• ì‚¬ìš© ê°€ëŠ¥ (ì‹¤ì œ AI ëª¨ë¸)")
        
        if 'deeplab' in self.models_loaded:
            methods.append(SegmentationMethod.DEEP_LAB)
            self.logger.info("âœ… DeepLab ë°©ë²• ì‚¬ìš© ê°€ëŠ¥ (ì‹¤ì œ AI ëª¨ë¸)")
        
        if 'sam' in self.models_loaded:
            methods.append(SegmentationMethod.SAM)
            self.logger.info("âœ… SAM ë°©ë²• ì‚¬ìš© ê°€ëŠ¥ (ì‹¤ì œ AI ëª¨ë¸)")
        
        # RemBG í™•ì¸
        if REMBG_AVAILABLE and self.rembg_sessions:
            methods.append(SegmentationMethod.REMBG)
            self.logger.info("âœ… RemBG ë°©ë²• ì‚¬ìš© ê°€ëŠ¥")
        
        # Traditional ë°©ë²• (ë³´ì¡° ë°©ë²•)
        if OPENCV_AVAILABLE and SKLEARN_AVAILABLE:
            methods.append(SegmentationMethod.TRADITIONAL)
            self.logger.info("âœ… Traditional ë°©ë²• ì‚¬ìš© ê°€ëŠ¥")
        
        # AUTO ë°©ë²• (AI ëª¨ë¸ì´ ìˆì„ ë•Œë§Œ)
        ai_methods = [m for m in methods if m != SegmentationMethod.TRADITIONAL]
        if ai_methods:
            methods.append(SegmentationMethod.AUTO)
            self.logger.info("âœ… AUTO ë°©ë²• ì‚¬ìš© ê°€ëŠ¥")
        
        # HYBRID ë°©ë²• (2ê°œ ì´ìƒ AI ë°©ë²•ì´ ìˆì„ ë•Œ)
        if len(ai_methods) >= 2:
            methods.append(SegmentationMethod.HYBRID)
            self.logger.info("âœ… HYBRID ë°©ë²• ì‚¬ìš© ê°€ëŠ¥")
        
        return methods

    # ==============================================
    # ğŸ”¥ 10. í•µì‹¬: process ë©”ì„œë“œ (ì‹¤ì œ AI ì¶”ë¡ )
    # ==============================================
    
    async def process(
        self,
        image,
        clothing_type: Optional[str] = None,
        quality_level: Optional[str] = None,
        **kwargs
    ) -> Dict[str, Any]:
        """
        ğŸ”¥ ë©”ì¸ ì²˜ë¦¬ ë©”ì„œë“œ - ì˜ì¡´ì„± ì£¼ì… + ì‹¤ì œ AI ì¶”ë¡ 
        """
        
        if not self.is_initialized:
            if not await self.initialize():
                return self._create_error_result("ì´ˆê¸°í™” ì‹¤íŒ¨")
        
        start_time = time.time()
        
        try:
            self.logger.info("ğŸ”„ ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ ì²˜ë¦¬ ì‹œì‘ (ì˜ì¡´ì„± ì£¼ì… + AI ì¶”ë¡ )")
            
            # ===== 1. ì´ë¯¸ì§€ ì „ì²˜ë¦¬ =====
            processed_image = self._preprocess_image(image)
            if processed_image is None:
                return self._create_error_result("ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì‹¤íŒ¨")
            
            # ===== 2. ì˜ë¥˜ íƒ€ì… ê°ì§€ =====
            detected_clothing_type = self._detect_clothing_type(processed_image, clothing_type)
            
            # ===== 3. í’ˆì§ˆ ë ˆë²¨ ì„¤ì • =====
            quality = QualityLevel(quality_level or self.segmentation_config.quality_level.value)
            
            # ===== 4. ì‹¤ì œ AI ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‹¤í–‰ =====
            mask, confidence = await self._run_ai_segmentation(
                processed_image, detected_clothing_type, quality
            )
            
            if mask is None:
                return self._create_error_result("AI ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‹¤íŒ¨")
            
            # ===== 5. í›„ì²˜ë¦¬ =====
            final_mask = self._post_process_mask(mask, quality)
            
            # ===== 6. ì‹œê°í™” ì´ë¯¸ì§€ ìƒì„± =====
            visualizations = {}
            if self.segmentation_config.enable_visualization:
                visualizations = self._create_visualizations(
                    processed_image, final_mask, detected_clothing_type
                )
            
            # ===== 7. ê²°ê³¼ ìƒì„± =====
            processing_time = time.time() - start_time
            
            result = {
                'success': True,
                'mask': final_mask,
                'confidence': confidence,
                'clothing_type': detected_clothing_type.value if hasattr(detected_clothing_type, 'value') else str(detected_clothing_type),
                'processing_time': processing_time,
                'method_used': self._get_current_method(),
                'ai_models_used': list(self.models_loaded.keys()),
                'metadata': {
                    'device': self.device,
                    'quality_level': quality.value,
                    'models_used': list(self.models_loaded.keys()),
                    'checkpoints_loaded': list(self.checkpoints_loaded.keys()),
                    'image_size': processed_image.size if hasattr(processed_image, 'size') else (512, 512),
                    'dependency_injection_enabled': self.segmentation_config.enable_dependency_injection,
                    'dependency_injection_calls': self.processing_stats['dependency_injection_calls'],
                    'ai_inference': True,
                    'model_loader_used': self.model_loader is not None,
                    'memory_manager_used': self.memory_manager is not None,
                    'is_m3_max': self.is_m3_max
                },
                'dependency_injection_info': {
                    'model_loader_injected': self.model_loader is not None,
                    'memory_manager_injected': self.memory_manager is not None,
                    'data_converter_injected': self.data_converter is not None,
                    'di_container_injected': self.di_container is not None,
                    'step_factory_injected': self.step_factory is not None,
                    'total_injection_calls': self.processing_stats['dependency_injection_calls']
                }
            }
            
            # ì‹œê°í™” ì´ë¯¸ì§€ë“¤ ì¶”ê°€
            if visualizations:
                if 'visualization' in visualizations:
                    result['visualization_base64'] = self._image_to_base64(visualizations['visualization'])
                if 'overlay' in visualizations:
                    result['overlay_base64'] = self._image_to_base64(visualizations['overlay'])
                if 'mask' in visualizations:
                    result['mask_base64'] = self._image_to_base64(visualizations['mask'])
                if 'boundary' in visualizations:
                    result['boundary_base64'] = self._image_to_base64(visualizations['boundary'])
            
            # í†µê³„ ì—…ë°ì´íŠ¸
            self._update_processing_stats(processing_time, True)
            
            self.logger.info(f"âœ… ì˜ì¡´ì„± ì£¼ì… + AI ì„¸ê·¸ë©˜í…Œì´ì…˜ ì™„ë£Œ - {processing_time:.2f}ì´ˆ")
            return result
            
        except Exception as e:
            processing_time = time.time() - start_time
            self._update_processing_stats(processing_time, False)
            
            self.logger.error(f"âŒ ì˜ì¡´ì„± ì£¼ì… + AI ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return self._create_error_result(f"ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")

    async def _run_ai_segmentation(
        self,
        image: Image.Image,
        clothing_type: ClothingType,
        quality: QualityLevel
    ) -> Tuple[Optional[np.ndarray], float]:
        """
        ğŸ”¥ ì‹¤ì œ AI ì„¸ê·¸ë©˜í…Œì´ì…˜ ì¶”ë¡  (ì˜ì¡´ì„± ì£¼ì…ëœ ëª¨ë¸ ì‚¬ìš©)
        """
        try:
            # ìš°ì„ ìˆœìœ„ ìˆœì„œë¡œ AI ë°©ë²• ì‹œë„
            methods_to_try = self._get_ai_methods_by_priority(quality)
            
            for method in methods_to_try:
                try:
                    self.logger.info(f"ğŸ§  AI ë°©ë²• ì‹œë„: {method.value}")
                    mask, confidence = await self._run_ai_method(method, image, clothing_type)
                    
                    if mask is not None:
                        # AI ëª¨ë¸ í˜¸ì¶œ í†µê³„ ì—…ë°ì´íŠ¸
                        self.processing_stats['ai_model_calls'] += 1
                        self.processing_stats['method_usage'][method.value] = (
                            self.processing_stats['method_usage'].get(method.value, 0) + 1
                        )
                        
                        self.logger.info(f"âœ… AI ì„¸ê·¸ë©˜í…Œì´ì…˜ ì„±ê³µ: {method.value} (ì‹ ë¢°ë„: {confidence:.3f})")
                        return mask, confidence
                        
                except Exception as e:
                    self.logger.warning(f"âš ï¸ AI ë°©ë²• {method.value} ì‹¤íŒ¨: {e}")
                    continue
            
            # ëª¨ë“  AI ë°©ë²• ì‹¤íŒ¨
            self.logger.error("âŒ ëª¨ë“  AI ì„¸ê·¸ë©˜í…Œì´ì…˜ ë°©ë²• ì‹¤íŒ¨")
            return None, 0.0
            
        except Exception as e:
            self.logger.error(f"âŒ AI ì„¸ê·¸ë©˜í…Œì´ì…˜ ì¶”ë¡  ì‹¤íŒ¨: {e}")
            return None, 0.0

    def _get_ai_methods_by_priority(self, quality: QualityLevel) -> List[SegmentationMethod]:
        """í’ˆì§ˆ ë ˆë²¨ë³„ AI ë°©ë²• ìš°ì„ ìˆœìœ„"""
        
        # ì‹¤ì œ ì‚¬ìš© ê°€ëŠ¥í•œ AI ë°©ë²•ë§Œ í•„í„°ë§
        available_ai_methods = [
            method for method in self.available_methods 
            if method not in [SegmentationMethod.TRADITIONAL, SegmentationMethod.AUTO, SegmentationMethod.HYBRID]
        ]
        
        if quality == QualityLevel.ULTRA:
            priority = [
                SegmentationMethod.U2NET,
                SegmentationMethod.SAM,
                SegmentationMethod.DEEP_LAB,
                SegmentationMethod.REMBG
            ]
        elif quality == QualityLevel.HIGH:
            priority = [
                SegmentationMethod.U2NET,
                SegmentationMethod.REMBG,
                SegmentationMethod.DEEP_LAB,
                SegmentationMethod.SAM
            ]
        elif quality == QualityLevel.BALANCED:
            priority = [
                SegmentationMethod.REMBG,
                SegmentationMethod.U2NET,
                SegmentationMethod.DEEP_LAB
            ]
        else:  # FAST
            priority = [
                SegmentationMethod.REMBG,
                SegmentationMethod.U2NET
            ]
        
        # ì‹¤ì œ ì‚¬ìš© ê°€ëŠ¥í•œ ë°©ë²•ë§Œ ë°˜í™˜
        return [method for method in priority if method in available_ai_methods]

    async def _run_ai_method(
        self,
        method: SegmentationMethod,
        image: Image.Image,
        clothing_type: ClothingType
    ) -> Tuple[Optional[np.ndarray], float]:
        """ê°œë³„ AI ì„¸ê·¸ë©˜í…Œì´ì…˜ ë°©ë²• ì‹¤í–‰"""
        
        if method == SegmentationMethod.U2NET:
            return await self._run_u2net_inference(image)
        elif method == SegmentationMethod.REMBG:
            return await self._run_rembg_inference(image)
        elif method == SegmentationMethod.SAM:
            return await self._run_sam_inference(image)
        elif method == SegmentationMethod.DEEP_LAB:
            return await self._run_deeplab_inference(image)
        else:
            raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” AI ë°©ë²•: {method}")

    async def _run_u2net_inference(self, image: Image.Image) -> Tuple[Optional[np.ndarray], float]:
        """
        ğŸ”¥ U2-Net ì‹¤ì œ AI ì¶”ë¡  (ì˜ì¡´ì„± ì£¼ì…ëœ ëª¨ë¸ ì‚¬ìš©)
        """
        try:
            if 'u2net' not in self.models_loaded:
                raise RuntimeError("âŒ U2-Net ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•ŠìŒ")
            
            model = self.models_loaded['u2net']
            
            # ì´ë¯¸ì§€ ì „ì²˜ë¦¬
            if not TORCH_AVAILABLE:
                raise RuntimeError("âŒ PyTorchê°€ í•„ìš”í•©ë‹ˆë‹¤")
            
            transform = transforms.Compose([
                transforms.ToTensor(),
                transforms.Normalize(mean=[0.485, 0.456, 0.406], 
                                   std=[0.229, 0.224, 0.225])
            ])
            
            input_tensor = transform(image).unsqueeze(0).to(self.device)
            
            # ğŸ”¥ ì‹¤ì œ AI ëª¨ë¸ ì¶”ë¡ 
            model.eval()
            with torch.no_grad():
                if self.is_m3_max and self.segmentation_config.use_fp16:
                    with torch.autocast(device_type='cpu'):  # M3 MaxëŠ” CPU autocast ì‚¬ìš©
                        output = model(input_tensor)
                else:
                    output = model(input_tensor)
                
                # ì¶œë ¥ ì²˜ë¦¬
                if isinstance(output, tuple):
                    output = output[0]  # ì²« ë²ˆì§¸ ì¶œë ¥ ì‚¬ìš©
                elif isinstance(output, list):
                    output = output[0]
                
                # ì‹œê·¸ëª¨ì´ë“œ ë° ì„ê³„ê°’ ì²˜ë¦¬
                if output.max() > 1.0:
                    prob_map = torch.sigmoid(output)
                else:
                    prob_map = output
                
                mask = (prob_map > self.segmentation_config.confidence_threshold).float()
                
                # CPUë¡œ ì´ë™ ë° NumPy ë³€í™˜
                mask_np = mask.squeeze().cpu().numpy()
                confidence = float(prob_map.max().item())
            
            self.logger.info(f"âœ… U2-Net AI ì¶”ë¡  ì™„ë£Œ - ì‹ ë¢°ë„: {confidence:.3f}")
            return mask_np, confidence
            
        except Exception as e:
            self.logger.error(f"âŒ U2-Net AI ì¶”ë¡  ì‹¤íŒ¨: {e}")
            raise

    async def _run_rembg_inference(self, image: Image.Image) -> Tuple[Optional[np.ndarray], float]:
        """RemBG AI ì¶”ë¡ """
        try:
            if not self.rembg_sessions:
                raise RuntimeError("âŒ RemBG ì„¸ì…˜ì´ ì—†ìŒ")
            
            # ìµœì  ì„¸ì…˜ ì„ íƒ
            session = (
                self.rembg_sessions.get('u2net') or
                list(self.rembg_sessions.values())[0]
            )
            
            # ğŸ”¥ ì‹¤ì œ RemBG AI ì¶”ë¡ 
            result = remove(image, session=session)
            
            # ì•ŒíŒŒ ì±„ë„ì—ì„œ ë§ˆìŠ¤í¬ ì¶”ì¶œ
            if result.mode == 'RGBA':
                mask = np.array(result)[:, :, 3]  # ì•ŒíŒŒ ì±„ë„
                mask = (mask > 128).astype(np.uint8)  # ì´ì§„í™”
                
                # ì‹ ë¢°ë„ ê³„ì‚°
                confidence = np.sum(mask) / mask.size
                confidence = min(confidence * 2, 1.0)  # ì •ê·œí™”
                
                self.logger.info(f"âœ… RemBG AI ì¶”ë¡  ì™„ë£Œ - ì‹ ë¢°ë„: {confidence:.3f}")
                return mask, confidence
            else:
                raise RuntimeError("âŒ RemBG ê²°ê³¼ì— ì•ŒíŒŒ ì±„ë„ì´ ì—†ìŒ")
                
        except Exception as e:
            self.logger.error(f"âŒ RemBG AI ì¶”ë¡  ì‹¤íŒ¨: {e}")
            raise

    async def _run_sam_inference(self, image: Image.Image) -> Tuple[Optional[np.ndarray], float]:
        """SAM AI ì¶”ë¡ """
        try:
            if 'sam' not in self.models_loaded:
                raise RuntimeError("âŒ SAM ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•ŠìŒ")
            
            model = self.models_loaded['sam']
            
            # ğŸ”¥ ì‹¤ì œ SAM AI ì¶”ë¡  (ê°„ë‹¨í•œ êµ¬í˜„)
            image_array = np.array(image)
            
            if hasattr(model, 'forward') and TORCH_AVAILABLE:
                # í…ì„œ ë³€í™˜
                input_tensor = torch.from_numpy(image_array).permute(2, 0, 1).unsqueeze(0).float().to(self.device)
                input_tensor = input_tensor / 255.0
                
                model.eval()
                with torch.no_grad():
                    output = model(input_tensor)
                
                if isinstance(output, dict) and 'masks' in output:
                    mask = output['masks'][0].cpu().numpy()
                elif torch.is_tensor(output):
                    mask = output.squeeze().cpu().numpy()
                else:
                    raise RuntimeError("âŒ SAM ì¶œë ¥ í˜•ì‹ì„ ì•Œ ìˆ˜ ì—†ìŒ")
                
                mask = (mask > 0.5).astype(np.uint8)
                confidence = 0.8  # SAMì€ ì¼ë°˜ì ìœ¼ë¡œ ë†’ì€ ì‹ ë¢°ë„
                
                self.logger.info(f"âœ… SAM AI ì¶”ë¡  ì™„ë£Œ - ì‹ ë¢°ë„: {confidence:.3f}")
                return mask, confidence
            else:
                # í´ë°±: ê°„ë‹¨í•œ ì„¸ê·¸ë©˜í…Œì´ì…˜
                mask = np.ones((image_array.shape[0], image_array.shape[1]), dtype=np.uint8)
                confidence = 0.5
                return mask, confidence
                
        except Exception as e:
            self.logger.error(f"âŒ SAM AI ì¶”ë¡  ì‹¤íŒ¨: {e}")
            raise

    async def _run_deeplab_inference(self, image: Image.Image) -> Tuple[Optional[np.ndarray], float]:
        """DeepLab AI ì¶”ë¡ """
        try:
            if 'deeplab' not in self.models_loaded:
                raise RuntimeError("âŒ DeepLab ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•ŠìŒ")
            
            model = self.models_loaded['deeplab']
            
            # ğŸ”¥ ì‹¤ì œ DeepLab AI ì¶”ë¡ 
            if TORCH_AVAILABLE:
                # ì´ë¯¸ì§€ ì „ì²˜ë¦¬
                transform = transforms.Compose([
                    transforms.ToTensor(),
                    transforms.Normalize(mean=[0.485, 0.456, 0.406], 
                                       std=[0.229, 0.224, 0.225])
                ])
                
                input_tensor = transform(image).unsqueeze(0).to(self.device)
                
                model.eval()
                with torch.no_grad():
                    output = model(input_tensor)
                    
                    # DeepLab ì¶œë ¥ ì²˜ë¦¬
                    if isinstance(output, dict):
                        if 'out' in output:
                            logits = output['out']
                        else:
                            logits = list(output.values())[0]
                    else:
                        logits = output
                    
                    # ì‚¬ëŒ/ì˜ë¥˜ í´ë˜ìŠ¤ ì¶”ì¶œ (í´ë˜ìŠ¤ ì¸ë±ìŠ¤ëŠ” ëª¨ë¸ì— ë”°ë¼ ë‹¤ë¦„)
                    person_mask = torch.argmax(logits, dim=1) == 1  # ì‚¬ëŒ í´ë˜ìŠ¤
                    mask = person_mask.squeeze().cpu().numpy().astype(np.uint8)
                    
                    # ì‹ ë¢°ë„ ê³„ì‚°
                    confidence_map = torch.softmax(logits, dim=1)[:, 1, :, :]  # ì‚¬ëŒ í´ë˜ìŠ¤ í™•ë¥ 
                    confidence = float(confidence_map.max().item())
                    
                    self.logger.info(f"âœ… DeepLab AI ì¶”ë¡  ì™„ë£Œ - ì‹ ë¢°ë„: {confidence:.3f}")
                    return mask, confidence
            else:
                raise RuntimeError("âŒ PyTorchê°€ í•„ìš”í•©ë‹ˆë‹¤")
                
        except Exception as e:
            self.logger.error(f"âŒ DeepLab AI ì¶”ë¡  ì‹¤íŒ¨: {e}")
            raise

    # ==============================================
    # ğŸ”¥ 11. ì´ë¯¸ì§€ ì²˜ë¦¬ ë° í›„ì²˜ë¦¬ ë©”ì„œë“œë“¤
    # ==============================================
    
    def _preprocess_image(self, image):
        """ì´ë¯¸ì§€ ì „ì²˜ë¦¬"""
        try:
            # ì…ë ¥ íƒ€ì…ë³„ ì²˜ë¦¬
            if isinstance(image, str):
                if image.startswith('data:image'):
                    # Base64
                    header, data = image.split(',', 1)
                    image_data = base64.b64decode(data)
                    image = Image.open(BytesIO(image_data))
                else:
                    # íŒŒì¼ ê²½ë¡œ
                    image = Image.open(image)
            elif isinstance(image, np.ndarray):
                if image.shape[2] == 3:  # RGB
                    image = Image.fromarray(image)
                elif image.shape[2] == 4:  # RGBA
                    image = Image.fromarray(image).convert('RGB')
                else:
                    raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì´ë¯¸ì§€ í˜•íƒœ: {image.shape}")
            elif not isinstance(image, Image.Image):
                raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì´ë¯¸ì§€ íƒ€ì…: {type(image)}")
            
            # RGB ë³€í™˜
            if image.mode != 'RGB':
                image = image.convert('RGB')
            
            # í¬ê¸° ì¡°ì •
            target_size = self.segmentation_config.input_size
            if image.size != target_size:
                image = image.resize(target_size, Image.Resampling.LANCZOS)
            
            return image
                
        except Exception as e:
            self.logger.error(f"âŒ ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return None

    def _detect_clothing_type(self, image, hint=None):
        """ì˜ë¥˜ íƒ€ì… ê°ì§€"""
        if hint:
            try:
                return ClothingType(hint.lower())
            except ValueError:
                pass
        
        # ê°„ë‹¨í•œ íœ´ë¦¬ìŠ¤í‹± ê¸°ë°˜ ê°ì§€
        if hasattr(image, 'size'):
            width, height = image.size
            aspect_ratio = height / width
            
            if aspect_ratio > 1.5:
                return ClothingType.DRESS
            elif aspect_ratio > 1.2:
                return ClothingType.SHIRT
            else:
                return ClothingType.PANTS
        
        return ClothingType.UNKNOWN

    def _post_process_mask(self, mask, quality):
        """ë§ˆìŠ¤í¬ í›„ì²˜ë¦¬"""
        try:
            if not OPENCV_AVAILABLE or not NUMPY_AVAILABLE:
                return mask
            
            processed_mask = mask.copy()
            
            if self.segmentation_config.remove_noise:
                # ë…¸ì´ì¦ˆ ì œê±°
                kernel_size = 3 if quality == QualityLevel.FAST else 5
                kernel = np.ones((kernel_size, kernel_size), np.uint8)
                processed_mask = cv2.morphologyEx(processed_mask, cv2.MORPH_OPEN, kernel)
                processed_mask = cv2.morphologyEx(processed_mask, cv2.MORPH_CLOSE, kernel)
            
            if self.segmentation_config.edge_smoothing:
                # ì—£ì§€ ìŠ¤ë¬´ë”©
                processed_mask = cv2.GaussianBlur(processed_mask.astype(np.float32), (3, 3), 0.5)
                processed_mask = (processed_mask > 0.5).astype(np.uint8)
            
            # í™€ ì±„ìš°ê¸°
            if self.segmentation_config.enable_hole_filling:
                processed_mask = self._fill_holes(processed_mask)
            
            # ê²½ê³„ ê°œì„ 
            if self.segmentation_config.enable_edge_refinement:
                processed_mask = self._refine_edges(processed_mask)
            
            return processed_mask
        except Exception as e:
            self.logger.warning(f"âš ï¸ ë§ˆìŠ¤í¬ í›„ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return mask

    def _fill_holes(self, mask: np.ndarray) -> np.ndarray:
        """ë§ˆìŠ¤í¬ ë‚´ë¶€ í™€ ì±„ìš°ê¸°"""
        try:
            if not OPENCV_AVAILABLE:
                return mask
            
            contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            filled_mask = np.zeros_like(mask)
            for contour in contours:
                cv2.fillPoly(filled_mask, [contour], 1)
            return filled_mask
        except Exception as e:
            self.logger.warning(f"âš ï¸ í™€ ì±„ìš°ê¸° ì‹¤íŒ¨: {e}")
            return mask

    def _refine_edges(self, mask: np.ndarray) -> np.ndarray:
        """ê²½ê³„ ê°œì„ """
        try:
            if not OPENCV_AVAILABLE:
                return mask
            
            if self.segmentation_config.enable_edge_refinement:
                # ê²½ê³„ ê²€ì¶œ
                edges = cv2.Canny(mask, 50, 150)
                
                # ê²½ê³„ ì£¼ë³€ ì˜ì—­ í™•ì¥
                kernel = np.ones((5, 5), np.uint8)
                edge_region = cv2.dilate(edges, kernel, iterations=1)
                
                # í•´ë‹¹ ì˜ì—­ì— ê°€ìš°ì‹œì•ˆ ë¸”ëŸ¬ ì ìš©
                blurred_mask = cv2.GaussianBlur(mask.astype(np.float32), (5, 5), 1.0)
                
                # ê²½ê³„ ì˜ì—­ë§Œ ë¸”ëŸ¬ëœ ê°’ìœ¼ë¡œ êµì²´
                refined_mask = mask.copy().astype(np.float32)
                refined_mask[edge_region > 0] = blurred_mask[edge_region > 0]
                
                return (refined_mask > 0.5).astype(np.uint8)
            
            return mask
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ ê²½ê³„ ê°œì„  ì‹¤íŒ¨: {e}")
            return mask

    # ==============================================
    # ğŸ”¥ 12. ì‹œê°í™” ë©”ì„œë“œë“¤
    # ==============================================

    def _create_visualizations(self, image, mask, clothing_type):
        """ì‹œê°í™” ì´ë¯¸ì§€ ìƒì„±"""
        try:
            if not PIL_AVAILABLE or not NUMPY_AVAILABLE:
                return {}
            
            visualizations = {}
            
            # ìƒ‰ìƒ ì„ íƒ
            color = CLOTHING_COLORS.get(
                clothing_type.value if hasattr(clothing_type, 'value') else str(clothing_type), 
                CLOTHING_COLORS['unknown']
            )
            
            # 1. ë§ˆìŠ¤í¬ ì´ë¯¸ì§€ (ìƒ‰ìƒ êµ¬ë¶„)
            mask_colored = np.zeros((*mask.shape, 3), dtype=np.uint8)
            mask_colored[mask > 0] = color
            visualizations['mask'] = Image.fromarray(mask_colored)
            
            # 2. ì˜¤ë²„ë ˆì´ ì´ë¯¸ì§€
            image_array = np.array(image)
            overlay = image_array.copy()
            alpha = self.segmentation_config.overlay_opacity
            overlay[mask > 0] = (
                overlay[mask > 0] * (1 - alpha) + 
                np.array(color) * alpha
            ).astype(np.uint8)
            
            # ê²½ê³„ì„  ì¶”ê°€ (OpenCV ì‚¬ìš© ê°€ëŠ¥í•œ ê²½ìš°)
            if OPENCV_AVAILABLE:
                boundary = cv2.Canny((mask * 255).astype(np.uint8), 50, 150)
                overlay[boundary > 0] = (255, 255, 255)
            
            visualizations['overlay'] = Image.fromarray(overlay)
            
            # 3. ê²½ê³„ì„  ì´ë¯¸ì§€
            if OPENCV_AVAILABLE:
                boundary = cv2.Canny((mask * 255).astype(np.uint8), 50, 150)
                boundary_colored = np.zeros((*boundary.shape, 3), dtype=np.uint8)
                boundary_colored[boundary > 0] = (255, 255, 255)
                
                boundary_overlay = image_array.copy()
                boundary_overlay[boundary > 0] = (255, 255, 255)
                visualizations['boundary'] = Image.fromarray(boundary_overlay)
            
            # 4. ì¢…í•© ì‹œê°í™” ì´ë¯¸ì§€
            visualization = self._create_comprehensive_visualization(
                image, mask, clothing_type, color
            )
            visualizations['visualization'] = visualization
            
            return visualizations
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ ì‹œê°í™” ìƒì„± ì‹¤íŒ¨: {e}")
            return {}

    def _create_comprehensive_visualization(self, image, mask, clothing_type, color):
        """ì¢…í•© ì‹œê°í™” ì´ë¯¸ì§€ ìƒì„±"""
        try:
            if not PIL_AVAILABLE:
                return image
            
            # ìº”ë²„ìŠ¤ ìƒì„±
            width, height = image.size
            canvas_width = width * 2 + 20
            canvas_height = height + 60
            
            canvas = Image.new('RGB', (canvas_width, canvas_height), (240, 240, 240))
            
            # ì›ë³¸ ì´ë¯¸ì§€ ë°°ì¹˜
            canvas.paste(image, (10, 30))
            
            # ë§ˆìŠ¤í¬ ì˜¤ë²„ë ˆì´ ì´ë¯¸ì§€ ìƒì„±
            image_array = np.array(image)
            overlay = image_array.copy()
            alpha = self.segmentation_config.overlay_opacity
            overlay[mask > 0] = (
                overlay[mask > 0] * (1 - alpha) + 
                np.array(color) * alpha
            ).astype(np.uint8)
            
            # ê²½ê³„ì„  ì¶”ê°€
            if OPENCV_AVAILABLE:
                boundary = cv2.Canny((mask * 255).astype(np.uint8), 50, 150)
                overlay[boundary > 0] = (255, 255, 255)
            
            overlay_image = Image.fromarray(overlay)
            canvas.paste(overlay_image, (width + 20, 30))
            
            # í…ìŠ¤íŠ¸ ì •ë³´ ì¶”ê°€
            if self.font:
                draw = ImageDraw.Draw(canvas)
                
                # ì œëª©
                draw.text((10, 5), "Original", fill=(0, 0, 0), font=self.font)
                clothing_type_str = clothing_type.value if hasattr(clothing_type, 'value') else str(clothing_type)
                draw.text((width + 20, 5), f"AI Segmented ({clothing_type_str})", 
                         fill=(0, 0, 0), font=self.font)
                
                # í†µê³„ ì •ë³´
                mask_area = np.sum(mask)
                total_area = mask.size
                coverage = (mask_area / total_area) * 100
                
                info_text = f"Coverage: {coverage:.1f}% | AI Models: {len(self.models_loaded)} | DI: ON"
                draw.text((10, height + 35), info_text, fill=(0, 0, 0), font=self.font)
            
            return canvas
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ ì¢…í•© ì‹œê°í™” ìƒì„± ì‹¤íŒ¨: {e}")
            return image

    # ==============================================
    # ğŸ”¥ 13. ìœ í‹¸ë¦¬í‹° ë©”ì„œë“œë“¤
    # ==============================================

    def _get_current_method(self):
        """í˜„ì¬ ì‚¬ìš©ëœ ë°©ë²• ë°˜í™˜"""
        if self.models_loaded.get('u2net'):
            return 'u2net_ai_di'
        elif self.models_loaded.get('deeplab'):
            return 'deeplab_ai_di'
        elif self.models_loaded.get('sam'):
            return 'sam_ai_di'
        elif self.rembg_sessions:
            return 'rembg_ai'
        else:
            return 'traditional'

    def _image_to_base64(self, image):
        """ì´ë¯¸ì§€ë¥¼ Base64ë¡œ ì¸ì½”ë”©"""
        try:
            if not PIL_AVAILABLE:
                return ""
            
            buffer = BytesIO()
            if isinstance(image, Image.Image):
                image.save(buffer, format='PNG')
            else:
                img = Image.fromarray(image)
                img.save(buffer, format='PNG')
            image_data = buffer.getvalue()
            return base64.b64encode(image_data).decode()
        except Exception as e:
            self.logger.warning(f"âš ï¸ Base64 ì¸ì½”ë”© ì‹¤íŒ¨: {e}")
            return ""

    def _create_error_result(self, error_message: str) -> Dict[str, Any]:
        """ì—ëŸ¬ ê²°ê³¼ ìƒì„±"""
        return {
            'success': False,
            'error': error_message,
            'mask': None,
            'confidence': 0.0,
            'processing_time': 0.0,
            'method_used': 'error',
            'ai_models_used': [],
            'metadata': {
                'error_details': error_message,
                'available_models': list(self.models_loaded.keys()),
                'dependency_injection_enabled': self.segmentation_config.enable_dependency_injection,
                'dependency_injection_calls': self.processing_stats['dependency_injection_calls']
            },
            'dependency_injection_info': {
                'model_loader_injected': self.model_loader is not None,
                'memory_manager_injected': self.memory_manager is not None,
                'data_converter_injected': self.data_converter is not None,
                'di_container_injected': self.di_container is not None,
                'error_in_dependency_injection': True
            }
        }

    def _update_processing_stats(self, processing_time: float, success: bool):
        """ì²˜ë¦¬ í†µê³„ ì—…ë°ì´íŠ¸"""
        try:
            self.processing_stats['total_processed'] += 1
            if success:
                self.processing_stats['successful_segmentations'] += 1
            else:
                self.processing_stats['failed_segmentations'] += 1
            
            # í‰ê·  ì‹œê°„ ì—…ë°ì´íŠ¸
            total = self.processing_stats['total_processed']
            current_avg = self.processing_stats['average_time']
            self.processing_stats['average_time'] = (
                (current_avg * (total - 1) + processing_time) / total
            )
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ í†µê³„ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")

    # ==============================================
    # ğŸ”¥ 14. ê³ ê¸‰ ê¸°ëŠ¥ ë©”ì„œë“œë“¤ (í˜¸í™˜ì„±)
    # ==============================================

    async def segment_clothing(self, image, **kwargs):
        """ê¸°ì¡´ í˜¸í™˜ì„± ë©”ì„œë“œ"""
        return await self.process(image, **kwargs)

    def get_segmentation_info(self) -> Dict[str, Any]:
        """ì„¸ê·¸ë©˜í…Œì´ì…˜ ì •ë³´ ë°˜í™˜ (ì˜ì¡´ì„± ì£¼ì… ì •ë³´ í¬í•¨)"""
        return {
            'step_name': self.step_name,
            'device': self.device,
            'is_initialized': self.is_initialized,
            'available_methods': [m.value for m in self.available_methods],
            'loaded_ai_models': list(self.models_loaded.keys()),
            'loaded_checkpoints': list(self.checkpoints_loaded.keys()),
            'rembg_sessions': list(self.rembg_sessions.keys()) if hasattr(self, 'rembg_sessions') else [],
            'processing_stats': self.processing_stats.copy(),
            'dependency_injection_info': {
                'enabled': self.segmentation_config.enable_dependency_injection,
                'model_loader_injected': self.model_loader is not None,
                'memory_manager_injected': self.memory_manager is not None,
                'data_converter_injected': self.data_converter is not None,
                'di_container_injected': self.di_container is not None,
                'step_factory_injected': self.step_factory is not None,
                'total_injection_calls': self.processing_stats['dependency_injection_calls']
            },
            'ai_model_stats': {
                'total_ai_calls': self.processing_stats['ai_model_calls'],
                'models_loaded': len(self.models_loaded),
                'checkpoints_loaded': len(self.checkpoints_loaded),
                'fallback_used': False
            },
            'config': {
                'method': self.segmentation_config.method.value,
                'quality_level': self.segmentation_config.quality_level.value,
                'enable_visualization': self.segmentation_config.enable_visualization,
                'confidence_threshold': self.segmentation_config.confidence_threshold,
                'enable_edge_refinement': self.segmentation_config.enable_edge_refinement,
                'enable_hole_filling': self.segmentation_config.enable_hole_filling,
                'overlay_opacity': self.segmentation_config.overlay_opacity,
                'enable_dependency_injection': self.segmentation_config.enable_dependency_injection,
                'use_step_factory': self.segmentation_config.use_step_factory
            }
        }

    def get_dependency_injection_status(self) -> Dict[str, Any]:
        """ì˜ì¡´ì„± ì£¼ì… ìƒíƒœ ë°˜í™˜"""
        return {
            'dependency_injection_enabled': self.segmentation_config.enable_dependency_injection,
            'injected_dependencies': {
                'model_loader': {
                    'injected': self.model_loader is not None,
                    'type': type(self.model_loader).__name__ if self.model_loader else None,
                    'methods_available': [
                        method for method in ['load_model', 'load_model_async', 'get_model']
                        if hasattr(self.model_loader, method)
                    ] if self.model_loader else []
                },
                'memory_manager': {
                    'injected': self.memory_manager is not None,
                    'type': type(self.memory_manager).__name__ if self.memory_manager else None
                },
                'data_converter': {
                    'injected': self.data_converter is not None,
                    'type': type(self.data_converter).__name__ if self.data_converter else None
                },
                'di_container': {
                    'injected': self.di_container is not None,
                    'type': type(self.di_container).__name__ if self.di_container else None
                },
                'step_factory': {
                    'injected': self.step_factory is not None,
                    'type': type(self.step_factory).__name__ if self.step_factory else None
                }
            },
            'injection_statistics': {
                'total_injection_calls': self.processing_stats['dependency_injection_calls'],
                'successful_initializations': 1 if self.is_initialized else 0,
                'ai_models_created_from_checkpoints': len(self.models_loaded),
                'checkpoints_loaded_via_model_loader': len(self.checkpoints_loaded)
            }
        }

    # ==============================================
    # ğŸ”¥ 15. ì •ë¦¬ ë©”ì„œë“œ
    # ==============================================
    
    async def cleanup(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        try:
            self.logger.info("ğŸ§¹ ClothSegmentationStep ì •ë¦¬ ì‹œì‘...")
            
            # AI ëª¨ë¸ ì •ë¦¬
            for model_name, model in self.models_loaded.items():
                try:
                    if hasattr(model, 'cpu'):
                        model.cpu()
                    del model
                except Exception as e:
                    self.logger.warning(f"âš ï¸ ëª¨ë¸ {model_name} ì •ë¦¬ ì‹¤íŒ¨: {e}")
            
            self.models_loaded.clear()
            
            # ì²´í¬í¬ì¸íŠ¸ ì •ë¦¬
            self.checkpoints_loaded.clear()
            
            # RemBG ì„¸ì…˜ ì •ë¦¬
            if hasattr(self, 'rembg_sessions'):
                self.rembg_sessions.clear()
            
            # ìºì‹œ ì •ë¦¬
            if hasattr(self, 'segmentation_cache'):
                self.segmentation_cache.clear()
            
            # ì‹¤í–‰ì ì •ë¦¬
            if hasattr(self, 'executor'):
                self.executor.shutdown(wait=False)
            
            # GPU ë©”ëª¨ë¦¬ ì •ë¦¬
            if self.device == "mps" and MPS_AVAILABLE:
                try:
                    torch.mps.empty_cache()
                except:
                    pass
            elif self.device == "cuda" and TORCH_AVAILABLE and torch.cuda.is_available():
                torch.cuda.empty_cache()
            
            # ê°€ë¹„ì§€ ì»¬ë ‰ì…˜
            gc.collect()
            
            # ì˜ì¡´ì„± ì°¸ì¡° ì •ë¦¬
            self.model_loader = None
            self.memory_manager = None
            self.data_converter = None
            self.di_container = None
            self.step_factory = None
            
            self.is_initialized = False
            self.logger.info("âœ… ClothSegmentationStep ì •ë¦¬ ì™„ë£Œ")
            
        except Exception as e:
            self.logger.error(f"âŒ ì •ë¦¬ ì‹¤íŒ¨: {e}")

    def __del__(self):
        """ì†Œë©¸ì"""
        try:
            if hasattr(self, 'executor'):
                self.executor.shutdown(wait=False)
        except Exception:
            pass

# ==============================================
# ğŸ”¥ 16. íŒ©í† ë¦¬ í•¨ìˆ˜ë“¤ (ì˜ì¡´ì„± ì£¼ì… íŒ¨í„´)
# ==============================================

def create_cloth_segmentation_step(
    device: Optional[str] = None,
    config: Optional[Dict[str, Any]] = None,
    **kwargs
) -> ClothSegmentationStep:
    """ClothSegmentationStep íŒ©í† ë¦¬ í•¨ìˆ˜ (ì˜ì¡´ì„± ì£¼ì… íŒ¨í„´)"""
    if config is None:
        config = {}
    
    # ì˜ì¡´ì„± ì£¼ì… í™œì„±í™”
    config['enable_dependency_injection'] = True
    config['use_step_factory'] = True
    
    return ClothSegmentationStep(device=device, config=config, **kwargs)

async def create_and_initialize_cloth_segmentation_step_with_di(
    device: str = "auto",
    config: Optional[Dict[str, Any]] = None,
    **kwargs
) -> ClothSegmentationStep:
    """ì˜ì¡´ì„± ì£¼ì…ì„ ì‚¬ìš©í•œ ClothSegmentationStep ìƒì„± ë° ì´ˆê¸°í™”"""
    
    # StepFactoryë¥¼ í†µí•œ ì˜ì¡´ì„± ì£¼ì… ë°©ì‹
    try:
        # StepFactory ì•ˆì „ import
        from ..factories.step_factory import get_global_step_factory, create_step_with_dependency_injection
        
        # StepFactoryë¥¼ í†µí•œ ìƒì„±
        step_factory = get_global_step_factory()
        if step_factory:
            step = create_step_with_dependency_injection(
                step_type="ClothSegmentationStep",
                device=device,
                config=config,
                **kwargs
            )
            if step:
                await step.initialize()
                return step
        
        # í´ë°±: ì§ì ‘ ìƒì„± ë° ìˆ˜ë™ ì˜ì¡´ì„± ì£¼ì…
        step = create_cloth_segmentation_step(device=device, config=config, **kwargs)
        
        # ìˆ˜ë™ ì˜ì¡´ì„± ì£¼ì…
        ModelLoader, get_global_model_loader = safe_import_model_loader()
        model_loader = get_global_model_loader()
        if model_loader:
            step.set_model_loader(model_loader)
        
        get_di_container, inject_dependencies_to_step = safe_import_di_container()
        if get_di_container:
            di_container = get_di_container()
            if di_container:
                step.set_di_container(di_container)
        
        await step.initialize()
        return step
        
    except Exception as e:
        logger.error(f"âŒ ì˜ì¡´ì„± ì£¼ì… ìƒì„± ì‹¤íŒ¨: {e}")
        
        # ìµœì¢… í´ë°±: ê¸°ë³¸ ìƒì„±
        step = create_cloth_segmentation_step(device=device, config=config, **kwargs)
        await step.initialize()
        return step

def create_m3_max_segmentation_step_with_di(
    config: Optional[Dict[str, Any]] = None,
    **kwargs
) -> ClothSegmentationStep:
    """M3 Max ìµœì í™”ëœ ClothSegmentationStep ìƒì„± (ì˜ì¡´ì„± ì£¼ì… íŒ¨í„´)"""
    m3_config = {
        'method': SegmentationMethod.AUTO,
        'quality_level': QualityLevel.HIGH,
        'use_fp16': True,
        'batch_size': 8,  # M3 Max 128GB í™œìš©
        'cache_size': 200,
        'enable_visualization': True,
        'visualization_quality': 'high',
        'enable_edge_refinement': True,
        'enable_hole_filling': True,
        'enable_dependency_injection': True,  # ğŸ”¥ ì˜ì¡´ì„± ì£¼ì… í™œì„±í™”
        'use_step_factory': True
    }
    
    if config:
        m3_config.update(config)
    
    return ClothSegmentationStep(device="mps", config=m3_config, **kwargs)

def create_production_segmentation_step_with_di(
    device: Optional[str] = None,
    **kwargs
) -> ClothSegmentationStep:
    """í”„ë¡œë•ì…˜ í™˜ê²½ìš© ClothSegmentationStep ìƒì„± (ì˜ì¡´ì„± ì£¼ì… íŒ¨í„´)"""
    production_config = {
        'method': SegmentationMethod.AUTO,
        'quality_level': QualityLevel.BALANCED,
        'enable_visualization': True,
        'enable_post_processing': True,
        'confidence_threshold': 0.7,
        'visualization_quality': 'medium',
        'enable_edge_refinement': True,
        'enable_hole_filling': True,
        'enable_dependency_injection': True,  # ğŸ”¥ ì˜ì¡´ì„± ì£¼ì… í™œì„±í™”
        'use_step_factory': True
    }
    
    return ClothSegmentationStep(device=device, config=production_config, **kwargs)

# ==============================================
# ğŸ”¥ 17. í…ŒìŠ¤íŠ¸ ë° ì˜ˆì‹œ í•¨ìˆ˜ë“¤
# ==============================================

async def test_dependency_injection_ai_segmentation():
    """ì˜ì¡´ì„± ì£¼ì… + AI ì„¸ê·¸ë©˜í…Œì´ì…˜ í…ŒìŠ¤íŠ¸"""
    print("ğŸ§ª ì˜ì¡´ì„± ì£¼ì… + AI ì„¸ê·¸ë©˜í…Œì´ì…˜ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    
    try:
        # Step ìƒì„± (ì˜ì¡´ì„± ì£¼ì… íŒ¨í„´)
        step = await create_and_initialize_cloth_segmentation_step_with_di(
            device="auto",
            config={
                "method": "auto",
                "enable_visualization": True,
                "visualization_quality": "high",
                "quality_level": "balanced",
                "enable_dependency_injection": True
            }
        )
        
        # ì˜ì¡´ì„± ì£¼ì… ìƒíƒœ í™•ì¸
        di_status = step.get_dependency_injection_status()
        print("ğŸ”— ì˜ì¡´ì„± ì£¼ì… ìƒíƒœ:")
        for dep_name, dep_info in di_status['injected_dependencies'].items():
            status = "âœ…" if dep_info['injected'] else "âŒ"
            print(f"   {status} {dep_name}: {dep_info['type']}")
        
        # ë”ë¯¸ ì´ë¯¸ì§€ ìƒì„±
        if PIL_AVAILABLE:
            dummy_image = Image.new('RGB', (512, 512), (200, 150, 100))
        else:
            dummy_image = np.random.randint(0, 255, (512, 512, 3), dtype=np.uint8)
        
        # AI ì²˜ë¦¬ ì‹¤í–‰
        result = await step.process(dummy_image, clothing_type="shirt", quality_level="high")
        
        # ê²°ê³¼ í™•ì¸
        if result['success']:
            print("âœ… ì˜ì¡´ì„± ì£¼ì… + AI ì²˜ë¦¬ ì„±ê³µ!")
            print(f"   - ì˜ë¥˜ íƒ€ì…: {result['clothing_type']}")
            print(f"   - ì‹ ë¢°ë„: {result['confidence']:.3f}")
            print(f"   - ì²˜ë¦¬ ì‹œê°„: {result['processing_time']:.2f}ì´ˆ")
            print(f"   - ì‚¬ìš© AI ëª¨ë¸: {result['ai_models_used']}")
            print(f"   - ModelLoader ì‚¬ìš©: {result['metadata']['model_loader_used']}")
            print(f"   - ì˜ì¡´ì„± ì£¼ì… í˜¸ì¶œ: {result['dependency_injection_info']['total_injection_calls']}")
            
            if 'visualization_base64' in result:
                print("   - AI ì‹œê°í™” ì´ë¯¸ì§€ ìƒì„±ë¨")
        else:
            print(f"âŒ ì˜ì¡´ì„± ì£¼ì… + AI ì²˜ë¦¬ ì‹¤íŒ¨: {result.get('error', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}")
        
        # ì‹œìŠ¤í…œ ì •ë³´ ì¶œë ¥
        info = step.get_segmentation_info()
        print(f"\nğŸ§  ì˜ì¡´ì„± ì£¼ì… + AI ì‹œìŠ¤í…œ ì •ë³´:")
        print(f"   - ë””ë°”ì´ìŠ¤: {info['device']}")
        print(f"   - ë¡œë“œëœ AI ëª¨ë¸: {info['loaded_ai_models']}")
        print(f"   - ë¡œë“œëœ ì²´í¬í¬ì¸íŠ¸: {info['loaded_checkpoints']}")
        print(f"   - AI ëª¨ë¸ í˜¸ì¶œ ìˆ˜: {info['ai_model_stats']['total_ai_calls']}")
        print(f"   - ì˜ì¡´ì„± ì£¼ì… í™œì„±í™”: {info['dependency_injection_info']['enabled']}")
        
        # ì •ë¦¬
        await step.cleanup()
        print("âœ… ì˜ì¡´ì„± ì£¼ì… + AI í…ŒìŠ¤íŠ¸ ì™„ë£Œ ë° ì •ë¦¬")
        
    except Exception as e:
        print(f"âŒ ì˜ì¡´ì„± ì£¼ì… + AI í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        print("ğŸ’¡ StepFactory, ModelLoader, BaseStepMixinì´ í•„ìš”í•©ë‹ˆë‹¤.")

def example_dependency_injection_usage():
    """ì˜ì¡´ì„± ì£¼ì… ì‚¬ìš© ì˜ˆì‹œ"""
    print("ğŸ”¥ MyCloset AI Step 03 - ì˜ì¡´ì„± ì£¼ì… + AI ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‚¬ìš© ì˜ˆì‹œ")
    print("=" * 80)
    
    print("""
# ğŸ”¥ ì˜ì¡´ì„± ì£¼ì… íŒ¨í„´ + ì‹¤ì œ AI ëª¨ë¸ ì—°ë™ ë²„ì „

# 1. StepFactoryë¥¼ í†µí•œ ì˜ì¡´ì„± ì£¼ì… (ê¶Œì¥)
from app.ai_pipeline.factories.step_factory import get_global_step_factory

step_factory = get_global_step_factory()
step = step_factory.create_step(
    step_type="ClothSegmentationStep",
    device="mps",
    config={
        "method": "auto",
        "enable_dependency_injection": True,
        "use_step_factory": True
    }
)

# 2. ìˆ˜ë™ ì˜ì¡´ì„± ì£¼ì…
from app.ai_pipeline.steps.step_03_cloth_segmentation import create_cloth_segmentation_step

step = create_cloth_segmentation_step(device="mps")

# ModelLoader ì£¼ì…
from app.ai_pipeline.utils.model_loader import get_global_model_loader
model_loader = get_global_model_loader()
step.set_model_loader(model_loader)

# DI Container ì£¼ì…
from app.core.di_container import get_di_container
di_container = get_di_container()
step.set_di_container(di_container)

# 3. í¸ì˜ í•¨ìˆ˜ ì‚¬ìš© (ì™„ì „ ìë™í™”)
step = await create_and_initialize_cloth_segmentation_step_with_di(
    device="mps",
    config={
        "quality_level": "ultra",
        "enable_visualization": True,
        "enable_dependency_injection": True
    }
)

# 4. M3 Max ìµœì í™” ë²„ì „ (ì˜ì¡´ì„± ì£¼ì…)
step = create_m3_max_segmentation_step_with_di({
    "quality_level": "ultra",
    "enable_visualization": True,
    "batch_size": 8  # M3 Max 128GB í™œìš©
})

# 5. ì‹¤ì œ AI + ì˜ì¡´ì„± ì£¼ì… ê²°ê³¼ í™œìš©
result = await step.process(image, clothing_type="shirt", quality_level="high")

if result['success']:
    # ì‹¤ì œ AI ìƒì„± ê²°ê³¼
    ai_mask = result['mask']
    ai_confidence = result['confidence']
    ai_models_used = result['ai_models_used']
    
    # ì˜ì¡´ì„± ì£¼ì… ì •ë³´
    di_info = result['dependency_injection_info']
    model_loader_used = di_info['model_loader_injected']
    injection_calls = di_info['total_injection_calls']
    
    print(f"AI ëª¨ë¸: {ai_models_used}")
    print(f"ModelLoader ì£¼ì…: {model_loader_used}")
    print(f"ì˜ì¡´ì„± ì£¼ì… íšŸìˆ˜: {injection_calls}")

# 6. ì˜ì¡´ì„± ì£¼ì… ìƒíƒœ í™•ì¸
di_status = step.get_dependency_injection_status()
print("ì˜ì¡´ì„± ì£¼ì… ìƒíƒœ:")
for dep_name, dep_info in di_status['injected_dependencies'].items():
    print(f"  {dep_name}: {dep_info['injected']}")

# 7. ì—ëŸ¬ ì²˜ë¦¬ (ì˜ì¡´ì„± ì£¼ì…)
try:
    await step.initialize()
except ImportError as e:
    print(f"ì˜ì¡´ì„± ëˆ„ë½: {e}")
    # StepFactoryë¥¼ í†µí•œ ìë™ í•´ê²°
    step = await create_and_initialize_cloth_segmentation_step_with_di()

# 8. conda í™˜ê²½ ì„¤ì • (ì˜ì¡´ì„± ì£¼ì… + AI ëª¨ë¸ìš©)
'''
conda create -n mycloset-ai-di python=3.9 -y
conda activate mycloset-ai-di

# í•µì‹¬ ë¼ì´ë¸ŒëŸ¬ë¦¬
conda install -c pytorch pytorch torchvision torchaudio -y
conda install -c conda-forge opencv numpy pillow -y

# AI ëª¨ë¸ ë¼ì´ë¸ŒëŸ¬ë¦¬
pip install rembg segment-anything transformers
pip install scikit-learn psutil

# M3 Max ìµœì í™”
conda install -c conda-forge accelerate -y

# ì‹¤í–‰
cd backend
python -m app.ai_pipeline.steps.step_03_cloth_segmentation
'''

# ë¦¬ì†ŒìŠ¤ ì •ë¦¬
await step.cleanup()
""")

def print_conda_setup_guide_with_di():
    """conda í™˜ê²½ ì„¤ì • ê°€ì´ë“œ (ì˜ì¡´ì„± ì£¼ì… + AIìš©)"""
    print("""
ğŸ MyCloset AI - conda í™˜ê²½ ì„¤ì • ê°€ì´ë“œ (ì˜ì¡´ì„± ì£¼ì… + AI ëª¨ë¸ìš©)

# 1. conda í™˜ê²½ ìƒì„± (ì˜ì¡´ì„± ì£¼ì… + AI)
conda create -n mycloset-ai-di python=3.9 -y
conda activate mycloset-ai-di

# 2. í•µì‹¬ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ (í•„ìˆ˜)
conda install -c pytorch pytorch torchvision torchaudio -y
conda install -c conda-forge opencv numpy pillow -y

# 3. AI ëª¨ë¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ (í•„ìˆ˜)
pip install rembg segment-anything transformers
pip install scikit-learn psutil ultralytics

# 4. M3 Max ìµœì í™” (macOS)
conda install -c conda-forge accelerate -y

# 5. ì˜ì¡´ì„± ì£¼ì… ê²€ì¦
python -c "
import torch
from app.ai_pipeline.utils.model_loader import get_global_model_loader
from app.core.di_container import get_di_container

print(f'PyTorch: {torch.__version__}')
print(f'MPS: {torch.backends.mps.is_available()}')
print(f'ModelLoader: {get_global_model_loader() is not None}')
print(f'DI Container: {get_di_container() is not None}')
"

# 6. ì‹¤í–‰ (ì˜ì¡´ì„± ì£¼ì… + AI)
cd backend
export MYCLOSET_AI_DI_MODE=true
python -m app.ai_pipeline.steps.step_03_cloth_segmentation

# 7. í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
export MYCLOSET_AI_DI_MODE=true
export MYCLOSET_AI_DEVICE=mps
export MYCLOSET_AI_MODELS_PATH=/path/to/ai_models
export MYCLOSET_AI_USE_STEP_FACTORY=true
""")

# ==============================================
# ğŸ”¥ 18. ëª¨ë“ˆ ìµìŠ¤í¬íŠ¸
# ==============================================

__all__ = [
    # ë©”ì¸ í´ë˜ìŠ¤
    'ClothSegmentationStep',
    
    # ì—´ê±°í˜• ë° ë°ì´í„° í´ë˜ìŠ¤
    'SegmentationMethod',
    'ClothingType', 
    'QualityLevel',
    'SegmentationConfig',
    'SegmentationResult',
    
    # AI ëª¨ë¸ í´ë˜ìŠ¤ë“¤
    'U2NET',
    'REBNCONV',
    'RSU7',
    
    # íŒ©í† ë¦¬ í•¨ìˆ˜ë“¤ (ì˜ì¡´ì„± ì£¼ì…)
    'create_cloth_segmentation_step',
    'create_and_initialize_cloth_segmentation_step_with_di',
    'create_m3_max_segmentation_step_with_di',
    'create_production_segmentation_step_with_di',
    
    # ì‹œê°í™” ê´€ë ¨
    'CLOTHING_COLORS',
    
    # ë¼ì´ë¸ŒëŸ¬ë¦¬ ìƒíƒœ
    'TORCH_AVAILABLE',
    'MPS_AVAILABLE',
    'NUMPY_AVAILABLE',
    'OPENCV_AVAILABLE',
    'PIL_AVAILABLE',
    'REMBG_AVAILABLE',
    'SKLEARN_AVAILABLE',
    'SAM_AVAILABLE',
    'TRANSFORMERS_AVAILABLE'
]

# ==============================================
# ğŸ”¥ 19. ëª¨ë“ˆ ì´ˆê¸°í™” ë¡œê¹…
# ==============================================

logger.info("=" * 80)
logger.info("âœ… Step 03 ì™„ì „ ì˜ì¡´ì„± ì£¼ì… + AI ì—°ë™ ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ ëª¨ë“ˆ ë¡œë“œ ì™„ë£Œ")
logger.info("=" * 80)
logger.info("ğŸ”¥ í•µì‹¬ íŠ¹ì§•:")
logger.info("   âœ… ì˜ì¡´ì„± ì£¼ì… íŒ¨í„´ ì™„ì „ ì ìš©")
logger.info("   âœ… StepFactory â†’ ModelLoader â†’ BaseStepMixin ì—°ë™")
logger.info("   âœ… ì‹¤ì œ AI ëª¨ë¸ ì—°ë™ ë° ì¶”ë¡  (U2Net, RemBG, SAM)")
logger.info("   âœ… ì²´í¬í¬ì¸íŠ¸ â†’ AI ëª¨ë¸ ë³€í™˜ ë¡œì§")
logger.info("   âœ… ìˆœí™˜ì°¸ì¡° ì™„ì „ ë°©ì§€ (TYPE_CHECKING)")
logger.info("   âœ… M3 Max 128GB ìµœì í™”")
logger.info("   âœ… conda í™˜ê²½ ì™„ë²½ ì§€ì›")
logger.info("   âœ… í”„ë¡œë•ì…˜ ë ˆë²¨ ì•ˆì •ì„±")
logger.info("")
logger.info("ğŸ”— ì˜ì¡´ì„± ì£¼ì… íë¦„:")
logger.info("   StepFactory â†’ ModelLoader ìƒì„± â†’ BaseStepMixin ìƒì„±")
logger.info("   â†’ ì˜ì¡´ì„± ì£¼ì… â†’ ClothSegmentationStep ì™„ì„±")
logger.info("")
logger.info("ğŸ§  AI ëª¨ë¸ ì—°ë™ íë¦„:")
logger.info("   ModelLoader.load_model() â†’ ì²´í¬í¬ì¸íŠ¸ ë¡œë”©")
logger.info("   â†’ AI ëª¨ë¸ ìƒì„± â†’ ì‹¤ì œ ì¶”ë¡  â†’ ê²°ê³¼ ë°˜í™˜")
logger.info("")
logger.info(f"ğŸ”§ ì‹œìŠ¤í…œ ìƒíƒœ:")
logger.info(f"   - PyTorch: {'âœ…' if TORCH_AVAILABLE else 'âŒ'}")
logger.info(f"   - MPS: {'âœ…' if MPS_AVAILABLE else 'âŒ'}")
logger.info(f"   - NumPy: {'âœ…' if NUMPY_AVAILABLE else 'âŒ'}")
logger.info(f"   - OpenCV: {'âœ…' if OPENCV_AVAILABLE else 'âŒ'}")
logger.info(f"   - PIL: {'âœ…' if PIL_AVAILABLE else 'âŒ'}")
logger.info(f"   - RemBG: {'âœ…' if REMBG_AVAILABLE else 'âŒ'}")
logger.info(f"   - SAM: {'âœ…' if SAM_AVAILABLE else 'âŒ'}")
logger.info(f"   - Transformers: {'âœ…' if TRANSFORMERS_AVAILABLE else 'âŒ'}")
logger.info("")
logger.info("ğŸŒŸ ì‚¬ìš© ì˜ˆì‹œ:")
logger.info("   # ì˜ì¡´ì„± ì£¼ì… + AI ì—°ë™")
logger.info("   step = await create_and_initialize_cloth_segmentation_step_with_di()")
logger.info("   result = await step.process(image)")
logger.info("")
logger.info("=" * 80)
logger.info("ğŸš€ ì™„ì „ ì˜ì¡´ì„± ì£¼ì… + AI ì—°ë™ Step 03 ì¤€ë¹„ ì™„ë£Œ!")
logger.info("   âœ… StepFactory ì˜ì¡´ì„± ì£¼ì… íŒ¨í„´")
logger.info("   âœ… ModelLoader ì²´í¬í¬ì¸íŠ¸ ë¡œë”©")
logger.info("   âœ… ì‹¤ì œ AI ëª¨ë¸ ìƒì„± ë° ì¶”ë¡ ")
logger.info("   âœ… ìˆœí™˜ì°¸ì¡° ì™„ì „ í•´ê²°")
logger.info("   âœ… M3 Max ìµœì í™”")
logger.info("   âœ… conda í™˜ê²½ ì§€ì›")
logger.info("=" * 80)

if __name__ == "__main__":
    """ì§ì ‘ ì‹¤í–‰ ì‹œ í…ŒìŠ¤íŠ¸ (ì˜ì¡´ì„± ì£¼ì… + AI)"""
    print("ğŸ”¥ Step 03 ì™„ì „ ì˜ì¡´ì„± ì£¼ì… + AI ì„¸ê·¸ë©˜í…Œì´ì…˜ - ì§ì ‘ ì‹¤í–‰ í…ŒìŠ¤íŠ¸")
    
    # ì˜ˆì‹œ ì¶œë ¥
    example_dependency_injection_usage()
    
    # conda ê°€ì´ë“œ
    print_conda_setup_guide_with_di()
    
    # ì‹¤ì œ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ (ë¹„ë™ê¸°)
    import asyncio
    try:
        asyncio.run(test_dependency_injection_ai_segmentation())
    except Exception as e:
        print(f"âŒ ì˜ì¡´ì„± ì£¼ì… + AI í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
        print("ğŸ’¡ ë‹¤ìŒì´ í•„ìš”í•©ë‹ˆë‹¤:")
        print("   1. StepFactory ëª¨ë“ˆ (ì˜ì¡´ì„± ì£¼ì…)")
        print("   2. ModelLoader ëª¨ë“ˆ (ì²´í¬í¬ì¸íŠ¸ ë¡œë”©)")
        print("   3. BaseStepMixin ëª¨ë“ˆ (ê¸°ë³¸ ê¸°ëŠ¥)")
        print("   4. ì‹¤ì œ AI ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ íŒŒì¼")
        print("   5. DI Container ì„¤ì •")