# app/ai_pipeline/steps/step_03_cloth_segmentation.py
"""
3ë‹¨ê³„: ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ (Clothing Segmentation) - í†µì¼ëœ ìƒì„±ì íŒ¨í„´ ì ìš©
âœ… ìµœì í™”ëœ ìƒì„±ì: device ìë™ê°ì§€, M3 Max ìµœì í™”, ì¼ê´€ëœ ì¸í„°í˜ì´ìŠ¤
M3 Max ìµœì í™” + ê²¬ê³ í•œ ì—ëŸ¬ ì²˜ë¦¬ + ì™„ì „í•œ ì´ˆê¸°í™” ì‹œìŠ¤í…œ
"""
import os
import logging
import time
import asyncio
from typing import Dict, Any, Optional, Tuple, List, Union
import numpy as np
import torch
import torch.nn.functional as F
import cv2
from PIL import Image
import json
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor

# í†µì¼ëœ ë² ì´ìŠ¤ í´ë˜ìŠ¤ import
from .base_step import ProcessingPipelineStep

# ë°°ê²½ ì œê±° ë¼ì´ë¸ŒëŸ¬ë¦¬ë“¤ (ì„ íƒì  import)
try:
    import rembg
    from rembg import remove, new_session
    REMBG_AVAILABLE = True
except ImportError:
    REMBG_AVAILABLE = False
    logging.warning("rembg ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤. ëŒ€ì•ˆ ë°©ë²•ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")

try:
    from sklearn.cluster import KMeans
    SKLEARN_AVAILABLE = True
except ImportError:
    SKLEARN_AVAILABLE = False
    logging.warning("scikit-learnì´ ì—†ìŠµë‹ˆë‹¤. K-means ì„¸ê·¸ë©˜í…Œì´ì…˜ ë¹„í™œì„±í™”ë©ë‹ˆë‹¤.")

logger = logging.getLogger(__name__)

class ClothSegmentationStep(ProcessingPipelineStep):
    """
    âœ… 3ë‹¨ê³„: ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ - í†µì¼ëœ ìƒì„±ì íŒ¨í„´
    - ìë™ ë””ë°”ì´ìŠ¤ ê°ì§€
    - M3 Max ìµœì í™”
    - ì¼ê´€ëœ ì¸í„°í˜ì´ìŠ¤
    - ë‹¤ì¤‘ ì„¸ê·¸ë©˜í…Œì´ì…˜ ë°©ë²• ì§€ì›
    """
    
    # ì˜ë¥˜ ì¹´í…Œê³ ë¦¬ ì •ì˜
    CLOTHING_CATEGORIES = {
        'upper': ['shirt', 't-shirt', 'blouse', 'sweater', 'jacket', 'coat', 'top'],
        'lower': ['pants', 'jeans', 'skirt', 'shorts', 'trousers', 'bottom'],
        'full': ['dress', 'jumpsuit', 'overall', 'gown'],
        'accessories': ['hat', 'scarf', 'gloves', 'shoes', 'bag', 'belt']
    }
    
    # ì§€ì›í•˜ëŠ” ì„¸ê·¸ë©˜í…Œì´ì…˜ ë°©ë²•ë“¤
    SEGMENTATION_METHODS = [
        'auto', 'rembg', 'model', 'grabcut', 'kmeans', 'threshold'
    ]
    
    def __init__(
        self,
        device: Optional[str] = None,
        config: Optional[Dict[str, Any]] = None,
        **kwargs
    ):
        """
        âœ… í†µì¼ëœ ìƒì„±ì - ìµœì í™”ëœ ì¸í„°í˜ì´ìŠ¤
        
        Args:
            device: ì‚¬ìš©í•  ë””ë°”ì´ìŠ¤ (None=ìë™ê°ì§€, 'cpu', 'cuda', 'mps')
            config: ìŠ¤í…ë³„ ì„¤ì • ë”•ì…”ë„ˆë¦¬
            **kwargs: í™•ì¥ íŒŒë¼ë¯¸í„°ë“¤
                - method: str = 'auto' (ì„¸ê·¸ë©˜í…Œì´ì…˜ ë°©ë²•)
                - model_name: str = 'u2net'
                - confidence_threshold: float = 0.5
                - use_background_removal: bool = True
                - quality_threshold: float = 0.7
                - enable_post_processing: bool = True
                - max_image_size: int = 1024 (M3 Maxì—ì„œ ë” í¼)
                - morphology_enabled: bool = True
                - gaussian_blur: bool = True
                - edge_refinement: bool = True
                - hole_filling: bool = True
        """
        # ë¶€ëª¨ í´ë˜ìŠ¤ ì´ˆê¸°í™” (ìë™ ë””ë°”ì´ìŠ¤ ê°ì§€, M3 Max ìµœì í™” ë“±)
        super().__init__(device, config, **kwargs)
        
        # 3ë‹¨ê³„ ì „ìš© ì„¸ê·¸ë©˜í…Œì´ì…˜ ì„¤ì •
        self.segmentation_config = self.config.get('segmentation', {})
        
        # ì„¸ê·¸ë©˜í…Œì´ì…˜ ë°©ë²• ì„¤ì •
        self.method = self.config.get('method', 'auto')
        self.model_name = self.config.get('model_name', 'u2net')
        self.confidence_threshold = self.config.get('confidence_threshold', 0.5)
        self.use_background_removal = self.config.get('use_background_removal', True)
        
        # í’ˆì§ˆ ì„¤ì • (M3 Maxì—ì„œ ë” ë†’ì€ í’ˆì§ˆ)
        default_quality = 0.8 if self.is_m3_max else 0.7
        self.quality_threshold = self.config.get('quality_threshold', default_quality)
        
        # í›„ì²˜ë¦¬ ì„¤ì •
        self.post_process_config = self.config.get('post_processing', {})
        self.enable_post_processing = self.config.get('enable_post_processing', True)
        self.morphology_enabled = self.config.get('morphology_enabled', True)
        self.gaussian_blur = self.config.get('gaussian_blur', True)
        self.edge_refinement = self.config.get('edge_refinement', True)
        self.hole_filling = self.config.get('hole_filling', True)
        
        # ëª¨ë¸ ë° ì„¸ì…˜ ë³€ìˆ˜ë“¤
        self.rembg_session = None
        self.rembg_sessions = {}
        self.segmentation_model = None
        self.backup_methods = None
        
        # 3ë‹¨ê³„ ì „ìš© í†µê³„
        self.segmentation_stats = {
            'total_processed': 0,
            'successful_segmentations': 0,
            'average_quality': 0.0,
            'method_usage': {},
            'rembg_usage': 0,
            'model_usage': 0,
            'fallback_usage': 0,
            'cache_hits': 0
        }
        
        # ì„±ëŠ¥ ìºì‹œ (M3 Maxì—ì„œ ë” í° ìºì‹œ)
        cache_size = 100 if self.is_m3_max and self.memory_gb >= 128 else 50
        self.segmentation_cache = {}
        self.cache_max_size = cache_size
        
        self.logger.info(f"ğŸ‘• ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ ìŠ¤í… ì´ˆê¸°í™” ì™„ë£Œ - RemBG: {'âœ…' if REMBG_AVAILABLE else 'âŒ'}")
        if self.is_m3_max:
            self.logger.info(f"ğŸ M3 Max ìµœì í™”: í’ˆì§ˆ {self.quality_threshold}, í¬ê¸° {self.max_resolution}")
    
    async def initialize(self) -> bool:
        """
        âœ… í†µì¼ëœ ì´ˆê¸°í™” ì¸í„°í˜ì´ìŠ¤
        
        Returns:
            bool: ì´ˆê¸°í™” ì„±ê³µ ì—¬ë¶€
        """
        try:
            self.logger.info("ğŸ”„ 3ë‹¨ê³„: ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...")
            
            # 1. RemBG ì´ˆê¸°í™”
            await self._initialize_rembg()
            
            # 2. ì»¤ìŠ¤í…€ ëª¨ë¸ ì´ˆê¸°í™”
            await self._initialize_custom_model()
            
            # 3. ë°±ì—… ë°©ë²•ë“¤ ì´ˆê¸°í™”
            self._initialize_backup_methods()
            
            # 4. M3 Max ìµœì í™” ì›Œë°ì—…
            if self.is_m3_max and self.optimization_enabled:
                await self._warmup_m3_max()
            
            self.is_initialized = True
            self.logger.info("âœ… ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
            return True
            
        except Exception as e:
            error_msg = f"ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}"
            self.logger.error(f"âŒ {error_msg}")
            self.initialization_error = error_msg
            
            # ìµœì†Œí•œì˜ í´ë°± ì‹œìŠ¤í…œìœ¼ë¡œë¼ë„ ì´ˆê¸°í™”
            self.backup_methods = self._create_simple_backup()
            self.is_initialized = True
            return True
    
    async def process(
        self, 
        clothing_image: Union[str, np.ndarray, Image.Image, torch.Tensor], 
        clothing_type: str = "shirt",
        quality_level: str = "high",
        **kwargs
    ) -> Dict[str, Any]:
        """
        âœ… í†µì¼ëœ ì²˜ë¦¬ ì¸í„°í˜ì´ìŠ¤
        
        Args:
            clothing_image: ì…ë ¥ ì˜ë¥˜ ì´ë¯¸ì§€
            clothing_type: ì˜ë¥˜ íƒ€ì…
            quality_level: í’ˆì§ˆ ë ˆë²¨ ('low', 'medium', 'high', 'ultra')
            **kwargs: ì¶”ê°€ ë§¤ê°œë³€ìˆ˜
                - method_override: str = None (ë°©ë²• ê°•ì œ ì§€ì •)
                - enable_fallback: bool = True
                - cache_result: bool = True
                
        Returns:
            Dict[str, Any]: ì„¸ê·¸ë©˜í…Œì´ì…˜ ê²°ê³¼
        """
        if not self.is_initialized:
            await self.initialize()
        
        start_time = time.time()
        
        try:
            self.logger.info(f"ğŸ‘• ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‹œì‘ - íƒ€ì…: {clothing_type}, í’ˆì§ˆ: {quality_level}")
            
            # ìºì‹œ í™•ì¸
            cache_key = self._generate_cache_key(clothing_image, clothing_type, quality_level)
            if cache_key in self.segmentation_cache and kwargs.get('cache_result', True):
                self.logger.info("ğŸ’¾ ìºì‹œì—ì„œ ì„¸ê·¸ë©˜í…Œì´ì…˜ ê²°ê³¼ ë°˜í™˜")
                self.segmentation_stats['cache_hits'] += 1
                cached_result = self.segmentation_cache[cache_key].copy()
                cached_result['from_cache'] = True
                return cached_result
            
            # 1. ì…ë ¥ í…ì„œ ê²€ì¦ ë° ì „ì²˜ë¦¬
            clothing_pil = self._prepare_input_image(clothing_image)
            
            # 2. ìµœì  ì„¸ê·¸ë©˜í…Œì´ì…˜ ë°©ë²• ì„ íƒ
            method = kwargs.get('method_override') or self._select_segmentation_method(
                clothing_pil, clothing_type, quality_level
            )
            self.logger.info(f"ğŸ“‹ ì„ íƒëœ ë°©ë²•: {method}")
            
            # 3. ë©”ì¸ ì„¸ê·¸ë©˜í…Œì´ì…˜ ìˆ˜í–‰
            segmentation_result = await self._perform_segmentation(clothing_pil, method)
            
            # 4. í’ˆì§ˆ í‰ê°€
            quality_score = self._evaluate_quality(clothing_pil, segmentation_result['mask'])
            
            # 5. í’ˆì§ˆì´ ë‚®ìœ¼ë©´ í´ë°± ì‹œë„
            if (quality_score < self.quality_threshold and 
                kwargs.get('enable_fallback', True) and 
                method != 'fallback'):
                
                self.logger.info(f"ğŸ”„ í’ˆì§ˆ ê°œì„  ì‹œë„ (í˜„ì¬: {quality_score:.3f})")
                improved_result = await self._try_fallback_methods(clothing_pil, clothing_type)
                
                if improved_result and improved_result.get('quality', 0) > quality_score:
                    segmentation_result = improved_result
                    quality_score = improved_result['quality']
                    method = improved_result.get('method', method)
            
            # 6. í›„ì²˜ë¦¬ ì ìš©
            if self.enable_post_processing:
                processed_result = self._apply_post_processing(segmentation_result, quality_level)
            else:
                processed_result = segmentation_result
            
            # 7. ìµœì¢… ê²°ê³¼ êµ¬ì„±
            processing_time = time.time() - start_time
            result = self._build_final_result(
                processed_result, quality_score, processing_time, method, 
                clothing_type, quality_level
            )
            
            # 8. í†µê³„ ì—…ë°ì´íŠ¸
            self._update_segmentation_stats(method, quality_score, processing_time)
            self._update_performance_stats(processing_time, quality_score > 0.5)
            
            # 9. ìºì‹œ ì €ì¥
            if kwargs.get('cache_result', True):
                self._update_cache(cache_key, result)
            
            self.logger.info(f"âœ… ì„¸ê·¸ë©˜í…Œì´ì…˜ ì™„ë£Œ - ë°©ë²•: {method}, í’ˆì§ˆ: {quality_score:.3f}, ì‹œê°„: {processing_time:.3f}ì´ˆ")
            return result
            
        except Exception as e:
            processing_time = time.time() - start_time
            error_msg = f"ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‹¤íŒ¨: {e}"
            self.logger.error(f"âŒ {error_msg}")
            
            # í†µê³„ ì—…ë°ì´íŠ¸ (ì‹¤íŒ¨)
            self._update_performance_stats(processing_time, False)
            
            return self._create_empty_result(error_msg)
    
    # =================================================================
    # ğŸ”§ í•µì‹¬ ì´ˆê¸°í™” ë©”ì„œë“œë“¤
    # =================================================================
    
    async def _warmup_m3_max(self):
        """M3 Max ì›Œë°ì—…"""
        try:
            self.logger.info("ğŸ M3 Max ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‹œìŠ¤í…œ ì›Œë°ì—…...")
            
            # ë”ë¯¸ ì´ë¯¸ì§€ë¡œ ì›Œë°ì—…
            dummy_image = Image.new('RGB', (256, 256), color='white')
            
            # RemBG ì›Œë°ì—…
            if self.rembg_session:
                try:
                    _ = remove(dummy_image, session=self.rembg_session)
                except Exception as e:
                    self.logger.warning(f"RemBG ì›Œë°ì—… ì‹¤íŒ¨: {e}")
            
            # ì»¤ìŠ¤í…€ ëª¨ë¸ ì›Œë°ì—…
            if self.segmentation_model:
                try:
                    dummy_tensor = self._preprocess_for_model(dummy_image)
                    with torch.no_grad():
                        _ = self.segmentation_model(dummy_tensor)
                except Exception as e:
                    self.logger.warning(f"ëª¨ë¸ ì›Œë°ì—… ì‹¤íŒ¨: {e}")
            
            self.logger.info("âœ… M3 Max ì›Œë°ì—… ì™„ë£Œ")
            
        except Exception as e:
            self.logger.warning(f"M3 Max ì›Œë°ì—… ì‹¤íŒ¨: {e}")
    
    async def _initialize_rembg(self):
        """RemBG ì´ˆê¸°í™” (M3 Max ìµœì í™”)"""
        if not REMBG_AVAILABLE:
            self.logger.warning("RemBG ì‚¬ìš© ë¶ˆê°€")
            return
        
        try:
            # ê¸°ë³¸ ì„¸ì…˜ ìƒì„±
            self.rembg_session = new_session('u2net')
            
            # íŠ¹í™” ì„¸ì…˜ë“¤ ìƒì„± (M3 Maxì—ì„œ ë” ë§ì€ ì„¸ì…˜)
            if self.is_m3_max and self.memory_gb >= 64:
                self.rembg_sessions = {
                    'human_seg': new_session('u2net_human_seg'),
                    'cloth_seg': new_session('u2net_cloth_seg') if hasattr(rembg, 'u2net_cloth_seg') else self.rembg_session,
                    'silueta': new_session('silueta') if hasattr(rembg, 'silueta') else self.rembg_session
                }
            else:
                self.rembg_sessions = {
                    'human_seg': new_session('u2net_human_seg')
                }
            
            self.logger.info(f"âœ… RemBG ì„¸ì…˜ ì´ˆê¸°í™” ì™„ë£Œ - ì„¸ì…˜ ìˆ˜: {len(self.rembg_sessions) + 1}")
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ RemBG ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.rembg_session = None
            self.rembg_sessions = {}
    
    async def _initialize_custom_model(self):
        """ì»¤ìŠ¤í…€ ëª¨ë¸ ì´ˆê¸°í™” (M3 Max ìµœì í™”)"""
        try:
            # ëª¨ë¸ ë¡œë”ê°€ ìˆìœ¼ë©´ ì‚¬ìš©
            if hasattr(self, 'model_loader') and self.model_loader:
                try:
                    self.segmentation_model = await self.model_loader.load_model(
                        self.model_name
                    )
                except Exception as e:
                    self.logger.warning(f"ëª¨ë¸ ë¡œë” ì‹¤íŒ¨: {e}")
            
            # ì—†ìœ¼ë©´ ê°„ë‹¨í•œ ëª¨ë¸ ìƒì„±
            if not self.segmentation_model:
                self.segmentation_model = await self._create_u2net_model()
            
            self.logger.info("âœ… ì»¤ìŠ¤í…€ ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ")
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ ì»¤ìŠ¤í…€ ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.segmentation_model = self._create_fallback_model()
    
    def _initialize_backup_methods(self):
        """ë°±ì—… ì„¸ê·¸ë©˜í…Œì´ì…˜ ë°©ë²•ë“¤ ì´ˆê¸°í™”"""
        try:
            self.backup_methods = BackupSegmentationMethods(
                self.device, 
                self.is_m3_max, 
                self.memory_gb
            )
            self.logger.info("âœ… ë°±ì—… ë°©ë²•ë“¤ ì´ˆê¸°í™” ì™„ë£Œ")
        except Exception as e:
            self.logger.warning(f"âš ï¸ ë°±ì—… ë°©ë²• ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.backup_methods = self._create_simple_backup()
    
    # =================================================================
    # ğŸ”§ í•µì‹¬ ì²˜ë¦¬ ë©”ì„œë“œë“¤
    # =================================================================
    
    def _prepare_input_image(self, image_input: Union[str, np.ndarray, Image.Image, torch.Tensor]) -> Image.Image:
        """ì…ë ¥ ì´ë¯¸ì§€ ì „ì²˜ë¦¬ (M3 Max ìµœì í™”)"""
        try:
            if isinstance(image_input, str):
                if not os.path.exists(image_input):
                    raise FileNotFoundError(f"ì´ë¯¸ì§€ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ: {image_input}")
                image_pil = Image.open(image_input).convert('RGB')
                
            elif isinstance(image_input, np.ndarray):
                if len(image_input.shape) == 3:
                    # BGR to RGB ë³€í™˜
                    if image_input.shape[2] == 3:
                        image_input = cv2.cvtColor(image_input, cv2.COLOR_BGR2RGB)
                    image_pil = Image.fromarray(image_input.astype(np.uint8))
                else:
                    raise ValueError("ì˜ëª»ëœ numpy ë°°ì—´ í˜•íƒœ")
                    
            elif isinstance(image_input, torch.Tensor):
                # í…ì„œë¥¼ numpyë¡œ ë³€í™˜
                if image_input.dim() == 4:
                    image_input = image_input.squeeze(0)
                if image_input.dim() == 3:
                    image_array = image_input.permute(1, 2, 0).cpu().numpy()
                    if image_array.max() <= 1.0:
                        image_array = (image_array * 255).astype(np.uint8)
                    image_pil = Image.fromarray(image_array)
                else:
                    raise ValueError("ì˜ëª»ëœ í…ì„œ í˜•íƒœ")
                    
            elif isinstance(image_input, Image.Image):
                image_pil = image_input.convert('RGB')
                
            else:
                raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì´ë¯¸ì§€ í˜•ì‹: {type(image_input)}")
            
            # í¬ê¸° ì¡°ì • (M3 Maxì—ì„œ ë” í° í¬ê¸° í—ˆìš©)
            max_size = self.max_resolution
            if max(image_pil.size) > max_size:
                # M3 Maxì—ì„œ ê³ í’ˆì§ˆ ë¦¬ìƒ˜í”Œë§
                resample = Image.Resampling.LANCZOS if self.is_m3_max else Image.Resampling.LANCZOS
                image_pil.thumbnail((max_size, max_size), resample)
                self.logger.info(f"ğŸ”„ ì´ë¯¸ì§€ í¬ê¸° ì¡°ì •: {image_pil.size}")
            
            return image_pil
            
        except Exception as e:
            self.logger.error(f"ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            raise
    
    def _select_segmentation_method(self, image: Image.Image, clothing_type: str, quality_level: str) -> str:
        """ìµœì  ì„¸ê·¸ë©˜í…Œì´ì…˜ ë°©ë²• ì„ íƒ (M3 Max ìµœì í™”)"""
        
        method = self.method
        
        # ìë™ ì„ íƒ ëª¨ë“œ
        if method == 'auto':
            # ì´ë¯¸ì§€ ë³µì¡ë„ ë¶„ì„
            complexity = self._analyze_image_complexity(image)
            
            # M3 Maxì—ì„œ ë” ì •êµí•œ ë°©ë²• ì„ íƒ
            if self.is_m3_max and quality_level in ['high', 'ultra']:
                if REMBG_AVAILABLE and self.rembg_session and complexity < 0.8:
                    return 'rembg'
                elif self.segmentation_model and complexity > 0.2:
                    return 'model'
            
            # í’ˆì§ˆ ë ˆë²¨ê³¼ ë³µì¡ë„ì— ë”°ë¥¸ ë°©ë²• ì„ íƒ
            if quality_level in ['high', 'ultra']:
                if REMBG_AVAILABLE and self.rembg_session and complexity < 0.7:
                    return 'rembg'
                elif self.segmentation_model and complexity > 0.3:
                    return 'model'
            
            elif quality_level == 'medium':
                if REMBG_AVAILABLE and self.rembg_session:
                    return 'rembg'
                elif self.backup_methods and complexity < 0.6:
                    return 'grabcut'
            
            # ê¸°ë³¸ ë°©ë²•
            if self.backup_methods:
                return 'grabcut'
            
            return 'threshold'  # ìµœí›„ì˜ ìˆ˜ë‹¨
        
        # ëª…ì‹œì  ë°©ë²• ì„ íƒ ì‹œ ì‚¬ìš© ê°€ëŠ¥ì„± í™•ì¸
        if method == 'rembg' and not (REMBG_AVAILABLE and self.rembg_session):
            return 'grabcut'
        elif method == 'model' and not self.segmentation_model:
            return 'grabcut'
        elif method == 'kmeans' and not SKLEARN_AVAILABLE:
            return 'grabcut'
        
        return method
    
    def _analyze_image_complexity(self, image: Image.Image) -> float:
        """ì´ë¯¸ì§€ ë³µì¡ë„ ë¶„ì„ (M3 Max ê³ ì •ë°€ë„)"""
        try:
            # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜
            gray = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2GRAY)
            
            # ì—£ì§€ ë°€ë„ ê³„ì‚°
            edges = cv2.Canny(gray, 50, 150)
            edge_density = np.sum(edges > 0) / edges.size
            
            # í…ìŠ¤ì²˜ ë³µì¡ë„ (í‘œì¤€í¸ì°¨ ê¸°ë°˜)
            texture_complexity = np.std(gray) / 255.0
            
            # íˆìŠ¤í† ê·¸ë¨ ë³µì¡ë„
            hist = cv2.calcHist([gray], [0], None, [256], [0, 256])
            hist = hist.astype(float)
            hist /= (hist.sum() + 1e-7)
            
            # ì—”íŠ¸ë¡œí”¼ ê³„ì‚°
            entropy = -np.sum(hist * np.log2(hist + 1e-7))
            hist_complexity = entropy / 8.0  # ì •ê·œí™”
            
            # M3 Maxì—ì„œ ë” ì •êµí•œ ë³µì¡ë„ ê³„ì‚°
            if self.is_m3_max:
                # ê·¸ë˜ë””ì–¸íŠ¸ ë³µì¡ë„ ì¶”ê°€
                grad_x = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3)
                grad_y = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)
                grad_magnitude = np.sqrt(grad_x**2 + grad_y**2)
                grad_complexity = np.std(grad_magnitude) / (np.mean(grad_magnitude) + 1e-7)
                grad_complexity = min(grad_complexity / 10.0, 1.0)
                
                # ì¢…í•© ë³µì¡ë„ (ê°€ì¤‘í‰ê· )
                complexity = (
                    edge_density * 0.3 + 
                    texture_complexity * 0.3 + 
                    hist_complexity * 0.2 +
                    grad_complexity * 0.2
                )
            else:
                # ê¸°ë³¸ ë³µì¡ë„
                complexity = (
                    edge_density * 0.4 + 
                    texture_complexity * 0.4 + 
                    hist_complexity * 0.2
                )
            
            return min(max(complexity, 0.0), 1.0)
            
        except Exception as e:
            self.logger.warning(f"ë³µì¡ë„ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return 0.5  # ê¸°ë³¸ê°’
    
    async def _perform_segmentation(self, image: Image.Image, method: str) -> Dict[str, Any]:
        """ë©”ì¸ ì„¸ê·¸ë©˜í…Œì´ì…˜ ìˆ˜í–‰"""
        try:
            if method == 'rembg' and self.rembg_session:
                result = await self._segment_with_rembg(image)
                self.segmentation_stats['rembg_usage'] += 1
                return result
            elif method == 'model' and self.segmentation_model:
                result = await self._segment_with_model(image)
                self.segmentation_stats['model_usage'] += 1
                return result
            elif method == 'grabcut' and self.backup_methods:
                result = self.backup_methods.grabcut_segmentation(image)
                self.segmentation_stats['fallback_usage'] += 1
                return result
            elif method == 'kmeans' and SKLEARN_AVAILABLE:
                result = await self._segment_with_kmeans(image)
                self.segmentation_stats['fallback_usage'] += 1
                return result
            elif method == 'threshold' and self.backup_methods:
                result = self.backup_methods.threshold_segmentation(image)
                self.segmentation_stats['fallback_usage'] += 1
                return result
            else:
                # í´ë°±
                result = await self._segment_with_simple_threshold(image)
                self.segmentation_stats['fallback_usage'] += 1
                return result
                
        except Exception as e:
            self.logger.warning(f"ì„¸ê·¸ë©˜í…Œì´ì…˜ ë°©ë²• {method} ì‹¤íŒ¨: {e}")
            result = await self._segment_with_simple_threshold(image)
            self.segmentation_stats['fallback_usage'] += 1
            return result
    
    async def _segment_with_rembg(self, image: Image.Image) -> Dict[str, Any]:
        """RemBGë¥¼ ì‚¬ìš©í•œ ì„¸ê·¸ë©˜í…Œì´ì…˜ (M3 Max ìµœì í™”)"""
        try:
            # ì˜ë¥˜ íƒ€ì…ë³„ ëª¨ë¸ ì„ íƒ (M3 Maxì—ì„œ ë” ì •êµ)
            if self.is_m3_max and 'cloth_seg' in self.rembg_sessions:
                specialized_session = self.rembg_sessions['cloth_seg']
            else:
                specialized_session = self.rembg_sessions.get('human_seg', self.rembg_session)
            
            # RemBG ì²˜ë¦¬
            result_image = remove(image, session=specialized_session)
            
            # ë§ˆìŠ¤í¬ ì¶”ì¶œ
            if result_image.mode == 'RGBA':
                mask = np.array(result_image)[:, :, 3]
                segmented_rgb = result_image.convert('RGB')
            else:
                # RGBAê°€ ì•„ë‹Œ ê²½ìš° ê°„ë‹¨í•œ ì„ê³„ê°’ ì‚¬ìš©
                gray = np.array(result_image.convert('L'))
                mask = (gray > 20).astype(np.uint8) * 255
                segmented_rgb = result_image.convert('RGB')
            
            return {
                'segmented_image': segmented_rgb,
                'mask': mask,
                'method': 'rembg',
                'confidence': 0.9
            }
            
        except Exception as e:
            self.logger.warning(f"RemBG ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            raise
    
    async def _segment_with_model(self, image: Image.Image) -> Dict[str, Any]:
        """ì»¤ìŠ¤í…€ ëª¨ë¸ì„ ì‚¬ìš©í•œ ì„¸ê·¸ë©˜í…Œì´ì…˜ (M3 Max ìµœì í™”)"""
        try:
            # ì…ë ¥ ì „ì²˜ë¦¬
            input_tensor = self._preprocess_for_model(image)
            
            # ëª¨ë¸ ì¶”ë¡  (M3 Maxì—ì„œ ë” í° ë°°ì¹˜ í¬ê¸° ê°€ëŠ¥)
            with torch.no_grad():
                if self.is_m3_max and self.memory_gb >= 64:
                    # ë†’ì€ ì •ë°€ë„ ëª¨ë“œ
                    if hasattr(self.segmentation_model, 'eval'):
                        self.segmentation_model.eval()
                
                mask_pred = self.segmentation_model(input_tensor)
                mask = mask_pred.squeeze().cpu().numpy()
                mask = (mask * 255).astype(np.uint8)
            
            # ì›ë³¸ í¬ê¸°ë¡œ ë³µì›
            if mask.shape != (image.height, image.width):
                # M3 Maxì—ì„œ ê³ í’ˆì§ˆ ë³´ê°„
                interpolation = cv2.INTER_LANCZOS4 if self.is_m3_max else cv2.INTER_NEAREST
                mask = cv2.resize(mask, (image.width, image.height), interpolation=interpolation)
            
            # ì„¸ê·¸ë©˜í…Œì´ì…˜ëœ ì´ë¯¸ì§€ ìƒì„±
            segmented_image = self._apply_mask_to_image(image, mask)
            
            return {
                'segmented_image': segmented_image,
                'mask': mask,
                'method': 'model',
                'confidence': 0.8
            }
            
        except Exception as e:
            self.logger.warning(f"ëª¨ë¸ ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‹¤íŒ¨: {e}")
            raise
    
    async def _segment_with_kmeans(self, image: Image.Image) -> Dict[str, Any]:
        """K-meansë¥¼ ì‚¬ìš©í•œ ì„¸ê·¸ë©˜í…Œì´ì…˜ (M3 Max ìµœì í™”)"""
        try:
            # ì´ë¯¸ì§€ë¥¼ numpy ë°°ì—´ë¡œ ë³€í™˜
            image_array = np.array(image)
            
            # í”½ì…€ì„ 1D ë°°ì—´ë¡œ ë³€í™˜
            pixels = image_array.reshape(-1, 3)
            
            # M3 Maxì—ì„œ ë” ë§ì€ í´ëŸ¬ìŠ¤í„° ì‚¬ìš©
            n_clusters = 3 if self.is_m3_max else 2
            
            # K-means í´ëŸ¬ìŠ¤í„°ë§
            kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)
            labels = kmeans.fit_predict(pixels)
            
            # ë¼ë²¨ì„ ì´ë¯¸ì§€ í¬ê¸°ë¡œ ë³µì›
            label_image = labels.reshape(image_array.shape[:2])
            
            # ì „ê²½ê³¼ ë°°ê²½ êµ¬ë¶„ (ê°€ì¥ í° í´ëŸ¬ìŠ¤í„°ë¥¼ ë°°ê²½ìœ¼ë¡œ ê°€ì •)
            unique, counts = np.unique(labels, return_counts=True)
            background_label = unique[np.argmax(counts)]
            
            # ë§ˆìŠ¤í¬ ìƒì„± (ì „ê²½=255, ë°°ê²½=0)
            mask = (label_image != background_label).astype(np.uint8) * 255
            
            # ì„¸ê·¸ë©˜í…Œì´ì…˜ëœ ì´ë¯¸ì§€ ìƒì„±
            segmented_image = self._apply_mask_to_image(image, mask)
            
            return {
                'segmented_image': segmented_image,
                'mask': mask,
                'method': 'kmeans',
                'confidence': 0.7
            }
            
        except Exception as e:
            self.logger.warning(f"K-means ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‹¤íŒ¨: {e}")
            raise
    
    async def _segment_with_simple_threshold(self, image: Image.Image) -> Dict[str, Any]:
        """ê°„ë‹¨í•œ ì„ê³„ê°’ ì„¸ê·¸ë©˜í…Œì´ì…˜ (ìµœí›„ì˜ ìˆ˜ë‹¨)"""
        try:
            # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜
            gray = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2GRAY)
            
            # M3 Maxì—ì„œ ë” ì •êµí•œ ì„ê³„ê°’ ì²˜ë¦¬
            if self.is_m3_max:
                # ì ì‘ì  ì„ê³„ê°’ + Otsu ì¡°í•©
                _, mask1 = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
                mask2 = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)
                mask = cv2.bitwise_or(mask1, mask2)
            else:
                # ê¸°ë³¸ Otsu ì„ê³„ê°’
                _, mask = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
            
            # ê°€ì¥ í° ì—°ê²° ì„±ë¶„ë§Œ ìœ ì§€
            contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            if contours:
                largest_contour = max(contours, key=cv2.contourArea)
                mask = np.zeros_like(mask)
                cv2.fillPoly(mask, [largest_contour], 255)
            
            # ì„¸ê·¸ë©˜í…Œì´ì…˜ëœ ì´ë¯¸ì§€ ìƒì„±
            segmented_image = self._apply_mask_to_image(image, mask)
            
            return {
                'segmented_image': segmented_image,
                'mask': mask,
                'method': 'threshold',
                'confidence': 0.6
            }
            
        except Exception as e:
            self.logger.error(f"ì„ê³„ê°’ ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‹¤íŒ¨: {e}")
            # ì „ì²´ ì´ë¯¸ì§€ë¥¼ ë§ˆìŠ¤í¬ë¡œ ë°˜í™˜
            mask = np.ones((image.height, image.width), dtype=np.uint8) * 255
            return {
                'segmented_image': image,
                'mask': mask,
                'method': 'fallback',
                'confidence': 0.3
            }
    
    # =================================================================
    # ğŸ”§ í’ˆì§ˆ í‰ê°€ ë° í›„ì²˜ë¦¬ ë©”ì„œë“œë“¤
    # =================================================================
    
    def _evaluate_quality(self, original_image: Image.Image, mask: np.ndarray) -> float:
        """ì„¸ê·¸ë©˜í…Œì´ì…˜ í’ˆì§ˆ í‰ê°€ (M3 Max ê³ ì •ë°€ë„)"""
        try:
            # 1. ë§ˆìŠ¤í¬ ì»¤ë²„ë¦¬ì§€ (ì „ì²´ ì´ë¯¸ì§€ ëŒ€ë¹„ ë§ˆìŠ¤í¬ ë¹„ìœ¨)
            mask_coverage = np.sum(mask > 0) / mask.size
            
            # 2. ë§ˆìŠ¤í¬ ì—°ê²°ì„± (ì—°ê²°ëœ ì˜ì—­ ìˆ˜)
            contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            connectivity_score = 1.0 / (len(contours) + 1)  # ì˜ì—­ì´ ì ì„ìˆ˜ë¡ ì¢‹ìŒ
            
            # 3. ì—£ì§€ í’ˆì§ˆ (ì—£ì§€ì˜ ë¶€ë“œëŸ¬ì›€)
            edges = cv2.Canny(mask, 50, 150)
            edge_density = np.sum(edges > 0) / edges.size
            edge_score = min(edge_density * 10, 1.0)  # ì ë‹¹í•œ ì—£ì§€ ë°€ë„
            
            # 4. í˜•íƒœ ë³µì¡ë„ (ë³¼ë¡ì„±)
            if contours:
                largest_contour = max(contours, key=cv2.contourArea)
                hull = cv2.convexHull(largest_contour)
                contour_area = cv2.contourArea(largest_contour)
                hull_area = cv2.contourArea(hull)
                
                if hull_area > 0:
                    convexity = contour_area / hull_area
                else:
                    convexity = 0.0
            else:
                convexity = 0.0
            
            # M3 Maxì—ì„œ ì¶”ê°€ í’ˆì§ˆ ë©”íŠ¸ë¦­
            if self.is_m3_max:
                # 5. ê²½ê³„ì„  ë¶€ë“œëŸ¬ì›€
                boundary_smoothness = self._calculate_boundary_smoothness(mask)
                
                # ì¢…í•© ì ìˆ˜ ê³„ì‚° (M3 Max ê°€ì¤‘ì¹˜)
                quality_score = (
                    mask_coverage * 0.25 +
                    connectivity_score * 0.25 +
                    edge_score * 0.2 +
                    convexity * 0.15 +
                    boundary_smoothness * 0.15
                )
            else:
                # ê¸°ë³¸ ì¢…í•© ì ìˆ˜
                quality_score = (
                    mask_coverage * 0.3 +
                    connectivity_score * 0.3 +
                    edge_score * 0.2 +
                    convexity * 0.2
                )
            
            return min(max(quality_score, 0.0), 1.0)
            
        except Exception as e:
            self.logger.warning(f"í’ˆì§ˆ í‰ê°€ ì‹¤íŒ¨: {e}")
            return 0.5
    
    def _calculate_boundary_smoothness(self, mask: np.ndarray) -> float:
        """ê²½ê³„ì„  ë¶€ë“œëŸ¬ì›€ ê³„ì‚° (M3 Max ì „ìš©)"""
        try:
            contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            
            if not contours:
                return 0.0
            
            largest_contour = max(contours, key=cv2.contourArea)
            
            if len(largest_contour) < 10:
                return 0.0
            
            # ìœ¤ê³½ì„ ì˜ ê³¡ë¥  ë³€í™” ê³„ì‚°
            contour_points = largest_contour.reshape(-1, 2)
            
            # ì—°ì†ëœ ì„¸ ì  ê°„ì˜ ê°ë„ ë³€í™” ê³„ì‚°
            angle_changes = []
            for i in range(2, len(contour_points)):
                p1, p2, p3 = contour_points[i-2], contour_points[i-1], contour_points[i]
                
                v1 = p2 - p1
                v2 = p3 - p2
                
                # ê°ë„ ê³„ì‚°
                cos_angle = np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2) + 1e-8)
                cos_angle = np.clip(cos_angle, -1.0, 1.0)
                angle = np.arccos(cos_angle)
                angle_changes.append(angle)
            
            # ê°ë„ ë³€í™”ì˜ í‘œì¤€í¸ì°¨ (ë‚®ì„ìˆ˜ë¡ ë¶€ë“œëŸ¬ì›€)
            if angle_changes:
                smoothness = 1.0 - min(np.std(angle_changes) / np.pi, 1.0)
                return smoothness
            
            return 0.5
            
        except Exception as e:
            self.logger.warning(f"ê²½ê³„ì„  ë¶€ë“œëŸ¬ì›€ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return 0.5
    
    def _apply_post_processing(self, segmentation_result: Dict[str, Any], quality_level: str) -> Dict[str, Any]:
        """í›„ì²˜ë¦¬ ì ìš© (M3 Max ìµœì í™”)"""
        
        if not self.enable_post_processing:
            return segmentation_result
        
        try:
            mask = segmentation_result['mask'].copy()
            
            # í’ˆì§ˆ ë ˆë²¨ì— ë”°ë¥¸ ì²˜ë¦¬ ê°•ë„
            intensity_map = {'low': 0, 'medium': 1, 'high': 2, 'ultra': 3}
            intensity = intensity_map.get(quality_level, 1)
            
            # M3 Maxì—ì„œ ë” ê°•ë ¥í•œ í›„ì²˜ë¦¬
            if self.is_m3_max and intensity >= 2:
                intensity += 1
            
            processed_mask = mask.copy()
            
            # 1. í˜•íƒœí•™ì  ì—°ì‚° (ë…¸ì´ì¦ˆ ì œê±°)
            if self.morphology_enabled:
                kernel_size = 3 + intensity
                kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (kernel_size, kernel_size))
                processed_mask = cv2.morphologyEx(processed_mask, cv2.MORPH_CLOSE, kernel)
                processed_mask = cv2.morphologyEx(processed_mask, cv2.MORPH_OPEN, kernel)
            
            # 2. ê°€ìš°ì‹œì•ˆ ë¸”ëŸ¬ (ì—£ì§€ ìŠ¤ë¬´ë”©)
            if self.gaussian_blur:
                blur_kernel = 3 + intensity * 2
                if blur_kernel % 2 == 0:
                    blur_kernel += 1
                processed_mask = cv2.GaussianBlur(processed_mask, (blur_kernel, blur_kernel), 0)
                processed_mask = (processed_mask > 127).astype(np.uint8) * 255
            
            # 3. í™€ ì±„ìš°ê¸°
            if self.hole_filling:
                contours, _ = cv2.findContours(processed_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                cv2.fillPoly(processed_mask, contours, 255)
            
            # 4. ì—£ì§€ ì •ì œ (M3 Max ê³ ê¸‰ ëª¨ë“œ)
            if self.edge_refinement and intensity > 0:
                processed_mask = self._refine_edges(processed_mask, intensity)
            
            # 5. M3 Max ì „ìš© ê³ ê¸‰ í›„ì²˜ë¦¬
            if self.is_m3_max and quality_level == 'ultra':
                processed_mask = self._advanced_post_processing(processed_mask)
            
            segmentation_result['mask'] = processed_mask
            segmentation_result['segmented_image'] = self._apply_mask_to_image(
                segmentation_result['segmented_image'], processed_mask
            )
            
            return segmentation_result
            
        except Exception as e:
            self.logger.warning(f"í›„ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return segmentation_result
    
    def _advanced_post_processing(self, mask: np.ndarray) -> np.ndarray:
        """M3 Max ì „ìš© ê³ ê¸‰ í›„ì²˜ë¦¬"""
        try:
            # 1. ìœ¤ê³½ì„  ìŠ¤ë¬´ë”©
            contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            
            if contours:
                # ê°€ì¥ í° ìœ¤ê³½ì„  ì„ íƒ
                largest_contour = max(contours, key=cv2.contourArea)
                
                # ìœ¤ê³½ì„  ê·¼ì‚¬í™” (Douglas-Peucker ì•Œê³ ë¦¬ì¦˜)
                epsilon = 0.005 * cv2.arcLength(largest_contour, True)
                approx_contour = cv2.approxPolyDP(largest_contour, epsilon, True)
                
                # ìƒˆë¡œìš´ ë§ˆìŠ¤í¬ ìƒì„±
                refined_mask = np.zeros_like(mask)
                cv2.fillPoly(refined_mask, [approx_contour], 255)
                
                return refined_mask
            
            return mask
            
        except Exception as e:
            self.logger.warning(f"ê³ ê¸‰ í›„ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return mask
    
    # =================================================================
    # ğŸ”§ í—¬í¼ ë©”ì„œë“œë“¤
    # =================================================================
    
    def _refine_edges(self, mask: np.ndarray, intensity: int) -> np.ndarray:
        """ì—£ì§€ ì •ì œ"""
        try:
            # ì—£ì§€ ê²€ì¶œ
            edges = cv2.Canny(mask, 50, 150)
            
            # ì—£ì§€ í™•ì¥
            kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))
            dilated_edges = cv2.dilate(edges, kernel, iterations=intensity)
            
            # ì›ë³¸ ë§ˆìŠ¤í¬ì™€ ê²°í•©
            refined_mask = cv2.bitwise_or(mask, dilated_edges)
            
            return refined_mask
            
        except Exception as e:
            self.logger.warning(f"ì—£ì§€ ì •ì œ ì‹¤íŒ¨: {e}")
            return mask
    
    def _apply_mask_to_image(self, image: Image.Image, mask: np.ndarray) -> Image.Image:
        """ì´ë¯¸ì§€ì— ë§ˆìŠ¤í¬ ì ìš©"""
        try:
            # PIL ì´ë¯¸ì§€ë¥¼ numpy ë°°ì—´ë¡œ ë³€í™˜
            image_array = np.array(image)
            
            # ë§ˆìŠ¤í¬ë¥¼ 3ì±„ë„ë¡œ í™•ì¥
            if len(mask.shape) == 2:
                mask_3channel = np.stack([mask] * 3, axis=2)
            else:
                mask_3channel = mask
            
            # ë§ˆìŠ¤í¬ ì •ê·œí™” (0-1 ë²”ìœ„)
            mask_normalized = mask_3channel.astype(np.float32) / 255.0
            
            # ë§ˆìŠ¤í¬ ì ìš©
            segmented_array = image_array * mask_normalized
            
            # PIL ì´ë¯¸ì§€ë¡œ ë³€í™˜
            segmented_image = Image.fromarray(segmented_array.astype(np.uint8))
            
            return segmented_image
            
        except Exception as e:
            self.logger.warning(f"ë§ˆìŠ¤í¬ ì ìš© ì‹¤íŒ¨: {e}")
            return image
    
    async def _try_fallback_methods(self, image: Image.Image, clothing_type: str) -> Optional[Dict[str, Any]]:
        """í´ë°± ë°©ë²•ë“¤ ì‹œë„"""
        
        fallback_methods = ['grabcut', 'kmeans', 'threshold']
        best_result = None
        best_quality = 0.0
        
        for method in fallback_methods:
            try:
                if method == 'grabcut' and self.backup_methods:
                    result = self.backup_methods.grabcut_segmentation(image)
                elif method == 'kmeans' and SKLEARN_AVAILABLE:
                    result = await self._segment_with_kmeans(image)
                elif method == 'threshold':
                    result = await self._segment_with_simple_threshold(image)
                else:
                    continue
                
                # í’ˆì§ˆ í‰ê°€
                quality = self._evaluate_quality(image, result['mask'])
                result['quality'] = quality
                
                if quality > best_quality:
                    best_quality = quality
                    best_result = result
                    
                self.logger.info(f"ğŸ“Š í´ë°± ë°©ë²• {method}: í’ˆì§ˆ {quality:.3f}")
                
            except Exception as e:
                self.logger.warning(f"í´ë°± ë°©ë²• {method} ì‹¤íŒ¨: {e}")
                continue
        
        return best_result
    
    # =================================================================
    # ğŸ”§ ê²°ê³¼ ìƒì„± ë° í†µê³„ ë©”ì„œë“œë“¤
    # =================================================================
    
    def _build_final_result(
        self,
        processed_result: Dict[str, Any],
        quality_score: float,
        processing_time: float,
        method: str,
        clothing_type: str,
        quality_level: str
    ) -> Dict[str, Any]:
        """ìµœì¢… ê²°ê³¼ êµ¬ì„±"""
        
        try:
            # ê¸°ë³¸ ê²°ê³¼ êµ¬ì¡°
            result = {
                'success': True,
                'segmented_image': processed_result['segmented_image'],
                'clothing_mask': processed_result['mask'],
                'mask': processed_result['mask'],  # í˜¸í™˜ì„±ì„ ìœ„í•œ ì¤‘ë³µ
                'clothing_type': clothing_type,
                'segmentation_method': method,
                'quality_score': quality_score,
                'confidence': processed_result.get('confidence', quality_score),
                'processing_time': processing_time,
                'quality_level': quality_level
            }
            
            # í’ˆì§ˆ ë“±ê¸‰ ì¶”ê°€
            if quality_score >= 0.9:
                result['quality_grade'] = 'excellent'
            elif quality_score >= 0.8:
                result['quality_grade'] = 'good'
            elif quality_score >= 0.6:
                result['quality_grade'] = 'fair'
            elif quality_score >= 0.4:
                result['quality_grade'] = 'poor'
            else:
                result['quality_grade'] = 'very_poor'
            
            # ì„¸ê·¸ë©˜í…Œì´ì…˜ ë¶„ì„ ì¶”ê°€
            result['segmentation_analysis'] = self._analyze_segmentation(processed_result['mask'])
            
            # ì²˜ë¦¬ ì •ë³´ ì¶”ê°€
            result['processing_info'] = {
                'method_used': method,
                'post_processing_applied': self.enable_post_processing,
                'fallback_used': method in ['grabcut', 'kmeans', 'threshold'],
                'device': self.device,
                'device_type': self.device_type,
                'm3_max_optimized': self.is_m3_max,
                'image_size': f"{processed_result['segmented_image'].size[0]}x{processed_result['segmented_image'].size[1]}",
                'mask_coverage': np.sum(processed_result['mask'] > 0) / processed_result['mask'].size,
                'quality_threshold_met': quality_score >= self.quality_threshold
            }
            
            return result
            
        except Exception as e:
            self.logger.error(f"ìµœì¢… ê²°ê³¼ êµ¬ì„± ì‹¤íŒ¨: {e}")
            return self._create_empty_result("ê²°ê³¼ êµ¬ì„± ì˜¤ë¥˜")
    
    def _analyze_segmentation(self, mask: np.ndarray) -> Dict[str, Any]:
        """ì„¸ê·¸ë©˜í…Œì´ì…˜ ë¶„ì„"""
        
        analysis = {}
        
        try:
            # ë§ˆìŠ¤í¬ ì˜ì—­ ë¶„ì„
            contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            
            if contours:
                # ê°€ì¥ í° ì˜ì—­
                largest_contour = max(contours, key=cv2.contourArea)
                
                # ë°”ìš´ë”© ë°•ìŠ¤
                x, y, w, h = cv2.boundingRect(largest_contour)
                analysis['bounding_box'] = {'x': int(x), 'y': int(y), 'width': int(w), 'height': int(h)}
                
                # ì˜ì—­ ì •ë³´
                analysis['area'] = float(cv2.contourArea(largest_contour))
                analysis['perimeter'] = float(cv2.arcLength(largest_contour, True))
                
                # í˜•íƒœ íŠ¹ì„±
                if analysis['perimeter'] > 0:
                    analysis['compactness'] = 4 * np.pi * analysis['area'] / (analysis['perimeter'] ** 2)
                else:
                    analysis['compactness'] = 0.0
                
                # ì¢…íš¡ë¹„
                if h > 0:
                    analysis['aspect_ratio'] = w / h
                else:
                    analysis['aspect_ratio'] = 1.0
                
                # ì˜ì—­ ê°œìˆ˜
                analysis['num_regions'] = len(contours)
                
                # M3 Max ì¶”ê°€ ë¶„ì„
                if self.is_m3_max:
                    # ë³¼ë¡ì„±
                    hull = cv2.convexHull(largest_contour)
                    hull_area = cv2.contourArea(hull)
                    if hull_area > 0:
                        analysis['convexity'] = analysis['area'] / hull_area
                    else:
                        analysis['convexity'] = 0.0
                    
                    # ê²¬ê³ ì„± (ë©´ì /ë°”ìš´ë”©ë°•ìŠ¤ë©´ì )
                    bbox_area = w * h
                    if bbox_area > 0:
                        analysis['solidity'] = analysis['area'] / bbox_area
                    else:
                        analysis['solidity'] = 0.0
                
            else:
                # ìœ¤ê³½ì„ ì´ ì—†ëŠ” ê²½ìš°
                analysis = {
                    'bounding_box': {'x': 0, 'y': 0, 'width': 0, 'height': 0},
                    'area': 0.0,
                    'perimeter': 0.0,
                    'compactness': 0.0,
                    'aspect_ratio': 1.0,
                    'num_regions': 0
                }
            
        except Exception as e:
            self.logger.warning(f"ì„¸ê·¸ë©˜í…Œì´ì…˜ ë¶„ì„ ì‹¤íŒ¨: {e}")
            analysis = {'error': str(e)}
        
        return analysis
    
    # =================================================================
    # ğŸ”§ ìºì‹œ ë° í†µê³„ ë©”ì„œë“œë“¤
    # =================================================================
    
    def _generate_cache_key(self, image_input, clothing_type: str, quality_level: str) -> str:
        """ìºì‹œ í‚¤ ìƒì„±"""
        try:
            if isinstance(image_input, str):
                base_hash = hash(image_input)
            elif hasattr(image_input, 'tobytes'):
                base_hash = hash(image_input.tobytes())
            else:
                base_hash = hash(str(image_input))
            
            return f"seg_{base_hash}_{clothing_type}_{quality_level}_{self.method}"
        except Exception:
            return f"seg_fallback_{time.time()}"
    
    def _update_cache(self, key: str, result: Dict[str, Any]):
        """ìºì‹œ ì—…ë°ì´íŠ¸"""
        try:
            if len(self.segmentation_cache) >= self.cache_max_size:
                # ê°€ì¥ ì˜¤ë˜ëœ í•­ëª© ì œê±°
                oldest_key = next(iter(self.segmentation_cache))
                del self.segmentation_cache[oldest_key]
            
            # ê²°ê³¼ ë³µì‚¬í•´ì„œ ì €ì¥ (ë¬´ê±°ìš´ ë°ì´í„° ì œì™¸)
            cached_result = {k: v for k, v in result.items() if k not in ['segmented_image']}
            self.segmentation_cache[key] = cached_result
            
        except Exception as e:
            self.logger.warning(f"ìºì‹œ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
    
    def _update_segmentation_stats(self, method: str, quality: float, processing_time: float):
        """3ë‹¨ê³„ ì „ìš© í†µê³„ ì—…ë°ì´íŠ¸"""
        self.segmentation_stats['total_processed'] += 1
        
        if quality > 0.5:
            self.segmentation_stats['successful_segmentations'] += 1
        
        # í’ˆì§ˆ ì´ë™ í‰ê· 
        alpha = 0.1
        self.segmentation_stats['average_quality'] = (
            alpha * quality + 
            (1 - alpha) * self.segmentation_stats['average_quality']
        )
        
        # ë°©ë²•ë³„ ì‚¬ìš© í†µê³„
        if method not in self.segmentation_stats['method_usage']:
            self.segmentation_stats['method_usage'][method] = 0
        self.segmentation_stats['method_usage'][method] += 1
    
    def _create_empty_result(self, reason: str) -> Dict[str, Any]:
        """ë¹ˆ ê²°ê³¼ ìƒì„±"""
        return {
            'success': False,
            'error': reason,
            'segmented_image': None,
            'clothing_mask': None,
            'mask': None,
            'clothing_type': 'unknown',
            'segmentation_method': 'none',
            'quality_score': 0.0,
            'confidence': 0.0,
            'quality_grade': 'failed',
            'processing_time': 0.0,
            'segmentation_analysis': {},
            'processing_info': {
                'method_used': 'none',
                'post_processing_applied': False,
                'fallback_used': False,
                'error_occurred': True,
                'device': self.device,
                'error_details': reason
            }
        }
    
    # =================================================================
    # ğŸ”§ ëª¨ë¸ ìƒì„± ë©”ì„œë“œë“¤
    # =================================================================
    
    async def _create_u2net_model(self):
        """UÂ²-Net ìŠ¤íƒ€ì¼ ëª¨ë¸ ìƒì„± (M3 Max ìµœì í™”)"""
        class SimpleU2Net(torch.nn.Module):
            def __init__(self, is_m3_max=False):
                super(SimpleU2Net, self).__init__()
                
                # M3 Maxì—ì„œ ë” ë³µì¡í•œ ëª¨ë¸
                channels = 64 if is_m3_max else 32
                
                # ê°„ë‹¨í•œ U-Net êµ¬ì¡°
                self.encoder = torch.nn.Sequential(
                    torch.nn.Conv2d(3, channels, 3, padding=1),
                    torch.nn.ReLU(inplace=True),
                    torch.nn.Conv2d(channels, channels, 3, padding=1),
                    torch.nn.ReLU(inplace=True),
                    torch.nn.MaxPool2d(2)
                )
                
                self.middle = torch.nn.Sequential(
                    torch.nn.Conv2d(channels, channels*2, 3, padding=1),
                    torch.nn.ReLU(inplace=True),
                    torch.nn.Conv2d(channels*2, channels*2, 3, padding=1),
                    torch.nn.ReLU(inplace=True),
                )
                
                self.decoder = torch.nn.Sequential(
                    torch.nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True),
                    torch.nn.Conv2d(channels*2, channels, 3, padding=1),
                    torch.nn.ReLU(inplace=True),
                    torch.nn.Conv2d(channels, 1, 1),
                    torch.nn.Sigmoid()
                )
            
            def forward(self, x):
                x1 = self.encoder(x)
                x2 = self.middle(x1)
                x3 = self.decoder(x2)
                return x3
        
        model = SimpleU2Net(self.is_m3_max).to(self.device)
        if self.is_m3_max and self.device == 'mps':
            # M3 Max MPS ìµœì í™”
            model.eval()
            for param in model.parameters():
                param.requires_grad_(False)
        
        return model
    
    def _create_fallback_model(self):
        """í´ë°± ëª¨ë¸ ìƒì„±"""
        class FallbackModel:
            def __call__(self, x):
                batch_size = x.shape[0] if len(x.shape) == 4 else 1
                height, width = x.shape[-2], x.shape[-1]
                return torch.ones(batch_size, 1, height, width) * 0.5
        
        return FallbackModel()
    
    def _create_simple_backup(self):
        """ê°„ë‹¨í•œ ë°±ì—… ë°©ë²• ìƒì„±"""
        class SimpleBackup:
            def grabcut_segmentation(self, image):
                mask = np.ones((image.height, image.width), dtype=np.uint8) * 255
                return {
                    'segmented_image': image,
                    'mask': mask,
                    'method': 'simple_grabcut',
                    'confidence': 0.5
                }
            
            def threshold_segmentation(self, image):
                mask = np.ones((image.height, image.width), dtype=np.uint8) * 255
                return {
                    'segmented_image': image,
                    'mask': mask,
                    'method': 'simple_threshold',
                    'confidence': 0.4
                }
        
        return SimpleBackup()
    
    def _preprocess_for_model(self, image: Image.Image) -> torch.Tensor:
        """ëª¨ë¸ìš© ì´ë¯¸ì§€ ì „ì²˜ë¦¬"""
        try:
            # PILì„ í…ì„œë¡œ ë³€í™˜
            image_array = np.array(image).astype(np.float32) / 255.0
            image_tensor = torch.from_numpy(image_array).permute(2, 0, 1).unsqueeze(0)
            
            # ë””ë°”ì´ìŠ¤ë¡œ ì´ë™
            image_tensor = image_tensor.to(self.device)
            
            return image_tensor
            
        except Exception as e:
            self.logger.error(f"ëª¨ë¸ ì „ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            raise
    
    # =================================================================
    # ğŸ”§ Pipeline Manager í˜¸í™˜ ë©”ì„œë“œë“¤
    # =================================================================
    
    async def get_step_info(self) -> Dict[str, Any]:
        """ğŸ” 3ë‹¨ê³„ ìƒì„¸ ì •ë³´ ë°˜í™˜"""
        base_info = await super().get_step_info()
        
        # 3ë‹¨ê³„ ì „ìš© ì •ë³´ ì¶”ê°€
        base_info.update({
            "segmentation_stats": self.segmentation_stats.copy(),
            "clothing_categories": {
                category: items for category, items in self.CLOTHING_CATEGORIES.items()
            },
            "supported_methods": self.SEGMENTATION_METHODS,
            "cache_usage": {
                "cache_size": len(self.segmentation_cache),
                "cache_limit": self.cache_max_size,
                "hit_rate": self.segmentation_stats['cache_hits'] / max(1, self.segmentation_stats['total_processed'])
            },
            "models_available": {
                "rembg": self.rembg_session is not None,
                "custom_model": self.segmentation_model is not None,
                "backup_methods": self.backup_methods is not None,
                "sklearn_kmeans": SKLEARN_AVAILABLE
            },
            "capabilities": {
                "segmentation_method": self.method,
                "model_name": self.model_name,
                "max_resolution": self.max_resolution,
                "post_processing_enabled": self.enable_post_processing,
                "quality_threshold": self.quality_threshold,
                "background_removal": self.use_background_removal,
                "advanced_analysis": self.is_m3_max
            },
            "rembg_sessions": list(self.rembg_sessions.keys()) if self.rembg_sessions else []
        })
        
        return base_info
    
    def get_supported_clothing_types(self) -> Dict[str, List[str]]:
        """ì§€ì›í•˜ëŠ” ì˜ë¥˜ íƒ€ì… ë°˜í™˜"""
        return self.CLOTHING_CATEGORIES.copy()
    
    def get_supported_methods(self) -> List[str]:
        """ì§€ì›í•˜ëŠ” ì„¸ê·¸ë©˜í…Œì´ì…˜ ë°©ë²•ë“¤ ë°˜í™˜"""
        return self.SEGMENTATION_METHODS.copy()
    
    async def cleanup(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        try:
            self.logger.info("ğŸ§¹ 3ë‹¨ê³„: ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì¤‘...")
            
            # RemBG ì„¸ì…˜ ì •ë¦¬
            if hasattr(self, 'rembg_session'):
                self.rembg_session = None
            self.rembg_sessions = {}
            
            # ëª¨ë¸ ì •ë¦¬
            if hasattr(self, 'segmentation_model'):
                if hasattr(self.segmentation_model, 'cpu'):
                    self.segmentation_model.cpu()
                self.segmentation_model = None
            
            # ë°±ì—… ë°©ë²•ë“¤ ì •ë¦¬
            self.backup_methods = None
            
            # ìºì‹œ ì •ë¦¬
            self.segmentation_cache.clear()
            
            # ë¶€ëª¨ í´ë˜ìŠ¤ ì •ë¦¬
            await super().cleanup()
            
            self.logger.info("âœ… 3ë‹¨ê³„ ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì™„ë£Œ")
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")


# =================================================================
# ğŸ”§ ë°±ì—… ì„¸ê·¸ë©˜í…Œì´ì…˜ ë°©ë²•ë“¤ í´ë˜ìŠ¤
# =================================================================

class BackupSegmentationMethods:
    """ë°±ì—… ì„¸ê·¸ë©˜í…Œì´ì…˜ ë°©ë²•ë“¤ (M3 Max ìµœì í™”)"""
    
    def __init__(self, device: str, is_m3_max: bool = False, memory_gb: float = 16.0):
        self.device = device
        self.is_m3_max = is_m3_max
        self.memory_gb = memory_gb
        self.logger = logging.getLogger(__name__)
    
    def grabcut_segmentation(self, image: Image.Image) -> Dict[str, Any]:
        """GrabCut ì•Œê³ ë¦¬ì¦˜ì„ ì‚¬ìš©í•œ ì„¸ê·¸ë©˜í…Œì´ì…˜ (M3 Max ìµœì í™”)"""
        try:
            # PILì„ OpenCV í˜•ì‹ìœ¼ë¡œ ë³€í™˜
            img = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)
            
            # ì´ˆê¸° ì‚¬ê°í˜• (ì´ë¯¸ì§€ì˜ 10% ì—¬ë°±)
            height, width = img.shape[:2]
            
            # M3 Maxì—ì„œ ë” ì •êµí•œ ì´ˆê¸° ì˜ì—­ ì„¤ì •
            if self.is_m3_max:
                margin = 0.08  # 8% ì—¬ë°± (ë” ì •ë°€)
            else:
                margin = 0.1   # 10% ì—¬ë°±
            
            rect = (
                int(width * margin), 
                int(height * margin), 
                int(width * (1 - 2 * margin)), 
                int(height * (1 - 2 * margin))
            )
            
            # GrabCut ì´ˆê¸°í™”
            mask = np.zeros((height, width), np.uint8)
            bgd_model = np.zeros((1, 65), np.float64)
            fgd_model = np.zeros((1, 65), np.float64)
            
            # M3 Maxì—ì„œ ë” ë§ì€ ë°˜ë³µ
            iterations = 7 if self.is_m3_max else 5
            
            # GrabCut ìˆ˜í–‰
            cv2.grabCut(img, mask, rect, bgd_model, fgd_model, iterations, cv2.GC_INIT_WITH_RECT)
            
            # ë§ˆìŠ¤í¬ í›„ì²˜ë¦¬
            mask2 = np.where((mask == 2) | (mask == 0), 0, 1).astype('uint8')
            final_mask = mask2 * 255
            
            # M3 Maxì—ì„œ ì¶”ê°€ ì •ì œ
            if self.is_m3_max:
                # ëª¨í´ë¡œì§€ ì—°ì‚°ìœ¼ë¡œ ì •ì œ
                kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))
                final_mask = cv2.morphologyEx(final_mask, cv2.MORPH_CLOSE, kernel)
                final_mask = cv2.morphologyEx(final_mask, cv2.MORPH_OPEN, kernel)
            
            # RGBë¡œ ë³€í™˜ëœ ì„¸ê·¸ë©˜í…Œì´ì…˜ ì´ë¯¸ì§€ ìƒì„±
            segmented_img = img * mask2[:, :, np.newaxis]
            segmented_img_rgb = cv2.cvtColor(segmented_img, cv2.COLOR_BGR2RGB)
            segmented_image = Image.fromarray(segmented_img_rgb.astype(np.uint8))
            
            confidence = 0.8 if self.is_m3_max else 0.75
            
            return {
                'segmented_image': segmented_image,
                'mask': final_mask,
                'method': 'grabcut',
                'confidence': confidence
            }
            
        except Exception as e:
            self.logger.warning(f"GrabCut ì‹¤íŒ¨: {e}")
            # í´ë°±: ì „ì²´ ì´ë¯¸ì§€ë¥¼ ë§ˆìŠ¤í¬ë¡œ ë°˜í™˜
            mask = np.ones((image.height, image.width), dtype=np.uint8) * 255
            return {
                'segmented_image': image,
                'mask': mask,
                'method': 'grabcut_fallback',
                'confidence': 0.3
            }
    
    def threshold_segmentation(self, image: Image.Image) -> Dict[str, Any]:
        """ì„ê³„ê°’ ê¸°ë°˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ (M3 Max ìµœì í™”)"""
        try:
            # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜
            gray = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2GRAY)
            
            # M3 Maxì—ì„œ ë” ì •êµí•œ ì„ê³„ê°’ ì²˜ë¦¬
            if self.is_m3_max:
                # ë‹¤ì¤‘ ì„ê³„ê°’ ì¡°í•©
                _, mask1 = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
                mask2 = cv2.adaptiveThreshold(
                    gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2
                )
                mask3 = cv2.adaptiveThreshold(
                    gray, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 11, 2
                )
                
                # ë§ˆìŠ¤í¬ ì¡°í•© (ë‹¤ìˆ˜ê²° ì›ë¦¬)
                mask_sum = (mask1.astype(np.float32) + mask2.astype(np.float32) + mask3.astype(np.float32)) / 3
                mask = (mask_sum > 127).astype(np.uint8) * 255
            else:
                # ê¸°ë³¸ ì ì‘í˜• ì„ê³„ê°’
                mask = cv2.adaptiveThreshold(
                    gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2
                )
            
            # ë…¸ì´ì¦ˆ ì œê±°
            kernel_size = 7 if self.is_m3_max else 5
            kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (kernel_size, kernel_size))
            mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)
            mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)
            
            # M3 Maxì—ì„œ ì¶”ê°€ ì •ì œ
            if self.is_m3_max:
                # ê°€ì¥ í° ì—°ê²° ì„±ë¶„ë§Œ ìœ ì§€
                contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                if contours:
                    # ë©´ì  ê¸°ì¤€ìœ¼ë¡œ ìƒìœ„ ì»´í¬ë„ŒíŠ¸ë“¤ ì„ íƒ
                    contours = sorted(contours, key=cv2.contourArea, reverse=True)
                    mask_refined = np.zeros_like(mask)
                    
                    # ì „ì²´ ë©´ì ì˜ 5% ì´ìƒì¸ ì»´í¬ë„ŒíŠ¸ë“¤ë§Œ ìœ ì§€
                    total_area = mask.shape[0] * mask.shape[1]
                    for contour in contours:
                        if cv2.contourArea(contour) > total_area * 0.05:
                            cv2.fillPoly(mask_refined, [contour], 255)
                    
                    mask = mask_refined
            
            # ì„¸ê·¸ë©˜í…Œì´ì…˜ëœ ì´ë¯¸ì§€ ìƒì„±
            image_array = np.array(image)
            mask_3channel = np.stack([mask] * 3, axis=2)
            segmented_array = image_array * (mask_3channel / 255.0)
            segmented_image = Image.fromarray(segmented_array.astype(np.uint8))
            
            confidence = 0.7 if self.is_m3_max else 0.65
            
            return {
                'segmented_image': segmented_image,
                'mask': mask,
                'method': 'adaptive_threshold',
                'confidence': confidence
            }
            
        except Exception as e:
            self.logger.warning(f"ì„ê³„ê°’ ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‹¤íŒ¨: {e}")
            # í´ë°±
            mask = np.ones((image.height, image.width), dtype=np.uint8) * 255
            return {
                'segmented_image': image,
                'mask': mask,
                'method': 'threshold_fallback',
                'confidence': 0.3
            }
    
    def watershed_segmentation(self, image: Image.Image) -> Dict[str, Any]:
        """Watershed ì„¸ê·¸ë©˜í…Œì´ì…˜ (M3 Max ì „ìš© ê³ ê¸‰ ë°©ë²•)"""
        if not self.is_m3_max:
            # M3 Maxê°€ ì•„ë‹ˆë©´ ê°„ë‹¨í•œ ë°©ë²•ìœ¼ë¡œ í´ë°±
            return self.threshold_segmentation(image)
        
        try:
            # numpy ë°°ì—´ë¡œ ë³€í™˜
            img = np.array(image)
            gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)
            
            # ë…¸ì´ì¦ˆ ì œê±°
            img_blur = cv2.medianBlur(gray, 5)
            
            # ì„ê³„ê°’ìœ¼ë¡œ ì´ì§„ ì´ë¯¸ì§€ ìƒì„±
            _, thresh = cv2.threshold(img_blur, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
            
            # ë…¸ì´ì¦ˆ ì œê±°
            kernel = np.ones((3, 3), np.uint8)
            opening = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel, iterations=2)
            
            # í™•ì‹¤í•œ ë°°ê²½ ì˜ì—­
            sure_bg = cv2.dilate(opening, kernel, iterations=3)
            
            # í™•ì‹¤í•œ ì „ê²½ ì˜ì—­
            dist_transform = cv2.distanceTransform(opening, cv2.DIST_L2, 5)
            _, sure_fg = cv2.threshold(dist_transform, 0.7 * dist_transform.max(), 255, 0)
            
            # ë¶ˆí™•ì‹¤í•œ ì˜ì—­
            sure_fg = np.uint8(sure_fg)
            unknown = cv2.subtract(sure_bg, sure_fg)
            
            # ë§ˆì»¤ ë¼ë²¨ë§
            _, markers = cv2.connectedComponents(sure_fg)
            markers = markers + 1
            markers[unknown == 255] = 0
            
            # Watershed ì ìš©
            markers = cv2.watershed(img, markers)
            
            # ê²°ê³¼ ë§ˆìŠ¤í¬ ìƒì„±
            mask = np.zeros(gray.shape, dtype=np.uint8)
            mask[markers > 1] = 255
            
            # ì„¸ê·¸ë©˜í…Œì´ì…˜ëœ ì´ë¯¸ì§€ ìƒì„±
            mask_3channel = np.stack([mask] * 3, axis=2)
            segmented_array = img * (mask_3channel / 255.0)
            segmented_image = Image.fromarray(segmented_array.astype(np.uint8))
            
            return {
                'segmented_image': segmented_image,
                'mask': mask,
                'method': 'watershed',
                'confidence': 0.8
            }
            
        except Exception as e:
            self.logger.warning(f"Watershed ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‹¤íŒ¨: {e}")
            # í´ë°±
            return self.threshold_segmentation(image)


# =================================================================
# ğŸ”„ í•˜ìœ„ í˜¸í™˜ì„± ì§€ì› (ê¸°ì¡´ ì½”ë“œ í˜¸í™˜)
# =================================================================

async def create_cloth_segmentation_step(
    device: str = "auto",
    config: Dict[str, Any] = None
) -> ClothSegmentationStep:
    """
    ğŸ”„ ê¸°ì¡´ íŒ©í† ë¦¬ í•¨ìˆ˜ í˜¸í™˜ (ê¸°ì¡´ íŒŒì´í”„ë¼ì¸ í˜¸í™˜)
    
    Args:
        device: ì‚¬ìš©í•  ë””ë°”ì´ìŠ¤ ("auto"ëŠ” ìë™ ê°ì§€)
        config: ì„¤ì • ë”•ì…”ë„ˆë¦¬
        
    Returns:
        ClothSegmentationStep: ì´ˆê¸°í™”ëœ 3ë‹¨ê³„ ìŠ¤í…
    """
    # ê¸°ì¡´ ë°©ì‹ í˜¸í™˜
    device_param = None if device == "auto" else device
    
    default_config = {
        "method": "auto",
        "model_name": "u2net",
        "confidence_threshold": 0.5,
        "use_background_removal": True,
        "quality_threshold": 0.7,
        "enable_post_processing": True,
        "max_image_size": 1024,
        "morphology_enabled": True,
        "gaussian_blur": True,
        "edge_refinement": True,
        "hole_filling": True
    }
    
    final_config = {**default_config, **(config or {})}
    
    # âœ… ìƒˆë¡œìš´ í†µì¼ëœ ìƒì„±ì ì‚¬ìš©
    step = ClothSegmentationStep(device=device_param, config=final_config)
    
    if not await step.initialize():
        logger.warning("3ë‹¨ê³„ ì´ˆê¸°í™” ì‹¤íŒ¨í–ˆì§€ë§Œ ì§„í–‰í•©ë‹ˆë‹¤.")
    
    return step

# ê¸°ì¡´ í´ë˜ìŠ¤ëª… ë³„ì¹­ (ì™„ì „ í˜¸í™˜)
ClothSegmentationStepLegacy = ClothSegmentationStep

# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
def get_supported_segmentation_methods() -> List[str]:
    """ì§€ì›í•˜ëŠ” ì„¸ê·¸ë©˜í…Œì´ì…˜ ë°©ë²•ë“¤ ë°˜í™˜"""
    return ClothSegmentationStep.SEGMENTATION_METHODS.copy()

def get_clothing_categories() -> Dict[str, List[str]]:
    """ì˜ë¥˜ ì¹´í…Œê³ ë¦¬ ì •ë³´ ë°˜í™˜"""
    return ClothSegmentationStep.CLOTHING_CATEGORIES.copy()

def is_rembg_available() -> bool:
    """RemBG ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€"""
    return REMBG_AVAILABLE

def is_sklearn_available() -> bool:
    """scikit-learn ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€"""
    return SKLEARN_AVAILABLE