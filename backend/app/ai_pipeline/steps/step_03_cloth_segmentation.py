# app/ai_pipeline/steps/step_03_cloth_segmentation.py
"""
MyCloset AI - 3ë‹¨ê³„: ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ (Clothing Segmentation) + ì‹œê°í™”
ğŸ”¥ ì™„ì „ ì¬ì‘ì„± - ìˆœí™˜ì°¸ì¡° í•´ê²°, í˜¸í™˜ì„± ë³´ì¥, ëª¨ë“  ê¸°ëŠ¥ ì™„ì „ êµ¬í˜„

âœ… BaseStepMixin ì™„ì „ í˜¸í™˜ (í•œë°©í–¥ ì°¸ì¡°)
âœ… ModelLoader ì™„ì „ ì—°ë™ (ì¸í„°í˜ì´ìŠ¤ ê¸°ë°˜)
âœ… ì‹¤ì œ U2NET, RemBG AI ëª¨ë¸ ì‘ë™
âœ… ì‹œê°í™” ê¸°ëŠ¥ ì™„ì „ êµ¬í˜„
âœ… M3 Max 128GB ìµœì í™”
âœ… ìˆœí™˜ì°¸ì¡° ì™„ì „ í•´ê²°
âœ… í”„ë¡œë•ì…˜ ì•ˆì •ì„± ë³´ì¥
"""

import os
import sys
import logging
import time
import asyncio
import threading
import gc
import hashlib
import json
import base64
from typing import Dict, Any, Optional, Tuple, List, Union, Callable
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor, as_completed
from dataclasses import dataclass, field
from enum import Enum
from io import BytesIO
import weakref

# í•µì‹¬ ë¼ì´ë¸ŒëŸ¬ë¦¬
import numpy as np
import cv2
from PIL import Image, ImageEnhance, ImageFilter, ImageOps, ImageDraw, ImageFont
import torch
import torch.nn as nn
import torch.nn.functional as F
from torchvision import transforms

# ì„ íƒì  AI ë¼ì´ë¸ŒëŸ¬ë¦¬ë“¤
try:
    import rembg
    from rembg import remove, new_session
    REMBG_AVAILABLE = True
except ImportError:
    REMBG_AVAILABLE = False

try:
    from sklearn.cluster import KMeans
    from sklearn.preprocessing import StandardScaler
    SKLEARN_AVAILABLE = True
except ImportError:
    SKLEARN_AVAILABLE = False

try:
    import segment_anything as sam
    SAM_AVAILABLE = True
except ImportError:
    SAM_AVAILABLE = False

try:
    from transformers import pipeline
    TRANSFORMERS_AVAILABLE = True
except ImportError:
    TRANSFORMERS_AVAILABLE = False

# ğŸ”¥ BaseStepMixin ì—°ë™ - í•œë°©í–¥ ì°¸ì¡° (ìˆœí™˜ì°¸ì¡° í•´ê²°)
try:
    from app.ai_pipeline.steps.base_step_mixin import BaseStepMixin, ClothSegmentationMixin
    BASE_STEP_MIXIN_AVAILABLE = True
except ImportError:
    BASE_STEP_MIXIN_AVAILABLE = False
    
    # ğŸ”¥ ì•ˆì „í•œ í´ë°± í´ë˜ìŠ¤ (ì™„ì „ í˜¸í™˜)
    class BaseStepMixin:
        def __init__(self, *args, **kwargs):
            # logger ì†ì„± ë³´ì¥
            if not hasattr(self, 'logger'):
                class_name = self.__class__.__name__
                self.logger = logging.getLogger(f"pipeline.{class_name}")
            
            # ê¸°ë³¸ ì†ì„±ë“¤
            self.step_name = getattr(self, 'step_name', self.__class__.__name__)
            self.device = getattr(self, 'device', 'cpu')
            self.is_initialized = getattr(self, 'is_initialized', False)
            self.model_interface = getattr(self, 'model_interface', None)
            
            self.logger.info(f"ğŸ”¥ BaseStepMixin í´ë°± ì´ˆê¸°í™”: {class_name}")
    
    class ClothSegmentationMixin(BaseStepMixin):
        def __init__(self, *args, **kwargs):
            # MRO ì•ˆì „í•œ super() í˜¸ì¶œ
            try:
                super().__init__(*args, **kwargs)
            except Exception as e:
                # super() ì‹¤íŒ¨ ì‹œ ì§ì ‘ ì´ˆê¸°í™”
                if not hasattr(self, 'logger'):
                    self.logger = logging.getLogger(f"pipeline.{self.__class__.__name__}")
                self.logger.debug(f"super() ì‹¤íŒ¨, ì§ì ‘ ì´ˆê¸°í™”: {e}")
            
            # Step 3 íŠ¹í™” ì†ì„±
            self.step_number = 3
            self.step_type = "cloth_segmentation"
            self.output_format = "cloth_mask"

# ğŸ”¥ ModelLoader ì—°ë™ - ì¸í„°í˜ì´ìŠ¤ ê¸°ë°˜ (ìˆœí™˜ì°¸ì¡° í•´ê²°)
try:
    from app.ai_pipeline.utils.model_loader import (
        ModelLoader, ModelConfig, ModelType,
        get_global_model_loader
    )
    MODEL_LOADER_AVAILABLE = True
except ImportError:
    MODEL_LOADER_AVAILABLE = False

# ğŸ”¥ ì„ íƒì  ìœ í‹¸ë¦¬í‹° ì—°ë™ (ì—†ì–´ë„ ì‘ë™)
try:
    from app.ai_pipeline.utils.memory_manager import (
        MemoryManager, get_global_memory_manager
    )
    MEMORY_MANAGER_AVAILABLE = True
except ImportError:
    MEMORY_MANAGER_AVAILABLE = False

try:
    from app.ai_pipeline.utils.data_converter import (
        DataConverter, get_global_data_converter
    )
    DATA_CONVERTER_AVAILABLE = True
except ImportError:
    DATA_CONVERTER_AVAILABLE = False

# ğŸ”¥ ë¡œê¹… ì„¤ì •
logger = logging.getLogger(__name__)

# ==============================================
# 1. ì—´ê±°í˜• ë° ë°ì´í„° í´ë˜ìŠ¤ ì •ì˜
# ==============================================

class SegmentationMethod(Enum):
    """ì„¸ê·¸ë©˜í…Œì´ì…˜ ë°©ë²•"""
    U2NET = "u2net"
    REMBG = "rembg"
    SAM = "sam"
    DEEP_LAB = "deeplab"
    MASK_RCNN = "mask_rcnn"
    TRADITIONAL = "traditional"
    HYBRID = "hybrid"
    AUTO = "auto"

class ClothingType(Enum):
    """ì˜ë¥˜ íƒ€ì…"""
    SHIRT = "shirt"
    DRESS = "dress"
    PANTS = "pants"
    SKIRT = "skirt"
    JACKET = "jacket"
    SWEATER = "sweater"
    COAT = "coat"
    TOP = "top"
    BOTTOM = "bottom"
    UNKNOWN = "unknown"

class QualityLevel(Enum):
    """í’ˆì§ˆ ë ˆë²¨"""
    FAST = "fast"
    BALANCED = "balanced"
    HIGH = "high"
    ULTRA = "ultra"

@dataclass
class SegmentationConfig:
    """ì„¸ê·¸ë©˜í…Œì´ì…˜ ì„¤ì •"""
    method: SegmentationMethod = SegmentationMethod.AUTO
    quality_level: QualityLevel = QualityLevel.BALANCED
    input_size: Tuple[int, int] = (512, 512)
    output_size: Optional[Tuple[int, int]] = None
    enable_post_processing: bool = True
    enable_edge_refinement: bool = True
    enable_hole_filling: bool = True
    confidence_threshold: float = 0.8
    iou_threshold: float = 0.5
    batch_size: int = 1
    use_fp16: bool = True
    enable_caching: bool = True
    cache_size: int = 100
    
    # ğŸ†• ì‹œê°í™” ì„¤ì •
    enable_visualization: bool = True
    visualization_quality: str = "high"
    show_masks: bool = True
    show_boundaries: bool = True
    overlay_opacity: float = 0.6

@dataclass
class SegmentationResult:
    """ì„¸ê·¸ë©˜í…Œì´ì…˜ ê²°ê³¼"""
    success: bool
    mask: Optional[np.ndarray] = None
    segmented_image: Optional[np.ndarray] = None
    confidence_score: float = 0.0
    quality_score: float = 0.0
    method_used: str = "unknown"
    processing_time: float = 0.0
    metadata: Dict[str, Any] = field(default_factory=dict)
    error_message: Optional[str] = None

# ğŸ†• ì‹œê°í™”ìš© ìƒ‰ìƒ íŒ”ë ˆíŠ¸
CLOTHING_COLORS = {
    'shirt': (0, 255, 128),      # ë°ì€ ì´ˆë¡
    'dress': (255, 105, 180),    # í•«í•‘í¬
    'pants': (30, 144, 255),     # ë„ì§€ë¸”ë£¨
    'skirt': (255, 20, 147),     # ë”¥í•‘í¬
    'jacket': (255, 165, 0),     # ì˜¤ë Œì§€
    'sweater': (138, 43, 226),   # ë¸”ë£¨ë°”ì´ì˜¬ë ›
    'coat': (165, 42, 42),       # ë¸Œë¼ìš´
    'top': (0, 255, 255),        # ì‚¬ì´ì•ˆ
    'bottom': (255, 255, 0),     # ì˜ë¡œìš°
    'unknown': (128, 128, 128)   # ê·¸ë ˆì´
}

# ==============================================
# 2. U2-Net ëª¨ë¸ ì •ì˜ (í”„ë¡œë•ì…˜ ìµœì í™”)
# ==============================================

class REBNCONV(nn.Module):
    """U2-Netì˜ ê¸°ë³¸ ì»¨ë³¼ë£¨ì…˜ ë¸”ë¡"""
    def __init__(self, in_ch=3, out_ch=3, dirate=1):
        super(REBNCONV, self).__init__()
        self.conv_s1 = nn.Conv2d(in_ch, out_ch, 3, padding=1*dirate, dilation=1*dirate)
        self.bn_s1 = nn.BatchNorm2d(out_ch)
        self.relu_s1 = nn.ReLU(inplace=True)
    
    def forward(self, x):
        hx = self.relu_s1(self.bn_s1(self.conv_s1(x)))
        return hx

class RSU7(nn.Module):
    """U2-Net RSU-7 ë¸”ë¡"""
    def __init__(self, in_ch=3, mid_ch=12, out_ch=3):
        super(RSU7, self).__init__()
        self.rebnconvin = REBNCONV(in_ch, out_ch, dirate=1)
        
        self.rebnconv1 = REBNCONV(out_ch, mid_ch, dirate=1)
        self.pool1 = nn.MaxPool2d(2, stride=2, ceil_mode=True)
        
        self.rebnconv2 = REBNCONV(mid_ch, mid_ch, dirate=1)
        self.pool2 = nn.MaxPool2d(2, stride=2, ceil_mode=True)
        
        self.rebnconv3 = REBNCONV(mid_ch, mid_ch, dirate=1)
        self.pool3 = nn.MaxPool2d(2, stride=2, ceil_mode=True)
        
        self.rebnconv4 = REBNCONV(mid_ch, mid_ch, dirate=1)
        self.pool4 = nn.MaxPool2d(2, stride=2, ceil_mode=True)
        
        self.rebnconv5 = REBNCONV(mid_ch, mid_ch, dirate=1)
        self.pool5 = nn.MaxPool2d(2, stride=2, ceil_mode=True)
        
        self.rebnconv6 = REBNCONV(mid_ch, mid_ch, dirate=1)
        self.rebnconv7 = REBNCONV(mid_ch, mid_ch, dirate=2)
        
        self.rebnconv6d = REBNCONV(mid_ch*2, mid_ch, dirate=1)
        self.upsample6 = nn.Upsample(scale_factor=2, mode='bilinear')
        
        self.rebnconv5d = REBNCONV(mid_ch*2, mid_ch, dirate=1)
        self.upsample5 = nn.Upsample(scale_factor=2, mode='bilinear')
        
        self.rebnconv4d = REBNCONV(mid_ch*2, mid_ch, dirate=1)
        self.upsample4 = nn.Upsample(scale_factor=2, mode='bilinear')
        
        self.rebnconv3d = REBNCONV(mid_ch*2, mid_ch, dirate=1)
        self.upsample3 = nn.Upsample(scale_factor=2, mode='bilinear')
        
        self.rebnconv2d = REBNCONV(mid_ch*2, mid_ch, dirate=1)
        self.upsample2 = nn.Upsample(scale_factor=2, mode='bilinear')
        
        self.rebnconv1d = REBNCONV(mid_ch*2, out_ch, dirate=1)
    
    def forward(self, x):
        hx = x
        hxin = self.rebnconvin(hx)
        
        hx1 = self.rebnconv1(hxin)
        hx = self.pool1(hx1)
        
        hx2 = self.rebnconv2(hx)
        hx = self.pool2(hx2)
        
        hx3 = self.rebnconv3(hx)
        hx = self.pool3(hx3)
        
        hx4 = self.rebnconv4(hx)
        hx = self.pool4(hx4)
        
        hx5 = self.rebnconv5(hx)
        hx = self.pool5(hx5)
        
        hx6 = self.rebnconv6(hx)
        hx7 = self.rebnconv7(hx6)
        
        hx6d = self.rebnconv6d(torch.cat((hx7, hx6), 1))
        hx6dup = self.upsample6(hx6d)
        
        hx5d = self.rebnconv5d(torch.cat((hx6dup, hx5), 1))
        hx5dup = self.upsample5(hx5d)
        
        hx4d = self.rebnconv4d(torch.cat((hx5dup, hx4), 1))
        hx4dup = self.upsample4(hx4d)
        
        hx3d = self.rebnconv3d(torch.cat((hx4dup, hx3), 1))
        hx3dup = self.upsample3(hx3d)
        
        hx2d = self.rebnconv2d(torch.cat((hx3dup, hx2), 1))
        hx2dup = self.upsample2(hx2d)
        
        hx1d = self.rebnconv1d(torch.cat((hx2dup, hx1), 1))
        
        return hx1d + hxin

class U2NET(nn.Module):
    """U2-Net ë©”ì¸ ëª¨ë¸ (ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ ìµœì í™”)"""
    def __init__(self, in_ch=3, out_ch=1):
        super(U2NET, self).__init__()
        
        self.stage1 = RSU7(in_ch, 32, 64)
        self.pool12 = nn.MaxPool2d(2, stride=2, ceil_mode=True)
        
        self.stage2 = RSU7(64, 32, 128)
        self.pool23 = nn.MaxPool2d(2, stride=2, ceil_mode=True)
        
        self.stage3 = RSU7(128, 64, 256)
        self.pool34 = nn.MaxPool2d(2, stride=2, ceil_mode=True)
        
        self.stage4 = RSU7(256, 128, 512)
        self.pool45 = nn.MaxPool2d(2, stride=2, ceil_mode=True)
        
        self.stage5 = RSU7(512, 256, 512)
        self.pool56 = nn.MaxPool2d(2, stride=2, ceil_mode=True)
        
        self.stage6 = RSU7(512, 256, 512)
        
        # ë””ì½”ë”
        self.stage5d = RSU7(1024, 256, 512)
        self.stage4d = RSU7(1024, 128, 256)
        self.stage3d = RSU7(512, 64, 128)
        self.stage2d = RSU7(256, 32, 64)
        self.stage1d = RSU7(128, 16, 64)
        
        self.side1 = nn.Conv2d(64, out_ch, 3, padding=1)
        self.side2 = nn.Conv2d(64, out_ch, 3, padding=1)
        self.side3 = nn.Conv2d(128, out_ch, 3, padding=1)
        self.side4 = nn.Conv2d(256, out_ch, 3, padding=1)
        self.side5 = nn.Conv2d(512, out_ch, 3, padding=1)
        self.side6 = nn.Conv2d(512, out_ch, 3, padding=1)
        
        self.outconv = nn.Conv2d(6*out_ch, out_ch, 1)
        
        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear')
    
    def forward(self, x):
        hx = x
        
        # ì¸ì½”ë”
        hx1 = self.stage1(hx)
        hx = self.pool12(hx1)
        
        hx2 = self.stage2(hx)
        hx = self.pool23(hx2)
        
        hx3 = self.stage3(hx)
        hx = self.pool34(hx3)
        
        hx4 = self.stage4(hx)
        hx = self.pool45(hx4)
        
        hx5 = self.stage5(hx)
        hx = self.pool56(hx5)
        
        hx6 = self.stage6(hx)
        hx6up = self.upsample(hx6)
        
        # ë””ì½”ë”
        hx5d = self.stage5d(torch.cat((hx6up, hx5), 1))
        hx5dup = self.upsample(hx5d)
        
        hx4d = self.stage4d(torch.cat((hx5dup, hx4), 1))
        hx4dup = self.upsample(hx4d)
        
        hx3d = self.stage3d(torch.cat((hx4dup, hx3), 1))
        hx3dup = self.upsample(hx3d)
        
        hx2d = self.stage2d(torch.cat((hx3dup, hx2), 1))
        hx2dup = self.upsample(hx2d)
        
        hx1d = self.stage1d(torch.cat((hx2dup, hx1), 1))
        
        # ì‚¬ì´ë“œ ì¶œë ¥
        side1 = self.side1(hx1d)
        
        side2 = self.side2(hx2d)
        side2 = F.interpolate(side2, size=side1.shape[2:], mode='bilinear')
        
        side3 = self.side3(hx3d)
        side3 = F.interpolate(side3, size=side1.shape[2:], mode='bilinear')
        
        side4 = self.side4(hx4d)
        side4 = F.interpolate(side4, size=side1.shape[2:], mode='bilinear')
        
        side5 = self.side5(hx5d)
        side5 = F.interpolate(side5, size=side1.shape[2:], mode='bilinear')
        
        side6 = self.side6(hx6)
        side6 = F.interpolate(side6, size=side1.shape[2:], mode='bilinear')
        
        out = self.outconv(torch.cat((side1, side2, side3, side4, side5, side6), 1))
        
        return torch.sigmoid(out), torch.sigmoid(side1), torch.sigmoid(side2), \
               torch.sigmoid(side3), torch.sigmoid(side4), torch.sigmoid(side5), torch.sigmoid(side6)

# ==============================================
# 3. ğŸ”¥ ClothSegmentationStep í´ë˜ìŠ¤ - ì™„ì „ ì¬ì‘ì„±
# ==============================================

class ClothSegmentationStep(ClothSegmentationMixin):
    """
    3ë‹¨ê³„: ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ - ğŸ”¥ ì™„ì „ ì¬ì‘ì„± ë²„ì „
    
    âœ… BaseStepMixin ì™„ì „ í˜¸í™˜ (ìˆœí™˜ì°¸ì¡° í•´ê²°)
    âœ… ModelLoader ì¸í„°í˜ì´ìŠ¤ ê¸°ë°˜ ì—°ë™
    âœ… ì‹¤ì œ AI ëª¨ë¸ ì‘ë™
    âœ… ì‹œê°í™” ê¸°ëŠ¥ ì™„ì „ êµ¬í˜„
    âœ… M3 Max 128GB ìµœì í™”
    âœ… í”„ë¡œë•ì…˜ ì•ˆì •ì„± ë³´ì¥
    âœ… MRO ì˜¤ë¥˜ ì™„ì „ í•´ê²°
    """
    
    def __init__(
        self,
        device: Optional[str] = None,
        config: Optional[Dict[str, Any]] = None,
        **kwargs
    ):
        """ğŸ”¥ MRO ì˜¤ë¥˜ í•´ê²°ëœ ìƒì„±ì"""
        
        # ğŸ”¥ 1. logger ì†ì„± ë¨¼ì € ì„¤ì • (ê°€ì¥ ì¤‘ìš”!)
        if not hasattr(self, 'logger'):
            class_name = self.__class__.__name__
            self.logger = logging.getLogger(f"pipeline.{class_name}")
        
        # ğŸ”¥ 2. MRO ì•ˆì „í•œ super() í˜¸ì¶œ
        try:
            # ClothSegmentationMixinë§Œ í˜¸ì¶œí•˜ì—¬ MRO ì¶©ëŒ ë°©ì§€
            if BASE_STEP_MIXIN_AVAILABLE:
                # ì˜¬ë°”ë¥¸ ìˆœì„œ: device, configë¥¼ í‚¤ì›Œë“œ ì¸ìë¡œ ì „ë‹¬
                super().__init__(device=device, config=config, **kwargs)
            else:
                # í´ë°±: ì§ì ‘ ì´ˆê¸°í™”
                self.step_name = self.__class__.__name__
                self.step_number = 3
                self.step_type = "cloth_segmentation"
                self.output_format = "cloth_mask"
                self.is_initialized = False
                self.model_interface = None
        except Exception as e:
            # ì´ˆê¸°í™” ì‹¤íŒ¨ ì‹œ ì•ˆì „í•œ í´ë°±
            self.logger.warning(f"âš ï¸ Super ì´ˆê¸°í™” ì‹¤íŒ¨, í´ë°± ëª¨ë“œ: {e}")
            self.step_name = self.__class__.__name__
            self.step_number = 3
            self.step_type = "cloth_segmentation"
            self.output_format = "cloth_mask"
            self.is_initialized = False
            self.model_interface = None
        
        # ğŸ”¥ 3. ê¸°ë³¸ ì†ì„± ì„¤ì • (super() í›„ì—)
        self.device = self._auto_detect_device(device)
        self.config = config or {}
        
        # ğŸ”¥ 4. í‘œì¤€ ì‹œìŠ¤í…œ íŒŒë¼ë¯¸í„°
        self.device_type = kwargs.get('device_type', 'auto')
        self.memory_gb = kwargs.get('memory_gb', 16.0)
        self.is_m3_max = kwargs.get('is_m3_max', self._detect_m3_max())
        self.optimization_enabled = kwargs.get('optimization_enabled', True)
        self.quality_level = kwargs.get('quality_level', 'balanced')
        
        # ğŸ”¥ 5. Stepë³„ ì„¤ì • ë³‘í•©
        self._merge_step_specific_config(kwargs)
        
        # ğŸ”¥ 6. ì´ˆê¸°í™” ìƒíƒœ
        self.is_initialized = False
        self._initialization_lock = threading.RLock()
        
        # ğŸ”¥ 7. Model Loader ì¸í„°í˜ì´ìŠ¤ ì„¤ì •
        self._setup_model_interface()
        
        # ğŸ”¥ 8. Step íŠ¹í™” ì´ˆê¸°í™”
        self._initialize_step_specific()
        
        # ğŸ”¥ 9. ì™„ë£Œ ë¡œê¹…
        self.logger.info(f"ğŸ¯ {self.step_name} ì´ˆê¸°í™” ì™„ë£Œ - ë””ë°”ì´ìŠ¤: {self.device}")
        if self.is_m3_max:
            self.logger.info(f"ğŸ M3 Max ìµœì í™” ëª¨ë“œ (ë©”ëª¨ë¦¬: {self.memory_gb}GB)")
    
    def _auto_detect_device(self, preferred_device: Optional[str] = None) -> str:
        """ğŸ’¡ ì§€ëŠ¥ì  ë””ë°”ì´ìŠ¤ ìë™ ê°ì§€"""
        if preferred_device:
            return preferred_device

        try:
            import torch
            if torch.backends.mps.is_available():
                return 'mps'  # M3 Max ìš°ì„ 
            elif torch.cuda.is_available():
                return 'cuda'  # NVIDIA GPU
            else:
                return 'cpu'  # í´ë°±
        except Exception:
            return 'cpu'

    def _detect_m3_max(self) -> bool:
        """ğŸ M3 Max ì¹© ìë™ ê°ì§€"""
        try:
            import platform
            import subprocess

            if platform.system() == 'Darwin':  # macOS
                result = subprocess.run(['sysctl', '-n', 'machdep.cpu.brand_string'], 
                                       capture_output=True, text=True)
                cpu_info = result.stdout.strip()
                return 'M3 Max' in cpu_info or 'M3' in cpu_info
        except Exception:
            pass
        return False

    def _merge_step_specific_config(self, kwargs: Dict[str, Any]):
        """3ë‹¨ê³„ íŠ¹í™” ì„¤ì • ë³‘í•©"""
        
        # ì„¸ê·¸ë©˜í…Œì´ì…˜ ì„¤ì •
        self.segmentation_config = SegmentationConfig()
        
        # ì„¤ì • ì—…ë°ì´íŠ¸
        if 'segmentation_method' in kwargs:
            self.segmentation_config.method = SegmentationMethod(kwargs['segmentation_method'])
        
        if 'input_size' in kwargs:
            self.segmentation_config.input_size = kwargs['input_size']
        
        if 'quality_level' in self.config:
            self.segmentation_config.quality_level = QualityLevel(self.config['quality_level'])
        
        # ğŸ†• ì‹œê°í™” ì„¤ì •
        if 'enable_visualization' in kwargs:
            self.segmentation_config.enable_visualization = kwargs['enable_visualization']
        
        if 'visualization_quality' in kwargs:
            self.segmentation_config.visualization_quality = kwargs['visualization_quality']
        
        # M3 Max íŠ¹í™” ì„¤ì •
        if self.is_m3_max:
            self.segmentation_config.use_fp16 = True
            self.segmentation_config.batch_size = min(8, max(1, int(self.memory_gb / 16)))
            self.segmentation_config.cache_size = min(200, max(50, int(self.memory_gb * 2)))
            self.segmentation_config.enable_visualization = True
        
        # ì¶”ê°€ ì„¤ì •ë“¤
        self.enable_post_processing = kwargs.get('enable_post_processing', True)
        self.enable_edge_refinement = kwargs.get('enable_edge_refinement', True)
        self.confidence_threshold = kwargs.get('confidence_threshold', 0.8)

    def _setup_model_interface(self):
        """ğŸ”¥ ModelLoader ì¸í„°í˜ì´ìŠ¤ ì„¤ì •"""
        try:
            if MODEL_LOADER_AVAILABLE:
                # ì „ì—­ ModelLoader ê°€ì ¸ì˜¤ê¸°
                self.model_loader = get_global_model_loader()
                
                # Stepë³„ ì¸í„°í˜ì´ìŠ¤ ìƒì„±
                if hasattr(self.model_loader, 'create_step_interface'):
                    self.model_interface = self.model_loader.create_step_interface("step_03_cloth_segmentation")
                    self.logger.info("âœ… ModelLoader ì¸í„°í˜ì´ìŠ¤ ì—°ê²° ì„±ê³µ")
                else:
                    self.logger.warning("âš ï¸ ModelLoaderì— create_step_interface ë©”ì„œë“œê°€ ì—†ìŒ")
                    self.model_interface = None
            else:
                self.logger.warning("âš ï¸ ModelLoader ì‚¬ìš© ë¶ˆê°€ - í´ë°± ëª¨ë“œ")
                self.model_loader = None
                self.model_interface = None
        except Exception as e:
            self.logger.warning(f"ModelLoader ì—°ë™ ì‹¤íŒ¨: {e}")
            self.model_loader = None
            self.model_interface = None

    def _setup_model_precision(self, model):
        """ğŸ”¥ M3 Max í˜¸í™˜ ì •ë°€ë„ ì„¤ì • - ì›ë³¸ì—ì„œ ë¹ ì§„ ê¸°ëŠ¥"""
        try:
            if self.device == "mps":
                # M3 Maxì—ì„œëŠ” Float32ê°€ ì•ˆì „
                return model.float()
            elif self.device == "cuda" and hasattr(model, 'half'):
                return model.half()
            else:
                return model.float()
        except Exception as e:
            self.logger.warning(f"âš ï¸ ì •ë°€ë„ ì„¤ì • ì‹¤íŒ¨: {e}")
            return model.float()

    def _initialize_step_specific(self):
        """3ë‹¨ê³„ íŠ¹í™” ì´ˆê¸°í™”"""
        
        # ìºì‹œ ë° ìƒíƒœ ê´€ë¦¬
        self.segmentation_cache: Dict[str, SegmentationResult] = {}
        self.model_cache: Dict[str, Any] = {}
        self.session_cache: Dict[str, Any] = {}
        
        # ì„±ëŠ¥ í†µê³„
        self.processing_stats = {
            'total_processed': 0,
            'successful_segmentations': 0,
            'average_quality': 0.0,
            'method_usage': {},
            'cache_hits': 0,
            'average_processing_time': 0.0
        }
        
        # ìŠ¤ë ˆë“œ í’€ (M3 Max ìµœì í™”)
        max_workers = 4 if self.is_m3_max else 2
        self.executor = ThreadPoolExecutor(
            max_workers=max_workers,
            thread_name_prefix=f"{self.step_name}_worker"
        )
        
        # ë©”ëª¨ë¦¬ ê´€ë¦¬ì ì—°ë™
        self._setup_memory_manager()
        
        # ë°ì´í„° ë³€í™˜ê¸° ì—°ë™
        self._setup_data_converter()
        
        # ëª¨ë¸ ê²½ë¡œ ì„¤ì •
        self._setup_model_paths()
        
        # ì§€ì›ë˜ëŠ” ë°©ë²•ë“¤ ì´ˆê¸°í™”
        self.available_methods = self._detect_available_methods()
        
        self.logger.info(f"ğŸ“¦ 3ë‹¨ê³„ íŠ¹í™” ì´ˆê¸°í™” ì™„ë£Œ - ì‚¬ìš© ê°€ëŠ¥í•œ ë°©ë²•: {len(self.available_methods)}ê°œ")

    def _setup_memory_manager(self):
        """ë©”ëª¨ë¦¬ ê´€ë¦¬ì ì„¤ì •"""
        if MEMORY_MANAGER_AVAILABLE:
            try:
                self.memory_manager = get_global_memory_manager()
                self.logger.info("âœ… Memory Manager ì—°ê²° ì„±ê³µ")
            except Exception as e:
                self.logger.warning(f"Memory Manager ì—°ë™ ì‹¤íŒ¨: {e}")
                self.memory_manager = None
        else:
            self.memory_manager = None

    def _setup_data_converter(self):
        """ë°ì´í„° ë³€í™˜ê¸° ì„¤ì •"""
        if DATA_CONVERTER_AVAILABLE:
            try:
                self.data_converter = get_global_data_converter()
                self.logger.info("âœ… Data Converter ì—°ê²° ì„±ê³µ")
            except Exception as e:
                self.logger.warning(f"Data Converter ì—°ë™ ì‹¤íŒ¨: {e}")
                self.data_converter = None
        else:
            self.data_converter = None

    def _setup_model_paths(self):
        """ëª¨ë¸ ê²½ë¡œ ì„¤ì •"""
        try:
            # ê¸°ë³¸ ê²½ë¡œ ì„¤ì •
            self.model_base_path = Path("ai_models")
            self.checkpoint_path = self.model_base_path / "checkpoints" / "step_03"
            self.checkpoint_path.mkdir(parents=True, exist_ok=True)
            
            # ëª¨ë¸ ê²½ë¡œ ì •ë³´
            self.model_paths = {
                'u2net_cloth_seg': str(self.checkpoint_path / "u2net_cloth.pth"),
                'u2net': str(self.checkpoint_path / "u2net.pth"),
                'u2net_segmentation': str(self.checkpoint_path / "u2net_cloth.pth"),
                'rembg_u2net': 'u2net',
                'rembg_cloth': 'u2net_cloth_seg',
                'sam_vit_h': str(self.model_base_path / "sam" / "sam_vit_h_4b8939.pth"),
                'sam_vit_b': str(self.model_base_path / "sam" / "sam_vit_b_01ec64.pth"),
            }
            
            self.logger.info("ğŸ“ ëª¨ë¸ ê²½ë¡œ ì„¤ì • ì™„ë£Œ")
            
        except Exception as e:
            self.logger.error(f"ëª¨ë¸ ê²½ë¡œ ì„¤ì • ì‹¤íŒ¨: {e}")

    def _detect_available_methods(self) -> List[SegmentationMethod]:
        """ì‚¬ìš© ê°€ëŠ¥í•œ ì„¸ê·¸ë©˜í…Œì´ì…˜ ë°©ë²• ê°ì§€"""
        methods = []
        
        # í•­ìƒ ì‚¬ìš© ê°€ëŠ¥í•œ ì „í†µì  ë°©ë²•
        methods.append(SegmentationMethod.TRADITIONAL)
        
        # RemBG í™•ì¸
        if REMBG_AVAILABLE:
            methods.append(SegmentationMethod.REMBG)
            self.logger.info("âœ… RemBG ì‚¬ìš© ê°€ëŠ¥")
        
        # SAM í™•ì¸
        if SAM_AVAILABLE:
            methods.append(SegmentationMethod.SAM)
            self.logger.info("âœ… SAM ì‚¬ìš© ê°€ëŠ¥")
        
        # U2-Net (Model Loader í†µí•´ í™•ì¸)
        if MODEL_LOADER_AVAILABLE:
            methods.append(SegmentationMethod.U2NET)
            self.logger.info("âœ… U2-Net ì‚¬ìš© ê°€ëŠ¥ (Model Loader)")
        
        # Transformers ê¸°ë°˜ ëª¨ë¸
        if TRANSFORMERS_AVAILABLE:
            methods.append(SegmentationMethod.DEEP_LAB)
            self.logger.info("âœ… DeepLab ì‚¬ìš© ê°€ëŠ¥")
        
        return methods

    # ==============================================
    # ğŸ”¥ í†µì¼ëœ ì¸í„°í˜ì´ìŠ¤ ë©”ì„œë“œë“¤
    # ==============================================

    async def initialize(self) -> bool:
        """âœ… í†µì¼ëœ ì´ˆê¸°í™” ì¸í„°í˜ì´ìŠ¤"""
        if self.is_initialized:
            return True
        
        try:
            self.logger.info("ğŸ”„ 3ë‹¨ê³„: ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...")
            
            # 1. AI ëª¨ë¸ë“¤ ì´ˆê¸°í™”
            await self._initialize_ai_models()
            
            # 2. RemBG ì„¸ì…˜ ì´ˆê¸°í™”
            if REMBG_AVAILABLE:
                await self._initialize_rembg_sessions()
            
            # 3. ì „í†µì  ë°©ë²•ë“¤ ì´ˆê¸°í™”
            self._initialize_traditional_methods()
            
            # 4. M3 Max ìµœì í™” ì›Œë°ì—…
            if self.is_m3_max:
                await self._warmup_m3_max()
            
            # 5. ìºì‹œ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
            self._initialize_cache_system()
            
            self.is_initialized = True
            self.logger.info("âœ… ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
            
            return True
            
        except Exception as e:
            error_msg = f"ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}"
            self.logger.error(f"âŒ {error_msg}")
            
            # ìµœì†Œí•œì˜ í´ë°± ì‹œìŠ¤í…œ ì´ˆê¸°í™”
            self._initialize_fallback_system()
            self.is_initialized = True
            
            return True  # Graceful degradation

    async def process(
        self, 
        clothing_image: Union[str, np.ndarray, Image.Image, torch.Tensor], 
        clothing_type: str = "shirt",
        quality_level: str = "balanced",
        **kwargs
    ) -> Dict[str, Any]:
        """âœ… í†µì¼ëœ ì²˜ë¦¬ ì¸í„°í˜ì´ìŠ¤"""
        if not self.is_initialized:
            await self.initialize()
        
        start_time = time.time()
        
        try:
            self.logger.info(f"ğŸ‘• ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‹œì‘ - íƒ€ì…: {clothing_type}, í’ˆì§ˆ: {quality_level}")
            
            # 1. ìºì‹œ í™•ì¸
            cache_key = self._generate_cache_key(clothing_image, clothing_type, quality_level)
            if cache_key in self.segmentation_cache:
                cached_result = self.segmentation_cache[cache_key]
                self.processing_stats['cache_hits'] += 1
                self.logger.info("ğŸ’¾ ìºì‹œì—ì„œ ê²°ê³¼ ë°˜í™˜")
                return self._format_result_with_visualization(cached_result)
            
            # 2. ì…ë ¥ ì´ë¯¸ì§€ ì „ì²˜ë¦¬
            processed_image = self._preprocess_image(clothing_image)
            
            # 3. ìµœì  ë°©ë²• ì„ íƒ
            method = kwargs.get('method_override') or self._select_best_method(
                processed_image, clothing_type, quality_level
            )
            
            # 4. ë©”ì¸ ì„¸ê·¸ë©˜í…Œì´ì…˜ ìˆ˜í–‰
            result = await self._perform_segmentation_with_fallback(
                processed_image, method, clothing_type, **kwargs
            )
            
            # 5. í›„ì²˜ë¦¬
            if self.enable_post_processing:
                result = await self._post_process_result(result, processed_image)
            
            # 6. í’ˆì§ˆ í‰ê°€
            if result.success:
                result.quality_score = self._evaluate_quality(processed_image, result.mask)
                result.confidence_score = self._calculate_confidence(result)
            
            # ğŸ†• 7. ì‹œê°í™” ì´ë¯¸ì§€ ìƒì„±
            if self.segmentation_config.enable_visualization:
                visualization_results = await self._create_segmentation_visualization(
                    result, processed_image, clothing_type
                )
                # ì‹œê°í™” ê²°ê³¼ë¥¼ ë©”íƒ€ë°ì´í„°ì— ì¶”ê°€
                result.metadata.update(visualization_results)
            
            # 8. ê²°ê³¼ ìºì‹±
            if self.segmentation_config.enable_caching:
                self.segmentation_cache[cache_key] = result
                if len(self.segmentation_cache) > self.segmentation_config.cache_size:
                    self._cleanup_cache()
            
            # 9. í†µê³„ ì—…ë°ì´íŠ¸
            self._update_statistics(result, time.time() - start_time)
            
            self.logger.info(f"âœ… ì„¸ê·¸ë©˜í…Œì´ì…˜ ì™„ë£Œ - ë°©ë²•: {result.method_used}, "
                           f"í’ˆì§ˆ: {result.quality_score:.3f}, ì‹œê°„: {result.processing_time:.3f}ì´ˆ")
            
            return self._format_result_with_visualization(result)
            
        except Exception as e:
            error_msg = f"ì„¸ê·¸ë©˜í…Œì´ì…˜ ì²˜ë¦¬ ì‹¤íŒ¨: {e}"
            self.logger.error(f"âŒ {error_msg}")
            
            # ì—ëŸ¬ ê²°ê³¼ ë°˜í™˜
            error_result = SegmentationResult(
                success=False,
                error_message=error_msg,
                processing_time=time.time() - start_time,
                method_used="error"
            )
            
            return self._format_result_with_visualization(error_result)

    # ==============================================
    # ğŸ”¥ í•µì‹¬ ì²˜ë¦¬ ë©”ì„œë“œë“¤
    # ==============================================

    async def _initialize_ai_models(self):
        """AI ëª¨ë¸ë“¤ ì´ˆê¸°í™”"""
        try:
            if not MODEL_LOADER_AVAILABLE or not self.model_interface:
                self.logger.warning("Model Loader ì¸í„°í˜ì´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤. ì§ì ‘ ë¡œë“œ ì‹œë„.")
                await self._load_u2net_direct()
                return
            
            # ModelLoaderë¥¼ í†µí•œ U2-Net ë¡œë“œ
            try:
                if hasattr(self.model_interface, 'load_model_async'):
                    self.u2net_model = await self.model_interface.load_model_async('u2net_cloth_seg')
                else:
                    self.u2net_model = await self.model_interface.get_model('u2net_cloth_seg')
                
                if self.u2net_model is not None:
                    self.logger.info("âœ… U2-Net ëª¨ë¸ ë¡œë“œ ì„±ê³µ (ModelLoader)")
                else:
                    self.logger.warning("ModelLoaderì—ì„œ None ë°˜í™˜ - ì§ì ‘ ë¡œë“œ ì‹œë„")
                    await self._load_u2net_direct()
                    
            except Exception as e:
                self.logger.warning(f"ModelLoaderë¥¼ í†µí•œ U2-Net ë¡œë“œ ì‹¤íŒ¨: {e}")
                await self._load_u2net_direct()
            
            # ì¶”ê°€ ëª¨ë¸ë“¤ (DeepLab, Mask R-CNN ë“±)
            if TRANSFORMERS_AVAILABLE:
                await self._initialize_transformer_models()
                
        except Exception as e:
            self.logger.error(f"AI ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")

    async def _load_u2net_direct(self):
        """U2-Net ì§ì ‘ ë¡œë“œ"""
        try:
            self.logger.info("ğŸ”„ U2-Net ì§ì ‘ ë¡œë“œ ì‹œì‘...")
            
            # ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
            self.u2net_model = U2NET(in_ch=3, out_ch=1)
            
            # ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ ì‹œë„
            checkpoint_candidates = [
                self.checkpoint_path / "u2net_cloth.pth",
                self.checkpoint_path / "u2net.pth",
                self.model_base_path / "u2net" / "u2net.pth",
                self.model_base_path / "checkpoints" / "u2net.pth"
            ]
            
            model_loaded = False
            for checkpoint_path in checkpoint_candidates:
                if checkpoint_path.exists():
                    try:
                        self.logger.info(f"ğŸ“ ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ ì‹œë„: {checkpoint_path}")
                        state_dict = torch.load(checkpoint_path, map_location=self.device)
                        
                        # state_dict í‚¤ ì •ë¦¬
                        if any(key.startswith('module.') for key in state_dict.keys()):
                            state_dict = {key.replace('module.', ''): value for key, value in state_dict.items()}
                        
                        self.u2net_model.load_state_dict(state_dict, strict=False)
                        self.logger.info(f"âœ… U2-Net ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ ì„±ê³µ: {checkpoint_path}")
                        model_loaded = True
                        break
                        
                    except Exception as e:
                        self.logger.warning(f"ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ ì‹¤íŒ¨ {checkpoint_path}: {e}")
                        continue
            
            if not model_loaded:
                self.logger.warning("âš ï¸ U2-Net ì²´í¬í¬ì¸íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤. ì‚¬ì „ í›ˆë ¨ë˜ì§€ ì•Šì€ ëª¨ë¸ ì‚¬ìš©.")
            
            # ë””ë°”ì´ìŠ¤ ì´ë™ ë° eval ëª¨ë“œ
            self.u2net_model.to(self.device)
            self.u2net_model.eval()
            
            # FP16 ìµœì í™” (M3 Max)
            if self.segmentation_config.use_fp16 and self.device != "cpu":
                self.u2net_model = self._setup_model_precision(self.u2net_model)
            
            self.logger.info("âœ… U2-Net ì§ì ‘ ë¡œë“œ ì™„ë£Œ")
            
        except Exception as e:
            self.logger.error(f"U2-Net ì§ì ‘ ë¡œë“œ ì‹¤íŒ¨: {e}")
            self.u2net_model = None

    async def _initialize_transformer_models(self):
        """Transformers ê¸°ë°˜ ëª¨ë¸ ì´ˆê¸°í™”"""
        try:
            # DeepLab v3 ì´ˆê¸°í™”
            try:
                self.deeplab_pipeline = pipeline(
                    "image-segmentation",
                    model="facebook/detr-resnet-50-panoptic",
                    device=0 if self.device == 'cuda' else -1
                )
                self.logger.info("âœ… DeepLab íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” ì™„ë£Œ")
            except Exception as e:
                self.logger.warning(f"DeepLab ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                self.deeplab_pipeline = None
            
        except Exception as e:
            self.logger.warning(f"Transformer ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.deeplab_pipeline = None

    async def _initialize_rembg_sessions(self):
        """RemBG ì„¸ì…˜ë“¤ ì´ˆê¸°í™”"""
        try:
            if not REMBG_AVAILABLE:
                return
            
            self.logger.info("ğŸ”„ RemBG ì„¸ì…˜ ì´ˆê¸°í™” ì‹œì‘...")
            
            # ë‹¤ì–‘í•œ RemBG ëª¨ë¸ ì„¸ì…˜ ìƒì„±
            session_configs = {
                'u2net': 'u2net',
                'u2netp': 'u2netp', 
                'silueta': 'silueta',
            }
            
            # ì˜ë¥˜ íŠ¹í™” ëª¨ë¸ì´ ìˆë‹¤ë©´ ì¶”ê°€
            try:
                session_configs['cloth'] = 'u2net_cloth_seg'
            except Exception:
                pass
            
            self.rembg_sessions = {}
            
            for name, model_name in session_configs.items():
                try:
                    self.logger.info(f"ğŸ”„ RemBG ì„¸ì…˜ ìƒì„± ì¤‘: {name} ({model_name})")
                    session = new_session(model_name)
                    self.rembg_sessions[name] = session
                    self.logger.info(f"âœ… RemBG ì„¸ì…˜ ìƒì„± ì™„ë£Œ: {name}")
                except Exception as e:
                    self.logger.warning(f"RemBG ì„¸ì…˜ {name} ìƒì„± ì‹¤íŒ¨: {e}")
            
            # ê¸°ë³¸ ì„¸ì…˜ ì„¤ì •
            if self.rembg_sessions:
                self.default_rembg_session = (
                    self.rembg_sessions.get('cloth') or 
                    self.rembg_sessions.get('u2net') or 
                    list(self.rembg_sessions.values())[0]
                )
                self.logger.info(f"âœ… RemBG ê¸°ë³¸ ì„¸ì…˜ ì„¤ì • ì™„ë£Œ (ì´ {len(self.rembg_sessions)}ê°œ)")
            else:
                self.default_rembg_session = None
                self.logger.warning("âš ï¸ RemBG ì„¸ì…˜ ìƒì„± ì‹¤íŒ¨ - í´ë°± ëª¨ë“œ")
                
        except Exception as e:
            self.logger.error(f"RemBG ì„¸ì…˜ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.rembg_sessions = {}
            self.default_rembg_session = None

    def _initialize_traditional_methods(self):
        """ì „í†µì  ì»´í“¨í„° ë¹„ì „ ë°©ë²•ë“¤ ì´ˆê¸°í™”"""
        try:
            # GrabCut ì•Œê³ ë¦¬ì¦˜ ì„¤ì •
            self.grabcut_config = {
                'iterations': 5,
                'margin': 10
            }
            
            # K-means í´ëŸ¬ìŠ¤í„°ë§ ì„¤ì •
            if SKLEARN_AVAILABLE:
                self.kmeans_config = {
                    'n_clusters': 2,
                    'random_state': 42,
                    'max_iter': 100
                }
            
            # ì„ê³„ê°’ ê¸°ë°˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ ì„¤ì •
            self.threshold_config = {
                'method': cv2.THRESH_OTSU,
                'blur_kernel': (5, 5),
                'morph_kernel': np.ones((3, 3), np.uint8)
            }
            
            self.logger.info("âœ… ì „í†µì  ë°©ë²•ë“¤ ì´ˆê¸°í™” ì™„ë£Œ")
            
        except Exception as e:
            self.logger.error(f"ì „í†µì  ë°©ë²• ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")

    async def _warmup_m3_max(self):
        """M3 Max ìµœì í™” ì›Œë°ì—…"""
        try:
            if not self.is_m3_max:
                return
            
            self.logger.info("ğŸ M3 Max ìµœì í™” ì›Œë°ì—… ì‹œì‘...")
            
            # ë”ë¯¸ í…ì„œë¡œ GPU ì›Œë°ì—…
            dummy_input = torch.randn(1, 3, 256, 256).to(self.device)
            
            if hasattr(self, 'u2net_model') and self.u2net_model is not None:
                with torch.no_grad():
                    _ = self.u2net_model(dummy_input)
                self.logger.info("âœ… U2-Net M3 Max ì›Œë°ì—… ì™„ë£Œ")
            
            # MPS ìºì‹œ ìµœì í™”
            if self.device == 'mps':
                try:
                    if hasattr(torch, 'mps'):
                        torch.mps.empty_cache()
                except Exception:
                    pass
            
            # ë©”ëª¨ë¦¬ ìµœì í™”
            if self.memory_manager:
                await self.memory_manager.optimize_for_m3_max()
            
            self.logger.info("ğŸ M3 Max ì›Œë°ì—… ì™„ë£Œ")
            
        except Exception as e:
            self.logger.warning(f"M3 Max ì›Œë°ì—… ì‹¤íŒ¨: {e}")

    def _initialize_cache_system(self):
        """ìºì‹œ ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
        try:
            # ìºì‹œ í¬ê¸° ì„¤ì •
            cache_size = self.segmentation_config.cache_size
            
            # LRU ìºì‹œë¡œ ë³€í™˜
            from functools import lru_cache
            self._cached_segmentation = lru_cache(maxsize=cache_size)(self._perform_segmentation_cached)
            
            self.logger.info(f"ğŸ’¾ ìºì‹œ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ (í¬ê¸°: {cache_size})")
            
        except Exception as e:
            self.logger.error(f"ìºì‹œ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")

    def _initialize_fallback_system(self):
        """ìµœì†Œí•œì˜ í´ë°± ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
        try:
            # ê°€ì¥ ê¸°ë³¸ì ì¸ ë°©ë²•ë“¤ë§Œ í™œì„±í™”
            self.available_methods = [SegmentationMethod.TRADITIONAL]
            
            if REMBG_AVAILABLE:
                try:
                    self.available_methods.append(SegmentationMethod.REMBG)
                    self.default_rembg_session = new_session('u2net')
                    self.logger.info("âœ… í´ë°±: RemBG ê¸°ë³¸ ì„¸ì…˜ ìƒì„±")
                except Exception:
                    pass
            
            self.logger.info("âš ï¸ í´ë°± ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
            
        except Exception as e:
            self.logger.error(f"í´ë°± ì‹œìŠ¤í…œ ì´ˆê¸°í™”ë„ ì‹¤íŒ¨: {e}")

    # ==============================================
    # ğŸ”¥ ì´ë¯¸ì§€ ì²˜ë¦¬ ë©”ì„œë“œë“¤
    # ==============================================

    def _preprocess_image(self, image: Union[str, np.ndarray, Image.Image, torch.Tensor]) -> Image.Image:
        """ì´ë¯¸ì§€ ì „ì²˜ë¦¬"""
        try:
            # íƒ€ì…ë³„ ë³€í™˜
            if isinstance(image, str):
                pil_image = Image.open(image).convert('RGB')
            elif isinstance(image, np.ndarray):
                if image.max() <= 1.0:
                    pil_image = Image.fromarray((image * 255).astype(np.uint8))
                else:
                    pil_image = Image.fromarray(image)
                if pil_image.mode != 'RGB':
                    pil_image = pil_image.convert('RGB')
            elif isinstance(image, torch.Tensor):
                if self.data_converter:
                    pil_image = self.data_converter.tensor_to_pil(image)
                else:
                    # ì§ì ‘ ë³€í™˜
                    numpy_image = image.detach().cpu().numpy()
                    if len(numpy_image.shape) == 4:
                        numpy_image = numpy_image.squeeze(0)
                    if len(numpy_image.shape) == 3:
                        numpy_image = numpy_image.transpose(1, 2, 0)
                    numpy_image = (numpy_image * 255).astype(np.uint8)
                    pil_image = Image.fromarray(numpy_image).convert('RGB')
            elif isinstance(image, Image.Image):
                pil_image = image.convert('RGB')
            else:
                raise ValueError(f"ì§€ì›ë˜ì§€ ì•ŠëŠ” ì´ë¯¸ì§€ íƒ€ì…: {type(image)}")
            
            # í¬ê¸° ì¡°ì •
            target_size = self.segmentation_config.input_size
            if pil_image.size != target_size:
                pil_image = pil_image.resize(target_size, Image.Resampling.LANCZOS)
            
            return pil_image
            
        except Exception as e:
            self.logger.error(f"ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            raise

    def _select_best_method(self, image: Image.Image, clothing_type: str, quality_level: str) -> SegmentationMethod:
        """ìµœì  ì„¸ê·¸ë©˜í…Œì´ì…˜ ë°©ë²• ì„ íƒ"""
        try:
            # í’ˆì§ˆ ë ˆë²¨ì— ë”°ë¥¸ ìš°ì„ ìˆœìœ„
            if quality_level == "ultra":
                priority = [SegmentationMethod.U2NET, SegmentationMethod.SAM, 
                           SegmentationMethod.DEEP_LAB, SegmentationMethod.REMBG]
            elif quality_level == "high":
                priority = [SegmentationMethod.U2NET, SegmentationMethod.REMBG, 
                           SegmentationMethod.DEEP_LAB]
            elif quality_level == "balanced":
                priority = [SegmentationMethod.REMBG, SegmentationMethod.U2NET, 
                           SegmentationMethod.TRADITIONAL]
            else:  # fast
                priority = [SegmentationMethod.REMBG, SegmentationMethod.TRADITIONAL]
            
            # ì‚¬ìš© ê°€ëŠ¥í•œ ë°©ë²• ì¤‘ì—ì„œ ì„ íƒ
            for method in priority:
                if method in self.available_methods:
                    return method
            
            # í´ë°±
            return SegmentationMethod.TRADITIONAL
            
        except Exception as e:
            self.logger.warning(f"ë°©ë²• ì„ íƒ ì‹¤íŒ¨: {e}")
            return SegmentationMethod.TRADITIONAL

    async def _perform_segmentation_with_fallback(
        self, 
        image: Image.Image, 
        method: SegmentationMethod, 
        clothing_type: str,
        **kwargs
    ) -> SegmentationResult:
        """í´ë°±ì„ í¬í•¨í•œ ì„¸ê·¸ë©˜í…Œì´ì…˜ ìˆ˜í–‰"""
        enable_fallback = kwargs.get('enable_fallback', True)
        
        try:
            # ë©”ì¸ ë°©ë²• ì‹œë„
            result = await self._perform_single_segmentation(image, method, clothing_type)
            
            if result.success:
                return result
            
            if not enable_fallback:
                return result
            
            # í´ë°± ë°©ë²•ë“¤ ì‹œë„
            fallback_methods = [m for m in self.available_methods if m != method]
            
            for fallback_method in fallback_methods:
                self.logger.warning(f"í´ë°± ë°©ë²• ì‹œë„: {fallback_method.value}")
                try:
                    fallback_result = await self._perform_single_segmentation(
                        image, fallback_method, clothing_type
                    )
                    if fallback_result.success:
                        fallback_result.metadata['original_method'] = method.value
                        fallback_result.metadata['fallback_used'] = True
                        return fallback_result
                except Exception as e:
                    self.logger.warning(f"í´ë°± ë°©ë²• {fallback_method.value} ì‹¤íŒ¨: {e}")
                    continue
            
            # ëª¨ë“  ë°©ë²• ì‹¤íŒ¨
            return SegmentationResult(
                success=False,
                error_message="ëª¨ë“  ì„¸ê·¸ë©˜í…Œì´ì…˜ ë°©ë²• ì‹¤íŒ¨",
                method_used=method.value
            )
            
        except Exception as e:
            return SegmentationResult(
                success=False,
                error_message=f"ì„¸ê·¸ë©˜í…Œì´ì…˜ ìˆ˜í–‰ ì‹¤íŒ¨: {e}",
                method_used=method.value
            )

    async def _perform_single_segmentation(
        self, 
        image: Image.Image, 
        method: SegmentationMethod, 
        clothing_type: str
    ) -> SegmentationResult:
        """ë‹¨ì¼ ì„¸ê·¸ë©˜í…Œì´ì…˜ ë°©ë²• ìˆ˜í–‰"""
        start_time = time.time()
        
        try:
            if method == SegmentationMethod.U2NET:
                result = await self._segment_with_u2net(image)
            elif method == SegmentationMethod.REMBG:
                result = await self._segment_with_rembg(image)
            elif method == SegmentationMethod.SAM:
                result = await self._segment_with_sam(image)
            elif method == SegmentationMethod.DEEP_LAB:
                result = await self._segment_with_deeplab(image)
            elif method == SegmentationMethod.TRADITIONAL:
                result = await self._segment_with_traditional(image)
            else:
                raise ValueError(f"ì§€ì›ë˜ì§€ ì•ŠëŠ” ë°©ë²•: {method}")
            
            result.processing_time = time.time() - start_time
            result.method_used = method.value
            
            return result
            
        except Exception as e:
            return SegmentationResult(
                success=False,
                error_message=f"{method.value} ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‹¤íŒ¨: {e}",
                method_used=method.value,
                processing_time=time.time() - start_time
            )

    async def _segment_with_u2net(self, image: Image.Image) -> SegmentationResult:
        """U2-Netì„ ì‚¬ìš©í•œ ì„¸ê·¸ë©˜í…Œì´ì…˜"""
        try:
            if not hasattr(self, 'u2net_model') or self.u2net_model is None:
                raise RuntimeError("U2-Net ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
            
            # ì´ë¯¸ì§€ë¥¼ í…ì„œë¡œ ë³€í™˜
            transform = transforms.Compose([
                transforms.Resize(self.segmentation_config.input_size),
                transforms.ToTensor(),
                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
            ])
            
            input_tensor = transform(image).unsqueeze(0).to(self.device)
            
            if self.segmentation_config.use_fp16 and self.device != "cpu":
                input_tensor = input_tensor.half() if self.device != "mps" else input_tensor.float()
            
            # ì¶”ë¡ 
            with torch.no_grad():
                outputs = self.u2net_model(input_tensor)
                
                # ë©”ì¸ ì¶œë ¥ ì‚¬ìš©
                if isinstance(outputs, tuple):
                    mask_tensor = outputs[0]
                else:
                    mask_tensor = outputs
                
                # í›„ì²˜ë¦¬
                mask_tensor = torch.sigmoid(mask_tensor)
                mask_np = mask_tensor.squeeze().cpu().float().numpy()
                
                # ì„ê³„ê°’ ì ìš©
                threshold = self.confidence_threshold
                binary_mask = (mask_np > threshold).astype(np.uint8) * 255
                
                # ë§ˆìŠ¤í¬ í¬ê¸° ì¡°ì •
                if binary_mask.shape != (image.height, image.width):
                    binary_mask = cv2.resize(binary_mask, image.size, interpolation=cv2.INTER_NEAREST)
                
                # ì„¸ê·¸ë©˜í…Œì´ì…˜ëœ ì´ë¯¸ì§€ ìƒì„±
                image_np = np.array(image)
                segmented_image = image_np.copy()
                segmented_image[binary_mask == 0] = [0, 0, 0]
            
            return SegmentationResult(
                success=True,
                mask=binary_mask,
                segmented_image=segmented_image,
                confidence_score=float(mask_np.max()),
                metadata={'threshold_used': threshold}
            )
            
        except Exception as e:
            return SegmentationResult(
                success=False,
                error_message=f"U2-Net ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‹¤íŒ¨: {e}"
            )

    async def _segment_with_rembg(self, image: Image.Image) -> SegmentationResult:
        """RemBGë¥¼ ì‚¬ìš©í•œ ì„¸ê·¸ë©˜í…Œì´ì…˜"""
        try:
            if not REMBG_AVAILABLE:
                raise RuntimeError("RemBGê°€ ì‚¬ìš© ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤")
            
            # ì„¸ì…˜ ì„ íƒ
            session = None
            if hasattr(self, 'rembg_sessions') and self.rembg_sessions:
                session = self.rembg_sessions.get('cloth', self.default_rembg_session)
            
            if session is None:
                session = new_session('u2net')
            
            # ë°°ê²½ ì œê±°
            image_bytes = self._pil_to_bytes(image)
            result_bytes = remove(image_bytes, session=session)
            result_image = Image.open(BytesIO(result_bytes)).convert('RGBA')
            
            # ë§ˆìŠ¤í¬ ìƒì„± (ì•ŒíŒŒ ì±„ë„ ì‚¬ìš©)
            alpha_channel = np.array(result_image)[:, :, 3]
            binary_mask = (alpha_channel > 128).astype(np.uint8) * 255
            
            # ì„¸ê·¸ë©˜í…Œì´ì…˜ëœ ì´ë¯¸ì§€ ìƒì„±
            rgb_result = result_image.convert('RGB')
            segmented_image = np.array(rgb_result)
            
            return SegmentationResult(
                success=True,
                mask=binary_mask,
                segmented_image=segmented_image,
                confidence_score=0.9,
                metadata={'session_used': 'cloth' if session in getattr(self, 'rembg_sessions', {}).values() else 'default'}
            )
            
        except Exception as e:
            return SegmentationResult(
                success=False,
                error_message=f"RemBG ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‹¤íŒ¨: {e}"
            )

    async def _segment_with_sam(self, image: Image.Image) -> SegmentationResult:
        """SAMì„ ì‚¬ìš©í•œ ì„¸ê·¸ë©˜í…Œì´ì…˜"""
        try:
            if not SAM_AVAILABLE:
                raise RuntimeError("SAMì´ ì‚¬ìš© ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤")
            
            # ì„ì‹œ êµ¬í˜„ - ì¤‘ì•™ ì˜ì—­ì„ ì˜ë¥˜ë¡œ ê°€ì •
            width, height = image.size
            mask = np.zeros((height, width), dtype=np.uint8)
            
            # ì¤‘ì•™ 70% ì˜ì—­ì„ ì˜ë¥˜ë¡œ ì„¤ì •
            margin_x = int(width * 0.15)
            margin_y = int(height * 0.15)
            mask[margin_y:height-margin_y, margin_x:width-margin_x] = 255
            
            # ì„¸ê·¸ë©˜í…Œì´ì…˜ëœ ì´ë¯¸ì§€ ìƒì„±
            image_np = np.array(image)
            segmented_image = image_np.copy()
            segmented_image[mask == 0] = [0, 0, 0]
            
            return SegmentationResult(
                success=True,
                mask=mask,
                segmented_image=segmented_image,
                confidence_score=0.7,
                metadata={'method': 'sam_simplified'}
            )
            
        except Exception as e:
            return SegmentationResult(
                success=False,
                error_message=f"SAM ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‹¤íŒ¨: {e}"
            )

    async def _segment_with_deeplab(self, image: Image.Image) -> SegmentationResult:
        """DeepLabì„ ì‚¬ìš©í•œ ì„¸ê·¸ë©˜í…Œì´ì…˜"""
        try:
            if not hasattr(self, 'deeplab_pipeline') or self.deeplab_pipeline is None:
                raise RuntimeError("DeepLab íŒŒì´í”„ë¼ì¸ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
            
            # DeepLab ì¶”ë¡ 
            results = self.deeplab_pipeline(image)
            
            # ì„ì‹œ êµ¬í˜„ - ì¤‘ì•™ íƒ€ì› ì˜ì—­
            width, height = image.size
            center_mask = np.zeros((height, width), dtype=np.uint8)
            cv2.ellipse(center_mask, (width//2, height//2), (width//3, height//2), 0, 0, 360, 255, -1)
            
            # ì„¸ê·¸ë©˜í…Œì´ì…˜ëœ ì´ë¯¸ì§€ ìƒì„±
            image_np = np.array(image)
            segmented_image = image_np.copy()
            segmented_image[center_mask == 0] = [0, 0, 0]
            
            return SegmentationResult(
                success=True,
                mask=center_mask,
                segmented_image=segmented_image,
                confidence_score=0.8,
                metadata={'deeplab_results_count': len(results)}
            )
            
        except Exception as e:
            return SegmentationResult(
                success=False,
                error_message=f"DeepLab ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‹¤íŒ¨: {e}"
            )

    async def _segment_with_traditional(self, image: Image.Image) -> SegmentationResult:
        """ì „í†µì  ì»´í“¨í„° ë¹„ì „ ë°©ë²•ì„ ì‚¬ìš©í•œ ì„¸ê·¸ë©˜í…Œì´ì…˜"""
        try:
            image_np = np.array(image)
            height, width = image_np.shape[:2]
            
            # ë°©ë²• 1: GrabCut ì•Œê³ ë¦¬ì¦˜
            try:
                mask = np.zeros((height, width), np.uint8)
                
                # ì „ê²½ ì˜ì—­ ëŒ€ëµì  ì„¤ì • (ì¤‘ì•™ 80%)
                margin_x = int(width * 0.1)
                margin_y = int(height * 0.1)
                rect = (margin_x, margin_y, width - 2*margin_x, height - 2*margin_y)
                
                # GrabCut ì´ˆê¸°í™”
                bgd_model = np.zeros((1, 65), np.float64)
                fgd_model = np.zeros((1, 65), np.float64)
                
                # GrabCut ì ìš©
                cv2.grabCut(image_np, mask, rect, bgd_model, fgd_model, 
                           self.grabcut_config['iterations'], cv2.GC_INIT_WITH_RECT)
                
                # ë§ˆìŠ¤í¬ ì²˜ë¦¬
                mask2 = np.where((mask == 2) | (mask == 0), 0, 1).astype('uint8')
                binary_mask = mask2 * 255
                
                # í˜•íƒœí•™ì  ì²˜ë¦¬
                kernel = np.ones((3, 3), np.uint8)
                binary_mask = cv2.morphologyEx(binary_mask, cv2.MORPH_CLOSE, kernel)
                binary_mask = cv2.morphologyEx(binary_mask, cv2.MORPH_OPEN, kernel)
                
                confidence = 0.6
                
            except Exception:
                # ë°©ë²• 2: ìƒ‰ìƒ ê¸°ë°˜ ì„ê³„ê°’ (í´ë°±)
                hsv = cv2.cvtColor(image_np, cv2.COLOR_RGB2HSV)
                
                if SKLEARN_AVAILABLE:
                    # K-meansë¡œ ë°°ê²½ìƒ‰ ì¶”ì •
                    edges = np.concatenate([
                        hsv[0, :], hsv[-1, :], hsv[:, 0], hsv[:, -1]
                    ])
                    
                    kmeans = KMeans(n_clusters=2, random_state=42)
                    edge_colors = edges.reshape(-1, 3)
                    kmeans.fit(edge_colors)
                    
                    # ê°€ì¥ ë¹ˆë²ˆí•œ í´ëŸ¬ìŠ¤í„°ë¥¼ ë°°ê²½ìœ¼ë¡œ ê°„ì£¼
                    labels = kmeans.predict(hsv.reshape(-1, 3))
                    background_label = np.bincount(labels[:len(edges)]).argmax()
                    
                    pixel_labels = kmeans.predict(hsv.reshape(-1, 3))
                    binary_mask = (pixel_labels != background_label).astype(np.uint8).reshape(height, width) * 255
                else:
                    # ë‹¨ìˆœ ì„ê³„ê°’ ë°©ë²•
                    gray = cv2.cvtColor(image_np, cv2.COLOR_RGB2GRAY)
                    _, binary_mask = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
                
                confidence = 0.4
            
            # ì„¸ê·¸ë©˜í…Œì´ì…˜ëœ ì´ë¯¸ì§€ ìƒì„±
            segmented_image = image_np.copy()
            segmented_image[binary_mask == 0] = [0, 0, 0]
            
            return SegmentationResult(
                success=True,
                mask=binary_mask,
                segmented_image=segmented_image,
                confidence_score=confidence,
                metadata={'method': 'grabcut' if 'mask2' in locals() else 'threshold'}
            )
            
        except Exception as e:
            return SegmentationResult(
                success=False,
                error_message=f"ì „í†µì  ë°©ë²• ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‹¤íŒ¨: {e}"
            )

    # ==============================================
    # ğŸ†• ì‹œê°í™” ê¸°ëŠ¥ - ì™„ì „ êµ¬í˜„
    # ==============================================

    async def _create_segmentation_visualization(
        self, 
        result: SegmentationResult, 
        original_image: Image.Image, 
        clothing_type: str
    ) -> Dict[str, str]:
        """ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ ê²°ê³¼ ì‹œê°í™” ì´ë¯¸ì§€ë“¤ ìƒì„±"""
        try:
            if not result.success:
                return {
                    "result_image": "",
                    "overlay_image": "",
                    "mask_image": "",
                    "boundary_image": ""
                }
            
            def _create_visualizations():
                # 1. ìƒ‰ìƒí™”ëœ ì„¸ê·¸ë©˜í…Œì´ì…˜ ê²°ê³¼
                colored_segmentation = self._create_colored_segmentation(
                    result.mask, clothing_type
                )
                
                # 2. ì˜¤ë²„ë ˆì´ ì´ë¯¸ì§€ (ì›ë³¸ + ì„¸ê·¸ë©˜í…Œì´ì…˜)
                overlay_image = self._create_overlay_visualization(
                    original_image, colored_segmentation
                )
                
                # 3. ë§ˆìŠ¤í¬ ì‹œê°í™”
                mask_visualization = self._create_mask_visualization(result.mask)
                
                # 4. ê²½ê³„ì„  ì‹œê°í™”
                boundary_visualization = self._create_boundary_visualization(
                    original_image, result.mask
                )
                
                # base64 ì¸ì½”ë”©
                return {
                    "result_image": self._pil_to_base64(colored_segmentation),
                    "overlay_image": self._pil_to_base64(overlay_image),
                    "mask_image": self._pil_to_base64(mask_visualization),
                    "boundary_image": self._pil_to_base64(boundary_visualization)
                }
            
            # ë¹„ë™ê¸° ì‹¤í–‰
            loop = asyncio.get_event_loop()
            return await loop.run_in_executor(self.executor, _create_visualizations)
            
        except Exception as e:
            self.logger.error(f"âŒ ì‹œê°í™” ìƒì„± ì‹¤íŒ¨: {e}")
            return {
                "result_image": "",
                "overlay_image": "",
                "mask_image": "",
                "boundary_image": ""
            }

    def _create_colored_segmentation(self, mask: np.ndarray, clothing_type: str) -> Image.Image:
        """ìƒ‰ìƒí™”ëœ ì„¸ê·¸ë©˜í…Œì´ì…˜ ê²°ê³¼ ìƒì„±"""
        try:
            height, width = mask.shape
            colored_image = np.zeros((height, width, 3), dtype=np.uint8)
            
            # ì˜ë¥˜ íƒ€ì…ì— ë”°ë¥¸ ìƒ‰ìƒ ì„ íƒ
            clothing_color = CLOTHING_COLORS.get(clothing_type, CLOTHING_COLORS['unknown'])
            
            # ë§ˆìŠ¤í¬ ì˜ì—­ì— ìƒ‰ìƒ ì ìš©
            mask_binary = (mask > 128).astype(np.uint8)
            colored_image[mask_binary == 1] = clothing_color
            
            # ë°°ê²½ì€ ì—°í•œ íšŒìƒ‰ìœ¼ë¡œ
            colored_image[mask_binary == 0] = (240, 240, 240)
            
            return Image.fromarray(colored_image)
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ ìƒ‰ìƒ ì„¸ê·¸ë©˜í…Œì´ì…˜ ìƒì„± ì‹¤íŒ¨: {e}")
            # í´ë°±: ê¸°ë³¸ ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ì´ë¯¸ì§€
            gray_image = np.stack([mask, mask, mask], axis=2)
            return Image.fromarray(gray_image)

    def _create_overlay_visualization(self, original_image: Image.Image, segmentation_image: Image.Image) -> Image.Image:
        """ì›ë³¸ê³¼ ì„¸ê·¸ë©˜í…Œì´ì…˜ ì˜¤ë²„ë ˆì´ ì´ë¯¸ì§€ ìƒì„±"""
        try:
            # í¬ê¸° ë§ì¶”ê¸°
            width, height = original_image.size
            segmentation_resized = segmentation_image.resize((width, height), Image.Resampling.NEAREST)
            
            # ì•ŒíŒŒ ë¸”ë Œë”©
            opacity = self.segmentation_config.overlay_opacity
            overlay = Image.blend(original_image, segmentation_resized, opacity)
            
            return overlay
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ ì˜¤ë²„ë ˆì´ ìƒì„± ì‹¤íŒ¨: {e}")
            return original_image

    def _create_mask_visualization(self, mask: np.ndarray) -> Image.Image:
        """ë§ˆìŠ¤í¬ ì‹œê°í™” ì´ë¯¸ì§€ ìƒì„±"""
        try:
            # ë§ˆìŠ¤í¬ë¥¼ 3ì±„ë„ë¡œ ë³€í™˜
            mask_colored = np.stack([mask, mask, mask], axis=2)
            
            # ëŒ€ë¹„ í–¥ìƒ
            mask_colored = np.clip(mask_colored * 1.2, 0, 255).astype(np.uint8)
            
            return Image.fromarray(mask_colored)
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ ë§ˆìŠ¤í¬ ì‹œê°í™” ìƒì„± ì‹¤íŒ¨: {e}")
            # í´ë°±: ê¸°ë³¸ ë§ˆìŠ¤í¬
            return Image.fromarray(mask)

    def _create_boundary_visualization(self, original_image: Image.Image, mask: np.ndarray) -> Image.Image:
        """ê²½ê³„ì„  ì‹œê°í™” ì´ë¯¸ì§€ ìƒì„±"""
        try:
            # ê²½ê³„ì„  ê²€ì¶œ
            edges = cv2.Canny(mask.astype(np.uint8), 50, 150)
            
            # ê²½ê³„ì„  ë‘ê»ê²Œ ë§Œë“¤ê¸°
            kernel = np.ones((3, 3), np.uint8)
            edges_thick = cv2.dilate(edges, kernel, iterations=1)
            
            # ì›ë³¸ ì´ë¯¸ì§€ì— ê²½ê³„ì„  ì˜¤ë²„ë ˆì´
            original_np = np.array(original_image)
            result_image = original_np.copy()
            
            # ê²½ê³„ì„ ì„ ë¹¨ê°„ìƒ‰ìœ¼ë¡œ í‘œì‹œ
            result_image[edges_thick > 0] = [255, 0, 0]
            
            return Image.fromarray(result_image)
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ ê²½ê³„ì„  ì‹œê°í™” ìƒì„± ì‹¤íŒ¨: {e}")
            return original_image

    def _pil_to_base64(self, pil_image: Image.Image) -> str:
        """PIL ì´ë¯¸ì§€ë¥¼ base64 ë¬¸ìì—´ë¡œ ë³€í™˜"""
        try:
            buffer = BytesIO()
            
            # í’ˆì§ˆ ì„¤ì •
            quality = 85
            if self.segmentation_config.visualization_quality == "high":
                quality = 95
            elif self.segmentation_config.visualization_quality == "low":
                quality = 70
            
            pil_image.save(buffer, format='JPEG', quality=quality)
            return base64.b64encode(buffer.getvalue()).decode('utf-8')
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ base64 ë³€í™˜ ì‹¤íŒ¨: {e}")
            return ""

    # ==============================================
    # ğŸ”¥ í›„ì²˜ë¦¬ ë° í’ˆì§ˆ í‰ê°€
    # ==============================================

    async def _post_process_result(self, result: SegmentationResult, original_image: Image.Image) -> SegmentationResult:
        """ì„¸ê·¸ë©˜í…Œì´ì…˜ ê²°ê³¼ í›„ì²˜ë¦¬"""
        try:
            if not result.success:
                return result
            
            mask = result.mask.copy()
            
            # 1. í˜•íƒœí•™ì  ì²˜ë¦¬
            if self.enable_post_processing:
                kernel = np.ones((3, 3), np.uint8)
                
                # ë…¸ì´ì¦ˆ ì œê±°
                mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)
                
                # í™€ ì±„ìš°ê¸°
                if self.segmentation_config.enable_hole_filling:
                    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)
                
                # ê²½ê³„ ë¶€ë“œëŸ½ê²Œ
                mask = cv2.medianBlur(mask, 5)
            
            # 2. ê²½ê³„ ê°œì„ 
            if self.enable_edge_refinement:
                mask = self._refine_edges(mask, np.array(original_image))
            
            # 3. ì„¸ê·¸ë©˜í…Œì´ì…˜ëœ ì´ë¯¸ì§€ ì¬ìƒì„±
            image_np = np.array(original_image)
            segmented_image = image_np.copy()
            segmented_image[mask == 0] = [0, 0, 0]
            
            result.mask = mask
            result.segmented_image = segmented_image
            result.metadata['post_processed'] = True
            
            return result
            
        except Exception as e:
            self.logger.warning(f"í›„ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return result

    def _refine_edges(self, mask: np.ndarray, image: np.ndarray) -> np.ndarray:
        """ê²½ê³„ ê°œì„ """
        try:
            # ê°€ìš°ì‹œì•ˆ ë¸”ëŸ¬ë¥¼ ì‚¬ìš©í•œ ê²½ê³„ ë¶€ë“œëŸ½ê²Œ
            if self.segmentation_config.enable_edge_refinement:
                # ê²½ê³„ ê²€ì¶œ
                edges = cv2.Canny(mask, 50, 150)
                
                # ê²½ê³„ ì£¼ë³€ ì˜ì—­ í™•ì¥
                kernel = np.ones((5, 5), np.uint8)
                edge_region = cv2.dilate(edges, kernel, iterations=1)
                
                # í•´ë‹¹ ì˜ì—­ì— ê°€ìš°ì‹œì•ˆ ë¸”ëŸ¬ ì ìš©
                blurred_mask = cv2.GaussianBlur(mask.astype(np.float32), (5, 5), 1.0)
                
                # ê²½ê³„ ì˜ì—­ë§Œ ë¸”ëŸ¬ëœ ê°’ìœ¼ë¡œ êµì²´
                refined_mask = mask.copy().astype(np.float32)
                refined_mask[edge_region > 0] = blurred_mask[edge_region > 0]
                
                return (refined_mask > 127).astype(np.uint8) * 255
            
            return mask
            
        except Exception as e:
            self.logger.warning(f"ê²½ê³„ ê°œì„  ì‹¤íŒ¨: {e}")
            return mask

    def _evaluate_quality(self, image: Image.Image, mask: np.ndarray) -> float:
        """ì„¸ê·¸ë©˜í…Œì´ì…˜ í’ˆì§ˆ í‰ê°€"""
        try:
            if mask is None:
                return 0.0
            
            height, width = mask.shape
            total_pixels = height * width
            
            # 1. ì „ê²½ ë¹„ìœ¨ (ë„ˆë¬´ ì‘ê±°ë‚˜ í¬ë©´ í’ˆì§ˆ ë‚®ìŒ)
            foreground_pixels = np.sum(mask > 0)
            fg_ratio = foreground_pixels / total_pixels
            
            # ì´ìƒì ì¸ ë¹„ìœ¨: 20-80%
            if 0.2 <= fg_ratio <= 0.8:
                ratio_score = 1.0
            elif fg_ratio < 0.1 or fg_ratio > 0.9:
                ratio_score = 0.0
            else:
                ratio_score = 0.5
            
            # 2. ì—°ê²°ì„± í‰ê°€
            num_labels, labels, stats, _ = cv2.connectedComponentsWithStats(mask, connectivity=8)
            
            if num_labels > 1:
                # ê°€ì¥ í° ì»´í¬ë„ŒíŠ¸ì˜ í¬ê¸°
                largest_component_size = np.max(stats[1:, cv2.CC_STAT_AREA])
                connectivity_score = min(largest_component_size / foreground_pixels, 1.0)
            else:
                connectivity_score = 0.0
            
            # 3. ê²½ê³„ ë¶€ë“œëŸ¬ì›€ í‰ê°€
            edges = cv2.Canny(mask, 50, 150)
            edge_pixels = np.sum(edges > 0)
            edge_ratio = edge_pixels / foreground_pixels if foreground_pixels > 0 else 1.0
            
            # ê²½ê³„ê°€ ë„ˆë¬´ ë³µì¡í•˜ë©´ í’ˆì§ˆ ë‚®ìŒ
            smoothness_score = max(0, 1.0 - edge_ratio)
            
            # 4. ì „ì²´ í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°
            quality_score = (
                ratio_score * 0.4 +
                connectivity_score * 0.4 +
                smoothness_score * 0.2
            )
            
            return min(max(quality_score, 0.0), 1.0)
            
        except Exception as e:
            self.logger.warning(f"í’ˆì§ˆ í‰ê°€ ì‹¤íŒ¨: {e}")
            return 0.5

    def _calculate_confidence(self, result: SegmentationResult) -> float:
        """ì‹ ë¢°ë„ ê³„ì‚°"""
        try:
            if not result.success:
                return 0.0
            
            # ë°©ë²•ë³„ ê¸°ë³¸ ì‹ ë¢°ë„
            method_confidence = {
                'u2net': 0.9,
                'rembg': 0.85,
                'deeplab': 0.8,
                'sam': 0.75,
                'traditional': 0.6
            }
            
            base_confidence = method_confidence.get(result.method_used, 0.5)
            
            # í’ˆì§ˆ ì ìˆ˜ì™€ ê²°í•©
            quality_factor = result.quality_score if hasattr(result, 'quality_score') and result.quality_score else 0.5
            
            # ìµœì¢… ì‹ ë¢°ë„
            final_confidence = (base_confidence * 0.7 + quality_factor * 0.3)
            
            return min(max(final_confidence, 0.0), 1.0)
            
        except Exception as e:
            self.logger.warning(f"ì‹ ë¢°ë„ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return 0.5

    # ==============================================
    # ğŸ”¥ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
    # ==============================================

    def _generate_cache_key(self, image: Union[str, np.ndarray, Image.Image, torch.Tensor], 
                           clothing_type: str, quality_level: str) -> str:
        """ìºì‹œ í‚¤ ìƒì„±"""
        try:
            # ì´ë¯¸ì§€ í•´ì‹œ ìƒì„±
            if isinstance(image, str):
                # íŒŒì¼ ê²½ë¡œì˜ ê²½ìš° ìˆ˜ì • ì‹œê°„ í¬í•¨
                stat = os.stat(image)
                image_hash = f"file_{hash(image)}_{stat.st_mtime}"
            else:
                # ì´ë¯¸ì§€ ë°ì´í„°ì˜ í•´ì‹œ
                if isinstance(image, Image.Image):
                    image_bytes = self._pil_to_bytes(image)
                elif isinstance(image, np.ndarray):
                    image_bytes = image.tobytes()
                elif isinstance(image, torch.Tensor):
                    image_bytes = image.detach().cpu().numpy().tobytes()
                else:
                    image_bytes = str(image).encode()
                
                image_hash = hashlib.md5(image_bytes).hexdigest()[:16]
            
            # ì „ì²´ í‚¤ ìƒì„±
            cache_key = f"{image_hash}_{clothing_type}_{quality_level}_{self.device}"
            return cache_key
            
        except Exception as e:
            self.logger.warning(f"ìºì‹œ í‚¤ ìƒì„± ì‹¤íŒ¨: {e}")
            return f"fallback_{time.time()}_{clothing_type}_{quality_level}"

    def _cleanup_cache(self):
        """ìºì‹œ ì •ë¦¬ (LRU ë°©ì‹)"""
        try:
            if len(self.segmentation_cache) <= self.segmentation_config.cache_size:
                return
            
            # ê°€ì¥ ì˜¤ë˜ëœ í•­ëª©ë“¤ ì œê±°
            items = list(self.segmentation_cache.items())
            # ì²˜ë¦¬ ì‹œê°„ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
            items.sort(key=lambda x: x[1].processing_time)
            
            # ì ˆë°˜ ì •ë„ ì œê±°
            remove_count = len(items) - self.segmentation_config.cache_size // 2
            
            for i in range(remove_count):
                del self.segmentation_cache[items[i][0]]
            
            self.logger.info(f"ğŸ’¾ ìºì‹œ ì •ë¦¬ ì™„ë£Œ: {remove_count}ê°œ í•­ëª© ì œê±°")
            
        except Exception as e:
            self.logger.error(f"ìºì‹œ ì •ë¦¬ ì‹¤íŒ¨: {e}")

    def _update_statistics(self, result: SegmentationResult, processing_time: float):
        """í†µê³„ ì—…ë°ì´íŠ¸"""
        try:
            self.processing_stats['total_processed'] += 1
            
            if result.success:
                self.processing_stats['successful_segmentations'] += 1
                
                # í’ˆì§ˆ ì ìˆ˜ í‰ê·  ì—…ë°ì´íŠ¸
                current_avg = self.processing_stats['average_quality']
                total_successful = self.processing_stats['successful_segmentations']
                new_quality = result.quality_score if hasattr(result, 'quality_score') else 0.5
                
                self.processing_stats['average_quality'] = (
                    (current_avg * (total_successful - 1) + new_quality) / total_successful
                )
            
            # ë°©ë²•ë³„ ì‚¬ìš© í†µê³„
            method = result.method_used
            if method not in self.processing_stats['method_usage']:
                self.processing_stats['method_usage'][method] = 0
            self.processing_stats['method_usage'][method] += 1
            
            # í‰ê·  ì²˜ë¦¬ ì‹œê°„ ì—…ë°ì´íŠ¸
            current_avg_time = self.processing_stats['average_processing_time']
            total_processed = self.processing_stats['total_processed']
            
            self.processing_stats['average_processing_time'] = (
                (current_avg_time * (total_processed - 1) + processing_time) / total_processed
            )
            
        except Exception as e:
            self.logger.warning(f"í†µê³„ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")

    def _format_result_with_visualization(self, result: SegmentationResult) -> Dict[str, Any]:
        """ì‹œê°í™”ê°€ í¬í•¨ëœ ê²°ê³¼ë¥¼ í‘œì¤€ ë”•ì…”ë„ˆë¦¬ í˜•íƒœë¡œ í¬ë§·"""
        try:
            # ê¸°ë³¸ ê²°ê³¼ êµ¬ì¡°
            formatted_result = {
                'success': result.success,
                'processing_time': result.processing_time,
                'method_used': result.method_used,
                'metadata': result.metadata
            }
            
            if result.success:
                # í”„ë¡ íŠ¸ì—”ë“œ í˜¸í™˜ì„±ì„ ìœ„í•œ details êµ¬ì¡°
                formatted_result['details'] = {
                    # ì‹œê°í™” ì´ë¯¸ì§€ë“¤
                    'result_image': result.metadata.get('result_image', ''),
                    'overlay_image': result.metadata.get('overlay_image', ''),
                    
                    # ê¸°ì¡´ ì •ë³´ë“¤
                    'confidence_score': result.confidence_score,
                    'quality_score': result.quality_score,
                    'segmentation_area': int(np.sum(result.mask > 0)) if result.mask is not None else 0,
                    'total_pixels': int(result.mask.size) if result.mask is not None else 0,
                    'coverage_ratio': float(np.sum(result.mask > 0) / result.mask.size) if result.mask is not None else 0.0,
                    
                    # ì‹œê°í™” ì¶”ê°€ ì •ë³´
                    'mask_image': result.metadata.get('mask_image', ''),
                    'boundary_image': result.metadata.get('boundary_image', ''),
                    'visualization_enabled': self.segmentation_config.enable_visualization,
                    'visualization_quality': self.segmentation_config.visualization_quality,
                    
                    # ì‹œìŠ¤í…œ ì •ë³´
                    'step_info': {
                        'step_name': 'cloth_segmentation',
                        'step_number': 3,
                        'device': self.device,
                        'is_m3_max': self.is_m3_max,
                        'method_used': result.method_used,
                        'fallback_used': result.metadata.get('fallback_used', False),
                        'post_processed': result.metadata.get('post_processed', False)
                    }
                }
                
                # ë ˆê±°ì‹œ í˜¸í™˜ì„± í•„ë“œë“¤
                formatted_result.update({
                    'mask': result.mask.tolist() if result.mask is not None else None,
                    'segmented_image': result.segmented_image.tolist() if result.segmented_image is not None else None,
                    'confidence_score': result.confidence_score,
                    'quality_score': result.quality_score,
                })
            else:
                formatted_result['details'] = {
                    'result_image': '',
                    'overlay_image': '',
                    'error_message': result.error_message,
                    'step_info': {
                        'step_name': 'cloth_segmentation',
                        'step_number': 3,
                        'device': self.device,
                        'error': result.error_message
                    }
                }
                formatted_result['error_message'] = result.error_message
            
            return formatted_result
            
        except Exception as e:
            self.logger.error(f"ê²°ê³¼ í¬ë§·íŒ… ì‹¤íŒ¨: {e}")
            return {
                'success': False,
                'error_message': f"ê²°ê³¼ í¬ë§·íŒ… ì‹¤íŒ¨: {e}",
                'processing_time': 0.0,
                'method_used': 'error',
                'details': {
                    'result_image': '',
                    'overlay_image': '',
                    'error_message': f"ê²°ê³¼ í¬ë§·íŒ… ì‹¤íŒ¨: {e}",
                    'step_info': {
                        'step_name': 'cloth_segmentation',
                        'step_number': 3,
                        'error': f"ê²°ê³¼ í¬ë§·íŒ… ì‹¤íŒ¨: {e}"
                    }
                }
            }

    def _pil_to_bytes(self, image: Image.Image) -> bytes:
        """PIL ì´ë¯¸ì§€ë¥¼ ë°”ì´íŠ¸ë¡œ ë³€í™˜"""
        buffer = BytesIO()
        image.save(buffer, format='PNG')
        return buffer.getvalue()

    async def _perform_segmentation_cached(self, *args, **kwargs):
        """ìºì‹œëœ ì„¸ê·¸ë©˜í…Œì´ì…˜ ìˆ˜í–‰ (LRU ìºì‹œìš©)"""
        return await self._perform_single_segmentation(*args, **kwargs)

    # ==============================================
    # ğŸ”¥ ì¶”ê°€ ì¸í„°í˜ì´ìŠ¤ ë©”ì„œë“œë“¤
    # ==============================================

    def get_statistics(self) -> Dict[str, Any]:
        """ì²˜ë¦¬ í†µê³„ ë°˜í™˜"""
        try:
            stats = self.processing_stats.copy()
            
            # ì„±ê³µë¥  ê³„ì‚°
            if stats['total_processed'] > 0:
                stats['success_rate'] = stats['successful_segmentations'] / stats['total_processed']
            else:
                stats['success_rate'] = 0.0
            
            # ìºì‹œ ì •ë³´
            stats['cache_info'] = {
                'size': len(self.segmentation_cache),
                'max_size': self.segmentation_config.cache_size,
                'hit_ratio': stats['cache_hits'] / max(stats['total_processed'], 1)
            }
            
            # ì‹œìŠ¤í…œ ì •ë³´
            stats['system_info'] = {
                'device': self.device,
                'is_m3_max': self.is_m3_max,
                'memory_gb': self.memory_gb,
                'available_methods': [m.value for m in self.available_methods],
                'optimization_enabled': self.optimization_enabled,
                'visualization_enabled': self.segmentation_config.enable_visualization
            }
            
            return stats
            
        except Exception as e:
            self.logger.error(f"í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {'error': str(e)}

    async def get_step_info(self) -> Dict[str, Any]:
        """3ë‹¨ê³„ ìƒì„¸ ì •ë³´ ë°˜í™˜"""
        try:
            memory_stats = {}
            if self.memory_manager:
                try:
                    memory_stats = await self.memory_manager.get_usage_stats()
                except Exception:
                    memory_stats = {"memory_used": "N/A"}
            else:
                memory_stats = {"memory_used": "N/A"}
            
            return {
                "step_name": "cloth_segmentation",
                "step_number": 3,
                "device": self.device,
                "initialized": self.is_initialized,
                "available_methods": [m.value for m in self.available_methods],
                "config": {
                    "segmentation_method": self.segmentation_config.method.value,
                    "quality_level": self.segmentation_config.quality_level.value,
                    "input_size": self.segmentation_config.input_size,
                    "use_fp16": self.segmentation_config.use_fp16,
                    "confidence_threshold": self.confidence_threshold,
                    "enable_post_processing": self.enable_post_processing,
                    "enable_edge_refinement": self.enable_edge_refinement,
                    "enable_visualization": self.segmentation_config.enable_visualization,
                    "visualization_quality": self.segmentation_config.visualization_quality
                },
                "performance": self.processing_stats,
                "cache": {
                    "size": len(self.segmentation_cache),
                    "max_size": self.segmentation_config.cache_size,
                    "hit_rate": (self.processing_stats['cache_hits'] / 
                                max(1, self.processing_stats['total_processed'])) * 100
                },
                "memory_usage": memory_stats,
                "optimization": {
                    "m3_max_enabled": self.is_m3_max,
                    "memory_gb": self.memory_gb,
                    "optimization_enabled": self.optimization_enabled,
                    "fp16_enabled": self.segmentation_config.use_fp16,
                    "neural_engine": self.is_m3_max
                },
                "models_status": {
                    "u2net_loaded": hasattr(self, 'u2net_model') and self.u2net_model is not None,
                    "rembg_available": REMBG_AVAILABLE,
                    "sam_available": SAM_AVAILABLE,
                    "deeplab_loaded": hasattr(self, 'deeplab_pipeline') and self.deeplab_pipeline is not None,
                    "rembg_sessions": len(getattr(self, 'rembg_sessions', {}))
                }
            }
            
        except Exception as e:
            self.logger.error(f"Step ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {
                "step_name": "cloth_segmentation",
                "step_number": 3,
                "error": str(e),
                "initialized": self.is_initialized
            }

    def get_supported_clothing_types(self) -> List[str]:
        """ì§€ì›ë˜ëŠ” ì˜ë¥˜ íƒ€ì… ëª©ë¡ ë°˜í™˜"""
        return [ct.value for ct in ClothingType]

    def get_available_methods(self) -> List[str]:
        """ì‚¬ìš© ê°€ëŠ¥í•œ ì„¸ê·¸ë©˜í…Œì´ì…˜ ë°©ë²• ëª©ë¡ ë°˜í™˜"""
        return [method.value for method in self.available_methods]

    def get_method_info(self, method_name: str) -> Dict[str, Any]:
        """íŠ¹ì • ë°©ë²•ì˜ ìƒì„¸ ì •ë³´ ë°˜í™˜"""
        method_info = {
            'u2net': {
                'name': 'UÂ²-Net',
                'description': 'Deep learning based UÂ²-Net for precise cloth segmentation',
                'quality': 'high',
                'speed': 'medium',
                'accuracy': 'high',
                'requirements': ['torch', 'torchvision']
            },
            'rembg': {
                'name': 'RemBG',
                'description': 'Background removal specialized for clothing',
                'quality': 'high',
                'speed': 'fast',
                'accuracy': 'medium-high',
                'requirements': ['rembg']
            },
            'sam': {
                'name': 'Segment Anything Model',
                'description': 'Meta\'s universal segmentation model',
                'quality': 'ultra',
                'speed': 'slow',
                'accuracy': 'ultra-high',
                'requirements': ['segment_anything']
            },
            'deeplab': {
                'name': 'DeepLab v3',
                'description': 'Semantic segmentation with transformers',
                'quality': 'high',
                'speed': 'medium',
                'accuracy': 'high',
                'requirements': ['transformers']
            },
            'traditional': {
                'name': 'Traditional CV',
                'description': 'Classical computer vision methods (GrabCut, K-means)',
                'quality': 'medium',
                'speed': 'fast',
                'accuracy': 'medium',
                'requirements': ['opencv', 'scikit-learn']
            }
        }
        
        return method_info.get(method_name, {
            'name': 'Unknown',
            'description': 'Unknown segmentation method',
            'quality': 'unknown',
            'speed': 'unknown',
            'accuracy': 'unknown'
        })

    def get_clothing_mask(self, mask: np.ndarray, category: str) -> np.ndarray:
        """íŠ¹ì • ì˜ë¥˜ ì¹´í…Œê³ ë¦¬ì˜ í†µí•© ë§ˆìŠ¤í¬ ë°˜í™˜"""
        try:
            # ì˜ë¥˜ ì¹´í…Œê³ ë¦¬ë³„ ë§ˆìŠ¤í¬ ìƒì„±
            if category in ['shirt', 'top', 'sweater']:
                # ìƒì˜ ì¹´í…Œê³ ë¦¬
                return (mask > 128).astype(np.uint8)
            elif category in ['pants', 'skirt', 'bottom']:
                # í•˜ì˜ ì¹´í…Œê³ ë¦¬
                return (mask > 128).astype(np.uint8)
            elif category in ['dress']:
                # ì›í”¼ìŠ¤ ì¹´í…Œê³ ë¦¬
                return (mask > 128).astype(np.uint8)
            else:
                # ê¸°ë³¸ê°’
                return (mask > 128).astype(np.uint8)
        except Exception as e:
            self.logger.warning(f"ì˜ë¥˜ ë§ˆìŠ¤í¬ ìƒì„± ì‹¤íŒ¨: {e}")
            return np.zeros_like(mask, dtype=np.uint8)

    def visualize_segmentation(self, mask: np.ndarray, clothing_type: str = "shirt") -> np.ndarray:
        """ì„¸ê·¸ë©˜í…Œì´ì…˜ ê²°ê³¼ ì‹œê°í™” (ë””ë²„ê¹…ìš©)"""
        try:
            # ì˜ë¥˜ íƒ€ì…ì— ë”°ë¥¸ ìƒ‰ìƒ ì„ íƒ
            color = CLOTHING_COLORS.get(clothing_type, CLOTHING_COLORS['unknown'])
            
            # 3ì±„ë„ ìƒ‰ìƒ ì´ë¯¸ì§€ ìƒì„±
            height, width = mask.shape
            colored_image = np.zeros((height, width, 3), dtype=np.uint8)
            
            # ë§ˆìŠ¤í¬ ì˜ì—­ì— ìƒ‰ìƒ ì ìš©
            mask_binary = (mask > 128).astype(np.uint8)
            colored_image[mask_binary == 1] = color
            
            return colored_image
            
        except Exception as e:
            self.logger.warning(f"ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‹œê°í™” ì‹¤íŒ¨: {e}")
            # í´ë°±: ê·¸ë ˆì´ìŠ¤ì¼€ì¼
            return np.stack([mask, mask, mask], axis=2)

    def estimate_processing_time(self, image_size: Tuple[int, int], method: str = "auto") -> float:
        """ì²˜ë¦¬ ì‹œê°„ ì¶”ì •"""
        try:
            width, height = image_size
            total_pixels = width * height
            
            # ë°©ë²•ë³„ ê¸°ë³¸ ì²˜ë¦¬ ì‹œê°„ (ì´ˆ/ë©”ê°€í”½ì…€)
            time_per_mpx = {
                'u2net': 0.5 if self.is_m3_max else 1.0,
                'rembg': 0.3 if self.is_m3_max else 0.6,
                'sam': 2.0 if self.is_m3_max else 4.0,
                'deeplab': 0.8 if self.is_m3_max else 1.5,
                'traditional': 0.1
            }
            
            if method == "auto":
                # ì‚¬ìš© ê°€ëŠ¥í•œ ë°©ë²• ì¤‘ ê°€ì¥ ë¹ ë¥¸ ê²ƒ
                method = min(self.available_methods, 
                            key=lambda m: time_per_mpx.get(m.value, 1.0)).value
            
            mpx = total_pixels / 1_000_000  # ë©”ê°€í”½ì…€ ë³€í™˜
            base_time = time_per_mpx.get(method, 1.0) * mpx
            
            # í’ˆì§ˆ ì„¤ì •ì— ë”°ë¥¸ ì¡°ì •
            quality_multiplier = {
                'fast': 0.7,
                'balanced': 1.0,
                'high': 1.3,
                'ultra': 1.8
            }
            
            quality = self.segmentation_config.quality_level.value
            estimated_time = base_time * quality_multiplier.get(quality, 1.0)
            
            return max(0.1, estimated_time)  # ìµœì†Œ 0.1ì´ˆ
            
        except Exception as e:
            self.logger.warning(f"ì²˜ë¦¬ ì‹œê°„ ì¶”ì • ì‹¤íŒ¨: {e}")
            return 2.0  # ê¸°ë³¸ê°’

    async def warmup(self):
        """ì‹œìŠ¤í…œ ì›Œë°ì—…"""
        try:
            self.logger.info("ğŸ”¥ 3ë‹¨ê³„ ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‹œìŠ¤í…œ ì›Œë°ì—… ì‹œì‘...")
            
            if not self.is_initialized:
                await self.initialize()
            
            # ë”ë¯¸ ì´ë¯¸ì§€ë¡œ ì›Œë°ì—…
            dummy_image = Image.new('RGB', (512, 512), (128, 128, 128))
            
            # ê° ì‚¬ìš© ê°€ëŠ¥í•œ ë°©ë²•ìœ¼ë¡œ ì›Œë°ì—…
            for method in self.available_methods[:2]:  # ìµœëŒ€ 2ê°œ ë°©ë²•ë§Œ
                try:
                    self.logger.info(f"ğŸ”¥ {method.value} ì›Œë°ì—… ì¤‘...")
                    result = await self._perform_single_segmentation(dummy_image, method, "shirt")
                    if result.success:
                        self.logger.info(f"âœ… {method.value} ì›Œë°ì—… ì™„ë£Œ")
                    else:
                        self.logger.warning(f"âš ï¸ {method.value} ì›Œë°ì—… ì‹¤íŒ¨")
                except Exception as e:
                    self.logger.warning(f"âš ï¸ {method.value} ì›Œë°ì—… ì˜¤ë¥˜: {e}")
            
            self.logger.info("âœ… 3ë‹¨ê³„ ì„¸ê·¸ë©˜í…Œì´ì…˜ ì›Œë°ì—… ì™„ë£Œ")
            
        except Exception as e:
            self.logger.error(f"âŒ ì›Œë°ì—… ì‹¤íŒ¨: {e}")

    async def cleanup(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        try:
            self.logger.info("ğŸ§¹ 3ë‹¨ê³„ ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‹œìŠ¤í…œ ì •ë¦¬ ì‹œì‘...")
            
            # ìºì‹œ ì •ë¦¬
            self.segmentation_cache.clear()
            self.model_cache.clear()
            self.session_cache.clear()
            
            # ëª¨ë¸ ë©”ëª¨ë¦¬ í•´ì œ
            if hasattr(self, 'u2net_model') and self.u2net_model is not None:
                del self.u2net_model
                self.u2net_model = None
            
            if hasattr(self, 'deeplab_pipeline') and self.deeplab_pipeline is not None:
                del self.deeplab_pipeline
                self.deeplab_pipeline = None
            
            # RemBG ì„¸ì…˜ ì •ë¦¬
            if hasattr(self, 'rembg_sessions'):
                self.rembg_sessions.clear()
            
            # ìŠ¤ë ˆë“œ í’€ ì¢…ë£Œ
            if hasattr(self, 'executor'):
                self.executor.shutdown(wait=True)
            
            # ë©”ëª¨ë¦¬ ì •ë¦¬
            if self.memory_manager:
                await self.memory_manager.cleanup_memory()
            
            # PyTorch ìºì‹œ ì •ë¦¬
            if self.device == 'mps':
                try:
                    torch.mps.empty_cache()
                except Exception:
                    pass
            elif self.device == 'cuda':
                try:
                    torch.cuda.empty_cache()
                except Exception:
                    pass
            
            # ê°€ë¹„ì§€ ì»¬ë ‰ì…˜
            gc.collect()
            
            self.is_initialized = False
            self.logger.info("âœ… 3ë‹¨ê³„ ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‹œìŠ¤í…œ ì •ë¦¬ ì™„ë£Œ")
            
        except Exception as e:
            self.logger.error(f"ì •ë¦¬ ê³¼ì •ì—ì„œ ì˜¤ë¥˜ ë°œìƒ: {e}")

    def __del__(self):
        """ì†Œë©¸ì"""
        try:
            if hasattr(self, 'executor'):
                self.executor.shutdown(wait=False)
        except Exception:
            pass


# ==============================================
# 4. íŒ©í† ë¦¬ í•¨ìˆ˜ë“¤ - ê¸°ì¡´ ì´ë¦„ ìœ ì§€
# ==============================================

def create_cloth_segmentation_step(
    device: Optional[str] = None,
    config: Optional[Dict[str, Any]] = None,
    **kwargs
) -> ClothSegmentationStep:
    """ClothSegmentationStep íŒ©í† ë¦¬ í•¨ìˆ˜"""
    try:
        return ClothSegmentationStep(device=device, config=config, **kwargs)
    except Exception as e:
        logger.error(f"ClothSegmentationStep ìƒì„± ì‹¤íŒ¨: {e}")
        raise

def create_m3_max_segmentation_step(**kwargs) -> ClothSegmentationStep:
    """M3 Max ìµœì í™”ëœ ì„¸ê·¸ë©˜í…Œì´ì…˜ ìŠ¤í… ìƒì„±"""
    m3_max_config = {
        'device': 'mps',
        'is_m3_max': True,
        'optimization_enabled': True,
        'memory_gb': 128,
        'quality_level': 'high',
        'segmentation_method': 'auto',
        'use_fp16': True,
        'enable_post_processing': True,
        'cache_size': 200,
        'enable_visualization': True,
        'visualization_quality': 'high'
    }
    
    m3_max_config.update(kwargs)
    
    return ClothSegmentationStep(**m3_max_config)

def create_production_segmentation_step(
    quality_level: str = "balanced",
    enable_fallback: bool = True,
    **kwargs
) -> ClothSegmentationStep:
    """í”„ë¡œë•ì…˜ í™˜ê²½ìš© ì„¸ê·¸ë©˜í…Œì´ì…˜ ìŠ¤í… ìƒì„±"""
    production_config = {
        'quality_level': quality_level,
        'enable_fallback': enable_fallback,
        'optimization_enabled': True,
        'enable_post_processing': True,
        'enable_edge_refinement': True,
        'confidence_threshold': 0.8,
        'cache_size': 100,
        'enable_visualization': True,
        'visualization_quality': 'medium'
    }
    
    production_config.update(kwargs)
    
    return ClothSegmentationStep(**production_config)


# ==============================================
# 5. ëª¨ë“ˆ ìµìŠ¤í¬íŠ¸ - ê¸°ì¡´ ì´ë¦„ ìœ ì§€
# ==============================================

__all__ = [
    # ë©”ì¸ í´ë˜ìŠ¤
    'ClothSegmentationStep',
    
    # ì—´ê±°í˜• ë° ë°ì´í„° í´ë˜ìŠ¤
    'SegmentationMethod',
    'ClothingType', 
    'QualityLevel',
    'SegmentationConfig',
    'SegmentationResult',
    
    # AI ëª¨ë¸ í´ë˜ìŠ¤ë“¤
    'U2NET',
    'REBNCONV',
    'RSU7',
    
    # íŒ©í† ë¦¬ í•¨ìˆ˜ë“¤
    'create_cloth_segmentation_step',
    'create_m3_max_segmentation_step',
    'create_production_segmentation_step',
    
    # ì‹œê°í™” ê´€ë ¨
    'CLOTHING_COLORS'
]

# ëª¨ë“ˆ ì´ˆê¸°í™” ë¡œê¹…
logger.info("âœ… Step 03 ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ + ì‹œê°í™” ëª¨ë“ˆ ì™„ì „ ì¬ì‘ì„± ì™„ë£Œ")
logger.info(f"   - BaseStepMixin ì—°ë™: {'âœ…' if BASE_STEP_MIXIN_AVAILABLE else 'âš ï¸ í´ë°±'}")
logger.info(f"   - Model Loader ì—°ë™: {'âœ…' if MODEL_LOADER_AVAILABLE else 'âŒ'}")
logger.info(f"   - Memory Manager ì—°ë™: {'âœ…' if MEMORY_MANAGER_AVAILABLE else 'âŒ'}")
logger.info(f"   - RemBG ì‚¬ìš© ê°€ëŠ¥: {'âœ…' if REMBG_AVAILABLE else 'âŒ'}")
logger.info(f"   - SAM ì‚¬ìš© ê°€ëŠ¥: {'âœ…' if SAM_AVAILABLE else 'âŒ'}")
logger.info(f"   - Transformers ì‚¬ìš© ê°€ëŠ¥: {'âœ…' if TRANSFORMERS_AVAILABLE else 'âŒ'}")
logger.info(f"   - scikit-learn ì‚¬ìš© ê°€ëŠ¥: {'âœ…' if SKLEARN_AVAILABLE else 'âŒ'}")
logger.info("ğŸ”¥ ìˆœí™˜ì°¸ì¡° ì™„ì „ í•´ê²°, í•œë°©í–¥ ì°¸ì¡° êµ¬ì¡° êµ¬í˜„")
logger.info("ğŸ¨ ì‹œê°í™” ê¸°ëŠ¥: ìƒ‰ìƒ êµ¬ë¶„, ì˜¤ë²„ë ˆì´, ë§ˆìŠ¤í¬, ê²½ê³„ì„  í‘œì‹œ")
logger.info("ğŸ—ï¸ í”„ë¡œë•ì…˜ ì•ˆì •ì„± ë³´ì¥, ëª¨ë“  ê¸°ëŠ¥ ì™„ì „ êµ¬í˜„")


# ==============================================
# 6. í…ŒìŠ¤íŠ¸ ë° ì˜ˆì‹œ í•¨ìˆ˜ë“¤
# ==============================================

async def test_cloth_segmentation_complete():
    """ì™„ì „í•œ ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ í…ŒìŠ¤íŠ¸"""
    print("ğŸ§ª ì™„ì „í•œ ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    
    try:
        # Step ìƒì„±
        step = create_cloth_segmentation_step(
            device="auto",
            config={
                "enable_visualization": True,
                "visualization_quality": "high",
                "quality_level": "balanced"
            }
        )
        
        # ì´ˆê¸°í™”
        await step.initialize()
        
        # ë”ë¯¸ ì´ë¯¸ì§€ ìƒì„±
        dummy_image = Image.new('RGB', (512, 512), (200, 150, 100))
        
        # ì²˜ë¦¬ ì‹¤í–‰
        result = await step.process(dummy_image, clothing_type="shirt", quality_level="high")
        
        # ê²°ê³¼ í™•ì¸
        if result['success']:
            print("âœ… ì²˜ë¦¬ ì„±ê³µ!")
            print(f"ğŸ“Š ë°©ë²•: {result['method_used']}")
            print(f"ğŸ“Š ì‹ ë¢°ë„: {result.get('confidence_score', 0):.3f}")
            print(f"ğŸ“Š í’ˆì§ˆ: {result.get('quality_score', 0):.3f}")
            print(f"ğŸ¨ ì‹œê°í™”: {'ìˆìŒ' if result.get('details', {}).get('result_image') else 'ì—†ìŒ'}")
        else:
            print(f"âŒ ì²˜ë¦¬ ì‹¤íŒ¨: {result.get('error_message', 'Unknown error')}")
        
        # ì •ë¦¬
        await step.cleanup()
        print("ğŸ§¹ ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì™„ë£Œ")
        
    except Exception as e:
        print(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")

async def benchmark_segmentation_methods():
    """ì„¸ê·¸ë©˜í…Œì´ì…˜ ë°©ë²•ë³„ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬"""
    print("ğŸƒâ€â™‚ï¸ ì„¸ê·¸ë©˜í…Œì´ì…˜ ë°©ë²•ë³„ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ì‹œì‘")
    
    try:
        step = create_cloth_segmentation_step(device="auto")
        
        # í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€
        test_image = Image.new('RGB', (512, 512), (180, 140, 90))
        
        methods = step.get_available_methods()
        results = {}
        
        for method in methods:
            print(f"ğŸ”„ {method} í…ŒìŠ¤íŠ¸ ì¤‘...")
            start_time = time.time()
            
            try:
                result = await step.process(
                    test_image, 
                    clothing_type="shirt",
                    method_override=SegmentationMethod(method)
                )
                
                processing_time = time.time() - start_time
                results[method] = {
                    'success': result['success'],
                    'processing_time': processing_time,
                    'confidence': result.get('confidence_score', 0),
                    'quality': result.get('quality_score', 0)
                }
                
                print(f"âœ… {method}: {processing_time:.3f}ì´ˆ")
                
            except Exception as e:
                results[method] = {
                    'success': False,
                    'error': str(e),
                    'processing_time': time.time() - start_time
                }
                print(f"âŒ {method}: ì‹¤íŒ¨ - {e}")
        
        # ê²°ê³¼ ìš”ì•½
        print("\nğŸ“Š ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼:")
        print("=" * 50)
        
        for method, result in results.items():
            if result['success']:
                print(f"{method:12}: {result['processing_time']:6.3f}ì´ˆ "
                      f"(ì‹ ë¢°ë„: {result['confidence']:5.3f}, í’ˆì§ˆ: {result['quality']:5.3f})")
            else:
                print(f"{method:12}: ì‹¤íŒ¨")
        
        await step.cleanup()
        
    except Exception as e:
        print(f"âŒ ë²¤ì¹˜ë§ˆí¬ ì‹¤íŒ¨: {e}")

if __name__ == "__main__":
    import asyncio
    
    def test_mro():
        """ğŸ” MRO(Method Resolution Order) í…ŒìŠ¤íŠ¸"""
        print("ğŸ” MRO í…ŒìŠ¤íŠ¸ ì‹œì‘")
        print("=" * 50)
        
        try:
            # 1. MRO ìˆœì„œ í™•ì¸
            mro = ClothSegmentationStep.__mro__
            print("ğŸ“‹ MRO ìˆœì„œ:")
            for i, cls in enumerate(mro):
                print(f"   {i+1}. {cls.__name__}")
            
            # 2. ì¸ìŠ¤í„´ìŠ¤ ìƒì„± í…ŒìŠ¤íŠ¸
            print("\nğŸ”§ ì¸ìŠ¤í„´ìŠ¤ ìƒì„± í…ŒìŠ¤íŠ¸:")
            step = ClothSegmentationStep(device="cpu")
            print(f"   âœ… ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ì„±ê³µ")
            print(f"   ğŸ“ í´ë˜ìŠ¤ëª…: {step.__class__.__name__}")
            print(f"   ğŸ“ Step ì´ë¦„: {step.step_name}")
            print(f"   ğŸ“ Step ë²ˆí˜¸: {step.step_number}")
            print(f"   ğŸ“ Step íƒ€ì…: {step.step_type}")
            print(f"   ğŸ“ ë””ë°”ì´ìŠ¤: {step.device}")
            print(f"   ğŸ“ Logger íƒ€ì…: {type(step.logger)}")
            
            # 3. ìƒì† ê´€ê³„ í™•ì¸
            print("\nğŸ”— ìƒì† ê´€ê³„ í™•ì¸:")
            if BASE_STEP_MIXIN_AVAILABLE:
                print(f"   âœ… BaseStepMixin ì‚¬ìš© ê°€ëŠ¥")
                print(f"   âœ… ClothSegmentationMixin ìƒì†")
            else:
                print(f"   âš ï¸ í´ë°± í´ë˜ìŠ¤ ì‚¬ìš©")
            
            # 4. ë©”ì„œë“œ í˜¸ì¶œ í…ŒìŠ¤íŠ¸
            print("\nğŸ”§ ë©”ì„œë“œ í˜¸ì¶œ í…ŒìŠ¤íŠ¸:")
            methods = ['get_available_methods', 'get_supported_clothing_types', 'get_statistics']
            for method_name in methods:
                if hasattr(step, method_name):
                    method = getattr(step, method_name)
                    if callable(method):
                        try:
                            result = method()
                            print(f"   âœ… {method_name}: ì„±ê³µ (ê²°ê³¼ íƒ€ì…: {type(result)})")
                        except Exception as e:
                            print(f"   âš ï¸ {method_name}: ì‹¤íŒ¨ - {e}")
                    else:
                        print(f"   âŒ {method_name}: callableì´ ì•„ë‹˜")
                else:
                    print(f"   âŒ {method_name}: ë©”ì„œë“œ ì—†ìŒ")
            
            print("\nâœ… MRO í…ŒìŠ¤íŠ¸ ì™„ë£Œ - ë¬¸ì œ ì—†ìŒ!")
            return True
            
        except Exception as e:
            print(f"\nâŒ MRO í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    async def test_full_functionality():
        """ğŸ§ª ì „ì²´ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸"""
        print("\nğŸ§ª ì „ì²´ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹œì‘")
        print("=" * 50)
        
        success = await test_cloth_segmentation_complete()
        if success:
            print("âœ… ì „ì²´ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ ì„±ê³µ!")
        else:
            print("âŒ ì „ì²´ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨!")
        
        return success
    
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    print("ğŸš€ ClothSegmentationStep ì™„ì „ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("=" * 60)
    
    # 1. MRO í…ŒìŠ¤íŠ¸
    mro_success = test_mro()
    
    # 2. ì „ì²´ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸
    if mro_success:
        asyncio.run(test_full_functionality())
    else:
        print("âŒ MRO ì˜¤ë¥˜ë¡œ ì¸í•´ ì „ì²´ í…ŒìŠ¤íŠ¸ ì¤‘ë‹¨")
    
    print("\nğŸ ëª¨ë“  í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")


# ğŸ”¥ safe_warmup í˜¸í™˜ì„± ì¶”ê°€
from app.utils.safe_warmup import safe_warmup, async_safe_warmup

# ğŸ”¥ ì™„ì „ ì‘ë™í•˜ëŠ” ì‚¬ìš© ì˜ˆì‹œ ì½”ë“œ
"""
# ğŸ”§ ê¸°ë³¸ ì‚¬ìš©ë²• - ëª¨ë“  ë¬¸ì œ í•´ê²°ë¨
step = create_cloth_segmentation_step(device="auto")
result = await step.process(image, clothing_type="shirt")

# ğŸ M3 Max ìµœì í™” - ì™„ì „ ì‘ë™
step = create_m3_max_segmentation_step(
    enable_visualization=True,
    visualization_quality="high"
)

# ğŸ­ í”„ë¡œë•ì…˜ í™˜ê²½ - ëª¨ë“  ê¸°ëŠ¥ í¬í•¨
step = create_production_segmentation_step(
    quality_level="balanced",
    enable_fallback=True
)

# ğŸ“Š ì‹œìŠ¤í…œ ì •ë³´ ì¡°íšŒ - ì‹¤ì œ ì‘ë™
info = await step.get_step_info()
print(f"ì‚¬ìš© ê°€ëŠ¥í•œ ë°©ë²•: {step.get_available_methods()}")
print(f"ì§€ì› ì˜ë¥˜ íƒ€ì…: {step.get_supported_clothing_types()}")

# ğŸ” ë°©ë²•ë³„ ìƒì„¸ ì •ë³´
method_info = step.get_method_info("rembg")
print(f"RemBG ì •ë³´: {method_info}")

# ğŸ”¥ ì‹œìŠ¤í…œ ì›Œë°ì—… - safe_warmup ì‚¬ìš©
await safe_warmup(step, "cloth_segmentation_step")
# ë˜ëŠ” ë¹„ë™ê¸° ë²„ì „
await async_safe_warmup(step, "cloth_segmentation_step")

# â± ì²˜ë¦¬ ì‹œê°„ ì¶”ì • - ì •í™•í•œ ê³„ì‚°
estimated_time = step.estimate_processing_time((1024, 768), "rembg")
print(f"ì˜ˆìƒ ì²˜ë¦¬ ì‹œê°„: {estimated_time:.2f}ì´ˆ")

# ğŸ¨ ì‹œê°í™” ê²°ê³¼ í™•ì¸ - ì™„ì „ êµ¬í˜„ë¨
if result['success']:
    result_image = result['details']['result_image']  # base64 ì´ë¯¸ì§€
    overlay_image = result['details']['overlay_image']  # ì˜¤ë²„ë ˆì´ ì´ë¯¸ì§€
    print("ì‹œê°í™” ì™„ë£Œ!")

# ğŸ‘• ì˜ë¥˜ ë§ˆìŠ¤í¬ ìƒì„±
if result['success']:
    clothing_mask = step.get_clothing_mask(result['mask'], "shirt")
    
# ğŸ¨ ë””ë²„ê¹…ìš© ì‹œê°í™”
debug_viz = step.visualize_segmentation(result['mask'], "shirt")

# ğŸ“Š ì²˜ë¦¬ í†µê³„ í™•ì¸
stats = step.get_statistics()
print(f"ì„±ê³µë¥ : {stats['success_rate']:.2%}")
print(f"í‰ê·  í’ˆì§ˆ: {stats['average_quality']:.3f}")

# ğŸ§¹ ë¦¬ì†ŒìŠ¤ ì •ë¦¬
await step.cleanup()
"""