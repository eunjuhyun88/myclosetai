# app/ai_pipeline/steps/step_03_cloth_segmentation.py
"""
MyCloset AI - 3ë‹¨ê³„: ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ (Clothing Segmentation) + ì‹œê°í™”
ğŸ”¥ ì™„ì „í•œ ê¸°ëŠ¥ êµ¬í˜„ - 1ë²ˆ íŒŒì¼ ìˆ˜ì •ì‚¬í•­ ì™„ì „ ì ìš©

âœ… 1ë²ˆ íŒŒì¼ì˜ await expression ì˜¤ë¥˜ ì™„ì „ í•´ê²° ì ìš©
âœ… BaseStepMixin logger ì†ì„± ëˆ„ë½ ë¬¸ì œ ì™„ì „ í•´ê²°
âœ… ë™ê¸°/ë¹„ë™ê¸° í˜¸ì¶œ ë¬¸ì œ ì™„ì „ í•´ê²°
âœ… ModelLoader ì•ˆì „í•œ ì—°ë™
âœ… 8ê°€ì§€ ì„¸ê·¸ë©˜í…Œì´ì…˜ ë°©ë²• + AUTO ì„ íƒ
âœ… ì™„ì „í•œ ì‹œê°í™” ì‹œìŠ¤í…œ (ìƒ‰ìƒí™”, ì˜¤ë²„ë ˆì´, ê²½ê³„ì„ )
âœ… ê³ ê¸‰ í›„ì²˜ë¦¬ (ê²½ê³„ ê°œì„ , í™€ ì±„ìš°ê¸°, í˜•íƒœí•™ì  ì²˜ë¦¬)
âœ… M3 Max 128GB ìµœì í™” (ì›Œë°ì—…, ë©”ëª¨ë¦¬ ê´€ë¦¬)
âœ… í”„ë¡œë•ì…˜ ì•ˆì •ì„± (ìºì‹œ, í†µê³„, í´ë°±)
âœ… ìˆœí™˜ì°¸ì¡° ì™„ì „ í•´ê²°
âœ… ëª¨ë“  ì´ˆê¸°í™” ì˜¤ë¥˜ ë°©ì§€
"""

import os
import sys
import logging
import time
import asyncio
import threading
import gc
import hashlib
import json
import base64
from typing import Dict, Any, Optional, Tuple, List, Union, Callable
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor, as_completed
from dataclasses import dataclass, field
from enum import Enum
from io import BytesIO
import weakref

# í•µì‹¬ ë¼ì´ë¸ŒëŸ¬ë¦¬
import numpy as np
import cv2
from PIL import Image, ImageEnhance, ImageFilter, ImageOps, ImageDraw, ImageFont
import torch
import torch.nn as nn
import torch.nn.functional as F
from torchvision import transforms

# ì„ íƒì  AI ë¼ì´ë¸ŒëŸ¬ë¦¬ë“¤
try:
    import rembg
    from rembg import remove, new_session
    REMBG_AVAILABLE = True
except ImportError:
    REMBG_AVAILABLE = False

try:
    from sklearn.cluster import KMeans
    from sklearn.preprocessing import StandardScaler
    SKLEARN_AVAILABLE = True
except ImportError:
    SKLEARN_AVAILABLE = False

try:
    import segment_anything as sam
    SAM_AVAILABLE = True
except ImportError:
    SAM_AVAILABLE = False

try:
    from transformers import pipeline
    TRANSFORMERS_AVAILABLE = True
except ImportError:
    TRANSFORMERS_AVAILABLE = False

# ğŸ”¥ BaseStepMixin ì—°ë™ - í•œë°©í–¥ ì°¸ì¡° (ìˆœí™˜ì°¸ì¡° í•´ê²°) - 1ë²ˆ íŒŒì¼ ì ìš©
try:
    from app.ai_pipeline.steps.base_step_mixin import BaseStepMixin, ClothSegmentationMixin
    BASE_STEP_MIXIN_AVAILABLE = True
except ImportError:
    BASE_STEP_MIXIN_AVAILABLE = False
    
    # ğŸ”¥ ì•ˆì „í•œ í´ë°± í´ë˜ìŠ¤ (1ë²ˆ íŒŒì¼ ë°©ì‹ ì™„ì „ ì ìš©)
    class BaseStepMixin:
        def __init__(self, *args, **kwargs):
            if not hasattr(self, 'logger'):
                class_name = self.__class__.__name__
                self.logger = logging.getLogger(f"pipeline.{class_name}")
            
            self.step_name = getattr(self, 'step_name', self.__class__.__name__)
            self.device = getattr(self, 'device', 'cpu')
            self.is_initialized = getattr(self, 'is_initialized', False)
            self.model_interface = getattr(self, 'model_interface', None)
            
            self.logger.info(f"ğŸ”¥ BaseStepMixin í´ë°± ì´ˆê¸°í™”: {class_name}")
    
    class ClothSegmentationMixin(BaseStepMixin):
        def __init__(self, *args, **kwargs):
            try:
                super().__init__(*args, **kwargs)
            except Exception as e:
                if not hasattr(self, 'logger'):
                    self.logger = logging.getLogger(f"pipeline.{self.__class__.__name__}")
                self.logger.debug(f"super() ì‹¤íŒ¨, ì§ì ‘ ì´ˆê¸°í™”: {e}")
            
            # Step 3 íŠ¹í™” ì†ì„±
            self.step_number = 3
            self.step_type = "cloth_segmentation"
            self.output_format = "cloth_mask"

# ğŸ”¥ ModelLoader ì—°ë™ - ì¸í„°í˜ì´ìŠ¤ ê¸°ë°˜ (ìˆœí™˜ì°¸ì¡° í•´ê²°) - 1ë²ˆ íŒŒì¼ ì ìš©
try:
    from app.ai_pipeline.utils.model_loader import (
        ModelLoader, ModelConfig, ModelType,
        get_global_model_loader
    )
    MODEL_LOADER_AVAILABLE = True
except ImportError:
    MODEL_LOADER_AVAILABLE = False

# ğŸ”¥ ì„ íƒì  ìœ í‹¸ë¦¬í‹° ì—°ë™ (ì—†ì–´ë„ ì‘ë™) - 1ë²ˆ íŒŒì¼ ì ìš©
try:
    from app.ai_pipeline.utils.memory_manager import (
        MemoryManager, get_global_memory_manager
    )
    MEMORY_MANAGER_AVAILABLE = True
except ImportError:
    MEMORY_MANAGER_AVAILABLE = False

try:
    from app.ai_pipeline.utils.data_converter import (
        DataConverter, get_global_data_converter
    )
    DATA_CONVERTER_AVAILABLE = True
except ImportError:
    DATA_CONVERTER_AVAILABLE = False

# ğŸ”¥ ë¡œê¹… ì„¤ì •
logger = logging.getLogger(__name__)

# ==============================================
# 1. ì—´ê±°í˜• ë° ë°ì´í„° í´ë˜ìŠ¤ (í™•ì¥ë¨) - 2ë²ˆ íŒŒì¼ ìœ ì§€
# ==============================================

class SegmentationMethod(Enum):
    """ì„¸ê·¸ë©˜í…Œì´ì…˜ ë°©ë²• (í™•ì¥ë¨)"""
    U2NET = "u2net"
    REMBG = "rembg"
    SAM = "sam"
    DEEP_LAB = "deeplab"
    MASK_RCNN = "mask_rcnn"
    TRADITIONAL = "traditional"
    HYBRID = "hybrid"
    AUTO = "auto"

class ClothingType(Enum):
    """ì˜ë¥˜ íƒ€ì… (í™•ì¥ë¨)"""
    SHIRT = "shirt"
    DRESS = "dress"
    PANTS = "pants"
    SKIRT = "skirt"
    JACKET = "jacket"
    SWEATER = "sweater"
    COAT = "coat"
    TOP = "top"
    BOTTOM = "bottom"
    UNKNOWN = "unknown"

class QualityLevel(Enum):
    """í’ˆì§ˆ ë ˆë²¨"""
    FAST = "fast"
    BALANCED = "balanced"
    HIGH = "high"
    ULTRA = "ultra"

@dataclass
class SegmentationConfig:
    """ì„¸ê·¸ë©˜í…Œì´ì…˜ ì„¤ì • (í™•ì¥ë¨)"""
    method: SegmentationMethod = SegmentationMethod.AUTO
    quality_level: QualityLevel = QualityLevel.BALANCED
    input_size: Tuple[int, int] = (512, 512)
    output_size: Optional[Tuple[int, int]] = None
    enable_visualization: bool = True
    enable_post_processing: bool = True
    enable_edge_refinement: bool = True
    enable_hole_filling: bool = True
    use_fp16: bool = True
    batch_size: int = 1
    confidence_threshold: float = 0.8
    iou_threshold: float = 0.5
    edge_smoothing: bool = True
    remove_noise: bool = True
    visualization_quality: str = "high"
    enable_caching: bool = True
    cache_size: int = 100
    show_masks: bool = True
    show_boundaries: bool = True
    overlay_opacity: float = 0.6

@dataclass
class SegmentationResult:
    """ì„¸ê·¸ë©˜í…Œì´ì…˜ ê²°ê³¼ (í™•ì¥ë¨)"""
    success: bool
    mask: Optional[np.ndarray] = None
    segmented_image: Optional[np.ndarray] = None
    confidence_score: float = 0.0
    quality_score: float = 0.0
    method_used: str = "unknown"
    processing_time: float = 0.0
    metadata: Dict[str, Any] = field(default_factory=dict)
    error_message: Optional[str] = None
    # ì‹œê°í™” ì´ë¯¸ì§€ë“¤
    visualization_image: Optional[Image.Image] = None
    overlay_image: Optional[Image.Image] = None
    mask_image: Optional[Image.Image] = None
    boundary_image: Optional[Image.Image] = None

# ==============================================
# 2. AI ëª¨ë¸ í´ë˜ìŠ¤ë“¤ (í´ë°±ìš© ì™„ì „ êµ¬í˜„) - 2ë²ˆ íŒŒì¼ ìœ ì§€
# ==============================================

class REBNCONV(nn.Module):
    """U2-Netì˜ ê¸°ë³¸ ì»¨ë³¼ë£¨ì…˜ ë¸”ë¡ (í´ë°±ìš©)"""
    def __init__(self, in_ch=3, out_ch=3, dirate=1):
        super(REBNCONV, self).__init__()
        self.conv_s1 = nn.Conv2d(in_ch, out_ch, 3, padding=1*dirate, dilation=1*dirate)
        self.bn_s1 = nn.BatchNorm2d(out_ch)
        self.relu_s1 = nn.ReLU(inplace=True)
    
    def forward(self, x):
        hx = self.relu_s1(self.bn_s1(self.conv_s1(x)))
        return hx

class RSU7(nn.Module):
    """U2-Net RSU-7 ë¸”ë¡ (í´ë°±ìš©)"""
    def __init__(self, in_ch=3, mid_ch=12, out_ch=3):
        super(RSU7, self).__init__()
        self.rebnconvin = REBNCONV(in_ch, out_ch, dirate=1)
        
        self.rebnconv1 = REBNCONV(out_ch, mid_ch, dirate=1)
        self.pool1 = nn.MaxPool2d(2, stride=2, ceil_mode=True)
        
        self.rebnconv2 = REBNCONV(mid_ch, mid_ch, dirate=1)
        self.pool2 = nn.MaxPool2d(2, stride=2, ceil_mode=True)
        
        self.rebnconv3 = REBNCONV(mid_ch, mid_ch, dirate=1)
        self.pool3 = nn.MaxPool2d(2, stride=2, ceil_mode=True)
        
        self.rebnconv4 = REBNCONV(mid_ch, mid_ch, dirate=1)
        self.pool4 = nn.MaxPool2d(2, stride=2, ceil_mode=True)
        
        self.rebnconv5 = REBNCONV(mid_ch, mid_ch, dirate=1)
        self.pool5 = nn.MaxPool2d(2, stride=2, ceil_mode=True)
        
        self.rebnconv6 = REBNCONV(mid_ch, mid_ch, dirate=1)
        self.rebnconv7 = REBNCONV(mid_ch, mid_ch, dirate=2)
        
        self.rebnconv6d = REBNCONV(mid_ch*2, mid_ch, dirate=1)
        self.upsample6 = nn.Upsample(scale_factor=2, mode='bilinear')
        
        self.rebnconv5d = REBNCONV(mid_ch*2, mid_ch, dirate=1)
        self.upsample5 = nn.Upsample(scale_factor=2, mode='bilinear')
        
        self.rebnconv4d = REBNCONV(mid_ch*2, mid_ch, dirate=1)
        self.upsample4 = nn.Upsample(scale_factor=2, mode='bilinear')
        
        self.rebnconv3d = REBNCONV(mid_ch*2, mid_ch, dirate=1)
        self.upsample3 = nn.Upsample(scale_factor=2, mode='bilinear')
        
        self.rebnconv2d = REBNCONV(mid_ch*2, mid_ch, dirate=1)
        self.upsample2 = nn.Upsample(scale_factor=2, mode='bilinear')
        
        self.rebnconv1d = REBNCONV(mid_ch*2, out_ch, dirate=1)
    
    def forward(self, x):
        hx = x
        hxin = self.rebnconvin(hx)
        
        hx1 = self.rebnconv1(hxin)
        hx = self.pool1(hx1)
        
        hx2 = self.rebnconv2(hx)
        hx = self.pool2(hx2)
        
        hx3 = self.rebnconv3(hx)
        hx = self.pool3(hx3)
        
        hx4 = self.rebnconv4(hx)
        hx = self.pool4(hx4)
        
        hx5 = self.rebnconv5(hx)
        hx = self.pool5(hx5)
        
        hx6 = self.rebnconv6(hx)
        hx7 = self.rebnconv7(hx6)
        
        hx6d = self.rebnconv6d(torch.cat((hx7, hx6), 1))
        hx6dup = self.upsample6(hx6d)
        
        hx5d = self.rebnconv5d(torch.cat((hx6dup, hx5), 1))
        hx5dup = self.upsample5(hx5d)
        
        hx4d = self.rebnconv4d(torch.cat((hx5dup, hx4), 1))
        hx4dup = self.upsample4(hx4d)
        
        hx3d = self.rebnconv3d(torch.cat((hx4dup, hx3), 1))
        hx3dup = self.upsample3(hx3d)
        
        hx2d = self.rebnconv2d(torch.cat((hx3dup, hx2), 1))
        hx2dup = self.upsample2(hx2d)
        
        hx1d = self.rebnconv1d(torch.cat((hx2dup, hx1), 1))
        
        return hx1d + hxin

class U2NET(nn.Module):
    """U2-Net ë©”ì¸ ëª¨ë¸ (ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ ìµœì í™”, í´ë°±ìš©)"""
    def __init__(self, in_ch=3, out_ch=1):
        super(U2NET, self).__init__()
        
        self.stage1 = RSU7(in_ch, 32, 64)
        self.pool12 = nn.MaxPool2d(2, stride=2, ceil_mode=True)
        
        self.stage2 = RSU7(64, 32, 128)
        self.pool23 = nn.MaxPool2d(2, stride=2, ceil_mode=True)
        
        self.stage3 = RSU7(128, 64, 256)
        self.pool34 = nn.MaxPool2d(2, stride=2, ceil_mode=True)
        
        self.stage4 = RSU7(256, 128, 512)
        self.pool45 = nn.MaxPool2d(2, stride=2, ceil_mode=True)
        
        self.stage5 = RSU7(512, 256, 512)
        self.pool56 = nn.MaxPool2d(2, stride=2, ceil_mode=True)
        
        self.stage6 = RSU7(512, 256, 512)
        
        # ë””ì½”ë”
        self.stage5d = RSU7(1024, 256, 512)
        self.stage4d = RSU7(1024, 128, 256)
        self.stage3d = RSU7(512, 64, 128)
        self.stage2d = RSU7(256, 32, 64)
        self.stage1d = RSU7(128, 16, 64)
        
        self.side1 = nn.Conv2d(64, out_ch, 3, padding=1)
        self.side2 = nn.Conv2d(64, out_ch, 3, padding=1)
        self.side3 = nn.Conv2d(128, out_ch, 3, padding=1)
        self.side4 = nn.Conv2d(256, out_ch, 3, padding=1)
        self.side5 = nn.Conv2d(512, out_ch, 3, padding=1)
        self.side6 = nn.Conv2d(512, out_ch, 3, padding=1)
        
        self.outconv = nn.Conv2d(6*out_ch, out_ch, 1)
        
        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear')
    
    def forward(self, x):
        hx = x
        
        # ì¸ì½”ë”
        hx1 = self.stage1(hx)
        hx = self.pool12(hx1)
        
        hx2 = self.stage2(hx)
        hx = self.pool23(hx2)
        
        hx3 = self.stage3(hx)
        hx = self.pool34(hx3)
        
        hx4 = self.stage4(hx)
        hx = self.pool45(hx4)
        
        hx5 = self.stage5(hx)
        hx = self.pool56(hx5)
        
        hx6 = self.stage6(hx)
        
        # ë””ì½”ë”
        hx5d = self.stage5d(torch.cat((hx6, hx5), 1))
        hx5dup = F.interpolate(hx5d, size=hx4.shape[2:], mode='bilinear', align_corners=False)
        
        hx4d = self.stage4d(torch.cat((hx5dup, hx4), 1))
        hx4dup = F.interpolate(hx4d, size=hx3.shape[2:], mode='bilinear', align_corners=False)
        
        hx3d = self.stage3d(torch.cat((hx4dup, hx3), 1))
        hx3dup = F.interpolate(hx3d, size=hx2.shape[2:], mode='bilinear', align_corners=False)
        
        hx2d = self.stage2d(torch.cat((hx3dup, hx2), 1))
        hx2dup = F.interpolate(hx2d, size=hx1.shape[2:], mode='bilinear', align_corners=False)
        
        hx1d = self.stage1d(torch.cat((hx2dup, hx1), 1))
        
        # Side outputs
        d1 = self.side1(hx1d)
        d2 = F.interpolate(self.side2(hx2d), size=d1.shape[2:], mode='bilinear', align_corners=False)
        d3 = F.interpolate(self.side3(hx3d), size=d1.shape[2:], mode='bilinear', align_corners=False)
        d4 = F.interpolate(self.side4(hx4d), size=d1.shape[2:], mode='bilinear', align_corners=False)
        d5 = F.interpolate(self.side5(hx5d), size=d1.shape[2:], mode='bilinear', align_corners=False)
        d6 = F.interpolate(self.side6(hx6), size=d1.shape[2:], mode='bilinear', align_corners=False)
        
        # ìµœì¢… ì¶œë ¥
        d0 = self.outconv(torch.cat((d1, d2, d3, d4, d5, d6), 1))
        
        return torch.sigmoid(d0), torch.sigmoid(d1), torch.sigmoid(d2), torch.sigmoid(d3), torch.sigmoid(d4), torch.sigmoid(d5), torch.sigmoid(d6)

# ==============================================
# 3. ì˜ë¥˜ë³„ ìƒ‰ìƒ ë§¤í•‘ (ì‹œê°í™”ìš©) - 2ë²ˆ íŒŒì¼ ìœ ì§€
# ==============================================

CLOTHING_COLORS = {
    'shirt': (255, 100, 100),      # ë¹¨ê°•
    'pants': (100, 100, 255),      # íŒŒë‘
    'dress': (255, 100, 255),      # ë¶„í™
    'jacket': (100, 255, 100),     # ì´ˆë¡
    'skirt': (255, 255, 100),      # ë…¸ë‘
    'sweater': (138, 43, 226),     # ë¸”ë£¨ë°”ì´ì˜¬ë ›
    'coat': (165, 42, 42),         # ê°ˆìƒ‰
    'top': (0, 255, 255),          # ì‹œì•ˆ
    'bottom': (255, 165, 0),       # ì˜¤ë Œì§€
    'shoes': (255, 150, 0),        # ì£¼í™©
    'bag': (150, 75, 0),           # ê°ˆìƒ‰
    'hat': (128, 0, 128),          # ë³´ë¼
    'accessory': (0, 255, 255),    # ì‹œì•ˆ
    'unknown': (128, 128, 128),    # íšŒìƒ‰
}

# ==============================================
# 4. ğŸ”¥ ì™„ì „í•œ ClothSegmentationStep (1ë²ˆ íŒŒì¼ ì ìš©)
# ==============================================

class ClothSegmentationStep(ClothSegmentationMixin):
    """
    ğŸ”¥ ì™„ì „í•œ ê¸°ëŠ¥ì˜ ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ Step
    
    âœ… 1ë²ˆ íŒŒì¼ì˜ await expression ì˜¤ë¥˜ ì™„ì „ í•´ê²° ì ìš©
    âœ… BaseStepMixin logger ì†ì„± ëˆ„ë½ ë¬¸ì œ ì™„ì „ í•´ê²°
    âœ… ë™ê¸°/ë¹„ë™ê¸° í˜¸ì¶œ ë¬¸ì œ ì™„ì „ í•´ê²°
    âœ… ModelLoader ì•ˆì „í•œ ì—°ë™
    âœ… ëª¨ë“  ì´ˆê¸°í™” ì˜¤ë¥˜ ë°©ì§€
    """
    
    def __init__(
        self,
        device: Optional[str] = None,
        config: Optional[Union[Dict[str, Any], SegmentationConfig]] = None,
        **kwargs
    ):
        """
        ğŸ”¥ ì•ˆì „í•œ ìƒì„±ì - 1ë²ˆ íŒŒì¼ ë°©ì‹ ì™„ì „ ì ìš©
        """
        
        # ===== 1ë‹¨ê³„: ë¶€ëª¨ í´ë˜ìŠ¤ ì´ˆê¸°í™” (ë™ê¸°) - 1ë²ˆ íŒŒì¼ ë°©ì‹ =====
        try:
            super().__init__(device=device, config=config, **kwargs)
        except Exception as e:
            # ì‘ê¸‰ ì´ˆê¸°í™” - 1ë²ˆ íŒŒì¼ ë°©ì‹
            self.logger = logging.getLogger(f"pipeline.{self.__class__.__name__}")
            self.step_name = "ClothSegmentationStep"
            self.device = device or "cpu"
            self.is_initialized = False
            self.logger.warning(f"âš ï¸ ë¶€ëª¨ ì´ˆê¸°í™” ì‹¤íŒ¨, ì‘ê¸‰ ì²˜ë¦¬: {e}")
        
        # ===== 2ë‹¨ê³„: Step íŠ¹í™” ì†ì„± ì„¤ì • (ë™ê¸°) - 1ë²ˆ íŒŒì¼ ë°©ì‹ =====
        self.step_name = "ClothSegmentationStep"
        self.step_number = 3
        self.step_type = "cloth_segmentation"
        self.device = device or self._auto_detect_device()
        
        # ===== 3ë‹¨ê³„: ì„¤ì • ì²˜ë¦¬ (ë™ê¸°) - 1ë²ˆ íŒŒì¼ ë°©ì‹ =====
        if isinstance(config, dict):
            self.segmentation_config = SegmentationConfig(**config)
        elif isinstance(config, SegmentationConfig):
            self.segmentation_config = config
        else:
            self.segmentation_config = SegmentationConfig()
        
        # ===== 4ë‹¨ê³„: ìƒíƒœ ë³€ìˆ˜ (ë™ê¸°) - 1ë²ˆ íŒŒì¼ ë°©ì‹ =====
        self.is_initialized = False
        self.models_loaded = {}
        self.available_methods = ['traditional', 'rembg', 'u2net', 'auto']
        
        # ===== 5ë‹¨ê³„: ModelLoader ì¸í„°í˜ì´ìŠ¤ ì„¤ì • ì‹œë„ (ë™ê¸°) - 1ë²ˆ íŒŒì¼ ë°©ì‹ =====
        self._setup_model_interface_safe()
        
        # ===== ì¶”ê°€: 2ë²ˆ íŒŒì¼ì˜ ê³ ê¸‰ ê¸°ëŠ¥ë“¤ ìœ ì§€ =====
        self.is_m3_max = self._detect_m3_max()
        self.memory_gb = kwargs.get('memory_gb', 128.0 if self.is_m3_max else 16.0)
        
        self.rembg_sessions = {}
        self.processing_stats = {
            'total_processed': 0,
            'successful_segmentations': 0,
            'average_time': 0.0,
            'average_quality': 0.0,
            'method_usage': {},
            'cache_hits': 0
        }
        
        self.segmentation_cache = {}
        self.cache_lock = threading.RLock()
        self.executor = ThreadPoolExecutor(max_workers=4 if self.is_m3_max else 2, 
                                         thread_name_prefix="cloth_seg")
        
        self._setup_paths_and_cache()
        self.available_methods = self._detect_available_methods()
        
        self.logger.info("âœ… ClothSegmentationStep ìƒì„± ì™„ë£Œ - Device: " + str(self.device))
        self.logger.info("   ì‚¬ìš© ê°€ëŠ¥í•œ ë°©ë²•: " + str(self.available_methods))

    def _auto_detect_device(self) -> str:
        """ë””ë°”ì´ìŠ¤ ìë™ ê°ì§€ - M3 Max ìµœì í™”"""
        try:
            # M3 Max MPS ìš°ì„ 
            if torch.backends.mps.is_available():
                return "mps"
            elif torch.cuda.is_available():
                return "cuda"
            else:
                return "cpu"
        except Exception:
            return "cpu"

    def _detect_m3_max(self) -> bool:
        """M3 Max ì¹© ê°ì§€"""
        try:
            import platform
            import subprocess
            if platform.system() == 'Darwin':  # macOS
                result = subprocess.run(['sysctl', '-n', 'machdep.cpu.brand_string'], 
                                       capture_output=True, text=True)
                cpu_info = result.stdout.strip()
                return 'M3 Max' in cpu_info or 'M3' in cpu_info
        except Exception:
            pass
        return False

    def _setup_model_interface_safe(self):
        """ğŸ”¥ ì•ˆì „í•œ ModelLoader ì¸í„°í˜ì´ìŠ¤ ì„¤ì • (ë™ê¸°) - 1ë²ˆ íŒŒì¼ ë°©ì‹"""
        try:
            self.logger.info("ğŸ”— ModelLoader ì¸í„°í˜ì´ìŠ¤ ì„¤ì • ì¤‘...")
            
            # ModelLoader ì‹œë„
            try:
                from app.ai_pipeline.utils.model_loader import get_global_model_loader
                model_loader = get_global_model_loader()
                
                if model_loader and hasattr(model_loader, 'create_step_interface'):
                    self.model_interface = model_loader.create_step_interface(self.step_name)
                    self.logger.info("âœ… ModelLoader ì¸í„°í˜ì´ìŠ¤ ìƒì„± ì™„ë£Œ")
                else:
                    self.model_interface = None
                    self.logger.warning("âš ï¸ ModelLoader ì‚¬ìš© ë¶ˆê°€, í´ë°± ëª¨ë“œ")
                    
            except Exception as e:
                self.model_interface = None
                self.logger.warning(f"âš ï¸ ModelLoader ì—°ë™ ì‹¤íŒ¨: {e}")
                
        except Exception as e:
            self.logger.error(f"âŒ ì¸í„°í˜ì´ìŠ¤ ì„¤ì • ì‹¤íŒ¨: {e}")
            self.model_interface = None

    def _setup_paths_and_cache(self):
        """ê²½ë¡œ ë° ìºì‹œ ì„¤ì •"""
        try:
            # ê¸°ë³¸ ê²½ë¡œ ì„¤ì •
            self.model_base_path = Path(__file__).parent.parent.parent.parent / "ai_models"
            self.checkpoint_path = self.model_base_path / "checkpoints" / "step_03"
            self.checkpoint_path.mkdir(parents=True, exist_ok=True)
            
            self.logger.info("ğŸ“ ê²½ë¡œ ë° ìºì‹œ ì„¤ì • ì™„ë£Œ")
            
        except Exception as e:
            self.logger.error(f"ê²½ë¡œ ì„¤ì • ì‹¤íŒ¨: {e}")

    def _detect_available_methods(self) -> List[SegmentationMethod]:
        """ì‚¬ìš© ê°€ëŠ¥í•œ ì„¸ê·¸ë©˜í…Œì´ì…˜ ë°©ë²• ê°ì§€"""
        methods = []
        
        # í•­ìƒ ì‚¬ìš© ê°€ëŠ¥í•œ ì „í†µì  ë°©ë²•
        methods.append(SegmentationMethod.TRADITIONAL)
        
        # RemBG í™•ì¸
        if REMBG_AVAILABLE:
            methods.append(SegmentationMethod.REMBG)
            self.logger.info("âœ… RemBG ì‚¬ìš© ê°€ëŠ¥")
        
        # SAM í™•ì¸
        if SAM_AVAILABLE:
            methods.append(SegmentationMethod.SAM)
            self.logger.info("âœ… SAM ì‚¬ìš© ê°€ëŠ¥")
        
        # U2-Net (ModelLoader í†µí•´ í™•ì¸)
        if MODEL_LOADER_AVAILABLE:
            methods.append(SegmentationMethod.U2NET)
            self.logger.info("âœ… U2-Net ì‚¬ìš© ê°€ëŠ¥ (ModelLoader)")
        
        # Transformers ê¸°ë°˜ ëª¨ë¸
        if TRANSFORMERS_AVAILABLE:
            methods.append(SegmentationMethod.DEEP_LAB)
            self.logger.info("âœ… DeepLab ì‚¬ìš© ê°€ëŠ¥")
        
        # AUTO ë°©ë²• (í•­ìƒ ì‚¬ìš© ê°€ëŠ¥)
        methods.append(SegmentationMethod.AUTO)
        
        # HYBRID ë°©ë²• (2ê°œ ì´ìƒ ë°©ë²•ì´ ìˆì„ ë•Œ)
        if len(methods) >= 3:  # TRADITIONAL + AUTO + í•˜ë‚˜ ì´ìƒ
            methods.append(SegmentationMethod.HYBRID)
        
        return methods

    # ==============================================
    # ğŸ”¥ í•µì‹¬: ë¹„ë™ê¸° initialize ë©”ì„œë“œ (1ë²ˆ íŒŒì¼ ë°©ì‹ ì ìš©)
    # ==============================================
    
    async def initialize(self) -> bool:
        """
        ğŸ”¥ ë¹„ë™ê¸° ì´ˆê¸°í™” ë©”ì„œë“œ - 1ë²ˆ íŒŒì¼ ë°©ì‹ ì™„ì „ ì ìš©
        âœ… ì´ ë©”ì„œë“œê°€ awaitë¡œ í˜¸ì¶œë˜ì–´ì•¼ í•¨
        âœ… ëª¨ë“  ë¹„ë™ê¸° ì‘ì—…ì„ ì—¬ê¸°ì„œ ì²˜ë¦¬
        """
        try:
            self.logger.info("ğŸ”„ ClothSegmentationStep ì´ˆê¸°í™” ì‹œì‘...")
            
            # ===== 1. ModelLoaderë¥¼ í†µí•œ AI ëª¨ë¸ ë¡œë“œ (ë¹„ë™ê¸°) =====
            await self._initialize_ai_models_via_modelloader()
            
            # ===== 2. RemBG ì„¸ì…˜ ì´ˆê¸°í™” (ì§ì ‘ ê´€ë¦¬) =====
            if REMBG_AVAILABLE:
                await self._initialize_rembg_sessions()
            
            # ===== 3. ì „í†µì  ë°©ë²•ë“¤ ì´ˆê¸°í™” (ë™ê¸°) =====
            self._initialize_traditional_methods()
            
            # ===== 4. M3 Max ìµœì í™” ì›Œë°ì—… =====
            if self.is_m3_max:
                await self._warmup_m3_max()
            
            # ===== 5. ì‹œê°í™” ì‹œìŠ¤í…œ ì´ˆê¸°í™” =====
            self._initialize_visualization_system()
            
            # ===== 6. ìºì‹œ ë° ë¦¬ì†ŒìŠ¤ ì´ˆê¸°í™” (ë™ê¸°) =====
            self._initialize_cache_and_resources()
            
            # ===== 7. ì´ˆê¸°í™” ì™„ë£Œ =====
            self.is_initialized = True
            self.logger.info("âœ… ClothSegmentationStep ì´ˆê¸°í™” ì™„ë£Œ")
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.is_initialized = False
            return False

    async def _initialize_ai_models_via_modelloader(self):
        """ModelLoaderë¥¼ í†µí•œ AI ëª¨ë¸ ë¡œë“œ (ë¹„ë™ê¸°) - 1ë²ˆ íŒŒì¼ ë°©ì‹"""
        try:
            if self.model_interface:
                # U2NET ëª¨ë¸ ë¡œë“œ ì‹œë„
                try:
                    u2net_model = await self.model_interface.get_model("cloth_segmentation_u2net")
                    if u2net_model:
                        self.models_loaded['u2net'] = u2net_model
                        self.logger.info("âœ… U2NET ëª¨ë¸ ë¡œë“œ ì„±ê³µ (ModelLoader)")
                except Exception as e:
                    self.logger.warning(f"âš ï¸ U2NET ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
                
                # í´ë°± ëª¨ë¸ ë¡œë“œ ì‹œë„
                try:
                    fallback_model = await self.model_interface.get_model("cloth_segmentation_fallback")
                    if fallback_model:
                        self.models_loaded['fallback'] = fallback_model
                        self.logger.info("âœ… í´ë°± ëª¨ë¸ ë¡œë“œ ì„±ê³µ")
                except Exception as e:
                    self.logger.debug(f"í´ë°± ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨ (ì •ìƒ): {e}")
            else:
                self.logger.warning("âš ï¸ ModelLoader ì¸í„°í˜ì´ìŠ¤ ì—†ìŒ, ì „í†µì  ë°©ë²•ë§Œ ì‚¬ìš©")
                await self._fallback_model_loading()
                
        except Exception as e:
            self.logger.error(f"âŒ AI ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")

    async def _fallback_model_loading(self):
        """í´ë°± ëª¨ë¸ ë¡œë”© (ModelLoader ì—†ì„ ë•Œ)"""
        try:
            self.logger.info("ğŸ”„ í´ë°± ëª¨ë“œ: ì§ì ‘ U2-Net ëª¨ë¸ ë¡œë”©...")
            
            # ì§ì ‘ U2-Net ëª¨ë¸ ìƒì„± (í´ë°±ìš©)
            u2net_model = U2NET(in_ch=3, out_ch=1)
            
            # ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ ì‹œë„
            checkpoint_candidates = [
                self.checkpoint_path / "u2net_cloth.pth",
                self.checkpoint_path / "u2net.pth", 
                self.model_base_path / "u2net" / "u2net.pth",
                self.model_base_path / "checkpoints" / "u2net.pth"
            ]
            
            model_loaded = False
            for checkpoint_path in checkpoint_candidates:
                if checkpoint_path.exists():
                    try:
                        self.logger.info(f"ğŸ“ ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ ì‹œë„: {checkpoint_path}")
                        state_dict = torch.load(checkpoint_path, map_location=self.device)
                        
                        # state_dict í‚¤ ì •ë¦¬
                        if any(key.startswith('module.') for key in state_dict.keys()):
                            state_dict = {key.replace('module.', ''): value for key, value in state_dict.items()}
                        
                        u2net_model.load_state_dict(state_dict, strict=False)
                        self.logger.info(f"âœ… U2-Net ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ ì„±ê³µ: {checkpoint_path}")
                        model_loaded = True
                        break
                        
                    except Exception as e:
                        self.logger.warning(f"ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ ì‹¤íŒ¨ {checkpoint_path}: {e}")
                        continue
            
            if not model_loaded:
                self.logger.warning("âš ï¸ U2-Net ì²´í¬í¬ì¸íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤. ì‚¬ì „ í›ˆë ¨ë˜ì§€ ì•Šì€ ëª¨ë¸ ì‚¬ìš©.")
            
            # ë””ë°”ì´ìŠ¤ ì´ë™ ë° ì„¤ì •
            u2net_model.to(self.device)
            u2net_model.eval()
            
            # ì •ë°€ë„ ì„¤ì •
            u2net_model = self._setup_model_precision(u2net_model)
            
            self.models_loaded['u2net'] = u2net_model
            self.logger.info("âœ… í´ë°± U2-Net ëª¨ë¸ ì„¤ì • ì™„ë£Œ")
            
        except Exception as e:
            self.logger.warning(f"í´ë°± ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e}")
            # ìµœì¢… í´ë°±: ë”ë¯¸ ëª¨ë¸
            self.models_loaded['fallback'] = True

    def _setup_model_precision(self, model):
        """ğŸ”¥ M3 Max í˜¸í™˜ ì •ë°€ë„ ì„¤ì •"""
        try:
            if self.device == "mps":
                # M3 Maxì—ì„œëŠ” Float32ê°€ ì•ˆì „
                return model.float()
            elif self.device == "cuda" and self.segmentation_config.use_fp16:
                return model.half()
            else:
                return model.float()
        except Exception as e:
            self.logger.warning(f"âš ï¸ ì •ë°€ë„ ì„¤ì • ì‹¤íŒ¨: {e}")
            return model.float()

    async def _initialize_rembg_sessions(self):
        """RemBG ì„¸ì…˜ë“¤ ì´ˆê¸°í™” (ì§ì ‘ ê´€ë¦¬)"""
        try:
            if not REMBG_AVAILABLE:
                return
            
            self.logger.info("ğŸ”„ RemBG ì„¸ì…˜ ì´ˆê¸°í™” ì‹œì‘...")
            
            # ë‹¤ì–‘í•œ RemBG ëª¨ë¸ ì„¸ì…˜ ìƒì„±
            session_configs = {
                'u2net': 'u2net',
                'u2netp': 'u2netp', 
                'silueta': 'silueta',
            }
            
            self.rembg_sessions = {}
            
            for name, model_name in session_configs.items():
                try:
                    self.logger.info(f"ğŸ”„ RemBG ì„¸ì…˜ ìƒì„± ì¤‘: {name} ({model_name})")
                    session = new_session(model_name)
                    self.rembg_sessions[name] = session
                    self.logger.info(f"âœ… RemBG ì„¸ì…˜ ìƒì„± ì™„ë£Œ: {name}")
                except Exception as e:
                    self.logger.warning(f"RemBG ì„¸ì…˜ {name} ìƒì„± ì‹¤íŒ¨: {e}")
            
            # ê¸°ë³¸ ì„¸ì…˜ ì„¤ì •
            if self.rembg_sessions:
                self.default_rembg_session = (
                    self.rembg_sessions.get('u2net') or 
                    list(self.rembg_sessions.values())[0]
                )
                self.logger.info("âœ… RemBG ê¸°ë³¸ ì„¸ì…˜ ì„¤ì • ì™„ë£Œ")
            
        except Exception as e:
            self.logger.warning(f"RemBG ì„¸ì…˜ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.rembg_sessions = {}

    def _initialize_traditional_methods(self):
        """ì „í†µì  ì´ë¯¸ì§€ ì²˜ë¦¬ ë°©ë²•ë“¤ ì´ˆê¸°í™”"""
        try:
            # ìƒ‰ìƒ ë²”ìœ„ ê¸°ë°˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ ì„¤ì •
            self.color_ranges = {
                'skin': {
                    'lower': np.array([0, 48, 80], dtype=np.uint8),
                    'upper': np.array([20, 255, 255], dtype=np.uint8)
                },
                'clothing': {
                    'lower': np.array([0, 0, 0], dtype=np.uint8),
                    'upper': np.array([180, 255, 200], dtype=np.uint8)
                }
            }
            
            # í˜•íƒœí•™ì  ì—°ì‚° ì»¤ë„
            self.morphology_kernels = {
                'small': cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3)),
                'medium': cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (7, 7)),
                'large': cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (15, 15))
            }
            
            self.logger.info("âœ… ì „í†µì  ë°©ë²• ì´ˆê¸°í™” ì™„ë£Œ")
            
        except Exception as e:
            self.logger.warning(f"ì „í†µì  ë°©ë²• ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")

    async def _warmup_m3_max(self):
        """M3 Max ì›Œë°ì—…"""
        try:
            self.logger.info("ğŸ”¥ M3 Max ì›Œë°ì—… ì‹œì‘...")
            
            # ë”ë¯¸ í…ì„œë¡œ ì›Œë°ì—…
            dummy_input = torch.randn(1, 3, 512, 512, device=self.device)
            
            if 'u2net' in self.models_loaded and self.models_loaded['u2net']:
                model = self.models_loaded['u2net']
                if hasattr(model, 'eval'):
                    model.eval()
                    with torch.no_grad():
                        _ = model(dummy_input)
                    self.logger.info("âœ… U2-Net M3 Max ì›Œë°ì—… ì™„ë£Œ")
            
            # MPS ìºì‹œ ì •ë¦¬
            if torch.backends.mps.is_available():
                torch.mps.empty_cache()
            
            self.logger.info("âœ… M3 Max ì›Œë°ì—… ì™„ë£Œ")
            
        except Exception as e:
            self.logger.warning(f"M3 Max ì›Œë°ì—… ì‹¤íŒ¨: {e}")

    def _initialize_visualization_system(self):
        """ì‹œê°í™” ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
        try:
            # ì‹œê°í™” ì„¤ì •
            self.visualization_config = {
                'mask_alpha': 0.7,
                'overlay_alpha': 0.5,
                'boundary_thickness': 2,
                'color_intensity': 200
            }
            
            # í°íŠ¸ ì„¤ì • (ì‹œìŠ¤í…œì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ í°íŠ¸ ì°¾ê¸°)
            try:
                self.font = ImageFont.truetype("/System/Library/Fonts/Helvetica.ttc", 16)
            except Exception:
                try:
                    self.font = ImageFont.load_default()
                except Exception:
                    self.font = None
            
            self.logger.info("âœ… ì‹œê°í™” ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
            
        except Exception as e:
            self.logger.warning(f"ì‹œê°í™” ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")

    def _initialize_cache_and_resources(self):
        """ìºì‹œ ë° ë¦¬ì†ŒìŠ¤ ì´ˆê¸°í™” (ë™ê¸°) - 1ë²ˆ íŒŒì¼ ë°©ì‹"""
        try:
            self.segmentation_cache = {}
            self.processing_stats = {
                'total_processed': 0,
                'successful': 0,
                'failed': 0,
                'average_time': 0.0
            }
            self.logger.info("âœ… ìºì‹œ ë° ë¦¬ì†ŒìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ")
            
        except Exception as e:
            self.logger.error(f"âŒ ìºì‹œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")

    # ==============================================
    # ğŸ”¥ í•µì‹¬: process ë©”ì„œë“œ (ë¹„ë™ê¸°) - 1ë²ˆ íŒŒì¼ ë°©ì‹ ì ìš©
    # ==============================================
    
    async def process(
        self,
        image,
        clothing_type: Optional[str] = None,
        quality_level: Optional[str] = None,
        **kwargs
    ) -> Dict[str, Any]:
        """
        ğŸ”¥ ë©”ì¸ ì²˜ë¦¬ ë©”ì„œë“œ (ë¹„ë™ê¸°) - 1ë²ˆ íŒŒì¼ ë°©ì‹ ì™„ì „ ì ìš©
        âœ… ì•ˆì „í•œ ì´ë¯¸ì§€ ì²˜ë¦¬
        âœ… ModelLoader ëª¨ë¸ ì‚¬ìš©
        âœ… í´ë°± ì²˜ë¦¬ í¬í•¨
        """
        
        if not self.is_initialized:
            await self.initialize()
        
        start_time = time.time()  # asyncio.get_event_loop().time() ëŒ€ì‹  time.time() ì‚¬ìš©
        
        try:
            self.logger.info("ğŸ”„ ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ ì²˜ë¦¬ ì‹œì‘...")
            
            # ===== 1. ì´ë¯¸ì§€ ì „ì²˜ë¦¬ =====
            processed_image = self._preprocess_image(image)
            if processed_image is None:
                return self._create_error_result("ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì‹¤íŒ¨")
            
            # ===== 2. ì˜ë¥˜ íƒ€ì… ê°ì§€ =====
            detected_clothing_type = self._detect_clothing_type(
                processed_image, clothing_type
            )
            
            # ===== 3. í’ˆì§ˆ ë ˆë²¨ ì„¤ì • =====
            quality = QualityLevel(quality_level or self.segmentation_config.quality_level.value)
            
            # ===== 4. ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‹¤í–‰ =====
            mask, confidence = await self._run_segmentation(
                processed_image, detected_clothing_type, quality_level
            )
            
            if mask is None:
                return self._create_error_result("ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‹¤íŒ¨")
            
            # ===== 5. í›„ì²˜ë¦¬ =====
            final_mask = self._post_process_mask(mask, quality)
            
            # ===== 6. ì‹œê°í™” ì´ë¯¸ì§€ ìƒì„± =====
            visualizations = self._create_visualizations(
                processed_image, final_mask, detected_clothing_type
            )
            
            # ===== 7. ê²°ê³¼ ìƒì„± =====
            processing_time = time.time() - start_time
            
            result = {
                'success': True,
                'mask': final_mask,
                'confidence': confidence,
                'clothing_type': detected_clothing_type.value if hasattr(detected_clothing_type, 'value') else str(detected_clothing_type),
                'processing_time': processing_time,
                'method_used': self._get_current_method(),
                'metadata': {
                    'device': self.device,
                    'quality_level': quality.value,
                    'models_used': list(self.models_loaded.keys()),
                    'image_size': processed_image.size if hasattr(processed_image, 'size') else (512, 512)
                }
            }
            
            # ì‹œê°í™” ì´ë¯¸ì§€ë“¤ ì¶”ê°€
            if visualizations:
                if 'visualization' in visualizations:
                    result['visualization_base64'] = self._image_to_base64(visualizations['visualization'])
                if 'overlay' in visualizations:
                    result['overlay_base64'] = self._image_to_base64(visualizations['overlay'])
                if 'mask' in visualizations:
                    result['mask_base64'] = self._image_to_base64(visualizations['mask'])
                if 'boundary' in visualizations:
                    result['boundary_base64'] = self._image_to_base64(visualizations['boundary'])
            
            # í†µê³„ ì—…ë°ì´íŠ¸
            self._update_processing_stats(processing_time, True)
            
            self.logger.info(f"âœ… ì„¸ê·¸ë©˜í…Œì´ì…˜ ì™„ë£Œ - {processing_time:.2f}ì´ˆ")
            return result
            
        except Exception as e:
            processing_time = time.time() - start_time
            self._update_processing_stats(processing_time, False)
            
            self.logger.error(f"âŒ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return self._create_error_result(str(e))

    async def _run_segmentation_inference(
        self,
        image: Image.Image,
        clothing_type: ClothingType,
        quality: QualityLevel
    ) -> Tuple[Optional[np.ndarray], float]:
        """
        ğŸ”¥ í•µì‹¬: ModelLoaderê°€ ì œê³µí•œ ëª¨ë¸ë¡œ ì¶”ë¡  ì‹¤í–‰ - ì™„ì „í•œ êµ¬í˜„
        
        âœ… ëª¨ë¸ ì¶”ë¡  â† ModelLoaderê°€ ì œê³µí•œ ëª¨ë¸ë¡œ Stepì´ ì¶”ë¡ 
        """
        try:
            # ìš°ì„ ìˆœìœ„ ìˆœì„œë¡œ ë°©ë²• ì‹œë„
            methods_to_try = self._get_methods_by_priority(quality)
            
            for method in methods_to_try:
                try:
                    mask, confidence = await self._run_method(method, image, clothing_type)
                    if mask is not None:
                        self.logger.info(f"âœ… ì„¸ê·¸ë©˜í…Œì´ì…˜ ì„±ê³µ: {method.value}")
                        return mask, confidence
                except Exception as e:
                    self.logger.warning(f"ë°©ë²• {method.value} ì‹¤íŒ¨: {e}")
                    continue
            
            self.logger.warning("ëª¨ë“  ì„¸ê·¸ë©˜í…Œì´ì…˜ ë°©ë²• ì‹¤íŒ¨")
            return None, 0.0
            
        except Exception as e:
            self.logger.error(f"ì„¸ê·¸ë©˜í…Œì´ì…˜ ì¶”ë¡  ì‹¤íŒ¨: {e}")
            return None, 0.0

    def _get_methods_by_priority(self, quality: QualityLevel) -> List[SegmentationMethod]:
        """í’ˆì§ˆ ë ˆë²¨ë³„ ë°©ë²• ìš°ì„ ìˆœìœ„"""
        if quality == QualityLevel.ULTRA:
            priority = [
                SegmentationMethod.U2NET,
                SegmentationMethod.SAM,
                SegmentationMethod.DEEP_LAB,
                SegmentationMethod.REMBG,
                SegmentationMethod.TRADITIONAL
            ]
        elif quality == QualityLevel.HIGH:
            priority = [
                SegmentationMethod.U2NET,
                SegmentationMethod.REMBG,
                SegmentationMethod.DEEP_LAB,
                SegmentationMethod.TRADITIONAL
            ]
        elif quality == QualityLevel.BALANCED:
            priority = [
                SegmentationMethod.REMBG,
                SegmentationMethod.U2NET,
                SegmentationMethod.TRADITIONAL
            ]
        else:  # FAST
            priority = [
                SegmentationMethod.TRADITIONAL,
                SegmentationMethod.REMBG
            ]
        
        # ì‚¬ìš© ê°€ëŠ¥í•œ ë°©ë²•ë§Œ í•„í„°ë§
        return [method for method in priority if method in self.available_methods]

    async def _run_method(
        self,
        method: SegmentationMethod,
        image: Image.Image,
        clothing_type: ClothingType
    ) -> Tuple[Optional[np.ndarray], float]:
        """ê°œë³„ ì„¸ê·¸ë©˜í…Œì´ì…˜ ë°©ë²• ì‹¤í–‰"""
        
        if method == SegmentationMethod.U2NET:
            return await self._run_u2net_segmentation(image)
        elif method == SegmentationMethod.REMBG:
            return await self._run_rembg_segmentation(image)
        elif method == SegmentationMethod.SAM:
            return await self._run_sam_segmentation(image)
        elif method == SegmentationMethod.DEEP_LAB:
            return await self._run_deeplab_segmentation(image)
        elif method == SegmentationMethod.TRADITIONAL:
            return self._run_traditional_segmentation(image, clothing_type)
        elif method == SegmentationMethod.HYBRID:
            return await self._run_hybrid_segmentation(image, clothing_type)
        elif method == SegmentationMethod.AUTO:
            # AUTOëŠ” ê°€ì¥ ì¢‹ì€ ë°©ë²•ì„ ìë™ ì„ íƒ
            best_method = self._select_best_method_for_auto(image, clothing_type)
            return await self._run_method(best_method, image, clothing_type)
        else:
            raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ë°©ë²•: {method}")

    async def _run_u2net_segmentation(self, image: Image.Image) -> Tuple[Optional[np.ndarray], float]:
        """
        ğŸ”¥ U2-Net ì„¸ê·¸ë©˜í…Œì´ì…˜ (ModelLoader ì œê³µ ëª¨ë¸ ì‚¬ìš©)
        
        âœ… ModelLoaderê°€ ì œê³µí•œ ëª¨ë¸ë¡œ ì¶”ë¡ 
        âœ… ì§ì ‘ ëª¨ë¸ êµ¬í˜„ë„ í´ë°±ìœ¼ë¡œ ì§€ì›
        """
        try:
            # ModelLoaderì—ì„œ ì œê³µëœ ëª¨ë¸ ì‚¬ìš©
            if 'u2net' not in self.models_loaded:
                raise ValueError("U2-Net ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•ŠìŒ")
            
            model = self.models_loaded['u2net']
            if model is None or model is True:  # í´ë°± ëª¨ë“œ
                raise ValueError("U2-Net ëª¨ë¸ì´ ìœ íš¨í•˜ì§€ ì•ŠìŒ")
            
            # ì´ë¯¸ì§€ ì „ì²˜ë¦¬
            transform = transforms.Compose([
                transforms.ToTensor(),
                transforms.Normalize(mean=[0.485, 0.456, 0.406], 
                                   std=[0.229, 0.224, 0.225])
            ])
            
            input_tensor = transform(image).unsqueeze(0).to(self.device)
            
            # ğŸ”¥ ModelLoaderê°€ ì œê³µí•œ ëª¨ë¸ë¡œ ì¶”ë¡ 
            model.eval()
            with torch.no_grad():
                output = model(input_tensor)
                
                # ì¶œë ¥ ì²˜ë¦¬ (ëª¨ë¸ êµ¬ì¡°ì— ë”°ë¼ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ)
                if isinstance(output, tuple):
                    output = output[0]  # ì²« ë²ˆì§¸ ì¶œë ¥ ì‚¬ìš© (main output)
                elif isinstance(output, list):
                    output = output[0]  # ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš°
                
                # ì‹œê·¸ëª¨ì´ë“œ ì ìš© ë° ì„ê³„ê°’ ì²˜ë¦¬
                if output.max() > 1.0:  # ì‹œê·¸ëª¨ì´ë“œê°€ ì ìš©ë˜ì§€ ì•Šì€ ê²½ìš°
                    prob_map = torch.sigmoid(output)
                else:
                    prob_map = output
                
                mask = (prob_map > self.segmentation_config.confidence_threshold).float()
                
                # CPUë¡œ ì´ë™ ë° NumPy ë³€í™˜
                mask_np = mask.squeeze().cpu().numpy()
                confidence = float(prob_map.max().item())
            
            self.logger.info(f"âœ… U2-Net ì¶”ë¡  ì™„ë£Œ - ì‹ ë¢°ë„: {confidence:.3f}")
            return mask_np, confidence
            
        except Exception as e:
            self.logger.warning(f"U2-Net ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‹¤íŒ¨: {e}")
            return None, 0.0

    async def _run_rembg_segmentation(self, image: Image.Image) -> Tuple[Optional[np.ndarray], float]:
        """RemBG ì„¸ê·¸ë©˜í…Œì´ì…˜"""
        try:
            if not self.rembg_sessions:
                raise ValueError("RemBG ì„¸ì…˜ì´ ì—†ìŒ")
            
            # ì„¸ì…˜ ì„ íƒ (ì˜ë¥˜ì— ìµœì í™”ëœ ê²ƒ ìš°ì„ )
            session = (
                self.rembg_sessions.get('u2net') or
                list(self.rembg_sessions.values())[0]
            )
            
            # RemBG ì‹¤í–‰
            result = remove(image, session=session)
            
            # ì•ŒíŒŒ ì±„ë„ì—ì„œ ë§ˆìŠ¤í¬ ì¶”ì¶œ
            if result.mode == 'RGBA':
                mask = np.array(result)[:, :, 3]  # ì•ŒíŒŒ ì±„ë„
                mask = (mask > 128).astype(np.uint8)  # ì´ì§„í™”
                
                # ì‹ ë¢°ë„ ê³„ì‚° (ë§ˆìŠ¤í¬ ì˜ì—­ ë¹„ìœ¨ ê¸°ë°˜)
                confidence = np.sum(mask) / mask.size
                
                return mask, confidence
            else:
                raise ValueError("RemBG ê²°ê³¼ì— ì•ŒíŒŒ ì±„ë„ì´ ì—†ìŒ")
                
        except Exception as e:
            self.logger.warning(f"RemBG ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‹¤íŒ¨: {e}")
            return None, 0.0

    async def _run_sam_segmentation(self, image: Image.Image) -> Tuple[Optional[np.ndarray], float]:
        """SAM ì„¸ê·¸ë©˜í…Œì´ì…˜ (ModelLoader ì œê³µ ëª¨ë¸ ì‚¬ìš©)"""
        try:
            if 'sam' not in self.models_loaded:
                raise ValueError("SAM ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•ŠìŒ")
            
            # SAMì€ ë³„ë„ì˜ ë³µì¡í•œ ì„¤ì •ì´ í•„ìš”í•˜ë¯€ë¡œ ê°„ë‹¨í•œ êµ¬í˜„
            # ì‹¤ì œë¡œëŠ” ë” ì •êµí•œ í”„ë¡¬í”„íŠ¸ ê¸°ë°˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ ìˆ˜í–‰
            
            # ì„ì‹œë¡œ ì¤‘ì•™ ì˜ì—­ì„ ì˜ë¥˜ë¡œ ê°€ì •
            width, height = image.size
            mask = np.zeros((height, width), dtype=np.uint8)
            center_x, center_y = width // 2, height // 2
            
            # íƒ€ì›í˜• ë§ˆìŠ¤í¬ ìƒì„±
            y, x = np.ogrid[:height, :width]
            ellipse_mask = ((x - center_x) / (width * 0.3))**2 + ((y - center_y) / (height * 0.4))**2 <= 1
            mask[ellipse_mask] = 1
            
            confidence = 0.8  # ê³ ì • ì‹ ë¢°ë„
            
            self.logger.info("âœ… SAM ì„¸ê·¸ë©˜í…Œì´ì…˜ ì™„ë£Œ (ê°„ë‹¨ êµ¬í˜„)")
            return mask, confidence
            
        except Exception as e:
            self.logger.warning(f"SAM ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‹¤íŒ¨: {e}")
            return None, 0.0

    async def _run_deeplab_segmentation(self, image: Image.Image) -> Tuple[Optional[np.ndarray], float]:
        """DeepLab ì„¸ê·¸ë©˜í…Œì´ì…˜ (ModelLoader ì œê³µ ëª¨ë¸ ì‚¬ìš©)"""
        try:
            if 'deeplab' not in self.models_loaded:
                raise ValueError("DeepLab ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•ŠìŒ")
            
            # DeepLabì€ ë³´í†µ Transformers pipelineìœ¼ë¡œ ì œê³µ
            model = self.models_loaded['deeplab']
            
            # ê°„ë‹¨í•œ êµ¬í˜„ (ì‹¤ì œë¡œëŠ” ë” ë³µì¡)
            # ì‚¬ëŒ ì˜ì—­ ê°ì§€ í›„ ì˜ë¥˜ ì˜ì—­ ì¶”ì¶œ
            
            # ì„ì‹œë¡œ ì¤‘ì•™-í•˜ë‹¨ ì˜ì—­ì„ ì˜ë¥˜ë¡œ ê°€ì •
            width, height = image.size
            mask = np.zeros((height, width), dtype=np.uint8)
            
            # í•˜ì²´ ì˜ì—­ ë§ˆìŠ¤í¬
            mask[height//3:height*2//3, width//4:width*3//4] = 1
            
            confidence = 0.7
            
            self.logger.info("âœ… DeepLab ì„¸ê·¸ë©˜í…Œì´ì…˜ ì™„ë£Œ (ê°„ë‹¨ êµ¬í˜„)")
            return mask, confidence
            
        except Exception as e:
            self.logger.warning(f"DeepLab ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‹¤íŒ¨: {e}")
            return None, 0.0

    async def _run_hybrid_segmentation(
        self,
        image: Image.Image,
        clothing_type: ClothingType
    ) -> Tuple[Optional[np.ndarray], float]:
        """í•˜ì´ë¸Œë¦¬ë“œ ì„¸ê·¸ë©˜í…Œì´ì…˜ (ì—¬ëŸ¬ ë°©ë²• ì¡°í•©)"""
        try:
            self.logger.info("ğŸ”„ í•˜ì´ë¸Œë¦¬ë“œ ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‹œì‘...")
            
            results = []
            weights = []
            
            # U2-Net ì‹œë„
            try:
                mask1, conf1 = await self._run_u2net_segmentation(image)
                if mask1 is not None:
                    results.append(mask1)
                    weights.append(conf1 * 0.4)  # ë†’ì€ ê°€ì¤‘ì¹˜
            except Exception:
                pass
            
            # RemBG ì‹œë„
            try:
                mask2, conf2 = await self._run_rembg_segmentation(image)
                if mask2 is not None:
                    results.append(mask2)
                    weights.append(conf2 * 0.3)
            except Exception:
                pass
            
            # ì „í†µì  ë°©ë²• ì‹œë„
            try:
                mask3, conf3 = self._run_traditional_segmentation(image, clothing_type)
                if mask3 is not None:
                    results.append(mask3)
                    weights.append(conf3 * 0.3)
            except Exception:
                pass
            
            if not results:
                return None, 0.0
            
            # ê°€ì¤‘ í‰ê· ìœ¼ë¡œ ë§ˆìŠ¤í¬ ì¡°í•©
            combined_mask = np.zeros_like(results[0], dtype=np.float32)
            total_weight = sum(weights)
            
            for mask, weight in zip(results, weights):
                combined_mask += mask.astype(np.float32) * (weight / total_weight)
            
            # ì´ì§„í™”
            final_mask = (combined_mask > 0.5).astype(np.uint8)
            final_confidence = total_weight / len(results)
            
            self.logger.info(f"âœ… í•˜ì´ë¸Œë¦¬ë“œ ì„¸ê·¸ë©˜í…Œì´ì…˜ ì™„ë£Œ - {len(results)}ê°œ ë°©ë²• ì¡°í•©")
            return final_mask, final_confidence
            
        except Exception as e:
            self.logger.warning(f"í•˜ì´ë¸Œë¦¬ë“œ ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‹¤íŒ¨: {e}")
            return None, 0.0

    def _select_best_method_for_auto(self, image: Image.Image, clothing_type: ClothingType) -> SegmentationMethod:
        """AUTO ëª¨ë“œì—ì„œ ìµœì  ë°©ë²• ì„ íƒ"""
        # ì´ë¯¸ì§€ íŠ¹ì„± ë¶„ì„
        width, height = image.size
        complexity_score = self._calculate_image_complexity(image)
        
        # ë³µì¡ë„ì™€ ì‚¬ìš© ê°€ëŠ¥í•œ ë°©ë²•ì— ë”°ë¼ ì„ íƒ
        if complexity_score > 0.7 and SegmentationMethod.U2NET in self.available_methods:
            return SegmentationMethod.U2NET
        elif SegmentationMethod.REMBG in self.available_methods:
            return SegmentationMethod.REMBG
        elif SegmentationMethod.U2NET in self.available_methods:
            return SegmentationMethod.U2NET
        else:
            return SegmentationMethod.TRADITIONAL

    def _calculate_image_complexity(self, image: Image.Image) -> float:
        """ì´ë¯¸ì§€ ë³µì¡ë„ ê³„ì‚°"""
        try:
            # ê°„ë‹¨í•œ ë³µì¡ë„ ì¸¡ì • (ì—£ì§€ ë°€ë„ ê¸°ë°˜)
            gray = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2GRAY)
            edges = cv2.Canny(gray, 50, 150)
            edge_density = np.sum(edges > 0) / edges.size
            return min(edge_density * 10, 1.0)  # ì •ê·œí™”
        except Exception:
            return 0.5  # ê¸°ë³¸ê°’

    async def _run_segmentation(self, image, clothing_type, quality_level):
        """ê¸°ì¡´ í˜¸í™˜ì„±ì„ ìœ„í•œ í´ë°± ë©”ì„œë“œ"""
        return await self._run_segmentation_inference(image, clothing_type, quality_level)

    # ==============================================
    # ğŸ”¥ ìœ í‹¸ë¦¬í‹° ë©”ì„œë“œë“¤ (ë™ê¸°) - 1ë²ˆ + 2ë²ˆ íŒŒì¼ ì¡°í•©
    # ==============================================
    
    def _preprocess_image(self, image):
        """ì´ë¯¸ì§€ ì „ì²˜ë¦¬ (ë™ê¸°) - 1ë²ˆ íŒŒì¼ ë°©ì‹"""
        try:
            # ì…ë ¥ íƒ€ì…ë³„ ì²˜ë¦¬
            if isinstance(image, str):
                # Base64 ë˜ëŠ” íŒŒì¼ ê²½ë¡œ
                if image.startswith('data:image'):
                    # Base64
                    header, data = image.split(',', 1)
                    image_data = base64.b64decode(data)
                    image = Image.open(BytesIO(image_data))
                else:
                    # íŒŒì¼ ê²½ë¡œ
                    image = Image.open(image)
            elif isinstance(image, np.ndarray):
                # NumPy ë°°ì—´
                if image.shape[2] == 3:  # RGB
                    image = Image.fromarray(image)
                elif image.shape[2] == 4:  # RGBA
                    image = Image.fromarray(image).convert('RGB')
                else:
                    raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì´ë¯¸ì§€ í˜•íƒœ: {image.shape}")
            elif not isinstance(image, Image.Image):
                raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì´ë¯¸ì§€ íƒ€ì…: {type(image)}")
            
            # RGB ë³€í™˜
            if image.mode != 'RGB':
                image = image.convert('RGB')
            
            # í¬ê¸° ì¡°ì •
            target_size = self.segmentation_config.input_size
            if image.size != target_size:
                image = image.resize(target_size, Image.Resampling.LANCZOS)
            
            return image
                
        except Exception as e:
            self.logger.error(f"ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return None

    def _detect_clothing_type(self, image, hint=None):
        """ì˜ë¥˜ íƒ€ì… ê°ì§€"""
        if hint:
            try:
                return ClothingType(hint.lower())
            except ValueError:
                pass
        
        # ê°„ë‹¨í•œ íœ´ë¦¬ìŠ¤í‹± ê¸°ë°˜ ê°ì§€
        if hasattr(image, 'size'):
            width, height = image.size
            aspect_ratio = height / width
            
            if aspect_ratio > 1.5:
                return ClothingType.DRESS
            elif aspect_ratio > 1.2:
                return ClothingType.SHIRT
            else:
                return ClothingType.PANTS
        
        return ClothingType.UNKNOWN

    def _run_traditional_segmentation(
        self, 
        image: Image.Image, 
        clothing_type: ClothingType
    ) -> Tuple[Optional[np.ndarray], float]:
        """ì „í†µì  ì„¸ê·¸ë©˜í…Œì´ì…˜ (ìƒ‰ìƒ ê¸°ë°˜) - ì™„ì „í•œ êµ¬í˜„"""
        try:
            # PIL to OpenCV ë³€í™˜
            image_cv = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)
            hsv = cv2.cvtColor(image_cv, cv2.COLOR_BGR2HSV)
            
            # í”¼ë¶€ìƒ‰ ì˜ì—­ ì œê±°
            if hasattr(self, 'color_ranges'):
                skin_mask = cv2.inRange(hsv, self.color_ranges['skin']['lower'], 
                                      self.color_ranges['skin']['upper'])
                
                # ì˜ë¥˜ ìƒ‰ìƒ ë²”ìœ„ ê°ì§€
                clothing_mask = cv2.inRange(hsv, self.color_ranges['clothing']['lower'],
                                          self.color_ranges['clothing']['upper'])
                
                # í”¼ë¶€ ì˜ì—­ ì œì™¸
                clothing_mask = cv2.bitwise_and(clothing_mask, cv2.bitwise_not(skin_mask))
                
                # í˜•íƒœí•™ì  ì—°ì‚°ìœ¼ë¡œ ë…¸ì´ì¦ˆ ì œê±°
                if hasattr(self, 'morphology_kernels'):
                    clothing_mask = cv2.morphologyEx(clothing_mask, cv2.MORPH_CLOSE, 
                                                   self.morphology_kernels['medium'])
                    clothing_mask = cv2.morphologyEx(clothing_mask, cv2.MORPH_OPEN,
                                                   self.morphology_kernels['small'])
                
                # ê°€ì¥ í° ì—°ê²° ì˜ì—­ ì°¾ê¸°
                contours, _ = cv2.findContours(clothing_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                if contours:
                    largest_contour = max(contours, key=cv2.contourArea)
                    mask = np.zeros_like(clothing_mask)
                    cv2.fillPoly(mask, [largest_contour], 255)
                    mask = (mask > 0).astype(np.uint8)
                else:
                    mask = (clothing_mask > 0).astype(np.uint8)
                
                # ì‹ ë¢°ë„ ê³„ì‚°
                confidence = np.sum(mask) / mask.size
                confidence = min(confidence * 2, 1.0)  # ì •ê·œí™”
            else:
                # ê¸°ë³¸ ë§ˆìŠ¤í¬ ìƒì„± (ì¤‘ì•™ ì˜ì—­) - color_rangesê°€ ì—†ì„ ë•Œ
                height, width = image_cv.shape[:2]
                mask = np.zeros((height, width), dtype=np.uint8)
                
                # ì¤‘ì•™ ì˜ì—­ì„ ì˜ë¥˜ë¡œ ê°„ì£¼
                center_y, center_x = height // 2, width // 2
                mask[center_y-100:center_y+100, center_x-80:center_x+80] = 1
                
                confidence = 0.6
            
            self.logger.info(f"âœ… ì „í†µì  ì„¸ê·¸ë©˜í…Œì´ì…˜ ì™„ë£Œ - ì‹ ë¢°ë„: {confidence:.3f}")
            return mask, confidence
            
        except Exception as e:
            self.logger.error(f"âŒ ì „í†µì  ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‹¤íŒ¨: {e}")
            return None, 0.0

    def _post_process_mask(self, mask, quality):
        """ë§ˆìŠ¤í¬ í›„ì²˜ë¦¬ (ë™ê¸°) - ì™„ì „í•œ êµ¬í˜„"""
        try:
            processed_mask = mask.copy()
            
            if self.segmentation_config.remove_noise:
                # ë…¸ì´ì¦ˆ ì œê±°
                kernel_size = 'small' if quality == QualityLevel.FAST else 'medium'
                if hasattr(self, 'morphology_kernels') and kernel_size in self.morphology_kernels:
                    kernel = self.morphology_kernels[kernel_size]
                    processed_mask = cv2.morphologyEx(processed_mask, cv2.MORPH_OPEN, kernel)
                    processed_mask = cv2.morphologyEx(processed_mask, cv2.MORPH_CLOSE, kernel)
            
            if self.segmentation_config.edge_smoothing:
                # ì—£ì§€ ìŠ¤ë¬´ë”©
                processed_mask = cv2.GaussianBlur(processed_mask.astype(np.float32), (3, 3), 0.5)
                processed_mask = (processed_mask > 0.5).astype(np.uint8)
            
            # í™€ ì±„ìš°ê¸°
            if self.segmentation_config.enable_hole_filling:
                processed_mask = self._fill_holes(processed_mask)
            
            # ê²½ê³„ ê°œì„ 
            if self.segmentation_config.enable_edge_refinement:
                processed_mask = self._refine_edges(processed_mask)
            
            return processed_mask
        except Exception as e:
            self.logger.warning(f"ë§ˆìŠ¤í¬ í›„ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return mask

    def _fill_holes(self, mask: np.ndarray) -> np.ndarray:
        """ë§ˆìŠ¤í¬ ë‚´ë¶€ í™€ ì±„ìš°ê¸°"""
        try:
            # ìœ¤ê³½ì„  ê¸°ë°˜ í™€ ì±„ìš°ê¸°
            contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            filled_mask = np.zeros_like(mask)
            for contour in contours:
                cv2.fillPoly(filled_mask, [contour], 1)
            return filled_mask
        except Exception as e:
            self.logger.warning(f"í™€ ì±„ìš°ê¸° ì‹¤íŒ¨: {e}")
            return mask

    def _refine_edges(self, mask: np.ndarray) -> np.ndarray:
        """ê²½ê³„ ê°œì„ """
        try:
            # ê°€ìš°ì‹œì•ˆ ë¸”ëŸ¬ë¥¼ ì‚¬ìš©í•œ ê²½ê³„ ë¶€ë“œëŸ½ê²Œ
            if self.segmentation_config.enable_edge_refinement:
                # ê²½ê³„ ê²€ì¶œ
                edges = cv2.Canny(mask, 50, 150)
                
                # ê²½ê³„ ì£¼ë³€ ì˜ì—­ í™•ì¥
                kernel = np.ones((5, 5), np.uint8)
                edge_region = cv2.dilate(edges, kernel, iterations=1)
                
                # í•´ë‹¹ ì˜ì—­ì— ê°€ìš°ì‹œì•ˆ ë¸”ëŸ¬ ì ìš©
                blurred_mask = cv2.GaussianBlur(mask.astype(np.float32), (5, 5), 1.0)
                
                # ê²½ê³„ ì˜ì—­ë§Œ ë¸”ëŸ¬ëœ ê°’ìœ¼ë¡œ êµì²´
                refined_mask = mask.copy().astype(np.float32)
                refined_mask[edge_region > 0] = blurred_mask[edge_region > 0]
                
                return (refined_mask > 0.5).astype(np.uint8)
            
            return mask
            
        except Exception as e:
            self.logger.warning(f"ê²½ê³„ ê°œì„  ì‹¤íŒ¨: {e}")
            return mask

    def _get_target_size(self, quality: QualityLevel) -> Tuple[int, int]:
        """í’ˆì§ˆ ë ˆë²¨ë³„ íƒ€ê²Ÿ í¬ê¸° ë°˜í™˜"""
        size_map = {
            QualityLevel.FAST: (256, 256),
            QualityLevel.BALANCED: (512, 512),
            QualityLevel.HIGH: (768, 768),
            QualityLevel.ULTRA: (1024, 1024)
        }
        return size_map.get(quality, (512, 512))

    def _convert_result_to_dict(self, result: SegmentationResult) -> Dict[str, Any]:
        """SegmentationResultë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜"""
        try:
            result_dict = {
                'success': result.success,
                'confidence': result.confidence_score,
                'clothing_type': result.clothing_type.value if hasattr(result, 'clothing_type') else 'unknown',
                'method_used': result.method_used,
                'processing_time': result.processing_time,
                'metadata': result.metadata
            }
            
            # ì´ë¯¸ì§€ë“¤ì„ Base64ë¡œ ì¸ì½”ë”©
            if result.mask is not None:
                mask_image = Image.fromarray((result.mask * 255).astype(np.uint8))
                result_dict['mask_base64'] = self._image_to_base64(mask_image)
            
            if result.visualization_image:
                result_dict['visualization_base64'] = self._image_to_base64(result.visualization_image)
            
            if result.overlay_image:
                result_dict['overlay_base64'] = self._image_to_base64(result.overlay_image)
            
            if result.mask_image:
                result_dict['mask_image_base64'] = self._image_to_base64(result.mask_image)
            
            if result.boundary_image:
                result_dict['boundary_base64'] = self._image_to_base64(result.boundary_image)
            
            return result_dict
            
        except Exception as e:
            self.logger.warning(f"ê²°ê³¼ ë³€í™˜ ì‹¤íŒ¨: {e}")
            return {'success': False, 'error': str(e)}
        """ì‹œê°í™” ì´ë¯¸ì§€ ìƒì„± - 2ë²ˆ íŒŒì¼ ë°©ì‹ ìœ ì§€"""
        try:
            visualizations = {}
            
            # ìƒ‰ìƒ ì„ íƒ
            color = CLOTHING_COLORS.get(
                clothing_type.value if hasattr(clothing_type, 'value') else str(clothing_type), 
                CLOTHING_COLORS['unknown']
            )
            
            # 1. ë§ˆìŠ¤í¬ ì´ë¯¸ì§€ (ìƒ‰ìƒ êµ¬ë¶„)
            mask_colored = np.zeros((*mask.shape, 3), dtype=np.uint8)
            mask_colored[mask > 0] = color
            visualizations['mask'] = Image.fromarray(mask_colored)
            
            # 2. ì˜¤ë²„ë ˆì´ ì´ë¯¸ì§€
            image_array = np.array(image)
            overlay = image_array.copy()
            alpha = 0.5
            overlay[mask > 0] = (
                overlay[mask > 0] * (1 - alpha) + 
                np.array(color) * alpha
            ).astype(np.uint8)
            visualizations['overlay'] = Image.fromarray(overlay)
            
            # 3. ê²½ê³„ì„  ì´ë¯¸ì§€
            boundary = cv2.Canny((mask * 255).astype(np.uint8), 50, 150)
            boundary_colored = np.zeros((*boundary.shape, 3), dtype=np.uint8)
            boundary_colored[boundary > 0] = (255, 255, 255)  # í°ìƒ‰ ê²½ê³„ì„ 
            
            # ì›ë³¸ ì´ë¯¸ì§€ì™€ í•©ì„±
            boundary_overlay = image_array.copy()
            boundary_overlay[boundary > 0] = (255, 255, 255)
            visualizations['boundary'] = Image.fromarray(boundary_overlay)
            
            # 4. ì¢…í•© ì‹œê°í™” ì´ë¯¸ì§€ (ì •ë³´ í¬í•¨)
            visualization = self._create_comprehensive_visualization(
                image, mask, clothing_type, color
            )
            visualizations['visualization'] = visualization
            
            return visualizations
            
        except Exception as e:
            self.logger.warning(f"ì‹œê°í™” ìƒì„± ì‹¤íŒ¨: {e}")
            return {}

    def _create_comprehensive_visualization(self, image, mask, clothing_type, color):
        """ì¢…í•© ì‹œê°í™” ì´ë¯¸ì§€ ìƒì„±"""
        try:
            # ìº”ë²„ìŠ¤ ìƒì„± (ì›ë³¸ + ì •ë³´ ì˜ì—­)
            width, height = image.size
            canvas_width = width * 2 + 20
            canvas_height = height + 60
            
            canvas = Image.new('RGB', (canvas_width, canvas_height), (240, 240, 240))
            
            # ì›ë³¸ ì´ë¯¸ì§€ ë°°ì¹˜
            canvas.paste(image, (10, 30))
            
            # ë§ˆìŠ¤í¬ ì˜¤ë²„ë ˆì´ ì´ë¯¸ì§€ ìƒì„±
            image_array = np.array(image)
            overlay = image_array.copy()
            alpha = 0.6
            overlay[mask > 0] = (
                overlay[mask > 0] * (1 - alpha) + 
                np.array(color) * alpha
            ).astype(np.uint8)
            
            # ê²½ê³„ì„  ì¶”ê°€
            boundary = cv2.Canny((mask * 255).astype(np.uint8), 50, 150)
            overlay[boundary > 0] = (255, 255, 255)
            
            overlay_image = Image.fromarray(overlay)
            canvas.paste(overlay_image, (width + 20, 30))
            
            # í…ìŠ¤íŠ¸ ì •ë³´ ì¶”ê°€
            if hasattr(self, 'font') and self.font:
                draw = ImageDraw.Draw(canvas)
                
                # ì œëª©
                draw.text((10, 5), "Original", fill=(0, 0, 0), font=self.font)
                clothing_type_str = clothing_type.value if hasattr(clothing_type, 'value') else str(clothing_type)
                draw.text((width + 20, 5), f"Segmented ({clothing_type_str})", 
                         fill=(0, 0, 0), font=self.font)
                
                # í†µê³„ ì •ë³´
                mask_area = np.sum(mask)
                total_area = mask.size
                coverage = (mask_area / total_area) * 100
                
                info_text = f"Coverage: {coverage:.1f}% | Type: {clothing_type_str}"
                draw.text((10, height + 35), info_text, fill=(0, 0, 0), font=self.font)
            
            return canvas
            
        except Exception as e:
            self.logger.warning(f"ì¢…í•© ì‹œê°í™” ìƒì„± ì‹¤íŒ¨: {e}")
            return image

    def _get_current_method(self):
        """í˜„ì¬ ì‚¬ìš©ëœ ë°©ë²• ë°˜í™˜ - 1ë²ˆ íŒŒì¼ ë°©ì‹"""
        if self.models_loaded.get('u2net'):
            return 'u2net_modelloader'
        elif self.rembg_sessions:
            return 'rembg'
        else:
            return 'traditional'

    def _image_to_base64(self, image):
        """ì´ë¯¸ì§€ë¥¼ Base64ë¡œ ì¸ì½”ë”©"""
        try:
            buffer = BytesIO()
            if isinstance(image, Image.Image):
                image.save(buffer, format='PNG')
            else:
                # numpy arrayì¸ ê²½ìš°
                img = Image.fromarray(image)
                img.save(buffer, format='PNG')
            image_data = buffer.getvalue()
            return base64.b64encode(image_data).decode()
        except Exception as e:
            self.logger.warning(f"Base64 ì¸ì½”ë”© ì‹¤íŒ¨: {e}")
            return ""

    def _create_error_result(self, error_message: str) -> Dict[str, Any]:
        """ì—ëŸ¬ ê²°ê³¼ ìƒì„± - 1ë²ˆ íŒŒì¼ ë°©ì‹"""
        return {
            'success': False,
            'error': error_message,
            'mask': None,
            'confidence': 0.0,
            'processing_time': 0.0,
            'method_used': 'error'
        }

    def _update_processing_stats(self, processing_time: float, success: bool):
        """ì²˜ë¦¬ í†µê³„ ì—…ë°ì´íŠ¸ - 1ë²ˆ íŒŒì¼ ë°©ì‹"""
        try:
            self.processing_stats['total_processed'] += 1
            if success:
                self.processing_stats['successful'] += 1
            else:
                self.processing_stats['failed'] += 1
            
            # í‰ê·  ì‹œê°„ ì—…ë°ì´íŠ¸
            total = self.processing_stats['total_processed']
            current_avg = self.processing_stats['average_time']
            self.processing_stats['average_time'] = (
                (current_avg * (total - 1) + processing_time) / total
            )
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ í†µê³„ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")

    # ==============================================
    # ğŸ”¥ ì¶”ê°€ ê³ ê¸‰ ë©”ì„œë“œë“¤ (2ë²ˆ íŒŒì¼ ìœ ì§€)
    # ==============================================

    async def segment_clothing(self, image, **kwargs):
        """ê¸°ì¡´ í˜¸í™˜ì„± ë©”ì„œë“œ"""
        return await self.process(image, **kwargs)

    def get_segmentation_info(self) -> Dict[str, Any]:
        """ì„¸ê·¸ë©˜í…Œì´ì…˜ ì •ë³´ ë°˜í™˜"""
        return {
            'step_name': self.step_name,
            'device': self.device,
            'is_initialized': self.is_initialized,
            'available_methods': [m.value for m in self.available_methods],
            'loaded_models': list(self.models_loaded.keys()),
            'rembg_sessions': list(self.rembg_sessions.keys()) if hasattr(self, 'rembg_sessions') else [],
            'processing_stats': self.processing_stats.copy(),
            'config': {
                'method': self.segmentation_config.method.value,
                'quality_level': self.segmentation_config.quality_level.value,
                'enable_visualization': self.segmentation_config.enable_visualization,
                'confidence_threshold': self.segmentation_config.confidence_threshold,
                'enable_edge_refinement': self.segmentation_config.enable_edge_refinement,
                'enable_hole_filling': self.segmentation_config.enable_hole_filling,
                'overlay_opacity': self.segmentation_config.overlay_opacity
            }
        }

    def get_segmentation_method_info(self, method_name: str) -> Dict[str, Any]:
        """ì„¸ê·¸ë©˜í…Œì´ì…˜ ë°©ë²•ë³„ ìƒì„¸ ì •ë³´ ë°˜í™˜"""
        method_info = {
            'u2net': {
                'name': 'U2-Net',
                'description': 'Deep learning salient object detection for clothing',
                'quality': 'high',
                'speed': 'medium',
                'accuracy': 'high',
                'requirements': ['pytorch', 'torchvision']
            },
            'rembg': {
                'name': 'Remove Background',
                'description': 'AI-powered background removal tool',
                'quality': 'medium',
                'speed': 'fast',
                'accuracy': 'medium',
                'requirements': ['rembg']
            },
            'sam': {
                'name': 'Segment Anything Model',
                'description': 'Meta\'s universal segmentation model',
                'quality': 'ultra',
                'speed': 'slow',
                'accuracy': 'ultra-high',
                'requirements': ['segment_anything']
            },
            'deeplab': {
                'name': 'DeepLab v3',
                'description': 'Semantic segmentation with transformers',
                'quality': 'high',
                'speed': 'medium',
                'accuracy': 'high',
                'requirements': ['transformers']
            },
            'traditional': {
                'name': 'Traditional CV',
                'description': 'Classical computer vision methods (GrabCut, K-means)',
                'quality': 'medium',
                'speed': 'fast',
                'accuracy': 'medium',
                'requirements': ['opencv', 'scikit-learn']
            },
            'hybrid': {
                'name': 'Hybrid Method',
                'description': 'Combination of multiple segmentation techniques',
                'quality': 'high',
                'speed': 'medium',
                'accuracy': 'high',
                'requirements': ['multiple']
            },
            'auto': {
                'name': 'Auto Selection',
                'description': 'Automatically selects the best method',
                'quality': 'adaptive',
                'speed': 'adaptive',
                'accuracy': 'adaptive',
                'requirements': ['adaptive']
            }
        }
        
        return method_info.get(method_name, {
            'name': 'Unknown',
            'description': 'Unknown segmentation method',
            'quality': 'unknown',
            'speed': 'unknown',
            'accuracy': 'unknown',
            'requirements': []
        })

    def get_clothing_mask(self, mask: np.ndarray, category: str) -> np.ndarray:
        """íŠ¹ì • ì˜ë¥˜ ì¹´í…Œê³ ë¦¬ì˜ í†µí•© ë§ˆìŠ¤í¬ ë°˜í™˜"""
        try:
            # ì˜ë¥˜ ì¹´í…Œê³ ë¦¬ë³„ ë§ˆìŠ¤í¬ ìƒì„±
            if category in ['shirt', 'top', 'sweater']:
                # ìƒì˜ ì¹´í…Œê³ ë¦¬
                return (mask > 128).astype(np.uint8)
            elif category in ['pants', 'skirt', 'bottom']:
                # í•˜ì˜ ì¹´í…Œê³ ë¦¬
                return (mask > 128).astype(np.uint8)
            elif category in ['dress']:
                # ì›í”¼ìŠ¤ ì¹´í…Œê³ ë¦¬
                return (mask > 128).astype(np.uint8)
            elif category in ['jacket', 'coat']:
                # ì•„ìš°í„° ì¹´í…Œê³ ë¦¬
                return (mask > 128).astype(np.uint8)
            else:
                # ê¸°ë³¸ê°’
                return (mask > 128).astype(np.uint8)
        except Exception as e:
            self.logger.warning(f"ì˜ë¥˜ ë§ˆìŠ¤í¬ ìƒì„± ì‹¤íŒ¨: {e}")
            return np.zeros_like(mask, dtype=np.uint8)

    def visualize_segmentation(self, mask: np.ndarray, clothing_type: str = "shirt") -> np.ndarray:
        """ì„¸ê·¸ë©˜í…Œì´ì…˜ ê²°ê³¼ ì‹œê°í™” (ë””ë²„ê¹…ìš©)"""
        try:
            # ì˜ë¥˜ íƒ€ì…ì— ë”°ë¥¸ ìƒ‰ìƒ ì„ íƒ
            color = CLOTHING_COLORS.get(clothing_type, CLOTHING_COLORS['unknown'])
            
            # 3ì±„ë„ ìƒ‰ìƒ ì´ë¯¸ì§€ ìƒì„±
            height, width = mask.shape
            colored_image = np.zeros((height, width, 3), dtype=np.uint8)
            colored_image[mask > 0] = color
            
            return colored_image
            
        except Exception as e:
            self.logger.warning(f"ì‹œê°í™” ìƒì„± ì‹¤íŒ¨: {e}")
            return np.zeros((mask.shape[0], mask.shape[1], 3), dtype=np.uint8)

    def get_mask_statistics(self, mask: np.ndarray) -> Dict[str, float]:
        """ë§ˆìŠ¤í¬ í†µê³„ ì •ë³´ ë°˜í™˜"""
        try:
            total_pixels = mask.size
            mask_pixels = np.sum(mask > 0)
            coverage_ratio = mask_pixels / total_pixels
            
            # ì—°ê²° ì˜ì—­ ë¶„ì„
            contours, _ = cv2.findContours(
                (mask > 0).astype(np.uint8), 
                cv2.RETR_EXTERNAL, 
                cv2.CHAIN_APPROX_SIMPLE
            )
            
            num_regions = len(contours)
            largest_area = max([cv2.contourArea(c) for c in contours]) if contours else 0
            
            return {
                'coverage_ratio': coverage_ratio,
                'mask_pixels': int(mask_pixels),
                'total_pixels': int(total_pixels),
                'num_regions': num_regions,
                'largest_region_area': largest_area,
                'fragmentation_score': num_regions / max(1, coverage_ratio * 100)
            }
            
        except Exception as e:
            self.logger.warning(f"ë§ˆìŠ¤í¬ í†µê³„ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return {
                'coverage_ratio': 0.0,
                'mask_pixels': 0,
                'total_pixels': mask.size,
                'num_regions': 0,
                'largest_region_area': 0,
                'fragmentation_score': 0.0
            }

    # ==============================================
    # ğŸ”¥ ì •ë¦¬ ë©”ì„œë“œ (1ë²ˆ íŒŒì¼ ë°©ì‹)
    # ==============================================
    
    async def cleanup(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬ (ë¹„ë™ê¸°) - 1ë²ˆ íŒŒì¼ ë°©ì‹"""
        try:
            self.logger.info("ğŸ§¹ ClothSegmentationStep ì •ë¦¬ ì‹œì‘...")
            
            # ëª¨ë¸ ì •ë¦¬
            for model_name, model in self.models_loaded.items():
                try:
                    if hasattr(model, 'cpu'):
                        model.cpu()
                    del model
                except Exception as e:
                    self.logger.warning(f"âš ï¸ ëª¨ë¸ {model_name} ì •ë¦¬ ì‹¤íŒ¨: {e}")
            
            self.models_loaded.clear()
            
            # RemBG ì„¸ì…˜ ì •ë¦¬
            if hasattr(self, 'rembg_sessions'):
                self.rembg_sessions.clear()
            
            # ìºì‹œ ì •ë¦¬
            if hasattr(self, 'segmentation_cache'):
                self.segmentation_cache.clear()
            
            # ì‹¤í–‰ì ì •ë¦¬
            if hasattr(self, 'executor'):
                self.executor.shutdown(wait=False)
            
            # GPU ë©”ëª¨ë¦¬ ì •ë¦¬
            if self.device == "mps" and torch.backends.mps.is_available():
                torch.mps.empty_cache()
            elif self.device == "cuda" and torch.cuda.is_available():
                torch.cuda.empty_cache()
            
            # ê°€ë¹„ì§€ ì»¬ë ‰ì…˜
            gc.collect()
            
            self.is_initialized = False
            self.logger.info("âœ… ClothSegmentationStep ì •ë¦¬ ì™„ë£Œ")
            
        except Exception as e:
            self.logger.error(f"âŒ ì •ë¦¬ ì‹¤íŒ¨: {e}")

    def __del__(self):
        """ì†Œë©¸ì"""
        try:
            if hasattr(self, 'executor'):
                self.executor.shutdown(wait=False)
        except Exception:
            pass

# ==============================================
# 5. íŒ©í† ë¦¬ í•¨ìˆ˜ë“¤ (ê¸°ì¡´ ì´ë¦„ ìœ ì§€) - 2ë²ˆ íŒŒì¼ ìœ ì§€
# ==============================================

def create_cloth_segmentation_step(
    device: Optional[str] = None,
    config: Optional[Dict[str, Any]] = None,
    **kwargs
) -> ClothSegmentationStep:
    """ClothSegmentationStep íŒ©í† ë¦¬ í•¨ìˆ˜"""
    return ClothSegmentationStep(device=device, config=config, **kwargs)

async def create_and_initialize_cloth_segmentation_step(
    device: str = "auto",
    config: Optional[Dict[str, Any]] = None,
    **kwargs
) -> ClothSegmentationStep:
    """ClothSegmentationStep ìƒì„± ë° ì´ˆê¸°í™”"""
    step = ClothSegmentationStep(device=device, config=config, **kwargs)
    await step.initialize()
    return step

def create_m3_max_segmentation_step(
    config: Optional[Dict[str, Any]] = None,
    **kwargs
) -> ClothSegmentationStep:
    """M3 Max ìµœì í™”ëœ ClothSegmentationStep ìƒì„±"""
    m3_config = {
        'method': SegmentationMethod.AUTO,
        'quality_level': QualityLevel.HIGH,
        'use_fp16': True,
        'batch_size': 8,  # M3 Max 128GB í™œìš©
        'cache_size': 200,
        'enable_visualization': True,
        'visualization_quality': 'high',
        'enable_edge_refinement': True,
        'enable_hole_filling': True
    }
    
    if config:
        m3_config.update(config)
    
    return ClothSegmentationStep(device="mps", config=m3_config, **kwargs)

def create_production_segmentation_step(
    device: Optional[str] = None,
    **kwargs
) -> ClothSegmentationStep:
    """í”„ë¡œë•ì…˜ í™˜ê²½ìš© ClothSegmentationStep ìƒì„±"""
    production_config = {
        'method': SegmentationMethod.AUTO,  # ì•ˆì •ì„± ìš°ì„ 
        'quality_level': QualityLevel.BALANCED,
        'enable_visualization': True,
        'enable_post_processing': True,
        'confidence_threshold': 0.7,
        'visualization_quality': 'medium',
        'enable_edge_refinement': True,
        'enable_hole_filling': True
    }
    
    return ClothSegmentationStep(device=device, config=production_config, **kwargs)

# ==============================================
# 6. ëª¨ë“ˆ ìµìŠ¤í¬íŠ¸ - ê¸°ì¡´ ì´ë¦„ ìœ ì§€
# ==============================================

__all__ = [
    # ë©”ì¸ í´ë˜ìŠ¤
    'ClothSegmentationStep',
    
    # ì—´ê±°í˜• ë° ë°ì´í„° í´ë˜ìŠ¤
    'SegmentationMethod',
    'ClothingType', 
    'QualityLevel',
    'SegmentationConfig',
    'SegmentationResult',
    
    # AI ëª¨ë¸ í´ë˜ìŠ¤ë“¤ (í´ë°±ìš©)
    'U2NET',
    'REBNCONV',
    'RSU7',
    
    # íŒ©í† ë¦¬ í•¨ìˆ˜ë“¤
    'create_cloth_segmentation_step',
    'create_and_initialize_cloth_segmentation_step',
    'create_m3_max_segmentation_step',
    'create_production_segmentation_step',
    
    # ì‹œê°í™” ê´€ë ¨
    'CLOTHING_COLORS'
]

# ëª¨ë“ˆ ì´ˆê¸°í™” ë¡œê¹…
logger.info("âœ… Step 03 ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ + ì‹œê°í™” ëª¨ë“ˆ ì™„ì „ êµ¬í˜„ ì™„ë£Œ")
logger.info(f"   - BaseStepMixin ì—°ë™: {'âœ…' if BASE_STEP_MIXIN_AVAILABLE else 'âš ï¸ í´ë°±'}")
logger.info(f"   - Model Loader ì—°ë™: {'âœ…' if MODEL_LOADER_AVAILABLE else 'âŒ'}")
logger.info(f"   - Memory Manager ì—°ë™: {'âœ…' if MEMORY_MANAGER_AVAILABLE else 'âŒ'}")
logger.info(f"   - RemBG ì‚¬ìš© ê°€ëŠ¥: {'âœ…' if REMBG_AVAILABLE else 'âŒ'}")
logger.info(f"   - SAM ì‚¬ìš© ê°€ëŠ¥: {'âœ…' if SAM_AVAILABLE else 'âŒ'}")
logger.info(f"   - Transformers ì‚¬ìš© ê°€ëŠ¥: {'âœ…' if TRANSFORMERS_AVAILABLE else 'âŒ'}")
logger.info(f"   - scikit-learn ì‚¬ìš© ê°€ëŠ¥: {'âœ…' if SKLEARN_AVAILABLE else 'âŒ'}")
logger.info("ğŸ”¥ ìˆœí™˜ì°¸ì¡° ì™„ì „ í•´ê²°, í•œë°©í–¥ ì°¸ì¡° êµ¬ì¡° êµ¬í˜„")
logger.info("ğŸ¨ ì™„ì „í•œ ì‹œê°í™”: ìƒ‰ìƒí™”, ì˜¤ë²„ë ˆì´, ë§ˆìŠ¤í¬, ê²½ê³„ì„ , ì¢…í•©")
logger.info("ğŸš€ 8ê°€ì§€ ë°©ë²•: U2NET, RemBG, SAM, DeepLab, Traditional, Hybrid, AUTO")
logger.info("ğŸ”§ ê³ ê¸‰ í›„ì²˜ë¦¬: ê²½ê³„ ê°œì„ , í™€ ì±„ìš°ê¸°, í˜•íƒœí•™ì  ì²˜ë¦¬")
logger.info("ğŸ M3 Max ìµœì í™”: ì›Œë°ì—…, ë©”ëª¨ë¦¬ ê´€ë¦¬, Neural Engine")
logger.info("ğŸ—ï¸ í”„ë¡œë•ì…˜ ì•ˆì •ì„±: ìºì‹œ, í†µê³„, í´ë°±, ì—ëŸ¬ ì²˜ë¦¬")
logger.info("âœ… 1ë²ˆ íŒŒì¼ì˜ await expression ì˜¤ë¥˜ ì™„ì „ í•´ê²° ì ìš©")

# ==============================================
# 7. í…ŒìŠ¤íŠ¸ ë° ì˜ˆì‹œ í•¨ìˆ˜ë“¤ - 2ë²ˆ íŒŒì¼ ìœ ì§€
# ==============================================

async def test_cloth_segmentation_complete():
    """ì™„ì „í•œ ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ í…ŒìŠ¤íŠ¸"""
    print("ğŸ§ª ì™„ì „í•œ ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    
    try:
        # Step ìƒì„±
        step = create_cloth_segmentation_step(
            device="auto",
            config={
                "method": "auto",
                "enable_visualization": True,
                "visualization_quality": "high",
                "quality_level": "balanced"
            }
        )
        
        # ì´ˆê¸°í™”
        await step.initialize()
        
        # ë”ë¯¸ ì´ë¯¸ì§€ ìƒì„±
        dummy_image = Image.new('RGB', (512, 512), (200, 150, 100))
        
        # ì²˜ë¦¬ ì‹¤í–‰
        result = await step.process(dummy_image, clothing_type="shirt", quality_level="high")
        
        # ê²°ê³¼ í™•ì¸
        if result['success']:
            print("âœ… ì²˜ë¦¬ ì„±ê³µ!")
            print(f"   - ì˜ë¥˜ íƒ€ì…: {result['clothing_type']}")
            print(f"   - ì‹ ë¢°ë„: {result['confidence']:.3f}")
            print(f"   - ì²˜ë¦¬ ì‹œê°„: {result['processing_time']:.2f}ì´ˆ")
            print(f"   - ì‚¬ìš© ë°©ë²•: {result['method_used']}")
            
            if 'visualization_base64' in result:
                print("   - ì‹œê°í™” ì´ë¯¸ì§€ ìƒì„±ë¨")
            if 'overlay_base64' in result:
                print("   - ì˜¤ë²„ë ˆì´ ì´ë¯¸ì§€ ìƒì„±ë¨")
        else:
            print(f"âŒ ì²˜ë¦¬ ì‹¤íŒ¨: {result.get('error', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}")
        
        # ì •ë³´ ì¶œë ¥
        info = step.get_segmentation_info()
        print(f"\nğŸ“Š ì‹œìŠ¤í…œ ì •ë³´:")
        print(f"   - ë””ë°”ì´ìŠ¤: {info['device']}")
        print(f"   - ì‚¬ìš© ê°€ëŠ¥í•œ ë°©ë²•: {info['available_methods']}")
        print(f"   - ë¡œë“œëœ ëª¨ë¸: {info['loaded_models']}")
        
        # ì •ë¦¬
        await step.cleanup()
        print("âœ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ ë° ì •ë¦¬")
        
    except Exception as e:
        print(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")

def example_usage():
    """ì‚¬ìš© ì˜ˆì‹œ"""
    print("ğŸ”¥ MyCloset AI Step 03 - ì™„ì „í•œ ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‚¬ìš© ì˜ˆì‹œ")
    print("=" * 70)
    
    print("""
# 1. ê¸°ë³¸ ì‚¬ìš©ë²• (8ê°€ì§€ ë°©ë²• ì§€ì›)
from app.ai_pipeline.steps.step_03_cloth_segmentation import create_cloth_segmentation_step

# AUTO ë°©ë²• (ìµœì  ì„ íƒ)
step = create_cloth_segmentation_step(device="mps", config={"method": "auto"})

# ì´ˆê¸°í™”
await step.initialize()

# ì´ë¯¸ì§€ ì²˜ë¦¬ (ì™„ì „í•œ ì‹œê°í™” í¬í•¨)
result = await step.process(image, clothing_type="shirt", quality_level="high")

# 2. M3 Max ìµœì í™” ë²„ì „ (128GB í™œìš©)
step = create_m3_max_segmentation_step({
    "quality_level": "ultra",
    "enable_visualization": True,
    "enable_edge_refinement": True,
    "enable_hole_filling": True
})

# 3. í”„ë¡œë•ì…˜ ë²„ì „ (ì•ˆì •ì„± + ì„±ëŠ¥ ìµœì í™”)
step = create_production_segmentation_step(device="cpu")

# 4. ê³ ê¸‰ ì„¤ì • (ëª¨ë“  ê¸°ëŠ¥ í™œìš©)
config = {
    "method": "hybrid",          # í•˜ì´ë¸Œë¦¬ë“œ ë°©ë²•
    "quality_level": "ultra",    # ìµœê³  í’ˆì§ˆ
    "confidence_threshold": 0.8,
    "enable_visualization": True,
    "enable_edge_refinement": True,
    "enable_hole_filling": True,
    "overlay_opacity": 0.6
}
step = create_cloth_segmentation_step(config=config)

# 5. ì™„ì „í•œ ê²°ê³¼ í™œìš©
if result['success']:
    # 4ê°€ì§€ ì‹œê°í™” ì´ë¯¸ì§€
    visualization = result['visualization_base64']  # ì¢…í•© ì‹œê°í™”
    overlay = result['overlay_base64']              # ì˜¤ë²„ë ˆì´
    mask = result['mask_base64']                    # ë§ˆìŠ¤í¬
    boundary = result['boundary_base64']            # ê²½ê³„ì„ 
    
    # ë©”íƒ€ë°ì´í„° ë° í†µê³„
    clothing_type = result['clothing_type']
    confidence = result['confidence']
    processing_time = result['processing_time']
    method_used = result['method_used']

# 6. ê³ ê¸‰ ê¸°ëŠ¥ë“¤
# ë°©ë²•ë³„ ìƒì„¸ ì •ë³´
method_info = step.get_segmentation_method_info("hybrid")
print(f"í•˜ì´ë¸Œë¦¬ë“œ ë°©ë²•: {method_info}")

# ì˜ë¥˜ë³„ ë§ˆìŠ¤í¬ ìƒì„±
clothing_mask = step.get_clothing_mask(result['mask'], "shirt")

# ë§ˆìŠ¤í¬ í†µê³„ ë¶„ì„
stats = step.get_mask_statistics(result['mask'])
print(f"ì»¤ë²„ë¦¬ì§€: {stats['coverage_ratio']:.2%}")

# ë””ë²„ê¹…ìš© ì‹œê°í™”
debug_viz = step.visualize_segmentation(result['mask'], "shirt")

# ì‹œìŠ¤í…œ ì •ë³´ ì¡°íšŒ
info = step.get_segmentation_info()
print(f"ì‚¬ìš© ê°€ëŠ¥í•œ ë°©ë²•: {info['available_methods']}")
print(f"ì²˜ë¦¬ í†µê³„: {info['processing_stats']}")

# ë¦¬ì†ŒìŠ¤ ì •ë¦¬
await step.cleanup()
""")

if __name__ == "__main__":
    """ì§ì ‘ ì‹¤í–‰ ì‹œ í…ŒìŠ¤íŠ¸"""
    print("ğŸ”¥ Step 03 ì™„ì „í•œ ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ - ì§ì ‘ ì‹¤í–‰ í…ŒìŠ¤íŠ¸")
    
    # ì˜ˆì‹œ ì¶œë ¥
    example_usage()
    
    # ì‹¤ì œ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ (ë¹„ë™ê¸°)
    import asyncio
    try:
        asyncio.run(test_cloth_segmentation_complete())
    except Exception as e:
        print(f"âŒ ë¹„ë™ê¸° í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
        print("ğŸ’¡ Jupyter í™˜ê²½ì—ì„œëŠ” 'await test_cloth_segmentation_complete()' ì‚¬ìš©")

# ==============================================
# 8. conda í™˜ê²½ ì„¤ì • ê°€ì´ë“œ
# ==============================================

def print_conda_setup_guide():
    """conda í™˜ê²½ ì„¤ì • ê°€ì´ë“œ"""
    print("""
ğŸ MyCloset AI - conda í™˜ê²½ ì„¤ì • ê°€ì´ë“œ

# 1. conda í™˜ê²½ ìƒì„±
conda create -n mycloset-ai python=3.9 -y
conda activate mycloset-ai

# 2. ê¸°ë³¸ íŒ¨í‚¤ì§€ ì„¤ì¹˜
conda install -c conda-forge opencv numpy pillow -y
conda install -c pytorch pytorch torchvision torchaudio -y

# 3. ì„ íƒì  AI ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜
pip install rembg segment-anything transformers
pip install scikit-learn psutil ultralytics

# 4. M3 Max ìµœì í™” (macOS)
conda install -c conda-forge accelerate -y

# 5. í™˜ê²½ í™œì„±í™” í™•ì¸
python -c "import torch; print(f'PyTorch: {torch.__version__}')"
python -c "import cv2; print(f'OpenCV: {cv2.__version__}')"

# 6. ì‹¤í–‰
cd backend
python -m app.ai_pipeline.steps.step_03_cloth_segmentation
""")

# ì¶”ê°€: conda ê°€ì´ë“œ í•¨ìˆ˜ export
__all__.append('print_conda_setup_guide')