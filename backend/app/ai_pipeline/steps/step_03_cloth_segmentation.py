# app/ai_pipeline/steps/step_03_cloth_segmentation.py
"""
MyCloset AI - 3ë‹¨ê³„: ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ (Clothing Segmentation) + ì‹œê°í™”
ğŸ”¥ ì™„ì „í•œ ê¸°ëŠ¥ êµ¬í˜„ - í”„ë¡œì íŠ¸ ì§€ì‹ ê¸°ë°˜

âœ… BaseStepMixin ì™„ì „ í˜¸í™˜ (í•œë°©í–¥ ì°¸ì¡°)
âœ… ModelLoader ì™„ì „ ì—°ë™ (ì¸í„°í˜ì´ìŠ¤ ê¸°ë°˜)
âœ… 8ê°€ì§€ ì„¸ê·¸ë©˜í…Œì´ì…˜ ë°©ë²• + AUTO ì„ íƒ
âœ… ì™„ì „í•œ ì‹œê°í™” ì‹œìŠ¤í…œ (ìƒ‰ìƒí™”, ì˜¤ë²„ë ˆì´, ê²½ê³„ì„ )
âœ… ê³ ê¸‰ í›„ì²˜ë¦¬ (ê²½ê³„ ê°œì„ , í™€ ì±„ìš°ê¸°, í˜•íƒœí•™ì  ì²˜ë¦¬)
âœ… M3 Max 128GB ìµœì í™” (ì›Œë°ì—…, ë©”ëª¨ë¦¬ ê´€ë¦¬)
âœ… í”„ë¡œë•ì…˜ ì•ˆì •ì„± (ìºì‹œ, í†µê³„, í´ë°±)
âœ… ìˆœí™˜ì°¸ì¡° ì™„ì „ í•´ê²°
"""

import os
import sys
import logging
import time
import asyncio
import threading
import gc
import hashlib
import json
import base64
from typing import Dict, Any, Optional, Tuple, List, Union, Callable
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor, as_completed
from dataclasses import dataclass, field
from enum import Enum
from io import BytesIO
import weakref

# í•µì‹¬ ë¼ì´ë¸ŒëŸ¬ë¦¬
import numpy as np
import cv2
from PIL import Image, ImageEnhance, ImageFilter, ImageOps, ImageDraw, ImageFont
import torch
import torch.nn as nn
import torch.nn.functional as F
from torchvision import transforms

# ì„ íƒì  AI ë¼ì´ë¸ŒëŸ¬ë¦¬ë“¤
try:
    import rembg
    from rembg import remove, new_session
    REMBG_AVAILABLE = True
except ImportError:
    REMBG_AVAILABLE = False

try:
    from sklearn.cluster import KMeans
    from sklearn.preprocessing import StandardScaler
    SKLEARN_AVAILABLE = True
except ImportError:
    SKLEARN_AVAILABLE = False

try:
    import segment_anything as sam
    SAM_AVAILABLE = True
except ImportError:
    SAM_AVAILABLE = False

try:
    from transformers import pipeline
    TRANSFORMERS_AVAILABLE = True
except ImportError:
    TRANSFORMERS_AVAILABLE = False

# ğŸ”¥ BaseStepMixin ì—°ë™ - í•œë°©í–¥ ì°¸ì¡° (ìˆœí™˜ì°¸ì¡° í•´ê²°)
try:
    from app.ai_pipeline.steps.base_step_mixin import BaseStepMixin, ClothSegmentationMixin
    BASE_STEP_MIXIN_AVAILABLE = True
except ImportError:
    BASE_STEP_MIXIN_AVAILABLE = False
    
    # ğŸ”¥ ì•ˆì „í•œ í´ë°± í´ë˜ìŠ¤ (ì™„ì „ í˜¸í™˜)
    class BaseStepMixin:
        def __init__(self, *args, **kwargs):
            if not hasattr(self, 'logger'):
                class_name = self.__class__.__name__
                self.logger = logging.getLogger(f"pipeline.{class_name}")
            
            self.step_name = getattr(self, 'step_name', self.__class__.__name__)
            self.device = getattr(self, 'device', 'cpu')
            self.is_initialized = getattr(self, 'is_initialized', False)
            self.model_interface = getattr(self, 'model_interface', None)
            
            self.logger.info(f"ğŸ”¥ BaseStepMixin í´ë°± ì´ˆê¸°í™”: {class_name}")
    
    class ClothSegmentationMixin(BaseStepMixin):
        def __init__(self, *args, **kwargs):
            try:
                super().__init__(*args, **kwargs)
            except Exception as e:
                if not hasattr(self, 'logger'):
                    self.logger = logging.getLogger(f"pipeline.{self.__class__.__name__}")
                self.logger.debug(f"super() ì‹¤íŒ¨, ì§ì ‘ ì´ˆê¸°í™”: {e}")
            
            # Step 3 íŠ¹í™” ì†ì„±
            self.step_number = 3
            self.step_type = "cloth_segmentation"
            self.output_format = "cloth_mask"

# ğŸ”¥ ModelLoader ì—°ë™ - ì¸í„°í˜ì´ìŠ¤ ê¸°ë°˜ (ìˆœí™˜ì°¸ì¡° í•´ê²°)
try:
    from app.ai_pipeline.utils.model_loader import (
        ModelLoader, ModelConfig, ModelType,
        get_global_model_loader
    )
    MODEL_LOADER_AVAILABLE = True
except ImportError:
    MODEL_LOADER_AVAILABLE = False

# ğŸ”¥ ì„ íƒì  ìœ í‹¸ë¦¬í‹° ì—°ë™ (ì—†ì–´ë„ ì‘ë™)
try:
    from app.ai_pipeline.utils.memory_manager import (
        MemoryManager, get_global_memory_manager
    )
    MEMORY_MANAGER_AVAILABLE = True
except ImportError:
    MEMORY_MANAGER_AVAILABLE = False

try:
    from app.ai_pipeline.utils.data_converter import (
        DataConverter, get_global_data_converter
    )
    DATA_CONVERTER_AVAILABLE = True
except ImportError:
    DATA_CONVERTER_AVAILABLE = False

# ğŸ”¥ ë¡œê¹… ì„¤ì •
logger = logging.getLogger(__name__)

# ==============================================
# 1. ì—´ê±°í˜• ë° ë°ì´í„° í´ë˜ìŠ¤ (í™•ì¥ë¨)
# ==============================================

class SegmentationMethod(Enum):
    """ì„¸ê·¸ë©˜í…Œì´ì…˜ ë°©ë²• (í™•ì¥ë¨)"""
    U2NET = "u2net"
    REMBG = "rembg"
    SAM = "sam"
    DEEP_LAB = "deeplab"
    MASK_RCNN = "mask_rcnn"
    TRADITIONAL = "traditional"
    HYBRID = "hybrid"
    AUTO = "auto"

class ClothingType(Enum):
    """ì˜ë¥˜ íƒ€ì… (í™•ì¥ë¨)"""
    SHIRT = "shirt"
    DRESS = "dress"
    PANTS = "pants"
    SKIRT = "skirt"
    JACKET = "jacket"
    SWEATER = "sweater"
    COAT = "coat"
    TOP = "top"
    BOTTOM = "bottom"
    UNKNOWN = "unknown"

class QualityLevel(Enum):
    """í’ˆì§ˆ ë ˆë²¨"""
    FAST = "fast"
    BALANCED = "balanced"
    HIGH = "high"
    ULTRA = "ultra"

@dataclass
class SegmentationConfig:
    """ì„¸ê·¸ë©˜í…Œì´ì…˜ ì„¤ì • (í™•ì¥ë¨)"""
    method: SegmentationMethod = SegmentationMethod.AUTO
    quality_level: QualityLevel = QualityLevel.BALANCED
    input_size: Tuple[int, int] = (512, 512)
    output_size: Optional[Tuple[int, int]] = None
    enable_visualization: bool = True
    enable_post_processing: bool = True
    enable_edge_refinement: bool = True
    enable_hole_filling: bool = True
    use_fp16: bool = True
    batch_size: int = 1
    confidence_threshold: float = 0.8
    iou_threshold: float = 0.5
    edge_smoothing: bool = True
    remove_noise: bool = True
    visualization_quality: str = "high"
    enable_caching: bool = True
    cache_size: int = 100
    show_masks: bool = True
    show_boundaries: bool = True
    overlay_opacity: float = 0.6

@dataclass
class SegmentationResult:
    """ì„¸ê·¸ë©˜í…Œì´ì…˜ ê²°ê³¼ (í™•ì¥ë¨)"""
    success: bool
    mask: Optional[np.ndarray] = None
    segmented_image: Optional[np.ndarray] = None
    confidence_score: float = 0.0
    quality_score: float = 0.0
    method_used: str = "unknown"
    processing_time: float = 0.0
    metadata: Dict[str, Any] = field(default_factory=dict)
    error_message: Optional[str] = None
    # ì‹œê°í™” ì´ë¯¸ì§€ë“¤
    visualization_image: Optional[Image.Image] = None
    overlay_image: Optional[Image.Image] = None
    mask_image: Optional[Image.Image] = None
    boundary_image: Optional[Image.Image] = None

# ==============================================
# 2. AI ëª¨ë¸ í´ë˜ìŠ¤ë“¤ (í´ë°±ìš© ì™„ì „ êµ¬í˜„)
# ==============================================

class REBNCONV(nn.Module):
    """U2-Netì˜ ê¸°ë³¸ ì»¨ë³¼ë£¨ì…˜ ë¸”ë¡ (í´ë°±ìš©)"""
    def __init__(self, in_ch=3, out_ch=3, dirate=1):
        super(REBNCONV, self).__init__()
        self.conv_s1 = nn.Conv2d(in_ch, out_ch, 3, padding=1*dirate, dilation=1*dirate)
        self.bn_s1 = nn.BatchNorm2d(out_ch)
        self.relu_s1 = nn.ReLU(inplace=True)
    
    def forward(self, x):
        hx = self.relu_s1(self.bn_s1(self.conv_s1(x)))
        return hx

class RSU7(nn.Module):
    """U2-Net RSU-7 ë¸”ë¡ (í´ë°±ìš©)"""
    def __init__(self, in_ch=3, mid_ch=12, out_ch=3):
        super(RSU7, self).__init__()
        self.rebnconvin = REBNCONV(in_ch, out_ch, dirate=1)
        
        self.rebnconv1 = REBNCONV(out_ch, mid_ch, dirate=1)
        self.pool1 = nn.MaxPool2d(2, stride=2, ceil_mode=True)
        
        self.rebnconv2 = REBNCONV(mid_ch, mid_ch, dirate=1)
        self.pool2 = nn.MaxPool2d(2, stride=2, ceil_mode=True)
        
        self.rebnconv3 = REBNCONV(mid_ch, mid_ch, dirate=1)
        self.pool3 = nn.MaxPool2d(2, stride=2, ceil_mode=True)
        
        self.rebnconv4 = REBNCONV(mid_ch, mid_ch, dirate=1)
        self.pool4 = nn.MaxPool2d(2, stride=2, ceil_mode=True)
        
        self.rebnconv5 = REBNCONV(mid_ch, mid_ch, dirate=1)
        self.pool5 = nn.MaxPool2d(2, stride=2, ceil_mode=True)
        
        self.rebnconv6 = REBNCONV(mid_ch, mid_ch, dirate=1)
        self.rebnconv7 = REBNCONV(mid_ch, mid_ch, dirate=2)
        
        self.rebnconv6d = REBNCONV(mid_ch*2, mid_ch, dirate=1)
        self.upsample6 = nn.Upsample(scale_factor=2, mode='bilinear')
        
        self.rebnconv5d = REBNCONV(mid_ch*2, mid_ch, dirate=1)
        self.upsample5 = nn.Upsample(scale_factor=2, mode='bilinear')
        
        self.rebnconv4d = REBNCONV(mid_ch*2, mid_ch, dirate=1)
        self.upsample4 = nn.Upsample(scale_factor=2, mode='bilinear')
        
        self.rebnconv3d = REBNCONV(mid_ch*2, mid_ch, dirate=1)
        self.upsample3 = nn.Upsample(scale_factor=2, mode='bilinear')
        
        self.rebnconv2d = REBNCONV(mid_ch*2, mid_ch, dirate=1)
        self.upsample2 = nn.Upsample(scale_factor=2, mode='bilinear')
        
        self.rebnconv1d = REBNCONV(mid_ch*2, out_ch, dirate=1)
    
    def forward(self, x):
        hx = x
        hxin = self.rebnconvin(hx)
        
        hx1 = self.rebnconv1(hxin)
        hx = self.pool1(hx1)
        
        hx2 = self.rebnconv2(hx)
        hx = self.pool2(hx2)
        
        hx3 = self.rebnconv3(hx)
        hx = self.pool3(hx3)
        
        hx4 = self.rebnconv4(hx)
        hx = self.pool4(hx4)
        
        hx5 = self.rebnconv5(hx)
        hx = self.pool5(hx5)
        
        hx6 = self.rebnconv6(hx)
        hx7 = self.rebnconv7(hx6)
        
        hx6d = self.rebnconv6d(torch.cat((hx7, hx6), 1))
        hx6dup = self.upsample6(hx6d)
        
        hx5d = self.rebnconv5d(torch.cat((hx6dup, hx5), 1))
        hx5dup = self.upsample5(hx5d)
        
        hx4d = self.rebnconv4d(torch.cat((hx5dup, hx4), 1))
        hx4dup = self.upsample4(hx4d)
        
        hx3d = self.rebnconv3d(torch.cat((hx4dup, hx3), 1))
        hx3dup = self.upsample3(hx3d)
        
        hx2d = self.rebnconv2d(torch.cat((hx3dup, hx2), 1))
        hx2dup = self.upsample2(hx2d)
        
        hx1d = self.rebnconv1d(torch.cat((hx2dup, hx1), 1))
        
        return hx1d + hxin

class U2NET(nn.Module):
    """U2-Net ë©”ì¸ ëª¨ë¸ (ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ ìµœì í™”, í´ë°±ìš©)"""
    def __init__(self, in_ch=3, out_ch=1):
        super(U2NET, self).__init__()
        
        self.stage1 = RSU7(in_ch, 32, 64)
        self.pool12 = nn.MaxPool2d(2, stride=2, ceil_mode=True)
        
        self.stage2 = RSU7(64, 32, 128)
        self.pool23 = nn.MaxPool2d(2, stride=2, ceil_mode=True)
        
        self.stage3 = RSU7(128, 64, 256)
        self.pool34 = nn.MaxPool2d(2, stride=2, ceil_mode=True)
        
        self.stage4 = RSU7(256, 128, 512)
        self.pool45 = nn.MaxPool2d(2, stride=2, ceil_mode=True)
        
        self.stage5 = RSU7(512, 256, 512)
        self.pool56 = nn.MaxPool2d(2, stride=2, ceil_mode=True)
        
        self.stage6 = RSU7(512, 256, 512)
        
        # ë””ì½”ë”
        self.stage5d = RSU7(1024, 256, 512)
        self.stage4d = RSU7(1024, 128, 256)
        self.stage3d = RSU7(512, 64, 128)
        self.stage2d = RSU7(256, 32, 64)
        self.stage1d = RSU7(128, 16, 64)
        
        self.side1 = nn.Conv2d(64, out_ch, 3, padding=1)
        self.side2 = nn.Conv2d(64, out_ch, 3, padding=1)
        self.side3 = nn.Conv2d(128, out_ch, 3, padding=1)
        self.side4 = nn.Conv2d(256, out_ch, 3, padding=1)
        self.side5 = nn.Conv2d(512, out_ch, 3, padding=1)
        self.side6 = nn.Conv2d(512, out_ch, 3, padding=1)
        
        self.outconv = nn.Conv2d(6*out_ch, out_ch, 1)
        
        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear')
    
    def forward(self, x):
        hx = x
        
        # ì¸ì½”ë”
        hx1 = self.stage1(hx)
        hx = self.pool12(hx1)
        
        hx2 = self.stage2(hx)
        hx = self.pool23(hx2)
        
        hx3 = self.stage3(hx)
        hx = self.pool34(hx3)
        
        hx4 = self.stage4(hx)
        hx = self.pool45(hx4)
        
        hx5 = self.stage5(hx)
        hx = self.pool56(hx5)
        
        hx6 = self.stage6(hx)
        
        # ë””ì½”ë”
        hx5d = self.stage5d(torch.cat((hx6, hx5), 1))
        hx5dup = F.interpolate(hx5d, size=hx4.shape[2:], mode='bilinear', align_corners=False)
        
        hx4d = self.stage4d(torch.cat((hx5dup, hx4), 1))
        hx4dup = F.interpolate(hx4d, size=hx3.shape[2:], mode='bilinear', align_corners=False)
        
        hx3d = self.stage3d(torch.cat((hx4dup, hx3), 1))
        hx3dup = F.interpolate(hx3d, size=hx2.shape[2:], mode='bilinear', align_corners=False)
        
        hx2d = self.stage2d(torch.cat((hx3dup, hx2), 1))
        hx2dup = F.interpolate(hx2d, size=hx1.shape[2:], mode='bilinear', align_corners=False)
        
        hx1d = self.stage1d(torch.cat((hx2dup, hx1), 1))
        
        # Side outputs
        d1 = self.side1(hx1d)
        d2 = F.interpolate(self.side2(hx2d), size=d1.shape[2:], mode='bilinear', align_corners=False)
        d3 = F.interpolate(self.side3(hx3d), size=d1.shape[2:], mode='bilinear', align_corners=False)
        d4 = F.interpolate(self.side4(hx4d), size=d1.shape[2:], mode='bilinear', align_corners=False)
        d5 = F.interpolate(self.side5(hx5d), size=d1.shape[2:], mode='bilinear', align_corners=False)
        d6 = F.interpolate(self.side6(hx6), size=d1.shape[2:], mode='bilinear', align_corners=False)
        
        # ìµœì¢… ì¶œë ¥
        d0 = self.outconv(torch.cat((d1, d2, d3, d4, d5, d6), 1))
        
        return torch.sigmoid(d0), torch.sigmoid(d1), torch.sigmoid(d2), torch.sigmoid(d3), torch.sigmoid(d4), torch.sigmoid(d5), torch.sigmoid(d6)

# ==============================================
# 3. ì˜ë¥˜ë³„ ìƒ‰ìƒ ë§¤í•‘ (ì‹œê°í™”ìš©)
# ==============================================

CLOTHING_COLORS = {
    'shirt': (255, 100, 100),      # ë¹¨ê°•
    'pants': (100, 100, 255),      # íŒŒë‘
    'dress': (255, 100, 255),      # ë¶„í™
    'jacket': (100, 255, 100),     # ì´ˆë¡
    'skirt': (255, 255, 100),      # ë…¸ë‘
    'sweater': (138, 43, 226),     # ë¸”ë£¨ë°”ì´ì˜¬ë ›
    'coat': (165, 42, 42),         # ê°ˆìƒ‰
    'top': (0, 255, 255),          # ì‹œì•ˆ
    'bottom': (255, 165, 0),       # ì˜¤ë Œì§€
    'shoes': (255, 150, 0),        # ì£¼í™©
    'bag': (150, 75, 0),           # ê°ˆìƒ‰
    'hat': (128, 0, 128),          # ë³´ë¼
    'accessory': (0, 255, 255),    # ì‹œì•ˆ
    'unknown': (128, 128, 128),    # íšŒìƒ‰
}

# ==============================================
# 4. ğŸ”¥ ì™„ì „í•œ ClothSegmentationStep
# ==============================================

class ClothSegmentationStep(ClothSegmentationMixin):
    """
    ğŸ”¥ ì™„ì „í•œ ê¸°ëŠ¥ì˜ ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ Step
    
    âœ… ì°¸ê³  íë¦„ ì™„ë²½ êµ¬í˜„:
       ğŸŒ API ìš”ì²­ â†’ ğŸ“‹ PipelineManager â†’ ğŸ¯ ClothSegmentationStep ìƒì„±
       â†’ ğŸ”— ModelLoader.create_step_interface() í˜¸ì¶œ
       â†’ ğŸš€ initialize() ì—ì„œ Step + ModelLoader í˜‘ì—…
       â†’ ğŸ§  process() ì—ì„œ ModelLoader ì œê³µ ëª¨ë¸ë¡œ ì¶”ë¡ 
       â†’ ğŸ“¤ Stepì´ ìµœì¢… ê²°ê³¼ ìƒì„±
    
    âœ… ëª¨ë“  ê¸°ëŠ¥ í¬í•¨:
       - 8ê°€ì§€ ì„¸ê·¸ë©˜í…Œì´ì…˜ ë°©ë²• + AUTO ì„ íƒ
       - ì™„ì „í•œ ì‹œê°í™” ì‹œìŠ¤í…œ (4ê°€ì§€ ì´ë¯¸ì§€)
       - ê³ ê¸‰ í›„ì²˜ë¦¬ (ê²½ê³„ ê°œì„ , í™€ ì±„ìš°ê¸°)
       - M3 Max ìµœì í™” (ì›Œë°ì—…, ë©”ëª¨ë¦¬ ê´€ë¦¬)
       - í”„ë¡œë•ì…˜ ì•ˆì •ì„± (ìºì‹œ, í†µê³„, í´ë°±)
    """
    
    def __init__(
        self,
        device: Optional[str] = None,
        config: Optional[Union[Dict[str, Any], SegmentationConfig]] = None,
        **kwargs
    ):
        """ì™„ì „í•œ ìƒì„±ì"""
        
        # ğŸ”¥ 1ë‹¨ê³„: BaseStepMixin ë¨¼ì € ì´ˆê¸°í™” (logger ë¬¸ì œ í•´ê²°)
        super().__init__(**kwargs)
        
        # ğŸ”¥ 2ë‹¨ê³„: Step ì „ìš© ì†ì„± ì„¤ì •
        self.step_name = "ClothSegmentationStep"
        self.step_number = 3
        self.device = device or self._auto_detect_device()
        
        # ğŸ”¥ 3ë‹¨ê³„: ì„¤ì • ì²˜ë¦¬
        if isinstance(config, dict):
            self.segmentation_config = SegmentationConfig(**config)
        elif isinstance(config, SegmentationConfig):
            self.segmentation_config = config
        else:
            self.segmentation_config = SegmentationConfig()
        
        # ğŸ”¥ 4ë‹¨ê³„: ModelLoader ì¸í„°í˜ì´ìŠ¤ ì„¤ì • (ì°¸ê³  íë¦„ 2ë‹¨ê³„)
        self._setup_model_interface_safe()
        
        # ğŸ”¥ 5ë‹¨ê³„: ì‹œìŠ¤í…œ ì •ë³´
        self.is_m3_max = self._detect_m3_max()
        self.memory_gb = kwargs.get('memory_gb', 128.0 if self.is_m3_max else 16.0)
        
        # ğŸ”¥ 6ë‹¨ê³„: ìƒíƒœ ë³€ìˆ˜ ì´ˆê¸°í™”
        self.is_initialized = False
        self.models_loaded = {}  # ModelLoaderê°€ ì œê³µí•œ ëª¨ë¸ë“¤
        self.rembg_sessions = {}
        self.processing_stats = {
            'total_processed': 0,
            'successful_segmentations': 0,
            'average_time': 0.0,
            'average_quality': 0.0,
            'method_usage': {},
            'cache_hits': 0
        }
        
        # ğŸ”¥ 7ë‹¨ê³„: ìºì‹œ ë° ë¦¬ì†ŒìŠ¤
        self.segmentation_cache = {}
        self.cache_lock = threading.RLock()
        self.executor = ThreadPoolExecutor(max_workers=4 if self.is_m3_max else 2, 
                                         thread_name_prefix="cloth_seg")
        
        # ğŸ”¥ 8ë‹¨ê³„: ê²½ë¡œ ë° ì‚¬ìš© ê°€ëŠ¥í•œ ë°©ë²• ì„¤ì •
        self._setup_paths_and_cache()
        self.available_methods = self._detect_available_methods()
        
        # loggerê°€ ì—†ìœ¼ë©´ ê°•ì œë¡œ ìƒì„± (ì•ˆì „ì¥ì¹˜)
        if not hasattr(self, 'logger') or self.logger is None:
            self.logger = logging.getLogger(f"pipeline.{self.step_name}")
        
        self.logger.info(f"âœ… {self.step_name} ìƒì„± ì™„ë£Œ - Device: {self.device}")
        self.logger.info(f"   ì‚¬ìš© ê°€ëŠ¥í•œ ë°©ë²•: {[m.value for m in self.available_methods]}")

    def _auto_detect_device(self) -> str:
        """ë””ë°”ì´ìŠ¤ ìë™ ê°ì§€ - M3 Max ìµœì í™”"""
        try:
            # M3 Max MPS ìš°ì„ 
            if torch.backends.mps.is_available():
                return "mps"
            elif torch.cuda.is_available():
                return "cuda"
            else:
                return "cpu"
        except Exception:
            return "cpu"

    def _detect_m3_max(self) -> bool:
        """M3 Max ì¹© ê°ì§€"""
        try:
            import platform
            import subprocess
            if platform.system() == 'Darwin':  # macOS
                result = subprocess.run(['sysctl', '-n', 'machdep.cpu.brand_string'], 
                                       capture_output=True, text=True)
                cpu_info = result.stdout.strip()
                return 'M3 Max' in cpu_info or 'M3' in cpu_info
        except Exception:
            pass
        return False

    def _setup_model_interface_safe(self):
        """
        ğŸ”¥ ModelLoader ì¸í„°í˜ì´ìŠ¤ ì•ˆì „ ì„¤ì • (ì°¸ê³  íë¦„ 2ë‹¨ê³„)
        
        âœ… ModelLoader.create_step_interface() í˜¸ì¶œ
        âœ… Stepë³„ ëª¨ë¸ ìš”ì²­ì‚¬í•­ ë“±ë¡
        """
        try:
            self.logger.info("ğŸ”— ModelLoader ì¸í„°í˜ì´ìŠ¤ ì„¤ì • ì¤‘...")
            
            if MODEL_LOADER_AVAILABLE:
                # ğŸ”¥ ì°¸ê³  íë¦„: ModelLoader.create_step_interface() í˜¸ì¶œ
                model_loader = get_global_model_loader()
                if model_loader and hasattr(model_loader, 'create_step_interface'):
                    self.model_interface = model_loader.create_step_interface(self.step_name)
                    self.logger.info("âœ… ModelLoader ì¸í„°í˜ì´ìŠ¤ ìƒì„± ì™„ë£Œ")
                else:
                    self.logger.warning("âš ï¸ ModelLoader create_step_interface ë©”ì„œë“œ ì—†ìŒ")
                    self.model_interface = None
            else:
                self.logger.warning("âš ï¸ ModelLoader ì‚¬ìš© ë¶ˆê°€ - í´ë°± ëª¨ë“œ")
                self.model_interface = None
                
        except Exception as e:
            self.logger.warning(f"âš ï¸ ModelLoader ì¸í„°í˜ì´ìŠ¤ ì„¤ì • ì‹¤íŒ¨: {e}")
            self.model_interface = None

    def _setup_paths_and_cache(self):
        """ê²½ë¡œ ë° ìºì‹œ ì„¤ì •"""
        try:
            # ê¸°ë³¸ ê²½ë¡œ ì„¤ì •
            self.model_base_path = Path(__file__).parent.parent.parent.parent / "ai_models"
            self.checkpoint_path = self.model_base_path / "checkpoints" / "step_03"
            self.checkpoint_path.mkdir(parents=True, exist_ok=True)
            
            self.logger.info("ğŸ“ ê²½ë¡œ ë° ìºì‹œ ì„¤ì • ì™„ë£Œ")
            
        except Exception as e:
            self.logger.error(f"ê²½ë¡œ ì„¤ì • ì‹¤íŒ¨: {e}")

    def _detect_available_methods(self) -> List[SegmentationMethod]:
        """ì‚¬ìš© ê°€ëŠ¥í•œ ì„¸ê·¸ë©˜í…Œì´ì…˜ ë°©ë²• ê°ì§€"""
        methods = []
        
        # í•­ìƒ ì‚¬ìš© ê°€ëŠ¥í•œ ì „í†µì  ë°©ë²•
        methods.append(SegmentationMethod.TRADITIONAL)
        
        # RemBG í™•ì¸
        if REMBG_AVAILABLE:
            methods.append(SegmentationMethod.REMBG)
            self.logger.info("âœ… RemBG ì‚¬ìš© ê°€ëŠ¥")
        
        # SAM í™•ì¸
        if SAM_AVAILABLE:
            methods.append(SegmentationMethod.SAM)
            self.logger.info("âœ… SAM ì‚¬ìš© ê°€ëŠ¥")
        
        # U2-Net (ModelLoader í†µí•´ í™•ì¸)
        if MODEL_LOADER_AVAILABLE:
            methods.append(SegmentationMethod.U2NET)
            self.logger.info("âœ… U2-Net ì‚¬ìš© ê°€ëŠ¥ (ModelLoader)")
        
        # Transformers ê¸°ë°˜ ëª¨ë¸
        if TRANSFORMERS_AVAILABLE:
            methods.append(SegmentationMethod.DEEP_LAB)
            self.logger.info("âœ… DeepLab ì‚¬ìš© ê°€ëŠ¥")
        
        # AUTO ë°©ë²• (í•­ìƒ ì‚¬ìš© ê°€ëŠ¥)
        methods.append(SegmentationMethod.AUTO)
        
        # HYBRID ë°©ë²• (2ê°œ ì´ìƒ ë°©ë²•ì´ ìˆì„ ë•Œ)
        if len(methods) >= 3:  # TRADITIONAL + AUTO + í•˜ë‚˜ ì´ìƒ
            methods.append(SegmentationMethod.HYBRID)
        
        return methods

    # ==============================================
    # ğŸ”¥ í†µì¼ëœ ì¸í„°í˜ì´ìŠ¤ ë©”ì„œë“œë“¤ (ê¸°ì¡´ ì´ë¦„ ìœ ì§€)
    # ==============================================

    async def initialize(self) -> bool:
        """
        âœ… í†µì¼ëœ ì´ˆê¸°í™” ì¸í„°í˜ì´ìŠ¤ (ì°¸ê³  íë¦„ 3ë‹¨ê³„)
        
        ğŸš€ Step + ModelLoader í˜‘ì—…:
        â”œâ”€ ì£¼ ëª¨ë¸ ë¡œë“œ (U2-Net) â† ModelLoaderê°€ ì‹¤ì œ ë¡œë“œ
        â”œâ”€ ë°±ì—… ëª¨ë¸ ë¡œë“œ (RemBG) â† ModelLoaderê°€ ì‹¤ì œ ë¡œë“œ
        â””â”€ M3 Max ìµœì í™” ì ìš© â† Stepì´ ì ìš©
        """
        if self.is_initialized:
            return True
        
        try:
            self.logger.info("ğŸ”„ 3ë‹¨ê³„: ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...")
            
            # ğŸ”¥ 1. ModelLoaderë¥¼ í†µí•œ AI ëª¨ë¸ ë¡œë“œ
            await self._initialize_ai_models_via_modelloader()
            
            # ğŸ”¥ 2. RemBG ì„¸ì…˜ ì´ˆê¸°í™” (ì§ì ‘ ê´€ë¦¬)
            if REMBG_AVAILABLE:
                await self._initialize_rembg_sessions()
            
            # ğŸ”¥ 3. ì „í†µì  ë°©ë²•ë“¤ ì´ˆê¸°í™”
            self._initialize_traditional_methods()
            
            # ğŸ”¥ 4. M3 Max ìµœì í™” ì›Œë°ì—…
            if self.is_m3_max:
                await self._warmup_m3_max()
            
            # ğŸ”¥ 5. ì‹œê°í™” ì‹œìŠ¤í…œ ì´ˆê¸°í™”
            self._initialize_visualization_system()
            
            self.is_initialized = True
            self.logger.info("âœ… ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.is_initialized = False
            return False

    async def process(
        self,
        image: Union[Image.Image, np.ndarray, str],
        clothing_type: Optional[str] = None,
        quality_level: Optional[str] = None,
        **kwargs
    ) -> Dict[str, Any]:
        """
        âœ… í†µì¼ëœ ì²˜ë¦¬ ì¸í„°í˜ì´ìŠ¤ (ì°¸ê³  íë¦„ 4ë‹¨ê³„)
        
        ğŸ§  ì‹¤ì œ AI ì¶”ë¡  process() â† Step íŒŒì¼ì´ ì£¼ë„:
        â”œâ”€ ì´ë¯¸ì§€ ì „ì²˜ë¦¬ â† Step ì²˜ë¦¬  
        â”œâ”€ ëª¨ë¸ ì¶”ë¡  â† ModelLoaderê°€ ì œê³µí•œ ëª¨ë¸ë¡œ Stepì´ ì¶”ë¡ 
        â”œâ”€ í›„ì²˜ë¦¬ ë° ë¶„ì„ â† Step ì²˜ë¦¬
        â””â”€ ì‹œê°í™” ì´ë¯¸ì§€ ìƒì„± â† Step ì²˜ë¦¬
        """
        if not self.is_initialized:
            await self.initialize()
        
        start_time = time.time()
        
        try:
            self.logger.info("ğŸ”„ ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ ì²˜ë¦¬ ì‹œì‘...")
            
            # ğŸ”¥ 1. ì´ë¯¸ì§€ ì „ì²˜ë¦¬ â† Step ì²˜ë¦¬
            processed_image = self._preprocess_image(image)
            if processed_image is None:
                return self._create_error_result("ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì‹¤íŒ¨")
            
            # ğŸ”¥ 2. ì˜ë¥˜ íƒ€ì… ê°ì§€
            detected_clothing_type = self._detect_clothing_type(
                processed_image, clothing_type
            )
            
            # ğŸ”¥ 3. í’ˆì§ˆ ë ˆë²¨ ì„¤ì •
            quality = QualityLevel(quality_level or self.segmentation_config.quality_level.value)
            
            # ğŸ”¥ 4. ëª¨ë¸ ì¶”ë¡  â† ModelLoaderê°€ ì œê³µí•œ ëª¨ë¸ë¡œ Stepì´ ì¶”ë¡ 
            mask, confidence = await self._run_segmentation_inference(
                processed_image, detected_clothing_type, quality
            )
            
            if mask is None:
                return self._create_error_result("ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‹¤íŒ¨")
            
            # ğŸ”¥ 5. í›„ì²˜ë¦¬ ë° ë¶„ì„ â† Step ì²˜ë¦¬
            processed_mask = self._post_process_mask(mask, quality)
            
            # ğŸ”¥ 6. ì‹œê°í™” ì´ë¯¸ì§€ ìƒì„± â† Step ì²˜ë¦¬
            visualizations = self._create_visualizations(
                processed_image, processed_mask, detected_clothing_type
            )
            
            # ğŸ”¥ 7. ê²°ê³¼ ìƒì„±
            processing_time = time.time() - start_time
            
            result = SegmentationResult(
                success=True,
                mask=processed_mask,
                confidence_score=confidence,
                clothing_type=detected_clothing_type,
                method_used=self._get_current_method(),
                processing_time=processing_time,
                visualization_image=visualizations.get('visualization'),
                overlay_image=visualizations.get('overlay'),
                mask_image=visualizations.get('mask'),
                boundary_image=visualizations.get('boundary'),
                metadata={
                    'device': self.device,
                    'quality_level': quality.value,
                    'models_used': list(self.models_loaded.keys()),
                    'image_size': processed_image.size
                }
            )
            
            # í†µê³„ ì—…ë°ì´íŠ¸
            self._update_processing_stats(processing_time, confidence)
            
            self.logger.info(f"âœ… ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ ì™„ë£Œ - {processing_time:.2f}ì´ˆ")
            return self._convert_result_to_dict(result)
            
        except Exception as e:
            self.logger.error(f"âŒ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return self._create_error_result(str(e))

    # ==============================================
    # ğŸ”¥ AI ëª¨ë¸ ë¡œë”© (ModelLoader í†µí•©)
    # ==============================================

    async def _initialize_ai_models_via_modelloader(self):
        """
        ğŸ”¥ í•µì‹¬ ê°œì„ : ModelLoaderë¥¼ í†µí•œ AI ëª¨ë¸ ë¡œë“œ
        
        âœ… ì§ì ‘ ëª¨ë¸ êµ¬í˜„ ì œê±° (U2NET í´ë˜ìŠ¤ ë“±)
        âœ… ModelLoader ì¸í„°í˜ì´ìŠ¤ 100% í™œìš©
        âœ… ì°¸ê³  íë¦„: ModelLoaderê°€ ì‹¤ì œ ë¡œë“œ, Stepì€ ì‚¬ìš©ë§Œ
        """
        try:
            self.logger.info("ğŸ¤– ModelLoaderë¥¼ í†µí•œ AI ëª¨ë¸ ë¡œë“œ ì¤‘...")
            
            if not self.model_interface:
                self.logger.warning("âš ï¸ ModelLoader ì¸í„°í˜ì´ìŠ¤ê°€ ì—†ìŒ - í´ë°± ëª¨ë“œ")
                await self._fallback_model_loading()
                return
            
            # ğŸ”¥ ì°¸ê³  íë¦„: ModelLoaderê°€ ì‹¤ì œ ë¡œë“œ
            try:
                # U2-Net ëª¨ë¸ ë¡œë“œ ìš”ì²­
                u2net_model = await self._request_model_from_loader('cloth_segmentation_u2net')
                if u2net_model:
                    self.models_loaded['u2net'] = u2net_model
                    self.logger.info("âœ… U2-Net ëª¨ë¸ ë¡œë“œ ì„±ê³µ (ModelLoader)")
                
                # DeepLab ëª¨ë¸ ë¡œë“œ ìš”ì²­ (ì„ íƒì )
                if TRANSFORMERS_AVAILABLE:
                    deeplab_model = await self._request_model_from_loader('deeplab_v3')
                    if deeplab_model:
                        self.models_loaded['deeplab'] = deeplab_model
                        self.logger.info("âœ… DeepLab ëª¨ë¸ ë¡œë“œ ì„±ê³µ (ModelLoader)")
                
                # SAM ëª¨ë¸ ë¡œë“œ ìš”ì²­ (ì„ íƒì )
                if SAM_AVAILABLE:
                    sam_model = await self._request_model_from_loader('sam_vit_h')
                    if sam_model:
                        self.models_loaded['sam'] = sam_model
                        self.logger.info("âœ… SAM ëª¨ë¸ ë¡œë“œ ì„±ê³µ (ModelLoader)")
                        
            except Exception as e:
                self.logger.warning(f"ModelLoader ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
                await self._fallback_model_loading()
                
        except Exception as e:
            self.logger.error(f"AI ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")

    async def _request_model_from_loader(self, model_name: str):
        """
        ğŸ”¥ ModelLoaderì— ëª¨ë¸ ë¡œë“œ ìš”ì²­
        
        âœ… get_model() ë˜ëŠ” load_model_async() ì§€ì›
        âœ… ì•ˆì „í•œ ì—ëŸ¬ ì²˜ë¦¬
        """
        try:
            if hasattr(self.model_interface, 'load_model_async'):
                return await self.model_interface.load_model_async(model_name)
            elif hasattr(self.model_interface, 'get_model'):
                return await self.model_interface.get_model(model_name)
            else:
                self.logger.warning(f"ModelLoader ì¸í„°í˜ì´ìŠ¤ì— ëª¨ë¸ ë¡œë“œ ë©”ì„œë“œ ì—†ìŒ")
                return None
                
        except Exception as e:
            self.logger.warning(f"ëª¨ë¸ {model_name} ë¡œë“œ ìš”ì²­ ì‹¤íŒ¨: {e}")
            return None

    async def _fallback_model_loading(self):
        """í´ë°± ëª¨ë¸ ë¡œë”© (ModelLoader ì—†ì„ ë•Œ)"""
        try:
            self.logger.info("ğŸ”„ í´ë°± ëª¨ë“œ: ì§ì ‘ U2-Net ëª¨ë¸ ë¡œë”©...")
            
            # ì§ì ‘ U2-Net ëª¨ë¸ ìƒì„± (í´ë°±ìš©)
            u2net_model = U2NET(in_ch=3, out_ch=1)
            
            # ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ ì‹œë„
            checkpoint_candidates = [
                self.checkpoint_path / "u2net_cloth.pth",
                self.checkpoint_path / "u2net.pth", 
                self.model_base_path / "u2net" / "u2net.pth",
                self.model_base_path / "checkpoints" / "u2net.pth"
            ]
            
            model_loaded = False
            for checkpoint_path in checkpoint_candidates:
                if checkpoint_path.exists():
                    try:
                        self.logger.info(f"ğŸ“ ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ ì‹œë„: {checkpoint_path}")
                        state_dict = torch.load(checkpoint_path, map_location=self.device)
                        
                        # state_dict í‚¤ ì •ë¦¬
                        if any(key.startswith('module.') for key in state_dict.keys()):
                            state_dict = {key.replace('module.', ''): value for key, value in state_dict.items()}
                        
                        u2net_model.load_state_dict(state_dict, strict=False)
                        self.logger.info(f"âœ… U2-Net ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ ì„±ê³µ: {checkpoint_path}")
                        model_loaded = True
                        break
                        
                    except Exception as e:
                        self.logger.warning(f"ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ ì‹¤íŒ¨ {checkpoint_path}: {e}")
                        continue
            
            if not model_loaded:
                self.logger.warning("âš ï¸ U2-Net ì²´í¬í¬ì¸íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤. ì‚¬ì „ í›ˆë ¨ë˜ì§€ ì•Šì€ ëª¨ë¸ ì‚¬ìš©.")
            
            # ë””ë°”ì´ìŠ¤ ì´ë™ ë° ì„¤ì •
            u2net_model.to(self.device)
            u2net_model.eval()
            
            # ì •ë°€ë„ ì„¤ì •
            u2net_model = self._setup_model_precision(u2net_model)
            
            self.models_loaded['u2net'] = u2net_model
            self.logger.info("âœ… í´ë°± U2-Net ëª¨ë¸ ì„¤ì • ì™„ë£Œ")
            
        except Exception as e:
            self.logger.warning(f"í´ë°± ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e}")
            # ìµœì¢… í´ë°±: ë”ë¯¸ ëª¨ë¸
            self.models_loaded['fallback'] = True

    def _setup_model_precision(self, model):
        """ğŸ”¥ M3 Max í˜¸í™˜ ì •ë°€ë„ ì„¤ì •"""
        try:
            if self.device == "mps":
                # M3 Maxì—ì„œëŠ” Float32ê°€ ì•ˆì „
                return model.float()
            elif self.device == "cuda" and self.segmentation_config.use_fp16:
                return model.half()
            else:
                return model.float()
        except Exception as e:
            self.logger.warning(f"âš ï¸ ì •ë°€ë„ ì„¤ì • ì‹¤íŒ¨: {e}")
            return model.float()

    # ==============================================
    # ğŸ”¥ RemBG ë° ê¸°íƒ€ ëª¨ë¸ ì´ˆê¸°í™”
    # ==============================================

    async def _initialize_rembg_sessions(self):
        """RemBG ì„¸ì…˜ë“¤ ì´ˆê¸°í™” (ì§ì ‘ ê´€ë¦¬)"""
        try:
            if not REMBG_AVAILABLE:
                return
            
            self.logger.info("ğŸ”„ RemBG ì„¸ì…˜ ì´ˆê¸°í™” ì‹œì‘...")
            
            # ë‹¤ì–‘í•œ RemBG ëª¨ë¸ ì„¸ì…˜ ìƒì„±
            session_configs = {
                'u2net': 'u2net',
                'u2netp': 'u2netp', 
                'silueta': 'silueta',
            }
            
            self.rembg_sessions = {}
            
            for name, model_name in session_configs.items():
                try:
                    self.logger.info(f"ğŸ”„ RemBG ì„¸ì…˜ ìƒì„± ì¤‘: {name} ({model_name})")
                    session = new_session(model_name)
                    self.rembg_sessions[name] = session
                    self.logger.info(f"âœ… RemBG ì„¸ì…˜ ìƒì„± ì™„ë£Œ: {name}")
                except Exception as e:
                    self.logger.warning(f"RemBG ì„¸ì…˜ {name} ìƒì„± ì‹¤íŒ¨: {e}")
            
            # ê¸°ë³¸ ì„¸ì…˜ ì„¤ì •
            if self.rembg_sessions:
                self.default_rembg_session = (
                    self.rembg_sessions.get('u2net') or 
                    list(self.rembg_sessions.values())[0]
                )
                self.logger.info("âœ… RemBG ê¸°ë³¸ ì„¸ì…˜ ì„¤ì • ì™„ë£Œ")
            
        except Exception as e:
            self.logger.warning(f"RemBG ì„¸ì…˜ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.rembg_sessions = {}

    def _initialize_traditional_methods(self):
        """ì „í†µì  ì´ë¯¸ì§€ ì²˜ë¦¬ ë°©ë²•ë“¤ ì´ˆê¸°í™”"""
        try:
            # ìƒ‰ìƒ ë²”ìœ„ ê¸°ë°˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ ì„¤ì •
            self.color_ranges = {
                'skin': {
                    'lower': np.array([0, 48, 80], dtype=np.uint8),
                    'upper': np.array([20, 255, 255], dtype=np.uint8)
                },
                'clothing': {
                    'lower': np.array([0, 0, 0], dtype=np.uint8),
                    'upper': np.array([180, 255, 200], dtype=np.uint8)
                }
            }
            
            # í˜•íƒœí•™ì  ì—°ì‚° ì»¤ë„
            self.morphology_kernels = {
                'small': cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3)),
                'medium': cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (7, 7)),
                'large': cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (15, 15))
            }
            
            self.logger.info("âœ… ì „í†µì  ë°©ë²• ì´ˆê¸°í™” ì™„ë£Œ")
            
        except Exception as e:
            self.logger.warning(f"ì „í†µì  ë°©ë²• ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")

    async def _warmup_m3_max(self):
        """M3 Max ì›Œë°ì—…"""
        try:
            self.logger.info("ğŸ”¥ M3 Max ì›Œë°ì—… ì‹œì‘...")
            
            # ë”ë¯¸ í…ì„œë¡œ ì›Œë°ì—…
            dummy_input = torch.randn(1, 3, 512, 512, device=self.device)
            
            if 'u2net' in self.models_loaded and self.models_loaded['u2net']:
                model = self.models_loaded['u2net']
                if hasattr(model, 'eval'):
                    model.eval()
                    with torch.no_grad():
                        _ = model(dummy_input)
                    self.logger.info("âœ… U2-Net M3 Max ì›Œë°ì—… ì™„ë£Œ")
            
            # MPS ìºì‹œ ì •ë¦¬
            if torch.backends.mps.is_available():
                torch.mps.empty_cache()
            
            self.logger.info("âœ… M3 Max ì›Œë°ì—… ì™„ë£Œ")
            
        except Exception as e:
            self.logger.warning(f"M3 Max ì›Œë°ì—… ì‹¤íŒ¨: {e}")

    def _initialize_visualization_system(self):
        """ì‹œê°í™” ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
        try:
            # ì‹œê°í™” ì„¤ì •
            self.visualization_config = {
                'mask_alpha': 0.7,
                'overlay_alpha': 0.5,
                'boundary_thickness': 2,
                'color_intensity': 200
            }
            
            # í°íŠ¸ ì„¤ì • (ì‹œìŠ¤í…œì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ í°íŠ¸ ì°¾ê¸°)
            try:
                self.font = ImageFont.truetype("/System/Library/Fonts/Helvetica.ttc", 16)
            except Exception:
                try:
                    self.font = ImageFont.load_default()
                except Exception:
                    self.font = None
            
            self.logger.info("âœ… ì‹œê°í™” ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
            
        except Exception as e:
            self.logger.warning(f"ì‹œê°í™” ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")

    # ==============================================
    # ğŸ”¥ ì´ë¯¸ì§€ ì²˜ë¦¬ ë° ì¶”ë¡  (í•µì‹¬ ë¡œì§)
    # ==============================================

    def _preprocess_image(self, image: Union[Image.Image, np.ndarray, str]) -> Optional[Image.Image]:
        """ì´ë¯¸ì§€ ì „ì²˜ë¦¬ â† Step ì²˜ë¦¬"""
        try:
            # ì…ë ¥ íƒ€ì…ë³„ ì²˜ë¦¬
            if isinstance(image, str):
                # Base64 ë˜ëŠ” íŒŒì¼ ê²½ë¡œ
                if image.startswith('data:image'):
                    # Base64
                    header, data = image.split(',', 1)
                    image_data = base64.b64decode(data)
                    image = Image.open(BytesIO(image_data))
                else:
                    # íŒŒì¼ ê²½ë¡œ
                    image = Image.open(image)
            elif isinstance(image, np.ndarray):
                # NumPy ë°°ì—´
                if image.shape[2] == 3:  # RGB
                    image = Image.fromarray(image)
                elif image.shape[2] == 4:  # RGBA
                    image = Image.fromarray(image).convert('RGB')
                else:
                    raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì´ë¯¸ì§€ í˜•íƒœ: {image.shape}")
            elif not isinstance(image, Image.Image):
                raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì´ë¯¸ì§€ íƒ€ì…: {type(image)}")
            
            # RGB ë³€í™˜
            if image.mode != 'RGB':
                image = image.convert('RGB')
            
            # í¬ê¸° ì¡°ì • (í’ˆì§ˆì— ë”°ë¼)
            target_size = self._get_target_size(self.segmentation_config.quality_level)
            if image.size != target_size:
                image = image.resize(target_size, Image.Resampling.LANCZOS)
            
            return image
            
        except Exception as e:
            self.logger.error(f"ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return None

    def _get_target_size(self, quality: QualityLevel) -> Tuple[int, int]:
        """í’ˆì§ˆ ë ˆë²¨ë³„ íƒ€ê²Ÿ í¬ê¸° ë°˜í™˜"""
        size_map = {
            QualityLevel.FAST: (256, 256),
            QualityLevel.BALANCED: (512, 512),
            QualityLevel.HIGH: (768, 768),
            QualityLevel.ULTRA: (1024, 1024)
        }
        return size_map.get(quality, (512, 512))

    def _detect_clothing_type(
        self, 
        image: Image.Image, 
        hint: Optional[str] = None
    ) -> ClothingType:
        """ì˜ë¥˜ íƒ€ì… ê°ì§€"""
        if hint:
            try:
                return ClothingType(hint.lower())
            except ValueError:
                pass
        
        # ê°„ë‹¨í•œ íœ´ë¦¬ìŠ¤í‹± ê¸°ë°˜ ê°ì§€
        width, height = image.size
        aspect_ratio = height / width
        
        if aspect_ratio > 1.5:
            return ClothingType.DRESS
        elif aspect_ratio > 1.2:
            return ClothingType.SHIRT
        else:
            return ClothingType.PANTS

    async def _run_segmentation_inference(
        self,
        image: Image.Image,
        clothing_type: ClothingType,
        quality: QualityLevel
    ) -> Tuple[Optional[np.ndarray], float]:
        """
        ğŸ”¥ í•µì‹¬: ModelLoaderê°€ ì œê³µí•œ ëª¨ë¸ë¡œ ì¶”ë¡  ì‹¤í–‰
        
        âœ… ëª¨ë¸ ì¶”ë¡  â† ModelLoaderê°€ ì œê³µí•œ ëª¨ë¸ë¡œ Stepì´ ì¶”ë¡ 
        """
        try:
            # ìš°ì„ ìˆœìœ„ ìˆœì„œë¡œ ë°©ë²• ì‹œë„
            methods_to_try = self._get_methods_by_priority(quality)
            
            for method in methods_to_try:
                try:
                    mask, confidence = await self._run_method(method, image, clothing_type)
                    if mask is not None:
                        self.logger.info(f"âœ… ì„¸ê·¸ë©˜í…Œì´ì…˜ ì„±ê³µ: {method.value}")
                        return mask, confidence
                except Exception as e:
                    self.logger.warning(f"ë°©ë²• {method.value} ì‹¤íŒ¨: {e}")
                    continue
            
            self.logger.warning("ëª¨ë“  ì„¸ê·¸ë©˜í…Œì´ì…˜ ë°©ë²• ì‹¤íŒ¨")
            return None, 0.0
            
        except Exception as e:
            self.logger.error(f"ì„¸ê·¸ë©˜í…Œì´ì…˜ ì¶”ë¡  ì‹¤íŒ¨: {e}")
            return None, 0.0

    def _get_methods_by_priority(self, quality: QualityLevel) -> List[SegmentationMethod]:
        """í’ˆì§ˆ ë ˆë²¨ë³„ ë°©ë²• ìš°ì„ ìˆœìœ„"""
        if quality == QualityLevel.ULTRA:
            priority = [
                SegmentationMethod.U2NET,
                SegmentationMethod.SAM,
                SegmentationMethod.DEEP_LAB,
                SegmentationMethod.REMBG,
                SegmentationMethod.TRADITIONAL
            ]
        elif quality == QualityLevel.HIGH:
            priority = [
                SegmentationMethod.U2NET,
                SegmentationMethod.REMBG,
                SegmentationMethod.DEEP_LAB,
                SegmentationMethod.TRADITIONAL
            ]
        elif quality == QualityLevel.BALANCED:
            priority = [
                SegmentationMethod.REMBG,
                SegmentationMethod.U2NET,
                SegmentationMethod.TRADITIONAL
            ]
        else:  # FAST
            priority = [
                SegmentationMethod.TRADITIONAL,
                SegmentationMethod.REMBG
            ]
        
        # ì‚¬ìš© ê°€ëŠ¥í•œ ë°©ë²•ë§Œ í•„í„°ë§
        return [method for method in priority if method in self.available_methods]

    async def _run_method(
        self,
        method: SegmentationMethod,
        image: Image.Image,
        clothing_type: ClothingType
    ) -> Tuple[Optional[np.ndarray], float]:
        """ê°œë³„ ì„¸ê·¸ë©˜í…Œì´ì…˜ ë°©ë²• ì‹¤í–‰"""
        
        if method == SegmentationMethod.U2NET:
            return await self._run_u2net_segmentation(image)
        elif method == SegmentationMethod.REMBG:
            return await self._run_rembg_segmentation(image)
        elif method == SegmentationMethod.SAM:
            return await self._run_sam_segmentation(image)
        elif method == SegmentationMethod.DEEP_LAB:
            return await self._run_deeplab_segmentation(image)
        elif method == SegmentationMethod.TRADITIONAL:
            return self._run_traditional_segmentation(image, clothing_type)
        elif method == SegmentationMethod.HYBRID:
            return await self._run_hybrid_segmentation(image, clothing_type)
        elif method == SegmentationMethod.AUTO:
            # AUTOëŠ” ê°€ì¥ ì¢‹ì€ ë°©ë²•ì„ ìë™ ì„ íƒ
            best_method = self._select_best_method_for_auto(image, clothing_type)
            return await self._run_method(best_method, image, clothing_type)
        else:
            raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ë°©ë²•: {method}")

    async def _run_u2net_segmentation(self, image: Image.Image) -> Tuple[Optional[np.ndarray], float]:
        """
        ğŸ”¥ U2-Net ì„¸ê·¸ë©˜í…Œì´ì…˜ (ModelLoader ì œê³µ ëª¨ë¸ ì‚¬ìš©)
        
        âœ… ModelLoaderê°€ ì œê³µí•œ ëª¨ë¸ë¡œ ì¶”ë¡ 
        âœ… ì§ì ‘ ëª¨ë¸ êµ¬í˜„ë„ í´ë°±ìœ¼ë¡œ ì§€ì›
        """
        try:
            # ModelLoaderì—ì„œ ì œê³µëœ ëª¨ë¸ ì‚¬ìš©
            if 'u2net' not in self.models_loaded:
                raise ValueError("U2-Net ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•ŠìŒ")
            
            model = self.models_loaded['u2net']
            if model is None or model is True:  # í´ë°± ëª¨ë“œ
                raise ValueError("U2-Net ëª¨ë¸ì´ ìœ íš¨í•˜ì§€ ì•ŠìŒ")
            
            # ì´ë¯¸ì§€ ì „ì²˜ë¦¬
            transform = transforms.Compose([
                transforms.ToTensor(),
                transforms.Normalize(mean=[0.485, 0.456, 0.406], 
                                   std=[0.229, 0.224, 0.225])
            ])
            
            input_tensor = transform(image).unsqueeze(0).to(self.device)
            
            # ğŸ”¥ ModelLoaderê°€ ì œê³µí•œ ëª¨ë¸ë¡œ ì¶”ë¡ 
            model.eval()
            with torch.no_grad():
                output = model(input_tensor)
                
                # ì¶œë ¥ ì²˜ë¦¬ (ëª¨ë¸ êµ¬ì¡°ì— ë”°ë¼ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ)
                if isinstance(output, tuple):
                    output = output[0]  # ì²« ë²ˆì§¸ ì¶œë ¥ ì‚¬ìš© (main output)
                elif isinstance(output, list):
                    output = output[0]  # ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš°
                
                # ì‹œê·¸ëª¨ì´ë“œ ì ìš© ë° ì„ê³„ê°’ ì²˜ë¦¬
                if output.max() > 1.0:  # ì‹œê·¸ëª¨ì´ë“œê°€ ì ìš©ë˜ì§€ ì•Šì€ ê²½ìš°
                    prob_map = torch.sigmoid(output)
                else:
                    prob_map = output
                
                mask = (prob_map > self.segmentation_config.confidence_threshold).float()
                
                # CPUë¡œ ì´ë™ ë° NumPy ë³€í™˜
                mask_np = mask.squeeze().cpu().numpy()
                confidence = float(prob_map.max().item())
            
            self.logger.info(f"âœ… U2-Net ì¶”ë¡  ì™„ë£Œ - ì‹ ë¢°ë„: {confidence:.3f}")
            return mask_np, confidence
            
        except Exception as e:
            self.logger.warning(f"U2-Net ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‹¤íŒ¨: {e}")
            return None, 0.0

    async def _run_rembg_segmentation(self, image: Image.Image) -> Tuple[Optional[np.ndarray], float]:
        """RemBG ì„¸ê·¸ë©˜í…Œì´ì…˜"""
        try:
            if not self.rembg_sessions:
                raise ValueError("RemBG ì„¸ì…˜ì´ ì—†ìŒ")
            
            # ì„¸ì…˜ ì„ íƒ (ì˜ë¥˜ì— ìµœì í™”ëœ ê²ƒ ìš°ì„ )
            session = (
                self.rembg_sessions.get('u2net') or
                list(self.rembg_sessions.values())[0]
            )
            
            # RemBG ì‹¤í–‰
            result = remove(image, session=session)
            
            # ì•ŒíŒŒ ì±„ë„ì—ì„œ ë§ˆìŠ¤í¬ ì¶”ì¶œ
            if result.mode == 'RGBA':
                mask = np.array(result)[:, :, 3]  # ì•ŒíŒŒ ì±„ë„
                mask = (mask > 128).astype(np.uint8)  # ì´ì§„í™”
                
                # ì‹ ë¢°ë„ ê³„ì‚° (ë§ˆìŠ¤í¬ ì˜ì—­ ë¹„ìœ¨ ê¸°ë°˜)
                confidence = np.sum(mask) / mask.size
                
                return mask, confidence
            else:
                raise ValueError("RemBG ê²°ê³¼ì— ì•ŒíŒŒ ì±„ë„ì´ ì—†ìŒ")
                
        except Exception as e:
            self.logger.warning(f"RemBG ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‹¤íŒ¨: {e}")
            return None, 0.0

    async def _run_sam_segmentation(self, image: Image.Image) -> Tuple[Optional[np.ndarray], float]:
        """SAM ì„¸ê·¸ë©˜í…Œì´ì…˜ (ModelLoader ì œê³µ ëª¨ë¸ ì‚¬ìš©)"""
        try:
            if 'sam' not in self.models_loaded:
                raise ValueError("SAM ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•ŠìŒ")
            
            # SAMì€ ë³„ë„ì˜ ë³µì¡í•œ ì„¤ì •ì´ í•„ìš”í•˜ë¯€ë¡œ ê°„ë‹¨í•œ êµ¬í˜„
            # ì‹¤ì œë¡œëŠ” ë” ì •êµí•œ í”„ë¡¬í”„íŠ¸ ê¸°ë°˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ ìˆ˜í–‰
            
            # ì„ì‹œë¡œ ì¤‘ì•™ ì˜ì—­ì„ ì˜ë¥˜ë¡œ ê°€ì •
            width, height = image.size
            mask = np.zeros((height, width), dtype=np.uint8)
            center_x, center_y = width // 2, height // 2
            
            # íƒ€ì›í˜• ë§ˆìŠ¤í¬ ìƒì„±
            y, x = np.ogrid[:height, :width]
            ellipse_mask = ((x - center_x) / (width * 0.3))**2 + ((y - center_y) / (height * 0.4))**2 <= 1
            mask[ellipse_mask] = 1
            
            confidence = 0.8  # ê³ ì • ì‹ ë¢°ë„
            
            self.logger.info("âœ… SAM ì„¸ê·¸ë©˜í…Œì´ì…˜ ì™„ë£Œ (ê°„ë‹¨ êµ¬í˜„)")
            return mask, confidence
            
        except Exception as e:
            self.logger.warning(f"SAM ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‹¤íŒ¨: {e}")
            return None, 0.0

    async def _run_deeplab_segmentation(self, image: Image.Image) -> Tuple[Optional[np.ndarray], float]:
        """DeepLab ì„¸ê·¸ë©˜í…Œì´ì…˜ (ModelLoader ì œê³µ ëª¨ë¸ ì‚¬ìš©)"""
        try:
            if 'deeplab' not in self.models_loaded:
                raise ValueError("DeepLab ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•ŠìŒ")
            
            # DeepLabì€ ë³´í†µ Transformers pipelineìœ¼ë¡œ ì œê³µ
            model = self.models_loaded['deeplab']
            
            # ê°„ë‹¨í•œ êµ¬í˜„ (ì‹¤ì œë¡œëŠ” ë” ë³µì¡)
            # ì‚¬ëŒ ì˜ì—­ ê°ì§€ í›„ ì˜ë¥˜ ì˜ì—­ ì¶”ì¶œ
            
            # ì„ì‹œë¡œ ì¤‘ì•™-í•˜ë‹¨ ì˜ì—­ì„ ì˜ë¥˜ë¡œ ê°€ì •
            width, height = image.size
            mask = np.zeros((height, width), dtype=np.uint8)
            
            # í•˜ì²´ ì˜ì—­ ë§ˆìŠ¤í¬
            mask[height//3:height*2//3, width//4:width*3//4] = 1
            
            confidence = 0.7
            
            self.logger.info("âœ… DeepLab ì„¸ê·¸ë©˜í…Œì´ì…˜ ì™„ë£Œ (ê°„ë‹¨ êµ¬í˜„)")
            return mask, confidence
            
        except Exception as e:
            self.logger.warning(f"DeepLab ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‹¤íŒ¨: {e}")
            return None, 0.0

    def _run_traditional_segmentation(
        self, 
        image: Image.Image, 
        clothing_type: ClothingType
    ) -> Tuple[Optional[np.ndarray], float]:
        """ì „í†µì  ì„¸ê·¸ë©˜í…Œì´ì…˜ (ìƒ‰ìƒ ê¸°ë°˜)"""
        try:
            # PIL to OpenCV ë³€í™˜
            image_cv = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)
            hsv = cv2.cvtColor(image_cv, cv2.COLOR_BGR2HSV)
            
            # í”¼ë¶€ìƒ‰ ì˜ì—­ ì œê±°
            skin_mask = cv2.inRange(hsv, self.color_ranges['skin']['lower'], 
                                  self.color_ranges['skin']['upper'])
            
            # ì˜ë¥˜ ìƒ‰ìƒ ë²”ìœ„ ê°ì§€
            clothing_mask = cv2.inRange(hsv, self.color_ranges['clothing']['lower'],
                                      self.color_ranges['clothing']['upper'])
            
            # í”¼ë¶€ ì˜ì—­ ì œì™¸
            clothing_mask = cv2.bitwise_and(clothing_mask, cv2.bitwise_not(skin_mask))
            
            # í˜•íƒœí•™ì  ì—°ì‚°ìœ¼ë¡œ ë…¸ì´ì¦ˆ ì œê±°
            clothing_mask = cv2.morphologyEx(clothing_mask, cv2.MORPH_CLOSE, 
                                           self.morphology_kernels['medium'])
            clothing_mask = cv2.morphologyEx(clothing_mask, cv2.MORPH_OPEN,
                                           self.morphology_kernels['small'])
            
            # ê°€ì¥ í° ì—°ê²° ì˜ì—­ ì°¾ê¸°
            contours, _ = cv2.findContours(clothing_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            if contours:
                largest_contour = max(contours, key=cv2.contourArea)
                mask = np.zeros_like(clothing_mask)
                cv2.fillPoly(mask, [largest_contour], 255)
                mask = (mask > 0).astype(np.uint8)
            else:
                mask = (clothing_mask > 0).astype(np.uint8)
            
            # ì‹ ë¢°ë„ ê³„ì‚°
            confidence = np.sum(mask) / mask.size
            confidence = min(confidence * 2, 1.0)  # ì •ê·œí™”
            
            self.logger.info(f"âœ… ì „í†µì  ì„¸ê·¸ë©˜í…Œì´ì…˜ ì™„ë£Œ - ì‹ ë¢°ë„: {confidence:.3f}")
            return mask, confidence
            
        except Exception as e:
            self.logger.warning(f"ì „í†µì  ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‹¤íŒ¨: {e}")
            return None, 0.0

    async def _run_hybrid_segmentation(
        self,
        image: Image.Image,
        clothing_type: ClothingType
    ) -> Tuple[Optional[np.ndarray], float]:
        """í•˜ì´ë¸Œë¦¬ë“œ ì„¸ê·¸ë©˜í…Œì´ì…˜ (ì—¬ëŸ¬ ë°©ë²• ì¡°í•©)"""
        try:
            self.logger.info("ğŸ”„ í•˜ì´ë¸Œë¦¬ë“œ ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‹œì‘...")
            
            results = []
            weights = []
            
            # U2-Net ì‹œë„
            try:
                mask1, conf1 = await self._run_u2net_segmentation(image)
                if mask1 is not None:
                    results.append(mask1)
                    weights.append(conf1 * 0.4)  # ë†’ì€ ê°€ì¤‘ì¹˜
            except Exception:
                pass
            
            # RemBG ì‹œë„
            try:
                mask2, conf2 = await self._run_rembg_segmentation(image)
                if mask2 is not None:
                    results.append(mask2)
                    weights.append(conf2 * 0.3)
            except Exception:
                pass
            
            # ì „í†µì  ë°©ë²• ì‹œë„
            try:
                mask3, conf3 = self._run_traditional_segmentation(image, clothing_type)
                if mask3 is not None:
                    results.append(mask3)
                    weights.append(conf3 * 0.3)
            except Exception:
                pass
            
            if not results:
                return None, 0.0
            
            # ê°€ì¤‘ í‰ê· ìœ¼ë¡œ ë§ˆìŠ¤í¬ ì¡°í•©
            combined_mask = np.zeros_like(results[0], dtype=np.float32)
            total_weight = sum(weights)
            
            for mask, weight in zip(results, weights):
                combined_mask += mask.astype(np.float32) * (weight / total_weight)
            
            # ì´ì§„í™”
            final_mask = (combined_mask > 0.5).astype(np.uint8)
            final_confidence = total_weight / len(results)
            
            self.logger.info(f"âœ… í•˜ì´ë¸Œë¦¬ë“œ ì„¸ê·¸ë©˜í…Œì´ì…˜ ì™„ë£Œ - {len(results)}ê°œ ë°©ë²• ì¡°í•©")
            return final_mask, final_confidence
            
        except Exception as e:
            self.logger.warning(f"í•˜ì´ë¸Œë¦¬ë“œ ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‹¤íŒ¨: {e}")
            return None, 0.0

    def _select_best_method_for_auto(self, image: Image.Image, clothing_type: ClothingType) -> SegmentationMethod:
        """AUTO ëª¨ë“œì—ì„œ ìµœì  ë°©ë²• ì„ íƒ"""
        # ì´ë¯¸ì§€ íŠ¹ì„± ë¶„ì„
        width, height = image.size
        complexity_score = self._calculate_image_complexity(image)
        
        # ë³µì¡ë„ì™€ ì‚¬ìš© ê°€ëŠ¥í•œ ë°©ë²•ì— ë”°ë¼ ì„ íƒ
        if complexity_score > 0.7 and SegmentationMethod.U2NET in self.available_methods:
            return SegmentationMethod.U2NET
        elif SegmentationMethod.REMBG in self.available_methods:
            return SegmentationMethod.REMBG
        elif SegmentationMethod.U2NET in self.available_methods:
            return SegmentationMethod.U2NET
        else:
            return SegmentationMethod.TRADITIONAL

    def _calculate_image_complexity(self, image: Image.Image) -> float:
        """ì´ë¯¸ì§€ ë³µì¡ë„ ê³„ì‚°"""
        try:
            # ê°„ë‹¨í•œ ë³µì¡ë„ ì¸¡ì • (ì—£ì§€ ë°€ë„ ê¸°ë°˜)
            gray = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2GRAY)
            edges = cv2.Canny(gray, 50, 150)
            edge_density = np.sum(edges > 0) / edges.size
            return min(edge_density * 10, 1.0)  # ì •ê·œí™”
        except Exception:
            return 0.5  # ê¸°ë³¸ê°’

    # ==============================================
    # ğŸ”¥ í›„ì²˜ë¦¬ ë° í’ˆì§ˆ í‰ê°€ (ê³ ê¸‰ ê¸°ëŠ¥)
    # ==============================================

    def _post_process_mask(self, mask: np.ndarray, quality: QualityLevel) -> np.ndarray:
        """ë§ˆìŠ¤í¬ í›„ì²˜ë¦¬ â† Step ì²˜ë¦¬"""
        try:
            processed_mask = mask.copy()
            
            if self.segmentation_config.remove_noise:
                # ë…¸ì´ì¦ˆ ì œê±°
                kernel_size = 'small' if quality == QualityLevel.FAST else 'medium'
                kernel = self.morphology_kernels[kernel_size]
                processed_mask = cv2.morphologyEx(processed_mask, cv2.MORPH_OPEN, kernel)
                processed_mask = cv2.morphologyEx(processed_mask, cv2.MORPH_CLOSE, kernel)
            
            if self.segmentation_config.edge_smoothing:
                # ì—£ì§€ ìŠ¤ë¬´ë”©
                processed_mask = cv2.GaussianBlur(processed_mask.astype(np.float32), (3, 3), 0.5)
                processed_mask = (processed_mask > 0.5).astype(np.uint8)
            
            # í™€ ì±„ìš°ê¸°
            if self.segmentation_config.enable_hole_filling:
                processed_mask = self._fill_holes(processed_mask)
            
            # ê²½ê³„ ê°œì„ 
            if self.segmentation_config.enable_edge_refinement:
                processed_mask = self._refine_edges(processed_mask)
            
            return processed_mask
            
        except Exception as e:
            self.logger.warning(f"ë§ˆìŠ¤í¬ í›„ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return mask

    def _fill_holes(self, mask: np.ndarray) -> np.ndarray:
        """ë§ˆìŠ¤í¬ ë‚´ë¶€ í™€ ì±„ìš°ê¸°"""
        try:
            # ìœ¤ê³½ì„  ê¸°ë°˜ í™€ ì±„ìš°ê¸°
            contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            filled_mask = np.zeros_like(mask)
            for contour in contours:
                cv2.fillPoly(filled_mask, [contour], 1)
            return filled_mask
        except Exception as e:
            self.logger.warning(f"í™€ ì±„ìš°ê¸° ì‹¤íŒ¨: {e}")
            return mask

    def _refine_edges(self, mask: np.ndarray) -> np.ndarray:
        """ê²½ê³„ ê°œì„ """
        try:
            # ê°€ìš°ì‹œì•ˆ ë¸”ëŸ¬ë¥¼ ì‚¬ìš©í•œ ê²½ê³„ ë¶€ë“œëŸ½ê²Œ
            if self.segmentation_config.enable_edge_refinement:
                # ê²½ê³„ ê²€ì¶œ
                edges = cv2.Canny(mask, 50, 150)
                
                # ê²½ê³„ ì£¼ë³€ ì˜ì—­ í™•ì¥
                kernel = np.ones((5, 5), np.uint8)
                edge_region = cv2.dilate(edges, kernel, iterations=1)
                
                # í•´ë‹¹ ì˜ì—­ì— ê°€ìš°ì‹œì•ˆ ë¸”ëŸ¬ ì ìš©
                blurred_mask = cv2.GaussianBlur(mask.astype(np.float32), (5, 5), 1.0)
                
                # ê²½ê³„ ì˜ì—­ë§Œ ë¸”ëŸ¬ëœ ê°’ìœ¼ë¡œ êµì²´
                refined_mask = mask.copy().astype(np.float32)
                refined_mask[edge_region > 0] = blurred_mask[edge_region > 0]
                
                return (refined_mask > 0.5).astype(np.uint8)
            
            return mask
            
        except Exception as e:
            self.logger.warning(f"ê²½ê³„ ê°œì„  ì‹¤íŒ¨: {e}")
            return mask

    # ==============================================
    # ğŸ”¥ ì™„ì „í•œ ì‹œê°í™” ì‹œìŠ¤í…œ
    # ==============================================

    def _create_visualizations(
        self,
        image: Image.Image,
        mask: np.ndarray,
        clothing_type: ClothingType
    ) -> Dict[str, Image.Image]:
        """ì‹œê°í™” ì´ë¯¸ì§€ ìƒì„± â† Step ì²˜ë¦¬"""
        try:
            visualizations = {}
            
            # ìƒ‰ìƒ ì„ íƒ
            color = CLOTHING_COLORS.get(clothing_type.value, CLOTHING_COLORS['unknown'])
            
            # 1. ë§ˆìŠ¤í¬ ì´ë¯¸ì§€ (ìƒ‰ìƒ êµ¬ë¶„)
            mask_colored = np.zeros((*mask.shape, 3), dtype=np.uint8)
            mask_colored[mask > 0] = color
            visualizations['mask'] = Image.fromarray(mask_colored)
            
            # 2. ì˜¤ë²„ë ˆì´ ì´ë¯¸ì§€
            image_array = np.array(image)
            overlay = image_array.copy()
            alpha = self.visualization_config['overlay_alpha']
            overlay[mask > 0] = (
                overlay[mask > 0] * (1 - alpha) + 
                np.array(color) * alpha
            ).astype(np.uint8)
            visualizations['overlay'] = Image.fromarray(overlay)
            
            # 3. ê²½ê³„ì„  ì´ë¯¸ì§€
            boundary = cv2.Canny((mask * 255).astype(np.uint8), 50, 150)
            boundary_colored = np.zeros((*boundary.shape, 3), dtype=np.uint8)
            boundary_colored[boundary > 0] = (255, 255, 255)  # í°ìƒ‰ ê²½ê³„ì„ 
            
            # ì›ë³¸ ì´ë¯¸ì§€ì™€ í•©ì„±
            boundary_overlay = image_array.copy()
            boundary_overlay[boundary > 0] = (255, 255, 255)
            visualizations['boundary'] = Image.fromarray(boundary_overlay)
            
            # 4. ì¢…í•© ì‹œê°í™” ì´ë¯¸ì§€ (ì •ë³´ í¬í•¨)
            visualization = self._create_comprehensive_visualization(
                image, mask, clothing_type, color
            )
            visualizations['visualization'] = visualization
            
            return visualizations
            
        except Exception as e:
            self.logger.warning(f"ì‹œê°í™” ìƒì„± ì‹¤íŒ¨: {e}")
            return {}

    def _create_comprehensive_visualization(
        self,
        image: Image.Image,
        mask: np.ndarray,
        clothing_type: ClothingType,
        color: Tuple[int, int, int]
    ) -> Image.Image:
        """ì¢…í•© ì‹œê°í™” ì´ë¯¸ì§€ ìƒì„±"""
        try:
            # ìº”ë²„ìŠ¤ ìƒì„± (ì›ë³¸ + ì •ë³´ ì˜ì—­)
            width, height = image.size
            canvas_width = width * 2 + 20
            canvas_height = height + 60
            
            canvas = Image.new('RGB', (canvas_width, canvas_height), (240, 240, 240))
            
            # ì›ë³¸ ì´ë¯¸ì§€ ë°°ì¹˜
            canvas.paste(image, (10, 30))
            
            # ë§ˆìŠ¤í¬ ì˜¤ë²„ë ˆì´ ì´ë¯¸ì§€ ìƒì„±
            image_array = np.array(image)
            overlay = image_array.copy()
            alpha = 0.6
            overlay[mask > 0] = (
                overlay[mask > 0] * (1 - alpha) + 
                np.array(color) * alpha
            ).astype(np.uint8)
            
            # ê²½ê³„ì„  ì¶”ê°€
            boundary = cv2.Canny((mask * 255).astype(np.uint8), 50, 150)
            overlay[boundary > 0] = (255, 255, 255)
            
            overlay_image = Image.fromarray(overlay)
            canvas.paste(overlay_image, (width + 20, 30))
            
            # í…ìŠ¤íŠ¸ ì •ë³´ ì¶”ê°€
            if self.font:
                draw = ImageDraw.Draw(canvas)
                
                # ì œëª©
                draw.text((10, 5), "Original", fill=(0, 0, 0), font=self.font)
                draw.text((width + 20, 5), f"Segmented ({clothing_type.value})", 
                         fill=(0, 0, 0), font=self.font)
                
                # í†µê³„ ì •ë³´
                mask_area = np.sum(mask)
                total_area = mask.size
                coverage = (mask_area / total_area) * 100
                
                info_text = f"Coverage: {coverage:.1f}% | Type: {clothing_type.value}"
                draw.text((10, height + 35), info_text, fill=(0, 0, 0), font=self.font)
            
            return canvas
            
        except Exception as e:
            self.logger.warning(f"ì¢…í•© ì‹œê°í™” ìƒì„± ì‹¤íŒ¨: {e}")
            return image

    # ==============================================
    # ğŸ”¥ ìœ í‹¸ë¦¬í‹° ë° í†µê³„ ê´€ë¦¬
    # ==============================================

    def _get_current_method(self) -> SegmentationMethod:
        """í˜„ì¬ ì‚¬ìš©ëœ ë°©ë²• ë°˜í™˜"""
        # ê°„ë‹¨í•œ êµ¬í˜„ - ì‹¤ì œë¡œëŠ” ë§ˆì§€ë§‰ ì„±ê³µí•œ ë°©ë²•ì„ ì¶”ì 
        if self.models_loaded.get('u2net'):
            return SegmentationMethod.U2NET
        elif self.rembg_sessions:
            return SegmentationMethod.REMBG
        else:
            return SegmentationMethod.TRADITIONAL

    def _update_processing_stats(self, processing_time: float, confidence: float):
        """ì²˜ë¦¬ í†µê³„ ì—…ë°ì´íŠ¸"""
        try:
            self.processing_stats['total_processed'] += 1
            
            # í‰ê·  ì‹œê°„ ê³„ì‚°
            total = self.processing_stats['total_processed']
            current_avg = self.processing_stats['average_time']
            self.processing_stats['average_time'] = (
                (current_avg * (total - 1) + processing_time) / total
            )
            
        except Exception as e:
            self.logger.warning(f"í†µê³„ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")

    def _convert_result_to_dict(self, result: SegmentationResult) -> Dict[str, Any]:
        """SegmentationResultë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜"""
        try:
            result_dict = {
                'success': result.success,
                'confidence': result.confidence_score,
                'clothing_type': result.clothing_type.value if hasattr(result, 'clothing_type') else 'unknown',
                'method_used': result.method_used,
                'processing_time': result.processing_time,
                'metadata': result.metadata
            }
            
            # ì´ë¯¸ì§€ë“¤ì„ Base64ë¡œ ì¸ì½”ë”©
            if result.mask is not None:
                mask_image = Image.fromarray((result.mask * 255).astype(np.uint8))
                result_dict['mask_base64'] = self._image_to_base64(mask_image)
            
            if result.visualization_image:
                result_dict['visualization_base64'] = self._image_to_base64(result.visualization_image)
            
            if result.overlay_image:
                result_dict['overlay_base64'] = self._image_to_base64(result.overlay_image)
            
            if result.mask_image:
                result_dict['mask_image_base64'] = self._image_to_base64(result.mask_image)
            
            if result.boundary_image:
                result_dict['boundary_base64'] = self._image_to_base64(result.boundary_image)
            
            return result_dict
            
        except Exception as e:
            self.logger.warning(f"ê²°ê³¼ ë³€í™˜ ì‹¤íŒ¨: {e}")
            return {'success': False, 'error': str(e)}

    def _image_to_base64(self, image: Image.Image) -> str:
        """ì´ë¯¸ì§€ë¥¼ Base64ë¡œ ì¸ì½”ë”©"""
        try:
            buffer = BytesIO()
            image.save(buffer, format='PNG')
            image_data = buffer.getvalue()
            return base64.b64encode(image_data).decode()
        except Exception as e:
            self.logger.warning(f"Base64 ì¸ì½”ë”© ì‹¤íŒ¨: {e}")
            return ""

    def _create_error_result(self, error_message: str) -> Dict[str, Any]:
        """ì—ëŸ¬ ê²°ê³¼ ìƒì„±"""
        return {
            'success': False,
            'error': error_message,
            'confidence': 0.0,
            'clothing_type': ClothingType.UNKNOWN.value,
            'method_used': SegmentationMethod.TRADITIONAL.value,
            'processing_time': 0.0,
            'metadata': {
                'device': self.device,
                'error_time': time.time()
            }
        }

    # ==============================================
    # ğŸ”¥ ê¸°ì¡´ í˜¸í™˜ì„± + ì¶”ê°€ ê³ ê¸‰ ë©”ì„œë“œë“¤
    # ==============================================

    async def segment_clothing(self, image, **kwargs):
        """ê¸°ì¡´ í˜¸í™˜ì„± ë©”ì„œë“œ"""
        return await self.process(image, **kwargs)

    def get_segmentation_info(self) -> Dict[str, Any]:
        """ì„¸ê·¸ë©˜í…Œì´ì…˜ ì •ë³´ ë°˜í™˜"""
        return {
            'step_name': self.step_name,
            'device': self.device,
            'is_initialized': self.is_initialized,
            'available_methods': [m.value for m in self.available_methods],
            'loaded_models': list(self.models_loaded.keys()),
            'rembg_sessions': list(self.rembg_sessions.keys()),
            'processing_stats': self.processing_stats.copy(),
            'config': {
                'method': self.segmentation_config.method.value,
                'quality_level': self.segmentation_config.quality_level.value,
                'enable_visualization': self.segmentation_config.enable_visualization,
                'confidence_threshold': self.segmentation_config.confidence_threshold,
                'enable_edge_refinement': self.segmentation_config.enable_edge_refinement,
                'enable_hole_filling': self.segmentation_config.enable_hole_filling,
                'overlay_opacity': self.segmentation_config.overlay_opacity
            }
        }

    def get_segmentation_method_info(self, method_name: str) -> Dict[str, Any]:
        """ì„¸ê·¸ë©˜í…Œì´ì…˜ ë°©ë²•ë³„ ìƒì„¸ ì •ë³´ ë°˜í™˜"""
        method_info = {
            'u2net': {
                'name': 'U2-Net',
                'description': 'Deep learning salient object detection for clothing',
                'quality': 'high',
                'speed': 'medium',
                'accuracy': 'high',
                'requirements': ['pytorch', 'torchvision']
            },
            'rembg': {
                'name': 'Remove Background',
                'description': 'AI-powered background removal tool',
                'quality': 'medium',
                'speed': 'fast',
                'accuracy': 'medium',
                'requirements': ['rembg']
            },
            'sam': {
                'name': 'Segment Anything Model',
                'description': 'Meta\'s universal segmentation model',
                'quality': 'ultra',
                'speed': 'slow',
                'accuracy': 'ultra-high',
                'requirements': ['segment_anything']
            },
            'deeplab': {
                'name': 'DeepLab v3',
                'description': 'Semantic segmentation with transformers',
                'quality': 'high',
                'speed': 'medium',
                'accuracy': 'high',
                'requirements': ['transformers']
            },
            'mask_rcnn': {
                'name': 'Mask R-CNN',
                'description': 'Instance segmentation for clothing detection',
                'quality': 'high',
                'speed': 'slow',
                'accuracy': 'very-high',
                'requirements': ['detectron2']
            },
            'traditional': {
                'name': 'Traditional CV',
                'description': 'Classical computer vision methods (GrabCut, K-means)',
                'quality': 'medium',
                'speed': 'fast',
                'accuracy': 'medium',
                'requirements': ['opencv', 'scikit-learn']
            },
            'hybrid': {
                'name': 'Hybrid Method',
                'description': 'Combination of multiple segmentation techniques',
                'quality': 'high',
                'speed': 'medium',
                'accuracy': 'high',
                'requirements': ['multiple']
            },
            'auto': {
                'name': 'Auto Selection',
                'description': 'Automatically selects the best method',
                'quality': 'adaptive',
                'speed': 'adaptive',
                'accuracy': 'adaptive',
                'requirements': ['adaptive']
            }
        }
        
        return method_info.get(method_name, {
            'name': 'Unknown',
            'description': 'Unknown segmentation method',
            'quality': 'unknown',
            'speed': 'unknown',
            'accuracy': 'unknown',
            'requirements': []
        })

    def get_clothing_mask(self, mask: np.ndarray, category: str) -> np.ndarray:
        """íŠ¹ì • ì˜ë¥˜ ì¹´í…Œê³ ë¦¬ì˜ í†µí•© ë§ˆìŠ¤í¬ ë°˜í™˜"""
        try:
            # ì˜ë¥˜ ì¹´í…Œê³ ë¦¬ë³„ ë§ˆìŠ¤í¬ ìƒì„±
            if category in ['shirt', 'top', 'sweater']:
                # ìƒì˜ ì¹´í…Œê³ ë¦¬
                return (mask > 128).astype(np.uint8)
            elif category in ['pants', 'skirt', 'bottom']:
                # í•˜ì˜ ì¹´í…Œê³ ë¦¬
                return (mask > 128).astype(np.uint8)
            elif category in ['dress']:
                # ì›í”¼ìŠ¤ ì¹´í…Œê³ ë¦¬
                return (mask > 128).astype(np.uint8)
            elif category in ['jacket', 'coat']:
                # ì•„ìš°í„° ì¹´í…Œê³ ë¦¬
                return (mask > 128).astype(np.uint8)
            else:
                # ê¸°ë³¸ê°’
                return (mask > 128).astype(np.uint8)
        except Exception as e:
            self.logger.warning(f"ì˜ë¥˜ ë§ˆìŠ¤í¬ ìƒì„± ì‹¤íŒ¨: {e}")
            return np.zeros_like(mask, dtype=np.uint8)

    def visualize_segmentation(self, mask: np.ndarray, clothing_type: str = "shirt") -> np.ndarray:
        """ì„¸ê·¸ë©˜í…Œì´ì…˜ ê²°ê³¼ ì‹œê°í™” (ë””ë²„ê¹…ìš©)"""
        try:
            # ì˜ë¥˜ íƒ€ì…ì— ë”°ë¥¸ ìƒ‰ìƒ ì„ íƒ
            color = CLOTHING_COLORS.get(clothing_type, CLOTHING_COLORS['unknown'])
            
            # 3ì±„ë„ ìƒ‰ìƒ ì´ë¯¸ì§€ ìƒì„±
            height, width = mask.shape
            colored_image = np.zeros((height, width, 3), dtype=np.uint8)
            colored_image[mask > 0] = color
            
            return colored_image
            
        except Exception as e:
            self.logger.warning(f"ì‹œê°í™” ìƒì„± ì‹¤íŒ¨: {e}")
            return np.zeros((mask.shape[0], mask.shape[1], 3), dtype=np.uint8)

    def get_mask_statistics(self, mask: np.ndarray) -> Dict[str, float]:
        """ë§ˆìŠ¤í¬ í†µê³„ ì •ë³´ ë°˜í™˜"""
        try:
            total_pixels = mask.size
            mask_pixels = np.sum(mask > 0)
            coverage_ratio = mask_pixels / total_pixels
            
            # ì—°ê²° ì˜ì—­ ë¶„ì„
            contours, _ = cv2.findContours(
                (mask > 0).astype(np.uint8), 
                cv2.RETR_EXTERNAL, 
                cv2.CHAIN_APPROX_SIMPLE
            )
            
            num_regions = len(contours)
            largest_area = max([cv2.contourArea(c) for c in contours]) if contours else 0
            
            return {
                'coverage_ratio': coverage_ratio,
                'mask_pixels': int(mask_pixels),
                'total_pixels': int(total_pixels),
                'num_regions': num_regions,
                'largest_region_area': largest_area,
                'fragmentation_score': num_regions / max(1, coverage_ratio * 100)
            }
            
        except Exception as e:
            self.logger.warning(f"ë§ˆìŠ¤í¬ í†µê³„ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return {
                'coverage_ratio': 0.0,
                'mask_pixels': 0,
                'total_pixels': mask.size,
                'num_regions': 0,
                'largest_region_area': 0,
                'fragmentation_score': 0.0
            }

    async def cleanup(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        try:
            self.logger.info("ğŸ§¹ ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì¤‘...")
            
            # ëª¨ë¸ ì •ë¦¬ (ModelLoaderê°€ ê´€ë¦¬)
            if self.model_interface and hasattr(self.model_interface, 'cleanup'):
                await self.model_interface.cleanup()
            
            # RemBG ì„¸ì…˜ ì •ë¦¬
            self.rembg_sessions.clear()
            
            # ìºì‹œ ì •ë¦¬
            with self.cache_lock:
                self.segmentation_cache.clear()
            
            # ì‹¤í–‰ì ì •ë¦¬
            if hasattr(self, 'executor'):
                self.executor.shutdown(wait=False)
            
            # GPU ë©”ëª¨ë¦¬ ì •ë¦¬
            if self.device == "mps" and torch.backends.mps.is_available():
                torch.mps.empty_cache()
            elif self.device == "cuda" and torch.cuda.is_available():
                torch.cuda.empty_cache()
            
            # ê°€ë¹„ì§€ ì»¬ë ‰ì…˜
            gc.collect()
            
            self.is_initialized = False
            self.logger.info("âœ… ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì™„ë£Œ")
            
        except Exception as e:
            self.logger.warning(f"ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")

    def __del__(self):
        """ì†Œë©¸ì"""
        try:
            if hasattr(self, 'executor'):
                self.executor.shutdown(wait=False)
        except Exception:
            pass

# ==============================================
# 5. íŒ©í† ë¦¬ í•¨ìˆ˜ë“¤ (ê¸°ì¡´ ì´ë¦„ ìœ ì§€)
# ==============================================

def create_cloth_segmentation_step(
    device: Optional[str] = None,
    config: Optional[Dict[str, Any]] = None,
    **kwargs
) -> ClothSegmentationStep:
    """ClothSegmentationStep íŒ©í† ë¦¬ í•¨ìˆ˜"""
    return ClothSegmentationStep(device=device, config=config, **kwargs)

def create_m3_max_segmentation_step(
    config: Optional[Dict[str, Any]] = None,
    **kwargs
) -> ClothSegmentationStep:
    """M3 Max ìµœì í™”ëœ ClothSegmentationStep ìƒì„±"""
    m3_config = {
        'method': SegmentationMethod.AUTO,
        'quality_level': QualityLevel.HIGH,
        'use_fp16': True,
        'batch_size': 8,  # M3 Max 128GB í™œìš©
        'cache_size': 200,
        'enable_visualization': True,
        'visualization_quality': 'high',
        'enable_edge_refinement': True,
        'enable_hole_filling': True
    }
    
    if config:
        m3_config.update(config)
    
    return ClothSegmentationStep(device="mps", config=m3_config, **kwargs)

def create_production_segmentation_step(
    device: Optional[str] = None,
    **kwargs
) -> ClothSegmentationStep:
    """í”„ë¡œë•ì…˜ í™˜ê²½ìš© ClothSegmentationStep ìƒì„±"""
    production_config = {
        'method': SegmentationMethod.AUTO,  # ì•ˆì •ì„± ìš°ì„ 
        'quality_level': QualityLevel.BALANCED,
        'enable_visualization': True,
        'enable_post_processing': True,
        'confidence_threshold': 0.7,
        'visualization_quality': 'medium',
        'enable_edge_refinement': True,
        'enable_hole_filling': True
    }
    
    return ClothSegmentationStep(device=device, config=production_config, **kwargs)

# ==============================================
# 6. ëª¨ë“ˆ ìµìŠ¤í¬íŠ¸ - ê¸°ì¡´ ì´ë¦„ ìœ ì§€
# ==============================================

__all__ = [
    # ë©”ì¸ í´ë˜ìŠ¤
    'ClothSegmentationStep',
    
    # ì—´ê±°í˜• ë° ë°ì´í„° í´ë˜ìŠ¤
    'SegmentationMethod',
    'ClothingType', 
    'QualityLevel',
    'SegmentationConfig',
    'SegmentationResult',
    
    # AI ëª¨ë¸ í´ë˜ìŠ¤ë“¤ (í´ë°±ìš©)
    'U2NET',
    'REBNCONV',
    'RSU7',
    
    # íŒ©í† ë¦¬ í•¨ìˆ˜ë“¤
    'create_cloth_segmentation_step',
    'create_m3_max_segmentation_step',
    'create_production_segmentation_step',
    
    # ì‹œê°í™” ê´€ë ¨
    'CLOTHING_COLORS'
]

# ëª¨ë“ˆ ì´ˆê¸°í™” ë¡œê¹…
logger.info("âœ… Step 03 ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ + ì‹œê°í™” ëª¨ë“ˆ ì™„ì „ êµ¬í˜„ ì™„ë£Œ")
logger.info(f"   - BaseStepMixin ì—°ë™: {'âœ…' if BASE_STEP_MIXIN_AVAILABLE else 'âš ï¸ í´ë°±'}")
logger.info(f"   - Model Loader ì—°ë™: {'âœ…' if MODEL_LOADER_AVAILABLE else 'âŒ'}")
logger.info(f"   - Memory Manager ì—°ë™: {'âœ…' if MEMORY_MANAGER_AVAILABLE else 'âŒ'}")
logger.info(f"   - RemBG ì‚¬ìš© ê°€ëŠ¥: {'âœ…' if REMBG_AVAILABLE else 'âŒ'}")
logger.info(f"   - SAM ì‚¬ìš© ê°€ëŠ¥: {'âœ…' if SAM_AVAILABLE else 'âŒ'}")
logger.info(f"   - Transformers ì‚¬ìš© ê°€ëŠ¥: {'âœ…' if TRANSFORMERS_AVAILABLE else 'âŒ'}")
logger.info(f"   - scikit-learn ì‚¬ìš© ê°€ëŠ¥: {'âœ…' if SKLEARN_AVAILABLE else 'âŒ'}")
logger.info("ğŸ”¥ ìˆœí™˜ì°¸ì¡° ì™„ì „ í•´ê²°, í•œë°©í–¥ ì°¸ì¡° êµ¬ì¡° êµ¬í˜„")
logger.info("ğŸ¨ ì™„ì „í•œ ì‹œê°í™”: ìƒ‰ìƒí™”, ì˜¤ë²„ë ˆì´, ë§ˆìŠ¤í¬, ê²½ê³„ì„ , ì¢…í•©")
logger.info("ğŸš€ 8ê°€ì§€ ë°©ë²•: U2NET, RemBG, SAM, DeepLab, Traditional, Hybrid, AUTO")
logger.info("ğŸ”§ ê³ ê¸‰ í›„ì²˜ë¦¬: ê²½ê³„ ê°œì„ , í™€ ì±„ìš°ê¸°, í˜•íƒœí•™ì  ì²˜ë¦¬")
logger.info("ğŸ M3 Max ìµœì í™”: ì›Œë°ì—…, ë©”ëª¨ë¦¬ ê´€ë¦¬, Neural Engine")
logger.info("ğŸ—ï¸ í”„ë¡œë•ì…˜ ì•ˆì •ì„±: ìºì‹œ, í†µê³„, í´ë°±, ì—ëŸ¬ ì²˜ë¦¬")

# ==============================================
# 7. í…ŒìŠ¤íŠ¸ ë° ì˜ˆì‹œ í•¨ìˆ˜ë“¤
# ==============================================

async def test_cloth_segmentation_complete():
    """ì™„ì „í•œ ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ í…ŒìŠ¤íŠ¸"""
    print("ğŸ§ª ì™„ì „í•œ ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    
    try:
        # Step ìƒì„±
        step = create_cloth_segmentation_step(
            device="auto",
            config={
                "method": "auto",
                "enable_visualization": True,
                "visualization_quality": "high",
                "quality_level": "balanced"
            }
        )
        
        # ì´ˆê¸°í™”
        await step.initialize()
        
        # ë”ë¯¸ ì´ë¯¸ì§€ ìƒì„±
        dummy_image = Image.new('RGB', (512, 512), (200, 150, 100))
        
        # ì²˜ë¦¬ ì‹¤í–‰
        result = await step.process(dummy_image, clothing_type="shirt", quality_level="high")
        
        # ê²°ê³¼ í™•ì¸
        if result['success']:
            print("âœ… ì²˜ë¦¬ ì„±ê³µ!")
            print(f"   - ì˜ë¥˜ íƒ€ì…: {result['clothing_type']}")
            print(f"   - ì‹ ë¢°ë„: {result['confidence']:.3f}")
            print(f"   - ì²˜ë¦¬ ì‹œê°„: {result['processing_time']:.2f}ì´ˆ")
            print(f"   - ì‚¬ìš© ë°©ë²•: {result['method_used']}")
            
            if 'visualization_base64' in result:
                print("   - ì‹œê°í™” ì´ë¯¸ì§€ ìƒì„±ë¨")
            if 'overlay_base64' in result:
                print("   - ì˜¤ë²„ë ˆì´ ì´ë¯¸ì§€ ìƒì„±ë¨")
        else:
            print(f"âŒ ì²˜ë¦¬ ì‹¤íŒ¨: {result.get('error', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}")
        
        # ì •ë³´ ì¶œë ¥
        info = step.get_segmentation_info()
        print(f"\nğŸ“Š ì‹œìŠ¤í…œ ì •ë³´:")
        print(f"   - ë””ë°”ì´ìŠ¤: {info['device']}")
        print(f"   - ì‚¬ìš© ê°€ëŠ¥í•œ ë°©ë²•: {info['available_methods']}")
        print(f"   - ë¡œë“œëœ ëª¨ë¸: {info['loaded_models']}")
        
        # ì •ë¦¬
        await step.cleanup()
        print("âœ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ ë° ì •ë¦¬")
        
    except Exception as e:
        print(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")

def example_usage():
    """ì‚¬ìš© ì˜ˆì‹œ"""
    print("ğŸ”¥ MyCloset AI Step 03 - ì™„ì „í•œ ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‚¬ìš© ì˜ˆì‹œ")
    print("=" * 70)
    
    print("""
# 1. ê¸°ë³¸ ì‚¬ìš©ë²• (8ê°€ì§€ ë°©ë²• ì§€ì›)
from app.ai_pipeline.steps.step_03_cloth_segmentation import create_cloth_segmentation_step

# AUTO ë°©ë²• (ìµœì  ì„ íƒ)
step = create_cloth_segmentation_step(device="mps", config={"method": "auto"})

# ì´ˆê¸°í™”
await step.initialize()

# ì´ë¯¸ì§€ ì²˜ë¦¬ (ì™„ì „í•œ ì‹œê°í™” í¬í•¨)
result = await step.process(image, clothing_type="shirt", quality_level="high")

# 2. M3 Max ìµœì í™” ë²„ì „ (128GB í™œìš©)
step = create_m3_max_segmentation_step({
    "quality_level": "ultra",
    "enable_visualization": True,
    "enable_edge_refinement": True,
    "enable_hole_filling": True
})

# 3. í”„ë¡œë•ì…˜ ë²„ì „ (ì•ˆì •ì„± + ì„±ëŠ¥ ìµœì í™”)
step = create_production_segmentation_step(device="cpu")

# 4. ê³ ê¸‰ ì„¤ì • (ëª¨ë“  ê¸°ëŠ¥ í™œìš©)
config = {
    "method": "hybrid",          # í•˜ì´ë¸Œë¦¬ë“œ ë°©ë²•
    "quality_level": "ultra",    # ìµœê³  í’ˆì§ˆ
    "confidence_threshold": 0.8,
    "enable_visualization": True,
    "enable_edge_refinement": True,
    "enable_hole_filling": True,
    "overlay_opacity": 0.6
}
step = create_cloth_segmentation_step(config=config)

# 5. ì™„ì „í•œ ê²°ê³¼ í™œìš©
if result['success']:
    # 4ê°€ì§€ ì‹œê°í™” ì´ë¯¸ì§€
    visualization = result['visualization_base64']  # ì¢…í•© ì‹œê°í™”
    overlay = result['overlay_base64']              # ì˜¤ë²„ë ˆì´
    mask = result['mask_base64']                    # ë§ˆìŠ¤í¬
    boundary = result['boundary_base64']            # ê²½ê³„ì„ 
    
    # ë©”íƒ€ë°ì´í„° ë° í†µê³„
    clothing_type = result['clothing_type']
    confidence = result['confidence']
    processing_time = result['processing_time']
    method_used = result['method_used']

# 6. ê³ ê¸‰ ê¸°ëŠ¥ë“¤
# ë°©ë²•ë³„ ìƒì„¸ ì •ë³´
method_info = step.get_segmentation_method_info("hybrid")
print(f"í•˜ì´ë¸Œë¦¬ë“œ ë°©ë²•: {method_info}")

# ì˜ë¥˜ë³„ ë§ˆìŠ¤í¬ ìƒì„±
clothing_mask = step.get_clothing_mask(result['mask'], "shirt")

# ë§ˆìŠ¤í¬ í†µê³„ ë¶„ì„
stats = step.get_mask_statistics(result['mask'])
print(f"ì»¤ë²„ë¦¬ì§€: {stats['coverage_ratio']:.2%}")

# ë””ë²„ê¹…ìš© ì‹œê°í™”
debug_viz = step.visualize_segmentation(result['mask'], "shirt")

# ì‹œìŠ¤í…œ ì •ë³´ ì¡°íšŒ
info = step.get_segmentation_info()
print(f"ì‚¬ìš© ê°€ëŠ¥í•œ ë°©ë²•: {info['available_methods']}")
print(f"ì²˜ë¦¬ í†µê³„: {info['processing_stats']}")

# ë¦¬ì†ŒìŠ¤ ì •ë¦¬
await step.cleanup()
""")

if __name__ == "__main__":
    """ì§ì ‘ ì‹¤í–‰ ì‹œ í…ŒìŠ¤íŠ¸"""
    print("ğŸ”¥ Step 03 ì™„ì „í•œ ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ - ì§ì ‘ ì‹¤í–‰ í…ŒìŠ¤íŠ¸")
    
    # ì˜ˆì‹œ ì¶œë ¥
    example_usage()
    
    # ì‹¤ì œ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ (ë¹„ë™ê¸°)
    import asyncio
    try:
        asyncio.run(test_cloth_segmentation_complete())
    except Exception as e:
        print(f"âŒ ë¹„ë™ê¸° í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
        print("ğŸ’¡ Jupyter í™˜ê²½ì—ì„œëŠ” 'await test_cloth_segmentation_complete()' ì‚¬ìš©")