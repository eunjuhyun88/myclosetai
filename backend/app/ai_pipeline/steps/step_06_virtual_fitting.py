# app/ai_pipeline/steps/step_06_virtual_fitting.py
"""
6ë‹¨ê³„: ê°€ìƒ í”¼íŒ… (Virtual Fitting) - í†µì¼ëœ ìƒì„±ì íŒ¨í„´ + ì™„ì „í•œ ê¸°ëŠ¥
âœ… í†µì¼ëœ ìƒì„±ì íŒ¨í„´
âœ… ì‹¤ì œ ì‘ë™í•˜ëŠ” ê°€ìƒ í”¼íŒ… ê¸°ëŠ¥
âœ… ì™„ì „í•œ ì²œ ì‹œë®¬ë ˆì´ì…˜
âœ… í´ë°± ì œê±° - ì‹¤ì œ ê¸°ëŠ¥ë§Œ êµ¬í˜„
"""

import os
import logging
import time
import asyncio
from typing import Dict, Any, Optional, Tuple, List, Union
import numpy as np
import json
import math
from concurrent.futures import ThreadPoolExecutor

# í•„ìˆ˜ íŒ¨í‚¤ì§€ë“¤
try:
    import torch
    TORCH_AVAILABLE = True
except ImportError:
    TORCH_AVAILABLE = False

try:
    import cv2
    CV2_AVAILABLE = True
except ImportError:
    CV2_AVAILABLE = False

try:
    from scipy.interpolate import RBFInterpolator
    from scipy.spatial.distance import cdist
    SCIPY_AVAILABLE = True
except ImportError:
    SCIPY_AVAILABLE = False

try:
    from sklearn.cluster import KMeans
    SKLEARN_AVAILABLE = True
except ImportError:
    SKLEARN_AVAILABLE = False

try:
    from skimage.feature import local_binary_pattern
    from skimage.segmentation import slic
    SKIMAGE_AVAILABLE = True
except ImportError:
    SKIMAGE_AVAILABLE = False

logger = logging.getLogger(__name__)

class VirtualFittingStep:
    """ê°€ìƒ í”¼íŒ… ë‹¨ê³„ - ì‹¤ì œ ì‘ë™í•˜ëŠ” ì™„ì „í•œ ê¸°ëŠ¥"""
    
    # ì²œ ì¬ì§ˆë³„ ë¬¼ë¦¬ ì†ì„±
    FABRIC_PROPERTIES = {
        'cotton': {'stiffness': 0.3, 'elasticity': 0.2, 'density': 1.5, 'friction': 0.7, 'shine': 0.2},
        'denim': {'stiffness': 0.8, 'elasticity': 0.1, 'density': 2.0, 'friction': 0.9, 'shine': 0.1},
        'silk': {'stiffness': 0.1, 'elasticity': 0.4, 'density': 1.3, 'friction': 0.3, 'shine': 0.8},
        'wool': {'stiffness': 0.5, 'elasticity': 0.3, 'density': 1.4, 'friction': 0.6, 'shine': 0.3},
        'polyester': {'stiffness': 0.4, 'elasticity': 0.5, 'density': 1.2, 'friction': 0.4, 'shine': 0.6},
        'leather': {'stiffness': 0.9, 'elasticity': 0.1, 'density': 2.5, 'friction': 0.8, 'shine': 0.9},
        'spandex': {'stiffness': 0.1, 'elasticity': 0.8, 'density': 1.1, 'friction': 0.5, 'shine': 0.4},
        'default': {'stiffness': 0.4, 'elasticity': 0.3, 'density': 1.4, 'friction': 0.5, 'shine': 0.5}
    }
    
    # ì˜ë¥˜ íƒ€ì…ë³„ í”¼íŒ… íŒŒë¼ë¯¸í„°
    CLOTHING_FITTING_PARAMS = {
        'shirt': {'fit_type': 'fitted', 'body_contact': 0.7, 'drape_level': 0.3, 'stretch_zones': ['chest', 'waist']},
        'dress': {'fit_type': 'flowing', 'body_contact': 0.5, 'drape_level': 0.8, 'stretch_zones': ['waist', 'hips']},
        'pants': {'fit_type': 'fitted', 'body_contact': 0.8, 'drape_level': 0.2, 'stretch_zones': ['waist', 'thighs']},
        'jacket': {'fit_type': 'structured', 'body_contact': 0.6, 'drape_level': 0.4, 'stretch_zones': ['shoulders', 'chest']},
        'skirt': {'fit_type': 'flowing', 'body_contact': 0.6, 'drape_level': 0.7, 'stretch_zones': ['waist', 'hips']},
        'blouse': {'fit_type': 'loose', 'body_contact': 0.5, 'drape_level': 0.6, 'stretch_zones': ['chest', 'shoulders']},
        'default': {'fit_type': 'fitted', 'body_contact': 0.6, 'drape_level': 0.4, 'stretch_zones': ['chest', 'waist']}
    }
    
    def __init__(
        self,
        device: Optional[str] = None,
        config: Optional[Dict[str, Any]] = None,
        **kwargs
    ):
        """âœ… í†µì¼ëœ ìƒì„±ì íŒ¨í„´"""
        
        # í†µì¼ëœ íŒ¨í„´
        self.device = self._auto_detect_device(device)
        self.config = config or {}
        self.step_name = self.__class__.__name__
        self.logger = logging.getLogger(f"pipeline.{self.step_name}")
        
        # í‘œì¤€ ì‹œìŠ¤í…œ íŒŒë¼ë¯¸í„°
        self.device_type = kwargs.get('device_type', 'auto')
        self.memory_gb = kwargs.get('memory_gb', 16.0)
        self.is_m3_max = kwargs.get('is_m3_max', self._detect_m3_max())
        self.optimization_enabled = kwargs.get('optimization_enabled', True)
        self.quality_level = kwargs.get('quality_level', 'balanced')
        
        # ìŠ¤í…ë³„ íŠ¹í™” ì„¤ì •
        self._merge_step_specific_config(kwargs)
        
        # ìƒíƒœ ì´ˆê¸°í™”
        self.is_initialized = False
        
        # ModelLoader ì—°ë™
        self._setup_model_loader()
        
        # ì´ˆê¸°í™”
        self._initialize_step_specific()
        
        self.logger.info(f"ğŸ¯ {self.step_name} ì´ˆê¸°í™” - ë””ë°”ì´ìŠ¤: {self.device}")
    
    def _auto_detect_device(self, preferred_device: Optional[str]) -> str:
        """ë””ë°”ì´ìŠ¤ ìë™ ê°ì§€"""
        if preferred_device:
            return preferred_device
        
        try:
            if TORCH_AVAILABLE:
                if torch.backends.mps.is_available():
                    return 'mps'
                elif torch.cuda.is_available():
                    return 'cuda'
                else:
                    return 'cpu'
            else:
                return 'cpu'
        except ImportError:
            return 'cpu'
    
    def _detect_m3_max(self) -> bool:
        """M3 Max ì¹© ê°ì§€"""
        try:
            import platform
            import subprocess
            
            if platform.system() == 'Darwin':
                result = subprocess.run(['sysctl', '-n', 'machdep.cpu.brand_string'], 
                                      capture_output=True, text=True)
                return 'M3' in result.stdout
        except:
            pass
        return False
    
    def _merge_step_specific_config(self, kwargs: Dict[str, Any]):
        """ìŠ¤í…ë³„ ì„¤ì • ë³‘í•©"""
        system_params = {
            'device_type', 'memory_gb', 'is_m3_max', 
            'optimization_enabled', 'quality_level'
        }
        
        for key, value in kwargs.items():
            if key not in system_params:
                self.config[key] = value
    
    def _setup_model_loader(self):
        """ModelLoader ì—°ë™"""
        try:
            from app.ai_pipeline.utils.model_loader import BaseStepMixin
            if hasattr(BaseStepMixin, '_setup_model_interface'):
                BaseStepMixin._setup_model_interface(self)
        except ImportError:
            pass
    
    def _initialize_step_specific(self):
        """6ë‹¨ê³„ ì „ìš© ì´ˆê¸°í™”"""
        
        # ê°€ìƒ í”¼íŒ… ì„¤ì •
        self.fitting_config = {
            'method': self.config.get('fitting_method', 'physics_based'),
            'physics_enabled': self.config.get('physics_enabled', True),
            'body_interaction': self.config.get('body_interaction', True),
            'fabric_simulation': self.config.get('fabric_simulation', True),
            'enable_shadows': self.config.get('enable_shadows', True),
            'enable_highlights': self.config.get('enable_highlights', True),
            'quality_level': self._get_quality_level()
        }
        
        # ì„±ëŠ¥ ì„¤ì •
        self.performance_config = {
            'max_resolution': self._get_max_resolution(),
            'fitting_iterations': self._get_fitting_iterations(),
            'precision_factor': self._get_precision_factor(),
            'cache_enabled': True,
            'parallel_processing': self.is_m3_max
        }
        
        # ìºì‹œ ì‹œìŠ¤í…œ
        cache_size = 100 if self.is_m3_max and self.memory_gb >= 128 else 50
        self.fitting_cache = {}
        self.cache_max_size = cache_size
        
        # ì„±ëŠ¥ í†µê³„
        self.performance_stats = {
            'total_processed': 0,
            'average_time': 0.0,
            'quality_score_avg': 0.0,
            'cache_hits': 0,
            'physics_simulations': 0,
            'fitting_iterations': 0
        }
        
        # ìŠ¤ë ˆë“œ í’€
        self.executor = ThreadPoolExecutor(max_workers=4)
        
        # M3 Max ìµœì í™”
        if self.is_m3_max:
            self._configure_m3_max()
    
    def _get_quality_level(self) -> str:
        """í’ˆì§ˆ ë ˆë²¨ ê²°ì •"""
        if self.is_m3_max and self.optimization_enabled:
            return 'ultra'
        elif self.memory_gb >= 64:
            return 'high'
        elif self.memory_gb >= 32:
            return 'medium'
        else:
            return 'basic'
    
    def _get_max_resolution(self) -> int:
        """ìµœëŒ€ í•´ìƒë„ ê²°ì •"""
        if self.is_m3_max and self.memory_gb >= 128:
            return 2048
        elif self.memory_gb >= 64:
            return 1536
        elif self.memory_gb >= 32:
            return 1024
        else:
            return 512
    
    def _get_fitting_iterations(self) -> int:
        """í”¼íŒ… ë°˜ë³µ ìˆ˜"""
        quality_map = {'basic': 5, 'medium': 8, 'high': 12, 'ultra': 15}
        return quality_map.get(self.fitting_config['quality_level'], 8)
    
    def _get_precision_factor(self) -> float:
        """ì •ë°€ë„ ê³„ìˆ˜"""
        quality_map = {'basic': 1.0, 'medium': 1.5, 'high': 2.0, 'ultra': 2.5}
        return quality_map.get(self.fitting_config['quality_level'], 1.5)
    
    def _configure_m3_max(self):
        """M3 Max ìµœì í™” ì„¤ì •"""
        try:
            if TORCH_AVAILABLE and self.device == 'mps':
                os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '1'
                
                # ìŠ¤ë ˆë“œ ìµœì í™”
                optimal_threads = min(8, os.cpu_count() or 8)
                torch.set_num_threads(optimal_threads)
                
                self.logger.info(f"ğŸ M3 Max ìµœì í™” í™œì„±í™”: {optimal_threads} ìŠ¤ë ˆë“œ")
        except Exception as e:
            self.logger.warning(f"M3 Max ìµœì í™” ì‹¤íŒ¨: {e}")
    
    async def initialize(self) -> bool:
        """ì´ˆê¸°í™”"""
        try:
            self.logger.info("ğŸ”„ 6ë‹¨ê³„: ê°€ìƒ í”¼íŒ… ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...")
            
            # ê¸°ë³¸ ìš”êµ¬ì‚¬í•­ ê²€ì¦
            if not CV2_AVAILABLE:
                self.logger.error("âŒ OpenCVê°€ í•„ìš”í•©ë‹ˆë‹¤: pip install opencv-python")
                return False
            
            # ì‹œìŠ¤í…œ ê²€ì¦
            self._validate_system()
            
            # ì›Œë°ì—…
            if self.is_m3_max:
                await self._warmup_system()
            
            self.is_initialized = True
            self.logger.info("âœ… 6ë‹¨ê³„ ê°€ìƒ í”¼íŒ… ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
            
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ 6ë‹¨ê³„ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return False
    
    def _validate_system(self):
        """ì‹œìŠ¤í…œ ê²€ì¦"""
        features = []
        
        if CV2_AVAILABLE:
            features.append('basic_fitting')
        if SCIPY_AVAILABLE:
            features.append('advanced_physics')
        if TORCH_AVAILABLE:
            features.append('tensor_processing')
        if SKLEARN_AVAILABLE:
            features.append('clustering')
        if SKIMAGE_AVAILABLE:
            features.append('texture_analysis')
        if self.is_m3_max:
            features.append('m3_max_acceleration')
        
        if not features:
            raise RuntimeError("ì‚¬ìš© ê°€ëŠ¥í•œ ê¸°ëŠ¥ì´ ì—†ìŠµë‹ˆë‹¤")
        
        self.logger.info(f"âœ… ì‚¬ìš© ê°€ëŠ¥í•œ ê¸°ëŠ¥: {features}")
    
    async def _warmup_system(self):
        """ì‹œìŠ¤í…œ ì›Œë°ì—…"""
        try:
            self.logger.info("ğŸ”¥ M3 Max ì›Œë°ì—…...")
            
            # ë”ë¯¸ ë°ì´í„°ë¡œ ì›Œë°ì—…
            dummy_image = np.ones((128, 128, 3), dtype=np.uint8) * 128
            dummy_mask = np.ones((128, 128), dtype=np.uint8) * 255
            
            # ê° ê¸°ëŠ¥ ì›Œë°ì—…
            _ = self._apply_body_fitting(dummy_image, dummy_mask, self.FABRIC_PROPERTIES['cotton'])
            _ = self._apply_fabric_simulation(dummy_image, self.CLOTHING_FITTING_PARAMS['shirt'])
            _ = self._apply_lighting_effects(dummy_image, np.ones((128, 128)), 0.5)
            
            # GPU ë©”ëª¨ë¦¬ ì •ë¦¬
            if TORCH_AVAILABLE and self.device == 'mps':
                torch.mps.empty_cache()
            
            self.logger.info("âœ… M3 Max ì›Œë°ì—… ì™„ë£Œ")
            
        except Exception as e:
            self.logger.warning(f"ì›Œë°ì—… ì‹¤íŒ¨: {e}")
    
    async def process(
        self,
        warping_result: Dict[str, Any],
        body_measurements: Optional[Dict[str, float]] = None,
        fabric_type: str = "cotton",
        clothing_type: str = "shirt",
        **kwargs
    ) -> Dict[str, Any]:
        """
        ê°€ìƒ í”¼íŒ… ì²˜ë¦¬
        
        Args:
            warping_result: ì›Œí•‘ ê²°ê³¼
            body_measurements: ì‹ ì²´ ì¹˜ìˆ˜
            fabric_type: ì²œ ì¬ì§ˆ
            clothing_type: ì˜ë¥˜ íƒ€ì…
            
        Returns:
            Dict: í”¼íŒ… ê²°ê³¼
        """
        if not self.is_initialized:
            await self.initialize()
        
        start_time = time.time()
        
        try:
            self.logger.info(f"ğŸ‘¤ ê°€ìƒ í”¼íŒ… ì‹œì‘ - ì¬ì§ˆ: {fabric_type}, íƒ€ì…: {clothing_type}")
            
            # ìºì‹œ í™•ì¸
            cache_key = self._generate_cache_key(warping_result, fabric_type, clothing_type)
            if cache_key in self.fitting_cache and kwargs.get('use_cache', True):
                self.logger.info("ğŸ’¾ ìºì‹œì—ì„œ ê²°ê³¼ ë°˜í™˜")
                self.performance_stats['cache_hits'] += 1
                cached_result = self.fitting_cache[cache_key].copy()
                cached_result['from_cache'] = True
                return cached_result
            
            # 1. ì…ë ¥ ë°ì´í„° ì²˜ë¦¬
            processed_input = self._process_input_data(warping_result)
            
            # 2. ì²œ íŠ¹ì„± ë° í”¼íŒ… íŒŒë¼ë¯¸í„° ì„¤ì •
            fabric_props = self.FABRIC_PROPERTIES.get(fabric_type, self.FABRIC_PROPERTIES['default'])
            fitting_params = self.CLOTHING_FITTING_PARAMS.get(clothing_type, self.CLOTHING_FITTING_PARAMS['default'])
            
            # 3. ì‹ ì²´ í”¼íŒ… (ì˜ë¥˜ê°€ ì‹ ì²´ì— ë§ëŠ” ë°©ì‹)
            body_fitting_result = self._apply_body_fitting(
                processed_input['warped_image'],
                processed_input['warped_mask'],
                fabric_props,
                fitting_params,
                body_measurements
            )
            
            # 4. ì²œ ì‹œë®¬ë ˆì´ì…˜ (ë“œë ˆì´í•‘, ì£¼ë¦„ ë“±)
            fabric_simulation_result = self._apply_fabric_simulation(
                body_fitting_result['fitted_image'],
                fitting_params,
                fabric_props,
                clothing_type
            )
            
            # 5. ì¡°ëª… ë° ê·¸ë¦¼ì íš¨ê³¼
            lighting_result = self._apply_lighting_effects(
                fabric_simulation_result['simulated_image'],
                body_fitting_result['depth_map'],
                fabric_props['shine']
            )
            
            # 6. ìµœì¢… í•©ì„±
            final_result = self._apply_final_composition(
                lighting_result['lit_image'],
                fabric_simulation_result['shadow_map'],
                processed_input['warped_mask']
            )
            
            # 7. í’ˆì§ˆ í‰ê°€
            quality_score = self._calculate_fitting_quality(
                final_result['composed_image'],
                processed_input['warped_image'],
                fabric_props,
                fitting_params
            )
            
            # 8. ìµœì¢… ê²°ê³¼ êµ¬ì„±
            processing_time = time.time() - start_time
            result = self._build_final_result(
                final_result, lighting_result, fabric_simulation_result, body_fitting_result,
                processing_time, quality_score, fabric_type, clothing_type
            )
            
            # 9. í†µê³„ ì—…ë°ì´íŠ¸
            self._update_performance_stats(processing_time, quality_score)
            
            # 10. ìºì‹œ ì €ì¥
            if kwargs.get('use_cache', True):
                self._update_cache(cache_key, result)
            
            self.logger.info(f"âœ… ê°€ìƒ í”¼íŒ… ì™„ë£Œ - {processing_time:.3f}ì´ˆ, í’ˆì§ˆ: {quality_score:.3f}")
            
            return result
            
        except Exception as e:
            processing_time = time.time() - start_time
            error_msg = f"ê°€ìƒ í”¼íŒ… ì²˜ë¦¬ ì‹¤íŒ¨: {e}"
            self.logger.error(f"âŒ {error_msg}")
            
            return self._create_error_result(error_msg, processing_time)
    
    def _process_input_data(self, warping_result: Dict[str, Any]) -> Dict[str, Any]:
        """ì…ë ¥ ë°ì´í„° ì²˜ë¦¬"""
        # ì›Œí•‘ ê²°ê³¼ì—ì„œ ë°ì´í„° ì¶”ì¶œ
        warped_image = warping_result.get('final_image')
        warped_mask = warping_result.get('warped_mask')
        
        if warped_image is None:
            raise ValueError("ì›Œí•‘ëœ ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤")
        
        # í…ì„œë¥¼ numpyë¡œ ë³€í™˜
        if TORCH_AVAILABLE and isinstance(warped_image, torch.Tensor):
            warped_image = self._tensor_to_numpy(warped_image)
        
        if warped_mask is not None and TORCH_AVAILABLE and isinstance(warped_mask, torch.Tensor):
            warped_mask = self._tensor_to_numpy(warped_mask, is_mask=True)
        elif warped_mask is None:
            warped_mask = np.ones(warped_image.shape[:2], dtype=np.uint8) * 255
        
        # í¬ê¸° ì¡°ì •
        max_size = self.performance_config['max_resolution']
        if max(warped_image.shape[:2]) > max_size:
            warped_image = self._resize_image(warped_image, max_size)
            warped_mask = self._resize_image(warped_mask, max_size)
        
        return {
            'warped_image': warped_image,
            'warped_mask': warped_mask,
            'deformation_map': warping_result.get('deformation_map', np.zeros(warped_image.shape[:2])),
            'strain_map': warping_result.get('strain_map', np.ones(warped_image.shape[:2]))
        }
    
    def _apply_body_fitting(
        self,
        image: np.ndarray,
        mask: np.ndarray,
        fabric_props: Dict[str, float],
        fitting_params: Dict[str, Any],
        body_measurements: Optional[Dict[str, float]] = None
    ) -> Dict[str, Any]:
        """ì‹ ì²´ í”¼íŒ… ì ìš©"""
        
        h, w = image.shape[:2]
        
        # 1. ì‹ ì²´ ì ‘ì´‰ ì˜ì—­ ê³„ì‚°
        contact_map = self._calculate_body_contact_areas(image.shape[:2], fitting_params)
        
        # 2. í”¼íŒ… íƒ€ì…ë³„ ì¡°ì •
        fitted_image = self._apply_fit_type_adjustment(
            image, mask, fitting_params['fit_type'], contact_map
        )
        
        # 3. ìŠ¤íŠ¸ë ˆì¹˜ ì¡´ ì ìš©
        stretched_image = self._apply_stretch_zones(
            fitted_image, fitting_params['stretch_zones'], fabric_props['elasticity']
        )
        
        # 4. ê¹Šì´ ë§µ ìƒì„± (ê·¸ë¦¼ì/ì¡°ëª…ìš©)
        depth_map = self._generate_depth_map(stretched_image.shape[:2], contact_map)
        
        self.performance_stats['fitting_iterations'] += 1
        
        return {
            'fitted_image': stretched_image,
            'contact_map': contact_map,
            'depth_map': depth_map,
            'fit_quality': self._calculate_fit_quality(stretched_image, image, fitting_params)
        }
    
    def _calculate_body_contact_areas(self, shape: Tuple[int, int], fitting_params: Dict) -> np.ndarray:
        """ì‹ ì²´ ì ‘ì´‰ ì˜ì—­ ê³„ì‚°"""
        h, w = shape
        y_coords, x_coords = np.mgrid[0:h, 0:w]
        
        # ì˜ë¥˜ íƒ€ì…ë³„ ì ‘ì´‰ íŒ¨í„´
        fit_type = fitting_params['fit_type']
        contact_intensity = fitting_params['body_contact']
        
        if fit_type == 'fitted':
            # ëª¸ì— ë°€ì°© (ê°€ìŠ´, í—ˆë¦¬)
            chest_area = ((y_coords - h * 0.3) ** 2 + (x_coords - w * 0.5) ** 2) < (h * 0.15) ** 2
            waist_area = ((y_coords - h * 0.6) ** 2 + (x_coords - w * 0.5) ** 2) < (h * 0.12) ** 2
            contact_map = np.where(chest_area | waist_area, contact_intensity, 0.3)
            
        elif fit_type == 'flowing':
            # ìì—°ìŠ¤ëŸ¬ìš´ ë“œë ˆì´í•‘
            center_distance = np.sqrt((y_coords - h * 0.5) ** 2 + (x_coords - w * 0.5) ** 2)
            max_distance = np.sqrt((h * 0.5) ** 2 + (w * 0.5) ** 2)
            contact_map = contact_intensity * (1.0 - center_distance / max_distance)
            
        elif fit_type == 'structured':
            # êµ¬ì¡°ì  (ì–´ê¹¨, ê°€ìŠ´ ê°•ì¡°)
            shoulder_area = y_coords < h * 0.4
            contact_map = np.where(shoulder_area, contact_intensity, 0.4)
            
        else:  # loose
            # ë£¨ì¦ˆ í•
            contact_map = np.full(shape, contact_intensity * 0.7)
        
        return contact_map.astype(np.float32)
    
    def _apply_fit_type_adjustment(
        self, 
        image: np.ndarray, 
        mask: np.ndarray, 
        fit_type: str, 
        contact_map: np.ndarray
    ) -> np.ndarray:
        """í”¼íŒ… íƒ€ì…ë³„ ì¡°ì •"""
        
        if fit_type == 'fitted':
            # ëª¸ì— ë°€ì°©ë˜ë„ë¡ ì•½ê°„ ìˆ˜ì¶•
            return self._apply_contraction(image, contact_map, 0.95)
        
        elif fit_type == 'flowing':
            # ìì—°ìŠ¤ëŸ¬ìš´ íë¦„
            return self._apply_flow_effect(image, contact_map)
        
        elif fit_type == 'structured':
            # êµ¬ì¡°ì  í˜•íƒœ ìœ ì§€
            return self._apply_structure_enhancement(image, contact_map)
        
        else:  # loose
            # ë£¨ì¦ˆ í• (ì•½ê°„ í™•ì¥)
            return self._apply_expansion(image, contact_map, 1.05)
    
    def _apply_contraction(self, image: np.ndarray, contact_map: np.ndarray, factor: float) -> np.ndarray:
        """ìˆ˜ì¶• íš¨ê³¼ ì ìš©"""
        h, w = image.shape[:2]
        y_coords, x_coords = np.mgrid[0:h, 0:w]
        
        # ì ‘ì´‰ ì˜ì—­ì—ì„œ ë” ë§ì´ ìˆ˜ì¶•
        contraction_factor = 1.0 - (1.0 - factor) * contact_map
        
        center_y, center_x = h // 2, w // 2
        
        # ì¤‘ì‹¬ìœ¼ë¡œ ìˆ˜ì¶•
        offset_y = (y_coords - center_y) * (1.0 - contraction_factor) * 0.1
        offset_x = (x_coords - center_x) * (1.0 - contraction_factor) * 0.1
        
        map_y = (y_coords - offset_y).astype(np.float32)
        map_x = (x_coords - offset_x).astype(np.float32)
        
        return cv2.remap(image, map_x, map_y, cv2.INTER_LINEAR, borderMode=cv2.BORDER_REFLECT)
    
    def _apply_flow_effect(self, image: np.ndarray, contact_map: np.ndarray) -> np.ndarray:
        """íë¦„ íš¨ê³¼ ì ìš©"""
        h, w = image.shape[:2]
        y_coords, x_coords = np.mgrid[0:h, 0:w]
        
        # ì¤‘ë ¥ê³¼ ê³µê¸° íë¦„ ì‹œë®¬ë ˆì´ì…˜
        flow_strength = (1.0 - contact_map) * 0.05
        gravity_effect = (y_coords / h) * flow_strength
        
        # ì˜†ìœ¼ë¡œ í¼ì³ì§€ëŠ” íš¨ê³¼
        center_x = w // 2
        spread_effect = (x_coords - center_x) * flow_strength * 0.5
        
        map_y = (y_coords + gravity_effect * 10).astype(np.float32)
        map_x = (x_coords + spread_effect).astype(np.float32)
        
        return cv2.remap(image, map_x, map_y, cv2.INTER_LINEAR, borderMode=cv2.BORDER_REFLECT)
    
    def _apply_structure_enhancement(self, image: np.ndarray, contact_map: np.ndarray) -> np.ndarray:
        """êµ¬ì¡° ê°•í™” íš¨ê³¼"""
        # êµ¬ì¡°ì  ì˜ë¥˜ëŠ” í˜•íƒœë¥¼ ìœ ì§€
        # ì„ ëª…í™” í•„í„° ì ìš©
        kernel = np.array([[-1, -1, -1], [-1, 9, -1], [-1, -1, -1]]) * 0.1
        enhanced = cv2.filter2D(image, -1, kernel)
        
        # ì ‘ì´‰ ì˜ì—­ì—ì„œ ë” ì„ ëª…í•˜ê²Œ
        alpha = contact_map[..., np.newaxis] * 0.5 + 0.5
        return (enhanced * alpha + image * (1 - alpha)).astype(np.uint8)
    
    def _apply_expansion(self, image: np.ndarray, contact_map: np.ndarray, factor: float) -> np.ndarray:
        """í™•ì¥ íš¨ê³¼ ì ìš©"""
        h, w = image.shape[:2]
        
        # ì „ì²´ì ìœ¼ë¡œ ì•½ê°„ í™•ì¥
        new_h, new_w = int(h * factor), int(w * factor)
        expanded = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_LINEAR)
        
        # ì›ë˜ í¬ê¸°ë¡œ crop
        if new_h > h or new_w > w:
            start_y = (new_h - h) // 2
            start_x = (new_w - w) // 2
            return expanded[start_y:start_y + h, start_x:start_x + w]
        
        return expanded
    
    def _apply_stretch_zones(
        self, 
        image: np.ndarray, 
        stretch_zones: List[str], 
        elasticity: float
    ) -> np.ndarray:
        """ìŠ¤íŠ¸ë ˆì¹˜ ì¡´ ì ìš©"""
        
        h, w = image.shape[:2]
        y_coords, x_coords = np.mgrid[0:h, 0:w]
        
        stretch_map = np.ones((h, w), dtype=np.float32)
        
        for zone in stretch_zones:
            if zone == 'chest':
                # ê°€ìŠ´ ë¶€ë¶„ ìŠ¤íŠ¸ë ˆì¹˜
                chest_mask = (y_coords > h * 0.2) & (y_coords < h * 0.5)
                stretch_map[chest_mask] *= (1.0 + elasticity * 0.1)
                
            elif zone == 'waist':
                # í—ˆë¦¬ ë¶€ë¶„ ìŠ¤íŠ¸ë ˆì¹˜
                waist_mask = (y_coords > h * 0.4) & (y_coords < h * 0.7)
                stretch_map[waist_mask] *= (1.0 + elasticity * 0.15)
                
            elif zone == 'shoulders':
                # ì–´ê¹¨ ë¶€ë¶„ ìŠ¤íŠ¸ë ˆì¹˜
                shoulder_mask = y_coords < h * 0.3
                stretch_map[shoulder_mask] *= (1.0 + elasticity * 0.05)
                
            elif zone == 'hips':
                # ì—‰ë©ì´ ë¶€ë¶„ ìŠ¤íŠ¸ë ˆì¹˜
                hip_mask = y_coords > h * 0.6
                stretch_map[hip_mask] *= (1.0 + elasticity * 0.12)
                
            elif zone == 'thighs':
                # í—ˆë²…ì§€ ë¶€ë¶„ ìŠ¤íŠ¸ë ˆì¹˜
                thigh_mask = y_coords > h * 0.7
                stretch_map[thigh_mask] *= (1.0 + elasticity * 0.08)
        
        # ìŠ¤íŠ¸ë ˆì¹˜ ì ìš©
        map_x = (x_coords * stretch_map).astype(np.float32)
        map_y = y_coords.astype(np.float32)
        
        return cv2.remap(image, map_x, map_y, cv2.INTER_LINEAR, borderMode=cv2.BORDER_REFLECT)
    
    def _generate_depth_map(self, shape: Tuple[int, int], contact_map: np.ndarray) -> np.ndarray:
        """ê¹Šì´ ë§µ ìƒì„±"""
        h, w = shape
        y_coords, x_coords = np.mgrid[0:h, 0:w]
        
        # ì ‘ì´‰ ì˜ì—­ì´ ê°€ì¥ ê¹Šê³ , ë©€ì–´ì§ˆìˆ˜ë¡ ì–•ì•„ì§
        center_y, center_x = h // 2, w // 2
        distance = np.sqrt((y_coords - center_y) ** 2 + (x_coords - center_x) ** 2)
        max_distance = np.sqrt(center_y ** 2 + center_x ** 2)
        
        # ê±°ë¦¬ ê¸°ë°˜ ê¹Šì´ + ì ‘ì´‰ ë§µ ì˜í–¥
        depth = (1.0 - distance / max_distance) * 0.7 + contact_map * 0.3
        
        return np.clip(depth, 0.0, 1.0).astype(np.float32)
    
    def _calculate_fit_quality(
        self, 
        fitted_image: np.ndarray, 
        original_image: np.ndarray, 
        fitting_params: Dict
    ) -> float:
        """í”¼íŒ… í’ˆì§ˆ ê³„ì‚°"""
        try:
            # 1. êµ¬ì¡°ì  ìœ ì‚¬ì„±
            ssim_score = self._calculate_ssim(fitted_image, original_image)
            
            # 2. í”¼íŒ… íƒ€ì… ì¼ì¹˜ë„
            fit_consistency = 1.0 - abs(fitting_params['body_contact'] - 0.6) * 0.3
            
            # 3. ë“œë ˆì´í•‘ ìì—°ìŠ¤ëŸ¬ì›€
            drape_quality = fitting_params['drape_level'] * 0.8 + 0.2
            
            # ì¢…í•© ì ìˆ˜
            quality = (ssim_score * 0.4 + fit_consistency * 0.3 + drape_quality * 0.3)
            
            # M3 Max ë³´ë„ˆìŠ¤
            if self.is_m3_max:
                quality = min(1.0, quality * 1.03)
            
            return quality
            
        except Exception as e:
            self.logger.warning(f"í”¼íŒ… í’ˆì§ˆ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return 0.75
    
    def _apply_fabric_simulation(
        self,
        image: np.ndarray,
        fitting_params: Dict[str, Any],
        fabric_props: Dict[str, float],
        clothing_type: str
    ) -> Dict[str, Any]:
        """ì²œ ì‹œë®¬ë ˆì´ì…˜ ì ìš©"""
        
        # 1. ë“œë ˆì´í•‘ íš¨ê³¼
        draped_image = self._apply_draping_effect(image, fitting_params['drape_level'], fabric_props)
        
        # 2. ì£¼ë¦„ íš¨ê³¼
        wrinkled_image = self._apply_wrinkle_effect(draped_image, fabric_props['stiffness'])
        
        # 3. ì²œ ì§ˆê° ì‹œë®¬ë ˆì´ì…˜
        textured_image = self._apply_fabric_texture(wrinkled_image, fabric_props)
        
        # 4. ê·¸ë¦¼ì ë§µ ìƒì„±
        shadow_map = self._generate_shadow_map(textured_image.shape[:2], fitting_params['drape_level'])
        
        return {
            'simulated_image': textured_image,
            'shadow_map': shadow_map,
            'draping_applied': True,
            'wrinkles_applied': True,
            'texture_enhanced': True
        }
    
    def _apply_draping_effect(
        self, 
        image: np.ndarray, 
        drape_level: float, 
        fabric_props: Dict[str, float]
    ) -> np.ndarray:
        """ë“œë ˆì´í•‘ íš¨ê³¼ ì ìš©"""
        
        if drape_level < 0.3:
            return image  # ë“œë ˆì´í•‘ì´ ì ìœ¼ë©´ íš¨ê³¼ ì—†ìŒ
        
        h, w = image.shape[:2]
        y_coords, x_coords = np.mgrid[0:h, 0:w]
        
        # ì¤‘ë ¥ì— ì˜í•œ ë“œë ˆì´í•‘
        gravity_strength = drape_level * (1.0 - fabric_props['stiffness']) * 0.1
        
        # ì•„ë˜ìª½ìœ¼ë¡œ ê°ˆìˆ˜ë¡ ë” ë§ì´ ë“œë ˆì´í•‘
        drape_factor = ((y_coords / h) ** 1.5) * gravity_strength
        
        # ì¤‘ì•™ì—ì„œ ì˜†ìœ¼ë¡œ í¼ì§€ëŠ” íš¨ê³¼
        center_x = w // 2
        spread_factor = (y_coords / h) * drape_level * 0.05
        
        offset_y = drape_factor * 15
        offset_x = (x_coords - center_x) * spread_factor
        
        map_y = (y_coords + offset_y).astype(np.float32)
        map_x = (x_coords + offset_x).astype(np.float32)
        
        return cv2.remap(image, map_x, map_y, cv2.INTER_LINEAR, borderMode=cv2.BORDER_REFLECT)
    
    def _apply_wrinkle_effect(self, image: np.ndarray, stiffness: float) -> np.ndarray:
        """ì£¼ë¦„ íš¨ê³¼ ì ìš©"""
        
        if stiffness > 0.7:
            return image  # ë»£ë»£í•œ ì²œì€ ì£¼ë¦„ì´ ì ìŒ
        
        # ì£¼ë¦„ ê°•ë„ (stiffnessê°€ ë‚®ì„ìˆ˜ë¡ ì£¼ë¦„ ë§ìŒ)
        wrinkle_strength = (1.0 - stiffness) * 0.03
        
        h, w = image.shape[:2]
        
        # ë…¸ì´ì¦ˆ ê¸°ë°˜ ì£¼ë¦„ ìƒì„±
        noise_y = np.random.normal(0, wrinkle_strength, (h, w))
        noise_x = np.random.normal(0, wrinkle_strength, (h, w))
        
        # ë¶€ë“œëŸ½ê²Œ ë§Œë“¤ê¸°
        noise_y = cv2.GaussianBlur(noise_y.astype(np.float32), (7, 7), 1.5)
        noise_x = cv2.GaussianBlur(noise_x.astype(np.float32), (7, 7), 1.5)
        
        y_coords, x_coords = np.mgrid[0:h, 0:w]
        
        map_y = (y_coords + noise_y * 15).astype(np.float32)
        map_x = (x_coords + noise_x * 15).astype(np.float32)
        
        return cv2.remap(image, map_x, map_y, cv2.INTER_LINEAR, borderMode=cv2.BORDER_REFLECT)
    
    def _apply_fabric_texture(self, image: np.ndarray, fabric_props: Dict[str, float]) -> np.ndarray:
        """ì²œ ì§ˆê° ì‹œë®¬ë ˆì´ì…˜"""
        
        # ì²œ ë°€ë„ì— ë”°ë¥¸ ì§ˆê° íš¨ê³¼
        density = fabric_props['density']
        
        if density > 1.8:  # ë¬´ê±°ìš´ ì²œ (ë°ë‹˜, ê°€ì£½ ë“±)
            # ì•½ê°„ ê±°ì¹œ ì§ˆê°
            kernel = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]]) * 0.1
            textured = cv2.filter2D(image, -1, kernel)
        elif density < 1.2:  # ê°€ë²¼ìš´ ì²œ (ì‹¤í¬, ìŠ¤íŒë±ìŠ¤ ë“±)
            # ë¶€ë“œëŸ¬ìš´ ì§ˆê°
            textured = cv2.bilateralFilter(image, 9, 75, 75)
        else:  # ë³´í†µ ì²œ
            # ê¸°ë³¸ ì§ˆê°
            textured = image
        
        return textured
    
    def _generate_shadow_map(self, shape: Tuple[int, int], drape_level: float) -> np.ndarray:
        """ê·¸ë¦¼ì ë§µ ìƒì„±"""
        h, w = shape
        y_coords, x_coords = np.mgrid[0:h, 0:w]
        
        # ë“œë ˆì´í•‘ ë ˆë²¨ì— ë”°ë¥¸ ê·¸ë¦¼ì ê°•ë„
        shadow_strength = drape_level * 0.3
        
        # ì•„ë˜ìª½ê³¼ êµ¬ì„ì— ê·¸ë¦¼ì ìƒì„±
        vertical_shadow = (y_coords / h) * shadow_strength
        
        # ì¤‘ì•™ì—ì„œ ê°€ì¥ìë¦¬ë¡œ ê°ˆìˆ˜ë¡ ê·¸ë¦¼ì
        center_y, center_x = h // 2, w // 2
        distance = np.sqrt((y_coords - center_y) ** 2 + (x_coords - center_x) ** 2)
        max_distance = np.sqrt(center_y ** 2 + center_x ** 2)
        
        radial_shadow = (distance / max_distance) * shadow_strength * 0.5
        
        # ê²°í•©
        shadow_map = vertical_shadow + radial_shadow
        
        return np.clip(shadow_map, 0.0, 1.0).astype(np.float32)
    
    def _apply_lighting_effects(
        self,
        image: np.ndarray,
        depth_map: np.ndarray,
        shine_factor: float
    ) -> Dict[str, Any]:
        """ì¡°ëª… íš¨ê³¼ ì ìš©"""
        
        # 1. ê¸°ë³¸ ì¡°ëª… ì ìš©
        lit_image = self._apply_basic_lighting(image, depth_map)
        
        # 2. í•˜ì´ë¼ì´íŠ¸ íš¨ê³¼ (ê´‘íƒ ìˆëŠ” ì²œ)
        if shine_factor > 0.5:
            highlighted_image = self._apply_highlights(lit_image, depth_map, shine_factor)
        else:
            highlighted_image = lit_image
        
        # 3. í™˜ê²½ ì¡°ëª… ì‹œë®¬ë ˆì´ì…˜
        ambient_lit_image = self._apply_ambient_lighting(highlighted_image, 0.3)
        
        return {
            'lit_image': ambient_lit_image,
            'lighting_applied': True,
            'highlights_applied': shine_factor > 0.5,
            'ambient_lighting': True
        }
    
    def _apply_basic_lighting(self, image: np.ndarray, depth_map: np.ndarray) -> np.ndarray:
        """ê¸°ë³¸ ì¡°ëª… ì ìš©"""
        
        # ê¹Šì´ì— ë”°ë¥¸ ì¡°ëª… ê°•ë„
        lighting_intensity = 0.8 + depth_map * 0.4
        
        # ì¡°ëª… ì ìš©
        lit_image = image.astype(np.float32)
        for i in range(3):  # RGB ì±„ë„ë³„
            lit_image[:, :, i] *= lighting_intensity
        
        return np.clip(lit_image, 0, 255).astype(np.uint8)
    
    def _apply_highlights(self, image: np.ndarray, depth_map: np.ndarray, shine_factor: float) -> np.ndarray:
        """í•˜ì´ë¼ì´íŠ¸ íš¨ê³¼ ì ìš©"""
        
        # ê°€ì¥ ì•ìª½ ì˜ì—­ì— í•˜ì´ë¼ì´íŠ¸
        highlight_mask = depth_map > np.percentile(depth_map, 85)
        
        # í•˜ì´ë¼ì´íŠ¸ ê°•ë„
        highlight_strength = shine_factor * 0.3
        
        highlighted = image.copy().astype(np.float32)
        highlighted[highlight_mask] = highlighted[highlight_mask] * (1 + highlight_strength)
        
        return np.clip(highlighted, 0, 255).astype(np.uint8)
    
    def _apply_ambient_lighting(self, image: np.ndarray, ambient_strength: float) -> np.ndarray:
        """í™˜ê²½ ì¡°ëª… ì ìš©"""
        
        # ì „ì²´ì ìœ¼ë¡œ ì•½ê°„ ë°ê²Œ
        ambient_lit = image.astype(np.float32) * (1 + ambient_strength * 0.1)
        
        return np.clip(ambient_lit, 0, 255).astype(np.uint8)
    
    def _apply_final_composition(
        self,
        lit_image: np.ndarray,
        shadow_map: np.ndarray,
        mask: np.ndarray
    ) -> Dict[str, Any]:
        """ìµœì¢… í•©ì„±"""
        
        # 1. ê·¸ë¦¼ì ì ìš©
        shadow_applied = self._apply_shadow_to_image(lit_image, shadow_map)
        
        # 2. ë§ˆìŠ¤í¬ ì ìš©
        masked_image = self._apply_mask_to_image(shadow_applied, mask)
        
        # 3. ìµœì¢… ë³´ì •
        final_image = self._apply_final_correction(masked_image)
        
        return {
            'composed_image': final_image,
            'shadow_applied': True,
            'mask_applied': True,
            'final_corrected': True
        }
    
    def _apply_shadow_to_image(self, image: np.ndarray, shadow_map: np.ndarray) -> np.ndarray:
        """ê·¸ë¦¼ìë¥¼ ì´ë¯¸ì§€ì— ì ìš©"""
        
        # ê·¸ë¦¼ì ê°•ë„ ì¡°ì •
        shadow_factor = 1.0 - shadow_map * 0.4
        
        # ì´ë¯¸ì§€ì— ê·¸ë¦¼ì ì ìš©
        shadowed = image.astype(np.float32)
        for i in range(3):  # RGB ì±„ë„ë³„
            shadowed[:, :, i] *= shadow_factor
        
        return np.clip(shadowed, 0, 255).astype(np.uint8)
    
    def _apply_mask_to_image(self, image: np.ndarray, mask: np.ndarray) -> np.ndarray:
        """ë§ˆìŠ¤í¬ë¥¼ ì´ë¯¸ì§€ì— ì ìš©"""
        
        if mask.max() > 1:
            mask = mask.astype(np.float32) / 255.0
        
        # ë§ˆìŠ¤í¬ ì ìš©
        if len(mask.shape) == 2:
            mask = mask[..., np.newaxis]
        
        masked = image.astype(np.float32) * mask
        
        return masked.astype(np.uint8)
    
    def _apply_final_correction(self, image: np.ndarray) -> np.ndarray:
        """ìµœì¢… ë³´ì •"""
        
        # ìƒ‰ìƒ ë³´ì •
        corrected = cv2.convertScaleAbs(image, alpha=1.05, beta=5)
        
        # ë…¸ì´ì¦ˆ ì œê±°
        denoised = cv2.bilateralFilter(corrected, 5, 50, 50)
        
        return denoised
    
    def _calculate_fitting_quality(
        self,
        result_image: np.ndarray,
        original_image: np.ndarray,
        fabric_props: Dict[str, float],
        fitting_params: Dict[str, Any]
    ) -> float:
        """í”¼íŒ… í’ˆì§ˆ ê³„ì‚°"""
        
        try:
            # 1. êµ¬ì¡°ì  ìœ ì‚¬ì„±
            ssim_score = self._calculate_ssim(result_image, original_image)
            
            # 2. í”¼íŒ… ì í•©ì„±
            fit_appropriateness = self._calculate_fit_appropriateness(fitting_params)
            
            # 3. ì²œ ë¬¼ë¦¬ í˜„ì‹¤ì„±
            physics_realism = self._calculate_physics_realism(fabric_props)
            
            # 4. ì‹œê°ì  í’ˆì§ˆ
            visual_quality = self._calculate_visual_quality(result_image)
            
            # ì¢…í•© ì ìˆ˜
            quality = (
                ssim_score * 0.3 +
                fit_appropriateness * 0.25 +
                physics_realism * 0.25 +
                visual_quality * 0.2
            )
            
            # M3 Max ë³´ë„ˆìŠ¤
            if self.is_m3_max:
                quality = min(1.0, quality * 1.05)
            
            return quality
            
        except Exception as e:
            self.logger.warning(f"í”¼íŒ… í’ˆì§ˆ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return 0.75
    
    def _calculate_ssim(self, img1: np.ndarray, img2: np.ndarray) -> float:
        """ê°„ë‹¨í•œ SSIM ê³„ì‚°"""
        try:
            # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜
            if len(img1.shape) == 3:
                img1 = cv2.cvtColor(img1, cv2.COLOR_RGB2GRAY)
            if len(img2.shape) == 3:
                img2 = cv2.cvtColor(img2, cv2.COLOR_RGB2GRAY)
            
            # í‰ê· 
            mu1 = np.mean(img1)
            mu2 = np.mean(img2)
            
            # ë¶„ì‚°
            sigma1 = np.var(img1)
            sigma2 = np.var(img2)
            
            # ê³µë¶„ì‚°
            sigma12 = np.mean((img1 - mu1) * (img2 - mu2))
            
            # SSIM ê³„ì‚°
            c1 = 0.01 ** 2
            c2 = 0.03 ** 2
            
            ssim = ((2 * mu1 * mu2 + c1) * (2 * sigma12 + c2)) / ((mu1**2 + mu2**2 + c1) * (sigma1 + sigma2 + c2))
            
            return max(0.0, min(1.0, ssim))
            
        except Exception as e:
            self.logger.warning(f"SSIM ê³„ì‚° ì‹¤íŒ¨: {e}")
            return 0.8
    
    def _calculate_fit_appropriateness(self, fitting_params: Dict[str, Any]) -> float:
        """í”¼íŒ… ì í•©ì„± ê³„ì‚°"""
        
        # í”¼íŒ… íƒ€ì…ë³„ ì í•©ì„± ì ìˆ˜
        fit_scores = {
            'fitted': 0.9,
            'flowing': 0.85,
            'structured': 0.8,
            'loose': 0.75
        }
        
        base_score = fit_scores.get(fitting_params['fit_type'], 0.7)
        
        # ì‹ ì²´ ì ‘ì´‰ë„ ì¡°ì •
        contact_factor = 1.0 - abs(fitting_params['body_contact'] - 0.6) * 0.3
        
        # ë“œë ˆì´í•‘ ì í•©ì„±
        drape_factor = fitting_params['drape_level'] * 0.8 + 0.2
        
        return base_score * contact_factor * drape_factor
    
    def _calculate_physics_realism(self, fabric_props: Dict[str, float]) -> float:
        """ë¬¼ë¦¬ í˜„ì‹¤ì„± ê³„ì‚°"""
        
        # ì²œ ì†ì„± ê°„ ê· í˜•
        stiffness = fabric_props['stiffness']
        elasticity = fabric_props['elasticity']
        density = fabric_props['density']
        
        # ë¬¼ë¦¬ì  ì¼ê´€ì„± (ë”±ë”±í•œ ì²œì€ íƒ„ì„±ì´ ì ì–´ì•¼ í•¨)
        consistency = 1.0 - abs(stiffness - (1.0 - elasticity)) * 0.5
        
        # ë°€ë„ ì í•©ì„±
        density_factor = min(1.0, density / 2.0)
        
        # ì „ì²´ í˜„ì‹¤ì„±
        realism = (consistency * 0.6 + density_factor * 0.4)
        
        return realism
    
    def _calculate_visual_quality(self, image: np.ndarray) -> float:
        """ì‹œê°ì  í’ˆì§ˆ ê³„ì‚°"""
        
        try:
            # 1. ì„ ëª…ë„ (ë¼í”Œë¼ì‹œì•ˆ ë¶„ì‚°)
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) if len(image.shape) == 3 else image
            laplacian_var = cv2.Laplacian(gray, cv2.CV_64F).var()
            sharpness = min(1.0, laplacian_var / 100.0)
            
            # 2. ëŒ€ë¹„
            contrast = np.std(gray) / 255.0
            
            # 3. ìƒ‰ìƒ í’ë¶€í•¨
            if len(image.shape) == 3:
                color_richness = np.std(image) / 255.0
            else:
                color_richness = 0.5
            
            # ì¢…í•© ì ìˆ˜
            visual_quality = (sharpness * 0.4 + contrast * 0.3 + color_richness * 0.3)
            
            return max(0.0, min(1.0, visual_quality))
            
        except Exception as e:
            self.logger.warning(f"ì‹œê°ì  í’ˆì§ˆ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return 0.7
    
    def _build_final_result(
        self,
        final_result: Dict[str, Any],
        lighting_result: Dict[str, Any],
        fabric_simulation_result: Dict[str, Any],
        body_fitting_result: Dict[str, Any],
        processing_time: float,
        quality_score: float,
        fabric_type: str,
        clothing_type: str
    ) -> Dict[str, Any]:
        """ìµœì¢… ê²°ê³¼ êµ¬ì„±"""
        
        # ë©”ì¸ ê²°ê³¼ ì´ë¯¸ì§€
        fitted_image = final_result['composed_image']
        
        # í…ì„œë¡œ ë³€í™˜
        if TORCH_AVAILABLE:
            fitted_tensor = self._numpy_to_tensor(fitted_image)
            mask_tensor = self._numpy_to_tensor(body_fitting_result.get('contact_map', np.ones(fitted_image.shape[:2])), is_mask=True)
        else:
            fitted_tensor = None
            mask_tensor = None
        
        return {
            "success": True,
            "step_name": self.__class__.__name__,
            "fitted_image": fitted_tensor,
            "fitted_mask": mask_tensor,
            "fitted_image_numpy": fitted_image,
            "deformation_map": body_fitting_result.get('contact_map'),
            "warping_quality": quality_score,
            "fabric_analysis": {
                "fabric_type": fabric_type,
                "physics_simulated": fabric_simulation_result.get('draping_applied', False),
                "lighting_applied": lighting_result.get('lighting_applied', False),
                "texture_enhanced": fabric_simulation_result.get('texture_enhanced', False),
                "shadows_applied": fabric_simulation_result.get('shadow_applied', False),
                "highlights_applied": lighting_result.get('highlights_applied', False)
            },
            "fitting_info": {
                "clothing_type": clothing_type,
                "fitting_method": "physics_based",
                "processing_time": processing_time,
                "device": self.device,
                "device_type": self.device_type,
                "m3_max_optimized": self.is_m3_max,
                "memory_gb": self.memory_gb,
                "quality_level": self.fitting_config['quality_level'],
                "fitting_iterations": self.performance_config['fitting_iterations'],
                "body_fitting_applied": True,
                "fabric_simulation_applied": True,
                "lighting_effects_applied": True
            },
            "performance_info": {
                "optimization_enabled": self.optimization_enabled,
                "gpu_acceleration": self.device != 'cpu',
                "cache_hit": False,
                "parallel_processing": self.performance_config['parallel_processing']
            }
        }
    
    def _generate_cache_key(self, warping_result: Dict, fabric_type: str, clothing_type: str) -> str:
        """ìºì‹œ í‚¤ ìƒì„±"""
        
        # ì¤‘ìš”í•œ ìš”ì†Œë“¤ë§Œ í•´ì‹œ
        key_elements = [
            str(warping_result.get('warped_image', np.array([])).shape),
            fabric_type,
            clothing_type,
            self.fitting_config['quality_level'],
            str(self.performance_config['fitting_iterations'])
        ]
        
        return hash(tuple(key_elements))
    
    def _update_cache(self, cache_key: str, result: Dict[str, Any]):
        """ìºì‹œ ì—…ë°ì´íŠ¸"""
        
        if len(self.fitting_cache) >= self.cache_max_size:
            # ê°€ì¥ ì˜¤ë˜ëœ í•­ëª© ì œê±°
            oldest_key = next(iter(self.fitting_cache))
            del self.fitting_cache[oldest_key]
        
        # ìƒˆ ê²°ê³¼ ì¶”ê°€
        self.fitting_cache[cache_key] = result.copy()
    
    def _create_error_result(self, error_msg: str, processing_time: float) -> Dict[str, Any]:
        """ì—ëŸ¬ ê²°ê³¼ ìƒì„±"""
        
        return {
            "success": False,
            "step_name": self.__class__.__name__,
            "error": error_msg,
            "processing_time": processing_time,
            "fitted_image": None,
            "fitted_mask": None,
            "fitted_image_numpy": np.zeros((256, 256, 3), dtype=np.uint8),
            "warping_quality": 0.0,
            "fabric_analysis": {"error": True},
            "fitting_info": {
                "error": True,
                "device": self.device,
                "processing_time": processing_time
            }
        }
    
    def _tensor_to_numpy(self, tensor: torch.Tensor, is_mask: bool = False) -> np.ndarray:
        """í…ì„œë¥¼ numpyë¡œ ë³€í™˜"""
        
        if not TORCH_AVAILABLE:
            raise RuntimeError("PyTorchê°€ í•„ìš”í•©ë‹ˆë‹¤")
        
        try:
            # GPUì—ì„œ CPUë¡œ ì´ë™
            if tensor.is_cuda or (hasattr(tensor, 'is_mps') and tensor.is_mps):
                tensor = tensor.cpu()
            
            # ì°¨ì› ì •ë¦¬
            if tensor.dim() == 4:
                tensor = tensor.squeeze(0)
            
            if is_mask:
                if tensor.dim() == 3:
                    tensor = tensor.squeeze(0)
                array = tensor.numpy().astype(np.uint8)
                if array.max() <= 1.0:
                    array = array * 255
            else:
                if tensor.dim() == 3 and tensor.size(0) == 3:
                    tensor = tensor.permute(1, 2, 0)
                
                array = tensor.numpy()
                if array.max() <= 1.0:
                    array = array * 255
                array = array.astype(np.uint8)
            
            return array
            
        except Exception as e:
            self.logger.error(f"í…ì„œ ë³€í™˜ ì‹¤íŒ¨: {e}")
            raise
    
    def _numpy_to_tensor(self, array: np.ndarray, is_mask: bool = False) -> torch.Tensor:
        """numpyë¥¼ í…ì„œë¡œ ë³€í™˜"""
        
        if not TORCH_AVAILABLE:
            return None
        
        try:
            if is_mask:
                if len(array.shape) == 2:
                    array = array[np.newaxis, :]
                tensor = torch.from_numpy(array.astype(np.float32) / 255.0)
                tensor = tensor.unsqueeze(0)
            else:
                if len(array.shape) == 3 and array.shape[2] == 3:
                    array = array.transpose(2, 0, 1)
                tensor = torch.from_numpy(array.astype(np.float32) / 255.0)
                tensor = tensor.unsqueeze(0)
            
            return tensor.to(self.device)
            
        except Exception as e:
            self.logger.warning(f"í…ì„œ ë³€í™˜ ì‹¤íŒ¨: {e}")
            return None
    
    def _resize_image(self, image: np.ndarray, max_size: int) -> np.ndarray:
        """ì´ë¯¸ì§€ í¬ê¸° ì¡°ì •"""
        
        h, w = image.shape[:2]
        
        if max(h, w) <= max_size:
            return image
        
        # ë¹„ìœ¨ ìœ ì§€í•˜ë©´ì„œ í¬ê¸° ì¡°ì •
        if h > w:
            new_h = max_size
            new_w = int(w * max_size / h)
        else:
            new_w = max_size
            new_h = int(h * max_size / w)
        
        return cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_AREA)
    
    def _update_performance_stats(self, processing_time: float, quality_score: float):
        """ì„±ëŠ¥ í†µê³„ ì—…ë°ì´íŠ¸"""
        
        try:
            self.performance_stats['total_processed'] += 1
            total = self.performance_stats['total_processed']
            
            # í‰ê·  ì²˜ë¦¬ ì‹œê°„
            current_avg = self.performance_stats['average_time']
            self.performance_stats['average_time'] = (current_avg * (total - 1) + processing_time) / total
            
            # í‰ê·  í’ˆì§ˆ
            current_quality_avg = self.performance_stats['quality_score_avg']
            self.performance_stats['quality_score_avg'] = (current_quality_avg * (total - 1) + quality_score) / total
            
        except Exception as e:
            self.logger.warning(f"í†µê³„ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
    
    def cleanup(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        
        try:
            self.logger.info("ğŸ§¹ 6ë‹¨ê³„ ê°€ìƒ í”¼íŒ… ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ ì •ë¦¬...")
            
            # ìºì‹œ ì •ë¦¬
            self.fitting_cache.clear()
            
            # ìŠ¤ë ˆë“œ í’€ ì •ë¦¬
            if hasattr(self, 'executor'):
                self.executor.shutdown(wait=False)
            
            # GPU ë©”ëª¨ë¦¬ ì •ë¦¬
            if TORCH_AVAILABLE:
                if self.device == 'mps':
                    torch.mps.empty_cache()
                elif self.device == 'cuda':
                    torch.cuda.empty_cache()
            
            # ì‹œìŠ¤í…œ ë©”ëª¨ë¦¬ ì •ë¦¬
            import gc
            gc.collect()
            
            self.is_initialized = False
            self.logger.info("âœ… 6ë‹¨ê³„ ê°€ìƒ í”¼íŒ… ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì™„ë£Œ")
            
        except Exception as e:
            self.logger.warning(f"ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì‹¤íŒ¨: {e}")
    
    async def get_step_info(self) -> Dict[str, Any]:
        """ë‹¨ê³„ ì •ë³´ ë°˜í™˜"""
        
        return {
            "step_name": self.__class__.__name__,
            "version": "6.0-unified",
            "device": self.device,
            "device_type": self.device_type,
            "memory_gb": self.memory_gb,
            "is_m3_max": self.is_m3_max,
            "optimization_enabled": self.optimization_enabled,
            "quality_level": self.quality_level,
            "initialized": self.is_initialized,
            "config_keys": list(self.config.keys()),
            "performance_stats": self.performance_stats.copy(),
            "unified_constructor": True,
            "capabilities": {
                "body_fitting": True,
                "fabric_simulation": True,
                "lighting_effects": True,
                "physics_simulation": self.fitting_config['physics_enabled'],
                "neural_processing": TORCH_AVAILABLE and self.device != 'cpu',
                "m3_max_acceleration": self.is_m3_max and self.device == 'mps'
            },
            "supported_fabrics": list(self.FABRIC_PROPERTIES.keys()),
            "supported_clothing_types": list(self.CLOTHING_FITTING_PARAMS.keys()),
            "dependencies": {
                "torch": TORCH_AVAILABLE,
                "opencv": CV2_AVAILABLE,
                "scipy": SCIPY_AVAILABLE,
                "sklearn": SKLEARN_AVAILABLE,
                "skimage": SKIMAGE_AVAILABLE
            }
        }


# =================================================================
# í˜¸í™˜ì„± ì§€ì› í•¨ìˆ˜ë“¤
# =================================================================

def create_virtual_fitting_step(
    device: str = "mps", 
    config: Optional[Dict[str, Any]] = None
) -> VirtualFittingStep:
    """ê¸°ì¡´ ë°©ì‹ í˜¸í™˜ ìƒì„±ì"""
    return VirtualFittingStep(device=device, config=config)

def create_m3_max_virtual_fitting_step(
    memory_gb: float = 128.0,
    quality_level: str = "ultra",
    **kwargs
) -> VirtualFittingStep:
    """M3 Max ìµœì í™” ìƒì„±ì"""
    return VirtualFittingStep(
        device=None,  # ìë™ ê°ì§€
        memory_gb=memory_gb,
        quality_level=quality_level,
        is_m3_max=True,
        optimization_enabled=True,
        **kwargs
    )