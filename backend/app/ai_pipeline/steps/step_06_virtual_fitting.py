# app/ai_pipeline/steps/step_06_virtual_fitting.py
"""
6ë‹¨ê³„: ê°€ìƒ í”¼íŒ… (Virtual Fitting) - ì™„ì „í•œ êµ¬í˜„
âœ… Pipeline Manager ì™„ì „ í˜¸í™˜
âœ… ModelLoader ì™„ì „ ì—°ë™
âœ… M3 Max 128GB ìµœì í™”
âœ… ì‹¤ì œ AI ëª¨ë¸ ì‚¬ìš© (OOTDiffusion, VITON-HD)
âœ… ë¬¼ë¦¬ ê¸°ë°˜ ì²œ ì‹œë®¬ë ˆì´ì…˜
âœ… í”„ë¡œë•ì…˜ ë ˆë²¨ ì½”ë“œ
"""

import os
import sys
import logging
import time
import asyncio
import json
import math
import threading
import uuid
from pathlib import Path
from typing import Dict, Any, Optional, Tuple, List, Union, Callable
from dataclasses import dataclass, field
from enum import Enum
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor
import gc
import weakref

# í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬
import numpy as np
from PIL import Image, ImageEnhance, ImageFilter, ImageDraw

# PyTorch ê´€ë ¨
try:
    import torch
    import torch.nn as nn
    import torch.nn.functional as F
    import torchvision.transforms as transforms
    TORCH_AVAILABLE = True
except ImportError:
    TORCH_AVAILABLE = False

# OpenCV
try:
    import cv2
    CV2_AVAILABLE = True
except ImportError:
    CV2_AVAILABLE = False

# ê³¼í•™ ì—°ì‚° ë¼ì´ë¸ŒëŸ¬ë¦¬
try:
    from scipy.interpolate import RBFInterpolator, griddata
    from scipy.spatial.distance import cdist
    from scipy.ndimage import gaussian_filter, binary_erosion, binary_dilation
    SCIPY_AVAILABLE = True
except ImportError:
    SCIPY_AVAILABLE = False

try:
    from sklearn.cluster import KMeans, DBSCAN
    from sklearn.preprocessing import StandardScaler
    SKLEARN_AVAILABLE = True
except ImportError:
    SKLEARN_AVAILABLE = False

try:
    from skimage.feature import local_binary_pattern, canny
    from skimage.segmentation import slic, watershed
    from skimage.transform import resize, rotate
    from skimage.measure import regionprops, label
    SKIMAGE_AVAILABLE = True
except ImportError:
    SKIMAGE_AVAILABLE = False

# AI ëª¨ë¸ ë¼ì´ë¸ŒëŸ¬ë¦¬
try:
    from diffusers import StableDiffusionPipeline, DDIMScheduler, UNet2DConditionModel
    from transformers import CLIPProcessor, CLIPModel
    DIFFUSERS_AVAILABLE = True
except ImportError:
    DIFFUSERS_AVAILABLE = False

# ë¡œê±° ì„¤ì •
logger = logging.getLogger(__name__)

# =================================================================
# 1. ìƒìˆ˜ ë° ì„¤ì •
# =================================================================

class FittingQuality(Enum):
    """í”¼íŒ… í’ˆì§ˆ ë ˆë²¨"""
    FAST = "fast"
    BALANCED = "balanced"
    HIGH = "high"
    ULTRA = "ultra"

class FittingMethod(Enum):
    """í”¼íŒ… ë°©ë²•"""
    PHYSICS_BASED = "physics_based"
    AI_NEURAL = "ai_neural"
    HYBRID = "hybrid"
    TEMPLATE_MATCHING = "template_matching"

@dataclass
class FabricProperties:
    """ì²œ ì¬ì§ˆ ì†ì„±"""
    stiffness: float = 0.5
    elasticity: float = 0.3
    density: float = 1.4
    friction: float = 0.5
    shine: float = 0.5
    transparency: float = 0.0
    texture_scale: float = 1.0

@dataclass
class FittingParams:
    """í”¼íŒ… íŒŒë¼ë¯¸í„°"""
    fit_type: str = "fitted"
    body_contact: float = 0.7
    drape_level: float = 0.3
    stretch_zones: List[str] = field(default_factory=lambda: ["chest", "waist"])
    wrinkle_intensity: float = 0.5
    shadow_strength: float = 0.6

# ì²œ ì¬ì§ˆë³„ ë¬¼ë¦¬ ì†ì„±
FABRIC_PROPERTIES = {
    'cotton': FabricProperties(0.3, 0.2, 1.5, 0.7, 0.2, 0.0, 1.0),
    'denim': FabricProperties(0.8, 0.1, 2.0, 0.9, 0.1, 0.0, 1.2),
    'silk': FabricProperties(0.1, 0.4, 1.3, 0.3, 0.8, 0.1, 0.8),
    'wool': FabricProperties(0.5, 0.3, 1.4, 0.6, 0.3, 0.0, 1.1),
    'polyester': FabricProperties(0.4, 0.5, 1.2, 0.4, 0.6, 0.0, 0.9),
    'leather': FabricProperties(0.9, 0.1, 2.5, 0.8, 0.9, 0.0, 1.5),
    'spandex': FabricProperties(0.1, 0.8, 1.1, 0.5, 0.4, 0.0, 0.7),
    'linen': FabricProperties(0.6, 0.2, 1.6, 0.8, 0.1, 0.0, 1.3),
    'default': FabricProperties(0.4, 0.3, 1.4, 0.5, 0.5, 0.0, 1.0)
}

# ì˜ë¥˜ íƒ€ì…ë³„ í”¼íŒ… íŒŒë¼ë¯¸í„°
CLOTHING_FITTING_PARAMS = {
    'shirt': FittingParams("fitted", 0.7, 0.3, ["chest", "waist"], 0.3, 0.6),
    'dress': FittingParams("flowing", 0.5, 0.7, ["bust", "waist", "hip"], 0.6, 0.7),
    'pants': FittingParams("fitted", 0.8, 0.2, ["thigh", "calf"], 0.4, 0.5),
    'jacket': FittingParams("structured", 0.6, 0.4, ["shoulder", "chest"], 0.2, 0.8),
    'skirt': FittingParams("flowing", 0.6, 0.6, ["waist", "hip"], 0.5, 0.6),
    'blouse': FittingParams("loose", 0.5, 0.5, ["chest", "waist"], 0.4, 0.6),
    'sweater': FittingParams("relaxed", 0.6, 0.4, ["chest", "arms"], 0.3, 0.5),
    'default': FittingParams("fitted", 0.6, 0.4, ["chest", "waist"], 0.4, 0.6)
}

# =================================================================
# 2. ë©”ì¸ í´ë˜ìŠ¤
# =================================================================

class VirtualFittingStep:
    """6ë‹¨ê³„: ê°€ìƒ í”¼íŒ… - ì™„ì „í•œ êµ¬í˜„"""
    
    def __init__(
        self,
        device: Optional[str] = None,
        config: Optional[Dict[str, Any]] = None,
        **kwargs
    ):
        """
        âœ… í†µì¼ëœ ìƒì„±ì íŒ¨í„´ - Pipeline Manager ì™„ì „ í˜¸í™˜
        
        Args:
            device: ë””ë°”ì´ìŠ¤ ('cpu', 'cuda', 'mps', None=ìë™ê°ì§€)
            config: ì„¤ì • ë”•ì…”ë„ˆë¦¬
            **kwargs: í™•ì¥ íŒŒë¼ë¯¸í„°
                - device_type: str = "auto"
                - memory_gb: float = 16.0
                - is_m3_max: bool = False
                - optimization_enabled: bool = True
                - quality_level: str = "balanced"
                - fitting_method: str = "physics_based"
                - enable_physics: bool = True
                - enable_ai_models: bool = True
        """
        
        # === 1. í†µì¼ëœ ì´ˆê¸°í™” íŒ¨í„´ ===
        self.device = self._auto_detect_device(device)
        self.config = config or {}
        self.step_name = self.__class__.__name__
        self.logger = logging.getLogger(f"pipeline.{self.step_name}")
        
        # === 2. ì‹œìŠ¤í…œ íŒŒë¼ë¯¸í„° ===
        self.device_type = kwargs.get('device_type', 'auto')
        self.memory_gb = kwargs.get('memory_gb', 16.0)
        self.is_m3_max = kwargs.get('is_m3_max', self._detect_m3_max())
        self.optimization_enabled = kwargs.get('optimization_enabled', True)
        self.quality_level = kwargs.get('quality_level', 'balanced')
        
        # === 3. 6ë‹¨ê³„ íŠ¹í™” íŒŒë¼ë¯¸í„° ===
        self.fitting_method = kwargs.get('fitting_method', 'physics_based')
        self.enable_physics = kwargs.get('enable_physics', True)
        self.enable_ai_models = kwargs.get('enable_ai_models', True)
        
        # === 4. Step íŠ¹í™” ì„¤ì • ë³‘í•© ===
        self._merge_step_specific_config(kwargs)
        
        # === 5. ìƒíƒœ ì´ˆê¸°í™” ===
        self.is_initialized = False
        self.session_id = str(uuid.uuid4())
        
        # === 6. ModelLoader ì—°ë™ ===
        self._setup_model_loader()
        
        # === 7. 6ë‹¨ê³„ ì „ìš© ì´ˆê¸°í™” ===
        self._initialize_step_specific()
        
        # ì´ˆê¸°í™” ì™„ë£Œ ë¡œê·¸
        self.logger.info(f"âœ… {self.step_name} ì´ˆê¸°í™” ì™„ë£Œ - ë””ë°”ì´ìŠ¤: {self.device}, "
                        f"í’ˆì§ˆ: {self.quality_level}, ë°©ë²•: {self.fitting_method}")
    
    def _auto_detect_device(self, device: Optional[str]) -> str:
        """ë””ë°”ì´ìŠ¤ ìë™ ê°ì§€"""
        if device is not None:
            return device
            
        if TORCH_AVAILABLE:
            if torch.backends.mps.is_available():
                return "mps"
            elif torch.cuda.is_available():
                return "cuda"
        return "cpu"
    
    def _detect_m3_max(self) -> bool:
        """M3 Max ê°ì§€"""
        try:
            if sys.platform == "darwin":
                import platform
                return "arm64" in platform.machine().lower()
        except:
            pass
        return False
    
    def _merge_step_specific_config(self, kwargs: Dict[str, Any]):
        """Step íŠ¹í™” ì„¤ì • ë³‘í•©"""
        system_params = {
            'device_type', 'memory_gb', 'is_m3_max', 
            'optimization_enabled', 'quality_level',
            'fitting_method', 'enable_physics', 'enable_ai_models'
        }
        
        for key, value in kwargs.items():
            if key not in system_params:
                self.config[key] = value
    
    def _setup_model_loader(self):
        """ModelLoader ì—°ë™"""
        try:
            # ModelLoader ì‹œìŠ¤í…œê³¼ ì—°ë™
            from app.ai_pipeline.utils.model_loader import BaseStepMixin
            if hasattr(BaseStepMixin, '_setup_model_interface'):
                BaseStepMixin._setup_model_interface(self)
        except ImportError:
            self.logger.warning("ModelLoader ì‚¬ìš© ë¶ˆê°€ - ë…ë¦½ ëª¨ë“œë¡œ ë™ì‘")
    
    def _initialize_step_specific(self):
        """6ë‹¨ê³„ ì „ìš© ì´ˆê¸°í™”"""
        
        # ê°€ìƒ í”¼íŒ… ì„¤ì •
        self.fitting_config = {
            'method': FittingMethod(self.fitting_method),
            'quality': FittingQuality(self.quality_level),
            'physics_enabled': self.enable_physics,
            'ai_models_enabled': self.enable_ai_models,
            'body_interaction': self.config.get('body_interaction', True),
            'fabric_simulation': self.config.get('fabric_simulation', True),
            'enable_shadows': self.config.get('enable_shadows', True),
            'enable_highlights': self.config.get('enable_highlights', True),
            'texture_preservation': self.config.get('texture_preservation', True),
            'wrinkle_simulation': self.config.get('wrinkle_simulation', True)
        }
        
        # ì„±ëŠ¥ ì„¤ì •
        self.performance_config = {
            'max_resolution': self._get_max_resolution(),
            'fitting_iterations': self._get_fitting_iterations(),
            'precision_factor': self._get_precision_factor(),
            'batch_size': self._get_batch_size(),
            'cache_enabled': True,
            'parallel_processing': self.is_m3_max,
            'memory_efficient': self.memory_gb < 32
        }
        
        # ìºì‹œ ì‹œìŠ¤í…œ
        cache_size = min(200 if self.is_m3_max and self.memory_gb >= 128 else 50, 
                        int(self.memory_gb * 2))
        self.fitting_cache = {}
        self.cache_max_size = cache_size
        
        # AI ëª¨ë¸ ê´€ë¦¬
        self.ai_models = {
            'diffusion_pipeline': None,
            'human_parser': None,
            'cloth_segmenter': None,
            'pose_estimator': None,
            'style_encoder': None
        }
        
        # ì„±ëŠ¥ í†µê³„
        self.performance_stats = {
            'total_processed': 0,
            'successful_fittings': 0,
            'failed_fittings': 0,
            'average_processing_time': 0.0,
            'cache_hits': 0,
            'cache_misses': 0,
            'memory_peak_mb': 0.0,
            'ai_model_usage': {model: 0 for model in self.ai_models.keys()}
        }
        
        # ìŠ¤ë ˆë“œ í’€
        max_workers = min(8, int(self.memory_gb / 8)) if self.is_m3_max else 2
        self.thread_pool = ThreadPoolExecutor(max_workers=max_workers)
        
        # ë©”ëª¨ë¦¬ ê´€ë¦¬
        self.memory_manager = self._create_memory_manager()
    
    def _get_max_resolution(self) -> int:
        """ìµœëŒ€ í•´ìƒë„ ê³„ì‚°"""
        if self.quality_level == "ultra" and self.memory_gb >= 64:
            return 1024
        elif self.quality_level == "high" and self.memory_gb >= 32:
            return 768
        elif self.quality_level == "balanced":
            return 512
        else:
            return 384
    
    def _get_fitting_iterations(self) -> int:
        """í”¼íŒ… ë°˜ë³µ íšŸìˆ˜"""
        quality_iterations = {
            "fast": 1,
            "balanced": 3,
            "high": 5,
            "ultra": 8
        }
        return quality_iterations.get(self.quality_level, 3)
    
    def _get_precision_factor(self) -> float:
        """ì •ë°€ë„ ê³„ìˆ˜"""
        quality_precision = {
            "fast": 0.5,
            "balanced": 1.0,
            "high": 1.5,
            "ultra": 2.0
        }
        return quality_precision.get(self.quality_level, 1.0)
    
    def _get_batch_size(self) -> int:
        """ë°°ì¹˜ í¬ê¸°"""
        if self.is_m3_max and self.memory_gb >= 128:
            return 4
        elif self.memory_gb >= 32:
            return 2
        else:
            return 1
    
    def _create_memory_manager(self):
        """ë©”ëª¨ë¦¬ ë§¤ë‹ˆì € ìƒì„±"""
        try:
            from app.ai_pipeline.utils.memory_manager import MemoryManager
            return MemoryManager(
                device=self.device,
                is_m3_max=self.is_m3_max,
                memory_gb=self.memory_gb
            )
        except ImportError:
            return None
    
    # =================================================================
    # 3. ì´ˆê¸°í™” ë° ëª¨ë¸ ë¡œë”©
    # =================================================================
    
    async def initialize(self) -> bool:
        """ë‹¨ê³„ ì´ˆê¸°í™”"""
        if self.is_initialized:
            return True
        
        try:
            start_time = time.time()
            self.logger.info(f"ğŸš€ {self.step_name} ì´ˆê¸°í™” ì‹œì‘...")
            
            # 1. ì˜ì¡´ì„± í™•ì¸
            if not self._check_dependencies():
                raise RuntimeError("í•„ìˆ˜ ì˜ì¡´ì„±ì´ ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ")
            
            # 2. AI ëª¨ë¸ ë¡œë“œ (ì„ íƒì )
            if self.fitting_config['ai_models_enabled']:
                await self._load_ai_models()
            
            # 3. ë¬¼ë¦¬ ì—”ì§„ ì´ˆê¸°í™” (ì„ íƒì )
            if self.fitting_config['physics_enabled']:
                self._initialize_physics_engine()
            
            # 4. í…ìŠ¤ì²˜ ë° ë Œë”ë§ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
            self._initialize_rendering_system()
            
            # 5. ìºì‹œ ì‹œìŠ¤í…œ ì¤€ë¹„
            self._prepare_cache_system()
            
            # ì´ˆê¸°í™” ì™„ë£Œ
            self.is_initialized = True
            init_time = time.time() - start_time
            
            self.logger.info(f"âœ… {self.step_name} ì´ˆê¸°í™” ì™„ë£Œ - {init_time:.2f}ì´ˆ")
            self.logger.info(f"   - AI ëª¨ë¸: {'í™œì„±í™”' if self.fitting_config['ai_models_enabled'] else 'ë¹„í™œì„±í™”'}")
            self.logger.info(f"   - ë¬¼ë¦¬ ì—”ì§„: {'í™œì„±í™”' if self.fitting_config['physics_enabled'] else 'ë¹„í™œì„±í™”'}")
            self.logger.info(f"   - ìµœëŒ€ í•´ìƒë„: {self.performance_config['max_resolution']}px")
            self.logger.info(f"   - ìºì‹œ í¬ê¸°: {self.cache_max_size}")
            
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ {self.step_name} ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.logger.error(f"   ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
            return False
    
    def _check_dependencies(self) -> bool:
        """ì˜ì¡´ì„± í™•ì¸"""
        required_packages = {
            'numpy': True,
            'PIL': True,
            'torch': TORCH_AVAILABLE,
            'cv2': CV2_AVAILABLE,
            'scipy': SCIPY_AVAILABLE,
            'sklearn': SKLEARN_AVAILABLE
        }
        
        missing = [pkg for pkg, available in required_packages.items() if not available]
        
        if missing:
            self.logger.warning(f"âš ï¸ ëˆ„ë½ëœ íŒ¨í‚¤ì§€: {missing}")
            return len(missing) <= 2  # ì¼ë¶€ ëˆ„ë½ í—ˆìš©
        
        return True
    
    async def _load_ai_models(self):
        """AI ëª¨ë¸ë“¤ ë¡œë“œ"""
        try:
            self.logger.info("ğŸ§  AI ëª¨ë¸ ë¡œë”© ì‹œì‘...")
            
            # 1. OOTDiffusion ëª¨ë¸ (ê°€ì¥ ì¤‘ìš”)
            if DIFFUSERS_AVAILABLE:
                await self._load_diffusion_model()
            
            # 2. ì¸ì²´ íŒŒì‹± ëª¨ë¸
            await self._load_human_parsing_model()
            
            # 3. í¬ì¦ˆ ì¶”ì • ëª¨ë¸
            await self._load_pose_estimation_model()
            
            # 4. ì˜ë¥˜ ë¶„í•  ëª¨ë¸
            await self._load_cloth_segmentation_model()
            
            # 5. ìŠ¤íƒ€ì¼ ì¸ì½”ë”
            await self._load_style_encoder()
            
            self.logger.info("âœ… AI ëª¨ë¸ ë¡œë”© ì™„ë£Œ")
            
        except Exception as e:
            self.logger.error(f"âŒ AI ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e}")
            # AI ëª¨ë¸ ì—†ì–´ë„ ë¬¼ë¦¬ ê¸°ë°˜ í”¼íŒ…ì€ ê°€ëŠ¥
            self.fitting_config['ai_models_enabled'] = False
    
    async def _load_diffusion_model(self):
        """ë””í“¨ì „ ëª¨ë¸ ë¡œë“œ"""
        try:
            if hasattr(self, 'model_loader') and self.model_loader:
                # ModelLoader ì‚¬ìš©
                pipeline = await self.model_loader.load_model("ootdiffusion")
                if pipeline:
                    self.ai_models['diffusion_pipeline'] = pipeline
                    self.performance_stats['ai_model_usage']['diffusion_pipeline'] += 1
                    self.logger.info("âœ… OOTDiffusion ëª¨ë¸ ë¡œë“œ ì„±ê³µ (ModelLoader)")
                    return
            
            # ì§ì ‘ ë¡œë“œ
            model_path = self._find_model_path("ootdiffusion") or "runwayml/stable-diffusion-v1-5"
            
            pipeline = StableDiffusionPipeline.from_pretrained(
                model_path,
                torch_dtype=torch.float16 if self.device != "cpu" else torch.float32,
                safety_checker=None,
                requires_safety_checker=False
            )
            
            pipeline.scheduler = DDIMScheduler.from_config(pipeline.scheduler.config)
            pipeline = pipeline.to(self.device)
            
            if self.device == "mps":
                # M3 Max ìµœì í™”
                pipeline.enable_attention_slicing()
            elif self.device == "cuda":
                pipeline.enable_memory_efficient_attention()
                pipeline.enable_attention_slicing()
            
            self.ai_models['diffusion_pipeline'] = pipeline
            self.performance_stats['ai_model_usage']['diffusion_pipeline'] += 1
            self.logger.info("âœ… ë””í“¨ì „ ëª¨ë¸ ë¡œë“œ ì„±ê³µ")
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ ë””í“¨ì „ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    async def _load_human_parsing_model(self):
        """ì¸ì²´ íŒŒì‹± ëª¨ë¸ ë¡œë“œ"""
        try:
            if hasattr(self, 'model_loader') and self.model_loader:
                model = await self.model_loader.load_model("human_parsing")
                if model:
                    self.ai_models['human_parser'] = model
                    self.performance_stats['ai_model_usage']['human_parser'] += 1
                    self.logger.info("âœ… ì¸ì²´ íŒŒì‹± ëª¨ë¸ ë¡œë“œ ì„±ê³µ")
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ ì¸ì²´ íŒŒì‹± ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    async def _load_pose_estimation_model(self):
        """í¬ì¦ˆ ì¶”ì • ëª¨ë¸ ë¡œë“œ"""
        try:
            if hasattr(self, 'model_loader') and self.model_loader:
                model = await self.model_loader.load_model("openpose")
                if model:
                    self.ai_models['pose_estimator'] = model
                    self.performance_stats['ai_model_usage']['pose_estimator'] += 1
                    self.logger.info("âœ… í¬ì¦ˆ ì¶”ì • ëª¨ë¸ ë¡œë“œ ì„±ê³µ")
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ í¬ì¦ˆ ì¶”ì • ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    async def _load_cloth_segmentation_model(self):
        """ì˜ë¥˜ ë¶„í•  ëª¨ë¸ ë¡œë“œ"""
        try:
            if hasattr(self, 'model_loader') and self.model_loader:
                model = await self.model_loader.load_model("u2net")
                if model:
                    self.ai_models['cloth_segmenter'] = model
                    self.performance_stats['ai_model_usage']['cloth_segmenter'] += 1
                    self.logger.info("âœ… ì˜ë¥˜ ë¶„í•  ëª¨ë¸ ë¡œë“œ ì„±ê³µ")
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ ì˜ë¥˜ ë¶„í•  ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    async def _load_style_encoder(self):
        """ìŠ¤íƒ€ì¼ ì¸ì½”ë” ë¡œë“œ"""
        try:
            if DIFFUSERS_AVAILABLE:
                if hasattr(self, 'model_loader') and self.model_loader:
                    model = await self.model_loader.load_model("clip")
                    if model:
                        self.ai_models['style_encoder'] = model
                        self.performance_stats['ai_model_usage']['style_encoder'] += 1
                        self.logger.info("âœ… ìŠ¤íƒ€ì¼ ì¸ì½”ë” ë¡œë“œ ì„±ê³µ")
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ ìŠ¤íƒ€ì¼ ì¸ì½”ë” ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    def _find_model_path(self, model_name: str) -> Optional[str]:
        """ëª¨ë¸ ê²½ë¡œ ì°¾ê¸°"""
        try:
            from app.core.optimized_model_paths import ANALYZED_MODELS
            for key, model_info in ANALYZED_MODELS.items():
                if model_name.lower() in key.lower():
                    if model_info.get('ready', False):
                        return str(model_info['path'])
        except ImportError:
            pass
        return None
    
    def _initialize_physics_engine(self):
        """ë¬¼ë¦¬ ì—”ì§„ ì´ˆê¸°í™”"""
        try:
            self.physics_engine = {
                'gravity': 9.81,
                'air_resistance': 0.1,
                'cloth_tension': 0.8,
                'body_collision': True,
                'wind_simulation': False,
                'fabric_stretching': True,
                'wrinkle_generation': True
            }
            
            # ë¬¼ë¦¬ ì‹œë®¬ë ˆì´ì…˜ íŒŒë¼ë¯¸í„°
            self.physics_params = {
                'time_step': 0.01,
                'iterations': self._get_fitting_iterations(),
                'damping': 0.95,
                'spring_constant': 100.0,
                'mass_distribution': 'uniform'
            }
            
            self.logger.info("âœ… ë¬¼ë¦¬ ì—”ì§„ ì´ˆê¸°í™” ì™„ë£Œ")
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ ë¬¼ë¦¬ ì—”ì§„ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.fitting_config['physics_enabled'] = False
    
    def _initialize_rendering_system(self):
        """ë Œë”ë§ ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
        try:
            self.rendering_config = {
                'lighting_model': 'pbr',  # Physically Based Rendering
                'shadow_quality': 'medium',
                'reflection_quality': 'low',
                'ambient_occlusion': True,
                'anti_aliasing': True,
                'texture_filtering': 'bilinear',
                'color_space': 'srgb'
            }
            
            # ì¡°ëª… ì„¤ì •
            self.lighting_setup = {
                'main_light': {'direction': (0.3, -0.5, 0.8), 'intensity': 1.0, 'color': (1.0, 1.0, 1.0)},
                'fill_light': {'direction': (-0.3, -0.2, 0.5), 'intensity': 0.4, 'color': (0.9, 0.9, 1.0)},
                'rim_light': {'direction': (0.0, 0.8, -0.2), 'intensity': 0.3, 'color': (1.0, 0.9, 0.8)},
                'ambient': {'intensity': 0.2, 'color': (0.5, 0.5, 0.6)}
            }
            
            self.logger.info("âœ… ë Œë”ë§ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ ë Œë”ë§ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    
    def _prepare_cache_system(self):
        """ìºì‹œ ì‹œìŠ¤í…œ ì¤€ë¹„"""
        try:
            # ìºì‹œ ë””ë ‰í† ë¦¬ ìƒì„±
            cache_dir = Path("cache/virtual_fitting")
            cache_dir.mkdir(parents=True, exist_ok=True)
            
            # ìºì‹œ ì„¤ì •
            self.cache_config = {
                'enabled': True,
                'max_size': self.cache_max_size,
                'ttl_seconds': 3600,  # 1ì‹œê°„
                'compression': True,
                'persist_to_disk': self.memory_gb < 64
            }
            
            # ë©”ëª¨ë¦¬ ê¸°ë°˜ ìºì‹œ
            self.fitting_cache = {}
            self.cache_access_times = {}
            
            self.logger.info(f"âœ… ìºì‹œ ì‹œìŠ¤í…œ ì¤€ë¹„ ì™„ë£Œ - í¬ê¸°: {self.cache_max_size}")
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ ìºì‹œ ì‹œìŠ¤í…œ ì¤€ë¹„ ì‹¤íŒ¨: {e}")
            self.cache_config['enabled'] = False
    
    # =================================================================
    # 4. ë©”ì¸ ì²˜ë¦¬ í•¨ìˆ˜
    # =================================================================
    
    async def process(
        self,
        person_image: Union[np.ndarray, Image.Image, str],
        clothing_image: Union[np.ndarray, Image.Image, str],
        **kwargs
    ) -> Dict[str, Any]:
        """
        ê°€ìƒ í”¼íŒ… ë©”ì¸ ì²˜ë¦¬ í•¨ìˆ˜
        
        Args:
            person_image: ì‚¬ëŒ ì´ë¯¸ì§€
            clothing_image: ì˜ë¥˜ ì´ë¯¸ì§€
            **kwargs: ì¶”ê°€ íŒŒë¼ë¯¸í„°
                - fabric_type: str = "cotton"
                - clothing_type: str = "shirt"
                - fit_preference: str = "fitted"
                - pose_guidance: Optional[Dict] = None
                - style_guidance: Optional[str] = None
                - preserve_background: bool = True
                - quality_enhancement: bool = True
        
        Returns:
            Dict containing fitted image and metadata
        """
        
        if not self.is_initialized:
            await self.initialize()
        
        start_time = time.time()
        session_id = f"vf_{uuid.uuid4().hex[:8]}"
        
        try:
            self.logger.info(f"ğŸ­ ê°€ìƒ í”¼íŒ… ì‹œì‘ - ì„¸ì…˜: {session_id}")
            
            # 1. ì…ë ¥ ê²€ì¦ ë° ì „ì²˜ë¦¬
            person_img, clothing_img = await self._preprocess_inputs(
                person_image, clothing_image
            )
            
            # 2. ìºì‹œ í™•ì¸
            cache_key = self._generate_cache_key(person_img, clothing_img, kwargs)
            cached_result = self._get_from_cache(cache_key)
            if cached_result:
                self.performance_stats['cache_hits'] += 1
                self.logger.info(f"ğŸ’¾ ìºì‹œì—ì„œ ê²°ê³¼ ë°˜í™˜ - {session_id}")
                return cached_result
            
            self.performance_stats['cache_misses'] += 1
            
            # 3. ë©”íƒ€ë°ì´í„° ì¶”ì¶œ
            metadata = await self._extract_metadata(person_img, clothing_img, kwargs)
            
            # 4. í”¼íŒ… ë°©ë²• ì„ íƒ
            fitting_result = await self._execute_fitting(
                person_img, clothing_img, metadata, session_id
            )
            
            # 5. í›„ì²˜ë¦¬
            final_result = await self._post_process_result(
                fitting_result, metadata, kwargs
            )
            
            # 6. ê²°ê³¼ êµ¬ì„±
            processing_time = time.time() - start_time
            result = self._build_result(
                final_result, metadata, processing_time, session_id
            )
            
            # 7. ìºì‹œ ì €ì¥
            self._save_to_cache(cache_key, result)
            
            # 8. í†µê³„ ì—…ë°ì´íŠ¸
            self._update_stats(processing_time, success=True)
            
            self.logger.info(f"âœ… ê°€ìƒ í”¼íŒ… ì™„ë£Œ - {session_id} ({processing_time:.2f}ì´ˆ)")
            return result
            
        except Exception as e:
            self.logger.error(f"âŒ ê°€ìƒ í”¼íŒ… ì‹¤íŒ¨ - {session_id}: {e}")
            self.logger.error(f"   ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
            
            processing_time = time.time() - start_time
            self._update_stats(processing_time, success=False)
            
            return {
                "success": False,
                "session_id": session_id,
                "error_message": str(e),
                "processing_time": processing_time,
                "fitted_image": None,
                "metadata": {}
            }
    
    async def _preprocess_inputs(
        self, 
        person_image: Union[np.ndarray, Image.Image, str],
        clothing_image: Union[np.ndarray, Image.Image, str]
    ) -> Tuple[np.ndarray, np.ndarray]:
        """ì…ë ¥ ì´ë¯¸ì§€ ì „ì²˜ë¦¬"""
        
        # ì´ë¯¸ì§€ ë¡œë“œ ë° ë³€í™˜
        person_img = self._load_and_convert_image(person_image)
        clothing_img = self._load_and_convert_image(clothing_image)
        
        # í•´ìƒë„ ì •ê·œí™”
        target_size = self.performance_config['max_resolution']
        person_img = self._resize_image(person_img, target_size)
        clothing_img = self._resize_image(clothing_img, target_size)
        
        # ìƒ‰ìƒ ê³µê°„ ì •ê·œí™”
        person_img = self._normalize_color_space(person_img)
        clothing_img = self._normalize_color_space(clothing_img)
        
        return person_img, clothing_img
    
    def _load_and_convert_image(self, image: Union[np.ndarray, Image.Image, str]) -> np.ndarray:
        """ì´ë¯¸ì§€ ë¡œë“œ ë° ë³€í™˜"""
        if isinstance(image, str):
            img = Image.open(image).convert('RGB')
            return np.array(img)
        elif isinstance(image, Image.Image):
            return np.array(image.convert('RGB'))
        elif isinstance(image, np.ndarray):
            if image.shape[-1] == 4:  # RGBA
                return image[:, :, :3]
            return image
        else:
            raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì´ë¯¸ì§€ í˜•ì‹: {type(image)}")
    
    def _resize_image(self, image: np.ndarray, target_size: int) -> np.ndarray:
        """ì´ë¯¸ì§€ ë¦¬ì‚¬ì´ì¦ˆ"""
        h, w = image.shape[:2]
        if max(h, w) != target_size:
            if h > w:
                new_h, new_w = target_size, int(w * target_size / h)
            else:
                new_h, new_w = int(h * target_size / w), target_size
            
            if CV2_AVAILABLE:
                return cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_LANCZOS4)
            else:
                from PIL import Image
                img = Image.fromarray(image)
                img = img.resize((new_w, new_h), Image.Resampling.LANCZOS)
                return np.array(img)
        
        return image
    
    def _normalize_color_space(self, image: np.ndarray) -> np.ndarray:
        """ìƒ‰ìƒ ê³µê°„ ì •ê·œí™”"""
        # 0-255 ë²”ìœ„ë¡œ ì •ê·œí™”
        if image.dtype != np.uint8:
            image = (image * 255).astype(np.uint8)
        
        # ìƒ‰ìƒ ë°¸ëŸ°ìŠ¤ ì¡°ì • (ì„ íƒì )
        if self.config.get('auto_color_balance', False):
            image = self._auto_color_balance(image)
        
        return image
    
    def _auto_color_balance(self, image: np.ndarray) -> np.ndarray:
        """ìë™ ìƒ‰ìƒ ë°¸ëŸ°ìŠ¤"""
        try:
            if CV2_AVAILABLE:
                lab = cv2.cvtColor(image, cv2.COLOR_RGB2LAB)
                l, a, b = cv2.split(lab)
                l = cv2.equalizeHist(l)
                lab = cv2.merge([l, a, b])
                return cv2.cvtColor(lab, cv2.COLOR_LAB2RGB)
            else:
                return image
        except:
            return image
    
    async def _extract_metadata(
        self, 
        person_img: np.ndarray, 
        clothing_img: np.ndarray, 
        kwargs: Dict[str, Any]
    ) -> Dict[str, Any]:
        """ë©”íƒ€ë°ì´í„° ì¶”ì¶œ"""
        
        metadata = {
            'fabric_type': kwargs.get('fabric_type', 'cotton'),
            'clothing_type': kwargs.get('clothing_type', 'shirt'),
            'fit_preference': kwargs.get('fit_preference', 'fitted'),
            'style_guidance': kwargs.get('style_guidance'),
            'preserve_background': kwargs.get('preserve_background', True),
            'quality_enhancement': kwargs.get('quality_enhancement', True),
            
            # ì´ë¯¸ì§€ ì •ë³´
            'person_image_shape': person_img.shape,
            'clothing_image_shape': clothing_img.shape,
            
            # ì¶”ì¶œëœ íŠ¹ì„±
            'fabric_properties': FABRIC_PROPERTIES.get(
                kwargs.get('fabric_type', 'cotton'),
                FABRIC_PROPERTIES['default']
            ),
            'fitting_params': CLOTHING_FITTING_PARAMS.get(
                kwargs.get('clothing_type', 'shirt'),
                CLOTHING_FITTING_PARAMS['default']
            )
        }
        
        # AI ëª¨ë¸ ê¸°ë°˜ ë¶„ì„ (ì„ íƒì )
        if self.fitting_config['ai_models_enabled']:
            ai_analysis = await self._ai_analysis(person_img, clothing_img)
            metadata.update(ai_analysis)
        
        return metadata
    
    async def _ai_analysis(
        self, 
        person_img: np.ndarray, 
        clothing_img: np.ndarray
    ) -> Dict[str, Any]:
        """AI ê¸°ë°˜ ë¶„ì„"""
        analysis = {}
        
        try:
            # ì¸ì²´ íŒŒì‹±
            if self.ai_models['human_parser']:
                body_parts = await self._parse_body_parts(person_img)
                analysis['body_parts'] = body_parts
            
            # í¬ì¦ˆ ì¶”ì •
            if self.ai_models['pose_estimator']:
                pose_keypoints = await self._estimate_pose(person_img)
                analysis['pose_keypoints'] = pose_keypoints
            
            # ì˜ë¥˜ ë¶„í• 
            if self.ai_models['cloth_segmenter']:
                cloth_mask = await self._segment_clothing(clothing_img)
                analysis['cloth_mask'] = cloth_mask
            
            # ìŠ¤íƒ€ì¼ íŠ¹ì„±
            if self.ai_models['style_encoder']:
                style_features = await self._encode_style(clothing_img)
                analysis['style_features'] = style_features
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ AI ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
        
        return analysis
    
    async def _execute_fitting(
        self,
        person_img: np.ndarray,
        clothing_img: np.ndarray,
        metadata: Dict[str, Any],
        session_id: str
    ) -> np.ndarray:
        """í”¼íŒ… ì‹¤í–‰"""
        
        method = self.fitting_config['method']
        
        if method == FittingMethod.AI_NEURAL and self.ai_models['diffusion_pipeline']:
            return await self._ai_neural_fitting(person_img, clothing_img, metadata)
        
        elif method == FittingMethod.PHYSICS_BASED and self.fitting_config['physics_enabled']:
            return await self._physics_based_fitting(person_img, clothing_img, metadata)
        
        elif method == FittingMethod.HYBRID:
            # AIì™€ ë¬¼ë¦¬ ê²°í•©
            ai_result = await self._ai_neural_fitting(person_img, clothing_img, metadata)
            if ai_result is not None:
                return await self._physics_refinement(ai_result, metadata)
            else:
                return await self._physics_based_fitting(person_img, clothing_img, metadata)
        
        else:
            # í…œí”Œë¦¿ ë§¤ì¹­ í´ë°±
            return await self._template_matching_fitting(person_img, clothing_img, metadata)
    
    async def _ai_neural_fitting(
        self,
        person_img: np.ndarray,
        clothing_img: np.ndarray,
        metadata: Dict[str, Any]
    ) -> Optional[np.ndarray]:
        """AI ì‹ ê²½ë§ ê¸°ë°˜ í”¼íŒ…"""
        
        try:
            pipeline = self.ai_models['diffusion_pipeline']
            if not pipeline:
                return None
            
            self.logger.info("ğŸ§  AI ì‹ ê²½ë§ í”¼íŒ… ì‹¤í–‰ ì¤‘...")
            
            # í”„ë¡¬í”„íŠ¸ ìƒì„±
            prompt = self._generate_fitting_prompt(metadata)
            
            # ì…ë ¥ ì´ë¯¸ì§€ ì¤€ë¹„
            person_pil = Image.fromarray(person_img)
            clothing_pil = Image.fromarray(clothing_img)
            
            # ì»¨íŠ¸ë¡¤ë„·ì´ë‚˜ ì¸í˜ì¸íŒ… ë°©ì‹ìœ¼ë¡œ ì²˜ë¦¬
            if hasattr(pipeline, 'img2img'):
                # img2img ë°©ì‹
                fitted_result = pipeline.img2img(
                    prompt=prompt,
                    image=person_pil,
                    strength=0.7,
                    guidance_scale=7.5,
                    num_inference_steps=20
                ).images[0]
            else:
                # ì¼ë°˜ text2imgì—ì„œ ì´ë¯¸ì§€ ì¡°ê±´ ì¶”ê°€
                fitted_result = pipeline(
                    prompt=prompt,
                    guidance_scale=7.5,
                    num_inference_steps=20,
                    height=person_img.shape[0],
                    width=person_img.shape[1]
                ).images[0]
            
            result_array = np.array(fitted_result)
            
            self.logger.info("âœ… AI ì‹ ê²½ë§ í”¼íŒ… ì™„ë£Œ")
            return result_array
            
        except Exception as e:
            self.logger.error(f"âŒ AI ì‹ ê²½ë§ í”¼íŒ… ì‹¤íŒ¨: {e}")
            return None
    
    def _generate_fitting_prompt(self, metadata: Dict[str, Any]) -> str:
        """í”¼íŒ…ìš© í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        fabric_type = metadata.get('fabric_type', 'cotton')
        clothing_type = metadata.get('clothing_type', 'shirt')
        fit_preference = metadata.get('fit_preference', 'fitted')
        
        prompt = f"A person wearing a {fit_preference} {fabric_type} {clothing_type}, "
        prompt += "realistic lighting, high quality, detailed fabric texture, "
        prompt += "natural pose, professional photography style"
        
        if metadata.get('style_guidance'):
            prompt += f", {metadata['style_guidance']}"
        
        return prompt
    
    async def _physics_based_fitting(
        self,
        person_img: np.ndarray,
        clothing_img: np.ndarray,
        metadata: Dict[str, Any]
    ) -> np.ndarray:
        """ë¬¼ë¦¬ ê¸°ë°˜ í”¼íŒ…"""
        
        try:
            self.logger.info("âš™ï¸ ë¬¼ë¦¬ ê¸°ë°˜ í”¼íŒ… ì‹¤í–‰ ì¤‘...")
            
            # 1. ì‹ ì²´ ëª¨ë¸ ìƒì„±
            body_model = self._create_body_model(person_img, metadata)
            
            # 2. ì˜ë¥˜ ë©”ì‰¬ ìƒì„±
            cloth_mesh = self._create_cloth_mesh(clothing_img, metadata)
            
            # 3. ë¬¼ë¦¬ ì‹œë®¬ë ˆì´ì…˜
            fitted_mesh = self._simulate_cloth_physics(body_model, cloth_mesh, metadata)
            
            # 4. ë Œë”ë§
            fitted_image = self._render_fitted_clothing(
                person_img, fitted_mesh, metadata
            )
            
            self.logger.info("âœ… ë¬¼ë¦¬ ê¸°ë°˜ í”¼íŒ… ì™„ë£Œ")
            return fitted_image
            
        except Exception as e:
            self.logger.error(f"âŒ ë¬¼ë¦¬ ê¸°ë°˜ í”¼íŒ… ì‹¤íŒ¨: {e}")
            # í´ë°±ìœ¼ë¡œ í…œí”Œë¦¿ ë§¤ì¹­ ì‚¬ìš©
            return await self._template_matching_fitting(person_img, clothing_img, metadata)
    
    def _create_body_model(
        self, 
        person_img: np.ndarray, 
        metadata: Dict[str, Any]
    ) -> Dict[str, Any]:
        """ì‹ ì²´ ëª¨ë¸ ìƒì„±"""
        
        # ê°„ë‹¨í•œ ì‹ ì²´ ëª¨ë¸ (ì‹¤ì œë¡œëŠ” ë” ë³µì¡í•œ 3D ëª¨ë¸ ì‚¬ìš©)
        body_model = {
            'image': person_img,
            'height': person_img.shape[0],
            'width': person_img.shape[1],
            'body_parts': metadata.get('body_parts', {}),
            'pose_keypoints': metadata.get('pose_keypoints', {}),
            'body_segments': self._segment_body_parts(person_img)
        }
        
        return body_model
    
    def _segment_body_parts(self, person_img: np.ndarray) -> Dict[str, np.ndarray]:
        """ì‹ ì²´ ë¶€ìœ„ ë¶„í• """
        
        # ê°„ë‹¨í•œ ìƒ‰ìƒ ê¸°ë°˜ ë¶„í•  (ì‹¤ì œë¡œëŠ” AI ëª¨ë¸ ì‚¬ìš©)
        segments = {}
        
        try:
            if CV2_AVAILABLE:
                # í”¼ë¶€ìƒ‰ ê°ì§€
                hsv = cv2.cvtColor(person_img, cv2.COLOR_RGB2HSV)
                
                # í”¼ë¶€ìƒ‰ ë²”ìœ„ (ëŒ€ëµì )
                lower_skin = np.array([0, 20, 70])
                upper_skin = np.array([20, 255, 255])
                skin_mask = cv2.inRange(hsv, lower_skin, upper_skin)
                
                segments['skin'] = skin_mask
                segments['clothing_area'] = 255 - skin_mask
            
            else:
                # OpenCV ì—†ì„ ë•Œ ê°„ë‹¨í•œ ë¶„í• 
                h, w = person_img.shape[:2]
                segments['torso'] = np.ones((h, w), dtype=np.uint8) * 255
                segments['arms'] = np.ones((h, w), dtype=np.uint8) * 128
        
        except Exception as e:
            self.logger.warning(f"âš ï¸ ì‹ ì²´ ë¶„í•  ì‹¤íŒ¨: {e}")
            h, w = person_img.shape[:2]
            segments['default'] = np.ones((h, w), dtype=np.uint8) * 255
        
        return segments
    
    def _create_cloth_mesh(
        self, 
        clothing_img: np.ndarray, 
        metadata: Dict[str, Any]
    ) -> Dict[str, Any]:
        """ì˜ë¥˜ ë©”ì‰¬ ìƒì„±"""
        
        fabric_props = metadata['fabric_properties']
        fitting_params = metadata['fitting_params']
        
        cloth_mesh = {
            'image': clothing_img,
            'fabric_properties': fabric_props,
            'fitting_parameters': fitting_params,
            'mesh_resolution': self._calculate_mesh_resolution(),
            'spring_constants': self._calculate_spring_constants(fabric_props),
            'mass_distribution': self._calculate_mass_distribution(fabric_props)
        }
        
        return cloth_mesh
    
    def _calculate_mesh_resolution(self) -> int:
        """ë©”ì‰¬ í•´ìƒë„ ê³„ì‚°"""
        quality_resolutions = {
            "fast": 32,
            "balanced": 64,
            "high": 128,
            "ultra": 256
        }
        return quality_resolutions.get(self.quality_level, 64)
    
    def _calculate_spring_constants(self, fabric_props: FabricProperties) -> Dict[str, float]:
        """ìŠ¤í”„ë§ ìƒìˆ˜ ê³„ì‚°"""
        base_spring = 100.0
        
        return {
            'structural': base_spring * fabric_props.stiffness,
            'shear': base_spring * fabric_props.stiffness * 0.5,
            'bend': base_spring * fabric_props.stiffness * 0.3,
            'stretch': base_spring * fabric_props.elasticity
        }
    
    def _calculate_mass_distribution(self, fabric_props: FabricProperties) -> float:
        """ì§ˆëŸ‰ ë¶„í¬ ê³„ì‚°"""
        return fabric_props.density * 0.01  # kg/mÂ²ë¥¼ ê°€ì •
    
    def _simulate_cloth_physics(
        self,
        body_model: Dict[str, Any],
        cloth_mesh: Dict[str, Any],
        metadata: Dict[str, Any]
    ) -> Dict[str, Any]:
        """ì²œ ë¬¼ë¦¬ ì‹œë®¬ë ˆì´ì…˜"""
        
        try:
            # ë¬¼ë¦¬ ì‹œë®¬ë ˆì´ì…˜ íŒŒë¼ë¯¸í„°
            iterations = self.physics_params['iterations']
            time_step = self.physics_params['time_step']
            damping = self.physics_params['damping']
            
            # ì´ˆê¸° ìƒíƒœ
            fitted_mesh = cloth_mesh.copy()
            
            # ë°˜ë³µ ì‹œë®¬ë ˆì´ì…˜
            for i in range(iterations):
                # ì¤‘ë ¥ ì ìš©
                fitted_mesh = self._apply_gravity(fitted_mesh, time_step)
                
                # ì‹ ì²´ ì¶©ëŒ ì²˜ë¦¬
                fitted_mesh = self._handle_body_collision(fitted_mesh, body_model)
                
                # ì²œ ì œì•½ ì¡°ê±´ ì ìš©
                fitted_mesh = self._apply_cloth_constraints(fitted_mesh)
                
                # ëŒí•‘ ì ìš©
                fitted_mesh = self._apply_damping(fitted_mesh, damping)
                
                # ìˆ˜ë ´ í™•ì¸
                if i > 0 and self._check_convergence(fitted_mesh, i):
                    break
            
            return fitted_mesh
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ ë¬¼ë¦¬ ì‹œë®¬ë ˆì´ì…˜ ì‹¤íŒ¨: {e}")
            return cloth_mesh  # ì›ë³¸ ë°˜í™˜
    
    def _apply_gravity(self, mesh: Dict[str, Any], time_step: float) -> Dict[str, Any]:
        """ì¤‘ë ¥ ì ìš©"""
        # ê°„ë‹¨í•œ ì¤‘ë ¥ ì‹œë®¬ë ˆì´ì…˜
        gravity_force = self.physics_engine['gravity'] * time_step
        mesh['gravity_offset'] = mesh.get('gravity_offset', 0) + gravity_force * 0.1
        return mesh
    
    def _handle_body_collision(
        self, 
        mesh: Dict[str, Any], 
        body_model: Dict[str, Any]
    ) -> Dict[str, Any]:
        """ì‹ ì²´ ì¶©ëŒ ì²˜ë¦¬"""
        # ì‹ ì²´ì™€ì˜ ì¶©ëŒ ê°ì§€ ë° ì²˜ë¦¬
        if self.physics_engine['body_collision']:
            # ê°„ë‹¨í•œ ì¶©ëŒ ì²˜ë¦¬ ë¡œì§
            mesh['collision_adjustments'] = mesh.get('collision_adjustments', {})
        return mesh
    
    def _apply_cloth_constraints(self, mesh: Dict[str, Any]) -> Dict[str, Any]:
        """ì²œ ì œì•½ ì¡°ê±´ ì ìš©"""
        # ìŠ¤í”„ë§ ìƒìˆ˜ë¥¼ ì´ìš©í•œ ì œì•½ ì¡°ê±´
        spring_constants = mesh['spring_constants']
        
        # êµ¬ì¡°ì  ì œì•½
        if 'structural' in spring_constants:
            mesh['structural_tension'] = spring_constants['structural']
        
        # ì‹ ì¶•ì„± ì œì•½
        if 'stretch' in spring_constants:
            mesh['stretch_limit'] = spring_constants['stretch']
        
        return mesh
    
    def _apply_damping(self, mesh: Dict[str, Any], damping: float) -> Dict[str, Any]:
        """ëŒí•‘ ì ìš©"""
        mesh['damping_factor'] = damping
        return mesh
    
    def _check_convergence(self, mesh: Dict[str, Any], iteration: int) -> bool:
        """ìˆ˜ë ´ í™•ì¸"""
        # ê°„ë‹¨í•œ ìˆ˜ë ´ ì¡°ê±´
        return iteration > self.physics_params['iterations'] * 0.8
    
    def _render_fitted_clothing(
        self,
        person_img: np.ndarray,
        fitted_mesh: Dict[str, Any],
        metadata: Dict[str, Any]
    ) -> np.ndarray:
        """í”¼íŒ…ëœ ì˜ë¥˜ ë Œë”ë§"""
        
        try:
            # ë² ì´ìŠ¤ ì´ë¯¸ì§€ë¡œ ì‹œì‘
            result = person_img.copy()
            clothing_img = fitted_mesh['image']
            
            # ê°„ë‹¨í•œ í•©ì„± (ì‹¤ì œë¡œëŠ” 3D ë Œë”ë§)
            fitted_result = self._simple_cloth_compositing(
                result, clothing_img, metadata
            )
            
            # ì¡°ëª… ë° ê·¸ë¦¼ì íš¨ê³¼
            if self.fitting_config['enable_shadows']:
                fitted_result = self._add_lighting_effects(fitted_result, metadata)
            
            # í…ìŠ¤ì²˜ ë³´ì¡´
            if self.fitting_config['texture_preservation']:
                fitted_result = self._preserve_texture_details(
                    fitted_result, clothing_img, metadata
                )
            
            return fitted_result
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ ë Œë”ë§ ì‹¤íŒ¨: {e}")
            return person_img
    
    def _simple_cloth_compositing(
        self,
        person_img: np.ndarray,
        clothing_img: np.ndarray,
        metadata: Dict[str, Any]
    ) -> np.ndarray:
        """ê°„ë‹¨í•œ ì˜ë¥˜ í•©ì„±"""
        
        # ì˜ë¥˜ ì˜ì—­ ê°ì§€
        clothing_mask = self._create_clothing_mask(person_img, metadata)
        
        # ì˜ë¥˜ ì´ë¯¸ì§€ ë³€í˜•
        warped_clothing = self._warp_clothing_to_body(
            clothing_img, person_img, clothing_mask, metadata
        )
        
        # ì•ŒíŒŒ ë¸”ë Œë”©
        alpha = 0.8  # ì˜ë¥˜ ë¶ˆíˆ¬ëª…ë„
        result = person_img.copy()
        
        # ë§ˆìŠ¤í¬ëœ ì˜ì—­ì— ì˜ë¥˜ ì ìš©
        for i in range(3):  # RGB ì±„ë„
            result[:, :, i] = np.where(
                clothing_mask > 128,
                alpha * warped_clothing[:, :, i] + (1 - alpha) * person_img[:, :, i],
                person_img[:, :, i]
            )
        
        return result.astype(np.uint8)
    
    def _create_clothing_mask(
        self, 
        person_img: np.ndarray, 
        metadata: Dict[str, Any]
    ) -> np.ndarray:
        """ì˜ë¥˜ ë§ˆìŠ¤í¬ ìƒì„±"""
        
        h, w = person_img.shape[:2]
        clothing_type = metadata.get('clothing_type', 'shirt')
        
        # ì˜ë¥˜ íƒ€ì…ë³„ ë§ˆìŠ¤í¬ ì˜ì—­
        if clothing_type in ['shirt', 'blouse', 'jacket']:
            # ìƒì²´ ì˜ì—­
            mask = np.zeros((h, w), dtype=np.uint8)
            mask[h//4:h//2, w//4:3*w//4] = 255
        
        elif clothing_type in ['dress']:
            # ë“œë ˆìŠ¤ ì˜ì—­ (ìƒì²´ + í•˜ì²´)
            mask = np.zeros((h, w), dtype=np.uint8)
            mask[h//4:3*h//4, w//4:3*w//4] = 255
        
        elif clothing_type in ['pants']:
            # í•˜ì²´ ì˜ì—­
            mask = np.zeros((h, w), dtype=np.uint8)
            mask[h//2:h, w//3:2*w//3] = 255
        
        else:
            # ê¸°ë³¸ ìƒì²´ ì˜ì—­
            mask = np.zeros((h, w), dtype=np.uint8)
            mask[h//4:h//2, w//4:3*w//4] = 255
        
        # ìŠ¤ë¬´ë”©
        if CV2_AVAILABLE:
            mask = cv2.GaussianBlur(mask, (15, 15), 0)
        
        return mask
    
    def _warp_clothing_to_body(
        self,
        clothing_img: np.ndarray,
        person_img: np.ndarray,
        clothing_mask: np.ndarray,
        metadata: Dict[str, Any]
    ) -> np.ndarray:
        """ì˜ë¥˜ë¥¼ ì‹ ì²´ì— ë§ê²Œ ë³€í˜•"""
        
        # ì˜ë¥˜ ì´ë¯¸ì§€ë¥¼ ë§ˆìŠ¤í¬ ì˜ì—­ í¬ê¸°ì— ë§ê²Œ ë¦¬ì‚¬ì´ì¦ˆ
        mask_coords = np.where(clothing_mask > 0)
        if len(mask_coords[0]) > 0:
            min_y, max_y = np.min(mask_coords[0]), np.max(mask_coords[0])
            min_x, max_x = np.min(mask_coords[1]), np.max(mask_coords[1])
            
            mask_h, mask_w = max_y - min_y, max_x - min_x
            
            if mask_h > 0 and mask_w > 0:
                # ì˜ë¥˜ ì´ë¯¸ì§€ ë¦¬ì‚¬ì´ì¦ˆ
                resized_clothing = self._resize_image(clothing_img, max(mask_h, mask_w))
                
                # ê²°ê³¼ ì´ë¯¸ì§€ í¬ê¸°ì— ë§ê²Œ ì¡°ì •
                warped = np.zeros_like(person_img)
                
                # ì¤‘ì•™ ë°°ì¹˜
                ch, cw = resized_clothing.shape[:2]
                cy = min_y + (mask_h - ch) // 2
                cx = min_x + (mask_w - cw) // 2
                
                # ë²”ìœ„ í™•ì¸ í›„ ë°°ì¹˜
                if cy >= 0 and cx >= 0 and cy + ch <= person_img.shape[0] and cx + cw <= person_img.shape[1]:
                    warped[cy:cy+ch, cx:cx+cw] = resized_clothing
                
                return warped
        
        # í´ë°±: ì „ì²´ ì´ë¯¸ì§€ ë¦¬ì‚¬ì´ì¦ˆ
        return self._resize_image(clothing_img, person_img.shape[0])
    
    def _add_lighting_effects(
        self, 
        fitted_img: np.ndarray, 
        metadata: Dict[str, Any]
    ) -> np.ndarray:
        """ì¡°ëª… íš¨ê³¼ ì¶”ê°€"""
        
        try:
            result = fitted_img.copy().astype(np.float32)
            
            # ë©”ì¸ ì¡°ëª…
            main_light = self.lighting_setup['main_light']
            result = self._apply_directional_light(result, main_light)
            
            # ë³´ì¡° ì¡°ëª…
            fill_light = self.lighting_setup['fill_light']
            result = self._apply_directional_light(result, fill_light, strength=0.3)
            
            # í™˜ê²½ ì¡°ëª…
            ambient = self.lighting_setup['ambient']
            result = self._apply_ambient_light(result, ambient)
            
            return np.clip(result, 0, 255).astype(np.uint8)
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ ì¡°ëª… íš¨ê³¼ ì¶”ê°€ ì‹¤íŒ¨: {e}")
            return fitted_img
    
    def _apply_directional_light(
        self, 
        image: np.ndarray, 
        light_config: Dict[str, Any], 
        strength: float = 1.0
    ) -> np.ndarray:
        """ë°©í–¥ì„± ì¡°ëª… ì ìš©"""
        
        direction = light_config['direction']
        intensity = light_config['intensity'] * strength
        color = light_config['color']
        
        # ê°„ë‹¨í•œ ì¡°ëª… ê³„ì‚°
        h, w = image.shape[:2]
        
        # ê·¸ë¼ë””ì–¸íŠ¸ ë§ˆìŠ¤í¬ ìƒì„±
        light_mask = np.ones((h, w), dtype=np.float32)
        
        # ì¡°ëª… ë°©í–¥ì— ë”°ë¥¸ ê·¸ë¼ë””ì–¸íŠ¸
        if direction[0] > 0:  # ì™¼ìª½ì—ì„œ ì˜¤ëŠ” ë¹›
            for x in range(w):
                light_mask[:, x] *= (1.0 - direction[0] * x / w)
        
        if direction[1] > 0:  # ìœ„ì—ì„œ ì˜¤ëŠ” ë¹›
            for y in range(h):
                light_mask[y, :] *= (1.0 - direction[1] * y / h)
        
        # ì¡°ëª… ì ìš©
        for i in range(3):  # RGB ì±„ë„
            channel_multiplier = intensity * color[i]
            image[:, :, i] *= (1.0 + light_mask * channel_multiplier * 0.2)
        
        return image
    
    def _apply_ambient_light(
        self, 
        image: np.ndarray, 
        ambient_config: Dict[str, Any]
    ) -> np.ndarray:
        """í™˜ê²½ ì¡°ëª… ì ìš©"""
        
        intensity = ambient_config['intensity']
        color = ambient_config['color']
        
        # ì „ì²´ì ìœ¼ë¡œ ë°ê¸° ì¡°ì •
        for i in range(3):
            image[:, :, i] += intensity * color[i] * 20
        
        return image
    
    def _preserve_texture_details(
        self,
        fitted_img: np.ndarray,
        clothing_img: np.ndarray,
        metadata: Dict[str, Any]
    ) -> np.ndarray:
        """í…ìŠ¤ì²˜ ë””í…Œì¼ ë³´ì¡´"""
        
        try:
            # ê³ ì£¼íŒŒ ì„±ë¶„ ì¶”ì¶œ
            if CV2_AVAILABLE:
                # ì˜ë¥˜ ì´ë¯¸ì§€ì˜ í…ìŠ¤ì²˜ ì¶”ì¶œ
                clothing_gray = cv2.cvtColor(clothing_img, cv2.COLOR_RGB2GRAY)
                texture = cv2.Laplacian(clothing_gray, cv2.CV_64F)
                texture = np.abs(texture)
                
                # í…ìŠ¤ì²˜ë¥¼ RGBë¡œ ë³€í™˜
                texture_rgb = np.stack([texture] * 3, axis=-1)
                texture_rgb = (texture_rgb / texture_rgb.max() * 50).astype(np.float32)
                
                # í”¼íŒ…ëœ ì´ë¯¸ì§€ì— í…ìŠ¤ì²˜ ì¶”ê°€
                result = fitted_img.astype(np.float32) + texture_rgb * 0.3
                return np.clip(result, 0, 255).astype(np.uint8)
            
            else:
                return fitted_img
                
        except Exception as e:
            self.logger.warning(f"âš ï¸ í…ìŠ¤ì²˜ ë³´ì¡´ ì‹¤íŒ¨: {e}")
            return fitted_img
    
    async def _template_matching_fitting(
        self,
        person_img: np.ndarray,
        clothing_img: np.ndarray,
        metadata: Dict[str, Any]
    ) -> np.ndarray:
        """í…œí”Œë¦¿ ë§¤ì¹­ í”¼íŒ… (í´ë°± ë°©ë²•)"""
        
        try:
            self.logger.info("ğŸ“ í…œí”Œë¦¿ ë§¤ì¹­ í”¼íŒ… ì‹¤í–‰ ì¤‘...")
            
            # 1. ì‹ ì²´ ì˜ì—­ ê°ì§€
            body_regions = self._detect_body_regions(person_img)
            
            # 2. ì˜ë¥˜ í…œí”Œë¦¿ ë§¤ì¹­
            clothing_regions = self._match_clothing_template(
                clothing_img, body_regions, metadata
            )
            
            # 3. ë³€í˜• ë° í•©ì„±
            fitted_result = self._apply_template_transformation(
                person_img, clothing_regions, metadata
            )
            
            self.logger.info("âœ… í…œí”Œë¦¿ ë§¤ì¹­ í”¼íŒ… ì™„ë£Œ")
            return fitted_result
            
        except Exception as e:
            self.logger.error(f"âŒ í…œí”Œë¦¿ ë§¤ì¹­ í”¼íŒ… ì‹¤íŒ¨: {e}")
            return self._simple_overlay_fitting(person_img, clothing_img, metadata)
    
    def _detect_body_regions(self, person_img: np.ndarray) -> Dict[str, Tuple[int, int, int, int]]:
        """ì‹ ì²´ ì˜ì—­ ê°ì§€"""
        
        h, w = person_img.shape[:2]
        
        # ê°„ë‹¨í•œ ì‹ ì²´ ì˜ì—­ ì¶”ì •
        regions = {
            'head': (w//3, 0, w//3, h//4),
            'torso': (w//4, h//4, w//2, h//2),
            'arms': (0, h//4, w, h//3),
            'legs': (w//3, 2*h//3, w//3, h//3)
        }
        
        return regions
    
    def _match_clothing_template(
        self,
        clothing_img: np.ndarray,
        body_regions: Dict[str, Tuple[int, int, int, int]],
        metadata: Dict[str, Any]
    ) -> Dict[str, np.ndarray]:
        """ì˜ë¥˜ í…œí”Œë¦¿ ë§¤ì¹­"""
        
        clothing_type = metadata.get('clothing_type', 'shirt')
        
        # ì˜ë¥˜ íƒ€ì…ì— ë”°ë¥¸ ì˜ì—­ ë§¤í•‘
        if clothing_type in ['shirt', 'blouse', 'jacket']:
            target_region = body_regions['torso']
        elif clothing_type == 'dress':
            target_region = (body_regions['torso'][0], body_regions['torso'][1],
                           body_regions['torso'][2], body_regions['torso'][3] + body_regions['legs'][3])
        elif clothing_type == 'pants':
            target_region = body_regions['legs']
        else:
            target_region = body_regions['torso']
        
        # ì˜ë¥˜ ì´ë¯¸ì§€ë¥¼ ëŒ€ìƒ ì˜ì—­ì— ë§ê²Œ ë³€í˜•
        x, y, w, h = target_region
        clothing_fitted = self._resize_image(clothing_img, max(w, h))
        
        return {'main': clothing_fitted, 'region': target_region}
    
    def _apply_template_transformation(
        self,
        person_img: np.ndarray,
        clothing_regions: Dict[str, Any],
        metadata: Dict[str, Any]
    ) -> np.ndarray:
        """í…œí”Œë¦¿ ë³€í˜• ì ìš©"""
        
        result = person_img.copy()
        clothing_fitted = clothing_regions['main']
        x, y, w, h = clothing_regions['region']
        
        # ì˜ë¥˜ ì´ë¯¸ì§€ í¬ê¸° ì¡°ì •
        ch, cw = clothing_fitted.shape[:2]
        if ch > h:
            scale = h / ch
            new_h, new_w = int(ch * scale), int(cw * scale)
            clothing_fitted = self._resize_image(clothing_fitted, max(new_h, new_w))
            ch, cw = clothing_fitted.shape[:2]
        
        # ì¤‘ì•™ ì •ë ¬
        start_y = max(0, y + (h - ch) // 2)
        start_x = max(0, x + (w - cw) // 2)
        end_y = min(person_img.shape[0], start_y + ch)
        end_x = min(person_img.shape[1], start_x + cw)
        
        # ì‹¤ì œ ë³µì‚¬ë  ì˜ì—­ ê³„ì‚°
        copy_h = end_y - start_y
        copy_w = end_x - start_x
        
        if copy_h > 0 and copy_w > 0:
            # ì•ŒíŒŒ ë¸”ë Œë”©ìœ¼ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ í•©ì„±
            alpha = 0.7
            clothing_crop = clothing_fitted[:copy_h, :copy_w]
            original_crop = result[start_y:end_y, start_x:end_x]
            
            blended = (alpha * clothing_crop + (1 - alpha) * original_crop).astype(np.uint8)
            result[start_y:end_y, start_x:end_x] = blended
        
        return result
    
    def _simple_overlay_fitting(
        self,
        person_img: np.ndarray,
        clothing_img: np.ndarray,
        metadata: Dict[str, Any]
    ) -> np.ndarray:
        """ê°„ë‹¨í•œ ì˜¤ë²„ë ˆì´ í”¼íŒ… (ìµœì¢… í´ë°±)"""
        
        self.logger.info("ğŸ”„ ê°„ë‹¨í•œ ì˜¤ë²„ë ˆì´ í”¼íŒ… ì‚¬ìš©")
        
        result = person_img.copy()
        h, w = result.shape[:2]
        
        # ì˜ë¥˜ë¥¼ ì¤‘ì•™ ìƒë‹¨ì— ë°°ì¹˜
        clothing_resized = self._resize_image(clothing_img, min(w//2, h//2))
        ch, cw = clothing_resized.shape[:2]
        
        y_offset = h // 4
        x_offset = (w - cw) // 2
        
        if (y_offset + ch <= h and x_offset + cw <= w and
            y_offset >= 0 and x_offset >= 0):
            
            # ê°„ë‹¨í•œ ì•ŒíŒŒ ë¸”ë Œë”©
            alpha = 0.6
            result[y_offset:y_offset+ch, x_offset:x_offset+cw] = (
                alpha * clothing_resized + 
                (1 - alpha) * result[y_offset:y_offset+ch, x_offset:x_offset+cw]
            ).astype(np.uint8)
        
        return result
    
    async def _physics_refinement(
        self,
        ai_result: np.ndarray,
        metadata: Dict[str, Any]
    ) -> np.ndarray:
        """ë¬¼ë¦¬ ê¸°ë°˜ ì„¸ë°€í™”"""
        
        try:
            # AI ê²°ê³¼ì— ë¬¼ë¦¬ì  íŠ¹ì„± ì¶”ê°€
            refined_result = ai_result.copy()
            
            # ì£¼ë¦„ íš¨ê³¼ ì¶”ê°€
            if self.fitting_config['wrinkle_simulation']:
                refined_result = self._add_wrinkle_effects(refined_result, metadata)
            
            # ì¤‘ë ¥ íš¨ê³¼ (ë“œë ˆì´í•‘)
            if metadata['fitting_params'].drape_level > 0.5:
                refined_result = self._add_draping_effects(refined_result, metadata)
            
            # ì²œ í…ìŠ¤ì²˜ í–¥ìƒ
            refined_result = self._enhance_fabric_texture(refined_result, metadata)
            
            return refined_result
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ ë¬¼ë¦¬ ì„¸ë°€í™” ì‹¤íŒ¨: {e}")
            return ai_result
    
    def _add_wrinkle_effects(
        self,
        image: np.ndarray,
        metadata: Dict[str, Any]
    ) -> np.ndarray:
        """ì£¼ë¦„ íš¨ê³¼ ì¶”ê°€"""
        
        try:
            wrinkle_intensity = metadata['fitting_params'].wrinkle_intensity
            
            if wrinkle_intensity > 0 and CV2_AVAILABLE:
                # ë…¸ì´ì¦ˆ ê¸°ë°˜ ì£¼ë¦„ ìƒì„±
                h, w = image.shape[:2]
                noise = np.random.normal(0, wrinkle_intensity * 10, (h, w))
                
                # ê°€ìš°ì‹œì•ˆ ë¸”ëŸ¬ë¡œ ë¶€ë“œëŸ½ê²Œ
                noise = cv2.GaussianBlur(noise.astype(np.float32), (5, 5), 0)
                
                # ì´ë¯¸ì§€ì— ì ìš©
                result = image.astype(np.float32)
                for i in range(3):
                    result[:, :, i] += noise * 0.5
                
                return np.clip(result, 0, 255).astype(np.uint8)
            
            return image
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ ì£¼ë¦„ íš¨ê³¼ ì¶”ê°€ ì‹¤íŒ¨: {e}")
            return image
    
    def _add_draping_effects(
        self,
        image: np.ndarray,
        metadata: Dict[str, Any]
    ) -> np.ndarray:
        """ë“œë ˆì´í•‘ íš¨ê³¼ ì¶”ê°€"""
        
        try:
            drape_level = metadata['fitting_params'].drape_level
            
            if drape_level > 0.3:
                # ê°„ë‹¨í•œ ì™œê³¡ íš¨ê³¼ë¡œ ë“œë ˆì´í•‘ ì‹œë®¬ë ˆì´ì…˜
                h, w = image.shape[:2]
                
                # ìˆ˜ì§ ì™œê³¡ ë§µ ìƒì„±
                map_y = np.zeros((h, w), dtype=np.float32)
                for y in range(h):
                    wave = np.sin(np.linspace(0, 4*np.pi, w)) * drape_level * 2
                    map_y[y, :] = y + wave * (y / h)
                
                map_x = np.tile(np.arange(w), (h, 1)).astype(np.float32)
                
                if CV2_AVAILABLE:
                    # ë¦¬ë§µ ì ìš©
                    draped = cv2.remap(image, map_x, map_y, cv2.INTER_LINEAR)
                    return draped
            
            return image
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ ë“œë ˆì´í•‘ íš¨ê³¼ ì¶”ê°€ ì‹¤íŒ¨: {e}")
            return image
    
    def _enhance_fabric_texture(
        self,
        image: np.ndarray,
        metadata: Dict[str, Any]
    ) -> np.ndarray:
        """ì²œ í…ìŠ¤ì²˜ í–¥ìƒ"""
        
        try:
            fabric_props = metadata['fabric_properties']
            
            # ê´‘íƒ íš¨ê³¼
            if fabric_props.shine > 0.5:
                image = self._add_shine_effect(image, fabric_props.shine)
            
            # í…ìŠ¤ì²˜ ìŠ¤ì¼€ì¼ë§
            if fabric_props.texture_scale != 1.0:
                image = self._scale_texture(image, fabric_props.texture_scale)
            
            return image
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ í…ìŠ¤ì²˜ í–¥ìƒ ì‹¤íŒ¨: {e}")
            return image
    
    def _add_shine_effect(self, image: np.ndarray, shine_level: float) -> np.ndarray:
        """ê´‘íƒ íš¨ê³¼ ì¶”ê°€"""
        
        try:
            # í•˜ì´ë¼ì´íŠ¸ ì˜ì—­ ìƒì„±
            h, w = image.shape[:2]
            highlight = np.zeros((h, w), dtype=np.float32)
            
            # ì¤‘ì•™ì—ì„œ ê°€ì¥ìë¦¬ë¡œ ê°ˆìˆ˜ë¡ ê°ì†Œí•˜ëŠ” ê´‘íƒ
            center_y, center_x = h // 2, w // 2
            for y in range(h):
                for x in range(w):
                    dist = np.sqrt((y - center_y)**2 + (x - center_x)**2)
                    max_dist = np.sqrt(center_y**2 + center_x**2)
                    highlight[y, x] = max(0, (1 - dist / max_dist) * shine_level)
            
            # ì´ë¯¸ì§€ì— ì ìš©
            result = image.astype(np.float32)
            for i in range(3):
                result[:, :, i] += highlight * 30
            
            return np.clip(result, 0, 255).astype(np.uint8)
            
        except Exception as e:
            return image
    
    def _scale_texture(self, image: np.ndarray, scale: float) -> np.ndarray:
        """í…ìŠ¤ì²˜ ìŠ¤ì¼€ì¼ë§"""
        # ê°„ë‹¨í•œ ë…¸ì´ì¦ˆ ì¶”ê°€ë¡œ í…ìŠ¤ì²˜ íš¨ê³¼
        if scale != 1.0:
            noise = np.random.normal(0, (scale - 1.0) * 5, image.shape)
            result = image.astype(np.float32) + noise
            return np.clip(result, 0, 255).astype(np.uint8)
        return image
    
    # =================================================================
    # 5. AI ëª¨ë¸ë³„ ì²˜ë¦¬ í•¨ìˆ˜ë“¤
    # =================================================================
    
    async def _parse_body_parts(self, person_img: np.ndarray) -> Dict[str, Any]:
        """AI ì¸ì²´ íŒŒì‹±"""
        try:
            parser = self.ai_models['human_parser']
            if parser and hasattr(parser, 'parse'):
                result = await parser.parse(person_img)
                return result
            return {}
        except Exception as e:
            self.logger.warning(f"âš ï¸ ì¸ì²´ íŒŒì‹± ì‹¤íŒ¨: {e}")
            return {}
    
    async def _estimate_pose(self, person_img: np.ndarray) -> Dict[str, Any]:
        """AI í¬ì¦ˆ ì¶”ì •"""
        try:
            estimator = self.ai_models['pose_estimator']
            if estimator and hasattr(estimator, 'estimate'):
                result = await estimator.estimate(person_img)
                return result
            return {}
        except Exception as e:
            self.logger.warning(f"âš ï¸ í¬ì¦ˆ ì¶”ì • ì‹¤íŒ¨: {e}")
            return {}
    
    async def _segment_clothing(self, clothing_img: np.ndarray) -> Optional[np.ndarray]:
        """AI ì˜ë¥˜ ë¶„í• """
        try:
            segmenter = self.ai_models['cloth_segmenter']
            if segmenter and hasattr(segmenter, 'segment'):
                result = await segmenter.segment(clothing_img)
                return result
            return None
        except Exception as e:
            self.logger.warning(f"âš ï¸ ì˜ë¥˜ ë¶„í•  ì‹¤íŒ¨: {e}")
            return None
    
    async def _encode_style(self, clothing_img: np.ndarray) -> Optional[np.ndarray]:
        """AI ìŠ¤íƒ€ì¼ ì¸ì½”ë”©"""
        try:
            encoder = self.ai_models['style_encoder']
            if encoder and hasattr(encoder, 'encode'):
                result = await encoder.encode(clothing_img)
                return result
            return None
        except Exception as e:
            self.logger.warning(f"âš ï¸ ìŠ¤íƒ€ì¼ ì¸ì½”ë”© ì‹¤íŒ¨: {e}")
            return None
    
    # =================================================================
    # 6. í›„ì²˜ë¦¬ ë° ê²°ê³¼ êµ¬ì„±
    # =================================================================
    
    async def _post_process_result(
        self,
        fitted_image: np.ndarray,
        metadata: Dict[str, Any],
        kwargs: Dict[str, Any]
    ) -> np.ndarray:
        """ê²°ê³¼ í›„ì²˜ë¦¬"""
        
        result = fitted_image.copy()
        
        try:
            # í’ˆì§ˆ í–¥ìƒ (ì„ íƒì )
            if kwargs.get('quality_enhancement', True):
                result = await self._enhance_image_quality(result)
            
            # ë°°ê²½ ë³´ì¡´ (ì„ íƒì )
            if kwargs.get('preserve_background', True):
                # ì›ë³¸ ë°°ê²½ê³¼ í•©ì„±ëœ ê²°ê³¼ ë¸”ë Œë”©
                pass  # êµ¬í˜„ ìƒëµ (ë³µì¡í•¨)
            
            # ìƒ‰ìƒ ë³´ì •
            result = self._color_correction(result, metadata)
            
            # ìµœì¢… í•„í„°ë§
            result = self._apply_final_filters(result, metadata)
            
            return result
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ í›„ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return fitted_image
    
    async def _enhance_image_quality(self, image: np.ndarray) -> np.ndarray:
        """ì´ë¯¸ì§€ í’ˆì§ˆ í–¥ìƒ"""
        
        try:
            result = image.copy()
            
            # ìƒ¤í”„ë‹
            if CV2_AVAILABLE:
                kernel = np.array([[-1,-1,-1], [-1,9,-1], [-1,-1,-1]])
                sharpened = cv2.filter2D(result, -1, kernel)
                result = cv2.addWeighted(result, 0.7, sharpened, 0.3, 0)
            
            # ëŒ€ë¹„ í–¥ìƒ
            result = self._enhance_contrast(result)
            
            # ë…¸ì´ì¦ˆ ì œê±°
            if CV2_AVAILABLE:
                result = cv2.bilateralFilter(result, 9, 75, 75)
            
            return result
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ í’ˆì§ˆ í–¥ìƒ ì‹¤íŒ¨: {e}")
            return image
    
    def _enhance_contrast(self, image: np.ndarray) -> np.ndarray:
        """ëŒ€ë¹„ í–¥ìƒ"""
        try:
            # íˆìŠ¤í† ê·¸ë¨ í‰í™œí™”
            if CV2_AVAILABLE:
                lab = cv2.cvtColor(image, cv2.COLOR_RGB2LAB)
                l, a, b = cv2.split(lab)
                l = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8)).apply(l)
                lab = cv2.merge([l, a, b])
                return cv2.cvtColor(lab, cv2.COLOR_LAB2RGB)
            else:
                return image
        except:
            return image
    
    def _color_correction(self, image: np.ndarray, metadata: Dict[str, Any]) -> np.ndarray:
        """ìƒ‰ìƒ ë³´ì •"""
        
        try:
            fabric_type = metadata.get('fabric_type', 'cotton')
            
            # ì²œ ì¬ì§ˆë³„ ìƒ‰ìƒ ì¡°ì •
            if fabric_type == 'silk':
                # ì‹¤í¬: ì±„ë„ ì¦ê°€
                if CV2_AVAILABLE:
                    hsv = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)
                    hsv[:, :, 1] = hsv[:, :, 1] * 1.2  # ì±„ë„ ì¦ê°€
                    return cv2.cvtColor(hsv, cv2.COLOR_HSV2RGB)
            
            elif fabric_type == 'denim':
                # ë°ë‹˜: íŒŒë€ìƒ‰ í†¤ ê°•í™”
                image[:, :, 2] = np.clip(image[:, :, 2] * 1.1, 0, 255)  # íŒŒë€ìƒ‰ ê°•í™”
            
            elif fabric_type == 'leather':
                # ê°€ì£½: ê°ˆìƒ‰ í†¤ ê°•í™”
                image[:, :, 0] = np.clip(image[:, :, 0] * 1.1, 0, 255)  # ë¹¨ê°„ìƒ‰ ê°•í™”
                image[:, :, 1] = np.clip(image[:, :, 1] * 1.05, 0, 255)  # ë…¹ìƒ‰ ì•½ê°„ ê°•í™”
            
            return image
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ ìƒ‰ìƒ ë³´ì • ì‹¤íŒ¨: {e}")
            return image
    
    def _apply_final_filters(self, image: np.ndarray, metadata: Dict[str, Any]) -> np.ndarray:
        """ìµœì¢… í•„í„° ì ìš©"""
        
        try:
            # ì§ˆê° í–¥ìƒ
            if metadata.get('fabric_properties'):
                fabric_props = metadata['fabric_properties']
                if fabric_props.shine > 0.3:
                    # ê´‘íƒ ìˆëŠ” ì¬ì§ˆì— ëŒ€í•œ ì¶”ê°€ ì²˜ë¦¬
                    image = self._add_shine_effect(image, fabric_props.shine * 0.5)
            
            # ì „ì²´ì ì¸ ìƒ‰ì˜¨ë„ ì¡°ì •
            if self.config.get('warm_tone', False):
                image[:, :, 0] = np.clip(image[:, :, 0] * 1.05, 0, 255)  # ë”°ëœ»í•œ í†¤
                image[:, :, 2] = np.clip(image[:, :, 2] * 0.98, 0, 255)
            
            return image
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ ìµœì¢… í•„í„° ì ìš© ì‹¤íŒ¨: {e}")
            return image
    
    def _build_result(
        self,
        fitted_image: np.ndarray,
        metadata: Dict[str, Any],
        processing_time: float,
        session_id: str
    ) -> Dict[str, Any]:
        """ìµœì¢… ê²°ê³¼ êµ¬ì„±"""
        
        # í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°
        quality_score = self._calculate_quality_score(fitted_image, metadata)
        
        # ì‹ ë¢°ë„ ê³„ì‚°
        confidence_score = self._calculate_confidence_score(metadata, processing_time)
        
        # í”¼íŒ… ì ìˆ˜ ê³„ì‚°
        fit_score = self._calculate_fit_score(metadata)
        
        result = {
            "success": True,
            "session_id": session_id,
            "fitted_image": fitted_image,
            "processing_time": processing_time,
            
            # ì ìˆ˜ë“¤
            "quality_score": quality_score,
            "confidence_score": confidence_score, 
            "fit_score": fit_score,
            "overall_score": (quality_score + confidence_score + fit_score) / 3,
            
            # ë©”íƒ€ë°ì´í„°
            "metadata": {
                "fabric_type": metadata.get('fabric_type'),
                "clothing_type": metadata.get('clothing_type'),
                "fitting_method": self.fitting_method,
                "quality_level": self.quality_level,
                "image_resolution": fitted_image.shape[:2],
                "ai_models_used": [name for name, model in self.ai_models.items() if model is not None],
                "physics_enabled": self.fitting_config['physics_enabled']
            },
            
            # ì„±ëŠ¥ ì •ë³´
            "performance_info": {
                "device": self.device,
                "memory_usage_mb": self._get_current_memory_usage(),
                "processing_method": self.fitting_config['method'].value,
                "cache_used": session_id in self.fitting_cache
            },
            
            # ê°œì„  ì œì•ˆ
            "recommendations": self._generate_recommendations(metadata, quality_score)
        }
        
        return result
    
    def _calculate_quality_score(self, image: np.ndarray, metadata: Dict[str, Any]) -> float:
        """í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°"""
        
        try:
            scores = []
            
            # 1. ì´ë¯¸ì§€ ì„ ëª…ë„
            if CV2_AVAILABLE:
                gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
                sharpness = cv2.Laplacian(gray, cv2.CV_64F).var()
                sharpness_score = min(1.0, sharpness / 1000.0)
                scores.append(sharpness_score)
            
            # 2. ìƒ‰ìƒ ë¶„í¬
            color_variance = np.var(image, axis=(0,1)).mean()
            color_score = min(1.0, color_variance / 5000.0)
            scores.append(color_score)
            
            # 3. ëŒ€ë¹„
            contrast = image.max() - image.min()
            contrast_score = min(1.0, contrast / 255.0)
            scores.append(contrast_score)
            
            # 4. ë…¸ì´ì¦ˆ ë ˆë²¨ (ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ)
            noise_level = np.std(image)
            noise_score = max(0.0, 1.0 - noise_level / 50.0)
            scores.append(noise_score)
            
            return float(np.mean(scores))
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ í’ˆì§ˆ ì ìˆ˜ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return 0.7  # ê¸°ë³¸ê°’
    
    def _calculate_confidence_score(self, metadata: Dict[str, Any], processing_time: float) -> float:
        """ì‹ ë¢°ë„ ì ìˆ˜ ê³„ì‚°"""
        
        try:
            scores = []
            
            # 1. AI ëª¨ë¸ ì‚¬ìš© ì—¬ë¶€
            ai_models_used = sum(1 for model in self.ai_models.values() if model is not None)
            ai_score = ai_models_used / len(self.ai_models)
            scores.append(ai_score)
            
            # 2. ì²˜ë¦¬ ì‹œê°„ (ì ì ˆí•œ ì‹œê°„ì¼ìˆ˜ë¡ ë†’ì€ ì ìˆ˜)
            if processing_time < 2.0:
                time_score = 0.6  # ë„ˆë¬´ ë¹¨ë¼ë„ ì‹ ë¢°ë„ ë‚®ìŒ
            elif processing_time < 10.0:
                time_score = 1.0  # ì ì ˆí•œ ì‹œê°„
            else:
                time_score = max(0.3, 1.0 - (processing_time - 10.0) / 30.0)
            scores.append(time_score)
            
            # 3. ì…ë ¥ ë°ì´í„° í’ˆì§ˆ
            input_quality = 1.0
            if metadata.get('person_image_shape') and metadata.get('clothing_image_shape'):
                person_pixels = np.prod(metadata['person_image_shape'][:2])
                clothing_pixels = np.prod(metadata['clothing_image_shape'][:2])
                min_pixels = min(person_pixels, clothing_pixels)
                input_quality = min(1.0, min_pixels / (512 * 512))
            scores.append(input_quality)
            
            return float(np.mean(scores))
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ ì‹ ë¢°ë„ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return 0.7
    
    def _calculate_fit_score(self, metadata: Dict[str, Any]) -> float:
        """í”¼íŒ… ì ìˆ˜ ê³„ì‚°"""
        
        try:
            scores = []
            
            # 1. ì²œ ì¬ì§ˆê³¼ ì˜ë¥˜ íƒ€ì… í˜¸í™˜ì„±
            fabric_type = metadata.get('fabric_type', 'cotton')
            clothing_type = metadata.get('clothing_type', 'shirt')
            
            compatibility_matrix = {
                ('cotton', 'shirt'): 0.9,
                ('cotton', 'dress'): 0.8,
                ('silk', 'dress'): 0.95,
                ('silk', 'blouse'): 0.9,
                ('denim', 'pants'): 0.95,
                ('leather', 'jacket'): 0.9
            }
            
            compatibility_score = compatibility_matrix.get(
                (fabric_type, clothing_type), 0.7
            )
            scores.append(compatibility_score)
            
            # 2. ë¬¼ë¦¬ ì‹œë®¬ë ˆì´ì…˜ í’ˆì§ˆ
            physics_score = 0.9 if self.fitting_config['physics_enabled'] else 0.6
            scores.append(physics_score)
            
            # 3. í•´ìƒë„ ì ìˆ˜
            max_res = self.performance_config['max_resolution']
            resolution_score = min(1.0, max_res / 512.0)
            scores.append(resolution_score)
            
            return float(np.mean(scores))
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ í”¼íŒ… ì ìˆ˜ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return 0.7
    
    def _generate_recommendations(
        self, 
        metadata: Dict[str, Any], 
        quality_score: float
    ) -> List[str]:
        """ê°œì„  ì œì•ˆ ìƒì„±"""
        
        recommendations = []
        
        try:
            # í’ˆì§ˆì´ ë‚®ì€ ê²½ìš°
            if quality_score < 0.6:
                recommendations.append("ë” ë†’ì€ í•´ìƒë„ì˜ ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í•´ë³´ì„¸ìš”")
                recommendations.append("ì¡°ëª…ì´ ì¢‹ì€ í™˜ê²½ì—ì„œ ì´¬ì˜ëœ ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í•´ë³´ì„¸ìš”")
            
            # AI ëª¨ë¸ ë¯¸ì‚¬ìš© ì‹œ
            if not self.fitting_config['ai_models_enabled']:
                recommendations.append("AI ëª¨ë¸ì„ í™œì„±í™”í•˜ë©´ ë” ì •í™•í•œ ê²°ê³¼ë¥¼ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤")
            
            # ë¬¼ë¦¬ ì—”ì§„ ë¯¸ì‚¬ìš© ì‹œ
            if not self.fitting_config['physics_enabled']:
                recommendations.append("ë¬¼ë¦¬ ì‹œë®¬ë ˆì´ì…˜ì„ í™œì„±í™”í•˜ë©´ ë” ìì—°ìŠ¤ëŸ¬ìš´ í”¼íŒ…ì„ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤")
            
            # ì²œ ì¬ì§ˆë³„ ì œì•ˆ
            fabric_type = metadata.get('fabric_type')
            if fabric_type == 'silk':
                recommendations.append("ì‹¤í¬ ì†Œì¬ì˜ íŠ¹ì„±ìƒ ë“œë ˆì´í•‘ íš¨ê³¼ë¥¼ ë†’ì—¬ë³´ì„¸ìš”")
            elif fabric_type == 'denim':
                recommendations.append("ë°ë‹˜ì˜ ê²¬ê³ í•¨ì„ í‘œí˜„í•˜ê¸° ìœ„í•´ í…ìŠ¤ì²˜ë¥¼ ê°•í™”í•´ë³´ì„¸ìš”")
            
            # ê¸°ë³¸ ì œì•ˆ
            if not recommendations:
                recommendations = [
                    "í›Œë¥­í•œ ê²°ê³¼ì…ë‹ˆë‹¤!",
                    "ë‹¤ì–‘í•œ í¬ì¦ˆë¡œ ì‹œë„í•´ë³´ì„¸ìš”",
                    "ë‹¤ë¥¸ ìŠ¤íƒ€ì¼ì˜ ì˜ë¥˜ë„ ì²´í—˜í•´ë³´ì„¸ìš”"
                ]
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ ì œì•ˆ ìƒì„± ì‹¤íŒ¨: {e}")
            recommendations = ["ê²°ê³¼ë¥¼ í™•ì¸í•´ë³´ì„¸ìš”"]
        
        return recommendations[:3]  # ìµœëŒ€ 3ê°œ ì œì•ˆ
    
    # =================================================================
    # 7. ìºì‹œ ë° ë©”ëª¨ë¦¬ ê´€ë¦¬
    # =================================================================
    
    def _generate_cache_key(
        self, 
        person_img: np.ndarray, 
        clothing_img: np.ndarray, 
        kwargs: Dict[str, Any]
    ) -> str:
        """ìºì‹œ í‚¤ ìƒì„±"""
        
        try:
            # ì´ë¯¸ì§€ í•´ì‹œ
            person_hash = hash(person_img.tobytes())
            clothing_hash = hash(clothing_img.tobytes())
            
            # ì„¤ì • í•´ì‹œ
            config_str = json.dumps({
                'fabric_type': kwargs.get('fabric_type', 'cotton'),
                'clothing_type': kwargs.get('clothing_type', 'shirt'),
                'quality_level': self.quality_level,
                'fitting_method': self.fitting_method
            }, sort_keys=True)
            config_hash = hash(config_str)
            
            return f"vf_{person_hash}_{clothing_hash}_{config_hash}"
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ ìºì‹œ í‚¤ ìƒì„± ì‹¤íŒ¨: {e}")
            return f"vf_{uuid.uuid4().hex[:16]}"
    
    def _get_from_cache(self, cache_key: str) -> Optional[Dict[str, Any]]:
        """ìºì‹œì—ì„œ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°"""
        
        if not self.cache_config['enabled']:
            return None
        
        try:
            if cache_key in self.fitting_cache:
                cached_data = self.fitting_cache[cache_key]
                
                # TTL í™•ì¸
                if time.time() - cached_data['timestamp'] < self.cache_config['ttl_seconds']:
                    self.cache_access_times[cache_key] = time.time()
                    return cached_data['result']
                else:
                    # ë§Œë£Œëœ ìºì‹œ ì œê±°
                    del self.fitting_cache[cache_key]
                    if cache_key in self.cache_access_times:
                        del self.cache_access_times[cache_key]
            
            return None
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ ìºì‹œ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return None
    
    def _save_to_cache(self, cache_key: str, result: Dict[str, Any]):
        """ìºì‹œì— ê²°ê³¼ ì €ì¥"""
        
        if not self.cache_config['enabled']:
            return
        
        try:
            # ìºì‹œ í¬ê¸° ì œí•œ
            if len(self.fitting_cache) >= self.cache_max_size:
                self._cleanup_cache()
            
            # ê²°ê³¼ ì €ì¥ (ì´ë¯¸ì§€ëŠ” ì œì™¸í•˜ê³  ë©”íƒ€ë°ì´í„°ë§Œ)
            cache_data = {
                'timestamp': time.time(),
                'result': {
                    k: v for k, v in result.items() 
                    if k != 'fitted_image'  # ì´ë¯¸ì§€ëŠ” ë©”ëª¨ë¦¬ ì ˆì•½ì„ ìœ„í•´ ìºì‹œí•˜ì§€ ì•ŠìŒ
                }
            }
            
            self.fitting_cache[cache_key] = cache_data
            self.cache_access_times[cache_key] = time.time()
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ ìºì‹œ ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def _cleanup_cache(self):
        """ìºì‹œ ì •ë¦¬"""
        
        try:
            # LRU ë°©ì‹ìœ¼ë¡œ ì˜¤ë˜ëœ í•­ëª© ì œê±°
            if self.cache_access_times:
                sorted_items = sorted(
                    self.cache_access_times.items(),
                    key=lambda x: x[1]
                )
                
                # ì˜¤ë˜ëœ 25% ì œê±°
                remove_count = len(sorted_items) // 4
                for cache_key, _ in sorted_items[:remove_count]:
                    if cache_key in self.fitting_cache:
                        del self.fitting_cache[cache_key]
                    del self.cache_access_times[cache_key]
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ ìºì‹œ ì •ë¦¬ ì‹¤íŒ¨: {e}")
    
    def _get_current_memory_usage(self) -> float:
        """í˜„ì¬ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ (MB)"""
        
        try:
            if self.memory_manager:
                return self.memory_manager.get_memory_usage()
            
            # í´ë°±: psutil ì‚¬ìš©
            import psutil
            process = psutil.Process()
            return process.memory_info().rss / (1024 * 1024)
            
        except Exception:
            return 0.0
    
    def _update_stats(self, processing_time: float, success: bool):
        """í†µê³„ ì—…ë°ì´íŠ¸"""
        
        self.performance_stats['total_processed'] += 1
        
        if success:
            self.performance_stats['successful_fittings'] += 1
        else:
            self.performance_stats['failed_fittings'] += 1
        
        # í‰ê·  ì²˜ë¦¬ ì‹œê°„ ì—…ë°ì´íŠ¸
        total_time = (self.performance_stats['average_processing_time'] * 
                     (self.performance_stats['total_processed'] - 1) + processing_time)
        self.performance_stats['average_processing_time'] = total_time / self.performance_stats['total_processed']
        
        # ë©”ëª¨ë¦¬ í”¼í¬ ì—…ë°ì´íŠ¸
        current_memory = self._get_current_memory_usage()
        if current_memory > self.performance_stats['memory_peak_mb']:
            self.performance_stats['memory_peak_mb'] = current_memory
    
    # =================================================================
    # 8. ì •ë³´ ì¡°íšŒ ë° ê´€ë¦¬ í•¨ìˆ˜ë“¤
    # =================================================================
    
    async def get_step_info(self) -> Dict[str, Any]:
        """ë‹¨ê³„ ì •ë³´ ë°˜í™˜"""
        
        return {
            "step_name": self.step_name,
            "version": "6.0-complete",
            "device": self.device,
            "device_type": self.device_type,
            "memory_gb": self.memory_gb,
            "is_m3_max": self.is_m3_max,
            "optimization_enabled": self.optimization_enabled,
            "quality_level": self.quality_level,
            "fitting_method": self.fitting_method,
            "initialized": self.is_initialized,
            "session_id": self.session_id,
            
            # êµ¬ì„± ì •ë³´
            "config": {
                "ai_models_enabled": self.fitting_config['ai_models_enabled'],
                "physics_enabled": self.fitting_config['physics_enabled'],
                "max_resolution": self.performance_config['max_resolution'],
                "cache_enabled": self.cache_config['enabled'],
                "cache_size": len(self.fitting_cache)
            },
            
            # ì„±ëŠ¥ í†µê³„
            "performance_stats": self.performance_stats.copy(),
            
            # ê¸°ëŠ¥ ì§€ì›
            "capabilities": {
                "ai_neural_fitting": DIFFUSERS_AVAILABLE and self.ai_models['diffusion_pipeline'] is not None,
                "physics_based_fitting": self.fitting_config['physics_enabled'],
                "hybrid_fitting": True,
                "template_matching": True,
                "texture_preservation": True,
                "lighting_effects": True,
                "fabric_simulation": True,
                "wrinkle_simulation": True,
                "m3_max_optimization": self.is_m3_max
            },
            
            # ì§€ì› í˜•ì‹
            "supported_formats": {
                "fabric_types": list(FABRIC_PROPERTIES.keys()),
                "clothing_types": list(CLOTHING_FITTING_PARAMS.keys()),
                "quality_levels": [q.value for q in FittingQuality],
                "fitting_methods": [m.value for m in FittingMethod]
            },
            
            # ì˜ì¡´ì„± ìƒíƒœ
            "dependencies": {
                "torch": TORCH_AVAILABLE,
                "opencv": CV2_AVAILABLE,
                "scipy": SCIPY_AVAILABLE,
                "sklearn": SKLEARN_AVAILABLE,
                "skimage": SKIMAGE_AVAILABLE,
                "diffusers": DIFFUSERS_AVAILABLE
            },
            
            # AI ëª¨ë¸ ìƒíƒœ
            "ai_models_status": {
                name: model is not None 
                for name, model in self.ai_models.items()
            }
        }
    
    async def cleanup(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        
        try:
            self.logger.info(f"ğŸ§¹ {self.step_name} ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì‹œì‘...")
            
            # AI ëª¨ë¸ ì–¸ë¡œë“œ
            for name, model in self.ai_models.items():
                if model is not None:
                    if hasattr(model, 'to'):
                        model.to('cpu')
                    del model
                    self.ai_models[name] = None
            
            # ìºì‹œ ì •ë¦¬
            self.fitting_cache.clear()
            self.cache_access_times.clear()
            
            # ìŠ¤ë ˆë“œ í’€ ì¢…ë£Œ
            if hasattr(self, 'thread_pool'):
                self.thread_pool.shutdown(wait=True)
            
            # GPU ë©”ëª¨ë¦¬ ì •ë¦¬
            if TORCH_AVAILABLE and self.device in ['cuda', 'mps']:
                if self.device == 'cuda':
                    torch.cuda.empty_cache()
                elif self.device == 'mps':
                    torch.mps.empty_cache()
            
            # ê°€ë¹„ì§€ ì»¬ë ‰ì…˜
            gc.collect()
            
            self.is_initialized = False
            self.logger.info(f"âœ… {self.step_name} ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì™„ë£Œ")
            
        except Exception as e:
            self.logger.error(f"âŒ ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì‹¤íŒ¨: {e}")

# =================================================================
# 9. í¸ì˜ í•¨ìˆ˜ë“¤ (í•˜ìœ„ í˜¸í™˜ì„±)
# =================================================================

def create_virtual_fitting_step(
    device: str = "auto", 
    config: Optional[Dict[str, Any]] = None,
    **kwargs
) -> VirtualFittingStep:
    """ê°€ìƒ í”¼íŒ… ë‹¨ê³„ ìƒì„± (ê¸°ì¡´ ë°©ì‹ í˜¸í™˜)"""
    return VirtualFittingStep(device=device, config=config, **kwargs)

def create_m3_max_virtual_fitting_step(
    memory_gb: float = 128.0,
    quality_level: str = "ultra",
    **kwargs
) -> VirtualFittingStep:
    """M3 Max ìµœì í™” ê°€ìƒ í”¼íŒ… ë‹¨ê³„ ìƒì„±"""
    return VirtualFittingStep(
        device=None,  # ìë™ ê°ì§€
        memory_gb=memory_gb,
        quality_level=quality_level,
        is_m3_max=True,
        optimization_enabled=True,
        **kwargs
    )

async def quick_virtual_fitting(
    person_image: Union[np.ndarray, Image.Image, str],
    clothing_image: Union[np.ndarray, Image.Image, str],
    fabric_type: str = "cotton",
    clothing_type: str = "shirt",
    **kwargs
) -> Dict[str, Any]:
    """ë¹ ë¥¸ ê°€ìƒ í”¼íŒ… (ì¼íšŒì„± ì‚¬ìš©)"""
    
    step = VirtualFittingStep()
    try:
        await step.initialize()
        result = await step.process(
            person_image, clothing_image,
            fabric_type=fabric_type,
            clothing_type=clothing_type,
            **kwargs
        )
        return result
    finally:
        await step.cleanup()

# =================================================================
# 10. ëª¨ë“ˆ ì •ë³´
# =================================================================

__version__ = "6.0.0"
__author__ = "MyCloset AI Team"
__description__ = "Complete Virtual Fitting Implementation with AI Models and Physics Simulation"

if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì½”ë“œ
    async def test_virtual_fitting():
        """í…ŒìŠ¤íŠ¸ í•¨ìˆ˜"""
        import asyncio
        
        # í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ìƒì„±
        test_person = np.random.randint(0, 255, (512, 512, 3), dtype=np.uint8)
        test_clothing = np.random.randint(0, 255, (512, 512, 3), dtype=np.uint8)
        
        # ê°€ìƒ í”¼íŒ… ì‹¤í–‰
        step = VirtualFittingStep(quality_level="balanced")
        await step.initialize()
        
        result = await step.process(
            test_person, test_clothing,
            fabric_type="cotton",
            clothing_type="shirt"
        )
        
        print(f"âœ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ: {result['success']}")
        print(f"   ì²˜ë¦¬ ì‹œê°„: {result['processing_time']:.2f}ì´ˆ")
        print(f"   í’ˆì§ˆ ì ìˆ˜: {result['quality_score']:.2f}")
        
        await step.cleanup()
    
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    asyncio.run(test_virtual_fitting())