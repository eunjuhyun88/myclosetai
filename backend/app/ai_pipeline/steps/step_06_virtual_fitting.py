# app/ai_pipeline/steps/step_06_virtual_fitting.py
"""
ğŸ”¥ 6ë‹¨ê³„: ê°€ìƒ í”¼íŒ… (Virtual Fitting) - ë‹¨ë°©í–¥ ì˜ì¡´ì„± ì™„ì „ ì¬êµ¬ì„±
=================================================================

âœ… ë‹¨ë°©í–¥ ì˜ì¡´ì„± êµ¬ì¡° (ìˆœí™˜ ì°¸ì¡° ì™„ì „ í•´ê²°)
âœ… ì¸í„°í˜ì´ìŠ¤ ë ˆì´ì–´ë¥¼ í†µí•œ ëª¨ë“ˆ ë¶„ë¦¬
âœ… BaseStepMixin ì™„ì „ í˜¸í™˜ (logger ì†ì„± ë³´ì¥)
âœ… ModelLoader ì˜ì¡´ì„± ì—­ì „ íŒ¨í„´ ì ìš©
âœ… ëª¨ë“  ê¸°ëŠ¥ 100% ìœ ì§€
âœ… M3 Max 128GB ìµœì í™”
âœ… ê³ ê¸‰ ì‹œê°í™” ì‹œìŠ¤í…œ ì™„ì „ í†µí•©
âœ… ë¬¼ë¦¬ ê¸°ë°˜ ì‹œë®¬ë ˆì´ì…˜ ì§€ì›
âœ… í”„ë¡œë•ì…˜ ë ˆë²¨ ì•ˆì •ì„±

ì˜ì¡´ì„± íë¦„:
VirtualFittingStep â†’ IModelProvider (ì¸í„°í˜ì´ìŠ¤) â†’ ModelLoader
VirtualFittingStep â†’ IStepBase (ì¸í„°í˜ì´ìŠ¤) â†’ BaseStepMixin
"""

import os
import sys
import logging
import time
import asyncio
import json
import math
import threading
import uuid
import base64
import traceback
import gc
import weakref
from pathlib import Path
from typing import Dict, Any, Optional, Tuple, List, Union, Callable, Protocol, runtime_checkable
from dataclasses import dataclass, field
from enum import Enum
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor
from io import BytesIO
from abc import ABC, abstractmethod

# í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬
import numpy as np
from PIL import Image, ImageEnhance, ImageFilter, ImageDraw, ImageFont

# PyTorch ê´€ë ¨ (ì„ íƒì )
try:
    import torch
    import torch.nn as nn
    import torch.nn.functional as F
    import torchvision.transforms as transforms
    TORCH_AVAILABLE = True
except ImportError:
    TORCH_AVAILABLE = False

# OpenCV (ì„ íƒì )
try:
    import cv2
    CV2_AVAILABLE = True
except ImportError:
    CV2_AVAILABLE = False

# ê³¼í•™ ì—°ì‚° ë¼ì´ë¸ŒëŸ¬ë¦¬ (ì„ íƒì )
try:
    from scipy.interpolate import RBFInterpolator, griddata
    from scipy.spatial.distance import cdist
    from scipy.ndimage import gaussian_filter, binary_erosion, binary_dilation
    SCIPY_AVAILABLE = True
except ImportError:
    SCIPY_AVAILABLE = False

try:
    from sklearn.cluster import KMeans, DBSCAN
    from sklearn.preprocessing import StandardScaler
    SKLEARN_AVAILABLE = True
except ImportError:
    SKLEARN_AVAILABLE = False

try:
    from skimage.feature import local_binary_pattern, canny
    from skimage.segmentation import slic, watershed
    from skimage.transform import resize, rotate
    from skimage.measure import regionprops, label
    SKIMAGE_AVAILABLE = True
except ImportError:
    SKIMAGE_AVAILABLE = False

# AI ëª¨ë¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ (ì„ íƒì )
try:
    from diffusers import StableDiffusionPipeline, DDIMScheduler, UNet2DConditionModel
    from transformers import CLIPProcessor, CLIPModel
    DIFFUSERS_AVAILABLE = True
except ImportError:
    DIFFUSERS_AVAILABLE = False

# =================================================================
# ğŸ”¥ ì˜ì¡´ì„± ì—­ì „ì„ ìœ„í•œ ì¸í„°í˜ì´ìŠ¤ ì •ì˜
# =================================================================

@runtime_checkable
class IModelProvider(Protocol):
    """ëª¨ë¸ ì œê³µì ì¸í„°í˜ì´ìŠ¤ (ì˜ì¡´ì„± ì—­ì „)"""
    
    async def load_model_async(self, model_name: str) -> Any:
        """ëª¨ë¸ ë¹„ë™ê¸° ë¡œë“œ"""
        ...
    
    def get_model(self, model_name: str) -> Optional[Any]:
        """ëª¨ë¸ ë™ê¸° íšë“"""
        ...
    
    def unload_model(self, model_name: str) -> bool:
        """ëª¨ë¸ ì–¸ë¡œë“œ"""
        ...
    
    def is_model_loaded(self, model_name: str) -> bool:
        """ëª¨ë¸ ë¡œë“œ ìƒíƒœ í™•ì¸"""
        ...

@runtime_checkable
class IStepBase(Protocol):
    """Step ê¸°ë³¸ ì¸í„°í˜ì´ìŠ¤ (ì˜ì¡´ì„± ì—­ì „)"""
    
    logger: logging.Logger
    step_name: str
    device: str
    is_initialized: bool
    
    async def initialize(self) -> bool:
        """ì´ˆê¸°í™”"""
        ...
    
    async def cleanup(self) -> None:
        """ì •ë¦¬"""
        ...

@runtime_checkable
class IMemoryManager(Protocol):
    """ë©”ëª¨ë¦¬ ê´€ë¦¬ì ì¸í„°í˜ì´ìŠ¤"""
    
    async def get_usage_stats(self) -> Dict[str, Any]:
        """ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í†µê³„"""
        ...
    
    def get_memory_usage(self) -> float:
        """í˜„ì¬ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ (MB)"""
        ...
    
    async def cleanup(self) -> None:
        """ë©”ëª¨ë¦¬ ì •ë¦¬"""
        ...

@runtime_checkable
class IDataConverter(Protocol):
    """ë°ì´í„° ë³€í™˜ê¸° ì¸í„°í˜ì´ìŠ¤"""
    
    def convert(self, data: Any, target_format: str) -> Any:
        """ë°ì´í„° ë³€í™˜"""
        ...
    
    def to_tensor(self, data: np.ndarray) -> Any:
        """í…ì„œ ë³€í™˜"""
        ...
    
    def to_numpy(self, data: Any) -> np.ndarray:
        """NumPy ë³€í™˜"""
        ...

# =================================================================
# ğŸ”¥ ëª¨ë¸ ì œê³µì ì–´ëŒ‘í„° (ì˜ì¡´ì„± ì—­ì „ êµ¬í˜„)
# =================================================================

class ModelProviderAdapter:
    """ModelLoaderë¥¼ IModelProvider ì¸í„°í˜ì´ìŠ¤ë¡œ ì ì‘ì‹œí‚¤ëŠ” ì–´ëŒ‘í„°"""
    
    def __init__(self, step_name: str):
        self.step_name = step_name
        self._model_loader = None
        self._model_interface = None
        self._cached_models: Dict[str, Any] = {}
        self._lock = threading.RLock()
        self.logger = logging.getLogger(f"ModelAdapter.{step_name}")
    
    def set_model_loader(self, model_loader: Any) -> None:
        """ModelLoader ì£¼ì… (ë‚˜ì¤‘ì— ì„¤ì •)"""
        try:
            self._model_loader = model_loader
            if hasattr(model_loader, 'create_step_interface'):
                self._model_interface = model_loader.create_step_interface(self.step_name)
            self.logger.info(f"âœ… ModelLoader ì–´ëŒ‘í„° ì„¤ì • ì™„ë£Œ: {self.step_name}")
        except Exception as e:
            self.logger.error(f"âŒ ModelLoader ì–´ëŒ‘í„° ì„¤ì • ì‹¤íŒ¨: {e}")
    
    async def load_model_async(self, model_name: str) -> Any:
        """ëª¨ë¸ ë¹„ë™ê¸° ë¡œë“œ"""
        try:
            with self._lock:
                # ìºì‹œ í™•ì¸
                if model_name in self._cached_models:
                    return self._cached_models[model_name]
                
                # ModelLoader ì¸í„°í˜ì´ìŠ¤ë¥¼ í†µí•œ ë¡œë“œ
                if self._model_interface:
                    model = await self._model_interface.load_model_async(model_name)
                    if model:
                        self._cached_models[model_name] = model
                        return model
                
                # í´ë°±: ê¸°ë³¸ ëª¨ë¸ ìƒì„±
                return await self._create_fallback_model(model_name)
                
        except Exception as e:
            self.logger.error(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨ {model_name}: {e}")
            return await self._create_fallback_model(model_name)
    
    def get_model(self, model_name: str) -> Optional[Any]:
        """ëª¨ë¸ ë™ê¸° íšë“"""
        try:
            with self._lock:
                return self._cached_models.get(model_name)
        except Exception as e:
            self.logger.error(f"âŒ ëª¨ë¸ íšë“ ì‹¤íŒ¨ {model_name}: {e}")
            return None
    
    def unload_model(self, model_name: str) -> bool:
        """ëª¨ë¸ ì–¸ë¡œë“œ"""
        try:
            with self._lock:
                if model_name in self._cached_models:
                    del self._cached_models[model_name]
                    return True
                return False
        except Exception as e:
            self.logger.error(f"âŒ ëª¨ë¸ ì–¸ë¡œë“œ ì‹¤íŒ¨ {model_name}: {e}")
            return False
    
    def is_model_loaded(self, model_name: str) -> bool:
        """ëª¨ë¸ ë¡œë“œ ìƒíƒœ í™•ì¸"""
        try:
            with self._lock:
                return model_name in self._cached_models
        except Exception as e:
            self.logger.error(f"âŒ ëª¨ë¸ ìƒíƒœ í™•ì¸ ì‹¤íŒ¨ {model_name}: {e}")
            return False
    
    async def _create_fallback_model(self, model_name: str) -> Any:
        """í´ë°± ëª¨ë¸ ìƒì„±"""
        try:
            self.logger.info(f"ğŸ”§ í´ë°± ëª¨ë¸ ìƒì„± ì¤‘: {model_name}")
            
            class FallbackModel:
                def __init__(self, name: str, device: str = "cpu"):
                    self.name = name
                    self.device = device
                    
                async def predict(self, *args, **kwargs):
                    # ê¸°ë³¸ì ì¸ ì²˜ë¦¬ ì‹œë®¬ë ˆì´ì…˜
                    await asyncio.sleep(0.1)
                    return None
                
                def process(self, *args, **kwargs):
                    return None
            
            fallback = FallbackModel(model_name)
            with self._lock:
                self._cached_models[model_name] = fallback
            
            return fallback
            
        except Exception as e:
            self.logger.error(f"âŒ í´ë°± ëª¨ë¸ ìƒì„± ì‹¤íŒ¨: {e}")
            return None

# =================================================================
# ğŸ”¥ Step ê¸°ë³¸ ì–´ëŒ‘í„° (ì˜ì¡´ì„± ì—­ì „ êµ¬í˜„)
# =================================================================

class StepBaseAdapter:
    """BaseStepMixinì„ IStepBase ì¸í„°í˜ì´ìŠ¤ë¡œ ì ì‘ì‹œí‚¤ëŠ” ì–´ëŒ‘í„°"""
    
    def __init__(self, step_name: str, device: str = "auto"):
        self.step_name = step_name
        self.device = self._auto_detect_device() if device == "auto" else device
        self.is_initialized = False
        self.logger = logging.getLogger(f"StepAdapter.{step_name}")
        self._base_step_mixin = None
    
    def set_base_step_mixin(self, base_mixin: Any) -> None:
        """BaseStepMixin ì£¼ì… (ë‚˜ì¤‘ì— ì„¤ì •)"""
        try:
            self._base_step_mixin = base_mixin
            # ì†ì„± ë™ê¸°í™”
            if hasattr(base_mixin, 'logger'):
                self.logger = base_mixin.logger
            self.logger.info(f"âœ… BaseStepMixin ì–´ëŒ‘í„° ì„¤ì • ì™„ë£Œ: {self.step_name}")
        except Exception as e:
            self.logger.error(f"âŒ BaseStepMixin ì–´ëŒ‘í„° ì„¤ì • ì‹¤íŒ¨: {e}")
    
    async def initialize(self) -> bool:
        """ì´ˆê¸°í™”"""
        try:
            self.logger.info(f"ğŸ”„ {self.step_name} ì–´ëŒ‘í„° ì´ˆê¸°í™” ì¤‘...")
            
            # BaseStepMixin ì´ˆê¸°í™” (ìˆëŠ” ê²½ìš°)
            if self._base_step_mixin and hasattr(self._base_step_mixin, 'initialize'):
                await self._base_step_mixin.initialize()
            
            self.is_initialized = True
            self.logger.info(f"âœ… {self.step_name} ì–´ëŒ‘í„° ì´ˆê¸°í™” ì™„ë£Œ")
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ {self.step_name} ì–´ëŒ‘í„° ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return False
    
    async def cleanup(self) -> None:
        """ì •ë¦¬"""
        try:
            self.logger.info(f"ğŸ§¹ {self.step_name} ì–´ëŒ‘í„° ì •ë¦¬ ì¤‘...")
            
            # BaseStepMixin ì •ë¦¬ (ìˆëŠ” ê²½ìš°)
            if self._base_step_mixin and hasattr(self._base_step_mixin, 'cleanup'):
                await self._base_step_mixin.cleanup()
            
            self.is_initialized = False
            self.logger.info(f"âœ… {self.step_name} ì–´ëŒ‘í„° ì •ë¦¬ ì™„ë£Œ")
            
        except Exception as e:
            self.logger.error(f"âŒ {self.step_name} ì–´ëŒ‘í„° ì •ë¦¬ ì‹¤íŒ¨: {e}")
    
    def _auto_detect_device(self) -> str:
        """ë””ë°”ì´ìŠ¤ ìë™ íƒì§€"""
        if not TORCH_AVAILABLE:
            return "cpu"
        
        try:
            if torch.backends.mps.is_available():
                return "mps"
            elif torch.cuda.is_available():
                return "cuda"
            else:
                return "cpu"
        except Exception:
            return "cpu"

# =================================================================
# ğŸ”¥ ìƒìˆ˜ ë° ì„¤ì • ì •ì˜
# =================================================================

class FittingQuality(Enum):
    """í”¼íŒ… í’ˆì§ˆ ë ˆë²¨"""
    FAST = "fast"
    BALANCED = "balanced"
    HIGH = "high"
    ULTRA = "ultra"

class FittingMethod(Enum):
    """í”¼íŒ… ë°©ë²•"""
    PHYSICS_BASED = "physics_based"
    AI_NEURAL = "ai_neural"
    HYBRID = "hybrid"
    TEMPLATE_MATCHING = "template_matching"
    DIFFUSION_BASED = "diffusion"
    LIGHTWEIGHT = "lightweight"

@dataclass
class FabricProperties:
    """ì²œ ì¬ì§ˆ ì†ì„±"""
    stiffness: float = 0.5
    elasticity: float = 0.3
    density: float = 1.4
    friction: float = 0.5
    shine: float = 0.5
    transparency: float = 0.0
    texture_scale: float = 1.0

@dataclass
class FittingParams:
    """í”¼íŒ… íŒŒë¼ë¯¸í„°"""
    fit_type: str = "fitted"
    body_contact: float = 0.7
    drape_level: float = 0.3
    stretch_zones: List[str] = field(default_factory=lambda: ["chest", "waist"])
    wrinkle_intensity: float = 0.5
    shadow_strength: float = 0.6

@dataclass
class VirtualFittingConfig:
    """ê°€ìƒ í”¼íŒ… ì„¤ì •"""
    # ëª¨ë¸ ì„¤ì •
    model_name: str = "ootdiffusion"
    inference_steps: int = 50
    guidance_scale: float = 7.5
    scheduler_type: str = "ddim"
    
    # í’ˆì§ˆ ì„¤ì •
    input_size: Tuple[int, int] = (512, 512)
    output_size: Tuple[int, int] = (512, 512)
    upscale_factor: float = 1.0
    
    # ë¬¼ë¦¬ ì‹œë®¬ë ˆì´ì…˜
    physics_enabled: bool = True
    cloth_stiffness: float = 0.3
    gravity_strength: float = 9.81
    wind_force: Tuple[float, float] = (0.0, 0.0)
    
    # ë Œë”ë§ ì„¤ì •
    lighting_type: str = "natural"
    shadow_enabled: bool = True
    reflection_enabled: bool = False
    
    # ìµœì í™” ì„¤ì •
    enable_attention_slicing: bool = True
    enable_cpu_offload: bool = False
    memory_efficient: bool = True
    use_half_precision: bool = True

@dataclass
class FittingResult:
    """ê°€ìƒ í”¼íŒ… ê²°ê³¼"""
    success: bool
    fitted_image: Optional[np.ndarray] = None
    confidence_score: float = 0.0
    processing_time: float = 0.0
    metadata: Dict[str, Any] = field(default_factory=dict)
    visualization_data: Dict[str, Any] = field(default_factory=dict)
    error_message: Optional[str] = None

# ì²œ ì¬ì§ˆë³„ ë¬¼ë¦¬ ì†ì„±
FABRIC_PROPERTIES = {
    'cotton': FabricProperties(0.3, 0.2, 1.5, 0.7, 0.2, 0.0, 1.0),
    'denim': FabricProperties(0.8, 0.1, 2.0, 0.9, 0.1, 0.0, 1.2),
    'silk': FabricProperties(0.1, 0.4, 1.3, 0.3, 0.8, 0.1, 0.8),
    'wool': FabricProperties(0.5, 0.3, 1.4, 0.6, 0.3, 0.0, 1.1),
    'polyester': FabricProperties(0.4, 0.5, 1.2, 0.4, 0.6, 0.0, 0.9),
    'leather': FabricProperties(0.9, 0.1, 2.5, 0.8, 0.9, 0.0, 1.5),
    'spandex': FabricProperties(0.1, 0.8, 1.1, 0.5, 0.4, 0.0, 0.7),
    'linen': FabricProperties(0.6, 0.2, 1.6, 0.8, 0.1, 0.0, 1.3),
    'default': FabricProperties(0.4, 0.3, 1.4, 0.5, 0.5, 0.0, 1.0)
}

# ì˜ë¥˜ íƒ€ì…ë³„ í”¼íŒ… íŒŒë¼ë¯¸í„°
CLOTHING_FITTING_PARAMS = {
    'shirt': FittingParams("fitted", 0.7, 0.3, ["chest", "waist"], 0.3, 0.6),
    'dress': FittingParams("flowing", 0.5, 0.7, ["bust", "waist", "hip"], 0.6, 0.7),
    'pants': FittingParams("fitted", 0.8, 0.2, ["thigh", "calf"], 0.4, 0.5),
    'jacket': FittingParams("structured", 0.6, 0.4, ["shoulder", "chest"], 0.2, 0.8),
    'skirt': FittingParams("flowing", 0.6, 0.6, ["waist", "hip"], 0.5, 0.6),
    'blouse': FittingParams("loose", 0.5, 0.5, ["chest", "waist"], 0.4, 0.6),
    'sweater': FittingParams("relaxed", 0.6, 0.4, ["chest", "arms"], 0.3, 0.5),
    'default': FittingParams("fitted", 0.6, 0.4, ["chest", "waist"], 0.4, 0.6)
}

# ì‹œê°í™”ìš© ìƒ‰ìƒ íŒ”ë ˆíŠ¸
VISUALIZATION_COLORS = {
    'original': (200, 200, 200),
    'cloth': (100, 149, 237),
    'fitted': (255, 105, 180),
    'skin': (255, 218, 185),
    'hair': (139, 69, 19),
    'background': (240, 248, 255),
    'shadow': (105, 105, 105),
    'highlight': (255, 255, 224),
    'seam': (255, 69, 0),
    'fold': (123, 104, 238),
    'overlay': (255, 255, 255, 128)
}

# =================================================================
# ğŸ”¥ ë©”ì¸ ê°€ìƒ í”¼íŒ… í´ë˜ìŠ¤ (ë‹¨ë°©í–¥ ì˜ì¡´ì„±)
# =================================================================

class VirtualFittingStep:
    """
    ğŸ”¥ 6ë‹¨ê³„: ê°€ìƒ í”¼íŒ… - ë‹¨ë°©í–¥ ì˜ì¡´ì„± ì™„ì „ êµ¬í˜„
    
    âœ… ì˜ì¡´ì„± ì—­ì „ íŒ¨í„´ìœ¼ë¡œ ìˆœí™˜ ì°¸ì¡° ì™„ì „ í•´ê²°
    âœ… ì¸í„°í˜ì´ìŠ¤ë¥¼ í†µí•œ ê¹”ë”í•œ ëª¨ë“ˆ ë¶„ë¦¬
    âœ… BaseStepMixin/ModelLoader í˜¸í™˜ì„± 100%
    âœ… ëª¨ë“  ê¸°ëŠ¥ ì™„ì „ ìœ ì§€
    âœ… M3 Max Neural Engine ê°€ì†
    âœ… ê³ ê¸‰ ì‹œê°í™” ì‹œìŠ¤í…œ
    âœ… ë¬¼ë¦¬ ê¸°ë°˜ ì²œ ì‹œë®¬ë ˆì´ì…˜
    """
    
    def __init__(
        self,
        device: Optional[str] = None,
        config: Optional[Dict[str, Any]] = None,
        **kwargs
    ):
        """
        ë‹¨ë°©í–¥ ì˜ì¡´ì„± ìƒì„±ì
        
        Args:
            device: ë””ë°”ì´ìŠ¤ ('cpu', 'cuda', 'mps', None=ìë™ê°ì§€)
            config: ì„¤ì • ë”•ì…”ë„ˆë¦¬
            **kwargs: í™•ì¥ íŒŒë¼ë¯¸í„°
        """
        
        # === 1. ê¸°ë³¸ ì†ì„± ì„¤ì • ===
        self.step_name = "VirtualFittingStep"
        self.step_number = 6
        self.device = device or self._auto_detect_device()
        self.config = config or {}
        
        # === 2. Logger ì„¤ì • (ì˜ì¡´ì„± ì—†ì´) ===
        self.logger = logging.getLogger(f"pipeline.{self.__class__.__name__}")
        self.logger.info("ğŸ”„ VirtualFittingStep ë‹¨ë°©í–¥ ì˜ì¡´ì„± ì´ˆê¸°í™” ì‹œì‘...")
        
        try:
            # === 3. ì‹œìŠ¤í…œ íŒŒë¼ë¯¸í„° ===
            self.device_type = kwargs.get('device_type', 'auto')
            self.memory_gb = kwargs.get('memory_gb', 16.0)
            self.is_m3_max = kwargs.get('is_m3_max', self._detect_m3_max())
            self.optimization_enabled = kwargs.get('optimization_enabled', True)
            self.quality_level = kwargs.get('quality_level', 'balanced')
            
            # === 4. 6ë‹¨ê³„ íŠ¹í™” íŒŒë¼ë¯¸í„° ===
            fitting_method_str = kwargs.get('fitting_method', 'hybrid')
            if isinstance(fitting_method_str, FittingMethod):
                self.fitting_method = fitting_method_str
            else:
                try:
                    self.fitting_method = FittingMethod(fitting_method_str)
                except ValueError:
                    self.fitting_method = FittingMethod.HYBRID
                    
            self.enable_physics = kwargs.get('enable_physics', True)
            self.enable_ai_models = kwargs.get('enable_ai_models', True)
            self.enable_visualization = kwargs.get('enable_visualization', True)
            
            # === 5. ì„¤ì • ê°ì²´ ìƒì„± ===
            self.fitting_config = self._create_fitting_config(kwargs)
            
            # === 6. ìƒíƒœ ë³€ìˆ˜ ì´ˆê¸°í™” ===
            self.is_initialized = False
            self.session_id = str(uuid.uuid4())
            self.last_result = None
            self.processing_stats = {}
            
            # === 7. ì˜ì¡´ì„± ì–´ëŒ‘í„°ë“¤ (ì˜ì¡´ì„± ì—­ì „) ===
            self.model_provider: IModelProvider = ModelProviderAdapter(self.step_name)
            self.step_base: IStepBase = StepBaseAdapter(self.step_name, self.device)
            
            # ë‚˜ì¤‘ì— ì£¼ì…ë  ì»´í¬ë„ŒíŠ¸ë“¤
            self.memory_manager: Optional[IMemoryManager] = None
            self.data_converter: Optional[IDataConverter] = None
            
            # === 8. ë©”ëª¨ë¦¬ ë° ìºì‹œ ê´€ë¦¬ ===
            self.result_cache: Dict[str, Any] = {}
            self.cache_lock = threading.RLock()
            self.executor = ThreadPoolExecutor(max_workers=2, thread_name_prefix="virtual_fitting")
            
            # === 9. AI ëª¨ë¸ ê´€ë¦¬ (ì–´ëŒ‘í„° í†µí•´) ===
            self.loaded_models = {}
            self.ai_models = {
                'diffusion_pipeline': None,
                'human_parser': None,
                'cloth_segmenter': None,
                'pose_estimator': None,
                'style_encoder': None
            }
            
            # === 10. ë¬¼ë¦¬ ì—”ì§„ ë° ë Œë”ëŸ¬ ===
            self.physics_engine = None
            self.renderer = None
            
            # === 11. ì„±ëŠ¥ í†µê³„ ===
            self.performance_stats = {
                'total_processed': 0,
                'successful_fittings': 0,
                'failed_fittings': 0,
                'average_processing_time': 0.0,
                'cache_hits': 0,
                'cache_misses': 0,
                'memory_peak_mb': 0.0,
                'ai_model_usage': {model: 0 for model in self.ai_models.keys()}
            }
            
            # === 12. ì‹œê°í™” ì„¤ì • ===
            self.visualization_config = {
                'enabled': self.enable_visualization,
                'quality': self.config.get('visualization_quality', 'medium'),
                'show_process_steps': self.config.get('show_process_steps', True),
                'show_fit_analysis': self.config.get('show_fit_analysis', True),
                'show_fabric_details': self.config.get('show_fabric_details', True),
                'overlay_opacity': self.config.get('overlay_opacity', 0.7),
                'comparison_mode': self.config.get('comparison_mode', 'side_by_side')
            }
            
            # === 13. ìºì‹œ ì‹œìŠ¤í…œ ===
            cache_size = min(200 if self.is_m3_max and self.memory_gb >= 128 else 50, 
                            int(self.memory_gb * 2))
            self.fitting_cache = {}
            self.cache_max_size = cache_size
            self.cache_stats = {'hits': 0, 'misses': 0, 'total_size': 0}
            self.cache_access_times = {}
            
            # === 14. ì„±ëŠ¥ ì„¤ì • ===
            self.performance_config = {
                'max_resolution': self._get_max_resolution(),
                'fitting_iterations': self._get_fitting_iterations(),
                'precision_factor': self._get_precision_factor(),
                'batch_size': self._get_batch_size(),
                'cache_enabled': True,
                'parallel_processing': self.is_m3_max,
                'memory_efficient': self.memory_gb < 32
            }
            
            # === 15. M3 Max ìµœì í™” ===
            if self.is_m3_max:
                self._setup_m3_max_optimization()
            
            # === 16. ë©”ëª¨ë¦¬ ê´€ë¦¬ì ìƒì„± ===
            self.memory_manager = self._create_memory_manager()
            self.data_converter = self._create_data_converter()
            
            # === 17. ìŠ¤ë ˆë“œ í’€ ===
            max_workers = min(8, int(self.memory_gb / 8)) if self.is_m3_max else 2
            self.thread_pool = ThreadPoolExecutor(max_workers=max_workers)
            
            self.logger.info("âœ… VirtualFittingStep ë‹¨ë°©í–¥ ì˜ì¡´ì„± ì´ˆê¸°í™” ì™„ë£Œ")
            
        except Exception as e:
            self.logger.error(f"âŒ VirtualFittingStep ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.logger.error(traceback.format_exc())
            raise
    
    def inject_dependencies(
        self, 
        model_loader: Any = None, 
        base_step_mixin: Any = None,
        memory_manager: IMemoryManager = None,
        data_converter: IDataConverter = None
    ) -> None:
        """
        ì˜ì¡´ì„± ì£¼ì… (Dependency Injection)
        
        ì´ ë©”ì„œë“œë¥¼ í†µí•´ ì™¸ë¶€ì—ì„œ ì˜ì¡´ì„±ì„ ì£¼ì…í•©ë‹ˆë‹¤.
        """
        try:
            self.logger.info("ğŸ”„ ì˜ì¡´ì„± ì£¼ì… ì‹œì‘...")
            
            # ModelLoader ì£¼ì…
            if model_loader:
                if isinstance(self.model_provider, ModelProviderAdapter):
                    self.model_provider.set_model_loader(model_loader)
                self.logger.info("âœ… ModelLoader ì˜ì¡´ì„± ì£¼ì… ì™„ë£Œ")
            
            # BaseStepMixin ì£¼ì…
            if base_step_mixin:
                if isinstance(self.step_base, StepBaseAdapter):
                    self.step_base.set_base_step_mixin(base_step_mixin)
                self.logger.info("âœ… BaseStepMixin ì˜ì¡´ì„± ì£¼ì… ì™„ë£Œ")
            
            # ì¶”ê°€ ì»´í¬ë„ŒíŠ¸ë“¤ ì£¼ì…
            if memory_manager:
                self.memory_manager = memory_manager
                self.logger.info("âœ… MemoryManager ì˜ì¡´ì„± ì£¼ì… ì™„ë£Œ")
            
            if data_converter:
                self.data_converter = data_converter
                self.logger.info("âœ… DataConverter ì˜ì¡´ì„± ì£¼ì… ì™„ë£Œ")
                
            self.logger.info("âœ… ëª¨ë“  ì˜ì¡´ì„± ì£¼ì… ì™„ë£Œ")
            
        except Exception as e:
            self.logger.error(f"âŒ ì˜ì¡´ì„± ì£¼ì… ì‹¤íŒ¨: {e}")
    
    def _auto_detect_device(self) -> str:
        """ë””ë°”ì´ìŠ¤ ìë™ íƒì§€"""
        if not TORCH_AVAILABLE:
            return "cpu"
            
        try:
            if torch.backends.mps.is_available():
                return "mps"
            elif torch.cuda.is_available():
                return "cuda"
            else:
                return "cpu"
        except Exception:
            return "cpu"
    
    def _detect_m3_max(self) -> bool:
        """M3 Max í•˜ë“œì›¨ì–´ íƒì§€"""
        try:
            if sys.platform == "darwin":  # macOS
                import platform
                if "arm" in platform.machine().lower():
                    return True
            return False
        except Exception:
            return False
    
    def _create_fitting_config(self, kwargs: Dict[str, Any]) -> VirtualFittingConfig:
        """í”¼íŒ… ì„¤ì • ìƒì„±"""
        config_params = {}
        
        # kwargsì—ì„œ ì„¤ì • íŒŒë¼ë¯¸í„° ì¶”ì¶œ
        if 'inference_steps' in kwargs:
            config_params['inference_steps'] = kwargs['inference_steps']
        if 'guidance_scale' in kwargs:
            config_params['guidance_scale'] = kwargs['guidance_scale']
        if 'physics_enabled' in kwargs:
            config_params['physics_enabled'] = kwargs['physics_enabled']
        if 'input_size' in kwargs:
            config_params['input_size'] = kwargs['input_size']
        
        return VirtualFittingConfig(**config_params)
    
    def _get_max_resolution(self) -> int:
        """ìµœëŒ€ í•´ìƒë„ ê³„ì‚°"""
        if self.is_m3_max and self.memory_gb >= 128:
            return 1024
        elif self.quality_level == "high" and self.memory_gb >= 32:
            return 768
        elif self.quality_level == "balanced":
            return 512
        else:
            return 384
    
    def _get_fitting_iterations(self) -> int:
        """í”¼íŒ… ë°˜ë³µ íšŸìˆ˜"""
        quality_iterations = {
            "fast": 1,
            "balanced": 3,
            "high": 5,
            "ultra": 8
        }
        return quality_iterations.get(self.quality_level, 3)
    
    def _get_precision_factor(self) -> float:
        """ì •ë°€ë„ ê³„ìˆ˜"""
        quality_precision = {
            "fast": 0.5,
            "balanced": 1.0,
            "high": 1.5,
            "ultra": 2.0
        }
        return quality_precision.get(self.quality_level, 1.0)
    
    def _get_batch_size(self) -> int:
        """ë°°ì¹˜ í¬ê¸°"""
        if self.is_m3_max and self.memory_gb >= 128:
            return 4
        elif self.memory_gb >= 32:
            return 2
        else:
            return 1
    
    def _setup_m3_max_optimization(self) -> None:
        """M3 Max ìµœì í™” ì„¤ì •"""
        try:
            if TORCH_AVAILABLE:
                # M3 Max íŠ¹í™” ì„¤ì •
                os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '1'
                os.environ['PYTORCH_MPS_HIGH_WATERMARK_RATIO'] = '0.0'
                
                # ë©”ëª¨ë¦¬ ìµœì í™”
                if torch.backends.mps.is_available():
                    torch.backends.mps.empty_cache()
                
                # 128GB ë©”ëª¨ë¦¬ í™œìš© ìµœì í™”
                if self.memory_gb >= 128:
                    torch.backends.mps.set_per_process_memory_fraction(0.8)
                
                self.logger.info("ğŸ M3 Max MPS ìµœì í™” ì„¤ì • ì™„ë£Œ")
        except Exception as e:
            self.logger.warning(f"âš ï¸ M3 Max ìµœì í™” ì„¤ì • ì‹¤íŒ¨: {e}")
    
    def _create_memory_manager(self) -> IMemoryManager:
        """ë©”ëª¨ë¦¬ ë§¤ë‹ˆì € ìƒì„± (ì˜ì¡´ì„± ì—†ëŠ”)"""
        class SimpleMemoryManager:
            def __init__(self, device: str):
                self.device = device
            
            async def get_usage_stats(self) -> Dict[str, Any]: 
                return {"memory_used": "N/A"}
            
            def get_memory_usage(self) -> float:
                try:
                    import psutil
                    process = psutil.Process()
                    return process.memory_info().rss / (1024 * 1024)
                except Exception:
                    return 0.0
            
            async def cleanup(self) -> None: 
                gc.collect()
                if TORCH_AVAILABLE:
                    try:
                        if torch.backends.mps.is_available():
                            torch.backends.mps.empty_cache()
                    except Exception:
                        pass
        
        return SimpleMemoryManager(self.device)
    
    def _create_data_converter(self) -> IDataConverter:
        """ë°ì´í„° ì»¨ë²„í„° ìƒì„± (ì˜ì¡´ì„± ì—†ëŠ”)"""
        class SimpleDataConverter:
            def convert(self, data: Any, target_format: str) -> Any:
                return data
            
            def to_tensor(self, data: np.ndarray) -> Any:
                if TORCH_AVAILABLE:
                    return torch.from_numpy(data)
                return data
            
            def to_numpy(self, data: Any) -> np.ndarray:
                if TORCH_AVAILABLE and torch.is_tensor(data):
                    return data.cpu().numpy()
                return data if isinstance(data, np.ndarray) else np.array(data)
        
        return SimpleDataConverter()
    
    def record_performance(self, operation: str, duration: float, success: bool) -> None:
        """ì„±ëŠ¥ ë©”íŠ¸ë¦­ ê¸°ë¡"""
        if operation not in self.performance_stats:
            self.performance_stats[operation] = {
                "total_calls": 0,
                "success_calls": 0,
                "total_duration": 0.0,
                "avg_duration": 0.0,
                "last_duration": 0.0
            }
        
        metrics = self.performance_stats[operation]
        metrics["total_calls"] += 1
        metrics["total_duration"] += duration
        metrics["last_duration"] = duration
        metrics["avg_duration"] = metrics["total_duration"] / metrics["total_calls"]
        
        if success:
            metrics["success_calls"] += 1
    
    # =================================================================
    # ğŸ”¥ ì´ˆê¸°í™” ë° ëª¨ë¸ ë¡œë”© (ì˜ì¡´ì„± ì£¼ì… í›„)
    # =================================================================
    
    async def initialize(self) -> bool:
        """
        Step ì´ˆê¸°í™” (ì˜ì¡´ì„± ì£¼ì… í›„ í˜¸ì¶œ)
        
        Returns:
            bool: ì´ˆê¸°í™” ì„±ê³µ ì—¬ë¶€
        """
        try:
            self.logger.info("ğŸ”„ 6ë‹¨ê³„: ê°€ìƒ í”¼íŒ… ëª¨ë¸ ì´ˆê¸°í™” ì¤‘...")
            
            # Step Base ì´ˆê¸°í™”
            success = await self.step_base.initialize()
            if not success:
                self.logger.warning("âš ï¸ Step Base ì´ˆê¸°í™” ì‹¤íŒ¨")
            
            # ì£¼ ëª¨ë¸ ë¡œë“œ
            success = await self._load_primary_model()
            if not success:
                self.logger.warning("âš ï¸ ì£¼ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨ - í´ë°± ëª¨ë“œë¡œ ê³„ì†")
            
            # ë³´ì¡° ëª¨ë¸ë“¤ ë¡œë“œ
            await self._load_auxiliary_models()
            
            # ë¬¼ë¦¬ ì—”ì§„ ì´ˆê¸°í™”
            if self.enable_physics:
                self._initialize_physics_engine()
            
            # ë Œë”ë§ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
            self._initialize_rendering_system()
            
            # ìºì‹œ ì‹œìŠ¤í…œ ì¤€ë¹„
            self._prepare_cache_system()
            
            # M3 Max ì¶”ê°€ ìµœì í™”
            if self.is_m3_max:
                await self._apply_m3_max_optimizations()
            
            self.is_initialized = True
            self.logger.info("âœ… 6ë‹¨ê³„: ê°€ìƒ í”¼íŒ… ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ")
            
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ 6ë‹¨ê³„ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.logger.error(traceback.format_exc())
            self.is_initialized = False
            return False
    
    async def _load_primary_model(self) -> bool:
        """ì£¼ ëª¨ë¸ ë¡œë“œ (ì˜ì¡´ì„± ì£¼ì…ëœ provider ì‚¬ìš©)"""
        try:
            self.logger.info("ğŸ“¦ ì£¼ ëª¨ë¸ ë¡œë“œ ì¤‘: Virtual Fitting Model")
            
            # ëª¨ë¸ ìš”ì²­ ìˆœì„œëŒ€ë¡œ ì‹œë„
            model_candidates = [
                "virtual_fitting_stable_diffusion",
                "ootdiffusion",
                "stable_diffusion",
                "diffusion_pipeline"
            ]
            
            for model_name in model_candidates:
                try:
                    model = await self.model_provider.load_model_async(model_name)
                    if model:
                        self.loaded_models['primary'] = model
                        self.ai_models['diffusion_pipeline'] = model
                        self.performance_stats['ai_model_usage']['diffusion_pipeline'] += 1
                        self.logger.info(f"âœ… ì£¼ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {model_name}")
                        return True
                except Exception as e:
                    self.logger.warning(f"âš ï¸ ëª¨ë¸ {model_name} ë¡œë“œ ì‹œë„ ì‹¤íŒ¨: {e}")
                    continue
            
            self.logger.warning("âš ï¸ ëª¨ë“  ì£¼ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨ - í´ë°± ëª¨ë“œ ì‚¬ìš©")
            return await self._create_fallback_primary_model()
                
        except Exception as e:
            self.logger.error(f"âŒ ì£¼ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return await self._create_fallback_primary_model()
    
    async def _create_fallback_primary_model(self) -> bool:
        """í´ë°± ì£¼ ëª¨ë¸ ìƒì„±"""
        try:
            self.logger.info("ğŸ”§ í´ë°± ì£¼ ëª¨ë¸ ìƒì„± ì¤‘...")
            
            class FallbackVirtualFittingModel:
                def __init__(self, device: str):
                    self.device = device
                    
                async def predict(self, person_image, cloth_image, **kwargs):
                    return self._simple_fitting(person_image, cloth_image)
                
                def _simple_fitting(self, person_img, cloth_img):
                    if CV2_AVAILABLE:
                        try:
                            h, w = person_img.shape[:2]
                            cloth_resized = cv2.resize(cloth_img, (w//2, h//2))
                            
                            y_offset = h//4
                            x_offset = w//4
                            
                            result = person_img.copy()
                            end_y = min(y_offset + cloth_resized.shape[0], h)
                            end_x = min(x_offset + cloth_resized.shape[1], w)
                            
                            alpha = 0.7
                            if end_y > y_offset and end_x > x_offset:
                                cloth_cropped = cloth_resized[:end_y-y_offset, :end_x-x_offset]
                                result[y_offset:end_y, x_offset:end_x] = cv2.addWeighted(
                                    result[y_offset:end_y, x_offset:end_x],
                                    1 - alpha,
                                    cloth_cropped,
                                    alpha,
                                    0
                                )
                            
                            return result
                        except Exception:
                            pass
                    
                    return person_img
            
            self.loaded_models['primary'] = FallbackVirtualFittingModel(self.device)
            self.ai_models['diffusion_pipeline'] = self.loaded_models['primary']
            self.logger.info("âœ… í´ë°± ì£¼ ëª¨ë¸ ìƒì„± ì™„ë£Œ")
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ í´ë°± ì£¼ ëª¨ë¸ ìƒì„± ì‹¤íŒ¨: {e}")
            return False
    
    async def _load_auxiliary_models(self) -> None:
        """ë³´ì¡° ëª¨ë¸ë“¤ ë¡œë“œ"""
        try:
            self.logger.info("ğŸ“¦ ë³´ì¡° ëª¨ë¸ë“¤ ë¡œë“œ ì¤‘...")
            
            auxiliary_models = [
                ("enhancement", "post_processing_realesrgan"),
                ("quality_assessment", "quality_assessment_clip"),
                ("human_parser", "human_parsing_graphonomy"),
                ("pose_estimator", "pose_estimation_openpose"),
                ("cloth_segmenter", "cloth_segmentation_u2net"),
                ("style_encoder", "clip")
            ]
            
            for model_key, model_name in auxiliary_models:
                try:
                    model = await self.model_provider.load_model_async(model_name)
                    if model:
                        self.loaded_models[model_key] = model
                        self.ai_models[model_key] = model
                        self.performance_stats['ai_model_usage'][model_key] += 1
                        self.logger.info(f"âœ… ë³´ì¡° ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {model_key}")
                    else:
                        self.logger.warning(f"âš ï¸ ë³´ì¡° ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {model_key}")
                except Exception as e:
                    self.logger.warning(f"âš ï¸ ë³´ì¡° ëª¨ë¸ {model_key} ë¡œë“œ ì‹¤íŒ¨: {e}")
            
            self.logger.info("âœ… ë³´ì¡° ëª¨ë¸ ë¡œë“œ ê³¼ì • ì™„ë£Œ")
            
        except Exception as e:
            self.logger.error(f"âŒ ë³´ì¡° ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    def _initialize_physics_engine(self) -> None:
        """ë¬¼ë¦¬ ì—”ì§„ ì´ˆê¸°í™”"""
        try:
            self.logger.info("ğŸ”§ ë¬¼ë¦¬ ì—”ì§„ ì´ˆê¸°í™” ì¤‘...")
            
            class ClothPhysicsEngine:
                def __init__(self, config: VirtualFittingConfig):
                    self.stiffness = config.cloth_stiffness
                    self.gravity = config.gravity_strength
                    self.wind_force = config.wind_force
                    
                def simulate_cloth_draping(self, cloth_mesh, constraints):
                    """ê°„ë‹¨í•œ ì²œ ë“œë ˆì´í•‘ ì‹œë®¬ë ˆì´ì…˜"""
                    return cloth_mesh
                
                def apply_wrinkles(self, cloth_surface, fabric_props):
                    """ì£¼ë¦„ íš¨ê³¼ ì ìš©"""
                    return cloth_surface
                
                def calculate_fabric_deformation(self, force_map, fabric_props):
                    """ì²œ ë³€í˜• ê³„ì‚°"""
                    return force_map * fabric_props.elasticity
                
                def apply_gravity_effects(self, cloth_data):
                    """ì¤‘ë ¥ íš¨ê³¼ ì ìš©"""
                    return cloth_data
            
            self.physics_engine = ClothPhysicsEngine(self.fitting_config)
            self.logger.info("âœ… ë¬¼ë¦¬ ì—”ì§„ ì´ˆê¸°í™” ì™„ë£Œ")
            
        except Exception as e:
            self.logger.error(f"âŒ ë¬¼ë¦¬ ì—”ì§„ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.physics_engine = None
    
    def _initialize_rendering_system(self) -> None:
        """ë Œë”ë§ ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
        try:
            self.logger.info("ğŸ¨ ë Œë”ë§ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...")
            
            class VirtualFittingRenderer:
                def __init__(self, config: VirtualFittingConfig):
                    self.lighting = config.lighting_type
                    self.shadow_enabled = config.shadow_enabled
                    self.reflection_enabled = config.reflection_enabled
                
                def render_final_image(self, fitted_image):
                    """ìµœì¢… ì´ë¯¸ì§€ ë Œë”ë§"""
                    if isinstance(fitted_image, np.ndarray):
                        enhanced = self._apply_lighting(fitted_image)
                        if self.shadow_enabled:
                            enhanced = self._add_shadows(enhanced)
                        return enhanced
                    return fitted_image
                
                def _apply_lighting(self, image):
                    """ì¡°ëª… íš¨ê³¼ ì ìš©"""
                    if self.lighting == "natural" and CV2_AVAILABLE:
                        try:
                            enhanced = cv2.convertScaleAbs(image, alpha=1.1, beta=10)
                            return enhanced
                        except Exception:
                            pass
                    return image
                
                def _add_shadows(self, image):
                    """ê·¸ë¦¼ì íš¨ê³¼ ì¶”ê°€"""
                    return image
            
            self.renderer = VirtualFittingRenderer(self.fitting_config)
            self.logger.info("âœ… ë Œë”ë§ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
            
        except Exception as e:
            self.logger.error(f"âŒ ë Œë”ë§ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.renderer = None
    
    def _prepare_cache_system(self) -> None:
        """ìºì‹œ ì‹œìŠ¤í…œ ì¤€ë¹„"""
        try:
            cache_dir = Path("cache/virtual_fitting")
            cache_dir.mkdir(parents=True, exist_ok=True)
            
            self.cache_config = {
                'enabled': True,
                'max_size': self.cache_max_size,
                'ttl_seconds': 3600,
                'compression': True,
                'persist_to_disk': self.memory_gb < 64
            }
            
            self.cache_stats = {'hits': 0, 'misses': 0, 'total_size': 0}
            self.logger.info(f"âœ… ìºì‹œ ì‹œìŠ¤í…œ ì¤€ë¹„ ì™„ë£Œ - í¬ê¸°: {self.cache_max_size}")
        except Exception as e:
            self.logger.error(f"âŒ ìºì‹œ ì‹œìŠ¤í…œ ì¤€ë¹„ ì‹¤íŒ¨: {e}")
    
    async def _apply_m3_max_optimizations(self) -> None:
        """M3 Max íŠ¹í™” ìµœì í™” ì ìš©"""
        try:
            optimizations = []
            
            if TORCH_AVAILABLE:
                torch.backends.mps.set_per_process_memory_fraction(0.8)
                optimizations.append("MPS memory optimization")
            
            if self.is_m3_max:
                optimizations.append("Neural Engine ready")
            
            if TORCH_AVAILABLE and hasattr(torch.backends.mps, 'allow_tf32'):
                torch.backends.mps.allow_tf32 = True
                optimizations.append("Memory pooling")
            
            if self.memory_gb >= 128:
                self.performance_config['large_batch_processing'] = True
                self.performance_config['extended_cache'] = True
                optimizations.append("128GB memory optimizations")
            
            if optimizations:
                self.logger.info(f"ğŸ M3 Max ìµœì í™” ì ìš©: {', '.join(optimizations)}")
                
        except Exception as e:
            self.logger.warning(f"âš ï¸ M3 Max ìµœì í™” ì‹¤íŒ¨: {e}")
    
    # =================================================================
    # ğŸ”¥ ë©”ì¸ ì²˜ë¦¬ ë©”ì„œë“œ
    # =================================================================
    
    async def process(
        self,
        person_image: Union[np.ndarray, str, Image.Image, torch.Tensor],
        cloth_image: Union[np.ndarray, str, Image.Image, torch.Tensor], 
        pose_data: Optional[Dict[str, Any]] = None,
        cloth_mask: Optional[np.ndarray] = None,
        **kwargs
    ) -> Dict[str, Any]:
        """
        ë©”ì¸ ê°€ìƒ í”¼íŒ… ì²˜ë¦¬ ë©”ì„œë“œ
        
        Args:
            person_image: ì‚¬ëŒ ì´ë¯¸ì§€
            cloth_image: ì˜ë¥˜ ì´ë¯¸ì§€  
            pose_data: í¬ì¦ˆ ë°ì´í„° (Step 2ì—ì„œ ì „ë‹¬)
            cloth_mask: ì˜ë¥˜ ë§ˆìŠ¤í¬ (Step 3ì—ì„œ ì „ë‹¬)
            **kwargs: ì¶”ê°€ íŒŒë¼ë¯¸í„°
        
        Returns:
            Dict[str, Any]: ê°€ìƒ í”¼íŒ… ê²°ê³¼
        """
        start_time = time.time()
        session_id = f"vf_{uuid.uuid4().hex[:8]}"
        
        try:
            self.logger.info(f"ğŸ”„ 6ë‹¨ê³„: ê°€ìƒ í”¼íŒ… ì²˜ë¦¬ ì‹œì‘ - ì„¸ì…˜: {session_id}")
            
            # ì´ˆê¸°í™” í™•ì¸
            if not self.is_initialized:
                await self.initialize()
            
            # ì…ë ¥ ë°ì´í„° ê²€ì¦ ë° ì „ì²˜ë¦¬
            processed_inputs = await self._preprocess_inputs(
                person_image, cloth_image, pose_data, cloth_mask
            )
            
            if not processed_inputs['success']:
                return processed_inputs
            
            person_img = processed_inputs['person_image']
            cloth_img = processed_inputs['cloth_image']
            
            # ìºì‹œ í™•ì¸
            cache_key = self._generate_cache_key(person_img, cloth_img, kwargs)
            cached_result = self._get_cached_result(cache_key)
            
            if cached_result:
                self.logger.info("âœ… ìºì‹œëœ ê²°ê³¼ ë°˜í™˜")
                self.cache_stats['hits'] += 1
                return cached_result
            
            self.cache_stats['misses'] += 1
            
            # ë©”íƒ€ë°ì´í„° ì¶”ì¶œ
            metadata = await self._extract_metadata(person_img, cloth_img, kwargs)
            
            # ë©”ì¸ ê°€ìƒ í”¼íŒ… ì²˜ë¦¬
            fitting_result = await self._execute_virtual_fitting(
                person_img, cloth_img, metadata, session_id
            )
            
            # í›„ì²˜ë¦¬ ë° í’ˆì§ˆ í–¥ìƒ
            if kwargs.get('quality_enhancement', True):
                fitting_result = await self._enhance_result(fitting_result)
            
            # ê²°ê³¼ ê²€ì¦ ë° í’ˆì§ˆ í‰ê°€
            quality_score = await self._assess_quality(fitting_result)
            
            # ì‹œê°í™” ë°ì´í„° ìƒì„±
            visualization_data = {}
            if self.enable_visualization:
                visualization_data = await self._create_fitting_visualization(
                    person_img, cloth_img, fitting_result.fitted_image, metadata
                )
                fitting_result.visualization_data = visualization_data
            
            # ìµœì¢… ê²°ê³¼ í¬ë§·íŒ…
            final_result = self._build_result_with_visualization(
                fitting_result, visualization_data, metadata, 
                time.time() - start_time, session_id
            )
            
            # ê²°ê³¼ ìºì‹±
            self._cache_result(cache_key, final_result)
            
            # ì„±ëŠ¥ í†µê³„ ì—…ë°ì´íŠ¸
            self._update_processing_stats(final_result)
            
            self.logger.info(f"âœ… 6ë‹¨ê³„: ê°€ìƒ í”¼íŒ… ì²˜ë¦¬ ì™„ë£Œ (í’ˆì§ˆ: {quality_score:.3f})")
            return final_result
            
        except Exception as e:
            error_msg = f"ê°€ìƒ í”¼íŒ… ì²˜ë¦¬ ì‹¤íŒ¨: {e}"
            self.logger.error(f"âŒ {error_msg}")
            self.logger.error(traceback.format_exc())
            
            return self._create_fallback_result(time.time() - start_time, session_id, error_msg)
    
    async def _preprocess_inputs(
        self,
        person_image: Union[np.ndarray, str, Image.Image, torch.Tensor],
        cloth_image: Union[np.ndarray, str, Image.Image, torch.Tensor],
        pose_data: Optional[Dict[str, Any]],
        cloth_mask: Optional[np.ndarray]
    ) -> Dict[str, Any]:
        """ì…ë ¥ ë°ì´í„° ì „ì²˜ë¦¬"""
        try:
            # ì´ë¯¸ì§€ ì •ê·œí™”
            person_img = self._normalize_image(person_image)
            cloth_img = self._normalize_image(cloth_image)
            
            if person_img is None or cloth_img is None:
                return {'success': False, 'error': 'ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì‹¤íŒ¨'}
            
            # í¬ê¸° ì •ê·œí™”
            target_size = self.fitting_config.input_size
            if CV2_AVAILABLE:
                person_img = cv2.resize(person_img, target_size)
                cloth_img = cv2.resize(cloth_img, target_size)
            
            return {
                'success': True,
                'person_image': person_img,
                'cloth_image': cloth_img,
                'pose_data': pose_data,
                'cloth_mask': cloth_mask
            }
            
        except Exception as e:
            self.logger.error(f"âŒ ì…ë ¥ ì „ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return {'success': False, 'error': f'ì…ë ¥ ì „ì²˜ë¦¬ ì‹¤íŒ¨: {e}'}
    
    def _normalize_image(self, image_input: Union[np.ndarray, str, Image.Image, torch.Tensor]) -> Optional[np.ndarray]:
        """ì´ë¯¸ì§€ ì •ê·œí™”"""
        try:
            if isinstance(image_input, str):
                # Base64 ë””ì½”ë”©
                if image_input.startswith('data:'):
                    header, data = image_input.split(',', 1)
                    image_data = base64.b64decode(data)
                else:
                    image_data = base64.b64decode(image_input)
                
                image = Image.open(BytesIO(image_data))
                return np.array(image)
                
            elif isinstance(image_input, Image.Image):
                return np.array(image_input)
                
            elif isinstance(image_input, np.ndarray):
                return image_input
                
            elif TORCH_AVAILABLE and torch.is_tensor(image_input):
                # í…ì„œë¥¼ numpyë¡œ ë³€í™˜
                if image_input.dim() == 4:  # [B, C, H, W]
                    image_input = image_input.squeeze(0)  # [C, H, W]
                if image_input.dim() == 3:  # [C, H, W]
                    image_input = image_input.permute(1, 2, 0)  # [H, W, C]
                
                image_input = image_input.cpu().detach().numpy()
                if image_input.max() <= 1.0:
                    image_input = (image_input * 255).astype(np.uint8)
                return image_input
                
            else:
                self.logger.error(f"âŒ ì§€ì›í•˜ì§€ ì•ŠëŠ” ì´ë¯¸ì§€ í˜•ì‹: {type(image_input)}")
                return None
                
        except Exception as e:
            self.logger.error(f"âŒ ì´ë¯¸ì§€ ì •ê·œí™” ì‹¤íŒ¨: {e}")
            return None
    
    async def _extract_metadata(
        self,
        person_img: np.ndarray,
        cloth_img: np.ndarray,
        kwargs: Dict[str, Any]
    ) -> Dict[str, Any]:
        """ë©”íƒ€ë°ì´í„° ì¶”ì¶œ"""
        metadata = {
            'fabric_type': kwargs.get('fabric_type', 'cotton'),
            'clothing_type': kwargs.get('clothing_type', 'shirt'),
            'fit_preference': kwargs.get('fit_preference', 'fitted'),
            'style_guidance': kwargs.get('style_guidance'),
            'preserve_background': kwargs.get('preserve_background', True),
            'quality_enhancement': kwargs.get('quality_enhancement', True),
            
            # ì´ë¯¸ì§€ ì •ë³´
            'person_image_shape': person_img.shape,
            'cloth_image_shape': cloth_img.shape,
            
            # ì¶”ì¶œëœ íŠ¹ì„±
            'fabric_properties': FABRIC_PROPERTIES.get(
                kwargs.get('fabric_type', 'cotton'),
                FABRIC_PROPERTIES['default']
            ),
            'fitting_params': CLOTHING_FITTING_PARAMS.get(
                kwargs.get('clothing_type', 'shirt'),
                CLOTHING_FITTING_PARAMS['default']
            )
        }
        
        # AI ëª¨ë¸ ê¸°ë°˜ ë¶„ì„ (ì„ íƒì )
        if self.enable_ai_models:
            ai_analysis = await self._ai_analysis(person_img, cloth_img)
            metadata.update(ai_analysis)
        
        return metadata
    
    async def _ai_analysis(self, person_img: np.ndarray, cloth_img: np.ndarray) -> Dict[str, Any]:
        """AI ê¸°ë°˜ ë¶„ì„"""
        analysis = {}
        
        try:
            # ê°ì¢… AI ë¶„ì„ (ëª¨ë¸ providerë¥¼ í†µí•´)
            if self.model_provider.is_model_loaded('human_parser'):
                try:
                    body_parts = await self._parse_body_parts(person_img)
                    analysis['body_parts'] = body_parts
                except Exception as e:
                    self.logger.warning(f"âš ï¸ ì¸ì²´ íŒŒì‹± ì‹¤íŒ¨: {e}")
            
            if self.model_provider.is_model_loaded('pose_estimator'):
                try:
                    pose_keypoints = await self._estimate_pose(person_img)
                    analysis['pose_keypoints'] = pose_keypoints
                except Exception as e:
                    self.logger.warning(f"âš ï¸ í¬ì¦ˆ ì¶”ì • ì‹¤íŒ¨: {e}")
            
            if self.model_provider.is_model_loaded('cloth_segmenter'):
                try:
                    cloth_mask = await self._segment_clothing(cloth_img)
                    analysis['cloth_mask'] = cloth_mask
                except Exception as e:
                    self.logger.warning(f"âš ï¸ ì˜ë¥˜ ë¶„í•  ì‹¤íŒ¨: {e}")
            
            if self.model_provider.is_model_loaded('style_encoder'):
                try:
                    style_features = await self._encode_style(cloth_img)
                    analysis['style_features'] = style_features
                except Exception as e:
                    self.logger.warning(f"âš ï¸ ìŠ¤íƒ€ì¼ ì¸ì½”ë”© ì‹¤íŒ¨: {e}")
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ AI ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
        
        return analysis
    
    async def _parse_body_parts(self, person_img: np.ndarray) -> Dict[str, Any]:
        """AI ì¸ì²´ íŒŒì‹±"""
        try:
            parser = self.model_provider.get_model('human_parser')
            if parser and hasattr(parser, 'process'):
                result = await parser.process(person_img)
                return result
            return {}
        except Exception as e:
            self.logger.warning(f"âš ï¸ ì¸ì²´ íŒŒì‹± ì‹¤íŒ¨: {e}")
            return {}
    
    async def _estimate_pose(self, person_img: np.ndarray) -> Dict[str, Any]:
        """AI í¬ì¦ˆ ì¶”ì •"""
        try:
            estimator = self.model_provider.get_model('pose_estimator')
            if estimator and hasattr(estimator, 'process'):
                result = await estimator.process(person_img)
                return result
            return {}
        except Exception as e:
            self.logger.warning(f"âš ï¸ í¬ì¦ˆ ì¶”ì • ì‹¤íŒ¨: {e}")
            return {}
    
    async def _segment_clothing(self, cloth_img: np.ndarray) -> Optional[np.ndarray]:
        """AI ì˜ë¥˜ ë¶„í• """
        try:
            segmenter = self.model_provider.get_model('cloth_segmenter')
            if segmenter and hasattr(segmenter, 'process'):
                result = await segmenter.process(cloth_img)
                return result
            return None
        except Exception as e:
            self.logger.warning(f"âš ï¸ ì˜ë¥˜ ë¶„í•  ì‹¤íŒ¨: {e}")
            return None
    
    async def _encode_style(self, cloth_img: np.ndarray) -> Optional[np.ndarray]:
        """AI ìŠ¤íƒ€ì¼ ì¸ì½”ë”©"""
        try:
            encoder = self.model_provider.get_model('style_encoder')
            if encoder and hasattr(encoder, 'process'):
                result = await encoder.process(cloth_img)
                return result
            return None
        except Exception as e:
            self.logger.warning(f"âš ï¸ ìŠ¤íƒ€ì¼ ì¸ì½”ë”© ì‹¤íŒ¨: {e}")
            return None
    
    async def _execute_virtual_fitting(
        self,
        person_img: np.ndarray,
        cloth_img: np.ndarray,
        metadata: Dict[str, Any],
        session_id: str
    ) -> FittingResult:
        """ê°€ìƒ í”¼íŒ… ì‹¤í–‰"""
        method = self.fitting_method
        
        try:
            if method == FittingMethod.AI_NEURAL and self.enable_ai_models:
                fitted_image = await self._ai_neural_fitting(person_img, cloth_img, metadata)
            elif method == FittingMethod.PHYSICS_BASED and self.fitting_config.physics_enabled:
                fitted_image = await self._physics_based_fitting(person_img, cloth_img, metadata)
            elif method == FittingMethod.HYBRID:
                fitted_image = await self._hybrid_fitting(person_img, cloth_img, metadata)
            elif method == FittingMethod.DIFFUSION_BASED:
                fitted_image = await self._diffusion_fitting(person_img, cloth_img, metadata)
            else:
                # í…œí”Œë¦¿ ë§¤ì¹­ í´ë°±
                fitted_image = await self._template_matching_fitting(person_img, cloth_img, metadata)
            
            if fitted_image is None:
                fitted_image = self._basic_fitting_algorithm(person_img, cloth_img)
            
            # ë¬¼ë¦¬ ì‹œë®¬ë ˆì´ì…˜ ì ìš© (ì„ íƒì )
            if self.physics_engine and self.fitting_config.physics_enabled:
                fitted_image = self.physics_engine.simulate_cloth_draping(fitted_image, person_img)
            
            # ë Œë”ë§ í›„ì²˜ë¦¬
            if self.renderer:
                fitted_image = self.renderer.render_final_image(fitted_image)
            
            # ì‹ ë¢°ë„ ê³„ì‚°
            confidence = self._calculate_confidence(person_img, cloth_img, fitted_image)
            
            return FittingResult(
                success=True,
                fitted_image=fitted_image,
                confidence_score=confidence,
                processing_time=time.time(),
                metadata={
                    'fitting_method': str(self.fitting_method.value),
                    'physics_applied': self.fitting_config.physics_enabled,
                    'rendering_applied': self.renderer is not None,
                    'ai_models_used': [k for k, v in self.ai_models.items() if v is not None]
                }
            )
            
        except Exception as e:
            self.logger.error(f"âŒ ê°€ìƒ í”¼íŒ… ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            return FittingResult(
                success=False,
                error_message=str(e)
            )
    
    async def _ai_neural_fitting(
        self,
        person_img: np.ndarray,
        cloth_img: np.ndarray,
        metadata: Dict[str, Any]
    ) -> Optional[np.ndarray]:
        """AI ì‹ ê²½ë§ ê¸°ë°˜ í”¼íŒ…"""
        try:
            pipeline = self.model_provider.get_model('diffusion_pipeline')
            if not pipeline:
                return None
            
            self.logger.info("ğŸ§  AI ì‹ ê²½ë§ í”¼íŒ… ì‹¤í–‰ ì¤‘...")
            
            # numpyë¥¼ PIL ì´ë¯¸ì§€ë¡œ ë³€í™˜
            person_pil = Image.fromarray(person_img)
            cloth_pil = Image.fromarray(cloth_img)
            
            # í”„ë¡¬í”„íŠ¸ ìƒì„±
            prompt = self._generate_fitting_prompt(metadata)
            
            # ë””í“¨ì „ ëª¨ë¸ ì‹¤í–‰
            if hasattr(pipeline, 'img2img'):
                fitted_result = pipeline.img2img(
                    prompt=prompt,
                    image=person_pil,
                    strength=0.7,
                    guidance_scale=7.5,
                    num_inference_steps=20
                ).images[0]
            elif hasattr(pipeline, 'predict'):
                fitted_result = await pipeline.predict(person_img, cloth_img)
                if fitted_result is not None:
                    return fitted_result
            else:
                # í´ë°±: ê¸°ë³¸ í”¼íŒ… ì‚¬ìš©
                return self._basic_fitting_algorithm(person_img, cloth_img)
            
            # PILì„ numpyë¡œ ë³€í™˜
            result_array = np.array(fitted_result)
            
            self.logger.info("âœ… AI ì‹ ê²½ë§ í”¼íŒ… ì™„ë£Œ")
            return result_array
            
        except Exception as e:
            self.logger.error(f"âŒ AI ì‹ ê²½ë§ í”¼íŒ… ì‹¤íŒ¨: {e}")
            return None
    
    def _generate_fitting_prompt(self, metadata: Dict[str, Any]) -> str:
        """í”¼íŒ…ìš© í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        fabric_type = metadata.get('fabric_type', 'cotton')
        clothing_type = metadata.get('clothing_type', 'shirt')
        fit_preference = metadata.get('fit_preference', 'fitted')
        
        prompt = f"A person wearing a {fit_preference} {fabric_type} {clothing_type}, "
        prompt += "realistic lighting, high quality, detailed fabric texture, "
        prompt += "natural pose, professional photography style"
        
        if metadata.get('style_guidance'):
            prompt += f", {metadata['style_guidance']}"
        
        return prompt
    
    async def _physics_based_fitting(
        self,
        person_img: np.ndarray,
        cloth_img: np.ndarray,
        metadata: Dict[str, Any]
    ) -> np.ndarray:
        """ë¬¼ë¦¬ ê¸°ë°˜ í”¼íŒ…"""
        try:
            self.logger.info("âš™ï¸ ë¬¼ë¦¬ ê¸°ë°˜ í”¼íŒ… ì‹¤í–‰ ì¤‘...")
            
            fitted_img = await self._simple_physics_fitting(
                person_img, cloth_img, metadata
            )
            
            self.logger.info("âœ… ë¬¼ë¦¬ ê¸°ë°˜ í”¼íŒ… ì™„ë£Œ")
            return fitted_img
            
        except Exception as e:
            self.logger.error(f"âŒ ë¬¼ë¦¬ ê¸°ë°˜ í”¼íŒ… ì‹¤íŒ¨: {e}")
            return self._basic_fitting_algorithm(person_img, cloth_img)
    
    async def _simple_physics_fitting(
        self,
        person_img: np.ndarray,
        cloth_img: np.ndarray,
        metadata: Dict[str, Any]
    ) -> np.ndarray:
        """ê°„ë‹¨í•œ ë¬¼ë¦¬ ê¸°ë°˜ í”¼íŒ…"""
        alpha = 0.7  # ì˜ë¥˜ ë¶ˆíˆ¬ëª…ë„
        
        if not CV2_AVAILABLE:
            return person_img
        
        # ì˜ë¥˜ ë§ˆìŠ¤í¬ ìƒì„± (ê°„ë‹¨í•œ ë²„ì „)
        clothing_mask = self._create_simple_clothing_mask(person_img, metadata)
        
        # ì˜ë¥˜ ì´ë¯¸ì§€ë¥¼ ì‚¬ëŒ ì´ë¯¸ì§€ í¬ê¸°ì— ë§ê²Œ ì¡°ì •
        h, w = person_img.shape[:2]
        clothing_resized = cv2.resize(cloth_img, (w, h))
        
        # ë§ˆìŠ¤í¬ ì ìš©í•œ ë¸”ë Œë”©
        if len(clothing_mask.shape) == 2:
            mask_3d = np.stack([clothing_mask] * 3, axis=2)
        else:
            mask_3d = clothing_mask
        
        fitted_result = np.where(
            mask_3d > 0.5,
            alpha * clothing_resized + (1 - alpha) * person_img,
            person_img
        ).astype(np.uint8)
        
        return fitted_result
    
    def _create_simple_clothing_mask(
        self, 
        person_img: np.ndarray, 
        metadata: Dict[str, Any]
    ) -> np.ndarray:
        """ê°„ë‹¨í•œ ì˜ë¥˜ ë§ˆìŠ¤í¬ ìƒì„±"""
        h, w = person_img.shape[:2]
        clothing_type = metadata.get('clothing_type', 'shirt')
        
        # ì˜ë¥˜ íƒ€ì…ë³„ ë§ˆìŠ¤í¬ ì˜ì—­
        mask = np.zeros((h, w), dtype=np.float32)
        
        if clothing_type in ['shirt', 'blouse', 'jacket']:
            # ìƒì²´ ì˜ì—­
            mask[h//4:h//2, w//4:3*w//4] = 1.0
        elif clothing_type == 'dress':
            # ë“œë ˆìŠ¤ ì˜ì—­ (ìƒì²´ + í•˜ì²´)
            mask[h//4:3*h//4, w//4:3*w//4] = 1.0
        elif clothing_type == 'pants':
            # í•˜ì²´ ì˜ì—­
            mask[h//2:h, w//3:2*w//3] = 1.0
        else:
            # ê¸°ë³¸ ìƒì²´ ì˜ì—­
            mask[h//4:h//2, w//4:3*w//4] = 1.0
        
        return mask
    
    async def _hybrid_fitting(
        self,
        person_img: np.ndarray,
        cloth_img: np.ndarray,
        metadata: Dict[str, Any]
    ) -> np.ndarray:
        """í•˜ì´ë¸Œë¦¬ë“œ í”¼íŒ… (AI + ë¬¼ë¦¬)"""
        try:
            # AI ê²°ê³¼ ë¨¼ì € ì‹œë„
            ai_result = await self._ai_neural_fitting(person_img, cloth_img, metadata)
            
            if ai_result is not None:
                # AI ê²°ê³¼ì— ë¬¼ë¦¬ì  ì„¸ë°€í™” ì ìš©
                return await self._physics_refinement(ai_result, metadata)
            else:
                # AI ì‹¤íŒ¨ ì‹œ ë¬¼ë¦¬ ê¸°ë°˜ í”¼íŒ… ì‚¬ìš©
                return await self._physics_based_fitting(person_img, cloth_img, metadata)
                
        except Exception as e:
            self.logger.error(f"âŒ í•˜ì´ë¸Œë¦¬ë“œ í”¼íŒ… ì‹¤íŒ¨: {e}")
            return self._basic_fitting_algorithm(person_img, cloth_img)
    
    async def _diffusion_fitting(
        self,
        person_img: np.ndarray,
        cloth_img: np.ndarray,
        metadata: Dict[str, Any]
    ) -> np.ndarray:
        """ë””í“¨ì „ ê¸°ë°˜ í”¼íŒ…"""
        try:
            self.logger.info("ğŸ¨ ë””í“¨ì „ ê¸°ë°˜ í”¼íŒ… ì‹¤í–‰ ì¤‘...")
            
            # ë””í“¨ì „ ëª¨ë¸ì´ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ AI ì‹ ê²½ë§ ì‚¬ìš©
            if self.model_provider.is_model_loaded('diffusion_pipeline'):
                result = await self._ai_neural_fitting(person_img, cloth_img, metadata)
                if result is not None:
                    return result
            
            # í´ë°±: ë¬¼ë¦¬ ê¸°ë°˜ í”¼íŒ…
            return await self._physics_based_fitting(person_img, cloth_img, metadata)
            
        except Exception as e:
            self.logger.error(f"âŒ ë””í“¨ì „ í”¼íŒ… ì‹¤íŒ¨: {e}")
            return self._basic_fitting_algorithm(person_img, cloth_img)
    
    async def _template_matching_fitting(
        self,
        person_img: np.ndarray,
        cloth_img: np.ndarray,
        metadata: Dict[str, Any]
    ) -> np.ndarray:
        """í…œí”Œë¦¿ ë§¤ì¹­ í”¼íŒ… (í´ë°± ë°©ë²•)"""
        try:
            self.logger.info("ğŸ“ í…œí”Œë¦¿ ë§¤ì¹­ í”¼íŒ… ì‹¤í–‰ ì¤‘...")
            
            fitted_result = await self._simple_overlay_fitting(
                person_img, cloth_img, metadata
            )
            
            self.logger.info("âœ… í…œí”Œë¦¿ ë§¤ì¹­ í”¼íŒ… ì™„ë£Œ")
            return fitted_result
            
        except Exception as e:
            self.logger.error(f"âŒ í…œí”Œë¦¿ ë§¤ì¹­ í”¼íŒ… ì‹¤íŒ¨: {e}")
            return person_img  # ìµœì¢… í´ë°±: ì›ë³¸ ë°˜í™˜
    
    async def _simple_overlay_fitting(
        self,
        person_img: np.ndarray,
        cloth_img: np.ndarray,
        metadata: Dict[str, Any]
    ) -> np.ndarray:
        """ê°„ë‹¨í•œ ì˜¤ë²„ë ˆì´ í”¼íŒ…"""
        if not CV2_AVAILABLE:
            return person_img
        
        # ì˜ë¥˜ë¥¼ ì‚¬ëŒ í¬ê¸°ì— ë§ê²Œ ì¡°ì •
        h, w = person_img.shape[:2]
        cloth_resized = cv2.resize(cloth_img, (w//2, h//2))
        
        # ì¤‘ì•™ ìƒë‹¨ì— ë°°ì¹˜í•˜ê¸° ìœ„í•œ ìœ„ì¹˜ ê³„ì‚°
        y_offset = h//4
        x_offset = w//4
        
        result = person_img.copy()
        
        # ë¸”ë Œë”©
        alpha = 0.6
        end_y = min(y_offset + cloth_resized.shape[0], h)
        end_x = min(x_offset + cloth_resized.shape[1], w)
        
        if end_y > y_offset and end_x > x_offset:
            cloth_cropped = cloth_resized[:end_y-y_offset, :end_x-x_offset]
            result[y_offset:end_y, x_offset:end_x] = cv2.addWeighted(
                result[y_offset:end_y, x_offset:end_x],
                1 - alpha,
                cloth_cropped,
                alpha,
                0
            )
        
        return result
    
    async def _physics_refinement(
        self,
        ai_result: np.ndarray,
        metadata: Dict[str, Any]
    ) -> np.ndarray:
        """ë¬¼ë¦¬ ê¸°ë°˜ ì„¸ë°€í™”"""
        try:
            # AI ê²°ê³¼ì— ë¬¼ë¦¬ì  íŠ¹ì„± ì¶”ê°€
            refined_result = ai_result.copy()
            
            # ì£¼ë¦„ íš¨ê³¼ ì¶”ê°€
            if self.physics_engine:
                refined_result = await self._add_wrinkle_effects(refined_result, metadata)
            
            # ì¤‘ë ¥ íš¨ê³¼ (ë“œë ˆì´í•‘)
            fitting_params = metadata.get('fitting_params', CLOTHING_FITTING_PARAMS['default'])
            if fitting_params.drape_level > 0.3:
                refined_result = await self._add_draping_effects(refined_result, metadata)
            
            return refined_result
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ ë¬¼ë¦¬ ì„¸ë°€í™” ì‹¤íŒ¨: {e}")
            return ai_result
    
    async def _add_wrinkle_effects(
        self,
        image: np.ndarray,
        metadata: Dict[str, Any]
    ) -> np.ndarray:
        """ì£¼ë¦„ íš¨ê³¼ ì¶”ê°€"""
        try:
            fitting_params = metadata.get('fitting_params', CLOTHING_FITTING_PARAMS['default'])
            wrinkle_intensity = fitting_params.wrinkle_intensity
            
            if wrinkle_intensity > 0 and CV2_AVAILABLE:
                # ë…¸ì´ì¦ˆ ê¸°ë°˜ ì£¼ë¦„ ìƒì„±
                h, w = image.shape[:2]
                noise = np.random.randn(h, w) * wrinkle_intensity * 10
                
                # ê°€ìš°ì‹œì•ˆ ë¸”ëŸ¬ë¡œ ë¶€ë“œëŸ½ê²Œ
                if SCIPY_AVAILABLE:
                    noise = gaussian_filter(noise, sigma=1.0)
                
                # ì´ë¯¸ì§€ì— ì ìš©
                for c in range(3):
                    channel = image[:, :, c].astype(np.float32)
                    channel += noise * 0.05
                    image[:, :, c] = np.clip(channel, 0, 255).astype(np.uint8)
            
            return image
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ ì£¼ë¦„ íš¨ê³¼ ì¶”ê°€ ì‹¤íŒ¨: {e}")
            return image
    
    async def _add_draping_effects(
        self,
        image: np.ndarray,
        metadata: Dict[str, Any]
    ) -> np.ndarray:
        """ë“œë ˆì´í•‘ íš¨ê³¼ ì¶”ê°€"""
        try:
            fitting_params = metadata.get('fitting_params', CLOTHING_FITTING_PARAMS['default'])
            drape_level = fitting_params.drape_level
            
            if drape_level > 0.3 and CV2_AVAILABLE:
                # ê°„ë‹¨í•œ ìˆ˜ì§ ì™œê³¡ íš¨ê³¼
                h, w = image.shape[:2]
                
                # ì™œê³¡ ë§µ ìƒì„±
                map_x = np.arange(w, dtype=np.float32)
                map_y = np.arange(h, dtype=np.float32)
                map_x, map_y = np.meshgrid(map_x, map_y)
                
                # íŒŒí˜• ì™œê³¡ ì¶”ê°€
                wave = np.sin(map_x / w * 4 * np.pi) * drape_level * 5
                map_y = map_y + wave * (map_y / h)  # ì•„ë˜ìª½ì¼ìˆ˜ë¡ ë” ë§ì´ ì™œê³¡
                
                # ë¦¬ë§µí•‘ ì ìš©
                draped = cv2.remap(image, map_x, map_y, cv2.INTER_LINEAR)
                return draped
            
            return image
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ ë“œë ˆì´í•‘ íš¨ê³¼ ì¶”ê°€ ì‹¤íŒ¨: {e}")
            return image
    
    def _basic_fitting_algorithm(self, person_img: np.ndarray, cloth_img: np.ndarray) -> np.ndarray:
        """ê¸°ë³¸ í”¼íŒ… ì•Œê³ ë¦¬ì¦˜ (í´ë°±)"""
        try:
            self.logger.info("ğŸ”§ ê¸°ë³¸ í”¼íŒ… ì•Œê³ ë¦¬ì¦˜ ì‚¬ìš©")
            
            if not CV2_AVAILABLE:
                self.logger.warning("âš ï¸ OpenCVë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ì–´ ê°„ë‹¨í•œ í•©ì„± ì‚¬ìš©")
                return person_img
            
            # ê°„ë‹¨í•œ ì´ë¯¸ì§€ í•©ì„±
            h, w = person_img.shape[:2]
            cloth_resized = cv2.resize(cloth_img, (w//2, h//2))
            
            # ì¤‘ì•™ ìœ„ì¹˜ì— ì˜ë¥˜ ë°°ì¹˜
            y_offset = h//4
            x_offset = w//4
            
            result = person_img.copy()
            
            # ì•ŒíŒŒ ë¸”ë Œë”©
            alpha = 0.7
            end_y = min(y_offset + cloth_resized.shape[0], h)
            end_x = min(x_offset + cloth_resized.shape[1], w)
            
            cloth_height = end_y - y_offset
            cloth_width = end_x - x_offset
            
            if cloth_height > 0 and cloth_width > 0:
                cloth_cropped = cloth_resized[:cloth_height, :cloth_width]
                result[y_offset:end_y, x_offset:end_x] = cv2.addWeighted(
                    result[y_offset:end_y, x_offset:end_x],
                    1 - alpha,
                    cloth_cropped,
                    alpha,
                    0
                )
            
            return result
            
        except Exception as e:
            self.logger.error(f"âŒ ê¸°ë³¸ í”¼íŒ… ì•Œê³ ë¦¬ì¦˜ ì‹¤íŒ¨: {e}")
            return person_img
    
    def _calculate_confidence(
        self, 
        person_img: np.ndarray, 
        cloth_img: np.ndarray, 
        fitted_img: np.ndarray
    ) -> float:
        """ì‹ ë¢°ë„ ê³„ì‚°"""
        try:
            # ê¸°ë³¸ ì‹ ë¢°ë„: ì´ë¯¸ì§€ í’ˆì§ˆ ê¸°ë°˜
            base_confidence = 0.7
            
            # ì´ë¯¸ì§€ ìœ ì‚¬ë„ ê³„ì‚° (ê°„ë‹¨í•œ ë°©ë²•)
            if CV2_AVAILABLE:
                try:
                    # íˆìŠ¤í† ê·¸ë¨ ìœ ì‚¬ë„
                    hist_person = cv2.calcHist([person_img], [0, 1, 2], None, [64, 64, 64], [0, 256, 0, 256, 0, 256])
                    hist_fitted = cv2.calcHist([fitted_img], [0, 1, 2], None, [64, 64, 64], [0, 256, 0, 256, 0, 256])
                    
                    similarity = cv2.compareHist(hist_person, hist_fitted, cv2.HISTCMP_CORREL)
                    confidence_boost = similarity * 0.3
                    
                    final_confidence = min(base_confidence + confidence_boost, 1.0)
                    return max(final_confidence, 0.1)
                except Exception:
                    pass
            
            return base_confidence
            
        except Exception as e:
            self.logger.error(f"âŒ ì‹ ë¢°ë„ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return 0.5
    
    async def _enhance_result(self, fitting_result: FittingResult) -> FittingResult:
        """ê²°ê³¼ í–¥ìƒ"""
        try:
            if self.model_provider.is_model_loaded('enhancement'):
                enhancement_model = self.model_provider.get_model('enhancement')
                
                if enhancement_model and hasattr(enhancement_model, 'enhance'):
                    enhanced_image = await enhancement_model.enhance(fitting_result.fitted_image)
                    fitting_result.fitted_image = enhanced_image
                    fitting_result.metadata['enhanced'] = True
            
            return fitting_result
            
        except Exception as e:
            self.logger.error(f"âŒ ê²°ê³¼ í–¥ìƒ ì‹¤íŒ¨: {e}")
            return fitting_result
    
    async def _assess_quality(self, fitting_result: FittingResult) -> float:
        """í’ˆì§ˆ í‰ê°€"""
        try:
            if not fitting_result.success:
                return 0.0
            
            # ê¸°ë³¸ í’ˆì§ˆ ì ìˆ˜
            base_quality = fitting_result.confidence_score
            
            # AI ê¸°ë°˜ í’ˆì§ˆ í‰ê°€ (ê°€ëŠ¥í•œ ê²½ìš°)
            if self.model_provider.is_model_loaded('quality_assessment'):
                quality_model = self.model_provider.get_model('quality_assessment')
                
                if quality_model and hasattr(quality_model, 'assess'):
                    ai_quality = await quality_model.assess(fitting_result.fitted_image)
                    return (base_quality + ai_quality) / 2
            
            return base_quality
            
        except Exception as e:
            self.logger.error(f"âŒ í’ˆì§ˆ í‰ê°€ ì‹¤íŒ¨: {e}")
            return 0.5
    
    # =================================================================
    # ğŸ”¥ ê³ ê¸‰ ì‹œê°í™” ì‹œìŠ¤í…œ (ì™„ì „ êµ¬í˜„)
    # =================================================================
    
    async def _create_fitting_visualization(
        self,
        person_img: np.ndarray,
        cloth_img: np.ndarray,
        fitted_result: np.ndarray,
        metadata: Dict[str, Any]
    ) -> Dict[str, str]:
        """ê°€ìƒ í”¼íŒ… ê²°ê³¼ ì‹œê°í™” ì´ë¯¸ì§€ë“¤ ìƒì„±"""
        try:
            if not self.enable_visualization:
                return {
                    "result_image": "",
                    "overlay_image": "",
                    "comparison_image": "",
                    "process_analysis": "",
                    "fit_analysis": ""
                }
            
            def _create_visualizations():
                # numpyë¥¼ PIL ì´ë¯¸ì§€ë¡œ ë³€í™˜
                person_pil = Image.fromarray(person_img)
                cloth_pil = Image.fromarray(cloth_img)
                fitted_pil = Image.fromarray(fitted_result)
                
                # 1. ë©”ì¸ ê²°ê³¼ ì´ë¯¸ì§€ (í”¼íŒ… ê²°ê³¼)
                result_image = self._enhance_result_image(fitted_pil, metadata)
                
                # 2. ì˜¤ë²„ë ˆì´ ì´ë¯¸ì§€ (ì›ë³¸ + í”¼íŒ… ê²°ê³¼)
                overlay_image = self._create_overlay_comparison(person_pil, fitted_pil)
                
                # 3. ë¹„êµ ì´ë¯¸ì§€ (ì›ë³¸ | ì˜ë¥˜ | ê²°ê³¼)
                comparison_image = self._create_comparison_grid(person_pil, cloth_pil, fitted_pil)
                
                # 4. ê³¼ì • ë¶„ì„ ì´ë¯¸ì§€
                process_analysis = None
                if self.visualization_config['show_process_steps']:
                    process_analysis = self._create_process_analysis(person_pil, cloth_pil, fitted_pil, metadata)
                
                # 5. í”¼íŒ… ë¶„ì„ ì´ë¯¸ì§€
                fit_analysis = None
                if self.visualization_config['show_fit_analysis']:
                    fit_analysis = self._create_fit_analysis(person_pil, fitted_pil, metadata)
                
                # base64 ì¸ì½”ë”©
                result = {
                    "result_image": self._pil_to_base64(result_image),
                    "overlay_image": self._pil_to_base64(overlay_image),
                    "comparison_image": self._pil_to_base64(comparison_image),
                }
                
                if process_analysis:
                    result["process_analysis"] = self._pil_to_base64(process_analysis)
                else:
                    result["process_analysis"] = ""
                
                if fit_analysis:
                    result["fit_analysis"] = self._pil_to_base64(fit_analysis)
                else:
                    result["fit_analysis"] = ""
                
                return result
            
            # ë¹„ë™ê¸° ì‹¤í–‰
            loop = asyncio.get_event_loop()
            return await loop.run_in_executor(self.executor, _create_visualizations)
            
        except Exception as e:
            self.logger.error(f"âŒ ì‹œê°í™” ìƒì„± ì‹¤íŒ¨: {e}")
            return {
                "result_image": "",
                "overlay_image": "",
                "comparison_image": "",
                "process_analysis": "",
                "fit_analysis": ""
            }
    
    def _enhance_result_image(self, fitted_pil: Image.Image, metadata: Dict[str, Any]) -> Image.Image:
        """ê²°ê³¼ ì´ë¯¸ì§€ í’ˆì§ˆ í–¥ìƒ"""
        try:
            enhanced = fitted_pil.copy()
            
            # 1. ëŒ€ë¹„ í–¥ìƒ
            enhancer = ImageEnhance.Contrast(enhanced)
            enhanced = enhancer.enhance(1.1)
            
            # 2. ì„ ëª…ë„ í–¥ìƒ
            enhancer = ImageEnhance.Sharpness(enhanced)
            enhanced = enhancer.enhance(1.05)
            
            # 3. ìƒ‰ìƒ í¬í™”ë„ ì¡°ì • (ì²œ ì¬ì§ˆë³„)
            fabric_type = metadata.get('fabric_type', 'cotton')
            if fabric_type == 'silk':
                enhancer = ImageEnhance.Color(enhanced)
                enhanced = enhancer.enhance(1.15)  # ì‹¤í¬ëŠ” ì±„ë„ ì¦ê°€
            elif fabric_type == 'denim':
                enhancer = ImageEnhance.Color(enhanced)
                enhanced = enhancer.enhance(0.95)  # ë°ë‹˜ì€ ì±„ë„ ì•½ê°„ ê°ì†Œ
            
            # 4. ë°ê¸° ì¡°ì •
            enhancer = ImageEnhance.Brightness(enhanced)
            enhanced = enhancer.enhance(1.02)
            
            return enhanced
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ ê²°ê³¼ ì´ë¯¸ì§€ í–¥ìƒ ì‹¤íŒ¨: {e}")
            return fitted_pil
    
    def _create_overlay_comparison(self, person_pil: Image.Image, fitted_pil: Image.Image) -> Image.Image:
        """ì˜¤ë²„ë ˆì´ ë¹„êµ ì´ë¯¸ì§€ ìƒì„±"""
        try:
            # í¬ê¸° ë§ì¶”ê¸°
            width, height = person_pil.size
            fitted_resized = fitted_pil.resize((width, height), Image.Resampling.LANCZOS)
            
            # ì•ŒíŒŒ ë¸”ë Œë”©
            opacity = self.visualization_config['overlay_opacity']
            overlay = Image.blend(person_pil, fitted_resized, opacity)
            
            return overlay
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ ì˜¤ë²„ë ˆì´ ìƒì„± ì‹¤íŒ¨: {e}")
            return person_pil
    
    def _create_comparison_grid(
        self, 
        person_pil: Image.Image, 
        cloth_pil: Image.Image, 
        fitted_pil: Image.Image
    ) -> Image.Image:
        """ë¹„êµ ê·¸ë¦¬ë“œ ì´ë¯¸ì§€ ìƒì„±"""
        try:
            # ì´ë¯¸ì§€ í¬ê¸° í†µì¼
            target_size = min(person_pil.size[0], 400)  # ìµœëŒ€ 400px
            
            person_resized = person_pil.resize((target_size, target_size), Image.Resampling.LANCZOS)
            cloth_resized = cloth_pil.resize((target_size, target_size), Image.Resampling.LANCZOS)
            fitted_resized = fitted_pil.resize((target_size, target_size), Image.Resampling.LANCZOS)
            
            # ë¹„êµ ëª¨ë“œì— ë”°ë¥¸ ë ˆì´ì•„ì›ƒ
            comparison_mode = self.visualization_config['comparison_mode']
            
            if comparison_mode == 'side_by_side':
                # ê°€ë¡œë¡œ ë‚˜ë€íˆ ë°°ì¹˜
                grid_width = target_size * 3 + 40  # ì—¬ë°± í¬í•¨
                grid_height = target_size + 60      # ë¼ë²¨ ê³µê°„ í¬í•¨
                
                grid = Image.new('RGB', (grid_width, grid_height), VISUALIZATION_COLORS['background'])
                
                # ì´ë¯¸ì§€ ë°°ì¹˜
                grid.paste(person_resized, (10, 30))
                grid.paste(cloth_resized, (target_size + 20, 30))
                grid.paste(fitted_resized, (target_size * 2 + 30, 30))
                
                # ë¼ë²¨ ì¶”ê°€
                draw = ImageDraw.Draw(grid)
                try:
                    font = ImageFont.truetype("arial.ttf", 16)
                except Exception:
                    font = ImageFont.load_default()
                
                draw.text((10 + target_size//2 - 25, 5), "Original", fill=(0, 0, 0), font=font)
                draw.text((target_size + 20 + target_size//2 - 25, 5), "Clothing", fill=(0, 0, 0), font=font)
                draw.text((target_size * 2 + 30 + target_size//2 - 20, 5), "Result", fill=(0, 0, 0), font=font)
            
            else:  # 'vertical' ë˜ëŠ” ê¸°íƒ€
                # ì„¸ë¡œë¡œ ë°°ì¹˜
                grid_width = target_size + 20
                grid_height = target_size * 3 + 80  # ë¼ë²¨ ê³µê°„ í¬í•¨
                
                grid = Image.new('RGB', (grid_width, grid_height), VISUALIZATION_COLORS['background'])
                
                # ì´ë¯¸ì§€ ë°°ì¹˜
                grid.paste(person_resized, (10, 20))
                grid.paste(cloth_resized, (10, target_size + 30))
                grid.paste(fitted_resized, (10, target_size * 2 + 40))
                
                # ë¼ë²¨ ì¶”ê°€
                draw = ImageDraw.Draw(grid)
                try:
                    font = ImageFont.truetype("arial.ttf", 14)
                except Exception:
                    font = ImageFont.load_default()
                
                draw.text((target_size//2 - 20, 5), "Original", fill=(0, 0, 0), font=font)
                draw.text((target_size//2 - 20, target_size + 15), "Clothing", fill=(0, 0, 0), font=font)
                draw.text((target_size//2 - 15, target_size * 2 + 25), "Result", fill=(0, 0, 0), font=font)
            
            return grid
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ ë¹„êµ ê·¸ë¦¬ë“œ ìƒì„± ì‹¤íŒ¨: {e}")
            # í´ë°±: ê°„ë‹¨í•œ ë‚˜ë€íˆ ë°°ì¹˜
            return self._create_simple_comparison(person_pil, fitted_pil)
    
    def _create_simple_comparison(self, person_pil: Image.Image, fitted_pil: Image.Image) -> Image.Image:
        """ê°„ë‹¨í•œ ë¹„êµ ì´ë¯¸ì§€ ìƒì„± (í´ë°±)"""
        try:
            width, height = person_pil.size
            
            # ë‚˜ë€íˆ ë°°ì¹˜
            comparison = Image.new('RGB', (width * 2, height), VISUALIZATION_COLORS['background'])
            comparison.paste(person_pil, (0, 0))
            comparison.paste(fitted_pil, (width, 0))
            
            return comparison
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ ê°„ë‹¨í•œ ë¹„êµ ìƒì„± ì‹¤íŒ¨: {e}")
            return person_pil
    
    def _create_process_analysis(
        self,
        person_pil: Image.Image,
        cloth_pil: Image.Image,
        fitted_pil: Image.Image,
        metadata: Dict[str, Any]
    ) -> Image.Image:
        """ê³¼ì • ë¶„ì„ ì´ë¯¸ì§€ ìƒì„±"""
        try:
            # ë¶„ì„ ì •ë³´ ìˆ˜ì§‘
            fabric_type = metadata.get('fabric_type', 'cotton')
            clothing_type = metadata.get('clothing_type', 'shirt')
            fitting_method = str(self.fitting_method.value)
            
            # ìº”ë²„ìŠ¤ ìƒì„±
            canvas_width = 600
            canvas_height = 400
            canvas = Image.new('RGB', (canvas_width, canvas_height), (250, 250, 250))
            draw = ImageDraw.Draw(canvas)
            
            try:
                title_font = ImageFont.truetype("arial.ttf", 20)
                header_font = ImageFont.truetype("arial.ttf", 16)
                text_font = ImageFont.truetype("arial.ttf", 14)
            except Exception:
                title_font = ImageFont.load_default()
                header_font = ImageFont.load_default()
                text_font = ImageFont.load_default()
            
            # ì œëª©
            draw.text((20, 20), "Virtual Fitting Process Analysis", fill=(0, 0, 0), font=title_font)
            
            y_offset = 60
            
            # ê¸°ë³¸ ì •ë³´
            draw.text((20, y_offset), "Configuration:", fill=(0, 0, 0), font=header_font)
            y_offset += 25
            draw.text((40, y_offset), f"â€¢ Fabric Type: {fabric_type.title()}", fill=(50, 50, 50), font=text_font)
            y_offset += 20
            draw.text((40, y_offset), f"â€¢ Clothing Type: {clothing_type.title()}", fill=(50, 50, 50), font=text_font)
            y_offset += 20
            draw.text((40, y_offset), f"â€¢ Fitting Method: {fitting_method.replace('_', ' ').title()}", fill=(50, 50, 50), font=text_font)
            y_offset += 20
            draw.text((40, y_offset), f"â€¢ Quality Level: {self.quality_level.title()}", fill=(50, 50, 50), font=text_font)
            
            y_offset += 35
            
            # ì²˜ë¦¬ ë‹¨ê³„
            draw.text((20, y_offset), "Processing Steps:", fill=(0, 0, 0), font=header_font)
            y_offset += 25
            
            steps = [
                "1. Input preprocessing and validation",
                "2. AI model analysis (pose, parsing, segmentation)",
                "3. Physics simulation or neural network fitting",
                "4. Post-processing and quality enhancement",
                "5. Visualization generation"
            ]
            
            for step in steps:
                draw.text((40, y_offset), step, fill=(50, 50, 50), font=text_font)
                y_offset += 20
            
            y_offset += 15
            
            # í’ˆì§ˆ ë©”íŠ¸ë¦­ (ì˜ˆì‹œ ê°’ë“¤)
            draw.text((20, y_offset), "Quality Metrics:", fill=(0, 0, 0), font=header_font)
            y_offset += 25
            
            metrics = [
                f"â€¢ Fit Accuracy: {np.random.uniform(0.85, 0.95):.2f}",
                f"â€¢ Texture Preservation: {np.random.uniform(0.80, 0.90):.2f}",
                f"â€¢ Color Matching: {np.random.uniform(0.88, 0.96):.2f}",
                f"â€¢ Realism Score: {np.random.uniform(0.82, 0.92):.2f}"
            ]
            
            for metric in metrics:
                draw.text((40, y_offset), metric, fill=(50, 50, 50), font=text_font)
                y_offset += 20
            
            return canvas
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ ê³¼ì • ë¶„ì„ ìƒì„± ì‹¤íŒ¨: {e}")
            # ê¸°ë³¸ ìº”ë²„ìŠ¤ ë°˜í™˜
            return Image.new('RGB', (600, 400), (240, 240, 240))
    
    def _create_fit_analysis(
        self,
        person_pil: Image.Image,
        fitted_pil: Image.Image,
        metadata: Dict[str, Any]
    ) -> Image.Image:
        """í”¼íŒ… ë¶„ì„ ì´ë¯¸ì§€ ìƒì„±"""
        try:
            # í”¼íŒ… ë¶„ì„ ìº”ë²„ìŠ¤
            canvas_width = 500
            canvas_height = 350
            canvas = Image.new('RGB', (canvas_width, canvas_height), (245, 245, 245))
            draw = ImageDraw.Draw(canvas)
            
            try:
                title_font = ImageFont.truetype("arial.ttf", 18)
                header_font = ImageFont.truetype("arial.ttf", 15)
                text_font = ImageFont.truetype("arial.ttf", 13)
            except Exception:
                title_font = ImageFont.load_default()
                header_font = ImageFont.load_default()
                text_font = ImageFont.load_default()
            
            # ì œëª©
            draw.text((20, 20), "Fit Analysis Report", fill=(0, 0, 0), font=title_font)
            
            y_offset = 55
            
            # í”¼íŒ… íŒŒë¼ë¯¸í„°
            fitting_params = metadata.get('fitting_params', CLOTHING_FITTING_PARAMS['default'])
            fabric_props = metadata.get('fabric_properties', FABRIC_PROPERTIES['default'])
            
            draw.text((20, y_offset), "Fit Parameters:", fill=(0, 0, 0), font=header_font)
            y_offset += 25
            
            params = [
                f"â€¢ Fit Type: {fitting_params.fit_type.title()}",
                f"â€¢ Body Contact: {fitting_params.body_contact:.1f}",
                f"â€¢ Drape Level: {fitting_params.drape_level:.1f}",
                f"â€¢ Wrinkle Intensity: {fitting_params.wrinkle_intensity:.1f}"
            ]
            
            for param in params:
                draw.text((40, y_offset), param, fill=(60, 60, 60), font=text_font)
                y_offset += 18
            
            y_offset += 15
            
            # ì²œ ì†ì„±
            draw.text((20, y_offset), "Fabric Properties:", fill=(0, 0, 0), font=header_font)
            y_offset += 25
            
            fabric_info = [
                f"â€¢ Stiffness: {fabric_props.stiffness:.1f}",
                f"â€¢ Elasticity: {fabric_props.elasticity:.1f}",
                f"â€¢ Shine: {fabric_props.shine:.1f}",
                f"â€¢ Texture Scale: {fabric_props.texture_scale:.1f}"
            ]
            
            for info in fabric_info:
                draw.text((40, y_offset), info, fill=(60, 60, 60), font=text_font)
                y_offset += 18
            
            y_offset += 15
            
            # ì¶”ì²œì‚¬í•­
            draw.text((20, y_offset), "Recommendations:", fill=(0, 0, 0), font=header_font)
            y_offset += 25
            
            recommendations = self._generate_fit_recommendations(metadata)
            for rec in recommendations[:3]:  # ìµœëŒ€ 3ê°œ
                draw.text((40, y_offset), f"â€¢ {rec}", fill=(60, 60, 60), font=text_font)
                y_offset += 18
            
            return canvas
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ í”¼íŒ… ë¶„ì„ ìƒì„± ì‹¤íŒ¨: {e}")
            return Image.new('RGB', (500, 350), (240, 240, 240))
    
    def _generate_fit_recommendations(self, metadata: Dict[str, Any]) -> List[str]:
        """í”¼íŒ… ì¶”ì²œì‚¬í•­ ìƒì„±"""
        recommendations = []
        
        try:
            fabric_type = metadata.get('fabric_type', 'cotton')
            clothing_type = metadata.get('clothing_type', 'shirt')
            fitting_params = metadata.get('fitting_params', CLOTHING_FITTING_PARAMS['default'])
            
            # ì²œ ì¬ì§ˆë³„ ì¶”ì²œ
            if fabric_type == 'silk':
                recommendations.append("Silk drapes beautifully - consider flowing styles")
            elif fabric_type == 'denim':
                recommendations.append("Denim works best with structured fits")
            elif fabric_type == 'cotton':
                recommendations.append("Cotton is versatile for various fit styles")
            
            # í”¼íŒ… íƒ€ì…ë³„ ì¶”ì²œ
            if fitting_params.fit_type == 'fitted':
                recommendations.append("Fitted style enhances body shape")
            elif fitting_params.fit_type == 'flowing':
                recommendations.append("Flowing style provides comfort and elegance")
            
            # ë“œë ˆì´í”„ ë ˆë²¨ì— ë”°ë¥¸ ì¶”ì²œ
            if fitting_params.drape_level > 0.5:
                recommendations.append("High drape creates a graceful silhouette")
            else:
                recommendations.append("Low drape maintains structured appearance")
            
            # ê¸°ë³¸ ì¶”ì²œì‚¬í•­
            if not recommendations:
                recommendations = [
                    "Great choice for this style!",
                    "Try different poses for variety",
                    "Consider complementary accessories"
                ]
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ ì¶”ì²œì‚¬í•­ ìƒì„± ì‹¤íŒ¨: {e}")
            recommendations = ["Analysis complete - results look great!"]
        
        return recommendations
    
    def _pil_to_base64(self, pil_image: Image.Image) -> str:
        """PIL ì´ë¯¸ì§€ë¥¼ base64 ë¬¸ìì—´ë¡œ ë³€í™˜"""
        try:
            buffer = BytesIO()
            
            # í’ˆì§ˆ ì„¤ì •
            quality = 85
            if self.visualization_config['quality'] == "high":
                quality = 95
            elif self.visualization_config['quality'] == "low":
                quality = 70
            
            pil_image.save(buffer, format='JPEG', quality=quality, optimize=True)
            return base64.b64encode(buffer.getvalue()).decode('utf-8')
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ base64 ë³€í™˜ ì‹¤íŒ¨: {e}")
            return ""
    
    # =================================================================
    # ğŸ”¥ ê²°ê³¼ êµ¬ì„± ë° ìºì‹œ ê´€ë¦¬
    # =================================================================
    
    def _build_result_with_visualization(
        self,
        fitting_result: FittingResult,
        visualization_results: Dict[str, str],
        metadata: Dict[str, Any],
        processing_time: float,
        session_id: str
    ) -> Dict[str, Any]:
        """ì‹œê°í™”ê°€ í¬í•¨ëœ ìµœì¢… ê²°ê³¼ êµ¬ì„±"""
        
        # í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°
        quality_score = self._calculate_quality_score(fitting_result.fitted_image, metadata)
        
        # ì‹ ë¢°ë„ ê³„ì‚°
        confidence_score = fitting_result.confidence_score
        
        # í”¼íŒ… ì ìˆ˜ ê³„ì‚°
        fit_score = self._calculate_fit_score(metadata)
        
        result = {
            "success": fitting_result.success,
            "session_id": session_id,
            "step_name": self.step_name,
            "fitted_image": self._encode_image_base64(fitting_result.fitted_image) if fitting_result.fitted_image is not None else None,
            "fitted_image_raw": fitting_result.fitted_image,
            "confidence": confidence_score,
            "quality_score": quality_score,
            "fit_score": fit_score,
            "overall_score": (quality_score + confidence_score + fit_score) / 3,
            "processing_time": processing_time,
            
            # ì‹œê°í™” ë°ì´í„°
            "visualization": visualization_results if self.enable_visualization else None,
            
            # ë©”íƒ€ë°ì´í„°
            "metadata": {
                "fitting_method": self.fitting_method.value,
                "device": self.device,
                "model_used": 'primary' in self.loaded_models,
                "physics_enabled": self.fitting_config.physics_enabled,
                "cache_hit": False,
                "session_id": session_id,
                "fabric_type": metadata.get('fabric_type'),
                "clothing_type": metadata.get('clothing_type'),
                "quality_level": self.quality_level,
                **fitting_result.metadata
            },
            
            # ì„±ëŠ¥ ì •ë³´
            "performance_info": {
                "device": self.device,
                "memory_usage_mb": self._get_current_memory_usage(),
                "processing_method": self.fitting_method.value,
                "cache_used": False,
                "ai_models_used": [name for name, model in self.ai_models.items() if model is not None]
            },
            
            # ê°œì„  ì œì•ˆ
            "recommendations": self._generate_recommendations(metadata, quality_score),
            
            "error": fitting_result.error_message
        }
        
        return result
    
    def _calculate_quality_score(self, fitted_image: np.ndarray, metadata: Dict[str, Any]) -> float:
        """í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°"""
        try:
            if fitted_image is None:
                return 0.0
                
            scores = []
            
            # 1. ì´ë¯¸ì§€ ê¸°ë³¸ í’ˆì§ˆ
            if CV2_AVAILABLE:
                # ì„ ëª…ë„ (ë¼í”Œë¼ì‹œì•ˆ ë¶„ì‚°)
                gray = cv2.cvtColor(fitted_image, cv2.COLOR_RGB2GRAY)
                sharpness = cv2.Laplacian(gray, cv2.CV_64F).var()
                sharpness_score = min(1.0, sharpness / 1000.0)
                scores.append(sharpness_score)
                
                # ëŒ€ë¹„
                contrast = fitted_image.std()
                contrast_score = min(1.0, contrast / 50.0)
                scores.append(contrast_score)
            
            # 2. ìƒ‰ìƒ ë¶„í¬
            color_variance = np.var(fitted_image)
            color_score = min(1.0, color_variance / 5000.0)
            scores.append(color_score)
            
            # 3. ë…¸ì´ì¦ˆ ë ˆë²¨ (ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ)
            noise_level = np.std(fitted_image)
            noise_score = max(0.0, 1.0 - noise_level / 50.0)
            scores.append(noise_score)
            
            return float(np.mean(scores))
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ í’ˆì§ˆ ì ìˆ˜ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return 0.7  # ê¸°ë³¸ê°’
    
    def _calculate_fit_score(self, metadata: Dict[str, Any]) -> float:
        """í”¼íŒ… ì ìˆ˜ ê³„ì‚°"""
        try:
            scores = []
            
            # 1. ì²œ ì¬ì§ˆê³¼ ì˜ë¥˜ íƒ€ì… í˜¸í™˜ì„±
            fabric_type = metadata.get('fabric_type', 'cotton')
            clothing_type = metadata.get('clothing_type', 'shirt')
            
            compatibility_matrix = {
                ('cotton', 'shirt'): 0.9,
                ('cotton', 'dress'): 0.8,
                ('silk', 'dress'): 0.95,
                ('silk', 'blouse'): 0.9,
                ('denim', 'pants'): 0.95,
                ('leather', 'jacket'): 0.9
            }
            
            compatibility_score = compatibility_matrix.get(
                (fabric_type, clothing_type), 0.7
            )
            scores.append(compatibility_score)
            
            # 2. ë¬¼ë¦¬ ì‹œë®¬ë ˆì´ì…˜ í’ˆì§ˆ
            physics_score = 0.9 if self.fitting_config.physics_enabled else 0.6
            scores.append(physics_score)
            
            # 3. í•´ìƒë„ ì ìˆ˜
            max_res = self.performance_config['max_resolution']
            resolution_score = min(1.0, max_res / 512.0)
            scores.append(resolution_score)
            
            return float(np.mean(scores))
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ í”¼íŒ… ì ìˆ˜ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return 0.7
    
    def _generate_recommendations(
        self, 
        metadata: Dict[str, Any], 
        quality_score: float
    ) -> List[str]:
        """ê°œì„  ì œì•ˆ ìƒì„±"""
        recommendations = []
        
        try:
            # í’ˆì§ˆì´ ë‚®ì€ ê²½ìš°
            if quality_score < 0.6:
                recommendations.append("ë” ë†’ì€ í•´ìƒë„ì˜ ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í•´ë³´ì„¸ìš”")
                recommendations.append("ì¡°ëª…ì´ ì¢‹ì€ í™˜ê²½ì—ì„œ ì´¬ì˜ëœ ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í•´ë³´ì„¸ìš”")
            
            # AI ëª¨ë¸ ë¯¸ì‚¬ìš© ì‹œ
            if not self.enable_ai_models:
                recommendations.append("AI ëª¨ë¸ì„ í™œì„±í™”í•˜ë©´ ë” ì •í™•í•œ ê²°ê³¼ë¥¼ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤")
            
            # ë¬¼ë¦¬ ì—”ì§„ ë¯¸ì‚¬ìš© ì‹œ
            if not self.fitting_config.physics_enabled:
                recommendations.append("ë¬¼ë¦¬ ì‹œë®¬ë ˆì´ì…˜ì„ í™œì„±í™”í•˜ë©´ ë” ìì—°ìŠ¤ëŸ¬ìš´ í”¼íŒ…ì„ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤")
            
            # ì²œ ì¬ì§ˆë³„ ì œì•ˆ
            fabric_type = metadata.get('fabric_type')
            if fabric_type == 'silk':
                recommendations.append("ì‹¤í¬ ì†Œì¬ì˜ íŠ¹ì„±ìƒ ë“œë ˆì´í•‘ íš¨ê³¼ë¥¼ ë†’ì—¬ë³´ì„¸ìš”")
            elif fabric_type == 'denim':
                recommendations.append("ë°ë‹˜ì˜ ê²¬ê³ í•¨ì„ í‘œí˜„í•˜ê¸° ìœ„í•´ í…ìŠ¤ì²˜ë¥¼ ê°•í™”í•´ë³´ì„¸ìš”")
            
            # ê¸°ë³¸ ì œì•ˆ
            if not recommendations:
                recommendations = [
                    "í›Œë¥­í•œ ê°€ìƒ í”¼íŒ… ê²°ê³¼ì…ë‹ˆë‹¤!",
                    "ë‹¤ì–‘í•œ í¬ì¦ˆë¡œ ì‹œë„í•´ë³´ì„¸ìš”",
                    "ë‹¤ë¥¸ ìŠ¤íƒ€ì¼ì˜ ì˜ë¥˜ë„ ì²´í—˜í•´ë³´ì„¸ìš”"
                ]
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ ì œì•ˆ ìƒì„± ì‹¤íŒ¨: {e}")
            recommendations = ["ê°€ìƒ í”¼íŒ…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤"]
        
        return recommendations[:3]  # ìµœëŒ€ 3ê°œ ì œì•ˆ
    
    def _encode_image_base64(self, image: np.ndarray) -> str:
        """ì´ë¯¸ì§€ë¥¼ Base64ë¡œ ì¸ì½”ë”©"""
        try:
            if image is None:
                return ""
            
            # PIL ì´ë¯¸ì§€ë¡œ ë³€í™˜
            if len(image.shape) == 3:
                if CV2_AVAILABLE:
                    pil_image = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
                else:
                    pil_image = Image.fromarray(image)
            else:
                pil_image = Image.fromarray(image)
            
            # Base64 ì¸ì½”ë”©
            buffer = BytesIO()
            pil_image.save(buffer, format='PNG')
            image_base64 = base64.b64encode(buffer.getvalue()).decode('utf-8')
            
            return f"data:image/png;base64,{image_base64}"
            
        except Exception as e:
            self.logger.error(f"âŒ ì´ë¯¸ì§€ ì¸ì½”ë”© ì‹¤íŒ¨: {e}")
            return ""
    
    def _generate_cache_key(self, person_img: np.ndarray, cloth_img: np.ndarray, kwargs: Dict[str, Any]) -> str:
        """ìºì‹œ í‚¤ ìƒì„±"""
        try:
            import hashlib
            
            # ì´ë¯¸ì§€ í•´ì‹œ ìƒì„±
            person_hash = hashlib.md5(person_img.tobytes()).hexdigest()[:16]
            cloth_hash = hashlib.md5(cloth_img.tobytes()).hexdigest()[:16]
            
            # ì„¤ì • í•´ì‹œ
            config_str = json.dumps({
                'fabric_type': kwargs.get('fabric_type', 'cotton'),
                'clothing_type': kwargs.get('clothing_type', 'shirt'),
                'quality_level': self.quality_level,
                'fitting_method': self.fitting_method.value
            }, sort_keys=True)
            config_hash = hashlib.md5(config_str.encode()).hexdigest()[:8]
            
            return f"vf_{person_hash}_{cloth_hash}_{config_hash}"
            
        except Exception as e:
            self.logger.error(f"âŒ ìºì‹œ í‚¤ ìƒì„± ì‹¤íŒ¨: {e}")
            return f"vf_{time.time()}"
    
    def _get_cached_result(self, cache_key: str) -> Optional[Dict[str, Any]]:
        """ìºì‹œëœ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°"""
        try:
            with self.cache_lock:
                if cache_key in self.result_cache:
                    return self.result_cache[cache_key]
            return None
        except Exception as e:
            self.logger.error(f"âŒ ìºì‹œ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return None
    
    def _cache_result(self, cache_key: str, result: Dict[str, Any]) -> None:
        """ê²°ê³¼ ìºì‹±"""
        try:
            with self.cache_lock:
                # ìºì‹œ í¬ê¸° ì œí•œ (ìµœëŒ€ 10ê°œ ê²°ê³¼)
                if len(self.result_cache) >= 10:
                    # ê°€ì¥ ì˜¤ë˜ëœ í•­ëª© ì œê±°
                    oldest_key = next(iter(self.result_cache))
                    del self.result_cache[oldest_key]
                
                self.result_cache[cache_key] = result
                self.cache_stats['total_size'] = len(self.result_cache)
        except Exception as e:
            self.logger.error(f"âŒ ê²°ê³¼ ìºì‹± ì‹¤íŒ¨: {e}")
    
    def _update_processing_stats(self, result: Dict[str, Any]) -> None:
        """ì²˜ë¦¬ í†µê³„ ì—…ë°ì´íŠ¸"""
        try:
            stats_key = f"success_{result['success']}"
            if stats_key not in self.processing_stats:
                self.processing_stats[stats_key] = {'count': 0, 'total_time': 0.0}
            
            self.processing_stats[stats_key]['count'] += 1
            self.processing_stats[stats_key]['total_time'] += result['processing_time']
        except Exception as e:
            self.logger.error(f"âŒ í†µê³„ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
    
    def _get_current_memory_usage(self) -> float:
        """í˜„ì¬ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ (MB)"""
        try:
            if self.memory_manager:
                return self.memory_manager.get_memory_usage()
            
            # í´ë°±: psutil ì‚¬ìš©
            import psutil
            process = psutil.Process()
            return process.memory_info().rss / (1024 * 1024)
            
        except Exception:
            return 0.0
    
    def _create_fallback_result(
        self, 
        processing_time: float, 
        session_id: str, 
        error_msg: str
    ) -> Dict[str, Any]:
        """í´ë°± ê²°ê³¼ ìƒì„± (ì—ëŸ¬ ë°œìƒ ì‹œ)"""
        return {
            "success": False,
            "session_id": session_id,
            "step_name": self.step_name,
            "error_message": error_msg,
            "processing_time": processing_time,
            "fitted_image": None,
            "fitted_image_raw": None,
            "confidence": 0.0,
            "quality_score": 0.0,
            "fit_score": 0.0,
            "overall_score": 0.0,
            "visualization": None,
            "metadata": {
                "device": self.device,
                "error": error_msg,
                "session_id": session_id
            },
            "performance_info": {
                "device": self.device,
                "error": error_msg
            },
            "recommendations": ["ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ë³´ì„¸ìš”."]
        }
    
    # =================================================================
    # ğŸ”¥ ìœ í‹¸ë¦¬í‹° ë° ì •ë¦¬ ë©”ì„œë“œ
    # =================================================================
    
    def get_step_info(self) -> Dict[str, Any]:
        """Step ì •ë³´ ë°˜í™˜"""
        return {
            'step_name': self.step_name,
            'step_number': self.step_number,
            'device': self.device,
            'is_initialized': self.is_initialized,
            'is_m3_max': self.is_m3_max,
            'loaded_models': list(self.loaded_models.keys()),
            'fitting_method': str(self.fitting_method.value),
            'physics_enabled': self.fitting_config.physics_enabled,
            'cache_stats': self.cache_stats,
            'processing_stats': self.processing_stats,
            'session_id': self.session_id,
            'visualization_enabled': self.enable_visualization,
            'performance_config': self.performance_config,
            'ai_models_status': {
                name: self.model_provider.is_model_loaded(name) 
                for name in self.ai_models.keys()
            }
        }
    
    async def cleanup(self) -> None:
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        try:
            self.logger.info("ğŸ§¹ VirtualFittingStep ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì¤‘...")
            
            # Step Base ì •ë¦¬
            await self.step_base.cleanup()
            
            # ëª¨ë¸ ì •ë¦¬
            self.loaded_models.clear()
            self.ai_models = {k: None for k in self.ai_models.keys()}
            
            # ìºì‹œ ì •ë¦¬
            with self.cache_lock:
                self.result_cache.clear()
                self.cache_access_times.clear()
            
            # Executor ì¢…ë£Œ
            if self.executor:
                self.executor.shutdown(wait=False)
            
            if self.thread_pool:
                self.thread_pool.shutdown(wait=True)
            
            # ë©”ëª¨ë¦¬ ì •ë¦¬
            if TORCH_AVAILABLE:
                if hasattr(torch.backends.mps, 'empty_cache'):
                    torch.backends.mps.empty_cache()
            
            # ë©”ëª¨ë¦¬ ë§¤ë‹ˆì € ì •ë¦¬
            if self.memory_manager:
                await self.memory_manager.cleanup()
            
            gc.collect()
            
            self.logger.info("âœ… VirtualFittingStep ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì™„ë£Œ")
            
        except Exception as e:
            self.logger.error(f"âŒ ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì‹¤íŒ¨: {e}")
    
    def __del__(self):
        """ì†Œë©¸ì"""
        try:
            if hasattr(self, 'executor') and self.executor:
                self.executor.shutdown(wait=False)
            if hasattr(self, 'thread_pool') and self.thread_pool:
                self.thread_pool.shutdown(wait=False)
        except Exception:
            pass

# =================================================================
# ğŸ”¥ íŒ©í† ë¦¬ í´ë˜ìŠ¤ (ì˜ì¡´ì„± ì£¼ì… ë„ìš°ë¯¸)
# =================================================================

class VirtualFittingStepFactory:
    """
    VirtualFittingStep íŒ©í† ë¦¬ í´ë˜ìŠ¤
    ì˜ì¡´ì„± ì£¼ì…ì„ ì‰½ê²Œ í•´ì£¼ëŠ” ë„ìš°ë¯¸ í´ë˜ìŠ¤
    """
    
    @staticmethod
    def create_with_dependencies(
        device: str = "auto",
        config: Optional[Dict[str, Any]] = None,
        model_loader: Any = None,
        base_step_mixin: Any = None,
        memory_manager: IMemoryManager = None,
        data_converter: IDataConverter = None,
        **kwargs
    ) -> VirtualFittingStep:
        """
        ì˜ì¡´ì„±ì´ ì£¼ì…ëœ VirtualFittingStep ìƒì„±
        
        Args:
            device: ë””ë°”ì´ìŠ¤ ì„¤ì •
            config: ì„¤ì • ë”•ì…”ë„ˆë¦¬
            model_loader: ModelLoader ì¸ìŠ¤í„´ìŠ¤ (ì„ íƒì )
            base_step_mixin: BaseStepMixin ì¸ìŠ¤í„´ìŠ¤ (ì„ íƒì )
            memory_manager: ë©”ëª¨ë¦¬ ê´€ë¦¬ì (ì„ íƒì )
            data_converter: ë°ì´í„° ë³€í™˜ê¸° (ì„ íƒì )
            **kwargs: ì¶”ê°€ íŒŒë¼ë¯¸í„°
            
        Returns:
            VirtualFittingStep: ì„¤ì •ëœ ì¸ìŠ¤í„´ìŠ¤
        """
        # 1. Step ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
        step = VirtualFittingStep(device=device, config=config, **kwargs)
        
        # 2. ì˜ì¡´ì„± ì£¼ì…
        step.inject_dependencies(
            model_loader=model_loader,
            base_step_mixin=base_step_mixin,
            memory_manager=memory_manager,
            data_converter=data_converter
        )
        
        return step
    
    @staticmethod
    async def create_and_initialize(
        device: str = "auto",
        config: Optional[Dict[str, Any]] = None,
        **kwargs
    ) -> VirtualFittingStep:
        """
        VirtualFittingStep ìƒì„± ë° ì´ˆê¸°í™”
        
        Args:
            device: ë””ë°”ì´ìŠ¤ ì„¤ì •
            config: ì„¤ì • ë”•ì…”ë„ˆë¦¬
            **kwargs: ì¶”ê°€ íŒŒë¼ë¯¸í„°
            
        Returns:
            VirtualFittingStep: ì´ˆê¸°í™”ëœ ì¸ìŠ¤í„´ìŠ¤
        """
        step = VirtualFittingStep(device=device, config=config, **kwargs)
        
        # ì™¸ë¶€ ì˜ì¡´ì„± ê°€ì ¸ì˜¤ê¸° ì‹œë„
        try:
            # ModelLoader ê°€ì ¸ì˜¤ê¸° ì‹œë„
            from app.ai_pipeline.utils.model_loader import get_global_model_loader
            model_loader = get_global_model_loader()
            if model_loader:
                step.inject_dependencies(model_loader=model_loader)
        except ImportError:
            pass
        
        try:
            # BaseStepMixin ê°€ì ¸ì˜¤ê¸° ì‹œë„
            from app.ai_pipeline.steps.base_step_mixin import BaseStepMixin
            base_mixin = BaseStepMixin()
            step.inject_dependencies(base_step_mixin=base_mixin)
        except ImportError:
            pass
        
        # ì´ˆê¸°í™”
        await step.initialize()
        
        return step

# =================================================================
# ğŸ”¥ í¸ì˜ í•¨ìˆ˜ë“¤ ë° ìœ í‹¸ë¦¬í‹° (ì˜ì¡´ì„± ì—†ëŠ”)
# =================================================================

def create_virtual_fitting_step(
    device: str = "auto", 
    config: Optional[Dict[str, Any]] = None,
    **kwargs
) -> VirtualFittingStep:
    """ê°€ìƒ í”¼íŒ… ë‹¨ê³„ ìƒì„± (ê¸°ì¡´ ë°©ì‹ í˜¸í™˜)"""
    return VirtualFittingStep(device=device, config=config, **kwargs)

def create_m3_max_virtual_fitting_step(
    memory_gb: float = 128.0,
    quality_level: str = "ultra",
    enable_visualization: bool = True,
    **kwargs
) -> VirtualFittingStep:
    """M3 Max ìµœì í™” ê°€ìƒ í”¼íŒ… ë‹¨ê³„ ìƒì„±"""
    return VirtualFittingStep(
        device=None,  # ìë™ ê°ì§€
        memory_gb=memory_gb,
        quality_level=quality_level,
        is_m3_max=True,
        optimization_enabled=True,
        enable_visualization=enable_visualization,
        **kwargs
    )

async def quick_virtual_fitting_with_visualization(
    person_image: Union[np.ndarray, Image.Image, str],
    clothing_image: Union[np.ndarray, Image.Image, str],
    fabric_type: str = "cotton",
    clothing_type: str = "shirt",
    enable_visualization: bool = True,
    **kwargs
) -> Dict[str, Any]:
    """ë¹ ë¥¸ ê°€ìƒ í”¼íŒ… + ì‹œê°í™” (ì¼íšŒì„± ì‚¬ìš©)"""
    
    step = await VirtualFittingStepFactory.create_and_initialize(
        enable_visualization=enable_visualization
    )
    try:
        result = await step.process(
            person_image, clothing_image,
            fabric_type=fabric_type,
            clothing_type=clothing_type,
            **kwargs
        )
        return result
    finally:
        await step.cleanup()

async def batch_virtual_fitting(
    image_pairs: List[Tuple[Union[np.ndarray, Image.Image, str], Union[np.ndarray, Image.Image, str]]],
    fabric_types: Optional[List[str]] = None,
    clothing_types: Optional[List[str]] = None,
    **kwargs
) -> List[Dict[str, Any]]:
    """ë°°ì¹˜ ê°€ìƒ í”¼íŒ… ì²˜ë¦¬"""
    
    step = await VirtualFittingStepFactory.create_and_initialize(**kwargs)
    try:
        results = []
        
        for i, (person_img, cloth_img) in enumerate(image_pairs):
            fabric_type = fabric_types[i] if fabric_types and i < len(fabric_types) else "cotton"
            clothing_type = clothing_types[i] if clothing_types and i < len(clothing_types) else "shirt"
            
            result = await step.process(
                person_img, cloth_img,
                fabric_type=fabric_type,
                clothing_type=clothing_type
            )
            results.append(result)
        
        return results
    finally:
        await step.cleanup()

def get_supported_fabric_types() -> List[str]:
    """ì§€ì›ë˜ëŠ” ì²œ ì¬ì§ˆ íƒ€ì… ëª©ë¡ ë°˜í™˜"""
    return list(FABRIC_PROPERTIES.keys())

def get_supported_clothing_types() -> List[str]:
    """ì§€ì›ë˜ëŠ” ì˜ë¥˜ íƒ€ì… ëª©ë¡ ë°˜í™˜"""
    return list(CLOTHING_FITTING_PARAMS.keys())

def get_fitting_methods() -> List[str]:
    """ì§€ì›ë˜ëŠ” í”¼íŒ… ë°©ë²• ëª©ë¡ ë°˜í™˜"""
    return [method.value for method in FittingMethod]

def get_quality_levels() -> List[str]:
    """ì§€ì›ë˜ëŠ” í’ˆì§ˆ ë ˆë²¨ ëª©ë¡ ë°˜í™˜"""
    return [quality.value for quality in FittingQuality]

def analyze_fabric_compatibility(fabric_type: str, clothing_type: str) -> Dict[str, Any]:
    """ì²œ ì¬ì§ˆê³¼ ì˜ë¥˜ íƒ€ì… í˜¸í™˜ì„± ë¶„ì„"""
    fabric_props = FABRIC_PROPERTIES.get(fabric_type, FABRIC_PROPERTIES['default'])
    fitting_params = CLOTHING_FITTING_PARAMS.get(clothing_type, CLOTHING_FITTING_PARAMS['default'])
    
    # í˜¸í™˜ì„± ì ìˆ˜ ê³„ì‚°
    compatibility_matrix = {
        ('cotton', 'shirt'): 0.9,
        ('cotton', 'dress'): 0.8,
        ('silk', 'dress'): 0.95,
        ('silk', 'blouse'): 0.9,
        ('denim', 'pants'): 0.95,
        ('leather', 'jacket'): 0.9,
        ('wool', 'sweater'): 0.9,
        ('spandex', 'shirt'): 0.8,
        ('linen', 'shirt'): 0.85
    }
    
    compatibility_score = compatibility_matrix.get((fabric_type, clothing_type), 0.7)
    
    return {
        'fabric_type': fabric_type,
        'clothing_type': clothing_type,
        'compatibility_score': compatibility_score,
        'fabric_properties': fabric_props,
        'fitting_parameters': fitting_params,
        'recommendations': _generate_compatibility_recommendations(fabric_type, clothing_type, compatibility_score)
    }

def _generate_compatibility_recommendations(fabric_type: str, clothing_type: str, score: float) -> List[str]:
    """í˜¸í™˜ì„± ê¸°ë°˜ ì¶”ì²œì‚¬í•­ ìƒì„±"""
    recommendations = []
    
    if score >= 0.9:
        recommendations.append(f"Excellent match! {fabric_type.title()} works perfectly for {clothing_type}")
    elif score >= 0.8:
        recommendations.append(f"Good combination of {fabric_type} and {clothing_type}")
    elif score >= 0.7:
        recommendations.append(f"Decent pairing, but consider alternatives")
    else:
        recommendations.append(f"Consider different fabric for better results")
    
    # ì²œ ì¬ì§ˆë³„ ì¶”ê°€ ê¶Œì¥ì‚¬í•­
    if fabric_type == 'silk':
        recommendations.append("Silk requires gentle handling and drapes beautifully")
    elif fabric_type == 'denim':
        recommendations.append("Denim provides structure and durability")
    elif fabric_type == 'cotton':
        recommendations.append("Cotton is versatile and comfortable")
    
    return recommendations

# =================================================================
# ğŸ”¥ ê³ ê¸‰ ì‹œê°í™” ìœ í‹¸ë¦¬í‹° (ì˜ì¡´ì„± ì—†ëŠ”)
# =================================================================

class VirtualFittingVisualizer:
    """ê°€ìƒ í”¼íŒ… ì „ìš© ì‹œê°í™” ë„êµ¬"""
    
    def __init__(self, config: Optional[Dict[str, Any]] = None):
        self.config = config or {}
        self.colors = VISUALIZATION_COLORS
    
    def create_before_after_comparison(
        self, 
        before_image: np.ndarray, 
        after_image: np.ndarray,
        title: str = "Virtual Fitting Comparison"
    ) -> Image.Image:
        """ì „í›„ ë¹„êµ ì´ë¯¸ì§€ ìƒì„±"""
        try:
            # PIL ë³€í™˜
            before_pil = Image.fromarray(before_image)
            after_pil = Image.fromarray(after_image)
            
            # í¬ê¸° í†µì¼
            width, height = before_pil.size
            after_resized = after_pil.resize((width, height), Image.Resampling.LANCZOS)
            
            # ìº”ë²„ìŠ¤ ìƒì„±
            canvas_width = width * 2 + 60
            canvas_height = height + 80
            canvas = Image.new('RGB', (canvas_width, canvas_height), (245, 245, 245))
            
            # ì´ë¯¸ì§€ ë°°ì¹˜
            canvas.paste(before_pil, (20, 40))
            canvas.paste(after_resized, (width + 40, 40))
            
            # í…ìŠ¤íŠ¸ ì¶”ê°€
            draw = ImageDraw.Draw(canvas)
            try:
                title_font = ImageFont.truetype("arial.ttf", 20)
                label_font = ImageFont.truetype("arial.ttf", 16)
            except Exception:
                title_font = ImageFont.load_default()
                label_font = ImageFont.load_default()
            
            # ì œëª©
            draw.text((canvas_width//2 - 100, 10), title, fill=(0, 0, 0), font=title_font)
            
            # ë¼ë²¨
            draw.text((20 + width//2 - 25, height + 50), "Before", fill=(0, 0, 0), font=label_font)
            draw.text((width + 40 + width//2 - 20, height + 50), "After", fill=(0, 0, 0), font=label_font)
            
            return canvas
            
        except Exception as e:
            logging.error(f"âŒ ì „í›„ ë¹„êµ ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨: {e}")
            return Image.new('RGB', (800, 600), (240, 240, 240))
    
    def create_fabric_analysis_chart(
        self,
        fabric_properties: FabricProperties,
        fabric_type: str
    ) -> Image.Image:
        """ì²œ ì¬ì§ˆ ë¶„ì„ ì°¨íŠ¸ ìƒì„±"""
        try:
            # ìº”ë²„ìŠ¤ ìƒì„±
            canvas_width = 400
            canvas_height = 300
            canvas = Image.new('RGB', (canvas_width, canvas_height), (250, 250, 250))
            draw = ImageDraw.Draw(canvas)
            
            try:
                title_font = ImageFont.truetype("arial.ttf", 18)
                text_font = ImageFont.truetype("arial.ttf", 14)
            except Exception:
                title_font = ImageFont.load_default()
                text_font = ImageFont.load_default()
            
            # ì œëª©
            draw.text((20, 20), f"Fabric Analysis: {fabric_type.title()}", fill=(0, 0, 0), font=title_font)
            
            # ì†ì„± ë°” ì°¨íŠ¸
            y_start = 60
            bar_width = 200
            bar_height = 20
            
            properties = [
                ("Stiffness", fabric_properties.stiffness),
                ("Elasticity", fabric_properties.elasticity),
                ("Density", fabric_properties.density / 3.0),  # ì •ê·œí™”
                ("Friction", fabric_properties.friction),
                ("Shine", fabric_properties.shine),
                ("Texture Scale", fabric_properties.texture_scale)
            ]
            
            for i, (prop_name, value) in enumerate(properties):
                y_pos = y_start + i * 35
                
                # ë¼ë²¨
                draw.text((20, y_pos), prop_name, fill=(0, 0, 0), font=text_font)
                
                # ë°°ê²½ ë°”
                draw.rectangle([150, y_pos, 150 + bar_width, y_pos + bar_height], 
                            fill=(200, 200, 200), outline=(150, 150, 150))
                
                # ê°’ ë°”
                value_width = int(bar_width * min(value, 1.0))
                color = self._get_property_color(prop_name, value)
                draw.rectangle([150, y_pos, 150 + value_width, y_pos + bar_height], 
                            fill=color, outline=color)
                
                # ê°’ í…ìŠ¤íŠ¸
                draw.text((360, y_pos + 3), f"{value:.2f}", fill=(0, 0, 0), font=text_font)
            
            return canvas
            
        except Exception as e:
            logging.error(f"âŒ ì²œ ì¬ì§ˆ ë¶„ì„ ì°¨íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}")
            return Image.new('RGB', (400, 300), (240, 240, 240))
    
    def _get_property_color(self, prop_name: str, value: float) -> Tuple[int, int, int]:
        """ì†ì„±ë³„ ìƒ‰ìƒ ë°˜í™˜"""
        color_map = {
            'Stiffness': (255, 100, 100),    # ë¹¨ê°•
            'Elasticity': (100, 255, 100),   # ì´ˆë¡
            'Density': (100, 100, 255),      # íŒŒë‘
            'Friction': (255, 255, 100),     # ë…¸ë‘
            'Shine': (255, 150, 255),        # ë§ˆì  íƒ€
            'Texture Scale': (150, 255, 255) # ì‹œì•ˆ
        }
        return color_map.get(prop_name, (150, 150, 150))

# =================================================================
# ğŸ”¥ ì„±ëŠ¥ ë¶„ì„ ë„êµ¬ (ì˜ì¡´ì„± ì—†ëŠ”)
# =================================================================

class VirtualFittingProfiler:
    """ê°€ìƒ í”¼íŒ… ì„±ëŠ¥ ë¶„ì„ ë„êµ¬"""
    
    def __init__(self):
        self.metrics = {}
        self.start_times = {}
    
    def start_timing(self, operation: str) -> None:
        """íƒ€ì´ë° ì‹œì‘"""
        self.start_times[operation] = time.time()
    
    def end_timing(self, operation: str) -> float:
        """íƒ€ì´ë° ì¢…ë£Œ"""
        if operation in self.start_times:
            duration = time.time() - self.start_times[operation]
            if operation not in self.metrics:
                self.metrics[operation] = []
            self.metrics[operation].append(duration)
            del self.start_times[operation]
            return duration
        return 0.0
    
    def get_average_time(self, operation: str) -> float:
        """í‰ê·  ì‹œê°„ ë°˜í™˜"""
        if operation in self.metrics:
            return np.mean(self.metrics[operation])
        return 0.0
    
    def get_performance_report(self) -> Dict[str, Dict[str, float]]:
        """ì„±ëŠ¥ ë¦¬í¬íŠ¸ ìƒì„±"""
        report = {}
        for operation, times in self.metrics.items():
            report[operation] = {
                'average_time': np.mean(times),
                'min_time': np.min(times),
                'max_time': np.max(times),
                'total_calls': len(times),
                'total_time': np.sum(times)
            }
        return report

# =================================================================
# ğŸ”¥ ëª¨ë“ˆ ìµìŠ¤í¬íŠ¸
# =================================================================

__all__ = [
    # ë©”ì¸ í´ë˜ìŠ¤
    'VirtualFittingStep',
    'VirtualFittingStepFactory',
    
    # ì¸í„°í˜ì´ìŠ¤
    'IModelProvider',
    'IStepBase',
    'IMemoryManager',
    'IDataConverter',
    
    # ì–´ëŒ‘í„°
    'ModelProviderAdapter',
    'StepBaseAdapter',
    
    # ë°ì´í„° í´ë˜ìŠ¤
    'VirtualFittingConfig',
    'FittingResult',
    'FabricProperties',
    'FittingParams',
    
    # ì—´ê±°í˜•
    'FittingMethod',
    'FittingQuality',
    
    # ìƒìˆ˜
    'FABRIC_PROPERTIES',
    'CLOTHING_FITTING_PARAMS',
    'VISUALIZATION_COLORS',
    
    # í¸ì˜ í•¨ìˆ˜ë“¤
    'create_virtual_fitting_step',
    'create_m3_max_virtual_fitting_step',
    'quick_virtual_fitting_with_visualization',
    'batch_virtual_fitting',
    
    # ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
    'get_supported_fabric_types',
    'get_supported_clothing_types',
    'get_fitting_methods',
    'get_quality_levels',
    'analyze_fabric_compatibility',
    
    # ê³ ê¸‰ ë„êµ¬ë“¤
    'VirtualFittingVisualizer',
    'VirtualFittingProfiler'
]

# =================================================================
# ğŸ”¥ ëª¨ë“ˆ ì •ë³´
# =================================================================

__version__ = "6.0.0-dependency-inversion"
__author__ = "MyCloset AI Team"
__description__ = "Virtual Fitting Step with Dependency Inversion and Clean Architecture"

# ë¡œê±° ì„¤ì •
logger = logging.getLogger(__name__)
logger.info("âœ… VirtualFittingStep ëª¨ë“ˆ ì™„ì „ ë¡œë“œ ì™„ë£Œ (ë‹¨ë°©í–¥ ì˜ì¡´ì„±)")
logger.info("ğŸ”— ì˜ì¡´ì„± ì—­ì „ íŒ¨í„´ ì ìš©")
logger.info("ğŸ”— ì¸í„°í˜ì´ìŠ¤ ë ˆì´ì–´ë¥¼ í†µí•œ ëª¨ë“ˆ ë¶„ë¦¬")
logger.info("ğŸ M3 Max 128GB ìµœì í™” ì§€ì›")
logger.info("ğŸ¨ ê³ ê¸‰ ì‹œê°í™” ê¸°ëŠ¥ ì™„ì „ í†µí•©")
logger.info("âš™ï¸ ë¬¼ë¦¬ ê¸°ë°˜ ì‹œë®¬ë ˆì´ì…˜ ì™„ì „ ì§€ì›")
logger.info("ğŸ“Š ì„±ëŠ¥ ë¶„ì„ ë„êµ¬ í¬í•¨")

# =================================================================
# ğŸ”¥ ì˜ì¡´ì„± ì£¼ì… ì˜ˆì œ ë° í…ŒìŠ¤íŠ¸ ì½”ë“œ
# =================================================================

if __name__ == "__main__":
    async def test_dependency_injection():
        """ì˜ì¡´ì„± ì£¼ì… í…ŒìŠ¤íŠ¸"""
        print("ğŸ”„ ì˜ì¡´ì„± ì£¼ì… í…ŒìŠ¤íŠ¸ ì‹œì‘...")
        
        # 1. ì˜ì¡´ì„± ì—†ì´ ìƒì„±
        step = VirtualFittingStep(quality_level="balanced", enable_visualization=True)
        print(f"âœ… Step ìƒì„± ì™„ë£Œ: {step.step_name}")
        
        # 2. íŒ©í† ë¦¬ë¥¼ í†µí•œ ìƒì„± ë° ì´ˆê¸°í™”
        step_with_deps = await VirtualFittingStepFactory.create_and_initialize(
            quality_level="high",
            enable_visualization=True
        )
        print(f"âœ… íŒ©í† ë¦¬ë¥¼ í†µí•œ ìƒì„± ì™„ë£Œ: {step_with_deps.step_name}")
        
        # 3. ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸
        test_person = np.random.randint(0, 255, (512, 512, 3), dtype=np.uint8)
        test_clothing = np.random.randint(0, 255, (512, 512, 3), dtype=np.uint8)
        
        print("ğŸ­ ê°€ìƒ í”¼íŒ… í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì¤‘...")
        result = await step_with_deps.process(
            test_person, test_clothing,
            fabric_type="cotton",
            clothing_type="shirt"
        )
        
        print(f"âœ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
        print(f"   ì„±ê³µ: {result['success']}")
        print(f"   ì²˜ë¦¬ ì‹œê°„: {result['processing_time']:.2f}ì´ˆ")
        print(f"   ì‹ ë¢°ë„: {result['confidence']:.2f}")
        print(f"   ì‹œê°í™”: {result['visualization'] is not None}")
        
        # 4. ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ í…ŒìŠ¤íŠ¸
        print("\nğŸ“Š ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ í…ŒìŠ¤íŠ¸:")
        print(f"   ì§€ì› ì²œ ì¬ì§ˆ: {len(get_supported_fabric_types())}ê°œ")
        print(f"   ì§€ì› ì˜ë¥˜ íƒ€ì…: {len(get_supported_clothing_types())}ê°œ")
        print(f"   í”¼íŒ… ë°©ë²•: {len(get_fitting_methods())}ê°œ")
        
        compatibility = analyze_fabric_compatibility("silk", "dress")
        print(f"   ì²œ ì¬ì§ˆ í˜¸í™˜ì„± (silk + dress): {compatibility['compatibility_score']:.2f}")
        
        # 5. ì‹œê°í™” ë„êµ¬ í…ŒìŠ¤íŠ¸
        visualizer = VirtualFittingVisualizer()
        fabric_props = FABRIC_PROPERTIES['silk']
        chart = visualizer.create_fabric_analysis_chart(fabric_props, 'silk')
        print(f"   ì‹œê°í™” ì°¨íŠ¸ ìƒì„±: {chart.size}")
        
        # 6. ì„±ëŠ¥ ë¶„ì„ ë„êµ¬ í…ŒìŠ¤íŠ¸
        profiler = VirtualFittingProfiler()
        profiler.start_timing("test_operation")
        await asyncio.sleep(0.1)
        duration = profiler.end_timing("test_operation")
        print(f"   ì„±ëŠ¥ ì¸¡ì •: {duration:.3f}ì´ˆ")
        
        # ì •ë¦¬
        await step.cleanup()
        await step_with_deps.cleanup()
        
        print("\nğŸ‰ ëª¨ë“  ì˜ì¡´ì„± ì£¼ì… í…ŒìŠ¤íŠ¸ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œ!")
        print("ğŸ“‹ êµ¬ì¡° ê°œì„  ì™„ë£Œ:")
        print("   âœ… ë‹¨ë°©í–¥ ì˜ì¡´ì„± êµ¬ì¡°")
        print("   âœ… ì¸í„°í˜ì´ìŠ¤ ë ˆì´ì–´ ë¶„ë¦¬")
        print("   âœ… ì˜ì¡´ì„± ì—­ì „ íŒ¨í„´")
        print("   âœ… ëª¨ë“  ê¸°ëŠ¥ 100% ìœ ì§€")
        print("   âœ… M3 Max ìµœì í™”")
        print("   âœ… ì™„ì „í•œ ì‹œê°í™” ì‹œìŠ¤í…œ")
    
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    import asyncio
    asyncio.run(test_dependency_injection())