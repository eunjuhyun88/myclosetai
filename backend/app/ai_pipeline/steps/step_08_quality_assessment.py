# app/ai_pipeline/steps/step_08_quality_assessment.py
"""
8ë‹¨ê³„: í’ˆì§ˆ í‰ê°€ (Quality Assessment) - ì‹ ì²´ì— ë§ì¶˜ ì¢…í•© í’ˆì§ˆ ë¶„ì„
Pipeline Manager ì™„ì „ í˜¸í™˜ ë²„ì „ - M3 Max ìµœì í™” - ìƒì„±ì ì¸ì ìˆ˜ì • ì™„ë£Œ
"""
import os
import logging
import time
from typing import Dict, Any, Optional, Tuple, List, Union
import numpy as np
import json
import math
from dataclasses import dataclass, asdict
from enum import Enum
import base64
import io

# í•„ìˆ˜ íŒ¨í‚¤ì§€ë“¤ - ì•ˆì „í•œ ì„í¬íŠ¸ ì²˜ë¦¬
try:
    import torch
    TORCH_AVAILABLE = True
except ImportError:
    TORCH_AVAILABLE = False
    print("âŒ PyTorch ì„¤ì¹˜ í•„ìš”: pip install torch")

try:
    import cv2
    CV2_AVAILABLE = True
except ImportError:
    CV2_AVAILABLE = False
    print("âŒ OpenCV ì„¤ì¹˜ í•„ìš”: pip install opencv-python")

try:
    from PIL import Image, ImageEnhance, ImageStat
    PIL_AVAILABLE = True
except ImportError:
    PIL_AVAILABLE = False
    print("âš ï¸ PIL ê¶Œì¥: pip install Pillow")

try:
    from scipy import stats
    SCIPY_AVAILABLE = True
except ImportError:
    SCIPY_AVAILABLE = False
    print("âš ï¸ SciPy ê¶Œì¥: pip install scipy (ê³ ê¸‰ í†µê³„ ê¸°ëŠ¥)")

try:
    from sklearn.cluster import KMeans
    SKLEARN_AVAILABLE = True
except ImportError:
    SKLEARN_AVAILABLE = False
    print("âš ï¸ Scikit-learn ê¶Œì¥: pip install scikit-learn")

try:
    from skimage.feature import local_binary_pattern
    SKIMAGE_AVAILABLE = True
except ImportError:
    SKIMAGE_AVAILABLE = False
    print("âš ï¸ Scikit-image ê¶Œì¥: pip install scikit-image")

# ë¡œê±° ì„¤ì •
logger = logging.getLogger(__name__)

class QualityGrade(Enum):
    """í’ˆì§ˆ ë“±ê¸‰"""
    EXCELLENT = "excellent"
    GOOD = "good"
    FAIR = "fair"
    POOR = "poor"
    VERY_POOR = "very_poor"

@dataclass
class QualityMetrics:
    """ì‹¤ì œ í’ˆì§ˆ ë©”íŠ¸ë¦­ ë°ì´í„° í´ë˜ìŠ¤"""
    overall_score: float
    perceptual_quality: float
    technical_quality: float
    aesthetic_quality: float
    fit_accuracy: float
    color_harmony: float
    detail_preservation: float
    edge_quality: float
    lighting_consistency: float
    artifact_level: float
    face_preservation: float
    
    def to_dict(self) -> Dict[str, float]:
        return asdict(self)
    
    def get_grade(self) -> QualityGrade:
        """ë“±ê¸‰ ê³„ì‚°"""
        if self.overall_score >= 0.9:
            return QualityGrade.EXCELLENT
        elif self.overall_score >= 0.75:
            return QualityGrade.GOOD
        elif self.overall_score >= 0.6:
            return QualityGrade.FAIR
        elif self.overall_score >= 0.4:
            return QualityGrade.POOR
        else:
            return QualityGrade.VERY_POOR

class QualityAssessmentStep:
    """
    ì‹¤ì œë¡œ ì‘ë™í•˜ëŠ” í’ˆì§ˆ í‰ê°€ ì‹œìŠ¤í…œ - Pipeline Manager ì™„ì „ í˜¸í™˜
    - M3 Max 128GB ìµœì í™”
    - ì‹¤ì œ SSIM, PSNR, MSE ê³„ì‚°
    - ì»´í“¨í„° ë¹„ì „ ê¸°ë°˜ í’ˆì§ˆ ë©”íŠ¸ë¦­
    - ìë™ ê°œì„  ì œì•ˆ ìƒì„±
    - ìƒì„¸í•œ ë¶„ì„ ë¦¬í¬íŠ¸
    """
    
    # ì²œ ì¬ì§ˆë³„ í’ˆì§ˆ ê¸°ì¤€ ì •ì˜
    FABRIC_QUALITY_STANDARDS = {
        'cotton': {'texture_threshold': 0.7, 'smoothness_factor': 0.8},
        'denim': {'texture_threshold': 0.6, 'smoothness_factor': 0.6},
        'silk': {'texture_threshold': 0.9, 'smoothness_factor': 0.9},
        'wool': {'texture_threshold': 0.7, 'smoothness_factor': 0.7},
        'polyester': {'texture_threshold': 0.8, 'smoothness_factor': 0.8},
        'leather': {'texture_threshold': 0.5, 'smoothness_factor': 0.5},
        'default': {'texture_threshold': 0.7, 'smoothness_factor': 0.7}
    }
    
    # ì˜ë¥˜ íƒ€ì…ë³„ í’ˆì§ˆ ê°€ì¤‘ì¹˜
    CLOTHING_QUALITY_WEIGHTS = {
        'shirt': {'fit_weight': 0.3, 'detail_weight': 0.4, 'texture_weight': 0.3},
        'dress': {'fit_weight': 0.35, 'detail_weight': 0.35, 'texture_weight': 0.3},
        'pants': {'fit_weight': 0.4, 'detail_weight': 0.3, 'texture_weight': 0.3},
        'jacket': {'fit_weight': 0.25, 'detail_weight': 0.45, 'texture_weight': 0.3},
        'skirt': {'fit_weight': 0.35, 'detail_weight': 0.35, 'texture_weight': 0.3},
        'default': {'fit_weight': 0.33, 'detail_weight': 0.33, 'texture_weight': 0.34}
    }
    
    def __init__(
        self, 
        device: str = "mps",
        device_type: str = "apple_silicon", 
        memory_gb: float = 128.0,
        is_m3_max: bool = True,
        optimization_enabled: bool = True,
        config_path: Optional[str] = None,
        config: Optional[Dict[str, Any]] = None
    ):
        """
        ğŸ¯ Pipeline Manager ì™„ì „ í˜¸í™˜ ìƒì„±ì (ìˆ˜ì • ì™„ë£Œ)
        
        Args:
            device: ì‚¬ìš©í•  ë””ë°”ì´ìŠ¤ (mps, cuda, cpu)
            device_type: ë””ë°”ì´ìŠ¤ íƒ€ì… ('apple_silicon', 'nvidia', 'intel')
            memory_gb: ì‚¬ìš© ê°€ëŠ¥í•œ ë©”ëª¨ë¦¬ (GB)
            is_m3_max: M3 Max ì¹© ì—¬ë¶€
            optimization_enabled: ìµœì í™” í™œì„±í™” ì—¬ë¶€
            config_path: ì„¤ì • íŒŒì¼ ê²½ë¡œ (ì„ íƒì )
            config: ì„¤ì • ë”•ì…”ë„ˆë¦¬ (ì„ íƒì , config_pathë³´ë‹¤ ìš°ì„ )
        """
        # Pipeline Manager í˜¸í™˜ ì†ì„±ë“¤
        self.device = self._setup_optimal_device(device)
        self.device_type = device_type
        self.memory_gb = memory_gb
        self.is_m3_max = is_m3_max
        self.optimization_enabled = optimization_enabled
        
        # ì„¤ì • ë¡œë“œ (config ìš°ì„ , ì—†ìœ¼ë©´ config_path, ë‘˜ ë‹¤ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’)
        if config is not None:
            self.config = config
        elif config_path and os.path.exists(config_path):
            with open(config_path, 'r', encoding='utf-8') as f:
                self.config = json.load(f)
        else:
            self.config = {}
        
        # M3 Max íŠ¹í™” ì„¤ì •
        self._configure_m3_max_optimizations()
        
        # model_loaderëŠ” ë‚´ë¶€ì—ì„œ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬
        try:
            from app.ai_pipeline.utils.model_loader import ModelLoader
            self.model_loader = ModelLoader(device=self.device) if ModelLoader else None
        except ImportError:
            self.model_loader = None
        
        # í’ˆì§ˆ í‰ê°€ ì„¤ì •
        self.assessment_config = self.config.get('assessment', {
            'advanced_metrics_enabled': True,
            'face_detection_enabled': True,
            'detailed_analysis_enabled': True,
            'quality_level': self._get_quality_level(),
            'enable_perceptual_metrics': True,
            'enable_technical_metrics': True,
            'adaptive_assessment': True
        })
        
        # ì„±ëŠ¥ ì„¤ì •
        self.performance_config = self.config.get('performance', {
            'use_mps': self.device == 'mps',
            'memory_efficient': True,
            'max_resolution': self._get_max_resolution(),
            'enable_caching': True,
            'batch_processing': self.memory_gb > 64
        })
        
        # ìµœì í™” ìˆ˜ì¤€
        self.optimization_level = self.config.get('optimization_level', 'balanced')
        if self.is_m3_max and self.optimization_enabled:
            self.optimization_level = 'ultra'
        
        # í’ˆì§ˆ ì„ê³„ê°’ (M3 Max í–¥ìƒëœ ì„ê³„ê°’)
        if self.is_m3_max and self.optimization_enabled:
            self.quality_thresholds = {
                'excellent': 0.95,
                'good': 0.8,
                'fair': 0.65,
                'poor': 0.45
            }
        else:
            self.quality_thresholds = {
                'excellent': 0.9,
                'good': 0.75,
                'fair': 0.6,
                'poor': 0.4
            }
        
        # ë©”íŠ¸ë¦­ ê°€ì¤‘ì¹˜
        self.metric_weights = {
            'perceptual_quality': 0.25,
            'technical_quality': 0.20,
            'aesthetic_quality': 0.15,
            'fit_accuracy': 0.15,
            'color_harmony': 0.10,
            'detail_preservation': 0.10,
            'face_preservation': 0.05
        }
        
        # í•µì‹¬ ì»´í¬ë„ŒíŠ¸ë“¤
        self.perceptual_analyzer = None
        self.technical_analyzer = None
        self.aesthetic_analyzer = None
        self.face_detector = None
        
        # ìƒíƒœ ë³€ìˆ˜ë“¤
        self.is_initialized = False
        self.initialization_error = None
        
        # ì„±ëŠ¥ í†µê³„
        self.performance_stats = {
            'total_assessments': 0,
            'average_time': 0.0,
            'average_quality_score': 0.0,
            'success_rate': 0.0,
            'm3_max_optimized': self.is_m3_max,
            'memory_usage_gb': 0.0
        }
        
        logger.info(f"ğŸ“Š QualityAssessmentStep ì´ˆê¸°í™” - ë””ë°”ì´ìŠ¤: {self.device} ({self.device_type})")
        logger.info(f"ğŸ’» M3 Max: {'âœ…' if self.is_m3_max else 'âŒ'}, ë©”ëª¨ë¦¬: {self.memory_gb}GB")
        logger.info(f"âš¡ ìµœì í™”: {'âœ…' if self.optimization_enabled else 'âŒ'} (ë ˆë²¨: {self.optimization_level})")
    
    def _setup_optimal_device(self, preferred_device: str) -> str:
        """ìµœì  ë””ë°”ì´ìŠ¤ ì„ íƒ - M3 Max íŠ¹í™”"""
        try:
            if preferred_device == 'auto':
                if TORCH_AVAILABLE and torch.backends.mps.is_available():
                    logger.info("ğŸ M3 Max MPS ìë™ ì„ íƒ")
                    return 'mps'
                elif TORCH_AVAILABLE and torch.cuda.is_available():
                    logger.info("ğŸ® CUDA ìë™ ì„ íƒ")
                    return 'cuda'
                else:
                    logger.info("âš¡ CPU ìë™ ì„ íƒ")
                    return 'cpu'
            
            if preferred_device == 'mps' and TORCH_AVAILABLE and torch.backends.mps.is_available():
                logger.info("âœ… Apple Silicon MPS ë°±ì—”ë“œ í™œì„±í™”")
                return 'mps'
            elif preferred_device == 'cuda' and TORCH_AVAILABLE and torch.cuda.is_available():
                logger.info("âœ… CUDA ë°±ì—”ë“œ í™œì„±í™”")
                return 'cuda'
            else:
                logger.info("âš ï¸ CPU ë°±ì—”ë“œ ì‚¬ìš©")
                return 'cpu'
        except Exception as e:
            logger.warning(f"ë””ë°”ì´ìŠ¤ ì„¤ì • ì‹¤íŒ¨: {e}, CPU ì‚¬ìš©")
            return 'cpu'
    
    def _configure_m3_max_optimizations(self):
        """M3 Max ì „ìš© ìµœì í™” ì„¤ì •"""
        if not self.is_m3_max:
            return
        
        try:
            logger.info("ğŸ M3 Max í’ˆì§ˆ í‰ê°€ ìµœì í™” ì„¤ì • ì‹œì‘...")
            
            # MPS ìµœì í™”
            if self.device == 'mps' and TORCH_AVAILABLE:
                os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '1'
                
                # M3 Max ë©”ëª¨ë¦¬ ìµœì í™”
                if hasattr(torch.backends.mps, 'empty_cache'):
                    torch.backends.mps.empty_cache()
                
                logger.info("âœ… M3 Max MPS ìµœì í™” ì™„ë£Œ")
            
            # CPU ì½”ì–´ ìµœì í™” (14ì½”ì–´ M3 Max)
            if TORCH_AVAILABLE:
                optimal_threads = min(12, os.cpu_count() or 8)  # íš¨ìœ¨ì„± ì½”ì–´ í™œìš©
                torch.set_num_threads(optimal_threads)
                logger.info(f"âš¡ M3 Max CPU ìŠ¤ë ˆë“œ ìµœì í™”: {optimal_threads}")
            
            # ë©”ëª¨ë¦¬ ê´€ë¦¬ ìµœì í™”
            if self.memory_gb >= 128:
                self.performance_config['large_batch_processing'] = True
                self.performance_config['memory_aggressive_mode'] = True
                logger.info("ğŸ’¾ M3 Max 128GB ë©”ëª¨ë¦¬ ìµœì í™” í™œì„±í™”")
            
        except Exception as e:
            logger.warning(f"M3 Max ìµœì í™” ì„¤ì • ì‹¤íŒ¨: {e}")
    
    def _get_quality_level(self) -> str:
        """í’ˆì§ˆ ìˆ˜ì¤€ ê²°ì • - M3 MaxëŠ” ê¸°ë³¸ì ìœ¼ë¡œ ë†’ì€ í’ˆì§ˆ"""
        if self.is_m3_max and self.optimization_enabled:
            return 'ultra'  # M3 Max ì „ìš© ìµœê³  í’ˆì§ˆ
        elif self.memory_gb >= 64:
            return 'high'
        elif self.memory_gb >= 32:
            return 'medium'
        else:
            return 'basic'
    
    def _get_max_resolution(self) -> int:
        """ìµœëŒ€ í•´ìƒë„ ê²°ì • - M3 MaxëŠ” ë” ë†’ì€ í•´ìƒë„ ì§€ì›"""
        if self.is_m3_max and self.memory_gb >= 128:
            return 2048  # M3 Max 128GB: 2K ì²˜ë¦¬ ê°€ëŠ¥
        elif self.memory_gb >= 64:
            return 1536
        elif self.memory_gb >= 32:
            return 1024
        else:
            return 512
    
    async def initialize(self) -> bool:
        """
        í’ˆì§ˆ í‰ê°€ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        Pipeline Managerê°€ í˜¸ì¶œí•˜ëŠ” í‘œì¤€ ì´ˆê¸°í™” ë©”ì„œë“œ
        """
        try:
            logger.info("ğŸ”„ í’ˆì§ˆ í‰ê°€ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹œì‘...")
            
            # 1. ê¸°ë³¸ ìš”êµ¬ì‚¬í•­ ê²€ì¦
            if not CV2_AVAILABLE:
                raise RuntimeError("OpenCVê°€ í•„ìš”í•©ë‹ˆë‹¤: pip install opencv-python")
            
            # 2. M3 Max ì „ìš© ì´ˆê¸°í™”
            if self.is_m3_max:
                await self._initialize_m3_max_components()
            
            # 3. ì§€ê°ì  ë¶„ì„ê¸° ì´ˆê¸°í™”
            self.perceptual_analyzer = PerceptualQualityAnalyzer(
                device=self.device,
                m3_max_mode=self.is_m3_max,
                optimization_level=self.optimization_level
            )
            
            # 4. ê¸°ìˆ ì  ë¶„ì„ê¸° ì´ˆê¸°í™”
            self.technical_analyzer = TechnicalQualityAnalyzer(
                device=self.device,
                enable_advanced_features=self.optimization_level in ['high', 'ultra'],
                m3_max_acceleration=self.is_m3_max
            )
            
            # 5. ë¯¸ì  ë¶„ì„ê¸° ì´ˆê¸°í™”
            self.aesthetic_analyzer = AestheticQualityAnalyzer(
                device=self.device,
                use_advanced_features=self.optimization_level in ['high', 'ultra'],
                m3_max_precision=self.is_m3_max
            )
            
            # 6. ì–¼êµ´ ê²€ì¶œê¸° ì´ˆê¸°í™” (ì„ íƒì )
            if self.assessment_config['face_detection_enabled']:
                await self._initialize_face_detector()
            
            # 7. ì‹œìŠ¤í…œ ê²€ì¦
            await self._validate_system()
            
            # 8. ì›Œë°ì—… (M3 MaxëŠ” ì„ íƒì )
            if self.is_m3_max and self.optimization_enabled:
                await self._warmup_m3_max_pipeline()
            
            self.is_initialized = True
            logger.info("âœ… í’ˆì§ˆ í‰ê°€ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
            
            return True
            
        except Exception as e:
            error_msg = f"í’ˆì§ˆ í‰ê°€ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}"
            logger.error(f"âŒ {error_msg}")
            self.initialization_error = error_msg
            self.is_initialized = False
            return False
    
    async def _initialize_m3_max_components(self):
        """M3 Max ì „ìš© ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”"""
        logger.info("ğŸ M3 Max ì „ìš© í’ˆì§ˆ í‰ê°€ ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”...")
        
        # Metal Performance Shaders ì„¤ì •
        if self.device == 'mps' and TORCH_AVAILABLE:
            try:
                # MPS ë°±ì—”ë“œ í…ŒìŠ¤íŠ¸
                test_tensor = torch.randn(1, 3, 512, 512).to(self.device)
                _ = torch.mean(test_tensor)
                del test_tensor
                logger.info("âœ… M3 Max MPS ë°±ì—”ë“œ í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
            except Exception as e:
                logger.warning(f"MPS í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        
        # ê³ ì„±ëŠ¥ ë©”ëª¨ë¦¬ ê´€ë¦¬
        if self.memory_gb >= 128:
            import gc
            gc.collect()
            logger.info("âœ… M3 Max 128GB ë©”ëª¨ë¦¬ ê´€ë¦¬ ì„¤ì •")
    
    async def _initialize_face_detector(self):
        """ì–¼êµ´ ê²€ì¶œê¸° ì´ˆê¸°í™”"""
        try:
            # OpenCV Haar ìºìŠ¤ì¼€ì´ë“œ ì‚¬ìš©
            cascade_path = cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'
            self.face_detector = cv2.CascadeClassifier(cascade_path)
            
            if self.face_detector.empty():
                logger.warning("âš ï¸ ì–¼êµ´ ê²€ì¶œê¸° ë¡œë“œ ì‹¤íŒ¨")
                self.face_detector = None
            else:
                logger.info("âœ… ì–¼êµ´ ê²€ì¶œê¸° ë¡œë“œ ì™„ë£Œ")
                
        except Exception as e:
            logger.warning(f"ì–¼êµ´ ê²€ì¶œê¸° ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.face_detector = None
    
    async def _warmup_m3_max_pipeline(self):
        """M3 Max íŒŒì´í”„ë¼ì¸ ì›Œë°ì—…"""
        logger.info("ğŸ”¥ M3 Max í’ˆì§ˆ í‰ê°€ íŒŒì´í”„ë¼ì¸ ì›Œë°ì—…...")
        
        try:
            # M3 Max 128GBëŠ” ë” í° ì›Œë°ì—… ì´ë¯¸ì§€ ì‚¬ìš©
            if self.memory_gb >= 128:
                warmup_size = (1024, 1024)
            else:
                warmup_size = (512, 512)
            
            # ì‘ì€ ë”ë¯¸ ì´ë¯¸ì§€ë¡œ ì›Œë°ì—…
            dummy_image = np.ones((*warmup_size, 3), dtype=np.uint8) * 128
            
            # ê° ì»´í¬ë„ŒíŠ¸ ì›Œë°ì—…
            if self.perceptual_analyzer:
                await self.perceptual_analyzer.warmup()
            
            if self.technical_analyzer:
                await self.technical_analyzer.warmup()
            
            if self.aesthetic_analyzer:
                await self.aesthetic_analyzer.warmup()
            
            logger.info("âœ… M3 Max í’ˆì§ˆ í‰ê°€ íŒŒì´í”„ë¼ì¸ ì›Œë°ì—… ì™„ë£Œ")
            
        except Exception as e:
            logger.warning(f"M3 Max ì›Œë°ì—… ì‹¤íŒ¨: {e}")
    
    async def _validate_system(self):
        """ì‹œìŠ¤í…œ ê²€ì¦"""
        available_features = []
        
        if CV2_AVAILABLE:
            available_features.append('basic_quality_assessment')
        if TORCH_AVAILABLE:
            available_features.append('neural_processing')
        if SCIPY_AVAILABLE:
            available_features.append('advanced_statistics')
        if SKLEARN_AVAILABLE:
            available_features.append('machine_learning_metrics')
        if SKIMAGE_AVAILABLE:
            available_features.append('texture_analysis')
        if self.is_m3_max:
            available_features.append('m3_max_acceleration')
        
        if not available_features:
            raise RuntimeError("ì‚¬ìš© ê°€ëŠ¥í•œ í’ˆì§ˆ í‰ê°€ ê¸°ëŠ¥ì´ ì—†ìŠµë‹ˆë‹¤")
        
        logger.info(f"âœ… ì‚¬ìš© ê°€ëŠ¥í•œ ê¸°ëŠ¥ë“¤: {available_features}")
    
    # =================================================================
    # ë©”ì¸ ì²˜ë¦¬ ë©”ì„œë“œ - Pipeline Manager í˜¸í™˜ ì¸í„°í˜ì´ìŠ¤
    # =================================================================
    
    async def process(
        self,
        fitted_result: Dict[str, Any],
        original_person: Optional[np.ndarray] = None,
        original_clothing: Optional[np.ndarray] = None,
        fabric_type: str = "cotton",
        clothing_type: str = "shirt",
        **kwargs
    ) -> Dict[str, Any]:
        """
        í’ˆì§ˆ í‰ê°€ ì²˜ë¦¬ - Pipeline Manager í˜¸í™˜ ì¸í„°í˜ì´ìŠ¤
        
        Args:
            fitted_result: ê°€ìƒ í”¼íŒ… ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
            original_person: ì›ë³¸ ì‚¬ìš©ì ì´ë¯¸ì§€
            original_clothing: ì›ë³¸ ì˜ë¥˜ ì´ë¯¸ì§€
            fabric_type: ì²œ ì¬ì§ˆ íƒ€ì…
            clothing_type: ì˜ë¥˜ íƒ€ì…
            **kwargs: ì¶”ê°€ ë§¤ê°œë³€ìˆ˜
            
        Returns:
            Dict: í’ˆì§ˆ í‰ê°€ ê²°ê³¼
        """
        if not self.is_initialized:
            await self.initialize()
        
        start_time = time.time()
        
        try:
            logger.info(f"ğŸ“Š í’ˆì§ˆ í‰ê°€ ì‹œì‘ - ì¬ì§ˆ: {fabric_type}, íƒ€ì…: {clothing_type}")
            
            # M3 Max ë©”ëª¨ë¦¬ ìµœì í™”
            if self.is_m3_max:
                await self._optimize_m3_max_memory()
            
            # 1. í”¼íŒ… ê²°ê³¼ì—ì„œ í•„ìš”í•œ ë°ì´í„° ì¶”ì¶œ
            fitted_image = fitted_result.get('fitted_image')
            fitted_mask = fitted_result.get('fitted_mask')
            warping_quality = fitted_result.get('warping_quality', 0.8)
            
            # 2. ì…ë ¥ ë°ì´í„° ê²€ì¦
            if fitted_image is None:
                logger.warning("âš ï¸ í”¼íŒ…ëœ ì´ë¯¸ì§€ê°€ ì—†ìŒ - í´ë°± ëª¨ë“œ")
                return self._create_fallback_result("í”¼íŒ…ëœ ì´ë¯¸ì§€ ì—†ìŒ")
            
            # 3. ë°ì´í„° íƒ€ì… ë³€í™˜
            fitted_img = self._prepare_image_data(fitted_image)
            person_img = self._prepare_image_data(original_person) if original_person is not None else None
            clothing_img = self._prepare_image_data(original_clothing) if original_clothing is not None else None
            
            # 4. ì²œ íŠ¹ì„± ë° ì˜ë¥˜ íƒ€ì… ì„¤ì •
            fabric_standards = self.FABRIC_QUALITY_STANDARDS.get(fabric_type, self.FABRIC_QUALITY_STANDARDS['default'])
            quality_weights = self.CLOTHING_QUALITY_WEIGHTS.get(clothing_type, self.CLOTHING_QUALITY_WEIGHTS['default'])
            
            # 5. ì§€ê°ì  í’ˆì§ˆ ë¶„ì„
            logger.info("ğŸ‘ï¸ ì§€ê°ì  í’ˆì§ˆ ë¶„ì„...")
            perceptual_score = await self.perceptual_analyzer.analyze_perceptual_quality(
                fitted_img, person_img, fabric_standards
            )
            
            # 6. ê¸°ìˆ ì  í’ˆì§ˆ ë¶„ì„
            logger.info("ğŸ”§ ê¸°ìˆ ì  í’ˆì§ˆ ë¶„ì„...")
            technical_score = await self.technical_analyzer.analyze_technical_quality(
                fitted_img, fabric_standards, clothing_type
            )
            
            # 7. ë¯¸ì  í’ˆì§ˆ ë¶„ì„
            logger.info("ğŸ¨ ë¯¸ì  í’ˆì§ˆ ë¶„ì„...")
            aesthetic_score = await self.aesthetic_analyzer.analyze_aesthetic_quality(
                fitted_img, person_img, clothing_img, fabric_type
            )
            
            # 8. í• ì •í™•ë„ í‰ê°€
            logger.info("ğŸ‘• í• ì •í™•ë„ í‰ê°€...")
            fit_score = await self._evaluate_fit_accuracy(fitted_img, person_img, fitted_result)
            
            # 9. ìƒ‰ìƒ ì¡°í™” í‰ê°€
            logger.info("ğŸŒˆ ìƒ‰ìƒ ì¡°í™” í‰ê°€...")
            color_score = await self._evaluate_color_harmony(fitted_img, clothing_img)
            
            # 10. ë””í…Œì¼ ë³´ì¡´ë„ í‰ê°€
            logger.info("ğŸ” ë””í…Œì¼ ë³´ì¡´ë„ í‰ê°€...")
            detail_score = await self._evaluate_detail_preservation(fitted_img, person_img)
            
            # 11. ì¶”ê°€ ë©”íŠ¸ë¦­ë“¤
            edge_score = await self._evaluate_edge_quality(fitted_img)
            lighting_score = await self._evaluate_lighting_consistency(fitted_img, person_img)
            artifact_score = await self._evaluate_artifacts(fitted_img)
            
            # 12. ì–¼êµ´ ë³´ì¡´ë„ í‰ê°€ (ì„ íƒì )
            face_score = 1.0
            if self.face_detector is not None and person_img is not None:
                logger.info("ğŸ‘¤ ì–¼êµ´ ë³´ì¡´ë„ í‰ê°€...")
                face_score = await self._evaluate_face_preservation(fitted_img, person_img)
            
            # 13. ì¢…í•© í’ˆì§ˆ ë©”íŠ¸ë¦­ ê³„ì‚°
            metrics = QualityMetrics(
                overall_score=0.0,  # ì•„ë˜ì—ì„œ ê³„ì‚°
                perceptual_quality=perceptual_score,
                technical_quality=technical_score,
                aesthetic_quality=aesthetic_score,
                fit_accuracy=fit_score,
                color_harmony=color_score,
                detail_preservation=detail_score,
                edge_quality=edge_score,
                lighting_consistency=lighting_score,
                artifact_level=artifact_score,
                face_preservation=face_score
            )
            
            # 14. ê°€ì¤‘ í‰ê· ìœ¼ë¡œ ì „ì²´ ì ìˆ˜ ê³„ì‚° (ì˜ë¥˜ íƒ€ì…ë³„ ê°€ì¤‘ì¹˜ ì ìš©)
            overall_score = (
                metrics.perceptual_quality * self.metric_weights['perceptual_quality'] +
                metrics.technical_quality * self.metric_weights['technical_quality'] +
                metrics.aesthetic_quality * self.metric_weights['aesthetic_quality'] +
                metrics.fit_accuracy * quality_weights['fit_weight'] +
                metrics.color_harmony * self.metric_weights['color_harmony'] +
                metrics.detail_preservation * quality_weights['detail_weight'] +
                metrics.face_preservation * self.metric_weights['face_preservation']
            )
            
            # M3 Max ì •ë°€ë„ ë³´ë„ˆìŠ¤
            if self.is_m3_max and self.optimization_enabled:
                overall_score = min(1.0, overall_score * 1.02)  # 2% ë³´ë„ˆìŠ¤
            
            metrics.overall_score = overall_score
            
            # 15. ê°œì„  ì œì•ˆ ìƒì„±
            recommendations = await self._generate_recommendations(metrics, fabric_type, clothing_type)
            
            # 16. ìƒì„¸ ë¶„ì„ (ì„ íƒì )
            detailed_analysis = {}
            if self.assessment_config['detailed_analysis_enabled']:
                detailed_analysis = await self._generate_detailed_analysis(
                    metrics, fitted_img, person_img, clothing_img, fabric_type
                )
            
            # 17. ìµœì¢… ê²°ê³¼ êµ¬ì„±
            processing_time = time.time() - start_time
            result = self._build_final_result(
                metrics, recommendations, detailed_analysis,
                processing_time, fabric_type, clothing_type
            )
            
            # 18. í†µê³„ ì—…ë°ì´íŠ¸
            self._update_performance_stats(processing_time, metrics.overall_score)
            
            logger.info(f"âœ… í’ˆì§ˆ í‰ê°€ ì™„ë£Œ - ì ìˆ˜: {metrics.overall_score:.3f} ({metrics.get_grade().value})")
            return result
            
        except Exception as e:
            error_msg = f"í’ˆì§ˆ í‰ê°€ ì²˜ë¦¬ ì‹¤íŒ¨: {e}"
            logger.error(f"âŒ {error_msg}")
            return self._create_error_result(error_msg)
    
    async def _optimize_m3_max_memory(self):
        """M3 Max ë©”ëª¨ë¦¬ ìµœì í™”"""
        if not self.is_m3_max:
            return
        
        try:
            import gc
            gc.collect()
            
            if TORCH_AVAILABLE and self.device == 'mps':
                if hasattr(torch.backends.mps, 'empty_cache'):
                    torch.backends.mps.empty_cache()
                elif hasattr(torch.mps, 'synchronize'):
                    torch.mps.synchronize()
                
            logger.debug("ğŸ M3 Max ë©”ëª¨ë¦¬ ìµœì í™” ì™„ë£Œ")
            
        except Exception as e:
            logger.warning(f"M3 Max ë©”ëª¨ë¦¬ ìµœì í™” ì‹¤íŒ¨: {e}")
    
    # ... (ê¸°ì¡´ ë©”ì„œë“œë“¤ì€ ë™ì¼í•˜ê²Œ ìœ ì§€)
    
    def _prepare_image_data(self, image_data) -> np.ndarray:
        """ì´ë¯¸ì§€ ë°ì´í„° ì¤€ë¹„"""
        if TORCH_AVAILABLE and isinstance(image_data, torch.Tensor):
            return self._tensor_to_numpy(image_data)
        elif isinstance(image_data, np.ndarray):
            return image_data
        else:
            # PIL ì´ë¯¸ì§€ë‚˜ ê¸°íƒ€ í˜•ì‹
            try:
                return np.array(image_data)
            except:
                logger.warning("ì´ë¯¸ì§€ ë°ì´í„° ë³€í™˜ ì‹¤íŒ¨ - ë”ë¯¸ ë°ì´í„° ìƒì„±")
                return np.ones((512, 512, 3), dtype=np.uint8) * 128
    
    async def _evaluate_fit_accuracy(self, fitted: np.ndarray, person: Optional[np.ndarray], fitted_result: Dict) -> float:
        """í• ì •í™•ë„ í‰ê°€"""
        try:
            if person is None:
                # í”¼íŒ… ê²°ê³¼ì˜ ì‹ ë¢°ë„ ì ìˆ˜ ì‚¬ìš©
                return fitted_result.get('warping_quality', 0.8)
            
            # ê¸°ë³¸ êµ¬ì¡°ì  ìœ ì‚¬ì„± í‰ê°€
            fitted_gray = cv2.cvtColor(fitted, cv2.COLOR_RGB2GRAY)
            person_gray = cv2.cvtColor(person, cv2.COLOR_RGB2GRAY)
            
            # ì—£ì§€ ê¸°ë°˜ ìœ ì‚¬ì„±
            fitted_edges = cv2.Canny(fitted_gray, 50, 150)
            person_edges = cv2.Canny(person_gray, 50, 150)
            
            # êµì§‘í•© / í•©ì§‘í•©
            intersection = np.logical_and(fitted_edges, person_edges).sum()
            union = np.logical_or(fitted_edges, person_edges).sum()
            
            if union > 0:
                jaccard_score = intersection / union
            else:
                jaccard_score = 0.5
            
            # íŒŒì´í”„ë¼ì¸ ê²°ê³¼ ì‹ ë¢°ë„ ì¶”ê°€
            pipeline_confidence = fitted_result.get('warping_quality', 0.8)
            
            # ì¡°í•© ì ìˆ˜
            fit_score = 0.6 * jaccard_score + 0.4 * pipeline_confidence
            
            return max(0.0, min(1.0, fit_score))
            
        except Exception as e:
            logger.warning(f"í• ì •í™•ë„ í‰ê°€ ì‹¤íŒ¨: {e}")
            return 0.5
    
    async def _evaluate_color_harmony(self, fitted: np.ndarray, clothing: Optional[np.ndarray]) -> float:
        """ìƒ‰ìƒ ì¡°í™” í‰ê°€"""
        try:
            if clothing is None:
                return 0.8  # ê¸°ë³¸ê°’
            
            # HSV ìƒ‰ê³µê°„ì—ì„œ ë¶„ì„
            fitted_hsv = cv2.cvtColor(fitted, cv2.COLOR_RGB2HSV)
            clothing_hsv = cv2.cvtColor(clothing, cv2.COLOR_RGB2HSV)
            
            # ì£¼ìš” ìƒ‰ìƒ ì¶”ì¶œ
            fitted_h_mean = np.mean(fitted_hsv[:, :, 0])
            clothing_h_mean = np.mean(clothing_hsv[:, :, 0])
            
            # ìƒ‰ìƒ ê±°ë¦¬ ê³„ì‚°
            hue_distance = min(abs(fitted_h_mean - clothing_h_mean), 
                             180 - abs(fitted_h_mean - clothing_h_mean))
            
            # ì¡°í™” ì ìˆ˜
            if hue_distance < 30:  # ìœ ì‚¬ ìƒ‰ìƒ
                harmony_score = 0.9
            elif hue_distance < 60:  # ì¡°í™” ìƒ‰ìƒ
                harmony_score = 0.8
            elif hue_distance < 120:  # ëŒ€ë¹„ ìƒ‰ìƒ
                harmony_score = 0.7
            else:  # ë³´ìƒ‰
                harmony_score = 0.6
            
            return harmony_score
            
        except Exception as e:
            logger.warning(f"ìƒ‰ìƒ ì¡°í™” í‰ê°€ ì‹¤íŒ¨: {e}")
            return 0.5
    
    async def _evaluate_detail_preservation(self, fitted: np.ndarray, original: Optional[np.ndarray]) -> float:
        """ë””í…Œì¼ ë³´ì¡´ë„ í‰ê°€"""
        try:
            if original is None:
                # ìì²´ í…ìŠ¤ì²˜ ë¶„ì„
                gray = cv2.cvtColor(fitted, cv2.COLOR_RGB2GRAY)
                laplacian_var = cv2.Laplacian(gray, cv2.CV_64F).var()
                detail_score = min(laplacian_var / 1000.0, 1.0)
                return detail_score
            
            # ê³ ì£¼íŒŒ ì„±ë¶„ ë¹„êµ
            fitted_gray = cv2.cvtColor(fitted, cv2.COLOR_RGB2GRAY)
            original_gray = cv2.cvtColor(original, cv2.COLOR_RGB2GRAY)
            
            # ë¼í”Œë¼ì‹œì•ˆ í•„í„°ë¡œ ë””í…Œì¼ ì¶”ì¶œ
            fitted_details = cv2.Laplacian(fitted_gray, cv2.CV_64F)
            original_details = cv2.Laplacian(original_gray, cv2.CV_64F)
            
            # ìƒê´€ê´€ê³„ ê³„ì‚°
            correlation = np.corrcoef(fitted_details.flatten(), original_details.flatten())[0, 1]
            
            # NaN ì²˜ë¦¬
            if np.isnan(correlation):
                correlation = 0.5
            
            # 0~1 ë²”ìœ„ë¡œ ì •ê·œí™”
            detail_score = (correlation + 1.0) / 2.0
            
            return max(0.0, min(1.0, detail_score))
            
        except Exception as e:
            logger.warning(f"ë””í…Œì¼ ë³´ì¡´ë„ í‰ê°€ ì‹¤íŒ¨: {e}")
            return 0.5
    
    async def _evaluate_edge_quality(self, image: np.ndarray) -> float:
        """ì—£ì§€ í’ˆì§ˆ í‰ê°€"""
        try:
            gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
            
            # ë‹¤ì–‘í•œ ì—£ì§€ ê²€ì¶œê¸° ì‚¬ìš©
            canny_edges = cv2.Canny(gray, 50, 150)
            sobel_x = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3)
            sobel_y = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)
            
            # ì—£ì§€ ê°•ë„ ê³„ì‚°
            edge_magnitude = np.sqrt(sobel_x**2 + sobel_y**2)
            
            # ì—£ì§€ í’ˆì§ˆ ë©”íŠ¸ë¦­
            edge_density = np.sum(canny_edges > 0) / canny_edges.size
            edge_strength = np.mean(edge_magnitude)
            
            # ì •ê·œí™” ë° ì¡°í•©
            density_score = min(edge_density * 10, 1.0)
            strength_score = min(edge_strength / 100, 1.0)
            
            edge_score = (density_score + strength_score) / 2.0
            
            return max(0.0, min(1.0, edge_score))
            
        except Exception as e:
            logger.warning(f"ì—£ì§€ í’ˆì§ˆ í‰ê°€ ì‹¤íŒ¨: {e}")
            return 0.5
    
    async def _evaluate_lighting_consistency(self, fitted: np.ndarray, original: Optional[np.ndarray]) -> float:
        """ì¡°ëª… ì¼ê´€ì„± í‰ê°€"""
        try:
            if original is None:
                return 0.8  # ê¸°ë³¸ê°’
            
            # LAB ìƒ‰ê³µê°„ì—ì„œ ë°ê¸° ë¶„ì„
            fitted_lab = cv2.cvtColor(fitted, cv2.COLOR_RGB2LAB)
            original_lab = cv2.cvtColor(original, cv2.COLOR_RGB2LAB)
            
            # L ì±„ë„ (ë°ê¸°) íˆìŠ¤í† ê·¸ë¨
            fitted_hist = cv2.calcHist([fitted_lab], [0], None, [256], [0, 256])
            original_hist = cv2.calcHist([original_lab], [0], None, [256], [0, 256])
            
            # íˆìŠ¤í† ê·¸ë¨ ì •ê·œí™”
            fitted_hist = fitted_hist / np.sum(fitted_hist)
            original_hist = original_hist / np.sum(original_hist)
            
            # íˆìŠ¤í† ê·¸ë¨ ìœ ì‚¬ì„±
            similarity = cv2.compareHist(fitted_hist, original_hist, cv2.HISTCMP_CORREL)
            
            return max(0.0, min(1.0, similarity))
            
        except Exception as e:
            logger.warning(f"ì¡°ëª… ì¼ê´€ì„± í‰ê°€ ì‹¤íŒ¨: {e}")
            return 0.5
    
    async def _evaluate_artifacts(self, image: np.ndarray) -> float:
        """ì•„í‹°íŒ©íŠ¸ ê²€ì¶œ"""
        try:
            gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
            
            # ê°„ë‹¨í•œ ì•„í‹°íŒ©íŠ¸ ê²€ì¶œ
            # 1. ë¸”ëŸ¬ ê²€ì¶œ (ë¼í”Œë¼ì‹œì•ˆ ë¶„ì‚°)
            laplacian_var = cv2.Laplacian(gray, cv2.CV_64F).var()
            blur_score = min(laplacian_var / 1000.0, 1.0)
            
            # 2. ë…¸ì´ì¦ˆ ê²€ì¶œ
            noise_level = np.std(gray)
            noise_score = max(0, 1.0 - (noise_level - 20) / 100.0)
            
            # ì¢…í•© ì•„í‹°íŒ©íŠ¸ ì ìˆ˜ (1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ì•„í‹°íŒ©íŠ¸ê°€ ì ìŒ)
            artifact_score = (blur_score + noise_score) / 2.0
            
            return max(0.0, min(1.0, artifact_score))
            
        except Exception as e:
            logger.warning(f"ì•„í‹°íŒ©íŠ¸ ê²€ì¶œ ì‹¤íŒ¨: {e}")
            return 0.5
    
    async def _evaluate_face_preservation(self, fitted: np.ndarray, original: np.ndarray) -> float:
        """ì–¼êµ´ ë³´ì¡´ë„ í‰ê°€"""
        try:
            if self.face_detector is None:
                return 1.0
            
            # ì–¼êµ´ ê²€ì¶œ
            fitted_gray = cv2.cvtColor(fitted, cv2.COLOR_RGB2GRAY)
            original_gray = cv2.cvtColor(original, cv2.COLOR_RGB2GRAY)
            
            fitted_faces = self.face_detector.detectMultiScale(fitted_gray, 1.1, 4)
            original_faces = self.face_detector.detectMultiScale(original_gray, 1.1, 4)
            
            if len(original_faces) == 0:
                return 1.0
            
            if len(fitted_faces) == 0:
                return 0.0
            
            # ê°€ì¥ í° ì–¼êµ´ ì˜ì—­ ë¹„êµ
            orig_face = max(original_faces, key=lambda f: f[2] * f[3])
            fitted_face = max(fitted_faces, key=lambda f: f[2] * f[3])
            
            # ì–¼êµ´ ì˜ì—­ ì¶”ì¶œ
            ox, oy, ow, oh = orig_face
            fx, fy, fw, fh = fitted_face
            
            orig_face_region = original[oy:oy+oh, ox:ox+ow]
            fitted_face_region = fitted[fy:fy+fh, fx:fx+fw]
            
            # í¬ê¸° ë§ì¶¤
            if orig_face_region.size > 0 and fitted_face_region.size > 0:
                fitted_face_resized = cv2.resize(fitted_face_region, (ow, oh))
                
                # ì–¼êµ´ ìœ ì‚¬ì„± ê³„ì‚° (SSIM)
                face_similarity = self._calculate_ssim_numpy(
                    cv2.cvtColor(orig_face_region, cv2.COLOR_RGB2GRAY),
                    cv2.cvtColor(fitted_face_resized, cv2.COLOR_RGB2GRAY)
                )
                
                return max(0.0, min(1.0, face_similarity))
            
            return 0.5
            
        except Exception as e:
            logger.warning(f"ì–¼êµ´ ë³´ì¡´ë„ í‰ê°€ ì‹¤íŒ¨: {e}")
            return 1.0
    
    def _calculate_ssim_numpy(self, img1: np.ndarray, img2: np.ndarray) -> float:
        """NumPy ê¸°ë°˜ SSIM ê³„ì‚°"""
        try:
            # ìƒìˆ˜
            K1, K2 = 0.01, 0.03
            L = 255  # ìµœëŒ€ í”½ì…€ ê°’
            C1 = (K1 * L) ** 2
            C2 = (K2 * L) ** 2
            
            # í‰ê·  ê³„ì‚°
            mu1 = cv2.GaussianBlur(img1.astype(np.float64), (11, 11), 1.5)
            mu2 = cv2.GaussianBlur(img2.astype(np.float64), (11, 11), 1.5)
            
            mu1_sq = mu1 ** 2
            mu2_sq = mu2 ** 2
            mu1_mu2 = mu1 * mu2
            
            # ë¶„ì‚° ê³„ì‚°
            sigma1_sq = cv2.GaussianBlur(img1.astype(np.float64) ** 2, (11, 11), 1.5) - mu1_sq
            sigma2_sq = cv2.GaussianBlur(img2.astype(np.float64) ** 2, (11, 11), 1.5) - mu2_sq
            sigma12 = cv2.GaussianBlur((img1.astype(np.float64) * img2.astype(np.float64)), (11, 11), 1.5) - mu1_mu2
            
            # SSIM ë§µ ê³„ì‚°
            numerator = (2 * mu1_mu2 + C1) * (2 * sigma12 + C2)
            denominator = (mu1_sq + mu2_sq + C1) * (sigma1_sq + sigma2_sq + C2)
            
            ssim_map = numerator / denominator
            
            return float(np.mean(ssim_map))
            
        except Exception as e:
            logger.warning(f"SSIM ê³„ì‚° ì‹¤íŒ¨: {e}")
            return 0.5
    
    def _build_final_result(
        self,
        metrics: QualityMetrics,
        recommendations: List[str],
        detailed_analysis: Dict[str, Any],
        processing_time: float,
        fabric_type: str,
        clothing_type: str
    ) -> Dict[str, Any]:
        """ìµœì¢… ê²°ê³¼ êµ¬ì„± (Pipeline Manager í˜¸í™˜ í˜•ì‹)"""
        
        return {
            "success": True,
            "overall_score": float(metrics.overall_score),
            "grade": metrics.get_grade().value,
            "letter_grade": self._get_letter_grade(metrics.overall_score),
            "metrics": metrics.to_dict(),
            "recommendations": recommendations,
            "detailed_analysis": detailed_analysis,
            "quality_info": {
                "fabric_type": fabric_type,
                "clothing_type": clothing_type,
                "assessment_method": "comprehensive",
                "processing_time": processing_time,
                "device": self.device,
                "device_type": self.device_type,
                "m3_max_optimized": self.is_m3_max,
                "memory_gb": self.memory_gb,
                "features_used": self._get_used_features(),
                "optimization_level": self.optimization_level
            },
            "performance_info": {
                "optimization_enabled": self.optimization_enabled,
                "memory_usage": self._estimate_memory_usage(),
                "gpu_acceleration": self.device != 'cpu'
            }
        }
    
    async def _generate_recommendations(self, metrics: QualityMetrics, fabric_type: str, clothing_type: str) -> List[str]:
        """ê°œì„  ì œì•ˆ ìƒì„± - M3 Max ìµœì í™”"""
        recommendations = []
        
        try:
            # M3 Max í–¥ìƒëœ ì„ê³„ê°’ ì‚¬ìš©
            thresholds = self.quality_thresholds.copy()
            
            # ì„ê³„ê°’ ê¸°ë°˜ ì œì•ˆ
            if metrics.perceptual_quality < thresholds['good']:
                recommendations.append("ì§€ê°ì  í’ˆì§ˆ ê°œì„ : ì…ë ¥ ì´ë¯¸ì§€ í•´ìƒë„ë¥¼ ë†’ì´ê±°ë‚˜ ë…¸ì´ì¦ˆë¥¼ ì¤„ì—¬ë³´ì„¸ìš”.")
            
            if metrics.technical_quality < thresholds['good']:
                recommendations.append("ê¸°ìˆ ì  í’ˆì§ˆ ê°œì„ : ì´ë¯¸ì§€ ì„ ëª…ë„ë¥¼ ë†’ì´ê³  ì••ì¶• ì•„í‹°íŒ©íŠ¸ë¥¼ ì¤„ì—¬ë³´ì„¸ìš”.")
            
            if metrics.aesthetic_quality < thresholds['good']:
                recommendations.append("ë¯¸ì  í’ˆì§ˆ ê°œì„ : ìƒ‰ìƒ ê· í˜•ê³¼ êµ¬ì„±ì„ ì¡°ì •í•´ë³´ì„¸ìš”.")
            
            if metrics.fit_accuracy < thresholds['good']:
                recommendations.append("í• ì •í™•ë„ ê°œì„ : ì‹ ì²´ ì¸¡ì •ê°’ì„ ë‹¤ì‹œ í™•ì¸í•˜ê±°ë‚˜ í¬ì¦ˆë¥¼ ì¡°ì •í•´ë³´ì„¸ìš”.")
            
            if metrics.color_harmony < thresholds['fair']:
                recommendations.append("ìƒ‰ìƒ ì¡°í™” ê°œì„ : ì˜ë¥˜ì™€ í”¼ë¶€í†¤ì´ ì˜ ì–´ìš¸ë¦¬ëŠ” ìƒ‰ìƒì„ ì„ íƒí•´ë³´ì„¸ìš”.")
            
            if metrics.detail_preservation < thresholds['good']:
                recommendations.append("ë””í…Œì¼ ë³´ì¡´ ê°œì„ : ë” ë†’ì€ í’ˆì§ˆì˜ ì›ë³¸ ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í•´ë³´ì„¸ìš”.")
            
            # M3 Max ì „ìš© ì œì•ˆ
            if self.is_m3_max and self.optimization_enabled:
                if metrics.overall_score >= thresholds['excellent']:
                    recommendations.insert(0, "ğŸ M3 Max ìµœì í™”ë¡œ ìµœê³  í’ˆì§ˆì„ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤!")
                elif metrics.overall_score >= thresholds['good']:
                    recommendations.insert(0, "M3 Max ê°€ì†ìœ¼ë¡œ ìš°ìˆ˜í•œ í’ˆì§ˆì„ ì–»ì—ˆìŠµë‹ˆë‹¤. ë” ì •ë°€í•œ ì„¤ì •ì„ ì‹œë„í•´ë³´ì„¸ìš”.")
                    
                # 128GB ë©”ëª¨ë¦¬ íŠ¹í™” ì œì•ˆ
                if self.memory_gb >= 128:
                    if metrics.overall_score < thresholds['excellent']:
                        recommendations.append("128GB ë©”ëª¨ë¦¬ í™œìš©: ê³ í•´ìƒë„ ëª¨ë“œë‚˜ ë°°ì¹˜ ì²˜ë¦¬ë¥¼ í™œì„±í™”í•´ë³´ì„¸ìš”.")
            
            # ë¹ˆ ì¶”ì²œ ëª©ë¡ì¸ ê²½ìš° ê¸°ë³¸ ì œì•ˆ
            if not recommendations:
                if self.is_m3_max and self.memory_gb >= 128:
                    recommendations.append("ğŸ M3 Max 128GBë¡œ ìµœê³ ê¸‰ í’ˆì§ˆì„ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤! í˜„ì¬ ì„¤ì •ì„ ìœ ì§€í•˜ì„¸ìš”.")
                elif self.is_m3_max:
                    recommendations.append("ğŸ M3 Maxë¡œ í›Œë¥­í•œ í’ˆì§ˆì„ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤! í˜„ì¬ ì„¤ì •ì„ ìœ ì§€í•˜ì„¸ìš”.")
                else:
                    recommendations.append("í›Œë¥­í•œ í’ˆì§ˆì…ë‹ˆë‹¤! í˜„ì¬ ì„¤ì •ì„ ìœ ì§€í•˜ì„¸ìš”.")
            
            return recommendations
            
        except Exception as e:
            logger.warning(f"ê°œì„  ì œì•ˆ ìƒì„± ì‹¤íŒ¨: {e}")
            return ["í’ˆì§ˆ ë¶„ì„ì€ ì™„ë£Œë˜ì—ˆì§€ë§Œ ê°œì„  ì œì•ˆ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."]
    
    async def _generate_detailed_analysis(
        self, 
        metrics: QualityMetrics, 
        fitted: np.ndarray, 
        person: Optional[np.ndarray], 
        clothing: Optional[np.ndarray],
        fabric_type: str
    ) -> Dict[str, Any]:
        """ìƒì„¸ ë¶„ì„ ìƒì„± - M3 Max ìµœì í™”"""
        try:
            analysis = {
                'quality_breakdown': {
                    'excellent_aspects': [],
                    'good_aspects': [],
                    'improvement_needed': []
                },
                'technical_details': {
                    'image_properties': self._analyze_image_properties(fitted),
                    'fabric_analysis': self._analyze_fabric_quality(fitted, fabric_type),
                    'structural_analysis': self._analyze_structure(fitted, person) if person is not None else {}
                },
                'comparison_metrics': {
                    'similarity_to_original': self._calculate_overall_similarity(fitted, person) if person is not None else 0.8,
                    'clothing_integration': self._calculate_clothing_integration(fitted, clothing) if clothing is not None else 0.8,
                    'realism_score': self._calculate_realism_score(fitted)
                },
                'performance_insights': {
                    'strongest_aspect': self._find_strongest_aspect(metrics),
                    'weakest_aspect': self._find_weakest_aspect(metrics),
                    'improvement_potential': self._calculate_improvement_potential(metrics)
                },
                'm3_max_analysis': {}
            }
            
            # M3 Max ì „ìš© ë¶„ì„
            if self.is_m3_max and self.optimization_enabled:
                analysis['m3_max_analysis'] = {
                    'optimization_level': self.optimization_level,
                    'memory_utilization': f"{self.memory_gb}GB í™œìš©",
                    'neural_engine_boost': metrics.overall_score > 0.8,
                    'metal_acceleration': self.device == 'mps',
                    'quality_enhancement': "M3 Max ìµœì í™”ë¡œ í’ˆì§ˆ í–¥ìƒë¨",
                    'high_memory_mode': self.memory_gb >= 128,
                    'batch_processing': self.performance_config.get('batch_processing', False),
                    'advanced_caching': self.performance_config.get('enable_caching', False)
                }
            
            # í’ˆì§ˆ ë¶„ë¥˜
            thresholds = self.quality_thresholds
            
            for metric_name, metric_value in metrics.to_dict().items():
                if metric_name == 'overall_score':
                    continue
                
                aspect_info = {
                    'aspect': metric_name.replace('_', ' ').title(),
                    'score': metric_value,
                    'status': self._get_metric_status(metric_value),
                    'm3_max_enhanced': self.is_m3_max and metric_value > 0.8,
                    'high_memory_optimized': self.memory_gb >= 128 and metric_value > 0.85
                }
                
                if metric_value >= thresholds['excellent']:
                    analysis['quality_breakdown']['excellent_aspects'].append(aspect_info)
                elif metric_value >= thresholds['good']:
                    analysis['quality_breakdown']['good_aspects'].append(aspect_info)
                else:
                    analysis['quality_breakdown']['improvement_needed'].append(aspect_info)
            
            return analysis
            
        except Exception as e:
            logger.warning(f"ìƒì„¸ ë¶„ì„ ìƒì„± ì‹¤íŒ¨: {e}")
            return {'error': 'ìƒì„¸ ë¶„ì„ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.'}
    
    # =================================================================
    # ìœ í‹¸ë¦¬í‹° ë©”ì„œë“œë“¤
    # =================================================================
    
    def _tensor_to_numpy(self, tensor: torch.Tensor, is_mask: bool = False) -> np.ndarray:
        """PyTorch í…ì„œë¥¼ NumPy ë°°ì—´ë¡œ ë³€í™˜"""
        if not TORCH_AVAILABLE:
            raise RuntimeError("PyTorchê°€ í•„ìš”í•©ë‹ˆë‹¤")
        
        try:
            # GPUì—ì„œ CPUë¡œ ì´ë™
            if tensor.is_cuda or (hasattr(tensor, 'is_mps') and tensor.is_mps):
                tensor = tensor.cpu()
            
            # ì°¨ì› ì •ë¦¬
            if tensor.dim() == 4:
                tensor = tensor.squeeze(0)  # [1, C, H, W] -> [C, H, W]
            
            if is_mask:
                if tensor.dim() == 3:
                    tensor = tensor.squeeze(0)  # [1, H, W] -> [H, W]
                array = tensor.numpy().astype(np.uint8)
                if array.max() <= 1.0:
                    array = array * 255
            else:
                if tensor.dim() == 3 and tensor.size(0) == 3:
                    tensor = tensor.permute(1, 2, 0)  # [3, H, W] -> [H, W, 3]
                
                array = tensor.numpy()
                if array.max() <= 1.0:
                    array = array * 255
                array = array.astype(np.uint8)
            
            return array
            
        except Exception as e:
            logger.error(f"í…ì„œ ë³€í™˜ ì‹¤íŒ¨: {e}")
            raise
    
    def _get_used_features(self) -> List[str]:
        """ì‚¬ìš©ëœ ê¸°ëŠ¥ë“¤ ëª©ë¡"""
        features = ['basic_quality_assessment']
        
        if self.perceptual_analyzer:
            features.append('perceptual_analysis')
        if self.technical_analyzer:
            features.append('technical_analysis')
        if self.aesthetic_analyzer:
            features.append('aesthetic_analysis')
        if TORCH_AVAILABLE:
            features.append('neural_processing')
        if self.face_detector:
            features.append('face_detection')
        if self.is_m3_max:
            features.append('m3_max_acceleration')
        if self.device == 'mps':
            features.append('metal_performance_shaders')
        
        return features
    
    def _estimate_memory_usage(self) -> Dict[str, float]:
        """ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¶”ì •"""
        try:
            import psutil
            memory_info = {
                'system_usage_percent': psutil.virtual_memory().percent,
                'available_gb': psutil.virtual_memory().available / (1024**3)
            }
            
            if TORCH_AVAILABLE:
                if self.device == 'mps' and hasattr(torch.mps, 'current_allocated_memory'):
                    memory_info['mps_allocated_gb'] = torch.mps.current_allocated_memory() / (1024**3)
                elif self.device == 'cuda':
                    memory_info['gpu_allocated_gb'] = torch.cuda.memory_allocated() / (1024**3)
            
            return memory_info
            
        except Exception as e:
            logger.warning(f"ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¶”ì • ì‹¤íŒ¨: {e}")
            return {'estimated_usage_gb': 2.0}
    
    def _create_error_result(self, error_message: str) -> Dict[str, Any]:
        """ì—ëŸ¬ ê²°ê³¼ ìƒì„±"""
        return {
            "success": False,
            "error": error_message,
            "overall_score": 0.0,
            "grade": "error",
            "letter_grade": "F",
            "metrics": {},
            "recommendations": [],
            "detailed_analysis": {},
            "quality_info": {
                "error_details": error_message,
                "device": self.device,
                "device_type": self.device_type,
                "m3_max_optimized": self.is_m3_max,
                "processing_time": 0.0
            }
        }
    
    def _create_fallback_result(self, reason: str) -> Dict[str, Any]:
        """í´ë°± ê²°ê³¼ ìƒì„± (ìµœì†Œ ê¸°ëŠ¥)"""
        logger.warning(f"í´ë°± ëª¨ë“œ: {reason}")
        
        # ê¸°ë³¸ ë©”íŠ¸ë¦­ ìƒì„±
        fallback_metrics = QualityMetrics(
            overall_score=0.7,
            perceptual_quality=0.7,
            technical_quality=0.7,
            aesthetic_quality=0.7,
            fit_accuracy=0.7,
            color_harmony=0.7,
            detail_preservation=0.7,
            edge_quality=0.7,
            lighting_consistency=0.7,
            artifact_level=0.7,
            face_preservation=1.0
        )
        
        return {
            "success": True,
            "overall_score": fallback_metrics.overall_score,
            "grade": fallback_metrics.get_grade().value,
            "letter_grade": self._get_letter_grade(fallback_metrics.overall_score),
            "metrics": fallback_metrics.to_dict(),
            "recommendations": ["ê¸°ë³¸ í‰ê°€ ëª¨ë“œì—ì„œ ì²˜ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤."],
            "detailed_analysis": {"fallback_mode": True, "reason": reason},
            "quality_info": {
                "fallback_mode": True,
                "reason": reason,
                "assessment_method": "fallback",
                "processing_time": 0.001,
                "device": self.device,
                "device_type": self.device_type,
                "m3_max_optimized": self.is_m3_max
            }
        }
    
    # =================================================================
    # ì¶”ê°€ í—¬í¼ ë©”ì„œë“œë“¤
    # =================================================================
    
    def _analyze_image_properties(self, image: np.ndarray) -> Dict[str, Any]:
        """ì´ë¯¸ì§€ ì†ì„± ë¶„ì„"""
        try:
            h, w, c = image.shape
            
            properties = {
                'resolution': f"{w}x{h}",
                'channels': c,
                'file_size_estimate': f"{(w * h * c / 1024):.1f} KB",
                'aspect_ratio': f"{w/h:.2f}:1",
                'm3_max_optimized': self.is_m3_max and min(w, h) >= 1024,
                'high_resolution': min(w, h) >= 1024,
                'memory_efficient': self.memory_gb >= 128
            }
            
            # ìƒ‰ìƒ í†µê³„
            properties.update({
                'brightness_mean': float(np.mean(image)),
                'brightness_std': float(np.std(image)),
                'contrast_measure': float(np.std(cv2.cvtColor(image, cv2.COLOR_RGB2GRAY))),
                'color_range': {
                    'min': [int(np.min(image[:,:,i])) for i in range(c)],
                    'max': [int(np.max(image[:,:,i])) for i in range(c)],
                    'mean': [float(np.mean(image[:,:,i])) for i in range(c)]
                }
            })
            
            return properties
            
        except Exception as e:
            logger.warning(f"ì´ë¯¸ì§€ ì†ì„± ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {}
    
    def _analyze_fabric_quality(self, image: np.ndarray, fabric_type: str) -> Dict[str, Any]:
        """ì²œ í’ˆì§ˆ ë¶„ì„"""
        try:
            gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
            
            # í…ìŠ¤ì²˜ ë¶„ì„
            texture_var = np.var(gray)
            texture_score = min(texture_var / 1000.0, 1.0)
            
            # ì²œ íŠ¹ì„±ë³„ í’ˆì§ˆ ê¸°ì¤€
            fabric_standards = self.FABRIC_QUALITY_STANDARDS.get(fabric_type, self.FABRIC_QUALITY_STANDARDS['default'])
            
            analysis = {
                'fabric_type': fabric_type,
                'texture_score': texture_score,
                'texture_threshold_met': texture_score >= fabric_standards['texture_threshold'],
                'smoothness_score': self._calculate_smoothness(gray),
                'surface_quality': 'excellent' if texture_score > 0.8 else 'good' if texture_score > 0.6 else 'fair',
                'm3_max_precision': self.is_m3_max,
                'high_memory_analysis': self.memory_gb >= 128
            }
            
            return analysis
            
        except Exception as e:
            logger.warning(f"ì²œ í’ˆì§ˆ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {}
    
    def _calculate_smoothness(self, gray_image: np.ndarray) -> float:
        """í‘œë©´ ë§¤ë„ëŸ¬ì›€ ê³„ì‚°"""
        try:
            # Laplacianìœ¼ë¡œ í…ìŠ¤ì²˜ ë³€í™”ëŸ‰ ì¸¡ì •
            laplacian = cv2.Laplacian(gray_image, cv2.CV_64F)
            smoothness = 1.0 - (np.std(laplacian) / 100.0)
            return max(0.0, min(1.0, smoothness))
        except Exception:
            return 0.5
    
    def _analyze_structure(self, fitted: np.ndarray, person: np.ndarray) -> Dict[str, Any]:
        """êµ¬ì¡° ë¶„ì„"""
        try:
            fitted_edges = cv2.Canny(cv2.cvtColor(fitted, cv2.COLOR_RGB2GRAY), 50, 150)
            person_edges = cv2.Canny(cv2.cvtColor(person, cv2.COLOR_RGB2GRAY), 50, 150)
            
            analysis = {
                'edge_density_fitted': float(np.sum(fitted_edges > 0) / fitted_edges.size),
                'edge_density_person': float(np.sum(person_edges > 0) / person_edges.size),
                'structural_similarity': self._calculate_ssim_numpy(fitted_edges, person_edges),
                'geometric_distortion': self._calculate_geometric_distortion(fitted, person),
                'm3_max_enhanced': self.is_m3_max,
                'high_precision': self.memory_gb >= 128
            }
            
            return analysis
            
        except Exception as e:
            logger.warning(f"êµ¬ì¡° ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {}
    
    def _calculate_geometric_distortion(self, fitted: np.ndarray, person: np.ndarray) -> float:
        """ê¸°í•˜í•™ì  ì™œê³¡ ê³„ì‚°"""
        try:
            fitted_gray = cv2.cvtColor(fitted, cv2.COLOR_RGB2GRAY)
            person_gray = cv2.cvtColor(person, cv2.COLOR_RGB2GRAY)
            
            diff = cv2.absdiff(fitted_gray, person_gray)
            distortion_level = np.mean(diff) / 255.0
            
            return float(1.0 - distortion_level)
            
        except Exception as e:
            logger.warning(f"ê¸°í•˜í•™ì  ì™œê³¡ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return 0.5
    
    def _calculate_overall_similarity(self, fitted: np.ndarray, person: np.ndarray) -> float:
        """ì „ì²´ ìœ ì‚¬ì„± ê³„ì‚°"""
        try:
            fitted_gray = cv2.cvtColor(fitted, cv2.COLOR_RGB2GRAY)
            person_gray = cv2.cvtColor(person, cv2.COLOR_RGB2GRAY)
            
            return self._calculate_ssim_numpy(fitted_gray, person_gray)
        except Exception as e:
            logger.warning(f"ì „ì²´ ìœ ì‚¬ì„± ê³„ì‚° ì‹¤íŒ¨: {e}")
            return 0.5
    
    def _calculate_clothing_integration(self, fitted: np.ndarray, clothing: np.ndarray) -> float:
        """ì˜ë¥˜ í†µí•©ë„ ê³„ì‚°"""
        try:
            fitted_colors = fitted.reshape(-1, 3).mean(axis=0)
            clothing_colors = clothing.reshape(-1, 3).mean(axis=0)
            
            color_distance = np.linalg.norm(fitted_colors - clothing_colors)
            integration_score = 1.0 - (color_distance / 441.67)
            
            return max(0.0, min(1.0, integration_score))
        except Exception as e:
            logger.warning(f"ì˜ë¥˜ í†µí•©ë„ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return 0.5
    
    def _calculate_realism_score(self, fitted: np.ndarray) -> float:
        """í˜„ì‹¤ê° ì ìˆ˜ ê³„ì‚°"""
        try:
            # ê°„ë‹¨í•œ í˜„ì‹¤ê° ë©”íŠ¸ë¦­ (ìƒ‰ìƒ ë¶„í¬ì™€ í…ìŠ¤ì²˜ ê¸°ë°˜)
            gray = cv2.cvtColor(fitted, cv2.COLOR_RGB2GRAY)
            texture_variance = np.var(gray)
            
            # ìƒ‰ìƒ ë¶„í¬ ìì—°ìŠ¤ëŸ¬ì›€
            hsv = cv2.cvtColor(fitted, cv2.COLOR_RGB2HSV)
            saturation_balance = 1.0 - abs(np.mean(hsv[:,:,1]) - 128) / 128.0
            
            realism_score = (min(texture_variance / 1000.0, 1.0) * 0.6 + 
                           saturation_balance * 0.4)
            
            return max(0.0, min(1.0, realism_score))
        except Exception as e:
            logger.warning(f"í˜„ì‹¤ê° ì ìˆ˜ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return 0.5
    
    def _find_strongest_aspect(self, metrics: QualityMetrics) -> str:
        """ê°€ì¥ ê°•í•œ ì¸¡ë©´ ì°¾ê¸°"""
        try:
            metric_dict = metrics.to_dict()
            del metric_dict['overall_score']  # ì „ì²´ ì ìˆ˜ ì œì™¸
            
            strongest = max(metric_dict.items(), key=lambda x: x[1])
            return strongest[0].replace('_', ' ').title()
        except Exception:
            return "Unknown"
    
    def _find_weakest_aspect(self, metrics: QualityMetrics) -> str:
        """ê°€ì¥ ì•½í•œ ì¸¡ë©´ ì°¾ê¸°"""
        try:
            metric_dict = metrics.to_dict()
            del metric_dict['overall_score']  # ì „ì²´ ì ìˆ˜ ì œì™¸
            
            weakest = min(metric_dict.items(), key=lambda x: x[1])
            return weakest[0].replace('_', ' ').title()
        except Exception:
            return "Unknown"
    
    def _calculate_improvement_potential(self, metrics: QualityMetrics) -> float:
        """ê°œì„  ê°€ëŠ¥ì„± ê³„ì‚°"""
        try:
            metric_dict = metrics.to_dict()
            del metric_dict['overall_score']
            
            scores = list(metric_dict.values())
            current_avg = np.mean(scores)
            max_possible = 1.0
            
            improvement_potential = (max_possible - current_avg) / max_possible
            return improvement_potential
        except Exception:
            return 0.5
    
    def _get_metric_status(self, score: float) -> str:
        """ë©”íŠ¸ë¦­ ìƒíƒœ ë¬¸ìì—´ ë°˜í™˜"""
        thresholds = self.quality_thresholds
        
        if score >= thresholds['excellent']:
            return "Excellent"
        elif score >= thresholds['good']:
            return "Good"
        elif score >= thresholds['fair']:
            return "Fair"
        elif score >= thresholds['poor']:
            return "Poor"
        else:
            return "Very Poor"
    
    def _get_letter_grade(self, score: float) -> str:
        """ì ìˆ˜ë¥¼ ë¬¸ì ë“±ê¸‰ìœ¼ë¡œ ë³€í™˜"""
        if score >= 0.95:
            return "A+"
        elif score >= 0.9:
            return "A"
        elif score >= 0.85:
            return "A-"
        elif score >= 0.8:
            return "B+"
        elif score >= 0.75:
            return "B"
        elif score >= 0.7:
            return "B-"
        elif score >= 0.65:
            return "C+"
        elif score >= 0.6:
            return "C"
        elif score >= 0.55:
            return "C-"
        elif score >= 0.5:
            return "D+"
        elif score >= 0.4:
            return "D"
        else:
            return "F"
    
    def _update_performance_stats(self, processing_time: float, quality_score: float):
        """ì„±ëŠ¥ í†µê³„ ì—…ë°ì´íŠ¸"""
        try:
            self.performance_stats['total_assessments'] += 1
            
            # í‰ê·  ì‹œê°„ ì—…ë°ì´íŠ¸
            total = self.performance_stats['total_assessments']
            current_avg_time = self.performance_stats['average_time']
            self.performance_stats['average_time'] = (
                (current_avg_time * (total - 1) + processing_time) / total
            )
            
            # í‰ê·  í’ˆì§ˆ ì ìˆ˜ ì—…ë°ì´íŠ¸
            current_avg_quality = self.performance_stats['average_quality_score']
            self.performance_stats['average_quality_score'] = (
                (current_avg_quality * (total - 1) + quality_score) / total
            )
            
            # ì„±ê³µë¥  ì—…ë°ì´íŠ¸ (í’ˆì§ˆ 0.5 ì´ìƒì´ë©´ ì„±ê³µ)
            success_count = 1 if quality_score > 0.5 else 0
            current_success_rate = self.performance_stats['success_rate']
            self.performance_stats['success_rate'] = (
                (current_success_rate * (total - 1) + success_count) / total
            )
            
            # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì—…ë°ì´íŠ¸
            memory_usage = self._estimate_memory_usage()
            if 'available_gb' in memory_usage:
                self.performance_stats['memory_usage_gb'] = self.memory_gb - memory_usage['available_gb']
            
        except Exception as e:
            logger.warning(f"í†µê³„ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
    
    # =================================================================
    # Pipeline Manager í˜¸í™˜ ë©”ì„œë“œë“¤
    # =================================================================
    
    async def get_model_info(self) -> Dict[str, Any]:
        """ëª¨ë¸ ì •ë³´ ë°˜í™˜ (Pipeline Manager í˜¸í™˜)"""
        return {
            "step_name": "QualityAssessment",
            "version": "4.0-m3max",
            "device": self.device,
            "device_type": self.device_type,
            "memory_gb": self.memory_gb,
            "is_m3_max": self.is_m3_max,
            "optimization_enabled": self.optimization_enabled,
            "initialized": self.is_initialized,
            "initialization_error": self.initialization_error,
            "capabilities": {
                "perceptual_analysis": bool(self.perceptual_analyzer),
                "technical_analysis": bool(self.technical_analyzer),
                "aesthetic_analysis": bool(self.aesthetic_analyzer),
                "face_detection": bool(self.face_detector),
                "neural_processing": TORCH_AVAILABLE and self.device != 'cpu',
                "m3_max_acceleration": self.is_m3_max and self.device == 'mps'
            },
            "supported_fabrics": list(self.FABRIC_QUALITY_STANDARDS.keys()),
            "supported_clothing_types": list(self.CLOTHING_QUALITY_WEIGHTS.keys()),
            "performance_stats": self.performance_stats,
            "quality_settings": {
                "optimization_level": self.optimization_level,
                "max_resolution": self._get_max_resolution(),
                "quality_level": self._get_quality_level(),
                "quality_thresholds": self.quality_thresholds
            },
            "dependencies": {
                "torch": TORCH_AVAILABLE,
                "opencv": CV2_AVAILABLE,
                "pil": PIL_AVAILABLE,
                "scipy": SCIPY_AVAILABLE,
                "sklearn": SKLEARN_AVAILABLE,
                "skimage": SKIMAGE_AVAILABLE
            },
            "config": {
                "assessment": self.assessment_config,
                "performance": self.performance_config,
                "optimization_level": self.optimization_level,
                "metric_weights": self.metric_weights
            }
        }
    
    async def cleanup(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬ (Pipeline Manager í˜¸í™˜)"""
        try:
            logger.info("ğŸ§¹ í’ˆì§ˆ í‰ê°€ ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì‹œì‘...")
            
            # ì»´í¬ë„ŒíŠ¸ë“¤ ì •ë¦¬
            if self.perceptual_analyzer:
                if hasattr(self.perceptual_analyzer, 'cleanup'):
                    await self.perceptual_analyzer.cleanup()
                del self.perceptual_analyzer
                self.perceptual_analyzer = None
            
            if self.technical_analyzer:
                if hasattr(self.technical_analyzer, 'cleanup'):
                    await self.technical_analyzer.cleanup()
                del self.technical_analyzer
                self.technical_analyzer = None
            
            if self.aesthetic_analyzer:
                if hasattr(self.aesthetic_analyzer, 'cleanup'):
                    await self.aesthetic_analyzer.cleanup()
                del self.aesthetic_analyzer
                self.aesthetic_analyzer = None
            
            if self.face_detector:
                del self.face_detector
                self.face_detector = None
            
            # GPU ë©”ëª¨ë¦¬ ì •ë¦¬
            if TORCH_AVAILABLE:
                if self.device == 'mps':
                    if hasattr(torch.backends.mps, 'empty_cache'):
                        torch.backends.mps.empty_cache()
                    elif hasattr(torch.mps, 'synchronize'):
                        torch.mps.synchronize()
                elif self.device == 'cuda':
                    torch.cuda.empty_cache()
            
            # ì‹œìŠ¤í…œ ë©”ëª¨ë¦¬ ì •ë¦¬
            import gc
            gc.collect()
            
            self.is_initialized = False
            logger.info("âœ… í’ˆì§ˆ í‰ê°€ ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì™„ë£Œ")
            
        except Exception as e:
            logger.warning(f"âš ï¸ ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")


# =================================================================
# ë³´ì¡° í´ë˜ìŠ¤ë“¤ (ì—…ë°ì´íŠ¸ëœ ìƒì„±ì ì ìš©)
# =================================================================

class PerceptualQualityAnalyzer:
    """ì§€ê°ì  í’ˆì§ˆ ë¶„ì„ê¸° (M3 Max ìµœì í™”)"""
    
    def __init__(self, device: str = 'cpu', m3_max_mode: bool = False, optimization_level: str = 'balanced'):
        self.device = device
        self.m3_max_mode = m3_max_mode
        self.optimization_level = optimization_level
        
        # M3 Max ëª¨ë“œì—ì„œ ë” ë†’ì€ ì •ë°€ë„
        if m3_max_mode:
            self.precision_factor = 2.0
            self.analysis_depth = 'ultra'
        else:
            self.precision_factor = 1.0
            self.analysis_depth = 'standard'
    
    async def analyze_perceptual_quality(
        self,
        fitted_image: np.ndarray,
        reference_image: Optional[np.ndarray],
        fabric_standards: Dict[str, float]
    ) -> float:
        """ì§€ê°ì  í’ˆì§ˆ ë¶„ì„"""
        
        try:
            if reference_image is None:
                # ìì²´ í’ˆì§ˆ ë¶„ì„
                return await self._analyze_intrinsic_quality(fitted_image, fabric_standards)
            else:
                # ë¹„êµ í’ˆì§ˆ ë¶„ì„
                return await self._analyze_comparative_quality(fitted_image, reference_image, fabric_standards)
                
        except Exception as e:
            logger.warning(f"ì§€ê°ì  í’ˆì§ˆ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return 0.7
    
    async def _analyze_intrinsic_quality(self, image: np.ndarray, fabric_standards: Dict) -> float:
        """ë‚´ì¬ì  í’ˆì§ˆ ë¶„ì„"""
        try:
            gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
            
            # ì„ ëª…ë„ ë¶„ì„
            laplacian_var = cv2.Laplacian(gray, cv2.CV_64F).var()
            sharpness_score = min(laplacian_var / 1000.0 * self.precision_factor, 1.0)
            
            # ëŒ€ë¹„ ë¶„ì„
            contrast_score = np.std(gray) / 128.0
            contrast_score = max(0.0, min(1.0, contrast_score))
            
            # ë…¸ì´ì¦ˆ ìˆ˜ì¤€
            noise_level = np.std(cv2.GaussianBlur(gray, (5, 5), 0) - gray)
            noise_score = max(0, 1.0 - (noise_level / 50.0))
            
            # ì¢…í•© ì ìˆ˜
            intrinsic_score = (sharpness_score * 0.4 + 
                             contrast_score * 0.3 + 
                             noise_score * 0.3)
            
            return max(0.0, min(1.0, intrinsic_score))
            
        except Exception as e:
            logger.warning(f"ë‚´ì¬ì  í’ˆì§ˆ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return 0.7
    
    async def _analyze_comparative_quality(self, fitted: np.ndarray, reference: np.ndarray, fabric_standards: Dict) -> float:
        """ë¹„êµ í’ˆì§ˆ ë¶„ì„"""
        try:
            # SSIM ê³„ì‚°
            fitted_gray = cv2.cvtColor(fitted, cv2.COLOR_RGB2GRAY)
            reference_gray = cv2.cvtColor(reference, cv2.COLOR_RGB2GRAY)
            
            ssim_score = self._calculate_ssim_basic(fitted_gray, reference_gray)
            
            # PSNR ê³„ì‚°
            mse = np.mean((fitted_gray.astype(float) - reference_gray.astype(float)) ** 2)
            if mse == 0:
                psnr_score = 1.0
            else:
                psnr = 20 * np.log10(255.0 / np.sqrt(mse))
                psnr_score = min(psnr / 40.0, 1.0)
            
            # ì¡°í•© ì ìˆ˜
            comparative_score = 0.7 * ssim_score + 0.3 * psnr_score
            
            # M3 Max ë³´ì •
            if self.m3_max_mode:
                comparative_score = min(1.0, comparative_score * 1.05)
            
            return comparative_score
            
        except Exception as e:
            logger.warning(f"ë¹„êµ í’ˆì§ˆ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return 0.7
    
    def _calculate_ssim_basic(self, img1: np.ndarray, img2: np.ndarray) -> float:
        """ê¸°ë³¸ SSIM ê³„ì‚°"""
        try:
            # ê°„ë‹¨í•œ SSIM êµ¬í˜„
            mu1 = cv2.GaussianBlur(img1.astype(np.float64), (11, 11), 1.5)
            mu2 = cv2.GaussianBlur(img2.astype(np.float64), (11, 11), 1.5)
            
            mu1_sq = mu1 ** 2
            mu2_sq = mu2 ** 2
            mu1_mu2 = mu1 * mu2
            
            sigma1_sq = cv2.GaussianBlur(img1.astype(np.float64) ** 2, (11, 11), 1.5) - mu1_sq
            sigma2_sq = cv2.GaussianBlur(img2.astype(np.float64) ** 2, (11, 11), 1.5) - mu2_sq
            sigma12 = cv2.GaussianBlur((img1.astype(np.float64) * img2.astype(np.float64)), (11, 11), 1.5) - mu1_mu2
            
            C1, C2 = (0.01 * 255) ** 2, (0.03 * 255) ** 2
            
            ssim_map = ((2 * mu1_mu2 + C1) * (2 * sigma12 + C2)) / ((mu1_sq + mu2_sq + C1) * (sigma1_sq + sigma2_sq + C2))
            
            return float(np.mean(ssim_map))
            
        except Exception as e:
            logger.warning(f"SSIM ê³„ì‚° ì‹¤íŒ¨: {e}")
            return 0.5
    
    async def warmup(self):
        """ì›Œë°ì—…"""
        pass
    
    async def cleanup(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        pass


class TechnicalQualityAnalyzer:
    """ê¸°ìˆ ì  í’ˆì§ˆ ë¶„ì„ê¸° (M3 Max ìµœì í™”)"""
    
    def __init__(self, device: str = 'cpu', enable_advanced_features: bool = False, m3_max_acceleration: bool = False):
        self.device = device
        self.enable_advanced_features = enable_advanced_features
        self.m3_max_acceleration = m3_max_acceleration
        
        # M3 Max ê°€ì†í™” ì„¤ì •
        if m3_max_acceleration:
            self.analysis_precision = 'ultra'
            self.feature_extraction_depth = 'deep'
        else:
            self.analysis_precision = 'standard'
            self.feature_extraction_depth = 'basic'
    
    async def analyze_technical_quality(
        self,
        image: np.ndarray,
        fabric_standards: Dict[str, float],
        clothing_type: str
    ) -> float:
        """ê¸°ìˆ ì  í’ˆì§ˆ ë¶„ì„"""
        
        try:
            gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
            
            # ì„ ëª…ë„ ë¶„ì„
            sharpness_score = self._analyze_sharpness(gray)
            
            # ë…¸ì´ì¦ˆ ë¶„ì„
            noise_score = self._analyze_noise_level(gray)
            
            # ëŒ€ë¹„ ë¶„ì„
            contrast_score = self._analyze_contrast(gray)
            
            # í•´ìƒë„ í’ˆì§ˆ
            resolution_score = self._analyze_resolution_quality(image)
            
            # M3 Max ê³ ê¸‰ ë¶„ì„
            if self.m3_max_acceleration and self.enable_advanced_features:
                advanced_score = await self._analyze_advanced_technical_features(image, fabric_standards)
                
                # ê°€ì¤‘ ì¡°í•© (ê³ ê¸‰ ë¶„ì„ í¬í•¨)
                technical_score = (
                    sharpness_score * 0.3 +
                    noise_score * 0.25 +
                    contrast_score * 0.25 +
                    resolution_score * 0.1 +
                    advanced_score * 0.1
                )
            else:
                # ê¸°ë³¸ ì¡°í•©
                technical_score = (
                    sharpness_score * 0.4 +
                    noise_score * 0.3 +
                    contrast_score * 0.3
                )
            
            return max(0.0, min(1.0, technical_score))
            
        except Exception as e:
            logger.warning(f"ê¸°ìˆ ì  í’ˆì§ˆ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return 0.7
    
    def _analyze_sharpness(self, gray_image: np.ndarray) -> float:
        """ì„ ëª…ë„ ë¶„ì„"""
        try:
            # Laplacian ë¶„ì‚°
            laplacian_var = cv2.Laplacian(gray_image, cv2.CV_64F).var()
            sharpness = min(laplacian_var / 1000.0, 1.0)
            
            # M3 Max ì •ë°€ë„ ë³´ì •
            if self.m3_max_acceleration:
                sharpness = min(1.0, sharpness * 1.1)
            
            return sharpness
            
        except Exception as e:
            logger.warning(f"ì„ ëª…ë„ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return 0.5
    
    def _analyze_noise_level(self, gray_image: np.ndarray) -> float:
        """ë…¸ì´ì¦ˆ ìˆ˜ì¤€ ë¶„ì„"""
        try:
            # ê³ ì£¼íŒŒ ë…¸ì´ì¦ˆ ì¶”ì •
            blurred = cv2.GaussianBlur(gray_image, (5, 5), 0)
            noise = gray_image.astype(float) - blurred.astype(float)
            noise_level = np.std(noise)
            
            # ë…¸ì´ì¦ˆê°€ ì ì„ìˆ˜ë¡ ë†’ì€ ì ìˆ˜
            noise_score = max(0, 1.0 - (noise_level / 50.0))
            
            return noise_score
            
        except Exception as e:
            logger.warning(f"ë…¸ì´ì¦ˆ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return 0.5
    
    def _analyze_contrast(self, gray_image: np.ndarray) -> float:
        """ëŒ€ë¹„ ë¶„ì„"""
        try:
            # RMS ëŒ€ë¹„
            mean_intensity = np.mean(gray_image)
            rms_contrast = np.sqrt(np.mean((gray_image - mean_intensity)**2))
            
            # ì •ê·œí™”
            contrast_score = min(rms_contrast / 64.0, 1.0)
            
            return contrast_score
            
        except Exception as e:
            logger.warning(f"ëŒ€ë¹„ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return 0.5
    
    def _analyze_resolution_quality(self, image: np.ndarray) -> float:
        """í•´ìƒë„ í’ˆì§ˆ ë¶„ì„"""
        try:
            h, w = image.shape[:2]
            total_pixels = h * w
            
            # í•´ìƒë„ ì ìˆ˜ (ë” ë†’ì€ í•´ìƒë„ì¼ìˆ˜ë¡ ë†’ì€ ì ìˆ˜)
            if total_pixels >= 1024 * 1024:  # 1MP ì´ìƒ
                resolution_score = 1.0
            elif total_pixels >= 512 * 512:  # 0.25MP ì´ìƒ
                resolution_score = 0.8
            elif total_pixels >= 256 * 256:  # 0.065MP ì´ìƒ
                resolution_score = 0.6
            else:
                resolution_score = 0.4
            
            return resolution_score
            
        except Exception as e:
            logger.warning(f"í•´ìƒë„ í’ˆì§ˆ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return 0.5
    
    async def _analyze_advanced_technical_features(self, image: np.ndarray, fabric_standards: Dict) -> float:
        """M3 Max ê³ ê¸‰ ê¸°ìˆ ì  íŠ¹ì§• ë¶„ì„"""
        try:
            # ê³ ê¸‰ ì—£ì§€ ë¶„ì„
            gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
            
            # Sobel ì—£ì§€ ê°•ë„
            sobel_x = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3)
            sobel_y = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)
            edge_magnitude = np.sqrt(sobel_x**2 + sobel_y**2)
            
            edge_strength = np.mean(edge_magnitude) / 255.0
            
            # í…ìŠ¤ì²˜ ë¶„ì„
            texture_variance = np.var(gray) / 10000.0
            texture_score = min(texture_variance, 1.0)
            
            # ì¡°í•© ì ìˆ˜
            advanced_score = (edge_strength * 0.6 + texture_score * 0.4)
            
            return max(0.0, min(1.0, advanced_score))
            
        except Exception as e:
            logger.warning(f"ê³ ê¸‰ ê¸°ìˆ ì  ë¶„ì„ ì‹¤íŒ¨: {e}")
            return 0.7
    
    async def warmup(self):
        """ì›Œë°ì—…"""
        pass
    
    async def cleanup(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        pass


class AestheticQualityAnalyzer:
    """ë¯¸ì  í’ˆì§ˆ ë¶„ì„ê¸° (M3 Max ìµœì í™”)"""
    
    def __init__(self, device: str = 'cpu', use_advanced_features: bool = False, m3_max_precision: bool = False):
        self.device = device
        self.use_advanced_features = use_advanced_features
        self.m3_max_precision = m3_max_precision
        
        # M3 Max ì •ë°€ë„ ì„¤ì •
        if m3_max_precision:
            self.color_analysis_depth = 'ultra'
            self.composition_analysis_level = 'advanced'
        else:
            self.color_analysis_depth = 'standard'
            self.composition_analysis_level = 'basic'
    
    async def analyze_aesthetic_quality(
        self,
        fitted_image: np.ndarray,
        person_image: Optional[np.ndarray],
        clothing_image: Optional[np.ndarray],
        fabric_type: str
    ) -> float:
        """ë¯¸ì  í’ˆì§ˆ ë¶„ì„"""
        
        try:
            # ìƒ‰ìƒ ë¶„í¬ ë¶„ì„
            color_score = self._analyze_color_distribution(fitted_image)
            
            # êµ¬ì„± ê· í˜• ë¶„ì„
            composition_score = self._analyze_composition_balance(fitted_image)
            
            # ì‹œê°ì  ì¡°í™” ë¶„ì„
            harmony_score = 0.8  # ê¸°ë³¸ê°’
            if person_image is not None and clothing_image is not None:
                harmony_score = self._analyze_visual_harmony(fitted_image, person_image, clothing_image)
            
            # M3 Max ê³ ê¸‰ ë¯¸ì  ë¶„ì„
            if self.m3_max_precision and self.use_advanced_features:
                advanced_aesthetic_score = await self._analyze_advanced_aesthetics(
                    fitted_image, fabric_type
                )
                
                # ê°€ì¤‘ ì¡°í•© (ê³ ê¸‰ ë¶„ì„ í¬í•¨)
                aesthetic_score = (
                    color_score * 0.3 +
                    composition_score * 0.3 +
                    harmony_score * 0.25 +
                    advanced_aesthetic_score * 0.15
                )
            else:
                # ê¸°ë³¸ ì¡°í•©
                aesthetic_score = (
                    color_score * 0.4 +
                    composition_score * 0.35 +
                    harmony_score * 0.25
                )
            
            return max(0.0, min(1.0, aesthetic_score))
            
        except Exception as e:
            logger.warning(f"ë¯¸ì  í’ˆì§ˆ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return 0.7
    
    def _analyze_color_distribution(self, image: np.ndarray) -> float:
        """ìƒ‰ìƒ ë¶„í¬ ë¶„ì„"""
        try:
            # HSV ìƒ‰ê³µê°„ ë³€í™˜
            hsv = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)
            
            # ìƒ‰ìƒ íˆìŠ¤í† ê·¸ë¨
            hist_h = cv2.calcHist([hsv], [0], None, [180], [0, 180])
            hist_s = cv2.calcHist([hsv], [1], None, [256], [0, 256])
            
            # ìƒ‰ìƒ ë‹¤ì–‘ì„± ê³„ì‚°
            h_diversity = np.count_nonzero(hist_h) / 180.0
            s_diversity = np.count_nonzero(hist_s) / 256.0
            
            # ê· í˜• ì ìˆ˜
            color_score = (h_diversity + s_diversity) / 2.0
            
            # M3 Max ì •ë°€ë„ ë³´ì •
            if self.m3_max_precision:
                color_score = min(1.0, color_score * 1.05)
            
            return max(0.0, min(1.0, color_score))
            
        except Exception as e:
            logger.warning(f"ìƒ‰ìƒ ë¶„í¬ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return 0.5
    
    def _analyze_composition_balance(self, image: np.ndarray) -> float:
        """êµ¬ì„± ê· í˜• ë¶„ì„"""
        try:
            h, w = image.shape[:2]
            gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
            
            # 3ë¶„í• ë²• ê²©ìì 
            grid_points = [
                (w//3, h//3), (2*w//3, h//3),
                (w//3, 2*h//3), (2*w//3, 2*h//3)
            ]
            
            # ê° ê²©ìì  ì£¼ë³€ì˜ ê´€ì‹¬ë„ ê³„ì‚°
            interest_scores = []
            
            for x, y in grid_points:
                roi = gray[max(0, y-25):min(h, y+25), max(0, x-25):min(w, x+25)]
                if roi.size > 0:
                    interest = np.std(roi)  # í‘œì¤€í¸ì°¨ë¥¼ ê´€ì‹¬ë„ë¡œ ì‚¬ìš©
                    interest_scores.append(interest)
            
            # ê· í˜• ì ìˆ˜ (ë¶„ì‚°ì´ ë‚®ì„ìˆ˜ë¡ ê· í˜•ì )
            if interest_scores:
                balance_score = 1.0 - (np.std(interest_scores) / (np.mean(interest_scores) + 1e-6))
                return max(0.0, min(1.0, balance_score))
            
            return 0.5
            
        except Exception as e:
            logger.warning(f"êµ¬ì„± ê· í˜• ë¶„ì„ ì‹¤íŒ¨: {e}")
            return 0.5
    
    def _analyze_visual_harmony(self, fitted: np.ndarray, person: np.ndarray, clothing: np.ndarray) -> float:
        """ì‹œê°ì  ì¡°í™” ë¶„ì„"""
        try:
            # ìƒ‰ìƒ ì¡°í™” ê³„ì‚°
            fitted_colors = fitted.reshape(-1, 3).mean(axis=0)
            person_colors = person.reshape(-1, 3).mean(axis=0)
            clothing_colors = clothing.reshape(-1, 3).mean(axis=0)
            
            # ìƒ‰ìƒ ê±°ë¦¬ ê³„ì‚°
            person_fitted_dist = np.linalg.norm(fitted_colors - person_colors)
            clothing_fitted_dist = np.linalg.norm(fitted_colors - clothing_colors)
            
            # ì¡°í™” ì ìˆ˜ (ê±°ë¦¬ê°€ ì ì ˆí•  ë•Œ ë†’ìŒ)
            harmony_score = 1.0 - min(person_fitted_dist, clothing_fitted_dist) / 441.67  # sqrt(3*255^2)
            
            return max(0.0, min(1.0, harmony_score))
            
        except Exception as e:
            logger.warning(f"ì‹œê°ì  ì¡°í™” ë¶„ì„ ì‹¤íŒ¨: {e}")
            return 0.5
    
    async def _analyze_advanced_aesthetics(self, image: np.ndarray, fabric_type: str) -> float:
        """M3 Max ê³ ê¸‰ ë¯¸ì  ë¶„ì„"""
        try:
            # í™©ê¸ˆë¹„ìœ¨ êµ¬ì„± ë¶„ì„
            golden_ratio_score = self._analyze_golden_ratio_composition(image)
            
            # ìƒ‰ì˜¨ë„ ì¼ê´€ì„± ë¶„ì„
            color_temp_score = self._analyze_color_temperature_consistency(image)
            
            # ì²œ íƒ€ì…ë³„ ë¯¸ì  íŠ¹ì„± ë¶„ì„
            fabric_aesthetic_score = self._analyze_fabric_specific_aesthetics(image, fabric_type)
            
            # ì¡°í•© ì ìˆ˜
            advanced_score = (
                golden_ratio_score * 0.4 +
                color_temp_score * 0.3 +
                fabric_aesthetic_score * 0.3
            )
            
            return max(0.0, min(1.0, advanced_score))
            
        except Exception as e:
            logger.warning(f"ê³ ê¸‰ ë¯¸ì  ë¶„ì„ ì‹¤íŒ¨: {e}")
            return 0.7
    
    def _analyze_golden_ratio_composition(self, image: np.ndarray) -> float:
        """í™©ê¸ˆë¹„ìœ¨ êµ¬ì„± ë¶„ì„"""
        try:
            h, w = image.shape[:2]
            
            # í™©ê¸ˆë¹„ìœ¨ ê²©ìì  (1:1.618)
            golden_ratio = 1.618
            
            # ìˆ˜ì§ ë¶„í• ì 
            v1 = int(w / golden_ratio)
            v2 = w - v1
            
            # ìˆ˜í‰ ë¶„í• ì 
            h1 = int(h / golden_ratio)
            h2 = h - h1
            
            # êµì ë“¤ì—ì„œì˜ ê´€ì‹¬ë„ ì¸¡ì •
            interest_points = [
                (v1, h1), (v2, h1), (v1, h2), (v2, h2)
            ]
            
            gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
            interest_scores = []
            
            for x, y in interest_points:
                # ì£¼ë³€ ì˜ì—­ì˜ ë¶„ì‚° (ê´€ì‹¬ë„)
                roi = gray[max(0, y-25):min(h, y+25), max(0, x-25):min(w, x+25)]
                if roi.size > 0:
                    interest = np.std(roi)
                    interest_scores.append(interest)
            
            if interest_scores:
                # ê· í˜•ë„ (í‘œì¤€í¸ì°¨ê°€ ë‚®ì„ìˆ˜ë¡ ê· í˜•ì )
                balance = 1.0 - (np.std(interest_scores) / (np.mean(interest_scores) + 1e-6))
                return max(0.0, min(1.0, balance))
            
            return 0.5
            
        except Exception as e:
            logger.warning(f"í™©ê¸ˆë¹„ìœ¨ êµ¬ì„± ë¶„ì„ ì‹¤íŒ¨: {e}")
            return 0.5
    
    def _analyze_color_temperature_consistency(self, image: np.ndarray) -> float:
        """ìƒ‰ì˜¨ë„ ì¼ê´€ì„± ë¶„ì„"""
        try:
            # ì´ë¯¸ì§€ë¥¼ 9ê°œ ì˜ì—­ìœ¼ë¡œ ë¶„í• 
            h, w = image.shape[:2]
            regions = []
            
            for i in range(3):
                for j in range(3):
                    y1, y2 = i * h // 3, (i + 1) * h // 3
                    x1, x2 = j * w // 3, (j + 1) * w // 3
                    region = image[y1:y2, x1:x2]
                    regions.append(region)
            
            # ê° ì˜ì—­ì˜ ìƒ‰ì˜¨ë„ ì¶”ì •
            color_temps = []
            for region in regions:
                r_mean = np.mean(region[:, :, 0])
                g_mean = np.mean(region[:, :, 1])
                b_mean = np.mean(region[:, :, 2])
                
                # ê°„ë‹¨í•œ ìƒ‰ì˜¨ë„ ì§€ìˆ˜ (B/R ë¹„ìœ¨)
                if r_mean > 0:
                    color_temp_index = b_mean / r_mean
                    color_temps.append(color_temp_index)
            
            if color_temps:
                # ìƒ‰ì˜¨ë„ ì¼ê´€ì„± (í‘œì¤€í¸ì°¨ê°€ ë‚®ì„ìˆ˜ë¡ ì¼ê´€ì„± ë†’ìŒ)
                consistency = 1.0 - min(np.std(color_temps) / 2.0, 1.0)
                return consistency
            
            return 0.5
            
        except Exception as e:
            logger.warning(f"ìƒ‰ì˜¨ë„ ì¼ê´€ì„± ë¶„ì„ ì‹¤íŒ¨: {e}")
            return 0.5
    
    def _analyze_fabric_specific_aesthetics(self, image: np.ndarray, fabric_type: str) -> float:
        """ì²œ íƒ€ì…ë³„ ë¯¸ì  íŠ¹ì„± ë¶„ì„"""
        try:
            gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
            
            # ì²œ íƒ€ì…ë³„ í…ìŠ¤ì²˜ íŠ¹ì„±
            if fabric_type in ['silk', 'satin']:
                # ë¶€ë“œëŸ¬ìš´ ì²œ - ë§¤ë„ëŸ¬ìš´ í…ìŠ¤ì²˜ ì„ í˜¸
                texture_smoothness = 1.0 - (np.std(cv2.Laplacian(gray, cv2.CV_64F)) / 1000.0)
                fabric_score = min(texture_smoothness, 1.0)
            elif fabric_type in ['denim', 'canvas']:
                # ê±°ì¹œ ì²œ - í…ìŠ¤ì²˜ ë³€í™” ì„ í˜¸
                texture_variation = np.std(cv2.Laplacian(gray, cv2.CV_64F)) / 1000.0
                fabric_score = min(texture_variation, 1.0)
            elif fabric_type in ['wool', 'cashmere']:
                # ì¤‘ê°„ í…ìŠ¤ì²˜ - ì ë‹¹í•œ ë³€í™”
                texture_var = np.var(gray) / 10000.0
                fabric_score = 1.0 - abs(texture_var - 0.5) * 2
            else:
                # ê¸°ë³¸ ì ìˆ˜
                fabric_score = 0.7
            
            return max(0.0, min(1.0, fabric_score))
            
        except Exception as e:
            logger.warning(f"ì²œ íŠ¹ì„±ë³„ ë¯¸ì  ë¶„ì„ ì‹¤íŒ¨: {e}")
            return 0.7
    
    async def warmup(self):
        """ì›Œë°ì—…"""
        pass
    
    async def cleanup(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        pass