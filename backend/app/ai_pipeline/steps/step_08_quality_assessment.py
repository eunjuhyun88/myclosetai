# backend/app/ai_pipeline/steps/step_08_quality_assessment.py
"""
ğŸ”¥ MyCloset AI - 8ë‹¨ê³„: í’ˆì§ˆ í‰ê°€ (Quality Assessment) - ModelLoader ì—°ë™ ì™„ì „ ê°œì„  ë²„ì „
âœ… BaseStepMixin ì™„ì „ ìƒì†ìœ¼ë¡œ logger ì†ì„± ëˆ„ë½ ë¬¸ì œ í•´ê²°
âœ… ModelLoader ì¸í„°í˜ì´ìŠ¤ ì™„ë²½ ì—°ë™ìœ¼ë¡œ AI ëª¨ë¸ ê°„ì ‘ í˜¸ì¶œ
âœ… ìˆœí™˜ì°¸ì¡° ì™„ì „ í•´ê²° (í•œë°©í–¥ ì°¸ì¡°)
âœ… ê¸°ì¡´ íŒŒì¼ì˜ ëª¨ë“  ì„¸ë¶€ ë¶„ì„ ê¸°ëŠ¥ ìœ ì§€
âœ… Pipeline Manager 100% í˜¸í™˜
âœ… M3 Max 128GB ìµœì í™”
âœ… conda í™˜ê²½ ìµœì í™”
âœ… ëª¨ë“  í•¨ìˆ˜/í´ë˜ìŠ¤ëª… ìœ ì§€

ì°¸ì¡° êµ¬ì¡°:
step_08_quality_assessment.py
    â†’ base_step_mixin.py (QualityAssessmentMixin)
    â†’ model_loader.py (ModelLoader ì¸í„°í˜ì´ìŠ¤)
    â†’ config.py (ì„¤ì •)
    (í•œë°©í–¥ ì°¸ì¡°ë§Œ ì‚¬ìš©)

ì²˜ë¦¬ íë¦„:
1. QualityAssessmentMixin ìƒì†ìœ¼ë¡œ logger ë³´ì¥
2. ModelLoader ì¸í„°í˜ì´ìŠ¤ë¥¼ í†µí•œ AI ëª¨ë¸ í˜¸ì¶œ
3. 8ê°€ì§€ í’ˆì§ˆ í‰ê°€ (ì§€ê°ì , ê¸°ìˆ ì , ë¯¸ì , ê¸°ëŠ¥ì )
4. ì¢…í•© í’ˆì§ˆ ì ìˆ˜ ê³„ì‚° ë° ë“±ê¸‰ ë¶€ì—¬
5. M3 Max ìµœì í™” ë° ë©”ëª¨ë¦¬ ê´€ë¦¬
"""

import os
import sys
import logging
import time
import asyncio
import threading
import json
import math
import gc
from typing import Dict, Any, Optional, Tuple, List, Union, Callable
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor
from dataclasses import dataclass, field, asdict
from enum import Enum
from functools import lru_cache, wraps
import numpy as np
import base64
import io

# ==============================================
# ğŸ”¥ í•œë°©í–¥ ì°¸ì¡° êµ¬ì¡° - ìˆœí™˜ì°¸ì¡° í•´ê²°
# ==============================================

# 1. BaseStepMixin ë° QualityAssessmentMixin ì„í¬íŠ¸ (í•µì‹¬)
try:
    from .base_step_mixin import BaseStepMixin, QualityAssessmentMixin
    BASE_STEP_MIXIN_AVAILABLE = True
    logger = logging.getLogger(__name__)
    logger.info("âœ… BaseStepMixin ì„í¬íŠ¸ ì„±ê³µ")
except ImportError as e:
    BASE_STEP_MIXIN_AVAILABLE = False
    logger = logging.getLogger(__name__)
    logger.warning(f"âš ï¸ BaseStepMixin ì„í¬íŠ¸ ì‹¤íŒ¨: {e}")

# 2. ModelLoader ì¸í„°í˜ì´ìŠ¤ ì„í¬íŠ¸ (í•µì‹¬)
try:
    from ..utils.model_loader import ModelLoader, get_global_model_loader
    MODEL_LOADER_AVAILABLE = True
    logger.info("âœ… ModelLoader ì„í¬íŠ¸ ì„±ê³µ")
except ImportError as e:
    MODEL_LOADER_AVAILABLE = False
    logger.warning(f"âš ï¸ ModelLoader ì„í¬íŠ¸ ì‹¤íŒ¨: {e}")

# 3. ì„¤ì • ë° ì½”ì–´ ëª¨ë“ˆ ì„í¬íŠ¸
try:
    from ...core.config import MODEL_CONFIG
    from ...core.gpu_config import GPUConfig
    from ...core.m3_optimizer import M3MaxOptimizer
    CORE_AVAILABLE = True
except ImportError as e:
    CORE_AVAILABLE = False
    logger.warning(f"âš ï¸ Core ëª¨ë“ˆ ì„í¬íŠ¸ ì‹¤íŒ¨: {e}")

# 4. ì„ íƒì  ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸
try:
    import torch
    import torch.nn.functional as F
    from PIL import Image, ImageDraw, ImageFont, ImageFilter, ImageEnhance
    import cv2
    TORCH_AVAILABLE = True
except ImportError:
    TORCH_AVAILABLE = False

try:
    import psutil
    PSUTIL_AVAILABLE = True
except ImportError:
    PSUTIL_AVAILABLE = False

# ==============================================
# ğŸ”¥ MRO ì•ˆì „í•œ í´ë°± í´ë˜ìŠ¤ë“¤ (import ì‹¤íŒ¨ ì‹œ)
# ==============================================

if not BASE_STEP_MIXIN_AVAILABLE:
    class BaseStepMixin:
        """MRO ì•ˆì „í•œ í´ë°± BaseStepMixin"""
        def __init__(self, *args, **kwargs):
            super().__init__()  # MRO ì•ˆì „
            self.logger = logging.getLogger(f"pipeline.{self.__class__.__name__}")
            self.step_name = getattr(self, 'step_name', 'quality_assessment')
            self.step_number = 8
            self.device = 'cpu'
            self.is_initialized = False
    
    class QualityAssessmentMixin(BaseStepMixin):
        """MRO ì•ˆì „í•œ í´ë°± QualityAssessmentMixin"""
        def __init__(self, *args, **kwargs):
            super().__init__()
            self.step_type = "quality_assessment"
            self.quality_threshold = 0.7

# ==============================================
# ğŸ”¥ í’ˆì§ˆ í‰ê°€ ë°ì´í„° êµ¬ì¡°ë“¤ (ê¸°ì¡´ ìœ ì§€)
# ==============================================

class QualityGrade(Enum):
    """í’ˆì§ˆ ë“±ê¸‰"""
    EXCELLENT = "excellent"
    GOOD = "good"
    ACCEPTABLE = "acceptable"
    POOR = "poor"
    FAILED = "failed"

class AssessmentMode(Enum):
    """í‰ê°€ ëª¨ë“œ"""
    COMPREHENSIVE = "comprehensive"
    FAST = "fast"
    DETAILED = "detailed"
    CUSTOM = "custom"

class QualityAspect(Enum):
    """í’ˆì§ˆ í‰ê°€ ì˜ì—­"""
    SHARPNESS = "sharpness"
    COLOR = "color"
    FITTING = "fitting"
    REALISM = "realism"
    ARTIFACTS = "artifacts"
    ALIGNMENT = "alignment"
    LIGHTING = "lighting"
    TEXTURE = "texture"

@dataclass
class QualityMetrics:
    """í’ˆì§ˆ ë©”íŠ¸ë¦­ ë°ì´í„° êµ¬ì¡°"""
    overall_score: float = 0.0
    confidence: float = 0.0
    
    # ì„¸ë¶€ ì ìˆ˜ë“¤
    sharpness_score: float = 0.0
    color_score: float = 0.0
    fitting_score: float = 0.0
    realism_score: float = 0.0
    artifacts_score: float = 0.0
    alignment_score: float = 0.0
    lighting_score: float = 0.0
    texture_score: float = 0.0
    
    # ë©”íƒ€ë°ì´í„°
    processing_time: float = 0.0
    device_used: str = "cpu"
    model_version: str = "v1.0"
    
    def to_dict(self) -> Dict[str, Any]:
        """ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜"""
        return asdict(self)

# ==============================================
# ğŸ”¥ ë©”ì¸ QualityAssessmentStep í´ë˜ìŠ¤
# ==============================================

class QualityAssessmentStep(QualityAssessmentMixin):
    """
    ğŸ”¥ 8ë‹¨ê³„: í’ˆì§ˆ í‰ê°€ Step - ModelLoader ì—°ë™ ì™„ì „ ë²„ì „
    âœ… QualityAssessmentMixin ìƒì†ìœ¼ë¡œ logger ë³´ì¥
    âœ… ModelLoader ì¸í„°í˜ì´ìŠ¤ í†µí•œ AI ëª¨ë¸ í˜¸ì¶œ
    âœ… ê¸°ì¡´ ëª¨ë“  ë¶„ì„ ê¸°ëŠ¥ ìœ ì§€
    âœ… M3 Max ìµœì í™”
    """
    
    def __init__(
        self,
        device: str = "auto",
        config: Optional[Dict[str, Any]] = None,
        **kwargs
    ):
        """í’ˆì§ˆ í‰ê°€ Step ì´ˆê¸°í™”"""
        
        # ğŸ”¥ MRO ì•ˆì „í•œ ì´ˆê¸°í™”
        super().__init__()
        
        # ğŸ”¥ Step ê¸°ë³¸ ì •ë³´ ì„¤ì •
        self.step_name = 'quality_assessment'
        self.step_number = 8
        self.step_type = "quality_assessment"
        
        # ğŸ”¥ ë””ë°”ì´ìŠ¤ ì„¤ì •
        self.device = self._determine_device(device)
        self.device_type = self._get_device_type()
        
        # ğŸ”¥ ì‹œìŠ¤í…œ ì •ë³´
        self.memory_gb = self._get_system_memory()
        self.is_m3_max = self._detect_m3_max()
        
        # ğŸ”¥ ì„¤ì • ì´ˆê¸°í™”
        self.config = config or {}
        self.quality_threshold = self.config.get('quality_threshold', 0.7)
        self.assessment_mode = AssessmentMode(self.config.get('mode', 'comprehensive'))
        
        # ğŸ”¥ í’ˆì§ˆ í‰ê°€ ì„¤ì •
        self.assessment_config = {
            'mode': self.assessment_mode,
            'quality_threshold': self.quality_threshold,
            'enable_detailed_analysis': self.config.get('detailed_analysis', True),
            'enable_visualization': self.config.get('visualization', True)
        }
        
        # ğŸ”¥ ModelLoader ì¸í„°í˜ì´ìŠ¤ (í•µì‹¬)
        self.model_interface = None
        self.models_loaded = {}
        
        # ğŸ”¥ í’ˆì§ˆ í‰ê°€ íŒŒì´í”„ë¼ì¸
        self.assessment_pipeline = []
        
        # ğŸ”¥ ë¶„ì„ê¸°ë“¤ (ê¸°ì¡´ ìœ ì§€)
        self.technical_analyzer = None
        self.perceptual_analyzer = None
        self.aesthetic_analyzer = None
        self.functional_analyzer = None
        self.color_analyzer = None
        
        # ğŸ”¥ ìƒíƒœ ê´€ë¦¬
        self.is_initialized = False
        self.initialization_error = None
        self.error_count = 0
        self.last_error = None
        
        # ğŸ”¥ ì„±ëŠ¥ ìµœì í™”
        self.optimization_enabled = self.is_m3_max and self.memory_gb >= 64
        
        self.logger.info(f"âœ… {self.step_name} ì´ˆê¸°í™” ì™„ë£Œ - Device: {self.device}, Memory: {self.memory_gb}GB")
    
    # ==============================================
    # ğŸ”¥ ì´ˆê¸°í™” ë° ModelLoader ì—°ë™ ë©”ì„œë“œë“¤
    # ==============================================
    
    async def initialize(self) -> bool:
        """í’ˆì§ˆ í‰ê°€ Step ì´ˆê¸°í™”"""
        try:
            self.logger.info(f"ğŸš€ {self.step_name} ì´ˆê¸°í™” ì‹œì‘...")
            
            # 1. ModelLoader ì¸í„°í˜ì´ìŠ¤ ì„¤ì • (í•µì‹¬)
            await self._setup_model_interface()
            
            # 2. AI ëª¨ë¸ ë¡œë“œ (ModelLoader í†µí•´)
            await self._load_quality_assessment_models()
            
            # 3. í’ˆì§ˆ í‰ê°€ íŒŒì´í”„ë¼ì¸ êµ¬ì„±
            self._setup_assessment_pipeline()
            
            # 4. ì „ë¬¸ ë¶„ì„ê¸° ì´ˆê¸°í™”
            self._initialize_analyzers()
            
            # 5. M3 Max ìµœì í™” ì„¤ì •
            if self.optimization_enabled:
                self._optimize_for_m3_max()
            
            self.is_initialized = True
            self.logger.info(f"âœ… {self.step_name} ì´ˆê¸°í™” ì™„ë£Œ")
            return True
            
            self.logger.error(f"âŒ ì˜ë¥˜ ì •ë ¬ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return 0.5
    
    def _analyze_naturalness(self, image: np.ndarray) -> float:
        """ìì—°ìŠ¤ëŸ¬ì›€ ë¶„ì„"""
        try:
            # ìƒ‰ìƒ ë¶„í¬ì˜ ìì—°ìŠ¤ëŸ¬ì›€ ì²´í¬
            if len(image.shape) == 3:
                # RGB ì±„ë„ë³„ íˆìŠ¤í† ê·¸ë¨ ë¶„ì„
                color_variance = np.mean([np.var(image[:,:,i]) for i in range(3)])
                color_naturalness = min(1.0, color_variance / (255.0 * 255.0) * 10)
            else:
                color_naturalness = 0.7
            
            # ê²½ê³„ì„ ì˜ ë¶€ë“œëŸ¬ì›€ ì²´í¬
            if 'cv2' in globals():
                gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY) if len(image.shape) == 3 else image
                edges = cv2.Canny(gray.astype(np.uint8), 50, 150)
                edge_density = np.sum(edges > 0) / edges.size
                smoothness = max(0.0, 1.0 - edge_density * 5)
            else:
                smoothness = 0.7
            
            naturalness = (color_naturalness + smoothness) / 2
            return max(0.0, min(1.0, naturalness))
        
        except Exception as e:
            self.logger.error(f"âŒ ìì—°ìŠ¤ëŸ¬ì›€ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return 0.5
    
    def _analyze_color_consistency(self, image: np.ndarray) -> float:
        """ìƒ‰ìƒ ì¼ê´€ì„± ë¶„ì„"""
        try:
            if len(image.shape) != 3:
                return 0.5
            
            # ì˜ì—­ë³„ ìƒ‰ìƒ ë¶„í¬ ë¶„ì„
            height, width = image.shape[:2]
            regions = [
                image[:height//2, :width//2],    # ì¢Œìƒ
                image[:height//2, width//2:],    # ìš°ìƒ
                image[height//2:, :width//2],    # ì¢Œí•˜
                image[height//2:, width//2:]     # ìš°í•˜
            ]
            
            # ê° ì˜ì—­ì˜ í‰ê·  ìƒ‰ìƒ
            region_colors = [np.mean(region, axis=(0,1)) for region in regions]
            
            # ìƒ‰ìƒ ê°„ í¸ì°¨ ê³„ì‚°
            color_std = np.std(region_colors, axis=0)
            consistency = 1.0 - np.mean(color_std) / 255.0
            
            return max(0.0, min(1.0, consistency))
        
        except Exception as e:
            self.logger.error(f"âŒ ìƒ‰ìƒ ì¼ê´€ì„± ë¶„ì„ ì‹¤íŒ¨: {e}")
            return 0.5
    
    def _analyze_color_naturalness(self, image: np.ndarray) -> float:
        """ìƒ‰ìƒ ìì—°ìŠ¤ëŸ¬ì›€ ë¶„ì„"""
        try:
            if len(image.shape) != 3:
                return 0.5
            
            # ìƒ‰ìƒ í¬í™”ë„ ë¶„ì„
            hsv = cv2.cvtColor(image, cv2.COLOR_RGB2HSV) if 'cv2' in globals() else image
            
            if 'cv2' in globals():
                saturation = hsv[:,:,1]
                avg_saturation = np.mean(saturation) / 255.0
                
                # ì ì ˆí•œ í¬í™”ë„ ë²”ìœ„ (0.3-0.8)
                if 0.3 <= avg_saturation <= 0.8:
                    saturation_score = 1.0
                else:
                    saturation_score = max(0.0, 1.0 - abs(avg_saturation - 0.55) * 2)
            else:
                # OpenCV ì—†ì„ ë•Œ RGB ê¸°ë°˜ ê·¼ì‚¬
                max_vals = np.max(image, axis=2)
                min_vals = np.min(image, axis=2)
                saturation = (max_vals - min_vals) / (max_vals + 1e-8)
                avg_saturation = np.mean(saturation)
                saturation_score = min(1.0, avg_saturation * 1.5)
            
            return saturation_score
        
        except Exception as e:
            self.logger.error(f"âŒ ìƒ‰ìƒ ìì—°ìŠ¤ëŸ¬ì›€ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return 0.5
    
    def _analyze_color_contrast(self, image: np.ndarray) -> float:
        """ìƒ‰ìƒ ëŒ€ë¹„ ë¶„ì„"""
        try:
            if len(image.shape) == 3:
                # ë°ê¸° ì±„ë„ ì¶”ì¶œ
                brightness = np.mean(image, axis=2)
            else:
                brightness = image
            
            # ëŒ€ë¹„ ê³„ì‚° (í‘œì¤€í¸ì°¨ ê¸°ë°˜)
            contrast = np.std(brightness) / 255.0
            
            # ì ì ˆí•œ ëŒ€ë¹„ ë²”ìœ„ (0.2-0.6)
            if 0.2 <= contrast <= 0.6:
                contrast_score = 1.0
            else:
                contrast_score = max(0.0, 1.0 - abs(contrast - 0.4) * 2.5)
            
            return contrast_score
        
        except Exception as e:
            self.logger.error(f"âŒ ìƒ‰ìƒ ëŒ€ë¹„ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return 0.5
    
    def _calculate_confidence(self, data: Dict[str, Any]) -> float:
        """ì‹ ë¢°ë„ ê³„ì‚°"""
        try:
            confidence_factors = []
            
            # 1. AI ëª¨ë¸ ì‚¬ìš© ì—¬ë¶€
            ai_model_count = sum(1 for key in self.models_loaded.keys() if key in ['technical', 'perceptual', 'aesthetic'])
            ai_confidence = min(1.0, ai_model_count / 3.0)  # ìµœëŒ€ 3ê°œ ëª¨ë¸
            confidence_factors.append(ai_confidence)
            
            # 2. ì…ë ¥ ë°ì´í„° í’ˆì§ˆ
            has_original = data.get('original_image') is not None
            has_clothing = data.get('clothing_image') is not None
            data_quality = (0.5 + 0.3 * has_original + 0.2 * has_clothing)
            confidence_factors.append(data_quality)
            
            # 3. ë¶„ì„ ê²°ê³¼ ì¼ê´€ì„±
            scores = [
                data.get('technical_score', 0.5),
                data.get('perceptual_score', 0.5),
                data.get('aesthetic_score', 0.5),
                data.get('functional_score', 0.5),
                data.get('color_score', 0.5)
            ]
            score_std = np.std(scores)
            consistency = max(0.0, 1.0 - score_std * 2)  # í‘œì¤€í¸ì°¨ê°€ ë‚®ì„ìˆ˜ë¡ ì¼ê´€ì„± ë†’ìŒ
            confidence_factors.append(consistency)
            
            # 4. ì‹œìŠ¤í…œ ìµœì í™” ìƒíƒœ
            optimization_factor = 0.9 if self.optimization_enabled else 0.7
            confidence_factors.append(optimization_factor)
            
            return np.mean(confidence_factors)
        
        except Exception as e:
            self.logger.error(f"âŒ ì‹ ë¢°ë„ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return 0.7
    
    # ==============================================
    # ğŸ”¥ ì‹œìŠ¤í…œ ìµœì í™” ë° ê´€ë¦¬ ë©”ì„œë“œë“¤
    # ==============================================
    
    def _determine_device(self, device: str) -> str:
        """ë””ë°”ì´ìŠ¤ ê²°ì •"""
        if device == "auto":
            if TORCH_AVAILABLE:
                if torch.backends.mps.is_available():
                    return "mps"
                elif torch.cuda.is_available():
                    return "cuda"
            return "cpu"
        return device
    
    def _get_device_type(self) -> str:
        """ë””ë°”ì´ìŠ¤ íƒ€ì… ë°˜í™˜"""
        if "mps" in self.device:
            return "Apple Silicon"
        elif "cuda" in self.device:
            return "NVIDIA GPU"
        else:
            return "CPU"
    
    def _get_system_memory(self) -> int:
        """ì‹œìŠ¤í…œ ë©”ëª¨ë¦¬ ìš©ëŸ‰ (GB)"""
        try:
            if PSUTIL_AVAILABLE:
                return int(psutil.virtual_memory().total / (1024**3))
            else:
                return 8  # ê¸°ë³¸ê°’
        except:
            return 8
    
    def _detect_m3_max(self) -> bool:
        """M3 Max ì¹© ê°ì§€"""
        try:
            if self.device == "mps" and self.memory_gb >= 32:
                return True
            return False
        except:
            return False
    
    def _optimize_for_m3_max(self):
        """M3 Max ìµœì í™” ì„¤ì •"""
        try:
            if TORCH_AVAILABLE and self.device == "mps":
                # MPS ìµœì í™” ì„¤ì •
                torch.mps.set_high_watermark_ratio(0.0)
                
                # ë©”ëª¨ë¦¬ íš¨ìœ¨ì  ì„¤ì •
                if hasattr(torch.backends.mps, 'set_max_memory_allocation'):
                    torch.backends.mps.set_max_memory_allocation(self.memory_gb * 0.8 * 1024**3)
            
            self.logger.info("âœ… M3 Max ìµœì í™” ì„¤ì • ì™„ë£Œ")
        
        except Exception as e:
            self.logger.warning(f"âš ï¸ M3 Max ìµœì í™” ì„¤ì • ì‹¤íŒ¨: {e}")
    
    def _optimize_memory(self):
        """ë©”ëª¨ë¦¬ ìµœì í™”"""
        try:
            if TORCH_AVAILABLE:
                if self.device == "mps":
                    torch.mps.empty_cache()
                elif self.device == "cuda":
                    torch.cuda.empty_cache()
            
            # ê°€ë¹„ì§€ ì»¬ë ‰ì…˜
            gc.collect()
            
        except Exception as e:
            self.logger.debug(f"ë©”ëª¨ë¦¬ ìµœì í™” ì˜¤ë¥˜: {e}")
    
    def cleanup_resources(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        try:
            self.logger.info(f"ğŸ§¹ {self.step_name} ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì‹œì‘...")
            
            # ModelLoader ì¸í„°í˜ì´ìŠ¤ ì •ë¦¬
            if self.model_interface:
                try:
                    self.model_interface.cleanup()
                except Exception as e:
                    self.logger.warning(f"âš ï¸ ModelLoader ì¸í„°í˜ì´ìŠ¤ ì •ë¦¬ ì‹¤íŒ¨: {e}")
            
            # ëª¨ë¸ ë©”ëª¨ë¦¬ í•´ì œ
            self.models_loaded.clear()
            
            # ë¶„ì„ê¸° ì •ë¦¬
            for analyzer_name in ['technical_analyzer', 'perceptual_analyzer', 'aesthetic_analyzer', 'functional_analyzer', 'color_analyzer']:
                analyzer = getattr(self, analyzer_name, None)
                if analyzer and hasattr(analyzer, 'cleanup'):
                    try:
                        analyzer.cleanup()
                    except Exception as e:
                        self.logger.warning(f"âš ï¸ {analyzer_name} ì •ë¦¬ ì‹¤íŒ¨: {e}")
                setattr(self, analyzer_name, None)
            
            # íŒŒì´í”„ë¼ì¸ ì •ë¦¬
            self.assessment_pipeline.clear()
            
            # ë©”ëª¨ë¦¬ ìµœì í™”
            self._optimize_memory()
            
            self.is_initialized = False
            self.logger.info(f"âœ… {self.step_name} ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì™„ë£Œ")
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
    
    def get_step_info(self) -> Dict[str, Any]:
        """Step ì •ë³´ ë°˜í™˜"""
        return {
            'step_name': self.step_name,
            'step_number': self.step_number,
            'device': self.device,
            'device_type': self.device_type,
            'memory_gb': self.memory_gb,
            'is_m3_max': self.is_m3_max,
            'ai_models_loaded': len(self.models_loaded),
            'assessment_modes': [mode.value for mode in AssessmentMode],
            'quality_threshold': self.quality_threshold,
            'pipeline_stages': len(self.assessment_pipeline),
            'optimization_enabled': self.optimization_enabled,
            'is_initialized': self.is_initialized,
            'model_interface_available': self.model_interface is not None,
            'base_step_mixin_available': BASE_STEP_MIXIN_AVAILABLE,
            'model_loader_available': MODEL_LOADER_AVAILABLE
        }

# ==============================================
# ğŸ”¥ í–¥ìƒëœ AI ëª¨ë¸ í´ë˜ìŠ¤ë“¤ (ê¸°ì¡´ íŒŒì¼ì—ì„œ ê°€ì ¸ì˜´)
# ==============================================

if TORCH_AVAILABLE:
    import torch.nn as nn
    
    class EnhancedPerceptualQualityModel(nn.Module):
        """í–¥ìƒëœ ì§€ê°ì  í’ˆì§ˆ í‰ê°€ ëª¨ë¸ (ResNet ë°±ë³¸)"""
        
        def __init__(self):
            super().__init__()
            
            # ResNet ìŠ¤íƒ€ì¼ íŠ¹ì§• ì¶”ì¶œê¸°
            self.feature_extractor = nn.Sequential(
                # Block 1
                nn.Conv2d(3, 64, 7, stride=2, padding=3),
                nn.BatchNorm2d(64),
                nn.ReLU(),
                nn.MaxPool2d(3, stride=2, padding=1),
                
                # Block 2
                nn.Conv2d(64, 128, 3, padding=1),
                nn.BatchNorm2d(128),
                nn.ReLU(),
                nn.Conv2d(128, 128, 3, padding=1),
                nn.BatchNorm2d(128),
                nn.ReLU(),
                nn.MaxPool2d(2),
                
                # Block 3
                nn.Conv2d(128, 256, 3, padding=1),
                nn.BatchNorm2d(256),
                nn.ReLU(),
                nn.Conv2d(256, 256, 3, padding=1),
                nn.BatchNorm2d(256),
                nn.ReLU(),
                nn.AdaptiveAvgPool2d((8, 8))
            )
            
            # ë‹¤ì¤‘ í’ˆì§ˆ ì˜ˆì¸¡ê¸°
            feature_dim = 256 * 8 * 8
            self.quality_predictors = nn.ModuleDict({
                'overall': nn.Sequential(
                    nn.Linear(feature_dim, 512),
                    nn.ReLU(),
                    nn.Dropout(0.3),
                    nn.Linear(512, 128),
                    nn.ReLU(),
                    nn.Dropout(0.3),
                    nn.Linear(128, 1),
                    nn.Sigmoid()
                ),
                'sharpness': nn.Sequential(
                    nn.Linear(feature_dim, 256),
                    nn.ReLU(),
                    nn.Linear(256, 1),
                    nn.Sigmoid()
                ),
                'artifacts': nn.Sequential(
                    nn.Linear(feature_dim, 256),
                    nn.ReLU(),
                    nn.Linear(256, 1),
                    nn.Sigmoid()
                ),
                'noise': nn.Sequential(
                    nn.Linear(feature_dim, 256),
                    nn.ReLU(),
                    nn.Linear(256, 1),
                    nn.Sigmoid()
                )
            })
        
        def forward(self, x):
            features = self.feature_extractor(x)
            features = features.view(features.size(0), -1)
            
            results = {}
            for name, predictor in self.quality_predictors.items():
                results[name] = predictor(features)
            
            return results

    class EnhancedAestheticQualityModel(nn.Module):
        """í–¥ìƒëœ ë¯¸ì  í’ˆì§ˆ í‰ê°€ ëª¨ë¸ (ë‹¤ì¤‘ í—¤ë“œ)"""
        
        def __init__(self):
            super().__init__()
            
            # ë°±ë³¸ ë„¤íŠ¸ì›Œí¬
            self.backbone = nn.Sequential(
                nn.Conv2d(3, 64, 7, stride=2, padding=3),
                nn.BatchNorm2d(64),
                nn.ReLU(),
                nn.MaxPool2d(3, stride=2, padding=1),
                
                self._make_layer(64, 64, 2),
                self._make_layer(64, 128, 2, stride=2),
                self._make_layer(128, 256, 2, stride=2),
                self._make_layer(256, 512, 2, stride=2),
                
                nn.AdaptiveAvgPool2d((1, 1))
            )
            
            # ë¯¸ì  ì ìˆ˜ ì˜ˆì¸¡ í—¤ë“œë“¤
            self.aesthetic_heads = nn.ModuleDict({
                'composition': nn.Sequential(
                    nn.Linear(512, 256),
                    nn.ReLU(),
                    nn.Dropout(0.3),
                    nn.Linear(256, 1),
                    nn.Sigmoid()
                ),
                'color_harmony': nn.Sequential(
                    nn.Linear(512, 256),
                    nn.ReLU(),
                    nn.Linear(256, 1),
                    nn.Sigmoid()
                ),
                'lighting': nn.Sequential(
                    nn.Linear(512, 256),
                    nn.ReLU(),
                    nn.Linear(256, 1),
                    nn.Sigmoid()
                ),
                'symmetry': nn.Sequential(
                    nn.Linear(512, 128),
                    nn.ReLU(),
                    nn.Linear(128, 1),
                    nn.Sigmoid()
                ),
                'balance': nn.Sequential(
                    nn.Linear(512, 128),
                    nn.ReLU(),
                    nn.Linear(128, 1),
                    nn.Sigmoid()
                )
            })
        
        def _make_layer(self, in_channels, out_channels, blocks, stride=1):
            """ResNet ìŠ¤íƒ€ì¼ ë ˆì´ì–´ ìƒì„±"""
            layers = []
            layers.append(nn.Conv2d(in_channels, out_channels, 3, stride=stride, padding=1))
            layers.append(nn.BatchNorm2d(out_channels))
            layers.append(nn.ReLU())
            
            for _ in range(1, blocks):
                layers.append(nn.Conv2d(out_channels, out_channels, 3, padding=1))
                layers.append(nn.BatchNorm2d(out_channels))
                layers.append(nn.ReLU())
            
            return nn.Sequential(*layers)
        
        def forward(self, x):
            features = self.backbone(x)
            features = features.view(features.size(0), -1)
            
            results = {}
            for name, head in self.aesthetic_heads.items():
                results[name] = head(features)
            
            return results

else:
    # PyTorch ì—†ì„ ë•Œ ë”ë¯¸ í´ë˜ìŠ¤
    class EnhancedPerceptualQualityModel:
        def __init__(self):
            self.logger = logging.getLogger(__name__)
            self.logger.warning("PyTorch ì—†ìŒ - ë”ë¯¸ EnhancedPerceptualQualityModel")
        
        def predict(self, x):
            return {'overall': 0.7, 'sharpness': 0.8, 'artifacts': 0.9, 'noise': 0.8}
    
    class EnhancedAestheticQualityModel:
        def __init__(self):
            self.logger = logging.getLogger(__name__)
            self.logger.warning("PyTorch ì—†ìŒ - ë”ë¯¸ EnhancedAestheticQualityModel")
        
        def predict(self, x):
            return {'composition': 0.7, 'color_harmony': 0.8, 'lighting': 0.75, 'symmetry': 0.7, 'balance': 0.8}

# ==============================================
# ğŸ”¥ ModelLoaderInterface í´ë˜ìŠ¤ (ê¸°ì¡´ íŒŒì¼ì—ì„œ ê°€ì ¸ì˜´)
# ==============================================

class ModelLoaderInterface:
    """ModelLoader ì¸í„°í˜ì´ìŠ¤ (ìˆœí™˜ì°¸ì¡° í•´ê²°)"""
    
    def __init__(self):
        self._model_loader = None
        self._models = {}
        self.logger = logging.getLogger(f"{__name__}.ModelLoaderInterface")
    
    def set_model_loader(self, model_loader):
        """ModelLoader ì„¤ì • (ì˜ì¡´ì„± ì£¼ì…)"""
        self._model_loader = model_loader
        self.logger.info("âœ… ModelLoader ì˜ì¡´ì„± ì£¼ì… ì™„ë£Œ")
    
    async def load_model(self, model_name: str, **kwargs) -> Any:
        """ëª¨ë¸ ë¡œë“œ"""
        if self._model_loader:
            try:
                model = await self._model_loader.load_model(model_name, **kwargs)
                self._models[model_name] = model
                self.logger.info(f"âœ… ëª¨ë¸ ë¡œë“œ ì„±ê³µ: {model_name}")
                return model
            except Exception as e:
                self.logger.warning(f"âš ï¸ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨ {model_name}: {e}")
                return None
        else:
            self.logger.warning("âš ï¸ ModelLoaderê°€ ì„¤ì •ë˜ì§€ ì•ŠìŒ")
            return None
    
    def get_model(self, model_name: str) -> Any:
        """ë¡œë“œëœ ëª¨ë¸ ë°˜í™˜"""
        return self._models.get(model_name)
    
    def has_model(self, model_name: str) -> bool:
        """ëª¨ë¸ ì¡´ì¬ ì—¬ë¶€"""
        return model_name in self._models
    
    def cleanup(self):
        """ì¸í„°í˜ì´ìŠ¤ ì •ë¦¬"""
        self._models.clear()
        self.logger.info("âœ… ModelLoaderInterface ì •ë¦¬ ì™„ë£Œ")

# ==============================================
# ğŸ”¥ ì „ë¬¸ ë¶„ì„ê¸° í´ë˜ìŠ¤ë“¤ (ì™„ì „í•œ ë²„ì „)
# ==============================================

class TechnicalQualityAnalyzer:
    """ê¸°ìˆ ì  í’ˆì§ˆ ë¶„ì„ê¸° (í–¥ìƒëœ ë²„ì „)"""
    
    def __init__(self, device: str = "cpu", enable_gpu: bool = False):
        self.device = device
        self.enable_gpu = enable_gpu
        self.logger = logging.getLogger(f"{__name__}.TechnicalQualityAnalyzer")
        
        # ë¶„ì„ ìºì‹œ
        self.analysis_cache = {}
        
        # ê¸°ìˆ ì  ë¶„ì„ ì„ê³„ê°’ë“¤
        self.thresholds = {
            'sharpness_min': 100.0,
            'noise_max': 50.0,
            'contrast_min': 20.0,
            'brightness_range': (50, 200)
        }
    
    def analyze(self, image: np.ndarray) -> Dict[str, Any]:
        """ì¢…í•© ê¸°ìˆ ì  í’ˆì§ˆ ë¶„ì„"""
        try:
            results = {}
            
            # 1. ì„ ëª…ë„ ë¶„ì„
            results['sharpness'] = self._analyze_sharpness(image)
            
            # 2. ë…¸ì´ì¦ˆ ë ˆë²¨ ë¶„ì„
            results['noise_level'] = self._analyze_noise_level(image)
            
            # 3. ëŒ€ë¹„ ë¶„ì„
            results['contrast'] = self._analyze_contrast(image)
            
            # 4. ë°ê¸° ë¶„ì„
            results['brightness'] = self._analyze_brightness(image)
            
            # 5. í¬í™”ë„ ë¶„ì„
            results['saturation'] = self._analyze_saturation(image)
            
            # 6. ì•„í‹°íŒ©íŠ¸ ê²€ì¶œ
            results['artifacts'] = self._detect_artifacts(image)
            
            # 7. ì¢…í•© ì ìˆ˜ ê³„ì‚°
            results['overall_score'] = self._calculate_technical_score(results)
            
            return results
            
        except Exception as e:
            self.logger.error(f"âŒ ê¸°ìˆ ì  ë¶„ì„ ì‹¤íŒ¨: {e}")
            return self._get_fallback_technical_results()
    
    def analyze_comprehensive(self, image: np.ndarray, original: Optional[np.ndarray] = None) -> Dict[str, Any]:
        """ì¢…í•© ê¸°ìˆ ì  ë¶„ì„ (ì›ë³¸ ì´ë¯¸ì§€ì™€ ë¹„êµ)"""
        try:
            # ê¸°ë³¸ ë¶„ì„
            results = self.analyze(image)
            
            # ì›ë³¸ê³¼ì˜ ë¹„êµ ë¶„ì„
            if original is not None:
                comparison = self._compare_with_original(image, original)
                results.update(comparison)
            
            # ì„¸ë¶€ ë©”íŠ¸ë¦­ ì¶”ê°€
            results.update(self._calculate_advanced_metrics(image))
            
            return results
            
        except Exception as e:
            self.logger.error(f"âŒ ì¢…í•© ê¸°ìˆ ì  ë¶„ì„ ì‹¤íŒ¨: {e}")
            return self._get_fallback_technical_results()
    
    def _analyze_sharpness(self, image: np.ndarray) -> float:
        """ì„ ëª…ë„ ë¶„ì„"""
        try:
            if len(image.shape) == 3:
                gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY) if 'cv2' in globals() else np.mean(image, axis=2)
            else:
                gray = image
            
            if 'cv2' in globals():
                laplacian = cv2.Laplacian(gray.astype(np.uint8), cv2.CV_64F)
                sharpness = laplacian.var()
            else:
                # ê°„ë‹¨í•œ gradient ê¸°ë°˜ ì„ ëª…ë„
                dx = np.diff(gray, axis=1)
                dy = np.diff(gray, axis=0)
                sharpness = np.var(dx) + np.var(dy)
            
            # ì •ê·œí™” (0-1)
            normalized_sharpness = min(1.0, sharpness / 10000.0)
            return max(0.0, normalized_sharpness)
            
        except Exception as e:
            self.logger.error(f"ì„ ëª…ë„ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return 0.5
    
    def _analyze_noise_level(self, image: np.ndarray) -> float:
        """ë…¸ì´ì¦ˆ ë ˆë²¨ ë¶„ì„"""
        try:
            if len(image.shape) == 3:
                # ê° ì±„ë„ë³„ ë…¸ì´ì¦ˆ ë¶„ì„
                noise_levels = []
                for channel in range(3):
                    channel_data = image[:, :, channel]
                    # ê³ ì£¼íŒŒ ì„±ë¶„ ë¶„ì„
                    if 'cv2' in globals():
                        blur = cv2.GaussianBlur(channel_data.astype(np.uint8), (5, 5), 0)
                        noise = np.abs(channel_data.astype(float) - blur.astype(float))
                    else:
                        # ê°„ë‹¨í•œ ì´ë™í‰ê·  ê¸°ë°˜
                        kernel = np.ones((3, 3)) / 9
                        blur = np.convolve(channel_data.flatten(), kernel.flatten(), mode='same').reshape(channel_data.shape)
                        noise = np.abs(channel_data.astype(float) - blur)
                    
                    noise_level = np.mean(noise) / 255.0
                    noise_levels.append(noise_level)
                
                # í‰ê·  ë…¸ì´ì¦ˆ ë ˆë²¨
                avg_noise = np.mean(noise_levels)
            else:
                # ê·¸ë ˆì´ìŠ¤ì¼€ì¼
                if 'cv2' in globals():
                    blur = cv2.GaussianBlur(image.astype(np.uint8), (5, 5), 0)
                    noise = np.abs(image.astype(float) - blur.astype(float))
                else:
                    noise = np.std(image) / 255.0
                avg_noise = np.mean(noise) / 255.0 if 'cv2' in globals() else noise
            
            # ë…¸ì´ì¦ˆê°€ ì ì„ìˆ˜ë¡ í’ˆì§ˆì´ ì¢‹ìŒ (ì—­ìˆœ)
            return max(0.0, min(1.0, 1.0 - avg_noise * 5))
            
        except Exception as e:
            self.logger.error(f"ë…¸ì´ì¦ˆ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return 0.7
    
    def _analyze_contrast(self, image: np.ndarray) -> float:
        """ëŒ€ë¹„ ë¶„ì„"""
        try:
            if len(image.shape) == 3:
                gray = np.mean(image, axis=2)
            else:
                gray = image
            
            # RMS ëŒ€ë¹„ ê³„ì‚°
            contrast = np.std(gray)
            
            # ì •ê·œí™” (ì ì ˆí•œ ëŒ€ë¹„ ë²”ìœ„: 30-80)
            if 30 <= contrast <= 80:
                contrast_score = 1.0
            elif contrast < 30:
                contrast_score = contrast / 30.0
            else:
                contrast_score = max(0.3, 1.0 - (contrast - 80) / 100.0)
            
            return max(0.0, min(1.0, contrast_score))
            
        except Exception as e:
            self.logger.error(f"ëŒ€ë¹„ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return 0.6
    
    def _analyze_brightness(self, image: np.ndarray) -> float:
        """ë°ê¸° ë¶„ì„"""
        try:
            if len(image.shape) == 3:
                brightness = np.mean(image)
            else:
                brightness = np.mean(image)
            
            # ì ì ˆí•œ ë°ê¸° ë²”ìœ„ (100-160)
            if 100 <= brightness <= 160:
                brightness_score = 1.0
            elif brightness < 100:
                brightness_score = brightness / 100.0
            else:
                brightness_score = max(0.3, 1.0 - (brightness - 160) / 95.0)
            
            return max(0.0, min(1.0, brightness_score))
            
        except Exception as e:
            self.logger.error(f"ë°ê¸° ë¶„ì„ ì‹¤íŒ¨: {e}")
            return 0.6
    
    def _analyze_saturation(self, image: np.ndarray) -> float:
        """í¬í™”ë„ ë¶„ì„"""
        try:
            if len(image.shape) != 3:
                return 0.5
            
            # HSV ë³€í™˜ ë° í¬í™”ë„ ë¶„ì„
            if 'cv2' in globals():
                hsv = cv2.cvtColor(image.astype(np.uint8), cv2.COLOR_RGB2HSV)
                saturation = np.mean(hsv[:, :, 1])
            else:
                # RGB ê¸°ë°˜ í¬í™”ë„ ê·¼ì‚¬
                max_vals = np.max(image, axis=2)
                min_vals = np.min(image, axis=2)
                saturation = np.mean((max_vals - min_vals) / (max_vals + 1e-8)) * 255
            
            # ì ì ˆí•œ í¬í™”ë„ ë²”ìœ„ (80-180)
            if 80 <= saturation <= 180:
                saturation_score = 1.0
            elif saturation < 80:
                saturation_score = saturation / 80.0
            else:
                saturation_score = max(0.3, 1.0 - (saturation - 180) / 75.0)
            
            return max(0.0, min(1.0, saturation_score))
            
        except Exception as e:
            self.logger.error(f"í¬í™”ë„ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return 0.6
    
    def _detect_artifacts(self, image: np.ndarray) -> float:
        """ì•„í‹°íŒ©íŠ¸ ê²€ì¶œ"""
        try:
            artifact_score = 1.0  # ê¸°ë³¸ê°’: ì•„í‹°íŒ©íŠ¸ ì—†ìŒ
            
            # 1. ë¸”ë¡œí‚¹ ì•„í‹°íŒ©íŠ¸ ê²€ì¶œ
            blocking_score = self._detect_blocking_artifacts(image)
            
            # 2. ë§ì‰ ì•„í‹°íŒ©íŠ¸ ê²€ì¶œ
            ringing_score = self._detect_ringing_artifacts(image)
            
            # 3. ì••ì¶• ì•„í‹°íŒ©íŠ¸ ê²€ì¶œ
            compression_score = self._detect_compression_artifacts(image)
            
            # ì¢…í•© ì•„í‹°íŒ©íŠ¸ ì ìˆ˜ (ë†’ì„ìˆ˜ë¡ ì•„í‹°íŒ©íŠ¸ ì ìŒ)
            artifact_score = np.mean([blocking_score, ringing_score, compression_score])
            
            return max(0.0, min(1.0, artifact_score))
            
        except Exception as e:
            self.logger.error(f"ì•„í‹°íŒ©íŠ¸ ê²€ì¶œ ì‹¤íŒ¨: {e}")
            return 0.8
    
    def _detect_blocking_artifacts(self, image: np.ndarray) -> float:
        """ë¸”ë¡œí‚¹ ì•„í‹°íŒ©íŠ¸ ê²€ì¶œ"""
        try:
            # 8x8 ë¸”ë¡ ê²½ê³„ì—ì„œì˜ ë¶ˆì—°ì†ì„± ê²€ì‚¬
            if len(image.shape) == 3:
                gray = np.mean(image, axis=2)
            else:
                gray = image
            
            h, w = gray.shape
            blocking_score = 1.0
            
            # ìˆ˜ì§/ìˆ˜í‰ ë¸”ë¡ ê²½ê³„ ê²€ì‚¬
            for i in range(8, h-8, 8):
                diff = np.mean(np.abs(gray[i, :] - gray[i-1, :]))
                if diff > 10:  # ì„ê³„ê°’
                    blocking_score -= 0.1
            
            for j in range(8, w-8, 8):
                diff = np.mean(np.abs(gray[:, j] - gray[:, j-1]))
                if diff > 10:  # ì„ê³„ê°’
                    blocking_score -= 0.1
            
            return max(0.0, blocking_score)
            
        except Exception as e:
            return 0.9
    
    def _detect_ringing_artifacts(self, image: np.ndarray) -> float:
        """ë§ì‰ ì•„í‹°íŒ©íŠ¸ ê²€ì¶œ"""
        try:
            # ì—ì§€ ê·¼ì²˜ì˜ ì§„ë™ íŒ¨í„´ ê²€ì¶œ
            if 'cv2' in globals() and len(image.shape) == 3:
                gray = cv2.cvtColor(image.astype(np.uint8), cv2.COLOR_RGB2GRAY)
                edges = cv2.Canny(gray, 50, 150)
                
                # ì—ì§€ ê·¼ì²˜ì˜ ê³ ì£¼íŒŒ ì„±ë¶„ ë¶„ì„
                kernel = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]])
                enhanced = cv2.filter2D(gray, -1, kernel)
                
                # ë§ì‰ ì •ë„ ê³„ì‚°
                ringing_metric = np.mean(np.abs(enhanced - gray))
                ringing_score = max(0.0, 1.0 - ringing_metric / 50.0)
            else:
                ringing_score = 0.9  # ê¸°ë³¸ê°’
            
            return ringing_score
            
        except Exception as e:
            return 0.9
    
    def _detect_compression_artifacts(self, image: np.ndarray) -> float:
        """ì••ì¶• ì•„í‹°íŒ©íŠ¸ ê²€ì¶œ"""
        try:
            # DCT ê³„ìˆ˜ ë¶„ì„ ê¸°ë°˜ ì••ì¶• ì•„í‹°íŒ©íŠ¸ ê²€ì¶œ
            if len(image.shape) == 3:
                gray = np.mean(image, axis=2)
            else:
                gray = image
            
            # ê³ ì£¼íŒŒ ì„±ë¶„ ì†ì‹¤ ì •ë„ ë¶„ì„
            if 'cv2' in globals():
                # ë¼í”Œë¼ì‹œì•ˆ í•„í„°ë¡œ ê³ ì£¼íŒŒ ì„±ë¶„ ì¶”ì¶œ
                laplacian = cv2.Laplacian(gray.astype(np.uint8), cv2.CV_64F)
                high_freq_energy = np.var(laplacian)
                
                # ì••ì¶•ë˜ì§€ ì•Šì€ ì´ë¯¸ì§€ì˜ ì˜ˆìƒ ê³ ì£¼íŒŒ ì—ë„ˆì§€ì™€ ë¹„êµ
                expected_energy = np.var(gray) * 0.1  # ì¶”ì •ê°’
                compression_score = min(1.0, high_freq_energy / (expected_energy + 1e-8))
            else:
                compression_score = 0.8  # ê¸°ë³¸ê°’
            
            return max(0.0, compression_score)
            
        except Exception as e:
            return 0.8
    
    def _calculate_technical_score(self, results: Dict[str, Any]) -> float:
        """ê¸°ìˆ ì  í’ˆì§ˆ ì¢…í•© ì ìˆ˜ ê³„ì‚°"""
        try:
            # ê°€ì¤‘ì¹˜ ì„¤ì •
            weights = {
                'sharpness': 0.25,
                'noise_level': 0.20,
                'contrast': 0.15,
                'brightness': 0.15,
                'saturation': 0.10,
                'artifacts': 0.15
            }
            
            # ê°€ì¤‘ í‰ê·  ê³„ì‚°
            total_score = 0.0
            total_weight = 0.0
            
            for metric, weight in weights.items():
                if metric in results:
                    total_score += results[metric] * weight
                    total_weight += weight
            
            # ì •ê·œí™”
            if total_weight > 0:
                final_score = total_score / total_weight
            else:
                final_score = 0.5
            
            return max(0.0, min(1.0, final_score))
            
        except Exception as e:
            self.logger.error(f"ê¸°ìˆ ì  ì ìˆ˜ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return 0.5
    
    def _compare_with_original(self, processed: np.ndarray, original: np.ndarray) -> Dict[str, Any]:
        """ì›ë³¸ ì´ë¯¸ì§€ì™€ì˜ ë¹„êµ ë¶„ì„"""
        try:
            comparison = {}
            
            # 1. êµ¬ì¡°ì  ìœ ì‚¬ì„±
            comparison['structural_similarity'] = self._calculate_ssim(processed, original)
            
            # 2. í”¼í¬ ì‹ í˜¸ ëŒ€ ë…¸ì´ì¦ˆ ë¹„ìœ¨
            comparison['psnr'] = self._calculate_psnr(processed, original)
            
            # 3. í‰ê·  ì œê³± ì˜¤ì°¨
            comparison['mse'] = self._calculate_mse(processed, original)
            
            return comparison
            
        except Exception as e:
            self.logger.error(f"ì›ë³¸ ë¹„êµ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {}
    
    def _calculate_ssim(self, img1: np.ndarray, img2: np.ndarray) -> float:
        """êµ¬ì¡°ì  ìœ ì‚¬ì„± ì§€ìˆ˜ ê³„ì‚° (ê°„ë‹¨ ë²„ì „)"""
        try:
            # ì´ë¯¸ì§€ í¬ê¸° ë§ì¶”ê¸°
            h1, w1 = img1.shape[:2]
            h2, w2 = img2.shape[:2]
            
            if h1 != h2 or w1 != w2:
                min_h, min_w = min(h1, h2), min(w1, w2)
                img1 = img1[:min_h, :min_w]
                img2 = img2[:min_h, :min_w]
            
            # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜
            if len(img1.shape) == 3:
                gray1 = np.mean(img1, axis=2)
            else:
                gray1 = img1
                
            if len(img2.shape) == 3:
                gray2 = np.mean(img2, axis=2)
            else:
                gray2 = img2
            
            # ê°„ë‹¨í•œ SSIM ê³„ì‚°
            mu1, mu2 = np.mean(gray1), np.mean(gray2)
            sigma1, sigma2 = np.var(gray1), np.var(gray2)
            sigma12 = np.mean((gray1 - mu1) * (gray2 - mu2))
            
            c1, c2 = 0.01**2, 0.03**2
            
            ssim = ((2*mu1*mu2 + c1) * (2*sigma12 + c2)) / ((mu1**2 + mu2**2 + c1) * (sigma1 + sigma2 + c2))
            
            return max(0.0, min(1.0, ssim))
            
        except Exception as e:
            self.logger.error(f"SSIM ê³„ì‚° ì‹¤íŒ¨: {e}")
            return 0.7
    
    def _calculate_psnr(self, img1: np.ndarray, img2: np.ndarray) -> float:
        """í”¼í¬ ì‹ í˜¸ ëŒ€ ë…¸ì´ì¦ˆ ë¹„ìœ¨ ê³„ì‚°"""
        try:
            mse = self._calculate_mse(img1, img2)
            if mse == 0:
                return 100.0  # ì™„ì „íˆ ë™ì¼
            
            psnr = 20 * np.log10(255.0 / np.sqrt(mse))
            
            # 0-1 ë²”ìœ„ë¡œ ì •ê·œí™” (40dB ì´ìƒì„ 1.0ìœ¼ë¡œ)
            normalized_psnr = min(1.0, psnr / 40.0)
            
            return max(0.0, normalized_psnr)
            
        except Exception as e:
            self.logger.error(f"PSNR ê³„ì‚° ì‹¤íŒ¨: {e}")
            return 0.7
    
    def _calculate_mse(self, img1: np.ndarray, img2: np.ndarray) -> float:
        """í‰ê·  ì œê³± ì˜¤ì°¨ ê³„ì‚°"""
        try:
            # ì´ë¯¸ì§€ í¬ê¸° ë° íƒ€ì… ë§ì¶”ê¸°
            h1, w1 = img1.shape[:2]
            h2, w2 = img2.shape[:2]
            
            if h1 != h2 or w1 != w2:
                min_h, min_w = min(h1, h2), min(w1, w2)
                img1 = img1[:min_h, :min_w]
                img2 = img2[:min_h, :min_w]
            
            # MSE ê³„ì‚°
            mse = np.mean((img1.astype(float) - img2.astype(float)) ** 2)
            
            return mse
            
        except Exception as e:
            self.logger.error(f"MSE ê³„ì‚° ì‹¤íŒ¨: {e}")
            return 100.0
    
    def _calculate_advanced_metrics(self, image: np.ndarray) -> Dict[str, Any]:
        """ê³ ê¸‰ ê¸°ìˆ ì  ë©”íŠ¸ë¦­ ê³„ì‚°"""
        try:
            metrics = {}
            
            # 1. ì—”íŠ¸ë¡œí”¼ (ì •ë³´ëŸ‰)
            metrics['entropy'] = self._calculate_entropy(image)
            
            # 2. ì—ì§€ ë°€ë„
            metrics['edge_density'] = self._calculate_edge_density(image)
            
            # 3. í…ìŠ¤ì²˜ ë³µì¡ë„
            metrics['texture_complexity'] = self._calculate_texture_complexity(image)
            
            return metrics
            
        except Exception as e:
            self.logger.error(f"ê³ ê¸‰ ë©”íŠ¸ë¦­ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return {}
    
    def _calculate_entropy(self, image: np.ndarray) -> float:
        """ì´ë¯¸ì§€ ì—”íŠ¸ë¡œí”¼ ê³„ì‚°"""
        try:
            if len(image.shape) == 3:
                gray = np.mean(image, axis=2)
            else:
                gray = image
            
            # íˆìŠ¤í† ê·¸ë¨ ê³„ì‚°
            hist, _ = np.histogram(gray, bins=256, range=(0, 256))
            hist = hist / hist.sum()  # ì •ê·œí™”
            
            # ì—”íŠ¸ë¡œí”¼ ê³„ì‚°
            entropy = -np.sum(hist * np.log2(hist + 1e-8))
            
            # 0-1 ë²”ìœ„ë¡œ ì •ê·œí™” (ìµœëŒ€ ì—”íŠ¸ë¡œí”¼ëŠ” 8)
            return min(1.0, entropy / 8.0)
            
        except Exception as e:
            return 0.5
    
    def _calculate_edge_density(self, image: np.ndarray) -> float:
        """ì—ì§€ ë°€ë„ ê³„ì‚°"""
        try:
            if 'cv2' in globals():
                if len(image.shape) == 3:
                    gray = cv2.cvtColor(image.astype(np.uint8), cv2.COLOR_RGB2GRAY)
                else:
                    gray = image.astype(np.uint8)
                
                edges = cv2.Canny(gray, 50, 150)
                edge_density = np.sum(edges > 0) / edges.size
            else:
                # ê°„ë‹¨í•œ gradient ê¸°ë°˜
                if len(image.shape) == 3:
                    gray = np.mean(image, axis=2)
                else:
                    gray = image
                
                dx = np.abs(np.diff(gray, axis=1))
                dy = np.abs(np.diff(gray, axis=0))
                edge_density = (np.sum(dx > 10) + np.sum(dy > 10)) / gray.size
            
            return min(1.0, edge_density * 10)  # ìŠ¤ì¼€ì¼ë§
            
        except Exception as e:
            return 0.3
    
    def _calculate_texture_complexity(self, image: np.ndarray) -> float:
        """í…ìŠ¤ì²˜ ë³µì¡ë„ ê³„ì‚°"""
        try:
            if len(image.shape) == 3:
                gray = np.mean(image, axis=2)
            else:
                gray = image
            
            # ì§€ì—­ í‘œì¤€í¸ì°¨ ê¸°ë°˜ í…ìŠ¤ì²˜ ë³µì¡ë„
            kernel_size = 5
            kernel = np.ones((kernel_size, kernel_size)) / (kernel_size ** 2)
            
            # ì§€ì—­ í‰ê· 
            mean_img = cv2.filter2D(gray, -1, kernel) if 'cv2' in globals() else gray
            
            # ì§€ì—­ ë¶„ì‚°
            var_img = cv2.filter2D((gray - mean_img)**2, -1, kernel) if 'cv2' in globals() else np.var(gray)
            
            # í‰ê·  í…ìŠ¤ì²˜ ë³µì¡ë„
            if 'cv2' in globals():
                complexity = np.mean(np.sqrt(var_img))
            else:
                complexity = np.sqrt(var_img) if isinstance(var_img, (int, float)) else np.sqrt(np.mean(var_img))
            
            # ì •ê·œí™”
            return min(1.0, complexity / 50.0)
            
        except Exception as e:
            return 0.5
    
    def _get_fallback_technical_results(self) -> Dict[str, Any]:
        """í´ë°± ê¸°ìˆ ì  ë¶„ì„ ê²°ê³¼"""
        return {
            'sharpness': 0.5,
            'noise_level': 0.6,
            'contrast': 0.5,
            'brightness': 0.6,
            'saturation': 0.5,
            'artifacts': 0.7,
            'overall_score': 0.55,
            'analysis_method': 'fallback'
        }
    
    def cleanup(self):
        """ë¶„ì„ê¸° ì •ë¦¬"""
        self.analysis_cache.clear()

class FittingQualityAnalyzer:
    """ê¸°ëŠ¥ì  í’ˆì§ˆ ë¶„ì„ê¸° (í”¼íŒ… ì „ë¬¸)"""
    
    def __init__(self, device: str = "cpu"):
        self.device = device
        self.logger = logging.getLogger(f"{__name__}.FittingQualityAnalyzer")
        
        # ì˜ë¥˜ íƒ€ì…ë³„ ê¸°ëŒ€ ë¹„ìœ¨
        self.clothing_ratios = {
            'shirt': {'aspect_ratio': (0.7, 1.3), 'coverage': (0.3, 0.7)},
            'dress': {'aspect_ratio': (0.5, 1.0), 'coverage': (0.5, 0.9)},
            'pants': {'aspect_ratio': (0.8, 1.2), 'coverage': (0.4, 0.8)},
            'jacket': {'aspect_ratio': (0.6, 1.2), 'coverage': (0.4, 0.8)},
            'skirt': {'aspect_ratio': (0.8, 1.4), 'coverage': (0.2, 0.6)},
            'top': {'aspect_ratio': (0.7, 1.4), 'coverage': (0.2, 0.6)},
            'default': {'aspect_ratio': (0.5, 1.5), 'coverage': (0.2, 0.9)}
        }
    
    def analyze(self, image: np.ndarray, clothing_type: str = "default") -> Dict[str, Any]:
        """ê¸°ëŠ¥ì  í’ˆì§ˆ ë¶„ì„ ì‹¤í–‰"""
        try:
            results = {}
            
            # 1. í”¼íŒ… ì •í™•ë„ ë¶„ì„
            results['fitting_accuracy'] = self._analyze_fitting_accuracy(image, clothing_type)
            
            # 2. ì˜ë¥˜ ì •ë ¬ ë¶„ì„
            results['clothing_alignment'] = self._analyze_clothing_alignment(image)
            
            # 3. ìì—°ìŠ¤ëŸ¬ì›€ ë¶„ì„
            results['naturalness'] = self._analyze_naturalness(image)
            
            # 4. ì—ì§€ ë³´ì¡´ë„ ë¶„ì„
            results['edge_preservation'] = self._analyze_edge_preservation(image)
            
            # 5. í…ìŠ¤ì²˜ í’ˆì§ˆ ë¶„ì„
            results['texture_quality'] = self._analyze_texture_quality(image)
            
            # 6. ì„¸ë¶€ì‚¬í•­ ë³´ì¡´ë„ ë¶„ì„
            results['detail_preservation'] = self._analyze_detail_preservation(image)
            
            # 7. ì¢…í•© ì ìˆ˜ ê³„ì‚°
            results['overall_score'] = self._calculate_fitting_score(results)
            
            return results
            
        except Exception as e:
            self.logger.error(f"âŒ ê¸°ëŠ¥ì  ë¶„ì„ ì‹¤íŒ¨: {e}")
            return self._get_fallback_fitting_results()
    
    def analyze_comprehensive(self, image: np.ndarray, original: Optional[np.ndarray] = None, clothing_type: str = "default") -> Dict[str, Any]:
        """ì¢…í•© ê¸°ëŠ¥ì  ë¶„ì„"""
        try:
            # ê¸°ë³¸ ë¶„ì„
            results = self.analyze(image, clothing_type)
            
            # ì›ë³¸ê³¼ì˜ ë¹„êµ ë¶„ì„
            if original is not None:
                comparison = self._compare_fitting_quality(image, original)
                results.update(comparison)
            
            # ê³ ê¸‰ ë©”íŠ¸ë¦­ ì¶”ê°€
            advanced_metrics = self._calculate_advanced_fitting_metrics(image, clothing_type)
            results.update(advanced_metrics)
            
            return results
            
        except Exception as e:
            self.logger.error(f"âŒ ì¢…í•© ê¸°ëŠ¥ì  ë¶„ì„ ì‹¤íŒ¨: {e}")
            return self._get_fallback_fitting_results()
    
    def _analyze_fitting_accuracy(self, image: np.ndarray, clothing_type: str) -> float:
        """í”¼íŒ… ì •í™•ë„ ë¶„ì„"""
        try:
            height, width = image.shape[:2]
            aspect_ratio = width / height
            
            # ì˜ë¥˜ íƒ€ì…ë³„ ê¸°ëŒ€ ë¹„ìœ¨
            expected = self.clothing_ratios.get(clothing_type, self.clothing_ratios['default'])
            min_ratio, max_ratio = expected['aspect_ratio']
            
            # ë¹„ìœ¨ ì ìˆ˜ ê³„ì‚°
            if min_ratio <= aspect_ratio <= max_ratio:
                ratio_score = 1.0
            else:
                center_ratio = (min_ratio + max_ratio) / 2
                ratio_score = max(0.0, 1.0 - abs(aspect_ratio - center_ratio) * 2)
            
            # ì»¤ë²„ë¦¬ì§€ ë¶„ì„ (ì˜ë¥˜ê°€ ì°¨ì§€í•˜ëŠ” ì˜ì—­)
            coverage_score = self._analyze_clothing_coverage(image, expected['coverage'])
            
            # ì¢…í•© í”¼íŒ… ì •í™•ë„
            fitting_accuracy = (ratio_score * 0.6 + coverage_score * 0.4)
            
            return max(0.0, min(1.0, fitting_accuracy))
            
        except Exception as e:
            self.logger.error(f"í”¼íŒ… ì •í™•ë„ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return 0.5
    
    def _analyze_clothing_coverage(self, image: np.ndarray, expected_coverage: Tuple[float, float]) -> float:
        """ì˜ë¥˜ ì»¤ë²„ë¦¬ì§€ ë¶„ì„"""
        try:
            # ì˜ë¥˜ ì˜ì—­ ì¶”ì • (ìƒ‰ìƒ ê¸°ë°˜ ê°„ë‹¨í•œ ì„¸ê·¸ë©˜í…Œì´ì…˜)
            if len(image.shape) == 3:
                # ë°°ê²½ê³¼ ì „ê²½ êµ¬ë¶„ (ê°„ë‹¨í•œ ì„ê³„ê°’ ê¸°ë°˜)
                gray = np.mean(image, axis=2)
                
                # Otsu's ë°©ë²• ê·¼ì‚¬
                if 'cv2' in globals():
                    _, binary = cv2.threshold(gray.astype(np.uint8), 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
                    clothing_pixels = np.sum(binary > 0)
                else:
                    # ê°„ë‹¨í•œ ì„ê³„ê°’
                    threshold = np.mean(gray)
                    clothing_pixels = np.sum(gray > threshold)
                
                total_pixels = gray.size
                coverage_ratio = clothing_pixels / total_pixels
            else:
                # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ì˜ ê²½ìš°
                threshold = np.mean(image)
                coverage_ratio = np.sum(image > threshold) / image.size
            
            # ê¸°ëŒ€ ì»¤ë²„ë¦¬ì§€ì™€ ë¹„êµ
            min_coverage, max_coverage = expected_coverage
            
            if min_coverage <= coverage_ratio <= max_coverage:
                coverage_score = 1.0
            else:
                center_coverage = (min_coverage + max_coverage) / 2
                coverage_score = max(0.0, 1.0 - abs(coverage_ratio - center_coverage) * 3)
            
            return coverage_score
            
        except Exception as e:
            self.logger.error(f"ì»¤ë²„ë¦¬ì§€ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return 0.6
    
    def _analyze_clothing_alignment(self, image: np.ndarray) -> float:
        """ì˜ë¥˜ ì •ë ¬ ë¶„ì„"""
        try:
            height, width = image.shape[:2]
            
            # ì¢Œìš° ëŒ€ì¹­ì„± ë¶„ì„
            left_half = image[:, :width//2]
            right_half = image[:, width//2:]
            right_half_flipped = np.flip(right_half, axis=1)
            
            # í¬ê¸° ë§ì¶”ê¸°
            min_width = min(left_half.shape[1], right_half_flipped.shape[1])
            left_half = left_half[:, :min_width]
            right_half_flipped = right_half_flipped[:, :min_width]
            
            # ì°¨ì´ ê³„ì‚°
            diff = np.mean(np.abs(left_half.astype(float) - right_half_flipped.astype(float)))
            symmetry_score = max(0.0, 1.0 - diff / 128.0)  # ì •ê·œí™”
            
            # ìˆ˜ì§ ì •ë ¬ ë¶„ì„ (ì¤‘ì‹¬ì„  ê¸°ì¤€)
            center_col = width // 2
            center_line = image[:, max(0, center_col-2):min(width, center_col+3)]
            
            # ì¤‘ì‹¬ì„ ì˜ ì¼ê´€ì„± ë¶„ì„
            if center_line.size > 0:
                vertical_consistency = 1.0 - np.std(np.mean(center_line, axis=1)) / 255.0
                vertical_consistency = max(0.0, min(1.0, vertical_consistency))
            else:
                vertical_consistency = 0.5
            
            # ì¢…í•© ì •ë ¬ ì ìˆ˜
            alignment_score = (symmetry_score * 0.7 + vertical_consistency * 0.3)
            
            return max(0.0, min(1.0, alignment_score))
            
        except Exception as e:
            self.logger.error(f"ì˜ë¥˜ ì •ë ¬ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return 0.5
    
    def _analyze_naturalness(self, image: np.ndarray) -> float:
        """ìì—°ìŠ¤ëŸ¬ì›€ ë¶„ì„"""
        try:
            naturalness_scores = []
            
            # 1. ìƒ‰ìƒ ë¶„í¬ì˜ ìì—°ìŠ¤ëŸ¬ì›€
            color_naturalness = self._analyze_color_naturalness_detailed(image)
            naturalness_scores.append(color_naturalness)
            
            # 2. ê²½ê³„ì„ ì˜ ë¶€ë“œëŸ¬ì›€
            edge_smoothness = self._analyze_edge_smoothness(image)
            naturalness_scores.append(edge_smoothness)
            
            # 3. ê·¸ë¼ë””ì–¸íŠ¸ì˜ ì—°ì†ì„±
            gradient_continuity = self._analyze_gradient_continuity(image)
            naturalness_scores.append(gradient_continuity)
            
            # 4. ì¡°ëª…ì˜ ì¼ê´€ì„±
            lighting_consistency = self._analyze_lighting_consistency(image)
            naturalness_scores.append(lighting_consistency)
            
            # ì¢…í•© ìì—°ìŠ¤ëŸ¬ì›€ ì ìˆ˜
            overall_naturalness = np.mean(naturalness_scores)
            
            return max(0.0, min(1.0, overall_naturalness))
            
        except Exception as e:
            self.logger.error(f"ìì—°ìŠ¤ëŸ¬ì›€ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return 0.5
    
    def _analyze_color_naturalness_detailed(self, image: np.ndarray) -> float:
        """ì„¸ë°€í•œ ìƒ‰ìƒ ìì—°ìŠ¤ëŸ¬ì›€ ë¶„ì„"""
        try:
            if len(image.shape) != 3:
                return 0.5
            
            # HSV ìƒ‰ê³µê°„ì—ì„œ ë¶„ì„
            if 'cv2' in globals():
                hsv = cv2.cvtColor(image.astype(np.uint8), cv2.COLOR_RGB2HSV)
                
                # ìƒ‰ì¡° ë¶„í¬ ë¶„ì„
                hue = hsv[:, :, 0]
                hue_variance = np.var(hue)
                hue_score = min(1.0, hue_variance / 1000.0)  # ì ì ˆí•œ ìƒ‰ì¡° ë‹¤ì–‘ì„±
                
                # í¬í™”ë„ ë¶„ì„
                saturation = hsv[:, :, 1]
                sat_mean = np.mean(saturation)
                sat_score = 1.0 - abs(sat_mean - 128) / 128.0  # ì ì ˆí•œ í¬í™”ë„
                
                # ëª…ë„ ë¶„ì„
                value = hsv[:, :, 2]
                val_mean = np.mean(value)
                val_score = 1.0 - abs(val_mean - 128) / 128.0  # ì ì ˆí•œ ëª…ë„
                
                color_naturalness = np.mean([hue_score, sat_score, val_score])
            else:
                # RGB ê¸°ë°˜ ê°„ë‹¨í•œ ë¶„ì„
                r_var, g_var, b_var = np.var(image[:,:,0]), np.var(image[:,:,1]), np.var(image[:,:,2])
                color_variance = np.mean([r_var, g_var, b_var])
                color_naturalness = min(1.0, color_variance / 2000.0)
            
            return max(0.0, min(1.0, color_naturalness))
            
        except Exception as e:
            return 0.6
    
    def _analyze_edge_smoothness(self, image: np.ndarray) -> float:
        """ê²½ê³„ì„  ë¶€ë“œëŸ¬ì›€ ë¶„ì„"""
        try:
            if 'cv2' in globals():
                if len(image.shape) == 3:
                    gray = cv2.cvtColor(image.astype(np.uint8), cv2.COLOR_RGB2GRAY)
                else:
                    gray = image.astype(np.uint8)
                
                # Canny ì—ì§€ ê²€ì¶œ
                edges = cv2.Canny(gray, 50, 150)
                
                # ì—ì§€ ë°€ë„ ê³„ì‚°
                edge_density = np.sum(edges > 0) / edges.size
                
                # ì ì ˆí•œ ì—ì§€ ë°€ë„ (0.05-0.15)
                if 0.05 <= edge_density <= 0.15:
                    smoothness_score = 1.0
                else:
                    smoothness_score = max(0.0, 1.0 - abs(edge_density - 0.1) * 10)
                
                # ì—ì§€ì˜ ì—°ì†ì„± ë¶„ì„
                contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                
                if contours:
                    # ê°€ì¥ í° ì»¨íˆ¬ì–´ì˜ ë¶€ë“œëŸ¬ì›€ ë¶„ì„
                    largest_contour = max(contours, key=cv2.contourArea)
                    if len(largest_contour) > 10:
                        # ê³¡ë¥  ë³€í™”ëŸ‰ ë¶„ì„ (ê°„ë‹¨ ë²„ì „)
                        contour_smoothness = self._calculate_contour_smoothness(largest_contour)
                        smoothness_score = (smoothness_score + contour_smoothness) / 2
                
            else:
                # OpenCV ì—†ì„ ë•Œ ê°„ë‹¨í•œ gradient ë¶„ì„
                if len(image.shape) == 3:
                    gray = np.mean(image, axis=2)
                else:
                    gray = image
                
                dx = np.abs(np.diff(gray, axis=1))
                dy = np.abs(np.diff(gray, axis=0))
                edge_strength = np.mean(dx) + np.mean(dy)
                
                # ì ì ˆí•œ ì—ì§€ ê°•ë„
                smoothness_score = max(0.0, 1.0 - edge_strength / 100.0)
            
            return max(0.0, min(1.0, smoothness_score))
            
        except Exception as e:
            return 0.6
    
    def _calculate_contour_smoothness(self, contour: np.ndarray) -> float:
        """ì»¨íˆ¬ì–´ ë¶€ë“œëŸ¬ì›€ ê³„ì‚°"""
        try:
            if len(contour) < 3:
                return 0.5
            
            # ì»¨íˆ¬ì–´ í¬ì¸íŠ¸ë“¤ ê°„ì˜ ê°ë„ ë³€í™”ëŸ‰ ê³„ì‚°
            angles = []
            for i in range(1, len(contour) - 1):
                p1 = contour[i-1][0]
                p2 = contour[i][0]
                p3 = contour[i+1][0]
                
                # ë²¡í„° ê³„ì‚°
                v1 = p2 - p1
                v2 = p3 - p2
                
                # ê°ë„ ê³„ì‚°
                if np.linalg.norm(v1) > 0 and np.linalg.norm(v2) > 0:
                    cos_angle = np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))
                    cos_angle = np.clip(cos_angle, -1, 1)
                    angle = np.arccos(cos_angle)
                    angles.append(angle)
            
            if angles:
                angle_variance = np.var(angles)
                smoothness = max(0.0, 1.0 - angle_variance)
            else:
                smoothness = 0.5
            
            return smoothness
            
        except Exception as e:
            return 0.5
    
    def _analyze_gradient_continuity(self, image: np.ndarray) -> float:
        """ê·¸ë¼ë””ì–¸íŠ¸ ì—°ì†ì„± ë¶„ì„"""
        try:
            if len(image.shape) == 3:
                gray = np.mean(image, axis=2)
            else:
                gray = image
            
            # 1ì°¨ ë¯¸ë¶„ (ê·¸ë¼ë””ì–¸íŠ¸)
            dx = np.diff(gray, axis=1)
            dy = np.diff(gray, axis=0)
            
            # 2ì°¨ ë¯¸ë¶„ (ê·¸ë¼ë””ì–¸íŠ¸ì˜ ë³€í™”)
            ddx = np.diff(dx, axis=1)
            ddy = np.diff(dy, axis=0)
            
            # 2ì°¨ ë¯¸ë¶„ì˜ ë¶„ì‚°ì´ ë‚®ì„ìˆ˜ë¡ ì—°ì†ì„±ì´ ì¢‹ìŒ
            gradient_variance = np.var(ddx) + np.var(ddy)
            continuity_score = max(0.0, 1.0 - gradient_variance / 1000.0)
            
            return max(0.0, min(1.0, continuity_score))
            
        except Exception as e:
            return 0.6
    
    def _analyze_lighting_consistency(self, image: np.ndarray) -> float:
        """ì¡°ëª… ì¼ê´€ì„± ë¶„ì„"""
        try:
            if len(image.shape) == 3:
                # RGB ê° ì±„ë„ì˜ ë°ê¸° ë¶„í¬ ë¶„ì„
                brightness_maps = []
                for channel in range(3):
                    brightness_maps.append(image[:, :, channel])
                
                # ê° ì˜ì—­ë³„ ë°ê¸° ì¼ê´€ì„± ì²´í¬
                h, w = image.shape[:2]
                regions = [
                    image[:h//2, :w//2],    # ì¢Œìƒ
                    image[:h//2, w//2:],    # ìš°ìƒ
                    image[h//2:, :w//2],    # ì¢Œí•˜
                    image[h//2:, w//2:]     # ìš°í•˜
                ]
                
                region_brightness = [np.mean(region) for region in regions]
                brightness_std = np.std(region_brightness)
                
                # í‘œì¤€í¸ì°¨ê°€ ë‚®ì„ìˆ˜ë¡ ì¼ê´€ì„±ì´ ì¢‹ìŒ
                consistency_score = max(0.0, 1.0 - brightness_std / 50.0)
            else:
                # ê·¸ë ˆì´ìŠ¤ì¼€ì¼
                brightness_std = np.std(image)
                consistency_score = max(0.0, 1.0 - brightness_std / 100.0)
            
            return max(0.0, min(1.0, consistency_score))
            
        except Exception as e:
            return 0.6
    
    def _analyze_edge_preservation(self, image: np.ndarray) -> float:
        """ì—ì§€ ë³´ì¡´ë„ ë¶„ì„"""
        try:
            # ì—ì§€ ê²€ì¶œ ë° í’ˆì§ˆ í‰ê°€
            if 'cv2' in globals():
                if len(image.shape) == 3:
                    gray = cv2.cvtColor(image.astype(np.uint8), cv2.COLOR_RGB2GRAY)
                else:
                    gray = image.astype(np.uint8)
                
                # ë‹¤ì¤‘ ìŠ¤ì¼€ì¼ ì—ì§€ ê²€ì¶œ
                edges_fine = cv2.Canny(gray, 50, 150)
                edges_coarse = cv2.Canny(gray, 100, 200)
                
                # ì—ì§€ì˜ ì„ ëª…ë„ ë° ì—°ì†ì„± í‰ê°€
                edge_strength = np.mean(edges_fine)
                edge_consistency = 1.0 - abs(np.mean(edges_fine) - np.mean(edges_coarse)) / 255.0
                
                preservation_score = (edge_strength / 255.0) * 0.6 + edge_consistency * 0.4
            else:
                # ê°„ë‹¨í•œ gradient ê¸°ë°˜
                if len(image.shape) == 3:
                    gray = np.mean(image, axis=2)
                else:
                    gray = image
                
                dx = np.abs(np.diff(gray, axis=1))
                dy = np.abs(np.diff(gray, axis=0))
                edge_strength = (np.mean(dx) + np.mean(dy)) / 2
                
                preservation_score = min(1.0, edge_strength / 30.0)
            
            return max(0.0, min(1.0, preservation_score))
            
        except Exception as e:
            return 0.5
    
    def _analyze_texture_quality(self, image: np.ndarray) -> float:
        """í…ìŠ¤ì²˜ í’ˆì§ˆ ë¶„ì„"""
        try:
            if len(image.shape) == 3:
                gray = np.mean(image, axis=2)
            else:
                gray = image
            
            # ì§€ì—­ ë°”ì´ë„ˆë¦¬ íŒ¨í„´ (LBP) ê·¼ì‚¬
            texture_features = []
            
            # ë‹¤ì–‘í•œ ë°©í–¥ì˜ í…ìŠ¤ì²˜ ë¶„ì„
            for dx, dy in [(1, 0), (0, 1), (1, 1), (-1, 1)]:
                if dx == 1 and dy == 0:  # ìˆ˜í‰
                    diff = np.abs(np.diff(gray, axis=1))
                elif dx == 0 and dy == 1:  # ìˆ˜ì§
                    diff = np.abs(np.diff(gray, axis=0))
                else:  # ëŒ€ê°ì„  (ê°„ë‹¨ ê·¼ì‚¬)
                    diff = np.abs(gray[1:, 1:] - gray[:-1, :-1])
                
                texture_strength = np.mean(diff)
                texture_features.append(texture_strength)
            
            # í…ìŠ¤ì²˜ ë³µì¡ë„
            texture_complexity = np.mean(texture_features)
            
            # ì ì ˆí•œ í…ìŠ¤ì²˜ ë³µì¡ë„ (5-25)
            if 5 <= texture_complexity <= 25:
                texture_score = 1.0
            else:
                texture_score = max(0.0, 1.0 - abs(texture_complexity - 15) / 20.0)
            
            return max(0.0, min(1.0, texture_score))
            
        except Exception as e:
            return 0.5
    
    def _analyze_detail_preservation(self, image: np.ndarray) -> float:
        """ì„¸ë¶€ì‚¬í•­ ë³´ì¡´ë„ ë¶„ì„"""
        try:
            if len(image.shape) == 3:
                gray = np.mean(image, axis=2)
            else:
                gray = image
            
            # ê³ ì£¼íŒŒ ì„±ë¶„ ë¶„ì„
            if 'cv2' in globals():
                # ë¼í”Œë¼ì‹œì•ˆ í•„í„°ë¡œ ì„¸ë¶€ì‚¬í•­ ì¶”ì¶œ
                laplacian = cv2.Laplacian(gray.astype(np.uint8), cv2.CV_64F)
                detail_strength = np.var(laplacian)
                
                # ê°€ìš°ì‹œì•ˆ í”¼ë¼ë¯¸ë“œë¡œ ë‹¤ì¤‘ ìŠ¤ì¼€ì¼ ë¶„ì„
                pyramid_levels = []
                current = gray.astype(np.uint8)
                for _ in range(3):
                    current = cv2.pyrDown(current)
                    pyramid_levels.append(np.var(current))
                
                detail_preservation = detail_strength / (1 + np.mean(pyramid_levels))
                preservation_score = min(1.0, detail_preservation / 1000.0)
            else:
                # ê°„ë‹¨í•œ ë¶„ì‚° ê¸°ë°˜ ì„¸ë¶€ì‚¬í•­ ë¶„ì„
                detail_variance = np.var(gray)
                preservation_score = min(1.0, detail_variance / 2000.0)
            
            return max(0.0, min(1.0, preservation_score))
            
        except Exception as e:
            return 0.5
    
    def _calculate_fitting_score(self, results: Dict[str, Any]) -> float:
        """ê¸°ëŠ¥ì  í’ˆì§ˆ ì¢…í•© ì ìˆ˜ ê³„ì‚°"""
        try:
            # ê°€ì¤‘ì¹˜ ì„¤ì •
            weights = {
                'fitting_accuracy': 0.25,
                'clothing_alignment': 0.20,
                'naturalness': 0.20,
                'edge_preservation': 0.15,
                'texture_quality': 0.10,
                'detail_preservation': 0.10
            }
            
            # ê°€ì¤‘ í‰ê·  ê³„ì‚°
            total_score = 0.0
            total_weight = 0.0
            
            for metric, weight in weights.items():
                if metric in results:
                    total_score += results[metric] * weight
                    total_weight += weight
            
            # ì •ê·œí™”
            if total_weight > 0:
                final_score = total_score / total_weight
            else:
                final_score = 0.5
            
            return max(0.0, min(1.0, final_score))
            
        except Exception as e:
            self.logger.error(f"ê¸°ëŠ¥ì  ì ìˆ˜ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return 0.5
    
    def _compare_fitting_quality(self, processed: np.ndarray, original: np.ndarray) -> Dict[str, Any]:
        """í”¼íŒ… í’ˆì§ˆ ë¹„êµ ë¶„ì„"""
        try:
            comparison = {}
            
            # 1. í˜•íƒœ ë³´ì¡´ë„
            comparison['shape_preservation'] = self._calculate_shape_preservation(processed, original)
            
            # 2. ë¹„ìœ¨ ìœ ì§€ë„
            comparison['proportion_maintenance'] = self._calculate_proportion_maintenance(processed, original)
            
            # 3. ìì„¸ ì¼ê´€ì„±
            comparison['pose_consistency'] = self._calculate_pose_consistency(processed, original)
            
            return comparison
            
        except Exception as e:
            self.logger.error(f"í”¼íŒ… í’ˆì§ˆ ë¹„êµ ì‹¤íŒ¨: {e}")
            return {}
    
    def _calculate_shape_preservation(self, processed: np.ndarray, original: np.ndarray) -> float:
        """í˜•íƒœ ë³´ì¡´ë„ ê³„ì‚°"""
        try:
            # ì´ë¯¸ì§€ í¬ê¸° ë§ì¶”ê¸°
            if processed.shape != original.shape:
                min_h = min(processed.shape[0], original.shape[0])
                min_w = min(processed.shape[1], original.shape[1])
                processed = processed[:min_h, :min_w]
                original = original[:min_h, :min_w]
            
            # ì—ì§€ ê¸°ë°˜ í˜•íƒœ ë¹„êµ
            if 'cv2' in globals():
                if len(processed.shape) == 3:
                    proc_gray = cv2.cvtColor(processed.astype(np.uint8), cv2.COLOR_RGB2GRAY)
                    orig_gray = cv2.cvtColor(original.astype(np.uint8), cv2.COLOR_RGB2GRAY)
                else:
                    proc_gray = processed.astype(np.uint8)
                    orig_gray = original.astype(np.uint8)
                
                proc_edges = cv2.Canny(proc_gray, 50, 150)
                orig_edges = cv2.Canny(orig_gray, 50, 150)
                
                # ì—ì§€ ì¼ì¹˜ë„ ê³„ì‚°
                edge_match = np.sum(proc_edges & orig_edges) / np.sum(proc_edges | orig_edges + 1e-8)
            else:
                # ê°„ë‹¨í•œ êµ¬ì¡°ì  ë¹„êµ
                if len(processed.shape) == 3:
                    proc_gray = np.mean(processed, axis=2)
                    orig_gray = np.mean(original, axis=2)
                else:
                    proc_gray = processed
                    orig_gray = original
                
                correlation = np.corrcoef(proc_gray.flatten(), orig_gray.flatten())[0, 1]
                edge_match = max(0.0, correlation)
            
            return max(0.0, min(1.0, edge_match))
            
        except Exception as e:
            return 0.5
    
    def _calculate_proportion_maintenance(self, processed: np.ndarray, original: np.ndarray) -> float:
        """ë¹„ìœ¨ ìœ ì§€ë„ ê³„ì‚°"""
        try:
            # ê° ì´ë¯¸ì§€ì˜ ì£¼ìš” êµ¬ì¡° ë¹„ìœ¨ ë¶„ì„
            proc_h, proc_w = processed.shape[:2]
            orig_h, orig_w = original.shape[:2]
            
            proc_ratio = proc_w / proc_h
            orig_ratio = orig_w / orig_h
            
            ratio_diff = abs(proc_ratio - orig_ratio) / orig_ratio
            proportion_score = max(0.0, 1.0 - ratio_diff)
            
            return proportion_score
            
        except Exception as e:
            return 0.7
    
    def _calculate_pose_consistency(self, processed: np.ndarray, original: np.ndarray) -> float:
        """ìì„¸ ì¼ê´€ì„± ê³„ì‚°"""
        try:
            # ê°„ë‹¨í•œ ì§ˆëŸ‰ ì¤‘ì‹¬ ê¸°ë°˜ ìì„¸ ë¶„ì„
            if len(processed.shape) == 3:
                proc_gray = np.mean(processed, axis=2)
                orig_gray = np.mean(original, axis=2)
            else:
                proc_gray = processed
                orig_gray = original
            
            # ì§ˆëŸ‰ ì¤‘ì‹¬ ê³„ì‚°
            proc_center = self._calculate_center_of_mass(proc_gray)
            orig_center = self._calculate_center_of_mass(orig_gray)
            
            # ì¤‘ì‹¬ì  ê°„ ê±°ë¦¬
            if proc_center and orig_center:
                distance = np.sqrt((proc_center[0] - orig_center[0])**2 + (proc_center[1] - orig_center[1])**2)
                max_distance = np.sqrt(proc_gray.shape[0]**2 + proc_gray.shape[1]**2)
                pose_consistency = max(0.0, 1.0 - distance / max_distance)
            else:
                pose_consistency = 0.5
            
            return pose_consistency
            
        except Exception as e:
            return 0.6
    
    def _calculate_center_of_mass(self, image: np.ndarray) -> Optional[Tuple[float, float]]:
        """ì§ˆëŸ‰ ì¤‘ì‹¬ ê³„ì‚°"""
        try:
            # ì„ê³„ê°’ ê¸°ë°˜ ì „ê²½ ì¶”ì¶œ
            threshold = np.mean(image)
            foreground = image > threshold
            
            if np.sum(foreground) == 0:
                return None
            
            # ì§ˆëŸ‰ ì¤‘ì‹¬ ê³„ì‚°
            y_coords, x_coords = np.where(foreground)
            center_y = np.mean(y_coords)
            center_x = np.mean(x_coords)
            
            return (center_y, center_x)
            
        except Exception as e:
            return None
    
    def _calculate_advanced_fitting_metrics(self, image: np.ndarray, clothing_type: str) -> Dict[str, Any]:
        """ê³ ê¸‰ ê¸°ëŠ¥ì  ë©”íŠ¸ë¦­ ê³„ì‚°"""
        try:
            metrics = {}
            
            # 1. ì˜ë¥˜ë³„ íŠ¹í™” ë¶„ì„
            metrics.update(self._analyze_clothing_specific_features(image, clothing_type))
            
            # 2. ì¸ì²´ ë¹„ìœ¨ ë¶„ì„
            metrics['body_proportion_score'] = self._analyze_body_proportions(image)
            
            # 3. ì°©ìš©ê° ë¶„ì„
            metrics['wearing_comfort_score'] = self._analyze_wearing_comfort(image, clothing_type)
            
            return metrics
            
        except Exception as e:
            self.logger.error(f"ê³ ê¸‰ ê¸°ëŠ¥ì  ë©”íŠ¸ë¦­ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return {}
    
    def _analyze_clothing_specific_features(self, image: np.ndarray, clothing_type: str) -> Dict[str, Any]:
        """ì˜ë¥˜ë³„ íŠ¹í™” ë¶„ì„"""
        try:
            features = {}
            
            if clothing_type in ['shirt', 'top']:
                # ì…”ì¸ /ìƒì˜: ëª©ì„ , ì–´ê¹¨ì„ , ì†Œë§¤ ë¶„ì„
                features['neckline_alignment'] = self._analyze_neckline(image)
                features['shoulder_fit'] = self._analyze_shoulder_fit(image)
                features['sleeve_proportion'] = self._analyze_sleeve_proportion(image)
                
            elif clothing_type in ['pants', 'jeans']:
                # ë°”ì§€: í—ˆë¦¬ì„ , ë‹¤ë¦¬ í•, ê¸¸ì´ ë¶„ì„
                features['waistline_position'] = self._analyze_waistline(image)
                features['leg_fit'] = self._analyze_leg_fit(image)
                features['length_appropriateness'] = self._analyze_pants_length(image)
                
            elif clothing_type == 'dress':
                # ë“œë ˆìŠ¤: ì „ì²´ ì‹¤ë£¨ì—£, í—ˆë¦¬ì„ , ê¸¸ì´ ë¶„ì„
                features['silhouette_quality'] = self._analyze_dress_silhouette(image)
                features['waist_definition'] = self._analyze_waist_definition(image)
                features['dress_length'] = self._analyze_dress_length(image)
                
            else:
                # ê¸°ë³¸ ë¶„ì„
                features['general_fit'] = self._analyze_general_fit(image)
            
            return features
            
        except Exception as e:
            return {}
    
    def _analyze_neckline(self, image: np.ndarray) -> float:
        """ëª©ì„  ë¶„ì„"""
        try:
            # ìƒë‹¨ ì˜ì—­ì—ì„œ ëª©ì„  ì¶”ì •
            h, w = image.shape[:2]
            neck_region = image[:h//4, w//4:3*w//4]  # ìƒë‹¨ ì¤‘ì•™ ì˜ì—­
            
            if len(neck_region.shape) == 3:
                neck_gray = np.mean(neck_region, axis=2)
            else:
                neck_gray = neck_region
            
            # ëª©ì„ ì˜ ëŒ€ì¹­ì„± ë° ìì—°ìŠ¤ëŸ¬ì›€ ë¶„ì„
            left_half = neck_gray[:, :neck_gray.shape[1]//2]
            right_half = neck_gray[:, neck_gray.shape[1]//2:]
            right_flipped = np.flip(right_half, axis=1)
            
            # í¬ê¸° ë§ì¶”ê¸°
            min_w = min(left_half.shape[1], right_flipped.shape[1])
            left_half = left_half[:, :min_w]
            right_flipped = right_flipped[:, :min_w]
            
            # ëŒ€ì¹­ì„± ì ìˆ˜
            symmetry = 1.0 - np.mean(np.abs(left_half - right_flipped)) / 255.0
            
            return max(0.0, min(1.0, symmetry))
            
        except Exception as e:
            return 0.6
    
    def _analyze_shoulder_fit(self, image: np.ndarray) -> float:
        """ì–´ê¹¨ í• ë¶„ì„"""
        try:
            # ì–´ê¹¨ ì˜ì—­ ì¶”ì • (ìƒë‹¨ 1/3 ì˜ì—­)
            h, w = image.shape[:2]
            shoulder_region = image[:h//3, :]
            
            # ì–´ê¹¨ì„ ì˜ ìì—°ìŠ¤ëŸ¬ìš´ ê³¡ì„  ë¶„ì„
            if 'cv2' in globals() and len(shoulder_region.shape) == 3:
                gray = cv2.cvtColor(shoulder_region.astype(np.uint8), cv2.COLOR_RGB2GRAY)
                edges = cv2.Canny(gray, 50, 150)
                
                # ìˆ˜í‰ì„  ê·¼ì²˜ì˜ ì—ì§€ ë¶„ì„ (ì–´ê¹¨ì„ )
                horizontal_edges = np.sum(edges[h//6:h//4, :], axis=0)
                
                # ì–´ê¹¨ì„ ì˜ ì—°ì†ì„± ë¶„ì„
                if np.max(horizontal_edges) > 0:
                    shoulder_continuity = np.sum(horizontal_edges > 0) / len(horizontal_edges)
                else:
                    shoulder_continuity = 0.5
                    
                # ì–´ê¹¨ í­ì˜ ì ì ˆì„± (ì´ë¯¸ì§€ í­ì˜ 60-80%)
                shoulder_width_ratio = np.sum(horizontal_edges > 0) / w
                if 0.6 <= shoulder_width_ratio <= 0.8:
                    width_score = 1.0
                else:
                    width_score = max(0.0, 1.0 - abs(shoulder_width_ratio - 0.7) * 5)
                
                shoulder_fit = (shoulder_continuity + width_score) / 2
            else:
                # ê°„ë‹¨í•œ ëŒ€ì¹­ì„± ê¸°ë°˜ ë¶„ì„
                left_shoulder = shoulder_region[:, :w//3]
                right_shoulder = shoulder_region[:, 2*w//3:]
                
                if left_shoulder.size > 0 and right_shoulder.size > 0:
                    left_brightness = np.mean(left_shoulder)
                    right_brightness = np.mean(right_shoulder)
                    shoulder_fit = 1.0 - abs(left_brightness - right_brightness) / 255.0
                else:
                    shoulder_fit = 0.6
            
            return max(0.0, min(1.0, shoulder_fit))
            
        except Exception as e:
            return 0.6
    
    def _analyze_sleeve_proportion(self, image: np.ndarray) -> float:
        """ì†Œë§¤ ë¹„ìœ¨ ë¶„ì„"""
        try:
            h, w = image.shape[:2]
            
            # ì†Œë§¤ ì˜ì—­ ì¶”ì • (ì¢Œìš° ì¸¡ë©´)
            left_sleeve = image[:2*h//3, :w//4]
            right_sleeve = image[:2*h//3, 3*w//4:]
            
            # ì†Œë§¤ ê¸¸ì´ ë° í­ ë¶„ì„
            sleeve_scores = []
            
            for sleeve in [left_sleeve, right_sleeve]:
                if sleeve.size > 0:
                    if len(sleeve.shape) == 3:
                        sleeve_gray = np.mean(sleeve, axis=2)
                    else:
                        sleeve_gray = sleeve
                    
                    # ì†Œë§¤ì˜ ì¼ê´€ì„± ë¶„ì„ (ìˆ˜ì§ ë°©í–¥)
                    vertical_consistency = 1.0 - np.std(np.mean(sleeve_gray, axis=1)) / 255.0
                    sleeve_scores.append(max(0.0, vertical_consistency))
            
            if sleeve_scores:
                sleeve_proportion = np.mean(sleeve_scores)
            else:
                sleeve_proportion = 0.6
            
            return max(0.0, min(1.0, sleeve_proportion))
            
        except Exception as e:
            return 0.6
    
    def _analyze_waistline(self, image: np.ndarray) -> float:
        """í—ˆë¦¬ì„  ë¶„ì„"""
        try:
            h, w = image.shape[:2]
            
            # í—ˆë¦¬ì„  ì˜ì—­ (ì¤‘ì•™ ë¶€ë¶„)
            waist_region = image[h//3:2*h//3, w//4:3*w//4]
            
            if len(waist_region.shape) == 3:
                waist_gray = np.mean(waist_region, axis=2)
            else:
                waist_gray = waist_region
            
            # í—ˆë¦¬ì„ ì˜ ìˆ˜í‰ì„± ë¶„ì„
            if 'cv2' in globals():
                edges = cv2.Canny(waist_gray.astype(np.uint8), 50, 150)
                
                # ìˆ˜í‰ ì—ì§€ ê²€ì¶œ
                horizontal_kernel = np.array([[1, 1, 1], [0, 0, 0], [-1, -1, -1]])
                horizontal_edges = cv2.filter2D(edges, -1, horizontal_kernel)
                
                # í—ˆë¦¬ì„ ì˜ ëª…í™•ì„±
                waistline_clarity = np.max(horizontal_edges) / 255.0
            else:
                # ê°„ë‹¨í•œ ìˆ˜í‰ ë³€í™” ë¶„ì„
                horizontal_diff = np.mean(np.abs(np.diff(waist_gray, axis=0)))
                waistline_clarity = min(1.0, horizontal_diff / 30.0)
            
            return max(0.0, min(1.0, waistline_clarity))
            
        except Exception as e:
            return 0.5
    
    def _analyze_leg_fit(self, image: np.ndarray) -> float:
        """ë‹¤ë¦¬ í• ë¶„ì„"""
        try:
            h, w = image.shape[:2]
            
            # ë‹¤ë¦¬ ì˜ì—­ (í•˜ë‹¨ 2/3)
            leg_region = image[h//3:, :]
            
            # ì¢Œìš° ë‹¤ë¦¬ì˜ ëŒ€ì¹­ì„± ë¶„ì„
            left_leg = leg_region[:, :w//2]
            right_leg = leg_region[:, w//2:]
            
            if left_leg.size > 0 and right_leg.size > 0:
                # ê° ë‹¤ë¦¬ì˜ í­ ì¼ê´€ì„±
                left_widths = []
                right_widths = []
                
                leg_height = left_leg.shape[0]
                for i in range(0, leg_height, leg_height//10):
                    if i < left_leg.shape[0]:
                        if len(left_leg.shape) == 3:
                            left_row = np.mean(left_leg[i], axis=1) if len(left_leg[i].shape) > 1 else left_leg[i]
                            right_row = np.mean(right_leg[i], axis=1) if len(right_leg[i].shape) > 1 else right_leg[i]
                        else:
                            left_row = left_leg[i]
                            right_row = right_leg[i]
                        
                        # ì„ê³„ê°’ ê¸°ë°˜ í­ ê³„ì‚°
                        threshold = np.mean([np.mean(left_row), np.mean(right_row)])
                        left_width = np.sum(left_row > threshold)
                        right_width = np.sum(right_row > threshold)
                        
                        left_widths.append(left_width)
                        right_widths.append(right_width)
                
                if left_widths and right_widths:
                    # ì¢Œìš° ëŒ€ì¹­ì„±
                    symmetry = 1.0 - abs(np.mean(left_widths) - np.mean(right_widths)) / max(np.mean(left_widths), np.mean(right_widths), 1)
                    
                    # ê° ë‹¤ë¦¬ì˜ ì¼ê´€ì„±
                    left_consistency = 1.0 - np.std(left_widths) / (np.mean(left_widths) + 1e-8)
                    right_consistency = 1.0 - np.std(right_widths) / (np.mean(right_widths) + 1e-8)
                    
                    leg_fit = (symmetry + left_consistency + right_consistency) / 3
                else:
                    leg_fit = 0.5
            else:
                leg_fit = 0.5
            
            return max(0.0, min(1.0, leg_fit))
            
        except Exception as e:
            return 0.5
    
    def _analyze_pants_length(self, image: np.ndarray) -> float:
        """ë°”ì§€ ê¸¸ì´ ë¶„ì„"""
        try:
            h, w = image.shape[:2]
            
            # í•˜ë‹¨ ì˜ì—­ì—ì„œ ë°”ì§€ ë ë¶„ì„
            bottom_region = image[4*h//5:, :]
            
            if len(bottom_region.shape) == 3:
                bottom_gray = np.mean(bottom_region, axis=2)
            else:
                bottom_gray = bottom_region
            
            # ë°”ì§€ ëì˜ ìˆ˜í‰ì„± (ì¬ë‹¨ì„ )
            if 'cv2' in globals():
                edges = cv2.Canny(bottom_gray.astype(np.uint8), 50, 150)
                
                # í•˜ë‹¨ ìˆ˜í‰ì„  ê²€ì¶œ
                bottom_edges = edges[-edges.shape[0]//4:, :]
                horizontal_lines = np.sum(bottom_edges, axis=1)
                
                if len(horizontal_lines) > 0 and np.max(horizontal_lines) > 0:
                    # ê°€ì¥ ê°•í•œ ìˆ˜í‰ì„ ì˜ ìœ„ì¹˜ì™€ ê°•ë„
                    strongest_line_pos = np.argmax(horizontal_lines)
                    line_strength = np.max(horizontal_lines) / bottom_edges.shape[1]
                    
                    # ë°”ì§€ ëì˜ ëª…í™•ì„±
                    length_score = min(1.0, line_strength * 2)
                else:
                    length_score = 0.5
            else:
                # ê°„ë‹¨í•œ í•˜ë‹¨ ì¼ê´€ì„± ë¶„ì„
                bottom_consistency = 1.0 - np.std(bottom_gray[-1, :]) / 255.0
                length_score = max(0.0, bottom_consistency)
            
            return max(0.0, min(1.0, length_score))
            
        except Exception as e:
            return 0.5
    
    def _analyze_dress_silhouette(self, image: np.ndarray) -> float:
        """ë“œë ˆìŠ¤ ì‹¤ë£¨ì—£ ë¶„ì„"""
        try:
            h, w = image.shape[:2]
            
            # ë“œë ˆìŠ¤ì˜ ì „ì²´ì ì¸ í˜•íƒœ ë¶„ì„
            if len(image.shape) == 3:
                gray = np.mean(image, axis=2)
            else:
                gray = image
            
            # ì„¸ë¡œ ë°©í–¥ìœ¼ë¡œ í­ ë³€í™” ë¶„ì„
            width_profile = []
            for i in range(0, h, h//20):
                row = gray[i, :]
                threshold = np.mean(row)
                width = np.sum(row > threshold)
                width_profile.append(width)
            
            if len(width_profile) > 1:
                # ë“œë ˆìŠ¤ì˜ ìì—°ìŠ¤ëŸ¬ìš´ ì‹¤ë£¨ì—£ ê³¡ì„  ë¶„ì„
                width_changes = np.abs(np.diff(width_profile))
                smoothness = 1.0 - np.mean(width_changes) / (np.mean(width_profile) + 1e-8)
                
                # Aë¼ì¸, ìŠ¤íŠ¸ë ˆì´íŠ¸ ë“± ì¼ë°˜ì ì¸ ë“œë ˆìŠ¤ í˜•íƒœì™€ì˜ ì¼ì¹˜ë„
                top_width = np.mean(width_profile[:len(width_profile)//3])
                bottom_width = np.mean(width_profile[2*len(width_profile)//3:])
                
                if bottom_width > top_width:  # Aë¼ì¸
                    silhouette_type_score = 1.0
                elif abs(bottom_width - top_width) / top_width < 0.2:  # ìŠ¤íŠ¸ë ˆì´íŠ¸
                    silhouette_type_score = 0.9
                else:
                    silhouette_type_score = 0.7
                
                silhouette_quality = (smoothness + silhouette_type_score) / 2
            else:
                silhouette_quality = 0.5
            
            return max(0.0, min(1.0, silhouette_quality))
            
        except Exception as e:
            return 0.5
    
    def _analyze_waist_definition(self, image: np.ndarray) -> float:
        """í—ˆë¦¬ ì •ì˜ë„ ë¶„ì„"""
        try:
            h, w = image.shape[:2]
            
            # í—ˆë¦¬ ì˜ì—­ (ì¤‘ì•™ ë¶€ë¶„)
            waist_region = image[2*h//5:3*h//5, :]
            
            if len(waist_region.shape) == 3:
                waist_gray = np.mean(waist_region, axis=2)
            else:
                waist_gray = waist_region
            
            # í—ˆë¦¬ì˜ ì˜ë¡í•œ ì •ë„ ë¶„ì„
            waist_widths = []
            for i in range(waist_gray.shape[0]):
                row = waist_gray[i, :]
                threshold = np.mean(row)
                width = np.sum(row > threshold)
                waist_widths.append(width)
            
            if waist_widths:
                min_waist = np.min(waist_widths)
                max_waist = np.max(waist_widths)
                
                # í—ˆë¦¬ì˜ ë³€í™”ëŸ‰ (ì˜ë¡í•œ ì •ë„)
                if max_waist > 0:
                    waist_definition = (max_waist - min_waist) / max_waist
                else:
                    waist_definition = 0.0
                
                # ì ì ˆí•œ í—ˆë¦¬ ì •ì˜ë„ (10-40%)
                if 0.1 <= waist_definition <= 0.4:
                    definition_score = 1.0
                else:
                    definition_score = max(0.0, 1.0 - abs(waist_definition - 0.25) * 4)
            else:
                definition_score = 0.5
            
            return max(0.0, min(1.0, definition_score))
            
        except Exception as e:
            return 0.5
    
    def _analyze_dress_length(self, image: np.ndarray) -> float:
        """ë“œë ˆìŠ¤ ê¸¸ì´ ë¶„ì„"""
        try:
            h, w = image.shape[:2]
            
            # ë“œë ˆìŠ¤ ê¸¸ì´ì˜ ì ì ˆì„± ë¶„ì„
            # ì¼ë°˜ì ìœ¼ë¡œ ë¬´ë¦ ìœ„/ì•„ë˜, ë°œëª© ê¸¸ì´ ë“±ì´ ìì—°ìŠ¤ëŸ¬ì›€
            
            if len(image.shape) == 3:
                gray = np.mean(image, axis=2)
            else:
                gray = image
            
            # í•˜ë‹¨ë¶€ ë¶„ì„
            bottom_quarter = gray[3*h//4:, :]
            
            # ë“œë ˆìŠ¤ ëì˜ ëª…í™•ì„±
            if 'cv2' in globals():
                edges = cv2.Canny(bottom_quarter.astype(np.uint8), 50, 150)
                bottom_edges = np.sum(edges, axis=1)
                
                if len(bottom_edges) > 0:
                    # í•˜ë‹¨ ì—ì§€ì˜ ê°•ë„
                    edge_strength = np.max(bottom_edges) / bottom_quarter.shape[1]
                    length_clarity = min(1.0, edge_strength * 3)
                else:
                    length_clarity = 0.5
            else:
                # ê°„ë‹¨í•œ í•˜ë‹¨ ë³€í™” ë¶„ì„
                bottom_variance = np.var(bottom_quarter[-1, :])
                length_clarity = min(1.0, bottom_variance / 1000.0)
            
            return max(0.0, min(1.0, length_clarity))
            
        except Exception as e:
            return 0.5
    
    def _analyze_general_fit(self, image: np.ndarray) -> float:
        """ì¼ë°˜ì ì¸ í• ë¶„ì„"""
        try:
            # ì „ì²´ì ì¸ ì˜ë³µì˜ í• ë¶„ì„
            h, w = image.shape[:2]
            
            if len(image.shape) == 3:
                gray = np.mean(image, axis=2)
            else:
                gray = image
            
            # ëŒ€ì¹­ì„± ë¶„ì„
            left_half = gray[:, :w//2]
            right_half = gray[:, w//2:]
            right_flipped = np.flip(right_half, axis=1)
            
            # í¬ê¸° ë§ì¶”ê¸°
            min_w = min(left_half.shape[1], right_flipped.shape[1])
            left_half = left_half[:, :min_w]
            right_flipped = right_flipped[:, :min_w]
            
            # ëŒ€ì¹­ì„± ì ìˆ˜
            symmetry = 1.0 - np.mean(np.abs(left_half - right_flipped)) / 255.0
            
            # ì „ì²´ì ì¸ ì¼ê´€ì„±
            overall_consistency = 1.0 - np.std(gray) / np.mean(gray + 1e-8)
            
            general_fit = (symmetry + overall_consistency) / 2
            
            return max(0.0, min(1.0, general_fit))
            
        except Exception as e:
            return 0.6
    
    def _analyze_body_proportions(self, image: np.ndarray) -> float:
        """ì¸ì²´ ë¹„ìœ¨ ë¶„ì„"""
        try:
            h, w = image.shape[:2]
            
            # ê¸°ë³¸ì ì¸ ì¸ì²´ ë¹„ë¡€ ë¶„ì„
            # ì¼ë°˜ì ìœ¼ë¡œ ë¨¸ë¦¬:ëª¸í†µ:ë‹¤ë¦¬ = 1:3:4 ë¹„ìœ¨
            
            head_region = image[:h//8, :]  # ìƒë‹¨ 1/8
            torso_region = image[h//8:5*h//8, :]  # ì¤‘ê°„ 4/8
            leg_region = image[5*h//8:, :]  # í•˜ë‹¨ 3/8
            
            regions = [head_region, torso_region, leg_region]
            region_intensities = []
            
            for region in regions:
                if region.size > 0:
                    if len(region.shape) == 3:
                        intensity = np.mean(region)
                    else:
                        intensity = np.mean(region)
                    region_intensities.append(intensity)
                else:
                    region_intensities.append(128)  # ê¸°ë³¸ê°’
            
            # ê° ì˜ì—­ì˜ ë°ê¸° ì¼ê´€ì„± (ì˜ë³µì´ ì „ì²´ì ìœ¼ë¡œ ì¼ê´€ë˜ê²Œ í‘œí˜„ë˜ëŠ”ì§€)
            if len(region_intensities) >= 3:
                intensity_std = np.std(region_intensities)
                proportion_score = max(0.0, 1.0 - intensity_std / 50.0)
            else:
                proportion_score = 0.6
            
            return max(0.0, min(1.0, proportion_score))
            
        except Exception as e:
            return 0.6
    
    def _analyze_wearing_comfort(self, image: np.ndarray, clothing_type: str) -> float:
        """ì°©ìš©ê° ë¶„ì„"""
        try:
            # ì°©ìš©ê°ì„ ì‹œê°ì ìœ¼ë¡œ ì¶”ì • (ë„ˆë¬´ íƒ€ì´íŠ¸í•˜ê±°ë‚˜ ë£¨ì¦ˆí•˜ì§€ ì•Šì€ì§€)
            h, w = image.shape[:2]
            
            if len(image.shape) == 3:
                gray = np.mean(image, axis=2)
            else:
                gray = image
            
            comfort_factors = []
            
            # 1. ì˜ë³µì˜ ìì—°ìŠ¤ëŸ¬ìš´ ë“œë ˆì´í”„ (ì£¼ë¦„ê³¼ ê³¡ì„ )
            if 'cv2' in globals():
                # ê°€ìš°ì‹œì•ˆ ë¸”ëŸ¬ë¡œ ë¶€ë“œëŸ¬ìš´ ë³€í™” ê°ì§€
                blurred = cv2.GaussianBlur(gray.astype(np.uint8), (5, 5), 0)
                natural_variation = np.std(blurred)
                drape_score = min(1.0, natural_variation / 30.0)
            else:
                drape_score = 0.7
            
            comfort_factors.append(drape_score)
            
            # 2. ê³¼ë„í•œ ì‹ ì¶•ì´ë‚˜ ì••ë°• ì§•í›„ ì—†ìŒ
            edge_intensity = np.mean(np.abs(np.diff(gray, axis=1))) + np.mean(np.abs(np.diff(gray, axis=0)))
            
            # ì ì ˆí•œ ì—ì§€ ê°•ë„ (ê³¼ë„í•˜ê²Œ ë‹¹ê²¨ì§€ì§€ ì•ŠìŒ)
            if 10 <= edge_intensity <= 40:
                tension_score = 1.0
            else:
                tension_score = max(0.0, 1.0 - abs(edge_intensity - 25) / 25.0)
            
            comfort_factors.append(tension_score)
            
            # 3. ì˜ë¥˜ë³„ íŠ¹í™” ì°©ìš©ê° ë¶„ì„
            if clothing_type in ['shirt', 'top']:
                # ìƒì˜: ì–´ê¹¨ì™€ íŒ” ë¶€ë¶„ì˜ ìì—°ìŠ¤ëŸ¬ì›€
                shoulder_comfort = self._analyze_shoulder_comfort(image)
                comfort_factors.append(shoulder_comfort)
            elif clothing_type in ['pants', 'jeans']:
                # í•˜ì˜: í—ˆë²…ì§€ì™€ ì¢…ì•„ë¦¬ ë¶€ë¶„ì˜ ìì—°ìŠ¤ëŸ¬ì›€
                leg_comfort = self._analyze_leg_comfort(image)
                comfort_factors.append(leg_comfort)
            
            # ì¢…í•© ì°©ìš©ê° ì ìˆ˜
            comfort_score = np.mean(comfort_factors)
            
            return max(0.0, min(1.0, comfort_score))
            
        except Exception as e:
            return 0.6
    
    def _analyze_shoulder_comfort(self, image: np.ndarray) -> float:
        """ì–´ê¹¨ ì°©ìš©ê° ë¶„ì„"""
        try:
            h, w = image.shape[:2]
            shoulder_region = image[:h//3, :]
            
            if len(shoulder_region.shape) == 3:
                shoulder_gray = np.mean(shoulder_region, axis=2)
            else:
                shoulder_gray = shoulder_region
            
            # ì–´ê¹¨ì„ ì˜ ìì—°ìŠ¤ëŸ¬ìš´ ê³¡ì„  (ê³¼ë„í•˜ê²Œ ê°ì§€ì§€ ì•ŠìŒ)
            if 'cv2' in globals():
                # ìˆ˜í‰ ë°©í–¥ ë³€í™”ëŸ‰ ë¶„ì„
                horizontal_changes = np.abs(np.diff(shoulder_gray, axis=1))
                avg_change = np.mean(horizontal_changes)
                
                # ì ì ˆí•œ ë³€í™”ëŸ‰ (ìì—°ìŠ¤ëŸ¬ìš´ ê³¡ì„ )
                if 5 <= avg_change <= 20:
                    comfort = 1.0
                else:
                    comfort = max(0.0, 1.0 - abs(avg_change - 12.5) / 12.5)
            else:
                # ê°„ë‹¨í•œ ë¶„ì‚° ê¸°ë°˜ ë¶„ì„
                shoulder_variance = np.var(shoulder_gray)
                comfort = min(1.0, shoulder_variance / 1000.0)
            
            return max(0.0, min(1.0, comfort))
            
        except Exception as e:
            return 0.7
    
    def _analyze_leg_comfort(self, image: np.ndarray) -> float:
        """ë‹¤ë¦¬ ì°©ìš©ê° ë¶„ì„"""
        try:
            h, w = image.shape[:2]
            leg_region = image[h//2:, :]
            
            if len(leg_region.shape) == 3:
                leg_gray = np.mean(leg_region, axis=2)
            else:
                leg_gray = leg_region
            
            # ë‹¤ë¦¬ ë¶€ë¶„ì˜ ìì—°ìŠ¤ëŸ¬ìš´ í…Œì´í¼ë§
            leg_widths = []
            for i in range(0, leg_gray.shape[0], max(1, leg_gray.shape[0]//10)):
                if i < leg_gray.shape[0]:
                    row = leg_gray[i, :]
                    threshold = np.mean(row)
                    width = np.sum(row > threshold)
                    leg_widths.append(width)
            
            if len(leg_widths) > 1:
                # ìì—°ìŠ¤ëŸ¬ìš´ ë‹¤ë¦¬ ëª¨ì–‘ (ì ì§„ì  ë³€í™”)
                width_changes = np.abs(np.diff(leg_widths))
                gradual_change = 1.0 - np.std(width_changes) / (np.mean(width_changes) + 1e-8)
                comfort = max(0.0, min(1.0, gradual_change))
            else:
                comfort = 0.6
            
            return comfort
            
        except Exception as e:
            return 0.6
    
    def _get_fallback_fitting_results(self) -> Dict[str, Any]:
        """í´ë°± ê¸°ëŠ¥ì  ë¶„ì„ ê²°ê³¼"""
        return {
            'fitting_accuracy': 0.6,
            'clothing_alignment': 0.6,
            'naturalness': 0.5,
            'edge_preservation': 0.6,
            'texture_quality': 0.5,
            'detail_preservation': 0.6,
            'overall_score': 0.57,
            'analysis_method': 'fallback'
        }
    
    def cleanup(self):
        """ë¶„ì„ê¸° ì •ë¦¬"""
        pass

# ==============================================
# ğŸ”¥ ì™„ì „í•œ QualityMetrics í´ë˜ìŠ¤ (í–¥ìƒëœ ë²„ì „)
# ==============================================

@dataclass
class QualityMetrics:
    """í’ˆì§ˆ ë©”íŠ¸ë¦­ ë°ì´í„° êµ¬ì¡° (ì™„ì „í•œ ë²„ì „)"""
    overall_score: float = 0.0
    confidence: float = 0.0
    
    # ê¸°ìˆ ì  í’ˆì§ˆ ë©”íŠ¸ë¦­ë“¤
    sharpness: float = 0.0
    noise_level: float = 0.0
    contrast: float = 0.0
    brightness: float = 0.0
    saturation: float = 0.0
    artifacts: float = 0.0
    
    # ì§€ê°ì  í’ˆì§ˆ ë©”íŠ¸ë¦­ë“¤
    structural_similarity: float = 0.0
    perceptual_distance: float = 0.0
    lpips_score: float = 0.0
    fid_score: float = 0.0
    
    # ë¯¸ì  í’ˆì§ˆ ë©”íŠ¸ë¦­ë“¤
    composition: float = 0.0
    color_harmony: float = 0.0
    lighting: float = 0.0
    texture: float = 0.0
    symmetry: float = 0.0
    balance: float = 0.0
    
    # ê¸°ëŠ¥ì  í’ˆì§ˆ ë©”íŠ¸ë¦­ë“¤
    fitting_quality: float = 0.0
    edge_preservation: float = 0.0
    texture_quality: float = 0.0
    detail_preservation: float = 0.0
    
    # ë©”íƒ€ë°ì´í„°
    processing_time: float = 0.0
    device_used: str = "cpu"
    model_version: str = "v2.0"
    analysis_timestamp: float = 0.0
    
    def __post_init__(self):
        """ì´ˆê¸°í™” í›„ ì²˜ë¦¬"""
        if self.analysis_timestamp == 0.0:
            self.analysis_timestamp = time.time()
    
    def calculate_overall_score(self, weights: Optional[Dict[str, float]] = None) -> float:
        """ê°€ì¤‘ì¹˜ë¥¼ ì ìš©í•œ ì¢…í•© ì ìˆ˜ ê³„ì‚°"""
        if weights is None:
            weights = {
                'technical': 0.25,
                'perceptual': 0.25,
                'aesthetic': 0.25,
                'functional': 0.25
            }
        
        # ê° ì¹´í…Œê³ ë¦¬ë³„ ì ìˆ˜ ê³„ì‚°
        technical_score = np.mean([
            self.sharpness, 
            1.0 - self.noise_level,  # ë…¸ì´ì¦ˆëŠ” ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ
            self.contrast,
            self.brightness, 
            self.saturation,
            self.artifacts
        ])
        
        perceptual_score = np.mean([
            self.structural_similarity,
            1.0 - self.perceptual_distance,  # ê±°ë¦¬ëŠ” ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ
            max(0.0, 1.0 - self.lpips_score / 100.0),  # LPIPS ì •ê·œí™”
            max(0.0, 1.0 - self.fid_score / 100.0)     # FID ì •ê·œí™”
        ])
        
        aesthetic_score = np.mean([
            self.composition, 
            self.color_harmony,
            self.lighting,
            self.texture,
            self.symmetry, 
            self.balance
        ])
        
        functional_score = np.mean([
            self.fitting_quality, 
            self.edge_preservation,
            self.texture_quality, 
            self.detail_preservation
        ])
        
        # ê°€ì¤‘ í‰ê· 
        self.overall_score = (
            technical_score * weights.get('technical', 0.25) +
            perceptual_score * weights.get('perceptual', 0.25) +
            aesthetic_score * weights.get('aesthetic', 0.25) +
            functional_score * weights.get('functional', 0.25)
        )
        
        return self.overall_score
    
    def get_grade(self) -> QualityGrade:
        """ë“±ê¸‰ ë°˜í™˜"""
        score = self.overall_score * 100
        
        if score >= 90:
            return QualityGrade.EXCELLENT
        elif score >= 75:
            return QualityGrade.GOOD
        elif score >= 60:
            return QualityGrade.ACCEPTABLE
        elif score >= 40:
            return QualityGrade.POOR
        else:
            return QualityGrade.FAILED
    
    def to_dict(self) -> Dict[str, Any]:
        """ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜"""
        return asdict(self)
    
    def get_detailed_breakdown(self) -> Dict[str, Dict[str, float]]:
        """ì„¸ë¶€ ë¶„ì„ ê²°ê³¼ ë°˜í™˜"""
        return {
            'technical_quality': {
                'sharpness': self.sharpness,
                'noise_level': self.noise_level,
                'contrast': self.contrast,
                'brightness': self.brightness,
                'saturation': self.saturation,
                'artifacts': self.artifacts
            },
            'perceptual_quality': {
                'structural_similarity': self.structural_similarity,
                'perceptual_distance': self.perceptual_distance,
                'lpips_score': self.lpips_score,
                'fid_score': self.fid_score
            },
            'aesthetic_quality': {
                'composition': self.composition,
                'color_harmony': self.color_harmony,
                'lighting': self.lighting,
                'texture': self.texture,
                'symmetry': self.symmetry,
                'balance': self.balance
            },
            'functional_quality': {
                'fitting_quality': self.fitting_quality,
                'edge_preservation': self.edge_preservation,
                'texture_quality': self.texture_quality,
                'detail_preservation': self.detail_preservation
            }
        }

# ==============================================
# ğŸ”¥ ì¢…í•© íŒŒì´í”„ë¼ì¸ ë©”ì„œë“œë“¤ ì¶”ê°€
# ==============================================

    async def _analyze_technical_quality_comprehensive(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """ì¢…í•© ê¸°ìˆ ì  í’ˆì§ˆ ë¶„ì„ (í–¥ìƒëœ ë²„ì „)"""
        try:
            image = data['processed_image']
            original = data.get('original_image')
            
            # ì „ë¬¸ ë¶„ì„ê¸° ì‚¬ìš©
            if self.technical_analyzer:
                if original is not None:
                    results = self.technical_analyzer.analyze_comprehensive(image, original)
                else:
                    results = self.technical_analyzer.analyze(image)
            else:
                # í´ë°± ë¶„ì„
                results = self._traditional_technical_analysis(image)
            
            # AI ëª¨ë¸ ì¶”ê°€ ë¶„ì„ (ê°€ëŠ¥í•œ ê²½ìš°)
            if 'technical' in self.models_loaded:
                ai_results = await self._run_technical_ai_analysis(image)
                results.update(ai_results)
            
            self.logger.info("ğŸ”§ ì¢…í•© ê¸°ìˆ ì  í’ˆì§ˆ ë¶„ì„ ì™„ë£Œ")
            
            return {
                'technical_analysis_successful': True,
                'technical_results': results
            }
            
        except Exception as e:
            self.logger.error(f"âŒ ì¢…í•© ê¸°ìˆ ì  í’ˆì§ˆ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {'technical_analysis_successful': False, 'error': str(e)}
    
    async def _analyze_perceptual_quality_enhanced(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """í–¥ìƒëœ ì§€ê°ì  í’ˆì§ˆ ë¶„ì„"""
        try:
            image = data['processed_image']
            original = data.get('original_image')
            
            # AI ëª¨ë¸ì„ í†µí•œ ì§€ê°ì  ë¶„ì„
            if 'perceptual' in self.models_loaded:
                ai_results = await self._run_perceptual_ai_analysis(image, original)
            else:
                ai_results = {}
            
            # ì „í†µì  ë¶„ì„ê³¼ ê²°í•©
            traditional_results = self._traditional_perceptual_analysis(image, original)
            
            # ê²°ê³¼ í†µí•©
            results = {**traditional_results, **ai_results}
            
            self.logger.info("ğŸ‘ í–¥ìƒëœ ì§€ê°ì  í’ˆì§ˆ ë¶„ì„ ì™„ë£Œ")
            
            return {
                'perceptual_analysis_successful': True,
                'perceptual_results': results
            }
            
        except Exception as e:
            self.logger.error(f"âŒ í–¥ìƒëœ ì§€ê°ì  í’ˆì§ˆ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {'perceptual_analysis_successful': False, 'error': str(e)}
    
    async def _analyze_aesthetic_quality_enhanced(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """í–¥ìƒëœ ë¯¸ì  í’ˆì§ˆ ë¶„ì„"""
        try:
            image = data['processed_image']
            
            # AI ëª¨ë¸ì„ í†µí•œ ë¯¸ì  ë¶„ì„
            if 'aesthetic' in self.models_loaded:
                ai_results = await self._run_aesthetic_ai_analysis(image)
            else:
                ai_results = {}
            
            # ì „ë¬¸ ë¶„ì„ê¸° ì‚¬ìš©
            if self.aesthetic_analyzer:
                analyzer_results = self.aesthetic_analyzer.analyze(image)
            else:
                analyzer_results = self._traditional_aesthetic_analysis(image)
            
            # ê²°ê³¼ í†µí•©
            results = {**analyzer_results, **ai_results}
            
            self.logger.info("ğŸ¨ í–¥ìƒëœ ë¯¸ì  í’ˆì§ˆ ë¶„ì„ ì™„ë£Œ")
            
            return {
                'aesthetic_analysis_successful': True,
                'aesthetic_results': results
            }
            
        except Exception as e:
            self.logger.error(f"âŒ í–¥ìƒëœ ë¯¸ì  í’ˆì§ˆ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {'aesthetic_analysis_successful': False, 'error': str(e)}
    
    async def _run_technical_ai_analysis(self, image: np.ndarray) -> Dict[str, Any]:
        """ê¸°ìˆ ì  AI ë¶„ì„ ì‹¤í–‰"""
        try:
            model = self.models_loaded['technical']
            processed_tensor = self._preprocess_for_ai_model(image)
            
            with torch.no_grad() if TORCH_AVAILABLE else self._dummy_context():
                if hasattr(model, 'predict'):
                    ai_result = model.predict(processed_tensor)
                else:
                    ai_result = model(processed_tensor)
            
            # AI ê²°ê³¼ í•´ì„
            return self._interpret_technical_ai_result(ai_result)
            
        except Exception as e:
            self.logger.error(f"ê¸°ìˆ ì  AI ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {}
    
    async def _run_perceptual_ai_analysis(self, image: np.ndarray, original: Optional[np.ndarray]) -> Dict[str, Any]:
        """ì§€ê°ì  AI ë¶„ì„ ì‹¤í–‰"""
        try:
            model = self.models_loaded['perceptual']
            
            if original is not None:
                processed_pair = self._preprocess_image_pair_for_ai(image, original)
            else:
                processed_pair = self._preprocess_for_ai_model(image)
            
            with torch.no_grad() if TORCH_AVAILABLE else self._dummy_context():
                if hasattr(model, 'predict'):
                    ai_result = model.predict(processed_pair)
                else:
                    ai_result = model(processed_pair)
            
            # AI ê²°ê³¼ í•´ì„
            return self._interpret_perceptual_ai_result(ai_result)
            
        except Exception as e:
            self.logger.error(f"ì§€ê°ì  AI ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {}
    
    async def _run_aesthetic_ai_analysis(self, image: np.ndarray) -> Dict[str, Any]:
        """ë¯¸ì  AI ë¶„ì„ ì‹¤í–‰"""
        try:
            model = self.models_loaded['aesthetic']
            processed_tensor = self._preprocess_for_ai_model(image)
            
            with torch.no_grad() if TORCH_AVAILABLE else self._dummy_context():
                if hasattr(model, 'predict'):
                    ai_result = model.predict(processed_tensor)
                else:
                    ai_result = model(processed_tensor)
            
            # AI ê²°ê³¼ í•´ì„
            return self._interpret_aesthetic_ai_result(ai_result)
            
        except Exception as e:
            self.logger.error(f"ë¯¸ì  AI ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {}
    
    def _calculate_comprehensive_final_score(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """ì¢…í•© ìµœì¢… ì ìˆ˜ ê³„ì‚° (ì™„ì „í•œ ë²„ì „)"""
        try:
            # ëª¨ë“  ë¶„ì„ ê²°ê³¼ ìˆ˜ì§‘
            technical_results = data.get('technical_results', {})
            perceptual_results = data.get('perceptual_results', {})
            aesthetic_results = data.get('aesthetic_results', {})
            functional_results = data.get('functional_results', {})
            color_results = data.get('color_results', {})
            
            # ì™„ì „í•œ QualityMetrics ê°ì²´ ìƒì„±
            metrics = QualityMetrics()
            
            # ê¸°ìˆ ì  í’ˆì§ˆ ë§¤í•‘
            metrics.sharpness = technical_results.get('sharpness', 0.5)
            metrics.noise_level = technical_results.get('noise_level', 0.5)
            metrics.contrast = technical_results.get('contrast', 0.5)
            metrics.brightness = technical_results.get('brightness', 0.5)
            metrics.saturation = technical_results.get('saturation', 0.5)
            metrics.artifacts = technical_results.get('artifacts', 0.5)
            
            # ì§€ê°ì  í’ˆì§ˆ ë§¤í•‘
            metrics.structural_similarity = perceptual_results.get('ssim_score', perceptual_results.get('structural_similarity', 0.5))
            metrics.perceptual_distance = perceptual_results.get('perceptual_distance', 0.5)
            metrics.lpips_score = perceptual_results.get('lpips_score', 50.0)
            metrics.fid_score = perceptual_results.get('fid_score', 50.0)
            
            # ë¯¸ì  í’ˆì§ˆ ë§¤í•‘
            metrics.composition = aesthetic_results.get('composition', 0.5)
            metrics.color_harmony = aesthetic_results.get('color_harmony', color_results.get('color_harmony', 0.5))
            metrics.lighting = aesthetic_results.get('lighting', 0.5)
            metrics.texture = aesthetic_results.get('texture', 0.5)
            metrics.symmetry = aesthetic_results.get('symmetry', 0.5)
            metrics.balance = aesthetic_results.get('balance', 0.5)
            
            # ê¸°ëŠ¥ì  í’ˆì§ˆ ë§¤í•‘
            metrics.fitting_quality = functional_results.get('fitting_accuracy', 0.5)
            metrics.edge_preservation = functional_results.get('edge_preservation', 0.5)
            metrics.texture_quality = functional_results.get('texture_quality', 0.5)
            metrics.detail_preservation = functional_results.get('detail_preservation', 0.5)
            
            # ë©”íƒ€ë°ì´í„° ì„¤ì •
            metrics.device_used = self.device
            metrics.model_version = "v2.0_complete"
            
            # ì¢…í•© ì ìˆ˜ ê³„ì‚°
            metrics.calculate_overall_score()
            
            # ì‹ ë¢°ë„ ê³„ì‚°
            metrics.confidence = self._calculate_confidence(data)
            
            return {
                'quality_metrics': metrics,
                'overall_score': metrics.overall_score,
                'confidence': metrics.confidence,
                'detailed_breakdown': metrics.get_detailed_breakdown()
            }
            
        except Exception as e:
            self.logger.error(f"âŒ ì¢…í•© ìµœì¢… ì ìˆ˜ ê³„ì‚° ì‹¤íŒ¨: {e}")
            fallback_metrics = QualityMetrics()
            fallback_metrics.overall_score = 0.5
            fallback_metrics.confidence = 0.3
            return {
                'quality_metrics': fallback_metrics,
                'overall_score': 0.5,
                'confidence': 0.3
            }

# ==============================================
# ğŸ”¥ BaseStepMixin ë°ì½”ë ˆì´í„°ë“¤ (ì™„ì „í•œ êµ¬í˜„)
# ==============================================

    # í´ë°± ë°ì½”ë ˆì´í„°ë“¤ (BaseStepMixin ì—†ì„ ë•Œ)
    def ensure_step_initialization(func):
        @wraps(func)
        async def wrapper(self, *args, **kwargs):
            if not getattr(self, 'is_initialized', False):
                try:
                    await self.initialize()
                except Exception as e:
                    self.logger.error(f"Step ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return await func(self, *args, **kwargs)
        return wrapper
    
    def safe_step_method(func):
        @wraps(func)
        async def wrapper(self, *args, **kwargs):
            try:
                return await func(self, *args, **kwargs)
            except Exception as e:
                if hasattr(self, 'logger'):
                    self.logger.error(f"âŒ {func.__name__} ì‹¤í–‰ ì‹¤íŒ¨: {e}")
                if hasattr(self, 'error_count'):
                    self.error_count += 1
                if hasattr(self, 'last_error'):
                    self.last_error = str(e)
                
                return {
                    'success': False,
                    'error': str(e),
                    'error_type': type(e).__name__,
                    'step_name': getattr(self, 'step_name', self.__class__.__name__),
                    'method_name': func.__name__,
                    'timestamp': time.time()
                }
        return wrapper
    
    def performance_monitor(operation_name):
        def decorator(func):
            @wraps(func)
            async def wrapper(self, *args, **kwargs):
                start_time = time.time()
                try:
                    result = await func(self, *args, **kwargs)
                    duration = time.time() - start_time
                    if hasattr(self, 'logger'):
                        self.logger.info(f"âš¡ {operation_name} ì™„ë£Œ: {duration:.2f}ì´ˆ")
                    return result
                except Exception as e:
                    duration = time.time() - start_time
                    if hasattr(self, 'logger'):
                        self.logger.error(f"âŒ {operation_name} ì‹¤íŒ¨: {e} ({duration:.2f}ì´ˆ)")
                    raise
            return wrapper
        return decorator

class PerceptualQualityAnalyzer:
    """ì§€ê°ì  í’ˆì§ˆ ë¶„ì„ê¸°"""
    
    def __init__(self, models: Dict[str, Any], device: str = "cpu"):
        self.models = models
        self.device = device
        self.logger = logging.getLogger(f"{__name__}.PerceptualQualityAnalyzer")
    
    def analyze(self, image1: np.ndarray, image2: Optional[np.ndarray] = None) -> Dict[str, Any]:
        """ì§€ê°ì  í’ˆì§ˆ ë¶„ì„ ì‹¤í–‰"""
        try:
            # ê¸°ë³¸ ë¶„ì„ ë¡œì§
            return {
                'visual_quality': 0.75,
                'structural_similarity': 0.8,
                'perceptual_distance': 0.25,
                'overall_score': 0.75
            }
        except Exception as e:
            self.logger.error(f"âŒ ì§€ê°ì  ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {'overall_score': 0.5}
    
    def cleanup(self):
        """ì •ë¦¬"""
        pass

class AestheticQualityAnalyzer:
    """ë¯¸ì  í’ˆì§ˆ ë¶„ì„ê¸°"""
    
    def __init__(self, models: Dict[str, Any], device: str = "cpu"):
        self.models = models
        self.device = device
        self.logger = logging.getLogger(f"{__name__}.AestheticQualityAnalyzer")
    
    def analyze(self, image: np.ndarray) -> Dict[str, Any]:
        """ë¯¸ì  í’ˆì§ˆ ë¶„ì„ ì‹¤í–‰"""
        try:
            # ê¸°ë³¸ ë¶„ì„ ë¡œì§
            return {
                'composition': 0.7,
                'lighting': 0.8,
                'color_harmony': 0.75,
                'texture': 0.7,
                'overall_score': 0.7
            }
        except Exception as e:
            self.logger.error(f"âŒ ë¯¸ì  ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {'overall_score': 0.5}
    
    def cleanup(self):
        """ì •ë¦¬"""
        pass

class FunctionalQualityAnalyzer:
    """ê¸°ëŠ¥ì  í’ˆì§ˆ ë¶„ì„ê¸°"""
    
    def __init__(self, device: str = "cpu"):
        self.device = device
        self.logger = logging.getLogger(f"{__name__}.FunctionalQualityAnalyzer")
    
    def analyze(self, image: np.ndarray, clothing_type: str = "default") -> Dict[str, Any]:
        """ê¸°ëŠ¥ì  í’ˆì§ˆ ë¶„ì„ ì‹¤í–‰"""
        try:
            # ê¸°ë³¸ ë¶„ì„ ë¡œì§
            return {
                'fitting_accuracy': 0.8,
                'clothing_alignment': 0.75,
                'naturalness': 0.7,
                'overall_score': 0.75
            }
        except Exception as e:
            self.logger.error(f"âŒ ê¸°ëŠ¥ì  ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {'overall_score': 0.5}
    
    def cleanup(self):
        """ì •ë¦¬"""
        pass

class ColorQualityAnalyzer:
    """ìƒ‰ìƒ í’ˆì§ˆ ë¶„ì„ê¸°"""
    
    def __init__(self, device: str = "cpu"):
        self.device = device
        self.logger = logging.getLogger(f"{__name__}.ColorQualityAnalyzer")
    
    def analyze(self, image: np.ndarray) -> Dict[str, Any]:
        """ìƒ‰ìƒ í’ˆì§ˆ ë¶„ì„ ì‹¤í–‰"""
        try:
            # ê¸°ë³¸ ë¶„ì„ ë¡œì§
            return {
                'color_consistency': 0.8,
                'color_naturalness': 0.75,
                'color_contrast': 0.7,
                'overall_score': 0.75
            }
        except Exception as e:
            self.logger.error(f"âŒ ìƒ‰ìƒ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {'overall_score': 0.5}
    
    def cleanup(self):
        """ì •ë¦¬"""
        pass

# ==============================================
# ğŸ”¥ íŒ©í† ë¦¬ ë° ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
# ==============================================

def create_quality_assessment_step(
    device: str = "auto",
    config: Optional[Dict[str, Any]] = None,
    **kwargs
) -> QualityAssessmentStep:
    """í’ˆì§ˆ í‰ê°€ Step ìƒì„± í•¨ìˆ˜ (ê¸°ì¡´ í˜¸í™˜ì„±)"""
    return QualityAssessmentStep(device=device, config=config, **kwargs)

async def create_and_initialize_quality_assessment_step(
    device: str = "auto",
    config: Optional[Dict[str, Any]] = None,
    **kwargs
) -> QualityAssessmentStep:
    """í’ˆì§ˆ í‰ê°€ Step ìƒì„± ë° ì´ˆê¸°í™”"""
    step = QualityAssessmentStep(device=device, config=config, **kwargs)
    await step.initialize()
    return step

# ==============================================
# ğŸ”¥ ëª¨ë“ˆ ìµìŠ¤í¬íŠ¸ (ê¸°ì¡´ í˜¸í™˜ì„± ìœ ì§€)
# ==============================================

__all__ = [
    # ë©”ì¸ í´ë˜ìŠ¤
    'QualityAssessmentStep',
    
    # ë°ì´í„° êµ¬ì¡°
    'QualityMetrics',
    'QualityGrade', 
    'AssessmentMode',
    'QualityAspect',
    
    # ë¶„ì„ê¸° í´ë˜ìŠ¤ë“¤
    'TechnicalQualityAnalyzer',
    'PerceptualQualityAnalyzer',
    'AestheticQualityAnalyzer',
    'FunctionalQualityAnalyzer',
    'ColorQualityAnalyzer',
    
    # íŒ©í† ë¦¬ í•¨ìˆ˜ë“¤
    'create_quality_assessment_step',
    'create_and_initialize_quality_assessment_step'
]

# ==============================================
# ğŸ”¥ í…ŒìŠ¤íŠ¸ ì½”ë“œ (ê°œë°œìš©)
# ==============================================

if __name__ == "__main__":
    async def test_quality_assessment_step():
        """í’ˆì§ˆ í‰ê°€ Step í…ŒìŠ¤íŠ¸"""
        try:
            print("ğŸ§ª QualityAssessmentStep í…ŒìŠ¤íŠ¸ ì‹œì‘...")
            
            # Step ìƒì„±
            step = QualityAssessmentStep(device="auto")
            
            # ê¸°ë³¸ ì†ì„± í™•ì¸
            assert hasattr(step, 'logger'), "logger ì†ì„±ì´ ì—†ìŠµë‹ˆë‹¤!"
            assert hasattr(step, 'process'), "process ë©”ì„œë“œê°€ ì—†ìŠµë‹ˆë‹¤!"
            assert hasattr(step, 'cleanup_resources'), "cleanup_resources ë©”ì„œë“œê°€ ì—†ìŠµë‹ˆë‹¤!"
            
            # Step ì •ë³´ í™•ì¸
            step_info = step.get_step_info()
            assert 'step_name' in step_info, "step_nameì´ step_infoì— ì—†ìŠµë‹ˆë‹¤!"
            
            print("âœ… QualityAssessmentStep í…ŒìŠ¤íŠ¸ ì„±ê³µ")
            print(f"ğŸ“Š Step ì •ë³´: {step_info}")
            print(f"ğŸ”§ ë””ë°”ì´ìŠ¤: {step.device} ({step.device_type})")
            print(f"ğŸ’¾ ë©”ëª¨ë¦¬: {step.memory_gb}GB")
            print(f"ğŸ M3 Max: {'âœ…' if step.is_m3_max else 'âŒ'}")
            print(f"ğŸ§  BaseStepMixin: {'âœ…' if BASE_STEP_MIXIN_AVAILABLE else 'âŒ'}")
            print(f"ğŸ”Œ ModelLoader: {'âœ…' if MODEL_LOADER_AVAILABLE else 'âŒ'}")
            
            return True
            
        except Exception as e:
            print(f"âŒ QualityAssessmentStep í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    # ë¹„ë™ê¸° í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    import asyncio
    asyncio.run(test_quality_assessment_step())
            self.initialization_error = str(e)
            self.logger.error(f"âŒ {self.step_name} ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return False
    
    async def _setup_model_interface(self):
        """ModelLoader ì¸í„°í˜ì´ìŠ¤ ì„¤ì • (í•µì‹¬)"""
        try:
            if MODEL_LOADER_AVAILABLE:
                # ê¸€ë¡œë²Œ ModelLoader ê°€ì ¸ì˜¤ê¸°
                model_loader = get_global_model_loader()
                if model_loader:
                    # Stepë³„ ì¸í„°í˜ì´ìŠ¤ ìƒì„±
                    self.model_interface = model_loader.create_step_interface(self.step_name)
                    
                    # ëª¨ë¸ ìš”ì²­ì‚¬í•­ ë“±ë¡
                    self._register_model_requirements()
                    
                    self.logger.info(f"âœ… ModelLoader ì¸í„°í˜ì´ìŠ¤ ì„¤ì • ì™„ë£Œ: {self.step_name}")
                    return
            
            # í´ë°±: ì§ì ‘ ëª¨ë¸ ë¡œë“œ ì¤€ë¹„
            self.logger.warning("ModelLoader ë¯¸ì‚¬ìš©, ì§ì ‘ ë¡œë“œ ëª¨ë“œ")
            self.model_interface = None
            
        except Exception as e:
            self.logger.error(f"âŒ ModelLoader ì¸í„°í˜ì´ìŠ¤ ì„¤ì • ì‹¤íŒ¨: {e}")
            self.model_interface = None
    
    def _register_model_requirements(self):
        """í’ˆì§ˆ í‰ê°€ìš© ëª¨ë¸ ìš”ì²­ì‚¬í•­ ë“±ë¡"""
        try:
            if self.model_interface:
                # ì§€ê°ì  í’ˆì§ˆ í‰ê°€ ëª¨ë¸
                self.model_interface.register_model_requirement(
                    model_name="perceptual_quality_model",
                    model_type="quality_assessment",
                    priority="high",
                    fallback_models=["lpips_model", "ssim_model"]
                )
                
                # ê¸°ìˆ ì  í’ˆì§ˆ ë¶„ì„ ëª¨ë¸
                self.model_interface.register_model_requirement(
                    model_name="technical_quality_model", 
                    model_type="image_analysis",
                    priority="medium",
                    fallback_models=["opencv_analysis"]
                )
                
                # ë¯¸ì  í’ˆì§ˆ í‰ê°€ ëª¨ë¸
                self.model_interface.register_model_requirement(
                    model_name="aesthetic_quality_model",
                    model_type="aesthetic_analysis", 
                    priority="medium",
                    fallback_models=["traditional_metrics"]
                )
                
                self.logger.info(f"âœ… ëª¨ë¸ ìš”ì²­ì‚¬í•­ ë“±ë¡ ì™„ë£Œ: {self.step_name}")
        
        except Exception as e:
            self.logger.error(f"âŒ ëª¨ë¸ ìš”ì²­ì‚¬í•­ ë“±ë¡ ì‹¤íŒ¨: {e}")
    
    async def _load_quality_assessment_models(self):
        """í’ˆì§ˆ í‰ê°€ AI ëª¨ë¸ë“¤ ë¡œë“œ (ModelLoader í†µí•´)"""
        try:
            if self.model_interface:
                # ì§€ê°ì  í’ˆì§ˆ ëª¨ë¸ ë¡œë“œ
                perceptual_model = await self.model_interface.get_model("perceptual_quality_model")
                if perceptual_model:
                    self.models_loaded['perceptual'] = perceptual_model
                    self.logger.info("âœ… ì§€ê°ì  í’ˆì§ˆ ëª¨ë¸ ë¡œë“œ ì„±ê³µ")
                
                # ê¸°ìˆ ì  í’ˆì§ˆ ëª¨ë¸ ë¡œë“œ  
                technical_model = await self.model_interface.get_model("technical_quality_model")
                if technical_model:
                    self.models_loaded['technical'] = technical_model
                    self.logger.info("âœ… ê¸°ìˆ ì  í’ˆì§ˆ ëª¨ë¸ ë¡œë“œ ì„±ê³µ")
                
                # ë¯¸ì  í’ˆì§ˆ ëª¨ë¸ ë¡œë“œ
                aesthetic_model = await self.model_interface.get_model("aesthetic_quality_model")
                if aesthetic_model:
                    self.models_loaded['aesthetic'] = aesthetic_model
                    self.logger.info("âœ… ë¯¸ì  í’ˆì§ˆ ëª¨ë¸ ë¡œë“œ ì„±ê³µ")
                
                self.logger.info(f"âœ… {len(self.models_loaded)}ê°œ AI ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
            else:
                # í´ë°±: ì „í†µì  ë¶„ì„ ë°©ë²• ì‚¬ìš©
                self.logger.warning("AI ëª¨ë¸ ì—†ìŒ, ì „í†µì  ë¶„ì„ ë°©ë²• ì‚¬ìš©")
                await self._setup_traditional_analysis()
        
        except Exception as e:
            self.logger.error(f"âŒ í’ˆì§ˆ í‰ê°€ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            await self._setup_traditional_analysis()
    
    async def _setup_traditional_analysis(self):
        """ì „í†µì  ë¶„ì„ ë°©ë²• ì„¤ì • (AI ëª¨ë¸ ì—†ì„ ë•Œ)"""
        try:
            # OpenCV ê¸°ë°˜ ê¸°ìˆ ì  ë¶„ì„
            self.models_loaded['opencv_technical'] = True
            
            # PIL ê¸°ë°˜ ë¯¸ì  ë¶„ì„  
            self.models_loaded['pil_aesthetic'] = True
            
            # NumPy ê¸°ë°˜ ì§€ê°ì  ë¶„ì„
            self.models_loaded['numpy_perceptual'] = True
            
            self.logger.info("âœ… ì „í†µì  ë¶„ì„ ë°©ë²• ì„¤ì • ì™„ë£Œ")
        
        except Exception as e:
            self.logger.error(f"âŒ ì „í†µì  ë¶„ì„ ì„¤ì • ì‹¤íŒ¨: {e}")
    
    def _setup_assessment_pipeline(self):
        """í’ˆì§ˆ í‰ê°€ íŒŒì´í”„ë¼ì¸ êµ¬ì„±"""
        try:
            self.assessment_pipeline = [
                ("ê¸°ìˆ ì _í’ˆì§ˆ_ë¶„ì„", self._analyze_technical_quality),
                ("ì§€ê°ì _í’ˆì§ˆ_ë¶„ì„", self._analyze_perceptual_quality), 
                ("ë¯¸ì _í’ˆì§ˆ_ë¶„ì„", self._analyze_aesthetic_quality),
                ("ê¸°ëŠ¥ì _í’ˆì§ˆ_ë¶„ì„", self._analyze_functional_quality),
                ("ìƒ‰ìƒ_í’ˆì§ˆ_ë¶„ì„", self._analyze_color_quality),
                ("ì¢…í•©_ì ìˆ˜_ê³„ì‚°", self._calculate_overall_quality),
                ("ë“±ê¸‰_ë¶€ì—¬", self._assign_quality_grade),
                ("ì‹œê°í™”_ìƒì„±", self._generate_quality_visualization)
            ]
            
            self.logger.info(f"âœ… í’ˆì§ˆ í‰ê°€ íŒŒì´í”„ë¼ì¸ êµ¬ì„± ì™„ë£Œ: {len(self.assessment_pipeline)}ë‹¨ê³„")
        
        except Exception as e:
            self.logger.error(f"âŒ íŒŒì´í”„ë¼ì¸ êµ¬ì„± ì‹¤íŒ¨: {e}")
            self.assessment_pipeline = []
    
    def _initialize_analyzers(self):
        """ì „ë¬¸ ë¶„ì„ê¸°ë“¤ ì´ˆê¸°í™” (ê¸°ì¡´ ë°©ì‹ ìœ ì§€)"""
        try:
            # ê¸°ìˆ ì  ë¶„ì„ê¸°
            self.technical_analyzer = TechnicalQualityAnalyzer(
                device=self.device,
                enable_gpu=TORCH_AVAILABLE and self.device != 'cpu'
            )
            
            # ì§€ê°ì  ë¶„ì„ê¸°
            self.perceptual_analyzer = PerceptualQualityAnalyzer(
                models=self.models_loaded,
                device=self.device
            )
            
            # ë¯¸ì  ë¶„ì„ê¸°
            self.aesthetic_analyzer = AestheticQualityAnalyzer(
                models=self.models_loaded,
                device=self.device
            )
            
            # ê¸°ëŠ¥ì  ë¶„ì„ê¸°
            self.functional_analyzer = FunctionalQualityAnalyzer(
                device=self.device
            )
            
            # ìƒ‰ìƒ ë¶„ì„ê¸°
            self.color_analyzer = ColorQualityAnalyzer(
                device=self.device
            )
            
            self.logger.info("âœ… ì „ë¬¸ ë¶„ì„ê¸° ì´ˆê¸°í™” ì™„ë£Œ")
        
        except Exception as e:
            self.logger.error(f"âŒ ë¶„ì„ê¸° ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    
    # ==============================================
    # ğŸ”¥ ë©”ì¸ ì²˜ë¦¬ ë©”ì„œë“œ (process)
    # ==============================================
    
    async def process(
        self,
        fitted_image: Union[np.ndarray, str, Path],
        person_image: Optional[Union[np.ndarray, str, Path]] = None,
        clothing_image: Optional[Union[np.ndarray, str, Path]] = None,
        fabric_type: str = "default",
        clothing_type: str = "default",
        **kwargs
    ) -> Dict[str, Any]:
        """
        ğŸ”¥ ë©”ì¸ í’ˆì§ˆ í‰ê°€ ì²˜ë¦¬ í•¨ìˆ˜
        âœ… ModelLoader í†µí•œ AI ëª¨ë¸ í˜¸ì¶œ
        âœ… 8ê°€ì§€ í’ˆì§ˆ í‰ê°€ ì‹¤í–‰
        âœ… ì¢…í•© ì ìˆ˜ ê³„ì‚°
        """
        
        start_time = time.time()
        
        try:
            self.logger.info(f"ğŸ¯ {self.step_name} í’ˆì§ˆ í‰ê°€ ì‹œì‘")
            
            # 1. ì´ë¯¸ì§€ ë¡œë“œ ë° ê²€ì¦
            fitted_img = self._load_and_validate_image(fitted_image, "fitted_image")
            if fitted_img is None:
                raise ValueError("ìœ íš¨í•˜ì§€ ì•Šì€ fitted_imageì…ë‹ˆë‹¤")
            
            person_img = self._load_and_validate_image(person_image, "person_image") if person_image else None
            clothing_img = self._load_and_validate_image(clothing_image, "clothing_image") if clothing_image else None
            
            # 2. ì…ë ¥ ë°ì´í„° ì¤€ë¹„
            assessment_data = {
                'processed_image': fitted_img,
                'original_image': person_img,
                'clothing_image': clothing_img,
                'fabric_type': fabric_type,
                'clothing_type': clothing_type,
                'assessment_mode': self.assessment_config['mode'],
                **kwargs
            }
            
            # 3. ë©”ëª¨ë¦¬ ìµœì í™”
            if TORCH_AVAILABLE and self.optimization_enabled:
                self._optimize_memory()
            
            # 4. í’ˆì§ˆ í‰ê°€ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
            for stage_name, stage_func in self.assessment_pipeline:
                self.logger.info(f"ğŸ”„ {stage_name} ì‹¤í–‰ ì¤‘...")
                
                stage_start = time.time()
                
                if asyncio.iscoroutinefunction(stage_func):
                    stage_result = await stage_func(assessment_data)
                else:
                    stage_result = stage_func(assessment_data)
                
                stage_duration = time.time() - stage_start
                
                # ê²°ê³¼ ë³‘í•©
                assessment_data.update(stage_result)
                
                self.logger.info(f"âœ… {stage_name} ì™„ë£Œ ({stage_duration:.2f}ì´ˆ)")
            
            # 5. ìµœì¢… ê²°ê³¼ êµ¬ì„±
            processing_time = time.time() - start_time
            quality_metrics = assessment_data.get('quality_metrics')
            
            if quality_metrics is None:
                raise ValueError("í’ˆì§ˆ ë©”íŠ¸ë¦­ ê³„ì‚° ì‹¤íŒ¨")
            
            result = {
                'success': True,
                'step_name': self.step_name,
                'overall_score': quality_metrics.overall_score,
                'confidence': quality_metrics.confidence,
                'grade': assessment_data.get('grade', 'acceptable'),
                'grade_description': assessment_data.get('grade_description', 'ìˆ˜ìš© ê°€ëŠ¥í•œ í’ˆì§ˆ'),
                
                # ì„¸ë¶€ ë¶„ì„ ê²°ê³¼
                'detailed_scores': {
                    'technical': assessment_data.get('technical_results', {}),
                    'perceptual': assessment_data.get('perceptual_results', {}),
                    'aesthetic': assessment_data.get('aesthetic_results', {}),
                    'functional': assessment_data.get('functional_results', {}),
                    'color': assessment_data.get('color_results', {})
                },
                
                # í’ˆì§ˆ ë©”íŠ¸ë¦­ ì „ì²´
                'quality_metrics': asdict(quality_metrics),
                
                # ë©”íƒ€ë°ì´í„°
                'processing_time': processing_time,
                'fabric_type': fabric_type,
                'clothing_type': clothing_type,
                'assessment_mode': self.assessment_config['mode'].value,
                
                # ì‹œìŠ¤í…œ ì •ë³´
                'device_info': {
                    'device': self.device,
                    'is_m3_max': self.is_m3_max,
                    'ai_models_used': len(self.models_loaded),
                    'optimization_enabled': self.optimization_enabled
                },
                
                # ê²½ê³  ë° ê¶Œì¥ì‚¬í•­
                'warnings': assessment_data.get('warnings', []),
                'recommendations': assessment_data.get('recommendations', [])
            }
            
            self.logger.info(f"âœ… {self.step_name} í’ˆì§ˆ í‰ê°€ ì™„ë£Œ - ì ìˆ˜: {result['overall_score']:.3f} ({processing_time:.2f}ì´ˆ)")
            
            return result
            
        except Exception as e:
            processing_time = time.time() - start_time
            self.logger.error(f"âŒ {self.step_name} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            
            return {
                'success': False,
                'step_name': self.step_name,
                'error': str(e),
                'error_type': type(e).__name__,
                'processing_time': processing_time,
                'metadata': {
                    'device': self.device,
                    'pipeline_stages': len(self.assessment_pipeline),
                    'error_location': 'main_process'
                }
            }
    
    # ==============================================
    # ğŸ”¥ í’ˆì§ˆ ë¶„ì„ ë©”ì„œë“œë“¤ (AI ëª¨ë¸ í˜¸ì¶œ)
    # ==============================================
    
    async def _analyze_technical_quality(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """ê¸°ìˆ ì  í’ˆì§ˆ ë¶„ì„ (AI ëª¨ë¸ ë˜ëŠ” ì „í†µì  ë°©ë²•)"""
        try:
            image = data['processed_image']
            
            # AI ëª¨ë¸ ì‚¬ìš© ê°€ëŠ¥í•œ ê²½ìš°
            if 'technical' in self.models_loaded:
                model = self.models_loaded['technical']
                
                # ModelLoaderê°€ ì œê³µí•œ AI ëª¨ë¸ë¡œ ì¶”ë¡ 
                if hasattr(model, 'predict') or hasattr(model, '__call__'):
                    # ì´ë¯¸ì§€ ì „ì²˜ë¦¬
                    processed_tensor = self._preprocess_for_ai_model(image)
                    
                    # AI ëª¨ë¸ ì¶”ë¡  ì‹¤í–‰
                    with torch.no_grad() if TORCH_AVAILABLE else self._dummy_context():
                        if hasattr(model, 'predict'):
                            ai_result = model.predict(processed_tensor)
                        else:
                            ai_result = model(processed_tensor)
                    
                    # AI ê²°ê³¼ í•´ì„
                    technical_scores = self._interpret_technical_ai_result(ai_result)
                else:
                    # ì „í†µì  ë°©ë²•ìœ¼ë¡œ í´ë°±
                    technical_scores = self._traditional_technical_analysis(image)
            else:
                # ì „í†µì  ë¶„ì„ ë°©ë²•
                technical_scores = self._traditional_technical_analysis(image)
            
            return {
                'technical_results': technical_scores,
                'technical_score': technical_scores.get('overall_score', 0.5)
            }
        
        except Exception as e:
            self.logger.error(f"âŒ ê¸°ìˆ ì  í’ˆì§ˆ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {
                'technical_results': {'error': str(e)},
                'technical_score': 0.3
            }
    
    async def _analyze_perceptual_quality(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """ì§€ê°ì  í’ˆì§ˆ ë¶„ì„ (AI ëª¨ë¸ ë˜ëŠ” ì „í†µì  ë°©ë²•)"""
        try:
            image = data['processed_image']
            original = data.get('original_image')
            
            # AI ëª¨ë¸ ì‚¬ìš© ê°€ëŠ¥í•œ ê²½ìš°
            if 'perceptual' in self.models_loaded:
                model = self.models_loaded['perceptual']
                
                # ModelLoaderê°€ ì œê³µí•œ AI ëª¨ë¸ë¡œ ì¶”ë¡ 
                if hasattr(model, 'predict') or hasattr(model, '__call__'):
                    # ì´ë¯¸ì§€ ìŒ ì „ì²˜ë¦¬
                    processed_pair = self._preprocess_image_pair_for_ai(image, original)
                    
                    # AI ëª¨ë¸ ì¶”ë¡  ì‹¤í–‰
                    with torch.no_grad() if TORCH_AVAILABLE else self._dummy_context():
                        if hasattr(model, 'predict'):
                            ai_result = model.predict(processed_pair)
                        else:
                            ai_result = model(processed_pair)
                    
                    # AI ê²°ê³¼ í•´ì„
                    perceptual_scores = self._interpret_perceptual_ai_result(ai_result)
                else:
                    # ì „í†µì  ë°©ë²•ìœ¼ë¡œ í´ë°±
                    perceptual_scores = self._traditional_perceptual_analysis(image, original)
            else:
                # ì „í†µì  ë¶„ì„ ë°©ë²•
                perceptual_scores = self._traditional_perceptual_analysis(image, original)
            
            return {
                'perceptual_results': perceptual_scores,
                'perceptual_score': perceptual_scores.get('overall_score', 0.5)
            }
        
        except Exception as e:
            self.logger.error(f"âŒ ì§€ê°ì  í’ˆì§ˆ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {
                'perceptual_results': {'error': str(e)},
                'perceptual_score': 0.3
            }
    
    async def _analyze_aesthetic_quality(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """ë¯¸ì  í’ˆì§ˆ ë¶„ì„ (AI ëª¨ë¸ ë˜ëŠ” ì „í†µì  ë°©ë²•)"""
        try:
            image = data['processed_image']
            
            # AI ëª¨ë¸ ì‚¬ìš© ê°€ëŠ¥í•œ ê²½ìš°
            if 'aesthetic' in self.models_loaded:
                model = self.models_loaded['aesthetic']
                
                # ModelLoaderê°€ ì œê³µí•œ AI ëª¨ë¸ë¡œ ì¶”ë¡ 
                if hasattr(model, 'predict') or hasattr(model, '__call__'):
                    # ì´ë¯¸ì§€ ì „ì²˜ë¦¬
                    processed_tensor = self._preprocess_for_ai_model(image)
                    
                    # AI ëª¨ë¸ ì¶”ë¡  ì‹¤í–‰
                    with torch.no_grad() if TORCH_AVAILABLE else self._dummy_context():
                        if hasattr(model, 'predict'):
                            ai_result = model.predict(processed_tensor)
                        else:
                            ai_result = model(processed_tensor)
                    
                    # AI ê²°ê³¼ í•´ì„
                    aesthetic_scores = self._interpret_aesthetic_ai_result(ai_result)
                else:
                    # ì „í†µì  ë°©ë²•ìœ¼ë¡œ í´ë°±
                    aesthetic_scores = self._traditional_aesthetic_analysis(image)
            else:
                # ì „í†µì  ë¶„ì„ ë°©ë²•
                aesthetic_scores = self._traditional_aesthetic_analysis(image)
            
            return {
                'aesthetic_results': aesthetic_scores,
                'aesthetic_score': aesthetic_scores.get('overall_score', 0.5)
            }
        
        except Exception as e:
            self.logger.error(f"âŒ ë¯¸ì  í’ˆì§ˆ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {
                'aesthetic_results': {'error': str(e)},
                'aesthetic_score': 0.3
            }
    
    def _analyze_functional_quality(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """ê¸°ëŠ¥ì  í’ˆì§ˆ ë¶„ì„"""
        try:
            image = data['processed_image']
            clothing_type = data.get('clothing_type', 'default')
            
            # í”¼íŒ… ì •í™•ë„ ë¶„ì„
            fitting_score = self._analyze_fitting_accuracy(image, clothing_type)
            
            # ì˜ë¥˜ ì •ë ¬ ë¶„ì„  
            alignment_score = self._analyze_clothing_alignment(image)
            
            # ìì—°ìŠ¤ëŸ¬ì›€ ë¶„ì„
            naturalness_score = self._analyze_naturalness(image)
            
            functional_scores = {
                'fitting_accuracy': fitting_score,
                'clothing_alignment': alignment_score,
                'naturalness': naturalness_score,
                'overall_score': (fitting_score + alignment_score + naturalness_score) / 3
            }
            
            return {
                'functional_results': functional_scores,
                'functional_score': functional_scores['overall_score']
            }
        
        except Exception as e:
            self.logger.error(f"âŒ ê¸°ëŠ¥ì  í’ˆì§ˆ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {
                'functional_results': {'error': str(e)},
                'functional_score': 0.3
            }
    
    def _analyze_color_quality(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """ìƒ‰ìƒ í’ˆì§ˆ ë¶„ì„"""
        try:
            image = data['processed_image']
            
            # ìƒ‰ìƒ ì¼ê´€ì„± ë¶„ì„
            color_consistency = self._analyze_color_consistency(image)
            
            # ìƒ‰ìƒ ìì—°ìŠ¤ëŸ¬ì›€ ë¶„ì„
            color_naturalness = self._analyze_color_naturalness(image)
            
            # ìƒ‰ìƒ ëŒ€ë¹„ ë¶„ì„
            color_contrast = self._analyze_color_contrast(image)
            
            color_scores = {
                'color_consistency': color_consistency,
                'color_naturalness': color_naturalness,
                'color_contrast': color_contrast,
                'overall_score': (color_consistency + color_naturalness + color_contrast) / 3
            }
            
            return {
                'color_results': color_scores,
                'color_score': color_scores['overall_score']
            }
        
        except Exception as e:
            self.logger.error(f"âŒ ìƒ‰ìƒ í’ˆì§ˆ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {
                'color_results': {'error': str(e)},
                'color_score': 0.3
            }
    
    def _calculate_overall_quality(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """ì¢…í•© í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°"""
        try:
            # ê° ì˜ì—­ë³„ ì ìˆ˜ ìˆ˜ì§‘
            scores = {
                'technical': data.get('technical_score', 0.5),
                'perceptual': data.get('perceptual_score', 0.5),
                'aesthetic': data.get('aesthetic_score', 0.5),
                'functional': data.get('functional_score', 0.5),
                'color': data.get('color_score', 0.5)
            }
            
            # ê°€ì¤‘ì¹˜ ì ìš©
            weights = {
                'technical': 0.25,
                'perceptual': 0.25,
                'aesthetic': 0.20,
                'functional': 0.20,
                'color': 0.10
            }
            
            # ê°€ì¤‘ í‰ê·  ê³„ì‚°
            overall_score = sum(scores[key] * weights[key] for key in scores.keys())
            
            # ì‹ ë¢°ë„ ê³„ì‚°
            confidence = self._calculate_confidence(data)
            
            # QualityMetrics ê°ì²´ ìƒì„±
            quality_metrics = QualityMetrics(
                overall_score=overall_score,
                confidence=confidence,
                sharpness_score=data.get('technical_results', {}).get('sharpness', 0.5),
                color_score=data.get('color_score', 0.5),
                fitting_score=data.get('functional_results', {}).get('fitting_accuracy', 0.5),
                realism_score=data.get('perceptual_score', 0.5),
                artifacts_score=data.get('technical_results', {}).get('artifacts', 0.5),
                alignment_score=data.get('functional_results', {}).get('clothing_alignment', 0.5),
                lighting_score=data.get('aesthetic_results', {}).get('lighting', 0.5),
                texture_score=data.get('aesthetic_results', {}).get('texture', 0.5),
                device_used=self.device,
                model_version="v2.0"
            )
            
            return {
                'quality_metrics': quality_metrics,
                'overall_score': overall_score,
                'confidence': confidence
            }
        
        except Exception as e:
            self.logger.error(f"âŒ ì¢…í•© í’ˆì§ˆ ì ìˆ˜ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return {
                'quality_metrics': QualityMetrics(),
                'overall_score': 0.3,
                'confidence': 0.1
            }
    
    def _assign_quality_grade(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """í’ˆì§ˆ ë“±ê¸‰ ë¶€ì—¬"""
        try:
            overall_score = data.get('overall_score', 0.5)
            
            if overall_score >= 0.9:
                grade = QualityGrade.EXCELLENT
                description = "íƒì›”í•œ í’ˆì§ˆ - ìƒì—…ì  ì‚¬ìš© ê°€ëŠ¥"
            elif overall_score >= 0.75:
                grade = QualityGrade.GOOD  
                description = "ì¢‹ì€ í’ˆì§ˆ - ì¼ë°˜ì  ì‚¬ìš© ì í•©"
            elif overall_score >= 0.6:
                grade = QualityGrade.ACCEPTABLE
                description = "ìˆ˜ìš© ê°€ëŠ¥í•œ í’ˆì§ˆ - ê°œì„  ê¶Œì¥"
            elif overall_score >= 0.4:
                grade = QualityGrade.POOR
                description = "ë¶ˆëŸ‰í•œ í’ˆì§ˆ - ìƒë‹¹í•œ ê°œì„  í•„ìš”"
            else:
                grade = QualityGrade.FAILED
                description = "ì‹¤íŒ¨í•œ í’ˆì§ˆ - ì¬ì²˜ë¦¬ í•„ìš”"
            
            return {
                'grade': grade.value,
                'grade_description': description
            }
        
        except Exception as e:
            self.logger.error(f"âŒ í’ˆì§ˆ ë“±ê¸‰ ë¶€ì—¬ ì‹¤íŒ¨: {e}")
            return {
                'grade': QualityGrade.ACCEPTABLE.value,
                'grade_description': "ë“±ê¸‰ ê³„ì‚° ì‹¤íŒ¨"
            }
    
    def _generate_quality_visualization(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """í’ˆì§ˆ í‰ê°€ ì‹œê°í™” ìƒì„±"""
        try:
            # ê¸°ë³¸ ì‹œê°í™” ì •ë³´ë§Œ ë°˜í™˜ (ì‹¤ì œ ì´ë¯¸ì§€ ìƒì„±ì€ ì„ íƒì‚¬í•­)
            visualization_info = {
                'has_visualization': True,
                'quality_chart': f"í’ˆì§ˆ ì ìˆ˜: {data.get('overall_score', 0.5):.3f}",
                'grade_display': data.get('grade_description', 'ì•Œ ìˆ˜ ì—†ìŒ'),
                'detailed_breakdown': data.get('detailed_scores', {})
            }
            
            return {
                'visualization': visualization_info
            }
        
        except Exception as e:
            self.logger.error(f"âŒ ì‹œê°í™” ìƒì„± ì‹¤íŒ¨: {e}")
            return {
                'visualization': {'error': str(e)}
            }
    
    # ==============================================
    # ğŸ”¥ ìœ í‹¸ë¦¬í‹° ë©”ì„œë“œë“¤
    # ==============================================
    
    def _load_and_validate_image(self, image_input: Union[np.ndarray, str, Path], name: str) -> Optional[np.ndarray]:
        """ì´ë¯¸ì§€ ë¡œë“œ ë° ê²€ì¦"""
        try:
            if image_input is None:
                return None
            
            if isinstance(image_input, np.ndarray):
                return image_input
            elif isinstance(image_input, (str, Path)):
                image_path = Path(image_input)
                if image_path.exists():
                    from PIL import Image
                    with Image.open(image_path) as img:
                        return np.array(img)
            
            self.logger.warning(f"âŒ ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {name}")
            return None
        
        except Exception as e:
            self.logger.error(f"âŒ ì´ë¯¸ì§€ ë¡œë“œ ì˜¤ë¥˜ {name}: {e}")
            return None
    
    def _preprocess_for_ai_model(self, image: np.ndarray) -> Any:
        """AI ëª¨ë¸ìš© ì´ë¯¸ì§€ ì „ì²˜ë¦¬"""
        try:
            if TORCH_AVAILABLE:
                # NumPy to Tensor ë³€í™˜
                if len(image.shape) == 3:
                    tensor = torch.from_numpy(image).permute(2, 0, 1).float() / 255.0
                else:
                    tensor = torch.from_numpy(image).float() / 255.0
                
                # ë°°ì¹˜ ì°¨ì› ì¶”ê°€
                tensor = tensor.unsqueeze(0)
                
                # ë””ë°”ì´ìŠ¤ë¡œ ì´ë™
                if self.device != 'cpu':
                    tensor = tensor.to(self.device)
                
                return tensor
            else:
                # PyTorch ì—†ì„ ë•ŒëŠ” NumPy ë°°ì—´ ê·¸ëŒ€ë¡œ ë°˜í™˜
                return image
        
        except Exception as e:
            self.logger.error(f"âŒ AI ëª¨ë¸ìš© ì „ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return image
    
    def _preprocess_image_pair_for_ai(self, image1: np.ndarray, image2: Optional[np.ndarray]) -> Any:
        """ì´ë¯¸ì§€ ìŒ AI ëª¨ë¸ìš© ì „ì²˜ë¦¬"""
        try:
            if image2 is None:
                return self._preprocess_for_ai_model(image1)
            
            if TORCH_AVAILABLE:
                tensor1 = self._preprocess_for_ai_model(image1)
                tensor2 = self._preprocess_for_ai_model(image2)
                
                # ìŒìœ¼ë¡œ ë¬¶ê¸°
                pair_tensor = torch.cat([tensor1, tensor2], dim=1)
                return pair_tensor
            else:
                return np.concatenate([image1, image2], axis=-1)
        
        except Exception as e:
            self.logger.error(f"âŒ ì´ë¯¸ì§€ ìŒ ì „ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return self._preprocess_for_ai_model(image1)
    
    def _dummy_context(self):
        """PyTorch ì—†ì„ ë•Œ dummy context manager"""
        class DummyContext:
            def __enter__(self):
                return self
            def __exit__(self, *args):
                pass
        return DummyContext()
    
    # ==============================================
    # ğŸ”¥ AI ê²°ê³¼ í•´ì„ ë©”ì„œë“œë“¤
    # ==============================================
    
    def _interpret_technical_ai_result(self, ai_result: Any) -> Dict[str, Any]:
        """ê¸°ìˆ ì  í’ˆì§ˆ AI ê²°ê³¼ í•´ì„"""
        try:
            if TORCH_AVAILABLE and hasattr(ai_result, 'cpu'):
                result_data = ai_result.cpu().numpy()
            elif hasattr(ai_result, 'numpy'):
                result_data = ai_result.numpy()
            else:
                result_data = ai_result
            
            # AI ê²°ê³¼ë¥¼ í’ˆì§ˆ ì ìˆ˜ë¡œ ë³€í™˜
            if isinstance(result_data, np.ndarray):
                if result_data.size == 1:
                    overall_score = float(result_data.item())
                else:
                    overall_score = float(np.mean(result_data))
            else:
                overall_score = float(result_data) if isinstance(result_data, (int, float)) else 0.5
            
            return {
                'overall_score': max(0.0, min(1.0, overall_score)),
                'sharpness': overall_score * 0.9 + 0.1,
                'artifacts': 1.0 - overall_score * 0.3,
                'noise_level': overall_score * 0.8 + 0.2,
                'analysis_method': 'ai_model'
            }
        
        except Exception as e:
            self.logger.error(f"âŒ ê¸°ìˆ ì  AI ê²°ê³¼ í•´ì„ ì‹¤íŒ¨: {e}")
            return self._traditional_technical_analysis(None)
    
    def _interpret_perceptual_ai_result(self, ai_result: Any) -> Dict[str, Any]:
        """ì§€ê°ì  í’ˆì§ˆ AI ê²°ê³¼ í•´ì„"""
        try:
            if TORCH_AVAILABLE and hasattr(ai_result, 'cpu'):
                result_data = ai_result.cpu().numpy()
            elif hasattr(ai_result, 'numpy'):
                result_data = ai_result.numpy()
            else:
                result_data = ai_result
            
            # AI ê²°ê³¼ë¥¼ ì§€ê°ì  ì ìˆ˜ë¡œ ë³€í™˜
            if isinstance(result_data, np.ndarray):
                overall_score = float(np.mean(result_data))
            else:
                overall_score = float(result_data) if isinstance(result_data, (int, float)) else 0.5
            
            return {
                'overall_score': max(0.0, min(1.0, overall_score)),
                'visual_quality': overall_score,
                'structural_similarity': overall_score * 0.95 + 0.05,
                'perceptual_distance': 1.0 - overall_score,
                'analysis_method': 'ai_model'
            }
        
        except Exception as e:
            self.logger.error(f"âŒ ì§€ê°ì  AI ê²°ê³¼ í•´ì„ ì‹¤íŒ¨: {e}")
            return self._traditional_perceptual_analysis(None, None)
    
    def _interpret_aesthetic_ai_result(self, ai_result: Any) -> Dict[str, Any]:
        """ë¯¸ì  í’ˆì§ˆ AI ê²°ê³¼ í•´ì„"""
        try:
            if TORCH_AVAILABLE and hasattr(ai_result, 'cpu'):
                result_data = ai_result.cpu().numpy()
            elif hasattr(ai_result, 'numpy'):
                result_data = ai_result.numpy()
            else:
                result_data = ai_result
            
            # AI ê²°ê³¼ë¥¼ ë¯¸ì  ì ìˆ˜ë¡œ ë³€í™˜
            if isinstance(result_data, np.ndarray):
                overall_score = float(np.mean(result_data))
            else:
                overall_score = float(result_data) if isinstance(result_data, (int, float)) else 0.5
            
            return {
                'overall_score': max(0.0, min(1.0, overall_score)),
                'composition': overall_score * 0.9 + 0.1,
                'lighting': overall_score * 0.95 + 0.05,
                'texture': overall_score * 0.85 + 0.15,
                'color_harmony': overall_score * 0.8 + 0.2,
                'analysis_method': 'ai_model'
            }
        
        except Exception as e:
            self.logger.error(f"âŒ ë¯¸ì  AI ê²°ê³¼ í•´ì„ ì‹¤íŒ¨: {e}")
            return self._traditional_aesthetic_analysis(None)
    
    # ==============================================
    # ğŸ”¥ ì „í†µì  ë¶„ì„ ë©”ì„œë“œë“¤ (AI ëª¨ë¸ ì—†ì„ ë•Œ)
    # ==============================================
    
    def _traditional_technical_analysis(self, image: Optional[np.ndarray]) -> Dict[str, Any]:
        """ì „í†µì  ê¸°ìˆ ì  ë¶„ì„ ë°©ë²•"""
        try:
            if image is None:
                return {
                    'overall_score': 0.5,
                    'sharpness': 0.5,
                    'artifacts': 0.7,
                    'noise_level': 0.6,
                    'analysis_method': 'fallback'
                }
            
            # ê°„ë‹¨í•œ ì„ ëª…ë„ ì¸¡ì • (Laplacian variance)
            if len(image.shape) == 3:
                gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY) if 'cv2' in globals() else np.mean(image, axis=2)
            else:
                gray = image
            
            # ì„ ëª…ë„ ê³„ì‚°
            if 'cv2' in globals():
                laplacian = cv2.Laplacian(gray.astype(np.uint8), cv2.CV_64F)
                sharpness = laplacian.var() / 10000.0  # ì •ê·œí™”
            else:
                # OpenCV ì—†ì„ ë•Œ ê°„ë‹¨í•œ gradient ê³„ì‚°
                dx = np.diff(gray, axis=1)
                dy = np.diff(gray, axis=0)
                sharpness = (np.var(dx) + np.var(dy)) / 20000.0
            
            sharpness = max(0.0, min(1.0, sharpness))
            
            return {
                'overall_score': sharpness * 0.8 + 0.2,
                'sharpness': sharpness,
                'artifacts': 0.8,  # ê¸°ë³¸ê°’
                'noise_level': 0.7,  # ê¸°ë³¸ê°’
                'analysis_method': 'traditional'
            }
        
        except Exception as e:
            self.logger.error(f"âŒ ì „í†µì  ê¸°ìˆ  ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {
                'overall_score': 0.5,
                'sharpness': 0.5,
                'artifacts': 0.7,
                'noise_level': 0.6,
                'analysis_method': 'error_fallback'
            }
    
    def _traditional_perceptual_analysis(self, image1: Optional[np.ndarray], image2: Optional[np.ndarray]) -> Dict[str, Any]:
        """ì „í†µì  ì§€ê°ì  ë¶„ì„ ë°©ë²•"""
        try:
            if image1 is None:
                return {
                    'overall_score': 0.5,
                    'visual_quality': 0.5,
                    'structural_similarity': 0.5,
                    'perceptual_distance': 0.5,
                    'analysis_method': 'fallback'
                }
            
            # ê°„ë‹¨í•œ í†µê³„ì  ë¶„ì„
            mean_brightness = np.mean(image1) / 255.0
            brightness_score = 1.0 - abs(mean_brightness - 0.5) * 2  # 0.5ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ì¢‹ìŒ
            
            # ëŒ€ë¹„ ë¶„ì„
            contrast = np.std(image1) / 255.0
            contrast_score = min(1.0, contrast * 2)  # ì ì ˆí•œ ëŒ€ë¹„
            
            overall_score = (brightness_score + contrast_score) / 2
            
            return {
                'overall_score': overall_score,
                'visual_quality': overall_score,
                'structural_similarity': overall_score * 0.9 + 0.1,
                'perceptual_distance': 1.0 - overall_score,
                'analysis_method': 'traditional'
            }
        
        except Exception as e:
            self.logger.error(f"âŒ ì „í†µì  ì§€ê° ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {
                'overall_score': 0.5,
                'visual_quality': 0.5,
                'structural_similarity': 0.5,
                'perceptual_distance': 0.5,
                'analysis_method': 'error_fallback'
            }
    
    def _traditional_aesthetic_analysis(self, image: Optional[np.ndarray]) -> Dict[str, Any]:
        """ì „í†µì  ë¯¸ì  ë¶„ì„ ë°©ë²•"""
        try:
            if image is None:
                return {
                    'overall_score': 0.5,
                    'composition': 0.5,
                    'lighting': 0.5,
                    'texture': 0.5,
                    'color_harmony': 0.5,
                    'analysis_method': 'fallback'
                }
            
            # ìƒ‰ìƒ ë¶„í¬ ë¶„ì„
            if len(image.shape) == 3:
                color_std = np.mean([np.std(image[:,:,i]) for i in range(3)]) / 255.0
            else:
                color_std = np.std(image) / 255.0
            
            color_harmony = min(1.0, color_std * 1.5)
            
            # ë°ê¸° ë¶„í¬ ë¶„ì„
            brightness = np.mean(image) / 255.0
            lighting_score = 1.0 - abs(brightness - 0.5) * 1.5
            lighting_score = max(0.0, min(1.0, lighting_score))
            
            overall_score = (color_harmony + lighting_score) / 2
            
            return {
                'overall_score': overall_score,
                'composition': overall_score * 0.9 + 0.1,
                'lighting': lighting_score,
                'texture': overall_score * 0.8 + 0.2,
                'color_harmony': color_harmony,
                'analysis_method': 'traditional'
            }
        
        except Exception as e:
            self.logger.error(f"âŒ ì „í†µì  ë¯¸ì  ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {
                'overall_score': 0.5,
                'composition': 0.5,
                'lighting': 0.5,
                'texture': 0.5,
                'color_harmony': 0.5,
                'analysis_method': 'error_fallback'
            }
    
    # ==============================================
    # ğŸ”¥ ê¸°ëŠ¥ì /ìƒ‰ìƒ ë¶„ì„ ë©”ì„œë“œë“¤
    # ==============================================
    
    def _analyze_fitting_accuracy(self, image: np.ndarray, clothing_type: str) -> float:
        """í”¼íŒ… ì •í™•ë„ ë¶„ì„"""
        try:
            # ê°„ë‹¨í•œ ê¸°í•˜í•™ì  ì¼ê´€ì„± ì²´í¬
            height, width = image.shape[:2]
            aspect_ratio = width / height
            
            # ì˜ë¥˜ íƒ€ì…ë³„ ê¸°ëŒ€ ë¹„ìœ¨
            expected_ratios = {
                'shirt': (0.7, 1.3),
                'dress': (0.6, 1.0),
                'pants': (0.8, 1.2),
                'default': (0.5, 1.5)
            }
            
            min_ratio, max_ratio = expected_ratios.get(clothing_type, expected_ratios['default'])
            
            if min_ratio <= aspect_ratio <= max_ratio:
                ratio_score = 1.0
            else:
                ratio_score = max(0.0, 1.0 - abs(aspect_ratio - (min_ratio + max_ratio) / 2) * 2)
            
            return ratio_score
        
        except Exception as e:
            self.logger.error(f"âŒ í”¼íŒ… ì •í™•ë„ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return 0.5
    
    def _analyze_clothing_alignment(self, image: np.ndarray) -> float:
        """ì˜ë¥˜ ì •ë ¬ ë¶„ì„"""
        try:
            # ê°„ë‹¨í•œ ëŒ€ì¹­ì„± ì²´í¬
            height, width = image.shape[:2]
            
            # ì¢Œìš° ë°˜ìª½ ë¹„êµ
            left_half = image[:, :width//2]
            right_half = image[:, width//2:]
            right_half_flipped = np.flip(right_half, axis=1)
            
            # í¬ê¸° ë§ì¶”ê¸°
            min_width = min(left_half.shape[1], right_half_flipped.shape[1])
            left_half = left_half[:, :min_width]
            right_half_flipped = right_half_flipped[:, :min_width]
            
            # ì°¨ì´ ê³„ì‚°
            diff = np.mean(np.abs(left_half.astype(float) - right_half_flipped.astype(float)))
            similarity = 1.0 - (diff / 255.0)
            
            return max(0.0, min(1.0, similarity))
        
        except Exception as e: