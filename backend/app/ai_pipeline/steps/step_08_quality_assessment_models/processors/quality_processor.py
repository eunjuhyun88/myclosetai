"""
ğŸ”¥ Quality Assessment Processor
==============================

í’ˆì§ˆ í‰ê°€ë¥¼ ìœ„í•œ ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ë° í›„ì²˜ë¦¬ í”„ë¡œì„¸ì„œì…ë‹ˆë‹¤.
ë…¼ë¬¸ ê¸°ë°˜ì˜ AI ëª¨ë¸ êµ¬ì¡°ì— ë§ì¶° êµ¬í˜„ë˜ì—ˆìŠµë‹ˆë‹¤.
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
from typing import Dict, Any, Optional, Union, List, Tuple
import numpy as np
import cv2
from PIL import Image
import logging

# í”„ë¡œì íŠ¸ ë¡œê¹… ì„¤ì • import
try:
    from backend.app.core.logging_config import get_logger
    logger = get_logger(__name__)
except ImportError:
    logger = logging.getLogger(__name__)

class QualityProcessor:
    """
    í’ˆì§ˆ í‰ê°€ë¥¼ ìœ„í•œ ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ë° í›„ì²˜ë¦¬ í”„ë¡œì„¸ì„œ
    """

    def __init__(self, device: str = 'auto'):
        """
        Args:
            device: ì‚¬ìš©í•  ë””ë°”ì´ìŠ¤ ('auto', 'cpu', 'cuda')
        """
        if device == 'auto':
            self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        else:
            self.device = torch.device(device)
        
        logger.info(f"QualityProcessor initialized on device: {self.device}")

    def preprocess_for_quality_assessment(self, image: Union[np.ndarray, Image.Image, torch.Tensor],
                                       target_size: Tuple[int, int] = (224, 224),
                                       normalize: bool = True) -> torch.Tensor:
        """
        í’ˆì§ˆ í‰ê°€ë¥¼ ìœ„í•œ ì´ë¯¸ì§€ ì „ì²˜ë¦¬
        
        Args:
            image: ì…ë ¥ ì´ë¯¸ì§€
            target_size: ëª©í‘œ í¬ê¸°
            normalize: ì •ê·œí™” ì—¬ë¶€
            
        Returns:
            ì „ì²˜ë¦¬ëœ ì´ë¯¸ì§€ í…ì„œ
        """
        try:
            # ì´ë¯¸ì§€ íƒ€ì… í†µì¼
            if isinstance(image, Image.Image):
                image = np.array(image)
            
            if isinstance(image, np.ndarray):
                # RGBë¡œ ë³€í™˜
                if len(image.shape) == 2:
                    image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)
                elif image.shape[2] == 4:
                    image = cv2.cvtColor(image, cv2.COLOR_RGBA2RGB)
                
                # í…ì„œë¡œ ë³€í™˜
                image = torch.from_numpy(image).permute(2, 0, 1).float()
            elif isinstance(image, torch.Tensor):
                if len(image.shape) == 2:
                    image = image.unsqueeze(0).repeat(3, 1, 1)
                elif len(image.shape) == 3 and image.shape[0] == 1:
                    image = image.repeat(3, 1, 1)
            
            # í¬ê¸° ì¡°ì •
            if image.shape[-2:] != target_size:
                image = F.interpolate(image.unsqueeze(0), size=target_size, 
                                    mode='bilinear', align_corners=False).squeeze(0)
            
            # ì •ê·œí™”
            if normalize:
                image = image / 255.0
            
            # ë°°ì¹˜ ì°¨ì› ì¶”ê°€
            if len(image.shape) == 3:
                image = image.unsqueeze(0)
            
            # ë””ë°”ì´ìŠ¤ ì´ë™
            image = image.to(self.device)
            
            logger.info(f"âœ… Image preprocessing completed: {image.shape}")
            return image
            
        except Exception as e:
            logger.error(f"âŒ Image preprocessing failed: {e}")
            raise

    def enhance_image_quality(self, image: torch.Tensor, 
                            enhancement_type: str = 'denoise',
                            **kwargs) -> torch.Tensor:
        """
        ì´ë¯¸ì§€ í’ˆì§ˆ í–¥ìƒ
        
        Args:
            image: ì…ë ¥ ì´ë¯¸ì§€ í…ì„œ
            enhancement_type: í–¥ìƒ íƒ€ì…
            **kwargs: ì¶”ê°€ íŒŒë¼ë¯¸í„°
            
        Returns:
            í–¥ìƒëœ ì´ë¯¸ì§€ í…ì„œ
        """
        try:
            if enhancement_type == 'denoise':
                return self._denoise_image(image, **kwargs)
            elif enhancement_type == 'sharpen':
                return self._sharpen_image(image, **kwargs)
            elif enhancement_type == 'contrast':
                return self._enhance_contrast(image, **kwargs)
            elif enhancement_type == 'brightness':
                return self._enhance_brightness(image, **kwargs)
            else:
                logger.warning(f"âš ï¸ Unknown enhancement type: {enhancement_type}")
                return image
                
        except Exception as e:
            logger.error(f"âŒ Image enhancement failed: {e}")
            return image

    def _denoise_image(self, image: torch.Tensor, 
                      kernel_size: int = 3,
                      sigma: float = 1.0) -> torch.Tensor:
        """
        ì´ë¯¸ì§€ ë…¸ì´ì¦ˆ ì œê±°
        """
        # ê°€ìš°ì‹œì•ˆ í•„í„° ì ìš©
        if kernel_size % 2 == 0:
            kernel_size += 1
        
        # 2D ê°€ìš°ì‹œì•ˆ ì»¤ë„ ìƒì„±
        kernel = self._create_gaussian_kernel2d(kernel_size, sigma)
        kernel = kernel.to(self.device)
        
        # ê° ì±„ë„ì— ëŒ€í•´ ì»¨ë³¼ë£¨ì…˜ ì ìš©
        denoised = torch.zeros_like(image)
        for c in range(image.shape[1]):
            denoised[:, c:c+1] = F.conv2d(
                image[:, c:c+1], 
                kernel.unsqueeze(0).unsqueeze(0),
                padding=kernel_size // 2
            )
        
        return denoised

    def _sharpen_image(self, image: torch.Tensor, 
                      strength: float = 1.0) -> torch.Tensor:
        """
        ì´ë¯¸ì§€ ì„ ëª…ë„ í–¥ìƒ
        """
        # ì–¸ìƒ¤í”„ ë§ˆìŠ¤í¬ ì ìš©
        kernel = torch.tensor([
            [0, -1, 0],
            [-1, 5, -1],
            [0, -1, 0]
        ], dtype=torch.float32, device=self.device)
        
        kernel = kernel.unsqueeze(0).unsqueeze(0)
        
        sharpened = torch.zeros_like(image)
        for c in range(image.shape[1]):
            sharpened[:, c:c+1] = F.conv2d(
                image[:, c:c+1], 
                kernel,
                padding=1
            )
        
        # ì›ë³¸ê³¼ ë¸”ë Œë”©
        result = image + strength * (sharpened - image)
        return torch.clamp(result, 0, 1)

    def _enhance_contrast(self, image: torch.Tensor, 
                         alpha: float = 1.2,
                         beta: float = 0.0) -> torch.Tensor:
        """
        ì´ë¯¸ì§€ ëŒ€ë¹„ í–¥ìƒ
        """
        # íˆìŠ¤í† ê·¸ë¨ í‰í™œí™”ì™€ ìœ ì‚¬í•œ íš¨ê³¼
        mean_val = image.mean()
        enhanced = alpha * (image - mean_val) + mean_val + beta
        return torch.clamp(enhanced, 0, 1)

    def _enhance_brightness(self, image: torch.Tensor, 
                          beta: float = 0.1) -> torch.Tensor:
        """
        ì´ë¯¸ì§€ ë°ê¸° í–¥ìƒ
        """
        enhanced = image + beta
        return torch.clamp(enhanced, 0, 1)

    def _create_gaussian_kernel2d(self, kernel_size: int, sigma: float) -> torch.Tensor:
        """
        2D ê°€ìš°ì‹œì•ˆ ì»¤ë„ ìƒì„±
        """
        kernel = torch.zeros(kernel_size, kernel_size)
        center = kernel_size // 2
        
        for i in range(kernel_size):
            for j in range(kernel_size):
                x, y = i - center, j - center
                kernel[i, j] = torch.exp(-(x**2 + y**2) / (2 * sigma**2))
        
        # ì •ê·œí™”
        kernel = kernel / kernel.sum()
        return kernel

    def extract_quality_features(self, image: torch.Tensor) -> Dict[str, float]:
        """
        ì´ë¯¸ì§€ì—ì„œ í’ˆì§ˆ ê´€ë ¨ íŠ¹ì§• ì¶”ì¶œ
        
        Args:
            image: ì…ë ¥ ì´ë¯¸ì§€ í…ì„œ
            
        Returns:
            í’ˆì§ˆ íŠ¹ì§• ë”•ì…”ë„ˆë¦¬
        """
        try:
            features = {}
            
            # ë°ê¸°
            features['brightness'] = image.mean().item()
            
            # ëŒ€ë¹„ (í‘œì¤€í¸ì°¨)
            features['contrast'] = image.std().item()
            
            # ì„ ëª…ë„ (ë¼í”Œë¼ì‹œì•ˆ ë¶„ì‚°)
            features['sharpness'] = self._calculate_sharpness(image)
            
            # ë…¸ì´ì¦ˆ ë ˆë²¨
            features['noise_level'] = self._estimate_noise_level(image)
            
            # ìƒ‰ìƒ ë¶„í¬
            features['color_variance'] = self._calculate_color_variance(image)
            
            logger.info(f"âœ… Quality features extracted: {len(features)} features")
            return features
            
        except Exception as e:
            logger.error(f"âŒ Feature extraction failed: {e}")
            return {}

    def _calculate_sharpness(self, image: torch.Tensor) -> float:
        """
        ì´ë¯¸ì§€ ì„ ëª…ë„ ê³„ì‚° (ë¼í”Œë¼ì‹œì•ˆ ë¶„ì‚°)
        """
        try:
            # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ë¡œ ë³€í™˜
            if image.shape[1] == 3:
                gray = 0.299 * image[:, 0] + 0.587 * image[:, 1] + 0.114 * image[:, 2]
            else:
                gray = image[:, 0]
            
            # ë¼í”Œë¼ì‹œì•ˆ í•„í„°
            laplacian_kernel = torch.tensor([
                [0, 1, 0],
                [1, -4, 1],
                [0, 1, 0]
            ], dtype=torch.float32, device=self.device).unsqueeze(0).unsqueeze(0)
            
            laplacian = F.conv2d(gray.unsqueeze(1), laplacian_kernel, padding=1)
            
            # ë¶„ì‚° ê³„ì‚°
            sharpness = laplacian.var().item()
            return sharpness
            
        except Exception as e:
            logger.warning(f"âš ï¸ Sharpness calculation failed: {e}")
            return 0.0

    def _estimate_noise_level(self, image: torch.Tensor) -> float:
        """
        ì´ë¯¸ì§€ ë…¸ì´ì¦ˆ ë ˆë²¨ ì¶”ì •
        """
        try:
            # ê³ ì£¼íŒŒ ì„±ë¶„ ì¶”ì¶œ
            high_pass_kernel = torch.tensor([
                [-1, -1, -1],
                [-1, 8, -1],
                [-1, -1, -1]
            ], dtype=torch.float32, device=self.device).unsqueeze(0).unsqueeze(0)
            
            high_pass = F.conv2d(image[:, 0:1], high_pass_kernel, padding=1)
            
            # ë…¸ì´ì¦ˆ ë ˆë²¨ ì¶”ì •
            noise_level = high_pass.std().item()
            return noise_level
            
        except Exception as e:
            logger.warning(f"âš ï¸ Noise level estimation failed: {e}")
            return 0.0

    def _calculate_color_variance(self, image: torch.Tensor) -> float:
        """
        ìƒ‰ìƒ ë¶„ì‚° ê³„ì‚°
        """
        try:
            if image.shape[1] == 3:
                # RGB ì±„ë„ ê°„ ë¶„ì‚°
                color_variance = image.var(dim=1).mean().item()
            else:
                color_variance = 0.0
            
            return color_variance
            
        except Exception as e:
            logger.warning(f"âš ï¸ Color variance calculation failed: {e}")
            return 0.0

    def batch_process(self, images: List[torch.Tensor],
                     preprocessing: bool = True,
                     enhancement: bool = False,
                     feature_extraction: bool = True) -> Dict[str, Any]:
        """
        ì—¬ëŸ¬ ì´ë¯¸ì§€ë¥¼ ì¼ê´„ ì²˜ë¦¬
        
        Args:
            images: ì…ë ¥ ì´ë¯¸ì§€ ë¦¬ìŠ¤íŠ¸
            preprocessing: ì „ì²˜ë¦¬ ì—¬ë¶€
            enhancement: í’ˆì§ˆ í–¥ìƒ ì—¬ë¶€
            feature_extraction: íŠ¹ì§• ì¶”ì¶œ ì—¬ë¶€
            
        Returns:
            ì²˜ë¦¬ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        results = {
            'processed_images': [],
            'features': [],
            'processing_time': 0.0
        }
        
        start_time = torch.cuda.Event() if torch.cuda.is_available() else None
        
        for i, image in enumerate(images):
            try:
                processed_image = image
                
                # ì „ì²˜ë¦¬
                if preprocessing:
                    processed_image = self.preprocess_for_quality_assessment(
                        image, target_size=(224, 224), normalize=True
                    )
                
                # í’ˆì§ˆ í–¥ìƒ
                if enhancement:
                    processed_image = self.enhance_image_quality(
                        processed_image, enhancement_type='denoise'
                    )
                
                # íŠ¹ì§• ì¶”ì¶œ
                features = {}
                if feature_extraction:
                    features = self.extract_quality_features(processed_image)
                    features['image_index'] = i
                
                results['processed_images'].append(processed_image)
                results['features'].append(features)
                
            except Exception as e:
                logger.error(f"âŒ Failed to process image {i}: {e}")
                results['processed_images'].append(image)
                results['features'].append({'image_index': i, 'error': str(e)})
        
        # ì²˜ë¦¬ ì‹œê°„ ì¸¡ì •
        if start_time:
            end_time = torch.cuda.Event()
            end_time.record()
            torch.cuda.synchronize()
            results['processing_time'] = start_time.elapsed_time(end_time) / 1000.0
        
        logger.info(f"âœ… Batch processing completed: {len(images)} images")
        return results
