#!/usr/bin/env python3
"""
ğŸ”¥ MyCloset AI - Quality Assessment Utils
=========================================

í’ˆì§ˆ í‰ê°€ë¥¼ ìœ„í•œ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
- ì´ë¯¸ì§€ í’ˆì§ˆ ë©”íŠ¸ë¦­ ê³„ì‚°
- í’ˆì§ˆ ì ìˆ˜ ì‚°ì¶œ
- í’ˆì§ˆ í–¥ìƒ ì œì•ˆ

Author: MyCloset AI Team
Date: 2025-08-14
Version: 1.0
"""

import os
import sys
import logging
import numpy as np
from pathlib import Path
from typing import Dict, Any, Optional, List, Tuple, Union

# ë¡œê¹… ì„¤ì •
logger = logging.getLogger(__name__)

# ë¼ì´ë¸ŒëŸ¬ë¦¬ ê°€ìš©ì„± í™•ì¸
try:
    import cv2
    CV2_AVAILABLE = True
except ImportError:
    CV2_AVAILABLE = False
    cv2 = None

try:
    from PIL import Image
    PIL_AVAILABLE = True
except ImportError:
    PIL_AVAILABLE = False
    Image = None

try:
    from skimage.metrics import structural_similarity as ssim
    from skimage.metrics import peak_signal_noise_ratio as psnr
    SKIMAGE_AVAILABLE = True
except ImportError:
    SKIMAGE_AVAILABLE = False
    ssim = None
    psnr = None

# ==============================================
# ğŸ”¥ í’ˆì§ˆ í‰ê°€ ë©”íŠ¸ë¦­ í•¨ìˆ˜ë“¤
# ==============================================

def calculate_image_quality_metrics(image: np.ndarray, reference_image: Optional[np.ndarray] = None) -> Dict[str, float]:
    """ì´ë¯¸ì§€ í’ˆì§ˆ ë©”íŠ¸ë¦­ ê³„ì‚°"""
    metrics = {}
    
    try:
        if CV2_AVAILABLE:
            # Laplacian variance (ì„ ëª…ë„)
            if len(image.shape) == 3:
                gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
            else:
                gray = image
            laplacian_var = cv2.Laplacian(gray, cv2.CV_64F).var()
            metrics['sharpness'] = float(laplacian_var)
            
            # ë…¸ì´ì¦ˆ ë ˆë²¨ ì¶”ì •
            noise_level = estimate_noise_level(gray)
            metrics['noise_level'] = float(noise_level)
        
        # ì°¸ì¡° ì´ë¯¸ì§€ê°€ ìˆëŠ” ê²½ìš° ìƒëŒ€ì  ë©”íŠ¸ë¦­ ê³„ì‚°
        if reference_image is not None and SKIMAGE_AVAILABLE:
            try:
                # SSIM (êµ¬ì¡°ì  ìœ ì‚¬ì„±)
                ssim_score = ssim(image, reference_image, multichannel=True)
                metrics['ssim'] = float(ssim_score)
                
                # PSNR (í”¼í¬ ì‹ í˜¸ ëŒ€ ì¡ìŒë¹„)
                psnr_score = psnr(image, reference_image)
                metrics['psnr'] = float(psnr_score)
            except Exception as e:
                logger.warning(f"ìƒëŒ€ì  ë©”íŠ¸ë¦­ ê³„ì‚° ì‹¤íŒ¨: {e}")
        
        # ê¸°ë³¸ í†µê³„ ë©”íŠ¸ë¦­
        metrics['mean_intensity'] = float(np.mean(image))
        metrics['std_intensity'] = float(np.std(image))
        metrics['contrast'] = float(np.max(image) - np.min(image))
        
    except Exception as e:
        logger.error(f"í’ˆì§ˆ ë©”íŠ¸ë¦­ ê³„ì‚° ì‹¤íŒ¨: {e}")
        metrics = {'error': str(e)}
    
    return metrics

def estimate_noise_level(image: np.ndarray) -> float:
    """ì´ë¯¸ì§€ ë…¸ì´ì¦ˆ ë ˆë²¨ ì¶”ì •"""
    try:
        if CV2_AVAILABLE:
            # ê°€ìš°ì‹œì•ˆ ë¸”ëŸ¬ë¥¼ ì‚¬ìš©í•œ ë…¸ì´ì¦ˆ ì¶”ì •
            blurred = cv2.GaussianBlur(image, (5, 5), 0)
            noise = image.astype(np.float64) - blurred.astype(np.float64)
            noise_level = np.std(noise)
            return float(noise_level)
        else:
            # ê°„ë‹¨í•œ ì°¨ë¶„ ê¸°ë°˜ ë…¸ì´ì¦ˆ ì¶”ì •
            diff = np.diff(image, axis=1)
            noise_level = np.std(diff)
            return float(noise_level)
    except Exception as e:
        logger.warning(f"ë…¸ì´ì¦ˆ ë ˆë²¨ ì¶”ì • ì‹¤íŒ¨: {e}")
        return 0.0

def calculate_overall_quality_score(metrics: Dict[str, float]) -> Dict[str, Any]:
    """ì „ì²´ í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°"""
    try:
        score = 0.0
        max_score = 100.0
        factors = {}
        
        # ì„ ëª…ë„ ì ìˆ˜ (0-30ì )
        if 'sharpness' in metrics:
            sharpness_score = min(30.0, metrics['sharpness'] / 100.0)
            factors['sharpness'] = sharpness_score
            score += sharpness_score
        
        # ë…¸ì´ì¦ˆ ì ìˆ˜ (0-25ì )
        if 'noise_level' in metrics:
            noise_score = max(0.0, 25.0 - (metrics['noise_level'] / 10.0))
            factors['noise'] = noise_score
            score += noise_score
        
        # ëŒ€ë¹„ ì ìˆ˜ (0-20ì )
        if 'contrast' in metrics:
            contrast_score = min(20.0, metrics['contrast'] / 50.0)
            factors['contrast'] = contrast_score
            score += contrast_score
        
        # SSIM ì ìˆ˜ (0-15ì )
        if 'ssim' in metrics:
            ssim_score = metrics['ssim'] * 15.0
            factors['ssim'] = ssim_score
            score += ssim_score
        
        # PSNR ì ìˆ˜ (0-10ì )
        if 'psnr' in metrics:
            psnr_score = min(10.0, metrics['psnr'] / 10.0)
            factors['psnr'] = psnr_score
            score += psnr_score
        
        # í’ˆì§ˆ ë“±ê¸‰ ê²°ì •
        if score >= 90:
            grade = "A+"
        elif score >= 80:
            grade = "A"
        elif score >= 70:
            grade = "B+"
        elif score >= 60:
            grade = "B"
        elif score >= 50:
            grade = "C+"
        elif score >= 40:
            grade = "C"
        else:
            grade = "D"
        
        return {
            'overall_score': float(score),
            'max_score': float(max_score),
            'percentage': float((score / max_score) * 100),
            'grade': grade,
            'factors': factors,
            'metrics': metrics
        }
        
    except Exception as e:
        logger.error(f"ì „ì²´ í’ˆì§ˆ ì ìˆ˜ ê³„ì‚° ì‹¤íŒ¨: {e}")
        return {
            'overall_score': 0.0,
            'max_score': 100.0,
            'percentage': 0.0,
            'grade': 'F',
            'error': str(e)
        }

def generate_quality_improvement_suggestions(metrics: Dict[str, float], score_result: Dict[str, Any]) -> List[str]:
    """í’ˆì§ˆ í–¥ìƒ ì œì•ˆ ìƒì„±"""
    suggestions = []
    
    try:
        overall_score = score_result.get('overall_score', 0)
        
        # ì „ë°˜ì ì¸ í’ˆì§ˆì´ ë‚®ì€ ê²½ìš°
        if overall_score < 50:
            suggestions.append("ì´ë¯¸ì§€ í’ˆì§ˆì´ ë§¤ìš° ë‚®ìŠµë‹ˆë‹¤. ì´¬ì˜ í™˜ê²½ì„ ê°œì„ í•˜ê±°ë‚˜ ê³ í’ˆì§ˆ ì¹´ë©”ë¼ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.")
        
        # ì„ ëª…ë„ ê´€ë ¨ ì œì•ˆ
        if 'sharpness' in metrics and metrics['sharpness'] < 100:
            suggestions.append("ì´ë¯¸ì§€ê°€ íë¦¿í•©ë‹ˆë‹¤. ì¹´ë©”ë¼ë¥¼ ê³ ì •í•˜ê±°ë‚˜ ì…”í„° ì†ë„ë¥¼ ë†’ì´ì„¸ìš”.")
        
        # ë…¸ì´ì¦ˆ ê´€ë ¨ ì œì•ˆ
        if 'noise_level' in metrics and metrics['noise_level'] > 20:
            suggestions.append("ë…¸ì´ì¦ˆê°€ ë§ìŠµë‹ˆë‹¤. ISO ì„¤ì •ì„ ë‚®ì¶”ê±°ë‚˜ ì¡°ëª…ì„ ê°œì„ í•˜ì„¸ìš”.")
        
        # ëŒ€ë¹„ ê´€ë ¨ ì œì•ˆ
        if 'contrast' in metrics and metrics['contrast'] < 100:
            suggestions.append("ëŒ€ë¹„ê°€ ë‚®ìŠµë‹ˆë‹¤. ì¡°ëª…ì„ ì¡°ì •í•˜ê±°ë‚˜ HDR ëª¨ë“œë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.")
        
        # SSIM ê´€ë ¨ ì œì•ˆ
        if 'ssim' in metrics and metrics['ssim'] < 0.7:
            suggestions.append("êµ¬ì¡°ì  í’ˆì§ˆì´ ë‚®ìŠµë‹ˆë‹¤. ì´ë¯¸ì§€ ì••ì¶•ì„ ì¤„ì´ê±°ë‚˜ ê³ í•´ìƒë„ë¡œ ì´¬ì˜í•˜ì„¸ìš”.")
        
        # PSNR ê´€ë ¨ ì œì•ˆ
        if 'psnr' in metrics and metrics['psnr'] < 20:
            suggestions.append("ì‹ í˜¸ ëŒ€ ì¡ìŒë¹„ê°€ ë‚®ìŠµë‹ˆë‹¤. ì´¬ì˜ í™˜ê²½ì„ ê°œì„ í•˜ê±°ë‚˜ í›„ì²˜ë¦¬ë¥¼ ì ìš©í•˜ì„¸ìš”.")
        
        # ì œì•ˆì´ ì—†ëŠ” ê²½ìš°
        if not suggestions:
            suggestions.append("ì´ë¯¸ì§€ í’ˆì§ˆì´ ì–‘í˜¸í•©ë‹ˆë‹¤. í˜„ì¬ ì„¤ì •ì„ ìœ ì§€í•˜ì„¸ìš”.")
            
    except Exception as e:
        logger.error(f"í’ˆì§ˆ í–¥ìƒ ì œì•ˆ ìƒì„± ì‹¤íŒ¨: {e}")
        suggestions = ["í’ˆì§ˆ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."]
    
    return suggestions

def assess_image_quality(image: np.ndarray, reference_image: Optional[np.ndarray] = None) -> Dict[str, Any]:
    """ì´ë¯¸ì§€ í’ˆì§ˆ ì¢…í•© í‰ê°€"""
    try:
        # í’ˆì§ˆ ë©”íŠ¸ë¦­ ê³„ì‚°
        metrics = calculate_image_quality_metrics(image, reference_image)
        
        # ì „ì²´ í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°
        score_result = calculate_overall_quality_score(metrics)
        
        # í’ˆì§ˆ í–¥ìƒ ì œì•ˆ ìƒì„±
        suggestions = generate_quality_improvement_suggestions(metrics, score_result)
        
        return {
            'success': True,
            'metrics': metrics,
            'score_result': score_result,
            'suggestions': suggestions,
            'timestamp': str(np.datetime64('now'))
        }
        
    except Exception as e:
        logger.error(f"ì´ë¯¸ì§€ í’ˆì§ˆ í‰ê°€ ì‹¤íŒ¨: {e}")
        return {
            'success': False,
            'error': str(e),
            'timestamp': str(np.datetime64('now'))
        }

# ==============================================
# ğŸ”¥ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
# ==============================================

def validate_image_input(image: np.ndarray) -> bool:
    """ì´ë¯¸ì§€ ì…ë ¥ ìœ íš¨ì„± ê²€ì‚¬"""
    try:
        if image is None:
            return False
        
        if not isinstance(image, np.ndarray):
            return False
        
        if len(image.shape) < 2 or len(image.shape) > 3:
            return False
        
        if image.size == 0:
            return False
        
        return True
        
    except Exception:
        return False

def normalize_image_for_analysis(image: np.ndarray) -> np.ndarray:
    """ë¶„ì„ì„ ìœ„í•œ ì´ë¯¸ì§€ ì •ê·œí™”"""
    try:
        if not validate_image_input(image):
            raise ValueError("ìœ íš¨í•˜ì§€ ì•Šì€ ì´ë¯¸ì§€ ì…ë ¥")
        
        # 0-255 ë²”ìœ„ë¡œ ì •ê·œí™”
        if image.dtype != np.uint8:
            if image.max() <= 1.0:
                image = (image * 255).astype(np.uint8)
            else:
                image = image.astype(np.uint8)
        
        return image
        
    except Exception as e:
        logger.error(f"ì´ë¯¸ì§€ ì •ê·œí™” ì‹¤íŒ¨: {e}")
        return image

def get_quality_assessment_summary(assessment_result: Dict[str, Any]) -> str:
    """í’ˆì§ˆ í‰ê°€ ê²°ê³¼ ìš”ì•½"""
    try:
        if not assessment_result.get('success', False):
            return "í’ˆì§ˆ í‰ê°€ ì‹¤íŒ¨"
        
        score_result = assessment_result.get('score_result', {})
        overall_score = score_result.get('overall_score', 0)
        grade = score_result.get('grade', 'F')
        percentage = score_result.get('percentage', 0)
        
        summary = f"í’ˆì§ˆ ì ìˆ˜: {overall_score:.1f}/100 ({percentage:.1f}%) - ë“±ê¸‰: {grade}"
        
        # ì£¼ìš” ë©”íŠ¸ë¦­ ì¶”ê°€
        metrics = assessment_result.get('metrics', {})
        if 'sharpness' in metrics:
            summary += f"\nì„ ëª…ë„: {metrics['sharpness']:.1f}"
        if 'noise_level' in metrics:
            summary += f"\në…¸ì´ì¦ˆ: {metrics['noise_level']:.1f}"
        if 'contrast' in metrics:
            summary += f"\nëŒ€ë¹„: {metrics['contrast']:.1f}"
        
        return summary
        
    except Exception as e:
        logger.error(f"í’ˆì§ˆ í‰ê°€ ìš”ì•½ ìƒì„± ì‹¤íŒ¨: {e}")
        return "í’ˆì§ˆ í‰ê°€ ìš”ì•½ ìƒì„± ì‹¤íŒ¨"

# ==============================================
# ğŸ”¥ AssessmentUtils í´ë˜ìŠ¤
# ==============================================

class AssessmentUtils:
    """í’ˆì§ˆ í‰ê°€ ìœ í‹¸ë¦¬í‹° í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        self.assessment_history = []
        
    def assess_image_quality_batch(self, images: List[np.ndarray], 
                                 reference_images: Optional[List[np.ndarray]] = None) -> List[Dict[str, Any]]:
        """ë°°ì¹˜ ì´ë¯¸ì§€ í’ˆì§ˆ í‰ê°€"""
        results = []
        
        for i, image in enumerate(images):
            reference = reference_images[i] if reference_images else None
            result = assess_image_quality(image, reference)
            result['image_index'] = i
            results.append(result)
            self.assessment_history.append(result)
        
        return results
    
    def get_average_quality_score(self, assessment_results: List[Dict[str, Any]]) -> float:
        """í‰ê·  í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°"""
        if not assessment_results:
            return 0.0
        
        total_score = 0.0
        valid_results = 0
        
        for result in assessment_results:
            if result.get('success', False):
                score = result.get('score_result', {}).get('overall_score', 0)
                total_score += score
                valid_results += 1
        
        return total_score / valid_results if valid_results > 0 else 0.0
    
    def generate_quality_report(self, assessment_results: List[Dict[str, Any]]) -> Dict[str, Any]:
        """í’ˆì§ˆ í‰ê°€ ë³´ê³ ì„œ ìƒì„±"""
        if not assessment_results:
            return {'error': 'í‰ê°€ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.'}
        
        # í†µê³„ ê³„ì‚°
        scores = []
        grades = []
        successful_assessments = 0
        
        for result in assessment_results:
            if result.get('success', False):
                successful_assessments += 1
                score_result = result.get('score_result', {})
                scores.append(score_result.get('overall_score', 0))
                grades.append(score_result.get('grade', 'F'))
        
        if not scores:
            return {'error': 'ìœ íš¨í•œ í‰ê°€ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.'}
        
        # ë“±ê¸‰ë³„ ë¶„í¬
        grade_distribution = {}
        for grade in grades:
            grade_distribution[grade] = grade_distribution.get(grade, 0) + 1
        
        return {
            'total_images': len(assessment_results),
            'successful_assessments': successful_assessments,
            'average_score': sum(scores) / len(scores),
            'min_score': min(scores),
            'max_score': max(scores),
            'grade_distribution': grade_distribution,
            'overall_quality': self._get_overall_quality_rating(scores)
        }
    
    def _get_overall_quality_rating(self, scores: List[float]) -> str:
        """ì „ì²´ í’ˆì§ˆ ë“±ê¸‰ ê²°ì •"""
        if not scores:
            return 'F'
        
        avg_score = sum(scores) / len(scores)
        
        if avg_score >= 90:
            return 'A+'
        elif avg_score >= 80:
            return 'A'
        elif avg_score >= 70:
            return 'B+'
        elif avg_score >= 60:
            return 'B'
        elif avg_score >= 50:
            return 'C+'
        elif avg_score >= 40:
            return 'C'
        else:
            return 'D'
    
    def export_assessment_history(self, file_path: str) -> bool:
        """í‰ê°€ íˆìŠ¤í† ë¦¬ ë‚´ë³´ë‚´ê¸°"""
        try:
            import json
            with open(file_path, 'w', encoding='utf-8') as f:
                json.dump(self.assessment_history, f, ensure_ascii=False, indent=2)
            self.logger.info(f"í‰ê°€ íˆìŠ¤í† ë¦¬ ë‚´ë³´ë‚´ê¸° ì„±ê³µ: {file_path}")
            return True
        except Exception as e:
            self.logger.error(f"í‰ê°€ íˆìŠ¤í† ë¦¬ ë‚´ë³´ë‚´ê¸° ì‹¤íŒ¨: {e}")
            return False
    
    def clear_assessment_history(self):
        """í‰ê°€ íˆìŠ¤í† ë¦¬ ì´ˆê¸°í™”"""
        self.assessment_history.clear()
        self.logger.info("í‰ê°€ íˆìŠ¤í† ë¦¬ ì´ˆê¸°í™” ì™„ë£Œ")

