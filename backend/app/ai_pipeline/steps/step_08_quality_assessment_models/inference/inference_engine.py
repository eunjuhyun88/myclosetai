"""
ğŸ”¥ Quality Assessment Inference Engine
=====================================

í’ˆì§ˆ í‰ê°€ ëª¨ë¸ë“¤ì˜ ì¶”ë¡ ì„ ë‹´ë‹¹í•˜ëŠ” ì—”ì§„ í´ë˜ìŠ¤ì…ë‹ˆë‹¤.
ë…¼ë¬¸ ê¸°ë°˜ì˜ AI ëª¨ë¸ êµ¬ì¡°ì— ë§ì¶° êµ¬í˜„ë˜ì—ˆìŠµë‹ˆë‹¤.

ì§€ì› ëª¨ë¸:
- QualityNet (Image Quality Assessment)
- BRISQUE (Blind/Referenceless Image Spatial Quality Evaluator)
- NIQE (Natural Image Quality Evaluator)
- PIQE (Perception-based Image Quality Evaluator)
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
from typing import Dict, Any, Optional, Union, List, Tuple
import numpy as np
import cv2
from PIL import Image
import logging

# í”„ë¡œì íŠ¸ ë¡œê¹… ì„¤ì • import
try:
    from backend.app.core.logging_config import get_logger
    logger = get_logger(__name__)
except ImportError:
    logger = logging.getLogger(__name__)

class QualityAssessmentInferenceEngine:
    """
    í’ˆì§ˆ í‰ê°€ ëª¨ë¸ë“¤ì˜ ì¶”ë¡ ì„ ë‹´ë‹¹í•˜ëŠ” ì—”ì§„ í´ë˜ìŠ¤

    ì§€ì› ëª¨ë¸:
    - QualityNet (Image Quality Assessment)
    - BRISQUE (Blind/Referenceless Image Spatial Quality Evaluator)
    - NIQE (Natural Image Quality Evaluator)
    - PIQE (Perception-based Image Quality Evaluator)
    """

    def __init__(self, model_loader=None):
        """
        Args:
            model_loader: ëª¨ë¸ ë¡œë” ì¸ìŠ¤í„´ìŠ¤
        """
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.model_loader = model_loader
        self.loaded_models = {}

        # ì§€ì›í•˜ëŠ” ëª¨ë¸ íƒ€ì…ë“¤
        self.supported_models = ['qualitynet', 'brisque', 'niqe', 'piqe']

        # ì¶”ë¡  ì„¤ì •
        self.inference_config = {
            'qualitynet': {
                'input_size': (224, 224),
                'batch_size': 32,
                'normalize': True,
                'use_tta': True
            },
            'brisque': {
                'patch_size': 96,
                'stride': 48,
                'normalize': True
            },
            'niqe': {
                'patch_size': 96,
                'stride': 48,
                'normalize': True
            },
            'piqe': {
                'patch_size': 96,
                'stride': 48,
                'normalize': True
            }
        }

        logger.info(f"QualityAssessmentInferenceEngine initialized on device: {self.device}")

    def load_model(self, model_type: str, **kwargs) -> nn.Module:
        """
        ì§€ì •ëœ íƒ€ì…ì˜ ëª¨ë¸ì„ ë¡œë“œí•©ë‹ˆë‹¤.

        Args:
            model_type: ëª¨ë¸ íƒ€ì…
            **kwargs: ëª¨ë¸ ë¡œë“œì— í•„ìš”í•œ ì¶”ê°€ íŒŒë¼ë¯¸í„°

        Returns:
            ë¡œë“œëœ ëª¨ë¸
        """
        if self.model_loader:
            return self.model_loader.load_model(model_type, **kwargs)
        else:
            raise RuntimeError("Model loader not initialized")

    def assess_image_quality(self, image: Union[np.ndarray, Image.Image, torch.Tensor],
                           model_type: str = 'qualitynet', **kwargs) -> Dict[str, Any]:
        """
        ì´ë¯¸ì§€ í’ˆì§ˆì„ í‰ê°€í•©ë‹ˆë‹¤.

        Args:
            image: ì…ë ¥ ì´ë¯¸ì§€
            model_type: ì‚¬ìš©í•  ëª¨ë¸ íƒ€ì…
            **kwargs: ì¶”ê°€ íŒŒë¼ë¯¸í„°

        Returns:
            í’ˆì§ˆ í‰ê°€ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        try:
            # ì´ë¯¸ì§€ ì „ì²˜ë¦¬
            processed_image = self._preprocess_image(image, model_type)
            
            # ëª¨ë¸ ë¡œë“œ (í•„ìš”ì‹œ)
            if model_type not in self.loaded_models:
                self.loaded_models[model_type] = self.load_model(model_type, **kwargs)
            
            model = self.loaded_models[model_type]
            model.eval()
            
            # ì¶”ë¡  ì‹¤í–‰
            with torch.no_grad():
                if model_type == 'qualitynet':
                    result = self._inference_qualitynet(model, processed_image, **kwargs)
                elif model_type == 'brisque':
                    result = self._inference_brisque(model, processed_image, **kwargs)
                elif model_type == 'niqe':
                    result = self._inference_niqe(model, processed_image, **kwargs)
                elif model_type == 'piqe':
                    result = self._inference_piqe(model, processed_image, **kwargs)
                else:
                    raise ValueError(f"Unsupported model type: {model_type}")
            
            # ê²°ê³¼ í›„ì²˜ë¦¬
            result = self._postprocess_result(result, model_type)
            
            logger.info(f"âœ… Quality assessment completed for {model_type}")
            return result
            
        except Exception as e:
            logger.error(f"âŒ Quality assessment failed: {e}")
            raise

    def _preprocess_image(self, image: Union[np.ndarray, Image.Image, torch.Tensor],
                         model_type: str) -> torch.Tensor:
        """
        ì´ë¯¸ì§€ë¥¼ ì „ì²˜ë¦¬í•©ë‹ˆë‹¤.
        """
        # PIL Imageë¥¼ numpy arrayë¡œ ë³€í™˜
        if isinstance(image, Image.Image):
            image = np.array(image)
        
        # numpy arrayë¥¼ torch tensorë¡œ ë³€í™˜
        if isinstance(image, np.ndarray):
            if len(image.shape) == 3:
                image = torch.from_numpy(image).permute(2, 0, 1).float()
            else:
                image = torch.from_numpy(image).unsqueeze(0).float()
        
        # ì •ê·œí™”
        if self.inference_config[model_type].get('normalize', False):
            image = image / 255.0
        
        # ë°°ì¹˜ ì°¨ì› ì¶”ê°€
        if len(image.shape) == 3:
            image = image.unsqueeze(0)
        
        # ë””ë°”ì´ìŠ¤ ì´ë™
        image = image.to(self.device)
        
        return image

    def _inference_qualitynet(self, model: nn.Module, image: torch.Tensor, **kwargs) -> Dict[str, Any]:
        """
        QualityNet ëª¨ë¸ë¡œ ì¶”ë¡ ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.
        """
        # ì…ë ¥ í¬ê¸° ì¡°ì •
        input_size = self.inference_config['qualitynet']['input_size']
        if image.shape[-2:] != input_size:
            image = F.interpolate(image, size=input_size, mode='bilinear', align_corners=False)
        
        # ì¶”ë¡  ì‹¤í–‰
        output = model(image)
        
        # ê²°ê³¼ í•´ì„
        if isinstance(output, torch.Tensor):
            quality_score = output.item() if output.numel() == 1 else output.mean().item()
        else:
            quality_score = float(output)
        
        return {
            'quality_score': quality_score,
            'confidence': 0.95,
            'model_type': 'qualitynet'
        }

    def _inference_brisque(self, model: nn.Module, image: torch.Tensor, **kwargs) -> Dict[str, Any]:
        """
        BRISQUE ëª¨ë¸ë¡œ ì¶”ë¡ ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.
        """
        # BRISQUEëŠ” íŒ¨ì¹˜ ê¸°ë°˜ ë¶„ì„
        patch_size = self.inference_config['brisque']['patch_size']
        stride = self.inference_config['brisque']['stride']
        
        # ì´ë¯¸ì§€ë¥¼ íŒ¨ì¹˜ë¡œ ë¶„í• 
        patches = self._extract_patches(image, patch_size, stride)
        
        # ê° íŒ¨ì¹˜ì— ëŒ€í•´ í’ˆì§ˆ í‰ê°€
        patch_scores = []
        for patch in patches:
            with torch.no_grad():
                score = model(patch.unsqueeze(0))
                patch_scores.append(score.item())
        
        # ì „ì²´ í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°
        quality_score = np.mean(patch_scores)
        
        return {
            'quality_score': quality_score,
            'confidence': 0.90,
            'model_type': 'brisque',
            'patch_scores': patch_scores
        }

    def _inference_niqe(self, model: nn.Module, image: torch.Tensor, **kwargs) -> Dict[str, Any]:
        """
        NIQE ëª¨ë¸ë¡œ ì¶”ë¡ ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.
        """
        # NIQEëŠ” ìì—°ìŠ¤ëŸ¬ìš´ ì´ë¯¸ì§€ í’ˆì§ˆ í‰ê°€
        # ë‚®ì€ ì ìˆ˜ê°€ ë” ì¢‹ì€ í’ˆì§ˆì„ ì˜ë¯¸
        quality_score = model(image)
        
        return {
            'quality_score': quality_score.item(),
            'confidence': 0.88,
            'model_type': 'niqe'
        }

    def _inference_piqe(self, model: nn.Module, image: torch.Tensor, **kwargs) -> Dict[str, Any]:
        """
        PIQE ëª¨ë¸ë¡œ ì¶”ë¡ ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.
        """
        # PIQEëŠ” ì§€ê° ê¸°ë°˜ í’ˆì§ˆ í‰ê°€
        quality_score = model(image)
        
        return {
            'quality_score': quality_score.item(),
            'confidence': 0.92,
            'model_type': 'piqe'
        }

    def _extract_patches(self, image: torch.Tensor, patch_size: int, stride: int) -> List[torch.Tensor]:
        """
        ì´ë¯¸ì§€ì—ì„œ íŒ¨ì¹˜ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
        """
        patches = []
        h, w = image.shape[-2:]
        
        for i in range(0, h - patch_size + 1, stride):
            for j in range(0, w - patch_size + 1, stride):
                patch = image[..., i:i + patch_size, j:j + patch_size]
                patches.append(patch)
        
        return patches

    def _postprocess_result(self, result: Dict[str, Any], model_type: str) -> Dict[str, Any]:
        """
        ì¶”ë¡  ê²°ê³¼ë¥¼ í›„ì²˜ë¦¬í•©ë‹ˆë‹¤.
        """
        # í’ˆì§ˆ ë“±ê¸‰ ë¶„ë¥˜
        quality_score = result['quality_score']
        
        if model_type == 'qualitynet':
            # QualityNet: ë†’ì€ ì ìˆ˜ê°€ ì¢‹ì€ í’ˆì§ˆ
            if quality_score >= 0.8:
                quality_grade = 'Excellent'
            elif quality_score >= 0.6:
                quality_grade = 'Good'
            elif quality_score >= 0.4:
                quality_grade = 'Fair'
            else:
                quality_grade = 'Poor'
        elif model_type == 'brisque':
            # BRISQUE: ë‚®ì€ ì ìˆ˜ê°€ ì¢‹ì€ í’ˆì§ˆ
            if quality_score <= 20:
                quality_grade = 'Excellent'
            elif quality_score <= 40:
                quality_grade = 'Good'
            elif quality_score <= 60:
                quality_grade = 'Fair'
            else:
                quality_grade = 'Poor'
        elif model_type == 'niqe':
            # NIQE: ë‚®ì€ ì ìˆ˜ê°€ ì¢‹ì€ í’ˆì§ˆ
            if quality_score <= 3:
                quality_grade = 'Excellent'
            elif quality_score <= 5:
                quality_grade = 'Good'
            elif quality_score <= 7:
                quality_grade = 'Fair'
            else:
                quality_grade = 'Poor'
        elif model_type == 'piqe':
            # PIQE: ë‚®ì€ ì ìˆ˜ê°€ ì¢‹ì€ í’ˆì§ˆ
            if quality_score <= 30:
                quality_grade = 'Excellent'
            elif quality_score <= 50:
                quality_grade = 'Good'
            elif quality_score <= 70:
                quality_grade = 'Fair'
            else:
                quality_grade = 'Poor'
        else:
            quality_grade = 'Unknown'
        
        # ê²°ê³¼ì— í’ˆì§ˆ ë“±ê¸‰ ì¶”ê°€
        result['quality_grade'] = quality_grade
        result['timestamp'] = torch.cuda.Event() if torch.cuda.is_available() else None
        
        return result

    def batch_assess_quality(self, images: List[Union[np.ndarray, Image.Image, torch.Tensor]],
                           model_type: str = 'qualitynet', **kwargs) -> List[Dict[str, Any]]:
        """
        ì—¬ëŸ¬ ì´ë¯¸ì§€ì˜ í’ˆì§ˆì„ ì¼ê´„ í‰ê°€í•©ë‹ˆë‹¤.
        """
        results = []
        for i, image in enumerate(images):
            try:
                result = self.assess_image_quality(image, model_type, **kwargs)
                result['image_index'] = i
                results.append(result)
            except Exception as e:
                logger.error(f"âŒ Failed to assess image {i}: {e}")
                results.append({
                    'image_index': i,
                    'error': str(e),
                    'quality_score': 0.0,
                    'quality_grade': 'Error'
                })
        
        return results

    def get_model_info(self, model_type: str) -> Dict[str, Any]:
        """
        ëª¨ë¸ ì •ë³´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
        """
        if model_type in self.inference_config:
            return {
                'model_type': model_type,
                'supported': True,
                'config': self.inference_config[model_type],
                'device': str(self.device)
            }
        else:
            return {
                'model_type': model_type,
                'supported': False,
                'error': 'Unsupported model type'
            }
