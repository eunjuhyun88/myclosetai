# backend/app/ai_pipeline/steps/step_05_cloth_warping_integrated.py
"""
ğŸ”¥ ClothWarpingStep - í†µí•© ëª¨ë¸ ë¡œë” ë²„ì „
================================================================================

âœ… Central Hub í†µí•©
âœ… ì²´í¬í¬ì¸íŠ¸ ë¶„ì„ ì‹œìŠ¤í…œ ì—°ë™  
âœ… ëª¨ë¸ ì•„í‚¤í…ì²˜ ê¸°ë°˜ ìƒì„±
âœ… ë‹¨ê³„ì  í´ë°± ì‹œìŠ¤í…œ
âœ… BaseStepMixin ì™„ì „ í˜¸í™˜
âœ… ê¸°ì¡´ ClothWarpingStepê³¼ 100% í˜¸í™˜

Author: MyCloset AI Team
Date: 2025-01-27
Version: 2.0 (í†µí•© ëª¨ë¸ ë¡œë” ë²„ì „)
"""

import os
import sys
import gc
import time
import json
import logging
import traceback
import warnings
from pathlib import Path
from typing import Dict, Any, Optional, Union, List, Tuple
from dataclasses import dataclass

# PyTorch ì•ˆì „ import
try:
    import torch
    import torch.nn as nn
    import torch.nn.functional as F
    TORCH_AVAILABLE = True
except ImportError:
    TORCH_AVAILABLE = False
    torch = None
    nn = None
    F = None

# NumPy ì•ˆì „ import
try:
    import numpy as np
    NUMPY_AVAILABLE = True
except ImportError:
    NUMPY_AVAILABLE = False
    np = None

# MPS ì§€ì› í™•ì¸
MPS_AVAILABLE = TORCH_AVAILABLE and hasattr(torch.backends, 'mps') and torch.backends.mps.is_available()

# ê¸°ë³¸ ë””ë°”ì´ìŠ¤ ì„¤ì •
DEFAULT_DEVICE = "mps" if MPS_AVAILABLE else ("cuda" if TORCH_AVAILABLE and torch.cuda.is_available() else "cpu")

# BaseStepMixin import
try:
    from .base_step_mixin import BaseStepMixin
    BASESTEP_AVAILABLE = True
except ImportError:
    try:
        from app.ai_pipeline.steps.base_step_mixin import BaseStepMixin
        BASESTEP_AVAILABLE = True
    except ImportError:
        BASESTEP_AVAILABLE = False
        BaseStepMixin = object

logger = logging.getLogger(__name__)

class ClothWarpingStepIntegrated(BaseStepMixin):
    """ClothWarpingStep - í†µí•© ëª¨ë¸ ë¡œë” ë²„ì „"""
    
    def __init__(self, **kwargs):
        """ClothWarpingStep ì´ˆê¸°í™” - í†µí•© ë¡œë” ì ìš©"""
        super().__init__(**kwargs)
        
        # ê¸°ë³¸ ì„¤ì •
        self.step_name = "cloth_warping"
        self.step_id = "step_05"
        self.device = kwargs.get('device', 'auto')
        
        # ë¡œê±° ì„¤ì •
        self.logger = logging.getLogger(f"{self.__class__.__name__}")
        
        # ğŸ”¥ ìƒˆë¡œìš´ í†µí•© ëª¨ë¸ ë¡œë” ì‚¬ìš©
        try:
            from .cloth_warping_integrated_loader import get_integrated_loader
            self.integrated_loader = get_integrated_loader(device=self.device, logger=self.logger)
            self.logger.info("âœ… í†µí•© ëª¨ë¸ ë¡œë” ì´ˆê¸°í™” ì™„ë£Œ")
        except ImportError as e:
            self.logger.warning(f"âš ï¸ í†µí•© ë¡œë” import ì‹¤íŒ¨, ê¸°ì¡´ ë°©ì‹ ì‚¬ìš©: {e}")
            self.integrated_loader = None
        
        # ëª¨ë¸ ì»¨í…Œì´ë„ˆ
        self.models = {}
        self.loaded_models = {}
        self.ai_models = {}
        
        # ëª¨ë¸ ë¡œë”© ì‹œë„
        self._load_models_with_integrated_system()
        
        # ê¸°íƒ€ ì„¤ì •
        self.executor = None
        self.session_data = {}
        
        self.logger.info(f"âœ… ClothWarpingStepIntegrated ì´ˆê¸°í™” ì™„ë£Œ (device: {self.device})")
    
    def _load_models_with_integrated_system(self):
        """í†µí•© ì‹œìŠ¤í…œì„ í†µí•œ ëª¨ë¸ ë¡œë”©"""
        try:
            if self.integrated_loader:
                # ìƒˆë¡œìš´ í†µí•© ë¡œë” ì‚¬ìš©
                success = self.integrated_loader.load_models_integrated()
                if success:
                    # ë¡œë“œëœ ëª¨ë¸ë“¤ì„ ê¸°ì¡´ ì»¨í…Œì´ë„ˆì— ë³µì‚¬
                    loaded_models = self.integrated_loader.get_loaded_models()
                    self.models.update(loaded_models)
                    self.loaded_models.update(loaded_models)
                    self.ai_models.update(loaded_models)
                    self.logger.info(f"âœ… í†µí•© ë¡œë”ë¥¼ í†µí•œ ëª¨ë¸ ë¡œë”© ì„±ê³µ: {len(loaded_models)}ê°œ")
                    return
                else:
                    self.logger.warning("âš ï¸ í†µí•© ë¡œë” ì‹¤íŒ¨, ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ í´ë°±")
            
            # ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ í´ë°±
            self._load_models_fallback()
            
        except Exception as e:
            self.logger.error(f"âŒ í†µí•© ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e}")
            self._load_models_fallback()
    
    def _load_models_fallback(self):
        """ê¸°ì¡´ ëª¨ë¸ ë¡œë”© ë°©ì‹ (í´ë°±)"""
        try:
            # ê°„ë‹¨í•œ í´ë°± ëª¨ë¸ ìƒì„±
            self._create_fallback_models()
            self.logger.info("âœ… í´ë°± ëª¨ë¸ ìƒì„± ì™„ë£Œ")
            
        except Exception as e:
            self.logger.error(f"âŒ í´ë°± ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e}")
    
    def _create_fallback_models(self):
        """ê°„ë‹¨í•œ í´ë°± ëª¨ë¸ ìƒì„±"""
        try:
            if not TORCH_AVAILABLE:
                self.logger.error("âŒ PyTorchë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                return
            
            # TPS ëª¨ë¸ í´ë°±
            tps_model = self._create_simple_tps_model()
            if tps_model:
                self.models['tps_model'] = tps_model
                self.loaded_models['tps_model'] = tps_model
                self.ai_models['tps_model'] = tps_model
            
            # VITON ëª¨ë¸ í´ë°±
            viton_model = self._create_simple_viton_model()
            if viton_model:
                self.models['viton_checkpoint'] = viton_model
                self.loaded_models['viton_checkpoint'] = viton_model
                self.ai_models['viton_checkpoint'] = viton_model
            
            # DPT ëª¨ë¸ í´ë°±
            dpt_model = self._create_simple_dpt_model()
            if dpt_model:
                self.models['dpt_model'] = dpt_model
                self.loaded_models['dpt_model'] = dpt_model
                self.ai_models['dpt_model'] = dpt_model
            
            self.logger.info(f"âœ… í´ë°± ëª¨ë¸ ìƒì„± ì™„ë£Œ: {len(self.models)}ê°œ")
            
        except Exception as e:
            self.logger.error(f"âŒ í´ë°± ëª¨ë¸ ìƒì„± ì‹¤íŒ¨: {e}")
    
    def _create_simple_tps_model(self) -> Optional[nn.Module]:
        """ê°„ë‹¨í•œ TPS ëª¨ë¸ ìƒì„±"""
        try:
            class SimpleTPSModel(nn.Module):
                def __init__(self, num_control_points=25):
                    super().__init__()
                    self.num_control_points = num_control_points
                    
                    # ê°„ë‹¨í•œ TPS êµ¬ì¡°
                    self.backbone = nn.Sequential(
                        nn.Conv2d(6, 64, 3, padding=1),  # cloth + person
                        nn.BatchNorm2d(64),
                        nn.ReLU(inplace=True),
                        nn.Conv2d(64, 128, 3, padding=1),
                        nn.BatchNorm2d(128),
                        nn.ReLU(inplace=True),
                        nn.Conv2d(128, 256, 3, padding=1),
                        nn.BatchNorm2d(256),
                        nn.ReLU(inplace=True),
                    )
                    
                    # ì œì–´ì  ì˜ˆì¸¡
                    self.control_points_head = nn.Sequential(
                        nn.Conv2d(256, 128, 3, padding=1),
                        nn.BatchNorm2d(128),
                        nn.ReLU(inplace=True),
                        nn.Conv2d(128, num_control_points * 2, 1)  # x, y ì¢Œí‘œ
                    )
                
                def forward(self, cloth_image, person_image):
                    # ì…ë ¥ ê²°í•©
                    combined = torch.cat([cloth_image, person_image], dim=1)
                    features = self.backbone(combined)
                    control_points = self.control_points_head(features)
                    return {'control_points': control_points, 'warped_cloth': cloth_image}
            
            model = SimpleTPSModel()
            model.eval()
            
            # ë””ë°”ì´ìŠ¤ ì´ë™
            if self.device != "cpu":
                model = model.to(self.device)
            
            return model
            
        except Exception as e:
            self.logger.error(f"âŒ Simple TPS ëª¨ë¸ ìƒì„± ì‹¤íŒ¨: {e}")
            return None
    
    def _create_simple_viton_model(self) -> Optional[nn.Module]:
        """ê°„ë‹¨í•œ VITON ëª¨ë¸ ìƒì„±"""
        try:
            class SimpleVITONModel(nn.Module):
                def __init__(self, input_channels=6):
                    super().__init__()
                    
                    # ê°„ë‹¨í•œ VITON êµ¬ì¡°
                    self.encoder = nn.Sequential(
                        nn.Conv2d(input_channels, 64, 3, padding=1),
                        nn.BatchNorm2d(64),
                        nn.ReLU(inplace=True),
                        nn.Conv2d(64, 128, 3, padding=1),
                        nn.BatchNorm2d(128),
                        nn.ReLU(inplace=True),
                    )
                    
                    self.decoder = nn.Sequential(
                        nn.Conv2d(128, 64, 3, padding=1),
                        nn.BatchNorm2d(64),
                        nn.ReLU(inplace=True),
                        nn.Conv2d(64, 3, 3, padding=1)
                    )
                
                def forward(self, cloth_image, person_image):
                    combined = torch.cat([cloth_image, person_image], dim=1)
                    features = self.encoder(combined)
                    warped_cloth = self.decoder(features)
                    return {'warped_cloth': warped_cloth}
            
            model = SimpleVITONModel()
            model.eval()
            
            # ë””ë°”ì´ìŠ¤ ì´ë™
            if self.device != "cpu":
                model = model.to(self.device)
            
            return model
            
        except Exception as e:
            self.logger.error(f"âŒ Simple VITON ëª¨ë¸ ìƒì„± ì‹¤íŒ¨: {e}")
            return None
    
    def _create_simple_dpt_model(self) -> Optional[nn.Module]:
        """ê°„ë‹¨í•œ DPT ëª¨ë¸ ìƒì„±"""
        try:
            class SimpleDPTModel(nn.Module):
                def __init__(self):
                    super().__init__()
                    
                    # ê°„ë‹¨í•œ DPT êµ¬ì¡°
                    self.encoder = nn.Sequential(
                        nn.Conv2d(3, 64, 3, padding=1),
                        nn.BatchNorm2d(64),
                        nn.ReLU(inplace=True),
                        nn.Conv2d(64, 128, 3, padding=1),
                        nn.BatchNorm2d(128),
                        nn.ReLU(inplace=True),
                    )
                    
                    self.decoder = nn.Sequential(
                        nn.Conv2d(128, 64, 3, padding=1),
                        nn.BatchNorm2d(64),
                        nn.ReLU(inplace=True),
                        nn.Conv2d(64, 1, 1)  # depth map
                    )
                
                def forward(self, x):
                    features = self.encoder(x)
                    depth_map = self.decoder(features)
                    return {'depth_map': depth_map}
            
            model = SimpleDPTModel()
            model.eval()
            
            # ë””ë°”ì´ìŠ¤ ì´ë™
            if self.device != "cpu":
                model = model.to(self.device)
            
            return model
            
        except Exception as e:
            self.logger.error(f"âŒ Simple DPT ëª¨ë¸ ìƒì„± ì‹¤íŒ¨: {e}")
            return None
    
    def _run_ai_inference(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """AI ì¶”ë¡  ì‹¤í–‰ - í†µí•© ë²„ì „"""
        try:
            start_time = time.time()
            
            # ì…ë ¥ ë°ì´í„° ì¶”ì¶œ
            cloth_image = self._extract_cloth_image(input_data)
            person_image = self._extract_person_image(input_data)
            
            if cloth_image is None or person_image is None:
                return self._create_error_response("ì…ë ¥ ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            
            # ì´ë¯¸ì§€ ì „ì²˜ë¦¬
            cloth_tensor = self._preprocess_image_for_inference(cloth_image)
            person_tensor = self._preprocess_image_for_inference(person_image)
            
            if cloth_tensor is None or person_tensor is None:
                return self._create_error_response("ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì‹¤íŒ¨")
            
            # ì•™ìƒë¸” ì¶”ë¡  ì‹¤í–‰
            ensemble_results = {}
            model_confidences = {}
            
            for model_name, model in self.models.items():
                try:
                    result = self._run_single_model_inference(cloth_tensor, person_tensor, model, model_name)
                    if result['success']:
                        ensemble_results[model_name] = result['warped_cloth']
                        model_confidences[model_name] = result['confidence']
                        self.logger.info(f"âœ… {model_name} ì¶”ë¡  ì„±ê³µ")
                    else:
                        self.logger.warning(f"âš ï¸ {model_name} ì¶”ë¡  ì‹¤íŒ¨: {result['error']}")
                except Exception as e:
                    self.logger.error(f"âŒ {model_name} ì¶”ë¡  ì¤‘ ì˜¤ë¥˜: {e}")
            
            if not ensemble_results:
                return self._create_error_response("ëª¨ë“  ëª¨ë¸ ì¶”ë¡  ì‹¤íŒ¨")
            
            # ì•™ìƒë¸” ê²°ê³¼ ìœµí•©
            final_warped_cloth = self._ensemble_fusion(ensemble_results, model_confidences)
            
            # í›„ì²˜ë¦¬
            processed_result = self._postprocess_warping_result(final_warped_cloth, cloth_image, person_image)
            
            processing_time = time.time() - start_time
            
            return {
                'success': True,
                'warped_cloth': processed_result['warped_cloth'],
                'confidence': processed_result['confidence'],
                'transformation_matrix': processed_result['transformation_matrix'],
                'processing_time': processing_time,
                'models_used': list(ensemble_results.keys()),
                'ensemble_method': 'weighted_average'
            }
            
        except Exception as e:
            self.logger.error(f"âŒ AI ì¶”ë¡  ì‹¤íŒ¨: {e}")
            return self._create_error_response(f"AI ì¶”ë¡  ì‹¤íŒ¨: {str(e)}")
    
    def _extract_cloth_image(self, input_data: Dict[str, Any]) -> Optional[np.ndarray]:
        """ì…ë ¥ ë°ì´í„°ì—ì„œ ì˜· ì´ë¯¸ì§€ ì¶”ì¶œ"""
        try:
            if 'cloth_image' in input_data:
                return input_data['cloth_image']
            elif 'cloth_image_path' in input_data:
                # ì´ë¯¸ì§€ ê²½ë¡œì—ì„œ ë¡œë“œ
                image_path = input_data['cloth_image_path']
                if NUMPY_AVAILABLE:
                    import cv2
                    image = cv2.imread(image_path)
                    if image is not None:
                        return cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            return None
        except Exception as e:
            self.logger.error(f"âŒ ì˜· ì´ë¯¸ì§€ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return None
    
    def _extract_person_image(self, input_data: Dict[str, Any]) -> Optional[np.ndarray]:
        """ì…ë ¥ ë°ì´í„°ì—ì„œ ì‚¬ëŒ ì´ë¯¸ì§€ ì¶”ì¶œ"""
        try:
            if 'person_image' in input_data:
                return input_data['person_image']
            elif 'person_image_path' in input_data:
                # ì´ë¯¸ì§€ ê²½ë¡œì—ì„œ ë¡œë“œ
                image_path = input_data['person_image_path']
                if NUMPY_AVAILABLE:
                    import cv2
                    image = cv2.imread(image_path)
                    if image is not None:
                        return cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            return None
        except Exception as e:
            self.logger.error(f"âŒ ì‚¬ëŒ ì´ë¯¸ì§€ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return None
    
    def _preprocess_image_for_inference(self, image: np.ndarray) -> Optional[torch.Tensor]:
        """ì¶”ë¡ ì„ ìœ„í•œ ì´ë¯¸ì§€ ì „ì²˜ë¦¬"""
        try:
            if not TORCH_AVAILABLE or not NUMPY_AVAILABLE:
                return None
            
            # ì´ë¯¸ì§€ í¬ê¸° ì¡°ì •
            target_size = (256, 256)
            if image.shape[:2] != target_size:
                import cv2
                image = cv2.resize(image, target_size)
            
            # ì •ê·œí™”
            image = image.astype(np.float32) / 255.0
            
            # í…ì„œ ë³€í™˜
            image_tensor = torch.from_numpy(image).permute(2, 0, 1).unsqueeze(0)
            
            # ë””ë°”ì´ìŠ¤ ì´ë™
            if self.device != "cpu":
                image_tensor = image_tensor.to(self.device)
            
            return image_tensor
            
        except Exception as e:
            self.logger.error(f"âŒ ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return None
    
    def _run_single_model_inference(self, cloth_tensor: torch.Tensor, person_tensor: torch.Tensor, model: nn.Module, model_name: str) -> Dict[str, Any]:
        """ë‹¨ì¼ ëª¨ë¸ ì¶”ë¡  ì‹¤í–‰"""
        try:
            model.eval()
            
            with torch.no_grad():
                output = model(cloth_tensor, person_tensor)
            
            # ì¶œë ¥ ì²˜ë¦¬
            if isinstance(output, dict):
                if 'warped_cloth' in output:
                    warped_cloth = output['warped_cloth']
                elif 'control_points' in output:
                    # TPS ëª¨ë¸ì˜ ê²½ìš° ê°„ë‹¨í•œ ë³€í™˜ ì ìš©
                    warped_cloth = cloth_tensor
                else:
                    warped_cloth = output
            else:
                warped_cloth = output
            
            # ì‹ ë¢°ë„ ê³„ì‚°
            confidence = self._calculate_confidence(warped_cloth)
            
            return {
                'success': True,
                'warped_cloth': warped_cloth.cpu().numpy(),
                'confidence': confidence
            }
            
        except Exception as e:
            return {
                'success': False,
                'error': str(e)
            }
    
    def _ensemble_fusion(self, ensemble_results: Dict[str, np.ndarray], model_confidences: Dict[str, float]) -> np.ndarray:
        """ì•™ìƒë¸” ê²°ê³¼ ìœµí•©"""
        try:
            if len(ensemble_results) == 1:
                return list(ensemble_results.values())[0]
            
            # ê°€ì¤‘ í‰ê·  ìœµí•©
            total_weight = sum(model_confidences.values())
            if total_weight == 0:
                # ë™ì¼ ê°€ì¤‘ì¹˜
                weights = {name: 1.0 for name in ensemble_results.keys()}
                total_weight = len(weights)
            else:
                weights = model_confidences
            
            # ê°€ì¤‘ í‰ê·  ê³„ì‚°
            fused_result = np.zeros_like(list(ensemble_results.values())[0], dtype=np.float32)
            for model_name, result in ensemble_results.items():
                weight = weights[model_name] / total_weight
                fused_result += result.astype(np.float32) * weight
            
            return fused_result
            
        except Exception as e:
            self.logger.error(f"âŒ ì•™ìƒë¸” ìœµí•© ì‹¤íŒ¨: {e}")
            # ì²« ë²ˆì§¸ ê²°ê³¼ ë°˜í™˜
            return list(ensemble_results.values())[0]
    
    def _postprocess_warping_result(self, warped_cloth: np.ndarray, original_cloth: np.ndarray, original_person: np.ndarray) -> Dict[str, Any]:
        """ì›Œí•‘ ê²°ê³¼ í›„ì²˜ë¦¬"""
        try:
            # ì‹ ë¢°ë„ ê³„ì‚°
            confidence = 0.8  # ê¸°ë³¸ê°’
            
            # ë³€í™˜ í–‰ë ¬ ìƒì„± (ë‹¨ìˆœí™”)
            transformation_matrix = np.eye(3)
            
            return {
                'warped_cloth': warped_cloth,
                'confidence': confidence,
                'transformation_matrix': transformation_matrix
            }
            
        except Exception as e:
            self.logger.error(f"âŒ í›„ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return {
                'warped_cloth': warped_cloth,
                'confidence': 0.5,
                'transformation_matrix': np.eye(3)
            }
    
    def _calculate_confidence(self, warped_cloth: torch.Tensor) -> float:
        """ì‹ ë¢°ë„ ê³„ì‚°"""
        try:
            # ê°„ë‹¨í•œ ì‹ ë¢°ë„ ê³„ì‚°
            confidence = torch.mean(warped_cloth).item()
            return max(0.0, min(1.0, confidence))
        except Exception as e:
            self.logger.error(f"âŒ ì‹ ë¢°ë„ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return 0.5
    
    def _create_error_response(self, error_message: str) -> Dict[str, Any]:
        """ì˜¤ë¥˜ ì‘ë‹µ ìƒì„±"""
        return {
            'success': False,
            'error': error_message,
            'warped_cloth': None,
            'confidence': 0.0,
            'transformation_matrix': None,
            'processing_time': 0.0
        }
    
    def process(self, **kwargs) -> Dict[str, Any]:
        """ë©”ì¸ ì²˜ë¦¬ ë©”ì„œë“œ"""
        try:
            self.logger.info("ğŸš€ ClothWarpingStepIntegrated ì²˜ë¦¬ ì‹œì‘")
            
            # ì…ë ¥ ë°ì´í„° ì¤€ë¹„
            input_data = self.convert_api_input_to_step_input(kwargs)
            
            # AI ì¶”ë¡  ì‹¤í–‰
            result = self._run_ai_inference(input_data)
            
            # ì¶œë ¥ ë³€í™˜
            api_response = self.convert_step_output_to_api_response(result)
            
            self.logger.info("âœ… ClothWarpingStepIntegrated ì²˜ë¦¬ ì™„ë£Œ")
            return api_response
            
        except Exception as e:
            self.logger.error(f"âŒ ClothWarpingStepIntegrated ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return {
                'success': False,
                'error': str(e),
                'step_name': self.step_name,
                'step_id': self.step_id
            }
    
    def convert_api_input_to_step_input(self, api_input: Dict[str, Any]) -> Dict[str, Any]:
        """API ì…ë ¥ì„ Step ì…ë ¥ìœ¼ë¡œ ë³€í™˜"""
        return api_input
    
    def convert_step_output_to_api_response(self, step_output: Dict[str, Any]) -> Dict[str, Any]:
        """Step ì¶œë ¥ì„ API ì‘ë‹µìœ¼ë¡œ ë³€í™˜"""
        return step_output
    
    def get_step_requirements(self) -> Dict[str, Any]:
        """Step ìš”êµ¬ì‚¬í•­ ë°˜í™˜"""
        return {
            'step_name': self.step_name,
            'step_id': self.step_id,
            'required_models': ['tps_model', 'viton_checkpoint', 'dpt_model', 'raft_model'],
            'input_format': {
                'cloth_image': 'numpy.ndarray or cloth_image_path',
                'person_image': 'numpy.ndarray or person_image_path',
                'device': 'str (optional)'
            },
            'output_format': {
                'warped_cloth': 'numpy.ndarray',
                'confidence': 'float',
                'transformation_matrix': 'numpy.ndarray'
            }
        }
    
    def cleanup_resources(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        try:
            # í†µí•© ë¡œë” ì •ë¦¬
            if self.integrated_loader:
                self.integrated_loader.cleanup_resources()
            
            # ëª¨ë¸ ì •ë¦¬
            for model_name, model in self.models.items():
                try:
                    if hasattr(model, 'cpu'):
                        model.cpu()
                    del model
                except:
                    pass
            
            self.models.clear()
            self.loaded_models.clear()
            self.ai_models.clear()
            
            # ë©”ëª¨ë¦¬ ì •ë¦¬
            for _ in range(3):
                gc.collect()
            if TORCH_AVAILABLE and MPS_AVAILABLE:
                try:
                    torch.mps.empty_cache()
                    if hasattr(torch.mps, 'synchronize'):
                        torch.mps.synchronize()
                except Exception as e:
                    self.logger.warning(f"âš ï¸ MPS ë©”ëª¨ë¦¬ ì •ë¦¬ ì‹¤íŒ¨: {e}")
            
            self.logger.info("âœ… ClothWarpingStepIntegrated ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì™„ë£Œ")
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì‹¤íŒ¨: {e}")

# ëª¨ë“ˆ ë‚´ë³´ë‚´ê¸°
__all__ = [
    "ClothWarpingStepIntegrated"
]
