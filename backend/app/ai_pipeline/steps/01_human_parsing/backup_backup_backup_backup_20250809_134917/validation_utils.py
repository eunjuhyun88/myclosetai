"""
ğŸ”¥ Human Parsing ê²€ì¦ ìœ í‹¸ë¦¬í‹°
==========================

íŒŒì‹± ë§µ ê²€ì¦, í…ì„œ í˜•íƒœ ê²€ì¦, ì˜¤ë¥˜ ì²˜ë¦¬ í—¬í¼ í•¨ìˆ˜ë“¤ì„ í¬í•¨í•©ë‹ˆë‹¤.

ì£¼ìš” ê¸°ëŠ¥:
- íŒŒì‹± ë§µ ìœ íš¨ì„± ê²€ì‚¬
- í…ì„œ í˜•íƒœ ê²€ì¦
- ì›ë³¸ í¬ê¸° ì•ˆì „í•œ ê²°ì •
- ì˜¤ë¥˜ ì²˜ë¦¬ ë° í´ë°± ë©”ì»¤ë‹ˆì¦˜

Author: MyCloset AI Team
Date: 2025-08-07
Version: 1.0
"""

import logging
import numpy as np
from typing import Tuple, Optional, Union, Any, Dict
from PIL import Image

logger = logging.getLogger(__name__)


class ConfidenceCalculator:
    """ì‹ ë¢°ë„ ê³„ì‚° ë° ë¶„ì„ í´ë˜ìŠ¤"""
    
    def __init__(self, logger_instance: Optional[logging.Logger] = None):
        self.logger = logger_instance or logger
    
    def calculate_confidence_map(self, parsing_map: np.ndarray, model_output: Any = None) -> np.ndarray:
        """
        íŒŒì‹± ë§µì—ì„œ ì‹ ë¢°ë„ ë§µì„ ê³„ì‚°í•©ë‹ˆë‹¤.
        
        Args:
            parsing_map: íŒŒì‹± ë§µ (np.ndarray)
            model_output: ëª¨ë¸ ì¶œë ¥ (ì„ íƒì‚¬í•­)
            
        Returns:
            ì‹ ë¢°ë„ ë§µ (np.ndarray)
        """
        try:
            if model_output is not None:
                return self._calculate_from_model_output(parsing_map, model_output)
            else:
                return self._calculate_from_parsing_map(parsing_map)
                
        except Exception as e:
            self.logger.error(f"âŒ ì‹ ë¢°ë„ ë§µ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return self._create_default_confidence_map(parsing_map.shape)
    
    def _calculate_from_model_output(self, parsing_map: np.ndarray, model_output: Any) -> np.ndarray:
        """ëª¨ë¸ ì¶œë ¥ì—ì„œ ì‹ ë¢°ë„ ë§µ ê³„ì‚°"""
        try:
            # ëª¨ë¸ ì¶œë ¥ì„ NumPy ë°°ì—´ë¡œ ë³€í™˜
            if hasattr(model_output, 'cpu') and hasattr(model_output, 'numpy'):
                # PyTorch í…ì„œ
                output_array = model_output.detach().cpu().numpy()
            elif isinstance(model_output, np.ndarray):
                output_array = model_output
            elif isinstance(model_output, dict):
                # ë”•ì…”ë„ˆë¦¬ì—ì„œ ì‹ ë¢°ë„ ì •ë³´ ì¶”ì¶œ
                for key in ['confidence', 'prob', 'logits', 'output']:
                    if key in model_output:
                        output_array = self._convert_to_numpy(model_output[key])
                        break
                else:
                    # í‚¤ë¥¼ ì°¾ì§€ ëª»í•œ ê²½ìš° ì²« ë²ˆì§¸ ê°’ ì‚¬ìš©
                    first_value = next(iter(model_output.values()))
                    output_array = self._convert_to_numpy(first_value)
            else:
                output_array = self._convert_to_numpy(model_output)
            
            # ì‹ ë¢°ë„ ê³„ì‚° (ì†Œí”„íŠ¸ë§¥ìŠ¤ ì ìš©)
            if len(output_array.shape) == 3 and output_array.shape[0] > 1:
                # ë‹¤ì¤‘ í´ë˜ìŠ¤ ì¶œë ¥
                confidence_map = self._calculate_multiclass_confidence(output_array, parsing_map)
            else:
                # ë‹¨ì¼ í´ë˜ìŠ¤ ì¶œë ¥
                confidence_map = self._calculate_singleclass_confidence(output_array)
            
            return confidence_map
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ ëª¨ë¸ ì¶œë ¥ì—ì„œ ì‹ ë¢°ë„ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return self._calculate_from_parsing_map(parsing_map)
    
    def _calculate_from_parsing_map(self, parsing_map: np.ndarray) -> np.ndarray:
        """íŒŒì‹± ë§µì—ì„œ ì‹ ë¢°ë„ ë§µ ê³„ì‚°"""
        try:
            # íŒŒì‹± ë§µì˜ ê²½ê³„ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‹ ë¢°ë„ ê³„ì‚°
            confidence_map = np.ones_like(parsing_map, dtype=np.float32)
            
            # ê²½ê³„ ì˜ì—­ ì‹ ë¢°ë„ ê°ì†Œ
            from scipy import ndimage
            if hasattr(ndimage, 'binary_erosion'):
                eroded = ndimage.binary_erosion(parsing_map > 0, iterations=1)
                boundary = (parsing_map > 0) & ~eroded
                confidence_map[boundary] = 0.7
            
            # ë…¸ì´ì¦ˆ ì˜ì—­ ì‹ ë¢°ë„ ê°ì†Œ
            small_components = self._remove_small_components(parsing_map > 0, min_size=50)
            confidence_map[~small_components] *= 0.5
            
            return confidence_map
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ íŒŒì‹± ë§µì—ì„œ ì‹ ë¢°ë„ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return self._create_default_confidence_map(parsing_map.shape)
    
    def _calculate_multiclass_confidence(self, output_array: np.ndarray, parsing_map: np.ndarray) -> np.ndarray:
        """ë‹¤ì¤‘ í´ë˜ìŠ¤ ì¶œë ¥ì—ì„œ ì‹ ë¢°ë„ ê³„ì‚°"""
        try:
            # ì†Œí”„íŠ¸ë§¥ìŠ¤ ì ìš©
            exp_output = np.exp(output_array - np.max(output_array, axis=0, keepdims=True))
            softmax_output = exp_output / np.sum(exp_output, axis=0, keepdims=True)
            
            # íŒŒì‹± ë§µì— í•´ë‹¹í•˜ëŠ” í´ë˜ìŠ¤ì˜ ì‹ ë¢°ë„ ì¶”ì¶œ
            confidence_map = np.zeros(parsing_map.shape, dtype=np.float32)
            
            for class_id in range(softmax_output.shape[0]):
                mask = (parsing_map == class_id)
                confidence_map[mask] = softmax_output[class_id, mask]
            
            return confidence_map
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ ë‹¤ì¤‘ í´ë˜ìŠ¤ ì‹ ë¢°ë„ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return np.ones(parsing_map.shape, dtype=np.float32) * 0.8
    
    def _calculate_singleclass_confidence(self, output_array: np.ndarray) -> np.ndarray:
        """ë‹¨ì¼ í´ë˜ìŠ¤ ì¶œë ¥ì—ì„œ ì‹ ë¢°ë„ ê³„ì‚°"""
        try:
            if len(output_array.shape) == 3:
                # (1, H, W) í˜•íƒœ
                confidence_map = output_array[0]
            else:
                # (H, W) í˜•íƒœ
                confidence_map = output_array
            
            # ì‹œê·¸ëª¨ì´ë“œ ì ìš© (0-1 ë²”ìœ„ë¡œ ì •ê·œí™”)
            confidence_map = 1 / (1 + np.exp(-confidence_map))
            
            return confidence_map
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ ë‹¨ì¼ í´ë˜ìŠ¤ ì‹ ë¢°ë„ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return np.ones(output_array.shape[-2:], dtype=np.float32) * 0.8
    
    def _remove_small_components(self, binary_map: np.ndarray, min_size: int = 50) -> np.ndarray:
        """ì‘ì€ ì—°ê²° ìš”ì†Œ ì œê±°"""
        try:
            from scipy import ndimage
            labeled, num_features = ndimage.label(binary_map)
            
            # ê° ì—°ê²° ìš”ì†Œì˜ í¬ê¸° ê³„ì‚°
            component_sizes = np.bincount(labeled.ravel())[1:]  # 0ë²ˆì€ ë°°ê²½ì´ë¯€ë¡œ ì œì™¸
            
            # ì‘ì€ ì—°ê²° ìš”ì†Œ ì œê±°
            for i, size in enumerate(component_sizes, 1):
                if size < min_size:
                    binary_map[labeled == i] = False
            
            return binary_map
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ ì‘ì€ ì—°ê²° ìš”ì†Œ ì œê±° ì‹¤íŒ¨: {e}")
            return binary_map
    
    def _convert_to_numpy(self, data: Any) -> np.ndarray:
        """ë‹¤ì–‘í•œ íƒ€ì…ì˜ ë°ì´í„°ë¥¼ NumPy ë°°ì—´ë¡œ ë³€í™˜"""
        try:
            if isinstance(data, np.ndarray):
                return data
            elif hasattr(data, 'cpu') and hasattr(data, 'numpy'):
                # PyTorch í…ì„œ
                return data.detach().cpu().numpy()
            elif isinstance(data, list):
                return np.array(data)
            else:
                return np.array(data)
                
        except Exception as e:
            self.logger.warning(f"âš ï¸ ë°ì´í„° ë³€í™˜ ì‹¤íŒ¨: {e}")
            raise
    
    def _create_default_confidence_map(self, shape: Tuple[int, ...]) -> np.ndarray:
        """ê¸°ë³¸ ì‹ ë¢°ë„ ë§µ ìƒì„±"""
        return np.ones(shape, dtype=np.float32) * 0.8
    
    def analyze_confidence_distribution(self, confidence_map: np.ndarray) -> Dict[str, float]:
        """ì‹ ë¢°ë„ ë¶„í¬ ë¶„ì„"""
        try:
            analysis = {
                'mean_confidence': float(np.mean(confidence_map)),
                'std_confidence': float(np.std(confidence_map)),
                'min_confidence': float(np.min(confidence_map)),
                'max_confidence': float(np.max(confidence_map)),
                'high_confidence_ratio': float(np.sum(confidence_map > 0.8) / confidence_map.size),
                'low_confidence_ratio': float(np.sum(confidence_map < 0.3) / confidence_map.size)
            }
            
            return analysis
            
        except Exception as e:
            self.logger.error(f"âŒ ì‹ ë¢°ë„ ë¶„í¬ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {
                'mean_confidence': 0.5,
                'std_confidence': 0.1,
                'min_confidence': 0.0,
                'max_confidence': 1.0,
                'high_confidence_ratio': 0.5,
                'low_confidence_ratio': 0.2
            }


class ParsingValidator:
    """íŒŒì‹± ê²°ê³¼ ì¢…í•© ê²€ì¦ í´ë˜ìŠ¤"""
    
    def __init__(self, logger_instance: Optional[logging.Logger] = None):
        self.logger = logger_instance or logger
        self.map_validator = ParsingMapValidator(logger_instance)
    
    def validate_parsing_result(self, parsing_result: Any, original_size: Tuple[int, int]) -> Dict[str, Any]:
        """
        íŒŒì‹± ê²°ê³¼ë¥¼ ì¢…í•©ì ìœ¼ë¡œ ê²€ì¦í•©ë‹ˆë‹¤.
        
        Args:
            parsing_result: ê²€ì¦í•  íŒŒì‹± ê²°ê³¼
            original_size: ì›ë³¸ ì´ë¯¸ì§€ í¬ê¸° (height, width)
            
        Returns:
            ê²€ì¦ëœ íŒŒì‹± ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        try:
            validated_result = {}
            
            # íŒŒì‹± ë§µ ê²€ì¦
            if 'parsing_map' in parsing_result:
                validated_result['parsing_map'] = self.map_validator.validate_parsing_map(
                    parsing_result['parsing_map'], original_size
                )
            
            # ì‹ ë¢°ë„ ë§µ ê²€ì¦
            if 'confidence_map' in parsing_result:
                validated_result['confidence_map'] = validate_confidence_map(
                    parsing_result['confidence_map'], original_size
                )
            
            # ë©”íƒ€ë°ì´í„° ê²€ì¦
            if 'metadata' in parsing_result:
                validated_result['metadata'] = self._validate_metadata(parsing_result['metadata'])
            
            # í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°
            validated_result['quality_score'] = self._calculate_quality_score(validated_result)
            
            return validated_result
            
        except Exception as e:
            self.logger.error(f"âŒ íŒŒì‹± ê²°ê³¼ ê²€ì¦ ì‹¤íŒ¨: {e}")
            return self._create_fallback_result(original_size)
    
    def _validate_metadata(self, metadata: Dict[str, Any]) -> Dict[str, Any]:
        """ë©”íƒ€ë°ì´í„° ê²€ì¦"""
        try:
            validated_metadata = {}
            
            # í•„ìˆ˜ í•„ë“œ ê²€ì¦
            required_fields = ['model_name', 'processing_time', 'input_size']
            for field in required_fields:
                if field in metadata:
                    validated_metadata[field] = metadata[field]
                else:
                    validated_metadata[field] = 'unknown'
            
            # ì¶”ê°€ í•„ë“œë“¤ ë³µì‚¬
            for key, value in metadata.items():
                if key not in validated_metadata:
                    validated_metadata[key] = value
            
            return validated_metadata
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ ë©”íƒ€ë°ì´í„° ê²€ì¦ ì‹¤íŒ¨: {e}")
            return {'model_name': 'unknown', 'processing_time': 0.0, 'input_size': (0, 0)}
    
    def _calculate_quality_score(self, validated_result: Dict[str, Any]) -> float:
        """í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°"""
        try:
            score = 0.0
            
            # íŒŒì‹± ë§µ í’ˆì§ˆ ì ìˆ˜
            if 'parsing_map' in validated_result:
                parsing_map = validated_result['parsing_map']
                if isinstance(parsing_map, np.ndarray):
                    # ìœ íš¨í•œ í”½ì…€ ë¹„ìœ¨ ê³„ì‚°
                    valid_pixels = np.sum(parsing_map > 0)
                    total_pixels = parsing_map.size
                    if total_pixels > 0:
                        score += (valid_pixels / total_pixels) * 0.6
            
            # ì‹ ë¢°ë„ ë§µ í’ˆì§ˆ ì ìˆ˜
            if 'confidence_map' in validated_result:
                confidence_map = validated_result['confidence_map']
                if isinstance(confidence_map, np.ndarray):
                    # í‰ê·  ì‹ ë¢°ë„ ê³„ì‚°
                    avg_confidence = np.mean(confidence_map)
                    score += avg_confidence * 0.4
            
            return min(score, 1.0)
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ í’ˆì§ˆ ì ìˆ˜ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return 0.5
    
    def _create_fallback_result(self, original_size: Tuple[int, int]) -> Dict[str, Any]:
        """í´ë°± ê²°ê³¼ ìƒì„±"""
        return {
            'parsing_map': self.map_validator._create_fallback_parsing_map(original_size),
            'confidence_map': np.ones(original_size, dtype=np.float32) * 0.5,
            'metadata': {
                'model_name': 'fallback',
                'processing_time': 0.0,
                'input_size': original_size
            },
            'quality_score': 0.5
        }


class ParsingMapValidator:
    """íŒŒì‹± ë§µ ê²€ì¦ ë° ì •ì œ í´ë˜ìŠ¤"""
    
    def __init__(self, logger_instance: Optional[logging.Logger] = None):
        self.logger = logger_instance or logger
    
    def validate_parsing_map(self, parsing_map: Any, original_size: Tuple[int, int]) -> np.ndarray:
        """
        íŒŒì‹± ë§µì„ ê²€ì¦í•˜ê³  ì •ì œí•©ë‹ˆë‹¤.
        
        Args:
            parsing_map: ê²€ì¦í•  íŒŒì‹± ë§µ (ë‹¤ì–‘í•œ íƒ€ì… ì§€ì›)
            original_size: ì›ë³¸ ì´ë¯¸ì§€ í¬ê¸° (height, width)
            
        Returns:
            ì •ì œëœ íŒŒì‹± ë§µ (np.ndarray)
        """
        try:
            # 1ë‹¨ê³„: íƒ€ì… ê²€ì¦ ë° ë³€í™˜
            parsing_map = self._convert_to_numpy(parsing_map)
            
            # 2ë‹¨ê³„: í˜•íƒœ ê²€ì¦
            parsing_map = self._validate_shape(parsing_map)
            
            # 3ë‹¨ê³„: ê°’ ê²€ì¦
            parsing_map = self._validate_values(parsing_map)
            
            # 4ë‹¨ê³„: í¬ê¸° ì¡°ì •
            parsing_map = self._resize_to_original(parsing_map, original_size)
            
            # 5ë‹¨ê³„: ìµœì¢… ê²€ì¦
            self._final_validation(parsing_map)
            
            return parsing_map
            
        except Exception as e:
            self.logger.error(f"âŒ íŒŒì‹± ë§µ ê²€ì¦ ì‹¤íŒ¨: {e}")
            return self._create_fallback_parsing_map(original_size)
    
    def _convert_to_numpy(self, parsing_map: Any) -> np.ndarray:
        """ë‹¤ì–‘í•œ íƒ€ì…ì˜ íŒŒì‹± ë§µì„ NumPy ë°°ì—´ë¡œ ë³€í™˜"""
        try:
            if isinstance(parsing_map, np.ndarray):
                return parsing_map
            elif hasattr(parsing_map, 'cpu') and hasattr(parsing_map, 'numpy'):
                # PyTorch í…ì„œ
                return parsing_map.detach().cpu().numpy()
            elif isinstance(parsing_map, list):
                return np.array(parsing_map)
            elif isinstance(parsing_map, dict):
                # ë”•ì…”ë„ˆë¦¬ì—ì„œ íŒŒì‹± ë§µ ì¶”ì¶œ
                for key in ['parsing_pred', 'parsing', 'output', 'parsing_output']:
                    if key in parsing_map:
                        return self._convert_to_numpy(parsing_map[key])
                # í‚¤ë¥¼ ì°¾ì§€ ëª»í•œ ê²½ìš° ì²« ë²ˆì§¸ ê°’ ì‚¬ìš©
                first_value = next(iter(parsing_map.values()))
                return self._convert_to_numpy(first_value)
            else:
                raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì‹± ë§µ íƒ€ì…: {type(parsing_map)}")
                
        except Exception as e:
            self.logger.warning(f"âš ï¸ íŒŒì‹± ë§µ ë³€í™˜ ì‹¤íŒ¨: {e}")
            raise
    
    def _validate_shape(self, parsing_map: np.ndarray) -> np.ndarray:
        """íŒŒì‹± ë§µ í˜•íƒœë¥¼ ê²€ì¦í•˜ê³  ì •ê·œí™”"""
        try:
            if len(parsing_map.shape) == 2:
                # 2D ë°°ì—´ - ê·¸ëŒ€ë¡œ ì‚¬ìš©
                return parsing_map
            elif len(parsing_map.shape) == 3:
                # 3D ë°°ì—´ - ì²« ë²ˆì§¸ ì±„ë„ ì‚¬ìš©
                if parsing_map.shape[0] == 1:
                    return parsing_map[0]
                elif parsing_map.shape[2] == 1:
                    return parsing_map[:, :, 0]
                else:
                    # ì²« ë²ˆì§¸ ë°°ì¹˜ ì‚¬ìš©
                    return parsing_map[0]
            elif len(parsing_map.shape) == 4:
                # 4D ë°°ì—´ - ì²« ë²ˆì§¸ ë°°ì¹˜, ì²« ë²ˆì§¸ ì±„ë„ ì‚¬ìš©
                return parsing_map[0, 0] if parsing_map.shape[1] == 1 else parsing_map[0]
            else:
                raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì‹± ë§µ ì°¨ì›: {parsing_map.shape}")
                
        except Exception as e:
            self.logger.warning(f"âš ï¸ íŒŒì‹± ë§µ í˜•íƒœ ê²€ì¦ ì‹¤íŒ¨: {e}")
            raise
    
    def _validate_values(self, parsing_map: np.ndarray) -> np.ndarray:
        """íŒŒì‹± ë§µ ê°’ì„ ê²€ì¦í•˜ê³  ì •ì œ"""
        try:
            # ë°ì´í„° íƒ€ì… ë³€í™˜
            if parsing_map.dtype != np.uint8:
                parsing_map = parsing_map.astype(np.uint8)
            
            # ê°’ ë²”ìœ„ ê²€ì¦ (0-19, 20ê°œ í´ë˜ìŠ¤)
            unique_values = np.unique(parsing_map)
            self.logger.debug(f"ğŸ” íŒŒì‹± ë§µ ê³ ìœ  ê°’ë“¤: {unique_values}")
            
            # ëª¨ë“  ê°’ì´ 0ì¸ ê²½ìš° ê²€ì‚¬
            if len(unique_values) == 1 and unique_values[0] == 0:
                self.logger.warning("âš ï¸ íŒŒì‹± ë§µì´ ë¹„ì–´ìˆê±°ë‚˜ ëª¨ë“  ê°’ì´ 0ì…ë‹ˆë‹¤. ê¸°ë³¸ê°’ì„ ìƒì„±í•©ë‹ˆë‹¤.")
                return self._create_default_parsing_map(parsing_map.shape)
            
            # ê°’ ë²”ìœ„ ê²€ì¦
            if parsing_map.max() > 19 or parsing_map.min() < 0:
                self.logger.warning(f"âš ï¸ íŒŒì‹± ë§µ ê°’ ë²”ìœ„ê°€ ì˜ëª»ë¨: {parsing_map.min()} ~ {parsing_map.max()}")
                # ë²”ìœ„ë¥¼ 0-19ë¡œ í´ë¦¬í•‘
                parsing_map = np.clip(parsing_map, 0, 19).astype(np.uint8)
            
            return parsing_map
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ íŒŒì‹± ë§µ ê°’ ê²€ì¦ ì‹¤íŒ¨: {e}")
            raise
    
    def _resize_to_original(self, parsing_map: np.ndarray, original_size: Tuple[int, int]) -> np.ndarray:
        """íŒŒì‹± ë§µì„ ì›ë³¸ í¬ê¸°ë¡œ ë¦¬ì‚¬ì´ì¦ˆ"""
        try:
            if parsing_map.shape[:2] != original_size:
                self.logger.debug(f"ğŸ” íŒŒì‹± ë§µ ë¦¬ì‚¬ì´ì¦ˆ: {parsing_map.shape[:2]} -> {original_size}")
                
                # PIL Imageë¡œ ë³€í™˜í•˜ì—¬ ë¦¬ì‚¬ì´ì¦ˆ
                parsing_pil = Image.fromarray(parsing_map)
                parsing_resized = parsing_pil.resize(
                    (original_size[1], original_size[0]),  # (width, height)
                    Image.NEAREST  # ë¶„í•  ë§µì—ëŠ” NEARESTê°€ ì í•©
                )
                parsing_map = np.array(parsing_resized)
                
            return parsing_map
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ íŒŒì‹± ë§µ ë¦¬ì‚¬ì´ì¦ˆ ì‹¤íŒ¨: {e}")
            raise
    
    def _final_validation(self, parsing_map: np.ndarray) -> None:
        """ìµœì¢… ê²€ì¦"""
        try:
            # í˜•íƒœ ê²€ì¦
            if len(parsing_map.shape) != 2:
                raise ValueError(f"ìµœì¢… íŒŒì‹± ë§µì´ 2Dê°€ ì•„ë‹˜: {parsing_map.shape}")
            
            # ê°’ ê²€ì¦
            if parsing_map.max() > 19 or parsing_map.min() < 0:
                raise ValueError(f"ìµœì¢… íŒŒì‹± ë§µ ê°’ ë²”ìœ„ ì˜¤ë¥˜: {parsing_map.min()} ~ {parsing_map.max()}")
            
            # ë°ì´í„° íƒ€ì… ê²€ì¦
            if parsing_map.dtype != np.uint8:
                raise ValueError(f"ìµœì¢… íŒŒì‹± ë§µ ë°ì´í„° íƒ€ì… ì˜¤ë¥˜: {parsing_map.dtype}")
            
            self.logger.debug(f"âœ… íŒŒì‹± ë§µ ê²€ì¦ ì™„ë£Œ: {parsing_map.shape}, ê°’ ë²”ìœ„: {parsing_map.min()} ~ {parsing_map.max()}")
            
        except Exception as e:
            self.logger.error(f"âŒ ìµœì¢… ê²€ì¦ ì‹¤íŒ¨: {e}")
            raise
    
    def _create_default_parsing_map(self, shape: Tuple[int, int]) -> np.ndarray:
        """ê¸°ë³¸ íŒŒì‹± ë§µ ìƒì„± (ëª¨ë“  ê°’ì´ 0ì¸ ê²½ìš°)"""
        try:
            # ê°„ë‹¨í•œ ì¸ì²´ í˜•íƒœ ìƒì„± (í…ŒìŠ¤íŠ¸ìš©)
            height, width = shape
            parsing_map = np.zeros(shape, dtype=np.uint8)
            
            # ì¤‘ì•™ì— ê°„ë‹¨í•œ ì¸ì²´ í˜•íƒœ ìƒì„±
            center_y, center_x = height // 2, width // 2
            
            # ëª¸í†µ ì˜ì—­ (í´ë˜ìŠ¤ 10: torso_skin)
            torso_height = height // 3
            torso_width = width // 4
            y1 = max(0, center_y - torso_height // 2)
            y2 = min(height, center_y + torso_height // 2)
            x1 = max(0, center_x - torso_width // 2)
            x2 = min(width, center_x + torso_width // 2)
            parsing_map[y1:y2, x1:x2] = 10
            
            # ë¨¸ë¦¬ ì˜ì—­ (í´ë˜ìŠ¤ 13: face)
            head_radius = min(torso_width // 3, height // 6)
            head_y = max(head_radius, y1 - head_radius)
            head_x = center_x
            for i in range(max(0, head_y - head_radius), min(height, head_y + head_radius)):
                for j in range(max(0, head_x - head_radius), min(width, head_x + head_radius)):
                    if (i - head_y) ** 2 + (j - head_x) ** 2 <= head_radius ** 2:
                        parsing_map[i, j] = 13
            
            self.logger.info("âœ… ê¸°ë³¸ íŒŒì‹± ë§µ ìƒì„± ì™„ë£Œ")
            return parsing_map
            
        except Exception as e:
            self.logger.error(f"âŒ ê¸°ë³¸ íŒŒì‹± ë§µ ìƒì„± ì‹¤íŒ¨: {e}")
            return np.zeros(shape, dtype=np.uint8)
    
    def _create_fallback_parsing_map(self, original_size: Tuple[int, int]) -> np.ndarray:
        """í´ë°± íŒŒì‹± ë§µ ìƒì„± (ì˜¤ë¥˜ ë°œìƒ ì‹œ)"""
        try:
            self.logger.warning("âš ï¸ í´ë°± íŒŒì‹± ë§µ ìƒì„±")
            return np.zeros(original_size, dtype=np.uint8)
        except Exception as e:
            self.logger.error(f"âŒ í´ë°± íŒŒì‹± ë§µ ìƒì„± ì‹¤íŒ¨: {e}")
            return np.zeros((512, 512), dtype=np.uint8)


def get_original_size_safely(original_image: Any) -> Tuple[int, int]:
    """
    ì›ë³¸ ì´ë¯¸ì§€ì—ì„œ ì•ˆì „í•˜ê²Œ í¬ê¸°ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
    
    Args:
        original_image: ì›ë³¸ ì´ë¯¸ì§€ (PIL Image, NumPy ë°°ì—´ ë“±)
        
    Returns:
        ì›ë³¸ í¬ê¸° (height, width)
    """
    try:
        # ê¸°ë³¸ê°’ ì„¤ì •
        original_size = (512, 512)
        
        if hasattr(original_image, 'size') and not isinstance(original_image, np.ndarray):
            # PIL Imageì¸ ê²½ìš°
            original_size = original_image.size[::-1]  # (width, height) -> (height, width)
            logger.debug(f"ğŸ” PIL Image í¬ê¸°: {original_size}")
            
        elif isinstance(original_image, np.ndarray):
            # NumPy ë°°ì—´ì¸ ê²½ìš°
            if len(original_image.shape) >= 2:
                original_size = original_image.shape[:2]
                logger.debug(f"ğŸ” NumPy ë°°ì—´ í¬ê¸°: {original_size}")
            else:
                logger.warning(f"âš ï¸ NumPy ë°°ì—´ í˜•íƒœê°€ ì˜ëª»ë¨: {original_image.shape}")
                
        elif original_image is None:
            logger.warning("âš ï¸ original_imageê°€ Noneì…ë‹ˆë‹¤. ê¸°ë³¸ í¬ê¸° ì‚¬ìš©")
            
        else:
            logger.warning(f"âš ï¸ ì•Œ ìˆ˜ ì—†ëŠ” ì´ë¯¸ì§€ íƒ€ì…: {type(original_image)}")
            
        logger.debug(f"ğŸ” ìµœì¢… ì›ë³¸ í¬ê¸°: {original_size}")
        return original_size
        
    except Exception as e:
        logger.warning(f"âš ï¸ ì›ë³¸ í¬ê¸° ê²°ì • ì‹¤íŒ¨: {e}. ê¸°ë³¸ í¬ê¸° ì‚¬ìš©")
        return (512, 512)


def validate_confidence_map(confidence_map: Any, original_size: Tuple[int, int]) -> np.ndarray:
    """
    ì‹ ë¢°ë„ ë§µì„ ê²€ì¦í•˜ê³  ì •ì œí•©ë‹ˆë‹¤.
    
    Args:
        confidence_map: ê²€ì¦í•  ì‹ ë¢°ë„ ë§µ
        original_size: ì›ë³¸ ì´ë¯¸ì§€ í¬ê¸°
        
    Returns:
        ì •ì œëœ ì‹ ë¢°ë„ ë§µ (np.ndarray)
    """
    try:
        confidence_array = None
        
        if confidence_map is not None:
            if hasattr(confidence_map, 'cpu') and hasattr(confidence_map, 'numpy'):
                # PyTorch í…ì„œ
                confidence_array = confidence_map.detach().cpu().numpy()
            elif isinstance(confidence_map, (int, float, np.float64)):
                confidence_array = np.array([float(confidence_map)])
            elif isinstance(confidence_map, dict):
                # ë”•ì…”ë„ˆë¦¬ì¸ ê²½ìš° ì²« ë²ˆì§¸ ê°’ ì‚¬ìš©
                first_value = next(iter(confidence_map.values()))
                if isinstance(first_value, (int, float, np.float64)):
                    confidence_array = np.array([float(first_value)])
                else:
                    confidence_array = np.array([0.5])
            else:
                try:
                    confidence_array = np.array(confidence_map, dtype=np.float32)
                except:
                    confidence_array = np.array([0.5])
        
        # ì‹ ë¢°ë„ ë§µì´ Noneì´ê±°ë‚˜ ì˜ëª»ëœ í˜•íƒœì¸ ê²½ìš°
        if confidence_array is None:
            confidence_array = np.ones(original_size, dtype=np.float32) * 0.8
        elif len(confidence_array.shape) != 2:
            # 1D ë°°ì—´ì¸ ê²½ìš° 2Dë¡œ í™•ì¥
            if len(confidence_array.shape) == 1:
                confidence_array = np.full(original_size, confidence_array[0], dtype=np.float32)
            else:
                confidence_array = np.ones(original_size, dtype=np.float32) * 0.8
        
        # í¬ê¸° ì¡°ì •
        if confidence_array.shape != original_size:
            try:
                confidence_pil = Image.fromarray((confidence_array * 255).astype(np.uint8))
                confidence_resized = confidence_pil.resize(
                    (original_size[1], original_size[0]), 
                    Image.BILINEAR
                )
                confidence_array = np.array(confidence_resized).astype(np.float32) / 255.0
            except Exception as e:
                logger.warning(f"âš ï¸ confidence_array ë¦¬ì‚¬ì´ì¦ˆ ì‹¤íŒ¨: {e}")
                confidence_array = np.ones(original_size, dtype=np.float32) * 0.8
        
        return confidence_array
        
    except Exception as e:
        logger.warning(f"âš ï¸ ì‹ ë¢°ë„ ë§µ ê²€ì¦ ì‹¤íŒ¨: {e}")
        return np.ones(original_size, dtype=np.float32) * 0.8


# ì „ì—­ ê²€ì¦ê¸° ì¸ìŠ¤í„´ìŠ¤
parsing_validator = ParsingMapValidator()
