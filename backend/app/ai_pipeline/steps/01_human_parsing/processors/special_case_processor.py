"""
ğŸ”¥ Special Case Processor
========================

íŠ¹ìˆ˜ ì¼€ì´ìŠ¤ ì´ë¯¸ì§€ ì²˜ë¦¬ ì‹œìŠ¤í…œ

Author: MyCloset AI Team
Date: 2025-08-07
Version: 1.0
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import logging
from typing import Dict, Any, List, Optional


class SpecialCaseProcessor(nn.Module):
    """íŠ¹ìˆ˜ ì¼€ì´ìŠ¤ ì´ë¯¸ì§€ ì²˜ë¦¬ ì‹œìŠ¤í…œ"""
    
    def __init__(self, config):
        super().__init__()
        self.config = config
        
        # ë¡œê±° ì„¤ì •
        self.logger = logging.getLogger(__name__)
        
        # íˆ¬ëª… ì˜ë¥˜ ê°ì§€ê¸°
        self.transparent_detector = self._build_transparent_detector()
        
        # ë ˆì´ì–´ë“œ ì˜ë¥˜ ê°ì§€ê¸°
        self.layered_detector = self._build_layered_detector()
        
        # ë³µì¡í•œ íŒ¨í„´ ê°ì§€ê¸°
        self.pattern_detector = self._build_pattern_detector()
        
        # ë°˜ì‚¬ ì¬ì§ˆ ê°ì§€ê¸°
        self.reflective_detector = self._build_reflective_detector()
        
        # ì˜¤ë²„ì‚¬ì´ì¦ˆ ì˜ë¥˜ ê°ì§€ê¸°
        self.oversized_detector = self._build_oversized_detector()
        
        # íƒ€ì´íŠ¸ ì˜ë¥˜ ê°ì§€ê¸°
        self.tight_detector = self._build_tight_detector()
        
        # ì²˜ë¦¬ í†µê³„
        self.processing_stats = {
            'special_case_calls': 0,
            'transparent_clothing_calls': 0,
            'layered_clothing_calls': 0,
            'complex_pattern_calls': 0,
            'reflective_material_calls': 0,
            'oversized_clothing_calls': 0,
            'tight_clothing_calls': 0
        }
    
    def _build_transparent_detector(self):
        """íˆ¬ëª… ì˜ë¥˜ ê°ì§€ê¸° êµ¬ì¶•"""
        return nn.Sequential(
            nn.Conv2d(3, 32, 3, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv2d(32, 32, 3, padding=1),
            nn.ReLU(inplace=True),
            nn.AdaptiveAvgPool2d((1, 1)),
            nn.Flatten(),
            nn.Linear(32, 1),
            nn.Sigmoid()
        )
    
    def _build_layered_detector(self):
        """ë ˆì´ì–´ë“œ ì˜ë¥˜ ê°ì§€ê¸° êµ¬ì¶•"""
        return nn.Sequential(
            nn.Conv2d(3, 32, 3, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv2d(32, 32, 3, padding=1),
            nn.ReLU(inplace=True),
            nn.AdaptiveAvgPool2d((1, 1)),
            nn.Flatten(),
            nn.Linear(32, 1),
            nn.Sigmoid()
        )
    
    def _build_pattern_detector(self):
        """ë³µì¡í•œ íŒ¨í„´ ê°ì§€ê¸° êµ¬ì¶•"""
        return nn.Sequential(
            nn.Conv2d(3, 32, 3, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv2d(32, 32, 3, padding=1),
            nn.ReLU(inplace=True),
            nn.AdaptiveAvgPool2d((1, 1)),
            nn.Flatten(),
            nn.Linear(32, 1),
            nn.Sigmoid()
        )
    
    def _build_reflective_detector(self):
        """ë°˜ì‚¬ ì¬ì§ˆ ê°ì§€ê¸° êµ¬ì¶•"""
        return nn.Sequential(
            nn.Conv2d(3, 32, 3, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv2d(32, 32, 3, padding=1),
            nn.ReLU(inplace=True),
            nn.AdaptiveAvgPool2d((1, 1)),
            nn.Flatten(),
            nn.Linear(32, 1),
            nn.Sigmoid()
        )
    
    def _build_oversized_detector(self):
        """ì˜¤ë²„ì‚¬ì´ì¦ˆ ì˜ë¥˜ ê°ì§€ê¸° êµ¬ì¶•"""
        return nn.Sequential(
            nn.Conv2d(3, 32, 3, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv2d(32, 32, 3, padding=1),
            nn.ReLU(inplace=True),
            nn.AdaptiveAvgPool2d((1, 1)),
            nn.Flatten(),
            nn.Linear(32, 1),
            nn.Sigmoid()
        )
    
    def _build_tight_detector(self):
        """íƒ€ì´íŠ¸ ì˜ë¥˜ ê°ì§€ê¸° êµ¬ì¶•"""
        return nn.Sequential(
            nn.Conv2d(3, 32, 3, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv2d(32, 32, 3, padding=1),
            nn.ReLU(inplace=True),
            nn.AdaptiveAvgPool2d((1, 1)),
            nn.Flatten(),
            nn.Linear(32, 1),
            nn.Sigmoid()
        )
    
    def detect_special_cases(self, image):
        """íŠ¹ìˆ˜ ì¼€ì´ìŠ¤ ê°ì§€"""
        self.processing_stats['special_case_calls'] += 1
        
        # ì´ë¯¸ì§€ íƒ€ì… ê²€ì¦ ë° ì•ˆì „í•œ ë³€í™˜
        try:
            # dict íƒ€ì…ì¸ ê²½ìš° ì²˜ë¦¬
            if isinstance(image, dict):
                self.logger.warning("ì´ë¯¸ì§€ê°€ dict íƒ€ì…ìœ¼ë¡œ ì „ë‹¬ë¨, ê¸°ë³¸ê°’ ë°˜í™˜")
                return {
                    'transparent_clothing': False,
                    'layered_clothing': False,
                    'complex_patterns': False,
                    'reflective_materials': False,
                    'oversized_clothing': False,
                    'tight_clothing': False
                }
            
            # NumPy ë°°ì—´ì¸ ê²½ìš°
            if isinstance(image, np.ndarray):
                if image.dtype == np.object_:
                    image_array = np.array(image, dtype=np.uint8)
                else:
                    image_array = image
                image_tensor = torch.from_numpy(image_array).permute(2, 0, 1).unsqueeze(0).float() / 255.0
            
            # PIL Imageì¸ ê²½ìš°
            elif hasattr(image, 'convert'):  # PIL Image í™•ì¸
                image_array = np.array(image, dtype=np.uint8)
                image_tensor = torch.from_numpy(image_array).permute(2, 0, 1).unsqueeze(0).float() / 255.0
            
            # ê¸°íƒ€ íƒ€ì…ì¸ ê²½ìš°
            else:
                self.logger.warning(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì´ë¯¸ì§€ íƒ€ì…: {type(image)}")
                return {
                    'transparent_clothing': False,
                    'layered_clothing': False,
                    'complex_patterns': False,
                    'reflective_materials': False,
                    'oversized_clothing': False,
                    'tight_clothing': False
                }
                
        except Exception as e:
            # ë³€í™˜ ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ê°’ ë°˜í™˜
            self.logger.warning(f"ì´ë¯¸ì§€ ë³€í™˜ ì‹¤íŒ¨: {e}")
            return {
                'transparent_clothing': False,
                'layered_clothing': False,
                'complex_patterns': False,
                'reflective_materials': False,
                'oversized_clothing': False,
                'tight_clothing': False
            }
        
        # ê° íŠ¹ìˆ˜ ì¼€ì´ìŠ¤ ê°ì§€
        special_cases = {
            'transparent_clothing': self.transparent_detector(image_tensor).item() > 0.5,
            'layered_clothing': self.layered_detector(image_tensor).item() > 0.5,
            'complex_patterns': self.pattern_detector(image_tensor).item() > 0.5,
            'reflective_materials': self.reflective_detector(image_tensor).item() > 0.5,
            'oversized_clothing': self.oversized_detector(image_tensor).item() > 0.5,
            'tight_clothing': self.tight_detector(image_tensor).item() > 0.5
        }
        
        return special_cases
    
    def apply_special_case_enhancement(self, parsing_map, image, special_cases):
        """íŠ¹ìˆ˜ ì¼€ì´ìŠ¤ í–¥ìƒ ì ìš©"""
        enhanced_parsing = parsing_map.copy()
        
        # íˆ¬ëª… ì˜ë¥˜ í–¥ìƒ
        if special_cases.get('transparent_clothing', False):
            enhanced_parsing = self._enhance_transparent_clothing(enhanced_parsing, image)
        
        # ë ˆì´ì–´ë“œ ì˜ë¥˜ í–¥ìƒ
        if special_cases.get('layered_clothing', False):
            enhanced_parsing = self._enhance_layered_clothing(enhanced_parsing, image)
        
        # ë³µì¡í•œ íŒ¨í„´ í–¥ìƒ
        if special_cases.get('complex_patterns', False):
            enhanced_parsing = self._enhance_complex_patterns(enhanced_parsing, image)
        
        # ë°˜ì‚¬ ì¬ì§ˆ í–¥ìƒ
        if special_cases.get('reflective_materials', False):
            enhanced_parsing = self._enhance_reflective_materials(enhanced_parsing, image)
        
        # ì˜¤ë²„ì‚¬ì´ì¦ˆ ì˜ë¥˜ í–¥ìƒ
        if special_cases.get('oversized_clothing', False):
            enhanced_parsing = self._enhance_oversized_clothing(enhanced_parsing, image)
        
        # íƒ€ì´íŠ¸ ì˜ë¥˜ í–¥ìƒ
        if special_cases.get('tight_clothing', False):
            enhanced_parsing = self._enhance_tight_clothing(enhanced_parsing, image)
        
        return enhanced_parsing
    
    def _enhance_transparent_clothing(self, parsing_map, image):
        """íˆ¬ëª… ì˜ë¥˜ í–¥ìƒ"""
        self.processing_stats['transparent_clothing_calls'] += 1
        # íˆ¬ëª… ì˜ë¥˜ íŠ¹í™” ì²˜ë¦¬ ë¡œì§
        return parsing_map
    
    def _enhance_layered_clothing(self, parsing_map, image):
        """ë ˆì´ì–´ë“œ ì˜ë¥˜ í–¥ìƒ"""
        self.processing_stats['layered_clothing_calls'] += 1
        # ë ˆì´ì–´ë“œ ì˜ë¥˜ íŠ¹í™” ì²˜ë¦¬ ë¡œì§
        return parsing_map
    
    def _enhance_complex_patterns(self, parsing_map, image):
        """ë³µì¡í•œ íŒ¨í„´ í–¥ìƒ"""
        self.processing_stats['complex_pattern_calls'] += 1
        # ë³µì¡í•œ íŒ¨í„´ íŠ¹í™” ì²˜ë¦¬ ë¡œì§
        return parsing_map
    
    def _enhance_reflective_materials(self, parsing_map, image):
        """ë°˜ì‚¬ ì¬ì§ˆ í–¥ìƒ"""
        self.processing_stats['reflective_material_calls'] += 1
        # ë°˜ì‚¬ ì¬ì§ˆ íŠ¹í™” ì²˜ë¦¬ ë¡œì§
        return parsing_map
    
    def _enhance_oversized_clothing(self, parsing_map, image):
        """ì˜¤ë²„ì‚¬ì´ì¦ˆ ì˜ë¥˜ í–¥ìƒ"""
        self.processing_stats['oversized_clothing_calls'] += 1
        # ì˜¤ë²„ì‚¬ì´ì¦ˆ ì˜ë¥˜ íŠ¹í™” ì²˜ë¦¬ ë¡œì§
        return parsing_map
    
    def _enhance_tight_clothing(self, parsing_map, image):
        """íƒ€ì´íŠ¸ ì˜ë¥˜ í–¥ìƒ"""
        self.processing_stats['tight_clothing_calls'] += 1
        # íƒ€ì´íŠ¸ ì˜ë¥˜ íŠ¹í™” ì²˜ë¦¬ ë¡œì§
        return parsing_map
