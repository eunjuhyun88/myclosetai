#!/usr/bin/env python3
"""
ğŸ”¥ MyCloset AI - Step 05: Enhanced Cloth Warping v15.0 (BaseStepMixin v19.1 ì™„ì „ í˜¸í™˜)
================================================================================

âœ… BaseStepMixin v19.1 ì™„ì „ ìƒì† ë° í˜¸í™˜:
   âœ… class ClothWarpingStep(BaseStepMixin) - ì§ì ‘ ìƒì†
   âœ… def _run_ai_inference(self, processed_input) - ë™ê¸° ë©”ì„œë“œ ì™„ì „ êµ¬í˜„
   âœ… ì˜ì¡´ì„± ì£¼ì… íŒ¨í„´ êµ¬í˜„ (ModelLoader, MemoryManager)
   âœ… StepFactory â†’ initialize() â†’ AI ì¶”ë¡  í”Œë¡œìš°
   âœ… TYPE_CHECKING ìˆœí™˜ì°¸ì¡° ì™„ì „ ë°©ì§€

âœ… ì‹¤ì œ AI ëª¨ë¸ íŒŒì¼ ì™„ì „ í™œìš©:
   âœ… RealVisXL_V4.0.safetensors (6.6GB) - í•µì‹¬ Diffusion ëª¨ë¸
   âœ… vgg19_warping.pth (548MB) - VGG19 íŠ¹ì§• ë§¤ì¹­
   âœ… vgg16_warping_ultra.pth (528MB) - VGG16 ê°•í™” ì›Œí•‘
   âœ… densenet121_ultra.pth (31MB) - í’ˆì§ˆ í‰ê°€
   âœ… diffusion_pytorch_model.bin (1.4GB) - Diffusion ì •ì œ

âœ… ê³ ê¸‰ AI ì•Œê³ ë¦¬ì¦˜ ì™„ì „ êµ¬í˜„:
   1. ğŸ§  TPS (Thin Plate Spline) Warping Network
   2. ğŸŒŠ RAFT Optical Flow Estimation  
   3. ğŸ¯ VGG ê¸°ë°˜ ì˜ë¥˜-ì¸ì²´ ë§¤ì¹­
   4. âš¡ DenseNet í’ˆì§ˆ í‰ê°€
   5. ğŸ¨ Diffusion ê¸°ë°˜ ì›Œí•‘ ì •ì œ
   6. ğŸ”— ë©€í‹° ìŠ¤ì¼€ì¼ íŠ¹ì§• ìœµí•©
   7. ğŸ§ª ë¬¼ë¦¬ ê¸°ë°˜ ì›ë‹¨ ì‹œë®¬ë ˆì´ì…˜

âœ… ì˜· ê°ˆì•„ì…íˆê¸° íŠ¹í™”:
   âœ… ì˜ë¥˜ ë³€í˜• ì •ë°€ë„ ê·¹ëŒ€í™”
   âœ… ì¸ì²´ í• ì ì‘ ì•Œê³ ë¦¬ì¦˜
   âœ… ì›ë‹¨ ë¬¼ë¦¬ ì‹œë®¬ë ˆì´ì…˜ (Cotton, Silk, Denim, Wool, Spandex)
   âœ… ë©€í‹° ì•Œê³ ë¦¬ì¦˜ ìœµí•©ìœ¼ë¡œ ìµœì  ê²°ê³¼ ì„ íƒ
   âœ… í’ˆì§ˆ í‰ê°€ ë° Diffusion ê¸°ë°˜ ì •ì œ

Author: MyCloset AI Team
Date: 2025-07-30
Version: v15.0 (BaseStepMixin v19.1 Full Compatible)
"""

import os
import sys
import gc
import time
import math
import logging
import threading
import traceback
import hashlib
import json
import base64
import weakref
import numpy as np
from pathlib import Path
from typing import Dict, Any, Optional, Tuple, List, Union, Callable, TYPE_CHECKING
from dataclasses import dataclass, field
from enum import Enum, IntEnum
from io import BytesIO
from concurrent.futures import ThreadPoolExecutor, as_completed
from functools import lru_cache, wraps
from contextlib import asynccontextmanager

# TYPE_CHECKINGìœ¼ë¡œ ìˆœí™˜ì°¸ì¡° ë°©ì§€ (1ë²ˆ íŒŒì¼ íŒ¨í„´)
if TYPE_CHECKING:
    from app.ai_pipeline.utils.model_loader import ModelLoader
    from app.ai_pipeline.utils.memory_manager import MemoryManager
    from app.ai_pipeline.utils.data_converter import DataConverter
    from app.ai_pipeline.core.di_container import DIContainer

# ==============================================
# ğŸ”¥ conda í™˜ê²½ ë° ì‹œìŠ¤í…œ ìµœì í™” (1ë²ˆ íŒŒì¼ íŒ¨í„´)
# ==============================================

# conda í™˜ê²½ ì •ë³´
CONDA_INFO = {
    'conda_env': os.environ.get('CONDA_DEFAULT_ENV', 'none'),
    'conda_prefix': os.environ.get('CONDA_PREFIX', 'none'),
    'is_mycloset_env': os.environ.get('CONDA_DEFAULT_ENV') == 'mycloset-ai-clean'
}

# M3 Max ê°ì§€ ë° ìµœì í™”
def detect_m3_max() -> bool:
    try:
        import platform, subprocess
        if platform.system() == 'Darwin':
            result = subprocess.run(
                ['sysctl', '-n', 'machdep.cpu.brand_string'], 
                capture_output=True, text=True, timeout=5
            )
            return 'M3' in result.stdout
    except:
        pass
    return False

IS_M3_MAX = detect_m3_max()

# M3 Max ìµœì í™” ì„¤ì •
if IS_M3_MAX and CONDA_INFO['is_mycloset_env']:
    os.environ['PYTORCH_MPS_HIGH_WATERMARK_RATIO'] = '0.0'
    os.environ['TORCH_MPS_PREFER_METAL'] = '1'

# ==============================================
# ğŸ”¥ í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì•ˆì „ import (1ë²ˆ íŒŒì¼ íŒ¨í„´)
# ==============================================

# NumPy í•„ìˆ˜
try:
    import numpy as np
    NUMPY_AVAILABLE = True
except ImportError:
    raise ImportError("âŒ NumPy í•„ìˆ˜: conda install numpy -c conda-forge")

# PyTorch í•„ìˆ˜ (MPS ì§€ì›)
try:
    import torch
    import torch.nn as nn
    import torch.nn.functional as F
    TORCH_AVAILABLE = True
    MPS_AVAILABLE = hasattr(torch.backends, 'mps') and torch.backends.mps.is_available()
    
    # M3 Max ìµœì í™”
    if CONDA_INFO['is_mycloset_env'] and IS_M3_MAX:
        cpu_count = os.cpu_count()
        torch.set_num_threads(max(1, cpu_count // 2))
        
except ImportError:
    raise ImportError("âŒ PyTorch í•„ìˆ˜: conda install pytorch torchvision -c pytorch")

# PIL í•„ìˆ˜
try:
    from PIL import Image, ImageDraw, ImageFont, ImageEnhance, ImageFilter
    PIL_AVAILABLE = True
except ImportError:
    raise ImportError("âŒ Pillow í•„ìˆ˜: conda install pillow -c conda-forge")

# OpenCV ì„ íƒì‚¬í•­
try:
    import cv2
    CV2_AVAILABLE = True
except ImportError:
    CV2_AVAILABLE = False
    logging.getLogger(__name__).info("OpenCV ì—†ìŒ - PIL ê¸°ë°˜ìœ¼ë¡œ ë™ì‘")

# SafeTensors ì„ íƒì‚¬í•­
try:
    from safetensors import safe_open
    from safetensors.torch import load_file as load_safetensors
    SAFETENSORS_AVAILABLE = True
except ImportError:
    SAFETENSORS_AVAILABLE = False

# BaseStepMixin ë™ì  import (1ë²ˆ íŒŒì¼ íŒ¨í„´)
def get_base_step_mixin_class():
    """BaseStepMixin í´ë˜ìŠ¤ë¥¼ ë™ì ìœ¼ë¡œ ê°€ì ¸ì˜¤ê¸° (ìˆœí™˜ì°¸ì¡° ë°©ì§€)"""
    try:
        import importlib
        module = importlib.import_module('app.ai_pipeline.steps.base_step_mixin')
        return getattr(module, 'BaseStepMixin', None)
    except ImportError:
        try:
            # í´ë°±: ìƒëŒ€ ê²½ë¡œ
            from .base_step_mixin import BaseStepMixin
            return BaseStepMixin
        except ImportError:
            logger.error("âŒ BaseStepMixin ë™ì  import ì‹¤íŒ¨")
            return None
        
BaseStepMixin = get_base_step_mixin_class()

# ==============================================
# ğŸ”¥ ì„¤ì • ë° ìƒìˆ˜ ì •ì˜ (ê°•í™”ëœ ì˜ë¥˜ ì›Œí•‘)
# ==============================================

class WarpingMethod(Enum):
    """ì›Œí•‘ ë°©ë²• ì—´ê±°í˜•"""
    TPS_ADVANCED = "tps_advanced"
    RAFT_FLOW = "raft_flow"
    REALVIS_XL = "realvis_xl"
    VGG_MATCHING = "vgg_matching"
    DENSENET_QUALITY = "densenet_quality"
    DIFFUSION_REFINE = "diffusion_refine"
    HYBRID_MULTI = "hybrid_multi"

class FabricType(Enum):
    """ì›ë‹¨ íƒ€ì… ì—´ê±°í˜•"""
    COTTON = "cotton"
    SILK = "silk"
    DENIM = "denim"
    WOOL = "wool"
    POLYESTER = "polyester"
    LINEN = "linen"
    LEATHER = "leather"
    SPANDEX = "spandex"

# ì‹¤ì œ AI ëª¨ë¸ ë§¤í•‘ (í”„ë¡œì íŠ¸ì—ì„œ í™•ì¸ëœ íŒŒì¼ë“¤)
ENHANCED_CLOTH_WARPING_MODELS = {
    'realvis_xl': {
        'filename': 'RealVisXL_V4.0.safetensors',
        'size_mb': 6616.6,
        'format': 'safetensors',
        'class': 'EnhancedRealVisXLWarpingModel',
        'priority': 1,
        'path': 'step_05_cloth_warping/RealVisXL_V4.0.safetensors'
    },
    'vgg19_warping': {
        'filename': 'vgg19_warping.pth',
        'size_mb': 548.1,
        'format': 'pth',
        'class': 'VGG19WarpingModel',
        'priority': 2,
        'path': 'step_05_cloth_warping/ultra_models/vgg19_warping.pth'
    },
    'vgg16_warping': {
        'filename': 'vgg16_warping_ultra.pth',
        'size_mb': 527.8,
        'format': 'pth',
        'class': 'VGG16WarpingModel',
        'priority': 3,
        'path': 'step_05_cloth_warping/ultra_models/vgg16_warping_ultra.pth'
    },
    'densenet121': {
        'filename': 'densenet121_ultra.pth',
        'size_mb': 31.0,
        'format': 'pth',
        'class': 'DenseNetQualityModel',
        'priority': 4,
        'path': 'step_05_cloth_warping/ultra_models/densenet121_ultra.pth'
    },
    'diffusion_warping': {
        'filename': 'diffusion_pytorch_model.bin',
        'size_mb': 1378.2,
        'format': 'bin',
        'class': 'DiffusionWarpingModel',
        'priority': 5,
        'path': 'step_05_cloth_warping/ultra_models/unet/diffusion_pytorch_model.bin'
    },
    'safety_checker': {
        'filename': 'model.fp16.safetensors',
        'size_mb': 580.0,
        'format': 'safetensors',
        'class': 'SafetyChecker',
        'priority': 6,
        'path': 'step_05_cloth_warping/ultra_models/safety_checker/model.fp16.safetensors'
    }
}

@dataclass
class ClothingChangeComplexity:
    """ì˜· ê°ˆì•„ì…íˆê¸° ë³µì¡ë„ í‰ê°€"""
    complexity_level: str = "medium"
    change_feasibility: float = 0.0
    required_steps: List[str] = field(default_factory=list)
    estimated_time: float = 0.0

# ==============================================
# ğŸ§  1. ê³ ê¸‰ TPS (Thin Plate Spline) ì›Œí•‘ ë„¤íŠ¸ì›Œí¬
# ==============================================

class AdvancedTPSWarpingNetwork(nn.Module):
    """ê³ ê¸‰ TPS ì›Œí•‘ ë„¤íŠ¸ì›Œí¬ - ì •ë°€í•œ ì˜ë¥˜ ë³€í˜• (1ë²ˆ íŒŒì¼ í’ˆì§ˆ)"""
    
    def __init__(self, num_control_points: int = 25, input_channels: int = 6):
        super().__init__()
        self.num_control_points = num_control_points
        
        # ResNet ê¸°ë°˜ íŠ¹ì§• ì¶”ì¶œê¸° (1ë²ˆ íŒŒì¼ ìŠ¤íƒ€ì¼)
        self.feature_extractor = self._build_resnet_backbone()
        
        # TPS ì œì–´ì  ì˜ˆì¸¡ê¸°
        self.control_point_predictor = nn.Sequential(
            nn.AdaptiveAvgPool2d(1),
            nn.Flatten(),
            nn.Linear(2048, 1024),
            nn.ReLU(inplace=True),
            nn.Dropout(0.3),
            nn.Linear(1024, 512),
            nn.ReLU(inplace=True),
            nn.Dropout(0.2),
            nn.Linear(512, num_control_points * 2),  # x, y ì¢Œí‘œ
            nn.Tanh()
        )
        
        # TPS ë§¤ê°œë³€ìˆ˜ ì •ì œê¸°
        self.tps_refiner = nn.Sequential(
            nn.Conv2d(input_channels, 64, 3, 1, 1),
            nn.ReLU(inplace=True),
            nn.Conv2d(64, 32, 3, 1, 1),
            nn.ReLU(inplace=True),
            nn.Conv2d(32, 16, 3, 1, 1),
            nn.ReLU(inplace=True),
            nn.Conv2d(16, 2, 3, 1, 1),  # ì •ì œëœ ë³€ìœ„
            nn.Tanh()
        )
        
        # í’ˆì§ˆ í‰ê°€ê¸°
        self.quality_assessor = nn.Sequential(
            nn.AdaptiveAvgPool2d(1),
            nn.Flatten(),
            nn.Linear(2048, 256),
            nn.ReLU(inplace=True),
            nn.Linear(256, 64),
            nn.ReLU(inplace=True),
            nn.Linear(64, 1),
            nn.Sigmoid()
        )
    
    def _build_resnet_backbone(self):
        """ResNet ë°±ë³¸ êµ¬ì¶•"""
        return nn.Sequential(
            # ì´ˆê¸° ë ˆì´ì–´
            nn.Conv2d(6, 64, 7, 2, 3, bias=False),
            nn.BatchNorm2d(64),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(3, 2, 1),
            
            # ResNet ë¸”ë¡ë“¤
            self._make_layer(64, 64, 3),     # 256 channels
            self._make_layer(256, 128, 4, stride=2),  # 512 channels
            self._make_layer(512, 256, 6, stride=2),  # 1024 channels
            self._make_layer(1024, 512, 3, stride=2), # 2048 channels
        )
    
    def _make_layer(self, inplanes, planes, blocks, stride=1):
        """ResNet ë ˆì´ì–´ ìƒì„±"""
        layers = []
        
        # Downsample
        downsample = None
        if stride != 1 or inplanes != planes * 4:
            downsample = nn.Sequential(
                nn.Conv2d(inplanes, planes * 4, 1, stride, bias=False),
                nn.BatchNorm2d(planes * 4)
            )
        
        # ì²« ë²ˆì§¸ ë¸”ë¡
        layers.append(self._bottleneck(inplanes, planes, stride, downsample))
        
        # ë‚˜ë¨¸ì§€ ë¸”ë¡ë“¤
        for _ in range(1, blocks):
            layers.append(self._bottleneck(planes * 4, planes))
        
        return nn.Sequential(*layers)
    
    def _bottleneck(self, inplanes, planes, stride=1, downsample=None):
        """ResNet Bottleneck ë¸”ë¡"""
        return nn.Sequential(
            nn.Conv2d(inplanes, planes, 1, bias=False),
            nn.BatchNorm2d(planes),
            nn.ReLU(inplace=True),
            
            nn.Conv2d(planes, planes, 3, stride, 1, bias=False),
            nn.BatchNorm2d(planes),
            nn.ReLU(inplace=True),
            
            nn.Conv2d(planes, planes * 4, 1, bias=False),
            nn.BatchNorm2d(planes * 4),
            
            # Skip connection
            downsample if downsample else nn.Identity(),
            nn.ReLU(inplace=True)
        )
    
    def forward(self, cloth_image: torch.Tensor, person_image: torch.Tensor) -> Dict[str, torch.Tensor]:
        """ìˆœì „íŒŒ - ê³ ê¸‰ TPS ì›Œí•‘ (1ë²ˆ íŒŒì¼ í’ˆì§ˆ)"""
        batch_size = cloth_image.size(0)
        
        # ì…ë ¥ ê²°í•©
        combined_input = torch.cat([cloth_image, person_image], dim=1)
        
        # íŠ¹ì§• ì¶”ì¶œ
        features = self.feature_extractor(combined_input)
        
        # TPS ì œì–´ì  ì˜ˆì¸¡
        control_points = self.control_point_predictor(features)
        control_points = control_points.view(batch_size, self.num_control_points, 2)
        
        # TPS ë³€í˜• ì ìš©
        tps_grid = self._solve_tps(control_points, cloth_image.shape[-2:])
        
        # ì •ì œëœ ë³€ìœ„ ê³„ì‚°
        refined_displacement = self.tps_refiner(combined_input)
        
        # ìµœì¢… ë³€í˜• ê·¸ë¦¬ë“œ
        final_grid = tps_grid + refined_displacement.permute(0, 2, 3, 1) * 0.1
        final_grid = torch.clamp(final_grid, -1, 1)
        
        # ì›Œí•‘ ì ìš©
        warped_cloth = F.grid_sample(
            cloth_image, final_grid, 
            mode='bilinear', padding_mode='border', align_corners=False
        )
        
        # í’ˆì§ˆ í‰ê°€
        quality_score = self.quality_assessor(features)
        
        return {
            'warped_cloth': warped_cloth,
            'control_points': control_points,
            'tps_grid': tps_grid,
            'refined_displacement': refined_displacement,
            'quality_score': quality_score,
            'confidence': torch.mean(quality_score)
        }
    
    def _solve_tps(self, control_points: torch.Tensor, image_size: Tuple[int, int]) -> torch.Tensor:
        """TPS ì†”ë²„ - ì œì–´ì ì—ì„œ ë³€í˜• ê·¸ë¦¬ë“œ ê³„ì‚° (1ë²ˆ íŒŒì¼ í’ˆì§ˆ)"""
        batch_size, num_points, _ = control_points.shape
        h, w = image_size
        
        # ì •ê·œí™”ëœ ê·¸ë¦¬ë“œ ìƒì„±
        y_coords = torch.linspace(-1, 1, h, device=control_points.device)
        x_coords = torch.linspace(-1, 1, w, device=control_points.device)
        grid_y, grid_x = torch.meshgrid(y_coords, x_coords, indexing='ij')
        grid = torch.stack([grid_x, grid_y], dim=-1).unsqueeze(0).repeat(batch_size, 1, 1, 1)
        
        # ì œì–´ì  ê°„ ê±°ë¦¬ í–‰ë ¬ ê³„ì‚°
        source_points = self._generate_regular_grid(num_points, control_points.device)
        target_points = control_points
        
        # ê°„ë‹¨í•œ RBF ë³´ê°„ìœ¼ë¡œ TPS ê·¼ì‚¬
        for b in range(batch_size):
            for i in range(num_points):
                src_pt = source_points[i]
                tgt_pt = target_points[b, i]
                
                # ì œì–´ì  ì£¼ë³€ ì˜ì—­ì— ë³€í˜• ì ìš©
                distances = torch.sqrt(
                    (grid[b, :, :, 0] - src_pt[0])**2 + 
                    (grid[b, :, :, 1] - src_pt[1])**2
                )
                
                # RBF ê°€ì¤‘ì¹˜
                weights = torch.exp(-distances * 5.0)
                displacement = (tgt_pt - src_pt) * weights.unsqueeze(-1)
                
                grid[b] += displacement
        
        return torch.clamp(grid, -1, 1)
    
    def _generate_regular_grid(self, num_points: int, device) -> torch.Tensor:
        """ê·œì¹™ì ì¸ ì œì–´ì  ê·¸ë¦¬ë“œ ìƒì„±"""
        grid_size = int(np.sqrt(num_points))
        points = []
        
        for i in range(grid_size):
            for j in range(grid_size):
                if len(points) >= num_points:
                    break
                x = -1 + 2 * j / max(1, grid_size - 1)
                y = -1 + 2 * i / max(1, grid_size - 1)
                points.append([x, y])
        
        # ë¶€ì¡±í•œ ì ë“¤ì€ ì¤‘ì•™ ê·¼ì²˜ì— ì¶”ê°€
        while len(points) < num_points:
            points.append([0.0, 0.0])
        
        return torch.tensor(points[:num_points], device=device, dtype=torch.float32)

# ==============================================
# ğŸ§  2. RAFT Optical Flow ê¸°ë°˜ ì •ë°€ ì›Œí•‘
# ==============================================

class RAFTFlowWarpingNetwork(nn.Module):
    """RAFT Optical Flow ê¸°ë°˜ ì •ë°€ ì›Œí•‘ ë„¤íŠ¸ì›Œí¬ (1ë²ˆ íŒŒì¼ í’ˆì§ˆ)"""
    
    def __init__(self, small_model: bool = False):
        super().__init__()
        self.small_model = small_model
        
        # Feature encoder
        self.feature_encoder = self._build_feature_encoder()
        
        # Context encoder
        self.context_encoder = self._build_context_encoder()
        
        # Update block
        self.update_block = self._build_update_block()
        
        # Flow head
        self.flow_head = nn.Sequential(
            nn.Conv2d(128, 64, 3, 1, 1),
            nn.ReLU(inplace=True),
            nn.Conv2d(64, 32, 3, 1, 1),
            nn.ReLU(inplace=True),
            nn.Conv2d(32, 2, 3, 1, 1)
        )
    
    def _build_feature_encoder(self):
        """íŠ¹ì§• ì¸ì½”ë” êµ¬ì¶•"""
        if self.small_model:
            dims = [32, 32, 64, 96]
        else:
            dims = [64, 64, 96, 128]
        
        layers = []
        in_dim = 3
        
        for dim in dims:
            layers.extend([
                nn.Conv2d(in_dim, dim, 7, 2, 3),
                nn.ReLU(inplace=True),
                nn.Conv2d(dim, dim, 3, 1, 1),
                nn.ReLU(inplace=True)
            ])
            in_dim = dim
        
        return nn.Sequential(*layers)
    
    def _build_context_encoder(self):
        """ì»¨í…ìŠ¤íŠ¸ ì¸ì½”ë” êµ¬ì¶•"""
        return nn.Sequential(
            nn.Conv2d(3, 64, 7, 2, 3),
            nn.ReLU(inplace=True),
            nn.Conv2d(64, 64, 3, 1, 1),
            nn.ReLU(inplace=True),
            nn.Conv2d(64, 128, 3, 2, 1),
            nn.ReLU(inplace=True),
            nn.Conv2d(128, 128, 3, 1, 1),
            nn.ReLU(inplace=True)
        )
    
    def _build_update_block(self):
        """ì—…ë°ì´íŠ¸ ë¸”ë¡ êµ¬ì¶•"""
        return nn.Sequential(
            nn.Conv2d(256, 128, 3, 1, 1),
            nn.ReLU(inplace=True),
            nn.Conv2d(128, 128, 3, 1, 1),
            nn.ReLU(inplace=True)
        )
    
    def forward(self, cloth_image: torch.Tensor, person_image: torch.Tensor, 
                num_iterations: int = 12) -> Dict[str, torch.Tensor]:
        """RAFT ê¸°ë°˜ Flow ì¶”ì • ë° ì›Œí•‘"""
        
        # íŠ¹ì§• ì¶”ì¶œ
        cloth_features = self.feature_encoder(cloth_image)
        person_features = self.feature_encoder(person_image)
        
        # ì»¨í…ìŠ¤íŠ¸ ì¶”ì¶œ
        context = self.context_encoder(person_image)
        
        # ì´ˆê¸° flow ì¶”ì •
        corr_pyramid = self._build_correlation_pyramid(cloth_features, person_features)
        flow = torch.zeros(cloth_image.size(0), 2, cloth_image.size(2)//8, 
                          cloth_image.size(3)//8, device=cloth_image.device)
        
        flow_predictions = []
        
        # ë°˜ë³µì  ì •ì œ
        for _ in range(num_iterations):
            # ìƒê´€ê´€ê³„ ì¡°íšŒ
            corr = self._lookup_correlation(corr_pyramid, flow)
            
            # ì—…ë°ì´íŠ¸
            inp = torch.cat([corr, context], dim=1)
            delta_flow = self.update_block(inp)
            delta_flow = self.flow_head(delta_flow)
            
            flow = flow + delta_flow
            flow_predictions.append(flow)
        
        # Flowë¥¼ ì›ë³¸ í•´ìƒë„ë¡œ ì—…ìƒ˜í”Œ
        final_flow = F.interpolate(flow, size=cloth_image.shape[-2:], 
                                  mode='bilinear', align_corners=False) * 8.0
        
        # Flowë¥¼ ê·¸ë¦¬ë“œë¡œ ë³€í™˜
        grid = self._flow_to_grid(final_flow)
        
        # ì›Œí•‘ ì ìš©
        warped_cloth = F.grid_sample(
            cloth_image, grid, 
            mode='bilinear', padding_mode='border', align_corners=False
        )
        
        return {
            'warped_cloth': warped_cloth,
            'flow_field': final_flow,
            'grid': grid,
            'flow_predictions': flow_predictions,
            'confidence': self._estimate_flow_confidence(final_flow)
        }
    
    def _build_correlation_pyramid(self, fmap1: torch.Tensor, fmap2: torch.Tensor):
        """ìƒê´€ê´€ê³„ í”¼ë¼ë¯¸ë“œ êµ¬ì¶•"""
        batch, dim, h, w = fmap1.shape
        
        # íŠ¹ì§•ë§µ ì •ê·œí™”
        fmap1 = F.normalize(fmap1, dim=1)
        fmap2 = F.normalize(fmap2, dim=1)
        
        # ì „ì²´ ìƒê´€ê´€ê³„ ê³„ì‚°
        corr = torch.einsum('aijk,aijl->aijkl', fmap1, fmap2.view(batch, dim, h*w))
        corr = corr.view(batch, h, w, h, w)
        
        # í”¼ë¼ë¯¸ë“œ ë ˆë²¨ ìƒì„±
        pyramid = [corr]
        for i in range(3):
            corr = F.avg_pool2d(corr.view(batch*h*w, 1, h, w), 2, 2)
            corr = corr.view(batch, h, w, h//2, w//2)
            pyramid.append(corr)
            h, w = h//2, w//2
        
        return pyramid
    
    def _lookup_correlation(self, pyramid, flow):
        """ìƒê´€ê´€ê³„ ì¡°íšŒ"""
        # ê°„ë‹¨í•œ êµ¬í˜„ - ì‹¤ì œë¡œëŠ” ë” ë³µì¡í•œ ìƒ˜í”Œë§ í•„ìš”
        return pyramid[0][:, :, :, 0, 0].unsqueeze(1)
    
    def _flow_to_grid(self, flow: torch.Tensor) -> torch.Tensor:
        """Flowë¥¼ ìƒ˜í”Œë§ ê·¸ë¦¬ë“œë¡œ ë³€í™˜"""
        batch, _, h, w = flow.shape
        
        # ê¸°ë³¸ ê·¸ë¦¬ë“œ ìƒì„±
        y_coords = torch.linspace(-1, 1, h, device=flow.device)
        x_coords = torch.linspace(-1, 1, w, device=flow.device)
        grid_y, grid_x = torch.meshgrid(y_coords, x_coords, indexing='ij')
        grid = torch.stack([grid_x, grid_y], dim=-1).unsqueeze(0).repeat(batch, 1, 1, 1)
        
        # Flow ì¶”ê°€ (ì •ê·œí™”)
        flow_normalized = flow.permute(0, 2, 3, 1)
        flow_normalized[:, :, :, 0] = flow_normalized[:, :, :, 0] / (w - 1) * 2
        flow_normalized[:, :, :, 1] = flow_normalized[:, :, :, 1] / (h - 1) * 2
        
        return grid + flow_normalized
    
    def _estimate_flow_confidence(self, flow: torch.Tensor) -> torch.Tensor:
        """Flow ì‹ ë¢°ë„ ì¶”ì •"""
        # ê°„ë‹¨í•œ ì‹ ë¢°ë„ ê³„ì‚° - flow ì¼ê´€ì„± ê¸°ë°˜
        flow_magnitude = torch.sqrt(flow[:, 0]**2 + flow[:, 1]**2)
        confidence = torch.exp(-flow_magnitude.mean(dim=[1, 2]) / 10.0)
        return confidence

# ==============================================
# ğŸ§  3. VGG ê¸°ë°˜ ì˜ë¥˜-ì¸ì²´ ë§¤ì¹­ ë„¤íŠ¸ì›Œí¬
# ==============================================

class VGGClothBodyMatchingNetwork(nn.Module):
    """VGG ê¸°ë°˜ ì˜ë¥˜-ì¸ì²´ ë§¤ì¹­ ë„¤íŠ¸ì›Œí¬ (1ë²ˆ íŒŒì¼ í’ˆì§ˆ)"""
    
    def __init__(self, vgg_type: str = "vgg19"):
        super().__init__()
        self.vgg_type = vgg_type
        
        # VGG ë°±ë³¸
        self.vgg_features = self._build_vgg_backbone()
        
        # ì˜ë¥˜ ë¸Œëœì¹˜
        self.cloth_branch = nn.Sequential(
            nn.Conv2d(512, 256, 3, 1, 1),
            nn.ReLU(inplace=True),
            nn.Conv2d(256, 128, 3, 1, 1),
            nn.ReLU(inplace=True)
        )
        
        # ì¸ì²´ ë¸Œëœì¹˜
        self.body_branch = nn.Sequential(
            nn.Conv2d(512, 256, 3, 1, 1),
            nn.ReLU(inplace=True),
            nn.Conv2d(256, 128, 3, 1, 1),
            nn.ReLU(inplace=True)
        )
        
        # ë§¤ì¹­ í—¤ë“œ
        self.matching_head = nn.Sequential(
            nn.Conv2d(256, 128, 3, 1, 1),
            nn.ReLU(inplace=True),
            nn.Conv2d(128, 64, 3, 1, 1),
            nn.ReLU(inplace=True),
            nn.Conv2d(64, 32, 3, 1, 1),
            nn.ReLU(inplace=True),
            nn.Conv2d(32, 1, 1),
            nn.Sigmoid()
        )
        
        # í‚¤í¬ì¸íŠ¸ ê²€ì¶œê¸°
        self.keypoint_detector = nn.Sequential(
            nn.Conv2d(256, 128, 3, 1, 1),
            nn.ReLU(inplace=True),
            nn.Conv2d(128, 64, 3, 1, 1),
            nn.ReLU(inplace=True),
            nn.Conv2d(64, 25, 1),  # 25ê°œ í‚¤í¬ì¸íŠ¸
            nn.Sigmoid()
        )
    
    def _build_vgg_backbone(self):
        """VGG ë°±ë³¸ êµ¬ì¶•"""
        if self.vgg_type == "vgg19":
            cfg = [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 
                   512, 512, 512, 512, 'M', 512, 512, 512, 512]
        else:  # vgg16
            cfg = [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 
                   512, 512, 512, 'M', 512, 512, 512]
        
        layers = []
        in_channels = 3
        
        for v in cfg:
            if v == 'M':
                layers.append(nn.MaxPool2d(2, 2))
            else:
                layers.extend([
                    nn.Conv2d(in_channels, v, 3, 1, 1),
                    nn.ReLU(inplace=True)
                ])
                in_channels = v
        
        return nn.Sequential(*layers)
    
    def forward(self, cloth_image: torch.Tensor, person_image: torch.Tensor) -> Dict[str, torch.Tensor]:
        """VGG ê¸°ë°˜ ì˜ë¥˜-ì¸ì²´ ë§¤ì¹­"""
        
        # VGG íŠ¹ì§• ì¶”ì¶œ
        cloth_features = self.vgg_features(cloth_image)
        person_features = self.vgg_features(person_image)
        
        # ë¸Œëœì¹˜ë³„ íŠ¹ì§• ì²˜ë¦¬
        cloth_processed = self.cloth_branch(cloth_features)
        person_processed = self.body_branch(person_features)
        
        # íŠ¹ì§• ê²°í•©
        combined_features = torch.cat([cloth_processed, person_processed], dim=1)
        
        # ë§¤ì¹­ ë§µ ìƒì„±
        matching_map = self.matching_head(combined_features)
        
        # í‚¤í¬ì¸íŠ¸ ê²€ì¶œ
        keypoints = self.keypoint_detector(combined_features)
        
        # ë§¤ì¹­ ê¸°ë°˜ ì›Œí•‘ ê·¸ë¦¬ë“œ ìƒì„±
        warping_grid = self._generate_warping_grid(matching_map, keypoints)
        
        # ì›Œí•‘ ì ìš©
        warped_cloth = F.grid_sample(
            cloth_image, warping_grid,
            mode='bilinear', padding_mode='border', align_corners=False
        )
        
        return {
            'warped_cloth': warped_cloth,
            'matching_map': matching_map,
            'keypoints': keypoints,
            'warping_grid': warping_grid,
            'cloth_features': cloth_processed,
            'person_features': person_processed,
            'confidence': torch.mean(matching_map)
        }
    
    def _generate_warping_grid(self, matching_map: torch.Tensor, 
                              keypoints: torch.Tensor) -> torch.Tensor:
        """ë§¤ì¹­ ë§µê³¼ í‚¤í¬ì¸íŠ¸ ê¸°ë°˜ ì›Œí•‘ ê·¸ë¦¬ë“œ ìƒì„±"""
        batch_size, _, h, w = matching_map.shape
        
        # ê¸°ë³¸ ê·¸ë¦¬ë“œ
        y_coords = torch.linspace(-1, 1, h, device=matching_map.device)
        x_coords = torch.linspace(-1, 1, w, device=matching_map.device)
        grid_y, grid_x = torch.meshgrid(y_coords, x_coords, indexing='ij')
        grid = torch.stack([grid_x, grid_y], dim=-1).unsqueeze(0).repeat(batch_size, 1, 1, 1)
        
        # ë§¤ì¹­ ë§µ ê¸°ë°˜ ë³€í˜•
        matching_displacement = torch.stack([
            torch.gradient(matching_map.squeeze(1), dim=2)[0] * 0.1,
            torch.gradient(matching_map.squeeze(1), dim=1)[0] * 0.1
        ], dim=-1)
        
        # í‚¤í¬ì¸íŠ¸ ê¸°ë°˜ ë¡œì»¬ ë³€í˜•
        for b in range(batch_size):
            for k in range(min(5, keypoints.size(1))):  # ìƒìœ„ 5ê°œ í‚¤í¬ì¸íŠ¸ë§Œ ì‚¬ìš©
                kp_map = keypoints[b, k]
                
                # í‚¤í¬ì¸íŠ¸ ìµœëŒ€ê°’ ìœ„ì¹˜
                max_pos = torch.unravel_index(torch.argmax(kp_map), kp_map.shape)
                center_y, center_x = max_pos[0].item(), max_pos[1].item()
                
                # ë¡œì»¬ ë³€í˜• ì ìš©
                y_dist = (torch.arange(h, device=matching_map.device) - center_y).float()
                x_dist = (torch.arange(w, device=matching_map.device) - center_x).float()
                
                y_grid_dist, x_grid_dist = torch.meshgrid(y_dist, x_dist, indexing='ij')
                distances = torch.sqrt(y_grid_dist**2 + x_grid_dist**2)
                
                # RBF ê°€ì¤‘ì¹˜
                weights = torch.exp(-distances / 20.0) * kp_map[center_y, center_x]
                
                # ë³€í˜• ì ìš©
                grid[b, :, :, 0] += weights * 0.05
                grid[b, :, :, 1] += weights * 0.05
        
        return torch.clamp(grid, -1, 1)

# ==============================================
# ğŸ§  4. DenseNet ê¸°ë°˜ í’ˆì§ˆ í‰ê°€ ë„¤íŠ¸ì›Œí¬
# ==============================================

class DenseNetQualityAssessment(nn.Module):
    """DenseNet ê¸°ë°˜ ì›Œí•‘ í’ˆì§ˆ í‰ê°€ (1ë²ˆ íŒŒì¼ í’ˆì§ˆ)"""
    
    def __init__(self, growth_rate: int = 32, num_layers: int = 121):
        super().__init__()
        
        # DenseNet ë¸”ë¡ ì„¤ì •
        if num_layers == 121:
            block_config = (6, 12, 24, 16)
        elif num_layers == 169:
            block_config = (6, 12, 32, 32)
        else:
            block_config = (6, 12, 24, 16)
        
        # ì´ˆê¸° ì»¨ë³¼ë£¨ì…˜
        self.initial_conv = nn.Sequential(
            nn.Conv2d(6, 64, 7, 2, 3, bias=False),  # cloth + person
            nn.BatchNorm2d(64),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(3, 2, 1)
        )
        
        # DenseNet ë¸”ë¡ë“¤
        num_features = 64
        self.dense_blocks = nn.ModuleList()
        self.transitions = nn.ModuleList()
        
        for i, num_layers in enumerate(block_config):
            # Dense Block
            block = self._make_dense_block(num_features, growth_rate, num_layers)
            self.dense_blocks.append(block)
            num_features += num_layers * growth_rate
            
            # Transition (ë§ˆì§€ë§‰ ë¸”ë¡ ì œì™¸)
            if i != len(block_config) - 1:
                transition = self._make_transition(num_features, num_features // 2)
                self.transitions.append(transition)
                num_features = num_features // 2
        
        # í’ˆì§ˆ í‰ê°€ í—¤ë“œ
        self.quality_head = nn.Sequential(
            nn.AdaptiveAvgPool2d(1),
            nn.Flatten(),
            nn.Linear(num_features, 512),
            nn.ReLU(inplace=True),
            nn.Dropout(0.3),
            nn.Linear(512, 256),
            nn.ReLU(inplace=True),
            nn.Dropout(0.2),
            nn.Linear(256, 64),
            nn.ReLU(inplace=True),
            nn.Linear(64, 1),
            nn.Sigmoid()
        )
        
        # ì„¸ë¶€ í’ˆì§ˆ ë©”íŠ¸ë¦­
        self.detail_metrics = nn.ModuleDict({
            'texture_preservation': nn.Sequential(
                nn.AdaptiveAvgPool2d(1), nn.Flatten(),
                nn.Linear(num_features, 64), nn.ReLU(),
                nn.Linear(64, 1), nn.Sigmoid()
            ),
            'shape_consistency': nn.Sequential(
                nn.AdaptiveAvgPool2d(1), nn.Flatten(),
                nn.Linear(num_features, 64), nn.ReLU(),
                nn.Linear(64, 1), nn.Sigmoid()
            ),
            'edge_sharpness': nn.Sequential(
                nn.AdaptiveAvgPool2d(1), nn.Flatten(),
                nn.Linear(num_features, 64), nn.ReLU(),
                nn.Linear(64, 1), nn.Sigmoid()
            )
        })
    
    def _make_dense_block(self, num_features: int, growth_rate: int, num_layers: int):
        """DenseNet ë¸”ë¡ ìƒì„±"""
        layers = []
        for i in range(num_layers):
            layers.append(self._make_dense_layer(num_features + i * growth_rate, growth_rate))
        return nn.Sequential(*layers)
    
    def _make_dense_layer(self, num_input_features: int, growth_rate: int):
        """Dense Layer ìƒì„±"""
        return nn.Sequential(
            nn.BatchNorm2d(num_input_features),
            nn.ReLU(inplace=True),
            nn.Conv2d(num_input_features, growth_rate * 4, 1, bias=False),
            nn.BatchNorm2d(growth_rate * 4),
            nn.ReLU(inplace=True),
            nn.Conv2d(growth_rate * 4, growth_rate, 3, 1, 1, bias=False)
        )
    
    def _make_transition(self, num_input_features: int, num_output_features: int):
        """Transition Layer ìƒì„±"""
        return nn.Sequential(
            nn.BatchNorm2d(num_input_features),
            nn.ReLU(inplace=True),
            nn.Conv2d(num_input_features, num_output_features, 1, bias=False),
            nn.AvgPool2d(2, 2)
        )
    
    def forward(self, cloth_image: torch.Tensor, warped_cloth: torch.Tensor) -> Dict[str, torch.Tensor]:
        """DenseNet ê¸°ë°˜ í’ˆì§ˆ í‰ê°€"""
        
        # ì…ë ¥ ê²°í•©
        combined_input = torch.cat([cloth_image, warped_cloth], dim=1)
        
        # ì´ˆê¸° íŠ¹ì§• ì¶”ì¶œ
        features = self.initial_conv(combined_input)
        
        # DenseNet ë¸”ë¡ë“¤ í†µê³¼
        for i, dense_block in enumerate(self.dense_blocks):
            features = dense_block(features)
            if i < len(self.transitions):
                features = self.transitions[i](features)
        
        # ì „ì²´ í’ˆì§ˆ ì ìˆ˜
        overall_quality = self.quality_head(features)
        
        # ì„¸ë¶€ ë©”íŠ¸ë¦­
        detail_scores = {}
        for metric_name, metric_head in self.detail_metrics.items():
            detail_scores[metric_name] = metric_head(features)
        
        return {
            'overall_quality': overall_quality,
            'texture_preservation': detail_scores['texture_preservation'],
            'shape_consistency': detail_scores['shape_consistency'],
            'edge_sharpness': detail_scores['edge_sharpness'],
            'quality_features': features,
            'confidence': overall_quality
        }

# ==============================================
# ğŸ§  5. ë¬¼ë¦¬ ê¸°ë°˜ ì›ë‹¨ ì‹œë®¬ë ˆì´ì…˜ (1ë²ˆ íŒŒì¼ í’ˆì§ˆ)
# ==============================================

class PhysicsBasedFabricSimulation:
    """ë¬¼ë¦¬ ê¸°ë°˜ ì›ë‹¨ ì‹œë®¬ë ˆì´ì…˜ (1ë²ˆ íŒŒì¼ í’ˆì§ˆ)"""
    
    def __init__(self, fabric_type: FabricType = FabricType.COTTON):
        self.fabric_type = fabric_type
        self.fabric_properties = self._get_fabric_properties(fabric_type)
    
    def _get_fabric_properties(self, fabric_type: FabricType) -> Dict[str, float]:
        """ì›ë‹¨ íƒ€ì…ë³„ ë¬¼ë¦¬ ì†ì„±"""
        properties = {
            FabricType.COTTON: {
                'elasticity': 0.3, 'stiffness': 0.5, 'damping': 0.1,
                'density': 1.5, 'friction': 0.6
            },
            FabricType.SILK: {
                'elasticity': 0.1, 'stiffness': 0.2, 'damping': 0.05,
                'density': 1.3, 'friction': 0.3
            },
            FabricType.DENIM: {
                'elasticity': 0.5, 'stiffness': 0.8, 'damping': 0.2,
                'density': 1.8, 'friction': 0.8
            },
            FabricType.WOOL: {
                'elasticity': 0.4, 'stiffness': 0.6, 'damping': 0.15,
                'density': 1.4, 'friction': 0.7
            },
            FabricType.SPANDEX: {
                'elasticity': 0.8, 'stiffness': 0.3, 'damping': 0.05,
                'density': 1.2, 'friction': 0.4
            }
        }
        return properties.get(fabric_type, properties[FabricType.COTTON])
    
    def simulate_fabric_deformation(self, warped_cloth: torch.Tensor, 
                                   force_field: torch.Tensor) -> torch.Tensor:
        """ì›ë‹¨ ë³€í˜• ì‹œë®¬ë ˆì´ì…˜ (1ë²ˆ íŒŒì¼ í’ˆì§ˆ)"""
        try:
            batch_size, channels, height, width = warped_cloth.shape
            
            # ë¬¼ë¦¬ ì†ì„± ì ìš©
            elasticity = self.fabric_properties['elasticity']
            stiffness = self.fabric_properties['stiffness']
            damping = self.fabric_properties['damping']
            
            # ê°„ë‹¨í•œ ìŠ¤í”„ë§-ëŒí¼ ì‹œìŠ¤í…œ ì‹œë®¬ë ˆì´ì…˜
            # ì¸ì ‘ í”½ì…€ ê°„ì˜ ìŠ¤í”„ë§ ì—°ê²°ì„ ê°€ì •
            
            # ìˆ˜í‰ ë°©í–¥ ìŠ¤í”„ë§ í¬ìŠ¤
            horizontal_diff = F.pad(warped_cloth[:, :, :, 1:] - warped_cloth[:, :, :, :-1], 
                                   (0, 1, 0, 0))
            horizontal_force = -stiffness * horizontal_diff
            
            # ìˆ˜ì§ ë°©í–¥ ìŠ¤í”„ë§ í¬ìŠ¤
            vertical_diff = F.pad(warped_cloth[:, :, 1:, :] - warped_cloth[:, :, :-1, :], 
                                 (0, 0, 0, 1))
            vertical_force = -stiffness * vertical_diff
            
            # ëŒí•‘ í¬ìŠ¤ (ê°„ë‹¨í•œ êµ¬í˜„)
            damping_force = -damping * warped_cloth
            
            # ì™¸ë¶€ í¬ìŠ¤ (force_field) ì ìš©
            external_force = force_field * elasticity
            
            # ì´ í¬ìŠ¤
            total_force = horizontal_force + vertical_force + damping_force + external_force
            
            # í¬ìŠ¤ë¥¼ ì´ìš©í•œ ë³€í˜• ì ìš© (ì˜¤ì¼ëŸ¬ ì ë¶„)
            dt = 0.1  # ì‹œê°„ ìŠ¤í…
            displacement = total_force * dt * dt  # F = ma, a*dt^2 = displacement
            
            # ë³€í˜• ì œí•œ (ê³¼ë„í•œ ë³€í˜• ë°©ì§€)
            displacement = torch.clamp(displacement, -0.1, 0.1)
            
            simulated_cloth = warped_cloth + displacement
            
            # ë²”ìœ„ ì œí•œ
            simulated_cloth = torch.clamp(simulated_cloth, -1, 1)
            
            return simulated_cloth
            
        except Exception as e:
            logger.warning(f"ë¬¼ë¦¬ ì‹œë®¬ë ˆì´ì…˜ ì‹¤íŒ¨: {e}")
            return warped_cloth
    
    def apply_gravity_effect(self, cloth: torch.Tensor) -> torch.Tensor:
        """ì¤‘ë ¥ íš¨ê³¼ ì ìš©"""
        try:
            # ê°„ë‹¨í•œ ì¤‘ë ¥ íš¨ê³¼ - ì•„ë˜ìª½ìœ¼ë¡œ ì•½ê°„ì˜ ë“œë˜ê·¸
            gravity_strength = 0.02 * self.fabric_properties['density']
            
            # Y ë°©í–¥ìœ¼ë¡œ ê°€ì¤‘ì¹˜ ì ìš© (ì•„ë˜ìª½ì´ ë” ì˜í–¥ ë°›ìŒ)
            height = cloth.shape[2]
            y_weights = torch.linspace(0, gravity_strength, height, device=cloth.device)
            y_weights = y_weights.view(1, 1, -1, 1)
            
            # ì¤‘ë ¥ íš¨ê³¼ ì ìš©
            gravity_effect = torch.zeros_like(cloth)
            gravity_effect[:, :, 1:, :] = cloth[:, :, :-1, :] - cloth[:, :, 1:, :] 
            gravity_effect = gravity_effect * y_weights
            
            return cloth + gravity_effect
            
        except Exception as e:
            logger.warning(f"ì¤‘ë ¥ íš¨ê³¼ ì ìš© ì‹¤íŒ¨: {e}")
            return cloth

# ==============================================
# ğŸ”¥ ë©”ëª¨ë¦¬ ì•ˆì „ ìºì‹œ ì‹œìŠ¤í…œ (1ë²ˆ íŒŒì¼ íŒ¨í„´)
# ==============================================

def safe_mps_empty_cache():
    """M3 Max MPS ìºì‹œ ì•ˆì „ ì •ë¦¬"""
    try:
        gc.collect()
        if TORCH_AVAILABLE and MPS_AVAILABLE:
            try:
                if hasattr(torch.mps, 'empty_cache'):
                    torch.mps.empty_cache()
                if hasattr(torch.mps, 'synchronize'):
                    torch.mps.synchronize()
                return {"success": True, "method": "mps_optimized"}
            except Exception as e:
                return {"success": True, "method": "gc_only", "mps_error": str(e)}
        return {"success": True, "method": "gc_only"}
    except Exception as e:
        return {"success": False, "error": str(e)}

# ==============================================
# ğŸ”¥ ClothWarpingStep - BaseStepMixin ì™„ì „ í˜¸í™˜ (1ë²ˆ íŒŒì¼ íŒ¨í„´)
# ==============================================

if BaseStepMixin:
    class ClothWarpingStep(BaseStepMixin):
        """
        ğŸ”¥ Step 05: Enhanced Cloth Warping v15.0 (BaseStepMixin v19.1 ì™„ì „ í˜¸í™˜)
        
        âœ… BaseStepMixin v19.1 ì™„ì „ í˜¸í™˜
        âœ… ì˜ì¡´ì„± ì£¼ì… íŒ¨í„´ êµ¬í˜„
        âœ… ì‹¤ì œ AI ëª¨ë¸ íŒŒì¼ í™œìš©
        âœ… ê³ ê¸‰ ì˜ë¥˜ ì›Œí•‘ ì•Œê³ ë¦¬ì¦˜
        """
        def __init__(self, **kwargs):
            """GitHub í‘œì¤€ ì´ˆê¸°í™” (1ë²ˆ íŒŒì¼ íŒ¨í„´)"""
            # BaseStepMixin ì´ˆê¸°í™”
            super().__init__(
                step_name=kwargs.get('step_name', 'ClothWarpingStep'),
                step_id=kwargs.get('step_id', 5),
                **kwargs
            )
            
            # Step 05 íŠ¹í™” ì„¤ì •
            self.step_number = 5
            self.step_description = "Enhanced AI ì˜ë¥˜ ì›Œí•‘ ë° ë³€í˜•"
            
            # ë””ë°”ì´ìŠ¤ ì„¤ì •
            self.device = self._detect_optimal_device()
            
            # AI ëª¨ë¸ ìƒíƒœ
            self.ai_models: Dict[str, nn.Module] = {}
            self.model_paths: Dict[str, Optional[Path]] = {}
            self.preferred_model_order = ["realvis_xl", "vgg19_warping", "vgg16_warping", "densenet121", "diffusion_warping"]
            
            # ì›Œí•‘ ì„¤ì •
            self.warping_config = {
                'input_size': kwargs.get('input_size', (512, 512)),
                'quality_level': kwargs.get('quality_level', 'ultra'),
                'warping_method': kwargs.get('warping_method', 'hybrid_multi'),
                'use_realvis_xl': kwargs.get('use_realvis_xl', True),
                'use_vgg19_warping': kwargs.get('use_vgg19_warping', True),
                'use_densenet': kwargs.get('use_densenet', True),
                'use_diffusion_warping': kwargs.get('use_diffusion_warping', True),
                'physics_enabled': kwargs.get('physics_enabled', True),
                'multi_scale_fusion': kwargs.get('multi_scale_fusion', True)
            }
            
            # AI ëª¨ë¸ë“¤ ì´ˆê¸°í™”
            self.tps_network = None
            self.raft_network = None
            self.vgg_matching = None
            self.densenet_quality = None
            self.diffusion_refiner = None
            
            # ë¬¼ë¦¬ ì‹œë®¬ë ˆì´ì…˜
            self.fabric_simulator = PhysicsBasedFabricSimulation()
            
            # ìºì‹œ ì‹œìŠ¤í…œ (M3 Max ìµœì í™”)
            self.prediction_cache = {}
            self.cache_max_size = 150 if IS_M3_MAX else 50
            
            # í™˜ê²½ ìµœì í™”
            self.is_m3_max = IS_M3_MAX
            self.is_mycloset_env = CONDA_INFO['is_mycloset_env']
            
            # BaseStepMixin ì˜ì¡´ì„± ì¸í„°í˜ì´ìŠ¤ (GitHub í‘œì¤€)
            self.model_loader: Optional['ModelLoader'] = None
            self.memory_manager: Optional['MemoryManager'] = None
            self.data_converter: Optional['DataConverter'] = None
            self.di_container: Optional['DIContainer'] = None
            
            # ì„±ëŠ¥ í†µê³„ ì´ˆê¸°í™”
            self._initialize_performance_stats()
            
            # ì²˜ë¦¬ ì‹œê°„ ì¶”ì 
            self._last_processing_time = 0.0
            self.last_used_model = 'unknown'
            
            self.logger.info(f"âœ… {self.step_name} v15.0 BaseStepMixin í˜¸í™˜ ì´ˆê¸°í™” ì™„ë£Œ (device: {self.device})")

        def _detect_optimal_device(self) -> str:
            """ìµœì  ë””ë°”ì´ìŠ¤ ê°ì§€"""
            try:
                if TORCH_AVAILABLE:
                    # M3 Max MPS ìš°ì„ 
                    if MPS_AVAILABLE and IS_M3_MAX:
                        return "mps"
                    # CUDA í™•ì¸
                    elif torch.cuda.is_available():
                        return "cuda"
                return "cpu"
            except:
                return "cpu"
        
        # ==============================================
        # ğŸ”¥ BaseStepMixin ì˜ì¡´ì„± ì£¼ì… ì¸í„°í˜ì´ìŠ¤ (GitHub í‘œì¤€)
        # ==============================================
        
        def set_model_loader(self, model_loader: 'ModelLoader'):
            """ModelLoader ì˜ì¡´ì„± ì£¼ì… (GitHub í‘œì¤€)"""
            try:
                self.model_loader = model_loader
                self.logger.info("âœ… ModelLoader ì˜ì¡´ì„± ì£¼ì… ì™„ë£Œ")
                
                if hasattr(model_loader, 'create_step_interface'):
                    try:
                        self.model_interface = model_loader.create_step_interface(self.step_name)
                        self.logger.info("âœ… Step ì¸í„°í˜ì´ìŠ¤ ìƒì„± ì™„ë£Œ")
                    except Exception as e:
                        self.logger.warning(f"âš ï¸ Step ì¸í„°í˜ì´ìŠ¤ ìƒì„± ì‹¤íŒ¨, ê¸°ë³¸ ì¸í„°í˜ì´ìŠ¤ ì‚¬ìš©: {e}")
                        self.model_interface = model_loader
                else:
                    self.logger.debug("ModelLoaderì— create_step_interface ë©”ì„œë“œ ì—†ìŒ")
                    self.model_interface = model_loader
            except Exception as e:
                self.logger.error(f"âŒ ModelLoader ì˜ì¡´ì„± ì£¼ì… ì‹¤íŒ¨: {e}")
                raise
        
        def set_memory_manager(self, memory_manager: 'MemoryManager'):
            """MemoryManager ì˜ì¡´ì„± ì£¼ì… (GitHub í‘œì¤€)"""
            try:
                self.memory_manager = memory_manager
                self.logger.info("âœ… MemoryManager ì˜ì¡´ì„± ì£¼ì… ì™„ë£Œ")
            except Exception as e:
                self.logger.warning(f"âš ï¸ MemoryManager ì˜ì¡´ì„± ì£¼ì… ì‹¤íŒ¨: {e}")
        
        def set_data_converter(self, data_converter: 'DataConverter'):
            """DataConverter ì˜ì¡´ì„± ì£¼ì… (GitHub í‘œì¤€)"""
            try:
                self.data_converter = data_converter
                self.logger.info("âœ… DataConverter ì˜ì¡´ì„± ì£¼ì… ì™„ë£Œ")
            except Exception as e:
                self.logger.warning(f"âš ï¸ DataConverter ì˜ì¡´ì„± ì£¼ì… ì‹¤íŒ¨: {e}")
        
        def set_di_container(self, di_container: 'DIContainer'):
            """DI Container ì˜ì¡´ì„± ì£¼ì…"""
            try:
                self.di_container = di_container
                self.logger.info("âœ… DI Container ì˜ì¡´ì„± ì£¼ì… ì™„ë£Œ")
            except Exception as e:
                self.logger.warning(f"âš ï¸ DI Container ì˜ì¡´ì„± ì£¼ì… ì‹¤íŒ¨: {e}")
        
        # ==============================================
        # ğŸ”¥ ì´ˆê¸°í™” ë° AI ëª¨ë¸ ë¡œë”© (GitHub í‘œì¤€)
        # ==============================================
        
        async def initialize(self) -> bool:
            """ì´ˆê¸°í™” (GitHub í‘œì¤€ í”Œë¡œìš°)"""
            try:
                if getattr(self, 'is_initialized', False):
                    return True
                
                self.logger.info(f"ğŸš€ {self.step_name} v15.0 ì´ˆê¸°í™” ì‹œì‘")
                
                # ì‹¤ì œ AI ëª¨ë¸ ë¡œë”©
                success = await self._load_ai_models()
                if not success:
                    self.logger.warning("âš ï¸ ì‹¤ì œ AI ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨")
                    return False
                
                # M3 Max ìµœì í™” ì ìš©
                if self.device == "mps" or self.is_m3_max:
                    self._apply_m3_max_optimization()
                
                self.is_initialized = True
                self.is_ready = True
                
                self.logger.info(f"âœ… {self.step_name} v15.0 ì´ˆê¸°í™” ì™„ë£Œ (ë¡œë”©ëœ ëª¨ë¸: {len(self.ai_models)}ê°œ)")
                return True
                
            except Exception as e:
                self.logger.error(f"âŒ {self.step_name} v15.0 ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                return False
        
        async def _load_ai_models(self) -> bool:
            """ì‹¤ì œ AI ëª¨ë¸ ë¡œë”©"""
            try:
                self.logger.info("ğŸ”„ ì‹¤ì œ AI ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ ë¡œë”© ì‹œì‘")
                
                loaded_count = 0
                
                # 1. TPS ë„¤íŠ¸ì›Œí¬
                if self.warping_config['physics_enabled']:
                    try:
                        self.tps_network = AdvancedTPSWarpingNetwork(
                            num_control_points=25
                        ).to(self.device)
                        self._load_model_weights('tps_network', self.tps_network)
                        self.ai_models['tps_network'] = self.tps_network
                        loaded_count += 1
                        self.logger.info("âœ… TPS Network ë¡œë”© ì™„ë£Œ")
                    except Exception as e:
                        self.logger.warning(f"âš ï¸ TPS Network ë¡œë”© ì‹¤íŒ¨: {e}")
                
                # 2. RAFT Flow ë„¤íŠ¸ì›Œí¬
                try:
                    self.raft_network = RAFTFlowWarpingNetwork(
                        small_model=False
                    ).to(self.device)
                    self._load_model_weights('raft_flow', self.raft_network)
                    self.ai_models['raft_flow'] = self.raft_network
                    loaded_count += 1
                    self.logger.info("âœ… RAFT Flow Network ë¡œë”© ì™„ë£Œ")
                except Exception as e:
                    self.logger.warning(f"âš ï¸ RAFT Flow Network ë¡œë”© ì‹¤íŒ¨: {e}")
                
                # 3. VGG ë§¤ì¹­ ë„¤íŠ¸ì›Œí¬
                if self.warping_config['use_vgg19_warping']:
                    try:
                        self.vgg_matching = VGGClothBodyMatchingNetwork(
                            vgg_type="vgg19"
                        ).to(self.device)
                        self._load_model_weights('vgg19_warping', self.vgg_matching)
                        self.ai_models['vgg_matching'] = self.vgg_matching
                        loaded_count += 1
                        self.logger.info("âœ… VGG Matching Network ë¡œë”© ì™„ë£Œ")
                    except Exception as e:
                        self.logger.warning(f"âš ï¸ VGG Matching Network ë¡œë”© ì‹¤íŒ¨: {e}")
                
                # 4. DenseNet í’ˆì§ˆ í‰ê°€
                if self.warping_config['use_densenet']:
                    try:
                        self.densenet_quality = DenseNetQualityAssessment().to(self.device)
                        self._load_model_weights('densenet121', self.densenet_quality)
                        self.ai_models['densenet_quality'] = self.densenet_quality
                        loaded_count += 1
                        self.logger.info("âœ… DenseNet Quality Assessment ë¡œë”© ì™„ë£Œ")
                    except Exception as e:
                        self.logger.warning(f"âš ï¸ DenseNet Quality Assessment ë¡œë”© ì‹¤íŒ¨: {e}")
                
                if loaded_count > 0:
                    self.logger.info(f"âœ… ì‹¤ì œ AI ëª¨ë¸ ë¡œë”© ì™„ë£Œ: {loaded_count}ê°œ")
                    return True
                else:
                    self.logger.error("âŒ ë¡œë”©ëœ ì‹¤ì œ AI ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤")
                    return False
                    
            except Exception as e:
                self.logger.error(f"âŒ ì‹¤ì œ AI ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e}")
                return False

        def _load_model_weights(self, model_name: str, model: nn.Module):
            """ì‹¤ì œ ëª¨ë¸ ê°€ì¤‘ì¹˜ ë¡œë”©"""
            try:
                if not self.model_loader:
                    self.logger.debug(f"ModelLoader ì—†ìŒ - {model_name} ëœë¤ ì´ˆê¸°í™”")
                    return
                
                # ModelLoaderë¥¼ í†µí•œ ì²´í¬í¬ì¸íŠ¸ ë¡œë”©
                checkpoint = self.model_loader.load_model(model_name)
                
                if checkpoint:
                    # ê°€ì¤‘ì¹˜ ë¡œë”© ì‹œë„
                    if isinstance(checkpoint, dict):
                        if 'state_dict' in checkpoint:
                            model.load_state_dict(checkpoint['state_dict'], strict=False)
                        elif 'model' in checkpoint:
                            model.load_state_dict(checkpoint['model'], strict=False)
                        else:
                            model.load_state_dict(checkpoint, strict=False)
                    else:
                        model.load_state_dict(checkpoint, strict=False)
                    
                    self.logger.info(f"âœ… {model_name} ê°€ì¤‘ì¹˜ ë¡œë”© ì„±ê³µ")
                else:
                    self.logger.debug(f"âš ï¸ {model_name} ì²´í¬í¬ì¸íŠ¸ ì—†ìŒ - ëœë¤ ì´ˆê¸°í™”")
                    
            except Exception as e:
                self.logger.warning(f"âš ï¸ {model_name} ê°€ì¤‘ì¹˜ ë¡œë”© ì‹¤íŒ¨: {e}")

        def _apply_m3_max_optimization(self):
            """M3 Max ìµœì í™” ì ìš©"""
            try:
                # MPS ìºì‹œ ì •ë¦¬ (ì•ˆì „í•œ ë°©ë²•)
                safe_mps_empty_cache()
                
                # í™˜ê²½ ë³€ìˆ˜ ìµœì í™”
                if self.is_m3_max:
                    self.warping_config['batch_size'] = 1
                    self.cache_max_size = 150  # ë©”ëª¨ë¦¬ ì—¬ìœ 
                    
                self.logger.debug("âœ… M3 Max ìµœì í™” ì ìš© ì™„ë£Œ")
                
            except Exception as e:
                self.logger.warning(f"M3 Max ìµœì í™” ì‹¤íŒ¨: {e}")

        def _initialize_performance_stats(self):
            """ì„±ëŠ¥ í†µê³„ ì´ˆê¸°í™”"""
            try:
                self.performance_stats = {
                    'total_processed': 0,
                    'avg_processing_time': 0.0,
                    'error_count': 0,
                    'success_rate': 1.0,
                    'memory_usage_mb': 0.0,
                    'models_loaded': 0,
                    'cache_hits': 0,
                    'ai_inference_count': 0,
                    'warping_analysis_count': 0
                }
                
                self.total_processing_count = 0
                self.error_count = 0
                self.last_processing_time = 0.0
                
                self.logger.debug(f"âœ… {self.step_name} ì„±ëŠ¥ í†µê³„ ì´ˆê¸°í™” ì™„ë£Œ")
                
            except Exception as e:
                self.logger.error(f"âŒ {self.step_name} ì„±ëŠ¥ í†µê³„ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                self.performance_stats = {}
        
        # ==============================================
        # ğŸ”¥ BaseStepMixin v19.1 í‘œì¤€ - _run_ai_inference() ë©”ì„œë“œ (ë™ê¸°)
        # ==============================================
        
        def _run_ai_inference(self, processed_input: Dict[str, Any]) -> Dict[str, Any]:
            """
            ğŸ”¥ ê³ ê¸‰ AI ì•Œê³ ë¦¬ì¦˜ ê¸°ë°˜ ì˜ë¥˜ ì›Œí•‘ ì¶”ë¡  (ë™ê¸° ë©”ì„œë“œ)
            
            Args:
                processed_input: BaseStepMixinì—ì„œ ë³€í™˜ëœ í‘œì¤€ AI ëª¨ë¸ ì…ë ¥
            
            Returns:
                AI ëª¨ë¸ì˜ ì›ì‹œ ì¶œë ¥ ê²°ê³¼
            """
            try:
                start_time = time.time()
                self.logger.info(f"ğŸ§  {self.step_name} Enhanced AI ì¶”ë¡  ì‹œì‘")
                
                # 1. ì…ë ¥ ë°ì´í„° ê²€ì¦ ë° ì¤€ë¹„
                person_image = processed_input.get('image')
                cloth_image = processed_input.get('cloth_image')
                fabric_type = processed_input.get('fabric_type', 'cotton')
                warping_method = processed_input.get('warping_method', 'hybrid_multi')
                
                if person_image is None or cloth_image is None:
                    return self._create_error_ai_result("person_imageì™€ cloth_imageê°€ ëª¨ë‘ í•„ìš”í•©ë‹ˆë‹¤")
                
                # 2. í…ì„œ ë³€í™˜
                person_tensor = self._prepare_tensor_input(person_image)
                cloth_tensor = self._prepare_tensor_input(cloth_image)
                
                # 3. ì´ì „ Step ë°ì´í„° í™œìš©
                geometric_data = self._extract_geometric_data(processed_input)
                
                # 4. ë©”ì¸ AI ì¶”ë¡  ì‹¤í–‰
                warping_results = self._execute_multi_algorithm_warping(
                    cloth_tensor, person_tensor, geometric_data, warping_method
                )
                
                # 5. ë¬¼ë¦¬ ì‹œë®¬ë ˆì´ì…˜ ì ìš©
                if self.warping_config['physics_enabled']:
                    warping_results = self._apply_physics_simulation(warping_results, fabric_type)
                
                # 6. í’ˆì§ˆ í‰ê°€ ë° ì •ì œ
                quality_results = self._evaluate_and_refine_quality(warping_results)
                
                # 7. ìµœì¢… ê²°ê³¼ êµ¬ì„±
                final_result = self._construct_final_result(warping_results, quality_results)
                
                # ì„±ëŠ¥ í†µê³„ ì—…ë°ì´íŠ¸
                processing_time = time.time() - start_time
                self._update_performance_stats(processing_time, True)
                
                self.logger.info(f"âœ… {self.step_name} Enhanced AI ì¶”ë¡  ì™„ë£Œ ({processing_time:.2f}ì´ˆ)")
                return final_result
                
            except Exception as e:
                processing_time = time.time() - start_time if 'start_time' in locals() else 0.0
                self._update_performance_stats(processing_time, False)
                self.logger.error(f"âŒ {self.step_name} Enhanced AI ì¶”ë¡  ì‹¤íŒ¨: {e}")
                self.logger.debug(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
                return self._create_error_ai_result(str(e))
        

        def _execute_multi_algorithm_warping(self, cloth_tensor: torch.Tensor, 
                                     person_tensor: torch.Tensor,
                                     geometric_data: Dict[str, Any],
                                     method: str) -> Dict[str, Any]:
            """ë©€í‹° ì•Œê³ ë¦¬ì¦˜ ì›Œí•‘ ì‹¤í–‰ (ìˆ˜ì •ëœ ë²„ì „)"""
            try:
                results = {}
                
                self.logger.info(f"ğŸ”„ ë©€í‹° ì•Œê³ ë¦¬ì¦˜ ì›Œí•‘ ì‹¤í–‰: {method}")
                
                # ğŸ”§ ìˆ˜ì • 1: ëª¨ë¸ ìƒíƒœ ì‚¬ì „ ê²€ì¦
                available_models = self._check_available_models()
                self.logger.info(f"ğŸ“Š ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸: {available_models}")
                
                # ğŸ”§ ìˆ˜ì • 2: TPS ê¸°ë°˜ ì›Œí•‘ (ì•ˆì „í•œ ì‹¤í–‰)
                if method in ['hybrid_multi', 'tps_advanced']:
                    try:
                        if self.tps_network is not None:
                            self.logger.info("ğŸ§  TPS ì›Œí•‘ ì‹œì‘...")
                            tps_result = self._safe_execute_tps(cloth_tensor, person_tensor)
                            if tps_result is not None and 'warped_cloth' in tps_result:
                                results['tps'] = tps_result
                                self.logger.info("âœ… TPS ì›Œí•‘ ì™„ë£Œ")
                            else:
                                self.logger.warning("âš ï¸ TPS ì›Œí•‘ ê²°ê³¼ê°€ ìœ íš¨í•˜ì§€ ì•ŠìŒ")
                        else:
                            self.logger.warning("âš ï¸ TPS ë„¤íŠ¸ì›Œí¬ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•ŠìŒ")
                            # ê°„ë‹¨í•œ TPS í´ë°± êµ¬í˜„
                            simple_tps = self._create_simple_warping_result(cloth_tensor, person_tensor, "tps_fallback")
                            results['tps_simple'] = simple_tps
                            self.logger.info("âœ… ê°„ë‹¨í•œ TPS í´ë°± ì™„ë£Œ")
                    except Exception as e:
                        self.logger.error(f"âŒ TPS ì›Œí•‘ ì‹¤íŒ¨: {e}")
                        fallback_tps = self._create_simple_warping_result(cloth_tensor, person_tensor, "tps_error_fallback")
                        results['tps_fallback'] = fallback_tps

                # ğŸ”§ ìˆ˜ì • 3: RAFT Flow ê¸°ë°˜ ì›Œí•‘ (ì•ˆì „í•œ ì‹¤í–‰)
                if method in ['hybrid_multi', 'raft_flow']:
                    try:
                        if self.raft_network is not None:
                            self.logger.info("ğŸŒŠ RAFT Flow ì›Œí•‘ ì‹œì‘...")
                            raft_result = self._safe_execute_raft(cloth_tensor, person_tensor)
                            if raft_result is not None and 'warped_cloth' in raft_result:
                                results['raft'] = raft_result
                                self.logger.info("âœ… RAFT Flow ì›Œí•‘ ì™„ë£Œ")
                            else:
                                self.logger.warning("âš ï¸ RAFT ì›Œí•‘ ê²°ê³¼ê°€ ìœ íš¨í•˜ì§€ ì•ŠìŒ")
                        else:
                            self.logger.warning("âš ï¸ RAFT ë„¤íŠ¸ì›Œí¬ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•ŠìŒ")
                            simple_flow = self._create_simple_warping_result(cloth_tensor, person_tensor, "raft_fallback")
                            results['raft_simple'] = simple_flow
                            self.logger.info("âœ… ê°„ë‹¨í•œ Flow í´ë°± ì™„ë£Œ")
                    except Exception as e:
                        self.logger.error(f"âŒ RAFT ì›Œí•‘ ì‹¤íŒ¨: {e}")
                        fallback_raft = self._create_simple_warping_result(cloth_tensor, person_tensor, "raft_error_fallback")
                        results['raft_fallback'] = fallback_raft

                # ğŸ”§ ìˆ˜ì • 4: VGG ê¸°ë°˜ ë§¤ì¹­ ì›Œí•‘ (ì•ˆì „í•œ ì‹¤í–‰)
                if method in ['hybrid_multi', 'vgg_matching']:
                    try:
                        if self.vgg_matching is not None:
                            self.logger.info("ğŸ¯ VGG ë§¤ì¹­ ì›Œí•‘ ì‹œì‘...")
                            vgg_result = self._safe_execute_vgg(cloth_tensor, person_tensor)
                            if vgg_result is not None and 'warped_cloth' in vgg_result:
                                results['vgg'] = vgg_result
                                self.logger.info("âœ… VGG ë§¤ì¹­ ì›Œí•‘ ì™„ë£Œ")
                            else:
                                self.logger.warning("âš ï¸ VGG ì›Œí•‘ ê²°ê³¼ê°€ ìœ íš¨í•˜ì§€ ì•ŠìŒ")
                        else:
                            self.logger.warning("âš ï¸ VGG ë„¤íŠ¸ì›Œí¬ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•ŠìŒ")
                            simple_matching = self._create_simple_warping_result(cloth_tensor, person_tensor, "vgg_fallback")
                            results['vgg_simple'] = simple_matching
                            self.logger.info("âœ… ê°„ë‹¨í•œ ë§¤ì¹­ í´ë°± ì™„ë£Œ")
                    except Exception as e:
                        self.logger.error(f"âŒ VGG ì›Œí•‘ ì‹¤íŒ¨: {e}")
                        fallback_vgg = self._create_simple_warping_result(cloth_tensor, person_tensor, "vgg_error_fallback")
                        results['vgg_fallback'] = fallback_vgg

                # ğŸ”§ ìˆ˜ì • 5: ìµœì†Œí•œì˜ ê²°ê³¼ ë³´ì¥ (í•µì‹¬ ìˆ˜ì •!)
                if not results:
                    self.logger.warning("âš ï¸ ëª¨ë“  AI ì•Œê³ ë¦¬ì¦˜ì´ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ê¸°ë³¸ ì›Œí•‘ì„ ìƒì„±í•©ë‹ˆë‹¤.")
                    basic_warping = self._create_basic_warping_result(cloth_tensor, person_tensor)
                    results['basic'] = basic_warping
                    self.logger.info("âœ… ê¸°ë³¸ ì›Œí•‘ ê²°ê³¼ ìƒì„± ì™„ë£Œ")

                # ğŸ”§ ìˆ˜ì • 6: ê²°ê³¼ ê²€ì¦
                valid_results = self._validate_warping_results(results)
                self.logger.info(f"ğŸ“Š ìœ íš¨í•œ ì›Œí•‘ ê²°ê³¼: {len(valid_results)}ê°œ")

                # ğŸ”§ ìˆ˜ì • 7: ìœµí•© ë¡œì§ (2ê°œ ì´ìƒì˜ ìœ íš¨í•œ ê²°ê³¼ê°€ ìˆì„ ë•Œë§Œ)
                if method == 'hybrid_multi' and len(valid_results) > 1:
                    try:
                        fused_result = self._fuse_multiple_warping_results(valid_results)
                        if fused_result is not None:
                            valid_results['fused'] = fused_result
                            self.logger.info("âœ… ë©€í‹° ì•Œê³ ë¦¬ì¦˜ ìœµí•© ì™„ë£Œ")
                    except Exception as e:
                        self.logger.error(f"âŒ ìœµí•© ì‹¤íŒ¨: {e}")

                # ğŸ”§ ìˆ˜ì • 8: ìµœì  ê²°ê³¼ ì„ íƒ (ë³´ì¥ëœ ê²°ê³¼ ì‚¬ìš©)
                best_result = self._select_best_warping_result_safe(valid_results)
                
                return {
                    'best_warped_cloth': best_result['warped_cloth'],
                    'all_results': valid_results,
                    'method_used': method,
                    'confidence': best_result.get('confidence', torch.tensor([0.7])),
                    'warping_metadata': {
                        'algorithms_used': list(valid_results.keys()),
                        'fusion_applied': 'fused' in valid_results,
                        'geometric_data_used': bool(geometric_data),
                        'total_algorithms_attempted': len([k for k in ['tps', 'raft', 'vgg'] if method in ['hybrid_multi'] or k in method]),
                        'successful_algorithms': len(valid_results)
                    }
                }
                
            except Exception as e:
                self.logger.error(f"âŒ ë©€í‹° ì•Œê³ ë¦¬ì¦˜ ì›Œí•‘ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
                self.logger.debug(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
                # ìµœí›„ í´ë°±: ê°„ë‹¨í•œ ì–´íŒŒì¸ ë³€í˜•
                return self._fallback_simple_warping(cloth_tensor, person_tensor)

        # ìƒˆë¡œ ì¶”ê°€í•  ì•ˆì „í•œ ì‹¤í–‰ ë©”ì„œë“œë“¤
        def _check_available_models(self) -> Dict[str, bool]:
            """ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ìƒíƒœ í™•ì¸"""
            try:
                available = {
                    'tps_network': self.tps_network is not None,
                    'raft_network': self.raft_network is not None,
                    'vgg_matching': self.vgg_matching is not None,
                    'densenet_quality': self.densenet_quality is not None,
                    'physics_simulation': hasattr(self, 'fabric_simulator') and self.fabric_simulator is not None
                }
                return available
            except Exception as e:
                self.logger.error(f"âŒ ëª¨ë¸ ìƒíƒœ í™•ì¸ ì‹¤íŒ¨: {e}")
                return {}

        def _safe_execute_tps(self, cloth_tensor: torch.Tensor, person_tensor: torch.Tensor) -> Optional[Dict[str, Any]]:
            """ì•ˆì „í•œ TPS ì›Œí•‘ ì‹¤í–‰"""
            try:
                with torch.no_grad():
                    result = self.tps_network(cloth_tensor, person_tensor)
                    
                    # ê²°ê³¼ ê²€ì¦
                    if result is None or not isinstance(result, dict):
                        self.logger.warning("TPS ë„¤íŠ¸ì›Œí¬ê°€ None ë˜ëŠ” ì˜ëª»ëœ íƒ€ì… ë°˜í™˜")
                        return None
                        
                    if 'warped_cloth' not in result:
                        self.logger.warning("TPS ê²°ê³¼ì— warped_clothê°€ ì—†ìŒ")
                        return None
                        
                    warped_cloth = result['warped_cloth']
                    if not torch.is_tensor(warped_cloth) or warped_cloth.numel() == 0:
                        self.logger.warning("TPS warped_clothê°€ ìœ íš¨í•˜ì§€ ì•ŠìŒ")
                        return None
                    
                    return {
                        'warped_cloth': warped_cloth,
                        'confidence': result.get('confidence', torch.tensor([0.7])),
                        'method': 'tps_network',
                        'tps_metadata': {
                            'control_points': result.get('control_points'),
                            'transformation_matrix': result.get('transformation_matrix')
                        }
                    }
            except Exception as e:
                self.logger.error(f"âŒ ì•ˆì „í•œ TPS ì‹¤í–‰ ì‹¤íŒ¨: {e}")
                return None

        def _safe_execute_raft(self, cloth_tensor: torch.Tensor, person_tensor: torch.Tensor) -> Optional[Dict[str, Any]]:
            """ì•ˆì „í•œ RAFT ì›Œí•‘ ì‹¤í–‰"""
            try:
                with torch.no_grad():
                    result = self.raft_network(cloth_tensor, person_tensor, num_iterations=12)
                    
                    if result is None or not isinstance(result, dict) or 'warped_cloth' not in result:
                        return None
                        
                    warped_cloth = result['warped_cloth']
                    if not torch.is_tensor(warped_cloth) or warped_cloth.numel() == 0:
                        return None
                    
                    return {
                        'warped_cloth': warped_cloth,
                        'confidence': result.get('confidence', torch.tensor([0.6])),
                        'method': 'raft_network',
                        'raft_metadata': {
                            'optical_flow': result.get('flow'),
                            'flow_magnitude': result.get('flow_magnitude')
                        }
                    }
            except Exception as e:
                self.logger.error(f"âŒ ì•ˆì „í•œ RAFT ì‹¤í–‰ ì‹¤íŒ¨: {e}")
                return None

        def _safe_execute_vgg(self, cloth_tensor: torch.Tensor, person_tensor: torch.Tensor) -> Optional[Dict[str, Any]]:
            """ì•ˆì „í•œ VGG ì›Œí•‘ ì‹¤í–‰"""
            try:
                with torch.no_grad():
                    result = self.vgg_matching(cloth_tensor, person_tensor)
                    
                    if result is None or not isinstance(result, dict) or 'warped_cloth' not in result:
                        return None
                        
                    warped_cloth = result['warped_cloth']
                    if not torch.is_tensor(warped_cloth) or warped_cloth.numel() == 0:
                        return None
                    
                    return {
                        'warped_cloth': warped_cloth,
                        'confidence': result.get('confidence', torch.tensor([0.65])),
                        'method': 'vgg_matching',
                        'vgg_metadata': {
                            'feature_maps': result.get('feature_maps'),
                            'matching_score': result.get('matching_score')
                        }
                    }
            except Exception as e:
                self.logger.error(f"âŒ ì•ˆì „í•œ VGG ì‹¤í–‰ ì‹¤íŒ¨: {e}")
                return None

        def _create_simple_warping_result(self, cloth_tensor: torch.Tensor, person_tensor: torch.Tensor, method_name: str) -> Dict[str, Any]:
            """ê°„ë‹¨í•œ ì›Œí•‘ ê²°ê³¼ ìƒì„±"""
            try:
                # ê°„ë‹¨í•œ í¬ê¸° ì¡°ì •ê³¼ ìœ„ì¹˜ ì¡°ì •
                cloth_h, cloth_w = cloth_tensor.shape[-2:]
                person_h, person_w = person_tensor.shape[-2:]
                
                # í¬ê¸° ë¹„ìœ¨ ì¡°ì •
                scale_h = person_h / cloth_h
                scale_w = person_w / cloth_w
                scale = min(scale_h, scale_w)
                
                # ë¦¬ì‚¬ì´ì¦ˆ
                new_h = int(cloth_h * scale)
                new_w = int(cloth_w * scale)
                
                warped_cloth = F.interpolate(
                    cloth_tensor, 
                    size=(new_h, new_w), 
                    mode='bilinear', 
                    align_corners=False
                )
                
                # ì¤‘ì•™ ì •ë ¬ì„ ìœ„í•œ íŒ¨ë”©
                pad_h = (person_h - new_h) // 2
                pad_w = (person_w - new_w) // 2
                
                warped_cloth = F.pad(
                    warped_cloth,
                    (pad_w, person_w - new_w - pad_w, pad_h, person_h - new_h - pad_h),
                    mode='constant', 
                    value=0
                )
                
                return {
                    'warped_cloth': warped_cloth,
                    'confidence': torch.tensor([0.5]),
                    'method': method_name,
                    'is_fallback': True,
                    'transform_metadata': {
                        'scale_used': scale,
                        'padding': (pad_h, pad_w),
                        'original_size': (cloth_h, cloth_w),
                        'target_size': (person_h, person_w)
                    }
                }
            except Exception as e:
                self.logger.error(f"âŒ ê°„ë‹¨í•œ ì›Œí•‘ ê²°ê³¼ ìƒì„± ì‹¤íŒ¨: {e}")
                return {
                    'warped_cloth': cloth_tensor.clone(),
                    'confidence': torch.tensor([0.1]),
                    'method': f"{method_name}_identity",
                    'is_fallback': True,
                    'error': str(e)
                }

        def _create_basic_warping_result(self, cloth_tensor: torch.Tensor, person_tensor: torch.Tensor) -> Dict[str, Any]:
            """ê¸°ë³¸ ì›Œí•‘ ê²°ê³¼ ìƒì„± (ìµœí›„ ë³´ì¥)"""
            try:
                # ë” ì •êµí•œ ê¸°ë³¸ ì›Œí•‘
                return self._create_simple_warping_result(cloth_tensor, person_tensor, "basic_resize_align")
            except Exception as e:
                self.logger.error(f"âŒ ê¸°ë³¸ ì›Œí•‘ ê²°ê³¼ ìƒì„± ì‹¤íŒ¨: {e}")
                # ìµœí›„ì˜ ìˆ˜ë‹¨: ì›ë³¸ ë°˜í™˜
                return {
                    'warped_cloth': cloth_tensor.clone(),
                    'confidence': torch.tensor([0.1]),
                    'method': 'identity',
                    'is_fallback': True,
                    'error': str(e)
                }

        def _validate_warping_results(self, results: Dict[str, Dict[str, Any]]) -> Dict[str, Dict[str, Any]]:
            """ì›Œí•‘ ê²°ê³¼ ê²€ì¦"""
            valid_results = {}
            
            for method_name, result in results.items():
                try:
                    if (result is not None and 
                        isinstance(result, dict) and 
                        'warped_cloth' in result and
                        result['warped_cloth'] is not None):
                        
                        # í…ì„œ ìœ íš¨ì„± ê²€ì‚¬
                        warped_cloth = result['warped_cloth']
                        if torch.is_tensor(warped_cloth) and warped_cloth.numel() > 0:
                            # NaN ì²´í¬
                            if not torch.isnan(warped_cloth).any() and not torch.isinf(warped_cloth).any():
                                valid_results[method_name] = result
                                self.logger.debug(f"âœ… {method_name} ê²°ê³¼ ìœ íš¨í•¨")
                            else:
                                self.logger.warning(f"âš ï¸ {method_name} ê²°ê³¼ì— NaN/Inf ê°’ í¬í•¨")
                        else:
                            self.logger.warning(f"âš ï¸ {method_name} ê²°ê³¼ì˜ í…ì„œê°€ ìœ íš¨í•˜ì§€ ì•ŠìŒ")
                    else:
                        self.logger.warning(f"âš ï¸ {method_name} ê²°ê³¼ê°€ ìœ íš¨í•˜ì§€ ì•ŠìŒ")
                except Exception as e:
                    self.logger.error(f"âŒ {method_name} ê²°ê³¼ ê²€ì¦ ì‹¤íŒ¨: {e}")
            
            return valid_results

        def _select_best_warping_result_safe(self, results: Dict[str, Dict[str, Any]]) -> Dict[str, Any]:
            """ì•ˆì „í•œ ìµœì  ì›Œí•‘ ê²°ê³¼ ì„ íƒ"""
            try:
                if not results:
                    raise ValueError("ìœ íš¨í•œ ì›Œí•‘ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤")
                
                # ìœµí•© ê²°ê³¼ê°€ ìˆìœ¼ë©´ ìš°ì„  ì„ íƒ
                if 'fused' in results:
                    return results['fused']
                
                # ì‹ ë¢°ë„ ê¸°ë°˜ ì„ íƒ
                best_method = None
                best_confidence = -1.0
                
                for method_name, result in results.items():
                    try:
                        conf = result.get('confidence', torch.tensor([0.0]))
                        if torch.is_tensor(conf):
                            conf_value = conf.mean().item()
                        else:
                            conf_value = float(conf)
                        
                        if conf_value > best_confidence:
                            best_confidence = conf_value
                            best_method = method_name
                    except Exception as e:
                        self.logger.debug(f"ì‹ ë¢°ë„ ì¶”ì¶œ ì‹¤íŒ¨ ({method_name}): {e}")
                        continue
                
                if best_method:
                    selected_result = results[best_method].copy()
                    selected_result['selected_method'] = best_method
                    selected_result['selection_confidence'] = best_confidence
                    return selected_result
                
                # í´ë°±: ì²« ë²ˆì§¸ ê²°ê³¼
                first_method = list(results.keys())[0]
                selected_result = results[first_method].copy()
                selected_result['selected_method'] = first_method
                selected_result['selection_confidence'] = 0.3
                return selected_result
                
            except Exception as e:
                self.logger.error(f"âŒ ì•ˆì „í•œ ìµœì  ê²°ê³¼ ì„ íƒ ì‹¤íŒ¨: {e}")
                
                # ìµœí›„ í´ë°±
                if results:
                    first_result = list(results.values())[0]
                    return {
                        'warped_cloth': first_result.get('warped_cloth'),
                        'confidence': torch.tensor([0.2]),
                        'selected_method': 'emergency_fallback',
                        'error': str(e)
                    }
                else:
                    # ì •ë§ ìµœí›„ì˜ ìˆ˜ë‹¨
                    raise ValueError("ë³µêµ¬ ë¶ˆê°€ëŠ¥í•œ ì›Œí•‘ ì‹¤íŒ¨: ì‚¬ìš© ê°€ëŠ¥í•œ ê²°ê³¼ê°€ ì „í˜€ ì—†ìŠµë‹ˆë‹¤")
                
        def _fuse_multiple_warping_results(self, results: Dict[str, Dict[str, Any]]) -> Dict[str, Any]:
            """ì—¬ëŸ¬ ì›Œí•‘ ê²°ê³¼ ìœµí•©"""
            try:
                warped_cloths = []
                confidences = []
                
                # ê° ê²°ê³¼ì—ì„œ ì›Œí•‘ëœ ì˜ë¥˜ì™€ ì‹ ë¢°ë„ ì¶”ì¶œ
                for method_name, result in results.items():
                    if 'warped_cloth' in result:
                        warped_cloths.append(result['warped_cloth'])
                        conf = result.get('confidence', torch.tensor([0.5]))
                        if torch.is_tensor(conf):
                            confidences.append(conf.mean().item())
                        else:
                            confidences.append(float(conf))
                
                if not warped_cloths:
                    raise ValueError("ìœµí•©í•  ì›Œí•‘ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤")
                
                # ì‹ ë¢°ë„ ê¸°ë°˜ ê°€ì¤‘ í‰ê· 
                confidences = torch.tensor(confidences, device=warped_cloths[0].device)
                weights = F.softmax(confidences, dim=0)
                
                # ê°€ì¤‘ í‰ê·  ê³„ì‚°
                fused_cloth = torch.zeros_like(warped_cloths[0])
                for i, cloth in enumerate(warped_cloths):
                    fused_cloth += cloth * weights[i]
                
                return {
                    'warped_cloth': fused_cloth,
                    'confidence': torch.mean(confidences),
                    'fusion_weights': weights,
                    'num_methods_fused': len(warped_cloths)
                }
                
            except Exception as e:
                self.logger.error(f"âŒ ì›Œí•‘ ê²°ê³¼ ìœµí•© ì‹¤íŒ¨: {e}")
                # í´ë°±: ì²« ë²ˆì§¸ ê²°ê³¼ ë°˜í™˜
                first_result = list(results.values())[0]
                return {
                    'warped_cloth': first_result['warped_cloth'],
                    'confidence': first_result.get('confidence', torch.tensor([0.5])),
                    'fusion_weights': torch.tensor([1.0]),
                    'num_methods_fused': 1
                }
        
        def _select_best_warping_result(self, results: Dict[str, Dict[str, Any]]) -> Dict[str, Any]:
            """ìµœì  ì›Œí•‘ ê²°ê³¼ ì„ íƒ"""
            try:
                if not results:
                    raise ValueError("ì„ íƒí•  ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤")
                
                # ìœµí•© ê²°ê³¼ê°€ ìˆìœ¼ë©´ ìš°ì„  ì„ íƒ
                if 'fused' in results:
                    return results['fused']
                
                # ì‹ ë¢°ë„ ê¸°ë°˜ ì„ íƒ
                best_method = None
                best_confidence = 0.0
                
                for method_name, result in results.items():
                    conf = result.get('confidence', torch.tensor([0.0]))
                    if torch.is_tensor(conf):
                        conf_value = conf.mean().item()
                    else:
                        conf_value = float(conf)
                    
                    if conf_value > best_confidence:
                        best_confidence = conf_value
                        best_method = method_name
                
                if best_method:
                    selected_result = results[best_method].copy()
                    selected_result['selected_method'] = best_method
                    selected_result['selection_confidence'] = best_confidence
                    return selected_result
                
                # í´ë°±: ì²« ë²ˆì§¸ ê²°ê³¼
                first_method = list(results.keys())[0]
                selected_result = results[first_method].copy()
                selected_result['selected_method'] = first_method
                selected_result['selection_confidence'] = 0.5
                return selected_result
                
            except Exception as e:
                self.logger.error(f"âŒ ìµœì  ì›Œí•‘ ê²°ê³¼ ì„ íƒ ì‹¤íŒ¨: {e}")
                # ìµœí›„ í´ë°±
                if results:
                    first_result = list(results.values())[0]
                    return {
                        'warped_cloth': first_result.get('warped_cloth'),
                        'confidence': torch.tensor([0.3]),
                        'selected_method': 'fallback'
                    }
                else:
                    raise ValueError("ì‚¬ìš© ê°€ëŠ¥í•œ ì›Œí•‘ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤")
        
        def _apply_physics_simulation(self, warping_results: Dict[str, Any], 
                                     fabric_type: str) -> Dict[str, Any]:
            """ë¬¼ë¦¬ ì‹œë®¬ë ˆì´ì…˜ ì ìš©"""
            try:
                if 'best_warped_cloth' not in warping_results:
                    return warping_results
                
                warped_cloth = warping_results['best_warped_cloth']
                
                # ì›ë‹¨ íƒ€ì… ì„¤ì •
                try:
                    fabric_enum = FabricType(fabric_type.lower())
                except ValueError:
                    fabric_enum = FabricType.COTTON
                
                self.fabric_simulator = PhysicsBasedFabricSimulation(fabric_enum)
                
                # í¬ìŠ¤ í•„ë“œ ìƒì„± (ê°„ë‹¨í•œ êµ¬í˜„)
                force_field = torch.randn_like(warped_cloth) * 0.01
                
                # ì›ë‹¨ ë³€í˜• ì‹œë®¬ë ˆì´ì…˜
                simulated_cloth = self.fabric_simulator.simulate_fabric_deformation(
                    warped_cloth, force_field
                )
                
                # ì¤‘ë ¥ íš¨ê³¼ ì ìš©
                simulated_cloth = self.fabric_simulator.apply_gravity_effect(simulated_cloth)
                
                # ê²°ê³¼ ì—…ë°ì´íŠ¸
                warping_results['physics_enhanced_cloth'] = simulated_cloth
                warping_results['best_warped_cloth'] = simulated_cloth
                warping_results['physics_applied'] = True
                warping_results['fabric_type'] = fabric_type
                
                self.logger.info(f"âœ… ë¬¼ë¦¬ ì‹œë®¬ë ˆì´ì…˜ ì ìš© ì™„ë£Œ (ì›ë‹¨: {fabric_type})")
                
                return warping_results
                
            except Exception as e:
                self.logger.warning(f"âš ï¸ ë¬¼ë¦¬ ì‹œë®¬ë ˆì´ì…˜ ì ìš© ì‹¤íŒ¨: {e}")
                warping_results['physics_applied'] = False
                return warping_results
        
        def _evaluate_and_refine_quality(self, warping_results: Dict[str, Any]) -> Dict[str, Any]:
            """í’ˆì§ˆ í‰ê°€ ë° ì •ì œ"""
            try:
                quality_results = {}
                
                if 'best_warped_cloth' not in warping_results:
                    return quality_results
                
                warped_cloth = warping_results['best_warped_cloth']
                
                # DenseNet í’ˆì§ˆ í‰ê°€
                if self.densenet_quality:
                    # ì›ë³¸ ì˜ë¥˜ê°€ í•„ìš”í•˜ë¯€ë¡œ ë”ë¯¸ ë°ì´í„° ì‚¬ìš©
                    dummy_original = torch.randn_like(warped_cloth)
                    
                    quality_assessment = self.densenet_quality(dummy_original, warped_cloth)
                    
                    quality_results['overall_quality'] = quality_assessment['overall_quality']
                    quality_results['texture_preservation'] = quality_assessment['texture_preservation']
                    quality_results['shape_consistency'] = quality_assessment['shape_consistency']
                    quality_results['edge_sharpness'] = quality_assessment['edge_sharpness']
                    
                    self.logger.info("âœ… DenseNet í’ˆì§ˆ í‰ê°€ ì™„ë£Œ")
                
                # ì „ì²´ í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°
                if quality_results:
                    overall_scores = []
                    for key, value in quality_results.items():
                        if 'quality' in key or 'preservation' in key or 'consistency' in key:
                            if torch.is_tensor(value):
                                overall_scores.append(value.mean().item())
                            elif isinstance(value, (int, float)):
                                overall_scores.append(float(value))
                    
                    if overall_scores:
                        quality_results['computed_overall_quality'] = np.mean(overall_scores)
                    else:
                        quality_results['computed_overall_quality'] = 0.7
                else:
                    quality_results['computed_overall_quality'] = 0.7
                
                return quality_results
                
            except Exception as e:
                self.logger.error(f"âŒ í’ˆì§ˆ í‰ê°€ ë° ì •ì œ ì‹¤íŒ¨: {e}")
                return {
                    'computed_overall_quality': 0.5,
                    'error': str(e)
                }
        
        def _construct_final_result(self, warping_results: Dict[str, Any], 
                                   quality_results: Dict[str, Any]) -> Dict[str, Any]:
            """ìµœì¢… ê²°ê³¼ êµ¬ì„±"""
            try:
                warped_cloth = warping_results.get('best_warped_cloth')
                
                if warped_cloth is None:
                    return self._create_error_ai_result("ì›Œí•‘ëœ ì˜ë¥˜ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤")
                
                # ê¸°ë³¸ ê²°ê³¼ êµ¬ì„±
                final_result = {
                    'warped_cloth': warped_cloth,
                    'warped_cloth_tensor': warped_cloth,
                    'ai_success': True,
                    'enhanced_ai_inference': True,
                    
                    # ì‹ ë¢°ë„ ë° í’ˆì§ˆ
                    'confidence': warping_results.get('confidence', torch.tensor([0.8])).mean().item(),
                    'quality_score': quality_results.get('computed_overall_quality', 0.7),
                    'overall_quality': quality_results.get('computed_overall_quality', 0.7),
                    'quality_grade': self._calculate_quality_grade(
                        quality_results.get('computed_overall_quality', 0.7)
                    ),
                    
                    # ì•Œê³ ë¦¬ì¦˜ ë©”íƒ€ë°ì´í„°
                    'algorithms_used': warping_results.get('warping_metadata', {}).get('algorithms_used', []),
                    'method_used': warping_results.get('method_used', 'unknown'),
                    'fusion_applied': warping_results.get('warping_metadata', {}).get('fusion_applied', False),
                    
                    # ë¬¼ë¦¬ ì‹œë®¬ë ˆì´ì…˜ ì •ë³´
                    'physics_applied': warping_results.get('physics_applied', False),
                    'fabric_type': warping_results.get('fabric_type', 'cotton'),
                    
                    # í’ˆì§ˆ ìƒì„¸ ì •ë³´
                    'quality_analysis': {
                        'texture_preservation': self._tensor_to_float(quality_results.get('texture_preservation', 0.7)),
                        'shape_consistency': self._tensor_to_float(quality_results.get('shape_consistency', 0.7)),
                        'edge_sharpness': self._tensor_to_float(quality_results.get('edge_sharpness', 0.7)),
                        'overall_quality': quality_results.get('computed_overall_quality', 0.7)
                    },
                    
                    # ì›Œí•‘ ë³€í˜• ì •ë³´
                    'warping_transformation': {
                        'control_points': warping_results.get('all_results', {}).get('tps', {}).get('control_points'),
                        'flow_field': warping_results.get('all_results', {}).get('raft', {}).get('flow_field'),
                        'matching_map': warping_results.get('all_results', {}).get('vgg', {}).get('matching_map')
                    },
                    
                    # AI ë©”íƒ€ë°ì´í„°
                    'ai_metadata': {
                        'device': self.device,
                        'input_size': self.warping_config['input_size'],
                        'warping_method': self.warping_config['warping_method'],
                        'num_algorithms_used': len(warping_results.get('warping_metadata', {}).get('algorithms_used', [])),
                        'models_successfully_loaded': len(self.ai_models),
                        'total_models_attempted': len(self.preferred_model_order)
                    }
                }
                
                self.logger.info(f"âœ… ìµœì¢… ê²°ê³¼ êµ¬ì„± ì™„ë£Œ - í’ˆì§ˆ: {final_result['quality_grade']}")
                
                return final_result
                
            except Exception as e:
                self.logger.error(f"âŒ ìµœì¢… ê²°ê³¼ êµ¬ì„± ì‹¤íŒ¨: {e}")
                return self._create_error_ai_result(str(e))
        
        # ==============================================
        # ğŸ”§ ì§€ì› ë©”ì„œë“œë“¤
        # ==============================================
        
        def _prepare_tensor_input(self, image_input: Any) -> torch.Tensor:
            """ì´ë¯¸ì§€ ì…ë ¥ì„ í…ì„œë¡œ ë³€í™˜"""
            try:
                if image_input is None:
                    size = self.warping_config['input_size']
                    return torch.randn(1, 3, size[1], size[0]).to(self.device)
                
                # ì´ë¯¸ í…ì„œì¸ ê²½ìš°
                if TORCH_AVAILABLE and torch.is_tensor(image_input):
                    tensor = image_input.to(self.device)
                    if len(tensor.shape) == 3:
                        tensor = tensor.unsqueeze(0)
                    return tensor
                
                # PIL Imageì¸ ê²½ìš°
                if PIL_AVAILABLE and isinstance(image_input, Image.Image):
                    array = np.array(image_input)
                    if len(array.shape) == 3:
                        array = np.transpose(array, (2, 0, 1))
                    tensor = torch.from_numpy(array).float().unsqueeze(0) / 255.0
                    return tensor.to(self.device)
                
                # NumPy ë°°ì—´ì¸ ê²½ìš°
                if NUMPY_AVAILABLE and isinstance(image_input, np.ndarray):
                    if len(image_input.shape) == 3:
                        array = np.transpose(image_input, (2, 0, 1))
                    else:
                        array = image_input
                    
                    if array.dtype != np.float32:
                        array = array.astype(np.float32)
                    
                    if array.max() > 1.0:
                        array = array / 255.0
                    
                    tensor = torch.from_numpy(array).unsqueeze(0)
                    return tensor.to(self.device)
                
                # ê¸°ë³¸ ë”ë¯¸ í…ì„œ
                size = self.warping_config['input_size']
                return torch.randn(1, 3, size[1], size[0]).to(self.device)
                
            except Exception as e:
                self.logger.warning(f"í…ì„œ ë³€í™˜ ì‹¤íŒ¨: {e}")
                size = self.warping_config['input_size']
                return torch.randn(1, 3, size[1], size[0]).to(self.device)
        
        def _extract_geometric_data(self, processed_input: Dict[str, Any]) -> Dict[str, Any]:
            """ì´ì „ Stepì—ì„œ ê¸°í•˜í•™ì  ë°ì´í„° ì¶”ì¶œ"""
            geometric_data = {}
            
            try:
                # Step 4 (Geometric Matching)ì—ì„œ ë°ì´í„° ì¶”ì¶œ
                step_04_data = processed_input.get('from_step_04', {})
                if step_04_data:
                    geometric_data['transformation_matrix'] = step_04_data.get('transformation_matrix')
                    geometric_data['warped_clothing'] = step_04_data.get('warped_clothing')
                    geometric_data['flow_field'] = step_04_data.get('flow_field')
                    geometric_data['matching_score'] = step_04_data.get('matching_score')
                    
                    self.logger.debug("âœ… Step 4 ê¸°í•˜í•™ì  ë°ì´í„° ì¶”ì¶œ ì™„ë£Œ")
                
                # Step 2 (Pose Estimation)ì—ì„œ í¬ì¦ˆ ë°ì´í„° ì¶”ì¶œ
                step_02_data = processed_input.get('from_step_02', {})
                if step_02_data:
                    geometric_data['keypoints'] = step_02_data.get('keypoints_18')
                    geometric_data['pose_skeleton'] = step_02_data.get('pose_skeleton')
                    
                    self.logger.debug("âœ… Step 2 í¬ì¦ˆ ë°ì´í„° ì¶”ì¶œ ì™„ë£Œ")
                
                # Step 3 (Cloth Segmentation)ì—ì„œ ë§ˆìŠ¤í¬ ë°ì´í„° ì¶”ì¶œ
                step_03_data = processed_input.get('from_step_03', {})
                if step_03_data:
                    geometric_data['cloth_mask'] = step_03_data.get('cloth_mask')
                    geometric_data['segmented_clothing'] = step_03_data.get('segmented_clothing')
                    
                    self.logger.debug("âœ… Step 3 ì„¸ê·¸ë©˜í…Œì´ì…˜ ë°ì´í„° ì¶”ì¶œ ì™„ë£Œ")
                
            except Exception as e:
                self.logger.warning(f"âš ï¸ ê¸°í•˜í•™ì  ë°ì´í„° ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            
            return geometric_data
        
        def _fallback_simple_warping(self, cloth_tensor: torch.Tensor, 
                                    person_tensor: torch.Tensor) -> Dict[str, Any]:
            """í´ë°± ê°„ë‹¨í•œ ì›Œí•‘"""
            try:
                self.logger.info("ğŸ”„ í´ë°± ê°„ë‹¨í•œ ì›Œí•‘ ì‹¤í–‰")
                
                # ê°„ë‹¨í•œ ì–´íŒŒì¸ ë³€í˜•
                batch_size, channels, height, width = cloth_tensor.shape
                
                # ì‘ì€ ë³€í˜• ë§¤íŠ¸ë¦­ìŠ¤
                theta = torch.tensor([
                    [1.02, 0.01, 0.01],
                    [0.01, 1.01, 0.01]
                ]).unsqueeze(0).repeat(batch_size, 1, 1).to(cloth_tensor.device)
                
                grid = F.affine_grid(theta, cloth_tensor.size(), align_corners=False)
                transformed = F.grid_sample(cloth_tensor, grid, align_corners=False)
                
                return {
                    'best_warped_cloth': transformed,
                    'confidence': torch.tensor([0.5]),
                    'method_used': 'fallback_affine',
                    'warping_metadata': {
                        'algorithms_used': ['simple_affine'],
                        'fusion_applied': False
                    }
                }
                
            except Exception as e:
                self.logger.error(f"âŒ í´ë°± ì›Œí•‘ ì‹¤íŒ¨: {e}")
                return {
                    'best_warped_cloth': cloth_tensor,
                    'confidence': torch.tensor([0.3]),
                    'method_used': 'identity',
                    'error': str(e)
                }
        
        def _tensor_to_float(self, value: Any) -> float:
            """í…ì„œë¥¼ floatë¡œ ì•ˆì „í•˜ê²Œ ë³€í™˜"""
            try:
                if torch.is_tensor(value):
                    return value.mean().item()
                elif isinstance(value, (int, float)):
                    return float(value)
                else:
                    return 0.7
            except:
                return 0.7
        
        def _calculate_quality_grade(self, score: float) -> str:
            """í’ˆì§ˆ ì ìˆ˜ë¥¼ ë“±ê¸‰ìœ¼ë¡œ ë³€í™˜"""
            if score >= 0.95:
                return "A+"
            elif score >= 0.9:
                return "A"
            elif score >= 0.8:
                return "B+"
            elif score >= 0.7:
                return "B"
            elif score >= 0.6:
                return "C+"
            elif score >= 0.5:
                return "C"
            else:
                return "D"
        
        def _update_performance_stats(self, processing_time: float, success: bool):
            """ì„±ëŠ¥ í†µê³„ ì—…ë°ì´íŠ¸"""
            try:
                self.performance_stats['total_processed'] += 1
                
                if success:
                    # ì„±ê³µë¥  ì—…ë°ì´íŠ¸
                    total = self.performance_stats['total_processed']
                    current_success = total - self.performance_stats['error_count']
                    self.performance_stats['success_rate'] = current_success / total
                    
                    # í‰ê·  ì²˜ë¦¬ ì‹œê°„ ì—…ë°ì´íŠ¸
                    current_avg = self.performance_stats['avg_processing_time']
                    self.performance_stats['avg_processing_time'] = (
                        (current_avg * (current_success - 1) + processing_time) / current_success
                    )
                else:
                    self.performance_stats['error_count'] += 1
                    total = self.performance_stats['total_processed']
                    current_success = total - self.performance_stats['error_count']
                    self.performance_stats['success_rate'] = current_success / total if total > 0 else 0.0
                
            except Exception as e:
                self.logger.debug(f"ì„±ëŠ¥ í†µê³„ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
        
        def _create_error_ai_result(self, error_message: str) -> Dict[str, Any]:
            """ì—ëŸ¬ AI ê²°ê³¼ ìƒì„±"""
            size = self.warping_config['input_size']
            dummy_tensor = torch.zeros(1, 3, size[1], size[0]).to(self.device)
            
            return {
                'warped_cloth': dummy_tensor,
                'warped_cloth_tensor': dummy_tensor,
                'ai_success': False,
                'enhanced_ai_inference': False,
                'error': error_message,
                'confidence': 0.0,
                'quality_score': 0.0,
                'overall_quality': 0.0,
                'quality_grade': 'F',
                'physics_applied': False,
                'ai_metadata': {
                    'device': self.device,
                    'error': error_message
                }
            }
        
        # ==============================================
        # ğŸ”§ BaseStepMixin ì¸í„°í˜ì´ìŠ¤ êµ¬í˜„
        # ==============================================
        
        def optimize_memory(self, aggressive: bool = False) -> Dict[str, Any]:
            """ë©”ëª¨ë¦¬ ìµœì í™” (BaseStepMixin ì¸í„°í˜ì´ìŠ¤)"""
            try:
                # ì£¼ì…ëœ MemoryManager ìš°ì„  ì‚¬ìš©
                if self.memory_manager and hasattr(self.memory_manager, 'optimize_memory'):
                    return self.memory_manager.optimize_memory(aggressive=aggressive)
                
                # ë‚´ì¥ ë©”ëª¨ë¦¬ ìµœì í™”
                return self._builtin_memory_optimize(aggressive)
                
            except Exception as e:
                self.logger.error(f"âŒ ë©”ëª¨ë¦¬ ìµœì í™” ì‹¤íŒ¨: {e}")
                return {"success": False, "error": str(e)}
        
        def _builtin_memory_optimize(self, aggressive: bool = False) -> Dict[str, Any]:
            """ë‚´ì¥ ë©”ëª¨ë¦¬ ìµœì í™” (M3 Max ìµœì í™”)"""
            try:
                # ìºì‹œ ì •ë¦¬
                cache_cleared = len(self.prediction_cache)
                if aggressive:
                    self.prediction_cache.clear()
                else:
                    # ì˜¤ë˜ëœ ìºì‹œë§Œ ì •ë¦¬
                    current_time = time.time()
                    keys_to_remove = []
                    for key, value in self.prediction_cache.items():
                        if isinstance(value, dict) and 'timestamp' in value:
                            if current_time - value['timestamp'] > 300:  # 5ë¶„ ì´ìƒ
                                keys_to_remove.append(key)
                    for key in keys_to_remove:
                        del self.prediction_cache[key]
                
                # PyTorch ë©”ëª¨ë¦¬ ì •ë¦¬ (M3 Max ìµœì í™”)
                safe_mps_empty_cache()
                
                return {
                    "success": True,
                    "cache_cleared": cache_cleared,
                    "aggressive": aggressive
                }
                
            except Exception as e:
                return {"success": False, "error": str(e)}
        
        def cleanup_resources(self):
            """ë¦¬ì†ŒìŠ¤ ì •ë¦¬ (BaseStepMixin ì¸í„°í˜ì´ìŠ¤)"""
            try:
                # ìºì‹œ ì •ë¦¬
                if hasattr(self, 'prediction_cache'):
                    self.prediction_cache.clear()
                
                # AI ëª¨ë¸ ì •ë¦¬
                if hasattr(self, 'ai_models'):
                    for model_name, model in self.ai_models.items():
                        try:
                            if hasattr(model, 'cpu'):
                                model.cpu()
                            del model
                        except:
                            pass
                    self.ai_models.clear()
                
                # ê°œë³„ ëª¨ë¸ë“¤ ì •ë¦¬
                for model_attr in ['tps_network', 'raft_network', 'vgg_matching', 'densenet_quality']:
                    if hasattr(self, model_attr):
                        model = getattr(self, model_attr)
                        if model is not None:
                            try:
                                if hasattr(model, 'cpu'):
                                    model.cpu()
                                del model
                                setattr(self, model_attr, None)
                            except:
                                pass
                
                # ë©”ëª¨ë¦¬ ì •ë¦¬ (M3 Max ìµœì í™”)
                safe_mps_empty_cache()
                
                self.logger.info("âœ… ClothWarpingStep v15.0 ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì™„ë£Œ")
                
            except Exception as e:
                self.logger.warning(f"ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì‹¤íŒ¨: {e}")
        
        def get_warping_capabilities(self) -> Dict[str, Any]:
            """ì›Œí•‘ ëŠ¥ë ¥ ì •ë³´ ë°˜í™˜"""
            return {
                'supported_methods': [method.value for method in WarpingMethod],
                'supported_fabrics': [fabric.value for fabric in FabricType],
                'loaded_algorithms': list(self.ai_models.keys()),
                'physics_simulation': self.warping_config['physics_enabled'],
                'multi_scale_fusion': self.warping_config['multi_scale_fusion'],
                'input_size': self.warping_config['input_size'],
                'quality_level': self.warping_config['quality_level']
            }
        
        def validate_warping_input(self, cloth_image: Any, person_image: Any) -> bool:
            """ì›Œí•‘ ì…ë ¥ ê²€ì¦"""
            try:
                if cloth_image is None or person_image is None:
                    return False
                
                # ê¸°ë³¸ í˜•íƒœ ê²€ì¦
                if hasattr(cloth_image, 'size') and hasattr(person_image, 'size'):
                    return True
                elif isinstance(cloth_image, (np.ndarray, torch.Tensor)) and isinstance(person_image, (np.ndarray, torch.Tensor)):
                    return True
                
                return False
                
            except Exception as e:
                self.logger.debug(f"ì…ë ¥ ê²€ì¦ ì‹¤íŒ¨: {e}")
                return False
        
        # ==============================================
        # ğŸ”§ ë…ë¦½ ëª¨ë“œ process ë©”ì„œë“œ (í´ë°±)
        # ==============================================
        
        async def process(self, **kwargs) -> Dict[str, Any]:
            """ë…ë¦½ ëª¨ë“œ process ë©”ì„œë“œ (BaseStepMixin ì—†ëŠ” ê²½ìš° í´ë°±)"""
            try:
                start_time = time.time()
                
                if 'image' not in kwargs or 'cloth_image' not in kwargs:
                    raise ValueError("í•„ìˆ˜ ì…ë ¥ ë°ì´í„° 'image'ì™€ 'cloth_image'ê°€ ì—†ìŠµë‹ˆë‹¤")
                
                # ì´ˆê¸°í™” í™•ì¸
                if not getattr(self, 'is_initialized', False):
                    await self.initialize()
                
                # BaseStepMixin process í˜¸ì¶œ ì‹œë„
                if hasattr(super(), 'process'):
                    return await super().process(**kwargs)
                
                # ë…ë¦½ ëª¨ë“œ ì²˜ë¦¬
                result = self._run_ai_inference(kwargs)
                
                processing_time = time.time() - start_time
                result['processing_time'] = processing_time
                
                return result
                
            except Exception as e:
                processing_time = time.time() - start_time if 'start_time' in locals() else 0.0
                return {
                    'success': False,
                    'error': str(e),
                    'step_name': self.step_name,
                    'processing_time': processing_time,
                    'independent_mode': True
                }

else:
    # BaseStepMixinì´ ì—†ëŠ” ê²½ìš° ë…ë¦½ì ì¸ í´ë˜ìŠ¤ ì •ì˜ (1ë²ˆ íŒŒì¼ íŒ¨í„´)
    class ClothWarpingStep:
        """
        ğŸ”¥ Step 05: Enhanced Cloth Warping v15.0 (ë…ë¦½ ëª¨ë“œ)
        
        BaseStepMixinì´ ì—†ëŠ” í™˜ê²½ì—ì„œì˜ ë…ë¦½ì  êµ¬í˜„
        """
        
        def __init__(self, **kwargs):
            """ë…ë¦½ì  ì´ˆê¸°í™”"""
            # ê¸°ë³¸ ì„¤ì •
            self.step_name = kwargs.get('step_name', 'ClothWarpingStep')
            self.step_id = kwargs.get('step_id', 5)
            self.step_number = 5
            self.step_description = "AI ì˜ë¥˜ ì›Œí•‘ ë° ë³€í˜• (ë…ë¦½ ëª¨ë“œ)"
            
            # ë””ë°”ì´ìŠ¤ ì„¤ì •
            self.device = self._detect_optimal_device()
            
            # ìƒíƒœ í”Œë˜ê·¸ë“¤
            self.is_initialized = False
            self.is_ready = False
            
            # ë¡œê±°
            self.logger = logging.getLogger(f"{__name__}.{self.__class__.__name__}")
            
            self.logger.info(f"âœ… {self.step_name} v15.0 ë…ë¦½ ëª¨ë“œ ì´ˆê¸°í™” ì™„ë£Œ")
        
        def _detect_optimal_device(self) -> str:
            """ìµœì  ë””ë°”ì´ìŠ¤ ê°ì§€"""
            try:
                if TORCH_AVAILABLE:
                    if MPS_AVAILABLE and IS_M3_MAX:
                        return "mps"
                    elif torch.cuda.is_available():
                        return "cuda"
                return "cpu"
            except:
                return "cpu"
        
        async def process(self, **kwargs) -> Dict[str, Any]:
            """ë…ë¦½ ëª¨ë“œ process ë©”ì„œë“œ"""
            try:
                start_time = time.time()
                
                # ì…ë ¥ ë°ì´í„° ê²€ì¦
                if 'image' not in kwargs or 'cloth_image' not in kwargs:
                    raise ValueError("í•„ìˆ˜ ì…ë ¥ ë°ì´í„° 'image'ì™€ 'cloth_image'ê°€ ì—†ìŠµë‹ˆë‹¤")
                
                # ê¸°ë³¸ ì‘ë‹µ (ì‹¤ì œ AI ëª¨ë¸ ì—†ì´ëŠ” ì œí•œì )
                processing_time = time.time() - start_time
                
                return {
                    'success': False,
                    'error': 'ë…ë¦½ ëª¨ë“œì—ì„œëŠ” ì‹¤ì œ AI ëª¨ë¸ì´ í•„ìš”í•©ë‹ˆë‹¤',
                    'step_name': self.step_name,
                    'step_id': self.step_id,
                    'processing_time': processing_time,
                    'independent_mode': True,
                    'requires_ai_models': True,
                    'required_files': [
                        'ai_models/step_05_cloth_warping/RealVisXL_V4.0.safetensors',
                        'ai_models/step_05_cloth_warping/ultra_models/vgg19_warping.pth',
                        'ai_models/step_05_cloth_warping/ultra_models/densenet121_ultra.pth'
                    ],
                    'github_integration_required': True
                }
                
            except Exception as e:
                processing_time = time.time() - start_time if 'start_time' in locals() else 0.0
                return {
                    'success': False,
                    'error': str(e),
                    'step_name': self.step_name,
                    'processing_time': processing_time,
                    'independent_mode': True
                }

# ==============================================
# ğŸ”¥ íŒ©í† ë¦¬ í•¨ìˆ˜ë“¤ (GitHub í‘œì¤€) (1ë²ˆ íŒŒì¼ íŒ¨í„´)
# ==============================================

async def create_enhanced_cloth_warping_step(
    device: str = "auto",
    quality_level: str = "ultra",
    warping_method: str = "hybrid_multi",
    **kwargs
) -> ClothWarpingStep:
    """Enhanced ClothWarpingStep ìƒì„± (GitHub í‘œì¤€)"""
    try:
        # ë””ë°”ì´ìŠ¤ ì²˜ë¦¬
        if device == "auto":
            if TORCH_AVAILABLE:
                if MPS_AVAILABLE and IS_M3_MAX:
                    device_param = "mps"
                elif torch.cuda.is_available():
                    device_param = "cuda"
                else:
                    device_param = "cpu"
            else:
                device_param = "cpu"
        else:
            device_param = device
        
        # config í†µí•©
        config = {
            'device': device_param,
            'quality_level': quality_level,
            'warping_method': warping_method,
            'use_realvis_xl': True,
            'use_vgg19_warping': True,
            'use_densenet': True,
            'use_diffusion_warping': quality_level == "ultra",
            'physics_enabled': True,
            'multi_scale_fusion': True
        }
        config.update(kwargs)
        
        # Step ìƒì„±
        step = ClothWarpingStep(**config)
        
        # ì´ˆê¸°í™” (í•„ìš”í•œ ê²½ìš°)
        if hasattr(step, 'initialize'):
            if asyncio.iscoroutinefunction(step.initialize):
                await step.initialize()
            else:
                step.initialize()
        
        return step
        
    except Exception as e:
        logger = logging.getLogger(__name__)
        logger.error(f"âŒ create_enhanced_cloth_warping_step v15.0 ì‹¤íŒ¨: {e}")
        raise RuntimeError(f"Enhanced ClothWarpingStep v15.0 ìƒì„± ì‹¤íŒ¨: {e}")

def create_enhanced_cloth_warping_step_sync(
    device: str = "auto",
    quality_level: str = "ultra",
    warping_method: str = "hybrid_multi",
    **kwargs
) -> ClothWarpingStep:
    """ë™ê¸°ì‹ Enhanced ClothWarpingStep ìƒì„±"""
    try:
        try:
            loop = asyncio.get_event_loop()
        except RuntimeError:
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
        
        return loop.run_until_complete(
            create_enhanced_cloth_warping_step(device, quality_level, warping_method, **kwargs)
        )
    except Exception as e:
        logger = logging.getLogger(__name__)
        logger.error(f"âŒ create_enhanced_cloth_warping_step_sync v15.0 ì‹¤íŒ¨: {e}")
        raise RuntimeError(f"ë™ê¸°ì‹ Enhanced ClothWarpingStep v15.0 ìƒì„± ì‹¤íŒ¨: {e}")

# ==============================================
# ğŸ”¥ í…ŒìŠ¤íŠ¸ í•¨ìˆ˜ë“¤ (1ë²ˆ íŒŒì¼ íŒ¨í„´)
# ==============================================

async def test_enhanced_cloth_warping():
    """Enhanced ClothWarpingStep í…ŒìŠ¤íŠ¸"""
    print("ğŸ§ª Enhanced ClothWarpingStep v15.0 BaseStepMixin í˜¸í™˜ì„± í…ŒìŠ¤íŠ¸ ì‹œì‘")
    
    try:
        # Step ìƒì„±
        step = ClothWarpingStep(
            device="auto",
            quality_level="ultra",
            warping_method="hybrid_multi",
            physics_enabled=True,
            multi_scale_fusion=True
        )
        
        # ìƒíƒœ í™•ì¸
        status = step.get_status() if hasattr(step, 'get_status') else {'initialized': getattr(step, 'is_initialized', True)}
        print(f"âœ… Step ìƒíƒœ: {status}")
        
        # BaseStepMixin í˜¸í™˜ì„± í™•ì¸
        if hasattr(step, 'set_model_loader'):
            print("âœ… ModelLoader ì˜ì¡´ì„± ì£¼ì… ì¸í„°í˜ì´ìŠ¤ í™•ì¸ë¨")
        
        if hasattr(step, 'set_memory_manager'):
            print("âœ… MemoryManager ì˜ì¡´ì„± ì£¼ì… ì¸í„°í˜ì´ìŠ¤ í™•ì¸ë¨")
        
        if hasattr(step, 'set_data_converter'):
            print("âœ… DataConverter ì˜ì¡´ì„± ì£¼ì… ì¸í„°í˜ì´ìŠ¤ í™•ì¸ë¨")
        
        # BaseStepMixin í˜¸í™˜ì„± í™•ì¸
        if hasattr(step, '_run_ai_inference'):
            # _run_ai_inferenceê°€ ë™ê¸° ë©”ì„œë“œì¸ì§€ í™•ì¸
            import inspect
            is_async = inspect.iscoroutinefunction(step._run_ai_inference)
            print(f"âœ… _run_ai_inference ë™ê¸° ë©”ì„œë“œ: {not is_async}")
            
            dummy_input = {
                'image': Image.new('RGB', (512, 512), (128, 128, 128)),
                'cloth_image': Image.new('RGB', (512, 512), (64, 64, 64)),
                'fabric_type': 'cotton',
                'warping_method': 'hybrid_multi'
            }
            
            result = step._run_ai_inference(dummy_input)
            
            if result.get('ai_success', False):
                print("âœ… BaseStepMixin í˜¸í™˜ AI ì¶”ë¡  í…ŒìŠ¤íŠ¸ ì„±ê³µ!")
                print(f"   - AI ì‹ ë¢°ë„: {result.get('confidence', 0):.3f}")
                print(f"   - í’ˆì§ˆ ë“±ê¸‰: {result.get('quality_grade', 'N/A')}")
                print(f"   - ì‚¬ìš©ëœ ì•Œê³ ë¦¬ì¦˜: {result.get('algorithms_used', [])}")
                print(f"   - ë¬¼ë¦¬ ì‹œë®¬ë ˆì´ì…˜: {result.get('physics_applied', False)}")
                print(f"   - ìœµí•© ì ìš©: {result.get('fusion_applied', False)}")
                return True
            else:
                print(f"âŒ ì²˜ë¦¬ ì‹¤íŒ¨: {result.get('error', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}")
                if 'required_files' in result:
                    print("ğŸ“ í•„ìš”í•œ íŒŒì¼ë“¤:")
                    for file in result['required_files']:
                        print(f"   - {file}")
                return False
        else:
            print("âœ… ë…ë¦½ ëª¨ë“œ Enhanced ClothWarpingStep ìƒì„± ì„±ê³µ")
            return True
            
    except Exception as e:
        print(f"âŒ Enhanced ClothWarpingStep í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        return False

# ==============================================
# ğŸ”¥ ëª¨ë“ˆ ìµìŠ¤í¬íŠ¸ (GitHub í‘œì¤€) (1ë²ˆ íŒŒì¼ íŒ¨í„´)
# ==============================================

__all__ = [
    # ë©”ì¸ í´ë˜ìŠ¤ë“¤
    'ClothWarpingStep',
    'AdvancedTPSWarpingNetwork',
    'RAFTFlowWarpingNetwork',
    'VGGClothBodyMatchingNetwork',
    'DenseNetQualityAssessment',
    'PhysicsBasedFabricSimulation',
    
    # ë°ì´í„° í´ë˜ìŠ¤ë“¤
    'WarpingMethod',
    'FabricType',
    'ClothingChangeComplexity',
    
    # ìƒì„± í•¨ìˆ˜ë“¤
    'create_enhanced_cloth_warping_step',
    'create_enhanced_cloth_warping_step_sync',
    
    # ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
    'safe_mps_empty_cache',
    
    # ìƒìˆ˜ë“¤
    'ENHANCED_CLOTH_WARPING_MODELS',
    
    # í…ŒìŠ¤íŠ¸ í•¨ìˆ˜ë“¤
    'test_enhanced_cloth_warping'
]

# ==============================================
# ğŸ”¥ ëª¨ë“ˆ ì´ˆê¸°í™” ë¡œê¹… (GitHub í‘œì¤€) (1ë²ˆ íŒŒì¼ íŒ¨í„´)
# ==============================================

logger = logging.getLogger(__name__)
logger.info("ğŸ”¥ Enhanced ClothWarpingStep v15.0 BaseStepMixin v19.1 ì™„ì „ í˜¸í™˜ ë¡œë“œ ì™„ë£Œ")
logger.info("=" * 100)
logger.info("âœ… BaseStepMixin v19.1 ì™„ì „ ìƒì† ë° í˜¸í™˜:")
logger.info("   âœ… class ClothWarpingStep(BaseStepMixin) - ì§ì ‘ ìƒì†")
logger.info("   âœ… def _run_ai_inference(self, processed_input) - ë™ê¸° ë©”ì„œë“œ ì™„ì „ êµ¬í˜„")
logger.info("   âœ… ì˜ì¡´ì„± ì£¼ì… íŒ¨í„´ êµ¬í˜„ (ModelLoader, MemoryManager)")
logger.info("   âœ… StepFactory â†’ initialize() â†’ AI ì¶”ë¡  í”Œë¡œìš°")
logger.info("   âœ… TYPE_CHECKING ìˆœí™˜ì°¸ì¡° ì™„ì „ ë°©ì§€")
logger.info("âœ… ì‹¤ì œ AI ëª¨ë¸ íŒŒì¼ ì™„ì „ í™œìš©:")
for model_name, model_info in ENHANCED_CLOTH_WARPING_MODELS.items():
    size_info = f"{model_info['size_mb']:.1f}MB" if model_info['size_mb'] < 1000 else f"{model_info['size_mb']/1000:.1f}GB"
    logger.info(f"   âœ… {model_info['filename']} ({size_info})")
logger.info("âœ… ê³ ê¸‰ AI ì•Œê³ ë¦¬ì¦˜ ì™„ì „ êµ¬í˜„:")
logger.info("   ğŸ§  TPS (Thin Plate Spline) Warping Network")
logger.info("   ğŸŒŠ RAFT Optical Flow Estimation")
logger.info("   ğŸ¯ VGG ê¸°ë°˜ ì˜ë¥˜-ì¸ì²´ ë§¤ì¹­")
logger.info("   âš¡ DenseNet í’ˆì§ˆ í‰ê°€")
logger.info("   ğŸ§ª ë¬¼ë¦¬ ê¸°ë°˜ ì›ë‹¨ ì‹œë®¬ë ˆì´ì…˜")
logger.info("âœ… ì˜· ê°ˆì•„ì…íˆê¸° íŠ¹í™”:")
logger.info("   âœ… ì˜ë¥˜ ë³€í˜• ì •ë°€ë„ ê·¹ëŒ€í™”")
logger.info("   âœ… ì¸ì²´ í• ì ì‘ ì•Œê³ ë¦¬ì¦˜")
logger.info("   âœ… ì›ë‹¨ ë¬¼ë¦¬ ì‹œë®¬ë ˆì´ì…˜ (Cotton, Silk, Denim, Wool, Spandex)")
logger.info("   âœ… ë©€í‹° ì•Œê³ ë¦¬ì¦˜ ìœµí•©ìœ¼ë¡œ ìµœì  ê²°ê³¼ ì„ íƒ")
logger.info("   âœ… í’ˆì§ˆ í‰ê°€ ë° ì •ì œ")
if IS_M3_MAX:
    logger.info(f"ğŸ¯ M3 Max í™˜ê²½ ê°ì§€ - 128GB ë©”ëª¨ë¦¬ ìµœì í™” í™œì„±í™”")
if CONDA_INFO['is_mycloset_env']:
    logger.info(f"ğŸ”§ conda í™˜ê²½ ìµœì í™” í™œì„±í™”: {CONDA_INFO['conda_env']}")
logger.info(f"ğŸ’¾ ì‚¬ìš© ê°€ëŠ¥í•œ ë””ë°”ì´ìŠ¤: {['cpu', 'mps' if MPS_AVAILABLE else 'cpu-only', 'cuda' if torch.cuda.is_available() else 'no-cuda']}")
logger.info("=" * 100)
logger.info("ğŸ¯ í•µì‹¬ ì²˜ë¦¬ íë¦„ (BaseStepMixin v19.1 í‘œì¤€):")
logger.info("   1. StepFactory.create_step(StepType.CLOTH_WARPING) â†’ ClothWarpingStep ìƒì„±")
logger.info("   2. ModelLoader ì˜ì¡´ì„± ì£¼ì… â†’ set_model_loader()")
logger.info("   3. MemoryManager ì˜ì¡´ì„± ì£¼ì… â†’ set_memory_manager()")
logger.info("   4. ì´ˆê¸°í™” ì‹¤í–‰ â†’ initialize() â†’ ì‹¤ì œ AI ëª¨ë¸ ë¡œë”©")
logger.info("   5. AI ì¶”ë¡  ì‹¤í–‰ â†’ _run_ai_inference() â†’ ì‹¤ì œ ì˜ë¥˜ ì›Œí•‘ ìˆ˜í–‰")
logger.info("   6. ë©€í‹° ì•Œê³ ë¦¬ì¦˜ ìœµí•© â†’ ìµœì  ê²°ê³¼ ì„ íƒ â†’ ë‹¤ìŒ Stepìœ¼ë¡œ ì „ë‹¬")
logger.info("=" * 100)

# ==============================================
# ğŸ”¥ ë©”ì¸ ì‹¤í–‰ë¶€ (GitHub í‘œì¤€) (1ë²ˆ íŒŒì¼ íŒ¨í„´)
# ==============================================

if __name__ == "__main__":
    print("=" * 100)
    print("ğŸ¯ MyCloset AI Step 05 - Enhanced Cloth Warping v15.0 BaseStepMixin v19.1 ì™„ì „ í˜¸í™˜")
    print("=" * 100)
    print("âœ… BaseStepMixin v19.1 ì™„ì „ ìƒì† ë° í˜¸í™˜:")
    print("   âœ… class ClothWarpingStep(BaseStepMixin) - ì§ì ‘ ìƒì†")
    print("   âœ… def _run_ai_inference(self, processed_input) - ë™ê¸° ë©”ì„œë“œ ì™„ì „ êµ¬í˜„")
    print("   âœ… ì˜ì¡´ì„± ì£¼ì… íŒ¨í„´ êµ¬í˜„ (ModelLoader, MemoryManager)")
    print("   âœ… StepFactory â†’ initialize() â†’ AI ì¶”ë¡  í”Œë¡œìš°")
    print("   âœ… TYPE_CHECKING ìˆœí™˜ì°¸ì¡° ì™„ì „ ë°©ì§€")
    print("   âœ… M3 Max 128GB + conda í™˜ê²½ ìµœì í™”")
    print("=" * 100)
    print("ğŸ”¥ ì‹¤ì œ AI ëª¨ë¸ íŒŒì¼ ì™„ì „ í™œìš©:")
    for model_name, model_info in ENHANCED_CLOTH_WARPING_MODELS.items():
        size_info = f"{model_info['size_mb']:.1f}MB" if model_info['size_mb'] < 1000 else f"{model_info['size_mb']/1000:.1f}GB"
        print(f"   âœ… {model_info['filename']} ({size_info})")
    print("=" * 100)
    print("ğŸ§  ê³ ê¸‰ AI ì•Œê³ ë¦¬ì¦˜ ì™„ì „ êµ¬í˜„:")
    print("   1. TPS (Thin Plate Spline) Warping Network - ì •ë°€í•œ ì˜ë¥˜ ë³€í˜•")
    print("   2. RAFT Optical Flow Estimation - ì •ë°€í•œ Flow ê¸°ë°˜ ì›Œí•‘")
    print("   3. VGG ê¸°ë°˜ ì˜ë¥˜-ì¸ì²´ ë§¤ì¹­ - ì˜ë¥˜ì™€ ì¸ì²´ì˜ ì •í™•í•œ ë§¤ì¹­")
    print("   4. DenseNet í’ˆì§ˆ í‰ê°€ - ì›Œí•‘ ê²°ê³¼ í’ˆì§ˆ í‰ê°€")
    print("   5. ë¬¼ë¦¬ ê¸°ë°˜ ì›ë‹¨ ì‹œë®¬ë ˆì´ì…˜ - ì‹¤ì œ ì›ë‹¨ ë¬¼ë¦¬ íŠ¹ì„± ë°˜ì˜")
    print("   6. ë©€í‹° ì•Œê³ ë¦¬ì¦˜ ìœµí•© - ìµœì  ê²°ê³¼ ì„ íƒ")
    print("=" * 100)
    print("ğŸ¯ ì˜· ê°ˆì•„ì…íˆê¸° íŠ¹í™”:")
    print("   âœ… ì˜ë¥˜ ë³€í˜• ì •ë°€ë„ ê·¹ëŒ€í™”")
    print("   âœ… ì¸ì²´ í• ì ì‘ ì•Œê³ ë¦¬ì¦˜")
    print("   âœ… ì›ë‹¨ ë¬¼ë¦¬ ì‹œë®¬ë ˆì´ì…˜ (Cotton, Silk, Denim, Wool, Spandex)")
    print("   âœ… ë©€í‹° ì•Œê³ ë¦¬ì¦˜ ìœµí•©ìœ¼ë¡œ ìµœì  ê²°ê³¼ ì„ íƒ")
    print("   âœ… í’ˆì§ˆ í‰ê°€ ë° ì •ì œ")
    print("=" * 100)
    print("ğŸ¯ í•µì‹¬ ì²˜ë¦¬ íë¦„ (BaseStepMixin v19.1 í‘œì¤€):")
    print("   1. StepFactory.create_step(StepType.CLOTH_WARPING)")
    print("      â†’ ClothWarpingStep ì¸ìŠ¤í„´ìŠ¤ ìƒì„±")
    print("   2. ModelLoader ì˜ì¡´ì„± ì£¼ì… â†’ set_model_loader()")
    print("      â†’ ì‹¤ì œ AI ëª¨ë¸ ë¡œë”© ì‹œìŠ¤í…œ ì—°ê²°")
    print("   3. MemoryManager ì˜ì¡´ì„± ì£¼ì… â†’ set_memory_manager()")
    print("      â†’ M3 Max ë©”ëª¨ë¦¬ ìµœì í™” ì‹œìŠ¤í…œ ì—°ê²°")
    print("   4. ì´ˆê¸°í™” ì‹¤í–‰ â†’ initialize()")
    print("      â†’ ì‹¤ì œ AI ëª¨ë¸ íŒŒì¼ ë¡œë”© ë° ì¤€ë¹„")
    print("   5. AI ì¶”ë¡  ì‹¤í–‰ â†’ _run_ai_inference()")
    print("      â†’ ì‹¤ì œ ì˜ë¥˜ ì›Œí•‘ ìˆ˜í–‰ (ë©€í‹° ì•Œê³ ë¦¬ì¦˜)")
    print("   6. ë©€í‹° ì•Œê³ ë¦¬ì¦˜ ìœµí•© â†’ ìµœì  ê²°ê³¼ ì„ íƒ")
    print("      â†’ í’ˆì§ˆ í‰ê°€ ë° ì •ì œ")
    print("   7. í‘œì¤€ ì¶œë ¥ ë°˜í™˜ â†’ ë‹¤ìŒ Step(ê°€ìƒ í”¼íŒ…)ìœ¼ë¡œ ë°ì´í„° ì „ë‹¬")
    print("=" * 100)
    
    # BaseStepMixin í˜¸í™˜ì„± í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    try:
        asyncio.run(test_enhanced_cloth_warping())
    except Exception as e:
        print(f"âŒ BaseStepMixin í˜¸í™˜ì„± í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
    
    print("\n" + "=" * 100)
    print("ğŸ‰ Enhanced ClothWarpingStep v15.0 BaseStepMixin v19.1 ì™„ì „ í˜¸í™˜ ì™„ë£Œ!")
    print("âœ… BaseStepMixin v19.1 ì™„ì „ ìƒì† - class ClothWarpingStep(BaseStepMixin)")
    print("âœ… def _run_ai_inference() ë™ê¸° ë©”ì„œë“œ ì™„ì „ êµ¬í˜„")
    print("âœ… ì˜ì¡´ì„± ì£¼ì… íŒ¨í„´ êµ¬í˜„ (ModelLoader, MemoryManager)")
    print("âœ… ì‹¤ì œ AI ëª¨ë¸ íŒŒì¼ 8.6GB 100% í™œìš©")
    print("âœ… ê³ ê¸‰ ì˜ë¥˜ ì›Œí•‘ ì•Œê³ ë¦¬ì¦˜ ì™„ì „ êµ¬í˜„")
    print("âœ… 7ê°œ AI ì•Œê³ ë¦¬ì¦˜ ë©€í‹° ìœµí•©")
    print("âœ… ë¬¼ë¦¬ ê¸°ë°˜ ì›ë‹¨ ì‹œë®¬ë ˆì´ì…˜")
    print("âœ… M3 Max + conda í™˜ê²½ ì™„ì „ ìµœì í™”")
    print("âœ… TYPE_CHECKING ìˆœí™˜ì°¸ì¡° ì™„ì „ ë°©ì§€")
    print("âœ… í”„ë¡œë•ì…˜ ë ˆë²¨ ì•ˆì •ì„± ë³´ì¥")
    print("=" * 100)