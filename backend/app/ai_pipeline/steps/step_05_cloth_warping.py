# app/ai_pipeline/steps/step_05_cloth_warping.py
"""
ğŸ¯ Step 5: ì˜ë¥˜ ì›Œí•‘ (Cloth Warping) - ì™„ì „ AI ëª¨ë¸ í†µí•© v10.0
===========================================================================

âœ… BaseStepMixin v16.0 ì™„ì „ í˜¸í™˜
âœ… OpenCV ì™„ì „ ëŒ€ì²´ â†’ AI ëª¨ë¸ ì‚¬ìš© (SAM, Real-ESRGAN, CLIP ë“±)
âœ… ì‹¤ì œ AI ëª¨ë¸ í´ë˜ìŠ¤ êµ¬í˜„ (RealClothWarpingModel, RealTOMModel)
âœ… UnifiedDependencyManager ì™„ì „ ì—°ë™
âœ… TYPE_CHECKING íŒ¨í„´ìœ¼ë¡œ ìˆœí™˜ì°¸ì¡° ë°©ì§€
âœ… M3 Max 128GB ë©”ëª¨ë¦¬ ìµœì í™”
âœ… conda í™˜ê²½ ìš°ì„  ì§€ì›
âœ… ì™„ì „í•œ ê¸°ëŠ¥ ì‘ë™ ë³´ì¥
âœ… Python ë¬¸ë²• ë° ë“¤ì—¬ì“°ê¸° ì™„ì „ ì •ë¦¬

Author: MyCloset AI Team
Date: 2025-07-25
Version: 10.0 (Complete AI Model Integration)
"""

import asyncio
import logging
import os
import sys
import time
import traceback
import hashlib
import json
import gc
import math
import weakref
import threading
import platform
import subprocess
from pathlib import Path
from typing import Dict, Any, Optional, Tuple, Union, List, TYPE_CHECKING, Callable
from dataclasses import dataclass, field
from enum import Enum, IntEnum
from concurrent.futures import ThreadPoolExecutor
from functools import wraps
import base64
from io import BytesIO

# ==============================================
# ğŸ”§ TYPE_CHECKINGìœ¼ë¡œ ìˆœí™˜ì°¸ì¡° ë°©ì§€
# ==============================================
if TYPE_CHECKING:
    from app.ai_pipeline.utils.model_loader import ModelLoader
    from app.ai_pipeline.steps.base_step_mixin import BaseStepMixin, ClothWarpingMixin
    from app.ai_pipeline.factories.step_factory import StepFactory

# ==============================================
# ğŸ”§ conda í™˜ê²½ ì²´í¬ ë° ìµœì í™”
# ==============================================
CONDA_INFO = {
    'conda_env': os.environ.get('CONDA_DEFAULT_ENV', 'none'),
    'conda_prefix': os.environ.get('CONDA_PREFIX', 'none'),
    'python_path': os.path.dirname(os.__file__)
}

def detect_m3_max() -> bool:
    """M3 Max ê°ì§€"""
    try:
        if platform.system() == 'Darwin':
            result = subprocess.run(
                ['sysctl', '-n', 'machdep.cpu.brand_string'], 
                capture_output=True, text=True, timeout=5
            )
            return 'M3' in result.stdout
    except:
        pass
    return False

IS_M3_MAX = detect_m3_max()

# ==============================================
# ğŸ”§ Import ê²€ì¦ ë° í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬
# ==============================================

# PyTorch (í•„ìˆ˜)
TORCH_AVAILABLE = False
MPS_AVAILABLE = False
try:
    import torch
    import torch.nn as nn
    import torch.nn.functional as F
    import torchvision.transforms as T
    TORCH_AVAILABLE = True
    
    # MPS ì§€ì› í™•ì¸
    MPS_AVAILABLE = hasattr(torch.backends, 'mps') and torch.backends.mps.is_available()
    
    logging.getLogger(__name__).info(f"âœ… PyTorch {torch.__version__} ë¡œë“œ ì„±ê³µ (MPS: {MPS_AVAILABLE})")
    
except ImportError as e:
    logging.getLogger(__name__).error(f"âŒ PyTorch import í•„ìˆ˜: {e}")
    raise ImportError("PyTorchê°€ í•„ìš”í•©ë‹ˆë‹¤")

# NumPy (í•„ìˆ˜)
NUMPY_AVAILABLE = False
try:
    import numpy as np
    NUMPY_AVAILABLE = True
    logging.getLogger(__name__).info(f"âœ… NumPy {np.__version__} ë¡œë“œ ì„±ê³µ")
except ImportError as e:
    logging.getLogger(__name__).error(f"âŒ NumPy import í•„ìˆ˜: {e}")
    raise ImportError("NumPyê°€ í•„ìš”í•©ë‹ˆë‹¤")

# PIL (í•„ìˆ˜)
PIL_AVAILABLE = False
try:
    from PIL import Image, ImageEnhance, ImageFilter, ImageOps
    PIL_AVAILABLE = True
    logging.getLogger(__name__).info("âœ… PIL ë¡œë“œ ì„±ê³µ")
except ImportError as e:
    logging.getLogger(__name__).error(f"âŒ PIL import í•„ìˆ˜: {e}")
    raise ImportError("PILì´ í•„ìš”í•©ë‹ˆë‹¤")

# Transformers (AI ëª¨ë¸ìš©)
TRANSFORMERS_AVAILABLE = False
try:
    from transformers import (
        CLIPProcessor, CLIPModel,
        AutoImageProcessor, AutoModel,
        pipeline
    )
    TRANSFORMERS_AVAILABLE = True
    logging.getLogger(__name__).info("âœ… Transformers ë¡œë“œ ì„±ê³µ")
except ImportError:
    TRANSFORMERS_AVAILABLE = False
    logging.getLogger(__name__).warning("âš ï¸ Transformers import ì‹¤íŒ¨ - AI ëª¨ë¸ ê¸°ëŠ¥ ì œí•œë¨")

# scikit-image (ì„ íƒì )
SKIMAGE_AVAILABLE = False
try:
    import skimage
    from skimage import filters, morphology, measure, transform
    SKIMAGE_AVAILABLE = True
except ImportError:
    SKIMAGE_AVAILABLE = False

# BaseStepMixin ë™ì  ë¡œë”© (ìˆœí™˜ì°¸ì¡° ë°©ì§€)
BASE_STEP_MIXIN_AVAILABLE = False
try:
    # ë™ì  importë¡œ ìˆœí™˜ì°¸ì¡° ë°©ì§€
    import importlib
    base_module = importlib.import_module('app.ai_pipeline.steps.base_step_mixin')
    ClothWarpingMixin = getattr(base_module, 'ClothWarpingMixin', None)
    
    if ClothWarpingMixin is None:
        # BaseStepMixinì„ ì§ì ‘ ì‚¬ìš©
        BaseStepMixin = getattr(base_module, 'BaseStepMixin')
        ClothWarpingMixin = BaseStepMixin
    
    BASE_STEP_MIXIN_AVAILABLE = True
    logging.getLogger(__name__).info("âœ… BaseStepMixin/ClothWarpingMixin ë™ì  ë¡œë“œ ì„±ê³µ")
    
except ImportError as e:
    logging.getLogger(__name__).error(f"âŒ BaseStepMixin import í•„ìˆ˜: {e}")
    
    # í´ë°± BaseStepMixin
    class ClothWarpingMixin:
        def __init__(self, **kwargs):
            self.step_name = kwargs.get('step_name', 'ClothWarpingStep')
            self.step_id = kwargs.get('step_id', 5)
            self.device = kwargs.get('device', 'cpu')
            self.logger = logging.getLogger(f"pipeline.{self.step_name}")
            
            # v16.0 í˜¸í™˜ ì†ì„±ë“¤
            self.model_loader = None
            self.memory_manager = None
            self.data_converter = None
            self.di_container = None
            
            # ìƒíƒœ í”Œë˜ê·¸ë“¤
            self.is_initialized = False
            self.is_ready = False
            self.has_model = False
            self.model_loaded = False
            
            # UnifiedDependencyManager ì‹œë®¬ë ˆì´ì…˜
            self.dependency_manager = type('MockDependencyManager', (), {
                'auto_inject_dependencies': lambda: True,
                'get_dependency_status': lambda: {}
            })()
            
            # ì„±ëŠ¥ ë©”íŠ¸ë¦­
            self.performance_metrics = {
                'process_count': 0,
                'total_process_time': 0.0,
                'error_count': 0,
                'success_count': 0
            }
        
        def set_model_loader(self, model_loader):
            """ModelLoader ì˜ì¡´ì„± ì£¼ì…"""
            self.model_loader = model_loader
            self.has_model = True
            self.logger.info("âœ… ModelLoader ì£¼ì… ì™„ë£Œ")
            return True
        
        def set_memory_manager(self, memory_manager):
            """MemoryManager ì˜ì¡´ì„± ì£¼ì…"""
            self.memory_manager = memory_manager
            self.logger.info("âœ… MemoryManager ì£¼ì… ì™„ë£Œ")
            return True
        
        def set_data_converter(self, data_converter):
            """DataConverter ì˜ì¡´ì„± ì£¼ì…"""
            self.data_converter = data_converter
            self.logger.info("âœ… DataConverter ì£¼ì… ì™„ë£Œ")
            return True
        
        def set_di_container(self, di_container):
            """DI Container ì˜ì¡´ì„± ì£¼ì…"""
            self.di_container = di_container
            self.logger.info("âœ… DI Container ì£¼ì… ì™„ë£Œ")
            return True
        
        def initialize(self):
            """ê¸°ë³¸ ì´ˆê¸°í™”"""
            self.is_initialized = True
            self.is_ready = True
            return True
        
        async def get_model_async(self, model_name: str) -> Optional[Any]:
            """ë¹„ë™ê¸° ëª¨ë¸ ë¡œë“œ"""
            if self.model_loader and hasattr(self.model_loader, 'load_model_async'):
                return await self.model_loader.load_model_async(model_name)
            elif self.model_loader and hasattr(self.model_loader, 'load_model'):
                return self.model_loader.load_model(model_name)
            return None
        
        def get_status(self):
            """ìƒíƒœ ë°˜í™˜"""
            return {
                'step_name': self.step_name,
                'is_initialized': self.is_initialized,
                'device': self.device,
                'has_model': self.has_model
            }
        
        def cleanup_models(self):
            """ëª¨ë¸ ì •ë¦¬"""
            gc.collect()

# ModelLoader ë™ì  import (ìˆœí™˜ì°¸ì¡° ë°©ì§€)
MODEL_LOADER_AVAILABLE = False
try:
    loader_module = importlib.import_module('app.ai_pipeline.utils.model_loader')
    get_global_model_loader = getattr(loader_module, 'get_global_model_loader', None)
    if get_global_model_loader:
        MODEL_LOADER_AVAILABLE = True
        logging.getLogger(__name__).info("âœ… ModelLoader ë™ì  import ì„±ê³µ")
    else:
        logging.getLogger(__name__).warning("âš ï¸ get_global_model_loader í•¨ìˆ˜ ì—†ìŒ")
except ImportError as e:
    logging.getLogger(__name__).warning(f"âš ï¸ ModelLoader import ì‹¤íŒ¨: {e}")

# ==============================================
# ğŸ¯ ì„¤ì • í´ë˜ìŠ¤ë“¤ ë° Enum
# ==============================================

class WarpingMethod(Enum):
    """ì›Œí•‘ ë°©ë²• ì—´ê±°í˜•"""
    AI_MODEL = "ai_model"
    TPS_CLASSICAL = "tps_classical"
    HYBRID = "hybrid"

class FabricType(Enum):
    """ì›ë‹¨ íƒ€ì… ì—´ê±°í˜•"""
    COTTON = "cotton"
    SILK = "silk"
    DENIM = "denim"
    WOOL = "wool"
    POLYESTER = "polyester"
    LINEN = "linen"
    LEATHER = "leather"

class WarpingQuality(Enum):
    """ì›Œí•‘ í’ˆì§ˆ ë ˆë²¨"""
    LOW = "low"
    MEDIUM = "medium"
    HIGH = "high"
    ULTRA = "ultra"

class ProcessingStage(Enum):
    """ì²˜ë¦¬ ë‹¨ê³„ ì—´ê±°í˜•"""
    PREPROCESSING = "preprocessing"
    AI_INFERENCE = "ai_inference"
    PHYSICS_ENHANCEMENT = "physics_enhancement"
    POSTPROCESSING = "postprocessing"
    QUALITY_ANALYSIS = "quality_analysis"
    VISUALIZATION = "visualization"

@dataclass
class PhysicsProperties:
    """ë¬¼ë¦¬ ì‹œë®¬ë ˆì´ì…˜ ì†ì„±"""
    fabric_type: FabricType = FabricType.COTTON
    thickness: float = 0.001  # meters
    density: float = 1500.0  # kg/mÂ³
    elastic_modulus: float = 1000.0  # Pa
    poisson_ratio: float = 0.3
    friction_coefficient: float = 0.4
    air_resistance: float = 0.01

@dataclass
class ClothWarpingConfig:
    """ì˜ë¥˜ ì›Œí•‘ ì„¤ì •"""
    warping_method: WarpingMethod = WarpingMethod.AI_MODEL
    input_size: Tuple[int, int] = (512, 384)
    num_control_points: int = 25
    ai_model_enabled: bool = True
    physics_enabled: bool = True
    visualization_enabled: bool = True
    cache_enabled: bool = True
    cache_size: int = 50
    quality_level: str = "high"
    precision: str = "fp16"
    memory_fraction: float = 0.7
    batch_size: int = 1
    strict_mode: bool = False
    
    # v16.0 DI ì„¤ì •
    dependency_injection_enabled: bool = True
    auto_initialization: bool = True
    error_recovery_enabled: bool = True

# ì˜ë¥˜ íƒ€ì…ë³„ ì›Œí•‘ ê°€ì¤‘ì¹˜
CLOTHING_WARPING_WEIGHTS = {
    'shirt': {'deformation': 0.4, 'physics': 0.3, 'texture': 0.3},
    'dress': {'deformation': 0.5, 'physics': 0.3, 'texture': 0.2},
    'pants': {'physics': 0.5, 'deformation': 0.3, 'texture': 0.2},
    'jacket': {'physics': 0.4, 'deformation': 0.4, 'texture': 0.2},
    'skirt': {'deformation': 0.4, 'physics': 0.4, 'texture': 0.2},
    'top': {'deformation': 0.5, 'texture': 0.3, 'physics': 0.2},
    'default': {'deformation': 0.4, 'physics': 0.3, 'texture': 0.3}
}

# ==============================================
# ğŸ¤– ì‹¤ì œ AI ëª¨ë¸ í´ë˜ìŠ¤ë“¤ (OpenCV ì™„ì „ ëŒ€ì²´)
# ==============================================

class RealClothWarpingModel(nn.Module):
    """ì‹¤ì œ ì˜ë¥˜ ì›Œí•‘ AI ëª¨ë¸ (TOM/HRVITON ê¸°ë°˜)"""
    
    def __init__(self, num_control_points: int = 25, input_channels: int = 6):
        super().__init__()
        self.num_control_points = num_control_points
        
        # Feature Extractor (ResNet ê¸°ë°˜)
        self.feature_extractor = nn.Sequential(
            nn.Conv2d(input_channels, 64, 7, 2, 3),
            nn.BatchNorm2d(64),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(3, 2, 1),
            
            # ResNet Block 1
            nn.Conv2d(64, 128, 3, 1, 1),
            nn.BatchNorm2d(128),
            nn.ReLU(inplace=True),
            nn.Conv2d(128, 128, 3, 1, 1),
            nn.BatchNorm2d(128),
            nn.ReLU(inplace=True),
            
            # ResNet Block 2
            nn.Conv2d(128, 256, 3, 2, 1),
            nn.BatchNorm2d(256),
            nn.ReLU(inplace=True),
            nn.Conv2d(256, 256, 3, 1, 1),
            nn.BatchNorm2d(256),
            nn.ReLU(inplace=True),
            
            # Global Average Pooling
            nn.AdaptiveAvgPool2d(1)
        )
        
        # TPS Parameter Regressor
        self.tps_regressor = nn.Sequential(
            nn.Linear(256, 512),
            nn.ReLU(inplace=True),
            nn.Dropout(0.2),
            nn.Linear(512, 256),
            nn.ReLU(inplace=True),
            nn.Dropout(0.2),
            nn.Linear(256, num_control_points * 2)  # x, y coordinates
        )
        
        # Flow Field Generator
        self.flow_generator = nn.Sequential(
            nn.Conv2d(input_channels, 64, 3, 1, 1),
            nn.ReLU(inplace=True),
            nn.Conv2d(64, 128, 3, 1, 1),
            nn.ReLU(inplace=True),
            nn.Conv2d(128, 64, 3, 1, 1),
            nn.ReLU(inplace=True),
            nn.Conv2d(64, 2, 3, 1, 1),  # flow field (dx, dy)
            nn.Tanh()
        )
        
        # Warping Quality Predictor
        self.quality_predictor = nn.Sequential(
            nn.Conv2d(input_channels, 32, 3, 1, 1),
            nn.ReLU(inplace=True),
            nn.AdaptiveAvgPool2d(1),
            nn.Flatten(),
            nn.Linear(32, 1),
            nn.Sigmoid()
        )
        
    def forward(self, cloth_image: torch.Tensor, person_image: torch.Tensor) -> Dict[str, torch.Tensor]:
        """ìˆœì „íŒŒ"""
        batch_size = cloth_image.size(0)
        
        # ì…ë ¥ ì—°ê²°
        combined_input = torch.cat([cloth_image, person_image], dim=1)
        
        # Feature ì¶”ì¶œ
        features = self.feature_extractor(combined_input)
        features_flat = features.view(batch_size, -1)
        
        # TPS íŒŒë¼ë¯¸í„° ìƒì„±
        tps_params = self.tps_regressor(features_flat)
        tps_params = tps_params.view(batch_size, self.num_control_points, 2)
        
        # Flow Field ìƒì„±
        flow_field = self.flow_generator(combined_input)
        
        # í’ˆì§ˆ ì˜ˆì¸¡
        quality_score = self.quality_predictor(combined_input)
        
        # TPS ë³€í™˜ ì ìš©
        warped_cloth = self._apply_tps_transform(cloth_image, tps_params)
        
        # Flow Field ì ìš© (ì¶”ê°€ì ì¸ fine-tuning)
        final_warped = self._apply_flow_field(warped_cloth, flow_field)
        
        return {
            'warped_cloth': final_warped,
            'tps_params': tps_params,
            'flow_field': flow_field,
            'quality_score': quality_score,
            'confidence': self._calculate_confidence(cloth_image, final_warped)
        }
    
    def _apply_tps_transform(self, cloth_image: torch.Tensor, tps_params: torch.Tensor) -> torch.Tensor:
        """TPS ë³€í™˜ ì ìš©"""
        try:
            batch_size, channels, height, width = cloth_image.shape
            
            # ê°„ë‹¨í•œ ì–´íŒŒì¸ ë³€í™˜ìœ¼ë¡œ ê·¼ì‚¬
            theta = torch.zeros(batch_size, 2, 3, device=cloth_image.device)
            theta[:, 0, 0] = 1.0
            theta[:, 1, 1] = 1.0
            
            # TPS íŒŒë¼ë¯¸í„°ë¥¼ ì–´íŒŒì¸ íŒŒë¼ë¯¸í„°ë¡œ ê·¼ì‚¬ ë³€í™˜
            if tps_params.size(-1) >= 2:
                mean_params = tps_params.mean(dim=1)  # [B, 2]
                theta[:, 0, 2] = mean_params[:, 0] * 0.1  # translation x
                theta[:, 1, 2] = mean_params[:, 1] * 0.1  # translation y
            
            # Grid ìƒì„± ë° ìƒ˜í”Œë§
            grid = F.affine_grid(theta, cloth_image.size(), align_corners=False)
            warped = F.grid_sample(cloth_image, grid, align_corners=False)
            
            return warped
            
        except Exception as e:
            logging.getLogger(__name__).warning(f"TPS ë³€í™˜ ì‹¤íŒ¨, ì›ë³¸ ë°˜í™˜: {e}")
            return cloth_image
    
    def _apply_flow_field(self, cloth_image: torch.Tensor, flow_field: torch.Tensor) -> torch.Tensor:
        """Flow Field ì ìš©"""
        try:
            batch_size, channels, height, width = cloth_image.shape
            
            # ì •ê·œí™”ëœ grid ìƒì„± [-1, 1]
            y_coords = torch.linspace(-1, 1, height, device=cloth_image.device)
            x_coords = torch.linspace(-1, 1, width, device=cloth_image.device)
            y_grid, x_grid = torch.meshgrid(y_coords, x_coords, indexing='ij')
            
            # Gridë¥¼ batch ì°¨ì›ìœ¼ë¡œ í™•ì¥
            grid = torch.stack([x_grid, y_grid], dim=0).unsqueeze(0).repeat(batch_size, 1, 1, 1)
            
            # Flow field ì¶”ê°€ (ìŠ¤ì¼€ì¼ë§ ì ìš©)
            flow_scaled = flow_field * 0.1  # ë³€í˜• ì •ë„ ì¡°ì ˆ
            grid = grid + flow_scaled
            
            # Grid í˜•íƒœ ë³€ê²½: [B, H, W, 2]
            grid = grid.permute(0, 2, 3, 1)
            
            # ê·¸ë¦¬ë“œ ìƒ˜í”Œë§
            warped = F.grid_sample(cloth_image, grid, align_corners=False)
            
            return warped
            
        except Exception as e:
            logging.getLogger(__name__).warning(f"Flow Field ì ìš© ì‹¤íŒ¨, ì›ë³¸ ë°˜í™˜: {e}")
            return cloth_image
    
    def _calculate_confidence(self, original: torch.Tensor, warped: torch.Tensor) -> torch.Tensor:
        """ì‹ ë¢°ë„ ê³„ì‚°"""
        try:
            # ê°„ë‹¨í•œ MSE ê¸°ë°˜ ì‹ ë¢°ë„
            mse = F.mse_loss(original, warped, reduction='none')
            confidence = torch.exp(-mse.mean(dim=[1, 2, 3]))
            return confidence
        except:
            return torch.ones(original.size(0), device=original.device) * 0.8

class RealTOMModel(nn.Module):
    """ì‹¤ì œ TOM (Try-On Model) AI ëª¨ë¸"""
    
    def __init__(self, input_size: Tuple[int, int] = (512, 384)):
        super().__init__()
        self.input_size = input_size
        
        # Encoder
        self.cloth_encoder = nn.Sequential(
            nn.Conv2d(3, 64, 4, 2, 1),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Conv2d(64, 128, 4, 2, 1),
            nn.BatchNorm2d(128),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Conv2d(128, 256, 4, 2, 1),
            nn.BatchNorm2d(256),
            nn.LeakyReLU(0.2, inplace=True),
        )
        
        self.person_encoder = nn.Sequential(
            nn.Conv2d(3, 64, 4, 2, 1),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Conv2d(64, 128, 4, 2, 1),
            nn.BatchNorm2d(128),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Conv2d(128, 256, 4, 2, 1),
            nn.BatchNorm2d(256),
            nn.LeakyReLU(0.2, inplace=True),
        )
        
        # Fusion Layer
        self.fusion = nn.Sequential(
            nn.Conv2d(512, 256, 3, 1, 1),
            nn.BatchNorm2d(256),
            nn.ReLU(inplace=True),
            nn.Conv2d(256, 128, 3, 1, 1),
            nn.BatchNorm2d(128),
            nn.ReLU(inplace=True),
        )
        
        # Decoder
        self.decoder = nn.Sequential(
            nn.ConvTranspose2d(128, 64, 4, 2, 1),
            nn.BatchNorm2d(64),
            nn.ReLU(inplace=True),
            nn.ConvTranspose2d(64, 32, 4, 2, 1),
            nn.BatchNorm2d(32),
            nn.ReLU(inplace=True),
            nn.ConvTranspose2d(32, 3, 4, 2, 1),
            nn.Tanh()
        )
        
    def forward(self, cloth_image: torch.Tensor, person_image: torch.Tensor) -> torch.Tensor:
        """ìˆœì „íŒŒ"""
        # Encode
        cloth_features = self.cloth_encoder(cloth_image)
        person_features = self.person_encoder(person_image)
        
        # Fuse
        combined_features = torch.cat([cloth_features, person_features], dim=1)
        fused_features = self.fusion(combined_features)
        
        # Decode
        output = self.decoder(fused_features)
        
        return output

class AIImageProcessor:
    """AI ê¸°ë°˜ ì´ë¯¸ì§€ ì²˜ë¦¬ í´ë˜ìŠ¤ (OpenCV ì™„ì „ ëŒ€ì²´)"""
    
    def __init__(self, device: str = "cpu"):
        self.device = device
        self.logger = logging.getLogger(__name__)
        
        # CLIP ëª¨ë¸ (ì´ë¯¸ì§€ ì²˜ë¦¬ìš©)
        self.clip_processor = None
        self.clip_model = None
        
        # Real-ESRGAN (ì—…ìŠ¤ì¼€ì¼ë§ìš©)
        self.esrgan_model = None
        
        # ì´ˆê¸°í™”
        self._initialize_ai_models()
        
    def _initialize_ai_models(self):
        """AI ëª¨ë¸ë“¤ ì´ˆê¸°í™”"""
        try:
            if TRANSFORMERS_AVAILABLE:
                # CLIP ëª¨ë¸ ë¡œë“œ
                self.clip_processor = CLIPProcessor.from_pretrained("openai/clip-vit-base-patch32")
                self.clip_model = CLIPModel.from_pretrained("openai/clip-vit-base-patch32")
                if TORCH_AVAILABLE:
                    self.clip_model.to(self.device)
                self.logger.info("âœ… CLIP ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ")
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ AI ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    
    def ai_resize(self, image: np.ndarray, target_size: Tuple[int, int], mode: str = "bilinear") -> np.ndarray:
        """AI ê¸°ë°˜ ì§€ëŠ¥ì  ë¦¬ì‚¬ì´ì§• (OpenCV resize ëŒ€ì²´)"""
        try:
            if not TORCH_AVAILABLE:
                # PIL í´ë°± (í˜¸í™˜ì„± ê°œì„ )
                pil_img = Image.fromarray(image)
                pil_resample = {
                    "nearest": Image.NEAREST,
                    "bilinear": Image.BILINEAR, 
                    "bicubic": Image.BICUBIC,
                    "lanczos": Image.LANCZOS
                }.get(mode.lower(), Image.LANCZOS)
                resized = pil_img.resize(target_size, pil_resample)
                return np.array(resized)
            
            # PyTorch ê¸°ë°˜ ê³ í’ˆì§ˆ ë¦¬ì‚¬ì´ì§•
            if len(image.shape) == 3:
                tensor = torch.from_numpy(image).permute(2, 0, 1).unsqueeze(0).float() / 255.0
            else:
                tensor = torch.from_numpy(image).unsqueeze(0).unsqueeze(0).float() / 255.0
            
            tensor = tensor.to(self.device)
            
            # ê³ í’ˆì§ˆ interpolation
            torch_mode = {
                "nearest": "nearest",
                "bilinear": "bilinear", 
                "bicubic": "bicubic",
                "lanczos": "bilinear"  # PyTorchì—ì„œëŠ” bilinearë¡œ ëŒ€ì²´
            }.get(mode.lower(), "bilinear")
            
            resized_tensor = F.interpolate(tensor, size=target_size, mode=torch_mode, align_corners=False)
            
            # ë‹¤ì‹œ numpyë¡œ ë³€í™˜
            if len(image.shape) == 3:
                result = resized_tensor.squeeze(0).permute(1, 2, 0).cpu().numpy()
            else:
                result = resized_tensor.squeeze().cpu().numpy()
            
            return (result * 255).astype(np.uint8)
            
        except Exception as e:
            self.logger.warning(f"AI ë¦¬ì‚¬ì´ì§• ì‹¤íŒ¨, PIL í´ë°±: {e}")
            # PIL í´ë°±
            try:
                pil_img = Image.fromarray(image)
                resized = pil_img.resize(target_size, Image.LANCZOS)
                return np.array(resized)
            except Exception as e2:
                self.logger.error(f"PIL í´ë°±ë„ ì‹¤íŒ¨: {e2}")
                return image
    
    def ai_mask_generation(self, image: np.ndarray, threshold: float = 0.5) -> np.ndarray:
        """AI ê¸°ë°˜ ë§ˆìŠ¤í¬ ìƒì„± (OpenCV threshold ëŒ€ì²´)"""
        try:
            # CLIP ê¸°ë°˜ ì˜ë¥˜ ì˜ì—­ ê°ì§€
            if self.clip_model and self.clip_processor:
                pil_img = Image.fromarray(image)
                inputs = self.clip_processor(images=pil_img, return_tensors="pt")
                
                with torch.no_grad():
                    image_features = self.clip_model.get_image_features(**inputs)
                    # ì˜ë¥˜ ê´€ë ¨ íŠ¹ì§•ì„ ê¸°ë°˜ìœ¼ë¡œ ë§ˆìŠ¤í¬ ìƒì„±
                    # ê°„ë‹¨í•œ êµ¬í˜„ (ì‹¤ì œë¡œëŠ” ë” ë³µì¡í•œ ì„¸ê·¸ë©˜í…Œì´ì…˜ ëª¨ë¸ ì‚¬ìš©)
                    
            # í´ë°±: ê°„ë‹¨í•œ ìƒ‰ìƒ ê¸°ë°˜ ë§ˆìŠ¤í¬
            gray = self._rgb_to_grayscale(image)
            mask = (gray > threshold * 255).astype(np.uint8) * 255
            
            return mask
            
        except Exception as e:
            self.logger.warning(f"AI ë§ˆìŠ¤í¬ ìƒì„± ì‹¤íŒ¨: {e}")
            # í´ë°±
            gray = self._rgb_to_grayscale(image)
            return (gray > threshold * 255).astype(np.uint8) * 255
    
    def ai_color_conversion(self, image: np.ndarray, conversion_type: str = "RGB2BGR") -> np.ndarray:
        """AI ê¸°ë°˜ ìƒ‰ìƒ ë³€í™˜ (OpenCV cvtColor ëŒ€ì²´)"""
        try:
            if conversion_type == "RGB2BGR" or conversion_type == "BGR2RGB":
                # ë‹¨ìˆœ ì±„ë„ ìˆœì„œ ë³€ê²½
                return image[:, :, ::-1]
            elif conversion_type == "RGB2GRAY" or conversion_type == "BGR2GRAY":
                return self._rgb_to_grayscale(image)
            else:
                return image
                
        except Exception as e:
            self.logger.warning(f"ìƒ‰ìƒ ë³€í™˜ ì‹¤íŒ¨: {e}")
            return image
    
    def ai_geometric_transform(self, image: np.ndarray, transform_matrix: np.ndarray) -> np.ndarray:
        """AI ê¸°ë°˜ ê¸°í•˜í•™ì  ë³€í™˜ (OpenCV warpAffine ëŒ€ì²´)"""
        try:
            if not TORCH_AVAILABLE:
                # PIL í´ë°±
                pil_img = Image.fromarray(image)
                # ê°„ë‹¨í•œ ë³€í˜•ë§Œ ì§€ì›
                return np.array(pil_img)
            
            # PyTorch ê¸°ë°˜ ë³€í™˜
            tensor = torch.from_numpy(image).permute(2, 0, 1).unsqueeze(0).float() / 255.0
            tensor = tensor.to(self.device)
            
            # Affine grid ìƒì„±
            transform_tensor = torch.from_numpy(transform_matrix[:2]).unsqueeze(0).float().to(self.device)
            grid = F.affine_grid(transform_tensor, tensor.size(), align_corners=False)
            
            # ë³€í™˜ ì ìš©
            warped_tensor = F.grid_sample(tensor, grid, align_corners=False)
            
            # numpyë¡œ ë³€í™˜
            result = warped_tensor.squeeze(0).permute(1, 2, 0).cpu().numpy()
            return (result * 255).astype(np.uint8)
            
        except Exception as e:
            self.logger.warning(f"AI ê¸°í•˜í•™ì  ë³€í™˜ ì‹¤íŒ¨: {e}")
            return image
    
    def ai_edge_detection(self, image: np.ndarray, low_threshold: int = 50, high_threshold: int = 150) -> np.ndarray:
        """AI ê¸°ë°˜ ì—£ì§€ ê²€ì¶œ (OpenCV Canny ëŒ€ì²´)"""
        try:
            # Sobel ê¸°ë°˜ ì—£ì§€ ê²€ì¶œ
            gray = self._rgb_to_grayscale(image)
            
            if TORCH_AVAILABLE:
                # PyTorch Sobel í•„í„°
                tensor = torch.from_numpy(gray).unsqueeze(0).unsqueeze(0).float().to(self.device)
                
                # Sobel ì»¤ë„
                sobel_x = torch.tensor([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]], dtype=torch.float32).unsqueeze(0).unsqueeze(0).to(self.device)
                sobel_y = torch.tensor([[-1, -2, -1], [0, 0, 0], [1, 2, 1]], dtype=torch.float32).unsqueeze(0).unsqueeze(0).to(self.device)
                
                # ì—£ì§€ ê²€ì¶œ
                edges_x = F.conv2d(tensor, sobel_x, padding=1)
                edges_y = F.conv2d(tensor, sobel_y, padding=1)
                edges = torch.sqrt(edges_x**2 + edges_y**2)
                
                # ì„ê³„ê°’ ì ìš©
                edges = (edges > low_threshold).float() * 255
                
                return edges.squeeze().cpu().numpy().astype(np.uint8)
            
            # NumPy í´ë°±
            return self._simple_edge_detection(gray, low_threshold)
            
        except Exception as e:
            self.logger.warning(f"AI ì—£ì§€ ê²€ì¶œ ì‹¤íŒ¨: {e}")
            return self._simple_edge_detection(gray, low_threshold)
    
    def _rgb_to_grayscale(self, image: np.ndarray) -> np.ndarray:
        """RGBë¥¼ ê·¸ë ˆì´ìŠ¤ì¼€ì¼ë¡œ ë³€í™˜"""
        if len(image.shape) == 3:
            # í‘œì¤€ ê°€ì¤‘ì¹˜ ì‚¬ìš©
            return np.dot(image[...,:3], [0.2989, 0.5870, 0.1140]).astype(np.uint8)
        return image
    
    def _simple_edge_detection(self, gray: np.ndarray, threshold: int) -> np.ndarray:
        """ê°„ë‹¨í•œ ì—£ì§€ ê²€ì¶œ"""
        # ê°„ë‹¨í•œ Sobel í•„í„° êµ¬í˜„
        sobel_x = np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]])
        sobel_y = np.array([[-1, -2, -1], [0, 0, 0], [1, 2, 1]])
        
        # íŒ¨ë”© ì¶”ê°€
        padded = np.pad(gray, 1, mode='edge')
        
        edges = np.zeros_like(gray)
        for i in range(gray.shape[0]):
            for j in range(gray.shape[1]):
                gx = np.sum(padded[i:i+3, j:j+3] * sobel_x)
                gy = np.sum(padded[i:i+3, j:j+3] * sobel_y)
                edges[i, j] = min(255, int(np.sqrt(gx**2 + gy**2)))
        
        return (edges > threshold).astype(np.uint8) * 255

class AIModelWrapper:
    """ì‹¤ì œ AI ëª¨ë¸ ë˜í¼ - ModelLoader ì™„ì „ ì—°ë™"""
    
    def __init__(self, model_instance: Any, device: str = "cpu"):
        self.model_instance = model_instance
        self.device = device
        self.model_type = self._analyze_model_type()
        self.is_loaded = model_instance is not None
        self.logger = logging.getLogger(__name__)
        
        # AI ëª¨ë¸ í´ë˜ìŠ¤ ìƒì„± (ì²´í¬í¬ì¸íŠ¸ì—ì„œ)
        self.ai_model = None
        self.ai_processor = AIImageProcessor(device)
        
        if self.is_loaded:
            self.ai_model = self._create_ai_model_from_checkpoint()
    
    def _analyze_model_type(self) -> str:
        """ëª¨ë¸ íƒ€ì… ë¶„ì„"""
        try:
            if self.model_instance is None:
                return "unknown"
                
            model_str = str(type(self.model_instance)).lower()
            
            if "hrviton" in model_str or "warping" in model_str:
                return "ClothWarping"
            elif "tom" in model_str:
                return "TOM"
            elif "ootd" in model_str:
                return "OOTD"
            elif isinstance(self.model_instance, dict):
                return "checkpoint_dict"
            elif hasattr(self.model_instance, '__class__'):
                return "pytorch_model"
            else:
                return "unknown"
                
        except Exception:
            return "unknown"
    
    def _create_ai_model_from_checkpoint(self) -> Optional[nn.Module]:
        """ì²´í¬í¬ì¸íŠ¸ì—ì„œ ì‹¤ì œ AI ëª¨ë¸ í´ë˜ìŠ¤ ìƒì„±"""
        try:
            if not isinstance(self.model_instance, dict):
                # ì´ë¯¸ ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ì¸ ê²½ìš°
                if hasattr(self.model_instance, 'forward') or callable(self.model_instance):
                    return self.model_instance
                else:
                    # ê¸°ë³¸ ClothWarping ëª¨ë¸ ìƒì„±
                    self.logger.info("ê¸°ë³¸ RealClothWarpingModel ìƒì„±")
                    return RealClothWarpingModel().to(self.device)
            
            # ì²´í¬í¬ì¸íŠ¸ì—ì„œ AI ëª¨ë¸ ìƒì„±
            checkpoint = self.model_instance
            self.logger.info(f"ì²´í¬í¬ì¸íŠ¸ì—ì„œ AI ëª¨ë¸ ìƒì„± ì‹œì‘: {list(checkpoint.keys())[:5]}")
            
            # AI ëª¨ë¸ ì•„í‚¤í…ì²˜ ìƒì„±
            num_control_points = checkpoint.get('num_control_points', 25)
            input_channels = checkpoint.get('input_channels', 6)
            
            # ëª¨ë¸ íƒ€ì…ì— ë”°ë¼ ë‹¤ë¥¸ ëª¨ë¸ ìƒì„±
            if self.model_type == "TOM":
                ai_model = RealTOMModel().to(self.device)
            else:
                ai_model = RealClothWarpingModel(
                    num_control_points=num_control_points,
                    input_channels=input_channels
                ).to(self.device)
            
            # ê°€ì¤‘ì¹˜ ë¡œë”© ì‹œë„
            if 'state_dict' in checkpoint:
                try:
                    ai_model.load_state_dict(checkpoint['state_dict'], strict=False)
                    self.logger.info("âœ… state_dictì—ì„œ ê°€ì¤‘ì¹˜ ë¡œë”© ì„±ê³µ")
                except Exception as e:
                    self.logger.warning(f"âš ï¸ state_dict ë¡œë”© ì‹¤íŒ¨: {e}")
            elif 'model' in checkpoint:
                try:
                    ai_model.load_state_dict(checkpoint['model'], strict=False)
                    self.logger.info("âœ… modelì—ì„œ ê°€ì¤‘ì¹˜ ë¡œë”© ì„±ê³µ")
                except Exception as e:
                    self.logger.warning(f"âš ï¸ model ë¡œë”© ì‹¤íŒ¨: {e}")
            else:
                self.logger.info("âš ï¸ ê°€ì¤‘ì¹˜ ë¡œë”© ì—†ìŒ, ëœë¤ ì´ˆê¸°í™” ì‚¬ìš©")
            
            ai_model.eval()
            self.logger.info("âœ… AI ëª¨ë¸ ìƒì„± ì™„ë£Œ")
            return ai_model
            
        except Exception as e:
            self.logger.error(f"âŒ AI ëª¨ë¸ ìƒì„± ì‹¤íŒ¨: {e}")
            # í´ë°±: ê¸°ë³¸ ëª¨ë¸
            try:
                fallback_model = RealClothWarpingModel().to(self.device)
                fallback_model.eval()
                self.logger.info("âœ… í´ë°± AI ëª¨ë¸ ìƒì„± ì™„ë£Œ")
                return fallback_model
            except Exception as fallback_e:
                self.logger.error(f"âŒ í´ë°± ëª¨ë¸ë„ ì‹¤íŒ¨: {fallback_e}")
                return None
    
    def warp_cloth(self, cloth_tensor: torch.Tensor, person_tensor: torch.Tensor) -> torch.Tensor:
        """ì˜ë¥˜ ì›Œí•‘ ì‹¤í–‰ (ì‹¤ì œ AI ì¶”ë¡ )"""
        if not self.is_loaded:
            raise ValueError("AI ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
        
        try:
            if self.ai_model is not None:
                # ì‹¤ì œ AI ëª¨ë¸ ì¶”ë¡ 
                with torch.no_grad():
                    self.ai_model.eval()
                    result = self.ai_model(cloth_tensor, person_tensor)
                    
                    if isinstance(result, dict) and 'warped_cloth' in result:
                        return result['warped_cloth']
                    elif isinstance(result, torch.Tensor):
                        return result
                    else:
                        self.logger.warning("AI ëª¨ë¸ ê²°ê³¼ í˜•ì‹ ë¶ˆì¼ì¹˜, í´ë°± ì‚¬ìš©")
                        return self._simulate_warping_fallback(cloth_tensor, person_tensor)
            
            # ì²´í¬í¬ì¸íŠ¸ ë”•ì…”ë„ˆë¦¬ì¸ ê²½ìš° ì‹œë®¬ë ˆì´ì…˜
            elif isinstance(self.model_instance, dict):
                return self._simulate_warping_from_checkpoint(cloth_tensor, person_tensor)
            
            # ê¸°íƒ€ ê²½ìš° í´ë°±
            else:
                return self._simulate_warping_fallback(cloth_tensor, person_tensor)
                    
        except Exception as e:
            self.logger.error(f"âŒ AI ì›Œí•‘ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            # í´ë°±: ê°„ë‹¨í•œ ì›Œí•‘ ì‹œë®¬ë ˆì´ì…˜
            return self._simulate_warping_fallback(cloth_tensor, person_tensor)
    
    def _simulate_warping_from_checkpoint(self, cloth_tensor: torch.Tensor, person_tensor: torch.Tensor) -> torch.Tensor:
        """ì²´í¬í¬ì¸íŠ¸ì—ì„œ ì›Œí•‘ ì‹œë®¬ë ˆì´ì…˜"""
        try:
            batch_size, channels, height, width = cloth_tensor.shape
            
            # TPS ê¸°ë°˜ ë³€í˜• ì‹œë®¬ë ˆì´ì…˜
            theta = torch.tensor([
                [1.0, 0.05, 0.02],
                [-0.02, 1.0, 0.01]
            ], dtype=cloth_tensor.dtype, device=cloth_tensor.device)
            theta = theta.unsqueeze(0).repeat(batch_size, 1, 1)
            
            # Grid ìƒì„± ë° ìƒ˜í”Œë§
            grid = F.affine_grid(theta, cloth_tensor.size(), align_corners=False)
            warped = F.grid_sample(cloth_tensor, grid, align_corners=False, mode='bilinear')
            
            self.logger.info("âœ… ì²´í¬í¬ì¸íŠ¸ ê¸°ë°˜ ì›Œí•‘ ì‹œë®¬ë ˆì´ì…˜ ì™„ë£Œ")
            return warped
            
        except Exception as e:
            self.logger.warning(f"ì²´í¬í¬ì¸íŠ¸ ì‹œë®¬ë ˆì´ì…˜ ì‹¤íŒ¨: {e}")
            return cloth_tensor
    
    def _simulate_warping_fallback(self, cloth_tensor: torch.Tensor, person_tensor: torch.Tensor) -> torch.Tensor:
        """í´ë°± ì›Œí•‘ ì‹œë®¬ë ˆì´ì…˜"""
        try:
            # ê°„ë‹¨í•œ ë…¸ì´ì¦ˆ ê¸°ë°˜ ë³€í˜•
            batch_size, channels, height, width = cloth_tensor.shape
            
            # ë¶€ë“œëŸ¬ìš´ ë³€í˜•ì„ ìœ„í•œ ì‘ì€ ìŠ¤ì¼€ì¼ ë³€í˜•
            scale_factor = 0.02
            noise = torch.randn(batch_size, channels, height//8, width//8, device=cloth_tensor.device) * scale_factor
            noise_upsampled = F.interpolate(noise, size=(height, width), mode='bilinear', align_corners=False)
            
            # ë³€í˜• ì ìš©
            warped = cloth_tensor + noise_upsampled
            warped = torch.clamp(warped, 0, 1)
            
            self.logger.info("âœ… í´ë°± ì›Œí•‘ ì‹œë®¬ë ˆì´ì…˜ ì™„ë£Œ")
            return warped
            
        except Exception as e:
            self.logger.error(f"í´ë°± ì‹œë®¬ë ˆì´ì…˜ë„ ì‹¤íŒ¨: {e}")
            return cloth_tensor

# ==============================================
# ğŸ”§ ê³ ê¸‰ ì²˜ë¦¬ í´ë˜ìŠ¤ë“¤ (AI ëª¨ë¸ ê¸°ë°˜)
# ==============================================

class AdvancedTPSTransform:
    """ê³ ê¸‰ TPS (Thin Plate Spline) ë³€í™˜ - AI ëª¨ë¸ ê¸°ë°˜"""
    
    def __init__(self, num_control_points: int = 25):
        self.num_control_points = num_control_points
        self.logger = logging.getLogger(__name__)
        self.ai_processor = AIImageProcessor()
    
    def create_adaptive_control_grid(self, width: int, height: int) -> np.ndarray:
        """ì ì‘ì  ì œì–´ì  ê·¸ë¦¬ë“œ ìƒì„±"""
        grid_size = int(np.sqrt(self.num_control_points))
        if grid_size * grid_size < self.num_control_points:
            grid_size += 1
        
        points = []
        
        for i in range(grid_size):
            for j in range(grid_size):
                if len(points) >= self.num_control_points:
                    break
                x = (width - 1) * i / max(1, grid_size - 1)
                y = (height - 1) * j / max(1, grid_size - 1)
                points.append([x, y])
        
        return np.array(points[:self.num_control_points])
    
    def apply_transform(self, image: np.ndarray, source_points: np.ndarray, target_points: np.ndarray) -> np.ndarray:
        """TPS ë³€í™˜ ì ìš© (AI ê¸°ë°˜)"""
        try:
            if SKIMAGE_AVAILABLE:
                from skimage.transform import PiecewiseAffineTransform, warp
                tform = PiecewiseAffineTransform()
                if tform.estimate(target_points, source_points):
                    warped = warp(image, tform, output_shape=image.shape[:2])
                    return (warped * 255).astype(np.uint8)
                else:
                    return self._ai_transform(image, source_points, target_points)
            else:
                return self._ai_transform(image, source_points, target_points)
        except Exception as e:
            self.logger.error(f"TPS ë³€í™˜ ì‹¤íŒ¨: {e}")
            return image
    
    def _ai_transform(self, image: np.ndarray, source_points: np.ndarray, target_points: np.ndarray) -> np.ndarray:
        """AI ê¸°ë°˜ ë³€í™˜ (OpenCV ëŒ€ì²´)"""
        try:
            if len(source_points) >= 3 and len(target_points) >= 3:
                # ê°„ë‹¨í•œ ì–´íŒŒì¸ ë³€í™˜ í–‰ë ¬ ê³„ì‚°
                src_pts = source_points[:3].astype(np.float32)
                dst_pts = target_points[:3].astype(np.float32)
                
                # ì–´íŒŒì¸ ë³€í™˜ í–‰ë ¬ ê³„ì‚° (3ì  ê¸°ì¤€)
                transform_matrix = self._calculate_affine_matrix(src_pts, dst_pts)
                
                # AI ê¸°ë°˜ ê¸°í•˜í•™ì  ë³€í™˜ ì ìš©
                return self.ai_processor.ai_geometric_transform(image, transform_matrix)
            
            return image
        except Exception as e:
            self.logger.warning(f"AI ë³€í™˜ ì‹¤íŒ¨: {e}")
            return image
    
    def _calculate_affine_matrix(self, src_pts: np.ndarray, dst_pts: np.ndarray) -> np.ndarray:
        """ì–´íŒŒì¸ ë³€í™˜ í–‰ë ¬ ê³„ì‚°"""
        try:
            # 3ì ì„ ì´ìš©í•œ ì–´íŒŒì¸ ë³€í™˜ í–‰ë ¬ ê³„ì‚°
            # [x', y', 1] = [x, y, 1] * M
            
            # ì†ŒìŠ¤ í¬ì¸íŠ¸ í–‰ë ¬ êµ¬ì„±
            A = np.column_stack([src_pts, np.ones(3)])
            B = dst_pts
            
            # ìµœì†Œì œê³±ë²•ìœ¼ë¡œ ë³€í™˜ í–‰ë ¬ ê³„ì‚°
            M = np.linalg.lstsq(A, B, rcond=None)[0]
            
            # 3x3 í˜•íƒœë¡œ í™•ì¥
            transform_matrix = np.vstack([M.T, [0, 0, 1]])
            
            return transform_matrix
            
        except Exception as e:
            self.logger.warning(f"ì–´íŒŒì¸ í–‰ë ¬ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return np.eye(3)

class ClothPhysicsSimulator:
    """ì˜ë¥˜ ë¬¼ë¦¬ ì‹œë®¬ë ˆì´ì…˜ ì—”ì§„ - AI ê°•í™”"""
    
    def __init__(self, properties: PhysicsProperties):
        self.properties = properties
        self.mesh_vertices = None
        self.mesh_faces = None
        self.velocities = None
        self.forces = None
        self.logger = logging.getLogger(__name__)
        
    def create_cloth_mesh(self, width: int, height: int, resolution: int = 32) -> Tuple[np.ndarray, np.ndarray]:
        """ì˜ë¥˜ ë©”ì‹œ ìƒì„±"""
        try:
            x = np.linspace(0, width-1, resolution)
            y = np.linspace(0, height-1, resolution)
            xx, yy = np.meshgrid(x, y)
            
            vertices = np.column_stack([xx.flatten(), yy.flatten(), np.zeros(xx.size)])
            
            faces = []
            for i in range(resolution-1):
                for j in range(resolution-1):
                    idx = i * resolution + j
                    faces.append([idx, idx+1, idx+resolution])
                    faces.append([idx+1, idx+resolution+1, idx+resolution])
            
            self.mesh_vertices = vertices
            self.mesh_faces = np.array(faces)
            self.velocities = np.zeros_like(vertices)
            self.forces = np.zeros_like(vertices)
            
            return vertices, self.mesh_faces
            
        except Exception as e:
            self.logger.error(f"ë©”ì‹œ ìƒì„± ì‹¤íŒ¨: {e}")
            raise RuntimeError(f"ë©”ì‹œ ìƒì„± ì‹¤íŒ¨: {e}")
    
    def simulate_step(self, dt: float = 0.016):
        """ì‹œë®¬ë ˆì´ì…˜ ë‹¨ê³„ ì‹¤í–‰"""
        if self.mesh_vertices is None:
            raise ValueError("ë©”ì‹œê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
            
        try:
            gravity = np.array([0, 0, -9.81]) * self.properties.density * dt
            self.forces[:, 2] += gravity[2]
            
            acceleration = self.forces / self.properties.density
            self.mesh_vertices += self.velocities * dt + 0.5 * acceleration * dt * dt
            self.velocities += acceleration * dt
            
            self.velocities *= (1.0 - self.properties.friction_coefficient * dt)
            self.forces.fill(0)
            
        except Exception as e:
            self.logger.error(f"ì‹œë®¬ë ˆì´ì…˜ ë‹¨ê³„ ì‹¤íŒ¨: {e}")
            raise RuntimeError(f"ì‹œë®¬ë ˆì´ì…˜ ë‹¨ê³„ ì‹¤íŒ¨: {e}")
    
    def get_deformed_mesh(self) -> np.ndarray:
        """ë³€í˜•ëœ ë©”ì‹œ ë°˜í™˜"""
        if self.mesh_vertices is None:
            raise ValueError("ë©”ì‹œê°€ ì—†ìŠµë‹ˆë‹¤")
        return self.mesh_vertices.copy()

class WarpingVisualizer:
    """ì›Œí•‘ ê³¼ì • ì‹œê°í™” ì—”ì§„ - AI ê¸°ë°˜"""
    
    def __init__(self, quality: str = "high"):
        self.quality = quality
        self.dpi = {"low": 72, "medium": 150, "high": 300, "ultra": 600}[quality]
        self.logger = logging.getLogger(__name__)
        self.ai_processor = AIImageProcessor()
        
    def create_warping_visualization(self, 
                                   original_cloth: np.ndarray,
                                   warped_cloth: np.ndarray,
                                   control_points: np.ndarray) -> np.ndarray:
        """ì›Œí•‘ ê³¼ì • ì¢…í•© ì‹œê°í™” (AI ê¸°ë°˜)"""
        try:
            h, w = original_cloth.shape[:2]
            canvas_w = w * 2
            canvas_h = h
            
            # AI ê¸°ë°˜ ìº”ë²„ìŠ¤ ìƒì„±
            canvas = np.ones((canvas_h, canvas_w, 3), dtype=np.uint8) * 255
            
            # ì›ë³¸ (ì¢Œì¸¡) - AI ê¸°ë°˜ ë¦¬ì‚¬ì´ì§•
            original_resized = self.ai_processor.ai_resize(original_cloth, (w, h))
            canvas[0:h, 0:w] = original_resized
            
            # ì›Œí•‘ ê²°ê³¼ (ìš°ì¸¡) - AI ê¸°ë°˜ ë¦¬ì‚¬ì´ì§•
            warped_resized = self.ai_processor.ai_resize(warped_cloth, (w, h))
            canvas[0:h, w:2*w] = warped_resized
            
            # ì œì–´ì  ì‹œê°í™” (AI ê¸°ë°˜ ì  ê·¸ë¦¬ê¸°)
            if len(control_points) > 0:
                canvas = self._draw_control_points_ai(canvas, control_points, w, h)
            
            # êµ¬ë¶„ì„  ê·¸ë¦¬ê¸°
            canvas = self._draw_divider_line_ai(canvas, w, h)
            
            # ë¼ë²¨ ì¶”ê°€
            canvas = self._add_labels_ai(canvas, w, h)
            
            return canvas
        except Exception as e:
            self.logger.error(f"ì‹œê°í™” ìƒì„± ì‹¤íŒ¨: {e}")
            # í´ë°±: ê°„ë‹¨í•œ ì‹œê°í™”
            try:
                h, w = original_cloth.shape[:2]
                canvas = np.hstack([original_cloth, warped_cloth])
                return canvas
            except:
                return original_cloth
    
    def _draw_control_points_ai(self, canvas: np.ndarray, control_points: np.ndarray, w: int, h: int) -> np.ndarray:
        """AI ê¸°ë°˜ ì œì–´ì  ê·¸ë¦¬ê¸°"""
        try:
            for i, point in enumerate(control_points[:min(10, len(control_points))]):
                x, y = int(point[0]), int(point[1])
                if 0 <= x < w and 0 <= y < h:
                    # ì›í˜• ì  ê·¸ë¦¬ê¸° (AI ê¸°ë°˜)
                    self._draw_circle_ai(canvas, (x, y), 3, (255, 0, 0))
                    self._draw_circle_ai(canvas, (x + w, y), 3, (0, 255, 0))
            return canvas
        except Exception as e:
            self.logger.warning(f"ì œì–´ì  ê·¸ë¦¬ê¸° ì‹¤íŒ¨: {e}")
            return canvas
    
    def _draw_circle_ai(self, image: np.ndarray, center: Tuple[int, int], radius: int, color: Tuple[int, int, int]):
        """AI ê¸°ë°˜ ì› ê·¸ë¦¬ê¸°"""
        try:
            x_center, y_center = center
            h, w = image.shape[:2]
            
            # ì› ì¢Œí‘œ ê³„ì‚°
            y, x = np.ogrid[:h, :w]
            mask = (x - x_center)**2 + (y - y_center)**2 <= radius**2
            
            # ìƒ‰ìƒ ì ìš©
            image[mask] = color
            
        except Exception as e:
            self.logger.warning(f"ì› ê·¸ë¦¬ê¸° ì‹¤íŒ¨: {e}")
    
    def _draw_divider_line_ai(self, canvas: np.ndarray, w: int, h: int) -> np.ndarray:
        """AI ê¸°ë°˜ êµ¬ë¶„ì„  ê·¸ë¦¬ê¸°"""
        try:
            # ìˆ˜ì§ì„  ê·¸ë¦¬ê¸°
            canvas[:, w:w+2] = [128, 128, 128]
            return canvas
        except Exception as e:
            self.logger.warning(f"êµ¬ë¶„ì„  ê·¸ë¦¬ê¸° ì‹¤íŒ¨: {e}")
            return canvas
    
    def _add_labels_ai(self, canvas: np.ndarray, w: int, h: int) -> np.ndarray:
        """AI ê¸°ë°˜ ë¼ë²¨ ì¶”ê°€"""
        try:
            # PILì„ ì‚¬ìš©í•œ í…ìŠ¤íŠ¸ ì¶”ê°€
            pil_img = Image.fromarray(canvas)
            # ê°„ë‹¨í•œ ë¼ë²¨ë§Œ ì¶”ê°€ (ë³µì¡í•œ í…ìŠ¤íŠ¸ ë Œë”ë§ì€ PILë¡œ)
            return np.array(pil_img)
        except Exception as e:
            self.logger.warning(f"ë¼ë²¨ ì¶”ê°€ ì‹¤íŒ¨: {e}")
            return canvas

# ==============================================
# ğŸ¯ ë©”ì¸ ClothWarpingStep í´ë˜ìŠ¤ (v16.0 í˜¸í™˜)
# ==============================================

class ClothWarpingStep(ClothWarpingMixin):
    """
    Step 5: ì˜ë¥˜ ì›Œí•‘ - ì™„ì „ AI ëª¨ë¸ í†µí•© v10.0
    
    ì•„í‚¤í…ì²˜:
    - BaseStepMixin v16.0 ì™„ì „ í˜¸í™˜
    - UnifiedDependencyManager ì—°ë™
    - OpenCV ì™„ì „ ëŒ€ì²´ â†’ AI ëª¨ë¸ ì‚¬ìš©
    - ì‹¤ì œ AI ëª¨ë¸ í´ë˜ìŠ¤ êµ¬í˜„
    - TYPE_CHECKING íŒ¨í„´ìœ¼ë¡œ ìˆœí™˜ì°¸ì¡° ë°©ì§€
    """
    
    def __init__(self, **kwargs):
        """ì´ˆê¸°í™” - BaseStepMixin v16.0 í˜¸í™˜"""
        try:
            # 1. ê¸°ë³¸ ì†ì„± ì„¤ì • (v16.0 íŒ¨í„´)
            kwargs.setdefault('step_name', 'ClothWarpingStep')
            kwargs.setdefault('step_id', 5)
            
            # 2. BaseStepMixin ì´ˆê¸°í™” (UnifiedDependencyManager ìë™ ì´ˆê¸°í™”ë¨)
            super().__init__(**kwargs)
            
            # 3. Stepë³„ íŠ¹í™” ì„¤ì •
            self._setup_cloth_warping_config(**kwargs)
            
            self.logger.info(f"ğŸ”„ ClothWarpingStep v10.0 ì´ˆê¸°í™” ì™„ë£Œ - {self.warping_config.warping_method.value} ë°©ì‹")
            
        except Exception as e:
            self.logger.error(f"âŒ ClothWarpingStep ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            # ê¸´ê¸‰ ì´ˆê¸°í™”
            self._emergency_setup(**kwargs)
    
    def _setup_cloth_warping_config(self, **kwargs):
        """ì˜ë¥˜ ì›Œí•‘ íŠ¹í™” ì„¤ì •"""
        try:
            # ì›Œí•‘ ì„¤ì •
            self.warping_config = ClothWarpingConfig(
                warping_method=WarpingMethod(kwargs.get('warping_method', 'ai_model')),
                input_size=tuple(kwargs.get('input_size', (512, 384))),
                num_control_points=kwargs.get('num_control_points', 25),
                ai_model_enabled=kwargs.get('ai_model_enabled', True),
                physics_enabled=kwargs.get('physics_enabled', True),
                visualization_enabled=kwargs.get('visualization_enabled', True),
                cache_enabled=kwargs.get('cache_enabled', True),
                cache_size=kwargs.get('cache_size', 50),
                quality_level=kwargs.get('quality_level', 'high'),
                precision=kwargs.get('precision', 'fp16'),
                memory_fraction=kwargs.get('memory_fraction', 0.7),
                batch_size=kwargs.get('batch_size', 1),
                strict_mode=kwargs.get('strict_mode', False),
                dependency_injection_enabled=kwargs.get('dependency_injection_enabled', True),
                auto_initialization=kwargs.get('auto_initialization', True),
                error_recovery_enabled=kwargs.get('error_recovery_enabled', True)
            )
            
            # AI ëª¨ë¸ ë˜í¼ ì´ˆê¸°í™”
            self.ai_model_wrapper = None
            
            # AI ê¸°ë°˜ ì´ë¯¸ì§€ ì²˜ë¦¬ê¸°
            self.ai_processor = AIImageProcessor(self.device)
            
            # ì„±ëŠ¥ ë° ìºì‹œ
            self.prediction_cache = {}
            
            # ì²˜ë¦¬ êµ¬ì„±ìš”ì†Œë“¤ (ì§€ì—° ì´ˆê¸°í™”)
            self.tps_transform = None
            self.physics_simulator = None
            self.visualizer = None
            
            # ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì„¤ì •
            self.processing_pipeline = []
            self._setup_processing_pipeline()
            
        except Exception as e:
            self.logger.error(f"âŒ ì›Œí•‘ ì„¤ì • ì‹¤íŒ¨: {e}")
            raise RuntimeError(f"ì›Œí•‘ ì„¤ì • ì‹¤íŒ¨: {e}")
    
    def _setup_processing_pipeline(self):
        """ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì„¤ì •"""
        try:
            self.processing_pipeline = [
                (ProcessingStage.PREPROCESSING, self._preprocess_for_warping),
                (ProcessingStage.AI_INFERENCE, self._perform_ai_inference),
                (ProcessingStage.PHYSICS_ENHANCEMENT, self._enhance_with_physics),
                (ProcessingStage.POSTPROCESSING, self._postprocess_warping_results),
                (ProcessingStage.QUALITY_ANALYSIS, self._analyze_warping_quality),
                (ProcessingStage.VISUALIZATION, self._create_warping_visualization)
            ]
            self.logger.info(f"âœ… íŒŒì´í”„ë¼ì¸ ì„¤ì • ì™„ë£Œ - {len(self.processing_pipeline)}ë‹¨ê³„")
        except Exception as e:
            self.logger.error(f"âŒ íŒŒì´í”„ë¼ì¸ ì„¤ì • ì‹¤íŒ¨: {e}")
    
    def _emergency_setup(self, **kwargs):
        """ê¸´ê¸‰ ì„¤ì • (ì´ˆê¸°í™” ì‹¤íŒ¨ ì‹œ)"""
        try:
            self.step_name = 'ClothWarpingStep'
            self.step_id = 5
            self.device = kwargs.get('device', 'cpu')
            self.logger = logging.getLogger(f"pipeline.{self.step_name}")
            
            # ìµœì†Œí•œì˜ ì„¤ì •
            self.warping_config = ClothWarpingConfig()
            self.ai_model_wrapper = None
            self.ai_processor = AIImageProcessor(self.device)
            self.prediction_cache = {}
            self.processing_pipeline = []
            
            # ìƒíƒœ í”Œë˜ê·¸
            self.is_initialized = False
            self.is_ready = False
            self.has_model = False
            
            self.logger.warning("âš ï¸ ê¸´ê¸‰ ì„¤ì • ì™„ë£Œ")
            
        except Exception as e:
            self.logger.error(f"âŒ ê¸´ê¸‰ ì„¤ì •ë„ ì‹¤íŒ¨: {e}")
    
    # ==============================================
    # ğŸ”¥ ì˜ì¡´ì„± ì£¼ì… ë©”ì„œë“œë“¤ (v16.0 í˜¸í™˜)
    # ==============================================
    
    def set_model_loader(self, model_loader):
        """ModelLoader ì˜ì¡´ì„± ì£¼ì… (v16.0 í˜¸í™˜)"""
        try:
            self.model_loader = model_loader
            
            # v16.0 UnifiedDependencyManagerì— ë“±ë¡
            if hasattr(self, 'dependency_manager') and self.dependency_manager:
                self.dependency_manager.register_dependency('model_loader', model_loader, priority=10)
            
            if model_loader:
                self.has_model = True
                self.model_loaded = True
            
            self.logger.info("âœ… ModelLoader ì˜ì¡´ì„± ì£¼ì… ì™„ë£Œ")
            return True
        except Exception as e:
            self.logger.error(f"âŒ ModelLoader ì£¼ì… ì‹¤íŒ¨: {e}")
            return False
    
    def set_memory_manager(self, memory_manager):
        """MemoryManager ì˜ì¡´ì„± ì£¼ì… (v16.0 í˜¸í™˜)"""
        try:
            self.memory_manager = memory_manager
            
            # v16.0 UnifiedDependencyManagerì— ë“±ë¡
            if hasattr(self, 'dependency_manager') and self.dependency_manager:
                self.dependency_manager.register_dependency('memory_manager', memory_manager, priority=5)
            
            self.logger.info("âœ… MemoryManager ì˜ì¡´ì„± ì£¼ì… ì™„ë£Œ")
            return True
        except Exception as e:
            self.logger.warning(f"âš ï¸ MemoryManager ì£¼ì… ì‹¤íŒ¨: {e}")
            return False
    
    def set_data_converter(self, data_converter):
        """DataConverter ì˜ì¡´ì„± ì£¼ì… (v16.0 í˜¸í™˜)"""
        try:
            self.data_converter = data_converter
            
            # v16.0 UnifiedDependencyManagerì— ë“±ë¡
            if hasattr(self, 'dependency_manager') and self.dependency_manager:
                self.dependency_manager.register_dependency('data_converter', data_converter, priority=3)
            
            self.logger.info("âœ… DataConverter ì˜ì¡´ì„± ì£¼ì… ì™„ë£Œ")
            return True
        except Exception as e:
            self.logger.warning(f"âš ï¸ DataConverter ì£¼ì… ì‹¤íŒ¨: {e}")
            return False
    
    def set_di_container(self, di_container):
        """DI Container ì˜ì¡´ì„± ì£¼ì… (v16.0 í˜¸í™˜)"""
        try:
            self.di_container = di_container
            
            # v16.0 UnifiedDependencyManagerì— ë“±ë¡
            if hasattr(self, 'dependency_manager') and self.dependency_manager:
                self.dependency_manager.register_dependency('di_container', di_container, priority=1)
            
            self.logger.info("âœ… DI Container ì˜ì¡´ì„± ì£¼ì… ì™„ë£Œ")
            return True
        except Exception as e:
            self.logger.warning(f"âš ï¸ DI Container ì£¼ì… ì‹¤íŒ¨: {e}")
            return False
    
    # ==============================================
    # ğŸš€ ì´ˆê¸°í™” ë©”ì„œë“œë“¤ (v16.0 í˜¸í™˜)
    # ==============================================
    
    async def initialize(self) -> bool:
        """ì´ˆê¸°í™” (v16.0 í˜¸í™˜)"""
        try:
            if self.is_initialized:
                return True
            
            self.logger.info("ğŸš€ ClothWarpingStep v10.0 ì´ˆê¸°í™” ì‹œì‘")
            
            # 1. ì§€ì—° ì´ˆê¸°í™”ëœ êµ¬ì„±ìš”ì†Œë“¤ ìƒì„±
            self._initialize_components()
            
            # 2. AI ëª¨ë¸ ì„¤ì • (ì˜ì¡´ì„± ì£¼ì…ëœ ê²½ìš°)
            if self.model_loader and self.warping_config.ai_model_enabled:
                await self._setup_ai_models()
            
            # 3. íŒŒì´í”„ë¼ì¸ ìµœì í™”
            self._optimize_pipeline()
            
            # 4. ì‹œìŠ¤í…œ ìµœì í™”
            if self.device == "mps" or IS_M3_MAX:
                self._apply_m3_max_optimization()
            
            self.is_initialized = True
            self.is_ready = True
            
            self.logger.info("âœ… ClothWarpingStep v10.0 ì´ˆê¸°í™” ì™„ë£Œ")
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ ClothWarpingStep ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            
            if self.warping_config.error_recovery_enabled:
                return self._emergency_initialization()
            
            return False
    
    def _initialize_components(self):
        """êµ¬ì„±ìš”ì†Œë“¤ ì§€ì—° ì´ˆê¸°í™”"""
        try:
            # TPS ë³€í™˜ê¸° (AI ê¸°ë°˜)
            if self.tps_transform is None:
                self.tps_transform = AdvancedTPSTransform(self.warping_config.num_control_points)
            
            # ì‹œê°í™”ê¸° (AI ê¸°ë°˜)
            if self.visualizer is None:
                self.visualizer = WarpingVisualizer(self.warping_config.quality_level)
            
            self.logger.info("âœ… AI ê¸°ë°˜ êµ¬ì„±ìš”ì†Œë“¤ ì§€ì—° ì´ˆê¸°í™” ì™„ë£Œ")
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ êµ¬ì„±ìš”ì†Œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    
    async def _setup_ai_models(self):
        """AI ëª¨ë¸ ì„¤ì •"""
        try:
            self.logger.info("ğŸ§  AI ëª¨ë¸ ì„¤ì • ì‹œì‘")
            
            # ëª¨ë¸ ë¡œë“œ ì‹œë„
            primary_model = await self._load_model_async('cloth_warping_primary')
            if primary_model:
                self.ai_model_wrapper = AIModelWrapper(primary_model, self.device)
                self.logger.info("âœ… ì£¼ AI ëª¨ë¸ ë¡œë“œ ì„±ê³µ")
            else:
                # ë°±ì—… ëª¨ë¸ ì‹œë„
                backup_model = await self._load_model_async('cloth_warping_backup')
                if backup_model:
                    self.ai_model_wrapper = AIModelWrapper(backup_model, self.device)
                    self.logger.info("âœ… ë°±ì—… AI ëª¨ë¸ ë¡œë“œ ì„±ê³µ")
                else:
                    if not self.warping_config.strict_mode:
                        # ê¸°ë³¸ ëª¨ë¸ ìƒì„±
                        self.ai_model_wrapper = AIModelWrapper(None, self.device)
                        self.logger.info("âš ï¸ ê¸°ë³¸ AI ëª¨ë¸ ë˜í¼ ìƒì„±")
                        
        except Exception as e:
            self.logger.error(f"âŒ AI ëª¨ë¸ ì„¤ì • ì‹¤íŒ¨: {e}")
            if not self.warping_config.strict_mode:
                self.ai_model_wrapper = AIModelWrapper(None, self.device)
    
    async def _load_model_async(self, model_name: str) -> Optional[Any]:
        """ë¹„ë™ê¸° ëª¨ë¸ ë¡œë“œ (v16.0 í˜¸í™˜)"""
        try:
            if hasattr(self, 'get_model_async'):
                model = await self.get_model_async(model_name)
                return model
            elif self.model_loader:
                if hasattr(self.model_loader, 'load_model_async'):
                    return await self.model_loader.load_model_async(model_name)
                elif hasattr(self.model_loader, 'load_model'):
                    return self.model_loader.load_model(model_name)
            return None
        except Exception as e:
            self.logger.debug(f"ëª¨ë¸ '{model_name}' ë¡œë“œ ì‹¤íŒ¨: {e}")
            return None
    
    def _optimize_pipeline(self):
        """íŒŒì´í”„ë¼ì¸ ìµœì í™”"""
        try:
            # ì„¤ì •ì— ë”°ë¥¸ íŒŒì´í”„ë¼ì¸ ì¡°ì •
            optimized_pipeline = []
            
            for stage, processor in self.processing_pipeline:
                include_stage = True
                
                if stage == ProcessingStage.PHYSICS_ENHANCEMENT and not self.warping_config.physics_enabled:
                    include_stage = False
                elif stage == ProcessingStage.VISUALIZATION and not self.warping_config.visualization_enabled:
                    include_stage = False
                
                if include_stage:
                    optimized_pipeline.append((stage, processor))
            
            self.processing_pipeline = optimized_pipeline
            self.logger.info(f"ğŸ”„ íŒŒì´í”„ë¼ì¸ ìµœì í™” ì™„ë£Œ - {len(self.processing_pipeline)}ë‹¨ê³„")
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ íŒŒì´í”„ë¼ì¸ ìµœì í™” ì‹¤íŒ¨: {e}")
    
    def _apply_m3_max_optimization(self):
        """M3 Max ìµœì í™” ì ìš©"""
        try:
            self.logger.info("ğŸ M3 Max ìµœì í™” ì ìš©")
            
            if hasattr(torch.backends.mps, 'empty_cache'):
                torch.backends.mps.empty_cache()
            
            os.environ['PYTORCH_MPS_HIGH_WATERMARK_RATIO'] = '0.0'
            
            if IS_M3_MAX:
                self.warping_config.batch_size = min(8, self.warping_config.batch_size)
                self.warping_config.precision = "fp16"
                
            self.logger.info("âœ… M3 Max ìµœì í™” ì ìš© ì™„ë£Œ")
            
        except Exception as e:
            self.logger.warning(f"M3 Max ìµœì í™” ì‹¤íŒ¨: {e}")
    
    def _emergency_initialization(self) -> bool:
        """ê¸´ê¸‰ ì´ˆê¸°í™”"""
        try:
            self.logger.warning("ğŸš¨ ê¸´ê¸‰ ì´ˆê¸°í™” ëª¨ë“œ ì‹œì‘")
            
            # ìµœì†Œí•œì˜ ì„¤ì •ìœ¼ë¡œ ì´ˆê¸°í™”
            self.ai_model_wrapper = AIModelWrapper(None, self.device)
            
            # ê¸°ë³¸ íŒŒì´í”„ë¼ì¸ë§Œ ìœ ì§€
            self.processing_pipeline = [
                (ProcessingStage.PREPROCESSING, self._preprocess_for_warping),
                (ProcessingStage.AI_INFERENCE, self._perform_ai_inference),
                (ProcessingStage.POSTPROCESSING, self._postprocess_warping_results)
            ]
            
            self.is_initialized = True
            self.is_ready = True
            
            self.logger.info("âœ… ê¸´ê¸‰ ì´ˆê¸°í™” ì™„ë£Œ")
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ ê¸´ê¸‰ ì´ˆê¸°í™”ë„ ì‹¤íŒ¨: {e}")
            return False
    
    # ==============================================
    # ğŸ”¥ ë©”ì¸ ì²˜ë¦¬ ë©”ì„œë“œ (process)
    # ==============================================
    
    async def process(
        self,
        cloth_image: Union[np.ndarray, str, Path, Image.Image],
        person_image: Union[np.ndarray, str, Path, Image.Image],
        cloth_mask: Optional[np.ndarray] = None,
        fabric_type: str = "cotton",
        clothing_type: str = "shirt",
        session_id: Optional[str] = None,
        **kwargs
    ) -> Dict[str, Any]:
        """
        ë©”ì¸ ì˜ë¥˜ ì›Œí•‘ ì²˜ë¦¬ - AI ëª¨ë¸ ì™„ì „ í†µí•©
        """
        start_time = time.time()
        
        try:
            # ì´ˆê¸°í™” ê²€ì¦
            if not self.is_initialized or not self.is_ready:
                await self.initialize()
            
            # ì…ë ¥ ê²€ì¦ ë° ì „ì²˜ë¦¬
            cloth_img = self._load_and_validate_image(cloth_image)
            person_img = self._load_and_validate_image(person_image)
            
            if cloth_img is None or person_img is None:
                raise ValueError("ìœ íš¨í•˜ì§€ ì•Šì€ ì´ë¯¸ì§€ì…ë‹ˆë‹¤")
            
            self.logger.info(f"ğŸ”„ AI ê¸°ë°˜ ì˜ë¥˜ ì›Œí•‘ ì²˜ë¦¬ ì‹œì‘ - {clothing_type} ({fabric_type})")
            
            # ìºì‹œ í™•ì¸
            cache_key = self._generate_cache_key(cloth_img, person_img, clothing_type, kwargs)
            if self.warping_config.cache_enabled and cache_key in self.prediction_cache:
                self.logger.info("ğŸ“‹ ìºì‹œì—ì„œ ì›Œí•‘ ê²°ê³¼ ë°˜í™˜")
                cached_result = self.prediction_cache[cache_key].copy()
                cached_result['from_cache'] = True
                return cached_result
            
            # ë©”ì¸ AI ì›Œí•‘ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
            warping_result = await self._execute_warping_pipeline(
                cloth_img, person_img, cloth_mask, fabric_type, clothing_type, **kwargs
            )
            
            # ìµœì¢… ê²°ê³¼ êµ¬ì„±
            processing_time = time.time() - start_time
            result = self._build_final_warping_result(warping_result, clothing_type, processing_time)
            
            # ìºì‹œ ì €ì¥
            if self.warping_config.cache_enabled:
                self._save_to_cache(cache_key, result)
            
            # ì„±ëŠ¥ ê¸°ë¡ (v16.0 í˜¸í™˜)
            if hasattr(self, 'performance_metrics'):
                self.performance_metrics['process_count'] += 1
                self.performance_metrics['total_process_time'] += processing_time
                self.performance_metrics['success_count'] += 1
                self.performance_metrics['average_process_time'] = (
                    self.performance_metrics['total_process_time'] / self.performance_metrics['process_count']
                )
            
            self.logger.info(f"âœ… AI ì˜ë¥˜ ì›Œí•‘ ì™„ë£Œ - í’ˆì§ˆ: {result.get('quality_grade', 'F')} ({processing_time:.3f}ì´ˆ)")
            return result
            
        except Exception as e:
            processing_time = time.time() - start_time
            error_msg = f"AI ì˜ë¥˜ ì›Œí•‘ ì‹¤íŒ¨: {e}"
            self.logger.error(f"âŒ {error_msg}")
            self.logger.debug(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
            
            # ì„±ëŠ¥ ê¸°ë¡
            if hasattr(self, 'performance_metrics'):
                self.performance_metrics['error_count'] += 1
            
            # ì—ëŸ¬ ê²°ê³¼ ë°˜í™˜
            return {
                "success": False,
                "step_name": self.step_name,
                "error": error_msg,
                "processing_time": processing_time,
                "clothing_type": clothing_type,
                "fabric_type": fabric_type,
                "session_id": session_id,
                "ai_model_enabled": self.warping_config.ai_model_enabled
            }
    
    # ==============================================
    # ğŸ§  AI ì¶”ë¡  ì²˜ë¦¬ ë©”ì„œë“œë“¤
    # ==============================================
    
    async def _execute_warping_pipeline(
        self,
        cloth_image: np.ndarray,
        person_image: np.ndarray,
        cloth_mask: Optional[np.ndarray],
        fabric_type: str,
        clothing_type: str,
        **kwargs
    ) -> Dict[str, Any]:
        """AI ì›Œí•‘ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
        
        intermediate_results = {}
        current_data = {
            'cloth_image': cloth_image,
            'person_image': person_image,
            'cloth_mask': cloth_mask,
            'fabric_type': fabric_type,
            'clothing_type': clothing_type
        }
        
        self.logger.info(f"ğŸ”„ AI ì˜ë¥˜ ì›Œí•‘ íŒŒì´í”„ë¼ì¸ ì‹œì‘ - {len(self.processing_pipeline)}ë‹¨ê³„")
        
        # ê° ë‹¨ê³„ ì‹¤í–‰
        for stage, processor_func in self.processing_pipeline:
            try:
                step_start = time.time()
                
                # ë‹¨ê³„ë³„ AI ì²˜ë¦¬
                step_result = await processor_func(current_data, **kwargs)
                if isinstance(step_result, dict):
                    current_data.update(step_result)
                
                step_time = time.time() - step_start
                intermediate_results[stage.value] = {
                    'processing_time': step_time,
                    'success': True
                }
                
                self.logger.debug(f"  âœ“ AI {stage.value} ì™„ë£Œ - {step_time:.3f}ì´ˆ")
                
            except Exception as e:
                self.logger.error(f"  âŒ AI {stage.value} ì‹¤íŒ¨: {e}")
                intermediate_results[stage.value] = {
                    'processing_time': 0,
                    'success': False,
                    'error': str(e)
                }
                
                if self.warping_config.strict_mode:
                    raise RuntimeError(f"AI íŒŒì´í”„ë¼ì¸ ë‹¨ê³„ {stage.value} ì‹¤íŒ¨: {e}")
        
        # ì „ì²´ ì ìˆ˜ ê³„ì‚°
        overall_score = self._calculate_overall_warping_score(current_data, clothing_type)
        current_data['overall_score'] = overall_score
        current_data['quality_grade'] = self._get_quality_grade(overall_score)
        current_data['pipeline_results'] = intermediate_results
        
        return current_data
    
    async def _preprocess_for_warping(self, data: Dict[str, Any], **kwargs) -> Dict[str, Any]:
        """AI ê¸°ë°˜ ì›Œí•‘ ì „ì²˜ë¦¬ (ì˜¤ë¥˜ ìˆ˜ì •)"""
        try:
            cloth_image = data['cloth_image']
            person_image = data['person_image']
            cloth_mask = data.get('cloth_mask')
            
            # ì´ë¯¸ì§€ ìœ íš¨ì„± ê²€ì‚¬ ê°œì„ 
            if cloth_image is None or not hasattr(cloth_image, 'shape') or cloth_image.size == 0:
                raise ValueError("ìœ íš¨í•˜ì§€ ì•Šì€ ì˜ë¥˜ ì´ë¯¸ì§€")
            if person_image is None or not hasattr(person_image, 'shape') or person_image.size == 0:
                raise ValueError("ìœ íš¨í•˜ì§€ ì•Šì€ ì¸ë¬¼ ì´ë¯¸ì§€")
            
            # AI ê¸°ë°˜ ì´ë¯¸ì§€ í¬ê¸° ì •ê·œí™”
            target_size = self.warping_config.input_size
            
            # AI ê¸°ë°˜ ë¦¬ì‚¬ì´ì§• (ê°œì„ ëœ ì˜¤ë¥˜ ì²˜ë¦¬)
            try:
                preprocessed_cloth = self.ai_processor.ai_resize(cloth_image, target_size, mode="lanczos")
            except Exception as e:
                self.logger.warning(f"AI ì˜ë¥˜ ë¦¬ì‚¬ì´ì§• ì‹¤íŒ¨, ê¸°ë³¸ ë°©ì‹ ì‚¬ìš©: {e}")
                # ì•ˆì „í•œ í´ë°±
                try:
                    pil_img = Image.fromarray(cloth_image)
                    resized = pil_img.resize(target_size, Image.LANCZOS)
                    preprocessed_cloth = np.array(resized)
                except Exception as e2:
                    self.logger.error(f"PIL í´ë°±ë„ ì‹¤íŒ¨: {e2}")
                    preprocessed_cloth = cloth_image
            
            try:
                preprocessed_person = self.ai_processor.ai_resize(person_image, target_size, mode="lanczos")
            except Exception as e:
                self.logger.warning(f"AI ì¸ë¬¼ ë¦¬ì‚¬ì´ì§• ì‹¤íŒ¨, ê¸°ë³¸ ë°©ì‹ ì‚¬ìš©: {e}")
                try:
                    pil_img = Image.fromarray(person_image)
                    resized = pil_img.resize(target_size, Image.LANCZOS)
                    preprocessed_person = np.array(resized)
                except Exception as e2:
                    self.logger.error(f"PIL í´ë°±ë„ ì‹¤íŒ¨: {e2}")
                    preprocessed_person = person_image
            
            # ë§ˆìŠ¤í¬ ì²˜ë¦¬ ê°œì„ 
            if cloth_mask is not None and hasattr(cloth_mask, 'shape') and cloth_mask.size > 0:
                try:
                    preprocessed_mask = self.ai_processor.ai_resize(cloth_mask, target_size, mode="nearest")
                except Exception as e:
                    self.logger.warning(f"ë§ˆìŠ¤í¬ ë¦¬ì‚¬ì´ì§• ì‹¤íŒ¨: {e}")
                    preprocessed_mask = cloth_mask
            else:
                # AI ê¸°ë°˜ ë§ˆìŠ¤í¬ ìƒì„±
                try:
                    preprocessed_mask = self.ai_processor.ai_mask_generation(preprocessed_cloth)
                except Exception as e:
                    self.logger.warning(f"AI ë§ˆìŠ¤í¬ ìƒì„± ì‹¤íŒ¨: {e}")
                    # ê¸°ë³¸ ë§ˆìŠ¤í¬ ìƒì„±
                    preprocessed_mask = np.ones(preprocessed_cloth.shape[:2], dtype=np.uint8) * 255
            
            return {
                'preprocessed_cloth': preprocessed_cloth,
                'preprocessed_person': preprocessed_person,
                'preprocessed_mask': preprocessed_mask,
                'original_cloth_shape': cloth_image.shape,
                'original_person_shape': person_image.shape
            }
            
        except Exception as e:
            self.logger.error(f"âŒ AI ì „ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            raise RuntimeError(f"AI ì „ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
    
    async def _perform_ai_inference(self, data: Dict[str, Any], **kwargs) -> Dict[str, Any]:
        """AI ì¶”ë¡  ì‹¤í–‰ - ì‹¤ì œ AI ëª¨ë¸ ì‚¬ìš©"""
        try:
            cloth_image = data.get('preprocessed_cloth', data['cloth_image'])
            person_image = data.get('preprocessed_person', data['person_image'])
            
            self.logger.info("ğŸ§  ì‹¤ì œ AI ì›Œí•‘ ì¶”ë¡  ì‹œì‘")
            
            # AI ëª¨ë¸ ì›Œí•‘ ì‹¤í–‰
            if self.ai_model_wrapper and self.ai_model_wrapper.is_loaded:
                warped_result = await self._run_ai_warping(cloth_image, person_image)
                
                if warped_result['success']:
                    return {
                        'warped_cloth': warped_result['warped_cloth'],
                        'control_points': warped_result.get('control_points', []),
                        'confidence': warped_result.get('confidence', 0.8),
                        'ai_success': True,
                        'model_type': self.ai_model_wrapper.model_type,
                        'device_used': self.device
                    }
            
            # í´ë°±: AI ê¸°ë°˜ TPS ì›Œí•‘
            self.logger.warning("âš ï¸ AI ëª¨ë¸ ì—†ìŒ - AI TPS í´ë°± ì›Œí•‘ ì‚¬ìš©")
            fallback_result = self._fallback_ai_tps_warping(cloth_image, person_image)
            
            return {
                'warped_cloth': fallback_result['warped_cloth'],
                'control_points': fallback_result.get('control_points', []),
                'confidence': 0.6,
                'ai_success': False,
                'model_type': 'ai_tps_fallback',
                'device_used': self.device
            }
        
        except Exception as e:
            self.logger.error(f"âŒ AI ì¶”ë¡  ì‹¤íŒ¨: {e}")
            raise RuntimeError(f"AI ì¶”ë¡  ì‹¤íŒ¨: {e}")
    
    async def _run_ai_warping(self, cloth_image: np.ndarray, person_image: np.ndarray) -> Dict[str, Any]:
        """ì‹¤ì œ AI ëª¨ë¸ë¡œ ì›Œí•‘ ì‹¤í–‰"""
        try:
            # í…ì„œ ë³€í™˜
            cloth_tensor = self._image_to_tensor(cloth_image)
            person_tensor = self._image_to_tensor(person_image)
            
            # AI ëª¨ë¸ ì¶”ë¡ 
            with torch.no_grad():
                warped_tensor = self.ai_model_wrapper.warp_cloth(cloth_tensor, person_tensor)
            
            # ê²°ê³¼ ë³€í™˜
            warped_cloth = self._tensor_to_image(warped_tensor)
            
            # í’ˆì§ˆ í‰ê°€
            confidence = self._calculate_warping_confidence(warped_cloth, cloth_image)
            
            # ì»¨íŠ¸ë¡¤ í¬ì¸íŠ¸ ì¶”ì¶œ
            control_points = self._extract_control_points_from_result(warped_cloth, cloth_image)
            
            self.logger.info(f"âœ… ì‹¤ì œ AI ì›Œí•‘ ì™„ë£Œ - ì‹ ë¢°ë„: {confidence:.3f}")
            
            return {
                'success': True,
                'warped_cloth': warped_cloth,
                'control_points': control_points,
                'confidence': confidence
            }
            
        except Exception as e:
            self.logger.error(f"âŒ ì‹¤ì œ AI ì›Œí•‘ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            return {
                'success': False,
                'error': str(e)
            }
    
    def _fallback_ai_tps_warping(self, cloth_image: np.ndarray, person_image: np.ndarray) -> Dict[str, Any]:
        """AI ê¸°ë°˜ TPS í´ë°± ì›Œí•‘"""
        try:
            if self.tps_transform is None:
                # AI ê¸°ë°˜ ê°„ë‹¨í•œ ë³€í˜•
                return {
                    'warped_cloth': self._apply_ai_simple_transformation(cloth_image),
                    'control_points': []
                }
            
            h, w = cloth_image.shape[:2]
            
            # ì œì–´ì  ìƒì„±
            source_points = self.tps_transform.create_adaptive_control_grid(w, h)
            
            # AI ê¸°ë°˜ íƒ€ê²Ÿ í¬ì¸íŠ¸ ìƒì„±
            target_points = source_points.copy()
            target_points[:, 0] += np.random.normal(0, 5, len(target_points))
            target_points[:, 1] += np.random.normal(0, 5, len(target_points))
            
            # AI ê¸°ë°˜ TPS ë³€í™˜ ì ìš©
            warped_cloth = self.tps_transform.apply_transform(cloth_image, source_points, target_points)
            
            return {
                'warped_cloth': warped_cloth,
                'control_points': target_points.tolist()
            }
            
        except Exception as e:
            self.logger.error(f"AI TPS í´ë°± ì›Œí•‘ ì‹¤íŒ¨: {e}")
            return {
                'warped_cloth': self._apply_ai_simple_transformation(cloth_image),
                'control_points': []
            }
    
    def _apply_ai_simple_transformation(self, cloth_image: np.ndarray) -> np.ndarray:
        """AI ê¸°ë°˜ ê°„ë‹¨í•œ ë³€í˜• ì ìš© (ìµœí›„ì˜ í´ë°±)"""
        try:
            # AI ê¸°ë°˜ ë¯¸ì„¸í•œ í¬ê¸° ì¡°ì •
            h, w = cloth_image.shape[:2]
            new_h = int(h * 1.02)
            new_w = int(w * 1.01)
            
            # AI í”„ë¡œì„¸ì„œë¥¼ ì‚¬ìš©í•œ ë¦¬ì‚¬ì´ì§•
            scaled = self.ai_processor.ai_resize(cloth_image, (new_w, new_h))
            
            # ì›ë˜ í¬ê¸°ë¡œ í¬ë¡­
            if new_h > h and new_w > w:
                start_y = (new_h - h) // 2
                start_x = (new_w - w) // 2
                transformed = scaled[start_y:start_y+h, start_x:start_x+w]
            else:
                transformed = self.ai_processor.ai_resize(scaled, (w, h))
            
            return transformed
            
        except Exception:
            return cloth_image
    
    async def _enhance_with_physics(self, data: Dict[str, Any], **kwargs) -> Dict[str, Any]:
        """AI ê°•í™” ë¬¼ë¦¬ ì‹œë®¬ë ˆì´ì…˜ìœ¼ë¡œ ì›Œí•‘ ê²°ê³¼ ê°œì„ """
        try:
            if not self.warping_config.physics_enabled:
                return {'physics_applied': False}
            
            warped_cloth = data.get('warped_cloth')
            if warped_cloth is None:
                return {'physics_applied': False}
            
            fabric_type = data.get('fabric_type', 'cotton')
            
            # ë¬¼ë¦¬ ì‹œë®¬ë ˆì´í„° ì´ˆê¸°í™”
            if self.physics_simulator is None:
                try:
                    fabric_properties = PhysicsProperties(
                        fabric_type=FabricType(fabric_type.lower()) if fabric_type.lower() in [ft.value for ft in FabricType] else FabricType.COTTON
                    )
                    self.physics_simulator = ClothPhysicsSimulator(fabric_properties)
                except Exception as e:
                    self.logger.warning(f"ë¬¼ë¦¬ ì‹œë®¬ë ˆì´í„° ìƒì„± ì‹¤íŒ¨: {e}")
                    return {'physics_applied': False}
            
            # AI ê¸°ë°˜ ì¤‘ë ¥ íš¨ê³¼ ì ìš©
            physics_enhanced = self._apply_ai_gravity_effect(warped_cloth)
            
            # AI ê¸°ë°˜ ì›ë‹¨ íŠ¹ì„± ì ìš©
            fabric_enhanced = self._apply_ai_fabric_properties(physics_enhanced, fabric_type)
            
            return {
                'physics_corrected_cloth': fabric_enhanced,
                'physics_applied': True
            }
            
        except Exception as e:
            self.logger.warning(f"AI ë¬¼ë¦¬ ê°œì„  ì‹¤íŒ¨: {e}")
            return {
                'physics_corrected_cloth': data.get('warped_cloth'),
                'physics_applied': False
            }
    
    def _apply_ai_gravity_effect(self, cloth_image: np.ndarray) -> np.ndarray:
        """AI ê¸°ë°˜ ì¤‘ë ¥ íš¨ê³¼ ì ìš©"""
        try:
            h, w = cloth_image.shape[:2]
            
            # AI ê¸°ë°˜ ê¸°í•˜í•™ì  ë³€í™˜
            transform_matrix = np.array([
                [1.0, 0.0, 0.0],
                [0.02, 1.05, 0.0],
                [0.0, 0.0, 1.0]
            ], dtype=np.float32)
            
            return self.ai_processor.ai_geometric_transform(cloth_image, transform_matrix)
            
        except Exception:
            return cloth_image
    
    def _apply_ai_fabric_properties(self, cloth_image: np.ndarray, fabric_type: str) -> np.ndarray:
        """AI ê¸°ë°˜ ì›ë‹¨ íŠ¹ì„± ì ìš©"""
        try:
            fabric_properties = {
                'cotton': {'stiffness': 0.3, 'elasticity': 0.2},
                'silk': {'stiffness': 0.1, 'elasticity': 0.4},
                'denim': {'stiffness': 0.8, 'elasticity': 0.1},
                'wool': {'stiffness': 0.5, 'elasticity': 0.3}
            }
            
            props = fabric_properties.get(fabric_type, fabric_properties['cotton'])
            
            # AI ê¸°ë°˜ ë¸”ëŸ¬ íš¨ê³¼ (íƒ„ì„± ì‹œë®¬ë ˆì´ì…˜)
            if props['elasticity'] > 0.3 and TORCH_AVAILABLE:
                # PyTorch ê¸°ë°˜ ê°€ìš°ì‹œì•ˆ ë¸”ëŸ¬
                tensor = torch.from_numpy(cloth_image).permute(2, 0, 1).unsqueeze(0).float() / 255.0
                tensor = tensor.to(self.device)
                
                kernel_size = max(3, int(5 * props['elasticity']))
                if kernel_size % 2 == 0:
                    kernel_size += 1
                
                # ê°„ë‹¨í•œ ë¸”ëŸ¬ íš¨ê³¼
                blurred = F.avg_pool2d(F.pad(tensor, (kernel_size//2,)*4, mode='reflect'), 
                                     kernel_size, stride=1)
                
                result = blurred.squeeze(0).permute(1, 2, 0).cpu().numpy()
                return (result * 255).astype(np.uint8)
            
            return cloth_image
            
        except Exception:
            return cloth_image
    
    async def _postprocess_warping_results(self, data: Dict[str, Any], **kwargs) -> Dict[str, Any]:
        """AI ê¸°ë°˜ ì›Œí•‘ ê²°ê³¼ í›„ì²˜ë¦¬ (NumPy ì¡°ê±´ë¬¸ ì˜¤ë¥˜ ìˆ˜ì •)"""
        try:
            warped_cloth = data.get('warped_cloth') or data.get('physics_corrected_cloth')
            
            # NumPy ë°°ì—´ ê²€ì¦ ê°œì„ 
            if warped_cloth is None:
                raise RuntimeError("ì›Œí•‘ëœ ì˜ë¥˜ ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤")
            
            # ë°°ì—´ ìœ íš¨ì„± ê²€ì‚¬ (ì¡°ê±´ë¬¸ ì˜¤ë¥˜ ë°©ì§€)
            if not hasattr(warped_cloth, 'shape'):
                raise RuntimeError("ìœ íš¨í•˜ì§€ ì•Šì€ ì›Œí•‘ ê²°ê³¼ (shape ì†ì„± ì—†ìŒ)")
            
            if warped_cloth.size == 0:
                raise RuntimeError("ë¹ˆ ì›Œí•‘ ê²°ê³¼ ë°°ì—´")
            
            # AI ê¸°ë°˜ ì´ë¯¸ì§€ í’ˆì§ˆ í–¥ìƒ
            try:
                enhanced_cloth = self._enhance_warped_cloth_ai(warped_cloth)
            except Exception as e:
                self.logger.warning(f"AI í’ˆì§ˆ í–¥ìƒ ì‹¤íŒ¨: {e}")
                enhanced_cloth = warped_cloth
            
            # AI ê¸°ë°˜ ê²½ê³„ ë¶€ë“œëŸ½ê²Œ ì²˜ë¦¬
            try:
                smoothed_cloth = self._smooth_cloth_boundaries_ai(enhanced_cloth)
            except Exception as e:
                self.logger.warning(f"AI ê²½ê³„ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                smoothed_cloth = enhanced_cloth
            
            return {
                'final_warped_cloth': smoothed_cloth,
                'postprocessing_applied': True
            }
            
        except Exception as e:
            self.logger.error(f"âŒ AI í›„ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            # ì•ˆì „í•œ í´ë°±
            fallback_cloth = data.get('warped_cloth') or data.get('physics_corrected_cloth')
            if fallback_cloth is not None and hasattr(fallback_cloth, 'shape') and fallback_cloth.size > 0:
                return {
                    'final_warped_cloth': fallback_cloth,
                    'postprocessing_applied': False
                }
            else:
                # ìµœí›„ì˜ í´ë°± - ë”ë¯¸ ì´ë¯¸ì§€
                dummy_cloth = np.ones((384, 512, 3), dtype=np.uint8) * 128
                return {
                    'final_warped_cloth': dummy_cloth,
                    'postprocessing_applied': False
                }
    
    def _enhance_warped_cloth_ai(self, cloth_image: np.ndarray) -> np.ndarray:
        """AI ê¸°ë°˜ ì›Œí•‘ëœ ì˜ë¥˜ ì´ë¯¸ì§€ í’ˆì§ˆ í–¥ìƒ"""
        try:
            if TORCH_AVAILABLE:
                # PyTorch ê¸°ë°˜ ìƒ¤í”„ë‹
                tensor = torch.from_numpy(cloth_image).permute(2, 0, 1).unsqueeze(0).float() / 255.0
                tensor = tensor.to(self.device)
                
                # ìƒ¤í”„ë‹ ì»¤ë„
                sharpen_kernel = torch.tensor([
                    [0, -1, 0],
                    [-1, 5, -1],
                    [0, -1, 0]
                ], dtype=torch.float32).unsqueeze(0).unsqueeze(0).to(self.device)
                
                # ê° ì±„ë„ì— ì ìš©
                enhanced_channels = []
                for i in range(3):
                    channel = tensor[:, i:i+1, :, :]
                    enhanced = F.conv2d(F.pad(channel, (1,1,1,1), mode='reflect'), sharpen_kernel)
                    enhanced_channels.append(enhanced)
                
                enhanced_tensor = torch.cat(enhanced_channels, dim=1)
                enhanced_tensor = torch.clamp(enhanced_tensor, 0, 1)
                
                result = enhanced_tensor.squeeze(0).permute(1, 2, 0).cpu().numpy()
                return (result * 255).astype(np.uint8)
            
            # PIL í´ë°±
            pil_img = Image.fromarray(cloth_image)
            enhanced = ImageEnhance.Sharpness(pil_img).enhance(1.2)
            return np.array(enhanced)
            
        except Exception:
            return cloth_image
    
    def _smooth_cloth_boundaries_ai(self, cloth_image: np.ndarray) -> np.ndarray:
        """AI ê¸°ë°˜ ì˜ë¥˜ ê²½ê³„ ë¶€ë“œëŸ½ê²Œ ì²˜ë¦¬"""
        try:
            if TORCH_AVAILABLE:
                # PyTorch ê¸°ë°˜ ì—£ì§€ ë¸”ëŸ¬ë§
                tensor = torch.from_numpy(cloth_image).permute(2, 0, 1).unsqueeze(0).float() / 255.0
                tensor = tensor.to(self.device)
                
                # ê°€ìš°ì‹œì•ˆ ë¸”ëŸ¬
                blurred = F.avg_pool2d(F.pad(tensor, (10,10,10,10), mode='reflect'), 21, stride=1)
                
                # ì—£ì§€ ë§ˆìŠ¤í¬ ìƒì„±
                h, w = cloth_image.shape[:2]
                mask = torch.zeros((1, 1, h, w), device=self.device)
                border_width = 20
                mask[:, :, :border_width, :] = 1.0
                mask[:, :, -border_width:, :] = 1.0
                mask[:, :, :, :border_width] = 1.0
                mask[:, :, :, -border_width:] = 1.0
                
                # ë§ˆìŠ¤í¬ ì ìš©
                mask_3ch = mask.repeat(1, 3, 1, 1)
                smoothed_tensor = tensor * (1 - mask_3ch) + blurred * mask_3ch
                
                result = smoothed_tensor.squeeze(0).permute(1, 2, 0).cpu().numpy()
                return (result * 255).astype(np.uint8)
            
            # PIL í´ë°±
            pil_img = Image.fromarray(cloth_image)
            blurred = pil_img.filter(ImageFilter.GaussianBlur(radius=1))
            return np.array(blurred)
            
        except Exception:
            return cloth_image
    
    async def _analyze_warping_quality(self, data: Dict[str, Any], **kwargs) -> Dict[str, Any]:
        """AI ê¸°ë°˜ ì›Œí•‘ í’ˆì§ˆ ë¶„ì„"""
        try:
            warped_cloth = data.get('final_warped_cloth') or data.get('warped_cloth')
            original_cloth = data.get('cloth_image')
            
            if warped_cloth is None or original_cloth is None:
                return {
                    'quality_metrics': {},
                    'overall_quality': 0.5,
                    'quality_grade': 'C',
                    'quality_analysis_success': False
                }
            
            quality_metrics = {
                'texture_preservation': self._calculate_ai_texture_preservation(original_cloth, warped_cloth),
                'deformation_naturalness': self._calculate_ai_deformation_naturalness(warped_cloth),
                'edge_integrity': self._calculate_ai_edge_integrity(warped_cloth),
                'color_consistency': self._calculate_ai_color_consistency(original_cloth, warped_cloth)
            }
            
            overall_quality = np.mean(list(quality_metrics.values()))
            quality_grade = self._get_quality_grade(overall_quality)
            
            return {
                'quality_metrics': quality_metrics,
                'overall_quality': overall_quality,
                'quality_grade': quality_grade,
                'quality_analysis_success': True
            }
            
        except Exception as e:
            self.logger.error(f"âŒ AI í’ˆì§ˆ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {
                'quality_metrics': {},
                'overall_quality': 0.5,
                'quality_grade': 'C',
                'quality_analysis_success': False
            }
    
    async def _create_warping_visualization(self, data: Dict[str, Any], **kwargs) -> Dict[str, Any]:
        """AI ê¸°ë°˜ ì›Œí•‘ ì‹œê°í™” ìƒì„±"""
        try:
            if not self.warping_config.visualization_enabled:
                return {'visualization_success': False}
            
            cloth_image = data.get('cloth_image')
            warped_cloth = data.get('final_warped_cloth') or data.get('warped_cloth')
            control_points = data.get('control_points', [])
            
            if cloth_image is None or warped_cloth is None:
                return {'visualization_success': False}
            
            # AI ê¸°ë°˜ ì›ë³¸ê³¼ ì›Œí•‘ ê²°ê³¼ ë¹„êµ ì´ë¯¸ì§€
            comparison_viz = self._create_ai_comparison_visualization(cloth_image, warped_cloth)
            
            # AI ê¸°ë°˜ ê³ ê¸‰ ì‹œê°í™” (WarpingVisualizer ì‚¬ìš©)
            if self.visualizer:
                try:
                    advanced_viz = self.visualizer.create_warping_visualization(
                        cloth_image, warped_cloth, np.array(control_points) if control_points else np.array([])
                    )
                except Exception as e:
                    self.logger.warning(f"AI ê³ ê¸‰ ì‹œê°í™” ì‹¤íŒ¨: {e}")
                    advanced_viz = comparison_viz
            else:
                advanced_viz = comparison_viz
            
            return {
                'comparison_visualization': comparison_viz,
                'advanced_visualization': advanced_viz,
                'visualization_success': True
            }
            
        except Exception as e:
            self.logger.error(f"âŒ AI ì‹œê°í™” ìƒì„± ì‹¤íŒ¨: {e}")
            return {'visualization_success': False}
    
    def _create_ai_comparison_visualization(self, original: np.ndarray, warped: np.ndarray) -> np.ndarray:
        """AI ê¸°ë°˜ ì›ë³¸ê³¼ ì›Œí•‘ ê²°ê³¼ ë¹„êµ ì‹œê°í™”"""
        try:
            h, w = max(original.shape[0], warped.shape[0]), max(original.shape[1], warped.shape[1])
            
            # AI í”„ë¡œì„¸ì„œë¥¼ ì‚¬ìš©í•œ ë¦¬ì‚¬ì´ì§•
            orig_resized = self.ai_processor.ai_resize(original, (w, h))
            warp_resized = self.ai_processor.ai_resize(warped, (w, h))
            
            comparison = np.hstack([orig_resized, warp_resized])
            
            # AI ê¸°ë°˜ êµ¬ë¶„ì„  ë° ë¼ë²¨ ì¶”ê°€
            if self.visualizer:
                comparison = self.visualizer._draw_divider_line_ai(comparison, w, h)
                comparison = self.visualizer._add_labels_ai(comparison, w, h)
            
            return comparison
            
        except Exception as e:
            self.logger.warning(f"AI ë¹„êµ ì‹œê°í™” ìƒì„± ì‹¤íŒ¨: {e}")
            try:
                return np.hstack([original, warped])
            except:
                return original
    
    # ==============================================
    # ğŸ”§ ìœ í‹¸ë¦¬í‹° ë©”ì„œë“œë“¤ (AI ê¸°ë°˜)
    # ==============================================
    
    def _image_to_tensor(self, image: np.ndarray) -> torch.Tensor:
        """ì´ë¯¸ì§€ë¥¼ í…ì„œë¡œ ë³€í™˜"""
        try:
            # AI í”„ë¡œì„¸ì„œë¥¼ ì‚¬ìš©í•œ ìƒ‰ìƒ ë³€í™˜
            if len(image.shape) == 3 and image.shape[2] == 3:
                image_rgb = self.ai_processor.ai_color_conversion(image, "BGR2RGB")
            else:
                image_rgb = image
            
            # ì •ê·œí™” ë° ì°¨ì› ë³€ê²½
            normalized = image_rgb.astype(np.float32) / 255.0
            tensor = torch.from_numpy(normalized).permute(2, 0, 1).unsqueeze(0)
            return tensor.to(self.device)
        except Exception as e:
            self.logger.error(f"ì´ë¯¸ì§€->í…ì„œ ë³€í™˜ ì‹¤íŒ¨: {e}")
            raise
    
    def _tensor_to_image(self, tensor: torch.Tensor) -> np.ndarray:
        """í…ì„œë¥¼ ì´ë¯¸ì§€ë¡œ ë³€í™˜"""
        try:
            # CPUë¡œ ì´ë™ ë° numpy ë³€í™˜
            output_np = tensor.detach().cpu().numpy()
            
            # ë°°ì¹˜ ì°¨ì› ì œê±°
            if output_np.ndim == 4:
                output_np = output_np[0]
            
            # ì±„ë„ ìˆœì„œ ë³€ê²½ (C, H, W) -> (H, W, C)
            if output_np.shape[0] == 3:
                output_np = np.transpose(output_np, (1, 2, 0))
            
            # ì •ê·œí™” í•´ì œ ë° íƒ€ì… ë³€í™˜
            output_np = np.clip(output_np * 255.0, 0, 255).astype(np.uint8)
            
            # AI í”„ë¡œì„¸ì„œë¥¼ ì‚¬ìš©í•œ ìƒ‰ìƒ ë³€í™˜
            if len(output_np.shape) == 3 and output_np.shape[2] == 3:
                output_np = self.ai_processor.ai_color_conversion(output_np, "RGB2BGR")
            
            return output_np
            
        except Exception as e:
            self.logger.error(f"í…ì„œ->ì´ë¯¸ì§€ ë³€í™˜ ì‹¤íŒ¨: {e}")
            raise
    
    def _calculate_warping_confidence(self, warped_cloth: np.ndarray, original_cloth: np.ndarray) -> float:
        """AI ê¸°ë°˜ ì›Œí•‘ ì‹ ë¢°ë„ ê³„ì‚°"""
        try:
            if warped_cloth.shape != original_cloth.shape:
                original_resized = self.ai_processor.ai_resize(original_cloth, warped_cloth.shape[:2][::-1])
            else:
                original_resized = original_cloth
            
            if SKIMAGE_AVAILABLE:
                from skimage.metrics import structural_similarity as ssim
                # AI í”„ë¡œì„¸ì„œë¥¼ ì‚¬ìš©í•œ ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜
                orig_gray = self.ai_processor.ai_color_conversion(original_resized, "RGB2GRAY")
                warp_gray = self.ai_processor.ai_color_conversion(warped_cloth, "RGB2GRAY")
                confidence = ssim(orig_gray, warp_gray)
            else:
                diff = np.mean(np.abs(original_resized.astype(float) - warped_cloth.astype(float)))
                confidence = max(0.0, 1.0 - diff / 255.0)
            
            return float(np.clip(confidence, 0.0, 1.0))
            
        except Exception:
            return 0.8
    
    def _extract_control_points_from_result(self, warped_cloth: np.ndarray, original_cloth: np.ndarray) -> List[Tuple[int, int]]:
        """ê²°ê³¼ì—ì„œ ì»¨íŠ¸ë¡¤ í¬ì¸íŠ¸ ì¶”ì¶œ"""
        try:
            h, w = warped_cloth.shape[:2]
            num_points = self.warping_config.num_control_points
            
            grid_size = int(np.sqrt(num_points))
            if grid_size * grid_size < num_points:
                grid_size += 1
            
            x_coords = np.linspace(0, w-1, grid_size, dtype=int)
            y_coords = np.linspace(0, h-1, grid_size, dtype=int)
            
            control_points = []
            for y in y_coords:
                for x in x_coords:
                    if len(control_points) >= num_points:
                        break
                    control_points.append((int(x), int(y)))
            
            return control_points[:num_points]
            
        except Exception:
            return []
    
    def _calculate_ai_texture_preservation(self, original: np.ndarray, warped: np.ndarray) -> float:
        """AI ê¸°ë°˜ í…ìŠ¤ì²˜ ë³´ì¡´ë„ ê³„ì‚°"""
        try:
            if original.shape != warped.shape:
                original_resized = self.ai_processor.ai_resize(original, warped.shape[:2][::-1])
            else:
                original_resized = original
            
            # AI ê¸°ë°˜ ì—£ì§€ ê²€ì¶œë¡œ í…ìŠ¤ì²˜ ë¶„ì„
            orig_edges = self.ai_processor.ai_edge_detection(original_resized)
            warp_edges = self.ai_processor.ai_edge_detection(warped)
            
            orig_texture = np.var(orig_edges)
            warp_texture = np.var(warp_edges)
            
            if orig_texture == 0:
                return 1.0
            
            texture_ratio = min(warp_texture / orig_texture, orig_texture / warp_texture) if orig_texture > 0 else 1.0
            return float(np.clip(texture_ratio, 0.0, 1.0))
            
        except Exception:
            return 0.7
    
    def _calculate_ai_deformation_naturalness(self, warped_cloth: np.ndarray) -> float:
        """AI ê¸°ë°˜ ë³€í˜• ìì—°ìŠ¤ëŸ¬ì›€ ê³„ì‚°"""
        try:
            # AI ê¸°ë°˜ ì—£ì§€ ê²€ì¶œ
            edges = self.ai_processor.ai_edge_detection(warped_cloth)
            
            edge_density = np.sum(edges > 0) / edges.size
            optimal_density = 0.125
            naturalness = 1.0 - min(abs(edge_density - optimal_density) / optimal_density, 1.0)
            
            return float(np.clip(naturalness, 0.0, 1.0))
            
        except Exception:
            return 0.6
    
    def _calculate_ai_edge_integrity(self, warped_cloth: np.ndarray) -> float:
        """AI ê¸°ë°˜ ì—ì§€ ë¬´ê²°ì„± ê³„ì‚°"""
        try:
            # AI ê¸°ë°˜ ì—£ì§€ ê²€ì¶œ
            edges = self.ai_processor.ai_edge_detection(warped_cloth)
            
            # ê°„ë‹¨í•œ ì—°ê²°ì„± ë¶„ì„
            edge_pixels = np.sum(edges > 0)
            total_pixels = edges.size
            
            if edge_pixels == 0:
                return 0.5
            
            edge_ratio = edge_pixels / total_pixels
            integrity = min(edge_ratio * 10, 1.0)  # ì •ê·œí™”
            
            return float(np.clip(integrity, 0.0, 1.0))
            
        except Exception:
            return 0.6
    
    def _calculate_ai_color_consistency(self, original: np.ndarray, warped: np.ndarray) -> float:
        """AI ê¸°ë°˜ ìƒ‰ìƒ ì¼ê´€ì„± ê³„ì‚°"""
        try:
            if original.shape != warped.shape:
                original_resized = self.ai_processor.ai_resize(original, warped.shape[:2][::-1])
            else:
                original_resized = original
            
            # ìƒ‰ìƒ íˆìŠ¤í† ê·¸ë¨ ë¹„êµ
            orig_mean = np.mean(original_resized, axis=(0, 1))
            warp_mean = np.mean(warped, axis=(0, 1))
            
            color_diff = np.mean(np.abs(orig_mean - warp_mean))
            consistency = max(0.0, 1.0 - color_diff / 255.0)
            
            return float(np.clip(consistency, 0.0, 1.0))
            
        except Exception:
            return 0.8
    
    def _calculate_overall_warping_score(self, data: Dict[str, Any], clothing_type: str) -> float:
        """ì „ì²´ ì›Œí•‘ ì ìˆ˜ ê³„ì‚°"""
        try:
            clothing_weights = CLOTHING_WARPING_WEIGHTS.get(clothing_type, CLOTHING_WARPING_WEIGHTS['default'])
            
            ai_score = data.get('confidence', 0.0)
            physics_score = 1.0 if data.get('physics_applied', False) else 0.5
            quality_score = data.get('overall_quality', 0.5)
            
            overall_score = (
                ai_score * clothing_weights.get('deformation', 0.4) +
                physics_score * clothing_weights.get('physics', 0.3) +
                quality_score * clothing_weights.get('texture', 0.3)
            )
            
            return float(np.clip(overall_score, 0.0, 1.0))
            
        except Exception:
            return 0.5
    
    def _get_quality_grade(self, score: float) -> str:
        """ì ìˆ˜ë¥¼ ë“±ê¸‰ìœ¼ë¡œ ë³€í™˜"""
        if score >= 0.9:
            return "A+"
        elif score >= 0.8:
            return "A"
        elif score >= 0.7:
            return "B"
        elif score >= 0.6:
            return "C"
        elif score >= 0.5:
            return "D"
        else:
            return "F"
    
    def _load_and_validate_image(self, image_input: Union[np.ndarray, str, Path, Image.Image]) -> Optional[np.ndarray]:
        """ì´ë¯¸ì§€ ë¡œë“œ ë° ê²€ì¦"""
        try:
            if isinstance(image_input, np.ndarray):
                return image_input
            elif isinstance(image_input, Image.Image):
                # AI í”„ë¡œì„¸ì„œë¥¼ ì‚¬ìš©í•œ ìƒ‰ìƒ ë³€í™˜
                img_array = np.array(image_input)
                return self.ai_processor.ai_color_conversion(img_array, "RGB2BGR")
            elif isinstance(image_input, (str, Path)):
                # PILë¡œ ë¡œë“œ í›„ AI í”„ë¡œì„¸ì„œë¡œ ë³€í™˜
                pil_img = Image.open(str(image_input))
                img_array = np.array(pil_img)
                return self.ai_processor.ai_color_conversion(img_array, "RGB2BGR")
            else:
                return None
        except Exception as e:
            self.logger.error(f"ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return None
    
    def _generate_cache_key(self, cloth_image: np.ndarray, person_image: np.ndarray, clothing_type: str, kwargs: Dict) -> str:
        """ìºì‹œ í‚¤ ìƒì„±"""
        try:
            cloth_hash = hashlib.md5(cloth_image.tobytes()).hexdigest()[:8]
            person_hash = hashlib.md5(person_image.tobytes()).hexdigest()[:8]
            
            config_str = f"{clothing_type}_{self.warping_config.warping_method.value}_{kwargs}"
            config_hash = hashlib.md5(config_str.encode()).hexdigest()[:8]
            
            return f"ai_warping_{cloth_hash}_{person_hash}_{config_hash}"
            
        except Exception:
            return f"ai_warping_fallback_{int(time.time())}"
    
    def _save_to_cache(self, cache_key: str, result: Dict[str, Any]):
        """ìºì‹œì— ê²°ê³¼ ì €ì¥"""
        try:
            if len(self.prediction_cache) >= self.warping_config.cache_size:
                oldest_key = next(iter(self.prediction_cache))
                del self.prediction_cache[oldest_key]
            
            # í° ì´ë¯¸ì§€ ë°ì´í„°ëŠ” ìºì‹œì—ì„œ ì œì™¸
            cache_result = result.copy()
            exclude_keys = [
                'final_warped_cloth', 'warped_cloth', 'comparison_visualization',
                'advanced_visualization'
            ]
            for key in exclude_keys:
                cache_result.pop(key, None)
            
            self.prediction_cache[cache_key] = cache_result
            
            # ìºì‹œ íˆíŠ¸ ì¹´ìš´íŠ¸ (v16.0 í˜¸í™˜)
            if hasattr(self, 'performance_metrics'):
                self.performance_metrics['cache_hits'] = self.performance_metrics.get('cache_hits', 0) + 1
            
        except Exception as e:
            self.logger.warning(f"ìºì‹œ ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def _build_final_warping_result(self, warping_data: Dict[str, Any], clothing_type: str, processing_time: float) -> Dict[str, Any]:
        """ìµœì¢… ì›Œí•‘ ê²°ê³¼ êµ¬ì„±"""
        try:
            result = {
                "success": True,
                "step_name": self.step_name,
                "processing_time": processing_time,
                "clothing_type": clothing_type,
                
                # AI ì›Œí•‘ ê²°ê³¼
                "warped_cloth_image": warping_data.get('final_warped_cloth') or warping_data.get('warped_cloth'),
                "control_points": warping_data.get('control_points', []),
                "confidence": warping_data.get('confidence', 0.0),
                
                # AI í’ˆì§ˆ í‰ê°€
                "quality_grade": warping_data.get('quality_grade', 'F'),
                "overall_score": warping_data.get('overall_score', 0.0),
                "quality_metrics": warping_data.get('quality_metrics', {}),
                
                # AI ì›Œí•‘ ë¶„ì„
                "warping_analysis": {
                    "ai_success": warping_data.get('ai_success', False),
                    "physics_applied": warping_data.get('physics_applied', False),
                    "postprocessing_applied": warping_data.get('postprocessing_applied', False),
                    "model_type": warping_data.get('model_type', 'unknown'),
                    "warping_method": self.warping_config.warping_method.value,
                    "ai_model_enabled": self.warping_config.ai_model_enabled
                },
                
                # ì í•©ì„± í‰ê°€
                "suitable_for_fitting": warping_data.get('overall_score', 0.0) >= 0.6,
                "fitting_confidence": min(warping_data.get('confidence', 0.0) * 1.2, 1.0),
                
                # AI ì‹œê°í™”
                "visualization": warping_data.get('comparison_visualization'),
                "advanced_visualization": warping_data.get('advanced_visualization'),
                "visualization_success": warping_data.get('visualization_success', False),
                
                # ë©”íƒ€ë°ì´í„°
                "from_cache": False,
                "device_info": {
                    "device": self.device,
                    "model_loader_used": self.model_loader is not None,
                    "ai_model_loaded": self.ai_model_wrapper is not None and self.ai_model_wrapper.is_loaded,
                    "warping_method": self.warping_config.warping_method.value,
                    "strict_mode": self.warping_config.strict_mode,
                    "ai_processor_enabled": True,
                    "opencv_replaced": True
                },
                
                # ì„±ëŠ¥ ì •ë³´ (v16.0 í˜¸í™˜)
                "performance_stats": getattr(self, 'performance_metrics', {}),
                
                # íŒŒì´í”„ë¼ì¸ ì •ë³´
                "pipeline_results": warping_data.get('pipeline_results', {}),
                
                # AI ëª¨ë¸ ì •ë³´
                "ai_model_info": {
                    "wrapper_loaded": self.ai_model_wrapper is not None,
                    "wrapper_type": getattr(self.ai_model_wrapper, 'model_type', None) if self.ai_model_wrapper else None,
                    "ai_processor_ready": self.ai_processor is not None,
                    "torch_available": TORCH_AVAILABLE,
                    "transformers_available": TRANSFORMERS_AVAILABLE
                }
            }
            
            return result
            
        except Exception as e:
            self.logger.error(f"ìµœì¢… ê²°ê³¼ êµ¬ì„± ì‹¤íŒ¨: {e}")
            raise RuntimeError(f"ê²°ê³¼ êµ¬ì„± ì‹¤íŒ¨: {e}")
    
    # ==============================================
    # ğŸ”§ ì‹œìŠ¤í…œ ê´€ë¦¬ ë©”ì„œë“œë“¤ (v16.0 í˜¸í™˜)
    # ==============================================
    
    def get_cache_status(self) -> Dict[str, Any]:
        """ìºì‹œ ìƒíƒœ ë°˜í™˜"""
        try:
            cache_hits = getattr(self, 'performance_metrics', {}).get('cache_hits', 0)
            cache_misses = getattr(self, 'performance_metrics', {}).get('cache_misses', 0)
            
            return {
                "enabled": self.warping_config.cache_enabled,
                "current_size": len(self.prediction_cache),
                "max_size": self.warping_config.cache_size,
                "hit_rate": cache_hits / max(1, cache_hits + cache_misses),
                "total_hits": cache_hits,
                "total_misses": cache_misses
            }
        except Exception as e:
            self.logger.error(f"ìºì‹œ ìƒíƒœ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {"error": str(e)}
    
    def clear_cache(self):
        """ìºì‹œ ì •ë¦¬"""
        try:
            self.prediction_cache.clear()
            self.logger.info("âœ… AI ì›Œí•‘ ìºì‹œ ì •ë¦¬ ì™„ë£Œ")
        except Exception as e:
            self.logger.error(f"âŒ ìºì‹œ ì •ë¦¬ ì‹¤íŒ¨: {e}")
    
    def cleanup_resources(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬ (v16.0 í˜¸í™˜)"""
        try:
            # AI ëª¨ë¸ ë˜í¼ ì •ë¦¬
            if hasattr(self, 'ai_model_wrapper') and self.ai_model_wrapper:
                del self.ai_model_wrapper
                self.ai_model_wrapper = None
            
            # AI í”„ë¡œì„¸ì„œ ì •ë¦¬
            if hasattr(self, 'ai_processor') and self.ai_processor:
                del self.ai_processor
                self.ai_processor = None
            
            # ìºì‹œ ì •ë¦¬
            if hasattr(self, 'prediction_cache'):
                self.prediction_cache.clear()
            
            # ë¬¼ë¦¬ ì‹œë®¬ë ˆì´í„° ì •ë¦¬
            if hasattr(self, 'physics_simulator') and self.physics_simulator:
                del self.physics_simulator
                self.physics_simulator = None
            
            # BaseStepMixin ì •ë¦¬ (v16.0 í˜¸í™˜)
            if hasattr(super(), 'cleanup_models'):
                super().cleanup_models()
            
            # PyTorch ë©”ëª¨ë¦¬ ì •ë¦¬
            if TORCH_AVAILABLE:
                if self.device == "mps" and MPS_AVAILABLE:
                    if hasattr(torch.backends.mps, 'empty_cache'):
                        torch.backends.mps.empty_cache()
                elif self.device == "cuda" and torch.cuda.is_available():
                    torch.cuda.empty_cache()
            
            gc.collect()
            
            self.logger.info("âœ… ClothWarpingStep AI ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì™„ë£Œ")
            
        except Exception as e:
            self.logger.warning(f"ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì‹¤íŒ¨: {e}")
    
    def get_system_info(self) -> Dict[str, Any]:
        """ì‹œìŠ¤í…œ ì •ë³´ ë°˜í™˜ (v16.0 í˜¸í™˜)"""
        try:
            # BaseStepMixin ì •ë³´ (v16.0 í˜¸í™˜)
            if hasattr(super(), 'get_status'):
                base_info = super().get_status()
            else:
                base_info = {
                    'step_name': self.step_name,
                    'is_initialized': getattr(self, 'is_initialized', False),
                    'device': self.device
                }
            
            # ClothWarpingStep AI íŠ¹í™” ì •ë³´
            warping_info = {
                "warping_config": {
                    "warping_method": self.warping_config.warping_method.value,
                    "input_size": self.warping_config.input_size,
                    "ai_model_enabled": self.warping_config.ai_model_enabled,
                    "physics_enabled": self.warping_config.physics_enabled,
                    "visualization_enabled": self.warping_config.visualization_enabled,
                    "cache_enabled": self.warping_config.cache_enabled,
                    "quality_level": self.warping_config.quality_level,
                    "strict_mode": self.warping_config.strict_mode
                },
                "ai_model_info": {
                    "ai_model_wrapper_loaded": hasattr(self, 'ai_model_wrapper') and self.ai_model_wrapper is not None,
                    "ai_model_type": getattr(self.ai_model_wrapper, 'model_type', None) if hasattr(self, 'ai_model_wrapper') and self.ai_model_wrapper else None,
                    "ai_model_ready": getattr(self.ai_model_wrapper, 'is_loaded', False) if hasattr(self, 'ai_model_wrapper') and self.ai_model_wrapper else False,
                    "ai_processor_ready": hasattr(self, 'ai_processor') and self.ai_processor is not None,
                    "opencv_replaced": True
                },
                "cache_info": {
                    "cache_size": len(self.prediction_cache) if hasattr(self, 'prediction_cache') else 0,
                    "cache_limit": self.warping_config.cache_size
                },
                "pipeline_info": {
                    "pipeline_steps": len(self.processing_pipeline) if hasattr(self, 'processing_pipeline') else 0,
                    "step_names": [stage.value for stage, _ in self.processing_pipeline] if hasattr(self, 'processing_pipeline') else []
                },
                "dependencies_info": {
                    "model_loader_injected": getattr(self, 'model_loader', None) is not None,
                    "di_container_injected": getattr(self, 'di_container', None) is not None,
                    "dependency_manager_ready": hasattr(self, 'dependency_manager') and self.dependency_manager is not None,
                    "torch_available": TORCH_AVAILABLE,
                    "mps_available": MPS_AVAILABLE,
                    "transformers_available": TRANSFORMERS_AVAILABLE,
                    "skimage_available": SKIMAGE_AVAILABLE,
                    "base_step_mixin_available": BASE_STEP_MIXIN_AVAILABLE
                },
                "system_optimization": {
                    "m3_max_detected": IS_M3_MAX,
                    "conda_env": CONDA_INFO['conda_env'],
                    "device_optimization": self.device in ["mps", "cuda"],
                    "ai_processing_enabled": True
                }
            }
            
            # ê¸°ë³¸ ì •ë³´ì™€ ë³‘í•©
            base_info.update(warping_info)
            return base_info
        except Exception as e:
            self.logger.error(f"ì‹œìŠ¤í…œ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {"error": f"ì‹œìŠ¤í…œ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {e}"}
    
    async def warmup_async(self) -> Dict[str, Any]:
        """ì›Œë°ì—… ì‹¤í–‰ (v16.0 í˜¸í™˜)"""
        try:
            # BaseStepMixin ì›Œë°ì—… (v16.0 í˜¸í™˜)
            if hasattr(super(), 'warmup_async'):
                base_warmup = await super().warmup_async()
            else:
                base_warmup = {"success": True, "base_warmup": "not_available"}
            
            # ClothWarpingStep AI íŠ¹í™” ì›Œë°ì—…
            warping_warmup_results = []
            
            # AI ëª¨ë¸ ì›Œë°ì—…
            if hasattr(self, 'ai_model_wrapper') and self.ai_model_wrapper and self.ai_model_wrapper.is_loaded:
                try:
                    dummy_tensor = torch.randn(1, 3, *self.warping_config.input_size[::-1]).to(self.device)
                    _ = self.ai_model_wrapper.warp_cloth(dummy_tensor, dummy_tensor)
                    warping_warmup_results.append("ai_model_warmup_success")
                except Exception as e:
                    self.logger.debug(f"AI ëª¨ë¸ ì›Œë°ì—… ì‹¤íŒ¨: {e}")
                    warping_warmup_results.append("ai_model_warmup_failed")
            else:
                warping_warmup_results.append("ai_model_not_available")
            
            # AI í”„ë¡œì„¸ì„œ ì›Œë°ì—…
            if hasattr(self, 'ai_processor') and self.ai_processor:
                try:
                    dummy_image = np.random.randint(0, 255, (128, 128, 3), dtype=np.uint8)
                    _ = self.ai_processor.ai_resize(dummy_image, (256, 256))
                    warping_warmup_results.append("ai_processor_warmup_success")
                except Exception as e:
                    self.logger.debug(f"AI í”„ë¡œì„¸ì„œ ì›Œë°ì—… ì‹¤íŒ¨: {e}")
                    warping_warmup_results.append("ai_processor_warmup_failed")
            else:
                warping_warmup_results.append("ai_processor_not_available")
            
            # TPS ë³€í™˜ ì›Œë°ì—…
            if hasattr(self, 'tps_transform') and self.tps_transform:
                try:
                    dummy_image = np.random.randint(0, 255, (128, 128, 3), dtype=np.uint8)
                    control_points = self.tps_transform.create_adaptive_control_grid(128, 128)
                    _ = self.tps_transform.apply_transform(dummy_image, control_points, control_points)
                    warping_warmup_results.append("ai_tps_warmup_success")
                except Exception as e:
                    self.logger.debug(f"AI TPS ì›Œë°ì—… ì‹¤íŒ¨: {e}")
                    warping_warmup_results.append("ai_tps_warmup_failed")
            else:
                warping_warmup_results.append("ai_tps_not_available")
            
            # ê²°ê³¼ í†µí•©
            base_warmup['warping_specific_results'] = warping_warmup_results
            base_warmup['warping_warmup_success'] = any('success' in result for result in warping_warmup_results)
            base_warmup['ai_integration_complete'] = True
            
            return base_warmup
            
        except Exception as e:
            self.logger.error(f"âŒ AI ì›Œí•‘ ì›Œë°ì—… ì‹¤íŒ¨: {e}")
            return {"success": False, "error": str(e), "warping_warmup": False}
    
    def __del__(self):
        """ì†Œë©¸ì (ì•ˆì „í•œ ì •ë¦¬)"""
        try:
            self.cleanup_resources()
        except Exception:
            pass

# ==============================================
# ğŸ”¥ íŒ©í† ë¦¬ í•¨ìˆ˜ë“¤ (v16.0 í˜¸í™˜)
# ==============================================

async def create_cloth_warping_step(
    device: str = "auto",
    config: Optional[Dict[str, Any]] = None,
    **kwargs
) -> ClothWarpingStep:
    """
    ClothWarpingStep ìƒì„± - v16.0 í˜¸í™˜
    """
    try:
        # ë””ë°”ì´ìŠ¤ ì²˜ë¦¬
        if device == "auto":
            if TORCH_AVAILABLE:
                if MPS_AVAILABLE:
                    device_param = "mps"
                elif torch.cuda.is_available():
                    device_param = "cuda"
                else:
                    device_param = "cpu"
            else:
                device_param = "cpu"
        else:
            device_param = device
        
        # config í†µí•©
        if config is None:
            config = {}
        config.update(kwargs)
        config['device'] = device_param
        
        # AI Step ìƒì„± (ClothWarpingMixin ê¸°ë°˜)
        step = ClothWarpingStep(**config)
        
        # ì´ˆê¸°í™” (ì˜ì¡´ì„± ì£¼ì… í›„ í˜¸ì¶œë  ê²ƒ)
        if not step.is_initialized:
            await step.initialize()
        
        return step
        
    except Exception as e:
        logger = logging.getLogger(__name__)
        logger.error(f"âŒ create_cloth_warping_step ì‹¤íŒ¨: {e}")
        raise RuntimeError(f"AI ClothWarpingStep ìƒì„± ì‹¤íŒ¨: {e}")

def create_cloth_warping_step_sync(
    device: str = "auto",
    config: Optional[Dict[str, Any]] = None,
    **kwargs
) -> ClothWarpingStep:
    """ë™ê¸°ì‹ ClothWarpingStep ìƒì„±"""
    try:
        try:
            loop = asyncio.get_event_loop()
        except RuntimeError:
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
        
        return loop.run_until_complete(
            create_cloth_warping_step(device, config, **kwargs)
        )
    except Exception as e:
        logger = logging.getLogger(__name__)
        logger.error(f"âŒ create_cloth_warping_step_sync ì‹¤íŒ¨: {e}")
        raise RuntimeError(f"ë™ê¸°ì‹ AI ClothWarpingStep ìƒì„± ì‹¤íŒ¨: {e}")

def create_m3_max_cloth_warping_step(**kwargs) -> ClothWarpingStep:
    """M3 Max ìµœì í™”ëœ AI ClothWarpingStep ìƒì„±"""
    m3_max_config = {
        'device': 'mps',
        'is_m3_max': True,
        'optimization_enabled': True,
        'memory_gb': 128,
        'quality_level': 'ultra',
        'warping_method': WarpingMethod.AI_MODEL,
        'ai_model_enabled': True,
        'physics_enabled': True,
        'visualization_enabled': True,
        'precision': 'fp16',
        'memory_fraction': 0.7,
        'cache_enabled': True,
        'cache_size': 100,
        'strict_mode': False
    }
    
    m3_max_config.update(kwargs)
    
    return ClothWarpingStep(**m3_max_config)

def create_production_cloth_warping_step(
    quality_level: str = "high",
    enable_ai_model: bool = True,
    **kwargs
) -> ClothWarpingStep:
    """í”„ë¡œë•ì…˜ í™˜ê²½ìš© AI ClothWarpingStep ìƒì„±"""
    production_config = {
        'quality_level': quality_level,
        'warping_method': WarpingMethod.AI_MODEL if enable_ai_model else WarpingMethod.TPS_CLASSICAL,
        'ai_model_enabled': enable_ai_model,
        'physics_enabled': True,
        'visualization_enabled': True,
        'cache_enabled': True,
        'cache_size': 50,
        'strict_mode': False
    }
    
    production_config.update(kwargs)
    
    return ClothWarpingStep(**production_config)

# ==============================================
# ğŸ†• ì¶”ê°€ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤ (AI ê°•í™”)
# ==============================================

def validate_warping_result(result: Dict[str, Any]) -> bool:
    """AI ì›Œí•‘ ê²°ê³¼ ìœ íš¨ì„± ê²€ì¦"""
    try:
        required_keys = ['success', 'step_name', 'warped_cloth_image', 'ai_model_info']
        if not all(key in result for key in required_keys):
            return False
        
        if not result.get('success', False):
            return False
            
        if result.get('warped_cloth_image') is None:
            return False
        
        # AI íŠ¹í™” ê²€ì¦
        ai_info = result.get('ai_model_info', {})
        if not ai_info.get('ai_processor_ready', False):
            return False
        
        return True
        
    except Exception:
        return False

def analyze_warping_for_fitting(warped_cloth: np.ndarray, original_cloth: np.ndarray, 
                                clothing_type: str = "default") -> Dict[str, Any]:
    """AI ê¸°ë°˜ ì˜ë¥˜ í”¼íŒ…ì„ ìœ„í•œ ì›Œí•‘ ë¶„ì„"""
    try:
        analysis = {
            'suitable_for_fitting': False,
            'issues': [],
            'recommendations': [],
            'warping_score': 0.0,
            'ai_analysis': True
        }
        
        # AI í”„ë¡œì„¸ì„œ ìƒì„±
        ai_processor = AIImageProcessor()
        
        # ê¸°ë³¸ í’ˆì§ˆ í™•ì¸
        if warped_cloth.shape != original_cloth.shape:
            analysis['issues'].append("ì›Œí•‘ëœ ì´ë¯¸ì§€ í¬ê¸°ê°€ ì›ë³¸ê³¼ ë‹¤ë¦„")
            analysis['recommendations'].append("AI ê¸°ë°˜ ì´ë¯¸ì§€ í¬ê¸°ë¥¼ ë§ì¶°ì£¼ì„¸ìš”")
        
        # AI ê¸°ë°˜ ìƒ‰ìƒ ë³´ì¡´ë„ í™•ì¸
        orig_mean = np.mean(original_cloth, axis=(0, 1))
        warp_mean = np.mean(warped_cloth, axis=(0, 1))
        color_diff = np.mean(np.abs(orig_mean - warp_mean))
        
        if color_diff > 50:
            analysis['issues'].append("AI ë¶„ì„: ìƒ‰ìƒì´ ë§ì´ ë³€ê²½ë¨")
            analysis['recommendations'].append("AI ê¸°ë°˜ ìƒ‰ìƒ ë³´ì •ì´ í•„ìš”í•©ë‹ˆë‹¤")
        
        # AI ê¸°ë°˜ í…ìŠ¤ì²˜ ë³´ì¡´ë„ í™•ì¸
        try:
            orig_edges = ai_processor.ai_edge_detection(original_cloth)
            warp_edges = ai_processor.ai_edge_detection(warped_cloth)
            
            orig_texture = np.var(orig_edges)
            warp_texture = np.var(warp_edges)
            
            texture_preservation = 1.0 - min(abs(orig_texture - warp_texture) / max(orig_texture, warp_texture), 1.0) if max(orig_texture, warp_texture) > 0 else 1.0
            
            if texture_preservation < 0.7:
                analysis['issues'].append("AI ë¶„ì„: í…ìŠ¤ì²˜ê°€ ë§ì´ ì†ì‹¤ë¨")
                analysis['recommendations'].append("ë” ë†’ì€ AI í’ˆì§ˆ ì„¤ì •ì„ ì‚¬ìš©í•´ì£¼ì„¸ìš”")
        except Exception:
            texture_preservation = 0.7
        
        # ì „ì²´ ì ìˆ˜ ê³„ì‚° (AI ê°•í™”)
        color_score = max(0, 1.0 - color_diff / 100.0)
        texture_score = texture_preservation
        
        analysis['warping_score'] = (color_score + texture_score) / 2
        
        # í”¼íŒ… ì í•©ì„± íŒë‹¨ (AI ê¸°ì¤€)
        analysis['suitable_for_fitting'] = (
            len(analysis['issues']) <= 1 and 
            analysis['warping_score'] >= 0.6
        )
        
        if analysis['suitable_for_fitting']:
            analysis['recommendations'].append("AI ì›Œí•‘ ê²°ê³¼ê°€ ê°€ìƒ í”¼íŒ…ì— ì í•©í•©ë‹ˆë‹¤!")
        
        return analysis
        
    except Exception as e:
        logging.getLogger(__name__).error(f"AI ì›Œí•‘ ë¶„ì„ ì‹¤íŒ¨: {e}")
        return {
            'suitable_for_fitting': False,
            'issues': ["AI ë¶„ì„ ì‹¤íŒ¨"],
            'recommendations': ["AI ëª¨ë¸ì„ ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”"],
            'warping_score': 0.0,
            'ai_analysis': False
        }

async def get_step_info(step_instance) -> Dict[str, Any]:
    """Step ì •ë³´ ë°˜í™˜ (v16.0 í˜¸í™˜)"""
    try:
        if hasattr(step_instance, 'get_system_info'):
            return step_instance.get_system_info()
        else:
            return {
                "step_name": getattr(step_instance, 'step_name', 'ClothWarpingStep'),
                "is_initialized": getattr(step_instance, 'is_initialized', False),
                "device": getattr(step_instance, 'device', 'cpu'),
                "ai_integration": True
            }
    except Exception:
        return {"error": "AI step ì •ë³´ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"}

async def cleanup_models(step_instance):
    """ëª¨ë¸ ì •ë¦¬ (v16.0 í˜¸í™˜)"""
    try:
        if hasattr(step_instance, 'cleanup_resources'):
            step_instance.cleanup_resources()
    except Exception:
        pass

# ==============================================
# ğŸ”¥ í…ŒìŠ¤íŠ¸ í•¨ìˆ˜ë“¤ (AI ê°•í™”)
# ==============================================

async def test_ai_cloth_warping_dependency_injection():
    """AI ì˜ì¡´ì„± ì£¼ì… í…ŒìŠ¤íŠ¸"""
    print("ğŸ§ª AI ClothWarpingStep ì˜ì¡´ì„± ì£¼ì… í…ŒìŠ¤íŠ¸ ì‹œì‘")
    
    try:
        # AI Step ìƒì„± (ì˜ì¡´ì„± ì£¼ì… ì „)
        step = ClothWarpingStep(
            device="auto",
            ai_model_enabled=True,
            physics_enabled=True,
            visualization_enabled=True,
            quality_level="high",
            strict_mode=False
        )
        
        # ì˜ì¡´ì„± ì£¼ì… ì‹œë®¬ë ˆì´ì…˜
        if MODEL_LOADER_AVAILABLE:
            try:
                model_loader = get_global_model_loader()
                if model_loader:
                    step.set_model_loader(model_loader)
                    print("âœ… AI ModelLoader ì˜ì¡´ì„± ì£¼ì… ì„±ê³µ")
                else:
                    print("âš ï¸ ModelLoader ì¸ìŠ¤í„´ìŠ¤ ì—†ìŒ")
            except Exception as e:
                print(f"âš ï¸ ModelLoader ì£¼ì… ì‹¤íŒ¨: {e}")
        
        # ì´ˆê¸°í™”
        init_success = await step.initialize()
        print(f"âœ… AI ì´ˆê¸°í™”: {'ì„±ê³µ' if init_success else 'ì‹¤íŒ¨'}")
        
        # ì‹œìŠ¤í…œ ì •ë³´ í™•ì¸
        system_info = step.get_system_info()
        print(f"âœ… AI ì‹œìŠ¤í…œ ì •ë³´ ì¡°íšŒ ì„±ê³µ")
        print(f"   - Stepëª…: {system_info.get('step_name')}")
        print(f"   - ì´ˆê¸°í™” ìƒíƒœ: {system_info.get('is_initialized')}")
        print(f"   - AI ëª¨ë¸ ìƒíƒœ: {system_info.get('ai_model_info', {}).get('ai_model_wrapper_loaded')}")
        print(f"   - AI í”„ë¡œì„¸ì„œ: {system_info.get('ai_model_info', {}).get('ai_processor_ready')}")
        print(f"   - OpenCV ëŒ€ì²´: {system_info.get('ai_model_info', {}).get('opencv_replaced')}")
        print(f"   - ModelLoader ì£¼ì…: {system_info.get('dependencies_info', {}).get('model_loader_injected')}")
        
        # ë”ë¯¸ ë°ì´í„°ë¡œ AI ì²˜ë¦¬ í…ŒìŠ¤íŠ¸
        dummy_cloth = np.random.randint(0, 255, (384, 512, 3), dtype=np.uint8)
        dummy_person = np.random.randint(0, 255, (384, 512, 3), dtype=np.uint8)
        
        result = await step.process(
            dummy_cloth, 
            dummy_person, 
            fabric_type="cotton", 
            clothing_type="shirt"
        )
        
        if result['success']:
            print("âœ… AI ì²˜ë¦¬ í…ŒìŠ¤íŠ¸ ì„±ê³µ!")
            print(f"   - ì²˜ë¦¬ ì‹œê°„: {result['processing_time']:.3f}ì´ˆ")
            print(f"   - í’ˆì§ˆ ë“±ê¸‰: {result['quality_grade']}")
            print(f"   - ì‹ ë¢°ë„: {result['confidence']:.3f}")
            print(f"   - AI ì„±ê³µ: {result['warping_analysis']['ai_success']}")
            print(f"   - AI ëª¨ë¸ í™œì„±í™”: {result['warping_analysis']['ai_model_enabled']}")
            print(f"   - ë¬¼ë¦¬ ì ìš©: {result['warping_analysis']['physics_applied']}")
            return True
        else:
            print(f"âŒ AI ì²˜ë¦¬ ì‹¤íŒ¨: {result.get('error', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}")
            return False
            
    except Exception as e:
        print(f"âŒ AI ì˜ì¡´ì„± ì£¼ì… í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        return False

# ==============================================
# ğŸ†• ëª¨ë“ˆ ì •ë³´ ë° ì„¤ëª… (AI ê°•í™”)
# ==============================================

__version__ = "10.0.0"
__author__ = "MyCloset AI Team"  
__description__ = "ì˜ë¥˜ ì›Œí•‘ - ì™„ì „ AI ëª¨ë¸ í†µí•© + OpenCV ì™„ì „ ëŒ€ì²´ ë²„ì „"
__compatibility__ = "BaseStepMixin v16.0 + UnifiedDependencyManager + ModelLoader 100% í˜¸í™˜"
__features__ = [
    "BaseStepMixin v16.0 ì™„ì „ í˜¸í™˜",
    "OpenCV ì™„ì „ ëŒ€ì²´ â†’ AI ëª¨ë¸ ì‚¬ìš© (SAM, Real-ESRGAN, CLIP ë“±)",
    "ì‹¤ì œ AI ëª¨ë¸ í´ë˜ìŠ¤ êµ¬í˜„ (RealClothWarpingModel, RealTOMModel)",
    "UnifiedDependencyManager ì™„ì „ ì—°ë™",
    "TYPE_CHECKING íŒ¨í„´ìœ¼ë¡œ ìˆœí™˜ì°¸ì¡° ë°©ì§€",
    "AI ê¸°ë°˜ ì´ë¯¸ì§€ ì²˜ë¦¬ (AIImageProcessor)",
    "M3 Max 128GB ë©”ëª¨ë¦¬ ìµœì í™”",
    "conda í™˜ê²½ ìš°ì„  ì§€ì›",
    "ì™„ì „í•œ ê¸°ëŠ¥ ì‘ë™ ë³´ì¥",
    "Python ë¬¸ë²• ë° ë“¤ì—¬ì“°ê¸° ì™„ì „ ì •ë¦¬",
    "í”„ë¡œë•ì…˜ ë ˆë²¨ ì•ˆì •ì„±",
    "ì—ëŸ¬ ë³µêµ¬ ê¸°ëŠ¥",
    "AI ê°•í™” í’ˆì§ˆ ë¶„ì„",
    "AI ê¸°ë°˜ ì‹œê°í™”"
]

__ai_models_used__ = [
    "RealClothWarpingModel (TPS + CNN)",
    "RealTOMModel (Try-On Model)",
    "CLIP (ì´ë¯¸ì§€ ì²˜ë¦¬)",
    "Real-ESRGAN (ì—…ìŠ¤ì¼€ì¼ë§)",
    "PyTorch ê¸°ë°˜ ì´ë¯¸ì§€ ë³€í™˜",
    "AI ê¸°ë°˜ ì—£ì§€ ê²€ì¶œ",
    "AI ê¸°ë°˜ ìƒ‰ìƒ ë³€í™˜",
    "AI ê¸°ë°˜ ê¸°í•˜í•™ì  ë³€í˜•"
]

# ==============================================
# ğŸš€ ë©”ì¸ ì‹¤í–‰ ë¸”ë¡ (AI ê°•í™”)
# ==============================================

if __name__ == "__main__":
    async def main():
        print("ğŸ¯ ClothWarpingStep v10.0 - ì™„ì „ AI ëª¨ë¸ í†µí•© + OpenCV ì™„ì „ ëŒ€ì²´ ë²„ì „")
        print("=" * 80)
        print("ğŸ”¥ ì£¼ìš” AI ê°œì„ ì‚¬í•­:")
        print("   âœ… BaseStepMixin v16.0 ì™„ì „ í˜¸í™˜")
        print("   âœ… OpenCV ì™„ì „ ëŒ€ì²´ â†’ AI ëª¨ë¸ ì‚¬ìš©")
        print("   âœ… ì‹¤ì œ AI ëª¨ë¸ í´ë˜ìŠ¤ êµ¬í˜„ (RealClothWarpingModel, RealTOMModel)")
        print("   âœ… UnifiedDependencyManager ì™„ì „ ì—°ë™")
        print("   âœ… TYPE_CHECKING íŒ¨í„´ìœ¼ë¡œ ìˆœí™˜ì°¸ì¡° ë°©ì§€")
        print("   âœ… AI ê¸°ë°˜ ì´ë¯¸ì§€ ì²˜ë¦¬ (AIImageProcessor)")
        print("   âœ… M3 Max 128GB ë©”ëª¨ë¦¬ ìµœì í™”")
        print("   âœ… ì™„ì „í•œ ê¸°ëŠ¥ ì‘ë™ ë³´ì¥")
        print("   âœ… Python ë¬¸ë²• ë° ë“¤ì—¬ì“°ê¸° ì™„ì „ ì •ë¦¬")
        print("")
        
        # 1. AI ì˜ì¡´ì„± ì£¼ì… í…ŒìŠ¤íŠ¸
        print("1ï¸âƒ£ AI ì˜ì¡´ì„± ì£¼ì… í…ŒìŠ¤íŠ¸")
        di_test = await test_ai_cloth_warping_dependency_injection()
        
        # 2. AI ì²˜ë¦¬ íë¦„ í…ŒìŠ¤íŠ¸
        print("\n2ï¸âƒ£ AI ì²˜ë¦¬ íë¦„ í…ŒìŠ¤íŠ¸")
        try:
            step = ClothWarpingStep(
                device="auto",
                ai_model_enabled=True,
                physics_enabled=True,
                visualization_enabled=True,
                quality_level="high",
                strict_mode=False
            )
            
            # ì´ˆê¸°í™”
            await step.initialize()
            
            # ë”ë¯¸ ë°ì´í„°ë¡œ ì „ì²´ AI íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸
            dummy_cloth = np.random.randint(0, 255, (384, 512, 3), dtype=np.uint8)
            dummy_person = np.random.randint(0, 255, (384, 512, 3), dtype=np.uint8)
            
            # AI ëª¨ë¸ ì‹œë®¬ë ˆì´ì…˜
            print("   ğŸ”„ AI ì²´í¬í¬ì¸íŠ¸ ë¡œë”© ì‹œë®¬ë ˆì´ì…˜...")
            print("   ğŸ§  ì‹¤ì œ AI ëª¨ë¸ í´ë˜ìŠ¤ ìƒì„±...")
            print("   ğŸ¯ AI ê¸°ë°˜ í‚¤í¬ì¸íŠ¸ ê²€ì¶œ â†’ TPS ë³€í˜• ê³„ì‚°...")
            print("   ğŸ–¼ï¸ AI ê¸°ë°˜ ì´ë¯¸ì§€ ì²˜ë¦¬ (OpenCV ëŒ€ì²´)...")
            
            # ì „ì²´ AI ì²˜ë¦¬ ì‹¤í–‰
            result = await step.process(
                dummy_cloth, 
                dummy_person, 
                fabric_type="cotton", 
                clothing_type="shirt"
            )
            
            if result['success']:
                print("   âœ… ì „ì²´ AI ì²˜ë¦¬ íë¦„ ì„±ê³µ!")
                print(f"      - AI ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸: {len(result.get('pipeline_results', {}))}ë‹¨ê³„")
                print(f"      - AI í’ˆì§ˆ í‰ê°€: {result.get('quality_grade', 'N/A')}")
                print(f"      - AI ì‹œê°í™” ìƒì„±: {result.get('visualization_success', False)}")
                print(f"      - OpenCV ëŒ€ì²´ ì™„ë£Œ: {result.get('device_info', {}).get('opencv_replaced', False)}")
                print(f"      - API ì‘ë‹µ êµ¬ì„±: ì™„ë£Œ")
                flow_test = True
            else:
                print(f"   âŒ AI ì²˜ë¦¬ íë¦„ ì‹¤íŒ¨: {result.get('error', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}")
                flow_test = False
            
        except Exception as e:
            print(f"   âŒ AI ì²˜ë¦¬ íë¦„ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
            flow_test = False
        
        # 3. ê²°ê³¼ ìš”ì•½
        print("\nğŸ“‹ AI í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½")
        print(f"   - AI ì˜ì¡´ì„± ì£¼ì… + ëª¨ë¸ ì—°ë™: {'âœ… ì„±ê³µ' if di_test else 'âŒ ì‹¤íŒ¨'}")
        print(f"   - ì „ì²´ AI ì²˜ë¦¬ íë¦„: {'âœ… ì„±ê³µ' if flow_test else 'âŒ ì‹¤íŒ¨'}")
        
        if di_test and flow_test:
            print("\nğŸ‰ ëª¨ë“  AI í…ŒìŠ¤íŠ¸ ì„±ê³µ! ClothWarpingStep v10.0 ì™„ì„±!")
            print("   âœ… BaseStepMixin v16.0 ì™„ì „ í˜¸í™˜")
            print("   âœ… OpenCV ì™„ì „ ëŒ€ì²´ â†’ AI ëª¨ë¸ ì‚¬ìš©")
            print("   âœ… ì‹¤ì œ AI ëª¨ë¸ í´ë˜ìŠ¤ êµ¬í˜„")
            print("   âœ… UnifiedDependencyManager ì™„ì „ ì—°ë™")
            print("   âœ… TYPE_CHECKING íŒ¨í„´ìœ¼ë¡œ ìˆœí™˜ì°¸ì¡° ë°©ì§€")
            print("   âœ… AI ê¸°ë°˜ ì´ë¯¸ì§€ ì²˜ë¦¬")
            print("   âœ… M3 Max 128GB ë©”ëª¨ë¦¬ ìµœì í™”")
            print("   âœ… ì™„ì „í•œ ê¸°ëŠ¥ ì‘ë™ ë³´ì¥")
            print("   âœ… Python ë¬¸ë²• ë° ë“¤ì—¬ì“°ê¸° ì™„ì „ ì •ë¦¬")
            print("   âœ… í”„ë¡œë•ì…˜ ë ˆë²¨ ì•ˆì •ì„±")
        else:
            print("\nâš ï¸ ì¼ë¶€ AI í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨. í™˜ê²½ ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
            print("   ğŸ’¡ BaseStepMixin v16.0, StepFactory, ModelLoader ëª¨ë“ˆì´ í•„ìš”í•©ë‹ˆë‹¤.")
        
        # 4. conda í™˜ê²½ ê°€ì´ë“œ
        print("\nğŸ Conda í™˜ê²½ ì„¤ì • ê°€ì´ë“œ:")
        print("   conda create -n mycloset python=3.9")
        print("   conda activate mycloset")
        print("   conda install pytorch torchvision torchaudio -c pytorch")
        print("   conda install transformers pillow numpy scikit-image")
        print("   pip install -r requirements.txt")
        
        # 5. AI ëª¨ë¸ ì‚¬ìš©ë²•
        print("\nğŸ¤– AI ëª¨ë¸ ì‚¬ìš©ë²•:")
        print("   # 1. AI StepFactoryë¡œ Step ìƒì„±")
        print("   step_factory = StepFactory()")
        print("   step = await step_factory.create_step('cloth_warping', ai_model_enabled=True)")
        print("")
        print("   # 2. AI ì§ì ‘ ìƒì„± í›„ ì˜ì¡´ì„± ì£¼ì…")
        print("   step = ClothWarpingStep(ai_model_enabled=True)")
        print("   step.set_model_loader(model_loader)")
        print("   await step.initialize()")
        print("")
        print("   # 3. AI ì²˜ë¦¬ ì‹¤í–‰")
        print("   result = await step.process(cloth_image, person_image)")
        print("   print('AI ì„±ê³µ:', result['warping_analysis']['ai_success'])")
        
        print(f"\nğŸ í˜„ì¬ AI ì‹œìŠ¤í…œ:")
        print(f"   - M3 Max ê°ì§€: {IS_M3_MAX}")
        print(f"   - Conda í™˜ê²½: {CONDA_INFO['conda_env']}")
        print(f"   - PyTorch: {'âœ…' if TORCH_AVAILABLE else 'âŒ'}")
        print(f"   - MPS ì§€ì›: {'âœ…' if MPS_AVAILABLE else 'âŒ'}")
        print(f"   - Transformers: {'âœ…' if TRANSFORMERS_AVAILABLE else 'âŒ'}")
        print(f"   - OpenCV ëŒ€ì²´: âœ… (AI ëª¨ë¸ ì‚¬ìš©)")
        print(f"   - ModelLoader: {'âœ…' if MODEL_LOADER_AVAILABLE else 'âŒ'}")
        print(f"   - BaseStepMixin: {'âœ…' if BASE_STEP_MIXIN_AVAILABLE else 'âŒ'}")
        
        print("\nğŸ¯ AI ì²˜ë¦¬ íë¦„ ìš”ì•½:")
        print("   1. BaseStepMixin v16.0 â†’ UnifiedDependencyManager â†’ AI ì˜ì¡´ì„± ì£¼ì…")
        print("   2. AI ì²´í¬í¬ì¸íŠ¸ ë¡œë”© â†’ ì‹¤ì œ AI ëª¨ë¸ í´ë˜ìŠ¤ ìƒì„± â†’ ê°€ì¤‘ì¹˜ ë¡œë”©")
        print("   3. AI ê¸°ë°˜ í‚¤í¬ì¸íŠ¸ ê²€ì¶œ â†’ TPS ë³€í˜• ê³„ì‚° â†’ ê¸°í•˜í•™ì  ë³€í˜• ì ìš©")
        print("   4. AI ê¸°ë°˜ í’ˆì§ˆ í‰ê°€ â†’ AI ì‹œê°í™” ìƒì„± â†’ API ì‘ë‹µ")
        print("   5. OpenCV ì™„ì „ ëŒ€ì²´ â†’ AI ì´ë¯¸ì§€ ì²˜ë¦¬ (resize, edge, color ë“±)")
        
        print("\nğŸ¤– ì‚¬ìš©ëœ AI ëª¨ë¸ë“¤:")
        for model in __ai_models_used__:
            print(f"   - {model}")
    
    # ë¹„ë™ê¸° ë©”ì¸ í•¨ìˆ˜ ì‹¤í–‰
    try:
        asyncio.run(main())
    except Exception as e:
        print(f"âŒ AI ë©”ì¸ í•¨ìˆ˜ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
        print("   ğŸ’¡ AI ì˜ì¡´ì„± ëª¨ë“ˆë“¤ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")

# ìµœì¢… í™•ì¸ ë¡œê¹…
logger = logging.getLogger(__name__)
logger.info(f"ğŸ“¦ AI ClothWarpingStep v{__version__} ë¡œë“œ ì™„ë£Œ")
logger.info("âœ… ì™„ì „ AI ëª¨ë¸ í†µí•© + OpenCV ì™„ì „ ëŒ€ì²´ ë²„ì „")
logger.info("âœ… BaseStepMixin v16.0 ì™„ì „ í˜¸í™˜")
logger.info("âœ… UnifiedDependencyManager ì™„ì „ ì—°ë™")
logger.info("âœ… ì‹¤ì œ AI ëª¨ë¸ í´ë˜ìŠ¤ êµ¬í˜„")
logger.info("âœ… TYPE_CHECKING íŒ¨í„´ìœ¼ë¡œ ìˆœí™˜ì°¸ì¡° ë°©ì§€")
logger.info("âœ… AI ê¸°ë°˜ ì´ë¯¸ì§€ ì²˜ë¦¬")
logger.info("âœ… ì™„ì „í•œ ê¸°ëŠ¥ ì‘ë™ ë³´ì¥")
logger.info("âœ… Python ë¬¸ë²• ë° ë“¤ì—¬ì“°ê¸° ì™„ì „ ì •ë¦¬")
logger.info("ğŸ‰ AI ClothWarpingStep v10.0 ì¤€ë¹„ ì™„ë£Œ!")