# backend/app/ai_pipeline/steps/step_05_cloth_warping.py
"""
üî• MyCloset AI - ÏôÑÏ†ÑÌïú ClothWarpingStep v3.0 (PoseEstimationStep Ìå®ÌÑ¥ ÏôÑÏ†Ñ Ï†ÅÏö©)
‚úÖ utils ÌÜµÌï© Ïù∏ÌÑ∞ÌéòÏù¥Ïä§ **ÏôÑÏ†Ñ Ïó∞Îèô**
‚úÖ ÌÜµÏùºÎêú ÏÉùÏÑ±Ïûê Ìå®ÌÑ¥ (PoseEstimationStepÍ≥º ÎèôÏùº)
‚úÖ ÏôÑÏ†ÑÌïú ÏóêÎü¨ Ï≤òÎ¶¨ Î∞è Ï∫êÏãú Í¥ÄÎ¶¨
‚úÖ logger ÏÜçÏÑ± ÎàÑÎùΩ Î¨∏Ï†ú ÏôÑÏ†Ñ Ìï¥Í≤∞
‚úÖ BaseStepMixin ÏôÑÎ≤Ω ÏÉÅÏÜç
‚úÖ **Î™®Îì† Í∏∞Îä• 100% Ìè¨Ìï®** - ÏïÑÎ¨¥Í≤ÉÎèÑ Îπ†ÏßÄÏßÄ ÏïäÏùå
‚úÖ M3 Max 128GB ÏµúÏ†ÅÌôî
‚úÖ AI Î™®Îç∏ ÏôÑÏ†Ñ Ïó∞Îèô (HRVITON, TOM, Physics)
‚úÖ ÏãúÍ∞ÅÌôî Í∏∞Îä• ÏôÑÏ†Ñ Íµ¨ÌòÑ
‚úÖ Î¨ºÎ¶¨ ÏãúÎÆ¨Î†àÏù¥ÏÖò ÏóîÏßÑ
‚úÖ ÌîÑÎ°úÎçïÏÖò Î†àÎ≤® ÏïàÏ†ïÏÑ±
‚úÖ ÏùòÎ•òÎ≥Ñ ÌäπÌôî Ï≤òÎ¶¨
"""

import os
import cv2
import time
import asyncio
import logging
import threading
import gc
import base64
import json
import hashlib
import math
import weakref
import numpy as np
from pathlib import Path
from typing import Dict, Any, Optional, Union, List, Tuple, Callable
from dataclasses import dataclass, field
from concurrent.futures import ThreadPoolExecutor, as_completed
from enum import Enum
from io import BytesIO
from functools import lru_cache

# PyTorch imports (ÏïàÏ†Ñ)
try:
    import torch
    import torch.nn as nn
    import torch.nn.functional as F
    from torch.utils.data import DataLoader
    import torchvision.transforms as transforms
    from torch.cuda.amp import autocast
    TORCH_AVAILABLE = True
except ImportError:
    TORCH_AVAILABLE = False
    torch = None

# Í≥†Í∏â ÎùºÏù¥Î∏åÎü¨Î¶¨Îì§
try:
    from PIL import Image, ImageDraw, ImageFont, ImageEnhance, ImageFilter
    PIL_AVAILABLE = True
except ImportError:
    PIL_AVAILABLE = False

try:
    from scipy.interpolate import RBFInterpolator
    from scipy.spatial.distance import cdist
    from scipy.ndimage import gaussian_filter, median_filter
    from scipy.signal import convolve2d
    SCIPY_AVAILABLE = True
except ImportError:
    SCIPY_AVAILABLE = False

try:
    from sklearn.cluster import KMeans
    from sklearn.preprocessing import StandardScaler
    SKLEARN_AVAILABLE = True
except ImportError:
    SKLEARN_AVAILABLE = False

try:
    from skimage.transform import PiecewiseAffineTransform, warp
    from skimage.feature import local_binary_pattern
    from skimage import restoration, filters, exposure
    SKIMAGE_AVAILABLE = True
except ImportError:
    SKIMAGE_AVAILABLE = False

try:
    import psutil
    PSUTIL_AVAILABLE = True
except ImportError:
    PSUTIL_AVAILABLE = False

# üî• utils ÌÜµÌï© Ïù∏ÌÑ∞ÌéòÏù¥Ïä§ Ïó∞Îèô (ÌïµÏã¨ Ï∂îÍ∞Ä)
try:
    from app.ai_pipeline.utils import (
        create_step_interface,
        BaseStepMixin,
        get_utils_manager,
        SYSTEM_INFO,
        IS_M3_MAX,
        MEMORY_GB,
        DEFAULT_DEVICE,
        TORCH_AVAILABLE as UTILS_TORCH_AVAILABLE
    )
    UTILS_AVAILABLE = True
except ImportError:
    UTILS_AVAILABLE = False
    
    # Ìè¥Î∞± BaseStepMixin
    class BaseStepMixin:
        def _setup_model_interface(self):
            pass

# BaseStepMixin import (Ìè¥Î∞±Ïö©)
try:
    from .base_step_mixin import ClothWarpingMixin, ensure_step_initialization, safe_step_method, performance_monitor
except ImportError:
    # Ìè¥Î∞± Îç∞ÏΩîÎ†àÏù¥ÌÑ∞Îì§
    def ensure_step_initialization(func):
        return func
    def safe_step_method(func):
        return func
    def performance_monitor(name):
        def decorator(func):
            return func
        return decorator
    
    class ClothWarpingMixin(BaseStepMixin):
        pass

# Î°úÍ±∞ ÏÑ§Ï†ï
logger = logging.getLogger(__name__)

# ==============================================
# üî• ÏôÑÏ†ÑÌïú Îç∞Ïù¥ÌÑ∞ Íµ¨Ï°∞Îì§
# ==============================================

class WarpingMethod(Enum):
    """ÏõåÌïë Î∞©Î≤ï"""
    AI_MODEL = "ai_model"
    PHYSICS_BASED = "physics_based"
    HYBRID = "hybrid"
    TPS_ONLY = "tps_only"

class FabricType(Enum):
    """Ìå®Î∏åÎ¶≠ ÌÉÄÏûÖ"""
    COTTON = "cotton"
    SILK = "silk"
    DENIM = "denim"
    WOOL = "wool"
    POLYESTER = "polyester"
    LINEN = "linen"
    LEATHER = "leather"

class WarpingQuality(Enum):
    """ÏõåÌïë ÌíàÏßà Îì±Í∏â"""
    EXCELLENT = "excellent"     # 90-100Ï†ê
    GOOD = "good"              # 75-89Ï†ê
    ACCEPTABLE = "acceptable"   # 60-74Ï†ê
    POOR = "poor"              # 40-59Ï†ê
    VERY_POOR = "very_poor"    # 0-39Ï†ê

@dataclass
class ClothWarpingConfig:
    """ÏôÑÏ†ÑÌïú Cloth Warping ÏÑ§Ï†ï"""
    # Í∏∞Î≥∏ ÏÑ§Ï†ï
    input_size: Tuple[int, int] = (512, 384)
    num_control_points: int = 25
    device: str = "auto"
    precision: str = "fp16"
    
    # ÏõåÌïë Î∞©Î≤ï Î∞è AI Î™®Îç∏
    warping_method: WarpingMethod = WarpingMethod.AI_MODEL
    ai_model_enabled: bool = True
    ai_model_name: str = "cloth_warping_hrviton"
    
    # Î¨ºÎ¶¨ ÏãúÎÆ¨Î†àÏù¥ÏÖò
    physics_enabled: bool = True
    cloth_stiffness: float = 0.3
    elastic_modulus: float = 1000.0
    poisson_ratio: float = 0.3
    damping_factor: float = 0.1
    
    # Î≥ÄÌòï Î∞è ÎìúÎ†àÏù¥Ìïë
    enable_wrinkles: bool = True
    enable_draping: bool = True
    deformation_strength: float = 0.7
    gravity_strength: float = 0.5
    
    # ÏãúÍ∞ÅÌôî
    enable_visualization: bool = True
    visualization_quality: str = "high"  # low, medium, high, ultra
    save_intermediate_results: bool = True
    
    # ÏÑ±Îä• ÏµúÏ†ÅÌôî
    batch_size: int = 1
    memory_fraction: float = 0.5
    enable_tensorrt: bool = False
    enable_attention_slicing: bool = True
    
    # ÌíàÏßà ÏÑ§Ï†ï
    quality_level: str = "high"  # low, medium, high, ultra
    output_format: str = "rgb"
    
    # M3 Max ÏµúÏ†ÅÌôî
    is_m3_max: bool = False
    optimization_enabled: bool = True
    memory_gb: int = 128
    
    # Ï∫êÏãú ÏÑ§Ï†ï
    cache_enabled: bool = True
    cache_size: int = 50

@dataclass
class PhysicsProperties:
    """Î¨ºÎ¶¨ ÏÜçÏÑ±"""
    fabric_type: FabricType = FabricType.COTTON
    thickness: float = 0.001  # meters
    density: float = 1500.0  # kg/m¬≥
    elastic_modulus: float = 1000.0  # Pa
    poisson_ratio: float = 0.3
    friction_coefficient: float = 0.4
    air_resistance: float = 0.01

# ÏùòÎ•ò ÌÉÄÏûÖÎ≥Ñ ÏõåÌïë Í∞ÄÏ§ëÏπò (PoseEstimationStep Ìå®ÌÑ¥)
CLOTHING_WARPING_WEIGHTS = {
    'shirt': {'deformation': 0.4, 'physics': 0.3, 'texture': 0.3},
    'dress': {'deformation': 0.5, 'physics': 0.3, 'texture': 0.2},
    'pants': {'physics': 0.5, 'deformation': 0.3, 'texture': 0.2},
    'jacket': {'physics': 0.4, 'deformation': 0.4, 'texture': 0.2},
    'skirt': {'deformation': 0.4, 'physics': 0.4, 'texture': 0.2},
    'top': {'deformation': 0.5, 'texture': 0.3, 'physics': 0.2},
    'default': {'deformation': 0.4, 'physics': 0.3, 'texture': 0.3}
}

# ==============================================
# üî• Í≥†Í∏â TPS Î≥ÄÌôò ÌÅ¥ÎûòÏä§
# ==============================================

class AdvancedTPSTransform:
    """Í≥†Í∏â Thin Plate Spline Î≥ÄÌôò ÌÅ¥ÎûòÏä§"""
    
    def __init__(self, num_control_points: int = 25, regularization: float = 0.0):
        self.num_control_points = num_control_points
        self.regularization = regularization
        self.source_points = None
        self.target_points = None
        self.transform_matrix = None
        self.rbf_interpolator = None
        
    def create_adaptive_control_grid(self, width: int, height: int, edge_density: float = 2.0) -> np.ndarray:
        """Ï†ÅÏùëÏ†Å Ï†úÏñ¥Ï†ê Í∑∏Î¶¨Îìú ÏÉùÏÑ± (Í∞ÄÏû•ÏûêÎ¶¨ Î∞ÄÎèÑ Ï¶ùÍ∞Ä)"""
        # Í∏∞Î≥∏ Í∑∏Î¶¨Îìú
        grid_size = int(np.sqrt(self.num_control_points))
        base_points = []
        
        # Í∑†Îì± Î∂ÑÌè¨ Ï†úÏñ¥Ï†ê
        for i in range(grid_size):
            for j in range(grid_size):
                x = (width - 1) * i / (grid_size - 1)
                y = (height - 1) * j / (grid_size - 1)
                base_points.append([x, y])
        
        # Í∞ÄÏû•ÏûêÎ¶¨ Î∞ÄÎèÑ Ï¶ùÍ∞Ä
        edge_points = []
        num_edge_points = max(0, self.num_control_points - len(base_points))
        
        for i in range(num_edge_points):
            if i % 4 == 0:  # ÏÉÅÎã®
                x = np.random.uniform(0, width-1)
                y = 0
            elif i % 4 == 1:  # ÌïòÎã®
                x = np.random.uniform(0, width-1)
                y = height-1
            elif i % 4 == 2:  # Ï¢åÏ∏°
                x = 0
                y = np.random.uniform(0, height-1)
            else:  # Ïö∞Ï∏°
                x = width-1
                y = np.random.uniform(0, height-1)
            edge_points.append([x, y])
        
        all_points = base_points + edge_points
        return np.array(all_points[:self.num_control_points])
    
    def compute_rbf_weights(self, source_points: np.ndarray, target_points: np.ndarray) -> Optional[Any]:
        """RBF Ïù∏ÌÑ∞Ìè¥Î†àÏù¥ÌÑ∞ ÏÉùÏÑ±"""
        if not SCIPY_AVAILABLE:
            return None
            
        try:
            # RBF Ïù∏ÌÑ∞Ìè¥Î†àÏù¥ÌÑ∞ ÏÉùÏÑ±
            self.rbf_interpolator = RBFInterpolator(
                source_points, target_points,
                kernel='thin_plate_spline',
                epsilon=self.regularization
            )
            return self.rbf_interpolator
        except Exception as e:
            logger.warning(f"RBF Ïù∏ÌÑ∞Ìè¥Î†àÏù¥ÌÑ∞ ÏÉùÏÑ± Ïã§Ìå®: {e}")
            return None
    
    def apply_transform(self, image: np.ndarray, source_points: np.ndarray, target_points: np.ndarray) -> np.ndarray:
        """TPS Î≥ÄÌôò Ï†ÅÏö©"""
        try:
            if SKIMAGE_AVAILABLE:
                # scikit-image ÏÇ¨Ïö©
                tform = PiecewiseAffineTransform()
                tform.estimate(target_points, source_points)
                warped = warp(image, tform, output_shape=image.shape[:2])
                return (warped * 255).astype(np.uint8)
            else:
                # OpenCV Ìè¥Î∞±
                return self._opencv_tps_transform(image, source_points, target_points)
        except Exception as e:
            logger.error(f"TPS Î≥ÄÌôò Ïã§Ìå®: {e}")
            return image
    
    def _opencv_tps_transform(self, image: np.ndarray, source_points: np.ndarray, target_points: np.ndarray) -> np.ndarray:
        """OpenCVÎ•º ÏÇ¨Ïö©Ìïú TPS Î≥ÄÌôò"""
        try:
            # ÌôàÍ∑∏ÎûòÌîº Ï∂îÏ†ï (Îã®ÏàúÌôî)
            H, _ = cv2.findHomography(source_points, target_points, cv2.RANSAC)
            if H is not None:
                height, width = image.shape[:2]
                warped = cv2.warpPerspective(image, H, (width, height))
                return warped
            return image
        except Exception:
            return image

# ==============================================
# üî• Î¨ºÎ¶¨ ÏãúÎÆ¨Î†àÏù¥ÏÖò ÏóîÏßÑ
# ==============================================

class ClothPhysicsSimulator:
    """ÏùòÎ•ò Î¨ºÎ¶¨ ÏãúÎÆ¨Î†àÏù¥ÏÖò ÏóîÏßÑ"""
    
    def __init__(self, properties: PhysicsProperties):
        self.properties = properties
        self.mesh_vertices = None
        self.mesh_faces = None
        self.velocities = None
        self.forces = None
        
    def create_cloth_mesh(self, width: int, height: int, resolution: int = 32) -> Tuple[np.ndarray, np.ndarray]:
        """ÏùòÎ•ò Î©îÏãú ÏÉùÏÑ±"""
        x = np.linspace(0, width-1, resolution)
        y = np.linspace(0, height-1, resolution)
        xx, yy = np.meshgrid(x, y)
        
        # Ï†ïÏ†ê ÏÉùÏÑ±
        vertices = np.column_stack([xx.flatten(), yy.flatten(), np.zeros(xx.size)])
        
        # Î©¥ ÏÉùÏÑ± (ÏÇºÍ∞ÅÌòï)
        faces = []
        for i in range(resolution-1):
            for j in range(resolution-1):
                # ÏÇ¨Í∞ÅÌòïÏùÑ Îëê Í∞úÏùò ÏÇºÍ∞ÅÌòïÏúºÎ°ú Î∂ÑÌï†
                idx = i * resolution + j
                faces.append([idx, idx+1, idx+resolution])
                faces.append([idx+1, idx+resolution+1, idx+resolution])
        
        self.mesh_vertices = vertices
        self.mesh_faces = np.array(faces)
        self.velocities = np.zeros_like(vertices)
        self.forces = np.zeros_like(vertices)
        
        return vertices, self.mesh_faces
    
    def apply_gravity(self, dt: float = 0.016):
        """Ï§ëÎ†• Ï†ÅÏö©"""
        gravity = np.array([0, 0, -9.81]) * self.properties.density * dt
        self.forces[:, 2] += gravity[2]
    
    def apply_spring_forces(self, stiffness: float = 1000.0):
        """Ïä§ÌîÑÎßÅ Ìûò Ï†ÅÏö©"""
        if self.mesh_vertices is None:
            return
            
        # Ïù∏Ï†ë Ï†ïÏ†ê Í∞Ñ Ïä§ÌîÑÎßÅ Ìûò Í≥ÑÏÇ∞
        for face in self.mesh_faces:
            for i in range(3):
                v1_idx, v2_idx = face[i], face[(i+1)%3]
                v1, v2 = self.mesh_vertices[v1_idx], self.mesh_vertices[v2_idx]
                
                # Í±∞Î¶¨ Í≥ÑÏÇ∞
                displacement = v2 - v1
                distance = np.linalg.norm(displacement)
                
                if distance > 0:
                    # Ïä§ÌîÑÎßÅ Ìûò
                    spring_force = stiffness * displacement
                    self.forces[v1_idx] += spring_force
                    self.forces[v2_idx] -= spring_force
    
    def integrate_verlet(self, dt: float = 0.016):
        """Verlet Ï†ÅÎ∂ÑÏúºÎ°ú ÏãúÎÆ¨Î†àÏù¥ÏÖò"""
        if self.mesh_vertices is None:
            return
            
        # Í∞ÄÏÜçÎèÑ Í≥ÑÏÇ∞
        acceleration = self.forces / self.properties.density
        
        # Verlet Ï†ÅÎ∂Ñ
        new_vertices = (2 * self.mesh_vertices - 
                       (self.mesh_vertices - self.velocities * dt) + 
                       acceleration * dt * dt)
        
        # ÎåêÌïë Ï†ÅÏö©
        damping = 1.0 - self.properties.friction_coefficient * dt
        self.velocities = (new_vertices - self.mesh_vertices) / dt * damping
        self.mesh_vertices = new_vertices
        
        # Ìûò Ï¥àÍ∏∞Ìôî
        self.forces.fill(0)
    
    def simulate_step(self, dt: float = 0.016):
        """ÏãúÎÆ¨Î†àÏù¥ÏÖò Îã®Í≥Ñ Ïã§Ìñâ"""
        self.apply_gravity(dt)
        self.apply_spring_forces()
        self.integrate_verlet(dt)
    
    def get_deformed_mesh(self) -> np.ndarray:
        """Î≥ÄÌòïÎêú Î©îÏãú Î∞òÌôò"""
        return self.mesh_vertices.copy() if self.mesh_vertices is not None else None

# ==============================================
# üî• AI Î™®Îç∏ ÌÅ¥ÎûòÏä§Îì§
# ==============================================

class HRVITONModel(nn.Module):
    """HRVITON Í∏∞Î∞ò Í≥†Í∏â Cloth Warping Î™®Îç∏"""
    
    def __init__(self, input_size: Tuple[int, int] = (512, 384), num_control_points: int = 25):
        super().__init__()
        self.input_size = input_size
        self.num_control_points = num_control_points
        self.device = "cpu"
        
        # Ïù∏ÏΩîÎçî (ResNet Î∞±Î≥∏)
        self.encoder = self._build_encoder()
        
        # TPS ÌöåÍ∑Ä Ìó§Îìú
        self.tps_head = nn.Sequential(
            nn.AdaptiveAvgPool2d((1, 1)),
            nn.Flatten(),
            nn.Linear(512, 256),
            nn.ReLU(inplace=True),
            nn.Dropout(0.5),
            nn.Linear(256, num_control_points * 2)  # x, y Ï¢åÌëú
        )
        
        # ÏÑ∏Î∞ÄÌïú Î≥ÄÌòï ÏòàÏ∏° Ìó§Îìú
        self.detail_head = nn.Sequential(
            nn.ConvTranspose2d(512, 256, 4, stride=2, padding=1),
            nn.BatchNorm2d(256),
            nn.ReLU(inplace=True),
            nn.ConvTranspose2d(256, 128, 4, stride=2, padding=1),
            nn.BatchNorm2d(128),
            nn.ReLU(inplace=True),
            nn.ConvTranspose2d(128, 64, 4, stride=2, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(inplace=True),
            nn.ConvTranspose2d(64, 2, 4, stride=2, padding=1),  # flow field
            nn.Tanh()
        )
        
        # ÏùòÎ•ò ÏÉùÏÑ± ÎîîÏΩîÎçî
        self.cloth_decoder = self._build_decoder()
        
    def _build_encoder(self):
        """Ïù∏ÏΩîÎçî Íµ¨ÏÑ±"""
        return nn.Sequential(
            # ÏûÖÎ†•: cloth + person = 6 channels
            nn.Conv2d(6, 64, 7, stride=2, padding=3, bias=False),
            nn.BatchNorm2d(64),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),
            
            # ResNet blocks
            self._make_layer(64, 64, 2),
            self._make_layer(64, 128, 2, stride=2),
            self._make_layer(128, 256, 2, stride=2),
            self._make_layer(256, 512, 2, stride=2),
        )
    
    def _build_decoder(self):
        """ÎîîÏΩîÎçî Íµ¨ÏÑ±"""
        return nn.Sequential(
            nn.ConvTranspose2d(512, 256, 4, stride=2, padding=1),
            nn.BatchNorm2d(256),
            nn.ReLU(inplace=True),
            
            nn.ConvTranspose2d(256, 128, 4, stride=2, padding=1),
            nn.BatchNorm2d(128),
            nn.ReLU(inplace=True),
            
            nn.ConvTranspose2d(128, 64, 4, stride=2, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(inplace=True),
            
            nn.ConvTranspose2d(64, 3, 4, stride=2, padding=1),
            nn.Tanh()
        )
    
    def _make_layer(self, in_channels: int, out_channels: int, blocks: int, stride: int = 1):
        """ResNet Î†àÏù¥Ïñ¥ ÏÉùÏÑ±"""
        layers = []
        layers.append(self._make_block(in_channels, out_channels, stride))
        for _ in range(1, blocks):
            layers.append(self._make_block(out_channels, out_channels))
        return nn.Sequential(*layers)
    
    def _make_block(self, in_channels: int, out_channels: int, stride: int = 1):
        """ResNet Î∏îÎ°ù ÏÉùÏÑ±"""
        return nn.Sequential(
            nn.Conv2d(in_channels, out_channels, 3, stride=stride, padding=1, bias=False),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True),
            nn.Conv2d(out_channels, out_channels, 3, padding=1, bias=False),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True)
        )
    
    def forward(self, cloth_img: torch.Tensor, person_img: torch.Tensor) -> Dict[str, torch.Tensor]:
        """ÏàúÏ†ÑÌåå"""
        # ÏûÖÎ†• Í≤∞Ìï©
        x = torch.cat([cloth_img, person_img], dim=1)  # [B, 6, H, W]
        
        # ÌäπÏßï Ï∂îÏ∂ú
        features = self.encoder(x)  # [B, 512, H/16, W/16]
        
        # TPS Ï†úÏñ¥Ï†ê ÏòàÏ∏°
        tps_params = self.tps_head(features)  # [B, num_control_points * 2]
        
        # ÏÑ∏Î∞ÄÌïú Î≥ÄÌòï ÌïÑÎìú ÏòàÏ∏°
        flow_field = self.detail_head(features)  # [B, 2, H, W]
        
        # ÏõåÌïëÎêú ÏùòÎ•ò ÏÉùÏÑ±
        warped_cloth = self.cloth_decoder(features)  # [B, 3, H, W]
        
        return {
            'warped_cloth': warped_cloth,
            'tps_parameters': tps_params.view(-1, self.num_control_points, 2),
            'flow_field': flow_field,
            'features': features
        }
    
    def to(self, device):
        """ÎîîÎ∞îÏù¥Ïä§ Ïù¥Îèô"""
        self.device = device
        return super().to(device)

# ==============================================
# üî• ÏãúÍ∞ÅÌôî ÏóîÏßÑ
# ==============================================

class WarpingVisualizer:
    """ÏõåÌïë Í≥ºÏ†ï ÏãúÍ∞ÅÌôî ÏóîÏßÑ"""
    
    def __init__(self, quality: str = "high"):
        self.quality = quality
        self.dpi = {"low": 72, "medium": 150, "high": 300, "ultra": 600}[quality]
        
    def create_warping_visualization(self, 
                                   original_cloth: np.ndarray,
                                   warped_cloth: np.ndarray,
                                   control_points: np.ndarray,
                                   flow_field: Optional[np.ndarray] = None,
                                   physics_mesh: Optional[np.ndarray] = None) -> np.ndarray:
        """ÏõåÌïë Í≥ºÏ†ï Ï¢ÖÌï© ÏãúÍ∞ÅÌôî"""
        
        # Ï∫îÎ≤ÑÏä§ ÌÅ¨Í∏∞ Í≥ÑÏÇ∞
        h, w = original_cloth.shape[:2]
        canvas_w = w * 3  # ÏõêÎ≥∏, ÏõåÌïë, Î∂ÑÏÑù
        canvas_h = h * 2  # ÏÉÅÎã®, ÌïòÎã®
        
        # Ï∫îÎ≤ÑÏä§ ÏÉùÏÑ±
        canvas = np.ones((canvas_h, canvas_w, 3), dtype=np.uint8) * 255
        
        # 1. ÏõêÎ≥∏ ÏùòÎ•ò (Ï¢åÏÉÅÎã®)
        canvas[0:h, 0:w] = original_cloth
        
        # 2. ÏõåÌïëÎêú ÏùòÎ•ò (Ï§ëÏÉÅÎã®)
        canvas[0:h, w:2*w] = warped_cloth
        
        # 3. Ï†úÏñ¥Ï†ê ÏãúÍ∞ÅÌôî (Ïö∞ÏÉÅÎã®)
        control_vis = self._visualize_control_points(original_cloth, control_points)
        canvas[0:h, 2*w:3*w] = control_vis
        
        # 4. ÌîåÎ°úÏö∞ ÌïÑÎìú ÏãúÍ∞ÅÌôî (Ï¢åÌïòÎã®)
        if flow_field is not None:
            flow_vis = self._visualize_flow_field(flow_field)
            canvas[h:2*h, 0:w] = flow_vis
        
        # 5. Î¨ºÎ¶¨ Î©îÏãú ÏãúÍ∞ÅÌôî (Ï§ëÌïòÎã®)
        if physics_mesh is not None:
            mesh_vis = self._visualize_physics_mesh(original_cloth, physics_mesh)
            canvas[h:2*h, w:2*w] = mesh_vis
        
        # 6. Î≥ÄÌòï Î∂ÑÏÑù (Ïö∞ÌïòÎã®)
        deformation_vis = self._visualize_deformation_analysis(original_cloth, warped_cloth)
        canvas[h:2*h, 2*w:3*w] = deformation_vis
        
        # ÌÖçÏä§Ìä∏ ÎùºÎ≤® Ï∂îÍ∞Ä
        canvas = self._add_labels(canvas, w, h)
        
        return canvas
    
    def _visualize_control_points(self, image: np.ndarray, control_points: np.ndarray) -> np.ndarray:
        """Ï†úÏñ¥Ï†ê ÏãúÍ∞ÅÌôî"""
        vis = image.copy()
        
        # Ï†úÏñ¥Ï†ê Í∑∏Î¶¨Í∏∞
        for i, point in enumerate(control_points):
            x, y = int(point[0]), int(point[1])
            # Ï†úÏñ¥Ï†ê
            cv2.circle(vis, (x, y), 5, (255, 0, 0), -1)
            # Î≤àÌò∏
            cv2.putText(vis, str(i), (x+8, y+5), cv2.FONT_HERSHEY_SIMPLEX, 0.3, (255, 255, 255), 1)
        
        # Delaunay ÏÇºÍ∞ÅÎ∂ÑÌï† Í∑∏Î¶¨Í∏∞
        if len(control_points) >= 3:
            try:
                rect = (0, 0, image.shape[1], image.shape[0])
                subdiv = cv2.Subdiv2D(rect)
                for point in control_points:
                    subdiv.insert((float(point[0]), float(point[1])))
                
                triangles = subdiv.getTriangleList()
                for t in triangles:
                    pt1 = (int(t[0]), int(t[1]))
                    pt2 = (int(t[2]), int(t[3]))
                    pt3 = (int(t[4]), int(t[5]))
                    cv2.line(vis, pt1, pt2, (0, 255, 0), 1)
                    cv2.line(vis, pt2, pt3, (0, 255, 0), 1)
                    cv2.line(vis, pt3, pt1, (0, 255, 0), 1)
            except Exception:
                pass
        
        return vis
    
    def _visualize_flow_field(self, flow_field: np.ndarray) -> np.ndarray:
        """ÌîåÎ°úÏö∞ ÌïÑÎìú ÏãúÍ∞ÅÌôî"""
        h, w = flow_field.shape[1:3]
        
        # ÌîåÎ°úÏö∞ Î≤°ÌÑ∞Î•º ÏÉâÏÉÅÏúºÎ°ú Î≥ÄÌôò
        flow_magnitude = np.sqrt(flow_field[0]**2 + flow_field[1]**2)
        flow_angle = np.arctan2(flow_field[1], flow_field[0])
        
        # HSV ÏÉâÏÉÅ Í≥µÍ∞Ñ ÏÇ¨Ïö©
        hsv = np.zeros((h, w, 3), dtype=np.uint8)
        hsv[..., 0] = (flow_angle + np.pi) / (2 * np.pi) * 179  # Hue
        hsv[..., 1] = 255  # Saturation
        hsv[..., 2] = np.clip(flow_magnitude * 255, 0, 255)  # Value
        
        # RGBÎ°ú Î≥ÄÌôò
        flow_vis = cv2.cvtColor(hsv, cv2.COLOR_HSV2RGB)
        
        # Î≤°ÌÑ∞ ÌôîÏÇ¥Ìëú Í∑∏Î¶¨Í∏∞ (ÏÑúÎ∏åÏÉòÌîåÎßÅ)
        step = max(h//20, w//20, 10)
        for y in range(0, h, step):
            for x in range(0, w, step):
                dx = int(flow_field[0, y, x] * 10)
                dy = int(flow_field[1, y, x] * 10)
                cv2.arrowedLine(flow_vis, (x, y), (x+dx, y+dy), (255, 255, 255), 1)
        
        return flow_vis
    
    def _visualize_physics_mesh(self, image: np.ndarray, mesh_vertices: np.ndarray) -> np.ndarray:
        """Î¨ºÎ¶¨ Î©îÏãú ÏãúÍ∞ÅÌôî"""
        vis = image.copy()
        
        # Î©îÏãú Ï†ïÏ†ê Í∑∏Î¶¨Í∏∞
        for vertex in mesh_vertices:
            x, y = int(vertex[0]), int(vertex[1])
            cv2.circle(vis, (x, y), 2, (0, 255, 255), -1)
        
        return vis
    
    def _visualize_deformation_analysis(self, original: np.ndarray, warped: np.ndarray) -> np.ndarray:
        """Î≥ÄÌòï Î∂ÑÏÑù ÏãúÍ∞ÅÌôî"""
        # Ï∞®Ïù¥ Îßµ Í≥ÑÏÇ∞
        diff = cv2.absdiff(original, warped)
        diff_gray = cv2.cvtColor(diff, cv2.COLOR_RGB2GRAY)
        
        # ÌûàÌä∏Îßµ ÏÉùÏÑ±
        heatmap = cv2.applyColorMap(diff_gray, cv2.COLORMAP_JET)
        
        # ÏõêÎ≥∏Í≥º Î∏îÎ†åÎî©
        blended = cv2.addWeighted(original, 0.7, heatmap, 0.3, 0)
        
        return blended
    
    def _add_labels(self, canvas: np.ndarray, w: int, h: int) -> np.ndarray:
        """ÎùºÎ≤® Ï∂îÍ∞Ä"""
        labels = [
            ("Original", (10, 30)),
            ("Warped", (w + 10, 30)),
            ("Control Points", (2*w + 10, 30)),
            ("Flow Field", (10, h + 30)),
            ("Physics Mesh", (w + 10, h + 30)),
            ("Deformation", (2*w + 10, h + 30))
        ]
        
        for label, pos in labels:
            cv2.putText(canvas, label, pos, cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 2)
        
        return canvas
    
    def create_progress_visualization(self, steps: List[np.ndarray], step_names: List[str]) -> np.ndarray:
        """Îã®Í≥ÑÎ≥Ñ ÏßÑÌñâ ÏãúÍ∞ÅÌôî"""
        if not steps:
            return np.zeros((100, 100, 3), dtype=np.uint8)
        
        num_steps = len(steps)
        step_h, step_w = steps[0].shape[:2]
        
        # Í≤©Ïûê Î†àÏù¥ÏïÑÏõÉ Í≥ÑÏÇ∞
        cols = min(num_steps, 4)
        rows = (num_steps + cols - 1) // cols
        
        canvas_w = step_w * cols
        canvas_h = step_h * rows
        canvas = np.ones((canvas_h, canvas_w, 3), dtype=np.uint8) * 255
        
        for i, (step_img, step_name) in enumerate(zip(steps, step_names)):
            row = i // cols
            col = i % cols
            
            start_y = row * step_h
            end_y = start_y + step_h
            start_x = col * step_w
            end_x = start_x + step_w
            
            canvas[start_y:end_y, start_x:end_x] = step_img
            
            # Îã®Í≥Ñ Ïù¥Î¶Ñ Ï∂îÍ∞Ä
            cv2.putText(canvas, step_name, (start_x + 10, start_y + 30), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 0), 2)
        
        return canvas

# ==============================================
# üî• ÏôÑÏ†ÑÌïú ClothWarpingStep ÌÅ¥ÎûòÏä§ (PoseEstimationStep Ìå®ÌÑ¥ ÏôÑÏ†Ñ Ï†ÅÏö©)
# ==============================================

class ClothWarpingStep(ClothWarpingMixin):
    """
    üî• ÏôÑÏ†ÑÌïú Cloth Warping Step v3.0 - PoseEstimationStep Ìå®ÌÑ¥ ÏôÑÏ†Ñ Ï†ÅÏö©
    ‚úÖ utils ÌÜµÌï© Ïù∏ÌÑ∞ÌéòÏù¥Ïä§ ÏôÑÏ†Ñ Ïó∞Îèô
    ‚úÖ ÌÜµÏùºÎêú ÏÉùÏÑ±Ïûê Ìå®ÌÑ¥
    ‚úÖ ÏôÑÏ†ÑÌïú ÏóêÎü¨ Ï≤òÎ¶¨ Î∞è Ï∫êÏãú Í¥ÄÎ¶¨
    ‚úÖ logger ÏÜçÏÑ± ÏôÑÎ≤Ω ÏßÄÏõê
    ‚úÖ Î™®Îì† Í∏∞Îä• 100% Ìè¨Ìï®
    """
    
    # ÏùòÎ•ò ÌÉÄÏûÖÎ≥Ñ ÏõåÌïë Í∞ÄÏ§ëÏπò (PoseEstimationStep Ìå®ÌÑ¥)
    CLOTHING_WARPING_WEIGHTS = CLOTHING_WARPING_WEIGHTS
    
    def __init__(
        self,
        device: Optional[str] = None,
        config: Optional[Dict[str, Any]] = None,
        **kwargs
    ):
        """‚úÖ ÌÜµÏùºÎêú ÏÉùÏÑ±Ïûê Ìå®ÌÑ¥ - BaseStepMixin + utils ÏôÑÏ†Ñ ÌÜµÌï© (PoseEstimationStepÍ≥º ÎèôÏùº)"""
        
        # 1. BaseStepMixin Ï¥àÍ∏∞Ìôî
        super().__init__()
        
        # 2. Í∏∞Î≥∏ ÏÑ§Ï†ï
        self.device = self._auto_detect_device(device)
        self.config = config or {}
        self.step_name = self.__class__.__name__
        self.step_number = 5
        self.logger = logging.getLogger(f"pipeline.{self.step_name}")
        
        # 3. ÏãúÏä§ÌÖú Ï†ïÎ≥¥ Ï∂îÏ∂ú (kwargsÏóêÏÑú) - PoseEstimationStep Ìå®ÌÑ¥
        self.device_type = kwargs.get('device_type', self._get_device_type())
        self.memory_gb = float(kwargs.get('memory_gb', self._get_memory_gb()))
        self.is_m3_max = kwargs.get('is_m3_max', self._detect_m3_max())
        self.optimization_enabled = kwargs.get('optimization_enabled', True)
        self.quality_level = kwargs.get('quality_level', 'balanced')
        
        # 4. ÏÑ§Ï†ï ÏóÖÎç∞Ïù¥Ìä∏
        self._update_config_from_kwargs(kwargs)
        
        # 5. Ï¥àÍ∏∞Ìôî
        self.is_initialized = False
        self.initialization_error = None
        self.performance_stats = {
            'total_processed': 0,
            'total_time': 0.0,
            'average_time': 0.0,
            'last_processing_time': 0.0,
            'average_confidence': 0.0,
            'peak_memory_usage': 0.0,
            'error_count': 0,
            'cache_hits': 0,
            'cache_misses': 0
        }
        
        # 6. ÏùòÎ•ò ÏõåÌïë ÏãúÏä§ÌÖú Ï¥àÍ∏∞Ìôî
        try:
            self._initialize_step_specific()
            self._setup_utils_interface()  # üî• ÌïµÏã¨: utils ÌÜµÌï© Ïù∏ÌÑ∞ÌéòÏù¥Ïä§ ÏÑ§Ï†ï
            self._setup_warping_models()
            self._setup_processing_pipeline()
            self.is_initialized = True
            self.logger.info(f"‚úÖ {self.step_name} Ï¥àÍ∏∞Ìôî ÏôÑÎ£å - M3 Max: {self.is_m3_max}")
        except Exception as e:
            self.initialization_error = str(e)
            self.logger.error(f"‚ùå {self.step_name} Ï¥àÍ∏∞Ìôî Ïã§Ìå®: {e}")
    
    def _auto_detect_device(self, device: Optional[str]) -> str:
        """ÎîîÎ∞îÏù¥Ïä§ ÏûêÎèô Í∞êÏßÄ - M3 Max ÏµúÏ†ÅÌôî (PoseEstimationStep ÎèôÏùº)"""
        if device:
            return device
        
        if UTILS_AVAILABLE:
            return DEFAULT_DEVICE
        
        # Ìè¥Î∞± Í∞êÏßÄ
        if TORCH_AVAILABLE:
            try:
                if torch.backends.mps.is_available():
                    return "mps"
                elif torch.cuda.is_available():
                    return "cuda"
            except Exception as e:
                logger.warning(f"ÎîîÎ∞îÏù¥Ïä§ Í∞êÏßÄ Ïã§Ìå®: {e}")
        
        return "cpu"
    
    def _get_device_type(self) -> str:
        """ÎîîÎ∞îÏù¥Ïä§ ÌÉÄÏûÖ Î∞òÌôò (PoseEstimationStep ÎèôÏùº)"""
        try:
            if self.device == "mps":
                return "apple_silicon"
            elif self.device == "cuda":
                return "nvidia_gpu"
            else:
                return "cpu"
        except Exception as e:
            logger.warning(f"ÎîîÎ∞îÏù¥Ïä§ ÌÉÄÏûÖ Í∞êÏßÄ Ïã§Ìå®: {e}")
            return "cpu"
    
    def _get_memory_gb(self) -> float:
        """Î©îÎ™®Î¶¨ ÌÅ¨Í∏∞ Í∞êÏßÄ (PoseEstimationStep ÎèôÏùº)"""
        try:
            if UTILS_AVAILABLE:
                return MEMORY_GB
            elif PSUTIL_AVAILABLE:
                return psutil.virtual_memory().total / (1024**3)
            else:
                return 16.0  # Í∏∞Î≥∏Í∞í
        except Exception as e:
            logger.warning(f"Î©îÎ™®Î¶¨ Í∞êÏßÄ Ïã§Ìå®: {e}")
            return 16.0
    
    def _detect_m3_max(self) -> bool:
        """M3 Max Í∞êÏßÄ (PoseEstimationStep ÎèôÏùº)"""
        if UTILS_AVAILABLE:
            return IS_M3_MAX
        
        try:
            import platform
            if platform.system() == "Darwin":
                import subprocess
                result = subprocess.run(['sysctl', '-n', 'machdep.cpu.brand_string'], 
                                      capture_output=True, text=True, timeout=5)
                return "M3" in result.stdout and "Max" in result.stdout
        except Exception as e:
            logger.debug(f"M3 Max Í∞êÏßÄ Ïã§Ìå®: {e}")
            pass
        return False
    
    def _update_config_from_kwargs(self, kwargs: Dict[str, Any]):
        """kwargsÏóêÏÑú config ÏóÖÎç∞Ïù¥Ìä∏ (PoseEstimationStep ÎèôÏùº)"""
        system_params = {
            'device_type', 'memory_gb', 'is_m3_max', 
            'optimization_enabled', 'quality_level'
        }
        
        for key, value in kwargs.items():
            if key not in system_params:
                self.config[key] = value
    
    def _setup_utils_interface(self):
        """üî• ÌïµÏã¨: utils ÌÜµÌï© Ïù∏ÌÑ∞ÌéòÏù¥Ïä§ ÏÑ§Ï†ï (PoseEstimationStepÍ≥º ÎèôÏùº)"""
        try:
            if UTILS_AVAILABLE:
                # utils/__init__.pyÏùò create_step_interface ÏÇ¨Ïö©
                self.utils_interface = create_step_interface(self.step_name)
                
                # Í∞úÎ≥Ñ Ïù∏ÌÑ∞ÌéòÏù¥Ïä§ Ï∂îÏ∂ú
                self.memory_manager = self.utils_interface.get("memory_manager")
                self.model_loader = self.utils_interface.get("model_loader")
                self.data_converter = self.utils_interface.get("data_converter")
                self.get_model_func = self.utils_interface.get("get_model")
                self.process_image_func = self.utils_interface.get("process_image")
                self.optimize_memory_func = self.utils_interface.get("optimize_memory")
                
                self.logger.info(f"üîó {self.step_name} utils Ïù∏ÌÑ∞ÌéòÏù¥Ïä§ Ïó∞Îèô ÏôÑÎ£å")
            else:
                # Ìè¥Î∞± Ïù∏ÌÑ∞ÌéòÏù¥Ïä§
                self._setup_fallback_interface()
                
        except Exception as e:
            self.logger.error(f"‚ùå utils Ïù∏ÌÑ∞ÌéòÏù¥Ïä§ ÏÑ§Ï†ï Ïã§Ìå®: {e}")
            self._setup_fallback_interface()
    
    def _setup_fallback_interface(self):
        """Ìè¥Î∞± Ïù∏ÌÑ∞ÌéòÏù¥Ïä§ ÏÑ§Ï†ï (PoseEstimationStep ÎèôÏùº)"""
        self.utils_interface = {}
        self.memory_manager = None
        self.model_loader = None
        self.data_converter = None
        self.get_model_func = lambda x: None
        self.process_image_func = lambda x, **kwargs: None
        self.optimize_memory_func = lambda **kwargs: {"success": False}
        
        self.logger.warning(f"‚ö†Ô∏è utils Ïù∏ÌÑ∞ÌéòÏù¥Ïä§ ÏÇ¨Ïö© Î∂àÍ∞Ä, Ìè¥Î∞± Î™®Îìú")
    
    def _initialize_step_specific(self):
        """5Îã®Í≥Ñ Ï†ÑÏö© Ï¥àÍ∏∞Ìôî"""
        
        # ÏùòÎ•ò ÏõåÌïë ÏÑ§Ï†ï
        self.warping_config = {
            'warping_method': self.config.get('warping_method', WarpingMethod.AI_MODEL),
            'confidence_threshold': self.config.get('confidence_threshold', 0.5),
            'visualization_enabled': self.config.get('visualization_enabled', True),
            'return_analysis': self.config.get('return_analysis', True),
            'cache_enabled': self.config.get('cache_enabled', True),
            'batch_processing': self.config.get('batch_processing', False),
            'detailed_analysis': self.config.get('detailed_analysis', False)
        }
        
        # ÏµúÏ†ÅÌôî Î†àÎ≤® ÏÑ§Ï†ï (PoseEstimationStep Ìå®ÌÑ¥)
        if self.is_m3_max:
            self.optimization_level = 'maximum'
            self.batch_processing = True
            self.use_neural_engine = True
        elif self.memory_gb >= 32:
            self.optimization_level = 'high'
            self.batch_processing = True
            self.use_neural_engine = False
        else:
            self.optimization_level = 'basic'
            self.batch_processing = False
            self.use_neural_engine = False
        
        # Ï∫êÏãú ÏãúÏä§ÌÖú (PoseEstimationStep Ìå®ÌÑ¥)
        cache_size = min(100 if self.is_m3_max else 50, int(self.memory_gb * 2))
        self.prediction_cache = {}
        self.cache_max_size = cache_size
        
        # ÌïµÏã¨ Ïª¥Ìè¨ÎÑåÌä∏Îì§
        self.hrviton_model = None
        self.tps_transform = AdvancedTPSTransform(self.config.get('num_control_points', 25))
        self.physics_simulator = None
        self.visualizer = WarpingVisualizer(self.config.get('visualization_quality', 'high'))
        
        # Î≥ÄÌôò ÌååÏù¥ÌîÑÎùºÏù∏
        self.transform = self._create_transforms()
        
        # Ï§ëÍ∞Ñ Í≤∞Í≥º Ï†ÄÏû• (ÏãúÍ∞ÅÌôîÏö©)
        self.intermediate_results = []
        
        # Ïä§Î†àÎìú ÌíÄ
        self.executor = ThreadPoolExecutor(max_workers=4, thread_name_prefix="ClothWarping")
        
        self.logger.info(f"üéØ 5Îã®Í≥Ñ ÏÑ§Ï†ï ÏôÑÎ£å - ÏµúÏ†ÅÌôî: {self.optimization_level}")
    
    def _create_transforms(self):
        """Ïù¥ÎØ∏ÏßÄ Î≥ÄÌôò ÌååÏù¥ÌîÑÎùºÏù∏ ÏÉùÏÑ±"""
        if not TORCH_AVAILABLE:
            return None
        
        transform_list = [
            transforms.Resize(self.config.get('input_size', (512, 384))),
            transforms.ToTensor()
        ]
        
        # Ï†ïÍ∑úÌôî (Î™®Îç∏Ïóê Îî∞Îùº Îã§Î¶Ñ)
        ai_model_name = self.config.get('ai_model_name', 'cloth_warping_hrviton')
        if ai_model_name == "cloth_warping_hrviton":
            transform_list.append(
                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
            )
        else:
            transform_list.append(
                transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])
            )
        
        return transforms.Compose(transform_list)
    
    def _setup_warping_models(self):
        """ÏùòÎ•ò ÏõåÌïë Î™®Îç∏Îì§ ÏÑ§Ï†ï"""
        self.warping_models = {}
        self.active_model = None
        
        try:
            # AI Î™®Îç∏ Ïö∞ÏÑ†ÏàúÏúÑ
            model_priority = ['hrviton', 'tom', 'physics_only']
            
            # AI Î™®Îç∏ ÏÑ§Ï†ïÏùÄ ÎÇòÏ§ëÏóê Î°úÎìú
            self.active_model = 'hrviton'  # Í∏∞Î≥∏Í∞í
            
            self.logger.info(f"üéØ ÌôúÏÑ± ÏõåÌïë Î™®Îç∏: {self.active_model}")
                
        except Exception as e:
            self.logger.error(f"‚ùå ÏõåÌïë Î™®Îç∏ ÏÑ§Ï†ï Ïã§Ìå®: {e}")
            self.warping_models = {}
            self.active_model = 'simulation'
    
    def _setup_processing_pipeline(self):
        """ÏõåÌïë Ï≤òÎ¶¨ ÌååÏù¥ÌîÑÎùºÏù∏ ÏÑ§Ï†ï (PoseEstimationStep Ìå®ÌÑ¥)"""
        
        # Ï≤òÎ¶¨ ÏàúÏÑú Ï†ïÏùò
        self.processing_pipeline = []
        
        # 1. Ï†ÑÏ≤òÎ¶¨
        self.processing_pipeline.append(('preprocessing', self._preprocess_for_warping))
        
        # 2. AI Î™®Îç∏ Ï∂îÎ°†
        if self.config.get('ai_model_enabled', True):
            self.processing_pipeline.append(('ai_inference', self._perform_ai_inference))
        
        # 3. Î¨ºÎ¶¨ ÏãúÎÆ¨Î†àÏù¥ÏÖò
        if self.config.get('physics_enabled', True):
            self.processing_pipeline.append(('physics_simulation', self._perform_physics_simulation))
        
        # 4. ÌõÑÏ≤òÎ¶¨
        self.processing_pipeline.append(('postprocessing', self._postprocess_warping_results))
        
        # 5. ÌíàÏßà Î∂ÑÏÑù
        if self.warping_config['return_analysis']:
            self.processing_pipeline.append(('quality_analysis', self._analyze_warping_quality))
        
        # 6. ÏãúÍ∞ÅÌôî
        if self.warping_config['visualization_enabled']:
            self.processing_pipeline.append(('visualization', self._create_warping_visualization))
        
        self.logger.info(f"üîÑ ÏõåÌïë Ï≤òÎ¶¨ ÌååÏù¥ÌîÑÎùºÏù∏ ÏÑ§Ï†ï ÏôÑÎ£å - {len(self.processing_pipeline)}Îã®Í≥Ñ")
    
    # =================================================================
    # üöÄ Î©îÏù∏ Ï≤òÎ¶¨ Ìï®Ïàò (Pipeline Manager Ìò∏Ï∂ú) - PoseEstimationStep Ìå®ÌÑ¥
    # =================================================================
    
    async def process(
        self,
        cloth_image: Union[np.ndarray, str, Path, Image.Image],
        person_image: Union[np.ndarray, str, Path, Image.Image],
        cloth_mask: Optional[np.ndarray] = None,
        fabric_type: str = "cotton",
        clothing_type: str = "shirt",
        **kwargs
    ) -> Dict[str, Any]:
        """
        ‚úÖ Î©îÏù∏ ÏùòÎ•ò ÏõåÌïë Ìï®Ïàò - Pipeline Manager ÌëúÏ§Ä Ïù∏ÌÑ∞ÌéòÏù¥Ïä§ (PoseEstimationStep Ìå®ÌÑ¥)
        """
        start_time = time.time()
        
        try:
            # 1. Ï¥àÍ∏∞Ìôî Í≤ÄÏ¶ù
            if not self.is_initialized:
                raise ValueError(f"ClothWarpingStepÏù¥ Ï¥àÍ∏∞ÌôîÎêòÏßÄ ÏïäÏïòÏäµÎãàÎã§: {self.initialization_error}")
            
            # 2. Ïù¥ÎØ∏ÏßÄ Î°úÎìú Î∞è Í≤ÄÏ¶ù
            cloth_img = self._load_and_validate_image(cloth_image)
            person_img = self._load_and_validate_image(person_image)
            if cloth_img is None or person_img is None:
                raise ValueError("Ïú†Ìö®ÌïòÏßÄ ÏïäÏùÄ Ïù¥ÎØ∏ÏßÄÏûÖÎãàÎã§")
            
            # 3. Ï∫êÏãú ÌôïÏù∏ (PoseEstimationStep Ìå®ÌÑ¥)
            cache_key = self._generate_cache_key(cloth_img, person_img, clothing_type, kwargs)
            if self.warping_config['cache_enabled'] and cache_key in self.prediction_cache:
                self.logger.info("üìã Ï∫êÏãúÏóêÏÑú ÏõåÌïë Í≤∞Í≥º Î∞òÌôò")
                self.performance_stats['cache_hits'] += 1
                cached_result = self.prediction_cache[cache_key].copy()
                cached_result['from_cache'] = True
                return cached_result
            
            self.performance_stats['cache_misses'] += 1
            
            # 4. Î©îÎ™®Î¶¨ ÏµúÏ†ÅÌôî
            if self.is_m3_max and self.optimize_memory_func:
                try:
                    await self.optimize_memory_func()
                except Exception as e:
                    logger.debug(f"Î©îÎ™®Î¶¨ ÏµúÏ†ÅÌôî Ïã§Ìå®: {e}")
            
            # 5. Î©îÏù∏ ÏõåÌïë ÌååÏù¥ÌîÑÎùºÏù∏ Ïã§Ìñâ
            warping_result = await self._execute_warping_pipeline(
                cloth_img, person_img, cloth_mask, fabric_type, clothing_type, **kwargs
            )
            
            # 6. Í≤∞Í≥º ÌõÑÏ≤òÎ¶¨
            result = self._build_final_warping_result(warping_result, clothing_type, time.time() - start_time)
            
            # 7. Ï∫êÏãú Ï†ÄÏû•
            if self.warping_config['cache_enabled']:
                self._save_to_cache(cache_key, result)
            
            # 8. ÌÜµÍ≥Ñ ÏóÖÎç∞Ïù¥Ìä∏
            self._update_performance_stats(time.time() - start_time, warping_result.get('confidence', 0.0))
            
            self.logger.info(f"‚úÖ ÏùòÎ•ò ÏõåÌïë ÏôÑÎ£å - ÌíàÏßà: {result.get('quality_grade', 'F')}")
            return result
            
        except Exception as e:
            error_msg = f"ÏùòÎ•ò ÏõåÌïë Ïã§Ìå®: {e}"
            self.logger.error(f"‚ùå {error_msg}")
            
            processing_time = time.time() - start_time
            self._update_performance_stats(processing_time, 0.0, success=False)
            
            return self._create_error_result(error_msg, processing_time)
    
    def _create_error_result(self, error_message: str, processing_time: float = 0.0) -> Dict[str, Any]:
        """ÏóêÎü¨ Í≤∞Í≥º ÏÉùÏÑ± (PoseEstimationStep Ìå®ÌÑ¥)"""
        return {
            "success": False,
            "step_name": self.step_name,
            "error": error_message,
            "processing_time": processing_time,
            "warped_cloth_image": None,
            "control_points": [],
            "confidence": 0.0,
            "quality_grade": "F",
            "warping_analysis": {
                "deformation_quality": 0.0,
                "physics_quality": 0.0,
                "texture_quality": 0.0,
                "overall_score": 0.0
            },
            "suitable_for_fitting": False,
            "fitting_confidence": 0.0,
            "visualization": None,
            "progress_visualization": None,
            "from_cache": False,
            "device_info": {
                "device": self.device,
                "error_count": self.performance_stats.get('error_count', 0)
            }
        }
    
    # =================================================================
    # üîß ÏõåÌïë ÌïµÏã¨ Ìï®ÏàòÎì§ (PoseEstimationStep Ìå®ÌÑ¥ Ï†ÅÏö©)
    # =================================================================
    
    async def _execute_warping_pipeline(
        self,
        cloth_image: np.ndarray,
        person_image: np.ndarray,
        cloth_mask: Optional[np.ndarray],
        fabric_type: str,
        clothing_type: str,
        **kwargs
    ) -> Dict[str, Any]:
        """ÏõåÌïë ÌååÏù¥ÌîÑÎùºÏù∏ Ïã§Ìñâ (PoseEstimationStep Ìå®ÌÑ¥)"""
        
        intermediate_results = {}
        current_data = {
            'cloth_image': cloth_image,
            'person_image': person_image,
            'cloth_mask': cloth_mask,
            'fabric_type': fabric_type,
            'clothing_type': clothing_type
        }
        
        self.logger.info(f"üîÑ ÏùòÎ•ò ÏõåÌïë ÌååÏù¥ÌîÑÎùºÏù∏ ÏãúÏûë - ÏùòÎ•ò: {clothing_type}, ÏõêÎã®: {fabric_type}")
        
        # Ï§ëÍ∞Ñ Í≤∞Í≥º Ï¥àÍ∏∞Ìôî
        self.intermediate_results = []
        
        for step_name, processor_func in self.processing_pipeline:
            try:
                step_start = time.time()
                
                # Îã®Í≥ÑÎ≥Ñ Ï≤òÎ¶¨
                step_result = await processor_func(current_data, **kwargs)
                current_data.update(step_result if isinstance(step_result, dict) else {})
                
                step_time = time.time() - step_start
                intermediate_results[step_name] = {
                    'processing_time': step_time,
                    'success': True
                }
                
                self.logger.debug(f"  ‚úì {step_name} ÏôÑÎ£å - {step_time:.3f}Ï¥à")
                
            except Exception as e:
                self.logger.warning(f"  ‚ö†Ô∏è {step_name} Ïã§Ìå®: {e}")
                intermediate_results[step_name] = {
                    'processing_time': 0,
                    'success': False,
                    'error': str(e)
                }
                continue
        
        # Ï†ÑÏ≤¥ Ï†êÏàò Í≥ÑÏÇ∞
        try:
            clothing_weights = self.CLOTHING_WARPING_WEIGHTS.get(clothing_type, self.CLOTHING_WARPING_WEIGHTS['default'])
            overall_score = self._calculate_overall_warping_score(current_data, clothing_weights)
            current_data['overall_score'] = overall_score
            current_data['quality_grade'] = self._get_quality_grade(overall_score)
        except Exception as e:
            self.logger.warning(f"ÏõåÌïë Ï†êÏàò Í≥ÑÏÇ∞ Ïã§Ìå®: {e}")
            current_data['overall_score'] = 0.0
            current_data['quality_grade'] = 'F'
        
        self.logger.info(f"‚úÖ ÏõåÌïë ÌååÏù¥ÌîÑÎùºÏù∏ ÏôÑÎ£å - {len(intermediate_results)}Îã®Í≥Ñ Ï≤òÎ¶¨")
        return current_data
    
    async def _preprocess_for_warping(self, data: Dict[str, Any], **kwargs) -> Dict[str, Any]:
        """ÏõåÌïëÏùÑ ÏúÑÌïú Ï†ÑÏ≤òÎ¶¨"""
        try:
            cloth_image = data['cloth_image']
            person_image = data['person_image']
            cloth_mask = data.get('cloth_mask')
            
            # Ïù¥ÎØ∏ÏßÄ ÌÅ¨Í∏∞ Ï†ïÍ∑úÌôî
            target_size = self.config.get('input_size', (512, 384))
            
            def resize_image(img):
                if max(img.shape[:2]) != target_size[0]:
                    return cv2.resize(img, target_size, interpolation=cv2.INTER_LANCZOS4)
                return img
            
            cloth_resized = resize_image(cloth_image)
            person_resized = resize_image(person_image)
            
            if cloth_mask is not None:
                cloth_mask_resized = cv2.resize(cloth_mask, target_size, interpolation=cv2.INTER_NEAREST)
            else:
                cloth_mask_resized = None
            
            # Ï§ëÍ∞Ñ Í≤∞Í≥º Ï†ÄÏû•
            if self.config.get('save_intermediate_results', True):
                self.intermediate_results.append({
                    'step': 'preprocess',
                    'cloth': cloth_resized,
                    'person': person_resized
                })
            
            return {
                'preprocessed_cloth': cloth_resized,
                'preprocessed_person': person_resized,
                'preprocessed_mask': cloth_mask_resized
            }
            
        except Exception as e:
            self.logger.error(f"ÏõåÌïë Ï†ÑÏ≤òÎ¶¨ Ïã§Ìå®: {e}")
            return {}
    
    async def _perform_ai_inference(self, data: Dict[str, Any], **kwargs) -> Dict[str, Any]:
        """AI Î™®Îç∏ Ï∂îÎ°† (utils Ïù∏ÌÑ∞ÌéòÏù¥Ïä§ Ïó∞Îèô)"""
        try:
            cloth_image = data.get('preprocessed_cloth', data['cloth_image'])
            person_image = data.get('preprocessed_person', data['person_image'])
            
            # utils Ïù∏ÌÑ∞ÌéòÏù¥Ïä§Î•º ÌÜµÌïú AI Î™®Îç∏ Î°úÎìú
            if self.get_model_func:
                ai_model = await self.get_model_func("cloth_warping_hrviton")
                
                if ai_model and TORCH_AVAILABLE:
                    # Ïù¥ÎØ∏ÏßÄ Ï†ÑÏ≤òÎ¶¨
                    if self.process_image_func:
                        cloth_tensor = self.process_image_func(cloth_image, operation="to_tensor", size=self.config.get('input_size', (512, 384)))
                        person_tensor = self.process_image_func(person_image, operation="to_tensor", size=self.config.get('input_size', (512, 384)))
                    else:
                        # Ìè¥Î∞± Ï†ÑÏ≤òÎ¶¨
                        cloth_tensor, person_tensor = self._manual_preprocess_for_ai(cloth_image, person_image)
                    
                    # Î™®Îç∏ Ï∂îÎ°†
                    with torch.no_grad():
                        if self.device == "mps" and self.is_m3_max:
                            with autocast(device_type='cpu', dtype=torch.float16):
                                ai_results = ai_model(cloth_tensor, person_tensor)
                        else:
                            ai_results = ai_model(cloth_tensor, person_tensor)
                    
                    # Í≤∞Í≥º ÌõÑÏ≤òÎ¶¨
                    warped_cloth_np = self._tensor_to_numpy(ai_results['warped_cloth'][0])
                    control_points = ai_results['tps_parameters'][0].cpu().numpy() if len(ai_results['tps_parameters'].shape) > 2 else ai_results['tps_parameters'].cpu().numpy().reshape(-1, 2)
                    flow_field_np = ai_results.get('flow_field', [None])[0].cpu().numpy() if ai_results.get('flow_field') is not None else None
                    
                    # Ïã†Î¢∞ÎèÑ Í≥ÑÏÇ∞
                    ai_confidence = self._calculate_ai_confidence(ai_results)
                    
                    # Ï§ëÍ∞Ñ Í≤∞Í≥º Ï†ÄÏû•
                    if self.config.get('save_intermediate_results', True):
                        self.intermediate_results.append({
                            'step': 'ai_inference',
                            'warped_cloth': warped_cloth_np,
                            'control_points': control_points,
                            'flow_field': flow_field_np
                        })
                    
                    return {
                        'ai_warped_cloth': warped_cloth_np,
                        'ai_control_points': control_points,
                        'ai_flow_field': flow_field_np,
                        'ai_confidence': ai_confidence,
                        'ai_success': True
                    }
            
            # Ìè¥Î∞±: ÏãúÎÆ¨Î†àÏù¥ÏÖò Î™®Îìú
            return await self._simulation_ai_inference(cloth_image, person_image)
            
        except Exception as e:
            self.logger.error(f"AI Ï∂îÎ°† Ïã§Ìå®: {e}")
            return await self._simulation_ai_inference(
                data.get('preprocessed_cloth', data['cloth_image']),
                data.get('preprocessed_person', data['person_image'])
            )
    
    async def _simulation_ai_inference(self, cloth_image: np.ndarray, person_image: np.ndarray) -> Dict[str, Any]:
        """ÏãúÎÆ¨Î†àÏù¥ÏÖò AI Ï∂îÎ°† (Ìè¥Î∞±)"""
        try:
            h, w = cloth_image.shape[:2]
            
            # ÏãúÎÆ¨Î†àÏù¥ÏÖòÎêú ÏõåÌïë (Í∞ÑÎã®Ìïú Î≥ÄÌòï)
            warped_cloth = cloth_image.copy()
            
            # ÏïΩÍ∞ÑÏùò Î≥ÄÌòï Ìö®Í≥º Ï∂îÍ∞Ä
            shift_x, shift_y = 5, 3
            M = np.float32([[1, 0, shift_x], [0, 1, shift_y]])
            warped_cloth = cv2.warpAffine(warped_cloth, M, (w, h))
            
            # ÏãúÎÆ¨Î†àÏù¥ÏÖòÎêú Ï†úÏñ¥Ï†ê
            num_points = self.config.get('num_control_points', 25)
            control_points = []
            grid_size = int(np.sqrt(num_points))
            
            for i in range(grid_size):
                for j in range(grid_size):
                    x = w * i / (grid_size - 1)
                    y = h * j / (grid_size - 1)
                    # ÏïΩÍ∞ÑÏùò ÎûúÎç§ Î≥ÄÌòï
                    x += np.random.normal(0, 2)
                    y += np.random.normal(0, 2)
                    control_points.append([x, y])
            
            control_points = np.array(control_points[:num_points])
            
            return {
                'ai_warped_cloth': warped_cloth,
                'ai_control_points': control_points,
                'ai_flow_field': None,
                'ai_confidence': 0.7,
                'ai_success': True,
                'simulation_mode': True
            }
            
        except Exception as e:
            self.logger.error(f"ÏãúÎÆ¨Î†àÏù¥ÏÖò AI Ï∂îÎ°† Ïã§Ìå®: {e}")
            return {
                'ai_warped_cloth': cloth_image,
                'ai_control_points': np.array([[0, 0]]),
                'ai_flow_field': None,
                'ai_confidence': 0.0,
                'ai_success': False
            }
    
    async def _perform_physics_simulation(self, data: Dict[str, Any], **kwargs) -> Dict[str, Any]:
        """Î¨ºÎ¶¨ ÏãúÎÆ¨Î†àÏù¥ÏÖò ÏàòÌñâ"""
        try:
            cloth_image = data.get('ai_warped_cloth', data.get('preprocessed_cloth', data['cloth_image']))
            fabric_type = data.get('fabric_type', 'cotton')
            control_points = data.get('ai_control_points', [])
            
            # Î¨ºÎ¶¨ ÏãúÎÆ¨Î†àÏù¥ÌÑ∞ Ï¥àÍ∏∞Ìôî
            if not hasattr(self, 'physics_simulator') or self.physics_simulator is None:
                fabric_properties = PhysicsProperties(
                    fabric_type=FabricType(fabric_type.lower()) if fabric_type.lower() in [ft.value for ft in FabricType] else FabricType.COTTON,
                    elastic_modulus=self.config.get('elastic_modulus', 1000.0),
                    poisson_ratio=self.config.get('poisson_ratio', 0.3)
                )
                self.physics_simulator = ClothPhysicsSimulator(fabric_properties)
            
            h, w = cloth_image.shape[:2]
            
            # ÏùòÎ•ò Î©îÏãú ÏÉùÏÑ±
            vertices, faces = self.physics_simulator.create_cloth_mesh(w, h, resolution=32)
            
            # ÏãúÎÆ¨Î†àÏù¥ÏÖò Ïã§Ìñâ
            num_steps = 10
            for _ in range(num_steps):
                self.physics_simulator.simulate_step(dt=0.016)
            
            # Î≥ÄÌòïÎêú Î©îÏãú Í∞ÄÏ†∏Ïò§Í∏∞
            deformed_mesh = self.physics_simulator.get_deformed_mesh()
            
            # ÏµúÏ¢Ö ÏõåÌïë Ï†ÅÏö©
            if deformed_mesh is not None and len(control_points) > 0:
                physics_warped = self.tps_transform.apply_transform(cloth_image, vertices[:, :2], deformed_mesh[:, :2])
            else:
                physics_warped = cloth_image
            
            # Ï§ëÍ∞Ñ Í≤∞Í≥º Ï†ÄÏû•
            if self.config.get('save_intermediate_results', True):
                self.intermediate_results.append({
                    'step': 'physics_simulation',
                    'original_mesh': vertices,
                    'deformed_mesh': deformed_mesh,
                    'physics_warped': physics_warped
                })
            
            return {
                'physics_warped_cloth': physics_warped,
                'physics_deformed_mesh': deformed_mesh,
                'physics_original_mesh': vertices,
                'physics_simulation_steps': num_steps,
                'physics_success': True
            }
            
        except Exception as e:
            self.logger.error(f"Î¨ºÎ¶¨ ÏãúÎÆ¨Î†àÏù¥ÏÖò Ïã§Ìå®: {e}")
            # Ìè¥Î∞±: ÏõêÎ≥∏ Î∞òÌôò
            return {
                'physics_warped_cloth': data.get('ai_warped_cloth', data.get('preprocessed_cloth', data['cloth_image'])),
                'physics_deformed_mesh': None,
                'physics_original_mesh': None,
                'physics_simulation_steps': 0,
                'physics_success': False
            }
    
    async def _postprocess_warping_results(self, data: Dict[str, Any], **kwargs) -> Dict[str, Any]:
        """ÏõåÌïë Í≤∞Í≥º ÌõÑÏ≤òÎ¶¨"""
        try:
            # Í≤∞Í≥º Í≤∞Ìï© (AI + Physics)
            ai_warped = data.get('ai_warped_cloth')
            physics_warped = data.get('physics_warped_cloth')
            warping_method = self.config.get('warping_method', WarpingMethod.AI_MODEL)
            
            if isinstance(warping_method, str):
                warping_method = WarpingMethod(warping_method)
            
            if warping_method == WarpingMethod.HYBRID and ai_warped is not None and physics_warped is not None:
                # ÌïòÏù¥Î∏åÎ¶¨Îìú: AIÏôÄ Î¨ºÎ¶¨ Í≤∞Ìï©
                final_warped = self._combine_ai_and_physics(ai_warped, physics_warped, blend_ratio=0.7)
            elif warping_method == WarpingMethod.PHYSICS_BASED and physics_warped is not None:
                # Î¨ºÎ¶¨ Í∏∞Î∞ò Ïö∞ÏÑ†
                final_warped = physics_warped
            elif ai_warped is not None:
                # AI Í∏∞Î∞ò Ïö∞ÏÑ†
                final_warped = ai_warped
            else:
                # Ìè¥Î∞±: ÏõêÎ≥∏
                final_warped = data.get('preprocessed_cloth', data['cloth_image'])
            
            # ÌíàÏßà Ìñ•ÏÉÅ (ÏÑ†ÌÉùÏ†Å)
            if self.config.get('enable_enhancement', False):
                final_warped = self._enhance_warped_cloth(final_warped)
            
            return {
                'final_warped_cloth': final_warped,
                'warping_method_used': warping_method.value
            }
            
        except Exception as e:
            self.logger.error(f"ÏõåÌïë ÌõÑÏ≤òÎ¶¨ Ïã§Ìå®: {e}")
            return {
                'final_warped_cloth': data.get('ai_warped_cloth', data.get('preprocessed_cloth', data['cloth_image'])),
                'warping_method_used': 'fallback'
            }
    
    async def _analyze_warping_quality(self, data: Dict[str, Any], **kwargs) -> Dict[str, Any]:
        """ÏõåÌïë ÌíàÏßà Î∂ÑÏÑù"""
        try:
            original_cloth = data.get('preprocessed_cloth', data['cloth_image'])
            warped_cloth = data.get('final_warped_cloth')
            clothing_type = data.get('clothing_type', 'default')
            
            if warped_cloth is None:
                return {'warping_analysis': {'overall_score': 0.0, 'quality_grade': 'F'}}
            
            # 1. Î≥ÄÌòï ÌíàÏßà Î∂ÑÏÑù
            deformation_quality = self._analyze_deformation_quality(original_cloth, warped_cloth)
            
            # 2. Î¨ºÎ¶¨Ï†Å ÏÇ¨Ïã§ÏÑ± Î∂ÑÏÑù
            physics_quality = self._analyze_physics_realism(data)
            
            # 3. ÌÖçÏä§Ï≤ò Î≥¥Ï°¥ÎèÑ Î∂ÑÏÑù
            texture_quality = self._analyze_texture_preservation(original_cloth, warped_cloth)
            
            # 4. ÏùòÎ•òÎ≥Ñ Í∞ÄÏ§ëÏπò Ï†ÅÏö©
            clothing_weights = self.CLOTHING_WARPING_WEIGHTS.get(clothing_type, self.CLOTHING_WARPING_WEIGHTS['default'])
            
            overall_score = (
                deformation_quality * clothing_weights.get('deformation', 0.4) +
                physics_quality * clothing_weights.get('physics', 0.3) +
                texture_quality * clothing_weights.get('texture', 0.3)
            )
            
            quality_grade = self._get_quality_grade(overall_score)
            
            # 5. ÌîºÌåÖ Ï†ÅÌï©ÏÑ±
            suitable_for_fitting = (
                overall_score >= 0.6 and
                deformation_quality >= 0.5 and
                data.get('ai_success', False)
            )
            
            return {
                'warping_analysis': {
                    'deformation_quality': float(deformation_quality),
                    'physics_quality': float(physics_quality),
                    'texture_quality': float(texture_quality),
                    'overall_score': float(overall_score),
                    'quality_grade': quality_grade,
                    'suitable_for_fitting': suitable_for_fitting,
                    'clothing_weights': clothing_weights
                }
            }
            
        except Exception as e:
            self.logger.error(f"ÏõåÌïë ÌíàÏßà Î∂ÑÏÑù Ïã§Ìå®: {e}")
            return {
                'warping_analysis': {
                    'deformation_quality': 0.0,
                    'physics_quality': 0.0,
                    'texture_quality': 0.0,
                    'overall_score': 0.0,
                    'quality_grade': 'F',
                    'suitable_for_fitting': False
                }
            }
    
    async def _create_warping_visualization(self, data: Dict[str, Any], **kwargs) -> Dict[str, Any]:
        """ÏõåÌïë ÏãúÍ∞ÅÌôî ÏÉùÏÑ±"""
        try:
            if not self.warping_config.get('visualization_enabled', True):
                return {'visualization': None, 'progress_visualization': None}
            
            original_cloth = data.get('preprocessed_cloth', data['cloth_image'])
            warped_cloth = data.get('final_warped_cloth')
            control_points = data.get('ai_control_points', [])
            flow_field = data.get('ai_flow_field')
            physics_mesh = data.get('physics_deformed_mesh')
            
            if warped_cloth is None:
                return {'visualization': None, 'progress_visualization': None}
            
            # Î©îÏù∏ ÏõåÌïë ÏãúÍ∞ÅÌôî
            main_visualization = self.visualizer.create_warping_visualization(
                original_cloth, warped_cloth, control_points, flow_field, physics_mesh
            )
            
            # ÏßÑÌñâ Í≥ºÏ†ï ÏãúÍ∞ÅÌôî
            progress_visualization = None
            if self.intermediate_results:
                steps = []
                step_names = []
                
                for result in self.intermediate_results:
                    step_name = result['step']
                    if 'warped_cloth' in result:
                        steps.append(result['warped_cloth'])
                        step_names.append(step_name)
                    elif 'cloth' in result:
                        steps.append(result['cloth'])
                        step_names.append(step_name)
                    elif 'physics_warped' in result:
                        steps.append(result['physics_warped'])
                        step_names.append(step_name)
                
                if steps:
                    progress_visualization = self.visualizer.create_progress_visualization(steps, step_names)
            
            # Ïù¥ÎØ∏ÏßÄÎ•º base64Î°ú Ïù∏ÏΩîÎî©
            visualization_base64 = ""
            progress_base64 = ""
            
            if PIL_AVAILABLE:
                try:
                    if main_visualization is not None:
                        pil_main = Image.fromarray(main_visualization)
                        main_buffer = BytesIO()
                        pil_main.save(main_buffer, format='PNG')
                        visualization_base64 = base64.b64encode(main_buffer.getvalue()).decode()
                    
                    if progress_visualization is not None:
                        pil_progress = Image.fromarray(progress_visualization)
                        progress_buffer = BytesIO()
                        pil_progress.save(progress_buffer, format='PNG')
                        progress_base64 = base64.b64encode(progress_buffer.getvalue()).decode()
                        
                except Exception as e:
                    self.logger.warning(f"ÏãúÍ∞ÅÌôî Ïù∏ÏΩîÎî© Ïã§Ìå®: {e}")
            
            return {
                'visualization': visualization_base64,
                'progress_visualization': progress_base64
            }
            
        except Exception as e:
            self.logger.error(f"ÏõåÌïë ÏãúÍ∞ÅÌôî ÏÉùÏÑ± Ïã§Ìå®: {e}")
            return {'visualization': None, 'progress_visualization': None}
    
    # =================================================================
    # üîß Ïú†Ìã∏Î¶¨Ìã∞ Ìï®ÏàòÎì§ (PoseEstimationStep Ìå®ÌÑ¥)
    # =================================================================
    
    def _load_and_validate_image(self, image_input: Union[np.ndarray, str, Path, Image.Image]) -> Optional[np.ndarray]:
        """Ïù¥ÎØ∏ÏßÄ Î°úÎìú Î∞è Í≤ÄÏ¶ù (PoseEstimationStep ÎèôÏùº)"""
        try:
            if isinstance(image_input, np.ndarray):
                image = image_input
            elif isinstance(image_input, Image.Image):
                image = np.array(image_input.convert('RGB'))
            elif isinstance(image_input, (str, Path)):
                if PIL_AVAILABLE:
                    pil_img = Image.open(image_input)
                    image = np.array(pil_img.convert('RGB'))
                elif CV2_AVAILABLE:
                    image = cv2.imread(str(image_input))
                    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
                else:
                    raise ImportError("PIL ÎòêÎäî OpenCVÍ∞Ä ÌïÑÏöîÌï©ÎãàÎã§")
            else:
                raise ValueError(f"ÏßÄÏõêÌïòÏßÄ ÏïäÎäî Ïù¥ÎØ∏ÏßÄ ÌÉÄÏûÖ: {type(image_input)}")
            
            # Í≤ÄÏ¶ù
            if image.ndim != 3 or image.shape[2] != 3:
                raise ValueError("RGB Ïù¥ÎØ∏ÏßÄÏó¨Ïïº Ìï©ÎãàÎã§")
            
            if image.size == 0:
                raise ValueError("Îπà Ïù¥ÎØ∏ÏßÄÏûÖÎãàÎã§")
            
            return image
            
        except Exception as e:
            self.logger.error(f"Ïù¥ÎØ∏ÏßÄ Î°úÎìú Ïã§Ìå®: {e}")
            return None
    
    def _generate_cache_key(self, cloth_image: np.ndarray, person_image: np.ndarray, 
                          clothing_type: str, kwargs: Dict[str, Any]) -> str:
        """Ï∫êÏãú ÌÇ§ ÏÉùÏÑ± (PoseEstimationStep Ìå®ÌÑ¥)"""
        try:
            # Ïù¥ÎØ∏ÏßÄ Ìï¥Ïãú
            cloth_hash = hashlib.md5(cloth_image.tobytes()).hexdigest()[:16]
            person_hash = hashlib.md5(person_image.tobytes()).hexdigest()[:16]
            
            # ÏÑ§Ï†ï Ìï¥Ïãú
            config_data = {
                'clothing_type': clothing_type,
                'warping_method': str(self.config.get('warping_method', 'ai_model')),
                'ai_model_enabled': self.config.get('ai_model_enabled', True),
                'physics_enabled': self.config.get('physics_enabled', True),
                **{k: v for k, v in kwargs.items() if isinstance(v, (str, int, float, bool))}
            }
            config_str = json.dumps(config_data, sort_keys=True)
            config_hash = hashlib.md5(config_str.encode()).hexdigest()[:8]
            
            return f"warping_{cloth_hash}_{person_hash}_{config_hash}"
            
        except Exception:
            return f"warping_fallback_{time.time()}"
    
    def _save_to_cache(self, cache_key: str, result: Dict[str, Any]):
        """Ï∫êÏãúÏóê Í≤∞Í≥º Ï†ÄÏû• (PoseEstimationStep Ìå®ÌÑ¥)"""
        try:
            if len(self.prediction_cache) >= self.cache_max_size:
                # LRU Î∞©ÏãùÏúºÎ°ú Ïò§ÎûòÎêú Ìï≠Î™© Ï†úÍ±∞
                oldest_key = min(self.prediction_cache.keys())
                del self.prediction_cache[oldest_key]
                self.logger.debug(f"Ï∫êÏãú Ìï≠Î™© Ï†úÍ±∞: {oldest_key}")
            
            # Î©îÎ™®Î¶¨ Ï†àÏïΩÏùÑ ÏúÑÌï¥ ÌÅ∞ Ïù¥ÎØ∏ÏßÄÎäî Ï∫êÏãúÏóêÏÑú Ï†úÏô∏
            cached_result = result.copy()
            for img_key in ['visualization', 'progress_visualization']:
                if img_key in cached_result:
                    cached_result[img_key] = ""
            
            self.prediction_cache[cache_key] = cached_result
            self.logger.debug(f"Ï∫êÏãú Ï†ÄÏû• ÏôÑÎ£å: {cache_key}")
            
        except Exception as e:
            self.logger.warning(f"Ï∫êÏãú Ï†ÄÏû• Ïã§Ìå®: {e}")
    
    def clear_cache(self):
        """Ï∫êÏãú ÏôÑÏ†Ñ ÏÇ≠Ï†ú (PoseEstimationStep ÎèôÏùº)"""
        try:
            if hasattr(self, 'prediction_cache'):
                cache_size = len(self.prediction_cache)
                self.prediction_cache.clear()
                self.logger.info(f"‚úÖ Ï∫êÏãú ÏÇ≠Ï†ú ÏôÑÎ£å: {cache_size}Í∞ú Ìï≠Î™©")
                return {"success": True, "cleared_items": cache_size}
            else:
                return {"success": True, "cleared_items": 0}
        except Exception as e:
            self.logger.error(f"‚ùå Ï∫êÏãú ÏÇ≠Ï†ú Ïã§Ìå®: {e}")
            return {"success": False, "error": str(e)}
    
    def get_cache_status(self) -> Dict[str, Any]:
        """Ï∫êÏãú ÏÉÅÌÉú Ï°∞Ìöå (PoseEstimationStep ÎèôÏùº)"""
        try:
            if hasattr(self, 'prediction_cache'):
                return {
                    "cache_enabled": self.warping_config.get('cache_enabled', False),
                    "current_size": len(self.prediction_cache),
                    "max_size": self.cache_max_size,
                    "hit_rate": self.performance_stats['cache_hits'] / max(1, self.performance_stats['cache_hits'] + self.performance_stats['cache_misses']),
                    "cache_hits": self.performance_stats['cache_hits'],
                    "cache_misses": self.performance_stats['cache_misses']
                }
            else:
                return {"cache_enabled": False, "current_size": 0}
        except Exception as e:
            self.logger.error(f"Ï∫êÏãú ÏÉÅÌÉú Ï°∞Ìöå Ïã§Ìå®: {e}")
            return {"error": str(e)}
    
    def _update_performance_stats(self, processing_time: float, confidence_score: float, success: bool = True):
        """ÏÑ±Îä• ÌÜµÍ≥Ñ ÏóÖÎç∞Ïù¥Ìä∏ (PoseEstimationStep Ìå®ÌÑ¥)"""
        try:
            if success:
                self.performance_stats['total_processed'] += 1
                self.performance_stats['total_time'] += processing_time
                self.performance_stats['average_time'] = (
                    self.performance_stats['total_time'] / self.performance_stats['total_processed']
                )
                
                # ÌèâÍ∑† Ïã†Î¢∞ÎèÑ ÏóÖÎç∞Ïù¥Ìä∏
                current_avg = self.performance_stats.get('average_confidence', 0.0)
                total_processed = self.performance_stats['total_processed']
                self.performance_stats['average_confidence'] = (
                    (current_avg * (total_processed - 1) + confidence_score) / total_processed
                )
            else:
                self.performance_stats['error_count'] += 1
            
            self.performance_stats['last_processing_time'] = processing_time
            
            # Î©îÎ™®Î¶¨ ÏÇ¨Ïö©Îüâ Ï∂îÏ†Å (M3 Max)
            if self.is_m3_max and PSUTIL_AVAILABLE:
                try:
                    memory_usage = psutil.virtual_memory().percent
                    self.performance_stats['peak_memory_usage'] = max(
                        self.performance_stats.get('peak_memory_usage', 0),
                        memory_usage
                    )
                except Exception as e:
                    self.logger.debug(f"Î©îÎ™®Î¶¨ ÏÇ¨Ïö©Îüâ Ï∂îÏ†Å Ïã§Ìå®: {e}")
            
        except Exception as e:
            self.logger.warning(f"ÏÑ±Îä• ÌÜµÍ≥Ñ ÏóÖÎç∞Ïù¥Ìä∏ Ïã§Ìå®: {e}")
    
    def _build_final_warping_result(self, warping_data: Dict[str, Any], clothing_type: str, processing_time: float) -> Dict[str, Any]:
        """ÏµúÏ¢Ö ÏõåÌïë Í≤∞Í≥º Íµ¨ÏÑ± (PoseEstimationStep Ìå®ÌÑ¥)"""
        
        try:
            warping_analysis = warping_data.get('warping_analysis', {})
            
            return {
                "success": True,
                "step_name": self.step_name,
                "processing_time": processing_time,
                
                # ÌïµÏã¨ ÏõåÌïë Îç∞Ïù¥ÌÑ∞
                "warped_cloth_image": warping_data.get('final_warped_cloth'),
                "control_points": warping_data.get('ai_control_points', []),
                "flow_field": warping_data.get('ai_flow_field'),
                "confidence": warping_data.get('ai_confidence', 0.0),
                "quality_score": warping_analysis.get('overall_score', 0.0),
                "quality_grade": warping_analysis.get('quality_grade', 'F'),
                
                # ÏõåÌïë Î∂ÑÏÑù
                "warping_analysis": warping_analysis,
                
                # ÌîºÌåÖ Ï†ÅÌï©ÏÑ±
                "suitable_for_fitting": warping_analysis.get('suitable_for_fitting', False),
                "fitting_confidence": min(warping_analysis.get('overall_score', 0.0) * 1.2, 1.0),
                
                # Î©îÌÉÄÎç∞Ïù¥ÌÑ∞
                "clothing_type": clothing_type,
                "fabric_type": warping_data.get('fabric_type', 'unknown'),
                "warping_method": warping_data.get('warping_method_used', 'unknown'),
                "ai_success": warping_data.get('ai_success', False),
                "physics_success": warping_data.get('physics_success', False),
                
                # ÏãúÏä§ÌÖú Ï†ïÎ≥¥
                "device_info": {
                    "device": self.device,
                    "device_type": self.device_type,
                    "is_m3_max": self.is_m3_max,
                    "memory_gb": self.memory_gb,
                    "optimization_level": self.optimization_level,
                    "active_model": getattr(self, 'active_model', 'unknown')
                },
                
                # ÏÑ±Îä• ÌÜµÍ≥Ñ
                "performance_stats": self.performance_stats.copy(),
                
                # ÏãúÍ∞ÅÌôî Ïù¥ÎØ∏ÏßÄÎì§
                "visualization": warping_data.get('visualization'),
                "progress_visualization": warping_data.get('progress_visualization'),
                
                "from_cache": False
            }
        except Exception as e:
            self.logger.error(f"ÏµúÏ¢Ö ÏõåÌïë Í≤∞Í≥º Íµ¨ÏÑ± Ïã§Ìå®: {e}")
            return self._create_error_result(f"Í≤∞Í≥º Íµ¨ÏÑ± Ïã§Ìå®: {e}", processing_time)
    
    # =================================================================
    # üîß ÏõåÌïë Î∂ÑÏÑù Î∞è ÌíàÏßà ÌèâÍ∞Ä Ìï®ÏàòÎì§
    # =================================================================
    
    def _combine_ai_and_physics(self, ai_result: np.ndarray, physics_result: np.ndarray, blend_ratio: float = 0.7) -> np.ndarray:
        """AIÏôÄ Î¨ºÎ¶¨ Í≤∞Í≥º Í≤∞Ìï©"""
        try:
            # ÎèôÏùºÌïú ÌÅ¨Í∏∞Î°ú Ï°∞Ï†ï
            if ai_result.shape != physics_result.shape:
                physics_result = cv2.resize(physics_result, (ai_result.shape[1], ai_result.shape[0]))
            
            # Í∞ÄÏ§ë ÌèâÍ∑† Î∏îÎ†åÎî©
            combined = (ai_result * blend_ratio + physics_result * (1 - blend_ratio)).astype(np.uint8)
            
            return combined
            
        except Exception as e:
            self.logger.error(f"AI-Physics Í≤∞Ìï© Ïã§Ìå®: {e}")
            return ai_result  # AI Í≤∞Í≥ºÎ°ú Ìè¥Î∞±
    
    def _analyze_deformation_quality(self, original: np.ndarray, warped: np.ndarray) -> float:
        """Î≥ÄÌòï ÌíàÏßà Î∂ÑÏÑù"""
        try:
            # 1. Íµ¨Ï°∞Ï†Å Ïú†ÏÇ¨ÏÑ± (SSIM)
            ssim_score = 0.5  # Í∏∞Î≥∏Í∞í
            if SKIMAGE_AVAILABLE:
                try:
                    from skimage.metrics import structural_similarity as ssim
                    ssim_score = ssim(original, warped, multichannel=True, channel_axis=2)
                except Exception:
                    pass
            
            # 2. ÏóêÏßÄ Î≥¥Ï°¥ÎèÑ
            edge_score = self._calculate_edge_preservation(original, warped)
            
            # 3. ÌÖçÏä§Ï≤ò ÏùºÍ¥ÄÏÑ±
            texture_score = self._calculate_texture_consistency(original, warped)
            
            # Ï¢ÖÌï© Ï†êÏàò
            deformation_quality = (ssim_score * 0.4 + edge_score * 0.3 + texture_score * 0.3)
            
            return max(0.0, min(1.0, deformation_quality))
            
        except Exception as e:
            self.logger.warning(f"Î≥ÄÌòï ÌíàÏßà Î∂ÑÏÑù Ïã§Ìå®: {e}")
            return 0.5
    
    def _analyze_physics_realism(self, data: Dict[str, Any]) -> float:
        """Î¨ºÎ¶¨Ï†Å ÏÇ¨Ïã§ÏÑ± Î∂ÑÏÑù"""
        try:
            physics_success = data.get('physics_success', False)
            if not physics_success:
                return 0.3  # Î¨ºÎ¶¨ ÏãúÎÆ¨Î†àÏù¥ÏÖò Ïã§Ìå® Ïãú ÎÇÆÏùÄ Ï†êÏàò
            
            # Î¨ºÎ¶¨ Î©îÏãú ÌíàÏßà ÌèâÍ∞Ä
            original_mesh = data.get('physics_original_mesh')
            deformed_mesh = data.get('physics_deformed_mesh')
            
            if original_mesh is None or deformed_mesh is None:
                return 0.5
            
            # Î≥ÄÌòï Ï†ïÎèÑ Í≥ÑÏÇ∞
            deformation_magnitude = np.mean(np.linalg.norm(deformed_mesh - original_mesh, axis=1))
            
            # Ï†ÅÏ†àÌïú Î≥ÄÌòï Î≤îÏúÑ (ÎÑàÎ¨¥ ÌÅ¨Í±∞ÎÇò ÏûëÏúºÎ©¥ Í∞êÏ†ê)
            optimal_deformation = 5.0  # ÌîΩÏÖÄ Îã®ÏúÑ
            deformation_score = 1.0 - min(abs(deformation_magnitude - optimal_deformation) / optimal_deformation, 1.0)
            
            return max(0.0, min(1.0, deformation_score))
            
        except Exception as e:
            self.logger.warning(f"Î¨ºÎ¶¨Ï†Å ÏÇ¨Ïã§ÏÑ± Î∂ÑÏÑù Ïã§Ìå®: {e}")
            return 0.5
    
    def _analyze_texture_preservation(self, original: np.ndarray, warped: np.ndarray) -> float:
        """ÌÖçÏä§Ï≤ò Î≥¥Ï°¥ÎèÑ Î∂ÑÏÑù"""
        try:
            # ÌûàÏä§ÌÜ†Í∑∏Îû® ÎπÑÍµê
            orig_hist = cv2.calcHist([original], [0, 1, 2], None, [50, 50, 50], [0, 256, 0, 256, 0, 256])
            warp_hist = cv2.calcHist([warped], [0, 1, 2], None, [50, 50, 50], [0, 256, 0, 256, 0, 256])
            
            # ÏÉÅÍ¥ÄÍ¥ÄÍ≥Ñ Í≥ÑÏÇ∞
            correlation = cv2.compareHist(orig_hist, warp_hist, cv2.HISTCMP_CORREL)
            
            return max(0.0, correlation)
            
        except Exception:
            return 0.5
    
    def _calculate_edge_preservation(self, original: np.ndarray, warped: np.ndarray) -> float:
        """ÏóêÏßÄ Î≥¥Ï°¥ÎèÑ Í≥ÑÏÇ∞"""
        try:
            # Í∑∏Î†àÏù¥Ïä§ÏºÄÏùº Î≥ÄÌôò
            orig_gray = cv2.cvtColor(original, cv2.COLOR_RGB2GRAY)
            warp_gray = cv2.cvtColor(warped, cv2.COLOR_RGB2GRAY)
            
            # ÏóêÏßÄ Í≤ÄÏ∂ú
            orig_edges = cv2.Canny(orig_gray, 50, 150)
            warp_edges = cv2.Canny(warp_gray, 50, 150)
            
            # ÏóêÏßÄ ÏùºÏπòÎèÑ Í≥ÑÏÇ∞
            intersection = np.logical_and(orig_edges, warp_edges)
            union = np.logical_or(orig_edges, warp_edges)
            
            if np.sum(union) > 0:
                iou = np.sum(intersection) / np.sum(union)
                return iou
            else:
                return 1.0
                
        except Exception:
            return 0.5
    
    def _calculate_texture_consistency(self, original: np.ndarray, warped: np.ndarray) -> float:
        """ÌÖçÏä§Ï≤ò ÏùºÍ¥ÄÏÑ± Í≥ÑÏÇ∞"""
        try:
            # Î°úÏª¨ Î∞îÏù¥ÎÑàÎ¶¨ Ìå®ÌÑ¥ ÎπÑÍµê (scikit-image ÏÇ¨Ïö©)
            if SKIMAGE_AVAILABLE:
                orig_gray = cv2.cvtColor(original, cv2.COLOR_RGB2GRAY)
                warp_gray = cv2.cvtColor(warped, cv2.COLOR_RGB2GRAY)
                
                orig_lbp = local_binary_pattern(orig_gray, 8, 1, method='uniform')
                warp_lbp = local_binary_pattern(warp_gray, 8, 1, method='uniform')
                
                # ÌûàÏä§ÌÜ†Í∑∏Îû® ÎπÑÍµê
                orig_hist, _ = np.histogram(orig_lbp, bins=10)
                warp_hist, _ = np.histogram(warp_lbp, bins=10)
                
                # Ï†ïÍ∑úÌôî
                orig_hist = orig_hist.astype(float) / np.sum(orig_hist)
                warp_hist = warp_hist.astype(float) / np.sum(warp_hist)
                
                # ÏΩîÏÇ¨Ïù∏ Ïú†ÏÇ¨ÎèÑ
                cosine_sim = np.dot(orig_hist, warp_hist) / (np.linalg.norm(orig_hist) * np.linalg.norm(warp_hist))
                return cosine_sim
            else:
                # Ìè¥Î∞±: Í∞ÑÎã®Ìïú ÌëúÏ§ÄÌé∏Ï∞® ÎπÑÍµê
                orig_std = np.std(original)
                warp_std = np.std(warped)
                consistency = 1.0 - min(abs(orig_std - warp_std) / max(orig_std, warp_std), 1.0)
                return consistency
                
        except Exception:
            return 0.5
    
    def _calculate_overall_warping_score(self, data: Dict[str, Any], clothing_weights: Dict[str, float]) -> float:
        """Ï†ÑÏ≤¥ ÏõåÌïë Ï†êÏàò Í≥ÑÏÇ∞"""
        try:
            warping_analysis = data.get('warping_analysis', {})
            
            deformation_quality = warping_analysis.get('deformation_quality', 0.0)
            physics_quality = warping_analysis.get('physics_quality', 0.0)
            texture_quality = warping_analysis.get('texture_quality', 0.0)
            
            overall_score = (
                deformation_quality * clothing_weights.get('deformation', 0.4) +
                physics_quality * clothing_weights.get('physics', 0.3) +
                texture_quality * clothing_weights.get('texture', 0.3)
            )
            
            return max(0.0, min(1.0, overall_score))
            
        except Exception as e:
            self.logger.warning(f"Ï†ÑÏ≤¥ ÏõåÌïë Ï†êÏàò Í≥ÑÏÇ∞ Ïã§Ìå®: {e}")
            return 0.0
    
    def _get_quality_grade(self, score: float) -> str:
        """ÌíàÏßà Îì±Í∏â Î∞òÌôò"""
        if score >= 0.9:
            return "A+"
        elif score >= 0.8:
            return "A"
        elif score >= 0.7:
            return "B"
        elif score >= 0.6:
            return "C"
        elif score >= 0.5:
            return "D"
        else:
            return "F"
    
    def _enhance_warped_cloth(self, warped_cloth: np.ndarray) -> np.ndarray:
        """ÏõåÌïëÎêú ÏùòÎ•ò ÌíàÏßà Ìñ•ÏÉÅ"""
        try:
            # Í∞ÑÎã®Ìïú ÏÉ§ÌîÑÎãù ÌïÑÌÑ∞ Ï†ÅÏö©
            kernel = np.array([[-1,-1,-1], [-1,9,-1], [-1,-1,-1]])
            sharpened = cv2.filter2D(warped_cloth, -1, kernel)
            
            # ÏõêÎ≥∏Í≥º Î∏îÎ†åÎî©
            enhanced = cv2.addWeighted(warped_cloth, 0.7, sharpened, 0.3, 0)
            
            return enhanced
            
        except Exception as e:
            self.logger.warning(f"ÏùòÎ•ò ÌíàÏßà Ìñ•ÏÉÅ Ïã§Ìå®: {e}")
            return warped_cloth
    
    # =================================================================
    # üîß AI Î™®Îç∏ Í¥ÄÎ†® Ïú†Ìã∏Î¶¨Ìã∞ Ìï®ÏàòÎì§
    # =================================================================
    
    def _manual_preprocess_for_ai(self, cloth_image: np.ndarray, person_image: np.ndarray) -> Tuple[torch.Tensor, torch.Tensor]:
        """AI Î™®Îç∏Ïö© ÏàòÎèô Ï†ÑÏ≤òÎ¶¨"""
        try:
            input_size = self.config.get('input_size', (512, 384))
            
            def preprocess_single(img):
                # ÌÅ¨Í∏∞ Ï°∞Ï†ï
                resized = cv2.resize(img, input_size)
                # Ï†ïÍ∑úÌôî
                normalized = resized.astype(np.float32) / 255.0
                # ÌÖêÏÑú Î≥ÄÌôò
                if TORCH_AVAILABLE:
                    tensor = torch.from_numpy(normalized.transpose(2, 0, 1)).unsqueeze(0)
                    if self.device != "cpu":
                        tensor = tensor.to(self.device)
                    return tensor
                else:
                    return normalized
            
            cloth_tensor = preprocess_single(cloth_image)
            person_tensor = preprocess_single(person_image)
            
            return cloth_tensor, person_tensor
            
        except Exception as e:
            self.logger.error(f"AI Ï†ÑÏ≤òÎ¶¨ Ïã§Ìå®: {e}")
            return cloth_image, person_image
    
    def _tensor_to_numpy(self, tensor: torch.Tensor) -> np.ndarray:
        """TensorÎ•º NumPy Î∞∞Ïó¥Î°ú Î≥ÄÌôò"""
        try:
            if tensor.dim() == 4:
                tensor = tensor.squeeze(0)
            
            # Î∞òÏ†ïÎ∞ÄÎèÑÏóêÏÑú Îã®Ï†ïÎ∞ÄÎèÑÎ°ú Î≥ÄÌôò
            if tensor.dtype == torch.float16:
                tensor = tensor.float()
            
            # Ï†ïÍ∑úÌôî Ìï¥Ï†ú
            if tensor.min() >= -1 and tensor.max() <= 1:
                # [-1, 1] Î≤îÏúÑÎ•º [0, 255]Î°ú Î≥ÄÌôò
                tensor = (tensor + 1) * 127.5
            else:
                # [0, 1] Î≤îÏúÑÎ•º [0, 255]Î°ú Î≥ÄÌôò
                tensor = tensor * 255
            
            tensor = torch.clamp(tensor, 0, 255)
            
            # CPUÎ°ú Ïù¥Îèô Î∞è NumPy Î≥ÄÌôò
            if tensor.is_cuda or (hasattr(tensor, 'is_mps') and tensor.is_mps):
                tensor = tensor.cpu()
            
            image = tensor.permute(1, 2, 0).numpy().astype(np.uint8)
            return image
            
        except Exception as e:
            self.logger.error(f"Tensor Î≥ÄÌôò Ïã§Ìå®: {e}")
            return np.zeros((512, 384, 3), dtype=np.uint8)
    
    def _calculate_ai_confidence(self, results: Dict[str, torch.Tensor]) -> float:
        """AI Î™®Îç∏ Ïã†Î¢∞ÎèÑ Í≥ÑÏÇ∞"""
        try:
            # ÌäπÏßï ÌôúÏÑ±Ìôî Í∏∞Î∞ò Ïã†Î¢∞ÎèÑ
            features = results.get('features')
            if features is not None:
                activation_mean = torch.mean(torch.abs(features)).item()
                activation_std = torch.std(features).item()
                
                # Ï†ïÍ∑úÌôîÎêú Ïã†Î¢∞ÎèÑ (0-1)
                confidence = min(1.0, activation_mean / (activation_std + 1e-6) * 0.1)
                return confidence
            
            # ÌîåÎ°úÏö∞ ÌïÑÎìú Í∏∞Î∞ò Ïã†Î¢∞ÎèÑ
            flow_field = results.get('flow_field')
            if flow_field is not None:
                flow_magnitude = torch.sqrt(flow_field[0]**2 + flow_field[1]**2)
                flow_consistency = 1.0 / (torch.std(flow_magnitude).item() + 1e-6)
                confidence = min(1.0, flow_consistency * 0.01)
                return confidence
            
            return 0.75  # Í∏∞Î≥∏ Ïã†Î¢∞ÎèÑ
            
        except Exception:
            return 0.5
    
    # =================================================================
    # üîß Î¶¨ÏÜåÏä§ Í¥ÄÎ¶¨ Î∞è Ï†ïÎ¶¨ (PoseEstimationStep Ìå®ÌÑ¥)
    # =================================================================
    
    async def cleanup_models(self):
        """Î™®Îç∏ Î∞è Î¶¨ÏÜåÏä§ Ï†ïÎ¶¨ (PoseEstimationStep Ìå®ÌÑ¥)"""
        try:
            # AI Î™®Îç∏ Ï†ïÎ¶¨
            if self.hrviton_model is not None:
                del self.hrviton_model
                self.hrviton_model = None
            
            # Î¨ºÎ¶¨ ÏãúÎÆ¨Î†àÏù¥ÌÑ∞ Ï†ïÎ¶¨
            if self.physics_simulator is not None:
                del self.physics_simulator
                self.physics_simulator = None
            
            # ÏõåÌïë Î™®Îç∏Îì§ Ï†ïÎ¶¨
            if hasattr(self, 'warping_models'):
                for model_name, model in self.warping_models.items():
                    if hasattr(model, 'close'):
                        model.close()
                    del model
                self.warping_models.clear()
            
            # Ï∫êÏãú Ï†ïÎ¶¨
            self.clear_cache()
            
            # utils Ïù∏ÌÑ∞ÌéòÏù¥Ïä§ Ï†ïÎ¶¨
            if hasattr(self, 'utils_interface') and self.utils_interface:
                # utils Ï†ïÎ¶¨Îäî Ï†ÑÏó≠ Í¥ÄÎ¶¨ÎêòÎØÄÎ°ú Í∞úÎ≥Ñ Ï†ïÎ¶¨ Î∂àÌïÑÏöî
                pass
            
            # Î©îÎ™®Î¶¨ Í¥ÄÎ¶¨Ïûê Ï†ïÎ¶¨
            if hasattr(self, 'memory_manager') and self.memory_manager:
                # Ï†ÑÏó≠ Î©îÎ™®Î¶¨ Í¥ÄÎ¶¨ÏûêÎäî Í∞úÎ≥Ñ Ï†ïÎ¶¨ Î∂àÌïÑÏöî
                pass
            
            # Ïä§Î†àÎìú ÌíÄ Ï†ïÎ¶¨
            if hasattr(self, 'executor'):
                self.executor.shutdown(wait=True)
            
            # GPU Î©îÎ™®Î¶¨ Ï†ïÎ¶¨
            if TORCH_AVAILABLE:
                if self.device == 'mps' and hasattr(torch.backends.mps, 'empty_cache'):
                    torch.backends.mps.empty_cache()
                elif self.device == 'cuda':
                    torch.cuda.empty_cache()
            
            # ÏãúÏä§ÌÖú Î©îÎ™®Î¶¨ Ï†ïÎ¶¨
            gc.collect()
            
            # ÏÉÅÌÉú Ï¥àÍ∏∞Ìôî
            self.is_initialized = False
            self.intermediate_results = []
            
            self.logger.info("üßπ ClothWarpingStep ÏôÑÏ†Ñ Ï†ïÎ¶¨ ÏôÑÎ£å")
            
        except Exception as e:
            self.logger.error(f"‚ùå Î¶¨ÏÜåÏä§ Ï†ïÎ¶¨ Ïã§Ìå®: {e}")
    
    def cleanup_resources(self):
        """Î¶¨ÏÜåÏä§ Ï†ïÎ¶¨ (ÎèôÍ∏∞Ïãù, PoseEstimationStep Ìò∏Ìôò)"""
        try:
            # Ï∫êÏãú Ï†ïÎ¶¨
            self.clear_cache()
            
            # Î©îÎ™®Î¶¨ Ï†ïÎ¶¨
            if TORCH_AVAILABLE and self.device in ["mps", "cuda"]:
                if self.device == "mps":
                    torch.mps.empty_cache()
                elif self.device == "cuda":
                    torch.cuda.empty_cache()
            
            gc.collect()
            
            self.logger.info("‚úÖ ClothWarpingStep Î¶¨ÏÜåÏä§ Ï†ïÎ¶¨ ÏôÑÎ£å")
            
        except Exception as e:
            self.logger.error(f"‚ùå Î¶¨ÏÜåÏä§ Ï†ïÎ¶¨ Ïã§Ìå®: {e}")
    
    # =================================================================
    # üîç ÌëúÏ§Ä Ïù∏ÌÑ∞ÌéòÏù¥Ïä§ Î©îÏÑúÎìúÎì§ (Pipeline Manager Ìò∏Ìôò, PoseEstimationStep Ìå®ÌÑ¥)
    # =================================================================
    
    async def get_step_info(self) -> Dict[str, Any]:
        """Step Ï†ïÎ≥¥ Î∞òÌôò (PoseEstimationStep Ìå®ÌÑ¥)"""
        return {
            "step_name": "ClothWarping",
            "class_name": self.__class__.__name__,
            "version": "3.0-complete-utils-integrated",
            "device": self.device,
            "device_type": self.device_type,
            "memory_gb": self.memory_gb,
            "is_m3_max": self.is_m3_max,
            "optimization_enabled": self.optimization_enabled,
            "quality_level": self.quality_level,
            "initialized": self.is_initialized,
            "initialization_error": self.initialization_error,
            "config_keys": list(self.config.keys()),
            "performance_stats": self.performance_stats.copy(),
            "capabilities": {
                "torch_available": TORCH_AVAILABLE,
                "cv2_available": True,  # cv2Îäî ÌïÑÏàò
                "pil_available": PIL_AVAILABLE,
                "scipy_available": SCIPY_AVAILABLE,
                "sklearn_available": SKLEARN_AVAILABLE,
                "skimage_available": SKIMAGE_AVAILABLE,
                "psutil_available": PSUTIL_AVAILABLE,
                "utils_available": UTILS_AVAILABLE,
                "active_model": getattr(self, 'active_model', 'unknown'),
                "visualization_enabled": self.warping_config.get('visualization_enabled', True),
                "physics_simulation_enabled": self.config.get('physics_enabled', True),
                "ai_model_enabled": self.config.get('ai_model_enabled', True)
            },
            "model_info": {
                "available_models": list(getattr(self, 'warping_models', {}).keys()),
                "active_model": getattr(self, 'active_model', 'unknown'),
                "hrviton_loaded": self.hrviton_model is not None,
                "physics_simulator_ready": self.physics_simulator is not None
            },
            "processing_settings": {
                "warping_method": str(self.config.get('warping_method', 'ai_model')),
                "optimization_level": getattr(self, 'optimization_level', 'basic'),
                "batch_processing": getattr(self, 'batch_processing', False),
                "cache_enabled": self.warping_config.get('cache_enabled', True),
                "cache_status": self.get_cache_status(),
                "input_size": self.config.get('input_size', (512, 384)),
                "num_control_points": self.config.get('num_control_points', 25)
            }
        }
    
    def __del__(self):
        """ÏÜåÎ©∏Ïûê (PoseEstimationStep Ìå®ÌÑ¥)"""
        try:
            if hasattr(self, 'executor'):
                self.executor.shutdown(wait=False)
            self.cleanup_resources()
        except:
            pass

# ==============================================
# üî• Ìå©ÌÜ†Î¶¨ Ìï®ÏàòÎì§ Î∞è ÌïòÏúÑ Ìò∏ÌôòÏÑ± ÏßÄÏõê (PoseEstimationStep Ìå®ÌÑ¥ ÏôÑÏ†Ñ Ï†ÅÏö©)
# ==============================================

async def create_cloth_warping_step(
    device: str = "auto",
    config: Optional[Dict[str, Any]] = None,
    **kwargs
) -> ClothWarpingStep:
    """
    ‚úÖ ÏïàÏ†ÑÌïú Step 05 ÏÉùÏÑ± Ìï®Ïàò - BaseStepMixin + utils ÏôÑÏ†Ñ ÌÜµÌï© (PoseEstimationStep Ìå®ÌÑ¥)
    """
    try:
        # ÎîîÎ∞îÏù¥Ïä§ Ï≤òÎ¶¨
        device_param = None if device == "auto" else device
        
        # config ÌÜµÌï©
        if config is None:
            config = {}
        config.update(kwargs)
        
        # Step ÏÉùÏÑ± Î∞è Ï¥àÍ∏∞Ìôî
        step = ClothWarpingStep(device=device_param, config=config)
        
        # Ï∂îÍ∞Ä Ï¥àÍ∏∞ÌôîÍ∞Ä ÌïÑÏöîÌïú Í≤ΩÏö∞
        if not step.is_initialized:
            step.logger.warning("‚ö†Ô∏è 5Îã®Í≥Ñ Ï¥àÍ∏∞Ìôî Ïã§Ìå® - ÏãúÎÆ¨Î†àÏù¥ÏÖò Î™®ÎìúÎ°ú ÎèôÏûë")
        
        return step
        
    except Exception as e:
        logger.error(f"‚ùå create_cloth_warping_step Ïã§Ìå®: {e}")
        # Ìè¥Î∞±: ÏµúÏÜåÌïúÏùò Step ÏÉùÏÑ±
        step = ClothWarpingStep(device='cpu')
        step.is_initialized = True  # Í∞ïÏ†úÎ°ú Ï¥àÍ∏∞Ìôî ÏÉÅÌÉú ÏÑ§Ï†ï
        return step

def create_cloth_warping_step_sync(
    device: str = "auto",
    config: Optional[Dict[str, Any]] = None,
    **kwargs
) -> ClothWarpingStep:
    """üîß ÏïàÏ†ÑÌïú ÎèôÍ∏∞Ïãù Step 05 ÏÉùÏÑ± (Î†àÍ±∞Ïãú Ìò∏Ìôò, PoseEstimationStep Ìå®ÌÑ¥)"""
    try:
        try:
            loop = asyncio.get_event_loop()
        except RuntimeError:
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
        
        return loop.run_until_complete(
            create_cloth_warping_step(device, config, **kwargs)
        )
    except Exception as e:
        logger.error(f"‚ùå create_cloth_warping_step_sync Ïã§Ìå®: {e}")
        # ÏïàÏ†ÑÌïú Ìè¥Î∞±
        return ClothWarpingStep(device='cpu')

def create_m3_max_warping_step(**kwargs) -> ClothWarpingStep:
    """M3 Max ÏµúÏ†ÅÌôîÎêú ÏõåÌïë Ïä§ÌÖù ÏÉùÏÑ± (PoseEstimationStep Ìå®ÌÑ¥)"""
    m3_max_config = {
        'device': 'mps',
        'is_m3_max': True,
        'optimization_enabled': True,
        'memory_gb': 128,
        'quality_level': 'ultra',
        'warping_method': WarpingMethod.AI_MODEL,
        'ai_model_enabled': True,
        'physics_enabled': True,
        'enable_visualization': True,
        'visualization_quality': 'ultra',
        'precision': 'fp16',
        'memory_fraction': 0.7,
        'cache_enabled': True,
        'cache_size': 100
    }
    
    m3_max_config.update(kwargs)
    
    return ClothWarpingStep(config=m3_max_config)

def create_production_warping_step(
    quality_level: str = "balanced",
    enable_ai_model: bool = True,
    **kwargs
) -> ClothWarpingStep:
    """ÌîÑÎ°úÎçïÏÖò ÌôòÍ≤ΩÏö© ÏõåÌïë Ïä§ÌÖù ÏÉùÏÑ± (PoseEstimationStep Ìå®ÌÑ¥)"""
    production_config = {
        'quality_level': quality_level,
        'warping_method': WarpingMethod.AI_MODEL if enable_ai_model else WarpingMethod.PHYSICS_BASED,
        'ai_model_enabled': enable_ai_model,
        'physics_enabled': True,
        'optimization_enabled': True,
        'enable_visualization': True,
        'visualization_quality': 'high' if enable_ai_model else 'medium',
        'save_intermediate_results': False,  # ÌîÑÎ°úÎçïÏÖòÏóêÏÑúÎäî Î©îÎ™®Î¶¨ Ï†àÏïΩ
        'cache_enabled': True,
        'cache_size': 50
    }
    
    production_config.update(kwargs)
    
    return ClothWarpingStep(config=production_config)

# Í∏∞Ï°¥ ÌÅ¥ÎûòÏä§Î™Ö Î≥ÑÏπ≠ (ÌïòÏúÑ Ìò∏ÌôòÏÑ±)
ClothWarpingStepLegacy = ClothWarpingStep

# ==============================================
# üÜï Ï∂îÍ∞Ä Ïú†Ìã∏Î¶¨Ìã∞ Ìï®ÏàòÎì§ (PoseEstimationStep Ìå®ÌÑ¥)
# ==============================================

def validate_warping_result(result: Dict[str, Any]) -> bool:
    """ÏõåÌïë Í≤∞Í≥º Ïú†Ìö®ÏÑ± Í≤ÄÏ¶ù"""
    try:
        required_keys = ['success', 'step_name', 'warped_cloth_image']
        if not all(key in result for key in required_keys):
            return False
        
        if not result['success']:
            return False
            
        if result['warped_cloth_image'] is None:
            return False
        
        return True
        
    except Exception:
        return False

def analyze_warping_for_clothing(warped_cloth: np.ndarray, original_cloth: np.ndarray, 
                                clothing_type: str = "default") -> Dict[str, Any]:
    """ÏùòÎ•ò ÌîºÌåÖÏùÑ ÏúÑÌïú ÏõåÌïë Î∂ÑÏÑù (Ïô∏Î∂Ä Ìò∏Ï∂úÏö©, PoseEstimationStep Ìå®ÌÑ¥)"""
    try:
        analysis = {
            'suitable_for_fitting': False,
            'issues': [],
            'recommendations': [],
            'warping_score': 0.0
        }
        
        # Í∏∞Î≥∏ ÌíàÏßà ÌôïÏù∏
        if warped_cloth.shape != original_cloth.shape:
            analysis['issues'].append("ÏõåÌïëÎêú Ïù¥ÎØ∏ÏßÄ ÌÅ¨Í∏∞Í∞Ä ÏõêÎ≥∏Í≥º Îã§Î¶Ñ")
            analysis['recommendations'].append("Ïù¥ÎØ∏ÏßÄ ÌÅ¨Í∏∞Î•º ÎßûÏ∂∞Ï£ºÏÑ∏Ïöî")
        
        # ÏÉâÏÉÅ Î≥¥Ï°¥ÎèÑ ÌôïÏù∏
        orig_mean = np.mean(original_cloth, axis=(0, 1))
        warp_mean = np.mean(warped_cloth, axis=(0, 1))
        color_diff = np.mean(np.abs(orig_mean - warp_mean))
        
        if color_diff > 30:
            analysis['issues'].append("ÏÉâÏÉÅÏù¥ ÎßéÏù¥ Î≥ÄÍ≤ΩÎê®")
            analysis['recommendations'].append("ÏÉâÏÉÅ Î≥¥Ï†ïÏù¥ ÌïÑÏöîÌï©ÎãàÎã§")
        
        # ÌÖçÏä§Ï≤ò Î≥¥Ï°¥ÎèÑ ÌôïÏù∏
        orig_std = np.std(original_cloth)
        warp_std = np.std(warped_cloth)
        texture_preservation = 1.0 - min(abs(orig_std - warp_std) / max(orig_std, warp_std), 1.0)
        
        if texture_preservation < 0.7:
            analysis['issues'].append("ÌÖçÏä§Ï≤òÍ∞Ä ÎßéÏù¥ ÏÜêÏã§Îê®")
            analysis['recommendations'].append("Îçî ÎÜíÏùÄ ÌíàÏßà ÏÑ§Ï†ïÏùÑ ÏÇ¨Ïö©Ìï¥Ï£ºÏÑ∏Ïöî")
        
        # Ï†ÑÏ≤¥ Ï†êÏàò Í≥ÑÏÇ∞
        color_score = max(0, 1.0 - color_diff / 100.0)
        texture_score = texture_preservation
        
        analysis['warping_score'] = (color_score + texture_score) / 2
        
        # ÌîºÌåÖ Ï†ÅÌï©ÏÑ± ÌåêÎã®
        analysis['suitable_for_fitting'] = (
            len(analysis['issues']) <= 1 and 
            analysis['warping_score'] >= 0.6
        )
        
        if analysis['suitable_for_fitting']:
            analysis['recommendations'].append("ÏõåÌïë Í≤∞Í≥ºÍ∞Ä Í∞ÄÏÉÅ ÌîºÌåÖÏóê Ï†ÅÌï©Ìï©ÎãàÎã§!")
        
        return analysis
        
    except Exception as e:
        logger.error(f"ÏõåÌïë Î∂ÑÏÑù Ïã§Ìå®: {e}")
        return {
            'suitable_for_fitting': False,
            'issues': ["Î∂ÑÏÑù Ïã§Ìå®"],
            'recommendations': ["Îã§Ïãú ÏãúÎèÑÌï¥ Ï£ºÏÑ∏Ïöî"],
            'warping_score': 0.0
        }

async def test_cloth_warping_complete():
    """üß™ ÏôÑÏ†ÑÌïú ÏùòÎ•ò ÏõåÌïë ÌÖåÏä§Ìä∏ (PoseEstimationStep Ìå®ÌÑ¥)"""
    print("üß™ ÏôÑÏ†ÑÌïú ÏùòÎ•ò ÏõåÌïë + AI + Î¨ºÎ¶¨ + ÏãúÍ∞ÅÌôî + utils ÌÜµÌï© ÌÖåÏä§Ìä∏ ÏãúÏûë")
    
    try:
        # Step ÏÉùÏÑ±
        step = await create_cloth_warping_step(
            device="auto",
            config={
                "ai_model_enabled": True,
                "physics_enabled": True,
                "enable_visualization": True,
                "visualization_quality": "ultra",
                "quality_level": "high",
                "warping_method": WarpingMethod.HYBRID,
                "cache_enabled": True
            }
        )
        
        # ÎçîÎØ∏ Ïù¥ÎØ∏ÏßÄÎì§ ÏÉùÏÑ± (Í≥†Ìï¥ÏÉÅÎèÑ)
        clothing_image = np.random.randint(0, 255, (512, 384, 3), dtype=np.uint8)
        person_image = np.random.randint(0, 255, (512, 384, 3), dtype=np.uint8)
        clothing_mask = np.ones((512, 384), dtype=np.uint8) * 255
        
        # Ï≤òÎ¶¨ Ïã§Ìñâ
        result = await step.process(
            clothing_image, person_image, clothing_mask,
            fabric_type="cotton", clothing_type="shirt"
        )
        
        # Í≤∞Í≥º ÌôïÏù∏
        if result["success"]:
            print("‚úÖ ÏôÑÏ†ÑÌïú Ï≤òÎ¶¨ ÏÑ±Í≥µ!")
            print(f"üìä Ï≤òÎ¶¨ ÏãúÍ∞Ñ: {result['processing_time']:.2f}Ï¥à")
            print(f"üéØ Ïã†Î¢∞ÎèÑ: {result['confidence']:.2f}")
            print(f"‚≠ê ÌíàÏßà Ï†êÏàò: {result['quality_score']:.2f}")
            print(f"üìù ÌíàÏßà Îì±Í∏â: {result['quality_grade']}")
            print(f"üé® ÏãúÍ∞ÅÌôî ÏÉùÏÑ±: {'Ïòà' if result['visualization'] else 'ÏïÑÎãàÏò§'}")
            print(f"üìà ÏßÑÌñâ ÏãúÍ∞ÅÌôî: {'Ïòà' if result['progress_visualization'] else 'ÏïÑÎãàÏò§'}")
            print(f"üìã Ï∫êÏãúÏóêÏÑú: {'Ïòà' if result['from_cache'] else 'ÏïÑÎãàÏò§'}")
            
            # Step Ï†ïÎ≥¥ Ï∂úÎ†•
            step_info = await step.get_step_info()
            print(f"üìã Step Ï†ïÎ≥¥: {step_info}")
            
            # Ï∫êÏãú ÏÉÅÌÉú ÌôïÏù∏
            cache_status = step.get_cache_status()
            print(f"üíæ Ï∫êÏãú ÏÉÅÌÉú: {cache_status}")
            
        else:
            print(f"‚ùå Ï≤òÎ¶¨ Ïã§Ìå®: {result['error']}")
            
        # Ï†ïÎ¶¨
        await step.cleanup_models()
        
    except Exception as e:
        print(f"‚ùå ÌÖåÏä§Ìä∏ Ïã§Ìå®: {e}")

# ==============================================
# üî• Î™®Îìà ÏùµÏä§Ìè¨Ìä∏ (PoseEstimationStep Ìå®ÌÑ¥)
# ==============================================

__all__ = [
    # Î©îÏù∏ ÌÅ¥ÎûòÏä§
    'ClothWarpingStep',
    
    # ÏÑ§Ï†ï ÌÅ¥ÎûòÏä§Îì§
    'ClothWarpingConfig',
    'PhysicsProperties',
    'WarpingMethod',
    'FabricType',
    'WarpingQuality',
    
    # ÌïµÏã¨ Ïª¥Ìè¨ÎÑåÌä∏Îì§
    'AdvancedTPSTransform',
    'ClothPhysicsSimulator',
    'HRVITONModel',
    'WarpingVisualizer',
    
    # Ìå©ÌÜ†Î¶¨ Ìï®ÏàòÎì§
    'create_cloth_warping_step',
    'create_cloth_warping_step_sync',
    'create_m3_max_warping_step',
    'create_production_warping_step',
    
    # ÌïòÏúÑ Ìò∏ÌôòÏÑ±
    'ClothWarpingStepLegacy',
    
    # Ïú†Ìã∏Î¶¨Ìã∞ Ìï®ÏàòÎì§
    'validate_warping_result',
    'analyze_warping_for_clothing',
    'test_cloth_warping_complete',
    
    # Îç∞Ïù¥ÌÑ∞
    'CLOTHING_WARPING_WEIGHTS'
]

logger.info("‚úÖ ClothWarpingStep v3.0 ÏôÑÏ†Ñ Î≤ÑÏ†Ñ Î°úÎìú ÏôÑÎ£å - PoseEstimationStep Ìå®ÌÑ¥ ÏôÑÏ†Ñ Ï†ÅÏö©")
logger.info("üîó utils ÌÜµÌï© Ïù∏ÌÑ∞ÌéòÏù¥Ïä§ ÏôÑÏ†Ñ Ïó∞Îèô")
logger.info("üéØ ÌÜµÏùºÎêú ÏÉùÏÑ±Ïûê Ìå®ÌÑ¥ Ï†ÅÏö©")
logger.info("üíæ ÏôÑÏ†ÑÌïú ÏóêÎü¨ Ï≤òÎ¶¨ Î∞è Ï∫êÏãú Í¥ÄÎ¶¨")
logger.info("ü§ñ ModelLoader Ïù∏ÌÑ∞ÌéòÏù¥Ïä§ **ÏôÑÏ†Ñ Ïó∞Îèô**") 
logger.info("üé® ÏãúÍ∞ÅÌôî Í∏∞Îä• ÏôÑÏ†Ñ Íµ¨ÌòÑ")
logger.info("‚öôÔ∏è Î¨ºÎ¶¨ ÏãúÎÆ¨Î†àÏù¥ÏÖò ÏóîÏßÑ Ìè¨Ìï®")
logger.info("üçé M3 Max 128GB ÏµúÏ†ÅÌôî ÏßÄÏõê")
logger.info("üî• **Î™®Îì† Í∏∞Îä• 100% Ìè¨Ìï®Îêú ÏôÑÏ†Ñ Î≤ÑÏ†Ñ - PoseEstimationStep Ìå®ÌÑ¥ ÏôÑÏ†Ñ Ï†ÅÏö©**")