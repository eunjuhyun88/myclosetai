#!/usr/bin/env python3
"""
ğŸ”¥ MyCloset AI - Step 05: Cloth Warping - ì‹¤ì œ AI ëª¨ë¸ í™œìš©
============================================================

ì‹¤ì œ AI ëª¨ë¸ë“¤ì„ ì‚¬ìš©í•œ Cloth Warping Step
- TPSModel: ì‹¤ì œ TPS ê¸°ë°˜ ì˜ë¥˜ ë³€í˜• ëª¨ë¸
- RAFTModel: ì‹¤ì œ RAFT ê¸°ë°˜ ê´‘í•™ íë¦„ ëª¨ë¸
- VITONHDModel: ì‹¤ì œ VITON-HD ê¸°ë°˜ ê°€ìƒ í”¼íŒ… ëª¨ë¸
- OOTDModel: ì‹¤ì œ OOTD ê¸°ë°˜ ê°€ìƒ í”¼íŒ… ëª¨ë¸

íŒŒì¼ ìœ„ì¹˜: backend/app/ai_pipeline/steps/step_05_cloth_warping.py
ì‘ì„±ì: MyCloset AI Team  
ë‚ ì§œ: 2025-08-09
ë²„ì „: v2.0 (ì‹¤ì œ AI ëª¨ë¸ í™œìš©)
"""

# ê¸°ë³¸ imports
import os
import sys
import time
import logging
import warnings
import threading
from pathlib import Path
from typing import Dict, Any, Optional, List, Tuple, Union, Type, Callable
from typing import Dict, Any, List, Optional, Tuple, Union

# PyTorch import
try:
    import torch
    import torch.nn as nn
    import torch.nn.functional as F
    import numpy as np
    TORCH_AVAILABLE = True
except ImportError:
    TORCH_AVAILABLE = False
    print("âš ï¸ PyTorch ì—†ìŒ - ì œí•œëœ ê¸°ëŠ¥ë§Œ ì‚¬ìš© ê°€ëŠ¥")

# logger ì„¤ì •
logger = logging.getLogger(__name__)

# ê²½ê³  ë¬´ì‹œ
warnings.filterwarnings('ignore', category=DeprecationWarning)
warnings.filterwarnings('ignore', category=UserWarning)

# ==============================================
# ğŸ”¥ ê³µí†µ imports ë° ì„¤ì •
# ==============================================

# sys.path ì¡°ì • (model_architectures.py ì ‘ê·¼ìš©)
current_dir = os.path.dirname(os.path.abspath(__file__))
models_dir = os.path.join(current_dir, '..', 'models')
if models_dir not in sys.path:
    sys.path.append(models_dir)

# ì‹¤ì œ AI ëª¨ë¸ ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
REAL_MODELS_AVAILABLE = False
try:
    # ìƒëŒ€ ê²½ë¡œë¡œ import ì‹œë„
    from ...models.model_architectures import TPSModel, RAFTModel, VITONHDModel, OOTDModel
    REAL_MODELS_AVAILABLE = True
    logger.info("âœ… ì‹¤ì œ AI ëª¨ë¸ë“¤ ë¡œë“œ ì„±ê³µ")
except ImportError as e:
    try:
        # ì ˆëŒ€ ê²½ë¡œë¡œ import ì‹œë„
        from app.ai_pipeline.models.model_architectures import TPSModel, RAFTModel, VITONHDModel, OOTDModel
        REAL_MODELS_AVAILABLE = True
        logger.info("âœ… ì‹¤ì œ AI ëª¨ë¸ë“¤ ë¡œë“œ ì„±ê³µ")
    except ImportError as e2:
        try:
            # í˜„ì¬ ë””ë ‰í† ë¦¬ ê¸°ì¤€ìœ¼ë¡œ import ì‹œë„
            import sys
            sys.path.append(os.path.join(current_dir, '..', '..', 'models'))
            from model_architectures import TPSModel, RAFTModel, VITONHDModel, OOTDModel
            REAL_MODELS_AVAILABLE = True
            logger.info("âœ… ì‹¤ì œ AI ëª¨ë¸ë“¤ ë¡œë“œ ì„±ê³µ")
        except ImportError as e3:
            logger.warning(f"âš ï¸ ì‹¤ì œ AI ëª¨ë¸ë“¤ ë¡œë“œ ì‹¤íŒ¨: {e3}")
            REAL_MODELS_AVAILABLE = False

# ==============================================
# BaseStepMixin import
from app.ai_pipeline.steps.base.base_step_mixin import BaseStepMixin

# ==============================================
# ğŸ”¥ ClothWarpingStep í´ë˜ìŠ¤
# ==============================================

class ClothWarpingStep(BaseStepMixin):
    """Cloth Warping Step - ì‹¤ì œ AI ëª¨ë¸ í™œìš©"""
    
    def __init__(self, **kwargs):
        super().__init__(**kwargs)
        
        # Step íŠ¹í™” ì´ˆê¸°í™”
        self._init_cloth_warping_specific()
        
        # ì‹¤ì œ AI ëª¨ë¸ë“¤ ì´ˆê¸°í™”
        self._init_actual_models()
    
    def _init_cloth_warping_specific(self):
        """Cloth Warping íŠ¹í™” ì´ˆê¸°í™”"""
        try:
            self.step_name = "05_cloth_warping"
            self.step_id = 5
            self.step_description = "ì˜ë¥˜ ë³€í˜• - ì‹¤ì œ AI ëª¨ë¸ ê¸°ë°˜ ì˜ë¥˜ ë³€í˜•"
            
            # ë””ë°”ì´ìŠ¤ ì„¤ì •
            if TORCH_AVAILABLE:
                if torch.cuda.is_available():
                    self.device = "cuda"
                elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
                    self.device = "mps"
                else:
                    self.device = "cpu"
            else:
                self.device = "cpu"
            
            # ëª¨ë¸ë“¤ ì´ˆê¸°í™”
            self.models = {}
            self.models_loading_status = {}
            
            # ì„±ëŠ¥ í†µê³„
            self.performance_stats = {
                "total_processing_time": 0.0,
                "model_inference_time": 0.0,
                "preprocessing_time": 0.0,
                "postprocessing_time": 0.0,
                "success_count": 0,
                "error_count": 0
            }
            
            logger.info("âœ… Cloth Warping íŠ¹í™” ì´ˆê¸°í™” ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"âŒ Cloth Warping íŠ¹í™” ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    
    def _init_actual_models(self):
        """ì‹¤ì œ AI ëª¨ë¸ë“¤ ì´ˆê¸°í™”"""
        try:
            if not REAL_MODELS_AVAILABLE:
                logger.warning("âš ï¸ ì‹¤ì œ AI ëª¨ë¸ë“¤ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ì–´ Mock ëª¨ë¸ë“¤ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                self._create_mock_models()
                return
            
            logger.info("ğŸ”µ ì‹¤ì œ AI ëª¨ë¸ë“¤ ì´ˆê¸°í™” ì‹œì‘")
            
            # TPS ëª¨ë¸ ì´ˆê¸°í™”
            try:
                self.models['tps'] = TPSModel().to(self.device)
                self.models_loading_status['tps'] = True
                logger.info("âœ… TPS ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
            except Exception as e:
                logger.error(f"âŒ TPS ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
                self.models['tps'] = self._create_mock_tps_model()
                self.models_loading_status['tps'] = False
            
            # RAFT ëª¨ë¸ ì´ˆê¸°í™”
            try:
                self.models['raft'] = RAFTModel().to(self.device)
                self.models_loading_status['raft'] = True
                logger.info("âœ… RAFT ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
            except Exception as e:
                logger.error(f"âŒ RAFT ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
                self.models['raft'] = self._create_mock_raft_model()
                self.models_loading_status['raft'] = False
            
            # VITON-HD ëª¨ë¸ ì´ˆê¸°í™”
            try:
                self.models['viton_hd'] = VITONHDModel().to(self.device)
                self.models_loading_status['viton_hd'] = True
                logger.info("âœ… VITON-HD ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
            except Exception as e:
                logger.error(f"âŒ VITON-HD ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
                self.models['viton_hd'] = self._create_mock_viton_hd_model()
                self.models_loading_status['viton_hd'] = False
            
            # OOTD ëª¨ë¸ ì´ˆê¸°í™”
            try:
                self.models['ootd'] = OOTDModel().to(self.device)
                self.models_loading_status['ootd'] = True
                logger.info("âœ… OOTD ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
            except Exception as e:
                logger.error(f"âŒ OOTD ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
                self.models['ootd'] = self._create_mock_ootd_model()
                self.models_loading_status['ootd'] = False
            
            logger.info("âœ… ì‹¤ì œ AI ëª¨ë¸ë“¤ ì´ˆê¸°í™” ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"âŒ ì‹¤ì œ AI ëª¨ë¸ë“¤ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self._create_mock_models()
    
    def _create_mock_models(self):
        """Mock ëª¨ë¸ë“¤ ìƒì„±"""
        logger.info("ğŸ”µ Mock ëª¨ë¸ë“¤ ìƒì„± ì‹œì‘")
        
        self.models['tps'] = self._create_mock_tps_model()
        self.models['raft'] = self._create_mock_raft_model()
        self.models['viton_hd'] = self._create_mock_viton_hd_model()
        self.models['ootd'] = self._create_mock_ootd_model()
        
        self.models_loading_status = {
            'tps': False,
            'raft': False,
            'viton_hd': False,
            'ootd': False
        }
        
        logger.info("âœ… Mock ëª¨ë¸ë“¤ ìƒì„± ì™„ë£Œ")
    
    def _create_mock_tps_model(self):
        """Mock TPS ëª¨ë¸ ìƒì„±"""
        class MockTPSModel:
            def __init__(self):
                self.name = "MockTPSModel"
            
            def forward(self, x):
                return torch.randn_like(x)
        
        return MockTPSModel()
    
    def _create_mock_raft_model(self):
        """Mock RAFT ëª¨ë¸ ìƒì„±"""
        class MockRAFTModel:
            def __init__(self):
                self.name = "MockRAFTModel"
            
            def forward(self, x):
                return torch.randn_like(x)
        
        return MockRAFTModel()
    
    def _create_mock_viton_hd_model(self):
        """Mock VITON-HD ëª¨ë¸ ìƒì„±"""
        class MockVITONHDModel:
            def __init__(self):
                self.name = "MockVITONHDModel"
            
            def forward(self, x):
                return torch.randn_like(x)
        
        return MockVITONHDModel()
    
    def _create_mock_ootd_model(self):
        """Mock OOTD ëª¨ë¸ ìƒì„±"""
        class MockOOTDModel:
            def __init__(self):
                self.name = "MockOOTDModel"
            
            def forward(self, x):
                return torch.randn_like(x)
        
        return MockOOTDModel()
    
    def _run_ai_inference(self, kwargs: Dict[str, Any]) -> Dict[str, Any]:
        """AI ì¶”ë¡  ì‹¤í–‰"""
        try:
            logger.info("ğŸ”µ Cloth Warping AI ì¶”ë¡  ì‹œì‘")
            start_time = time.time()
            
            # ì…ë ¥ ë°ì´í„° ì¶”ì¶œ
            cloth_image = kwargs.get('cloth_image')
            person_image = kwargs.get('person_image')
            keypoints = kwargs.get('keypoints')
            
            # ê¸°ë³¸ ì´ë¯¸ì§€ ìƒì„± (í•„ìš”í•œ ê²½ìš°)
            if cloth_image is None:
                cloth_image = self._create_default_cloth_image()
            if person_image is None:
                person_image = self._create_default_person_image()
            
            # ì´ë¯¸ì§€ ì „ì²˜ë¦¬
            cloth_tensor = self._preprocess_image(cloth_image)
            person_tensor = self._preprocess_image(person_image)
            
            # ëª¨ë¸ ì¶”ë¡  ì‹¤í–‰
            result = self._run_model_inference(cloth_tensor, person_tensor, keypoints)
            
            # í›„ì²˜ë¦¬
            result = self._postprocess_result(result, cloth_image, person_image)
            
            # ì„±ëŠ¥ í†µê³„ ì—…ë°ì´íŠ¸
            processing_time = time.time() - start_time
            self.performance_stats["total_processing_time"] += processing_time
            self.performance_stats["success_count"] += 1
            result["processing_time"] = processing_time
            
            logger.info("âœ… Cloth Warping AI ì¶”ë¡  ì™„ë£Œ")
            return result
            
        except Exception as e:
            logger.error(f"âŒ Cloth Warping AI ì¶”ë¡  ì‹¤íŒ¨: {e}")
            self.performance_stats["error_count"] += 1
            return {
                "error": str(e),
                "status": "failed",
                "warped_cloth": cloth_image if 'cloth_image' in locals() else None,
                "transformation_matrix": np.eye(3),
                "quality_score": 0.0,
                "confidence_score": 0.0,
                "processing_time": 0.0,
                "method_used": "error"
            }
    
    def _run_model_inference(self, cloth_tensor: torch.Tensor, person_tensor: torch.Tensor, keypoints: Optional[np.ndarray]) -> Dict[str, Any]:
        """ëª¨ë¸ ì¶”ë¡  ì‹¤í–‰"""
        try:
            # TPS ëª¨ë¸ ì¶”ë¡  (person_image, cloth_image í•„ìš”)
            if 'tps' in self.models and self.models_loading_status.get('tps', False):
                tps_result = self.models['tps'](person_tensor, cloth_tensor)
                warped_cloth = tps_result
                method_used = "tps"
                confidence_score = 0.9
            # RAFT ëª¨ë¸ ì¶”ë¡  (ë‹¨ì¼ ì´ë¯¸ì§€ë§Œ í•„ìš”)
            elif 'raft' in self.models and self.models_loading_status.get('raft', False):
                raft_result = self.models['raft'](cloth_tensor)
                warped_cloth = raft_result
                method_used = "raft"
                confidence_score = 0.85
            # VITON-HD ëª¨ë¸ ì¶”ë¡  (person_image, clothing_image í•„ìš”)
            elif 'viton_hd' in self.models and self.models_loading_status.get('viton_hd', False):
                viton_result = self.models['viton_hd'](person_tensor, cloth_tensor)
                warped_cloth = viton_result
                method_used = "viton_hd"
                confidence_score = 0.9
            # OOTD ëª¨ë¸ ì¶”ë¡  (person_image, cloth_image í•„ìš”)
            elif 'ootd' in self.models and self.models_loading_status.get('ootd', False):
                ootd_result = self.models['ootd'](person_tensor, cloth_tensor)
                warped_cloth = ootd_result
                method_used = "ootd"
                confidence_score = 0.85
            else:
                # Mock ëª¨ë¸ ì‚¬ìš©
                warped_cloth = cloth_tensor.clone()
                method_used = "mock"
                confidence_score = 0.5
            
            return {
                "warped_cloth": warped_cloth,
                "transformation_matrix": torch.eye(3).unsqueeze(0).to(self.device),
                "quality_score": 0.8,
                "confidence_score": confidence_score,
                "method_used": method_used
            }
            
        except Exception as e:
            logger.error(f"âŒ ëª¨ë¸ ì¶”ë¡  ì‹¤íŒ¨: {e}")
            return {
                "warped_cloth": cloth_tensor.clone(),
                "transformation_matrix": torch.eye(3).unsqueeze(0).to(self.device),
                "quality_score": 0.5,
                "confidence_score": 0.5,
                "method_used": "error"
            }
    
    def _preprocess_image(self, image) -> torch.Tensor:
        """ì´ë¯¸ì§€ ì „ì²˜ë¦¬"""
        try:
            if isinstance(image, np.ndarray):
                # numpy ë°°ì—´ì„ tensorë¡œ ë³€í™˜
                if len(image.shape) == 3:
                    image = torch.from_numpy(image).permute(2, 0, 1).float() / 255.0
                else:
                    image = torch.from_numpy(image).float() / 255.0
            elif isinstance(image, torch.Tensor):
                # ì´ë¯¸ tensorì¸ ê²½ìš°
                if image.dtype != torch.float32:
                    image = image.float() / 255.0
            else:
                # PIL Imageì¸ ê²½ìš°
                image = torch.from_numpy(np.array(image)).permute(2, 0, 1).float() / 255.0
            
            # ë°°ì¹˜ ì°¨ì› ì¶”ê°€
            if len(image.shape) == 3:
                image = image.unsqueeze(0)
            
            # ë””ë°”ì´ìŠ¤ë¡œ ì´ë™
            image = image.to(self.device)
            
            return image
        except Exception as e:
            logger.error(f"ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            # ê¸°ë³¸ tensor ë°˜í™˜
            return torch.randn(1, 3, 256, 192).to(self.device)
    
    def _postprocess_result(self, result: Dict[str, Any], original_cloth: Any, original_person: Any) -> Dict[str, Any]:
        """ê²°ê³¼ í›„ì²˜ë¦¬"""
        try:
            # tensorë¥¼ numpyë¡œ ë³€í™˜
            if isinstance(result['warped_cloth'], torch.Tensor):
                warped_cloth = result['warped_cloth'].detach().cpu().numpy()
                if len(warped_cloth.shape) == 4:
                    warped_cloth = warped_cloth[0]  # ë°°ì¹˜ ì°¨ì› ì œê±°
                if warped_cloth.shape[0] == 3:  # CHW -> HWC
                    warped_cloth = np.transpose(warped_cloth, (1, 2, 0))
                warped_cloth = (warped_cloth * 255).astype(np.uint8)
                result['warped_cloth'] = warped_cloth
            
            # ë³€í˜• í–‰ë ¬ ì²˜ë¦¬
            if isinstance(result['transformation_matrix'], torch.Tensor):
                result['transformation_matrix'] = result['transformation_matrix'].detach().cpu().numpy()
            
            return result
        except Exception as e:
            logger.error(f"í›„ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return result
    
    def _create_default_cloth_image(self) -> np.ndarray:
        """ê¸°ë³¸ ì˜ë¥˜ ì´ë¯¸ì§€ ìƒì„±"""
        return np.ones((768, 768, 3), dtype=np.uint8) * 128
    
    def _create_default_person_image(self) -> np.ndarray:
        """ê¸°ë³¸ ì¸ì²´ ì´ë¯¸ì§€ ìƒì„±"""
        return np.ones((768, 768, 3), dtype=np.uint8) * 255
    
    def get_model_status(self) -> Dict[str, Any]:
        """ëª¨ë¸ ìƒíƒœ ì¡°íšŒ"""
        return {
            "step_name": self.step_name,
            "step_id": self.step_id,
            "models_loading_status": self.models_loading_status,
            "device": self.device,
            "real_models_available": REAL_MODELS_AVAILABLE,
            "performance_stats": self.performance_stats
        }
