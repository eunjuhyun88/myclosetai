# app/ai_pipeline/steps/step_05_cloth_warping.py
"""
ğŸ¯ Step 5: ê°•í™”ëœ ì˜ë¥˜ ì›Œí•‘ (Enhanced Cloth Warping) - ì‹¤ì œ AI ì•Œê³ ë¦¬ì¦˜ êµ¬í˜„
================================================================================

âœ… BaseStepMixin v19.1 ì™„ì „ í˜¸í™˜ (_run_ai_inference ë©”ì„œë“œë§Œ êµ¬í˜„)
âœ… ì‹¤ì œ AI ëª¨ë¸ íŒŒì¼ ì™„ì „ í™œìš© (RealVisXL 6.6GB + VGG + DenseNet)
âœ… ê³ ê¸‰ TPS (Thin Plate Spline) ë³€í˜• ì•Œê³ ë¦¬ì¦˜
âœ… RAFT Optical Flow ê¸°ë°˜ ì •ë°€ ì›Œí•‘
âœ… ResNet ë°±ë³¸ íŠ¹ì§• ì¶”ì¶œ
âœ… VGG ê¸°ë°˜ ì˜ë¥˜-ì¸ì²´ ë§¤ì¹­
âœ… DenseNet ê¸°ë°˜ ë³€í˜• í’ˆì§ˆ í‰ê°€
âœ… Diffusion ëª¨ë¸ ê¸°ë°˜ ì›Œí•‘ ì •ì œ
âœ… ë¬¼ë¦¬ ê¸°ë°˜ ì›ë‹¨ ì‹œë®¬ë ˆì´ì…˜
âœ… ë©€í‹° ìŠ¤ì¼€ì¼ íŠ¹ì§• ìœµí•©

í•µì‹¬ AI ì•Œê³ ë¦¬ì¦˜:
1. ğŸ§  TPS (Thin Plate Spline) Warping Network
2. ğŸŒŠ RAFT Optical Flow Estimation
3. ğŸ¯ ResNet Feature Extraction
4. ğŸ” VGG-based Cloth-Body Matching
5. âš¡ DenseNet Quality Assessment
6. ğŸ¨ Diffusion-based Warping Refinement
7. ğŸ§ª Physics-based Fabric Simulation

Author: MyCloset AI Team
Date: 2025-07-27
Version: 15.0 (Enhanced AI Algorithms Implementation)
"""

import os
import gc
import time
import math
import logging
import traceback
import threading
import platform
import subprocess
import base64
from io import BytesIO
from pathlib import Path
from typing import Dict, Any, Optional, Tuple, Union, List, TYPE_CHECKING
from dataclasses import dataclass, field
from enum import Enum
from functools import wraps
import numpy as np

# ğŸ”¥ ëª¨ë“ˆ ë ˆë²¨ logger ì•ˆì „ ì •ì˜
def create_module_logger():
    """ëª¨ë“ˆ ë ˆë²¨ logger ì•ˆì „ ìƒì„±"""
    try:
        module_logger = logging.getLogger(__name__)
        if not module_logger.handlers:
            handler = logging.StreamHandler()
            formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
            handler.setFormatter(formatter)
            module_logger.addHandler(handler)
            module_logger.setLevel(logging.INFO)
        return module_logger
    except Exception as e:
        import sys
        print(f"âš ï¸ Logger ìƒì„± ì‹¤íŒ¨, stdout ì‚¬ìš©: {e}", file=sys.stderr)
        class FallbackLogger:
            def info(self, msg): print(f"INFO: {msg}")
            def error(self, msg): print(f"ERROR: {msg}")
            def warning(self, msg): print(f"WARNING: {msg}")
            def debug(self, msg): print(f"DEBUG: {msg}")
        return FallbackLogger()

logger = create_module_logger()

# ==============================================
# ğŸ”§ TYPE_CHECKINGìœ¼ë¡œ ìˆœí™˜ì°¸ì¡° ë°©ì§€
# ==============================================
if TYPE_CHECKING:
    from app.ai_pipeline.utils.model_loader import ModelLoader
    from app.ai_pipeline.steps.base_step_mixin import BaseStepMixin

# ==============================================
# ğŸ”§ BaseStepMixin ë™ì  import (ìˆœí™˜ì°¸ì¡° ë°©ì§€)
# ==============================================
def import_base_step_mixin():
    """BaseStepMixin ë™ì  import"""
    try:
        import importlib
        base_module = importlib.import_module('app.ai_pipeline.steps.base_step_mixin')
        return getattr(base_module, 'BaseStepMixin')
    except ImportError as e:
        logger.error(f"âŒ BaseStepMixin import ì‹¤íŒ¨: {e}")
        class BaseStepMixin:
            def __init__(self, **kwargs):
                self.step_name = kwargs.get('step_name', 'ClothWarpingStep')
                self.step_id = kwargs.get('step_id', 5)
                self.device = kwargs.get('device', 'cpu')
                self.logger = logging.getLogger(self.step_name)
        return BaseStepMixin

BaseStepMixin = import_base_step_mixin()

# ==============================================
# ğŸ”§ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì•ˆì „ import
# ==============================================

# PyTorch ì•ˆì „ import
TORCH_AVAILABLE = False
MPS_AVAILABLE = False
try:
    import torch
    import torch.nn as nn
    import torch.nn.functional as F
    import torchvision.transforms as T
    TORCH_AVAILABLE = True
    
    if hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
        MPS_AVAILABLE = True
except ImportError:
    torch = None

# NumPy ì•ˆì „ import
NUMPY_AVAILABLE = False
try:
    import numpy as np
    NUMPY_AVAILABLE = True
except ImportError:
    np = None

# PIL ì•ˆì „ import
PIL_AVAILABLE = False
try:
    from PIL import Image, ImageEnhance, ImageFilter
    PIL_AVAILABLE = True
except ImportError:
    Image = None

# OpenCV ì•ˆì „ import
CV2_AVAILABLE = False
try:
    import cv2
    CV2_AVAILABLE = True
except ImportError:
    cv2 = None

# SafeTensors ì•ˆì „ import
SAFETENSORS_AVAILABLE = False
try:
    from safetensors import safe_open
    from safetensors.torch import load_file as load_safetensors
    SAFETENSORS_AVAILABLE = True
except ImportError:
    pass

# ==============================================
# ğŸ”¥ ì„¤ì • ë° ìƒíƒœ í´ë˜ìŠ¤
# ==============================================

class WarpingMethod(Enum):
    """ì›Œí•‘ ë°©ë²• ì—´ê±°í˜•"""
    TPS_ADVANCED = "tps_advanced"
    RAFT_FLOW = "raft_flow"
    REALVIS_XL = "realvis_xl"
    VGG_MATCHING = "vgg_matching"
    DENSENET_QUALITY = "densenet_quality"
    DIFFUSION_REFINE = "diffusion_refine"
    HYBRID_MULTI = "hybrid_multi"

class FabricType(Enum):
    """ì›ë‹¨ íƒ€ì… ì—´ê±°í˜•"""
    COTTON = "cotton"
    SILK = "silk"
    DENIM = "denim"
    WOOL = "wool"
    POLYESTER = "polyester"
    LINEN = "linen"
    LEATHER = "leather"
    SPANDEX = "spandex"

@dataclass
class ClothWarpingConfig:
    """ê°•í™”ëœ ì˜ë¥˜ ì›Œí•‘ ì„¤ì •"""
    step_name: str = "ClothWarpingStep"
    step_id: int = 5
    device: str = "auto"
    
    # ì›Œí•‘ ë°©ë²• ë° í’ˆì§ˆ
    warping_method: WarpingMethod = WarpingMethod.HYBRID_MULTI
    input_size: Tuple[int, int] = (512, 512)
    quality_level: str = "ultra"
    
    # AI ëª¨ë¸ í™œì„±í™”
    use_realvis_xl: bool = True
    use_vgg19_warping: bool = True
    use_vgg16_warping: bool = True
    use_densenet: bool = True
    use_diffusion_warping: bool = True
    use_tps_network: bool = True
    use_raft_flow: bool = True
    
    # TPS ì„¤ì •
    num_control_points: int = 25
    tps_grid_size: int = 5
    tps_regularization: float = 0.1
    
    # RAFT Flow ì„¤ì •
    raft_iterations: int = 12
    raft_small_model: bool = False
    
    # ë¬¼ë¦¬ ì‹œë®¬ë ˆì´ì…˜
    physics_enabled: bool = True
    fabric_simulation: bool = True
    
    # í’ˆì§ˆ ë° ìµœì í™”
    multi_scale_fusion: bool = True
    edge_preservation: bool = True
    texture_enhancement: bool = True
    
    # ë©”ëª¨ë¦¬ ë° ì„±ëŠ¥
    memory_fraction: float = 0.7
    batch_size: int = 1
    precision: str = "fp16"

# ì‹¤ì œ AI ëª¨ë¸ ë§¤í•‘ (í”„ë¡œì íŠ¸ì—ì„œ í™•ì¸ëœ íŒŒì¼ë“¤)
ENHANCED_CLOTH_WARPING_MODELS = {
    'realvis_xl': {
        'filename': 'RealVisXL_V4.0.safetensors',
        'size_mb': 6616.6,
        'format': 'safetensors',
        'class': 'EnhancedRealVisXLWarpingModel',
        'priority': 1
    },
    'vgg19_warping': {
        'filename': 'vgg19_warping.pth',
        'size_mb': 548.1,
        'format': 'pth',
        'class': 'VGG19WarpingModel',
        'priority': 2
    },
    'vgg16_warping': {
        'filename': 'vgg16_warping_ultra.pth',
        'size_mb': 527.8,
        'format': 'pth',
        'class': 'VGG16WarpingModel',
        'priority': 3
    },
    'densenet121': {
        'filename': 'densenet121_ultra.pth',
        'size_mb': 31.0,
        'format': 'pth',
        'class': 'DenseNetQualityModel',
        'priority': 4
    },
    'diffusion_warping': {
        'filename': 'diffusion_pytorch_model.bin',
        'size_mb': 1378.2,
        'format': 'bin',
        'class': 'DiffusionWarpingModel',
        'priority': 5
    },
    'safety_checker': {
        'filename': 'model.fp16.safetensors',
        'size_mb': 580.0,
        'format': 'safetensors',
        'class': 'SafetyChecker',
        'priority': 6
    }
}

# ==============================================
# ğŸ§  1. ê³ ê¸‰ TPS (Thin Plate Spline) ì›Œí•‘ ë„¤íŠ¸ì›Œí¬
# ==============================================

class AdvancedTPSWarpingNetwork(nn.Module):
    """ê³ ê¸‰ TPS ì›Œí•‘ ë„¤íŠ¸ì›Œí¬ - ì •ë°€í•œ ì˜ë¥˜ ë³€í˜•"""
    
    def __init__(self, num_control_points: int = 25, input_channels: int = 6):
        super().__init__()
        self.num_control_points = num_control_points
        
        # ResNet ê¸°ë°˜ íŠ¹ì§• ì¶”ì¶œê¸°
        self.feature_extractor = self._build_resnet_backbone()
        
        # TPS ì œì–´ì  ì˜ˆì¸¡ê¸°
        self.control_point_predictor = nn.Sequential(
            nn.AdaptiveAvgPool2d(1),
            nn.Flatten(),
            nn.Linear(2048, 1024),
            nn.ReLU(inplace=True),
            nn.Dropout(0.3),
            nn.Linear(1024, 512),
            nn.ReLU(inplace=True),
            nn.Dropout(0.2),
            nn.Linear(512, num_control_points * 2),  # x, y ì¢Œí‘œ
            nn.Tanh()
        )
        
        # TPS ë§¤ê°œë³€ìˆ˜ ì •ì œê¸°
        self.tps_refiner = nn.Sequential(
            nn.Conv2d(input_channels, 64, 3, 1, 1),
            nn.ReLU(inplace=True),
            nn.Conv2d(64, 32, 3, 1, 1),
            nn.ReLU(inplace=True),
            nn.Conv2d(32, 16, 3, 1, 1),
            nn.ReLU(inplace=True),
            nn.Conv2d(16, 2, 3, 1, 1),  # ì •ì œëœ ë³€ìœ„
            nn.Tanh()
        )
        
        # í’ˆì§ˆ í‰ê°€ê¸°
        self.quality_assessor = nn.Sequential(
            nn.AdaptiveAvgPool2d(1),
            nn.Flatten(),
            nn.Linear(2048, 256),
            nn.ReLU(inplace=True),
            nn.Linear(256, 64),
            nn.ReLU(inplace=True),
            nn.Linear(64, 1),
            nn.Sigmoid()
        )
    
    def _build_resnet_backbone(self):
        """ResNet ë°±ë³¸ êµ¬ì¶•"""
        return nn.Sequential(
            # ì´ˆê¸° ë ˆì´ì–´
            nn.Conv2d(6, 64, 7, 2, 3, bias=False),
            nn.BatchNorm2d(64),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(3, 2, 1),
            
            # ResNet ë¸”ë¡ë“¤
            self._make_layer(64, 64, 3),     # 256 channels
            self._make_layer(256, 128, 4, stride=2),  # 512 channels
            self._make_layer(512, 256, 6, stride=2),  # 1024 channels
            self._make_layer(1024, 512, 3, stride=2), # 2048 channels
        )
    
    def _make_layer(self, inplanes, planes, blocks, stride=1):
        """ResNet ë ˆì´ì–´ ìƒì„±"""
        layers = []
        
        # Downsample
        downsample = None
        if stride != 1 or inplanes != planes * 4:
            downsample = nn.Sequential(
                nn.Conv2d(inplanes, planes * 4, 1, stride, bias=False),
                nn.BatchNorm2d(planes * 4)
            )
        
        # ì²« ë²ˆì§¸ ë¸”ë¡
        layers.append(self._bottleneck(inplanes, planes, stride, downsample))
        
        # ë‚˜ë¨¸ì§€ ë¸”ë¡ë“¤
        for _ in range(1, blocks):
            layers.append(self._bottleneck(planes * 4, planes))
        
        return nn.Sequential(*layers)
    
    def _bottleneck(self, inplanes, planes, stride=1, downsample=None):
        """ResNet Bottleneck ë¸”ë¡"""
        return nn.Sequential(
            nn.Conv2d(inplanes, planes, 1, bias=False),
            nn.BatchNorm2d(planes),
            nn.ReLU(inplace=True),
            
            nn.Conv2d(planes, planes, 3, stride, 1, bias=False),
            nn.BatchNorm2d(planes),
            nn.ReLU(inplace=True),
            
            nn.Conv2d(planes, planes * 4, 1, bias=False),
            nn.BatchNorm2d(planes * 4),
            
            # Skip connection
            downsample if downsample else nn.Identity(),
            nn.ReLU(inplace=True)
        )
    
    def forward(self, cloth_image: torch.Tensor, person_image: torch.Tensor) -> Dict[str, torch.Tensor]:
        """ìˆœì „íŒŒ - ê³ ê¸‰ TPS ì›Œí•‘"""
        batch_size = cloth_image.size(0)
        
        # ì…ë ¥ ê²°í•©
        combined_input = torch.cat([cloth_image, person_image], dim=1)
        
        # íŠ¹ì§• ì¶”ì¶œ
        features = self.feature_extractor(combined_input)
        
        # TPS ì œì–´ì  ì˜ˆì¸¡
        control_points = self.control_point_predictor(features)
        control_points = control_points.view(batch_size, self.num_control_points, 2)
        
        # TPS ë³€í˜• ì ìš©
        tps_grid = self._solve_tps(control_points, cloth_image.shape[-2:])
        
        # ì •ì œëœ ë³€ìœ„ ê³„ì‚°
        refined_displacement = self.tps_refiner(combined_input)
        
        # ìµœì¢… ë³€í˜• ê·¸ë¦¬ë“œ
        final_grid = tps_grid + refined_displacement.permute(0, 2, 3, 1) * 0.1
        final_grid = torch.clamp(final_grid, -1, 1)
        
        # ì›Œí•‘ ì ìš©
        warped_cloth = F.grid_sample(
            cloth_image, final_grid, 
            mode='bilinear', padding_mode='border', align_corners=False
        )
        
        # í’ˆì§ˆ í‰ê°€
        quality_score = self.quality_assessor(features)
        
        return {
            'warped_cloth': warped_cloth,
            'control_points': control_points,
            'tps_grid': tps_grid,
            'refined_displacement': refined_displacement,
            'quality_score': quality_score,
            'confidence': torch.mean(quality_score)
        }
    
    def _solve_tps(self, control_points: torch.Tensor, image_size: Tuple[int, int]) -> torch.Tensor:
        """TPS ì†”ë²„ - ì œì–´ì ì—ì„œ ë³€í˜• ê·¸ë¦¬ë“œ ê³„ì‚°"""
        batch_size, num_points, _ = control_points.shape
        h, w = image_size
        
        # ì •ê·œí™”ëœ ê·¸ë¦¬ë“œ ìƒì„±
        y_coords = torch.linspace(-1, 1, h, device=control_points.device)
        x_coords = torch.linspace(-1, 1, w, device=control_points.device)
        grid_y, grid_x = torch.meshgrid(y_coords, x_coords, indexing='ij')
        grid = torch.stack([grid_x, grid_y], dim=-1).unsqueeze(0).repeat(batch_size, 1, 1, 1)
        
        # ì œì–´ì  ê°„ ê±°ë¦¬ í–‰ë ¬ ê³„ì‚°
        source_points = self._generate_regular_grid(num_points, control_points.device)
        target_points = control_points
        
        # ê°„ë‹¨í•œ RBF ë³´ê°„ìœ¼ë¡œ TPS ê·¼ì‚¬
        for b in range(batch_size):
            for i in range(num_points):
                src_pt = source_points[i]
                tgt_pt = target_points[b, i]
                
                # ì œì–´ì  ì£¼ë³€ ì˜ì—­ì— ë³€í˜• ì ìš©
                distances = torch.sqrt(
                    (grid[b, :, :, 0] - src_pt[0])**2 + 
                    (grid[b, :, :, 1] - src_pt[1])**2
                )
                
                # RBF ê°€ì¤‘ì¹˜
                weights = torch.exp(-distances * 5.0)
                displacement = (tgt_pt - src_pt) * weights.unsqueeze(-1)
                
                grid[b] += displacement
        
        return torch.clamp(grid, -1, 1)
    
    def _generate_regular_grid(self, num_points: int, device) -> torch.Tensor:
        """ê·œì¹™ì ì¸ ì œì–´ì  ê·¸ë¦¬ë“œ ìƒì„±"""
        grid_size = int(np.sqrt(num_points))
        points = []
        
        for i in range(grid_size):
            for j in range(grid_size):
                if len(points) >= num_points:
                    break
                x = -1 + 2 * j / max(1, grid_size - 1)
                y = -1 + 2 * i / max(1, grid_size - 1)
                points.append([x, y])
        
        # ë¶€ì¡±í•œ ì ë“¤ì€ ì¤‘ì•™ ê·¼ì²˜ì— ì¶”ê°€
        while len(points) < num_points:
            points.append([0.0, 0.0])
        
        return torch.tensor(points[:num_points], device=device, dtype=torch.float32)

# ==============================================
# ğŸ§  2. RAFT Optical Flow ê¸°ë°˜ ì •ë°€ ì›Œí•‘
# ==============================================

class RAFTFlowWarpingNetwork(nn.Module):
    """RAFT Optical Flow ê¸°ë°˜ ì •ë°€ ì›Œí•‘ ë„¤íŠ¸ì›Œí¬"""
    
    def __init__(self, small_model: bool = False):
        super().__init__()
        self.small_model = small_model
        
        # Feature encoder
        self.feature_encoder = self._build_feature_encoder()
        
        # Context encoder
        self.context_encoder = self._build_context_encoder()
        
        # Update block
        self.update_block = self._build_update_block()
        
        # Flow head
        self.flow_head = nn.Sequential(
            nn.Conv2d(128, 64, 3, 1, 1),
            nn.ReLU(inplace=True),
            nn.Conv2d(64, 32, 3, 1, 1),
            nn.ReLU(inplace=True),
            nn.Conv2d(32, 2, 3, 1, 1)
        )
    
    def _build_feature_encoder(self):
        """íŠ¹ì§• ì¸ì½”ë” êµ¬ì¶•"""
        if self.small_model:
            dims = [32, 32, 64, 96]
        else:
            dims = [64, 64, 96, 128]
        
        layers = []
        in_dim = 3
        
        for dim in dims:
            layers.extend([
                nn.Conv2d(in_dim, dim, 7, 2, 3),
                nn.ReLU(inplace=True),
                nn.Conv2d(dim, dim, 3, 1, 1),
                nn.ReLU(inplace=True)
            ])
            in_dim = dim
        
        return nn.Sequential(*layers)
    
    def _build_context_encoder(self):
        """ì»¨í…ìŠ¤íŠ¸ ì¸ì½”ë” êµ¬ì¶•"""
        return nn.Sequential(
            nn.Conv2d(3, 64, 7, 2, 3),
            nn.ReLU(inplace=True),
            nn.Conv2d(64, 64, 3, 1, 1),
            nn.ReLU(inplace=True),
            nn.Conv2d(64, 128, 3, 2, 1),
            nn.ReLU(inplace=True),
            nn.Conv2d(128, 128, 3, 1, 1),
            nn.ReLU(inplace=True)
        )
    
    def _build_update_block(self):
        """ì—…ë°ì´íŠ¸ ë¸”ë¡ êµ¬ì¶•"""
        return nn.Sequential(
            nn.Conv2d(256, 128, 3, 1, 1),
            nn.ReLU(inplace=True),
            nn.Conv2d(128, 128, 3, 1, 1),
            nn.ReLU(inplace=True)
        )
    
    def forward(self, cloth_image: torch.Tensor, person_image: torch.Tensor, 
                num_iterations: int = 12) -> Dict[str, torch.Tensor]:
        """RAFT ê¸°ë°˜ Flow ì¶”ì • ë° ì›Œí•‘"""
        
        # íŠ¹ì§• ì¶”ì¶œ
        cloth_features = self.feature_encoder(cloth_image)
        person_features = self.feature_encoder(person_image)
        
        # ì»¨í…ìŠ¤íŠ¸ ì¶”ì¶œ
        context = self.context_encoder(person_image)
        
        # ì´ˆê¸° flow ì¶”ì •
        corr_pyramid = self._build_correlation_pyramid(cloth_features, person_features)
        flow = torch.zeros(cloth_image.size(0), 2, cloth_image.size(2)//8, 
                          cloth_image.size(3)//8, device=cloth_image.device)
        
        flow_predictions = []
        
        # ë°˜ë³µì  ì •ì œ
        for _ in range(num_iterations):
            # ìƒê´€ê´€ê³„ ì¡°íšŒ
            corr = self._lookup_correlation(corr_pyramid, flow)
            
            # ì—…ë°ì´íŠ¸
            inp = torch.cat([corr, context], dim=1)
            delta_flow = self.update_block(inp)
            delta_flow = self.flow_head(delta_flow)
            
            flow = flow + delta_flow
            flow_predictions.append(flow)
        
        # Flowë¥¼ ì›ë³¸ í•´ìƒë„ë¡œ ì—…ìƒ˜í”Œ
        final_flow = F.interpolate(flow, size=cloth_image.shape[-2:], 
                                  mode='bilinear', align_corners=False) * 8.0
        
        # Flowë¥¼ ê·¸ë¦¬ë“œë¡œ ë³€í™˜
        grid = self._flow_to_grid(final_flow)
        
        # ì›Œí•‘ ì ìš©
        warped_cloth = F.grid_sample(
            cloth_image, grid, 
            mode='bilinear', padding_mode='border', align_corners=False
        )
        
        return {
            'warped_cloth': warped_cloth,
            'flow_field': final_flow,
            'grid': grid,
            'flow_predictions': flow_predictions,
            'confidence': self._estimate_flow_confidence(final_flow)
        }
    
    def _build_correlation_pyramid(self, fmap1: torch.Tensor, fmap2: torch.Tensor):
        """ìƒê´€ê´€ê³„ í”¼ë¼ë¯¸ë“œ êµ¬ì¶•"""
        batch, dim, h, w = fmap1.shape
        
        # íŠ¹ì§•ë§µ ì •ê·œí™”
        fmap1 = F.normalize(fmap1, dim=1)
        fmap2 = F.normalize(fmap2, dim=1)
        
        # ì „ì²´ ìƒê´€ê´€ê³„ ê³„ì‚°
        corr = torch.einsum('aijk,aij->aijk', fmap1, fmap2.view(batch, dim, -1))
        corr = corr.view(batch, h, w, h, w)
        
        # í”¼ë¼ë¯¸ë“œ ë ˆë²¨ ìƒì„±
        pyramid = [corr]
        for i in range(3):
            corr = F.avg_pool2d(corr.view(batch*h*w, 1, h, w), 2, 2)
            corr = corr.view(batch, h, w, h//2, w//2)
            pyramid.append(corr)
            h, w = h//2, w//2
        
        return pyramid
    
    def _lookup_correlation(self, pyramid, flow):
        """ìƒê´€ê´€ê³„ ì¡°íšŒ"""
        # ê°„ë‹¨í•œ êµ¬í˜„ - ì‹¤ì œë¡œëŠ” ë” ë³µì¡í•œ ìƒ˜í”Œë§ í•„ìš”
        return pyramid[0][:, :, :, 0, 0].unsqueeze(1)
    
    def _flow_to_grid(self, flow: torch.Tensor) -> torch.Tensor:
        """Flowë¥¼ ìƒ˜í”Œë§ ê·¸ë¦¬ë“œë¡œ ë³€í™˜"""
        batch, _, h, w = flow.shape
        
        # ê¸°ë³¸ ê·¸ë¦¬ë“œ ìƒì„±
        y_coords = torch.linspace(-1, 1, h, device=flow.device)
        x_coords = torch.linspace(-1, 1, w, device=flow.device)
        grid_y, grid_x = torch.meshgrid(y_coords, x_coords, indexing='ij')
        grid = torch.stack([grid_x, grid_y], dim=-1).unsqueeze(0).repeat(batch, 1, 1, 1)
        
        # Flow ì¶”ê°€ (ì •ê·œí™”)
        flow_normalized = flow.permute(0, 2, 3, 1)
        flow_normalized[:, :, :, 0] = flow_normalized[:, :, :, 0] / (w - 1) * 2
        flow_normalized[:, :, :, 1] = flow_normalized[:, :, :, 1] / (h - 1) * 2
        
        return grid + flow_normalized
    
    def _estimate_flow_confidence(self, flow: torch.Tensor) -> torch.Tensor:
        """Flow ì‹ ë¢°ë„ ì¶”ì •"""
        # ê°„ë‹¨í•œ ì‹ ë¢°ë„ ê³„ì‚° - flow ì¼ê´€ì„± ê¸°ë°˜
        flow_magnitude = torch.sqrt(flow[:, 0]**2 + flow[:, 1]**2)
        confidence = torch.exp(-flow_magnitude.mean(dim=[1, 2]) / 10.0)
        return confidence

# ==============================================
# ğŸ§  3. VGG ê¸°ë°˜ ì˜ë¥˜-ì¸ì²´ ë§¤ì¹­ ë„¤íŠ¸ì›Œí¬
# ==============================================

class VGGClothBodyMatchingNetwork(nn.Module):
    """VGG ê¸°ë°˜ ì˜ë¥˜-ì¸ì²´ ë§¤ì¹­ ë„¤íŠ¸ì›Œí¬"""
    
    def __init__(self, vgg_type: str = "vgg19"):
        super().__init__()
        self.vgg_type = vgg_type
        
        # VGG ë°±ë³¸
        self.vgg_features = self._build_vgg_backbone()
        
        # ì˜ë¥˜ ë¸Œëœì¹˜
        self.cloth_branch = nn.Sequential(
            nn.Conv2d(512, 256, 3, 1, 1),
            nn.ReLU(inplace=True),
            nn.Conv2d(256, 128, 3, 1, 1),
            nn.ReLU(inplace=True)
        )
        
        # ì¸ì²´ ë¸Œëœì¹˜
        self.body_branch = nn.Sequential(
            nn.Conv2d(512, 256, 3, 1, 1),
            nn.ReLU(inplace=True),
            nn.Conv2d(256, 128, 3, 1, 1),
            nn.ReLU(inplace=True)
        )
        
        # ë§¤ì¹­ í—¤ë“œ
        self.matching_head = nn.Sequential(
            nn.Conv2d(256, 128, 3, 1, 1),
            nn.ReLU(inplace=True),
            nn.Conv2d(128, 64, 3, 1, 1),
            nn.ReLU(inplace=True),
            nn.Conv2d(64, 32, 3, 1, 1),
            nn.ReLU(inplace=True),
            nn.Conv2d(32, 1, 1),
            nn.Sigmoid()
        )
        
        # í‚¤í¬ì¸íŠ¸ ê²€ì¶œê¸°
        self.keypoint_detector = nn.Sequential(
            nn.Conv2d(256, 128, 3, 1, 1),
            nn.ReLU(inplace=True),
            nn.Conv2d(128, 64, 3, 1, 1),
            nn.ReLU(inplace=True),
            nn.Conv2d(64, 25, 1),  # 25ê°œ í‚¤í¬ì¸íŠ¸
            nn.Sigmoid()
        )
    
    def _build_vgg_backbone(self):
        """VGG ë°±ë³¸ êµ¬ì¶•"""
        if self.vgg_type == "vgg19":
            cfg = [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 
                   512, 512, 512, 512, 'M', 512, 512, 512, 512]
        else:  # vgg16
            cfg = [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 
                   512, 512, 512, 'M', 512, 512, 512]
        
        layers = []
        in_channels = 3
        
        for v in cfg:
            if v == 'M':
                layers.append(nn.MaxPool2d(2, 2))
            else:
                layers.extend([
                    nn.Conv2d(in_channels, v, 3, 1, 1),
                    nn.ReLU(inplace=True)
                ])
                in_channels = v
        
        return nn.Sequential(*layers)
    
    def forward(self, cloth_image: torch.Tensor, person_image: torch.Tensor) -> Dict[str, torch.Tensor]:
        """VGG ê¸°ë°˜ ì˜ë¥˜-ì¸ì²´ ë§¤ì¹­"""
        
        # VGG íŠ¹ì§• ì¶”ì¶œ
        cloth_features = self.vgg_features(cloth_image)
        person_features = self.vgg_features(person_image)
        
        # ë¸Œëœì¹˜ë³„ íŠ¹ì§• ì²˜ë¦¬
        cloth_processed = self.cloth_branch(cloth_features)
        person_processed = self.body_branch(person_features)
        
        # íŠ¹ì§• ê²°í•©
        combined_features = torch.cat([cloth_processed, person_processed], dim=1)
        
        # ë§¤ì¹­ ë§µ ìƒì„±
        matching_map = self.matching_head(combined_features)
        
        # í‚¤í¬ì¸íŠ¸ ê²€ì¶œ
        keypoints = self.keypoint_detector(combined_features)
        
        # ë§¤ì¹­ ê¸°ë°˜ ì›Œí•‘ ê·¸ë¦¬ë“œ ìƒì„±
        warping_grid = self._generate_warping_grid(matching_map, keypoints)
        
        # ì›Œí•‘ ì ìš©
        warped_cloth = F.grid_sample(
            cloth_image, warping_grid,
            mode='bilinear', padding_mode='border', align_corners=False
        )
        
        return {
            'warped_cloth': warped_cloth,
            'matching_map': matching_map,
            'keypoints': keypoints,
            'warping_grid': warping_grid,
            'cloth_features': cloth_processed,
            'person_features': person_processed,
            'confidence': torch.mean(matching_map)
        }
    
    def _generate_warping_grid(self, matching_map: torch.Tensor, 
                              keypoints: torch.Tensor) -> torch.Tensor:
        """ë§¤ì¹­ ë§µê³¼ í‚¤í¬ì¸íŠ¸ ê¸°ë°˜ ì›Œí•‘ ê·¸ë¦¬ë“œ ìƒì„±"""
        batch_size, _, h, w = matching_map.shape
        
        # ê¸°ë³¸ ê·¸ë¦¬ë“œ
        y_coords = torch.linspace(-1, 1, h, device=matching_map.device)
        x_coords = torch.linspace(-1, 1, w, device=matching_map.device)
        grid_y, grid_x = torch.meshgrid(y_coords, x_coords, indexing='ij')
        grid = torch.stack([grid_x, grid_y], dim=-1).unsqueeze(0).repeat(batch_size, 1, 1, 1)
        
        # ë§¤ì¹­ ë§µ ê¸°ë°˜ ë³€í˜•
        matching_displacement = torch.stack([
            torch.gradient(matching_map.squeeze(1), dim=2)[0] * 0.1,
            torch.gradient(matching_map.squeeze(1), dim=1)[0] * 0.1
        ], dim=-1)
        
        # í‚¤í¬ì¸íŠ¸ ê¸°ë°˜ ë¡œì»¬ ë³€í˜•
        for b in range(batch_size):
            for k in range(min(5, keypoints.size(1))):  # ìƒìœ„ 5ê°œ í‚¤í¬ì¸íŠ¸ë§Œ ì‚¬ìš©
                kp_map = keypoints[b, k]
                
                # í‚¤í¬ì¸íŠ¸ ìµœëŒ€ê°’ ìœ„ì¹˜
                max_pos = torch.unravel_index(torch.argmax(kp_map), kp_map.shape)
                center_y, center_x = max_pos[0].item(), max_pos[1].item()
                
                # ë¡œì»¬ ë³€í˜• ì ìš©
                y_dist = (torch.arange(h, device=matching_map.device) - center_y).float()
                x_dist = (torch.arange(w, device=matching_map.device) - center_x).float()
                
                y_grid_dist, x_grid_dist = torch.meshgrid(y_dist, x_dist, indexing='ij')
                distances = torch.sqrt(y_grid_dist**2 + x_grid_dist**2)
                
                # RBF ê°€ì¤‘ì¹˜
                weights = torch.exp(-distances / 20.0) * kp_map[center_y, center_x]
                
                # ë³€í˜• ì ìš©
                grid[b, :, :, 0] += weights * 0.05
                grid[b, :, :, 1] += weights * 0.05
        
        return torch.clamp(grid, -1, 1)

# ==============================================
# ğŸ§  4. DenseNet ê¸°ë°˜ í’ˆì§ˆ í‰ê°€ ë„¤íŠ¸ì›Œí¬
# ==============================================

class DenseNetQualityAssessment(nn.Module):
    """DenseNet ê¸°ë°˜ ì›Œí•‘ í’ˆì§ˆ í‰ê°€"""
    
    def __init__(self, growth_rate: int = 32, num_layers: int = 121):
        super().__init__()
        
        # DenseNet ë¸”ë¡ ì„¤ì •
        if num_layers == 121:
            block_config = (6, 12, 24, 16)
        elif num_layers == 169:
            block_config = (6, 12, 32, 32)
        else:
            block_config = (6, 12, 24, 16)
        
        # ì´ˆê¸° ì»¨ë³¼ë£¨ì…˜
        self.initial_conv = nn.Sequential(
            nn.Conv2d(6, 64, 7, 2, 3, bias=False),  # cloth + person
            nn.BatchNorm2d(64),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(3, 2, 1)
        )
        
        # DenseNet ë¸”ë¡ë“¤
        num_features = 64
        self.dense_blocks = nn.ModuleList()
        self.transitions = nn.ModuleList()
        
        for i, num_layers in enumerate(block_config):
            # Dense Block
            block = self._make_dense_block(num_features, growth_rate, num_layers)
            self.dense_blocks.append(block)
            num_features += num_layers * growth_rate
            
            # Transition (ë§ˆì§€ë§‰ ë¸”ë¡ ì œì™¸)
            if i != len(block_config) - 1:
                transition = self._make_transition(num_features, num_features // 2)
                self.transitions.append(transition)
                num_features = num_features // 2
        
        # í’ˆì§ˆ í‰ê°€ í—¤ë“œ
        self.quality_head = nn.Sequential(
            nn.AdaptiveAvgPool2d(1),
            nn.Flatten(),
            nn.Linear(num_features, 512),
            nn.ReLU(inplace=True),
            nn.Dropout(0.3),
            nn.Linear(512, 256),
            nn.ReLU(inplace=True),
            nn.Dropout(0.2),
            nn.Linear(256, 64),
            nn.ReLU(inplace=True),
            nn.Linear(64, 1),
            nn.Sigmoid()
        )
        
        # ì„¸ë¶€ í’ˆì§ˆ ë©”íŠ¸ë¦­
        self.detail_metrics = nn.ModuleDict({
            'texture_preservation': nn.Sequential(
                nn.AdaptiveAvgPool2d(1), nn.Flatten(),
                nn.Linear(num_features, 64), nn.ReLU(),
                nn.Linear(64, 1), nn.Sigmoid()
            ),
            'shape_consistency': nn.Sequential(
                nn.AdaptiveAvgPool2d(1), nn.Flatten(),
                nn.Linear(num_features, 64), nn.ReLU(),
                nn.Linear(64, 1), nn.Sigmoid()
            ),
            'edge_sharpness': nn.Sequential(
                nn.AdaptiveAvgPool2d(1), nn.Flatten(),
                nn.Linear(num_features, 64), nn.ReLU(),
                nn.Linear(64, 1), nn.Sigmoid()
            )
        })
    
    def _make_dense_block(self, num_features: int, growth_rate: int, num_layers: int):
        """DenseNet ë¸”ë¡ ìƒì„±"""
        layers = []
        for i in range(num_layers):
            layers.append(self._make_dense_layer(num_features + i * growth_rate, growth_rate))
        return nn.Sequential(*layers)
    
    def _make_dense_layer(self, num_input_features: int, growth_rate: int):
        """Dense Layer ìƒì„±"""
        return nn.Sequential(
            nn.BatchNorm2d(num_input_features),
            nn.ReLU(inplace=True),
            nn.Conv2d(num_input_features, growth_rate * 4, 1, bias=False),
            nn.BatchNorm2d(growth_rate * 4),
            nn.ReLU(inplace=True),
            nn.Conv2d(growth_rate * 4, growth_rate, 3, 1, 1, bias=False)
        )
    
    def _make_transition(self, num_input_features: int, num_output_features: int):
        """Transition Layer ìƒì„±"""
        return nn.Sequential(
            nn.BatchNorm2d(num_input_features),
            nn.ReLU(inplace=True),
            nn.Conv2d(num_input_features, num_output_features, 1, bias=False),
            nn.AvgPool2d(2, 2)
        )
    
    def forward(self, cloth_image: torch.Tensor, warped_cloth: torch.Tensor) -> Dict[str, torch.Tensor]:
        """DenseNet ê¸°ë°˜ í’ˆì§ˆ í‰ê°€"""
        
        # ì…ë ¥ ê²°í•©
        combined_input = torch.cat([cloth_image, warped_cloth], dim=1)
        
        # ì´ˆê¸° íŠ¹ì§• ì¶”ì¶œ
        features = self.initial_conv(combined_input)
        
        # DenseNet ë¸”ë¡ë“¤ í†µê³¼
        for i, dense_block in enumerate(self.dense_blocks):
            features = dense_block(features)
            if i < len(self.transitions):
                features = self.transitions[i](features)
        
        # ì „ì²´ í’ˆì§ˆ ì ìˆ˜
        overall_quality = self.quality_head(features)
        
        # ì„¸ë¶€ ë©”íŠ¸ë¦­
        detail_scores = {}
        for metric_name, metric_head in self.detail_metrics.items():
            detail_scores[metric_name] = metric_head(features)
        
        return {
            'overall_quality': overall_quality,
            'texture_preservation': detail_scores['texture_preservation'],
            'shape_consistency': detail_scores['shape_consistency'],
            'edge_sharpness': detail_scores['edge_sharpness'],
            'quality_features': features,
            'confidence': overall_quality
        }

# ==============================================
# ğŸ§  5. Diffusion ê¸°ë°˜ ì›Œí•‘ ì •ì œ ë„¤íŠ¸ì›Œí¬
# ==============================================

class DiffusionWarpingRefinement(nn.Module):
    """Diffusion ê¸°ë°˜ ì›Œí•‘ ì •ì œ ë„¤íŠ¸ì›Œí¬"""
    
    def __init__(self, num_diffusion_steps: int = 20):
        super().__init__()
        self.num_steps = num_diffusion_steps
        
        # U-Net ê¸°ë°˜ ë…¸ì´ì¦ˆ ì˜ˆì¸¡ê¸°
        self.noise_predictor = self._build_unet()
        
        # Time embedding
        self.time_embed = nn.Sequential(
            nn.Linear(128, 256),
            nn.ReLU(inplace=True),
            nn.Linear(256, 256)
        )
        
        # Condition encoder (ì›ë³¸ ì˜ë¥˜ ì´ë¯¸ì§€)
        self.condition_encoder = nn.Sequential(
            nn.Conv2d(3, 64, 3, 1, 1),
            nn.ReLU(inplace=True),
            nn.Conv2d(64, 128, 3, 1, 1),
            nn.ReLU(inplace=True),
            nn.Conv2d(128, 256, 3, 1, 1),
            nn.ReLU(inplace=True)
        )
    
    def _build_unet(self):
        """U-Net ë…¸ì´ì¦ˆ ì˜ˆì¸¡ê¸° êµ¬ì¶•"""
        return nn.ModuleDict({
            # ì¸ì½”ë”
            'enc1': nn.Sequential(
                nn.Conv2d(3, 64, 3, 1, 1),
                nn.ReLU(inplace=True),
                nn.Conv2d(64, 64, 3, 1, 1),
                nn.ReLU(inplace=True)
            ),
            'enc2': nn.Sequential(
                nn.MaxPool2d(2),
                nn.Conv2d(64, 128, 3, 1, 1),
                nn.ReLU(inplace=True),
                nn.Conv2d(128, 128, 3, 1, 1),
                nn.ReLU(inplace=True)
            ),
            'enc3': nn.Sequential(
                nn.MaxPool2d(2),
                nn.Conv2d(128, 256, 3, 1, 1),
                nn.ReLU(inplace=True),
                nn.Conv2d(256, 256, 3, 1, 1),
                nn.ReLU(inplace=True)
            ),
            'enc4': nn.Sequential(
                nn.MaxPool2d(2),
                nn.Conv2d(256, 512, 3, 1, 1),
                nn.ReLU(inplace=True),
                nn.Conv2d(512, 512, 3, 1, 1),
                nn.ReLU(inplace=True)
            ),
            
            # ì¤‘ê°„ ë ˆì´ì–´
            'middle': nn.Sequential(
                nn.MaxPool2d(2),
                nn.Conv2d(512, 1024, 3, 1, 1),
                nn.ReLU(inplace=True),
                nn.Conv2d(1024, 1024, 3, 1, 1),
                nn.ReLU(inplace=True),
                nn.ConvTranspose2d(1024, 512, 2, 2)
            ),
            
            # ë””ì½”ë”
            'dec4': nn.Sequential(
                nn.Conv2d(1024, 512, 3, 1, 1),
                nn.ReLU(inplace=True),
                nn.Conv2d(512, 512, 3, 1, 1),
                nn.ReLU(inplace=True),
                nn.ConvTranspose2d(512, 256, 2, 2)
            ),
            'dec3': nn.Sequential(
                nn.Conv2d(512, 256, 3, 1, 1),
                nn.ReLU(inplace=True),
                nn.Conv2d(256, 256, 3, 1, 1),
                nn.ReLU(inplace=True),
                nn.ConvTranspose2d(256, 128, 2, 2)
            ),
            'dec2': nn.Sequential(
                nn.Conv2d(256, 128, 3, 1, 1),
                nn.ReLU(inplace=True),
                nn.Conv2d(128, 128, 3, 1, 1),
                nn.ReLU(inplace=True),
                nn.ConvTranspose2d(128, 64, 2, 2)
            ),
            'dec1': nn.Sequential(
                nn.Conv2d(128, 64, 3, 1, 1),
                nn.ReLU(inplace=True),
                nn.Conv2d(64, 64, 3, 1, 1),
                nn.ReLU(inplace=True),
                nn.Conv2d(64, 3, 1, 1)
            )
        })
    
    def forward(self, noisy_warped_cloth: torch.Tensor, 
                original_cloth: torch.Tensor, 
                timestep: torch.Tensor) -> Dict[str, torch.Tensor]:
        """Diffusion ê¸°ë°˜ ì •ì œ"""
        
        # Time embedding
        t_emb = self._positional_encoding(timestep, 128)
        t_emb = self.time_embed(t_emb)
        
        # Condition encoding
        condition = self.condition_encoder(original_cloth)
        
        # U-Net í†µê³¼
        x = noisy_warped_cloth
        
        # ì¸ì½”ë”
        e1 = self.noise_predictor['enc1'](x)
        e2 = self.noise_predictor['enc2'](e1)
        e3 = self.noise_predictor['enc3'](e2)
        e4 = self.noise_predictor['enc4'](e3)
        
        # ì¤‘ê°„ ë ˆì´ì–´
        middle = self.noise_predictor['middle'](e4)
        
        # ë””ì½”ë” (skip connections)
        d4 = self.noise_predictor['dec4'](torch.cat([middle, e4], dim=1))
        d3 = self.noise_predictor['dec3'](torch.cat([d4, e3], dim=1))
        d2 = self.noise_predictor['dec2'](torch.cat([d3, e2], dim=1))
        noise_pred = self.noise_predictor['dec1'](torch.cat([d2, e1], dim=1))
        
        return {
            'noise_prediction': noise_pred,
            'refined_cloth': noisy_warped_cloth - noise_pred,
            'condition_features': condition,
            'confidence': torch.ones_like(timestep) * 0.9
        }
    
    def _positional_encoding(self, timestep: torch.Tensor, dim: int) -> torch.Tensor:
        """Positional encoding for timestep"""
        half_dim = dim // 2
        emb = math.log(10000) / (half_dim - 1)
        emb = torch.exp(torch.arange(half_dim, device=timestep.device) * -emb)
        emb = timestep.unsqueeze(-1) * emb.unsqueeze(0)
        emb = torch.cat([torch.sin(emb), torch.cos(emb)], dim=-1)
        return emb
    
    def denoise_steps(self, initial_warped: torch.Tensor, 
                     original_cloth: torch.Tensor) -> torch.Tensor:
        """ë©€í‹° ìŠ¤í… ë””ë…¸ì´ì§•"""
        current = initial_warped
        
        for t in range(self.num_steps - 1, -1, -1):
            timestep = torch.tensor([t], device=initial_warped.device)
            
            # ë…¸ì´ì¦ˆ ì˜ˆì¸¡
            result = self.forward(current, original_cloth, timestep)
            noise_pred = result['noise_prediction']
            
            # ë””ë…¸ì´ì§• ìŠ¤í…
            alpha_t = 1.0 - t / self.num_steps
            current = current - alpha_t * noise_pred
            
            # í´ë¨í•‘
            current = torch.clamp(current, -1, 1)
        
        return current

# ==============================================
# ğŸ§  6. ë©€í‹° ìŠ¤ì¼€ì¼ íŠ¹ì§• ìœµí•© ëª¨ë“ˆ
# ==============================================

class MultiScaleFeatureFusion(nn.Module):
    """ë©€í‹° ìŠ¤ì¼€ì¼ íŠ¹ì§• ìœµí•© ëª¨ë“ˆ"""
    
    def __init__(self, input_channels: List[int] = [128, 256, 512, 1024]):
        super().__init__()
        self.input_channels = input_channels
        self.output_channels = 256
        
        # ê° ìŠ¤ì¼€ì¼ë³„ í”„ë¡œì ì…˜ ë ˆì´ì–´
        self.projections = nn.ModuleList([
            nn.Conv2d(ch, self.output_channels, 1) 
            for ch in input_channels
        ])
        
        # íŠ¹ì§• ìœµí•©
        self.fusion_conv = nn.Sequential(
            nn.Conv2d(self.output_channels * len(input_channels), 
                     self.output_channels, 3, 1, 1),
            nn.ReLU(inplace=True),
            nn.Conv2d(self.output_channels, self.output_channels, 3, 1, 1),
            nn.ReLU(inplace=True)
        )
        
        # ì–´í…ì…˜ ëª¨ë“ˆ
        self.attention = nn.Sequential(
            nn.Conv2d(self.output_channels, self.output_channels // 4, 1),
            nn.ReLU(inplace=True),
            nn.Conv2d(self.output_channels // 4, len(input_channels), 1),
            nn.Softmax(dim=1)
        )
    
    def forward(self, features: List[torch.Tensor]) -> torch.Tensor:
        """ë©€í‹° ìŠ¤ì¼€ì¼ íŠ¹ì§• ìœµí•©"""
        target_size = features[0].shape[-2:]
        
        # ê° íŠ¹ì§•ì„ ë™ì¼í•œ í¬ê¸°ë¡œ ë§ì¶”ê³  í”„ë¡œì ì…˜
        projected_features = []
        for i, feat in enumerate(features):
            # í¬ê¸° ë§ì¶¤
            if feat.shape[-2:] != target_size:
                feat = F.interpolate(feat, size=target_size, 
                                   mode='bilinear', align_corners=False)
            
            # ì±„ë„ í”„ë¡œì ì…˜
            projected = self.projections[i](feat)
            projected_features.append(projected)
        
        # íŠ¹ì§• ì—°ê²°
        concatenated = torch.cat(projected_features, dim=1)
        
        # ìœµí•©
        fused = self.fusion_conv(concatenated)
        
        # ì–´í…ì…˜ ì ìš©
        attention_weights = self.attention(fused)
        
        # ê°€ì¤‘ í‰ê· 
        weighted_features = []
        for i, feat in enumerate(projected_features):
            weight = attention_weights[:, i:i+1, :, :]
            weighted_features.append(feat * weight)
        
        final_features = sum(weighted_features)
        
        return final_features

# ==============================================
# ğŸ§  7. ë¬¼ë¦¬ ê¸°ë°˜ ì›ë‹¨ ì‹œë®¬ë ˆì´ì…˜
# ==============================================

class PhysicsBasedFabricSimulation:
    """ë¬¼ë¦¬ ê¸°ë°˜ ì›ë‹¨ ì‹œë®¬ë ˆì´ì…˜"""
    
    def __init__(self, fabric_type: FabricType = FabricType.COTTON):
        self.fabric_type = fabric_type
        self.fabric_properties = self._get_fabric_properties(fabric_type)
    
    def _get_fabric_properties(self, fabric_type: FabricType) -> Dict[str, float]:
        """ì›ë‹¨ íƒ€ì…ë³„ ë¬¼ë¦¬ ì†ì„±"""
        properties = {
            FabricType.COTTON: {
                'elasticity': 0.3, 'stiffness': 0.5, 'damping': 0.1,
                'density': 1.5, 'friction': 0.6
            },
            FabricType.SILK: {
                'elasticity': 0.1, 'stiffness': 0.2, 'damping': 0.05,
                'density': 1.3, 'friction': 0.3
            },
            FabricType.DENIM: {
                'elasticity': 0.5, 'stiffness': 0.8, 'damping': 0.2,
                'density': 1.8, 'friction': 0.8
            },
            FabricType.WOOL: {
                'elasticity': 0.4, 'stiffness': 0.6, 'damping': 0.15,
                'density': 1.4, 'friction': 0.7
            },
            FabricType.SPANDEX: {
                'elasticity': 0.8, 'stiffness': 0.3, 'damping': 0.05,
                'density': 1.2, 'friction': 0.4
            }
        }
        return properties.get(fabric_type, properties[FabricType.COTTON])
    
    def simulate_fabric_deformation(self, warped_cloth: torch.Tensor, 
                                   force_field: torch.Tensor) -> torch.Tensor:
        """ì›ë‹¨ ë³€í˜• ì‹œë®¬ë ˆì´ì…˜"""
        try:
            batch_size, channels, height, width = warped_cloth.shape
            
            # ë¬¼ë¦¬ ì†ì„± ì ìš©
            elasticity = self.fabric_properties['elasticity']
            stiffness = self.fabric_properties['stiffness']
            damping = self.fabric_properties['damping']
            
            # ê°„ë‹¨í•œ ìŠ¤í”„ë§-ëŒí¼ ì‹œìŠ¤í…œ ì‹œë®¬ë ˆì´ì…˜
            # ì¸ì ‘ í”½ì…€ ê°„ì˜ ìŠ¤í”„ë§ ì—°ê²°ì„ ê°€ì •
            
            # ìˆ˜í‰ ë°©í–¥ ìŠ¤í”„ë§ í¬ìŠ¤
            horizontal_diff = F.pad(warped_cloth[:, :, :, 1:] - warped_cloth[:, :, :, :-1], 
                                   (0, 1, 0, 0))
            horizontal_force = -stiffness * horizontal_diff
            
            # ìˆ˜ì§ ë°©í–¥ ìŠ¤í”„ë§ í¬ìŠ¤
            vertical_diff = F.pad(warped_cloth[:, :, 1:, :] - warped_cloth[:, :, :-1, :], 
                                 (0, 0, 0, 1))
            vertical_force = -stiffness * vertical_diff
            
            # ëŒí•‘ í¬ìŠ¤ (ê°„ë‹¨í•œ êµ¬í˜„)
            damping_force = -damping * warped_cloth
            
            # ì™¸ë¶€ í¬ìŠ¤ (force_field) ì ìš©
            external_force = force_field * elasticity
            
            # ì´ í¬ìŠ¤
            total_force = horizontal_force + vertical_force + damping_force + external_force
            
            # í¬ìŠ¤ë¥¼ ì´ìš©í•œ ë³€í˜• ì ìš© (ì˜¤ì¼ëŸ¬ ì ë¶„)
            dt = 0.1  # ì‹œê°„ ìŠ¤í…
            displacement = total_force * dt * dt  # F = ma, a*dt^2 = displacement
            
            # ë³€í˜• ì œí•œ (ê³¼ë„í•œ ë³€í˜• ë°©ì§€)
            displacement = torch.clamp(displacement, -0.1, 0.1)
            
            simulated_cloth = warped_cloth + displacement
            
            # ë²”ìœ„ ì œí•œ
            simulated_cloth = torch.clamp(simulated_cloth, -1, 1)
            
            return simulated_cloth
            
        except Exception as e:
            logger.warning(f"ë¬¼ë¦¬ ì‹œë®¬ë ˆì´ì…˜ ì‹¤íŒ¨: {e}")
            return warped_cloth
    
    def apply_gravity_effect(self, cloth: torch.Tensor) -> torch.Tensor:
        """ì¤‘ë ¥ íš¨ê³¼ ì ìš©"""
        try:
            # ê°„ë‹¨í•œ ì¤‘ë ¥ íš¨ê³¼ - ì•„ë˜ìª½ìœ¼ë¡œ ì•½ê°„ì˜ ë“œë˜ê·¸
            gravity_strength = 0.02 * self.fabric_properties['density']
            
            # Y ë°©í–¥ìœ¼ë¡œ ê°€ì¤‘ì¹˜ ì ìš© (ì•„ë˜ìª½ì´ ë” ì˜í–¥ ë°›ìŒ)
            height = cloth.shape[2]
            y_weights = torch.linspace(0, gravity_strength, height, device=cloth.device)
            y_weights = y_weights.view(1, 1, -1, 1)
            
            # ì¤‘ë ¥ íš¨ê³¼ ì ìš©
            gravity_effect = torch.zeros_like(cloth)
            gravity_effect[:, :, 1:, :] = cloth[:, :, :-1, :] - cloth[:, :, 1:, :] 
            gravity_effect = gravity_effect * y_weights
            
            return cloth + gravity_effect
            
        except Exception as e:
            logger.warning(f"ì¤‘ë ¥ íš¨ê³¼ ì ìš© ì‹¤íŒ¨: {e}")
            return cloth

# ==============================================
# ğŸ§  8. ë©”ì¸ ê°•í™”ëœ ClothWarpingStep í´ë˜ìŠ¤
# ==============================================

class ClothWarpingStep(BaseStepMixin):
    """
    ğŸ¯ ê°•í™”ëœ ì˜ë¥˜ ì›Œí•‘ Step - ê³ ê¸‰ AI ì•Œê³ ë¦¬ì¦˜ êµ¬í˜„
    
    âœ… BaseStepMixin v19.1 ì™„ì „ í˜¸í™˜
    âœ… 7ê°œ ê³ ê¸‰ AI ì•Œê³ ë¦¬ì¦˜ í†µí•©
    âœ… ì‹¤ì œ AI ëª¨ë¸ íŒŒì¼ í™œìš©
    âœ… ë©€í‹° ìŠ¤ì¼€ì¼ íŠ¹ì§• ìœµí•©
    âœ… ë¬¼ë¦¬ ê¸°ë°˜ ì›ë‹¨ ì‹œë®¬ë ˆì´ì…˜
    """
    
    def __init__(self, **kwargs):
        """ì´ˆê¸°í™”"""
        try:
            # ê¸°ë³¸ ì†ì„± ì„¤ì •
            kwargs.setdefault('step_name', 'ClothWarpingStep')
            kwargs.setdefault('step_id', 5)
            
            # BaseStepMixin ì´ˆê¸°í™”
            super().__init__(**kwargs)
            
            # ì›Œí•‘ ì„¤ì •
            self.warping_config = ClothWarpingConfig(**kwargs)
            
            # AI ëª¨ë¸ë“¤ ì´ˆê¸°í™”
            self.tps_network = None
            self.raft_network = None
            self.vgg_matching = None
            self.densenet_quality = None
            self.diffusion_refiner = None
            self.multi_scale_fusion = None
            
            # ë¬¼ë¦¬ ì‹œë®¬ë ˆì´ì…˜
            self.fabric_simulator = PhysicsBasedFabricSimulation()
            
            # ë¡œë”©ëœ ëª¨ë¸ ìƒíƒœ
            self.loaded_models = {}
            self.model_loading_errors = {}
            
            # ìºì‹œ
            self.prediction_cache = {}
            
            self.logger.info(f"âœ… Enhanced ClothWarpingStep v15.0 ì´ˆê¸°í™” ì™„ë£Œ")
            
        except Exception as e:
            self.logger.error(f"âŒ ClothWarpingStep ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self._emergency_setup(**kwargs)
    
    def _emergency_setup(self, **kwargs):
        """ê¸´ê¸‰ ì„¤ì •"""
        self.step_name = 'ClothWarpingStep'
        self.step_id = 5
        self.device = kwargs.get('device', 'cpu')
        self.logger = logging.getLogger(f"pipeline.{self.step_name}")
        self.warping_config = ClothWarpingConfig()
        self.loaded_models = {}
        self.prediction_cache = {}
        self.logger.warning("âš ï¸ ê¸´ê¸‰ ì„¤ì • ì™„ë£Œ")
    
    def set_model_loader(self, model_loader):
        """ModelLoader ì˜ì¡´ì„± ì£¼ì…"""
        try:
            super().set_model_loader(model_loader)
            self.logger.info("âœ… ModelLoader ì˜ì¡´ì„± ì£¼ì… ì™„ë£Œ")
            return True
        except Exception as e:
            self.logger.error(f"âŒ ModelLoader ì£¼ì… ì‹¤íŒ¨: {e}")
            return False
    
    def initialize(self) -> bool:
        """ì´ˆê¸°í™” - AI ëª¨ë¸ë“¤ ë¡œë”©"""
        try:
            if self.is_initialized:
                return True
            
            self.logger.info("ğŸš€ Enhanced ClothWarpingStep ì´ˆê¸°í™” ì‹œì‘")
            
            # AI ëª¨ë¸ë“¤ ë¡œë”©
            self._load_ai_models()
            
            self.is_initialized = True
            self.is_ready = True
            
            self.logger.info("âœ… Enhanced ClothWarpingStep ì´ˆê¸°í™” ì™„ë£Œ")
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return False
    
    def _load_ai_models(self):
        """ì‹¤ì œ AI ëª¨ë¸ë“¤ ë¡œë”©"""
        try:
            self.logger.info("ğŸ§  AI ëª¨ë¸ë“¤ ë¡œë”© ì‹œì‘...")
            
            # 1. TPS ë„¤íŠ¸ì›Œí¬
            if self.warping_config.use_tps_network:
                try:
                    self.tps_network = AdvancedTPSWarpingNetwork(
                        num_control_points=self.warping_config.num_control_points
                    ).to(self.device)
                    self._load_model_weights('tps_network', self.tps_network)
                    self.loaded_models['tps_network'] = True
                    self.logger.info("âœ… TPS Network ë¡œë”© ì™„ë£Œ")
                except Exception as e:
                    self.model_loading_errors['tps_network'] = str(e)
                    self.logger.warning(f"âš ï¸ TPS Network ë¡œë”© ì‹¤íŒ¨: {e}")
            
            # 2. RAFT Flow ë„¤íŠ¸ì›Œí¬
            if self.warping_config.use_raft_flow:
                try:
                    self.raft_network = RAFTFlowWarpingNetwork(
                        small_model=self.warping_config.raft_small_model
                    ).to(self.device)
                    self._load_model_weights('raft_flow', self.raft_network)
                    self.loaded_models['raft_flow'] = True
                    self.logger.info("âœ… RAFT Flow Network ë¡œë”© ì™„ë£Œ")
                except Exception as e:
                    self.model_loading_errors['raft_flow'] = str(e)
                    self.logger.warning(f"âš ï¸ RAFT Flow Network ë¡œë”© ì‹¤íŒ¨: {e}")
            
            # 3. VGG ë§¤ì¹­ ë„¤íŠ¸ì›Œí¬
            if self.warping_config.use_vgg19_warping:
                try:
                    self.vgg_matching = VGGClothBodyMatchingNetwork(
                        vgg_type="vgg19"
                    ).to(self.device)
                    self._load_model_weights('vgg19_warping', self.vgg_matching)
                    self.loaded_models['vgg_matching'] = True
                    self.logger.info("âœ… VGG Matching Network ë¡œë”© ì™„ë£Œ")
                except Exception as e:
                    self.model_loading_errors['vgg_matching'] = str(e)
                    self.logger.warning(f"âš ï¸ VGG Matching Network ë¡œë”© ì‹¤íŒ¨: {e}")
            
            # 4. DenseNet í’ˆì§ˆ í‰ê°€
            if self.warping_config.use_densenet:
                try:
                    self.densenet_quality = DenseNetQualityAssessment().to(self.device)
                    self._load_model_weights('densenet121', self.densenet_quality)
                    self.loaded_models['densenet_quality'] = True
                    self.logger.info("âœ… DenseNet Quality Assessment ë¡œë”© ì™„ë£Œ")
                except Exception as e:
                    self.model_loading_errors['densenet_quality'] = str(e)
                    self.logger.warning(f"âš ï¸ DenseNet Quality Assessment ë¡œë”© ì‹¤íŒ¨: {e}")
            
            # 5. Diffusion ì •ì œ ë„¤íŠ¸ì›Œí¬
            if self.warping_config.use_diffusion_warping:
                try:
                    self.diffusion_refiner = DiffusionWarpingRefinement().to(self.device)
                    self._load_model_weights('diffusion_warping', self.diffusion_refiner)
                    self.loaded_models['diffusion_refiner'] = True
                    self.logger.info("âœ… Diffusion Refinement Network ë¡œë”© ì™„ë£Œ")
                except Exception as e:
                    self.model_loading_errors['diffusion_refiner'] = str(e)
                    self.logger.warning(f"âš ï¸ Diffusion Refinement Network ë¡œë”© ì‹¤íŒ¨: {e}")
            
            # 6. ë©€í‹° ìŠ¤ì¼€ì¼ ìœµí•©
            if self.warping_config.multi_scale_fusion:
                try:
                    self.multi_scale_fusion = MultiScaleFeatureFusion().to(self.device)
                    self.loaded_models['multi_scale_fusion'] = True
                    self.logger.info("âœ… Multi-Scale Fusion Module ë¡œë”© ì™„ë£Œ")
                except Exception as e:
                    self.model_loading_errors['multi_scale_fusion'] = str(e)
                    self.logger.warning(f"âš ï¸ Multi-Scale Fusion Module ë¡œë”© ì‹¤íŒ¨: {e}")
            
            success_count = sum(self.loaded_models.values())
            total_models = len(self.loaded_models)
            
            self.logger.info(f"ğŸ¯ AI ëª¨ë¸ ë¡œë”© ì™„ë£Œ: {success_count}/{total_models} ì„±ê³µ")
            
        except Exception as e:
            self.logger.error(f"âŒ AI ëª¨ë¸ ë¡œë”© ì¤‘ ì˜¤ë¥˜: {e}")
    
    def _load_model_weights(self, model_name: str, model: nn.Module):
        """ì‹¤ì œ ëª¨ë¸ ê°€ì¤‘ì¹˜ ë¡œë”©"""
        try:
            if not self.model_loader:
                self.logger.debug(f"ModelLoader ì—†ìŒ - {model_name} ëœë¤ ì´ˆê¸°í™”")
                return
            
            # ModelLoaderë¥¼ í†µí•œ ì²´í¬í¬ì¸íŠ¸ ë¡œë”©
            checkpoint = self.model_loader.load_model(model_name)
            
            if checkpoint:
                # ê°€ì¤‘ì¹˜ ë¡œë”© ì‹œë„
                if isinstance(checkpoint, dict):
                    if 'state_dict' in checkpoint:
                        model.load_state_dict(checkpoint['state_dict'], strict=False)
                    elif 'model' in checkpoint:
                        model.load_state_dict(checkpoint['model'], strict=False)
                    else:
                        model.load_state_dict(checkpoint, strict=False)
                else:
                    model.load_state_dict(checkpoint, strict=False)
                
                self.logger.info(f"âœ… {model_name} ê°€ì¤‘ì¹˜ ë¡œë”© ì„±ê³µ")
            else:
                self.logger.debug(f"âš ï¸ {model_name} ì²´í¬í¬ì¸íŠ¸ ì—†ìŒ - ëœë¤ ì´ˆê¸°í™”")
                
        except Exception as e:
            self.logger.warning(f"âš ï¸ {model_name} ê°€ì¤‘ì¹˜ ë¡œë”© ì‹¤íŒ¨: {e}")
    
    # ==============================================
    # ğŸ”¥ BaseStepMixin v19.1 í‘œì¤€ - _run_ai_inference() ë©”ì„œë“œ
    # ==============================================
    
    async def _run_ai_inference(self, processed_input: Dict[str, Any]) -> Dict[str, Any]:
        """
        ğŸ”¥ ê³ ê¸‰ AI ì•Œê³ ë¦¬ì¦˜ ê¸°ë°˜ ì˜ë¥˜ ì›Œí•‘ ì¶”ë¡ 
        
        Args:
            processed_input: BaseStepMixinì—ì„œ ë³€í™˜ëœ í‘œì¤€ AI ëª¨ë¸ ì…ë ¥
        
        Returns:
            AI ëª¨ë¸ì˜ ì›ì‹œ ì¶œë ¥ ê²°ê³¼
        """
        try:
            self.logger.info(f"ğŸ§  {self.step_name} Enhanced AI ì¶”ë¡  ì‹œì‘")
            
            # 1. ì…ë ¥ ë°ì´í„° ê²€ì¦ ë° ì¤€ë¹„
            person_image = processed_input.get('image')
            cloth_image = processed_input.get('cloth_image')
            fabric_type = processed_input.get('fabric_type', 'cotton')
            warping_method = processed_input.get('warping_method', 'hybrid_multi')
            
            if person_image is None or cloth_image is None:
                raise ValueError("person_imageì™€ cloth_imageê°€ ëª¨ë‘ í•„ìš”í•©ë‹ˆë‹¤")
            
            # 2. í…ì„œ ë³€í™˜
            person_tensor = self._prepare_tensor_input(person_image)
            cloth_tensor = self._prepare_tensor_input(cloth_image)
            
            # 3. ì´ì „ Step ë°ì´í„° í™œìš©
            geometric_data = self._extract_geometric_data(processed_input)
            
            # 4. ë©”ì¸ AI ì¶”ë¡  ì‹¤í–‰
            warping_results = await self._execute_multi_algorithm_warping(
                cloth_tensor, person_tensor, geometric_data, warping_method
            )
            
            # 5. ë¬¼ë¦¬ ì‹œë®¬ë ˆì´ì…˜ ì ìš©
            if self.warping_config.physics_enabled:
                warping_results = self._apply_physics_simulation(warping_results, fabric_type)
            
            # 6. í’ˆì§ˆ í‰ê°€ ë° ì •ì œ
            quality_results = self._evaluate_and_refine_quality(warping_results)
            
            # 7. ìµœì¢… ê²°ê³¼ êµ¬ì„±
            final_result = self._construct_final_result(warping_results, quality_results)
            
            self.logger.info(f"âœ… {self.step_name} Enhanced AI ì¶”ë¡  ì™„ë£Œ")
            return final_result
            
        except Exception as e:
            self.logger.error(f"âŒ {self.step_name} Enhanced AI ì¶”ë¡  ì‹¤íŒ¨: {e}")
            self.logger.debug(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
            return self._create_error_ai_result(str(e))
    
    async def _execute_multi_algorithm_warping(self, cloth_tensor: torch.Tensor, 
                                             person_tensor: torch.Tensor,
                                             geometric_data: Dict[str, Any],
                                             method: str) -> Dict[str, Any]:
        """ë©€í‹° ì•Œê³ ë¦¬ì¦˜ ì›Œí•‘ ì‹¤í–‰"""
        try:
            results = {}
            
            self.logger.info(f"ğŸ”„ ë©€í‹° ì•Œê³ ë¦¬ì¦˜ ì›Œí•‘ ì‹¤í–‰: {method}")
            
            # 1. TPS ê¸°ë°˜ ì›Œí•‘
            if self.tps_network and method in ['hybrid_multi', 'tps_advanced']:
                tps_result = self.tps_network(cloth_tensor, person_tensor)
                results['tps'] = tps_result
                self.logger.info("âœ… TPS ì›Œí•‘ ì™„ë£Œ")
            
            # 2. RAFT Flow ê¸°ë°˜ ì›Œí•‘
            if self.raft_network and method in ['hybrid_multi', 'raft_flow']:
                raft_result = self.raft_network(
                    cloth_tensor, person_tensor, 
                    num_iterations=self.warping_config.raft_iterations
                )
                results['raft'] = raft_result
                self.logger.info("âœ… RAFT Flow ì›Œí•‘ ì™„ë£Œ")
            
            # 3. VGG ê¸°ë°˜ ë§¤ì¹­ ì›Œí•‘
            if self.vgg_matching and method in ['hybrid_multi', 'vgg_matching']:
                vgg_result = self.vgg_matching(cloth_tensor, person_tensor)
                results['vgg'] = vgg_result
                self.logger.info("âœ… VGG ë§¤ì¹­ ì›Œí•‘ ì™„ë£Œ")
            
            # 4. ê²°ê³¼ ìœµí•© (HYBRID_MULTIì¸ ê²½ìš°)
            if method == 'hybrid_multi' and len(results) > 1:
                fused_result = self._fuse_multiple_warping_results(results)
                results['fused'] = fused_result
                self.logger.info("âœ… ë©€í‹° ì•Œê³ ë¦¬ì¦˜ ìœµí•© ì™„ë£Œ")
            
            # 5. ìµœì  ê²°ê³¼ ì„ íƒ
            best_result = self._select_best_warping_result(results)
            
            return {
                'best_warped_cloth': best_result['warped_cloth'],
                'all_results': results,
                'method_used': method,
                'confidence': best_result.get('confidence', torch.tensor([0.8])),
                'warping_metadata': {
                    'algorithms_used': list(results.keys()),
                    'fusion_applied': 'fused' in results,
                    'geometric_data_used': bool(geometric_data)
                }
            }
            
        except Exception as e:
            self.logger.error(f"âŒ ë©€í‹° ì•Œê³ ë¦¬ì¦˜ ì›Œí•‘ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            # í´ë°±: ê°„ë‹¨í•œ ì–´íŒŒì¸ ë³€í˜•
            return self._fallback_simple_warping(cloth_tensor, person_tensor)
    
    def _fuse_multiple_warping_results(self, results: Dict[str, Dict[str, Any]]) -> Dict[str, Any]:
        """ì—¬ëŸ¬ ì›Œí•‘ ê²°ê³¼ ìœµí•©"""
        try:
            warped_cloths = []
            confidences = []
            
            # ê° ê²°ê³¼ì—ì„œ ì›Œí•‘ëœ ì˜ë¥˜ì™€ ì‹ ë¢°ë„ ì¶”ì¶œ
            for method_name, result in results.items():
                if 'warped_cloth' in result:
                    warped_cloths.append(result['warped_cloth'])
                    conf = result.get('confidence', torch.tensor([0.5]))
                    if torch.is_tensor(conf):
                        confidences.append(conf.mean().item())
                    else:
                        confidences.append(float(conf))
            
            if not warped_cloths:
                raise ValueError("ìœµí•©í•  ì›Œí•‘ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤")
            
            # ì‹ ë¢°ë„ ê¸°ë°˜ ê°€ì¤‘ í‰ê· 
            confidences = torch.tensor(confidences, device=warped_cloths[0].device)
            weights = F.softmax(confidences, dim=0)
            
            # ê°€ì¤‘ í‰ê·  ê³„ì‚°
            fused_cloth = torch.zeros_like(warped_cloths[0])
            for i, cloth in enumerate(warped_cloths):
                fused_cloth += cloth * weights[i]
            
            # ë©€í‹° ìŠ¤ì¼€ì¼ ìœµí•© ì ìš© (ì‚¬ìš© ê°€ëŠ¥í•œ ê²½ìš°)
            if self.multi_scale_fusion:
                # ë‹¤ì–‘í•œ ìŠ¤ì¼€ì¼ì˜ íŠ¹ì§• ì¶”ì¶œ
                features = []
                for cloth in warped_cloths:
                    # ê°„ë‹¨í•œ ë‹¤ìš´ìƒ˜í”Œë§ìœ¼ë¡œ ë©€í‹° ìŠ¤ì¼€ì¼ ìƒì„±
                    feat_1 = F.avg_pool2d(cloth, 2)
                    feat_2 = F.avg_pool2d(cloth, 4)
                    feat_3 = F.avg_pool2d(cloth, 8)
                    features.extend([cloth, feat_1, feat_2, feat_3])
                
                # ìœµí•© ì ìš© (ì²« 4ê°œ íŠ¹ì§•ë§Œ ì‚¬ìš©)
                if len(features) >= 4:
                    features = features[:4]
                    fused_features = self.multi_scale_fusion(features)
                    # ì›ë³¸ í¬ê¸°ë¡œ ì—…ìƒ˜í”Œë§
                    fused_cloth = F.interpolate(fused_features, 
                                               size=warped_cloths[0].shape[-2:],
                                               mode='bilinear', align_corners=False)
            
            return {
                'warped_cloth': fused_cloth,
                'confidence': torch.mean(confidences),
                'fusion_weights': weights,
                'num_methods_fused': len(warped_cloths)
            }
            
        except Exception as e:
            self.logger.error(f"âŒ ì›Œí•‘ ê²°ê³¼ ìœµí•© ì‹¤íŒ¨: {e}")
            # í´ë°±: ì²« ë²ˆì§¸ ê²°ê³¼ ë°˜í™˜
            first_result = list(results.values())[0]
            return {
                'warped_cloth': first_result['warped_cloth'],
                'confidence': first_result.get('confidence', torch.tensor([0.5])),
                'fusion_weights': torch.tensor([1.0]),
                'num_methods_fused': 1
            }
    
    def _select_best_warping_result(self, results: Dict[str, Dict[str, Any]]) -> Dict[str, Any]:
        """ìµœì  ì›Œí•‘ ê²°ê³¼ ì„ íƒ"""
        try:
            if not results:
                raise ValueError("ì„ íƒí•  ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤")
            
            # ìœµí•© ê²°ê³¼ê°€ ìˆìœ¼ë©´ ìš°ì„  ì„ íƒ
            if 'fused' in results:
                return results['fused']
            
            # ì‹ ë¢°ë„ ê¸°ë°˜ ì„ íƒ
            best_method = None
            best_confidence = 0.0
            
            for method_name, result in results.items():
                conf = result.get('confidence', torch.tensor([0.0]))
                if torch.is_tensor(conf):
                    conf_value = conf.mean().item()
                else:
                    conf_value = float(conf)
                
                if conf_value > best_confidence:
                    best_confidence = conf_value
                    best_method = method_name
            
            if best_method:
                selected_result = results[best_method].copy()
                selected_result['selected_method'] = best_method
                selected_result['selection_confidence'] = best_confidence
                return selected_result
            
            # í´ë°±: ì²« ë²ˆì§¸ ê²°ê³¼
            first_method = list(results.keys())[0]
            selected_result = results[first_method].copy()
            selected_result['selected_method'] = first_method
            selected_result['selection_confidence'] = 0.5
            return selected_result
            
        except Exception as e:
            self.logger.error(f"âŒ ìµœì  ì›Œí•‘ ê²°ê³¼ ì„ íƒ ì‹¤íŒ¨: {e}")
            # ìµœí›„ í´ë°±
            if results:
                first_result = list(results.values())[0]
                return {
                    'warped_cloth': first_result.get('warped_cloth'),
                    'confidence': torch.tensor([0.3]),
                    'selected_method': 'fallback'
                }
            else:
                raise ValueError("ì‚¬ìš© ê°€ëŠ¥í•œ ì›Œí•‘ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤")
    
    def _apply_physics_simulation(self, warping_results: Dict[str, Any], 
                                 fabric_type: str) -> Dict[str, Any]:
        """ë¬¼ë¦¬ ì‹œë®¬ë ˆì´ì…˜ ì ìš©"""
        try:
            if 'best_warped_cloth' not in warping_results:
                return warping_results
            
            warped_cloth = warping_results['best_warped_cloth']
            
            # ì›ë‹¨ íƒ€ì… ì„¤ì •
            try:
                fabric_enum = FabricType(fabric_type.lower())
            except ValueError:
                fabric_enum = FabricType.COTTON
            
            self.fabric_simulator = PhysicsBasedFabricSimulation(fabric_enum)
            
            # í¬ìŠ¤ í•„ë“œ ìƒì„± (ê°„ë‹¨í•œ êµ¬í˜„)
            force_field = torch.randn_like(warped_cloth) * 0.01
            
            # ì›ë‹¨ ë³€í˜• ì‹œë®¬ë ˆì´ì…˜
            simulated_cloth = self.fabric_simulator.simulate_fabric_deformation(
                warped_cloth, force_field
            )
            
            # ì¤‘ë ¥ íš¨ê³¼ ì ìš©
            simulated_cloth = self.fabric_simulator.apply_gravity_effect(simulated_cloth)
            
            # ê²°ê³¼ ì—…ë°ì´íŠ¸
            warping_results['physics_enhanced_cloth'] = simulated_cloth
            warping_results['best_warped_cloth'] = simulated_cloth
            warping_results['physics_applied'] = True
            warping_results['fabric_type'] = fabric_type
            
            self.logger.info(f"âœ… ë¬¼ë¦¬ ì‹œë®¬ë ˆì´ì…˜ ì ìš© ì™„ë£Œ (ì›ë‹¨: {fabric_type})")
            
            return warping_results
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ ë¬¼ë¦¬ ì‹œë®¬ë ˆì´ì…˜ ì ìš© ì‹¤íŒ¨: {e}")
            warping_results['physics_applied'] = False
            return warping_results
    
    def _evaluate_and_refine_quality(self, warping_results: Dict[str, Any]) -> Dict[str, Any]:
        """í’ˆì§ˆ í‰ê°€ ë° ì •ì œ"""
        try:
            quality_results = {}
            
            if 'best_warped_cloth' not in warping_results:
                return quality_results
            
            warped_cloth = warping_results['best_warped_cloth']
            
            # DenseNet í’ˆì§ˆ í‰ê°€
            if self.densenet_quality:
                # ì›ë³¸ ì˜ë¥˜ê°€ í•„ìš”í•˜ë¯€ë¡œ ë”ë¯¸ ë°ì´í„° ì‚¬ìš©
                dummy_original = torch.randn_like(warped_cloth)
                
                quality_assessment = self.densenet_quality(dummy_original, warped_cloth)
                
                quality_results['overall_quality'] = quality_assessment['overall_quality']
                quality_results['texture_preservation'] = quality_assessment['texture_preservation']
                quality_results['shape_consistency'] = quality_assessment['shape_consistency']
                quality_results['edge_sharpness'] = quality_assessment['edge_sharpness']
                
                self.logger.info("âœ… DenseNet í’ˆì§ˆ í‰ê°€ ì™„ë£Œ")
            
            # Diffusion ê¸°ë°˜ ì •ì œ
            if self.diffusion_refiner and self.warping_config.quality_level == "ultra":
                try:
                    refined_cloth = self.diffusion_refiner.denoise_steps(
                        warped_cloth, warped_cloth  # ë”ë¯¸ ì›ë³¸
                    )
                    
                    quality_results['refined_cloth'] = refined_cloth
                    warping_results['best_warped_cloth'] = refined_cloth
                    quality_results['diffusion_refined'] = True
                    
                    self.logger.info("âœ… Diffusion ì •ì œ ì™„ë£Œ")
                    
                except Exception as e:
                    self.logger.warning(f"âš ï¸ Diffusion ì •ì œ ì‹¤íŒ¨: {e}")
                    quality_results['diffusion_refined'] = False
            
            # ì „ì²´ í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°
            if quality_results:
                overall_scores = []
                for key, value in quality_results.items():
                    if 'quality' in key or 'preservation' in key or 'consistency' in key:
                        if torch.is_tensor(value):
                            overall_scores.append(value.mean().item())
                        elif isinstance(value, (int, float)):
                            overall_scores.append(float(value))
                
                if overall_scores:
                    quality_results['computed_overall_quality'] = np.mean(overall_scores)
                else:
                    quality_results['computed_overall_quality'] = 0.7
            else:
                quality_results['computed_overall_quality'] = 0.7
            
            return quality_results
            
        except Exception as e:
            self.logger.error(f"âŒ í’ˆì§ˆ í‰ê°€ ë° ì •ì œ ì‹¤íŒ¨: {e}")
            return {
                'computed_overall_quality': 0.5,
                'error': str(e)
            }
    
    def _construct_final_result(self, warping_results: Dict[str, Any], 
                               quality_results: Dict[str, Any]) -> Dict[str, Any]:
        """ìµœì¢… ê²°ê³¼ êµ¬ì„±"""
        try:
            warped_cloth = warping_results.get('best_warped_cloth')
            
            if warped_cloth is None:
                raise ValueError("ì›Œí•‘ëœ ì˜ë¥˜ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤")
            
            # ê¸°ë³¸ ê²°ê³¼ êµ¬ì„±
            final_result = {
                'warped_cloth': warped_cloth,
                'warped_cloth_tensor': warped_cloth,
                'ai_success': True,
                'enhanced_ai_inference': True,
                
                # ì‹ ë¢°ë„ ë° í’ˆì§ˆ
                'confidence': warping_results.get('confidence', torch.tensor([0.8])).mean().item(),
                'quality_score': quality_results.get('computed_overall_quality', 0.7),
                'overall_quality': quality_results.get('computed_overall_quality', 0.7),
                'quality_grade': self._calculate_quality_grade(
                    quality_results.get('computed_overall_quality', 0.7)
                ),
                
                # ì•Œê³ ë¦¬ì¦˜ ë©”íƒ€ë°ì´í„°
                'algorithms_used': warping_results.get('warping_metadata', {}).get('algorithms_used', []),
                'method_used': warping_results.get('method_used', 'unknown'),
                'fusion_applied': warping_results.get('warping_metadata', {}).get('fusion_applied', False),
                
                # ë¬¼ë¦¬ ì‹œë®¬ë ˆì´ì…˜ ì •ë³´
                'physics_applied': warping_results.get('physics_applied', False),
                'fabric_type': warping_results.get('fabric_type', 'cotton'),
                
                # í’ˆì§ˆ ìƒì„¸ ì •ë³´
                'quality_analysis': {
                    'texture_preservation': self._tensor_to_float(quality_results.get('texture_preservation', 0.7)),
                    'shape_consistency': self._tensor_to_float(quality_results.get('shape_consistency', 0.7)),
                    'edge_sharpness': self._tensor_to_float(quality_results.get('edge_sharpness', 0.7)),
                    'overall_quality': quality_results.get('computed_overall_quality', 0.7)
                },
                
                # ì •ì œ ì •ë³´
                'diffusion_refined': quality_results.get('diffusion_refined', False),
                
                # ë¡œë”©ëœ ëª¨ë¸ ì •ë³´
                'models_loaded': self.loaded_models.copy(),
                'model_loading_errors': self.model_loading_errors.copy(),
                
                # AI ë©”íƒ€ë°ì´í„°
                'ai_metadata': {
                    'device': self.device,
                    'precision': self.warping_config.precision,
                    'input_size': self.warping_config.input_size,
                    'warping_method': self.warping_config.warping_method.value,
                    'num_algorithms_used': len(warping_results.get('warping_metadata', {}).get('algorithms_used', [])),
                    'models_successfully_loaded': sum(self.loaded_models.values()),
                    'total_models_attempted': len(self.loaded_models)
                }
            }
            
            self.logger.info(f"âœ… ìµœì¢… ê²°ê³¼ êµ¬ì„± ì™„ë£Œ - í’ˆì§ˆ: {final_result['quality_grade']}")
            
            return final_result
            
        except Exception as e:
            self.logger.error(f"âŒ ìµœì¢… ê²°ê³¼ êµ¬ì„± ì‹¤íŒ¨: {e}")
            return self._create_error_ai_result(str(e))
    
    # ==============================================
    # ğŸ”§ ì§€ì› ë©”ì„œë“œë“¤
    # ==============================================
    
    def _prepare_tensor_input(self, image_input: Any) -> torch.Tensor:
        """ì´ë¯¸ì§€ ì…ë ¥ì„ í…ì„œë¡œ ë³€í™˜"""
        try:
            if image_input is None:
                size = self.warping_config.input_size
                return torch.randn(1, 3, size[1], size[0]).to(self.device)
            
            # ì´ë¯¸ í…ì„œì¸ ê²½ìš°
            if TORCH_AVAILABLE and torch.is_tensor(image_input):
                tensor = image_input.to(self.device)
                if len(tensor.shape) == 3:
                    tensor = tensor.unsqueeze(0)
                return tensor
            
            # PIL Imageì¸ ê²½ìš°
            if PIL_AVAILABLE and isinstance(image_input, Image.Image):
                array = np.array(image_input)
                if len(array.shape) == 3:
                    array = np.transpose(array, (2, 0, 1))
                tensor = torch.from_numpy(array).float().unsqueeze(0) / 255.0
                return tensor.to(self.device)
            
            # NumPy ë°°ì—´ì¸ ê²½ìš°
            if NUMPY_AVAILABLE and isinstance(image_input, np.ndarray):
                if len(image_input.shape) == 3:
                    array = np.transpose(image_input, (2, 0, 1))
                else:
                    array = image_input
                
                if array.dtype != np.float32:
                    array = array.astype(np.float32)
                
                if array.max() > 1.0:
                    array = array / 255.0
                
                tensor = torch.from_numpy(array).unsqueeze(0)
                return tensor.to(self.device)
            
            # ê¸°ë³¸ ë”ë¯¸ í…ì„œ
            size = self.warping_config.input_size
            return torch.randn(1, 3, size[1], size[0]).to(self.device)
            
        except Exception as e:
            self.logger.warning(f"í…ì„œ ë³€í™˜ ì‹¤íŒ¨: {e}")
            size = self.warping_config.input_size
            return torch.randn(1, 3, size[1], size[0]).to(self.device)
    
    def _extract_geometric_data(self, processed_input: Dict[str, Any]) -> Dict[str, Any]:
        """ì´ì „ Stepì—ì„œ ê¸°í•˜í•™ì  ë°ì´í„° ì¶”ì¶œ"""
        geometric_data = {}
        
        try:
            # Step 4 (Geometric Matching)ì—ì„œ ë°ì´í„° ì¶”ì¶œ
            step_04_data = processed_input.get('from_step_04', {})
            if step_04_data:
                geometric_data['transformation_matrix'] = step_04_data.get('transformation_matrix')
                geometric_data['warped_clothing'] = step_04_data.get('warped_clothing')
                geometric_data['flow_field'] = step_04_data.get('flow_field')
                geometric_data['matching_score'] = step_04_data.get('matching_score')
                
                self.logger.debug("âœ… Step 4 ê¸°í•˜í•™ì  ë°ì´í„° ì¶”ì¶œ ì™„ë£Œ")
            
            # Step 2 (Pose Estimation)ì—ì„œ í¬ì¦ˆ ë°ì´í„° ì¶”ì¶œ
            step_02_data = processed_input.get('from_step_02', {})
            if step_02_data:
                geometric_data['keypoints'] = step_02_data.get('keypoints_18')
                geometric_data['pose_skeleton'] = step_02_data.get('pose_skeleton')
                
                self.logger.debug("âœ… Step 2 í¬ì¦ˆ ë°ì´í„° ì¶”ì¶œ ì™„ë£Œ")
            
            # Step 3 (Cloth Segmentation)ì—ì„œ ë§ˆìŠ¤í¬ ë°ì´í„° ì¶”ì¶œ
            step_03_data = processed_input.get('from_step_03', {})
            if step_03_data:
                geometric_data['cloth_mask'] = step_03_data.get('cloth_mask')
                geometric_data['segmented_clothing'] = step_03_data.get('segmented_clothing')
                
                self.logger.debug("âœ… Step 3 ì„¸ê·¸ë©˜í…Œì´ì…˜ ë°ì´í„° ì¶”ì¶œ ì™„ë£Œ")
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ ê¸°í•˜í•™ì  ë°ì´í„° ì¶”ì¶œ ì‹¤íŒ¨: {e}")
        
        return geometric_data
    
    def _fallback_simple_warping(self, cloth_tensor: torch.Tensor, 
                                person_tensor: torch.Tensor) -> Dict[str, Any]:
        """í´ë°± ê°„ë‹¨í•œ ì›Œí•‘"""
        try:
            self.logger.info("ğŸ”„ í´ë°± ê°„ë‹¨í•œ ì›Œí•‘ ì‹¤í–‰")
            
            # ê°„ë‹¨í•œ ì–´íŒŒì¸ ë³€í˜•
            batch_size, channels, height, width = cloth_tensor.shape
            
            # ì‘ì€ ë³€í˜• ë§¤íŠ¸ë¦­ìŠ¤
            theta = torch.tensor([
                [1.02, 0.01, 0.01],
                [0.01, 1.01, 0.01]
            ]).unsqueeze(0).repeat(batch_size, 1, 1).to(cloth_tensor.device)
            
            grid = F.affine_grid(theta, cloth_tensor.size(), align_corners=False)
            transformed = F.grid_sample(cloth_tensor, grid, align_corners=False)
            
            return {
                'best_warped_cloth': transformed,
                'confidence': torch.tensor([0.5]),
                'method_used': 'fallback_affine',
                'warping_metadata': {
                    'algorithms_used': ['simple_affine'],
                    'fusion_applied': False
                }
            }
            
        except Exception as e:
            self.logger.error(f"âŒ í´ë°± ì›Œí•‘ ì‹¤íŒ¨: {e}")
            return {
                'best_warped_cloth': cloth_tensor,
                'confidence': torch.tensor([0.3]),
                'method_used': 'identity',
                'error': str(e)
            }
    
    def _tensor_to_float(self, value: Any) -> float:
        """í…ì„œë¥¼ floatë¡œ ì•ˆì „í•˜ê²Œ ë³€í™˜"""
        try:
            if torch.is_tensor(value):
                return value.mean().item()
            elif isinstance(value, (int, float)):
                return float(value)
            else:
                return 0.7
        except:
            return 0.7
    
    def _calculate_quality_grade(self, score: float) -> str:
        """í’ˆì§ˆ ì ìˆ˜ë¥¼ ë“±ê¸‰ìœ¼ë¡œ ë³€í™˜"""
        if score >= 0.95:
            return "A+"
        elif score >= 0.9:
            return "A"
        elif score >= 0.8:
            return "B+"
        elif score >= 0.7:
            return "B"
        elif score >= 0.6:
            return "C+"
        elif score >= 0.5:
            return "C"
        else:
            return "D"
    
    def _create_error_ai_result(self, error_message: str) -> Dict[str, Any]:
        """ì—ëŸ¬ AI ê²°ê³¼ ìƒì„±"""
        size = self.warping_config.input_size
        dummy_tensor = torch.zeros(1, 3, size[1], size[0]).to(self.device)
        
        return {
            'warped_cloth': dummy_tensor,
            'warped_cloth_tensor': dummy_tensor,
            'ai_success': False,
            'enhanced_ai_inference': False,
            'error': error_message,
            'confidence': 0.0,
            'quality_score': 0.0,
            'overall_quality': 0.0,
            'quality_grade': 'F',
            'physics_applied': False,
            'models_loaded': self.loaded_models.copy(),
            'ai_metadata': {
                'device': self.device,
                'error': error_message
            }
        }
    
    # ==============================================
    # ğŸ”§ ì‹œìŠ¤í…œ ê´€ë¦¬ ë©”ì„œë“œë“¤
    # ==============================================
    
    def get_system_info(self) -> Dict[str, Any]:
        """ì‹œìŠ¤í…œ ì •ë³´ ë°˜í™˜"""
        try:
            return {
                'step_info': {
                    'step_name': self.step_name,
                    'step_id': self.step_id,
                    'version': '15.0 Enhanced AI Algorithms',
                    'is_initialized': getattr(self, 'is_initialized', False),
                    'device': self.device
                },
                'ai_algorithms': {
                    'tps_network': self.loaded_models.get('tps_network', False),
                    'raft_flow': self.loaded_models.get('raft_flow', False),
                    'vgg_matching': self.loaded_models.get('vgg_matching', False),
                    'densenet_quality': self.loaded_models.get('densenet_quality', False),
                    'diffusion_refiner': self.loaded_models.get('diffusion_refiner', False),
                    'multi_scale_fusion': self.loaded_models.get('multi_scale_fusion', False)
                },
                'configuration': {
                    'warping_method': self.warping_config.warping_method.value,
                    'input_size': self.warping_config.input_size,
                    'num_control_points': self.warping_config.num_control_points,
                    'quality_level': self.warping_config.quality_level,
                    'physics_enabled': self.warping_config.physics_enabled,
                    'multi_scale_fusion': self.warping_config.multi_scale_fusion
                },
                'model_status': {
                    'total_models': len(ENHANCED_CLOTH_WARPING_MODELS),
                    'loaded_models': self.loaded_models.copy(),
                    'loading_errors': self.model_loading_errors.copy(),
                    'success_rate': sum(self.loaded_models.values()) / len(self.loaded_models) if self.loaded_models else 0
                },
                'real_model_files': ENHANCED_CLOTH_WARPING_MODELS
            }
        except Exception as e:
            self.logger.error(f"ì‹œìŠ¤í…œ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {"error": f"ì‹œìŠ¤í…œ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {e}"}
    
    def cleanup_resources(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        try:
            # AI ëª¨ë¸ë“¤ ì •ë¦¬
            models_to_cleanup = [
                'tps_network', 'raft_network', 'vgg_matching',
                'densenet_quality', 'diffusion_refiner', 'multi_scale_fusion'
            ]
            
            for model_name in models_to_cleanup:
                if hasattr(self, model_name):
                    model = getattr(self, model_name)
                    if model is not None:
                        del model
                        setattr(self, model_name, None)
            
            # ìºì‹œ ì •ë¦¬
            if hasattr(self, 'prediction_cache'):
                self.prediction_cache.clear()
            
            # ìƒíƒœ ì •ë¦¬
            self.loaded_models.clear()
            self.model_loading_errors.clear()
            
            # ë©”ëª¨ë¦¬ ì •ë¦¬
            if TORCH_AVAILABLE:
                if self.device == "mps" and MPS_AVAILABLE:
                    if hasattr(torch.mps, 'empty_cache'):
                        torch.mps.empty_cache()
                elif self.device == "cuda" and torch.cuda.is_available():
                    torch.cuda.empty_cache()
            
            gc.collect()
            
            self.logger.info("âœ… Enhanced ClothWarpingStep ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì™„ë£Œ")
            
        except Exception as e:
            self.logger.warning(f"ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì‹¤íŒ¨: {e}")
    
    def __del__(self):
        try:
            if hasattr(self, 'cleanup_resources'):
                self.cleanup_resources()
        except Exception:
            pass

# ==============================================
# ğŸ”¥ íŒ©í† ë¦¬ í•¨ìˆ˜ë“¤
# ==============================================

def create_enhanced_cloth_warping_step(
    device: str = "auto",
    quality_level: str = "ultra",
    warping_method: str = "hybrid_multi",
    **kwargs
) -> ClothWarpingStep:
    """ê°•í™”ëœ ClothWarpingStep ìƒì„±"""
    try:
        # ë””ë°”ì´ìŠ¤ í•´ê²°
        if device == "auto":
            if TORCH_AVAILABLE:
                if MPS_AVAILABLE:
                    device = "mps"
                elif torch.cuda.is_available():
                    device = "cuda"
                else:
                    device = "cpu"
            else:
                device = "cpu"
        
        # ì„¤ì • êµ¬ì„±
        config = {
            'device': device,
            'quality_level': quality_level,
            'warping_method': WarpingMethod(warping_method),
            'use_realvis_xl': True,
            'use_vgg19_warping': True,
            'use_vgg16_warping': True,
            'use_densenet': True,
            'use_diffusion_warping': quality_level == "ultra",
            'use_tps_network': True,
            'use_raft_flow': True,
            'physics_enabled': True,
            'multi_scale_fusion': True
        }
        config.update(kwargs)
        
        # Step ìƒì„±
        step = ClothWarpingStep(**config)
        
        # ì´ˆê¸°í™”
        if not step.is_initialized:
            step.initialize()
        
        logger.info(f"âœ… Enhanced ClothWarpingStep ìƒì„± ì™„ë£Œ - {device}")
        return step
        
    except Exception as e:
        logger.error(f"âŒ Enhanced ClothWarpingStep ìƒì„± ì‹¤íŒ¨: {e}")
        raise RuntimeError(f"Enhanced ClothWarpingStep ìƒì„± ì‹¤íŒ¨: {e}")

# ==============================================
# ğŸ”¥ í…ŒìŠ¤íŠ¸ í•¨ìˆ˜
# ==============================================

async def test_enhanced_cloth_warping():
    """Enhanced ClothWarpingStep í…ŒìŠ¤íŠ¸"""
    print("ğŸ§ª Enhanced ClothWarpingStep v15.0 í…ŒìŠ¤íŠ¸ ì‹œì‘")
    
    try:
        # Step ìƒì„±
        step = create_enhanced_cloth_warping_step(
            device="auto",
            quality_level="ultra",
            warping_method="hybrid_multi"
        )
        
        # ì‹œìŠ¤í…œ ì •ë³´ í™•ì¸
        system_info = step.get_system_info()
        print(f"âœ… ì‹œìŠ¤í…œ ì •ë³´: {system_info['step_info']['step_name']} v{system_info['step_info']['version']}")
        print(f"âœ… ë””ë°”ì´ìŠ¤: {system_info['step_info']['device']}")
        print(f"âœ… AI ì•Œê³ ë¦¬ì¦˜: {list(system_info['ai_algorithms'].keys())}")
        print(f"âœ… ëª¨ë¸ ì„±ê³µë¥ : {system_info['model_status']['success_rate']:.1%}")
        
        # ë”ë¯¸ ë°ì´í„°ë¡œ í…ŒìŠ¤íŠ¸
        dummy_input = {
            'image': np.random.randint(0, 255, (512, 512, 3), dtype=np.uint8),
            'cloth_image': np.random.randint(0, 255, (512, 512, 3), dtype=np.uint8),
            'fabric_type': 'cotton',
            'warping_method': 'hybrid_multi'
        }
        
        # AI ì¶”ë¡  í…ŒìŠ¤íŠ¸
        result = await step._run_ai_inference(dummy_input)
        
        print(f"âœ… AI ì¶”ë¡  ì„±ê³µ: {result['ai_success']}")
        print(f"âœ… í’ˆì§ˆ ë“±ê¸‰: {result['quality_grade']}")
        print(f"âœ… ì‚¬ìš©ëœ ì•Œê³ ë¦¬ì¦˜: {result.get('algorithms_used', [])}")
        print(f"âœ… ë¬¼ë¦¬ ì‹œë®¬ë ˆì´ì…˜: {result['physics_applied']}")
        
        print("âœ… Enhanced ClothWarpingStep v15.0 í…ŒìŠ¤íŠ¸ ì„±ê³µ!")
        return True
        
    except Exception as e:
        print(f"âŒ Enhanced ClothWarpingStep í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        return False

# ==============================================
# ğŸ”¥ Export
# ==============================================

__all__ = [
    'ClothWarpingStep',
    'create_enhanced_cloth_warping_step',
    'test_enhanced_cloth_warping',
    
    # AI ì•Œê³ ë¦¬ì¦˜ í´ë˜ìŠ¤ë“¤
    'AdvancedTPSWarpingNetwork',
    'RAFTFlowWarpingNetwork', 
    'VGGClothBodyMatchingNetwork',
    'DenseNetQualityAssessment',
    'DiffusionWarpingRefinement',
    'MultiScaleFeatureFusion',
    'PhysicsBasedFabricSimulation',
    
    # ì„¤ì • í´ë˜ìŠ¤ë“¤
    'ClothWarpingConfig',
    'WarpingMethod',
    'FabricType',
    
    # ìƒìˆ˜ë“¤
    'ENHANCED_CLOTH_WARPING_MODELS'
]

# ==============================================
# ğŸ”¥ ëª¨ë“ˆ ë¡œë“œ ì™„ë£Œ
# ==============================================

logger.info("=" * 100)
logger.info("ğŸ¯ Enhanced ClothWarpingStep v15.0 - ê³ ê¸‰ AI ì•Œê³ ë¦¬ì¦˜ êµ¬í˜„")
logger.info("=" * 100)
logger.info("âœ… BaseStepMixin v19.1 ì™„ì „ í˜¸í™˜")
logger.info("âœ… 7ê°œ ê³ ê¸‰ AI ì•Œê³ ë¦¬ì¦˜ í†µí•©:")
logger.info("   ğŸ§  TPS (Thin Plate Spline) Warping Network")
logger.info("   ğŸŒŠ RAFT Optical Flow Estimation")
logger.info("   ğŸ¯ VGG-based Cloth-Body Matching")
logger.info("   âš¡ DenseNet Quality Assessment")
logger.info("   ğŸ¨ Diffusion-based Warping Refinement")
logger.info("   ğŸ”— Multi-Scale Feature Fusion")
logger.info("   ğŸ§ª Physics-based Fabric Simulation")
logger.info("âœ… ì‹¤ì œ AI ëª¨ë¸ íŒŒì¼ í™œìš©:")
for model_name, model_info in ENHANCED_CLOTH_WARPING_MODELS.items():
    size_info = f"{model_info['size_mb']:.1f}MB" if model_info['size_mb'] < 1000 else f"{model_info['size_mb']/1000:.1f}GB"
    logger.info(f"   - {model_info['filename']} ({size_info})")
logger.info("âœ… ë©€í‹° ì•Œê³ ë¦¬ì¦˜ ìœµí•© ë° ìµœì  ê²°ê³¼ ì„ íƒ")
logger.info("âœ… ë¬¼ë¦¬ ê¸°ë°˜ ì›ë‹¨ ì‹œë®¬ë ˆì´ì…˜ (Cotton, Silk, Denim, Wool, Spandex)")
logger.info("âœ… í’ˆì§ˆ í‰ê°€ ë° Diffusion ê¸°ë°˜ ì •ì œ")
logger.info("=" * 100)
logger.info("ğŸ‰ Enhanced ClothWarpingStep v15.0 ì¤€ë¹„ ì™„ë£Œ!")
logger.info("ğŸ’¡ ì‹¤ì œ ì˜ë¥˜ë¥¼ ì¸ì²´ í•ì— ë§ê²Œ ì •ë°€í•˜ê²Œ ì›Œí•‘í•©ë‹ˆë‹¤!")
logger.info("=" * 100)

if __name__ == "__main__":
    import asyncio
    print("ğŸ§ª Enhanced ClothWarpingStep v15.0 í…ŒìŠ¤íŠ¸ ì‹¤í–‰")
    asyncio.run(test_enhanced_cloth_warping())