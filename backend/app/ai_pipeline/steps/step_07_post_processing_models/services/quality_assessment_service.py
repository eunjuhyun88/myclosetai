"""
Quality Assessment Service
ì´ë¯¸ì§€ í’ˆì§ˆì„ í‰ê°€í•˜ê³  ë¶„ì„í•˜ëŠ” ì„œë¹„ìŠ¤ í´ë˜ìŠ¤
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
from typing import Dict, Any, List, Optional, Union, Tuple
import numpy as np
from PIL import Image
import cv2
import logging
import time
from dataclasses import dataclass

# ë¡œê¹… ì„¤ì •
import logging

logger = logging.getLogger(__name__)

@dataclass
class QualityMetrics:
    """í’ˆì§ˆ ë©”íŠ¸ë¦­ ê²°ê³¼ë¥¼ ì €ì¥í•˜ëŠ” ë°ì´í„° í´ë˜ìŠ¤"""
    psnr: float
    ssim: float
    perceptual_score: float
    sharpness: float
    noise_level: float
    overall_score: float
    processing_time: float

class QualityAssessmentService:
    """
    ì´ë¯¸ì§€ í’ˆì§ˆì„ í‰ê°€í•˜ê³  ë¶„ì„í•˜ëŠ” ì„œë¹„ìŠ¤ í´ë˜ìŠ¤
    """
    
    def __init__(self, device: Optional[torch.device] = None):
        """
        Args:
            device: ì‚¬ìš©í•  ë””ë°”ì´ìŠ¤
        """
        self.device = device or torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        
        # í’ˆì§ˆ í‰ê°€ ì„¤ì •
        self.quality_config = {
            'psnr_threshold': 30.0,
            'ssim_threshold': 0.8,
            'perceptual_threshold': 0.7,
            'sharpness_threshold': 0.6,
            'noise_threshold': 0.3
        }
        
        # í’ˆì§ˆ ë©”íŠ¸ë¦­ ê°€ì¤‘ì¹˜
        self.metric_weights = {
            'psnr': 0.25,
            'ssim': 0.25,
            'perceptual': 0.2,
            'sharpness': 0.15,
            'noise': 0.15
        }
        
        logger.info(f"QualityAssessmentService initialized on device: {self.device}")
    
    def calculate_psnr(self, img1: torch.Tensor, img2: torch.Tensor) -> float:
        """
        PSNR (Peak Signal-to-Noise Ratio) ê³„ì‚°
        
        Args:
            img1: ì²« ë²ˆì§¸ ì´ë¯¸ì§€ í…ì„œ
            img2: ë‘ ë²ˆì§¸ ì´ë¯¸ì§€ í…ì„œ
            
        Returns:
            PSNR ê°’
        """
        try:
            # ì´ë¯¸ì§€ë¥¼ 0-1 ë²”ìœ„ë¡œ ì •ê·œí™”
            img1 = img1.clamp(0, 1)
            img2 = img2.clamp(0, 1)
            
            # MSE ê³„ì‚°
            mse = F.mse_loss(img1, img2)
            
            if mse == 0:
                return float('inf')
            
            # PSNR ê³„ì‚° (ìµœëŒ€ê°’ì„ 1ë¡œ ê°€ì •)
            psnr = 20 * torch.log10(1.0 / torch.sqrt(mse))
            
            return psnr.item()
        except Exception as e:
            logger.error(f"PSNR ê³„ì‚° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return 0.0
    
    def calculate_ssim(self, img1: torch.Tensor, img2: torch.Tensor, window_size: int = 11) -> float:
        """
        SSIM (Structural Similarity Index) ê³„ì‚°
        
        Args:
            img1: ì²« ë²ˆì§¸ ì´ë¯¸ì§€ í…ì„œ
            img2: ë‘ ë²ˆì§¸ ì´ë¯¸ì§€ í…ì„œ
            window_size: SSIM ê³„ì‚°ì„ ìœ„í•œ ìœˆë„ìš° í¬ê¸°
            
        Returns:
            SSIM ê°’
        """
        try:
            # ì´ë¯¸ì§€ë¥¼ 0-1 ë²”ìœ„ë¡œ ì •ê·œí™”
            img1 = img1.clamp(0, 1)
            img2 = img2.clamp(0, 1)
            
            # ë‹¨ì¼ ì±„ë„ë¡œ ë³€í™˜ (ê·¸ë ˆì´ìŠ¤ì¼€ì¼)
            if img1.dim() == 3 and img1.size(0) == 3:
                img1 = 0.299 * img1[0] + 0.587 * img1[1] + 0.114 * img1[2]
            if img2.dim() == 3 and img2.size(0) == 3:
                img2 = 0.299 * img2[0] + 0.587 * img2[1] + 0.114 * img2[2]
            
            # ë°°ì¹˜ ì°¨ì› ì¶”ê°€
            img1 = img1.unsqueeze(0).unsqueeze(0)
            img2 = img2.unsqueeze(0).unsqueeze(0)
            
            # SSIM ê³„ì‚°
            ssim = self._ssim(img1, img2, window_size)
            
            return ssim.item()
        except Exception as e:
            logger.error(f"SSIM ê³„ì‚° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return 0.0
    
    def _ssim(self, img1: torch.Tensor, img2: torch.Tensor, window_size: int) -> torch.Tensor:
        """SSIM ê³„ì‚°ì˜ ë‚´ë¶€ êµ¬í˜„"""
        C1 = 0.01 ** 2
        C2 = 0.03 ** 2
        
        # ê°€ìš°ì‹œì•ˆ ìœˆë„ìš° ìƒì„±
        window = self._create_window(window_size, img1.size(1)).to(img1.device)
        
        mu1 = F.conv2d(img1, window, padding=window_size//2, groups=img1.size(1))
        mu2 = F.conv2d(img2, window, padding=window_size//2, groups=img2.size(1))
        
        mu1_sq = mu1.pow(2)
        mu2_sq = mu2.pow(2)
        mu1_mu2 = mu1 * mu2
        
        sigma1_sq = F.conv2d(img1 * img1, window, padding=window_size//2, groups=img1.size(1)) - mu1_sq
        sigma2_sq = F.conv2d(img2 * img2, window, padding=window_size//2, groups=img2.size(1)) - mu2_sq
        sigma12 = F.conv2d(img1 * img2, window, padding=window_size//2, groups=img1.size(1)) - mu1_mu2
        
        ssim_map = ((2 * mu1_mu2 + C1) * (2 * sigma12 + C2)) / ((mu1_sq + mu2_sq + C1) * (sigma1_sq + sigma2_sq + C2))
        
        return ssim_map.mean()
    
    def _create_window(self, window_size: int, channels: int) -> torch.Tensor:
        """ê°€ìš°ì‹œì•ˆ ìœˆë„ìš° ìƒì„±"""
        def _gaussian(window_size, sigma):
            gauss = torch.Tensor([np.exp(-(x - window_size//2)**2/float(2*sigma**2)) for x in range(window_size)])
            return gauss/gauss.sum()
        
        _1D_window = _gaussian(window_size, 1.5).unsqueeze(1)
        _2D_window = _1D_window.mm(_1D_window.t()).float().unsqueeze(0).unsqueeze(0)
        window = _2D_window.expand(channels, 1, window_size, window_size).contiguous()
        return window
    
    def calculate_perceptual_score(self, img1: torch.Tensor, img2: torch.Tensor) -> float:
        """
        ì§€ê°ì  í’ˆì§ˆ ì ìˆ˜ ê³„ì‚° (ê°„ë‹¨í•œ êµ¬í˜„)
        
        Args:
            img1: ì²« ë²ˆì§¸ ì´ë¯¸ì§€ í…ì„œ
            img2: ë‘ ë²ˆì§¸ ì´ë¯¸ì§€ í…ì„œ
            
        Returns:
            ì§€ê°ì  í’ˆì§ˆ ì ìˆ˜
        """
        try:
            # ì´ë¯¸ì§€ë¥¼ 0-1 ë²”ìœ„ë¡œ ì •ê·œí™”
            img1 = img1.clamp(0, 1)
            img2 = img2.clamp(0, 1)
            
            # ìƒ‰ìƒ ì°¨ì´ ê³„ì‚°
            color_diff = torch.mean(torch.abs(img1 - img2))
            
            # ì§€ê°ì  ì ìˆ˜ (ì°¨ì´ê°€ ì ì„ìˆ˜ë¡ ë†’ì€ ì ìˆ˜)
            perceptual_score = 1.0 - color_diff.item()
            
            return max(0.0, perceptual_score)
        except Exception as e:
            logger.error(f"ì§€ê°ì  í’ˆì§ˆ ì ìˆ˜ ê³„ì‚° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return 0.0
    
    def calculate_sharpness(self, img: torch.Tensor) -> float:
        """
        ì´ë¯¸ì§€ ì„ ëª…ë„ ê³„ì‚°
        
        Args:
            img: ì´ë¯¸ì§€ í…ì„œ
            
        Returns:
            ì„ ëª…ë„ ì ìˆ˜
        """
        try:
            # ì´ë¯¸ì§€ë¥¼ 0-1 ë²”ìœ„ë¡œ ì •ê·œí™”
            img = img.clamp(0, 1)
            
            # ë‹¨ì¼ ì±„ë„ë¡œ ë³€í™˜
            if img.dim() == 3 and img.size(0) == 3:
                img = 0.299 * img[0] + 0.587 * img[1] + 0.114 * img[2]
            
            # ë¼í”Œë¼ì‹œì•ˆ í•„í„°ë¥¼ ì‚¬ìš©í•œ ì„ ëª…ë„ ê³„ì‚°
            laplacian_kernel = torch.tensor([
                [0, -1, 0],
                [-1, 4, -1],
                [0, -1, 0]
            ], dtype=torch.float32, device=img.device).unsqueeze(0).unsqueeze(0)
            
            # ì»¨ë³¼ë£¨ì…˜ ì ìš©
            sharpness_map = F.conv2d(img.unsqueeze(0).unsqueeze(0), laplacian_kernel, padding=1)
            
            # ì„ ëª…ë„ ì ìˆ˜ ê³„ì‚°
            sharpness_score = torch.mean(torch.abs(sharpness_map)).item()
            
            # 0-1 ë²”ìœ„ë¡œ ì •ê·œí™”
            sharpness_score = min(1.0, sharpness_score / 2.0)
            
            return sharpness_score
        except Exception as e:
            logger.error(f"ì„ ëª…ë„ ê³„ì‚° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return 0.0
    
    def calculate_noise_level(self, img: torch.Tensor) -> float:
        """
        ì´ë¯¸ì§€ ë…¸ì´ì¦ˆ ë ˆë²¨ ê³„ì‚°
        
        Args:
            img: ì´ë¯¸ì§€ í…ì„œ
            
        Returns:
            ë…¸ì´ì¦ˆ ë ˆë²¨ ì ìˆ˜ (ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ)
        """
        try:
            # ì´ë¯¸ì§€ë¥¼ 0-1 ë²”ìœ„ë¡œ ì •ê·œí™”
            img = img.clamp(0, 1)
            
            # ë‹¨ì¼ ì±„ë„ë¡œ ë³€í™˜
            if img.dim() == 3 and img.size(0) == 3:
                img = 0.299 * img[0] + 0.587 * img[1] + 0.114 * img[2]
            
            # ê°€ìš°ì‹œì•ˆ ë¸”ëŸ¬ë¥¼ ì‚¬ìš©í•œ ë…¸ì´ì¦ˆ ì¶”ì •
            blurred = F.avg_pool2d(img.unsqueeze(0).unsqueeze(0), kernel_size=3, stride=1, padding=1)
            
            # ì›ë³¸ê³¼ ë¸”ëŸ¬ëœ ì´ë¯¸ì§€ì˜ ì°¨ì´ë¡œ ë…¸ì´ì¦ˆ ì¶”ì •
            noise_map = torch.abs(img.unsqueeze(0).unsqueeze(0) - blurred)
            
            # ë…¸ì´ì¦ˆ ë ˆë²¨ ê³„ì‚°
            noise_level = torch.mean(noise_map).item()
            
            # 0-1 ë²”ìœ„ë¡œ ì •ê·œí™” (ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ)
            noise_score = 1.0 - min(1.0, noise_level * 10.0)
            
            return noise_score
        except Exception as e:
            logger.error(f"ë…¸ì´ì¦ˆ ë ˆë²¨ ê³„ì‚° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return 0.0
    
    def calculate_overall_quality(self, metrics: QualityMetrics) -> float:
        """
        ì „ì²´ í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°
        
        Args:
            metrics: í’ˆì§ˆ ë©”íŠ¸ë¦­
            
        Returns:
            ì „ì²´ í’ˆì§ˆ ì ìˆ˜
        """
        try:
            # ê°€ì¤‘ í‰ê· ìœ¼ë¡œ ì „ì²´ ì ìˆ˜ ê³„ì‚°
            overall_score = (
                self.metric_weights['psnr'] * min(1.0, metrics.psnr / 50.0) +
                self.metric_weights['ssim'] * metrics.ssim +
                self.metric_weights['perceptual'] * metrics.perceptual_score +
                self.metric_weights['sharpness'] * metrics.sharpness +
                self.metric_weights['noise'] * metrics.noise_level
            )
            
            return overall_score
        except Exception as e:
            logger.error(f"ì „ì²´ í’ˆì§ˆ ì ìˆ˜ ê³„ì‚° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return 0.0
    
    def assess_image_quality(self, original_img: torch.Tensor, processed_img: torch.Tensor) -> QualityMetrics:
        """
        ì´ë¯¸ì§€ í’ˆì§ˆ í‰ê°€
        
        Args:
            original_img: ì›ë³¸ ì´ë¯¸ì§€ í…ì„œ
            processed_img: ì²˜ë¦¬ëœ ì´ë¯¸ì§€ í…ì„œ
            
        Returns:
            í’ˆì§ˆ ë©”íŠ¸ë¦­ ê²°ê³¼
        """
        start_time = time.time()
        
        try:
            logger.info("ì´ë¯¸ì§€ í’ˆì§ˆ í‰ê°€ ì‹œì‘")
            
            # PSNR ê³„ì‚°
            psnr = self.calculate_psnr(original_img, processed_img)
            
            # SSIM ê³„ì‚°
            ssim = self.calculate_ssim(original_img, processed_img)
            
            # ì§€ê°ì  í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°
            perceptual_score = self.calculate_perceptual_score(original_img, processed_img)
            
            # ì„ ëª…ë„ ê³„ì‚° (ì²˜ë¦¬ëœ ì´ë¯¸ì§€ ê¸°ì¤€)
            sharpness = self.calculate_sharpness(processed_img)
            
            # ë…¸ì´ì¦ˆ ë ˆë²¨ ê³„ì‚° (ì²˜ë¦¬ëœ ì´ë¯¸ì§€ ê¸°ì¤€)
            noise_level = self.calculate_noise_level(processed_img)
            
            # ì²˜ë¦¬ ì‹œê°„ ê³„ì‚°
            processing_time = time.time() - start_time
            
            # í’ˆì§ˆ ë©”íŠ¸ë¦­ ìƒì„±
            metrics = QualityMetrics(
                psnr=psnr,
                ssim=ssim,
                perceptual_score=perceptual_score,
                sharpness=sharpness,
                noise_level=noise_level,
                overall_score=0.0,  # ë‚˜ì¤‘ì— ê³„ì‚°
                processing_time=processing_time
            )
            
            # ì „ì²´ í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°
            metrics.overall_score = self.calculate_overall_quality(metrics)
            
            logger.info(f"í’ˆì§ˆ í‰ê°€ ì™„ë£Œ - PSNR: {psnr:.2f}, SSIM: {ssim:.3f}, "
                       f"ì „ì²´ ì ìˆ˜: {metrics.overall_score:.3f}")
            
            return metrics
            
        except Exception as e:
            logger.error(f"ì´ë¯¸ì§€ í’ˆì§ˆ í‰ê°€ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            processing_time = time.time() - start_time
            
            # ì˜¤ë¥˜ ì‹œ ê¸°ë³¸ ë©”íŠ¸ë¦­ ë°˜í™˜
            return QualityMetrics(
                psnr=0.0,
                ssim=0.0,
                perceptual_score=0.0,
                sharpness=0.0,
                noise_level=0.0,
                overall_score=0.0,
                processing_time=processing_time
            )
    
    def batch_quality_assessment(self, original_imgs: List[torch.Tensor], 
                                processed_imgs: List[torch.Tensor]) -> List[QualityMetrics]:
        """
        ë°°ì¹˜ ì´ë¯¸ì§€ í’ˆì§ˆ í‰ê°€
        
        Args:
            original_imgs: ì›ë³¸ ì´ë¯¸ì§€ í…ì„œ ë¦¬ìŠ¤íŠ¸
            processed_imgs: ì²˜ë¦¬ëœ ì´ë¯¸ì§€ í…ì„œ ë¦¬ìŠ¤íŠ¸
            
        Returns:
            í’ˆì§ˆ ë©”íŠ¸ë¦­ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        """
        try:
            if len(original_imgs) != len(processed_imgs):
                raise ValueError("ì›ë³¸ ì´ë¯¸ì§€ì™€ ì²˜ë¦¬ëœ ì´ë¯¸ì§€ì˜ ê°œìˆ˜ê°€ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤")
            
            logger.info(f"ë°°ì¹˜ í’ˆì§ˆ í‰ê°€ ì‹œì‘ - {len(original_imgs)}ê°œ ì´ë¯¸ì§€")
            
            results = []
            for i, (orig_img, proc_img) in enumerate(zip(original_imgs, processed_imgs)):
                logger.info(f"ì´ë¯¸ì§€ {i+1}/{len(original_imgs)} í’ˆì§ˆ í‰ê°€ ì¤‘...")
                metrics = self.assess_image_quality(orig_img, proc_img)
                results.append(metrics)
            
            logger.info("ë°°ì¹˜ í’ˆì§ˆ í‰ê°€ ì™„ë£Œ")
            return results
            
        except Exception as e:
            logger.error(f"ë°°ì¹˜ í’ˆì§ˆ í‰ê°€ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return []
    
    def get_quality_summary(self, metrics_list: List[QualityMetrics]) -> Dict[str, Any]:
        """
        í’ˆì§ˆ ë©”íŠ¸ë¦­ ìš”ì•½ ì •ë³´ ë°˜í™˜
        
        Args:
            metrics_list: í’ˆì§ˆ ë©”íŠ¸ë¦­ ë¦¬ìŠ¤íŠ¸
            
        Returns:
            ìš”ì•½ ì •ë³´ ë”•ì…”ë„ˆë¦¬
        """
        try:
            if not metrics_list:
                return {}
            
            summary = {
                'total_images': len(metrics_list),
                'average_psnr': np.mean([m.psnr for m in metrics_list]),
                'average_ssim': np.mean([m.ssim for m in metrics_list]),
                'average_perceptual': np.mean([m.perceptual_score for m in metrics_list]),
                'average_sharpness': np.mean([m.sharpness for m in metrics_list]),
                'average_noise': np.mean([m.noise_level for m in metrics_list]),
                'average_overall': np.mean([m.overall_score for m in metrics_list]),
                'average_processing_time': np.mean([m.processing_time for m in metrics_list]),
                'best_image_index': np.argmax([m.overall_score for m in metrics_list]),
                'worst_image_index': np.argmin([m.overall_score for m in metrics_list])
            }
            
            return summary
            
        except Exception as e:
            logger.error(f"í’ˆì§ˆ ìš”ì•½ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return {}
    
    def is_quality_acceptable(self, metrics: QualityMetrics) -> bool:
        """
        í’ˆì§ˆì´ í—ˆìš© ê°€ëŠ¥í•œì§€ í™•ì¸
        
        Args:
            metrics: í’ˆì§ˆ ë©”íŠ¸ë¦­
            
        Returns:
            í’ˆì§ˆì´ í—ˆìš© ê°€ëŠ¥í•˜ë©´ True
        """
        try:
            return (
                metrics.psnr >= self.quality_config['psnr_threshold'] and
                metrics.ssim >= self.quality_config['ssim_threshold'] and
                metrics.perceptual_score >= self.quality_config['perceptual_threshold'] and
                metrics.sharpness >= self.quality_config['sharpness_threshold'] and
                metrics.noise_level >= self.quality_config['noise_threshold']
            )
        except Exception as e:
            logger.error(f"í’ˆì§ˆ í—ˆìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return False

class PostProcessingQualityAssessmentService:
    """í›„ì²˜ë¦¬ í’ˆì§ˆ í‰ê°€ ì„œë¹„ìŠ¤"""
    
    def __init__(self, config: Dict[str, Any] = None):
        self.config = config or {}
        self.logger = logging.getLogger(__name__)
        
        # MPS ë””ë°”ì´ìŠ¤ í™•ì¸
        self.device = torch.device("mps" if torch.backends.mps.is_available() else "cpu")
        self.logger.info(f"ğŸ¯ Post Processing í’ˆì§ˆ í‰ê°€ ì„œë¹„ìŠ¤ ì´ˆê¸°í™” (ë””ë°”ì´ìŠ¤: {self.device})")
        
        # ê¸°ë³¸ í’ˆì§ˆ í‰ê°€ ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
        self.quality_service = QualityAssessmentService(device=self.device)
        
        # í›„ì²˜ë¦¬ í’ˆì§ˆ í‰ê°€ ì„¤ì •
        self.post_processing_config = {
            'enable_psnr': True,
            'enable_ssim': True,
            'enable_perceptual': True,
            'enable_sharpness': True,
            'enable_noise': True,
            'quality_threshold': 0.7,
            'auto_quality_check': True
        }
        
        # ì„¤ì • ë³‘í•©
        self.post_processing_config.update(self.config)
        
        # í’ˆì§ˆ í‰ê°€ í†µê³„
        self.quality_stats = {
            'total_assessments': 0,
            'passed_assessments': 0,
            'failed_assessments': 0,
            'average_quality_score': 0.0,
            'total_processing_time': 0.0
        }
        
        self.logger.info("âœ… Post Processing í’ˆì§ˆ í‰ê°€ ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ")
    
    def assess_post_processing_quality(self, original_image: torch.Tensor, 
                                     post_processed_image: torch.Tensor) -> Dict[str, Any]:
        """
        í›„ì²˜ë¦¬ í’ˆì§ˆì„ í‰ê°€í•©ë‹ˆë‹¤.
        
        Args:
            original_image: ì›ë³¸ ì´ë¯¸ì§€
            post_processed_image: í›„ì²˜ë¦¬ëœ ì´ë¯¸ì§€
            
        Returns:
            í’ˆì§ˆ í‰ê°€ ê²°ê³¼
        """
        try:
            start_time = time.time()
            
            # ì…ë ¥ì„ ë””ë°”ì´ìŠ¤ë¡œ ì´ë™
            original_image = original_image.to(self.device)
            post_processed_image = post_processed_image.to(self.device)
            
            # í’ˆì§ˆ í‰ê°€ ìˆ˜í–‰
            quality_metrics = self.quality_service.assess_image_quality(
                original_image, post_processed_image
            )
            
            # í’ˆì§ˆ í†µê³¼ ì—¬ë¶€ í™•ì¸
            is_acceptable = self.quality_service.is_quality_acceptable(quality_metrics)
            
            # í†µê³„ ì—…ë°ì´íŠ¸
            self._update_quality_stats(quality_metrics, is_acceptable)
            
            # ê²°ê³¼ ë°˜í™˜
            result = {
                'quality_metrics': quality_metrics,
                'is_acceptable': is_acceptable,
                'quality_score': quality_metrics.overall_score,
                'assessment_time': time.time() - start_time,
                'device': str(self.device)
            }
            
            self.logger.info(f"í›„ì²˜ë¦¬ í’ˆì§ˆ í‰ê°€ ì™„ë£Œ (ì ìˆ˜: {quality_metrics.overall_score:.4f}, í†µê³¼: {is_acceptable})")
            return result
            
        except Exception as e:
            self.logger.error(f"í›„ì²˜ë¦¬ í’ˆì§ˆ í‰ê°€ ì‹¤íŒ¨: {e}")
            return {
                'quality_metrics': None,
                'is_acceptable': False,
                'quality_score': 0.0,
                'assessment_time': 0.0,
                'error': str(e),
                'device': str(self.device)
            }
    
    def assess_batch_post_processing_quality(self, original_images: List[torch.Tensor],
                                           post_processed_images: List[torch.Tensor]) -> Dict[str, Any]:
        """
        ë°°ì¹˜ í›„ì²˜ë¦¬ í’ˆì§ˆì„ í‰ê°€í•©ë‹ˆë‹¤.
        
        Args:
            original_images: ì›ë³¸ ì´ë¯¸ì§€ ë¦¬ìŠ¤íŠ¸
            post_processed_images: í›„ì²˜ë¦¬ëœ ì´ë¯¸ì§€ ë¦¬ìŠ¤íŠ¸
            
        Returns:
            ë°°ì¹˜ í’ˆì§ˆ í‰ê°€ ê²°ê³¼
        """
        try:
            if len(original_images) != len(post_processed_images):
                raise ValueError("ì›ë³¸ ì´ë¯¸ì§€ì™€ í›„ì²˜ë¦¬ ì´ë¯¸ì§€ì˜ ê°œìˆ˜ê°€ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤")
            
            start_time = time.time()
            
            # ê°œë³„ í’ˆì§ˆ í‰ê°€
            individual_results = []
            for i, (orig_img, proc_img) in enumerate(zip(original_images, post_processed_images)):
                try:
                    result = self.assess_post_processing_quality(orig_img, proc_img)
                    individual_results.append(result)
                    self.logger.debug(f"ì´ë¯¸ì§€ {i+1} í’ˆì§ˆ í‰ê°€ ì™„ë£Œ")
                except Exception as e:
                    self.logger.error(f"ì´ë¯¸ì§€ {i+1} í’ˆì§ˆ í‰ê°€ ì‹¤íŒ¨: {e}")
                    individual_results.append({
                        'quality_metrics': None,
                        'is_acceptable': False,
                        'quality_score': 0.0,
                        'assessment_time': 0.0,
                        'error': str(e)
                    })
            
            # ë°°ì¹˜ ìš”ì•½ ìƒì„±
            batch_summary = self._create_batch_summary(individual_results)
            
            # ì „ì²´ ì²˜ë¦¬ ì‹œê°„
            total_time = time.time() - start_time
            
            result = {
                'individual_results': individual_results,
                'batch_summary': batch_summary,
                'total_assessment_time': total_time,
                'batch_size': len(original_images),
                'device': str(self.device)
            }
            
            self.logger.info(f"ë°°ì¹˜ í›„ì²˜ë¦¬ í’ˆì§ˆ í‰ê°€ ì™„ë£Œ (ë°°ì¹˜ í¬ê¸°: {len(original_images)}, ì´ ì‹œê°„: {total_time:.4f}ì´ˆ)")
            return result
            
        except Exception as e:
            self.logger.error(f"ë°°ì¹˜ í›„ì²˜ë¦¬ í’ˆì§ˆ í‰ê°€ ì‹¤íŒ¨: {e}")
            return {
                'individual_results': [],
                'batch_summary': {},
                'total_assessment_time': 0.0,
                'batch_size': 0,
                'error': str(e),
                'device': str(self.device)
            }
    
    def _create_batch_summary(self, individual_results: List[Dict[str, Any]]) -> Dict[str, Any]:
        """ë°°ì¹˜ ìš”ì•½ì„ ìƒì„±í•©ë‹ˆë‹¤."""
        try:
            if not individual_results:
                return {}
            
            # í†µê³¼í•œ í‰ê°€ ìˆ˜
            passed_count = sum(1 for result in individual_results if result.get('is_acceptable', False))
            
            # í’ˆì§ˆ ì ìˆ˜ë“¤
            quality_scores = [result.get('quality_score', 0.0) for result in individual_results if result.get('quality_score') is not None]
            
            # í‰ê°€ ì‹œê°„ë“¤
            assessment_times = [result.get('assessment_time', 0.0) for result in individual_results if result.get('assessment_time') is not None]
            
            summary = {
                'total_images': len(individual_results),
                'passed_count': passed_count,
                'failed_count': len(individual_results) - passed_count,
                'pass_rate': passed_count / len(individual_results) if individual_results else 0.0,
                'average_quality_score': sum(quality_scores) / len(quality_scores) if quality_scores else 0.0,
                'min_quality_score': min(quality_scores) if quality_scores else 0.0,
                'max_quality_score': max(quality_scores) if quality_scores else 0.0,
                'average_assessment_time': sum(assessment_times) / len(assessment_times) if assessment_times else 0.0,
                'total_assessment_time': sum(assessment_times)
            }
            
            return summary
            
        except Exception as e:
            self.logger.error(f"ë°°ì¹˜ ìš”ì•½ ìƒì„± ì‹¤íŒ¨: {e}")
            return {'error': str(e)}
    
    def _update_quality_stats(self, quality_metrics: QualityMetrics, is_acceptable: bool):
        """í’ˆì§ˆ í†µê³„ë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤."""
        try:
            self.quality_stats['total_assessments'] += 1
            
            if is_acceptable:
                self.quality_stats['passed_assessments'] += 1
            else:
                self.quality_stats['failed_assessments'] += 1
            
            # í‰ê·  í’ˆì§ˆ ì ìˆ˜ ì—…ë°ì´íŠ¸
            total_score = self.quality_stats['average_quality_score'] * (self.quality_stats['total_assessments'] - 1)
            total_score += quality_metrics.overall_score
            self.quality_stats['average_quality_score'] = total_score / self.quality_stats['total_assessments']
            
            # ì´ ì²˜ë¦¬ ì‹œê°„ ì—…ë°ì´íŠ¸
            self.quality_stats['total_processing_time'] += quality_metrics.processing_time
            
        except Exception as e:
            self.logger.error(f"í’ˆì§ˆ í†µê³„ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
    
    def get_quality_stats(self) -> Dict[str, Any]:
        """í’ˆì§ˆ í‰ê°€ í†µê³„ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
        return {
            **self.quality_stats,
            'service_config': self.post_processing_config,
            'device': str(self.device)
        }
    
    def reset_quality_stats(self):
        """í’ˆì§ˆ í‰ê°€ í†µê³„ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."""
        self.quality_stats = {
            'total_assessments': 0,
            'passed_assessments': 0,
            'failed_assessments': 0,
            'average_quality_score': 0.0,
            'total_processing_time': 0.0
        }
        self.logger.info("í’ˆì§ˆ í‰ê°€ í†µê³„ ì´ˆê¸°í™” ì™„ë£Œ")
    
    def cleanup(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤."""
        try:
            # í’ˆì§ˆ í‰ê°€ í†µê³„ ì´ˆê¸°í™”
            self.reset_quality_stats()
            
            self.logger.info("Post Processing í’ˆì§ˆ í‰ê°€ ì„œë¹„ìŠ¤ ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì™„ë£Œ")
            
        except Exception as e:
            self.logger.error(f"ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì‹¤íŒ¨: {e}")

# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    # ì„¤ì •
    config = {
        'enable_psnr': True,
        'enable_ssim': True,
        'enable_perceptual': True,
        'enable_sharpness': True,
        'enable_noise': True,
        'quality_threshold': 0.7,
        'auto_quality_check': True
    }
    
    # Post Processing í’ˆì§ˆ í‰ê°€ ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
    quality_service = PostProcessingQualityAssessmentService(config)
    
    # í…ŒìŠ¤íŠ¸ ì…ë ¥
    batch_size = 2
    channels = 3
    height = 256
    width = 256
    
    test_original = [torch.randn(channels, height, width) for _ in range(batch_size)]
    test_processed = [torch.randn(channels, height, width) for _ in range(batch_size)]
    
    # ê°œë³„ í’ˆì§ˆ í‰ê°€
    for i in range(batch_size):
        result = quality_service.assess_post_processing_quality(test_original[i], test_processed[i])
        print(f"ì´ë¯¸ì§€ {i+1} í’ˆì§ˆ í‰ê°€: {result['quality_score']:.4f}")
    
    # ë°°ì¹˜ í’ˆì§ˆ í‰ê°€
    batch_result = quality_service.assess_batch_post_processing_quality(test_original, test_processed)
    print(f"ë°°ì¹˜ í’ˆì§ˆ í‰ê°€ ìš”ì•½: {batch_result['batch_summary']}")
    
    # í’ˆì§ˆ í‰ê°€ í†µê³„
    stats = quality_service.get_quality_stats()
    print(f"í’ˆì§ˆ í‰ê°€ í†µê³„: {stats}")
    
    # ë¦¬ì†ŒìŠ¤ ì •ë¦¬
    quality_service.cleanup()
