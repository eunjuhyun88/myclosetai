# app/ai_pipeline/steps/step_04_geometric_matching.py
"""
4ë‹¨ê³„: ê¸°í•˜í•™ì  ë§¤ì¹­ (Geometric Matching) - ìµœì  ìƒì„±ì íŒ¨í„´ ì ìš©
M3 Max ìµœì í™” + ê²¬ê³ í•œ ì—ëŸ¬ ì²˜ë¦¬ + ê¸°ì¡´ ê¸°ëŠ¥ 100% ìœ ì§€
"""
import os
import logging
import time
import asyncio
from typing import Dict, Any, Optional, Tuple, List, Union
import numpy as np
from PIL import Image
import cv2

# PyTorch ì„ íƒì  ì„í¬íŠ¸
try:
    import torch
    import torch.nn.functional as F
    TORCH_AVAILABLE = True
except ImportError:
    TORCH_AVAILABLE = False
    torch = None

# SciPy ì„ íƒì  ì„í¬íŠ¸
try:
    from scipy.spatial.distance import cdist
    from scipy.optimize import minimize
    SCIPY_AVAILABLE = True
except ImportError:
    SCIPY_AVAILABLE = False
    cdist = None

logger = logging.getLogger(__name__)
class GeometricMatchingStep:
    def __init__(
        self,
        device: Optional[str] = None,
        config: Optional[Dict[str, Any]] = None,
        **kwargs
    ):
        """âœ… ìµœì  ìƒì„±ì íŒ¨í„´ ì ìš©"""
        
        # ë™ì¼í•œ íŒ¨í„´...
        self.device = self._auto_detect_device(device)
        self.config = config or {}
        self.step_name = self.__class__.__name__
        self.logger = logging.getLogger(f"pipeline.{self.step_name}")
        
        self.device_type = kwargs.get('device_type', 'auto')
        self.memory_gb = kwargs.get('memory_gb', 16.0)
        self.is_m3_max = kwargs.get('is_m3_max', self._detect_m3_max())
        self.optimization_enabled = kwargs.get('optimization_enabled', True)
        self.quality_level = kwargs.get('quality_level', 'balanced')
        
        self._merge_step_specific_config(kwargs)
        self.is_initialized = False
        
        from app.ai_pipeline.utils.model_loader import BaseStepMixin
        if hasattr(BaseStepMixin, '_setup_model_interface'):
            BaseStepMixin._setup_model_interface(self)
        
        self._initialize_step_specific()
        self.logger.info(f"ğŸ¯ {self.step_name} ì´ˆê¸°í™” - ë””ë°”ì´ìŠ¤: {self.device}")
    
        
        # ë§¤ì¹­ ì„¤ì • (ê¸°ì¡´ ê¸°ëŠ¥ ìœ ì§€ + kwargs í™•ì¥)
        self.matching_config = self.config.get('matching', {
            'method': kwargs.get('method', 'auto'),  # 'tps', 'affine', 'homography', 'auto'
            'max_iterations': kwargs.get('max_iterations', 1000),
            'convergence_threshold': kwargs.get('convergence_threshold', 1e-6),
            'outlier_threshold': kwargs.get('outlier_threshold', 0.15),
            'use_pose_guidance': kwargs.get('use_pose_guidance', True),
            'adaptive_weights': kwargs.get('adaptive_weights', True),
            'quality_threshold': kwargs.get('quality_threshold', 0.7)
        })
        
        # TPS ì„¤ì • (M3 Max ìµœì í™”)
        self.tps_config = self.config.get('tps', {
            'regularization': kwargs.get('tps_regularization', 0.1),
            'grid_size': kwargs.get('tps_grid_size', 30 if self.is_m3_max else 20),
            'boundary_padding': kwargs.get('tps_boundary_padding', 0.1)
        })
        
        # ìµœì í™” ì„¤ì • (M3 Max ê³ ë ¤)
        learning_rate_base = 0.01
        if self.is_m3_max and self.optimization_enabled:
            learning_rate_base *= 1.2  # M3 MaxëŠ” ë” ë¹ ë¥¸ í•™ìŠµ
        
        self.optimization_config = self.config.get('optimization', {
            'learning_rate': kwargs.get('learning_rate', learning_rate_base),
            'momentum': kwargs.get('momentum', 0.9),
            'weight_decay': kwargs.get('weight_decay', 1e-4),
            'scheduler_step': kwargs.get('scheduler_step', 100)
        })
        
        # ë§¤ì¹­ í†µê³„ (ê¸°ì¡´ê³¼ ë™ì¼)
        self.matching_stats = {
            'total_matches': 0,
            'successful_matches': 0,
            'average_accuracy': 0.0,
            'method_performance': {}
        }
        
        # ë§¤ì¹­ ì»´í¬ë„ŒíŠ¸ë“¤ ì´ˆê¸°í™”
        self.tps_grid = None
        self.ransac_params = None
        self.optimizer_config = None
        
        self.logger.info(f"ğŸ¯ ê¸°í•˜í•™ì  ë§¤ì¹­ ìŠ¤í… ì´ˆê¸°í™” ì™„ë£Œ - ë””ë°”ì´ìŠ¤: {self.device}")
    
    def _auto_detect_device(self, preferred_device: Optional[str]) -> str:
        """ğŸ’¡ ì§€ëŠ¥ì  ë””ë°”ì´ìŠ¤ ìë™ ê°ì§€"""
        if preferred_device:
            return preferred_device

        try:
            import torch
            if torch.backends.mps.is_available():
                return 'mps'  # M3 Max ìš°ì„ 
            elif torch.cuda.is_available():
                return 'cuda'  # NVIDIA GPU
            else:
                return 'cpu'  # í´ë°±
        except ImportError:
            return 'cpu'

    def _detect_m3_max(self) -> bool:
        """ğŸ M3 Max ì¹© ìë™ ê°ì§€"""
        try:
            import platform
            import subprocess

            if platform.system() == 'Darwin':  # macOS
                result = subprocess.run(['sysctl', '-n', 'machdep.cpu.brand_string'], 
                                      capture_output=True, text=True)
                return 'M3' in result.stdout
        except:
            pass
        return False

    def _merge_step_specific_config(self, kwargs: Dict[str, Any]):
        """âš™ï¸ ìŠ¤í…ë³„ íŠ¹í™” ì„¤ì • ë³‘í•©"""
        system_params = {
            'device_type', 'memory_gb', 'is_m3_max', 
            'optimization_enabled', 'quality_level'
        }

        for key, value in kwargs.items():
            if key not in system_params:
                self.config[key] = value

    async def initialize(self) -> bool:
        """ì´ˆê¸°í™” ë©”ì„œë“œ (ê¸°ì¡´ê³¼ ë™ì¼í•˜ì§€ë§Œ M3 Max ìµœì í™” ì¶”ê°€)"""
        try:
            self.logger.info("ğŸ”„ ê¸°í•˜í•™ì  ë§¤ì¹­ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹œì‘...")
            
            # ë””ë°”ì´ìŠ¤ ê²€ì¦
            if not self._validate_device():
                self.logger.warning(f"âš ï¸ ë””ë°”ì´ìŠ¤ {self.device} ê²€ì¦ ì‹¤íŒ¨, CPUë¡œ í´ë°±")
                self.device = "cpu"
            
            # M3 Max íŠ¹í™” ìµœì í™”
            if self.is_m3_max:
                await self._initialize_m3_max_optimizations()
            
            # ë§¤ì¹­ ì•Œê³ ë¦¬ì¦˜ ì´ˆê¸°í™”
            await self._initialize_matching_algorithms()
            
            # ìµœì í™” ë„êµ¬ ì´ˆê¸°í™”
            await self._initialize_optimization_tools()
            
            # í…ŒìŠ¤íŠ¸ ë§¤ì¹­ ìˆ˜í–‰
            await self._test_system()
            
            self.is_initialized = True
            self.logger.info("âœ… ê¸°í•˜í•™ì  ë§¤ì¹­ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
            return True
            
        except Exception as e:
            error_msg = f"ë§¤ì¹­ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}"
            self.logger.error(f"âŒ {error_msg}")
            self.initialization_error = error_msg
            
            # ê¸°ë³¸ ì‹œìŠ¤í…œìœ¼ë¡œ í´ë°±
            await self._initialize_fallback_system()
            self.is_initialized = True
            return True
    
    async def _initialize_m3_max_optimizations(self):
        """M3 Max íŠ¹í™” ìµœì í™”"""
        try:
            self.logger.info("ğŸ M3 Max ìµœì í™” ì ìš©...")
            
            # MPS ë©”ëª¨ë¦¬ ìµœì í™”
            if TORCH_AVAILABLE and self.device == 'mps':
                os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '1'
                if hasattr(torch.backends.mps, 'empty_cache'):
                    if hasattr(torch.mps, "empty_cache"): torch.mps.empty_cache()
            
            # M3 Maxìš© ê³ ì„±ëŠ¥ íŒŒë¼ë¯¸í„°
            self.matching_config['quality_threshold'] = 0.8
            
            # ê³ ì •ë°€ë„ ëª¨ë“œ
            if self.quality_level in ['high', 'ultra']:
                self.tps_config['grid_size'] = 30
                self.matching_config['max_iterations'] = 1500
            
            self.logger.info("âœ… M3 Max ìµœì í™” ì™„ë£Œ")
            
        except Exception as e:
            self.logger.warning(f"M3 Max ìµœì í™” ì‹¤íŒ¨: {e}")
    
    def _validate_device(self) -> bool:
        """ë””ë°”ì´ìŠ¤ ìœ íš¨ì„± ê²€ì‚¬"""
        if self.device == 'mps':
            return TORCH_AVAILABLE and torch.backends.mps.is_available()
        elif self.device == 'cuda':
            return TORCH_AVAILABLE and torch.cuda.is_available()
        elif self.device == 'cpu':
            return True
        return False
    
    async def _initialize_matching_algorithms(self):
        """ë§¤ì¹­ ì•Œê³ ë¦¬ì¦˜ ì´ˆê¸°í™”"""
        try:
            # TPS ê·¸ë¦¬ë“œ ì´ˆê¸°í™”
            if SCIPY_AVAILABLE:
                grid_size = self.tps_config['grid_size']
                self.tps_grid = np.mgrid[0:grid_size, 0:grid_size].reshape(2, -1).T
                self.logger.debug("âœ… TPS ê·¸ë¦¬ë“œ ì´ˆê¸°í™” ì™„ë£Œ")
            
            # RANSAC íŒŒë¼ë¯¸í„° ì„¤ì • (M3 Max ìµœì í™”)
            max_trials = 1500 if self.is_m3_max else 1000
            residual_threshold = 4.0 if self.is_m3_max else 5.0
            
            self.ransac_params = {
                'max_trials': max_trials,
                'residual_threshold': residual_threshold,
                'min_samples': 4
            }
            
            self.logger.info("âœ… ë§¤ì¹­ ì•Œê³ ë¦¬ì¦˜ ì´ˆê¸°í™” ì™„ë£Œ")
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ ë§¤ì¹­ ì•Œê³ ë¦¬ì¦˜ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.tps_grid = None
            self.ransac_params = {'max_trials': 100, 'residual_threshold': 10.0, 'min_samples': 3}
    
    async def _initialize_optimization_tools(self):
        """ìµœì í™” ë„êµ¬ ì´ˆê¸°í™”"""
        try:
            method = 'L-BFGS-B' if (SCIPY_AVAILABLE and self.is_m3_max) else ('L-BFGS-B' if SCIPY_AVAILABLE else 'Powell')
            
            self.optimizer_config = {
                'method': method,
                'options': {
                    'maxiter': self.matching_config['max_iterations'],
                    'ftol': self.matching_config['convergence_threshold']
                }
            }
            
            self.logger.info(f"âœ… ìµœì í™” ë„êµ¬ ì´ˆê¸°í™” ì™„ë£Œ (ë°©ë²•: {method})")
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ ìµœì í™” ë„êµ¬ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.optimizer_config = {'method': 'Powell', 'options': {'maxiter': 100}}
    
    async def _test_system(self):
        """ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸"""
        try:
            test_person_points = [(100, 100), (200, 100), (150, 200)]
            test_clothing_points = [(105, 105), (195, 95), (155, 205)]
            
            test_result = await self._perform_initial_matching(
                test_person_points, test_clothing_points, 'affine'
            )
            
            if test_result.get('success', True):
                self.logger.debug("âœ… ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ í†µê³¼")
            else:
                self.logger.warning("âš ï¸ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨, ê¸°ë³¸ ëª¨ë“œë¡œ ë™ì‘")
                
        except Exception as e:
            self.logger.warning(f"âš ï¸ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
    
    async def _initialize_fallback_system(self):
        """í´ë°± ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
        try:
            self.logger.info("ğŸ”„ ê¸°ë³¸ ë§¤ì¹­ ì‹œìŠ¤í…œìœ¼ë¡œ ì´ˆê¸°í™”...")
            
            self.matching_config['method'] = 'similarity'
            self.tps_grid = None
            self.ransac_params = {'max_trials': 50, 'residual_threshold': 15.0, 'min_samples': 2}
            self.optimizer_config = {'method': 'Powell', 'options': {'maxiter': 50}}
            
            self.logger.info("âœ… ê¸°ë³¸ ë§¤ì¹­ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
            
        except Exception as e:
            self.logger.error(f"âŒ í´ë°± ì‹œìŠ¤í…œ ì´ˆê¸°í™”ë„ ì‹¤íŒ¨: {e}")
    
    async def process(
        self,
        person_parsing: Dict[str, Any],
        pose_keypoints: List[List[float]],
        clothing_segmentation: Dict[str, Any],
        clothing_type: str = "shirt",
        **kwargs
    ) -> Dict[str, Any]:
        """
        ê¸°í•˜í•™ì  ë§¤ì¹­ ì²˜ë¦¬ (ê¸°ì¡´ê³¼ ë™ì¼)
        
        Args:
            person_parsing: ì¸ì²´ íŒŒì‹± ê²°ê³¼
            pose_keypoints: í¬ì¦ˆ í‚¤í¬ì¸íŠ¸ (OpenPose 18 í˜•ì‹)
            clothing_segmentation: ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ ê²°ê³¼
            clothing_type: ì˜ë¥˜ íƒ€ì…
            **kwargs: ì¶”ê°€ ë§¤ê°œë³€ìˆ˜
            
        Returns:
            Dict: ë§¤ì¹­ ê²°ê³¼
        """
        start_time = time.time()
        
        try:
            if not self.is_initialized:
                await self.initialize()
            
            self.logger.info(f"ğŸ¯ ê¸°í•˜í•™ì  ë§¤ì¹­ ì‹œì‘ - ì˜ë¥˜: {clothing_type}")
            
            # 1. ì…ë ¥ ë°ì´í„° ê²€ì¦ ë° ì „ì²˜ë¦¬
            person_points = self._extract_person_keypoints(pose_keypoints, clothing_type)
            clothing_points = self._extract_clothing_keypoints(clothing_segmentation, clothing_type)
            
            if len(person_points) < 2 or len(clothing_points) < 2:
                return self._create_empty_result("ì¶©ë¶„í•˜ì§€ ì•Šì€ ë§¤ì¹­ í¬ì¸íŠ¸", clothing_type)
            
            # 2. ë§¤ì¹­ ë°©ë²• ì„ íƒ (M3 Max ìµœì í™”)
            matching_method = self._select_matching_method(person_points, clothing_points, clothing_type)
            self.logger.info(f"ğŸ“ ì„ íƒëœ ë§¤ì¹­ ë°©ë²•: {matching_method}")
            
            # 3. ì´ˆê¸° ë§¤ì¹­ ìˆ˜í–‰
            initial_match = await self._perform_initial_matching(
                person_points, clothing_points, matching_method
            )
            
            # 4. í¬ì¦ˆ ê¸°ë°˜ ì •ì œ
            if self.matching_config['use_pose_guidance'] and len(pose_keypoints) > 5:
                refined_match = await self._refine_with_pose_guidance(
                    initial_match, pose_keypoints, clothing_type
                )
            else:
                refined_match = initial_match
            
            # 5. ë§¤ì¹­ í’ˆì§ˆ í‰ê°€
            quality_metrics = self._evaluate_matching_quality(
                person_points, clothing_points, refined_match
            )
            
            # 6. í’ˆì§ˆ ê°œì„  ì‹œë„ (M3 MaxëŠ” ë” ë†’ì€ ì„ê³„ê°’)
            quality_threshold = 0.8 if self.is_m3_max else self.matching_config['quality_threshold']
            if quality_metrics['overall_quality'] < quality_threshold:
                self.logger.info(f"ğŸ”„ í’ˆì§ˆ ê°œì„  ì‹œë„ (í˜„ì¬: {quality_metrics['overall_quality']:.3f})")
                alternative_match = await self._try_alternative_methods(
                    person_points, clothing_points, clothing_type
                )
                
                if alternative_match:
                    alternative_quality = self._evaluate_matching_quality(
                        person_points, clothing_points, alternative_match
                    )
                    
                    if alternative_quality['overall_quality'] > quality_metrics['overall_quality']:
                        refined_match = alternative_match
                        quality_metrics = alternative_quality
                        matching_method = alternative_match.get('method', matching_method)
            
            # 7. ì›Œí•‘ íŒŒë¼ë¯¸í„° ìƒì„±
            warp_params = self._generate_warp_parameters(refined_match, clothing_segmentation)
            
            # 8. ìµœì¢… ê²°ê³¼ êµ¬ì„±
            processing_time = time.time() - start_time
            result = self._build_final_result(
                refined_match, warp_params, quality_metrics, 
                processing_time, matching_method, clothing_type
            )
            
            # 9. í†µê³„ ì—…ë°ì´íŠ¸
            self._update_statistics(matching_method, quality_metrics['overall_quality'])
            
            self.logger.info(f"âœ… ê¸°í•˜í•™ì  ë§¤ì¹­ ì™„ë£Œ - ë°©ë²•: {matching_method}, í’ˆì§ˆ: {quality_metrics['overall_quality']:.3f}")
            return result
            
        except Exception as e:
            error_msg = f"ê¸°í•˜í•™ì  ë§¤ì¹­ ì‹¤íŒ¨: {e}"
            self.logger.error(f"âŒ {error_msg}")
            return self._create_empty_result(error_msg, clothing_type)
    
    def _extract_person_keypoints(self, pose_keypoints: List[List[float]], clothing_type: str) -> List[Tuple[float, float]]:
        """ì¸ì²´ì—ì„œ ë§¤ì¹­ í¬ì¸íŠ¸ ì¶”ì¶œ (M3 Max ìµœì í™”)"""
        
        try:
            keypoint_mapping = {
                'neck': 1, 'left_shoulder': 5, 'right_shoulder': 2,
                'left_elbow': 6, 'right_elbow': 3,
                'left_wrist': 7, 'right_wrist': 4,
                'left_hip': 11, 'right_hip': 8,
                'left_knee': 12, 'right_knee': 9,
                'left_ankle': 13, 'right_ankle': 10
            }
            
            matching_points = self.MATCHING_POINTS.get(clothing_type, self.MATCHING_POINTS['shirt'])
            person_points = []
            
            # M3 MaxëŠ” ë” ë‚®ì€ ì‹ ë¢°ë„ ì„ê³„ê°’ìœ¼ë¡œ ë” ë§ì€ í¬ì¸íŠ¸ í™œìš©
            confidence_threshold = 0.2 if self.is_m3_max else 0.3
            
            for keypoint_name in matching_points['keypoints']:
                if keypoint_name in keypoint_mapping:
                    idx = keypoint_mapping[keypoint_name]
                    if idx < len(pose_keypoints):
                        x, y, conf = pose_keypoints[idx]
                        if conf > confidence_threshold:
                            person_points.append((float(x), float(y)))
            
            # ìµœì†Œ í¬ì¸íŠ¸ í™•ë³´ (M3 MaxëŠ” ë” ë§ì´)
            min_points = 3 if self.is_m3_max else 2
            max_points = 7 if self.is_m3_max else 5
            
            if len(person_points) < min_points and len(pose_keypoints) > 2:
                for i, (x, y, conf) in enumerate(pose_keypoints):
                    if conf > 0.5 and len(person_points) < max_points:
                        person_points.append((float(x), float(y)))
            
            self.logger.debug(f"ì¶”ì¶œëœ ì¸ì²´ í¬ì¸íŠ¸: {len(person_points)}ê°œ (M3 Max: {self.is_m3_max})")
            return person_points
            
        except Exception as e:
            self.logger.warning(f"ì¸ì²´ í‚¤í¬ì¸íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return []
    
    def _extract_clothing_keypoints(self, clothing_segmentation: Dict[str, Any], clothing_type: str) -> List[Tuple[float, float]]:
        """ì˜ë¥˜ì—ì„œ ë§¤ì¹­ í¬ì¸íŠ¸ ì¶”ì¶œ"""
        
        try:
            mask = clothing_segmentation.get('mask')
            if mask is None:
                return []
            
            # NumPy ë°°ì—´ë¡œ ë³€í™˜
            if hasattr(mask, 'cpu'):  # Tensorì¸ ê²½ìš°
                mask = mask.cpu().numpy()
            
            mask = np.array(mask, dtype=np.uint8)
            
            # ì˜ë¥˜ ìœ¤ê³½ì„  ì¶”ì¶œ
            contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            
            if not contours:
                return []
            
            # ê°€ì¥ í° ìœ¤ê³½ì„  ì„ íƒ
            largest_contour = max(contours, key=cv2.contourArea)
            
            # ì˜ë¥˜ íƒ€ì…ë³„ íŠ¹ì§•ì  ì¶”ì¶œ
            clothing_points = self._extract_clothing_features(largest_contour, mask, clothing_type)
            
            self.logger.debug(f"ì¶”ì¶œëœ ì˜ë¥˜ í¬ì¸íŠ¸: {len(clothing_points)}ê°œ")
            return clothing_points
            
        except Exception as e:
            self.logger.warning(f"ì˜ë¥˜ í‚¤í¬ì¸íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return []
    
    def _extract_clothing_features(self, contour: np.ndarray, mask: np.ndarray, clothing_type: str) -> List[Tuple[float, float]]:
        """ì˜ë¥˜ íŠ¹ì§•ì  ì¶”ì¶œ"""
        
        features = []
        
        try:
            # ë°”ìš´ë”© ë°•ìŠ¤
            x, y, w, h = cv2.boundingRect(contour)
            
            if clothing_type in ['shirt', 't-shirt', 'blouse']:
                features.extend([
                    (x + w * 0.2, y + h * 0.1),  # ì™¼ìª½ ì–´ê¹¨
                    (x + w * 0.8, y + h * 0.1),  # ì˜¤ë¥¸ìª½ ì–´ê¹¨
                    (x + w * 0.5, y),            # ëª©/ì¹¼ë¼
                    (x, y + h * 0.3),            # ì™¼ìª½ ì†Œë§¤
                    (x + w, y + h * 0.3)         # ì˜¤ë¥¸ìª½ ì†Œë§¤
                ])
                
            elif clothing_type in ['pants', 'jeans', 'trousers']:
                features.extend([
                    (x + w * 0.2, y),            # ì™¼ìª½ í—ˆë¦¬
                    (x + w * 0.8, y),            # ì˜¤ë¥¸ìª½ í—ˆë¦¬
                    (x + w * 0.3, y + h * 0.6),  # ì™¼ìª½ ë¬´ë¦
                    (x + w * 0.7, y + h * 0.6),  # ì˜¤ë¥¸ìª½ ë¬´ë¦
                    (x + w * 0.3, y + h),        # ì™¼ìª½ ë°œëª©
                    (x + w * 0.7, y + h)         # ì˜¤ë¥¸ìª½ ë°œëª©
                ])
                
            elif clothing_type in ['dress', 'gown']:
                features.extend([
                    (x + w * 0.2, y + h * 0.1),  # ì™¼ìª½ ì–´ê¹¨
                    (x + w * 0.8, y + h * 0.1),  # ì˜¤ë¥¸ìª½ ì–´ê¹¨
                    (x + w * 0.5, y),            # ëª©/ì¹¼ë¼
                    (x + w * 0.2, y + h * 0.4),  # ì™¼ìª½ í—ˆë¦¬
                    (x + w * 0.8, y + h * 0.4)   # ì˜¤ë¥¸ìª½ í—ˆë¦¬
                ])
            
            # ìœ¤ê³½ì„  ê¸°ë°˜ ì¶”ê°€ íŠ¹ì§•ì 
            features.extend(self._extract_contour_features(contour))
            
            return features
            
        except Exception as e:
            self.logger.warning(f"ì˜ë¥˜ íŠ¹ì§•ì  ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return []
    
    def _extract_contour_features(self, contour: np.ndarray) -> List[Tuple[float, float]]:
        """ìœ¤ê³½ì„  ê¸°ë°˜ íŠ¹ì§•ì  ì¶”ì¶œ"""
        
        features = []
        
        try:
            # ê·¹ê°’ì ë“¤
            leftmost = tuple(contour[contour[:, :, 0].argmin()][0])
            rightmost = tuple(contour[contour[:, :, 0].argmax()][0])
            topmost = tuple(contour[contour[:, :, 1].argmin()][0])
            bottommost = tuple(contour[contour[:, :, 1].argmax()][0])
            
            features.extend([leftmost, rightmost, topmost, bottommost])
            
            # ì¤‘ì‹¬ì 
            M = cv2.moments(contour)
            if M['m00'] != 0:
                cx = int(M['m10'] / M['m00'])
                cy = int(M['m01'] / M['m00'])
                features.append((cx, cy))
            
            return features
            
        except Exception as e:
            self.logger.warning(f"ìœ¤ê³½ì„  íŠ¹ì§•ì  ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return []
    
    def _select_matching_method(self, person_points: List, clothing_points: List, clothing_type: str) -> str:
        """ë§¤ì¹­ ë°©ë²• ì„ íƒ (M3 Max ìµœì í™”)"""
        
        method = self.matching_config['method']
        
        if method == 'auto':
            num_points = min(len(person_points), len(clothing_points))
            
            # M3 MaxëŠ” ë” ê³ ê¸‰ ì•Œê³ ë¦¬ì¦˜ ì„ í˜¸
            if self.is_m3_max and num_points >= 6 and SCIPY_AVAILABLE:
                return 'tps_advanced'  # M3 Max ì „ìš© ê³ ê¸‰ TPS
            elif num_points >= 8 and SCIPY_AVAILABLE:
                return 'tps'  # ì¶©ë¶„í•œ í¬ì¸íŠ¸ê°€ ìˆìœ¼ë©´ TPS
            elif num_points >= 4:
                return 'homography'  # 4-7ê°œ í¬ì¸íŠ¸ëŠ” Homography
            elif num_points >= 3:
                return 'affine'  # 3ê°œ í¬ì¸íŠ¸ëŠ” Affine
            else:
                return 'similarity'  # ìµœì†Œ ë³€í™˜
        
        return method
    
    async def _perform_initial_matching(
        self, 
        person_points: List, 
        clothing_points: List, 
        method: str
    ) -> Dict[str, Any]:
        """ì´ˆê¸° ë§¤ì¹­ ìˆ˜í–‰ (M3 Max ê³ ê¸‰ TPS ì¶”ê°€)"""
        
        try:
            if method == 'tps_advanced' and SCIPY_AVAILABLE and self.is_m3_max:
                return await self._tps_advanced_matching(person_points, clothing_points)
            elif method == 'tps' and SCIPY_AVAILABLE:
                return await self._tps_matching(person_points, clothing_points)
            elif method == 'homography':
                return self._homography_matching(person_points, clothing_points)
            elif method == 'affine':
                return self._affine_matching(person_points, clothing_points)
            else:  # similarity
                return self._similarity_matching(person_points, clothing_points)
                
        except Exception as e:
            self.logger.warning(f"ë§¤ì¹­ ë°©ë²• {method} ì‹¤íŒ¨: {e}")
            return self._similarity_matching(person_points, clothing_points)
    
    async def _tps_advanced_matching(self, person_points: List, clothing_points: List) -> Dict[str, Any]:
        """M3 Max ì „ìš© ê³ ê¸‰ TPS ë§¤ì¹­"""
        
        try:
            if not SCIPY_AVAILABLE:
                raise ImportError("SciPy ì—†ì´ëŠ” ê³ ê¸‰ TPS ì‚¬ìš© ë¶ˆê°€")
            
            # ëŒ€ì‘ì  ìŒ ìƒì„± (M3 MaxëŠ” ë” ì •êµ)
            person_array = np.array(person_points)
            clothing_array = np.array(clothing_points)
            
            # ìµœì  ëŒ€ì‘ì  ì°¾ê¸° (ê³ ê¸‰ ì•Œê³ ë¦¬ì¦˜)
            correspondences = self._find_optimal_correspondences(person_array, clothing_array)
            
            if len(correspondences) >= 4:  # M3 MaxëŠ” ë” ë†’ì€ ìµœì†Œ ìš”êµ¬ì‚¬í•­
                source_pts = np.array([corr[1] for corr in correspondences])
                target_pts = np.array([corr[0] for corr in correspondences])
                
                # ê³ ê¸‰ TPS ë³€í™˜ ê³„ì‚°
                tps_transform = self._compute_advanced_tps_transform(source_pts, target_pts)
                
                return {
                    'method': 'tps_advanced',
                    'transform': tps_transform,
                    'correspondences': correspondences,
                    'source_points': source_pts.tolist(),
                    'target_points': target_pts.tolist(),
                    'confidence': 0.95,  # M3 MaxëŠ” ë” ë†’ì€ ì‹ ë¢°ë„
                    'success': True,
                    'm3_max_optimized': True
                }
            else:
                raise ValueError("ê³ ê¸‰ TPSë¥¼ ìœ„í•œ ì¶©ë¶„í•œ ëŒ€ì‘ì ì´ ì—†ìŒ")
                
        except Exception as e:
            self.logger.warning(f"ê³ ê¸‰ TPS ë§¤ì¹­ ì‹¤íŒ¨: {e}")
            # ê¸°ë³¸ TPSë¡œ í´ë°±
            return await self._tps_matching(person_points, clothing_points)
    
    def _find_optimal_correspondences(self, person_array: np.ndarray, clothing_array: np.ndarray) -> List:
        """ìµœì  ëŒ€ì‘ì  ì°¾ê¸° (M3 Max ì „ìš©)"""
        
        try:
            # ê±°ë¦¬ ê¸°ë°˜ + ê¸°í•˜í•™ì  ì œì•½ ì¡°ê±´
            distances = cdist(person_array, clothing_array)
            correspondences = []
            
            # í—ê°€ë¦¬ì•ˆ ì•Œê³ ë¦¬ì¦˜ ëŒ€ì‹  íƒìš•ì  ìµœì í™” + ê¸°í•˜í•™ì  ê²€ì¦
            used_clothing = set()
            used_person = set()
            
            # ê±°ë¦¬ ìˆœìœ¼ë¡œ ì •ë ¬ëœ ëª¨ë“  ìŒ
            pairs = []
            for i, person_pt in enumerate(person_array):
                for j, clothing_pt in enumerate(clothing_array):
                    distance = distances[i, j]
                    pairs.append((distance, i, j, person_pt, clothing_pt))
            
            pairs.sort()  # ê±°ë¦¬ ìˆœìœ¼ë¡œ ì •ë ¬
            
            for distance, i, j, person_pt, clothing_pt in pairs:
                if i not in used_person and j not in used_clothing:
                    # ê¸°í•˜í•™ì  ì¼ê´€ì„± ê²€ì‚¬ (M3 Max ì „ìš©)
                    if self._is_geometrically_consistent(person_pt, clothing_pt, correspondences):
                        correspondences.append((person_pt, clothing_pt))
                        used_person.add(i)
                        used_clothing.add(j)
                        
                        # M3 MaxëŠ” ë” ë§ì€ ëŒ€ì‘ì  í™œìš©
                        if len(correspondences) >= min(len(person_array), len(clothing_array), 8):
                            break
            
            return correspondences
            
        except Exception as e:
            self.logger.warning(f"ìµœì  ëŒ€ì‘ì  ì°¾ê¸° ì‹¤íŒ¨: {e}")
            # ê¸°ë³¸ ëŒ€ì‘ì  ë°˜í™˜
            min_points = min(len(person_array), len(clothing_array))
            return [(person_array[i], clothing_array[i]) for i in range(min_points)]
    
    def _is_geometrically_consistent(self, person_pt: np.ndarray, clothing_pt: np.ndarray, existing_correspondences: List) -> bool:
        """ê¸°í•˜í•™ì  ì¼ê´€ì„± ê²€ì‚¬ (M3 Max ì „ìš©)"""
        
        if len(existing_correspondences) < 2:
            return True
        
        try:
            # ê°ë„ ì¼ê´€ì„± ê²€ì‚¬
            for p1, c1 in existing_correspondences[-2:]:
                # ì¸ì²´ í¬ì¸íŠ¸ë“¤ ê°„ì˜ ê°ë„
                person_angle = np.arctan2(person_pt[1] - p1[1], person_pt[0] - p1[0])
                # ì˜ë¥˜ í¬ì¸íŠ¸ë“¤ ê°„ì˜ ê°ë„
                clothing_angle = np.arctan2(clothing_pt[1] - c1[1], clothing_pt[0] - c1[0])
                
                # ê°ë„ ì°¨ì´ (ë¼ë””ì•ˆ)
                angle_diff = abs(person_angle - clothing_angle)
                if angle_diff > np.pi:
                    angle_diff = 2 * np.pi - angle_diff
                
                # M3 MaxëŠ” ë” ì—„ê²©í•œ ê¸°í•˜í•™ì  ì œì•½
                if angle_diff > np.pi / 3:  # 60ë„ ì´ìƒ ì°¨ì´ë‚˜ë©´ ê±°ë¶€
                    return False
            
            return True
            
        except Exception as e:
            self.logger.warning(f"ê¸°í•˜í•™ì  ì¼ê´€ì„± ê²€ì‚¬ ì‹¤íŒ¨: {e}")
            return True
    
    def _compute_advanced_tps_transform(self, source_pts: np.ndarray, target_pts: np.ndarray) -> Dict[str, Any]:
        """ê³ ê¸‰ TPS ë³€í™˜ ê³„ì‚° (M3 Max ì „ìš©)"""
        
        try:
            n = len(source_pts)
            
            # TPS ê¸°ë³¸ í•¨ìˆ˜ (ê°œì„ ëœ U í•¨ìˆ˜)
            def U(r):
                # M3 Maxìš© ê³ ì •ë°€ë„ TPS í•¨ìˆ˜
                return np.where(r < 1e-8, 0, r**2 * np.log(r**2 + 1e-12))
            
            # ê±°ë¦¬ í–‰ë ¬ ê³„ì‚° (ê³ ì •ë°€ë„)
            if SCIPY_AVAILABLE:
                distances = cdist(source_pts, source_pts)
            else:
                distances = np.sqrt(((source_pts[:, np.newaxis] - source_pts[np.newaxis, :])**2).sum(axis=2))
            
            # K í–‰ë ¬ (ê¸°ë³¸ í•¨ìˆ˜ë“¤ì˜ ê°’)
            K = U(distances)
            
            # ì •ê·œí™” ì¶”ê°€ (M3 Max ì „ìš©)
            regularization = self.tps_config['regularization'] * 0.5  # M3 MaxëŠ” ë” ë‚®ì€ ì •ê·œí™”
            K += regularization * np.eye(n)
            
            # P í–‰ë ¬ (affine ë¶€ë¶„ì„ ìœ„í•œ ë‹¤í•­ì‹ ê¸°ì €)
            P = np.column_stack([np.ones(n), source_pts])
            
            # L í–‰ë ¬ êµ¬ì„±
            O = np.zeros((3, 3))
            L = np.block([[K, P], [P.T, O]])
            
            # ëª©í‘œ ì ë“¤ì„ í™•ì¥
            Y = np.vstack([target_pts.T, np.zeros((3, 2))])
            
            # ì„ í˜• ì‹œìŠ¤í…œ í•´ê²° (ê³ ì •ë°€ë„)
            try:
                coeffs = np.linalg.solve(L, Y)
            except np.linalg.LinAlgError:
                # íŠ¹ì´ í–‰ë ¬ì¸ ê²½ìš° SVD ê¸°ë°˜ pseudo-inverse ì‚¬ìš©
                U_svd, s, Vt = np.linalg.svd(L, full_matrices=False)
                s_inv = np.where(s > 1e-10, 1/s, 0)
                coeffs = Vt.T @ np.diag(s_inv) @ U_svd.T @ Y
            
            # ê³„ìˆ˜ ë¶„ë¦¬
            w = coeffs[:n]  # TPS ê°€ì¤‘ì¹˜
            a = coeffs[n:]  # affine ê³„ìˆ˜
            
            return {
                'source_points': source_pts.tolist(),
                'weights': w.tolist(),
                'affine_coeffs': a.tolist(),
                'regularization': regularization,
                'advanced_mode': True,
                'm3_max_precision': True
            }
            
        except Exception as e:
            self.logger.error(f"ê³ ê¸‰ TPS ë³€í™˜ ê³„ì‚° ì‹¤íŒ¨: {e}")
            # ê¸°ë³¸ TPSë¡œ í´ë°±
            return self._compute_tps_transform(source_pts, target_pts)
    
    async def _tps_matching(self, person_points: List, clothing_points: List) -> Dict[str, Any]:
        """Thin Plate Spline ë§¤ì¹­"""
        
        try:
            if not SCIPY_AVAILABLE:
                raise ImportError("SciPy ì—†ì´ëŠ” TPS ì‚¬ìš© ë¶ˆê°€")
            
            # ëŒ€ì‘ì  ìŒ ìƒì„±
            person_array = np.array(person_points)
            clothing_array = np.array(clothing_points)
            
            # ìµœì†Œ ê°œìˆ˜ì— ë§ì¶° ëŒ€ì‘
            min_points = min(len(person_array), len(clothing_array))
            person_array = person_array[:min_points]
            clothing_array = clothing_array[:min_points]
            
            # ê±°ë¦¬ ê¸°ë°˜ ëŒ€ì‘ ì°¾ê¸°
            distances = cdist(person_array, clothing_array)
            correspondences = []
            
            used_clothing = set()
            for i, person_pt in enumerate(person_array):
                distances_to_clothing = distances[i]
                sorted_indices = np.argsort(distances_to_clothing)
                
                for clothing_idx in sorted_indices:
                    if clothing_idx not in used_clothing:
                        correspondences.append((person_pt, clothing_array[clothing_idx]))
                        used_clothing.add(clothing_idx)
                        break
            
            if len(correspondences) >= 3:
                source_pts = np.array([corr[1] for corr in correspondences])  # ì˜ë¥˜ ì ë“¤
                target_pts = np.array([corr[0] for corr in correspondences])  # ì¸ì²´ ì ë“¤
                
                tps_transform = self._compute_tps_transform(source_pts, target_pts)
                
                return {
                    'method': 'tps',
                    'transform': tps_transform,
                    'correspondences': correspondences,
                    'source_points': source_pts.tolist(),
                    'target_points': target_pts.tolist(),
                    'confidence': 0.9,
                    'success': True
                }
            else:
                raise ValueError("TPSë¥¼ ìœ„í•œ ì¶©ë¶„í•œ ëŒ€ì‘ì ì´ ì—†ìŒ")
                
        except Exception as e:
            self.logger.warning(f"TPS ë§¤ì¹­ ì‹¤íŒ¨: {e}")
            raise
    
    def _compute_tps_transform(self, source_pts: np.ndarray, target_pts: np.ndarray) -> Dict[str, Any]:
        """TPS ë³€í™˜ ë§¤ê°œë³€ìˆ˜ ê³„ì‚°"""
        
        try:
            n = len(source_pts)
            
            # TPS ê¸°ë³¸ í•¨ìˆ˜ (U í•¨ìˆ˜: r^2 * log(r))
            def U(r):
                return np.where(r == 0, 0, r**2 * np.log(r + 1e-10))
            
            # ê±°ë¦¬ í–‰ë ¬ ê³„ì‚°
            if SCIPY_AVAILABLE:
                distances = cdist(source_pts, source_pts)
            else:
                # SciPy ì—†ì´ ê³„ì‚°
                distances = np.sqrt(((source_pts[:, np.newaxis] - source_pts[np.newaxis, :])**2).sum(axis=2))
            
            # K í–‰ë ¬ (ê¸°ë³¸ í•¨ìˆ˜ë“¤ì˜ ê°’)
            K = U(distances)
            
            # P í–‰ë ¬ (affine ë¶€ë¶„ì„ ìœ„í•œ ë‹¤í•­ì‹ ê¸°ì €)
            P = np.column_stack([np.ones(n), source_pts])
            
            # L í–‰ë ¬ êµ¬ì„±
            O = np.zeros((3, 3))
            L = np.block([[K, P], [P.T, O]])
            
            # ëª©í‘œ ì ë“¤ì„ í™•ì¥
            Y = np.vstack([target_pts.T, np.zeros((3, 2))])
            
            # ì„ í˜• ì‹œìŠ¤í…œ í•´ê²°
            try:
                coeffs = np.linalg.solve(L, Y)
            except np.linalg.LinAlgError:
                # íŠ¹ì´ í–‰ë ¬ì¸ ê²½ìš° pseudo-inverse ì‚¬ìš©
                coeffs = np.linalg.pinv(L) @ Y
            
            # ê³„ìˆ˜ ë¶„ë¦¬
            w = coeffs[:n]  # TPS ê°€ì¤‘ì¹˜
            a = coeffs[n:]  # affine ê³„ìˆ˜
            
            return {
                'source_points': source_pts.tolist(),
                'weights': w.tolist(),
                'affine_coeffs': a.tolist(),
                'regularization': self.tps_config['regularization']
            }
            
        except Exception as e:
            self.logger.error(f"TPS ë³€í™˜ ê³„ì‚° ì‹¤íŒ¨: {e}")
            # í´ë°±: ë‹¨ìœ„ ë³€í™˜
            return {
                'source_points': source_pts.tolist(),
                'weights': np.zeros((len(source_pts), 2)).tolist(),
                'affine_coeffs': np.array([[1, 0, 0], [0, 1, 0]]).tolist(),
                'regularization': 0.0
            }
    
    def _homography_matching(self, person_points: List, clothing_points: List) -> Dict[str, Any]:
        """Homography ë§¤ì¹­"""
        
        try:
            person_array = np.array(person_points, dtype=np.float32)
            clothing_array = np.array(clothing_points, dtype=np.float32)
            
            # ìµœì†Œ 4ê°œ ì  í•„ìš”
            min_points = min(len(person_array), len(clothing_array), 4)
            
            if min_points < 4:
                raise ValueError("Homographyë¥¼ ìœ„í•œ ì¶©ë¶„í•œ ì ì´ ì—†ìŒ")
            
            # ì²« 4ê°œ ì  ì‚¬ìš©
            src_pts = clothing_array[:min_points]
            dst_pts = person_array[:min_points]
            
            # Homography ê³„ì‚°
            H, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)
            
            if H is None:
                raise ValueError("Homography ê³„ì‚° ì‹¤íŒ¨")
            
            return {
                'method': 'homography',
                'transform': H.tolist(),
                'source_points': src_pts.tolist(),
                'target_points': dst_pts.tolist(),
                'inlier_mask': mask.flatten().tolist() if mask is not None else [],
                'confidence': 0.8,
                'success': True
            }
            
        except Exception as e:
            self.logger.warning(f"Homography ë§¤ì¹­ ì‹¤íŒ¨: {e}")
            raise
    
    def _affine_matching(self, person_points: List, clothing_points: List) -> Dict[str, Any]:
        """Affine ë³€í™˜ ë§¤ì¹­"""
        
        try:
            person_array = np.array(person_points, dtype=np.float32)
            clothing_array = np.array(clothing_points, dtype=np.float32)
            
            # ìµœì†Œ 3ê°œ ì  í•„ìš”
            min_points = min(len(person_array), len(clothing_array), 3)
            
            if min_points < 3:
                raise ValueError("Affine ë³€í™˜ì„ ìœ„í•œ ì¶©ë¶„í•œ ì ì´ ì—†ìŒ")
            
            # ì²« 3ê°œ ì  ì‚¬ìš©
            src_pts = clothing_array[:min_points]
            dst_pts = person_array[:min_points]
            
            # Affine ë³€í™˜ ê³„ì‚°
            M = cv2.getAffineTransform(src_pts[:3], dst_pts[:3])
            
            return {
                'method': 'affine',
                'transform': M.tolist(),
                'source_points': src_pts.tolist(),
                'target_points': dst_pts.tolist(),
                'confidence': 0.7,
                'success': True
            }
            
        except Exception as e:
            self.logger.warning(f"Affine ë§¤ì¹­ ì‹¤íŒ¨: {e}")
            raise
    
    def _similarity_matching(self, person_points: List, clothing_points: List) -> Dict[str, Any]:
        """ìœ ì‚¬ì„± ë³€í™˜ ë§¤ì¹­ (íšŒì „, ìŠ¤ì¼€ì¼, í‰í–‰ì´ë™)"""
        
        try:
            if len(person_points) < 1 or len(clothing_points) < 1:
                # ìµœì†Œ ë³€í™˜: ë‹¨ìœ„ ë³€í™˜
                M = np.array([[1, 0, 0], [0, 1, 0]], dtype=np.float32)
            elif len(person_points) < 2 or len(clothing_points) < 2:
                # ìµœì†Œ ë³€í™˜: í‰í–‰ì´ë™ë§Œ
                tx = person_points[0][0] - clothing_points[0][0]
                ty = person_points[0][1] - clothing_points[0][1]
                M = np.array([[1, 0, tx], [0, 1, ty]], dtype=np.float32)
            else:
                # ì¤‘ì‹¬ì  ê¸°ë°˜ ë³€í™˜
                person_center = np.mean(person_points, axis=0)
                clothing_center = np.mean(clothing_points, axis=0)
                
                # ìŠ¤ì¼€ì¼ ì¶”ì •
                person_spread = np.std(person_points, axis=0)
                clothing_spread = np.std(clothing_points, axis=0)
                
                scale_x = person_spread[0] / (clothing_spread[0] + 1e-6)
                scale_y = person_spread[1] / (clothing_spread[1] + 1e-6)
                scale = (scale_x + scale_y) / 2  # í‰ê·  ìŠ¤ì¼€ì¼
                
                # í‰í–‰ì´ë™
                tx = person_center[0] - clothing_center[0] * scale
                ty = person_center[1] - clothing_center[1] * scale
                
                M = np.array([[scale, 0, tx], [0, scale, ty]], dtype=np.float32)
            
            return {
                'method': 'similarity',
                'transform': M.tolist(),
                'source_points': clothing_points[:2] if len(clothing_points) >= 2 else clothing_points,
                'target_points': person_points[:2] if len(person_points) >= 2 else person_points,
                'confidence': 0.6,
                'success': True
            }
            
        except Exception as e:
            self.logger.warning(f"ìœ ì‚¬ì„± ë³€í™˜ ì‹¤íŒ¨: {e}")
            # ìµœí›„ì˜ í´ë°±: ë‹¨ìœ„ ë³€í™˜
            return {
                'method': 'identity',
                'transform': [[1, 0, 0], [0, 1, 0]],
                'source_points': [],
                'target_points': [],
                'confidence': 0.3,
                'success': True
            }
    
    async def _refine_with_pose_guidance(
        self, 
        initial_match: Dict[str, Any], 
        pose_keypoints: List[List[float]], 
        clothing_type: str
    ) -> Dict[str, Any]:
        """í¬ì¦ˆ ê¸°ë°˜ ë§¤ì¹­ ì •ì œ"""
        
        try:
            # í¬ì¦ˆ íŠ¹ì„± ë¶„ì„
            pose_analysis = self._analyze_pose_characteristics(pose_keypoints)
            
            # ì˜ë¥˜ íƒ€ì…ë³„ í¬ì¦ˆ ì ì‘
            adaptation_factor = self._calculate_pose_adaptation(pose_analysis, clothing_type)
            
            # ë³€í™˜ ë§¤ê°œë³€ìˆ˜ ì¡°ì •
            refined_transform = self._adapt_transform_to_pose(
                initial_match['transform'], adaptation_factor, pose_analysis
            )
            
            refined_match = initial_match.copy()
            refined_match['transform'] = refined_transform
            refined_match['pose_adapted'] = True
            refined_match['adaptation_factor'] = adaptation_factor
            
            return refined_match
            
        except Exception as e:
            self.logger.warning(f"í¬ì¦ˆ ê¸°ë°˜ ì •ì œ ì‹¤íŒ¨: {e}")
            return initial_match
    
    def _analyze_pose_characteristics(self, pose_keypoints: List[List[float]]) -> Dict[str, Any]:
        """í¬ì¦ˆ íŠ¹ì„± ë¶„ì„"""
        
        analysis = {}
        
        try:
            # ì–´ê¹¨ ê°ë„
            if len(pose_keypoints) > 5 and all(pose_keypoints[i][2] > 0.5 for i in [2, 5]):
                left_shoulder = pose_keypoints[5][:2]
                right_shoulder = pose_keypoints[2][:2]
                shoulder_angle = np.degrees(np.arctan2(
                    left_shoulder[1] - right_shoulder[1],
                    left_shoulder[0] - right_shoulder[0]
                ))
                analysis['shoulder_angle'] = shoulder_angle
            
            # ëª¸í†µ ê¸°ìš¸ê¸°
            if len(pose_keypoints) > 11 and all(pose_keypoints[i][2] > 0.5 for i in [1, 8, 11]):
                neck = pose_keypoints[1][:2]
                hip_center = np.mean([pose_keypoints[8][:2], pose_keypoints[11][:2]], axis=0)
                torso_angle = np.degrees(np.arctan2(
                    neck[0] - hip_center[0],
                    hip_center[1] - neck[1]
                ))
                analysis['torso_angle'] = torso_angle
            
        except Exception as e:
            self.logger.warning(f"í¬ì¦ˆ íŠ¹ì„± ë¶„ì„ ì‹¤íŒ¨: {e}")
        
        return analysis
    
    def _calculate_pose_adaptation(self, pose_analysis: Dict[str, Any], clothing_type: str) -> Dict[str, float]:
        """í¬ì¦ˆ ì ì‘ ì¸ìˆ˜ ê³„ì‚°"""
        
        adaptation = {
            'scale_factor': 1.0,
            'rotation_adjustment': 0.0,
            'shear_factor': 0.0
        }
        
        try:
            # ì–´ê¹¨ ê¸°ìš¸ê¸°ì— ë”°ë¥¸ íšŒì „ ì¡°ì •
            if 'shoulder_angle' in pose_analysis:
                shoulder_angle = pose_analysis['shoulder_angle']
                adaptation['rotation_adjustment'] = -shoulder_angle * 0.3
            
            # ëª¸í†µ ê¸°ìš¸ê¸°ì— ë”°ë¥¸ ì „ë‹¨ ì¡°ì •
            if 'torso_angle' in pose_analysis:
                torso_angle = pose_analysis['torso_angle']
                adaptation['shear_factor'] = np.tan(np.radians(torso_angle)) * 0.2
            
        except Exception as e:
            self.logger.warning(f"í¬ì¦ˆ ì ì‘ ê³„ì‚° ì‹¤íŒ¨: {e}")
        
        return adaptation
    
    def _adapt_transform_to_pose(
        self, 
        original_transform: List[List[float]], 
        adaptation_factor: Dict[str, float], 
        pose_analysis: Dict[str, Any]
    ) -> List[List[float]]:
        """í¬ì¦ˆì— ë§ê²Œ ë³€í™˜ ì¡°ì •"""
        
        try:
            transform = np.array(original_transform)
            
            # íšŒì „ ì¡°ì •
            rotation_adj = adaptation_factor.get('rotation_adjustment', 0.0)
            if abs(rotation_adj) > 0.1:
                cos_r = np.cos(np.radians(rotation_adj))
                sin_r = np.sin(np.radians(rotation_adj))
                rotation_matrix = np.array([[cos_r, -sin_r, 0], [sin_r, cos_r, 0], [0, 0, 1]])
                
                if transform.shape[0] == 2:  # Affine transform
                    transform = np.vstack([transform, [0, 0, 1]])
                    transform = rotation_matrix @ transform
                    transform = transform[:2]
            
            # ìŠ¤ì¼€ì¼ ì¡°ì •
            scale_factor = adaptation_factor.get('scale_factor', 1.0)
            if abs(scale_factor - 1.0) > 0.01:
                if transform.shape[0] == 2:  # Affine
                    transform[0, 0] *= scale_factor
                    transform[1, 1] *= scale_factor
            
            return transform.tolist()
            
        except Exception as e:
            self.logger.warning(f"ë³€í™˜ í¬ì¦ˆ ì ì‘ ì‹¤íŒ¨: {e}")
            return original_transform
    
    def _evaluate_matching_quality(
        self, 
        person_points: List, 
        clothing_points: List, 
        match_result: Dict[str, Any]
    ) -> Dict[str, float]:
        """ë§¤ì¹­ í’ˆì§ˆ í‰ê°€"""
        
        try:
            transform = np.array(match_result['transform'])
            method = match_result['method']
            
            # 1. ì¬íˆ¬ì˜ ì˜¤ì°¨ ê³„ì‚°
            reprojection_error = self._calculate_reprojection_error(
                clothing_points, person_points, transform, method
            )
            
            # 2. ê¸°í•˜í•™ì  ì¼ê´€ì„±
            geometric_consistency = self._evaluate_geometric_consistency(transform, method)
            
            # 3. ë³€í™˜ ì•ˆì •ì„±
            transform_stability = self._evaluate_transform_stability(transform, method)
            
            # 4. ëŒ€ì‘ì  ì‹ ë¢°ë„
            correspondence_confidence = match_result.get('confidence', 0.5)
            
            # 5. ì „ì²´ í’ˆì§ˆ ì ìˆ˜
            overall_quality = (
                (1.0 - min(1.0, reprojection_error)) * 0.4 +
                geometric_consistency * 0.3 +
                transform_stability * 0.2 +
                correspondence_confidence * 0.1
            )
            
            return {
                'overall_quality': max(0.0, min(1.0, overall_quality)),
                'reprojection_error': min(1.0, reprojection_error),
                'geometric_consistency': geometric_consistency,
                'transform_stability': transform_stability,
                'correspondence_confidence': correspondence_confidence,
                'quality_grade': self._get_quality_grade(overall_quality)
            }
            
        except Exception as e:
            self.logger.warning(f"í’ˆì§ˆ í‰ê°€ ì‹¤íŒ¨: {e}")
            return {
                'overall_quality': 0.5,
                'reprojection_error': 1.0,
                'geometric_consistency': 0.0,
                'transform_stability': 0.0,
                'correspondence_confidence': 0.0,
                'quality_grade': 'poor'
            }
    
    def _calculate_reprojection_error(
        self, 
        source_points: List, 
        target_points: List, 
        transform: np.ndarray, 
        method: str
    ) -> float:
        """ì¬íˆ¬ì˜ ì˜¤ì°¨ ê³„ì‚°"""
        
        try:
            if not source_points or not target_points:
                return 1.0
            
            source_array = np.array(source_points)
            target_array = np.array(target_points)
            
            # ë³€í™˜ ì ìš©
            if method == 'tps':
                # TPSëŠ” ë³„ë„ ì²˜ë¦¬ í•„ìš” (ì—¬ê¸°ì„œëŠ” ê°„ë‹¨í™”)
                projected_points = source_array
            elif method in ['homography']:
                if transform.shape == (3, 3):
                    # ë™ì°¨ ì¢Œí‘œë¡œ ë³€í™˜
                    source_homo = np.column_stack([source_array, np.ones(len(source_array))])
                    projected_homo = source_homo @ transform.T
                    projected_points = projected_homo[:, :2] / (projected_homo[:, 2:3] + 1e-8)
                else:
                    projected_points = source_array
            else:  # affine, similarity
                if transform.shape == (2, 3):
                    source_homo = np.column_stack([source_array, np.ones(len(source_array))])
                    projected_points = source_homo @ transform.T
                else:
                    projected_points = source_array
            
            # ê°€ì¥ ê°€ê¹Œìš´ ëŒ€ì‘ì ë“¤ ì°¾ê¸°
            min_len = min(len(projected_points), len(target_array))
            if min_len == 0:
                return 1.0
            
            if SCIPY_AVAILABLE:
                distances = cdist(projected_points[:min_len], target_array[:min_len])
                min_distances = np.min(distances, axis=1)
            else:
                # SciPy ì—†ì´ ê³„ì‚°
                min_distances = []
                for p in projected_points[:min_len]:
                    dists = [np.linalg.norm(p - t) for t in target_array[:min_len]]
                    min_distances.append(min(dists))
                min_distances = np.array(min_distances)
            
            avg_error = np.mean(min_distances)
            
            # ì •ê·œí™” (ì´ë¯¸ì§€ í¬ê¸° ëŒ€ë¹„)
            if target_array.size > 0:
                image_diagonal = np.linalg.norm(np.ptp(target_array, axis=0))
                normalized_error = avg_error / (image_diagonal + 1e-6)
            else:
                normalized_error = 1.0
            
            return min(1.0, normalized_error)
            
        except Exception as e:
            self.logger.warning(f"ì¬íˆ¬ì˜ ì˜¤ì°¨ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return 1.0
    
    def _evaluate_geometric_consistency(self, transform: np.ndarray, method: str) -> float:
        """ê¸°í•˜í•™ì  ì¼ê´€ì„± í‰ê°€"""
        
        try:
            if method == 'tps':
                return 0.9  # TPSëŠ” í•­ìƒ ì¼ê´€ì„± ìˆìŒ
            
            if transform.shape[0] < 2:
                return 0.0
            
            # í–‰ë ¬ì‹ ê³„ì‚° (ìŠ¤ì¼€ì¼ ë³€í™”)
            if transform.shape == (2, 3):  # Affine
                det = np.linalg.det(transform[:2, :2])
            elif transform.shape == (3, 3):  # Homography
                det = np.linalg.det(transform[:2, :2])
            else:
                return 0.5
            
            # í•©ë¦¬ì ì¸ ìŠ¤ì¼€ì¼ ë³€í™”ì¸ì§€ í™•ì¸ (0.1 ~ 10 ë°°)
            if 0.1 <= abs(det) <= 10:
                scale_consistency = 1.0
            else:
                scale_consistency = 0.0
            
            return scale_consistency
            
        except Exception as e:
            self.logger.warning(f"ê¸°í•˜í•™ì  ì¼ê´€ì„± í‰ê°€ ì‹¤íŒ¨: {e}")
            return 0.5
    
    def _evaluate_transform_stability(self, transform: np.ndarray, method: str) -> float:
        """ë³€í™˜ ì•ˆì •ì„± í‰ê°€"""
        
        try:
            # ì¡°ê±´ìˆ˜ í™•ì¸
            if transform.shape == (2, 3):  # Affine
                matrix_part = transform[:2, :2]
            elif transform.shape == (3, 3):  # Homography
                matrix_part = transform[:2, :2]
            else:
                return 0.5
            
            condition_number = np.linalg.cond(matrix_part)
            
            # ì¡°ê±´ìˆ˜ê°€ ë‚®ì„ìˆ˜ë¡ ì•ˆì •ì 
            if condition_number < 10:
                stability = 1.0
            elif condition_number < 100:
                stability = 0.8
            elif condition_number < 1000:
                stability = 0.5
            else:
                stability = 0.2
            
            return stability
            
        except Exception as e:
            self.logger.warning(f"ë³€í™˜ ì•ˆì •ì„± í‰ê°€ ì‹¤íŒ¨: {e}")
            return 0.5
    
    def _get_quality_grade(self, overall_quality: float) -> str:
        """í’ˆì§ˆ ë“±ê¸‰ ë°˜í™˜"""
        if overall_quality >= 0.9:
            return "excellent"
        elif overall_quality >= 0.8:
            return "good"
        elif overall_quality >= 0.6:
            return "fair"
        elif overall_quality >= 0.4:
            return "poor"
        else:
            return "very_poor"
    
    async def _try_alternative_methods(
        self, 
        person_points: List, 
        clothing_points: List, 
        clothing_type: str
    ) -> Optional[Dict[str, Any]]:
        """ëŒ€ì•ˆ ë§¤ì¹­ ë°©ë²•ë“¤ ì‹œë„"""
        
        alternative_methods = ['affine', 'similarity', 'homography']
        best_result = None
        best_quality = 0.0
        
        for method in alternative_methods:
            try:
                result = await self._perform_initial_matching(person_points, clothing_points, method)
                quality = self._evaluate_matching_quality(person_points, clothing_points, result)
                
                if quality['overall_quality'] > best_quality:
                    best_quality = quality['overall_quality']
                    best_result = result
                    
                self.logger.debug(f"ëŒ€ì•ˆ ë°©ë²• {method}: í’ˆì§ˆ {quality['overall_quality']:.3f}")
                
            except Exception as e:
                self.logger.warning(f"ëŒ€ì•ˆ ë°©ë²• {method} ì‹¤íŒ¨: {e}")
                continue
        
        return best_result
    
    def _generate_warp_parameters(self, match_result: Dict[str, Any], clothing_segmentation: Dict[str, Any]) -> Dict[str, Any]:
        """ì›Œí•‘ íŒŒë¼ë¯¸í„° ìƒì„±"""
        
        try:
            transform = match_result['transform']
            method = match_result['method']
            
            # ê¸°ë³¸ ì›Œí•‘ íŒŒë¼ë¯¸í„°
            warp_params = {
                'transform_matrix': transform,
                'transform_method': method,
                'interpolation': 'bilinear',
                'border_mode': 'reflect',
                'output_size': None  # ì›ë³¸ í¬ê¸° ìœ ì§€
            }
            
            # ì˜ë¥˜ ë§ˆìŠ¤í¬ ì •ë³´ ì¶”ê°€
            if 'mask' in clothing_segmentation:
                mask = clothing_segmentation['mask']
                warp_params['mask_transform'] = transform
                
                if hasattr(mask, 'shape'):
                    warp_params['original_mask_size'] = mask.shape
                elif hasattr(mask, 'size'):
                    warp_params['original_mask_size'] = mask.size
            
            # ë°©ë²•ë³„ íŠ¹í™” íŒŒë¼ë¯¸í„°
            if method == 'tps' and isinstance(transform, dict):
                warp_params.update({
                    'source_points': transform.get('source_points', []),
                    'tps_weights': transform.get('weights', []),
                    'tps_affine': transform.get('affine_coeffs', [])
                })
            
            return warp_params
            
        except Exception as e:
            self.logger.warning(f"ì›Œí•‘ íŒŒë¼ë¯¸í„° ìƒì„± ì‹¤íŒ¨: {e}")
            return {
                'transform_matrix': [[1, 0, 0], [0, 1, 0]],
                'transform_method': 'identity',
                'interpolation': 'bilinear',
                'border_mode': 'reflect'
            }
    
    def _build_final_result(
        self,
        match_result: Dict[str, Any],
        warp_params: Dict[str, Any],
        quality_metrics: Dict[str, float],
        processing_time: float,
        method: str,
        clothing_type: str
    ) -> Dict[str, Any]:
        """ìµœì¢… ê²°ê³¼ êµ¬ì„± (M3 Max ì •ë³´ ì¶”ê°€)"""
        
        return {
            'success': match_result.get('success', True),
            'transform_matrix': match_result['transform'],
            'warp_matrix': match_result['transform'],  # í˜¸í™˜ì„±ì„ ìœ„í•œ ì¤‘ë³µ
            'warp_parameters': warp_params,
            'matching_method': method,
            'clothing_type': clothing_type,
            'quality_metrics': quality_metrics,
            'confidence': quality_metrics['overall_quality'],
            'processing_time': processing_time,
            'matching_info': {
                'source_points': match_result.get('source_points', []),
                'target_points': match_result.get('target_points', []),
                'correspondences': match_result.get('correspondences', []),
                'pose_adapted': match_result.get('pose_adapted', False),
                'method_used': method,
                'm3_max_optimized': match_result.get('m3_max_optimized', False),
                'optimal_constructor': True  # ìµœì  ìƒì„±ì ì‚¬ìš© í‘œì‹œ
            },
            'geometric_analysis': {
                'reprojection_error': quality_metrics['reprojection_error'],
                'geometric_consistency': quality_metrics['geometric_consistency'],
                'transform_stability': quality_metrics['transform_stability'],
                'quality_grade': quality_metrics['quality_grade']
            }
        }
    
    def _create_empty_result(self, reason: str, clothing_type: str = "unknown") -> Dict[str, Any]:
        """ë¹ˆ ê²°ê³¼ ìƒì„±"""
        return {
            'success': False,
            'error': reason,
            'transform_matrix': [[1, 0, 0], [0, 1, 0]],
            'warp_matrix': [[1, 0, 0], [0, 1, 0]],
            'warp_parameters': {
                'transform_matrix': [[1, 0, 0], [0, 1, 0]],
                'transform_method': 'identity',
                'interpolation': 'bilinear'
            },
            'matching_method': 'none',
            'clothing_type': clothing_type,
            'quality_metrics': {
                'overall_quality': 0.0,
                'quality_grade': 'failed'
            },
            'confidence': 0.0,
            'processing_time': 0.0,
            'matching_info': {
                'error_occurred': True,
                'error_message': reason,
                'method_used': 'none',
                'optimal_constructor': True
            }
        }
    
    def _update_statistics(self, method: str, quality: float):
        """í†µê³„ ì—…ë°ì´íŠ¸"""
        try:
            self.matching_stats['total_matches'] += 1
            
            if quality > 0.6:
                self.matching_stats['successful_matches'] += 1
            
            # í’ˆì§ˆ ì´ë™ í‰ê· 
            alpha = 0.1
            self.matching_stats['average_accuracy'] = (
                alpha * quality + 
                (1 - alpha) * self.matching_stats['average_accuracy']
            )
            
            # ë°©ë²•ë³„ ì„±ëŠ¥ ì¶”ì 
            if method not in self.matching_stats['method_performance']:
                self.matching_stats['method_performance'][method] = {'count': 0, 'avg_quality': 0.0}
            
            method_stats = self.matching_stats['method_performance'][method]
            method_stats['count'] += 1
            method_stats['avg_quality'] = (
                (method_stats['avg_quality'] * (method_stats['count'] - 1) + quality) / 
                method_stats['count']
            )
            
        except Exception as e:
            self.logger.warning(f"í†µê³„ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
    
    async def cleanup(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        try:
            # ìºì‹œëœ ë°ì´í„° ì •ë¦¬
            if hasattr(self, 'tps_grid'):
                self.tps_grid = None
            
            # í†µê³„ ì´ˆê¸°í™”
            self.matching_stats = {
                'total_matches': 0,
                'successful_matches': 0,
                'average_accuracy': 0.0,
                'method_performance': {}
            }
            
            self.is_initialized = False
            self.logger.info("ğŸ§¹ ê¸°í•˜í•™ì  ë§¤ì¹­ ìŠ¤í… ì •ë¦¬ ì™„ë£Œ")
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
    
    # ìµœì  íŒ¨í„´ í˜¸í™˜ ë©”ì„œë“œë“¤
    async def get_step_info(self) -> Dict[str, Any]:
        """ğŸ” ìŠ¤í… ì •ë³´ ë°˜í™˜ (ìµœì  íŒ¨í„´ í˜¸í™˜)"""
        return {
            "step_name": "GeometricMatching",
            "class_name": self.__class__.__name__,
            "version": "3.0-optimal",
            "device": self.device,
            "device_type": self.device_type,
            "memory_gb": self.memory_gb,
            "is_m3_max": self.is_m3_max,
            "optimization_enabled": self.optimization_enabled,
            "quality_level": self.quality_level,
            "initialized": self.is_initialized,
            "initialization_error": self.initialization_error,
            "optimal_constructor": True,
            "capabilities": {
                "tps_matching": SCIPY_AVAILABLE,
                "tps_advanced_matching": SCIPY_AVAILABLE and self.is_m3_max,
                "homography_matching": True,
                "affine_matching": True,
                "similarity_matching": True,
                "pose_guidance": True,
                "m3_max_acceleration": self.is_m3_max
            },
            "performance_stats": self.matching_stats,
            "dependencies": {
                "opencv": True,
                "numpy": True,
                "scipy": SCIPY_AVAILABLE,
                "torch": TORCH_AVAILABLE
            },
            "config": {
                "matching": self.matching_config,
                "tps": self.tps_config,
                "optimization": self.optimization_config
            }
        }
    
    def get_statistics(self) -> Dict[str, Any]:
        """í†µê³„ ì •ë³´ ë°˜í™˜"""
        return self.matching_stats.copy()
    
    def reset_statistics(self):
        """í†µê³„ ì´ˆê¸°í™”"""
        self.matching_stats = {
            'total_matches': 0,
            'successful_matches': 0,
            'average_accuracy': 0.0,
            'method_performance': {}
        }


# ===============================================================
# ğŸ”„ í•˜ìœ„ í˜¸í™˜ì„± ì§€ì› (ê¸°ì¡´ ì½”ë“œ 100% ì§€ì›)
# ===============================================================

def create_geometric_matching_step(
    device: str = "mps", 
    config: Optional[Dict[str, Any]] = None
) -> GeometricMatchingStep:
    """ğŸ”„ ê¸°ì¡´ ë°©ì‹ 100% í˜¸í™˜ ìƒì„±ì"""
    return GeometricMatchingStep(device=device, config=config)

# M3 Max ìµœì í™” ì „ìš© ìƒì„±ìë„ ì§€ì›
def create_m3_max_geometric_matching_step(
    device: Optional[str] = None,
    memory_gb: float = 128.0,
    optimization_level: str = "ultra",
    **kwargs
) -> GeometricMatchingStep:
    """ğŸ M3 Max ìµœì í™” ì „ìš© ìƒì„±ì"""
    return GeometricMatchingStep(
        device=device,
        memory_gb=memory_gb,
        quality_level=optimization_level,
        is_m3_max=True,
        optimization_enabled=True,
        **kwargs
    )