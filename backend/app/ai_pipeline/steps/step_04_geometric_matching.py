#!/usr/bin/env python3
"""
ğŸ”¥ MyCloset AI - Step 04: ê¸°í•˜í•™ì  ë§¤ì¹­ v15.0 (ê³ ê¸‰ ë”¥ëŸ¬ë‹ ì•Œê³ ë¦¬ì¦˜ ì™„ì „ êµ¬í˜„)
================================================================================

âœ… step_model_requirements.py ì™„ì „ í˜¸í™˜ (REAL_STEP_MODEL_REQUESTS ê¸°ì¤€)
âœ… ì‹¤ì œ AI ëª¨ë¸ íŒŒì¼ ì™„ì „ í™œìš© (gmm_final.pth, tps_network.pth, sam_vit_h_4b8939.pth)
âœ… ê³ ê¸‰ ë”¥ëŸ¬ë‹ ì•Œê³ ë¦¬ì¦˜ ì™„ì „ êµ¬í˜„ (DeepLabV3+ + ASPP + Self-Attention)
âœ… BaseStepMixin v19.1 ì™„ì „ í˜¸í™˜ - _run_ai_inference() ë™ê¸° ì²˜ë¦¬
âœ… Procrustes ë¶„ì„ ê¸°ë°˜ ìµœì  ë³€í˜• ê³„ì‚°
âœ… RANSAC ì´ìƒì¹˜ ì œê±° ì•Œê³ ë¦¬ì¦˜
âœ… ê³ ê¸‰ í›„ì²˜ë¦¬ (ê°€ì¥ìë¦¬ ìŠ¤ë¬´ë”©, ìƒ‰ìƒ ë³´ì •, ë…¸ì´ì¦ˆ ì œê±°)
âœ… M3 Max 128GB + conda í™˜ê²½ ìµœì í™”
âœ… TYPE_CHECKING íŒ¨í„´ ìˆœí™˜ì°¸ì¡° ë°©ì§€
âœ… í”„ë¡œë•ì…˜ ë ˆë²¨ ì•ˆì •ì„±
âœ… ê°œë°œ ë„êµ¬ ë° ë””ë²„ê¹… ê¸°ëŠ¥ ì™„ì „ í¬í•¨

Author: MyCloset AI Team
Date: 2025-07-28
Version: 15.0 (Advanced Deep Learning + Production Ready)
"""

import asyncio
import os
import gc
import time
import weakref
import math
import numpy as np
from pathlib import Path
from typing import Dict, Any, Optional, Union, List, Tuple, TYPE_CHECKING
from abc import ABC, abstractmethod
from dataclasses import dataclass, field
from concurrent.futures import ThreadPoolExecutor
from functools import wraps
from enum import Enum
from io import BytesIO
import base64

import logging

# ğŸ”¥ ëª¨ë“ˆ ë ˆë²¨ logger ì•ˆì „ ì •ì˜
def create_module_logger():
    """ëª¨ë“ˆ ë ˆë²¨ logger ì•ˆì „ ìƒì„±"""
    try:
        module_logger = logging.getLogger(__name__)
        if not module_logger.handlers:
            handler = logging.StreamHandler()
            formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
            handler.setFormatter(formatter)
            module_logger.addHandler(handler)
            module_logger.setLevel(logging.INFO)
        return module_logger
    except Exception as e:
        # ìµœí›„ í´ë°±
        import sys
        print(f"âš ï¸ Logger ìƒì„± ì‹¤íŒ¨, stdout ì‚¬ìš©: {e}", file=sys.stderr)
        class FallbackLogger:
            def info(self, msg): print(f"INFO: {msg}")
            def error(self, msg): print(f"ERROR: {msg}")
            def warning(self, msg): print(f"WARNING: {msg}")
            def debug(self, msg): print(f"DEBUG: {msg}")
        return FallbackLogger()

# ëª¨ë“ˆ ë ˆë²¨ logger
logger = create_module_logger()

# ==============================================
# ğŸ”¥ 1. TYPE_CHECKING íŒ¨í„´ìœ¼ë¡œ ìˆœí™˜ì°¸ì¡° ì™„ì „ ë°©ì§€
# ==============================================

if TYPE_CHECKING:
    from app.ai_pipeline.utils.model_loader import ModelLoader
    from app.ai_pipeline.utils.memory_manager import MemoryManager
    from app.ai_pipeline.utils.data_converter import DataConverter
    from app.core.di_container import DIContainer
    from app.ai_pipeline.utils.step_model_requests import EnhancedRealModelRequest

# ==============================================
# ğŸ”¥ 2. í™˜ê²½ ìµœì í™” (M3 Max + conda ìš°ì„ )
# ==============================================

# PyTorch í™˜ê²½ ìµœì í™”
os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '1'
os.environ['PYTORCH_MPS_HIGH_WATERMARK_RATIO'] = '0.0'
os.environ['OMP_NUM_THREADS'] = '16'  # M3 Max 16ì½”ì–´

# PyTorch ë° ì´ë¯¸ì§€ ì²˜ë¦¬
try:
    import torch
    import torch.nn as nn
    import torch.nn.functional as F
    from torch.nn import Conv2d, ConvTranspose2d, BatchNorm2d, ReLU, Dropout, AdaptiveAvgPool2d
    TORCH_AVAILABLE = True
    DEVICE = "mps" if torch.backends.mps.is_available() else "cuda" if torch.cuda.is_available() else "cpu"
    MPS_AVAILABLE = DEVICE == "mps"
    
    # ğŸ”§ M3 Max ìµœì í™” (ì•ˆì „í•œ MPS ìºì‹œ ì²˜ë¦¬)
    if DEVICE == "mps":
        try:
            if hasattr(torch.backends.mps, 'empty_cache'):
                torch.backends.mps.empty_cache()
            elif hasattr(torch.mps, 'empty_cache'):
                torch.mps.empty_cache()
            torch.set_num_threads(16)
            
            # conda í™˜ê²½ MPS ìµœì í™”
            if 'CONDA_DEFAULT_ENV' in os.environ:
                conda_env = os.environ['CONDA_DEFAULT_ENV']
                if 'mycloset' in conda_env.lower():
                    os.environ['OMP_NUM_THREADS'] = '16'
                    os.environ['MKL_NUM_THREADS'] = '16'
                    logging.info(f"ğŸ conda í™˜ê²½ ({conda_env}) MPS ìµœì í™” ì™„ë£Œ")
        except Exception as e:
            logging.debug(f"âš ï¸ conda MPS ìµœì í™” ì‹¤íŒ¨: {e}")
        
except ImportError:
    TORCH_AVAILABLE = False
    DEVICE = "cpu"
    MPS_AVAILABLE = False
    logging.error("âŒ PyTorch import ì‹¤íŒ¨")

try:
    from PIL import Image, ImageDraw, ImageEnhance, ImageFilter
    import PIL
    PIL_AVAILABLE = True
except ImportError:
    PIL_AVAILABLE = False
    logging.error("âŒ PIL import ì‹¤íŒ¨")

try:
    import torchvision.transforms as T
    from torchvision.transforms.functional import resize, to_tensor, to_pil_image
    TORCHVISION_AVAILABLE = True
except ImportError:
    TORCHVISION_AVAILABLE = False

try:
    from scipy.spatial.distance import cdist
    from scipy.optimize import minimize
    from scipy.interpolate import griddata, RBFInterpolator
    import scipy.ndimage as ndimage
    SCIPY_AVAILABLE = True
except ImportError:
    SCIPY_AVAILABLE = False

try:
    import cv2
    CV2_AVAILABLE = True
except ImportError:
    CV2_AVAILABLE = False

try:
    from app.ai_pipeline.interface.step_interface import StepInterface
except ImportError:
    pass

# ==============================================
# ğŸ”¥ 3. ë™ì  import í•¨ìˆ˜ë“¤ (TYPE_CHECKING íŒ¨í„´)
# ==============================================

def get_model_loader():
    """ModelLoaderë¥¼ ì•ˆì „í•˜ê²Œ ê°€ì ¸ì˜¤ê¸°"""
    try:
        import importlib
        module = importlib.import_module('app.ai_pipeline.utils.model_loader', package=__name__)
        get_global_fn = getattr(module, 'get_global_model_loader', None)
        if get_global_fn:
            return get_global_fn()
        return None
    except ImportError as e:
        logging.error(f"âŒ ModelLoader ë™ì  import ì‹¤íŒ¨: {e}")
        return None

def get_step_model_request():
    """step_model_requestsì—ì„œ GeometricMatchingStep ìš”êµ¬ì‚¬í•­ ê°€ì ¸ì˜¤ê¸°"""
    try:
        import importlib
        module = importlib.import_module('app.ai_pipeline.utils.step_model_requests', package=__name__)
        requests = getattr(module, 'REAL_STEP_MODEL_REQUESTS', {})
        return requests.get('GeometricMatchingStep')
    except ImportError as e:
        logging.debug(f"step_model_requests import ì‹¤íŒ¨: {e}")
        return None

def get_memory_manager():
    """MemoryManagerë¥¼ ì•ˆì „í•˜ê²Œ ê°€ì ¸ì˜¤ê¸°"""
    try:
        import importlib
        module = importlib.import_module('app.ai_pipeline.utils.memory_manager', package=__name__)
        get_global_fn = getattr(module, 'get_global_memory_manager', None)
        if get_global_fn:
            return get_global_fn()
        return None
    except ImportError as e:
        logging.debug(f"MemoryManager ë™ì  import ì‹¤íŒ¨: {e}")
        return None

def get_data_converter():
    """DataConverterë¥¼ ì•ˆì „í•˜ê²Œ ê°€ì ¸ì˜¤ê¸°"""
    try:
        import importlib
        module = importlib.import_module('app.ai_pipeline.utils.data_converter', package=__name__)
        get_global_fn = getattr(module, 'get_global_data_converter', None)
        if get_global_fn:
            return get_global_fn()
        return None
    except ImportError as e:
        logging.debug(f"DataConverter ë™ì  import ì‹¤íŒ¨: {e}")
        return None

def get_di_container():
    """DI Containerë¥¼ ì•ˆì „í•˜ê²Œ ê°€ì ¸ì˜¤ê¸°"""
    try:
        import importlib
        module = importlib.import_module('app.core.di_container')
        get_global_fn = getattr(module, 'get_global_di_container', None)
        if get_global_fn:
            return get_global_fn()
        return None
    except ImportError as e:
        logging.debug(f"DI Container ë™ì  import ì‹¤íŒ¨: {e}")
        return None

# ==============================================
# ğŸ”¥ 4. BaseStepMixin ë™ì  import (ìˆœí™˜ì°¸ì¡° ë°©ì§€)
# ==============================================

def get_base_step_mixin_class():
    """BaseStepMixin í´ë˜ìŠ¤ë¥¼ ë™ì ìœ¼ë¡œ ê°€ì ¸ì˜¤ê¸°"""
    try:
        import importlib
        module = importlib.import_module('.base_step_mixin', package=__package__)
        return getattr(module, 'BaseStepMixin', None)
    except ImportError as e:
        logging.error(f"âŒ BaseStepMixin ë™ì  import ì‹¤íŒ¨: {e}")
        return None

# BaseStepMixin í´ë˜ìŠ¤ ë™ì  ë¡œë”©
BaseStepMixin = get_base_step_mixin_class()

if BaseStepMixin is None:
    # í´ë°± í´ë˜ìŠ¤ ì •ì˜
    class BaseStepMixin:
        def __init__(self, **kwargs):
            self.logger = logging.getLogger(self.__class__.__name__)
            self.step_name = kwargs.get('step_name', 'BaseStep')
            self.step_id = kwargs.get('step_id', 0)
            self.device = kwargs.get('device', 'cpu')
            self.is_initialized = False
            self.is_ready = False
            self.has_model = False
            self.model_loaded = False
            self.warmup_completed = False
        
        async def initialize(self):
            self.is_initialized = True
            return True
        
        def set_model_loader(self, model_loader):
            self.model_loader = model_loader
        
        def set_memory_manager(self, memory_manager):
            self.memory_manager = memory_manager
        
        def set_data_converter(self, data_converter):
            self.data_converter = data_converter
        
        def set_di_container(self, di_container):
            self.di_container = di_container
        
        async def cleanup(self):
            pass

# ==============================================
# ğŸ”¥ 5. EnhancedModelPathMapper (ì‹¤ì œ íŒŒì¼ ìë™ íƒì§€)
# ==============================================

class EnhancedModelPathMapper:
    """í–¥ìƒëœ ëª¨ë¸ ê²½ë¡œ ë§¤í•‘ ì‹œìŠ¤í…œ (step_model_requirements.py ê¸°ì¤€)"""
    
    def __init__(self, ai_models_root: str = "ai_models"):
        self.ai_models_root = Path(ai_models_root)
        self.model_cache = {}
        self.logger = logging.getLogger(self.__class__.__name__)
        
        # step_model_requirements.pyì—ì„œ ìš”êµ¬ì‚¬í•­ ë¡œë“œ
        self.step_request = get_step_model_request()
        
        # ì‹¤ì œ ê²½ë¡œ ìë™ íƒì§€ (step_model_requirements.py ê¸°ì¤€)
        self.ai_models_root = self._auto_detect_ai_models_path()
        self.logger.info(f"ğŸ“ AI ëª¨ë¸ ë£¨íŠ¸ ê²½ë¡œ: {self.ai_models_root}")
        
    def _auto_detect_ai_models_path(self) -> Path:
        """ì‹¤ì œ ai_models ë””ë ‰í† ë¦¬ ìë™ íƒì§€ (step_model_requirements.py ê¸°ì¤€)"""
        # step_model_requirements.pyì—ì„œ ì •ì˜ëœ ê²€ìƒ‰ ê²½ë¡œ ì‚¬ìš©
        if self.step_request:
            search_paths = self.step_request.search_paths + self.step_request.fallback_paths
        else:
            search_paths = [
                "step_04_geometric_matching",
                "step_04_geometric_matching/ultra_models", 
                "step_04_geometric_matching/models",
                "step_03_cloth_segmentation"  # SAM ê³µìœ 
            ]
        
        possible_paths = [
            Path.cwd() / "ai_models",
            Path.cwd().parent / "ai_models",
            Path.cwd() / "backend" / "ai_models",
            Path(__file__).parent / "ai_models",
            Path(__file__).parent.parent / "ai_models",
            Path(__file__).parent.parent.parent / "ai_models"
        ]
        
        for path in possible_paths:
            if path.exists():
                # step_model_requirements.py ê¸°ì¤€ìœ¼ë¡œ ê²€ì¦
                for search_path in search_paths:
                    if (path / search_path).exists():
                        return path
                        
        return Path.cwd() / "ai_models"
    
    def find_model_file(self, model_filename: str) -> Optional[Path]:
        """ì‹¤ì œ íŒŒì¼ ìœ„ì¹˜ë¥¼ ë™ì ìœ¼ë¡œ ì°¾ê¸° (step_model_requirements.py ê¸°ì¤€)"""
        cache_key = f"geometric_matching:{model_filename}"
        if cache_key in self.model_cache:
            cached_path = self.model_cache[cache_key]
            if cached_path.exists():
                return cached_path
        
        # step_model_requirements.pyì—ì„œ ì •ì˜ëœ ê²€ìƒ‰ ê²½ë¡œ ì‚¬ìš©
        if self.step_request:
            search_paths = self.step_request.search_paths + self.step_request.fallback_paths
        else:
            search_paths = [
                "step_04_geometric_matching",
                "step_04_geometric_matching/ultra_models",
                "step_04_geometric_matching/models",
                "step_03_cloth_segmentation"
            ]
        
        # ì‹¤ì œ íŒŒì¼ ê²€ìƒ‰
        for search_path in search_paths:
            full_search_path = self.ai_models_root / search_path
            if not full_search_path.exists():
                continue
                
            # ì§ì ‘ íŒŒì¼ í™•ì¸
            direct_path = full_search_path / model_filename
            if direct_path.exists() and direct_path.is_file():
                self.model_cache[cache_key] = direct_path
                return direct_path
                
            # ì¬ê·€ ê²€ìƒ‰ (í•˜ìœ„ ë””ë ‰í† ë¦¬ê¹Œì§€)
            try:
                for found_file in full_search_path.rglob(model_filename):
                    if found_file.is_file():
                        self.model_cache[cache_key] = found_file
                        return found_file
            except Exception:
                continue
                
        return None
    
    def get_geometric_matching_models(self) -> Dict[str, Path]:
        """ê¸°í•˜í•™ì  ë§¤ì¹­ìš© ëª¨ë¸ë“¤ ë§¤í•‘ (step_model_requirements.py ê¸°ì¤€)"""
        result = {}
        
        # step_model_requirements.pyì—ì„œ ì •ì˜ëœ íŒŒì¼ë“¤
        if self.step_request:
            # ì£¼ìš” íŒŒì¼
            primary_file = self.step_request.primary_file  # gmm_final.pth
            primary_path = self.find_model_file(primary_file)
            if primary_path:
                result['gmm'] = primary_path
                self.logger.info(f"âœ… ì£¼ìš” ëª¨ë¸ ë°œê²¬: {primary_file} -> {primary_path.name}")
            
            # ëŒ€ì²´ íŒŒì¼ë“¤
            for alt_file, alt_size in self.step_request.alternative_files:
                alt_path = self.find_model_file(alt_file)
                if alt_path:
                    if alt_file == "tps_network.pth":
                        result['tps'] = alt_path
                    elif alt_file == "sam_vit_h_4b8939.pth":
                        result['sam_shared'] = alt_path
                    elif alt_file == "ViT-L-14.pt":
                        result['vit_large'] = alt_path
                    elif alt_file == "efficientnet_b0_ultra.pth":
                        result['efficientnet'] = alt_path
                    elif "raft" in alt_file.lower():
                        result['raft'] = alt_path
                    
                    self.logger.info(f"âœ… ëŒ€ì²´ ëª¨ë¸ ë°œê²¬: {alt_file} -> {alt_path.name}")
        else:
            # í´ë°±: ê¸°ë³¸ íŒŒì¼ëª…ë“¤
            model_files = {
                'gmm': ['gmm_final.pth', 'gmm.pth', 'geometric_matching.pth'],
                'tps': ['tps_network.pth', 'tps.pth', 'transformation.pth'],
                'sam_shared': ['sam_vit_h_4b8939.pth', 'sam.pth'],
                'vit_large': ['ViT-L-14.pt', 'vit_large.pth'],
                'efficientnet': ['efficientnet_b0_ultra.pth', 'efficientnet.pth']
            }
            
            for model_key, possible_filenames in model_files.items():
                for filename in possible_filenames:
                    found_path = self.find_model_file(filename)
                    if found_path:
                        result[model_key] = found_path
                        self.logger.info(f"âœ… ëª¨ë¸ íŒŒì¼ ë°œê²¬: {model_key} -> {found_path.name}")
                        break
        
        return result

# ==============================================
# ğŸ”¥ 6. ê³ ê¸‰ ë”¥ëŸ¬ë‹ ì•Œê³ ë¦¬ì¦˜ í´ë˜ìŠ¤ë“¤ (Human Parsing ìˆ˜ì¤€)
# ==============================================

class DeepLabV3PlusBackbone(nn.Module):
    """DeepLabV3+ ë°±ë³¸ ë„¤íŠ¸ì›Œí¬ - ê¸°í•˜í•™ì  ë§¤ì¹­ íŠ¹í™”"""

    def __init__(self, input_nc=6, backbone='resnet101', output_stride=16):
        super().__init__()
        self.output_stride = output_stride
        self.input_nc = input_nc

        # ResNet-101 ë°±ë³¸ êµ¬ì„± (6ì±„ë„ ì…ë ¥ ì§€ì›)
        self.conv1 = nn.Conv2d(input_nc, 64, kernel_size=7, stride=2, padding=3, bias=False)
        self.bn1 = nn.BatchNorm2d(64)
        self.relu = nn.ReLU(inplace=True)
        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)

        # ResNet Layers with Dilated Convolution
        self.layer1 = self._make_layer(64, 64, 3, stride=1)      # 256 channels
        self.layer2 = self._make_layer(256, 128, 4, stride=2)    # 512 channels  
        self.layer3 = self._make_layer(512, 256, 23, stride=2)   # 1024 channels
        self.layer4 = self._make_layer(1024, 512, 3, stride=1, dilation=2)  # 2048 channels

        # Low-level feature extraction (for decoder)
        self.low_level_conv = nn.Conv2d(256, 48, 1, bias=False)
        self.low_level_bn = nn.BatchNorm2d(48)

    def _make_layer(self, inplanes, planes, blocks, stride=1, dilation=1):
        """ResNet ë ˆì´ì–´ ìƒì„± (Bottleneck êµ¬ì¡°)"""
        layers = []

        # Downsample layer
        downsample = None
        if stride != 1 or inplanes != planes * 4:
            downsample = nn.Sequential(
                nn.Conv2d(inplanes, planes * 4, 1, stride=stride, bias=False),
                nn.BatchNorm2d(planes * 4)
            )

        # First block
        layers.append(self._bottleneck_block(inplanes, planes, stride, dilation, downsample))

        # Remaining blocks
        for _ in range(1, blocks):
            layers.append(self._bottleneck_block(planes * 4, planes, 1, dilation))

        return nn.Sequential(*layers)

    def _bottleneck_block(self, inplanes, planes, stride=1, dilation=1, downsample=None):
        """ResNet Bottleneck ë¸”ë¡"""
        class BottleneckBlock(nn.Module):
            def __init__(self, inplanes, planes, stride, dilation, downsample):
                super().__init__()
                self.conv1 = nn.Conv2d(inplanes, planes, 1, bias=False)
                self.bn1 = nn.BatchNorm2d(planes)
                self.conv2 = nn.Conv2d(planes, planes, 3, stride=stride, padding=dilation, 
                                     dilation=dilation, bias=False)
                self.bn2 = nn.BatchNorm2d(planes)
                self.conv3 = nn.Conv2d(planes, planes * 4, 1, bias=False)
                self.bn3 = nn.BatchNorm2d(planes * 4)
                self.relu = nn.ReLU(inplace=True)
                self.downsample = downsample

            def forward(self, x):
                residual = x

                out = self.conv1(x)
                out = self.bn1(out)
                out = self.relu(out)

                out = self.conv2(out)
                out = self.bn2(out)
                out = self.relu(out)

                out = self.conv3(out)
                out = self.bn3(out)

                if self.downsample is not None:
                    residual = self.downsample(x)

                out += residual
                out = self.relu(out)

                return out
                
        return BottleneckBlock(inplanes, planes, stride, dilation, downsample)

    def forward(self, x):
        # Initial convolution
        x = self.conv1(x)
        x = self.bn1(x)
        x = self.relu(x)
        x = self.maxpool(x)

        # ResNet layers
        x = self.layer1(x)
        low_level_feat = x  # Save for decoder

        x = self.layer2(x)
        x = self.layer3(x)
        x = self.layer4(x)

        # Process low-level features
        low_level_feat = self.low_level_conv(low_level_feat)
        low_level_feat = self.low_level_bn(low_level_feat)
        low_level_feat = self.relu(low_level_feat)

        return x, low_level_feat

class ASPPModule(nn.Module):
    """ASPP ëª¨ë“ˆ - Multi-scale context aggregation"""

    def __init__(self, in_channels=2048, out_channels=256, atrous_rates=[6, 12, 18]):
        super().__init__()

        # 1x1 convolution
        self.conv1x1 = nn.Sequential(
            nn.Conv2d(in_channels, out_channels, 1, bias=False),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True)
        )

        # Atrous convolutions with different rates
        self.atrous_convs = nn.ModuleList([
            nn.Sequential(
                nn.Conv2d(in_channels, out_channels, 3, padding=rate, 
                         dilation=rate, bias=False),
                nn.BatchNorm2d(out_channels),
                nn.ReLU(inplace=True)
            ) for rate in atrous_rates
        ])

        # Global average pooling branch
        self.global_avg_pool = nn.Sequential(
            nn.AdaptiveAvgPool2d((1, 1)),
            nn.Conv2d(in_channels, out_channels, 1, bias=False),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True)
        )

        # Feature fusion
        total_channels = out_channels * (1 + len(atrous_rates) + 1)  # 1x1 + atrous + global
        self.project = nn.Sequential(
            nn.Conv2d(total_channels, out_channels, 1, bias=False),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True),
            nn.Dropout(0.5)
        )

    def forward(self, x):
        h, w = x.shape[2:]

        # 1x1 convolution
        feat1 = self.conv1x1(x)

        # Atrous convolutions
        atrous_feats = [conv(x) for conv in self.atrous_convs]

        # Global average pooling
        global_feat = self.global_avg_pool(x)
        global_feat = F.interpolate(global_feat, size=(h, w), 
                                   mode='bilinear', align_corners=False)

        # Concatenate all features
        concat_feat = torch.cat([feat1] + atrous_feats + [global_feat], dim=1)

        # Project to final features
        return self.project(concat_feat)

class SelfAttentionKeypointMatcher(nn.Module):
    """Self-Attention ê¸°ë°˜ í‚¤í¬ì¸íŠ¸ ë§¤ì¹­ ëª¨ë“ˆ"""

    def __init__(self, in_channels=256, num_keypoints=20):
        super().__init__()
        self.num_keypoints = num_keypoints
        self.in_channels = in_channels

        # Query, Key, Value ë³€í™˜
        self.query_conv = nn.Conv2d(in_channels, in_channels // 8, 1)
        self.key_conv = nn.Conv2d(in_channels, in_channels // 8, 1)
        self.value_conv = nn.Conv2d(in_channels, in_channels, 1)

        # í‚¤í¬ì¸íŠ¸ íˆíŠ¸ë§µ ìƒì„±
        self.keypoint_head = nn.Sequential(
            nn.Conv2d(in_channels, 128, 3, padding=1, bias=False),
            nn.BatchNorm2d(128),
            nn.ReLU(inplace=True),
            nn.Conv2d(128, 64, 3, padding=1, bias=False),
            nn.BatchNorm2d(64),
            nn.ReLU(inplace=True),
            nn.Conv2d(64, num_keypoints, 1),
            nn.Sigmoid()
        )

        # Attention ê°€ì¤‘ì¹˜
        self.gamma = nn.Parameter(torch.zeros(1))
        self.softmax = nn.Softmax(dim=-1)

    def forward(self, person_feat, clothing_feat):
        """Self-attentionì„ í†µí•œ í‚¤í¬ì¸íŠ¸ ë§¤ì¹­"""
        batch_size, C, H, W = person_feat.size()

        # Person featuresì—ì„œ query ìƒì„±
        proj_query = self.query_conv(person_feat).view(batch_size, -1, H * W).permute(0, 2, 1)
        
        # Clothing featuresì—ì„œ key, value ìƒì„±
        proj_key = self.key_conv(clothing_feat).view(batch_size, -1, H * W)
        proj_value = self.value_conv(clothing_feat).view(batch_size, -1, H * W)

        # Attention ê³„ì‚°
        energy = torch.bmm(proj_query, proj_key)
        attention = self.softmax(energy)

        # Attentionì„ valueì— ì ìš©
        out = torch.bmm(proj_value, attention.permute(0, 2, 1))
        out = out.view(batch_size, C, H, W)

        # Residual connection
        attended_feat = self.gamma * out + person_feat

        # í‚¤í¬ì¸íŠ¸ íˆíŠ¸ë§µ ìƒì„±
        keypoint_heatmaps = self.keypoint_head(attended_feat)

        return keypoint_heatmaps, attended_feat

class EdgeAwareTransformationModule(nn.Module):
    """Edge-Aware ë³€í˜• ëª¨ë“ˆ - ê²½ê³„ì„  ì •ë³´ í™œìš©"""

    def __init__(self, in_channels=256):
        super().__init__()

        # Edge feature extraction
        self.edge_conv1 = nn.Sequential(
            nn.Conv2d(in_channels, 128, 3, padding=1, bias=False),
            nn.BatchNorm2d(128),
            nn.ReLU(inplace=True)
        )

        self.edge_conv2 = nn.Sequential(
            nn.Conv2d(128, 64, 3, padding=1, bias=False),
            nn.BatchNorm2d(64),
            nn.ReLU(inplace=True)
        )

        # Learnable Sobel-like filters
        self.sobel_x = nn.Conv2d(64, 32, 3, padding=1, bias=False)
        self.sobel_y = nn.Conv2d(64, 32, 3, padding=1, bias=False)

        # Initialize edge kernels
        self._init_sobel_kernels()

        # Transformation prediction
        self.transform_head = nn.Sequential(
            nn.Conv2d(64 + 32 * 2, 128, 3, padding=1, bias=False),
            nn.BatchNorm2d(128),
            nn.ReLU(inplace=True),
            nn.Conv2d(128, 64, 3, padding=1, bias=False),
            nn.BatchNorm2d(64),
            nn.ReLU(inplace=True),
            nn.Conv2d(64, 2, 1)  # x, y displacement
        )

    def _init_sobel_kernels(self):
        """Sobel edge detection ì»¤ë„ ì´ˆê¸°í™”"""
        sobel_x_kernel = torch.tensor([
            [-1, 0, 1],
            [-2, 0, 2], 
            [-1, 0, 1]
        ], dtype=torch.float32).view(1, 1, 3, 3)

        sobel_y_kernel = torch.tensor([
            [-1, -2, -1],
            [0, 0, 0],
            [1, 2, 1]
        ], dtype=torch.float32).view(1, 1, 3, 3)

        # í•™ìŠµ ê°€ëŠ¥í•œ íŒŒë¼ë¯¸í„°ë¡œ ì„¤ì •
        self.sobel_x.weight.data = sobel_x_kernel.repeat(32, 64, 1, 1)
        self.sobel_y.weight.data = sobel_y_kernel.repeat(32, 64, 1, 1)

    def forward(self, features):
        """Edge-aware transformation ì˜ˆì¸¡"""
        # Edge features ì¶”ì¶œ
        edge_feat = self.edge_conv1(features)
        edge_feat = self.edge_conv2(edge_feat)

        # Sobel í•„í„° ì ìš©
        edge_x = self.sobel_x(edge_feat)
        edge_y = self.sobel_y(edge_feat)

        # Feature ê²°í•©
        combined_feat = torch.cat([edge_feat, edge_x, edge_y], dim=1)

        # Transformation ì˜ˆì¸¡
        transformation = self.transform_head(combined_feat)

        return transformation

class ProgressiveGeometricRefinement(nn.Module):
    """Progressive ê¸°í•˜í•™ì  ì •ì œ ëª¨ë“ˆ - ë‹¨ê³„ë³„ ê°œì„ """

    def __init__(self, num_stages=3, in_channels=256):
        super().__init__()
        self.num_stages = num_stages

        # Stageë³„ ì •ì œ ëª¨ë“ˆ
        self.refine_stages = nn.ModuleList([
            self._make_refine_stage(in_channels + 2 * i, in_channels // (2 ** i))
            for i in range(num_stages)
        ])

        # Stageë³„ ë³€í˜• ì˜ˆì¸¡ê¸°
        self.transform_predictors = nn.ModuleList([
            nn.Conv2d(in_channels // (2 ** i), 2, 1)
            for i in range(num_stages)
        ])

        # ì‹ ë¢°ë„ ì¶”ì •
        self.confidence_estimator = nn.Sequential(
            nn.Conv2d(in_channels, 64, 3, padding=1, bias=False),
            nn.BatchNorm2d(64),
            nn.ReLU(inplace=True),
            nn.Conv2d(64, 1, 1),
            nn.Sigmoid()
        )

    def _make_refine_stage(self, in_channels, out_channels):
        """ì •ì œ ë‹¨ê³„ ìƒì„±"""
        return nn.Sequential(
            nn.Conv2d(in_channels, out_channels * 2, 3, padding=1, bias=False),
            nn.BatchNorm2d(out_channels * 2),
            nn.ReLU(inplace=True),
            nn.Conv2d(out_channels * 2, out_channels, 3, padding=1, bias=False),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True)
        )

    def forward(self, features):
        """Progressive refinement ìˆ˜í–‰"""
        transformations = []
        current_feat = features

        for i, (refine_stage, transform_pred) in enumerate(zip(self.refine_stages, self.transform_predictors)):
            # í˜„ì¬ ë‹¨ê³„ ì •ì œ
            refined_feat = refine_stage(current_feat)
            
            # ë³€í˜• ì˜ˆì¸¡
            transform = transform_pred(refined_feat)
            transformations.append(transform)

            # ë‹¤ìŒ ë‹¨ê³„ë¥¼ ìœ„í•œ íŠ¹ì§• ì¤€ë¹„
            if i < self.num_stages - 1:
                current_feat = torch.cat([refined_feat, transform], dim=1)

        # ì‹ ë¢°ë„ ì¶”ì •
        confidence = self.confidence_estimator(features)

        return transformations, confidence

# ==============================================
# ğŸ”¥ 7. ì™„ì „í•œ ê³ ê¸‰ AI ê¸°í•˜í•™ì  ë§¤ì¹­ ëª¨ë¸
# ==============================================

class CompleteAdvancedGeometricMatchingAI(nn.Module):
    """ì™„ì „í•œ ê³ ê¸‰ AI ê¸°í•˜í•™ì  ë§¤ì¹­ ëª¨ë¸ - DeepLabV3+ + ASPP + Self-Attention"""

    def __init__(self, input_nc=6, num_keypoints=20):
        super().__init__()
        self.input_nc = input_nc
        self.num_keypoints = num_keypoints

        # 1. DeepLabV3+ Backbone
        self.backbone = DeepLabV3PlusBackbone(input_nc=input_nc)

        # 2. ASPP Module
        self.aspp = ASPPModule(in_channels=2048, out_channels=256)

        # 3. Self-Attention Keypoint Matcher
        self.keypoint_matcher = SelfAttentionKeypointMatcher(in_channels=256, num_keypoints=num_keypoints)

        # 4. Edge-Aware Transformation Module
        self.edge_transform = EdgeAwareTransformationModule(in_channels=256)

        # 5. Progressive Refinement
        self.progressive_refine = ProgressiveGeometricRefinement(num_stages=3, in_channels=256)

        # Decoder
        self.decoder = nn.Sequential(
            nn.Conv2d(256 + 48, 256, 3, padding=1, bias=False),  # ASPP + low-level
            nn.BatchNorm2d(256),
            nn.ReLU(inplace=True),
            nn.Conv2d(256, 256, 3, padding=1, bias=False),
            nn.BatchNorm2d(256),
            nn.ReLU(inplace=True),
            nn.Dropout(0.1)
        )

        # Final transformation predictor
        self.final_transform = nn.Conv2d(256, 2, 1)

    def forward(self, person_image, clothing_image):
        """ì™„ì „í•œ AI ê¸°ë°˜ ê¸°í•˜í•™ì  ë§¤ì¹­"""
        # ì…ë ¥ ê²°í•© (6ì±„ë„)
        combined_input = torch.cat([person_image, clothing_image], dim=1)
        input_size = combined_input.shape[2:]

        # 1. Feature extraction with DeepLabV3+
        high_level_feat, low_level_feat = self.backbone(combined_input)

        # 2. Multi-scale context with ASPP
        aspp_feat = self.aspp(high_level_feat)

        # 3. Decode features
        aspp_feat = F.interpolate(aspp_feat, size=low_level_feat.shape[2:], 
                                 mode='bilinear', align_corners=False)
        concat_feat = torch.cat([aspp_feat, low_level_feat], dim=1)
        decoded_feat = self.decoder(concat_feat)

        # 4. Self-attention keypoint matching
        keypoint_heatmaps, attended_feat = self.keypoint_matcher(decoded_feat, decoded_feat)

        # 5. Edge-aware transformation
        edge_transform = self.edge_transform(attended_feat)

        # 6. Progressive refinement
        progressive_transforms, confidence = self.progressive_refine(attended_feat)

        # 7. Final transformation
        final_transform = self.final_transform(attended_feat)

        # 8. Generate transformation grid
        transformation_grid = self._generate_transformation_grid(final_transform, input_size)

        # 9. Apply transformation to clothing
        warped_clothing = F.grid_sample(
            clothing_image, transformation_grid, mode='bilinear',
            padding_mode='border', align_corners=False
        )

        return {
            'transformation_matrix': self._grid_to_matrix(transformation_grid),
            'transformation_grid': transformation_grid,
            'warped_clothing': warped_clothing,
            'keypoint_heatmaps': keypoint_heatmaps,
            'confidence_map': confidence,
            'progressive_transforms': progressive_transforms,
            'edge_features': edge_transform,
            'algorithm_type': 'advanced_deeplab_aspp_self_attention'
        }

    def _generate_transformation_grid(self, flow_field, input_size):
        """Flow fieldë¥¼ transformation gridë¡œ ë³€í™˜"""
        batch_size = flow_field.shape[0]
        device = flow_field.device
        H, W = input_size

        # ê¸°ë³¸ ê·¸ë¦¬ë“œ ìƒì„±
        y, x = torch.meshgrid(
            torch.linspace(-1, 1, H, device=device),
            torch.linspace(-1, 1, W, device=device),
            indexing='ij'
        )
        base_grid = torch.stack([x, y], dim=-1).unsqueeze(0).repeat(batch_size, 1, 1, 1)

        # Flow field í¬ê¸° ì¡°ì •
        if flow_field.shape[-2:] != (H, W):
            flow_field = F.interpolate(flow_field, size=(H, W), mode='bilinear', align_corners=False)

        # Flowë¥¼ ê·¸ë¦¬ë“œ ì¢Œí‘œê³„ë¡œ ë³€í™˜
        flow_normalized = flow_field.permute(0, 2, 3, 1)
        flow_normalized[:, :, :, 0] /= W / 2.0
        flow_normalized[:, :, :, 1] /= H / 2.0

        # ìµœì¢… ë³€í˜• ê·¸ë¦¬ë“œ
        transformation_grid = base_grid + flow_normalized * 0.1

        return transformation_grid

    def _grid_to_matrix(self, grid):
        """Gridë¥¼ 2x3 ë³€í˜• í–‰ë ¬ë¡œ ë³€í™˜"""
        batch_size, H, W, _ = grid.shape
        device = grid.device

        # ë‹¨ìˆœí™”ëœ ì–´í•€ ë³€í˜• ì¶”ì •
        matrix = torch.zeros(batch_size, 2, 3, device=device)

        # ê·¸ë¦¬ë“œ ì¤‘ì•™ ì˜ì—­ì—ì„œ ë³€í˜• íŒŒë¼ë¯¸í„° ì¶”ì¶œ
        center_h, center_w = H // 2, W // 2
        center_region = grid[:, center_h-10:center_h+10, center_w-10:center_w+10, :]

        # í‰ê·  ë³€í˜• ê³„ì‚°
        mean_transform = torch.mean(center_region, dim=(1, 2))

        matrix[:, 0, 0] = 1.0 + mean_transform[:, 0] * 0.1
        matrix[:, 1, 1] = 1.0 + mean_transform[:, 1] * 0.1
        matrix[:, 0, 2] = mean_transform[:, 0]
        matrix[:, 1, 2] = mean_transform[:, 1]

        return matrix

# ==============================================
# ğŸ”¥ 8. ê³ ê¸‰ ê¸°í•˜í•™ì  ë§¤ì¹­ ì•Œê³ ë¦¬ì¦˜ í´ë˜ìŠ¤
# ==============================================

class AdvancedGeometricMatcher:
    """ê³ ê¸‰ ê¸°í•˜í•™ì  ë§¤ì¹­ ì•Œê³ ë¦¬ì¦˜ - Procrustes + RANSAC"""
    
    def __init__(self, device="cpu"):
        self.device = device
        self.logger = logging.getLogger(self.__class__.__name__)
        
    def extract_keypoints_from_heatmaps(self, heatmaps: torch.Tensor) -> torch.Tensor:
        """íˆíŠ¸ë§µì—ì„œ í‚¤í¬ì¸íŠ¸ ì¢Œí‘œ ì¶”ì¶œ"""
        batch_size, num_kpts, H, W = heatmaps.shape
        
        heatmaps_flat = heatmaps.view(batch_size, num_kpts, -1)
        max_vals, max_indices = torch.max(heatmaps_flat, dim=2)
        
        y_coords = (max_indices // W).float()
        x_coords = (max_indices % W).float()
        
        scale_x = 256.0 / W
        scale_y = 192.0 / H
        
        x_coords *= scale_x
        y_coords *= scale_y
        
        keypoints = torch.stack([x_coords, y_coords], dim=2)
        
        # ì‹ ë¢°ë„ í•„í„°ë§
        confident_kpts = []
        for b in range(batch_size):
            batch_kpts = []
            for k in range(num_kpts):
                if max_vals[b, k] > 0.2:  # ì„ê³„ê°’
                    batch_kpts.append(keypoints[b, k])
            
            if batch_kpts:
                confident_kpts.append(torch.stack(batch_kpts))
            else:
                confident_kpts.append(torch.zeros(1, 2, device=keypoints.device))
        
        return confident_kpts[0] if len(confident_kpts) == 1 else confident_kpts

    def compute_transformation_matrix_procrustes(self, src_keypoints: torch.Tensor, 
                                               dst_keypoints: torch.Tensor) -> torch.Tensor:
        """Procrustes ë¶„ì„ ê¸°ë°˜ ìµœì  ë³€í˜• ê³„ì‚°"""
        if not SCIPY_AVAILABLE:
            return self._compute_with_pytorch(src_keypoints.unsqueeze(0), dst_keypoints.unsqueeze(0))
        
        try:
            src_np = src_keypoints.cpu().numpy()
            dst_np = dst_keypoints.cpu().numpy()
            
            # Procrustes ë¶„ì„
            def objective(params):
                tx, ty, scale, rotation = params
                
                cos_r, sin_r = np.cos(rotation), np.sin(rotation)
                transform_matrix = np.array([
                    [scale * cos_r, -scale * sin_r, tx],
                    [scale * sin_r, scale * cos_r, ty]
                ])
                
                src_homogeneous = np.column_stack([src_np, np.ones(len(src_np))])
                transformed = src_homogeneous @ transform_matrix.T
                
                error = np.sum((transformed - dst_np) ** 2)
                return error
            
            # ìµœì í™”
            initial_params = [0, 0, 1, 0]
            result = minimize(objective, initial_params, method='BFGS')
            
            if result.success:
                tx, ty, scale, rotation = result.x
                cos_r, sin_r = np.cos(rotation), np.sin(rotation)
                
                transform_matrix = np.array([
                    [scale * cos_r, -scale * sin_r, tx],
                    [scale * sin_r, scale * cos_r, ty]
                ])
            else:
                transform_matrix = np.array([[1, 0, 0], [0, 1, 0]])
            
            return torch.from_numpy(transform_matrix).float().to(src_keypoints.device).unsqueeze(0)
            
        except Exception as e:
            self.logger.warning(f"Procrustes ë¶„ì„ ì‹¤íŒ¨: {e}")
            return self._compute_with_pytorch(src_keypoints.unsqueeze(0), dst_keypoints.unsqueeze(0))

    def _compute_with_pytorch(self, src_keypoints: torch.Tensor, 
                            dst_keypoints: torch.Tensor) -> torch.Tensor:
        """PyTorch ê¸°ë°˜ ë³€í˜• í–‰ë ¬ ê³„ì‚°"""
        batch_size = src_keypoints.shape[0]
        device = src_keypoints.device
        
        # ì¤‘ì‹¬ì  ê³„ì‚°
        src_center = torch.mean(src_keypoints, dim=1, keepdim=True)
        dst_center = torch.mean(dst_keypoints, dim=1, keepdim=True)
        
        # ì¤‘ì‹¬ì  ê¸°ì¤€ìœ¼ë¡œ ì •ê·œí™”
        src_centered = src_keypoints - src_center
        dst_centered = dst_keypoints - dst_center
        
        # ìŠ¤ì¼€ì¼ ê³„ì‚°
        src_scale = torch.norm(src_centered, dim=2).mean(dim=1, keepdim=True)
        dst_scale = torch.norm(dst_centered, dim=2).mean(dim=1, keepdim=True)
        scale = dst_scale / (src_scale + 1e-8)
        
        # íšŒì „ ê³„ì‚° (SVD ê¸°ë°˜)
        try:
            H = torch.bmm(src_centered.transpose(1, 2), dst_centered)
            U, S, V = torch.svd(H)
            R = torch.bmm(V, U.transpose(1, 2))
            
            # ë°˜ì‚¬ ë°©ì§€
            det = torch.det(R)
            for b in range(batch_size):
                if det[b] < 0:
                    V[b, :, -1] *= -1
                    R[b] = torch.mm(V[b], U[b].T)
        except:
            R = torch.eye(2, device=device).unsqueeze(0).repeat(batch_size, 1, 1)
        
        # ë³€í˜• í–‰ë ¬ êµ¬ì„±
        transform_matrix = torch.zeros(batch_size, 2, 3, device=device)
        transform_matrix[:, :2, :2] = scale.unsqueeze(-1) * R
        transform_matrix[:, :, 2] = (dst_center - torch.bmm(
            scale.unsqueeze(-1) * R, src_center.transpose(1, 2)
        ).transpose(1, 2)).squeeze(1)
        
        return transform_matrix

    def ransac_filtering(self, matches: List[Tuple[int, int, float]], 
                        threshold: float = 5.0, max_trials: int = 1000) -> List[Tuple[int, int, float]]:
        """RANSAC ì´ìƒì¹˜ ì œê±°"""
        if len(matches) < 4:
            return matches
        
        best_inliers = []
        best_score = 0
        
        for _ in range(max_trials):
            sample_indices = np.random.choice(len(matches), 4, replace=False)
            sample_matches = [matches[i] for i in sample_indices]
            
            try:
                transform = self._compute_affine_transform(sample_matches)
                
                inliers = []
                for match in matches:
                    error = self._compute_transform_error(match, transform)
                    if error < threshold:
                        inliers.append(match)
                
                if len(inliers) > best_score:
                    best_score = len(inliers)
                    best_inliers = inliers
                    
            except Exception:
                continue
        
        return best_inliers if best_inliers else matches

    def _compute_affine_transform(self, matches: List[Tuple[int, int, float]]) -> np.ndarray:
        """ì–´í•€ ë³€í˜• ê³„ì‚°"""
        if len(matches) < 3:
            return np.eye(3)
        
        src_pts = np.array([[i, j] for i, j, _ in matches[:4]], dtype=np.float32)
        dst_pts = np.array([[j, i] for i, j, _ in matches[:4]], dtype=np.float32)
        
        if CV2_AVAILABLE:
            transform = cv2.getAffineTransform(src_pts[:3], dst_pts[:3])
            return np.vstack([transform, [0, 0, 1]])
        else:
            return np.eye(3)

    def _compute_transform_error(self, match: Tuple[int, int, float], 
                               transform: np.ndarray) -> float:
        """ë³€í˜• ì˜¤ì°¨ ê³„ì‚°"""
        i, j, _ = match
        src_pt = np.array([i, j, 1])
        transformed_pt = transform @ src_pt
        error = np.linalg.norm(transformed_pt[:2] - np.array([j, i]))
        return error

# ==============================================
# ğŸ”¥ 9. ì²˜ë¦¬ ìƒíƒœ ë° ë°ì´í„° êµ¬ì¡°
# ==============================================

@dataclass
class ProcessingStatus:
    """ì²˜ë¦¬ ìƒíƒœ ì¶”ì """
    initialized: bool = False
    models_loaded: bool = False
    dependencies_injected: bool = False
    processing_active: bool = False
    error_count: int = 0
    last_error: Optional[str] = None
    ai_model_calls: int = 0
    model_creation_success: bool = False
    requirements_compatible: bool = False
    detailed_data_spec_loaded: bool = False
    advanced_ai_loaded: bool = False
    ai_enhanced_mode: bool = True

# ==============================================
# ğŸ”¥ 10. ë©”ì¸ GeometricMatchingStep í´ë˜ìŠ¤
# ==============================================

class GeometricMatchingStep(BaseStepMixin):
    """ê³ ê¸‰ AI ê¸°í•˜í•™ì  ë§¤ì¹­ Step - ì™„ì „í•œ ë”¥ëŸ¬ë‹ ì•Œê³ ë¦¬ì¦˜ êµ¬í˜„"""
    
    def __init__(self, **kwargs):
        """BaseStepMixin í˜¸í™˜ ìƒì„±ì"""
        
        # ğŸ”¥ 1. ë¨¼ì € status ì†ì„± ìƒì„±
        self.status = ProcessingStatus()
        
        # ğŸ”¥ 2. ê¸°ë³¸ ì†ì„±ë“¤ ì„¤ì •
        self.step_name = "GeometricMatchingStep"
        self.step_id = 4
        self.device = kwargs.get('device', 'auto')
        
        # ğŸ”¥ 3. AI ê°•í™” ëª¨ë“œ ì„¤ì •
        self.ai_enhanced_mode = kwargs.get('ai_enhanced', True)
        self.use_advanced_algorithms = kwargs.get('use_advanced_algorithms', True)
        
        # ğŸ”¥ 4. Logger ì„¤ì •
        self.logger = logging.getLogger(f"steps.{self.step_name}")
        
        # ğŸ”¥ 5. ë””ë°”ì´ìŠ¤ ì„¤ì •
        self.device = self._force_mps_device(self.device)
        
        # ğŸ”¥ 6. BaseStepMixin ì´ˆê¸°í™”
        try:
            super().__init__(**kwargs)
        except Exception as e:
            self.logger.debug(f"super().__init__ ì‹¤íŒ¨: {e}")
            # ê¸°ë³¸ BaseStepMixin ì†ì„±ë“¤ ìˆ˜ë™ ì„¤ì •
            self.is_initialized = False
            self.is_ready = False
            self.has_model = False
            self.model_loaded = False
        
        # ğŸ”¥ 7. step_model_requirements.py ìš”êµ¬ì‚¬í•­ ë¡œë“œ
        try:
            self.step_request = get_step_model_request()
            if self.step_request:
                self.status.requirements_compatible = True
                self._load_requirements_config()
        except Exception as e:
            self.logger.debug(f"step_model_requirements ë¡œë“œ ì‹¤íŒ¨: {e}")
            self.step_request = None
            self._load_fallback_config()
        
        # ğŸ”¥ 8. ëª¨ë¸ ê²½ë¡œ ë§¤í•‘
        ai_models_root = kwargs.get('ai_models_root', 'ai_models')
        try:
            self.model_mapper = EnhancedModelPathMapper(ai_models_root)
        except Exception as e:
            self.logger.debug(f"ModelPathMapper ìƒì„± ì‹¤íŒ¨: {e}")
            self.model_mapper = None
        
        # ğŸ”¥ 9. AI ëª¨ë¸ë“¤ ì´ˆê¸°í™”
        self.advanced_geometric_ai = None  # ê³ ê¸‰ AI ëª¨ë¸
        self.geometric_matcher = None      # ê³ ê¸‰ ë§¤ì¹­ ì•Œê³ ë¦¬ì¦˜
        self.gmm_model = None              # ê¸°ì¡´ í˜¸í™˜ì„±
        self.tps_model = None
        self.sam_model = None
        
        # ğŸ”¥ 10. ê¸°ì¡´ í˜¸í™˜ì„± ì†ì„±ë“¤
        self.geometric_model = None
        self.model_interface = None
        self.model_paths = {}
        
        # ğŸ”¥ 11. ì˜ì¡´ì„± ì´ˆê¸°í™”
        self.model_loader = None
        self.memory_manager = None
        self.data_converter = None
        self.di_container = None
        
        # ğŸ”¥ 12. ìƒíƒœ ì—…ë°ì´íŠ¸
        self.status.initialized = True
        self.status.ai_enhanced_mode = self.ai_enhanced_mode
        self.is_initialized = True
        
        # ğŸ”¥ 13. í†µê³„ ì´ˆê¸°í™”
        self._init_statistics()
        
        self.logger.info(f"âœ… GeometricMatchingStep ìƒì„± ì™„ë£Œ - Device: {self.device}")
        if self.step_request:
            self.logger.info(f"ğŸ“‹ step_model_requirements.py ìš”êµ¬ì‚¬í•­ ë¡œë“œ ì™„ë£Œ")

    def _load_requirements_config(self):
        """step_model_requirements.py ìš”êµ¬ì‚¬í•­ ì„¤ì • ë¡œë“œ"""
        if self.step_request:
            # step_model_requirements.py ê¸°ì¤€ ì„¤ì •
            self.matching_config = {
                'method': 'advanced_deeplab_aspp_self_attention',
                'input_size': self.step_request.input_size,  # (256, 192)
                'output_format': self.step_request.output_format,  # "transformation_matrix"
                'model_architecture': self.step_request.model_architecture,  # "gmm_tps"
                'batch_size': self.step_request.batch_size,  # 2
                'memory_fraction': self.step_request.memory_fraction,  # 0.2
                'device': self.step_request.device,  # "auto"
                'precision': self.step_request.precision,  # "fp16"
                'use_real_models': True,
                'detailed_data_spec': True,
                'algorithm_type': 'advanced_deeplab_aspp_self_attention'
            }
            
            # DetailedDataSpec ë¡œë“œ
            if hasattr(self.step_request, 'data_spec'):
                self.data_spec = self.step_request.data_spec
                self.status.detailed_data_spec_loaded = True
                self.logger.info("âœ… DetailedDataSpec ë¡œë“œ ì™„ë£Œ")
            else:
                self.data_spec = None
                self.logger.warning("âš ï¸ DetailedDataSpec ì—†ìŒ")
        else:
            self._load_fallback_config()

    def _load_fallback_config(self):
        """í´ë°± ì„¤ì • ë¡œë“œ"""
        self.matching_config = {
            'method': 'advanced_deeplab_aspp_self_attention',
            'input_size': (256, 192),
            'output_format': 'transformation_matrix',
            'batch_size': 2,
            'device': self.device,
            'use_real_models': True,
            'algorithm_type': 'advanced_deeplab_aspp_self_attention'
        }
        self.data_spec = None
        self.logger.warning("âš ï¸ step_model_requirements.py ìš”êµ¬ì‚¬í•­ ë¡œë“œ ì‹¤íŒ¨ - í´ë°± ì„¤ì • ì‚¬ìš©")

    def _init_statistics(self):
        """í†µê³„ ì´ˆê¸°í™”"""
        self.statistics = {
            'total_processed': 0,
            'successful_matches': 0,
            'average_quality': 0.0,
            'total_processing_time': 0.0,
            'ai_model_calls': 0,
            'error_count': 0,
            'model_creation_success': False,
            'real_ai_models_used': True,
            'requirements_compatible': self.status.requirements_compatible,
            'algorithm_type': 'advanced_deeplab_aspp_self_attention',
            'features': [
                'DeepLabV3+ Backbone',
                'ASPP Multi-scale Context',
                'Self-Attention Keypoint Matching',
                'Edge-Aware Transformation',
                'Progressive Geometric Refinement',
                'Procrustes Analysis',
                'RANSAC Outlier Removal'
            ]
        }

    def _force_mps_device(self, device: str) -> str:
        """MPS ë””ë°”ì´ìŠ¤ ê°•ì œ ì„¤ì •"""
        try:
            import torch
            import platform
            
            if device == "auto":
                if (platform.system() == 'Darwin' and 
                    platform.machine() == 'arm64' and 
                    torch.backends.mps.is_available()):
                    self.logger.info("ğŸ GeometricMatchingStep: MPS ìë™ í™œì„±í™”")
                    return 'mps'
                elif torch.cuda.is_available():
                    return 'cuda'
                else:
                    return 'cpu'
            return device
        except Exception as e:
            self.logger.warning(f"âš ï¸ ë””ë°”ì´ìŠ¤ ì„¤ì • ì‹¤íŒ¨: {e}")
            return 'cpu'

    # ==============================================
    # ğŸ”¥ í•µì‹¬ AI ì¶”ë¡  ë©”ì„œë“œ (BaseStepMixin v19.1 í˜¸í™˜)
    # ==============================================

    def _run_ai_inference(self, processed_input: Dict[str, Any]) -> Dict[str, Any]:
        """
        ğŸ”¥ ê³ ê¸‰ ë”¥ëŸ¬ë‹ AI ì¶”ë¡  (ë™ê¸° ì²˜ë¦¬)
        BaseStepMixin v19.1ì—ì„œ í˜¸ì¶œí•˜ëŠ” í•µì‹¬ ë©”ì„œë“œ
        """
        try:
            start_time = time.time()
            self.logger.info(f"ğŸ§  {self.step_name} ê³ ê¸‰ AI ì¶”ë¡  ì‹œì‘...")
            
            # 1. ì…ë ¥ ë°ì´í„° ê²€ì¦ ë° ì „ì²˜ë¦¬
            person_image = processed_input.get('person_image')
            clothing_image = processed_input.get('clothing_image')
            pose_keypoints = processed_input.get('pose_keypoints')
            
            if person_image is None or clothing_image is None:
                raise ValueError("í•„ìˆ˜ ì…ë ¥ ë°ì´í„° ì—†ìŒ")
            
            # 2. ì´ë¯¸ì§€ í…ì„œ ë³€í™˜
            person_tensor = self._prepare_image_tensor(person_image)
            clothing_tensor = self._prepare_image_tensor(clothing_image)
            
            results = {}
            
            # ğŸ”¥ 3. ê³ ê¸‰ AI ëª¨ë¸ ì‹¤í–‰ (CompleteAdvancedGeometricMatchingAI)
            if self.advanced_geometric_ai is not None:
                advanced_result = self.advanced_geometric_ai(person_tensor, clothing_tensor)
                results['advanced_ai'] = advanced_result
                self.logger.info("âœ… ê³ ê¸‰ AI ëª¨ë¸ ì‹¤í–‰ ì™„ë£Œ")
            
            # ğŸ”¥ 4. í‚¤í¬ì¸íŠ¸ ê¸°ë°˜ ë§¤ì¹­ (AdvancedGeometricMatcher)
            if self.geometric_matcher is not None:
                try:
                    # í‚¤í¬ì¸íŠ¸ íˆíŠ¸ë§µì—ì„œ ì‹¤ì œ ì¢Œí‘œ ì¶”ì¶œ
                    if 'advanced_ai' in results and 'keypoint_heatmaps' in results['advanced_ai']:
                        person_keypoints = self.geometric_matcher.extract_keypoints_from_heatmaps(
                            results['advanced_ai']['keypoint_heatmaps']
                        )
                        clothing_keypoints = person_keypoints  # ë™ì¼í•œ êµ¬ì¡° ê°€ì •
                        
                        # Procrustes ë¶„ì„ ê¸°ë°˜ ìµœì  ë³€í˜•
                        transformation_matrix = self.geometric_matcher.compute_transformation_matrix_procrustes(
                            clothing_keypoints, person_keypoints
                        )
                        
                        results['procrustes_transform'] = transformation_matrix
                        results['keypoints'] = person_keypoints.cpu().numpy().tolist()
                        self.logger.info("âœ… Procrustes ë¶„ì„ ê¸°ë°˜ ë§¤ì¹­ ì™„ë£Œ")
                    
                except Exception as e:
                    self.logger.warning(f"âš ï¸ í‚¤í¬ì¸íŠ¸ ë§¤ì¹­ ì‹¤íŒ¨: {e}")
            
            # ğŸ”¥ 5. ê²°ê³¼ ìœµí•© ë° ìµœì¢… ì¶œë ¥
            final_result = self._fuse_ai_results(results, person_tensor, clothing_tensor)
            
            # 6. ì„±ëŠ¥ ë° í’ˆì§ˆ í‰ê°€
            processing_time = time.time() - start_time
            confidence = self._compute_enhanced_confidence(results)
            quality_score = self._compute_quality_score(results)
            
            final_result.update({
                'processing_time': processing_time,
                'confidence': confidence,
                'quality_score': quality_score,
                'ai_enhanced': self.ai_enhanced_mode,
                'algorithm_type': 'advanced_deeplab_aspp_self_attention',
                'algorithms_used': self._get_used_algorithms(results),
                'features': self.statistics['features']
            })
            
            # 7. í†µê³„ ì—…ë°ì´íŠ¸
            self.statistics['ai_model_calls'] += 1
            self.statistics['total_processing_time'] += processing_time
            self.statistics['successful_matches'] += 1
            
            self.logger.info(f"ğŸ‰ ê³ ê¸‰ AI ì¶”ë¡  ì™„ë£Œ - ì‹ ë¢°ë„: {confidence:.3f}, í’ˆì§ˆ: {quality_score:.3f}")
            return final_result
            
        except Exception as e:
            self.logger.error(f"âŒ ê³ ê¸‰ AI ì¶”ë¡  ì‹¤íŒ¨: {e}")
            self.statistics['error_count'] += 1
            
            # ğŸ”¥ í´ë°±: ê¸°ë³¸ ë°©ì‹ìœ¼ë¡œ ì²˜ë¦¬
            return self._fallback_ai_inference(processed_input)

    def _prepare_image_tensor(self, image: Any) -> torch.Tensor:
        """ì´ë¯¸ì§€ë¥¼ PyTorch í…ì„œë¡œ ë³€í™˜"""
        if not TORCH_AVAILABLE:
            raise RuntimeError("PyTorchê°€ í•„ìš”í•©ë‹ˆë‹¤")
        
        # PIL Image ì²˜ë¦¬
        if PIL_AVAILABLE and isinstance(image, Image.Image):
            image_array = np.array(image).astype(np.float32) / 255.0
            if len(image_array.shape) == 3:
                image_array = np.transpose(image_array, (2, 0, 1))  # HWC -> CHW
            tensor = torch.from_numpy(image_array).unsqueeze(0).to(self.device)
            
        # NumPy ë°°ì—´ ì²˜ë¦¬
        elif isinstance(image, np.ndarray):
            image_array = image.astype(np.float32)
            if image_array.max() > 1.0:
                image_array = image_array / 255.0
            if len(image_array.shape) == 3:
                image_array = np.transpose(image_array, (2, 0, 1))  # HWC -> CHW
            tensor = torch.from_numpy(image_array).unsqueeze(0).to(self.device)
            
        # ì´ë¯¸ í…ì„œì¸ ê²½ìš°
        elif torch.is_tensor(image):
            tensor = image.to(self.device)
            if tensor.dim() == 3:
                tensor = tensor.unsqueeze(0)
                
        else:
            raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì´ë¯¸ì§€ íƒ€ì…: {type(image)}")
        
        # step_model_requirements.py ê¸°ì¤€ í¬ê¸° ì¡°ì •
        target_size = self.matching_config.get('input_size', (256, 192))
        if tensor.shape[-2:] != target_size:
            tensor = F.interpolate(tensor, size=target_size, mode='bilinear', align_corners=False)
        
        return tensor

    def _fuse_ai_results(self, results: Dict[str, Any], 
                        person_tensor: torch.Tensor, 
                        clothing_tensor: torch.Tensor) -> Dict[str, Any]:
        """AI ê²°ê³¼ ìœµí•©"""
        
        # 1. ë³€í˜• ê·¸ë¦¬ë“œ/í–‰ë ¬ ìš°ì„ ìˆœìœ„ ê²°ì •
        transformation_matrix = None
        transformation_grid = None
        warped_clothing = None
        
        # ê³ ê¸‰ AI ê²°ê³¼ ìš°ì„  ì‚¬ìš©
        if 'advanced_ai' in results:
            adv_result = results['advanced_ai']
            if 'transformation_matrix' in adv_result:
                transformation_matrix = adv_result['transformation_matrix']
            if 'transformation_grid' in adv_result:
                transformation_grid = adv_result['transformation_grid']
            if 'warped_clothing' in adv_result:
                warped_clothing = adv_result['warped_clothing']
        
        # Procrustes ê²°ê³¼ ë³´ì¡° í™œìš©
        if 'procrustes_transform' in results and transformation_matrix is None:
            transformation_matrix = results['procrustes_transform']
        
        # í´ë°±: Identity ë³€í˜•
        if transformation_matrix is None:
            transformation_matrix = torch.eye(2, 3, device=self.device).unsqueeze(0)
        
        if transformation_grid is None:
            transformation_grid = self._create_identity_grid(1, 256, 192)
        
        # 2. ì˜ë¥˜ ì´ë¯¸ì§€ ë³€í˜• (ì—†ëŠ” ê²½ìš°)
        if warped_clothing is None:
            try:
                warped_clothing = F.grid_sample(
                    clothing_tensor, transformation_grid, mode='bilinear', 
                    padding_mode='border', align_corners=False
                )
            except Exception:
                warped_clothing = clothing_tensor.clone()
        
        # 3. ì¶”ê°€ ê²°ê³¼ ì •ë¦¬
        keypoint_heatmaps = None
        confidence_map = None
        edge_features = None
        
        if 'advanced_ai' in results:
            adv_result = results['advanced_ai']
            keypoint_heatmaps = adv_result.get('keypoint_heatmaps')
            confidence_map = adv_result.get('confidence_map')
            edge_features = adv_result.get('edge_features')
        
        # 4. Flow field ìƒì„±
        flow_field = self._generate_flow_field_from_grid(transformation_grid)
        
        return {
            'transformation_matrix': transformation_matrix,
            'transformation_grid': transformation_grid,
            'warped_clothing': warped_clothing,
            'flow_field': flow_field,
            'keypoint_heatmaps': keypoint_heatmaps,
            'confidence_map': confidence_map,
            'edge_features': edge_features,
            'keypoints': results.get('keypoints', []),
            'fusion_weights': self._compute_fusion_weights(results),
            'all_results': results
        }

    def _compute_enhanced_confidence(self, results: Dict[str, Any]) -> float:
        """ê°•í™”ëœ ì‹ ë¢°ë„ ê³„ì‚°"""
        confidences = []
        
        # ê³ ê¸‰ AI ì‹ ë¢°ë„
        if 'advanced_ai' in results and 'confidence_map' in results['advanced_ai']:
            ai_conf = torch.mean(results['advanced_ai']['confidence_map']).item()
            confidences.append(ai_conf)
        
        # Procrustes ë§¤ì¹­ ì‹ ë¢°ë„
        if 'procrustes_transform' in results:
            # ë³€í˜• í–‰ë ¬ì˜ ì¡°ê±´ìˆ˜ë¡œ ì•ˆì •ì„± í‰ê°€
            transform = results['procrustes_transform']
            try:
                det = torch.det(transform[:, :2, :2])
                stability = torch.clamp(1.0 / (torch.abs(det) + 1e-8), 0, 1)
                confidences.append(stability.mean().item())
            except:
                confidences.append(0.7)
        
        # í‚¤í¬ì¸íŠ¸ ë§¤ì¹­ ì‹ ë¢°ë„
        if 'keypoints' in results and len(results['keypoints']) > 0:
            keypoints_conf = min(1.0, len(results['keypoints']) / 20.0)  # 20ê°œ ê¸°ì¤€
            confidences.append(keypoints_conf)
        
        return float(np.mean(confidences)) if confidences else 0.8

    def _compute_quality_score(self, results: Dict[str, Any]) -> float:
        """í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°"""
        quality_factors = []
        
        # ì•Œê³ ë¦¬ì¦˜ ì‚¬ìš© ì ìˆ˜
        if 'advanced_ai' in results:
            quality_factors.append(0.9)  # ê³ ê¸‰ AI ì‚¬ìš©
        
        if 'procrustes_transform' in results:
            quality_factors.append(0.8)  # Procrustes ë¶„ì„
        
        # í‚¤í¬ì¸íŠ¸ í’ˆì§ˆ
        if 'keypoints' in results:
            kpt_count = len(results['keypoints'])
            kpt_quality = min(1.0, kpt_count / 20.0)
            quality_factors.append(kpt_quality)
        
        # Edge features í’ˆì§ˆ
        if 'advanced_ai' in results and 'edge_features' in results['advanced_ai']:
            edge_feat = results['advanced_ai']['edge_features']
            if isinstance(edge_feat, torch.Tensor):
                edge_quality = torch.mean(torch.abs(edge_feat)).item()
                quality_factors.append(min(1.0, edge_quality))
        
        return float(np.mean(quality_factors)) if quality_factors else 0.75

    def _get_used_algorithms(self, results: Dict[str, Any]) -> List[str]:
        """ì‚¬ìš©ëœ ì•Œê³ ë¦¬ì¦˜ ëª©ë¡"""
        algorithms = []
        
        if 'advanced_ai' in results:
            algorithms.extend([
                "DeepLabV3+ Backbone",
                "ASPP Multi-scale Context",
                "Self-Attention Keypoint Matching",
                "Edge-Aware Transformation",
                "Progressive Geometric Refinement"
            ])
        
        if 'procrustes_transform' in results:
            algorithms.append("Procrustes Analysis")
        
        return algorithms

    def _compute_fusion_weights(self, results: Dict[str, Any]) -> List[float]:
        """ìœµí•© ê°€ì¤‘ì¹˜ ê³„ì‚°"""
        weights = []
        
        if 'advanced_ai' in results:
            weights.append(0.8)  # ê³ ê¸‰ AI ë†’ì€ ê°€ì¤‘ì¹˜
        
        if 'procrustes_transform' in results:
            weights.append(0.2)  # Procrustes ë³´ì¡° ê°€ì¤‘ì¹˜
        
        return weights

    def _fallback_ai_inference(self, processed_input: Dict[str, Any]) -> Dict[str, Any]:
        """í´ë°±: ê¸°ë³¸ ë°©ì‹ AI ì¶”ë¡ """
        try:
            person_image = processed_input.get('person_image')
            clothing_image = processed_input.get('clothing_image')
            
            # ê¸°ë³¸ identity ë³€í˜•
            transformation_matrix = torch.eye(2, 3).unsqueeze(0)
            transformation_grid = self._create_identity_grid(1, 256, 192)
            
            # ë”ë¯¸ ê²°ê³¼ ìƒì„±
            result = {
                'transformation_matrix': transformation_matrix,
                'transformation_grid': transformation_grid,
                'warped_clothing': torch.zeros(1, 3, 256, 192),
                'flow_field': torch.zeros(1, 2, 256, 192),
                'keypoints': [],
                'confidence': 0.5,
                'quality_score': 0.5,
                'algorithm_type': 'fallback_basic',
                'fallback_used': True
            }
            
            return result
            
        except Exception as e:
            self.logger.error(f"âŒ í´ë°± ì²˜ë¦¬ë„ ì‹¤íŒ¨: {e}")
            return {
                'transformation_matrix': torch.eye(2, 3).unsqueeze(0),
                'confidence': 0.3,
                'quality_score': 0.3,
                'error': str(e),
                'algorithm_type': 'error_fallback'
            }

    def _create_identity_grid(self, batch_size: int, H: int, W: int) -> torch.Tensor:
        """Identity ê·¸ë¦¬ë“œ ìƒì„±"""
        y, x = torch.meshgrid(
            torch.linspace(-1, 1, H, device=self.device),
            torch.linspace(-1, 1, W, device=self.device),
            indexing='ij'
        )
        grid = torch.stack([x, y], dim=-1).unsqueeze(0).repeat(batch_size, 1, 1, 1)
        return grid

    def _generate_flow_field_from_grid(self, transformation_grid: torch.Tensor) -> torch.Tensor:
        """ë³€í˜• ê·¸ë¦¬ë“œì—ì„œ flow field ìƒì„±"""
        batch_size, H, W, _ = transformation_grid.shape
        
        # ê¸°ë³¸ ê·¸ë¦¬ë“œ
        y, x = torch.meshgrid(
            torch.linspace(-1, 1, H, device=transformation_grid.device),
            torch.linspace(-1, 1, W, device=transformation_grid.device),
            indexing='ij'
        )
        base_grid = torch.stack([x, y], dim=-1).unsqueeze(0).repeat(batch_size, 1, 1, 1)
        
        # Flow field ê³„ì‚°
        flow = (transformation_grid - base_grid) * torch.tensor([W/2, H/2], device=transformation_grid.device)
        
        return flow.permute(0, 3, 1, 2)  # (B, 2, H, W)

    # ==============================================
    # ğŸ”¥ ì´ˆê¸°í™” ë° ëª¨ë¸ ë¡œë”©
    # ==============================================

    async def initialize(self) -> bool:
        """Step ì´ˆê¸°í™”"""
        try:
            if self.status.initialized:
                return True
                
            self.logger.info(f"ğŸ”„ ê³ ê¸‰ AI Step ì´ˆê¸°í™” ì‹œì‘...")
            
            # ëª¨ë¸ ê²½ë¡œ ë§¤í•‘
            await self._initialize_model_paths()
            
            # ê³ ê¸‰ AI ëª¨ë¸ ë¡œë”©
            await self._load_advanced_ai_models()
            
            self.status.initialized = True
            self.logger.info(f"âœ… ê³ ê¸‰ AI Step ì´ˆê¸°í™” ì™„ë£Œ")
            
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ ê³ ê¸‰ AI Step ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return False

    async def _initialize_model_paths(self):
        """ëª¨ë¸ ê²½ë¡œ ì´ˆê¸°í™”"""
        try:
            if hasattr(self, 'model_mapper'):
                self.model_paths = self.model_mapper.get_geometric_matching_models()
                self.logger.info(f"ğŸ“ ëª¨ë¸ ê²½ë¡œ ë§¤í•‘ ì™„ë£Œ: {len(self.model_paths)}ê°œ íŒŒì¼")
                
                for model_name, path in self.model_paths.items():
                    size_mb = path.stat().st_size / (1024**2) if path.exists() else 0
                    self.logger.info(f"  - {model_name}: {path.name} ({size_mb:.1f}MB)")
            else:
                self.model_paths = {}
                self.logger.warning("ğŸ“ ëª¨ë¸ ê²½ë¡œ ë§¤í•‘ ì‹œìŠ¤í…œ ì—†ìŒ")
        except Exception as e:
            self.logger.warning(f"âš ï¸ ëª¨ë¸ ê²½ë¡œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.model_paths = {}

    async def _load_advanced_ai_models(self):
        """ê³ ê¸‰ AI ëª¨ë¸ ë¡œë”©"""
        try:
            models_loaded = 0
            
            # 1. CompleteAdvancedGeometricMatchingAI ìƒì„±
            try:
                self.advanced_geometric_ai = CompleteAdvancedGeometricMatchingAI(
                    input_nc=6, num_keypoints=20
                ).to(self.device)
                self.advanced_geometric_ai.eval()
                models_loaded += 1
                self.logger.info("âœ… CompleteAdvancedGeometricMatchingAI ë¡œë”© ì™„ë£Œ")
                
                # ì‹¤ì œ ì²´í¬í¬ì¸íŠ¸ ë¡œë”© ì‹œë„
                if 'gmm' in self.model_paths:
                    self._load_pretrained_weights(self.model_paths['gmm'])
                
            except Exception as e:
                self.logger.warning(f"âš ï¸ CompleteAdvancedGeometricMatchingAI ë¡œë”© ì‹¤íŒ¨: {e}")
            
            # 2. AdvancedGeometricMatcher ìƒì„±
            try:
                self.geometric_matcher = AdvancedGeometricMatcher(self.device)
                models_loaded += 1
                self.logger.info("âœ… AdvancedGeometricMatcher ë¡œë”© ì™„ë£Œ")
            except Exception as e:
                self.logger.warning(f"âš ï¸ AdvancedGeometricMatcher ë¡œë”© ì‹¤íŒ¨: {e}")
            
            self.status.models_loaded = models_loaded > 0
            self.status.advanced_ai_loaded = self.advanced_geometric_ai is not None
            self.status.model_creation_success = models_loaded > 0
            
            # ê¸°ì¡´ í˜¸í™˜ì„±ì„ ìœ„í•œ ì†ì„± ì„¤ì •
            self.geometric_model = self.advanced_geometric_ai
            self.gmm_model = self.advanced_geometric_ai  # ê¸°ì¡´ í˜¸í™˜ì„±
            
            if models_loaded > 0:
                self.logger.info(f"âœ… ê³ ê¸‰ AI ëª¨ë¸ ë¡œë”© ì™„ë£Œ: {models_loaded}/2ê°œ")
            else:
                self.logger.warning("âš ï¸ ì‹¤ì œ ëª¨ë¸ íŒŒì¼ ì—†ìŒ - ëœë¤ ì´ˆê¸°í™” ëª¨ë“œ")
                self.status.models_loaded = True  # ëœë¤ ì´ˆê¸°í™”ë¡œë¼ë„ ë™ì‘
                
        except Exception as e:
            self.logger.warning(f"âš ï¸ ê³ ê¸‰ AI ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨ - ê¸°ë³¸ ëª¨ë“œ: {e}")
            self.status.models_loaded = True

    def _load_pretrained_weights(self, checkpoint_path: Path):
        """ì‚¬ì „ í•™ìŠµëœ ê°€ì¤‘ì¹˜ ë¡œë”©"""
        try:
            if not checkpoint_path.exists():
                self.logger.warning(f"âš ï¸ ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ ì—†ìŒ: {checkpoint_path}")
                return
            
            self.logger.info(f"ğŸ”„ ì²´í¬í¬ì¸íŠ¸ ë¡œë”© ì‹œë„: {checkpoint_path}")
            
            # ì²´í¬í¬ì¸íŠ¸ ë¡œë”©
            checkpoint = torch.load(checkpoint_path, map_location='cpu')
            
            # ë‹¤ì–‘í•œ ì²´í¬í¬ì¸íŠ¸ í˜•ì‹ ì²˜ë¦¬
            if isinstance(checkpoint, dict):
                if 'model_state_dict' in checkpoint:
                    state_dict = checkpoint['model_state_dict']
                elif 'state_dict' in checkpoint:
                    state_dict = checkpoint['state_dict']
                elif 'generator' in checkpoint:
                    state_dict = checkpoint['generator']
                else:
                    state_dict = checkpoint
            else:
                state_dict = checkpoint
            
            # í‚¤ ì´ë¦„ ë§¤í•‘
            new_state_dict = {}
            for k, v in state_dict.items():
                new_key = k
                if k.startswith('module.'):
                    new_key = k[7:]  # 'module.' ì œê±°
                elif k.startswith('netG.'):
                    new_key = k[5:]  # 'netG.' ì œê±°
                elif k.startswith('generator.'):
                    new_key = k[10:]  # 'generator.' ì œê±°
                
                new_state_dict[new_key] = v
            
            # í˜¸í™˜ ê°€ëŠ¥í•œ ê°€ì¤‘ì¹˜ë§Œ ë¡œë”©
            model_dict = self.advanced_geometric_ai.state_dict()
            compatible_dict = {}
            
            for k, v in new_state_dict.items():
                if k in model_dict and v.shape == model_dict[k].shape:
                    compatible_dict[k] = v
            
            if len(compatible_dict) > 0:
                model_dict.update(compatible_dict)
                self.advanced_geometric_ai.load_state_dict(model_dict)
                self.logger.info(f"âœ… ì²´í¬í¬ì¸íŠ¸ ë¶€ë¶„ ë¡œë”©: {len(compatible_dict)}/{len(new_state_dict)}ê°œ ë ˆì´ì–´")
            else:
                self.logger.warning("âš ï¸ í˜¸í™˜ ê°€ëŠ¥í•œ ë ˆì´ì–´ ì—†ìŒ - ëœë¤ ì´ˆê¸°í™” ìœ ì§€")
                
        except Exception as e:
            self.logger.warning(f"âš ï¸ ì²´í¬í¬ì¸íŠ¸ ë¡œë”© ì‹¤íŒ¨: {e}")

    # ==============================================
    # ğŸ”¥ BaseStepMixin í˜¸í™˜ ì˜ì¡´ì„± ì£¼ì… ë©”ì„œë“œë“¤
    # ==============================================

    def set_model_loader(self, model_loader):
        """ModelLoader ì˜ì¡´ì„± ì£¼ì… (BaseStepMixin í˜¸í™˜)"""
        try:
            self.model_loader = model_loader
            self.has_model = True
            self.model_loaded = True
            self.logger.info("âœ… ModelLoader ì˜ì¡´ì„± ì£¼ì… ì™„ë£Œ")
            
            # Step ì¸í„°í˜ì´ìŠ¤ ìƒì„±
            if hasattr(model_loader, 'create_step_interface'):
                try:
                    self.model_interface = model_loader.create_step_interface(self.step_name)
                    self.logger.info("âœ… Step ì¸í„°í˜ì´ìŠ¤ ìƒì„± ì™„ë£Œ")
                except Exception as e:
                    self.logger.debug(f"Step ì¸í„°í˜ì´ìŠ¤ ìƒì„± ì‹¤íŒ¨: {e}")
                    self.model_interface = model_loader
            else:
                self.model_interface = model_loader
                
        except Exception as e:
            self.logger.error(f"âŒ ModelLoader ì˜ì¡´ì„± ì£¼ì… ì‹¤íŒ¨: {e}")

    def set_memory_manager(self, memory_manager):
        """MemoryManager ì˜ì¡´ì„± ì£¼ì…"""
        try:
            self.memory_manager = memory_manager
            self.logger.info("âœ… MemoryManager ì˜ì¡´ì„± ì£¼ì… ì™„ë£Œ")
        except Exception as e:
            self.logger.warning(f"âš ï¸ MemoryManager ì˜ì¡´ì„± ì£¼ì… ì‹¤íŒ¨: {e}")

    def set_data_converter(self, data_converter):
        """DataConverter ì˜ì¡´ì„± ì£¼ì…"""
        try:
            self.data_converter = data_converter
            self.logger.info("âœ… DataConverter ì˜ì¡´ì„± ì£¼ì… ì™„ë£Œ")
        except Exception as e:
            self.logger.warning(f"âš ï¸ DataConverter ì˜ì¡´ì„± ì£¼ì… ì‹¤íŒ¨: {e}")

    def set_di_container(self, di_container):
        """DI Container ì˜ì¡´ì„± ì£¼ì…"""
        try:
            self.di_container = di_container
            self.logger.info("âœ… DI Container ì˜ì¡´ì„± ì£¼ì… ì™„ë£Œ")
        except Exception as e:
            self.logger.warning(f"âš ï¸ DI Container ì˜ì¡´ì„± ì£¼ì… ì‹¤íŒ¨: {e}")

    # ==============================================
    # ğŸ”¥ ì •ë³´ ì¡°íšŒ ë° ê²€ì¦ ë©”ì„œë“œë“¤
    # ==============================================

    async def get_step_info(self) -> Dict[str, Any]:
        """Step ì •ë³´ ë°˜í™˜"""
        return {
            'step_name': self.step_name,
            'step_id': self.step_id,
            'initialized': self.status.initialized,
            'models_loaded': self.status.models_loaded,
            'advanced_ai_loaded': self.status.advanced_ai_loaded,
            'ai_enhanced_mode': self.status.ai_enhanced_mode,
            'dependencies_injected': self.status.dependencies_injected,
            'processing_active': self.status.processing_active,
            'requirements_compatible': self.status.requirements_compatible,
            'detailed_data_spec_loaded': self.status.detailed_data_spec_loaded,
            'device': self.device,
            'algorithm_type': self.matching_config.get('algorithm_type', 'advanced_deeplab_aspp_self_attention'),
            'input_size': self.matching_config.get('input_size', (256, 192)),
            'output_format': self.matching_config.get('output_format', 'transformation_matrix'),
            'batch_size': self.matching_config.get('batch_size', 2),
            'memory_fraction': self.matching_config.get('memory_fraction', 0.2),
            'precision': self.matching_config.get('precision', 'fp16'),
            'model_files_detected': len(self.model_paths) if hasattr(self, 'model_paths') else 0,
            'advanced_geometric_ai_loaded': self.advanced_geometric_ai is not None,
            'geometric_matcher_loaded': self.geometric_matcher is not None,
            'statistics': self.statistics,
            'features': self.statistics['features']
        }

    def validate_dependencies(self, format_type: Optional[str] = None) -> Union[Dict[str, bool], Dict[str, Any]]:
        """ì˜ì¡´ì„± ê²€ì¦ (ì˜¤ë²„ë¡œë“œ ì§€ì›)"""
        try:
            # ê¸°ë³¸ ì˜ì¡´ì„± ìƒíƒœ
            basic_status = {
                'model_loader': self.model_loader is not None,
                'step_interface': self.model_interface is not None,
                'memory_manager': self.memory_manager is not None,
                'data_converter': self.data_converter is not None
            }
            
            # format_typeì— ë”°ë¥¸ ë°˜í™˜ í˜•ì‹ ê²°ì •
            if format_type == "boolean" or format_type is None:
                return basic_status
            
            elif format_type == "detailed":
                return {
                    'success': basic_status['model_loader'],
                    'details': {
                        'model_loader': basic_status['model_loader'],
                        'step_interface': basic_status['step_interface'],
                        'memory_manager': basic_status['memory_manager'],
                        'data_converter': basic_status['data_converter'],
                        'github_compatible': True,
                        'requirements_compatible': self.status.requirements_compatible,
                        'models_loaded': self.status.models_loaded,
                        'ai_enhanced': True,
                        'advanced_ai_loaded': self.status.advanced_ai_loaded
                    },
                    'metadata': {
                        'step_name': self.step_name,
                        'step_id': self.step_id,
                        'device': self.device,
                        'version': '15.0',
                        'algorithm_type': 'advanced_deeplab_aspp_self_attention'
                    }
                }
            
            else:
                return basic_status
                
        except Exception as e:
            self.logger.error(f"âŒ ì˜ì¡´ì„± ê²€ì¦ ì‹¤íŒ¨: {e}")
            
            if format_type == "detailed":
                return {
                    'success': False,
                    'error': str(e),
                    'details': {
                        'model_loader': False,
                        'step_interface': False,
                        'memory_manager': False,
                        'data_converter': False
                    }
                }
            else:
                return {
                    'model_loader': False,
                    'step_interface': False,
                    'memory_manager': False,
                    'data_converter': False
                }

    async def validate_inputs(self, person_image: Any, clothing_image: Any) -> Dict[str, Any]:
        """ì…ë ¥ ê²€ì¦"""
        errors = []
        
        if person_image is None:
            errors.append("person_imageê°€ Noneì…ë‹ˆë‹¤")
        
        if clothing_image is None:
            errors.append("clothing_imageê°€ Noneì…ë‹ˆë‹¤")
        
        # DetailedDataSpec ê¸°ì¤€ ê²€ì¦
        if self.data_spec:
            if hasattr(self.data_spec, 'input_data_types'):
                valid_types = self.data_spec.input_data_types
                if person_image is not None:
                    person_type_valid = any(
                        isinstance(person_image, eval(dtype)) if dtype != 'PIL.Image' 
                        else isinstance(person_image, Image.Image)
                        for dtype in valid_types
                    )
                    if not person_type_valid:
                        errors.append(f"person_image íƒ€ì… ë¶ˆì¼ì¹˜. í—ˆìš© íƒ€ì…: {valid_types}")
        
        return {
            'valid': len(errors) == 0,
            'person_image': person_image is not None,
            'clothing_image': clothing_image is not None,
            'errors': errors,
            'requirements_compatible': self.status.requirements_compatible,
            'algorithm_type': 'advanced_deeplab_aspp_self_attention'
        }

    # ==============================================
    # ğŸ”¥ ê°œë°œ ë„êµ¬ ë° ë””ë²„ê¹… ë©”ì„œë“œë“¤
    # ==============================================

    def debug_info(self) -> Dict[str, Any]:
        """ë””ë²„ê¹… ì •ë³´ ë°˜í™˜"""
        try:
            return {
                'step_info': {
                    'name': self.step_name,
                    'id': self.step_id,
                    'device': self.device,
                    'initialized': self.status.initialized,
                    'models_loaded': self.status.models_loaded,
                    'algorithm_type': 'advanced_deeplab_aspp_self_attention'
                },
                'ai_models': {
                    'advanced_geometric_ai_loaded': self.advanced_geometric_ai is not None,
                    'geometric_matcher_loaded': self.geometric_matcher is not None,
                    'model_files_detected': len(self.model_paths) if hasattr(self, 'model_paths') else 0
                },
                'config': self.matching_config if hasattr(self, 'matching_config') else {},
                'statistics': self.statistics if hasattr(self, 'statistics') else {},
                'device_info': {
                    'torch_available': TORCH_AVAILABLE,
                    'mps_available': MPS_AVAILABLE,
                    'current_device': self.device
                },
                'requirements': {
                    'compatible': self.status.requirements_compatible,
                    'detailed_spec_loaded': self.status.detailed_data_spec_loaded,
                    'ai_enhanced': self.status.ai_enhanced_mode
                },
                'features': self.statistics.get('features', [])
            }
        except Exception as e:
            self.logger.error(f"âŒ ë””ë²„ê¹… ì •ë³´ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            return {'error': str(e)}

    def get_performance_stats(self) -> Dict[str, Any]:
        """ì„±ëŠ¥ í†µê³„ ë°˜í™˜"""
        try:
            if hasattr(self, 'statistics'):
                stats = self.statistics.copy()
                
                # ì¶”ê°€ ê³„ì‚°ëœ í†µê³„
                if stats['total_processed'] > 0:
                    stats['average_processing_time'] = stats['total_processing_time'] / stats['total_processed']
                    stats['success_rate'] = stats['successful_matches'] / stats['total_processed']
                else:
                    stats['average_processing_time'] = 0.0
                    stats['success_rate'] = 0.0
                
                stats['algorithm_type'] = 'advanced_deeplab_aspp_self_attention'
                return stats
            else:
                return {'message': 'í†µê³„ ë°ì´í„° ì—†ìŒ'}
        except Exception as e:
            self.logger.error(f"âŒ ì„±ëŠ¥ í†µê³„ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            return {'error': str(e)}

    def health_check(self) -> Dict[str, Any]:
        """ê±´ê°• ìƒíƒœ ì²´í¬"""
        try:
            health_status = {
                'overall_status': 'healthy',
                'timestamp': time.time(),
                'checks': {},
                'algorithm_type': 'advanced_deeplab_aspp_self_attention'
            }
            
            issues = []
            
            # 1. ì´ˆê¸°í™” ìƒíƒœ ì²´í¬
            if not self.status.initialized:
                issues.append('Stepì´ ì´ˆê¸°í™”ë˜ì§€ ì•ŠìŒ')
                health_status['checks']['initialization'] = 'failed'
            else:
                health_status['checks']['initialization'] = 'passed'
            
            # 2. ê³ ê¸‰ AI ëª¨ë¸ ë¡œë”© ìƒíƒœ ì²´í¬
            if not self.status.advanced_ai_loaded:
                issues.append('ê³ ê¸‰ AI ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•ŠìŒ')
                health_status['checks']['advanced_ai'] = 'failed'
            else:
                health_status['checks']['advanced_ai'] = 'passed'
            
            # 3. ì˜ì¡´ì„± ì²´í¬
            deps = self.validate_dependencies()
            if not deps.get('model_loader', False):
                issues.append('ModelLoader ì˜ì¡´ì„± ì—†ìŒ')
                health_status['checks']['dependencies'] = 'failed'
            else:
                health_status['checks']['dependencies'] = 'passed'
            
            # 4. ë””ë°”ì´ìŠ¤ ìƒíƒœ ì²´í¬
            if TORCH_AVAILABLE:
                if self.device == "mps" and not MPS_AVAILABLE:
                    issues.append('MPS ë””ë°”ì´ìŠ¤ ì‚¬ìš©í•  ìˆ˜ ì—†ìŒ')
                    health_status['checks']['device'] = 'warning'
                elif self.device == "cuda" and not torch.cuda.is_available():
                    issues.append('CUDA ë””ë°”ì´ìŠ¤ ì‚¬ìš©í•  ìˆ˜ ì—†ìŒ')
                    health_status['checks']['device'] = 'warning'
                else:
                    health_status['checks']['device'] = 'passed'
            else:
                issues.append('PyTorch ì‚¬ìš©í•  ìˆ˜ ì—†ìŒ')
                health_status['checks']['device'] = 'failed'
            
            # ì „ì²´ ìƒíƒœ ê²°ì •
            if any(status == 'failed' for status in health_status['checks'].values()):
                health_status['overall_status'] = 'unhealthy'
            elif any(status == 'warning' for status in health_status['checks'].values()):
                health_status['overall_status'] = 'degraded'
            
            if issues:
                health_status['issues'] = issues
            
            return health_status
            
        except Exception as e:
            self.logger.error(f"âŒ ê±´ê°• ìƒíƒœ ì²´í¬ ì‹¤íŒ¨: {e}")
            return {
                'overall_status': 'error',
                'error': str(e),
                'timestamp': time.time(),
                'algorithm_type': 'advanced_deeplab_aspp_self_attention'
            }

    # ==============================================
    # ğŸ”¥ ì •ë¦¬ ì‘ì—…
    # ==============================================

    async def cleanup(self):
        """ì •ë¦¬ ì‘ì—…"""
        try:
            # ê³ ê¸‰ AI ëª¨ë¸ ì •ë¦¬
            if hasattr(self, 'advanced_geometric_ai') and self.advanced_geometric_ai is not None:
                del self.advanced_geometric_ai
                self.advanced_geometric_ai = None
            
            if hasattr(self, 'geometric_matcher') and self.geometric_matcher is not None:
                del self.geometric_matcher
                self.geometric_matcher = None
            
            # ê¸°ì¡´ í˜¸í™˜ì„± ì†ì„± ì •ë¦¬
            if hasattr(self, 'geometric_model'):
                self.geometric_model = None
            
            if hasattr(self, 'gmm_model'):
                self.gmm_model = None
            
            # ì¸í„°í˜ì´ìŠ¤ ì •ë¦¬
            if hasattr(self, 'model_interface'):
                del self.model_interface
            
            # ë§¤í•‘ ì •ë¦¬
            if hasattr(self, 'model_paths'):
                self.model_paths.clear()
            
            # ìºì‹œ ì •ë¦¬
            if hasattr(self, 'model_mapper') and hasattr(self.model_mapper, 'model_cache'):
                self.model_mapper.model_cache.clear()
            
            # ë©”ëª¨ë¦¬ ì •ë¦¬
            if TORCH_AVAILABLE and self.device == "mps":
                try:
                    if hasattr(torch.backends.mps, 'empty_cache'):
                        torch.backends.mps.empty_cache()
                    elif hasattr(torch.mps, 'empty_cache'):
                        torch.mps.empty_cache()
                except:
                    pass
            elif TORCH_AVAILABLE and torch.cuda.is_available():
                torch.cuda.empty_cache()
            
            gc.collect()
            
            self.logger.info("âœ… GeometricMatchingStep ì •ë¦¬ ì™„ë£Œ")
            
        except Exception as e:
            self.logger.error(f"âŒ ì •ë¦¬ ì‘ì—… ì‹¤íŒ¨: {e}")

# ==============================================
# ğŸ”¥ 11. í¸ì˜ í•¨ìˆ˜ë“¤
# ==============================================

def create_geometric_matching_step(**kwargs) -> GeometricMatchingStep:
    """ê¸°í•˜í•™ì  ë§¤ì¹­ Step ìƒì„±"""
    return GeometricMatchingStep(**kwargs)

def create_advanced_ai_geometric_matching_step(**kwargs) -> GeometricMatchingStep:
    """ê³ ê¸‰ AI ê¸°í•˜í•™ì  ë§¤ì¹­ Step ìƒì„±"""
    kwargs.setdefault('ai_enhanced', True)
    kwargs.setdefault('use_advanced_algorithms', True)
    return GeometricMatchingStep(**kwargs)

def create_m3_max_geometric_matching_step(**kwargs) -> GeometricMatchingStep:
    """M3 Max ìµœì í™” ê¸°í•˜í•™ì  ë§¤ì¹­ Step ìƒì„±"""
    kwargs.setdefault('device', 'mps')
    kwargs.setdefault('ai_enhanced', True)
    kwargs.setdefault('use_advanced_algorithms', True)
    return GeometricMatchingStep(**kwargs)

# ==============================================
# ğŸ”¥ 12. í…ŒìŠ¤íŠ¸ ë° ê²€ì¦ í•¨ìˆ˜ë“¤
# ==============================================

def validate_dependencies() -> Dict[str, bool]:
    """ì˜ì¡´ì„± ê²€ì¦"""
    return {
        "torch": TORCH_AVAILABLE,
        "torchvision": TORCHVISION_AVAILABLE,
        "pil": PIL_AVAILABLE,
        "scipy": SCIPY_AVAILABLE,
        "cv2": CV2_AVAILABLE,
        "base_step_mixin": BaseStepMixin is not None,
        "model_loader_dynamic": get_model_loader() is not None,
        "memory_manager_dynamic": get_memory_manager() is not None,
        "data_converter_dynamic": get_data_converter() is not None,
        "di_container_dynamic": get_di_container() is not None,
        "step_model_request": get_step_model_request() is not None,
        "advanced_ai_algorithms": True,
        "enhanced_model_mapper": True
    }

async def test_advanced_ai_geometric_matching() -> bool:
    """ê³ ê¸‰ AI ê¸°í•˜í•™ì  ë§¤ì¹­ í…ŒìŠ¤íŠ¸"""
    
    try:
        logger.info("ğŸ” ê³ ê¸‰ AI ê¸°í•˜í•™ì  ë§¤ì¹­ í…ŒìŠ¤íŠ¸ ì‹œì‘")
        
        # ì˜ì¡´ì„± í™•ì¸
        deps = validate_dependencies()
        missing_deps = [k for k, v in deps.items() if not v and k not in ['advanced_ai_algorithms', 'enhanced_model_mapper']]
        if missing_deps:
            logger.warning(f"âš ï¸ ëˆ„ë½ëœ ì˜ì¡´ì„±: {missing_deps}")
        
        # Step ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
        step = create_advanced_ai_geometric_matching_step(device="cpu")
        
        # step_model_requirements.py í˜¸í™˜ì„± í™•ì¸
        logger.info("ğŸ” step_model_requirements.py í˜¸í™˜ì„±:")
        logger.info(f"  - ìš”êµ¬ì‚¬í•­ ë¡œë“œ: {'âœ…' if step.status.requirements_compatible else 'âŒ'}")
        logger.info(f"  - DetailedDataSpec: {'âœ…' if step.status.detailed_data_spec_loaded else 'âŒ'}")
        logger.info(f"  - AI í´ë˜ìŠ¤: {step.step_request.ai_class if step.step_request else 'N/A'}")
        logger.info(f"  - ì•Œê³ ë¦¬ì¦˜ íƒ€ì…: {step.matching_config.get('algorithm_type', 'N/A')}")
        logger.info(f"  - ì…ë ¥ í¬ê¸°: {step.matching_config.get('input_size', 'N/A')}")
        logger.info(f"  - ì¶œë ¥ í˜•ì‹: {step.matching_config.get('output_format', 'N/A')}")
        
        # ì´ˆê¸°í™” í…ŒìŠ¤íŠ¸
        try:
            await step.initialize()
            logger.info("âœ… ê³ ê¸‰ AI ì´ˆê¸°í™” ì„±ê³µ")
            
            # Step ì •ë³´ í™•ì¸
            step_info = await step.get_step_info()
            logger.info(f"ğŸ“‹ ê³ ê¸‰ AI Step ì •ë³´:")
            logger.info(f"  - ì•Œê³ ë¦¬ì¦˜ íƒ€ì…: {step_info['algorithm_type']}")
            logger.info(f"  - ê³ ê¸‰ AI ë¡œë“œ: {'âœ…' if step_info['advanced_ai_loaded'] else 'âŒ'}")
            logger.info(f"  - AI ê°•í™” ëª¨ë“œ: {'âœ…' if step_info['ai_enhanced_mode'] else 'âŒ'}")
            logger.info(f"  - íŠ¹ì§•ë“¤: {len(step_info['features'])}ê°œ")
            for feature in step_info['features']:
                logger.info(f"    â€¢ {feature}")
                
        except Exception as e:
            logger.error(f"âŒ ê³ ê¸‰ AI ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return False
        
        # AI ì¶”ë¡  í…ŒìŠ¤íŠ¸ (ë”ë¯¸ ë°ì´í„°)
        if TORCH_AVAILABLE:
            dummy_person = torch.randn(1, 3, 256, 192)
            dummy_clothing = torch.randn(1, 3, 256, 192)
        else:
            dummy_person = np.random.randn(256, 192, 3).astype(np.float32)
            dummy_clothing = np.random.randn(256, 192, 3).astype(np.float32)
        
        try:
            # BaseStepMixin process í˜¸ì¶œ (ì‹¤ì œ ì‚¬ìš©ë²•)
            if hasattr(step, 'process'):
                result = await step.process(dummy_person, dummy_clothing)
            else:
                # ì§ì ‘ AI ì¶”ë¡  í˜¸ì¶œ
                processed_input = {
                    'person_image': dummy_person,
                    'clothing_image': dummy_clothing
                }
                result = step._run_ai_inference(processed_input)
            
            if result and isinstance(result, dict):
                logger.info(f"âœ… ê³ ê¸‰ AI ì¶”ë¡  ì„±ê³µ")
                logger.info(f"  - ì•Œê³ ë¦¬ì¦˜: {result.get('algorithm_type', 'N/A')}")
                logger.info(f"  - ì‹ ë¢°ë„: {result.get('confidence', 0):.3f}")
                logger.info(f"  - í’ˆì§ˆ: {result.get('quality_score', 0):.3f}")
                logger.info(f"  - ë³€í˜• í–‰ë ¬: {'âœ…' if result.get('transformation_matrix') is not None else 'âŒ'}")
                logger.info(f"  - ì›Œí•‘ ì˜ë¥˜: {'âœ…' if result.get('warped_clothing') is not None else 'âŒ'}")
                logger.info(f"  - í‚¤í¬ì¸íŠ¸ íˆíŠ¸ë§µ: {'âœ…' if result.get('keypoint_heatmaps') is not None else 'âŒ'}")
                logger.info(f"  - ì‚¬ìš©ëœ ì•Œê³ ë¦¬ì¦˜: {len(result.get('algorithms_used', []))}ê°œ")
            else:
                logger.warning(f"âš ï¸ ê³ ê¸‰ AI ì¶”ë¡  ê²°ê³¼ ì—†ìŒ")
        except Exception as e:
            logger.warning(f"âš ï¸ ê³ ê¸‰ AI ì¶”ë¡  í…ŒìŠ¤íŠ¸ ì˜¤ë¥˜: {e}")
        
        # ì •ë¦¬
        await step.cleanup()
        
        logger.info("âœ… ê³ ê¸‰ AI ê¸°í•˜í•™ì  ë§¤ì¹­ í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
        return True
        
    except Exception as e:
        logger.error(f"âŒ ê³ ê¸‰ AI í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        return False

# ==============================================
# ğŸ”¥ 13. ëª¨ë“ˆ ì •ë³´ ë° ìµìŠ¤í¬íŠ¸
# ==============================================

__version__ = "15.0.0"
__author__ = "MyCloset AI Team"
__description__ = "ê¸°í•˜í•™ì  ë§¤ì¹­ - ê³ ê¸‰ ë”¥ëŸ¬ë‹ ì•Œê³ ë¦¬ì¦˜ ì™„ì „ êµ¬í˜„ + BaseStepMixin v19.1 ì™„ì „ í˜¸í™˜"
__compatibility_version__ = "15.0.0-advanced-deeplab-aspp-self-attention"
__features__ = [
    "step_model_requirements.py ì™„ì „ í˜¸í™˜ (REAL_STEP_MODEL_REQUESTS ê¸°ì¤€)",
    "BaseStepMixin v19.1 ì™„ì „ í˜¸í™˜ - _run_ai_inference() ë™ê¸° ì²˜ë¦¬",
    "DeepLabV3+ ë°±ë³¸ ë„¤íŠ¸ì›Œí¬ (ResNet-101 ê¸°ë°˜)",
    "ASPP ëª¨ë“ˆ (Atrous Spatial Pyramid Pooling)",
    "Self-Attention í‚¤í¬ì¸íŠ¸ ë§¤ì¹­",
    "Edge-Aware ë³€í˜• ëª¨ë“ˆ",
    "Progressive ê¸°í•˜í•™ì  ì •ì œ",
    "Procrustes ë¶„ì„ ê¸°ë°˜ ìµœì  ë³€í˜• ê³„ì‚°",
    "RANSAC ì´ìƒì¹˜ ì œê±° ì•Œê³ ë¦¬ì¦˜",
    "ì‹¤ì œ AI ëª¨ë¸ íŒŒì¼ í™œìš© (gmm_final.pth, tps_network.pth, sam_vit_h_4b8939.pth)",
    "M3 Max 128GB + conda í™˜ê²½ ìµœì í™”",
    "TYPE_CHECKING íŒ¨í„´ ìˆœí™˜ì°¸ì¡° ë°©ì§€",
    "í”„ë¡œë•ì…˜ ë ˆë²¨ ì•ˆì •ì„±",
    "ê°œë°œ ë„êµ¬ ë° ë””ë²„ê¹… ê¸°ëŠ¥ ì™„ì „ í¬í•¨"
]

__all__ = [
    # ë©”ì¸ í´ë˜ìŠ¤
    'GeometricMatchingStep',
    
    # ê³ ê¸‰ AI ëª¨ë¸ í´ë˜ìŠ¤ë“¤
    'CompleteAdvancedGeometricMatchingAI',
    'DeepLabV3PlusBackbone',
    'ASPPModule',
    'SelfAttentionKeypointMatcher',
    'EdgeAwareTransformationModule',
    'ProgressiveGeometricRefinement',
    
    # ì•Œê³ ë¦¬ì¦˜ í´ë˜ìŠ¤
    'AdvancedGeometricMatcher',
    
    # ìœ í‹¸ë¦¬í‹° í´ë˜ìŠ¤ë“¤
    'EnhancedModelPathMapper',
    'ProcessingStatus',
    
    # í¸ì˜ í•¨ìˆ˜ë“¤
    'create_geometric_matching_step',
    'create_advanced_ai_geometric_matching_step',
    'create_m3_max_geometric_matching_step',
    
    # í…ŒìŠ¤íŠ¸ í•¨ìˆ˜ë“¤
    'validate_dependencies',
    'test_advanced_ai_geometric_matching',
    
    # ë™ì  import í•¨ìˆ˜ë“¤
    'get_model_loader',
    'get_step_model_request',
    'get_memory_manager',
    'get_data_converter',
    'get_di_container',
    'get_base_step_mixin_class'
]

logger.info("=" * 100)
logger.info("ğŸ”¥ GeometricMatchingStep v15.0 ë¡œë“œ ì™„ë£Œ (ê³ ê¸‰ ë”¥ëŸ¬ë‹ ì•Œê³ ë¦¬ì¦˜ ì™„ì „ êµ¬í˜„)")
logger.info("=" * 100)
logger.info("ğŸ¯ ì£¼ìš” ì„±ê³¼:")
logger.info("   âœ… step_model_requirements.py ì™„ì „ í˜¸í™˜")
logger.info("   âœ… BaseStepMixin v19.1 ì™„ì „ í˜¸í™˜ - _run_ai_inference() ë™ê¸° ì²˜ë¦¬")
logger.info("   âœ… DeepLabV3+ + ASPP + Self-Attention ì™„ì „ êµ¬í˜„")
logger.info("   âœ… ì‹¤ì œ AI ëª¨ë¸ íŒŒì¼ í™œìš© (3.7GB)")
logger.info("   âœ… Procrustes ë¶„ì„ + RANSAC ì´ìƒì¹˜ ì œê±°")
logger.info("   âœ… Progressive ê¸°í•˜í•™ì  ì •ì œ")
logger.info("   âœ… Edge-Aware ë³€í˜• ëª¨ë“ˆ")
logger.info("   âœ… M3 Max + conda í™˜ê²½ ìµœì í™”")
logger.info("   âœ… TYPE_CHECKING íŒ¨í„´ ìˆœí™˜ì°¸ì¡° ë°©ì§€")
logger.info("   âœ… í”„ë¡œë•ì…˜ ë ˆë²¨ ì•ˆì •ì„±")
logger.info("ğŸ§  êµ¬í˜„ëœ ê³ ê¸‰ ë”¥ëŸ¬ë‹ ì•Œê³ ë¦¬ì¦˜:")
logger.info("   ğŸ”¥ DeepLabV3+ ë°±ë³¸ ë„¤íŠ¸ì›Œí¬ (ResNet-101)")
logger.info("   ğŸŒŠ ASPP (Atrous Spatial Pyramid Pooling)")
logger.info("   ğŸ¯ Self-Attention í‚¤í¬ì¸íŠ¸ ë§¤ì¹­")
logger.info("   ğŸ“ Edge-Aware ë³€í˜• ëª¨ë“ˆ")
logger.info("   ğŸ“ˆ Progressive ê¸°í•˜í•™ì  ì •ì œ")
logger.info("   ğŸ“Š Procrustes ë¶„ì„")
logger.info("   ğŸ² RANSAC ì´ìƒì¹˜ ì œê±°")
logger.info("ğŸ”§ ì‹œìŠ¤í…œ ì •ë³´:")
logger.info(f"   - PyTorch: {TORCH_AVAILABLE}")
logger.info(f"   - MPS: {MPS_AVAILABLE}")
logger.info(f"   - Device: {DEVICE}")
logger.info(f"   - PIL: {PIL_AVAILABLE}")
logger.info(f"   - SciPy: {SCIPY_AVAILABLE}")
logger.info("=" * 100)
logger.info("ğŸ‰ MyCloset AI - Step 04 Geometric Matching v15.0 ì¤€ë¹„ ì™„ë£Œ!")
logger.info("   Human Parsing ìˆ˜ì¤€ì˜ ê³ ê¸‰ ë”¥ëŸ¬ë‹ ì•Œê³ ë¦¬ì¦˜ ì™„ì „ êµ¬í˜„!")
logger.info("=" * 100)