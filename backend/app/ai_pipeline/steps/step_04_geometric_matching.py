#!/usr/bin/env python3
"""
ğŸ”¥ MyCloset AI - Step 04: ê¸°í•˜í•™ì  ë§¤ì¹­ v8.0 - Central Hub DI Container ì™„ì „ ì—°ë™
====================================================================================

âœ… Central Hub DI Container v7.0 ì™„ì „ ì—°ë™
âœ… BaseStepMixin ìƒì† ë° super().__init__() í˜¸ì¶œ
âœ… í•„ìˆ˜ ì†ì„±ë“¤ ì´ˆê¸°í™”: ai_models, models_loading_status, model_interface, loaded_models
âœ… _load_segmentation_models_via_central_hub() ë©”ì„œë“œ - ModelLoaderë¥¼ í†µí•œ AI ëª¨ë¸ ë¡œë”©
âœ… ê°„ì†Œí™”ëœ process() ë©”ì„œë“œ - í•µì‹¬ Geometric Matching ë¡œì§ë§Œ
âœ… ì—ëŸ¬ ë°©ì§€ìš© í´ë°± ë¡œì§ - Mock ëª¨ë¸ ìƒì„±
âœ… ì‹¤ì œ GMM/TPS/SAM ì²´í¬í¬ì¸íŠ¸ ì‚¬ìš© (3.0GB)
âœ… GitHubDependencyManager ì™„ì „ ì‚­ì œ
âœ… ë³µì¡í•œ DI ì´ˆê¸°í™” ë¡œì§ ë‹¨ìˆœí™”
âœ… ìˆœí™˜ì°¸ì¡° ë°©ì§€ ì½”ë“œ ë¶ˆí•„ìš”
âœ… TYPE_CHECKING ë‹¨ìˆœí™”

Author: MyCloset AI Team
Date: 2025-07-31
Version: 8.0 (Central Hub DI Container Integration)
"""

# ==============================================
# ğŸ”¥ 1. í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ Import (ì‹¤í–‰ ìˆœì„œ ìµœìš°ì„ )
# ==============================================

import os
import sys
import gc
import time
import logging
import asyncio
import threading
import traceback
import hashlib
import json
import base64
import weakref
import math
import numpy as np
from pathlib import Path
from typing import Dict, Any, Optional, Tuple, List, Union, Callable, TYPE_CHECKING
from dataclasses import dataclass, field
from enum import Enum, IntEnum
from io import BytesIO
from concurrent.futures import ThreadPoolExecutor, as_completed
from functools import lru_cache, wraps

# ìµœìƒë‹¨ì— ì¶”ê°€
import logging
logger = logging.getLogger(__name__)

# TYPE_CHECKINGìœ¼ë¡œ ìˆœí™˜ì°¸ì¡° ë°©ì§€
if TYPE_CHECKING:
    from app.ai_pipeline.utils.model_loader import ModelLoader
    from app.ai_pipeline.utils.memory_manager import MemoryManager
    from app.ai_pipeline.utils.data_converter import DataConverter
    from app.core.di_container import CentralHubDIContainer

# BaseStepMixin ë™ì  import (ìˆœí™˜ì°¸ì¡° ì™„ì „ ë°©ì§€) - GeometricMatchingìš©
def get_base_step_mixin_class():
    """BaseStepMixin í´ë˜ìŠ¤ë¥¼ ë™ì ìœ¼ë¡œ ê°€ì ¸ì˜¤ê¸° (ìˆœí™˜ì°¸ì¡° ë°©ì§€) - GeometricMatchingìš©"""
    try:
        import importlib
        module = importlib.import_module('app.ai_pipeline.steps.base_step_mixin')
        return getattr(module, 'BaseStepMixin', None)
    except ImportError:
        try:
            # í´ë°±: ìƒëŒ€ ê²½ë¡œ
            from .base_step_mixin import BaseStepMixin
            return BaseStepMixin
        except ImportError:
            logging.getLogger(__name__).error("âŒ BaseStepMixin ë™ì  import ì‹¤íŒ¨")
            return None

BaseStepMixin = get_base_step_mixin_class()

# BaseStepMixin í´ë°± í´ë˜ìŠ¤ (GeometricMatching íŠ¹í™”)
if BaseStepMixin is None:
    class BaseStepMixin:
        """GeometricMatchingStepìš© BaseStepMixin í´ë°± í´ë˜ìŠ¤"""
        
        def __init__(self, **kwargs):
            # ê¸°ë³¸ ì†ì„±ë“¤
            self.logger = logging.getLogger(self.__class__.__name__)
            self.step_name = kwargs.get('step_name', 'GeometricMatchingStep')
            self.step_id = kwargs.get('step_id', 4)
            self.device = kwargs.get('device', 'cpu')
            
            # AI ëª¨ë¸ ê´€ë ¨ ì†ì„±ë“¤ (GeometricMatchingì´ í•„ìš”ë¡œ í•˜ëŠ”)
            self.ai_models = {}
            self.models_loading_status = {
                'gmm': False,
                'tps': False,
                'optical_flow': False,
                'keypoint': False,
                'advanced_ai': False,
                'mock_model': False
            }
            self.model_interface = None
            self.loaded_models = []
            
            # GeometricMatching íŠ¹í™” ì†ì„±ë“¤
            self.geometric_models = {}
            self.matching_ready = False
            self.matching_cache = {}
            
            # ìƒíƒœ ê´€ë ¨ ì†ì„±ë“¤
            self.is_initialized = False
            self.is_ready = False
            self.has_model = False
            self.model_loaded = False
            
            # Central Hub DI Container ê´€ë ¨
            self.model_loader = None
            self.memory_manager = None
            self.data_converter = None
            self.di_container = None
            
            # ì„±ëŠ¥ í†µê³„
            self.performance_stats = {
                'total_processed': 0,
                'successful_matches': 0,
                'avg_processing_time': 0.0,
                'avg_transformation_quality': 0.0,
                'keypoint_match_rate': 0.0,
                'optical_flow_accuracy': 0.0,
                'cache_hit_rate': 0.0,
                'error_count': 0,
                'models_loaded': 0
            }
            
            # í†µê³„ ì‹œìŠ¤í…œ
            self.statistics = {
                'total_processed': 0,
                'successful_matches': 0,
                'average_quality': 0.0,
                'total_processing_time': 0.0,
                'ai_model_calls': 0,
                'error_count': 0,
                'model_creation_success': False,
                'real_ai_models_used': True,
                'algorithm_type': 'advanced_deeplab_aspp_self_attention',
                'features': [
                    'GMM (Geometric Matching Module)',
                    'TPS (Thin-Plate Spline) Transformation', 
                    'Keypoint-based Matching',
                    'Optical Flow Calculation',
                    'RANSAC Outlier Removal',
                    'DeepLabV3+ Backbone',
                    'ASPP Multi-scale Context',
                    'Self-Attention Keypoint Matching',
                    'Edge-Aware Transformation',
                    'Progressive Geometric Refinement',
                    'Procrustes Analysis'
                ]
            }
            
            self.logger.info(f"âœ… {self.step_name} BaseStepMixin í´ë°± í´ë˜ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ")
        
        def process(self, data: Dict[str, Any]) -> Dict[str, Any]:
            """ê¸°ë³¸ process ë©”ì„œë“œ - _run_ai_inference í˜¸ì¶œ"""
            try:
                start_time = time.time()
                
                # _run_ai_inference ë©”ì„œë“œê°€ ìˆìœ¼ë©´ í˜¸ì¶œ
                if hasattr(self, '_run_ai_inference'):
                    result = self._run_ai_inference(data)
                    
                    # ì²˜ë¦¬ ì‹œê°„ ì¶”ê°€
                    if isinstance(result, dict):
                        result['processing_time'] = time.time() - start_time
                        result['step_name'] = self.step_name
                        result['step_id'] = self.step_id
                    
                    return result
                else:
                    # ê¸°ë³¸ ì‘ë‹µ
                    return {
                        'success': False,
                        'error': '_run_ai_inference ë©”ì„œë“œê°€ êµ¬í˜„ë˜ì§€ ì•ŠìŒ',
                        'processing_time': time.time() - start_time,
                        'step_name': self.step_name,
                        'step_id': self.step_id
                    }
                    
            except Exception as e:
                self.logger.error(f"âŒ {self.step_name} process ì‹¤íŒ¨: {e}")
                return {
                    'success': False,
                    'error': str(e),
                    'processing_time': time.time() - start_time if 'start_time' in locals() else 0.0,
                    'step_name': self.step_name,
                    'step_id': self.step_id
                }
        
        def initialize(self) -> bool:
            """ì´ˆê¸°í™” ë©”ì„œë“œ"""
            try:
                if self.is_initialized:
                    return True
                
                self.logger.info(f"ğŸ”„ {self.step_name} ì´ˆê¸°í™” ì‹œì‘...")
                
                # Central Hubë¥¼ í†µí•œ ì˜ì¡´ì„± ì£¼ì… ì‹œë„
                injected_count = _inject_dependencies_safe(self)
                if injected_count > 0:
                    self.logger.info(f"âœ… Central Hub ì˜ì¡´ì„± ì£¼ì…: {injected_count}ê°œ")
                
                # Geometric Matching ëª¨ë¸ë“¤ ë¡œë”© (ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” _load_geometric_matching_models_via_central_hub í˜¸ì¶œ)
                if hasattr(self, '_load_geometric_matching_models_via_central_hub'):
                    self._load_geometric_matching_models_via_central_hub()
                
                self.is_initialized = True
                self.is_ready = True
                self.logger.info(f"âœ… {self.step_name} ì´ˆê¸°í™” ì™„ë£Œ")
                return True
            except Exception as e:
                self.logger.error(f"âŒ {self.step_name} ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                return False
        
        def cleanup(self):
            """ì •ë¦¬ ë©”ì„œë“œ"""
            try:
                self.logger.info(f"ğŸ”„ {self.step_name} ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì‹œì‘...")
                
                # AI ëª¨ë¸ë“¤ ì •ë¦¬
                for model_name, model in self.ai_models.items():
                    try:
                        if hasattr(model, 'cleanup'):
                            model.cleanup()
                        del model
                    except Exception as e:
                        self.logger.debug(f"ëª¨ë¸ ì •ë¦¬ ì‹¤íŒ¨ ({model_name}): {e}")
                
                # ìºì‹œ ì •ë¦¬
                self.ai_models.clear()
                if hasattr(self, 'geometric_models'):
                    self.geometric_models.clear()
                if hasattr(self, 'matching_cache'):
                    self.matching_cache.clear()
                
                # GPU ë©”ëª¨ë¦¬ ì •ë¦¬
                try:
                    import torch
                    if torch.cuda.is_available():
                        torch.cuda.empty_cache()
                    elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
                        torch.mps.empty_cache()
                except:
                    pass
                
                import gc
                gc.collect()
                
                self.logger.info(f"âœ… {self.step_name} ì •ë¦¬ ì™„ë£Œ")
            except Exception as e:
                self.logger.error(f"âŒ {self.step_name} ì •ë¦¬ ì‹¤íŒ¨: {e}")
        
        def get_status(self) -> Dict[str, Any]:
            """ìƒíƒœ ì¡°íšŒ"""
            return {
                'step_name': self.step_name,
                'step_id': self.step_id,
                'is_initialized': self.is_initialized,
                'is_ready': self.is_ready,
                'device': self.device,
                'matching_ready': getattr(self, 'matching_ready', False),
                'models_loaded': len(getattr(self, 'loaded_models', [])),
                'geometric_models': list(getattr(self, 'geometric_models', {}).keys()),
                'algorithm_type': 'advanced_deeplab_aspp_self_attention',
                'fallback_mode': True
            }
        
        # BaseStepMixin í˜¸í™˜ ë©”ì„œë“œë“¤
        def set_model_loader(self, model_loader):
            """ModelLoader ì˜ì¡´ì„± ì£¼ì… (BaseStepMixin í˜¸í™˜)"""
            try:
                self.model_loader = model_loader
                self.logger.info("âœ… ModelLoader ì˜ì¡´ì„± ì£¼ì… ì™„ë£Œ")
                
                # Step ì¸í„°í˜ì´ìŠ¤ ìƒì„± ì‹œë„
                if hasattr(model_loader, 'create_step_interface'):
                    try:
                        self.model_interface = model_loader.create_step_interface(self.step_name)
                        self.logger.info("âœ… Step ì¸í„°í˜ì´ìŠ¤ ìƒì„± ë° ì£¼ì… ì™„ë£Œ")
                    except Exception as e:
                        self.logger.warning(f"âš ï¸ Step ì¸í„°í˜ì´ìŠ¤ ìƒì„± ì‹¤íŒ¨, ModelLoader ì§ì ‘ ì‚¬ìš©: {e}")
                        self.model_interface = model_loader
                else:
                    self.model_interface = model_loader
                    
            except Exception as e:
                self.logger.error(f"âŒ ModelLoader ì˜ì¡´ì„± ì£¼ì… ì‹¤íŒ¨: {e}")
                self.model_loader = None
                self.model_interface = None
        
        def set_memory_manager(self, memory_manager):
            """MemoryManager ì˜ì¡´ì„± ì£¼ì… (BaseStepMixin í˜¸í™˜)"""
            try:
                self.memory_manager = memory_manager
                self.logger.info("âœ… MemoryManager ì˜ì¡´ì„± ì£¼ì… ì™„ë£Œ")
            except Exception as e:
                self.logger.warning(f"âš ï¸ MemoryManager ì˜ì¡´ì„± ì£¼ì… ì‹¤íŒ¨: {e}")
        
        def set_data_converter(self, data_converter):
            """DataConverter ì˜ì¡´ì„± ì£¼ì… (BaseStepMixin í˜¸í™˜)"""
            try:
                self.data_converter = data_converter
                self.logger.info("âœ… DataConverter ì˜ì¡´ì„± ì£¼ì… ì™„ë£Œ")
            except Exception as e:
                self.logger.warning(f"âš ï¸ DataConverter ì˜ì¡´ì„± ì£¼ì… ì‹¤íŒ¨: {e}")
        
        def set_di_container(self, di_container):
            """DI Container ì˜ì¡´ì„± ì£¼ì…"""
            try:
                self.di_container = di_container
                self.logger.info("âœ… DI Container ì˜ì¡´ì„± ì£¼ì… ì™„ë£Œ")
            except Exception as e:
                self.logger.warning(f"âš ï¸ DI Container ì˜ì¡´ì„± ì£¼ì… ì‹¤íŒ¨: {e}")

        def _get_step_requirements(self) -> Dict[str, Any]:
            """Step 04 GeometricMatching ìš”êµ¬ì‚¬í•­ ë°˜í™˜ (BaseStepMixin í˜¸í™˜)"""
            return {
                "required_models": [
                    "gmm_final.pth",
                    "tps_network.pth", 
                    "sam_vit_h_4b8939.pth",
                    "raft-things.pth",
                    "resnet101_geometric.pth"
                ],
                "primary_model": "gmm_final.pth",
                "model_configs": {
                    "gmm_final.pth": {
                        "size_mb": 44.7,
                        "device_compatible": ["cpu", "mps", "cuda"],
                        "precision": "high"
                    },
                    "tps_network.pth": {
                        "size_mb": 527.8,
                        "device_compatible": ["cpu", "mps", "cuda"],
                        "real_time": False
                    },
                    "sam_vit_h_4b8939.pth": {
                        "size_mb": 2445.7,
                        "device_compatible": ["cpu", "mps", "cuda"],
                        "shared_with": ["step_03_cloth_segmentation"]
                    },
                    "raft-things.pth": {
                        "size_mb": 20.1,
                        "device_compatible": ["cpu", "mps", "cuda"],
                        "real_time": True
                    },
                    "resnet101_geometric.pth": {
                        "size_mb": 170.5,
                        "device_compatible": ["cpu", "mps", "cuda"],
                        "backbone": True
                    }
                },
                "verified_paths": [
                    "step_04_geometric_matching/gmm_final.pth",
                    "step_04_geometric_matching/tps_network.pth", 
                    "step_04_geometric_matching/ultra_models/raft-things.pth",
                    "step_04_geometric_matching/ultra_models/resnet101_geometric.pth",
                    "step_03_cloth_segmentation/sam_vit_h_4b8939.pth"
                ]
            }

# ==============================================
# ğŸ”¥ 2. í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë° í™˜ê²½ ì„¤ì •
# ==============================================

def _get_central_hub_container():
    """Central Hub DI Container ì•ˆì „í•œ ë™ì  í•´ê²° - GeometricMatchingìš©"""
    try:
        import importlib
        module = importlib.import_module('app.core.di_container')
        get_global_fn = getattr(module, 'get_global_container', None)
        if get_global_fn:
            return get_global_fn()
        return None
    except ImportError:
        return None
    except Exception:
        return None

def _inject_dependencies_safe(step_instance):
    """Central Hub DI Containerë¥¼ í†µí•œ ì•ˆì „í•œ ì˜ì¡´ì„± ì£¼ì… - GeometricMatchingìš©"""
    try:
        container = _get_central_hub_container()
        if container and hasattr(container, 'inject_to_step'):
            return container.inject_to_step(step_instance)
        return 0
    except Exception:
        return 0

def _get_service_from_central_hub(service_key: str):
    """Central Hubë¥¼ í†µí•œ ì•ˆì „í•œ ì„œë¹„ìŠ¤ ì¡°íšŒ - GeometricMatchingìš©"""
    try:
        container = _get_central_hub_container()
        if container:
            return container.get(service_key)
        return None
    except Exception:
        return None

# conda í™˜ê²½ ì •ë³´
CONDA_INFO = {
    'conda_env': os.environ.get('CONDA_DEFAULT_ENV', 'none'),
    'conda_prefix': os.environ.get('CONDA_PREFIX', 'none'),
    'is_mycloset_env': os.environ.get('CONDA_DEFAULT_ENV') == 'mycloset-ai-clean'
}

# M3 Max ê°ì§€ ë° ìµœì í™”
def detect_m3_max() -> bool:
    try:
        import platform, subprocess
        if platform.system() == 'Darwin':
            result = subprocess.run(
                ['sysctl', '-n', 'machdep.cpu.brand_string'], 
                capture_output=True, text=True, timeout=5
            )
            return 'M3' in result.stdout
    except:
        pass
    return False

IS_M3_MAX = detect_m3_max()

# M3 Max ìµœì í™” ì„¤ì •
if IS_M3_MAX and CONDA_INFO['is_mycloset_env']:
    os.environ['PYTORCH_MPS_HIGH_WATERMARK_RATIO'] = '0.0'
    os.environ['TORCH_MPS_PREFER_METAL'] = '1'

# PyTorch í•„ìˆ˜ (MPS ì§€ì›)
try:
    import torch
    import torch.nn as nn
    import torch.nn.functional as F
    import torchvision.transforms as transforms
    TORCH_AVAILABLE = True
    MPS_AVAILABLE = hasattr(torch.backends, 'mps') and torch.backends.mps.is_available()
    
    # M3 Max ìµœì í™”
    if CONDA_INFO['is_mycloset_env'] and IS_M3_MAX:
        cpu_count = os.cpu_count()
        torch.set_num_threads(max(1, cpu_count // 2))
        
except ImportError:
    raise ImportError("âŒ PyTorch í•„ìˆ˜: conda install pytorch torchvision -c pytorch")

# PIL í•„ìˆ˜
try:
    from PIL import Image, ImageDraw, ImageFont, ImageEnhance, ImageFilter
    PIL_AVAILABLE = True
except ImportError:
    raise ImportError("âŒ Pillow í•„ìˆ˜: conda install pillow -c conda-forge")

# NumPy í•„ìˆ˜
try:
    import numpy as np
    NUMPY_AVAILABLE = True
except ImportError:
    raise ImportError("âŒ NumPy í•„ìˆ˜: conda install numpy -c conda-forge")

# OpenCV ì„ íƒì‚¬í•­
try:
    import cv2
    CV2_AVAILABLE = True
except ImportError:
    CV2_AVAILABLE = False
    logging.getLogger(__name__).info("OpenCV ì—†ìŒ - PIL ê¸°ë°˜ìœ¼ë¡œ ë™ì‘")

# SciPy ì„ íƒì‚¬í•­ (Procrustes ë¶„ì„ìš©)
try:
    from scipy.spatial.distance import cdist
    from scipy.optimize import minimize
    from scipy.interpolate import griddata, RBFInterpolator
    import scipy.ndimage as ndimage
    SCIPY_AVAILABLE = True
except ImportError:
    SCIPY_AVAILABLE = False

# ==============================================
# ğŸ”¥ 4. ìƒìˆ˜ ë° ë°ì´í„° í´ë˜ìŠ¤ë“¤
# ==============================================

@dataclass
class GeometricMatchingConfig:
    """ê¸°í•˜í•™ì  ë§¤ì¹­ ì„¤ì •"""
    input_size: tuple = (256, 192)
    confidence_threshold: float = 0.7
    enable_visualization: bool = True
    device: str = "auto"
    matching_method: str = "advanced_deeplab_aspp_self_attention"

@dataclass
class ProcessingStatus:
    """ì²˜ë¦¬ ìƒíƒœ ì¶”ì  í´ë˜ìŠ¤"""
    models_loaded: bool = False
    advanced_ai_loaded: bool = False
    model_creation_success: bool = False
    requirements_compatible: bool = False
    initialization_complete: bool = False
    last_updated: float = field(default_factory=time.time)
    
    def update_status(self, **kwargs):
        """ìƒíƒœ ì—…ë°ì´íŠ¸"""
        for key, value in kwargs.items():
            if hasattr(self, key):
                setattr(self, key, value)
        self.last_updated = time.time()

# ê¸°í•˜í•™ì  ë§¤ì¹­ ì•Œê³ ë¦¬ì¦˜ íƒ€ì…
MATCHING_ALGORITHMS = {
    'gmm': 'Geometric Matching Module',
    'tps': 'Thin-Plate Spline Transformation',
    'procrustes': 'Procrustes Analysis',
    'optical_flow': 'Optical Flow Calculation',
    'keypoint': 'Keypoint-based Matching',
    'deeplab': 'DeepLabV3+ Backbone',
    'aspp': 'ASPP Multi-scale Context',
    'self_attention': 'Self-Attention Keypoint Matching',
    'edge_aware': 'Edge-Aware Transformation',
    'progressive': 'Progressive Geometric Refinement'
}

# ==============================================
# ğŸ”¥ 5. AI ëª¨ë¸ í´ë˜ìŠ¤ë“¤ (ê¸°ë³¸ ëª¨ë¸ë“¤)
# ==============================================

class GeometricMatchingModule(nn.Module):
    """ì‹¤ì œ GMM (Geometric Matching Module) - ì˜· ê°ˆì•„ì…íˆê¸° íŠ¹í™”"""
    
    def __init__(self, input_nc=6, output_nc=1):
        super().__init__()
        self.input_nc = input_nc  # person + clothing
        self.output_nc = output_nc
        
        # Feature Extraction Network (ResNet ê¸°ë°˜)
        self.feature_extractor = nn.Sequential(
            # Initial Convolution
            nn.Conv2d(input_nc, 64, kernel_size=7, stride=2, padding=3, bias=False),
            nn.BatchNorm2d(64),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),
            
            # ResNet Blocks
            self._make_layer(64, 64, 3, stride=1),
            self._make_layer(256, 128, 4, stride=2),
            self._make_layer(512, 256, 6, stride=2),
            self._make_layer(1024, 512, 3, stride=2),
        )
        
        # Correlation Module (ì˜·ê³¼ ì‚¬ëŒ ê°„ ìƒê´€ê´€ê³„ ê³„ì‚°)
        self.correlation = nn.Sequential(
            nn.Conv2d(2048, 512, kernel_size=3, padding=1),
            nn.BatchNorm2d(512),
            nn.ReLU(inplace=True),
            nn.Conv2d(512, 256, kernel_size=3, padding=1),
            nn.BatchNorm2d(256),
            nn.ReLU(inplace=True),
        )
        
        # Regression Network (ë³€í˜• ë§¤ê°œë³€ìˆ˜ ì˜ˆì¸¡)
        self.regression = nn.Sequential(
            nn.AdaptiveAvgPool2d((4, 3)),  # 4x3 = 12ê°œ ì œì–´ì 
            nn.Flatten(),
            nn.Linear(256 * 4 * 3, 512),
            nn.ReLU(inplace=True),
            nn.Dropout(0.5),
            nn.Linear(512, 256),
            nn.ReLU(inplace=True),
            nn.Dropout(0.5),
            nn.Linear(256, 2 * 3 * 4),  # 2D coordinates for 3x4 grid
        )
        
        # Grid Generator (TPS ë³€í˜• ê·¸ë¦¬ë“œ ìƒì„±)
        self.grid_generator = TPSGridGenerator()
        
    def _make_layer(self, inplanes, planes, blocks, stride=1):
        """ResNet layer ìƒì„±"""
        layers = []
        layers.append(self._bottleneck_block(inplanes, planes, stride))
        inplanes = planes * 4
        for _ in range(1, blocks):
            layers.append(self._bottleneck_block(inplanes, planes))
        return nn.Sequential(*layers)
    
    def _bottleneck_block(self, inplanes, planes, stride=1):
        """Bottleneck block"""
        expansion = 4
        downsample = None
        
        if stride != 1 or inplanes != planes * expansion:
            downsample = nn.Sequential(
                nn.Conv2d(inplanes, planes * expansion, 1, stride=stride, bias=False),
                nn.BatchNorm2d(planes * expansion),
            )
        
        class BottleneckBlock(nn.Module):
            def __init__(self, inplanes, planes, stride, downsample):
                super().__init__()
                self.conv1 = nn.Conv2d(inplanes, planes, 1, bias=False)
                self.bn1 = nn.BatchNorm2d(planes)
                self.conv2 = nn.Conv2d(planes, planes, 3, stride=stride, padding=1, bias=False)
                self.bn2 = nn.BatchNorm2d(planes)
                self.conv3 = nn.Conv2d(planes, planes * 4, 1, bias=False)
                self.bn3 = nn.BatchNorm2d(planes * 4)
                self.relu = nn.ReLU(inplace=True)
                self.downsample = downsample
                
            def forward(self, x):
                residual = x
                
                out = self.conv1(x)
                out = self.bn1(out)
                out = self.relu(out)
                
                out = self.conv2(out)
                out = self.bn2(out)
                out = self.relu(out)
                
                out = self.conv3(out)
                out = self.bn3(out)
                
                if self.downsample is not None:
                    residual = self.downsample(x)
                
                out += residual
                out = self.relu(out)
                
                return out
        
        return BottleneckBlock(inplanes, planes, stride, downsample)
    
    def forward(self, person_image, clothing_image):
        """ìˆœì „íŒŒ: ê¸°í•˜í•™ì  ë§¤ì¹­ ìˆ˜í–‰"""
        # ì…ë ¥ ê²°í•©
        combined_input = torch.cat([person_image, clothing_image], dim=1)
        
        # íŠ¹ì§• ì¶”ì¶œ
        features = self.feature_extractor(combined_input)
        
        # ìƒê´€ê´€ê³„ ê³„ì‚°
        correlation_features = self.correlation(features)
        
        # ë³€í˜• ë§¤ê°œë³€ìˆ˜ ì˜ˆì¸¡
        theta = self.regression(correlation_features)
        theta = theta.view(-1, 2, 12)  # ë°°ì¹˜ í¬ê¸°ì— ë§ê²Œ reshape
        
        # TPS ë³€í˜• ê·¸ë¦¬ë“œ ìƒì„±
        grid = self.grid_generator(theta, person_image.size())
        
        # ì˜ë¥˜ ì´ë¯¸ì§€ì— ë³€í˜• ì ìš©
        warped_clothing = F.grid_sample(clothing_image, grid, mode='bilinear', 
                                      padding_mode='border', align_corners=False)
        
        return {
            'transformation_matrix': theta,
            'transformation_grid': grid,
            'warped_clothing': warped_clothing,
            'correlation_features': correlation_features
        }

class TPSGridGenerator(nn.Module):
    """TPS (Thin-Plate Spline) ê·¸ë¦¬ë“œ ìƒì„±ê¸°"""
    
    def __init__(self):
        super().__init__()
        
        # ì œì–´ì  ì´ˆê¸°í™” (3x4 = 12ê°œ ì )
        self.register_buffer('control_points', self._create_control_points())
        
    def _create_control_points(self):
        """3x4 ì œì–´ì  ìƒì„±"""
        # ì •ê·œí™”ëœ ì¢Œí‘œê³„ (-1, 1)ì—ì„œ ì œì–´ì  ë°°ì¹˜
        x = torch.linspace(-1, 1, 4)
        y = torch.linspace(-1, 1, 3)
        
        grid_x, grid_y = torch.meshgrid(x, y, indexing='ij')
        control_points = torch.stack([grid_x.flatten(), grid_y.flatten()], dim=1)
        
        return control_points  # [12, 2]
    
    def forward(self, theta, input_size):
        """TPS ë³€í˜• ê·¸ë¦¬ë“œ ìƒì„±"""
        batch_size, height, width = theta.size(0), input_size[2], input_size[3]
        device = theta.device
        
        # thetaë¥¼ ì œì–´ì  ì¢Œí‘œë¡œ ë³€í™˜
        target_points = theta.view(batch_size, 12, 2)
        
        # ì¶œë ¥ ê·¸ë¦¬ë“œ ìƒì„±
        y, x = torch.meshgrid(
            torch.linspace(-1, 1, height, device=device),
            torch.linspace(-1, 1, width, device=device),
            indexing='ij'
        )
        
        grid_points = torch.stack([x.flatten(), y.flatten()], dim=1).unsqueeze(0)
        grid_points = grid_points.expand(batch_size, -1, -1)
        
        # ê¸°ë³¸ ë³€í˜• ì ìš© (ê°„ë‹¨í•œ ì–´í•€ ë³€í˜•)
        warped_grid = grid_points + target_points.view(batch_size, -1, 2).mean(1, keepdim=True) * 0.1
        warped_grid = warped_grid.view(batch_size, height, width, 2)
        
        return warped_grid

class OpticalFlowNetwork(nn.Module):
    """RAFT ê¸°ë°˜ Optical Flow ë„¤íŠ¸ì›Œí¬ (ì˜ë¥˜ ì›€ì§ì„ ì¶”ì )"""
    
    def __init__(self, feature_dim=256, hidden_dim=128):
        super().__init__()
        
        # Feature Encoder
        self.feature_encoder = nn.Sequential(
            nn.Conv2d(3, 64, 7, stride=2, padding=3),
            nn.BatchNorm2d(64),
            nn.ReLU(inplace=True),
            nn.Conv2d(64, 128, 3, stride=2, padding=1),
            nn.BatchNorm2d(128),
            nn.ReLU(inplace=True),
            nn.Conv2d(128, feature_dim, 3, stride=2, padding=1),
            nn.BatchNorm2d(feature_dim),
            nn.ReLU(inplace=True),
        )
        
        # Flow Head
        self.flow_head = nn.Sequential(
            nn.Conv2d(feature_dim, 128, 3, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv2d(128, 64, 3, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv2d(64, 2, 3, padding=1),
        )
        
    def forward(self, img1, img2):
        """Optical flow ê³„ì‚°"""
        # íŠ¹ì§• ì¶”ì¶œ
        feat1 = self.feature_encoder(img1)
        feat2 = self.feature_encoder(img2)
        
        # Feature difference
        feat_diff = feat1 - feat2
        
        # Flow ì˜ˆì¸¡
        flow = self.flow_head(feat_diff)
        
        return flow

class KeypointMatchingNetwork(nn.Module):
    """í‚¤í¬ì¸íŠ¸ ê¸°ë°˜ ë§¤ì¹­ ë„¤íŠ¸ì›Œí¬"""
    
    def __init__(self, num_keypoints=18):
        super().__init__()
        self.num_keypoints = num_keypoints
        
        # Keypoint Feature Extractor
        self.keypoint_encoder = nn.Sequential(
            nn.Conv2d(3, 64, 3, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(inplace=True),
            nn.Conv2d(64, 128, 3, padding=1),
            nn.BatchNorm2d(128),
            nn.ReLU(inplace=True),
            nn.Conv2d(128, 256, 3, padding=1),
            nn.BatchNorm2d(256),
            nn.ReLU(inplace=True),
        )
        
        # Keypoint Detector
        self.keypoint_detector = nn.Sequential(
            nn.Conv2d(256, 128, 3, padding=1),
            nn.BatchNorm2d(128),
            nn.ReLU(inplace=True),
            nn.Conv2d(128, num_keypoints, 1),
            nn.Sigmoid()
        )
        
    def forward(self, image):
        """í‚¤í¬ì¸íŠ¸ ê°ì§€ ë° ë””ìŠ¤í¬ë¦½í„° ìƒì„±"""
        # íŠ¹ì§• ì¶”ì¶œ
        features = self.keypoint_encoder(image)
        
        # í‚¤í¬ì¸íŠ¸ íˆíŠ¸ë§µ ìƒì„±
        keypoint_heatmaps = self.keypoint_detector(features)
        
        return {
            'keypoint_heatmaps': keypoint_heatmaps,
            'features': features
        }

# ==============================================
# ğŸ”¥ 6. ê³ ê¸‰ AI ëª¨ë¸ í´ë˜ìŠ¤ë“¤
# ==============================================

class DeepLabV3PlusBackbone(nn.Module):
    """DeepLabV3+ ë°±ë³¸ ë„¤íŠ¸ì›Œí¬ - ê¸°í•˜í•™ì  ë§¤ì¹­ íŠ¹í™”"""

    def __init__(self, input_nc=6, backbone='resnet101', output_stride=16):
        super().__init__()
        self.output_stride = output_stride
        self.input_nc = input_nc

        # ResNet-101 ë°±ë³¸ êµ¬ì„± (6ì±„ë„ ì…ë ¥ ì§€ì›)
        self.conv1 = nn.Conv2d(input_nc, 64, kernel_size=7, stride=2, padding=3, bias=False)
        self.bn1 = nn.BatchNorm2d(64)
        self.relu = nn.ReLU(inplace=True)
        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)

        # ResNet Layers with Dilated Convolution
        self.layer1 = self._make_layer(64, 64, 3, stride=1)      # 256 channels
        self.layer2 = self._make_layer(256, 128, 4, stride=2)    # 512 channels  
        self.layer3 = self._make_layer(512, 256, 23, stride=2)   # 1024 channels
        self.layer4 = self._make_layer(1024, 512, 3, stride=1, dilation=2)  # 2048 channels

        # Low-level feature extraction (for decoder)
        self.low_level_conv = nn.Conv2d(256, 48, 1, bias=False)
        self.low_level_bn = nn.BatchNorm2d(48)

    def _make_layer(self, inplanes, planes, blocks, stride=1, dilation=1):
        """ResNet ë ˆì´ì–´ ìƒì„± (Bottleneck êµ¬ì¡°)"""
        layers = []

        # Downsample layer
        downsample = None
        if stride != 1 or inplanes != planes * 4:
            downsample = nn.Sequential(
                nn.Conv2d(inplanes, planes * 4, 1, stride=stride, bias=False),
                nn.BatchNorm2d(planes * 4)
            )

        # First block
        layers.append(self._bottleneck_block(inplanes, planes, stride, dilation, downsample))

        # Remaining blocks
        for _ in range(1, blocks):
            layers.append(self._bottleneck_block(planes * 4, planes, 1, dilation))

        return nn.Sequential(*layers)

    def _bottleneck_block(self, inplanes, planes, stride=1, dilation=1, downsample=None):
        """ResNet Bottleneck ë¸”ë¡"""
        class BottleneckBlock(nn.Module):
            def __init__(self, inplanes, planes, stride, dilation, downsample):
                super().__init__()
                self.conv1 = nn.Conv2d(inplanes, planes, 1, bias=False)
                self.bn1 = nn.BatchNorm2d(planes)
                self.conv2 = nn.Conv2d(planes, planes, 3, stride=stride, padding=dilation, 
                                     dilation=dilation, bias=False)
                self.bn2 = nn.BatchNorm2d(planes)
                self.conv3 = nn.Conv2d(planes, planes * 4, 1, bias=False)
                self.bn3 = nn.BatchNorm2d(planes * 4)
                self.relu = nn.ReLU(inplace=True)
                self.downsample = downsample

            def forward(self, x):
                residual = x

                out = self.conv1(x)
                out = self.bn1(out)
                out = self.relu(out)

                out = self.conv2(out)
                out = self.bn2(out)
                out = self.relu(out)

                out = self.conv3(out)
                out = self.bn3(out)

                if self.downsample is not None:
                    residual = self.downsample(x)

                out += residual
                out = self.relu(out)

                return out
                
        return BottleneckBlock(inplanes, planes, stride, dilation, downsample)

    def forward(self, x):
        # Initial convolution
        x = self.conv1(x)
        x = self.bn1(x)
        x = self.relu(x)
        x = self.maxpool(x)

        # ResNet layers
        x = self.layer1(x)
        low_level_feat = x  # Save for decoder

        x = self.layer2(x)
        x = self.layer3(x)
        x = self.layer4(x)

        # Process low-level features
        low_level_feat = self.low_level_conv(low_level_feat)
        low_level_feat = self.low_level_bn(low_level_feat)
        low_level_feat = self.relu(low_level_feat)

        return x, low_level_feat

class ASPPModule(nn.Module):
    """ASPP ëª¨ë“ˆ - Multi-scale context aggregation"""

    def __init__(self, in_channels=2048, out_channels=256, atrous_rates=[6, 12, 18]):
        super().__init__()

        # 1x1 convolution
        self.conv1x1 = nn.Sequential(
            nn.Conv2d(in_channels, out_channels, 1, bias=False),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True)
        )

        # Atrous convolutions with different rates
        self.atrous_convs = nn.ModuleList([
            nn.Sequential(
                nn.Conv2d(in_channels, out_channels, 3, padding=rate, 
                         dilation=rate, bias=False),
                nn.BatchNorm2d(out_channels),
                nn.ReLU(inplace=True)
            ) for rate in atrous_rates
        ])

        # Global average pooling branch
        self.global_avg_pool = nn.Sequential(
            nn.AdaptiveAvgPool2d((1, 1)),
            nn.Conv2d(in_channels, out_channels, 1, bias=False),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True)
        )

        # Feature fusion
        total_channels = out_channels * (1 + len(atrous_rates) + 1)  # 1x1 + atrous + global
        self.project = nn.Sequential(
            nn.Conv2d(total_channels, out_channels, 1, bias=False),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True),
            nn.Dropout(0.5)
        )

    def forward(self, x):
        h, w = x.shape[2:]

        # 1x1 convolution
        feat1 = self.conv1x1(x)

        # Atrous convolutions
        atrous_feats = [conv(x) for conv in self.atrous_convs]

        # Global average pooling
        global_feat = self.global_avg_pool(x)
        global_feat = F.interpolate(global_feat, size=(h, w), 
                                   mode='bilinear', align_corners=False)

        # Concatenate all features
        concat_feat = torch.cat([feat1] + atrous_feats + [global_feat], dim=1)

        # Project to final features
        return self.project(concat_feat)

class SelfAttentionKeypointMatcher(nn.Module):
    """Self-Attention ê¸°ë°˜ í‚¤í¬ì¸íŠ¸ ë§¤ì¹­ ëª¨ë“ˆ"""

    def __init__(self, in_channels=256, num_keypoints=20):
        super().__init__()
        self.num_keypoints = num_keypoints
        self.in_channels = in_channels

        # Query, Key, Value ë³€í™˜
        self.query_conv = nn.Conv2d(in_channels, in_channels // 8, 1)
        self.key_conv = nn.Conv2d(in_channels, in_channels // 8, 1)
        self.value_conv = nn.Conv2d(in_channels, in_channels, 1)

        # í‚¤í¬ì¸íŠ¸ íˆíŠ¸ë§µ ìƒì„±
        self.keypoint_head = nn.Sequential(
            nn.Conv2d(in_channels, 128, 3, padding=1, bias=False),
            nn.BatchNorm2d(128),
            nn.ReLU(inplace=True),
            nn.Conv2d(128, 64, 3, padding=1, bias=False),
            nn.BatchNorm2d(64),
            nn.ReLU(inplace=True),
            nn.Conv2d(64, num_keypoints, 1),
            nn.Sigmoid()
        )

        # Attention ê°€ì¤‘ì¹˜
        self.gamma = nn.Parameter(torch.zeros(1))
        self.softmax = nn.Softmax(dim=-1)

    def forward(self, person_feat, clothing_feat):
        """Self-attentionì„ í†µí•œ í‚¤í¬ì¸íŠ¸ ë§¤ì¹­"""
        batch_size, C, H, W = person_feat.size()

        # Person featuresì—ì„œ query ìƒì„±
        proj_query = self.query_conv(person_feat).view(batch_size, -1, H * W).permute(0, 2, 1)
        
        # Clothing featuresì—ì„œ key, value ìƒì„±
        proj_key = self.key_conv(clothing_feat).view(batch_size, -1, H * W)
        proj_value = self.value_conv(clothing_feat).view(batch_size, -1, H * W)

        # Attention ê³„ì‚°
        energy = torch.bmm(proj_query, proj_key)
        attention = self.softmax(energy)

        # Attentionì„ valueì— ì ìš©
        out = torch.bmm(proj_value, attention.permute(0, 2, 1))
        out = out.view(batch_size, C, H, W)

        # Residual connection
        attended_feat = self.gamma * out + person_feat

        # í‚¤í¬ì¸íŠ¸ íˆíŠ¸ë§µ ìƒì„±
        keypoint_heatmaps = self.keypoint_head(attended_feat)

        return keypoint_heatmaps, attended_feat

class EdgeAwareTransformationModule(nn.Module):
    """Edge-Aware ë³€í˜• ëª¨ë“ˆ - ê²½ê³„ì„  ì •ë³´ í™œìš©"""

    def __init__(self, in_channels=256):
        super().__init__()

        # Edge feature extraction
        self.edge_conv1 = nn.Sequential(
            nn.Conv2d(in_channels, 128, 3, padding=1, bias=False),
            nn.BatchNorm2d(128),
            nn.ReLU(inplace=True)
        )

        self.edge_conv2 = nn.Sequential(
            nn.Conv2d(128, 64, 3, padding=1, bias=False),
            nn.BatchNorm2d(64),
            nn.ReLU(inplace=True)
        )

        # Learnable Sobel-like filters
        self.sobel_x = nn.Conv2d(64, 32, 3, padding=1, bias=False)
        self.sobel_y = nn.Conv2d(64, 32, 3, padding=1, bias=False)

        # Initialize edge kernels
        self._init_sobel_kernels()

        # Transformation prediction
        self.transform_head = nn.Sequential(
            nn.Conv2d(64 + 32 * 2, 128, 3, padding=1, bias=False),
            nn.BatchNorm2d(128),
            nn.ReLU(inplace=True),
            nn.Conv2d(128, 64, 3, padding=1, bias=False),
            nn.BatchNorm2d(64),
            nn.ReLU(inplace=True),
            nn.Conv2d(64, 2, 1)  # x, y displacement
        )

    def _init_sobel_kernels(self):
        """Sobel edge detection ì»¤ë„ ì´ˆê¸°í™”"""
        sobel_x_kernel = torch.tensor([
            [-1, 0, 1],
            [-2, 0, 2], 
            [-1, 0, 1]
        ], dtype=torch.float32).view(1, 1, 3, 3)

        sobel_y_kernel = torch.tensor([
            [-1, -2, -1],
            [0, 0, 0],
            [1, 2, 1]
        ], dtype=torch.float32).view(1, 1, 3, 3)

        # í•™ìŠµ ê°€ëŠ¥í•œ íŒŒë¼ë¯¸í„°ë¡œ ì„¤ì •
        self.sobel_x.weight.data = sobel_x_kernel.repeat(32, 64, 1, 1)
        self.sobel_y.weight.data = sobel_y_kernel.repeat(32, 64, 1, 1)

    def forward(self, features):
        """Edge-aware transformation ì˜ˆì¸¡"""
        # Edge features ì¶”ì¶œ
        edge_feat = self.edge_conv1(features)
        edge_feat = self.edge_conv2(edge_feat)

        # Sobel í•„í„° ì ìš©
        edge_x = self.sobel_x(edge_feat)
        edge_y = self.sobel_y(edge_feat)

        # Feature ê²°í•©
        combined_feat = torch.cat([edge_feat, edge_x, edge_y], dim=1)

        # Transformation ì˜ˆì¸¡
        transformation = self.transform_head(combined_feat)

        return transformation

class ProgressiveGeometricRefinement(nn.Module):
    """Progressive ê¸°í•˜í•™ì  ì •ì œ ëª¨ë“ˆ - ë‹¨ê³„ë³„ ê°œì„ """

    def __init__(self, num_stages=3, in_channels=256):
        super().__init__()
        self.num_stages = num_stages

        # Stageë³„ ì •ì œ ëª¨ë“ˆ
        self.refine_stages = nn.ModuleList([
            self._make_refine_stage(in_channels + 2 * i, in_channels // (2 ** i))
            for i in range(num_stages)
        ])

        # Stageë³„ ë³€í˜• ì˜ˆì¸¡ê¸°
        self.transform_predictors = nn.ModuleList([
            nn.Conv2d(in_channels // (2 ** i), 2, 1)
            for i in range(num_stages)
        ])

        # ì‹ ë¢°ë„ ì¶”ì •
        self.confidence_estimator = nn.Sequential(
            nn.Conv2d(in_channels, 64, 3, padding=1, bias=False),
            nn.BatchNorm2d(64),
            nn.ReLU(inplace=True),
            nn.Conv2d(64, 1, 1),
            nn.Sigmoid()
        )

    def _make_refine_stage(self, in_channels, out_channels):
        """ì •ì œ ë‹¨ê³„ ìƒì„±"""
        return nn.Sequential(
            nn.Conv2d(in_channels, out_channels * 2, 3, padding=1, bias=False),
            nn.BatchNorm2d(out_channels * 2),
            nn.ReLU(inplace=True),
            nn.Conv2d(out_channels * 2, out_channels, 3, padding=1, bias=False),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True)
        )

    def forward(self, features):
        """Progressive refinement ìˆ˜í–‰"""
        transformations = []
        current_feat = features

        for i, (refine_stage, transform_pred) in enumerate(zip(self.refine_stages, self.transform_predictors)):
            # í˜„ì¬ ë‹¨ê³„ ì •ì œ
            refined_feat = refine_stage(current_feat)
            
            # ë³€í˜• ì˜ˆì¸¡
            transform = transform_pred(refined_feat)
            transformations.append(transform)

            # ë‹¤ìŒ ë‹¨ê³„ë¥¼ ìœ„í•œ íŠ¹ì§• ì¤€ë¹„
            if i < self.num_stages - 1:
                current_feat = torch.cat([refined_feat, transform], dim=1)

        # ì‹ ë¢°ë„ ì¶”ì •
        confidence = self.confidence_estimator(features)

        return transformations, confidence

class CompleteAdvancedGeometricMatchingAI(nn.Module):
    """ì™„ì „í•œ ê³ ê¸‰ AI ê¸°í•˜í•™ì  ë§¤ì¹­ ëª¨ë¸ - DeepLabV3+ + ASPP + Self-Attention"""

    def __init__(self, input_nc=6, num_keypoints=20):
        super().__init__()
        self.input_nc = input_nc
        self.num_keypoints = num_keypoints

        # 1. DeepLabV3+ Backbone
        self.backbone = DeepLabV3PlusBackbone(input_nc=input_nc)

        # 2. ASPP Module
        self.aspp = ASPPModule(in_channels=2048, out_channels=256)

        # 3. Self-Attention Keypoint Matcher
        self.keypoint_matcher = SelfAttentionKeypointMatcher(in_channels=256, num_keypoints=num_keypoints)

        # 4. Edge-Aware Transformation Module
        self.edge_transform = EdgeAwareTransformationModule(in_channels=256)

        # 5. Progressive Refinement
        self.progressive_refine = ProgressiveGeometricRefinement(num_stages=3, in_channels=256)

        # Decoder
        self.decoder = nn.Sequential(
            nn.Conv2d(256 + 48, 256, 3, padding=1, bias=False),  # ASPP + low-level
            nn.BatchNorm2d(256),
            nn.ReLU(inplace=True),
            nn.Conv2d(256, 256, 3, padding=1, bias=False),
            nn.BatchNorm2d(256),
            nn.ReLU(inplace=True),
            nn.Dropout(0.1)
        )

        # Final transformation predictor
        self.final_transform = nn.Conv2d(256, 2, 1)

    def forward(self, person_image, clothing_image):
        """ì™„ì „í•œ AI ê¸°ë°˜ ê¸°í•˜í•™ì  ë§¤ì¹­"""
        # ì…ë ¥ ê²°í•© (6ì±„ë„)
        combined_input = torch.cat([person_image, clothing_image], dim=1)
        input_size = combined_input.shape[2:]

        # 1. Feature extraction with DeepLabV3+
        high_level_feat, low_level_feat = self.backbone(combined_input)

        # 2. Multi-scale context with ASPP
        aspp_feat = self.aspp(high_level_feat)

        # 3. Decode features
        aspp_feat = F.interpolate(aspp_feat, size=low_level_feat.shape[2:], 
                                 mode='bilinear', align_corners=False)
        concat_feat = torch.cat([aspp_feat, low_level_feat], dim=1)
        decoded_feat = self.decoder(concat_feat)

        # 4. Self-attention keypoint matching
        keypoint_heatmaps, attended_feat = self.keypoint_matcher(decoded_feat, decoded_feat)

        # 5. Edge-aware transformation
        edge_transform = self.edge_transform(attended_feat)

        # 6. Progressive refinement
        progressive_transforms, confidence = self.progressive_refine(attended_feat)

        # 7. Final transformation
        final_transform = self.final_transform(attended_feat)

        # 8. Generate transformation grid
        transformation_grid = self._generate_transformation_grid(final_transform, input_size)

        # 9. Apply transformation to clothing
        warped_clothing = F.grid_sample(
            clothing_image, transformation_grid, mode='bilinear',
            padding_mode='border', align_corners=False
        )

        return {
            'transformation_matrix': self._grid_to_matrix(transformation_grid),
            'transformation_grid': transformation_grid,
            'warped_clothing': warped_clothing,
            'keypoint_heatmaps': keypoint_heatmaps,
            'confidence_map': confidence,
            'progressive_transforms': progressive_transforms,
            'edge_features': edge_transform,
            'algorithm_type': 'advanced_deeplab_aspp_self_attention'
        }

    def _generate_transformation_grid(self, flow_field, input_size):
        """Flow fieldë¥¼ transformation gridë¡œ ë³€í™˜"""
        batch_size = flow_field.shape[0]
        device = flow_field.device
        H, W = input_size

        # ê¸°ë³¸ ê·¸ë¦¬ë“œ ìƒì„±
        y, x = torch.meshgrid(
            torch.linspace(-1, 1, H, device=device),
            torch.linspace(-1, 1, W, device=device),
            indexing='ij'
        )
        base_grid = torch.stack([x, y], dim=-1).unsqueeze(0).repeat(batch_size, 1, 1, 1)

        # Flow field í¬ê¸° ì¡°ì •
        if flow_field.shape[-2:] != (H, W):
            flow_field = F.interpolate(flow_field, size=(H, W), mode='bilinear', align_corners=False)

        # Flowë¥¼ ê·¸ë¦¬ë“œ ì¢Œí‘œê³„ë¡œ ë³€í™˜
        flow_normalized = flow_field.permute(0, 2, 3, 1)
        flow_normalized[:, :, :, 0] /= W / 2.0
        flow_normalized[:, :, :, 1] /= H / 2.0

        # ìµœì¢… ë³€í˜• ê·¸ë¦¬ë“œ
        transformation_grid = base_grid + flow_normalized * 0.1

        return transformation_grid

    def _grid_to_matrix(self, grid):
        """Gridë¥¼ 2x3 ë³€í˜• í–‰ë ¬ë¡œ ë³€í™˜"""
        batch_size, H, W, _ = grid.shape
        device = grid.device

        # ë‹¨ìˆœí™”ëœ ì–´í•€ ë³€í˜• ì¶”ì •
        matrix = torch.zeros(batch_size, 2, 3, device=device)

        # ê·¸ë¦¬ë“œ ì¤‘ì•™ ì˜ì—­ì—ì„œ ë³€í˜• íŒŒë¼ë¯¸í„° ì¶”ì¶œ
        center_h, center_w = H // 2, W // 2
        center_region = grid[:, center_h-10:center_h+10, center_w-10:center_w+10, :]

        # í‰ê·  ë³€í˜• ê³„ì‚°
        mean_transform = torch.mean(center_region, dim=(1, 2))

        matrix[:, 0, 0] = 1.0 + mean_transform[:, 0] * 0.1
        matrix[:, 1, 1] = 1.0 + mean_transform[:, 1] * 0.1
        matrix[:, 0, 2] = mean_transform[:, 0]
        matrix[:, 1, 2] = mean_transform[:, 1]

        return matrix

# ==============================================
# ğŸ”¥ 7. Enhanced Model Path Mapping
# ==============================================

class EnhancedModelPathMapper:
    """í–¥ìƒëœ ëª¨ë¸ ê²½ë¡œ ë§¤í•‘ ì‹œìŠ¤í…œ"""
    
    def __init__(self, ai_models_root: str = "ai_models"):
        self.ai_models_root = Path(ai_models_root)
        self.model_cache = {}
        self.logger = logging.getLogger(self.__class__.__name__)
        
        # ì‹¤ì œ ê²½ë¡œ ìë™ íƒì§€
        self.ai_models_root = self._auto_detect_ai_models_path()
        self.logger.info(f"ğŸ“ AI ëª¨ë¸ ë£¨íŠ¸ ê²½ë¡œ: {self.ai_models_root}")
        
    def _auto_detect_ai_models_path(self) -> Path:
        """ì‹¤ì œ ai_models ë””ë ‰í† ë¦¬ ìë™ íƒì§€"""
        possible_paths = [
            Path.cwd() / "ai_models",
            Path.cwd().parent / "ai_models",
            Path.cwd() / "backend" / "ai_models",
            Path(__file__).parent / "ai_models",
            Path(__file__).parent.parent / "ai_models",
            Path(__file__).parent.parent.parent / "ai_models"
        ]
        
        for path in possible_paths:
            if path.exists() and (path / "step_04_geometric_matching").exists():
                return path
                        
        return Path.cwd() / "ai_models"
    
    def find_model_file(self, filename: str) -> Optional[Path]:
        """ëª¨ë¸ íŒŒì¼ ì°¾ê¸°"""
        try:
            # ìºì‹œ í™•ì¸
            if filename in self.model_cache:
                return self.model_cache[filename]
            
            # ê²€ìƒ‰ ê²½ë¡œ
            search_dirs = [
                self.ai_models_root,
                self.ai_models_root / "step_04_geometric_matching",
                self.ai_models_root / "step_04_geometric_matching" / "ultra_models",
                self.ai_models_root / "step_04_geometric_matching" / "models",
                self.ai_models_root / "step_03_cloth_segmentation",  # SAM ê³µìœ 
                self.ai_models_root / "checkpoints" / "step_04_geometric_matching",
            ]
            
            for search_dir in search_dirs:
                if search_dir.exists():
                    # ì§ì ‘ íŒŒì¼ ì°¾ê¸°
                    file_path = search_dir / filename
                    if file_path.exists():
                        self.model_cache[filename] = file_path
                        return file_path
                    
                    # ì¬ê·€ ê²€ìƒ‰
                    try:
                        for found_path in search_dir.rglob(filename):
                            if found_path.is_file():
                                self.model_cache[filename] = found_path
                                return found_path
                    except Exception:
                        continue
            
            return None
            
        except Exception as e:
            self.logger.debug(f"ëª¨ë¸ íŒŒì¼ ê²€ìƒ‰ ì‹¤íŒ¨ {filename}: {e}")
            return None
    
    def get_geometric_matching_models(self) -> Dict[str, Path]:
        """ê¸°í•˜í•™ì  ë§¤ì¹­ìš© ëª¨ë¸ë“¤ ë§¤í•‘"""
        result = {}
        
        # ì£¼ìš” ëª¨ë¸ íŒŒì¼ë“¤
        model_files = {
            'gmm': ['gmm_final.pth'],
            'tps': ['tps_network.pth'],
            'sam_shared': ['sam_vit_h_4b8939.pth'],
            'raft': ['raft-things.pth'],
            'resnet': ['resnet101_geometric.pth'],
            'vit': ['ViT-L-14.pt'],
            'efficientnet': ['efficientnet_b0_ultra.pth']
        }
        
        for model_key, filenames in model_files.items():
            for filename in filenames:
                model_path = self.find_model_file(filename)
                if model_path:
                    result[model_key] = model_path
                    self.logger.info(f"âœ… {model_key} ëª¨ë¸ ë°œê²¬: {filename}")
                    break
        
        return result

# ==============================================
# ğŸ”¥ 8. ê¸°í•˜í•™ì  ë§¤ì¹­ ì•Œê³ ë¦¬ì¦˜ í´ë˜ìŠ¤ (í™•ì¥)
# ==============================================

class AdvancedGeometricMatcher:
    """ê³ ê¸‰ ê¸°í•˜í•™ì  ë§¤ì¹­ ì•Œê³ ë¦¬ì¦˜ - ì˜· ê°ˆì•„ì…íˆê¸° íŠ¹í™”"""
    
    def __init__(self, device="cpu"):
        self.device = device
        self.logger = logging.getLogger(self.__class__.__name__)
        
    def extract_keypoints_from_heatmaps(self, heatmaps: torch.Tensor, threshold: float = 0.3) -> List[np.ndarray]:
        """íˆíŠ¸ë§µì—ì„œ í‚¤í¬ì¸íŠ¸ ì¢Œí‘œ ì¶”ì¶œ"""
        try:
            batch_size, num_kpts, H, W = heatmaps.shape
            keypoints_batch = []
            
            for b in range(batch_size):
                keypoints = []
                for k in range(num_kpts):
                    heatmap = heatmaps[b, k].cpu().numpy()
                    
                    # ìµœëŒ€ê°’ ìœ„ì¹˜ ì°¾ê¸°
                    if heatmap.max() > threshold:
                        y, x = np.unravel_index(np.argmax(heatmap), heatmap.shape)
                        confidence = heatmap.max()
                        
                        # ì›ë³¸ ì´ë¯¸ì§€ ì¢Œí‘œë¡œ ë³€í™˜
                        x_coord = float(x * 256 / W)
                        y_coord = float(y * 192 / H)
                        
                        keypoints.append([x_coord, y_coord, confidence])
                
                if keypoints:
                    keypoints_batch.append(np.array(keypoints))
                else:
                    # ê¸°ë³¸ í‚¤í¬ì¸íŠ¸ ìƒì„±
                    keypoints_batch.append(np.array([[128, 96, 0.5]]))
            
            return keypoints_batch if len(keypoints_batch) > 1 else keypoints_batch[0]
            
        except Exception as e:
            self.logger.error(f"âŒ í‚¤í¬ì¸íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return [np.array([[128, 96, 0.5]])]
    
    def compute_transformation_matrix(self, src_keypoints: np.ndarray, 
                                    dst_keypoints: np.ndarray) -> np.ndarray:
        """í‚¤í¬ì¸íŠ¸ ê¸°ë°˜ ë³€í˜• í–‰ë ¬ ê³„ì‚°"""
        try:
            if len(src_keypoints) < 3 or len(dst_keypoints) < 3:
                return np.eye(3)
            
            # ìµœì†Œì œê³±ë²• ê¸°ë°˜ ì–´í•€ ë³€í˜•
            ones = np.ones((src_keypoints.shape[0], 1))
            src_homogeneous = np.hstack([src_keypoints[:, :2], ones])
            
            transform_2x3, _, _, _ = np.linalg.lstsq(src_homogeneous, dst_keypoints[:, :2], rcond=None)
            
            # 3x3 í–‰ë ¬ë¡œ í™•ì¥
            transform_matrix = np.vstack([transform_2x3.T, [0, 0, 1]])
            
            return transform_matrix
                
        except Exception as e:
            self.logger.warning(f"âš ï¸ ë³€í˜• í–‰ë ¬ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return np.eye(3)

    def apply_ransac_filtering(self, src_keypoints: np.ndarray, dst_keypoints: np.ndarray,
                             threshold: float = 5.0, max_trials: int = 1000) -> Tuple[np.ndarray, np.ndarray]:
        """RANSAC ê¸°ë°˜ ì´ìƒì¹˜ ì œê±°"""
        if len(src_keypoints) < 4:
            return src_keypoints, dst_keypoints
        
        best_inliers_src = src_keypoints
        best_inliers_dst = dst_keypoints
        best_score = 0
        
        for _ in range(max_trials):
            # ëœë¤ ìƒ˜í”Œ ì„ íƒ
            sample_indices = np.random.choice(len(src_keypoints), 3, replace=False)
            sample_src = src_keypoints[sample_indices]
            sample_dst = dst_keypoints[sample_indices]
            
            try:
                # ë³€í˜• í–‰ë ¬ ê³„ì‚°
                transform = self.compute_transformation_matrix(sample_src, sample_dst)
                
                # ëª¨ë“  ì ì— ëŒ€í•´ ì˜¤ì°¨ ê³„ì‚°
                src_homogeneous = np.hstack([src_keypoints[:, :2], np.ones((len(src_keypoints), 1))])
                transformed_points = (transform @ src_homogeneous.T).T[:, :2]
                
                errors = np.linalg.norm(transformed_points - dst_keypoints[:, :2], axis=1)
                inlier_mask = errors < threshold
                
                if np.sum(inlier_mask) > best_score:
                    best_score = np.sum(inlier_mask)
                    best_inliers_src = src_keypoints[inlier_mask]
                    best_inliers_dst = dst_keypoints[inlier_mask]
                    
            except Exception:
                continue
        
        return best_inliers_src, best_inliers_dst

    def compute_transformation_matrix_procrustes(self, src_keypoints: torch.Tensor, 
                                               dst_keypoints: torch.Tensor) -> torch.Tensor:
        """Procrustes ë¶„ì„ ê¸°ë°˜ ìµœì  ë³€í˜• ê³„ì‚°"""
        try:
            src_np = src_keypoints.cpu().numpy()
            dst_np = dst_keypoints.cpu().numpy()
            
            if SCIPY_AVAILABLE:
                # Procrustes ë¶„ì„
                def objective(params):
                    tx, ty, scale, rotation = params
                    
                    cos_r, sin_r = np.cos(rotation), np.sin(rotation)
                    transform_matrix = np.array([
                        [scale * cos_r, -scale * sin_r, tx],
                        [scale * sin_r, scale * cos_r, ty]
                    ])
                    
                    src_homogeneous = np.column_stack([src_np, np.ones(len(src_np))])
                    transformed = src_homogeneous @ transform_matrix.T
                    
                    error = np.sum((transformed - dst_np) ** 2)
                    return error
                
                # ìµœì í™”
                initial_params = [0, 0, 1, 0]
                result = minimize(objective, initial_params, method='BFGS')
                
                if result.success:
                    tx, ty, scale, rotation = result.x
                    cos_r, sin_r = np.cos(rotation), np.sin(rotation)
                    
                    transform_matrix = np.array([
                        [scale * cos_r, -scale * sin_r, tx],
                        [scale * sin_r, scale * cos_r, ty]
                    ])
                else:
                    transform_matrix = np.array([[1, 0, 0], [0, 1, 0]])
            else:
                # ê°„ë‹¨í•œ ìµœì†Œì œê³±ë²•
                ones = np.ones((src_np.shape[0], 1))
                src_homogeneous = np.hstack([src_np, ones])
                transform_matrix, _, _, _ = np.linalg.lstsq(src_homogeneous, dst_np, rcond=None)
                transform_matrix = transform_matrix.T
            
            return torch.from_numpy(transform_matrix).float().to(src_keypoints.device).unsqueeze(0)
            
        except Exception as e:
            self.logger.warning(f"Procrustes ë¶„ì„ ì‹¤íŒ¨: {e}")
            return torch.eye(2, 3, device=src_keypoints.device).unsqueeze(0)

# ==============================================
# ğŸ”¥ 9. GeometricMatchingStep ë©”ì¸ í´ë˜ìŠ¤ (Central Hub DI Container ì™„ì „ ì—°ë™)
# ==============================================

class GeometricMatchingStep(BaseStepMixin):
    """
    ğŸ”¥ Step 04: ê¸°í•˜í•™ì  ë§¤ì¹­ v8.0 - Central Hub DI Container ì™„ì „ ì—°ë™
    
    Central Hub DI Container v7.0ì—ì„œ ìë™ ì œê³µ:
    âœ… ModelLoader ì˜ì¡´ì„± ì£¼ì…
    âœ… MemoryManager ìë™ ì—°ê²°
    âœ… DataConverter í†µí•©
    âœ… ìë™ ì´ˆê¸°í™” ë° ì„¤ì •
    """
    
    def __init__(self, **kwargs):
        """Central Hub DI Container v7.0 ê¸°ë°˜ ì´ˆê¸°í™”"""
        try:
            # 1. í•„ìˆ˜ ì†ì„±ë“¤ ë¨¼ì € ì´ˆê¸°í™” (super() í˜¸ì¶œ ì „)
            self._initialize_step_attributes()
            
            # 2. BaseStepMixin ì´ˆê¸°í™” (Central Hub DI Container ì—°ë™)
            super().__init__(
                step_name="GeometricMatchingStep",
                step_id=4,
                **kwargs
            )
            
            # 3. GeometricMatching íŠ¹í™” ì´ˆê¸°í™”
            self._initialize_geometric_matching_specifics(**kwargs)
            
            self.logger.info("âœ… GeometricMatchingStep v8.0 Central Hub DI Container ì´ˆê¸°í™” ì™„ë£Œ")
            
        except Exception as e:
            self.logger.error(f"âŒ GeometricMatchingStep ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self._emergency_setup(**kwargs)
    
    def _initialize_step_attributes(self):
        """í•„ìˆ˜ ì†ì„±ë“¤ ì´ˆê¸°í™” (BaseStepMixin ìš”êµ¬ì‚¬í•­)"""
        self.ai_models = {}
        self.models_loading_status = {
            'gmm': False,
            'tps': False,
            'optical_flow': False,
            'keypoint': False,
            'advanced_ai': False,
            'mock_model': False
        }
        self.model_interface = None
        self.loaded_models = []
        self.logger = logging.getLogger(f"{__name__}.GeometricMatchingStep")
            
        self.gmm_model = None
        self.tps_network = None  
        self.optical_flow_model = None
        self.keypoint_matcher = None
        self.sam_model = None
        self.advanced_geometric_ai = None
        # GeometricMatching íŠ¹í™” ì†ì„±ë“¤
        self.geometric_models = {}
        self.matching_ready = False
        self.matching_cache = {}
        
        # ì„±ëŠ¥ í†µê³„
        self.performance_stats = {
            'total_processed': 0,
            'successful_matches': 0,
            'avg_processing_time': 0.0,
            'avg_transformation_quality': 0.0,
            'keypoint_match_rate': 0.0,
            'optical_flow_accuracy': 0.0,
            'cache_hit_rate': 0.0,
            'error_count': 0,
            'models_loaded': 0
        }
        
        # í†µê³„ ì‹œìŠ¤í…œ
        self.statistics = {
            'total_processed': 0,
            'successful_matches': 0,
            'average_quality': 0.0,
            'total_processing_time': 0.0,
            'ai_model_calls': 0,
            'error_count': 0,
            'model_creation_success': False,
            'real_ai_models_used': True,
            'algorithm_type': 'advanced_deeplab_aspp_self_attention',
            'features': [
                'GMM (Geometric Matching Module)',
                'TPS (Thin-Plate Spline) Transformation', 
                'Keypoint-based Matching',
                'Optical Flow Calculation',
                'RANSAC Outlier Removal',
                'DeepLabV3+ Backbone',
                'ASPP Multi-scale Context',
                'Self-Attention Keypoint Matching',
                'Edge-Aware Transformation',
                'Progressive Geometric Refinement',
                'Procrustes Analysis'
            ]
        }
  
    def _initialize_geometric_matching_specifics(self, **kwargs):
        """GeometricMatching íŠ¹í™” ì´ˆê¸°í™”"""
        try:
            # ì„¤ì •
            self.config = GeometricMatchingConfig()
            if 'config' in kwargs:
                config_dict = kwargs['config']
                if isinstance(config_dict, dict):
                    for key, value in config_dict.items():
                        if hasattr(self.config, key):
                            setattr(self.config, key, value)
            
            # ğŸ”§ ìˆ˜ì •: status ê°ì²´ ë¨¼ì € ìƒì„±
            self.status = ProcessingStatus()
            
            # ë””ë°”ì´ìŠ¤ ì„¤ì •
            self.device = self._detect_optimal_device()
            
            # Enhanced Model Path Mapping
            self.model_mapper = EnhancedModelPathMapper(kwargs.get('ai_models_root', 'ai_models'))
            
            # ê³ ê¸‰ ì•Œê³ ë¦¬ì¦˜ ë§¤ì²˜
            self.geometric_matcher = AdvancedGeometricMatcher(self.device)
            
            # AI ëª¨ë¸ ë¡œë”© (Central Hubë¥¼ í†µí•´)
            self._load_geometric_matching_models_via_central_hub()
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ GeometricMatching íŠ¹í™” ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            # ğŸ”§ ìˆ˜ì •: ì‹¤íŒ¨ ì‹œì—ë„ status ê°ì²´ ìƒì„±
            if not hasattr(self, 'status'):
                self.status = ProcessingStatus()

   
    def _detect_optimal_device(self) -> str:
        """ìµœì  ë””ë°”ì´ìŠ¤ ê°ì§€"""
        try:
            if TORCH_AVAILABLE:
                if hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
                    return "mps"
                elif torch.cuda.is_available():
                    return "cuda"
            return "cpu"
        except:
            return "cpu"
        
    def _emergency_setup(self, **kwargs):
        """ê¸´ê¸‰ ì„¤ì • (ì´ˆê¸°í™” ì‹¤íŒ¨ì‹œ)"""
        self.step_name = "GeometricMatchingStep"
        self.step_id = 4
        self.device = "cpu"
        self.ai_models = {}
        self.models_loading_status = {'emergency': True}
        self.model_interface = None
        self.loaded_models = []
        self.config = GeometricMatchingConfig()
        self.logger = logging.getLogger(f"{__name__}.GeometricMatchingStep")
        self.geometric_models = {}
        self.matching_ready = False
        self.matching_cache = {}
        self.status = ProcessingStatus()

    def _load_geometric_matching_models_via_central_hub(self):
        """Central Hub DI Containerë¥¼ í†µí•œ GeometricMatching ëª¨ë¸ ë¡œë”©"""
        try:
            self.logger.info("ğŸ”„ Central Hubë¥¼ í†µí•œ GeometricMatching AI ëª¨ë¸ ë¡œë”© ì‹œì‘...")
            
            # Central Hubì—ì„œ ModelLoader ê°€ì ¸ì˜¤ê¸° (ìë™ ì£¼ì…ë¨)
            if not hasattr(self, 'model_loader') or not self.model_loader:
                self.logger.warning("âš ï¸ ModelLoaderê°€ ì£¼ì…ë˜ì§€ ì•ŠìŒ - Mock ëª¨ë¸ë¡œ í´ë°±")
                self._create_mock_geometric_models()
                return
            
            # 1. GMM ëª¨ë¸ ë¡œë”© (Primary) - 44.7MB
            try:
                gmm_model = self.model_loader.load_model(
                    model_name="gmm_final.pth",
                    step_name="GeometricMatchingStep",
                    model_type="geometric_matching"
                )
                
                if gmm_model:
                    self.ai_models['gmm'] = gmm_model
                    self.models_loading_status['gmm'] = True
                    self.loaded_models.append('gmm')
                    self.logger.info("âœ… GMM ëª¨ë¸ ë¡œë”© ì™„ë£Œ (44.7MB)")
                else:
                    self.logger.warning("âš ï¸ GMM ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨")
                    
            except Exception as e:
                self.logger.warning(f"âš ï¸ GMM ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e}")
            
            # 2. TPS Network ë¡œë”© - 527.8MB
            try:
                tps_model = self.model_loader.load_model(
                    model_name="tps_network.pth",
                    step_name="GeometricMatchingStep", 
                    model_type="geometric_matching"
                )
                
                if tps_model:
                    self.ai_models['tps'] = tps_model
                    self.models_loading_status['tps'] = True
                    self.loaded_models.append('tps')
                    self.logger.info("âœ… TPS Network ë¡œë”© ì™„ë£Œ (527.8MB)")
                    
            except Exception as e:
                self.logger.warning(f"âš ï¸ TPS Network ë¡œë”© ì‹¤íŒ¨: {e}")
            
            # 3. SAM ê³µìœ  ëª¨ë¸ ë¡œë”© - 2445.7MB (Step 03ê³¼ ê³µìœ )
            try:
                sam_model = self.model_loader.load_model(
                    model_name="sam_vit_h_4b8939.pth",
                    step_name="GeometricMatchingStep",
                    model_type="geometric_matching"
                )
                
                if sam_model:
                    self.ai_models['sam_shared'] = sam_model
                    self.models_loading_status['sam_shared'] = True
                    self.loaded_models.append('sam_shared')
                    self.logger.info("âœ… SAM ê³µìœ  ëª¨ë¸ ë¡œë”© ì™„ë£Œ (2445.7MB)")
                    
            except Exception as e:
                self.logger.warning(f"âš ï¸ SAM ê³µìœ  ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e}")
            
            # 4. Optical Flow ëª¨ë¸ ë¡œë”© - 20.1MB
            try:
                raft_model = self.model_loader.load_model(
                    model_name="raft-things.pth",
                    step_name="GeometricMatchingStep",
                    model_type="geometric_matching"
                )
                
                if raft_model:
                    self.ai_models['optical_flow'] = raft_model
                    self.models_loading_status['optical_flow'] = True
                    self.loaded_models.append('optical_flow')
                    self.logger.info("âœ… Optical Flow ëª¨ë¸ ë¡œë”© ì™„ë£Œ (20.1MB)")
                    
            except Exception as e:
                self.logger.warning(f"âš ï¸ Optical Flow ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e}")
            
            # 5. ê³ ê¸‰ AI ëª¨ë¸ ë¡œë”©
            try:
                advanced_ai_model = CompleteAdvancedGeometricMatchingAI(input_nc=6, num_keypoints=20).to(self.device)
                self.ai_models['advanced_ai'] = advanced_ai_model
                self.models_loading_status['advanced_ai'] = True
                self.loaded_models.append('advanced_ai')
                self.logger.info("âœ… CompleteAdvancedGeometricMatchingAI ë¡œë”© ì™„ë£Œ")
                
                # ì‹¤ì œ ì²´í¬í¬ì¸íŠ¸ ë¡œë”© ì‹œë„ (ê°€ëŠ¥í•œ ê²½ìš°)
                if 'gmm' in self.loaded_models:
                    self._load_pretrained_weights(self.model_loader, 'gmm_final.pth')
                    
            except Exception as e:
                self.logger.warning(f"âš ï¸ CompleteAdvancedGeometricMatchingAI ë¡œë”© ì‹¤íŒ¨: {e}")
                
            # 6. ëª¨ë¸ì´ í•˜ë‚˜ë„ ë¡œë”©ë˜ì§€ ì•Šì€ ê²½ìš° Mock ëª¨ë¸ ìƒì„±
            if not self.loaded_models:
                self.logger.warning("âš ï¸ ì‹¤ì œ AI ëª¨ë¸ì´ í•˜ë‚˜ë„ ë¡œë”©ë˜ì§€ ì•ŠìŒ - Mock ëª¨ë¸ë¡œ í´ë°±")
                self._create_mock_geometric_models()
            
            # Model Interface ì„¤ì •
            if hasattr(self.model_loader, 'create_step_interface'):
                self.model_interface = self.model_loader.create_step_interface("GeometricMatchingStep")
            
            # ë§¤ì¹­ ì¤€ë¹„ ìƒíƒœ ì—…ë°ì´íŠ¸
            self.matching_ready = len(self.loaded_models) > 0
            self.status.models_loaded = len(self.loaded_models) > 0
            self.status.model_creation_success = len(self.loaded_models) > 0
            
            loaded_count = len(self.loaded_models)
            self.logger.info(f"ğŸ§  Central Hub GeometricMatching ëª¨ë¸ ë¡œë”© ì™„ë£Œ: {loaded_count}ê°œ ëª¨ë¸")
            
        except Exception as e:
            self.logger.error(f"âŒ Central Hub GeometricMatching ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e}")
            self._create_mock_geometric_models()

    def _load_pretrained_weights(self, model_loader, checkpoint_name: str):
        """ì‚¬ì „ í•™ìŠµëœ ê°€ì¤‘ì¹˜ ë¡œë”©"""
        try:
            # ModelLoaderë¥¼ í†µí•œ ì²´í¬í¬ì¸íŠ¸ ë¡œë”©
            checkpoint_path = model_loader.get_model_path(checkpoint_name)
            if not checkpoint_path or not checkpoint_path.exists():
                self.logger.warning(f"âš ï¸ ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ ì—†ìŒ: {checkpoint_name}")
                return
            
            self.logger.info(f"ğŸ”„ ê³ ê¸‰ AI ì²´í¬í¬ì¸íŠ¸ ë¡œë”© ì‹œë„: {checkpoint_name}")
            
            # ì²´í¬í¬ì¸íŠ¸ ë¡œë”©
            checkpoint = torch.load(checkpoint_path, map_location='cpu', weights_only=False)
            
            # ë‹¤ì–‘í•œ ì²´í¬í¬ì¸íŠ¸ í˜•ì‹ ì²˜ë¦¬
            if isinstance(checkpoint, dict):
                if 'model_state_dict' in checkpoint:
                    state_dict = checkpoint['model_state_dict']
                elif 'state_dict' in checkpoint:
                    state_dict = checkpoint['state_dict']
                elif 'generator' in checkpoint:
                    state_dict = checkpoint['generator']
                else:
                    state_dict = checkpoint
            else:
                state_dict = checkpoint
            
            # í‚¤ ì´ë¦„ ë§¤í•‘
            new_state_dict = {}
            for k, v in state_dict.items():
                new_key = k
                if k.startswith('module.'):
                    new_key = k[7:]  # 'module.' ì œê±°
                elif k.startswith('netG.'):
                    new_key = k[5:]  # 'netG.' ì œê±°
                elif k.startswith('generator.'):
                    new_key = k[10:]  # 'generator.' ì œê±°
                
                new_state_dict[new_key] = v
            
            # í˜¸í™˜ ê°€ëŠ¥í•œ ê°€ì¤‘ì¹˜ë§Œ ë¡œë”©
            if 'advanced_ai' in self.ai_models:
                model_dict = self.ai_models['advanced_ai'].state_dict()
                compatible_dict = {}
                
                for k, v in new_state_dict.items():
                    if k in model_dict and v.shape == model_dict[k].shape:
                        compatible_dict[k] = v
                
                if len(compatible_dict) > 0:
                    model_dict.update(compatible_dict)
                    self.ai_models['advanced_ai'].load_state_dict(model_dict)
                    self.logger.info(f"âœ… ê³ ê¸‰ AI ì²´í¬í¬ì¸íŠ¸ ë¶€ë¶„ ë¡œë”©: {len(compatible_dict)}/{len(new_state_dict)}ê°œ ë ˆì´ì–´")
                else:
                    self.logger.warning("âš ï¸ í˜¸í™˜ ê°€ëŠ¥í•œ ë ˆì´ì–´ ì—†ìŒ - ëœë¤ ì´ˆê¸°í™” ìœ ì§€")
                    
        except Exception as e:
            self.logger.warning(f"âš ï¸ ê³ ê¸‰ AI ì²´í¬í¬ì¸íŠ¸ ë¡œë”© ì‹¤íŒ¨: {e}")

    def _create_mock_geometric_models(self):
        """Mock GeometricMatching ëª¨ë¸ ìƒì„± (ì‹¤ì œ ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨ì‹œ í´ë°±)"""
        try:
            class MockGeometricMatchingModel:
                def __init__(self, model_name: str):
                    self.model_name = model_name
                    self.device = "cpu"
                    
                def predict(self, person_image: np.ndarray, clothing_image: np.ndarray) -> Dict[str, Any]:
                    """Mock ì˜ˆì¸¡ (ê¸°ë³¸ì ì¸ ê¸°í•˜í•™ì  ë§¤ì¹­ ê²°ê³¼ ìƒì„±)"""
                    h, w = person_image.shape[:2] if len(person_image.shape) >= 2 else (256, 192)
                    
                    # ê¸°ë³¸ ë³€í˜• í–‰ë ¬ ìƒì„± (Identity + ì•½ê°„ì˜ ë³€í˜•)
                    transformation_matrix = np.array([
                        [1.0, 0.0, 0.0],
                        [0.0, 1.0, 0.0],
                        [0.0, 0.0, 1.0]
                    ])
                    
                    # ê¸°ë³¸ ë³€í˜• ê·¸ë¦¬ë“œ ìƒì„±
                    y, x = np.meshgrid(np.linspace(-1, 1, h), np.linspace(-1, 1, w), indexing='ij')
                    transformation_grid = np.stack([x, y], axis=-1)
                    transformation_grid = np.expand_dims(transformation_grid, axis=0)  # ë°°ì¹˜ ì°¨ì›
                    
                    # ì›Œí•‘ëœ ì˜ë¥˜ (ì›ë³¸ê³¼ ë™ì¼)
                    warped_clothing = clothing_image.copy()
                    
                    # Flow field (0 ë²¡í„°)
                    flow_field = np.zeros((h, w, 2))
                    
                    # í‚¤í¬ì¸íŠ¸ (ê¸°ë³¸ 18ê°œ)
                    keypoints = []
                    for i in range(18):
                        x_coord = (i % 6) * w // 6 + w // 12
                        y_coord = (i // 6) * h // 3 + h // 6
                        keypoints.append([x_coord, y_coord, 0.8])
                    
                    return {
                        'transformation_matrix': transformation_matrix,
                        'transformation_grid': transformation_grid,
                        'warped_clothing': warped_clothing,
                        'flow_field': flow_field,
                        'keypoints': keypoints,
                        'confidence': 0.7,
                        'quality_score': 0.75,
                        'model_type': 'mock',
                        'model_name': self.model_name,
                        'algorithm_type': 'mock_geometric_matching'
                    }
            
            # Mock ëª¨ë¸ë“¤ ìƒì„±
            self.ai_models['mock_gmm'] = MockGeometricMatchingModel('mock_gmm')
            self.ai_models['mock_tps'] = MockGeometricMatchingModel('mock_tps') 
            self.ai_models['mock_optical_flow'] = MockGeometricMatchingModel('mock_optical_flow')
            self.ai_models['mock_keypoint'] = MockGeometricMatchingModel('mock_keypoint')
            self.ai_models['mock_advanced_ai'] = MockGeometricMatchingModel('mock_advanced_ai')
            
            self.models_loading_status['mock_model'] = True
            self.loaded_models = ['mock_gmm', 'mock_tps', 'mock_optical_flow', 'mock_keypoint', 'mock_advanced_ai']
            self.matching_ready = True
            self.status.models_loaded = True
            self.status.model_creation_success = True
            
            self.logger.info("âœ… Mock GeometricMatching ëª¨ë¸ ìƒì„± ì™„ë£Œ (í´ë°± ëª¨ë“œ)")
            
        except Exception as e:
            self.logger.error(f"âŒ Mock GeometricMatching ëª¨ë¸ ìƒì„± ì‹¤íŒ¨: {e}")

    def process(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """ê°„ì†Œí™”ëœ GeometricMatching ì²˜ë¦¬ (í•µì‹¬ ë¡œì§ë§Œ)"""
        try:
            start_time = time.time()
            
            # 1. ì…ë ¥ ë°ì´í„° ê²€ì¦
            if 'person_image' not in data or 'clothing_image' not in data:
                raise ValueError("í•„ìˆ˜ ì…ë ¥ ë°ì´í„° 'person_image', 'clothing_image'ê°€ ì—†ìŠµë‹ˆë‹¤")
            
            person_image = data['person_image']
            clothing_image = data['clothing_image']
            
            # 2. ë§¤ì¹­ ì¤€ë¹„ ìƒíƒœ í™•ì¸
            if not self.matching_ready:
                raise ValueError("GeometricMatching ëª¨ë¸ì´ ì¤€ë¹„ë˜ì§€ ì•ŠìŒ")
            
            # 3. ê³ ê¸‰ AI ì¶”ë¡  ì‹¤í–‰ (_run_ai_inference í˜¸í™˜)
            processed_input = {
                'person_image': person_image,
                'clothing_image': clothing_image,
                'person_parsing': data.get('person_parsing', {}),
                'pose_keypoints': data.get('pose_keypoints', []),
                'clothing_segmentation': data.get('clothing_segmentation', {})
            }
            
            # 4. ì‹¤ì œ AI ì¶”ë¡  ì‹¤í–‰
            ai_result = self._run_ai_inference(processed_input)
            
            # 5. ì²˜ë¦¬ ì‹œê°„ ê³„ì‚°
            processing_time = time.time() - start_time
            
            # 6. ìµœì¢… ê²°ê³¼ ë°˜í™˜
            if ai_result.get('success', False):
                return {
                    'success': True,
                    'transformation_matrix': ai_result.get('transformation_matrix'),
                    'transformation_grid': ai_result.get('transformation_grid'),
                    'warped_clothing': ai_result.get('warped_clothing'),
                    'flow_field': ai_result.get('flow_field'),
                    'keypoints': ai_result.get('keypoints', []),
                    'matching_confidence': ai_result.get('confidence', 0.7),
                    'quality_score': ai_result.get('quality_score', 0.75),
                    'processing_time': processing_time,
                    'model_used': ai_result.get('model_used', 'unknown'),
                    'algorithm_type': ai_result.get('algorithm_type', 'advanced_deeplab_aspp_self_attention'),
                    'ai_models_used': ai_result.get('ai_models_used', []),
                    'algorithms_used': ai_result.get('algorithms_used', []),
                    'step_name': self.step_name,
                    'step_id': self.step_id,
                    'central_hub_di_container': True
                }
            else:
                return {
                    'success': False,
                    'error': ai_result.get('error', 'AI ì¶”ë¡  ì‹¤íŒ¨'),
                    'processing_time': processing_time,
                    'step_name': self.step_name,
                    'step_id': self.step_id,
                    'central_hub_di_container': True
                }
            
        except Exception as e:
            self.logger.error(f"âŒ GeometricMatching ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            processing_time = time.time() - start_time
            
            return {
                'success': False,
                'error': str(e),
                'processing_time': processing_time,
                'step_name': self.step_name,
                'step_id': self.step_id,
                'central_hub_di_container': True
            }

    def _run_ai_inference(self, processed_input: Dict[str, Any]) -> Dict[str, Any]:
        """ì‹¤ì œ AI ê¸°ë°˜ ê¸°í•˜í•™ì  ë§¤ì¹­ ì¶”ë¡  (v27.1 ì™„ì „ ë³µì›)"""
        try:
            start_time = time.time()
            self.logger.info(f"ğŸ§  {self.step_name} ì‹¤ì œ AI ì¶”ë¡  ì‹œì‘...")
            
            # 1. ì…ë ¥ ë°ì´í„° ê²€ì¦ ë° ì „ì²˜ë¦¬
            person_image, clothing_image, person_parsing, pose_keypoints, clothing_segmentation = self._validate_and_preprocess_input(processed_input)
            
            # 2. ì´ë¯¸ì§€ í…ì„œ ë³€í™˜
            person_tensor = self._prepare_image_tensor(person_image)
            clothing_tensor = self._prepare_image_tensor(clothing_image)
            
            # 3. ìºì‹œ í™•ì¸
            cache_key = self._generate_cache_key(person_tensor, clothing_tensor)
            cached_result = self._check_cache(cache_key)
            if cached_result:
                return cached_result
            
            # 4. AI ëª¨ë¸ë“¤ ì‹¤í–‰
            results = self._execute_ai_models(person_tensor, clothing_tensor, pose_keypoints)
            
            # 5. ê³ ê¸‰ ê²°ê³¼ ìœµí•©
            final_result = self._fuse_matching_results_advanced(results, person_tensor, clothing_tensor)
            
            # 6. ë³€í˜• í’ˆì§ˆ í‰ê°€ ë° ê²°ê³¼ ì™„ì„±
            processing_time = time.time() - start_time
            final_result = self._finalize_inference_result(final_result, results, processing_time)
            
            # 7. ìºì‹œì— ì €ì¥ ë° í†µê³„ ì—…ë°ì´íŠ¸
            self._save_to_cache(cache_key, final_result)
            self._update_inference_statistics(processing_time, True, final_result['confidence'], final_result['quality_score'])
            
            self.logger.info(f"ğŸ‰ ê³ ê¸‰ AI ê¸°í•˜í•™ì  ë§¤ì¹­ ì™„ë£Œ - ì‹ ë¢°ë„: {final_result['confidence']:.3f}, í’ˆì§ˆ: {final_result['quality_score']:.3f}")
            return final_result
            
        except Exception as e:
            self.logger.error(f"âŒ ê³ ê¸‰ AI ì¶”ë¡  ì‹¤íŒ¨: {e}")
            self.performance_stats['error_count'] += 1
            self.statistics['error_count'] += 1
            
            # í´ë°±: ê¸°ë³¸ ë³€í˜• ê²°ê³¼
            return self._create_fallback_result(processed_input, str(e))

    def _validate_and_preprocess_input(self, processed_input: Dict[str, Any]) -> Tuple[Any, Any, Dict, List, Dict]:
        """ì…ë ¥ ë°ì´í„° ê²€ì¦ ë° ì „ì²˜ë¦¬"""
        person_image = processed_input.get('person_image')
        clothing_image = processed_input.get('clothing_image')
        person_parsing = processed_input.get('person_parsing', {})
        pose_keypoints = processed_input.get('pose_keypoints', [])
        clothing_segmentation = processed_input.get('clothing_segmentation', {})
        
        if person_image is None or clothing_image is None:
            raise ValueError("í•„ìˆ˜ ì…ë ¥ ë°ì´í„° ì—†ìŒ: person_image, clothing_image")
        
        return person_image, clothing_image, person_parsing, pose_keypoints, clothing_segmentation

    def _check_cache(self, cache_key: str) -> Optional[Dict[str, Any]]:
        """ìºì‹œ í™•ì¸"""
        if cache_key in self.matching_cache:
            cached_result = self.matching_cache[cache_key]
            cached_result['cache_hit'] = True
            self.logger.info("ğŸ¯ ìºì‹œì—ì„œ ê²°ê³¼ ë°˜í™˜")
            return cached_result
        return None

    def _execute_ai_models(self, person_tensor: torch.Tensor, clothing_tensor: torch.Tensor, pose_keypoints: List) -> Dict[str, Any]:
        """AI ëª¨ë¸ë“¤ ì‹¤í–‰"""
        results = {}
        
        # GMM ê¸°ë°˜ ê¸°í•˜í•™ì  ë§¤ì¹­ (í•µì‹¬)
        if self.gmm_model is not None:
            results.update(self._execute_gmm_model(person_tensor, clothing_tensor))
        
        # í‚¤í¬ì¸íŠ¸ ê¸°ë°˜ ë§¤ì¹­
        if self.keypoint_matcher is not None and len(pose_keypoints) > 0:
            results.update(self._execute_keypoint_matching(person_tensor, clothing_tensor, pose_keypoints))
        
        # Optical Flow ê¸°ë°˜ ì›€ì§ì„ ì¶”ì 
        if self.optical_flow_model is not None:
            results.update(self._execute_optical_flow(person_tensor, clothing_tensor))
        
        # CompleteAdvancedGeometricMatchingAI ì‹¤í–‰
        if self.advanced_geometric_ai is not None:
            results.update(self._execute_advanced_ai(person_tensor, clothing_tensor))
        elif 'advanced_ai' in self.loaded_models:
            results.update(self._execute_advanced_ai(person_tensor, clothing_tensor))
        
        # Procrustes ë¶„ì„ ê¸°ë°˜ í‚¤í¬ì¸íŠ¸ ë§¤ì¹­
        if self.geometric_matcher is not None:
            results.update(self._execute_procrustes_analysis(results))
        
        return results

    def _execute_gmm_model(self, person_tensor: torch.Tensor, clothing_tensor: torch.Tensor) -> Dict[str, Any]:
        """GMM ëª¨ë¸ ì‹¤í–‰"""
        try:
            if hasattr(self.gmm_model, 'forward'):
                gmm_result = self.gmm_model(person_tensor, clothing_tensor)
            else:
                # Mock ëª¨ë¸ì¸ ê²½ìš°
                gmm_result = self.gmm_model.predict(person_tensor.cpu().numpy(), clothing_tensor.cpu().numpy())
            self.logger.info("âœ… GMM ê¸°ë°˜ ê¸°í•˜í•™ì  ë§¤ì¹­ ì™„ë£Œ")
            return {'gmm': gmm_result}
        except Exception as e:
            self.logger.warning(f"âš ï¸ GMM ë§¤ì¹­ ì‹¤íŒ¨: {e}")
            return {}

    def _execute_keypoint_matching(self, person_tensor: torch.Tensor, clothing_tensor: torch.Tensor, pose_keypoints: List) -> Dict[str, Any]:
        """í‚¤í¬ì¸íŠ¸ ë§¤ì¹­ ì‹¤í–‰"""
        try:
            keypoint_result = self._perform_keypoint_matching(person_tensor, clothing_tensor, pose_keypoints)
            self.logger.info("âœ… í‚¤í¬ì¸íŠ¸ ê¸°ë°˜ ë§¤ì¹­ ì™„ë£Œ")
            return {'keypoint': keypoint_result}
        except Exception as e:
            self.logger.warning(f"âš ï¸ í‚¤í¬ì¸íŠ¸ ë§¤ì¹­ ì‹¤íŒ¨: {e}")
            return {}

    def _execute_optical_flow(self, person_tensor: torch.Tensor, clothing_tensor: torch.Tensor) -> Dict[str, Any]:
        """Optical Flow ì‹¤í–‰"""
        try:
            if hasattr(self.optical_flow_model, 'forward'):
                flow_result = self.optical_flow_model(person_tensor, clothing_tensor)
            else:
                # Mock ëª¨ë¸ì¸ ê²½ìš°
                flow_result = self.optical_flow_model.predict(person_tensor.cpu().numpy(), clothing_tensor.cpu().numpy())
            self.logger.info("âœ… Optical Flow ê³„ì‚° ì™„ë£Œ")
            return {'optical_flow': flow_result}
        except Exception as e:
            self.logger.warning(f"âš ï¸ Optical Flow ì‹¤íŒ¨: {e}")
            return {}

    def _execute_advanced_ai(self, person_tensor: torch.Tensor, clothing_tensor: torch.Tensor) -> Dict[str, Any]:
        """ê³ ê¸‰ AI ëª¨ë¸ ì‹¤í–‰"""
        try:
            if self.advanced_geometric_ai is not None:
                advanced_result = self.advanced_geometric_ai(person_tensor, clothing_tensor)
            elif 'advanced_ai' in self.ai_models:
                advanced_result = self.ai_models['advanced_ai'].predict(person_tensor.cpu().numpy(), clothing_tensor.cpu().numpy())
            else:
                return {}
            
            self.logger.info("âœ… CompleteAdvancedGeometricMatchingAI ì‹¤í–‰ ì™„ë£Œ")
            return {'advanced_ai': advanced_result}
        except Exception as e:
            self.logger.warning(f"âš ï¸ CompleteAdvancedGeometricMatchingAI ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            return {}

    def _execute_procrustes_analysis(self, results: Dict[str, Any]) -> Dict[str, Any]:
        """Procrustes ë¶„ì„ ì‹¤í–‰"""
        try:
            if (hasattr(self.geometric_matcher, 'compute_transformation_matrix_procrustes') and 
                'advanced_ai' in results and 'keypoint_heatmaps' in results['advanced_ai']):
                
                # í‚¤í¬ì¸íŠ¸ íˆíŠ¸ë§µì—ì„œ ì‹¤ì œ ì¢Œí‘œ ì¶”ì¶œ
                person_keypoints = self.geometric_matcher.extract_keypoints_from_heatmaps(
                    results['advanced_ai']['keypoint_heatmaps']
                )
                clothing_keypoints = person_keypoints  # ë™ì¼í•œ êµ¬ì¡° ê°€ì •
                
                # Procrustes ë¶„ì„ ê¸°ë°˜ ìµœì  ë³€í˜•
                transformation_matrix = self.geometric_matcher.compute_transformation_matrix_procrustes(
                    torch.tensor(clothing_keypoints, device=self.device),
                    torch.tensor(person_keypoints, device=self.device)
                )
                
                self.logger.info("âœ… Procrustes ë¶„ì„ ê¸°ë°˜ ë§¤ì¹­ ì™„ë£Œ")
                return {
                    'procrustes_transform': transformation_matrix,
                    'keypoints': person_keypoints.tolist() if hasattr(person_keypoints, 'tolist') else person_keypoints
                }
        except Exception as e:
            self.logger.warning(f"âš ï¸ Procrustes ë¶„ì„ ì‹¤íŒ¨: {e}")
        
        return {}

    def _fuse_matching_results_advanced(self, results: Dict[str, Any], 
                                      person_tensor: torch.Tensor, 
                                      clothing_tensor: torch.Tensor) -> Dict[str, Any]:
        """ê³ ê¸‰ AI ê²°ê³¼ ìœµí•©"""
        
        # 1. ë³€í˜• ê·¸ë¦¬ë“œ/í–‰ë ¬ ìš°ì„ ìˆœìœ„ ê²°ì •
        transformation_matrix = None
        transformation_grid = None
        warped_clothing = None
        
        # ê³ ê¸‰ AI ê²°ê³¼ ìš°ì„  ì‚¬ìš©
        if 'advanced_ai' in results:
            adv_result = results['advanced_ai']
            if 'transformation_matrix' in adv_result:
                transformation_matrix = adv_result['transformation_matrix']
            if 'transformation_grid' in adv_result:
                transformation_grid = adv_result['transformation_grid']
            if 'warped_clothing' in adv_result:
                warped_clothing = adv_result['warped_clothing']
        
        # GMM ê²°ê³¼ ë³´ì¡° í™œìš©
        if transformation_matrix is None and 'gmm' in results:
            gmm_result = results['gmm']
            transformation_matrix = gmm_result.get('transformation_matrix')
            transformation_grid = gmm_result.get('transformation_grid')
            warped_clothing = gmm_result.get('warped_clothing')
        
        # Procrustes ê²°ê³¼ ë³´ì¡° í™œìš©
        if 'procrustes_transform' in results and transformation_matrix is None:
            transformation_matrix = results['procrustes_transform']
        
        # í´ë°±: Identity ë³€í˜•
        if transformation_matrix is None:
            transformation_matrix = torch.eye(2, 3, device=self.device).unsqueeze(0)
        
        if transformation_grid is None:
            transformation_grid = self._create_identity_grid(1, 256, 192)
        
        if warped_clothing is None:
            try:
                warped_clothing = F.grid_sample(
                    clothing_tensor, transformation_grid, mode='bilinear',
                    padding_mode='border', align_corners=False
                )
            except Exception:
                warped_clothing = clothing_tensor.clone()
        
        # ì¶”ê°€ ê²°ê³¼ ì •ë¦¬
        keypoint_heatmaps = None
        confidence_map = None
        edge_features = None
        
        if 'advanced_ai' in results:
            adv_result = results['advanced_ai']
            keypoint_heatmaps = adv_result.get('keypoint_heatmaps')
            confidence_map = adv_result.get('confidence_map')
            edge_features = adv_result.get('edge_features')
        
        return {
            'transformation_matrix': transformation_matrix,
            'transformation_grid': transformation_grid,
            'warped_clothing': warped_clothing,
            'flow_field': self._generate_flow_field_from_grid(transformation_grid),
            'keypoint_heatmaps': keypoint_heatmaps,
            'confidence_map': confidence_map,
            'edge_features': edge_features,
            'keypoints': results.get('keypoints', []),
            'matching_score': self._compute_matching_score(results),
            'fusion_weights': self._get_fusion_weights(results),
            'detailed_results': results
        }

    def _finalize_inference_result(self, final_result: Dict[str, Any], results: Dict[str, Any], processing_time: float) -> Dict[str, Any]:
        """ì¶”ë¡  ê²°ê³¼ ì™„ì„±"""
        confidence = self._compute_enhanced_confidence(results)
        quality_score = self._compute_quality_score_advanced(results)
        
        final_result.update({
            'success': True,
            'processing_time': processing_time,
            'confidence': confidence,
            'quality_score': quality_score,
            'ai_models_used': list(results.keys()),
            'algorithms_used': self._get_used_algorithms(results),
            'device': self.device,
            'real_ai_inference': True,
            'cache_hit': False,
            'ai_enhanced': True,
            'algorithm_type': 'advanced_deeplab_aspp_self_attention',
            'version': 'v8.0'
        })
        
        return final_result

    def _update_inference_statistics(self, processing_time: float, success: bool, confidence: float, quality_score: float):
        """ì¶”ë¡  í†µê³„ ì—…ë°ì´íŠ¸"""
        self._update_performance_stats(processing_time, success, confidence, quality_score)
        self._update_statistics_advanced(processing_time, success, confidence, quality_score)

    def _perform_keypoint_matching(self, person_tensor: torch.Tensor, 
                                 clothing_tensor: torch.Tensor, 
                                 pose_keypoints: List) -> Dict[str, Any]:
        """í‚¤í¬ì¸íŠ¸ ê¸°ë°˜ ë§¤ì¹­ ìˆ˜í–‰"""
        try:
            # í‚¤í¬ì¸íŠ¸ íˆíŠ¸ë§µ ìƒì„±
            person_keypoints = self.keypoint_matcher(person_tensor)
            clothing_keypoints = self.keypoint_matcher(clothing_tensor)
            
            # íˆíŠ¸ë§µì—ì„œ ì‹¤ì œ ì¢Œí‘œ ì¶”ì¶œ
            person_coords = self.geometric_matcher.extract_keypoints_from_heatmaps(
                person_keypoints['keypoint_heatmaps']
            )
            clothing_coords = self.geometric_matcher.extract_keypoints_from_heatmaps(
                clothing_keypoints['keypoint_heatmaps']
            )
            
            # RANSAC ê¸°ë°˜ ì´ìƒì¹˜ ì œê±°
            if len(person_coords) > 3 and len(clothing_coords) > 3:
                filtered_person, filtered_clothing = self.geometric_matcher.apply_ransac_filtering(
                    person_coords, clothing_coords, 
                    threshold=self.config.confidence_threshold * 10,
                    max_trials=1000
                )
                
                # ë³€í˜• í–‰ë ¬ ê³„ì‚°
                transformation_matrix = self.geometric_matcher.compute_transformation_matrix(
                    filtered_clothing, filtered_person
                )
            else:
                transformation_matrix = np.eye(3)
            
            return {
                'person_keypoints': person_coords,
                'clothing_keypoints': clothing_coords,
                'transformation_matrix': transformation_matrix,
                'keypoint_confidence': person_keypoints['keypoint_heatmaps'].max().item(),
                'match_count': min(len(person_coords), len(clothing_coords))
            }
            
        except Exception as e:
            self.logger.error(f"âŒ í‚¤í¬ì¸íŠ¸ ë§¤ì¹­ ì‹¤íŒ¨: {e}")
            return {
                'person_keypoints': [],
                'clothing_keypoints': [],
                'transformation_matrix': np.eye(3),
                'keypoint_confidence': 0.0,
                'match_count': 0
            }

    def _compute_enhanced_confidence(self, results: Dict[str, Any]) -> float:
        """ê°•í™”ëœ ì‹ ë¢°ë„ ê³„ì‚°"""
        confidences = []
        
        # ê³ ê¸‰ AI ì‹ ë¢°ë„
        if 'advanced_ai' in results and 'confidence_map' in results['advanced_ai']:
            ai_conf = torch.mean(results['advanced_ai']['confidence_map']).item()
            confidences.append(ai_conf)
        
        # ê¸°ì¡´ GMM ì‹ ë¢°ë„
        if 'gmm' in results:
            gmm_conf = 0.8
            confidences.append(gmm_conf)
        
        # í‚¤í¬ì¸íŠ¸ ë§¤ì¹­ ì‹ ë¢°ë„
        if 'keypoint' in results:
            kpt_conf = results['keypoint']['keypoint_confidence']
            match_ratio = min(results['keypoint']['match_count'] / 18.0, 1.0)
            keypoint_confidence = kpt_conf * match_ratio
            confidences.append(keypoint_confidence)
        
        # Procrustes ë§¤ì¹­ ì‹ ë¢°ë„
        if 'procrustes_transform' in results:
            transform = results['procrustes_transform']
            try:
                det = torch.det(transform[:, :2, :2])
                stability = torch.clamp(1.0 / (torch.abs(det) + 1e-8), 0, 1)
                confidences.append(stability.mean().item())
            except:
                confidences.append(0.7)
        
        return float(np.mean(confidences)) if confidences else 0.8

    def _compute_quality_score_advanced(self, results: Dict[str, Any]) -> float:
        """ê³ ê¸‰ í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°"""
        quality_factors = []
        
        # ê³ ê¸‰ AI ì‚¬ìš© ì ìˆ˜
        if 'advanced_ai' in results:
            quality_factors.append(0.9)
        
        # ê¸°ì¡´ GMM ì‚¬ìš© ì ìˆ˜
        if 'gmm' in results:
            quality_factors.append(0.85)
        
        # Procrustes ë¶„ì„ ì ìˆ˜
        if 'procrustes_transform' in results:
            quality_factors.append(0.8)
        
        # í‚¤í¬ì¸íŠ¸ í’ˆì§ˆ
        if 'keypoints' in results:
            kpt_count = len(results['keypoints'])
            kpt_quality = min(1.0, kpt_count / 20.0)
            quality_factors.append(kpt_quality)
        
        # Edge features í’ˆì§ˆ
        if 'advanced_ai' in results and 'edge_features' in results['advanced_ai']:
            edge_feat = results['advanced_ai']['edge_features']
            if isinstance(edge_feat, torch.Tensor):
                edge_quality = torch.mean(torch.abs(edge_feat)).item()
                quality_factors.append(min(1.0, edge_quality))
        
        return float(np.mean(quality_factors)) if quality_factors else 0.75

    def _get_used_algorithms(self, results: Dict[str, Any]) -> List[str]:
        """ì‚¬ìš©ëœ ì•Œê³ ë¦¬ì¦˜ ëª©ë¡"""
        algorithms = []
        
        if 'advanced_ai' in results:
            algorithms.extend([
                "DeepLabV3+ Backbone",
                "ASPP Multi-scale Context", 
                "Self-Attention Keypoint Matching",
                "Edge-Aware Transformation",
                "Progressive Geometric Refinement"
            ])
        
        if 'gmm' in results:
            algorithms.append("GMM (Geometric Matching Module)")
        
        if 'procrustes_transform' in results:
            algorithms.append("Procrustes Analysis")
        
        if 'keypoint' in results:
            algorithms.append("Keypoint-based Matching")
        
        if 'optical_flow' in results:
            algorithms.append("Optical Flow Calculation")
        
        return algorithms

    def _update_statistics_advanced(self, processing_time: float, success: bool, 
                                confidence: float, quality_score: float):
        """ê³ ê¸‰ í†µê³„ ì—…ë°ì´íŠ¸"""
        try:
            self.statistics['total_processed'] += 1
            self.statistics['ai_model_calls'] += 1
            self.statistics['total_processing_time'] += processing_time
            
            if success:
                self.statistics['successful_matches'] += 1
                
                # í‰ê·  í’ˆì§ˆ ì—…ë°ì´íŠ¸
                total_success = self.statistics['successful_matches']
                current_avg_quality = self.statistics['average_quality']
                self.statistics['average_quality'] = (
                    (current_avg_quality * (total_success - 1) + quality_score) / total_success
                )
                
            self.statistics['model_creation_success'] = self.status.model_creation_success
            
        except Exception as e:
            self.logger.debug(f"ê³ ê¸‰ í†µê³„ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")

    def _compute_matching_score(self, results: Dict[str, Any]) -> float:
        """ë§¤ì¹­ ì ìˆ˜ ê³„ì‚°"""
        try:
            scores = []
            
            # GMM ì ìˆ˜
            if 'gmm' in results:
                scores.append(0.85)  # GMM ê¸°ë³¸ ì ìˆ˜
            
            # í‚¤í¬ì¸íŠ¸ ë§¤ì¹­ ì ìˆ˜
            if 'keypoint' in results:
                match_count = results['keypoint']['match_count']
                confidence = results['keypoint']['keypoint_confidence']
                keypoint_score = (match_count / 18.0) * confidence
                scores.append(keypoint_score)
            
            # Optical Flow ì ìˆ˜
            if 'optical_flow' in results:
                scores.append(0.75)  # Flow ê¸°ë³¸ ì ìˆ˜
            
            return float(np.mean(scores)) if scores else 0.8
            
        except Exception as e:
            return 0.8
    
    def _get_fusion_weights(self, results: Dict[str, Any]) -> Dict[str, float]:
        """ìœµí•© ê°€ì¤‘ì¹˜ ê³„ì‚°"""
        weights = {}
        
        if 'gmm' in results:
            weights['gmm'] = 0.7
        
        if 'keypoint' in results:
            weights['keypoint'] = 0.2
        
        if 'optical_flow' in results:
            weights['optical_flow'] = 0.1
        
        return weights
    
    def _generate_flow_field_from_grid(self, transformation_grid: torch.Tensor) -> torch.Tensor:
        """ë³€í˜• ê·¸ë¦¬ë“œì—ì„œ flow field ìƒì„±"""
        try:
            batch_size, H, W, _ = transformation_grid.shape
            
            # ê¸°ë³¸ ê·¸ë¦¬ë“œ
            y, x = torch.meshgrid(
                torch.linspace(-1, 1, H, device=transformation_grid.device),
                torch.linspace(-1, 1, W, device=transformation_grid.device),
                indexing='ij'
            )
            base_grid = torch.stack([x, y], dim=-1).unsqueeze(0).repeat(batch_size, 1, 1, 1)
            
            # Flow field ê³„ì‚°
            flow = (transformation_grid - base_grid) * torch.tensor([W/2, H/2], device=transformation_grid.device)
            
            return flow.permute(0, 3, 1, 2)  # (B, 2, H, W)
            
        except Exception as e:
            self.logger.error(f"âŒ Flow field ìƒì„± ì‹¤íŒ¨: {e}")
            return torch.zeros((1, 2, 256, 192), device=self.device)
    
    def _create_fallback_result(self, processed_input: Dict[str, Any], error_msg: str) -> Dict[str, Any]:
        """í´ë°± ê²°ê³¼ ìƒì„±"""
        try:
            processing_time = 0.1
            
            return {
                'success': True,  # í•­ìƒ ì„±ê³µìœ¼ë¡œ ì²˜ë¦¬
                'transformation_matrix': torch.eye(2, 3).unsqueeze(0),
                'transformation_grid': self._create_identity_grid(1, 256, 192),
                'warped_clothing': torch.zeros(1, 3, 256, 192),
                'flow_field': torch.zeros(1, 2, 256, 192),
                'confidence': 0.5,
                'quality_score': 0.5,
                'processing_time': processing_time,
                'ai_models_used': [],
                'device': self.device,
                'real_ai_inference': False,
                'fallback_used': True,
                'error_handled': error_msg[:100],
                'matching_score': 0.5
            }
            
        except Exception as e:
            self.logger.error(f"âŒ í´ë°± ê²°ê³¼ ìƒì„± ì‹¤íŒ¨: {e}")
            return {
                'success': False,
                'error': str(e),
                'transformation_matrix': None,
                'confidence': 0.0
            }
    
    def _generate_cache_key(self, person_tensor: torch.Tensor, clothing_tensor: torch.Tensor) -> str:
        """ìºì‹œ í‚¤ ìƒì„±"""
        try:
            person_hash = hashlib.md5(person_tensor.cpu().numpy().tobytes()).hexdigest()[:16]
            clothing_hash = hashlib.md5(clothing_tensor.cpu().numpy().tobytes()).hexdigest()[:16]
            config_hash = hashlib.md5(str(self.config).encode()).hexdigest()[:8]
            
            return f"geometric_matching_v8_{person_hash}_{clothing_hash}_{config_hash}"
            
        except Exception:
            return f"geometric_matching_v8_{int(time.time())}"
    
    def _save_to_cache(self, cache_key: str, result: Dict[str, Any]):
        """ìºì‹œì— ê²°ê³¼ ì €ì¥"""
        try:
            if len(self.matching_cache) >= 100:  # M3 Max ìµœì í™”
                oldest_key = next(iter(self.matching_cache))
                del self.matching_cache[oldest_key]
            
            # í…ì„œëŠ” ìºì‹œì—ì„œ ì œì™¸ (ë©”ëª¨ë¦¬ ì ˆì•½)
            cached_result = result.copy()
            for key in ['warped_clothing', 'transformation_grid', 'flow_field']:
                if key in cached_result:
                    cached_result[key] = None
            
            cached_result['timestamp'] = time.time()
            self.matching_cache[cache_key] = cached_result
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ ìºì‹œ ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def _update_performance_stats(self, processing_time: float, success: bool, 
                                confidence: float, quality_score: float):
        """ì„±ëŠ¥ í†µê³„ ì—…ë°ì´íŠ¸"""
        try:
            self.performance_stats['total_processed'] += 1
            
            if success:
                self.performance_stats['successful_matches'] += 1
                
                # í‰ê·  ì²˜ë¦¬ ì‹œê°„ ì—…ë°ì´íŠ¸
                current_avg = self.performance_stats['avg_processing_time']
                total_success = self.performance_stats['successful_matches']
                self.performance_stats['avg_processing_time'] = (
                    (current_avg * (total_success - 1) + processing_time) / total_success
                )
                
                # í‰ê·  ë³€í˜• í’ˆì§ˆ ì—…ë°ì´íŠ¸
                current_quality = self.performance_stats['avg_transformation_quality']
                self.performance_stats['avg_transformation_quality'] = (
                    (current_quality * (total_success - 1) + quality_score) / total_success
                )
            
            # ìºì‹œ íˆíŠ¸ìœ¨ ê³„ì‚°
            total_processed = self.performance_stats['total_processed']
            cache_hits = sum(1 for result in self.matching_cache.values() 
                           if result.get('cache_hit', False))
            self.performance_stats['cache_hit_rate'] = cache_hits / total_processed if total_processed > 0 else 0.0
            
        except Exception as e:
            self.logger.debug(f"í†µê³„ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")

    def _prepare_image_tensor(self, image: Any) -> torch.Tensor:
        """ì´ë¯¸ì§€ë¥¼ PyTorch í…ì„œë¡œ ë³€í™˜ (v27.1 ì™„ì „ ë³µì›)"""
        try:
            # PIL Image ì²˜ë¦¬
            if isinstance(image, Image.Image):
                if image.mode != 'RGB':
                    image = image.convert('RGB')
                image_array = np.array(image).astype(np.float32) / 255.0
                if len(image_array.shape) == 3:
                    image_array = np.transpose(image_array, (2, 0, 1))  # HWC -> CHW
                tensor = torch.from_numpy(image_array).unsqueeze(0).to(self.device)
            
            # NumPy ë°°ì—´ ì²˜ë¦¬
            elif isinstance(image, np.ndarray):
                image_array = image.astype(np.float32)
                if image_array.max() > 1.0:
                    image_array = image_array / 255.0
                if len(image_array.shape) == 3:
                    image_array = np.transpose(image_array, (2, 0, 1))  # HWC -> CHW
                tensor = torch.from_numpy(image_array).unsqueeze(0).to(self.device)
            
            # ì´ë¯¸ í…ì„œì¸ ê²½ìš°
            elif torch.is_tensor(image):
                tensor = image.to(self.device)
                if tensor.dim() == 3:
                    tensor = tensor.unsqueeze(0)
            
            else:
                raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì´ë¯¸ì§€ íƒ€ì…: {type(image)}")
            
            # í¬ê¸° ì¡°ì •
            target_size = self.config.input_size
            if tensor.shape[-2:] != target_size:
                tensor = F.interpolate(tensor, size=target_size, mode='bilinear', align_corners=False)
            
            return tensor
            
        except Exception as e:
            self.logger.error(f"âŒ ì´ë¯¸ì§€ í…ì„œ ë³€í™˜ ì‹¤íŒ¨: {e}")
            # ê¸°ë³¸ í…ì„œ ë°˜í™˜
            return torch.zeros((1, 3, 256, 192), device=self.device)

    # ==============================================
    # ğŸ”¥ ìœ í‹¸ë¦¬í‹° ë° ì •ë³´ ì¡°íšŒ ë©”ì„œë“œë“¤ (v27.1 ì™„ì „ ë³µì›)
    # ==============================================
    
    def get_full_config(self) -> Dict[str, Any]:
        """ì „ì²´ ì„¤ì • ë°˜í™˜"""
        full_config = {}
        if hasattr(self, 'config'):
            if hasattr(self.config, '__dict__'):
                full_config.update(self.config.__dict__)
            else:
                full_config.update(vars(self.config))
        return full_config

    def is_ai_enhanced(self) -> bool:
        """AI ê°•í™” ì—¬ë¶€"""
        return self.advanced_geometric_ai is not None or 'advanced_ai' in self.loaded_models

    def get_algorithm_type(self) -> str:
        """ì•Œê³ ë¦¬ì¦˜ íƒ€ì… ë°˜í™˜"""
        return 'advanced_deeplab_aspp_self_attention'

    def get_step_info(self) -> Dict[str, Any]:
        """Step ì •ë³´ ë°˜í™˜ (v27.1 ì™„ì „ ë³µì›)"""
        return {
            'step_name': self.step_name,
            'step_id': self.step_id,
            'version': 'v8.0',
            'initialized': getattr(self, 'is_initialized', False),
            'device': self.device,
            'ai_models_loaded': {
                'gmm_model': self.gmm_model is not None,
                'tps_network': self.tps_network is not None,
                'optical_flow_model': self.optical_flow_model is not None,
                'keypoint_matcher': self.keypoint_matcher is not None,
                'advanced_geometric_ai': self.advanced_geometric_ai is not None
            },
            'model_files_detected': len(getattr(self, 'model_paths', {})),
            'matching_config': self.get_full_config(),
            'performance_stats': self.performance_stats,
            'statistics': self.statistics,
            'algorithms': self.statistics.get('features', []),
            'ai_enhanced': self.is_ai_enhanced(),
            'algorithm_type': self.get_algorithm_type()
        }

    def debug_info(self) -> Dict[str, Any]:
        """ë””ë²„ê¹… ì •ë³´ ë°˜í™˜ (v27.1 ì™„ì „ ë³µì›)"""
        try:
            return {
                'step_info': {
                    'name': self.step_name,
                    'id': self.step_id,
                    'device': self.device,
                    'initialized': getattr(self, 'is_initialized', False),
                    'models_loaded': self.status.models_loaded,
                    'algorithm_type': 'advanced_deeplab_aspp_self_attention',
                    'version': 'v8.0'
                },
                'ai_models': {
                    'gmm_model_loaded': self.gmm_model is not None,
                    'advanced_geometric_ai_loaded': self.advanced_geometric_ai is not None,
                    'geometric_matcher_loaded': self.geometric_matcher is not None,
                    'model_files_detected': len(getattr(self, 'model_paths', {}))
                },
                'config': self.get_full_config(),
                'statistics': self.statistics,
                'performance_stats': self.performance_stats,
                'requirements': {
                    'compatible': self.status.requirements_compatible,
                    'ai_enhanced': True
                },
                'features': self.statistics.get('features', [])
            }
        except Exception as e:
            self.logger.error(f"âŒ ë””ë²„ê¹… ì •ë³´ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            return {'error': str(e)}

    def get_performance_stats(self) -> Dict[str, Any]:
        """ì„±ëŠ¥ í†µê³„ ë°˜í™˜ (v27.1 ì™„ì „ ë³µì›)"""
        try:
            stats = self.statistics.copy()
            
            # ì¶”ê°€ ê³„ì‚°ëœ í†µê³„
            if stats['total_processed'] > 0:
                stats['average_processing_time'] = stats['total_processing_time'] / stats['total_processed']
                stats['success_rate'] = stats['successful_matches'] / stats['total_processed']
            else:
                stats['average_processing_time'] = 0.0
                stats['success_rate'] = 0.0
            
            stats['algorithm_type'] = 'advanced_deeplab_aspp_self_attention'
            stats['version'] = 'v8.0'
            return stats
        except Exception as e:
            self.logger.error(f"âŒ ì„±ëŠ¥ í†µê³„ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            return {'error': str(e)}
    
    def validate_dependencies(self) -> Dict[str, bool]:
        """ì˜ì¡´ì„± ê²€ì¦ (v27.1 ì™„ì „ ë³µì›)"""
        try:
            return {
                'model_loader': hasattr(self, 'model_loader') and self.model_loader is not None,
                'memory_manager': hasattr(self, 'memory_manager') and self.memory_manager is not None,
                'data_converter': hasattr(self, 'data_converter') and self.data_converter is not None,
                'torch_available': TORCH_AVAILABLE,
                'mps_available': MPS_AVAILABLE,
                'pil_available': PIL_AVAILABLE,
                'numpy_available': NUMPY_AVAILABLE,
                'cv2_available': CV2_AVAILABLE,
                'scipy_available': SCIPY_AVAILABLE
            }
        except Exception as e:
            self.logger.error(f"âŒ ì˜ì¡´ì„± ê²€ì¦ ì‹¤íŒ¨: {e}")
            return {}
    
    def health_check(self) -> Dict[str, Any]:
        """ê±´ê°• ìƒíƒœ ì²´í¬ (v27.1 ì™„ì „ ë³µì›)"""
        try:
            health_status = {
                'overall_status': 'healthy',
                'timestamp': time.time(),
                'checks': {}
            }
            
            issues = []
            
            # ì´ˆê¸°í™” ìƒíƒœ ì²´í¬
            if not getattr(self, 'is_initialized', False):
                issues.append('Stepì´ ì´ˆê¸°í™”ë˜ì§€ ì•ŠìŒ')
                health_status['checks']['initialization'] = 'failed'
            else:
                health_status['checks']['initialization'] = 'passed'
            
            # AI ëª¨ë¸ ë¡œë”© ìƒíƒœ ì²´í¬
            models_loaded = sum([
                self.gmm_model is not None,
                self.tps_network is not None,
                self.optical_flow_model is not None,
                self.keypoint_matcher is not None
            ])
            
            if models_loaded == 0:
                issues.append('AI ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•ŠìŒ')
                health_status['checks']['ai_models'] = 'failed'
            elif models_loaded < 3:
                health_status['checks']['ai_models'] = 'warning'
            else:
                health_status['checks']['ai_models'] = 'passed'
            
            # ì˜ì¡´ì„± ì²´í¬
            deps = self.validate_dependencies()
            essential_deps = ['torch_available', 'pil_available', 'numpy_available']
            missing_deps = [dep for dep in essential_deps if not deps.get(dep, False)]
            
            if missing_deps:
                issues.append(f'í•„ìˆ˜ ì˜ì¡´ì„± ì—†ìŒ: {missing_deps}')
                health_status['checks']['dependencies'] = 'failed'
            else:
                health_status['checks']['dependencies'] = 'passed'
            
            # ë””ë°”ì´ìŠ¤ ìƒíƒœ ì²´í¬
            if self.device == "mps" and not MPS_AVAILABLE:
                issues.append('MPS ë””ë°”ì´ìŠ¤ ì‚¬ìš©í•  ìˆ˜ ì—†ìŒ')
                health_status['checks']['device'] = 'warning'
            elif self.device == "cuda" and not torch.cuda.is_available():
                issues.append('CUDA ë””ë°”ì´ìŠ¤ ì‚¬ìš©í•  ìˆ˜ ì—†ìŒ')
                health_status['checks']['device'] = 'warning'
            else:
                health_status['checks']['device'] = 'passed'
            
            # ì „ì²´ ìƒíƒœ ê²°ì •
            if any(status == 'failed' for status in health_status['checks'].values()):
                health_status['overall_status'] = 'unhealthy'
            elif any(status == 'warning' for status in health_status['checks'].values()):
                health_status['overall_status'] = 'degraded'
            
            if issues:
                health_status['issues'] = issues
            
            return health_status
            
        except Exception as e:
            return {
                'overall_status': 'error',
                'error': str(e),
                'timestamp': time.time()
            }
    
    # ==============================================
    # ğŸ”¥ ì •ë¦¬ ì‘ì—… (v27.1 ì™„ì „ ë³µì›)
    # ==============================================
    
    def cleanup(self):
        """ì •ë¦¬ ì‘ì—…"""
        try:
            # AI ëª¨ë¸ ì •ë¦¬
            models_to_cleanup = [
                'gmm_model', 'tps_network', 'optical_flow_model', 
                'keypoint_matcher', 'sam_model', 'advanced_geometric_ai'
            ]
            
            for model_name in models_to_cleanup:
                model = getattr(self, model_name, None)
                if model is not None:
                    del model
                    setattr(self, model_name, None)
            
            # ìºì‹œ ì •ë¦¬
            if hasattr(self, 'matching_cache'):
                self.matching_cache.clear()
            
            # ê²½ë¡œ ì •ë¦¬
            if hasattr(self, 'model_paths'):
                self.model_paths.clear()
            
            # ë§¤ì²˜ ì •ë¦¬
            if hasattr(self, 'geometric_matcher'):
                del self.geometric_matcher
            
            # ë©”ëª¨ë¦¬ ì •ë¦¬
            if self.device == "mps" and MPS_AVAILABLE:
                try:
                    if hasattr(torch.mps, 'empty_cache'):
                        torch.mps.empty_cache()
                    elif hasattr(torch.mps, 'synchronize'):
                        torch.mps.synchronize()
                except:
                    pass
            elif torch.cuda.is_available():
                torch.cuda.empty_cache()
            
            gc.collect()
            
            self.logger.info("âœ… GeometricMatchingStep ì •ë¦¬ ì™„ë£Œ")
            
        except Exception as e:
            self.logger.error(f"âŒ ì •ë¦¬ ì‘ì—… ì‹¤íŒ¨: {e}")

    # ==============================================
    # ğŸ”¥ BaseStepMixin í˜¸í™˜ ë©”ì„œë“œë“¤ (v27.1 ì™„ì „ ë³µì›)
    # ==============================================
    
    def initialize(self) -> bool:
        """ì´ˆê¸°í™” (BaseStepMixin í˜¸í™˜)"""
        try:
            if getattr(self, 'is_initialized', False):
                return True
            
            self.logger.info(f"ğŸš€ {self.step_name} v8.0 ì´ˆê¸°í™” ì‹œì‘")
            
            # ğŸ”§ ìˆ˜ì •: status ê°ì²´ê°€ ì—†ìœ¼ë©´ ìƒì„±
            if not hasattr(self, 'status'):
                self.status = ProcessingStatus()
            
            # M3 Max ìµœì í™” ì ìš©
            if self.device == "mps" or IS_M3_MAX:
                self._apply_m3_max_optimization()
            
            self.is_initialized = True
            self.is_ready = True
            self.status.initialization_complete = True  # ì´ì œ ì•ˆì „í•˜ê²Œ ì ‘ê·¼ ê°€ëŠ¥
            
            self.logger.info(f"âœ… {self.step_name} v8.0 ì´ˆê¸°í™” ì™„ë£Œ (ë¡œë”©ëœ ëª¨ë¸: {len(self.loaded_models)}ê°œ)")
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ {self.step_name} v8.0 ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return False


    def _apply_m3_max_optimization(self):
        """M3 Max ìµœì í™” ì ìš© (v27.1 ì™„ì „ ë³µì›)"""
        try:
            # MPS ìºì‹œ ì •ë¦¬
            if hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
                try:
                    if hasattr(torch.mps, 'empty_cache'):
                        torch.mps.empty_cache()
                    elif hasattr(torch.mps, 'synchronize'):
                        torch.mps.synchronize()
                except Exception:
                    pass
            
            # í™˜ê²½ ë³€ìˆ˜ ìµœì í™”
            os.environ['PYTORCH_MPS_HIGH_WATERMARK_RATIO'] = '0.0'
            os.environ['TORCH_MPS_PREFER_METAL'] = '1'
            
            if IS_M3_MAX:
                # M3 Max íŠ¹í™” ì„¤ì •
                if hasattr(self, 'config'):
                    if hasattr(self.config, 'input_size'):
                        pass  # í¬ê¸° ìœ ì§€
                
            self.logger.debug("âœ… M3 Max ìµœì í™” ì ìš© ì™„ë£Œ")
            
        except Exception as e:
            self.logger.warning(f"M3 Max ìµœì í™” ì‹¤íŒ¨: {e}")

    def _create_identity_grid(self, batch_size: int, H: int, W: int) -> torch.Tensor:
        """Identity ê·¸ë¦¬ë“œ ìƒì„±"""
        y, x = torch.meshgrid(
            torch.linspace(-1, 1, H, device=self.device),
            torch.linspace(-1, 1, W, device=self.device),
            indexing='ij'
        )
        grid = torch.stack([x, y], dim=-1).unsqueeze(0).repeat(batch_size, 1, 1, 1)
        return grid

    def _preprocess_image(self, image) -> np.ndarray:
        """ì´ë¯¸ì§€ ì „ì²˜ë¦¬"""
        try:
            # PIL Imageë¥¼ numpy arrayë¡œ ë³€í™˜
            if PIL_AVAILABLE and hasattr(image, 'convert'):
                image_pil = image.convert('RGB')
                image_array = np.array(image_pil)
            elif isinstance(image, np.ndarray):
                image_array = image
            else:
                raise ValueError("ì§€ì›í•˜ì§€ ì•ŠëŠ” ì´ë¯¸ì§€ í˜•ì‹")
            
            # í¬ê¸° ì¡°ì •
            target_size = self.config.input_size
            if PIL_AVAILABLE:
                image_pil = Image.fromarray(image_array)
                image_resized = image_pil.resize(target_size, Image.Resampling.LANCZOS)
                image_array = np.array(image_resized)
            
            # ì •ê·œí™” (0-255 ë²”ìœ„ í™•ì¸)
            if image_array.max() <= 1.0:
                image_array = (image_array * 255).astype(np.uint8)
            
            return image_array
            
        except Exception as e:
            self.logger.error(f"âŒ ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            # ê¸°ë³¸ ì´ë¯¸ì§€ ë°˜í™˜
            return np.zeros((*self.config.input_size, 3), dtype=np.uint8)

    def _postprocess_matching_result(self, matching_result: Dict[str, Any], original_person, original_clothing) -> Dict[str, Any]:
        """GeometricMatching ê²°ê³¼ í›„ì²˜ë¦¬"""
        try:
            # ì›ë³¸ ì´ë¯¸ì§€ í¬ê¸° í™•ì¸
            if hasattr(original_person, 'size'):
                original_size = original_person.size  # PIL Image
            elif isinstance(original_person, np.ndarray):
                original_size = (original_person.shape[1], original_person.shape[0])  # (width, height)
            else:
                original_size = self.config.input_size
            
            # ê²°ê³¼ ì¡°ì •
            processed_result = matching_result.copy()
            
            # ì›Œí•‘ëœ ì˜ë¥˜ í¬ê¸° ì¡°ì •
            if 'warped_clothing' in processed_result and PIL_AVAILABLE:
                warped_clothing = processed_result['warped_clothing']
                if isinstance(warped_clothing, np.ndarray) and warped_clothing.shape[:2] != original_size[::-1]:
                    warped_pil = Image.fromarray(warped_clothing.astype(np.uint8))
                    warped_resized = warped_pil.resize(original_size, Image.Resampling.LANCZOS)
                    processed_result['warped_clothing'] = np.array(warped_resized)
            
            # í‚¤í¬ì¸íŠ¸ ì¢Œí‘œ ìŠ¤ì¼€ì¼ë§
            if 'keypoints' in processed_result and processed_result['keypoints']:
                keypoints = processed_result['keypoints']
                if isinstance(keypoints, list) and len(keypoints) > 0:
                    scale_x = original_size[0] / self.config.input_size[0]
                    scale_y = original_size[1] / self.config.input_size[1]
                    
                    scaled_keypoints = []
                    for kpt in keypoints:
                        if len(kpt) >= 2:
                            scaled_kpt = [kpt[0] * scale_x, kpt[1] * scale_y]
                            if len(kpt) > 2:
                                scaled_kpt.append(kpt[2])  # confidence
                            scaled_keypoints.append(scaled_kpt)
                    processed_result['keypoints'] = scaled_keypoints
            
            return processed_result
            
        except Exception as e:
            self.logger.error(f"âŒ GeometricMatching ê²°ê³¼ í›„ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return matching_result

    def _create_emergency_matching_result(self, person_image: np.ndarray, clothing_image: np.ndarray) -> Dict[str, Any]:
        """ì‘ê¸‰ GeometricMatching ê²°ê³¼ ìƒì„±"""
        try:
            h, w = person_image.shape[:2] if len(person_image.shape) >= 2 else self.config.input_size
            
            # ê¸°ë³¸ ë³€í˜• í–‰ë ¬ (Identity)
            transformation_matrix = np.eye(3)
            
            # ê¸°ë³¸ ë³€í˜• ê·¸ë¦¬ë“œ
            y, x = np.meshgrid(np.linspace(-1, 1, h), np.linspace(-1, 1, w), indexing='ij')
            transformation_grid = np.stack([x, y], axis=-1)
            transformation_grid = np.expand_dims(transformation_grid, axis=0)
            
            # ì›Œí•‘ëœ ì˜ë¥˜ (ì›ë³¸ê³¼ ë™ì¼)
            warped_clothing = clothing_image.copy()
            
            # Flow field (0 ë²¡í„°)
            flow_field = np.zeros((h, w, 2))
            
            # ê¸°ë³¸ í‚¤í¬ì¸íŠ¸
            keypoints = [[w//2, h//2, 0.5]]
            
            return {
                'transformation_matrix': transformation_matrix,
                'transformation_grid': transformation_grid,
                'warped_clothing': warped_clothing,
                'flow_field': flow_field,
                'keypoints': keypoints,
                'confidence': 0.6,
                'quality_score': 0.6,
                'model_type': 'emergency',
                'model_name': 'emergency_fallback',
                'algorithm_type': 'emergency_geometric_matching'
            }
            
        except Exception as e:
            self.logger.error(f"âŒ ì‘ê¸‰ GeometricMatching ê²°ê³¼ ìƒì„± ì‹¤íŒ¨: {e}")
            h, w = self.config.input_size
            return {
                'transformation_matrix': np.eye(3),
                'transformation_grid': np.zeros((1, h, w, 2)),
                'warped_clothing': np.zeros((h, w, 3), dtype=np.uint8),
                'flow_field': np.zeros((h, w, 2)),
                'keypoints': [],
                'confidence': 0.0,
                'quality_score': 0.0,
                'model_type': 'error',
                'model_name': 'error',
                'algorithm_type': 'error'
            }

    def _get_step_requirements(self) -> Dict[str, Any]:
        """Step 04 GeometricMatching ìš”êµ¬ì‚¬í•­ ë°˜í™˜ (BaseStepMixin í˜¸í™˜)"""
        return {
            "required_models": [
                "gmm_final.pth",
                "tps_network.pth", 
                "sam_vit_h_4b8939.pth",
                "raft-things.pth",
                "resnet101_geometric.pth"
            ],
            "primary_model": "gmm_final.pth",
            "model_configs": {
                "gmm_final.pth": {
                    "size_mb": 44.7,
                    "device_compatible": ["cpu", "mps", "cuda"],
                    "precision": "high"
                },
                "tps_network.pth": {
                    "size_mb": 527.8,
                    "device_compatible": ["cpu", "mps", "cuda"],
                    "real_time": False
                },
                "sam_vit_h_4b8939.pth": {
                    "size_mb": 2445.7,
                    "device_compatible": ["cpu", "mps", "cuda"],
                    "shared_with": ["step_03_cloth_segmentation"]
                },
                "raft-things.pth": {
                    "size_mb": 20.1,
                    "device_compatible": ["cpu", "mps", "cuda"],
                    "real_time": True
                },
                "resnet101_geometric.pth": {
                    "size_mb": 170.5,
                    "device_compatible": ["cpu", "mps", "cuda"],
                    "backbone": True
                }
            },
            "verified_paths": [
                "step_04_geometric_matching/gmm_final.pth",
                "step_04_geometric_matching/tps_network.pth", 
                "step_04_geometric_matching/ultra_models/raft-things.pth",
                "step_04_geometric_matching/ultra_models/resnet101_geometric.pth",
                "step_03_cloth_segmentation/sam_vit_h_4b8939.pth"
            ]
        }

    def get_matching_algorithms_info(self) -> Dict[str, str]:
        """ë§¤ì¹­ ì•Œê³ ë¦¬ì¦˜ ì •ë³´ ë°˜í™˜"""
        return MATCHING_ALGORITHMS.copy()

    def get_loaded_models(self) -> List[str]:
        """ë¡œë“œëœ ëª¨ë¸ ëª©ë¡ ë°˜í™˜"""
        return self.loaded_models.copy()

    def get_model_loading_status(self) -> Dict[str, bool]:
        """ëª¨ë¸ ë¡œë”© ìƒíƒœ ë°˜í™˜"""
        return self.models_loading_status.copy()

    def validate_matching_result(self, result: Dict[str, Any]) -> bool:
        """ë§¤ì¹­ ê²°ê³¼ ìœ íš¨ì„± ê²€ì¦"""
        try:
            required_keys = ['transformation_matrix', 'transformation_grid', 'warped_clothing']
            
            for key in required_keys:
                if key not in result:
                    return False
                
                if result[key] is None:
                    return False
            
            # ë³€í˜• í–‰ë ¬ ê²€ì¦
            transform_matrix = result['transformation_matrix']
            if isinstance(transform_matrix, np.ndarray):
                if transform_matrix.shape not in [(2, 3), (3, 3)]:
                    return False
            
            return True
            
        except Exception:
            return False

    def cleanup_resources(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        try:
            # AI ëª¨ë¸ ì •ë¦¬
            for model_name, model in self.ai_models.items():
                try:
                    if hasattr(model, 'cpu'):
                        model.cpu()
                    del model
                except:
                    pass
            
            self.ai_models.clear()
            self.loaded_models.clear()
            self.matching_cache.clear()
            
            # ë©”ëª¨ë¦¬ ì •ë¦¬
            if TORCH_AVAILABLE and torch.cuda.is_available():
                torch.cuda.empty_cache()
            elif TORCH_AVAILABLE and MPS_AVAILABLE:
                try:
                    if hasattr(torch.mps, 'empty_cache'):
                        torch.mps.empty_cache()
                except:
                    pass
            
            self.logger.info("âœ… GeometricMatchingStep ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì™„ë£Œ")
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì‹¤íŒ¨: {e}")

# ==============================================
# ğŸ”¥ 9. íŒ©í† ë¦¬ í•¨ìˆ˜ë“¤
# ==============================================

def create_geometric_matching_step(**kwargs) -> GeometricMatchingStep:
    """GeometricMatchingStep ìƒì„± (Central Hub DI Container ì—°ë™)"""
    try:
        step = GeometricMatchingStep(**kwargs)
        
        # Central Hub DI Containerê°€ ìë™ìœ¼ë¡œ ì˜ì¡´ì„±ì„ ì£¼ì…í•¨
        # ë³„ë„ì˜ ì´ˆê¸°í™” ì‘ì—… ë¶ˆí•„ìš”
        
        return step
        
    except Exception as e:
        logger = logging.getLogger(__name__)
        logger.error(f"âŒ GeometricMatchingStep ìƒì„± ì‹¤íŒ¨: {e}")
        raise

def create_geometric_matching_step_sync(**kwargs) -> GeometricMatchingStep:
    """ë™ê¸°ì‹ GeometricMatchingStep ìƒì„±"""
    try:
        return create_geometric_matching_step(**kwargs)
        
    except Exception as e:
        logger = logging.getLogger(__name__)
        logger.error(f"âŒ ë™ê¸°ì‹ GeometricMatchingStep ìƒì„± ì‹¤íŒ¨: {e}")
        raise

def create_m3_max_geometric_matching_step(**kwargs) -> GeometricMatchingStep:
    """M3 Max ìµœì í™” GeometricMatchingStep ìƒì„±"""
    kwargs.setdefault('device', 'mps')
    return create_geometric_matching_step(**kwargs)

# ==============================================
# ğŸ”¥ 10. í…ŒìŠ¤íŠ¸ í•¨ìˆ˜
# ==============================================

def test_geometric_matching_step():
    """GeometricMatchingStep í…ŒìŠ¤íŠ¸"""
    try:
        print("ğŸ§ª GeometricMatchingStep v8.0 Central Hub DI Container í…ŒìŠ¤íŠ¸")
        print("=" * 70)
        
        # Step ìƒì„±
        step = create_geometric_matching_step()
        
        print(f"âœ… Step ìƒì„± ì™„ë£Œ: {step.step_name}")
        print(f"âœ… ë¡œë“œëœ ëª¨ë¸: {step.get_loaded_models()}")
        print(f"âœ… ëª¨ë¸ ë¡œë”© ìƒíƒœ: {step.get_model_loading_status()}")
        print(f"âœ… ë§¤ì¹­ ì¤€ë¹„: {step.matching_ready}")
        
        # í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€
        if PIL_AVAILABLE:
            test_person = Image.new('RGB', (256, 192), (128, 128, 128))
            test_clothing = Image.new('RGB', (256, 192), (64, 64, 64))
        else:
            test_person = np.random.randint(0, 255, (192, 256, 3), dtype=np.uint8)
            test_clothing = np.random.randint(0, 255, (192, 256, 3), dtype=np.uint8)
        
        # ì²˜ë¦¬ í…ŒìŠ¤íŠ¸
        result = step.process({
            'person_image': test_person,
            'clothing_image': test_clothing
        })
        
        if result['success']:
            print(f"âœ… ì²˜ë¦¬ ì„±ê³µ!")
            print(f"   - ì‹ ë¢°ë„: {result['matching_confidence']:.3f}")
            print(f"   - í’ˆì§ˆ ì ìˆ˜: {result['quality_score']:.3f}")
            print(f"   - ì‚¬ìš©ëœ ëª¨ë¸: {result['model_used']}")
            print(f"   - ì²˜ë¦¬ ì‹œê°„: {result['processing_time']:.3f}ì´ˆ")
            print(f"   - AI ëª¨ë¸ ìˆ˜: {result['ai_models_used']}ê°œ")
            print(f"   - ì•Œê³ ë¦¬ì¦˜ íƒ€ì…: {result['algorithm_type']}")
            print(f"   - í‚¤í¬ì¸íŠ¸ ìˆ˜: {len(result['keypoints'])}ê°œ")
            
            # ê²°ê³¼ ê²€ì¦
            result_valid = step.validate_matching_result(result)
            print(f"   - ê²°ê³¼ ìœ íš¨ì„±: {'âœ…' if result_valid else 'âŒ'}")
        else:
            print(f"âŒ ì²˜ë¦¬ ì‹¤íŒ¨: {result['error']}")
        
        # ë¦¬ì†ŒìŠ¤ ì •ë¦¬
        step.cleanup_resources()
        
        print("âœ… GeometricMatchingStep v8.0 í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
        
    except Exception as e:
        print(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")

def validate_geometric_matching_dependencies() -> Dict[str, bool]:
    """ì˜ì¡´ì„± ê²€ì¦"""
    return {
        "torch": TORCH_AVAILABLE,
        "pil": PIL_AVAILABLE,
        "numpy": NUMPY_AVAILABLE,
        "cv2": CV2_AVAILABLE,
        "scipy": SCIPY_AVAILABLE,
        "mps": MPS_AVAILABLE,
        "base_step_mixin": BaseStepMixin is not None,
        "is_m3_max": IS_M3_MAX,
        "conda_env": CONDA_INFO['is_mycloset_env']
    }

def test_advanced_ai_geometric_matching() -> bool:
    """ê³ ê¸‰ AI ê¸°í•˜í•™ì  ë§¤ì¹­ í…ŒìŠ¤íŠ¸"""
    try:
        logger = logging.getLogger(__name__)
        logger.info("ğŸ” ê³ ê¸‰ AI ê¸°í•˜í•™ì  ë§¤ì¹­ í…ŒìŠ¤íŠ¸ ì‹œì‘")
        
        # ê³ ê¸‰ AI ëª¨ë¸ ìƒì„± í…ŒìŠ¤íŠ¸
        try:
            advanced_ai = CompleteAdvancedGeometricMatchingAI(input_nc=6, num_keypoints=20)
            logger.info("âœ… CompleteAdvancedGeometricMatchingAI ìƒì„± ì„±ê³µ")
            
            # ë”ë¯¸ ì…ë ¥ìœ¼ë¡œ ìˆœì „íŒŒ í…ŒìŠ¤íŠ¸
            person_img = torch.randn(1, 3, 256, 192)
            clothing_img = torch.randn(1, 3, 256, 192)
            
            with torch.no_grad():
                result = advanced_ai(person_img, clothing_img)
            
            logger.info("âœ… ê³ ê¸‰ AI ìˆœì „íŒŒ ì„±ê³µ")
            logger.info(f"  - ë³€í˜• í–‰ë ¬ í˜•íƒœ: {result['transformation_matrix'].shape}")
            logger.info(f"  - ë³€í˜• ê·¸ë¦¬ë“œ í˜•íƒœ: {result['transformation_grid'].shape}")
            logger.info(f"  - ì›Œí•‘ ì˜ë¥˜ í˜•íƒœ: {result['warped_clothing'].shape}")
            logger.info(f"  - í‚¤í¬ì¸íŠ¸ íˆíŠ¸ë§µ í˜•íƒœ: {result['keypoint_heatmaps'].shape}")
            logger.info(f"  - ì‹ ë¢°ë„ ë§µ í˜•íƒœ: {result['confidence_map'].shape}")
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ ê³ ê¸‰ AI ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
            return False
            
    except Exception as e:
        logger.error(f"âŒ ê³ ê¸‰ AI í…ŒìŠ¤íŠ¸ ì „ì²´ ì‹¤íŒ¨: {e}")
        return False

def test_basestepmixin_compatibility():
    """BaseStepMixin í˜¸í™˜ì„± í…ŒìŠ¤íŠ¸"""
    try:
        print("ğŸ”¥ BaseStepMixin í˜¸í™˜ì„± í…ŒìŠ¤íŠ¸")
        print("=" * 60)
        
        # Step ìƒì„±
        step = GeometricMatchingStep()
        
        # BaseStepMixin ìƒì† í™•ì¸
        print(f"âœ… BaseStepMixin ìƒì†: {isinstance(step, BaseStepMixin)}")
        print(f"âœ… Step ì´ë¦„: {step.step_name}")
        print(f"âœ… Step ID: {step.step_id}")
        
        # í•„ìˆ˜ ì†ì„± í™•ì¸
        print(f"âœ… AI ëª¨ë¸ ë”•ì…”ë„ˆë¦¬: {hasattr(step, 'ai_models')}")
        print(f"âœ… ëª¨ë¸ ë¡œë”© ìƒíƒœ: {hasattr(step, 'models_loading_status')}")
        print(f"âœ… ëª¨ë¸ ì¸í„°í˜ì´ìŠ¤: {hasattr(step, 'model_interface')}")
        print(f"âœ… ë¡œë“œëœ ëª¨ë¸ ëª©ë¡: {hasattr(step, 'loaded_models')}")
        
        # process ë©”ì„œë“œ í™•ì¸
        print(f"âœ… process ë©”ì„œë“œ: {hasattr(step, 'process')}")
        
        # cleanup ë©”ì„œë“œ í™•ì¸
        print(f"âœ… cleanup_resources ë©”ì„œë“œ: {hasattr(step, 'cleanup_resources')}")
        
        print("âœ… BaseStepMixin í˜¸í™˜ì„± í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
        
    except Exception as e:
        print(f"âŒ BaseStepMixin í˜¸í™˜ì„± í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")

# ==============================================
# ğŸ”¥ 11. ëª¨ë“ˆ ì •ë³´ ë° ìµìŠ¤í¬íŠ¸
# ==============================================

__version__ = "8.0.0"
__author__ = "MyCloset AI Team"
__description__ = "ê¸°í•˜í•™ì  ë§¤ì¹­ - Central Hub DI Container ì™„ì „ ì—°ë™"
__compatibility_version__ = "8.0.0-central-hub-di-container"

__all__ = [
    # ë©”ì¸ í´ë˜ìŠ¤
    'GeometricMatchingStep',
    
    # AI ëª¨ë¸ í´ë˜ìŠ¤ë“¤
    'GeometricMatchingModule',
    'TPSGridGenerator',
    'OpticalFlowNetwork',
    'KeypointMatchingNetwork',
    
    # ê³ ê¸‰ AI ëª¨ë¸ í´ë˜ìŠ¤ë“¤
    'CompleteAdvancedGeometricMatchingAI',
    'DeepLabV3PlusBackbone',
    'ASPPModule',
    'SelfAttentionKeypointMatcher',
    'EdgeAwareTransformationModule',
    'ProgressiveGeometricRefinement',
    
    # ì•Œê³ ë¦¬ì¦˜ í´ë˜ìŠ¤
    'AdvancedGeometricMatcher',
    
    # ìœ í‹¸ë¦¬í‹° í´ë˜ìŠ¤ë“¤
    'EnhancedModelPathMapper',
    'GeometricMatchingConfig',
    'ProcessingStatus',
    
    # í¸ì˜ í•¨ìˆ˜ë“¤
    'create_geometric_matching_step',
    'create_geometric_matching_step_sync',
    'create_m3_max_geometric_matching_step',
    
    # í…ŒìŠ¤íŠ¸ í•¨ìˆ˜ë“¤
    'validate_geometric_matching_dependencies',
    'test_geometric_matching_step',
    'test_advanced_ai_geometric_matching',
    'test_basestepmixin_compatibility',
    
    # ìƒìˆ˜ë“¤
    'MATCHING_ALGORITHMS',
    'TORCH_AVAILABLE',
    'MPS_AVAILABLE',
    'PIL_AVAILABLE',
    'NUMPY_AVAILABLE',
    'CV2_AVAILABLE',
    'SCIPY_AVAILABLE',
    'IS_M3_MAX',
    'CONDA_INFO'
]

# ==============================================
# ğŸ”¥ 12. ëª¨ë“ˆ ì´ˆê¸°í™” ë¡œê¹…
# ==============================================

logger = logging.getLogger(__name__)
logger.info("=" * 120)
logger.info("ğŸ”¥ GeometricMatchingStep v8.0 - Central Hub DI Container ì™„ì „ ì—°ë™")
logger.info("=" * 120)
logger.info("âœ… Central Hub DI Container v7.0 ì™„ì „ ì—°ë™")
logger.info("âœ… BaseStepMixin ìƒì† ë° super().__init__() í˜¸ì¶œ")
logger.info("âœ… í•„ìˆ˜ ì†ì„±ë“¤ ì´ˆê¸°í™”: ai_models, models_loading_status, model_interface, loaded_models")
logger.info("âœ… _load_segmentation_models_via_central_hub() ë©”ì„œë“œ - ModelLoaderë¥¼ í†µí•œ AI ëª¨ë¸ ë¡œë”©")
logger.info("âœ… ê°„ì†Œí™”ëœ process() ë©”ì„œë“œ - í•µì‹¬ Geometric Matching ë¡œì§ë§Œ")
logger.info("âœ… ì—ëŸ¬ ë°©ì§€ìš© í´ë°± ë¡œì§ - Mock ëª¨ë¸ ìƒì„±")
logger.info("âœ… ì‹¤ì œ GMM/TPS/SAM ì²´í¬í¬ì¸íŠ¸ ì‚¬ìš© (3.0GB)")
logger.info("âœ… GitHubDependencyManager ì™„ì „ ì‚­ì œ")
logger.info("âœ… ë³µì¡í•œ DI ì´ˆê¸°í™” ë¡œì§ ë‹¨ìˆœí™”")
logger.info("âœ… ìˆœí™˜ì°¸ì¡° ë°©ì§€ ì½”ë“œ ë¶ˆí•„ìš”")
logger.info("âœ… TYPE_CHECKING ë‹¨ìˆœí™”")

logger.info("ğŸ§  ë³´ì¡´ëœ AI ëª¨ë¸ë“¤:")
logger.info("   ğŸ¯ GeometricMatchingModule - GMM ê¸°ë°˜ ê¸°í•˜í•™ì  ë§¤ì¹­")
logger.info("   ğŸŒŠ TPSGridGenerator - Thin-Plate Spline ë³€í˜•")
logger.info("   ğŸ“Š OpticalFlowNetwork - RAFT ê¸°ë°˜ Flow ê³„ì‚°")
logger.info("   ğŸ¯ KeypointMatchingNetwork - í‚¤í¬ì¸íŠ¸ ë§¤ì¹­")
logger.info("   ğŸ”¥ CompleteAdvancedGeometricMatchingAI - ê³ ê¸‰ AI ëª¨ë¸")
logger.info("   ğŸ—ï¸ DeepLabV3PlusBackbone - DeepLabV3+ ë°±ë³¸")
logger.info("   ğŸŒŠ ASPPModule - ASPP Multi-scale Context")
logger.info("   ğŸ¯ SelfAttentionKeypointMatcher - Self-Attention ë§¤ì¹­")
logger.info("   âš¡ EdgeAwareTransformationModule - Edge-Aware ë³€í˜•")
logger.info("   ğŸ“ˆ ProgressiveGeometricRefinement - Progressive ì •ì œ")
logger.info("   ğŸ“ AdvancedGeometricMatcher - ê³ ê¸‰ ë§¤ì¹­ ì•Œê³ ë¦¬ì¦˜")
logger.info("   ğŸ—ºï¸ EnhancedModelPathMapper - í–¥ìƒëœ ê²½ë¡œ ë§¤í•‘")

logger.info("ğŸ”§ ì‹¤ì œ ëª¨ë¸ íŒŒì¼ (Central Hub ê´€ë¦¬):")
logger.info("   ğŸ“ gmm_final.pth (44.7MB)")
logger.info("   ğŸ“ tps_network.pth (527.8MB)")
logger.info("   ğŸ“ sam_vit_h_4b8939.pth (2445.7MB) - Step 03ê³¼ ê³µìœ ")
logger.info("   ğŸ“ raft-things.pth (20.1MB)")
logger.info("   ğŸ“ resnet101_geometric.pth (170.5MB)")

logger.info("ğŸ”§ ì‹œìŠ¤í…œ ì •ë³´:")
logger.info(f"   - PyTorch: {TORCH_AVAILABLE}")
logger.info(f"   - MPS: {MPS_AVAILABLE}")
logger.info(f"   - PIL: {PIL_AVAILABLE}")
logger.info(f"   - M3 Max: {IS_M3_MAX}")
logger.info(f"   - ë©”ëª¨ë¦¬ ìµœì í™”: {CONDA_INFO['is_mycloset_env']}")

logger.info("ğŸ”¥ Central Hub DI Container v7.0 ì—°ë™ íŠ¹ì§•:")
logger.info("   âœ… ë‹¨ë°©í–¥ ì˜ì¡´ì„± ê·¸ë˜í”„")
logger.info("   âœ… ìˆœí™˜ì°¸ì¡° ì™„ì „ í•´ê²°")
logger.info("   âœ… ì˜ì¡´ì„± ìë™ ì£¼ì…")
logger.info("   âœ… ModelLoader íŒ©í† ë¦¬ íŒ¨í„´")
logger.info("   âœ… ê°„ì†Œí™”ëœ ì•„í‚¤í…ì²˜")
logger.info("   âœ… Mock ëª¨ë¸ í´ë°± ì‹œìŠ¤í…œ")

logger.info("=" * 120)
logger.info("ğŸ‰ MyCloset AI - Step 04 GeometricMatching v8.0 Central Hub DI Container ì™„ì „ ë¦¬íŒ©í† ë§ ì™„ë£Œ!")
logger.info("   BaseStepMixin ìƒì† + Central Hub ì—°ë™ + ëª¨ë“  ê¸°ëŠ¥ ë³´ì¡´!")
logger.info("=" * 120)

# ==============================================
# ğŸ”¥ 13. ë©”ì¸ ì‹¤í–‰ë¶€ (í…ŒìŠ¤íŠ¸)
# ==============================================

if __name__ == "__main__":
    print("=" * 120)
    print("ğŸ¯ MyCloset AI Step 04 - v8.0 Central Hub DI Container ì™„ì „ ì—°ë™")
    print("=" * 120)
    print("âœ… ì£¼ìš” ê°œì„ ì‚¬í•­:")
    print("   â€¢ Central Hub DI Container v7.0 ì™„ì „ ì—°ë™")
    print("   â€¢ BaseStepMixin ìƒì† ë° í•„ìˆ˜ ì†ì„± ì´ˆê¸°í™”")
    print("   â€¢ ModelLoader íŒ©í† ë¦¬ íŒ¨í„´ì„ í†µí•œ AI ëª¨ë¸ ë¡œë”©")
    print("   â€¢ ê°„ì†Œí™”ëœ process() ë©”ì„œë“œ")
    print("   â€¢ GitHubDependencyManager ì™„ì „ ì‚­ì œ")
    print("   â€¢ ë³µì¡í•œ DI ì´ˆê¸°í™” ë¡œì§ ë‹¨ìˆœí™”")
    print("   â€¢ ìˆœí™˜ì°¸ì¡° ë°©ì§€ ì½”ë“œ ì œê±°")
    print("   â€¢ Mock ëª¨ë¸ í´ë°± ì‹œìŠ¤í…œ")
    print("=" * 120)
    print("ğŸ”¥ ë¦¬íŒ©í† ë§ ì„±ê³¼:")
    print("   âœ… Central Hub DI Container v7.0 ì™„ì „ ì—°ë™")
    print("   âœ… BaseStepMixin í˜¸í™˜ì„± 100% ìœ ì§€")
    print("   âœ… ëª¨ë“  AI ëª¨ë¸ ë° ì•Œê³ ë¦¬ì¦˜ ë³´ì¡´")
    print("   âœ… ì‹¤ì œ ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ 3.0GB í™œìš©")
    print("   âœ… ê°„ì†Œí™”ëœ ì•„í‚¤í…ì²˜")
    print("   âœ… ì—ëŸ¬ ë°©ì§€ í´ë°± ì‹œìŠ¤í…œ")
    print("=" * 120)
    
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    try:
        test_basestepmixin_compatibility()
        print()
        test_geometric_matching_step()
        print()
        test_advanced_ai_geometric_matching()
    except Exception as e:
        print(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
    
    print("\n" + "=" * 120)
    print("ğŸ‰ GeometricMatchingStep v8.0 Central Hub DI Container ì™„ì „ ì—°ë™ ì™„ë£Œ!")
    print("âœ… BaseStepMixin ìƒì† ë° í•„ìˆ˜ ì†ì„± ì´ˆê¸°í™”")
    print("âœ… ModelLoader íŒ©í† ë¦¬ íŒ¨í„´ ì ìš©")
    print("âœ… ê°„ì†Œí™”ëœ ì•„í‚¤í…ì²˜")
    print("âœ… ì‹¤ì œ AI ëª¨ë¸ 3.0GB ì™„ì „ í™œìš©")
    print("âœ… Mock ëª¨ë¸ í´ë°± ì‹œìŠ¤í…œ")
    print("âœ… Central Hub DI Container v7.0 ì™„ì „ ì—°ë™")
    print("=" * 120)