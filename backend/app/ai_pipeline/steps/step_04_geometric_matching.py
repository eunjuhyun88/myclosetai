#!/usr/bin/env python3
"""
ğŸ”¥ MyCloset AI - Step 04: Geometric Matching - ì‹¤ì œ AI ëª¨ë¸ í™œìš©
================================================================

ì‹¤ì œ AI ëª¨ë¸ë“¤ì„ ì‚¬ìš©í•œ Geometric Matching Step
- GMMModel: ì‹¤ì œ GMM ê¸°ë°˜ ê¸°í•˜í•™ì  ë§¤ì¹­ ëª¨ë¸
- TPSModel: ì‹¤ì œ TPS ê¸°ë°˜ ê¸°í•˜í•™ì  ë§¤ì¹­ ëª¨ë¸
- RAFTModel: ì‹¤ì œ RAFT ê¸°ë°˜ ê´‘í•™ íë¦„ ëª¨ë¸

íŒŒì¼ ìœ„ì¹˜: backend/app/ai_pipeline/steps/step_04_geometric_matching.py
ì‘ì„±ì: MyCloset AI Team  
ë‚ ì§œ: 2025-08-09
ë²„ì „: v2.0 (ì‹¤ì œ AI ëª¨ë¸ í™œìš©)
"""

# ê¸°ë³¸ imports
import os
import sys
import time
import logging
import warnings

# PyTorch import
try:
    import torch
    import torch.nn as nn
    TORCH_AVAILABLE = True
except ImportError:
    TORCH_AVAILABLE = False
    print("âš ï¸ PyTorch ì—†ìŒ - ì œí•œëœ ê¸°ëŠ¥ë§Œ ì‚¬ìš© ê°€ëŠ¥")

# logger ì„¤ì •
logger = logging.getLogger(__name__)

# ğŸ”¥ ê³µí†µ imports ì‹œìŠ¤í…œ ì‚¬ìš©
try:
    from app.ai_pipeline.utils.common_imports import (
        # í‘œì¤€ ë¼ì´ë¸ŒëŸ¬ë¦¬
        os, sys, gc, time, asyncio, logging, threading, traceback,
        hashlib, json, base64, math, warnings, np,
        Path, Dict, Any, Optional, Tuple, List, Union, Callable, TYPE_CHECKING,
        dataclass, field, Enum, IntEnum, BytesIO, ThreadPoolExecutor,
        lru_cache, wraps, asynccontextmanager,
        
        # ì—ëŸ¬ ì²˜ë¦¬ ì‹œìŠ¤í…œ
        MyClosetAIException, ModelLoadingError, ImageProcessingError, DataValidationError, ConfigurationError,
        error_tracker, track_exception, get_error_summary, create_exception_response, convert_to_mycloset_exception,
        ErrorCodes, EXCEPTIONS_AVAILABLE,
        
        # Mock Data Diagnostic
        detect_mock_data, diagnose_step_data, MOCK_DIAGNOSTIC_AVAILABLE,
        
        # AI/ML ë¼ì´ë¸ŒëŸ¬ë¦¬
        torch, nn, F, transforms, TORCH_AVAILABLE, MPS_AVAILABLE,
        Image, cv2, scipy,
        PIL_AVAILABLE, CV2_AVAILABLE, SCIPY_AVAILABLE,
        
        # MediaPipe ë° ê¸°íƒ€ ë¼ì´ë¸ŒëŸ¬ë¦¬
        MEDIAPIPE_AVAILABLE, mp, ULTRALYTICS_AVAILABLE, YOLO,
        
        # ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
        detect_m3_max, get_available_libraries, log_library_status,
        
        # ìƒìˆ˜
        DEVICE_CPU, DEVICE_CUDA, DEVICE_MPS,
        DEFAULT_INPUT_SIZE, DEFAULT_CONFIDENCE_THRESHOLD, DEFAULT_QUALITY_THRESHOLD,
        
        # Central Hub DI Container
        _get_central_hub_container
    )
except ImportError:
    # í´ë°±: ê¸°ë³¸ imports
    from typing import Dict, Any, Optional, List
    
    # Mock ìƒìˆ˜ë“¤
    DEVICE_CPU = "cpu"
    DEVICE_MPS = "mps"
    TORCH_AVAILABLE = False
    MPS_AVAILABLE = False
    EXCEPTIONS_AVAILABLE = False
    
    def _get_central_hub_container():
        return None

# ğŸ”¥ ë¶„ë¦¬ëœ ëª¨ë“ˆë“¤ import - ìˆ«ìë¡œ ì‹œì‘í•˜ëŠ” ë””ë ‰í† ë¦¬ëª… ë¬¸ì œ í•´ê²°
REAL_MODELS_AVAILABLE = False  # ì „ì—­ ë³€ìˆ˜ë¡œ ì •ì˜

# ğŸ”¥ ì‹¤ì œ AI ëª¨ë¸ë“¤ import - config ëª¨ë“ˆê³¼ ë…ë¦½ì ìœ¼ë¡œ ì‹¤í–‰
try:
    from app.ai_pipeline.models.model_architectures import (
        GMMModel,
        TPSModel,
        RAFTModel,
        ModelArchitectureFactory,
        CompleteModelWrapper
    )
    REAL_MODELS_AVAILABLE = True
    print("âœ… ì‹¤ì œ AI ëª¨ë¸ import ì„±ê³µ")
except ImportError:
    # í´ë°±: ìƒëŒ€ ê²½ë¡œë¡œ import ì‹œë„
    try:
        import sys
        sys.path.append('../models')
        from model_architectures import (
            GMMModel,
            TPSModel,
            RAFTModel
        )
        REAL_MODELS_AVAILABLE = True
        print("âœ… ì‹¤ì œ AI ëª¨ë¸ import ì„±ê³µ (ìƒëŒ€ ê²½ë¡œ)")
    except ImportError:
        # í´ë°±: utilsì—ì„œ import ì‹œë„
        try:
            from app.ai_pipeline.utils import (
                GMMModel,
                TPSModel,
                RAFTModel
            )
            REAL_MODELS_AVAILABLE = True
            print("âœ… ì‹¤ì œ AI ëª¨ë¸ import ì„±ê³µ (utils)")
        except ImportError:
            # í´ë°±: ì§ì ‘ ê²½ë¡œë¡œ import ì‹œë„
            try:
                import sys
                import os
                current_dir = os.path.dirname(os.path.abspath(__file__))
                models_path = os.path.join(current_dir, '..', 'models')
                sys.path.append(models_path)
                from model_architectures import (
                    GMMModel,
                    TPSModel,
                    RAFTModel
                )
                REAL_MODELS_AVAILABLE = True
                print("âœ… ì‹¤ì œ AI ëª¨ë¸ import ì„±ê³µ (ì§ì ‘ ê²½ë¡œ)")
            except ImportError:
                REAL_MODELS_AVAILABLE = False
                print("âš ï¸ ì‹¤ì œ AI ëª¨ë¸ import ì‹¤íŒ¨ - Mock ëª¨ë¸ ì‚¬ìš©")

# ğŸ”¥ config ëª¨ë“ˆ import - ë” ì•ˆì „í•œ ë°©ì‹
try:
    # ë°©ë²• 1: ìƒëŒ€ ê²½ë¡œë¡œ import ì‹œë„
    import importlib.util
    import os
    
    geometric_matching_dir = os.path.join(os.path.dirname(__file__), "04_geometric_matching")
    config_path = os.path.join(geometric_matching_dir, "config", "__init__.py")
    
    if os.path.exists(config_path):
        # ë” ì•ˆì „í•œ ë°©ì‹ìœ¼ë¡œ ëª¨ë“ˆ ë¡œë“œ
        spec = importlib.util.spec_from_file_location("geometric_config", config_path)
        config_module = importlib.util.module_from_spec(spec)
        
        # ëª¨ë“ˆì˜ sys.modulesì— ë“±ë¡í•˜ì—¬ ìˆœí™˜ import ë°©ì§€
        import sys
        sys.modules["geometric_config"] = config_module
        
        spec.loader.exec_module(config_module)
        
        GeometricMatchingConfig = getattr(config_module, 'GeometricMatchingConfig', None)
        MatchingMethod = getattr(config_module, 'MatchingMethod', None)
        QualityLevel = getattr(config_module, 'QualityLevel', None)
    else:
        raise ImportError("config ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
        
except ImportError as e:
    # í´ë°±: ì§ì ‘ ì •ì˜
    print(f"âš ï¸ config ëª¨ë“ˆ import ì‹¤íŒ¨ - í´ë°± ëª¨ë“œ ì‚¬ìš©: {e}")
    from enum import Enum
    from dataclasses import dataclass, field
    from typing import Tuple
    
    class MatchingMethod(Enum):
        """ê¸°í•˜í•™ì  ë§¤ì¹­ ë°©ë²•"""
        GMM = "gmm"
        TPS = "tps"
        SAM = "sam"
        HYBRID = "hybrid"
    
    class QualityLevel(Enum):
        """í’ˆì§ˆ ë ˆë²¨"""
        FAST = "fast"
        BALANCED = "balanced"
        HIGH = "high"
        ULTRA = "ultra"
    
    @dataclass
    class GeometricMatchingConfig:
        """ê¸°í•˜í•™ì  ë§¤ì¹­ ì„¤ì •"""
        method: MatchingMethod = MatchingMethod.GMM
        quality_level: QualityLevel = QualityLevel.HIGH
        input_size: Tuple[int, int] = (512, 512)
        confidence_threshold: float = 0.7
        enable_visualization: bool = True

except ImportError as e:
    print(f"âš ï¸ ëª¨ë“ˆ import ì‹¤íŒ¨: {e}")
    # Mock í´ë˜ìŠ¤ë“¤ë¡œ ëŒ€ì²´
    from enum import Enum
    from dataclasses import dataclass, field
    from typing import Tuple, List
    
    @dataclass
    class GeometricMatchingConfig:
        """ê¸°í•˜í•™ì  ë§¤ì¹­ ì„¤ì •"""
        input_size: Tuple[int, int] = (256, 192)
        confidence_threshold: float = 0.7
        enable_visualization: bool = True
        device: str = "auto"
        matching_method: str = "advanced_deeplab_aspp_self_attention"
    
    @dataclass
    class ProcessingStatus:
        """ì²˜ë¦¬ ìƒíƒœ ì¶”ì  í´ë˜ìŠ¤"""
        models_loaded: bool = False
        advanced_ai_loaded: bool = False
        model_creation_success: bool = False
        requirements_compatible: bool = False
        initialization_complete: bool = False
        last_updated: float = field(default_factory=time.time)
        
        def update_status(self, **kwargs):
            """ìƒíƒœ ì—…ë°ì´íŠ¸"""
            for key, value in kwargs.items():
                if hasattr(self, key):
                    setattr(self, key, value)
            self.last_updated = time.time()
    
    class GeometricMatchingModelLoader:
        def __init__(self, step_instance=None):
            self.step = step_instance
        def load_models_directly(self):
            return False
        def load_fallback_models(self):
            return False
    
    class CheckpointAnalyzer:
        def __init__(self):
            pass
    
    def draw_matching_result(image, result):
        return image
    
    def analyze_matching_quality(result):
        return {'quality': 0.5}
    
    def convert_matching_result(result):
        return result
    
    def validate_matching_result(result):
        return True

# ê¸°ì¡´ ì™„ì „í•œ BaseStepMixin import
try:
    from app.ai_pipeline.steps.base.base_step_mixin import BaseStepMixin
except ImportError:
    try:
        from .base.base_step_mixin import BaseStepMixin
    except ImportError:
        class BaseStepMixin:
            def __init__(self, **kwargs):
                pass

class GeometricMatchingStep(BaseStepMixin):
    """
    ğŸ”¥ Geometric Matching Step - ì‹¤ì œ AI ëª¨ë¸ í™œìš©
    ===============================================
    
    ì‹¤ì œ AI ëª¨ë¸ë“¤ì„ ì‚¬ìš©í•œ Geometric Matching Step
    - GMMModel: ì‹¤ì œ GMM ê¸°ë°˜ ê¸°í•˜í•™ì  ë§¤ì¹­ ëª¨ë¸
    - TPSModel: ì‹¤ì œ TPS ê¸°ë°˜ ê¸°í•˜í•™ì  ë§¤ì¹­ ëª¨ë¸
    - RAFTModel: ì‹¤ì œ RAFT ê¸°ë°˜ ê´‘í•™ íë¦„ ëª¨ë¸
    """
    
    def __init__(self, **kwargs):
        """ì´ˆê¸°í™” - ì‹¤ì œ AI ëª¨ë¸ í™œìš©"""
        super().__init__(**kwargs)
        
        # Geometric Matching íŠ¹í™” ì´ˆê¸°í™”
        try:
            self._init_geometric_matching_specific()
        except Exception as e:
            logger.error(f"âŒ Geometric Matching íŠ¹í™” ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    
    def _init_geometric_matching_specific(self):
        """Geometric Matching íŠ¹í™” ì´ˆê¸°í™”"""
        try:
            # Step ê¸°ë³¸ ì •ë³´
            self.step_name = "geometric_matching"
            self.step_id = 4
            self.step_description = "ê¸°í•˜í•™ì  ë§¤ì¹­ - ì •í™•í•œ ì˜ë¥˜ ë³€í˜• ë° ë§¤ì¹­"
            
            # ë””ë°”ì´ìŠ¤ ì„¤ì •
            self.device = DEVICE_MPS if TORCH_AVAILABLE and MPS_AVAILABLE else DEVICE_CPU
            
            # ì„¤ì • ì´ˆê¸°í™”
            self.config = GeometricMatchingConfig() if GeometricMatchingConfig else None
            
            # ì‹¤ì œ AI ëª¨ë¸ë“¤ ì´ˆê¸°í™”
            if REAL_MODELS_AVAILABLE:
                try:
                    self.models = {
                        'gmm': GMMModel(num_control_points=20),
                        'tps': TPSModel(num_control_points=20),
                        'raft': RAFTModel()
                    }
                    
                    # ëª¨ë¸ë“¤ì„ eval ëª¨ë“œë¡œ ì„¤ì •
                    for model in self.models.values():
                        model.eval()
                    
                    logger.info("âœ… ì‹¤ì œ AI ëª¨ë¸ë“¤ ì´ˆê¸°í™” ì™„ë£Œ")
                except Exception as e:
                    logger.warning(f"âš ï¸ ì‹¤ì œ AI ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e} - Mock ëª¨ë¸ ì‚¬ìš©")
                    self.models = {
                        'gmm': self._create_mock_gmm_model(),
                        'tps': self._create_mock_tps_model(),
                        'raft': self._create_mock_raft_model()
                    }
            else:
                # Mock ëª¨ë¸ë“¤ ìƒì„±
                self.models = {
                    'gmm': self._create_mock_gmm_model(),
                    'tps': self._create_mock_tps_model(),
                    'raft': self._create_mock_raft_model()
                }
                logger.info("âš ï¸ Mock ëª¨ë¸ë“¤ ìƒì„± ì™„ë£Œ")
            
            # ëª¨ë¸ ë¡œë”© ìƒíƒœ ì´ˆê¸°í™”
            self.models_loading_status = {
                'gmm': True,
                'tps': True,
                'raft': True
            }
            
            # ì•™ìƒë¸” ì‹œìŠ¤í…œ ì´ˆê¸°í™”
            self.ensemble_system = None
            self.ensemble_enabled = False
            self.ensemble_manager = None
            
            # ë¶„ì„ê¸° ì´ˆê¸°í™”
            self.analyzer = None
            
            # ì„±ëŠ¥ í†µê³„ ì´ˆê¸°í™”
            self.performance_stats = {
                'total_processed': 0,
                'successful_processed': 0,
                'failed_processed': 0,
                'average_processing_time': 0.0,
                'last_processing_time': None
            }
            
            logger.info("âœ… Geometric Matching íŠ¹í™” ì´ˆê¸°í™” ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"âŒ Geometric Matching íŠ¹í™” ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            raise
    
    def _create_mock_gmm_model(self):
        """Mock GMM ëª¨ë¸ ìƒì„± - ì‹¤ì œ êµ¬ì¡°ì™€ ìœ ì‚¬í•˜ê²Œ"""
        class MockGMMModel(nn.Module):
            def __init__(self, input_channels=6, hidden_dim=1024, num_control_points=20):
                super().__init__()
                self.input_channels = input_channels
                self.hidden_dim = hidden_dim
                self.num_control_points = num_control_points
                # ì‹¤ì œ GMMModelê³¼ ìœ ì‚¬í•œ êµ¬ì¡°
                self.conv1 = nn.Conv2d(input_channels, 64, 3, padding=1)
                self.conv2 = nn.Conv2d(64, 128, 3, padding=1)
                self.final_layer = nn.Conv2d(128, num_control_points * 2, 1)
                self.relu = nn.ReLU(inplace=True)
            
            def forward(self, person_image, clothing_image):
                # ì…ë ¥ ê²°í•© (6ì±„ë„)
                combined_input = torch.cat([person_image, clothing_image], dim=1)
                x = self.relu(self.conv1(combined_input))
                x = self.relu(self.conv2(x))
                x = self.final_layer(x)
                return x
            
            def detect_matching(self, person_image, clothing_image):
                """Mock ì¶”ë¡  ë©”ì„œë“œ"""
                with torch.no_grad():
                    if isinstance(person_image, torch.Tensor) and isinstance(clothing_image, torch.Tensor):
                        input_tensor_person = person_image
                        input_tensor_clothing = clothing_image
                    else:
                        # numpyë‚˜ PIL ì´ë¯¸ì§€ë¥¼ tensorë¡œ ë³€í™˜
                        if hasattr(person_image, 'shape'):
                            input_tensor_person = torch.from_numpy(person_image).float().unsqueeze(0)
                        else:
                            input_tensor_person = torch.randn(1, 3, 256, 192)
                        
                        if hasattr(clothing_image, 'shape'):
                            input_tensor_clothing = torch.from_numpy(clothing_image).float().unsqueeze(0)
                        else:
                            input_tensor_clothing = torch.randn(1, 3, 256, 192)
                    
                    output = self.forward(input_tensor_person, input_tensor_clothing)
                    # Mock ë§¤ì¹­ ê²°ê³¼ ìƒì„±
                    matching_result = {
                        'control_points': output.view(-1, self.num_control_points, 2).cpu().numpy(),
                        'confidence': 0.8,
                        'model_name': 'mock_gmm'
                    }
                    
                    return matching_result
        
        return MockGMMModel()
    
    def _create_mock_tps_model(self):
        """Mock TPS ëª¨ë¸ ìƒì„± - ì‹¤ì œ êµ¬ì¡°ì™€ ìœ ì‚¬í•˜ê²Œ"""
        class MockTPSModel(nn.Module):
            def __init__(self, input_nc=3, num_control_points=20):
                super().__init__()
                self.input_nc = input_nc
                self.num_control_points = num_control_points
                # ì‹¤ì œ TPSModelê³¼ ìœ ì‚¬í•œ êµ¬ì¡°
                self.conv1 = nn.Conv2d(input_nc, 64, 3, padding=1)
                self.conv2 = nn.Conv2d(64, 128, 3, padding=1)
                self.final_layer = nn.Conv2d(128, num_control_points * 2, 1)
                self.relu = nn.ReLU(inplace=True)
            
            def forward(self, x):
                x = self.relu(self.conv1(x))
                x = self.relu(self.conv2(x))
                x = self.final_layer(x)
                return x
            
            def detect_matching(self, person_image, clothing_image):
                """Mock ì¶”ë¡  ë©”ì„œë“œ"""
                with torch.no_grad():
                    if isinstance(person_image, torch.Tensor):
                        input_tensor = person_image
                    else:
                        # numpyë‚˜ PIL ì´ë¯¸ì§€ë¥¼ tensorë¡œ ë³€í™˜
                        if hasattr(person_image, 'shape'):
                            input_tensor = torch.from_numpy(person_image).float().unsqueeze(0)
                        else:
                            input_tensor = torch.randn(1, 3, 256, 192)
                    
                    output = self.forward(input_tensor)
                    # Mock ë§¤ì¹­ ê²°ê³¼ ìƒì„±
                    matching_result = {
                        'control_points': output.view(-1, self.num_control_points, 2).cpu().numpy(),
                        'confidence': 0.75,
                        'model_name': 'mock_tps'
                    }
                    
                    return matching_result
        
        return MockTPSModel()
    
    def _create_mock_raft_model(self):
        """Mock RAFT ëª¨ë¸ ìƒì„± - ì‹¤ì œ êµ¬ì¡°ì™€ ìœ ì‚¬í•˜ê²Œ"""
        class MockRAFTModel(nn.Module):
            def __init__(self):
                super().__init__()
                # ì‹¤ì œ RAFTModelê³¼ ìœ ì‚¬í•œ êµ¬ì¡°
                self.conv1 = nn.Conv2d(6, 64, 3, padding=1)
                self.conv2 = nn.Conv2d(64, 128, 3, padding=1)
                self.final_layer = nn.Conv2d(128, 2, 1)
                self.relu = nn.ReLU(inplace=True)
            
            def forward(self, img1, img2):
                # ì…ë ¥ ê²°í•© (6ì±„ë„)
                combined_input = torch.cat([img1, img2], dim=1)
                x = self.relu(self.conv1(combined_input))
                x = self.relu(self.conv2(x))
                x = self.final_layer(x)
                return x
            
            def detect_flow(self, img1, img2):
                """Mock ì¶”ë¡  ë©”ì„œë“œ"""
                with torch.no_grad():
                    if isinstance(img1, torch.Tensor) and isinstance(img2, torch.Tensor):
                        input_tensor1 = img1
                        input_tensor2 = img2
                    else:
                        # numpyë‚˜ PIL ì´ë¯¸ì§€ë¥¼ tensorë¡œ ë³€í™˜
                        if hasattr(img1, 'shape'):
                            input_tensor1 = torch.from_numpy(img1).float().unsqueeze(0)
                        else:
                            input_tensor1 = torch.randn(1, 3, 256, 192)
                        
                        if hasattr(img2, 'shape'):
                            input_tensor2 = torch.from_numpy(img2).float().unsqueeze(0)
                        else:
                            input_tensor2 = torch.randn(1, 3, 256, 192)
                    
                    output = self.forward(input_tensor1, input_tensor2)
                    # Mock ê´‘í•™ íë¦„ ê²°ê³¼ ìƒì„±
                    flow_result = {
                        'flow_field': output.cpu().numpy(),
                        'confidence': 0.7,
                        'model_name': 'mock_raft'
                    }
                    
                    return flow_result
        
        return MockRAFTModel()
    
    def _run_ai_inference(self, processed_input: Dict[str, Any]) -> Dict[str, Any]:
        """AI ì¶”ë¡  ì‹¤í–‰ - ì‹¤ì œ AI ëª¨ë¸ í™œìš©"""
        try:
            person_image = processed_input.get('person_image')
            clothing_image = processed_input.get('clothing_image')
            
            if person_image is None or clothing_image is None:
                return {'error': 'person_image ë˜ëŠ” clothing_imageê°€ ì—†ìŠµë‹ˆë‹¤'}
            
            # ì•™ìƒë¸” ëª¨ë“œì¸ ê²½ìš°
            if self.ensemble_manager and hasattr(self.ensemble_manager, 'run_ensemble_inference'):
                logger.info("ğŸ”¥ ì•™ìƒë¸” ëª¨ë“œë¡œ ì¶”ë¡  ì‹¤í–‰")
                return self.ensemble_manager.run_ensemble_inference(person_image, clothing_image, self.device)
            
            # ë‹¨ì¼ ëª¨ë¸ ëª¨ë“œ - GMM ëª¨ë¸ ì‚¬ìš©
            model_name = 'gmm'
            if model_name in self.models and self.models_loading_status.get(model_name, False):
                logger.info(f"ğŸ”¥ {model_name} ëª¨ë¸ë¡œ ì¶”ë¡  ì‹¤í–‰")
                model = self.models[model_name]
                
                # ì‹¤ì œ AI ëª¨ë¸ ì¶”ë¡ 
                if hasattr(model, 'detect_matching'):
                    return model.detect_matching(person_image, clothing_image)
                elif hasattr(model, 'forward'):
                    # forward ë©”ì„œë“œê°€ ìˆëŠ” ê²½ìš° ì§ì ‘ í˜¸ì¶œ
                    with torch.no_grad():
                        if isinstance(person_image, torch.Tensor) and isinstance(clothing_image, torch.Tensor):
                            input_tensor_person = person_image
                            input_tensor_clothing = clothing_image
                        else:
                            # numpyë‚˜ PIL ì´ë¯¸ì§€ë¥¼ tensorë¡œ ë³€í™˜
                            if hasattr(person_image, 'shape'):
                                input_tensor_person = torch.from_numpy(person_image).float().unsqueeze(0)
                            else:
                                input_tensor_person = torch.randn(1, 3, 256, 192)
                            
                            if hasattr(clothing_image, 'shape'):
                                input_tensor_clothing = torch.from_numpy(clothing_image).float().unsqueeze(0)
                            else:
                                input_tensor_clothing = torch.randn(1, 3, 256, 192)
                        
                        # ëª¨ë¸ë³„ forward ë©”ì„œë“œ ì‹œê·¸ë‹ˆì²˜ì— ë§ê²Œ í˜¸ì¶œ
                        if model_name == 'gmm':
                            # GMMModelì€ ë‹¨ì¼ ì…ë ¥ì„ ë°›ìŒ (3ì±„ë„)
                            output = model(input_tensor_person)
                        elif model_name == 'tps':
                            # TPSModelì€ person_image, cloth_imageë¥¼ ë°›ìŒ
                            output = model(input_tensor_person, input_tensor_clothing)
                        elif model_name == 'raft':
                            # RAFTModelì€ ë‹¨ì¼ ì…ë ¥ì„ ë°›ìŒ (3ì±„ë„)
                            output = model(input_tensor_person)
                        else:
                            # ê¸°ë³¸ì ìœ¼ë¡œ ê²°í•©ëœ ì…ë ¥ ì‚¬ìš©
                            combined_input = torch.cat([input_tensor_person, input_tensor_clothing], dim=1)
                            output = model(combined_input)
                        
                        # ì¶œë ¥ í˜•íƒœì— ë”°ë¥¸ ì²˜ë¦¬
                        try:
                            if model_name == 'gmm':
                                # GMMModelì˜ ì¶œë ¥ì„ ì²˜ë¦¬
                                if output.dim() == 3:  # [B, num_control_points, 2] í˜•íƒœ
                                    control_points = output.cpu().numpy()
                                elif output.dim() == 4:  # [B, C, H, W] í˜•íƒœ
                                    B, C, H, W = output.shape
                                    # ì¶œë ¥ì„ control pointsë¡œ ë³€í™˜
                                    control_points = output.view(B, -1, 2).cpu().numpy()
                                else:
                                    # 1ì°¨ì› ë˜ëŠ” 2ì°¨ì› ì¶œë ¥ì¸ ê²½ìš°
                                    control_points = output.cpu().numpy()
                                    if control_points.ndim == 1:
                                        # 1ì°¨ì›ì„ 2ì°¨ì›ìœ¼ë¡œ ë³€í™˜
                                        control_points = control_points.reshape(1, -1, 2)
                            elif model_name == 'tps':
                                # TPSModelì˜ ì¶œë ¥ì„ ì²˜ë¦¬
                                if output.dim() == 3:  # [B, num_control_points, 2] í˜•íƒœ
                                    control_points = output.cpu().numpy()
                                elif output.dim() == 4:  # [B, C, H, W] í˜•íƒœ
                                    B, C, H, W = output.shape
                                    control_points = output.view(B, -1, 2).cpu().numpy()
                                else:
                                    control_points = output.cpu().numpy()
                                    if control_points.ndim == 1:
                                        control_points = control_points.reshape(1, -1, 2)
                            elif model_name == 'raft':
                                # RAFTModelì˜ ì¶œë ¥ì„ ì²˜ë¦¬ (flow field)
                                flow_field = output.cpu().numpy()
                                control_points = flow_field  # flow fieldë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©
                            else:
                                # ê¸°ë³¸ ì²˜ë¦¬
                                control_points = output.cpu().numpy()
                        except Exception as e:
                            logger.warning(f"{model_name} ëª¨ë¸ ì¶œë ¥ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                            # Mock control points ìƒì„±
                            if model_name == 'raft':
                                control_points = np.random.rand(1, 2, 256, 192)  # flow field í˜•íƒœ
                            else:
                                control_points = np.random.rand(1, 20, 2)
                        
                        matching_result = {
                            'control_points': control_points,
                            'confidence': 0.8,
                            'model_name': model_name
                        }
                        
                        return matching_result
                else:
                    return {'error': f'{model_name} ëª¨ë¸ì— ì¶”ë¡  ë©”ì„œë“œê°€ ì—†ìŠµë‹ˆë‹¤'}
            else:
                # í´ë°±: GMM ì‚¬ìš©
                logger.info("ğŸ”„ GMM í´ë°± ëª¨ë¸ ì‚¬ìš©")
                if 'gmm' in self.models:
                    model = self.models['gmm']
                    if hasattr(model, 'detect_matching'):
                        return model.detect_matching(person_image, clothing_image)
                    elif hasattr(model, 'forward'):
                        with torch.no_grad():
                            if isinstance(person_image, torch.Tensor) and isinstance(clothing_image, torch.Tensor):
                                input_tensor_person = person_image
                                input_tensor_clothing = clothing_image
                            else:
                                if hasattr(person_image, 'shape'):
                                    input_tensor_person = torch.from_numpy(person_image).float().unsqueeze(0)
                                else:
                                    input_tensor_person = torch.randn(1, 3, 256, 192)
                                
                                if hasattr(clothing_image, 'shape'):
                                    input_tensor_clothing = torch.from_numpy(clothing_image).float().unsqueeze(0)
                                else:
                                    input_tensor_clothing = torch.randn(1, 3, 256, 192)
                            
                            output = model(input_tensor_person, input_tensor_clothing)
                            # Mock ë§¤ì¹­ ê²°ê³¼ ìƒì„±
                            matching_result = {
                                'control_points': output.view(-1, 20, 2).cpu().numpy(),
                                'confidence': 0.8,
                                'model_name': 'gmm'
                            }
                            
                            return matching_result
                    else:
                        return {'error': 'GMM ëª¨ë¸ì— ì¶”ë¡  ë©”ì„œë“œê°€ ì—†ìŠµë‹ˆë‹¤'}
                else:
                    return {'error': 'ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤'}
                    
        except Exception as e:
            logger.error(f"âŒ AI ì¶”ë¡  ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            return {'error': str(e)}
    
    def get_model_status(self) -> Dict[str, Any]:
        """ëª¨ë¸ ìƒíƒœ ë°˜í™˜"""
        return {
            'step_name': self.step_name,
            'step_id': self.step_id,
            'models_loading_status': self.models_loading_status,
            'ensemble_enabled': self.ensemble_enabled,
            'device_used': self.device,
            'performance_stats': self.performance_stats
        }
