"""
4ë‹¨ê³„: ê¸°í•˜í•™ì  ë§¤ì¹­ (Geometric Matching) - í†µí•© ë²„ì „
ë‘ íŒŒì¼ì˜ ì¥ì ì„ ëª¨ë‘ í¬í•¨í•œ ì™„ì „í•œ TPS ë³€í™˜ + ë©”ì‰¬ ì›Œí•‘ ì‹œìŠ¤í…œ
M3 Max ìµœì í™” í¬í•¨
"""
import os
import logging
import time
import math
from typing import Dict, Any, Optional, Tuple, List
import numpy as np
import torch
import torch.nn.functional as F
import cv2
from scipy.interpolate import RBFInterpolator
from scipy.spatial import Delaunay
from scipy.spatial.distance import cdist
from scipy.optimize import linear_sum_assignment
import json

logger = logging.getLogger(__name__)

class GeometricMatchingStep:
    """ê¸°í•˜í•™ì  ë§¤ì¹­ ìŠ¤í… - TPS ë³€í™˜ + ë©”ì‰¬ ì›Œí•‘ í†µí•© ë²„ì „"""
    
    # ì˜ë¥˜ë³„ ì£¼ìš” ë§¤ì¹­ í¬ì¸íŠ¸ ì •ì˜ (ë” ì„¸ë¶„í™”)
    CLOTHING_KEYPOINTS = {
        'shirt': ['left_shoulder', 'right_shoulder', 'left_sleeve', 'right_sleeve', 
                 'collar', 'hem', 'left_armpit', 'right_armpit'],
        'pants': ['waist_left', 'waist_right', 'left_leg', 'right_leg', 
                 'left_ankle', 'right_ankle', 'left_thigh', 'right_thigh'],
        'dress': ['left_shoulder', 'right_shoulder', 'waist_left', 'waist_right', 
                 'hem_left', 'hem_right', 'left_hip', 'right_hip'],
        'skirt': ['waist_left', 'waist_right', 'hem_left', 'hem_right']
    }
    
    # OpenPose 18 í‚¤í¬ì¸íŠ¸ì™€ ì˜ë¥˜ í‚¤í¬ì¸íŠ¸ ë§¤í•‘
    POSE_TO_CLOTHING = {
        'shirt': {
            5: 'left_shoulder',   # left_shoulder
            2: 'right_shoulder',  # right_shoulder  
            7: 'left_sleeve',     # left_elbow
            4: 'right_sleeve',    # right_elbow
            1: 'collar',          # neck
            11: 'hem',            # left_hip (í•˜ë‹¨)
        },
        'pants': {
            11: 'waist_left',     # left_hip
            8: 'waist_right',     # right_hip
            12: 'left_leg',       # left_knee
            9: 'right_leg',       # right_knee
            13: 'left_ankle',     # left_ankle
            10: 'right_ankle',    # right_ankle
        },
        'dress': {
            5: 'left_shoulder',   # left_shoulder
            2: 'right_shoulder',  # right_shoulder
            11: 'waist_left',     # left_hip
            8: 'waist_right',     # right_hip
            13: 'hem_left',       # left_ankle
            10: 'hem_right',      # right_ankle
        }
    }
    
    def __init__(self, model_loader, device: str, config: Dict[str, Any] = None):
        """
        Args:
            model_loader: ëª¨ë¸ ë¡œë” ì¸ìŠ¤í„´ìŠ¤
            device: ì‚¬ìš©í•  ë””ë°”ì´ìŠ¤ ('cpu', 'cuda', 'mps')
            config: ì„¤ì • ë”•ì…”ë„ˆë¦¬
        """
        self.model_loader = model_loader
        self.device = device
        self.config = config or {}
        
        # TPS ë³€í™˜ ì„¤ì •
        self.tps_config = self.config.get('tps_transform', {
            'regularization': 0.001,
            'smoothing': 0.01,
            'kernel': 'thin_plate_spline',
            'mesh_density': 15
        })
        
        # ë§¤ì¹­ ì•Œê³ ë¦¬ì¦˜ ì„¤ì •
        self.matching_config = self.config.get('matching', {
            'feature_method': 'sift',
            'keypoint_threshold': 0.02,
            'outlier_threshold': 2.0,
            'max_keypoints': 50,
            'matching_threshold': 50.0,
            'min_matching_points': 4
        })
        
        # ì„±ëŠ¥ ìµœì í™” ì„¤ì • (M3 Max)
        self.use_mps = device == 'mps' and torch.backends.mps.is_available()
        
        # ë³€í™˜ ê°ì²´ë“¤
        self.tps_solver = None
        self.tps_transformer = None
        self.mesh_warper = None
        
        self.is_initialized = False
        
        logger.info(f"ğŸ¯ ê¸°í•˜í•™ì  ë§¤ì¹­ ìŠ¤í… ì´ˆê¸°í™” - ë””ë°”ì´ìŠ¤: {device}, MPS: {self.use_mps}")
    
    async def initialize(self) -> bool:
        """ì´ˆê¸°í™”"""
        try:
            logger.info("ğŸ”„ ê¸°í•˜í•™ì  ë§¤ì¹­ ì´ˆê¸°í™” ì¤‘...")
            
            # TPS ì†”ë²„ ì´ˆê¸°í™” (ìˆ˜í•™ì ìœ¼ë¡œ ì •í™•í•œ ë²„ì „)
            self.tps_solver = TPSSolver(
                device=self.device, 
                reg_factor=self.tps_config['regularization']
            )
            
            # TPS ë³€í™˜ê¸° ì´ˆê¸°í™” (RBF ê¸°ë°˜)
            self.tps_transformer = ThinPlateSplineTransform(
                regularization=self.tps_config['regularization'],
                smoothing=self.tps_config['smoothing']
            )
            
            # ë©”ì‰¬ ì›Œí•‘ ì´ˆê¸°í™”
            self.mesh_warper = MeshBasedWarping(
                mesh_size=self.tps_config['mesh_density']
            )
            
            self.is_initialized = True
            logger.info("âœ… ê¸°í•˜í•™ì  ë§¤ì¹­ ì´ˆê¸°í™” ì™„ë£Œ")
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ ê¸°í•˜í•™ì  ë§¤ì¹­ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.is_initialized = False
            return False
    
    def process(
        self,
        person_image_tensor: torch.Tensor,
        clothing_image_tensor: torch.Tensor,
        clothing_mask: torch.Tensor,
        pose_keypoints: List[List[float]],
        parsing_result: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        ê¸°í•˜í•™ì  ë§¤ì¹­ ì²˜ë¦¬ (í†µí•© ë²„ì „)
        
        Args:
            person_image_tensor: ì‚¬ìš©ì ì´ë¯¸ì§€ í…ì„œ [1, 3, H, W]
            clothing_image_tensor: ì˜ë¥˜ ì´ë¯¸ì§€ í…ì„œ [1, 3, H, W]  
            clothing_mask: ì˜ë¥˜ ë§ˆìŠ¤í¬ í…ì„œ [1, 1, H, W]
            pose_keypoints: 18ê°œ í¬ì¦ˆ í‚¤í¬ì¸íŠ¸
            parsing_result: ì¸ì²´ íŒŒì‹± ê²°ê³¼
            
        Returns:
            ì²˜ë¦¬ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        if not self.is_initialized:
            raise RuntimeError("ê¸°í•˜í•™ì  ë§¤ì¹­ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        start_time = time.time()
        
        try:
            # 1. ì˜ë¥˜ íƒ€ì… ê²°ì •
            clothing_type = self._determine_clothing_type(parsing_result, pose_keypoints)
            
            # 2. í…ì„œë¥¼ numpy ë°°ì—´ë¡œ ë³€í™˜
            person_img = self._tensor_to_numpy(person_image_tensor)
            cloth_img = self._tensor_to_numpy(clothing_image_tensor)
            cloth_mask = self._tensor_to_numpy(clothing_mask, is_mask=True)
            
            # 3. ì‹ ì²´ í‚¤í¬ì¸íŠ¸ ì¶”ì¶œ (í¬ì¦ˆ ê¸°ë°˜)
            body_keypoints = self._extract_body_keypoints(pose_keypoints, clothing_type)
            
            # 4. ì˜ë¥˜ í‚¤í¬ì¸íŠ¸ ì¶”ì¶œ (ìœ¤ê³½ì„  ê¸°ë°˜)
            clothing_keypoints = self._extract_clothing_keypoints_from_contour(
                cloth_img, cloth_mask, clothing_type
            )
            
            # 5. í‚¤í¬ì¸íŠ¸ ë§¤ì¹­ (Hungarian ì•Œê³ ë¦¬ì¦˜ + ì§ì ‘ ë§¤ì¹­)
            matched_pairs = self._match_keypoints_advanced(body_keypoints, clothing_keypoints)
            
            # 6. TPS ë³€í™˜ ë§¤íŠ¸ë¦­ìŠ¤ ê³„ì‚°
            tps_matrix = self._calculate_tps_transform(matched_pairs)
            
            # 7. TPS ë³€í™˜ ì ìš©
            warped_cloth, warped_mask = self._apply_tps_transform(
                cloth_img, cloth_mask, matched_pairs
            )
            
            # 8. ë©”ì‰¬ ê¸°ë°˜ ì„¸ë°€ ì¡°ì •
            refined_cloth, refined_mask = self._apply_mesh_refinement(
                warped_cloth, warped_mask, matched_pairs
            )
            
            # 9. ê²°ê³¼ í’ˆì§ˆ í‰ê°€
            quality_metrics = self._evaluate_matching_quality_comprehensive(
                cloth_img, refined_cloth, matched_pairs, body_keypoints, clothing_keypoints
            )
            
            # 10. ë³€í˜• ì˜ì—­ ê³„ì‚°
            deformation_regions = self._calculate_deformation_regions(matched_pairs, clothing_type)
            
            processing_time = time.time() - start_time
            
            result = {
                "success": True,
                "warped_clothing": self._numpy_to_tensor(refined_cloth),
                "warped_mask": self._numpy_to_tensor(refined_mask, is_mask=True),
                "tps_matrix": tps_matrix,
                "matched_pairs": matched_pairs,
                "body_keypoints": body_keypoints,
                "clothing_keypoints": clothing_keypoints,
                "clothing_type": clothing_type,
                "transform_quality": quality_metrics,
                "deformation_regions": deformation_regions,
                "confidence": float(quality_metrics.get('overall_score', 0.7)),
                "processing_time": processing_time,
                "num_matched_points": len(matched_pairs),
                "transform_method": "TPS + Mesh Hybrid"
            }
            
            logger.info(f"âœ… ê¸°í•˜í•™ì  ë§¤ì¹­ ì™„ë£Œ - ì²˜ë¦¬ì‹œê°„: {processing_time:.3f}ì´ˆ, ë§¤ì¹­ í¬ì¸íŠ¸: {len(matched_pairs)}")
            
            return result
            
        except Exception as e:
            logger.error(f"âŒ ê¸°í•˜í•™ì  ë§¤ì¹­ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            raise
    
    def _determine_clothing_type(self, parsing_result: Dict[str, Any], pose_keypoints: List[List[float]]) -> str:
        """ì˜ë¥˜ íƒ€ì… ê²°ì • (í–¥ìƒëœ ë¡œì§)"""
        try:
            # íŒŒì‹± ê²°ê³¼ì—ì„œ ê°ì§€ëœ ì‹ ì²´ ë¶€ìœ„ ë¶„ì„
            detected_parts = parsing_result.get('body_parts_detected', {})
            
            # ì˜ë¥˜ ê´€ë ¨ ë¶€ìœ„ í™•ì¸
            has_upper_clothes = any(part in detected_parts for part in ['upper_clothes', 'dress', 'coat', 'top'])
            has_lower_clothes = any(part in detected_parts for part in ['pants', 'skirt', 'bottom'])
            has_dress = 'dress' in detected_parts
            
            # í¬ì¦ˆì—ì„œ ì‹ ì²´ ì˜ì—­ ë¶„ì„
            has_upper_body = len([kp for kp in pose_keypoints[:11] if len(kp) > 2 and kp[2] > 0.3]) >= 3
            has_lower_body = len([kp for kp in pose_keypoints[11:] if len(kp) > 2 and kp[2] > 0.3]) >= 2
            
            # ì˜ë¥˜ íƒ€ì… ê²°ì • ë¡œì§ (ìš°ì„ ìˆœìœ„ ê¸°ë°˜)
            if has_dress and has_upper_body and has_lower_body:
                return 'dress'
            elif has_upper_clothes and has_upper_body:
                return 'shirt'
            elif has_lower_clothes and has_lower_body:
                return 'pants'
            elif 'skirt' in detected_parts:
                return 'skirt'
            else:
                # ê¸°ë³¸ê°’: í¬ì¦ˆ ê¸°ë°˜ ì¶”ì •
                return 'shirt' if has_upper_body else 'pants'
            
        except Exception as e:
            logger.warning(f"ì˜ë¥˜ íƒ€ì… ê²°ì • ì‹¤íŒ¨: {e}")
            return 'shirt'  # ê¸°ë³¸ê°’
    
    def _tensor_to_numpy(self, tensor: torch.Tensor, is_mask: bool = False) -> np.ndarray:
        """í…ì„œë¥¼ numpy ë°°ì—´ë¡œ ë³€í™˜"""
        if tensor.dim() == 4:
            tensor = tensor.squeeze(0)
        
        if is_mask:
            # ë§ˆìŠ¤í¬ì˜ ê²½ìš° 2Dë¡œ ë³€í™˜
            if tensor.dim() == 3:
                tensor = tensor.squeeze(0)
            return (tensor.cpu().numpy() * 255).astype(np.uint8)
        else:
            # ì´ë¯¸ì§€ì˜ ê²½ìš° [3, H, W] â†’ [H, W, 3]ìœ¼ë¡œ ë³€í™˜
            if tensor.shape[0] == 3:
                tensor = tensor.permute(1, 2, 0)
            
            # 0-1 ë²”ìœ„ë¥¼ 0-255ë¡œ ë³€í™˜
            if tensor.max() <= 1.0:
                tensor = tensor * 255
            
            return tensor.cpu().numpy().astype(np.uint8)
    
    def _numpy_to_tensor(self, array: np.ndarray, is_mask: bool = False) -> torch.Tensor:
        """numpy ë°°ì—´ì„ í…ì„œë¡œ ë³€í™˜"""
        if is_mask:
            # ë§ˆìŠ¤í¬: [H, W] â†’ [1, 1, H, W]
            if array.ndim == 2:
                tensor = torch.from_numpy(array / 255.0).float()
                return tensor.unsqueeze(0).unsqueeze(0).to(self.device)
        else:
            # ì´ë¯¸ì§€: [H, W, 3] â†’ [1, 3, H, W]
            if array.ndim == 3:
                tensor = torch.from_numpy(array).permute(2, 0, 1).float() / 255.0
                return tensor.unsqueeze(0).to(self.device)
        
        return torch.from_numpy(array).to(self.device)
    
    def _extract_body_keypoints(self, pose_keypoints: List[List[float]], clothing_type: str) -> Dict[str, Tuple[float, float]]:
        """ì‹ ì²´ í‚¤í¬ì¸íŠ¸ ì¶”ì¶œ (í¬ì¦ˆ ê¸°ë°˜)"""
        body_keypoints = {}
        
        try:
            # ì˜ë¥˜ íƒ€ì…ì— ë”°ë¥¸ ê´€ë ¨ í‚¤í¬ì¸íŠ¸ ì¶”ì¶œ
            if clothing_type in self.POSE_TO_CLOTHING:
                for pose_idx, clothing_name in self.POSE_TO_CLOTHING[clothing_type].items():
                    if pose_idx < len(pose_keypoints):
                        kp = pose_keypoints[pose_idx]
                        if len(kp) > 2 and kp[2] > 0.3:  # ì‹ ë¢°ë„ ì²´í¬
                            body_keypoints[clothing_name] = (kp[0], kp[1])
            
            # ì¶”ê°€ ê³„ì‚°ëœ í¬ì¸íŠ¸ë“¤
            if clothing_type == 'shirt':
                # ê²¨ë“œë‘ì´ ê³„ì‚°
                if 5 < len(pose_keypoints) and 7 < len(pose_keypoints):
                    left_shoulder = pose_keypoints[5]
                    left_elbow = pose_keypoints[7]
                    if len(left_shoulder) > 2 and len(left_elbow) > 2:
                        if left_shoulder[2] > 0.3 and left_elbow[2] > 0.3:
                            armpit_x = left_shoulder[0] + (left_elbow[0] - left_shoulder[0]) * 0.3
                            armpit_y = left_shoulder[1] + (left_elbow[1] - left_shoulder[1]) * 0.3
                            body_keypoints['left_armpit'] = (armpit_x, armpit_y)
                
                if 2 < len(pose_keypoints) and 4 < len(pose_keypoints):
                    right_shoulder = pose_keypoints[2]
                    right_elbow = pose_keypoints[4]
                    if len(right_shoulder) > 2 and len(right_elbow) > 2:
                        if right_shoulder[2] > 0.3 and right_elbow[2] > 0.3:
                            armpit_x = right_shoulder[0] + (right_elbow[0] - right_shoulder[0]) * 0.3
                            armpit_y = right_shoulder[1] + (right_elbow[1] - right_shoulder[1]) * 0.3
                            body_keypoints['right_armpit'] = (armpit_x, armpit_y)
            
            elif clothing_type == 'pants':
                # í—ˆë²…ì§€ ì¤‘ê°„ì  ê³„ì‚°
                if 11 < len(pose_keypoints) and 12 < len(pose_keypoints):
                    left_hip = pose_keypoints[11]
                    left_knee = pose_keypoints[12]
                    if len(left_hip) > 2 and len(left_knee) > 2:
                        if left_hip[2] > 0.3 and left_knee[2] > 0.3:
                            thigh_x = (left_hip[0] + left_knee[0]) / 2
                            thigh_y = (left_hip[1] + left_knee[1]) / 2
                            body_keypoints['left_thigh'] = (thigh_x, thigh_y)
                
                if 8 < len(pose_keypoints) and 9 < len(pose_keypoints):
                    right_hip = pose_keypoints[8]
                    right_knee = pose_keypoints[9]
                    if len(right_hip) > 2 and len(right_knee) > 2:
                        if right_hip[2] > 0.3 and right_knee[2] > 0.3:
                            thigh_x = (right_hip[0] + right_knee[0]) / 2
                            thigh_y = (right_hip[1] + right_knee[1]) / 2
                            body_keypoints['right_thigh'] = (thigh_x, thigh_y)
            
        except Exception as e:
            logger.warning(f"ì‹ ì²´ í‚¤í¬ì¸íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
        
        return body_keypoints
    
    def _extract_clothing_keypoints_from_contour(
        self, 
        cloth_img: np.ndarray, 
        cloth_mask: np.ndarray, 
        clothing_type: str
    ) -> Dict[str, Tuple[float, float]]:
        """ìœ¤ê³½ì„  ê¸°ë°˜ ì˜ë¥˜ í‚¤í¬ì¸íŠ¸ ì¶”ì¶œ (í–¥ìƒëœ ë²„ì „)"""
        
        clothing_keypoints = {}
        
        try:
            # ìœ¤ê³½ì„  ì°¾ê¸°
            contours, _ = cv2.findContours(cloth_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            
            if not contours:
                return self._generate_default_keypoints(cloth_img.shape[1], cloth_img.shape[0], clothing_type)
            
            # ê°€ì¥ í° ìœ¤ê³½ì„  ì„ íƒ
            main_contour = max(contours, key=cv2.contourArea)
            
            # ë°”ìš´ë”© ë°•ìŠ¤
            x, y, w, h = cv2.boundingRect(main_contour)
            
            # ì˜ë¥˜ íƒ€ì…ë³„ í‚¤í¬ì¸íŠ¸ ì¶”ì¶œ
            if clothing_type == 'shirt':
                clothing_keypoints = self._extract_shirt_keypoints_detailed(main_contour, x, y, w, h)
            elif clothing_type == 'pants':
                clothing_keypoints = self._extract_pants_keypoints_detailed(main_contour, x, y, w, h)
            elif clothing_type == 'dress':
                clothing_keypoints = self._extract_dress_keypoints_detailed(main_contour, x, y, w, h)
            elif clothing_type == 'skirt':
                clothing_keypoints = self._extract_skirt_keypoints_detailed(main_contour, x, y, w, h)
            else:
                clothing_keypoints = self._generate_default_keypoints(w, h, clothing_type)
            
        except Exception as e:
            logger.warning(f"ì˜ë¥˜ í‚¤í¬ì¸íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            # ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ í‚¤í¬ì¸íŠ¸ ìƒì„±
            h, w = cloth_img.shape[:2]
            clothing_keypoints = self._generate_default_keypoints(w, h, clothing_type)
        
        return clothing_keypoints
    
    def _extract_shirt_keypoints_detailed(
        self, 
        contour: np.ndarray, 
        x: int, y: int, w: int, h: int
    ) -> Dict[str, Tuple[float, float]]:
        """ìƒì˜ í‚¤í¬ì¸íŠ¸ ìƒì„¸ ì¶”ì¶œ"""
        keypoints = {}
        
        try:
            # ì–´ê¹¨ ë¼ì¸ (ìƒë‹¨ 15% ì§€ì )
            shoulder_y = y + int(h * 0.15)
            left_shoulder = self._find_contour_point_at_height(contour, shoulder_y, 'left')
            right_shoulder = self._find_contour_point_at_height(contour, shoulder_y, 'right')
            
            keypoints['left_shoulder'] = (left_shoulder[0], left_shoulder[1])
            keypoints['right_shoulder'] = (right_shoulder[0], right_shoulder[1])
            
            # ê²¨ë“œë‘ì´ (ì–´ê¹¨ì—ì„œ 25% ì•„ë˜)
            armpit_y = y + int(h * 0.25)
            left_armpit = self._find_contour_point_at_height(contour, armpit_y, 'left')
            right_armpit = self._find_contour_point_at_height(contour, armpit_y, 'right')
            
            keypoints['left_armpit'] = (left_armpit[0], left_armpit[1])
            keypoints['right_armpit'] = (right_armpit[0], right_armpit[1])
            
            # ì†Œë§¤ ë (ì¢Œìš° ê·¹ë‹¨ì )
            leftmost = tuple(contour[contour[:, :, 0].argmin()][0])
            rightmost = tuple(contour[contour[:, :, 0].argmax()][0])
            
            keypoints['left_sleeve'] = leftmost
            keypoints['right_sleeve'] = rightmost
            
            # ëª© ë¼ì¸ (ìµœìƒë‹¨ ì¤‘ì•™)
            top_points = contour[contour[:, :, 1] < y + h * 0.1]
            if len(top_points) > 0:
                neck_center = np.mean(top_points, axis=0)
                keypoints['collar'] = (int(neck_center[0][0]), int(neck_center[0][1]))
            else:
                keypoints['collar'] = (x + w // 2, y)
            
            # í•˜ë‹¨ (hem)
            bottom_y = y + int(h * 0.9)
            hem_points = contour[np.abs(contour[:, :, 1] - bottom_y) < h * 0.1]
            if len(hem_points) > 0:
                hem_center = np.mean(hem_points, axis=0)
                keypoints['hem'] = (int(hem_center[0][0]), int(hem_center[0][1]))
            else:
                keypoints['hem'] = (x + w // 2, y + h)
            
        except Exception as e:
            logger.warning(f"ìƒì˜ í‚¤í¬ì¸íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
        
        return keypoints
    
    def _extract_pants_keypoints_detailed(
        self, 
        contour: np.ndarray, 
        x: int, y: int, w: int, h: int
    ) -> Dict[str, Tuple[float, float]]:
        """ë°”ì§€ í‚¤í¬ì¸íŠ¸ ìƒì„¸ ì¶”ì¶œ"""
        keypoints = {}
        
        try:
            # í—ˆë¦¬ ë¼ì¸ (ìƒë‹¨ 10%)
            waist_y = y + int(h * 0.1)
            left_waist = self._find_contour_point_at_height(contour, waist_y, 'left')
            right_waist = self._find_contour_point_at_height(contour, waist_y, 'right')
            
            keypoints['waist_left'] = (left_waist[0], left_waist[1])
            keypoints['waist_right'] = (right_waist[0], right_waist[1])
            
            # í—ˆë²…ì§€ (ìƒë‹¨ 40%)
            thigh_y = y + int(h * 0.4)
            left_thigh = self._find_contour_point_at_height(contour, thigh_y, 'left')
            right_thigh = self._find_contour_point_at_height(contour, thigh_y, 'right')
            
            keypoints['left_thigh'] = (left_thigh[0], left_thigh[1])
            keypoints['right_thigh'] = (right_thigh[0], right_thigh[1])
            
            # ë¬´ë¦ (ì¤‘ê°„ 60%)
            knee_y = y + int(h * 0.6)
            left_knee = self._find_contour_point_at_height(contour, knee_y, 'left')
            right_knee = self._find_contour_point_at_height(contour, knee_y, 'right')
            
            keypoints['left_leg'] = (left_knee[0], left_knee[1])
            keypoints['right_leg'] = (right_knee[0], right_knee[1])
            
            # ë°œëª© (í•˜ë‹¨ 90%)
            ankle_y = y + int(h * 0.9)
            left_ankle = self._find_contour_point_at_height(contour, ankle_y, 'left')
            right_ankle = self._find_contour_point_at_height(contour, ankle_y, 'right')
            
            keypoints['left_ankle'] = (left_ankle[0], left_ankle[1])
            keypoints['right_ankle'] = (right_ankle[0], right_ankle[1])
            
        except Exception as e:
            logger.warning(f"ë°”ì§€ í‚¤í¬ì¸íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
        
        return keypoints
    
    def _extract_dress_keypoints_detailed(
        self, 
        contour: np.ndarray, 
        x: int, y: int, w: int, h: int
    ) -> Dict[str, Tuple[float, float]]:
        """ì›í”¼ìŠ¤ í‚¤í¬ì¸íŠ¸ ìƒì„¸ ì¶”ì¶œ"""
        keypoints = {}
        
        try:
            # ìƒì˜ ë¶€ë¶„ (ìƒë‹¨ 50%)
            shirt_keypoints = self._extract_shirt_keypoints_detailed(contour, x, y, w, int(h * 0.5))
            keypoints.update(shirt_keypoints)
            
            # í—ˆë¦¬ ë¼ì¸ (ì¤‘ê°„ 40%)
            waist_y = y + int(h * 0.4)
            left_waist = self._find_contour_point_at_height(contour, waist_y, 'left')
            right_waist = self._find_contour_point_at_height(contour, waist_y, 'right')
            
            keypoints['waist_left'] = (left_waist[0], left_waist[1])
            keypoints['waist_right'] = (right_waist[0], right_waist[1])
            
            # ì—‰ë©ì´ ë¼ì¸ (ì¤‘ê°„ 60%)
            hip_y = y + int(h * 0.6)
            left_hip = self._find_contour_point_at_height(contour, hip_y, 'left')
            right_hip = self._find_contour_point_at_height(contour, hip_y, 'right')
            
            keypoints['left_hip'] = (left_hip[0], left_hip[1])
            keypoints['right_hip'] = (right_hip[0], right_hip[1])
            
            # ë°‘ë‹¨ (í•˜ë‹¨ 95%)
            hem_y = y + int(h * 0.95)
            left_hem = self._find_contour_point_at_height(contour, hem_y, 'left')
            right_hem = self._find_contour_point_at_height(contour, hem_y, 'right')
            
            keypoints['hem_left'] = (left_hem[0], left_hem[1])
            keypoints['hem_right'] = (right_hem[0], right_hem[1])
            
        except Exception as e:
            logger.warning(f"ì›í”¼ìŠ¤ í‚¤í¬ì¸íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
        
        return keypoints
    
    def _extract_skirt_keypoints_detailed(
        self, 
        contour: np.ndarray, 
        x: int, y: int, w: int, h: int
    ) -> Dict[str, Tuple[float, float]]:
        """ìŠ¤ì»¤íŠ¸ í‚¤í¬ì¸íŠ¸ ìƒì„¸ ì¶”ì¶œ"""
        keypoints = {}
        
        try:
            # í—ˆë¦¬ ë¼ì¸ (ìƒë‹¨ 10%)
            waist_y = y + int(h * 0.1)
            left_waist = self._find_contour_point_at_height(contour, waist_y, 'left')
            right_waist = self._find_contour_point_at_height(contour, waist_y, 'right')
            
            keypoints['waist_left'] = (left_waist[0], left_waist[1])
            keypoints['waist_right'] = (right_waist[0], right_waist[1])
            
            # ë°‘ë‹¨ (í•˜ë‹¨ 95%)
            hem_y = y + int(h * 0.95)
            left_hem = self._find_contour_point_at_height(contour, hem_y, 'left')
            right_hem = self._find_contour_point_at_height(contour, hem_y, 'right')
            
            keypoints['hem_left'] = (left_hem[0], left_hem[1])
            keypoints['hem_right'] = (right_hem[0], right_hem[1])
            
        except Exception as e:
            logger.warning(f"ìŠ¤ì»¤íŠ¸ í‚¤í¬ì¸íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
        
        return keypoints
    
    def _find_contour_point_at_height(
        self, 
        contour: np.ndarray, 
        y: int, 
        side: str
    ) -> List[int]:
        """íŠ¹ì • ë†’ì´ì—ì„œ ìœ¤ê³½ì„ ì˜ ì¢Œ/ìš° ëì  ì°¾ê¸°"""
        tolerance = 15
        points_at_height = []
        
        for point in contour:
            if abs(point[0][1] - y) < tolerance:
                points_at_height.append(point[0])
        
        if not points_at_height:
            # ê°€ì¥ ê°€ê¹Œìš´ í¬ì¸íŠ¸ ì°¾ê¸°
            distances = [abs(point[0][1] - y) for point in contour]
            nearest_idx = np.argmin(distances)
            return contour[nearest_idx][0].tolist()
        
        # ì¢Œì¸¡ ë˜ëŠ” ìš°ì¸¡ ê·¹ë‹¨ì  ì„ íƒ
        if side == 'left':
            return min(points_at_height, key=lambda p: p[0]).tolist()
        else:
            return max(points_at_height, key=lambda p: p[0]).tolist()
    
    def _generate_default_keypoints(self, w: int, h: int, clothing_type: str) -> Dict[str, Tuple[float, float]]:
        """ê¸°ë³¸ í‚¤í¬ì¸íŠ¸ ìƒì„±"""
        keypoints = {}
        
        if clothing_type == 'shirt':
            keypoints = {
                'left_shoulder': (w * 0.2, h * 0.15),
                'right_shoulder': (w * 0.8, h * 0.15),
                'left_sleeve': (w * 0.05, h * 0.4),
                'right_sleeve': (w * 0.95, h * 0.4),
                'left_armpit': (w * 0.25, h * 0.25),
                'right_armpit': (w * 0.75, h * 0.25),
                'collar': (w * 0.5, h * 0.05),
                'hem': (w * 0.5, h * 0.9)
            }
        elif clothing_type == 'pants':
            keypoints = {
                'waist_left': (w * 0.3, h * 0.1),
                'waist_right': (w * 0.7, h * 0.1),
                'left_thigh': (w * 0.35, h * 0.4),
                'right_thigh': (w * 0.65, h * 0.4),
                'left_leg': (w * 0.35, h * 0.6),
                'right_leg': (w * 0.65, h * 0.6),
                'left_ankle': (w * 0.35, h * 0.9),
                'right_ankle': (w * 0.65, h * 0.9)
            }
        elif clothing_type == 'dress':
            keypoints = {
                'left_shoulder': (w * 0.2, h * 0.1),
                'right_shoulder': (w * 0.8, h * 0.1),
                'waist_left': (w * 0.25, h * 0.4),
                'waist_right': (w * 0.75, h * 0.4),
                'left_hip': (w * 0.3, h * 0.6),
                'right_hip': (w * 0.7, h * 0.6),
                'hem_left': (w * 0.3, h * 0.95),
                'hem_right': (w * 0.7, h * 0.95)
            }
        elif clothing_type == 'skirt':
            keypoints = {
                'waist_left': (w * 0.25, h * 0.1),
                'waist_right': (w * 0.75, h * 0.1),
                'hem_left': (w * 0.2, h * 0.95),
                'hem_right': (w * 0.8, h * 0.95)
            }
        
        return keypoints
    
    def _match_keypoints_advanced(
        self,
        body_keypoints: Dict[str, Tuple[float, float]],
        clothing_keypoints: Dict[str, Tuple[float, float]]
    ) -> List[Tuple[Tuple[float, float], Tuple[float, float], str]]:
        """ê³ ê¸‰ í‚¤í¬ì¸íŠ¸ ë§¤ì¹­ (ì§ì ‘ ë§¤ì¹­ + Hungarian ì•Œê³ ë¦¬ì¦˜)"""
        
        matched_pairs = []
        
        try:
            # 1. ë™ì¼í•œ ì´ë¦„ì˜ í‚¤í¬ì¸íŠ¸ ì§ì ‘ ë§¤ì¹­
            common_names = set(body_keypoints.keys()) & set(clothing_keypoints.keys())
            used_body_names = set()
            used_clothing_names = set()
            
            for name in common_names:
                body_point = body_keypoints[name]
                clothing_point = clothing_keypoints[name]
                
                # ê±°ë¦¬ ê²€ì‚¬
                distance = math.sqrt((body_point[0] - clothing_point[0])**2 + (body_point[1] - clothing_point[1])**2)
                
                # ë§¤ì¹­ í—ˆìš© (ê±°ë¦¬ ê¸°ë°˜)
                if distance < self.matching_config['matching_threshold'] * 2:  # ê´€ëŒ€í•œ ì„ê³„ê°’
                    matched_pairs.append((body_point, clothing_point, name))
                    used_body_names.add(name)
                    used_clothing_names.add(name)
            
            # 2. ë‚¨ì€ í‚¤í¬ì¸íŠ¸ë“¤ì— ëŒ€í•´ Hungarian ì•Œê³ ë¦¬ì¦˜ ì ìš©
            available_body = {k: v for k, v in body_keypoints.items() if k not in used_body_names}
            available_clothing = {k: v for k, v in clothing_keypoints.items() if k not in used_clothing_names}
            
            if available_body and available_clothing:
                additional_pairs = self._find_additional_matches_hungarian(
                    available_body, available_clothing
                )
                matched_pairs.extend(additional_pairs)
            
            # 3. ìµœì†Œ ë§¤ì¹­ ê°œìˆ˜ í™•ë³´
            if len(matched_pairs) < self.matching_config['min_matching_points']:
                extra_pairs = self._generate_additional_correspondences(
                    body_keypoints, clothing_keypoints, matched_pairs
                )
                matched_pairs.extend(extra_pairs)
            
        except Exception as e:
            logger.warning(f"í‚¤í¬ì¸íŠ¸ ë§¤ì¹­ ì‹¤íŒ¨: {e}")
        
        logger.info(f"ë§¤ì¹­ëœ í‚¤í¬ì¸íŠ¸ ìŒ: {len(matched_pairs)}ê°œ")
        return matched_pairs
    
    def _find_additional_matches_hungarian(
        self,
        available_body: Dict[str, Tuple[float, float]],
        available_clothing: Dict[str, Tuple[float, float]]
    ) -> List[Tuple[Tuple[float, float], Tuple[float, float], str]]:
        """Hungarian ì•Œê³ ë¦¬ì¦˜ì„ ì‚¬ìš©í•œ ì¶”ê°€ ë§¤ì¹­"""
        
        additional_pairs = []
        
        try:
            if not available_body or not available_clothing:
                return additional_pairs
            
            # ê±°ë¦¬ ê¸°ë°˜ ë§¤ì¹­
            body_points = list(available_body.values())
            clothing_points = list(available_clothing.values())
            body_names = list(available_body.keys())
            clothing_names = list(available_clothing.keys())
            
            # ê±°ë¦¬ í–‰ë ¬ ê³„ì‚°
            distances = cdist(body_points, clothing_points)
            
            # Hungarian ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ ìµœì  í• ë‹¹
            row_indices, col_indices = linear_sum_assignment(distances)
            
            for i, j in zip(row_indices, col_indices):
                if distances[i, j] < self.matching_config['matching_threshold'] * 2:
                    body_point = body_points[i]
                    clothing_point = clothing_points[j]
                    match_name = f"{body_names[i]}_to_{clothing_names[j]}"
                    additional_pairs.append((body_point, clothing_point, match_name))
            
        except Exception as e:
            logger.warning(f"Hungarian ë§¤ì¹­ ì‹¤íŒ¨: {e}")
        
        return additional_pairs
    
    def _generate_additional_correspondences(
        self,
        body_keypoints: Dict[str, Tuple[float, float]],
        clothing_keypoints: Dict[str, Tuple[float, float]],
        existing_pairs: List
    ) -> List[Tuple[Tuple[float, float], Tuple[float, float], str]]:
        """ì¶”ê°€ ëŒ€ì‘ì  ìƒì„±"""
        
        additional_pairs = []
        
        try:
            # ì˜ë¥˜ ë°”ìš´ë”© ë°•ìŠ¤ì˜ ëª¨ì„œë¦¬ì ë“¤ ì¶”ê°€
            if clothing_keypoints:
                cloth_xs = [kp[0] for kp in clothing_keypoints.values()]
                cloth_ys = [kp[1] for kp in clothing_keypoints.values()]
                
                cloth_min_x, cloth_max_x = min(cloth_xs), max(cloth_xs)
                cloth_min_y, cloth_max_y = min(cloth_ys), max(cloth_ys)
                
                # ì˜ë¥˜ ì¤‘ì‹¬ì 
                cloth_center = (
                    (cloth_min_x + cloth_max_x) / 2,
                    (cloth_min_y + cloth_max_y) / 2
                )
                
                # ì‹ ì²´ ì¤‘ì‹¬ì  ê³„ì‚°
                if body_keypoints:
                    body_xs = [kp[0] for kp in body_keypoints.values()]
                    body_ys = [kp[1] for kp in body_keypoints.values()]
                    
                    body_center = (
                        sum(body_xs) / len(body_xs),
                        sum(body_ys) / len(body_ys)
                    )
                    
                    additional_pairs.append((body_center, cloth_center, "center_correspondence"))
            
        except Exception as e:
            logger.warning(f"ì¶”ê°€ ëŒ€ì‘ì  ìƒì„± ì‹¤íŒ¨: {e}")
        
        return additional_pairs
    
    def _calculate_tps_transform(
        self, 
        matched_pairs: List[Tuple[Tuple[float, float], Tuple[float, float], str]]
    ) -> Optional[np.ndarray]:
        """TPS ë³€í™˜ ë§¤íŠ¸ë¦­ìŠ¤ ê³„ì‚°"""
        if len(matched_pairs) < self.matching_config['min_matching_points']:
            logger.warning(f"ë§¤ì¹­ í¬ì¸íŠ¸ ë¶€ì¡±: {len(matched_pairs)} < {self.matching_config['min_matching_points']}")
            return None
        
        try:
            # ì†ŒìŠ¤ í¬ì¸íŠ¸ (ì˜ë¥˜) ë° íƒ€ê²Ÿ í¬ì¸íŠ¸ (ì‹ ì²´) ì¶”ì¶œ
            source_points = np.array([pair[1] for pair in matched_pairs], dtype=np.float32)  # ì˜ë¥˜
            target_points = np.array([pair[0] for pair in matched_pairs], dtype=np.float32)  # ì‹ ì²´
            
            # TPS ì†”ë²„ë¡œ ë³€í™˜ ê³„ì‚°
            tps_matrix = self.tps_solver.solve(source_points, target_points)
            
            return tps_matrix
            
        except Exception as e:
            logger.error(f"TPS ë³€í™˜ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return None
    
    def _apply_tps_transform(
        self,
        cloth_img: np.ndarray,
        cloth_mask: np.ndarray,
        matched_pairs: List[Tuple[Tuple[float, float], Tuple[float, float], str]]
    ) -> Tuple[np.ndarray, np.ndarray]:
        """TPS ë³€í™˜ ì ìš©"""
        
        if len(matched_pairs) < 3:
            logger.warning("ë§¤ì¹­ í¬ì¸íŠ¸ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤. ì›ë³¸ì„ ë°˜í™˜í•©ë‹ˆë‹¤.")
            return cloth_img, cloth_mask
        
        try:
            # ì†ŒìŠ¤ì™€ íƒ€ê²Ÿ í¬ì¸íŠ¸ ë¶„ë¦¬
            source_points = np.array([pair[1] for pair in matched_pairs], dtype=np.float32)
            target_points = np.array([pair[0] for pair in matched_pairs], dtype=np.float32)
            
            # TPS ë³€í™˜ê¸°ì— í•™ìŠµ
            self.tps_transformer.fit(source_points, target_points)
            
            # ì´ë¯¸ì§€ ì›Œí•‘
            warped_cloth = self.tps_transformer.transform_image(cloth_img)
            warped_mask = self.tps_transformer.transform_image(cloth_mask)
            
            # ë§ˆìŠ¤í¬ ì´ì§„í™”
            if len(warped_mask.shape) == 3:
                warped_mask = cv2.cvtColor(warped_mask, cv2.COLOR_BGR2GRAY)
            warped_mask = (warped_mask > 128).astype(np.uint8) * 255
            
            return warped_cloth, warped_mask
            
        except Exception as e:
            logger.error(f"TPS ë³€í™˜ ì ìš© ì‹¤íŒ¨: {e}")
            return cloth_img, cloth_mask
    
    def _apply_mesh_refinement(
        self,
        warped_cloth: np.ndarray,
        warped_mask: np.ndarray,
        matched_pairs: List[Tuple[Tuple[float, float], Tuple[float, float], str]]
    ) -> Tuple[np.ndarray, np.ndarray]:
        """ë©”ì‰¬ ê¸°ë°˜ ì„¸ë°€ ì¡°ì •"""
        
        try:
            # ë©”ì‰¬ ìƒì„± ë° ì„¸ë°€ ì¡°ì •
            refined_cloth = self.mesh_warper.refine_warping(
                warped_cloth, warped_mask, matched_pairs
            )
            
            # ë§ˆìŠ¤í¬ë„ ë™ì¼í•˜ê²Œ ì •ì œ
            refined_mask = self.mesh_warper.refine_warping(
                warped_mask, warped_mask, matched_pairs
            )
            
            return refined_cloth, refined_mask
            
        except Exception as e:
            logger.warning(f"ë©”ì‰¬ ì •ì œ ì‹¤íŒ¨: {e}")
            return warped_cloth, warped_mask
    
    def _evaluate_matching_quality_comprehensive(
        self,
        original_cloth: np.ndarray,
        warped_cloth: np.ndarray,
        matched_pairs: List,
        body_keypoints: Dict,
        clothing_keypoints: Dict
    ) -> Dict[str, float]:
        """ì¢…í•©ì ì¸ ë§¤ì¹­ í’ˆì§ˆ í‰ê°€"""
        
        metrics = {}
        
        try:
            # 1. í‚¤í¬ì¸íŠ¸ ë§¤ì¹­ ì •í™•ë„
            num_matched = len(matched_pairs)
            total_possible = min(len(body_keypoints), len(clothing_keypoints))
            
            metrics['keypoint_count'] = num_matched
            metrics['matching_ratio'] = num_matched / max(1, total_possible)
            metrics['keypoint_density'] = num_matched / max(original_cloth.shape[:2])
            
            # 2. í‰ê·  ë§¤ì¹­ ê±°ë¦¬
            if matched_pairs:
                distances = []
                for body_point, clothing_point, _ in matched_pairs:
                    dist = math.sqrt((body_point[0] - clothing_point[0])**2 + (body_point[1] - clothing_point[1])**2)
                    distances.append(dist)
                
                metrics['average_distance'] = np.mean(distances)
                metrics['max_distance'] = np.max(distances)
                metrics['distance_std'] = np.std(distances)
                
                # ê±°ë¦¬ ê¸°ë°˜ í’ˆì§ˆ ì ìˆ˜
                normalized_distance = min(1.0, metrics['average_distance'] / self.matching_config['matching_threshold'])
                metrics['distance_score'] = 1.0 - normalized_distance
            else:
                metrics['average_distance'] = float('inf')
                metrics['distance_score'] = 0.0
            
            # 3. ë³€í˜• ì¼ê´€ì„± (ì¸ì ‘ í‚¤í¬ì¸íŠ¸ ê°„ ê±°ë¦¬ ë¹„ìœ¨)
            if len(matched_pairs) >= 2:
                source_distances = []
                target_distances = []
                
                for i in range(len(matched_pairs)):
                    for j in range(i+1, len(matched_pairs)):
                        src_dist = np.linalg.norm(np.array(matched_pairs[i][1]) - np.array(matched_pairs[j][1]))
                        tgt_dist = np.linalg.norm(np.array(matched_pairs[i][0]) - np.array(matched_pairs[j][0]))
                        
                        if src_dist > 0:
                            source_distances.append(src_dist)
                            target_distances.append(tgt_dist)
                
                if source_distances:
                    distance_ratios = np.array(target_distances) / np.array(source_distances)
                    metrics['deformation_consistency'] = 1.0 - min(1.0, np.std(distance_ratios))
                else:
                    metrics['deformation_consistency'] = 0.0
            else:
                metrics['deformation_consistency'] = 0.0
            
            # 4. ì´ë¯¸ì§€ í’ˆì§ˆ (íˆìŠ¤í† ê·¸ë¨ ìœ ì‚¬ë„)
            metrics['transform_quality'] = self._calculate_image_similarity(original_cloth, warped_cloth)
            
            # 5. ì „ì²´ í’ˆì§ˆ ì ìˆ˜ (ê°€ì¤‘í‰ê· )
            overall_score = (
                metrics['matching_ratio'] * 0.3 +
                metrics.get('distance_score', 0) * 0.3 +
                metrics['deformation_consistency'] * 0.2 +
                metrics['transform_quality'] * 0.2
            )
            metrics['overall_score'] = min(1.0, max(0.0, overall_score))
            
            # 6. ì‹ ë¢°ë„ ë ˆë²¨
            if metrics['overall_score'] > 0.8:
                metrics['confidence_level'] = 'high'
            elif metrics['overall_score'] > 0.6:
                metrics['confidence_level'] = 'medium'
            else:
                metrics['confidence_level'] = 'low'
            
        except Exception as e:
            logger.warning(f"ë§¤ì¹­ í’ˆì§ˆ í‰ê°€ ì‹¤íŒ¨: {e}")
            metrics = {'overall_score': 0.5, 'confidence_level': 'medium'}
        
        return metrics
    
    def _calculate_image_similarity(self, img1: np.ndarray, img2: np.ndarray) -> float:
        """ì´ë¯¸ì§€ ìœ ì‚¬ë„ ê³„ì‚°"""
        try:
            # í¬ê¸° ë§ì¶”ê¸°
            if img1.shape != img2.shape:
                img2 = cv2.resize(img2, (img1.shape[1], img1.shape[0]))
            
            # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜
            if len(img1.shape) == 3:
                img1_gray = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)
            else:
                img1_gray = img1
                
            if len(img2.shape) == 3:
                img2_gray = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)
            else:
                img2_gray = img2
            
            # íˆìŠ¤í† ê·¸ë¨ ë¹„êµ
            hist1 = cv2.calcHist([img1_gray], [0], None, [256], [0, 256])
            hist2 = cv2.calcHist([img2_gray], [0], None, [256], [0, 256])
            
            # ì½”ì‚¬ì¸ ìœ ì‚¬ë„
            correlation = cv2.compareHist(hist1, hist2, cv2.HISTCMP_CORREL)
            
            return max(0.0, correlation)
            
        except Exception:
            return 0.5  # ê¸°ë³¸ê°’
    
    def _calculate_deformation_regions(
        self, 
        matched_pairs: List, 
        clothing_type: str
    ) -> Dict[str, Any]:
        """ë³€í˜• ì˜ì—­ ê³„ì‚° (í–¥ìƒëœ ë²„ì „)"""
        regions = {}
        
        try:
            if not matched_pairs:
                return regions
            
            # ë³€í˜• ë²¡í„° ê³„ì‚°
            deformation_vectors = []
            for body_point, clothing_point, name in matched_pairs:
                vector = (body_point[0] - clothing_point[0], body_point[1] - clothing_point[1])
                deformation_vectors.append({
                    'name': name,
                    'vector': vector,
                    'magnitude': math.sqrt(vector[0]**2 + vector[1]**2),
                    'angle': math.atan2(vector[1], vector[0])
                })
            
            regions['deformation_vectors'] = deformation_vectors
            
            # í†µê³„ ì •ë³´
            magnitudes = [v['magnitude'] for v in deformation_vectors]
            regions['average_deformation'] = np.mean(magnitudes)
            regions['max_deformation'] = np.max(magnitudes)
            regions['min_deformation'] = np.min(magnitudes)
            regions['deformation_variance'] = np.var(magnitudes)
            
            # ì£¼ìš” ë³€í˜• ë°©í–¥
            angles = [v['angle'] for v in deformation_vectors]
            regions['primary_direction'] = np.mean(angles)
            regions['direction_consistency'] = 1.0 - (np.std(angles) / np.pi)
            
            # ì˜ë¥˜ë³„ íŠ¹í™” ë¶„ì„
            if clothing_type == 'shirt':
                regions['sleeve_analysis'] = self._analyze_sleeve_deformation(deformation_vectors)
                regions['torso_analysis'] = self._analyze_torso_deformation(deformation_vectors)
            elif clothing_type == 'pants':
                regions['waist_analysis'] = self._analyze_waist_deformation(deformation_vectors)
                regions['leg_analysis'] = self._analyze_leg_deformation(deformation_vectors)
            elif clothing_type == 'dress':
                regions['upper_analysis'] = self._analyze_torso_deformation(deformation_vectors)
                regions['lower_analysis'] = self._analyze_leg_deformation(deformation_vectors)
            
        except Exception as e:
            logger.warning(f"ë³€í˜• ì˜ì—­ ê³„ì‚° ì‹¤íŒ¨: {e}")
        
        return regions
    
    def _analyze_sleeve_deformation(self, vectors: List[Dict]) -> Dict[str, float]:
        """ì†Œë§¤ ë³€í˜• ë¶„ì„"""
        sleeve_vectors = [v for v in vectors if 'sleeve' in v['name'].lower() or 'armpit' in v['name'].lower()]
        if not sleeve_vectors:
            return {'magnitude': 0.0, 'asymmetry': 0.0, 'consistency': 1.0}
        
        magnitudes = [v['magnitude'] for v in sleeve_vectors]
        angles = [v['angle'] for v in sleeve_vectors]
        
        return {
            'magnitude': np.mean(magnitudes),
            'asymmetry': np.std(magnitudes) if len(magnitudes) > 1 else 0.0,
            'consistency': 1.0 - (np.std(angles) / np.pi) if len(angles) > 1 else 1.0
        }
    
    def _analyze_torso_deformation(self, vectors: List[Dict]) -> Dict[str, float]:
        """ëª¸í†µ ë³€í˜• ë¶„ì„"""
        torso_keywords = ['shoulder', 'collar', 'hem', 'chest']
        torso_vectors = [v for v in vectors if any(keyword in v['name'].lower() for keyword in torso_keywords)]
        
        if not torso_vectors:
            return {'magnitude': 0.0, 'uniformity': 1.0, 'stability': 1.0}
        
        magnitudes = [v['magnitude'] for v in torso_vectors]
        angles = [v['angle'] for v in torso_vectors]
        
        return {
            'magnitude': np.mean(magnitudes),
            'uniformity': 1.0 - (np.std(magnitudes) / np.mean(magnitudes)) if np.mean(magnitudes) > 0 else 1.0,
            'stability': 1.0 - (np.std(angles) / np.pi) if len(angles) > 1 else 1.0
        }
    
    def _analyze_waist_deformation(self, vectors: List[Dict]) -> Dict[str, float]:
        """í—ˆë¦¬ ë³€í˜• ë¶„ì„"""
        waist_vectors = [v for v in vectors if 'waist' in v['name'].lower()]
        if not waist_vectors:
            return {'magnitude': 0.0, 'symmetry': 1.0, 'fit_quality': 1.0}
        
        magnitudes = [v['magnitude'] for v in waist_vectors]
        
        return {
            'magnitude': np.mean(magnitudes),
            'symmetry': 1.0 - (np.std(magnitudes) / np.mean(magnitudes)) if np.mean(magnitudes) > 0 else 1.0,
            'fit_quality': 1.0 / (1.0 + np.mean(magnitudes) / 50.0)  # ë³€í˜•ì´ ì ì„ìˆ˜ë¡ ì¢‹ì€ í•
        }
    
    def _analyze_leg_deformation(self, vectors: List[Dict]) -> Dict[str, float]:
        """ë‹¤ë¦¬ ë³€í˜• ë¶„ì„"""
        leg_keywords = ['leg', 'ankle', 'thigh', 'knee']
        leg_vectors = [v for v in vectors if any(keyword in v['name'].lower() for keyword in leg_keywords)]
        
        if not leg_vectors:
            return {'magnitude': 0.0, 'proportion': 1.0, 'length_consistency': 1.0}
        
        magnitudes = [v['magnitude'] for v in leg_vectors]
        
        return {
            'magnitude': np.mean(magnitudes),
            'proportion': min(magnitudes) / max(magnitudes) if max(magnitudes) > 0 else 1.0,
            'length_consistency': 1.0 - (np.std(magnitudes) / np.mean(magnitudes)) if np.mean(magnitudes) > 0 else 1.0
        }
    
    async def get_model_info(self) -> Dict[str, Any]:
        """ëª¨ë¸ ì •ë³´ ë°˜í™˜"""
        return {
            "step_name": "GeometricMatching",
            "version": "unified_v1.0",
            "transform_method": "TPS + Mesh Hybrid",
            "device": self.device,
            "use_mps": self.use_mps,
            "initialized": self.is_initialized,
            "tps_config": self.tps_config,
            "matching_config": self.matching_config,
            "supported_clothing_types": list(self.CLOTHING_KEYPOINTS.keys()),
            "pose_mapping": self.POSE_TO_CLOTHING,
            "min_keypoints": self.matching_config["min_matching_points"],
            "max_keypoints": self.matching_config["max_keypoints"],
            "features": [
                "Hungarian algorithm matching",
                "Contour-based keypoint extraction", 
                "TPS + Mesh hybrid warping",
                "Comprehensive quality evaluation",
                "M3 Max optimization"
            ]
        }
    
    async def cleanup(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        if self.tps_solver:
            del self.tps_solver
            self.tps_solver = None
            
        if self.tps_transformer:
            del self.tps_transformer
            self.tps_transformer = None
        
        if self.mesh_warper:
            del self.mesh_warper
            self.mesh_warper = None
        
        self.is_initialized = False
        logger.info("ğŸ§¹ ê¸°í•˜í•™ì  ë§¤ì¹­ ìŠ¤í… ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì™„ë£Œ")


class TPSSolver:
    """Thin Plate Spline ë³€í™˜ ì†”ë²„ (ìˆ˜í•™ì ìœ¼ë¡œ ì •í™•í•œ ë²„ì „)"""
    
    def __init__(self, device: str, reg_factor: float = 0.1):
        self.device = device
        self.reg_factor = reg_factor
    
    def solve(self, source_points: np.ndarray, target_points: np.ndarray) -> np.ndarray:
        """TPS ë³€í™˜ ë§¤íŠ¸ë¦­ìŠ¤ ê³„ì‚°"""
        try:
            n_points = source_points.shape[0]
            
            # ê±°ë¦¬ í–‰ë ¬ ê³„ì‚°
            distances = cdist(source_points, source_points)
            
            # TPS ê¸°ì € í•¨ìˆ˜: r^2 * log(r)
            with np.errstate(divide='ignore', invalid='ignore'):
                K = np.where(distances == 0, 0, distances**2 * np.log(distances))
            
            # ì‹œìŠ¤í…œ í–‰ë ¬ êµ¬ì„±
            P = np.hstack([np.ones((n_points, 1)), source_points])
            
            # ìƒë‹¨ ë¸”ë¡
            top_block = np.hstack([K + self.reg_factor * np.eye(n_points), P])
            
            # í•˜ë‹¨ ë¸”ë¡
            bottom_block = np.hstack([P.T, np.zeros((3, 3))])
            
            # ì „ì²´ ì‹œìŠ¤í…œ í–‰ë ¬
            A = np.vstack([top_block, bottom_block])
            
            # ìš°ë³€ ë²¡í„°
            b_x = np.hstack([target_points[:, 0], np.zeros(3)])
            b_y = np.hstack([target_points[:, 1], np.zeros(3)])
            
            # ì„ í˜• ì‹œìŠ¤í…œ í•´ê²°
            weights_x = np.linalg.solve(A, b_x)
            weights_y = np.linalg.solve(A, b_y)
            
            # ë³€í™˜ ë§¤íŠ¸ë¦­ìŠ¤ ë°˜í™˜
            tps_matrix = np.column_stack([weights_x, weights_y])
            
            return tps_matrix
            
        except Exception as e:
            logger.error(f"TPS í•´ê²° ì‹¤íŒ¨: {e}")
            # í•­ë“± ë³€í™˜ ë°˜í™˜
            return np.eye(source_points.shape[0] + 3, 2)
    
    def transform(self, points: np.ndarray, tps_matrix: np.ndarray, source_points: np.ndarray) -> np.ndarray:
        """TPS ë³€í™˜ ì ìš©"""
        try:
            n_source = source_points.shape[0]
            n_points = points.shape[0]
            
            # ë³€í™˜í•  ì ë“¤ê³¼ ì†ŒìŠ¤ ì ë“¤ ê°„ì˜ ê±°ë¦¬
            distances = cdist(points, source_points)
            
            # TPS ê¸°ì € í•¨ìˆ˜ ê³„ì‚°
            with np.errstate(divide='ignore', invalid='ignore'):
                U = np.where(distances == 0, 0, distances**2 * np.log(distances))
            
            # ì–´íŒŒì¸ ë¶€ë¶„
            affine_part = np.hstack([np.ones((n_points, 1)), points])
            
            # ì „ì²´ ê¸°ì € í•¨ìˆ˜
            basis = np.hstack([U, affine_part])
            
            # ë³€í™˜ ì ìš©
            transformed = basis @ tps_matrix
            
            return transformed
            
        except Exception as e:
            logger.error(f"TPS ë³€í™˜ ì ìš© ì‹¤íŒ¨: {e}")
            return points  # ì›ë³¸ ì ë“¤ ë°˜í™˜


class ThinPlateSplineTransform:
    """Thin Plate Spline ë³€í™˜ êµ¬í˜„ (RBF ê¸°ë°˜)"""
    
    def __init__(self, regularization: float = 0.001, smoothing: float = 0.01):
        self.regularization = regularization
        self.smoothing = smoothing
        self.rbf_x = None
        self.rbf_y = None
        self.control_points = None
        self.target_points = None
    
    def fit(self, control_points: np.ndarray, target_points: np.ndarray):
        """TPS ë³€í™˜ í•™ìŠµ"""
        self.control_points = control_points.astype(np.float32)
        self.target_points = target_points.astype(np.float32)
        
        # RBF ë³´ê°„ê¸° ìƒì„±
        self.rbf_x = RBFInterpolator(
            self.control_points,
            self.target_points[:, 0],
            kernel='thin_plate_spline',
            smoothing=self.smoothing
        )
        
        self.rbf_y = RBFInterpolator(
            self.control_points,
            self.target_points[:, 1],
            kernel='thin_plate_spline',
            smoothing=self.smoothing
        )
    
    def transform_image(self, image: np.ndarray) -> np.ndarray:
        """ì´ë¯¸ì§€ ë³€í™˜"""
        h, w = image.shape[:2]
        
        # ê·¸ë¦¬ë“œ ìƒì„±
        x, y = np.meshgrid(np.arange(w), np.arange(h))
        grid_points = np.stack([x.ravel(), y.ravel()], axis=-1).astype(np.float32)
        
        # ë³€í™˜ ì ìš©
        transformed_x = self.rbf_x(grid_points).reshape(h, w)
        transformed_y = self.rbf_y(grid_points).reshape(h, w)
        
        # ë¦¬ë§¤í•‘
        map_x = transformed_x.astype(np.float32)
        map_y = transformed_y.astype(np.float32)
        
        # ì´ë¯¸ì§€ ì›Œí•‘
        warped = cv2.remap(image, map_x, map_y, cv2.INTER_LINEAR, borderMode=cv2.BORDER_CONSTANT)
        
        return warped


class MeshBasedWarping:
    """ë©”ì‰¬ ê¸°ë°˜ ì›Œí•‘ (ì„¸ë°€ ì¡°ì •ìš©)"""
    
    def __init__(self, mesh_size: int = 15):
        self.mesh_size = mesh_size
    
    def refine_warping(
        self,
        image: np.ndarray,
        mask: np.ndarray,
        matched_pairs: List[Tuple[Tuple[float, float], Tuple[float, float], str]]
    ) -> np.ndarray:
        """ë©”ì‰¬ ê¸°ë°˜ ì„¸ë°€ ì¡°ì •"""
        
        try:
            # 1. ê¸°ë³¸ ê°€ìš°ì‹œì•ˆ ìŠ¤ë¬´ë”©
            refined = cv2.GaussianBlur(image, (3, 3), 0.5)
            
            # 2. ì—£ì§€ ë³´ì¡´
            if len(image.shape) == 3:
                edges = cv2.Canny(cv2.cvtColor(image, cv2.COLOR_BGR2GRAY), 50, 150)
            else:
                edges = cv2.Canny(image, 50, 150)
            
            # ì—£ì§€ ì˜ì—­ì€ ì›ë³¸ ìœ ì§€
            edge_mask = edges > 0
            if len(image.shape) == 3:
                edge_mask = np.stack([edge_mask] * 3, axis=2)
            
            refined = np.where(edge_mask, image, refined)
            
            # 3. í‚¤í¬ì¸íŠ¸ ì£¼ë³€ êµ­ì†Œ ì¡°ì •
            if matched_pairs:
                refined = self._apply_local_adjustments(refined, matched_pairs)
            
            # 4. ë§ˆìŠ¤í¬ ê¸°ë°˜ ë¸”ë Œë”©
            if mask is not None and mask.max() > 0:
                mask_normalized = mask.astype(np.float32) / 255.0
                if len(image.shape) == 3 and len(mask_normalized.shape) == 2:
                    mask_normalized = np.stack([mask_normalized] * 3, axis=2)
                
                # ë§ˆìŠ¤í¬ ì˜ì—­ë§Œ ì ìš©
                refined = refined * mask_normalized + image * (1 - mask_normalized)
            
            return refined.astype(np.uint8)
            
        except Exception as e:
            logger.warning(f"ë©”ì‰¬ ê¸°ë°˜ ì›Œí•‘ ì‹¤íŒ¨: {e}")
            return image
    
    def _apply_local_adjustments(
        self, 
        image: np.ndarray, 
        matched_pairs: List[Tuple[Tuple[float, float], Tuple[float, float], str]]
    ) -> np.ndarray:
        """í‚¤í¬ì¸íŠ¸ ì£¼ë³€ êµ­ì†Œ ì¡°ì •"""
        
        try:
            h, w = image.shape[:2]
            adjusted = image.copy()
            
            for body_point, cloth_point, name in matched_pairs:
                # ë³€í˜• ë²¡í„°
                dx = body_point[0] - cloth_point[0]
                dy = body_point[1] - cloth_point[1]
                
                # ì˜í–¥ ë°˜ê²½ (ì ì‘ì )
                influence_radius = min(50, max(20, math.sqrt(dx*dx + dy*dy)))
                
                # ì¤‘ì‹¬ì  ì£¼ë³€ ì˜ì—­
                center_x, center_y = int(cloth_point[0]), int(cloth_point[1])
                
                # ì˜ì—­ ë²”ìœ„ ê³„ì‚°
                x_min = max(0, center_x - int(influence_radius))
                x_max = min(w, center_x + int(influence_radius))
                y_min = max(0, center_y - int(influence_radius))
                y_max = min(h, center_y + int(influence_radius))
                
                # êµ­ì†Œ ì˜ì—­ì— ë¶€ë“œëŸ¬ìš´ ë³€í˜• ì ìš©
                for y in range(y_min, y_max):
                    for x in range(x_min, x_max):
                        dist = math.sqrt((x - center_x)**2 + (y - center_y)**2)
                        
                        if dist < influence_radius:
                            # ê°€ìš°ì‹œì•ˆ ê°€ì¤‘ì¹˜
                            weight = math.exp(-(dist**2) / (2 * (influence_radius/3)**2))
                            
                            # ìƒˆë¡œìš´ ìœ„ì¹˜ ê³„ì‚°
                            new_x = x + dx * weight
                            new_y = y + dy * weight
                            
                            # ê²½ê³„ í™•ì¸ ë° ê°’ ë³´ê°„
                            if 0 <= new_x < w-1 and 0 <= new_y < h-1:
                                # ë°”ì´ë¦¬ë‹ˆì–´ ë³´ê°„
                                x1, y1 = int(new_x), int(new_y)
                                x2, y2 = x1 + 1, y1 + 1
                                
                                dx_frac = new_x - x1
                                dy_frac = new_y - y1
                                
                                if len(image.shape) == 3:
                                    interpolated = (
                                        image[y1, x1] * (1-dx_frac) * (1-dy_frac) +
                                        image[y1, x2] * dx_frac * (1-dy_frac) +
                                        image[y2, x1] * (1-dx_frac) * dy_frac +
                                        image[y2, x2] * dx_frac * dy_frac
                                    )
                                else:
                                    interpolated = (
                                        image[y1, x1] * (1-dx_frac) * (1-dy_frac) +
                                        image[y1, x2] * dx_frac * (1-dy_frac) +
                                        image[y2, x1] * (1-dx_frac) * dy_frac +
                                        image[y2, x2] * dx_frac * dy_frac
                                    )
                                
                                # ê°€ì¤‘ í‰ê· ìœ¼ë¡œ ë¸”ë Œë”©
                                adjusted[y, x] = (
                                    adjusted[y, x] * (1 - weight) + 
                                    interpolated * weight
                                ).astype(np.uint8)
            
            return adjusted
            
        except Exception as e:
            logger.warning(f"êµ­ì†Œ ì¡°ì • ì‹¤íŒ¨: {e}")
            return image


# ì¶”ê°€ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
def visualize_keypoints(
    image: np.ndarray, 
    keypoints: Dict[str, Tuple[float, float]], 
    color: Tuple[int, int, int] = (0, 255, 0),
    radius: int = 5,
    thickness: int = 2
) -> np.ndarray:
    """í‚¤í¬ì¸íŠ¸ ì‹œê°í™”"""
    vis_image = image.copy()
    
    for name, (x, y) in keypoints.items():
        cv2.circle(vis_image, (int(x), int(y)), radius, color, thickness)
        cv2.putText(vis_image, name, (int(x)+10, int(y)-10), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)
    
    return vis_image


def visualize_matches(
    image1: np.ndarray,
    image2: np.ndarray, 
    matched_pairs: List[Tuple[Tuple[float, float], Tuple[float, float], str]]
) -> np.ndarray:
    """ë§¤ì¹­ ê²°ê³¼ ì‹œê°í™”"""
    h1, w1 = image1.shape[:2]
    h2, w2 = image2.shape[:2]
    h = max(h1, h2)
    w = w1 + w2
    
    # ì´ë¯¸ì§€ í•©ì¹˜ê¸°
    vis_image = np.zeros((h, w, 3), dtype=np.uint8)
    vis_image[:h1, :w1] = image1 if len(image1.shape) == 3 else cv2.cvtColor(image1, cv2.COLOR_GRAY2BGR)
    vis_image[:h2, w1:w1+w2] = image2 if len(image2.shape) == 3 else cv2.cvtColor(image2, cv2.COLOR_GRAY2BGR)
    
    # ë§¤ì¹­ ë¼ì¸ ê·¸ë¦¬ê¸°
    colors = [(255, 0, 0), (0, 255, 0), (0, 0, 255), (255, 255, 0), (255, 0, 255), (0, 255, 255)]
    
    for i, (body_point, cloth_point, name) in enumerate(matched_pairs):
        color = colors[i % len(colors)]
        
        # í¬ì¸íŠ¸ ê·¸ë¦¬ê¸°
        cv2.circle(vis_image, (int(body_point[0]), int(body_point[1])), 8, color, -1)
        cv2.circle(vis_image, (int(cloth_point[0] + w1), int(cloth_point[1])), 8, color, -1)
        
        # ì—°ê²° ë¼ì¸ ê·¸ë¦¬ê¸°
        cv2.line(vis_image, 
                (int(body_point[0]), int(body_point[1])),
                (int(cloth_point[0] + w1), int(cloth_point[1])),
                color, 2)
        
        # ì´ë¦„ í‘œì‹œ
        cv2.putText(vis_image, f"{i+1}", 
                   (int(body_point[0])-20, int(body_point[1])-20),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)
    
    return vis_image


def save_intermediate_results(
    cloth_img: np.ndarray,
    warped_cloth: np.ndarray,
    matched_pairs: List,
    output_dir: str,
    step_name: str = "geometric_matching"
):
    """ì¤‘ê°„ ê²°ê³¼ ì €ì¥"""
    try:
        os.makedirs(output_dir, exist_ok=True)
        
        # ì›ë³¸ ì˜ë¥˜ ì´ë¯¸ì§€ ì €ì¥
        cv2.imwrite(os.path.join(output_dir, f"{step_name}_original_cloth.jpg"), cloth_img)
        
        # ë³€í˜•ëœ ì˜ë¥˜ ì´ë¯¸ì§€ ì €ì¥
        cv2.imwrite(os.path.join(output_dir, f"{step_name}_warped_cloth.jpg"), warped_cloth)
        
        # í‚¤í¬ì¸íŠ¸ ì •ë³´ ì €ì¥
        keypoint_data = {
            "num_matches": len(matched_pairs),
            "matches": [
                {
                    "body_point": [float(pair[0][0]), float(pair[0][1])],
                    "cloth_point": [float(pair[1][0]), float(pair[1][1])], 
                    "name": pair[2]
                }
                for pair in matched_pairs
            ]
        }
        
        with open(os.path.join(output_dir, f"{step_name}_keypoints.json"), 'w') as f:
            json.dump(keypoint_data, f, indent=2)
        
        logger.info(f"ì¤‘ê°„ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {output_dir}")
        
    except Exception as e:
        logger.warning(f"ì¤‘ê°„ ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {e}")


# ì„±ëŠ¥ ìµœì í™”ë¥¼ ìœ„í•œ M3 Max ì „ìš© í•¨ìˆ˜ë“¤
def optimize_for_m3_max():
    """M3 Max ì¹© ìµœì í™” ì„¤ì •"""
    if torch.backends.mps.is_available():
        # MPS ë©”ëª¨ë¦¬ ê´€ë¦¬ ìµœì í™”
        torch.mps.empty_cache()
        
        # ìˆ˜ì¹˜ ì•ˆì •ì„± ì„¤ì •
        torch.backends.mps.enable_fusion = True
        
        logger.info("M3 Max MPS ìµœì í™” ì„¤ì • ì™„ë£Œ")
        return True
    
    return False


def batch_process_keypoints(
    keypoints_list: List[Dict[str, Tuple[float, float]]],
    batch_size: int = 8
) -> List[Dict[str, Tuple[float, float]]]:
    """í‚¤í¬ì¸íŠ¸ ë°°ì¹˜ ì²˜ë¦¬ (ë©”ëª¨ë¦¬ ìµœì í™”)"""
    processed = []
    
    for i in range(0, len(keypoints_list), batch_size):
        batch = keypoints_list[i:i+batch_size]
        
        # ë°°ì¹˜ ì²˜ë¦¬ ë¡œì§
        batch_processed = []
        for kp_dict in batch:
            # í‚¤í¬ì¸íŠ¸ ì •ê·œí™” ë° í•„í„°ë§
            filtered_kp = {
                name: point for name, point in kp_dict.items()
                if 0 <= point[0] <= 2048 and 0 <= point[1] <= 2048  # í•©ë¦¬ì ì¸ ì´ë¯¸ì§€ í¬ê¸° ë²”ìœ„
            }
            batch_processed.append(filtered_kp)
        
        processed.extend(batch_processed)
        
        # ë©”ëª¨ë¦¬ ì •ë¦¬
        if torch.backends.mps.is_available():
            torch.mps.empty_cache()
    
    return processed