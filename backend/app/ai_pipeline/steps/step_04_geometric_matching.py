# app/ai_pipeline/steps/step_04_geometric_matching.py
"""
4ë‹¨ê³„: ê¸°í•˜í•™ì  ë§¤ì¹­ (Geometric Matching) - ìˆ˜ì •ëœ ë²„ì „
Pipeline Managerì™€ ì™„ì „ í˜¸í™˜ë˜ëŠ” ì˜ë¥˜-ì¸ì²´ ë§¤ì¹­ ì‹œìŠ¤í…œ
M3 Max ìµœì í™” + ê³ ê¸‰ ë§¤ì¹­ ì•Œê³ ë¦¬ì¦˜ + ê²¬ê³ í•œ ì—ëŸ¬ ì²˜ë¦¬
"""
import os
import logging
import time
import asyncio
from typing import Dict, Any, Optional, Tuple, List, Union
import numpy as np
import torch
import torch.nn.functional as F
import cv2
from PIL import Image
import json
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor
from scipy.spatial.distance import cdist
from scipy.optimize import minimize

logger = logging.getLogger(__name__)

class GeometricMatchingStep:
    """
    ê¸°í•˜í•™ì  ë§¤ì¹­ ìŠ¤í… - Pipeline Manager ì™„ì „ í˜¸í™˜
    - M3 Max MPS ìµœì í™”
    - ê³ ê¸‰ ë§¤ì¹­ ì•Œê³ ë¦¬ì¦˜ (TPS, Affine, Homography)
    - í¬ì¦ˆ ê¸°ë°˜ ì ì‘í˜• ë§¤ì¹­
    - ì‹¤ì‹œê°„ ë§¤ì¹­ í’ˆì§ˆ í‰ê°€
    """
    
    # ì˜ë¥˜ë³„ í•µì‹¬ ë§¤ì¹­ í¬ì¸íŠ¸ ì •ì˜
    MATCHING_POINTS = {
        'shirt': {
            'keypoints': ['left_shoulder', 'right_shoulder', 'neck', 'left_wrist', 'right_wrist'],
            'clothing_points': ['left_shoulder', 'right_shoulder', 'collar', 'left_cuff', 'right_cuff'],
            'priority_weights': [1.0, 1.0, 0.8, 0.7, 0.7]
        },
        'pants': {
            'keypoints': ['left_hip', 'right_hip', 'left_knee', 'right_knee', 'left_ankle', 'right_ankle'],
            'clothing_points': ['left_waist', 'right_waist', 'left_knee', 'right_knee', 'left_hem', 'right_hem'],
            'priority_weights': [1.0, 1.0, 0.8, 0.8, 0.6, 0.6]
        },
        'dress': {
            'keypoints': ['left_shoulder', 'right_shoulder', 'neck', 'left_hip', 'right_hip'],
            'clothing_points': ['left_shoulder', 'right_shoulder', 'collar', 'left_waist', 'right_waist'],
            'priority_weights': [1.0, 1.0, 0.8, 0.7, 0.7]
        }
    }
    
    def __init__(self, device: str, config: Optional[Dict[str, Any]] = None):
        """
        ì´ˆê¸°í™” - Pipeline Manager ì™„ì „ í˜¸í™˜
        
        Args:
            device: ì‚¬ìš©í•  ë””ë°”ì´ìŠ¤ (mps, cuda, cpu)
            config: ì„¤ì • ë”•ì…”ë„ˆë¦¬ (ì„ íƒì )
        """
        # model_loaderëŠ” ë‚´ë¶€ì—ì„œ ì „ì—­ í•¨ìˆ˜ë¡œ ê°€ì ¸ì˜´
        from app.ai_pipeline.utils.model_loader import get_global_model_loader
        self.model_loader = get_global_model_loader()
        
        self.device = device
        self.config = config or {}
        self.is_initialized = False
        
        # ë¡œê¹… ì„¤ì •
        self.logger = logging.getLogger(__name__)
        
        # ë§¤ì¹­ ì„¤ì •
        self.matching_config = self.config.get('matching', {
            'method': 'auto',  # 'tps', 'affine', 'homography', 'auto'
            'max_iterations': 1000,
            'convergence_threshold': 1e-6,
            'outlier_threshold': 0.15,
            'use_pose_guidance': True,
            'adaptive_weights': True,
            'quality_threshold': 0.7
        })
        
        # TPS (Thin Plate Spline) ì„¤ì •
        self.tps_config = self.config.get('tps', {
            'regularization': 0.1,
            'grid_size': 20,
            'boundary_padding': 0.1
        })
        
        # ìµœì í™” ì„¤ì •
        self.optimization_config = self.config.get('optimization', {
            'learning_rate': 0.01,
            'momentum': 0.9,
            'weight_decay': 1e-4,
            'scheduler_step': 100
        })
        
        # ë§¤ì¹­ í†µê³„
        self.matching_stats = {
            'total_matches': 0,
            'successful_matches': 0,
            'average_accuracy': 0.0,
            'method_performance': {}
        }
        
        self.logger.info(f"ğŸ¯ ê¸°í•˜í•™ì  ë§¤ì¹­ ìŠ¤í… ì´ˆê¸°í™” - ë””ë°”ì´ìŠ¤: {device}")
    
    async def initialize(self) -> bool:
        """ì´ˆê¸°í™” ë©”ì„œë“œ"""
        try:
            # ë§¤ì¹­ ì•Œê³ ë¦¬ì¦˜ ì´ˆê¸°í™”
            await self._initialize_matching_algorithms()
            
            # ìµœì í™” ë„êµ¬ ì´ˆê¸°í™”
            await self._initialize_optimization_tools()
            
            self.is_initialized = True
            self.logger.info("âœ… ê¸°í•˜í•™ì  ë§¤ì¹­ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ ë§¤ì¹­ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            # ê¸°ë³¸ ì‹œìŠ¤í…œìœ¼ë¡œ í´ë°±
            self.is_initialized = True
            return True
    
    async def process(
        self,
        person_parsing: Dict[str, Any],
        pose_keypoints: List[List[float]],
        clothing_segmentation: Dict[str, Any],
        clothing_type: str = "shirt",
        **kwargs
    ) -> Dict[str, Any]:
        """
        ê¸°í•˜í•™ì  ë§¤ì¹­ ì²˜ë¦¬
        
        Args:
            person_parsing: ì¸ì²´ íŒŒì‹± ê²°ê³¼
            pose_keypoints: í¬ì¦ˆ í‚¤í¬ì¸íŠ¸ (OpenPose 18 í˜•ì‹)
            clothing_segmentation: ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ ê²°ê³¼
            clothing_type: ì˜ë¥˜ íƒ€ì…
            **kwargs: ì¶”ê°€ ë§¤ê°œë³€ìˆ˜
            
        Returns:
            Dict: ë§¤ì¹­ ê²°ê³¼
        """
        start_time = time.time()
        
        try:
            if not self.is_initialized:
                await self.initialize()
            
            # 1. ì…ë ¥ ë°ì´í„° ê²€ì¦ ë° ì „ì²˜ë¦¬
            person_points = self._extract_person_keypoints(pose_keypoints, clothing_type)
            clothing_points = self._extract_clothing_keypoints(clothing_segmentation, clothing_type)
            
            if len(person_points) < 3 or len(clothing_points) < 3:
                return self._create_empty_result("ì¶©ë¶„í•˜ì§€ ì•Šì€ ë§¤ì¹­ í¬ì¸íŠ¸")
            
            # 2. ë§¤ì¹­ ë°©ë²• ì„ íƒ
            matching_method = self._select_matching_method(person_points, clothing_points, clothing_type)
            self.logger.info(f"ğŸ“ ì„ íƒëœ ë§¤ì¹­ ë°©ë²•: {matching_method}")
            
            # 3. ì´ˆê¸° ë§¤ì¹­ ìˆ˜í–‰
            initial_match = await self._perform_initial_matching(
                person_points, clothing_points, matching_method
            )
            
            # 4. í¬ì¦ˆ ê¸°ë°˜ ì •ì œ
            if self.matching_config['use_pose_guidance']:
                refined_match = await self._refine_with_pose_guidance(
                    initial_match, pose_keypoints, clothing_type
                )
            else:
                refined_match = initial_match
            
            # 5. ë§¤ì¹­ í’ˆì§ˆ í‰ê°€
            quality_metrics = self._evaluate_matching_quality(
                person_points, clothing_points, refined_match
            )
            
            # 6. í’ˆì§ˆì´ ë‚®ìœ¼ë©´ ëŒ€ì•ˆ ë°©ë²• ì‹œë„
            if quality_metrics['overall_quality'] < self.matching_config['quality_threshold']:
                self.logger.info(f"ğŸ”„ í’ˆì§ˆ ê°œì„  ì‹œë„ (í˜„ì¬: {quality_metrics['overall_quality']:.3f})")
                alternative_match = await self._try_alternative_methods(
                    person_points, clothing_points, clothing_type
                )
                
                alternative_quality = self._evaluate_matching_quality(
                    person_points, clothing_points, alternative_match
                )
                
                if alternative_quality['overall_quality'] > quality_metrics['overall_quality']:
                    refined_match = alternative_match
                    quality_metrics = alternative_quality
                    matching_method = alternative_match.get('method', matching_method)
            
            # 7. ì›Œí•‘ íŒŒë¼ë¯¸í„° ìƒì„±
            warp_params = self._generate_warp_parameters(refined_match, clothing_segmentation)
            
            # 8. ìµœì¢… ê²°ê³¼ êµ¬ì„±
            processing_time = time.time() - start_time
            result = self._build_final_result(
                refined_match, warp_params, quality_metrics, 
                processing_time, matching_method, clothing_type
            )
            
            # 9. í†µê³„ ì—…ë°ì´íŠ¸
            self._update_statistics(matching_method, quality_metrics['overall_quality'])
            
            self.logger.info(f"âœ… ê¸°í•˜í•™ì  ë§¤ì¹­ ì™„ë£Œ - ë°©ë²•: {matching_method}, í’ˆì§ˆ: {quality_metrics['overall_quality']:.3f}")
            return result
            
        except Exception as e:
            self.logger.error(f"âŒ ê¸°í•˜í•™ì  ë§¤ì¹­ ì‹¤íŒ¨: {e}")
            return self._create_empty_result(f"ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")
    
    def _extract_person_keypoints(self, pose_keypoints: List[List[float]], clothing_type: str) -> List[Tuple[float, float]]:
        """ì¸ì²´ì—ì„œ ë§¤ì¹­ í¬ì¸íŠ¸ ì¶”ì¶œ"""
        
        try:
            keypoint_mapping = {
                'neck': 1, 'left_shoulder': 5, 'right_shoulder': 2,
                'left_elbow': 6, 'right_elbow': 3,
                'left_wrist': 7, 'right_wrist': 4,
                'left_hip': 11, 'right_hip': 8,
                'left_knee': 12, 'right_knee': 9,
                'left_ankle': 13, 'right_ankle': 10
            }
            
            matching_points = self.MATCHING_POINTS.get(clothing_type, self.MATCHING_POINTS['shirt'])
            person_points = []
            
            for keypoint_name in matching_points['keypoints']:
                if keypoint_name in keypoint_mapping:
                    idx = keypoint_mapping[keypoint_name]
                    if idx < len(pose_keypoints):
                        x, y, conf = pose_keypoints[idx]
                        if conf > 0.5:  # ì‹ ë¢°ë„ ì„ê³„ê°’
                            person_points.append((float(x), float(y)))
            
            self.logger.debug(f"ì¶”ì¶œëœ ì¸ì²´ í¬ì¸íŠ¸: {len(person_points)}ê°œ")
            return person_points
            
        except Exception as e:
            self.logger.warning(f"ì¸ì²´ í‚¤í¬ì¸íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return []
    
    def _extract_clothing_keypoints(self, clothing_segmentation: Dict[str, Any], clothing_type: str) -> List[Tuple[float, float]]:
        """ì˜ë¥˜ì—ì„œ ë§¤ì¹­ í¬ì¸íŠ¸ ì¶”ì¶œ"""
        
        try:
            mask = clothing_segmentation.get('mask')
            if mask is None:
                return []
            
            # ì˜ë¥˜ ìœ¤ê³½ì„  ì¶”ì¶œ
            contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            
            if not contours:
                return []
            
            # ê°€ì¥ í° ìœ¤ê³½ì„  ì„ íƒ
            largest_contour = max(contours, key=cv2.contourArea)
            
            # ì˜ë¥˜ íƒ€ì…ë³„ íŠ¹ì§•ì  ì¶”ì¶œ
            clothing_points = self._extract_clothing_features(largest_contour, mask, clothing_type)
            
            self.logger.debug(f"ì¶”ì¶œëœ ì˜ë¥˜ í¬ì¸íŠ¸: {len(clothing_points)}ê°œ")
            return clothing_points
            
        except Exception as e:
            self.logger.warning(f"ì˜ë¥˜ í‚¤í¬ì¸íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return []
    
    def _extract_clothing_features(self, contour: np.ndarray, mask: np.ndarray, clothing_type: str) -> List[Tuple[float, float]]:
        """ì˜ë¥˜ íŠ¹ì§•ì  ì¶”ì¶œ"""
        
        features = []
        
        try:
            # ë°”ìš´ë”© ë°•ìŠ¤
            x, y, w, h = cv2.boundingRect(contour)
            
            if clothing_type in ['shirt', 't-shirt', 'blouse']:
                # ìƒì˜: ì–´ê¹¨, ëª©, ì†Œë§¤ ë¶€ë¶„
                features.extend([
                    (x + w * 0.2, y + h * 0.1),  # ì™¼ìª½ ì–´ê¹¨
                    (x + w * 0.8, y + h * 0.1),  # ì˜¤ë¥¸ìª½ ì–´ê¹¨
                    (x + w * 0.5, y),            # ëª©/ì¹¼ë¼
                    (x, y + h * 0.3),            # ì™¼ìª½ ì†Œë§¤
                    (x + w, y + h * 0.3)         # ì˜¤ë¥¸ìª½ ì†Œë§¤
                ])
                
            elif clothing_type in ['pants', 'jeans', 'trousers']:
                # í•˜ì˜: í—ˆë¦¬, ë¬´ë¦, ë°œëª© ë¶€ë¶„
                features.extend([
                    (x + w * 0.2, y),            # ì™¼ìª½ í—ˆë¦¬
                    (x + w * 0.8, y),            # ì˜¤ë¥¸ìª½ í—ˆë¦¬
                    (x + w * 0.3, y + h * 0.6),  # ì™¼ìª½ ë¬´ë¦
                    (x + w * 0.7, y + h * 0.6),  # ì˜¤ë¥¸ìª½ ë¬´ë¦
                    (x + w * 0.3, y + h),        # ì™¼ìª½ ë°œëª©
                    (x + w * 0.7, y + h)         # ì˜¤ë¥¸ìª½ ë°œëª©
                ])
                
            elif clothing_type in ['dress', 'gown']:
                # ë“œë ˆìŠ¤: ì–´ê¹¨, ëª©, í—ˆë¦¬ ë¶€ë¶„
                features.extend([
                    (x + w * 0.2, y + h * 0.1),  # ì™¼ìª½ ì–´ê¹¨
                    (x + w * 0.8, y + h * 0.1),  # ì˜¤ë¥¸ìª½ ì–´ê¹¨
                    (x + w * 0.5, y),            # ëª©/ì¹¼ë¼
                    (x + w * 0.2, y + h * 0.4),  # ì™¼ìª½ í—ˆë¦¬
                    (x + w * 0.8, y + h * 0.4)   # ì˜¤ë¥¸ìª½ í—ˆë¦¬
                ])
            
            # ìœ¤ê³½ì„  ê¸°ë°˜ ì¶”ê°€ íŠ¹ì§•ì 
            features.extend(self._extract_contour_features(contour))
            
            return features
            
        except Exception as e:
            self.logger.warning(f"ì˜ë¥˜ íŠ¹ì§•ì  ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return []
    
    def _extract_contour_features(self, contour: np.ndarray) -> List[Tuple[float, float]]:
        """ìœ¤ê³½ì„  ê¸°ë°˜ íŠ¹ì§•ì  ì¶”ì¶œ"""
        
        features = []
        
        try:
            # ë³¼ë¡ ê»ì§ˆ
            hull = cv2.convexHull(contour)
            
            # ê·¹ê°’ì ë“¤
            leftmost = tuple(contour[contour[:, :, 0].argmin()][0])
            rightmost = tuple(contour[contour[:, :, 0].argmax()][0])
            topmost = tuple(contour[contour[:, :, 1].argmin()][0])
            bottommost = tuple(contour[contour[:, :, 1].argmax()][0])
            
            features.extend([leftmost, rightmost, topmost, bottommost])
            
            # ì½”ë„ˆ ì ë“¤ (Harris corner detection)
            mask = np.zeros(contour.max(axis=0).max(axis=0) + 10, dtype=np.uint8)
            cv2.fillPoly(mask, [contour], 255)
            
            corners = cv2.goodFeaturesToTrack(
                mask, maxCorners=10, qualityLevel=0.01, minDistance=10
            )
            
            if corners is not None:
                for corner in corners:
                    features.append(tuple(corner.ravel()))
            
            return features
            
        except Exception as e:
            self.logger.warning(f"ìœ¤ê³½ì„  íŠ¹ì§•ì  ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return []
    
    def _select_matching_method(self, person_points: List, clothing_points: List, clothing_type: str) -> str:
        """ë§¤ì¹­ ë°©ë²• ì„ íƒ"""
        
        method = self.matching_config['method']
        
        if method == 'auto':
            num_points = min(len(person_points), len(clothing_points))
            
            # í¬ì¸íŠ¸ ìˆ˜ì™€ ì˜ë¥˜ íƒ€ì…ì— ë”°ë¥¸ ìë™ ì„ íƒ
            if num_points >= 8:
                return 'tps'  # ì¶©ë¶„í•œ í¬ì¸íŠ¸ê°€ ìˆìœ¼ë©´ TPS
            elif num_points >= 4:
                return 'homography'  # 4-7ê°œ í¬ì¸íŠ¸ëŠ” Homography
            elif num_points >= 3:
                return 'affine'  # 3ê°œ í¬ì¸íŠ¸ëŠ” Affine
            else:
                return 'similarity'  # ìµœì†Œ ë³€í™˜
        
        return method
    
    async def _perform_initial_matching(
        self, 
        person_points: List, 
        clothing_points: List, 
        method: str
    ) -> Dict[str, Any]:
        """ì´ˆê¸° ë§¤ì¹­ ìˆ˜í–‰"""
        
        try:
            if method == 'tps':
                return await self._tps_matching(person_points, clothing_points)
            elif method == 'homography':
                return self._homography_matching(person_points, clothing_points)
            elif method == 'affine':
                return self._affine_matching(person_points, clothing_points)
            elif method == 'similarity':
                return self._similarity_matching(person_points, clothing_points)
            else:
                # ê¸°ë³¸: ì•„í•€ ë³€í™˜
                return self._affine_matching(person_points, clothing_points)
                
        except Exception as e:
            self.logger.warning(f"ë§¤ì¹­ ë°©ë²• {method} ì‹¤íŒ¨: {e}")
            # í´ë°±: ë‹¨ìˆœ ë³€í™˜
            return self._similarity_matching(person_points, clothing_points)
    
    async def _tps_matching(self, person_points: List, clothing_points: List) -> Dict[str, Any]:
        """Thin Plate Spline ë§¤ì¹­"""
        
        try:
            # ëŒ€ì‘ì  ìŒ ìƒì„± (ê°€ì¥ ê°€ê¹Œìš´ ì ë“¤ ë§¤ì¹­)
            person_array = np.array(person_points)
            clothing_array = np.array(clothing_points)
            
            # ê±°ë¦¬ ê¸°ë°˜ ëŒ€ì‘ ì°¾ê¸°
            distances = cdist(person_array, clothing_array)
            correspondences = []
            
            used_clothing = set()
            for i, person_pt in enumerate(person_array):
                # ê° ì¸ì²´ í¬ì¸íŠ¸ì— ëŒ€í•´ ê°€ì¥ ê°€ê¹Œìš´ ì˜ë¥˜ í¬ì¸íŠ¸ ì°¾ê¸°
                distances_to_clothing = distances[i]
                sorted_indices = np.argsort(distances_to_clothing)
                
                for clothing_idx in sorted_indices:
                    if clothing_idx not in used_clothing:
                        correspondences.append((person_pt, clothing_array[clothing_idx]))
                        used_clothing.add(clothing_idx)
                        break
            
            # TPS ë³€í™˜ ê³„ì‚°
            if len(correspondences) >= 3:
                source_pts = np.array([corr[1] for corr in correspondences])  # ì˜ë¥˜ ì ë“¤
                target_pts = np.array([corr[0] for corr in correspondences])  # ì¸ì²´ ì ë“¤
                
                tps_transform = self._compute_tps_transform(source_pts, target_pts)
                
                return {
                    'method': 'tps',
                    'transform': tps_transform,
                    'correspondences': correspondences,
                    'source_points': source_pts.tolist(),
                    'target_points': target_pts.tolist(),
                    'confidence': 0.9
                }
            else:
                raise ValueError("TPSë¥¼ ìœ„í•œ ì¶©ë¶„í•œ ëŒ€ì‘ì ì´ ì—†ìŒ")
                
        except Exception as e:
            self.logger.warning(f"TPS ë§¤ì¹­ ì‹¤íŒ¨: {e}")
            raise
    
    def _compute_tps_transform(self, source_pts: np.ndarray, target_pts: np.ndarray) -> Dict[str, Any]:
        """TPS ë³€í™˜ ë§¤ê°œë³€ìˆ˜ ê³„ì‚°"""
        
        try:
            n = len(source_pts)
            
            # TPS ê¸°ë³¸ í•¨ìˆ˜ (U í•¨ìˆ˜: r^2 * log(r))
            def U(r):
                return np.where(r == 0, 0, r**2 * np.log(r + 1e-10))
            
            # ê±°ë¦¬ í–‰ë ¬ ê³„ì‚°
            distances = cdist(source_pts, source_pts)
            
            # K í–‰ë ¬ (ê¸°ë³¸ í•¨ìˆ˜ë“¤ì˜ ê°’)
            K = U(distances)
            
            # P í–‰ë ¬ (affine ë¶€ë¶„ì„ ìœ„í•œ ë‹¤í•­ì‹ ê¸°ì €)
            P = np.column_stack([np.ones(n), source_pts])
            
            # L í–‰ë ¬ êµ¬ì„±
            O = np.zeros((3, 3))
            L = np.block([[K, P], [P.T, O]])
            
            # ëª©í‘œ ì ë“¤ì„ í™•ì¥
            Y = np.vstack([target_pts.T, np.zeros((3, 2))])
            
            # ì„ í˜• ì‹œìŠ¤í…œ í•´ê²°
            try:
                coeffs = np.linalg.solve(L, Y)
            except np.linalg.LinAlgError:
                # íŠ¹ì´ í–‰ë ¬ì¸ ê²½ìš° pseudo-inverse ì‚¬ìš©
                coeffs = np.linalg.pinv(L) @ Y
            
            # ê³„ìˆ˜ ë¶„ë¦¬
            w = coeffs[:n]  # TPS ê°€ì¤‘ì¹˜
            a = coeffs[n:]  # affine ê³„ìˆ˜
            
            return {
                'source_points': source_pts.tolist(),
                'weights': w.tolist(),
                'affine_coeffs': a.tolist(),
                'regularization': self.tps_config['regularization']
            }
            
        except Exception as e:
            self.logger.error(f"TPS ë³€í™˜ ê³„ì‚° ì‹¤íŒ¨: {e}")
            # í´ë°±: ë‹¨ìœ„ ë³€í™˜
            return {
                'source_points': source_pts.tolist(),
                'weights': np.zeros((len(source_pts), 2)).tolist(),
                'affine_coeffs': np.array([[1, 0, 0], [0, 1, 0]]).tolist(),
                'regularization': 0.0
            }
    
    def _homography_matching(self, person_points: List, clothing_points: List) -> Dict[str, Any]:
        """Homography ë§¤ì¹­"""
        
        try:
            person_array = np.array(person_points, dtype=np.float32)
            clothing_array = np.array(clothing_points, dtype=np.float32)
            
            # ìµœì†Œ 4ê°œ ì  í•„ìš”
            min_points = min(len(person_array), len(clothing_array), 4)
            
            if min_points < 4:
                raise ValueError("Homographyë¥¼ ìœ„í•œ ì¶©ë¶„í•œ ì ì´ ì—†ìŒ")
            
            # ì²« 4ê°œ ì  ì‚¬ìš© (ë” ì •êµí•œ ëŒ€ì‘ ë°©ë²•ìœ¼ë¡œ ê°œì„  ê°€ëŠ¥)
            src_pts = clothing_array[:min_points]
            dst_pts = person_array[:min_points]
            
            # Homography ê³„ì‚°
            H, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)
            
            if H is None:
                raise ValueError("Homography ê³„ì‚° ì‹¤íŒ¨")
            
            return {
                'method': 'homography',
                'transform': H.tolist(),
                'source_points': src_pts.tolist(),
                'target_points': dst_pts.tolist(),
                'inlier_mask': mask.flatten().tolist() if mask is not None else [],
                'confidence': 0.8
            }
            
        except Exception as e:
            self.logger.warning(f"Homography ë§¤ì¹­ ì‹¤íŒ¨: {e}")
            raise
    
    def _affine_matching(self, person_points: List, clothing_points: List) -> Dict[str, Any]:
        """Affine ë³€í™˜ ë§¤ì¹­"""
        
        try:
            person_array = np.array(person_points, dtype=np.float32)
            clothing_array = np.array(clothing_points, dtype=np.float32)
            
            # ìµœì†Œ 3ê°œ ì  í•„ìš”
            min_points = min(len(person_array), len(clothing_array), 3)
            
            if min_points < 3:
                raise ValueError("Affine ë³€í™˜ì„ ìœ„í•œ ì¶©ë¶„í•œ ì ì´ ì—†ìŒ")
            
            # ì²« 3ê°œ ì  ì‚¬ìš©
            src_pts = clothing_array[:min_points]
            dst_pts = person_array[:min_points]
            
            # Affine ë³€í™˜ ê³„ì‚°
            M = cv2.getAffineTransform(src_pts[:3], dst_pts[:3])
            
            return {
                'method': 'affine',
                'transform': M.tolist(),
                'source_points': src_pts.tolist(),
                'target_points': dst_pts.tolist(),
                'confidence': 0.7
            }
            
        except Exception as e:
            self.logger.warning(f"Affine ë§¤ì¹­ ì‹¤íŒ¨: {e}")
            raise
    
    def _similarity_matching(self, person_points: List, clothing_points: List) -> Dict[str, Any]:
        """ìœ ì‚¬ì„± ë³€í™˜ ë§¤ì¹­ (íšŒì „, ìŠ¤ì¼€ì¼, í‰í–‰ì´ë™)"""
        
        try:
            if len(person_points) < 2 or len(clothing_points) < 2:
                # ìµœì†Œ ë³€í™˜: í‰í–‰ì´ë™ë§Œ
                if person_points and clothing_points:
                    tx = person_points[0][0] - clothing_points[0][0]
                    ty = person_points[0][1] - clothing_points[0][1]
                    M = np.array([[1, 0, tx], [0, 1, ty]], dtype=np.float32)
                else:
                    M = np.array([[1, 0, 0], [0, 1, 0]], dtype=np.float32)
            else:
                # ì¤‘ì‹¬ì  ê¸°ë°˜ ë³€í™˜
                person_center = np.mean(person_points, axis=0)
                clothing_center = np.mean(clothing_points, axis=0)
                
                # ìŠ¤ì¼€ì¼ ì¶”ì •
                person_spread = np.std(person_points, axis=0)
                clothing_spread = np.std(clothing_points, axis=0)
                
                scale_x = person_spread[0] / (clothing_spread[0] + 1e-6)
                scale_y = person_spread[1] / (clothing_spread[1] + 1e-6)
                scale = (scale_x + scale_y) / 2  # í‰ê·  ìŠ¤ì¼€ì¼
                
                # í‰í–‰ì´ë™
                tx = person_center[0] - clothing_center[0] * scale
                ty = person_center[1] - clothing_center[1] * scale
                
                M = np.array([[scale, 0, tx], [0, scale, ty]], dtype=np.float32)
            
            return {
                'method': 'similarity',
                'transform': M.tolist(),
                'source_points': clothing_points[:2] if len(clothing_points) >= 2 else clothing_points,
                'target_points': person_points[:2] if len(person_points) >= 2 else person_points,
                'confidence': 0.6
            }
            
        except Exception as e:
            self.logger.warning(f"ìœ ì‚¬ì„± ë³€í™˜ ì‹¤íŒ¨: {e}")
            # ìµœí›„ì˜ í´ë°±: ë‹¨ìœ„ ë³€í™˜
            return {
                'method': 'identity',
                'transform': [[1, 0, 0], [0, 1, 0]],
                'source_points': [],
                'target_points': [],
                'confidence': 0.3
            }
    
    async def _refine_with_pose_guidance(
        self, 
        initial_match: Dict[str, Any], 
        pose_keypoints: List[List[float]], 
        clothing_type: str
    ) -> Dict[str, Any]:
        """í¬ì¦ˆ ê¸°ë°˜ ë§¤ì¹­ ì •ì œ"""
        
        try:
            # í¬ì¦ˆ íŠ¹ì„± ë¶„ì„
            pose_analysis = self._analyze_pose_characteristics(pose_keypoints)
            
            # ì˜ë¥˜ íƒ€ì…ë³„ í¬ì¦ˆ ì ì‘
            adaptation_factor = self._calculate_pose_adaptation(pose_analysis, clothing_type)
            
            # ë³€í™˜ ë§¤ê°œë³€ìˆ˜ ì¡°ì •
            refined_transform = self._adapt_transform_to_pose(
                initial_match['transform'], adaptation_factor, pose_analysis
            )
            
            refined_match = initial_match.copy()
            refined_match['transform'] = refined_transform
            refined_match['pose_adapted'] = True
            refined_match['adaptation_factor'] = adaptation_factor
            
            return refined_match
            
        except Exception as e:
            self.logger.warning(f"í¬ì¦ˆ ê¸°ë°˜ ì •ì œ ì‹¤íŒ¨: {e}")
            return initial_match
    
    def _analyze_pose_characteristics(self, pose_keypoints: List[List[float]]) -> Dict[str, Any]:
        """í¬ì¦ˆ íŠ¹ì„± ë¶„ì„"""
        
        analysis = {}
        
        try:
            # ì–´ê¹¨ ê°ë„
            if all(pose_keypoints[i][2] > 0.5 for i in [2, 5]):  # ì–‘ìª½ ì–´ê¹¨
                left_shoulder = pose_keypoints[5][:2]
                right_shoulder = pose_keypoints[2][:2]
                shoulder_angle = np.degrees(np.arctan2(
                    left_shoulder[1] - right_shoulder[1],
                    left_shoulder[0] - right_shoulder[0]
                ))
                analysis['shoulder_angle'] = shoulder_angle
            
            # ëª¸í†µ ê¸°ìš¸ê¸°
            if all(pose_keypoints[i][2] > 0.5 for i in [1, 8, 11]):  # ëª©, ì–‘ìª½ ì—‰ë©ì´
                neck = pose_keypoints[1][:2]
                hip_center = np.mean([pose_keypoints[8][:2], pose_keypoints[11][:2]], axis=0)
                torso_angle = np.degrees(np.arctan2(
                    neck[0] - hip_center[0],
                    hip_center[1] - neck[1]
                ))
                analysis['torso_angle'] = torso_angle
            
            # íŒ” ìœ„ì¹˜
            arm_angles = {}
            if all(pose_keypoints[i][2] > 0.5 for i in [2, 3, 4]):  # ì˜¤ë¥¸íŒ”
                shoulder = pose_keypoints[2][:2]
                elbow = pose_keypoints[3][:2]
                wrist = pose_keypoints[4][:2]
                
                upper_arm_angle = np.degrees(np.arctan2(
                    elbow[1] - shoulder[1], elbow[0] - shoulder[0]
                ))
                arm_angles['right_upper'] = upper_arm_angle
            
            if all(pose_keypoints[i][2] > 0.5 for i in [5, 6, 7]):  # ì™¼íŒ”
                shoulder = pose_keypoints[5][:2]
                elbow = pose_keypoints[6][:2]
                wrist = pose_keypoints[7][:2]
                
                upper_arm_angle = np.degrees(np.arctan2(
                    elbow[1] - shoulder[1], elbow[0] - shoulder[0]
                ))
                arm_angles['left_upper'] = upper_arm_angle
            
            analysis['arm_angles'] = arm_angles
            
        except Exception as e:
            self.logger.warning(f"í¬ì¦ˆ íŠ¹ì„± ë¶„ì„ ì‹¤íŒ¨: {e}")
        
        return analysis
    
    def _calculate_pose_adaptation(self, pose_analysis: Dict[str, Any], clothing_type: str) -> Dict[str, float]:
        """í¬ì¦ˆ ì ì‘ ì¸ìˆ˜ ê³„ì‚°"""
        
        adaptation = {
            'scale_factor': 1.0,
            'rotation_adjustment': 0.0,
            'shear_factor': 0.0
        }
        
        try:
            # ì–´ê¹¨ ê¸°ìš¸ê¸°ì— ë”°ë¥¸ íšŒì „ ì¡°ì •
            if 'shoulder_angle' in pose_analysis:
                shoulder_angle = pose_analysis['shoulder_angle']
                # ì–´ê¹¨ê°€ ê¸°ìš¸ì–´ì§„ ë§Œí¼ ì—­ë°©í–¥ìœ¼ë¡œ ì¡°ì •
                adaptation['rotation_adjustment'] = -shoulder_angle * 0.5
            
            # ëª¸í†µ ê¸°ìš¸ê¸°ì— ë”°ë¥¸ ì „ë‹¨ ì¡°ì •
            if 'torso_angle' in pose_analysis:
                torso_angle = pose_analysis['torso_angle']
                adaptation['shear_factor'] = np.tan(np.radians(torso_angle)) * 0.3
            
            # íŒ” ìœ„ì¹˜ì— ë”°ë¥¸ ìŠ¤ì¼€ì¼ ì¡°ì • (ìƒì˜ì˜ ê²½ìš°)
            if clothing_type in ['shirt', 't-shirt', 'blouse']:
                arm_angles = pose_analysis.get('arm_angles', {})
                if arm_angles:
                    # íŒ”ì´ ë²Œì–´ì§„ ì •ë„ì— ë”°ë¼ ìŠ¤ì¼€ì¼ ì¡°ì •
                    avg_arm_angle = np.mean(list(arm_angles.values()))
                    if abs(avg_arm_angle) > 45:  # íŒ”ì´ ë§ì´ ë²Œì–´ì§„ ê²½ìš°
                        adaptation['scale_factor'] = 1.1
                    elif abs(avg_arm_angle) < 15:  # íŒ”ì´ ëª¸ì— ë¶™ì€ ê²½ìš°
                        adaptation['scale_factor'] = 0.95
            
        except Exception as e:
            self.logger.warning(f"í¬ì¦ˆ ì ì‘ ê³„ì‚° ì‹¤íŒ¨: {e}")
        
        return adaptation
    
    def _adapt_transform_to_pose(
        self, 
        original_transform: List[List[float]], 
        adaptation_factor: Dict[str, float], 
        pose_analysis: Dict[str, Any]
    ) -> List[List[float]]:
        """í¬ì¦ˆì— ë§ê²Œ ë³€í™˜ ì¡°ì •"""
        
        try:
            transform = np.array(original_transform)
            
            # íšŒì „ ì¡°ì •
            rotation_adj = adaptation_factor.get('rotation_adjustment', 0.0)
            if abs(rotation_adj) > 0.1:
                cos_r = np.cos(np.radians(rotation_adj))
                sin_r = np.sin(np.radians(rotation_adj))
                rotation_matrix = np.array([[cos_r, -sin_r, 0], [sin_r, cos_r, 0], [0, 0, 1]])
                
                if transform.shape[0] == 2:  # Affine transform
                    transform = np.vstack([transform, [0, 0, 1]])
                    transform = rotation_matrix @ transform
                    transform = transform[:2]
                else:  # Homography
                    transform = rotation_matrix @ transform
            
            # ìŠ¤ì¼€ì¼ ì¡°ì •
            scale_factor = adaptation_factor.get('scale_factor', 1.0)
            if abs(scale_factor - 1.0) > 0.01:
                if transform.shape[0] == 2:  # Affine
                    transform[0, 0] *= scale_factor
                    transform[1, 1] *= scale_factor
                else:  # Homography
                    transform[:2, :2] *= scale_factor
            
            # ì „ë‹¨ ì¡°ì •
            shear_factor = adaptation_factor.get('shear_factor', 0.0)
            if abs(shear_factor) > 0.01:
                if transform.shape[0] == 2:  # Affine
                    transform[0, 1] += shear_factor
                else:  # Homography
                    transform[0, 1] += shear_factor
            
            return transform.tolist()
            
        except Exception as e:
            self.logger.warning(f"ë³€í™˜ í¬ì¦ˆ ì ì‘ ì‹¤íŒ¨: {e}")
            return original_transform
    
    def _evaluate_matching_quality(
        self, 
        person_points: List, 
        clothing_points: List, 
        match_result: Dict[str, Any]
    ) -> Dict[str, float]:
        """ë§¤ì¹­ í’ˆì§ˆ í‰ê°€"""
        
        try:
            transform = np.array(match_result['transform'])
            method = match_result['method']
            
            # 1. ì¬íˆ¬ì˜ ì˜¤ì°¨ ê³„ì‚°
            reprojection_error = self._calculate_reprojection_error(
                clothing_points, person_points, transform, method
            )
            
            # 2. ê¸°í•˜í•™ì  ì¼ê´€ì„±
            geometric_consistency = self._evaluate_geometric_consistency(transform, method)
            
            # 3. ë³€í™˜ ì•ˆì •ì„±
            transform_stability = self._evaluate_transform_stability(transform, method)
            
            # 4. ëŒ€ì‘ì  ì‹ ë¢°ë„
            correspondence_confidence = match_result.get('confidence', 0.5)
            
            # 5. ì „ì²´ í’ˆì§ˆ ì ìˆ˜
            overall_quality = (
                (1.0 - reprojection_error) * 0.4 +
                geometric_consistency * 0.3 +
                transform_stability * 0.2 +
                correspondence_confidence * 0.1
            )
            
            return {
                'overall_quality': max(0.0, min(1.0, overall_quality)),
                'reprojection_error': reprojection_error,
                'geometric_consistency': geometric_consistency,
                'transform_stability': transform_stability,
                'correspondence_confidence': correspondence_confidence,
                'quality_grade': self._get_quality_grade(overall_quality)
            }
            
        except Exception as e:
            self.logger.warning(f"í’ˆì§ˆ í‰ê°€ ì‹¤íŒ¨: {e}")
            return {
                'overall_quality': 0.5,
                'reprojection_error': 1.0,
                'geometric_consistency': 0.0,
                'transform_stability': 0.0,
                'correspondence_confidence': 0.0,
                'quality_grade': 'poor'
            }
    
    def _calculate_reprojection_error(
        self, 
        source_points: List, 
        target_points: List, 
        transform: np.ndarray, 
        method: str
    ) -> float:
        """ì¬íˆ¬ì˜ ì˜¤ì°¨ ê³„ì‚°"""
        
        try:
            if not source_points or not target_points:
                return 1.0
            
            source_array = np.array(source_points)
            target_array = np.array(target_points)
            
            # ë³€í™˜ ì ìš©
            if method == 'tps':
                # TPSëŠ” ë³„ë„ ì²˜ë¦¬ í•„ìš” (ì—¬ê¸°ì„œëŠ” ê°„ë‹¨í™”)
                projected_points = source_array  # ì„ì‹œ
            elif method in ['homography']:
                # ë™ì°¨ ì¢Œí‘œë¡œ ë³€í™˜
                source_homo = np.column_stack([source_array, np.ones(len(source_array))])
                projected_homo = source_homo @ transform.T
                projected_points = projected_homo[:, :2] / projected_homo[:, 2:3]
            else:  # affine, similarity
                source_homo = np.column_stack([source_array, np.ones(len(source_array))])
                projected_points = source_homo @ transform.T
            
            # ê°€ì¥ ê°€ê¹Œìš´ ëŒ€ì‘ì ë“¤ ì°¾ê¸°
            min_len = min(len(projected_points), len(target_array))
            distances = cdist(projected_points[:min_len], target_array[:min_len])
            
            # ìµœì†Œ ê±°ë¦¬ë“¤ì˜ í‰ê· 
            min_distances = np.min(distances, axis=1)
            avg_error = np.mean(min_distances)
            
            # ì •ê·œí™” (ì´ë¯¸ì§€ í¬ê¸° ëŒ€ë¹„)
            if target_array.size > 0:
                image_diagonal = np.linalg.norm(np.ptp(target_array, axis=0))
                normalized_error = avg_error / (image_diagonal + 1e-6)
            else:
                normalized_error = 1.0
            
            return min(1.0, normalized_error)
            
        except Exception as e:
            self.logger.warning(f"ì¬íˆ¬ì˜ ì˜¤ì°¨ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return 1.0
    
    def _evaluate_geometric_consistency(self, transform: np.ndarray, method: str) -> float:
        """ê¸°í•˜í•™ì  ì¼ê´€ì„± í‰ê°€"""
        
        try:
            if method == 'tps':
                # TPSëŠ” í•­ìƒ ì¼ê´€ì„± ìˆìŒ
                return 0.9
            
            if transform.shape[0] < 2:
                return 0.0
            
            # í–‰ë ¬ì‹ ê³„ì‚° (ìŠ¤ì¼€ì¼ ë³€í™”)
            if transform.shape == (2, 3):  # Affine
                det = np.linalg.det(transform[:2, :2])
            else:  # Homography
                det = np.linalg.det(transform[:2, :2])
            
            # í•©ë¦¬ì ì¸ ìŠ¤ì¼€ì¼ ë³€í™”ì¸ì§€ í™•ì¸ (0.1 ~ 10 ë°°)
            if 0.1 <= abs(det) <= 10:
                scale_consistency = 1.0
            else:
                scale_consistency = 0.0
            
            # íšŒì „ ê°ë„ í™•ì¸
            if transform.shape == (2, 3):
                rotation_matrix = transform[:2, :2]
                if abs(det) > 1e-6:
                    U, _, Vt = np.linalg.svd(rotation_matrix)
                    rotation_part = U @ Vt
                    # ì§êµì„± í™•ì¸
                    orthogonality = np.linalg.norm(rotation_part @ rotation_part.T - np.eye(2))
                    rotation_consistency = max(0.0, 1.0 - orthogonality)
                else:
                    rotation_consistency = 0.0
            else:
                rotation_consistency = 0.8  # Homographyì˜ ê²½ìš° ê¸°ë³¸ê°’
            
            consistency = (scale_consistency + rotation_consistency) / 2
            return min(1.0, max(0.0, consistency))
            
        except Exception as e:
            self.logger.warning(f"ê¸°í•˜í•™ì  ì¼ê´€ì„± í‰ê°€ ì‹¤íŒ¨: {e}")
            return 0.5
    
    def _evaluate_transform_stability(self, transform: np.ndarray, method: str) -> float:
        """ë³€í™˜ ì•ˆì •ì„± í‰ê°€"""
        
        try:
            # ì¡°ê±´ìˆ˜ í™•ì¸
            if transform.shape == (2, 3):  # Affine
                matrix_part = transform[:2, :2]
            else:  # Homography
                matrix_part = transform[:2, :2]
            
            condition_number = np.linalg.cond(matrix_part)
            
            # ì¡°ê±´ìˆ˜ê°€ ë‚®ì„ìˆ˜ë¡ ì•ˆì •ì 
            if condition_number < 10:
                stability = 1.0
            elif condition_number < 100:
                stability = 0.8
            elif condition_number < 1000:
                stability = 0.5
            else:
                stability = 0.2
            
            # íŠ¹ì´ê°’ ë¶„ì„
            singular_values = np.linalg.svd(matrix_part, compute_uv=False)
            sv_ratio = np.max(singular_values) / (np.min(singular_values) + 1e-6)
            
            if sv_ratio < 5:
                sv_stability = 1.0
            elif sv_ratio < 20:
                sv_stability = 0.7
            else:
                sv_stability = 0.3
            
            return (stability + sv_stability) / 2
            
        except Exception as e:
            self.logger.warning(f"ë³€í™˜ ì•ˆì •ì„± í‰ê°€ ì‹¤íŒ¨: {e}")
            return 0.5
    
    def _get_quality_grade(self, overall_quality: float) -> str:
        """í’ˆì§ˆ ë“±ê¸‰ ë°˜í™˜"""
        if overall_quality >= 0.9:
            return "excellent"
        elif overall_quality >= 0.8:
            return "good"
        elif overall_quality >= 0.6:
            return "fair"
        elif overall_quality >= 0.4:
            return "poor"
        else:
            return "very_poor"
    
    async def _try_alternative_methods(
        self, 
        person_points: List, 
        clothing_points: List, 
        clothing_type: str
    ) -> Dict[str, Any]:
        """ëŒ€ì•ˆ ë§¤ì¹­ ë°©ë²•ë“¤ ì‹œë„"""
        
        alternative_methods = ['affine', 'similarity', 'homography']
        best_result = None
        best_quality = 0.0
        
        for method in alternative_methods:
            try:
                result = await self._perform_initial_matching(person_points, clothing_points, method)
                quality = self._evaluate_matching_quality(person_points, clothing_points, result)
                
                if quality['overall_quality'] > best_quality:
                    best_quality = quality['overall_quality']
                    best_result = result
                    
                self.logger.debug(f"ëŒ€ì•ˆ ë°©ë²• {method}: í’ˆì§ˆ {quality['overall_quality']:.3f}")
                
            except Exception as e:
                self.logger.warning(f"ëŒ€ì•ˆ ë°©ë²• {method} ì‹¤íŒ¨: {e}")
                continue
        
        return best_result if best_result else {
            'method': 'identity',
            'transform': [[1, 0, 0], [0, 1, 0]],
            'confidence': 0.3
        }
    
    def _generate_warp_parameters(self, match_result: Dict[str, Any], clothing_segmentation: Dict[str, Any]) -> Dict[str, Any]:
        """ì›Œí•‘ íŒŒë¼ë¯¸í„° ìƒì„±"""
        
        try:
            transform = match_result['transform']
            method = match_result['method']
            
            # ê¸°ë³¸ ì›Œí•‘ íŒŒë¼ë¯¸í„°
            warp_params = {
                'transform_matrix': transform,
                'transform_method': method,
                'interpolation': 'bilinear',
                'border_mode': 'reflect',
                'output_size': None  # ì›ë³¸ í¬ê¸° ìœ ì§€
            }
            
            # ì˜ë¥˜ ë§ˆìŠ¤í¬ ì •ë³´ ì¶”ê°€
            if 'mask' in clothing_segmentation:
                mask = clothing_segmentation['mask']
                warp_params['mask_transform'] = transform  # ë§ˆìŠ¤í¬ë„ ê°™ì€ ë³€í™˜ ì ìš©
                warp_params['original_mask_size'] = mask.shape
            
            # ë°©ë²•ë³„ íŠ¹í™” íŒŒë¼ë¯¸í„°
            if method == 'tps':
                warp_params.update({
                    'source_points': match_result.get('source_points', []),
                    'target_points': match_result.get('target_points', []),
                    'tps_weights': transform.get('weights', []) if isinstance(transform, dict) else [],
                    'tps_affine': transform.get('affine_coeffs', []) if isinstance(transform, dict) else []
                })
            
            # í’ˆì§ˆ ê¸°ë°˜ íŒŒë¼ë¯¸í„° ì¡°ì •
            if 'quality_metrics' in match_result:
                quality = match_result['quality_metrics']['overall_quality']
                if quality < 0.6:
                    warp_params['interpolation'] = 'nearest'  # ë‚®ì€ í’ˆì§ˆì¼ ë•ŒëŠ” ë³´ê°„ ë‹¨ìˆœí™”
                elif quality > 0.8:
                    warp_params['interpolation'] = 'bicubic'   # ë†’ì€ í’ˆì§ˆì¼ ë•ŒëŠ” ê³ ê¸‰ ë³´ê°„
            
            return warp_params
            
        except Exception as e:
            self.logger.warning(f"ì›Œí•‘ íŒŒë¼ë¯¸í„° ìƒì„± ì‹¤íŒ¨: {e}")
            return {
                'transform_matrix': [[1, 0, 0], [0, 1, 0]],
                'transform_method': 'identity',
                'interpolation': 'bilinear',
                'border_mode': 'reflect'
            }
    
    def _build_final_result(
        self,
        match_result: Dict[str, Any],
        warp_params: Dict[str, Any],
        quality_metrics: Dict[str, float],
        processing_time: float,
        method: str,
        clothing_type: str
    ) -> Dict[str, Any]:
        """ìµœì¢… ê²°ê³¼ êµ¬ì„±"""
        
        return {
            'success': True,
            'transform_matrix': match_result['transform'],
            'warp_matrix': match_result['transform'],  # í˜¸í™˜ì„±ì„ ìœ„í•œ ì¤‘ë³µ
            'warp_parameters': warp_params,
            'matching_method': method,
            'clothing_type': clothing_type,
            'quality_metrics': quality_metrics,
            'confidence': quality_metrics['overall_quality'],
            'processing_time': processing_time,
            'matching_info': {
                'source_points': match_result.get('source_points', []),
                'target_points': match_result.get('target_points', []),
                'correspondences': match_result.get('correspondences', []),
                'pose_adapted': match_result.get('pose_adapted', False),
                'method_used': method
            },
            'geometric_analysis': {
                'reprojection_error': quality_metrics['reprojection_error'],
                'geometric_consistency': quality_metrics['geometric_consistency'],
                'transform_stability': quality_metrics['transform_stability'],
                'quality_grade': quality_metrics['quality_grade']
            }
        }
    
    def _create_empty_result(self, reason: str) -> Dict[str, Any]:
        """ë¹ˆ ê²°ê³¼ ìƒì„±"""
        return {
            'success': False,
            'error': reason,
            'transform_matrix': [[1, 0, 0], [0, 1, 0]],
            'warp_matrix': [[1, 0, 0], [0, 1, 0]],
            'warp_parameters': {
                'transform_matrix': [[1, 0, 0], [0, 1, 0]],
                'transform_method': 'identity',
                'interpolation': 'bilinear'
            },
            'matching_method': 'none',
            'clothing_type': 'unknown',
            'quality_metrics': {
                'overall_quality': 0.0,
                'quality_grade': 'failed'
            },
            'confidence': 0.0,
            'processing_time': 0.0,
            'matching_info': {
                'error_occurred': True,
                'method_used': 'none'
            }
        }
    
    def _update_statistics(self, method: str, quality: float):
        """í†µê³„ ì—…ë°ì´íŠ¸"""
        self.matching_stats['total_matches'] += 1
        
        if quality > 0.6:
            self.matching_stats['successful_matches'] += 1
        
        # í’ˆì§ˆ ì´ë™ í‰ê· 
        alpha = 0.1
        self.matching_stats['average_accuracy'] = (
            alpha * quality + 
            (1 - alpha) * self.matching_stats['average_accuracy']
        )
        
        # ë°©ë²•ë³„ ì„±ëŠ¥ ì¶”ì 
        if method not in self.matching_stats['method_performance']:
            self.matching_stats['method_performance'][method] = {'count': 0, 'avg_quality': 0.0}
        
        method_stats = self.matching_stats['method_performance'][method]
        method_stats['count'] += 1
        method_stats['avg_quality'] = (
            (method_stats['avg_quality'] * (method_stats['count'] - 1) + quality) / 
            method_stats['count']
        )
    
    async def _initialize_matching_algorithms(self):
        """ë§¤ì¹­ ì•Œê³ ë¦¬ì¦˜ ì´ˆê¸°í™”"""
        try:
            # TPS ê·¸ë¦¬ë“œ ì´ˆê¸°í™”
            grid_size = self.tps_config['grid_size']
            self.tps_grid = np.mgrid[0:grid_size, 0:grid_size].reshape(2, -1).T
            
            # RANSAC íŒŒë¼ë¯¸í„° ì„¤ì •
            self.ransac_params = {
                'max_trials': 1000,
                'residual_threshold': 5.0,
                'min_samples': 4
            }
            
            self.logger.info("âœ… ë§¤ì¹­ ì•Œê³ ë¦¬ì¦˜ ì´ˆê¸°í™” ì™„ë£Œ")
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ ë§¤ì¹­ ì•Œê³ ë¦¬ì¦˜ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    
    async def _initialize_optimization_tools(self):
        """ìµœì í™” ë„êµ¬ ì´ˆê¸°í™”"""
        try:
            # ìµœì í™” ê¸°ë²• ì„¤ì •
            self.optimizer_config = {
                'method': 'L-BFGS-B',
                'options': {
                    'maxiter': self.matching_config['max_iterations'],
                    'ftol': self.matching_config['convergence_threshold']
                }
            }
            
            self.logger.info("âœ… ìµœì í™” ë„êµ¬ ì´ˆê¸°í™” ì™„ë£Œ")
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ ìµœì í™” ë„êµ¬ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    
    async def cleanup(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        try:
            # ìºì‹œëœ ë°ì´í„° ì •ë¦¬
            if hasattr(self, 'tps_grid'):
                del self.tps_grid
            
            # í†µê³„ ì´ˆê¸°í™”
            self.matching_stats = {
                'total_matches': 0,
                'successful_matches': 0,
                'average_accuracy': 0.0,
                'method_performance': {}
            }
            
            self.is_initialized = False
            self.logger.info("ğŸ§¹ ê¸°í•˜í•™ì  ë§¤ì¹­ ìŠ¤í… ì •ë¦¬ ì™„ë£Œ")
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")