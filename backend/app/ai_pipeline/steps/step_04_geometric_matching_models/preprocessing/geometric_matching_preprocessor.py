"""
ğŸ”¥ Geometric Matching ì „ìš© ì „ì²˜ë¦¬ ì‹œìŠ¤í…œ
========================================

ê¸°í•˜í•™ì  ë§¤ì¹­ì— ìµœì í™”ëœ ì „ì²˜ë¦¬ ê¸°ëŠ¥ë“¤:
1. ì˜ë¥˜ ì •ê·œí™” ë° ì •ë ¬
2. ê¸°í•˜í•™ì  ë³€í™˜ ë§¤íŠ¸ë¦­ìŠ¤ ê³„ì‚°
3. ìŠ¤ì¼€ì¼ ë° íšŒì „ ì •ë ¬
4. ì™œê³¡ ë³´ì • ë° ì •ê·œí™”
5. ë§¤ì¹­ í’ˆì§ˆ ìµœì í™”

Author: MyCloset AI Team
Date: 2025-01-27
Version: 1.0 (ì™„ì „ êµ¬í˜„)
"""

import cv2
import numpy as np
import torch
import torch.nn.functional as F
from typing import Dict, Any, Optional, Tuple, List
import logging
from PIL import Image
import matplotlib.pyplot as plt
import matplotlib.patches as patches

logger = logging.getLogger(__name__)

class GeometricMatchingPreprocessor:
    """ê¸°í•˜í•™ì  ë§¤ì¹­ì— ìµœì í™”ëœ ì „ì²˜ë¦¬ ì‹œìŠ¤í…œ"""
    
    def __init__(self, target_size: Tuple[int, int] = (512, 512)):
        self.target_size = target_size
        self.logger = logging.getLogger(f"{__name__}.GeometricMatchingPreprocessor")
        
        # ê¸°í•˜í•™ì  ë§¤ì¹­ìš© ì „ì²˜ë¦¬ íŒŒë¼ë¯¸í„°
        self.geometric_params = {
            'normalization': True,
            'alignment': True,
            'distortion_correction': True,
            'scale_matching': True,
            'rotation_correction': True
        }
        
        # ì²˜ë¦¬ í†µê³„
        self.processing_stats = {
            'images_processed': 0,
            'geometric_transforms': 0,
            'distortions_corrected': 0,
            'alignments_applied': 0
        }
    
    def preprocess_image(self, image: np.ndarray, mode: str = 'advanced') -> Dict[str, Any]:
        """ê¸°í•˜í•™ì  ë§¤ì¹­ì„ ìœ„í•œ ì™„ì „í•œ ì „ì²˜ë¦¬"""
        try:
            self.processing_stats['images_processed'] += 1
            self.logger.info(f"ğŸ”¥ ê¸°í•˜í•™ì  ë§¤ì¹­ ì „ì²˜ë¦¬ ì‹œì‘ (ëª¨ë“œ: {mode})")
            
            # 1. ì´ë¯¸ì§€ ê²€ì¦
            validated_image = self._validate_image(image)
            
            # 2. ê¸°í•˜í•™ì  ì •ê·œí™”
            normalized_image, geometric_info = self._normalize_geometry(validated_image)
            if geometric_info['transform_applied']:
                self.processing_stats['geometric_transforms'] += 1
            
            # 3. í•´ìƒë„ í‘œì¤€í™”
            resized_image = self._standardize_resolution(normalized_image)
            
            # 4. ê¸°í•˜í•™ì  ë§¤ì¹­ ìµœì í™”
            if mode == 'advanced':
                optimized_image = self._optimize_for_geometric_matching(resized_image)
                self.processing_stats['distortions_corrected'] += 1
                self.processing_stats['alignments_applied'] += 1
            else:
                optimized_image = resized_image
            
            # 5. ì •ê·œí™” ë° í…ì„œ ë³€í™˜
            normalized_tensor = self._normalize_and_convert(optimized_image)
            
            # 6. ì „ì²˜ë¦¬ ê²°ê³¼ ìš”ì•½
            preprocessing_result = {
                'processed_image': optimized_image,
                'tensor': normalized_tensor,
                'geometric_info': geometric_info,
                'target_size': self.target_size,
                'mode': mode,
                'geometric_params': self.geometric_params,
                'success': True
            }
            
            self.logger.info("âœ… ê¸°í•˜í•™ì  ë§¤ì¹­ ì „ì²˜ë¦¬ ì™„ë£Œ")
            return preprocessing_result
            
        except Exception as e:
            self.logger.error(f"âŒ ê¸°í•˜í•™ì  ë§¤ì¹­ ì „ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return {
                'success': False,
                'error': str(e),
                'processed_image': image,
                'tensor': torch.randn(1, 3, *self.target_size)
            }
    
    def _validate_image(self, image: np.ndarray) -> np.ndarray:
        """ì´ë¯¸ì§€ ìœ íš¨ì„± ê²€ì¦ ë° ë³€í™˜"""
        try:
            # PIL Imageë¥¼ NumPyë¡œ ë³€í™˜
            if isinstance(image, Image.Image):
                image = np.array(image)
            
            # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ì„ RGBë¡œ ë³€í™˜
            if len(image.shape) == 2:
                image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)
            elif image.shape[2] == 4:  # RGBA
                image = cv2.cvtColor(image, cv2.COLOR_RGBA2RGB)
            
            # ë°ì´í„° íƒ€ì… ì •ê·œí™”
            if image.dtype != np.uint8:
                image = image.astype(np.uint8)
            
            return image
            
        except Exception as e:
            self.logger.warning(f"ì´ë¯¸ì§€ ê²€ì¦ ì‹¤íŒ¨: {e}")
            return image
    
    def _normalize_geometry(self, image: np.ndarray) -> Tuple[np.ndarray, Dict[str, Any]]:
        """ê¸°í•˜í•™ì  ì •ê·œí™”"""
        try:
            # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜
            gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
            
            # 1. ì—£ì§€ ê°ì§€
            edges = cv2.Canny(gray, 50, 150)
            
            # 2. ìœ¤ê³½ì„  ì°¾ê¸°
            contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            
            # 3. ê°€ì¥ í° ìœ¤ê³½ì„  ì°¾ê¸° (ì˜ë¥˜ ì˜ì—­)
            if contours:
                largest_contour = max(contours, key=cv2.contourArea)
                
                # 4. ê²½ê³„ ì‚¬ê°í˜• ê³„ì‚°
                x, y, w, h = cv2.boundingRect(largest_contour)
                
                # 5. ê¸°í•˜í•™ì  ì¤‘ì‹¬ ê³„ì‚°
                center_x = x + w // 2
                center_y = y + h // 2
                
                # 6. íšŒì „ ê°ë„ ê³„ì‚° (ìµœì†Œ ê²½ê³„ ì‚¬ê°í˜•)
                rect = cv2.minAreaRect(largest_contour)
                angle = rect[2]
                
                # 7. ê¸°í•˜í•™ì  ì •ê·œí™” ì ìš©
                normalized = self._apply_geometric_transform(image, center_x, center_y, angle)
                
                geometric_info = {
                    'transform_applied': True,
                    'center': (center_x, center_y),
                    'rotation_angle': angle,
                    'bounding_box': (x, y, w, h),
                    'contour_area': cv2.contourArea(largest_contour),
                    'original_size': image.shape[:2],
                    'normalized_size': normalized.shape[:2]
                }
                
                return normalized, geometric_info
            else:
                # ìœ¤ê³½ì„ ì´ ì—†ëŠ” ê²½ìš° ì›ë³¸ ë°˜í™˜
                return image, {
                    'transform_applied': False,
                    'center': (image.shape[1]//2, image.shape[0]//2),
                    'rotation_angle': 0.0,
                    'bounding_box': (0, 0, image.shape[1], image.shape[0]),
                    'contour_area': 0,
                    'original_size': image.shape[:2],
                    'normalized_size': image.shape[:2]
                }
                
        except Exception as e:
            self.logger.warning(f"ê¸°í•˜í•™ì  ì •ê·œí™” ì‹¤íŒ¨: {e}")
            return image, {
                'transform_applied': False,
                'center': (image.shape[1]//2, image.shape[0]//2),
                'rotation_angle': 0.0,
                'bounding_box': (0, 0, image.shape[1], image.shape[0]),
                'contour_area': 0,
                'original_size': image.shape[:2],
                'normalized_size': image.shape[:2]
            }
    
    def _apply_geometric_transform(self, image: np.ndarray, center_x: int, center_y: int, angle: float) -> np.ndarray:
        """ê¸°í•˜í•™ì  ë³€í™˜ ì ìš©"""
        try:
            # íšŒì „ ì¤‘ì‹¬ì 
            center = (center_x, center_y)
            
            # íšŒì „ í–‰ë ¬ ê³„ì‚°
            rotation_matrix = cv2.getRotationMatrix2D(center, angle, 1.0)
            
            # íšŒì „ ì ìš©
            rotated = cv2.warpAffine(image, rotation_matrix, (image.shape[1], image.shape[0]))
            
            # ì¤‘ì‹¬ í¬ë¡­ (ì •ì‚¬ê°í˜•)
            h, w = rotated.shape[:2]
            crop_size = min(w, h)
            
            x1 = max(0, center_x - crop_size // 2)
            y1 = max(0, center_y - crop_size // 2)
            x2 = min(w, x1 + crop_size)
            y2 = min(h, y1 + crop_size)
            
            cropped = rotated[y1:y2, x1:x2]
            
            return cropped
            
        except Exception as e:
            self.logger.warning(f"ê¸°í•˜í•™ì  ë³€í™˜ ì ìš© ì‹¤íŒ¨: {e}")
            return image
    
    def _standardize_resolution(self, image: np.ndarray) -> np.ndarray:
        """í•´ìƒë„ í‘œì¤€í™”"""
        try:
            # ëª©í‘œ í•´ìƒë„ë¡œ ë¦¬ì‚¬ì´ì¦ˆ
            resized = cv2.resize(image, self.target_size, interpolation=cv2.INTER_LANCZOS4)
            return resized
            
        except Exception as e:
            self.logger.warning(f"í•´ìƒë„ í‘œì¤€í™” ì‹¤íŒ¨: {e}")
            return image
    
    def _optimize_for_geometric_matching(self, image: np.ndarray) -> np.ndarray:
        """ê¸°í•˜í•™ì  ë§¤ì¹­ ìµœì í™”"""
        try:
            optimized = image.copy()
            
            # 1. ê¸°í•˜í•™ì  ì •ê·œí™”
            if self.geometric_params['normalization']:
                optimized = self._apply_geometric_normalization(optimized)
            
            # 2. ì •ë ¬ ìµœì í™”
            if self.geometric_params['alignment']:
                optimized = self._optimize_alignment(optimized)
            
            # 3. ì™œê³¡ ë³´ì •
            if self.geometric_params['distortion_correction']:
                optimized = self._correct_distortion(optimized)
            
            # 4. ìŠ¤ì¼€ì¼ ë§¤ì¹­
            if self.geometric_params['scale_matching']:
                optimized = self._optimize_scale(optimized)
            
            # 5. íšŒì „ ë³´ì •
            if self.geometric_params['rotation_correction']:
                optimized = self._correct_rotation(optimized)
            
            return optimized
            
        except Exception as e:
            self.logger.warning(f"ê¸°í•˜í•™ì  ë§¤ì¹­ ìµœì í™” ì‹¤íŒ¨: {e}")
            return image
    
    def _apply_geometric_normalization(self, image: np.ndarray) -> np.ndarray:
        """ê¸°í•˜í•™ì  ì •ê·œí™” ì ìš©"""
        try:
            # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜
            gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
            
            # íˆìŠ¤í† ê·¸ë¨ í‰í™œí™”
            normalized = cv2.equalizeHist(gray)
            
            # ì—£ì§€ ê°•í™”
            edges = cv2.Canny(normalized, 30, 100)
            
            # ì—£ì§€ë¥¼ RGBë¡œ ë³€í™˜
            edges_rgb = cv2.cvtColor(edges, cv2.COLOR_GRAY2RGB)
            
            # ì›ë³¸ê³¼ ì—£ì§€ í•©ì„±
            enhanced = cv2.addWeighted(image, 0.8, edges_rgb, 0.2, 0)
            
            return enhanced
            
        except Exception as e:
            self.logger.warning(f"ê¸°í•˜í•™ì  ì •ê·œí™” ì ìš© ì‹¤íŒ¨: {e}")
            return image
    
    def _optimize_alignment(self, image: np.ndarray) -> np.ndarray:
        """ì •ë ¬ ìµœì í™”"""
        try:
            # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜
            gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
            
            # ëª¨ë©˜íŠ¸ ê³„ì‚°
            moments = cv2.moments(gray)
            
            if moments['m00'] != 0:
                # ì§ˆëŸ‰ ì¤‘ì‹¬ ê³„ì‚°
                center_x = int(moments['m10'] / moments['m00'])
                center_y = int(moments['m01'] / moments['m00'])
                
                # ì´ë¯¸ì§€ ì¤‘ì‹¬ê³¼ì˜ ì°¨ì´ ê³„ì‚°
                h, w = image.shape[:2]
                target_center = (w // 2, h // 2)
                
                # ì´ë™ ë²¡í„° ê³„ì‚°
                dx = target_center[0] - center_x
                dy = target_center[1] - center_y
                
                # ì´ë™ í–‰ë ¬ ìƒì„±
                translation_matrix = np.float32([[1, 0, dx], [0, 1, dy]])
                
                # ì´ë™ ì ìš©
                aligned = cv2.warpAffine(image, translation_matrix, (w, h))
                
                return aligned
            
            return image
            
        except Exception as e:
            self.logger.warning(f"ì •ë ¬ ìµœì í™” ì‹¤íŒ¨: {e}")
            return image
    
    def _correct_distortion(self, image: np.ndarray) -> np.ndarray:
        """ì™œê³¡ ë³´ì •"""
        try:
            # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜
            gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
            
            # ê°€ìš°ì‹œì•ˆ ë¸”ëŸ¬ë¡œ ë…¸ì´ì¦ˆ ì œê±°
            blurred = cv2.GaussianBlur(gray, (5, 5), 0)
            
            # ì–¸ìƒ¤í”„ ë§ˆìŠ¤í‚¹ìœ¼ë¡œ ì„ ëª…ë„ í–¥ìƒ
            sharpened = cv2.addWeighted(gray, 1.5, blurred, -0.5, 0)
            
            # ì™œê³¡ ë³´ì •ì„ ìœ„í•œ í•„í„°ë§
            corrected = cv2.medianBlur(sharpened, 3)
            
            # RGBë¡œ ë³€í™˜
            corrected_rgb = cv2.cvtColor(corrected, cv2.COLOR_GRAY2RGB)
            
            return corrected_rgb
            
        except Exception as e:
            self.logger.warning(f"ì™œê³¡ ë³´ì • ì‹¤íŒ¨: {e}")
            return image
    
    def _optimize_scale(self, image: np.ndarray) -> np.ndarray:
        """ìŠ¤ì¼€ì¼ ìµœì í™”"""
        try:
            # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜
            gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
            
            # ë¡œì»¬ ì´ì§„ íŒ¨í„´ (LBP) ê³„ì‚°ìœ¼ë¡œ í…ìŠ¤ì²˜ íŠ¹ì„± ë¶„ì„
            lbp = self._calculate_lbp(gray)
            
            # ìŠ¤ì¼€ì¼ ìµœì í™”ë¥¼ ìœ„í•œ í•„í„°ë§
            optimized = cv2.bilateralFilter(image, 9, 75, 75)
            
            # ëŒ€ë¹„ í–¥ìƒ
            optimized = cv2.convertScaleAbs(optimized, alpha=1.1, beta=5)
            
            return optimized
            
        except Exception as e:
            self.logger.warning(f"ìŠ¤ì¼€ì¼ ìµœì í™” ì‹¤íŒ¨: {e}")
            return image
    
    def _calculate_lbp(self, gray_image: np.ndarray) -> np.ndarray:
        """ë¡œì»¬ ì´ì§„ íŒ¨í„´ ê³„ì‚°"""
        try:
            h, w = gray_image.shape
            lbp = np.zeros((h-2, w-2), dtype=np.uint8)
            
            for i in range(1, h-1):
                for j in range(1, w-1):
                    center = gray_image[i, j]
                    code = 0
                    
                    # 8-ì´ì›ƒ í”½ì…€ ê²€ì‚¬
                    neighbors = [
                        gray_image[i-1, j-1], gray_image[i-1, j], gray_image[i-1, j+1],
                        gray_image[i, j+1], gray_image[i+1, j+1], gray_image[i+1, j],
                        gray_image[i+1, j-1], gray_image[i, j-1]
                    ]
                    
                    for k, neighbor in enumerate(neighbors):
                        if neighbor >= center:
                            code |= (1 << k)
                    
                    lbp[i-1, j-1] = code
            
            return lbp
            
        except Exception as e:
            self.logger.warning(f"LBP ê³„ì‚° ì‹¤íŒ¨: {e}")
            return np.zeros_like(gray_image)
    
    def _correct_rotation(self, image: np.ndarray) -> np.ndarray:
        """íšŒì „ ë³´ì •"""
        try:
            # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜
            gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
            
            # ì—£ì§€ ê°ì§€
            edges = cv2.Canny(gray, 50, 150)
            
            # ì§ì„  ê°ì§€ (Hough ë³€í™˜)
            lines = cv2.HoughLines(edges, 1, np.pi/180, threshold=100)
            
            if lines is not None:
                # ì£¼ìš” ë°©í–¥ ê³„ì‚°
                angles = []
                for rho, theta in lines[:10]:  # ìƒìœ„ 10ê°œ ì„ ë§Œ ì‚¬ìš©
                    angle = theta * 180 / np.pi
                    if angle < 90:
                        angles.append(angle)
                    else:
                        angles.append(angle - 180)
                
                if angles:
                    # í‰ê·  ê°ë„ ê³„ì‚°
                    mean_angle = np.mean(angles)
                    
                    # íšŒì „ ë³´ì •
                    h, w = image.shape[:2]
                    center = (w // 2, h // 2)
                    rotation_matrix = cv2.getRotationMatrix2D(center, mean_angle, 1.0)
                    corrected = cv2.warpAffine(image, rotation_matrix, (w, h))
                    
                    return corrected
            
            return image
            
        except Exception as e:
            self.logger.warning(f"íšŒì „ ë³´ì • ì‹¤íŒ¨: {e}")
            return image
    
    def _normalize_and_convert(self, image: np.ndarray) -> torch.Tensor:
        """ì •ê·œí™” ë° í…ì„œ ë³€í™˜"""
        try:
            # 0-1 ë²”ìœ„ë¡œ ì •ê·œí™”
            normalized = image.astype(np.float32) / 255.0
            
            # ImageNet í‰ê· /í‘œì¤€í¸ì°¨ë¡œ ì •ê·œí™”
            mean = np.array([0.485, 0.456, 0.406])
            std = np.array([0.229, 0.224, 0.225])
            
            normalized = (normalized - mean) / std
            
            # í…ì„œë¡œ ë³€í™˜ [H, W, C] -> [C, H, W] -> [1, C, H, W]
            tensor = torch.from_numpy(normalized).permute(2, 0, 1).unsqueeze(0)
            
            return tensor
            
        except Exception as e:
            self.logger.warning(f"ì •ê·œí™” ë° ë³€í™˜ ì‹¤íŒ¨: {e}")
            return torch.randn(1, 3, *self.target_size)
    
    def get_processing_stats(self) -> Dict[str, Any]:
        """ì²˜ë¦¬ í†µê³„ ë°˜í™˜"""
        return self.processing_stats.copy()
    
    def reset_stats(self):
        """í†µê³„ ì´ˆê¸°í™”"""
        self.processing_stats = {
            'images_processed': 0,
            'geometric_transforms': 0,
            'distortions_corrected': 0,
            'alignments_applied': 0
        }
    
    def update_geometric_params(self, **kwargs):
        """ê¸°í•˜í•™ì  ë§¤ì¹­ íŒŒë¼ë¯¸í„° ì—…ë°ì´íŠ¸"""
        for key, value in kwargs.items():
            if key in self.geometric_params:
                self.geometric_params[key] = value
                self.logger.info(f"ê¸°í•˜í•™ì  ë§¤ì¹­ íŒŒë¼ë¯¸í„° ì—…ë°ì´íŠ¸: {key} = {value}")
