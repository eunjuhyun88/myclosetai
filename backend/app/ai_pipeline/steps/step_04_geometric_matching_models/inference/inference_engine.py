#!/usr/bin/env python3
"""
ğŸ”¥ MyCloset AI - Geometric Matching Inference Engine
====================================================

ğŸ¯ ê¸°í•˜í•™ì  ë§¤ì¹­ ì¶”ë¡  ì—”ì§„
âœ… ë‹¤ì¤‘ ëª¨ë¸ ì¶”ë¡  ê´€ë¦¬
âœ… M3 Max ìµœì í™”
âœ… ë©”ëª¨ë¦¬ íš¨ìœ¨ì  ì²˜ë¦¬
âœ… ì‹¤ì‹œê°„ ì¶”ë¡  ì§€ì›
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import logging
from typing import Dict, List, Tuple, Optional, Union, Any
from dataclasses import dataclass
import time
import cv2

# ë¡œê±° ì„¤ì •
logger = logging.getLogger(__name__)

@dataclass
class InferenceConfig:
    """ì¶”ë¡  ì„¤ì •"""
    batch_size: int = 1
    use_mps: bool = True
    memory_efficient: bool = True
    enable_ensemble: bool = True
    confidence_threshold: float = 0.5
    max_models: int = 8

class GeometricMatchingInferenceEngine(nn.Module):
    """
    ğŸ”¥ Geometric Matching ì¶”ë¡  ì—”ì§„
    
    ê¸°í•˜í•™ì  ë§¤ì¹­ì„ ìœ„í•œ ê³ ì„±ëŠ¥ ì¶”ë¡  ì‹œìŠ¤í…œì…ë‹ˆë‹¤.
    """
    
    def __init__(self, config: InferenceConfig = None):
        super().__init__()
        self.config = config or InferenceConfig()
        self.logger = logging.getLogger(__name__)
        
        # MPS ë””ë°”ì´ìŠ¤ í™•ì¸
        self.device = torch.device("mps" if torch.backends.mps.is_available() and self.config.use_mps else "cpu")
        self.logger.info(f"ğŸ¯ Geometric Matching ì¶”ë¡  ì—”ì§„ ì´ˆê¸°í™” (ë””ë°”ì´ìŠ¤: {self.device})")
        
        # ëª¨ë¸ ì´ˆê¸°í™”
        self.models = {}
        self.model_weights = {}
        self.ensemble_system = None
        
        # ì¶”ë¡  í†µê³„
        self.inference_stats = {
            "total_inferences": 0,
            "total_time": 0.0,
            "avg_time": 0.0,
            "success_rate": 1.0
        }
        
        self.logger.info("âœ… Geometric Matching ì¶”ë¡  ì—”ì§„ ì´ˆê¸°í™” ì™„ë£Œ")
    
    def load_model(self, model_name: str, model_path: str, weight: float = 1.0):
        """ëª¨ë¸ ë¡œë“œ"""
        try:
            # ì‹¤ì œ ëª¨ë¸ ë¡œë“œ ë¡œì§ (ì—¬ê¸°ì„œëŠ” ë”ë¯¸ ëª¨ë¸ ìƒì„±)
            model = self._create_dummy_model(model_name)
            model.to(self.device)
            model.eval()
            
            self.models[model_name] = model
            self.model_weights[model_name] = weight
            
            self.logger.info(f"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {model_name} (ê°€ì¤‘ì¹˜: {weight})")
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {model_name} - {str(e)}")
            return False
    
    def _create_dummy_model(self, model_name: str) -> nn.Module:
        """ë”ë¯¸ ëª¨ë¸ ìƒì„± (ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ì‹¤ì œ ëª¨ë¸ ë¡œë“œ)"""
        class DummyGeometricMatchingModel(nn.Module):
            def __init__(self, name: str):
                super().__init__()
                self.name = name
                # ê°„ë‹¨í•œ CNN ê¸°ë°˜ ë§¤ì¹­ ëª¨ë¸
                self.feature_extractor = nn.Sequential(
                    nn.Conv2d(3, 64, 3, padding=1),
                    nn.ReLU(),
                    nn.Conv2d(64, 128, 3, padding=1),
                    nn.ReLU(),
                    nn.Conv2d(128, 256, 3, padding=1),
                    nn.ReLU()
                )
                
                self.matching_head = nn.Sequential(
                    nn.Conv2d(256, 128, 3, padding=1),
                    nn.ReLU(),
                    nn.Conv2d(128, 64, 3, padding=1),
                    nn.ReLU(),
                    nn.Conv2d(64, 1, 1),
                    nn.Sigmoid()
                )
            
            def forward(self, x):
                features = self.feature_extractor(x)
                matching_score = self.matching_head(features)
                return matching_score
        
        return DummyGeometricMatchingModel(model_name)
    
    def set_ensemble_system(self, ensemble_system):
        """ì•™ìƒë¸” ì‹œìŠ¤í…œ ì„¤ì •"""
        self.ensemble_system = ensemble_system
        self.logger.info("âœ… ì•™ìƒë¸” ì‹œìŠ¤í…œ ì„¤ì • ì™„ë£Œ")
    
    def forward(self, image_1: torch.Tensor, image_2: torch.Tensor, 
                keypoints_1: Optional[torch.Tensor] = None,
                keypoints_2: Optional[torch.Tensor] = None) -> Dict[str, torch.Tensor]:
        """
        ì¶”ë¡  ìˆ˜í–‰
        
        Args:
            image_1: ì²« ë²ˆì§¸ ì´ë¯¸ì§€ (B, C, H, W)
            image_2: ë‘ ë²ˆì§¸ ì´ë¯¸ì§€ (B, C, H, W)
            keypoints_1: ì²« ë²ˆì§¸ ì´ë¯¸ì§€ í‚¤í¬ì¸íŠ¸ (B, N, 2)
            keypoints_2: ë‘ ë²ˆì§¸ ì´ë¯¸ì§€ í‚¤í¬ì¸íŠ¸ (B, M, 2)
        
        Returns:
            ì¶”ë¡  ê²°ê³¼
        """
        start_time = time.time()
        
        try:
            # ì…ë ¥ ê²€ì¦
            if not self._validate_inputs(image_1, image_2):
                raise ValueError("ì…ë ¥ ê²€ì¦ ì‹¤íŒ¨")
            
            # ë””ë°”ì´ìŠ¤ ì´ë™
            image_1 = image_1.to(self.device)
            image_2 = image_2.to(self.device)
            if keypoints_1 is not None:
                keypoints_1 = keypoints_1.to(self.device)
            if keypoints_2 is not None:
                keypoints_2 = keypoints_2.to(self.device)
            
            # ê°œë³„ ëª¨ë¸ ì¶”ë¡ 
            model_outputs = []
            model_confidences = []
            
            for model_name, model in self.models.items():
                try:
                    with torch.no_grad():
                        # ëª¨ë¸ë³„ ì¶”ë¡ 
                        output = self._inference_single_model(model, image_1, image_2, keypoints_1, keypoints_2)
                        confidence = self._calculate_confidence(output)
                        
                        model_outputs.append(output)
                        model_confidences.append(confidence)
                        
                except Exception as e:
                    self.logger.warning(f"ëª¨ë¸ {model_name} ì¶”ë¡  ì‹¤íŒ¨: {str(e)}")
                    continue
            
            if not model_outputs:
                raise RuntimeError("ëª¨ë“  ëª¨ë¸ ì¶”ë¡  ì‹¤íŒ¨")
            
            # ì•™ìƒë¸” ì¶”ë¡ 
            if self.ensemble_system and len(model_outputs) > 1:
                ensemble_output = self.ensemble_system(model_outputs, model_confidences)
            else:
                ensemble_output = model_outputs[0] if model_outputs else torch.zeros_like(image_1[:, :1, :, :])
            
            # í›„ì²˜ë¦¬
            final_output = self._postprocess_output(ensemble_output, image_1, image_2)
            
            # ì¶”ë¡  í†µê³„ ì—…ë°ì´íŠ¸
            inference_time = time.time() - start_time
            self._update_inference_stats(inference_time, True)
            
            # ê²°ê³¼ ë°˜í™˜
            result = {
                "matching_matrix": final_output,
                "model_outputs": model_outputs,
                "model_confidences": model_confidences,
                "ensemble_output": ensemble_output,
                "inference_time": inference_time,
                "success": True
            }
            
            self.logger.debug(f"âœ… ì¶”ë¡  ì™„ë£Œ - ì‹œê°„: {inference_time:.3f}ì´ˆ")
            return result
            
        except Exception as e:
            # ì¶”ë¡  ì‹¤íŒ¨ ì²˜ë¦¬
            inference_time = time.time() - start_time
            self._update_inference_stats(inference_time, False)
            
            self.logger.error(f"âŒ ì¶”ë¡  ì‹¤íŒ¨: {str(e)}")
            
            # ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ê°’ ë°˜í™˜
            return {
                "matching_matrix": torch.zeros_like(image_1[:, :1, :, :]),
                "model_outputs": [],
                "model_confidences": [],
                "ensemble_output": torch.zeros_like(image_1[:, :1, :, :]),
                "inference_time": inference_time,
                "success": False,
                "error": str(e)
            }
    
    def _validate_inputs(self, image_1: torch.Tensor, image_2: torch.Tensor) -> bool:
        """ì…ë ¥ ê²€ì¦"""
        if image_1.dim() != 4 or image_2.dim() != 4:
            return False
        
        if image_1.size(0) != image_2.size(0):
            return False
        
        if image_1.size(2) != image_2.size(2) or image_1.size(3) != image_2.size(3):
            return False
        
        return True
    
    def _inference_single_model(self, model: nn.Module, image_1: torch.Tensor, 
                               image_2: torch.Tensor, keypoints_1: Optional[torch.Tensor],
                               keypoints_2: Optional[torch.Tensor]) -> torch.Tensor:
        """ë‹¨ì¼ ëª¨ë¸ ì¶”ë¡ """
        # ì´ë¯¸ì§€ ì „ì²˜ë¦¬
        processed_image_1 = self._preprocess_image(image_1)
        processed_image_2 = self._preprocess_image(image_2)
        
        # ëª¨ë¸ ì¶”ë¡ 
        if keypoints_1 is not None and keypoints_2 is not None:
            # í‚¤í¬ì¸íŠ¸ ì •ë³´ê°€ ìˆëŠ” ê²½ìš°
            output = model(processed_image_1, processed_image_2, keypoints_1, keypoints_2)
        else:
            # í‚¤í¬ì¸íŠ¸ ì •ë³´ê°€ ì—†ëŠ” ê²½ìš°
            output = model(processed_image_1, processed_image_2)
        
        return output
    
    def _preprocess_image(self, image: torch.Tensor) -> torch.Tensor:
        """ì´ë¯¸ì§€ ì „ì²˜ë¦¬"""
        # ì •ê·œí™” (0-1 ë²”ìœ„)
        if image.max() > 1.0:
            image = image / 255.0
        
        # í¬ê¸° ì¡°ì • (í•„ìš”í•œ ê²½ìš°)
        target_size = (256, 256)
        if image.size(2) != target_size[0] or image.size(3) != target_size[1]:
            image = F.interpolate(image, size=target_size, mode='bilinear', align_corners=False)
        
        return image
    
    def _calculate_confidence(self, output: torch.Tensor) -> float:
        """ì¶œë ¥ ì‹ ë¢°ë„ ê³„ì‚°"""
        if output.numel() == 0:
            return 0.0
        
        # ì¶œë ¥ì˜ í’ˆì§ˆ ê¸°ë°˜ ì‹ ë¢°ë„ ê³„ì‚°
        confidence = float(output.mean().item())
        
        # 0-1 ë²”ìœ„ë¡œ ì •ê·œí™”
        confidence = max(0.0, min(1.0, confidence))
        
        return confidence
    
    def _postprocess_output(self, output: torch.Tensor, image_1: torch.Tensor, 
                           image_2: torch.Tensor) -> torch.Tensor:
        """ì¶œë ¥ í›„ì²˜ë¦¬"""
        # ì¶œë ¥ í¬ê¸°ë¥¼ ì›ë³¸ ì´ë¯¸ì§€ í¬ê¸°ë¡œ ì¡°ì •
        if output.size(2) != image_1.size(2) or output.size(3) != image_1.size(3):
            output = F.interpolate(output, size=(image_1.size(2), image_1.size(3)), 
                                 mode='bilinear', align_corners=False)
        
        # ì‹ ë¢°ë„ ì„ê³„ê°’ ì ìš©
        if self.config.confidence_threshold > 0:
            confidence_mask = output > self.config.confidence_threshold
            output = output * confidence_mask.float()
        
        return output
    
    def _update_inference_stats(self, inference_time: float, success: bool):
        """ì¶”ë¡  í†µê³„ ì—…ë°ì´íŠ¸"""
        self.inference_stats["total_inferences"] += 1
        self.inference_stats["total_time"] += inference_time
        self.inference_stats["avg_time"] = self.inference_stats["total_time"] / self.inference_stats["total_inferences"]
        
        if not success:
            failed_count = int((1 - self.inference_stats["success_rate"]) * self.inference_stats["total_inferences"])
            self.inference_stats["success_rate"] = (self.inference_stats["total_inferences"] - failed_count - 1) / self.inference_stats["total_inferences"]
    
    def get_inference_stats(self) -> Dict[str, Any]:
        """ì¶”ë¡  í†µê³„ ë°˜í™˜"""
        return self.inference_stats.copy()
    
    def get_model_info(self) -> Dict[str, Any]:
        """ëª¨ë¸ ì •ë³´ ë°˜í™˜"""
        model_info = {}
        for model_name, model in self.models.items():
            model_info[model_name] = {
                "weight": self.model_weights.get(model_name, 1.0),
                "parameters": sum(p.numel() for p in model.parameters()),
                "device": str(next(model.parameters()).device)
            }
        return model_info
    
    def clear_cache(self):
        """ìºì‹œ ì •ë¦¬"""
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
        self.logger.info("âœ… ìºì‹œ ì •ë¦¬ ì™„ë£Œ")

# ì¶”ë¡  ì—”ì§„ ì¸ìŠ¤í„´ìŠ¤ ìƒì„± í•¨ìˆ˜
def create_geometric_matching_inference_engine(config: InferenceConfig = None) -> GeometricMatchingInferenceEngine:
    """Geometric Matching ì¶”ë¡  ì—”ì§„ ìƒì„±"""
    return GeometricMatchingInferenceEngine(config)

# ê¸°ë³¸ ì„¤ì •ìœ¼ë¡œ ì¶”ë¡  ì—”ì§„ ìƒì„±
def create_default_inference_engine() -> GeometricMatchingInferenceEngine:
    """ê¸°ë³¸ ì„¤ì •ìœ¼ë¡œ ì¶”ë¡  ì—”ì§„ ìƒì„±"""
    config = InferenceConfig(
        batch_size=1,
        use_mps=True,
        memory_efficient=True,
        enable_ensemble=True,
        confidence_threshold=0.5,
        max_models=8
    )
    return GeometricMatchingInferenceEngine(config)

if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì½”ë“œ
    logging.basicConfig(level=logging.INFO)
    
    # ì¶”ë¡  ì—”ì§„ ìƒì„±
    engine = create_default_inference_engine()
    
    # ë”ë¯¸ ëª¨ë¸ ë¡œë“œ
    engine.load_model("model_1", "dummy_path_1", 1.0)
    engine.load_model("model_2", "dummy_path_2", 0.8)
    
    # í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±
    batch_size, channels, height, width = 2, 3, 256, 256
    test_image_1 = torch.randn(batch_size, channels, height, width)
    test_image_2 = torch.randn(batch_size, channels, height, width)
    
    # ì¶”ë¡  ìˆ˜í–‰
    result = engine(test_image_1, test_image_2)
    print(f"ì¶”ë¡  ê²°ê³¼: {result['success']}")
    print(f"ì¶”ë¡  ì‹œê°„: {result['inference_time']:.3f}ì´ˆ")
    print(f"ëª¨ë¸ ì •ë³´: {engine.get_model_info()}")
    print(f"ì¶”ë¡  í†µê³„: {engine.get_inference_stats()}")
