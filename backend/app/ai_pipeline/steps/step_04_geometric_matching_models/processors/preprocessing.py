#!/usr/bin/env python3
"""
ğŸ”¥ MyCloset AI - Geometric Matching Preprocessing
==================================================

ğŸ¯ ê¸°í•˜í•™ì  ë§¤ì¹­ ì „ì²˜ë¦¬ ëª¨ë“ˆ
âœ… ì´ë¯¸ì§€ ì •ê·œí™” ë° í‘œì¤€í™”
âœ… íŠ¹ì§• ê°•í™” ë° ë…¸ì´ì¦ˆ ì œê±°
âœ… ê¸°í•˜í•™ì  ë³€í˜• ì²˜ë¦¬
âœ… M3 Max ìµœì í™”
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import logging
from typing import Dict, List, Tuple, Optional, Union, Any
from dataclasses import dataclass
import cv2
from PIL import Image, ImageEnhance, ImageFilter

logger = logging.getLogger(__name__)

@dataclass
class PreprocessingConfig:
    """ì „ì²˜ë¦¬ ì„¤ì •"""
    input_size: Tuple[int, int] = (256, 256)
    output_size: Tuple[int, int] = (256, 256)
    normalize_mean: Tuple[float, float, float] = (0.485, 0.456, 0.406)
    normalize_std: Tuple[float, float, float] = (0.229, 0.224, 0.225)
    enable_augmentation: bool = True
    enable_noise_reduction: bool = True
    enable_contrast_enhancement: bool = True
    enable_edge_detection: bool = True
    enable_geometric_correction: bool = True
    use_mps: bool = True

class ImageNormalizer(nn.Module):
    """ì´ë¯¸ì§€ ì •ê·œí™” ëª¨ë“ˆ"""
    
    def __init__(self, mean: Tuple[float, float, float], std: Tuple[float, float, float]):
        super().__init__()
        self.mean = torch.tensor(mean, dtype=torch.float32).view(1, 3, 1, 1)
        self.std = torch.tensor(std, dtype=torch.float32).view(1, 3, 1, 1)
        
    def to(self, device):
        self.mean = self.mean.to(device)
        self.std = self.std.to(device)
        return self
        
    def forward(self, x):
        # ì •ê·œí™” ì ìš©
        normalized = (x - self.mean) / self.std
        return normalized

class NoiseReductionNetwork(nn.Module):
    """ë…¸ì´ì¦ˆ ì œê±° ë„¤íŠ¸ì›Œí¬"""
    
    def __init__(self, input_channels: int = 3):
        super().__init__()
        self.input_channels = input_channels
        
        # ë…¸ì´ì¦ˆ ì œê±°ë¥¼ ìœ„í•œ U-Net êµ¬ì¡°
        self.encoder = nn.ModuleList([
            nn.Conv2d(input_channels, 64, 3, padding=1),
            nn.ReLU(),
            nn.Conv2d(64, 64, 3, padding=1),
            nn.ReLU()
        ])
        
        self.bottleneck = nn.Sequential(
            nn.Conv2d(64, 128, 3, padding=1),
            nn.ReLU(),
            nn.Conv2d(128, 64, 3, padding=1),
            nn.ReLU()
        )
        
        self.decoder = nn.ModuleList([
            nn.Conv2d(64, 64, 3, padding=1),
            nn.ReLU(),
            nn.Conv2d(64, input_channels, 3, padding=1),
            nn.Sigmoid()
        ])
        
    def forward(self, x):
        # Encoder
        encoded = x
        for layer in self.encoder:
            encoded = layer(encoded)
        
        # Bottleneck
        bottleneck = self.bottleneck(encoded)
        
        # Decoder
        decoded = bottleneck
        for layer in self.decoder:
            decoded = layer(decoded)
        
        return decoded

class ContrastEnhancementNetwork(nn.Module):
    """ëŒ€ë¹„ í–¥ìƒ ë„¤íŠ¸ì›Œí¬"""
    
    def __init__(self, input_channels: int = 3):
        super().__init__()
        self.input_channels = input_channels
        
        # ëŒ€ë¹„ í–¥ìƒì„ ìœ„í•œ ë„¤íŠ¸ì›Œí¬
        self.enhancement_net = nn.Sequential(
            nn.Conv2d(input_channels, 64, 3, padding=1),
            nn.ReLU(),
            nn.Conv2d(64, 128, 3, padding=1),
            nn.ReLU(),
            nn.Conv2d(128, 64, 3, padding=1),
            nn.ReLU(),
            nn.Conv2d(64, input_channels, 3, padding=1),
            nn.Tanh()
        )
        
        # ì ì‘í˜• ëŒ€ë¹„ ì¡°ì •
        self.adaptive_contrast = nn.Sequential(
            nn.AdaptiveAvgPool2d(1),
            nn.Conv2d(input_channels, 32, 1),
            nn.ReLU(),
            nn.Conv2d(32, input_channels, 1),
            nn.Sigmoid()
        )
        
    def forward(self, x):
        # ëŒ€ë¹„ í–¥ìƒ
        enhanced = self.enhancement_net(x)
        
        # ì ì‘í˜• ëŒ€ë¹„ ì¡°ì •
        contrast_weights = self.adaptive_contrast(x)
        adjusted = enhanced * contrast_weights
        
        return adjusted

class EdgeDetectionNetwork(nn.Module):
    """ì—£ì§€ ê²€ì¶œ ë„¤íŠ¸ì›Œí¬"""
    
    def __init__(self, input_channels: int = 3):
        super().__init__()
        self.input_channels = input_channels
        
        # Sobel í•„í„° ê¸°ë°˜ ì—£ì§€ ê²€ì¶œ
        self.sobel_x = nn.Conv2d(input_channels, input_channels, 3, padding=1, bias=False)
        self.sobel_y = nn.Conv2d(input_channels, input_channels, 3, padding=1, bias=False)
        
        # Sobel ì»¤ë„ ì´ˆê¸°í™”
        self._init_sobel_kernels()
        
        # ì—£ì§€ ê°•í™” ë„¤íŠ¸ì›Œí¬
        self.edge_enhancement = nn.Sequential(
            nn.Conv2d(input_channels * 2, 64, 3, padding=1),
            nn.ReLU(),
            nn.Conv2d(64, input_channels, 3, padding=1),
            nn.Sigmoid()
        )
        
    def _init_sobel_kernels(self):
        """Sobel ì»¤ë„ì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."""
        # Sobel X ì»¤ë„
        sobel_x_kernel = torch.tensor([
            [-1, 0, 1],
            [-2, 0, 2],
            [-1, 0, 1]
        ], dtype=torch.float32).unsqueeze(0).unsqueeze(0)
        
        # Sobel Y ì»¤ë„
        sobel_y_kernel = torch.tensor([
            [-1, -2, -1],
            [0, 0, 0],
            [1, 2, 1]
        ], dtype=torch.float32).unsqueeze(0).unsqueeze(0)
        
        # ëª¨ë“  ì±„ë„ì— ì ìš©
        for i in range(self.input_channels):
            self.sobel_x.weight.data[i, i] = sobel_x_kernel
            self.sobel_y.weight.data[i, i] = sobel_y_kernel
        
        # ê°€ì¤‘ì¹˜ ê³ ì •
        self.sobel_x.weight.requires_grad = False
        self.sobel_y.weight.requires_grad = False
        
    def forward(self, x):
        # Sobel X ë°©í–¥ ì—£ì§€
        edge_x = self.sobel_x(x)
        
        # Sobel Y ë°©í–¥ ì—£ì§€
        edge_y = self.sobel_y(x)
        
        # ì—£ì§€ ê²°í•©
        edges = torch.cat([edge_x, edge_y], dim=1)
        
        # ì—£ì§€ ê°•í™”
        enhanced_edges = self.edge_enhancement(edges)
        
        return enhanced_edges

class GeometricCorrectionNetwork(nn.Module):
    """ê¸°í•˜í•™ì  ë³´ì • ë„¤íŠ¸ì›Œí¬"""
    
    def __init__(self, input_channels: int = 3):
        super().__init__()
        self.input_channels = input_channels
        
        # ê¸°í•˜í•™ì  ë³´ì •ì„ ìœ„í•œ ë„¤íŠ¸ì›Œí¬
        self.correction_net = nn.Sequential(
            nn.Conv2d(input_channels, 64, 3, padding=1),
            nn.ReLU(),
            nn.Conv2d(64, 128, 3, padding=1),
            nn.ReLU(),
            nn.Conv2d(128, 64, 3, padding=1),
            nn.ReLU(),
            nn.Conv2d(64, input_channels, 3, padding=1),
            nn.Tanh()
        )
        
        # ê³µê°„ ë³€í˜• í•„ë“œ
        self.spatial_transform = nn.Sequential(
            nn.Conv2d(input_channels, 64, 3, padding=1),
            nn.ReLU(),
            nn.Conv2d(64, 32, 3, padding=1),
            nn.ReLU(),
            nn.Conv2d(32, 2, 3, padding=1),  # 2 channels for x, y offsets
            nn.Tanh()
        )
        
    def forward(self, x):
        # ê¸°í•˜í•™ì  ë³´ì •
        corrected = self.correction_net(x)
        
        # ê³µê°„ ë³€í˜• í•„ë“œ ìƒì„±
        transform_field = self.spatial_transform(x)
        
        # ë³€í˜• í•„ë“œ ì ìš© (ê°„ë‹¨í•œ êµ¬í˜„)
        batch_size, channels, height, width = x.shape
        
        # ê·¸ë¦¬ë“œ ìƒì„± (ë°°ì¹˜ ì°¨ì› í¬í•¨)
        grid_y, grid_x = torch.meshgrid(
            torch.linspace(-1, 1, height, device=x.device),
            torch.linspace(-1, 1, width, device=x.device),
            indexing='ij'
        )
        
        # ë°°ì¹˜ ì°¨ì› ì¶”ê°€
        grid_x = grid_x.unsqueeze(0).expand(batch_size, -1, -1)
        grid_y = grid_y.unsqueeze(0).expand(batch_size, -1, -1)
        
        # ë³€í˜• í•„ë“œ ì ìš©
        grid_x = grid_x + transform_field[:, 0, :, :] * 0.1
        grid_y = grid_y + transform_field[:, 1, :, :] * 0.1
        
        # ê·¸ë¦¬ë“œ ì •ê·œí™”
        grid = torch.stack([grid_x, grid_y], dim=-1)
        
        # ë³€í˜• ì ìš©
        transformed = F.grid_sample(corrected, grid, mode='bilinear', align_corners=False)
        
        return transformed

class GeometricMatchingPreprocessor(nn.Module):
    """ê¸°í•˜í•™ì  ë§¤ì¹­ ì „ì²˜ë¦¬ê¸°"""
    
    def __init__(self, config: PreprocessingConfig = None):
        super().__init__()
        self.config = config or PreprocessingConfig()
        self.logger = logging.getLogger(__name__)
        
        # MPS ë””ë°”ì´ìŠ¤ í™•ì¸
        self.device = torch.device("mps" if torch.backends.mps.is_available() and self.config.use_mps else "cpu")
        self.logger.info(f"ğŸ¯ Geometric Matching ì „ì²˜ë¦¬ê¸° ì´ˆê¸°í™” (ë””ë°”ì´ìŠ¤: {self.device})")
        
        # ì´ë¯¸ì§€ ì •ê·œí™”
        self.normalizer = ImageNormalizer(
            self.config.normalize_mean, 
            self.config.normalize_std
        ).to(self.device)
        
        # ë…¸ì´ì¦ˆ ì œê±° ë„¤íŠ¸ì›Œí¬
        if self.config.enable_noise_reduction:
            self.noise_reduction_net = NoiseReductionNetwork(3).to(self.device)
        
        # ëŒ€ë¹„ í–¥ìƒ ë„¤íŠ¸ì›Œí¬
        if self.config.enable_contrast_enhancement:
            self.contrast_enhancement_net = ContrastEnhancementNetwork(3).to(self.device)
        
        # ì—£ì§€ ê²€ì¶œ ë„¤íŠ¸ì›Œí¬
        if self.config.enable_edge_detection:
            self.edge_detection_net = EdgeDetectionNetwork(3).to(self.device)
        
        # ê¸°í•˜í•™ì  ë³´ì • ë„¤íŠ¸ì›Œí¬
        if self.config.enable_geometric_correction:
            self.geometric_correction_net = GeometricCorrectionNetwork(3).to(self.device)
        
        # ìµœì¢… ì¶œë ¥ ì¡°ì •
        self.output_adjustment = nn.Sequential(
            nn.Conv2d(3, 64, 3, padding=1),
            nn.ReLU(),
            nn.Conv2d(64, 3, 3, padding=1),
            nn.Tanh()
        ).to(self.device)
        
        self.logger.info("âœ… Geometric Matching ì „ì²˜ë¦¬ê¸° ì´ˆê¸°í™” ì™„ë£Œ")
    
    def forward(self, image: torch.Tensor) -> Dict[str, torch.Tensor]:
        """
        ì´ë¯¸ì§€ë¥¼ ì „ì²˜ë¦¬í•©ë‹ˆë‹¤.
        
        Args:
            image: ì…ë ¥ ì´ë¯¸ì§€ (B, C, H, W)
            
        Returns:
            ì „ì²˜ë¦¬ëœ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        batch_size, channels, height, width = image.shape
        
        # ì…ë ¥ ê²€ì¦
        if channels != 3:
            raise ValueError(f"Expected 3 channels, got {channels}")
        
        # ë…¸ì´ì¦ˆ ì œê±°
        if self.config.enable_noise_reduction:
            denoised = self.noise_reduction_net(image)
            self.logger.debug("ë…¸ì´ì¦ˆ ì œê±° ì™„ë£Œ")
        else:
            denoised = image
        
        # ëŒ€ë¹„ í–¥ìƒ
        if self.config.enable_contrast_enhancement:
            enhanced = self.contrast_enhancement_net(denoised)
            self.logger.debug("ëŒ€ë¹„ í–¥ìƒ ì™„ë£Œ")
        else:
            enhanced = denoised
        
        # ì—£ì§€ ê²€ì¶œ
        if self.config.enable_edge_detection:
            edges = self.edge_detection_net(enhanced)
            self.logger.debug("ì—£ì§€ ê²€ì¶œ ì™„ë£Œ")
        else:
            edges = enhanced
        
        # ê¸°í•˜í•™ì  ë³´ì •
        if self.config.enable_geometric_correction:
            corrected = self.geometric_correction_net(edges)
            self.logger.debug("ê¸°í•˜í•™ì  ë³´ì • ì™„ë£Œ")
        else:
            corrected = edges
        
        # ìµœì¢… ì¶œë ¥ ì¡°ì •
        output = self.output_adjustment(corrected)
        
        # ëª©í‘œ í•´ìƒë„ë¡œ ë¦¬ì‚¬ì´ì¦ˆ
        if output.shape[-2:] != self.config.output_size:
            output = F.interpolate(
                output, 
                size=self.config.output_size, 
                mode='bilinear', 
                align_corners=False
            )
        
        # ì •ê·œí™” ì ìš©
        normalized = self.normalizer(output)
        
        # ê²°ê³¼ ë°˜í™˜
        result = {
            'preprocessed_image': normalized,
            'denoised_image': denoised,
            'enhanced_image': enhanced,
            'edge_image': edges,
            'corrected_image': corrected,
            'output_size': self.config.output_size,
            'input_size': (height, width)
        }
        
        return result
    
    def process_batch(self, batch_images: List[torch.Tensor]) -> List[Dict[str, torch.Tensor]]:
        """
        ë°°ì¹˜ ë‹¨ìœ„ë¡œ ì „ì²˜ë¦¬ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.
        
        Args:
            batch_images: ì´ë¯¸ì§€ ë°°ì¹˜ ë¦¬ìŠ¤íŠ¸
            
        Returns:
            ì „ì²˜ë¦¬ëœ ê²°ê³¼ ë°°ì¹˜ ë¦¬ìŠ¤íŠ¸
        """
        results = []
        
        for i, image in enumerate(batch_images):
            try:
                result = self.forward(image)
                results.append(result)
                self.logger.debug(f"ë°°ì¹˜ {i} ì „ì²˜ë¦¬ ì™„ë£Œ")
            except Exception as e:
                self.logger.error(f"ë°°ì¹˜ {i} ì „ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                # ì—ëŸ¬ ë°œìƒ ì‹œ ì›ë³¸ ì´ë¯¸ì§€ ë°˜í™˜
                results.append({
                    'preprocessed_image': image,
                    'denoised_image': image,
                    'enhanced_image': image,
                    'edge_image': image,
                    'corrected_image': image,
                    'output_size': image.shape[-2:],
                    'input_size': image.shape[-2:]
                })
        
        return results
    
    def get_preprocessing_stats(self) -> Dict[str, Any]:
        """ì „ì²˜ë¦¬ í†µê³„ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
        return {
            'noise_reduction_enabled': self.config.enable_noise_reduction,
            'contrast_enhancement_enabled': self.config.enable_contrast_enhancement,
            'edge_detection_enabled': self.config.enable_edge_detection,
            'geometric_correction_enabled': self.config.enable_geometric_correction,
            'input_size': self.config.input_size,
            'output_size': self.config.output_size,
            'device': str(self.device),
            'config': self.config.__dict__
        }

# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    # ì„¤ì •
    config = PreprocessingConfig(
        input_size=(256, 256),
        output_size=(256, 256),
        enable_augmentation=True,
        enable_noise_reduction=True,
        enable_contrast_enhancement=True,
        enable_edge_detection=True,
        enable_geometric_correction=True,
        use_mps=True
    )
    
    # ì „ì²˜ë¦¬ê¸° ì´ˆê¸°í™”
    preprocessor = GeometricMatchingPreprocessor(config)
    
    # í…ŒìŠ¤íŠ¸ ì…ë ¥
    batch_size = 2
    channels = 3
    height = 256
    width = 256
    
    test_image = torch.randn(batch_size, channels, height, width)
    
    # ì „ì²˜ë¦¬ ìˆ˜í–‰
    with torch.no_grad():
        result = preprocessor(test_image)
        
        print("âœ… ì „ì²˜ë¦¬ ì™„ë£Œ!")
        print(f"ì…ë ¥ í˜•íƒœ: {test_image.shape}")
        print(f"ì¶œë ¥ í˜•íƒœ: {result['preprocessed_image'].shape}")
        print(f"ì¶œë ¥ í¬ê¸°: {result['output_size']}")
        print(f"ì „ì²˜ë¦¬ í†µê³„: {preprocessor.get_preprocessing_stats()}")
