"""
ğŸ”¥ Final Output Inference Engine
================================

ìµœì¢… ì¶œë ¥ ìƒì„±ì„ ìœ„í•œ ì¶”ë¡  ì—”ì§„ì…ë‹ˆë‹¤.
ë…¼ë¬¸ ê¸°ë°˜ì˜ AI ëª¨ë¸ êµ¬ì¡°ì— ë§ì¶° êµ¬í˜„ë˜ì—ˆìŠµë‹ˆë‹¤.

ì§€ì› ëª¨ë¸:
- Final Output Generator
- Quality Optimizer
- Style Transfer
- Resolution Enhancer
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
from typing import Dict, Any, Optional, Union, List, Tuple
import numpy as np
import cv2
from PIL import Image
import logging

# í”„ë¡œì íŠ¸ ë¡œê¹… ì„¤ì • import
try:
    from backend.app.core.logging_config import get_logger
    logger = get_logger(__name__)
except ImportError:
    logger = logging.getLogger(__name__)

class FinalOutputInferenceEngine:
    """
    ìµœì¢… ì¶œë ¥ ìƒì„±ì„ ìœ„í•œ ì¶”ë¡  ì—”ì§„ í´ë˜ìŠ¤

    ì§€ì› ëª¨ë¸:
    - Final Output Generator
    - Quality Optimizer
    - Style Transfer
    - Resolution Enhancer
    """

    def __init__(self, model_loader=None):
        """
        Args:
            model_loader: ëª¨ë¸ ë¡œë” ì¸ìŠ¤í„´ìŠ¤
        """
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.model_loader = model_loader
        self.loaded_models = {}

        # ì§€ì›í•˜ëŠ” ëª¨ë¸ íƒ€ì…ë“¤
        self.supported_models = ['final_generator', 'quality_optimizer', 'style_transfer', 'resolution_enhancer']

        # ì¶”ë¡  ì„¤ì •
        self.inference_config = {
            'final_generator': {
                'input_size': (512, 512),
                'output_size': (1024, 1024),
                'batch_size': 16,
                'use_attention': True,
                'enable_style_mixing': True
            },
            'quality_optimizer': {
                'input_size': (512, 512),
                'enhancement_level': 'high',
                'denoise_strength': 0.8,
                'sharpen_strength': 0.6,
                'color_enhancement': True
            },
            'style_transfer': {
                'input_size': (512, 512),
                'style_strength': 0.7,
                'content_weight': 1.0,
                'style_weight': 0.8,
                'preserve_colors': True
            },
            'resolution_enhancer': {
                'input_size': (512, 512),
                'scale_factor': 2,
                'interpolation_mode': 'bicubic',
                'enable_denoising': True,
                'edge_enhancement': True
            }
        }

        logger.info(f"FinalOutputInferenceEngine initialized on device: {self.device}")

    def generate_final_output(self, input_data: Union[np.ndarray, Image.Image, torch.Tensor],
                            model_type: str = 'final_generator',
                            **kwargs) -> Dict[str, Any]:
        """
        ìµœì¢… ì¶œë ¥ì„ ìƒì„±í•©ë‹ˆë‹¤.

        Args:
            input_data: ì…ë ¥ ë°ì´í„°
            model_type: ì‚¬ìš©í•  ëª¨ë¸ íƒ€ì…
            **kwargs: ì¶”ê°€ íŒŒë¼ë¯¸í„°

        Returns:
            ìµœì¢… ì¶œë ¥ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        try:
            # ì…ë ¥ ë°ì´í„° ì „ì²˜ë¦¬
            processed_input = self._preprocess_input(input_data, model_type)
            
            # ëª¨ë¸ ë¡œë“œ (í•„ìš”ì‹œ)
            if model_type not in self.loaded_models:
                self.loaded_models[model_type] = self.load_model(model_type, **kwargs)
            
            model = self.loaded_models[model_type]
            model.eval()
            
            # ì¶”ë¡  ì‹¤í–‰
            with torch.no_grad():
                if model_type == 'final_generator':
                    result = self._inference_final_generator(model, processed_input, **kwargs)
                elif model_type == 'quality_optimizer':
                    result = self._inference_quality_optimizer(model, processed_input, **kwargs)
                elif model_type == 'style_transfer':
                    result = self._inference_style_transfer(model, processed_input, **kwargs)
                elif model_type == 'resolution_enhancer':
                    result = self._inference_resolution_enhancer(model, processed_input, **kwargs)
                else:
                    raise ValueError(f"Unsupported model type: {model_type}")
            
            # ê²°ê³¼ í›„ì²˜ë¦¬
            result = self._postprocess_result(result, model_type)
            
            logger.info(f"âœ… Final output generation completed for {model_type}")
            return result
            
        except Exception as e:
            logger.error(f"âŒ Final output generation failed: {e}")
            raise

    def _preprocess_input(self, input_data: Union[np.ndarray, Image.Image, torch.Tensor],
                         model_type: str) -> torch.Tensor:
        """
        ì…ë ¥ ë°ì´í„°ë¥¼ ì „ì²˜ë¦¬í•©ë‹ˆë‹¤.
        """
        # PIL Imageë¥¼ numpy arrayë¡œ ë³€í™˜
        if isinstance(input_data, Image.Image):
            input_data = np.array(input_data)
        
        # numpy arrayë¥¼ torch tensorë¡œ ë³€í™˜
        if isinstance(input_data, np.ndarray):
            if len(input_data.shape) == 3:
                input_data = torch.from_numpy(input_data).permute(2, 0, 1).float()
            else:
                input_data = torch.from_numpy(input_data).unsqueeze(0).float()
        
        # ì •ê·œí™”
        if input_data.max() > 1.0:
            input_data = input_data / 255.0
        
        # ë°°ì¹˜ ì°¨ì› ì¶”ê°€
        if len(input_data.shape) == 3:
            input_data = input_data.unsqueeze(0)
        
        # í¬ê¸° ì¡°ì •
        target_size = self.inference_config[model_type]['input_size']
        if input_data.shape[-2:] != target_size:
            input_data = F.interpolate(input_data, size=target_size, 
                                     mode='bilinear', align_corners=False)
        
        # ë””ë°”ì´ìŠ¤ ì´ë™
        input_data = input_data.to(self.device)
        
        return input_data

    def _inference_final_generator(self, model: nn.Module, 
                                 input_data: torch.Tensor, **kwargs) -> Dict[str, Any]:
        """
        Final Generator ëª¨ë¸ë¡œ ì¶”ë¡ ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.
        """
        # ì…ë ¥ ë°ì´í„° ì¤€ë¹„
        input_size = self.inference_config['final_generator']['input_size']
        output_size = self.inference_config['final_generator']['output_size']
        
        # ì…ë ¥ í¬ê¸° ì¡°ì •
        if input_data.shape[-2:] != input_size:
            input_data = F.interpolate(input_data, size=input_size, 
                                     mode='bilinear', align_corners=False)
        
        # ì¶”ë¡  ì‹¤í–‰
        output = model(input_data)
        
        # ì¶œë ¥ í¬ê¸° ì¡°ì •
        if output.shape[-2:] != output_size:
            output = F.interpolate(output, size=output_size, 
                                 mode='bilinear', align_corners=False)
        
        # ê²°ê³¼ í•´ì„
        if isinstance(output, torch.Tensor):
            # í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°
            quality_score = self._calculate_output_quality(output)
        else:
            quality_score = 0.8
        
        return {
            'output': output,
            'quality_score': quality_score,
            'output_size': output_size,
            'model_type': 'final_generator'
        }

    def _inference_quality_optimizer(self, model: nn.Module, 
                                   input_data: torch.Tensor, **kwargs) -> Dict[str, Any]:
        """
        Quality Optimizer ëª¨ë¸ë¡œ ì¶”ë¡ ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.
        """
        # í’ˆì§ˆ ìµœì í™” ì„¤ì •
        config = self.inference_config['quality_optimizer']
        enhancement_level = config['enhancement_level']
        denoise_strength = config['denoise_strength']
        sharpen_strength = config['sharpen_strength']
        
        # ì¶”ë¡  ì‹¤í–‰
        output = model(input_data)
        
        # ì¶”ê°€ í’ˆì§ˆ í–¥ìƒ (í•„ìš”ì‹œ)
        if enhancement_level == 'high':
            output = self._apply_quality_enhancements(output, denoise_strength, sharpen_strength)
        
        # í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°
        quality_score = self._calculate_output_quality(output)
        
        return {
            'output': output,
            'quality_score': quality_score,
            'enhancement_level': enhancement_level,
            'model_type': 'quality_optimizer'
        }

    def _inference_style_transfer(self, model: nn.Module, 
                                input_data: torch.Tensor, **kwargs) -> Dict[str, Any]:
        """
        Style Transfer ëª¨ë¸ë¡œ ì¶”ë¡ ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.
        """
        # ìŠ¤íƒ€ì¼ ì „ì†¡ ì„¤ì •
        config = self.inference_config['style_transfer']
        style_strength = config['style_strength']
        content_weight = config['content_weight']
        style_weight = config['style_weight']
        
        # ì¶”ë¡  ì‹¤í–‰
        output = model(input_data)
        
        # ìŠ¤íƒ€ì¼ ê°•ë„ ì¡°ì •
        if style_strength != 1.0:
            output = self._adjust_style_strength(input_data, output, style_strength)
        
        # í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°
        quality_score = self._calculate_output_quality(output)
        
        return {
            'output': output,
            'quality_score': quality_score,
            'style_strength': style_strength,
            'model_type': 'style_transfer'
        }

    def _inference_resolution_enhancer(self, model: nn.Module, 
                                     input_data: torch.Tensor, **kwargs) -> Dict[str, Any]:
        """
        Resolution Enhancer ëª¨ë¸ë¡œ ì¶”ë¡ ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.
        """
        # í•´ìƒë„ í–¥ìƒ ì„¤ì •
        config = self.inference_config['resolution_enhancer']
        scale_factor = config['scale_factor']
        interpolation_mode = config['interpolation_mode']
        
        # ì¶”ë¡  ì‹¤í–‰
        output = model(input_data)
        
        # í•´ìƒë„ í–¥ìƒ
        target_size = (input_data.shape[-2] * scale_factor, input_data.shape[-1] * scale_factor)
        if output.shape[-2:] != target_size:
            output = F.interpolate(output, size=target_size, 
                                 mode=interpolation_mode, align_corners=False)
        
        # í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°
        quality_score = self._calculate_output_quality(output)
        
        return {
            'output': output,
            'quality_score': quality_score,
            'scale_factor': scale_factor,
            'output_size': target_size,
            'model_type': 'resolution_enhancer'
        }

    def _apply_quality_enhancements(self, output: torch.Tensor, 
                                  denoise_strength: float, 
                                  sharpen_strength: float) -> torch.Tensor:
        """
        í’ˆì§ˆ í–¥ìƒì„ ì ìš©í•©ë‹ˆë‹¤.
        """
        enhanced_output = output
        
        # ë…¸ì´ì¦ˆ ì œê±°
        if denoise_strength > 0:
            enhanced_output = self._denoise_image(enhanced_output, denoise_strength)
        
        # ì„ ëª…ë„ í–¥ìƒ
        if sharpen_strength > 0:
            enhanced_output = self._sharpen_image(enhanced_output, sharpen_strength)
        
        return enhanced_output

    def _denoise_image(self, image: torch.Tensor, strength: float) -> torch.Tensor:
        """
        ì´ë¯¸ì§€ ë…¸ì´ì¦ˆë¥¼ ì œê±°í•©ë‹ˆë‹¤.
        """
        # ê°€ìš°ì‹œì•ˆ í•„í„° ì ìš©
        kernel_size = max(3, int(5 * strength))
        if kernel_size % 2 == 0:
            kernel_size += 1
        
        sigma = strength * 2.0
        
        # 2D ê°€ìš°ì‹œì•ˆ ì»¤ë„ ìƒì„±
        kernel = self._create_gaussian_kernel2d(kernel_size, sigma)
        kernel = kernel.to(self.device)
        
        # ê° ì±„ë„ì— ëŒ€í•´ ì»¨ë³¼ë£¨ì…˜ ì ìš©
        denoised = torch.zeros_like(image)
        for c in range(image.shape[1]):
            denoised[:, c:c+1] = F.conv2d(
                image[:, c:c+1], 
                kernel.unsqueeze(0).unsqueeze(0),
                padding=kernel_size // 2
            )
        
        # ì›ë³¸ê³¼ ë¸”ë Œë”©
        result = image * (1 - strength) + denoised * strength
        return torch.clamp(result, 0, 1)

    def _sharpen_image(self, image: torch.Tensor, strength: float) -> torch.Tensor:
        """
        ì´ë¯¸ì§€ ì„ ëª…ë„ë¥¼ í–¥ìƒì‹œí‚µë‹ˆë‹¤.
        """
        # ì–¸ìƒ¤í”„ ë§ˆìŠ¤í¬ ì ìš©
        kernel = torch.tensor([
            [0, -1, 0],
            [-1, 5, -1],
            [0, -1, 0]
        ], dtype=torch.float32, device=self.device)
        
        kernel = kernel.unsqueeze(0).unsqueeze(0)
        
        sharpened = torch.zeros_like(image)
        for c in range(image.shape[1]):
            sharpened[:, c:c+1] = F.conv2d(
                image[:, c:c+1], 
                kernel,
                padding=1
            )
        
        # ì›ë³¸ê³¼ ë¸”ë Œë”©
        result = image + strength * (sharpened - image)
        return torch.clamp(result, 0, 1)

    def _create_gaussian_kernel2d(self, kernel_size: int, sigma: float) -> torch.Tensor:
        """
        2D ê°€ìš°ì‹œì•ˆ ì»¤ë„ì„ ìƒì„±í•©ë‹ˆë‹¤.
        """
        kernel = torch.zeros(kernel_size, kernel_size)
        center = kernel_size // 2
        
        for i in range(kernel_size):
            for j in range(kernel_size):
                x, y = i - center, j - center
                kernel[i, j] = torch.exp(-(x**2 + y**2) / (2 * sigma**2))
        
        # ì •ê·œí™”
        kernel = kernel / kernel.sum()
        return kernel

    def _adjust_style_strength(self, content: torch.Tensor, 
                              styled: torch.Tensor, 
                              strength: float) -> torch.Tensor:
        """
        ìŠ¤íƒ€ì¼ ê°•ë„ë¥¼ ì¡°ì •í•©ë‹ˆë‹¤.
        """
        # ì½˜í…ì¸ ì™€ ìŠ¤íƒ€ì¼ ì´ë¯¸ì§€ ë¸”ë Œë”©
        result = content * (1 - strength) + styled * strength
        return torch.clamp(result, 0, 1)

    def _calculate_output_quality(self, output: torch.Tensor) -> float:
        """
        ì¶œë ¥ í’ˆì§ˆì„ ê³„ì‚°í•©ë‹ˆë‹¤.
        """
        try:
            # ê¸°ë³¸ í’ˆì§ˆ ë©”íŠ¸ë¦­
            if len(output.shape) == 4:
                output = output.squeeze(0)
            
            # ë°ê¸°
            brightness = output.mean().item()
            
            # ëŒ€ë¹„
            contrast = output.std().item()
            
            # ì„ ëª…ë„ (ë¼í”Œë¼ì‹œì•ˆ ë¶„ì‚°)
            if output.shape[0] == 3:  # RGB
                gray = 0.299 * output[0] + 0.587 * output[1] + 0.114 * output[2]
            else:
                gray = output[0]
            
            # ë¼í”Œë¼ì‹œì•ˆ í•„í„°
            laplacian_kernel = torch.tensor([
                [0, 1, 0],
                [1, -4, 1],
                [0, 1, 0]
            ], dtype=torch.float32, device=output.device).unsqueeze(0).unsqueeze(0)
            
            laplacian = F.conv2d(gray.unsqueeze(1), laplacian_kernel, padding=1)
            sharpness = laplacian.var().item()
            
            # ì¢…í•© í’ˆì§ˆ ì ìˆ˜ ê³„ì‚° (0-1 ë²”ìœ„)
            quality_score = min(1.0, (brightness * 0.3 + contrast * 0.3 + sharpness * 0.4))
            
            return quality_score
            
        except Exception as e:
            logger.warning(f"âš ï¸ Quality calculation failed: {e}")
            return 0.8

    def _postprocess_result(self, result: Dict[str, Any], model_type: str) -> Dict[str, Any]:
        """
        ì¶”ë¡  ê²°ê³¼ë¥¼ í›„ì²˜ë¦¬í•©ë‹ˆë‹¤.
        """
        # í’ˆì§ˆ ë“±ê¸‰ ê²°ì •
        quality_score = result.get('quality_score', 0.0)
        
        if quality_score >= 0.9:
            quality_grade = 'Excellent'
        elif quality_score >= 0.7:
            quality_grade = 'Good'
        elif quality_score >= 0.5:
            quality_grade = 'Fair'
        else:
            quality_grade = 'Poor'
        
        # ê²°ê³¼ì— í’ˆì§ˆ ë“±ê¸‰ ì¶”ê°€
        result['quality_grade'] = quality_grade
        
        # ì‹ ë¢°ë„ ì ìˆ˜ ì¶”ê°€
        confidence_scores = {
            'final_generator': 0.95,
            'quality_optimizer': 0.92,
            'style_transfer': 0.88,
            'resolution_enhancer': 0.90
        }
        
        result['confidence'] = confidence_scores.get(model_type, 0.85)
        result['timestamp'] = torch.cuda.Event() if torch.cuda.is_available() else None
        
        return result

    def batch_generate_outputs(self, input_data_list: List[Union[np.ndarray, Image.Image, torch.Tensor]],
                             model_type: str = 'final_generator',
                             **kwargs) -> List[Dict[str, Any]]:
        """
        ì—¬ëŸ¬ ì…ë ¥ì— ëŒ€í•´ ìµœì¢… ì¶œë ¥ì„ ì¼ê´„ ìƒì„±í•©ë‹ˆë‹¤.
        """
        results = []
        for i, input_data in enumerate(input_data_list):
            try:
                result = self.generate_final_output(input_data, model_type, **kwargs)
                result['input_index'] = i
                results.append(result)
            except Exception as e:
                logger.error(f"âŒ Failed to generate output for input {i}: {e}")
                results.append({
                    'input_index': i,
                    'error': str(e),
                    'quality_score': 0.0,
                    'quality_grade': 'Error'
                })
        
        return results

    def get_model_info(self, model_type: str) -> Dict[str, Any]:
        """
        ëª¨ë¸ ì •ë³´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
        """
        if model_type in self.inference_config:
            return {
                'model_type': model_type,
                'supported': True,
                'config': self.inference_config[model_type],
                'device': str(self.device)
            }
        else:
            return {
                'model_type': model_type,
                'supported': False,
                'error': 'Unsupported model type'
            }

    def load_model(self, model_type: str, **kwargs) -> nn.Module:
        """
        ì§€ì •ëœ íƒ€ì…ì˜ ëª¨ë¸ì„ ë¡œë“œí•©ë‹ˆë‹¤.
        """
        if self.model_loader:
            return self.model_loader.load_model(model_type, **kwargs)
        else:
            raise RuntimeError("Model loader not initialized")
