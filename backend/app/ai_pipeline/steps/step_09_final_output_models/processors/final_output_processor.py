"""
ğŸ”¥ Final Output Processor
=========================

ìµœì¢… ì¶œë ¥ ìƒì„±ì„ ìœ„í•œ ì „ì²˜ë¦¬ ë° í›„ì²˜ë¦¬ í”„ë¡œì„¸ì„œì…ë‹ˆë‹¤.
ë…¼ë¬¸ ê¸°ë°˜ì˜ AI ëª¨ë¸ êµ¬ì¡°ì— ë§ì¶° êµ¬í˜„ë˜ì—ˆìŠµë‹ˆë‹¤.
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
from typing import Dict, Any, Optional, Union, List, Tuple
import numpy as np
import cv2
from PIL import Image
import logging

# í”„ë¡œì íŠ¸ ë¡œê¹… ì„¤ì • import
try:
    from backend.app.core.logging_config import get_logger
    logger = get_logger(__name__)
except ImportError:
    logger = logging.getLogger(__name__)

class FinalOutputProcessor:
    """
    ìµœì¢… ì¶œë ¥ ìƒì„±ì„ ìœ„í•œ ì „ì²˜ë¦¬ ë° í›„ì²˜ë¦¬ í”„ë¡œì„¸ì„œ
    """

    def __init__(self, device: str = 'auto'):
        """
        Args:
            device: ì‚¬ìš©í•  ë””ë°”ì´ìŠ¤ ('auto', 'cpu', 'cuda')
        """
        if device == 'auto':
            self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        else:
            self.device = torch.device(device)
        
        # í”„ë¡œì„¸ì„œ ì„¤ì •
        self.processor_config = {
            'default_input_size': (512, 512),
            'default_output_size': (1024, 1024),
            'enable_quality_enhancement': True,
            'enable_noise_reduction': True,
            'enable_edge_enhancement': True,
            'enable_color_correction': True
        }
        
        logger.info(f"FinalOutputProcessor initialized on device: {self.device}")

    def preprocess_for_final_output(self, input_data: Union[np.ndarray, Image.Image, torch.Tensor],
                                 target_size: Tuple[int, int] = None,
                                 normalize: bool = True,
                                 **kwargs) -> torch.Tensor:
        """
        ìµœì¢… ì¶œë ¥ ìƒì„±ì„ ìœ„í•œ ì…ë ¥ ë°ì´í„° ì „ì²˜ë¦¬
        
        Args:
            input_data: ì…ë ¥ ë°ì´í„°
            target_size: ëª©í‘œ í¬ê¸°
            normalize: ì •ê·œí™” ì—¬ë¶€
            **kwargs: ì¶”ê°€ íŒŒë¼ë¯¸í„°
            
        Returns:
            ì „ì²˜ë¦¬ëœ ë°ì´í„° í…ì„œ
        """
        try:
            # ëª©í‘œ í¬ê¸° ì„¤ì •
            if target_size is None:
                target_size = self.processor_config['default_input_size']
            
            # ì´ë¯¸ì§€ íƒ€ì… í†µì¼
            if isinstance(input_data, Image.Image):
                input_data = np.array(input_data)
            
            if isinstance(input_data, np.ndarray):
                # RGBë¡œ ë³€í™˜
                if len(input_data.shape) == 2:
                    input_data = cv2.cvtColor(input_data, cv2.COLOR_GRAY2RGB)
                elif input_data.shape[2] == 4:
                    input_data = cv2.cvtColor(input_data, cv2.COLOR_RGBA2RGB)
                
                # í…ì„œë¡œ ë³€í™˜
                input_data = torch.from_numpy(input_data).permute(2, 0, 1).float()
            elif isinstance(input_data, torch.Tensor):
                if len(input_data.shape) == 2:
                    input_data = input_data.unsqueeze(0).repeat(3, 1, 1)
                elif len(input_data.shape) == 3 and input_data.shape[0] == 1:
                    input_data = input_data.repeat(3, 1, 1)
            
            # í¬ê¸° ì¡°ì •
            if input_data.shape[-2:] != target_size:
                input_data = F.interpolate(input_data.unsqueeze(0), size=target_size, 
                                        mode='bilinear', align_corners=False).squeeze(0)
            
            # ì •ê·œí™”
            if normalize:
                if input_data.max() > 1.0:
                    input_data = input_data / 255.0
            
            # ë°°ì¹˜ ì°¨ì› ì¶”ê°€
            if len(input_data.shape) == 3:
                input_data = input_data.unsqueeze(0)
            
            # ë””ë°”ì´ìŠ¤ ì´ë™
            input_data = input_data.to(self.device)
            
            logger.info(f"âœ… Input preprocessing completed: {input_data.shape}")
            return input_data
            
        except Exception as e:
            logger.error(f"âŒ Input preprocessing failed: {e}")
            raise

    def postprocess_final_output(self, output: torch.Tensor,
                               target_size: Tuple[int, int] = None,
                               denormalize: bool = True,
                               **kwargs) -> torch.Tensor:
        """
        ìµœì¢… ì¶œë ¥ í›„ì²˜ë¦¬
        
        Args:
            output: ëª¨ë¸ ì¶œë ¥
            target_size: ëª©í‘œ í¬ê¸°
            denormalize: ì—­ì •ê·œí™” ì—¬ë¶€
            **kwargs: ì¶”ê°€ íŒŒë¼ë¯¸í„°
            
        Returns:
            í›„ì²˜ë¦¬ëœ ì¶œë ¥ í…ì„œ
        """
        try:
            processed_output = output
            
            # í¬ê¸° ì¡°ì •
            if target_size is not None and output.shape[-2:] != target_size:
                processed_output = F.interpolate(processed_output, size=target_size, 
                                              mode='bilinear', align_corners=False)
            
            # í’ˆì§ˆ í–¥ìƒ ì ìš©
            if self.processor_config['enable_quality_enhancement']:
                processed_output = self._apply_quality_enhancements(processed_output, **kwargs)
            
            # ì—­ì •ê·œí™”
            if denormalize:
                processed_output = torch.clamp(processed_output, 0, 1)
                if processed_output.max() <= 1.0:
                    processed_output = processed_output * 255.0
            
            logger.info(f"âœ… Output postprocessing completed: {processed_output.shape}")
            return processed_output
            
        except Exception as e:
            logger.error(f"âŒ Output postprocessing failed: {e}")
            return output

    def _apply_quality_enhancements(self, output: torch.Tensor, **kwargs) -> torch.Tensor:
        """
        í’ˆì§ˆ í–¥ìƒì„ ì ìš©í•©ë‹ˆë‹¤.
        """
        enhanced_output = output
        
        # ë…¸ì´ì¦ˆ ê°ì†Œ
        if self.processor_config['enable_noise_reduction']:
            enhanced_output = self._reduce_noise(enhanced_output, **kwargs)
        
        # ì—ì§€ í–¥ìƒ
        if self.processor_config['enable_edge_enhancement']:
            enhanced_output = self._enhance_edges(enhanced_output, **kwargs)
        
        # ìƒ‰ìƒ ë³´ì •
        if self.processor_config['enable_color_correction']:
            enhanced_output = self._correct_colors(enhanced_output, **kwargs)
        
        return enhanced_output

    def _reduce_noise(self, image: torch.Tensor, 
                     kernel_size: int = 3,
                     sigma: float = 1.0) -> torch.Tensor:
        """
        ì´ë¯¸ì§€ ë…¸ì´ì¦ˆë¥¼ ê°ì†Œì‹œí‚µë‹ˆë‹¤.
        """
        # ê°€ìš°ì‹œì•ˆ í•„í„° ì ìš©
        if kernel_size % 2 == 0:
            kernel_size += 1
        
        # 2D ê°€ìš°ì‹œì•ˆ ì»¤ë„ ìƒì„±
        kernel = self._create_gaussian_kernel2d(kernel_size, sigma)
        kernel = kernel.to(self.device)
        
        # ê° ì±„ë„ì— ëŒ€í•´ ì»¨ë³¼ë£¨ì…˜ ì ìš©
        denoised = torch.zeros_like(image)
        for c in range(image.shape[1]):
            denoised[:, c:c+1] = F.conv2d(
                image[:, c:c+1], 
                kernel.unsqueeze(0).unsqueeze(0),
                padding=kernel_size // 2
            )
        
        return denoised

    def _enhance_edges(self, image: torch.Tensor, 
                      strength: float = 0.5) -> torch.Tensor:
        """
        ì´ë¯¸ì§€ ì—ì§€ë¥¼ í–¥ìƒì‹œí‚µë‹ˆë‹¤.
        """
        # ì–¸ìƒ¤í”„ ë§ˆìŠ¤í¬ ì ìš©
        kernel = torch.tensor([
            [0, -1, 0],
            [-1, 5, -1],
            [0, -1, 0]
        ], dtype=torch.float32, device=self.device)
        
        kernel = kernel.unsqueeze(0).unsqueeze(0)
        
        sharpened = torch.zeros_like(image)
        for c in range(image.shape[1]):
            sharpened[:, c:c+1] = F.conv2d(
                image[:, c:c+1], 
                kernel,
                padding=1
            )
        
        # ì›ë³¸ê³¼ ë¸”ë Œë”©
        result = image + strength * (sharpened - image)
        return torch.clamp(result, 0, 1)

    def _correct_colors(self, image: torch.Tensor, 
                       brightness: float = 0.0,
                       contrast: float = 1.0,
                       saturation: float = 1.0) -> torch.Tensor:
        """
        ì´ë¯¸ì§€ ìƒ‰ìƒì„ ë³´ì •í•©ë‹ˆë‹¤.
        """
        corrected = image
        
        # ë°ê¸° ì¡°ì •
        if brightness != 0.0:
            corrected = corrected + brightness
            corrected = torch.clamp(corrected, 0, 1)
        
        # ëŒ€ë¹„ ì¡°ì •
        if contrast != 1.0:
            mean_val = corrected.mean()
            corrected = (corrected - mean_val) * contrast + mean_val
            corrected = torch.clamp(corrected, 0, 1)
        
        # ì±„ë„ ì¡°ì • (ê°„ë‹¨í•œ ë°©ë²•)
        if saturation != 1.0 and corrected.shape[1] == 3:
            # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ê³„ì‚°
            gray = 0.299 * corrected[:, 0] + 0.587 * corrected[:, 1] + 0.114 * corrected[:, 2]
            gray = gray.unsqueeze(1)
            
            # ì±„ë„ ì¡°ì •
            corrected = gray + saturation * (corrected - gray)
            corrected = torch.clamp(corrected, 0, 1)
        
        return corrected

    def _create_gaussian_kernel2d(self, kernel_size: int, sigma: float) -> torch.Tensor:
        """
        2D ê°€ìš°ì‹œì•ˆ ì»¤ë„ì„ ìƒì„±í•©ë‹ˆë‹¤.
        """
        kernel = torch.zeros(kernel_size, kernel_size)
        center = kernel_size // 2
        
        for i in range(kernel_size):
            for j in range(kernel_size):
                x, y = i - center, j - center
                kernel[i, j] = torch.exp(-(x**2 + y**2) / (2 * sigma**2))
        
        # ì •ê·œí™”
        kernel = kernel / kernel.sum()
        return kernel

    def generate_final_output_batch(self, input_data_list: List[Union[np.ndarray, Image.Image, torch.Tensor]],
                                  target_size: Tuple[int, int] = None,
                                  **kwargs) -> List[torch.Tensor]:
        """
        ì—¬ëŸ¬ ì…ë ¥ì— ëŒ€í•´ ìµœì¢… ì¶œë ¥ì„ ì¼ê´„ ìƒì„±í•©ë‹ˆë‹¤.
        
        Args:
            input_data_list: ì…ë ¥ ë°ì´í„° ë¦¬ìŠ¤íŠ¸
            target_size: ëª©í‘œ í¬ê¸°
            **kwargs: ì¶”ê°€ íŒŒë¼ë¯¸í„°
            
        Returns:
            ì „ì²˜ë¦¬ëœ ë°ì´í„° ë¦¬ìŠ¤íŠ¸
        """
        try:
            processed_data = []
            
            for i, input_data in enumerate(input_data_list):
                try:
                    processed = self.preprocess_for_final_output(
                        input_data, target_size=target_size, **kwargs
                    )
                    processed_data.append(processed)
                except Exception as e:
                    logger.error(f"âŒ Failed to process input {i}: {e}")
                    # ì—ëŸ¬ ë°œìƒ ì‹œ ì›ë³¸ ë°ì´í„° ë°˜í™˜
                    if isinstance(input_data, torch.Tensor):
                        processed_data.append(input_data)
                    else:
                        # ê¸°ë³¸ í…ì„œ ìƒì„±
                        default_tensor = torch.zeros(1, 3, 512, 512, device=self.device)
                        processed_data.append(default_tensor)
            
            logger.info(f"âœ… Batch processing completed: {len(processed_data)} inputs")
            return processed_data
            
        except Exception as e:
            logger.error(f"âŒ Batch processing failed: {e}")
            return []

    def apply_output_optimizations(self, output: torch.Tensor,
                                 optimizations: List[str] = None,
                                 **kwargs) -> torch.Tensor:
        """
        ì¶œë ¥ì— ìµœì í™”ë¥¼ ì ìš©í•©ë‹ˆë‹¤.
        
        Args:
            output: ì…ë ¥ ì¶œë ¥
            optimizations: ì ìš©í•  ìµœì í™” ëª©ë¡
            **kwargs: ìµœì í™” íŒŒë¼ë¯¸í„°
            
        Returns:
            ìµœì í™”ëœ ì¶œë ¥
        """
        try:
            if optimizations is None:
                optimizations = ['noise_reduction', 'edge_enhancement', 'color_correction']
            
            optimized_output = output
            
            for optimization in optimizations:
                if optimization == 'noise_reduction':
                    optimized_output = self._reduce_noise(optimized_output, **kwargs)
                elif optimization == 'edge_enhancement':
                    optimized_output = self._enhance_edges(optimized_output, **kwargs)
                elif optimization == 'color_correction':
                    optimized_output = self._correct_colors(optimized_output, **kwargs)
                elif optimization == 'resolution_enhancement':
                    optimized_output = self._enhance_resolution(optimized_output, **kwargs)
            
            logger.info(f"âœ… Output optimizations applied: {optimizations}")
            return optimized_output
            
        except Exception as e:
            logger.error(f"âŒ Output optimization failed: {e}")
            return output

    def _enhance_resolution(self, image: torch.Tensor, 
                          scale_factor: float = 2.0,
                          method: str = 'bicubic') -> torch.Tensor:
        """
        ì´ë¯¸ì§€ í•´ìƒë„ë¥¼ í–¥ìƒì‹œí‚µë‹ˆë‹¤.
        """
        try:
            # ëª©í‘œ í¬ê¸° ê³„ì‚°
            current_size = image.shape[-2:]
            target_size = (int(current_size[0] * scale_factor), int(current_size[1] * scale_factor))
            
            # ë³´ê°„ ë°©ë²• ì„ íƒ
            if method == 'bicubic':
                mode = 'bicubic'
            elif method == 'bilinear':
                mode = 'bilinear'
            elif method == 'nearest':
                mode = 'nearest'
            else:
                mode = 'bicubic'
            
            # í•´ìƒë„ í–¥ìƒ
            enhanced = F.interpolate(image, size=target_size, 
                                   mode=mode, align_corners=False)
            
            return enhanced
            
        except Exception as e:
            logger.warning(f"âš ï¸ Resolution enhancement failed: {e}")
            return image

    def get_processor_info(self) -> Dict[str, Any]:
        """
        í”„ë¡œì„¸ì„œ ì •ë³´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
        """
        return {
            'processor_name': 'FinalOutputProcessor',
            'device': str(self.device),
            'config': self.processor_config,
            'supported_optimizations': [
                'noise_reduction', 'edge_enhancement', 
                'color_correction', 'resolution_enhancement'
            ]
        }

    def update_processor_config(self, **kwargs):
        """
        í”„ë¡œì„¸ì„œ ì„¤ì •ì„ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.
        """
        try:
            for key, value in kwargs.items():
                if key in self.processor_config:
                    self.processor_config[key] = value
                    logger.info(f"âœ… Processor config updated: {key} = {value}")
                else:
                    logger.warning(f"âš ï¸ Unknown config key: {key}")
        except Exception as e:
            logger.error(f"âŒ Processor config update failed: {e}")
