# app/ai_pipeline/steps/step_07_post_processing.py
"""
7ë‹¨ê³„: í›„ì²˜ë¦¬ (Post Processing) - ìµœì  ìƒì„±ì íŒ¨í„´ ì ìš©
í†µì¼ëœ ìƒì„±ì: def __init__(self, device: Optional[str] = None, config: Optional[Dict[str, Any]] = None, **kwargs)
"""

import os
import logging
import time
import asyncio
from typing import Dict, Any, Optional, Tuple, List, Union
from pathlib import Path

import numpy as np
import json

# í•„ìˆ˜ íŒ¨í‚¤ì§€ë“¤ - ì•ˆì „í•œ ì„í¬íŠ¸ ì²˜ë¦¬
try:
    import torch
    import torch.nn as nn
    import torch.nn.functional as F
    TORCH_AVAILABLE = True
except ImportError:
    TORCH_AVAILABLE = False
    print("âŒ PyTorch ì„¤ì¹˜ í•„ìš”: pip install torch")

try:
    import cv2
    CV2_AVAILABLE = True
except ImportError:
    CV2_AVAILABLE = False
    print("âŒ OpenCV ì„¤ì¹˜ í•„ìš”: pip install opencv-python")

try:
    from PIL import Image, ImageFilter, ImageEnhance
    PIL_AVAILABLE = True
except ImportError:
    PIL_AVAILABLE = False
    print("âš ï¸ PIL ê¶Œì¥: pip install Pillow")

try:
    from concurrent.futures import ThreadPoolExecutor
    CONCURRENT_AVAILABLE = True
except ImportError:
    CONCURRENT_AVAILABLE = False

logger = logging.getLogger(__name__)

class PostProcessingStep:
    """
    Step 7: í›„ì²˜ë¦¬ í’ˆì§ˆ í–¥ìƒ - ìµœì  ìƒì„±ì íŒ¨í„´ ì ìš©
    í†µì¼ëœ ìƒì„±ì: def __init__(self, device: Optional[str] = None, config: Optional[Dict[str, Any]] = None, **kwargs)
    """
    
    def __init__(
        self, 
        device: Optional[str] = None,
        config: Optional[Dict[str, Any]] = None,
        **kwargs
    ):
        """
        ğŸ¯ ìµœì  ìƒì„±ì íŒ¨í„´ - ëª¨ë“  MyCloset AI Stepê³¼ í˜¸í™˜
        
        Args:
            device: ì‚¬ìš©í•  ë””ë°”ì´ìŠ¤ (None=ìë™ê°ì§€, 'cpu', 'cuda', 'mps')
            config: ì„¤ì • ë”•ì…”ë„ˆë¦¬ (ì„ íƒì )
            **kwargs: í™•ì¥ íŒŒë¼ë¯¸í„°ë“¤
                - device_type: str = "auto"
                - memory_gb: float = 16.0  
                - is_m3_max: bool = False
                - optimization_enabled: bool = True
                - quality_level: str = "balanced"
                - ê¸°íƒ€ ìŠ¤í…ë³„ íŠ¹í™” íŒŒë¼ë¯¸í„°ë“¤...
        """
        # 1. ğŸ’¡ ì§€ëŠ¥ì  ë””ë°”ì´ìŠ¤ ìë™ ê°ì§€
        self.device = self._auto_detect_device(device)

        # 2. ğŸ“‹ ê¸°ë³¸ ì„¤ì •
        self.config = config or {}
        self.step_name = self.__class__.__name__
        self.logger = logging.getLogger(f"pipeline.{self.step_name}")

        # 3. ğŸ”§ í‘œì¤€ ì‹œìŠ¤í…œ íŒŒë¼ë¯¸í„° ì¶”ì¶œ (ì¼ê´€ì„±)
        self.device_type = kwargs.get('device_type', 'auto')
        self.memory_gb = kwargs.get('memory_gb', 16.0)
        self.is_m3_max = kwargs.get('is_m3_max', self._detect_m3_max())
        self.optimization_enabled = kwargs.get('optimization_enabled', True)
        self.quality_level = kwargs.get('quality_level', 'balanced')

        # 4. âš™ï¸ ìŠ¤í…ë³„ íŠ¹í™” íŒŒë¼ë¯¸í„°ë¥¼ configì— ë³‘í•©
        self._merge_step_specific_config(kwargs)

        # 5. âœ… ìƒíƒœ ì´ˆê¸°í™”
        self.is_initialized = False

        # 6. ğŸ¯ ê¸°ì¡´ í´ë˜ìŠ¤ë³„ ê³ ìœ  ì´ˆê¸°í™” ë¡œì§ ì‹¤í–‰
        self._initialize_step_specific()

        self.logger.info(f"ğŸ¯ {self.step_name} ì´ˆê¸°í™” - ë””ë°”ì´ìŠ¤: {self.device}")
    
    def _auto_detect_device(self, preferred_device: Optional[str]) -> str:
        """ğŸ’¡ ì§€ëŠ¥ì  ë””ë°”ì´ìŠ¤ ìë™ ê°ì§€"""
        if preferred_device:
            return preferred_device

        try:
            if TORCH_AVAILABLE:
                if torch.backends.mps.is_available():
                    return 'mps'  # M3 Max ìš°ì„ 
                elif torch.cuda.is_available():
                    return 'cuda'  # NVIDIA GPU
                else:
                    return 'cpu'  # í´ë°±
            else:
                return 'cpu'
        except ImportError:
            return 'cpu'

    def _detect_m3_max(self) -> bool:
        """ğŸ M3 Max ì¹© ìë™ ê°ì§€"""
        try:
            import platform
            import subprocess

            if platform.system() == 'Darwin':  # macOS
                # M3 Max ê°ì§€ ë¡œì§
                result = subprocess.run(['sysctl', '-n', 'machdep.cpu.brand_string'], 
                                      capture_output=True, text=True)
                return 'M3' in result.stdout
        except:
            pass
        return False

    def _merge_step_specific_config(self, kwargs: Dict[str, Any]):
        """âš™ï¸ ìŠ¤í…ë³„ íŠ¹í™” ì„¤ì • ë³‘í•©"""
        # ì‹œìŠ¤í…œ íŒŒë¼ë¯¸í„° ì œì™¸í•˜ê³  ëª¨ë“  kwargsë¥¼ configì— ë³‘í•©
        system_params = {
            'device_type', 'memory_gb', 'is_m3_max', 
            'optimization_enabled', 'quality_level'
        }

        for key, value in kwargs.items():
            if key not in system_params:
                self.config[key] = value

    def _initialize_step_specific(self):
        """ğŸ¯ ê¸°ì¡´ ì´ˆê¸°í™” ë¡œì§ ì™„ì „ ìœ ì§€"""
        # M3 Max íŠ¹í™” ì„¤ì •
        self._configure_m3_max_optimizations()
        
        # í›„ì²˜ë¦¬ ì„¤ì •
        self.enhancement_config = self.config.get('post_processing', {
            'super_resolution': True,    # Real-ESRGAN
            'face_enhancement': True,    # GFPGAN
            'image_restoration': True,   # CodeFormer
            'color_correction': True,    # ìƒ‰ìƒ ë³´ì •
            'noise_reduction': True,     # ë…¸ì´ì¦ˆ ì œê±°
            'edge_enhancement': True,    # ì—£ì§€ í–¥ìƒ
            'quality_level': self._get_quality_level()
        })
        
        # M3 Max ìµœì í™” ì„¤ì •
        self.use_mps = self.device == 'mps' and TORCH_AVAILABLE and torch.backends.mps.is_available()
        self.batch_size = self._get_optimal_batch_size()
        self.tile_size = self._get_optimal_tile_size()
        self.enable_neural_enhancement = self.is_m3_max and self.optimization_enabled
        
        # ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ë“¤
        self.real_esrgan = None
        self.gfpgan = None
        self.codeformer = None
        
        # ì „í†µì  ì²˜ë¦¬ ë„êµ¬ë“¤
        self.color_enhancer = None
        self.noise_reducer = None
        self.edge_enhancer = None
        
        # ì´ˆê¸°í™” ìƒíƒœ
        self.initialization_error = None
        
        # ì„±ëŠ¥ í†µê³„
        self.processing_stats = {
            'total_images': 0,
            'average_time': 0.0,
            'enhancement_success_rate': 0.0,
            'm3_max_accelerated': self.is_m3_max,
            'memory_efficiency': 0.0
        }
        
        if self.is_m3_max:
            self.logger.info(f"ğŸ M3 Max ìµœì í™” í™œì„±í™” - ë©”ëª¨ë¦¬: {self.memory_gb}GB")
    
    def _configure_m3_max_optimizations(self):
        """M3 Max ì „ìš© ìµœì í™” ì„¤ì •"""
        if not self.is_m3_max:
            return
        
        try:
            self.logger.info("ğŸ M3 Max í›„ì²˜ë¦¬ ìµœì í™” ì„¤ì •...")
            
            # MPS ìµœì í™”
            if self.device == 'mps' and TORCH_AVAILABLE:
                os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '1'
                os.environ['PYTORCH_MPS_HIGH_WATERMARK_RATIO'] = '0.0'  # ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±
                
                # M3 Max ë©”ëª¨ë¦¬ ìµœì í™”
                if hasattr(torch.backends.mps, 'empty_cache'):
                    torch.backends.mps.empty_cache()
                
                self.logger.info("âœ… M3 Max MPS í›„ì²˜ë¦¬ ìµœì í™” ì™„ë£Œ")
            
            # CPU ìµœì í™” (14ì½”ì–´ M3 Max)
            if TORCH_AVAILABLE:
                optimal_threads = min(12, os.cpu_count() or 8)  # ì„±ëŠ¥ ì½”ì–´ ì¤‘ì‹¬
                torch.set_num_threads(optimal_threads)
                self.logger.info(f"âš¡ M3 Max CPU ìŠ¤ë ˆë“œ ìµœì í™”: {optimal_threads}")
            
            # 128GB ë©”ëª¨ë¦¬ í™œìš© ìµœì í™”
            if self.memory_gb >= 128:
                self.enhancement_config['enable_large_batch'] = True
                self.enhancement_config['memory_aggressive_mode'] = True
                self.logger.info("ğŸ’¾ M3 Max 128GB ë©”ëª¨ë¦¬ í™œìš© ìµœì í™” í™œì„±í™”")
            
        except Exception as e:
            self.logger.warning(f"M3 Max ìµœì í™” ì„¤ì • ì‹¤íŒ¨: {e}")
    
    def _get_quality_level(self) -> str:
        """í’ˆì§ˆ ìˆ˜ì¤€ ê²°ì • - M3 MaxëŠ” ìµœê³  í’ˆì§ˆ"""
        if self.is_m3_max and self.optimization_enabled:
            return 'ultra'  # M3 Max ì „ìš© ìµœê³  í’ˆì§ˆ
        elif self.memory_gb >= 64:
            return 'high'
        elif self.memory_gb >= 32:
            return 'medium'
        else:
            return 'basic'
    
    def _get_optimal_batch_size(self) -> int:
        """ìµœì  ë°°ì¹˜ í¬ê¸° ê²°ì •"""
        if self.is_m3_max and self.memory_gb >= 128:
            return 4  # M3 Max 128GB: ëŒ€ìš©ëŸ‰ ë°°ì¹˜
        elif self.memory_gb >= 64:
            return 2
        else:
            return 1
    
    def _get_optimal_tile_size(self) -> int:
        """ìµœì  íƒ€ì¼ í¬ê¸° ê²°ì •"""
        if self.is_m3_max and self.memory_gb >= 128:
            return 1024  # M3 Max: í° íƒ€ì¼ ì²˜ë¦¬ ê°€ëŠ¥
        elif self.memory_gb >= 64:
            return 768
        else:
            return 512
    
    async def initialize(self) -> bool:
        """í›„ì²˜ë¦¬ ëª¨ë¸ë“¤ ì´ˆê¸°í™”"""
        try:
            self.logger.info("ğŸ”„ Step 7 í›„ì²˜ë¦¬ ëª¨ë¸ ë¡œë“œ ì¤‘...")
            
            # M3 Max ì „ìš© ì´ˆê¸°í™”
            if self.is_m3_max:
                await self._initialize_m3_max_components()
            
            initialization_tasks = []
            
            # AI ëª¨ë¸ ë¹„ë™ê¸° ì´ˆê¸°í™”
            if self.enhancement_config.get('super_resolution', True):
                initialization_tasks.append(self._init_real_esrgan())
            
            if self.enhancement_config.get('face_enhancement', True):
                initialization_tasks.append(self._init_gfpgan())
            
            if self.enhancement_config.get('image_restoration', True):
                initialization_tasks.append(self._init_codeformer())
            
            # ì „í†µì  ë„êµ¬ ì´ˆê¸°í™”
            initialization_tasks.extend([
                self._init_color_enhancer(),
                self._init_noise_reducer(),
                self._init_edge_enhancer()
            ])
            
            # ë³‘ë ¬ ì´ˆê¸°í™” ì‹¤í–‰
            results = await asyncio.gather(*initialization_tasks, return_exceptions=True)
            
            # ì´ˆê¸°í™” ê²°ê³¼ í™•ì¸
            success_count = sum(1 for result in results if result is True)
            total_count = len(results)
            
            if success_count >= total_count // 2:  # ì ˆë°˜ ì´ìƒ ì„±ê³µì‹œ OK
                self.is_initialized = True
                
                # M3 Max ì›Œë°ì—…
                if self.is_m3_max and self.optimization_enabled:
                    await self._warmup_m3_max_pipeline()
                
                self.logger.info(f"âœ… Step 7 í›„ì²˜ë¦¬ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ ({success_count}/{total_count})")
                return True
            else:
                self.logger.error(f"âŒ Step 7 í›„ì²˜ë¦¬ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨ ({success_count}/{total_count})")
                return False
                
        except Exception as e:
            self.logger.error(f"âŒ Step 7 í›„ì²˜ë¦¬ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.is_initialized = False
            self.initialization_error = str(e)
            return False
    
    async def _initialize_m3_max_components(self):
        """M3 Max ì „ìš© ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”"""
        self.logger.info("ğŸ M3 Max í›„ì²˜ë¦¬ ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”...")
        
        # Metal Performance Shaders ì„¤ì •
        if self.device == 'mps' and TORCH_AVAILABLE:
            try:
                # MPS ë°±ì—”ë“œ í…ŒìŠ¤íŠ¸
                test_tensor = torch.randn(1, 3, 256, 256).to(self.device)
                _ = F.conv2d(test_tensor, torch.randn(3, 3, 3, 3).to(self.device), padding=1)
                del test_tensor
                self.logger.info("âœ… M3 Max MPS í›„ì²˜ë¦¬ í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
            except Exception as e:
                self.logger.warning(f"MPS í›„ì²˜ë¦¬ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        
        # ê³ ì„±ëŠ¥ ë©”ëª¨ë¦¬ ê´€ë¦¬
        if self.memory_gb >= 128:
            import gc
            gc.collect()
            self.logger.info("âœ… M3 Max 128GB í›„ì²˜ë¦¬ ë©”ëª¨ë¦¬ ê´€ë¦¬ ì„¤ì •")
    
    async def _warmup_m3_max_pipeline(self):
        """M3 Max í›„ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì›Œë°ì—…"""
        self.logger.info("ğŸ”¥ M3 Max í›„ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì›Œë°ì—…...")
        
        try:
            # ì‘ì€ ë”ë¯¸ ì´ë¯¸ì§€ë¡œ ì›Œë°ì—…
            if TORCH_AVAILABLE:
                dummy_image = torch.randn(1, 3, 256, 256).to(self.device)
            
            # ê° ì»´í¬ë„ŒíŠ¸ ì›Œë°ì—…
            if self.real_esrgan and hasattr(self.real_esrgan, 'warmup'):
                await self.real_esrgan.warmup()
            
            if self.color_enhancer and TORCH_AVAILABLE:
                self.color_enhancer.correct_colors(dummy_image)
            
            self.logger.info("âœ… M3 Max í›„ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì›Œë°ì—… ì™„ë£Œ")
            
        except Exception as e:
            self.logger.warning(f"M3 Max í›„ì²˜ë¦¬ ì›Œë°ì—… ì‹¤íŒ¨: {e}")
    
    async def _init_real_esrgan(self) -> bool:
        """Real-ESRGAN Super Resolution ëª¨ë¸ ì´ˆê¸°í™”"""
        try:
            # M3 Max ìµœì í™” ì—…ìŠ¤ì¼€ì¼ë§
            self.real_esrgan = M3MaxUpscaler(
                device=self.device,
                scale_factor=4 if self.is_m3_max else 2,
                use_neural=self.enable_neural_enhancement
            )
            self.logger.info("âœ… Real-ESRGAN M3 Max ìµœì í™” ëª¨ë“œ ì‚¬ìš©")
            return True
                
        except Exception as e:
            self.logger.warning(f"Real-ESRGAN ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.real_esrgan = M3MaxUpscaler(device=self.device)
            return True
    
    async def _init_gfpgan(self) -> bool:
        """GFPGAN ì–¼êµ´ í–¥ìƒ ëª¨ë¸ ì´ˆê¸°í™”"""
        try:
            # M3 Max ì–¼êµ´ í–¥ìƒ
            self.gfpgan = M3MaxFaceEnhancer(
                device=self.device,
                enhancement_strength=1.5 if self.is_m3_max else 1.0
            )
            self.logger.info("âœ… GFPGAN M3 Max ìµœì í™” ëª¨ë“œ ì‚¬ìš©")
            return True
                
        except Exception as e:
            self.logger.warning(f"GFPGAN ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.gfpgan = M3MaxFaceEnhancer(device=self.device)
            return True
    
    async def _init_codeformer(self) -> bool:
        """CodeFormer ì´ë¯¸ì§€ ë³µì› ëª¨ë¸ ì´ˆê¸°í™”"""
        try:
            # M3 Max ì´ë¯¸ì§€ ë³µì›
            self.codeformer = M3MaxImageRestorer(
                device=self.device,
                restoration_strength=1.2 if self.is_m3_max else 1.0
            )
            self.logger.info("âœ… CodeFormer M3 Max ìµœì í™” ëª¨ë“œ ì‚¬ìš©")
            return True
                
        except Exception as e:
            self.logger.warning(f"CodeFormer ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.codeformer = M3MaxImageRestorer(device=self.device)
            return True
    
    async def _init_color_enhancer(self) -> bool:
        """ìƒ‰ìƒ í–¥ìƒê¸° ì´ˆê¸°í™”"""
        try:
            self.color_enhancer = ColorEnhancer(
                device=self.device,
                m3_max_mode=self.is_m3_max
            )
            return True
        except Exception as e:
            self.logger.warning(f"ìƒ‰ìƒ í–¥ìƒê¸° ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return False
    
    async def _init_noise_reducer(self) -> bool:
        """ë…¸ì´ì¦ˆ ì œê±°ê¸° ì´ˆê¸°í™”"""
        try:
            self.noise_reducer = NoiseReducer(
                device=self.device,
                m3_max_mode=self.is_m3_max
            )
            return True
        except Exception as e:
            self.logger.warning(f"ë…¸ì´ì¦ˆ ì œê±°ê¸° ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return False
    
    async def _init_edge_enhancer(self) -> bool:
        """ì—£ì§€ í–¥ìƒê¸° ì´ˆê¸°í™”"""
        try:
            self.edge_enhancer = EdgeEnhancer(
                device=self.device,
                m3_max_mode=self.is_m3_max
            )
            return True
        except Exception as e:
            self.logger.warning(f"ì—£ì§€ í–¥ìƒê¸° ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return False
    
    # =================================================================
    # ë©”ì¸ ì²˜ë¦¬ ë©”ì„œë“œ - ê¸°ì¡´ ë¡œì§ ì™„ì „ ìœ ì§€
    # =================================================================
    
    async def process(
        self, 
        input_data: Union[np.ndarray, torch.Tensor, str, Dict[str, Any]],
        **kwargs
    ) -> Dict[str, Any]:
        """
        í›„ì²˜ë¦¬ ë©”ì¸ ì²˜ë¦¬ í•¨ìˆ˜ - ê¸°ì¡´ ë¡œì§ ì™„ì „ ìœ ì§€
        
        Args:
            input_data: ì…ë ¥ ì´ë¯¸ì§€ (ë‹¤ì–‘í•œ í˜•íƒœ ì§€ì›)
            **kwargs: ì¶”ê°€ ë§¤ê°œë³€ìˆ˜
                - enhancement_options: Optional[Dict[str, Any]] = None
                - quality_target: float = 0.8
                
        Returns:
            í›„ì²˜ë¦¬ ê²°ê³¼
        """
        if not self.is_initialized:
            await self.initialize()
        
        start_time = time.time()
        
        try:
            # M3 Max ë©”ëª¨ë¦¬ ìµœì í™”
            if self.is_m3_max:
                await self._optimize_m3_max_memory()
            
            # 1. ì…ë ¥ ì „ì²˜ë¦¬
            if isinstance(input_data, dict):
                # ê°€ìƒ í”¼íŒ… ê²°ê³¼ì—ì„œ ì´ë¯¸ì§€ ì¶”ì¶œ
                input_image = input_data.get('fitted_image') or input_data.get('fitted_image_numpy')
                if input_image is None:
                    raise ValueError("ì…ë ¥ ë”•ì…”ë„ˆë¦¬ì—ì„œ ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            else:
                input_image = input_data
            
            image_tensor = await self._preprocess_input(input_image)
            original_shape = image_tensor.shape if TORCH_AVAILABLE else input_image.shape
            
            self.logger.info(f"ğŸ¨ í›„ì²˜ë¦¬ ì‹œì‘ - í¬ê¸°: {original_shape}")
            
            # 2. í–¥ìƒ ì˜µì…˜ ì„¤ì •
            enhancement_options = kwargs.get('enhancement_options', {})
            quality_target = kwargs.get('quality_target', 0.8)
            
            options = {**self.enhancement_config, **enhancement_options}
            
            # M3 Max ëª¨ë“œì—ì„œ ìë™ ìµœì í™”
            if self.is_m3_max and self.optimization_enabled:
                options = self._apply_m3_max_optimizations(options)
            
            # 3. ìˆœì°¨ì  í–¥ìƒ ì²˜ë¦¬
            enhanced_image = image_tensor
            processing_log = []
            
            # Super Resolution (í•´ìƒë„ í–¥ìƒ)
            if options.get('super_resolution', True) and self.real_esrgan:
                self.logger.info("ğŸ” Super Resolution ì ìš© ì¤‘...")
                enhanced_image, sr_metrics = await self._apply_super_resolution(enhanced_image)
                processing_log.append({'step': 'super_resolution', 'metrics': sr_metrics})
            
            # Face Enhancement (ì–¼êµ´ í–¥ìƒ)
            if options.get('face_enhancement', True) and self.gfpgan:
                self.logger.info("ğŸ‘¤ ì–¼êµ´ í–¥ìƒ ì ìš© ì¤‘...")
                enhanced_image, face_metrics = await self._apply_face_enhancement(enhanced_image)
                processing_log.append({'step': 'face_enhancement', 'metrics': face_metrics})
            
            # Image Restoration (ì „ì²´ ë³µì›)
            if options.get('image_restoration', True) and self.codeformer:
                self.logger.info("ğŸ”§ ì´ë¯¸ì§€ ë³µì› ì ìš© ì¤‘...")
                enhanced_image, restoration_metrics = await self._apply_image_restoration(enhanced_image)
                processing_log.append({'step': 'image_restoration', 'metrics': restoration_metrics})
            
            # Color Correction (ìƒ‰ìƒ ë³´ì •)
            if options.get('color_correction', True) and self.color_enhancer:
                self.logger.info("ğŸŒˆ ìƒ‰ìƒ ë³´ì • ì ìš© ì¤‘...")
                enhanced_image, color_metrics = await self._apply_color_correction(enhanced_image)
                processing_log.append({'step': 'color_correction', 'metrics': color_metrics})
            
            # Noise Reduction (ë…¸ì´ì¦ˆ ì œê±°)
            if options.get('noise_reduction', True) and self.noise_reducer:
                self.logger.info("ğŸ”‡ ë…¸ì´ì¦ˆ ì œê±° ì ìš© ì¤‘...")
                enhanced_image, noise_metrics = await self._apply_noise_reduction(enhanced_image)
                processing_log.append({'step': 'noise_reduction', 'metrics': noise_metrics})
            
            # Edge Enhancement (ì—£ì§€ í–¥ìƒ)
            if options.get('edge_enhancement', True) and self.edge_enhancer:
                self.logger.info("ğŸ“ ì—£ì§€ í–¥ìƒ ì ìš© ì¤‘...")
                enhanced_image, edge_metrics = await self._apply_edge_enhancement(enhanced_image)
                processing_log.append({'step': 'edge_enhancement', 'metrics': edge_metrics})
            
            # M3 Max ì „ìš© ìµœì¢… í–¥ìƒ
            if self.is_m3_max and self.optimization_enabled:
                self.logger.info("ğŸ M3 Max ìµœì¢… í–¥ìƒ ì ìš© ì¤‘...")
                enhanced_image, m3_metrics = await self._apply_m3_max_final_enhancement(enhanced_image)
                processing_log.append({'step': 'm3_max_enhancement', 'metrics': m3_metrics})
            
            # 4. í›„ì²˜ë¦¬ ë° í’ˆì§ˆ í‰ê°€
            final_image = await self._postprocess_output(enhanced_image)
            quality_score = await self._evaluate_enhancement_quality(
                original=image_tensor, 
                enhanced=final_image
            )
            
            # 5. ê²°ê³¼ êµ¬ì„±
            processing_time = time.time() - start_time
            
            result = {
                'success': True,
                'enhanced_image': final_image,
                'original_shape': original_shape,
                'final_shape': final_image.shape if hasattr(final_image, 'shape') else (0, 0),
                'quality_score': quality_score,
                'processing_time': processing_time,
                'enhancement_log': processing_log,
                'applied_enhancements': [log['step'] for log in processing_log],
                'target_achieved': quality_score >= quality_target,
                'device_used': self.device,
                'device_type': self.device_type,
                'm3_max_optimized': self.is_m3_max,
                'memory_gb': self.memory_gb,
                'config_used': options,
                'performance_info': {
                    'optimization_enabled': self.optimization_enabled,
                    'batch_size': self.batch_size,
                    'tile_size': self.tile_size,
                    'neural_enhancement': self.enable_neural_enhancement
                }
            }
            
            # 6. í†µê³„ ì—…ë°ì´íŠ¸
            self._update_processing_stats(processing_time, quality_score)
            
            self.logger.info(f"âœ… í›„ì²˜ë¦¬ ì™„ë£Œ - í’ˆì§ˆ: {quality_score:.3f}, ì‹œê°„: {processing_time:.2f}ì´ˆ")
            
            return result
            
        except Exception as e:
            error_msg = f"í›„ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}"
            self.logger.error(error_msg)
            
            return {
                'success': False,
                'error': error_msg,
                'processing_time': time.time() - start_time,
                'device_used': self.device,
                'device_type': self.device_type,
                'm3_max_optimized': self.is_m3_max
            }
    
    async def _optimize_m3_max_memory(self):
        """M3 Max ë©”ëª¨ë¦¬ ìµœì í™”"""
        if not self.is_m3_max:
            return
        
        try:
            import gc
            gc.collect()
            
            if self.device == 'mps' and TORCH_AVAILABLE:
                if hasattr(torch.backends.mps, 'empty_cache'):
                    torch.backends.mps.empty_cache()
                elif hasattr(torch.mps, 'synchronize'):
                    torch.mps.synchronize()
                
            self.logger.debug("ğŸ M3 Max í›„ì²˜ë¦¬ ë©”ëª¨ë¦¬ ìµœì í™” ì™„ë£Œ")
            
        except Exception as e:
            self.logger.warning(f"M3 Max ë©”ëª¨ë¦¬ ìµœì í™” ì‹¤íŒ¨: {e}")
    
    def _apply_m3_max_optimizations(self, options: Dict[str, Any]) -> Dict[str, Any]:
        """M3 Max ì „ìš© ì˜µì…˜ ìµœì í™”"""
        if not self.is_m3_max:
            return options
        
        # M3 Maxì—ì„œ ë” ê³µê²©ì ì¸ í–¥ìƒ
        optimized_options = options.copy()
        optimized_options['enhancement_strength'] = 1.2
        optimized_options['precision_mode'] = 'high'
        optimized_options['memory_efficient'] = True
        
        if self.memory_gb >= 128:
            optimized_options['enable_large_operations'] = True
            optimized_options['batch_optimization'] = True
        
        self.logger.debug("ğŸ M3 Max ì˜µì…˜ ìµœì í™” ì ìš©")
        return optimized_options
    
    async def _preprocess_input(self, input_image: Union[np.ndarray, torch.Tensor, str]) -> Union[torch.Tensor, np.ndarray]:
        """ì…ë ¥ ì „ì²˜ë¦¬ - M3 Max ìµœì í™”"""
        try:
            if isinstance(input_image, str):
                # Base64 ë””ì½”ë”©
                import base64
                import io
                from PIL import Image
                
                if input_image.startswith('data:image'):
                    header, data = input_image.split(',', 1)
                    image_data = base64.b64decode(data)
                else:
                    image_data = base64.b64decode(input_image)
                
                pil_image = Image.open(io.BytesIO(image_data))
                image_np = np.array(pil_image)
                
            elif isinstance(input_image, np.ndarray):
                image_np = input_image.copy()
                
            elif TORCH_AVAILABLE and isinstance(input_image, torch.Tensor):
                return input_image.to(self.device)
                
            else:
                raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì…ë ¥ íƒ€ì…: {type(input_image)}")
            
            if not TORCH_AVAILABLE:
                return image_np
            
            # NumPyë¥¼ PyTorch í…ì„œë¡œ ë³€í™˜
            if len(image_np.shape) == 3 and image_np.shape[2] == 3:
                # HWC -> CHW
                tensor = torch.from_numpy(image_np.transpose(2, 0, 1)).float()
                
                # ì •ê·œí™” (0-255 -> 0-1)
                if tensor.max() > 1.0:
                    tensor = tensor / 255.0
                
                # ë°°ì¹˜ ì°¨ì› ì¶”ê°€
                if len(tensor.shape) == 3:
                    tensor = tensor.unsqueeze(0)
                
                return tensor.to(self.device)
            
            else:
                raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì´ë¯¸ì§€ í˜•íƒœ: {image_np.shape}")
                
        except Exception as e:
            self.logger.error(f"ì…ë ¥ ì „ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            # ê¸°ë³¸ ë”ë¯¸ í…ì„œ ë°˜í™˜
            if TORCH_AVAILABLE:
                return torch.zeros(1, 3, 512, 512, device=self.device)
            else:
                return np.zeros((512, 512, 3), dtype=np.uint8)
    
    # =================================================================
    # í–¥ìƒ ì²˜ë¦¬ ë©”ì„œë“œë“¤ - ê¸°ì¡´ ë¡œì§ ì™„ì „ ìœ ì§€
    # =================================================================
    
    async def _apply_super_resolution(self, image: Union[torch.Tensor, np.ndarray]) -> Tuple[Union[torch.Tensor, np.ndarray], Dict]:
        """Super Resolution ì ìš© - M3 Max ìµœì í™”"""
        try:
            start_time = time.time()
            
            if hasattr(self.real_esrgan, 'enhance'):
                # ì‹¤ì œ Real-ESRGAN ëª¨ë¸
                enhanced = await asyncio.to_thread(self.real_esrgan.enhance, image)
            else:
                # M3 Max ìµœì í™” ì—…ìŠ¤ì¼€ì¼ë§
                enhanced = await asyncio.to_thread(self.real_esrgan.upscale, image)
            
            processing_time = time.time() - start_time
            
            # í’ˆì§ˆ ë©”íŠ¸ë¦­ ê³„ì‚°
            if hasattr(enhanced, 'shape') and hasattr(image, 'shape'):
                scale_factor = enhanced.shape[-1] / image.shape[-1]
                improvement_score = self._calculate_sharpness_improvement(image, enhanced)
            else:
                scale_factor = 2.0
                improvement_score = 0.8
            
            # M3 Max ë³´ë„ˆìŠ¤
            if self.is_m3_max:
                improvement_score = min(1.0, improvement_score * 1.1)
            
            metrics = {
                'processing_time': processing_time,
                'scale_factor': scale_factor,
                'improvement_score': improvement_score,
                'm3_max_accelerated': self.is_m3_max,
                'device': self.device
            }
            
            return enhanced, metrics
            
        except Exception as e:
            self.logger.warning(f"Super Resolution ì‹¤íŒ¨: {e}")
            return image, {'error': str(e)}
    
    async def _apply_face_enhancement(self, image: Union[torch.Tensor, np.ndarray]) -> Tuple[Union[torch.Tensor, np.ndarray], Dict]:
        """ì–¼êµ´ í–¥ìƒ ì ìš© - M3 Max ìµœì í™”"""
        try:
            start_time = time.time()
            
            if hasattr(self.gfpgan, 'enhance'):
                enhanced = await asyncio.to_thread(self.gfpgan.enhance, image)
            else:
                enhanced = await asyncio.to_thread(self.gfpgan.process, image)
            
            processing_time = time.time() - start_time
            
            face_regions = self._count_face_regions(image)
            enhancement_strength = 0.8 if self.is_m3_max else 0.7
            
            metrics = {
                'processing_time': processing_time,
                'face_regions_processed': face_regions,
                'enhancement_strength': enhancement_strength,
                'm3_max_enhanced': self.is_m3_max
            }
            
            return enhanced, metrics
            
        except Exception as e:
            self.logger.warning(f"ì–¼êµ´ í–¥ìƒ ì‹¤íŒ¨: {e}")
            return image, {'error': str(e)}
    
    async def _apply_image_restoration(self, image: Union[torch.Tensor, np.ndarray]) -> Tuple[Union[torch.Tensor, np.ndarray], Dict]:
        """ì´ë¯¸ì§€ ë³µì› ì ìš© - M3 Max ìµœì í™”"""
        try:
            start_time = time.time()
            
            if hasattr(self.codeformer, 'restore'):
                enhanced = await asyncio.to_thread(self.codeformer.restore, image)
            else:
                enhanced = await asyncio.to_thread(self.codeformer.process, image)
            
            processing_time = time.time() - start_time
            
            artifacts_removed = self._estimate_artifacts_removed(image, enhanced)
            detail_preservation = self._calculate_detail_preservation(image, enhanced)
            
            # M3 Max ì •ë°€ë„ ë³´ë„ˆìŠ¤
            if self.is_m3_max:
                detail_preservation = min(1.0, detail_preservation * 1.05)
            
            metrics = {
                'processing_time': processing_time,
                'artifacts_removed': artifacts_removed,
                'detail_preservation': detail_preservation,
                'm3_max_precision': self.is_m3_max
            }
            
            return enhanced, metrics
            
        except Exception as e:
            self.logger.warning(f"ì´ë¯¸ì§€ ë³µì› ì‹¤íŒ¨: {e}")
            return image, {'error': str(e)}
    
    async def _apply_color_correction(self, image: Union[torch.Tensor, np.ndarray]) -> Tuple[Union[torch.Tensor, np.ndarray], Dict]:
        """ìƒ‰ìƒ ë³´ì • ì ìš© - M3 Max ìµœì í™”"""
        try:
            start_time = time.time()
            
            enhanced = await asyncio.to_thread(self.color_enhancer.correct_colors, image)
            
            processing_time = time.time() - start_time
            
            color_improvement = self._calculate_color_balance_improvement(image, enhanced)
            saturation_change = self._calculate_saturation_change(image, enhanced)
            
            metrics = {
                'processing_time': processing_time,
                'color_balance_improvement': color_improvement,
                'saturation_adjustment': saturation_change,
                'm3_max_precision': self.is_m3_max
            }
            
            return enhanced, metrics
            
        except Exception as e:
            self.logger.warning(f"ìƒ‰ìƒ ë³´ì • ì‹¤íŒ¨: {e}")
            return image, {'error': str(e)}
    
    async def _apply_noise_reduction(self, image: Union[torch.Tensor, np.ndarray]) -> Tuple[Union[torch.Tensor, np.ndarray], Dict]:
        """ë…¸ì´ì¦ˆ ì œê±° ì ìš© - M3 Max ìµœì í™”"""
        try:
            start_time = time.time()
            
            enhanced = await asyncio.to_thread(self.noise_reducer.reduce_noise, image)
            
            processing_time = time.time() - start_time
            
            noise_reduction = self._calculate_noise_reduction(image, enhanced)
            detail_preservation = self._calculate_detail_preservation(image, enhanced)
            
            metrics = {
                'processing_time': processing_time,
                'noise_reduction_amount': noise_reduction,
                'detail_preservation': detail_preservation,
                'm3_max_filtering': self.is_m3_max
            }
            
            return enhanced, metrics
            
        except Exception as e:
            self.logger.warning(f"ë…¸ì´ì¦ˆ ì œê±° ì‹¤íŒ¨: {e}")
            return image, {'error': str(e)}
    
    async def _apply_edge_enhancement(self, image: Union[torch.Tensor, np.ndarray]) -> Tuple[Union[torch.Tensor, np.ndarray], Dict]:
        """ì—£ì§€ í–¥ìƒ ì ìš© - M3 Max ìµœì í™”"""
        try:
            start_time = time.time()
            
            enhanced = await asyncio.to_thread(self.edge_enhancer.enhance_edges, image)
            
            processing_time = time.time() - start_time
            
            edge_improvement = self._calculate_edge_improvement(image, enhanced)
            sharpness_gain = self._calculate_sharpness_improvement(image, enhanced)
            
            metrics = {
                'processing_time': processing_time,
                'edge_strength_improvement': edge_improvement,
                'sharpness_gain': sharpness_gain,
                'm3_max_precision': self.is_m3_max
            }
            
            return enhanced, metrics
            
        except Exception as e:
            self.logger.warning(f"ì—£ì§€ í–¥ìƒ ì‹¤íŒ¨: {e}")
            return image, {'error': str(e)}
    
    async def _apply_m3_max_final_enhancement(self, image: Union[torch.Tensor, np.ndarray]) -> Tuple[Union[torch.Tensor, np.ndarray], Dict]:
        """M3 Max ì „ìš© ìµœì¢… í–¥ìƒ"""
        if not self.is_m3_max:
            return image, {'skipped': 'not_m3_max'}
        
        try:
            start_time = time.time()
            
            # M3 Max Metal Performance Shaders í™œìš©
            if TORCH_AVAILABLE and isinstance(image, torch.Tensor):
                enhanced = image.clone()
                
                # 1. ê³ ê¸‰ ì–¸ìƒµ ë§ˆìŠ¤í¬
                enhanced = self._apply_advanced_unsharp_mask(enhanced, strength=0.3)
                
                # 2. ì ì‘ì  íˆìŠ¤í† ê·¸ë¨ ê· ë“±í™” (í…ì„œ ê¸°ë°˜)
                enhanced = self._apply_adaptive_histogram_equalization(enhanced)
                
                # 3. ìƒ‰ìƒ ë¯¸ì„¸ ì¡°ì •
                enhanced = self._apply_color_fine_tuning(enhanced)
            else:
                # NumPy ê¸°ë°˜ ì²˜ë¦¬
                enhanced = self._apply_numpy_enhancement(image)
            
            processing_time = time.time() - start_time
            
            metrics = {
                'processing_time': processing_time,
                'advanced_unsharp': True,
                'adaptive_histogram': True,
                'color_fine_tuning': True,
                'm3_max_exclusive': True
            }
            
            return enhanced, metrics
            
        except Exception as e:
            self.logger.warning(f"M3 Max ìµœì¢… í–¥ìƒ ì‹¤íŒ¨: {e}")
            return image, {'error': str(e)}
    
    # =================================================================
    # í—¬í¼ ë©”ì„œë“œë“¤ - ê¸°ì¡´ ë¡œì§ ì™„ì „ ìœ ì§€
    # =================================================================
    
    def _apply_advanced_unsharp_mask(self, image: torch.Tensor, strength: float = 0.3) -> torch.Tensor:
        """M3 Max ê³ ê¸‰ ì–¸ìƒµ ë§ˆìŠ¤í¬"""
        try:
            # ê°€ìš°ì‹œì•ˆ ë¸”ëŸ¬
            kernel_size = 5
            sigma = 1.5
            
            # ê°€ìš°ì‹œê°„ ì»¤ë„ ìƒì„±
            kernel = self._get_gaussian_kernel(kernel_size, sigma).to(image.device)
            
            # ë¸”ëŸ¬ ì ìš©
            blurred = F.conv2d(image, kernel, padding=kernel_size//2, groups=image.shape[1])
            
            # ì–¸ìƒµ ë§ˆìŠ¤í¬
            unsharp = image + strength * (image - blurred)
            
            return torch.clamp(unsharp, 0.0, 1.0)
            
        except Exception as e:
            self.logger.warning(f"ê³ ê¸‰ ì–¸ìƒµ ë§ˆìŠ¤í¬ ì‹¤íŒ¨: {e}")
            return image
    
    def _apply_adaptive_histogram_equalization(self, image: torch.Tensor) -> torch.Tensor:
        """ì ì‘ì  íˆìŠ¤í† ê·¸ë¨ ê· ë“±í™” (í…ì„œ ê¸°ë°˜)"""
        try:
            # L ì±„ë„ ê·¼ì‚¬ (ë°ê¸°)
            l_channel = 0.299 * image[:, 0:1] + 0.587 * image[:, 1:2] + 0.114 * image[:, 2:3]
            
            # íˆìŠ¤í† ê·¸ë¨ ê· ë“±í™” ê·¼ì‚¬
            enhanced_l = torch.clamp(l_channel * 1.1, 0.0, 1.0)
            
            # ì›ë˜ ìƒ‰ìƒ ë¹„ìœ¨ ìœ ì§€
            ratio = enhanced_l / (l_channel + 1e-6)
            enhanced = image * ratio
            
            return torch.clamp(enhanced, 0.0, 1.0)
            
        except Exception as e:
            self.logger.warning(f"ì ì‘ì  íˆìŠ¤í† ê·¸ë¨ ê· ë“±í™” ì‹¤íŒ¨: {e}")
            return image
    
    def _apply_color_fine_tuning(self, image: torch.Tensor) -> torch.Tensor:
        """M3 Max ìƒ‰ìƒ ë¯¸ì„¸ ì¡°ì •"""
        try:
            # ì±„ë„ ë¯¸ì„¸ ì¦ê°€
            enhanced = image.clone()
            
            # RGB í‰ê· 
            mean_intensity = torch.mean(enhanced, dim=1, keepdim=True)
            
            # ì±„ë„ ì¦ê°€
            saturation_boost = 0.05  # 5% ì¦ê°€
            enhanced = enhanced + saturation_boost * (enhanced - mean_intensity)
            
            return torch.clamp(enhanced, 0.0, 1.0)
            
        except Exception as e:
            self.logger.warning(f"ìƒ‰ìƒ ë¯¸ì„¸ ì¡°ì • ì‹¤íŒ¨: {e}")
            return image
    
    def _apply_numpy_enhancement(self, image: np.ndarray) -> np.ndarray:
        """NumPy ê¸°ë°˜ í–¥ìƒ ì²˜ë¦¬"""
        try:
            if not CV2_AVAILABLE:
                return image
            
            # ê¸°ë³¸ ì„ ëª…í™”
            kernel = np.array([[-1,-1,-1], [-1,9,-1], [-1,-1,-1]]) * 0.1
            enhanced = cv2.filter2D(image, -1, kernel)
            
            return np.clip(enhanced, 0, 255).astype(np.uint8)
            
        except Exception as e:
            self.logger.warning(f"NumPy í–¥ìƒ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return image
    
    async def _postprocess_output(self, image: Union[torch.Tensor, np.ndarray]) -> Union[torch.Tensor, np.ndarray]:
        """ì¶œë ¥ í›„ì²˜ë¦¬ - M3 Max ìµœì í™”"""
        try:
            if TORCH_AVAILABLE and isinstance(image, torch.Tensor):
                # í…ì„œ ì •ê·œí™” ë° í´ë¦¬í•‘
                image = torch.clamp(image, 0.0, 1.0)
                
                # ìµœì¢… í’ˆì§ˆ ì¡°ì •
                if self.enhancement_config.get('final_adjustment', True):
                    image = self._apply_final_adjustments(image)
                
                # M3 Max ì „ìš© ìµœì¢… í´ë¦¬ì‹±
                if self.is_m3_max and self.optimization_enabled:
                    image = self._apply_m3_max_final_polish(image)
            
            return image
            
        except Exception as e:
            self.logger.warning(f"ì¶œë ¥ í›„ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return image
    
    def _apply_final_adjustments(self, image: torch.Tensor) -> torch.Tensor:
        """ìµœì¢… ì¡°ì • ì ìš©"""
        try:
            # ì•½ê°„ì˜ ì„ ëª…ë„ í–¥ìƒ
            if self.enhancement_config.get('final_sharpening', True):
                strength = 0.3 if self.is_m3_max else 0.2
                image = self._apply_unsharp_mask(image, strength=strength)
            
            # ìƒ‰ìƒ ë¯¸ì„¸ ì¡°ì •
            if self.enhancement_config.get('final_color_boost', True):
                factor = 0.15 if self.is_m3_max else 0.1
                image = self._boost_colors(image, factor=factor)
            
            return image
            
        except Exception as e:
            self.logger.warning(f"ìµœì¢… ì¡°ì • ì‹¤íŒ¨: {e}")
            return image
    
    def _apply_m3_max_final_polish(self, image: torch.Tensor) -> torch.Tensor:
        """M3 Max ì „ìš© ìµœì¢… í´ë¦¬ì‹±"""
        try:
            # ë¯¸ì„¸í•œ ë…¸ì´ì¦ˆ ì œê±°
            polished = F.conv2d(
                image,
                self._get_smoothing_kernel().to(image.device),
                padding=1,
                groups=image.shape[1]
            )
            
            # ì›ë³¸ê³¼ ë¸”ë Œë”© (99% ì›ë³¸, 1% ìŠ¤ë¬´ë”©)
            final = 0.99 * image + 0.01 * polished
            
            return torch.clamp(final, 0.0, 1.0)
            
        except Exception as e:
            self.logger.warning(f"M3 Max ìµœì¢… í´ë¦¬ì‹± ì‹¤íŒ¨: {e}")
            return image
    
    def _apply_unsharp_mask(self, image: torch.Tensor, strength: float = 0.2) -> torch.Tensor:
        """ì–¸ìƒµ ë§ˆìŠ¤í¬ ì ìš©"""
        try:
            # ê°€ìš°ì‹œì•ˆ ë¸”ëŸ¬
            blurred = F.conv2d(
                image,
                self._get_gaussian_kernel(5, 1.0).to(image.device),
                padding=2,
                groups=image.shape[1]
            )
            
            # ì–¸ìƒµ ë§ˆìŠ¤í¬
            unsharp = image + strength * (image - blurred)
            
            return torch.clamp(unsharp, 0.0, 1.0)
            
        except Exception as e:
            self.logger.warning(f"ì–¸ìƒµ ë§ˆìŠ¤í¬ ì‹¤íŒ¨: {e}")
            return image
    
    def _boost_colors(self, image: torch.Tensor, factor: float = 0.1) -> torch.Tensor:
        """ìƒ‰ìƒ ë¶€ìŠ¤íŠ¸"""
        try:
            # RGBë¥¼ HSVë¡œ ë³€í™˜ (ê·¼ì‚¬)
            # ë‹¨ìˆœí™”ëœ ì±„ë„ ì¦ê°€
            mean_brightness = torch.mean(image, dim=1, keepdim=True)
            color_deviation = image - mean_brightness
            
            # ì±„ë„ ì¦ê°€
            boosted = image + factor * color_deviation
            
            return torch.clamp(boosted, 0.0, 1.0)
            
        except Exception as e:
            self.logger.warning(f"ìƒ‰ìƒ ë¶€ìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
            return image
    
    def _get_gaussian_kernel(self, size: int, sigma: float) -> torch.Tensor:
        """ê°€ìš°ì‹œì•ˆ ì»¤ë„ ìƒì„±"""
        coords = torch.arange(size, dtype=torch.float32)
        coords -= size // 2
        
        g = torch.exp(-(coords ** 2) / (2 * sigma ** 2))
        g /= g.sum()
        
        # 2D ì»¤ë„
        kernel = g[:, None] * g[None, :]
        
        # 3ì±„ë„ìš©ìœ¼ë¡œ í™•ì¥
        kernel = kernel.expand(3, 1, size, size)
        
        return kernel
    
    def _get_smoothing_kernel(self) -> torch.Tensor:
        """ìŠ¤ë¬´ë”© ì»¤ë„ ìƒì„±"""
        kernel = torch.tensor([
            [[1, 2, 1],
             [2, 4, 2],
             [1, 2, 1]]
        ], dtype=torch.float32) / 16.0
        
        # 3ì±„ë„ìš©ìœ¼ë¡œ í™•ì¥
        kernel = kernel.expand(3, 1, 3, 3)
        
        return kernel
    
    # =================================================================
    # í’ˆì§ˆ í‰ê°€ ë° í—¬í¼ ë©”ì„œë“œë“¤ - ê¸°ì¡´ ë¡œì§ ì™„ì „ ìœ ì§€
    # =================================================================
    
    async def _evaluate_enhancement_quality(self, original: Union[torch.Tensor, np.ndarray], enhanced: Union[torch.Tensor, np.ndarray]) -> float:
        """í–¥ìƒ í’ˆì§ˆ í‰ê°€ - M3 Max ì •ë°€ë„"""
        try:
            # ì—¬ëŸ¬ í’ˆì§ˆ ë©”íŠ¸ë¦­ ì¡°í•©
            
            # 1. ì„ ëª…ë„ ê°œì„ 
            sharpness_gain = self._calculate_sharpness_improvement(original, enhanced)
            
            # 2. ë””í…Œì¼ ë³´ì¡´
            detail_preservation = self._calculate_detail_preservation(original, enhanced)
            
            # 3. ìƒ‰ìƒ ìì—°ìŠ¤ëŸ¬ì›€
            color_naturalness = self._calculate_color_naturalness(enhanced)
            
            # 4. ì•„í‹°íŒ©íŠ¸ ìˆ˜ì¤€
            artifact_level = self._estimate_artifact_level(enhanced)
            
            # M3 Max ì •ë°€ë„ ë³´ë„ˆìŠ¤
            precision_bonus = 0.02 if self.is_m3_max else 0.0
            
            # ì¢…í•© ì ìˆ˜
            quality_score = (
                sharpness_gain * 0.3 +
                detail_preservation * 0.25 +
                color_naturalness * 0.25 +
                (1.0 - artifact_level) * 0.2 +
                precision_bonus
            )
            
            return max(0.0, min(1.0, quality_score))
            
        except Exception as e:
            self.logger.warning(f"í’ˆì§ˆ í‰ê°€ ì‹¤íŒ¨: {e}")
            return 0.5
    
    def _calculate_sharpness_improvement(self, original: Union[torch.Tensor, np.ndarray], enhanced: Union[torch.Tensor, np.ndarray]) -> float:
        """ì„ ëª…ë„ ê°œì„  ê³„ì‚°"""
        try:
            if TORCH_AVAILABLE and isinstance(original, torch.Tensor) and isinstance(enhanced, torch.Tensor):
                # ë¼í”Œë¼ì‹œì•ˆ ë¶„ì‚°ìœ¼ë¡œ ì„ ëª…ë„ ì¸¡ì •
                laplacian_kernel = torch.tensor([[[0, -1, 0], [-1, 4, -1], [0, -1, 0]]], 
                                              dtype=torch.float32, device=original.device)
                
                orig_sharpness = self._calculate_laplacian_variance_tensor(original, laplacian_kernel)
                enhanced_sharpness = self._calculate_laplacian_variance_tensor(enhanced, laplacian_kernel)
                
                if orig_sharpness > 0:
                    improvement = (enhanced_sharpness - orig_sharpness) / orig_sharpness
                    return max(0.0, min(1.0, improvement + 0.5))  # 0.5 ê¸°ì¤€ì 
            
            return 0.5
            
        except Exception as e:
            self.logger.warning(f"ì„ ëª…ë„ ê°œì„  ê³„ì‚° ì‹¤íŒ¨: {e}")
            return 0.5
    
    def _calculate_laplacian_variance_tensor(self, image: torch.Tensor, kernel: torch.Tensor) -> float:
        """ë¼í”Œë¼ì‹œì•ˆ ë¶„ì‚° ê³„ì‚° (í…ì„œ ë²„ì „)"""
        try:
            # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜
            if image.shape[1] == 3:
                gray = 0.299 * image[:, 0:1] + 0.587 * image[:, 1:2] + 0.114 * image[:, 2:3]
            else:
                gray = image
            
            # ë¼í”Œë¼ì‹œì•ˆ ì ìš©
            laplacian = F.conv2d(gray, kernel.unsqueeze(0), padding=1)
            
            return float(torch.var(laplacian))
            
        except Exception as e:
            self.logger.warning(f"ë¼í”Œë¼ì‹œì•ˆ ë¶„ì‚° ê³„ì‚° ì‹¤íŒ¨: {e}")
            return 0.0
    
    def _calculate_detail_preservation(self, original: Union[torch.Tensor, np.ndarray], enhanced: Union[torch.Tensor, np.ndarray]) -> float:
        """ë””í…Œì¼ ë³´ì¡´ë„ ê³„ì‚°"""
        try:
            if TORCH_AVAILABLE and isinstance(original, torch.Tensor) and isinstance(enhanced, torch.Tensor):
                # ê³ ì£¼íŒŒ ì„±ë¶„ ë¹„êµ
                orig_details = self._extract_high_frequency_tensor(original)
                enhanced_details = self._extract_high_frequency_tensor(enhanced)
                
                # ìƒê´€ê´€ê³„ ê³„ì‚°
                correlation = F.cosine_similarity(
                    orig_details.flatten(), 
                    enhanced_details.flatten(), 
                    dim=0
                )
                
                return float((correlation + 1.0) / 2.0)  # -1~1ì„ 0~1ë¡œ ë³€í™˜
            
            return 0.5
            
        except Exception as e:
            self.logger.warning(f"ë””í…Œì¼ ë³´ì¡´ë„ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return 0.5
    
    def _extract_high_frequency_tensor(self, image: torch.Tensor) -> torch.Tensor:
        """ê³ ì£¼íŒŒ ì„±ë¶„ ì¶”ì¶œ (í…ì„œ ë²„ì „)"""
        try:
            # ê³ ì£¼íŒŒ í•„í„° (ë¼í”Œë¼ì‹œì•ˆ)
            kernel = torch.tensor([[[0, -1, 0], [-1, 4, -1], [0, -1, 0]]], 
                                dtype=torch.float32, device=image.device)
            
            if image.shape[1] == 3:
                # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜
                gray = 0.299 * image[:, 0:1] + 0.587 * image[:, 1:2] + 0.114 * image[:, 2:3]
            else:
                gray = image
            
            high_freq = F.conv2d(gray, kernel.unsqueeze(0), padding=1)
            
            return high_freq
            
        except Exception as e:
            self.logger.warning(f"ê³ ì£¼íŒŒ ì„±ë¶„ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return torch.zeros_like(image[:, 0:1])
    
    def _calculate_color_naturalness(self, image: Union[torch.Tensor, np.ndarray]) -> float:
        """ìƒ‰ìƒ ìì—°ìŠ¤ëŸ¬ì›€ ê³„ì‚°"""
        try:
            if TORCH_AVAILABLE and isinstance(image, torch.Tensor):
                # RGB ê°’ ë¶„í¬ ë¶„ì„
                r_mean = torch.mean(image[:, 0])
                g_mean = torch.mean(image[:, 1])
                b_mean = torch.mean(image[:, 2])
                
                # ìƒ‰ìƒ ê· í˜• ê²€ì‚¬
                color_balance = 1.0 - torch.std(torch.tensor([r_mean, g_mean, b_mean]))
                
                # ì±„ë„ ê²€ì‚¬
                saturation = torch.std(image, dim=1).mean()
                saturation_score = 1.0 - torch.clamp(saturation - 0.2, 0, 1)
                
                # ì¡°í•©
                naturalness = (color_balance * 0.6 + saturation_score * 0.4)
                
                return float(torch.clamp(naturalness, 0.0, 1.0))
            
            return 0.5
            
        except Exception as e:
            self.logger.warning(f"ìƒ‰ìƒ ìì—°ìŠ¤ëŸ¬ì›€ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return 0.5
    
    def _estimate_artifact_level(self, image: Union[torch.Tensor, np.ndarray]) -> float:
        """ì•„í‹°íŒ©íŠ¸ ìˆ˜ì¤€ ì¶”ì •"""
        try:
            # ê°„ë‹¨í•œ ì•„í‹°íŒ©íŠ¸ ê²€ì¶œ
            return 0.2  # ê¸°ë³¸ê°’
            
        except Exception as e:
            self.logger.warning(f"ì•„í‹°íŒ©íŠ¸ ìˆ˜ì¤€ ì¶”ì • ì‹¤íŒ¨: {e}")
            return 0.3
    
    # ê¸°íƒ€ í—¬í¼ ë©”ì„œë“œë“¤...
    
    def _count_face_regions(self, image: Union[torch.Tensor, np.ndarray]) -> int:
        """ì–¼êµ´ ì˜ì—­ ì¹´ìš´íŠ¸ (ê°„ë‹¨ ë²„ì „)"""
        return 1  # ê¸°ë³¸ê°’
    
    def _estimate_artifacts_removed(self, original: Union[torch.Tensor, np.ndarray], enhanced: Union[torch.Tensor, np.ndarray]) -> float:
        """ì œê±°ëœ ì•„í‹°íŒ©íŠ¸ ì¶”ì •"""
        return 0.3  # ê¸°ë³¸ê°’
    
    def _calculate_color_balance_improvement(self, original: Union[torch.Tensor, np.ndarray], enhanced: Union[torch.Tensor, np.ndarray]) -> float:
        """ìƒ‰ìƒ ê· í˜• ê°œì„  ê³„ì‚°"""
        return 0.2  # ê¸°ë³¸ê°’
    
    def _calculate_saturation_change(self, original: Union[torch.Tensor, np.ndarray], enhanced: Union[torch.Tensor, np.ndarray]) -> float:
        """ì±„ë„ ë³€í™” ê³„ì‚°"""
        return 0.1  # ê¸°ë³¸ê°’
    
    def _calculate_noise_reduction(self, original: Union[torch.Tensor, np.ndarray], enhanced: Union[torch.Tensor, np.ndarray]) -> float:
        """ë…¸ì´ì¦ˆ ê°ì†ŒëŸ‰ ê³„ì‚°"""
        return 0.3  # ê¸°ë³¸ê°’
    
    def _calculate_edge_improvement(self, original: Union[torch.Tensor, np.ndarray], enhanced: Union[torch.Tensor, np.ndarray]) -> float:
        """ì—£ì§€ ê°œì„  ê³„ì‚°"""
        return 0.2  # ê¸°ë³¸ê°’
    
    def _update_processing_stats(self, processing_time: float, quality_score: float):
        """ì²˜ë¦¬ í†µê³„ ì—…ë°ì´íŠ¸"""
        try:
            self.processing_stats['total_images'] += 1
            
            # í‰ê·  ì‹œê°„ ì—…ë°ì´íŠ¸
            total_images = self.processing_stats['total_images']
            old_avg_time = self.processing_stats['average_time']
            self.processing_stats['average_time'] = (
                (old_avg_time * (total_images - 1) + processing_time) / total_images
            )
            
            # ì„±ê³µë¥  ì—…ë°ì´íŠ¸ (í’ˆì§ˆ ì ìˆ˜ 0.6 ì´ìƒì„ ì„±ê³µìœ¼ë¡œ ê°„ì£¼)
            success_count = self.processing_stats.get('success_count', 0)
            if quality_score >= 0.6:
                success_count += 1
            
            self.processing_stats['success_count'] = success_count
            self.processing_stats['enhancement_success_rate'] = success_count / total_images
            
        except Exception as e:
            self.logger.warning(f"í†µê³„ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
    
    # =================================================================
    # ìµœì  ìƒì„±ì í˜¸í™˜ ë©”ì„œë“œë“¤
    # =================================================================
    
    async def get_step_info(self) -> Dict[str, Any]:
        """ğŸ” ìŠ¤í… ì •ë³´ ë°˜í™˜ (ìµœì  ìƒì„±ì í˜¸í™˜)"""
        return {
            "step_name": "PostProcessing",
            "class_name": self.__class__.__name__,
            "version": "4.0-m3max",
            "device": self.device,
            "device_type": self.device_type,
            "memory_gb": self.memory_gb,
            "is_m3_max": self.is_m3_max,
            "optimization_enabled": self.optimization_enabled,
            "quality_level": self.quality_level,
            "initialized": self.is_initialized,
            "initialization_error": self.initialization_error,
            "config_keys": list(self.config.keys()),
            "performance_stats": self.processing_stats.copy(),
            "capabilities": {
                "super_resolution": bool(self.real_esrgan),
                "face_enhancement": bool(self.gfpgan),
                "image_restoration": bool(self.codeformer),
                "color_correction": bool(self.color_enhancer),
                "noise_reduction": bool(self.noise_reducer),
                "edge_enhancement": bool(self.edge_enhancer),
                "neural_enhancement": self.enable_neural_enhancement,
                "m3_max_acceleration": self.is_m3_max and self.device == 'mps'
            },
            "performance_settings": {
                "batch_size": self.batch_size,
                "tile_size": self.tile_size,
                "quality_level": self.enhancement_config.get('quality_level', 'high'),
                "use_mps": self.use_mps
            },
            "enhancement_config": self.enhancement_config
        }
    
    async def cleanup(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬ (ìµœì  ìƒì„±ì í˜¸í™˜)"""
        try:
            self.logger.info("ğŸ§¹ í›„ì²˜ë¦¬ ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì‹œì‘...")
            
            # ëª¨ë¸ ì •ë¦¬
            if self.real_esrgan and hasattr(self.real_esrgan, 'cleanup'):
                await self.real_esrgan.cleanup()
            
            if self.gfpgan and hasattr(self.gfpgan, 'cleanup'):
                await self.gfpgan.cleanup()
            
            if self.codeformer and hasattr(self.codeformer, 'cleanup'):
                await self.codeformer.cleanup()
            
            # GPU ë©”ëª¨ë¦¬ ì •ë¦¬
            if self.use_mps and TORCH_AVAILABLE:
                if hasattr(torch.backends.mps, 'empty_cache'):
                    torch.backends.mps.empty_cache()
                elif hasattr(torch.mps, 'synchronize'):
                    torch.mps.synchronize()
            elif TORCH_AVAILABLE and torch.cuda.is_available():
                torch.cuda.empty_cache()
            
            # ì‹œìŠ¤í…œ ë©”ëª¨ë¦¬ ì •ë¦¬
            import gc
            gc.collect()
            
            self.is_initialized = False
            self.logger.info("âœ… í›„ì²˜ë¦¬ ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì™„ë£Œ")
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")


# =================================================================
# M3 Max ìµœì í™” í´ë°± í´ë˜ìŠ¤ë“¤ - ê¸°ì¡´ ë¡œì§ ì™„ì „ ìœ ì§€
# =================================================================

class M3MaxUpscaler:
    """M3 Max ìµœì í™” ì—…ìŠ¤ì¼€ì¼ëŸ¬"""
    
    def __init__(self, device: str = 'mps', scale_factor: int = 4, use_neural: bool = True):
        self.device = device
        self.scale_factor = scale_factor
        self.use_neural = use_neural
    
    def upscale(self, image: Union[torch.Tensor, np.ndarray]) -> Union[torch.Tensor, np.ndarray]:
        """M3 Max ìµœì í™” ì—…ìŠ¤ì¼€ì¼ë§"""
        try:
            if TORCH_AVAILABLE and isinstance(image, torch.Tensor):
                b, c, h, w = image.shape
                new_h, new_w = h * self.scale_factor, w * self.scale_factor
                
                if self.use_neural and self.device == 'mps':
                    # M3 Max Neural Engine í™œìš© (ê·¼ì‚¬)
                    upscaled = F.interpolate(
                        image, 
                        size=(new_h, new_w), 
                        mode='bicubic', 
                        align_corners=False,
                        antialias=True
                    )
                    
                    # ì¶”ê°€ ì„ ëª…í™”
                    kernel = torch.tensor([[[-0.5, -0.5, -0.5], [-0.5, 5, -0.5], [-0.5, -0.5, -0.5]]], 
                                        dtype=torch.float32, device=self.device) / 4.0
                    sharpened = F.conv2d(upscaled, kernel.repeat(c, 1, 1, 1), padding=1, groups=c)
                    upscaled = torch.clamp(sharpened, 0.0, 1.0)
                    
                else:
                    # ê¸°ë³¸ ë°”ì´íë¹… ì—…ìŠ¤ì¼€ì¼ë§
                    upscaled = F.interpolate(
                        image, 
                        size=(new_h, new_w), 
                        mode='bicubic', 
                        align_corners=False
                    )
                
                return upscaled
            else:
                # NumPy ì²˜ë¦¬
                if CV2_AVAILABLE:
                    h, w = image.shape[:2]
                    new_size = (w * self.scale_factor, h * self.scale_factor)
                    return cv2.resize(image, new_size, interpolation=cv2.INTER_CUBIC)
                else:
                    return image
            
        except Exception as e:
            logger.warning(f"M3 Max ì—…ìŠ¤ì¼€ì¼ë§ ì‹¤íŒ¨: {e}")
            return image
    
    async def cleanup(self):
        pass


class M3MaxFaceEnhancer:
    """M3 Max ìµœì í™” ì–¼êµ´ í–¥ìƒê¸°"""
    
    def __init__(self, device: str = 'mps', enhancement_strength: float = 1.0):
        self.device = device
        self.enhancement_strength = enhancement_strength
    
    def process(self, image: Union[torch.Tensor, np.ndarray]) -> Union[torch.Tensor, np.ndarray]:
        """M3 Max ì–¼êµ´ í–¥ìƒ"""
        try:
            if TORCH_AVAILABLE and isinstance(image, torch.Tensor):
                # ê³ ê¸‰ ì–¸ìƒµ ë§ˆìŠ¤í¬ ì ìš©
                kernel = torch.tensor([[[-1, -2, -1], [-2, 13, -2], [-1, -2, -1]]], 
                                    dtype=torch.float32, device=self.device) / 8.0 * self.enhancement_strength
                
                if image.shape[1] == 3:
                    enhanced = F.conv2d(image, kernel.repeat(3, 1, 1, 1), padding=1, groups=3)
                else:
                    enhanced = F.conv2d(image, kernel, padding=1)
                
                return torch.clamp(enhanced, 0.0, 1.0)
            else:
                # NumPy ì²˜ë¦¬
                if CV2_AVAILABLE:
                    kernel = np.array([[-1, -2, -1], [-2, 13, -2], [-1, -2, -1]]) / 8.0 * self.enhancement_strength
                    enhanced = cv2.filter2D(image, -1, kernel)
                    return np.clip(enhanced, 0, 255).astype(np.uint8)
                else:
                    return image
            
        except Exception as e:
            logger.warning(f"M3 Max ì–¼êµ´ í–¥ìƒ ì‹¤íŒ¨: {e}")
            return image
    
    async def cleanup(self):
        pass


class M3MaxImageRestorer:
    """M3 Max ìµœì í™” ì´ë¯¸ì§€ ë³µì›ê¸°"""
    
    def __init__(self, device: str = 'mps', restoration_strength: float = 1.0):
        self.device = device
        self.restoration_strength = restoration_strength
    
    def process(self, image: Union[torch.Tensor, np.ndarray]) -> Union[torch.Tensor, np.ndarray]:
        """M3 Max ì´ë¯¸ì§€ ë³µì›"""
        try:
            if TORCH_AVAILABLE and isinstance(image, torch.Tensor):
                # ì ì‘ì  ê°€ìš°ì‹œì•ˆ ë…¸ì´ì¦ˆ ì œê±°
                kernel_size = int(3 * self.restoration_strength)
                if kernel_size % 2 == 0:
                    kernel_size += 1
                
                sigma = 0.5 * self.restoration_strength
                
                # ê°€ìš°ì‹œì•ˆ ì»¤ë„ ìƒì„±
                coords = torch.arange(kernel_size, dtype=torch.float32, device=self.device)
                coords -= kernel_size // 2
                g = torch.exp(-(coords ** 2) / (2 * sigma ** 2))
                g /= g.sum()
                
                kernel = g[:, None] * g[None, :]
                kernel = kernel.expand(image.shape[1], 1, kernel_size, kernel_size)
                
                # ì ìš©
                restored = F.conv2d(image, kernel, padding=kernel_size//2, groups=image.shape[1])
                
                # ì›ë³¸ê³¼ ë¸”ë Œë”©
                alpha = 0.7 * self.restoration_strength
                final = alpha * restored + (1 - alpha) * image
                
                return final
            else:
                # NumPy ì²˜ë¦¬
                if CV2_AVAILABLE:
                    # ê°€ìš°ì‹œì•ˆ ë¸”ëŸ¬ ì ìš©
                    restored = cv2.GaussianBlur(image, (5, 5), 1.0)
                    alpha = 0.7 * self.restoration_strength
                    final = alpha * restored + (1 - alpha) * image
                    return np.clip(final, 0, 255).astype(np.uint8)
                else:
                    return image
            
        except Exception as e:
            logger.warning(f"M3 Max ì´ë¯¸ì§€ ë³µì› ì‹¤íŒ¨: {e}")
            return image
    
    async def cleanup(self):
        pass


class ColorEnhancer:
    """M3 Max ìµœì í™” ìƒ‰ìƒ í–¥ìƒê¸°"""
    
    def __init__(self, device: str = 'mps', m3_max_mode: bool = True):
        self.device = device
        self.m3_max_mode = m3_max_mode
    
    def correct_colors(self, image: Union[torch.Tensor, np.ndarray]) -> Union[torch.Tensor, np.ndarray]:
        """M3 Max ìƒ‰ìƒ ë³´ì •"""
        try:
            if TORCH_AVAILABLE and isinstance(image, torch.Tensor):
                if self.m3_max_mode:
                    # M3 Max ì •ë°€ ìƒ‰ìƒ ë³´ì •
                    corrected = self._advanced_color_correction_tensor(image)
                else:
                    # ê¸°ë³¸ ìƒ‰ìƒ ë³´ì •
                    corrected = self._basic_color_correction_tensor(image)
                
                return torch.clamp(corrected, 0.0, 1.0)
            else:
                # NumPy ì²˜ë¦¬
                return self._numpy_color_correction(image)
            
        except Exception as e:
            logger.warning(f"ìƒ‰ìƒ ë³´ì • ì‹¤íŒ¨: {e}")
            return image
    
    def _advanced_color_correction_tensor(self, image: torch.Tensor) -> torch.Tensor:
        """ê³ ê¸‰ ìƒ‰ìƒ ë³´ì • (í…ì„œ)"""
        # ì±„ë„ë³„ í‰ê·  ê³„ì‚°
        r_mean = torch.mean(image[:, 0])
        g_mean = torch.mean(image[:, 1])
        b_mean = torch.mean(image[:, 2])
        
        overall_mean = (r_mean + g_mean + b_mean) / 3.0
        
        # ì ì‘ì  ì¡°ì • ê³„ìˆ˜
        r_factor = torch.clamp(overall_mean / (r_mean + 1e-8), 0.9, 1.1)
        g_factor = torch.clamp(overall_mean / (g_mean + 1e-8), 0.9, 1.1)
        b_factor = torch.clamp(overall_mean / (b_mean + 1e-8), 0.9, 1.1)
        
        # ë¶€ë“œëŸ¬ìš´ ì¡°ì •
        corrected = image.clone()
        corrected[:, 0] *= (1.0 + 0.1 * (r_factor - 1.0))
        corrected[:, 1] *= (1.0 + 0.1 * (g_factor - 1.0))
        corrected[:, 2] *= (1.0 + 0.1 * (b_factor - 1.0))
        
        return corrected
    
    def _basic_color_correction_tensor(self, image: torch.Tensor) -> torch.Tensor:
        """ê¸°ë³¸ ìƒ‰ìƒ ë³´ì • (í…ì„œ)"""
        # ê°„ë‹¨í•œ ìƒ‰ìƒ ê· í˜• ì¡°ì •
        r_mean = torch.mean(image[:, 0])
        g_mean = torch.mean(image[:, 1])
        b_mean = torch.mean(image[:, 2])
        
        overall_mean = (r_mean + g_mean + b_mean) / 3.0
        
        r_factor = overall_mean / (r_mean + 1e-8)
        g_factor = overall_mean / (g_mean + 1e-8)
        b_factor = overall_mean / (b_mean + 1e-8)
        
        # ë¶€ë“œëŸ¬ìš´ ì¡°ì •
        r_factor = 1.0 + 0.05 * (r_factor - 1.0)
        g_factor = 1.0 + 0.05 * (g_factor - 1.0)
        b_factor = 1.0 + 0.05 * (b_factor - 1.0)
        
        corrected = image.clone()
        corrected[:, 0] *= r_factor
        corrected[:, 1] *= g_factor
        corrected[:, 2] *= b_factor
        
        return corrected
    
    def _numpy_color_correction(self, image: np.ndarray) -> np.ndarray:
        """NumPy ìƒ‰ìƒ ë³´ì •"""
        try:
            if len(image.shape) == 3 and image.shape[2] == 3:
                # RGB ì±„ë„ë³„ í‰ê· 
                r_mean = np.mean(image[:, :, 0])
                g_mean = np.mean(image[:, :, 1])
                b_mean = np.mean(image[:, :, 2])
                
                overall_mean = (r_mean + g_mean + b_mean) / 3.0
                
                # ë³´ì • ê³„ìˆ˜
                r_factor = overall_mean / (r_mean + 1e-8)
                g_factor = overall_mean / (g_mean + 1e-8)
                b_factor = overall_mean / (b_mean + 1e-8)
                
                # ë¶€ë“œëŸ¬ìš´ ì¡°ì •
                r_factor = 1.0 + 0.05 * (r_factor - 1.0)
                g_factor = 1.0 + 0.05 * (g_factor - 1.0)
                b_factor = 1.0 + 0.05 * (b_factor - 1.0)
                
                corrected = image.astype(np.float32)
                corrected[:, :, 0] *= r_factor
                corrected[:, :, 1] *= g_factor
                corrected[:, :, 2] *= b_factor
                
                return np.clip(corrected, 0, 255).astype(np.uint8)
            
            return image
            
        except Exception as e:
            logger.warning(f"NumPy ìƒ‰ìƒ ë³´ì • ì‹¤íŒ¨: {e}")
            return image


class NoiseReducer:
    """M3 Max ìµœì í™” ë…¸ì´ì¦ˆ ì œê±°ê¸°"""
    
    def __init__(self, device: str = 'mps', m3_max_mode: bool = True):
        self.device = device
        self.m3_max_mode = m3_max_mode
    
    def reduce_noise(self, image: Union[torch.Tensor, np.ndarray]) -> Union[torch.Tensor, np.ndarray]:
        """M3 Max ë…¸ì´ì¦ˆ ì œê±°"""
        try:
            if TORCH_AVAILABLE and isinstance(image, torch.Tensor):
                if self.m3_max_mode:
                    # M3 Max ê³ ê¸‰ ë…¸ì´ì¦ˆ ì œê±°
                    denoised = self._advanced_noise_reduction_tensor(image)
                else:
                    # ê¸°ë³¸ ë…¸ì´ì¦ˆ ì œê±°
                    denoised = self._basic_noise_reduction_tensor(image)
                
                return denoised
            else:
                # NumPy ì²˜ë¦¬
                return self._numpy_noise_reduction(image)
            
        except Exception as e:
            logger.warning(f"ë…¸ì´ì¦ˆ ì œê±° ì‹¤íŒ¨: {e}")
            return image
    
    def _advanced_noise_reduction_tensor(self, image: torch.Tensor) -> torch.Tensor:
        """ê³ ê¸‰ ë…¸ì´ì¦ˆ ì œê±° (ì–‘ë°©í–¥ í•„í„° ê·¼ì‚¬)"""
        # ë‹¤ì¤‘ ìŠ¤ì¼€ì¼ ê°€ìš°ì‹œì•ˆ ë¸”ëŸ¬
        scales = [0.5, 1.0, 1.5]
        blurred_images = []
        
        for sigma in scales:
            kernel_size = int(4 * sigma) + 1
            if kernel_size % 2 == 0:
                kernel_size += 1
            
            coords = torch.arange(kernel_size, dtype=torch.float32, device=self.device)
            coords -= kernel_size // 2
            g = torch.exp(-(coords ** 2) / (2 * sigma ** 2))
            g /= g.sum()
            
            kernel = g[:, None] * g[None, :]
            kernel = kernel.expand(image.shape[1], 1, kernel_size, kernel_size)
            
            blurred = F.conv2d(image, kernel, padding=kernel_size//2, groups=image.shape[1])
            blurred_images.append(blurred)
        
        # ê°€ì¤‘ í‰ê· 
        weights = [0.5, 0.3, 0.2]
        denoised = sum(w * img for w, img in zip(weights, blurred_images))
        
        # ì›ë³¸ê³¼ ë¸”ë Œë”© (ë””í…Œì¼ ë³´ì¡´)
        blending_factor = 0.7
        result = blending_factor * denoised + (1 - blending_factor) * image
        
        return result
    
    def _basic_noise_reduction_tensor(self, image: torch.Tensor) -> torch.Tensor:
        """ê¸°ë³¸ ë…¸ì´ì¦ˆ ì œê±° (í…ì„œ)"""
        kernel_size = 5
        sigma = 1.0
        
        coords = torch.arange(kernel_size, dtype=torch.float32, device=self.device)
        coords -= kernel_size // 2
        g = torch.exp(-(coords ** 2) / (2 * sigma ** 2))
        g /= g.sum()
        
        kernel = g[:, None] * g[None, :]
        kernel = kernel.expand(image.shape[1], 1, kernel_size, kernel_size)
        
        denoised = F.conv2d(image, kernel, padding=kernel_size//2, groups=image.shape[1])
        
        # ì›ë³¸ê³¼ ë¸”ë Œë”©
        blending_factor = 0.6
        result = blending_factor * denoised + (1 - blending_factor) * image
        
        return result
    
    def _numpy_noise_reduction(self, image: np.ndarray) -> np.ndarray:
        """NumPy ë…¸ì´ì¦ˆ ì œê±°"""
        try:
            if CV2_AVAILABLE:
                # ê°€ìš°ì‹œì•ˆ ë¸”ëŸ¬ë¥¼ ì‚¬ìš©í•œ ë…¸ì´ì¦ˆ ì œê±°
                denoised = cv2.GaussianBlur(image, (5, 5), 1.0)
                
                # ì›ë³¸ê³¼ ë¸”ë Œë”©
                blending_factor = 0.6
                result = blending_factor * denoised + (1 - blending_factor) * image
                
                return np.clip(result, 0, 255).astype(np.uint8)
            else:
                return image
                
        except Exception as e:
            logger.warning(f"NumPy ë…¸ì´ì¦ˆ ì œê±° ì‹¤íŒ¨: {e}")
            return image


class EdgeEnhancer:
    """M3 Max ìµœì í™” ì—£ì§€ í–¥ìƒê¸°"""
    
    def __init__(self, device: str = 'mps', m3_max_mode: bool = True):
        self.device = device
        self.m3_max_mode = m3_max_mode
    
    def enhance_edges(self, image: Union[torch.Tensor, np.ndarray]) -> Union[torch.Tensor, np.ndarray]:
        """M3 Max ì—£ì§€ í–¥ìƒ"""
        try:
            if TORCH_AVAILABLE and isinstance(image, torch.Tensor):
                if self.m3_max_mode:
                    # M3 Max ê³ ê¸‰ ì—£ì§€ í–¥ìƒ
                    enhanced = self._advanced_edge_enhancement_tensor(image)
                else:
                    # ê¸°ë³¸ ì—£ì§€ í–¥ìƒ
                    enhanced = self._basic_edge_enhancement_tensor(image)
                
                return torch.clamp(enhanced, 0.0, 1.0)
            else:
                # NumPy ì²˜ë¦¬
                return self._numpy_edge_enhancement(image)
            
        except Exception as e:
            logger.warning(f"ì—£ì§€ í–¥ìƒ ì‹¤íŒ¨: {e}")
            return image
    
    def _advanced_edge_enhancement_tensor(self, image: torch.Tensor) -> torch.Tensor:
        """ê³ ê¸‰ ì—£ì§€ í–¥ìƒ (ì ì‘ì  ì–¸ìƒµ ë§ˆìŠ¤í¬)"""
        # 1. ì—£ì§€ ê²€ì¶œ
        sobel_x = torch.tensor([[[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]]], 
                             dtype=torch.float32, device=self.device)
        sobel_y = torch.tensor([[[-1, -2, -1], [0, 0, 0], [1, 2, 1]]], 
                             dtype=torch.float32, device=self.device)
        
        # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜
        if image.shape[1] == 3:
            gray = 0.299 * image[:, 0:1] + 0.587 * image[:, 1:2] + 0.114 * image[:, 2:3]
        else:
            gray = image
        
        # ì—£ì§€ í¬ê¸° ê³„ì‚°
        edge_x = F.conv2d(gray, sobel_x.unsqueeze(0), padding=1)
        edge_y = F.conv2d(gray, sobel_y.unsqueeze(0), padding=1)
        edge_magnitude = torch.sqrt(edge_x ** 2 + edge_y ** 2)
        
        # ì ì‘ì  ë§ˆìŠ¤í¬ ìƒì„±
        edge_mask = torch.sigmoid(edge_magnitude * 5.0)  # ì—£ì§€ ì˜ì—­ ê°•ì¡°
        
        # 2. ì–¸ìƒµ ë§ˆìŠ¤í¬
        kernel_size = 5
        sigma = 1.5
        
        coords = torch.arange(kernel_size, dtype=torch.float32, device=self.device)
        coords -= kernel_size // 2
        g = torch.exp(-(coords ** 2) / (2 * sigma ** 2))
        g /= g.sum()
        
        kernel = g[:, None] * g[None, :]
        kernel = kernel.expand(image.shape[1], 1, kernel_size, kernel_size)
        
        blurred = F.conv2d(image, kernel, padding=kernel_size//2, groups=image.shape[1])
        
        # 3. ì ì‘ì  í–¥ìƒ
        strength = 0.3
        unsharp = image + strength * (image - blurred)
        
        # ì—£ì§€ ì˜ì—­ì—ì„œë§Œ ê°•í•˜ê²Œ ì ìš©
        enhanced = image * (1 - edge_mask) + unsharp * edge_mask
        
        return enhanced
    
    def _basic_edge_enhancement_tensor(self, image: torch.Tensor) -> torch.Tensor:
        """ê¸°ë³¸ ì—£ì§€ í–¥ìƒ (í…ì„œ)"""
        # ê¸°ë³¸ ì–¸ìƒµ ë§ˆìŠ¤í¬
        kernel_size = 5
        sigma = 1.0
        
        coords = torch.arange(kernel_size, dtype=torch.float32, device=self.device)
        coords -= kernel_size // 2
        g = torch.exp(-(coords ** 2) / (2 * sigma ** 2))
        g /= g.sum()
        
        kernel = g[:, None] * g[None, :]
        kernel = kernel.expand(image.shape[1], 1, kernel_size, kernel_size)
        
        blurred = F.conv2d(image, kernel, padding=kernel_size//2, groups=image.shape[1])
        
        # ì–¸ìƒµ ë§ˆìŠ¤í¬
        strength = 0.2
        enhanced = image + strength * (image - blurred)
        
        return enhanced
    
    def _numpy_edge_enhancement(self, image: np.ndarray) -> np.ndarray:
        """NumPy ì—£ì§€ í–¥ìƒ"""
        try:
            if CV2_AVAILABLE:
                # ì–¸ìƒµ ë§ˆìŠ¤í¬
                blurred = cv2.GaussianBlur(image, (5, 5), 1.0)
                
                # ê°•ë„ ì¡°ì ˆ
                strength = 0.2
                enhanced = image.astype(np.float32) + strength * (image.astype(np.float32) - blurred.astype(np.float32))
                
                return np.clip(enhanced, 0, 255).astype(np.uint8)
            else:
                return image
                
        except Exception as e:
            logger.warning(f"NumPy ì—£ì§€ í–¥ìƒ ì‹¤íŒ¨: {e}")
            return image