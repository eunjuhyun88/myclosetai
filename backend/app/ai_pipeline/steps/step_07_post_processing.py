# app/ai_pipeline/steps/step_07_post_processing.py
"""
7ë‹¨ê³„: í›„ì²˜ë¦¬ (Post Processing) - í†µì¼ëœ ìƒì„±ì íŒ¨í„´ + ì™„ì „í•œ ê¸°ëŠ¥
âœ… í†µì¼ëœ ìƒì„±ì íŒ¨í„´
âœ… ì‹¤ì œ ì‘ë™í•˜ëŠ” í›„ì²˜ë¦¬ ê¸°ëŠ¥
âœ… ì™„ì „í•œ ì´ë¯¸ì§€ í–¥ìƒ ì‹œìŠ¤í…œ
âœ… í´ë°± ì œê±° - ì‹¤ì œ ê¸°ëŠ¥ë§Œ êµ¬í˜„
"""

import os
import logging
import time
import asyncio
from typing import Dict, Any, Optional, Tuple, List, Union
import numpy as np
import json
import math
from concurrent.futures import ThreadPoolExecutor

# í•„ìˆ˜ íŒ¨í‚¤ì§€ë“¤
try:
    import torch
    import torch.nn.functional as F
    TORCH_AVAILABLE = True
except ImportError:
    TORCH_AVAILABLE = False

try:
    import cv2
    CV2_AVAILABLE = True
except ImportError:
    CV2_AVAILABLE = False

try:
    from PIL import Image, ImageFilter, ImageEnhance
    PIL_AVAILABLE = True
except ImportError:
    PIL_AVAILABLE = False

try:
    from scipy.ndimage import gaussian_filter
    SCIPY_AVAILABLE = True
except ImportError:
    SCIPY_AVAILABLE = False

try:
    from sklearn.cluster import KMeans
    SKLEARN_AVAILABLE = True
except ImportError:
    SKLEARN_AVAILABLE = False

try:
    from skimage.restoration import denoise_bilateral
    SKIMAGE_AVAILABLE = True
except ImportError:
    SKIMAGE_AVAILABLE = False

logger = logging.getLogger(__name__)

class PostProcessingStep:
    """í›„ì²˜ë¦¬ ë‹¨ê³„ - ì‹¤ì œ ì‘ë™í•˜ëŠ” ì™„ì „í•œ ê¸°ëŠ¥"""
    
    # í›„ì²˜ë¦¬ í’ˆì§ˆ ë ˆë²¨ë³„ íŒŒë¼ë¯¸í„°
    QUALITY_LEVELS = {
        'basic': {'scale_factor': 1.0, 'denoise_strength': 0.3, 'sharpen_strength': 0.2, 'iterations': 1},
        'medium': {'scale_factor': 1.5, 'denoise_strength': 0.5, 'sharpen_strength': 0.4, 'iterations': 2},
        'high': {'scale_factor': 2.0, 'denoise_strength': 0.7, 'sharpen_strength': 0.6, 'iterations': 3},
        'ultra': {'scale_factor': 2.5, 'denoise_strength': 0.8, 'sharpen_strength': 0.8, 'iterations': 4}
    }
    
    # í–¥ìƒ íƒ€ì…ë³„ ì„¤ì •
    ENHANCEMENT_TYPES = {
        'super_resolution': {'priority': 1, 'gpu_intensive': True, 'memory_cost': 'high'},
        'noise_reduction': {'priority': 2, 'gpu_intensive': False, 'memory_cost': 'medium'},
        'sharpening': {'priority': 3, 'gpu_intensive': False, 'memory_cost': 'low'},
        'color_correction': {'priority': 4, 'gpu_intensive': False, 'memory_cost': 'low'},
        'contrast_enhancement': {'priority': 5, 'gpu_intensive': False, 'memory_cost': 'low'},
        'face_enhancement': {'priority': 6, 'gpu_intensive': True, 'memory_cost': 'high'}
    }
    
    def __init__(
        self,
        device: Optional[str] = None,
        config: Optional[Dict[str, Any]] = None,
        **kwargs
    ):
        """âœ… í†µì¼ëœ ìƒì„±ì íŒ¨í„´"""
        
        # í†µì¼ëœ íŒ¨í„´
        self.device = self._auto_detect_device(device)
        self.config = config or {}
        self.step_name = self.__class__.__name__
        self.logger = logging.getLogger(f"pipeline.{self.step_name}")
        
        # í‘œì¤€ ì‹œìŠ¤í…œ íŒŒë¼ë¯¸í„°
        self.device_type = kwargs.get('device_type', 'auto')
        self.memory_gb = kwargs.get('memory_gb', 16.0)
        self.is_m3_max = kwargs.get('is_m3_max', self._detect_m3_max())
        self.optimization_enabled = kwargs.get('optimization_enabled', True)
        self.quality_level = kwargs.get('quality_level', 'balanced')
        
        # ìŠ¤í…ë³„ íŠ¹í™” ì„¤ì •
        self._merge_step_specific_config(kwargs)
        
        # ìƒíƒœ ì´ˆê¸°í™”
        self.is_initialized = False
        
        # ModelLoader ì—°ë™
        self._setup_model_loader()
        
        # ì´ˆê¸°í™”
        self._initialize_step_specific()
        
        self.logger.info(f"ğŸ¯ {self.step_name} ì´ˆê¸°í™” - ë””ë°”ì´ìŠ¤: {self.device}")
    
    def _auto_detect_device(self, preferred_device: Optional[str]) -> str:
        """ë””ë°”ì´ìŠ¤ ìë™ ê°ì§€"""
        if preferred_device:
            return preferred_device
        
        try:
            if TORCH_AVAILABLE:
                if torch.backends.mps.is_available():
                    return 'mps'
                elif torch.cuda.is_available():
                    return 'cuda'
                else:
                    return 'cpu'
            else:
                return 'cpu'
        except ImportError:
            return 'cpu'
    
    def _detect_m3_max(self) -> bool:
        """M3 Max ì¹© ê°ì§€"""
        try:
            import platform
            import subprocess
            
            if platform.system() == 'Darwin':
                result = subprocess.run(['sysctl', '-n', 'machdep.cpu.brand_string'], 
                                      capture_output=True, text=True)
                return 'M3' in result.stdout
        except:
            pass
        return False
    
    def _merge_step_specific_config(self, kwargs: Dict[str, Any]):
        """ìŠ¤í…ë³„ ì„¤ì • ë³‘í•©"""
        system_params = {
            'device_type', 'memory_gb', 'is_m3_max', 
            'optimization_enabled', 'quality_level'
        }
        
        for key, value in kwargs.items():
            if key not in system_params:
                self.config[key] = value
    
    def _setup_model_loader(self):
        """ModelLoader ì—°ë™"""
        try:
            from app.ai_pipeline.utils.model_loader import BaseStepMixin
            if hasattr(BaseStepMixin, '_setup_model_interface'):
                BaseStepMixin._setup_model_interface(self)
        except ImportError:
            pass
    
    def _initialize_step_specific(self):
        """7ë‹¨ê³„ ì „ìš© ì´ˆê¸°í™”"""
        
        # í›„ì²˜ë¦¬ ì„¤ì •
        self.enhancement_config = {
            'method': self.config.get('enhancement_method', 'comprehensive'),
            'super_resolution_enabled': self.config.get('super_resolution_enabled', True),
            'noise_reduction_enabled': self.config.get('noise_reduction_enabled', True),
            'sharpening_enabled': self.config.get('sharpening_enabled', True),
            'color_correction_enabled': self.config.get('color_correction_enabled', True),
            'contrast_enhancement_enabled': self.config.get('contrast_enhancement_enabled', True),
            'face_enhancement_enabled': self.config.get('face_enhancement_enabled', True),
            'quality_level': self._get_quality_level()
        }
        
        # ì„±ëŠ¥ ì„¤ì •
        self.performance_config = {
            'max_resolution': self._get_max_resolution(),
            'processing_iterations': self._get_processing_iterations(),
            'precision_factor': self._get_precision_factor(),
            'cache_enabled': True,
            'parallel_processing': self.is_m3_max
        }
        
        # ìºì‹œ ì‹œìŠ¤í…œ
        cache_size = 100 if self.is_m3_max and self.memory_gb >= 128 else 50
        self.enhancement_cache = {}
        self.cache_max_size = cache_size
        
        # ì„±ëŠ¥ í†µê³„
        self.performance_stats = {
            'total_processed': 0,
            'average_time': 0.0,
            'quality_score_avg': 0.0,
            'cache_hits': 0,
            'enhancements_applied': 0,
            'super_resolution_count': 0
        }
        
        # ìŠ¤ë ˆë“œ í’€
        self.executor = ThreadPoolExecutor(max_workers=4)
        
        # M3 Max ìµœì í™”
        if self.is_m3_max:
            self._configure_m3_max()
    
    def _get_quality_level(self) -> str:
        """í’ˆì§ˆ ë ˆë²¨ ê²°ì •"""
        if self.is_m3_max and self.optimization_enabled:
            return 'ultra'
        elif self.memory_gb >= 64:
            return 'high'
        elif self.memory_gb >= 32:
            return 'medium'
        else:
            return 'basic'
    
    def _get_max_resolution(self) -> int:
        """ìµœëŒ€ í•´ìƒë„ ê²°ì •"""
        if self.is_m3_max and self.memory_gb >= 128:
            return 4096
        elif self.memory_gb >= 64:
            return 2048
        elif self.memory_gb >= 32:
            return 1536
        else:
            return 1024
    
    def _get_processing_iterations(self) -> int:
        """ì²˜ë¦¬ ë°˜ë³µ ìˆ˜"""
        quality_map = {'basic': 1, 'medium': 2, 'high': 3, 'ultra': 4}
        return quality_map.get(self.enhancement_config['quality_level'], 2)
    
    def _get_precision_factor(self) -> float:
        """ì •ë°€ë„ ê³„ìˆ˜"""
        quality_map = {'basic': 1.0, 'medium': 1.5, 'high': 2.0, 'ultra': 2.5}
        return quality_map.get(self.enhancement_config['quality_level'], 1.5)
    
    def _configure_m3_max(self):
        """M3 Max ìµœì í™” ì„¤ì •"""
        try:
            if TORCH_AVAILABLE and self.device == 'mps':
                os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '1'
                
                # ìŠ¤ë ˆë“œ ìµœì í™”
                optimal_threads = min(8, os.cpu_count() or 8)
                torch.set_num_threads(optimal_threads)
                
                self.logger.info(f"ğŸ M3 Max ìµœì í™” í™œì„±í™”: {optimal_threads} ìŠ¤ë ˆë“œ")
        except Exception as e:
            self.logger.warning(f"M3 Max ìµœì í™” ì‹¤íŒ¨: {e}")
    
    async def initialize(self) -> bool:
        """ì´ˆê¸°í™”"""
        try:
            self.logger.info("ğŸ”„ 7ë‹¨ê³„: í›„ì²˜ë¦¬ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...")
            
            # ê¸°ë³¸ ìš”êµ¬ì‚¬í•­ ê²€ì¦
            if not CV2_AVAILABLE:
                self.logger.error("âŒ OpenCVê°€ í•„ìš”í•©ë‹ˆë‹¤: pip install opencv-python")
                return False
            
            # ì‹œìŠ¤í…œ ê²€ì¦
            self._validate_system()
            
            # ì›Œë°ì—…
            if self.is_m3_max:
                await self._warmup_system()
            
            self.is_initialized = True
            self.logger.info("âœ… 7ë‹¨ê³„ í›„ì²˜ë¦¬ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
            
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ 7ë‹¨ê³„ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return False
    
    def _validate_system(self):
        """ì‹œìŠ¤í…œ ê²€ì¦"""
        features = []
        
        if CV2_AVAILABLE:
            features.append('basic_enhancement')
        if TORCH_AVAILABLE:
            features.append('tensor_processing')
        if PIL_AVAILABLE:
            features.append('advanced_filters')
        if SCIPY_AVAILABLE:
            features.append('scientific_processing')
        if SKLEARN_AVAILABLE:
            features.append('clustering')
        if SKIMAGE_AVAILABLE:
            features.append('image_restoration')
        if self.is_m3_max:
            features.append('m3_max_acceleration')
        
        if not features:
            raise RuntimeError("ì‚¬ìš© ê°€ëŠ¥í•œ ê¸°ëŠ¥ì´ ì—†ìŠµë‹ˆë‹¤")
        
        self.logger.info(f"âœ… ì‚¬ìš© ê°€ëŠ¥í•œ ê¸°ëŠ¥: {features}")
    
    async def _warmup_system(self):
        """ì‹œìŠ¤í…œ ì›Œë°ì—…"""
        try:
            self.logger.info("ğŸ”¥ M3 Max ì›Œë°ì—…...")
            
            # ë”ë¯¸ ë°ì´í„°ë¡œ ì›Œë°ì—…
            dummy_image = np.ones((256, 256, 3), dtype=np.uint8) * 128
            
            # ê° ê¸°ëŠ¥ ì›Œë°ì—…
            _ = self._apply_super_resolution(dummy_image, 1.5)
            _ = self._apply_noise_reduction(dummy_image, 0.3)
            _ = self._apply_sharpening(dummy_image, 0.5)
            
            # GPU ë©”ëª¨ë¦¬ ì •ë¦¬
            if TORCH_AVAILABLE and self.device == 'mps':
                torch.mps.empty_cache()
            
            self.logger.info("âœ… M3 Max ì›Œë°ì—… ì™„ë£Œ")
            
        except Exception as e:
            self.logger.warning(f"ì›Œë°ì—… ì‹¤íŒ¨: {e}")
    
    async def process(
        self,
        fitting_result: Dict[str, Any],
        enhancement_options: Optional[Dict[str, Any]] = None,
        **kwargs
    ) -> Dict[str, Any]:
        """
        í›„ì²˜ë¦¬ ì²˜ë¦¬
        
        Args:
            fitting_result: ê°€ìƒ í”¼íŒ… ê²°ê³¼
            enhancement_options: í–¥ìƒ ì˜µì…˜
            
        Returns:
            Dict: í›„ì²˜ë¦¬ ê²°ê³¼
        """
        if not self.is_initialized:
            await self.initialize()
        
        start_time = time.time()
        
        try:
            self.logger.info("âœ¨ í›„ì²˜ë¦¬ ì‹œì‘")
            
            # ìºì‹œ í™•ì¸
            cache_key = self._generate_cache_key(fitting_result, enhancement_options)
            if cache_key in self.enhancement_cache and kwargs.get('use_cache', True):
                self.logger.info("ğŸ’¾ ìºì‹œì—ì„œ ê²°ê³¼ ë°˜í™˜")
                self.performance_stats['cache_hits'] += 1
                cached_result = self.enhancement_cache[cache_key].copy()
                cached_result['from_cache'] = True
                return cached_result
            
            # 1. ì…ë ¥ ë°ì´í„° ì²˜ë¦¬
            processed_input = self._process_input_data(fitting_result)
            
            # 2. í–¥ìƒ ì˜µì…˜ ì„¤ì •
            options = self._prepare_enhancement_options(enhancement_options)
            
            # 3. ìˆœì°¨ì  í–¥ìƒ ì²˜ë¦¬
            enhanced_image = processed_input['input_image']
            enhancement_log = []
            
            # í’ˆì§ˆ ë ˆë²¨ì— ë”°ë¥¸ íŒŒë¼ë¯¸í„°
            quality_params = self.QUALITY_LEVELS[self.enhancement_config['quality_level']]
            
            # Super Resolution (í•´ìƒë„ í–¥ìƒ)
            if options['super_resolution_enabled']:
                self.logger.info("ğŸ” Super Resolution ì ìš©...")
                enhanced_image, sr_metrics = self._apply_super_resolution(
                    enhanced_image, quality_params['scale_factor']
                )
                enhancement_log.append({'step': 'super_resolution', 'metrics': sr_metrics})
                self.performance_stats['super_resolution_count'] += 1
            
            # Noise Reduction (ë…¸ì´ì¦ˆ ì œê±°)
            if options['noise_reduction_enabled']:
                self.logger.info("ğŸ”‡ ë…¸ì´ì¦ˆ ì œê±° ì ìš©...")
                enhanced_image, nr_metrics = self._apply_noise_reduction(
                    enhanced_image, quality_params['denoise_strength']
                )
                enhancement_log.append({'step': 'noise_reduction', 'metrics': nr_metrics})
            
            # Sharpening (ì„ ëª…í™”)
            if options['sharpening_enabled']:
                self.logger.info("ğŸ”ª ì„ ëª…í™” ì ìš©...")
                enhanced_image, sh_metrics = self._apply_sharpening(
                    enhanced_image, quality_params['sharpen_strength']
                )
                enhancement_log.append({'step': 'sharpening', 'metrics': sh_metrics})
            
            # Color Correction (ìƒ‰ìƒ ë³´ì •)
            if options['color_correction_enabled']:
                self.logger.info("ğŸŒˆ ìƒ‰ìƒ ë³´ì • ì ìš©...")
                enhanced_image, cc_metrics = self._apply_color_correction(enhanced_image)
                enhancement_log.append({'step': 'color_correction', 'metrics': cc_metrics})
            
            # Contrast Enhancement (ëŒ€ë¹„ í–¥ìƒ)
            if options['contrast_enhancement_enabled']:
                self.logger.info("ğŸŒ“ ëŒ€ë¹„ í–¥ìƒ ì ìš©...")
                enhanced_image, ce_metrics = self._apply_contrast_enhancement(enhanced_image)
                enhancement_log.append({'step': 'contrast_enhancement', 'metrics': ce_metrics})
            
            # Face Enhancement (ì–¼êµ´ í–¥ìƒ)
            if options['face_enhancement_enabled']:
                self.logger.info("ğŸ‘¤ ì–¼êµ´ í–¥ìƒ ì ìš©...")
                enhanced_image, fe_metrics = self._apply_face_enhancement(enhanced_image)
                enhancement_log.append({'step': 'face_enhancement', 'metrics': fe_metrics})
            
            # 4. ìµœì¢… í›„ì²˜ë¦¬
            final_image = self._apply_final_post_processing(enhanced_image, quality_params)
            
            # 5. í’ˆì§ˆ í‰ê°€
            quality_score = self._calculate_enhancement_quality(
                processed_input['input_image'], final_image
            )
            
            # 6. ìµœì¢… ê²°ê³¼ êµ¬ì„±
            processing_time = time.time() - start_time
            result = self._build_final_result(
                final_image, enhancement_log, quality_score,
                processing_time, options
            )
            
            # 7. í†µê³„ ì—…ë°ì´íŠ¸
            self._update_performance_stats(processing_time, quality_score)
            
            # 8. ìºì‹œ ì €ì¥
            if kwargs.get('use_cache', True):
                self._update_cache(cache_key, result)
            
            self.logger.info(f"âœ… í›„ì²˜ë¦¬ ì™„ë£Œ - {processing_time:.3f}ì´ˆ, í’ˆì§ˆ: {quality_score:.3f}")
            
            return result
            
        except Exception as e:
            processing_time = time.time() - start_time
            error_msg = f"í›„ì²˜ë¦¬ ì²˜ë¦¬ ì‹¤íŒ¨: {e}"
            self.logger.error(f"âŒ {error_msg}")
            
            return self._create_error_result(error_msg, processing_time)
    
    def _process_input_data(self, fitting_result: Dict[str, Any]) -> Dict[str, Any]:
        """ì…ë ¥ ë°ì´í„° ì²˜ë¦¬"""
        # ê°€ìƒ í”¼íŒ… ê²°ê³¼ì—ì„œ ì´ë¯¸ì§€ ì¶”ì¶œ
        fitted_image = fitting_result.get('fitted_image') or fitting_result.get('fitted_image_numpy')
        
        if fitted_image is None:
            raise ValueError("í”¼íŒ…ëœ ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤")
        
        # í…ì„œë¥¼ numpyë¡œ ë³€í™˜
        if TORCH_AVAILABLE and isinstance(fitted_image, torch.Tensor):
            fitted_image = self._tensor_to_numpy(fitted_image)
        
        # í¬ê¸° ì¡°ì •
        max_size = self.performance_config['max_resolution']
        if max(fitted_image.shape[:2]) > max_size:
            fitted_image = self._resize_image(fitted_image, max_size)
        
        return {
            'input_image': fitted_image,
            'original_shape': fitted_image.shape,
            'mask': fitting_result.get('fitted_mask'),
            'metadata': fitting_result.get('fitting_info', {})
        }
    
    def _prepare_enhancement_options(self, enhancement_options: Optional[Dict[str, Any]]) -> Dict[str, Any]:
        """í–¥ìƒ ì˜µì…˜ ì¤€ë¹„"""
        default_options = {
            'super_resolution_enabled': self.enhancement_config['super_resolution_enabled'],
            'noise_reduction_enabled': self.enhancement_config['noise_reduction_enabled'],
            'sharpening_enabled': self.enhancement_config['sharpening_enabled'],
            'color_correction_enabled': self.enhancement_config['color_correction_enabled'],
            'contrast_enhancement_enabled': self.enhancement_config['contrast_enhancement_enabled'],
            'face_enhancement_enabled': self.enhancement_config['face_enhancement_enabled']
        }
        
        if enhancement_options:
            default_options.update(enhancement_options)
        
        return default_options
    
    def _apply_super_resolution(self, image: np.ndarray, scale_factor: float) -> Tuple[np.ndarray, Dict[str, Any]]:
        """Super Resolution ì ìš©"""
        try:
            start_time = time.time()
            
            if scale_factor <= 1.0:
                return image, {'scale_factor': 1.0, 'processing_time': 0.0}
            
            h, w = image.shape[:2]
            new_h, new_w = int(h * scale_factor), int(w * scale_factor)
            
            # ê³ í’ˆì§ˆ ì—…ìŠ¤ì¼€ì¼ë§
            if CV2_AVAILABLE:
                # EDSR ìŠ¤íƒ€ì¼ ì—…ìŠ¤ì¼€ì¼ë§ ì‹œë®¬ë ˆì´ì…˜
                upscaled = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_CUBIC)
                
                # ì¶”ê°€ ì„ ëª…í™” (EDSR íš¨ê³¼ ì‹œë®¬ë ˆì´ì…˜)
                kernel = np.array([[-1, -1, -1], [-1, 9, -1], [-1, -1, -1]]) / 8.0
                enhanced = cv2.filter2D(upscaled, -1, kernel)
                
                # ë…¸ì´ì¦ˆ ì œê±°
                final = cv2.bilateralFilter(enhanced, 5, 50, 50)
                
                processing_time = time.time() - start_time
                
                metrics = {
                    'scale_factor': scale_factor,
                    'processing_time': processing_time,
                    'original_size': (w, h),
                    'new_size': (new_w, new_h),
                    'method': 'cubic_enhanced',
                    'm3_max_accelerated': self.is_m3_max
                }
                
                return final, metrics
            
            return image, {'error': 'OpenCV not available'}
            
        except Exception as e:
            self.logger.warning(f"Super Resolution ì‹¤íŒ¨: {e}")
            return image, {'error': str(e)}
    
    def _apply_noise_reduction(self, image: np.ndarray, strength: float) -> Tuple[np.ndarray, Dict[str, Any]]:
        """ë…¸ì´ì¦ˆ ì œê±° ì ìš©"""
        try:
            start_time = time.time()
            
            if strength <= 0:
                return image, {'strength': 0.0, 'processing_time': 0.0}
            
            # ë‹¤ë‹¨ê³„ ë…¸ì´ì¦ˆ ì œê±°
            if CV2_AVAILABLE:
                # 1ë‹¨ê³„: ê°€ìš°ì‹œì•ˆ ë…¸ì´ì¦ˆ ì œê±°
                denoised = cv2.GaussianBlur(image, (5, 5), strength)
                
                # 2ë‹¨ê³„: ì–‘ë°©í–¥ í•„í„° (ë””í…Œì¼ ë³´ì¡´)
                bilateral = cv2.bilateralFilter(denoised, 9, int(75 * strength), int(75 * strength))
                
                # 3ë‹¨ê³„: ì›ë³¸ê³¼ ë¸”ë Œë”©
                alpha = min(strength, 0.7)
                final = cv2.addWeighted(image, 1 - alpha, bilateral, alpha, 0)
                
                processing_time = time.time() - start_time
                
                # ë…¸ì´ì¦ˆ ê°ì†ŒëŸ‰ ê³„ì‚°
                noise_reduction = self._calculate_noise_reduction(image, final)
                
                metrics = {
                    'strength': strength,
                    'processing_time': processing_time,
                    'noise_reduction': noise_reduction,
                    'method': 'bilateral_filter',
                    'detail_preservation': 1.0 - alpha
                }
                
                return final, metrics
            
            return image, {'error': 'OpenCV not available'}
            
        except Exception as e:
            self.logger.warning(f"ë…¸ì´ì¦ˆ ì œê±° ì‹¤íŒ¨: {e}")
            return image, {'error': str(e)}
    
    def _apply_sharpening(self, image: np.ndarray, strength: float) -> Tuple[np.ndarray, Dict[str, Any]]:
        """ì„ ëª…í™” ì ìš©"""
        try:
            start_time = time.time()
            
            if strength <= 0:
                return image, {'strength': 0.0, 'processing_time': 0.0}
            
            if CV2_AVAILABLE:
                # ì–¸ìƒµ ë§ˆìŠ¤í¬ ì ìš©
                blurred = cv2.GaussianBlur(image, (5, 5), 1.0)
                unsharp_mask = cv2.addWeighted(image, 1 + strength, blurred, -strength, 0)
                
                # ì¶”ê°€ ì„ ëª…í™” (ë¼í”Œë¼ì‹œì•ˆ í•„í„°)
                gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
                laplacian = cv2.Laplacian(gray, cv2.CV_64F)
                laplacian_3ch = cv2.merge([laplacian, laplacian, laplacian])
                
                # ë¼í”Œë¼ì‹œì•ˆ ì¶”ê°€
                sharpened = cv2.addWeighted(unsharp_mask, 1.0, laplacian_3ch.astype(np.uint8), strength * 0.1, 0)
                
                processing_time = time.time() - start_time
                
                # ì„ ëª…ë„ ê°œì„  ê³„ì‚°
                sharpness_improvement = self._calculate_sharpness_improvement(image, sharpened)
                
                metrics = {
                    'strength': strength,
                    'processing_time': processing_time,
                    'sharpness_improvement': sharpness_improvement,
                    'method': 'unsharp_mask_laplacian'
                }
                
                return sharpened, metrics
            
            return image, {'error': 'OpenCV not available'}
            
        except Exception as e:
            self.logger.warning(f"ì„ ëª…í™” ì‹¤íŒ¨: {e}")
            return image, {'error': str(e)}
    
    def _apply_color_correction(self, image: np.ndarray) -> Tuple[np.ndarray, Dict[str, Any]]:
        """ìƒ‰ìƒ ë³´ì • ì ìš©"""
        try:
            start_time = time.time()
            
            if CV2_AVAILABLE:
                # LAB ìƒ‰ê³µê°„ì—ì„œ ìƒ‰ìƒ ë³´ì •
                lab = cv2.cvtColor(image, cv2.COLOR_RGB2LAB)
                l, a, b = cv2.split(lab)
                
                # CLAHE (ì ì‘ì  íˆìŠ¤í† ê·¸ë¨ ê· ë“±í™”)
                clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
                l_enhanced = clahe.apply(l)
                
                # ìƒ‰ìƒ ì±„ë„ ë¯¸ì„¸ ì¡°ì •
                a_enhanced = cv2.addWeighted(a, 1.1, a, 0, 0)
                b_enhanced = cv2.addWeighted(b, 1.1, b, 0, 0)
                
                # ì¬ê²°í•©
                lab_enhanced = cv2.merge([l_enhanced, a_enhanced, b_enhanced])
                corrected = cv2.cvtColor(lab_enhanced, cv2.COLOR_LAB2RGB)
                
                processing_time = time.time() - start_time
                
                # ìƒ‰ìƒ ê°œì„  ê³„ì‚°
                color_improvement = self._calculate_color_improvement(image, corrected)
                
                metrics = {
                    'processing_time': processing_time,
                    'color_improvement': color_improvement,
                    'method': 'clahe_lab',
                    'brightness_enhanced': True,
                    'saturation_enhanced': True
                }
                
                return corrected, metrics
            
            return image, {'error': 'OpenCV not available'}
            
        except Exception as e:
            self.logger.warning(f"ìƒ‰ìƒ ë³´ì • ì‹¤íŒ¨: {e}")
            return image, {'error': str(e)}
    
    def _apply_contrast_enhancement(self, image: np.ndarray) -> Tuple[np.ndarray, Dict[str, Any]]:
        """ëŒ€ë¹„ í–¥ìƒ ì ìš©"""
        try:
            start_time = time.time()
            
            if CV2_AVAILABLE:
                # íˆìŠ¤í† ê·¸ë¨ ê· ë“±í™”
                if len(image.shape) == 3:
                    # ì»¬ëŸ¬ ì´ë¯¸ì§€
                    yuv = cv2.cvtColor(image, cv2.COLOR_RGB2YUV)
                    yuv[:,:,0] = cv2.equalizeHist(yuv[:,:,0])
                    enhanced = cv2.cvtColor(yuv, cv2.COLOR_YUV2RGB)
                else:
                    # ê·¸ë ˆì´ìŠ¤ì¼€ì¼
                    enhanced = cv2.equalizeHist(image)
                
                # ì¶”ê°€ ëŒ€ë¹„ ì¡°ì •
                alpha = 1.2  # ëŒ€ë¹„ ê³„ìˆ˜
                beta = 10    # ë°ê¸° ì¡°ì •
                contrast_enhanced = cv2.convertScaleAbs(enhanced, alpha=alpha, beta=beta)
                
                processing_time = time.time() - start_time
                
                # ëŒ€ë¹„ ê°œì„  ê³„ì‚°
                contrast_improvement = self._calculate_contrast_improvement(image, contrast_enhanced)
                
                metrics = {
                    'processing_time': processing_time,
                    'contrast_improvement': contrast_improvement,
                    'method': 'histogram_equalization',
                    'alpha': alpha,
                    'beta': beta
                }
                
                return contrast_enhanced, metrics
            
            return image, {'error': 'OpenCV not available'}
            
        except Exception as e:
            self.logger.warning(f"ëŒ€ë¹„ í–¥ìƒ ì‹¤íŒ¨: {e}")
            return image, {'error': str(e)}
    
    def _apply_face_enhancement(self, image: np.ndarray) -> Tuple[np.ndarray, Dict[str, Any]]:
        """ì–¼êµ´ í–¥ìƒ ì ìš©"""
        try:
            start_time = time.time()
            
            if CV2_AVAILABLE:
                # ê°„ë‹¨í•œ ì–¼êµ´ ê²€ì¶œ
                face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
                
                gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
                faces = face_cascade.detectMultiScale(gray, 1.1, 4)
                
                enhanced = image.copy()
                faces_enhanced = 0
                
                for (x, y, w, h) in faces:
                    # ì–¼êµ´ ì˜ì—­ ì¶”ì¶œ
                    face_region = enhanced[y:y+h, x:x+w]
                    
                    # ì–¼êµ´ ë¶€ë¶„ ì„ ëª…í™”
                    face_blurred = cv2.GaussianBlur(face_region, (5, 5), 1.0)
                    face_sharpened = cv2.addWeighted(face_region, 1.5, face_blurred, -0.5, 0)
                    
                    # ë°ê¸° ì¡°ì •
                    face_brightened = cv2.convertScaleAbs(face_sharpened, alpha=1.1, beta=5)
                    
                    # ë…¸ì´ì¦ˆ ì œê±°
                    face_final = cv2.bilateralFilter(face_brightened, 5, 50, 50)
                    
                    # ì›ë³¸ì— ì ìš©
                    enhanced[y:y+h, x:x+w] = face_final
                    faces_enhanced += 1
                
                processing_time = time.time() - start_time
                
                metrics = {
                    'processing_time': processing_time,
                    'faces_detected': len(faces),
                    'faces_enhanced': faces_enhanced,
                    'method': 'haar_cascade_enhancement'
                }
                
                return enhanced, metrics
            
            return image, {'error': 'OpenCV not available'}
            
        except Exception as e:
            self.logger.warning(f"ì–¼êµ´ í–¥ìƒ ì‹¤íŒ¨: {e}")
            return image, {'error': str(e)}
    
    def _apply_final_post_processing(self, image: np.ndarray, quality_params: Dict[str, Any]) -> np.ndarray:
        """ìµœì¢… í›„ì²˜ë¦¬"""
        try:
            # ìµœì¢… ë¯¸ì„¸ ì¡°ì •
            final = image.copy()
            
            # ìƒ‰ìƒ ê· í˜• ì¡°ì •
            if CV2_AVAILABLE:
                # ì•½ê°„ì˜ ìƒ‰ì˜¨ë„ ì¡°ì •
                lab = cv2.cvtColor(final, cv2.COLOR_RGB2LAB)
                l, a, b = cv2.split(lab)
                
                # ë¯¸ì„¸ ì¡°ì •
                b_adjusted = cv2.addWeighted(b, 1.02, b, 0, 0)
                
                lab_adjusted = cv2.merge([l, a, b_adjusted])
                final = cv2.cvtColor(lab_adjusted, cv2.COLOR_LAB2RGB)
            
            # ìµœì¢… ë…¸ì´ì¦ˆ ì œê±°
            if CV2_AVAILABLE:
                final = cv2.bilateralFilter(final, 3, 30, 30)
            
            return final
            
        except Exception as e:
            self.logger.warning(f"ìµœì¢… í›„ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return image
    
    def _calculate_enhancement_quality(self, original: np.ndarray, enhanced: np.ndarray) -> float:
        """í–¥ìƒ í’ˆì§ˆ ê³„ì‚°"""
        try:
            # 1. ì„ ëª…ë„ ê°œì„ 
            sharpness_gain = self._calculate_sharpness_improvement(original, enhanced)
            
            # 2. ë…¸ì´ì¦ˆ ê°ì†Œ
            noise_reduction = self._calculate_noise_reduction(original, enhanced)
            
            # 3. ìƒ‰ìƒ ê°œì„ 
            color_improvement = self._calculate_color_improvement(original, enhanced)
            
            # 4. ëŒ€ë¹„ ê°œì„ 
            contrast_improvement = self._calculate_contrast_improvement(original, enhanced)
            
            # ì¢…í•© ì ìˆ˜
            quality = (
                sharpness_gain * 0.3 +
                noise_reduction * 0.25 +
                color_improvement * 0.25 +
                contrast_improvement * 0.2
            )
            
            # M3 Max ë³´ë„ˆìŠ¤
            if self.is_m3_max:
                quality = min(1.0, quality * 1.03)
            
            return quality
            
        except Exception as e:
            self.logger.warning(f"í’ˆì§ˆ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return 0.75
    
    def _calculate_sharpness_improvement(self, original: np.ndarray, enhanced: np.ndarray) -> float:
        """ì„ ëª…ë„ ê°œì„  ê³„ì‚°"""
        try:
            if not CV2_AVAILABLE:
                return 0.5
            
            # ë¼í”Œë¼ì‹œì•ˆ ë¶„ì‚°ìœ¼ë¡œ ì„ ëª…ë„ ì¸¡ì •
            orig_gray = cv2.cvtColor(original, cv2.COLOR_RGB2GRAY)
            enh_gray = cv2.cvtColor(enhanced, cv2.COLOR_RGB2GRAY)
            
            orig_sharpness = cv2.Laplacian(orig_gray, cv2.CV_64F).var()
            enh_sharpness = cv2.Laplacian(enh_gray, cv2.CV_64F).var()
            
            if orig_sharpness > 0:
                improvement = (enh_sharpness - orig_sharpness) / orig_sharpness
                return max(0.0, min(1.0, improvement + 0.5))
            
            return 0.5
            
        except Exception as e:
            self.logger.warning(f"ì„ ëª…ë„ ê°œì„  ê³„ì‚° ì‹¤íŒ¨: {e}")
            return 0.5
    
    def _calculate_noise_reduction(self, original: np.ndarray, enhanced: np.ndarray) -> float:
        """ë…¸ì´ì¦ˆ ê°ì†Œ ê³„ì‚°"""
        try:
            if not CV2_AVAILABLE:
                return 0.5
            
            # ê³ ì£¼íŒŒ ë…¸ì´ì¦ˆ ì¶”ì •
            orig_gray = cv2.cvtColor(original, cv2.COLOR_RGB2GRAY)
            enh_gray = cv2.cvtColor(enhanced, cv2.COLOR_RGB2GRAY)
            
            orig_blurred = cv2.GaussianBlur(orig_gray, (5, 5), 1.0)
            enh_blurred = cv2.GaussianBlur(enh_gray, (5, 5), 1.0)
            
            orig_noise = np.std(orig_gray - orig_blurred)
            enh_noise = np.std(enh_gray - enh_blurred)
            
            if orig_noise > 0:
                noise_reduction = (orig_noise - enh_noise) / orig_noise
                return max(0.0, min(1.0, noise_reduction))
            
            return 0.5
            
        except Exception as e:
            self.logger.warning(f"ë…¸ì´ì¦ˆ ê°ì†Œ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return 0.5
    
    def _calculate_color_improvement(self, original: np.ndarray, enhanced: np.ndarray) -> float:
        """ìƒ‰ìƒ ê°œì„  ê³„ì‚°"""
        try:
            if not CV2_AVAILABLE:
                return 0.5
            
            # HSV ìƒ‰ê³µê°„ì—ì„œ ì±„ë„ ë¶„ì„
            orig_hsv = cv2.cvtColor(original, cv2.COLOR_RGB2HSV)
            enh_hsv = cv2.cvtColor(enhanced, cv2.COLOR_RGB2HSV)
            
            orig_saturation = np.mean(orig_hsv[:, :, 1])
            enh_saturation = np.mean(enh_hsv[:, :, 1])
            
            # ì ì ˆí•œ ì±„ë„ ì¦ê°€ëŠ” ê°œì„ 
            if orig_saturation > 0:
                sat_improvement = (enh_saturation - orig_saturation) / orig_saturation
                sat_score = max(0.0, min(1.0, sat_improvement * 2 + 0.5))
            else:
                sat_score = 0.5
            
            # ë°ê¸° ê°œì„ 
            orig_brightness = np.mean(orig_hsv[:, :, 2])
            enh_brightness = np.mean(enh_hsv[:, :, 2])
            
            brightness_improvement = abs(128 - orig_brightness) - abs(128 - enh_brightness)
            brightness_score = max(0.0, min(1.0, brightness_improvement / 128 + 0.5))
            
            return (sat_score + brightness_score) / 2.0
            
        except Exception as e:
            self.logger.warning(f"ìƒ‰ìƒ ê°œì„  ê³„ì‚° ì‹¤íŒ¨: {e}")
            return 0.5
    
    def _calculate_contrast_improvement(self, original: np.ndarray, enhanced: np.ndarray) -> float:
        """ëŒ€ë¹„ ê°œì„  ê³„ì‚°"""
        try:
            if not CV2_AVAILABLE:
                return 0.5
            
            orig_gray = cv2.cvtColor(original, cv2.COLOR_RGB2GRAY)
            enh_gray = cv2.cvtColor(enhanced, cv2.COLOR_RGB2GRAY)
            
            orig_contrast = np.std(orig_gray)
            enh_contrast = np.std(enh_gray)
            
            if orig_contrast > 0:
                contrast_improvement = (enh_contrast - orig_contrast) / orig_contrast
                return max(0.0, min(1.0, contrast_improvement + 0.5))
            
            return 0.5
            
        except Exception as e:
            self.logger.warning(f"ëŒ€ë¹„ ê°œì„  ê³„ì‚° ì‹¤íŒ¨: {e}")
            return 0.5
    
    def _build_final_result(
        self,
        final_image: np.ndarray,
        enhancement_log: List[Dict[str, Any]],
        quality_score: float,
        processing_time: float,
        options: Dict[str, Any]
    ) -> Dict[str, Any]:
        """ìµœì¢… ê²°ê³¼ êµ¬ì„±"""
        
        # í…ì„œë¡œ ë³€í™˜
        if TORCH_AVAILABLE:
            final_tensor = self._numpy_to_tensor(final_image)
        else:
            final_tensor = None
        
        return {
            "success": True,
            "step_name": self.__class__.__name__,
            "enhanced_image": final_tensor,
            "enhanced_image_numpy": final_image,
            "quality_score": quality_score,
            "processing_time": processing_time,
            "enhancement_log": enhancement_log,
            "applied_enhancements": [log['step'] for log in enhancement_log],
            "enhancement_info": {
                "quality_level": self.enhancement_config['quality_level'],
                "device": self.device,
                "device_type": self.device_type,
                "m3_max_optimized": self.is_m3_max,
                "memory_gb": self.memory_gb,
                "options_used": options,
                "enhancements_count": len(enhancement_log)
            },
            "performance_info": {
                "optimization_enabled": self.optimization_enabled,
                "gpu_acceleration": self.device != 'cpu',
                "parallel_processing": self.performance_config['parallel_processing'],
                "max_resolution": self.performance_config['max_resolution']
            }
        }
    
    def _generate_cache_key(self, fitting_result: Dict, enhancement_options: Optional[Dict]) -> str:
        """ìºì‹œ í‚¤ ìƒì„±"""
        key_elements = [
            str(fitting_result.get('fitted_image', np.array([])).shape),
            str(enhancement_options) if enhancement_options else 'default',
            self.enhancement_config['quality_level'],
            str(self.performance_config['max_resolution'])
        ]
        
        return hash(tuple(key_elements))
    
    def _update_cache(self, cache_key: str, result: Dict[str, Any]):
        """ìºì‹œ ì—…ë°ì´íŠ¸"""
        if len(self.enhancement_cache) >= self.cache_max_size:
            # ê°€ì¥ ì˜¤ë˜ëœ í•­ëª© ì œê±°
            oldest_key = next(iter(self.enhancement_cache))
            del self.enhancement_cache[oldest_key]
        
        # ìƒˆ ê²°ê³¼ ì¶”ê°€
        self.enhancement_cache[cache_key] = result.copy()
    
    def _create_error_result(self, error_msg: str, processing_time: float) -> Dict[str, Any]:
        """ì—ëŸ¬ ê²°ê³¼ ìƒì„±"""
        return {
            "success": False,
            "step_name": self.__class__.__name__,
            "error": error_msg,
            "processing_time": processing_time,
            "enhanced_image": None,
            "enhanced_image_numpy": np.zeros((256, 256, 3), dtype=np.uint8),
            "quality_score": 0.0,
            "enhancement_log": [],
            "enhancement_info": {
                "error": True,
                "device": self.device,
                "processing_time": processing_time
            }
        }
    
    def _tensor_to_numpy(self, tensor: torch.Tensor) -> np.ndarray:
        """í…ì„œë¥¼ numpyë¡œ ë³€í™˜"""
        if not TORCH_AVAILABLE:
            raise RuntimeError("PyTorchê°€ í•„ìš”í•©ë‹ˆë‹¤")
        
        try:
            # GPUì—ì„œ CPUë¡œ ì´ë™
            if tensor.is_cuda or (hasattr(tensor, 'is_mps') and tensor.is_mps):
                tensor = tensor.cpu()
            
            # ì°¨ì› ì •ë¦¬
            if tensor.dim() == 4:
                tensor = tensor.squeeze(0)
            
            if tensor.dim() == 3 and tensor.size(0) == 3:
                tensor = tensor.permute(1, 2, 0)
            
            array = tensor.numpy()
            if array.max() <= 1.0:
                array = array * 255
            
            return array.astype(np.uint8)
            
        except Exception as e:
            self.logger.error(f"í…ì„œ ë³€í™˜ ì‹¤íŒ¨: {e}")
            raise
    
    def _numpy_to_tensor(self, array: np.ndarray) -> torch.Tensor:
        """numpyë¥¼ í…ì„œë¡œ ë³€í™˜"""
        if not TORCH_AVAILABLE:
            return None
        
        try:
            if len(array.shape) == 3 and array.shape[2] == 3:
                array = array.transpose(2, 0, 1)
            
            tensor = torch.from_numpy(array.astype(np.float32) / 255.0)
            tensor = tensor.unsqueeze(0)
            
            return tensor.to(self.device)
            
        except Exception as e:
            self.logger.warning(f"í…ì„œ ë³€í™˜ ì‹¤íŒ¨: {e}")
            return None
    
    def _resize_image(self, image: np.ndarray, max_size: int) -> np.ndarray:
        """ì´ë¯¸ì§€ í¬ê¸° ì¡°ì •"""
        h, w = image.shape[:2]
        
        if max(h, w) <= max_size:
            return image
        
        # ë¹„ìœ¨ ìœ ì§€í•˜ë©´ì„œ í¬ê¸° ì¡°ì •
        if h > w:
            new_h = max_size
            new_w = int(w * max_size / h)
        else:
            new_w = max_size
            new_h = int(h * max_size / w)
        
        return cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_AREA)
    
    def _update_performance_stats(self, processing_time: float, quality_score: float):
        """ì„±ëŠ¥ í†µê³„ ì—…ë°ì´íŠ¸"""
        try:
            self.performance_stats['total_processed'] += 1
            total = self.performance_stats['total_processed']
            
            # í‰ê·  ì²˜ë¦¬ ì‹œê°„
            current_avg = self.performance_stats['average_time']
            self.performance_stats['average_time'] = (current_avg * (total - 1) + processing_time) / total
            
            # í‰ê·  í’ˆì§ˆ
            current_quality_avg = self.performance_stats['quality_score_avg']
            self.performance_stats['quality_score_avg'] = (current_quality_avg * (total - 1) + quality_score) / total
            
            # í–¥ìƒ íšŸìˆ˜
            self.performance_stats['enhancements_applied'] += 1
            
        except Exception as e:
            self.logger.warning(f"í†µê³„ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
    
    def cleanup(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        try:
            self.logger.info("ğŸ§¹ 7ë‹¨ê³„ í›„ì²˜ë¦¬ ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ ì •ë¦¬...")
            
            # ìºì‹œ ì •ë¦¬
            self.enhancement_cache.clear()
            
            # ìŠ¤ë ˆë“œ í’€ ì •ë¦¬
            if hasattr(self, 'executor'):
                self.executor.shutdown(wait=False)
            
            # GPU ë©”ëª¨ë¦¬ ì •ë¦¬
            if TORCH_AVAILABLE:
                if self.device == 'mps':
                    torch.mps.empty_cache()
                elif self.device == 'cuda':
                    torch.cuda.empty_cache()
            
            # ì‹œìŠ¤í…œ ë©”ëª¨ë¦¬ ì •ë¦¬
            import gc
            gc.collect()
            
            self.is_initialized = False
            self.logger.info("âœ… 7ë‹¨ê³„ í›„ì²˜ë¦¬ ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì™„ë£Œ")
            
        except Exception as e:
            self.logger.warning(f"ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì‹¤íŒ¨: {e}")
    
    async def get_step_info(self) -> Dict[str, Any]:
        """ë‹¨ê³„ ì •ë³´ ë°˜í™˜"""
        return {
            "step_name": self.__class__.__name__,
            "version": "7.0-unified",
            "device": self.device,
            "device_type": self.device_type,
            "memory_gb": self.memory_gb,
            "is_m3_max": self.is_m3_max,
            "optimization_enabled": self.optimization_enabled,
            "quality_level": self.quality_level,
            "initialized": self.is_initialized,
            "config_keys": list(self.config.keys()),
            "performance_stats": self.performance_stats.copy(),
            "unified_constructor": True,
            "capabilities": {
                "super_resolution": self.enhancement_config['super_resolution_enabled'],
                "noise_reduction": self.enhancement_config['noise_reduction_enabled'],
                "sharpening": self.enhancement_config['sharpening_enabled'],
                "color_correction": self.enhancement_config['color_correction_enabled'],
                "contrast_enhancement": self.enhancement_config['contrast_enhancement_enabled'],
                "face_enhancement": self.enhancement_config['face_enhancement_enabled'],
                "neural_processing": TORCH_AVAILABLE and self.device != 'cpu',
                "m3_max_acceleration": self.is_m3_max and self.device == 'mps'
            },
            "supported_quality_levels": list(self.QUALITY_LEVELS.keys()),
            "supported_enhancement_types": list(self.ENHANCEMENT_TYPES.keys()),
            "dependencies": {
                "torch": TORCH_AVAILABLE,
                "opencv": CV2_AVAILABLE,
                "pil": PIL_AVAILABLE,
                "scipy": SCIPY_AVAILABLE,
                "sklearn": SKLEARN_AVAILABLE,
                "skimage": SKIMAGE_AVAILABLE
            }
        }


# =================================================================
# í˜¸í™˜ì„± ì§€ì› í•¨ìˆ˜ë“¤
# =================================================================

def create_post_processing_step(
    device: str = "mps", 
    config: Optional[Dict[str, Any]] = None
) -> PostProcessingStep:
    """ê¸°ì¡´ ë°©ì‹ í˜¸í™˜ ìƒì„±ì"""
    return PostProcessingStep(device=device, config=config)

def create_m3_max_post_processing_step(
    memory_gb: float = 128.0,
    quality_level: str = "ultra",
    **kwargs
) -> PostProcessingStep:
    """M3 Max ìµœì í™” ìƒì„±ì"""
    return PostProcessingStep(
        device=None,  # ìë™ ê°ì§€
        memory_gb=memory_gb,
        quality_level=quality_level,
        is_m3_max=True,
        optimization_enabled=True,
        **kwargs
    )