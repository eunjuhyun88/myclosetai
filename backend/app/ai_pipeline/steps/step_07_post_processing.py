# app/ai_pipeline/steps/step_07_post_processing.py
"""
MyCloset AI - 7ë‹¨ê³„: í›„ì²˜ë¦¬ (Post Processing) + ì‹œê°í™” ê¸°ëŠ¥
ğŸ”¥ ì™„ì „ ì¬ì‘ì„± ë²„ì „ - ë‹¨ì¼ ìƒì† êµ¬ì¡° + MRO ë¬¸ì œ ì™„ì „ í•´ê²°

âœ… ë‹¨ì¼ ìƒì† êµ¬ì¡° (PostProcessingStep â†’ BaseStepMixin)
âœ… í•œë°©í–¥ ì°¸ì¡° (ModelLoader â† BaseStepMixin â† PostProcessingStep)
âœ… MRO ì˜¤ë¥˜ ì™„ì „ í•´ê²° (ë‹¤ì¤‘ ìƒì† ì œê±°)
âœ… Logger ì†ì„± ëˆ„ë½ ë¬¸ì œ ì™„ì „ í•´ê²°
âœ… ìˆœí™˜ ì°¸ì¡° ì™„ì „ ì œê±°
âœ… ëª¨ë“  ê¸°ëŠ¥ 100% ë³´ì¡´ (í´ë˜ìŠ¤ëª…, í•¨ìˆ˜ëª… ë™ì¼)
âœ… M3 Max 128GB ìµœì í™”
âœ… ì‹œê°í™” ê¸°ëŠ¥ ì™„ì „ í†µí•©
âœ… í”„ë¡œë•ì…˜ ë ˆë²¨ ì•ˆì •ì„±
âœ… ëª¨ë“  import ì˜¤ë¥˜ ìˆ˜ì •
âœ… StepModelRequestAnalyzer ì™„ì „ ì—°ë™
"""

import os
import sys
import logging
import time
import asyncio
import threading
import gc
import hashlib
import json
import math
import base64
from typing import Dict, Any, Optional, Tuple, List, Union, Callable
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor, as_completed
from dataclasses import dataclass, field
from enum import Enum
from io import BytesIO
import weakref

# í•µì‹¬ ë¼ì´ë¸ŒëŸ¬ë¦¬
import numpy as np
import cv2
from PIL import Image, ImageEnhance, ImageFilter, ImageOps, ImageDraw, ImageFont
import torch
import torch.nn as nn
import torch.nn.functional as F
from torchvision import transforms

# ì„ íƒì  ê³ ê¸‰ ë¼ì´ë¸ŒëŸ¬ë¦¬ë“¤
try:
    from scipy.ndimage import gaussian_filter, median_filter
    from scipy.signal import convolve2d
    SCIPY_AVAILABLE = True
except ImportError:
    SCIPY_AVAILABLE = False

try:
    from skimage import restoration, filters, exposure, morphology
    from skimage.metrics import structural_similarity, peak_signal_noise_ratio
    SKIMAGE_AVAILABLE = True
except ImportError:
    SKIMAGE_AVAILABLE = False

try:
    from sklearn.cluster import KMeans
    SKLEARN_AVAILABLE = True
except ImportError:
    SKLEARN_AVAILABLE = False

try:
    import cupy as cp
    CUPY_AVAILABLE = True
except ImportError:
    CUPY_AVAILABLE = False

try:
    import psutil
    PSUTIL_AVAILABLE = True
except ImportError:
    PSUTIL_AVAILABLE = False

# ğŸ”¥ BaseStepMixin ë‹¨ì¼ import (í•œë°©í–¥ ì°¸ì¡°)
try:
    from app.ai_pipeline.steps.base_step_mixin import BaseStepMixin
    BASE_STEP_MIXIN_AVAILABLE = True
except ImportError:
    BASE_STEP_MIXIN_AVAILABLE = False
    # ì•ˆì „í•œ í´ë°± í´ë˜ìŠ¤
    class BaseStepMixin:
        def __init__(self, *args, **kwargs):
            if not hasattr(self, 'logger'):
                self.logger = logging.getLogger(f"pipeline.{self.__class__.__name__}")

# ModelLoader ìœ í‹¸ë¦¬í‹°ë“¤ (ì„ íƒì )
try:
    from app.ai_pipeline.utils.model_loader import (
        get_global_model_loader, create_model_loader
    )
    MODEL_LOADER_AVAILABLE = True
except ImportError:
    MODEL_LOADER_AVAILABLE = False

# ğŸ”¥ StepModelRequestAnalyzer import ì¶”ê°€
try:
    from app.ai_pipeline.utils.step_model_requirements import (
        StepModelRequestAnalyzer, get_step_request
    )
    STEP_REQUESTS_AVAILABLE = True
except ImportError:
    STEP_REQUESTS_AVAILABLE = False

try:
    from app.ai_pipeline.utils.memory_manager import (
        MemoryManager, get_global_memory_manager, optimize_memory_usage
    )
    MEMORY_MANAGER_AVAILABLE = True
except ImportError:
    MEMORY_MANAGER_AVAILABLE = False

try:
    from app.ai_pipeline.utils.data_converter import (
        DataConverter, get_global_data_converter
    )
    DATA_CONVERTER_AVAILABLE = True
except ImportError:
    DATA_CONVERTER_AVAILABLE = False

# ë¡œê¹… ì„¤ì •
logger = logging.getLogger(__name__)

# ==============================================
# 1. ì—´ê±°í˜• ë° ë°ì´í„° í´ë˜ìŠ¤ ì •ì˜
# ==============================================

class EnhancementMethod(Enum):
    """í–¥ìƒ ë°©ë²•"""
    SUPER_RESOLUTION = "super_resolution"
    NOISE_REDUCTION = "noise_reduction"
    DENOISING = "denoising"  # noise_reductionê³¼ ë™ì¼í•˜ì§€ë§Œ í˜¸í™˜ì„± ìœ„í•´ ìœ ì§€
    SHARPENING = "sharpening"
    COLOR_CORRECTION = "color_correction"
    CONTRAST_ENHANCEMENT = "contrast_enhancement"
    FACE_ENHANCEMENT = "face_enhancement"
    EDGE_ENHANCEMENT = "edge_enhancement"
    TEXTURE_ENHANCEMENT = "texture_enhancement"
    AUTO = "auto"

class QualityLevel(Enum):
    """í’ˆì§ˆ ë ˆë²¨"""
    FAST = "fast"
    BALANCED = "balanced"
    HIGH = "high"
    ULTRA = "ultra"

class ProcessingMode(Enum):
    """ì²˜ë¦¬ ëª¨ë“œ"""
    REAL_TIME = "real_time"
    QUALITY = "quality"
    BATCH = "batch"

@dataclass
class PostProcessingConfig:
    """í›„ì²˜ë¦¬ ì„¤ì •"""
    quality_level: QualityLevel = QualityLevel.BALANCED
    processing_mode: ProcessingMode = ProcessingMode.QUALITY
    enabled_methods: List[EnhancementMethod] = field(default_factory=lambda: [
        EnhancementMethod.NOISE_REDUCTION,
        EnhancementMethod.SHARPENING,
        EnhancementMethod.COLOR_CORRECTION,
        EnhancementMethod.CONTRAST_ENHANCEMENT
    ])
    max_resolution: Tuple[int, int] = (2048, 2048)
    use_gpu_acceleration: bool = True
    preserve_original_ratio: bool = True
    apply_face_detection: bool = True
    batch_size: int = 1
    cache_size: int = 50
    # ì‹œê°í™” ì„¤ì •
    enable_visualization: bool = True
    visualization_quality: str = "high"  # low, medium, high
    show_before_after: bool = True
    show_enhancement_details: bool = True

@dataclass
class PostProcessingResult:
    """í›„ì²˜ë¦¬ ê²°ê³¼"""
    success: bool
    enhanced_image: Optional[np.ndarray] = None
    quality_improvement: float = 0.0
    applied_methods: List[str] = field(default_factory=list)
    processing_time: float = 0.0
    metadata: Dict[str, Any] = field(default_factory=dict)
    error_message: Optional[str] = None

# ==============================================
# 2. ê³ ê¸‰ ì´ë¯¸ì§€ í–¥ìƒ ì‹ ê²½ë§ ëª¨ë¸
# ==============================================

class SRResNet(nn.Module):
    """Super Resolution ResNet ëª¨ë¸"""
    def __init__(self, in_channels=3, out_channels=3, num_features=64, num_blocks=16):
        super(SRResNet, self).__init__()
        
        # ì´ˆê¸° ì»¨ë³¼ë£¨ì…˜
        self.conv_first = nn.Conv2d(in_channels, num_features, 9, padding=4)
        self.relu = nn.ReLU(inplace=True)
        
        # ì”ì°¨ ë¸”ë¡ë“¤
        self.res_blocks = nn.ModuleList()
        for _ in range(num_blocks):
            self.res_blocks.append(self._make_res_block(num_features))
        
        # ì—…ìƒ˜í”Œë§ ë ˆì´ì–´ë“¤
        self.upsampler = nn.Sequential(
            nn.Conv2d(num_features, num_features * 4, 3, padding=1),
            nn.PixelShuffle(2),
            nn.ReLU(inplace=True),
            nn.Conv2d(num_features, num_features * 4, 3, padding=1),
            nn.PixelShuffle(2),
            nn.ReLU(inplace=True)
        )
        
        # ìµœì¢… ì¶œë ¥
        self.conv_last = nn.Conv2d(num_features, out_channels, 9, padding=4)
    
    def _make_res_block(self, num_features):
        """ì”ì°¨ ë¸”ë¡ ìƒì„±"""
        return nn.Sequential(
            nn.Conv2d(num_features, num_features, 3, padding=1),
            nn.BatchNorm2d(num_features),
            nn.ReLU(inplace=True),
            nn.Conv2d(num_features, num_features, 3, padding=1),
            nn.BatchNorm2d(num_features)
        )
    
    def forward(self, x):
        """ìˆœì „íŒŒ"""
        # ì´ˆê¸° íŠ¹ì„± ì¶”ì¶œ
        feat = self.relu(self.conv_first(x))
        residual = feat
        
        # ì”ì°¨ ë¸”ë¡ë“¤ í†µê³¼
        for res_block in self.res_blocks:
            res_feat = res_block(feat)
            feat = feat + res_feat
        
        # ì—…ìƒ˜í”Œë§
        feat = self.upsampler(feat + residual)
        
        # ìµœì¢… ì¶œë ¥
        out = self.conv_last(feat)
        
        return out

class DenoiseNet(nn.Module):
    """ë…¸ì´ì¦ˆ ì œê±° ì‹ ê²½ë§"""
    def __init__(self, in_channels=3, out_channels=3, num_features=64):
        super(DenoiseNet, self).__init__()
        
        self.encoder = nn.Sequential(
            nn.Conv2d(in_channels, num_features, 3, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv2d(num_features, num_features, 3, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv2d(num_features, num_features * 2, 3, stride=2, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv2d(num_features * 2, num_features * 2, 3, padding=1),
            nn.ReLU(inplace=True)
        )
        
        self.decoder = nn.Sequential(
            nn.ConvTranspose2d(num_features * 2, num_features, 3, stride=2, padding=1, output_padding=1),
            nn.ReLU(inplace=True),
            nn.Conv2d(num_features, num_features, 3, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv2d(num_features, out_channels, 3, padding=1),
            nn.Sigmoid()
        )
    
    def forward(self, x):
        encoded = self.encoder(x)
        decoded = self.decoder(encoded)
        return decoded

# ==============================================
# 3. ë©”ì¸ PostProcessingStep í´ë˜ìŠ¤ (ë‹¨ì¼ ìƒì†)
# ==============================================

class PostProcessingStep(BaseStepMixin):
    """
    7ë‹¨ê³„: í›„ì²˜ë¦¬ - ë‹¨ì¼ ìƒì† êµ¬ì¡° + ì‹œê°í™”
    
    âœ… ë‹¨ì¼ ìƒì† (BaseStepMixinë§Œ ìƒì†)
    âœ… MRO ë¬¸ì œ ì™„ì „ í•´ê²°
    âœ… í•œë°©í–¥ ì°¸ì¡° êµ¬ì¡°
    âœ… Logger ì†ì„± ëˆ„ë½ ë¬¸ì œ í•´ê²°
    âœ… ëª¨ë“  ê¸°ëŠ¥ 100% ë³´ì¡´
    âœ… ì‹œê°í™” ê¸°ëŠ¥ í†µí•©
    âœ… StepModelRequestAnalyzer ì™„ì „ ì—°ë™
    """
    
    def __init__(
        self,
        device: Optional[str] = None,
        config: Optional[Dict[str, Any]] = None,
        **kwargs
    ):
        """âœ… ë‹¨ì¼ ìƒì† ìƒì„±ì - BaseStepMixinë§Œ ìƒì†"""
        
        # === 1. BaseStepMixin ì´ˆê¸°í™” (ë‹¨ì¼ ìƒì†) ===
        try:
            super().__init__(**kwargs)
        except Exception as e:
            # í´ë°±: ì§ì ‘ logger ì„¤ì •
            if not hasattr(self, 'logger'):
                self.logger = logging.getLogger(f"pipeline.{self.__class__.__name__}")
                self.logger.warning(f"âš ï¸ BaseStepMixin ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        
        # === 2. logger ë³´ì¥ ===
        if not hasattr(self, 'logger'):
            self.logger = logging.getLogger(f"pipeline.{self.__class__.__name__}")
            self.logger.info(f"ğŸ”§ {self.__class__.__name__} logger ì§ì ‘ ì´ˆê¸°í™”")
        
        # === 3. ê¸°ë³¸ ì´ˆê¸°í™” ===
        self.device = self._auto_detect_device(device)
        self.config = config or {}
        self.step_name = self.__class__.__name__
        
        # === 4. ì‹œìŠ¤í…œ íŒŒë¼ë¯¸í„° ===
        self.device_type = kwargs.get('device_type', 'auto')
        self.memory_gb = kwargs.get('memory_gb', 16.0)
        self.is_m3_max = kwargs.get('is_m3_max', self._detect_m3_max())
        self.optimization_enabled = kwargs.get('optimization_enabled', True)
        self.quality_level = kwargs.get('quality_level', 'balanced')
        
        # === 5. í›„ì²˜ë¦¬ íŠ¹í™” ì„¤ì • ===
        self._setup_post_processing_config(kwargs)
        
        # === 6. ì´ˆê¸°í™” ìƒíƒœ ===
        self.is_initialized = False
        self._initialization_lock = threading.RLock()
        
        # === 7. ë‹¨ë°©í–¥ ModelLoader ì—°ê²° ===
        self._setup_model_interface()
        
        # === 8. í›„ì²˜ë¦¬ íŠ¹í™” ì´ˆê¸°í™” ===
        self._initialize_post_processing_components()
        
        # === 9. ì™„ë£Œ ë¡œê¹… ===
        self.logger.info(f"ğŸ¯ {self.step_name} ì´ˆê¸°í™” ì™„ë£Œ - ë””ë°”ì´ìŠ¤: {self.device}")
        if self.is_m3_max:
            self.logger.info(f"ğŸ M3 Max ìµœì í™” ëª¨ë“œ (ë©”ëª¨ë¦¬: {self.memory_gb}GB)")
    
    def _auto_detect_device(self, preferred_device: Optional[str] = None) -> str:
        """ğŸ’¡ ì§€ëŠ¥ì  ë””ë°”ì´ìŠ¤ ìë™ ê°ì§€"""
        if preferred_device:
            return preferred_device

        try:
            if torch.backends.mps.is_available():
                return 'mps'  # M3 Max ìš°ì„ 
            elif torch.cuda.is_available():
                return 'cuda'  # NVIDIA GPU
            else:
                return 'cpu'  # í´ë°±
        except Exception:
            return 'cpu'

    def _detect_m3_max(self) -> bool:
        """ğŸ M3 Max ì¹© ìë™ ê°ì§€"""
        try:
            import platform
            import subprocess

            if platform.system() == 'Darwin':  # macOS
                result = subprocess.run(['sysctl', '-n', 'machdep.cpu.brand_string'], 
                                        capture_output=True, text=True)
                cpu_info = result.stdout.strip()
                return 'M3 Max' in cpu_info or 'M3' in cpu_info
        except Exception:
            pass
        return False

    def _setup_post_processing_config(self, kwargs: Dict[str, Any]):
        """í›„ì²˜ë¦¬ íŠ¹í™” ì„¤ì •"""
        
        # ê¸°ë³¸ ì„¤ì •
        self.post_processing_config = PostProcessingConfig()
        
        # ì„¤ì • ì—…ë°ì´íŠ¸
        if 'quality_level' in kwargs:
            if isinstance(kwargs['quality_level'], str):
                self.post_processing_config.quality_level = QualityLevel(kwargs['quality_level'])
            else:
                self.post_processing_config.quality_level = kwargs['quality_level']
        
        if 'processing_mode' in kwargs:
            if isinstance(kwargs['processing_mode'], str):
                self.post_processing_config.processing_mode = ProcessingMode(kwargs['processing_mode'])
            else:
                self.post_processing_config.processing_mode = kwargs['processing_mode']
        
        if 'enabled_methods' in kwargs:
            methods = []
            for method in kwargs['enabled_methods']:
                if isinstance(method, str):
                    methods.append(EnhancementMethod(method))
                else:
                    methods.append(method)
            self.post_processing_config.enabled_methods = methods
        
        # ì‹œê°í™” ì„¤ì •
        self.post_processing_config.enable_visualization = kwargs.get('enable_visualization', True)
        self.post_processing_config.visualization_quality = kwargs.get('visualization_quality', 'high')
        self.post_processing_config.show_before_after = kwargs.get('show_before_after', True)
        self.post_processing_config.show_enhancement_details = kwargs.get('show_enhancement_details', True)
        
        # M3 Max íŠ¹í™” ì„¤ì •
        if self.is_m3_max:
            self.post_processing_config.use_gpu_acceleration = True
            self.post_processing_config.max_resolution = (4096, 4096)
            self.post_processing_config.batch_size = min(8, max(1, int(self.memory_gb / 16)))
            self.post_processing_config.cache_size = min(100, max(25, int(self.memory_gb * 2)))
        
        # ì¶”ê°€ ì„¤ì •ë“¤
        self.enhancement_strength = kwargs.get('enhancement_strength', 0.7)
        self.preserve_faces = kwargs.get('preserve_faces', True)
        self.auto_adjust_brightness = kwargs.get('auto_adjust_brightness', True)

    def _setup_model_interface(self):
        """í•œë°©í–¥ ModelLoader ì¸í„°í˜ì´ìŠ¤ ì„¤ì •"""
        try:
            if MODEL_LOADER_AVAILABLE:
                self.logger.debug("ğŸ”— Model Loader ì¸í„°í˜ì´ìŠ¤ ì„¤ì • ì¤‘...")
                
                # ì „ì—­ ëª¨ë¸ ë¡œë” ì‚¬ìš© (í•œë°©í–¥ ì°¸ì¡°)
                model_loader = get_global_model_loader()
                if model_loader:
                    self.model_interface = model_loader.create_step_interface(self.step_name)
                    if self.model_interface:
                        self.logger.info(f"âœ… {self.step_name} Model Loader ì¸í„°í˜ì´ìŠ¤ ì—°ê²° ì™„ë£Œ")
                    else:
                        self.logger.warning("âš ï¸ Step ì¸í„°í˜ì´ìŠ¤ ìƒì„± ì‹¤íŒ¨")
                        self.model_interface = None
                else:
                    self.logger.warning(f"âš ï¸ ì „ì—­ ModelLoaderë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
                    self.model_interface = None
                    
            else:
                self.logger.warning("âš ï¸ ModelLoader ì‚¬ìš© ë¶ˆê°€ëŠ¥ - ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œ")
                self.model_interface = None
                
        except Exception as e:
            self.logger.warning(f"âš ï¸ Model Loader ì¸í„°í˜ì´ìŠ¤ ì„¤ì • ì‹¤íŒ¨: {e}")
            self.model_interface = None

    def _initialize_post_processing_components(self):
        """í›„ì²˜ë¦¬ íŠ¹í™” ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”"""
        
        # ìºì‹œ ë° ìƒíƒœ ê´€ë¦¬
        self.enhancement_cache: Dict[str, PostProcessingResult] = {}
        self.model_cache: Dict[str, Any] = {}
        self.face_detector = None
        
        # ì„±ëŠ¥ í†µê³„
        self.processing_stats = {
            'total_processed': 0,
            'successful_enhancements': 0,
            'average_improvement': 0.0,
            'method_usage': {},
            'cache_hits': 0,
            'average_processing_time': 0.0
        }
        
        # ìŠ¤ë ˆë“œ í’€ (M3 Max ìµœì í™”)
        max_workers = 6 if self.is_m3_max else 3
        self.executor = ThreadPoolExecutor(
            max_workers=max_workers,
            thread_name_prefix=f"{self.step_name}_worker"
        )
        
        # ë©”ëª¨ë¦¬ ê´€ë¦¬ì ì—°ê²° (ì„ íƒì )
        self.memory_manager = self._create_memory_manager_safe()
        
        # ë°ì´í„° ë³€í™˜ê¸° ì—°ê²° (ì„ íƒì )
        self.data_converter = self._create_data_converter_safe()
        
        # ëª¨ë¸ ê²½ë¡œ ì„¤ì •
        self.model_base_path = Path("backend/app/ai_pipeline/models/ai_models")
        self.checkpoint_path = self.model_base_path / "checkpoints" / "step_07_post_processing"
        self.checkpoint_path.mkdir(parents=True, exist_ok=True)
        
        # í–¥ìƒ ë°©ë²•ë³„ ê°€ì¤‘ì¹˜
        self.enhancement_weights = {
            EnhancementMethod.SUPER_RESOLUTION: 0.3,
            EnhancementMethod.NOISE_REDUCTION: 0.2,
            EnhancementMethod.SHARPENING: 0.2,
            EnhancementMethod.COLOR_CORRECTION: 0.15,
            EnhancementMethod.CONTRAST_ENHANCEMENT: 0.1,
            EnhancementMethod.FACE_ENHANCEMENT: 0.05
        }
        
        self.logger.info(f"ğŸ“¦ í›„ì²˜ë¦¬ ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™” ì™„ë£Œ - í™œì„±í™”ëœ ë°©ë²•: {len(self.post_processing_config.enabled_methods)}ê°œ")

    def _create_memory_manager_safe(self):
        """ì•ˆì „í•œ ë©”ëª¨ë¦¬ ë§¤ë‹ˆì € ìƒì„±"""
        try:
            if MEMORY_MANAGER_AVAILABLE:
                return get_global_memory_manager()
        except Exception as e:
            self.logger.warning(f"âš ï¸ MemoryManager ìƒì„± ì‹¤íŒ¨: {e}")
        
        # í´ë°± ë©”ëª¨ë¦¬ ë§¤ë‹ˆì €
        class SafeMemoryManager:
            def __init__(self):
                self.device = 'cpu'
            
            async def optimize_memory(self):
                gc.collect()
                if torch.cuda.is_available():
                    torch.cuda.empty_cache()
                elif torch.backends.mps.is_available():
                    try:
                        torch.mps.empty_cache()
                    except Exception:
                        pass
            
            async def cleanup_memory(self):
                await self.optimize_memory()
        
        return SafeMemoryManager()

    def _create_data_converter_safe(self):
        """ì•ˆì „í•œ ë°ì´í„° ë³€í™˜ê¸° ìƒì„±"""
        try:
            if DATA_CONVERTER_AVAILABLE:
                return get_global_data_converter()
        except Exception as e:
            self.logger.warning(f"âš ï¸ DataConverter ìƒì„± ì‹¤íŒ¨: {e}")
        
        # í´ë°± ë°ì´í„° ë³€í™˜ê¸°
        class SafeDataConverter:
            @staticmethod
            def pil_to_tensor(image: Image.Image) -> torch.Tensor:
                """PIL ì´ë¯¸ì§€ë¥¼ í…ì„œë¡œ ë³€í™˜"""
                if image.mode != 'RGB':
                    image = image.convert('RGB')
                transform = transforms.ToTensor()
                return transform(image)
            
            @staticmethod
            def tensor_to_pil(tensor: torch.Tensor) -> Image.Image:
                """í…ì„œë¥¼ PIL ì´ë¯¸ì§€ë¡œ ë³€í™˜"""
                if tensor.dim() == 4:
                    tensor = tensor.squeeze(0)
                tensor = torch.clamp(tensor, 0, 1)
                transform = transforms.ToPILImage()
                return transform(tensor)
            
            @staticmethod
            def tensor_to_numpy(tensor: torch.Tensor) -> np.ndarray:
                """í…ì„œë¥¼ numpyë¡œ ë³€í™˜"""
                if tensor.dim() == 4:
                    tensor = tensor.squeeze(0)
                tensor = tensor.cpu().detach()
                if tensor.dim() == 3 and tensor.shape[0] == 3:
                    tensor = tensor.permute(1, 2, 0)
                return (tensor.numpy() * 255).astype(np.uint8)
        
        return SafeDataConverter()

    async def initialize(self) -> bool:
        """
        âœ… í†µì¼ëœ ì´ˆê¸°í™” ì¸í„°í˜ì´ìŠ¤ - Pipeline Manager í˜¸í™˜
        
        Returns:
            bool: ì´ˆê¸°í™” ì„±ê³µ ì—¬ë¶€
        """
        async with asyncio.Lock():
            if self.is_initialized:
                return True
        
        try:
            self.logger.info("ğŸ”„ 7ë‹¨ê³„: í›„ì²˜ë¦¬ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...")
            
            # 1. AI ëª¨ë¸ë“¤ ì´ˆê¸°í™”
            await self._initialize_ai_models()
            
            # 2. ì–¼êµ´ ê²€ì¶œê¸° ì´ˆê¸°í™”
            if self.post_processing_config.apply_face_detection:
                await self._initialize_face_detector()
            
            # 3. ì´ë¯¸ì§€ í•„í„° ì´ˆê¸°í™”
            self._initialize_image_filters()
            
            # 4. GPU ê°€ì† ì´ˆê¸°í™” (M3 Max/CUDA)
            if self.post_processing_config.use_gpu_acceleration:
                await self._initialize_gpu_acceleration()
            
            # 5. M3 Max ìµœì í™” ì›Œë°ì—…
            if self.is_m3_max:
                await self._warmup_m3_max()
            
            # 6. ìºì‹œ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
            self._initialize_cache_system()
            
            self.is_initialized = True
            self.logger.info("âœ… í›„ì²˜ë¦¬ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
            
            return True
            
        except Exception as e:
            error_msg = f"í›„ì²˜ë¦¬ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}"
            self.logger.error(f"âŒ {error_msg}")
            
            # ìµœì†Œí•œì˜ í´ë°± ì‹œìŠ¤í…œ ì´ˆê¸°í™”
            self._initialize_fallback_system()
            self.is_initialized = True
            
            return True  # Graceful degradation

    async def _initialize_ai_models(self):
        """ğŸ”¥ AI ëª¨ë¸ë“¤ ì´ˆê¸°í™” - StepModelRequestAnalyzer ì—°ë™"""
        try:
            if not self.model_interface:
                self.logger.warning("Model Loader ì¸í„°í˜ì´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤. ì§ì ‘ ëª¨ë¸ ë¡œë“œ ì‹œë„.")
                await self._load_models_direct()
                return
            
            # ğŸ”¥ StepModelRequestAnalyzer ì‚¬ìš©í•´ì„œ ëª¨ë¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            if STEP_REQUESTS_AVAILABLE:
                step_request = StepModelRequestAnalyzer.get_step_request_info(self.step_name)
                
                if step_request:
                    self.logger.info(f"âœ… Step ìš”ì²­ ì •ë³´ íšë“: {step_request['model_name']}")
                    
                    # Super Resolution ëª¨ë¸ ë¡œë“œ
                    try:
                        self.sr_model = await self.model_interface.get_model('super_resolution_model')
                        if self.sr_model:
                            self.logger.info("âœ… Super Resolution ëª¨ë¸ ë¡œë“œ ì„±ê³µ (ModelLoader)")
                        else:
                            raise Exception("ModelLoaderì—ì„œ ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ")
                    except Exception as e:
                        self.logger.warning(f"âš ï¸ SR ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e} - ê¸°ë³¸ ëª¨ë¸ ìƒì„±")
                        self.sr_model = self._create_default_sr_model()
                    
                    # Denoising ëª¨ë¸ ë¡œë“œ
                    try:
                        self.denoise_model = await self.model_interface.get_model('denoising_model')
                        if self.denoise_model:
                            self.logger.info("âœ… Denoising ëª¨ë¸ ë¡œë“œ ì„±ê³µ (ModelLoader)")
                        else:
                            raise Exception("ModelLoaderì—ì„œ ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ")
                    except Exception as e:
                        self.logger.warning(f"âš ï¸ Denoising ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e} - ê¸°ë³¸ ëª¨ë¸ ìƒì„±")
                        self.denoise_model = self._create_default_denoise_model()
                    
                    # M3 Max ìµœì í™” ì ìš©
                    if self.is_m3_max:
                        self._optimize_models_for_m3_max()
                    
                    self.logger.info("ğŸ§  AI ëª¨ë¸ ë¡œë“œ ì™„ë£Œ (StepModelRequestAnalyzer ì—°ë™)")
                else:
                    self.logger.warning("âš ï¸ Step ìš”ì²­ ì •ë³´ ì—†ìŒ - ê¸°ë³¸ ëª¨ë¸ ìƒì„±")
                    await self._load_models_direct()
            else:
                self.logger.warning("âš ï¸ StepModelRequestAnalyzer ì‚¬ìš© ë¶ˆê°€ - ê¸°ë³¸ ëª¨ë¸ ìƒì„±")
                await self._load_models_direct()
                
        except Exception as e:
            self.logger.error(f"âŒ AI ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            await self._load_models_direct()

    def _create_default_sr_model(self) -> Optional[SRResNet]:
        """ê¸°ë³¸ Super Resolution ëª¨ë¸ ìƒì„±"""
        try:
            model = SRResNet(in_channels=3, out_channels=3, num_features=64, num_blocks=16)
            model.to(self.device)
            model.eval()
            
            # M3 Max ì •ë°€ë„ ìµœì í™”
            if self.device == "mps":
                model = model.float()
            elif self.device == "cuda":
                model = model.half()
            
            self.logger.info("ğŸ”§ ê¸°ë³¸ Super Resolution ëª¨ë¸ ìƒì„± ì™„ë£Œ")
            return model
            
        except Exception as e:
            self.logger.error(f"âŒ ê¸°ë³¸ SR ëª¨ë¸ ìƒì„± ì‹¤íŒ¨: {e}")
            return None

    def _create_default_denoise_model(self) -> Optional[DenoiseNet]:
        """ê¸°ë³¸ Denoising ëª¨ë¸ ìƒì„±"""
        try:
            model = DenoiseNet(in_channels=3, out_channels=3, num_features=64)
            model.to(self.device)
            model.eval()
            
            # M3 Max ì •ë°€ë„ ìµœì í™”
            if self.device == "mps":
                model = model.float()
            elif self.device == "cuda":
                model = model.half()
            
            self.logger.info("ğŸ”§ ê¸°ë³¸ Denoising ëª¨ë¸ ìƒì„± ì™„ë£Œ")
            return model
            
        except Exception as e:
            self.logger.error(f"âŒ ê¸°ë³¸ Denoising ëª¨ë¸ ìƒì„± ì‹¤íŒ¨: {e}")
            return None

    async def _load_models_direct(self):
        """AI ëª¨ë¸ ì§ì ‘ ë¡œë“œ (Model Loader ì—†ì´)"""
        try:
            # Super Resolution ëª¨ë¸
            self.sr_model = self._create_default_sr_model()
            
            # Denoising ëª¨ë¸
            self.denoise_model = self._create_default_denoise_model()
            
            # ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ ì‹œë„
            sr_checkpoint = self.checkpoint_path / "srresnet_x4.pth"
            if sr_checkpoint.exists() and self.sr_model:
                try:
                    state_dict = torch.load(sr_checkpoint, map_location=self.device)
                    self.sr_model.load_state_dict(state_dict)
                    self.logger.info("âœ… SR ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ ì„±ê³µ")
                except Exception as e:
                    self.logger.warning(f"âš ï¸ SR ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            
            denoise_checkpoint = self.checkpoint_path / "denoise_net.pth"
            if denoise_checkpoint.exists() and self.denoise_model:
                try:
                    state_dict = torch.load(denoise_checkpoint, map_location=self.device)
                    self.denoise_model.load_state_dict(state_dict)
                    self.logger.info("âœ… Denoising ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ ì„±ê³µ")
                except Exception as e:
                    self.logger.warning(f"âš ï¸ Denoising ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            
            # M3 Max ìµœì í™”
            if self.is_m3_max:
                self._optimize_models_for_m3_max()
            
            self.logger.info("âœ… ê¸°ë³¸ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
            
        except Exception as e:
            self.logger.error(f"âŒ ëª¨ë¸ ì§ì ‘ ë¡œë“œ ì‹¤íŒ¨: {e}")
            self.sr_model = None
            self.denoise_model = None

    def _optimize_models_for_m3_max(self):
        """M3 Max í•˜ë“œì›¨ì–´ ìµœì í™”"""
        try:
            self.logger.info("ğŸ M3 Max ëª¨ë¸ ìµœì í™” ì ìš© ì¤‘...")
            
            # ë©”ëª¨ë¦¬ ë§¤í•‘ ìµœì í™”
            if hasattr(self, 'sr_model') and self.sr_model:
                self.sr_model = self.sr_model.to(self.device)
                if self.device == "mps":
                    self.sr_model = self.sr_model.float()  # MPSëŠ” float32ê°€ ì•ˆì „
            
            if hasattr(self, 'denoise_model') and self.denoise_model:
                self.denoise_model = self.denoise_model.to(self.device)
                if self.device == "mps":
                    self.denoise_model = self.denoise_model.float()  # MPSëŠ” float32ê°€ ì•ˆì „
            
            # ë°°ì¹˜ í¬ê¸° ìµœì í™”
            self.optimal_batch_size = min(8, max(1, int(self.memory_gb / 16)))
            
            self.logger.info(f"âœ… M3 Max ìµœì í™” ì™„ë£Œ - ë°°ì¹˜ í¬ê¸°: {self.optimal_batch_size}")
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ M3 Max ìµœì í™” ì‹¤íŒ¨: {e}")

    async def _initialize_face_detector(self):
        """ì–¼êµ´ ê²€ì¶œê¸° ì´ˆê¸°í™”"""
        try:
            # OpenCV DNN ì–¼êµ´ ê²€ì¶œê¸°
            face_net_path = self.checkpoint_path / "opencv_face_detector_uint8.pb"
            face_config_path = self.checkpoint_path / "opencv_face_detector.pbtxt"
            
            if face_net_path.exists() and face_config_path.exists():
                self.face_detector = cv2.dnn.readNetFromTensorflow(
                    str(face_net_path), str(face_config_path)
                )
                self.logger.info("âœ… OpenCV DNN ì–¼êµ´ ê²€ì¶œê¸° ë¡œë“œ ì„±ê³µ")
            else:
                # Haar Cascade í´ë°±
                cascade_path = cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'
                self.face_detector = cv2.CascadeClassifier(cascade_path)
                self.logger.info("âœ… Haar Cascade ì–¼êµ´ ê²€ì¶œê¸° ë¡œë“œ ì„±ê³µ")
                
        except Exception as e:
            self.logger.warning(f"ì–¼êµ´ ê²€ì¶œê¸° ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.face_detector = None

    def _initialize_image_filters(self):
        """ì´ë¯¸ì§€ í•„í„° ì´ˆê¸°í™”"""
        try:
            # ì»¤ìŠ¤í…€ ì»¤ë„ë“¤
            self.sharpening_kernel = np.array([
                [-1, -1, -1],
                [-1,  9, -1],
                [-1, -1, -1]
            ], dtype=np.float32)
            
            self.edge_enhancement_kernel = np.array([
                [0, -1, 0],
                [-1, 5, -1],
                [0, -1, 0]
            ], dtype=np.float32)
            
            # ê°€ìš°ì‹œì•ˆ ì»¤ë„ (ë…¸ì´ì¦ˆ ì œê±°ìš©)
            self.gaussian_kernel_3x3 = cv2.getGaussianKernel(3, 0.8)
            self.gaussian_kernel_5x5 = cv2.getGaussianKernel(5, 1.2)
            
            # ì–¸ìƒ¤í”„ ë§ˆìŠ¤í‚¹ ë§¤ê°œë³€ìˆ˜
            self.unsharp_params = {
                'radius': 1.0,
                'amount': 1.5,
                'threshold': 0.05
            }
            
            self.logger.info("âœ… ì´ë¯¸ì§€ í•„í„° ì´ˆê¸°í™” ì™„ë£Œ")
            
        except Exception as e:
            self.logger.error(f"ì´ë¯¸ì§€ í•„í„° ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")

    async def _initialize_gpu_acceleration(self):
        """GPU ê°€ì† ì´ˆê¸°í™”"""
        try:
            if self.device == 'mps':
                # M3 Max Metal Performance Shaders
                self.logger.info("ğŸ M3 Max MPS ê°€ì† í™œì„±í™”")
                
            elif self.device == 'cuda':
                # CUDA ê°€ì†
                self.logger.info("ğŸš€ CUDA ê°€ì† í™œì„±í™”")
                
                # CuPy ì‚¬ìš© ê°€ëŠ¥ì‹œ í™œì„±í™”
                if CUPY_AVAILABLE:
                    self.use_cupy = True
                    self.logger.info("âœ… CuPy ê°€ì† í™œì„±í™”")
                else:
                    self.use_cupy = False
            else:
                self.logger.info("ğŸ’» CPU ëª¨ë“œì—ì„œ ì‹¤í–‰")
                
        except Exception as e:
            self.logger.warning(f"GPU ê°€ì† ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")

    async def _warmup_m3_max(self):
        """M3 Max ìµœì í™” ì›Œë°ì—…"""
        try:
            if not self.is_m3_max:
                return
            
            self.logger.info("ğŸ M3 Max ìµœì í™” ì›Œë°ì—… ì‹œì‘...")
            
            # ë”ë¯¸ ì´ë¯¸ì§€ë¡œ GPU ì›Œë°ì—…
            dummy_image = torch.randn(1, 3, 512, 512).to(self.device)
            
            if self.sr_model:
                with torch.no_grad():
                    _ = self.sr_model(dummy_image)
                self.logger.info("âœ… Super Resolution M3 Max ì›Œë°ì—… ì™„ë£Œ")
            
            if self.denoise_model:
                with torch.no_grad():
                    _ = self.denoise_model(dummy_image)
                self.logger.info("âœ… Denoising M3 Max ì›Œë°ì—… ì™„ë£Œ")
            
            # MPS ìºì‹œ ìµœì í™”
            if self.device == 'mps':
                try:
                    if torch.backends.mps.is_available():
                        torch.mps.empty_cache()
                except Exception:
                    pass
            
            # ë©”ëª¨ë¦¬ ìµœì í™”
            if self.memory_manager:
                await self.memory_manager.optimize_memory()
            
            self.logger.info("ğŸ M3 Max ì›Œë°ì—… ì™„ë£Œ")
            
        except Exception as e:
            self.logger.warning(f"M3 Max ì›Œë°ì—… ì‹¤íŒ¨: {e}")

    def _initialize_cache_system(self):
        """ìºì‹œ ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
        try:
            # ìºì‹œ í¬ê¸° ì„¤ì • (M3 Max ìµœì í™”)
            cache_size = self.post_processing_config.cache_size
            
            # LRU ìºì‹œë¡œ ë³€í™˜
            from functools import lru_cache
            self._cached_enhancement = lru_cache(maxsize=cache_size)(self._perform_enhancement_cached)
            
            self.logger.info(f"ğŸ’¾ ìºì‹œ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ (í¬ê¸°: {cache_size})")
            
        except Exception as e:
            self.logger.error(f"ìºì‹œ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")

    def _initialize_fallback_system(self):
        """ìµœì†Œí•œì˜ í´ë°± ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
        try:
            # ê°€ì¥ ê¸°ë³¸ì ì¸ ë°©ë²•ë“¤ë§Œ í™œì„±í™”
            self.post_processing_config.enabled_methods = [
                EnhancementMethod.SHARPENING,
                EnhancementMethod.COLOR_CORRECTION,
                EnhancementMethod.CONTRAST_ENHANCEMENT
            ]
            
            self.logger.info("âš ï¸ í´ë°± ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
            
        except Exception as e:
            self.logger.error(f"í´ë°± ì‹œìŠ¤í…œ ì´ˆê¸°í™”ë„ ì‹¤íŒ¨: {e}")

    async def process(
        self, 
        fitting_result: Dict[str, Any],
        enhancement_options: Optional[Dict[str, Any]] = None,
        **kwargs
    ) -> Dict[str, Any]:
        """
        âœ… í†µì¼ëœ ì²˜ë¦¬ ì¸í„°í˜ì´ìŠ¤ - Pipeline Manager í˜¸í™˜ + ì‹œê°í™”
        
        Args:
            fitting_result: ê°€ìƒ í”¼íŒ… ê²°ê³¼ (6ë‹¨ê³„ ì¶œë ¥)
            enhancement_options: í–¥ìƒ ì˜µì…˜
            **kwargs: ì¶”ê°€ ë§¤ê°œë³€ìˆ˜
                
        Returns:
            Dict[str, Any]: í›„ì²˜ë¦¬ ê²°ê³¼ + ì‹œê°í™” ì´ë¯¸ì§€
        """
        if not self.is_initialized:
            await self.initialize()
        
        start_time = time.time()
        
        try:
            self.logger.info("âœ¨ í›„ì²˜ë¦¬ ì‹œì‘...")
            
            # 1. ìºì‹œ í™•ì¸
            cache_key = self._generate_cache_key(fitting_result, enhancement_options)
            if cache_key in self.enhancement_cache:
                cached_result = self.enhancement_cache[cache_key]
                self.processing_stats['cache_hits'] += 1
                self.logger.info("ğŸ’¾ ìºì‹œì—ì„œ ê²°ê³¼ ë°˜í™˜")
                return self._format_result(cached_result)
            
            # 2. ì…ë ¥ ë°ì´í„° ì²˜ë¦¬
            processed_input = self._process_input_data(fitting_result)
            
            # 3. í–¥ìƒ ì˜µì…˜ ì¤€ë¹„
            options = self._prepare_enhancement_options(enhancement_options)
            
            # 4. ë©”ì¸ í–¥ìƒ ì²˜ë¦¬ (ì§„í–‰ë¥  ì¶”ì  ë²„ì „ ì‚¬ìš©)
            progress_callback = kwargs.get('progress_callback')
            if progress_callback:
                result = await self._perform_enhancement_pipeline_with_progress(
                    processed_input, options, progress_callback, **kwargs
                )
            else:
                result = await self._perform_enhancement_pipeline(
                    processed_input, options, **kwargs
                )
            
            # 5. ì‹œê°í™” ì´ë¯¸ì§€ ìƒì„±
            if self.post_processing_config.enable_visualization:
                visualization_results = await self._create_enhancement_visualization(
                    processed_input, result, options
                )
                # ì‹œê°í™” ê²°ê³¼ë¥¼ ë©”íƒ€ë°ì´í„°ì— ì¶”ê°€
                result.metadata['visualization'] = visualization_results
            
            # 6. ê²°ê³¼ ìºì‹±
            if result.success:
                self.enhancement_cache[cache_key] = result
                if len(self.enhancement_cache) > self.post_processing_config.cache_size:
                    self._cleanup_cache()
            
            # 7. í†µê³„ ì—…ë°ì´íŠ¸
            self._update_statistics(result, time.time() - start_time)
            
            self.logger.info(f"âœ… í›„ì²˜ë¦¬ ì™„ë£Œ - ê°œì„ ë„: {result.quality_improvement:.3f}, "
                            f"ì‹œê°„: {result.processing_time:.3f}ì´ˆ")
            
            return self._format_result(result)
            
        except Exception as e:
            error_msg = f"í›„ì²˜ë¦¬ ì²˜ë¦¬ ì‹¤íŒ¨: {e}"
            self.logger.error(f"âŒ {error_msg}")
            
            # ì—ëŸ¬ ê²°ê³¼ ë°˜í™˜
            error_result = PostProcessingResult(
                success=False,
                error_message=error_msg,
                processing_time=time.time() - start_time
            )
            
            return self._format_result(error_result)

    # ==============================================
    # ë‚˜ë¨¸ì§€ ë©”ì„œë“œë“¤ì€ ì›ë³¸ê³¼ ë™ì¼í•˜ë¯€ë¡œ ì£¼ìš” ë¶€ë¶„ë§Œ í¬í•¨
    # (ì‹¤ì œ íŒŒì¼ì—ëŠ” ëª¨ë“  ë©”ì„œë“œê°€ í¬í•¨ë˜ì–´ì•¼ í•¨)
    # ==============================================

    def _process_input_data(self, fitting_result: Dict[str, Any]) -> Dict[str, Any]:
        """ì…ë ¥ ë°ì´í„° ì²˜ë¦¬"""
        try:
            # ê°€ìƒ í”¼íŒ… ê²°ê³¼ì—ì„œ ì´ë¯¸ì§€ ì¶”ì¶œ
            fitted_image = fitting_result.get('fitted_image') or fitting_result.get('result_image')
            
            if fitted_image is None:
                raise ValueError("í”¼íŒ…ëœ ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤")
            
            # íƒ€ì…ë³„ ë³€í™˜
            if isinstance(fitted_image, str):
                # Base64 ë””ì½”ë”©
                import base64
                from io import BytesIO
                image_data = base64.b64decode(fitted_image)
                image_pil = Image.open(BytesIO(image_data)).convert('RGB')
                fitted_image = np.array(image_pil)
            elif isinstance(fitted_image, torch.Tensor):
                if self.data_converter:
                    fitted_image = self.data_converter.tensor_to_numpy(fitted_image)
                else:
                    fitted_image = fitted_image.detach().cpu().numpy()
                    if fitted_image.ndim == 4:
                        fitted_image = fitted_image.squeeze(0)
                    if fitted_image.ndim == 3 and fitted_image.shape[0] == 3:
                        fitted_image = fitted_image.transpose(1, 2, 0)
                    fitted_image = (fitted_image * 255).astype(np.uint8)
            elif isinstance(fitted_image, Image.Image):
                fitted_image = np.array(fitted_image.convert('RGB'))
            elif not isinstance(fitted_image, np.ndarray):
                raise ValueError(f"ì§€ì›ë˜ì§€ ì•ŠëŠ” ì´ë¯¸ì§€ íƒ€ì…: {type(fitted_image)}")
            
            # ì´ë¯¸ì§€ ê²€ì¦
            if fitted_image.ndim != 3 or fitted_image.shape[2] != 3:
                raise ValueError(f"ì˜ëª»ëœ ì´ë¯¸ì§€ í˜•íƒœ: {fitted_image.shape}")
            
            # í¬ê¸° ì œí•œ í™•ì¸
            max_height, max_width = self.post_processing_config.max_resolution
            if fitted_image.shape[0] > max_height or fitted_image.shape[1] > max_width:
                fitted_image = self._resize_image_preserve_ratio(fitted_image, max_height, max_width)
            
            return {
                'image': fitted_image,
                'original_shape': fitted_image.shape,
                'mask': fitting_result.get('mask'),
                'confidence': fitting_result.get('confidence', 1.0),
                'metadata': fitting_result.get('metadata', {})
            }
            
        except Exception as e:
            self.logger.error(f"ì…ë ¥ ë°ì´í„° ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            raise

    def _prepare_enhancement_options(self, enhancement_options: Optional[Dict[str, Any]]) -> Dict[str, Any]:
        """í–¥ìƒ ì˜µì…˜ ì¤€ë¹„"""
        try:
            # ê¸°ë³¸ ì˜µì…˜
            default_options = {
                'quality_level': self.post_processing_config.quality_level.value,
                'enabled_methods': [method.value for method in self.post_processing_config.enabled_methods],
                'enhancement_strength': self.enhancement_strength,
                'preserve_faces': self.preserve_faces,
                'auto_adjust_brightness': self.auto_adjust_brightness,
            }
            
            # ê° ë°©ë²•ë³„ ì ìš© ì—¬ë¶€ ì„¤ì •
            for method in self.post_processing_config.enabled_methods:
                default_options[f'apply_{method.value}'] = True
            
            # ì‚¬ìš©ì ì˜µì…˜ìœ¼ë¡œ ë®ì–´ì“°ê¸°
            if enhancement_options:
                default_options.update(enhancement_options)
            
            return default_options
            
        except Exception as e:
            self.logger.error(f"í–¥ìƒ ì˜µì…˜ ì¤€ë¹„ ì‹¤íŒ¨: {e}")
            return {}

    async def _perform_enhancement_pipeline(
        self,
        processed_input: Dict[str, Any],
        options: Dict[str, Any],
        **kwargs
    ) -> PostProcessingResult:
        """í–¥ìƒ íŒŒì´í”„ë¼ì¸ ìˆ˜í–‰"""
        try:
            image = processed_input['image'].copy()
            applied_methods = []
            enhancement_log = []
            
            original_quality = self._calculate_image_quality(image)
            
            # ê° í–¥ìƒ ë°©ë²• ì ìš©
            for method in self.post_processing_config.enabled_methods:
                method_name = method.value
                
                try:
                    if method == EnhancementMethod.SUPER_RESOLUTION and options.get(f'apply_{method_name}', False):
                        enhanced_image = await self._apply_super_resolution(image)
                        if enhanced_image is not None:
                            image = enhanced_image
                            applied_methods.append(method_name)
                            enhancement_log.append("Super Resolution ì ìš©")
                    
                    elif method in [EnhancementMethod.NOISE_REDUCTION, EnhancementMethod.DENOISING] and options.get(f'apply_{method_name}', False):
                        if self.denoise_model:
                            enhanced_image = await self._apply_ai_denoising(image)
                        else:
                            enhanced_image = self._apply_traditional_denoising(image)
                        
                        if enhanced_image is not None:
                            image = enhanced_image
                            applied_methods.append(method_name)
                            enhancement_log.append("ë…¸ì´ì¦ˆ ì œê±° ì ìš©")
                    
                    elif method == EnhancementMethod.SHARPENING and options.get(f'apply_{method_name}', False):
                        enhanced_image = self._apply_advanced_sharpening(image, options['enhancement_strength'])
                        if enhanced_image is not None:
                            image = enhanced_image
                            applied_methods.append(method_name)
                            enhancement_log.append("ì„ ëª…ë„ í–¥ìƒ ì ìš©")
                    
                    elif method == EnhancementMethod.COLOR_CORRECTION and options.get(f'apply_{method_name}', False):
                        enhanced_image = self._apply_color_correction(image)
                        if enhanced_image is not None:
                            image = enhanced_image
                            applied_methods.append(method_name)
                            enhancement_log.append("ìƒ‰ìƒ ë³´ì • ì ìš©")
                    
                    elif method == EnhancementMethod.CONTRAST_ENHANCEMENT and options.get(f'apply_{method_name}', False):
                        enhanced_image = self._apply_contrast_enhancement(image)
                        if enhanced_image is not None:
                            image = enhanced_image
                            applied_methods.append(method_name)
                            enhancement_log.append("ëŒ€ë¹„ í–¥ìƒ ì ìš©")
                    
                    elif method == EnhancementMethod.FACE_ENHANCEMENT and options.get('preserve_faces', False) and self.face_detector:
                        faces = self._detect_faces(image)
                        if faces:
                            enhanced_image = self._enhance_face_regions(image, faces)
                            if enhanced_image is not None:
                                image = enhanced_image
                                applied_methods.append(method_name)
                                enhancement_log.append(f"ì–¼êµ´ í–¥ìƒ ì ìš© ({len(faces)}ê°œ ì–¼êµ´)")
                
                except Exception as e:
                    self.logger.warning(f"{method_name} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                    continue
            
            # ìµœì¢… í›„ì²˜ë¦¬
            try:
                final_image = self._apply_final_post_processing(image)
                if final_image is not None:
                    image = final_image
                    enhancement_log.append("ìµœì¢… í›„ì²˜ë¦¬ ì ìš©")
            except Exception as e:
                self.logger.warning(f"ìµœì¢… í›„ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            
            # í’ˆì§ˆ ê°œì„ ë„ ê³„ì‚°
            final_quality = self._calculate_image_quality(image)
            quality_improvement = final_quality - original_quality
            
            return PostProcessingResult(
                success=True,
                enhanced_image=image,
                quality_improvement=quality_improvement,
                applied_methods=applied_methods,
                processing_time=0.0,  # í˜¸ì¶œë¶€ì—ì„œ ì„¤ì •
                metadata={
                    'enhancement_log': enhancement_log,
                    'original_quality': original_quality,
                    'final_quality': final_quality,
                    'original_shape': processed_input['original_shape'],
                    'options_used': options
                }
            )
            
        except Exception as e:
            return PostProcessingResult(
                success=False,
                error_message=f"í–¥ìƒ íŒŒì´í”„ë¼ì¸ ì‹¤íŒ¨: {e}",
                processing_time=0.0
            )

    # ==============================================
    # AI ëª¨ë¸ ì²˜ë¦¬ ë©”ì„œë“œë“¤
    # ==============================================

    async def _apply_super_resolution(self, image: np.ndarray) -> Optional[np.ndarray]:
        """Super Resolution ì ìš©"""
        try:
            if not self.sr_model:
                return None
            
            # ì´ë¯¸ì§€ë¥¼ í…ì„œë¡œ ë³€í™˜
            transform = transforms.Compose([
                transforms.ToTensor(),
            ])
            
            # PILë¡œ ë³€í™˜ í›„ í…ì„œë¡œ
            pil_image = Image.fromarray(image)
            input_tensor = transform(pil_image).unsqueeze(0).to(self.device)
            
            if self.device == "mps":
                input_tensor = input_tensor.float()
            elif self.device == "cuda":
                input_tensor = input_tensor.half()
            
            # ì¶”ë¡ 
            with torch.no_grad():
                output_tensor = self.sr_model(input_tensor)
                
                # í›„ì²˜ë¦¬
                output_tensor = torch.clamp(output_tensor, 0, 1)
                
                # í…ì„œë¥¼ numpyë¡œ ë³€í™˜
                output_np = output_tensor.squeeze().cpu().float().numpy()
                if output_np.ndim == 3:
                    output_np = output_np.transpose(1, 2, 0)
                
                # 0-255 ë²”ìœ„ë¡œ ë³€í™˜
                enhanced_image = (output_np * 255).astype(np.uint8)
                
                return enhanced_image
                
        except Exception as e:
            self.logger.error(f"Super Resolution ì ìš© ì‹¤íŒ¨: {e}")
            return None

    async def _apply_ai_denoising(self, image: np.ndarray) -> Optional[np.ndarray]:
        """AI ê¸°ë°˜ ë…¸ì´ì¦ˆ ì œê±°"""
        try:
            if not self.denoise_model:
                return None
            
            # ì´ë¯¸ì§€ë¥¼ í…ì„œë¡œ ë³€í™˜
            transform = transforms.Compose([
                transforms.ToTensor(),
            ])
            
            pil_image = Image.fromarray(image)
            input_tensor = transform(pil_image).unsqueeze(0).to(self.device)
            
            if self.device == "mps":
                input_tensor = input_tensor.float()
            elif self.device == "cuda":
                input_tensor = input_tensor.half()
            
            # ì¶”ë¡ 
            with torch.no_grad():
                output_tensor = self.denoise_model(input_tensor)
                
                # í…ì„œë¥¼ numpyë¡œ ë³€í™˜
                output_np = output_tensor.squeeze().cpu().float().numpy()
                if output_np.ndim == 3:
                    output_np = output_np.transpose(1, 2, 0)
                
                # 0-255 ë²”ìœ„ë¡œ ë³€í™˜
                denoised_image = (output_np * 255).astype(np.uint8)
                
                return denoised_image
                
        except Exception as e:
            self.logger.error(f"AI ë…¸ì´ì¦ˆ ì œê±° ì‹¤íŒ¨: {e}")
            return None

    # ==============================================
    # ì „í†µì  ì´ë¯¸ì§€ ì²˜ë¦¬ ë©”ì„œë“œë“¤
    # ==============================================

    def _apply_traditional_denoising(self, image: np.ndarray) -> np.ndarray:
        """ì „í†µì  ë…¸ì´ì¦ˆ ì œê±°"""
        try:
            # ë¹„ì„ í˜• í™•ì‚° í•„í„° ë˜ëŠ” bilateral í•„í„° ì‚¬ìš©
            if SKIMAGE_AVAILABLE:
                denoised = restoration.denoise_bilateral(
                    image, 
                    sigma_color=0.05, 
                    sigma_spatial=15, 
                    channel_axis=2
                )
                return (denoised * 255).astype(np.uint8)
            else:
                # OpenCV bilateral filter
                denoised = cv2.bilateralFilter(image, 9, 75, 75)
                return denoised
                
        except Exception as e:
            self.logger.error(f"ì „í†µì  ë…¸ì´ì¦ˆ ì œê±° ì‹¤íŒ¨: {e}")
            return image

    def _apply_advanced_sharpening(self, image: np.ndarray, strength: float) -> np.ndarray:
        """ê³ ê¸‰ ì„ ëª…ë„ í–¥ìƒ"""
        try:
            # ì–¸ìƒ¤í”„ ë§ˆìŠ¤í‚¹
            blurred = cv2.GaussianBlur(image, (5, 5), 1.0)
            unsharp_mask = cv2.addWeighted(image, 1 + strength, blurred, -strength, 0)
            
            # ì ì‘í˜• ì„ ëª…í™”
            gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
            edges = cv2.Canny(gray, 50, 150)
            
            # ì—ì§€ ì˜ì—­ì—ë§Œ ì¶”ê°€ ì„ ëª…í™” ì ìš©
            kernel = self.sharpening_kernel * strength
            sharpened = cv2.filter2D(unsharp_mask, -1, kernel)
            
            # ì—ì§€ ë§ˆìŠ¤í¬ ì ìš©
            edge_mask = (edges > 0).astype(np.float32)
            edge_mask = np.stack([edge_mask, edge_mask, edge_mask], axis=2)
            
            result = unsharp_mask * (1 - edge_mask) + sharpened * edge_mask
            
            return np.clip(result, 0, 255).astype(np.uint8)
            
        except Exception as e:
            self.logger.error(f"ì„ ëª…ë„ í–¥ìƒ ì‹¤íŒ¨: {e}")
            return image

    def _apply_color_correction(self, image: np.ndarray) -> np.ndarray:
        """ìƒ‰ìƒ ë³´ì •"""
        try:
            # LAB ìƒ‰ê³µê°„ìœ¼ë¡œ ë³€í™˜
            lab = cv2.cvtColor(image, cv2.COLOR_RGB2LAB)
            l, a, b = cv2.split(lab)
            
            # CLAHE (Contrast Limited Adaptive Histogram Equalization) ì ìš©
            clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
            l = clahe.apply(l)
            
            # LAB ì±„ë„ ì¬ê²°í•©
            lab = cv2.merge([l, a, b])
            
            # RGBë¡œ ë‹¤ì‹œ ë³€í™˜
            corrected = cv2.cvtColor(lab, cv2.COLOR_LAB2RGB)
            
            # í™”ì´íŠ¸ ë°¸ëŸ°ìŠ¤ ì¡°ì •
            corrected = self._adjust_white_balance(corrected)
            
            return corrected
            
        except Exception as e:
            self.logger.error(f"ìƒ‰ìƒ ë³´ì • ì‹¤íŒ¨: {e}")
            return image

    def _adjust_white_balance(self, image: np.ndarray) -> np.ndarray:
        """í™”ì´íŠ¸ ë°¸ëŸ°ìŠ¤ ì¡°ì •"""
        try:
            # Gray World ì•Œê³ ë¦¬ì¦˜
            r_mean = np.mean(image[:, :, 0])
            g_mean = np.mean(image[:, :, 1])
            b_mean = np.mean(image[:, :, 2])
            
            gray_mean = (r_mean + g_mean + b_mean) / 3
            
            r_gain = gray_mean / r_mean if r_mean > 0 else 1.0
            g_gain = gray_mean / g_mean if g_mean > 0 else 1.0
            b_gain = gray_mean / b_mean if b_mean > 0 else 1.0
            
            # ê²Œì¸ ì œí•œ
            max_gain = 1.5
            r_gain = min(r_gain, max_gain)
            g_gain = min(g_gain, max_gain)
            b_gain = min(b_gain, max_gain)
            
            # ì±„ë„ë³„ ì¡°ì •
            balanced = image.copy().astype(np.float32)
            balanced[:, :, 0] *= r_gain
            balanced[:, :, 1] *= g_gain
            balanced[:, :, 2] *= b_gain
            
            return np.clip(balanced, 0, 255).astype(np.uint8)
            
        except Exception as e:
            self.logger.error(f"í™”ì´íŠ¸ ë°¸ëŸ°ìŠ¤ ì¡°ì • ì‹¤íŒ¨: {e}")
            return image

    def _apply_contrast_enhancement(self, image: np.ndarray) -> np.ndarray:
        """ëŒ€ë¹„ í–¥ìƒ"""
        try:
            # ì ì‘í˜• íˆìŠ¤í† ê·¸ë¨ í‰í™œí™”
            lab = cv2.cvtColor(image, cv2.COLOR_RGB2LAB)
            l, a, b = cv2.split(lab)
            
            # CLAHE ì ìš©
            clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))
            l_enhanced = clahe.apply(l)
            
            # ì±„ë„ ì¬ê²°í•©
            lab_enhanced = cv2.merge([l_enhanced, a, b])
            enhanced = cv2.cvtColor(lab_enhanced, cv2.COLOR_LAB2RGB)
            
            # ì¶”ê°€ ëŒ€ë¹„ ì¡°ì • (sigmoid ê³¡ì„ )
            enhanced = self._apply_sigmoid_correction(enhanced, gain=1.2, cutoff=0.5)
            
            return enhanced
            
        except Exception as e:
            self.logger.error(f"ëŒ€ë¹„ í–¥ìƒ ì‹¤íŒ¨: {e}")
            return image

    def _apply_sigmoid_correction(self, image: np.ndarray, gain: float, cutoff: float) -> np.ndarray:
        """ì‹œê·¸ëª¨ì´ë“œ ê³¡ì„ ì„ ì‚¬ìš©í•œ ëŒ€ë¹„ ì¡°ì •"""
        try:
            # 0-1 ë²”ìœ„ë¡œ ì •ê·œí™”
            normalized = image.astype(np.float32) / 255.0
            
            # ì‹œê·¸ëª¨ì´ë“œ í•¨ìˆ˜ ì ìš©
            sigmoid = 1 / (1 + np.exp(gain * (cutoff - normalized)))
            
            # 0-255 ë²”ìœ„ë¡œ ë‹¤ì‹œ ë³€í™˜
            result = (sigmoid * 255).astype(np.uint8)
            
            return result
            
        except Exception as e:
            self.logger.error(f"ì‹œê·¸ëª¨ì´ë“œ ë³´ì • ì‹¤íŒ¨: {e}")
            return image

    def _detect_faces(self, image: np.ndarray) -> List[Tuple[int, int, int, int]]:
        """ì–¼êµ´ ê²€ì¶œ"""
        try:
            if not self.face_detector:
                return []
            
            faces = []
            
            if hasattr(self.face_detector, 'setInput'):
                # DNN ê¸°ë°˜ ê²€ì¶œê¸°
                blob = cv2.dnn.blobFromImage(image, 1.0, (300, 300), [104, 117, 123])
                self.face_detector.setInput(blob)
                detections = self.face_detector.forward()
                
                h, w = image.shape[:2]
                
                for i in range(detections.shape[2]):
                    confidence = detections[0, 0, i, 2]
                    if confidence > 0.5:
                        x1 = int(detections[0, 0, i, 3] * w)
                        y1 = int(detections[0, 0, i, 4] * h)
                        x2 = int(detections[0, 0, i, 5] * w)
                        y2 = int(detections[0, 0, i, 6] * h)
                        faces.append((x1, y1, x2 - x1, y2 - y1))
            else:
                # Haar Cascade ê²€ì¶œê¸°
                gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
                detected_faces = self.face_detector.detectMultiScale(
                    gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30)
                )
                faces = [tuple(face) for face in detected_faces]
            
            return faces
            
        except Exception as e:
            self.logger.error(f"ì–¼êµ´ ê²€ì¶œ ì‹¤íŒ¨: {e}")
            return []

    def _enhance_face_regions(self, image: np.ndarray, faces: List[Tuple[int, int, int, int]]) -> np.ndarray:
        """ì–¼êµ´ ì˜ì—­ í–¥ìƒ"""
        try:
            enhanced = image.copy()
            
            for (x, y, w, h) in faces:
                # ì–¼êµ´ ì˜ì—­ ì¶”ì¶œ
                face_region = image[y:y+h, x:x+w]
                
                if face_region.size == 0:
                    continue
                
                # ì–¼êµ´ ì˜ì—­ì— ëŒ€í•´ ë¶€ë“œëŸ¬ìš´ í–¥ìƒ ì ìš©
                # 1. ì•½ê°„ì˜ ë¸”ëŸ¬ë¥¼ í†µí•œ í”¼ë¶€ ë¶€ë“œëŸ½ê²Œ
                blurred = cv2.GaussianBlur(face_region, (5, 5), 1.0)
                
                # 2. ì›ë³¸ê³¼ ë¸”ëŸ¬ì˜ ê°€ì¤‘ í•©ì„±
                softened = cv2.addWeighted(face_region, 0.7, blurred, 0.3, 0)
                
                # 3. ë°ê¸° ì•½ê°„ ì¡°ì •
                brightened = cv2.convertScaleAbs(softened, alpha=1.1, beta=5)
                
                # 4. í–¥ìƒëœ ì–¼êµ´ ì˜ì—­ì„ ì›ë³¸ì— ì ìš©
                enhanced[y:y+h, x:x+w] = brightened
            
            return enhanced
            
        except Exception as e:
            self.logger.error(f"ì–¼êµ´ ì˜ì—­ í–¥ìƒ ì‹¤íŒ¨: {e}")
            return image

    def _apply_final_post_processing(self, image: np.ndarray) -> np.ndarray:
        """ìµœì¢… í›„ì²˜ë¦¬"""
        try:
            # 1. ë¯¸ì„¸í•œ ë…¸ì´ì¦ˆ ì œê±°
            denoised = cv2.medianBlur(image, 3)
            
            # 2. ì•½ê°„ì˜ ì„ ëª…í™”
            kernel = np.array([[-0.1, -0.1, -0.1],
                               [-0.1,  1.8, -0.1],
                               [-0.1, -0.1, -0.1]])
            sharpened = cv2.filter2D(denoised, -1, kernel)
            
            # 3. ìƒ‰ìƒ ë³´ì •
            final = cv2.convertScaleAbs(sharpened, alpha=1.02, beta=2)
            
            return final
            
        except Exception as e:
            self.logger.error(f"ìµœì¢… í›„ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return image

    def _calculate_image_quality(self, image: np.ndarray) -> float:
        """ì´ë¯¸ì§€ í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°"""
        try:
            # ì—¬ëŸ¬ í’ˆì§ˆ ì§€í‘œì˜ ì¡°í•©
            
            # 1. ì„ ëª…ë„ (ë¼í”Œë¼ì‹œì•ˆ ë¶„ì‚°)
            gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
            laplacian_var = cv2.Laplacian(gray, cv2.CV_64F).var()
            sharpness_score = min(laplacian_var / 1000.0, 1.0)
            
            # 2. ëŒ€ë¹„ (í‘œì¤€í¸ì°¨)
            contrast_score = min(np.std(gray) / 128.0, 1.0)
            
            # 3. ë°ê¸° ê· í˜• (íˆìŠ¤í† ê·¸ë¨ ë¶„í¬)
            hist = cv2.calcHist([gray], [0], None, [256], [0, 256])
            hist_normalized = hist / hist.sum()
            entropy = -np.sum(hist_normalized * np.log2(hist_normalized + 1e-10))
            brightness_score = min(entropy / 8.0, 1.0)
            
            # 4. ìƒ‰ìƒ ë‹¤ì–‘ì„±
            rgb_std = np.mean([np.std(image[:, :, i]) for i in range(3)])
            color_score = min(rgb_std / 64.0, 1.0)
            
            # ê°€ì¤‘ í‰ê· 
            quality_score = (
                sharpness_score * 0.3 +
                contrast_score * 0.3 +
                brightness_score * 0.2 +
                color_score * 0.2
            )
            
            return quality_score
            
        except Exception as e:
            self.logger.error(f"í’ˆì§ˆ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return 0.5

    def _resize_image_preserve_ratio(self, image: np.ndarray, max_height: int, max_width: int) -> np.ndarray:
        """ë¹„ìœ¨ì„ ìœ ì§€í•˜ë©´ì„œ ì´ë¯¸ì§€ í¬ê¸° ì¡°ì •"""
        try:
            h, w = image.shape[:2]
            
            if h <= max_height and w <= max_width:
                return image
            
            # ë¹„ìœ¨ ê³„ì‚°
            ratio = min(max_height / h, max_width / w)
            new_h = int(h * ratio)
            new_w = int(w * ratio)
            
            # ê³ í’ˆì§ˆ ë¦¬ìƒ˜í”Œë§
            resized = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_LANCZOS4)
            
            return resized
            
        except Exception as e:
            self.logger.error(f"ì´ë¯¸ì§€ í¬ê¸° ì¡°ì • ì‹¤íŒ¨: {e}")
            return image

    # ==============================================
    # ì‹œê°í™” ê´€ë ¨ ë©”ì„œë“œë“¤
    # ==============================================

    async def _create_enhancement_visualization(
        self,
        processed_input: Dict[str, Any],
        result: PostProcessingResult,
        options: Dict[str, Any]
    ) -> Dict[str, str]:
        """í›„ì²˜ë¦¬ ê²°ê³¼ ì‹œê°í™” ì´ë¯¸ì§€ë“¤ ìƒì„±"""
        try:
            if not self.post_processing_config.enable_visualization:
                return {
                    'before_after_comparison': '',
                    'enhancement_details': '',
                    'quality_metrics': ''
                }
            
            def _create_visualizations():
                original_image = processed_input['image']
                enhanced_image = result.enhanced_image
                
                visualizations = {}
                
                # 1. Before/After ë¹„êµ ì´ë¯¸ì§€
                if self.post_processing_config.show_before_after:
                    before_after = self._create_before_after_comparison(
                        original_image, enhanced_image, result
                    )
                    visualizations['before_after_comparison'] = self._numpy_to_base64(before_after)
                else:
                    visualizations['before_after_comparison'] = ''
                
                # 2. í–¥ìƒ ì„¸ë¶€ì‚¬í•­ ì‹œê°í™”
                if self.post_processing_config.show_enhancement_details:
                    enhancement_details = self._create_enhancement_details_visualization(
                        original_image, enhanced_image, result, options
                    )
                    visualizations['enhancement_details'] = self._numpy_to_base64(enhancement_details)
                else:
                    visualizations['enhancement_details'] = ''
                
                # 3. í’ˆì§ˆ ë©”íŠ¸ë¦­ ì‹œê°í™”
                quality_metrics = self._create_quality_metrics_visualization(
                    result, options
                )
                visualizations['quality_metrics'] = self._numpy_to_base64(quality_metrics)
                
                return visualizations
            
            # ë¹„ë™ê¸° ì‹¤í–‰
            loop = asyncio.get_event_loop()
            return await loop.run_in_executor(self.executor, _create_visualizations)
            
        except Exception as e:
            self.logger.error(f"âŒ ì‹œê°í™” ìƒì„± ì‹¤íŒ¨: {e}")
            return {
                'before_after_comparison': '',
                'enhancement_details': '',
                'quality_metrics': ''
            }

    def _create_before_after_comparison(
        self,
        original_image: np.ndarray,
        enhanced_image: np.ndarray,
        result: PostProcessingResult
    ) -> np.ndarray:
        """Before/After ë¹„êµ ì´ë¯¸ì§€ ìƒì„±"""
        try:
            # ì´ë¯¸ì§€ í¬ê¸° ë§ì¶”ê¸°
            target_size = (512, 512)
            original_resized = cv2.resize(original_image, target_size, interpolation=cv2.INTER_LANCZOS4)
            enhanced_resized = cv2.resize(enhanced_image, target_size, interpolation=cv2.INTER_LANCZOS4)
            
            # ë‚˜ë€íˆ ë°°ì¹˜í•  ìº”ë²„ìŠ¤ ìƒì„±
            canvas_width = target_size[0] * 2 + 100  # 100px ê°„ê²©
            canvas_height = target_size[1] + 100  # ìƒë‹¨ì— í…ìŠ¤íŠ¸ ê³µê°„
            canvas = np.ones((canvas_height, canvas_width, 3), dtype=np.uint8) * 240
            
            # ì´ë¯¸ì§€ ë°°ì¹˜
            canvas[50:50+target_size[1], 25:25+target_size[0]] = original_resized
            canvas[50:50+target_size[1], 75+target_size[0]:75+target_size[0]*2] = enhanced_resized
            
            # PILë¡œ ë³€í™˜í•´ì„œ í…ìŠ¤íŠ¸ ì¶”ê°€
            canvas_pil = Image.fromarray(canvas)
            draw = ImageDraw.Draw(canvas_pil)
            
            # í°íŠ¸ ì„¤ì •
            try:
                title_font = ImageFont.truetype("arial.ttf", 24)
                subtitle_font = ImageFont.truetype("arial.ttf", 16)
                text_font = ImageFont.truetype("arial.ttf", 14)
            except Exception:
                title_font = ImageFont.load_default()
                subtitle_font = ImageFont.load_default()
                text_font = ImageFont.load_default()
            
            # ì œëª©
            draw.text((canvas_width//2 - 100, 10), "í›„ì²˜ë¦¬ ê²°ê³¼ ë¹„êµ", fill=(50, 50, 50), font=title_font)
            
            # ë¼ë²¨
            draw.text((25 + target_size[0]//2 - 30, 25), "Before", fill=(100, 100, 100), font=subtitle_font)
            draw.text((75 + target_size[0] + target_size[0]//2 - 30, 25), "After", fill=(100, 100, 100), font=subtitle_font)
            
            # í’ˆì§ˆ ê°œì„  ì •ë³´
            improvement_text = f"í’ˆì§ˆ ê°œì„ : {result.quality_improvement:.1%}"
            methods_text = f"ì ìš©ëœ ë°©ë²•: {', '.join(result.applied_methods[:3])}"
            if len(result.applied_methods) > 3:
                methods_text += f" ì™¸ {len(result.applied_methods) - 3}ê°œ"
            
            draw.text((25, canvas_height - 40), improvement_text, fill=(0, 150, 0), font=text_font)
            draw.text((25, canvas_height - 20), methods_text, fill=(80, 80, 80), font=text_font)
            
            # êµ¬ë¶„ì„ 
            draw.line([(target_size[0] + 50, 50), (target_size[0] + 50, 50 + target_size[1])], 
                     fill=(200, 200, 200), width=2)
            
            return np.array(canvas_pil)
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ Before/After ë¹„êµ ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨: {e}")
            # í´ë°±: ê¸°ë³¸ ì´ë¯¸ì§€
            return np.ones((600, 1100, 3), dtype=np.uint8) * 200

    def _create_enhancement_details_visualization(
        self,
        original_image: np.ndarray,
        enhanced_image: np.ndarray,
        result: PostProcessingResult,
        options: Dict[str, Any]
    ) -> np.ndarray:
        """í–¥ìƒ ì„¸ë¶€ì‚¬í•­ ì‹œê°í™”"""
        try:
            # ê°„ë‹¨í•œ ê·¸ë¦¬ë“œ ìƒì„±
            grid_size = 256
            canvas_width = grid_size * 3 + 100
            canvas_height = grid_size * 2 + 100
            canvas = np.ones((canvas_height, canvas_width, 3), dtype=np.uint8) * 250
            
            # ì´ë¯¸ì§€ ë¦¬ì‚¬ì´ì¦ˆ
            original_small = cv2.resize(original_image, (grid_size, grid_size))
            enhanced_small = cv2.resize(enhanced_image, (grid_size, grid_size))
            
            # ì´ë¯¸ì§€ ë°°ì¹˜
            canvas[25:25+grid_size, 25:25+grid_size] = original_small
            canvas[25:25+grid_size, 50+grid_size:50+grid_size*2] = enhanced_small
            
            # í…ìŠ¤íŠ¸ ì •ë³´ ì¶”ê°€
            canvas_pil = Image.fromarray(canvas)
            draw = ImageDraw.Draw(canvas_pil)
            
            try:
                font = ImageFont.truetype("arial.ttf", 12)
            except Exception:
                font = ImageFont.load_default()
            
            # ë¼ë²¨
            draw.text((25, 5), "ì›ë³¸", fill=(50, 50, 50), font=font)
            draw.text((50+grid_size, 5), "í–¥ìƒëœ ì´ë¯¸ì§€", fill=(50, 50, 50), font=font)
            
            # í–¥ìƒ ë°©ë²• ë¦¬ìŠ¤íŠ¸
            y_offset = 25 + grid_size + 20
            draw.text((25, y_offset), "ì ìš©ëœ í–¥ìƒ ë°©ë²•:", fill=(50, 50, 50), font=font)
            
            for i, method in enumerate(result.applied_methods[:5]):  # ìµœëŒ€ 5ê°œë§Œ í‘œì‹œ
                method_name = method.replace('_', ' ').title()
                draw.text((25, y_offset + 20 + i*15), f"â€¢ {method_name}", fill=(80, 80, 80), font=font)
            
            return np.array(canvas_pil)
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ í–¥ìƒ ì„¸ë¶€ì‚¬í•­ ì‹œê°í™” ì‹¤íŒ¨: {e}")
            return np.ones((400, 800, 3), dtype=np.uint8) * 200

    def _create_quality_metrics_visualization(
        self,
        result: PostProcessingResult,
        options: Dict[str, Any]
    ) -> np.ndarray:
        """í’ˆì§ˆ ë©”íŠ¸ë¦­ ì‹œê°í™”"""
        try:
            # í’ˆì§ˆ ë©”íŠ¸ë¦­ ì •ë³´ íŒ¨ë„ ìƒì„±
            canvas_width = 400
            canvas_height = 300
            canvas = np.ones((canvas_height, canvas_width, 3), dtype=np.uint8) * 250
            
            canvas_pil = Image.fromarray(canvas)
            draw = ImageDraw.Draw(canvas_pil)
            
            # í°íŠ¸ ì„¤ì •
            try:
                title_font = ImageFont.truetype("arial.ttf", 16)
                text_font = ImageFont.truetype("arial.ttf", 12)
            except Exception:
                title_font = ImageFont.load_default()
                text_font = ImageFont.load_default()
            
            # ì œëª©
            draw.text((20, 20), "í›„ì²˜ë¦¬ í’ˆì§ˆ ë¶„ì„", fill=(50, 50, 50), font=title_font)
            
            # ì „ì²´ ê°œì„ ë„ í‘œì‹œ
            improvement_percent = result.quality_improvement * 100
            improvement_color = (0, 150, 0) if improvement_percent > 15 else (255, 150, 0) if improvement_percent > 5 else (255, 0, 0)
            draw.text((20, 50), f"ì „ì²´ í’ˆì§ˆ ê°œì„ : {improvement_percent:.1f}%", fill=improvement_color, font=text_font)
            
            # ì ìš©ëœ ë°©ë²•ë“¤
            y_offset = 80
            draw.text((20, y_offset), "ì ìš©ëœ í–¥ìƒ ë°©ë²•:", fill=(50, 50, 50), font=text_font)
            y_offset += 25
            
            for i, method in enumerate(result.applied_methods[:8]):  # ìµœëŒ€ 8ê°œ
                method_name = method.replace('_', ' ').title()
                draw.text((30, y_offset), f"â€¢ {method_name}", fill=(80, 80, 80), font=text_font)
                y_offset += 20
            
            # ì²˜ë¦¬ ì‹œê°„ ì •ë³´
            y_offset += 10
            draw.text((20, y_offset), f"ì²˜ë¦¬ ì‹œê°„: {result.processing_time:.2f}ì´ˆ", fill=(100, 100, 100), font=text_font)
            
            return np.array(canvas_pil)
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ í’ˆì§ˆ ë©”íŠ¸ë¦­ ì‹œê°í™” ì‹¤íŒ¨: {e}")
            return np.ones((300, 400, 3), dtype=np.uint8) * 200

    def _numpy_to_base64(self, image: np.ndarray) -> str:
        """numpy ë°°ì—´ì„ base64 ë¬¸ìì—´ë¡œ ë³€í™˜"""
        try:
            # PIL ì´ë¯¸ì§€ë¡œ ë³€í™˜
            pil_image = Image.fromarray(image)
            
            # BytesIO ë²„í¼ì— ì €ì¥
            buffer = BytesIO()
            
            # í’ˆì§ˆ ì„¤ì •
            quality = 90
            if self.post_processing_config.visualization_quality == 'high':
                quality = 95
            elif self.post_processing_config.visualization_quality == 'low':
                quality = 75
            
            pil_image.save(buffer, format='JPEG', quality=quality)
            
            # base64 ì¸ì½”ë”©
            return base64.b64encode(buffer.getvalue()).decode('utf-8')
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ base64 ë³€í™˜ ì‹¤íŒ¨: {e}")
            return ""

    # ==============================================
    # ìœ í‹¸ë¦¬í‹° ë° ê´€ë¦¬ ë©”ì„œë“œë“¤
    # ==============================================

    def _generate_cache_key(self, fitting_result: Dict[str, Any], enhancement_options: Optional[Dict[str, Any]]) -> str:
        """ìºì‹œ í‚¤ ìƒì„±"""
        try:
            # ì…ë ¥ ì´ë¯¸ì§€ í•´ì‹œ
            fitted_image = fitting_result.get('fitted_image') or fitting_result.get('result_image')
            if isinstance(fitted_image, str):
                # Base64 ë¬¸ìì—´ì˜ í•´ì‹œ
                image_hash = hashlib.md5(fitted_image.encode()).hexdigest()[:16]
            elif isinstance(fitted_image, np.ndarray):
                image_hash = hashlib.md5(fitted_image.tobytes()).hexdigest()[:16]
            else:
                image_hash = str(hash(str(fitted_image)))[:16]
            
            # ì˜µì…˜ í•´ì‹œ
            options_str = json.dumps(enhancement_options or {}, sort_keys=True)
            options_hash = hashlib.md5(options_str.encode()).hexdigest()[:8]
            
            # ì „ì²´ í‚¤ ìƒì„±
            cache_key = f"{image_hash}_{options_hash}_{self.device}_{self.quality_level}"
            return cache_key
            
        except Exception as e:
            self.logger.warning(f"ìºì‹œ í‚¤ ìƒì„± ì‹¤íŒ¨: {e}")
            return f"fallback_{time.time()}_{self.device}"

    def _cleanup_cache(self):
        """ìºì‹œ ì •ë¦¬ (LRU ë°©ì‹)"""
        try:
            if len(self.enhancement_cache) <= self.post_processing_config.cache_size:
                return
            
            # ê°€ì¥ ì˜¤ë˜ëœ í•­ëª©ë“¤ ì œê±°
            items = list(self.enhancement_cache.items())
            # ì²˜ë¦¬ ì‹œê°„ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬ (ìµœê·¼ ì‚¬ìš©ëœ ê²ƒì´ ë’¤ì—)
            items.sort(key=lambda x: x[1].processing_time)
            
            # ì ˆë°˜ ì •ë„ ì œê±°
            remove_count = len(items) - self.post_processing_config.cache_size // 2
            
            for i in range(remove_count):
                del self.enhancement_cache[items[i][0]]
            
            self.logger.info(f"ğŸ’¾ ìºì‹œ ì •ë¦¬ ì™„ë£Œ: {remove_count}ê°œ í•­ëª© ì œê±°")
            
        except Exception as e:
            self.logger.error(f"ìºì‹œ ì •ë¦¬ ì‹¤íŒ¨: {e}")

    def _update_statistics(self, result: PostProcessingResult, processing_time: float):
        """í†µê³„ ì—…ë°ì´íŠ¸"""
        try:
            self.processing_stats['total_processed'] += 1
            
            if result.success:
                self.processing_stats['successful_enhancements'] += 1
                
                # í‰ê·  ê°œì„ ë„ ì—…ë°ì´íŠ¸
                current_avg = self.processing_stats['average_improvement']
                total_successful = self.processing_stats['successful_enhancements']
                
                self.processing_stats['average_improvement'] = (
                    (current_avg * (total_successful - 1) + result.quality_improvement) / total_successful
                )
                
                # ë°©ë²•ë³„ ì‚¬ìš© í†µê³„
                for method in result.applied_methods:
                    if method not in self.processing_stats['method_usage']:
                        self.processing_stats['method_usage'][method] = 0
                    self.processing_stats['method_usage'][method] += 1
            
            # í‰ê·  ì²˜ë¦¬ ì‹œê°„ ì—…ë°ì´íŠ¸
            current_avg_time = self.processing_stats['average_processing_time']
            total_processed = self.processing_stats['total_processed']
            
            self.processing_stats['average_processing_time'] = (
                (current_avg_time * (total_processed - 1) + processing_time) / total_processed
            )
            
            # ê²°ê³¼ì— ì²˜ë¦¬ ì‹œê°„ ì„¤ì •
            result.processing_time = processing_time
            
        except Exception as e:
            self.logger.warning(f"í†µê³„ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")

    def _format_result(self, result: PostProcessingResult) -> Dict[str, Any]:
        """ê²°ê³¼ë¥¼ í‘œì¤€ ë”•ì…”ë„ˆë¦¬ í˜•íƒœë¡œ í¬ë§· + API í˜¸í™˜ì„±"""
        try:
            # API í˜¸í™˜ì„±ì„ ìœ„í•œ ê²°ê³¼ êµ¬ì¡° (ê¸°ì¡´ í•„ë“œ + ì‹œê°í™” í•„ë“œ)
            formatted_result = {
                'success': result.success,
                'message': f'í›„ì²˜ë¦¬ ì™„ë£Œ - í’ˆì§ˆ ê°œì„ : {result.quality_improvement:.1%}' if result.success else result.error_message,
                'confidence': min(1.0, max(0.0, result.quality_improvement + 0.7)) if result.success else 0.0,
                'processing_time': result.processing_time,
                'details': {}
            }
            
            if result.success:
                # í”„ë¡ íŠ¸ì—”ë“œìš© ì‹œê°í™” ì´ë¯¸ì§€ë“¤
                visualization = result.metadata.get('visualization', {})
                formatted_result['details'] = {
                    # ì‹œê°í™” ì´ë¯¸ì§€ë“¤
                    'result_image': visualization.get('before_after_comparison', ''),
                    'overlay_image': visualization.get('enhancement_details', ''),
                    
                    # ê¸°ì¡´ ë°ì´í„°ë“¤
                    'applied_methods': result.applied_methods,
                    'quality_improvement': result.quality_improvement,
                    'enhancement_count': len(result.applied_methods),
                    'processing_mode': self.post_processing_config.processing_mode.value,
                    'quality_level': self.post_processing_config.quality_level.value,
                    
                    # ìƒì„¸ í–¥ìƒ ì •ë³´
                    'enhancement_details': {
                        'methods_applied': len(result.applied_methods),
                        'improvement_percentage': result.quality_improvement * 100,
                        'enhancement_log': result.metadata.get('enhancement_log', []),
                        'quality_metrics': visualization.get('quality_metrics', '')
                    },
                    
                    # ì‹œìŠ¤í…œ ì •ë³´
                    'step_info': {
                        'step_name': 'post_processing',
                        'step_number': 7,
                        'device': self.device,
                        'quality_level': self.quality_level,
                        'optimization': 'M3 Max' if self.is_m3_max else self.device,
                        'models_used': {
                            'sr_model': hasattr(self, 'sr_model') and self.sr_model is not None,
                            'denoise_model': hasattr(self, 'denoise_model') and self.denoise_model is not None,
                            'face_detector': self.face_detector is not None
                        }
                    },
                    
                    # í’ˆì§ˆ ë©”íŠ¸ë¦­
                    'quality_metrics': {
                        'overall_improvement': result.quality_improvement,
                        'original_quality': result.metadata.get('original_quality', 0.5),
                        'final_quality': result.metadata.get('final_quality', 0.5),
                        'enhancement_strength': self.enhancement_strength,
                        'face_enhancement_applied': 'face_enhancement' in result.applied_methods
                    }
                }
                
                # ê¸°ì¡´ API í˜¸í™˜ì„± í•„ë“œë“¤
                formatted_result.update({
                    'enhanced_image': result.enhanced_image.tolist() if result.enhanced_image is not None else None,
                    'applied_methods': result.applied_methods,
                    'metadata': result.metadata
                })
            else:
                # ì—ëŸ¬ ì‹œ ê¸°ë³¸ êµ¬ì¡°
                formatted_result['details'] = {
                    'result_image': '',
                    'overlay_image': '',
                    'error': result.error_message,
                    'step_info': {
                        'step_name': 'post_processing',
                        'step_number': 7,
                        'error': result.error_message
                    }
                }
                formatted_result['error_message'] = result.error_message
            
            return formatted_result
            
        except Exception as e:
            self.logger.error(f"ê²°ê³¼ í¬ë§·íŒ… ì‹¤íŒ¨: {e}")
            return {
                'success': False,
                'message': f'ê²°ê³¼ í¬ë§·íŒ… ì‹¤íŒ¨: {e}',
                'confidence': 0.0,
                'processing_time': 0.0,
                'details': {
                    'result_image': '',
                    'overlay_image': '',
                    'error': str(e),
                    'step_info': {
                        'step_name': 'post_processing',
                        'step_number': 7,
                        'error': str(e)
                    }
                },
                'applied_methods': [],
                'error_message': str(e)
            }

    async def _perform_enhancement_cached(self, *args, **kwargs):
        """ìºì‹œëœ í–¥ìƒ ìˆ˜í–‰ (LRU ìºì‹œìš©)"""
        return await self._perform_enhancement_pipeline(*args, **kwargs)

    async def get_step_info(self) -> Dict[str, Any]:
        """7ë‹¨ê³„ ìƒì„¸ ì •ë³´ ë°˜í™˜"""
        try:
            return {
                "step_name": "post_processing",
                "step_number": 7,
                "device": self.device,
                "initialized": self.is_initialized,
                "models_loaded": {
                    "sr_model": hasattr(self, 'sr_model') and self.sr_model is not None,
                    "denoise_model": hasattr(self, 'denoise_model') and self.denoise_model is not None,
                    "face_detector": self.face_detector is not None
                },
                "config": {
                    "quality_level": self.post_processing_config.quality_level.value,
                    "processing_mode": self.post_processing_config.processing_mode.value,
                    "enabled_methods": [method.value for method in self.post_processing_config.enabled_methods],
                    "enhancement_strength": self.enhancement_strength,
                    "preserve_faces": self.preserve_faces,
                    "enable_visualization": self.post_processing_config.enable_visualization,
                    "visualization_quality": self.post_processing_config.visualization_quality
                },
                "performance": self.processing_stats,
                "cache": {
                    "size": len(self.enhancement_cache),
                    "max_size": self.post_processing_config.cache_size,
                    "hit_rate": (self.processing_stats['cache_hits'] / 
                                max(1, self.processing_stats['total_processed'])) * 100
                },
                "optimization": {
                    "m3_max_enabled": self.is_m3_max,
                    "optimization_enabled": self.optimization_enabled,
                    "memory_gb": self.memory_gb,
                    "device_type": self.device_type,
                    "use_gpu_acceleration": self.post_processing_config.use_gpu_acceleration
                }
            }
        except Exception as e:
            self.logger.error(f"ë‹¨ê³„ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {
                "step_name": "post_processing",
                "step_number": 7,
                "error": str(e)
            }

    def get_statistics(self) -> Dict[str, Any]:
        """ì²˜ë¦¬ í†µê³„ ë°˜í™˜"""
        try:
            stats = self.processing_stats.copy()
            
            # ì„±ê³µë¥  ê³„ì‚°
            if stats['total_processed'] > 0:
                stats['success_rate'] = stats['successful_enhancements'] / stats['total_processed']
            else:
                stats['success_rate'] = 0.0
            
            # ìºì‹œ ì •ë³´
            stats['cache_info'] = {
                'size': len(self.enhancement_cache),
                'max_size': self.post_processing_config.cache_size,
                'hit_ratio': stats['cache_hits'] / max(stats['total_processed'], 1)
            }
            
            # ì‹œìŠ¤í…œ ì •ë³´
            stats['system_info'] = {
                'device': self.device,
                'is_m3_max': self.is_m3_max,
                'memory_gb': self.memory_gb,
                'enabled_methods': [method.value for method in self.post_processing_config.enabled_methods],
                'optimization_enabled': self.optimization_enabled,
                'models_loaded': {
                    'sr_model': hasattr(self, 'sr_model') and self.sr_model is not None,
                    'denoise_model': hasattr(self, 'denoise_model') and self.denoise_model is not None,
                    'face_detector': self.face_detector is not None
                }
            }
            
            return stats
            
        except Exception as e:
            self.logger.error(f"í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {'error': str(e)}

    async def cleanup(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        try:
            self.logger.info("ğŸ§¹ 7ë‹¨ê³„ í›„ì²˜ë¦¬ ì‹œìŠ¤í…œ ì •ë¦¬ ì‹œì‘...")
            
            # ìºì‹œ ì •ë¦¬
            self.enhancement_cache.clear()
            self.model_cache.clear()
            
            # ëª¨ë¸ ë©”ëª¨ë¦¬ í•´ì œ
            if hasattr(self, 'sr_model') and self.sr_model:
                if hasattr(self.sr_model, 'cpu'):
                    self.sr_model.cpu()
                del self.sr_model
                self.sr_model = None
            
            if hasattr(self, 'denoise_model') and self.denoise_model:
                if hasattr(self.denoise_model, 'cpu'):
                    self.denoise_model.cpu()
                del self.denoise_model
                self.denoise_model = None
            
            if hasattr(self, 'face_detector') and self.face_detector:
                del self.face_detector
                self.face_detector = None
            
            # ìŠ¤ë ˆë“œ í’€ ì¢…ë£Œ
            if hasattr(self, 'executor'):
                self.executor.shutdown(wait=True)
            
            # ë©”ëª¨ë¦¬ ì •ë¦¬
            if self.memory_manager:
                await self.memory_manager.cleanup_memory()
            
            # PyTorch ìºì‹œ ì •ë¦¬
            if self.device == 'mps':
                try:
                    torch.mps.empty_cache()
                except Exception:
                    pass
            elif self.device == 'cuda':
                try:
                    torch.cuda.empty_cache()
                except Exception:
                    pass
            
            # ê°€ë¹„ì§€ ì»¬ë ‰ì…˜
            gc.collect()
            
            self.is_initialized = False
            self.logger.info("âœ… 7ë‹¨ê³„ í›„ì²˜ë¦¬ ì‹œìŠ¤í…œ ì •ë¦¬ ì™„ë£Œ")
            
        except Exception as e:
            self.logger.error(f"ì •ë¦¬ ê³¼ì •ì—ì„œ ì˜¤ë¥˜ ë°œìƒ: {e}")

    def __del__(self):
        """ì†Œë©¸ì"""
        try:
            if hasattr(self, 'executor'):
                self.executor.shutdown(wait=False)
        except Exception:
            pass

# ==============================================
# 4. íŒ©í† ë¦¬ í•¨ìˆ˜ë“¤ ë° ìœ í‹¸ë¦¬í‹°
# ==============================================

def create_post_processing_step(
    device: Optional[str] = None,
    config: Optional[Dict[str, Any]] = None,
    **kwargs
) -> PostProcessingStep:
    """PostProcessingStep íŒ©í† ë¦¬ í•¨ìˆ˜"""
    try:
        return PostProcessingStep(device=device, config=config, **kwargs)
    except Exception as e:
        logger.error(f"PostProcessingStep ìƒì„± ì‹¤íŒ¨: {e}")
        raise

def create_m3_max_post_processing_step(**kwargs) -> PostProcessingStep:
    """M3 Max ìµœì í™”ëœ í›„ì²˜ë¦¬ ìŠ¤í… ìƒì„±"""
    m3_max_config = {
        'device': 'mps',
        'is_m3_max': True,
        'optimization_enabled': True,
        'memory_gb': 128,
        'quality_level': 'high',
        'processing_mode': 'quality',
        'enabled_methods': [
            'super_resolution',
            'noise_reduction',
            'sharpening',
            'color_correction',
            'contrast_enhancement',
            'face_enhancement'
        ],
        'enhancement_strength': 0.8,
        'preserve_faces': True,
        'cache_size': 100,
        'enable_visualization': True,
        'visualization_quality': 'high'
    }
    
    m3_max_config.update(kwargs)
    
    return PostProcessingStep(**m3_max_config)

def create_production_post_processing_step(
    quality_level: str = "balanced",
    processing_mode: str = "quality",
    **kwargs
) -> PostProcessingStep:
    """í”„ë¡œë•ì…˜ í™˜ê²½ìš© í›„ì²˜ë¦¬ ìŠ¤í… ìƒì„±"""
    production_config = {
        'quality_level': quality_level,
        'processing_mode': processing_mode,
        'optimization_enabled': True,
        'enabled_methods': [
            'noise_reduction',
            'sharpening',
            'color_correction',
            'contrast_enhancement'
        ],
        'enhancement_strength': 0.6,
        'preserve_faces': True,
        'auto_adjust_brightness': True,
        'cache_size': 50,
        'enable_visualization': True,
        'visualization_quality': 'medium'
    }
    
    production_config.update(kwargs)
    
    return PostProcessingStep(**production_config)

def create_real_time_post_processing_step(**kwargs) -> PostProcessingStep:
    """ì‹¤ì‹œê°„ ì²˜ë¦¬ìš© í›„ì²˜ë¦¬ ìŠ¤í… ìƒì„±"""
    real_time_config = {
        'processing_mode': 'real_time',
        'quality_level': 'fast',
        'enabled_methods': [
            'sharpening',
            'color_correction'
        ],
        'enhancement_strength': 0.4,
        'preserve_faces': False,
        'cache_size': 25,
        'enable_visualization': False
    }
    
    real_time_config.update(kwargs)
    
    return PostProcessingStep(**real_time_config)

# ==============================================
# 5. ë…ë¦½ ì‹¤í–‰í˜• ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
# ==============================================

def enhance_image_quality(
    image: np.ndarray,
    methods: List[str] = None,
    strength: float = 0.7,
    device: str = "auto"
) -> np.ndarray:
    """ë…ë¦½ ì‹¤í–‰í˜• ì´ë¯¸ì§€ í’ˆì§ˆ í–¥ìƒ í•¨ìˆ˜"""
    try:
        if methods is None:
            methods = ['sharpening', 'color_correction', 'contrast_enhancement']
        
        step = create_post_processing_step(
            device=device,
            enabled_methods=methods,
            enhancement_strength=strength
        )
        
        # ë™ê¸°ì  ì²˜ë¦¬ë¥¼ ìœ„í•œ ë˜í¼
        import asyncio
        
        async def process_async():
            await step.initialize()
            
            fitting_result = {'fitted_image': image}
            result = await step.process(fitting_result)
            
            await step.cleanup()
            
            return result['enhanced_image'] if result['success'] else image
        
        # ì´ë²¤íŠ¸ ë£¨í”„ ì‹¤í–‰
        try:
            loop = asyncio.get_event_loop()
            return loop.run_until_complete(process_async())
        except RuntimeError:
            # ìƒˆ ì´ë²¤íŠ¸ ë£¨í”„ ìƒì„±
            return asyncio.run(process_async())
            
    except Exception as e:
        logger.error(f"ì´ë¯¸ì§€ í’ˆì§ˆ í–¥ìƒ ì‹¤íŒ¨: {e}")
        return image

def batch_enhance_images(
    images: List[np.ndarray],
    methods: List[str] = None,
    strength: float = 0.7,
    device: str = "auto",
    max_workers: int = 4
) -> List[np.ndarray]:
    """ë°°ì¹˜ ì´ë¯¸ì§€ í’ˆì§ˆ í–¥ìƒ"""
    try:
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            futures = []
            
            for image in images:
                future = executor.submit(
                    enhance_image_quality,
                    image, methods, strength, device
                )
                futures.append(future)
            
            # ê²°ê³¼ ìˆ˜ì§‘
            enhanced_images = []
            for future in as_completed(futures):
                try:
                    enhanced_image = future.result()
                    enhanced_images.append(enhanced_image)
                except Exception as e:
                    logger.error(f"ë°°ì¹˜ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
                    enhanced_images.append(None)
            
            return enhanced_images
            
    except Exception as e:
        logger.error(f"ë°°ì¹˜ ì´ë¯¸ì§€ í–¥ìƒ ì‹¤íŒ¨: {e}")
        return images

# ==============================================
# 6. ëª¨ë“ˆ ìµìŠ¤í¬íŠ¸
# ==============================================

__all__ = [
    # ë©”ì¸ í´ë˜ìŠ¤
    'PostProcessingStep',
    
    # ì—´ê±°í˜• ë° ë°ì´í„° í´ë˜ìŠ¤
    'EnhancementMethod',
    'QualityLevel',
    'ProcessingMode',
    'PostProcessingConfig',
    'PostProcessingResult',
    
    # AI ëª¨ë¸ í´ë˜ìŠ¤ë“¤
    'SRResNet',
    'DenoiseNet',
    
    # íŒ©í† ë¦¬ í•¨ìˆ˜ë“¤
    'create_post_processing_step',
    'create_m3_max_post_processing_step',
    'create_production_post_processing_step',
    'create_real_time_post_processing_step',
    
    # ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
    'enhance_image_quality',
    'batch_enhance_images',
    
    # ê°€ìš©ì„± í”Œë˜ê·¸ë“¤
    'SCIPY_AVAILABLE',
    'SKIMAGE_AVAILABLE', 
    'SKLEARN_AVAILABLE',
    'CUPY_AVAILABLE',
    'PSUTIL_AVAILABLE'
]

# ëª¨ë“ˆ ì´ˆê¸°í™” ë¡œê¹…
logger.info("âœ… Step 07 í›„ì²˜ë¦¬ ëª¨ë“ˆ ë¡œë“œ ì™„ë£Œ - ì™„ì „ ìˆ˜ì • ë²„ì „")
logger.info(f"   - BaseStepMixin ì—°ë™: {'âœ…' if BASE_STEP_MIXIN_AVAILABLE else 'âŒ'}")
logger.info(f"   - Model Loader ì—°ë™: {'âœ…' if MODEL_LOADER_AVAILABLE else 'âŒ'}")
logger.info(f"   - Step ìš”ì²­ì‚¬í•­ ì—°ë™: {'âœ…' if STEP_REQUESTS_AVAILABLE else 'âŒ'}")
logger.info(f"   - PyTorch ì‚¬ìš© ê°€ëŠ¥: {'âœ…' if torch.cuda.is_available() or torch.backends.mps.is_available() else 'âŒ'}")
logger.info(f"   - OpenCV ì‚¬ìš© ê°€ëŠ¥: {'âœ…' if cv2 else 'âŒ'}")
logger.info(f"   - scikit-image ì‚¬ìš© ê°€ëŠ¥: {'âœ…' if SKIMAGE_AVAILABLE else 'âŒ'}")
logger.info(f"   - SciPy ì‚¬ìš© ê°€ëŠ¥: {'âœ…' if SCIPY_AVAILABLE else 'âŒ'}")
logger.info(f"   - psutil ì‚¬ìš© ê°€ëŠ¥: {'âœ…' if PSUTIL_AVAILABLE else 'âŒ'}")

# ìë™ ì •ë¦¬ ë“±ë¡
import atexit

def _cleanup_on_exit():
    """í”„ë¡œê·¸ë¨ ì¢…ë£Œ ì‹œ ì •ë¦¬"""
    try:
        # ì „ì—­ ì¸ìŠ¤í„´ìŠ¤ë“¤ ì •ë¦¬
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
        elif torch.backends.mps.is_available():
            try:
                torch.mps.empty_cache()
            except Exception:
                pass
        gc.collect()
    except Exception:
        pass

atexit.register(_cleanup_on_exit)