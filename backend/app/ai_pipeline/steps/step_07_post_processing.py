"""
7ë‹¨ê³„: í›„ì²˜ë¦¬ (Post Processing) - í’ˆì§ˆ í–¥ìƒ
Super Resolution, ë…¸ì´ì¦ˆ ì œê±°, ìƒ‰ìƒ ë³´ì •ì„ í†µí•œ ìµœì¢… í’ˆì§ˆ í–¥ìƒ
"""
import os
import logging
import time
from typing import Dict, Any, Optional, Tuple
import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
import cv2
from PIL import Image, ImageEnhance, ImageFilter

logger = logging.getLogger(__name__)

class PostProcessingStep:
    """í›„ì²˜ë¦¬ ìŠ¤í… - í’ˆì§ˆ í–¥ìƒ ë° ìµœì¢… ë³´ì •"""
    
    def __init__(self, model_loader, device: str, config: Dict[str, Any] = None):
        """
        Args:
            model_loader: ëª¨ë¸ ë¡œë” ì¸ìŠ¤í„´ìŠ¤
            device: ì‚¬ìš©í•  ë””ë°”ì´ìŠ¤
            config: ì„¤ì • ë”•ì…”ë„ˆë¦¬
        """
        self.model_loader = model_loader
        self.device = device
        self.config = config or {}
        
        # ê¸°ë³¸ ì„¤ì •
        self.enable_super_resolution = self.config.get('enable_super_resolution', True)
        self.enable_denoising = self.config.get('enable_denoising', True)
        self.enable_color_correction = self.config.get('enable_color_correction', True)
        self.enable_sharpening = self.config.get('enable_sharpening', True)
        self.scale_factor = self.config.get('scale_factor', 2)  # SR ìŠ¤ì¼€ì¼
        
        # ëª¨ë¸ ê´€ë ¨
        self.sr_model = None
        self.denoising_model = None
        self.is_initialized = False
        
        logger.info(f"ğŸ¯ í›„ì²˜ë¦¬ ìŠ¤í… ì´ˆê¸°í™” - ë””ë°”ì´ìŠ¤: {device}")
    
    async def initialize(self) -> bool:
        """í›„ì²˜ë¦¬ ëª¨ë¸ ì´ˆê¸°í™”"""
        try:
            logger.info("ğŸ”„ í›„ì²˜ë¦¬ ëª¨ë¸ ë¡œë“œ ì¤‘...")
            
            # Super Resolution ëª¨ë¸ ì´ˆê¸°í™”
            if self.enable_super_resolution:
                await self._initialize_sr_model()
            
            # ë…¸ì´ì¦ˆ ì œê±° ëª¨ë¸ ì´ˆê¸°í™”
            if self.enable_denoising:
                await self._initialize_denoising_model()
            
            self.is_initialized = True
            logger.info("âœ… í›„ì²˜ë¦¬ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ í›„ì²˜ë¦¬ ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.is_initialized = False
            return False
    
    async def _initialize_sr_model(self):
        """Super Resolution ëª¨ë¸ ì´ˆê¸°í™”"""
        try:
            # ESRGAN ë˜ëŠ” Real-ESRGAN ìŠ¤íƒ€ì¼ ëª¨ë¸
            self.sr_model = self._create_sr_model()
            
            # ì‚¬ì „ í›ˆë ¨ëœ ê°€ì¤‘ì¹˜ ë¡œë“œ
            model_path = self._get_sr_model_path()
            if os.path.exists(model_path):
                checkpoint = torch.load(model_path, map_location=self.device)
                self.sr_model.load_state_dict(checkpoint['model_state_dict'])
                logger.info(f"âœ… Super Resolution ê°€ì¤‘ì¹˜ ë¡œë“œ: {model_path}")
            else:
                logger.warning(f"âš ï¸ SR ê°€ì¤‘ì¹˜ íŒŒì¼ ì—†ìŒ: {model_path} - ë°ëª¨ ëª¨ë“œë¡œ ì‹¤í–‰")
            
            # ëª¨ë¸ ìµœì í™”
            self.sr_model = self.model_loader.optimize_model(self.sr_model, 'post_processing')
            self.sr_model.eval()
            
        except Exception as e:
            logger.warning(f"SR ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.sr_model = None
    
    async def _initialize_denoising_model(self):
        """ë…¸ì´ì¦ˆ ì œê±° ëª¨ë¸ ì´ˆê¸°í™”"""
        try:
            # DnCNN ìŠ¤íƒ€ì¼ ë…¸ì´ì¦ˆ ì œê±° ëª¨ë¸
            self.denoising_model = self._create_denoising_model()
            
            # ê°€ì¤‘ì¹˜ ë¡œë“œ
            model_path = self._get_denoising_model_path()
            if os.path.exists(model_path):
                checkpoint = torch.load(model_path, map_location=self.device)
                self.denoising_model.load_state_dict(checkpoint['model_state_dict'])
                logger.info(f"âœ… ë…¸ì´ì¦ˆ ì œê±° ê°€ì¤‘ì¹˜ ë¡œë“œ: {model_path}")
            else:
                logger.warning(f"âš ï¸ ë…¸ì´ì¦ˆ ì œê±° ê°€ì¤‘ì¹˜ íŒŒì¼ ì—†ìŒ: {model_path}")
            
            # ëª¨ë¸ ìµœì í™”
            self.denoising_model = self.model_loader.optimize_model(self.denoising_model, 'post_processing')
            self.denoising_model.eval()
            
        except Exception as e:
            logger.warning(f"ë…¸ì´ì¦ˆ ì œê±° ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.denoising_model = None
    
    def _create_sr_model(self):
        """Super Resolution ëª¨ë¸ ìƒì„± (ESRGAN ìŠ¤íƒ€ì¼)"""
        class RRDB(nn.Module):
            """Residual in Residual Dense Block"""
            
            def __init__(self, nf, gc=32):
                super(RRDB, self).__init__()
                self.RDB1 = ResidualDenseBlock(nf, gc)
                self.RDB2 = ResidualDenseBlock(nf, gc)
                self.RDB3 = ResidualDenseBlock(nf, gc)
                
            def forward(self, x):
                out = self.RDB1(x)
                out = self.RDB2(out)
                out = self.RDB3(out)
                return out * 0.2 + x
        
        class ResidualDenseBlock(nn.Module):
            def __init__(self, nf=64, gc=32):
                super(ResidualDenseBlock, self).__init__()
                # Dense layers
                self.conv1 = nn.Conv2d(nf, gc, 3, 1, 1, bias=True)
                self.conv2 = nn.Conv2d(nf + gc, gc, 3, 1, 1, bias=True)
                self.conv3 = nn.Conv2d(nf + 2 * gc, gc, 3, 1, 1, bias=True)
                self.conv4 = nn.Conv2d(nf + 3 * gc, gc, 3, 1, 1, bias=True)
                self.conv5 = nn.Conv2d(nf + 4 * gc, nf, 3, 1, 1, bias=True)
                self.lrelu = nn.LeakyReLU(negative_slope=0.2, inplace=True)
                
            def forward(self, x):
                x1 = self.lrelu(self.conv1(x))
                x2 = self.lrelu(self.conv2(torch.cat((x, x1), 1)))
                x3 = self.lrelu(self.conv3(torch.cat((x, x1, x2), 1)))
                x4 = self.lrelu(self.conv4(torch.cat((x, x1, x2, x3), 1)))
                x5 = self.conv5(torch.cat((x, x1, x2, x3, x4), 1))
                return x5 * 0.2 + x
        
        class RRDBNet(nn.Module):
            def __init__(self, in_nc=3, out_nc=3, nf=64, nb=23, scale=2):
                super(RRDBNet, self).__init__()
                
                self.conv_first = nn.Conv2d(in_nc, nf, 3, 1, 1, bias=True)
                self.RRDB_trunk = nn.Sequential(*[RRDB(nf) for _ in range(nb)])
                self.trunk_conv = nn.Conv2d(nf, nf, 3, 1, 1, bias=True)
                
                # Upsampling
                if scale == 4:
                    self.upconv1 = nn.Conv2d(nf, nf, 3, 1, 1, bias=True)
                    self.upconv2 = nn.Conv2d(nf, nf, 3, 1, 1, bias=True)
                elif scale == 2:
                    self.upconv1 = nn.Conv2d(nf, nf, 3, 1, 1, bias=True)
                
                self.HRconv = nn.Conv2d(nf, nf, 3, 1, 1, bias=True)
                self.conv_last = nn.Conv2d(nf, out_nc, 3, 1, 1, bias=True)
                
                self.lrelu = nn.LeakyReLU(negative_slope=0.2, inplace=True)
                self.scale = scale
                
            def forward(self, x):
                fea = self.conv_first(x)
                trunk = self.trunk_conv(self.RRDB_trunk(fea))
                fea = fea + trunk
                
                # Upsampling
                fea = self.lrelu(self.upconv1(F.interpolate(fea, scale_factor=2, mode='nearest')))
                if self.scale == 4:
                    fea = self.lrelu(self.upconv2(F.interpolate(fea, scale_factor=2, mode='nearest')))
                
                out = self.conv_last(self.lrelu(self.HRconv(fea)))
                return out
        
        return RRDBNet(scale=self.scale_factor).to(self.device)
    
    def _create_denoising_model(self):
        """ë…¸ì´ì¦ˆ ì œê±° ëª¨ë¸ ìƒì„± (DnCNN ìŠ¤íƒ€ì¼)"""
        class DnCNN(nn.Module):
            def __init__(self, channels=3, num_of_layers=17):
                super(DnCNN, self).__init__()
                kernel_size = 3
                padding = 1
                features = 64
                
                layers = []
                layers.append(nn.Conv2d(in_channels=channels, out_channels=features, 
                                      kernel_size=kernel_size, padding=padding, bias=False))
                layers.append(nn.ReLU(inplace=True))
                
                for _ in range(num_of_layers - 2):
                    layers.append(nn.Conv2d(in_channels=features, out_channels=features, 
                                          kernel_size=kernel_size, padding=padding, bias=False))
                    layers.append(nn.BatchNorm2d(features))
                    layers.append(nn.ReLU(inplace=True))
                
                layers.append(nn.Conv2d(in_channels=features, out_channels=channels, 
                                      kernel_size=kernel_size, padding=padding, bias=False))
                
                self.dncnn = nn.Sequential(*layers)
                
            def forward(self, x):
                noise = self.dncnn(x)
                return x - noise  # ì”ì°¨ í•™ìŠµ
        
        return DnCNN().to(self.device)
    
    def _get_sr_model_path(self) -> str:
        """SR ëª¨ë¸ íŒŒì¼ ê²½ë¡œ"""
        model_dir = self.config.get('model_dir', 'app/models/ai_models/sr')
        model_file = self.config.get('sr_model_file', 'esrgan_x2.pth')
        return os.path.join(model_dir, model_file)
    
    def _get_denoising_model_path(self) -> str:
        """ë…¸ì´ì¦ˆ ì œê±° ëª¨ë¸ íŒŒì¼ ê²½ë¡œ"""
        model_dir = self.config.get('model_dir', 'app/models/ai_models/denoising')
        model_file = self.config.get('denoising_model_file', 'dncnn.pth')
        return os.path.join(model_dir, model_file)
    
    def process(self, fitted_image_tensor: torch.Tensor) -> Dict[str, Any]:
        """
        í›„ì²˜ë¦¬ ì‹¤í–‰
        
        Args:
            fitted_image_tensor: 6ë‹¨ê³„ ê°€ìƒ í”¼íŒ… ê²°ê³¼ ì´ë¯¸ì§€ í…ì„œ
            
        Returns:
            ì²˜ë¦¬ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        if not self.is_initialized:
            raise RuntimeError("í›„ì²˜ë¦¬ ëª¨ë“ˆì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        start_time = time.time()
        
        try:
            current_image = fitted_image_tensor.clone()
            processing_steps = []
            
            # 1. ë…¸ì´ì¦ˆ ì œê±°
            if self.enable_denoising:
                denoised_image, denoise_info = self._apply_denoising(current_image)
                current_image = denoised_image
                processing_steps.append(denoise_info)
            
            # 2. Super Resolution
            if self.enable_super_resolution:
                sr_image, sr_info = self._apply_super_resolution(current_image)
                current_image = sr_image
                processing_steps.append(sr_info)
            
            # 3. ìƒ‰ìƒ ë³´ì •
            if self.enable_color_correction:
                color_corrected, color_info = self._apply_color_correction(current_image)
                current_image = color_corrected
                processing_steps.append(color_info)
            
            # 4. ìƒ¤í”„ë‹
            if self.enable_sharpening:
                sharpened_image, sharp_info = self._apply_sharpening(current_image)
                current_image = sharpened_image
                processing_steps.append(sharp_info)
            
            # 5. ìµœì¢… í’ˆì§ˆ ê²€ì¦
            quality_metrics = self._evaluate_enhancement_quality(fitted_image_tensor, current_image)
            
            # 6. í›„ì²˜ë¦¬ í†µê³„
            enhancement_stats = self._calculate_enhancement_stats(fitted_image_tensor, current_image)
            
            processing_time = time.time() - start_time
            
            result = {
                "enhanced_image": current_image,
                "enhancement_score": float(quality_metrics.get('overall_score', 0.8)),
                "quality_metrics": quality_metrics,
                "enhancement_stats": enhancement_stats,
                "processing_steps": processing_steps,
                "processing_time": processing_time,
                "improvements_applied": len(processing_steps)
            }
            
            logger.info(f"âœ… í›„ì²˜ë¦¬ ì™„ë£Œ - ì²˜ë¦¬ì‹œê°„: {processing_time:.3f}ì´ˆ, ê°œì„ ì ìˆ˜: {quality_metrics.get('overall_score', 0):.2f}")
            
            return result
            
        except Exception as e:
            logger.error(f"âŒ í›„ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            raise
    
    def _apply_denoising(self, image_tensor: torch.Tensor) -> Tuple[torch.Tensor, Dict[str, Any]]:
        """ë…¸ì´ì¦ˆ ì œê±° ì ìš©"""
        step_start = time.time()
        
        try:
            if self.denoising_model is not None:
                # ë”¥ëŸ¬ë‹ ê¸°ë°˜ ë…¸ì´ì¦ˆ ì œê±°
                with torch.no_grad():
                    denoised = self.denoising_model(image_tensor)
                    denoised = torch.clamp(denoised, 0, 1)
                
                # ë…¸ì´ì¦ˆ ì œê±° íš¨ê³¼ ì¸¡ì •
                noise_reduction = self._measure_noise_reduction(image_tensor, denoised)
                method = "DnCNN"
                
            else:
                # ì „í†µì ì¸ ë°©ë²• (ê°€ìš°ì‹œì•ˆ ë¸”ëŸ¬)
                denoised = self._apply_gaussian_denoising(image_tensor)
                noise_reduction = 0.3  # ì¶”ì •ê°’
                method = "Gaussian"
            
            processing_time = time.time() - step_start
            
            info = {
                "step": "denoising",
                "method": method,
                "noise_reduction": noise_reduction,
                "processing_time": processing_time,
                "applied": True
            }
            
            return denoised, info
            
        except Exception as e:
            logger.warning(f"ë…¸ì´ì¦ˆ ì œê±° ì‹¤íŒ¨: {e}")
            info = {"step": "denoising", "applied": False, "error": str(e)}
            return image_tensor, info
    
    def _apply_gaussian_denoising(self, image_tensor: torch.Tensor) -> torch.Tensor:
        """ê°€ìš°ì‹œì•ˆ ë¸”ëŸ¬ë¥¼ ì´ìš©í•œ ë…¸ì´ì¦ˆ ì œê±°"""
        try:
            kernel_size = 3
            sigma = 0.5
            
            # ê°€ìš°ì‹œì•ˆ ì»¤ë„ ìƒì„±
            kernel_1d = torch.tensor([
                np.exp(-(x - kernel_size//2)**2 / (2 * sigma**2)) 
                for x in range(kernel_size)
            ]).float().to(self.device)
            kernel_1d = kernel_1d / kernel_1d.sum()
            
            # 2D ì»¤ë„
            kernel_2d = kernel_1d.unsqueeze(0) * kernel_1d.unsqueeze(1)
            kernel_2d = kernel_2d.unsqueeze(0).unsqueeze(0)
            
            # ì±„ë„ë³„ ì»¨ë³¼ë£¨ì…˜
            denoised_channels = []
            for i in range(image_tensor.shape[1]):
                channel = image_tensor[:, i:i+1, :, :]
                denoised_channel = F.conv2d(channel, kernel_2d, padding=kernel_size//2)
                denoised_channels.append(denoised_channel)
            
            denoised = torch.cat(denoised_channels, dim=1)
            
            return denoised
            
        except Exception as e:
            logger.warning(f"ê°€ìš°ì‹œì•ˆ ë…¸ì´ì¦ˆ ì œê±° ì‹¤íŒ¨: {e}")
            return image_tensor
    
    def _apply_super_resolution(self, image_tensor: torch.Tensor) -> Tuple[torch.Tensor, Dict[str, Any]]:
        """Super Resolution ì ìš©"""
        step_start = time.time()
        
        try:
            if self.sr_model is not None and self.scale_factor > 1:
                # ë”¥ëŸ¬ë‹ ê¸°ë°˜ Super Resolution
                with torch.no_grad():
                    # ì…ë ¥ í¬ê¸° ì œí•œ (ë©”ëª¨ë¦¬ ì ˆì•½)
                    h, w = image_tensor.shape[2], image_tensor.shape[3]
                    max_size = 512
                    
                    if max(h, w) > max_size:
                        # íƒ€ì¼ ê¸°ë°˜ ì²˜ë¦¬
                        sr_image = self._apply_tiled_sr(image_tensor, max_size)
                    else:
                        sr_image = self.sr_model(image_tensor)
                    
                    sr_image = torch.clamp(sr_image, 0, 1)
                
                # í’ˆì§ˆ í–¥ìƒ ì¸¡ì •
                quality_improvement = self._measure_sr_quality(image_tensor, sr_image)
                method = "ESRGAN"
                
            else:
                # ë°”ì´íë¹… ì—…ìŠ¤ì¼€ì¼ë§
                scale = self.scale_factor if self.scale_factor > 1 else 1
                sr_image = F.interpolate(
                    image_tensor, 
                    scale_factor=scale, 
                    mode='bicubic', 
                    align_corners=False
                )
                quality_improvement = 0.2  # ì¶”ì •ê°’
                method = "Bicubic"
            
            processing_time = time.time() - step_start
            
            info = {
                "step": "super_resolution",
                "method": method,
                "scale_factor": self.scale_factor,
                "quality_improvement": quality_improvement,
                "processing_time": processing_time,
                "applied": True
            }
            
            return sr_image, info
            
        except Exception as e:
            logger.warning(f"Super Resolution ì‹¤íŒ¨: {e}")
            info = {"step": "super_resolution", "applied": False, "error": str(e)}
            return image_tensor, info
    
    def _apply_tiled_sr(self, image_tensor: torch.Tensor, tile_size: int) -> torch.Tensor:
        """íƒ€ì¼ ê¸°ë°˜ Super Resolution"""
        try:
            b, c, h, w = image_tensor.shape
            scale = self.scale_factor
            
            # ì¶œë ¥ í¬ê¸°
            output_h, output_w = h * scale, w * scale
            sr_image = torch.zeros(b, c, output_h, output_w, device=self.device)
            
            # íƒ€ì¼ ë‹¨ìœ„ë¡œ ì²˜ë¦¬
            for y in range(0, h, tile_size):
                for x in range(0, w, tile_size):
                    # íƒ€ì¼ ì˜ì—­
                    y_end = min(y + tile_size, h)
                    x_end = min(x + tile_size, w)
                    
                    tile = image_tensor[:, :, y:y_end, x:x_end]
                    
                    # SR ì ìš©
                    sr_tile = self.sr_model(tile)
                    
                    # ì¶œë ¥ ìœ„ì¹˜
                    sr_y = y * scale
                    sr_x = x * scale
                    sr_y_end = sr_y + sr_tile.shape[2]
                    sr_x_end = sr_x + sr_tile.shape[3]
                    
                    sr_image[:, :, sr_y:sr_y_end, sr_x:sr_x_end] = sr_tile
            
            return sr_image
            
        except Exception as e:
            logger.warning(f"íƒ€ì¼ ê¸°ë°˜ SR ì‹¤íŒ¨: {e}")
            return F.interpolate(image_tensor, scale_factor=self.scale_factor, mode='bicubic')
    
    def _apply_color_correction(self, image_tensor: torch.Tensor) -> Tuple[torch.Tensor, Dict[str, Any]]:
        """ìƒ‰ìƒ ë³´ì • ì ìš©"""
        step_start = time.time()
        
        try:
            # PIL ì´ë¯¸ì§€ë¡œ ë³€í™˜
            pil_image = self._tensor_to_pil(image_tensor)
            
            # ìƒ‰ìƒ ë³´ì • ì ìš©
            enhanced_image = pil_image
            corrections = []
            
            # 1. ëŒ€ë¹„ ê°œì„ 
            enhancer = ImageEnhance.Contrast(enhanced_image)
            enhanced_image = enhancer.enhance(1.1)  # 10% ëŒ€ë¹„ ì¦ê°€
            corrections.append("contrast")
            
            # 2. ì±„ë„ ì¡°ì •
            enhancer = ImageEnhance.Color(enhanced_image)
            enhanced_image = enhancer.enhance(1.05)  # 5% ì±„ë„ ì¦ê°€
            corrections.append("saturation")
            
            # 3. ë°ê¸° ì¡°ì • (í•„ìš”í•œ ê²½ìš°)
            brightness_factor = self._calculate_brightness_factor(pil_image)
            if abs(brightness_factor - 1.0) > 0.05:
                enhancer = ImageEnhance.Brightness(enhanced_image)
                enhanced_image = enhancer.enhance(brightness_factor)
                corrections.append("brightness")
            
            # 4. ê°ë§ˆ ë³´ì •
            gamma_corrected = self._apply_gamma_correction(enhanced_image, 1.1)
            enhanced_image = gamma_corrected
            corrections.append("gamma")
            
            # í…ì„œë¡œ ë‹¤ì‹œ ë³€í™˜
            corrected_tensor = self._pil_to_tensor(enhanced_image)
            
            processing_time = time.time() - step_start
            
            info = {
                "step": "color_correction",
                "corrections_applied": corrections,
                "brightness_factor": brightness_factor,
                "processing_time": processing_time,
                "applied": True
            }
            
            return corrected_tensor, info
            
        except Exception as e:
            logger.warning(f"ìƒ‰ìƒ ë³´ì • ì‹¤íŒ¨: {e}")
            info = {"step": "color_correction", "applied": False, "error": str(e)}
            return image_tensor, info
    
    def _apply_sharpening(self, image_tensor: torch.Tensor) -> Tuple[torch.Tensor, Dict[str, Any]]:
        """ìƒ¤í”„ë‹ ì ìš©"""
        step_start = time.time()
        
        try:
            # PIL ì´ë¯¸ì§€ë¡œ ë³€í™˜
            pil_image = self._tensor_to_pil(image_tensor)
            
            # ì–¸ìƒµ ë§ˆìŠ¤í¬ í•„í„° ì ìš©
            sharpened = pil_image.filter(ImageFilter.UnsharpMask(radius=1, percent=120, threshold=2))
            
            # í…ì„œë¡œ ë³€í™˜
            sharpened_tensor = self._pil_to_tensor(sharpened)
            
            # ìƒ¤í”„ë‹ ê°•ë„ ì¸¡ì •
            sharpness_improvement = self._measure_sharpness(image_tensor, sharpened_tensor)
            
            processing_time = time.time() - step_start
            
            info = {
                "step": "sharpening",
                "method": "UnsharpMask",
                "sharpness_improvement": sharpness_improvement,
                "processing_time": processing_time,
                "applied": True
            }
            
            return sharpened_tensor, info
            
        except Exception as e:
            logger.warning(f"ìƒ¤í”„ë‹ ì‹¤íŒ¨: {e}")
            info = {"step": "sharpening", "applied": False, "error": str(e)}
            return image_tensor, info
    
    def _tensor_to_pil(self, tensor: torch.Tensor) -> Image.Image:
        """í…ì„œë¥¼ PIL ì´ë¯¸ì§€ë¡œ ë³€í™˜"""
        if tensor.dim() == 4:
            tensor = tensor.squeeze(0)
        
        if tensor.shape[0] == 3:
            tensor = tensor.permute(1, 2, 0)
        
        # 0-1 ë²”ìœ„ë¡œ í´ë¨í•‘
        tensor = torch.clamp(tensor, 0, 1)
        
        # NumPy ë°°ì—´ë¡œ ë³€í™˜
        array = (tensor.cpu().numpy() * 255).astype(np.uint8)
        
        return Image.fromarray(array)
    
    def _pil_to_tensor(self, pil_image: Image.Image) -> torch.Tensor:
        """PIL ì´ë¯¸ì§€ë¥¼ í…ì„œë¡œ ë³€í™˜"""
        array = np.array(pil_image) / 255.0
        tensor = torch.from_numpy(array).float().permute(2, 0, 1).unsqueeze(0)
        return tensor.to(self.device)
    
    def _calculate_brightness_factor(self, image: Image.Image) -> float:
        """ì ì ˆí•œ ë°ê¸° íŒ©í„° ê³„ì‚°"""
        try:
            # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ë¡œ ë³€í™˜í•˜ì—¬ í‰ê·  ë°ê¸° ê³„ì‚°
            gray = image.convert('L')
            histogram = gray.histogram()
            
            # í‰ê·  ë°ê¸° ê³„ì‚°
            total_pixels = sum(histogram)
            brightness_sum = sum(i * count for i, count in enumerate(histogram))
            average_brightness = brightness_sum / total_pixels
            
            # ì ì • ë°ê¸° (128)ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì¡°ì • íŒ©í„° ê³„ì‚°
            target_brightness = 128
            factor = target_brightness / average_brightness
            
            # ê·¹ë‹¨ì ì¸ ì¡°ì • ë°©ì§€
            return max(0.8, min(1.3, factor))
            
        except Exception as e:
            logger.warning(f"ë°ê¸° íŒ©í„° ê³„ì‚° ì‹¤íŒ¨: {e}")
            return 1.0
    
    def _apply_gamma_correction(self, image: Image.Image, gamma: float) -> Image.Image:
        """ê°ë§ˆ ë³´ì • ì ìš©"""
        try:
            # ê°ë§ˆ í…Œì´ë¸” ìƒì„±
            gamma_table = [int(((i / 255.0) ** (1.0 / gamma)) * 255) for i in range(256)]
            
            # ê° ì±„ë„ì— ê°ë§ˆ ë³´ì • ì ìš©
            if image.mode == 'RGB':
                r, g, b = image.split()
                r = r.point(gamma_table)
                g = g.point(gamma_table)
                b = b.point(gamma_table)
                return Image.merge('RGB', (r, g, b))
            else:
                return image.point(gamma_table)
                
        except Exception as e:
            logger.warning(f"ê°ë§ˆ ë³´ì • ì‹¤íŒ¨: {e}")
            return image
    
    def _measure_noise_reduction(self, original: torch.Tensor, denoised: torch.Tensor) -> float:
        """ë…¸ì´ì¦ˆ ì œê±° íš¨ê³¼ ì¸¡ì •"""
        try:
            # ë…¸ì´ì¦ˆ ì¶”ì • (ë¼í”Œë¼ì‹œì•ˆ ë¶„ì‚°)
            laplacian = torch.tensor([[0, -1, 0], [-1, 4, -1], [0, -1, 0]], dtype=torch.float32).unsqueeze(0).unsqueeze(0).to(self.device)
            
            original_gray = 0.299 * original[:, 0] + 0.587 * original[:, 1] + 0.114 * original[:, 2]
            denoised_gray = 0.299 * denoised[:, 0] + 0.587 * denoised[:, 1] + 0.114 * denoised[:, 2]
            
            original_noise = F.conv2d(original_gray.unsqueeze(1), laplacian, padding=1)
            denoised_noise = F.conv2d(denoised_gray.unsqueeze(1), laplacian, padding=1)
            
            original_variance = torch.var(original_noise)
            denoised_variance = torch.var(denoised_noise)
            
            if original_variance > 0:
                reduction = 1.0 - (denoised_variance / original_variance).item()
                return max(0.0, min(1.0, reduction))
            else:
                return 0.0
                
        except Exception as e:
            logger.warning(f"ë…¸ì´ì¦ˆ ì œê±° ì¸¡ì • ì‹¤íŒ¨: {e}")
            return 0.3
    
    def _measure_sr_quality(self, original: torch.Tensor, sr_image: torch.Tensor) -> float:
        """Super Resolution í’ˆì§ˆ ì¸¡ì •"""
        try:
            # ì›ë³¸ì„ SR í¬ê¸°ë¡œ ì—…ìŠ¤ì¼€ì¼
            upscaled_original = F.interpolate(original, size=sr_image.shape[2:], mode='bicubic', align_corners=False)
            
            # PSNR ê³„ì‚°
            mse = torch.mean((sr_image - upscaled_original) ** 2)
            if mse > 0:
                psnr = 20 * torch.log10(1.0 / torch.sqrt(mse))
                # PSNRì„ 0-1 ë²”ìœ„ë¡œ ì •ê·œí™” (30dB ì´ìƒì„ 1.0ìœ¼ë¡œ)
                quality = min(1.0, max(0.0, (psnr.item() - 20) / 10))
            else:
                quality = 1.0
            
            return quality
            
        except Exception as e:
            logger.warning(f"SR í’ˆì§ˆ ì¸¡ì • ì‹¤íŒ¨: {e}")
            return 0.5
    
    def _measure_sharpness(self, original: torch.Tensor, sharpened: torch.Tensor) -> float:
        """ìƒ¤í”„ë‹ íš¨ê³¼ ì¸¡ì •"""
        try:
            # ë¼í”Œë¼ì‹œì•ˆ ë¶„ì‚°ìœ¼ë¡œ ìƒ¤í”„ë‹ˆìŠ¤ ì¸¡ì •
            laplacian = torch.tensor([[0, -1, 0], [-1, 4, -1], [0, -1, 0]], dtype=torch.float32).unsqueeze(0).unsqueeze(0).to(self.device)
            
            original_gray = 0.299 * original[:, 0] + 0.587 * original[:, 1] + 0.114 * original[:, 2]
            sharpened_gray = 0.299 * sharpened[:, 0] + 0.587 * sharpened[:, 1] + 0.114 * sharpened[:, 2]
            
            original_edges = F.conv2d(original_gray.unsqueeze(1), laplacian, padding=1)
            sharpened_edges = F.conv2d(sharpened_gray.unsqueeze(1), laplacian, padding=1)
            
            original_sharpness = torch.var(original_edges)
            sharpened_sharpness = torch.var(sharpened_edges)
            
            if original_sharpness > 0:
                improvement = (sharpened_sharpness / original_sharpness).item() - 1.0
                return max(0.0, min(1.0, improvement))
            else:
                return 0.0
                
        except Exception as e:
            logger.warning(f"ìƒ¤í”„ë‹ˆìŠ¤ ì¸¡ì • ì‹¤íŒ¨: {e}")
            return 0.2
    
    def _evaluate_enhancement_quality(self, original: torch.Tensor, enhanced: torch.Tensor) -> Dict[str, float]:
        """í’ˆì§ˆ í–¥ìƒ í‰ê°€"""
        metrics = {}
        
        try:
            # êµ¬ì¡°ì  ìœ ì‚¬ë„
            metrics['structural_similarity'] = self._calculate_ssim(original, enhanced)
            
            # ìƒ‰ìƒ ë‹¤ì–‘ì„± (ìƒ‰ìƒ íˆìŠ¤í† ê·¸ë¨ì˜ ì—”íŠ¸ë¡œí”¼)
            metrics['color_diversity'] = self._calculate_color_diversity(enhanced)
            
            # ë””í…Œì¼ ë³´ì¡´ë„
            metrics['detail_preservation'] = self._calculate_detail_preservation(original, enhanced)
            
            # ì•„í‹°íŒ©íŠ¸ ë ˆë²¨
            metrics['artifact_level'] = 1.0 - self._detect_artifacts(enhanced)
            
            # ì „ì²´ í’ˆì§ˆ ì ìˆ˜
            overall_score = (
                metrics['structural_similarity'] * 0.3 +
                metrics['color_diversity'] * 0.2 +
                metrics['detail_preservation'] * 0.3 +
                metrics['artifact_level'] * 0.2
            )
            metrics['overall_score'] = max(0.0, min(1.0, overall_score))
            
        except Exception as e:
            logger.warning(f"í’ˆì§ˆ í‰ê°€ ì‹¤íŒ¨: {e}")
            metrics = {'overall_score': 0.8}
        
        return metrics
    
    def _calculate_ssim(self, img1: torch.Tensor, img2: torch.Tensor) -> float:
        """SSIM ê³„ì‚°"""
        try:
            # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜
            if img1.shape[1] == 3:
                gray1 = 0.299 * img1[:, 0] + 0.587 * img1[:, 1] + 0.114 * img1[:, 2]
                gray2 = 0.299 * img2[:, 0] + 0.587 * img2[:, 1] + 0.114 * img2[:, 2]
            else:
                gray1 = img1.squeeze(1)
                gray2 = img2.squeeze(1)
            
            # í¬ê¸° ì¡°ì • (í•„ìš”í•œ ê²½ìš°)
            if gray1.shape != gray2.shape:
                gray2 = F.interpolate(gray2.unsqueeze(1), size=gray1.shape[-2:], mode='bilinear', align_corners=False).squeeze(1)
            
            # SSIM ê³„ì‚°
            mu1 = torch.mean(gray1)
            mu2 = torch.mean(gray2)
            
            sigma1_sq = torch.var(gray1)
            sigma2_sq = torch.var(gray2)
            sigma12 = torch.mean((gray1 - mu1) * (gray2 - mu2))
            
            C1, C2 = 0.01**2, 0.03**2
            ssim = ((2 * mu1 * mu2 + C1) * (2 * sigma12 + C2)) / \
                   ((mu1**2 + mu2**2 + C1) * (sigma1_sq + sigma2_sq + C2))
            
            return float(ssim.item())
            
        except Exception as e:
            logger.warning(f"SSIM ê³„ì‚° ì‹¤íŒ¨: {e}")
            return 0.8
    
    def _calculate_color_diversity(self, image: torch.Tensor) -> float:
        """ìƒ‰ìƒ ë‹¤ì–‘ì„± ê³„ì‚°"""
        try:
            diversity_scores = []
            
            for c in range(3):  # RGB ì±„ë„
                channel = image[:, c, :, :].flatten()
                histogram = torch.histc(channel, bins=256, min=0, max=1)
                
                # ì •ê·œí™”
                histogram = histogram / torch.sum(histogram)
                
                # ì—”íŠ¸ë¡œí”¼ ê³„ì‚°
                entropy = -torch.sum(histogram * torch.log(histogram + 1e-10))
                diversity_scores.append(entropy.item())
            
            # í‰ê·  ì—”íŠ¸ë¡œí”¼ë¥¼ 0-1 ë²”ìœ„ë¡œ ì •ê·œí™”
            avg_entropy = np.mean(diversity_scores)
            normalized_diversity = min(1.0, avg_entropy / 8.0)  # log(256) â‰ˆ 8
            
            return normalized_diversity
            
        except Exception as e:
            logger.warning(f"ìƒ‰ìƒ ë‹¤ì–‘ì„± ê³„ì‚° ì‹¤íŒ¨: {e}")
            return 0.7
    
    def _calculate_detail_preservation(self, original: torch.Tensor, enhanced: torch.Tensor) -> float:
        """ë””í…Œì¼ ë³´ì¡´ë„ ê³„ì‚°"""
        try:
            # ê³ ì£¼íŒŒ ì„±ë¶„ ë¹„êµ
            sobel_x = torch.tensor([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]], dtype=torch.float32).unsqueeze(0).unsqueeze(0).to(self.device)
            sobel_y = torch.tensor([[-1, -2, -1], [0, 0, 0], [1, 2, 1]], dtype=torch.float32).unsqueeze(0).unsqueeze(0).to(self.device)
            
            # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜
            orig_gray = 0.299 * original[:, 0] + 0.587 * original[:, 1] + 0.114 * original[:, 2]
            enh_gray = 0.299 * enhanced[:, 0] + 0.587 * enhanced[:, 1] + 0.114 * enhanced[:, 2]
            
            # í¬ê¸° ì¡°ì •
            if orig_gray.shape != enh_gray.shape:
                enh_gray = F.interpolate(enh_gray.unsqueeze(1), size=orig_gray.shape[-2:], mode='bilinear', align_corners=False).squeeze(1)
            
            # ê·¸ë¼ë””ì–¸íŠ¸ ê³„ì‚°
            orig_grad_x = F.conv2d(orig_gray.unsqueeze(1), sobel_x, padding=1)
            orig_grad_y = F.conv2d(orig_gray.unsqueeze(1), sobel_y, padding=1)
            enh_grad_x = F.conv2d(enh_gray.unsqueeze(1), sobel_x, padding=1)
            enh_grad_y = F.conv2d(enh_gray.unsqueeze(1), sobel_y, padding=1)
            
            orig_grad_mag = torch.sqrt(orig_grad_x**2 + orig_grad_y**2)
            enh_grad_mag = torch.sqrt(enh_grad_x**2 + enh_grad_y**2)
            
            # ìƒê´€ê³„ìˆ˜ ê³„ì‚°
            correlation = torch.corrcoef(torch.stack([orig_grad_mag.flatten(), enh_grad_mag.flatten()]))[0, 1]
            
            return float(correlation.item()) if not torch.isnan(correlation) else 0.8
            
        except Exception as e:
            logger.warning(f"ë””í…Œì¼ ë³´ì¡´ë„ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return 0.8
    
    def _detect_artifacts(self, image: torch.Tensor) -> float:
        """ì•„í‹°íŒ©íŠ¸ ê²€ì¶œ"""
        try:
            # ë¼í”Œë¼ì‹œì•ˆìœ¼ë¡œ ê¸‰ê²©í•œ ë³€í™” ê²€ì¶œ
            laplacian = torch.tensor([[0, -1, 0], [-1, 4, -1], [0, -1, 0]], dtype=torch.float32).unsqueeze(0).unsqueeze(0).to(self.device)
            
            gray = 0.299 * image[:, 0] + 0.587 * image[:, 1] + 0.114 * image[:, 2]
            edges = F.conv2d(gray.unsqueeze(1), laplacian, padding=1)
            
            # ê·¹ê°’ ê²€ì¶œ
            edge_variance = torch.var(edges)
            artifact_score = min(1.0, edge_variance.item() / 0.1)  # ì •ê·œí™”
            
            return artifact_score
            
        except Exception as e:
            logger.warning(f"ì•„í‹°íŒ©íŠ¸ ê²€ì¶œ ì‹¤íŒ¨: {e}")
            return 0.1
    
    def _calculate_enhancement_stats(self, original: torch.Tensor, enhanced: torch.Tensor) -> Dict[str, Any]:
        """í’ˆì§ˆ í–¥ìƒ í†µê³„"""
        stats = {}
        
        try:
            # í¬ê¸° ë¹„êµ
            orig_size = original.shape[2:]
            enh_size = enhanced.shape[2:]
            stats['size_increase'] = {
                'original': orig_size,
                'enhanced': enh_size,
                'factor': (enh_size[0] * enh_size[1]) / (orig_size[0] * orig_size[1])
            }
            
            # ë°ê¸° ë³€í™”
            orig_brightness = torch.mean(original).item()
            enh_brightness = torch.mean(enhanced).item()
            stats['brightness_change'] = enh_brightness - orig_brightness
            
            # ëŒ€ë¹„ ë³€í™”
            orig_contrast = torch.std(original).item()
            enh_contrast = torch.std(enhanced).item()
            stats['contrast_change'] = enh_contrast - orig_contrast
            
            # ìƒ‰ìƒ ì±„ë„ ë³€í™”
            orig_saturation = self._calculate_saturation(original)
            enh_saturation = self._calculate_saturation(enhanced)
            stats['saturation_change'] = enh_saturation - orig_saturation
            
        except Exception as e:
            logger.warning(f"í†µê³„ ê³„ì‚° ì‹¤íŒ¨: {e}")
            stats = {}
        
        return stats
    
    def _calculate_saturation(self, image: torch.Tensor) -> float:
        """ìƒ‰ìƒ ì±„ë„ ê³„ì‚°"""
        try:
            # RGBë¥¼ HSVë¡œ ë³€í™˜ í›„ ì±„ë„ ê³„ì‚° (ê·¼ì‚¬)
            r, g, b = image[:, 0], image[:, 1], image[:, 2]
            
            max_val = torch.max(torch.max(r, g), b)
            min_val = torch.min(torch.min(r, g), b)
            
            saturation = (max_val - min_val) / (max_val + 1e-8)
            
            return torch.mean(saturation).item()
            
        except Exception as e:
            logger.warning(f"ì±„ë„ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return 0.5
    
    async def get_model_info(self) -> Dict[str, Any]:
        """ëª¨ë¸ ì •ë³´ ë°˜í™˜"""
        return {
            "enable_super_resolution": self.enable_super_resolution,
            "enable_denoising": self.enable_denoising,
            "enable_color_correction": self.enable_color_correction,
            "enable_sharpening": self.enable_sharpening,
            "scale_factor": self.scale_factor,
            "device": self.device,
            "initialized": self.is_initialized,
            "sr_model_loaded": self.sr_model is not None,
            "denoising_model_loaded": self.denoising_model is not None
        }
    
    async def cleanup(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        if self.sr_model:
            del self.sr_model
            self.sr_model = None
        
        if self.denoising_model:
            del self.denoising_model
            self.denoising_model = None
        
        self.is_initialized = False
        logger.info("ğŸ§¹ í›„ì²˜ë¦¬ ìŠ¤í… ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì™„ë£Œ")