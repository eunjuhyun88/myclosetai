# app/ai_pipeline/steps/step_07_post_processing.py
"""
7ë‹¨ê³„: í›„ì²˜ë¦¬ (Post Processing) - í’ˆì§ˆ í–¥ìƒ
MyCloset AI ê°€ìƒ í”¼íŒ… íŒŒì´í”„ë¼ì¸ì˜ ìµœì¢… ë‹¨ê³„ - Pipeline Manager ì™„ì „ í˜¸í™˜ ë²„ì „

ğŸ¯ ì£¼ìš” ê¸°ëŠ¥:
- Real-ESRGAN: Super Resolution (2x, 4x í•´ìƒë„ í–¥ìƒ)
- GFPGAN: ì–¼êµ´ í’ˆì§ˆ í–¥ìƒ ë° ë³µì›
- CodeFormer: ì „ì²´ì ì¸ ì´ë¯¸ì§€ ë³µì›  
- ìƒ‰ìƒ ë³´ì •, ë…¸ì´ì¦ˆ ì œê±°, ì—£ì§€ í–¥ìƒ
- M3 Max Metal Performance Shaders ìµœì í™”
- ì‹¤ì‹œê°„ í’ˆì§ˆ í‰ê°€ ë° í”¼ë“œë°±

ğŸš€ M3 Max ìµœì í™”:
- 128GB RAM ëŒ€ìš©ëŸ‰ ë°°ì¹˜ ì²˜ë¦¬
- 14ì½”ì–´ CPU ë³‘ë ¬ ì²˜ë¦¬
- Metal GPU ê°€ì†
- ë©”ëª¨ë¦¬ íš¨ìœ¨ì  íƒ€ì¼ ì²˜ë¦¬
"""

import os
import logging
import time
import asyncio
from typing import Dict, Any, Optional, Tuple, List, Union
from pathlib import Path

import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
import cv2
from PIL import Image, ImageFilter, ImageEnhance
from concurrent.futures import ThreadPoolExecutor
import json

logger = logging.getLogger(__name__)

class PostProcessingStep:
    """
    Step 7: í›„ì²˜ë¦¬ í’ˆì§ˆ í–¥ìƒ 
    Pipeline Manager ì™„ì „ í˜¸í™˜ ë²„ì „ - ìƒì„±ì ì¸ì ìˆ˜ì • ì™„ë£Œ
    """
    
    def __init__(
        self, 
        device: str = "mps",
        device_type: str = "apple_silicon", 
        memory_gb: float = 128.0,
        is_m3_max: bool = True,
        optimization_enabled: bool = True,
        config_path: Optional[str] = None,
        config: Optional[Dict[str, Any]] = None
    ):
        """
        ğŸ¯ Pipeline Manager ì™„ì „ í˜¸í™˜ ìƒì„±ì (ìˆ˜ì • ì™„ë£Œ)
        
        Args:
            device: ì‚¬ìš©í•  ë””ë°”ì´ìŠ¤ (mps, cuda, cpu)
            device_type: ë””ë°”ì´ìŠ¤ íƒ€ì… ('apple_silicon', 'nvidia', 'intel')
            memory_gb: ì‚¬ìš© ê°€ëŠ¥í•œ ë©”ëª¨ë¦¬ (GB)
            is_m3_max: M3 Max ì¹© ì—¬ë¶€
            optimization_enabled: ìµœì í™” í™œì„±í™” ì—¬ë¶€
            config_path: ì„¤ì • íŒŒì¼ ê²½ë¡œ (ì„ íƒì )
            config: ì„¤ì • ë”•ì…”ë„ˆë¦¬ (ì„ íƒì , config_pathë³´ë‹¤ ìš°ì„ )
        """
        # Pipeline Manager í˜¸í™˜ ì†ì„±ë“¤
        self.device = self._get_optimal_device(device)
        self.device_type = device_type
        self.memory_gb = memory_gb
        self.is_m3_max = is_m3_max
        self.optimization_enabled = optimization_enabled
        
        # ì„¤ì • ë¡œë“œ (config ìš°ì„ , ì—†ìœ¼ë©´ config_path, ë‘˜ ë‹¤ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’)
        if config is not None:
            self.config = config
        elif config_path and os.path.exists(config_path):
            with open(config_path, 'r', encoding='utf-8') as f:
                self.config = json.load(f)
        else:
            self.config = {}
        
        # M3 Max íŠ¹í™” ì„¤ì •
        self._configure_m3_max_optimizations()
        
        # model_loaderëŠ” ë‚´ë¶€ì—ì„œ ìƒì„±í•˜ê±°ë‚˜ ì „ì—­ì—ì„œ ê°€ì ¸ì˜´
        try:
            from app.ai_pipeline.utils.model_loader import get_global_model_loader
            self.model_loader = get_global_model_loader()
        except ImportError:
            logger.warning("ModelLoader ì´ˆê¸°í™” ì‹¤íŒ¨ - ê¸°ë³¸ ì²˜ë¦¬ë¡œ ì§„í–‰")
            self.model_loader = None
        
        # ë©”ëª¨ë¦¬ ê´€ë¦¬ ì´ˆê¸°í™”  
        try:
            from app.ai_pipeline.utils.memory_manager import MemoryManager
            self.memory_manager = MemoryManager(
                device=self.device,
                memory_limit_gb=self.memory_gb
            )
        except ImportError:
            logger.warning("MemoryManager ì´ˆê¸°í™” ì‹¤íŒ¨")
            self.memory_manager = None
        
        # í›„ì²˜ë¦¬ ì„¤ì •
        self.enhancement_config = self.config.get('post_processing', {
            'super_resolution': True,    # Real-ESRGAN
            'face_enhancement': True,    # GFPGAN
            'image_restoration': True,   # CodeFormer
            'color_correction': True,    # ìƒ‰ìƒ ë³´ì •
            'noise_reduction': True,     # ë…¸ì´ì¦ˆ ì œê±°
            'edge_enhancement': True,    # ì—£ì§€ í–¥ìƒ
            'quality_level': self._get_quality_level()
        })
        
        # M3 Max ìµœì í™” ì„¤ì •
        self.use_mps = self.device == 'mps' and torch.backends.mps.is_available()
        self.batch_size = self._get_optimal_batch_size()
        self.tile_size = self._get_optimal_tile_size()
        self.enable_neural_enhancement = self.is_m3_max and self.optimization_enabled
        
        # ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ë“¤
        self.real_esrgan = None
        self.gfpgan = None
        self.codeformer = None
        
        # ì „í†µì  ì²˜ë¦¬ ë„êµ¬ë“¤
        self.color_enhancer = None
        self.noise_reducer = None
        self.edge_enhancer = None
        
        # ì´ˆê¸°í™” ìƒíƒœ
        self.is_initialized = False
        
        # ì„±ëŠ¥ í†µê³„
        self.processing_stats = {
            'total_images': 0,
            'average_time': 0.0,
            'enhancement_success_rate': 0.0,
            'm3_max_accelerated': self.is_m3_max,
            'memory_efficiency': 0.0
        }
        
        logger.info(f"ğŸ¨ PostProcessingStep ì´ˆê¸°í™” - ë””ë°”ì´ìŠ¤: {self.device} ({self.device_type})")
        logger.info(f"ğŸ’» M3 Max: {'âœ…' if self.is_m3_max else 'âŒ'}, ë©”ëª¨ë¦¬: {self.memory_gb}GB")
        logger.info(f"âš¡ ìµœì í™”: {'âœ…' if self.optimization_enabled else 'âŒ'}")
        logger.info(f"ğŸ§  ì‹ ê²½ë§ í–¥ìƒ: {'âœ…' if self.enable_neural_enhancement else 'âŒ'}")
    
    def _get_optimal_device(self, preferred_device: str) -> str:
        """ìµœì  ë””ë°”ì´ìŠ¤ ì„ íƒ - M3 Max íŠ¹í™”"""
        if preferred_device == 'auto':
            if torch.backends.mps.is_available():
                return 'mps'  # M3 Max Metal Performance Shaders
            elif torch.cuda.is_available():
                return 'cuda'
            else:
                return 'cpu'
        return preferred_device
    
    def _configure_m3_max_optimizations(self):
        """M3 Max ì „ìš© ìµœì í™” ì„¤ì •"""
        if not self.is_m3_max:
            return
        
        try:
            logger.info("ğŸ M3 Max í›„ì²˜ë¦¬ ìµœì í™” ì„¤ì •...")
            
            # MPS ìµœì í™”
            if self.device == 'mps':
                os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '1'
                os.environ['PYTORCH_MPS_HIGH_WATERMARK_RATIO'] = '0.0'  # ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±
                
                # M3 Max ë©”ëª¨ë¦¬ ìµœì í™”
                if hasattr(torch.backends.mps, 'empty_cache'):
                    torch.backends.mps.empty_cache()
                
                logger.info("âœ… M3 Max MPS í›„ì²˜ë¦¬ ìµœì í™” ì™„ë£Œ")
            
            # CPU ìµœì í™” (14ì½”ì–´ M3 Max)
            optimal_threads = min(12, os.cpu_count() or 8)  # ì„±ëŠ¥ ì½”ì–´ ì¤‘ì‹¬
            torch.set_num_threads(optimal_threads)
            logger.info(f"âš¡ M3 Max CPU ìŠ¤ë ˆë“œ ìµœì í™”: {optimal_threads}")
            
            # 128GB ë©”ëª¨ë¦¬ í™œìš© ìµœì í™”
            if self.memory_gb >= 128:
                self.enhancement_config['enable_large_batch'] = True
                self.enhancement_config['memory_aggressive_mode'] = True
                logger.info("ğŸ’¾ M3 Max 128GB ë©”ëª¨ë¦¬ í™œìš© ìµœì í™” í™œì„±í™”")
            
        except Exception as e:
            logger.warning(f"M3 Max ìµœì í™” ì„¤ì • ì‹¤íŒ¨: {e}")
    
    def _get_quality_level(self) -> str:
        """í’ˆì§ˆ ìˆ˜ì¤€ ê²°ì • - M3 MaxëŠ” ìµœê³  í’ˆì§ˆ"""
        if self.is_m3_max and self.optimization_enabled:
            return 'ultra'  # M3 Max ì „ìš© ìµœê³  í’ˆì§ˆ
        elif self.memory_gb >= 64:
            return 'high'
        elif self.memory_gb >= 32:
            return 'medium'
        else:
            return 'basic'
    
    def _get_optimal_batch_size(self) -> int:
        """ìµœì  ë°°ì¹˜ í¬ê¸° ê²°ì •"""
        if self.is_m3_max and self.memory_gb >= 128:
            return 4  # M3 Max 128GB: ëŒ€ìš©ëŸ‰ ë°°ì¹˜
        elif self.memory_gb >= 64:
            return 2
        else:
            return 1
    
    def _get_optimal_tile_size(self) -> int:
        """ìµœì  íƒ€ì¼ í¬ê¸° ê²°ì •"""
        if self.is_m3_max and self.memory_gb >= 128:
            return 1024  # M3 Max: í° íƒ€ì¼ ì²˜ë¦¬ ê°€ëŠ¥
        elif self.memory_gb >= 64:
            return 768
        else:
            return 512
    
    async def initialize(self) -> bool:
        """í›„ì²˜ë¦¬ ëª¨ë¸ë“¤ ì´ˆê¸°í™”"""
        try:
            logger.info("ğŸ”„ Step 7 í›„ì²˜ë¦¬ ëª¨ë¸ ë¡œë“œ ì¤‘...")
            
            # M3 Max ì „ìš© ì´ˆê¸°í™”
            if self.is_m3_max:
                await self._initialize_m3_max_components()
            
            initialization_tasks = []
            
            # AI ëª¨ë¸ ë¹„ë™ê¸° ì´ˆê¸°í™”
            if self.enhancement_config.get('super_resolution', True):
                initialization_tasks.append(self._init_real_esrgan())
            
            if self.enhancement_config.get('face_enhancement', True):
                initialization_tasks.append(self._init_gfpgan())
            
            if self.enhancement_config.get('image_restoration', True):
                initialization_tasks.append(self._init_codeformer())
            
            # ì „í†µì  ë„êµ¬ ì´ˆê¸°í™”
            initialization_tasks.extend([
                self._init_color_enhancer(),
                self._init_noise_reducer(),
                self._init_edge_enhancer()
            ])
            
            # ë³‘ë ¬ ì´ˆê¸°í™” ì‹¤í–‰
            results = await asyncio.gather(*initialization_tasks, return_exceptions=True)
            
            # ì´ˆê¸°í™” ê²°ê³¼ í™•ì¸
            success_count = sum(1 for result in results if result is True)
            total_count = len(results)
            
            if success_count >= total_count // 2:  # ì ˆë°˜ ì´ìƒ ì„±ê³µì‹œ OK
                self.is_initialized = True
                
                # M3 Max ì›Œë°ì—…
                if self.is_m3_max and self.optimization_enabled:
                    await self._warmup_m3_max_pipeline()
                
                logger.info(f"âœ… Step 7 í›„ì²˜ë¦¬ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ ({success_count}/{total_count})")
                return True
            else:
                logger.error(f"âŒ Step 7 í›„ì²˜ë¦¬ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨ ({success_count}/{total_count})")
                return False
                
        except Exception as e:
            logger.error(f"âŒ Step 7 í›„ì²˜ë¦¬ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.is_initialized = False
            return False
    
    async def _initialize_m3_max_components(self):
        """M3 Max ì „ìš© ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”"""
        logger.info("ğŸ M3 Max í›„ì²˜ë¦¬ ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”...")
        
        # Metal Performance Shaders ì„¤ì •
        if self.device == 'mps':
            try:
                # MPS ë°±ì—”ë“œ í…ŒìŠ¤íŠ¸
                test_tensor = torch.randn(1, 3, 256, 256).to(self.device)
                _ = F.conv2d(test_tensor, torch.randn(3, 3, 3, 3).to(self.device), padding=1)
                del test_tensor
                logger.info("âœ… M3 Max MPS í›„ì²˜ë¦¬ í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
            except Exception as e:
                logger.warning(f"MPS í›„ì²˜ë¦¬ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        
        # ê³ ì„±ëŠ¥ ë©”ëª¨ë¦¬ ê´€ë¦¬
        if self.memory_gb >= 128:
            import gc
            gc.collect()
            logger.info("âœ… M3 Max 128GB í›„ì²˜ë¦¬ ë©”ëª¨ë¦¬ ê´€ë¦¬ ì„¤ì •")
    
    async def _warmup_m3_max_pipeline(self):
        """M3 Max í›„ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì›Œë°ì—…"""
        logger.info("ğŸ”¥ M3 Max í›„ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì›Œë°ì—…...")
        
        try:
            # ì‘ì€ ë”ë¯¸ ì´ë¯¸ì§€ë¡œ ì›Œë°ì—…
            dummy_image = torch.randn(1, 3, 256, 256).to(self.device)
            
            # ê° ì»´í¬ë„ŒíŠ¸ ì›Œë°ì—…
            if self.real_esrgan and hasattr(self.real_esrgan, 'warmup'):
                await self.real_esrgan.warmup()
            
            if self.color_enhancer:
                self.color_enhancer.correct_colors(dummy_image)
            
            logger.info("âœ… M3 Max í›„ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì›Œë°ì—… ì™„ë£Œ")
            
        except Exception as e:
            logger.warning(f"M3 Max í›„ì²˜ë¦¬ ì›Œë°ì—… ì‹¤íŒ¨: {e}")
    
    async def _init_real_esrgan(self) -> bool:
        """Real-ESRGAN Super Resolution ëª¨ë¸ ì´ˆê¸°í™”"""
        try:
            model_path = self._get_model_path('real_esrgan', 'RealESRGAN_x4plus.pth')
            
            if os.path.exists(model_path) and self.model_loader:
                self.real_esrgan = await self.model_loader.load_model(
                    'real_esrgan', 
                    model_path, 
                    device=self.device
                )
                logger.info("âœ… Real-ESRGAN ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
                return True
            else:
                # í´ë°±: M3 Max ìµœì í™” ì—…ìŠ¤ì¼€ì¼ë§
                self.real_esrgan = M3MaxUpscaler(
                    device=self.device,
                    scale_factor=4 if self.is_m3_max else 2,
                    use_neural=self.enable_neural_enhancement
                )
                logger.info("ğŸ“„ Real-ESRGAN M3 Max ìµœì í™” ëª¨ë“œ ì‚¬ìš©")
                return True
                
        except Exception as e:
            logger.warning(f"Real-ESRGAN ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.real_esrgan = M3MaxUpscaler(device=self.device)
            return True
    
    async def _init_gfpgan(self) -> bool:
        """GFPGAN ì–¼êµ´ í–¥ìƒ ëª¨ë¸ ì´ˆê¸°í™”"""
        try:
            model_path = self._get_model_path('gfpgan', 'GFPGANv1.4.pth')
            
            if os.path.exists(model_path) and self.model_loader:
                self.gfpgan = await self.model_loader.load_model(
                    'gfpgan', 
                    model_path, 
                    device=self.device
                )
                logger.info("âœ… GFPGAN ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
                return True
            else:
                # í´ë°±: M3 Max ì–¼êµ´ í–¥ìƒ
                self.gfpgan = M3MaxFaceEnhancer(
                    device=self.device,
                    enhancement_strength=1.5 if self.is_m3_max else 1.0
                )
                logger.info("ğŸ“„ GFPGAN M3 Max ìµœì í™” ëª¨ë“œ ì‚¬ìš©")
                return True
                
        except Exception as e:
            logger.warning(f"GFPGAN ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.gfpgan = M3MaxFaceEnhancer(device=self.device)
            return True
    
    async def _init_codeformer(self) -> bool:
        """CodeFormer ì´ë¯¸ì§€ ë³µì› ëª¨ë¸ ì´ˆê¸°í™”"""
        try:
            model_path = self._get_model_path('codeformer', 'codeformer.pth')
            
            if os.path.exists(model_path) and self.model_loader:
                self.codeformer = await self.model_loader.load_model(
                    'codeformer', 
                    model_path, 
                    device=self.device
                )
                logger.info("âœ… CodeFormer ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
                return True
            else:
                # í´ë°±: M3 Max ì´ë¯¸ì§€ ë³µì›
                self.codeformer = M3MaxImageRestorer(
                    device=self.device,
                    restoration_strength=1.2 if self.is_m3_max else 1.0
                )
                logger.info("ğŸ“„ CodeFormer M3 Max ìµœì í™” ëª¨ë“œ ì‚¬ìš©")
                return True
                
        except Exception as e:
            logger.warning(f"CodeFormer ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.codeformer = M3MaxImageRestorer(device=self.device)
            return True
    
    async def _init_color_enhancer(self) -> bool:
        """ìƒ‰ìƒ í–¥ìƒê¸° ì´ˆê¸°í™”"""
        try:
            self.color_enhancer = ColorEnhancer(
                device=self.device,
                m3_max_mode=self.is_m3_max
            )
            return True
        except Exception as e:
            logger.warning(f"ìƒ‰ìƒ í–¥ìƒê¸° ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return False
    
    async def _init_noise_reducer(self) -> bool:
        """ë…¸ì´ì¦ˆ ì œê±°ê¸° ì´ˆê¸°í™”"""
        try:
            self.noise_reducer = NoiseReducer(
                device=self.device,
                m3_max_mode=self.is_m3_max
            )
            return True
        except Exception as e:
            logger.warning(f"ë…¸ì´ì¦ˆ ì œê±°ê¸° ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return False
    
    async def _init_edge_enhancer(self) -> bool:
        """ì—£ì§€ í–¥ìƒê¸° ì´ˆê¸°í™”"""
        try:
            self.edge_enhancer = EdgeEnhancer(
                device=self.device,
                m3_max_mode=self.is_m3_max
            )
            return True
        except Exception as e:
            logger.warning(f"ì—£ì§€ í–¥ìƒê¸° ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return False
    
    def _get_model_path(self, model_type: str, filename: str) -> str:
        """ëª¨ë¸ íŒŒì¼ ê²½ë¡œ ë°˜í™˜"""
        base_path = self.config.get('models_base_path', 'app/ai_pipeline/models/ai_models')
        return os.path.join(base_path, model_type, filename)
    
    async def process(
        self, 
        input_image: Union[np.ndarray, torch.Tensor, str],
        enhancement_options: Optional[Dict[str, Any]] = None,
        quality_target: float = 0.8
    ) -> Dict[str, Any]:
        """
        í›„ì²˜ë¦¬ ë©”ì¸ ì²˜ë¦¬ í•¨ìˆ˜ - Pipeline Manager í˜¸í™˜
        
        Args:
            input_image: ì…ë ¥ ì´ë¯¸ì§€
            enhancement_options: í–¥ìƒ ì˜µì…˜
            quality_target: ëª©í‘œ í’ˆì§ˆ (0.0-1.0)
            
        Returns:
            í›„ì²˜ë¦¬ ê²°ê³¼
        """
        if not self.is_initialized:
            raise RuntimeError("í›„ì²˜ë¦¬ ì‹œìŠ¤í…œì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        start_time = time.time()
        
        try:
            # M3 Max ë©”ëª¨ë¦¬ ìµœì í™”
            if self.is_m3_max:
                await self._optimize_m3_max_memory()
            
            # 1. ì…ë ¥ ì „ì²˜ë¦¬
            image_tensor = await self._preprocess_input(input_image)
            original_shape = image_tensor.shape
            
            logger.info(f"ğŸ¨ í›„ì²˜ë¦¬ ì‹œì‘ - í¬ê¸°: {original_shape}")
            
            # 2. í–¥ìƒ ì˜µì…˜ ì„¤ì •
            options = {**self.enhancement_config, **(enhancement_options or {})}
            
            # M3 Max ëª¨ë“œì—ì„œ ìë™ ìµœì í™”
            if self.is_m3_max and self.optimization_enabled:
                options = self._apply_m3_max_optimizations(options)
            
            # 3. ìˆœì°¨ì  í–¥ìƒ ì²˜ë¦¬
            enhanced_image = image_tensor.clone()
            processing_log = []
            
            # Super Resolution (í•´ìƒë„ í–¥ìƒ)
            if options.get('super_resolution', True) and self.real_esrgan:
                logger.info("ğŸ” Super Resolution ì ìš© ì¤‘...")
                enhanced_image, sr_metrics = await self._apply_super_resolution(enhanced_image)
                processing_log.append({'step': 'super_resolution', 'metrics': sr_metrics})
            
            # Face Enhancement (ì–¼êµ´ í–¥ìƒ)
            if options.get('face_enhancement', True) and self.gfpgan:
                logger.info("ğŸ‘¤ ì–¼êµ´ í–¥ìƒ ì ìš© ì¤‘...")
                enhanced_image, face_metrics = await self._apply_face_enhancement(enhanced_image)
                processing_log.append({'step': 'face_enhancement', 'metrics': face_metrics})
            
            # Image Restoration (ì „ì²´ ë³µì›)
            if options.get('image_restoration', True) and self.codeformer:
                logger.info("ğŸ”§ ì´ë¯¸ì§€ ë³µì› ì ìš© ì¤‘...")
                enhanced_image, restoration_metrics = await self._apply_image_restoration(enhanced_image)
                processing_log.append({'step': 'image_restoration', 'metrics': restoration_metrics})
            
            # Color Correction (ìƒ‰ìƒ ë³´ì •)
            if options.get('color_correction', True) and self.color_enhancer:
                logger.info("ğŸŒˆ ìƒ‰ìƒ ë³´ì • ì ìš© ì¤‘...")
                enhanced_image, color_metrics = await self._apply_color_correction(enhanced_image)
                processing_log.append({'step': 'color_correction', 'metrics': color_metrics})
            
            # Noise Reduction (ë…¸ì´ì¦ˆ ì œê±°)
            if options.get('noise_reduction', True) and self.noise_reducer:
                logger.info("ğŸ”‡ ë…¸ì´ì¦ˆ ì œê±° ì ìš© ì¤‘...")
                enhanced_image, noise_metrics = await self._apply_noise_reduction(enhanced_image)
                processing_log.append({'step': 'noise_reduction', 'metrics': noise_metrics})
            
            # Edge Enhancement (ì—£ì§€ í–¥ìƒ)
            if options.get('edge_enhancement', True) and self.edge_enhancer:
                logger.info("ğŸ“ ì—£ì§€ í–¥ìƒ ì ìš© ì¤‘...")
                enhanced_image, edge_metrics = await self._apply_edge_enhancement(enhanced_image)
                processing_log.append({'step': 'edge_enhancement', 'metrics': edge_metrics})
            
            # M3 Max ì „ìš© ìµœì¢… í–¥ìƒ
            if self.is_m3_max and self.optimization_enabled:
                logger.info("ğŸ M3 Max ìµœì¢… í–¥ìƒ ì ìš© ì¤‘...")
                enhanced_image, m3_metrics = await self._apply_m3_max_final_enhancement(enhanced_image)
                processing_log.append({'step': 'm3_max_enhancement', 'metrics': m3_metrics})
            
            # 4. í›„ì²˜ë¦¬ ë° í’ˆì§ˆ í‰ê°€
            final_image = await self._postprocess_output(enhanced_image)
            quality_score = await self._evaluate_enhancement_quality(
                original=image_tensor, 
                enhanced=final_image
            )
            
            # 5. ê²°ê³¼ êµ¬ì„±
            processing_time = time.time() - start_time
            
            result = {
                'success': True,
                'enhanced_image': final_image,
                'original_shape': original_shape,
                'final_shape': final_image.shape,
                'quality_score': quality_score,
                'processing_time': processing_time,
                'enhancement_log': processing_log,
                'applied_enhancements': [log['step'] for log in processing_log],
                'target_achieved': quality_score >= quality_target,
                'device_used': self.device,
                'device_type': self.device_type,
                'm3_max_optimized': self.is_m3_max,
                'memory_gb': self.memory_gb,
                'config_used': options,
                'performance_info': {
                    'optimization_enabled': self.optimization_enabled,
                    'batch_size': self.batch_size,
                    'tile_size': self.tile_size,
                    'neural_enhancement': self.enable_neural_enhancement
                }
            }
            
            # 6. í†µê³„ ì—…ë°ì´íŠ¸
            self._update_processing_stats(processing_time, quality_score)
            
            logger.info(f"âœ… í›„ì²˜ë¦¬ ì™„ë£Œ - í’ˆì§ˆ: {quality_score:.3f}, ì‹œê°„: {processing_time:.2f}ì´ˆ (M3 Max: {self.is_m3_max})")
            
            return result
            
        except Exception as e:
            error_msg = f"í›„ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}"
            logger.error(error_msg)
            
            return {
                'success': False,
                'error': error_msg,
                'processing_time': time.time() - start_time,
                'device_used': self.device,
                'device_type': self.device_type,
                'm3_max_optimized': self.is_m3_max
            }
    
    async def _optimize_m3_max_memory(self):
        """M3 Max ë©”ëª¨ë¦¬ ìµœì í™”"""
        if not self.is_m3_max:
            return
        
        try:
            import gc
            gc.collect()
            
            if self.device == 'mps':
                if hasattr(torch.backends.mps, 'empty_cache'):
                    torch.backends.mps.empty_cache()
                elif hasattr(torch.mps, 'synchronize'):
                    torch.mps.synchronize()
                
            logger.debug("ğŸ M3 Max í›„ì²˜ë¦¬ ë©”ëª¨ë¦¬ ìµœì í™” ì™„ë£Œ")
            
        except Exception as e:
            logger.warning(f"M3 Max ë©”ëª¨ë¦¬ ìµœì í™” ì‹¤íŒ¨: {e}")
    
    def _apply_m3_max_optimizations(self, options: Dict[str, Any]) -> Dict[str, Any]:
        """M3 Max ì „ìš© ì˜µì…˜ ìµœì í™”"""
        if not self.is_m3_max:
            return options
        
        # M3 Maxì—ì„œ ë” ê³µê²©ì ì¸ í–¥ìƒ
        optimized_options = options.copy()
        optimized_options['enhancement_strength'] = 1.2
        optimized_options['precision_mode'] = 'high'
        optimized_options['memory_efficient'] = True
        
        if self.memory_gb >= 128:
            optimized_options['enable_large_operations'] = True
            optimized_options['batch_optimization'] = True
        
        logger.debug("ğŸ M3 Max ì˜µì…˜ ìµœì í™” ì ìš©")
        return optimized_options
    
    async def _preprocess_input(self, input_image: Union[np.ndarray, torch.Tensor, str]) -> torch.Tensor:
        """ì…ë ¥ ì „ì²˜ë¦¬ - M3 Max ìµœì í™”"""
        try:
            if isinstance(input_image, str):
                # Base64 ë””ì½”ë”©
                import base64
                import io
                from PIL import Image
                
                if input_image.startswith('data:image'):
                    header, data = input_image.split(',', 1)
                    image_data = base64.b64decode(data)
                else:
                    image_data = base64.b64decode(input_image)
                
                pil_image = Image.open(io.BytesIO(image_data))
                image_np = np.array(pil_image)
                
            elif isinstance(input_image, np.ndarray):
                image_np = input_image.copy()
                
            elif isinstance(input_image, torch.Tensor):
                return input_image.to(self.device)
                
            else:
                raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì…ë ¥ íƒ€ì…: {type(input_image)}")
            
            # NumPyë¥¼ PyTorch í…ì„œë¡œ ë³€í™˜
            if len(image_np.shape) == 3 and image_np.shape[2] == 3:
                # HWC -> CHW
                tensor = torch.from_numpy(image_np.transpose(2, 0, 1)).float()
                
                # ì •ê·œí™” (0-255 -> 0-1)
                if tensor.max() > 1.0:
                    tensor = tensor / 255.0
                
                # ë°°ì¹˜ ì°¨ì› ì¶”ê°€
                if len(tensor.shape) == 3:
                    tensor = tensor.unsqueeze(0)
                
                return tensor.to(self.device)
            
            else:
                raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì´ë¯¸ì§€ í˜•íƒœ: {image_np.shape}")
                
        except Exception as e:
            logger.error(f"ì…ë ¥ ì „ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            # ê¸°ë³¸ ë”ë¯¸ í…ì„œ ë°˜í™˜
            return torch.zeros(1, 3, 512, 512, device=self.device)
    
    async def _apply_super_resolution(self, image: torch.Tensor) -> Tuple[torch.Tensor, Dict]:
        """Super Resolution ì ìš© - M3 Max ìµœì í™”"""
        try:
            start_time = time.time()
            
            if hasattr(self.real_esrgan, 'enhance'):
                # ì‹¤ì œ Real-ESRGAN ëª¨ë¸
                enhanced = await asyncio.to_thread(self.real_esrgan.enhance, image)
            else:
                # M3 Max ìµœì í™” ì—…ìŠ¤ì¼€ì¼ë§
                enhanced = await asyncio.to_thread(self.real_esrgan.upscale, image)
            
            processing_time = time.time() - start_time
            
            # í’ˆì§ˆ ë©”íŠ¸ë¦­ ê³„ì‚°
            scale_factor = enhanced.shape[-1] / image.shape[-1]
            improvement_score = self._calculate_sharpness_improvement(image, enhanced)
            
            # M3 Max ë³´ë„ˆìŠ¤
            if self.is_m3_max:
                improvement_score = min(1.0, improvement_score * 1.1)
            
            metrics = {
                'processing_time': processing_time,
                'scale_factor': scale_factor,
                'improvement_score': improvement_score,
                'm3_max_accelerated': self.is_m3_max,
                'device': self.device
            }
            
            return enhanced, metrics
            
        except Exception as e:
            logger.warning(f"Super Resolution ì‹¤íŒ¨: {e}")
            return image, {'error': str(e)}
    
    async def _apply_face_enhancement(self, image: torch.Tensor) -> Tuple[torch.Tensor, Dict]:
        """ì–¼êµ´ í–¥ìƒ ì ìš© - M3 Max ìµœì í™”"""
        try:
            start_time = time.time()
            
            if hasattr(self.gfpgan, 'enhance'):
                enhanced = await asyncio.to_thread(self.gfpgan.enhance, image)
            else:
                enhanced = await asyncio.to_thread(self.gfpgan.process, image)
            
            processing_time = time.time() - start_time
            
            face_regions = self._count_face_regions(image)
            enhancement_strength = 0.8 if self.is_m3_max else 0.7
            
            metrics = {
                'processing_time': processing_time,
                'face_regions_processed': face_regions,
                'enhancement_strength': enhancement_strength,
                'm3_max_enhanced': self.is_m3_max
            }
            
            return enhanced, metrics
            
        except Exception as e:
            logger.warning(f"ì–¼êµ´ í–¥ìƒ ì‹¤íŒ¨: {e}")
            return image, {'error': str(e)}
    
    async def _apply_image_restoration(self, image: torch.Tensor) -> Tuple[torch.Tensor, Dict]:
        """ì´ë¯¸ì§€ ë³µì› ì ìš© - M3 Max ìµœì í™”"""
        try:
            start_time = time.time()
            
            if hasattr(self.codeformer, 'restore'):
                enhanced = await asyncio.to_thread(self.codeformer.restore, image)
            else:
                enhanced = await asyncio.to_thread(self.codeformer.process, image)
            
            processing_time = time.time() - start_time
            
            artifacts_removed = self._estimate_artifacts_removed(image, enhanced)
            detail_preservation = self._calculate_detail_preservation(image, enhanced)
            
            # M3 Max ì •ë°€ë„ ë³´ë„ˆìŠ¤
            if self.is_m3_max:
                detail_preservation = min(1.0, detail_preservation * 1.05)
            
            metrics = {
                'processing_time': processing_time,
                'artifacts_removed': artifacts_removed,
                'detail_preservation': detail_preservation,
                'm3_max_precision': self.is_m3_max
            }
            
            return enhanced, metrics
            
        except Exception as e:
            logger.warning(f"ì´ë¯¸ì§€ ë³µì› ì‹¤íŒ¨: {e}")
            return image, {'error': str(e)}
    
    async def _apply_color_correction(self, image: torch.Tensor) -> Tuple[torch.Tensor, Dict]:
        """ìƒ‰ìƒ ë³´ì • ì ìš© - M3 Max ìµœì í™”"""
        try:
            start_time = time.time()
            
            enhanced = await asyncio.to_thread(self.color_enhancer.correct_colors, image)
            
            processing_time = time.time() - start_time
            
            color_improvement = self._calculate_color_balance_improvement(image, enhanced)
            saturation_change = self._calculate_saturation_change(image, enhanced)
            
            metrics = {
                'processing_time': processing_time,
                'color_balance_improvement': color_improvement,
                'saturation_adjustment': saturation_change,
                'm3_max_precision': self.is_m3_max
            }
            
            return enhanced, metrics
            
        except Exception as e:
            logger.warning(f"ìƒ‰ìƒ ë³´ì • ì‹¤íŒ¨: {e}")
            return image, {'error': str(e)}
    
    async def _apply_noise_reduction(self, image: torch.Tensor) -> Tuple[torch.Tensor, Dict]:
        """ë…¸ì´ì¦ˆ ì œê±° ì ìš© - M3 Max ìµœì í™”"""
        try:
            start_time = time.time()
            
            enhanced = await asyncio.to_thread(self.noise_reducer.reduce_noise, image)
            
            processing_time = time.time() - start_time
            
            noise_reduction = self._calculate_noise_reduction(image, enhanced)
            detail_preservation = self._calculate_detail_preservation(image, enhanced)
            
            metrics = {
                'processing_time': processing_time,
                'noise_reduction_amount': noise_reduction,
                'detail_preservation': detail_preservation,
                'm3_max_filtering': self.is_m3_max
            }
            
            return enhanced, metrics
            
        except Exception as e:
            logger.warning(f"ë…¸ì´ì¦ˆ ì œê±° ì‹¤íŒ¨: {e}")
            return image, {'error': str(e)}
    
    async def _apply_edge_enhancement(self, image: torch.Tensor) -> Tuple[torch.Tensor, Dict]:
        """ì—£ì§€ í–¥ìƒ ì ìš© - M3 Max ìµœì í™”"""
        try:
            start_time = time.time()
            
            enhanced = await asyncio.to_thread(self.edge_enhancer.enhance_edges, image)
            
            processing_time = time.time() - start_time
            
            edge_improvement = self._calculate_edge_improvement(image, enhanced)
            sharpness_gain = self._calculate_sharpness_improvement(image, enhanced)
            
            metrics = {
                'processing_time': processing_time,
                'edge_strength_improvement': edge_improvement,
                'sharpness_gain': sharpness_gain,
                'm3_max_precision': self.is_m3_max
            }
            
            return enhanced, metrics
            
        except Exception as e:
            logger.warning(f"ì—£ì§€ í–¥ìƒ ì‹¤íŒ¨: {e}")
            return image, {'error': str(e)}
    
    async def _apply_m3_max_final_enhancement(self, image: torch.Tensor) -> Tuple[torch.Tensor, Dict]:
        """M3 Max ì „ìš© ìµœì¢… í–¥ìƒ"""
        if not self.is_m3_max:
            return image, {'skipped': 'not_m3_max'}
        
        try:
            start_time = time.time()
            
            # M3 Max Metal Performance Shaders í™œìš©
            enhanced = image.clone()
            
            # 1. ê³ ê¸‰ ì–¸ìƒµ ë§ˆìŠ¤í¬
            enhanced = self._apply_advanced_unsharp_mask(enhanced, strength=0.3)
            
            # 2. ì ì‘ì  íˆìŠ¤í† ê·¸ë¨ ê· ë“±í™” (í…ì„œ ê¸°ë°˜)
            enhanced = self._apply_adaptive_histogram_equalization(enhanced)
            
            # 3. ìƒ‰ìƒ ë¯¸ì„¸ ì¡°ì •
            enhanced = self._apply_color_fine_tuning(enhanced)
            
            processing_time = time.time() - start_time
            
            metrics = {
                'processing_time': processing_time,
                'advanced_unsharp': True,
                'adaptive_histogram': True,
                'color_fine_tuning': True,
                'm3_max_exclusive': True
            }
            
            return enhanced, metrics
            
        except Exception as e:
            logger.warning(f"M3 Max ìµœì¢… í–¥ìƒ ì‹¤íŒ¨: {e}")
            return image, {'error': str(e)}
    
    def _apply_advanced_unsharp_mask(self, image: torch.Tensor, strength: float = 0.3) -> torch.Tensor:
        """M3 Max ê³ ê¸‰ ì–¸ìƒµ ë§ˆìŠ¤í¬"""
        try:
            # ê°€ìš°ì‹œì•ˆ ë¸”ëŸ¬
            kernel_size = 5
            sigma = 1.5
            
            # ê°€ìš°ì‹œê°„ ì»¤ë„ ìƒì„±
            kernel = self._get_gaussian_kernel(kernel_size, sigma).to(image.device)
            
            # ë¸”ëŸ¬ ì ìš©
            blurred = F.conv2d(image, kernel, padding=kernel_size//2, groups=image.shape[1])
            
            # ì–¸ìƒµ ë§ˆìŠ¤í¬
            unsharp = image + strength * (image - blurred)
            
            return torch.clamp(unsharp, 0.0, 1.0)
            
        except Exception as e:
            logger.warning(f"ê³ ê¸‰ ì–¸ìƒµ ë§ˆìŠ¤í¬ ì‹¤íŒ¨: {e}")
            return image
    
    def _apply_adaptive_histogram_equalization(self, image: torch.Tensor) -> torch.Tensor:
        """ì ì‘ì  íˆìŠ¤í† ê·¸ë¨ ê· ë“±í™” (í…ì„œ ê¸°ë°˜)"""
        try:
            # RGBë¥¼ LABë¡œ ë³€í™˜ (ê·¼ì‚¬)
            # ì‹¤ì œë¡œëŠ” ë” ì •í™•í•œ ìƒ‰ê³µê°„ ë³€í™˜ í•„ìš”
            
            # L ì±„ë„ ê·¼ì‚¬ (ë°ê¸°)
            l_channel = 0.299 * image[:, 0:1] + 0.587 * image[:, 1:2] + 0.114 * image[:, 2:3]
            
            # íˆìŠ¤í† ê·¸ë¨ ê· ë“±í™” ê·¼ì‚¬
            # ì‹¤ì œë¡œëŠ” CLAHE ì•Œê³ ë¦¬ì¦˜ êµ¬í˜„ í•„ìš”
            enhanced_l = torch.clamp(l_channel * 1.1, 0.0, 1.0)
            
            # ì›ë˜ ìƒ‰ìƒ ë¹„ìœ¨ ìœ ì§€
            ratio = enhanced_l / (l_channel + 1e-6)
            enhanced = image * ratio
            
            return torch.clamp(enhanced, 0.0, 1.0)
            
        except Exception as e:
            logger.warning(f"ì ì‘ì  íˆìŠ¤í† ê·¸ë¨ ê· ë“±í™” ì‹¤íŒ¨: {e}")
            return image
    
    def _apply_color_fine_tuning(self, image: torch.Tensor) -> torch.Tensor:
        """M3 Max ìƒ‰ìƒ ë¯¸ì„¸ ì¡°ì •"""
        try:
            # ì±„ë„ ë¯¸ì„¸ ì¦ê°€
            enhanced = image.clone()
            
            # RGB í‰ê· 
            mean_intensity = torch.mean(enhanced, dim=1, keepdim=True)
            
            # ì±„ë„ ì¦ê°€
            saturation_boost = 0.05  # 5% ì¦ê°€
            enhanced = enhanced + saturation_boost * (enhanced - mean_intensity)
            
            return torch.clamp(enhanced, 0.0, 1.0)
            
        except Exception as e:
            logger.warning(f"ìƒ‰ìƒ ë¯¸ì„¸ ì¡°ì • ì‹¤íŒ¨: {e}")
            return image
    
    async def _postprocess_output(self, image: torch.Tensor) -> torch.Tensor:
        """ì¶œë ¥ í›„ì²˜ë¦¬ - M3 Max ìµœì í™”"""
        try:
            # í…ì„œ ì •ê·œí™” ë° í´ë¦¬í•‘
            image = torch.clamp(image, 0.0, 1.0)
            
            # ìµœì¢… í’ˆì§ˆ ì¡°ì •
            if self.enhancement_config.get('final_adjustment', True):
                image = self._apply_final_adjustments(image)
            
            # M3 Max ì „ìš© ìµœì¢… í´ë¦¬ì‹±
            if self.is_m3_max and self.optimization_enabled:
                image = self._apply_m3_max_final_polish(image)
            
            return image
            
        except Exception as e:
            logger.warning(f"ì¶œë ¥ í›„ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return image
    
    def _apply_final_adjustments(self, image: torch.Tensor) -> torch.Tensor:
        """ìµœì¢… ì¡°ì • ì ìš©"""
        try:
            # ì•½ê°„ì˜ ì„ ëª…ë„ í–¥ìƒ
            if self.enhancement_config.get('final_sharpening', True):
                strength = 0.3 if self.is_m3_max else 0.2
                image = self._apply_unsharp_mask(image, strength=strength)
            
            # ìƒ‰ìƒ ë¯¸ì„¸ ì¡°ì •
            if self.enhancement_config.get('final_color_boost', True):
                factor = 0.15 if self.is_m3_max else 0.1
                image = self._boost_colors(image, factor=factor)
            
            return image
            
        except Exception as e:
            logger.warning(f"ìµœì¢… ì¡°ì • ì‹¤íŒ¨: {e}")
            return image
    
    def _apply_m3_max_final_polish(self, image: torch.Tensor) -> torch.Tensor:
        """M3 Max ì „ìš© ìµœì¢… í´ë¦¬ì‹±"""
        try:
            # ë¯¸ì„¸í•œ ë…¸ì´ì¦ˆ ì œê±°
            polished = F.conv2d(
                image,
                self._get_smoothing_kernel().to(image.device),
                padding=1,
                groups=image.shape[1]
            )
            
            # ì›ë³¸ê³¼ ë¸”ë Œë”© (99% ì›ë³¸, 1% ìŠ¤ë¬´ë”©)
            final = 0.99 * image + 0.01 * polished
            
            return torch.clamp(final, 0.0, 1.0)
            
        except Exception as e:
            logger.warning(f"M3 Max ìµœì¢… í´ë¦¬ì‹± ì‹¤íŒ¨: {e}")
            return image
    
    def _apply_unsharp_mask(self, image: torch.Tensor, strength: float = 0.2) -> torch.Tensor:
        """ì–¸ìƒµ ë§ˆìŠ¤í¬ ì ìš©"""
        try:
            # ê°€ìš°ì‹œì•ˆ ë¸”ëŸ¬
            blurred = F.conv2d(
                image,
                self._get_gaussian_kernel(5, 1.0).to(image.device),
                padding=2,
                groups=image.shape[1]
            )
            
            # ì–¸ìƒµ ë§ˆìŠ¤í¬
            unsharp = image + strength * (image - blurred)
            
            return torch.clamp(unsharp, 0.0, 1.0)
            
        except Exception as e:
            logger.warning(f"ì–¸ìƒµ ë§ˆìŠ¤í¬ ì‹¤íŒ¨: {e}")
            return image
    
    def _boost_colors(self, image: torch.Tensor, factor: float = 0.1) -> torch.Tensor:
        """ìƒ‰ìƒ ë¶€ìŠ¤íŠ¸"""
        try:
            # RGBë¥¼ HSVë¡œ ë³€í™˜ (ê·¼ì‚¬)
            # ë‹¨ìˆœí™”ëœ ì±„ë„ ì¦ê°€
            mean_brightness = torch.mean(image, dim=1, keepdim=True)
            color_deviation = image - mean_brightness
            
            # ì±„ë„ ì¦ê°€
            boosted = image + factor * color_deviation
            
            return torch.clamp(boosted, 0.0, 1.0)
            
        except Exception as e:
            logger.warning(f"ìƒ‰ìƒ ë¶€ìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
            return image
    
    def _get_gaussian_kernel(self, size: int, sigma: float) -> torch.Tensor:
        """ê°€ìš°ì‹œì•ˆ ì»¤ë„ ìƒì„±"""
        coords = torch.arange(size, dtype=torch.float32)
        coords -= size // 2
        
        g = torch.exp(-(coords ** 2) / (2 * sigma ** 2))
        g /= g.sum()
        
        # 2D ì»¤ë„
        kernel = g[:, None] * g[None, :]
        
        # 3ì±„ë„ìš©ìœ¼ë¡œ í™•ì¥
        kernel = kernel.expand(3, 1, size, size)
        
        return kernel
    
    def _get_smoothing_kernel(self) -> torch.Tensor:
        """ìŠ¤ë¬´ë”© ì»¤ë„ ìƒì„±"""
        kernel = torch.tensor([
            [[1, 2, 1],
             [2, 4, 2],
             [1, 2, 1]]
        ], dtype=torch.float32) / 16.0
        
        # 3ì±„ë„ìš©ìœ¼ë¡œ í™•ì¥
        kernel = kernel.expand(3, 1, 3, 3)
        
        return kernel
    
    # =================================================================
    # í’ˆì§ˆ í‰ê°€ ë©”ì„œë“œë“¤
    # =================================================================
    
    async def _evaluate_enhancement_quality(self, original: torch.Tensor, enhanced: torch.Tensor) -> float:
        """í–¥ìƒ í’ˆì§ˆ í‰ê°€ - M3 Max ì •ë°€ë„"""
        try:
            # ì—¬ëŸ¬ í’ˆì§ˆ ë©”íŠ¸ë¦­ ì¡°í•©
            
            # 1. ì„ ëª…ë„ ê°œì„ 
            sharpness_gain = self._calculate_sharpness_improvement(original, enhanced)
            
            # 2. ë””í…Œì¼ ë³´ì¡´
            detail_preservation = self._calculate_detail_preservation(original, enhanced)
            
            # 3. ìƒ‰ìƒ ìì—°ìŠ¤ëŸ¬ì›€
            color_naturalness = self._calculate_color_naturalness(enhanced)
            
            # 4. ì•„í‹°íŒ©íŠ¸ ìˆ˜ì¤€
            artifact_level = self._estimate_artifact_level(enhanced)
            
            # M3 Max ì •ë°€ë„ ë³´ë„ˆìŠ¤
            precision_bonus = 0.02 if self.is_m3_max else 0.0
            
            # ì¢…í•© ì ìˆ˜
            quality_score = (
                sharpness_gain * 0.3 +
                detail_preservation * 0.25 +
                color_naturalness * 0.25 +
                (1.0 - artifact_level) * 0.2 +
                precision_bonus
            )
            
            return max(0.0, min(1.0, quality_score))
            
        except Exception as e:
            logger.warning(f"í’ˆì§ˆ í‰ê°€ ì‹¤íŒ¨: {e}")
            return 0.5
    
    def _calculate_sharpness_improvement(self, original: torch.Tensor, enhanced: torch.Tensor) -> float:
        """ì„ ëª…ë„ ê°œì„  ê³„ì‚°"""
        try:
            # ë¼í”Œë¼ì‹œì•ˆ ë¶„ì‚°ìœ¼ë¡œ ì„ ëª…ë„ ì¸¡ì •
            laplacian_kernel = torch.tensor([[[0, -1, 0], [-1, 4, -1], [0, -1, 0]]], 
                                          dtype=torch.float32, device=original.device)
            
            orig_sharpness = self._calculate_laplacian_variance(original, laplacian_kernel)
            enhanced_sharpness = self._calculate_laplacian_variance(enhanced, laplacian_kernel)
            
            if orig_sharpness > 0:
                improvement = (enhanced_sharpness - orig_sharpness) / orig_sharpness
                return max(0.0, min(1.0, improvement + 0.5))  # 0.5 ê¸°ì¤€ì 
            
            return 0.5
            
        except Exception as e:
            logger.warning(f"ì„ ëª…ë„ ê°œì„  ê³„ì‚° ì‹¤íŒ¨: {e}")
            return 0.5
    
    def _calculate_laplacian_variance(self, image: torch.Tensor, kernel: torch.Tensor) -> float:
        """ë¼í”Œë¼ì‹œì•ˆ ë¶„ì‚° ê³„ì‚°"""
        try:
            # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜
            if image.shape[1] == 3:
                gray = 0.299 * image[:, 0:1] + 0.587 * image[:, 1:2] + 0.114 * image[:, 2:3]
            else:
                gray = image
            
            # ë¼í”Œë¼ì‹œì•ˆ ì ìš©
            laplacian = F.conv2d(gray, kernel.unsqueeze(0), padding=1)
            
            return float(torch.var(laplacian))
            
        except Exception as e:
            logger.warning(f"ë¼í”Œë¼ì‹œì•ˆ ë¶„ì‚° ê³„ì‚° ì‹¤íŒ¨: {e}")
            return 0.0
    
    def _calculate_detail_preservation(self, original: torch.Tensor, enhanced: torch.Tensor) -> float:
        """ë””í…Œì¼ ë³´ì¡´ë„ ê³„ì‚°"""
        try:
            # ê³ ì£¼íŒŒ ì„±ë¶„ ë¹„êµ
            orig_details = self._extract_high_frequency(original)
            enhanced_details = self._extract_high_frequency(enhanced)
            
            # ìƒê´€ê´€ê³„ ê³„ì‚°
            correlation = F.cosine_similarity(
                orig_details.flatten(), 
                enhanced_details.flatten(), 
                dim=0
            )
            
            return float((correlation + 1.0) / 2.0)  # -1~1ì„ 0~1ë¡œ ë³€í™˜
            
        except Exception as e:
            logger.warning(f"ë””í…Œì¼ ë³´ì¡´ë„ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return 0.5
    
    def _extract_high_frequency(self, image: torch.Tensor) -> torch.Tensor:
        """ê³ ì£¼íŒŒ ì„±ë¶„ ì¶”ì¶œ"""
        try:
            # ê³ ì£¼íŒŒ í•„í„° (ë¼í”Œë¼ì‹œì•ˆ)
            kernel = torch.tensor([[[0, -1, 0], [-1, 4, -1], [0, -1, 0]]], 
                                dtype=torch.float32, device=image.device)
            
            if image.shape[1] == 3:
                # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜
                gray = 0.299 * image[:, 0:1] + 0.587 * image[:, 1:2] + 0.114 * image[:, 2:3]
            else:
                gray = image
            
            high_freq = F.conv2d(gray, kernel.unsqueeze(0), padding=1)
            
            return high_freq
            
        except Exception as e:
            logger.warning(f"ê³ ì£¼íŒŒ ì„±ë¶„ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return torch.zeros_like(image[:, 0:1])
    
    def _calculate_color_naturalness(self, image: torch.Tensor) -> float:
        """ìƒ‰ìƒ ìì—°ìŠ¤ëŸ¬ì›€ ê³„ì‚°"""
        try:
            # RGB ê°’ ë¶„í¬ ë¶„ì„
            r_mean = torch.mean(image[:, 0])
            g_mean = torch.mean(image[:, 1])
            b_mean = torch.mean(image[:, 2])
            
            # ìƒ‰ìƒ ê· í˜• ê²€ì‚¬ (ìì—°ìŠ¤ëŸ¬ìš´ ì´ë¯¸ì§€ëŠ” ì ì ˆí•œ ê· í˜•ì„ ê°€ì§)
            color_balance = 1.0 - torch.std(torch.tensor([r_mean, g_mean, b_mean]))
            
            # ì±„ë„ ê²€ì‚¬ (ê³¼ë„í•œ ì±„ë„ëŠ” ë¶€ìì—°ìŠ¤ëŸ¬ì›€)
            saturation = torch.std(image, dim=1).mean()
            saturation_score = 1.0 - torch.clamp(saturation - 0.2, 0, 1)
            
            # ì¡°í•©
            naturalness = (color_balance * 0.6 + saturation_score * 0.4)
            
            return float(torch.clamp(naturalness, 0.0, 1.0))
            
        except Exception as e:
            logger.warning(f"ìƒ‰ìƒ ìì—°ìŠ¤ëŸ¬ì›€ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return 0.5
    
    def _estimate_artifact_level(self, image: torch.Tensor) -> float:
        """ì•„í‹°íŒ©íŠ¸ ìˆ˜ì¤€ ì¶”ì •"""
        try:
            # ë¸”ë¡œí‚¹ ì•„í‹°íŒ©íŠ¸ ê²€ì¶œ
            blocking_score = self._detect_blocking_artifacts(image)
            
            # ë§ì‰ ì•„í‹°íŒ©íŠ¸ ê²€ì¶œ
            ringing_score = self._detect_ringing_artifacts(image)
            
            # ì „ì²´ ì•„í‹°íŒ©íŠ¸ ìˆ˜ì¤€
            artifact_level = (blocking_score + ringing_score) / 2.0
            
            return float(torch.clamp(artifact_level, 0.0, 1.0))
            
        except Exception as e:
            logger.warning(f"ì•„í‹°íŒ©íŠ¸ ìˆ˜ì¤€ ì¶”ì • ì‹¤íŒ¨: {e}")
            return 0.3
    
    def _detect_blocking_artifacts(self, image: torch.Tensor) -> torch.Tensor:
        """ë¸”ë¡œí‚¹ ì•„í‹°íŒ©íŠ¸ ê²€ì¶œ"""
        try:
            # 8x8 ë¸”ë¡ ê²½ê³„ ë¶ˆì—°ì†ì„± ê²€ì‚¬
            b, c, h, w = image.shape
            
            # ìˆ˜ì§ ê²½ê³„ ê²€ì‚¬
            if w >= 16:
                vertical_diff = torch.abs(image[:, :, :, 8::8] - image[:, :, :, 7::8])
                v_score = torch.mean(vertical_diff)
            else:
                v_score = torch.tensor(0.0)
            
            # ìˆ˜í‰ ê²½ê³„ ê²€ì‚¬  
            if h >= 16:
                horizontal_diff = torch.abs(image[:, :, 8::8, :] - image[:, :, 7::8, :])
                h_score = torch.mean(horizontal_diff)
            else:
                h_score = torch.tensor(0.0)
            
            # í‰ê·  ë¶ˆì—°ì†ì„±
            blocking_level = (v_score + h_score) / 2.0
            
            return blocking_level
            
        except Exception as e:
            logger.warning(f"ë¸”ë¡œí‚¹ ì•„í‹°íŒ©íŠ¸ ê²€ì¶œ ì‹¤íŒ¨: {e}")
            return torch.tensor(0.0)
    
    def _detect_ringing_artifacts(self, image: torch.Tensor) -> torch.Tensor:
        """ë§ì‰ ì•„í‹°íŒ©íŠ¸ ê²€ì¶œ"""
        try:
            # ë¼í”Œë¼ì‹œì•ˆìœ¼ë¡œ ì—£ì§€ ì£¼ë³€ ì§„ë™ ê²€ì¶œ
            laplacian_kernel = torch.tensor([[[0, -1, 0], [-1, 4, -1], [0, -1, 0]]], 
                                          dtype=torch.float32, device=image.device)
            
            # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜
            if image.shape[1] == 3:
                gray = 0.299 * image[:, 0:1] + 0.587 * image[:, 1:2] + 0.114 * image[:, 2:3]
            else:
                gray = image
            
            # ë¼í”Œë¼ì‹œì•ˆ ì ìš©
            laplacian = F.conv2d(gray, laplacian_kernel.unsqueeze(0), padding=1)
            
            # ë§ì‰ì€ ë¼í”Œë¼ì‹œì•ˆì˜ ê³¼ë„í•œ ë³€ë™ìœ¼ë¡œ ë‚˜íƒ€ë‚¨
            ringing_level = torch.std(laplacian)
            
            return ringing_level / 10.0  # ì •ê·œí™”
            
        except Exception as e:
            logger.warning(f"ë§ì‰ ì•„í‹°íŒ©íŠ¸ ê²€ì¶œ ì‹¤íŒ¨: {e}")
            return torch.tensor(0.0)
    
    # =================================================================
    # í—¬í¼ ë©”ì„œë“œë“¤
    # =================================================================
    
    def _count_face_regions(self, image: torch.Tensor) -> int:
        """ì–¼êµ´ ì˜ì—­ ì¹´ìš´íŠ¸ (ê°„ë‹¨ ë²„ì „)"""
        try:
            # ê°„ë‹¨í•œ ì–¼êµ´ ì˜ì—­ ì¶”ì •
            # ì‹¤ì œë¡œëŠ” ì–¼êµ´ ê²€ì¶œê¸°ë¥¼ ì‚¬ìš©í•´ì•¼ í•¨
            return 1  # ê¸°ë³¸ê°’
            
        except Exception as e:
            logger.warning(f"ì–¼êµ´ ì˜ì—­ ì¹´ìš´íŠ¸ ì‹¤íŒ¨: {e}")
            return 0
    
    def _estimate_artifacts_removed(self, original: torch.Tensor, enhanced: torch.Tensor) -> float:
        """ì œê±°ëœ ì•„í‹°íŒ©íŠ¸ ì¶”ì •"""
        try:
            orig_artifacts = self._estimate_artifact_level(original)
            enhanced_artifacts = self._estimate_artifact_level(enhanced)
            
            artifacts_removed = float(orig_artifacts - enhanced_artifacts)
            
            return max(0.0, artifacts_removed)
            
        except Exception as e:
            logger.warning(f"ì•„í‹°íŒ©íŠ¸ ì œê±° ì¶”ì • ì‹¤íŒ¨: {e}")
            return 0.0
    
    def _calculate_color_balance_improvement(self, original: torch.Tensor, enhanced: torch.Tensor) -> float:
        """ìƒ‰ìƒ ê· í˜• ê°œì„  ê³„ì‚°"""
        try:
            orig_balance = self._calculate_color_naturalness(original)
            enhanced_balance = self._calculate_color_naturalness(enhanced)
            
            improvement = enhanced_balance - orig_balance
            
            return float(max(0.0, improvement))
            
        except Exception as e:
            logger.warning(f"ìƒ‰ìƒ ê· í˜• ê°œì„  ê³„ì‚° ì‹¤íŒ¨: {e}")
            return 0.0
    
    def _calculate_saturation_change(self, original: torch.Tensor, enhanced: torch.Tensor) -> float:
        """ì±„ë„ ë³€í™” ê³„ì‚°"""
        try:
            orig_saturation = torch.std(original, dim=1).mean()
            enhanced_saturation = torch.std(enhanced, dim=1).mean()
            
            saturation_change = float(enhanced_saturation - orig_saturation)
            
            return saturation_change
            
        except Exception as e:
            logger.warning(f"ì±„ë„ ë³€í™” ê³„ì‚° ì‹¤íŒ¨: {e}")
            return 0.0
    
    def _calculate_noise_reduction(self, original: torch.Tensor, enhanced: torch.Tensor) -> float:
        """ë…¸ì´ì¦ˆ ê°ì†ŒëŸ‰ ê³„ì‚°"""
        try:
            # ê³ ì£¼íŒŒ ë…¸ì´ì¦ˆ ë¹„êµ
            orig_noise = torch.std(self._extract_high_frequency(original))
            enhanced_noise = torch.std(self._extract_high_frequency(enhanced))
            
            noise_reduction = float(orig_noise - enhanced_noise)
            
            return max(0.0, noise_reduction)
            
        except Exception as e:
            logger.warning(f"ë…¸ì´ì¦ˆ ê°ì†ŒëŸ‰ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return 0.0
    
    def _calculate_edge_improvement(self, original: torch.Tensor, enhanced: torch.Tensor) -> float:
        """ì—£ì§€ ê°œì„  ê³„ì‚°"""
        try:
            # ì—£ì§€ ê°•ë„ ë¹„êµ
            orig_edges = self._calculate_edge_strength(original)
            enhanced_edges = self._calculate_edge_strength(enhanced)
            
            edge_improvement = float(enhanced_edges - orig_edges)
            
            return max(0.0, edge_improvement)
            
        except Exception as e:
            logger.warning(f"ì—£ì§€ ê°œì„  ê³„ì‚° ì‹¤íŒ¨: {e}")
            return 0.0
    
    def _calculate_edge_strength(self, image: torch.Tensor) -> torch.Tensor:
        """ì—£ì§€ ê°•ë„ ê³„ì‚°"""
        try:
            # Sobel í•„í„°
            sobel_x = torch.tensor([[[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]]], 
                                 dtype=torch.float32, device=image.device)
            sobel_y = torch.tensor([[[-1, -2, -1], [0, 0, 0], [1, 2, 1]]], 
                                 dtype=torch.float32, device=image.device)
            
            # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜
            if image.shape[1] == 3:
                gray = 0.299 * image[:, 0:1] + 0.587 * image[:, 1:2] + 0.114 * image[:, 2:3]
            else:
                gray = image
            
            # Sobel ì ìš©
            edge_x = F.conv2d(gray, sobel_x.unsqueeze(0), padding=1)
            edge_y = F.conv2d(gray, sobel_y.unsqueeze(0), padding=1)
            
            # ì—£ì§€ í¬ê¸°
            edge_magnitude = torch.sqrt(edge_x ** 2 + edge_y ** 2)
            
            return torch.mean(edge_magnitude)
            
        except Exception as e:
            logger.warning(f"ì—£ì§€ ê°•ë„ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return torch.tensor(0.0)
    
    def _update_processing_stats(self, processing_time: float, quality_score: float):
        """ì²˜ë¦¬ í†µê³„ ì—…ë°ì´íŠ¸"""
        try:
            self.processing_stats['total_images'] += 1
            
            # í‰ê·  ì‹œê°„ ì—…ë°ì´íŠ¸
            total_images = self.processing_stats['total_images']
            old_avg_time = self.processing_stats['average_time']
            self.processing_stats['average_time'] = (
                (old_avg_time * (total_images - 1) + processing_time) / total_images
            )
            
            # ì„±ê³µë¥  ì—…ë°ì´íŠ¸ (í’ˆì§ˆ ì ìˆ˜ 0.6 ì´ìƒì„ ì„±ê³µìœ¼ë¡œ ê°„ì£¼)
            success_count = self.processing_stats.get('success_count', 0)
            if quality_score >= 0.6:
                success_count += 1
            
            self.processing_stats['success_count'] = success_count
            self.processing_stats['enhancement_success_rate'] = success_count / total_images
            
            # ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± ê³„ì‚°
            if self.memory_manager:
                memory_usage = self.memory_manager.get_memory_usage()
                self.processing_stats['memory_efficiency'] = 1.0 - (memory_usage / self.memory_gb)
            
        except Exception as e:
            logger.warning(f"í†µê³„ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
    
    # =================================================================
    # Pipeline Manager í˜¸í™˜ ë©”ì„œë“œë“¤
    # =================================================================
    
    async def get_model_info(self) -> Dict[str, Any]:
        """ëª¨ë¸ ì •ë³´ ë°˜í™˜ (Pipeline Manager í˜¸í™˜)"""
        return {
            "step_name": "PostProcessing",
            "version": "4.0-m3max",
            "device": self.device,
            "device_type": self.device_type,
            "memory_gb": self.memory_gb,
            "is_m3_max": self.is_m3_max,
            "optimization_enabled": self.optimization_enabled,
            "initialized": self.is_initialized,
            "capabilities": {
                "super_resolution": bool(self.real_esrgan),
                "face_enhancement": bool(self.gfpgan),
                "image_restoration": bool(self.codeformer),
                "color_correction": bool(self.color_enhancer),
                "noise_reduction": bool(self.noise_reducer),
                "edge_enhancement": bool(self.edge_enhancer),
                "neural_enhancement": self.enable_neural_enhancement,
                "m3_max_acceleration": self.is_m3_max and self.device == 'mps'
            },
            "performance_settings": {
                "batch_size": self.batch_size,
                "tile_size": self.tile_size,
                "quality_level": self.enhancement_config.get('quality_level', 'high'),
                "use_mps": self.use_mps
            },
            "processing_stats": self.processing_stats,
            "enhancement_config": self.enhancement_config
        }
    
    async def get_processing_stats(self) -> Dict[str, Any]:
        """ì²˜ë¦¬ í†µê³„ ë°˜í™˜"""
        return {
            **self.processing_stats,
            'device': self.device,
            'device_type': self.device_type,
            'is_m3_max': self.is_m3_max,
            'models_loaded': {
                'real_esrgan': self.real_esrgan is not None,
                'gfpgan': self.gfpgan is not None,
                'codeformer': self.codeformer is not None,
                'color_enhancer': self.color_enhancer is not None,
                'noise_reducer': self.noise_reducer is not None,
                'edge_enhancer': self.edge_enhancer is not None
            },
            'is_initialized': self.is_initialized
        }
    
    async def cleanup(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬ (Pipeline Manager í˜¸í™˜)"""
        try:
            logger.info("ğŸ§¹ í›„ì²˜ë¦¬ ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì‹œì‘...")
            
            # ëª¨ë¸ ì •ë¦¬
            if self.real_esrgan and hasattr(self.real_esrgan, 'cleanup'):
                await self.real_esrgan.cleanup()
            
            if self.gfpgan and hasattr(self.gfpgan, 'cleanup'):
                await self.gfpgan.cleanup()
            
            if self.codeformer and hasattr(self.codeformer, 'cleanup'):
                await self.codeformer.cleanup()
            
            # ë©”ëª¨ë¦¬ ì •ë¦¬
            if self.memory_manager:
                await self.memory_manager.cleanup()
            
            # GPU ë©”ëª¨ë¦¬ ì •ë¦¬
            if self.use_mps:
                if hasattr(torch.backends.mps, 'empty_cache'):
                    torch.backends.mps.empty_cache()
                elif hasattr(torch.mps, 'synchronize'):
                    torch.mps.synchronize()
            elif torch.cuda.is_available():
                torch.cuda.empty_cache()
            
            # ì‹œìŠ¤í…œ ë©”ëª¨ë¦¬ ì •ë¦¬
            import gc
            gc.collect()
            
            self.is_initialized = False
            logger.info("âœ… í›„ì²˜ë¦¬ ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì™„ë£Œ")
            
        except Exception as e:
            logger.warning(f"ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")


# === M3 Max ìµœì í™” í´ë°± í´ë˜ìŠ¤ë“¤ ===

class M3MaxUpscaler:
    """M3 Max ìµœì í™” ì—…ìŠ¤ì¼€ì¼ëŸ¬"""
    
    def __init__(self, device: str = 'mps', scale_factor: int = 4, use_neural: bool = True):
        self.device = device
        self.scale_factor = scale_factor
        self.use_neural = use_neural
    
    def upscale(self, image: torch.Tensor) -> torch.Tensor:
        """M3 Max ìµœì í™” ì—…ìŠ¤ì¼€ì¼ë§"""
        try:
            b, c, h, w = image.shape
            new_h, new_w = h * self.scale_factor, w * self.scale_factor
            
            if self.use_neural and self.device == 'mps':
                # M3 Max Neural Engine í™œìš© (ê·¼ì‚¬)
                # ì‹¤ì œë¡œëŠ” Metal Performance Shaders ì‚¬ìš©
                upscaled = F.interpolate(
                    image, 
                    size=(new_h, new_w), 
                    mode='bicubic', 
                    align_corners=False,
                    antialias=True
                )
                
                # ì¶”ê°€ ì„ ëª…í™”
                kernel = torch.tensor([[[-0.5, -0.5, -0.5], [-0.5, 5, -0.5], [-0.5, -0.5, -0.5]]], 
                                    dtype=torch.float32, device=self.device) / 4.0
                sharpened = F.conv2d(upscaled, kernel.repeat(c, 1, 1, 1), padding=1, groups=c)
                upscaled = torch.clamp(sharpened, 0.0, 1.0)
                
            else:
                # ê¸°ë³¸ ë°”ì´íë¹… ì—…ìŠ¤ì¼€ì¼ë§
                upscaled = F.interpolate(
                    image, 
                    size=(new_h, new_w), 
                    mode='bicubic', 
                    align_corners=False
                )
            
            return upscaled
            
        except Exception as e:
            logger.warning(f"M3 Max ì—…ìŠ¤ì¼€ì¼ë§ ì‹¤íŒ¨: {e}")
            return image
    
    async def cleanup(self):
        pass


class M3MaxFaceEnhancer:
    """M3 Max ìµœì í™” ì–¼êµ´ í–¥ìƒê¸°"""
    
    def __init__(self, device: str = 'mps', enhancement_strength: float = 1.0):
        self.device = device
        self.enhancement_strength = enhancement_strength
    
    def process(self, image: torch.Tensor) -> torch.Tensor:
        """M3 Max ì–¼êµ´ í–¥ìƒ"""
        try:
            # ê³ ê¸‰ ì–¸ìƒµ ë§ˆìŠ¤í¬ ì ìš©
            kernel = torch.tensor([[[-1, -2, -1], [-2, 13, -2], [-1, -2, -1]]], 
                                dtype=torch.float32, device=self.device) / 8.0 * self.enhancement_strength
            
            if image.shape[1] == 3:
                enhanced = F.conv2d(image, kernel.repeat(3, 1, 1, 1), padding=1, groups=3)
            else:
                enhanced = F.conv2d(image, kernel, padding=1)
            
            return torch.clamp(enhanced, 0.0, 1.0)
            
        except Exception as e:
            logger.warning(f"M3 Max ì–¼êµ´ í–¥ìƒ ì‹¤íŒ¨: {e}")
            return image
    
    async def cleanup(self):
        pass


class M3MaxImageRestorer:
    """M3 Max ìµœì í™” ì´ë¯¸ì§€ ë³µì›ê¸°"""
    
    def __init__(self, device: str = 'mps', restoration_strength: float = 1.0):
        self.device = device
        self.restoration_strength = restoration_strength
    
    def process(self, image: torch.Tensor) -> torch.Tensor:
        """M3 Max ì´ë¯¸ì§€ ë³µì›"""
        try:
            # ì ì‘ì  ê°€ìš°ì‹œì•ˆ ë…¸ì´ì¦ˆ ì œê±°
            kernel_size = int(3 * self.restoration_strength)
            if kernel_size % 2 == 0:
                kernel_size += 1
            
            sigma = 0.5 * self.restoration_strength
            
            # ê°€ìš°ì‹œì•ˆ ì»¤ë„ ìƒì„±
            coords = torch.arange(kernel_size, dtype=torch.float32, device=self.device)
            coords -= kernel_size // 2
            g = torch.exp(-(coords ** 2) / (2 * sigma ** 2))
            g /= g.sum()
            
            kernel = g[:, None] * g[None, :]
            kernel = kernel.expand(image.shape[1], 1, kernel_size, kernel_size)
            
            # ì ìš©
            restored = F.conv2d(image, kernel, padding=kernel_size//2, groups=image.shape[1])
            
            # ì›ë³¸ê³¼ ë¸”ë Œë”©
            alpha = 0.7 * self.restoration_strength
            final = alpha * restored + (1 - alpha) * image
            
            return final
            
        except Exception as e:
            logger.warning(f"M3 Max ì´ë¯¸ì§€ ë³µì› ì‹¤íŒ¨: {e}")
            return image
    
    async def cleanup(self):
        pass


class ColorEnhancer:
    """M3 Max ìµœì í™” ìƒ‰ìƒ í–¥ìƒê¸°"""
    
    def __init__(self, device: str = 'mps', m3_max_mode: bool = True):
        self.device = device
        self.m3_max_mode = m3_max_mode
    
    def correct_colors(self, image: torch.Tensor) -> torch.Tensor:
        """M3 Max ìƒ‰ìƒ ë³´ì •"""
        try:
            if self.m3_max_mode:
                # M3 Max ì •ë°€ ìƒ‰ìƒ ë³´ì •
                corrected = self._advanced_color_correction(image)
            else:
                # ê¸°ë³¸ ìƒ‰ìƒ ë³´ì •
                corrected = self._basic_color_correction(image)
            
            return torch.clamp(corrected, 0.0, 1.0)
            
        except Exception as e:
            logger.warning(f"ìƒ‰ìƒ ë³´ì • ì‹¤íŒ¨: {e}")
            return image
    
    def _advanced_color_correction(self, image: torch.Tensor) -> torch.Tensor:
        """ê³ ê¸‰ ìƒ‰ìƒ ë³´ì •"""
        # ì±„ë„ë³„ í‰ê·  ê³„ì‚°
        r_mean = torch.mean(image[:, 0])
        g_mean = torch.mean(image[:, 1])
        b_mean = torch.mean(image[:, 2])
        
        overall_mean = (r_mean + g_mean + b_mean) / 3.0
        
        # ì ì‘ì  ì¡°ì • ê³„ìˆ˜
        r_factor = torch.clamp(overall_mean / (r_mean + 1e-8), 0.9, 1.1)
        g_factor = torch.clamp(overall_mean / (g_mean + 1e-8), 0.9, 1.1)
        b_factor = torch.clamp(overall_mean / (b_mean + 1e-8), 0.9, 1.1)
        
        # ë¶€ë“œëŸ¬ìš´ ì¡°ì •
        corrected = image.clone()
        corrected[:, 0] *= (1.0 + 0.1 * (r_factor - 1.0))
        corrected[:, 1] *= (1.0 + 0.1 * (g_factor - 1.0))
        corrected[:, 2] *= (1.0 + 0.1 * (b_factor - 1.0))
        
        return corrected
    
    def _basic_color_correction(self, image: torch.Tensor) -> torch.Tensor:
        """ê¸°ë³¸ ìƒ‰ìƒ ë³´ì •"""
        # ê°„ë‹¨í•œ ìƒ‰ìƒ ê· í˜• ì¡°ì •
        r_mean = torch.mean(image[:, 0])
        g_mean = torch.mean(image[:, 1])
        b_mean = torch.mean(image[:, 2])
        
        overall_mean = (r_mean + g_mean + b_mean) / 3.0
        
        r_factor = overall_mean / (r_mean + 1e-8)
        g_factor = overall_mean / (g_mean + 1e-8)
        b_factor = overall_mean / (b_mean + 1e-8)
        
        # ë¶€ë“œëŸ¬ìš´ ì¡°ì •
        r_factor = 1.0 + 0.05 * (r_factor - 1.0)
        g_factor = 1.0 + 0.05 * (g_factor - 1.0)
        b_factor = 1.0 + 0.05 * (b_factor - 1.0)
        
        corrected = image.clone()
        corrected[:, 0] *= r_factor
        corrected[:, 1] *= g_factor
        corrected[:, 2] *= b_factor
        
        return corrected


class NoiseReducer:
    """M3 Max ìµœì í™” ë…¸ì´ì¦ˆ ì œê±°ê¸°"""
    
    def __init__(self, device: str = 'mps', m3_max_mode: bool = True):
        self.device = device
        self.m3_max_mode = m3_max_mode
    
    def reduce_noise(self, image: torch.Tensor) -> torch.Tensor:
        """M3 Max ë…¸ì´ì¦ˆ ì œê±°"""
        try:
            if self.m3_max_mode:
                # M3 Max ê³ ê¸‰ ë…¸ì´ì¦ˆ ì œê±°
                denoised = self._advanced_noise_reduction(image)
            else:
                # ê¸°ë³¸ ë…¸ì´ì¦ˆ ì œê±°
                denoised = self._basic_noise_reduction(image)
            
            return denoised
            
        except Exception as e:
            logger.warning(f"ë…¸ì´ì¦ˆ ì œê±° ì‹¤íŒ¨: {e}")
            return image
    
    def _advanced_noise_reduction(self, image: torch.Tensor) -> torch.Tensor:
        """ê³ ê¸‰ ë…¸ì´ì¦ˆ ì œê±° (ì–‘ë°©í–¥ í•„í„° ê·¼ì‚¬)"""
        # ë‹¤ì¤‘ ìŠ¤ì¼€ì¼ ê°€ìš°ì‹œì•ˆ ë¸”ëŸ¬
        scales = [0.5, 1.0, 1.5]
        blurred_images = []
        
        for sigma in scales:
            kernel_size = int(4 * sigma) + 1
            if kernel_size % 2 == 0:
                kernel_size += 1
            
            coords = torch.arange(kernel_size, dtype=torch.float32, device=self.device)
            coords -= kernel_size // 2
            g = torch.exp(-(coords ** 2) / (2 * sigma ** 2))
            g /= g.sum()
            
            kernel = g[:, None] * g[None, :]
            kernel = kernel.expand(image.shape[1], 1, kernel_size, kernel_size)
            
            blurred = F.conv2d(image, kernel, padding=kernel_size//2, groups=image.shape[1])
            blurred_images.append(blurred)
        
        # ê°€ì¤‘ í‰ê· 
        weights = [0.5, 0.3, 0.2]
        denoised = sum(w * img for w, img in zip(weights, blurred_images))
        
        # ì›ë³¸ê³¼ ë¸”ë Œë”© (ë””í…Œì¼ ë³´ì¡´)
        blending_factor = 0.7
        result = blending_factor * denoised + (1 - blending_factor) * image
        
        return result
    
    def _basic_noise_reduction(self, image: torch.Tensor) -> torch.Tensor:
        """ê¸°ë³¸ ë…¸ì´ì¦ˆ ì œê±°"""
        kernel_size = 5
        sigma = 1.0
        
        coords = torch.arange(kernel_size, dtype=torch.float32, device=self.device)
        coords -= kernel_size // 2
        g = torch.exp(-(coords ** 2) / (2 * sigma ** 2))
        g /= g.sum()
        
        kernel = g[:, None] * g[None, :]
        kernel = kernel.expand(image.shape[1], 1, kernel_size, kernel_size)
        
        denoised = F.conv2d(image, kernel, padding=kernel_size//2, groups=image.shape[1])
        
        # ì›ë³¸ê³¼ ë¸”ë Œë”©
        blending_factor = 0.6
        result = blending_factor * denoised + (1 - blending_factor) * image
        
        return result


class EdgeEnhancer:
    """M3 Max ìµœì í™” ì—£ì§€ í–¥ìƒê¸°"""
    
    def __init__(self, device: str = 'mps', m3_max_mode: bool = True):
        self.device = device
        self.m3_max_mode = m3_max_mode
    
    def enhance_edges(self, image: torch.Tensor) -> torch.Tensor:
        """M3 Max ì—£ì§€ í–¥ìƒ"""
        try:
            if self.m3_max_mode:
                # M3 Max ê³ ê¸‰ ì—£ì§€ í–¥ìƒ
                enhanced = self._advanced_edge_enhancement(image)
            else:
                # ê¸°ë³¸ ì—£ì§€ í–¥ìƒ
                enhanced = self._basic_edge_enhancement(image)
            
            return torch.clamp(enhanced, 0.0, 1.0)
            
        except Exception as e:
            logger.warning(f"ì—£ì§€ í–¥ìƒ ì‹¤íŒ¨: {e}")
            return image
    
    def _advanced_edge_enhancement(self, image: torch.Tensor) -> torch.Tensor:
        """ê³ ê¸‰ ì—£ì§€ í–¥ìƒ (ì ì‘ì  ì–¸ìƒµ ë§ˆìŠ¤í¬)"""
        # 1. ì—£ì§€ ê²€ì¶œ
        sobel_x = torch.tensor([[[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]]], 
                             dtype=torch.float32, device=self.device)
        sobel_y = torch.tensor([[[-1, -2, -1], [0, 0, 0], [1, 2, 1]]], 
                             dtype=torch.float32, device=self.device)
        
        # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜
        if image.shape[1] == 3:
            gray = 0.299 * image[:, 0:1] + 0.587 * image[:, 1:2] + 0.114 * image[:, 2:3]
        else:
            gray = image
        
        # ì—£ì§€ í¬ê¸° ê³„ì‚°
        edge_x = F.conv2d(gray, sobel_x.unsqueeze(0), padding=1)
        edge_y = F.conv2d(gray, sobel_y.unsqueeze(0), padding=1)
        edge_magnitude = torch.sqrt(edge_x ** 2 + edge_y ** 2)
        
        # ì ì‘ì  ë§ˆìŠ¤í¬ ìƒì„±
        edge_mask = torch.sigmoid(edge_magnitude * 5.0)  # ì—£ì§€ ì˜ì—­ ê°•ì¡°
        
        # 2. ì–¸ìƒµ ë§ˆìŠ¤í¬
        kernel_size = 5
        sigma = 1.5
        
        coords = torch.arange(kernel_size, dtype=torch.float32, device=self.device)
        coords -= kernel_size // 2
        g = torch.exp(-(coords ** 2) / (2 * sigma ** 2))
        g /= g.sum()
        
        kernel = g[:, None] * g[None, :]
        kernel = kernel.expand(image.shape[1], 1, kernel_size, kernel_size)
        
        blurred = F.conv2d(image, kernel, padding=kernel_size//2, groups=image.shape[1])
        
        # 3. ì ì‘ì  í–¥ìƒ
        strength = 0.3
        unsharp = image + strength * (image - blurred)
        
        # ì—£ì§€ ì˜ì—­ì—ì„œë§Œ ê°•í•˜ê²Œ ì ìš©
        enhanced = image * (1 - edge_mask) + unsharp * edge_mask
        
        return enhanced
    
    def _basic_edge_enhancement(self, image: torch.Tensor) -> torch.Tensor:
        """ê¸°ë³¸ ì—£ì§€ í–¥ìƒ"""
        # ê¸°ë³¸ ì–¸ìƒµ ë§ˆìŠ¤í¬
        kernel_size = 5
        sigma = 1.0
        
        coords = torch.arange(kernel_size, dtype=torch.float32, device=self.device)
        coords -= kernel_size // 2
        g = torch.exp(-(coords ** 2) / (2 * sigma ** 2))
        g /= g.sum()
        
        kernel = g[:, None] * g[None, :]
        kernel = kernel.expand(image.shape[1], 1, kernel_size, kernel_size)
        
        blurred = F.conv2d(image, kernel, padding=kernel_size//2, groups=image.shape[1])
        
        # ì–¸ìƒµ ë§ˆìŠ¤í¬
        strength = 0.2
        enhanced = image + strength * (image - blurred)
        
        return enhanced