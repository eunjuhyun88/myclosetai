#!/usr/bin/env python3
"""
ğŸ”¥ MyCloset AI - Step 07: í›„ì²˜ë¦¬ (Post Processing) - ì™„ì „í•œ ì˜ì¡´ì„± ì£¼ì… + AI ì—°ë™ v3.0
==========================================================================================

âœ… TYPE_CHECKING íŒ¨í„´ìœ¼ë¡œ ìˆœí™˜ì°¸ì¡° ì™„ì „ ë°©ì§€
âœ… ë™ì  import í•¨ìˆ˜ë¡œ ëŸ°íƒ€ì„ ì˜ì¡´ì„± í•´ê²°
âœ… StepFactory â†’ ModelLoader â†’ BaseStepMixin â†’ ì˜ì¡´ì„± ì£¼ì… â†’ ì™„ì„±ëœ Step êµ¬ì¡°
âœ… ì²´í¬í¬ì¸íŠ¸ â†’ ì‹¤ì œ AI ëª¨ë¸ í´ë˜ìŠ¤ ë³€í™˜ ì™„ì „ êµ¬í˜„
âœ… ì‹¤ì œ AI ëª¨ë¸ ì¶”ë¡  ì™„ì „ êµ¬í˜„ (SRResNet, DenoiseNet)
âœ… M3 Max 128GB ë©”ëª¨ë¦¬ ìµœì í™”
âœ… conda í™˜ê²½ ìš°ì„  ì§€ì›
âœ… ë¹„ë™ê¸° ì²˜ë¦¬ ì™„ì „ í•´ê²°
âœ… ì‹œê°í™” ê¸°ëŠ¥ í†µí•©
âœ… í”„ë¡œë•ì…˜ ë ˆë²¨ ì•ˆì •ì„±
âœ… ì˜ì¡´ì„± ì£¼ì… êµ¬ì¡° ì™„ì „ ê°œì„ 
âœ… ì´ˆê¸°í™” ë¡œì§ ê°„ì†Œí™”

í•µì‹¬ ì•„í‚¤í…ì²˜:
StepFactory â†’ ModelLoader (ìƒì„±) â†’ BaseStepMixin (ìƒì„±) â†’ ì˜ì¡´ì„± ì£¼ì… â†’ PostProcessingStep

ì²˜ë¦¬ íë¦„:
1. StepFactory â†’ ModelLoader â†’ BaseStepMixin â†’ ì˜ì¡´ì„± ì£¼ì…
2. ì²´í¬í¬ì¸íŠ¸ ë¡œë”© â†’ AI ëª¨ë¸ í´ë˜ìŠ¤ ìƒì„± â†’ ê°€ì¤‘ì¹˜ ë¡œë”©  
3. í›„ì²˜ë¦¬ AI ì¶”ë¡  â†’ í’ˆì§ˆ í–¥ìƒ â†’ ì‹œê°í™” ìƒì„±
4. í’ˆì§ˆ í‰ê°€ â†’ ì‹œê°í™” ìƒì„± â†’ API ì‘ë‹µ

íŒŒì¼ ìœ„ì¹˜: backend/app/ai_pipeline/steps/step_07_post_processing.py
ì‘ì„±ì: MyCloset AI Team  
ë‚ ì§œ: 2025-07-23
ë²„ì „: v3.0 (Complete Dependency Injection AI Implementation)
"""

# ==============================================
# ğŸ”¥ 1. Import ì„¹ì…˜ (TYPE_CHECKING íŒ¨í„´)
# ==============================================

import os
import sys
import gc
import time
import asyncio
import logging
import threading
import traceback
import hashlib
import json
import base64
import weakref
import math
from pathlib import Path
from typing import Dict, Any, Optional, Tuple, List, Union, Callable, TYPE_CHECKING
from dataclasses import dataclass, field
from enum import Enum, IntEnum
from io import BytesIO
from concurrent.futures import ThreadPoolExecutor, as_completed
from functools import lru_cache, wraps
from contextlib import asynccontextmanager

# TYPE_CHECKINGìœ¼ë¡œ ìˆœí™˜ì°¸ì¡° ë°©ì§€
if TYPE_CHECKING:
    from app.ai_pipeline.utils.model_loader import ModelLoader
    from ..factories.step_factory import StepFactory
    from ..steps.base_step_mixin import BaseStepMixin

logger = logging.getLogger(__name__)
# ==============================================
# ğŸ”¥ 2. conda í™˜ê²½ ë° ì‹œìŠ¤í…œ ì²´í¬
# ==============================================

CONDA_INFO = {
    'conda_env': os.environ.get('CONDA_DEFAULT_ENV', 'none'),
    'conda_prefix': os.environ.get('CONDA_PREFIX', 'none'), 
    'python_path': os.path.dirname(os.__file__)
}

def detect_m3_max() -> bool:
    """M3 Max ê°ì§€"""
    try:
        import platform
        import subprocess
        if platform.system() == 'Darwin':
            result = subprocess.run(
                ['sysctl', '-n', 'machdep.cpu.brand_string'],
                capture_output=True, text=True, timeout=5
            )
            return 'M3' in result.stdout
    except:
        pass
    return False

IS_M3_MAX = detect_m3_max()

# ==============================================
# ğŸ”¥ 3. ì•ˆì „í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ import
# ==============================================

# PyTorch ì•ˆì „ import
TORCH_AVAILABLE = False
MPS_AVAILABLE = False
try:
    os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '1'
    os.environ['PYTORCH_MPS_HIGH_WATERMARK_RATIO'] = '0.0'
    
    import torch
    import torch.nn as nn
    import torch.nn.functional as F
    from torchvision import transforms
    
    TORCH_AVAILABLE = True
    
    if hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
        MPS_AVAILABLE = True
        
except ImportError as e:
    print(f"âš ï¸ PyTorch ì—†ìŒ: {e}")

# ì´ë¯¸ì§€ ì²˜ë¦¬ ë¼ì´ë¸ŒëŸ¬ë¦¬
NUMPY_AVAILABLE = False
PIL_AVAILABLE = False
OPENCV_AVAILABLE = False

try:
    import numpy as np
    NUMPY_AVAILABLE = True
except ImportError:
    print("âš ï¸ NumPy ì—†ìŒ")

try:
    from PIL import Image, ImageEnhance, ImageFilter, ImageOps, ImageDraw, ImageFont
    PIL_AVAILABLE = True
except ImportError:
    print("âš ï¸ PIL ì—†ìŒ")

try:
    os.environ['OPENCV_IO_ENABLE_OPENEXR'] = '0'
    os.environ['OPENCV_IO_ENABLE_JASPER'] = '0'
    
    import cv2
    OPENCV_AVAILABLE = True
except ImportError:
    print("âš ï¸ OpenCV ì—†ìŒ")
    
    # OpenCV í´ë°±
    class OpenCVFallback:
        def __init__(self):
            self.INTER_LINEAR = 1
            self.INTER_CUBIC = 2
            self.COLOR_BGR2RGB = 4
            self.COLOR_RGB2BGR = 3
            
        def resize(self, img, size, interpolation=1):
            try:
                from PIL import Image
                if hasattr(img, 'shape'):
                    pil_img = Image.fromarray(img)
                    resized = pil_img.resize(size)
                    return np.array(resized) if NUMPY_AVAILABLE else img
                return img
            except:
                return img
                
        def cvtColor(self, img, code):
            if hasattr(img, 'shape') and len(img.shape) == 3:
                if code in [3, 4]:  # BGR<->RGB
                    return img[:, :, ::-1]
            return img
    
    cv2 = OpenCVFallback()

# ê³ ê¸‰ ë¼ì´ë¸ŒëŸ¬ë¦¬ë“¤ (ì˜µì…˜)
SCIPY_AVAILABLE = False
SKIMAGE_AVAILABLE = False

try:
    from scipy.ndimage import gaussian_filter, median_filter
    from scipy.signal import convolve2d
    SCIPY_AVAILABLE = True
except ImportError:
    pass

try:
    from skimage import restoration, filters, exposure, morphology
    from skimage.metrics import structural_similarity, peak_signal_noise_ratio
    SKIMAGE_AVAILABLE = True
except ImportError:
    pass

# GPU ì„¤ì •
try:
    from app.core.gpu_config import safe_mps_empty_cache
except ImportError:
    def safe_mps_empty_cache():
        import gc
        gc.collect()
        return {"success": True, "method": "fallback_gc"}

# ë¡œê¹… ì„¤ì •
logger = logging.getLogger(__name__)

# ==============================================
# ğŸ”¥ 4. ë™ì  import í•¨ìˆ˜ë“¤ (ìˆœí™˜ì°¸ì¡° ë°©ì§€)
# ==============================================

def dynamic_import_base_step_mixin():
    """BaseStepMixin ë™ì  import (ìˆœí™˜ì°¸ì¡° ë°©ì§€)"""
    try:
        from ..steps.base_step_mixin import BaseStepMixin
        return BaseStepMixin
    except ImportError as e:
        logger.warning(f"BaseStepMixin import ì‹¤íŒ¨: {e}")
        return None

def dynamic_import_model_loader():
    """ModelLoader ë™ì  import (ìˆœí™˜ì°¸ì¡° ë°©ì§€)"""
    try:
        from app.ai_pipeline.utils.model_loader import ModelLoader, get_global_model_loader
        return ModelLoader, get_global_model_loader
    except ImportError as e:
        logger.warning(f"ModelLoader import ì‹¤íŒ¨: {e}")
        return None, None

def dynamic_import_pytorch_safe_ops():
    """PyTorch ì•ˆì „ ì—°ì‚° ë™ì  import"""
    try:
        from app.ai_pipeline.utils.pytorch_safe_ops import (
            safe_max, safe_amax, safe_argmax,
            extract_keypoints_from_heatmaps,
            tensor_to_pil_conda_optimized
        )
        return {
            'safe_max': safe_max,
            'safe_amax': safe_amax, 
            'safe_argmax': safe_argmax,
            'extract_keypoints_from_heatmaps': extract_keypoints_from_heatmaps,
            'tensor_to_pil_conda_optimized': tensor_to_pil_conda_optimized
        }
    except ImportError as e:
        logger.warning(f"PyTorch ì•ˆì „ ì—°ì‚° import ì‹¤íŒ¨: {e}")
        return {}

# ==============================================
# ğŸ”¥ 5. ë°ì´í„° êµ¬ì¡° ì •ì˜
# ==============================================

class EnhancementMethod(Enum):
    """í–¥ìƒ ë°©ë²•"""
    SUPER_RESOLUTION = "super_resolution"
    NOISE_REDUCTION = "noise_reduction"
    DENOISING = "denoising"
    SHARPENING = "sharpening"
    COLOR_CORRECTION = "color_correction"
    CONTRAST_ENHANCEMENT = "contrast_enhancement"
    FACE_ENHANCEMENT = "face_enhancement"
    EDGE_ENHANCEMENT = "edge_enhancement"
    TEXTURE_ENHANCEMENT = "texture_enhancement"
    AUTO = "auto"

class QualityLevel(Enum):
    """í’ˆì§ˆ ë ˆë²¨"""
    FAST = "fast"
    BALANCED = "balanced"
    HIGH = "high"
    ULTRA = "ultra"
    MAXIMUM = "maximum"

class ProcessingMode(Enum):
    """ì²˜ë¦¬ ëª¨ë“œ"""
    REAL_TIME = "real_time"
    QUALITY = "quality"
    BATCH = "batch"

@dataclass
class PostProcessingConfig:
    """í›„ì²˜ë¦¬ ì„¤ì •"""
    quality_level: QualityLevel = QualityLevel.BALANCED
    processing_mode: ProcessingMode = ProcessingMode.QUALITY
    enabled_methods: List[EnhancementMethod] = field(default_factory=lambda: [
        EnhancementMethod.NOISE_REDUCTION,
        EnhancementMethod.SHARPENING,
        EnhancementMethod.COLOR_CORRECTION,
        EnhancementMethod.CONTRAST_ENHANCEMENT
    ])
    max_resolution: Tuple[int, int] = (2048, 2048)
    use_gpu_acceleration: bool = True
    preserve_original_ratio: bool = True
    apply_face_detection: bool = True
    batch_size: int = 1
    cache_size: int = 50
    enable_visualization: bool = True
    visualization_quality: str = "high"
    show_before_after: bool = True
    show_enhancement_details: bool = True

@dataclass
class PostProcessingResult:
    """í›„ì²˜ë¦¬ ê²°ê³¼"""
    success: bool
    enhanced_image: Optional[np.ndarray] = None
    quality_improvement: float = 0.0
    applied_methods: List[str] = field(default_factory=list)
    processing_time: float = 0.0
    metadata: Dict[str, Any] = field(default_factory=dict)
    error_message: Optional[str] = None

# ==============================================
# ğŸ”¥ 6. AI ì‹ ê²½ë§ ëª¨ë¸ ì •ì˜
# ==============================================

class SRResNet(nn.Module):
    """Super Resolution ResNet ëª¨ë¸"""
    
    def __init__(self, in_channels=3, out_channels=3, num_features=64, num_blocks=16):
        super(SRResNet, self).__init__()
        
        # ì´ˆê¸° ì»¨ë³¼ë£¨ì…˜
        self.conv_first = nn.Conv2d(in_channels, num_features, 9, padding=4)
        self.relu = nn.ReLU(inplace=True)
        
        # ì”ì°¨ ë¸”ë¡ë“¤
        self.res_blocks = nn.ModuleList()
        for _ in range(num_blocks):
            self.res_blocks.append(self._make_res_block(num_features))
        
        # ì—…ìƒ˜í”Œë§ ë ˆì´ì–´ë“¤
        self.upsampler = nn.Sequential(
            nn.Conv2d(num_features, num_features * 4, 3, padding=1),
            nn.PixelShuffle(2),
            nn.ReLU(inplace=True),
            nn.Conv2d(num_features, num_features * 4, 3, padding=1),
            nn.PixelShuffle(2),
            nn.ReLU(inplace=True)
        )
        
        # ìµœì¢… ì¶œë ¥
        self.conv_last = nn.Conv2d(num_features, out_channels, 9, padding=4)
    
    def _make_res_block(self, num_features):
        """ì”ì°¨ ë¸”ë¡ ìƒì„±"""
        return nn.Sequential(
            nn.Conv2d(num_features, num_features, 3, padding=1),
            nn.BatchNorm2d(num_features),
            nn.ReLU(inplace=True),
            nn.Conv2d(num_features, num_features, 3, padding=1),
            nn.BatchNorm2d(num_features)
        )
    
    def forward(self, x):
        """ìˆœì „íŒŒ"""
        feat = self.relu(self.conv_first(x))
        residual = feat
        
        # ì”ì°¨ ë¸”ë¡ë“¤ í†µê³¼
        for res_block in self.res_blocks:
            res_feat = res_block(feat)
            feat = feat + res_feat
        
        # ì—…ìƒ˜í”Œë§
        feat = self.upsampler(feat + residual)
        
        # ìµœì¢… ì¶œë ¥
        out = self.conv_last(feat)
        
        return out

class DenoiseNet(nn.Module):
    """ë…¸ì´ì¦ˆ ì œê±° ì‹ ê²½ë§"""
    
    def __init__(self, in_channels=3, out_channels=3, num_features=64):
        super(DenoiseNet, self).__init__()
        
        self.encoder = nn.Sequential(
            nn.Conv2d(in_channels, num_features, 3, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv2d(num_features, num_features, 3, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv2d(num_features, num_features * 2, 3, stride=2, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv2d(num_features * 2, num_features * 2, 3, padding=1),
            nn.ReLU(inplace=True)
        )
        
        self.decoder = nn.Sequential(
            nn.ConvTranspose2d(num_features * 2, num_features, 3, stride=2, padding=1, output_padding=1),
            nn.ReLU(inplace=True),
            nn.Conv2d(num_features, num_features, 3, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv2d(num_features, out_channels, 3, padding=1),
            nn.Sigmoid()
        )
    
    def forward(self, x):
        encoded = self.encoder(x)
        decoded = self.decoder(encoded)
        return decoded

# ==============================================
# ğŸ”¥ 7. ë©”ì¸ PostProcessingStep í´ë˜ìŠ¤ (ì™„ì „í•œ DI íŒ¨í„´)
# ==============================================

class PostProcessingStep:
    """
    7ë‹¨ê³„: í›„ì²˜ë¦¬ - ì™„ì „í•œ ì˜ì¡´ì„± ì£¼ì… íŒ¨í„´ ê¸°ë°˜ AI êµ¬í˜„
    
    âœ… TYPE_CHECKING íŒ¨í„´ìœ¼ë¡œ ìˆœí™˜ì°¸ì¡° ì™„ì „ ë°©ì§€
    âœ… ë™ì  importë¡œ ëŸ°íƒ€ì„ ì˜ì¡´ì„± í•´ê²°  
    âœ… BaseStepMixin í˜¸í™˜ ì˜ì¡´ì„± ì£¼ì… ì¸í„°í˜ì´ìŠ¤
    âœ… ì‹¤ì œ AI ëª¨ë¸ ì¶”ë¡  êµ¬í˜„
    âœ… M3 Max ìµœì í™”
    âœ… ì‹œê°í™” ê¸°ëŠ¥ í†µí•©
    """
    
    def __init__(
        self,
        device: Optional[str] = None,
        config: Optional[Dict[str, Any]] = None,
        **kwargs
    ):
        """ì´ˆê¸°í™” - ì˜ì¡´ì„± ì£¼ì… ì¤€ë¹„"""
        
        # === 1. ê¸°ë³¸ ì†ì„± ì„¤ì • ===
        self.step_name = kwargs.get('step_name', 'PostProcessingStep')
        self.step_id = kwargs.get('step_id', 7)
        self.logger = logging.getLogger(f"pipeline.{self.step_name}")
        
        # === 2. ì˜ì¡´ì„± ì£¼ì…ìš© ì†ì„±ë“¤ (BaseStepMixin í˜¸í™˜) ===
        self.model_loader = None
        self.memory_manager = None
        self.data_converter = None
        self.di_container = None
        self.step_factory = None
        self.step_interface = None
        self.model_interface = None
        
        # === 3. ì˜ì¡´ì„± ì£¼ì… ìƒíƒœ ì¶”ì  ===
        self.dependencies_injected = {
            'model_loader': False,
            'memory_manager': False,
            'data_converter': False,
            'di_container': False,
            'step_factory': False,
            'step_interface': False
        }
        
        # === 4. BaseStepMixin í˜¸í™˜ í”Œë˜ê·¸ë“¤ ===
        self.is_initialized = False
        self.is_ready = False
        self.has_model = False
        self.model_loaded = False
        
        # === 5. ë””ë°”ì´ìŠ¤ ë° ì‹œìŠ¤í…œ ì„¤ì • ===
        self.device = self._auto_detect_device(device)
        self.config = config or {}
        self.is_m3_max = IS_M3_MAX
        self.memory_gb = kwargs.get('memory_gb', 128.0 if IS_M3_MAX else 16.0)
        
        # === 6. í›„ì²˜ë¦¬ íŠ¹í™” ì„¤ì • ===
        self._setup_post_processing_config(kwargs)
        
        # === 7. AI ëª¨ë¸ ê´€ë ¨ ì´ˆê¸°í™” ===
        self.sr_model = None
        self.denoise_model = None
        self.face_detector = None
        
        # === 8. ìºì‹œ ë° ì„±ëŠ¥ ê´€ë¦¬ ===
        self.enhancement_cache = {}
        self.model_cache = {}
        self.processing_stats = {
            'total_processed': 0,
            'successful_enhancements': 0,
            'average_improvement': 0.0,
            'method_usage': {},
            'cache_hits': 0,
            'average_processing_time': 0.0
        }
        
        # === 9. ìŠ¤ë ˆë“œ í’€ ===
        max_workers = 8 if IS_M3_MAX else 4
        self.executor = ThreadPoolExecutor(
            max_workers=max_workers,
            thread_name_prefix=f"{self.step_name}_worker"
        )
        
        # === 10. ëª¨ë¸ ê²½ë¡œ ===
        # íŒŒì¼ ìœ„ì¹˜ ê¸°ë°˜ìœ¼ë¡œ backend ê²½ë¡œ ê³„ì‚°
        current_file = Path(__file__).absolute()  # step_07_post_processing.py ìœ„ì¹˜
        backend_root = current_file.parent.parent.parent.parent  # backend/ ê²½ë¡œ
        self.model_base_path = backend_root / "app" / "ai_pipeline" / "models" / "ai_models"
        self.checkpoint_path = self.model_base_path / "checkpoints" / "step_07_post_processing"
        self.checkpoint_path.mkdir(parents=True, exist_ok=True)
        
        # === 11. ì´ˆê¸°í™” ë½ ===
        self._initialization_lock = threading.RLock()
        
        self.logger.info(f"âœ… {self.step_name} ê¸°ë³¸ ì´ˆê¸°í™” ì™„ë£Œ - ë””ë°”ì´ìŠ¤: {self.device}")
        if self.is_m3_max:
            self.logger.info(f"ğŸ M3 Max ìµœì í™” ëª¨ë“œ (ë©”ëª¨ë¦¬: {self.memory_gb}GB)")
    
    def _auto_detect_device(self, preferred_device: Optional[str] = None) -> str:
        """ì§€ëŠ¥ì  ë””ë°”ì´ìŠ¤ ìë™ ê°ì§€"""
        if preferred_device:
            return preferred_device
        
        try:
            if TORCH_AVAILABLE:
                if MPS_AVAILABLE and IS_M3_MAX:
                    return 'mps'
                elif torch.cuda.is_available():
                    return 'cuda'
            return 'cpu'
        except Exception:
            return 'cpu'
    
    def _setup_post_processing_config(self, kwargs: Dict[str, Any]):
        """í›„ì²˜ë¦¬ íŠ¹í™” ì„¤ì •"""
        self.post_processing_config = PostProcessingConfig()
        
        # ì„¤ì • ì—…ë°ì´íŠ¸
        if 'quality_level' in kwargs:
            if isinstance(kwargs['quality_level'], str):
                self.post_processing_config.quality_level = QualityLevel(kwargs['quality_level'])
            else:
                self.post_processing_config.quality_level = kwargs['quality_level']
        
        # M3 Max íŠ¹í™” ì„¤ì •
        if IS_M3_MAX:
            self.post_processing_config.use_gpu_acceleration = True
            self.post_processing_config.max_resolution = (4096, 4096)
            self.post_processing_config.batch_size = min(8, max(1, int(self.memory_gb / 16)))
            self.post_processing_config.cache_size = min(100, max(25, int(self.memory_gb * 2)))
        
        # ê¸°íƒ€ ì„¤ì •ë“¤
        self.enhancement_strength = kwargs.get('enhancement_strength', 0.7)
        self.preserve_faces = kwargs.get('preserve_faces', True)
        self.auto_adjust_brightness = kwargs.get('auto_adjust_brightness', True)
        self.strict_mode = kwargs.get('strict_mode', False)
    
    # ==============================================
    # ğŸ”¥ 8. BaseStepMixin í˜¸í™˜ ì˜ì¡´ì„± ì£¼ì… ë©”ì„œë“œë“¤
    # ==============================================
    
    def set_model_loader(self, model_loader):
        """ModelLoader ì˜ì¡´ì„± ì£¼ì… (BaseStepMixin í˜¸í™˜)"""
        try:
            self.model_loader = model_loader
            self.dependencies_injected['model_loader'] = True
            self.logger.info("âœ… ModelLoader ì˜ì¡´ì„± ì£¼ì… ì™„ë£Œ")
            
            # Step ì¸í„°í˜ì´ìŠ¤ ìƒì„±
            if hasattr(model_loader, 'create_step_interface'):
                try:
                    self.model_interface = model_loader.create_step_interface(self.step_name)
                    self.dependencies_injected['step_interface'] = True
                    self.logger.info("âœ… Step ì¸í„°í˜ì´ìŠ¤ ìƒì„± ë° ì£¼ì… ì™„ë£Œ")
                except Exception as e:
                    self.logger.debug(f"Step ì¸í„°í˜ì´ìŠ¤ ìƒì„± ì‹¤íŒ¨: {e}")
                    self.model_interface = model_loader
            else:
                self.model_interface = model_loader
                
            # BaseStepMixin í˜¸í™˜ í”Œë˜ê·¸ ì—…ë°ì´íŠ¸
            self.has_model = True
            self.model_loaded = True
            
        except Exception as e:
            self.logger.error(f"âŒ ModelLoader ì˜ì¡´ì„± ì£¼ì… ì‹¤íŒ¨: {e}")
            if self.strict_mode:
                raise RuntimeError(f"Strict Mode: ModelLoader ì˜ì¡´ì„± ì£¼ì… ì‹¤íŒ¨: {e}")
    
    def set_memory_manager(self, memory_manager):
        """MemoryManager ì˜ì¡´ì„± ì£¼ì… (BaseStepMixin í˜¸í™˜)"""
        try:
            self.memory_manager = memory_manager
            self.dependencies_injected['memory_manager'] = True
            self.logger.info("âœ… MemoryManager ì˜ì¡´ì„± ì£¼ì… ì™„ë£Œ")
        except Exception as e:
            self.logger.warning(f"âš ï¸ MemoryManager ì˜ì¡´ì„± ì£¼ì… ì‹¤íŒ¨: {e}")
    
    def set_data_converter(self, data_converter):
        """DataConverter ì˜ì¡´ì„± ì£¼ì… (BaseStepMixin í˜¸í™˜)"""
        try:
            self.data_converter = data_converter
            self.dependencies_injected['data_converter'] = True
            self.logger.info("âœ… DataConverter ì˜ì¡´ì„± ì£¼ì… ì™„ë£Œ")
        except Exception as e:
            self.logger.warning(f"âš ï¸ DataConverter ì˜ì¡´ì„± ì£¼ì… ì‹¤íŒ¨: {e}")
    
    def set_di_container(self, di_container):
        """DI Container ì˜ì¡´ì„± ì£¼ì…"""
        try:
            self.di_container = di_container
            self.dependencies_injected['di_container'] = True
            self.logger.info("âœ… DI Container ì˜ì¡´ì„± ì£¼ì… ì™„ë£Œ")
        except Exception as e:
            self.logger.warning(f"âš ï¸ DI Container ì˜ì¡´ì„± ì£¼ì… ì‹¤íŒ¨: {e}")
    
    def set_step_factory(self, step_factory):
        """StepFactory ì˜ì¡´ì„± ì£¼ì…"""
        try:
            self.step_factory = step_factory
            self.dependencies_injected['step_factory'] = True
            self.logger.info("âœ… StepFactory ì˜ì¡´ì„± ì£¼ì… ì™„ë£Œ")
        except Exception as e:
            self.logger.warning(f"âš ï¸ StepFactory ì˜ì¡´ì„± ì£¼ì… ì‹¤íŒ¨: {e}")
    
    def set_step_interface(self, step_interface):
        """Step ì¸í„°í˜ì´ìŠ¤ ì˜ì¡´ì„± ì£¼ì…"""
        try:
            self.step_interface = step_interface
            self.dependencies_injected['step_interface'] = True
            self.logger.info("âœ… Step ì¸í„°í˜ì´ìŠ¤ ì˜ì¡´ì„± ì£¼ì… ì™„ë£Œ")
        except Exception as e:
            self.logger.warning(f"âš ï¸ Step ì¸í„°í˜ì´ìŠ¤ ì˜ì¡´ì„± ì£¼ì… ì‹¤íŒ¨: {e}")
    
    def get_injected_dependencies(self) -> Dict[str, bool]:
        """ì£¼ì…ëœ ì˜ì¡´ì„± ìƒíƒœ ë°˜í™˜ (BaseStepMixin í˜¸í™˜)"""
        return self.dependencies_injected.copy()
    
    # ==============================================
    # ğŸ”¥ 9. í†µì¼ëœ ì´ˆê¸°í™” ì¸í„°í˜ì´ìŠ¤ (ì˜ì¡´ì„± ì£¼ì… í›„ í˜¸ì¶œ)
    # ==============================================
    
    async def initialize(self) -> bool:
        """
        í†µì¼ëœ ì´ˆê¸°í™” ì¸í„°í˜ì´ìŠ¤ - ì˜ì¡´ì„± ì£¼ì… í›„ í˜¸ì¶œ
        StepFactoryì—ì„œ ì˜ì¡´ì„± ì£¼ì… ì™„ë£Œ í›„ ì´ ë©”ì„œë“œ í˜¸ì¶œ
        
        Returns:
            bool: ì´ˆê¸°í™” ì„±ê³µ ì—¬ë¶€
        """
        async with asyncio.Lock():
            if self.is_initialized:
                return True
        
        try:
            self.logger.info("ğŸ”„ 7ë‹¨ê³„: í›„ì²˜ë¦¬ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹œì‘...")
            
            # 1. AI ëª¨ë¸ë“¤ ì´ˆê¸°í™” (ì˜ì¡´ì„± ì£¼ì…ëœ ModelLoader í™œìš©)
            await self._initialize_ai_models()
            
            # 2. ì–¼êµ´ ê²€ì¶œê¸° ì´ˆê¸°í™”
            if self.post_processing_config.apply_face_detection:
                await self._initialize_face_detector()
            
            # 3. ì´ë¯¸ì§€ í•„í„° ì´ˆê¸°í™”
            self._initialize_image_filters()
            
            # 4. GPU ê°€ì† ì´ˆê¸°í™”
            if self.post_processing_config.use_gpu_acceleration:
                await self._initialize_gpu_acceleration()
            
            # 5. M3 Max ì›Œë°ì—…
            if IS_M3_MAX:
                await self._warmup_m3_max()
            
            # 6. ìºì‹œ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
            self._initialize_cache_system()
            
            self.is_initialized = True
            self.is_ready = True
            self.logger.info("âœ… í›„ì²˜ë¦¬ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
            
            return True
            
        except Exception as e:
            error_msg = f"í›„ì²˜ë¦¬ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}"
            self.logger.error(f"âŒ {error_msg}")
            
            # ìµœì†Œí•œì˜ í´ë°± ì‹œìŠ¤í…œ ì´ˆê¸°í™”
            self._initialize_fallback_system()
            self.is_initialized = True
            
            return True  # Graceful degradation
    
    async def _initialize_ai_models(self):
        """AI ëª¨ë¸ë“¤ ì´ˆê¸°í™” - ì˜ì¡´ì„± ì£¼ì…ëœ ModelLoader í™œìš©"""
        try:
            self.logger.info("ğŸ§  AI ëª¨ë¸ ì´ˆê¸°í™” ì‹œì‘...")
            
            # ModelLoaderê°€ ì˜ì¡´ì„± ì£¼ì…ë˜ì—ˆëŠ”ì§€ í™•ì¸
            if not self.model_loader:
                self.logger.warning("âš ï¸ ModelLoaderê°€ ì£¼ì…ë˜ì§€ ì•ŠìŒ - ê¸°ë³¸ ëª¨ë¸ ìƒì„±")
                await self._load_models_direct()
                return
            
            # === Super Resolution ëª¨ë¸ ë¡œë“œ ===
            try:
                # ModelLoaderë¥¼ í†µí•´ ëª¨ë¸ ìš”ì²­
                if hasattr(self.model_loader, 'get_model_async'):
                    sr_checkpoint = await self.model_loader.get_model_async('post_processing_model')
                else:
                    sr_checkpoint = self.model_loader.get_model('post_processing_model')
                
                if sr_checkpoint:
                    self.sr_model = self._create_sr_model_from_checkpoint(sr_checkpoint)
                    if self.sr_model:
                        self.logger.info("âœ… Super Resolution ëª¨ë¸ ë¡œë“œ ì„±ê³µ (ModelLoader)")
                        self.has_model = True
                        self.model_loaded = True
                    else:
                        raise Exception("ì²´í¬í¬ì¸íŠ¸ë¡œë¶€í„° ëª¨ë¸ ìƒì„± ì‹¤íŒ¨")
                else:
                    raise Exception("ModelLoaderì—ì„œ SR ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ")
                    
            except Exception as e:
                self.logger.warning(f"âš ï¸ SR ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e} - ê¸°ë³¸ ëª¨ë¸ ìƒì„±")
                self.sr_model = self._create_default_sr_model()
            
            # === Denoising ëª¨ë¸ ë¡œë“œ ===
            try:
                if hasattr(self.model_loader, 'get_model_async'):
                    denoise_checkpoint = await self.model_loader.get_model_async('post_processing_model')
                else:
                    denoise_checkpoint = self.model_loader.get_model('post_processing_model')
                
                if denoise_checkpoint:
                    self.denoise_model = self._create_denoise_model_from_checkpoint(denoise_checkpoint)
                    if self.denoise_model:
                        self.logger.info("âœ… Denoising ëª¨ë¸ ë¡œë“œ ì„±ê³µ (ModelLoader)")
                    else:
                        raise Exception("ì²´í¬í¬ì¸íŠ¸ë¡œë¶€í„° ëª¨ë¸ ìƒì„± ì‹¤íŒ¨")
                else:
                    raise Exception("ModelLoaderì—ì„œ Denoising ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ")
                    
            except Exception as e:
                self.logger.warning(f"âš ï¸ Denoising ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e} - ê¸°ë³¸ ëª¨ë¸ ìƒì„±")
                self.denoise_model = self._create_default_denoise_model()

            # M3 Max ìµœì í™” ì ìš©
            if IS_M3_MAX:
                self._optimize_models_for_m3_max()
            
            self.logger.info("ğŸ§  AI ëª¨ë¸ ë¡œë“œ ì™„ë£Œ (ModelLoader ì—°ë™)")
            
        except Exception as e:
            self.logger.error(f"âŒ AI ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            await self._load_models_direct()
    
    def _create_sr_model_from_checkpoint(self, checkpoint) -> Optional[SRResNet]:
        """ì²´í¬í¬ì¸íŠ¸ë¡œë¶€í„° Super Resolution ëª¨ë¸ ìƒì„±"""
        try:
            # ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
            model = SRResNet(in_channels=3, out_channels=3, num_features=64, num_blocks=16)
            
            # ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ
            if isinstance(checkpoint, dict):
                # ë”•ì…”ë„ˆë¦¬ í˜•íƒœì˜ ì²´í¬í¬ì¸íŠ¸
                if 'state_dict' in checkpoint:
                    state_dict = checkpoint['state_dict']
                elif 'model' in checkpoint:
                    state_dict = checkpoint['model']
                else:
                    state_dict = checkpoint
                
                model.load_state_dict(state_dict, strict=False)
            else:
                # ì´ë¯¸ ë¡œë“œëœ ëª¨ë¸ ê°ì²´ì¸ ê²½ìš°
                model = checkpoint
            
            # ë””ë°”ì´ìŠ¤ë¡œ ì´ë™
            model = model.to(self.device)
            model.eval()
            
            # ì •ë°€ë„ ìµœì í™”
            if self.device == "mps":
                model = model.float()
            elif self.device == "cuda":
                model = model.half()
            
            self.logger.info("ğŸ”§ SR ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ ë³€í™˜ ì™„ë£Œ")
            return model
            
        except Exception as e:
            self.logger.error(f"âŒ SR ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ ë³€í™˜ ì‹¤íŒ¨: {e}")
            return None
    
    def _create_denoise_model_from_checkpoint(self, checkpoint) -> Optional[DenoiseNet]:
        """ì²´í¬í¬ì¸íŠ¸ë¡œë¶€í„° Denoising ëª¨ë¸ ìƒì„±"""
        try:
            # ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
            model = DenoiseNet(in_channels=3, out_channels=3, num_features=64)
            
            # ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ
            if isinstance(checkpoint, dict):
                if 'state_dict' in checkpoint:
                    state_dict = checkpoint['state_dict']
                elif 'model' in checkpoint:
                    state_dict = checkpoint['model']
                else:
                    state_dict = checkpoint
                
                model.load_state_dict(state_dict, strict=False)
            else:
                model = checkpoint
            
            # ë””ë°”ì´ìŠ¤ë¡œ ì´ë™
            model = model.to(self.device)
            model.eval()
            
            # ì •ë°€ë„ ìµœì í™”
            if self.device == "mps":
                model = model.float()
            elif self.device == "cuda":
                model = model.half()
            
            self.logger.info("ğŸ”§ Denoising ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ ë³€í™˜ ì™„ë£Œ")
            return model
            
        except Exception as e:
            self.logger.error(f"âŒ Denoising ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ ë³€í™˜ ì‹¤íŒ¨: {e}")
            return None
    
    def _create_default_sr_model(self) -> Optional[SRResNet]:
        """ê¸°ë³¸ Super Resolution ëª¨ë¸ ìƒì„±"""
        try:
            if not TORCH_AVAILABLE:
                return None
                
            model = SRResNet(in_channels=3, out_channels=3, num_features=64, num_blocks=16)
            model.to(self.device)
            model.eval()
            
            # M3 Max ì •ë°€ë„ ìµœì í™”
            if self.device == "mps":
                model = model.float()
            elif self.device == "cuda":
                model = model.half()
            
            self.logger.info("ğŸ”§ ê¸°ë³¸ Super Resolution ëª¨ë¸ ìƒì„± ì™„ë£Œ")
            return model
            
        except Exception as e:
            self.logger.error(f"âŒ ê¸°ë³¸ SR ëª¨ë¸ ìƒì„± ì‹¤íŒ¨: {e}")
            return None
    
    def _create_default_denoise_model(self) -> Optional[DenoiseNet]:
        """ê¸°ë³¸ Denoising ëª¨ë¸ ìƒì„±"""
        try:
            if not TORCH_AVAILABLE:
                return None
                
            model = DenoiseNet(in_channels=3, out_channels=3, num_features=64)
            model.to(self.device)
            model.eval()
            
            # M3 Max ì •ë°€ë„ ìµœì í™”
            if self.device == "mps":
                model = model.float()
            elif self.device == "cuda":
                model = model.half()
            
            self.logger.info("ğŸ”§ ê¸°ë³¸ Denoising ëª¨ë¸ ìƒì„± ì™„ë£Œ")
            return model
            
        except Exception as e:
            self.logger.error(f"âŒ ê¸°ë³¸ Denoising ëª¨ë¸ ìƒì„± ì‹¤íŒ¨: {e}")
            return None
    
    async def _load_models_direct(self):
        """AI ëª¨ë¸ ì§ì ‘ ë¡œë“œ (ModelLoader ì—†ì´)"""
        try:
            # Super Resolution ëª¨ë¸
            self.sr_model = self._create_default_sr_model()
            
            # Denoising ëª¨ë¸  
            self.denoise_model = self._create_default_denoise_model()
            
            # ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ ì‹œë„
            sr_checkpoint = self.checkpoint_path / "srresnet_x4.pth"
            if sr_checkpoint.exists() and self.sr_model:
                try:
                    state_dict = torch.load(sr_checkpoint, map_location=self.device)
                    self.sr_model.load_state_dict(state_dict, strict=False)
                    self.logger.info("âœ… SR ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ ì„±ê³µ")
                except Exception as e:
                    self.logger.warning(f"âš ï¸ SR ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            
            denoise_checkpoint = self.checkpoint_path / "denoise_net.pth"
            if denoise_checkpoint.exists() and self.denoise_model:
                try:
                    state_dict = torch.load(denoise_checkpoint, map_location=self.device)
                    self.denoise_model.load_state_dict(state_dict, strict=False)
                    self.logger.info("âœ… Denoising ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ ì„±ê³µ")
                except Exception as e:
                    self.logger.warning(f"âš ï¸ Denoising ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            
            # M3 Max ìµœì í™”
            if IS_M3_MAX:
                self._optimize_models_for_m3_max()
            
            self.logger.info("âœ… ê¸°ë³¸ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
            
        except Exception as e:
            self.logger.error(f"âŒ ëª¨ë¸ ì§ì ‘ ë¡œë“œ ì‹¤íŒ¨: {e}")
            self.sr_model = None
            self.denoise_model = None
    
    def _optimize_models_for_m3_max(self):
        """M3 Max í•˜ë“œì›¨ì–´ ìµœì í™”"""
        try:
            self.logger.info("ğŸ M3 Max ëª¨ë¸ ìµœì í™” ì ìš© ì¤‘...")
            
            # ë©”ëª¨ë¦¬ ë§¤í•‘ ìµœì í™”
            if self.sr_model:
                self.sr_model = self.sr_model.to(self.device)
                if self.device == "mps":
                    self.sr_model = self.sr_model.float()
            
            if self.denoise_model:
                self.denoise_model = self.denoise_model.to(self.device)
                if self.device == "mps":
                    self.denoise_model = self.denoise_model.float()
            
            # ë°°ì¹˜ í¬ê¸° ìµœì í™”
            self.optimal_batch_size = min(8, max(1, int(self.memory_gb / 16)))
            
            self.logger.info(f"âœ… M3 Max ìµœì í™” ì™„ë£Œ - ë°°ì¹˜ í¬ê¸°: {self.optimal_batch_size}")
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ M3 Max ìµœì í™” ì‹¤íŒ¨: {e}")
    
    async def _initialize_face_detector(self):
        """ì–¼êµ´ ê²€ì¶œê¸° ì´ˆê¸°í™”"""
        try:
            if not OPENCV_AVAILABLE:
                self.logger.warning("âš ï¸ OpenCV ì—†ì–´ì„œ ì–¼êµ´ ê²€ì¶œ ë¹„í™œì„±í™”")
                return
                
            # OpenCV DNN ì–¼êµ´ ê²€ì¶œê¸° ì‹œë„
            face_net_path = self.checkpoint_path / "opencv_face_detector_uint8.pb"
            face_config_path = self.checkpoint_path / "opencv_face_detector.pbtxt"
            
            if face_net_path.exists() and face_config_path.exists():
                self.face_detector = cv2.dnn.readNetFromTensorflow(
                    str(face_net_path), str(face_config_path)
                )
                self.logger.info("âœ… OpenCV DNN ì–¼êµ´ ê²€ì¶œê¸° ë¡œë“œ ì„±ê³µ")
            else:
                # Haar Cascade í´ë°±
                try:
                    cascade_path = cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'
                    self.face_detector = cv2.CascadeClassifier(cascade_path)
                    self.logger.info("âœ… Haar Cascade ì–¼êµ´ ê²€ì¶œê¸° ë¡œë“œ ì„±ê³µ")
                except:
                    self.face_detector = None
                    self.logger.warning("âš ï¸ ì–¼êµ´ ê²€ì¶œê¸° ë¡œë“œ ì‹¤íŒ¨")
                
        except Exception as e:
            self.logger.warning(f"ì–¼êµ´ ê²€ì¶œê¸° ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.face_detector = None
    
    def _initialize_image_filters(self):
        """ì´ë¯¸ì§€ í•„í„° ì´ˆê¸°í™”"""
        try:
            if not NUMPY_AVAILABLE:
                self.logger.warning("âš ï¸ NumPy ì—†ì–´ì„œ í•„í„° ì œí•œë¨")
                return
                
            # ì»¤ìŠ¤í…€ ì»¤ë„ë“¤
            self.sharpening_kernel = np.array([
                [-1, -1, -1],
                [-1,  9, -1],
                [-1, -1, -1]
            ], dtype=np.float32)
            
            self.edge_enhancement_kernel = np.array([
                [0, -1, 0],
                [-1, 5, -1],
                [0, -1, 0]
            ], dtype=np.float32)
            
            # ê°€ìš°ì‹œì•ˆ ì»¤ë„
            if OPENCV_AVAILABLE:
                self.gaussian_kernel_3x3 = cv2.getGaussianKernel(3, 0.8)
                self.gaussian_kernel_5x5 = cv2.getGaussianKernel(5, 1.2)
            
            # ì–¸ìƒ¤í”„ ë§ˆìŠ¤í‚¹ ë§¤ê°œë³€ìˆ˜
            self.unsharp_params = {
                'radius': 1.0,
                'amount': 1.5,
                'threshold': 0.05
            }
            
            self.logger.info("âœ… ì´ë¯¸ì§€ í•„í„° ì´ˆê¸°í™” ì™„ë£Œ")
            
        except Exception as e:
            self.logger.error(f"ì´ë¯¸ì§€ í•„í„° ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    
    async def _initialize_gpu_acceleration(self):
        """GPU ê°€ì† ì´ˆê¸°í™”"""
        try:
            if self.device == 'mps':
                self.logger.info("ğŸ M3 Max MPS ê°€ì† í™œì„±í™”")
            elif self.device == 'cuda':
                self.logger.info("ğŸš€ CUDA ê°€ì† í™œì„±í™”")
            else:
                self.logger.info("ğŸ’» CPU ëª¨ë“œì—ì„œ ì‹¤í–‰")
                
        except Exception as e:
            self.logger.warning(f"GPU ê°€ì† ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    
    async def _warmup_m3_max(self):
        """M3 Max ìµœì í™” ì›Œë°ì—…"""
        try:
            if not IS_M3_MAX or not TORCH_AVAILABLE:
                return
            
            self.logger.info("ğŸ M3 Max ìµœì í™” ì›Œë°ì—… ì‹œì‘...")
            
            # ë”ë¯¸ ì´ë¯¸ì§€ë¡œ GPU ì›Œë°ì—…
            dummy_image = torch.randn(1, 3, 512, 512).to(self.device)
            
            if self.sr_model:
                with torch.no_grad():
                    _ = self.sr_model(dummy_image)
                self.logger.info("âœ… Super Resolution M3 Max ì›Œë°ì—… ì™„ë£Œ")
            
            if self.denoise_model:
                with torch.no_grad():
                    _ = self.denoise_model(dummy_image)
                self.logger.info("âœ… Denoising M3 Max ì›Œë°ì—… ì™„ë£Œ")
            
            # MPS ìºì‹œ ìµœì í™”
            if self.device == 'mps':
                try:
                    safe_mps_empty_cache()
                except Exception:
                    pass
            
            # ë©”ëª¨ë¦¬ ìµœì í™” (BaseStepMixin ì˜ì¡´ì„± ì£¼ì…ëœ ê²½ìš°)
            if self.memory_manager:
                try:
                    if hasattr(self.memory_manager, 'optimize_memory_async'):
                        await self.memory_manager.optimize_memory_async()
                    else:
                        await asyncio.get_event_loop().run_in_executor(
                            None, self.memory_manager.optimize_memory
                        )
                except Exception:
                    pass
            
            self.logger.info("ğŸ M3 Max ì›Œë°ì—… ì™„ë£Œ")
            
        except Exception as e:
            self.logger.warning(f"M3 Max ì›Œë°ì—… ì‹¤íŒ¨: {e}")
    
    def _initialize_cache_system(self):
        """ìºì‹œ ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
        try:
            cache_size = self.post_processing_config.cache_size
            self.logger.info(f"ğŸ’¾ ìºì‹œ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ (í¬ê¸°: {cache_size})")
        except Exception as e:
            self.logger.error(f"ìºì‹œ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    
    def _initialize_fallback_system(self):
        """ìµœì†Œí•œì˜ í´ë°± ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
        try:
            # ê°€ì¥ ê¸°ë³¸ì ì¸ ë°©ë²•ë“¤ë§Œ í™œì„±í™”
            self.post_processing_config.enabled_methods = [
                EnhancementMethod.SHARPENING,
                EnhancementMethod.COLOR_CORRECTION,
                EnhancementMethod.CONTRAST_ENHANCEMENT
            ]
            
            self.logger.info("âš ï¸ í´ë°± ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
            
        except Exception as e:
            self.logger.error(f"í´ë°± ì‹œìŠ¤í…œ ì´ˆê¸°í™”ë„ ì‹¤íŒ¨: {e}")
    
    # ==============================================
    # ğŸ”¥ 10. ë©”ì¸ ì²˜ë¦¬ ì¸í„°í˜ì´ìŠ¤ (Pipeline Manager í˜¸í™˜)
    # ==============================================
    
    async def process(
        self, 
        fitting_result: Dict[str, Any],
        enhancement_options: Optional[Dict[str, Any]] = None,
        **kwargs
    ) -> Dict[str, Any]:
        """
        í†µì¼ëœ ì²˜ë¦¬ ì¸í„°í˜ì´ìŠ¤ - Pipeline Manager í˜¸í™˜
        
        Args:
            fitting_result: ê°€ìƒ í”¼íŒ… ê²°ê³¼ (6ë‹¨ê³„ ì¶œë ¥)
            enhancement_options: í–¥ìƒ ì˜µì…˜
            **kwargs: ì¶”ê°€ ë§¤ê°œë³€ìˆ˜
                
        Returns:
            Dict[str, Any]: í›„ì²˜ë¦¬ ê²°ê³¼ + ì‹œê°í™” ì´ë¯¸ì§€
        """
        if not self.is_initialized:
            await self.initialize()
        
        start_time = time.time()
        
        try:
            self.logger.info("âœ¨ í›„ì²˜ë¦¬ ì‹œì‘...")
            
            # 1. ìºì‹œ í™•ì¸
            cache_key = self._generate_cache_key(fitting_result, enhancement_options)
            if cache_key in self.enhancement_cache:
                cached_result = self.enhancement_cache[cache_key]
                self.processing_stats['cache_hits'] += 1
                self.logger.info("ğŸ’¾ ìºì‹œì—ì„œ ê²°ê³¼ ë°˜í™˜")
                return self._format_result(cached_result)
            
            # 2. ì…ë ¥ ë°ì´í„° ì²˜ë¦¬
            processed_input = self._process_input_data(fitting_result)
            
            # 3. í–¥ìƒ ì˜µì…˜ ì¤€ë¹„
            options = self._prepare_enhancement_options(enhancement_options)
            
            # 4. ë©”ì¸ í–¥ìƒ ì²˜ë¦¬
            result = await self._perform_enhancement_pipeline(
                processed_input, options, **kwargs
            )
            
            # 5. ì‹œê°í™” ì´ë¯¸ì§€ ìƒì„±
            if self.post_processing_config.enable_visualization:
                visualization_results = await self._create_enhancement_visualization(
                    processed_input, result, options
                )
                result.metadata['visualization'] = visualization_results
            
            # 6. ê²°ê³¼ ìºì‹±
            if result.success:
                self.enhancement_cache[cache_key] = result
                if len(self.enhancement_cache) > self.post_processing_config.cache_size:
                    self._cleanup_cache()
            
            # 7. í†µê³„ ì—…ë°ì´íŠ¸
            self._update_statistics(result, time.time() - start_time)
            
            self.logger.info(f"âœ… í›„ì²˜ë¦¬ ì™„ë£Œ - ê°œì„ ë„: {result.quality_improvement:.3f}, "
                            f"ì‹œê°„: {result.processing_time:.3f}ì´ˆ")
            
            return self._format_result(result)
            
        except Exception as e:
            error_msg = f"í›„ì²˜ë¦¬ ì²˜ë¦¬ ì‹¤íŒ¨: {e}"
            self.logger.error(f"âŒ {error_msg}")
            
            # ì—ëŸ¬ ê²°ê³¼ ë°˜í™˜
            error_result = PostProcessingResult(
                success=False,
                error_message=error_msg,
                processing_time=time.time() - start_time
            )
            
            return self._format_result(error_result)
    
    def _process_input_data(self, fitting_result: Dict[str, Any]) -> Dict[str, Any]:
        """ì…ë ¥ ë°ì´í„° ì²˜ë¦¬"""
        try:
            # ê°€ìƒ í”¼íŒ… ê²°ê³¼ì—ì„œ ì´ë¯¸ì§€ ì¶”ì¶œ
            fitted_image = fitting_result.get('fitted_image') or fitting_result.get('result_image')
            
            if fitted_image is None:
                raise ValueError("í”¼íŒ…ëœ ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤")
            
            # íƒ€ì…ë³„ ë³€í™˜
            if isinstance(fitted_image, str):
                # Base64 ë””ì½”ë”©
                import base64
                from io import BytesIO
                image_data = base64.b64decode(fitted_image)
                if PIL_AVAILABLE:
                    image_pil = Image.open(BytesIO(image_data)).convert('RGB')
                    fitted_image = np.array(image_pil) if NUMPY_AVAILABLE else image_pil
                else:
                    raise ValueError("PILì´ ì—†ì–´ì„œ base64 ì´ë¯¸ì§€ ì²˜ë¦¬ ë¶ˆê°€")
                    
            elif TORCH_AVAILABLE and isinstance(fitted_image, torch.Tensor):
                # PyTorch í…ì„œ ì²˜ë¦¬
                if self.data_converter:
                    fitted_image = self.data_converter.tensor_to_numpy(fitted_image)
                else:
                    fitted_image = fitted_image.detach().cpu().numpy()
                    if fitted_image.ndim == 4:
                        fitted_image = fitted_image.squeeze(0)
                    if fitted_image.ndim == 3 and fitted_image.shape[0] == 3:
                        fitted_image = fitted_image.transpose(1, 2, 0)
                    fitted_image = (fitted_image * 255).astype(np.uint8)
                    
            elif PIL_AVAILABLE and isinstance(fitted_image, Image.Image):
                if NUMPY_AVAILABLE:
                    fitted_image = np.array(fitted_image.convert('RGB'))
                else:
                    fitted_image = fitted_image.convert('RGB')
                    
            elif not NUMPY_AVAILABLE or not isinstance(fitted_image, np.ndarray):
                raise ValueError(f"ì§€ì›ë˜ì§€ ì•ŠëŠ” ì´ë¯¸ì§€ íƒ€ì…: {type(fitted_image)}")
            
            # ì´ë¯¸ì§€ ê²€ì¦ (NumPy ë°°ì—´ì¸ ê²½ìš°)
            if NUMPY_AVAILABLE and isinstance(fitted_image, np.ndarray):
                if fitted_image.ndim != 3 or fitted_image.shape[2] != 3:
                    raise ValueError(f"ì˜ëª»ëœ ì´ë¯¸ì§€ í˜•íƒœ: {fitted_image.shape}")
                
                # í¬ê¸° ì œí•œ í™•ì¸
                max_height, max_width = self.post_processing_config.max_resolution
                if fitted_image.shape[0] > max_height or fitted_image.shape[1] > max_width:
                    fitted_image = self._resize_image_preserve_ratio(fitted_image, max_height, max_width)
            
            return {
                'image': fitted_image,
                'original_shape': fitted_image.shape if hasattr(fitted_image, 'shape') else None,
                'mask': fitting_result.get('mask'),
                'confidence': fitting_result.get('confidence', 1.0),
                'metadata': fitting_result.get('metadata', {})
            }
            
        except Exception as e:
            self.logger.error(f"ì…ë ¥ ë°ì´í„° ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            raise
    
    def _prepare_enhancement_options(self, enhancement_options: Optional[Dict[str, Any]]) -> Dict[str, Any]:
        """í–¥ìƒ ì˜µì…˜ ì¤€ë¹„"""
        try:
            # ê¸°ë³¸ ì˜µì…˜
            default_options = {
                'quality_level': self.post_processing_config.quality_level.value,
                'enabled_methods': [method.value for method in self.post_processing_config.enabled_methods],
                'enhancement_strength': self.enhancement_strength,
                'preserve_faces': self.preserve_faces,
                'auto_adjust_brightness': self.auto_adjust_brightness,
            }
            
            # ê° ë°©ë²•ë³„ ì ìš© ì—¬ë¶€ ì„¤ì •
            for method in self.post_processing_config.enabled_methods:
                default_options[f'apply_{method.value}'] = True
            
            # ì‚¬ìš©ì ì˜µì…˜ìœ¼ë¡œ ë®ì–´ì“°ê¸°
            if enhancement_options:
                default_options.update(enhancement_options)
            
            return default_options
            
        except Exception as e:
            self.logger.error(f"í–¥ìƒ ì˜µì…˜ ì¤€ë¹„ ì‹¤íŒ¨: {e}")
            return {}
    
    async def _perform_enhancement_pipeline(
        self,
        processed_input: Dict[str, Any],
        options: Dict[str, Any],
        **kwargs
    ) -> PostProcessingResult:
        """í–¥ìƒ íŒŒì´í”„ë¼ì¸ ìˆ˜í–‰ - ì‹¤ì œ AI ì¶”ë¡  êµ¬í˜„"""
        try:
            image = processed_input['image']
            if not NUMPY_AVAILABLE or not isinstance(image, np.ndarray):
                raise ValueError("NumPy ë°°ì—´ ì´ë¯¸ì§€ê°€ í•„ìš”í•©ë‹ˆë‹¤")
                
            applied_methods = []
            enhancement_log = []
            
            original_quality = self._calculate_image_quality(image)
            
            # ê° í–¥ìƒ ë°©ë²• ì ìš©
            for method in self.post_processing_config.enabled_methods:
                method_name = method.value
                
                try:
                    if method == EnhancementMethod.SUPER_RESOLUTION and options.get(f'apply_{method_name}', False):
                        # ğŸ”¥ ì‹¤ì œ AI ëª¨ë¸ ì¶”ë¡ 
                        enhanced_image = await self._apply_super_resolution(image)
                        if enhanced_image is not None:
                            image = enhanced_image
                            applied_methods.append(method_name)
                            enhancement_log.append("Super Resolution ì ìš© (AI ëª¨ë¸)")
                    
                    elif method in [EnhancementMethod.NOISE_REDUCTION, EnhancementMethod.DENOISING] and options.get(f'apply_{method_name}', False):
                        # ğŸ”¥ ì‹¤ì œ AI ëª¨ë¸ ì¶”ë¡ 
                        if self.denoise_model:
                            enhanced_image = await self._apply_ai_denoising(image)
                        else:
                            enhanced_image = self._apply_traditional_denoising(image)
                        
                        if enhanced_image is not None:
                            image = enhanced_image
                            applied_methods.append(method_name)
                            enhancement_log.append("ë…¸ì´ì¦ˆ ì œê±° ì ìš© (AI ëª¨ë¸)" if self.denoise_model else "ë…¸ì´ì¦ˆ ì œê±° ì ìš© (ì „í†µì )")
                    
                    elif method == EnhancementMethod.SHARPENING and options.get(f'apply_{method_name}', False):
                        enhanced_image = self._apply_advanced_sharpening(image, options['enhancement_strength'])
                        if enhanced_image is not None:
                            image = enhanced_image
                            applied_methods.append(method_name)
                            enhancement_log.append("ì„ ëª…ë„ í–¥ìƒ ì ìš©")
                    
                    elif method == EnhancementMethod.COLOR_CORRECTION and options.get(f'apply_{method_name}', False):
                        enhanced_image = self._apply_color_correction(image)
                        if enhanced_image is not None:
                            image = enhanced_image
                            applied_methods.append(method_name)
                            enhancement_log.append("ìƒ‰ìƒ ë³´ì • ì ìš©")
                    
                    elif method == EnhancementMethod.CONTRAST_ENHANCEMENT and options.get(f'apply_{method_name}', False):
                        enhanced_image = self._apply_contrast_enhancement(image)
                        if enhanced_image is not None:
                            image = enhanced_image
                            applied_methods.append(method_name)
                            enhancement_log.append("ëŒ€ë¹„ í–¥ìƒ ì ìš©")
                    
                    elif method == EnhancementMethod.FACE_ENHANCEMENT and options.get('preserve_faces', False) and self.face_detector:
                        faces = self._detect_faces(image)
                        if faces:
                            enhanced_image = self._enhance_face_regions(image, faces)
                            if enhanced_image is not None:
                                image = enhanced_image
                                applied_methods.append(method_name)
                                enhancement_log.append(f"ì–¼êµ´ í–¥ìƒ ì ìš© ({len(faces)}ê°œ ì–¼êµ´)")
                
                except Exception as e:
                    self.logger.warning(f"{method_name} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                    continue
            
            # ìµœì¢… í›„ì²˜ë¦¬
            try:
                final_image = self._apply_final_post_processing(image)
                if final_image is not None:
                    image = final_image
                    enhancement_log.append("ìµœì¢… í›„ì²˜ë¦¬ ì ìš©")
            except Exception as e:
                self.logger.warning(f"ìµœì¢… í›„ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            
            # í’ˆì§ˆ ê°œì„ ë„ ê³„ì‚°
            final_quality = self._calculate_image_quality(image)
            quality_improvement = final_quality - original_quality
            
            return PostProcessingResult(
                success=True,
                enhanced_image=image,
                quality_improvement=quality_improvement,
                applied_methods=applied_methods,
                processing_time=0.0,  # í˜¸ì¶œë¶€ì—ì„œ ì„¤ì •
                metadata={
                    'enhancement_log': enhancement_log,
                    'original_quality': original_quality,
                    'final_quality': final_quality,
                    'original_shape': processed_input['original_shape'],
                    'options_used': options
                }
            )
            
        except Exception as e:
            return PostProcessingResult(
                success=False,
                error_message=f"í–¥ìƒ íŒŒì´í”„ë¼ì¸ ì‹¤íŒ¨: {e}",
                processing_time=0.0
            )
    
    # ==============================================
    # ğŸ”¥ 11. AI ëª¨ë¸ ì¶”ë¡  ë©”ì„œë“œë“¤ (ì‹¤ì œ êµ¬í˜„)
    # ==============================================
    
    async def _apply_super_resolution(self, image: np.ndarray) -> Optional[np.ndarray]:
        """ğŸ”¥ ì‹¤ì œ Super Resolution AI ëª¨ë¸ ì¶”ë¡ """
        try:
            if not self.sr_model or not TORCH_AVAILABLE or not PIL_AVAILABLE:
                self.logger.warning("âš ï¸ SR ëª¨ë¸ ë˜ëŠ” í•„ìš” ë¼ì´ë¸ŒëŸ¬ë¦¬ ì—†ìŒ")
                return None
            
            # NumPy â†’ PIL â†’ Tensor ë³€í™˜
            if NUMPY_AVAILABLE and isinstance(image, np.ndarray):
                pil_image = Image.fromarray(image)
            else:
                return None
                
            # í…ì„œ ë³€í™˜
            transform = transforms.Compose([
                transforms.ToTensor(),
            ])
            
            input_tensor = transform(pil_image).unsqueeze(0).to(self.device)
            
            # ì •ë°€ë„ ì„¤ì •
            if self.device == "mps":
                input_tensor = input_tensor.float()
            elif self.device == "cuda":
                input_tensor = input_tensor.half()
            
            # ğŸ”¥ ì‹¤ì œ AI ëª¨ë¸ ì¶”ë¡ 
            with torch.no_grad():
                self.logger.debug("ğŸ§  Super Resolution AI ëª¨ë¸ ì¶”ë¡  ì‹œì‘...")
                output_tensor = self.sr_model(input_tensor)
                
                # í›„ì²˜ë¦¬
                output_tensor = torch.clamp(output_tensor, 0, 1)
                
                # Tensor â†’ NumPy ë³€í™˜
                output_np = output_tensor.squeeze().cpu().float().numpy()
                if output_np.ndim == 3:
                    output_np = output_np.transpose(1, 2, 0)
                
                # 0-255 ë²”ìœ„ë¡œ ë³€í™˜
                enhanced_image = (output_np * 255).astype(np.uint8)
                
                self.logger.debug("âœ… Super Resolution AI ëª¨ë¸ ì¶”ë¡  ì™„ë£Œ")
                return enhanced_image
                
        except Exception as e:
            self.logger.error(f"âŒ Super Resolution ì ìš© ì‹¤íŒ¨: {e}")
            return None
    
    async def _apply_ai_denoising(self, image: np.ndarray) -> Optional[np.ndarray]:
        """ğŸ”¥ ì‹¤ì œ AI ê¸°ë°˜ ë…¸ì´ì¦ˆ ì œê±° ëª¨ë¸ ì¶”ë¡ """
        try:
            if not self.denoise_model or not TORCH_AVAILABLE or not PIL_AVAILABLE:
                self.logger.warning("âš ï¸ Denoising ëª¨ë¸ ë˜ëŠ” í•„ìš” ë¼ì´ë¸ŒëŸ¬ë¦¬ ì—†ìŒ")
                return None
            
            # NumPy â†’ PIL â†’ Tensor ë³€í™˜
            if NUMPY_AVAILABLE and isinstance(image, np.ndarray):
                pil_image = Image.fromarray(image)
            else:
                return None
                
            transform = transforms.Compose([
                transforms.ToTensor(),
            ])
            
            input_tensor = transform(pil_image).unsqueeze(0).to(self.device)
            
            # ì •ë°€ë„ ì„¤ì •
            if self.device == "mps":
                input_tensor = input_tensor.float()
            elif self.device == "cuda":
                input_tensor = input_tensor.half()
            
            # ğŸ”¥ ì‹¤ì œ AI ëª¨ë¸ ì¶”ë¡ 
            with torch.no_grad():
                self.logger.debug("ğŸ§  Denoising AI ëª¨ë¸ ì¶”ë¡  ì‹œì‘...")
                output_tensor = self.denoise_model(input_tensor)
                
                # Tensor â†’ NumPy ë³€í™˜
                output_np = output_tensor.squeeze().cpu().float().numpy()
                if output_np.ndim == 3:
                    output_np = output_np.transpose(1, 2, 0)
                
                # 0-255 ë²”ìœ„ë¡œ ë³€í™˜
                denoised_image = (output_np * 255).astype(np.uint8)
                
                self.logger.debug("âœ… Denoising AI ëª¨ë¸ ì¶”ë¡  ì™„ë£Œ")
                return denoised_image
                
        except Exception as e:
            self.logger.error(f"âŒ AI ë…¸ì´ì¦ˆ ì œê±° ì‹¤íŒ¨: {e}")
            return None
    
    # ==============================================
    # ğŸ”¥ 12. ì „í†µì  ì´ë¯¸ì§€ ì²˜ë¦¬ ë©”ì„œë“œë“¤
    # ==============================================
    
    def _apply_traditional_denoising(self, image: np.ndarray) -> np.ndarray:
        """ì „í†µì  ë…¸ì´ì¦ˆ ì œê±°"""
        try:
            if not NUMPY_AVAILABLE or not isinstance(image, np.ndarray):
                return image
                
            # scikit-imageê°€ ìˆìœ¼ë©´ ê³ ê¸‰ í•„í„° ì‚¬ìš©
            if SKIMAGE_AVAILABLE:
                denoised = restoration.denoise_bilateral(
                    image, 
                    sigma_color=0.05, 
                    sigma_spatial=15, 
                    channel_axis=2
                )
                return (denoised * 255).astype(np.uint8)
            elif OPENCV_AVAILABLE:
                # OpenCV bilateral filter
                denoised = cv2.bilateralFilter(image, 9, 75, 75)
                return denoised
            else:
                # ê¸°ë³¸ì ì¸ ê°€ìš°ì‹œì•ˆ ë¸”ëŸ¬
                if SCIPY_AVAILABLE:
                    denoised = gaussian_filter(image, sigma=1.0)
                    return denoised.astype(np.uint8)
                else:
                    return image
                
        except Exception as e:
            self.logger.error(f"ì „í†µì  ë…¸ì´ì¦ˆ ì œê±° ì‹¤íŒ¨: {e}")
            return image
    
    def _apply_advanced_sharpening(self, image: np.ndarray, strength: float) -> np.ndarray:
        """ê³ ê¸‰ ì„ ëª…ë„ í–¥ìƒ"""
        try:
            if not NUMPY_AVAILABLE or not isinstance(image, np.ndarray):
                return image
                
            if not OPENCV_AVAILABLE:
                return image
                
            # ì–¸ìƒ¤í”„ ë§ˆìŠ¤í‚¹
            blurred = cv2.GaussianBlur(image, (5, 5), 1.0)
            unsharp_mask = cv2.addWeighted(image, 1 + strength, blurred, -strength, 0)
            
            # ì ì‘í˜• ì„ ëª…í™”
            gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
            edges = cv2.Canny(gray, 50, 150)
            
            # ì—ì§€ ì˜ì—­ì—ë§Œ ì¶”ê°€ ì„ ëª…í™” ì ìš©
            kernel = self.sharpening_kernel * strength
            sharpened = cv2.filter2D(unsharp_mask, -1, kernel)
            
            # ì—ì§€ ë§ˆìŠ¤í¬ ì ìš©
            edge_mask = (edges > 0).astype(np.float32)
            edge_mask = np.stack([edge_mask, edge_mask, edge_mask], axis=2)
            
            result = unsharp_mask * (1 - edge_mask) + sharpened * edge_mask
            
            return np.clip(result, 0, 255).astype(np.uint8)
            
        except Exception as e:
            self.logger.error(f"ì„ ëª…ë„ í–¥ìƒ ì‹¤íŒ¨: {e}")
            return image
    
    def _apply_color_correction(self, image: np.ndarray) -> np.ndarray:
        """ìƒ‰ìƒ ë³´ì •"""
        try:
            if not NUMPY_AVAILABLE or not isinstance(image, np.ndarray):
                return image
                
            if not OPENCV_AVAILABLE:
                return image
                
            # LAB ìƒ‰ê³µê°„ìœ¼ë¡œ ë³€í™˜
            lab = cv2.cvtColor(image, cv2.COLOR_RGB2LAB)
            l, a, b = cv2.split(lab)
            
            # CLAHE (Contrast Limited Adaptive Histogram Equalization) ì ìš©
            clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
            l = clahe.apply(l)
            
            # LAB ì±„ë„ ì¬ê²°í•©
            lab = cv2.merge([l, a, b])
            
            # RGBë¡œ ë‹¤ì‹œ ë³€í™˜
            corrected = cv2.cvtColor(lab, cv2.COLOR_LAB2RGB)
            
            # í™”ì´íŠ¸ ë°¸ëŸ°ìŠ¤ ì¡°ì •
            corrected = self._adjust_white_balance(corrected)
            
            return corrected
            
        except Exception as e:
            self.logger.error(f"ìƒ‰ìƒ ë³´ì • ì‹¤íŒ¨: {e}")
            return image
    
    def _adjust_white_balance(self, image: np.ndarray) -> np.ndarray:
        """í™”ì´íŠ¸ ë°¸ëŸ°ìŠ¤ ì¡°ì •"""
        try:
            if not NUMPY_AVAILABLE:
                return image
                
            # Gray World ì•Œê³ ë¦¬ì¦˜
            r_mean = np.mean(image[:, :, 0])
            g_mean = np.mean(image[:, :, 1])
            b_mean = np.mean(image[:, :, 2])
            
            gray_mean = (r_mean + g_mean + b_mean) / 3
            
            r_gain = gray_mean / r_mean if r_mean > 0 else 1.0
            g_gain = gray_mean / g_mean if g_mean > 0 else 1.0
            b_gain = gray_mean / b_mean if b_mean > 0 else 1.0
            
            # ê²Œì¸ ì œí•œ
            max_gain = 1.5
            r_gain = min(r_gain, max_gain)
            g_gain = min(g_gain, max_gain)
            b_gain = min(b_gain, max_gain)
            
            # ì±„ë„ë³„ ì¡°ì •
            balanced = image.copy().astype(np.float32)
            balanced[:, :, 0] *= r_gain
            balanced[:, :, 1] *= g_gain
            balanced[:, :, 2] *= b_gain
            
            return np.clip(balanced, 0, 255).astype(np.uint8)
            
        except Exception as e:
            self.logger.error(f"í™”ì´íŠ¸ ë°¸ëŸ°ìŠ¤ ì¡°ì • ì‹¤íŒ¨: {e}")
            return image
    
    def _apply_contrast_enhancement(self, image: np.ndarray) -> np.ndarray:
        """ëŒ€ë¹„ í–¥ìƒ"""
        try:
            if not NUMPY_AVAILABLE or not isinstance(image, np.ndarray):
                return image
                
            if not OPENCV_AVAILABLE:
                return image
                
            # ì ì‘í˜• íˆìŠ¤í† ê·¸ë¨ í‰í™œí™”
            lab = cv2.cvtColor(image, cv2.COLOR_RGB2LAB)
            l, a, b = cv2.split(lab)
            
            # CLAHE ì ìš©
            clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))
            l_enhanced = clahe.apply(l)
            
            # ì±„ë„ ì¬ê²°í•©
            lab_enhanced = cv2.merge([l_enhanced, a, b])
            enhanced = cv2.cvtColor(lab_enhanced, cv2.COLOR_LAB2RGB)
            
            # ì¶”ê°€ ëŒ€ë¹„ ì¡°ì • (sigmoid ê³¡ì„ )
            enhanced = self._apply_sigmoid_correction(enhanced, gain=1.2, cutoff=0.5)
            
            return enhanced
            
        except Exception as e:
            self.logger.error(f"ëŒ€ë¹„ í–¥ìƒ ì‹¤íŒ¨: {e}")
            return image
    
    def _apply_sigmoid_correction(self, image: np.ndarray, gain: float, cutoff: float) -> np.ndarray:
        """ì‹œê·¸ëª¨ì´ë“œ ê³¡ì„ ì„ ì‚¬ìš©í•œ ëŒ€ë¹„ ì¡°ì •"""
        try:
            if not NUMPY_AVAILABLE:
                return image
                
            # 0-1 ë²”ìœ„ë¡œ ì •ê·œí™”
            normalized = image.astype(np.float32) / 255.0
            
            # ì‹œê·¸ëª¨ì´ë“œ í•¨ìˆ˜ ì ìš©
            sigmoid = 1 / (1 + np.exp(gain * (cutoff - normalized)))
            
            # 0-255 ë²”ìœ„ë¡œ ë‹¤ì‹œ ë³€í™˜
            result = (sigmoid * 255).astype(np.uint8)
            
            return result
            
        except Exception as e:
            self.logger.error(f"ì‹œê·¸ëª¨ì´ë“œ ë³´ì • ì‹¤íŒ¨: {e}")
            return image
    
    def _detect_faces(self, image: np.ndarray) -> List[Tuple[int, int, int, int]]:
        """ì–¼êµ´ ê²€ì¶œ"""
        try:
            if not self.face_detector or not OPENCV_AVAILABLE or not NUMPY_AVAILABLE:
                return []
            
            faces = []
            
            if hasattr(self.face_detector, 'setInput'):
                # DNN ê¸°ë°˜ ê²€ì¶œê¸°
                blob = cv2.dnn.blobFromImage(image, 1.0, (300, 300), [104, 117, 123])
                self.face_detector.setInput(blob)
                detections = self.face_detector.forward()
                
                h, w = image.shape[:2]
                
                for i in range(detections.shape[2]):
                    confidence = detections[0, 0, i, 2]
                    if confidence > 0.5:
                        x1 = int(detections[0, 0, i, 3] * w)
                        y1 = int(detections[0, 0, i, 4] * h)
                        x2 = int(detections[0, 0, i, 5] * w)
                        y2 = int(detections[0, 0, i, 6] * h)
                        faces.append((x1, y1, x2 - x1, y2 - y1))
            else:
                # Haar Cascade ê²€ì¶œê¸°
                gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
                detected_faces = self.face_detector.detectMultiScale(
                    gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30)
                )
                faces = [tuple(face) for face in detected_faces]
            
            return faces
            
        except Exception as e:
            self.logger.error(f"ì–¼êµ´ ê²€ì¶œ ì‹¤íŒ¨: {e}")
            return []
    
    def _enhance_face_regions(self, image: np.ndarray, faces: List[Tuple[int, int, int, int]]) -> np.ndarray:
        """ì–¼êµ´ ì˜ì—­ í–¥ìƒ"""
        try:
            if not NUMPY_AVAILABLE or not OPENCV_AVAILABLE:
                return image
                
            enhanced = image.copy()
            
            for (x, y, w, h) in faces:
                # ì–¼êµ´ ì˜ì—­ ì¶”ì¶œ
                face_region = image[y:y+h, x:x+w]
                
                if face_region.size == 0:
                    continue
                
                # ì–¼êµ´ ì˜ì—­ì— ëŒ€í•´ ë¶€ë“œëŸ¬ìš´ í–¥ìƒ ì ìš©
                # 1. ì•½ê°„ì˜ ë¸”ëŸ¬ë¥¼ í†µí•œ í”¼ë¶€ ë¶€ë“œëŸ½ê²Œ
                blurred = cv2.GaussianBlur(face_region, (5, 5), 1.0)
                
                # 2. ì›ë³¸ê³¼ ë¸”ëŸ¬ì˜ ê°€ì¤‘ í•©ì„±
                softened = cv2.addWeighted(face_region, 0.7, blurred, 0.3, 0)
                
                # 3. ë°ê¸° ì•½ê°„ ì¡°ì •
                brightened = cv2.convertScaleAbs(softened, alpha=1.1, beta=5)
                
                # 4. í–¥ìƒëœ ì–¼êµ´ ì˜ì—­ì„ ì›ë³¸ì— ì ìš©
                enhanced[y:y+h, x:x+w] = brightened
            
            return enhanced
            
        except Exception as e:
            self.logger.error(f"ì–¼êµ´ ì˜ì—­ í–¥ìƒ ì‹¤íŒ¨: {e}")
            return image
    
    def _apply_final_post_processing(self, image: np.ndarray) -> np.ndarray:
        """ìµœì¢… í›„ì²˜ë¦¬"""
        try:
            if not NUMPY_AVAILABLE or not OPENCV_AVAILABLE:
                return image
                
            # 1. ë¯¸ì„¸í•œ ë…¸ì´ì¦ˆ ì œê±°
            denoised = cv2.medianBlur(image, 3)
            
            # 2. ì•½ê°„ì˜ ì„ ëª…í™”
            kernel = np.array([[-0.1, -0.1, -0.1],
                               [-0.1,  1.8, -0.1],
                               [-0.1, -0.1, -0.1]])
            sharpened = cv2.filter2D(denoised, -1, kernel)
            
            # 3. ìƒ‰ìƒ ë³´ì •
            final = cv2.convertScaleAbs(sharpened, alpha=1.02, beta=2)
            
            return final
            
        except Exception as e:
            self.logger.error(f"ìµœì¢… í›„ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return image
    
    def _calculate_image_quality(self, image: np.ndarray) -> float:
        """ì´ë¯¸ì§€ í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°"""
        try:
            if not NUMPY_AVAILABLE or not isinstance(image, np.ndarray):
                return 0.5
                
            if not OPENCV_AVAILABLE:
                return 0.5
            
            # ì—¬ëŸ¬ í’ˆì§ˆ ì§€í‘œì˜ ì¡°í•©
            
            # 1. ì„ ëª…ë„ (ë¼í”Œë¼ì‹œì•ˆ ë¶„ì‚°)
            gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
            laplacian_var = cv2.Laplacian(gray, cv2.CV_64F).var()
            sharpness_score = min(laplacian_var / 1000.0, 1.0)
            
            # 2. ëŒ€ë¹„ (í‘œì¤€í¸ì°¨)
            contrast_score = min(np.std(gray) / 128.0, 1.0)
            
            # 3. ë°ê¸° ê· í˜• (íˆìŠ¤í† ê·¸ë¨ ë¶„í¬)
            hist = cv2.calcHist([gray], [0], None, [256], [0, 256])
            hist_normalized = hist / hist.sum()
            entropy = -np.sum(hist_normalized * np.log2(hist_normalized + 1e-10))
            brightness_score = min(entropy / 8.0, 1.0)
            
            # 4. ìƒ‰ìƒ ë‹¤ì–‘ì„±
            rgb_std = np.mean([np.std(image[:, :, i]) for i in range(3)])
            color_score = min(rgb_std / 64.0, 1.0)
            
            # ê°€ì¤‘ í‰ê· 
            quality_score = (
                sharpness_score * 0.3 +
                contrast_score * 0.3 +
                brightness_score * 0.2 +
                color_score * 0.2
            )
            
            return quality_score
            
        except Exception as e:
            self.logger.error(f"í’ˆì§ˆ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return 0.5
    
    def _resize_image_preserve_ratio(self, image: np.ndarray, max_height: int, max_width: int) -> np.ndarray:
        """ë¹„ìœ¨ì„ ìœ ì§€í•˜ë©´ì„œ ì´ë¯¸ì§€ í¬ê¸° ì¡°ì •"""
        try:
            if not NUMPY_AVAILABLE or not OPENCV_AVAILABLE:
                return image
                
            h, w = image.shape[:2]
            
            if h <= max_height and w <= max_width:
                return image
            
            # ë¹„ìœ¨ ê³„ì‚°
            ratio = min(max_height / h, max_width / w)
            new_h = int(h * ratio)
            new_w = int(w * ratio)
            
            # ê³ í’ˆì§ˆ ë¦¬ìƒ˜í”Œë§
            resized = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_LANCZOS4)
            
            return resized
            
        except Exception as e:
            self.logger.error(f"ì´ë¯¸ì§€ í¬ê¸° ì¡°ì • ì‹¤íŒ¨: {e}")
            return image
    
    # ==============================================
    # ğŸ”¥ 13. ì‹œê°í™” ê´€ë ¨ ë©”ì„œë“œë“¤
    # ==============================================
    
    async def _create_enhancement_visualization(
        self,
        processed_input: Dict[str, Any],
        result: PostProcessingResult,
        options: Dict[str, Any]
    ) -> Dict[str, str]:
        """í›„ì²˜ë¦¬ ê²°ê³¼ ì‹œê°í™” ì´ë¯¸ì§€ë“¤ ìƒì„±"""
        try:
            if not self.post_processing_config.enable_visualization:
                return {
                    'before_after_comparison': '',
                    'enhancement_details': '',
                    'quality_metrics': ''
                }
            
            def _create_visualizations():
                original_image = processed_input['image']
                enhanced_image = result.enhanced_image
                
                if not NUMPY_AVAILABLE or not PIL_AVAILABLE:
                    return {
                        'before_after_comparison': '',
                        'enhancement_details': '',
                        'quality_metrics': ''
                    }
                
                visualizations = {}
                
                # 1. Before/After ë¹„êµ ì´ë¯¸ì§€
                if self.post_processing_config.show_before_after:
                    before_after = self._create_before_after_comparison(
                        original_image, enhanced_image, result
                    )
                    visualizations['before_after_comparison'] = self._numpy_to_base64(before_after)
                else:
                    visualizations['before_after_comparison'] = ''
                
                # 2. í–¥ìƒ ì„¸ë¶€ì‚¬í•­ ì‹œê°í™”
                if self.post_processing_config.show_enhancement_details:
                    enhancement_details = self._create_enhancement_details_visualization(
                        original_image, enhanced_image, result, options
                    )
                    visualizations['enhancement_details'] = self._numpy_to_base64(enhancement_details)
                else:
                    visualizations['enhancement_details'] = ''
                
                # 3. í’ˆì§ˆ ë©”íŠ¸ë¦­ ì‹œê°í™”
                quality_metrics = self._create_quality_metrics_visualization(
                    result, options
                )
                visualizations['quality_metrics'] = self._numpy_to_base64(quality_metrics)
                
                return visualizations
            
            # ë¹„ë™ê¸° ì‹¤í–‰
            loop = asyncio.get_event_loop()
            return await loop.run_in_executor(self.executor, _create_visualizations)
            
        except Exception as e:
            self.logger.error(f"âŒ ì‹œê°í™” ìƒì„± ì‹¤íŒ¨: {e}")
            return {
                'before_after_comparison': '',
                'enhancement_details': '',
                'quality_metrics': ''
            }
    
    def _create_before_after_comparison(
        self,
        original_image: np.ndarray,
        enhanced_image: np.ndarray,
        result: PostProcessingResult
    ) -> np.ndarray:
        """Before/After ë¹„êµ ì´ë¯¸ì§€ ìƒì„±"""
        try:
            if not NUMPY_AVAILABLE or not PIL_AVAILABLE or not OPENCV_AVAILABLE:
                return np.ones((600, 1100, 3), dtype=np.uint8) * 200
                
            # ì´ë¯¸ì§€ í¬ê¸° ë§ì¶”ê¸°
            target_size = (512, 512)
            original_resized = cv2.resize(original_image, target_size, interpolation=cv2.INTER_LANCZOS4)
            enhanced_resized = cv2.resize(enhanced_image, target_size, interpolation=cv2.INTER_LANCZOS4)
            
            # ë‚˜ë€íˆ ë°°ì¹˜í•  ìº”ë²„ìŠ¤ ìƒì„±
            canvas_width = target_size[0] * 2 + 100  # 100px ê°„ê²©
            canvas_height = target_size[1] + 100  # ìƒë‹¨ì— í…ìŠ¤íŠ¸ ê³µê°„
            canvas = np.ones((canvas_height, canvas_width, 3), dtype=np.uint8) * 240
            
            # ì´ë¯¸ì§€ ë°°ì¹˜
            canvas[50:50+target_size[1], 25:25+target_size[0]] = original_resized
            canvas[50:50+target_size[1], 75+target_size[0]:75+target_size[0]*2] = enhanced_resized
            
            # PILë¡œ ë³€í™˜í•´ì„œ í…ìŠ¤íŠ¸ ì¶”ê°€
            canvas_pil = Image.fromarray(canvas)
            draw = ImageDraw.Draw(canvas_pil)
            
            # í°íŠ¸ ì„¤ì •
            try:
                title_font = ImageFont.truetype("/System/Library/Fonts/Arial.ttf", 24)
                subtitle_font = ImageFont.truetype("/System/Library/Fonts/Arial.ttf", 16)
                text_font = ImageFont.truetype("/System/Library/Fonts/Arial.ttf", 14)
            except:
                try:
                    title_font = ImageFont.load_default()
                    subtitle_font = ImageFont.load_default()
                    text_font = ImageFont.load_default()
                except:
                    # í…ìŠ¤íŠ¸ ì—†ì´ ì´ë¯¸ì§€ë§Œ ë°˜í™˜
                    return np.array(canvas_pil)
            
            # ì œëª©
            draw.text((canvas_width//2 - 100, 10), "í›„ì²˜ë¦¬ ê²°ê³¼ ë¹„êµ", fill=(50, 50, 50), font=title_font)
            
            # ë¼ë²¨
            draw.text((25 + target_size[0]//2 - 30, 25), "Before", fill=(100, 100, 100), font=subtitle_font)
            draw.text((75 + target_size[0] + target_size[0]//2 - 30, 25), "After", fill=(100, 100, 100), font=subtitle_font)
            
            # í’ˆì§ˆ ê°œì„  ì •ë³´
            improvement_text = f"í’ˆì§ˆ ê°œì„ : {result.quality_improvement:.1%}"
            methods_text = f"ì ìš©ëœ ë°©ë²•: {', '.join(result.applied_methods[:3])}"
            if len(result.applied_methods) > 3:
                methods_text += f" ì™¸ {len(result.applied_methods) - 3}ê°œ"
            
            draw.text((25, canvas_height - 40), improvement_text, fill=(0, 150, 0), font=text_font)
            draw.text((25, canvas_height - 20), methods_text, fill=(80, 80, 80), font=text_font)
            
            # êµ¬ë¶„ì„ 
            draw.line([(target_size[0] + 50, 50), (target_size[0] + 50, 50 + target_size[1])], 
                     fill=(200, 200, 200), width=2)
            
            return np.array(canvas_pil)
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ Before/After ë¹„êµ ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨: {e}")
            # í´ë°±: ê¸°ë³¸ ì´ë¯¸ì§€
            if NUMPY_AVAILABLE:
                return np.ones((600, 1100, 3), dtype=np.uint8) * 200
            else:
                return None
    
    def _create_enhancement_details_visualization(
        self,
        original_image: np.ndarray,
        enhanced_image: np.ndarray,
        result: PostProcessingResult,
        options: Dict[str, Any]
    ) -> np.ndarray:
        """í–¥ìƒ ì„¸ë¶€ì‚¬í•­ ì‹œê°í™”"""
        try:
            if not NUMPY_AVAILABLE or not PIL_AVAILABLE or not OPENCV_AVAILABLE:
                return np.ones((400, 800, 3), dtype=np.uint8) * 200
                
            # ê°„ë‹¨í•œ ê·¸ë¦¬ë“œ ìƒì„±
            grid_size = 256
            canvas_width = grid_size * 3 + 100
            canvas_height = grid_size * 2 + 100
            canvas = np.ones((canvas_height, canvas_width, 3), dtype=np.uint8) * 250
            
            # ì´ë¯¸ì§€ ë¦¬ì‚¬ì´ì¦ˆ
            original_small = cv2.resize(original_image, (grid_size, grid_size))
            enhanced_small = cv2.resize(enhanced_image, (grid_size, grid_size))
            
            # ì´ë¯¸ì§€ ë°°ì¹˜
            canvas[25:25+grid_size, 25:25+grid_size] = original_small
            canvas[25:25+grid_size, 50+grid_size:50+grid_size*2] = enhanced_small
            
            # í…ìŠ¤íŠ¸ ì •ë³´ ì¶”ê°€
            canvas_pil = Image.fromarray(canvas)
            draw = ImageDraw.Draw(canvas_pil)
            
            try:
                font = ImageFont.load_default()
            except:
                return np.array(canvas_pil)
            
            # ë¼ë²¨
            draw.text((25, 5), "ì›ë³¸", fill=(50, 50, 50), font=font)
            draw.text((50+grid_size, 5), "í–¥ìƒëœ ì´ë¯¸ì§€", fill=(50, 50, 50), font=font)
            
            # í–¥ìƒ ë°©ë²• ë¦¬ìŠ¤íŠ¸
            y_offset = 25 + grid_size + 20
            draw.text((25, y_offset), "ì ìš©ëœ í–¥ìƒ ë°©ë²•:", fill=(50, 50, 50), font=font)
            
            for i, method in enumerate(result.applied_methods[:5]):  # ìµœëŒ€ 5ê°œë§Œ í‘œì‹œ
                method_name = method.replace('_', ' ').title()
                draw.text((25, y_offset + 20 + i*15), f"â€¢ {method_name}", fill=(80, 80, 80), font=font)
            
            return np.array(canvas_pil)
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ í–¥ìƒ ì„¸ë¶€ì‚¬í•­ ì‹œê°í™” ì‹¤íŒ¨: {e}")
            if NUMPY_AVAILABLE:
                return np.ones((400, 800, 3), dtype=np.uint8) * 200
            else:
                return None
    
    def _create_quality_metrics_visualization(
        self,
        result: PostProcessingResult,
        options: Dict[str, Any]
    ) -> np.ndarray:
        """í’ˆì§ˆ ë©”íŠ¸ë¦­ ì‹œê°í™”"""
        try:
            if not NUMPY_AVAILABLE or not PIL_AVAILABLE:
                return np.ones((300, 400, 3), dtype=np.uint8) * 200
                
            # í’ˆì§ˆ ë©”íŠ¸ë¦­ ì •ë³´ íŒ¨ë„ ìƒì„±
            canvas_width = 400
            canvas_height = 300
            canvas = np.ones((canvas_height, canvas_width, 3), dtype=np.uint8) * 250
            
            canvas_pil = Image.fromarray(canvas)
            draw = ImageDraw.Draw(canvas_pil)
            
            # í°íŠ¸ ì„¤ì •
            try:
                title_font = ImageFont.load_default()
                text_font = ImageFont.load_default()
            except:
                return np.array(canvas_pil)
            
            # ì œëª©
            draw.text((20, 20), "í›„ì²˜ë¦¬ í’ˆì§ˆ ë¶„ì„", fill=(50, 50, 50), font=title_font)
            
            # ì „ì²´ ê°œì„ ë„ í‘œì‹œ
            improvement_percent = result.quality_improvement * 100
            improvement_color = (0, 150, 0) if improvement_percent > 15 else (255, 150, 0) if improvement_percent > 5 else (255, 0, 0)
            draw.text((20, 50), f"ì „ì²´ í’ˆì§ˆ ê°œì„ : {improvement_percent:.1f}%", fill=improvement_color, font=text_font)
            
            # ì ìš©ëœ ë°©ë²•ë“¤
            y_offset = 80
            draw.text((20, y_offset), "ì ìš©ëœ í–¥ìƒ ë°©ë²•:", fill=(50, 50, 50), font=text_font)
            y_offset += 25
            
            for i, method in enumerate(result.applied_methods[:8]):  # ìµœëŒ€ 8ê°œ
                method_name = method.replace('_', ' ').title()
                draw.text((30, y_offset), f"â€¢ {method_name}", fill=(80, 80, 80), font=text_font)
                y_offset += 20
            
            # ì²˜ë¦¬ ì‹œê°„ ì •ë³´
            y_offset += 10
            draw.text((20, y_offset), f"ì²˜ë¦¬ ì‹œê°„: {result.processing_time:.2f}ì´ˆ", fill=(100, 100, 100), font=text_font)
            
            return np.array(canvas_pil)
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ í’ˆì§ˆ ë©”íŠ¸ë¦­ ì‹œê°í™” ì‹¤íŒ¨: {e}")
            if NUMPY_AVAILABLE:
                return np.ones((300, 400, 3), dtype=np.uint8) * 200
            else:
                return None
    
    
import base64
import numpy as np
from io import BytesIO
from PIL import Image

logger = logging.getLogger(__name__)
# ğŸ”§ ìˆ˜ì •ëœ _numpy_to_base64 í•¨ìˆ˜
def _numpy_to_base64(self, image) -> str:
    """numpy ë°°ì—´ì„ base64 ë¬¸ìì—´ë¡œ ë³€í™˜ - ì™„ì „ ìˆ˜ì • ë²„ì „"""
    try:
        # 1. ì…ë ¥ ê²€ì¦
        if image is None:
            self.logger.warning("âš ï¸ ì…ë ¥ ì´ë¯¸ì§€ê°€ Noneì…ë‹ˆë‹¤")
            return ""
            
        if not hasattr(image, 'shape'):
            self.logger.warning("âš ï¸ NumPy ë°°ì—´ì´ ì•„ë‹™ë‹ˆë‹¤")
            return ""
        
        # 2. ì´ë¯¸ì§€ íƒ€ì… ë° ë²”ìœ„ ì •ê·œí™”
        if image.dtype != np.uint8:
            # float íƒ€ì…ì¸ ê²½ìš° 0-1 ë²”ìœ„ë¥¼ 0-255ë¡œ ë³€í™˜
            if image.max() <= 1.0:
                image = (image * 255).astype(np.uint8)
            else:
                image = np.clip(image, 0, 255).astype(np.uint8)
        
        # 3. ì°¨ì› ê²€ì¦ ë° ìˆ˜ì •
        if len(image.shape) == 4:  # Batch ì°¨ì› ì œê±°
            image = image.squeeze(0)
        elif len(image.shape) == 2:  # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ì„ RGBë¡œ ë³€í™˜
            image = np.stack([image] * 3, axis=-1)
        elif len(image.shape) == 3 and image.shape[0] in [1, 3]:  # CHW â†’ HWC ë³€í™˜
            image = np.transpose(image, (1, 2, 0))
        
        # 4. PIL Imageë¡œ ì•ˆì „í•˜ê²Œ ë³€í™˜
        try:
            pil_image = Image.fromarray(image)
        except Exception as e:
            self.logger.error(f"âŒ PIL ë³€í™˜ ì‹¤íŒ¨: {e}")
            return ""
        
        # 5. RGB ëª¨ë“œ í™•ì¸ ë° ë³€í™˜
        if pil_image.mode not in ['RGB', 'RGBA']:
            pil_image = pil_image.convert('RGB')
        elif pil_image.mode == 'RGBA':
            # RGBAë¥¼ RGBë¡œ ë³€í™˜ (í°ìƒ‰ ë°°ê²½)
            rgb_image = Image.new('RGB', pil_image.size, (255, 255, 255))
            rgb_image.paste(pil_image, mask=pil_image.split()[-1])
            pil_image = rgb_image
        
        # 6. BytesIO ë²„í¼ì— ì €ì¥ (ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±)
        buffer = BytesIO()
        
        # 7. í’ˆì§ˆ ì„¤ì • - ë‹¨ê³„ë³„ë¡œ ì¡°ì •
        quality = 90  # ê¸°ë³¸ê°’
        if hasattr(self, 'post_processing_config'):
            if self.post_processing_config.visualization_quality == 'high':
                quality = 95
            elif self.post_processing_config.visualization_quality == 'low':
                quality = 75
        
        # 8. ì´ë¯¸ì§€ ì €ì¥ (ìµœì í™” ì˜µì…˜ í¬í•¨)
        pil_image.save(
            buffer, 
            format='JPEG', 
            quality=quality,
            optimize=True,  # íŒŒì¼ í¬ê¸° ìµœì í™”
            progressive=True  # ì ì§„ì  ë¡œë”©
        )
        
        # 9. Base64 ì¸ì½”ë”© (ë²„í¼ í¬ê¸° ê²€ì¦)
        buffer.seek(0)  # ë²„í¼ í¬ì¸í„°ë¥¼ ì²˜ìŒìœ¼ë¡œ
        image_bytes = buffer.getvalue()
        
        if len(image_bytes) == 0:
            self.logger.error("âŒ ì´ë¯¸ì§€ ì €ì¥ ì‹¤íŒ¨ - ë¹ˆ ë²„í¼")
            return ""
        
        base64_string = base64.b64encode(image_bytes).decode('utf-8')
        
        # 10. ê²°ê³¼ ê²€ì¦
        if len(base64_string) < 100:  # ë„ˆë¬´ ì§§ì€ ê²½ìš°
            self.logger.warning(f"âš ï¸ Base64 ë¬¸ìì—´ì´ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤: {len(base64_string)} ë¬¸ì")
            return ""
        
        self.logger.debug(f"âœ… Base64 ë³€í™˜ ì„±ê³µ: {len(base64_string)} ë¬¸ì, í’ˆì§ˆ: {quality}")
        return base64_string
        
    except Exception as e:
        self.logger.error(f"âŒ Base64 ë³€í™˜ ì™„ì „ ì‹¤íŒ¨: {e}")
        return ""


    # ==============================================
    # ğŸ”¥ 14. ìœ í‹¸ë¦¬í‹° ë° ê´€ë¦¬ ë©”ì„œë“œë“¤
    # ==============================================
    
    def _generate_cache_key(self, fitting_result: Dict[str, Any], enhancement_options: Optional[Dict[str, Any]]) -> str:
        """ìºì‹œ í‚¤ ìƒì„±"""
        try:
            # ì…ë ¥ ì´ë¯¸ì§€ í•´ì‹œ
            fitted_image = fitting_result.get('fitted_image') or fitting_result.get('result_image')
            if isinstance(fitted_image, str):
                # Base64 ë¬¸ìì—´ì˜ í•´ì‹œ
                image_hash = hashlib.md5(fitted_image.encode()).hexdigest()[:16]
            elif NUMPY_AVAILABLE and isinstance(fitted_image, np.ndarray):
                image_hash = hashlib.md5(fitted_image.tobytes()).hexdigest()[:16]
            else:
                image_hash = str(hash(str(fitted_image)))[:16]
            
            # ì˜µì…˜ í•´ì‹œ
            options_str = json.dumps(enhancement_options or {}, sort_keys=True)
            options_hash = hashlib.md5(options_str.encode()).hexdigest()[:8]
            
            # ì „ì²´ í‚¤ ìƒì„±
            cache_key = f"{image_hash}_{options_hash}_{self.device}_{self.post_processing_config.quality_level.value}"
            return cache_key
            
        except Exception as e:
            self.logger.warning(f"ìºì‹œ í‚¤ ìƒì„± ì‹¤íŒ¨: {e}")
            return f"fallback_{time.time()}_{self.device}"
    
    def _cleanup_cache(self):
        """ìºì‹œ ì •ë¦¬ (LRU ë°©ì‹)"""
        try:
            if len(self.enhancement_cache) <= self.post_processing_config.cache_size:
                return
            
            # ê°€ì¥ ì˜¤ë˜ëœ í•­ëª©ë“¤ ì œê±°
            items = list(self.enhancement_cache.items())
            # ì²˜ë¦¬ ì‹œê°„ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
            items.sort(key=lambda x: x[1].processing_time)
            
            # ì ˆë°˜ ì •ë„ ì œê±°
            remove_count = len(items) - self.post_processing_config.cache_size // 2
            
            for i in range(remove_count):
                del self.enhancement_cache[items[i][0]]
            
            self.logger.info(f"ğŸ’¾ ìºì‹œ ì •ë¦¬ ì™„ë£Œ: {remove_count}ê°œ í•­ëª© ì œê±°")
            
        except Exception as e:
            self.logger.error(f"ìºì‹œ ì •ë¦¬ ì‹¤íŒ¨: {e}")
    
    def _update_statistics(self, result: PostProcessingResult, processing_time: float):
        """í†µê³„ ì—…ë°ì´íŠ¸"""
        try:
            self.processing_stats['total_processed'] += 1
            
            if result.success:
                self.processing_stats['successful_enhancements'] += 1
                
                # í‰ê·  ê°œì„ ë„ ì—…ë°ì´íŠ¸
                current_avg = self.processing_stats['average_improvement']
                total_successful = self.processing_stats['successful_enhancements']
                
                self.processing_stats['average_improvement'] = (
                    (current_avg * (total_successful - 1) + result.quality_improvement) / total_successful
                )
                
                # ë°©ë²•ë³„ ì‚¬ìš© í†µê³„
                for method in result.applied_methods:
                    if method not in self.processing_stats['method_usage']:
                        self.processing_stats['method_usage'][method] = 0
                    self.processing_stats['method_usage'][method] += 1
            
            # í‰ê·  ì²˜ë¦¬ ì‹œê°„ ì—…ë°ì´íŠ¸
            current_avg_time = self.processing_stats['average_processing_time']
            total_processed = self.processing_stats['total_processed']
            
            self.processing_stats['average_processing_time'] = (
                (current_avg_time * (total_processed - 1) + processing_time) / total_processed
            )
            
            # ê²°ê³¼ì— ì²˜ë¦¬ ì‹œê°„ ì„¤ì •
            result.processing_time = processing_time
            
        except Exception as e:
            self.logger.warning(f"í†µê³„ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
    
    def _format_result(self, result: PostProcessingResult) -> Dict[str, Any]:
        """ê²°ê³¼ë¥¼ í‘œì¤€ ë”•ì…”ë„ˆë¦¬ í˜•íƒœë¡œ í¬ë§· + API í˜¸í™˜ì„±"""
        try:
            # API í˜¸í™˜ì„±ì„ ìœ„í•œ ê²°ê³¼ êµ¬ì¡° (ê¸°ì¡´ í•„ë“œ + ì‹œê°í™” í•„ë“œ)
            formatted_result = {
                'success': result.success,
                'message': f'í›„ì²˜ë¦¬ ì™„ë£Œ - í’ˆì§ˆ ê°œì„ : {result.quality_improvement:.1%}' if result.success else result.error_message,
                'confidence': min(1.0, max(0.0, result.quality_improvement + 0.7)) if result.success else 0.0,
                'processing_time': result.processing_time,
                'details': {}
            }
            
            if result.success:
                # í”„ë¡ íŠ¸ì—”ë“œìš© ì‹œê°í™” ì´ë¯¸ì§€ë“¤
                visualization = result.metadata.get('visualization', {})
                formatted_result['details'] = {
                    # ì‹œê°í™” ì´ë¯¸ì§€ë“¤
                    'result_image': visualization.get('before_after_comparison', ''),
                    'overlay_image': visualization.get('enhancement_details', ''),
                    
                    # ê¸°ì¡´ ë°ì´í„°ë“¤
                    'applied_methods': result.applied_methods,
                    'quality_improvement': result.quality_improvement,
                    'enhancement_count': len(result.applied_methods),
                    'processing_mode': self.post_processing_config.processing_mode.value,
                    'quality_level': self.post_processing_config.quality_level.value,
                    
                    # ìƒì„¸ í–¥ìƒ ì •ë³´
                    'enhancement_details': {
                        'methods_applied': len(result.applied_methods),
                        'improvement_percentage': result.quality_improvement * 100,
                        'enhancement_log': result.metadata.get('enhancement_log', []),
                        'quality_metrics': visualization.get('quality_metrics', '')
                    },
                    
                    # ì‹œìŠ¤í…œ ì •ë³´
                    'step_info': {
                        'step_name': 'post_processing',
                        'step_number': 7,
                        'device': self.device,
                        'quality_level': self.post_processing_config.quality_level.value,
                        'optimization': 'M3 Max' if self.is_m3_max else self.device,
                        'models_used': {
                            'sr_model': self.sr_model is not None,
                            'denoise_model': self.denoise_model is not None,
                            'face_detector': self.face_detector is not None
                        }
                    },
                    
                    # í’ˆì§ˆ ë©”íŠ¸ë¦­
                    'quality_metrics': {
                        'overall_improvement': result.quality_improvement,
                        'original_quality': result.metadata.get('original_quality', 0.5),
                        'final_quality': result.metadata.get('final_quality', 0.5),
                        'enhancement_strength': self.enhancement_strength,
                        'face_enhancement_applied': 'face_enhancement' in result.applied_methods
                    }
                }
                
                # ê¸°ì¡´ API í˜¸í™˜ì„± í•„ë“œë“¤
                formatted_result.update({
                    'enhanced_image': result.enhanced_image.tolist() if NUMPY_AVAILABLE and result.enhanced_image is not None else None,
                    'applied_methods': result.applied_methods,
                    'metadata': result.metadata
                })
            else:
                # ì—ëŸ¬ ì‹œ ê¸°ë³¸ êµ¬ì¡°
                formatted_result['details'] = {
                    'result_image': '',
                    'overlay_image': '',
                    'error': result.error_message,
                    'step_info': {
                        'step_name': 'post_processing',
                        'step_number': 7,
                        'error': result.error_message
                    }
                }
                formatted_result['error_message'] = result.error_message
            
            return formatted_result
            
        except Exception as e:
            self.logger.error(f"ê²°ê³¼ í¬ë§·íŒ… ì‹¤íŒ¨: {e}")
            return {
                'success': False,
                'message': f'ê²°ê³¼ í¬ë§·íŒ… ì‹¤íŒ¨: {e}',
                'confidence': 0.0,
                'processing_time': 0.0,
                'details': {
                    'result_image': '',
                    'overlay_image': '',
                    'error': str(e),
                    'step_info': {
                        'step_name': 'post_processing',
                        'step_number': 7,
                        'error': str(e)
                    }
                },
                'applied_methods': [],
                'error_message': str(e)
            }
    
    # ==============================================
    # ğŸ”¥ 15. BaseStepMixin í˜¸í™˜ ì¸í„°í˜ì´ìŠ¤ë“¤
    # ==============================================
    
    def get_model(self, model_name: Optional[str] = None) -> Optional[Any]:
        """ëª¨ë¸ ê°€ì ¸ì˜¤ê¸° - BaseStepMixin í˜¸í™˜ (ë™ê¸° ë²„ì „)"""
        try:
            # BaseStepMixin í˜¸í™˜ì„ ìœ„í•œ ë™ì  ë¶€ëª¨ ë©”ì„œë“œ í˜¸ì¶œ
            BaseStepMixin = dynamic_import_base_step_mixin()
            if BaseStepMixin and hasattr(BaseStepMixin, 'get_model'):
                try:
                    model = super(PostProcessingStep, self).get_model(model_name)
                    if model:
                        return model
                except:
                    pass
            
            # í›„ì²˜ë¦¬ íŠ¹í™” ëª¨ë¸ ë°˜í™˜
            if not model_name or model_name == "default":
                # ê¸°ë³¸ ëª¨ë¸ (Super Resolution ìš°ì„ )
                return self.sr_model or self.denoise_model
            elif "sr" in model_name.lower() or "super" in model_name.lower():
                return self.sr_model
            elif "denoise" in model_name.lower() or "noise" in model_name.lower():
                return self.denoise_model
            elif "face" in model_name.lower():
                return self.face_detector
            else:
                # ìºì‹œì—ì„œ ê²€ìƒ‰
                return self.model_cache.get(model_name)
                
        except Exception as e:
            self.logger.error(f"âŒ ëª¨ë¸ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {e}")
            return None
    
    async def get_model_async(self, model_name: Optional[str] = None) -> Optional[Any]:
        """ëª¨ë¸ ê°€ì ¸ì˜¤ê¸° - BaseStepMixin í˜¸í™˜ (ë¹„ë™ê¸° ë²„ì „)"""
        try:
            # ë™ê¸° ë©”ì„œë“œë¥¼ ë¹„ë™ê¸°ë¡œ ì‹¤í–‰
            loop = asyncio.get_event_loop()
            return await loop.run_in_executor(None, lambda: self.get_model(model_name))
            
        except Exception as e:
            self.logger.error(f"âŒ ë¹„ë™ê¸° ëª¨ë¸ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {e}")
            return None
    
    def optimize_memory(self, aggressive: bool = False) -> Dict[str, Any]:
        """ë©”ëª¨ë¦¬ ìµœì í™” - BaseStepMixin í˜¸í™˜ (ë™ê¸° ë²„ì „)"""
        try:
            # í›„ì²˜ë¦¬ íŠ¹í™” ë©”ëª¨ë¦¬ ìµœì í™”
            post_processing_result = {
                'cache_cleared': 0,
                'models_optimized': 0
            }
            
            # ìºì‹œ ì •ë¦¬
            if aggressive:
                cache_size_before = len(self.enhancement_cache)
                self.enhancement_cache.clear()
                post_processing_result['cache_cleared'] = cache_size_before
            
            # ëª¨ë¸ ë©”ëª¨ë¦¬ ìµœì í™”
            models_optimized = 0
            if self.sr_model and TORCH_AVAILABLE:
                if hasattr(self.sr_model, 'cpu'):
                    self.sr_model.cpu()
                models_optimized += 1
            
            if self.denoise_model and TORCH_AVAILABLE:
                if hasattr(self.denoise_model, 'cpu'):
                    self.denoise_model.cpu()
                models_optimized += 1
            
            post_processing_result['models_optimized'] = models_optimized
            
            # PyTorch ë©”ëª¨ë¦¬ ì •ë¦¬
            if TORCH_AVAILABLE:
                if self.device == 'mps' and MPS_AVAILABLE:
                    try:
                        safe_mps_empty_cache()
                    except:
                        pass
                elif self.device == 'cuda':
                    try:
                        torch.cuda.empty_cache()
                    except:
                        pass
                
                gc.collect()
            
            # ê²°ê³¼ ë°˜í™˜
            return {
                'post_processing': post_processing_result,
                'success': True
            }
            
        except Exception as e:
            self.logger.error(f"âŒ ë©”ëª¨ë¦¬ ìµœì í™” ì‹¤íŒ¨: {e}")
            return {"success": False, "error": str(e)}
    
    async def optimize_memory_async(self, aggressive: bool = False) -> Dict[str, Any]:
        """ë©”ëª¨ë¦¬ ìµœì í™” - BaseStepMixin í˜¸í™˜ (ë¹„ë™ê¸° ë²„ì „)"""
        try:
            # ë™ê¸° ë©”ì„œë“œë¥¼ ë¹„ë™ê¸°ë¡œ ì‹¤í–‰
            loop = asyncio.get_event_loop()
            return await loop.run_in_executor(None, lambda: self.optimize_memory(aggressive))
            
        except Exception as e:
            self.logger.error(f"âŒ ë¹„ë™ê¸° ë©”ëª¨ë¦¬ ìµœì í™” ì‹¤íŒ¨: {e}")
            return {"success": False, "error": str(e)}
    
    def warmup(self) -> Dict[str, Any]:
        """ì›Œë°ì—… - BaseStepMixin í˜¸í™˜ (ë™ê¸° ë²„ì „)"""
        try:
            # í›„ì²˜ë¦¬ íŠ¹í™” ì›Œë°ì—…
            start_time = time.time()
            warmup_results = []
            
            # AI ëª¨ë¸ ì›Œë°ì—…
            if self.sr_model and TORCH_AVAILABLE:
                try:
                    dummy_tensor = torch.randn(1, 3, 256, 256).to(self.device)
                    with torch.no_grad():
                        _ = self.sr_model(dummy_tensor)
                    warmup_results.append("sr_model_success")
                except:
                    warmup_results.append("sr_model_failed")
            
            if self.denoise_model and TORCH_AVAILABLE:
                try:
                    dummy_tensor = torch.randn(1, 3, 256, 256).to(self.device)
                    with torch.no_grad():
                        _ = self.denoise_model(dummy_tensor)
                    warmup_results.append("denoise_model_success")
                except:
                    warmup_results.append("denoise_model_failed")
            
            # ì´ë¯¸ì§€ ì²˜ë¦¬ ì›Œë°ì—…
            if NUMPY_AVAILABLE and OPENCV_AVAILABLE:
                try:
                    dummy_image = np.random.randint(0, 255, (256, 256, 3), dtype=np.uint8)
                    _ = self._calculate_image_quality(dummy_image)
                    warmup_results.append("image_processing_success")
                except:
                    warmup_results.append("image_processing_failed")
            
            duration = time.time() - start_time
            success_count = sum(1 for r in warmup_results if 'success' in r)
            
            return {
                'post_processing': {
                    'duration': duration,
                    'results': warmup_results,
                    'success_count': success_count,
                    'total_count': len(warmup_results),
                    'success': success_count > 0
                }
            }
            
        except Exception as e:
            self.logger.error(f"âŒ ì›Œë°ì—… ì‹¤íŒ¨: {e}")
            return {"success": False, "error": str(e)}
    
    async def warmup_async(self) -> Dict[str, Any]:
        """ì›Œë°ì—… - BaseStepMixin í˜¸í™˜ (ë¹„ë™ê¸° ë²„ì „)"""
        try:
            # ë™ê¸° ë©”ì„œë“œë¥¼ ë¹„ë™ê¸°ë¡œ ì‹¤í–‰
            loop = asyncio.get_event_loop()
            return await loop.run_in_executor(None, self.warmup)
            
        except Exception as e:
            self.logger.error(f"âŒ ë¹„ë™ê¸° ì›Œë°ì—… ì‹¤íŒ¨: {e}")
            return {"success": False, "error": str(e)}
    
    async def warmup_step(self) -> Dict[str, Any]:
        """Step ì›Œë°ì—… - BaseStepMixin í˜¸í™˜ ë³„ì¹­"""
        return await self.warmup_async()
    
    def cleanup_models(self):
        """ëª¨ë¸ ì •ë¦¬ - BaseStepMixin í˜¸í™˜"""
        try:
            # í›„ì²˜ë¦¬ íŠ¹í™” ëª¨ë¸ ì •ë¦¬
            models_cleaned = 0
            
            if self.sr_model:
                if hasattr(self.sr_model, 'cpu'):
                    self.sr_model.cpu()
                del self.sr_model
                self.sr_model = None
                models_cleaned += 1
            
            if self.denoise_model:
                if hasattr(self.denoise_model, 'cpu'):
                    self.denoise_model.cpu()
                del self.denoise_model
                self.denoise_model = None
                models_cleaned += 1
            
            if self.face_detector:
                del self.face_detector
                self.face_detector = None
                models_cleaned += 1
            
            # ìºì‹œ ì •ë¦¬
            self.model_cache.clear()
            self.enhancement_cache.clear()
            
            # PyTorch ë©”ëª¨ë¦¬ ì •ë¦¬
            if TORCH_AVAILABLE:
                if self.device == 'mps':
                    try:
                        safe_mps_empty_cache()
                    except:
                        pass
                elif self.device == 'cuda':
                    try:
                        torch.cuda.empty_cache()
                    except:
                        pass
                
                gc.collect()
            
            self.has_model = False
            self.model_loaded = False
            self.logger.info(f"ğŸ§¹ í›„ì²˜ë¦¬ ëª¨ë¸ ì •ë¦¬ ì™„ë£Œ ({models_cleaned}ê°œ ëª¨ë¸)")
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ ëª¨ë¸ ì •ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
    
    def get_status(self) -> Dict[str, Any]:
        """Step ìƒíƒœ ì¡°íšŒ - BaseStepMixin í˜¸í™˜"""
        try:
            # í›„ì²˜ë¦¬ íŠ¹í™” ìƒíƒœ ì •ë³´
            return {
                'step_name': 'PostProcessingStep',
                'step_id': 7,
                'device': self.device,
                'is_m3_max': self.is_m3_max,
                'memory_gb': self.memory_gb,
                'models': {
                    'sr_model_loaded': self.sr_model is not None,
                    'denoise_model_loaded': self.denoise_model is not None,
                    'face_detector_loaded': self.face_detector is not None
                },
                'config': {
                    'quality_level': self.post_processing_config.quality_level.value,
                    'processing_mode': self.post_processing_config.processing_mode.value,
                    'enabled_methods': [method.value for method in self.post_processing_config.enabled_methods],
                    'enhancement_strength': self.enhancement_strength,
                    'visualization_enabled': self.post_processing_config.enable_visualization
                },
                'cache': {
                    'enhancement_cache_size': len(self.enhancement_cache),
                    'model_cache_size': len(self.model_cache),
                    'max_cache_size': self.post_processing_config.cache_size
                },
                'statistics': self.processing_stats,
                'dependencies': {
                    'torch_available': TORCH_AVAILABLE,
                    'mps_available': MPS_AVAILABLE,
                    'opencv_available': OPENCV_AVAILABLE,
                    'pil_available': PIL_AVAILABLE,
                    'numpy_available': NUMPY_AVAILABLE,
                    'model_loader_injected': self.model_loader is not None,
                    'memory_manager_injected': self.memory_manager is not None,
                    'data_converter_injected': self.data_converter is not None
                }
            }
            
        except Exception as e:
            self.logger.error(f"âŒ ìƒíƒœ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {
                'step_name': 'PostProcessingStep',
                'error': str(e),
                'timestamp': time.time()
            }
    
    def record_processing(self, duration: float, success: bool = True):
        """ì²˜ë¦¬ ê¸°ë¡ - BaseStepMixin í˜¸í™˜"""
        try:
            # í›„ì²˜ë¦¬ íŠ¹í™” ê¸°ë¡
            self.processing_stats['total_processed'] += 1
            
            if success:
                self.processing_stats['successful_enhancements'] += 1
            
            # í‰ê·  ì²˜ë¦¬ ì‹œê°„ ì—…ë°ì´íŠ¸
            current_avg = self.processing_stats['average_processing_time']
            total = self.processing_stats['total_processed']
            self.processing_stats['average_processing_time'] = (
                (current_avg * (total - 1) + duration) / total
            )
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ ì²˜ë¦¬ ê¸°ë¡ ì‹¤íŒ¨: {e}")
    
    def get_performance_summary(self) -> Dict[str, Any]:
        """ì„±ëŠ¥ ìš”ì•½ ì¡°íšŒ - BaseStepMixin í˜¸í™˜"""
        try:
            # í›„ì²˜ë¦¬ íŠ¹í™” ì„±ëŠ¥ ìš”ì•½
            return {
                'total_enhancements': self.processing_stats['total_processed'],
                'successful_enhancements': self.processing_stats['successful_enhancements'],
                'success_rate': (
                    self.processing_stats['successful_enhancements'] / 
                    max(1, self.processing_stats['total_processed'])
                ),
                'average_improvement': self.processing_stats['average_improvement'],
                'average_processing_time': self.processing_stats['average_processing_time'],
                'cache_hits': self.processing_stats['cache_hits'],
                'cache_hit_rate': (
                    self.processing_stats['cache_hits'] / 
                    max(1, self.processing_stats['total_processed'])
                ),
                'method_usage': self.processing_stats['method_usage'],
                'models_loaded': {
                    'sr_model': self.sr_model is not None,
                    'denoise_model': self.denoise_model is not None,
                    'face_detector': self.face_detector is not None
                }
            }
            
        except Exception as e:
            self.logger.error(f"âŒ ì„±ëŠ¥ ìš”ì•½ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {}
    
    async def get_step_info(self) -> Dict[str, Any]:
        """7ë‹¨ê³„ ìƒì„¸ ì •ë³´ ë°˜í™˜ - í™•ì¥ ë²„ì „"""
        try:
            return {
                "step_name": "post_processing",
                "step_number": 7,
                "device": self.device,
                "initialized": self.is_initialized,
                "ready": self.is_ready,
                "models_loaded": {
                    "sr_model": self.sr_model is not None,
                    "denoise_model": self.denoise_model is not None,
                    "face_detector": self.face_detector is not None
                },
                "config": {
                    "quality_level": self.post_processing_config.quality_level.value,
                    "processing_mode": self.post_processing_config.processing_mode.value,
                    "enabled_methods": [method.value for method in self.post_processing_config.enabled_methods],
                    "enhancement_strength": self.enhancement_strength,
                    "preserve_faces": self.preserve_faces,
                    "enable_visualization": self.post_processing_config.enable_visualization,
                    "visualization_quality": self.post_processing_config.visualization_quality,
                    "max_resolution": self.post_processing_config.max_resolution,
                    "use_gpu_acceleration": self.post_processing_config.use_gpu_acceleration,
                    "batch_size": self.post_processing_config.batch_size,
                    "cache_size": self.post_processing_config.cache_size
                },
                "performance": self.processing_stats,
                "cache": {
                    "size": len(self.enhancement_cache),
                    "max_size": self.post_processing_config.cache_size,
                    "hit_rate": (self.processing_stats['cache_hits'] / 
                                max(1, self.processing_stats['total_processed'])) * 100
                },
                "optimization": {
                    "m3_max_enabled": self.is_m3_max,
                    "memory_gb": self.memory_gb,
                    "device_type": self.device,
                    "use_gpu_acceleration": self.post_processing_config.use_gpu_acceleration
                },
                "dependencies_injected": self.dependencies_injected,
                "system_info": {
                    "conda_env": CONDA_INFO['conda_env'],
                    "conda_prefix": CONDA_INFO['conda_prefix'],
                    "is_m3_max": IS_M3_MAX
                }
            }
        except Exception as e:
            self.logger.error(f"ë‹¨ê³„ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {
                "step_name": "post_processing",
                "step_number": 7,
                "error": str(e)
            }
    
    def get_statistics(self) -> Dict[str, Any]:
        """ì²˜ë¦¬ í†µê³„ ë°˜í™˜"""
        try:
            stats = self.processing_stats.copy()
            
            # ì„±ê³µë¥  ê³„ì‚°
            if stats['total_processed'] > 0:
                stats['success_rate'] = stats['successful_enhancements'] / stats['total_processed']
            else:
                stats['success_rate'] = 0.0
            
            # ìºì‹œ ì •ë³´
            stats['cache_info'] = {
                'size': len(self.enhancement_cache),
                'max_size': self.post_processing_config.cache_size,
                'hit_ratio': stats['cache_hits'] / max(stats['total_processed'], 1)
            }
            
            # ì‹œìŠ¤í…œ ì •ë³´
            stats['system_info'] = {
                'device': self.device,
                'is_m3_max': self.is_m3_max,
                'memory_gb': self.memory_gb,
                'enabled_methods': [method.value for method in self.post_processing_config.enabled_methods],
                'models_loaded': {
                    'sr_model': self.sr_model is not None,
                    'denoise_model': self.denoise_model is not None,
                    'face_detector': self.face_detector is not None
                }
            }
            
            return stats
            
        except Exception as e:
            self.logger.error(f"í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {'error': str(e)}
    
    async def cleanup(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        try:
            self.logger.info("ğŸ§¹ 7ë‹¨ê³„ í›„ì²˜ë¦¬ ì‹œìŠ¤í…œ ì •ë¦¬ ì‹œì‘...")
            
            # ìºì‹œ ì •ë¦¬
            self.enhancement_cache.clear()
            self.model_cache.clear()
            
            # ëª¨ë¸ ë©”ëª¨ë¦¬ í•´ì œ
            if self.sr_model:
                if hasattr(self.sr_model, 'cpu'):
                    self.sr_model.cpu()
                del self.sr_model
                self.sr_model = None
            
            if self.denoise_model:
                if hasattr(self.denoise_model, 'cpu'):
                    self.denoise_model.cpu()
                del self.denoise_model
                self.denoise_model = None
            
            if self.face_detector:
                del self.face_detector
                self.face_detector = None
            
            # ìŠ¤ë ˆë“œ í’€ ì¢…ë£Œ
            if hasattr(self, 'executor'):
                self.executor.shutdown(wait=True)
            
            # ë©”ëª¨ë¦¬ ì •ë¦¬ (BaseStepMixin ì˜ì¡´ì„± ì£¼ì…ëœ ê²½ìš°)
            if self.memory_manager:
                try:
                    if hasattr(self.memory_manager, 'cleanup_memory_async'):
                        await self.memory_manager.cleanup_memory_async()
                    elif hasattr(self.memory_manager, 'cleanup_memory'):
                        await asyncio.get_event_loop().run_in_executor(
                            None, self.memory_manager.cleanup_memory
                        )
                except Exception:
                    pass
            
            # PyTorch ìºì‹œ ì •ë¦¬
            if self.device == 'mps' and TORCH_AVAILABLE:
                try:
                    safe_mps_empty_cache()
                except Exception:
                    pass
            elif self.device == 'cuda' and TORCH_AVAILABLE:
                try:
                    torch.cuda.empty_cache()
                except Exception:
                    pass
            
            # ê°€ë¹„ì§€ ì»¬ë ‰ì…˜
            gc.collect()
            
            self.is_initialized = False
            self.is_ready = False
            self.logger.info("âœ… 7ë‹¨ê³„ í›„ì²˜ë¦¬ ì‹œìŠ¤í…œ ì •ë¦¬ ì™„ë£Œ")
            
        except Exception as e:
            self.logger.error(f"ì •ë¦¬ ê³¼ì •ì—ì„œ ì˜¤ë¥˜ ë°œìƒ: {e}")
    
    def __del__(self):
        """ì†Œë©¸ì"""
        try:
            if hasattr(self, 'executor'):
                self.executor.shutdown(wait=False)
        except Exception:
            pass

# ==============================================
# ğŸ”¥ 16. íŒ©í† ë¦¬ í•¨ìˆ˜ë“¤ (TYPE_CHECKING íŒ¨í„´)
# ==============================================

def create_post_processing_step(
    device: Optional[str] = None,
    config: Optional[Dict[str, Any]] = None,
    **kwargs
) -> PostProcessingStep:
    """PostProcessingStep íŒ©í† ë¦¬ í•¨ìˆ˜"""
    try:
        return PostProcessingStep(device=device, config=config, **kwargs)
    except Exception as e:
        logger.error(f"PostProcessingStep ìƒì„± ì‹¤íŒ¨: {e}")
        raise

def create_m3_max_post_processing_step(**kwargs) -> PostProcessingStep:
    """M3 Max ìµœì í™”ëœ í›„ì²˜ë¦¬ ìŠ¤í… ìƒì„±"""
    m3_max_config = {
        'device': 'mps' if MPS_AVAILABLE else 'cpu',
        'is_m3_max': True,
        'memory_gb': 128,
        'quality_level': 'high',
        'processing_mode': 'quality',
        'enabled_methods': [
            'super_resolution',
            'noise_reduction',
            'sharpening',
            'color_correction',
            'contrast_enhancement',
            'face_enhancement'
        ],
        'enhancement_strength': 0.8,
        'preserve_faces': True,
        'cache_size': 100,
        'enable_visualization': True,
        'visualization_quality': 'high'
    }
    
    m3_max_config.update(kwargs)
    
    return PostProcessingStep(**m3_max_config)

def create_production_post_processing_step(
    quality_level: str = "balanced",
    processing_mode: str = "quality",
    **kwargs
) -> PostProcessingStep:
    """í”„ë¡œë•ì…˜ í™˜ê²½ìš© í›„ì²˜ë¦¬ ìŠ¤í… ìƒì„±"""
    production_config = {
        'quality_level': quality_level,
        'processing_mode': processing_mode,
        'enabled_methods': [
            'noise_reduction',
            'sharpening',
            'color_correction',
            'contrast_enhancement'
        ],
        'enhancement_strength': 0.6,
        'preserve_faces': True,
        'auto_adjust_brightness': True,
        'cache_size': 50,
        'enable_visualization': True,
        'visualization_quality': 'medium'
    }
    
    production_config.update(kwargs)
    
    return PostProcessingStep(**production_config)

def create_real_time_post_processing_step(**kwargs) -> PostProcessingStep:
    """ì‹¤ì‹œê°„ ì²˜ë¦¬ìš© í›„ì²˜ë¦¬ ìŠ¤í… ìƒì„±"""
    real_time_config = {
        'processing_mode': 'real_time',
        'quality_level': 'fast',
        'enabled_methods': [
            'sharpening',
            'color_correction'
        ],
        'enhancement_strength': 0.4,
        'preserve_faces': False,
        'cache_size': 25,
        'enable_visualization': False
    }
    
    real_time_config.update(kwargs)
    
    return PostProcessingStep(**real_time_config)

# ==============================================
# ğŸ”¥ 17. ë…ë¦½ ì‹¤í–‰í˜• ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
# ==============================================

def enhance_image_quality(
    image: np.ndarray,
    methods: List[str] = None,
    strength: float = 0.7,
    device: str = "auto"
) -> np.ndarray:
    """ë…ë¦½ ì‹¤í–‰í˜• ì´ë¯¸ì§€ í’ˆì§ˆ í–¥ìƒ í•¨ìˆ˜"""
    try:
        if not NUMPY_AVAILABLE:
            return image
            
        if methods is None:
            methods = ['sharpening', 'color_correction', 'contrast_enhancement']
        
        step = create_post_processing_step(
            device=device,
            enabled_methods=methods,
            enhancement_strength=strength
        )
        
        # ë™ê¸°ì  ì²˜ë¦¬ë¥¼ ìœ„í•œ ë˜í¼
        import asyncio
        
        async def process_async():
            await step.initialize()
            
            fitting_result = {'fitted_image': image}
            result = await step.process(fitting_result)
            
            await step.cleanup()
            
            if result['success'] and result.get('enhanced_image') is not None:
                return np.array(result['enhanced_image'])
            else:
                return image
        
        # ì´ë²¤íŠ¸ ë£¨í”„ ì‹¤í–‰
        try:
            loop = asyncio.get_event_loop()
            return loop.run_until_complete(process_async())
        except RuntimeError:
            # ìƒˆ ì´ë²¤íŠ¸ ë£¨í”„ ìƒì„±
            return asyncio.run(process_async())
            
    except Exception as e:
        logger.error(f"ì´ë¯¸ì§€ í’ˆì§ˆ í–¥ìƒ ì‹¤íŒ¨: {e}")
        return image

def batch_enhance_images(
    images: List[np.ndarray],
    methods: List[str] = None,
    strength: float = 0.7,
    device: str = "auto",
    max_workers: int = 4
) -> List[np.ndarray]:
    """ë°°ì¹˜ ì´ë¯¸ì§€ í’ˆì§ˆ í–¥ìƒ"""
    try:
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            futures = []
            
            for image in images:
                future = executor.submit(
                    enhance_image_quality,
                    image, methods, strength, device
                )
                futures.append(future)
            
            # ê²°ê³¼ ìˆ˜ì§‘
            enhanced_images = []
            for future in as_completed(futures):
                try:
                    enhanced_image = future.result()
                    enhanced_images.append(enhanced_image)
                except Exception as e:
                    logger.error(f"ë°°ì¹˜ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
                    enhanced_images.append(None)
            
            return enhanced_images
            
    except Exception as e:
        logger.error(f"ë°°ì¹˜ ì´ë¯¸ì§€ í–¥ìƒ ì‹¤íŒ¨: {e}")
        return images

# ==============================================
# ğŸ”¥ 18. í…ŒìŠ¤íŠ¸ í•¨ìˆ˜ë“¤ (TYPE_CHECKING íŒ¨í„´)
# ==============================================

async def test_type_checking_post_processing():
    """TYPE_CHECKING íŒ¨í„´ í›„ì²˜ë¦¬ í…ŒìŠ¤íŠ¸"""
    try:
        print("ğŸ”¥ TYPE_CHECKING íŒ¨í„´ PostProcessingStep í…ŒìŠ¤íŠ¸ ì‹œì‘...")
        
        # ê¸°ë³¸ Step ìƒì„±
        step = create_post_processing_step(device="cpu", strict_mode=False)
        print(f"âœ… PostProcessingStep ìƒì„± ì„±ê³µ: {step.step_name}")
        
        # ì˜ì¡´ì„± ì£¼ì… ì‹œë®¬ë ˆì´ì…˜
        mock_model_loader = type('MockModelLoader', (), {
            'get_model': lambda self, name: None,
            'create_step_interface': lambda self, name: self
        })()
        
        step.set_model_loader(mock_model_loader)
        print("âœ… ModelLoader ì˜ì¡´ì„± ì£¼ì… ì„±ê³µ")
        
        # ì´ˆê¸°í™”
        success = await step.initialize()
        print(f"âœ… ì´ˆê¸°í™” {'ì„±ê³µ' if success else 'ì‹¤íŒ¨'}")
        
        # ë”ë¯¸ ì´ë¯¸ì§€ë¡œ í…ŒìŠ¤íŠ¸
        if NUMPY_AVAILABLE:
            dummy_image = np.random.randint(0, 255, (256, 256, 3), dtype=np.uint8)
            fitting_result = {'fitted_image': dummy_image}
            
            result = await step.process(fitting_result)
            print(f"âœ… ì²˜ë¦¬ {'ì„±ê³µ' if result['success'] else 'ì‹¤íŒ¨'}")
            
            if result['success']:
                print(f"   - ì ìš©ëœ ë°©ë²•: {result.get('applied_methods', [])}")
                print(f"   - ì²˜ë¦¬ ì‹œê°„: {result.get('processing_time', 0):.3f}ì´ˆ")
        
        # ì •ë¦¬
        await step.cleanup()
        print("âœ… TYPE_CHECKING íŒ¨í„´ PostProcessingStep í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
        
    except Exception as e:
        print(f"âŒ TYPE_CHECKING íŒ¨í„´ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()

def test_enhancement_methods_type_checking():
    """í–¥ìƒ ë°©ë²• í…ŒìŠ¤íŠ¸ (TYPE_CHECKING íŒ¨í„´)"""
    try:
        print("ğŸ¨ í–¥ìƒ ë°©ë²• TYPE_CHECKING íŒ¨í„´ í…ŒìŠ¤íŠ¸...")
        
        # ëª¨ë“  í–¥ìƒ ë°©ë²• í…ŒìŠ¤íŠ¸
        methods = [method.value for method in EnhancementMethod]
        print(f"âœ… ì§€ì›ë˜ëŠ” í–¥ìƒ ë°©ë²•: {methods}")
        
        # í’ˆì§ˆ ë ˆë²¨ í…ŒìŠ¤íŠ¸
        quality_levels = [level.value for level in QualityLevel]
        print(f"âœ… ì§€ì›ë˜ëŠ” í’ˆì§ˆ ë ˆë²¨: {quality_levels}")
        
        # ì²˜ë¦¬ ëª¨ë“œ í…ŒìŠ¤íŠ¸
        processing_modes = [mode.value for mode in ProcessingMode]
        print(f"âœ… ì§€ì›ë˜ëŠ” ì²˜ë¦¬ ëª¨ë“œ: {processing_modes}")
        
        print("âœ… í–¥ìƒ ë°©ë²• TYPE_CHECKING íŒ¨í„´ í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
        
    except Exception as e:
        print(f"âŒ í–¥ìƒ ë°©ë²• í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")

# ==============================================
# ğŸ”¥ 19. ëª¨ë“ˆ ë‚´ë³´ë‚´ê¸° (TYPE_CHECKING íŒ¨í„´)
# ==============================================

__all__ = [
    # ë©”ì¸ í´ë˜ìŠ¤
    'PostProcessingStep',
    
    # ì—´ê±°í˜• ë° ë°ì´í„° í´ë˜ìŠ¤
    'EnhancementMethod',
    'QualityLevel',
    'ProcessingMode',
    'PostProcessingConfig',
    'PostProcessingResult',
    
    # AI ëª¨ë¸ í´ë˜ìŠ¤ë“¤
    'SRResNet',
    'DenoiseNet',
    
    # íŒ©í† ë¦¬ í•¨ìˆ˜ë“¤
    'create_post_processing_step',
    'create_m3_max_post_processing_step',
    'create_production_post_processing_step',
    'create_real_time_post_processing_step',
    
    # ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
    'enhance_image_quality',
    'batch_enhance_images',
    
    # ë™ì  import í•¨ìˆ˜ë“¤ (TYPE_CHECKING)
    'dynamic_import_base_step_mixin',
    'dynamic_import_model_loader',
    'dynamic_import_pytorch_safe_ops',
    
    # í…ŒìŠ¤íŠ¸ í•¨ìˆ˜ë“¤ (TYPE_CHECKING)
    'test_type_checking_post_processing',
    'test_enhancement_methods_type_checking',
    
    # ê°€ìš©ì„± í”Œë˜ê·¸ë“¤
    'TORCH_AVAILABLE',
    'MPS_AVAILABLE',
    'NUMPY_AVAILABLE',
    'PIL_AVAILABLE',
    'OPENCV_AVAILABLE',
    'SCIPY_AVAILABLE',
    'SKIMAGE_AVAILABLE',
    
    # ì‹œìŠ¤í…œ ì •ë³´
    'IS_M3_MAX',
    'CONDA_INFO',
    'detect_m3_max'
]

# ==============================================
# ğŸ”¥ 20. ëª¨ë“ˆ ì´ˆê¸°í™” ë° ì •ë¦¬ (TYPE_CHECKING íŒ¨í„´)
# ==============================================

# ìë™ ì •ë¦¬ ë“±ë¡
import atexit

def _cleanup_on_exit():
    """í”„ë¡œê·¸ë¨ ì¢…ë£Œ ì‹œ ì •ë¦¬"""
    try:
        # ì „ì—­ ì¸ìŠ¤í„´ìŠ¤ë“¤ ì •ë¦¬
        if TORCH_AVAILABLE:
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
            elif MPS_AVAILABLE:
                try:
                    safe_mps_empty_cache()
                except Exception:
                    pass
        gc.collect()
    except Exception:
        pass

atexit.register(_cleanup_on_exit)

# ëª¨ë“ˆ ì´ˆê¸°í™” ë¡œê¹…
logger.info("=" * 80)
logger.info("âœ… Step 07 í›„ì²˜ë¦¬ ëª¨ë“ˆ ë¡œë“œ ì™„ë£Œ - TYPE_CHECKING íŒ¨í„´ + ì™„ì „í•œ DI v3.0")
logger.info("=" * 80)
logger.info("ğŸ”¥ í•µì‹¬ íŠ¹ì§•:")
logger.info("   âœ… TYPE_CHECKING íŒ¨í„´ìœ¼ë¡œ ìˆœí™˜ì°¸ì¡° ì™„ì „ ë°©ì§€")
logger.info("   âœ… ë™ì  import í•¨ìˆ˜ë¡œ ëŸ°íƒ€ì„ ì˜ì¡´ì„± í•´ê²°")
logger.info("   âœ… StepFactory â†’ ModelLoader â†’ BaseStepMixin â†’ ì˜ì¡´ì„± ì£¼ì… â†’ ì™„ì„±ëœ Step")
logger.info("   âœ… ì²´í¬í¬ì¸íŠ¸ â†’ ì‹¤ì œ AI ëª¨ë¸ í´ë˜ìŠ¤ ë³€í™˜ ì™„ì „ êµ¬í˜„")
logger.info("   âœ… ì‹¤ì œ AI ëª¨ë¸ ì¶”ë¡  ì™„ì „ êµ¬í˜„ (SRResNet, DenoiseNet)")
logger.info("   âœ… BaseStepMixin í˜¸í™˜ ì˜ì¡´ì„± ì£¼ì… ì¸í„°í˜ì´ìŠ¤")
logger.info("   âœ… M3 Max 128GB ë©”ëª¨ë¦¬ ìµœì í™”")
logger.info("   âœ… conda í™˜ê²½ ìš°ì„  ì§€ì›")
logger.info("   âœ… ë¹„ë™ê¸° ì²˜ë¦¬ ì™„ì „ í•´ê²°")
logger.info("   âœ… ì‹œê°í™” ê¸°ëŠ¥ í†µí•©")
logger.info("   âœ… í”„ë¡œë•ì…˜ ë ˆë²¨ ì•ˆì •ì„±")
logger.info("")
logger.info("ğŸ§  AI ëª¨ë¸ ì—°ë™:")
logger.info("   ğŸ”¥ Super Resolution (SRResNet) - ì‹¤ì œ AI ì¶”ë¡  êµ¬í˜„")
logger.info("   ğŸ”¥ Denoising (DenoiseNet) - ì‹¤ì œ AI ì¶”ë¡  êµ¬í˜„")
logger.info("   ğŸ‘ï¸ Face Detection (OpenCV DNN/Haar) - ì–¼êµ´ ê²€ì¶œ")
logger.info("   ğŸ¨ Traditional Image Processing - ì „í†µì  ì´ë¯¸ì§€ ì²˜ë¦¬")
logger.info("")
logger.info("ğŸ’‰ ì˜ì¡´ì„± ì£¼ì… ì¸í„°í˜ì´ìŠ¤:")
logger.info("   âœ… set_model_loader() - ModelLoader ì£¼ì…")
logger.info("   âœ… set_memory_manager() - MemoryManager ì£¼ì…")
logger.info("   âœ… set_data_converter() - DataConverter ì£¼ì…")
logger.info("   âœ… set_di_container() - DI Container ì£¼ì…")
logger.info("   âœ… set_step_factory() - StepFactory ì£¼ì…")
logger.info("   âœ… set_step_interface() - Step ì¸í„°í˜ì´ìŠ¤ ì£¼ì…")
logger.info("")
logger.info("ğŸ”§ ë¼ì´ë¸ŒëŸ¬ë¦¬ ìƒíƒœ:")
logger.info(f"   - PyTorch: {'âœ…' if TORCH_AVAILABLE else 'âŒ'}")
logger.info(f"   - MPS (M3 Max): {'âœ…' if MPS_AVAILABLE else 'âŒ'}")
logger.info(f"   - NumPy: {'âœ…' if NUMPY_AVAILABLE else 'âŒ'}")
logger.info(f"   - PIL: {'âœ…' if PIL_AVAILABLE else 'âŒ'}")
logger.info(f"   - OpenCV: {'âœ…' if OPENCV_AVAILABLE else 'âŒ'}")
logger.info(f"   - SciPy: {'âœ…' if SCIPY_AVAILABLE else 'âŒ'}")
logger.info(f"   - Scikit-Image: {'âœ…' if SKIMAGE_AVAILABLE else 'âŒ'}")
logger.info("")
logger.info(f"ğŸ ì‹œìŠ¤í…œ ìƒíƒœ:")
logger.info(f"   - conda í™˜ê²½: {CONDA_INFO['conda_env']}")
logger.info(f"   - M3 Max ê°ì§€: {'âœ…' if IS_M3_MAX else 'âŒ'}")
logger.info("")
logger.info("ğŸŒŸ ì‚¬ìš© ì˜ˆì‹œ:")
logger.info("   # ê¸°ë³¸ ì‚¬ìš© (TYPE_CHECKING íŒ¨í„´)")
logger.info("   step = create_post_processing_step()")
logger.info("   result = await step.process(fitting_result)")
logger.info("   ")
logger.info("   # M3 Max ìµœì í™”")
logger.info("   step = create_m3_max_post_processing_step()")
logger.info("   ")
logger.info("   # ì˜ì¡´ì„± ì£¼ì… (StepFactoryì—ì„œ ìë™)")
logger.info("   step.set_model_loader(model_loader)")
logger.info("   step.set_memory_manager(memory_manager)")
logger.info("   step.set_data_converter(data_converter)")
logger.info("   await step.initialize()")
logger.info("")
logger.info("=" * 80)
logger.info("ğŸš€ PostProcessingStep v3.0 ì¤€ë¹„ ì™„ë£Œ!")
logger.info("   âœ… TYPE_CHECKING íŒ¨í„´ìœ¼ë¡œ ìˆœí™˜ì°¸ì¡° ì™„ì „ ë°©ì§€")
logger.info("   âœ… ë™ì  importë¡œ ëŸ°íƒ€ì„ ì˜ì¡´ì„± ì•ˆì „ í•´ê²°")
logger.info("   âœ… ì™„ì „í•œ ì˜ì¡´ì„± ì£¼ì… íŒ¨í„´ êµ¬í˜„")
logger.info("   âœ… ì‹¤ì œ AI ëª¨ë¸ ì¶”ë¡  êµ¬í˜„")
logger.info("   âœ… BaseStepMixin í˜¸í™˜ì„± ì™„ì „ ë³´ì¥")
logger.info("   âœ… M3 Max 128GB ìµœì í™”")
logger.info("   âœ… í”„ë¡œë•ì…˜ ë ˆë²¨ ì•ˆì •ì„±")
logger.info("=" * 80)

# ==============================================
# ğŸ”¥ 21. ë©”ì¸ ì‹¤í–‰ë¶€ (TYPE_CHECKING íŒ¨í„´ ê²€ì¦)
# ==============================================

if __name__ == "__main__":
    print("=" * 80)
    print("ğŸ¯ MyCloset AI Step 07 - TYPE_CHECKING íŒ¨í„´ + ì™„ì „í•œ DI íŒ¨í„´")
    print("=" * 80)
    
    # ë¹„ë™ê¸° í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    async def run_all_tests():
        await test_type_checking_post_processing()
        print("\n" + "=" * 80)
        test_enhancement_methods_type_checking()
    
    try:
        asyncio.run(run_all_tests())
    except Exception as e:
        print(f"âŒ TYPE_CHECKING íŒ¨í„´ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
    
    print("\n" + "=" * 80)
    print("âœ¨ TYPE_CHECKING íŒ¨í„´ + ì™„ì „í•œ DI íŒ¨í„´ í›„ì²˜ë¦¬ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
    print("ğŸ”¥ TYPE_CHECKING íŒ¨í„´ìœ¼ë¡œ ìˆœí™˜ì°¸ì¡° ì™„ì „ ë°©ì§€")
    print("ğŸ§  ë™ì  importë¡œ ëŸ°íƒ€ì„ ì˜ì¡´ì„± ì•ˆì „ í•´ê²°")
    print("ğŸ”— StepFactory â†’ ModelLoader â†’ BaseStepMixin â†’ ì˜ì¡´ì„± ì£¼ì… â†’ ì™„ì„±ëœ Step êµ¬ì¡°")
    print("âš¡ SRResNet, DenoiseNet ì‹¤ì œ AI ì¶”ë¡  ì—”ì§„")
    print("ğŸ’‰ ì™„ë²½í•œ ì˜ì¡´ì„± ì£¼ì… íŒ¨í„´")
    print("ğŸ”’ BaseStepMixin í˜¸í™˜ì„± ì™„ì „ ë³´ì¥")
    print("ğŸ¨ ì‹œê°í™” ê¸°ëŠ¥ + í’ˆì§ˆ í‰ê°€ í†µí•©")
    print("=" * 80)

# ==============================================
# ğŸ”¥ END OF FILE - TYPE_CHECKING íŒ¨í„´ ì™„ë£Œ
# ==============================================

"""
âœ¨ TYPE_CHECKING íŒ¨í„´ + ì™„ì „í•œ DI íŒ¨í„´ ìš”ì•½:

ğŸ“‹ 21ê°œ ì„¹ì…˜ìœ¼ë¡œ ì²´ê³„ì  êµ¬ì„±:
   1-4:   Import, í™˜ê²½ ì²´í¬, ë™ì  import (TYPE_CHECKING)
   5-6:   ë°ì´í„° êµ¬ì¡° ë° AI ëª¨ë¸ ì •ì˜
   7-9:   ë©”ì¸ PostProcessingStep í´ë˜ìŠ¤ (ì™„ì „í•œ DI)
   10:    ë©”ì¸ ì²˜ë¦¬ ì¸í„°í˜ì´ìŠ¤
   11-12: AI ëª¨ë¸ ì¶”ë¡  ë° ì „í†µì  ì´ë¯¸ì§€ ì²˜ë¦¬
   13:    ì‹œê°í™” ê´€ë ¨ ë©”ì„œë“œ
   14-15: ìœ í‹¸ë¦¬í‹° ë° BaseStepMixin í˜¸í™˜
   16-17: íŒ©í† ë¦¬ í•¨ìˆ˜ ë° ìœ í‹¸ë¦¬í‹°
   18-21: í…ŒìŠ¤íŠ¸, ë‚´ë³´ë‚´ê¸°, ì´ˆê¸°í™”, ê²€ì¦

ğŸ”§ ì£¼ìš” ê°œì„ ì‚¬í•­:
   âœ… TYPE_CHECKING íŒ¨í„´ìœ¼ë¡œ ìˆœí™˜ì°¸ì¡° ì™„ì „ ë°©ì§€
   âœ… ë™ì  import í•¨ìˆ˜ë¡œ ëŸ°íƒ€ì„ ì˜ì¡´ì„± ì•ˆì „ í•´ê²°
   âœ… BaseStepMixin í˜¸í™˜ ì˜ì¡´ì„± ì£¼ì… ì¸í„°í˜ì´ìŠ¤ ì™„ì „ êµ¬í˜„
   âœ… ì²´í¬í¬ì¸íŠ¸ â†’ AI ëª¨ë¸ í´ë˜ìŠ¤ ë³€í™˜ ì™„ì „ í•´ê²°
   âœ… ì‹¤ì œ AI ëª¨ë¸ ì¶”ë¡  êµ¬í˜„ (SRResNet, DenoiseNet)
   âœ… ì´ˆê¸°í™” ë¡œì§ ê°„ì†Œí™” ë° ì¼ê´€ì„± í™•ë³´
   âœ… ëª¨ë“  ê¸°ì¡´ ê¸°ëŠ¥ 100% í˜¸í™˜ ìœ ì§€

ğŸš€ ê²°ê³¼:
   - TYPE_CHECKING íŒ¨í„´ìœ¼ë¡œ ìˆœí™˜ì°¸ì¡° ì›ì²œ ì°¨ë‹¨
   - StepFactory â†’ ModelLoader â†’ BaseStepMixin â†’ ì˜ì¡´ì„± ì£¼ì… ì™„ì „ êµ¬í˜„
   - ì‹¤ì œ AI ëª¨ë¸ ì¶”ë¡  ì—”ì§„ ë‚´ì¥
   - BaseStepMixin í˜¸í™˜ì„± ì™„ì „ ë³´ì¥
   - M3 Max 128GB ë©”ëª¨ë¦¬ ìµœì í™”
   - í”„ë¡œë•ì…˜ ë ˆë²¨ ì•ˆì •ì„±

ğŸ’¡ ì‚¬ìš©ë²•:
   from steps.step_07_post_processing import PostProcessingStep
   step = PostProcessingStep(device="auto", strict_mode=True)
   step.set_model_loader(model_loader)  # DI
   await step.initialize()
   result = await step.process(fitting_result)
   
ğŸ¯ MyCloset AI - Step 07 Post Processing v3.0
   TYPE_CHECKING íŒ¨í„´ + ì™„ì „í•œ ì˜ì¡´ì„± ì£¼ì… íŒ¨í„´ ì ìš© ì™„ë£Œ!
"""