#!/usr/bin/env python3
"""
ğŸ”¥ MyCloset AI - Virtual Fitting Quality Service
===============================================

ğŸ¯ ê°€ìƒ í”¼íŒ… í’ˆì§ˆ ê´€ë¦¬ ì„œë¹„ìŠ¤
âœ… í’ˆì§ˆ í–¥ìƒ ì„œë¹„ìŠ¤
âœ… í’ˆì§ˆ ê²€ì¦ ì„œë¹„ìŠ¤
âœ… í’ˆì§ˆ ëª¨ë‹ˆí„°ë§ ì„œë¹„ìŠ¤
âœ… M3 Max ìµœì í™”
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import logging
from typing import Dict, List, Tuple, Optional, Union, Any
from dataclasses import dataclass
import cv2
from PIL import Image
import time
import psutil
import gc

logger = logging.getLogger(__name__)

@dataclass
class QualityServiceConfig:
    """í’ˆì§ˆ ì„œë¹„ìŠ¤ ì„¤ì •"""
    enable_quality_enhancement: bool = True
    enable_quality_validation: bool = True
    enable_quality_monitoring: bool = True
    quality_threshold: float = 0.7
    monitoring_interval: float = 1.0
    use_mps: bool = True

class VirtualFittingQualityService:
    """ê°€ìƒ í”¼íŒ… í’ˆì§ˆ ê´€ë¦¬ ì„œë¹„ìŠ¤"""
    
    def __init__(self, config: QualityServiceConfig = None):
        self.config = config or QualityServiceConfig()
        self.logger = logging.getLogger(__name__)
        
        # MPS ë””ë°”ì´ìŠ¤ í™•ì¸
        self.device = torch.device("mps" if torch.backends.mps.is_available() and self.config.use_mps else "cpu")
        self.logger.info(f"ğŸ¯ Virtual Fitting í’ˆì§ˆ ê´€ë¦¬ ì„œë¹„ìŠ¤ ì´ˆê¸°í™” (ë””ë°”ì´ìŠ¤: {self.device})")
        
        # í’ˆì§ˆ í–¥ìƒê¸°
        if self.config.enable_quality_enhancement:
            try:
                import sys
                import os
                sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'processors'))
                from virtual_fitting_quality_enhancer import VirtualFittingQualityEnhancer
                from virtual_fitting_validator import VirtualFittingValidator
                
                self.quality_enhancer = VirtualFittingQualityEnhancer()
                self.validator = VirtualFittingValidator()
                self.logger.info("í’ˆì§ˆ í–¥ìƒê¸° ë° ê²€ì¦ê¸° ë¡œë“œ ì™„ë£Œ")
            except ImportError as e:
                self.logger.error(f"í’ˆì§ˆ í–¥ìƒê¸° ë¡œë“œ ì‹¤íŒ¨: {e}")
                self.quality_enhancer = None
                self.validator = None
        
        # í’ˆì§ˆ ëª¨ë‹ˆí„°ë§
        self.quality_history = []
        self.last_monitoring_time = time.time()
        
        self.logger.info("âœ… Virtual Fitting í’ˆì§ˆ ê´€ë¦¬ ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ")
    
    def enhance_quality(self, virtual_fitting_image: torch.Tensor) -> Dict[str, Any]:
        """
        ê°€ìƒ í”¼íŒ… ì´ë¯¸ì§€ì˜ í’ˆì§ˆì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤.
        
        Args:
            virtual_fitting_image: ê°€ìƒ í”¼íŒ… ì´ë¯¸ì§€ (B, C, H, W)
            
        Returns:
            í’ˆì§ˆ í–¥ìƒ ê²°ê³¼
        """
        if not self.config.enable_quality_enhancement or self.quality_enhancer is None:
            return {
                'status': 'disabled',
                'enhanced_image': virtual_fitting_image,
                'message': 'í’ˆì§ˆ í–¥ìƒì´ ë¹„í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤.'
            }
        
        try:
            start_time = time.time()
            
            # í’ˆì§ˆ í–¥ìƒ ìˆ˜í–‰
            enhanced_result = self.quality_enhancer(virtual_fitting_image)
            
            processing_time = time.time() - start_time
            
            result = {
                'status': 'success',
                'enhanced_image': enhanced_result['enhanced_image'],
                'processing_time': processing_time,
                'enhancement_strength': enhanced_result['enhancement_strength'],
                'input_size': enhanced_result['input_size']
            }
            
            self.logger.info(f"í’ˆì§ˆ í–¥ìƒ ì™„ë£Œ (ì²˜ë¦¬ ì‹œê°„: {processing_time:.4f}ì´ˆ)")
            return result
            
        except Exception as e:
            self.logger.error(f"í’ˆì§ˆ í–¥ìƒ ì‹¤íŒ¨: {e}")
            return {
                'status': 'error',
                'enhanced_image': virtual_fitting_image,
                'error': str(e),
                'message': 'í’ˆì§ˆ í–¥ìƒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.'
            }
    
    def validate_quality(self, virtual_fitting_image: torch.Tensor,
                        original_image: Optional[torch.Tensor] = None,
                        target_image: Optional[torch.Tensor] = None) -> Dict[str, Any]:
        """
        ê°€ìƒ í”¼íŒ… ì´ë¯¸ì§€ì˜ í’ˆì§ˆì„ ê²€ì¦í•©ë‹ˆë‹¤.
        
        Args:
            virtual_fitting_image: ê°€ìƒ í”¼íŒ… ì´ë¯¸ì§€ (B, C, H, W)
            original_image: ì›ë³¸ ì´ë¯¸ì§€ (B, C, H, W)
            target_image: ëª©í‘œ ì´ë¯¸ì§€ (B, C, H, W)
            
        Returns:
            í’ˆì§ˆ ê²€ì¦ ê²°ê³¼
        """
        if not self.config.enable_quality_validation or self.validator is None:
            return {
                'status': 'disabled',
                'message': 'í’ˆì§ˆ ê²€ì¦ì´ ë¹„í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤.'
            }
        
        try:
            start_time = time.time()
            
            # í’ˆì§ˆ ê²€ì¦ ìˆ˜í–‰
            validation_result = self.validator(virtual_fitting_image, original_image, target_image)
            
            # í’ˆì§ˆ ë©”íŠ¸ë¦­ ê³„ì‚°
            if original_image is not None:
                quality_metrics = self.validator.calculate_quality_metrics(original_image, virtual_fitting_image)
            else:
                quality_metrics = {'status': 'no_original_image'}
            
            processing_time = time.time() - start_time
            
            result = {
                'status': 'success',
                'validation_result': validation_result,
                'quality_metrics': quality_metrics,
                'processing_time': processing_time,
                'quality_passed': validation_result['validation_results'].get('quality_passed', False)
            }
            
            # í’ˆì§ˆ íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
            self.quality_history.append({
                'timestamp': time.time(),
                'quality_score': validation_result['validation_results'].get('overall_score', 0.0),
                'quality_passed': result['quality_passed']
            })
            
            self.logger.info(f"í’ˆì§ˆ ê²€ì¦ ì™„ë£Œ (ì²˜ë¦¬ ì‹œê°„: {processing_time:.4f}ì´ˆ, í†µê³¼: {result['quality_passed']})")
            return result
            
        except Exception as e:
            self.logger.error(f"í’ˆì§ˆ ê²€ì¦ ì‹¤íŒ¨: {e}")
            return {
                'status': 'error',
                'error': str(e),
                'message': 'í’ˆì§ˆ ê²€ì¦ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.'
            }
    
    def monitor_quality(self) -> Dict[str, Any]:
        """í’ˆì§ˆ ëª¨ë‹ˆí„°ë§ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤."""
        if not self.config.enable_quality_monitoring:
            return {
                'status': 'disabled',
                'message': 'í’ˆì§ˆ ëª¨ë‹ˆí„°ë§ì´ ë¹„í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤.'
            }
        
        current_time = time.time()
        
        # ëª¨ë‹ˆí„°ë§ ê°„ê²© í™•ì¸
        if current_time - self.last_monitoring_time < self.config.monitoring_interval:
            return {
                'status': 'skipped',
                'message': f'ëª¨ë‹ˆí„°ë§ ê°„ê²©ì´ ì¶©ì¡±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. (í•„ìš”: {self.config.monitoring_interval}ì´ˆ)'
            }
        
        try:
            # ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ ëª¨ë‹ˆí„°ë§
            cpu_percent = psutil.cpu_percent(interval=0.1)
            memory = psutil.virtual_memory()
            
            # PyTorch ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§
            if torch.cuda.is_available():
                torch_memory = torch.cuda.memory_stats()
                gpu_memory_allocated = torch.cuda.memory_allocated() / 1024**3  # GB
                gpu_memory_reserved = torch.cuda.memory_reserved() / 1024**3  # GB
            else:
                torch_memory = {}
                gpu_memory_allocated = 0.0
                gpu_memory_reserved = 0.0
            
            # í’ˆì§ˆ í†µê³„ ê³„ì‚°
            if self.quality_history:
                recent_quality = self.quality_history[-10:]  # ìµœê·¼ 10ê°œ
                avg_quality = sum(item['quality_score'] for item in recent_quality) / len(recent_quality)
                pass_rate = sum(1 for item in recent_quality if item['quality_passed']) / len(recent_quality)
            else:
                avg_quality = 0.0
                pass_rate = 0.0
            
            monitoring_result = {
                'status': 'success',
                'timestamp': current_time,
                'system_metrics': {
                    'cpu_percent': cpu_percent,
                    'memory_percent': memory.percent,
                    'memory_available_gb': memory.available / 1024**3
                },
                'torch_memory': {
                    'gpu_memory_allocated_gb': gpu_memory_allocated,
                    'gpu_memory_reserved_gb': gpu_memory_reserved
                },
                'quality_metrics': {
                    'average_quality': avg_quality,
                    'pass_rate': pass_rate,
                    'total_validations': len(self.quality_history)
                }
            }
            
            self.last_monitoring_time = current_time
            self.logger.info(f"í’ˆì§ˆ ëª¨ë‹ˆí„°ë§ ì™„ë£Œ (CPU: {cpu_percent:.1f}%, ë©”ëª¨ë¦¬: {memory.percent:.1f}%)")
            
            return monitoring_result
            
        except Exception as e:
            self.logger.error(f"í’ˆì§ˆ ëª¨ë‹ˆí„°ë§ ì‹¤íŒ¨: {e}")
            return {
                'status': 'error',
                'error': str(e),
                'message': 'í’ˆì§ˆ ëª¨ë‹ˆí„°ë§ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.'
            }
    
    def get_quality_report(self) -> Dict[str, Any]:
        """í’ˆì§ˆ ë³´ê³ ì„œë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
        try:
            # ìµœê·¼ í’ˆì§ˆ í†µê³„
            if self.quality_history:
                recent_quality = self.quality_history[-50:]  # ìµœê·¼ 50ê°œ
                avg_quality = sum(item['quality_score'] for item in recent_quality) / len(recent_quality)
                pass_rate = sum(1 for item in recent_quality if item['quality_passed']) / len(recent_quality)
                
                # í’ˆì§ˆ íŠ¸ë Œë“œ ë¶„ì„
                if len(recent_quality) >= 2:
                    first_half = recent_quality[:len(recent_quality)//2]
                    second_half = recent_quality[len(recent_quality)//2:]
                    
                    first_avg = sum(item['quality_score'] for item in first_half) / len(first_half)
                    second_avg = sum(item['quality_score'] for item in second_half) / len(second_half)
                    
                    trend = "í–¥ìƒ" if second_avg > first_avg else "í•˜ë½" if second_avg < first_avg else "ìœ ì§€"
                else:
                    trend = "ë¶„ì„ ë¶ˆê°€"
            else:
                avg_quality = 0.0
                pass_rate = 0.0
                trend = "ë°ì´í„° ì—†ìŒ"
            
            report = {
                'status': 'success',
                'timestamp': time.time(),
                'quality_summary': {
                    'average_quality': avg_quality,
                    'pass_rate': pass_rate,
                    'trend': trend,
                    'total_validations': len(self.quality_history)
                },
                'service_status': {
                    'quality_enhancement_enabled': self.config.enable_quality_enhancement,
                    'quality_validation_enabled': self.config.enable_quality_validation,
                    'quality_monitoring_enabled': self.config.enable_quality_monitoring
                },
                'device_info': str(self.device)
            }
            
            return report
            
        except Exception as e:
            self.logger.error(f"í’ˆì§ˆ ë³´ê³ ì„œ ìƒì„± ì‹¤íŒ¨: {e}")
            return {
                'status': 'error',
                'error': str(e),
                'message': 'í’ˆì§ˆ ë³´ê³ ì„œ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.'
            }
    
    def cleanup(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤."""
        try:
            # í’ˆì§ˆ íˆìŠ¤í† ë¦¬ ì •ë¦¬ (ìµœê·¼ 1000ê°œë§Œ ìœ ì§€)
            if len(self.quality_history) > 1000:
                self.quality_history = self.quality_history[-1000:]
            
            # ê°€ë¹„ì§€ ì»¬ë ‰ì…˜
            gc.collect()
            
            self.logger.info("í’ˆì§ˆ ê´€ë¦¬ ì„œë¹„ìŠ¤ ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì™„ë£Œ")
            
        except Exception as e:
            self.logger.error(f"ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì‹¤íŒ¨: {e}")

# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    # ì„¤ì •
    config = QualityServiceConfig(
        enable_quality_enhancement=True,
        enable_quality_validation=True,
        enable_quality_monitoring=True,
        quality_threshold=0.7,
        monitoring_interval=1.0,
        use_mps=True
    )
    
    # í’ˆì§ˆ ê´€ë¦¬ ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
    quality_service = VirtualFittingQualityService(config)
    
    # í…ŒìŠ¤íŠ¸ ì…ë ¥
    batch_size = 2
    channels = 3
    height = 256
    width = 256
    
    test_virtual_fitting = torch.randn(batch_size, channels, height, width)
    test_original = torch.randn(batch_size, channels, height, width)
    
    # í’ˆì§ˆ í–¥ìƒ
    enhancement_result = quality_service.enhance_quality(test_virtual_fitting)
    print(f"í’ˆì§ˆ í–¥ìƒ ê²°ê³¼: {enhancement_result['status']}")
    
    # í’ˆì§ˆ ê²€ì¦
    validation_result = quality_service.validate_quality(test_virtual_fitting, test_original)
    print(f"í’ˆì§ˆ ê²€ì¦ ê²°ê³¼: {validation_result['status']}")
    
    # í’ˆì§ˆ ëª¨ë‹ˆí„°ë§
    monitoring_result = quality_service.monitor_quality()
    print(f"í’ˆì§ˆ ëª¨ë‹ˆí„°ë§ ê²°ê³¼: {monitoring_result['status']}")
    
    # í’ˆì§ˆ ë³´ê³ ì„œ
    report = quality_service.get_quality_report()
    print(f"í’ˆì§ˆ ë³´ê³ ì„œ: {report['status']}")
    
    # ë¦¬ì†ŒìŠ¤ ì •ë¦¬
    quality_service.cleanup()
