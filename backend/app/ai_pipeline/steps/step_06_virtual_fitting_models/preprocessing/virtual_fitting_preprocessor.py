"""
ğŸ”¥ Virtual Fitting ì „ìš© ì „ì²˜ë¦¬ ì‹œìŠ¤í…œ
======================================

ê°€ìƒ í”¼íŒ…ì— ìµœì í™”ëœ ì „ì²˜ë¦¬ ê¸°ëŠ¥ë“¤:
1. ì¸ì²´-ì˜ë¥˜ ì •í•© ë° ì •ë ¬
2. í”¼íŒ… í’ˆì§ˆ ìµœì í™”
3. ìì—°ìŠ¤ëŸ¬ìš´ ë³€í˜• ì²˜ë¦¬
4. ì¡°ëª… ë° ê·¸ë¦¼ì ì¡°ì •
5. ìµœì¢… í”¼íŒ… í’ˆì§ˆ í–¥ìƒ

Author: MyCloset AI Team
Date: 2025-01-27
Version: 1.0 (ì™„ì „ êµ¬í˜„)
"""

import cv2
import numpy as np
import torch
import torch.nn.functional as F
from typing import Dict, Any, Optional, Tuple, List
import logging
from PIL import Image
import matplotlib.pyplot as plt
import matplotlib.patches as patches

logger = logging.getLogger(__name__)

class VirtualFittingPreprocessor:
    """ê°€ìƒ í”¼íŒ…ì— ìµœì í™”ëœ ì „ì²˜ë¦¬ ì‹œìŠ¤í…œ"""
    
    def __init__(self, target_size: Tuple[int, int] = (512, 512)):
        self.target_size = target_size
        self.logger = logging.getLogger(f"{__name__}.VirtualFittingPreprocessor")
        
        # ê°€ìƒ í”¼íŒ…ìš© ì „ì²˜ë¦¬ íŒŒë¼ë¯¸í„°
        self.fitting_params = {
            'body_clothing_alignment': True,
            'fitting_quality_optimization': True,
            'natural_deformation': True,
            'lighting_shadow_adjustment': True,
            'final_quality_enhancement': True
        }
        
        # ì²˜ë¦¬ í†µê³„
        self.processing_stats = {
            'images_processed': 0,
            'alignments_applied': 0,
            'deformations_processed': 0,
            'lighting_adjusted': 0
        }
    
    def preprocess_image(self, image: np.ndarray, mode: str = 'advanced') -> Dict[str, Any]:
        """ê°€ìƒ í”¼íŒ…ì„ ìœ„í•œ ì™„ì „í•œ ì „ì²˜ë¦¬"""
        try:
            self.processing_stats['images_processed'] += 1
            self.logger.info(f"ğŸ”¥ ê°€ìƒ í”¼íŒ… ì „ì²˜ë¦¬ ì‹œì‘ (ëª¨ë“œ: {mode})")
            
            # 1. ì´ë¯¸ì§€ ê²€ì¦
            validated_image = self._validate_image(image)
            
            # 2. ì¸ì²´-ì˜ë¥˜ ì •í•©
            aligned_image, alignment_info = self._align_body_clothing(validated_image)
            if alignment_info['alignment_applied']:
                self.processing_stats['alignments_applied'] += 1
            
            # 3. í•´ìƒë„ í‘œì¤€í™”
            resized_image = self._standardize_resolution(aligned_image)
            
            # 4. ê°€ìƒ í”¼íŒ… ìµœì í™”
            if mode == 'advanced':
                optimized_image = self._optimize_for_virtual_fitting(resized_image)
                self.processing_stats['deformations_processed'] += 1
                self.processing_stats['lighting_adjusted'] += 1
            else:
                optimized_image = resized_image
            
            # 5. ì •ê·œí™” ë° í…ì„œ ë³€í™˜
            normalized_tensor = self._normalize_and_convert(optimized_image)
            
            # 6. ì „ì²˜ë¦¬ ê²°ê³¼ ìš”ì•½
            preprocessing_result = {
                'processed_image': optimized_image,
                'tensor': normalized_tensor,
                'alignment_info': alignment_info,
                'target_size': self.target_size,
                'mode': mode,
                'fitting_params': self.fitting_params,
                'success': True
            }
            
            self.logger.info("âœ… ê°€ìƒ í”¼íŒ… ì „ì²˜ë¦¬ ì™„ë£Œ")
            return preprocessing_result
            
        except Exception as e:
            self.logger.error(f"âŒ ê°€ìƒ í”¼íŒ… ì „ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return {
                'success': False,
                'error': str(e),
                'processed_image': image,
                'tensor': torch.randn(1, 3, *self.target_size)
            }
    
    def _validate_image(self, image: np.ndarray) -> np.ndarray:
        """ì´ë¯¸ì§€ ìœ íš¨ì„± ê²€ì¦ ë° ë³€í™˜"""
        try:
            # PIL Imageë¥¼ NumPyë¡œ ë³€í™˜
            if isinstance(image, Image.Image):
                image = np.array(image)
            
            # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ì„ RGBë¡œ ë³€í™˜
            if len(image.shape) == 2:
                image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)
            elif image.shape[2] == 4:  # RGBA
                image = cv2.cvtColor(image, cv2.COLOR_RGBA2RGB)
            
            # ë°ì´í„° íƒ€ì… ì •ê·œí™”
            if image.dtype != np.uint8:
                image = image.astype(np.uint8)
            
            return image
            
        except Exception as e:
            self.logger.warning(f"ì´ë¯¸ì§€ ê²€ì¦ ì‹¤íŒ¨: {e}")
            return image
    
    def _align_body_clothing(self, image: np.ndarray) -> Tuple[np.ndarray, Dict[str, Any]]:
        """ì¸ì²´-ì˜ë¥˜ ì •í•©"""
        try:
            # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜
            gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
            
            # 1. ì¸ì²´ ê°ì§€ (HOG ë””í…í„° ì‚¬ìš©)
            hog = cv2.HOGDescriptor()
            hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())
            
            # ì¸ì²´ ê°ì§€
            bodies, weights = hog.detectMultiScale(gray, winStride=(8, 8), padding=(4, 4), scale=1.05)
            
            # 2. ì˜ë¥˜ ì˜ì—­ ê°ì§€
            clothing_contours = self._detect_clothing_areas(gray)
            
            # 3. ì •í•© ì²˜ë¦¬
            if len(bodies) > 0 and len(clothing_contours) > 0:
                # ê°€ì¥ í° ì¸ì²´ ì˜ì—­ ì„ íƒ
                largest_body = max(bodies, key=lambda x: x[2] * x[3])
                
                # ê°€ì¥ í° ì˜ë¥˜ ì˜ì—­ ì„ íƒ
                largest_clothing = max(clothing_contours, key=cv2.contourArea)
                
                # ì •í•© ì ìš©
                aligned_image = self._apply_body_clothing_alignment(image, largest_body, largest_clothing)
                
                alignment_info = {
                    'alignment_applied': True,
                    'body_count': len(bodies),
                    'clothing_count': len(clothing_contours),
                    'body_area': largest_body[2] * largest_body[3],
                    'clothing_area': cv2.contourArea(largest_clothing),
                    'alignment_quality': 'high'
                }
                
                return aligned_image, alignment_info
            else:
                # ì •í•©í•  ìˆ˜ ì—†ëŠ” ê²½ìš° ì›ë³¸ ë°˜í™˜
                return image, {
                    'alignment_applied': False,
                    'body_count': len(bodies),
                    'clothing_count': len(clothing_contours),
                    'body_area': 0,
                    'clothing_area': 0,
                    'alignment_quality': 'none'
                }
                
        except Exception as e:
            self.logger.warning(f"ì¸ì²´-ì˜ë¥˜ ì •í•© ì‹¤íŒ¨: {e}")
            return image, {
                'alignment_applied': False,
                'body_count': 0,
                'clothing_count': 0,
                'body_area': 0,
                'clothing_area': 0,
                'alignment_quality': 'none'
            }
    
    def _detect_clothing_areas(self, gray_image: np.ndarray) -> List[np.ndarray]:
        """ì˜ë¥˜ ì˜ì—­ ê°ì§€"""
        try:
            # 1. ì—£ì§€ ê°ì§€
            edges = cv2.Canny(gray_image, 30, 100)
            
            # 2. ìœ¤ê³½ì„  ì°¾ê¸°
            contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            
            # 3. ì˜ë¥˜ ì˜ì—­ í•„í„°ë§
            clothing_contours = []
            for contour in contours:
                area = cv2.contourArea(contour)
                if area > 2000:  # ìµœì†Œ ë©´ì  ì„ê³„ê°’
                    # í˜•íƒœ ë¶„ì„ìœ¼ë¡œ ì˜ë¥˜ ì˜ì—­ íŒë³„
                    if self._is_clothing_shape(contour):
                        clothing_contours.append(contour)
            
            return clothing_contours
            
        except Exception as e:
            self.logger.warning(f"ì˜ë¥˜ ì˜ì—­ ê°ì§€ ì‹¤íŒ¨: {e}")
            return []
    
    def _is_clothing_shape(self, contour: np.ndarray) -> bool:
        """ì˜ë¥˜ í˜•íƒœì¸ì§€ íŒë³„"""
        try:
            # ìœ¤ê³½ì„ ì˜ ë©´ì ê³¼ ë‘˜ë ˆ ë¹„ìœ¨ ê³„ì‚°
            area = cv2.contourArea(contour)
            perimeter = cv2.arcLength(contour, True)
            
            if perimeter > 0:
                # ì›í˜•ë„ ê³„ì‚° (1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ì›í˜•)
                circularity = 4 * np.pi * area / (perimeter * perimeter)
                
                # ì§ì‚¬ê°í˜•ë„ ê³„ì‚°
                x, y, w, h = cv2.boundingRect(contour)
                aspect_ratio = w / h if h > 0 else 0
                
                # ì˜ë¥˜ í˜•íƒœ íŒë³„ ì¡°ê±´
                is_clothing = (circularity < 0.8 and  # ë„ˆë¬´ ì›í˜•ì´ ì•„ë‹˜
                             0.2 < aspect_ratio < 5.0 and  # ì ì ˆí•œ ë¹„ìœ¨
                             area > 2000)  # ì¶©ë¶„í•œ í¬ê¸°
                
                return is_clothing
            
            return False
            
        except Exception as e:
            self.logger.warning(f"ì˜ë¥˜ í˜•íƒœ íŒë³„ ì‹¤íŒ¨: {e}")
            return False
    
    def _apply_body_clothing_alignment(self, image: np.ndarray, body: Tuple[int, int, int, int], 
                                     clothing_contour: np.ndarray) -> np.ndarray:
        """ì¸ì²´-ì˜ë¥˜ ì •í•© ì ìš©"""
        try:
            aligned = image.copy()
            
            # 1. ì¸ì²´ ì˜ì—­ í‘œì‹œ
            x, y, w, h = body
            cv2.rectangle(aligned, (x, y), (x + w, y + h), (0, 255, 0), 2)
            
            # 2. ì˜ë¥˜ ìœ¤ê³½ì„  í‘œì‹œ
            cv2.drawContours(aligned, [clothing_contour], -1, (255, 0, 0), 2)
            
            # 3. ì •í•© ì¤‘ì‹¬ì  ê³„ì‚°
            body_center = (x + w // 2, y + h // 2)
            
            # ì˜ë¥˜ ì¤‘ì‹¬ì  ê³„ì‚°
            M = cv2.moments(clothing_contour)
            if M['m00'] != 0:
                clothing_center_x = int(M['m10'] / M['m00'])
                clothing_center_y = int(M['m01'] / M['m00'])
                clothing_center = (clothing_center_x, clothing_center_y)
                
                # ì¤‘ì‹¬ì  ì—°ê²°ì„  ê·¸ë¦¬ê¸°
                cv2.line(aligned, body_center, clothing_center, (0, 255, 255), 2)
                
                # ì¤‘ì‹¬ì  í‘œì‹œ
                cv2.circle(aligned, body_center, 5, (0, 255, 0), -1)
                cv2.circle(aligned, clothing_center, 5, (255, 0, 0), -1)
            
            return aligned
            
        except Exception as e:
            self.logger.warning(f"ì¸ì²´-ì˜ë¥˜ ì •í•© ì ìš© ì‹¤íŒ¨: {e}")
            return image
    
    def _standardize_resolution(self, image: np.ndarray) -> np.ndarray:
        """í•´ìƒë„ í‘œì¤€í™”"""
        try:
            # ëª©í‘œ í•´ìƒë„ë¡œ ë¦¬ì‚¬ì´ì¦ˆ
            resized = cv2.resize(image, self.target_size, interpolation=cv2.INTER_LANCZOS4)
            return resized
            
        except Exception as e:
            self.logger.warning(f"í•´ìƒë„ í‘œì¤€í™” ì‹¤íŒ¨: {e}")
            return image
    
    def _optimize_for_virtual_fitting(self, image: np.ndarray) -> np.ndarray:
        """ê°€ìƒ í”¼íŒ… ìµœì í™”"""
        try:
            optimized = image.copy()
            
            # 1. ì¸ì²´-ì˜ë¥˜ ì •í•©
            if self.fitting_params['body_clothing_alignment']:
                optimized = self._enhance_body_clothing_alignment(optimized)
            
            # 2. í”¼íŒ… í’ˆì§ˆ ìµœì í™”
            if self.fitting_params['fitting_quality_optimization']:
                optimized = self._optimize_fitting_quality(optimized)
            
            # 3. ìì—°ìŠ¤ëŸ¬ìš´ ë³€í˜•
            if self.fitting_params['natural_deformation']:
                optimized = self._apply_natural_deformation(optimized)
            
            # 4. ì¡°ëª… ë° ê·¸ë¦¼ì ì¡°ì •
            if self.fitting_params['lighting_shadow_adjustment']:
                optimized = self._adjust_lighting_shadows(optimized)
            
            # 5. ìµœì¢… í’ˆì§ˆ í–¥ìƒ
            if self.fitting_params['final_quality_enhancement']:
                optimized = self._enhance_final_quality(optimized)
            
            return optimized
            
        except Exception as e:
            self.logger.warning(f"ê°€ìƒ í”¼íŒ… ìµœì í™” ì‹¤íŒ¨: {e}")
            return image
    
    def _enhance_body_clothing_alignment(self, image: np.ndarray) -> np.ndarray:
        """ì¸ì²´-ì˜ë¥˜ ì •í•© í–¥ìƒ"""
        try:
            enhanced = image.copy()
            
            # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜
            gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
            
            # 1. ì—£ì§€ ê°•í™”
            edges = cv2.Canny(gray, 20, 80)
            
            # 2. ëª¨í´ë¡œì§€ ì—°ì‚°ìœ¼ë¡œ ì—£ì§€ ì •ì œ
            kernel = np.ones((3, 3), np.uint8)
            refined_edges = cv2.morphologyEx(edges, cv2.MORPH_CLOSE, kernel)
            
            # 3. ì—£ì§€ë¥¼ RGBë¡œ ë³€í™˜
            edges_rgb = cv2.cvtColor(refined_edges, cv2.COLOR_GRAY2RGB)
            
            # 4. ì›ë³¸ê³¼ ì—£ì§€ í•©ì„±
            enhanced = cv2.addWeighted(enhanced, 0.9, edges_rgb, 0.1, 0)
            
            return enhanced
            
        except Exception as e:
            self.logger.warning(f"ì¸ì²´-ì˜ë¥˜ ì •í•© í–¥ìƒ ì‹¤íŒ¨: {e}")
            return image
    
    def _optimize_fitting_quality(self, image: np.ndarray) -> np.ndarray:
        """í”¼íŒ… í’ˆì§ˆ ìµœì í™”"""
        try:
            optimized = image.copy()
            
            # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜
            gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
            
            # 1. í”¼íŒ… í’ˆì§ˆì„ ìœ„í•œ í•„í„°ë§
            # ê°€ìš°ì‹œì•ˆ ë¸”ëŸ¬ë¡œ ë¶€ë“œëŸ¬ìš´ í”¼íŒ…
            blurred = cv2.GaussianBlur(gray, (5, 5), 0)
            
            # 2. í”¼íŒ… í’ˆì§ˆ ê°•ë„ ê³„ì‚°
            fitting_quality = cv2.addWeighted(gray, 1.3, blurred, -0.3, 0)
            
            # 3. í”¼íŒ… í’ˆì§ˆ ë§µ ì •ê·œí™”
            quality_map = cv2.normalize(fitting_quality, None, 0, 255, cv2.NORM_MINMAX)
            
            # 4. í’ˆì§ˆ ë§µì„ RGBë¡œ ë³€í™˜
            quality_rgb = cv2.cvtColor(quality_map, cv2.COLOR_GRAY2RGB)
            
            # 5. ì›ë³¸ê³¼ í’ˆì§ˆ ë§µ í•©ì„±
            optimized = cv2.addWeighted(optimized, 0.8, quality_rgb, 0.2, 0)
            
            return optimized
            
        except Exception as e:
            self.logger.warning(f"í”¼íŒ… í’ˆì§ˆ ìµœì í™” ì‹¤íŒ¨: {e}")
            return image
    
    def _apply_natural_deformation(self, image: np.ndarray) -> np.ndarray:
        """ìì—°ìŠ¤ëŸ¬ìš´ ë³€í˜• ì ìš©"""
        try:
            deformed = image.copy()
            
            # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜
            gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
            
            # 1. ìì—°ìŠ¤ëŸ¬ìš´ ë³€í˜•ì„ ìœ„í•œ í•„í„°ë§
            # ì–‘ë°©í–¥ í•„í„°ë¡œ í…ìŠ¤ì²˜ ë³´ì¡´í•˜ë©´ì„œ ë¶€ë“œëŸ½ê²Œ
            deformed = cv2.bilateralFilter(deformed, 9, 75, 75)
            
            # 2. ë³€í˜• ê°•ë„ ì¡°ì ˆ
            # ì›ë³¸ê³¼ ë³€í˜•ëœ ì´ë¯¸ì§€ì˜ ê°€ì¤‘ í‰ê· 
            deformed = cv2.addWeighted(image, 0.7, deformed, 0.3, 0)
            
            return deformed
            
        except Exception as e:
            self.logger.warning(f"ìì—°ìŠ¤ëŸ¬ìš´ ë³€í˜• ì ìš© ì‹¤íŒ¨: {e}")
            return image
    
    def _adjust_lighting_shadows(self, image: np.ndarray) -> np.ndarray:
        """ì¡°ëª… ë° ê·¸ë¦¼ì ì¡°ì •"""
        try:
            adjusted = image.copy()
            
            # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜
            gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
            
            # 1. íˆìŠ¤í† ê·¸ë¨ í‰í™œí™”ë¡œ ì¡°ëª… ì¡°ì •
            equalized = cv2.equalizeHist(gray)
            
            # 2. ê·¸ë¦¼ì ê°ì§€ ë° ë³´ì •
            # ì–´ë‘ìš´ ì˜ì—­ ê°ì§€
            _, shadow_mask = cv2.threshold(gray, 50, 255, cv2.THRESH_BINARY_INV)
            
            # ê·¸ë¦¼ì ì˜ì—­ì„ ë°ê²Œ ì¡°ì •
            shadow_corrected = cv2.addWeighted(gray, 0.8, equalized, 0.2, 0)
            
            # 3. ì¡°ì •ëœ ì´ë¯¸ì§€ë¥¼ RGBë¡œ ë³€í™˜
            adjusted_gray = cv2.cvtColor(shadow_corrected, cv2.COLOR_GRAY2RGB)
            
            # 4. ì›ë³¸ê³¼ ì¡°ì •ëœ ì´ë¯¸ì§€ í•©ì„±
            adjusted = cv2.addWeighted(adjusted, 0.8, adjusted_gray, 0.2, 0)
            
            return adjusted
            
        except Exception as e:
            self.logger.warning(f"ì¡°ëª… ë° ê·¸ë¦¼ì ì¡°ì • ì‹¤íŒ¨: {e}")
            return image
    
    def _enhance_final_quality(self, image: np.ndarray) -> np.ndarray:
        """ìµœì¢… í’ˆì§ˆ í–¥ìƒ"""
        try:
            enhanced = image.copy()
            
            # 1. ëŒ€ë¹„ í–¥ìƒ
            enhanced = cv2.convertScaleAbs(enhanced, alpha=1.1, beta=5)
            
            # 2. ì„ ëª…ë„ í–¥ìƒ
            kernel = np.array([[-1,-1,-1], [-1,9,-1], [-1,-1,-1]])
            enhanced = cv2.filter2D(enhanced, -1, kernel)
            
            # 3. ë…¸ì´ì¦ˆ ì œê±°
            enhanced = cv2.fastNlMeansDenoisingColored(enhanced, None, 10, 10, 7, 21)
            
            # 4. ìµœì¢… í’ˆì§ˆ ì¡°ì •
            enhanced = cv2.addWeighted(image, 0.3, enhanced, 0.7, 0)
            
            return enhanced
            
        except Exception as e:
            self.logger.warning(f"ìµœì¢… í’ˆì§ˆ í–¥ìƒ ì‹¤íŒ¨: {e}")
            return image
    
    def _normalize_and_convert(self, image: np.ndarray) -> torch.Tensor:
        """ì •ê·œí™” ë° í…ì„œ ë³€í™˜"""
        try:
            # 0-1 ë²”ìœ„ë¡œ ì •ê·œí™”
            normalized = image.astype(np.float32) / 255.0
            
            # ImageNet í‰ê· /í‘œì¤€í¸ì°¨ë¡œ ì •ê·œí™”
            mean = np.array([0.485, 0.456, 0.406])
            std = np.array([0.229, 0.224, 0.225])
            
            normalized = (normalized - mean) / std
            
            # í…ì„œë¡œ ë³€í™˜ [H, W, C] -> [C, H, W] -> [1, C, H, W]
            tensor = torch.from_numpy(normalized).permute(2, 0, 1).unsqueeze(0)
            
            return tensor
            
        except Exception as e:
            self.logger.warning(f"ì •ê·œí™” ë° ë³€í™˜ ì‹¤íŒ¨: {e}")
            return torch.randn(1, 3, *self.target_size)
    
    def get_processing_stats(self) -> Dict[str, Any]:
        """ì²˜ë¦¬ í†µê³„ ë°˜í™˜"""
        return self.processing_stats.copy()
    
    def reset_stats(self):
        """í†µê³„ ì´ˆê¸°í™”"""
        self.processing_stats = {
            'images_processed': 0,
            'alignments_applied': 0,
            'deformations_processed': 0,
            'lighting_adjusted': 0
        }
    
    def update_fitting_params(self, **kwargs):
        """ê°€ìƒ í”¼íŒ… íŒŒë¼ë¯¸í„° ì—…ë°ì´íŠ¸"""
        for key, value in kwargs.items():
            if key in self.fitting_params:
                self.fitting_params[key] = value
                self.logger.info(f"ê°€ìƒ í”¼íŒ… íŒŒë¼ë¯¸í„° ì—…ë°ì´íŠ¸: {key} = {value}")
