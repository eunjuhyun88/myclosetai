#!/usr/bin/env python3
"""
ğŸ”¥ MyCloset AI - Virtual Fitting Validator
=========================================

ğŸ¯ ê°€ìƒ í”¼íŒ… ê²€ì¦ê¸°
âœ… ê°€ìƒ í”¼íŒ… ê²°ê³¼ ê²€ì¦
âœ… í’ˆì§ˆ ë©”íŠ¸ë¦­ ê³„ì‚°
âœ… ì¼ê´€ì„± ê²€ì‚¬
âœ… M3 Max ìµœì í™”
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import logging
from typing import Dict, List, Tuple, Optional, Union, Any
from dataclasses import dataclass
import cv2
from PIL import Image

logger = logging.getLogger(__name__)

@dataclass
class ValidationConfig:
    """ê²€ì¦ ì„¤ì •"""
    enable_quality_metrics: bool = True
    enable_consistency_check: bool = True
    enable_realism_evaluation: bool = True
    enable_fitting_accuracy: bool = True
    quality_threshold: float = 0.7
    use_mps: bool = True

class VirtualFittingQualityEvaluator(nn.Module):
    """ê°€ìƒ í”¼íŒ… í’ˆì§ˆ í‰ê°€ê¸°"""
    
    def __init__(self, input_channels: int = 3):
        super().__init__()
        self.input_channels = input_channels
        
        # í’ˆì§ˆ í‰ê°€ë¥¼ ìœ„í•œ ë„¤íŠ¸ì›Œí¬
        self.quality_net = nn.Sequential(
            nn.Conv2d(input_channels, 64, 3, padding=1),
            nn.ReLU(),
            nn.Conv2d(64, 128, 3, padding=1),
            nn.ReLU(),
            nn.Conv2d(128, 64, 3, padding=1),
            nn.ReLU(),
            nn.AdaptiveAvgPool2d(1),
            nn.Flatten(),
            nn.Linear(64, 32),
            nn.ReLU(),
            nn.Linear(32, 1),
            nn.Sigmoid()
        )
        
    def forward(self, x):
        # í’ˆì§ˆ í‰ê°€
        quality_score = self.quality_net(x)
        return quality_score

class VirtualFittingConsistencyChecker(nn.Module):
    """ê°€ìƒ í”¼íŒ… ì¼ê´€ì„± ê²€ì‚¬ê¸°"""
    
    def __init__(self, input_channels: int = 6):  # 3 for original + 3 for result
        super().__init__()
        self.input_channels = input_channels
        
        # ì¼ê´€ì„± ê²€ì‚¬ë¥¼ ìœ„í•œ ë„¤íŠ¸ì›Œí¬
        self.consistency_net = nn.Sequential(
            nn.Conv2d(input_channels, 64, 3, padding=1),
            nn.ReLU(),
            nn.Conv2d(64, 128, 3, padding=1),
            nn.ReLU(),
            nn.Conv2d(128, 64, 3, padding=1),
            nn.ReLU(),
            nn.AdaptiveAvgPool2d(1),
            nn.Flatten(),
            nn.Linear(64, 32),
            nn.ReLU(),
            nn.Linear(32, 1),
            nn.Sigmoid()
        )
        
    def forward(self, x):
        # ì¼ê´€ì„± ê²€ì‚¬
        consistency_score = self.consistency_net(x)
        return consistency_score

class VirtualFittingRealismEvaluator(nn.Module):
    """ê°€ìƒ í”¼íŒ… í˜„ì‹¤ì„± í‰ê°€ê¸°"""
    
    def __init__(self, input_channels: int = 3):
        super().__init__()
        self.input_channels = input_channels
        
        # í˜„ì‹¤ì„± í‰ê°€ë¥¼ ìœ„í•œ ë„¤íŠ¸ì›Œí¬
        self.realism_net = nn.Sequential(
            nn.Conv2d(input_channels, 64, 3, padding=1),
            nn.ReLU(),
            nn.Conv2d(64, 128, 3, padding=1),
            nn.ReLU(),
            nn.Conv2d(128, 64, 3, padding=1),
            nn.ReLU(),
            nn.AdaptiveAvgPool2d(1),
            nn.Flatten(),
            nn.Linear(64, 32),
            nn.ReLU(),
            nn.Linear(32, 1),
            nn.Sigmoid()
        )
        
    def forward(self, x):
        # í˜„ì‹¤ì„± í‰ê°€
        realism_score = self.realism_net(x)
        return realism_score

class VirtualFittingAccuracyChecker(nn.Module):
    """ê°€ìƒ í”¼íŒ… ì •í™•ë„ ê²€ì‚¬ê¸°"""
    
    def __init__(self, input_channels: int = 6):  # 3 for target + 3 for result
        super().__init__()
        self.input_channels = input_channels
        
        # ì •í™•ë„ ê²€ì‚¬ë¥¼ ìœ„í•œ ë„¤íŠ¸ì›Œí¬
        self.accuracy_net = nn.Sequential(
            nn.Conv2d(input_channels, 64, 3, padding=1),
            nn.ReLU(),
            nn.Conv2d(64, 128, 3, padding=1),
            nn.ReLU(),
            nn.Conv2d(128, 64, 3, padding=1),
            nn.ReLU(),
            nn.AdaptiveAvgPool2d(1),
            nn.Flatten(),
            nn.Linear(64, 32),
            nn.ReLU(),
            nn.Linear(32, 1),
            nn.Sigmoid()
        )
        
    def forward(self, x):
        # ì •í™•ë„ ê²€ì‚¬
        accuracy_score = self.accuracy_net(x)
        return accuracy_score

class VirtualFittingValidator(nn.Module):
    """ê°€ìƒ í”¼íŒ… ê²€ì¦ê¸°"""
    
    def __init__(self, config: ValidationConfig = None):
        super().__init__()
        self.config = config or ValidationConfig()
        self.logger = logging.getLogger(__name__)
        
        # MPS ë””ë°”ì´ìŠ¤ í™•ì¸
        self.device = torch.device("mps" if torch.backends.mps.is_available() and self.config.use_mps else "cpu")
        self.logger.info(f"ğŸ¯ Virtual Fitting ê²€ì¦ê¸° ì´ˆê¸°í™” (ë””ë°”ì´ìŠ¤: {self.device})")
        
        # í’ˆì§ˆ í‰ê°€ê¸°
        if self.config.enable_quality_metrics:
            self.quality_evaluator = VirtualFittingQualityEvaluator(3).to(self.device)
        
        # ì¼ê´€ì„± ê²€ì‚¬ê¸°
        if self.config.enable_consistency_check:
            self.consistency_checker = VirtualFittingConsistencyChecker(6).to(self.device)
        
        # í˜„ì‹¤ì„± í‰ê°€ê¸°
        if self.config.enable_realism_evaluation:
            self.realism_evaluator = VirtualFittingRealismEvaluator(3).to(self.device)
        
        # ì •í™•ë„ ê²€ì‚¬ê¸°
        if self.config.enable_fitting_accuracy:
            self.accuracy_checker = VirtualFittingAccuracyChecker(6).to(self.device)
        
        self.logger.info("âœ… Virtual Fitting ê²€ì¦ê¸° ì´ˆê¸°í™” ì™„ë£Œ")
    
    def forward(self, virtual_fitting_result: torch.Tensor,
                original_image: Optional[torch.Tensor] = None,
                target_image: Optional[torch.Tensor] = None) -> Dict[str, torch.Tensor]:
        """
        ê°€ìƒ í”¼íŒ… ê²°ê³¼ë¥¼ ê²€ì¦í•©ë‹ˆë‹¤.
        
        Args:
            virtual_fitting_result: ê°€ìƒ í”¼íŒ… ê²°ê³¼ ì´ë¯¸ì§€ (B, C, H, W)
            original_image: ì›ë³¸ ì´ë¯¸ì§€ (B, C, H, W)
            target_image: ëª©í‘œ ì´ë¯¸ì§€ (B, C, H, W)
            
        Returns:
            ê²€ì¦ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        batch_size, channels, height, width = virtual_fitting_result.shape
        
        # ì…ë ¥ ê²€ì¦
        if channels != 3:
            raise ValueError(f"Expected 3 channels, got {channels}")
        
        # ì…ë ¥ì„ ë””ë°”ì´ìŠ¤ë¡œ ì´ë™
        virtual_fitting_result = virtual_fitting_result.to(self.device)
        if original_image is not None:
            original_image = original_image.to(self.device)
        if target_image is not None:
            target_image = target_image.to(self.device)
        
        validation_results = {}
        
        # í’ˆì§ˆ í‰ê°€
        if self.config.enable_quality_metrics:
            quality_score = self.quality_evaluator(virtual_fitting_result)
            validation_results['quality_score'] = quality_score
            self.logger.debug("í’ˆì§ˆ í‰ê°€ ì™„ë£Œ")
        
        # ì¼ê´€ì„± ê²€ì‚¬
        if self.config.enable_consistency_check and original_image is not None:
            combined_input = torch.cat([original_image, virtual_fitting_result], dim=1)
            consistency_score = self.consistency_checker(combined_input)
            validation_results['consistency_score'] = consistency_score
            self.logger.debug("ì¼ê´€ì„± ê²€ì‚¬ ì™„ë£Œ")
        
        # í˜„ì‹¤ì„± í‰ê°€
        if self.config.enable_realism_evaluation:
            realism_score = self.realism_evaluator(virtual_fitting_result)
            validation_results['realism_score'] = realism_score
            self.logger.debug("í˜„ì‹¤ì„± í‰ê°€ ì™„ë£Œ")
        
        # ì •í™•ë„ ê²€ì‚¬
        if self.config.enable_fitting_accuracy and target_image is not None:
            combined_input = torch.cat([target_image, virtual_fitting_result], dim=1)
            accuracy_score = self.accuracy_checker(combined_input)
            validation_results['accuracy_score'] = accuracy_score
            self.logger.debug("ì •í™•ë„ ê²€ì‚¬ ì™„ë£Œ")
        
        # ì „ì²´ ê²€ì¦ ì ìˆ˜ ê³„ì‚°
        if validation_results:
            scores = [score.mean().item() for score in validation_results.values()]
            overall_score = sum(scores) / len(scores)
            validation_results['overall_score'] = torch.tensor([[overall_score]], device=self.device)
            
            # í’ˆì§ˆ ì„ê³„ê°’ í™•ì¸
            validation_results['quality_passed'] = overall_score >= self.config.quality_threshold
        
        # ê²°ê³¼ ë°˜í™˜
        result = {
            'validation_results': validation_results,
            'input_size': (height, width),
            'batch_size': batch_size
        }
        
        return result
    
    def calculate_quality_metrics(self, original_image: torch.Tensor, 
                                 virtual_fitting_result: torch.Tensor) -> Dict[str, float]:
        """í’ˆì§ˆ ë©”íŠ¸ë¦­ì„ ê³„ì‚°í•©ë‹ˆë‹¤."""
        if not self.config.enable_quality_metrics:
            return {'status': 'disabled'}
        
        metrics = {}
        
        try:
            with torch.no_grad():
                # PSNR (Peak Signal-to-Noise Ratio) ê³„ì‚°
                mse = torch.mean((original_image - virtual_fitting_result) ** 2)
                if mse > 0:
                    psnr = 20 * torch.log10(1.0 / torch.sqrt(mse))
                    metrics['psnr'] = psnr.item() if hasattr(psnr, 'item') else float(psnr)
                else:
                    metrics['psnr'] = float('inf')
                
                # SSIM (Structural Similarity Index) ê³„ì‚° (ê°„ë‹¨í•œ ë²„ì „)
                def simple_ssim(x, y):
                    mu_x = torch.mean(x)
                    mu_y = torch.mean(y)
                    sigma_x = torch.std(x)
                    sigma_y = torch.std(y)
                    sigma_xy = torch.mean((x - mu_x) * (y - mu_y))
                    
                    c1 = 0.01 ** 2
                    c2 = 0.03 ** 2
                    
                    ssim = ((2 * mu_x * mu_y + c1) * (2 * sigma_xy + c2)) / \
                           ((mu_x ** 2 + mu_y ** 2 + c1) * (sigma_x ** 2 + sigma_y ** 2 + c2))
                    
                    return ssim
                
                ssim = simple_ssim(original_image, virtual_fitting_result)
                metrics['ssim'] = ssim.item() if hasattr(ssim, 'item') else float(ssim)
                
                # LPIPS (Learned Perceptual Image Patch Similarity) ê³„ì‚° (ê°„ë‹¨í•œ ë²„ì „)
                def simple_lpips(x, y):
                    diff = torch.mean(torch.abs(x - y))
                    return diff
                
                lpips = simple_lpips(original_image, virtual_fitting_result)
                metrics['lpips'] = lpips.item() if hasattr(lpips, 'item') else float(lpips)
                
                metrics['status'] = 'success'
                self.logger.info("í’ˆì§ˆ ë©”íŠ¸ë¦­ ê³„ì‚° ì™„ë£Œ")
                
        except Exception as e:
            metrics['status'] = 'error'
            metrics['error'] = str(e)
            self.logger.error(f"í’ˆì§ˆ ë©”íŠ¸ë¦­ ê³„ì‚° ì‹¤íŒ¨: {e}")
        
        return metrics
    
    def validate_batch(self, batch_virtual_fitting: List[torch.Tensor],
                      batch_original: Optional[List[torch.Tensor]] = None,
                      batch_target: Optional[List[torch.Tensor]] = None) -> List[Dict[str, torch.Tensor]]:
        """
        ë°°ì¹˜ ë‹¨ìœ„ë¡œ ê²€ì¦ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
        
        Args:
            batch_virtual_fitting: ê°€ìƒ í”¼íŒ… ê²°ê³¼ ë°°ì¹˜ ë¦¬ìŠ¤íŠ¸
            batch_original: ì›ë³¸ ì´ë¯¸ì§€ ë°°ì¹˜ ë¦¬ìŠ¤íŠ¸
            batch_target: ëª©í‘œ ì´ë¯¸ì§€ ë°°ì¹˜ ë¦¬ìŠ¤íŠ¸
            
        Returns:
            ê²€ì¦ ê²°ê³¼ ë°°ì¹˜ ë¦¬ìŠ¤íŠ¸
        """
        results = []
        
        for i, virtual_fitting in enumerate(batch_virtual_fitting):
            try:
                original = batch_original[i] if batch_original else None
                target = batch_target[i] if batch_target else None
                
                result = self.forward(virtual_fitting, original, target)
                results.append(result)
                self.logger.debug(f"ë°°ì¹˜ {i} ê²€ì¦ ì™„ë£Œ")
            except Exception as e:
                self.logger.error(f"ë°°ì¹˜ {i} ê²€ì¦ ì‹¤íŒ¨: {e}")
                # ì—ëŸ¬ ë°œìƒ ì‹œ ê¸°ë³¸ ê²°ê³¼ ë°˜í™˜
                results.append({
                    'validation_results': {},
                    'input_size': virtual_fitting.shape[-2:],
                    'batch_size': virtual_fitting.shape[0]
                })
        
        return results
    
    def get_validation_stats(self) -> Dict[str, Any]:
        """ê²€ì¦ í†µê³„ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
        return {
            'quality_metrics_enabled': self.config.enable_quality_metrics,
            'consistency_check_enabled': self.config.enable_consistency_check,
            'realism_evaluation_enabled': self.config.enable_realism_evaluation,
            'fitting_accuracy_enabled': self.config.enable_fitting_accuracy,
            'quality_threshold': self.config.quality_threshold,
            'device': str(self.device),
            'config': self.config.__dict__
        }

# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    # ì„¤ì •
    config = ValidationConfig(
        enable_quality_metrics=True,
        enable_consistency_check=True,
        enable_realism_evaluation=True,
        enable_fitting_accuracy=True,
        quality_threshold=0.7,
        use_mps=True
    )
    
    # ê²€ì¦ê¸° ì´ˆê¸°í™”
    validator = VirtualFittingValidator(config)
    
    # í…ŒìŠ¤íŠ¸ ì…ë ¥
    batch_size = 2
    channels = 3
    height = 256
    width = 256
    
    test_virtual_fitting = torch.randn(batch_size, channels, height, width)
    test_original = torch.randn(batch_size, channels, height, width)
    test_target = torch.randn(batch_size, channels, height, width)
    
    # ê²€ì¦ ìˆ˜í–‰
    with torch.no_grad():
        result = validator(test_virtual_fitting, test_original, test_target)
        
        print("âœ… ê²€ì¦ ì™„ë£Œ!")
        print(f"ê°€ìƒ í”¼íŒ… ê²°ê³¼ í˜•íƒœ: {test_virtual_fitting.shape}")
        print(f"ê²€ì¦ ê²°ê³¼: {result}")
        
        # í’ˆì§ˆ ë©”íŠ¸ë¦­ ê³„ì‚°
        metrics = validator.calculate_quality_metrics(test_original, test_virtual_fitting)
        print(f"í’ˆì§ˆ ë©”íŠ¸ë¦­: {metrics}")
        
        # ê²€ì¦ í†µê³„
        stats = validator.get_validation_stats()
        print(f"ê²€ì¦ í†µê³„: {stats}")
