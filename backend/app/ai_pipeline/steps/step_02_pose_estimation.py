# app/ai_pipeline/steps/step_02_pose_estimation.py
"""
ğŸ”¥ MyCloset AI - 2ë‹¨ê³„: í¬ì¦ˆ ì¶”ì • (Pose Estimation) - ì‹¤ì œ AI ì „ìš© ë²„ì „
================================================================================

âœ… í´ë°± ì™„ì „ ì œê±° - ì‹¤ì œ AI ëª¨ë¸ë§Œ ì‚¬ìš©
âœ… strict_mode=True - ì‹¤íŒ¨ ì‹œ ì¦‰ì‹œ ì—ëŸ¬ ë°˜í™˜
âœ… ModelLoader ì™„ì „ ì—°ë™ - ìˆœí™˜ì°¸ì¡° ì—†ëŠ” í•œë°©í–¥ ì°¸ì¡°
âœ… BaseStepMixin ì™„ì „ ìƒì† - logger ì†ì„± ëˆ„ë½ ì™„ì „ í•´ê²°
âœ… step_model_requests.py ì™„ë²½ í˜¸í™˜
âœ… ë°ì´í„° ì¸í„°í˜ì´ìŠ¤ ì™„ì „ ê²€ì¦
âœ… M3 Max 128GB ìµœì í™” + 18ê°œ í‚¤í¬ì¸íŠ¸ OpenPose
âœ… conda í™˜ê²½ ìµœì í™”
âœ… MRO ì˜¤ë¥˜ ì™„ì „ ë°©ì§€
âœ… í•œë°©í–¥ ë°ì´í„° íë¦„ ë³´ì¥

ğŸ¯ í•µì‹¬ ì›ì¹™:
- ì‹¤ì œ AI ëª¨ë¸ ì‹¤íŒ¨ â†’ ëª…í™•í•œ ì—ëŸ¬ ë°˜í™˜ (ê°€ì§œ ë°ì´í„° ìƒì„± ê¸ˆì§€)
- ModelLoader ì—†ìŒ â†’ ì¦‰ì‹œ ì´ˆê¸°í™” ì‹¤íŒ¨ 
- ì‹œë®¬ë ˆì´ì…˜ ì½”ë“œ ì™„ì „ ì œê±°
- strict ê²€ì¦ìœ¼ë¡œ ì‹ ë¢°ì„± ë³´ì¥

íŒŒì¼ ìœ„ì¹˜: backend/app/ai_pipeline/steps/step_02_pose_estimation.py
ì‘ì„±ì: MyCloset AI Team  
ë‚ ì§œ: 2025-07-21
ë²„ì „: v7.0 (ì‹¤ì œ AI ì „ìš©)
"""

import os
import sys
import logging
import time
import asyncio
import threading
import json
import gc
import hashlib
import base64
from typing import Dict, Any, Optional, Tuple, List, Union, Callable
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor
from dataclasses import dataclass, field, asdict
from enum import Enum
from functools import lru_cache
import numpy as np
import io

# í•„ìˆ˜ íŒ¨í‚¤ì§€ ê²€ì¦
try:
    import torch
    import torch.nn as nn
    import torch.nn.functional as F
    from torch.cuda.amp import autocast
    TORCH_AVAILABLE = True
except ImportError:
    TORCH_AVAILABLE = False
    raise ImportError("âŒ PyTorch í•„ìˆ˜: conda install pytorch torchvision pytorch-cuda -c pytorch -c nvidia")

try:
    import cv2
    CV2_AVAILABLE = True
except ImportError:
    CV2_AVAILABLE = False
    raise ImportError("âŒ OpenCV í•„ìˆ˜: conda install opencv -c conda-forge")

try:
    from PIL import Image, ImageDraw, ImageFont
    PIL_AVAILABLE = True
except ImportError:
    PIL_AVAILABLE = False
    raise ImportError("âŒ Pillow í•„ìˆ˜: conda install pillow -c conda-forge")

try:
    import psutil
    PSUTIL_AVAILABLE = True
except ImportError:
    PSUTIL_AVAILABLE = False
    print("âš ï¸ psutil ê¶Œì¥: conda install psutil -c conda-forge")

# ==============================================
# ğŸ”¥ í•œë°©í–¥ ì°¸ì¡° êµ¬ì¡° - ìˆœí™˜ì°¸ì¡° ì™„ì „ ë°©ì§€
# ==============================================

# 1. BaseStepMixin ì„í¬íŠ¸ (í•µì‹¬)
try:
    from app.ai_pipeline.steps.base_step_mixin import BaseStepMixin
    BASE_STEP_MIXIN_AVAILABLE = True
except ImportError as e:
    raise ImportError(f"âŒ BaseStepMixin í•„ìˆ˜: {e}")

# 2. ModelLoader ì„í¬íŠ¸ (í•„ìˆ˜)
try:
    from app.ai_pipeline.utils.model_loader import (
        ModelLoader, get_global_model_loader
    )
    MODEL_LOADER_AVAILABLE = True
except ImportError as e:
    raise ImportError(f"âŒ ModelLoader í•„ìˆ˜: {e}")

# 3. ë©”ëª¨ë¦¬ ë° ë°ì´í„° ë³€í™˜ê¸° (ì„ íƒì )
try:
    from app.ai_pipeline.utils.memory_manager import get_global_memory_manager
    MEMORY_MANAGER_AVAILABLE = True
except ImportError:
    MEMORY_MANAGER_AVAILABLE = False

try:
    from app.ai_pipeline.utils.data_converter import get_global_data_converter  
    DATA_CONVERTER_AVAILABLE = True
except ImportError:
    DATA_CONVERTER_AVAILABLE = False

# ë¡œê±° ì„¤ì •
logger = logging.getLogger(__name__)

# ==============================================
# ğŸ”¥ ìƒìˆ˜ ë° ë°ì´í„° êµ¬ì¡° ì •ì˜
# ==============================================

class PoseModel(Enum):
    """í¬ì¦ˆ ì¶”ì • ëª¨ë¸ íƒ€ì…"""
    OPENPOSE = "openpose"
    YOLOV8_POSE = "yolov8_pose"
    LIGHTWEIGHT = "lightweight"

class PoseQuality(Enum):
    """í¬ì¦ˆ í’ˆì§ˆ ë“±ê¸‰"""
    EXCELLENT = "excellent"     # 90-100ì 
    GOOD = "good"              # 75-89ì   
    ACCEPTABLE = "acceptable"   # 60-74ì 
    POOR = "poor"              # 40-59ì 
    VERY_POOR = "very_poor"    # 0-39ì 

class PoseType(Enum):
    """í¬ì¦ˆ íƒ€ì…"""
    T_POSE = "t_pose"          # Tì í¬ì¦ˆ
    A_POSE = "a_pose"          # Aì í¬ì¦ˆ
    STANDING = "standing"      # ì¼ë°˜ ì„œìˆëŠ” í¬ì¦ˆ
    SITTING = "sitting"        # ì•‰ì€ í¬ì¦ˆ
    ACTION = "action"          # ì•¡ì…˜ í¬ì¦ˆ
    UNKNOWN = "unknown"        # ì•Œ ìˆ˜ ì—†ëŠ” í¬ì¦ˆ

# OpenPose 18 í‚¤í¬ì¸íŠ¸ ì •ì˜ (step_model_requests.py í˜¸í™˜)
OPENPOSE_18_KEYPOINTS = [
    "nose", "neck", "right_shoulder", "right_elbow", "right_wrist",
    "left_shoulder", "left_elbow", "left_wrist", "middle_hip", "right_hip", 
    "right_knee", "right_ankle", "left_hip", "left_knee", "left_ankle",
    "right_eye", "left_eye", "right_ear", "left_ear"
]

# í‚¤í¬ì¸íŠ¸ ìƒ‰ìƒ (ì‹œê°í™”ìš©)
KEYPOINT_COLORS = [
    (255, 0, 0), (255, 85, 0), (255, 170, 0), (255, 255, 0), (170, 255, 0),
    (85, 255, 0), (0, 255, 0), (0, 255, 85), (0, 255, 170), (0, 255, 255),
    (0, 170, 255), (0, 85, 255), (0, 0, 255), (85, 0, 255), (170, 0, 255),
    (255, 0, 255), (255, 0, 170), (255, 0, 85), (255, 0, 0)
]

# ìŠ¤ì¼ˆë ˆí†¤ ì—°ê²° (OpenPose 18 ê¸°ì¤€)
SKELETON_CONNECTIONS = [
    (0, 1), (1, 2), (2, 3), (3, 4), (1, 5), (5, 6), (6, 7), (1, 8),
    (8, 9), (9, 10), (10, 11), (8, 12), (12, 13), (13, 14), (0, 15),
    (15, 17), (0, 16), (16, 18), (14, 19), (19, 20), (14, 21), (11, 22),
    (22, 23), (11, 24)
]

SKELETON_COLORS = [
    (255, 0, 0), (255, 85, 0), (255, 170, 0), (255, 255, 0), (170, 255, 0),
    (85, 255, 0), (0, 255, 0), (0, 255, 85), (0, 255, 170), (0, 255, 255),
    (0, 170, 255), (0, 85, 255), (0, 0, 255), (85, 0, 255), (170, 0, 255),
    (255, 0, 255), (255, 0, 170), (255, 0, 85), (255, 0, 0), (255, 85, 0),
    (255, 170, 0), (255, 255, 0), (170, 255, 0), (85, 255, 0)
]

# ==============================================
# ğŸ”¥ ë°ì´í„° í´ë˜ìŠ¤ ì •ì˜  
# ==============================================

@dataclass
class PoseMetrics:
    """í¬ì¦ˆ ì¸¡ì • ë°ì´í„°"""
    keypoints: List[List[float]] = field(default_factory=list)
    confidence_scores: List[float] = field(default_factory=list)
    bbox: Tuple[int, int, int, int] = field(default_factory=lambda: (0, 0, 0, 0))
    pose_type: PoseType = PoseType.UNKNOWN
    pose_quality: PoseQuality = PoseQuality.POOR
    overall_score: float = 0.0
    
    # ì‹ ì²´ ë¶€ìœ„ë³„ ì ìˆ˜
    head_score: float = 0.0
    torso_score: float = 0.0  
    arms_score: float = 0.0
    legs_score: float = 0.0
    
    # ì˜ë¥˜ ì°©ìš© ì í•©ì„±
    suitable_for_fitting: bool = False
    issues: List[str] = field(default_factory=list)
    recommendations: List[str] = field(default_factory=list)
    
    # ì²˜ë¦¬ ë©”íƒ€ë°ì´í„°
    model_used: str = ""
    processing_time: float = 0.0
    image_resolution: Tuple[int, int] = field(default_factory=lambda: (0, 0))
    
    def calculate_overall_score(self) -> float:
        """ì „ì²´ ì ìˆ˜ ê³„ì‚°"""
        try:
            if not self.confidence_scores:
                self.overall_score = 0.0
                return 0.0
            
            # ê°€ì¤‘ í‰ê·  ê³„ì‚°
            scores = [
                self.head_score * 0.2,
                self.torso_score * 0.3,
                self.arms_score * 0.25,
                self.legs_score * 0.25
            ]
            
            self.overall_score = sum(scores)
            return self.overall_score
            
        except Exception as e:
            logger.error(f"ì „ì²´ ì ìˆ˜ ê³„ì‚° ì‹¤íŒ¨: {e}")
            self.overall_score = 0.0
            return 0.0

# ==============================================
# ğŸ”¥ ë©”ì¸ PoseEstimationStep í´ë˜ìŠ¤
# ==============================================

class PoseEstimationStep(BaseStepMixin):
    """
    ğŸ”¥ 2ë‹¨ê³„: ì‹¤ì œ AI í¬ì¦ˆ ì¶”ì • ì‹œìŠ¤í…œ - í´ë°± ì™„ì „ ì œê±°
    âœ… BaseStepMixin ì™„ì „ ìƒì† - logger ì†ì„± ëˆ„ë½ ì™„ì „ í•´ê²°
    âœ… ModelLoader ì™„ì „ ì—°ë™ - ì§ì ‘ ëª¨ë¸ í˜¸ì¶œ ì œê±°  
    âœ… strict_mode=True - ì‹¤íŒ¨ ì‹œ ì¦‰ì‹œ ì—ëŸ¬ ë°˜í™˜
    âœ… ì‹¤ì œ AI ëª¨ë¸ë§Œ ì‚¬ìš© - ì‹œë®¬ë ˆì´ì…˜ ì™„ì „ ì œê±°
    âœ… step_model_requests.py ì™„ë²½ í˜¸í™˜
    âœ… M3 Max ìµœì í™” + 18ê°œ í‚¤í¬ì¸íŠ¸ OpenPose
    """
    
    # ì˜ë¥˜ íƒ€ì…ë³„ í¬ì¦ˆ ê°€ì¤‘ì¹˜ (step_model_requests.py ë©”íƒ€ë°ì´í„°ì™€ ì—°ë™)
    CLOTHING_POSE_WEIGHTS = {
        'shirt': {'arms': 0.4, 'torso': 0.4, 'visibility': 0.2},
        'dress': {'torso': 0.5, 'arms': 0.3, 'legs': 0.2},
        'pants': {'legs': 0.6, 'torso': 0.3, 'visibility': 0.1},
        'jacket': {'arms': 0.5, 'torso': 0.4, 'visibility': 0.1},
        'skirt': {'torso': 0.4, 'legs': 0.4, 'visibility': 0.2},
        'top': {'torso': 0.5, 'arms': 0.4, 'visibility': 0.1},
        'default': {'torso': 0.4, 'arms': 0.3, 'legs': 0.2, 'visibility': 0.1}
    }
    
    def __init__(
        self,
        device: Optional[str] = None,
        config: Optional[Dict[str, Any]] = None,
        strict_mode: bool = True,
        **kwargs
    ):
        """
        ğŸ”¥ ì‹¤ì œ AI ì „ìš© ìƒì„±ì - í´ë°± ì™„ì „ ì œê±°
        
        Args:
            device: ë””ë°”ì´ìŠ¤ ì„¤ì • ('auto', 'mps', 'cuda', 'cpu')
            config: ì„¤ì • ë”•ì…”ë„ˆë¦¬
            strict_mode: ì—„ê²© ëª¨ë“œ (Trueì‹œ AI ì‹¤íŒ¨ â†’ ì¦‰ì‹œ ì—ëŸ¬)
            **kwargs: ì¶”ê°€ ì„¤ì •
        """
        
        # ğŸ”¥ 1. BaseStepMixin ì´ˆê¸°í™” (MRO ì•ˆì „)
        super().__init__(device=device, config=config, **kwargs)
        
        # ğŸ”¥ 2. Step ê³ ìœ  ì„¤ì •
        self.step_name = "PoseEstimationStep"
        self.step_number = 2
        self.step_description = "ì‹¤ì œ AI ì¸ì²´ í¬ì¦ˆ ì¶”ì • ë° í‚¤í¬ì¸íŠ¸ ê²€ì¶œ"
        
        # ğŸ”¥ 3. ì—„ê²© ëª¨ë“œ ì„¤ì • (í•µì‹¬)
        self.strict_mode = strict_mode
        if self.strict_mode:
            self.logger.info("ğŸ”’ Strict Mode í™œì„±í™” - ì‹¤ì œ AI ëª¨ë¸ë§Œ ì‚¬ìš©")
        
        # ğŸ”¥ 4. ë””ë°”ì´ìŠ¤ ì„¤ì •
        self._setup_device(device)
        
        # ğŸ”¥ 5. ì„¤ì • í†µí•©
        self._setup_config(config, **kwargs)
        
        # ğŸ”¥ 6. í¬ì¦ˆ ì¶”ì • ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        self._initialize_pose_system()
        
        # ğŸ”¥ 7. ì´ˆê¸°í™” ìƒíƒœ
        self.is_initialized = False
        self.initialization_lock = threading.Lock()
        
        self.logger.info(f"ğŸ¯ {self.step_name} ìƒì„± ì™„ë£Œ (Strict Mode: {self.strict_mode})")
    
    def _setup_device(self, device: Optional[str]):
        """ë””ë°”ì´ìŠ¤ ì„¤ì •"""
        try:
            if device is None or device == "auto":
                if TORCH_AVAILABLE:
                    if torch.backends.mps.is_available():
                        self.device = "mps"
                        self.is_m3_max = True
                    elif torch.cuda.is_available():
                        self.device = "cuda"
                        self.is_m3_max = False
                    else:
                        self.device = "cpu"
                        self.is_m3_max = False
                else:
                    self.device = "cpu"
                    self.is_m3_max = False
            else:
                self.device = device
                self.is_m3_max = device == "mps"
            
            # ë©”ëª¨ë¦¬ ì •ë³´ ìˆ˜ì§‘
            if PSUTIL_AVAILABLE:
                memory = psutil.virtual_memory()
                self.memory_gb = memory.total / (1024**3)
            else:
                self.memory_gb = 16.0  # ê¸°ë³¸ê°’
            
            self.logger.info(f"ğŸ”§ ë””ë°”ì´ìŠ¤: {self.device}, M3 Max: {self.is_m3_max}, ë©”ëª¨ë¦¬: {self.memory_gb:.1f}GB")
            
        except Exception as e:
            self.logger.error(f"âŒ ë””ë°”ì´ìŠ¤ ì„¤ì • ì‹¤íŒ¨: {e}")
            if self.strict_mode:
                raise RuntimeError(f"Strict Mode: ë””ë°”ì´ìŠ¤ ì„¤ì • í•„ìˆ˜ - {e}")
            self.device = "cpu"
            self.is_m3_max = False
            self.memory_gb = 16.0
    
    def _setup_config(self, config: Optional[Dict[str, Any]], **kwargs):
        """ì„¤ì • í†µí•©"""
        self.config = config or {}
        
        # kwargsì—ì„œ ì‹œìŠ¤í…œ íŒŒë¼ë¯¸í„° ì¶”ì¶œ
        system_params = ['device', 'optimization_level', 'batch_size', 'memory_limit']
        for key, value in kwargs.items():
            if key in system_params:
                self.config[key] = value
    
    def _initialize_pose_system(self):
        """í¬ì¦ˆ ì¶”ì • ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
        
        # í¬ì¦ˆ ì¶”ì • ì„¤ì •
        self.pose_config = {
            'model_priority': self.config.get('model_priority', ['openpose', 'yolov8_pose', 'lightweight']),
            'confidence_threshold': self.config.get('confidence_threshold', 0.5),
            'visualization_enabled': self.config.get('visualization_enabled', True),
            'return_analysis': self.config.get('return_analysis', True),
            'cache_enabled': self.config.get('cache_enabled', True),
            'batch_processing': self.config.get('batch_processing', False),
            'detailed_analysis': self.config.get('detailed_analysis', False)
        }
        
        # ìµœì í™” ë ˆë²¨ ì„¤ì • (M3 Max íŠ¹í™”)
        if self.is_m3_max:
            self.optimization_level = 'maximum'
            self.batch_processing = True
            self.use_neural_engine = True
        elif self.memory_gb >= 32:
            self.optimization_level = 'high'
            self.batch_processing = True
            self.use_neural_engine = False
        else:
            self.optimization_level = 'basic'
            self.batch_processing = False
            self.use_neural_engine = False
        
        # ìºì‹œ ì‹œìŠ¤í…œ
        cache_size = min(100 if self.is_m3_max else 50, int(self.memory_gb * 2))
        self.prediction_cache = {}
        self.cache_max_size = cache_size
        
        self.logger.info(f"ğŸ¯ í¬ì¦ˆ ì¶”ì • ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ - ìµœì í™”: {self.optimization_level}")
    
    def _get_step_model_requirements(self) -> Dict[str, Any]:
        """ğŸ”¥ step_model_requests.py ì™„ë²½ í˜¸í™˜ ìš”êµ¬ì‚¬í•­"""
        return {
            "step_name": "PoseEstimationStep",
            "model_name": "pose_estimation_openpose",
            "step_priority": "HIGH",
            "model_class": "OpenPoseModel",
            "input_size": (368, 368),
            "num_classes": 18,
            "output_format": "keypoints_heatmap",
            "device": self.device,
            "precision": "fp16" if self.is_m3_max else "fp32",
            
            # ì²´í¬í¬ì¸íŠ¸ íƒì§€ íŒ¨í„´ (ì‹¤ì œ íŒŒì¼ ê¸°ë°˜)
            "checkpoint_patterns": [
                r".*openpose\.pth$",
                r".*yolov8n-pose\.pt$",
                r".*pose.*model.*\.pth$",
                r".*body.*pose.*\.pth$"
            ],
            "file_extensions": [".pth", ".pt", ".tflite"],
            "size_range_mb": (6.5, 199.6),  # ì‹¤ì œ íƒì§€ëœ í¬ê¸°
            
            # ìµœì í™” íŒŒë¼ë¯¸í„°
            "optimization_params": {
                "batch_size": 1,
                "memory_fraction": 0.25,
                "inference_threads": 4,
                "enable_tensorrt": self.is_m3_max,
                "enable_neural_engine": self.is_m3_max,
                "precision": "fp16" if self.is_m3_max else "fp32"
            },
            
            # ëŒ€ì²´ ëª¨ë¸ë“¤
            "alternative_models": [
                "yolov8n-pose.pt",  # 6.5MB
                "pose_estimation_lightweight"
            ],
            
            # ë©”íƒ€ë°ì´í„°
            "metadata": {
                "description": "18ê°œ í‚¤í¬ì¸íŠ¸ í¬ì¦ˆ ì¶”ì •",
                "keypoints_format": "openpose_18",
                "supports_hands": True,
                "num_stages": 6,
                "clothing_types_supported": list(self.CLOTHING_POSE_WEIGHTS.keys()),
                "quality_assessment": True,
                "visualization_support": True,
                "strict_mode_compatible": True
            }
        }
    
    async def initialize(self) -> bool:
        """
        ğŸ”¥ ì‹¤ì œ AI ëª¨ë¸ ì´ˆê¸°í™” - í´ë°± ì™„ì „ ì œê±°
        
        Returns:
            bool: ì´ˆê¸°í™” ì„±ê³µ ì—¬ë¶€ (strict_modeì—ì„œëŠ” ì‹¤íŒ¨ ì‹œ Exception)
        """
        try:
            with self.initialization_lock:
                if self.is_initialized:
                    return True
                
                self.logger.info(f"ğŸš€ {self.step_name} ì‹¤ì œ AI ì´ˆê¸°í™” ì‹œì‘")
                start_time = time.time()
                
                # ğŸ”¥ 1. ModelLoader í•„ìˆ˜ ê²€ì¦
                if not MODEL_LOADER_AVAILABLE:
                    error_msg = "ModelLoader ì‚¬ìš© ë¶ˆê°€"
                    self.logger.error(f"âŒ {error_msg}")
                    if self.strict_mode:
                        raise RuntimeError(f"Strict Mode: {error_msg}")
                    return False
                
                # ğŸ”¥ 2. ê¸€ë¡œë²Œ ModelLoader ê°€ì ¸ì˜¤ê¸°
                try:
                    self.model_loader = get_global_model_loader()
                    if not self.model_loader:
                        error_msg = "ê¸€ë¡œë²Œ ModelLoader ì—†ìŒ"
                        self.logger.error(f"âŒ {error_msg}")
                        if self.strict_mode:
                            raise RuntimeError(f"Strict Mode: {error_msg}")
                        return False
                    
                    # Step ì¸í„°í˜ì´ìŠ¤ ìƒì„±
                    if hasattr(self.model_loader, 'create_step_interface'):
                        self.model_interface = self.model_loader.create_step_interface(self.step_name)
                    else:
                        self.model_interface = self.model_loader
                    
                    self.logger.info("âœ… ModelLoader ì—°ë™ ì„±ê³µ")
                    
                except Exception as e:
                    error_msg = f"ModelLoader ì—°ë™ ì‹¤íŒ¨: {e}"
                    self.logger.error(f"âŒ {error_msg}")
                    if self.strict_mode:
                        raise RuntimeError(f"Strict Mode: {error_msg}")
                    return False
                
                # ğŸ”¥ 3. Step ìš”êµ¬ì‚¬í•­ ë“±ë¡
                requirements = self._get_step_model_requirements()
                requirements_registered = await self._register_step_requirements(requirements)
                
                if not requirements_registered:
                    error_msg = "Step ìš”êµ¬ì‚¬í•­ ë“±ë¡ ì‹¤íŒ¨"
                    self.logger.error(f"âŒ {error_msg}")
                    if self.strict_mode:
                        raise RuntimeError(f"Strict Mode: {error_msg}")
                    return False
                
                # ğŸ”¥ 4. ì‹¤ì œ AI ëª¨ë¸ ë¡œë“œ
                models_loaded = await self._load_real_ai_models(requirements)
                
                if not models_loaded:
                    error_msg = "ì‹¤ì œ AI ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨"
                    self.logger.error(f"âŒ {error_msg}")
                    if self.strict_mode:
                        raise RuntimeError(f"Strict Mode: {error_msg}")
                    return False
                
                # ğŸ”¥ 5. ëª¨ë¸ ê²€ì¦
                validation_success = await self._validate_loaded_models()
                
                if not validation_success:
                    error_msg = "ë¡œë“œëœ ëª¨ë¸ ê²€ì¦ ì‹¤íŒ¨"
                    self.logger.error(f"âŒ {error_msg}")
                    if self.strict_mode:
                        raise RuntimeError(f"Strict Mode: {error_msg}")
                    return False
                
                # ğŸ”¥ 6. ë©”ëª¨ë¦¬ ìµœì í™”
                self._apply_memory_optimization()
                
                # ğŸ”¥ 7. ì›Œë°ì—… (í•„ìˆ˜)
                await self._warmup_models()
                
                self.is_initialized = True
                elapsed_time = time.time() - start_time
                
                self.logger.info(f"âœ… {self.step_name} ì‹¤ì œ AI ì´ˆê¸°í™” ì™„ë£Œ ({elapsed_time:.2f}ì´ˆ)")
                self.logger.info(f"ğŸ¤– ë¡œë“œëœ ëª¨ë¸: {list(self.pose_models.keys())}")
                self.logger.info(f"ğŸ¯ í™œì„± ëª¨ë¸: {self.active_model}")
                
                return True
                
        except Exception as e:
            self.logger.error(f"âŒ {self.step_name} ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            if self.strict_mode:
                raise  # strict_modeì—ì„œëŠ” Exception ì¬ë°œìƒ
            return False
    
    async def _register_step_requirements(self, requirements: Dict[str, Any]) -> bool:
        """Step ìš”êµ¬ì‚¬í•­ ModelLoaderì— ë“±ë¡"""
        try:
            if hasattr(self.model_interface, 'register_step_requirements'):
                await self.model_interface.register_step_requirements(
                    step_name=requirements["step_name"],
                    requirements=requirements
                )
                self.logger.info("âœ… Step ìš”êµ¬ì‚¬í•­ ë“±ë¡ ì„±ê³µ")
                return True
            else:
                self.logger.warning("âš ï¸ ModelLoaderì— register_step_requirements ì—†ìŒ")
                return False
                
        except Exception as e:
            self.logger.error(f"âŒ Step ìš”êµ¬ì‚¬í•­ ë“±ë¡ ì‹¤íŒ¨: {e}")
            return False
    
    async def _load_real_ai_models(self, requirements: Dict[str, Any]) -> bool:
        """ì‹¤ì œ AI ëª¨ë¸ë§Œ ë¡œë“œ - í´ë°± ì—†ìŒ"""
        try:
            self.pose_models = {}
            self.active_model = None
            
            self.logger.info("ğŸ§  ì‹¤ì œ AI ëª¨ë¸ ë¡œë“œ ì‹œì‘...")
            
            # 1. ìš°ì„ ìˆœìœ„ ëª¨ë¸ ë¡œë“œ ì‹œë„
            primary_model = requirements["model_name"]
            
            try:
                model = await self._load_single_model(primary_model)
                if model:
                    self.pose_models[primary_model] = model
                    self.active_model = primary_model
                    self.logger.info(f"âœ… ì£¼ ëª¨ë¸ ë¡œë“œ ì„±ê³µ: {primary_model}")
                else:
                    raise ValueError(f"ì£¼ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {primary_model}")
                    
            except Exception as e:
                self.logger.error(f"âŒ ì£¼ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
                
                # ëŒ€ì²´ ëª¨ë¸ ì‹œë„
                for alt_model in requirements["alternative_models"]:
                    try:
                        model = await self._load_single_model(alt_model)
                        if model:
                            self.pose_models[alt_model] = model
                            self.active_model = alt_model
                            self.logger.info(f"âœ… ëŒ€ì²´ ëª¨ë¸ ë¡œë“œ ì„±ê³µ: {alt_model}")
                            break
                    except Exception as alt_e:
                        self.logger.warning(f"âš ï¸ ëŒ€ì²´ ëª¨ë¸ ì‹¤íŒ¨: {alt_model} - {alt_e}")
                        continue
            
            # ëª¨ë¸ ë¡œë“œ ê²€ì¦
            if not self.pose_models:
                self.logger.error("âŒ ëª¨ë“  AI ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨")
                return False
            
            # ëª¨ë¸ ìµœì í™” ì„¤ì • ì ìš©
            self._apply_model_optimization()
            
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ AI ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return False
    
    async def _load_single_model(self, model_name: str) -> Optional[Any]:
        """ë‹¨ì¼ ëª¨ë¸ ë¡œë“œ"""
        try:
            if hasattr(self.model_interface, 'get_model'):
                model = self.model_interface.get_model(model_name)
                if model:
                    self.logger.debug(f"âœ… ëª¨ë¸ ë¡œë“œ ì„±ê³µ: {model_name}")
                    return model
                else:
                    self.logger.warning(f"âš ï¸ ëª¨ë¸ ì—†ìŒ: {model_name}")
                    return None
            else:
                self.logger.error("âŒ ModelInterfaceì— get_model ë©”ì„œë“œ ì—†ìŒ")
                return None
                
        except Exception as e:
            self.logger.error(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨ {model_name}: {e}")
            return None
    
    async def _validate_loaded_models(self) -> bool:
        """ë¡œë“œëœ ëª¨ë¸ ê²€ì¦"""
        try:
            if not self.pose_models or not self.active_model:
                self.logger.error("âŒ ë¡œë“œëœ ëª¨ë¸ ì—†ìŒ")
                return False
            
            active_model = self.pose_models.get(self.active_model)
            if not active_model:
                self.logger.error(f"âŒ í™œì„± ëª¨ë¸ ì—†ìŒ: {self.active_model}")
                return False
            
            # ëª¨ë¸ì´ ì‹¤ì œ AI ëª¨ë¸ì¸ì§€ ê²€ì¦
            if hasattr(active_model, '__call__') or hasattr(active_model, 'forward'):
                self.logger.info(f"âœ… ì‹¤ì œ AI ëª¨ë¸ ê²€ì¦ ì„±ê³µ: {self.active_model}")
                return True
            else:
                self.logger.error(f"âŒ ìœ íš¨í•˜ì§€ ì•Šì€ ëª¨ë¸: {self.active_model}")
                return False
                
        except Exception as e:
            self.logger.error(f"âŒ ëª¨ë¸ ê²€ì¦ ì‹¤íŒ¨: {e}")
            return False
    
    def _apply_memory_optimization(self):
        """ë©”ëª¨ë¦¬ ìµœì í™” ì ìš©"""
        try:
            if TORCH_AVAILABLE:
                if self.device == "mps":
                    torch.mps.empty_cache()
                elif self.device == "cuda":
                    torch.cuda.empty_cache()
            
            # ê°€ë¹„ì§€ ì»¬ë ‰ì…˜
            gc.collect()
            
            self.logger.info("âœ… ë©”ëª¨ë¦¬ ìµœì í™” ì ìš© ì™„ë£Œ")
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ ë©”ëª¨ë¦¬ ìµœì í™” ì‹¤íŒ¨: {e}")
    
    def _apply_model_optimization(self):
        """ëª¨ë¸ ìµœì í™” ì„¤ì • ì ìš©"""
        try:
            requirements = self._get_step_model_requirements()
            optimization_params = requirements["optimization_params"]
            
            # ë””ë°”ì´ìŠ¤ë³„ ìµœì í™”
            if self.device == "mps":
                optimization_params.update({
                    "enable_neural_engine": True,
                    "memory_pool_size": min(int(self.memory_gb * 0.25), 32),
                    "optimization_level": "maximum"
                })
            elif self.device == "cuda":
                optimization_params.update({
                    "enable_tensorrt": True,
                    "cuda_optimization": True
                })
            
            self.pose_optimization_params = optimization_params
            
            # í™œì„± ëª¨ë¸ë³„ íŠ¹í™” ì„¤ì •
            if self.active_model == 'pose_estimation_openpose':
                self.target_input_size = (368, 368)
                self.output_format = "keypoints_heatmap"
                self.num_keypoints = 18
            elif 'yolov8' in self.active_model:
                self.target_input_size = (640, 640)
                self.output_format = "keypoints_tensor"
                self.num_keypoints = 17  # COCO format
            else:
                self.target_input_size = (256, 256)
                self.output_format = "keypoints_simple"
                self.num_keypoints = 17
            
            self.logger.info(f"âœ… {self.active_model} ëª¨ë¸ ìµœì í™” ì„¤ì • ì™„ë£Œ")
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ ëª¨ë¸ ìµœì í™” ì„¤ì • ì‹¤íŒ¨: {e}")
    
    async def _warmup_models(self):
        """ëª¨ë¸ ì›Œë°ì—… (í•„ìˆ˜)"""
        try:
            if not self.active_model or self.active_model not in self.pose_models:
                self.logger.error("âŒ ì›Œë°ì—…í•  ëª¨ë¸ ì—†ìŒ")
                if self.strict_mode:
                    raise RuntimeError("Strict Mode: ì›Œë°ì—…í•  ëª¨ë¸ ì—†ìŒ")
                return
            
            # ë”ë¯¸ ì´ë¯¸ì§€ë¡œ ì›Œë°ì—…
            dummy_image = np.zeros((256, 256, 3), dtype=np.uint8)
            dummy_image_pil = Image.fromarray(dummy_image)
            
            self.logger.info(f"ğŸ”¥ {self.active_model} ëª¨ë¸ ì›Œë°ì—… ì‹œì‘")
            
            try:
                await self._process_with_ai_model(dummy_image_pil, warmup=True)
                self.logger.info(f"âœ… {self.active_model} ëª¨ë¸ ì›Œë°ì—… ì™„ë£Œ")
            except Exception as e:
                error_msg = f"ëª¨ë¸ ì›Œë°ì—… ì‹¤íŒ¨: {e}"
                self.logger.error(f"âŒ {error_msg}")
                if self.strict_mode:
                    raise RuntimeError(f"Strict Mode: {error_msg}")
                
        except Exception as e:
            self.logger.error(f"âŒ ëª¨ë¸ ì›Œë°ì—… ì‹¤íŒ¨: {e}")
            if self.strict_mode:
                raise
    
    async def process(
        self, 
        image: Union[np.ndarray, Image.Image, str],
        clothing_type: Optional[str] = None,
        **kwargs
    ) -> Dict[str, Any]:
        """
        ğŸ”¥ ì‹¤ì œ AI í¬ì¦ˆ ì¶”ì • ì²˜ë¦¬ - í´ë°± ì™„ì „ ì œê±°
        
        Args:
            image: ì…ë ¥ ì´ë¯¸ì§€
            clothing_type: ì˜ë¥˜ íƒ€ì… (ì„ íƒì )
            **kwargs: ì¶”ê°€ ì„¤ì •
            
        Returns:
            Dict[str, Any]: í¬ì¦ˆ ì¶”ì • ê²°ê³¼
        """
        try:
            # ì´ˆê¸°í™” ê²€ì¦
            if not self.is_initialized:
                if not await self.initialize():
                    error_msg = "ì´ˆê¸°í™” ì‹¤íŒ¨"
                    if self.strict_mode:
                        raise RuntimeError(f"Strict Mode: {error_msg}")
                    return self._create_error_result(error_msg)
            
            start_time = time.time()
            self.logger.info(f"ğŸ§  {self.step_name} ì‹¤ì œ AI ì²˜ë¦¬ ì‹œì‘")
            
            # ğŸ”¥ 1. ì´ë¯¸ì§€ ì „ì²˜ë¦¬
            processed_image = self._preprocess_image(image)
            if processed_image is None:
                error_msg = "ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì‹¤íŒ¨"
                if self.strict_mode:
                    raise ValueError(f"Strict Mode: {error_msg}")
                return self._create_error_result(error_msg)
            
            # ğŸ”¥ 2. ìºì‹œ í™•ì¸ (ì„ íƒì )
            cache_key = None
            if self.pose_config['cache_enabled']:
                cache_key = self._generate_cache_key(processed_image, clothing_type)
                if cache_key in self.prediction_cache:
                    self.logger.info("ğŸ“‹ ìºì‹œì—ì„œ ê²°ê³¼ ë°˜í™˜")
                    return self.prediction_cache[cache_key]
            
            # ğŸ”¥ 3. ì‹¤ì œ AI ëª¨ë¸ë¡œ í¬ì¦ˆ ì¶”ì •
            pose_result = await self._process_with_ai_model(processed_image, clothing_type, **kwargs)
            
            if not pose_result or not pose_result.get('success', False):
                error_msg = f"AI í¬ì¦ˆ ì¶”ì • ì‹¤íŒ¨: {pose_result.get('error', 'Unknown')}"
                self.logger.error(f"âŒ {error_msg}")
                if self.strict_mode:
                    raise RuntimeError(f"Strict Mode: {error_msg}")
                return self._create_error_result(error_msg)
            
            # ğŸ”¥ 4. ê²°ê³¼ í›„ì²˜ë¦¬
            final_result = self._postprocess_result(pose_result, processed_image, start_time)
            
            # ğŸ”¥ 5. ìºì‹œ ì €ì¥
            if self.pose_config['cache_enabled'] and cache_key:
                self._save_to_cache(cache_key, final_result)
            
            processing_time = time.time() - start_time
            self.logger.info(f"âœ… {self.step_name} ì‹¤ì œ AI ì²˜ë¦¬ ì™„ë£Œ ({processing_time:.2f}ì´ˆ)")
            self.logger.info(f"ğŸ¯ í‚¤í¬ì¸íŠ¸ ìˆ˜: {len(final_result.get('keypoints', []))}")
            self.logger.info(f"ğŸ–ï¸ ì‹ ë¢°ë„: {final_result.get('pose_analysis', {}).get('quality_score', 0):.2f}")
            
            return final_result
            
        except Exception as e:
            self.logger.error(f"âŒ {self.step_name} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            if self.strict_mode:
                raise  # strict_modeì—ì„œëŠ” Exception ì¬ë°œìƒ
            return self._create_error_result(str(e))
    
    async def _process_with_ai_model(
        self, 
        image: Image.Image, 
        clothing_type: Optional[str] = None,
        warmup: bool = False,
        **kwargs
    ) -> Dict[str, Any]:
        """ì‹¤ì œ AI ëª¨ë¸ì„ í†µí•œ í¬ì¦ˆ ì¶”ì • ì²˜ë¦¬"""
        try:
            if not self.active_model or self.active_model not in self.pose_models:
                error_msg = "í™œì„± AI ëª¨ë¸ ì—†ìŒ"
                self.logger.error(f"âŒ {error_msg}")
                if self.strict_mode:
                    raise RuntimeError(f"Strict Mode: {error_msg}")
                return {'success': False, 'error': error_msg}
            
            model = self.pose_models[self.active_model]
            
            self.logger.info(f"ğŸ§  {self.active_model} AI ëª¨ë¸ë¡œ ì¶”ë¡  ì‹œì‘")
            
            # ì´ë¯¸ì§€ë¥¼ ëª¨ë¸ ì…ë ¥ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
            model_input = self._prepare_model_input(image)
            
            if model_input is None:
                error_msg = "ëª¨ë¸ ì…ë ¥ ì¤€ë¹„ ì‹¤íŒ¨"
                if self.strict_mode:
                    raise ValueError(f"Strict Mode: {error_msg}")
                return {'success': False, 'error': error_msg}
            
            # ğŸ”¥ ì‹¤ì œ AI ëª¨ë¸ ì¶”ë¡  ì‹¤í–‰
            try:
                if hasattr(model, '__call__'):
                    # ì§ì ‘ í˜¸ì¶œ ê°€ëŠ¥í•œ ëª¨ë¸
                    model_output = await self._safe_model_call(model, model_input)
                elif hasattr(model, 'predict'):
                    # predict ë©”ì„œë“œê°€ ìˆëŠ” ëª¨ë¸
                    model_output = await self._safe_model_predict(model, model_input)
                elif hasattr(model, 'forward'):
                    # PyTorch ëª¨ë¸
                    model_output = await self._safe_model_forward(model, model_input)
                else:
                    error_msg = f"ëª¨ë¸ í˜¸ì¶œ ë°©ë²• ì—†ìŒ: {type(model)}"
                    if self.strict_mode:
                        raise ValueError(f"Strict Mode: {error_msg}")
                    return {'success': False, 'error': error_msg}
                
            except Exception as e:
                error_msg = f"ëª¨ë¸ ì¶”ë¡  ì‹¤íŒ¨: {e}"
                self.logger.error(f"âŒ {error_msg}")
                if self.strict_mode:
                    raise RuntimeError(f"Strict Mode: {error_msg}")
                return {'success': False, 'error': error_msg}
            
            # ì›Œë°ì—… ëª¨ë“œì¸ ê²½ìš° ê°„ë‹¨í•œ ê²°ê³¼ ë°˜í™˜
            if warmup:
                return {"success": True, "warmup": True}
            
            # ğŸ”¥ ëª¨ë¸ ì¶œë ¥ í•´ì„
            pose_result = self._interpret_model_output(model_output, image.size, self.active_model)
            
            if not pose_result.get('success', False):
                error_msg = "ëª¨ë¸ ì¶œë ¥ í•´ì„ ì‹¤íŒ¨"
                if self.strict_mode:
                    raise ValueError(f"Strict Mode: {error_msg}")
                return {'success': False, 'error': error_msg}
            
            self.logger.info(f"âœ… {self.active_model} AI ì¶”ë¡  ì„±ê³µ")
            return pose_result
            
        except Exception as e:
            self.logger.error(f"âŒ AI ëª¨ë¸ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            if self.strict_mode:
                raise
            return {'success': False, 'error': str(e)}
    
    def _prepare_model_input(self, image: Image.Image) -> Optional[Any]:
        """ëª¨ë¸ ì…ë ¥ ì¤€ë¹„"""
        try:
            # ì´ë¯¸ì§€ë¥¼ numpy ë°°ì—´ë¡œ ë³€í™˜
            image_np = np.array(image)
            
            # ëª¨ë¸ë³„ ì…ë ¥ í¬ê¸° ì¡°ì •
            if hasattr(self, 'target_input_size'):
                target_size = self.target_input_size
                image_resized = cv2.resize(image_np, target_size)
            else:
                image_resized = image_np
            
            # PyTorch ëª¨ë¸ì¸ ê²½ìš° í…ì„œë¡œ ë³€í™˜
            if TORCH_AVAILABLE and hasattr(self, 'active_model'):
                if 'openpose' in self.active_model or 'yolo' in self.active_model:
                    # ì •ê·œí™” ë° í…ì„œ ë³€í™˜
                    image_tensor = torch.from_numpy(image_resized).float()
                    if len(image_tensor.shape) == 3:
                        image_tensor = image_tensor.permute(2, 0, 1).unsqueeze(0)  # BHWC -> BCHW
                    image_tensor = image_tensor / 255.0  # ì •ê·œí™”
                    image_tensor = image_tensor.to(self.device)
                    return image_tensor
            
            return image_resized
            
        except Exception as e:
            self.logger.error(f"âŒ ëª¨ë¸ ì…ë ¥ ì¤€ë¹„ ì‹¤íŒ¨: {e}")
            return None
    
    async def _safe_model_call(self, model: Any, input_data: Any) -> Any:
        """ì•ˆì „í•œ ëª¨ë¸ í˜¸ì¶œ"""
        try:
            if asyncio.iscoroutinefunction(model.__call__):
                return await model(input_data)
            else:
                return model(input_data)
        except Exception as e:
            self.logger.error(f"âŒ ëª¨ë¸ __call__ ì‹¤íŒ¨: {e}")
            raise
    
    async def _safe_model_predict(self, model: Any, input_data: Any) -> Any:
        """ì•ˆì „í•œ ëª¨ë¸ predict í˜¸ì¶œ"""
        try:
            if asyncio.iscoroutinefunction(model.predict):
                return await model.predict(input_data)
            else:
                return model.predict(input_data)
        except Exception as e:
            self.logger.error(f"âŒ ëª¨ë¸ predict ì‹¤íŒ¨: {e}")
            raise
    
    async def _safe_model_forward(self, model: Any, input_data: Any) -> Any:
        """ì•ˆì „í•œ ëª¨ë¸ forward í˜¸ì¶œ"""
        try:
            with torch.no_grad():
                if asyncio.iscoroutinefunction(model.forward):
                    return await model.forward(input_data)
                else:
                    return model.forward(input_data)
        except Exception as e:
            self.logger.error(f"âŒ ëª¨ë¸ forward ì‹¤íŒ¨: {e}")
            raise
    
    def _interpret_model_output(self, model_output: Any, image_size: Tuple[int, int], model_name: str) -> Dict[str, Any]:
        """ëª¨ë¸ ì¶œë ¥ í•´ì„"""
        try:
            if 'openpose' in model_name:
                return self._interpret_openpose_output(model_output, image_size)
            elif 'yolo' in model_name:
                return self._interpret_yolo_output(model_output, image_size)
            else:
                return self._interpret_generic_output(model_output, image_size)
                
        except Exception as e:
            self.logger.error(f"âŒ ëª¨ë¸ ì¶œë ¥ í•´ì„ ì‹¤íŒ¨: {e}")
            return {'success': False, 'error': str(e)}
    
    def _interpret_openpose_output(self, output: Any, image_size: Tuple[int, int]) -> Dict[str, Any]:
        """OpenPose ì¶œë ¥ í•´ì„"""
        try:
            keypoints = []
            confidence_scores = []
            
            if TORCH_AVAILABLE and torch.is_tensor(output):
                output_np = output.cpu().numpy()
                
                # íˆíŠ¸ë§µì—ì„œ í‚¤í¬ì¸íŠ¸ ì¶”ì¶œ
                if len(output_np.shape) == 4:  # [B, C, H, W]
                    output_np = output_np[0]  # ì²« ë²ˆì§¸ ë°°ì¹˜
                
                for i in range(min(output_np.shape[0], 18)):  # 18ê°œ í‚¤í¬ì¸íŠ¸ë§Œ
                    heatmap = output_np[i]
                    y, x = np.unravel_index(np.argmax(heatmap), heatmap.shape)
                    confidence = float(heatmap[y, x])
                    
                    # ì´ë¯¸ì§€ í¬ê¸°ë¡œ ìŠ¤ì¼€ì¼ë§
                    x_scaled = x * image_size[0] / heatmap.shape[1]
                    y_scaled = y * image_size[1] / heatmap.shape[0]
                    
                    keypoints.append([float(x_scaled), float(y_scaled), confidence])
                    confidence_scores.append(confidence)
            
            return {
                'keypoints': keypoints,
                'confidence_scores': confidence_scores,
                'model_used': 'openpose_ai',
                'success': len(keypoints) > 0
            }
            
        except Exception as e:
            self.logger.error(f"âŒ OpenPose ì¶œë ¥ í•´ì„ ì‹¤íŒ¨: {e}")
            return {'success': False, 'error': str(e)}
    
    def _interpret_yolo_output(self, results: Any, image_size: Tuple[int, int]) -> Dict[str, Any]:
        """YOLOv8 í¬ì¦ˆ ì¶œë ¥ í•´ì„"""
        try:
            keypoints = []
            confidence_scores = []
            
            if hasattr(results, 'keypoints') and results.keypoints is not None:
                for result in results:
                    if hasattr(result, 'keypoints') and result.keypoints is not None:
                        kps = result.keypoints.data[0]  # ì²« ë²ˆì§¸ ì‚¬ëŒ
                        for kp in kps:
                            x, y, conf = float(kp[0]), float(kp[1]), float(kp[2])
                            keypoints.append([x, y, conf])
                            confidence_scores.append(conf)
                        break
            
            # COCO 17ì„ OpenPose 18ë¡œ ë³€í™˜
            if len(keypoints) == 17:
                keypoints = self._convert_coco_to_openpose(keypoints, image_size)
                confidence_scores = [kp[2] for kp in keypoints]
            
            return {
                'keypoints': keypoints,
                'confidence_scores': confidence_scores,
                'model_used': 'yolov8_ai',
                'success': len(keypoints) > 0
            }
            
        except Exception as e:
            self.logger.error(f"âŒ YOLOv8 ì¶œë ¥ í•´ì„ ì‹¤íŒ¨: {e}")
            return {'success': False, 'error': str(e)}
    
    def _interpret_generic_output(self, output: Any, image_size: Tuple[int, int]) -> Dict[str, Any]:
        """ì¼ë°˜ì ì¸ ëª¨ë¸ ì¶œë ¥ í•´ì„"""
        try:
            keypoints = []
            confidence_scores = []
            
            # ë‹¤ì–‘í•œ ì¶œë ¥ í˜•ì‹ì— ëŒ€ì‘
            if isinstance(output, (list, tuple)):
                # ë¦¬ìŠ¤íŠ¸/íŠœí”Œ í˜•íƒœì˜ í‚¤í¬ì¸íŠ¸
                for item in output:
                    if len(item) >= 3:
                        keypoints.append([float(item[0]), float(item[1]), float(item[2])])
                        confidence_scores.append(float(item[2]))
            elif isinstance(output, np.ndarray):
                # NumPy ë°°ì—´
                if len(output.shape) == 2 and output.shape[1] >= 3:
                    for i in range(min(output.shape[0], 18)):
                        keypoints.append([float(output[i, 0]), float(output[i, 1]), float(output[i, 2])])
                        confidence_scores.append(float(output[i, 2]))
            elif TORCH_AVAILABLE and torch.is_tensor(output):
                # PyTorch í…ì„œ
                output_np = output.cpu().numpy()
                return self._interpret_generic_output(output_np, image_size)
            
            return {
                'keypoints': keypoints,
                'confidence_scores': confidence_scores,
                'model_used': 'generic_ai',
                'success': len(keypoints) > 0
            }
            
        except Exception as e:
            self.logger.error(f"âŒ ì¼ë°˜ ì¶œë ¥ í•´ì„ ì‹¤íŒ¨: {e}")
            return {'success': False, 'error': str(e)}
    
    def _convert_coco_to_openpose(self, coco_keypoints: List[List[float]], image_size: Tuple[int, int]) -> List[List[float]]:
        """COCO 17ì„ OpenPose 18ë¡œ ë³€í™˜"""
        try:
            # COCO 17 -> OpenPose 18 ë§¤í•‘
            coco_to_op_mapping = {
                0: 0,   # nose
                1: 16,  # left_eye -> left_eye
                2: 15,  # right_eye -> right_eye
                3: 18,  # left_ear -> left_ear
                4: 17,  # right_ear -> right_ear
                5: 5,   # left_shoulder -> left_shoulder
                6: 2,   # right_shoulder -> right_shoulder
                7: 6,   # left_elbow -> left_elbow
                8: 3,   # right_elbow -> right_elbow
                9: 7,   # left_wrist -> left_wrist
                10: 4,  # right_wrist -> right_wrist
                11: 12, # left_hip -> left_hip
                12: 9,  # right_hip -> right_hip
                13: 13, # left_knee -> left_knee
                14: 10, # right_knee -> right_knee
                15: 14, # left_ankle -> left_ankle
                16: 11  # right_ankle -> right_ankle
            }
            
            # OpenPose 18 í‚¤í¬ì¸íŠ¸ ì´ˆê¸°í™”
            openpose_18 = [[0.0, 0.0, 0.0] for _ in range(18)]
            
            # COCOì—ì„œ OpenPoseë¡œ ë³€í™˜
            for coco_idx, op_idx in coco_to_op_mapping.items():
                if coco_idx < len(coco_keypoints) and op_idx < 18:
                    openpose_18[op_idx] = coco_keypoints[coco_idx]
            
            # neck í‚¤í¬ì¸íŠ¸ ì¶”ì •
            left_shoulder = openpose_18[5]
            right_shoulder = openpose_18[2]
            if left_shoulder[2] > 0.3 and right_shoulder[2] > 0.3:
                neck_x = (left_shoulder[0] + right_shoulder[0]) / 2
                neck_y = (left_shoulder[1] + right_shoulder[1]) / 2
                neck_conf = min(left_shoulder[2], right_shoulder[2])
                openpose_18[1] = [neck_x, neck_y, neck_conf]
            
            # mid_hip í‚¤í¬ì¸íŠ¸ ì¶”ì •
            left_hip = openpose_18[12]
            right_hip = openpose_18[9]
            if left_hip[2] > 0.3 and right_hip[2] > 0.3:
                mid_hip_x = (left_hip[0] + right_hip[0]) / 2
                mid_hip_y = (left_hip[1] + right_hip[1]) / 2
                mid_hip_conf = min(left_hip[2], right_hip[2])
                openpose_18[8] = [mid_hip_x, mid_hip_y, mid_hip_conf]
            
            return openpose_18
            
        except Exception as e:
            self.logger.error(f"âŒ COCO to OpenPose ë³€í™˜ ì‹¤íŒ¨: {e}")
            return [[0.0, 0.0, 0.0] for _ in range(18)]
    
    def _preprocess_image(self, image: Union[np.ndarray, Image.Image, str]) -> Optional[Image.Image]:
        """ì´ë¯¸ì§€ ì „ì²˜ë¦¬"""
        try:
            if isinstance(image, str):
                # íŒŒì¼ ê²½ë¡œì¸ ê²½ìš°
                if os.path.exists(image):
                    image = Image.open(image)
                else:
                    # Base64 ì¸ì½”ë”©ëœ ì´ë¯¸ì§€ì¸ ê²½ìš°
                    image_data = base64.b64decode(image)
                    image = Image.open(io.BytesIO(image_data))
            elif isinstance(image, np.ndarray):
                image = Image.fromarray(image)
            elif not isinstance(image, Image.Image):
                raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì´ë¯¸ì§€ íƒ€ì…: {type(image)}")
            
            # RGB ë³€í™˜
            if image.mode != 'RGB':
                image = image.convert('RGB')
            
            # í¬ê¸° ì¡°ì • (ì„±ëŠ¥ ìµœì í™”)
            max_size = 1024 if self.is_m3_max else 512
            if max(image.size) > max_size:
                ratio = max_size / max(image.size)
                new_size = (int(image.size[0] * ratio), int(image.size[1] * ratio))
                image = image.resize(new_size, Image.Resampling.LANCZOS)
            
            return image
            
        except Exception as e:
            self.logger.error(f"âŒ ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return None
    
    def _generate_cache_key(self, image: Image.Image, clothing_type: Optional[str]) -> str:
        """ìºì‹œ í‚¤ ìƒì„±"""
        try:
            # ì´ë¯¸ì§€ í•´ì‹œ
            image_bytes = io.BytesIO()
            image.save(image_bytes, format='JPEG', quality=50)
            image_hash = hashlib.md5(image_bytes.getvalue()).hexdigest()[:16]
            
            # ì„¤ì • í•´ì‹œ
            config_str = f"{clothing_type}_{self.active_model}_{self.pose_config['confidence_threshold']}"
            config_hash = hashlib.md5(config_str.encode()).hexdigest()[:8]
            
            return f"pose_{image_hash}_{config_hash}"
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ ìºì‹œ í‚¤ ìƒì„± ì‹¤íŒ¨: {e}")
            return f"pose_{int(time.time())}"
    
    def _postprocess_result(self, pose_result: Dict[str, Any], image: Image.Image, start_time: float) -> Dict[str, Any]:
        """ê²°ê³¼ í›„ì²˜ë¦¬"""
        try:
            processing_time = time.time() - start_time
            
            # PoseMetrics ìƒì„±
            pose_metrics = PoseMetrics(
                keypoints=pose_result.get('keypoints', []),
                confidence_scores=pose_result.get('confidence_scores', []),
                model_used=pose_result.get('model_used', 'unknown'),
                processing_time=processing_time,
                image_resolution=image.size
            )
            
            # í¬ì¦ˆ ë¶„ì„
            pose_analysis = self._analyze_pose_quality(pose_metrics)
            
            # ì‹œê°í™” ìƒì„±
            visualization = None
            if self.pose_config['visualization_enabled']:
                visualization = self._create_pose_visualization(image, pose_metrics)
            
            # ìµœì¢… ê²°ê³¼ êµ¬ì„±
            result = {
                'success': pose_result.get('success', False),
                'keypoints': pose_metrics.keypoints,
                'confidence_scores': pose_metrics.confidence_scores,
                'pose_analysis': pose_analysis,
                'visualization': visualization,
                'processing_time': processing_time,
                'model_used': pose_metrics.model_used,
                'image_resolution': pose_metrics.image_resolution,
                'step_info': {
                    'step_name': self.step_name,
                    'step_number': self.step_number,
                    'optimization_level': self.optimization_level,
                    'strict_mode': self.strict_mode,
                    'ai_model_name': self.active_model
                }
            }
            
            return result
            
        except Exception as e:
            self.logger.error(f"âŒ ê²°ê³¼ í›„ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            if self.strict_mode:
                raise
            return self._create_error_result(str(e))
    
    def _analyze_pose_quality(self, pose_metrics: PoseMetrics) -> Dict[str, Any]:
        """í¬ì¦ˆ í’ˆì§ˆ ë¶„ì„"""
        try:
            if not pose_metrics.keypoints:
                return {
                    'suitable_for_fitting': False,
                    'issues': ['ì‹¤ì œ AI ëª¨ë¸ì—ì„œ í¬ì¦ˆë¥¼ ê²€ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤'],
                    'recommendations': ['ë” ì„ ëª…í•œ ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í•˜ê±°ë‚˜ í¬ì¦ˆë¥¼ ëª…í™•íˆ í•´ì£¼ì„¸ìš”'],
                    'quality_score': 0.0,
                    'ai_confidence': 0.0
                }
            
            # ì‹ ì²´ ë¶€ìœ„ë³„ ì ìˆ˜ ê³„ì‚°
            head_score = self._calculate_head_score(pose_metrics.keypoints)
            torso_score = self._calculate_torso_score(pose_metrics.keypoints)
            arms_score = self._calculate_arms_score(pose_metrics.keypoints)
            legs_score = self._calculate_legs_score(pose_metrics.keypoints)
            
            # AI ì‹ ë¢°ë„ ê³„ì‚°
            ai_confidence = np.mean(pose_metrics.confidence_scores) if pose_metrics.confidence_scores else 0.0
            
            # ì „ì²´ ì ìˆ˜ (AI ì‹ ë¢°ë„ ë°˜ì˜)
            overall_score = (head_score * 0.2 + torso_score * 0.3 + 
                           arms_score * 0.25 + legs_score * 0.25) * ai_confidence
            
            # ì í•©ì„± íŒë‹¨ (ë” ì—„ê²©í•œ ê¸°ì¤€)
            suitable_for_fitting = overall_score >= 0.7 and ai_confidence >= 0.6
            
            # ì´ìŠˆ ë° ê¶Œì¥ì‚¬í•­
            issues = []
            recommendations = []
            
            if ai_confidence < 0.6:
                issues.append('AI ëª¨ë¸ì˜ ì‹ ë¢°ë„ê°€ ë‚®ìŠµë‹ˆë‹¤')
                recommendations.append('ì¡°ëª…ì´ ì¢‹ì€ í™˜ê²½ì—ì„œ ë‹¤ì‹œ ì´¬ì˜í•´ ì£¼ì„¸ìš”')
            
            if head_score < 0.5:
                issues.append('ì–¼êµ´ ì˜ì—­ ê²€ì¶œì´ ë¶ˆë¶„ëª…í•©ë‹ˆë‹¤')
                recommendations.append('ì–¼êµ´ì´ ì •ë©´ì„ í–¥í•˜ë„ë¡ ì´¬ì˜í•´ ì£¼ì„¸ìš”')
            
            if torso_score < 0.5:
                issues.append('ìƒì²´ ì˜ì—­ì´ ë¶ˆë¶„ëª…í•©ë‹ˆë‹¤')
                recommendations.append('ìƒì²´ ì „ì²´ê°€ ë³´ì´ë„ë¡ ì´¬ì˜í•´ ì£¼ì„¸ìš”')
            
            if arms_score < 0.5:
                issues.append('íŒ”ì˜ ìœ„ì¹˜ê°€ ë¶€ì ì ˆí•©ë‹ˆë‹¤')
                recommendations.append('íŒ”ì„ ë²Œë¦¬ê±°ë‚˜ ìì—°ìŠ¤ëŸ½ê²Œ ë‚´ë ¤ì£¼ì„¸ìš”')
            
            if legs_score < 0.5:
                issues.append('ë‹¤ë¦¬ê°€ ê°€ë ¤ì ¸ ìˆìŠµë‹ˆë‹¤')
                recommendations.append('ì „ì‹ ì´ ë³´ì´ë„ë¡ ì´¬ì˜í•´ ì£¼ì„¸ìš”')
            
            return {
                'suitable_for_fitting': suitable_for_fitting,
                'issues': issues,
                'recommendations': recommendations,
                'quality_score': overall_score,
                'ai_confidence': ai_confidence,
                'detailed_scores': {
                    'head': head_score,
                    'torso': torso_score,
                    'arms': arms_score,
                    'legs': legs_score
                },
                'model_performance': {
                    'model_name': pose_metrics.model_used,
                    'keypoints_detected': len([kp for kp in pose_metrics.keypoints if len(kp) > 2 and kp[2] > self.pose_config['confidence_threshold']]),
                    'avg_confidence': ai_confidence,
                    'processing_time': pose_metrics.processing_time
                }
            }
            
        except Exception as e:
            self.logger.error(f"âŒ í¬ì¦ˆ í’ˆì§ˆ ë¶„ì„ ì‹¤íŒ¨: {e}")
            if self.strict_mode:
                raise
            return {
                'suitable_for_fitting': False,
                'issues': ['ë¶„ì„ ì‹¤íŒ¨'],
                'recommendations': ['ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”'],
                'quality_score': 0.0,
                'ai_confidence': 0.0
            }
    
    def _calculate_head_score(self, keypoints: List[List[float]]) -> float:
        """ë¨¸ë¦¬ ë¶€ìœ„ ì ìˆ˜ ê³„ì‚°"""
        try:
            if len(keypoints) < 19:
                return 0.0
            
            head_points = keypoints[:5]  # nose, eyes, ears
            visible_count = sum(1 for kp in head_points if len(kp) > 2 and kp[2] > self.pose_config['confidence_threshold'])
            
            return min(visible_count / 3.0, 1.0)
            
        except Exception:
            return 0.0
    
    def _calculate_torso_score(self, keypoints: List[List[float]]) -> float:
        """ìƒì²´ ì ìˆ˜ ê³„ì‚°"""
        try:
            if len(keypoints) < 19:
                return 0.0
            
            torso_points = keypoints[1:3] + keypoints[5:9]  # neck, shoulders, hips
            visible_count = sum(1 for kp in torso_points if len(kp) > 2 and kp[2] > self.pose_config['confidence_threshold'])
            
            return min(visible_count / 6.0, 1.0)
            
        except Exception:
            return 0.0
    
    def _calculate_arms_score(self, keypoints: List[List[float]]) -> float:
        """íŒ” ì ìˆ˜ ê³„ì‚°"""
        try:
            if len(keypoints) < 19:
                return 0.0
            
            arm_points = keypoints[2:5] + keypoints[5:8]  # shoulders, elbows, wrists
            visible_count = sum(1 for kp in arm_points if len(kp) > 2 and kp[2] > self.pose_config['confidence_threshold'])
            
            return min(visible_count / 6.0, 1.0)
            
        except Exception:
            return 0.0
    
    def _calculate_legs_score(self, keypoints: List[List[float]]) -> float:
        """ë‹¤ë¦¬ ì ìˆ˜ ê³„ì‚°"""
        try:
            if len(keypoints) < 19:
                return 0.0
            
            leg_points = keypoints[9:15]  # hips, knees, ankles
            visible_count = sum(1 for kp in leg_points if len(kp) > 2 and kp[2] > self.pose_config['confidence_threshold'])
            
            return min(visible_count / 6.0, 1.0)
            
        except Exception:
            return 0.0
    
    def _create_pose_visualization(self, image: Image.Image, pose_metrics: PoseMetrics) -> Optional[str]:
        """í¬ì¦ˆ ì‹œê°í™” ìƒì„±"""
        try:
            if not pose_metrics.keypoints:
                return None
            
            # ì´ë¯¸ì§€ ë³µì‚¬
            vis_image = image.copy()
            draw = ImageDraw.Draw(vis_image)
            
            # ì‹ ë¢°ë„ ê¸°ì¤€ìœ¼ë¡œ í‚¤í¬ì¸íŠ¸ ê·¸ë¦¬ê¸°
            confidence_threshold = self.pose_config['confidence_threshold']
            
            for i, kp in enumerate(pose_metrics.keypoints):
                if len(kp) >= 3 and kp[2] > confidence_threshold:
                    x, y = int(kp[0]), int(kp[1])
                    color = KEYPOINT_COLORS[i % len(KEYPOINT_COLORS)]
                    
                    # ì‹ ë¢°ë„ì— ë”°ë¥¸ í¬ê¸° ì¡°ì •
                    radius = int(4 + kp[2] * 4)  # 4-8 í”½ì…€
                    draw.ellipse([x-radius, y-radius, x+radius, y+radius], 
                               fill=color, outline=(255, 255, 255), width=2)
                    
                    # í‚¤í¬ì¸íŠ¸ ë²ˆí˜¸ í‘œì‹œ (ì„ íƒì )
                    if self.pose_config.get('show_keypoint_numbers', False):
                        draw.text((x+radius+2, y-radius-2), str(i), fill=(255, 255, 255))
            
            # ìŠ¤ì¼ˆë ˆí†¤ ì—°ê²°ì„  ê·¸ë¦¬ê¸°
            valid_connections = []
            for i, (start_idx, end_idx) in enumerate(SKELETON_CONNECTIONS):
                if (start_idx < len(pose_metrics.keypoints) and 
                    end_idx < len(pose_metrics.keypoints)):
                    
                    start_kp = pose_metrics.keypoints[start_idx]
                    end_kp = pose_metrics.keypoints[end_idx]
                    
                    if (len(start_kp) >= 3 and len(end_kp) >= 3 and
                        start_kp[2] > confidence_threshold and end_kp[2] > confidence_threshold):
                        
                        start_point = (int(start_kp[0]), int(start_kp[1]))
                        end_point = (int(end_kp[0]), int(end_kp[1]))
                        color = SKELETON_COLORS[i % len(SKELETON_COLORS)]
                        
                        # ì‹ ë¢°ë„ì— ë”°ë¥¸ ì„  ë‘ê»˜ ì¡°ì •
                        avg_confidence = (start_kp[2] + end_kp[2]) / 2
                        line_width = int(2 + avg_confidence * 3)  # 2-5 í”½ì…€
                        
                        draw.line([start_point, end_point], fill=color, width=line_width)
                        valid_connections.append((start_idx, end_idx))
            
            # ì •ë³´ ì˜¤ë²„ë ˆì´ ì¶”ê°€
            if self.pose_config.get('show_info_overlay', True):
                self._add_info_overlay(draw, pose_metrics, valid_connections)
            
            # Base64ë¡œ ì¸ì½”ë”©
            buffer = io.BytesIO()
            vis_image.save(buffer, format='JPEG', quality=90)
            image_base64 = base64.b64encode(buffer.getvalue()).decode('utf-8')
            
            return f"data:image/jpeg;base64,{image_base64}"
            
        except Exception as e:
            self.logger.error(f"âŒ í¬ì¦ˆ ì‹œê°í™” ìƒì„± ì‹¤íŒ¨: {e}")
            return None
    
    def _add_info_overlay(self, draw: ImageDraw.Draw, pose_metrics: PoseMetrics, valid_connections: List[Tuple[int, int]]):
        """ì •ë³´ ì˜¤ë²„ë ˆì´ ì¶”ê°€"""
        try:
            # í°íŠ¸ ì„¤ì • (ê¸°ë³¸ í°íŠ¸ ì‚¬ìš©)
            try:
                font = ImageFont.load_default()
            except:
                font = None
            
            # í†µê³„ ì •ë³´
            detected_keypoints = len([kp for kp in pose_metrics.keypoints if len(kp) > 2 and kp[2] > self.pose_config['confidence_threshold']])
            avg_confidence = np.mean([kp[2] for kp in pose_metrics.keypoints if len(kp) > 2]) if pose_metrics.keypoints else 0.0
            
            # í…ìŠ¤íŠ¸ ì •ë³´
            info_lines = [
                f"Model: {pose_metrics.model_used}",
                f"Keypoints: {detected_keypoints}/18",
                f"Confidence: {avg_confidence:.2f}",
                f"Connections: {len(valid_connections)}",
                f"Time: {pose_metrics.processing_time:.2f}s"
            ]
            
            # ë°°ê²½ ì˜ì—­
            y_offset = 10
            for i, line in enumerate(info_lines):
                text_y = y_offset + i * 20
                draw.rectangle([5, text_y-2, 200, text_y+18], fill=(0, 0, 0, 128))
                draw.text((10, text_y), line, fill=(255, 255, 255), font=font)
                
        except Exception as e:
            self.logger.debug(f"ì •ë³´ ì˜¤ë²„ë ˆì´ ì¶”ê°€ ì‹¤íŒ¨: {e}")
    
    def _save_to_cache(self, cache_key: str, result: Dict[str, Any]):
        """ìºì‹œì— ê²°ê³¼ ì €ì¥"""
        try:
            if len(self.prediction_cache) >= self.cache_max_size:
                # ì˜¤ë˜ëœ í•­ëª© ì œê±° (FIFO)
                oldest_key = next(iter(self.prediction_cache))
                del self.prediction_cache[oldest_key]
            
            # ì‹œê°í™”ëŠ” ìºì‹œì—ì„œ ì œì™¸ (ë©”ëª¨ë¦¬ ì ˆì•½)
            cached_result = result.copy()
            cached_result['visualization'] = None
            
            self.prediction_cache[cache_key] = cached_result
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ ìºì‹œ ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def _create_error_result(self, error_message: str, processing_time: float = 0.0) -> Dict[str, Any]:
        """ì—ëŸ¬ ê²°ê³¼ ìƒì„±"""
        return {
            'success': False,
            'error': error_message,
            'keypoints': [],
            'confidence_scores': [],
            'pose_analysis': {
                'suitable_for_fitting': False,
                'issues': [error_message],
                'recommendations': ['AI ëª¨ë¸ ìƒíƒœë¥¼ í™•ì¸í•˜ê±°ë‚˜ ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”'],
                'quality_score': 0.0,
                'ai_confidence': 0.0
            },
            'visualization': None,
            'processing_time': processing_time,
            'model_used': 'error',
            'step_info': {
                'step_name': self.step_name,
                'step_number': self.step_number,
                'optimization_level': getattr(self, 'optimization_level', 'unknown'),
                'strict_mode': self.strict_mode,
                'ai_model_name': getattr(self, 'active_model', 'none')
            }
        }
    
    # =================================================================
    # ğŸ”§ ìœ í‹¸ë¦¬í‹° ë©”ì„œë“œë“¤
    # =================================================================
    
    def _calculate_pose_angles(self, keypoints_18: List[List[float]]) -> Dict[str, float]:
        """í¬ì¦ˆ ê°ë„ ê³„ì‚° (ê´€ì ˆ ê°ë„)"""
        try:
            angles = {}
            confidence_threshold = self.pose_config['confidence_threshold']
            
            def calculate_angle(p1, p2, p3):
                """ì„¸ ì ìœ¼ë¡œ ê°ë„ ê³„ì‚°"""
                try:
                    if all(len(p) >= 3 and p[2] > confidence_threshold for p in [p1, p2, p3]):
                        v1 = np.array([p1[0] - p2[0], p1[1] - p2[1]])
                        v2 = np.array([p3[0] - p2[0], p3[1] - p2[1]])
                        
                        cos_angle = np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))
                        cos_angle = np.clip(cos_angle, -1.0, 1.0)
                        return float(np.degrees(np.arccos(cos_angle)))
                    return 0.0
                except Exception:
                    return 0.0
            
            if len(keypoints_18) >= 18:
                # íŒ” ê°ë„
                angles['right_elbow'] = calculate_angle(keypoints_18[2], keypoints_18[3], keypoints_18[4])
                angles['left_elbow'] = calculate_angle(keypoints_18[5], keypoints_18[6], keypoints_18[7])
                
                # ë‹¤ë¦¬ ê°ë„
                angles['right_knee'] = calculate_angle(keypoints_18[9], keypoints_18[10], keypoints_18[11])
                angles['left_knee'] = calculate_angle(keypoints_18[12], keypoints_18[13], keypoints_18[14])
                
                # ì–´ê¹¨ ê°ë„
                angles['right_shoulder'] = calculate_angle(keypoints_18[1], keypoints_18[2], keypoints_18[3])
                angles['left_shoulder'] = calculate_angle(keypoints_18[1], keypoints_18[5], keypoints_18[6])
            
            return angles
            
        except Exception as e:
            self.logger.debug(f"í¬ì¦ˆ ê°ë„ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return {}
    
    def _calculate_body_proportions(self, keypoints_18: List[List[float]]) -> Dict[str, float]:
        """ì‹ ì²´ ë¹„ìœ¨ ê³„ì‚°"""
        try:
            proportions = {}
            confidence_threshold = self.pose_config['confidence_threshold']
            
            if len(keypoints_18) >= 18:
                def distance(p1, p2):
                    """ë‘ ì  ê°„ ê±°ë¦¬"""
                    if (len(p1) >= 3 and len(p2) >= 3 and 
                        p1[2] > confidence_threshold and p2[2] > confidence_threshold):
                        return float(np.sqrt((p1[0] - p2[0])**2 + (p1[1] - p2[1])**2))
                    return 0.0
                
                # ì£¼ìš” ê±°ë¦¬ ì¸¡ì •
                head_neck = distance(keypoints_18[0], keypoints_18[1])
                neck_hip = distance(keypoints_18[1], keypoints_18[8])
                hip_knee = distance(keypoints_18[9], keypoints_18[10])
                knee_ankle = distance(keypoints_18[10], keypoints_18[11])
                shoulder_width = distance(keypoints_18[2], keypoints_18[5])
                hip_width = distance(keypoints_18[9], keypoints_18[12])
                
                # ë¹„ìœ¨ ê³„ì‚°
                total_height = head_neck + neck_hip + hip_knee + knee_ankle
                if total_height > 0:
                    proportions['head_to_total'] = head_neck / total_height
                    proportions['torso_to_total'] = neck_hip / total_height
                    proportions['upper_leg_to_total'] = hip_knee / total_height
                    proportions['lower_leg_to_total'] = knee_ankle / total_height
                    proportions['shoulder_to_hip_ratio'] = shoulder_width / hip_width if hip_width > 0 else 0.0
                
                # í˜„ì‹¤ì„± ê²€ì¦
                proportions['is_realistic'] = (
                    0.1 <= proportions.get('head_to_total', 0) <= 0.25 and
                    0.25 <= proportions.get('torso_to_total', 0) <= 0.45 and
                    0.8 <= proportions.get('shoulder_to_hip_ratio', 0) <= 1.5
                )
            
            return proportions
            
        except Exception as e:
            self.logger.debug(f"ì‹ ì²´ ë¹„ìœ¨ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return {}
    
    def clear_cache(self):
        """ìºì‹œ ì •ë¦¬"""
        try:
            self.prediction_cache.clear()
            self.logger.info("ğŸ“‹ ìºì‹œ ì •ë¦¬ ì™„ë£Œ")
        except Exception as e:
            self.logger.warning(f"âš ï¸ ìºì‹œ ì •ë¦¬ ì‹¤íŒ¨: {e}")
    
    def get_cache_status(self) -> Dict[str, Any]:
        """ìºì‹œ ìƒíƒœ ë°˜í™˜"""
        return {
            'cache_size': len(self.prediction_cache),
            'cache_max_size': self.cache_max_size,
            'cache_enabled': self.pose_config['cache_enabled']
        }
    
    def get_step_info(self) -> Dict[str, Any]:
        """Step ì •ë³´ ë°˜í™˜ (step_model_requests.py ì™„ë²½ í˜¸í™˜)"""
        
        # ê¸°ë³¸ Step ì •ë³´
        base_info = {
            "step_name": self.step_name,
            "step_number": self.step_number,
            "step_description": self.step_description,
            "is_initialized": self.is_initialized,
            "device": self.device,
            "optimization_level": getattr(self, 'optimization_level', 'unknown'),
            "strict_mode": self.strict_mode
        }
        
        # ëª¨ë¸ ìƒíƒœ ì •ë³´
        model_status = {
            "loaded_models": list(getattr(self, 'pose_models', {}).keys()),
            "active_model": getattr(self, 'active_model', None),
            "model_priority": self.pose_config['model_priority'],
            "model_interface_connected": hasattr(self, 'model_interface') and self.model_interface is not None,
            "real_ai_models_only": True  # ì‹¤ì œ AI ì „ìš©
        }
        
        # ì²˜ë¦¬ ì„¤ì • ì •ë³´
        processing_settings = {
            "confidence_threshold": self.pose_config['confidence_threshold'],
            "optimization_level": getattr(self, 'optimization_level', 'unknown'),
            "batch_processing": getattr(self, 'batch_processing', False),
            "cache_enabled": self.pose_config['cache_enabled'],
            "cache_status": self.get_cache_status(),
            "strict_mode_enabled": self.strict_mode
        }
        
        # step_model_requests.py í˜¸í™˜ ì •ë³´
        step_requirements = self._get_step_model_requirements()
        
        compliance_info = {
            "step_model_requests_compliance": True,
            "required_model_name": step_requirements["model_name"],
            "step_priority": step_requirements["step_priority"],
            "target_input_size": getattr(self, 'target_input_size', step_requirements["input_size"]),
            "optimization_params": getattr(self, 'pose_optimization_params', {}),
            "checkpoint_patterns": step_requirements["checkpoint_patterns"],
            "alternative_models": step_requirements["alternative_models"],
            "strict_mode_compatible": step_requirements["metadata"]["strict_mode_compatible"]
        }
        
        # ì„±ëŠ¥ ë° ë©”íƒ€ë°ì´í„°
        performance_info = {
            "memory_gb": self.memory_gb,
            "is_m3_max": self.is_m3_max,
            "use_neural_engine": getattr(self, 'use_neural_engine', False),
            "supported_clothing_types": list(self.CLOTHING_POSE_WEIGHTS.keys()),
            "keypoints_format": getattr(self, 'num_keypoints', 18),
            "visualization_enabled": self.pose_config['visualization_enabled'],
            "fallback_disabled": True,  # í´ë°± ì™„ì „ ì œê±°
            "ai_only_mode": True
        }
        
        return {
            **base_info,
            "model_status": model_status,
            "processing_settings": processing_settings,
            "step_requirements_compliance": compliance_info,
            "performance_info": performance_info,
            "metadata": step_requirements["metadata"]
        }
    
    def cleanup_resources(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        try:
            # í¬ì¦ˆ ëª¨ë¸ ì •ë¦¬
            if hasattr(self, 'pose_models'):
                for model_name, model in self.pose_models.items():
                    try:
                        if hasattr(model, 'cleanup'):
                            model.cleanup()
                        elif hasattr(model, 'close'):
                            model.close()
                    except Exception as e:
                        self.logger.debug(f"ëª¨ë¸ ì •ë¦¬ ì‹¤íŒ¨ {model_name}: {e}")
                    del model
                self.pose_models.clear()
            
            # ìºì‹œ ì •ë¦¬
            self.clear_cache()
            
            # ModelLoader ì¸í„°í˜ì´ìŠ¤ ì •ë¦¬
            if hasattr(self, 'model_interface') and self.model_interface:
                try:
                    if hasattr(self.model_interface, 'unload_models'):
                        self.model_interface.unload_models()
                except Exception as e:
                    self.logger.debug(f"ëª¨ë¸ ì¸í„°í˜ì´ìŠ¤ ì •ë¦¬ ì‹¤íŒ¨: {e}")
            
            # ë©”ëª¨ë¦¬ ì •ë¦¬
            if TORCH_AVAILABLE:
                if self.device == "mps":
                    torch.mps.empty_cache()
                elif self.device == "cuda":
                    torch.cuda.empty_cache()
            
            gc.collect()
            
            self.logger.info("âœ… PoseEstimationStep ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì™„ë£Œ")
            
        except Exception as e:
            self.logger.error(f"âŒ ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì‹¤íŒ¨: {e}")
    
    def __del__(self):
        """ì†Œë©¸ì"""
        try:
            self.cleanup_resources()
        except Exception:
            pass

# =================================================================
# ğŸ”¥ í˜¸í™˜ì„± ì§€ì› í•¨ìˆ˜ë“¤ (í´ë°± ì œê±°ëœ ë²„ì „)
# =================================================================

async def create_pose_estimation_step(
    device: str = "auto",
    config: Optional[Dict[str, Any]] = None,
    strict_mode: bool = True,
    **kwargs
) -> PoseEstimationStep:
    """
    âœ… ì‹¤ì œ AI ì „ìš© Step 02 ìƒì„± í•¨ìˆ˜ - í´ë°± ì™„ì „ ì œê±°
    
    Args:
        device: ë””ë°”ì´ìŠ¤ ì„¤ì •
        config: ì„¤ì • ë”•ì…”ë„ˆë¦¬
        strict_mode: ì—„ê²© ëª¨ë“œ (Trueì‹œ AI ì‹¤íŒ¨ â†’ Exception)
        **kwargs: ì¶”ê°€ ì„¤ì •
        
    Returns:
        PoseEstimationStep: ì´ˆê¸°í™”ëœ í¬ì¦ˆ ì¶”ì • Step
        
    Raises:
        RuntimeError: strict_mode=Trueì—ì„œ ì´ˆê¸°í™” ì‹¤íŒ¨ ì‹œ
    """
    try:
        # ë””ë°”ì´ìŠ¤ ì²˜ë¦¬
        device_param = None if device == "auto" else device
        
        # config í†µí•©
        if config is None:
            config = {}
        config.update(kwargs)
        
        # Step ìƒì„± ë° ì´ˆê¸°í™”
        step = PoseEstimationStep(device=device_param, config=config, strict_mode=strict_mode)
        
        # ì´ˆê¸°í™” ì‹¤í–‰
        initialization_success = await step.initialize()
        
        if not initialization_success:
            error_msg = "ì‹¤ì œ AI ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨"
            if strict_mode:
                raise RuntimeError(f"Strict Mode: {error_msg}")
            else:
                step.logger.warning(f"âš ï¸ {error_msg} - Step ìƒì„±ì€ ì™„ë£Œë¨")
        
        return step
        
    except Exception as e:
        logger.error(f"âŒ create_pose_estimation_step ì‹¤íŒ¨: {e}")
        if strict_mode:
            raise  # strict_modeì—ì„œëŠ” Exception ì¬ë°œìƒ
        else:
            # ìµœì†Œí•œì˜ Step ìƒì„± (ë¹„ì—„ê²© ëª¨ë“œ)
            step = PoseEstimationStep(device='cpu', strict_mode=False)
            return step

def create_pose_estimation_step_sync(
    device: str = "auto",
    config: Optional[Dict[str, Any]] = None,
    strict_mode: bool = True,
    **kwargs
) -> PoseEstimationStep:
    """ğŸ”§ ë™ê¸°ì‹ Step 02 ìƒì„± (ë ˆê±°ì‹œ í˜¸í™˜)"""
    try:
        try:
            loop = asyncio.get_event_loop()
        except RuntimeError:
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
        
        return loop.run_until_complete(
            create_pose_estimation_step(device, config, strict_mode, **kwargs)
        )
    except Exception as e:
        logger.error(f"âŒ create_pose_estimation_step_sync ì‹¤íŒ¨: {e}")
        if strict_mode:
            raise
        else:
            return PoseEstimationStep(device='cpu', strict_mode=False)

# =================================================================
# ğŸ”¥ ì¶”ê°€ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
# =================================================================

def validate_openpose_keypoints(keypoints_18: List[List[float]]) -> bool:
    """OpenPose 18 keypoints ìœ íš¨ì„± ê²€ì¦"""
    try:
        if len(keypoints_18) != 18:
            return False
        
        for kp in keypoints_18:
            if len(kp) != 3:
                return False
            if not all(isinstance(x, (int, float)) for x in kp):
                return False
            if kp[2] < 0 or kp[2] > 1:  # ì‹ ë¢°ë„ëŠ” 0~1 ì‚¬ì´
                return False
        
        return True
        
    except Exception:
        return False

def convert_keypoints_to_coco(keypoints_18: List[List[float]]) -> List[List[float]]:
    """OpenPose 18ì„ COCO 17 í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
    try:
        # OpenPose 18 -> COCO 17 ë§¤í•‘
        op_to_coco_mapping = {
            0: 0,   # nose
            15: 1,  # right_eye -> left_eye (COCO ê´€ì )
            16: 2,  # left_eye -> right_eye
            17: 3,  # right_ear -> left_ear
            18: 4,  # left_ear -> right_ear
            2: 5,   # right_shoulder -> left_shoulder (COCO ê´€ì )
            5: 6,   # left_shoulder -> right_shoulder
            3: 7,   # right_elbow -> left_elbow
            6: 8,   # left_elbow -> right_elbow
            4: 9,   # right_wrist -> left_wrist
            7: 10,  # left_wrist -> right_wrist
            9: 11,  # right_hip -> left_hip
            12: 12, # left_hip -> right_hip
            10: 13, # right_knee -> left_knee
            13: 14, # left_knee -> right_knee
            11: 15, # right_ankle -> left_ankle
            14: 16  # left_ankle -> right_ankle
        }
        
        coco_keypoints = []
        for coco_idx in range(17):
            if coco_idx in op_to_coco_mapping.values():
                op_idx = next(k for k, v in op_to_coco_mapping.items() if v == coco_idx)
                if op_idx < len(keypoints_18):
                    coco_keypoints.append(keypoints_18[op_idx])
                else:
                    coco_keypoints.append([0.0, 0.0, 0.0])
            else:
                coco_keypoints.append([0.0, 0.0, 0.0])
        
        return coco_keypoints
        
    except Exception as e:
        logger.error(f"í‚¤í¬ì¸íŠ¸ ë³€í™˜ ì‹¤íŒ¨: {e}")
        return [[0.0, 0.0, 0.0]] * 17

def draw_pose_on_image(
    image: Union[np.ndarray, Image.Image],
    keypoints: List[List[float]],
    confidence_threshold: float = 0.5,
    keypoint_size: int = 4,
    line_width: int = 3
) -> Image.Image:
    """ì´ë¯¸ì§€ì— í¬ì¦ˆ ê·¸ë¦¬ê¸°"""
    try:
        # ì´ë¯¸ì§€ ë³€í™˜
        if isinstance(image, np.ndarray):
            pil_image = Image.fromarray(image)
        else:
            pil_image = image.copy()
        
        draw = ImageDraw.Draw(pil_image)
        
        # í‚¤í¬ì¸íŠ¸ ê·¸ë¦¬ê¸°
        for i, kp in enumerate(keypoints):
            if len(kp) >= 3 and kp[2] > confidence_threshold:
                x, y = int(kp[0]), int(kp[1])
                color = KEYPOINT_COLORS[i % len(KEYPOINT_COLORS)]
                
                # ì‹ ë¢°ë„ì— ë”°ë¥¸ í¬ê¸° ì¡°ì •
                radius = int(keypoint_size + kp[2] * 2)
                draw.ellipse([x-radius, y-radius, x+radius, y+radius], 
                           fill=color, outline=(255, 255, 255), width=2)
        
        # ìŠ¤ì¼ˆë ˆí†¤ ê·¸ë¦¬ê¸°
        for i, (start_idx, end_idx) in enumerate(SKELETON_CONNECTIONS):
            if (start_idx < len(keypoints) and end_idx < len(keypoints)):
                start_kp = keypoints[start_idx]
                end_kp = keypoints[end_idx]
                
                if (len(start_kp) >= 3 and len(end_kp) >= 3 and
                    start_kp[2] > confidence_threshold and end_kp[2] > confidence_threshold):
                    
                    start_point = (int(start_kp[0]), int(start_kp[1]))
                    end_point = (int(end_kp[0]), int(end_kp[1]))
                    color = SKELETON_COLORS[i % len(SKELETON_COLORS)]
                    
                    # ì‹ ë¢°ë„ì— ë”°ë¥¸ ì„  ë‘ê»˜
                    avg_confidence = (start_kp[2] + end_kp[2]) / 2
                    adjusted_width = int(line_width * avg_confidence)
                    
                    draw.line([start_point, end_point], fill=color, width=max(1, adjusted_width))
        
        return pil_image
        
    except Exception as e:
        logger.error(f"í¬ì¦ˆ ê·¸ë¦¬ê¸° ì‹¤íŒ¨: {e}")
        return image if isinstance(image, Image.Image) else Image.fromarray(image)

def analyze_pose_for_clothing(
    keypoints: List[List[float]],
    clothing_type: str = "default",
    confidence_threshold: float = 0.5,
    strict_analysis: bool = True
) -> Dict[str, Any]:
    """ì˜ë¥˜ë³„ í¬ì¦ˆ ì í•©ì„± ë¶„ì„ (ì‹¤ì œ AI ê¸°ë°˜)"""
    try:
        if not keypoints:
            return {
                'suitable_for_fitting': False,
                'issues': ["ì‹¤ì œ AI ëª¨ë¸ì—ì„œ í¬ì¦ˆë¥¼ ê²€ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤"],
                'recommendations': ["AI ëª¨ë¸ ìƒíƒœë¥¼ í™•ì¸í•˜ê±°ë‚˜ ë” ì„ ëª…í•œ ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í•´ ì£¼ì„¸ìš”"],
                'pose_score': 0.0,
                'ai_based_analysis': True
            }
        
        # ì˜ë¥˜ë³„ ê°€ì¤‘ì¹˜ ê°€ì ¸ì˜¤ê¸°
        weights = PoseEstimationStep.CLOTHING_POSE_WEIGHTS.get(
            clothing_type, 
            PoseEstimationStep.CLOTHING_POSE_WEIGHTS['default']
        )
        
        # ì‹ ì²´ ë¶€ìœ„ë³„ ì ìˆ˜ ê³„ì‚°
        def calculate_body_part_score(part_indices: List[int]) -> float:
            visible_count = 0
            total_confidence = 0.0
            
            for idx in part_indices:
                if idx < len(keypoints) and len(keypoints[idx]) >= 3:
                    if keypoints[idx][2] > confidence_threshold:
                        visible_count += 1
                        total_confidence += keypoints[idx][2]
            
            if visible_count == 0:
                return 0.0
            
            return (visible_count / len(part_indices)) * (total_confidence / visible_count)
        
        # ë¶€ìœ„ë³„ ì ìˆ˜
        head_indices = [0, 15, 16, 17, 18]  # nose, eyes, ears
        torso_indices = [1, 2, 5, 8, 9, 12]  # neck, shoulders, hips
        arm_indices = [2, 3, 4, 5, 6, 7]  # shoulders, elbows, wrists
        leg_indices = [9, 10, 11, 12, 13, 14]  # hips, knees, ankles
        
        head_score = calculate_body_part_score(head_indices)
        torso_score = calculate_body_part_score(torso_indices)
        arms_score = calculate_body_part_score(arm_indices)
        legs_score = calculate_body_part_score(leg_indices)
        
        # AI ì‹ ë¢°ë„ ë°˜ì˜ ê°€ì¤‘ í‰ê· 
        ai_confidence = np.mean([kp[2] for kp in keypoints if len(kp) > 2]) if keypoints else 0.0
        
        pose_score = (
            torso_score * weights.get('torso', 0.4) +
            arms_score * weights.get('arms', 0.3) +
            legs_score * weights.get('legs', 0.2) +
            weights.get('visibility', 0.1) * min(head_score, 1.0)
        ) * ai_confidence  # AI ì‹ ë¢°ë„ ë°˜ì˜
        
        # ì—„ê²©í•œ ì í•©ì„± íŒë‹¨ (AI ê¸°ë°˜ì´ë¯€ë¡œ ë” ë†’ì€ ê¸°ì¤€)
        min_score = 0.7 if strict_analysis else 0.6
        min_confidence = 0.6 if strict_analysis else 0.5
        suitable_for_fitting = pose_score >= min_score and ai_confidence >= min_confidence
        
        # ì´ìŠˆ ë° ê¶Œì¥ì‚¬í•­
        issues = []
        recommendations = []
        
        if ai_confidence < min_confidence:
            issues.append("AI ëª¨ë¸ì˜ ì‹ ë¢°ë„ê°€ ë‚®ìŠµë‹ˆë‹¤")
            recommendations.append("ì¡°ëª…ì´ ì¢‹ì€ í™˜ê²½ì—ì„œ ë‹¤ì‹œ ì´¬ì˜í•´ ì£¼ì„¸ìš”")
        
        if torso_score < 0.5:
            issues.append(f"{clothing_type} ì°©ìš©ì— ì¤‘ìš”í•œ ìƒì²´ê°€ ë¶ˆë¶„ëª…í•©ë‹ˆë‹¤")
            recommendations.append("ìƒì²´ ì „ì²´ê°€ ë³´ì´ë„ë¡ ì´¬ì˜í•´ ì£¼ì„¸ìš”")
        
        if clothing_type in ['shirt', 'jacket', 'top'] and arms_score < 0.5:
            issues.append("íŒ”ì˜ ìœ„ì¹˜ê°€ ì˜ë¥˜ ì°©ìš© ì‹œë®¬ë ˆì´ì…˜ì— ë¶€ì ì ˆí•©ë‹ˆë‹¤")
            recommendations.append("íŒ”ì„ ë²Œë¦¬ê±°ë‚˜ ìì—°ìŠ¤ëŸ½ê²Œ ë‚´ë ¤ì£¼ì„¸ìš”")
        
        if clothing_type in ['pants', 'dress', 'skirt'] and legs_score < 0.5:
            issues.append("ë‹¤ë¦¬ê°€ ê°€ë ¤ì ¸ ìˆì–´ í•˜ì˜ ì°©ìš© ì‹œë®¬ë ˆì´ì…˜ì´ ì–´ë µìŠµë‹ˆë‹¤")
            recommendations.append("ì „ì‹ ì´ ë³´ì´ë„ë¡ ì´¬ì˜í•´ ì£¼ì„¸ìš”")
        
        if head_score < 0.3:
            issues.append("ì–¼êµ´ì´ ì˜ ë³´ì´ì§€ ì•ŠìŠµë‹ˆë‹¤")
            recommendations.append("ì–¼êµ´ì´ ì •ë©´ì„ í–¥í•˜ë„ë¡ ì´¬ì˜í•´ ì£¼ì„¸ìš”")
        
        analysis = {
            'suitable_for_fitting': suitable_for_fitting,
            'issues': issues,
            'recommendations': recommendations,
            'pose_score': pose_score,
            'ai_confidence': ai_confidence,
            'detailed_scores': {
                'head': head_score,
                'torso': torso_score,
                'arms': arms_score,
                'legs': legs_score
            },
            'clothing_type': clothing_type,
            'weights_used': weights,
            'ai_based_analysis': True,
            'strict_analysis': strict_analysis
        }
        
        return analysis
        
    except Exception as e:
        logger.error(f"í¬ì¦ˆ ë¶„ì„ ì‹¤íŒ¨: {e}")
        return {
            'suitable_for_fitting': False,
            'issues': ["AI ê¸°ë°˜ ë¶„ì„ ì‹¤íŒ¨"],
            'recommendations': ["AI ëª¨ë¸ ìƒíƒœë¥¼ í™•ì¸í•˜ê±°ë‚˜ ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”"],
            'pose_score': 0.0,
            'ai_confidence': 0.0,
            'ai_based_analysis': True
        }

# =================================================================
# ğŸ”¥ ëª¨ë“ˆ ìµìŠ¤í¬íŠ¸ (ì‹¤ì œ AI ì „ìš©)
# =================================================================

__all__ = [
    'PoseEstimationStep',
    'PoseMetrics',
    'PoseModel',
    'PoseQuality', 
    'PoseType',
    'create_pose_estimation_step',
    'create_pose_estimation_step_sync',
    'validate_openpose_keypoints',
    'convert_keypoints_to_coco',
    'draw_pose_on_image',
    'analyze_pose_for_clothing',
    'OPENPOSE_18_KEYPOINTS',
    'KEYPOINT_COLORS',
    'SKELETON_CONNECTIONS',
    'SKELETON_COLORS'
]

# ëª¨ë“ˆ ì´ˆê¸°í™” ë¡œê·¸
logger.info("ğŸ”¥ PoseEstimationStep v7.0 - ì‹¤ì œ AI ì „ìš© ë²„ì „ ë¡œë“œ ì™„ë£Œ")
logger.info("âœ… í´ë°± ì™„ì „ ì œê±° - ì‹¤ì œ AI ëª¨ë¸ë§Œ ì‚¬ìš©")
logger.info("ğŸ”’ strict_mode ì§€ì› - ì‹¤íŒ¨ ì‹œ ì¦‰ì‹œ ì—ëŸ¬ ë°˜í™˜")
logger.info("ğŸ”— BaseStepMixin ì™„ì „ ì—°ë™ - logger ì†ì„± ëˆ„ë½ ì™„ì „ í•´ê²°")
logger.info("ğŸ§  ModelLoader ì™„ë²½ ì—°ë™ - ìˆœí™˜ì°¸ì¡° ì—†ëŠ” í•œë°©í–¥ ì°¸ì¡°")
logger.info("ğŸ“‹ step_model_requests.py ì™„ë²½ í˜¸í™˜")
logger.info("ğŸ M3 Max 128GB ìµœì í™” + conda í™˜ê²½ ìµœì í™”")
logger.info("ğŸ¯ í•¨ìˆ˜ëª…/í´ë˜ìŠ¤ëª… ì™„ì „ ìœ ì§€ - í”„ë¡ íŠ¸ì—”ë“œ í˜¸í™˜ì„± ë³´ì¥")
logger.info("ğŸš€ ì‹¤ì œ AI í¬ì¦ˆ ì¶”ì • ì‹œìŠ¤í…œ ì¤€ë¹„ ì™„ë£Œ")