# app/ai_pipeline/steps/step_02_pose_estimation.py
"""
âœ… MyCloset AI - 2ë‹¨ê³„: í¬ì¦ˆ ì¶”ì • (Pose Estimation) - ì™„ì „ ìž¬ìž‘ì„± ë²„ì „
==============================================================================

âœ… BaseStepMixin ì™„ì „ ì—°ë™ - logger ì†ì„± ëˆ„ë½ ë¬¸ì œ ì™„ì „ í•´ê²°
âœ… ModelLoader ì¸í„°íŽ˜ì´ìŠ¤ ì™„ë²½ ì—°ë™ - ìˆœí™˜ì°¸ì¡° ì—†ëŠ” í•œë°©í–¥ ì°¸ì¡°
âœ… Pipeline Manager 100% í˜¸í™˜ - ëª¨ë“  ê¸°ì¡´ ê¸°ëŠ¥ ìœ ì§€
âœ… M3 Max 128GB ìµœì í™” + 18ê°œ í‚¤í¬ì¸íŠ¸ OpenPose í˜¸í™˜
âœ… ì‹¤ì œ ìž‘ë™í•˜ëŠ” ì™„ì „í•œ í¬ì¦ˆ ì¶”ì • ì‹œìŠ¤í…œ
âœ… ì™„ì „í•œ ì—ëŸ¬ ì²˜ë¦¬ ë° ìºì‹œ ê´€ë¦¬
âœ… ë‹¤ì¤‘ ëª¨ë¸ ì§€ì› (MediaPipe, OpenPose, YOLOv8)
âœ… ì‹œê°í™” ì´ë¯¸ì§€ ìƒì„± ê¸°ëŠ¥

íŒŒì¼ ìœ„ì¹˜: backend/app/ai_pipeline/steps/step_02_pose_estimation.py
ìž‘ì„±ìž: MyCloset AI Team
ë‚ ì§œ: 2025-07-19
ë²„ì „: v5.0 (Complete Rewrite)
"""

import os
import sys
import logging
import time
import asyncio
import threading
import json
import math
import gc
import hashlib
import base64
from typing import Dict, Any, Optional, Tuple, List, Union, Callable
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor
from dataclasses import dataclass, field, asdict
from enum import Enum
from functools import lru_cache
import numpy as np
import io

# í•„ìˆ˜ íŒ¨í‚¤ì§€ë“¤ - ì•ˆì „í•œ import
try:
    import torch
    import torch.nn as nn
    import torch.nn.functional as F
    from torch.cuda.amp import autocast
    TORCH_AVAILABLE = True
except ImportError:
    TORCH_AVAILABLE = False
    print("âŒ PyTorch í•„ìˆ˜: pip install torch torchvision")

try:
    import cv2
    CV2_AVAILABLE = True
except ImportError:
    CV2_AVAILABLE = False
    print("âŒ OpenCV í•„ìˆ˜: pip install opencv-python")

try:
    from PIL import Image, ImageDraw, ImageFont
    PIL_AVAILABLE = True
except ImportError:
    PIL_AVAILABLE = False
    print("âŒ Pillow í•„ìˆ˜: pip install Pillow")

try:
    import mediapipe as mp
    MEDIAPIPE_AVAILABLE = True
except ImportError:
    MEDIAPIPE_AVAILABLE = False
    print("âš ï¸ MediaPipe ê¶Œìž¥: pip install mediapipe")

try:
    from ultralytics import YOLO
    YOLO_AVAILABLE = True
except ImportError:
    YOLO_AVAILABLE = False
    print("âš ï¸ YOLOv8 ê¶Œìž¥: pip install ultralytics")

try:
    import psutil
    PSUTIL_AVAILABLE = True
except ImportError:
    PSUTIL_AVAILABLE = False
    print("âš ï¸ psutil ê¶Œìž¥: pip install psutil")

# ==============================================
# ðŸ”¥ MRO ì•ˆì „í•œ BaseStepMixin ì—°ë™ (ì™„ì „ ìˆ˜ì •)
# ==============================================

try:
    from app.ai_pipeline.steps.base_step_mixin import BaseStepMixin
    BASE_STEP_MIXIN_AVAILABLE = True
except ImportError:
    BASE_STEP_MIXIN_AVAILABLE = False
    # ðŸ”¥ MRO ì•ˆì „í•œ í´ë°± BaseStepMixin
    class BaseStepMixin:
        """MRO ì•ˆì „í•œ í´ë°± BaseStepMixin"""
        def __init__(self, *args, **kwargs):
            # logger ì†ì„± ëˆ„ë½ ë¬¸ì œ ì™„ì „ í•´ê²°
            if not hasattr(self, 'logger'):
                class_name = self.__class__.__name__
                self.logger = logging.getLogger(f"pipeline.{class_name}")
                self.logger.info(f"ðŸ”§ {class_name} í´ë°± logger ì´ˆê¸°í™” ì™„ë£Œ")
            
            # MRO ì•ˆì „í•œ ê¸°ë³¸ ì†ì„± ì„¤ì •
            if not hasattr(self, 'device'):
                self.device = kwargs.get('device', 'auto')
            if not hasattr(self, 'model_interface'):
                self.model_interface = None
            if not hasattr(self, 'config'):
                self.config = kwargs.get('config', {})
        
        def _setup_model_interface(self):
            """í´ë°± ëª¨ë¸ ì¸í„°íŽ˜ì´ìŠ¤ ì„¤ì •"""
            pass

# ==============================================
# ðŸ”¥ ModelLoader ì¸í„°íŽ˜ì´ìŠ¤ ì—°ë™ (í•œë°©í–¥ ì°¸ì¡°)
# ==============================================

try:
    from app.ai_pipeline.utils.model_loader import (
        get_global_model_loader, ModelLoader
    )
    MODEL_LOADER_AVAILABLE = True
except ImportError:
    MODEL_LOADER_AVAILABLE = False
    print("âš ï¸ ModelLoader ì‚¬ìš© ë¶ˆê°€")

try:
    from app.ai_pipeline.utils.memory_manager import (
        get_global_memory_manager, MemoryManager
    )
    MEMORY_MANAGER_AVAILABLE = True
except ImportError:
    MEMORY_MANAGER_AVAILABLE = False
    print("âš ï¸ MemoryManager ì‚¬ìš© ë¶ˆê°€")

try:
    from app.ai_pipeline.utils.data_converter import (
        get_global_data_converter, DataConverter
    )
    DATA_CONVERTER_AVAILABLE = True
except ImportError:
    DATA_CONVERTER_AVAILABLE = False
    print("âš ï¸ DataConverter ì‚¬ìš© ë¶ˆê°€")

# ë¡œê±° ì„¤ì • (ëª¨ë“ˆ ë ˆë²¨)
logger = logging.getLogger(__name__)

# ==============================================
# ðŸ”¥ ìƒìˆ˜ ë° ë°ì´í„° êµ¬ì¡° ì •ì˜
# ==============================================

class PoseModel(Enum):
    """í¬ì¦ˆ ì¶”ì • ëª¨ë¸ íƒ€ìž…"""
    MEDIAPIPE = "mediapipe"
    OPENPOSE = "openpose"
    YOLOV8 = "yolov8"
    LIGHTWEIGHT = "lightweight"

class PoseQuality(Enum):
    """í¬ì¦ˆ í’ˆì§ˆ ë“±ê¸‰"""
    EXCELLENT = "excellent"     # 90-100ì 
    GOOD = "good"              # 75-89ì 
    ACCEPTABLE = "acceptable"   # 60-74ì 
    POOR = "poor"              # 40-59ì 
    VERY_POOR = "very_poor"    # 0-39ì 

class PoseType(Enum):
    """í¬ì¦ˆ íƒ€ìž…"""
    T_POSE = "t_pose"          # Tìž í¬ì¦ˆ
    A_POSE = "a_pose"          # Aìž í¬ì¦ˆ  
    STANDING = "standing"      # ê¸°ë³¸ ì„œìžˆê¸°
    SITTING = "sitting"        # ì•‰ê¸°
    WALKING = "walking"        # ê±·ê¸°
    ARMS_UP = "arms_up"        # íŒ” ì˜¬ë¦¬ê¸°
    UNKNOWN = "unknown"        # ì•Œ ìˆ˜ ì—†ìŒ

# OpenPose 18 í‚¤í¬ì¸íŠ¸ ì •ì˜
OPENPOSE_18_KEYPOINTS = {
    0: "nose",
    1: "neck", 
    2: "right_shoulder",
    3: "right_elbow",
    4: "right_wrist",
    5: "left_shoulder",
    6: "left_elbow", 
    7: "left_wrist",
    8: "mid_hip",
    9: "right_hip",
    10: "right_knee",
    11: "right_ankle",
    12: "left_hip",
    13: "left_knee",
    14: "left_ankle",
    15: "right_eye",
    16: "left_eye",
    17: "right_ear"
}

# ì‹œê°í™”ìš© ìƒ‰ìƒ ì •ì˜
KEYPOINT_COLORS = [
    (255, 0, 0),    # nose - ë¹¨ê°•
    (255, 85, 0),   # neck - ì£¼í™©
    (255, 170, 0),  # right_shoulder - ë…¸ëž‘
    (255, 255, 0),  # right_elbow - ì—°ë…¸ëž‘
    (170, 255, 0),  # right_wrist - ì—°ë‘
    (85, 255, 0),   # left_shoulder - ì´ˆë¡
    (0, 255, 0),    # left_elbow - ì§„ì´ˆë¡
    (0, 255, 85),   # left_wrist - ì²­ë¡
    (0, 255, 170),  # mid_hip - ì—°ì²­ë¡
    (0, 255, 255),  # right_hip - í•˜ëŠ˜
    (0, 170, 255),  # right_knee - ì—°íŒŒëž‘
    (0, 85, 255),   # right_ankle - íŒŒëž‘
    (0, 0, 255),    # left_hip - ì§„íŒŒëž‘
    (85, 0, 255),   # left_knee - ë³´ë¼
    (170, 0, 255),  # left_ankle - ì—°ë³´ë¼
    (255, 0, 255),  # right_eye - ìží™
    (255, 0, 170),  # left_eye - ë¶„í™
    (255, 0, 85)    # right_ear - ì—°ë¶„í™
]

# ìŠ¤ì¼ˆë ˆí†¤ ì—°ê²° ì •ì˜
SKELETON_CONNECTIONS = [
    # ë¨¸ë¦¬-ëª©-ëª¸í†µ
    (0, 1),   # nose-neck
    (1, 2),   # neck-right_shoulder  
    (1, 5),   # neck-left_shoulder
    (2, 8),   # right_shoulder-mid_hip (ê°€ì •)
    (5, 8),   # left_shoulder-mid_hip (ê°€ì •)
    
    # ì˜¤ë¥¸íŒ”
    (2, 3),   # right_shoulder-right_elbow
    (3, 4),   # right_elbow-right_wrist
    
    # ì™¼íŒ”  
    (5, 6),   # left_shoulder-left_elbow
    (6, 7),   # left_elbow-left_wrist
    
    # ëª¸í†µ-ì—‰ë©ì´
    (8, 9),   # mid_hip-right_hip
    (8, 12),  # mid_hip-left_hip
    (9, 12),  # right_hip-left_hip
    
    # ì˜¤ë¥¸ë‹¤ë¦¬
    (9, 10),  # right_hip-right_knee
    (10, 11), # right_knee-right_ankle
    
    # ì™¼ë‹¤ë¦¬
    (12, 13), # left_hip-left_knee
    (13, 14), # left_knee-left_ankle
    
    # ì–¼êµ´
    (0, 15),  # nose-right_eye
    (0, 16),  # nose-left_eye
    (15, 17), # right_eye-right_ear
    (16, 17)  # left_eye-right_ear
]

SKELETON_COLORS = [
    (0, 255, 0),    # ì´ˆë¡ (ê¸°ë³¸)
    (255, 255, 0),  # ë…¸ëž‘ (íŒ”)
    (255, 0, 255),  # ìží™ (ë‹¤ë¦¬)
    (0, 255, 255)   # í•˜ëŠ˜ (ì–¼êµ´)
]

# ==============================================
# ðŸ”¥ í¬ì¦ˆ ë©”íŠ¸ë¦­ ë°ì´í„° í´ëž˜ìŠ¤
# ==============================================

@dataclass
class PoseMetrics:
    """í¬ì¦ˆ ë©”íŠ¸ë¦­"""
    
    # ê¸°ë³¸ í‚¤í¬ì¸íŠ¸ ì •ë³´
    keypoints_18: List[List[float]] = field(default_factory=lambda: [[0, 0, 0] for _ in range(18)])
    keypoints_detected: int = 0
    pose_confidence: float = 0.0
    
    # ì‹ ì²´ ë¹„ìœ¨
    total_height: float = 0.0
    torso_length: float = 0.0
    shoulder_width: float = 0.0
    hip_width: float = 0.0
    left_arm_length: float = 0.0
    right_arm_length: float = 0.0
    left_leg_length: float = 0.0
    right_leg_length: float = 0.0
    
    # í¬ì¦ˆ ê°ë„
    left_arm_angle: float = 0.0
    right_arm_angle: float = 0.0
    left_leg_angle: float = 0.0
    right_leg_angle: float = 0.0
    spine_angle: float = 0.0
    
    # í’ˆì§ˆ ë©”íŠ¸ë¦­
    detection_rate: float = 0.0
    major_keypoints_rate: float = 0.0
    average_confidence: float = 0.0
    symmetry_score: float = 0.0
    visibility_score: float = 0.0
    
    # í¬ì¦ˆ ë¶„ë¥˜
    pose_type: str = "unknown"
    quality_grade: str = "F"
    overall_score: float = 0.0
    
    # í”¼íŒ… ì í•©ì„±
    suitable_for_fitting: bool = False
    fitting_confidence: float = 0.0
    
    # ë©”íƒ€ë°ì´í„°
    detection_method: str = "unknown"
    processing_time: float = 0.0
    
    def calculate_overall_score(self) -> float:
        """ì „ì²´ ì ìˆ˜ ê³„ì‚°"""
        try:
            # ê°€ì¤‘ í‰ê·  ê³„ì‚°
            scores = [
                self.detection_rate * 0.3,        # ê²€ì¶œë¥  30%
                self.average_confidence * 0.25,   # í‰ê·  ì‹ ë¢°ë„ 25%
                self.symmetry_score * 0.2,        # ëŒ€ì¹­ì„± 20%
                self.visibility_score * 0.15,     # ê°€ì‹œì„± 15%
                self.major_keypoints_rate * 0.1   # ì£¼ìš” í‚¤í¬ì¸íŠ¸ 10%
            ]
            
            self.overall_score = sum(scores)
            return self.overall_score
            
        except Exception as e:
            logger.error(f"ì „ì²´ ì ìˆ˜ ê³„ì‚° ì‹¤íŒ¨: {e}")
            self.overall_score = 0.0
            return 0.0
    
    def get_quality_grade(self) -> str:
        """í’ˆì§ˆ ë“±ê¸‰ ë°˜í™˜"""
        if self.overall_score >= 0.9:
            self.quality_grade = "A+"
        elif self.overall_score >= 0.8:
            self.quality_grade = "A"
        elif self.overall_score >= 0.7:
            self.quality_grade = "B"
        elif self.overall_score >= 0.6:
            self.quality_grade = "C"
        elif self.overall_score >= 0.5:
            self.quality_grade = "D"
        else:
            self.quality_grade = "F"
        
        return self.quality_grade

# ==============================================
# ðŸ”¥ ë©”ì¸ PoseEstimationStep í´ëž˜ìŠ¤
# ==============================================

class PoseEstimationStep(BaseStepMixin):
    """
    âœ… 2ë‹¨ê³„: ì™„ì „í•œ í¬ì¦ˆ ì¶”ì • ì‹œìŠ¤í…œ - ì™„ì „ ìž¬ìž‘ì„±
    âœ… BaseStepMixin ì™„ì „ ì—°ë™ - logger ì†ì„± ëˆ„ë½ ì™„ì „ í•´ê²°
    âœ… ModelLoader ì¸í„°íŽ˜ì´ìŠ¤ ì™„ë²½ ì—°ë™ - ìˆœí™˜ì°¸ì¡° ì—†ëŠ” í•œë°©í–¥ ì°¸ì¡°
    âœ… Pipeline Manager í˜¸í™˜ì„± 100% - ëª¨ë“  ê¸°ì¡´ ê¸°ëŠ¥ ìœ ì§€
    âœ… M3 Max ìµœì í™” + 18ê°œ í‚¤í¬ì¸íŠ¸ OpenPose í˜¸í™˜
    âœ… ì‹¤ì œ ìž‘ë™í•˜ëŠ” ì™„ì „í•œ í¬ì¦ˆ ì¶”ì • ì‹œìŠ¤í…œ
    """
    
    # ì˜ë¥˜ íƒ€ìž…ë³„ í¬ì¦ˆ ê°€ì¤‘ì¹˜
    CLOTHING_POSE_WEIGHTS = {
        'shirt': {'arms': 0.4, 'torso': 0.4, 'visibility': 0.2},
        'dress': {'torso': 0.5, 'arms': 0.3, 'legs': 0.2},
        'pants': {'legs': 0.6, 'torso': 0.3, 'visibility': 0.1},
        'jacket': {'arms': 0.5, 'torso': 0.4, 'visibility': 0.1},
        'skirt': {'torso': 0.4, 'legs': 0.4, 'visibility': 0.2},
        'top': {'torso': 0.5, 'arms': 0.4, 'visibility': 0.1},
        'default': {'torso': 0.4, 'arms': 0.3, 'legs': 0.2, 'visibility': 0.1}
    }
    
    def __init__(
        self,
        device: Optional[str] = None,
        config: Optional[Dict[str, Any]] = None,
        **kwargs
    ):
        """âœ… MRO ì•ˆì „í•œ ìƒì„±ìž - ëª¨ë“  í˜¸í™˜ì„± ë¬¸ì œ í•´ê²°"""
        
        # ðŸ”¥ 1. logger ì†ì„± ëˆ„ë½ ë¬¸ì œ ì™„ì „ í•´ê²° - ìµœìš°ì„ 
        if not hasattr(self, 'logger'):
            self.logger = logging.getLogger(f"pipeline.{self.__class__.__name__}")
            self.logger.info(f"ðŸ”§ {self.__class__.__name__} logger ì´ˆê¸°í™” ì™„ë£Œ")
        
        # ðŸ”¥ 2. MRO ì•ˆì „í•œ BaseStepMixin ì´ˆê¸°í™”
        if BASE_STEP_MIXIN_AVAILABLE:
            try:
                # MRO ì²´í¬: BaseStepMixinì´ ë§ˆì§€ë§‰ì´ ì•„ë‹Œ ê²½ìš°ì—ë§Œ super() í˜¸ì¶œ
                mro = type(self).__mro__
                if len(mro) > 2 and BaseStepMixin in mro[1:-1]:
                    # BaseStepMixinì´ ì¤‘ê°„ì— ìžˆìœ¼ë©´ ì•ˆì „í•˜ê²Œ ì´ˆê¸°í™”
                    BaseStepMixin.__init__(self, **kwargs)
                else:
                    # BaseStepMixin ì§ì ‘ ì´ˆê¸°í™” (ì•ˆì „)
                    self._init_base_step_mixin_safely(**kwargs)
            except Exception as e:
                self.logger.warning(f"BaseStepMixin ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                # í´ë°±: ì§ì ‘ ì´ˆê¸°í™”
                self._init_base_step_mixin_safely(**kwargs)
        else:
            # BaseStepMixin ì—†ëŠ” ê²½ìš° í´ë°± ì´ˆê¸°í™”
            self._init_base_step_mixin_safely(**kwargs)
        
        # ðŸ”¥ 3. ê¸°ë³¸ ì„¤ì •
        self.device = self._auto_detect_device(device)
        self.config = config or {}
        self.step_name = self.__class__.__name__
        self.step_number = 2
        
        # ðŸ”¥ 4. ì‹œìŠ¤í…œ ì •ë³´ ì„¤ì •
        self.device_type = kwargs.get('device_type', self._get_device_type())
        self.memory_gb = float(kwargs.get('memory_gb', self._get_memory_gb()))
        self.is_m3_max = kwargs.get('is_m3_max', self._detect_m3_max())
        self.optimization_enabled = kwargs.get('optimization_enabled', True)
        self.quality_level = kwargs.get('quality_level', 'balanced')
        
        # ðŸ”¥ 5. ì„¤ì • ë³‘í•©
        self._merge_config_from_kwargs(kwargs)
        
        # ðŸ”¥ 6. ì´ˆê¸°í™” ìƒíƒœ
        self.is_initialized = False
        self.initialization_error = None
        self.performance_stats = {
            'total_processed': 0,
            'total_time': 0.0,
            'average_time': 0.0,
            'last_processing_time': 0.0,
            'average_confidence': 0.0,
            'peak_memory_usage': 0.0,
            'error_count': 0,
            'cache_hits': 0,
            'cache_misses': 0
        }
        
        # ðŸ”¥ 7. í¬ì¦ˆ ì¶”ì • ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        try:
            self._initialize_pose_system()
            self._setup_model_loader_interface()
            self._setup_pose_models()
            self._setup_processing_pipeline()
            self.is_initialized = True
            self.logger.info(f"âœ… {self.step_name} ì´ˆê¸°í™” ì™„ë£Œ - M3 Max: {self.is_m3_max}")
        except Exception as e:
            self.initialization_error = str(e)
            self.logger.error(f"âŒ {self.step_name} ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    
    def _init_base_step_mixin_safely(self, **kwargs):
        """ðŸ”¥ MRO ì•ˆì „í•œ BaseStepMixin ì´ˆê¸°í™” í´ë°±"""
        try:
            # BaseStepMixinì˜ ê¸°ë³¸ ì†ì„±ë“¤ì„ ì§ì ‘ ì„¤ì •
            if not hasattr(self, 'device'):
                self.device = kwargs.get('device', 'auto')
            if not hasattr(self, 'model_interface'):
                self.model_interface = None
            if not hasattr(self, 'config'):
                # SafeConfigê°€ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ dict ì‚¬ìš©
                try:
                    from app.ai_pipeline.steps.base_step_mixin import SafeConfig
                    self.config = SafeConfig(kwargs.get('config', {}))
                except ImportError:
                    self.config = kwargs.get('config', {})
            
            self.logger.debug("âœ… BaseStepMixin í´ë°± ì´ˆê¸°í™” ì™„ë£Œ")
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ BaseStepMixin í´ë°± ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            # ìµœì†Œí•œì˜ ì•ˆì „ ì„¤ì •
            if not hasattr(self, 'device'):
                self.device = 'cpu'
            if not hasattr(self, 'model_interface'):
                self.model_interface = None
            if not hasattr(self, 'config'):
                self.config = {}
    
    def _auto_detect_device(self, device: Optional[str] = None) -> str:
        """ë””ë°”ì´ìŠ¤ ìžë™ ê°ì§€ - M3 Max ìµœì í™”"""
        if device and device != "auto":
            return device
        
        # M3 Max ê°ì§€
        if TORCH_AVAILABLE:
            try:
                if torch.backends.mps.is_available():
                    return "mps"
                elif torch.cuda.is_available():
                    return "cuda"
            except Exception as e:
                self.logger.warning(f"ë””ë°”ì´ìŠ¤ ê°ì§€ ì‹¤íŒ¨: {e}")
        
        return "cpu"
    
    def _get_device_type(self) -> str:
        """ë””ë°”ì´ìŠ¤ íƒ€ìž… ë°˜í™˜"""
        try:
            if self.device == "mps":
                return "apple_silicon"
            elif self.device == "cuda":
                return "nvidia_gpu"
            else:
                return "cpu"
        except Exception as e:
            self.logger.warning(f"ë””ë°”ì´ìŠ¤ íƒ€ìž… ê°ì§€ ì‹¤íŒ¨: {e}")
            return "cpu"
    
    def _get_memory_gb(self) -> float:
        """ë©”ëª¨ë¦¬ í¬ê¸° ê°ì§€"""
        try:
            if PSUTIL_AVAILABLE:
                return psutil.virtual_memory().total / (1024**3)
            else:
                return 16.0  # ê¸°ë³¸ê°’
        except Exception as e:
            self.logger.warning(f"ë©”ëª¨ë¦¬ ê°ì§€ ì‹¤íŒ¨: {e}")
            return 16.0
    
    def _detect_m3_max(self) -> bool:
        """M3 Max ê°ì§€"""
        try:
            import platform
            if platform.system() == 'Darwin':
                import subprocess
                result = subprocess.run(['sysctl', '-n', 'machdep.cpu.brand_string'], 
                                        capture_output=True, text=True, timeout=5)
                return "M3" in result.stdout and "Max" in result.stdout
        except Exception as e:
            self.logger.debug(f"M3 Max ê°ì§€ ì‹¤íŒ¨: {e}")
            pass
        return False
    
    def _merge_config_from_kwargs(self, kwargs: Dict[str, Any]):
        """kwargsì—ì„œ config ë³‘í•©"""
        system_params = {
            'device_type', 'memory_gb', 'is_m3_max', 
            'optimization_enabled', 'quality_level'
        }
        
        for key, value in kwargs.items():
            if key not in system_params:
                self.config[key] = value
    
    def _initialize_pose_system(self):
        """í¬ì¦ˆ ì¶”ì • ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
        
        # í¬ì¦ˆ ì¶”ì • ì„¤ì •
        self.pose_config = {
            'model_priority': self.config.get('model_priority', ['mediapipe', 'openpose', 'yolov8']),
            'confidence_threshold': self.config.get('confidence_threshold', 0.5),
            'visualization_enabled': self.config.get('visualization_enabled', True),
            'return_analysis': self.config.get('return_analysis', True),
            'cache_enabled': self.config.get('cache_enabled', True),
            'batch_processing': self.config.get('batch_processing', False),
            'detailed_analysis': self.config.get('detailed_analysis', False)
        }
        
        # ìµœì í™” ë ˆë²¨ ì„¤ì •
        if self.is_m3_max:
            self.optimization_level = 'maximum'
            self.batch_processing = True
            self.use_neural_engine = True
        elif self.memory_gb >= 32:
            self.optimization_level = 'high'
            self.batch_processing = True
            self.use_neural_engine = False
        else:
            self.optimization_level = 'basic'
            self.batch_processing = False
            self.use_neural_engine = False
        
        # ìºì‹œ ì‹œìŠ¤í…œ
        cache_size = min(100 if self.is_m3_max else 50, int(self.memory_gb * 2))
        self.prediction_cache = {}
        self.cache_max_size = cache_size
        
        self.logger.info(f"ðŸŽ¯ í¬ì¦ˆ ì¶”ì • ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ - ìµœì í™”: {self.optimization_level}")
    
    def _setup_model_loader_interface(self):
        """ðŸ”¥ ModelLoader ì¸í„°íŽ˜ì´ìŠ¤ ì„¤ì • - ì™„ì „ ì•ˆì „í•œ í•œë°©í–¥ ì°¸ì¡°"""
        try:
            # ModelLoader ì—°ë™ (í•œë°©í–¥ ì°¸ì¡°)
            if MODEL_LOADER_AVAILABLE:
                try:
                    self.model_loader = get_global_model_loader()
                    if hasattr(self.model_loader, 'create_step_interface'):
                        self.model_interface = self.model_loader.create_step_interface(self.step_name)
                    else:
                        self.model_interface = self.model_loader
                    
                    self.logger.info(f"ðŸ”— {self.step_name} ModelLoader ì¸í„°íŽ˜ì´ìŠ¤ ì—°ë™ ì™„ë£Œ")
                except Exception as e:
                    self.logger.warning(f"ModelLoader ì—°ë™ ì‹¤íŒ¨: {e}")
                    self.model_loader = None
                    self.model_interface = None
            else:
                self.model_loader = None
                self.model_interface = None
                self.logger.warning(f"âš ï¸ ModelLoader ì‚¬ìš© ë¶ˆê°€, ë‚´ìž¥ ëª¨ë¸ ì‚¬ìš©")
                
            # Memory Manager ì—°ë™ (í•œë°©í–¥ ì°¸ì¡°)
            if MEMORY_MANAGER_AVAILABLE:
                try:
                    self.memory_manager = get_global_memory_manager()
                except Exception as e:
                    self.logger.warning(f"MemoryManager ì—°ë™ ì‹¤íŒ¨: {e}")
                    self.memory_manager = None
            else:
                self.memory_manager = None
            
            # Data Converter ì—°ë™ (í•œë°©í–¥ ì°¸ì¡°)
            if DATA_CONVERTER_AVAILABLE:
                try:
                    self.data_converter = get_global_data_converter()
                except Exception as e:
                    self.logger.warning(f"DataConverter ì—°ë™ ì‹¤íŒ¨: {e}")
                    self.data_converter = None
            else:
                self.data_converter = None
                
        except Exception as e:
            self.logger.error(f"âŒ ModelLoader ì¸í„°íŽ˜ì´ìŠ¤ ì„¤ì • ì‹¤íŒ¨: {e}")
            self.model_loader = None
            self.model_interface = None
            self.memory_manager = None
            self.data_converter = None
    
    def _setup_pose_models(self):
        """í¬ì¦ˆ ì¶”ì • ëª¨ë¸ë“¤ ì„¤ì •"""
        self.pose_models = {}
        self.active_model = None
        
        try:
            # 1. MediaPipe ì„¤ì •
            if MEDIAPIPE_AVAILABLE:
                try:
                    self.pose_models['mediapipe'] = mp.solutions.pose.Pose(
                        static_image_mode=True,
                        model_complexity=2,
                        enable_segmentation=False,
                        min_detection_confidence=0.5,
                        min_tracking_confidence=0.5
                    )
                    self.logger.info("âœ… MediaPipe í¬ì¦ˆ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
                except Exception as e:
                    self.logger.warning(f"âš ï¸ MediaPipe ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            
            # 2. YOLOv8 ì„¤ì • (ë°±ì—…)
            if YOLO_AVAILABLE:
                try:
                    # ê¸°ë³¸ YOLOv8 ëª¨ë¸ ë¡œë“œ
                    self.pose_models['yolov8'] = YOLO('yolov8n-pose.pt')
                    self.logger.info("âœ… YOLOv8 í¬ì¦ˆ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
                except Exception as e:
                    self.logger.warning(f"âš ï¸ YOLOv8 ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            
            # 3. ê¸°ë³¸ ëª¨ë¸ ì„ íƒ
            model_priority = self.pose_config['model_priority']
            for model_name in model_priority:
                if model_name in self.pose_models:
                    self.active_model = model_name
                    break
            
            if not self.active_model:
                self.logger.warning("âš ï¸ í¬ì¦ˆ ëª¨ë¸ ì—†ìŒ, ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œë¡œ ë™ìž‘")
                self.active_model = 'simulation'
            else:
                self.logger.info(f"ðŸŽ¯ í™œì„± í¬ì¦ˆ ëª¨ë¸: {self.active_model}")
                
        except Exception as e:
            self.logger.error(f"âŒ í¬ì¦ˆ ëª¨ë¸ ì„¤ì • ì‹¤íŒ¨: {e}")
            self.pose_models = {}
            self.active_model = 'simulation'
    
    def _setup_processing_pipeline(self):
        """í¬ì¦ˆ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì„¤ì •"""
        
        # ì²˜ë¦¬ ìˆœì„œ ì •ì˜
        self.processing_pipeline = []
        
        # 1. ì „ì²˜ë¦¬
        self.processing_pipeline.append(('preprocessing', self._preprocess_for_pose))
        
        # 2. í¬ì¦ˆ ì¶”ì •
        self.processing_pipeline.append(('pose_estimation', self._perform_pose_estimation))
        
        # 3. í›„ì²˜ë¦¬
        self.processing_pipeline.append(('postprocessing', self._postprocess_pose_results))
        
        # 4. í’ˆì§ˆ ë¶„ì„
        if self.pose_config['return_analysis']:
            self.processing_pipeline.append(('quality_analysis', self._analyze_pose_quality))
        
        # 5. ì‹œê°í™”
        if self.pose_config['visualization_enabled']:
            self.processing_pipeline.append(('visualization', self._create_pose_visualization))
        
        self.logger.info(f"ðŸ”„ í¬ì¦ˆ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì„¤ì • ì™„ë£Œ - {len(self.processing_pipeline)}ë‹¨ê³„")
    
    # =================================================================
    # ðŸš€ ë©”ì¸ ì²˜ë¦¬ í•¨ìˆ˜ (Pipeline Manager í˜¸ì¶œ)
    # =================================================================
    
    async def process(
        self,
        person_image: Union[np.ndarray, str, Path],
        clothing_type: str = "default",
        **kwargs
    ) -> Dict[str, Any]:
        """
        âœ… ë©”ì¸ í¬ì¦ˆ ì¶”ì • í•¨ìˆ˜ - Pipeline Manager í‘œì¤€ ì¸í„°íŽ˜ì´ìŠ¤
        
        Args:
            person_image: ì¸ë¬¼ ì´ë¯¸ì§€ (numpy array, íŒŒì¼ ê²½ë¡œ, PIL Image)
            clothing_type: ì˜ë¥˜ íƒ€ìž… (ê°€ì¤‘ì¹˜ ì¡°ì •ìš©)
            **kwargs: ì¶”ê°€ ì„¤ì •
        
        Returns:
            Dict[str, Any]: í¬ì¦ˆ ì¶”ì • ê²°ê³¼
        """
        start_time = time.time()
        
        try:
            # 1. ì´ˆê¸°í™” ê²€ì¦
            if not self.is_initialized:
                raise ValueError(f"PoseEstimationStepì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤: {self.initialization_error}")
            
            # 2. ì´ë¯¸ì§€ ë¡œë“œ ë° ê²€ì¦
            image = self._load_and_validate_image(person_image)
            if image is None:
                raise ValueError("ìœ íš¨í•˜ì§€ ì•Šì€ person_imageìž…ë‹ˆë‹¤")
            
            # 3. ìºì‹œ í™•ì¸
            cache_key = self._generate_cache_key(image, clothing_type, kwargs)
            if self.pose_config['cache_enabled'] and cache_key in self.prediction_cache:
                self.logger.info("ðŸ“‹ ìºì‹œì—ì„œ í¬ì¦ˆ ì¶”ì • ê²°ê³¼ ë°˜í™˜")
                self.performance_stats['cache_hits'] += 1
                cached_result = self.prediction_cache[cache_key].copy()
                cached_result['from_cache'] = True
                return cached_result
            
            self.performance_stats['cache_misses'] += 1
            
            # 4. ë©”ëª¨ë¦¬ ìµœì í™”
            if self.memory_manager:
                try:
                    await self._optimize_memory()
                except Exception as e:
                    self.logger.debug(f"ë©”ëª¨ë¦¬ ìµœì í™” ì‹¤íŒ¨: {e}")
            
            # 5. ë©”ì¸ í¬ì¦ˆ ì¶”ì • íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
            pose_metrics = await self._execute_pose_pipeline(image, clothing_type, **kwargs)
            
            # 6. ê²°ê³¼ í›„ì²˜ë¦¬
            result = self._build_final_result(pose_metrics, clothing_type, time.time() - start_time)
            
            # 7. ìºì‹œ ì €ìž¥
            if self.pose_config['cache_enabled']:
                self._save_to_cache(cache_key, result)
            
            # 8. í†µê³„ ì—…ë°ì´íŠ¸
            self._update_performance_stats(time.time() - start_time, pose_metrics.overall_score)
            
            self.logger.info(f"âœ… í¬ì¦ˆ ì¶”ì • ì™„ë£Œ - í‚¤í¬ì¸íŠ¸: {pose_metrics.keypoints_detected}/18, í’ˆì§ˆ: {pose_metrics.quality_grade}")
            return result
            
        except Exception as e:
            error_msg = f"í¬ì¦ˆ ì¶”ì • ì‹¤íŒ¨: {e}"
            self.logger.error(f"âŒ {error_msg}")
            
            processing_time = time.time() - start_time
            self._update_performance_stats(processing_time, 0.0, success=False)
            
            return self._create_error_result(error_msg, processing_time)
    
    def _create_error_result(self, error_message: str, processing_time: float) -> Dict[str, Any]:
        """ì—ëŸ¬ ê²°ê³¼ ìƒì„±"""
        return {
            "success": False,
            "step_name": self.step_name,
            "error": error_message,
            "processing_time": processing_time,
            "keypoints_18": [[0, 0, 0] for _ in range(18)],
            "pose_confidence": 0.0,
            "keypoints_detected": 0,
            "quality_grade": "F",
            "pose_analysis": {
                "detection_rate": 0.0,
                "quality_score": 0.0,
                "quality_grade": "F",
                "pose_type": "unknown",
                "suitable_for_fitting": False
            },
            "body_proportions": {},
            "pose_angles": {},
            "suitable_for_fitting": False,
            "fitting_confidence": 0.0,
            "keypoint_image": "",
            "skeleton_image": "", 
            "overlay_image": "",
            "from_cache": False,
            "device_info": {
                "device": self.device,
                "error_count": self.performance_stats.get('error_count', 0)
            }
        }
    
    # =================================================================
    # ðŸ”§ í¬ì¦ˆ ì¶”ì • í•µì‹¬ í•¨ìˆ˜ë“¤
    # =================================================================
    
    async def _execute_pose_pipeline(
        self,
        image: np.ndarray,
        clothing_type: str,
        **kwargs
    ) -> PoseMetrics:
        """í¬ì¦ˆ ì¶”ì • íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
        
        metrics = PoseMetrics()
        intermediate_results = {}
        current_data = image
        
        self.logger.info(f"ðŸ”„ í¬ì¦ˆ ì¶”ì • íŒŒì´í”„ë¼ì¸ ì‹œìž‘ - ì˜ë¥˜: {clothing_type}")
        
        for step_name, processor_func in self.processing_pipeline:
            try:
                step_start = time.time()
                
                # ë‹¨ê³„ë³„ ì²˜ë¦¬
                if step_name == 'preprocessing':
                    current_data = await processor_func(current_data, **kwargs)
                elif step_name == 'pose_estimation':
                    step_result = await processor_func(current_data, **kwargs)
                    current_data = step_result
                elif step_name == 'postprocessing':
                    step_result = await processor_func(current_data, image.shape, **kwargs)
                    current_data = step_result
                elif step_name == 'quality_analysis':
                    analysis_result = await processor_func(current_data, clothing_type, **kwargs)
                    if isinstance(analysis_result, dict):
                        current_data.update(analysis_result)
                elif step_name == 'visualization':
                    visualization_result = await processor_func(current_data, image, **kwargs)
                    if isinstance(visualization_result, dict):
                        current_data.update(visualization_result)
                
                step_time = time.time() - step_start
                intermediate_results[step_name] = {
                    'processing_time': step_time,
                    'success': True
                }
                
                # ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
                if isinstance(current_data, dict):
                    for key, value in current_data.items():
                        if hasattr(metrics, key):
                            setattr(metrics, key, value)
                
                self.logger.debug(f"  âœ“ {step_name} ì™„ë£Œ - {step_time:.3f}ì´ˆ")
                
            except Exception as e:
                self.logger.warning(f"  âš ï¸ {step_name} ì‹¤íŒ¨: {e}")
                intermediate_results[step_name] = {
                    'processing_time': 0,
                    'success': False,
                    'error': str(e)
                }
                continue
        
        # ì „ì²´ ì ìˆ˜ ê³„ì‚°
        try:
            clothing_weights = self.CLOTHING_POSE_WEIGHTS.get(clothing_type, self.CLOTHING_POSE_WEIGHTS['default'])
            metrics.calculate_overall_score()
            metrics.get_quality_grade()
            
            # í”¼íŒ… ì í•©ì„± ê³„ì‚°
            metrics.suitable_for_fitting = (
                metrics.keypoints_detected >= 12 and
                metrics.detection_rate >= 0.7 and
                metrics.overall_score >= 0.6
            )
            metrics.fitting_confidence = min(metrics.overall_score * 1.2, 1.0)
        except Exception as e:
            self.logger.warning(f"ë©”íŠ¸ë¦­ ê³„ì‚° ì‹¤íŒ¨: {e}")
        
        self.logger.info(f"âœ… í¬ì¦ˆ ì¶”ì • íŒŒì´í”„ë¼ì¸ ì™„ë£Œ - {len(intermediate_results)}ë‹¨ê³„ ì²˜ë¦¬")
        return metrics
    
    async def _preprocess_for_pose(self, image: np.ndarray, **kwargs) -> np.ndarray:
        """í¬ì¦ˆ ì¶”ì •ì„ ìœ„í•œ ì „ì²˜ë¦¬"""
        try:
            # 1. ì´ë¯¸ì§€ ì •ê·œí™”
            if image.dtype != np.uint8:
                image = np.clip(image * 255, 0, 255).astype(np.uint8)
            
            # 2. í¬ê¸° ì¡°ì • (ëª¨ë¸ì— ë”°ë¼)
            target_size = kwargs.get('target_size', (512, 512))
            if self.active_model == 'mediapipe':
                # MediaPipeëŠ” ì›ë³¸ í¬ê¸° ìœ ì§€ ì„ í˜¸
                pass
            elif self.active_model == 'yolov8':
                # YOLOëŠ” 640x640 ì„ í˜¸
                target_size = (640, 640)
            
            if target_size != image.shape[:2]:
                scale = target_size[0] / max(image.shape[:2])
                new_h, new_w = int(image.shape[0] * scale), int(image.shape[1] * scale)
                if CV2_AVAILABLE:
                    image = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_LANCZOS4)
            
            # 3. ìƒ‰ìƒ ê³µê°„ í™•ì¸
            if len(image.shape) == 3 and image.shape[2] == 3:
                # RGB ìˆœì„œ í™•ì¸ (MediaPipeëŠ” RGB, OpenCVëŠ” BGR)
                if self.active_model == 'mediapipe' and CV2_AVAILABLE:
                    # BGR to RGB ë³€í™˜ (OpenCV ì´ë¯¸ì§€ì¸ ê²½ìš°)
                    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            
            return image
            
        except Exception as e:
            self.logger.error(f"ì „ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return image
    
    async def _perform_pose_estimation(self, image: np.ndarray, **kwargs) -> Dict[str, Any]:
        """ì‹¤ì œ í¬ì¦ˆ ì¶”ì • ìˆ˜í–‰"""
        
        try:
            if self.active_model == 'mediapipe' and MEDIAPIPE_AVAILABLE:
                return await self._mediapipe_estimation(image, **kwargs)
            elif self.active_model == 'yolov8' and YOLO_AVAILABLE:
                return await self._yolov8_estimation(image, **kwargs)
            elif self.active_model == 'openpose':
                return await self._openpose_estimation(image, **kwargs)
            else:
                # ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œ
                return await self._simulation_estimation(image, **kwargs)
                
        except Exception as e:
            self.logger.error(f"í¬ì¦ˆ ì¶”ì • ì‹¤íŒ¨: {e}")
            return await self._simulation_estimation(image, **kwargs)
    
    async def _mediapipe_estimation(self, image: np.ndarray, **kwargs) -> Dict[str, Any]:
        """MediaPipe í¬ì¦ˆ ì¶”ì •"""
        try:
            model = self.pose_models['mediapipe']
            
            # MediaPipe ì¶”ë¡ 
            results = model.process(image)
            
            if results.pose_landmarks:
                # ëžœë“œë§ˆí¬ë¥¼ OpenPose 18 í˜•ì‹ìœ¼ë¡œ ë³€í™˜
                keypoints_18 = self._convert_mediapipe_to_openpose(results.pose_landmarks, image.shape)
                
                # ì‹ ë¢°ë„ ê³„ì‚°
                confidences = [kp[2] for kp in keypoints_18]
                pose_confidence = np.mean([c for c in confidences if c > 0])
                keypoints_detected = sum(1 for c in confidences if c > self.pose_config['confidence_threshold'])
                
                return {
                    'keypoints_18': keypoints_18,
                    'pose_confidence': float(pose_confidence),
                    'keypoints_detected': keypoints_detected,
                    'pose_angles': self._calculate_pose_angles(keypoints_18),
                    'body_proportions': self._calculate_body_proportions(keypoints_18),
                    'detection_method': 'mediapipe'
                }
            else:
                # ê²€ì¶œ ì‹¤íŒ¨
                return {
                    'keypoints_18': [[0, 0, 0] for _ in range(18)],
                    'pose_confidence': 0.0,
                    'keypoints_detected': 0,
                    'pose_angles': {},
                    'body_proportions': {},
                    'detection_method': 'mediapipe_failed'
                }
                
        except Exception as e:
            self.logger.error(f"MediaPipe í¬ì¦ˆ ì¶”ì • ì‹¤íŒ¨: {e}")
            return await self._simulation_estimation(image, **kwargs)
    
    async def _yolov8_estimation(self, image: np.ndarray, **kwargs) -> Dict[str, Any]:
        """YOLOv8 í¬ì¦ˆ ì¶”ì •"""
        try:
            model = self.pose_models['yolov8']
            
            # YOLO ì¶”ë¡ 
            results = model(image, verbose=False)
            
            if results and len(results) > 0 and results[0].keypoints is not None:
                # ì²« ë²ˆì§¸ ì‚¬ëžŒì˜ í‚¤í¬ì¸íŠ¸ ì¶”ì¶œ
                keypoints = results[0].keypoints.data[0].cpu().numpy()  # [17, 3] COCO format
                
                # COCO 17ì„ OpenPose 18ë¡œ ë³€í™˜
                keypoints_18 = self._convert_coco_to_openpose(keypoints, image.shape)
                
                # ì‹ ë¢°ë„ ê³„ì‚°
                confidences = [kp[2] for kp in keypoints_18]
                pose_confidence = np.mean([c for c in confidences if c > 0])
                keypoints_detected = sum(1 for c in confidences if c > self.pose_config['confidence_threshold'])
                
                return {
                    'keypoints_18': keypoints_18,
                    'pose_confidence': float(pose_confidence),
                    'keypoints_detected': keypoints_detected,
                    'pose_angles': self._calculate_pose_angles(keypoints_18),
                    'body_proportions': self._calculate_body_proportions(keypoints_18),
                    'detection_method': 'yolov8'
                }
            else:
                # ê²€ì¶œ ì‹¤íŒ¨
                return {
                    'keypoints_18': [[0, 0, 0] for _ in range(18)],
                    'pose_confidence': 0.0,
                    'keypoints_detected': 0,
                    'pose_angles': {},
                    'body_proportions': {},
                    'detection_method': 'yolov8_failed'
                }
                
        except Exception as e:
            self.logger.error(f"YOLOv8 í¬ì¦ˆ ì¶”ì • ì‹¤íŒ¨: {e}")
            return await self._simulation_estimation(image, **kwargs)
    
    async def _openpose_estimation(self, image: np.ndarray, **kwargs) -> Dict[str, Any]:
        """OpenPose í¬ì¦ˆ ì¶”ì • (ModelLoader í†µí•©)"""
        try:
            # ModelLoader ì¸í„°íŽ˜ì´ìŠ¤ë¥¼ í†µí•œ OpenPose ëª¨ë¸ ë¡œë“œ
            if self.model_interface:
                openpose_model = await self._get_model_safe("pose_estimation_openpose")
                
                if openpose_model and TORCH_AVAILABLE:
                    # ì´ë¯¸ì§€ ì „ì²˜ë¦¬
                    tensor_input = self._manual_preprocess_for_openpose(image)
                    
                    # ëª¨ë¸ ì¶”ë¡ 
                    with torch.no_grad():
                        if self.device == "cuda":
                            with autocast(device_type='cuda', dtype=torch.float16):
                                output = openpose_model(tensor_input)
                        else:
                            output = openpose_model(tensor_input)
                    
                    # í›„ì²˜ë¦¬
                    keypoints_18 = self._postprocess_openpose_output(output, image.shape)
                    
                    # ë©”íŠ¸ë¦­ ê³„ì‚°
                    confidences = [kp[2] for kp in keypoints_18]
                    pose_confidence = np.mean([c for c in confidences if c > 0])
                    keypoints_detected = sum(1 for c in confidences if c > self.pose_config['confidence_threshold'])
                    
                    return {
                        'keypoints_18': keypoints_18,
                        'pose_confidence': float(pose_confidence),
                        'keypoints_detected': keypoints_detected,
                        'pose_angles': self._calculate_pose_angles(keypoints_18),
                        'body_proportions': self._calculate_body_proportions(keypoints_18),
                        'detection_method': 'openpose'
                    }
            
            # ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨ ì‹œ ì‹œë®¬ë ˆì´ì…˜
            return await self._simulation_estimation(image, **kwargs)
            
        except Exception as e:
            self.logger.error(f"OpenPose í¬ì¦ˆ ì¶”ì • ì‹¤íŒ¨: {e}")
            return await self._simulation_estimation(image, **kwargs)
    
    async def _simulation_estimation(self, image: np.ndarray, **kwargs) -> Dict[str, Any]:
        """ì‹œë®¬ë ˆì´ì…˜ í¬ì¦ˆ ì¶”ì • (í´ë°±)"""
        try:
            h, w = image.shape[:2]
            
            # ì‹œë®¬ë ˆì´ì…˜ëœ í‚¤í¬ì¸íŠ¸ ìƒì„± (í•´ë¶€í•™ì ìœ¼ë¡œ íƒ€ë‹¹í•œ ìœ„ì¹˜)
            keypoints_18 = []
            
            # ê¸°ë³¸ ì¸ì²´ ë¹„ìœ¨ ì‚¬ìš©
            head_y = h * 0.15
            neck_y = h * 0.20
            shoulder_y = h * 0.25
            elbow_y = h * 0.40
            wrist_y = h * 0.55
            hip_y = h * 0.55
            knee_y = h * 0.75
            ankle_y = h * 0.95
            
            center_x = w * 0.5
            shoulder_width = w * 0.15
            hip_width = w * 0.12
            
            # 18ê°œ í‚¤í¬ì¸íŠ¸ ì‹œë®¬ë ˆì´ì…˜
            simulated_points = [
                [center_x, head_y, 0.95],                    # 0: nose
                [center_x, neck_y, 0.90],                    # 1: neck
                [center_x + shoulder_width, shoulder_y, 0.85], # 2: right_shoulder
                [center_x + shoulder_width * 1.5, elbow_y, 0.80], # 3: right_elbow
                [center_x + shoulder_width * 1.8, wrist_y, 0.75], # 4: right_wrist
                [center_x - shoulder_width, shoulder_y, 0.85], # 5: left_shoulder
                [center_x - shoulder_width * 1.5, elbow_y, 0.80], # 6: left_elbow
                [center_x - shoulder_width * 1.8, wrist_y, 0.75], # 7: left_wrist
                [center_x, hip_y, 0.90],                      # 8: mid_hip
                [center_x + hip_width, hip_y, 0.85],          # 9: right_hip
                [center_x + hip_width, knee_y, 0.80],         # 10: right_knee
                [center_x + hip_width, ankle_y, 0.75],        # 11: right_ankle
                [center_x - hip_width, hip_y, 0.85],          # 12: left_hip
                [center_x - hip_width, knee_y, 0.80],         # 13: left_knee
                [center_x - hip_width, ankle_y, 0.75],        # 14: left_ankle
                [center_x + 10, head_y - 20, 0.70],           # 15: right_eye
                [center_x - 10, head_y - 20, 0.70],           # 16: left_eye
                [center_x + 15, head_y - 10, 0.65]            # 17: right_ear
            ]
            
            # ì¢Œí‘œ ì •ìˆ˜ ë³€í™˜ ë° ë²”ìœ„ ì²´í¬
            for point in simulated_points:
                point[0] = max(0, min(w-1, int(point[0])))
                point[1] = max(0, min(h-1, int(point[1])))
            
            keypoints_18 = simulated_points[:18]  # 18ê°œë§Œ ì‚¬ìš©
            
            # ë©”íŠ¸ë¦­ ê³„ì‚°
            confidences = [kp[2] for kp in keypoints_18]
            pose_confidence = np.mean(confidences)
            keypoints_detected = len([c for c in confidences if c > self.pose_config['confidence_threshold']])
            
            return {
                'keypoints_18': keypoints_18,
                'pose_confidence': float(pose_confidence),
                'keypoints_detected': keypoints_detected,
                'pose_angles': self._calculate_pose_angles(keypoints_18),
                'body_proportions': self._calculate_body_proportions(keypoints_18),
                'detection_method': 'simulation'
            }
            
        except Exception as e:
            self.logger.error(f"ì‹œë®¬ë ˆì´ì…˜ í¬ì¦ˆ ì¶”ì • ì‹¤íŒ¨: {e}")
            return {
                'keypoints_18': [[0, 0, 0] for _ in range(18)],
                'pose_confidence': 0.0,
                'keypoints_detected': 0,
                'pose_angles': {},
                'body_proportions': {},
                'detection_method': 'failed'
            }
    
    # =================================================================
    # ðŸ”§ í›„ì²˜ë¦¬ ë° ë¶„ì„ í•¨ìˆ˜ë“¤
    # =================================================================
    
    async def _postprocess_pose_results(self, pose_results: Dict[str, Any], image_shape: Tuple[int, int], **kwargs) -> Dict[str, Any]:
        """í¬ì¦ˆ ê²°ê³¼ í›„ì²˜ë¦¬"""
        try:
            # 1. í‚¤í¬ì¸íŠ¸ ì •ê·œí™” ë° ê²€ì¦
            keypoints_18 = pose_results.get('keypoints_18', [[0, 0, 0] for _ in range(18)])
            keypoints_18 = self._validate_and_normalize_keypoints(keypoints_18, image_shape)
            
            # 2. ì¶”ê°€ ë©”íŠ¸ë¦­ ê³„ì‚°
            detection_rate = pose_results.get('keypoints_detected', 0) / 18.0
            major_keypoints_rate = self._calculate_major_keypoints_rate(keypoints_18)
            average_confidence = pose_results.get('pose_confidence', 0.0)
            symmetry_score = self._calculate_symmetry_score(keypoints_18)
            visibility_score = self._calculate_visibility_score(keypoints_18)
            
            # 3. ê²°ê³¼ ì—…ë°ì´íŠ¸
            pose_results.update({
                'keypoints_18': keypoints_18,
                'detection_rate': detection_rate,
                'major_keypoints_rate': major_keypoints_rate,
                'average_confidence': average_confidence,
                'symmetry_score': symmetry_score,
                'visibility_score': visibility_score
            })
            
            return pose_results
            
        except Exception as e:
            self.logger.error(f"í¬ì¦ˆ í›„ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return pose_results
    
    async def _analyze_pose_quality(self, pose_results: Dict[str, Any], clothing_type: str, **kwargs) -> Dict[str, Any]:
        """í¬ì¦ˆ í’ˆì§ˆ ë¶„ì„"""
        try:
            keypoints_18 = pose_results.get('keypoints_18', [[0, 0, 0] for _ in range(18)])
            
            # 1. ê¸°ë³¸ í’ˆì§ˆ ë©”íŠ¸ë¦­
            quality_metrics = {
                'detection_rate': pose_results.get('detection_rate', 0.0),
                'major_keypoints_rate': pose_results.get('major_keypoints_rate', 0.0),
                'average_confidence': pose_results.get('average_confidence', 0.0),
                'symmetry_score': pose_results.get('symmetry_score', 0.0),
                'visibility_score': pose_results.get('visibility_score', 0.0)
            }
            
            # 2. í¬ì¦ˆ íƒ€ìž… ë¶„ë¥˜
            pose_angles = pose_results.get('pose_angles', {})
            pose_type = self._classify_pose_type(keypoints_18, pose_angles)
            
            # 3. ì˜ë¥˜ë³„ ì í•©ì„± í‰ê°€
            clothing_weights = self.CLOTHING_POSE_WEIGHTS.get(clothing_type, self.CLOTHING_POSE_WEIGHTS['default'])
            clothing_score = self._calculate_clothing_specific_score(keypoints_18, clothing_weights)
            
            # 4. ì „ì²´ ì ìˆ˜ ê³„ì‚°
            overall_score = (
                quality_metrics['detection_rate'] * 0.3 +
                quality_metrics['average_confidence'] * 0.25 +
                quality_metrics['symmetry_score'] * 0.2 +
                quality_metrics['visibility_score'] * 0.15 +
                clothing_score * 0.1
            )
            
            # 5. ë“±ê¸‰ ê²°ì •
            if overall_score >= 0.9:
                quality_grade = "A+"
            elif overall_score >= 0.8:
                quality_grade = "A"
            elif overall_score >= 0.7:
                quality_grade = "B"
            elif overall_score >= 0.6:
                quality_grade = "C"
            elif overall_score >= 0.5:
                quality_grade = "D"
            else:
                quality_grade = "F"
            
            # 6. í”¼íŒ… ì í•©ì„±
            suitable_for_fitting = (
                quality_metrics['detection_rate'] >= 0.7 and
                overall_score >= 0.6 and
                pose_type not in ['unknown', 'sitting']
            )
            
            return {
                'pose_type': pose_type,
                'overall_score': overall_score,
                'quality_grade': quality_grade,
                'suitable_for_fitting': suitable_for_fitting,
                'fitting_confidence': min(overall_score * 1.2, 1.0),
                'quality_metrics': quality_metrics,
                'clothing_score': clothing_score
            }
            
        except Exception as e:
            self.logger.error(f"í¬ì¦ˆ í’ˆì§ˆ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {
                'pose_type': 'unknown',
                'overall_score': 0.0,
                'quality_grade': 'F',
                'suitable_for_fitting': False,
                'fitting_confidence': 0.0
            }
    
    async def _create_pose_visualization(self, pose_results: Dict[str, Any], original_image: np.ndarray, **kwargs) -> Dict[str, Any]:
        """í¬ì¦ˆ ì‹œê°í™” ìƒì„±"""
        try:
            if not self.pose_config['visualization_enabled']:
                return pose_results
            
            keypoints_18 = pose_results.get('keypoints_18', [[0, 0, 0] for _ in range(18)])
            
            # 1. í‚¤í¬ì¸íŠ¸ë§Œ í‘œì‹œí•œ ì´ë¯¸ì§€
            keypoint_image = self._draw_keypoints_only(original_image.copy(), keypoints_18)
            
            # 2. ìŠ¤ì¼ˆë ˆí†¤ ì—°ê²° ì´ë¯¸ì§€
            skeleton_image = self._draw_skeleton(original_image.copy(), keypoints_18)
            
            # 3. ì˜¤ë²„ë ˆì´ ì´ë¯¸ì§€ (ì›ë³¸ + í‚¤í¬ì¸íŠ¸ + ìŠ¤ì¼ˆë ˆí†¤)
            overlay_image = self._draw_full_pose_overlay(original_image.copy(), keypoints_18)
            
            # 4. ì´ë¯¸ì§€ë¥¼ base64ë¡œ ì¸ì½”ë”©
            visualization_results = {}
            
            if PIL_AVAILABLE:
                try:
                    # í‚¤í¬ì¸íŠ¸ ì´ë¯¸ì§€
                    pil_keypoint = Image.fromarray(keypoint_image)
                    keypoint_buffer = io.BytesIO()
                    pil_keypoint.save(keypoint_buffer, format='PNG')
                    visualization_results['keypoint_image'] = base64.b64encode(keypoint_buffer.getvalue()).decode()
                    
                    # ìŠ¤ì¼ˆë ˆí†¤ ì´ë¯¸ì§€
                    pil_skeleton = Image.fromarray(skeleton_image)
                    skeleton_buffer = io.BytesIO()
                    pil_skeleton.save(skeleton_buffer, format='PNG')
                    visualization_results['skeleton_image'] = base64.b64encode(skeleton_buffer.getvalue()).decode()
                    
                    # ì˜¤ë²„ë ˆì´ ì´ë¯¸ì§€
                    pil_overlay = Image.fromarray(overlay_image)
                    overlay_buffer = io.BytesIO()
                    pil_overlay.save(overlay_buffer, format='PNG')
                    visualization_results['overlay_image'] = base64.b64encode(overlay_buffer.getvalue()).decode()
                    
                except Exception as e:
                    self.logger.warning(f"ì´ë¯¸ì§€ ì¸ì½”ë”© ì‹¤íŒ¨: {e}")
                    visualization_results = {
                        'keypoint_image': "",
                        'skeleton_image': "",
                        'overlay_image': ""
                    }
            else:
                visualization_results = {
                    'keypoint_image': "",
                    'skeleton_image': "",
                    'overlay_image': ""
                }
            
            # ê²°ê³¼ì— ì‹œê°í™” ì¶”ê°€
            pose_results.update(visualization_results)
            
            return pose_results
            
        except Exception as e:
            self.logger.error(f"í¬ì¦ˆ ì‹œê°í™” ìƒì„± ì‹¤íŒ¨: {e}")
            pose_results.update({
                'keypoint_image': "",
                'skeleton_image': "",
                'overlay_image': ""
            })
            return pose_results
    
    # =================================================================
    # ðŸ”§ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
    # =================================================================
    
    async def _get_model_safe(self, model_name: str) -> Optional[Any]:
        """ì•ˆì „í•œ ëª¨ë¸ ë¡œë“œ"""
        try:
            if self.model_interface:
                return await self.model_interface.get_model(model_name)
            else:
                return None
        except Exception as e:
            self.logger.debug(f"ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {model_name} - {e}")
            return None
    
    async def _optimize_memory(self):
        """ë©”ëª¨ë¦¬ ìµœì í™”"""
        try:
            if self.memory_manager:
                await self.memory_manager.optimize_memory_usage()
            elif TORCH_AVAILABLE and self.device == "mps":
                torch.mps.empty_cache()
            elif TORCH_AVAILABLE and self.device == "cuda":
                torch.cuda.empty_cache()
            
            gc.collect()
        except Exception as e:
            self.logger.debug(f"ë©”ëª¨ë¦¬ ìµœì í™” ì‹¤íŒ¨: {e}")
    
    def _load_and_validate_image(self, image_input: Union[np.ndarray, str, Path]) -> Optional[np.ndarray]:
        """ì´ë¯¸ì§€ ë¡œë“œ ë° ê²€ì¦"""
        try:
            if isinstance(image_input, np.ndarray):
                image = image_input
            elif isinstance(image_input, (str, Path)):
                if PIL_AVAILABLE:
                    pil_img = Image.open(image_input)
                    image = np.array(pil_img.convert('RGB'))
                elif CV2_AVAILABLE:
                    image = cv2.imread(str(image_input))
                    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
                else:
                    raise ImportError("PIL ë˜ëŠ” OpenCVê°€ í•„ìš”í•©ë‹ˆë‹¤")
            else:
                raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì´ë¯¸ì§€ íƒ€ìž…: {type(image_input)}")
            
            # ê²€ì¦
            if len(image.shape) != 3 or image.shape[2] != 3:
                raise ValueError("RGB ì´ë¯¸ì§€ì—¬ì•¼ í•©ë‹ˆë‹¤")
            
            if image.shape[0] == 0 or image.shape[1] == 0:
                raise ValueError("ë¹ˆ ì´ë¯¸ì§€ìž…ë‹ˆë‹¤")
            
            return image
            
        except Exception as e:
            self.logger.error(f"ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return None
    
    def _generate_cache_key(self, image: np.ndarray, clothing_type: str, kwargs: Dict[str, Any]) -> str:
        """ìºì‹œ í‚¤ ìƒì„±"""
        try:
            # ì´ë¯¸ì§€ í•´ì‹œ
            image_hash = hashlib.md5(image.tobytes()).hexdigest()[:16]
            
            # ì„¤ì • í•´ì‹œ
            config_data = {
                'clothing_type': clothing_type,
                'confidence_threshold': self.pose_config['confidence_threshold'],
                'active_model': self.active_model,
                **{k: v for k, v in kwargs.items() if isinstance(v, (str, int, float, bool))}
            }
            config_str = json.dumps(config_data, sort_keys=True)
            config_hash = hashlib.md5(config_str.encode()).hexdigest()[:8]
            
            return f"pose_{image_hash}_{config_hash}"
            
        except Exception as e:
            return f"pose_fallback_{time.time()}"
    
    def _save_to_cache(self, cache_key: str, result: Dict[str, Any]):
        """ìºì‹œì— ê²°ê³¼ ì €ìž¥"""
        try:
            if len(self.prediction_cache) >= self.cache_max_size:
                # LRU ë°©ì‹ìœ¼ë¡œ ì˜¤ëž˜ëœ í•­ëª© ì œê±°
                oldest_key = min(self.prediction_cache.keys())
                del self.prediction_cache[oldest_key]
                self.logger.debug(f"ìºì‹œ í•­ëª© ì œê±°: {oldest_key}")
            
            # ë©”ëª¨ë¦¬ ì ˆì•½ì„ ìœ„í•´ ì‹œê°í™” ì´ë¯¸ì§€ëŠ” ìºì‹œì—ì„œ ì œì™¸
            cached_result = result.copy()
            for viz_key in ['keypoint_image', 'skeleton_image', 'overlay_image']:
                if viz_key in cached_result:
                    cached_result[viz_key] = ""
            
            self.prediction_cache[cache_key] = cached_result
            self.logger.debug(f"ìºì‹œ ì €ìž¥ ì™„ë£Œ: {cache_key}")
            
        except Exception as e:
            self.logger.warning(f"ìºì‹œ ì €ìž¥ ì‹¤íŒ¨: {e}")
    
    def clear_cache(self) -> Dict[str, Any]:
        """ìºì‹œ ì™„ì „ ì‚­ì œ"""
        try:
            if hasattr(self, 'prediction_cache'):
                cache_size = len(self.prediction_cache)
                self.prediction_cache.clear()
                self.logger.info(f"âœ… ìºì‹œ ì‚­ì œ ì™„ë£Œ: {cache_size}ê°œ í•­ëª©")
                return {"success": True, "cleared_items": cache_size}
            else:
                return {"success": True, "cleared_items": 0}
        except Exception as e:
            self.logger.error(f"âŒ ìºì‹œ ì‚­ì œ ì‹¤íŒ¨: {e}")
            return {"success": False, "error": str(e)}
    
    def get_cache_status(self) -> Dict[str, Any]:
        """ìºì‹œ ìƒíƒœ ì¡°íšŒ"""
        try:
            if hasattr(self, 'prediction_cache'):
                return {
                    "cache_enabled": self.pose_config.get('cache_enabled', False),
                    "current_size": len(self.prediction_cache),
                    "max_size": self.cache_max_size,
                    "hit_rate": self.performance_stats['cache_hits'] / max(1, self.performance_stats['cache_hits'] + self.performance_stats['cache_misses']),
                    "cache_hits": self.performance_stats['cache_hits'],
                    "cache_misses": self.performance_stats['cache_misses']
                }
            else:
                return {"cache_enabled": False, "current_size": 0}
        except Exception as e:
            self.logger.error(f"ìºì‹œ ìƒíƒœ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {"error": str(e)}
    
    def _update_performance_stats(self, processing_time: float, confidence_score: float, success: bool = True):
        """ì„±ëŠ¥ í†µê³„ ì—…ë°ì´íŠ¸"""
        try:
            if success:
                self.performance_stats['total_processed'] += 1
                self.performance_stats['total_time'] += processing_time
                self.performance_stats['average_time'] = (
                    self.performance_stats['total_time'] / self.performance_stats['total_processed']
                )
                
                # í‰ê·  ì‹ ë¢°ë„ ì—…ë°ì´íŠ¸
                current_avg = self.performance_stats.get('average_confidence', 0.0)
                total_processed = self.performance_stats['total_processed']
                self.performance_stats['average_confidence'] = (
                    (current_avg * (total_processed - 1) + confidence_score) / total_processed
                )
            else:
                self.performance_stats['error_count'] += 1
            
            self.performance_stats['last_processing_time'] = processing_time
            
            # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¶”ì  (M3 Max)
            if PSUTIL_AVAILABLE:
                try:
                    memory_usage = psutil.virtual_memory().percent
                    self.performance_stats['peak_memory_usage'] = max(
                        self.performance_stats.get('peak_memory_usage', 0),
                        memory_usage
                    )
                except Exception as e:
                    self.logger.debug(f"ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¶”ì  ì‹¤íŒ¨: {e}")
            
        except Exception as e:
            self.logger.warning(f"ì„±ëŠ¥ í†µê³„ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
    
    def _build_final_result(self, metrics: PoseMetrics, clothing_type: str, processing_time: float) -> Dict[str, Any]:
        """ìµœì¢… ê²°ê³¼ êµ¬ì„±"""
        
        try:
            return {
                "success": True,
                "step_name": self.step_name,
                "processing_time": processing_time,
                
                # í•µì‹¬ í¬ì¦ˆ ë°ì´í„°
                "keypoints_18": metrics.keypoints_18,
                "pose_confidence": float(metrics.pose_confidence),
                "keypoints_detected": metrics.keypoints_detected,
                
                # ì‹ ì²´ ì¸¡ì • ë°ì´í„°
                "body_proportions": {
                    "total_height": float(metrics.total_height),
                    "torso_length": float(metrics.torso_length),
                    "shoulder_width": float(metrics.shoulder_width),
                    "hip_width": float(metrics.hip_width),
                    "left_arm_length": float(metrics.left_arm_length),
                    "right_arm_length": float(metrics.right_arm_length),
                    "left_leg_length": float(metrics.left_leg_length),
                    "right_leg_length": float(metrics.right_leg_length)
                },
                
                # í¬ì¦ˆ ê°ë„
                "pose_angles": {
                    "left_arm_angle": float(metrics.left_arm_angle),
                    "right_arm_angle": float(metrics.right_arm_angle),
                    "left_leg_angle": float(metrics.left_leg_angle),
                    "right_leg_angle": float(metrics.right_leg_angle),
                    "spine_angle": float(metrics.spine_angle)
                },
                
                # í’ˆì§ˆ ë¶„ì„
                "pose_analysis": {
                    "detection_rate": float(metrics.detection_rate),
                    "major_keypoints_rate": float(metrics.major_keypoints_rate),
                    "average_confidence": float(metrics.average_confidence),
                    "symmetry_score": float(metrics.symmetry_score),
                    "visibility_score": float(metrics.visibility_score),
                    "pose_type": metrics.pose_type,
                    "quality_grade": metrics.quality_grade,
                    "overall_score": float(metrics.overall_score)
                },
                
                # í”¼íŒ… ì í•©ì„±
                "suitable_for_fitting": metrics.suitable_for_fitting,
                "fitting_confidence": float(metrics.fitting_confidence),
                
                # ë©”íƒ€ë°ì´í„°
                "clothing_type": clothing_type,
                "detection_method": getattr(metrics, 'detection_method', self.active_model or 'unknown'),
                
                # ì‹œìŠ¤í…œ ì •ë³´
                "device_info": {
                    "device": self.device,
                    "device_type": self.device_type,
                    "is_m3_max": self.is_m3_max,
                    "memory_gb": self.memory_gb,
                    "optimization_level": self.optimization_level,
                    "active_model": self.active_model
                },
                
                # ì„±ëŠ¥ í†µê³„
                "performance_stats": self.performance_stats.copy(),
                
                # ì‹œê°í™” ì´ë¯¸ì§€ë“¤ (create_pose_visualizationì—ì„œ ì¶”ê°€ë¨)
                "keypoint_image": "",
                "skeleton_image": "", 
                "overlay_image": "",
                
                "from_cache": False
            }
        except Exception as e:
            self.logger.error(f"ìµœì¢… ê²°ê³¼ êµ¬ì„± ì‹¤íŒ¨: {e}")
            return self._create_error_result(f"ê²°ê³¼ êµ¬ì„± ì‹¤íŒ¨: {e}", processing_time)
    
    # =================================================================
    # ðŸ”§ í¬ì¦ˆ ë¶„ì„ ë° ë³€í™˜ ìœ í‹¸ë¦¬í‹°ë“¤
    # =================================================================
    
    def _validate_and_normalize_keypoints(self, keypoints_18: List[List[float]], image_shape: Tuple[int, int]) -> List[List[float]]:
        """í‚¤í¬ì¸íŠ¸ ê²€ì¦ ë° ì •ê·œí™”"""
        try:
            h, w = image_shape[:2]
            normalized_keypoints = []
            
            for i, kp in enumerate(keypoints_18):
                if len(kp) >= 3:
                    x, y, conf = float(kp[0]), float(kp[1]), float(kp[2])
                    
                    # ì¢Œí‘œ ë²”ìœ„ ì²´í¬
                    x = max(0, min(w-1, x))
                    y = max(0, min(h-1, y))
                    
                    # ì‹ ë¢°ë„ ë²”ìœ„ ì²´í¬
                    conf = max(0.0, min(1.0, conf))
                    
                    normalized_keypoints.append([x, y, conf])
                else:
                    normalized_keypoints.append([0.0, 0.0, 0.0])
            
            # 18ê°œ í‚¤í¬ì¸íŠ¸ ë³´ìž¥
            while len(normalized_keypoints) < 18:
                normalized_keypoints.append([0.0, 0.0, 0.0])
            
            return normalized_keypoints[:18]
            
        except Exception as e:
            self.logger.error(f"í‚¤í¬ì¸íŠ¸ ì •ê·œí™” ì‹¤íŒ¨: {e}")
            return [[0.0, 0.0, 0.0] for _ in range(18)]
    
    def _calculate_major_keypoints_rate(self, keypoints_18: List[List[float]]) -> float:
        """ì£¼ìš” í‚¤í¬ì¸íŠ¸ ê²€ì¶œë¥  ê³„ì‚°"""
        try:
            # ì£¼ìš” í‚¤í¬ì¸íŠ¸: ì½”, ëª©, ì–´ê¹¨, ì—‰ë©ì´, ë¬´ë¦Ž
            major_indices = [0, 1, 2, 5, 8, 9, 10, 12, 13]
            detected_major = sum(1 for idx in major_indices if keypoints_18[idx][2] > self.pose_config['confidence_threshold'])
            return detected_major / len(major_indices)
        except Exception as e:
            self.logger.debug(f"ì£¼ìš” í‚¤í¬ì¸íŠ¸ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return 0.0
    
    def _calculate_symmetry_score(self, keypoints_18: List[List[float]]) -> float:
        """ì‹ ì²´ ëŒ€ì¹­ì„± ì ìˆ˜ ê³„ì‚°"""
        try:
            symmetry_pairs = [
                (2, 5),   # ì–´ê¹¨
                (3, 6),   # íŒ”ê¿ˆì¹˜
                (4, 7),   # ì†ëª©
                (9, 12),  # ì—‰ë©ì´
                (10, 13), # ë¬´ë¦Ž
                (11, 14), # ë°œëª©
                (15, 16)  # ëˆˆ
            ]
            
            symmetry_scores = []
            
            for left_idx, right_idx in symmetry_pairs:
                if left_idx < len(keypoints_18) and right_idx < len(keypoints_18):
                    left_kp = keypoints_18[left_idx]
                    right_kp = keypoints_18[right_idx]
                    
                    if left_kp[2] > 0.5 and right_kp[2] > 0.5:
                        # Y ì¢Œí‘œ ì°¨ì´ë¡œ ëŒ€ì¹­ì„± ê³„ì‚° (ìˆ˜í‰ ëŒ€ì¹­)
                        y_diff = abs(left_kp[1] - right_kp[1])
                        max_y = max(left_kp[1], right_kp[1])
                        if max_y > 0:
                            symmetry = 1.0 - min(y_diff / max_y, 1.0)
                            symmetry_scores.append(symmetry)
            
            return np.mean(symmetry_scores) if symmetry_scores else 0.5
            
        except Exception as e:
            self.logger.warning(f"ëŒ€ì¹­ì„± ê³„ì‚° ì‹¤íŒ¨: {e}")
            return 0.5
    
    def _calculate_visibility_score(self, keypoints_18: List[List[float]]) -> float:
        """ê°€ì‹œì„± ì ìˆ˜ ê³„ì‚°"""
        try:
            visible_count = sum(1 for kp in keypoints_18 if kp[2] > 0.3)
            return visible_count / 18.0
        except Exception as e:
            self.logger.debug(f"ê°€ì‹œì„± ê³„ì‚° ì‹¤íŒ¨: {e}")
            return 0.0
    
    def _calculate_pose_angles(self, keypoints_18: List[List[float]]) -> Dict[str, float]:
        """í¬ì¦ˆ ê°ë„ ê³„ì‚°"""
        try:
            angles = {}
            
            # ì™¼íŒ” ê°ë„ (ì–´ê¹¨-íŒ”ê¿ˆì¹˜-ì†ëª©)
            if all(keypoints_18[i][2] > 0.5 for i in [5, 6, 7]):
                shoulder = np.array(keypoints_18[5][:2])
                elbow = np.array(keypoints_18[6][:2])
                wrist = np.array(keypoints_18[7][:2])
                angles['left_arm_angle'] = self._calculate_angle(shoulder, elbow, wrist)
            
            # ì˜¤ë¥¸íŒ” ê°ë„
            if all(keypoints_18[i][2] > 0.5 for i in [2, 3, 4]):
                shoulder = np.array(keypoints_18[2][:2])
                elbow = np.array(keypoints_18[3][:2])
                wrist = np.array(keypoints_18[4][:2])
                angles['right_arm_angle'] = self._calculate_angle(shoulder, elbow, wrist)
            
            # ì™¼ë‹¤ë¦¬ ê°ë„ (ì—‰ë©ì´-ë¬´ë¦Ž-ë°œëª©)
            if all(keypoints_18[i][2] > 0.5 for i in [12, 13, 14]):
                hip = np.array(keypoints_18[12][:2])
                knee = np.array(keypoints_18[13][:2])
                ankle = np.array(keypoints_18[14][:2])
                angles['left_leg_angle'] = self._calculate_angle(hip, knee, ankle)
            
            # ì˜¤ë¥¸ë‹¤ë¦¬ ê°ë„
            if all(keypoints_18[i][2] > 0.5 for i in [9, 10, 11]):
                hip = np.array(keypoints_18[9][:2])
                knee = np.array(keypoints_18[10][:2])
                ankle = np.array(keypoints_18[11][:2])
                angles['right_leg_angle'] = self._calculate_angle(hip, knee, ankle)
            
            # ì²™ì¶” ê°ë„ (ëª©-ì¤‘ê°„ì—‰ë©ì´ ê¸°ì¤€)
            if all(keypoints_18[i][2] > 0.5 for i in [1, 8]):
                neck = np.array(keypoints_18[1][:2])
                mid_hip = np.array(keypoints_18[8][:2])
                # ìˆ˜ì§ ê¸°ì¤€ìœ¼ë¡œ ê¸°ìš¸ì–´ì§„ ì •ë„
                vertical = np.array([0, 1])
                spine_vector = mid_hip - neck
                if np.linalg.norm(spine_vector) > 0:
                    spine_vector = spine_vector / np.linalg.norm(spine_vector)
                    dot_product = np.dot(spine_vector, vertical)
                    angles['spine_angle'] = math.degrees(math.acos(np.clip(dot_product, -1, 1)))
            
            return angles
            
        except Exception as e:
            self.logger.warning(f"í¬ì¦ˆ ê°ë„ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return {}
    
    def _calculate_angle(self, point1: np.ndarray, point2: np.ndarray, point3: np.ndarray) -> float:
        """ì„¸ ì ìœ¼ë¡œ ê°ë„ ê³„ì‚°"""
        try:
            # ë²¡í„° ê³„ì‚°
            v1 = point1 - point2
            v2 = point3 - point2
            
            # ê°ë„ ê³„ì‚° (ë¼ë””ì•ˆ -> ë„)
            cos_angle = np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))
            cos_angle = np.clip(cos_angle, -1, 1)
            angle = math.degrees(math.acos(cos_angle))
            
            return float(angle)
            
        except Exception as e:
            return 180.0  # ê¸°ë³¸ ê°ë„
    
    def _calculate_body_proportions(self, keypoints_18: List[List[float]]) -> Dict[str, float]:
        """ì‹ ì²´ ë¹„ìœ¨ ê³„ì‚°"""
        try:
            proportions = {}
            
            # ì „ì²´ ì‹ ìž¥ (ë¨¸ë¦¬-ë°œëª©)
            if keypoints_18[0][2] > 0.5:
                head_y = keypoints_18[0][1]
                ankle_y = max(keypoints_18[11][1] if keypoints_18[11][2] > 0.5 else 0,
                            keypoints_18[14][1] if keypoints_18[14][2] > 0.5 else 0)
                if ankle_y > head_y:
                    proportions['total_height'] = ankle_y - head_y
            
            # ìƒì²´ ê¸¸ì´ (ëª©-ì—‰ë©ì´)
            if keypoints_18[1][2] > 0.5 and keypoints_18[8][2] > 0.5:
                proportions['torso_length'] = abs(keypoints_18[8][1] - keypoints_18[1][1])
            
            # ì–´ê¹¨ ë„ˆë¹„
            if keypoints_18[2][2] > 0.5 and keypoints_18[5][2] > 0.5:
                proportions['shoulder_width'] = abs(keypoints_18[2][0] - keypoints_18[5][0])
            
            # ì—‰ë©ì´ ë„ˆë¹„
            if keypoints_18[9][2] > 0.5 and keypoints_18[12][2] > 0.5:
                proportions['hip_width'] = abs(keypoints_18[9][0] - keypoints_18[12][0])
            
            # íŒ” ê¸¸ì´ (ì–´ê¹¨-ì†ëª©)
            if keypoints_18[4][2] > 0.5 and keypoints_18[2][2] > 0.5:
                right_arm_length = np.sqrt(
                    (keypoints_18[4][0] - keypoints_18[2][0])**2 + 
                    (keypoints_18[4][1] - keypoints_18[2][1])**2
                )
                proportions['right_arm_length'] = right_arm_length
            
            if keypoints_18[7][2] > 0.5 and keypoints_18[5][2] > 0.5:
                left_arm_length = np.sqrt(
                    (keypoints_18[7][0] - keypoints_18[5][0])**2 + 
                    (keypoints_18[7][1] - keypoints_18[5][1])**2
                )
                proportions['left_arm_length'] = left_arm_length
            
            # ë‹¤ë¦¬ ê¸¸ì´ (ì—‰ë©ì´-ë°œëª©)
            if keypoints_18[11][2] > 0.5 and keypoints_18[9][2] > 0.5:
                right_leg_length = np.sqrt(
                    (keypoints_18[11][0] - keypoints_18[9][0])**2 + 
                    (keypoints_18[11][1] - keypoints_18[9][1])**2
                )
                proportions['right_leg_length'] = right_leg_length
            
            if keypoints_18[14][2] > 0.5 and keypoints_18[12][2] > 0.5:
                left_leg_length = np.sqrt(
                    (keypoints_18[14][0] - keypoints_18[12][0])**2 + 
                    (keypoints_18[14][1] - keypoints_18[12][1])**2
                )
                proportions['left_leg_length'] = left_leg_length
            
            return proportions
            
        except Exception as e:
            self.logger.warning(f"ì‹ ì²´ ë¹„ìœ¨ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return {}
    
    def _classify_pose_type(self, keypoints_18: List[List[float]], pose_angles: Dict[str, float]) -> str:
        """í¬ì¦ˆ íƒ€ìž… ë¶„ë¥˜"""
        try:
            # íŒ” ê°ë„ ê¸°ë°˜ ë¶„ë¥˜
            right_arm = pose_angles.get('right_arm_angle', 180)
            left_arm = pose_angles.get('left_arm_angle', 180)
            
            # T-í¬ì¦ˆ (íŒ”ì´ ìˆ˜í‰)
            if 160 <= right_arm <= 180 and 160 <= left_arm <= 180:
                return PoseType.T_POSE.value
            
            # A-í¬ì¦ˆ (íŒ”ì´ ì•½ê°„ ì•„ëž˜)
            elif 140 <= right_arm < 160 and 140 <= left_arm < 160:
                return PoseType.A_POSE.value
            
            # íŒ” ì˜¬ë¦° í¬ì¦ˆ
            elif right_arm < 90 or left_arm < 90:
                return PoseType.ARMS_UP.value
            
            # ë‹¤ë¦¬ ìƒíƒœ í™•ì¸
            right_leg = pose_angles.get('right_leg_angle', 180)
            left_leg = pose_angles.get('left_leg_angle', 180)
            
            # ì•‰ì€ í¬ì¦ˆ
            if right_leg < 120 and left_leg < 120:
                return PoseType.SITTING.value
            
            # ê±·ê¸°/ë›°ê¸° (ë‹¤ë¦¬ ë¹„ëŒ€ì¹­)
            elif abs(right_leg - left_leg) > 30:
                return PoseType.WALKING.value
            
            # ê¸°ë³¸ ì„œìžˆëŠ” í¬ì¦ˆ
            else:
                return PoseType.STANDING.value
                
        except Exception as e:
            self.logger.warning(f"í¬ì¦ˆ íƒ€ìž… ë¶„ë¥˜ ì‹¤íŒ¨: {e}")
            return PoseType.UNKNOWN.value
    
    def _calculate_clothing_specific_score(self, keypoints_18: List[List[float]], weights: Dict[str, float]) -> float:
        """ì˜ë¥˜ë³„ íŠ¹í™” ì ìˆ˜ ê³„ì‚°"""
        try:
            scores = {}
            
            # íŒ” ì˜ì—­ ì ìˆ˜
            arm_keypoints = [2, 3, 4, 5, 6, 7]  # ì–´ê¹¨, íŒ”ê¿ˆì¹˜, ì†ëª©
            arm_detected = sum(1 for idx in arm_keypoints if keypoints_18[idx][2] > 0.5)
            scores['arms'] = arm_detected / len(arm_keypoints)
            
            # ìƒì²´ ì˜ì—­ ì ìˆ˜
            torso_keypoints = [1, 2, 5, 8]  # ëª©, ì–´ê¹¨, ì—‰ë©ì´
            torso_detected = sum(1 for idx in torso_keypoints if keypoints_18[idx][2] > 0.5)
            scores['torso'] = torso_detected / len(torso_keypoints)
            
            # ë‹¤ë¦¬ ì˜ì—­ ì ìˆ˜
            leg_keypoints = [9, 10, 11, 12, 13, 14]  # ì—‰ë©ì´, ë¬´ë¦Ž, ë°œëª©
            leg_detected = sum(1 for idx in leg_keypoints if keypoints_18[idx][2] > 0.5)
            scores['legs'] = leg_detected / len(leg_keypoints)
            
            # ê°€ì‹œì„± ì ìˆ˜
            total_visible = sum(1 for kp in keypoints_18 if kp[2] > 0.3)
            scores['visibility'] = total_visible / 18.0
            
            # ê°€ì¤‘ í‰ê·  ê³„ì‚°
            weighted_score = sum(scores.get(key, 0) * weight for key, weight in weights.items())
            return weighted_score
            
        except Exception as e:
            self.logger.warning(f"ì˜ë¥˜ë³„ ì ìˆ˜ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return 0.5
    
    # =================================================================
    # ðŸŽ¨ ì‹œê°í™” í•¨ìˆ˜ë“¤
    # =================================================================
    
    def _draw_keypoints_only(self, image: np.ndarray, keypoints_18: List[List[float]]) -> np.ndarray:
        """í‚¤í¬ì¸íŠ¸ë§Œ ê·¸ë¦¬ê¸°"""
        try:
            result_image = image.copy()
            
            for i, (x, y, conf) in enumerate(keypoints_18):
                if conf > 0.3:
                    color = KEYPOINT_COLORS[i % len(KEYPOINT_COLORS)]
                    
                    if CV2_AVAILABLE:
                        cv2.circle(result_image, (int(x), int(y)), 5, color, -1)
                        cv2.circle(result_image, (int(x), int(y)), 7, (255, 255, 255), 2)
                        
                        # í‚¤í¬ì¸íŠ¸ ë¼ë²¨ ì¶”ê°€
                        label = OPENPOSE_18_KEYPOINTS.get(i, f"kp_{i}")
                        cv2.putText(result_image, label, (int(x)+10, int(y)-10), 
                                    cv2.FONT_HERSHEY_SIMPLEX, 0.4, color, 1)
            
            return result_image
            
        except Exception as e:
            self.logger.error(f"í‚¤í¬ì¸íŠ¸ ê·¸ë¦¬ê¸° ì‹¤íŒ¨: {e}")
            return image
    
    def _draw_skeleton(self, image: np.ndarray, keypoints_18: List[List[float]]) -> np.ndarray:
        """ìŠ¤ì¼ˆë ˆí†¤ ì—°ê²° ê·¸ë¦¬ê¸°"""
        try:
            result_image = image.copy()
            
            for i, (start_idx, end_idx) in enumerate(SKELETON_CONNECTIONS):
                if start_idx < len(keypoints_18) and end_idx < len(keypoints_18):
                    start_kp = keypoints_18[start_idx]
                    end_kp = keypoints_18[end_idx]
                    
                    if start_kp[2] > 0.3 and end_kp[2] > 0.3:
                        color = SKELETON_COLORS[i % len(SKELETON_COLORS)]
                        
                        if CV2_AVAILABLE:
                            cv2.line(result_image, 
                                    (int(start_kp[0]), int(start_kp[1])),
                                    (int(end_kp[0]), int(end_kp[1])),
                                    color, 3)
            
            return result_image
            
        except Exception as e:
            self.logger.error(f"ìŠ¤ì¼ˆë ˆí†¤ ê·¸ë¦¬ê¸° ì‹¤íŒ¨: {e}")
            return image
    
    def _draw_full_pose_overlay(self, image: np.ndarray, keypoints_18: List[List[float]]) -> np.ndarray:
        """ì™„ì „í•œ í¬ì¦ˆ ì˜¤ë²„ë ˆì´ ê·¸ë¦¬ê¸°"""
        try:
            result_image = image.copy()
            
            # 1. ìŠ¤ì¼ˆë ˆí†¤ ì—°ê²° ê·¸ë¦¬ê¸°
            result_image = self._draw_skeleton(result_image, keypoints_18)
            
            # 2. í‚¤í¬ì¸íŠ¸ ê·¸ë¦¬ê¸°
            for i, (x, y, conf) in enumerate(keypoints_18):
                if conf > 0.3:
                    color = KEYPOINT_COLORS[i % len(KEYPOINT_COLORS)]
                    
                    if CV2_AVAILABLE:
                        # í‚¤í¬ì¸íŠ¸ ì›
                        cv2.circle(result_image, (int(x), int(y)), 6, color, -1)
                        cv2.circle(result_image, (int(x), int(y)), 8, (255, 255, 255), 2)
            
            return result_image
            
        except Exception as e:
            self.logger.error(f"í¬ì¦ˆ ì˜¤ë²„ë ˆì´ ê·¸ë¦¬ê¸° ì‹¤íŒ¨: {e}")
            return image
    
    # =================================================================
    # ðŸ”§ ëª¨ë¸ë³„ ë³€í™˜ í•¨ìˆ˜ë“¤
    # =================================================================
    
    def _convert_mediapipe_to_openpose(self, landmarks, image_shape: Tuple[int, int]) -> List[List[float]]:
        """MediaPipe ëžœë“œë§ˆí¬ë¥¼ OpenPose 18 í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
        try:
            h, w = image_shape[:2]
            keypoints_18 = [[0, 0, 0] for _ in range(18)]
            
            # MediaPipe 33ê°œ ëžœë“œë§ˆí¬ -> OpenPose 18ê°œ ë§¤í•‘
            mp_to_op_mapping = {
                0: 0,   # nose
                12: 1,  # neck (ì–´ê¹¨ ì¤‘ì ìœ¼ë¡œ ê·¼ì‚¬)
                12: 2,  # right_shoulder
                14: 3,  # right_elbow
                16: 4,  # right_wrist
                11: 5,  # left_shoulder
                13: 6,  # left_elbow
                15: 7,  # left_wrist
                24: 8,  # mid_hip (ì—‰ë©ì´ ì¤‘ì ìœ¼ë¡œ ê·¼ì‚¬)
                24: 9,  # right_hip
                26: 10, # right_knee
                28: 11, # right_ankle
                23: 12, # left_hip
                25: 13, # left_knee
                27: 14, # left_ankle
                5: 15,  # right_eye
                2: 16,  # left_eye
                8: 17   # right_ear
            }
            
            for op_idx, mp_idx in mp_to_op_mapping.items():
                if mp_idx < len(landmarks.landmark):
                    landmark = landmarks.landmark[mp_idx]
                    
                    x = landmark.x * w
                    y = landmark.y * h
                    conf = landmark.visibility if hasattr(landmark, 'visibility') else 0.8
                    
                    keypoints_18[op_idx] = [float(x), float(y), float(conf)]
            
            # ëª© ìœ„ì¹˜ ë³´ì • (ì–´ê¹¨ ì¤‘ì ìœ¼ë¡œ)
            if keypoints_18[2][2] > 0 and keypoints_18[5][2] > 0:
                neck_x = (keypoints_18[2][0] + keypoints_18[5][0]) / 2
                neck_y = (keypoints_18[2][1] + keypoints_18[5][1]) / 2
                keypoints_18[1] = [neck_x, neck_y, 0.9]
            
            # ì¤‘ê°„ ì—‰ë©ì´ ë³´ì •
            if keypoints_18[9][2] > 0 and keypoints_18[12][2] > 0:
                hip_x = (keypoints_18[9][0] + keypoints_18[12][0]) / 2
                hip_y = (keypoints_18[9][1] + keypoints_18[12][1]) / 2
                keypoints_18[8] = [hip_x, hip_y, 0.9]
            
            return keypoints_18
            
        except Exception as e:
            self.logger.error(f"MediaPipe ë³€í™˜ ì‹¤íŒ¨: {e}")
            return [[0, 0, 0] for _ in range(18)]
    
    def _convert_coco_to_openpose(self, coco_keypoints: np.ndarray, image_shape: Tuple[int, int]) -> List[List[float]]:
        """COCO 17 í‚¤í¬ì¸íŠ¸ë¥¼ OpenPose 18ë¡œ ë³€í™˜"""
        try:
            keypoints_18 = [[0, 0, 0] for _ in range(18)]
            
            # COCO 17 -> OpenPose 18 ë§¤í•‘
            coco_to_op_mapping = {
                0: 0,   # nose
                5: 2,   # right_shoulder
                7: 3,   # right_elbow
                9: 4,   # right_wrist
                6: 5,   # left_shoulder
                8: 6,   # left_elbow
                10: 7,  # left_wrist
                11: 9,  # right_hip
                13: 10, # right_knee
                15: 11, # right_ankle
                12: 12, # left_hip
                14: 13, # left_knee
                16: 14, # left_ankle
                2: 15,  # right_eye
                1: 16,  # left_eye
                4: 17   # right_ear
            }
            
            for coco_idx, op_idx in coco_to_op_mapping.items():
                if coco_idx < len(coco_keypoints):
                    if len(coco_keypoints[coco_idx]) >= 3:
                        x, y, conf = coco_keypoints[coco_idx][:3]
                        keypoints_18[op_idx] = [float(x), float(y), float(conf)]
            
            # ëª© ìœ„ì¹˜ ê³„ì‚° (ì–´ê¹¨ ì¤‘ì )
            if keypoints_18[2][2] > 0 and keypoints_18[5][2] > 0:
                neck_x = (keypoints_18[2][0] + keypoints_18[5][0]) / 2
                neck_y = (keypoints_18[2][1] + keypoints_18[5][1]) / 2 - 20  # ì•½ê°„ ìœ„ë¡œ
                keypoints_18[1] = [neck_x, neck_y, 0.9]
            
            # ì¤‘ê°„ ì—‰ë©ì´ ê³„ì‚°
            if keypoints_18[9][2] > 0 and keypoints_18[12][2] > 0:
                hip_x = (keypoints_18[9][0] + keypoints_18[12][0]) / 2
                hip_y = (keypoints_18[9][1] + keypoints_18[12][1]) / 2
                keypoints_18[8] = [hip_x, hip_y, 0.9]
            
            return keypoints_18
            
        except Exception as e:
            self.logger.error(f"COCO ë³€í™˜ ì‹¤íŒ¨: {e}")
            return [[0, 0, 0] for _ in range(18)]
    
    def _manual_preprocess_for_openpose(self, image: np.ndarray) -> Union[torch.Tensor, np.ndarray]:
        """OpenPoseìš© ìˆ˜ë™ ì „ì²˜ë¦¬"""
        try:
            # 368x368 í¬ê¸°ë¡œ ë¦¬ì‚¬ì´ì¦ˆ
            if CV2_AVAILABLE:
                resized = cv2.resize(image, (368, 368))
            else:
                # í´ë°±: ë‹¨ìˆœ í¬ê¸° ì¡°ì •
                resized = image
            
            # ì •ê·œí™”
            normalized = resized.astype(np.float32) / 255.0
            
            # í…ì„œ ë³€í™˜ [1, 3, 368, 368]
            if TORCH_AVAILABLE:
                tensor = torch.from_numpy(normalized.transpose(2, 0, 1)).unsqueeze(0)
                if self.device != "cpu":
                    tensor = tensor.to(self.device)
                return tensor
            else:
                return normalized
            
        except Exception as e:
            self.logger.error(f"OpenPose ì „ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return image
    
    def _postprocess_openpose_output(self, output: Any, image_shape: Tuple[int, int]) -> List[List[float]]:
        """OpenPose ì¶œë ¥ í›„ì²˜ë¦¬"""
        try:
            if TORCH_AVAILABLE and isinstance(output, torch.Tensor):
                # PAFì™€ ížˆíŠ¸ë§µ ë¶„ë¦¬
                if len(output.shape) == 4 and output.shape[1] >= 19:  # [1, C, H, W]
                    heatmaps = output[0, :18].cpu().numpy()  # ì²« 18ì±„ë„ì´ í‚¤í¬ì¸íŠ¸
                    
                    h, w = image_shape[:2]
                    heatmap_h, heatmap_w = heatmaps.shape[1:]
                    
                    keypoints_18 = []
                    
                    for i in range(18):
                        heatmap = heatmaps[i]
                        
                        # ìµœëŒ€ê°’ ìœ„ì¹˜ ì°¾ê¸°
                        max_idx = np.unravel_index(np.argmax(heatmap), heatmap.shape)
                        confidence = float(heatmap[max_idx])
                        
                        # ì¢Œí‘œ ë³€í™˜ (ížˆíŠ¸ë§µ -> ì›ë³¸ ì´ë¯¸ì§€)
                        x = float(max_idx[1] * w / heatmap_w)
                        y = float(max_idx[0] * h / heatmap_h)
                        
                        keypoints_18.append([x, y, confidence])
                    
                    return keypoints_18
                else:
                    self.logger.warning("ì˜ˆìƒê³¼ ë‹¤ë¥¸ OpenPose ì¶œë ¥ í˜•íƒœ")
                    return [[0, 0, 0] for _ in range(18)]
            else:
                self.logger.warning("PyTorch í…ì„œê°€ ì•„ë‹Œ ì¶œë ¥")
                return [[0, 0, 0] for _ in range(18)]
                
        except Exception as e:
            self.logger.error(f"OpenPose í›„ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return [[0, 0, 0] for _ in range(18)]
    
    # =================================================================
    # ðŸ” í‘œì¤€ ì¸í„°íŽ˜ì´ìŠ¤ ë©”ì„œë“œë“¤ (Pipeline Manager í˜¸í™˜)
    # =================================================================
    
    async def get_step_info(self) -> Dict[str, Any]:
        """Step ì •ë³´ ë°˜í™˜"""
        return {
            "step_name": "PoseEstimation",
            "class_name": self.__class__.__name__,
            "version": "5.0-complete-rewrite",
            "device": self.device,
            "device_type": self.device_type,
            "memory_gb": self.memory_gb,
            "is_m3_max": self.is_m3_max,
            "optimization_enabled": self.optimization_enabled,
            "quality_level": self.quality_level,
            "initialized": self.is_initialized,
            "initialization_error": self.initialization_error,
            "config_keys": list(self.config.keys()),
            "performance_stats": self.performance_stats.copy(),
            "capabilities": {
                "mediapipe_available": MEDIAPIPE_AVAILABLE,
                "yolov8_available": YOLO_AVAILABLE,
                "torch_available": TORCH_AVAILABLE,
                "cv2_available": CV2_AVAILABLE,
                "pil_available": PIL_AVAILABLE,
                "psutil_available": PSUTIL_AVAILABLE,
                "model_loader_available": MODEL_LOADER_AVAILABLE,
                "memory_manager_available": MEMORY_MANAGER_AVAILABLE,
                "data_converter_available": DATA_CONVERTER_AVAILABLE,
                "active_model": self.active_model,
                "visualization_enabled": self.pose_config['visualization_enabled'],
                "neural_engine_enabled": getattr(self, 'use_neural_engine', False)
            },
            "model_info": {
                "available_models": list(self.pose_models.keys()) if hasattr(self, 'pose_models') else [],
                "active_model": self.active_model,
                "model_priority": self.pose_config['model_priority'],
                "model_interface_connected": self.model_interface is not None
            },
            "processing_settings": {
                "confidence_threshold": self.pose_config['confidence_threshold'],
                "optimization_level": self.optimization_level,
                "batch_processing": self.batch_processing,
                "cache_enabled": self.pose_config['cache_enabled'],
                "cache_status": self.get_cache_status()
            }
        }
    
    def cleanup_resources(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        try:
            # í¬ì¦ˆ ëª¨ë¸ ì •ë¦¬
            if hasattr(self, 'pose_models'):
                for model_name, model in self.pose_models.items():
                    if hasattr(model, 'close'):
                        model.close()
                    del model
                self.pose_models.clear()
            
            # ìºì‹œ ì •ë¦¬
            self.clear_cache()
            
            # ModelLoader ì¸í„°íŽ˜ì´ìŠ¤ ì •ë¦¬
            if self.model_interface:
                try:
                    if hasattr(self.model_interface, 'unload_models'):
                        self.model_interface.unload_models()
                except Exception as e:
                    self.logger.debug(f"ëª¨ë¸ ì¸í„°íŽ˜ì´ìŠ¤ ì •ë¦¬ ì‹¤íŒ¨: {e}")
            
            # ë©”ëª¨ë¦¬ ì •ë¦¬
            if TORCH_AVAILABLE:
                if self.device == "mps":
                    torch.mps.empty_cache()
                elif self.device == "cuda":
                    torch.cuda.empty_cache()
            
            gc.collect()
            
            self.logger.info("âœ… PoseEstimationStep ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì™„ë£Œ")
            
        except Exception as e:
            self.logger.error(f"âŒ ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì‹¤íŒ¨: {e}")
    
    def __del__(self):
        """ì†Œë©¸ìž"""
        try:
            self.cleanup_resources()
        except Exception:
            pass

# =================================================================
# ðŸ”¥ í˜¸í™˜ì„± ì§€ì› í•¨ìˆ˜ë“¤ (ê¸°ì¡´ ì½”ë“œ í˜¸í™˜)
# =================================================================

async def create_pose_estimation_step(
    device: str = "auto",
    config: Optional[Dict[str, Any]] = None,
    **kwargs
) -> PoseEstimationStep:
    """âœ… ì•ˆì „í•œ Step 02 ìƒì„± í•¨ìˆ˜ - ì™„ì „ ìž¬ìž‘ì„±"""
    try:
        # ë””ë°”ì´ìŠ¤ ì²˜ë¦¬
        device_param = None if device == "auto" else device
        
        # config í†µí•©
        if config is None:
            config = {}
        config.update(kwargs)
        
        # Step ìƒì„± ë° ì´ˆê¸°í™”
        step = PoseEstimationStep(device=device_param, config=config)
        
        # ì¶”ê°€ ì´ˆê¸°í™”ê°€ í•„ìš”í•œ ê²½ìš°
        if not step.is_initialized:
            step.logger.warning("âš ï¸ 2ë‹¨ê³„ ì´ˆê¸°í™” ì‹¤íŒ¨ - ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œë¡œ ë™ìž‘")
        
        return step
        
    except Exception as e:
        logger.error(f"âŒ create_pose_estimation_step ì‹¤íŒ¨: {e}")
        # í´ë°±: ìµœì†Œí•œì˜ Step ìƒì„±
        step = PoseEstimationStep(device='cpu')
        step.is_initialized = True  # ê°•ì œë¡œ ì´ˆê¸°í™” ìƒíƒœ ì„¤ì •
        return step

def create_pose_estimation_step_sync(
    device: str = "auto",
    config: Optional[Dict[str, Any]] = None,
    **kwargs
) -> PoseEstimationStep:
    """ðŸ”§ ì•ˆì „í•œ ë™ê¸°ì‹ Step 02 ìƒì„± (ë ˆê±°ì‹œ í˜¸í™˜)"""
    try:
        try:
            loop = asyncio.get_event_loop()
        except RuntimeError:
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
        
        return loop.run_until_complete(
            create_pose_estimation_step(device, config, **kwargs)
        )
    except Exception as e:
        logger.error(f"âŒ create_pose_estimation_step_sync ì‹¤íŒ¨: {e}")
        # ì•ˆì „í•œ í´ë°±
        return PoseEstimationStep(device='cpu')

# =================================================================
# ðŸ”¥ ì¶”ê°€ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
# =================================================================

def validate_openpose_keypoints(keypoints_18: List[List[float]]) -> bool:
    """OpenPose 18 keypoints ìœ íš¨ì„± ê²€ì¦"""
    try:
        if len(keypoints_18) != 18:
            return False
        
        for kp in keypoints_18:
            if len(kp) != 3:
                return False
            if not all(isinstance(x, (int, float)) for x in kp):
                return False
            if kp[2] < 0 or kp[2] > 1:  # ì‹ ë¢°ë„ëŠ” 0~1 ì‚¬ì´
                return False
        
        return True
        
    except Exception as e:
        return False

def convert_keypoints_to_coco(keypoints_18: List[List[float]]) -> List[List[float]]:
    """OpenPose 18ì„ COCO 17 í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
    try:
        # OpenPose 18 -> COCO 17 ë§¤í•‘
        op_to_coco_mapping = {
            0: 0,   # nose
            15: 1,  # right_eye -> left_eye (COCO ê´€ì )
            16: 2,  # left_eye -> right_eye
            17: 3,  # right_ear -> left_ear
            2: 5,   # right_shoulder -> left_shoulder (COCO ê´€ì )
            5: 6,   # left_shoulder -> right_shoulder
            3: 7,   # right_elbow -> left_elbow
            6: 8,   # left_elbow -> right_elbow
            4: 9,   # right_wrist -> left_wrist
            7: 10,  # left_wrist -> right_wrist
            9: 11,  # right_hip -> left_hip
            12: 12, # left_hip -> right_hip
            10: 13, # right_knee -> left_knee
            13: 14, # left_knee -> right_knee
            11: 15, # right_ankle -> left_ankle
            14: 16  # left_ankle -> right_ankle
        }
        
        coco_keypoints = [[0, 0, 0] for _ in range(17)]
        
        for op_idx, coco_idx in op_to_coco_mapping.items():
            if op_idx < len(keypoints_18):
                coco_keypoints[coco_idx] = keypoints_18[op_idx].copy()
        
        return coco_keypoints
        
    except Exception as e:
        return [[0, 0, 0] for _ in range(17)]

def draw_pose_on_image(image: np.ndarray, keypoints_18: List[List[float]], 
                        confidence_threshold: float = 0.5) -> np.ndarray:
    """ì´ë¯¸ì§€ì— í¬ì¦ˆ ê·¸ë¦¬ê¸° (ì™¸ë¶€ í˜¸ì¶œìš©)"""
    try:
        result_image = image.copy()
        
        # í‚¤í¬ì¸íŠ¸ ê·¸ë¦¬ê¸°
        for i, (x, y, conf) in enumerate(keypoints_18):
            if conf > confidence_threshold:
                color = KEYPOINT_COLORS[i % len(KEYPOINT_COLORS)]
                
                if CV2_AVAILABLE:
                    cv2.circle(result_image, (int(x), int(y)), 5, color, -1)
                    cv2.circle(result_image, (int(x), int(y)), 7, (255, 255, 255), 2)
        
        # ìŠ¤ì¼ˆë ˆí†¤ ì—°ê²° ê·¸ë¦¬ê¸°
        for i, (start_idx, end_idx) in enumerate(SKELETON_CONNECTIONS):
            if (start_idx < len(keypoints_18) and end_idx < len(keypoints_18) and
                keypoints_18[start_idx][2] > confidence_threshold and 
                keypoints_18[end_idx][2] > confidence_threshold):
                
                color = SKELETON_COLORS[i % len(SKELETON_COLORS)]
                
                if CV2_AVAILABLE:
                    cv2.line(result_image, 
                            (int(keypoints_18[start_idx][0]), int(keypoints_18[start_idx][1])),
                            (int(keypoints_18[end_idx][0]), int(keypoints_18[end_idx][1])),
                            color, 3)
        
        return result_image
        
    except Exception as e:
        logger.error(f"í¬ì¦ˆ ê·¸ë¦¬ê¸° ì‹¤íŒ¨: {e}")
        return image

def analyze_pose_for_clothing(keypoints_18: List[List[float]], clothing_type: str = "default") -> Dict[str, Any]:
    """ì˜ë¥˜ í”¼íŒ…ì„ ìœ„í•œ í¬ì¦ˆ ë¶„ì„ (ì™¸ë¶€ í˜¸ì¶œìš©)"""
    try:
        analysis = {
            'suitable_for_fitting': False,
            'issues': [],
            'recommendations': [],
            'pose_score': 0.0
        }
        
        # í•„ìˆ˜ í‚¤í¬ì¸íŠ¸ í™•ì¸ (ë¨¸ë¦¬, ëª©, ì–´ê¹¨, ì—‰ë©ì´)
        essential_points = [0, 1, 2, 5, 8]
        essential_detected = sum(1 for idx in essential_points if keypoints_18[idx][2] > 0.5)
        
        if essential_detected < 4:
            analysis['issues'].append("ì£¼ìš” ì‹ ì²´ ë¶€ìœ„ê°€ ìž˜ ë³´ì´ì§€ ì•ŠìŒ")
            analysis['recommendations'].append("ì „ì‹ ì´ ìž˜ ë³´ì´ëŠ” ìžì„¸ë¥¼ ì·¨í•´ì£¼ì„¸ìš”")
        
        # íŒ” ìœ„ì¹˜ ë¶„ì„
        arms_visible = (keypoints_18[2][2] > 0.5 and keypoints_18[3][2] > 0.5 and 
                        keypoints_18[5][2] > 0.5 and keypoints_18[6][2] > 0.5)
        
        if not arms_visible:
            analysis['issues'].append("íŒ”ì´ ìž˜ ë³´ì´ì§€ ì•ŠìŒ")
            analysis['recommendations'].append("íŒ”ì´ ëª¸ì—ì„œ ë–¨ì–´ì ¸ ë³´ì´ëŠ” ìžì„¸ë¥¼ ì·¨í•´ì£¼ì„¸ìš”")
        
        # ë‹¤ë¦¬ ìœ„ì¹˜ ë¶„ì„
        legs_visible = (keypoints_18[9][2] > 0.5 and keypoints_18[10][2] > 0.5 and 
                        keypoints_18[12][2] > 0.5 and keypoints_18[13][2] > 0.5)
        
        if not legs_visible:
            analysis['issues'].append("ë‹¤ë¦¬ê°€ ìž˜ ë³´ì´ì§€ ì•ŠìŒ")
            analysis['recommendations'].append("ë‹¤ë¦¬ê°€ ë¶„ë¦¬ë˜ì–´ ë³´ì´ëŠ” ìžì„¸ë¥¼ ì·¨í•´ì£¼ì„¸ìš”")
        
        # ì •ë©´ ë°©í–¥ í™•ì¸ (ì–´ê¹¨ ëŒ€ì¹­ì„±)
        if keypoints_18[2][2] > 0.5 and keypoints_18[5][2] > 0.5:
            shoulder_diff = abs(keypoints_18[2][1] - keypoints_18[5][1])
            shoulder_width = abs(keypoints_18[2][0] - keypoints_18[5][0])
            
            if shoulder_width > 0 and shoulder_diff / shoulder_width > 0.2:
                analysis['issues'].append("ëª¸ì´ ê¸°ìš¸ì–´ì ¸ ìžˆìŒ")
                analysis['recommendations'].append("ì¹´ë©”ë¼ë¥¼ ì •ë©´ìœ¼ë¡œ ë°”ë¼ë´ ì£¼ì„¸ìš”")
        
        # ì „ì²´ ì ìˆ˜ ê³„ì‚°
        base_score = essential_detected / len(essential_points)
        arm_bonus = 0.2 if arms_visible else 0.0
        leg_bonus = 0.2 if legs_visible else 0.0
        
        analysis['pose_score'] = min(1.0, base_score + arm_bonus + leg_bonus)
        
        # í”¼íŒ… ì í•©ì„± íŒë‹¨
        analysis['suitable_for_fitting'] = (
            len(analysis['issues']) <= 1 and 
            analysis['pose_score'] >= 0.7
        )
        
        if analysis['suitable_for_fitting']:
            analysis['recommendations'].append("í¬ì¦ˆê°€ ê°€ìƒ í”¼íŒ…ì— ì í•©í•©ë‹ˆë‹¤!")
        
        return analysis
        
    except Exception as e:
        logger.error(f"í¬ì¦ˆ ë¶„ì„ ì‹¤íŒ¨: {e}")
        return {
            'suitable_for_fitting': False,
            'issues': ["ë¶„ì„ ì‹¤íŒ¨"],
            'recommendations': ["ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”"],
            'pose_score': 0.0
        }

# =================================================================
# ðŸ”¥ ëª¨ë“ˆ ìµìŠ¤í¬íŠ¸
# =================================================================

__all__ = [
    'PoseEstimationStep',
    'PoseMetrics',
    'PoseModel',
    'PoseQuality', 
    'PoseType',
    'create_pose_estimation_step',
    'create_pose_estimation_step_sync',
    'validate_openpose_keypoints',
    'convert_keypoints_to_coco',
    'draw_pose_on_image',
    'analyze_pose_for_clothing',
    'OPENPOSE_18_KEYPOINTS',
    'KEYPOINT_COLORS',
    'SKELETON_CONNECTIONS',
    'SKELETON_COLORS'
]

# ëª¨ë“ˆ ì´ˆê¸°í™” ë¡œê·¸
logger.info("âœ… PoseEstimationStep v5.0 - ì™„ì „ ìž¬ìž‘ì„± ë²„ì „ ë¡œë“œ ì™„ë£Œ")
logger.info("ðŸ”— BaseStepMixin ì™„ì „ ì—°ë™ - logger ì†ì„± ëˆ„ë½ ì™„ì „ í•´ê²°")
logger.info("ðŸ”„ ModelLoader ì¸í„°íŽ˜ì´ìŠ¤ ì™„ë²½ ì—°ë™ - ìˆœí™˜ì°¸ì¡° ì—†ëŠ” í•œë°©í–¥ ì°¸ì¡°")
logger.info("ðŸŽ M3 Max 128GB ìµœì í™” + ëª¨ë“  ê¸°ì¡´ ê¸°ëŠ¥ 100% ìœ ì§€")
logger.info("ðŸš€ ì™„ì „í•˜ê²Œ ìž‘ë™í•˜ëŠ” í¬ì¦ˆ ì¶”ì • ì‹œìŠ¤í…œ ì¤€ë¹„ ì™„ë£Œ")