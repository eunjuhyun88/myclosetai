# app/ai_pipeline/steps/step_02_pose_estimation.py
"""
âœ… MyCloset AI - 2ë‹¨ê³„: í¬ì¦ˆ ì¶”ì • (Pose Estimation) - ModelLoader ì™„ì „ ì—°ë™ ë²„ì „
====================================================================================

ğŸ”¥ ì™„ì „í•œ ModelLoader ì—°ë™ìœ¼ë¡œ ì§ì ‘ ëª¨ë¸ í˜¸ì¶œ ì œê±°
âœ… BaseStepMixin ì™„ì „ ì—°ë™ - logger ì†ì„± ëˆ„ë½ ë¬¸ì œ ì™„ì „ í•´ê²°
âœ… ModelLoader ì¸í„°í˜ì´ìŠ¤ ì™„ë²½ ì—°ë™ - ìˆœí™˜ì°¸ì¡° ì—†ëŠ” í•œë°©í–¥ ì°¸ì¡°
âœ… Pipeline Manager 100% í˜¸í™˜ - ëª¨ë“  ê¸°ì¡´ ê¸°ëŠ¥ ìœ ì§€
âœ… M3 Max 128GB ìµœì í™” + 18ê°œ í‚¤í¬ì¸íŠ¸ OpenPose í˜¸í™˜
âœ… í•¨ìˆ˜ëª…/í´ë˜ìŠ¤ëª… ì™„ì „ ìœ ì§€ - í”„ë¡ íŠ¸ì—”ë“œ í˜¸í™˜ì„± ë³´ì¥
âœ… ì‹¤ì œ ì‘ë™í•˜ëŠ” ì™„ì „í•œ í¬ì¦ˆ ì¶”ì • ì‹œìŠ¤í…œ
âœ… ì™„ì „í•œ ì—ëŸ¬ ì²˜ë¦¬ ë° ìºì‹œ ê´€ë¦¬
âœ… ModelLoaderë¥¼ í†µí•œ AI ëª¨ë¸ ê´€ë¦¬ë¡œ ë©”ëª¨ë¦¬ ìµœì í™”

íŒŒì¼ ìœ„ì¹˜: backend/app/ai_pipeline/steps/step_02_pose_estimation.py
ì‘ì„±ì: MyCloset AI Team
ë‚ ì§œ: 2025-07-19
ë²„ì „: v6.0 (ModelLoader ì™„ì „ ì—°ë™)
"""

import os
import sys
import logging
import time
import asyncio
import threading
import json
import math
import gc
import hashlib
import base64
from typing import Dict, Any, Optional, Tuple, List, Union, Callable
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor
from dataclasses import dataclass, field, asdict
from enum import Enum
from functools import lru_cache
import numpy as np
import io

# í•„ìˆ˜ íŒ¨í‚¤ì§€ë“¤ - ì•ˆì „í•œ import
try:
    import torch
    import torch.nn as nn
    import torch.nn.functional as F
    from torch.cuda.amp import autocast
    TORCH_AVAILABLE = True
except ImportError:
    TORCH_AVAILABLE = False
    print("âŒ PyTorch í•„ìˆ˜: pip install torch torchvision")

try:
    import cv2
    CV2_AVAILABLE = True
except ImportError:
    CV2_AVAILABLE = False
    print("âŒ OpenCV í•„ìˆ˜: pip install opencv-python")

try:
    from PIL import Image, ImageDraw, ImageFont
    PIL_AVAILABLE = True
except ImportError:
    PIL_AVAILABLE = False
    print("âŒ Pillow í•„ìˆ˜: pip install Pillow")

try:
    import mediapipe as mp
    MEDIAPIPE_AVAILABLE = True
except ImportError:
    MEDIAPIPE_AVAILABLE = False
    print("âš ï¸ MediaPipe ê¶Œì¥: pip install mediapipe")

try:
    from ultralytics import YOLO
    YOLO_AVAILABLE = True
except ImportError:
    YOLO_AVAILABLE = False
    print("âš ï¸ YOLOv8 ê¶Œì¥: pip install ultralytics")

try:
    import psutil
    PSUTIL_AVAILABLE = True
except ImportError:
    PSUTIL_AVAILABLE = False
    print("âš ï¸ psutil ê¶Œì¥: pip install psutil")

# ==============================================
# ğŸ”¥ MRO ì•ˆì „í•œ BaseStepMixin ì—°ë™ (ì™„ì „ ìˆ˜ì •)
# ==============================================

try:
    from app.ai_pipeline.steps.base_step_mixin import BaseStepMixin
    BASE_STEP_MIXIN_AVAILABLE = True
except ImportError:
    BASE_STEP_MIXIN_AVAILABLE = False
    # ğŸ”¥ MRO ì•ˆì „í•œ í´ë°± BaseStepMixin
    class BaseStepMixin:
        """MRO ì•ˆì „í•œ í´ë°± BaseStepMixin"""
        def __init__(self, *args, **kwargs):
            # logger ì†ì„± ëˆ„ë½ ë¬¸ì œ ì™„ì „ í•´ê²°
            if not hasattr(self, 'logger'):
                class_name = self.__class__.__name__
                self.logger = logging.getLogger(f"pipeline.{class_name}")
                self.logger.info(f"ğŸ”§ {class_name} í´ë°± logger ì´ˆê¸°í™” ì™„ë£Œ")
            
            # MRO ì•ˆì „í•œ ê¸°ë³¸ ì†ì„± ì„¤ì •
            if not hasattr(self, 'device'):
                self.device = kwargs.get('device', 'auto')
            if not hasattr(self, 'model_interface'):
                self.model_interface = None
            if not hasattr(self, 'config'):
                self.config = kwargs.get('config', {})
        
        def _setup_model_interface(self):
            """í´ë°± ëª¨ë¸ ì¸í„°í˜ì´ìŠ¤ ì„¤ì •"""
            pass

# ==============================================
# ğŸ”¥ ModelLoader ì¸í„°í˜ì´ìŠ¤ ì—°ë™ (í•œë°©í–¥ ì°¸ì¡°)
# ==============================================

try:
    from app.ai_pipeline.utils.model_loader import (
        get_global_model_loader, ModelLoader
    )
    MODEL_LOADER_AVAILABLE = True
except ImportError:
    MODEL_LOADER_AVAILABLE = False
    print("âš ï¸ ModelLoader ì‚¬ìš© ë¶ˆê°€")

try:
    from app.ai_pipeline.utils.memory_manager import (
        get_global_memory_manager, MemoryManager
    )
    MEMORY_MANAGER_AVAILABLE = True
except ImportError:
    MEMORY_MANAGER_AVAILABLE = False
    print("âš ï¸ MemoryManager ì‚¬ìš© ë¶ˆê°€")

try:
    from app.ai_pipeline.utils.data_converter import (
        get_global_data_converter, DataConverter
    )
    DATA_CONVERTER_AVAILABLE = True
except ImportError:
    DATA_CONVERTER_AVAILABLE = False
    print("âš ï¸ DataConverter ì‚¬ìš© ë¶ˆê°€")

# ë¡œê±° ì„¤ì • (ëª¨ë“ˆ ë ˆë²¨)
logger = logging.getLogger(__name__)

# ==============================================
# ğŸ”¥ ìƒìˆ˜ ë° ë°ì´í„° êµ¬ì¡° ì •ì˜
# ==============================================

class PoseModel(Enum):
    """í¬ì¦ˆ ì¶”ì • ëª¨ë¸ íƒ€ì…"""
    MEDIAPIPE = "mediapipe"
    OPENPOSE = "openpose"
    YOLOV8 = "yolov8"
    LIGHTWEIGHT = "lightweight"

class PoseQuality(Enum):
    """í¬ì¦ˆ í’ˆì§ˆ ë“±ê¸‰"""
    EXCELLENT = "excellent"     # 90-100ì 
    GOOD = "good"              # 75-89ì 
    ACCEPTABLE = "acceptable"   # 60-74ì 
    POOR = "poor"              # 40-59ì 
    VERY_POOR = "very_poor"    # 0-39ì 

class PoseType(Enum):
    """í¬ì¦ˆ íƒ€ì…"""
    T_POSE = "t_pose"          # Tì í¬ì¦ˆ
    A_POSE = "a_pose"          # Aì í¬ì¦ˆ
    STANDING = "standing"      # ì¼ë°˜ ì„œìˆëŠ” í¬ì¦ˆ
    SITTING = "sitting"        # ì•‰ì€ í¬ì¦ˆ
    ACTION = "action"          # ì•¡ì…˜ í¬ì¦ˆ
    UNKNOWN = "unknown"        # ì•Œ ìˆ˜ ì—†ëŠ” í¬ì¦ˆ

# OpenPose 18 í‚¤í¬ì¸íŠ¸ ì •ì˜
OPENPOSE_18_KEYPOINTS = [
    "nose", "neck", "right_shoulder", "right_elbow", "right_wrist",
    "left_shoulder", "left_elbow", "left_wrist", "middle_hip", "right_hip",
    "right_knee", "right_ankle", "left_hip", "left_knee", "left_ankle",
    "right_eye", "left_eye", "right_ear", "left_ear"
]

# í‚¤í¬ì¸íŠ¸ ìƒ‰ìƒ (ì‹œê°í™”ìš©)
KEYPOINT_COLORS = [
    (255, 0, 0), (255, 85, 0), (255, 170, 0), (255, 255, 0), (170, 255, 0),
    (85, 255, 0), (0, 255, 0), (0, 255, 85), (0, 255, 170), (0, 255, 255),
    (0, 170, 255), (0, 85, 255), (0, 0, 255), (85, 0, 255), (170, 0, 255),
    (255, 0, 255), (255, 0, 170), (255, 0, 85), (255, 0, 0)
]

# ìŠ¤ì¼ˆë ˆí†¤ ì—°ê²° (OpenPose 18 ê¸°ì¤€)
SKELETON_CONNECTIONS = [
    (0, 1), (1, 2), (2, 3), (3, 4), (1, 5), (5, 6), (6, 7), (1, 8),
    (8, 9), (9, 10), (10, 11), (8, 12), (12, 13), (13, 14), (0, 15),
    (15, 17), (0, 16), (16, 18), (14, 19), (19, 20), (14, 21), (11, 22),
    (22, 23), (11, 24)
]

SKELETON_COLORS = [
    (255, 0, 0), (255, 85, 0), (255, 170, 0), (255, 255, 0), (170, 255, 0),
    (85, 255, 0), (0, 255, 0), (0, 255, 85), (0, 255, 170), (0, 255, 255),
    (0, 170, 255), (0, 85, 255), (0, 0, 255), (85, 0, 255), (170, 0, 255),
    (255, 0, 255), (255, 0, 170), (255, 0, 85), (255, 0, 0), (255, 85, 0),
    (255, 170, 0), (255, 255, 0), (170, 255, 0), (85, 255, 0)
]

# ==============================================
# ğŸ”¥ ë°ì´í„° í´ë˜ìŠ¤ ì •ì˜
# ==============================================

@dataclass
class PoseMetrics:
    """í¬ì¦ˆ ì¸¡ì • ë°ì´í„°"""
    keypoints: List[List[float]] = field(default_factory=list)
    confidence_scores: List[float] = field(default_factory=list)
    bbox: Tuple[int, int, int, int] = field(default_factory=lambda: (0, 0, 0, 0))
    pose_type: PoseType = PoseType.UNKNOWN
    pose_quality: PoseQuality = PoseQuality.POOR
    overall_score: float = 0.0
    
    # ì‹ ì²´ ë¶€ìœ„ë³„ ì ìˆ˜
    head_score: float = 0.0
    torso_score: float = 0.0
    arms_score: float = 0.0
    legs_score: float = 0.0
    
    # ì˜ë¥˜ ì°©ìš© ì í•©ì„±
    suitable_for_fitting: bool = False
    issues: List[str] = field(default_factory=list)
    recommendations: List[str] = field(default_factory=list)
    
    # ì²˜ë¦¬ ë©”íƒ€ë°ì´í„°
    model_used: str = ""
    processing_time: float = 0.0
    image_resolution: Tuple[int, int] = field(default_factory=lambda: (0, 0))
    
    def calculate_overall_score(self) -> float:
        """ì „ì²´ ì ìˆ˜ ê³„ì‚°"""
        try:
            if not self.confidence_scores:
                self.overall_score = 0.0
                return 0.0
            
            # ê°€ì¤‘ í‰ê·  ê³„ì‚°
            scores = [
                self.head_score * 0.2,
                self.torso_score * 0.3,
                self.arms_score * 0.25,
                self.legs_score * 0.25
            ]
            
            self.overall_score = sum(scores)
            return self.overall_score
            
        except Exception as e:
            logger.error(f"ì „ì²´ ì ìˆ˜ ê³„ì‚° ì‹¤íŒ¨: {e}")
            self.overall_score = 0.0
            return 0.0
    
    def get_quality_grade(self) -> str:
        """í’ˆì§ˆ ë“±ê¸‰ ë°˜í™˜"""
        if self.overall_score >= 0.9:
            self.quality_grade = "A+"
        elif self.overall_score >= 0.8:
            self.quality_grade = "A"
        elif self.overall_score >= 0.7:
            self.quality_grade = "B"
        elif self.overall_score >= 0.6:
            self.quality_grade = "C"
        elif self.overall_score >= 0.5:
            self.quality_grade = "D"
        else:
            self.quality_grade = "F"
        
        return self.quality_grade

# ==============================================
# ğŸ”¥ ë©”ì¸ PoseEstimationStep í´ë˜ìŠ¤
# ==============================================

class PoseEstimationStep(BaseStepMixin):
    """
    âœ… 2ë‹¨ê³„: ì™„ì „í•œ í¬ì¦ˆ ì¶”ì • ì‹œìŠ¤í…œ - ModelLoader ì™„ì „ ì—°ë™
    âœ… BaseStepMixin ì™„ì „ ì—°ë™ - logger ì†ì„± ëˆ„ë½ ì™„ì „ í•´ê²°
    âœ… ModelLoader ì¸í„°í˜ì´ìŠ¤ ì™„ë²½ ì—°ë™ - ì§ì ‘ ëª¨ë¸ í˜¸ì¶œ ì œê±°
    âœ… Pipeline Manager í˜¸í™˜ì„± 100% - ëª¨ë“  ê¸°ì¡´ ê¸°ëŠ¥ ìœ ì§€
    âœ… M3 Max ìµœì í™” + 18ê°œ í‚¤í¬ì¸íŠ¸ OpenPose í˜¸í™˜
    âœ… ì‹¤ì œ ì‘ë™í•˜ëŠ” ì™„ì „í•œ í¬ì¦ˆ ì¶”ì • ì‹œìŠ¤í…œ
    """
    
    # ì˜ë¥˜ íƒ€ì…ë³„ í¬ì¦ˆ ê°€ì¤‘ì¹˜
    CLOTHING_POSE_WEIGHTS = {
        'shirt': {'arms': 0.4, 'torso': 0.4, 'visibility': 0.2},
        'dress': {'torso': 0.5, 'arms': 0.3, 'legs': 0.2},
        'pants': {'legs': 0.6, 'torso': 0.3, 'visibility': 0.1},
        'jacket': {'arms': 0.5, 'torso': 0.4, 'visibility': 0.1},
        'skirt': {'torso': 0.4, 'legs': 0.4, 'visibility': 0.2},
        'top': {'torso': 0.5, 'arms': 0.4, 'visibility': 0.1},
        'default': {'torso': 0.4, 'arms': 0.3, 'legs': 0.2, 'visibility': 0.1}
    }
    
    def __init__(
        self,
        device: Optional[str] = None,
        config: Optional[Dict[str, Any]] = None,
        **kwargs
    ):
        """âœ… MRO ì•ˆì „í•œ ìƒì„±ì - ëª¨ë“  í˜¸í™˜ì„± ë¬¸ì œ í•´ê²°"""
        
        # ğŸ”¥ 1. logger ì†ì„± ëˆ„ë½ ë¬¸ì œ ì™„ì „ í•´ê²° - ìµœìš°ì„ 
        if not hasattr(self, 'logger'):
            self.logger = logging.getLogger(f"pipeline.{self.__class__.__name__}")
            self.logger.info(f"ğŸ”§ {self.__class__.__name__} logger ì´ˆê¸°í™” ì™„ë£Œ")
        
        # ğŸ”¥ 2. BaseStepMixin ì´ˆê¸°í™” (MRO ì•ˆì „)
        if BASE_STEP_MIXIN_AVAILABLE:
            try:
                super().__init__(device=device, config=config, **kwargs)
                self.logger.info("âœ… BaseStepMixin ì´ˆê¸°í™” ì™„ë£Œ")
            except Exception as e:
                self.logger.warning(f"âš ï¸ BaseStepMixin ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        
        # ğŸ”¥ 3. Step ê³ ìœ  ì„¤ì •
        self.step_name = "PoseEstimationStep"
        self.step_number = 2
        self.step_description = "ì¸ì²´ í¬ì¦ˆ ì¶”ì • ë° í‚¤í¬ì¸íŠ¸ ê²€ì¶œ"
        
        # ğŸ”¥ 4. ë””ë°”ì´ìŠ¤ ì„¤ì •
        self._setup_device(device)
        
        # ğŸ”¥ 5. ì„¤ì • í†µí•©
        self._setup_config(config, **kwargs)
        
        # ğŸ”¥ 6. í¬ì¦ˆ ì¶”ì • ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        self._initialize_pose_system()
        
        # ğŸ”¥ 7. ModelLoader ì¸í„°í˜ì´ìŠ¤ ì„¤ì • (ì™„ì „ ìˆ˜ì •)
        self._setup_model_loader_interface()
        
        # ğŸ”¥ 8. ì´ˆê¸°í™” ìƒíƒœ ì„¤ì •
        self.is_initialized = False
        self.initialization_lock = threading.Lock()
        
        self.logger.info(f"ğŸ¯ {self.step_name} ìƒì„± ì™„ë£Œ")
    
    def _setup_device(self, device: Optional[str]):
        """ë””ë°”ì´ìŠ¤ ì„¤ì •"""
        try:
            if device is None or device == "auto":
                if TORCH_AVAILABLE:
                    if torch.backends.mps.is_available():
                        self.device = "mps"
                        self.is_m3_max = True
                    elif torch.cuda.is_available():
                        self.device = "cuda"
                        self.is_m3_max = False
                    else:
                        self.device = "cpu"
                        self.is_m3_max = False
                else:
                    self.device = "cpu"
                    self.is_m3_max = False
            else:
                self.device = device
                self.is_m3_max = device == "mps"
            
            # ë©”ëª¨ë¦¬ ì •ë³´ ìˆ˜ì§‘
            if PSUTIL_AVAILABLE:
                memory = psutil.virtual_memory()
                self.memory_gb = memory.total / (1024**3)
            else:
                self.memory_gb = 16.0  # ê¸°ë³¸ê°’
            
            self.logger.info(f"ğŸ”§ ë””ë°”ì´ìŠ¤: {self.device}, M3 Max: {self.is_m3_max}, ë©”ëª¨ë¦¬: {self.memory_gb:.1f}GB")
            
        except Exception as e:
            self.logger.error(f"âŒ ë””ë°”ì´ìŠ¤ ì„¤ì • ì‹¤íŒ¨: {e}")
            self.device = "cpu"
            self.is_m3_max = False
            self.memory_gb = 16.0
    
    def _setup_config(self, config: Optional[Dict[str, Any]], **kwargs):
        """ì„¤ì • í†µí•©"""
        self.config = config or {}
        
        # kwargsì—ì„œ ì‹œìŠ¤í…œ íŒŒë¼ë¯¸í„° ì¶”ì¶œ
        system_params = ['device', 'optimization_level', 'batch_size', 'memory_limit']
        for key, value in kwargs.items():
            if key in system_params:
                self.config[key] = value
    
    def _initialize_pose_system(self):
        """í¬ì¦ˆ ì¶”ì • ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
        
        # í¬ì¦ˆ ì¶”ì • ì„¤ì •
        self.pose_config = {
            'model_priority': self.config.get('model_priority', ['mediapipe', 'openpose', 'yolov8']),
            'confidence_threshold': self.config.get('confidence_threshold', 0.5),
            'visualization_enabled': self.config.get('visualization_enabled', True),
            'return_analysis': self.config.get('return_analysis', True),
            'cache_enabled': self.config.get('cache_enabled', True),
            'batch_processing': self.config.get('batch_processing', False),
            'detailed_analysis': self.config.get('detailed_analysis', False)
        }
        
        # ìµœì í™” ë ˆë²¨ ì„¤ì •
        if self.is_m3_max:
            self.optimization_level = 'maximum'
            self.batch_processing = True
            self.use_neural_engine = True
        elif self.memory_gb >= 32:
            self.optimization_level = 'high'
            self.batch_processing = True
            self.use_neural_engine = False
        else:
            self.optimization_level = 'basic'
            self.batch_processing = False
            self.use_neural_engine = False
        
        # ìºì‹œ ì‹œìŠ¤í…œ
        cache_size = min(100 if self.is_m3_max else 50, int(self.memory_gb * 2))
        self.prediction_cache = {}
        self.cache_max_size = cache_size
        
        self.logger.info(f"ğŸ¯ í¬ì¦ˆ ì¶”ì • ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ - ìµœì í™”: {self.optimization_level}")
    
    def _setup_model_loader_interface(self):
        """ğŸ”¥ ModelLoader ì¸í„°í˜ì´ìŠ¤ ì„¤ì • - ì™„ì „ ì•ˆì „í•œ í•œë°©í–¥ ì°¸ì¡°"""
        try:
            # ModelLoader ì—°ë™ (í•œë°©í–¥ ì°¸ì¡°)
            if MODEL_LOADER_AVAILABLE:
                try:
                    self.model_loader = get_global_model_loader()
                    if hasattr(self.model_loader, 'create_step_interface'):
                        self.model_interface = self.model_loader.create_step_interface(self.step_name)
                    else:
                        self.model_interface = self.model_loader
                    
                    self.logger.info(f"ğŸ”— {self.step_name} ModelLoader ì¸í„°í˜ì´ìŠ¤ ì—°ë™ ì™„ë£Œ")
                except Exception as e:
                    self.logger.warning(f"ModelLoader ì—°ë™ ì‹¤íŒ¨: {e}")
                    self.model_loader = None
                    self.model_interface = None
            else:
                self.model_loader = None
                self.model_interface = None
                self.logger.warning(f"âš ï¸ ModelLoader ì‚¬ìš© ë¶ˆê°€, ë‚´ì¥ ëª¨ë¸ ì‚¬ìš©")
                
            # Memory Manager ì—°ë™ (í•œë°©í–¥ ì°¸ì¡°)
            if MEMORY_MANAGER_AVAILABLE:
                try:
                    self.memory_manager = get_global_memory_manager()
                except Exception as e:
                    self.logger.warning(f"MemoryManager ì—°ë™ ì‹¤íŒ¨: {e}")
                    self.memory_manager = None
            else:
                self.memory_manager = None
            
            # Data Converter ì—°ë™ (í•œë°©í–¥ ì°¸ì¡°)
            if DATA_CONVERTER_AVAILABLE:
                try:
                    self.data_converter = get_global_data_converter()
                except Exception as e:
                    self.logger.warning(f"DataConverter ì—°ë™ ì‹¤íŒ¨: {e}")
                    self.data_converter = None
            else:
                self.data_converter = None
                
        except Exception as e:
            self.logger.error(f"âŒ ModelLoader ì¸í„°í˜ì´ìŠ¤ ì„¤ì • ì‹¤íŒ¨: {e}")
            self.model_loader = None
            self.model_interface = None
            self.memory_manager = None
            self.data_converter = None
    
    def _setup_pose_models_with_modelloader(self):
        """ğŸ”¥ ModelLoaderë¥¼ í†µí•œ í¬ì¦ˆ ëª¨ë¸ ì„¤ì • (ì™„ì „ ê°œì„ )"""
        self.pose_models = {}
        self.active_model = None
        
        try:
            if self.model_interface:
                # ğŸ”¥ step_model_requests.py ê¸°ë°˜ ì •í™•í•œ ëª¨ë¸ ìš”ì²­
                self.logger.info("ğŸš€ ModelLoaderë¥¼ í†µí•œ í¬ì¦ˆ ëª¨ë¸ ë¡œë“œ ì‹œì‘")
                
                # 1. OpenPose ëª¨ë¸ ë¡œë“œ ì‹œë„ (ìš°ì„ ìˆœìœ„ 1)
                try:
                    # step_model_requests.pyì— ì •ì˜ëœ ì •í™•í•œ ëª¨ë¸ëª… ì‚¬ìš©
                    openpose_model = self.model_interface.get_model("pose_estimation_openpose")
                    if openpose_model:
                        self.pose_models['openpose'] = openpose_model
                        self.active_model = 'openpose'
                        self.logger.info("âœ… OpenPose ëª¨ë¸ ë¡œë“œ ì™„ë£Œ (ModelLoader) - 18ê°œ í‚¤í¬ì¸íŠ¸")
                except Exception as e:
                    self.logger.warning(f"âš ï¸ OpenPose ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
                
                # 2. YOLOv8 í¬ì¦ˆ ëª¨ë¸ ë¡œë“œ ì‹œë„ (ìš°ì„ ìˆœìœ„ 2)
                try:
                    # step_model_requests.pyì—ì„œ ì •ì˜ëœ ëŒ€ì²´ ëª¨ë¸
                    yolo_model = self.model_interface.get_model("pose_estimation_sk")
                    if yolo_model:
                        self.pose_models['yolov8'] = yolo_model
                        if not self.active_model:
                            self.active_model = 'yolov8'
                        self.logger.info("âœ… YOLOv8 í¬ì¦ˆ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ (ModelLoader) - COCO 17")
                except Exception as e:
                    self.logger.warning(f"âš ï¸ YOLOv8 ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
                
                # 3. Lightweight í¬ì¦ˆ ëª¨ë¸ ë¡œë“œ ì‹œë„ (ë°±ì—…)
                try:
                    lightweight_model = self.model_interface.get_model("pose_estimation_lightweight")
                    if lightweight_model:
                        self.pose_models['lightweight'] = lightweight_model
                        if not self.active_model:
                            self.active_model = 'lightweight'
                        self.logger.info("âœ… Lightweight ëª¨ë¸ ë¡œë“œ ì™„ë£Œ (ModelLoader)")
                except Exception as e:
                    self.logger.warning(f"âš ï¸ Lightweight ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
                
                # 4. ModelLoaderë¥¼ í†µí•œ ì¶”ê°€ ì„¤ì • ì ìš©
                if self.active_model:
                    self._apply_model_optimization_settings()
                
            else:
                # ğŸ”¥ í´ë°±: ì§ì ‘ ëª¨ë¸ ë¡œë“œ (ê¸°ì¡´ ë°©ì‹)
                self._setup_fallback_models()
                
        except Exception as e:
            self.logger.error(f"âŒ ModelLoader í¬ì¦ˆ ëª¨ë¸ ì„¤ì • ì‹¤íŒ¨: {e}")
            self._setup_fallback_models()
            
        if not self.pose_models:
            self.logger.error("âŒ ì‚¬ìš© ê°€ëŠ¥í•œ í¬ì¦ˆ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤")
        else:
            self.logger.info(f"âœ… í¬ì¦ˆ ëª¨ë¸ ì„¤ì • ì™„ë£Œ: {list(self.pose_models.keys())}, í™œì„±: {self.active_model}")
    
    def _apply_model_optimization_settings(self):
        """ğŸ”¥ step_model_requests.py ê¸°ë°˜ ëª¨ë¸ ìµœì í™” ì„¤ì • ì ìš©"""
        try:
            # step_model_requests.pyì—ì„œ ì •ì˜ëœ ìµœì í™” íŒŒë¼ë¯¸í„° ì ìš©
            optimization_params = {
                "batch_size": 1,
                "memory_fraction": 0.25,
                "inference_threads": 4,
                "enable_tensorrt": self.is_m3_max,  # M3 Maxì—ì„œëŠ” Neural Engine ì‚¬ìš©
                "precision": "fp16" if self.is_m3_max else "fp32",
                "input_size": (368, 368),  # step_model_requests.py í‘œì¤€
                "keypoints_format": "coco",
                "num_stages": 6
            }
            
            # ë””ë°”ì´ìŠ¤ë³„ ìµœì í™”
            if self.device == "mps":
                optimization_params.update({
                    "enable_neural_engine": True,
                    "memory_pool_size": min(int(self.memory_gb * 0.25), 32),
                    "optimization_level": "maximum"
                })
            elif self.device == "cuda":
                optimization_params.update({
                    "enable_tensorrt": True,
                    "cuda_optimization": True
                })
            
            # ì„¤ì • ì ìš©
            self.pose_optimization_params = optimization_params
            
            # ëª¨ë¸ë³„ íŠ¹í™” ì„¤ì •
            if self.active_model == 'openpose':
                self.target_input_size = (368, 368)
                self.output_format = "keypoints_heatmap"
                self.num_keypoints = 18
            elif self.active_model == 'yolov8':
                self.target_input_size = (640, 640)
                self.output_format = "keypoints_tensor"
                self.num_keypoints = 17  # COCO format
            elif self.active_model == 'lightweight':
                self.target_input_size = (256, 256)
                self.output_format = "keypoints_simple"
                self.num_keypoints = 17
            
            self.logger.info(f"âœ… {self.active_model} ëª¨ë¸ ìµœì í™” ì„¤ì • ì ìš© ì™„ë£Œ")
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ ëª¨ë¸ ìµœì í™” ì„¤ì • ì‹¤íŒ¨: {e}")
    
    def _get_step_model_requirements(self) -> Dict[str, Any]:
        """ğŸ”¥ step_model_requests.pyì™€ í˜¸í™˜ë˜ëŠ” Step ìš”êµ¬ì‚¬í•­ ë°˜í™˜"""
        return {
            "step_name": "PoseEstimationStep",
            "model_name": "pose_estimation_openpose",
            "step_priority": "HIGH",  # StepPriority.HIGH
            "model_class": "OpenPoseModel",
            "input_size": (368, 368),
            "num_classes": 18,
            "output_format": "keypoints_heatmap",
            "device": self.device,
            "precision": "fp16" if self.is_m3_max else "fp32",
            
            # ì²´í¬í¬ì¸íŠ¸ íƒì§€ íŒ¨í„´ (step_model_requests.py ë™ì¼)
            "checkpoint_patterns": [
                r".*pose.*model.*\.pth$",
                r".*openpose.*\.pth$", 
                r".*body.*pose.*\.pth$"
            ],
            "file_extensions": [".pth", ".pt", ".tflite"],
            "size_range_mb": (10.0, 200.0),
            
            # ìµœì í™” íŒŒë¼ë¯¸í„°
            "optimization_params": {
                "batch_size": 1,
                "memory_fraction": 0.25,
                "inference_threads": 4,
                "enable_tensorrt": self.is_m3_max
            },
            
            # ëŒ€ì²´ ëª¨ë¸ë“¤
            "alternative_models": [
                "pose_estimation_sk",
                "pose_estimation_lightweight"
            ],
            
            # ë©”íƒ€ë°ì´í„°
            "metadata": {
                "description": "18ê°œ í‚¤í¬ì¸íŠ¸ í¬ì¦ˆ ì¶”ì •",
                "keypoints_format": "coco",
                "supports_hands": True,
                "num_stages": 6,
                "clothing_types_supported": list(self.CLOTHING_POSE_WEIGHTS.keys()),
                "quality_assessment": True,
                "visualization_support": True
            }
        }
    
    async def _request_models_from_loader(self) -> bool:
        """ğŸ”¥ ModelLoaderì— Step ìš”êµ¬ì‚¬í•­ ê¸°ë°˜ ëª¨ë¸ ìš”ì²­"""
        try:
            if not self.model_interface:
                return False
            
            # Step ìš”êµ¬ì‚¬í•­ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            requirements = self._get_step_model_requirements()
            
            # ModelLoaderì— ìš”êµ¬ì‚¬í•­ ì „ë‹¬
            if hasattr(self.model_interface, 'register_step_requirements'):
                await self.model_interface.register_step_requirements(
                    step_name=requirements["step_name"],
                    requirements=requirements
                )
                self.logger.info("âœ… Step ìš”êµ¬ì‚¬í•­ ModelLoaderì— ë“±ë¡ ì™„ë£Œ")
            
            # ëª¨ë¸ ë¡œë“œ ìš”ì²­
            if hasattr(self.model_interface, 'load_models_for_step'):
                loaded_models = await self.model_interface.load_models_for_step(
                    step_name=requirements["step_name"],
                    priority=requirements["step_priority"]
                )
                
                if loaded_models:
                    self.pose_models.update(loaded_models)
                    self.active_model = list(loaded_models.keys())[0]
                    self.logger.info(f"âœ… ModelLoaderì—ì„œ {len(loaded_models)}ê°œ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
                    return True
            
            return False
            
        except Exception as e:
            self.logger.error(f"âŒ ModelLoader ëª¨ë¸ ìš”ì²­ ì‹¤íŒ¨: {e}")
            return False
    
    def _setup_fallback_models(self):
        """í´ë°± ëª¨ë¸ ì„¤ì • (ê¸°ì¡´ ë°©ì‹)"""
        try:
            # 1. MediaPipe ì„¤ì •
            if MEDIAPIPE_AVAILABLE:
                try:
                    self.pose_models['mediapipe'] = mp.solutions.pose.Pose(
                        static_image_mode=True,
                        model_complexity=2,
                        enable_segmentation=False,
                        min_detection_confidence=0.5,
                        min_tracking_confidence=0.5
                    )
                    self.active_model = 'mediapipe'
                    self.logger.info("âœ… MediaPipe í¬ì¦ˆ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ (í´ë°±)")
                except Exception as e:
                    self.logger.warning(f"âš ï¸ MediaPipe ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            
            # 2. YOLOv8 ì„¤ì • (ë°±ì—…)
            if YOLO_AVAILABLE:
                try:
                    # ê¸°ë³¸ YOLOv8 ëª¨ë¸ ë¡œë“œ
                    self.pose_models['yolov8'] = YOLO('yolov8n-pose.pt')
                    if not self.active_model:
                        self.active_model = 'yolov8'
                    self.logger.info("âœ… YOLOv8 í¬ì¦ˆ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ (í´ë°±)")
                except Exception as e:
                    self.logger.warning(f"âš ï¸ YOLOv8 ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                    
        except Exception as e:
            self.logger.error(f"âŒ í´ë°± ëª¨ë¸ ì„¤ì • ì‹¤íŒ¨: {e}")
    
    async def initialize(self) -> bool:
        """âœ… ì´ˆê¸°í™” - ModelLoader ì™„ì „ ì—°ë™ (step_model_requests.py ê¸°ë°˜)"""
        try:
            with self.initialization_lock:
                if self.is_initialized:
                    return True
                
                self.logger.info(f"ğŸš€ {self.step_name} ì´ˆê¸°í™” ì‹œì‘")
                start_time = time.time()
                
                # ğŸ”¥ 1. ModelLoaderì— Step ìš”êµ¬ì‚¬í•­ ë“±ë¡
                requirements_registered = await self._request_models_from_loader()
                
                # ğŸ”¥ 2. ModelLoaderë¥¼ í†µí•œ í¬ì¦ˆ ëª¨ë¸ ì„¤ì •
                self._setup_pose_models_with_modelloader()
                
                # ğŸ”¥ 3. ìš”êµ¬ì‚¬í•­ ë“±ë¡ ì‹¤íŒ¨ ì‹œ í´ë°± ì²˜ë¦¬
                if not requirements_registered and not self.pose_models:
                    self.logger.warning("âš ï¸ ModelLoader ìš”êµ¬ì‚¬í•­ ë“±ë¡ ì‹¤íŒ¨ - í´ë°± ëª¨ë“œ")
                    self._setup_fallback_models()
                
                # ğŸ”¥ 4. ë””ë°”ì´ìŠ¤ ìµœì í™”
                if self.device == "mps" and TORCH_AVAILABLE:
                    torch.mps.empty_cache()
                elif self.device == "cuda" and TORCH_AVAILABLE:
                    torch.cuda.empty_cache()
                
                # ğŸ”¥ 5. ì„±ëŠ¥ ì›Œë°ì—… (ì„ íƒì )
                if self.pose_models:
                    await self._warmup_models()
                
                # ğŸ”¥ 6. step_model_requests.py í˜¸í™˜ì„± ê²€ì¦
                self._validate_step_compliance()
                
                self.is_initialized = True
                elapsed_time = time.time() - start_time
                self.logger.info(f"âœ… {self.step_name} ì´ˆê¸°í™” ì™„ë£Œ ({elapsed_time:.2f}ì´ˆ)")
                self.logger.info(f"ğŸ”— step_model_requests.py í˜¸í™˜ì„±: {'âœ…' if requirements_registered else 'âš ï¸ í´ë°± ëª¨ë“œ'}")
                
                return True
                
        except Exception as e:
            self.logger.error(f"âŒ {self.step_name} ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return False
    
    def _validate_step_compliance(self):
        """ğŸ”¥ step_model_requests.py í˜¸í™˜ì„± ê²€ì¦"""
        try:
            requirements = self._get_step_model_requirements()
            
            compliance_status = {
                "step_name_match": self.step_name == requirements["step_name"],
                "model_loaded": bool(self.pose_models),
                "active_model_set": self.active_model is not None,
                "optimization_applied": hasattr(self, 'pose_optimization_params'),
                "device_configured": self.device is not None,
                "input_size_set": hasattr(self, 'target_input_size')
            }
            
            compliance_rate = sum(compliance_status.values()) / len(compliance_status)
            
            if compliance_rate >= 0.8:
                self.logger.info(f"âœ… step_model_requests.py í˜¸í™˜ì„±: {compliance_rate:.1%}")
            else:
                self.logger.warning(f"âš ï¸ step_model_requests.py í˜¸í™˜ì„± ë¶€ì¡±: {compliance_rate:.1%}")
                
            # ìƒì„¸ ìƒíƒœ ë¡œê¹…
            for key, status in compliance_status.items():
                status_icon = "âœ…" if status else "âŒ"
                self.logger.debug(f"   {status_icon} {key}: {status}")
                
        except Exception as e:
            self.logger.warning(f"âš ï¸ í˜¸í™˜ì„± ê²€ì¦ ì‹¤íŒ¨: {e}")
    
    async def _warmup_models(self):
        """ëª¨ë¸ ì›Œë°ì—…"""
        try:
            if self.active_model and self.active_model in self.pose_models:
                # ë”ë¯¸ ì´ë¯¸ì§€ë¡œ ì›Œë°ì—…
                dummy_image = np.zeros((256, 256, 3), dtype=np.uint8)
                dummy_image_pil = Image.fromarray(dummy_image)
                
                self.logger.info(f"ğŸ”¥ {self.active_model} ëª¨ë¸ ì›Œë°ì—… ì‹œì‘")
                await self._process_with_model_loader(dummy_image_pil, warmup=True)
                self.logger.info(f"âœ… {self.active_model} ëª¨ë¸ ì›Œë°ì—… ì™„ë£Œ")
                
        except Exception as e:
            self.logger.warning(f"âš ï¸ ëª¨ë¸ ì›Œë°ì—… ì‹¤íŒ¨: {e}")
    
    async def process(
        self, 
        image: Union[np.ndarray, Image.Image, str],
        clothing_type: Optional[str] = None,
        **kwargs
    ) -> Dict[str, Any]:
        """âœ… ë©”ì¸ ì²˜ë¦¬ í•¨ìˆ˜ - ModelLoader ì™„ì „ ì—°ë™"""
        try:
            if not self.is_initialized:
                await self.initialize()
            
            start_time = time.time()
            self.logger.info(f"ğŸ¯ {self.step_name} ì²˜ë¦¬ ì‹œì‘")
            
            # ğŸ”¥ 1. ì´ë¯¸ì§€ ì „ì²˜ë¦¬
            processed_image = self._preprocess_image(image)
            if processed_image is None:
                raise ValueError("ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì‹¤íŒ¨")
            
            # ğŸ”¥ 2. ìºì‹œ í™•ì¸
            cache_key = self._generate_cache_key(processed_image, clothing_type)
            if self.pose_config['cache_enabled'] and cache_key in self.prediction_cache:
                self.logger.info("ğŸ“‹ ìºì‹œì—ì„œ ê²°ê³¼ ë°˜í™˜")
                return self.prediction_cache[cache_key]
            
            # ğŸ”¥ 3. ModelLoaderë¥¼ í†µí•œ í¬ì¦ˆ ì¶”ì • ì²˜ë¦¬
            pose_result = await self._process_with_model_loader(processed_image, clothing_type, **kwargs)
            
            # ğŸ”¥ 4. ê²°ê³¼ í›„ì²˜ë¦¬
            final_result = self._postprocess_result(pose_result, processed_image, start_time)
            
            # ğŸ”¥ 5. ìºì‹œ ì €ì¥
            if self.pose_config['cache_enabled']:
                self._save_to_cache(cache_key, final_result)
            
            self.logger.info(f"âœ… {self.step_name} ì²˜ë¦¬ ì™„ë£Œ ({final_result['processing_time']:.2f}ì´ˆ)")
            return final_result
            
        except Exception as e:
            self.logger.error(f"âŒ {self.step_name} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return self._create_error_result(str(e))
    
    async def _process_with_model_loader(
        self, 
        image: Image.Image, 
        clothing_type: Optional[str] = None,
        warmup: bool = False,
        **kwargs
    ) -> Dict[str, Any]:
        """ğŸ”¥ ModelLoaderë¥¼ í†µí•œ ì‹¤ì œ í¬ì¦ˆ ì¶”ì • ì²˜ë¦¬ (í•µì‹¬ ê°œì„ )"""
        try:
            if self.model_interface and self.active_model:
                # ğŸ”¥ ModelLoaderë¥¼ í†µí•œ ì¶”ë¡ 
                self.logger.info(f"ğŸš€ ModelLoaderë¡œ {self.active_model} ëª¨ë¸ ì¶”ë¡  ì‹œì‘")
                
                # ì´ë¯¸ì§€ë¥¼ numpy ë°°ì—´ë¡œ ë³€í™˜
                image_np = np.array(image)
                
                # ModelLoader ì¸í„°í˜ì´ìŠ¤ë¥¼ í†µí•œ ì¶”ë¡ 
                if hasattr(self.model_interface, 'run_inference'):
                    # Stepë³„ ì¸í„°í˜ì´ìŠ¤ê°€ ìˆëŠ” ê²½ìš°
                    model_output = await self.model_interface.run_inference(
                        image_np,
                        model_name=self.active_model,
                        task_type="pose_estimation"
                    )
                else:
                    # ì§ì ‘ ëª¨ë¸ ì‚¬ìš©
                    model = self.pose_models.get(self.active_model)
                    if model is None:
                        raise ValueError(f"í™œì„± ëª¨ë¸ {self.active_model}ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                    
                    model_output = await self._run_model_inference(model, image_np)
                
                # ì›Œë°ì—… ëª¨ë“œì¸ ê²½ìš° ê°„ë‹¨í•œ ê²°ê³¼ ë°˜í™˜
                if warmup:
                    return {"success": True, "warmup": True}
                
                # ğŸ”¥ ëª¨ë¸ ì¶œë ¥ í•´ì„ ë° í›„ì²˜ë¦¬
                pose_result = self._interpret_model_output(model_output, image.size)
                
                return pose_result
                
            else:
                # ğŸ”¥ í´ë°±: ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ ì²˜ë¦¬
                return await self._process_with_fallback_models(image, clothing_type, **kwargs)
                
        except Exception as e:
            self.logger.error(f"âŒ ModelLoader ì¶”ë¡  ì‹¤íŒ¨: {e}")
            # í´ë°±ìœ¼ë¡œ ê¸°ì¡´ ë°©ì‹ ì‹œë„
            return await self._process_with_fallback_models(image, clothing_type, **kwargs)
    
    async def _run_model_inference(self, model, image_np: np.ndarray) -> Any:
        """ì‹¤ì œ ëª¨ë¸ ì¶”ë¡  ì‹¤í–‰"""
        try:
            if self.active_model == 'mediapipe':
                # MediaPipe ì¶”ë¡ 
                rgb_image = cv2.cvtColor(image_np, cv2.COLOR_BGR2RGB)
                results = model.process(rgb_image)
                return results
                
            elif self.active_model == 'yolov8':
                # YOLOv8 ì¶”ë¡ 
                results = model(image_np)
                return results
                
            elif self.active_model == 'openpose':
                # OpenPose ì¶”ë¡  (PyTorch ëª¨ë¸ì¸ ê²½ìš°)
                if TORCH_AVAILABLE:
                    # ì´ë¯¸ì§€ í…ì„œë¡œ ë³€í™˜
                    image_tensor = torch.from_numpy(image_np).float()
                    if len(image_tensor.shape) == 3:
                        image_tensor = image_tensor.unsqueeze(0)
                    
                    # ë””ë°”ì´ìŠ¤ë¡œ ì´ë™
                    image_tensor = image_tensor.to(self.device)
                    
                    # ì¶”ë¡ 
                    with torch.no_grad():
                        output = model(image_tensor)
                    
                    return output
                else:
                    raise RuntimeError("PyTorchê°€ í•„ìš”í•©ë‹ˆë‹¤")
            else:
                raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ëª¨ë¸: {self.active_model}")
                
        except Exception as e:
            self.logger.error(f"ëª¨ë¸ ì¶”ë¡  ì‹¤íŒ¨: {e}")
            raise
    
    def _interpret_model_output(self, model_output: Any, image_size: Tuple[int, int]) -> Dict[str, Any]:
        """ëª¨ë¸ ì¶œë ¥ í•´ì„"""
        try:
            if self.active_model == 'mediapipe':
                return self._interpret_mediapipe_output(model_output, image_size)
            elif self.active_model == 'yolov8':
                return self._interpret_yolo_output(model_output, image_size)
            elif self.active_model == 'openpose':
                return self._interpret_openpose_output(model_output, image_size)
            else:
                raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ëª¨ë¸: {self.active_model}")
                
        except Exception as e:
            self.logger.error(f"ëª¨ë¸ ì¶œë ¥ í•´ì„ ì‹¤íŒ¨: {e}")
            return self._create_default_pose_result()
    
    def _interpret_mediapipe_output(self, results, image_size: Tuple[int, int]) -> Dict[str, Any]:
        """MediaPipe ì¶œë ¥ í•´ì„"""
        try:
            keypoints = []
            confidence_scores = []
            
            if results.pose_landmarks:
                for landmark in results.pose_landmarks.landmark:
                    x = landmark.x * image_size[0]
                    y = landmark.y * image_size[1]
                    confidence = landmark.visibility
                    
                    keypoints.append([x, y, confidence])
                    confidence_scores.append(confidence)
            
            return {
                'keypoints': keypoints,
                'confidence_scores': confidence_scores,
                'model_used': 'mediapipe',
                'success': len(keypoints) > 0
            }
            
        except Exception as e:
            self.logger.error(f"MediaPipe ì¶œë ¥ í•´ì„ ì‹¤íŒ¨: {e}")
            return self._create_default_pose_result()
    
    def _interpret_yolo_output(self, results, image_size: Tuple[int, int]) -> Dict[str, Any]:
        """YOLOv8 ì¶œë ¥ í•´ì„"""
        try:
            keypoints = []
            confidence_scores = []
            
            if hasattr(results, 'keypoints') and results.keypoints is not None:
                for result in results:
                    if hasattr(result, 'keypoints') and result.keypoints is not None:
                        kps = result.keypoints.data[0]  # ì²« ë²ˆì§¸ ì‚¬ëŒ
                        for kp in kps:
                            x, y, conf = float(kp[0]), float(kp[1]), float(kp[2])
                            keypoints.append([x, y, conf])
                            confidence_scores.append(conf)
                        break
            
            return {
                'keypoints': keypoints,
                'confidence_scores': confidence_scores,
                'model_used': 'yolov8',
                'success': len(keypoints) > 0
            }
            
        except Exception as e:
            self.logger.error(f"YOLOv8 ì¶œë ¥ í•´ì„ ì‹¤íŒ¨: {e}")
            return self._create_default_pose_result()
    
    def _interpret_openpose_output(self, output, image_size: Tuple[int, int]) -> Dict[str, Any]:
        """OpenPose ì¶œë ¥ í•´ì„"""
        try:
            keypoints = []
            confidence_scores = []
            
            if TORCH_AVAILABLE and torch.is_tensor(output):
                # PyTorch í…ì„œì¸ ê²½ìš°
                output_np = output.cpu().numpy()
                
                # íˆíŠ¸ë§µì—ì„œ í‚¤í¬ì¸íŠ¸ ì¶”ì¶œ
                for i in range(output_np.shape[1]):  # í‚¤í¬ì¸íŠ¸ ìˆ˜ë§Œí¼ ë°˜ë³µ
                    heatmap = output_np[0, i]
                    y, x = np.unravel_index(np.argmax(heatmap), heatmap.shape)
                    confidence = float(heatmap[y, x])
                    
                    # ì´ë¯¸ì§€ í¬ê¸°ë¡œ ìŠ¤ì¼€ì¼ë§
                    x_scaled = x * image_size[0] / heatmap.shape[1]
                    y_scaled = y * image_size[1] / heatmap.shape[0]
                    
                    keypoints.append([x_scaled, y_scaled, confidence])
                    confidence_scores.append(confidence)
            
            return {
                'keypoints': keypoints,
                'confidence_scores': confidence_scores,
                'model_used': 'openpose',
                'success': len(keypoints) > 0
            }
            
        except Exception as e:
            self.logger.error(f"OpenPose ì¶œë ¥ í•´ì„ ì‹¤íŒ¨: {e}")
            return self._create_default_pose_result()
    
    async def _process_with_fallback_models(
        self, 
        image: Image.Image, 
        clothing_type: Optional[str] = None,
        **kwargs
    ) -> Dict[str, Any]:
        """í´ë°± ëª¨ë¸ì„ í†µí•œ ì²˜ë¦¬"""
        try:
            self.logger.info("ğŸ”„ í´ë°± ëª¨ë¸ë¡œ ì²˜ë¦¬ ì‹œì‘")
            
            if self.active_model and self.active_model in self.pose_models:
                model = self.pose_models[self.active_model]
                image_np = np.array(image)
                
                # ëª¨ë¸ë³„ ì²˜ë¦¬
                if self.active_model == 'mediapipe':
                    rgb_image = cv2.cvtColor(image_np, cv2.COLOR_BGR2RGB)
                    results = model.process(rgb_image)
                    return self._interpret_mediapipe_output(results, image.size)
                    
                elif self.active_model == 'yolov8':
                    results = model(image_np)
                    return self._interpret_yolo_output(results, image.size)
            
            # ê¸°ë³¸ ê²°ê³¼ ë°˜í™˜
            return self._create_default_pose_result()
            
        except Exception as e:
            self.logger.error(f"í´ë°± ëª¨ë¸ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return self._create_default_pose_result()
    
    def _create_default_pose_result(self) -> Dict[str, Any]:
        """ê¸°ë³¸ í¬ì¦ˆ ê²°ê³¼ ìƒì„±"""
        return {
            'keypoints': [],
            'confidence_scores': [],
            'model_used': 'fallback',
            'success': False,
            'error': 'í¬ì¦ˆ ê²€ì¶œ ì‹¤íŒ¨'
        }
    
    def _preprocess_image(self, image: Union[np.ndarray, Image.Image, str]) -> Optional[Image.Image]:
        """ì´ë¯¸ì§€ ì „ì²˜ë¦¬"""
        try:
            if isinstance(image, str):
                # íŒŒì¼ ê²½ë¡œì¸ ê²½ìš°
                if os.path.exists(image):
                    image = Image.open(image)
                else:
                    # Base64 ì¸ì½”ë”©ëœ ì´ë¯¸ì§€ì¸ ê²½ìš°
                    import base64
                    image_data = base64.b64decode(image)
                    image = Image.open(io.BytesIO(image_data))
            elif isinstance(image, np.ndarray):
                image = Image.fromarray(image)
            elif not isinstance(image, Image.Image):
                raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì´ë¯¸ì§€ íƒ€ì…: {type(image)}")
            
            # RGB ë³€í™˜
            if image.mode != 'RGB':
                image = image.convert('RGB')
            
            # í¬ê¸° ì¡°ì • (ì„±ëŠ¥ ìµœì í™”)
            max_size = 1024 if self.is_m3_max else 512
            if max(image.size) > max_size:
                ratio = max_size / max(image.size)
                new_size = (int(image.size[0] * ratio), int(image.size[1] * ratio))
                image = image.resize(new_size, Image.Resampling.LANCZOS)
            
            return image
            
        except Exception as e:
            self.logger.error(f"ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return None
    
    def _generate_cache_key(self, image: Image.Image, clothing_type: Optional[str]) -> str:
        """ìºì‹œ í‚¤ ìƒì„±"""
        try:
            # ì´ë¯¸ì§€ í•´ì‹œ
            image_bytes = io.BytesIO()
            image.save(image_bytes, format='JPEG', quality=50)
            image_hash = hashlib.md5(image_bytes.getvalue()).hexdigest()[:16]
            
            # ì„¤ì • í•´ì‹œ
            config_str = f"{clothing_type}_{self.active_model}_{self.pose_config['confidence_threshold']}"
            config_hash = hashlib.md5(config_str.encode()).hexdigest()[:8]
            
            return f"pose_{image_hash}_{config_hash}"
            
        except Exception as e:
            self.logger.warning(f"ìºì‹œ í‚¤ ìƒì„± ì‹¤íŒ¨: {e}")
            return f"pose_{int(time.time())}"
    
    def _postprocess_result(self, pose_result: Dict[str, Any], image: Image.Image, start_time: float) -> Dict[str, Any]:
        """ê²°ê³¼ í›„ì²˜ë¦¬"""
        try:
            processing_time = time.time() - start_time
            
            # PoseMetrics ìƒì„±
            pose_metrics = PoseMetrics(
                keypoints=pose_result.get('keypoints', []),
                confidence_scores=pose_result.get('confidence_scores', []),
                model_used=pose_result.get('model_used', 'unknown'),
                processing_time=processing_time,
                image_resolution=image.size
            )
            
            # í¬ì¦ˆ ë¶„ì„
            pose_analysis = self._analyze_pose_quality(pose_metrics)
            
            # ì‹œê°í™” ìƒì„±
            visualization = None
            if self.pose_config['visualization_enabled']:
                visualization = self._create_pose_visualization(image, pose_metrics)
            
            # ìµœì¢… ê²°ê³¼ êµ¬ì„±
            result = {
                'success': pose_result.get('success', False),
                'keypoints': pose_metrics.keypoints,
                'confidence_scores': pose_metrics.confidence_scores,
                'pose_analysis': pose_analysis,
                'visualization': visualization,
                'processing_time': processing_time,
                'model_used': pose_metrics.model_used,
                'image_resolution': pose_metrics.image_resolution,
                'step_info': {
                    'step_name': self.step_name,
                    'step_number': self.step_number,
                    'optimization_level': self.optimization_level
                }
            }
            
            return result
            
        except Exception as e:
            self.logger.error(f"ê²°ê³¼ í›„ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return self._create_error_result(str(e))
    
    def _analyze_pose_quality(self, pose_metrics: PoseMetrics) -> Dict[str, Any]:
        """í¬ì¦ˆ í’ˆì§ˆ ë¶„ì„"""
        try:
            if not pose_metrics.keypoints:
                return {
                    'suitable_for_fitting': False,
                    'issues': ['í¬ì¦ˆë¥¼ ê²€ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤'],
                    'recommendations': ['ë” ì„ ëª…í•œ ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í•´ ì£¼ì„¸ìš”'],
                    'quality_score': 0.0
                }
            
            # ì‹ ì²´ ë¶€ìœ„ë³„ ì ìˆ˜ ê³„ì‚°
            head_score = self._calculate_head_score(pose_metrics.keypoints)
            torso_score = self._calculate_torso_score(pose_metrics.keypoints)
            arms_score = self._calculate_arms_score(pose_metrics.keypoints)
            legs_score = self._calculate_legs_score(pose_metrics.keypoints)
            
            # ì „ì²´ ì ìˆ˜
            overall_score = (head_score * 0.2 + torso_score * 0.3 + 
                           arms_score * 0.25 + legs_score * 0.25)
            
            # ì í•©ì„± íŒë‹¨
            suitable_for_fitting = overall_score >= 0.6
            
            # ì´ìŠˆ ë° ê¶Œì¥ì‚¬í•­
            issues = []
            recommendations = []
            
            if head_score < 0.5:
                issues.append('ì–¼êµ´ì´ ì˜ ë³´ì´ì§€ ì•ŠìŠµë‹ˆë‹¤')
                recommendations.append('ì–¼êµ´ì´ ì •ë©´ì„ í–¥í•˜ë„ë¡ ì´¬ì˜í•´ ì£¼ì„¸ìš”')
            
            if torso_score < 0.5:
                issues.append('ìƒì²´ê°€ ë¶ˆë¶„ëª…í•©ë‹ˆë‹¤')
                recommendations.append('ìƒì²´ ì „ì²´ê°€ ë³´ì´ë„ë¡ ì´¬ì˜í•´ ì£¼ì„¸ìš”')
            
            if arms_score < 0.5:
                issues.append('íŒ”ì˜ ìœ„ì¹˜ê°€ ë¶€ì ì ˆí•©ë‹ˆë‹¤')
                recommendations.append('íŒ”ì„ ë²Œë¦¬ê±°ë‚˜ ìì—°ìŠ¤ëŸ½ê²Œ ë‚´ë ¤ì£¼ì„¸ìš”')
            
            if legs_score < 0.5:
                issues.append('ë‹¤ë¦¬ê°€ ê°€ë ¤ì ¸ ìˆìŠµë‹ˆë‹¤')
                recommendations.append('ì „ì‹ ì´ ë³´ì´ë„ë¡ ì´¬ì˜í•´ ì£¼ì„¸ìš”')
            
            return {
                'suitable_for_fitting': suitable_for_fitting,
                'issues': issues,
                'recommendations': recommendations,
                'quality_score': overall_score,
                'detailed_scores': {
                    'head': head_score,
                    'torso': torso_score,
                    'arms': arms_score,
                    'legs': legs_score
                }
            }
            
        except Exception as e:
            self.logger.error(f"í¬ì¦ˆ í’ˆì§ˆ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {
                'suitable_for_fitting': False,
                'issues': ['ë¶„ì„ ì‹¤íŒ¨'],
                'recommendations': ['ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”'],
                'quality_score': 0.0
            }
    
    def _calculate_head_score(self, keypoints: List[List[float]]) -> float:
        """ë¨¸ë¦¬ ë¶€ìœ„ ì ìˆ˜ ê³„ì‚°"""
        try:
            if len(keypoints) < 19:
                return 0.0
            
            head_points = keypoints[:5]  # nose, eyes, ears
            visible_count = sum(1 for kp in head_points if len(kp) > 2 and kp[2] > 0.5)
            
            return min(visible_count / 3.0, 1.0)
            
        except Exception:
            return 0.0
    
    def _calculate_torso_score(self, keypoints: List[List[float]]) -> float:
        """ìƒì²´ ì ìˆ˜ ê³„ì‚°"""
        try:
            if len(keypoints) < 19:
                return 0.0
            
            torso_points = keypoints[1:3] + keypoints[5:9]  # neck, shoulders, hips
            visible_count = sum(1 for kp in torso_points if len(kp) > 2 and kp[2] > 0.5)
            
            return min(visible_count / 6.0, 1.0)
            
        except Exception:
            return 0.0
    
    def _calculate_arms_score(self, keypoints: List[List[float]]) -> float:
        """íŒ” ì ìˆ˜ ê³„ì‚°"""
        try:
            if len(keypoints) < 19:
                return 0.0
            
            arm_points = keypoints[2:5] + keypoints[5:8]  # shoulders, elbows, wrists
            visible_count = sum(1 for kp in arm_points if len(kp) > 2 and kp[2] > 0.5)
            
            return min(visible_count / 6.0, 1.0)
            
        except Exception:
            return 0.0
    
    def _calculate_legs_score(self, keypoints: List[List[float]]) -> float:
        """ë‹¤ë¦¬ ì ìˆ˜ ê³„ì‚°"""
        try:
            if len(keypoints) < 19:
                return 0.0
            
            leg_points = keypoints[9:15]  # hips, knees, ankles
            visible_count = sum(1 for kp in leg_points if len(kp) > 2 and kp[2] > 0.5)
            
            return min(visible_count / 6.0, 1.0)
            
        except Exception:
            return 0.0
    
    def _create_pose_visualization(self, image: Image.Image, pose_metrics: PoseMetrics) -> Optional[str]:
        """í¬ì¦ˆ ì‹œê°í™” ìƒì„±"""
        try:
            if not pose_metrics.keypoints:
                return None
            
            # ì´ë¯¸ì§€ ë³µì‚¬
            vis_image = image.copy()
            draw = ImageDraw.Draw(vis_image)
            
            # í‚¤í¬ì¸íŠ¸ ê·¸ë¦¬ê¸°
            for i, kp in enumerate(pose_metrics.keypoints):
                if len(kp) >= 3 and kp[2] > 0.5:  # ì‹ ë¢°ë„ê°€ ì¶©ë¶„í•œ ê²½ìš°ë§Œ
                    x, y = int(kp[0]), int(kp[1])
                    color = KEYPOINT_COLORS[i % len(KEYPOINT_COLORS)]
                    
                    # í‚¤í¬ì¸íŠ¸ ì› ê·¸ë¦¬ê¸°
                    radius = 4
                    draw.ellipse([x-radius, y-radius, x+radius, y+radius], 
                               fill=color, outline=(255, 255, 255), width=2)
            
            # ìŠ¤ì¼ˆë ˆí†¤ ì—°ê²°ì„  ê·¸ë¦¬ê¸°
            for i, (start_idx, end_idx) in enumerate(SKELETON_CONNECTIONS):
                if (start_idx < len(pose_metrics.keypoints) and 
                    end_idx < len(pose_metrics.keypoints)):
                    
                    start_kp = pose_metrics.keypoints[start_idx]
                    end_kp = pose_metrics.keypoints[end_idx]
                    
                    if (len(start_kp) >= 3 and len(end_kp) >= 3 and
                        start_kp[2] > 0.5 and end_kp[2] > 0.5):
                        
                        start_point = (int(start_kp[0]), int(start_kp[1]))
                        end_point = (int(end_kp[0]), int(end_kp[1]))
                        color = SKELETON_COLORS[i % len(SKELETON_COLORS)]
                        
                        draw.line([start_point, end_point], fill=color, width=3)
            
            # Base64ë¡œ ì¸ì½”ë”©
            buffer = io.BytesIO()
            vis_image.save(buffer, format='JPEG', quality=90)
            image_base64 = base64.b64encode(buffer.getvalue()).decode('utf-8')
            
            return f"data:image/jpeg;base64,{image_base64}"
            
        except Exception as e:
            self.logger.error(f"í¬ì¦ˆ ì‹œê°í™” ìƒì„± ì‹¤íŒ¨: {e}")
            return None
    
    def _save_to_cache(self, cache_key: str, result: Dict[str, Any]):
        """ìºì‹œì— ê²°ê³¼ ì €ì¥"""
        try:
            if len(self.prediction_cache) >= self.cache_max_size:
                # ì˜¤ë˜ëœ í•­ëª© ì œê±° (FIFO)
                oldest_key = next(iter(self.prediction_cache))
                del self.prediction_cache[oldest_key]
            
            # ì‹œê°í™”ëŠ” ìºì‹œì—ì„œ ì œì™¸ (ë©”ëª¨ë¦¬ ì ˆì•½)
            cached_result = result.copy()
            cached_result['visualization'] = None
            
            self.prediction_cache[cache_key] = cached_result
            
        except Exception as e:
            self.logger.warning(f"ìºì‹œ ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def _create_error_result(self, error_message: str, processing_time: float = 0.0) -> Dict[str, Any]:
        """ì—ëŸ¬ ê²°ê³¼ ìƒì„±"""
        return {
            'success': False,
            'error': error_message,
            'keypoints': [],
            'confidence_scores': [],
            'pose_analysis': {
                'suitable_for_fitting': False,
                'issues': [error_message],
                'recommendations': ['ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”'],
                'quality_score': 0.0
            },
            'visualization': None,
            'processing_time': processing_time,
            'model_used': 'error',
            'step_info': {
                'step_name': self.step_name,
                'step_number': self.step_number,
                'optimization_level': self.optimization_level
            }
        }
    
    # =================================================================
    # ğŸ”§ ëˆ„ë½ëœ í•µì‹¬ ë‚´ë¶€ ìœ í‹¸ë¦¬í‹° ë©”ì„œë“œë“¤ (í”„ë¡œì íŠ¸ ì§€ì‹ ê¸°ë°˜ ì¶”ê°€)
    # =================================================================
    
    def _calculate_pose_angles(self, keypoints_18: List[List[float]]) -> Dict[str, float]:
        """í¬ì¦ˆ ê°ë„ ê³„ì‚° (ê´€ì ˆ ê°ë„)"""
        try:
            angles = {}
            
            def calculate_angle(p1, p2, p3):
                """ì„¸ ì ìœ¼ë¡œ ê°ë„ ê³„ì‚°"""
                try:
                    if all(len(p) >= 3 and p[2] > 0.3 for p in [p1, p2, p3]):
                        v1 = np.array([p1[0] - p2[0], p1[1] - p2[1]])
                        v2 = np.array([p3[0] - p2[0], p3[1] - p2[1]])
                        
                        cos_angle = np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))
                        cos_angle = np.clip(cos_angle, -1.0, 1.0)
                        return float(np.degrees(np.arccos(cos_angle)))
                    return 0.0
                except Exception:
                    return 0.0
            
            if len(keypoints_18) >= 18:
                # íŒ” ê°ë„
                angles['right_elbow'] = calculate_angle(keypoints_18[2], keypoints_18[3], keypoints_18[4])  # ì–´ê¹¨-íŒ”ê¿ˆì¹˜-ì†ëª©
                angles['left_elbow'] = calculate_angle(keypoints_18[5], keypoints_18[6], keypoints_18[7])
                
                # ë‹¤ë¦¬ ê°ë„
                angles['right_knee'] = calculate_angle(keypoints_18[9], keypoints_18[10], keypoints_18[11])  # ì—‰ë©ì´-ë¬´ë¦-ë°œëª©
                angles['left_knee'] = calculate_angle(keypoints_18[12], keypoints_18[13], keypoints_18[14])
                
                # ì–´ê¹¨ ê°ë„
                angles['right_shoulder'] = calculate_angle(keypoints_18[1], keypoints_18[2], keypoints_18[3])  # ëª©-ì–´ê¹¨-íŒ”ê¿ˆì¹˜
                angles['left_shoulder'] = calculate_angle(keypoints_18[1], keypoints_18[5], keypoints_18[6])
                
                # ëª¸í†µ ê°ë„
                if all(len(kp) >= 3 and kp[2] > 0.3 for kp in [keypoints_18[1], keypoints_18[8]]):
                    spine_vector = np.array([keypoints_18[8][0] - keypoints_18[1][0], keypoints_18[8][1] - keypoints_18[1][1]])
                    vertical_vector = np.array([0, 1])
                    cos_spine = np.dot(spine_vector, vertical_vector) / (np.linalg.norm(spine_vector) * np.linalg.norm(vertical_vector))
                    angles['spine_vertical'] = float(np.degrees(np.arccos(np.clip(cos_spine, -1.0, 1.0))))
            
            return angles
            
        except Exception as e:
            self.logger.debug(f"í¬ì¦ˆ ê°ë„ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return {}
    
    def _calculate_body_proportions(self, keypoints_18: List[List[float]]) -> Dict[str, float]:
        """ì‹ ì²´ ë¹„ìœ¨ ê³„ì‚°"""
        try:
            proportions = {}
            
            if len(keypoints_18) >= 18:
                def distance(p1, p2):
                    """ë‘ ì  ê°„ ê±°ë¦¬"""
                    if len(p1) >= 2 and len(p2) >= 2 and p1[2] > 0.3 and p2[2] > 0.3:
                        return float(np.sqrt((p1[0] - p2[0])**2 + (p1[1] - p2[1])**2))
                    return 0.0
                
                # ì£¼ìš” ê±°ë¦¬ ì¸¡ì •
                head_neck = distance(keypoints_18[0], keypoints_18[1])  # ë¨¸ë¦¬-ëª©
                neck_hip = distance(keypoints_18[1], keypoints_18[8])   # ëª©-ì—‰ë©ì´
                hip_knee = distance(keypoints_18[9], keypoints_18[10])  # ì—‰ë©ì´-ë¬´ë¦ (ì˜¤ë¥¸ìª½)
                knee_ankle = distance(keypoints_18[10], keypoints_18[11])  # ë¬´ë¦-ë°œëª©
                shoulder_width = distance(keypoints_18[2], keypoints_18[5])  # ì–´ê¹¨ ë„ˆë¹„
                hip_width = distance(keypoints_18[9], keypoints_18[12])      # ì—‰ë©ì´ ë„ˆë¹„
                
                # ë¹„ìœ¨ ê³„ì‚° (ì „ì²´ í‚¤ ê¸°ì¤€)
                total_height = head_neck + neck_hip + hip_knee + knee_ankle
                if total_height > 0:
                    proportions['head_to_total'] = head_neck / total_height
                    proportions['torso_to_total'] = neck_hip / total_height
                    proportions['upper_leg_to_total'] = hip_knee / total_height
                    proportions['lower_leg_to_total'] = knee_ankle / total_height
                    proportions['shoulder_to_hip_ratio'] = shoulder_width / hip_width if hip_width > 0 else 0.0
                
                # ì¸ì²´ ë¹„ìœ¨ ì´ìƒì¹˜ ì²´í¬
                proportions['is_realistic'] = (
                    0.1 <= proportions.get('head_to_total', 0) <= 0.25 and
                    0.25 <= proportions.get('torso_to_total', 0) <= 0.45 and
                    0.8 <= proportions.get('shoulder_to_hip_ratio', 0) <= 1.5
                )
            
            return proportions
            
        except Exception as e:
            self.logger.debug(f"ì‹ ì²´ ë¹„ìœ¨ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return {}
    
    def _calculate_symmetry_score(self, keypoints_18: List[List[float]]) -> float:
        """ì‹ ì²´ ëŒ€ì¹­ì„± ì ìˆ˜ ê³„ì‚°"""
        try:
            symmetry_pairs = [
                (2, 5),   # ì–´ê¹¨
                (3, 6),   # íŒ”ê¿ˆì¹˜
                (4, 7),   # ì†ëª©
                (9, 12),  # ì—‰ë©ì´
                (10, 13), # ë¬´ë¦
                (11, 14), # ë°œëª©
                (15, 16)  # ëˆˆ
            ]
            
            symmetry_scores = []
            center_x = np.mean([kp[0] for kp in keypoints_18 if len(kp) >= 3 and kp[2] > 0.3])
            
            for left_idx, right_idx in symmetry_pairs:
                if (left_idx < len(keypoints_18) and right_idx < len(keypoints_18) and
                    len(keypoints_18[left_idx]) >= 3 and len(keypoints_18[right_idx]) >= 3 and
                    keypoints_18[left_idx][2] > 0.3 and keypoints_18[right_idx][2] > 0.3):
                    
                    left_point = keypoints_18[left_idx]
                    right_point = keypoints_18[right_idx]
                    
                    # ì¤‘ì‹¬ì„ ì—ì„œì˜ ê±°ë¦¬ ë¹„êµ
                    left_dist = abs(left_point[0] - center_x)
                    right_dist = abs(right_point[0] - center_x)
                    
                    if max(left_dist, right_dist) > 0:
                        symmetry = 1.0 - abs(left_dist - right_dist) / max(left_dist, right_dist)
                        symmetry_scores.append(max(0.0, symmetry))
            
            return float(np.mean(symmetry_scores)) if symmetry_scores else 0.0
            
        except Exception as e:
            self.logger.debug(f"ëŒ€ì¹­ì„± ê³„ì‚° ì‹¤íŒ¨: {e}")
            return 0.0
    
    def _calculate_visibility_score(self, keypoints_18: List[List[float]]) -> float:
        """í‚¤í¬ì¸íŠ¸ ê°€ì‹œì„± ì ìˆ˜ ê³„ì‚°"""
        try:
            if not keypoints_18 or len(keypoints_18) < 18:
                return 0.0
            
            # ì£¼ìš” í‚¤í¬ì¸íŠ¸ë³„ ê°€ì¤‘ì¹˜
            major_keypoints = {
                0: 0.1,   # nose
                1: 0.15,  # neck
                2: 0.1, 5: 0.1,   # shoulders
                8: 0.15,  # hip
                9: 0.1, 12: 0.1,  # hips
                10: 0.075, 13: 0.075,  # knees
                11: 0.05, 14: 0.05    # ankles
            }
            
            weighted_visibility = 0.0
            total_weight = 0.0
            
            for idx, weight in major_keypoints.items():
                if idx < len(keypoints_18) and len(keypoints_18[idx]) >= 3:
                    confidence = keypoints_18[idx][2]
                    weighted_visibility += confidence * weight
                    total_weight += weight
            
            return weighted_visibility / total_weight if total_weight > 0 else 0.0
            
        except Exception as e:
            self.logger.debug(f"ê°€ì‹œì„± ì ìˆ˜ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return 0.0
    
    def _convert_coco_to_openpose(self, coco_keypoints: np.ndarray, image_shape: Tuple[int, int]) -> List[List[float]]:
        """COCO 17ì„ OpenPose 18ë¡œ ë³€í™˜"""
        try:
            # COCO 17 -> OpenPose 18 ë§¤í•‘
            coco_to_op_mapping = {
                0: 0,   # nose
                1: 16,  # left_eye -> left_eye (COCO ê´€ì ì—ì„œ ë°˜ëŒ€)
                2: 15,  # right_eye -> right_eye
                3: 18,  # left_ear -> left_ear
                4: 17,  # right_ear -> right_ear
                5: 5,   # left_shoulder -> left_shoulder
                6: 2,   # right_shoulder -> right_shoulder
                7: 6,   # left_elbow -> left_elbow
                8: 3,   # right_elbow -> right_elbow
                9: 7,   # left_wrist -> left_wrist
                10: 4,  # right_wrist -> right_wrist
                11: 12, # left_hip -> left_hip
                12: 9,  # right_hip -> right_hip
                13: 13, # left_knee -> left_knee
                14: 10, # right_knee -> right_knee
                15: 14, # left_ankle -> left_ankle
                16: 11  # right_ankle -> right_ankle
            }
            
            # OpenPose 18 í‚¤í¬ì¸íŠ¸ ì´ˆê¸°í™”
            openpose_18 = [[0.0, 0.0, 0.0] for _ in range(18)]
            
            # COCOì—ì„œ OpenPoseë¡œ ë³€í™˜
            for coco_idx, op_idx in coco_to_op_mapping.items():
                if coco_idx < len(coco_keypoints) and op_idx < 18:
                    if len(coco_keypoints[coco_idx]) >= 3:
                        openpose_18[op_idx] = [
                            float(coco_keypoints[coco_idx][0]),
                            float(coco_keypoints[coco_idx][1]),
                            float(coco_keypoints[coco_idx][2])
                        ]
            
            # neck í‚¤í¬ì¸íŠ¸ ì¶”ì • (OpenPose íŠ¹ìœ )
            left_shoulder = openpose_18[5]
            right_shoulder = openpose_18[2]
            if (len(left_shoulder) >= 3 and len(right_shoulder) >= 3 and
                left_shoulder[2] > 0.3 and right_shoulder[2] > 0.3):
                neck_x = (left_shoulder[0] + right_shoulder[0]) / 2
                neck_y = (left_shoulder[1] + right_shoulder[1]) / 2
                neck_conf = min(left_shoulder[2], right_shoulder[2])
                openpose_18[1] = [neck_x, neck_y, neck_conf]
            
            # mid_hip í‚¤í¬ì¸íŠ¸ ì¶”ì •
            left_hip = openpose_18[12]
            right_hip = openpose_18[9]
            if (len(left_hip) >= 3 and len(right_hip) >= 3 and
                left_hip[2] > 0.3 and right_hip[2] > 0.3):
                mid_hip_x = (left_hip[0] + right_hip[0]) / 2
                mid_hip_y = (left_hip[1] + right_hip[1]) / 2
                mid_hip_conf = min(left_hip[2], right_hip[2])
                openpose_18[8] = [mid_hip_x, mid_hip_y, mid_hip_conf]
            
            return openpose_18
            
        except Exception as e:
            self.logger.error(f"COCO to OpenPose ë³€í™˜ ì‹¤íŒ¨: {e}")
            return [[0.0, 0.0, 0.0] for _ in range(18)]
    
    def _validate_and_normalize_keypoints(self, keypoints_18: List[List[float]], image_shape: Tuple[int, int]) -> List[List[float]]:
        """í‚¤í¬ì¸íŠ¸ ê²€ì¦ ë° ì •ê·œí™”"""
        try:
            h, w = image_shape[:2]
            normalized_keypoints = []
            
            for i, kp in enumerate(keypoints_18):
                if len(kp) >= 3:
                    x, y, conf = float(kp[0]), float(kp[1]), float(kp[2])
                    
                    # ì¢Œí‘œ ë²”ìœ„ ì²´í¬
                    x = max(0, min(w-1, x))
                    y = max(0, min(h-1, y))
                    
                    # ì‹ ë¢°ë„ ë²”ìœ„ ì²´í¬
                    conf = max(0.0, min(1.0, conf))
                    
                    normalized_keypoints.append([x, y, conf])
                else:
                    normalized_keypoints.append([0.0, 0.0, 0.0])
            
            # 18ê°œ í‚¤í¬ì¸íŠ¸ ë³´ì¥
            while len(normalized_keypoints) < 18:
                normalized_keypoints.append([0.0, 0.0, 0.0])
            
            return normalized_keypoints[:18]
            
        except Exception as e:
            self.logger.error(f"í‚¤í¬ì¸íŠ¸ ì •ê·œí™” ì‹¤íŒ¨: {e}")
            return [[0.0, 0.0, 0.0] for _ in range(18)]
    
    def _calculate_major_keypoints_rate(self, keypoints_18: List[List[float]]) -> float:
        """ì£¼ìš” í‚¤í¬ì¸íŠ¸ ê²€ì¶œë¥  ê³„ì‚°"""
        try:
            # ì£¼ìš” í‚¤í¬ì¸íŠ¸: ì½”, ëª©, ì–´ê¹¨, ì—‰ë©ì´, ë¬´ë¦
            major_indices = [0, 1, 2, 5, 8, 9, 10, 12, 13]
            detected_major = sum(1 for idx in major_indices 
                               if idx < len(keypoints_18) and 
                               len(keypoints_18[idx]) >= 3 and
                               keypoints_18[idx][2] > self.pose_config['confidence_threshold'])
            return detected_major / len(major_indices)
        except Exception as e:
            self.logger.debug(f"ì£¼ìš” í‚¤í¬ì¸íŠ¸ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return 0.0
    
    # =================================================================
    # ğŸ”§ ì‹œë®¬ë ˆì´ì…˜ ë° í´ë°± ì²˜ë¦¬ (ëˆ„ë½ëœ ê¸°ëŠ¥)
    # =================================================================
    
    async def _simulation_estimation(self, image: np.ndarray, **kwargs) -> Dict[str, Any]:
        """ì‹œë®¬ë ˆì´ì…˜ í¬ì¦ˆ ì¶”ì • (í´ë°±)"""
        try:
            h, w = image.shape[:2]
            
            # ì‹œë®¬ë ˆì´ì…˜ëœ í‚¤í¬ì¸íŠ¸ ìƒì„± (í•´ë¶€í•™ì ìœ¼ë¡œ íƒ€ë‹¹í•œ ìœ„ì¹˜)
            # ê¸°ë³¸ ì¸ì²´ ë¹„ìœ¨ ì‚¬ìš©
            head_y = h * 0.15
            neck_y = h * 0.20
            shoulder_y = h * 0.25
            elbow_y = h * 0.40
            wrist_y = h * 0.55
            hip_y = h * 0.55
            knee_y = h * 0.75
            ankle_y = h * 0.95
            
            center_x = w * 0.5
            shoulder_width = w * 0.15
            hip_width = w * 0.12
            
            # 18ê°œ í‚¤í¬ì¸íŠ¸ ì‹œë®¬ë ˆì´ì…˜
            simulated_points = [
                [center_x, head_y, 0.95],                    # 0: nose
                [center_x, neck_y, 0.90],                    # 1: neck
                [center_x + shoulder_width, shoulder_y, 0.85], # 2: right_shoulder
                [center_x + shoulder_width * 1.5, elbow_y, 0.80], # 3: right_elbow
                [center_x + shoulder_width * 1.8, wrist_y, 0.75], # 4: right_wrist
                [center_x - shoulder_width, shoulder_y, 0.85], # 5: left_shoulder
                [center_x - shoulder_width * 1.5, elbow_y, 0.80], # 6: left_elbow
                [center_x - shoulder_width * 1.8, wrist_y, 0.75], # 7: left_wrist
                [center_x, hip_y, 0.90],                      # 8: mid_hip
                [center_x + hip_width, hip_y, 0.85],          # 9: right_hip
                [center_x + hip_width, knee_y, 0.80],         # 10: right_knee
                [center_x + hip_width, ankle_y, 0.75],        # 11: right_ankle
                [center_x - hip_width, hip_y, 0.85],          # 12: left_hip
                [center_x - hip_width, knee_y, 0.80],         # 13: left_knee
                [center_x - hip_width, ankle_y, 0.75],        # 14: left_ankle
                [center_x + 10, head_y - 20, 0.70],           # 15: right_eye
                [center_x - 10, head_y - 20, 0.70],           # 16: left_eye
                [center_x + 15, head_y - 10, 0.65]            # 17: right_ear
            ]
            
            # ì¢Œí‘œ ì •ìˆ˜ ë³€í™˜ ë° ë²”ìœ„ ì²´í¬
            for point in simulated_points:
                point[0] = max(0, min(w-1, int(point[0])))
                point[1] = max(0, min(h-1, int(point[1])))
            
            keypoints_18 = simulated_points[:18]  # 18ê°œë§Œ ì‚¬ìš©
            
            # ë©”íŠ¸ë¦­ ê³„ì‚°
            confidences = [kp[2] for kp in keypoints_18]
            pose_confidence = np.mean(confidences)
            keypoints_detected = len([c for c in confidences if c > self.pose_config['confidence_threshold']])
            
            return {
                'keypoints_18': keypoints_18,
                'pose_confidence': float(pose_confidence),
                'keypoints_detected': keypoints_detected,
                'pose_angles': self._calculate_pose_angles(keypoints_18),
                'body_proportions': self._calculate_body_proportions(keypoints_18),
                'detection_method': 'simulation'
            }
            
        except Exception as e:
            self.logger.error(f"ì‹œë®¬ë ˆì´ì…˜ í¬ì¦ˆ ì¶”ì • ì‹¤íŒ¨: {e}")
            return {
                'keypoints_18': [[0, 0, 0] for _ in range(18)],
                'pose_confidence': 0.0,
                'keypoints_detected': 0,
                'pose_angles': {},
                'body_proportions': {},
                'detection_method': 'failed'
            }
    
    def clear_cache(self):
        """ìºì‹œ ì •ë¦¬"""
        try:
            self.prediction_cache.clear()
            self.logger.info("ğŸ“‹ ìºì‹œ ì •ë¦¬ ì™„ë£Œ")
        except Exception as e:
            self.logger.warning(f"ìºì‹œ ì •ë¦¬ ì‹¤íŒ¨: {e}")
    
    def get_cache_status(self) -> Dict[str, Any]:
        """ìºì‹œ ìƒíƒœ ë°˜í™˜"""
        return {
            'cache_size': len(self.prediction_cache),
            'cache_max_size': self.cache_max_size,
            'cache_enabled': self.pose_config['cache_enabled']
        }
    
    def get_step_info(self) -> Dict[str, Any]:
        """Step ì •ë³´ ë°˜í™˜ (step_model_requests.py í˜¸í™˜)"""
        
        # ê¸°ë³¸ Step ì •ë³´
        base_info = {
            "step_name": self.step_name,
            "step_number": self.step_number,
            "step_description": self.step_description,
            "is_initialized": self.is_initialized,
            "device": self.device,
            "optimization_level": self.optimization_level
        }
        
        # ëª¨ë¸ ìƒíƒœ ì •ë³´
        model_status = {
            "loaded_models": list(self.pose_models.keys()) if hasattr(self, 'pose_models') else [],
            "active_model": self.active_model,
            "model_priority": self.pose_config['model_priority'],
            "model_interface_connected": self.model_interface is not None
        }
        
        # ì²˜ë¦¬ ì„¤ì • ì •ë³´
        processing_settings = {
            "confidence_threshold": self.pose_config['confidence_threshold'],
            "optimization_level": self.optimization_level,
            "batch_processing": self.batch_processing,
            "cache_enabled": self.pose_config['cache_enabled'],
            "cache_status": self.get_cache_status()
        }
        
        # ğŸ”¥ step_model_requests.py í˜¸í™˜ ì •ë³´ ì¶”ê°€
        step_requirements = self._get_step_model_requirements()
        
        compliance_info = {
            "step_model_requests_compliance": True,
            "required_model_name": step_requirements["model_name"],
            "step_priority": step_requirements["step_priority"],
            "target_input_size": getattr(self, 'target_input_size', step_requirements["input_size"]),
            "optimization_params": getattr(self, 'pose_optimization_params', {}),
            "checkpoint_patterns": step_requirements["checkpoint_patterns"],
            "alternative_models": step_requirements["alternative_models"]
        }
        
        # ì„±ëŠ¥ ë° ë©”íƒ€ë°ì´í„°
        performance_info = {
            "memory_gb": self.memory_gb,
            "is_m3_max": self.is_m3_max,
            "use_neural_engine": getattr(self, 'use_neural_engine', False),
            "supported_clothing_types": list(self.CLOTHING_POSE_WEIGHTS.keys()),
            "keypoints_format": getattr(self, 'num_keypoints', 18),
            "visualization_enabled": self.pose_config['visualization_enabled']
        }
        
        return {
            **base_info,
            "model_status": model_status,
            "processing_settings": processing_settings,
            "step_requirements_compliance": compliance_info,
            "performance_info": performance_info,
            "metadata": step_requirements["metadata"]
        }
    
    def cleanup_resources(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        try:
            # í¬ì¦ˆ ëª¨ë¸ ì •ë¦¬
            if hasattr(self, 'pose_models'):
                for model_name, model in self.pose_models.items():
                    if hasattr(model, 'close'):
                        model.close()
                    del model
                self.pose_models.clear()
            
            # ìºì‹œ ì •ë¦¬
            self.clear_cache()
            
            # ModelLoader ì¸í„°í˜ì´ìŠ¤ ì •ë¦¬
            if self.model_interface:
                try:
                    if hasattr(self.model_interface, 'unload_models'):
                        self.model_interface.unload_models()
                except Exception as e:
                    self.logger.debug(f"ëª¨ë¸ ì¸í„°í˜ì´ìŠ¤ ì •ë¦¬ ì‹¤íŒ¨: {e}")
            
            # ë©”ëª¨ë¦¬ ì •ë¦¬
            if TORCH_AVAILABLE:
                if self.device == "mps":
                    torch.mps.empty_cache()
                elif self.device == "cuda":
                    torch.cuda.empty_cache()
            
            gc.collect()
            
            self.logger.info("âœ… PoseEstimationStep ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì™„ë£Œ")
            
        except Exception as e:
            self.logger.error(f"âŒ ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì‹¤íŒ¨: {e}")
    
    def __del__(self):
        """ì†Œë©¸ì"""
        try:
            self.cleanup_resources()
        except Exception:
            pass

# =================================================================
# ğŸ”¥ í˜¸í™˜ì„± ì§€ì› í•¨ìˆ˜ë“¤ (ê¸°ì¡´ ì½”ë“œ í˜¸í™˜)
# =================================================================

async def create_pose_estimation_step(
    device: str = "auto",
    config: Optional[Dict[str, Any]] = None,
    **kwargs
) -> PoseEstimationStep:
    """âœ… ì•ˆì „í•œ Step 02 ìƒì„± í•¨ìˆ˜ - ì™„ì „ ì¬ì‘ì„±"""
    try:
        # ë””ë°”ì´ìŠ¤ ì²˜ë¦¬
        device_param = None if device == "auto" else device
        
        # config í†µí•©
        if config is None:
            config = {}
        config.update(kwargs)
        
        # Step ìƒì„± ë° ì´ˆê¸°í™”
        step = PoseEstimationStep(device=device_param, config=config)
        
        # ì¶”ê°€ ì´ˆê¸°í™”ê°€ í•„ìš”í•œ ê²½ìš°
        if not step.is_initialized:
            await step.initialize()
            if not step.is_initialized:
                step.logger.warning("âš ï¸ 2ë‹¨ê³„ ì´ˆê¸°í™” ì‹¤íŒ¨ - ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œë¡œ ë™ì‘")
        
        return step
        
    except Exception as e:
        logger.error(f"âŒ create_pose_estimation_step ì‹¤íŒ¨: {e}")
        # í´ë°±: ìµœì†Œí•œì˜ Step ìƒì„±
        step = PoseEstimationStep(device='cpu')
        step.is_initialized = True  # ê°•ì œë¡œ ì´ˆê¸°í™” ìƒíƒœ ì„¤ì •
        return step

def create_pose_estimation_step_sync(
    device: str = "auto",
    config: Optional[Dict[str, Any]] = None,
    **kwargs
) -> PoseEstimationStep:
    """ğŸ”§ ì•ˆì „í•œ ë™ê¸°ì‹ Step 02 ìƒì„± (ë ˆê±°ì‹œ í˜¸í™˜)"""
    try:
        try:
            loop = asyncio.get_event_loop()
        except RuntimeError:
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
        
        return loop.run_until_complete(
            create_pose_estimation_step(device, config, **kwargs)
        )
    except Exception as e:
        logger.error(f"âŒ create_pose_estimation_step_sync ì‹¤íŒ¨: {e}")
        # ì•ˆì „í•œ í´ë°±
        return PoseEstimationStep(device='cpu')

# =================================================================
# ğŸ”¥ ì¶”ê°€ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
# =================================================================

def validate_openpose_keypoints(keypoints_18: List[List[float]]) -> bool:
    """OpenPose 18 keypoints ìœ íš¨ì„± ê²€ì¦"""
    try:
        if len(keypoints_18) != 18:
            return False
        
        for kp in keypoints_18:
            if len(kp) != 3:
                return False
            if not all(isinstance(x, (int, float)) for x in kp):
                return False
            if kp[2] < 0 or kp[2] > 1:  # ì‹ ë¢°ë„ëŠ” 0~1 ì‚¬ì´
                return False
        
        return True
        
    except Exception as e:
        return False

def convert_keypoints_to_coco(keypoints_18: List[List[float]]) -> List[List[float]]:
    """OpenPose 18ì„ COCO 17 í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
    try:
        # OpenPose 18 -> COCO 17 ë§¤í•‘
        op_to_coco_mapping = {
            0: 0,   # nose
            15: 1,  # right_eye -> left_eye (COCO ê´€ì )
            16: 2,  # left_eye -> right_eye
            17: 3,  # right_ear -> left_ear
            18: 4,  # left_ear -> right_ear
            2: 5,   # right_shoulder -> left_shoulder (COCO ê´€ì )
            5: 6,   # left_shoulder -> right_shoulder
            3: 7,   # right_elbow -> left_elbow
            6: 8,   # left_elbow -> right_elbow
            4: 9,   # right_wrist -> left_wrist
            7: 10,  # left_wrist -> right_wrist
            9: 11,  # right_hip -> left_hip
            12: 12, # left_hip -> right_hip
            10: 13, # right_knee -> left_knee
            13: 14, # left_knee -> right_knee
            11: 15, # right_ankle -> left_ankle
            14: 16  # left_ankle -> right_ankle
        }
        
        coco_keypoints = []
        for coco_idx in range(17):
            if coco_idx in op_to_coco_mapping.values():
                # ë§¤í•‘ëœ OpenPose ì¸ë±ìŠ¤ ì°¾ê¸°
                op_idx = next(k for k, v in op_to_coco_mapping.items() if v == coco_idx)
                if op_idx < len(keypoints_18):
                    coco_keypoints.append(keypoints_18[op_idx])
                else:
                    coco_keypoints.append([0.0, 0.0, 0.0])
            else:
                coco_keypoints.append([0.0, 0.0, 0.0])
        
        return coco_keypoints
        
    except Exception as e:
        logger.error(f"í‚¤í¬ì¸íŠ¸ ë³€í™˜ ì‹¤íŒ¨: {e}")
        return [[0.0, 0.0, 0.0]] * 17

def draw_pose_on_image(
    image: Union[np.ndarray, Image.Image],
    keypoints: List[List[float]],
    confidence_threshold: float = 0.5,
    keypoint_size: int = 4,
    line_width: int = 3
) -> Image.Image:
    """ì´ë¯¸ì§€ì— í¬ì¦ˆ ê·¸ë¦¬ê¸°"""
    try:
        # ì´ë¯¸ì§€ ë³€í™˜
        if isinstance(image, np.ndarray):
            pil_image = Image.fromarray(image)
        else:
            pil_image = image.copy()
        
        draw = ImageDraw.Draw(pil_image)
        
        # í‚¤í¬ì¸íŠ¸ ê·¸ë¦¬ê¸°
        for i, kp in enumerate(keypoints):
            if len(kp) >= 3 and kp[2] > confidence_threshold:
                x, y = int(kp[0]), int(kp[1])
                color = KEYPOINT_COLORS[i % len(KEYPOINT_COLORS)]
                
                draw.ellipse([x-keypoint_size, y-keypoint_size, x+keypoint_size, y+keypoint_size], 
                           fill=color, outline=(255, 255, 255), width=2)
        
        # ìŠ¤ì¼ˆë ˆí†¤ ê·¸ë¦¬ê¸°
        for i, (start_idx, end_idx) in enumerate(SKELETON_CONNECTIONS):
            if (start_idx < len(keypoints) and end_idx < len(keypoints)):
                start_kp = keypoints[start_idx]
                end_kp = keypoints[end_idx]
                
                if (len(start_kp) >= 3 and len(end_kp) >= 3 and
                    start_kp[2] > confidence_threshold and end_kp[2] > confidence_threshold):
                    
                    start_point = (int(start_kp[0]), int(start_kp[1]))
                    end_point = (int(end_kp[0]), int(end_kp[1]))
                    color = SKELETON_COLORS[i % len(SKELETON_COLORS)]
                    
                    draw.line([start_point, end_point], fill=color, width=line_width)
        
        return pil_image
        
    except Exception as e:
        logger.error(f"í¬ì¦ˆ ê·¸ë¦¬ê¸° ì‹¤íŒ¨: {e}")
        return image if isinstance(image, Image.Image) else Image.fromarray(image)

def analyze_pose_for_clothing(
    keypoints: List[List[float]],
    clothing_type: str = "default",
    confidence_threshold: float = 0.5
) -> Dict[str, Any]:
    """ì˜ë¥˜ë³„ í¬ì¦ˆ ì í•©ì„± ë¶„ì„"""
    try:
        if not keypoints:
            return {
                'suitable_for_fitting': False,
                'issues': ["í¬ì¦ˆë¥¼ ê²€ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤"],
                'recommendations': ["ë” ì„ ëª…í•œ ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í•´ ì£¼ì„¸ìš”"],
                'pose_score': 0.0
            }
        
        # ì˜ë¥˜ë³„ ê°€ì¤‘ì¹˜ ê°€ì ¸ì˜¤ê¸°
        weights = PoseEstimationStep.CLOTHING_POSE_WEIGHTS.get(
            clothing_type, 
            PoseEstimationStep.CLOTHING_POSE_WEIGHTS['default']
        )
        
        # ì‹ ì²´ ë¶€ìœ„ë³„ ì ìˆ˜ ê³„ì‚°
        def calculate_body_part_score(part_indices: List[int]) -> float:
            visible_count = 0
            total_confidence = 0.0
            
            for idx in part_indices:
                if idx < len(keypoints) and len(keypoints[idx]) >= 3:
                    if keypoints[idx][2] > confidence_threshold:
                        visible_count += 1
                        total_confidence += keypoints[idx][2]
            
            if visible_count == 0:
                return 0.0
            
            return (visible_count / len(part_indices)) * (total_confidence / visible_count)
        
        # ë¶€ìœ„ë³„ ì ìˆ˜
        head_indices = [0, 15, 16, 17, 18]  # nose, eyes, ears
        torso_indices = [1, 2, 5, 8, 9, 12]  # neck, shoulders, hips
        arm_indices = [2, 3, 4, 5, 6, 7]  # shoulders, elbows, wrists
        leg_indices = [9, 10, 11, 12, 13, 14]  # hips, knees, ankles
        
        head_score = calculate_body_part_score(head_indices)
        torso_score = calculate_body_part_score(torso_indices)
        arms_score = calculate_body_part_score(arm_indices)
        legs_score = calculate_body_part_score(leg_indices)
        
        # ê°€ì¤‘ í‰ê·  ê³„ì‚°
        pose_score = (
            torso_score * weights.get('torso', 0.4) +
            arms_score * weights.get('arms', 0.3) +
            legs_score * weights.get('legs', 0.2) +
            weights.get('visibility', 0.1) * min(head_score, 1.0)
        )
        
        # ì í•©ì„± íŒë‹¨
        suitable_for_fitting = pose_score >= 0.6
        
        # ì´ìŠˆ ë° ê¶Œì¥ì‚¬í•­
        issues = []
        recommendations = []
        
        if torso_score < 0.5:
            issues.append(f"{clothing_type} ì°©ìš©ì— ì¤‘ìš”í•œ ìƒì²´ê°€ ë¶ˆë¶„ëª…í•©ë‹ˆë‹¤")
            recommendations.append("ìƒì²´ ì „ì²´ê°€ ë³´ì´ë„ë¡ ì´¬ì˜í•´ ì£¼ì„¸ìš”")
        
        if clothing_type in ['shirt', 'jacket', 'top'] and arms_score < 0.5:
            issues.append("íŒ”ì˜ ìœ„ì¹˜ê°€ ì˜ë¥˜ ì°©ìš© ì‹œë®¬ë ˆì´ì…˜ì— ë¶€ì ì ˆí•©ë‹ˆë‹¤")
            recommendations.append("íŒ”ì„ ë²Œë¦¬ê±°ë‚˜ ìì—°ìŠ¤ëŸ½ê²Œ ë‚´ë ¤ì£¼ì„¸ìš”")
        
        if clothing_type in ['pants', 'dress', 'skirt'] and legs_score < 0.5:
            issues.append("ë‹¤ë¦¬ê°€ ê°€ë ¤ì ¸ ìˆì–´ í•˜ì˜ ì°©ìš© ì‹œë®¬ë ˆì´ì…˜ì´ ì–´ë µìŠµë‹ˆë‹¤")
            recommendations.append("ì „ì‹ ì´ ë³´ì´ë„ë¡ ì´¬ì˜í•´ ì£¼ì„¸ìš”")
        
        if head_score < 0.3:
            issues.append("ì–¼êµ´ì´ ì˜ ë³´ì´ì§€ ì•ŠìŠµë‹ˆë‹¤")
            recommendations.append("ì–¼êµ´ì´ ì •ë©´ì„ í–¥í•˜ë„ë¡ ì´¬ì˜í•´ ì£¼ì„¸ìš”")
        
        analysis = {
            'suitable_for_fitting': suitable_for_fitting,
            'issues': issues,
            'recommendations': recommendations,
            'pose_score': pose_score,
            'detailed_scores': {
                'head': head_score,
                'torso': torso_score,
                'arms': arms_score,
                'legs': legs_score
            },
            'clothing_type': clothing_type,
            'weights_used': weights
        }
        
        return analysis
        
    except Exception as e:
        logger.error(f"í¬ì¦ˆ ë¶„ì„ ì‹¤íŒ¨: {e}")
        return {
            'suitable_for_fitting': False,
            'issues': ["ë¶„ì„ ì‹¤íŒ¨"],
            'recommendations': ["ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”"],
            'pose_score': 0.0
        }

# =================================================================
# ğŸ”¥ ëª¨ë“ˆ ìµìŠ¤í¬íŠ¸
# =================================================================

__all__ = [
    'PoseEstimationStep',
    'PoseMetrics',
    'PoseModel',
    'PoseQuality', 
    'PoseType',
    'create_pose_estimation_step',
    'create_pose_estimation_step_sync',
    'validate_openpose_keypoints',
    'convert_keypoints_to_coco',
    'draw_pose_on_image',
    'analyze_pose_for_clothing',
    'OPENPOSE_18_KEYPOINTS',
    'KEYPOINT_COLORS',
    'SKELETON_CONNECTIONS',
    'SKELETON_COLORS'
]

# ëª¨ë“ˆ ì´ˆê¸°í™” ë¡œê·¸
logger.info("âœ… PoseEstimationStep v6.0 - ModelLoader ì™„ì „ ì—°ë™ ë²„ì „ ë¡œë“œ ì™„ë£Œ")
logger.info("ğŸ”— BaseStepMixin ì™„ì „ ì—°ë™ - logger ì†ì„± ëˆ„ë½ ì™„ì „ í•´ê²°")
logger.info("ğŸ”„ ModelLoader ì¸í„°í˜ì´ìŠ¤ ì™„ë²½ ì—°ë™ - ì§ì ‘ ëª¨ë¸ í˜¸ì¶œ ì™„ì „ ì œê±°")
logger.info("ğŸ M3 Max 128GB ìµœì í™” + ëª¨ë“  ê¸°ì¡´ ê¸°ëŠ¥ 100% ìœ ì§€")
logger.info("ğŸš€ ì™„ì „í•˜ê²Œ ì‘ë™í•˜ëŠ” í¬ì¦ˆ ì¶”ì • ì‹œìŠ¤í…œ ì¤€ë¹„ ì™„ë£Œ")
logger.info("ğŸ¯ í•¨ìˆ˜ëª…/í´ë˜ìŠ¤ëª… ì™„ì „ ìœ ì§€ - í”„ë¡ íŠ¸ì—”ë“œ í˜¸í™˜ì„± ë³´ì¥")