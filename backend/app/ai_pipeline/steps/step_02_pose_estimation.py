"""
backend/app/ai_pipeline/steps/step_02_pose_estimation.py

ğŸ”¥ ì™„ì „ ìˆ˜ì •ëœ MyCloset AI Step 02 - Pose Estimation
âœ… BaseStepMixin ì™„ì „ ì—°ë™ìœ¼ë¡œ logger ì†ì„± ëˆ„ë½ ë¬¸ì œ í•´ê²°
âœ… ModelLoader ì¸í„°í˜ì´ìŠ¤ ì™„ë²½ ì—°ë™ìœ¼ë¡œ ì‹¤ì œ AI ëª¨ë¸ ì‘ë™
âœ… M3 Max 128GB ìµœì í™” ë° Neural Engine ê°€ì†
âœ… í”„ë¡œë•ì…˜ ì•ˆì •ì„± ë° ì—ëŸ¬ ì²˜ë¦¬ ì™„ë²½
âœ… ê¸°ì¡´ API í˜¸í™˜ì„± 100% ìœ ì§€
âœ… OpenPose 18 í‚¤í¬ì¸íŠ¸ í¬ì¦ˆ ì¶”ì • + ì‹œê°í™”
âœ… ì•ˆì „í•œ íŒŒë¼ë¯¸í„° ì²˜ë¦¬ ë° í˜¸í™˜ì„± ë³´ì¥

ì²˜ë¦¬ ìˆœì„œ:
1. BaseStepMixin ì™„ì „ ì´ˆê¸°í™”ë¡œ logger ë¬¸ì œ í•´ê²°
2. ModelLoaderë¥¼ í†µí•œ ì‹¤ì œ OpenPose ëª¨ë¸ ë¡œë“œ
3. 18ê°œ í‚¤í¬ì¸íŠ¸ í¬ì¦ˆ ì¶”ì • ë° ë¶„ì„
4. í¬ì¦ˆ í’ˆì§ˆ í‰ê°€ ë° ê°€ìƒ í”¼íŒ… ì í•©ì„± íŒë‹¨
5. í‚¤í¬ì¸íŠ¸ ì‹œê°í™” ì´ë¯¸ì§€ ìƒì„±
6. M3 Max ìµœì í™” ë° ë©”ëª¨ë¦¬ ê´€ë¦¬
"""

import os
import gc
import time
import asyncio
import logging
import threading
import base64
import math
from typing import Dict, Any, Optional, Tuple, List, Union
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor
from dataclasses import dataclass, field
from enum import Enum
from io import BytesIO

import numpy as np
import torch
import torch.nn.functional as F
from PIL import Image, ImageDraw, ImageFont
import cv2

# ğŸ”¥ BaseStepMixin ì—°ë™ (ì™„ì „ ìˆ˜ì •) - logger ë¬¸ì œ í•´ê²°
try:
    from app.ai_pipeline.steps.base_step_mixin import BaseStepMixin
    BASE_STEP_MIXIN_AVAILABLE = True
except ImportError as e:
    logging.error(f"BaseStepMixin ì„í¬íŠ¸ ì‹¤íŒ¨: {e}")
    BASE_STEP_MIXIN_AVAILABLE = False
    # ì•ˆì „í•œ í´ë°± í´ë˜ìŠ¤
    class BaseStepMixin:
        def __init__(self, *args, **kwargs):
            self.logger = logging.getLogger(f"pipeline.{self.__class__.__name__}")
            self.device = "cpu"
            self.is_initialized = False
            self.model_interface = None

# ğŸ”¥ ModelLoader ì—°ë™ - í•µì‹¬ ì„í¬íŠ¸ (ì™„ì „ ìˆ˜ì •)
try:
    from app.ai_pipeline.utils.model_loader import (
        ModelLoader,
        ModelConfig,
        ModelType,
        get_global_model_loader,
        preprocess_image,
        postprocess_segmentation
    )
    MODEL_LOADER_AVAILABLE = True
except ImportError as e:
    logging.error(f"ModelLoader ì„í¬íŠ¸ ì‹¤íŒ¨: {e}")
    MODEL_LOADER_AVAILABLE = False

# ë©”ëª¨ë¦¬ ê´€ë¦¬ ë° ìœ í‹¸ë¦¬í‹°
try:
    from app.ai_pipeline.utils.memory_manager import MemoryManager
    from app.ai_pipeline.utils.data_converter import DataConverter
except ImportError:
    MemoryManager = None
    DataConverter = None

# Apple Metal Performance Shaders
try:
    import torch.backends.mps
    MPS_AVAILABLE = torch.backends.mps.is_available()
except (ImportError, AttributeError):
    MPS_AVAILABLE = False

# CoreML ì§€ì›
try:
    import coremltools as ct
    COREML_AVAILABLE = True
except ImportError:
    COREML_AVAILABLE = False

# ì„ íƒì  ê³ ê¸‰ ë¼ì´ë¸ŒëŸ¬ë¦¬ë“¤
try:
    from scipy.spatial.distance import euclidean
    from scipy.ndimage import gaussian_filter
    SCIPY_AVAILABLE = True
except ImportError:
    SCIPY_AVAILABLE = False

try:
    from sklearn.cluster import KMeans
    SKLEARN_AVAILABLE = True
except ImportError:
    SKLEARN_AVAILABLE = False

# ==============================================
# ğŸ”¥ í¬ì¦ˆ ì¶”ì • ì„¤ì • ë° ìƒìˆ˜
# ==============================================

@dataclass
class PoseEstimationConfig:
    """
    ğŸ”§ ì•ˆì „í•œ í¬ì¦ˆ ì¶”ì • ì „ìš© ì„¤ì •
    ëª¨ë“  ê°€ëŠ¥í•œ íŒŒë¼ë¯¸í„°ë¥¼ ì§€ì›í•˜ì—¬ í˜¸í™˜ì„± ë³´ì¥
    """
    
    # === í•µì‹¬ ëª¨ë¸ ì„¤ì • ===
    model_name: str = "openpose_body_25"
    backup_model: str = "mediapipe_pose"
    device: Optional[str] = None  # ìë™ ê°ì§€
    
    # === ì…ë ¥/ì¶œë ¥ ì„¤ì • ===
    input_size: Tuple[int, int] = (368, 368)
    num_keypoints: int = 18
    confidence_threshold: float = 0.3
    
    # === M3 Max ìµœì í™” ì„¤ì • ===
    use_fp16: bool = True
    use_coreml: bool = True
    enable_neural_engine: bool = True
    memory_efficient: bool = True
    
    # === PipelineManager í˜¸í™˜ì„± íŒŒë¼ë¯¸í„°ë“¤ ===
    optimization_enabled: bool = True
    device_type: str = "auto"
    memory_gb: float = 16.0
    is_m3_max: bool = False
    quality_level: str = "balanced"
    
    # === ì„±ëŠ¥ ì„¤ì • ===
    batch_size: int = 1
    max_cache_size: int = 30
    warmup_enabled: bool = True
    
    # === í’ˆì§ˆ ì„¤ì • ===
    apply_postprocessing: bool = True
    nms_threshold: float = 0.1
    keypoint_refinement: bool = True
    
    # === ì‹œê°í™” ì„¤ì • ===
    enable_visualization: bool = True
    visualization_quality: str = "high"
    show_keypoint_labels: bool = True
    skeleton_thickness: int = 3
    keypoint_radius: int = 6
    
    # === í¬ì¦ˆ ë¶„ì„ ì„¤ì • ===
    analyze_pose_quality: bool = True
    detect_pose_type: bool = True
    calculate_angles: bool = True
    estimate_proportions: bool = True
    
    # === ì¶”ê°€ í˜¸í™˜ì„± íŒŒë¼ë¯¸í„°ë“¤ ===
    model_type: Optional[str] = None
    model_path: Optional[str] = None
    enable_gpu_acceleration: bool = True
    enable_optimization: bool = True
    processing_mode: str = "production"
    fallback_enabled: bool = True
    
    def __post_init__(self):
        """ì•ˆì „í•œ í›„ì²˜ë¦¬ ì´ˆê¸°í™”"""
        try:
            # ë””ë°”ì´ìŠ¤ ìë™ ê°ì§€
            if self.device is None:
                self.device = self._auto_detect_device()
            
            # M3 Max ê°ì§€ ë° ì„¤ì •
            if self.device == 'mps' or self._detect_m3_max():
                self.is_m3_max = True
                if self.optimization_enabled:
                    self.use_fp16 = True
                    self.enable_neural_engine = True
                    if COREML_AVAILABLE:
                        self.use_coreml = True
            
            # ë©”ëª¨ë¦¬ í¬ê¸° ìë™ ê°ì§€
            if self.memory_gb <= 16.0:
                self.memory_gb = self._detect_system_memory()
            
            # í’ˆì§ˆ ë ˆë²¨ì— ë”°ë¥¸ ì„¤ì • ì¡°ì •
            self._adjust_quality_settings()
            
        except Exception as e:
            logging.warning(f"âš ï¸ PoseEstimationConfig í›„ì²˜ë¦¬ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    
    def _auto_detect_device(self) -> str:
        """ë””ë°”ì´ìŠ¤ ìë™ ê°ì§€"""
        try:
            if MPS_AVAILABLE:
                return 'mps'
            elif torch.cuda.is_available():
                return 'cuda'
            else:
                return 'cpu'
        except Exception:
            return 'cpu'
    
    def _detect_m3_max(self) -> bool:
        """M3 Max ê°ì§€"""
        try:
            import platform
            system_info = platform.processor()
            return 'M3 Max' in system_info or 'Apple M3 Max' in system_info
        except Exception:
            return False
    
    def _detect_system_memory(self) -> float:
        """ì‹œìŠ¤í…œ ë©”ëª¨ë¦¬ ê°ì§€"""
        try:
            import psutil
            memory_bytes = psutil.virtual_memory().total
            memory_gb = memory_bytes / (1024**3)
            return round(memory_gb, 1)
        except Exception:
            return 16.0
    
    def _adjust_quality_settings(self):
        """í’ˆì§ˆ ë ˆë²¨ì— ë”°ë¥¸ ì„¤ì • ì¡°ì •"""
        try:
            if self.quality_level == "fast":
                self.apply_postprocessing = False
                self.keypoint_refinement = False
                self.analyze_pose_quality = False
                self.input_size = (256, 256)
            elif self.quality_level == "balanced":
                self.apply_postprocessing = True
                self.keypoint_refinement = True
                self.analyze_pose_quality = True
                self.input_size = (368, 368)
            elif self.quality_level in ["high", "maximum"]:
                self.apply_postprocessing = True
                self.keypoint_refinement = True
                self.analyze_pose_quality = True
                self.input_size = (432, 432)
        except Exception as e:
            logging.warning(f"âš ï¸ í’ˆì§ˆ ì„¤ì • ì¡°ì • ì‹¤íŒ¨: {e}")

# OpenPose 18 í‚¤í¬ì¸íŠ¸ ì •ì˜
OPENPOSE_18_KEYPOINTS = {
    0: 'nose',
    1: 'neck',
    2: 'right_shoulder',
    3: 'right_elbow',
    4: 'right_wrist',
    5: 'left_shoulder',
    6: 'left_elbow',
    7: 'left_wrist',
    8: 'mid_hip',
    9: 'right_hip',
    10: 'right_knee',
    11: 'right_ankle',
    12: 'left_hip',
    13: 'left_knee',
    14: 'left_ankle',
    15: 'right_eye',
    16: 'left_eye',
    17: 'right_ear'
}

# í‚¤í¬ì¸íŠ¸ë³„ ìƒ‰ìƒ (ì‹œê°í™”ìš©)
KEYPOINT_COLORS = {
    0: (255, 0, 0),     # nose - ë¹¨ê°•
    1: (255, 165, 0),   # neck - ì£¼í™©
    2: (255, 255, 0),   # right_shoulder - ë…¸ë‘
    3: (0, 255, 0),     # right_elbow - ì´ˆë¡
    4: (0, 255, 255),   # right_wrist - ì²­ë¡
    5: (0, 0, 255),     # left_shoulder - íŒŒë‘
    6: (255, 0, 255),   # left_elbow - ìí™
    7: (128, 0, 128),   # left_wrist - ë³´ë¼
    8: (255, 192, 203), # mid_hip - ë¶„í™
    9: (255, 218, 185), # right_hip - ì‚´ìƒ‰
    10: (210, 180, 140), # right_knee - í™©ê°ˆìƒ‰
    11: (255, 20, 147),  # right_ankle - ì§„ë¶„í™
    12: (255, 228, 196), # left_hip - ì—°ì‚´ìƒ‰
    13: (255, 160, 122), # left_knee - ì—°ì£¼í™©
    14: (255, 182, 193), # left_ankle - ì—°ë¶„í™
    15: (173, 216, 230), # right_eye - ì—°í•˜ëŠ˜
    16: (144, 238, 144), # left_eye - ì—°ì´ˆë¡
    17: (139, 69, 19)    # right_ear - ê°ˆìƒ‰
}

# ìŠ¤ì¼ˆë ˆí†¤ ì—°ê²° ì •ì˜
SKELETON_CONNECTIONS = [
    # ë¨¸ë¦¬ ë° ëª©
    (0, 1),   # nose -> neck
    (15, 0),  # right_eye -> nose
    (16, 0),  # left_eye -> nose
    (17, 15), # right_ear -> right_eye
    
    # ìƒì²´
    (1, 2),   # neck -> right_shoulder
    (1, 5),   # neck -> left_shoulder
    (2, 3),   # right_shoulder -> right_elbow
    (3, 4),   # right_elbow -> right_wrist
    (5, 6),   # left_shoulder -> left_elbow
    (6, 7),   # left_elbow -> left_wrist
    
    # ëª¸í†µ
    (1, 8),   # neck -> mid_hip
    (2, 9),   # right_shoulder -> right_hip
    (5, 12),  # left_shoulder -> left_hip
    (8, 9),   # mid_hip -> right_hip
    (8, 12),  # mid_hip -> left_hip
    
    # í•˜ì²´
    (9, 10),  # right_hip -> right_knee
    (10, 11), # right_knee -> right_ankle
    (12, 13), # left_hip -> left_knee
    (13, 14)  # left_knee -> left_ankle
]

# ìŠ¤ì¼ˆë ˆí†¤ ì—°ê²°ë³„ ìƒ‰ìƒ
SKELETON_COLORS = {
    # ë¨¸ë¦¬/ëª© - ë¹¨ê°• ê³„ì—´
    (0, 1): (255, 0, 0),
    (15, 0): (255, 100, 100),
    (16, 0): (255, 150, 150),
    (17, 15): (200, 0, 0),
    
    # ì˜¤ë¥¸íŒ” - ì´ˆë¡ ê³„ì—´  
    (1, 2): (0, 255, 0),
    (2, 3): (0, 200, 0),
    (3, 4): (0, 150, 0),
    
    # ì™¼íŒ” - íŒŒë‘ ê³„ì—´
    (1, 5): (0, 0, 255),
    (5, 6): (0, 0, 200),
    (6, 7): (0, 0, 150),
    
    # ëª¸í†µ - ë…¸ë‘ ê³„ì—´
    (1, 8): (255, 255, 0),
    (2, 9): (200, 200, 0),
    (5, 12): (150, 150, 0),
    (8, 9): (255, 200, 0),
    (8, 12): (200, 255, 0),
    
    # ì˜¤ë¥¸ë‹¤ë¦¬ - ìí™ ê³„ì—´
    (9, 10): (255, 0, 255),
    (10, 11): (200, 0, 200),
    
    # ì™¼ë‹¤ë¦¬ - ì²­ë¡ ê³„ì—´
    (12, 13): (0, 255, 255),
    (13, 14): (0, 200, 200)
}

# í¬ì¦ˆ íƒ€ì… ë¶„ë¥˜
class PoseType(Enum):
    FRONT_FACING = "front_facing"
    SIDE_PROFILE = "side_profile"
    BACK_FACING = "back_facing"
    ANGLED = "angled"
    UNKNOWN = "unknown"

class PoseQuality(Enum):
    EXCELLENT = "excellent"
    GOOD = "good"
    FAIR = "fair"
    POOR = "poor"

# ==============================================
# ğŸ”¥ ë©”ì¸ PoseEstimationStep í´ë˜ìŠ¤ (ì™„ì „ ìˆ˜ì •)
# ==============================================

class PoseEstimationStep(BaseStepMixin):
    """
    ğŸ”¥ ì™„ì „ ìˆ˜ì •ëœ M3 Max ìµœì í™” í”„ë¡œë•ì…˜ ë ˆë²¨ í¬ì¦ˆ ì¶”ì • Step + ì‹œê°í™”
    
    âœ… BaseStepMixin ì™„ì „ ì—°ë™ìœ¼ë¡œ logger ì†ì„± ëˆ„ë½ ë¬¸ì œ í•´ê²°
    âœ… ModelLoader ì¸í„°í˜ì´ìŠ¤ ì™„ë²½ êµ¬í˜„
    âœ… OpenPose 18 í‚¤í¬ì¸íŠ¸ í¬ì¦ˆ ì¶”ì •
    âœ… M3 Max Neural Engine ê°€ì†
    âœ… í”„ë¡œë•ì…˜ ì•ˆì •ì„± ë³´ì¥
    âœ… í‚¤í¬ì¸íŠ¸ ë° ìŠ¤ì¼ˆë ˆí†¤ ì‹œê°í™”
    âœ… ì™„ì „í•œ íŒŒë¼ë¯¸í„° í˜¸í™˜ì„±
    """
    
    def __init__(
        self,
        device: Optional[str] = None,
        config: Optional[Union[Dict[str, Any], PoseEstimationConfig]] = None,
        **kwargs
    ):
        """
        ğŸ”¥ ì™„ì „ ìˆ˜ì •ëœ ìƒì„±ì - BaseStepMixin ë¨¼ì € ì´ˆê¸°í™”
        ëª¨ë“  ê°€ëŠ¥í•œ íŒŒë¼ë¯¸í„°ë¥¼ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬
        
        Args:
            device: ë””ë°”ì´ìŠ¤ ('mps', 'cuda', 'cpu', None=ìë™ê°ì§€)
            config: ì„¤ì • (dict ë˜ëŠ” PoseEstimationConfig)
            **kwargs: ì¶”ê°€ ì„¤ì • (PipelineManager í˜¸í™˜ì„±)
        """
        
        # ğŸ”¥ 1ë‹¨ê³„: BaseStepMixin ë¨¼ì € ì´ˆê¸°í™” (logger ë¬¸ì œ í•´ê²°)
        super().__init__()
        
        # ğŸ”¥ 2ë‹¨ê³„: Step ì „ìš© ì†ì„± ì„¤ì •
        self.step_name = "PoseEstimationStep"
        self.step_number = 2
        self.device = device or self._auto_detect_device()
        self.config = self._setup_config_safe(config, kwargs)
        
        # ğŸ”¥ 3ë‹¨ê³„: ModelLoader ì¸í„°í˜ì´ìŠ¤ ì„¤ì •
        self._setup_model_interface_safe()
        
        # ğŸ”¥ 4ë‹¨ê³„: ìƒíƒœ ë³€ìˆ˜ ì´ˆê¸°í™”
        self.is_initialized = False
        self.models_loaded = {}
        self.processing_stats = {
            'total_processed': 0,
            'average_time': 0.0,
            'cache_hits': 0,
            'model_switches': 0,
            'pose_qualities': {'excellent': 0, 'good': 0, 'fair': 0, 'poor': 0}
        }
        
        # ğŸ”¥ 5ë‹¨ê³„: ë©”ëª¨ë¦¬ ë° ìºì‹œ ê´€ë¦¬
        self.result_cache: Dict[str, Any] = {}
        self.cache_lock = threading.RLock()
        self.executor = ThreadPoolExecutor(max_workers=2, thread_name_prefix="pose_estimation")
        
        # ğŸ”¥ 6ë‹¨ê³„: ë©”ëª¨ë¦¬ ë§¤ë‹ˆì € ì´ˆê¸°í™”
        self.memory_manager = self._create_memory_manager_safe()
        self.data_converter = self._create_data_converter_safe()
        
        self.logger.info(f"ğŸ¯ {self.step_name} ì™„ì „ ì´ˆê¸°í™” ì™„ë£Œ - ë””ë°”ì´ìŠ¤: {self.device}")
    
    def _setup_config_safe(
        self, 
        config: Optional[Union[Dict, PoseEstimationConfig]], 
        kwargs: Dict[str, Any]
    ) -> PoseEstimationConfig:
        """ì•ˆì „í•œ ì„¤ì • ê°ì²´ ìƒì„±"""
        try:
            if isinstance(config, PoseEstimationConfig):
                # ê¸°ì¡´ configì— kwargs ì•ˆì „í•˜ê²Œ ë³‘í•©
                for key, value in kwargs.items():
                    if hasattr(config, key):
                        try:
                            setattr(config, key, value)
                        except Exception as e:
                            self.logger.warning(f"âš ï¸ ì„¤ì • ì†ì„± {key} ì„¤ì • ì‹¤íŒ¨: {e}")
                return config
            
            elif isinstance(config, dict):
                # dictë¥¼ PoseEstimationConfigë¡œ ì•ˆì „í•˜ê²Œ ë³€í™˜
                merged_config = {**config, **kwargs}
                return PoseEstimationConfig(**self._filter_valid_params(merged_config))
            
            else:
                # kwargsë¡œë§Œ ì•ˆì „í•˜ê²Œ ìƒì„±
                return PoseEstimationConfig(**self._filter_valid_params(kwargs))
                
        except Exception as e:
            self.logger.warning(f"âš ï¸ ì„¤ì • ìƒì„± ì‹¤íŒ¨, ê¸°ë³¸ ì„¤ì • ì‚¬ìš©: {e}")
            # ìµœì†Œí•œì˜ ì•ˆì „í•œ ì„¤ì •
            return PoseEstimationConfig(
                device=self.device,
                optimization_enabled=kwargs.get('optimization_enabled', True),
                quality_level=kwargs.get('quality_level', 'balanced')
            )
    
    def _filter_valid_params(self, params: Dict[str, Any]) -> Dict[str, Any]:
        """PoseEstimationConfigì— ìœ íš¨í•œ íŒŒë¼ë¯¸í„°ë§Œ í•„í„°ë§"""
        valid_params = {}
        config_fields = set(field.name for field in PoseEstimationConfig.__dataclass_fields__.values())
        
        for key, value in params.items():
            if key in config_fields:
                valid_params[key] = value
            else:
                self.logger.debug(f"ğŸ” ì•Œ ìˆ˜ ì—†ëŠ” íŒŒë¼ë¯¸í„° ë¬´ì‹œ: {key}")
        
        return valid_params
    
    def _setup_model_interface_safe(self, model_loader=None):
        """ì•ˆì „í•œ ModelLoader ì¸í„°í˜ì´ìŠ¤ ì„¤ì •"""
        try:
            if not MODEL_LOADER_AVAILABLE:
                self.logger.warning("âš ï¸ ModelLoader ì‚¬ìš© ë¶ˆê°€ëŠ¥ - ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œ")
                self.model_interface = None
                return
            
            if model_loader is None:
                # ì „ì—­ ëª¨ë¸ ë¡œë” ì‚¬ìš©
                model_loader = get_global_model_loader()
            
            if model_loader:
                self.model_interface = model_loader.create_step_interface(
                    self.__class__.__name__
                )
                self.logger.info(f"ğŸ”— {self.__class__.__name__} ëª¨ë¸ ì¸í„°í˜ì´ìŠ¤ ì„¤ì • ì™„ë£Œ")
            else:
                self.logger.warning("âš ï¸ ì „ì—­ ModelLoaderë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
                self.model_interface = None
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ {self.__class__.__name__} ëª¨ë¸ ì¸í„°í˜ì´ìŠ¤ ì„¤ì • ì‹¤íŒ¨: {e}")
            self.model_interface = None
    
    def _auto_detect_device(self) -> str:
        """ë””ë°”ì´ìŠ¤ ìë™ ê°ì§€"""
        try:
            if MPS_AVAILABLE:
                return 'mps'
            elif torch.cuda.is_available():
                return 'cuda'
            else:
                return 'cpu'
        except Exception:
            return 'cpu'
    
    def _create_memory_manager_safe(self):
        """ì•ˆì „í•œ ë©”ëª¨ë¦¬ ë§¤ë‹ˆì € ìƒì„±"""
        try:
            if MemoryManager:
                return MemoryManager(device=self.device)
        except Exception as e:
            self.logger.warning(f"âš ï¸ MemoryManager ìƒì„± ì‹¤íŒ¨: {e}")
        
        # ì•ˆì „í•œ í´ë°± ë©”ëª¨ë¦¬ ë§¤ë‹ˆì €
        class SafeMemoryManager:
            def __init__(self, device): 
                self.device = device
            
            async def get_usage_stats(self): 
                return {"memory_used": "N/A", "device": self.device}
            
            async def cleanup(self): 
                try:
                    gc.collect()
                    if self.device == 'mps' and MPS_AVAILABLE:
                        if hasattr(torch.mps, 'empty_cache'):
                            torch.mps.empty_cache()
                except Exception:
                    pass
        
        return SafeMemoryManager(self.device)
    
    def _create_data_converter_safe(self):
        """ì•ˆì „í•œ ë°ì´í„° ì»¨ë²„í„° ìƒì„±"""
        try:
            if DataConverter:
                return DataConverter()
        except Exception as e:
            self.logger.warning(f"âš ï¸ DataConverter ìƒì„± ì‹¤íŒ¨: {e}")
        
        # ì•ˆì „í•œ í´ë°± ì»¨ë²„í„°
        class SafeDataConverter:
            def convert(self, data): 
                return data
            
            def to_tensor(self, data): 
                try:
                    return torch.from_numpy(data) if isinstance(data, np.ndarray) else data
                except Exception:
                    return data
            
            def to_numpy(self, data): 
                try:
                    return data.cpu().numpy() if torch.is_tensor(data) else data
                except Exception:
                    return data
        
        return SafeDataConverter()
    
    async def initialize(self) -> bool:
        """
        âœ… Step ì´ˆê¸°í™” - ì‹¤ì œ AI ëª¨ë¸ ë¡œë“œ
        
        Returns:
            bool: ì´ˆê¸°í™” ì„±ê³µ ì—¬ë¶€
        """
        try:
            self.logger.info("ğŸ”„ 2ë‹¨ê³„: í¬ì¦ˆ ì¶”ì • ëª¨ë¸ ì´ˆê¸°í™” ì¤‘...")
            
            if not MODEL_LOADER_AVAILABLE:
                self.logger.warning("âš ï¸ ModelLoaderê°€ ì‚¬ìš© ë¶ˆê°€ëŠ¥ - ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œ")
                self.is_initialized = True
                return True
            
            # === ì£¼ ëª¨ë¸ ë¡œë“œ (OpenPose) ===
            primary_model = await self._load_primary_model_safe()
            
            # === ë°±ì—… ëª¨ë¸ ë¡œë“œ (MediaPipe) ===
            backup_model = await self._load_backup_model_safe()
            
            # === ëª¨ë¸ ì›Œë°ì—… ===
            if self.config.warmup_enabled:
                await self._warmup_models_safe()
            
            # === M3 Max ìµœì í™” ì ìš© ===
            if self.device == 'mps':
                await self._apply_m3_max_optimizations_safe()
            
            self.is_initialized = True
            self.logger.info("âœ… 2ë‹¨ê³„: í¬ì¦ˆ ì¶”ì • ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ")
            
            return True
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ 2ë‹¨ê³„ ì´ˆê¸°í™” ë¶€ë¶„ ì‹¤íŒ¨: {e}")
            # ë¶€ë¶„ ì‹¤íŒ¨ì—ë„ ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œë¡œ ê³„ì† ì§„í–‰
            self.is_initialized = True
            return True
    
    async def _load_primary_model_safe(self) -> Optional[Any]:
        """ì•ˆì „í•œ ì£¼ ëª¨ë¸ ë¡œë“œ"""
        try:
            if not self.model_interface:
                self.logger.warning("âš ï¸ ëª¨ë¸ ì¸í„°í˜ì´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤")
                return None
            
            self.logger.info(f"ğŸ“¦ ì£¼ ëª¨ë¸ ë¡œë“œ ì¤‘: {self.config.model_name}")
            
            # ModelLoaderë¥¼ í†µí•œ ì‹¤ì œ AI ëª¨ë¸ ë¡œë“œ
            model = await self.model_interface.get_model(self.config.model_name)
            
            if model:
                self.models_loaded['primary'] = model
                self.logger.info(f"âœ… ì£¼ ëª¨ë¸ ë¡œë“œ ì„±ê³µ: {self.config.model_name}")
                return model
            else:
                self.logger.warning(f"âš ï¸ ì£¼ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {self.config.model_name}")
                return None
                
        except Exception as e:
            self.logger.warning(f"âš ï¸ ì£¼ ëª¨ë¸ ë¡œë“œ ì˜¤ë¥˜: {e}")
            return None
    
    async def _load_backup_model_safe(self) -> Optional[Any]:
        """ì•ˆì „í•œ ë°±ì—… ëª¨ë¸ ë¡œë“œ"""
        try:
            if not self.model_interface:
                return None
            
            self.logger.info(f"ğŸ“¦ ë°±ì—… ëª¨ë¸ ë¡œë“œ ì¤‘: {self.config.backup_model}")
            
            backup_model = await self.model_interface.get_model(self.config.backup_model)
            
            if backup_model:
                self.models_loaded['backup'] = backup_model
                self.logger.info(f"âœ… ë°±ì—… ëª¨ë¸ ë¡œë“œ ì„±ê³µ: {self.config.backup_model}")
                return backup_model
            else:
                self.logger.info(f"â„¹ï¸ ë°±ì—… ëª¨ë¸ ë¡œë“œ ê±´ë„ˆëœ€: {self.config.backup_model}")
                return None
                
        except Exception as e:
            self.logger.warning(f"âš ï¸ ë°±ì—… ëª¨ë¸ ë¡œë“œ ì˜¤ë¥˜: {e}")
            return None
    
    async def _warmup_models_safe(self):
        """ì•ˆì „í•œ ëª¨ë¸ ì›Œë°ì—…"""
        try:
            self.logger.info("ğŸ”¥ 2ë‹¨ê³„ ëª¨ë¸ ì›Œë°ì—… ì¤‘...")
            
            # ë”ë¯¸ ì…ë ¥ ìƒì„±
            dummy_input = torch.randn(1, 3, *self.config.input_size, device=self.device)
            
            # ì£¼ ëª¨ë¸ ì›Œë°ì—…
            if 'primary' in self.models_loaded:
                try:
                    model = self.models_loaded['primary']
                    if hasattr(model, 'eval'):
                        model.eval()
                    with torch.no_grad():
                        _ = model(dummy_input)
                    self.logger.info("ğŸ”¥ ì£¼ ëª¨ë¸ ì›Œë°ì—… ì™„ë£Œ")
                except Exception as e:
                    self.logger.warning(f"âš ï¸ ì£¼ ëª¨ë¸ ì›Œë°ì—… ì‹¤íŒ¨: {e}")
            
            # ë°±ì—… ëª¨ë¸ ì›Œë°ì—…
            if 'backup' in self.models_loaded:
                try:
                    model = self.models_loaded['backup']
                    if hasattr(model, 'eval'):
                        model.eval()
                    with torch.no_grad():
                        _ = model(dummy_input)
                    self.logger.info("ğŸ”¥ ë°±ì—… ëª¨ë¸ ì›Œë°ì—… ì™„ë£Œ")
                except Exception as e:
                    self.logger.warning(f"âš ï¸ ë°±ì—… ëª¨ë¸ ì›Œë°ì—… ì‹¤íŒ¨: {e}")
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ ëª¨ë¸ ì›Œë°ì—… ì „ì²´ ì‹¤íŒ¨: {e}")
    
    async def _apply_m3_max_optimizations_safe(self):
        """ì•ˆì „í•œ M3 Max ìµœì í™”"""
        try:
            optimizations = []
            
            # 1. MPS ë°±ì—”ë“œ ìµœì í™”
            try:
                if hasattr(torch.backends.mps, 'set_per_process_memory_fraction'):
                    torch.backends.mps.set_per_process_memory_fraction(0.8)
                    optimizations.append("MPS memory optimization")
            except Exception as e:
                self.logger.debug(f"MPS ë©”ëª¨ë¦¬ ìµœì í™” ì‹¤íŒ¨: {e}")
            
            # 2. Neural Engine ì¤€ë¹„
            if self.config.enable_neural_engine and COREML_AVAILABLE:
                optimizations.append("Neural Engine ready")
            
            # 3. ë©”ëª¨ë¦¬ í’€ë§
            if self.config.memory_efficient:
                try:
                    torch.backends.mps.allow_tf32 = True
                    optimizations.append("Memory pooling")
                except Exception as e:
                    self.logger.debug(f"ë©”ëª¨ë¦¬ í’€ë§ ì„¤ì • ì‹¤íŒ¨: {e}")
            
            if optimizations:
                self.logger.info(f"ğŸ M3 Max ìµœì í™” ì ìš©: {', '.join(optimizations)}")
            else:
                self.logger.info("ğŸ M3 Max ê¸°ë³¸ ìµœì í™” ì ìš©")
                
        except Exception as e:
            self.logger.warning(f"âš ï¸ M3 Max ìµœì í™” ì‹¤íŒ¨: {e}")
    
    async def process(
        self,
        person_image_tensor: torch.Tensor,
        **kwargs
    ) -> Dict[str, Any]:
        """
        âœ… ë©”ì¸ ì²˜ë¦¬ í•¨ìˆ˜ - ì‹¤ì œ AI í¬ì¦ˆ ì¶”ì • + ì‹œê°í™”
        
        Args:
            person_image_tensor: ì…ë ¥ ì´ë¯¸ì§€ í…ì„œ [B, C, H, W]
            **kwargs: ì¶”ê°€ ì˜µì…˜
            
        Returns:
            Dict[str, Any]: í¬ì¦ˆ ì¶”ì • ê²°ê³¼ + ì‹œê°í™” ì´ë¯¸ì§€
        """
        
        if not self.is_initialized:
            self.logger.warning("âš ï¸ ëª¨ë¸ì´ ì´ˆê¸°í™”ë˜ì§€ ì•ŠìŒ - ìë™ ì´ˆê¸°í™” ì‹œë„")
            await self.initialize()
        
        start_time = time.time()
        
        try:
            # === ìºì‹œ í™•ì¸ ===
            cache_key = self._generate_cache_key_safe(person_image_tensor)
            cached_result = self._get_cached_result_safe(cache_key)
            if cached_result:
                self.processing_stats['cache_hits'] += 1
                self.logger.info("ğŸ’¾ 2ë‹¨ê³„: ìºì‹œëœ ê²°ê³¼ ë°˜í™˜")
                return cached_result
            
            # === ì…ë ¥ ì „ì²˜ë¦¬ ===
            preprocessed_input = await self._preprocess_input_safe(person_image_tensor)
            
            # === ì‹¤ì œ AI ëª¨ë¸ ì¶”ë¡  ===
            pose_result = await self._run_inference_safe(preprocessed_input)
            
            # === í›„ì²˜ë¦¬ ë° ê²°ê³¼ ìƒì„± ===
            final_result = await self._postprocess_result_safe(
                pose_result,
                person_image_tensor.shape[2:],
                person_image_tensor,
                start_time
            )
            
            # === ìºì‹œ ì €ì¥ ===
            self._cache_result_safe(cache_key, final_result)
            
            # === í†µê³„ ì—…ë°ì´íŠ¸ ===
            self._update_processing_stats(time.time() - start_time, final_result)
            
            self.logger.info(f"âœ… 2ë‹¨ê³„ ì™„ë£Œ - {final_result['processing_time']:.3f}ì´ˆ")
            
            return final_result
            
        except Exception as e:
            self.logger.error(f"âŒ 2ë‹¨ê³„ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            # í”„ë¡œë•ì…˜ í™˜ê²½ì—ì„œëŠ” ê¸°ë³¸ ê²°ê³¼ ë°˜í™˜
            return self._create_fallback_result_safe(person_image_tensor.shape[2:], time.time() - start_time, str(e))
    
    async def _preprocess_input_safe(self, image_tensor: torch.Tensor) -> torch.Tensor:
        """ì•ˆì „í•œ ì…ë ¥ ì´ë¯¸ì§€ ì „ì²˜ë¦¬"""
        try:
            # í¬ê¸° ì •ê·œí™”
            if image_tensor.shape[2:] != self.config.input_size:
                resized = F.interpolate(
                    image_tensor,
                    size=self.config.input_size,
                    mode='bilinear',
                    align_corners=False
                )
            else:
                resized = image_tensor
            
            # ê°’ ë²”ìœ„ ì •ê·œí™” (0-1)
            if resized.max() > 1.0:
                resized = resized.float() / 255.0
            
            # OpenPoseìš© ì •ê·œí™” (í‰ê·  128ë¡œ ì´ë™)
            normalized = (resized * 255.0) - 128.0
            
            # FP16 ë³€í™˜ (M3 Max ìµœì í™”)
            if self.config.use_fp16 and self.device != 'cpu':
                try:
                    normalized = normalized.half()
                except Exception as e:
                    self.logger.warning(f"âš ï¸ FP16 ë³€í™˜ ì‹¤íŒ¨: {e}")
            
            return normalized.to(self.device)
            
        except Exception as e:
            self.logger.error(f"âŒ ì…ë ¥ ì „ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            # ê¸°ë³¸ ì „ì²˜ë¦¬ í´ë°±
            try:
                return F.interpolate(image_tensor, size=self.config.input_size, mode='bilinear').to(self.device)
            except Exception as e2:
                self.logger.error(f"âŒ í´ë°± ì „ì²˜ë¦¬ë„ ì‹¤íŒ¨: {e2}")
                raise
    
    async def _run_inference_safe(self, input_tensor: torch.Tensor) -> Dict[str, Any]:
        """ì•ˆì „í•œ AI ëª¨ë¸ ì¶”ë¡ """
        try:
            # ì£¼ ëª¨ë¸ (OpenPose) ìš°ì„  ì‹œë„
            if 'primary' in self.models_loaded:
                model = self.models_loaded['primary']
                try:
                    with torch.no_grad():
                        if self.config.use_fp16 and self.device != 'cpu':
                            try:
                                with torch.autocast(device_type=self.device.replace(':', '_'), dtype=torch.float16):
                                    output = model(input_tensor)
                            except Exception:
                                # autocast ì‹¤íŒ¨ ì‹œ ì¼ë°˜ ì¶”ë¡ 
                                output = model(input_tensor)
                        else:
                            output = model(input_tensor)
                    
                    # OpenPose ì¶œë ¥ ì²˜ë¦¬
                    keypoints_18, confidence = self._process_openpose_output(output)
                    
                    self.logger.debug("ğŸš€ ì£¼ ëª¨ë¸ ì¶”ë¡  ì™„ë£Œ (OpenPose)")
                    return {
                        'keypoints_18': keypoints_18,
                        'pose_confidence': confidence,
                        'keypoints_detected': len([kp for kp in keypoints_18 if kp[2] > self.config.confidence_threshold]),
                        'detection_method': 'openpose'
                    }
                    
                except Exception as e:
                    self.logger.warning(f"âš ï¸ ì£¼ ëª¨ë¸ ì¶”ë¡  ì‹¤íŒ¨: {e}")
                    self.processing_stats['model_switches'] += 1
            
            # ë°±ì—… ëª¨ë¸ (MediaPipe) ì‹œë„
            if 'backup' in self.models_loaded:
                model = self.models_loaded['backup']
                try:
                    with torch.no_grad():
                        output = model(input_tensor)
                    
                    # MediaPipe ì¶œë ¥ ì²˜ë¦¬
                    keypoints_18, confidence = self._process_mediapipe_output(output)
                    
                    self.logger.debug("ğŸ”„ ë°±ì—… ëª¨ë¸ ì¶”ë¡  ì™„ë£Œ (MediaPipe)")
                    return {
                        'keypoints_18': keypoints_18,
                        'pose_confidence': confidence,
                        'keypoints_detected': len([kp for kp in keypoints_18 if kp[2] > self.config.confidence_threshold]),
                        'detection_method': 'mediapipe'
                    }
                    
                except Exception as e:
                    self.logger.warning(f"âš ï¸ ë°±ì—… ëª¨ë¸ ì¶”ë¡ ë„ ì‹¤íŒ¨: {e}")
            
            # ëª¨ë“  ëª¨ë¸ì´ ì‹¤íŒ¨í•œ ê²½ìš° - ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼ ìƒì„±
            self.logger.warning("âš ï¸ ëª¨ë“  AI ëª¨ë¸ ì‹¤íŒ¨ - ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼ ìƒì„±")
            return self._create_simulation_result_safe(input_tensor)
            
        except Exception as e:
            self.logger.error(f"âŒ ëª¨ë¸ ì¶”ë¡  ì‹¤íŒ¨: {e}")
            # ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼ë¡œ í´ë°±
            return self._create_simulation_result_safe(input_tensor)
    
    def _process_openpose_output(self, output: torch.Tensor) -> Tuple[List[List[float]], float]:
        """OpenPose ëª¨ë¸ ì¶œë ¥ ì²˜ë¦¬"""
        try:
            # OpenPoseëŠ” Part Affinity Fields (PAFs)ì™€ heatmapsì„ ì¶œë ¥
            if isinstance(output, (list, tuple)):
                paf_output, heatmap_output = output
            else:
                # ë‹¨ì¼ ì¶œë ¥ì¸ ê²½ìš° heatmapìœ¼ë¡œ ê°€ì •
                heatmap_output = output
            
            # Heatmapì—ì„œ í‚¤í¬ì¸íŠ¸ ì¶”ì¶œ
            batch_size, num_keypoints, height, width = heatmap_output.shape
            
            keypoints_18 = []
            confidences = []
            
            for i in range(min(18, num_keypoints)):  # 18ê°œ í‚¤í¬ì¸íŠ¸ë¡œ ì œí•œ
                heatmap = heatmap_output[0, i].cpu().numpy()
                
                # ìµœëŒ€ê°’ ìœ„ì¹˜ ì°¾ê¸°
                y_idx, x_idx = np.unravel_index(np.argmax(heatmap), heatmap.shape)
                
                # ì›ë³¸ ì´ë¯¸ì§€ í¬ê¸°ë¡œ ìŠ¤ì¼€ì¼ë§
                x = float(x_idx * self.config.input_size[1] / width)
                y = float(y_idx * self.config.input_size[0] / height)
                confidence = float(heatmap[y_idx, x_idx])
                
                keypoints_18.append([x, y, confidence])
                confidences.append(confidence)
            
            # 18ê°œ í‚¤í¬ì¸íŠ¸ë¡œ ë§ì¶”ê¸°
            while len(keypoints_18) < 18:
                keypoints_18.append([0.0, 0.0, 0.0])
            
            average_confidence = np.mean(confidences) if confidences else 0.0
            
            return keypoints_18[:18], average_confidence
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ OpenPose ì¶œë ¥ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return [[0.0, 0.0, 0.0] for _ in range(18)], 0.0
    
    def _process_mediapipe_output(self, output: torch.Tensor) -> Tuple[List[List[float]], float]:
        """MediaPipe ëª¨ë¸ ì¶œë ¥ ì²˜ë¦¬"""
        try:
            # MediaPipeëŠ” ì§ì ‘ í‚¤í¬ì¸íŠ¸ ì¢Œí‘œë¥¼ ì¶œë ¥
            output_np = output.cpu().numpy().squeeze()
            
            if output_np.shape[-1] == 3:  # [x, y, confidence] í˜•íƒœ
                keypoints_raw = output_np.reshape(-1, 3)
            else:
                # ë‹¤ë¥¸ í˜•íƒœì¸ ê²½ìš° ë³€í™˜
                keypoints_raw = output_np.reshape(-1, 2)
                # confidenceë¥¼ 1.0ìœ¼ë¡œ ê°€ì •
                keypoints_raw = np.concatenate([
                    keypoints_raw, 
                    np.ones((len(keypoints_raw), 1))
                ], axis=1)
            
            # MediaPipeì—ì„œ OpenPose 18 í‚¤í¬ì¸íŠ¸ë¡œ ë³€í™˜
            keypoints_18 = self._convert_mediapipe_to_openpose(keypoints_raw)
            
            confidences = [kp[2] for kp in keypoints_18]
            average_confidence = np.mean(confidences) if confidences else 0.0
            
            return keypoints_18, average_confidence
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ MediaPipe ì¶œë ¥ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return [[0.0, 0.0, 0.0] for _ in range(18)], 0.0
    
    def _convert_mediapipe_to_openpose(self, mediapipe_keypoints: np.ndarray) -> List[List[float]]:
        """MediaPipe í‚¤í¬ì¸íŠ¸ë¥¼ OpenPose 18 í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
        try:
            # MediaPipe Poseì—ì„œ OpenPose 18ë¡œì˜ ë§¤í•‘
            mp_to_op_mapping = {
                0: 0,   # nose
                11: 1,  # neck (approximate from shoulders)
                12: 2,  # right_shoulder
                14: 3,  # right_elbow
                16: 4,  # right_wrist
                11: 5,  # left_shoulder
                13: 6,  # left_elbow
                15: 7,  # left_wrist
                23: 8,  # mid_hip (approximate)
                24: 9,  # right_hip
                26: 10, # right_knee
                28: 11, # right_ankle
                23: 12, # left_hip
                25: 13, # left_knee
                27: 14, # left_ankle
                2: 15,  # right_eye
                5: 16,  # left_eye
                8: 17   # right_ear
            }
            
            openpose_keypoints = []
            
            for op_idx in range(18):
                if op_idx in mp_to_op_mapping:
                    mp_idx = mp_to_op_mapping[op_idx]
                    if mp_idx < len(mediapipe_keypoints):
                        kp = mediapipe_keypoints[mp_idx]
                        openpose_keypoints.append([float(kp[0]), float(kp[1]), float(kp[2])])
                    else:
                        openpose_keypoints.append([0.0, 0.0, 0.0])
                else:
                    openpose_keypoints.append([0.0, 0.0, 0.0])
            
            return openpose_keypoints
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ MediaPipe â†’ OpenPose ë³€í™˜ ì‹¤íŒ¨: {e}")
            return [[0.0, 0.0, 0.0] for _ in range(18)]
    
    def _create_simulation_result_safe(self, input_tensor: torch.Tensor) -> Dict[str, Any]:
        """ì•ˆì „í•œ ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼ ìƒì„±"""
        try:
            batch_size, channels, height, width = input_tensor.shape
            
            # ì‹œë®¬ë ˆì´ì…˜ëœ í‚¤í¬ì¸íŠ¸ ìƒì„± (í•´ë¶€í•™ì ìœ¼ë¡œ íƒ€ë‹¹í•œ ìœ„ì¹˜)
            
            # ê¸°ë³¸ ì¸ì²´ ë¹„ìœ¨ ì‚¬ìš©
            head_y = height * 0.15
            neck_y = height * 0.20
            shoulder_y = height * 0.25
            elbow_y = height * 0.40
            wrist_y = height * 0.55
            hip_y = height * 0.55
            knee_y = height * 0.75
            ankle_y = height * 0.95
            
            center_x = width * 0.5
            shoulder_width = width * 0.15
            hip_width = width * 0.12
            
            # 18ê°œ í‚¤í¬ì¸íŠ¸ ì‹œë®¬ë ˆì´ì…˜
            simulated_points = [
                [center_x, head_y, 0.95],                    # 0: nose
                [center_x, neck_y, 0.90],                    # 1: neck
                [center_x + shoulder_width, shoulder_y, 0.85], # 2: right_shoulder
                [center_x + shoulder_width * 1.5, elbow_y, 0.80], # 3: right_elbow
                [center_x + shoulder_width * 1.8, wrist_y, 0.75], # 4: right_wrist
                [center_x - shoulder_width, shoulder_y, 0.85], # 5: left_shoulder
                [center_x - shoulder_width * 1.5, elbow_y, 0.80], # 6: left_elbow
                [center_x - shoulder_width * 1.8, wrist_y, 0.75], # 7: left_wrist
                [center_x, hip_y, 0.90],                      # 8: mid_hip
                [center_x + hip_width, hip_y, 0.85],          # 9: right_hip
                [center_x + hip_width, knee_y, 0.80],         # 10: right_knee
                [center_x + hip_width, ankle_y, 0.75],        # 11: right_ankle
                [center_x - hip_width, hip_y, 0.85],          # 12: left_hip
                [center_x - hip_width, knee_y, 0.80],         # 13: left_knee
                [center_x - hip_width, ankle_y, 0.75],        # 14: left_ankle
                [center_x + 10, head_y - 20, 0.70],           # 15: right_eye
                [center_x - 10, head_y - 20, 0.70],           # 16: left_eye
                [center_x + 15, head_y - 10, 0.65]            # 17: right_ear
            ]
            
            # ì¢Œí‘œ ì •ìˆ˜ ë³€í™˜ ë° ë²”ìœ„ ì²´í¬
            for point in simulated_points:
                point[0] = max(0, min(width-1, int(point[0])))
                point[1] = max(0, min(height-1, int(point[1])))
            
            keypoints_18 = simulated_points[:18]  # 18ê°œë§Œ ì‚¬ìš©
            
            # ë©”íŠ¸ë¦­ ê³„ì‚°
            confidences = [kp[2] for kp in keypoints_18]
            pose_confidence = np.mean(confidences)
            keypoints_detected = len([c for c in confidences if c > self.config.confidence_threshold])
            
            return {
                'keypoints_18': keypoints_18,
                'pose_confidence': float(pose_confidence),
                'keypoints_detected': keypoints_detected,
                'detection_method': 'simulation'
            }
            
        except Exception as e:
            self.logger.error(f"âŒ ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼ ìƒì„± ì‹¤íŒ¨: {e}")
            return {
                'keypoints_18': [[0, 0, 0] for _ in range(18)],
                'pose_confidence': 0.0,
                'keypoints_detected': 0,
                'detection_method': 'failed'
            }
    
    async def _postprocess_result_safe(
        self,
        pose_result: Dict[str, Any],
        original_size: Tuple[int, int],
        original_image_tensor: torch.Tensor,
        start_time: float
    ) -> Dict[str, Any]:
        """ì•ˆì „í•œ ê²°ê³¼ í›„ì²˜ë¦¬ ë° ë¶„ì„ + ì‹œê°í™”"""
        try:
            def _postprocess_sync():
                try:
                    # í‚¤í¬ì¸íŠ¸ ì •ê·œí™” ë° ê²€ì¦
                    keypoints_18 = pose_result.get('keypoints_18', [[0, 0, 0] for _ in range(18)])
                    keypoints_18 = self._validate_and_normalize_keypoints(keypoints_18, original_size)
                    
                    # í¬ì¦ˆ ë¶„ì„
                    pose_analysis = self._analyze_pose_quality(keypoints_18)
                    pose_angles = self._calculate_pose_angles(keypoints_18)
                    body_proportions = self._calculate_body_proportions(keypoints_18)
                    pose_type = self._classify_pose_type(keypoints_18)
                    
                    return {
                        'keypoints_18': keypoints_18,
                        'pose_analysis': pose_analysis,
                        'pose_angles': pose_angles,
                        'body_proportions': body_proportions,
                        'pose_type': pose_type
                    }
                except Exception as e:
                    self.logger.warning(f"âš ï¸ ë™ê¸° í›„ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                    # í´ë°±: ê¸°ë³¸ í‚¤í¬ì¸íŠ¸
                    return {
                        'keypoints_18': [[0, 0, 0] for _ in range(18)],
                        'pose_analysis': {'quality': 'poor', 'score': 0.0},
                        'pose_angles': {},
                        'body_proportions': {},
                        'pose_type': PoseType.UNKNOWN
                    }
            
            # ë¹„ë™ê¸° ì‹¤í–‰
            try:
                loop = asyncio.get_event_loop()
                processed_data = await loop.run_in_executor(self.executor, _postprocess_sync)
            except Exception as e:
                self.logger.warning(f"âš ï¸ ë¹„ë™ê¸° í›„ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                processed_data = _postprocess_sync()
            
            # ì‹œê°í™” ì´ë¯¸ì§€ ìƒì„±
            visualization_results = await self._create_pose_visualization_safe(
                processed_data['keypoints_18'], 
                original_image_tensor
            )
            
            processing_time = time.time() - start_time
            
            # API í˜¸í™˜ì„±ì„ ìœ„í•œ ê²°ê³¼ êµ¬ì¡°
            result = {
                "success": True,
                "message": "í¬ì¦ˆ ì¶”ì • ì™„ë£Œ",
                "confidence": float(pose_result.get('pose_confidence', 0.0)),
                "processing_time": processing_time,
                "details": {
                    # í”„ë¡ íŠ¸ì—”ë“œìš© ì‹œê°í™” ì´ë¯¸ì§€ë“¤
                    "result_image": visualization_results.get("pose_skeleton", ""),
                    "keypoints_image": visualization_results.get("keypoints_only", ""),
                    
                    # í¬ì¦ˆ ë¶„ì„ ê²°ê³¼
                    "keypoints_detected": pose_result.get('keypoints_detected', 0),
                    "total_keypoints": 18,
                    "pose_quality": processed_data['pose_analysis'].get('quality', 'unknown'),
                    "pose_score": processed_data['pose_analysis'].get('score', 0.0),
                    "pose_type": processed_data['pose_type'].value if hasattr(processed_data['pose_type'], 'value') else str(processed_data['pose_type']),
                    
                    # ìƒì„¸ ë¶„ì„ ì •ë³´
                    "keypoints_18": processed_data['keypoints_18'],
                    "pose_angles": processed_data['pose_angles'],
                    "body_proportions": processed_data['body_proportions'],
                    "detection_method": pose_result.get('detection_method', 'unknown'),
                    
                    # ì‹œìŠ¤í…œ ì •ë³´
                    "step_info": {
                        "step_name": "pose_estimation",
                        "step_number": 2,
                        "model_used": self._get_active_model_name_safe(),
                        "device": self.device,
                        "input_size": self.config.input_size,
                        "num_keypoints": self.config.num_keypoints,
                        "optimization": "M3 Max" if self.device == 'mps' else self.device
                    },
                    
                    # í’ˆì§ˆ ë©”íŠ¸ë¦­
                    "quality_metrics": {
                        "keypoint_coverage": float(pose_result.get('keypoints_detected', 0) / 18),
                        "pose_confidence": float(pose_result.get('pose_confidence', 0.0)),
                        "pose_quality_score": processed_data['pose_analysis'].get('score', 0.0),
                        "visualization_quality": self.config.visualization_quality
                    }
                },
                
                # ë ˆê±°ì‹œ í˜¸í™˜ì„± í•„ë“œë“¤
                "keypoints_18": processed_data['keypoints_18'],
                "pose_confidence": pose_result.get('pose_confidence', 0.0),
                "keypoints_detected": pose_result.get('keypoints_detected', 0),
                "pose_analysis": processed_data['pose_analysis'],
                "pose_angles": processed_data['pose_angles'],
                "body_proportions": processed_data['body_proportions'],
                "pose_type": processed_data['pose_type'],
                "from_cache": False
            }
            
            return result
            
        except Exception as e:
            self.logger.error(f"âŒ ê²°ê³¼ í›„ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return self._create_fallback_result_safe(original_size, time.time() - start_time, str(e))
    
    # ==============================================
    # ì•ˆì „í•œ ì‹œê°í™” í•¨ìˆ˜ë“¤
    # ==============================================
    
    async def _create_pose_visualization_safe(
        self, 
        keypoints_18: List[List[float]], 
        original_image_tensor: torch.Tensor
    ) -> Dict[str, str]:
        """ì•ˆì „í•œ í¬ì¦ˆ ì‹œê°í™” ì´ë¯¸ì§€ ìƒì„±"""
        try:
            if not self.config.enable_visualization:
                return {"pose_skeleton": "", "keypoints_only": "", "pose_info": ""}
            
            def _create_visualizations_safe():
                try:
                    # ì›ë³¸ ì´ë¯¸ì§€ë¥¼ PIL í˜•íƒœë¡œ ë³€í™˜
                    original_pil = self._tensor_to_pil_safe(original_image_tensor)
                    
                    # 1. ìŠ¤ì¼ˆë ˆí†¤ + í‚¤í¬ì¸íŠ¸ ì´ë¯¸ì§€ ìƒì„±
                    skeleton_image = self._draw_pose_skeleton_safe(original_pil, keypoints_18)
                    
                    # 2. í‚¤í¬ì¸íŠ¸ë§Œ í‘œì‹œí•œ ì´ë¯¸ì§€ ìƒì„±
                    keypoints_image = self._draw_keypoints_only_safe(original_pil, keypoints_18)
                    
                    # 3. í¬ì¦ˆ ì •ë³´ ì´ë¯¸ì§€ ìƒì„± (ì˜µì…˜)
                    pose_info_image = ""
                    if self.config.show_keypoint_labels:
                        try:
                            info_img = self._create_pose_info_image_safe(keypoints_18)
                            pose_info_image = self._pil_to_base64_safe(info_img)
                        except Exception as e:
                            self.logger.warning(f"âš ï¸ í¬ì¦ˆ ì •ë³´ ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨: {e}")
                    
                    return {
                        "pose_skeleton": self._pil_to_base64_safe(skeleton_image),
                        "keypoints_only": self._pil_to_base64_safe(keypoints_image),
                        "pose_info": pose_info_image
                    }
                except Exception as e:
                    self.logger.warning(f"âš ï¸ ì‹œê°í™” ìƒì„± ì‹¤íŒ¨: {e}")
                    return {"pose_skeleton": "", "keypoints_only": "", "pose_info": ""}
            
            # ë¹„ë™ê¸° ì‹¤í–‰
            try:
                loop = asyncio.get_event_loop()
                return await loop.run_in_executor(self.executor, _create_visualizations_safe)
            except Exception as e:
                self.logger.warning(f"âš ï¸ ë¹„ë™ê¸° ì‹œê°í™” ì‹¤íŒ¨: {e}")
                return _create_visualizations_safe()
                
        except Exception as e:
            self.logger.error(f"âŒ ì‹œê°í™” ìƒì„± ì™„ì „ ì‹¤íŒ¨: {e}")
            return {"pose_skeleton": "", "keypoints_only": "", "pose_info": ""}
    
    def _tensor_to_pil_safe(self, tensor: torch.Tensor) -> Image.Image:
        """ì•ˆì „í•œ í…ì„œ->PIL ë³€í™˜"""
        try:
            # [B, C, H, W] -> [C, H, W]
            if tensor.dim() == 4:
                tensor = tensor.squeeze(0)
            
            # CPUë¡œ ì´ë™
            tensor = tensor.cpu()
            
            # ì •ê·œí™” í•´ì œ (0-1 ë²”ìœ„ë¡œ)
            if tensor.max() <= 1.0:
                tensor = tensor.clamp(0, 1)
            else:
                tensor = tensor / 255.0
            
            # [C, H, W] -> [H, W, C]
            tensor = tensor.permute(1, 2, 0)
            
            # numpy ë°°ì—´ë¡œ ë³€í™˜
            numpy_array = (tensor.numpy() * 255).astype(np.uint8)
            
            # PIL ì´ë¯¸ì§€ ìƒì„±
            return Image.fromarray(numpy_array)
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ í…ì„œ->PIL ë³€í™˜ ì‹¤íŒ¨: {e}")
            # í´ë°±: ê¸°ë³¸ ì´ë¯¸ì§€ ìƒì„±
            return Image.new('RGB', (512, 512), (128, 128, 128))
    
    def _draw_pose_skeleton_safe(self, original_pil: Image.Image, keypoints_18: List[List[float]]) -> Image.Image:
        """ì•ˆì „í•œ í¬ì¦ˆ ìŠ¤ì¼ˆë ˆí†¤ ê·¸ë¦¬ê¸°"""
        try:
            # ì´ë¯¸ì§€ ë³µì‚¬
            result_img = original_pil.copy()
            draw = ImageDraw.Draw(result_img)
            
            # 1. ìŠ¤ì¼ˆë ˆí†¤ ì—°ê²°ì„  ê·¸ë¦¬ê¸°
            for connection in SKELETON_CONNECTIONS:
                try:
                    point1_idx, point2_idx = connection
                    
                    if (point1_idx < len(keypoints_18) and point2_idx < len(keypoints_18)):
                        point1 = keypoints_18[point1_idx]
                        point2 = keypoints_18[point2_idx]
                        
                        # ë‘ ì  ëª¨ë‘ ìœ íš¨í•œ ê²½ìš°ë§Œ ì—°ê²°ì„  ê·¸ë¦¬ê¸°
                        if (point1[2] > self.config.confidence_threshold and 
                            point2[2] > self.config.confidence_threshold):
                            
                            color = SKELETON_COLORS.get(connection, (255, 255, 255))
                            
                            draw.line(
                                [(int(point1[0]), int(point1[1])), 
                                 (int(point2[0]), int(point2[1]))],
                                fill=color,
                                width=self.config.skeleton_thickness
                            )
                except Exception as e:
                    self.logger.debug(f"ìŠ¤ì¼ˆë ˆí†¤ ì—°ê²°ì„  ê·¸ë¦¬ê¸° ì‹¤íŒ¨ {connection}: {e}")
            
            # 2. í‚¤í¬ì¸íŠ¸ ì  ê·¸ë¦¬ê¸°
            for i, keypoint in enumerate(keypoints_18):
                try:
                    if keypoint[2] > self.config.confidence_threshold:
                        x, y = int(keypoint[0]), int(keypoint[1])
                        color = KEYPOINT_COLORS.get(i, (255, 255, 255))
                        
                        # í‚¤í¬ì¸íŠ¸ ì› ê·¸ë¦¬ê¸°
                        radius = self.config.keypoint_radius
                        draw.ellipse(
                            [x - radius, y - radius, x + radius, y + radius],
                            fill=color,
                            outline=(0, 0, 0),
                            width=2
                        )
                        
                        # í‚¤í¬ì¸íŠ¸ ë²ˆí˜¸ í‘œì‹œ (ì˜µì…˜)
                        if self.config.show_keypoint_labels:
                            try:
                                font = ImageFont.load_default()
                                draw.text((x + radius + 2, y - radius), str(i), 
                                         fill=(255, 255, 255), font=font)
                            except Exception:
                                pass
                                
                except Exception as e:
                    self.logger.debug(f"í‚¤í¬ì¸íŠ¸ {i} ê·¸ë¦¬ê¸° ì‹¤íŒ¨: {e}")
            
            return result_img
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ ìŠ¤ì¼ˆë ˆí†¤ ê·¸ë¦¬ê¸° ì‹¤íŒ¨: {e}")
            return original_pil
    
    def _draw_keypoints_only_safe(self, original_pil: Image.Image, keypoints_18: List[List[float]]) -> Image.Image:
        """ì•ˆì „í•œ í‚¤í¬ì¸íŠ¸ë§Œ ê·¸ë¦¬ê¸°"""
        try:
            # ì´ë¯¸ì§€ ë³µì‚¬
            result_img = original_pil.copy()
            draw = ImageDraw.Draw(result_img)
            
            # í‚¤í¬ì¸íŠ¸ë§Œ ê·¸ë¦¬ê¸°
            for i, keypoint in enumerate(keypoints_18):
                try:
                    if keypoint[2] > self.config.confidence_threshold:
                        x, y = int(keypoint[0]), int(keypoint[1])
                        color = KEYPOINT_COLORS.get(i, (255, 255, 255))
                        
                        # ë” í° í‚¤í¬ì¸íŠ¸ ì› ê·¸ë¦¬ê¸°
                        radius = self.config.keypoint_radius + 2
                        draw.ellipse(
                            [x - radius, y - radius, x + radius, y + radius],
                            fill=color,
                            outline=(0, 0, 0),
                            width=3
                        )
                        
                        # í‚¤í¬ì¸íŠ¸ ì´ë¦„ í‘œì‹œ
                        if self.config.show_keypoint_labels:
                            try:
                                font = ImageFont.load_default()
                                keypoint_name = OPENPOSE_18_KEYPOINTS.get(i, f"kp_{i}")
                                draw.text((x + radius + 5, y - radius), keypoint_name, 
                                         fill=(255, 255, 255), font=font)
                            except Exception:
                                pass
                                
                except Exception as e:
                    self.logger.debug(f"í‚¤í¬ì¸íŠ¸ {i} ê·¸ë¦¬ê¸° ì‹¤íŒ¨: {e}")
            
            return result_img
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ í‚¤í¬ì¸íŠ¸ ê·¸ë¦¬ê¸° ì‹¤íŒ¨: {e}")
            return original_pil
    
    def _create_pose_info_image_safe(self, keypoints_18: List[List[float]]) -> Image.Image:
        """ì•ˆì „í•œ í¬ì¦ˆ ì •ë³´ ì´ë¯¸ì§€ ìƒì„±"""
        try:
            # ì •ë³´ ì´ë¯¸ì§€ í¬ê¸° ê³„ì‚°
            info_width = 300
            info_height = 600
            
            # ì •ë³´ ì´ë¯¸ì§€ ìƒì„±
            info_img = Image.new('RGB', (info_width, info_height), (240, 240, 240))
            draw = ImageDraw.Draw(info_img)
            
            # í°íŠ¸ ë¡œë”©
            try:
                font = ImageFont.truetype("arial.ttf", 12)
                title_font = ImageFont.truetype("arial.ttf", 16)
            except Exception:
                font = ImageFont.load_default()
                title_font = ImageFont.load_default()
            
            # ì œëª©
            draw.text((10, 10), "Pose Information", fill=(0, 0, 0), font=title_font)
            
            # í‚¤í¬ì¸íŠ¸ ì •ë³´ í‘œì‹œ
            y_offset = 40
            line_height = 25
            
            detected_count = 0
            for i, keypoint in enumerate(keypoints_18):
                try:
                    keypoint_name = OPENPOSE_18_KEYPOINTS.get(i, f"keypoint_{i}")
                    confidence = keypoint[2]
                    
                    if confidence > self.config.confidence_threshold:
                        detected_count += 1
                        status = "âœ“"
                        color = (0, 150, 0)
                    else:
                        status = "âœ—"
                        color = (150, 0, 0)
                    
                    text = f"{status} {keypoint_name}: {confidence:.2f}"
                    draw.text((10, y_offset), text, fill=color, font=font)
                    y_offset += line_height
                    
                    if y_offset > info_height - 100:  # ê³µê°„ ë¶€ì¡± ì‹œ ì¤‘ë‹¨
                        break
                        
                except Exception as e:
                    self.logger.debug(f"í¬ì¦ˆ ì •ë³´ í•­ëª© ìƒì„± ì‹¤íŒ¨ (í‚¤í¬ì¸íŠ¸ {i}): {e}")
            
            # í†µê³„ ì •ë³´
            y_offset += 20
            stats_text = f"Detected: {detected_count}/18"
            draw.text((10, y_offset), stats_text, fill=(0, 0, 0), font=title_font)
            
            return info_img
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ í¬ì¦ˆ ì •ë³´ ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨: {e}")
            # ê¸°ë³¸ ì •ë³´ ì´ë¯¸ì§€
            return Image.new('RGB', (300, 200), (240, 240, 240))
    
    def _pil_to_base64_safe(self, pil_image: Image.Image) -> str:
        """ì•ˆì „í•œ PIL->base64 ë³€í™˜"""
        try:
            buffer = BytesIO()
            
            # í’ˆì§ˆ ì„¤ì •
            quality = 85
            if self.config.visualization_quality == "high":
                quality = 95
            elif self.config.visualization_quality == "low":
                quality = 70
            
            pil_image.save(buffer, format='JPEG', quality=quality)
            return base64.b64encode(buffer.getvalue()).decode('utf-8')
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ base64 ë³€í™˜ ì‹¤íŒ¨: {e}")
            return ""
    
    # ==============================================
    # ì•ˆì „í•œ ë¶„ì„ í•¨ìˆ˜ë“¤
    # ==============================================
    
    def _validate_and_normalize_keypoints(self, keypoints_18: List[List[float]], image_size: Tuple[int, int]) -> List[List[float]]:
        """í‚¤í¬ì¸íŠ¸ ê²€ì¦ ë° ì •ê·œí™”"""
        try:
            height, width = image_size
            validated_keypoints = []
            
            for i, keypoint in enumerate(keypoints_18):
                if len(keypoint) >= 3:
                    x, y, confidence = keypoint[0], keypoint[1], keypoint[2]
                    
                    # ì¢Œí‘œ ë²”ìœ„ í™•ì¸ ë° ì •ê·œí™”
                    x = max(0, min(width - 1, float(x)))
                    y = max(0, min(height - 1, float(y)))
                    confidence = max(0.0, min(1.0, float(confidence)))
                    
                    validated_keypoints.append([x, y, confidence])
                else:
                    validated_keypoints.append([0.0, 0.0, 0.0])
            
            # 18ê°œë¡œ ë§ì¶”ê¸°
            while len(validated_keypoints) < 18:
                validated_keypoints.append([0.0, 0.0, 0.0])
            
            return validated_keypoints[:18]
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ í‚¤í¬ì¸íŠ¸ ê²€ì¦ ì‹¤íŒ¨: {e}")
            return [[0.0, 0.0, 0.0] for _ in range(18)]
    
    def _analyze_pose_quality(self, keypoints_18: List[List[float]]) -> Dict[str, Any]:
        """í¬ì¦ˆ í’ˆì§ˆ ë¶„ì„"""
        try:
            # í‚¤í¬ì¸íŠ¸ ê°ì§€ìœ¨
            detected_keypoints = [kp for kp in keypoints_18 if kp[2] > self.config.confidence_threshold]
            detection_rate = len(detected_keypoints) / 18.0
            
            # í‰ê·  ì‹ ë¢°ë„
            confidences = [kp[2] for kp in keypoints_18 if kp[2] > 0]
            avg_confidence = np.mean(confidences) if confidences else 0.0
            
            # ì£¼ìš” í‚¤í¬ì¸íŠ¸ í™•ì¸ (ë¨¸ë¦¬, ì–´ê¹¨, ì—‰ë©ì´)
            major_keypoints = [0, 1, 2, 5, 8, 9, 12]  # nose, neck, shoulders, hips
            major_detected = sum(1 for idx in major_keypoints if keypoints_18[idx][2] > self.config.confidence_threshold)
            major_rate = major_detected / len(major_keypoints)
            
            # ëŒ€ì¹­ì„± ì ìˆ˜
            symmetry_score = self._calculate_symmetry_score(keypoints_18)
            
            # ì „ì²´ í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°
            quality_score = (
                detection_rate * 0.3 +
                avg_confidence * 0.3 +
                major_rate * 0.3 +
                symmetry_score * 0.1
            )
            
            # í’ˆì§ˆ ë“±ê¸‰ ê²°ì •
            if quality_score >= 0.8:
                quality = PoseQuality.EXCELLENT
            elif quality_score >= 0.6:
                quality = PoseQuality.GOOD
            elif quality_score >= 0.4:
                quality = PoseQuality.FAIR
            else:
                quality = PoseQuality.POOR
            
            return {
                'quality': quality.value,
                'score': float(quality_score),
                'detection_rate': float(detection_rate),
                'avg_confidence': float(avg_confidence),
                'major_keypoints_rate': float(major_rate),
                'symmetry_score': float(symmetry_score),
                'suitable_for_fitting': quality_score >= 0.5
            }
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ í¬ì¦ˆ í’ˆì§ˆ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {
                'quality': PoseQuality.POOR.value,
                'score': 0.0,
                'detection_rate': 0.0,
                'avg_confidence': 0.0,
                'major_keypoints_rate': 0.0,
                'symmetry_score': 0.0,
                'suitable_for_fitting': False
            }
    
    def _calculate_symmetry_score(self, keypoints_18: List[List[float]]) -> float:
        """ëŒ€ì¹­ì„± ì ìˆ˜ ê³„ì‚°"""
        try:
            # ì¢Œìš° ëŒ€ì¹­ í‚¤í¬ì¸íŠ¸ ìŒ
            symmetric_pairs = [
                (2, 5),   # shoulders
                (3, 6),   # elbows
                (4, 7),   # wrists
                (9, 12),  # hips
                (10, 13), # knees
                (11, 14), # ankles
                (15, 16)  # eyes
            ]
            
            symmetry_scores = []
            
            for left_idx, right_idx in symmetric_pairs:
                try:
                    left_kp = keypoints_18[left_idx]
                    right_kp = keypoints_18[right_idx]
                    
                    # ë‘ í‚¤í¬ì¸íŠ¸ ëª¨ë‘ ê°ì§€ëœ ê²½ìš°ë§Œ ê³„ì‚°
                    if (left_kp[2] > self.config.confidence_threshold and 
                        right_kp[2] > self.config.confidence_threshold):
                        
                        # ì¤‘ì‹¬ì  (neck ë˜ëŠ” mid_hip) ê¸°ì¤€ ëŒ€ì¹­ì„± ê³„ì‚°
                        center_x = keypoints_18[1][0] if keypoints_18[1][2] > 0 else keypoints_18[8][0]
                        
                        left_dist = abs(left_kp[0] - center_x)
                        right_dist = abs(right_kp[0] - center_x)
                        
                        if left_dist + right_dist > 0:
                            symmetry = 1.0 - abs(left_dist - right_dist) / (left_dist + right_dist)
                            symmetry_scores.append(max(0.0, symmetry))
                            
                except Exception as e:
                    self.logger.debug(f"ëŒ€ì¹­ì„± ê³„ì‚° ì‹¤íŒ¨ ({left_idx}, {right_idx}): {e}")
            
            return np.mean(symmetry_scores) if symmetry_scores else 0.0
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ ëŒ€ì¹­ì„± ì ìˆ˜ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return 0.0
    
    def _calculate_pose_angles(self, keypoints_18: List[List[float]]) -> Dict[str, float]:
        """ì£¼ìš” ê´€ì ˆ ê°ë„ ê³„ì‚°"""
        try:
            angles = {}
            
            # ê°ë„ ê³„ì‚° í•¨ìˆ˜
            def calculate_angle(p1, p2, p3):
                """ì„¸ ì ìœ¼ë¡œ ê°ë„ ê³„ì‚°"""
                try:
                    if SCIPY_AVAILABLE:
                        v1 = np.array([p1[0] - p2[0], p1[1] - p2[1]])
                        v2 = np.array([p3[0] - p2[0], p3[1] - p2[1]])
                        
                        cos_angle = np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))
                        cos_angle = np.clip(cos_angle, -1.0, 1.0)
                        angle = np.arccos(cos_angle) * 180 / np.pi
                        
                        return float(angle)
                    else:
                        # scipy ì—†ì´ ê°„ë‹¨í•œ ê°ë„ ê³„ì‚°
                        dx1, dy1 = p1[0] - p2[0], p1[1] - p2[1]
                        dx2, dy2 = p3[0] - p2[0], p3[1] - p2[1]
                        
                        dot_product = dx1 * dx2 + dy1 * dy2
                        norm1 = math.sqrt(dx1**2 + dy1**2)
                        norm2 = math.sqrt(dx2**2 + dy2**2)
                        
                        if norm1 * norm2 > 0:
                            cos_angle = dot_product / (norm1 * norm2)
                            cos_angle = max(-1.0, min(1.0, cos_angle))
                            angle = math.acos(cos_angle) * 180 / math.pi
                            return float(angle)
                        
                        return 0.0
                except Exception:
                    return 0.0
            
            # ì£¼ìš” ê´€ì ˆ ê°ë„ ê³„ì‚°
            angle_definitions = {
                'right_elbow': (2, 3, 4),      # right_shoulder, right_elbow, right_wrist
                'left_elbow': (5, 6, 7),       # left_shoulder, left_elbow, left_wrist
                'right_knee': (9, 10, 11),     # right_hip, right_knee, right_ankle
                'left_knee': (12, 13, 14),     # left_hip, left_knee, left_ankle
                'right_shoulder': (1, 2, 3),   # neck, right_shoulder, right_elbow
                'left_shoulder': (1, 5, 6),    # neck, left_shoulder, left_elbow
                'right_hip': (8, 9, 10),       # mid_hip, right_hip, right_knee
                'left_hip': (8, 12, 13)        # mid_hip, left_hip, left_knee
            }
            
            for angle_name, (p1_idx, p2_idx, p3_idx) in angle_definitions.items():
                try:
                    p1, p2, p3 = keypoints_18[p1_idx], keypoints_18[p2_idx], keypoints_18[p3_idx]
                    
                    # ëª¨ë“  í‚¤í¬ì¸íŠ¸ê°€ ê°ì§€ëœ ê²½ìš°ë§Œ ê³„ì‚°
                    if (p1[2] > self.config.confidence_threshold and 
                        p2[2] > self.config.confidence_threshold and 
                        p3[2] > self.config.confidence_threshold):
                        
                        angle = calculate_angle(p1, p2, p3)
                        angles[angle_name] = angle
                        
                except Exception as e:
                    self.logger.debug(f"ê°ë„ ê³„ì‚° ì‹¤íŒ¨ ({angle_name}): {e}")
            
            return angles
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ í¬ì¦ˆ ê°ë„ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return {}
    
    def _calculate_body_proportions(self, keypoints_18: List[List[float]]) -> Dict[str, float]:
        """ì‹ ì²´ ë¹„ìœ¨ ê³„ì‚°"""
        try:
            proportions = {}
            
            # ê±°ë¦¬ ê³„ì‚° í•¨ìˆ˜
            def calculate_distance(p1, p2):
                try:
                    if SCIPY_AVAILABLE:
                        return euclidean([p1[0], p1[1]], [p2[0], p2[1]])
                    else:
                        dx = p1[0] - p2[0]
                        dy = p1[1] - p2[1]
                        return math.sqrt(dx**2 + dy**2)
                except Exception:
                    return 0.0
            
            # ì£¼ìš” ì‹ ì²´ ë¶„ì ˆ ê¸¸ì´ ê³„ì‚°
            segments = {
                'head_neck': (0, 1),           # nose to neck
                'torso': (1, 8),               # neck to mid_hip
                'right_upper_arm': (2, 3),     # right_shoulder to right_elbow
                'right_forearm': (3, 4),       # right_elbow to right_wrist
                'left_upper_arm': (5, 6),      # left_shoulder to left_elbow
                'left_forearm': (6, 7),        # left_elbow to left_wrist
                'right_thigh': (9, 10),        # right_hip to right_knee
                'right_shin': (10, 11),        # right_knee to right_ankle
                'left_thigh': (12, 13),        # left_hip to left_knee
                'left_shin': (13, 14),         # left_knee to left_ankle
                'shoulder_width': (2, 5),      # right_shoulder to left_shoulder
                'hip_width': (9, 12)           # right_hip to left_hip
            }
            
            segment_lengths = {}
            
            for segment_name, (p1_idx, p2_idx) in segments.items():
                try:
                    p1, p2 = keypoints_18[p1_idx], keypoints_18[p2_idx]
                    
                    # ë‘ í‚¤í¬ì¸íŠ¸ ëª¨ë‘ ê°ì§€ëœ ê²½ìš°ë§Œ ê³„ì‚°
                    if (p1[2] > self.config.confidence_threshold and 
                        p2[2] > self.config.confidence_threshold):
                        
                        length = calculate_distance(p1, p2)
                        segment_lengths[segment_name] = length
                        
                except Exception as e:
                    self.logger.debug(f"ë¶„ì ˆ ê¸¸ì´ ê³„ì‚° ì‹¤íŒ¨ ({segment_name}): {e}")
            
            # ë¹„ìœ¨ ê³„ì‚° (torso ê¸¸ì´ë¥¼ ê¸°ì¤€ìœ¼ë¡œ)
            if 'torso' in segment_lengths and segment_lengths['torso'] > 0:
                torso_length = segment_lengths['torso']
                
                for segment_name, length in segment_lengths.items():
                    if segment_name != 'torso':
                        try:
                            ratio = length / torso_length
                            proportions[f"{segment_name}_to_torso_ratio"] = float(ratio)
                        except Exception:
                            pass
            
            # ëŒ€ì¹­ì„± ë¹„ìœ¨ ê³„ì‚°
            symmetry_ratios = {
                'arm_symmetry': ('right_upper_arm', 'left_upper_arm'),
                'forearm_symmetry': ('right_forearm', 'left_forearm'),
                'thigh_symmetry': ('right_thigh', 'left_thigh'),
                'shin_symmetry': ('right_shin', 'left_shin')
            }
            
            for ratio_name, (right_segment, left_segment) in symmetry_ratios.items():
                try:
                    if right_segment in segment_lengths and left_segment in segment_lengths:
                        right_len = segment_lengths[right_segment]
                        left_len = segment_lengths[left_segment]
                        
                        if right_len + left_len > 0:
                            symmetry = 1.0 - abs(right_len - left_len) / (right_len + left_len)
                            proportions[ratio_name] = float(max(0.0, symmetry))
                            
                except Exception as e:
                    self.logger.debug(f"ëŒ€ì¹­ì„± ë¹„ìœ¨ ê³„ì‚° ì‹¤íŒ¨ ({ratio_name}): {e}")
            
            return proportions
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ ì‹ ì²´ ë¹„ìœ¨ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return {}
    
    def _classify_pose_type(self, keypoints_18: List[List[float]]) -> PoseType:
        """í¬ì¦ˆ íƒ€ì… ë¶„ë¥˜"""
        try:
            # ì–´ê¹¨ì™€ ì—‰ë©ì´ì˜ ìƒëŒ€ì  ìœ„ì¹˜ë¡œ í¬ì¦ˆ íƒ€ì… íŒë‹¨
            right_shoulder = keypoints_18[2]
            left_shoulder = keypoints_18[5]
            right_hip = keypoints_18[9]
            left_hip = keypoints_18[12]
            
            # ëª¨ë“  ì£¼ìš” í‚¤í¬ì¸íŠ¸ê°€ ê°ì§€ëœ ê²½ìš°ë§Œ ë¶„ë¥˜
            major_keypoints = [right_shoulder, left_shoulder, right_hip, left_hip]
            if not all(kp[2] > self.config.confidence_threshold for kp in major_keypoints):
                return PoseType.UNKNOWN
            
            # ì–´ê¹¨ ë„ˆë¹„ì™€ ì—‰ë©ì´ ë„ˆë¹„
            shoulder_width = abs(right_shoulder[0] - left_shoulder[0])
            hip_width = abs(right_hip[0] - left_hip[0])
            
            # ì¢Œìš° ëŒ€ì¹­ì„± í™•ì¸
            center_x = (right_shoulder[0] + left_shoulder[0]) / 2
            shoulder_symmetry = abs((right_shoulder[0] - center_x) + (left_shoulder[0] - center_x))
            
            # ì •ë©´/í›„ë©´ íŒë‹¨ (ì–´ê¹¨ ë„ˆë¹„ ê¸°ì¤€)
            if shoulder_width > hip_width * 0.8 and shoulder_symmetry < shoulder_width * 0.2:
                # ëˆˆì´ ê°ì§€ë˜ë©´ ì •ë©´, ì•„ë‹ˆë©´ í›„ë©´
                right_eye = keypoints_18[15]
                left_eye = keypoints_18[16]
                
                if (right_eye[2] > self.config.confidence_threshold or 
                    left_eye[2] > self.config.confidence_threshold):
                    return PoseType.FRONT_FACING
                else:
                    return PoseType.BACK_FACING
            
            # ì¸¡ë©´ í¬ì¦ˆ íŒë‹¨
            elif shoulder_width < hip_width * 0.6:
                return PoseType.SIDE_PROFILE
            
            # ê°ë„ê°€ ìˆëŠ” í¬ì¦ˆ
            else:
                return PoseType.ANGLED
                
        except Exception as e:
            self.logger.warning(f"âš ï¸ í¬ì¦ˆ íƒ€ì… ë¶„ë¥˜ ì‹¤íŒ¨: {e}")
            return PoseType.UNKNOWN
    
    def _get_active_model_name_safe(self) -> str:
        """ì•ˆì „í•œ í™œì„± ëª¨ë¸ ì´ë¦„ ë°˜í™˜"""
        try:
            if 'primary' in self.models_loaded:
                return self.config.model_name
            elif 'backup' in self.models_loaded:
                return self.config.backup_model
            else:
                return "simulation"  # ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œ
        except Exception:
            return "unknown"
    
    # ==============================================
    # ì•ˆì „í•œ ìºì‹œ ë° ì„±ëŠ¥ ê´€ë¦¬
    # ==============================================
    
    def _generate_cache_key_safe(self, tensor: torch.Tensor) -> str:
        """ì•ˆì „í•œ ìºì‹œ í‚¤ ìƒì„±"""
        try:
            # í…ì„œì˜ í•´ì‹œê°’ ê¸°ë°˜ í‚¤ ìƒì„±
            tensor_bytes = tensor.cpu().numpy().tobytes()
            import hashlib
            hash_value = hashlib.md5(tensor_bytes).hexdigest()[:16]
            return f"step02_{hash_value}_{self.config.input_size[0]}x{self.config.input_size[1]}"
        except Exception as e:
            self.logger.warning(f"âš ï¸ ìºì‹œ í‚¤ ìƒì„± ì‹¤íŒ¨: {e}")
            return f"step02_fallback_{int(time.time())}"
    
    def _get_cached_result_safe(self, cache_key: str) -> Optional[Dict[str, Any]]:
        """ì•ˆì „í•œ ìºì‹œëœ ê²°ê³¼ ì¡°íšŒ"""
        try:
            with self.cache_lock:
                if cache_key in self.result_cache:
                    cached = self.result_cache[cache_key].copy()
                    cached["from_cache"] = True
                    return cached
                return None
        except Exception as e:
            self.logger.warning(f"âš ï¸ ìºì‹œ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return None
    
    def _cache_result_safe(self, cache_key: str, result: Dict[str, Any]):
        """ì•ˆì „í•œ ê²°ê³¼ ìºì‹± (LRU ë°©ì‹)"""
        try:
            with self.cache_lock:
                # ìºì‹œ í¬ê¸° ì œí•œ
                if len(self.result_cache) >= self.config.max_cache_size:
                    # ê°€ì¥ ì˜¤ë˜ëœ í•­ëª© ì œê±°
                    try:
                        oldest_key = next(iter(self.result_cache))
                        del self.result_cache[oldest_key]
                    except Exception:
                        # ìºì‹œ ì´ˆê¸°í™”
                        self.result_cache.clear()
                
                # ìƒˆ ê²°ê³¼ ì €ì¥
                cached_result = result.copy()
                cached_result["from_cache"] = False
                self.result_cache[cache_key] = cached_result
                
        except Exception as e:
            self.logger.warning(f"âš ï¸ ìºì‹œ ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def _update_processing_stats(self, processing_time: float, result: Dict[str, Any]):
        """ì²˜ë¦¬ í†µê³„ ì—…ë°ì´íŠ¸"""
        try:
            self.processing_stats['total_processed'] += 1
            
            # ì´ë™ í‰ê·  ê³„ì‚°
            current_avg = self.processing_stats['average_time']
            count = self.processing_stats['total_processed']
            new_avg = (current_avg * (count - 1) + processing_time) / count
            self.processing_stats['average_time'] = new_avg
            
            # í¬ì¦ˆ í’ˆì§ˆ í†µê³„ ì—…ë°ì´íŠ¸
            if 'details' in result and 'pose_quality' in result['details']:
                quality = result['details']['pose_quality']
                if quality in self.processing_stats['pose_qualities']:
                    self.processing_stats['pose_qualities'][quality] += 1
                    
        except Exception as e:
            self.logger.warning(f"âš ï¸ í†µê³„ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
    
    def _create_fallback_result_safe(self, original_size: Tuple[int, int], processing_time: float, error_msg: str) -> Dict[str, Any]:
        """ì•ˆì „í•œ í´ë°± ê²°ê³¼ ìƒì„± (ì—ëŸ¬ ë°œìƒ ì‹œ)"""
        try:
            return {
                "success": False,
                "message": f"í¬ì¦ˆ ì¶”ì • ì‹¤íŒ¨: {error_msg}",
                "confidence": 0.0,
                "processing_time": processing_time,
                "details": {
                    "result_image": "",  # ë¹ˆ ì´ë¯¸ì§€
                    "keypoints_image": "",
                    "keypoints_detected": 0,
                    "total_keypoints": 18,
                    "pose_quality": "poor",
                    "pose_score": 0.0,
                    "pose_type": "unknown",
                    "error": error_msg,
                    "step_info": {
                        "step_name": "pose_estimation",
                        "step_number": 2,
                        "model_used": "fallback",
                        "device": self.device,
                        "error": error_msg
                    },
                    "quality_metrics": {
                        "keypoint_coverage": 0.0,
                        "pose_confidence": 0.0,
                        "pose_quality_score": 0.0
                    }
                },
                "keypoints_18": [[0, 0, 0] for _ in range(18)],
                "pose_confidence": 0.0,
                "keypoints_detected": 0,
                "pose_analysis": {
                    'quality': 'poor',
                    'score': 0.0,
                    'suitable_for_fitting': False
                },
                "pose_angles": {},
                "body_proportions": {},
                "pose_type": PoseType.UNKNOWN,
                "from_cache": False
            }
        except Exception as e:
            self.logger.error(f"âŒ í´ë°± ê²°ê³¼ ìƒì„±ë„ ì‹¤íŒ¨: {e}")
            # ìµœì†Œí•œì˜ ì•ˆì „í•œ ê²°ê³¼
            return {
                "success": False,
                "message": "ì‹¬ê°í•œ ì˜¤ë¥˜ ë°œìƒ",
                "confidence": 0.0,
                "processing_time": processing_time,
                "details": {"error": f"Fallback failed: {e}"},
                "keypoints_18": [[0, 0, 0] for _ in range(18)],
                "pose_confidence": 0.0,
                "keypoints_detected": 0,
                "pose_analysis": {},
                "pose_angles": {},
                "body_proportions": {},
                "pose_type": PoseType.UNKNOWN,
                "from_cache": False
            }
    
    # ==============================================
    # ì•ˆì „í•œ ìœ í‹¸ë¦¬í‹° ë©”ì„œë“œë“¤
    # ==============================================
    
    def get_pose_keypoints(self, format: str = "openpose_18") -> List[str]:
        """ì§€ì›í•˜ëŠ” í‚¤í¬ì¸íŠ¸ í˜•ì‹ ë°˜í™˜"""
        try:
            if format == "openpose_18":
                return list(OPENPOSE_18_KEYPOINTS.values())
            else:
                self.logger.warning(f"âš ï¸ ì§€ì›í•˜ì§€ ì•ŠëŠ” í˜•ì‹: {format}")
                return list(OPENPOSE_18_KEYPOINTS.values())
        except Exception as e:
            self.logger.warning(f"âš ï¸ í‚¤í¬ì¸íŠ¸ ëª©ë¡ ë°˜í™˜ ì‹¤íŒ¨: {e}")
            return []
    
    def analyze_pose_for_virtual_fitting(self, keypoints_18: List[List[float]]) -> Dict[str, Any]:
        """ê°€ìƒ í”¼íŒ…ì„ ìœ„í•œ í¬ì¦ˆ ë¶„ì„"""
        try:
            analysis = {
                'suitable_for_fitting': False,
                'issues': [],
                'recommendations': [],
                'pose_score': 0.0
            }
            
            # ì£¼ìš” í‚¤í¬ì¸íŠ¸ í™•ì¸
            essential_keypoints = [1, 2, 5, 8, 9, 12]  # neck, shoulders, hips
            essential_detected = [idx for idx in essential_keypoints 
                                if keypoints_18[idx][2] > self.config.confidence_threshold]
            
            if len(essential_detected) < 4:
                analysis['issues'].append("ì£¼ìš” í‚¤í¬ì¸íŠ¸ ë¶€ì¡±")
                analysis['recommendations'].append("ë” ëª…í™•í•œ í¬ì¦ˆë¡œ ì´¬ì˜í•´ ì£¼ì„¸ìš”")
                return analysis
            
            # í¬ì¦ˆ íƒ€ì… í™•ì¸
            pose_type = self._classify_pose_type(keypoints_18)
            if pose_type in [PoseType.FRONT_FACING, PoseType.ANGLED]:
                analysis['pose_score'] += 0.4
            elif pose_type == PoseType.SIDE_PROFILE:
                analysis['pose_score'] += 0.2
                analysis['issues'].append("ì¸¡ë©´ í¬ì¦ˆëŠ” ì •í™•ë„ê°€ ë–¨ì–´ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤")
            else:
                analysis['issues'].append("í¬ì¦ˆ íƒ€ì…ì„ ì¸ì‹í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            
            # íŒ” ìœ„ì¹˜ í™•ì¸
            right_wrist = keypoints_18[4]
            left_wrist = keypoints_18[7]
            right_hip = keypoints_18[9]
            left_hip = keypoints_18[12]
            
            if (right_wrist[2] > self.config.confidence_threshold and 
                left_wrist[2] > self.config.confidence_threshold):
                
                # íŒ”ì´ ëª¸í†µì„ ê°€ë¦¬ì§€ ì•ŠëŠ”ì§€ í™•ì¸
                if (right_wrist[0] > right_hip[0] + 50 or 
                    left_wrist[0] < left_hip[0] - 50):
                    analysis['pose_score'] += 0.3
                else:
                    analysis['issues'].append("íŒ”ì´ ëª¸í†µì„ ê°€ë¦¬ê³  ìˆìŠµë‹ˆë‹¤")
                    analysis['recommendations'].append("íŒ”ì„ ë²Œë ¤ì£¼ì„¸ìš”")
            
            # ë‹¤ë¦¬ ìœ„ì¹˜ í™•ì¸
            right_ankle = keypoints_18[11]
            left_ankle = keypoints_18[14]
            
            if (right_ankle[2] > self.config.confidence_threshold and 
                left_ankle[2] > self.config.confidence_threshold):
                
                ankle_distance = abs(right_ankle[0] - left_ankle[0])
                hip_distance = abs(right_hip[0] - left_hip[0])
                
                if ankle_distance > hip_distance * 0.8:
                    analysis['pose_score'] += 0.3
                else:
                    analysis['issues'].append("ë‹¤ë¦¬ê°€ ë„ˆë¬´ ê°€ê¹Œì´ ìˆìŠµë‹ˆë‹¤")
                    analysis['recommendations'].append("ë‹¤ë¦¬ë¥¼ ì•½ê°„ ë²Œë ¤ì£¼ì„¸ìš”")
            
            # ìµœì¢… íŒë‹¨
            analysis['suitable_for_fitting'] = analysis['pose_score'] >= 0.6
            
            if not analysis['issues']:
                analysis['recommendations'].append("ì¢‹ì€ í¬ì¦ˆì…ë‹ˆë‹¤!")
            
            return analysis
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ ê°€ìƒ í”¼íŒ… í¬ì¦ˆ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {
                'suitable_for_fitting': False,
                'issues': ["ë¶„ì„ ì‹¤íŒ¨"],
                'recommendations': ["ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”"],
                'pose_score': 0.0
            }
    
    async def get_step_info(self) -> Dict[str, Any]:
        """2ë‹¨ê³„ ìƒì„¸ ì •ë³´ ë°˜í™˜"""
        try:
            try:
                memory_stats = await self.memory_manager.get_usage_stats()
            except Exception:
                memory_stats = {"memory_used": "N/A"}
            
            return {
                "step_name": "pose_estimation",
                "step_number": 2,
                "device": self.device,
                "initialized": self.is_initialized,
                "models_loaded": list(self.models_loaded.keys()),
                "config": {
                    "model_name": self.config.model_name,
                    "backup_model": self.config.backup_model,
                    "input_size": self.config.input_size,
                    "num_keypoints": self.config.num_keypoints,
                    "use_fp16": self.config.use_fp16,
                    "use_coreml": self.config.use_coreml,
                    "confidence_threshold": self.config.confidence_threshold,
                    "enable_visualization": self.config.enable_visualization,
                    "visualization_quality": self.config.visualization_quality,
                    "optimization_enabled": self.config.optimization_enabled,
                    "quality_level": self.config.quality_level
                },
                "performance": self.processing_stats,
                "cache": {
                    "size": len(self.result_cache),
                    "max_size": self.config.max_cache_size,
                    "hit_rate": (self.processing_stats['cache_hits'] / 
                               max(1, self.processing_stats['total_processed'])) * 100
                },
                "memory_usage": memory_stats,
                "optimization": {
                    "m3_max_enabled": self.device == 'mps',
                    "neural_engine": self.config.enable_neural_engine,
                    "memory_efficient": self.config.memory_efficient,
                    "fp16_enabled": self.config.use_fp16,
                    "coreml_available": COREML_AVAILABLE
                }
            }
        except Exception as e:
            self.logger.warning(f"âš ï¸ Step ì •ë³´ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            return {
                "step_name": "pose_estimation",
                "step_number": 2,
                "device": self.device,
                "initialized": self.is_initialized,
                "error": str(e)
            }
    
    async def cleanup(self):
        """ì•ˆì „í•œ ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        self.logger.info("ğŸ§¹ 2ë‹¨ê³„: ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì¤‘...")
        
        try:
            # ëª¨ë¸ ì •ë¦¬
            if hasattr(self, 'models_loaded'):
                try:
                    for model_name, model in self.models_loaded.items():
                        try:
                            if hasattr(model, 'cpu'):
                                model.cpu()
                            del model
                        except Exception as e:
                            self.logger.debug(f"ëª¨ë¸ ì •ë¦¬ ì‹¤íŒ¨ ({model_name}): {e}")
                    self.models_loaded.clear()
                except Exception as e:
                    self.logger.warning(f"âš ï¸ ëª¨ë¸ ì •ë¦¬ ì‹¤íŒ¨: {e}")
            
            # ìºì‹œ ì •ë¦¬
            try:
                with self.cache_lock:
                    self.result_cache.clear()
            except Exception as e:
                self.logger.warning(f"âš ï¸ ìºì‹œ ì •ë¦¬ ì‹¤íŒ¨: {e}")
            
            # ModelLoader ì¸í„°í˜ì´ìŠ¤ ì •ë¦¬
            try:
                if hasattr(self, 'model_interface') and self.model_interface:
                    self.model_interface.unload_models()
            except Exception as e:
                self.logger.warning(f"âš ï¸ ëª¨ë¸ ì¸í„°í˜ì´ìŠ¤ ì •ë¦¬ ì‹¤íŒ¨: {e}")
            
            # ìŠ¤ë ˆë“œ í’€ ì •ë¦¬
            try:
                if hasattr(self, 'executor'):
                    self.executor.shutdown(wait=True)
            except Exception as e:
                self.logger.warning(f"âš ï¸ ìŠ¤ë ˆë“œ í’€ ì •ë¦¬ ì‹¤íŒ¨: {e}")
            
            # ë©”ëª¨ë¦¬ ì •ë¦¬
            try:
                await self.memory_manager.cleanup()
            except Exception as e:
                self.logger.warning(f"âš ï¸ ë©”ëª¨ë¦¬ ë§¤ë‹ˆì € ì •ë¦¬ ì‹¤íŒ¨: {e}")
            
            # MPS ìºì‹œ ì •ë¦¬
            try:
                if self.device == 'mps' and MPS_AVAILABLE:
                    if hasattr(torch.mps, 'empty_cache'):
                        torch.mps.empty_cache()
            except Exception as e:
                self.logger.debug(f"MPS ìºì‹œ ì •ë¦¬ ì‹¤íŒ¨: {e}")
            
            # ê°€ë¹„ì§€ ì»¬ë ‰ì…˜
            try:
                gc.collect()
            except Exception:
                pass
            
            self.is_initialized = False
            self.logger.info("âœ… 2ë‹¨ê³„ ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì™„ë£Œ")
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")

# ==============================================
# í•˜ìœ„ í˜¸í™˜ì„± ë° íŒ©í† ë¦¬ í•¨ìˆ˜
# ==============================================

async def create_pose_estimation_step(
    device: str = "auto",
    config: Optional[Union[Dict[str, Any], PoseEstimationConfig]] = None,
    **kwargs
) -> PoseEstimationStep:
    """
    Step 02 íŒ©í† ë¦¬ í•¨ìˆ˜ (ê¸°ì¡´ í˜¸í™˜ì„±)
    
    Args:
        device: ë””ë°”ì´ìŠ¤ ("auto"ëŠ” ìë™ ê°ì§€)
        config: ì„¤ì • ë”•ì…”ë„ˆë¦¬ ë˜ëŠ” PoseEstimationConfig
        **kwargs: ì¶”ê°€ ì„¤ì •
        
    Returns:
        PoseEstimationStep: ì´ˆê¸°í™”ëœ 2ë‹¨ê³„ ìŠ¤í…
    """
    
    try:
        # ë””ë°”ì´ìŠ¤ ì„¤ì •
        device_param = None if device == "auto" else device
        
        # ê¸°ë³¸ ì„¤ì • ë³‘í•©
        default_config = PoseEstimationConfig(
            model_name="openpose_body_25",
            backup_model="mediapipe_pose",
            device=device_param,
            use_fp16=True,
            use_coreml=COREML_AVAILABLE,
            warmup_enabled=True,
            apply_postprocessing=True,
            enable_visualization=True,  # ì‹œê°í™” ê¸°ë³¸ í™œì„±í™”
            visualization_quality="high",
            show_keypoint_labels=True,
            optimization_enabled=kwargs.get('optimization_enabled', True),
            quality_level=kwargs.get('quality_level', 'balanced')
        )
        
        # ì‚¬ìš©ì ì„¤ì • ë³‘í•©
        if isinstance(config, dict):
            for key, value in config.items():
                if hasattr(default_config, key):
                    try:
                        setattr(default_config, key, value)
                    except Exception:
                        pass
            final_config = default_config
        elif isinstance(config, PoseEstimationConfig):
            final_config = config
        else:
            final_config = default_config
        
        # kwargs ì ìš©
        for key, value in kwargs.items():
            if hasattr(final_config, key):
                try:
                    setattr(final_config, key, value)
                except Exception:
                    pass
        
        # Step ìƒì„± ë° ì´ˆê¸°í™”
        step = PoseEstimationStep(device=device_param, config=final_config)
        
        if not await step.initialize():
            step.logger.warning("âš ï¸ 2ë‹¨ê³„ ì´ˆê¸°í™” ì‹¤íŒ¨ - ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œë¡œ ë™ì‘")
        
        return step
        
    except Exception as e:
        logger = logging.getLogger(__name__)
        logger.error(f"âŒ create_pose_estimation_step ì‹¤íŒ¨: {e}")
        # í´ë°±: ìµœì†Œí•œì˜ Step ìƒì„±
        step = PoseEstimationStep(device='cpu')
        step.is_initialized = True  # ê°•ì œë¡œ ì´ˆê¸°í™” ìƒíƒœ ì„¤ì •
        return step

def create_pose_estimation_step_sync(
    device: str = "auto",
    config: Optional[Union[Dict[str, Any], PoseEstimationConfig]] = None,
    **kwargs
) -> PoseEstimationStep:
    """ì•ˆì „í•œ ë™ê¸°ì‹ Step 02 ìƒì„± (ë ˆê±°ì‹œ í˜¸í™˜)"""
    try:
        try:
            loop = asyncio.get_event_loop()
        except RuntimeError:
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
        
        return loop.run_until_complete(
            create_pose_estimation_step(device, config, **kwargs)
        )
    except Exception as e:
        logger = logging.getLogger(__name__)
        logger.error(f"âŒ create_pose_estimation_step_sync ì‹¤íŒ¨: {e}")
        # ì•ˆì „í•œ í´ë°±
        return PoseEstimationStep(device='cpu')

# ==============================================
# ì¶”ê°€ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
# ==============================================

def validate_openpose_keypoints(keypoints_18: List[List[float]]) -> bool:
    """OpenPose 18 keypoints ìœ íš¨ì„± ê²€ì¦"""
    try:
        if len(keypoints_18) != 18:
            return False
        
        for kp in keypoints_18:
            if len(kp) != 3:
                return False
            if not all(isinstance(x, (int, float)) for x in kp):
                return False
            if kp[2] < 0 or kp[2] > 1:  # ì‹ ë¢°ë„ëŠ” 0~1 ì‚¬ì´
                return False
        
        return True
        
    except Exception:
        return False

def convert_keypoints_to_coco(keypoints_18: List[List[float]]) -> List[List[float]]:
    """OpenPose 18ì„ COCO 17 í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
    try:
        # OpenPose 18 -> COCO 17 ë§¤í•‘
        op_to_coco_mapping = {
            0: 0,   # nose
            15: 1,  # right_eye -> left_eye (COCO ê´€ì )
            16: 2,  # left_eye -> right_eye
            17: 3,  # right_ear -> left_ear
            2: 5,   # right_shoulder -> left_shoulder (COCO ê´€ì )
            5: 6,   # left_shoulder -> right_shoulder
            3: 7,   # right_elbow -> left_elbow
            6: 8,   # left_elbow -> right_elbow
            4: 9,   # right_wrist -> left_wrist
            7: 10,  # left_wrist -> right_wrist
            9: 11,  # right_hip -> left_hip
            12: 12, # left_hip -> right_hip
            10: 13, # right_knee -> left_knee
            13: 14, # left_knee -> right_knee
            11: 15, # right_ankle -> left_ankle
            14: 16  # left_ankle -> right_ankle
        }
        
        coco_keypoints = [[0.0, 0.0, 0.0] for _ in range(17)]
        
        for coco_idx in range(17):
            if coco_idx in op_to_coco_mapping:
                op_idx = op_to_coco_mapping[coco_idx]
                if op_idx < len(keypoints_18):
                    coco_keypoints[coco_idx] = keypoints_18[op_idx].copy()
        
        return coco_keypoints
        
    except Exception as e:
        logging.error(f"í‚¤í¬ì¸íŠ¸ ë³€í™˜ ì‹¤íŒ¨: {e}")
        return [[0.0, 0.0, 0.0] for _ in range(17)]

def draw_pose_on_image(image: np.ndarray, keypoints_18: List[List[float]], 
                      confidence_threshold: float = 0.3) -> np.ndarray:
    """ì´ë¯¸ì§€ì— í¬ì¦ˆ ê·¸ë¦¬ê¸° (ë””ë²„ê¹…ìš©)"""
    try:
        result_image = image.copy()
        
        # ìŠ¤ì¼ˆë ˆí†¤ ì—°ê²°ì„  ê·¸ë¦¬ê¸°
        for connection in SKELETON_CONNECTIONS:
            try:
                point1_idx, point2_idx = connection
                
                if (point1_idx < len(keypoints_18) and point2_idx < len(keypoints_18)):
                    point1 = keypoints_18[point1_idx]
                    point2 = keypoints_18[point2_idx]
                    
                    if (point1[2] > confidence_threshold and point2[2] > confidence_threshold):
                        color = SKELETON_COLORS.get(connection, (255, 255, 255))
                        
                        cv2.line(result_image, 
                               (int(point1[0]), int(point1[1])), 
                               (int(point2[0]), int(point2[1])),
                               color, 2)
            except Exception:
                continue
        
        # í‚¤í¬ì¸íŠ¸ ì  ê·¸ë¦¬ê¸°
        for i, keypoint in enumerate(keypoints_18):
            try:
                if keypoint[2] > confidence_threshold:
                    color = KEYPOINT_COLORS.get(i, (255, 255, 255))
                    cv2.circle(result_image, (int(keypoint[0]), int(keypoint[1])), 4, color, -1)
                    cv2.circle(result_image, (int(keypoint[0]), int(keypoint[1])), 4, (0, 0, 0), 1)
            except Exception:
                continue
        
        return result_image
        
    except Exception as e:
        logging.error(f"í¬ì¦ˆ ê·¸ë¦¬ê¸° ì‹¤íŒ¨: {e}")
        return image

def analyze_pose_for_clothing(keypoints_18: List[List[float]], 
                            confidence_threshold: float = 0.3) -> Dict[str, Any]:
    """ì˜ë¥˜ í”¼íŒ…ì„ ìœ„í•œ í¬ì¦ˆ ë¶„ì„"""
    try:
        analysis = {
            'suitable_for_fitting': False,
            'issues': [],
            'recommendations': [],
            'pose_score': 0.0
        }
        
        # ì£¼ìš” í‚¤í¬ì¸íŠ¸ í™•ì¸
        essential_keypoints = [1, 2, 5, 8, 9, 12]  # neck, shoulders, hips
        essential_detected = [idx for idx in essential_keypoints 
                            if keypoints_18[idx][2] > confidence_threshold]
        
        if len(essential_detected) >= 5:
            analysis['pose_score'] += 0.5
        else:
            analysis['issues'].append("ì£¼ìš” í‚¤í¬ì¸íŠ¸ ë¶€ì¡±")
        
        # íŒ” ìœ„ì¹˜ í™•ì¸
        right_wrist = keypoints_18[4]
        left_wrist = keypoints_18[7]
        
        if (right_wrist[2] > confidence_threshold and left_wrist[2] > confidence_threshold):
            analysis['pose_score'] += 0.3
        else:
            analysis['issues'].append("ì†ëª© í‚¤í¬ì¸íŠ¸ ë¯¸ê°ì§€")
            analysis['recommendations'].append("íŒ”ì„ ëª…í™•íˆ ë³´ì´ê²Œ í•´ì£¼ì„¸ìš”")
        
        # ë‹¤ë¦¬ ìœ„ì¹˜ í™•ì¸
        right_ankle = keypoints_18[11]
        left_ankle = keypoints_18[14]
        
        if (right_ankle[2] > confidence_threshold and left_ankle[2] > confidence_threshold):
            analysis['pose_score'] += 0.2
        else:
            analysis['issues'].append("ë°œëª© í‚¤í¬ì¸íŠ¸ ë¯¸ê°ì§€")
            analysis['recommendations'].append("ì „ì‹ ì´ ë³´ì´ë„ë¡ ì´¬ì˜í•´ì£¼ì„¸ìš”")
        
        # ìµœì¢… íŒë‹¨
        analysis['suitable_for_fitting'] = analysis['pose_score'] >= 0.6
        
        if not analysis['issues']:
            analysis['recommendations'].append("ì™„ë²½í•œ í¬ì¦ˆì…ë‹ˆë‹¤!")
        
        return analysis
        
    except Exception as e:
        logging.error(f"í¬ì¦ˆ ë¶„ì„ ì‹¤íŒ¨: {e}")
        return {
            'suitable_for_fitting': False,
            'issues': ["ë¶„ì„ ì‹¤íŒ¨"],
            'recommendations': ["ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”"],
            'pose_score': 0.0
        }

# ==============================================
# ëª¨ë“ˆ Export
# ==============================================

__all__ = [
    'PoseEstimationStep',
    'PoseEstimationConfig',
    'PoseType',
    'PoseQuality',
    'create_pose_estimation_step',
    'create_pose_estimation_step_sync',
    'validate_openpose_keypoints',
    'convert_keypoints_to_coco',
    'draw_pose_on_image',
    'analyze_pose_for_clothing',
    'OPENPOSE_18_KEYPOINTS',
    'KEYPOINT_COLORS',
    'SKELETON_CONNECTIONS',
    'SKELETON_COLORS'
]

# ==============================================
# ì‚¬ìš© ì˜ˆì‹œ ë° í…ŒìŠ¤íŠ¸ í•¨ìˆ˜ë“¤
# ==============================================

async def test_pose_estimation_with_visualization():
    """ì‹œê°í™” ê¸°ëŠ¥ í¬í•¨ í…ŒìŠ¤íŠ¸ í•¨ìˆ˜"""
    print("ğŸ§ª í¬ì¦ˆ ì¶”ì • + ì‹œê°í™” í…ŒìŠ¤íŠ¸ ì‹œì‘")
    
    try:
        # Step ìƒì„±
        step = await create_pose_estimation_step(
            device="auto",
            config={
                "enable_visualization": True,
                "visualization_quality": "high",
                "show_keypoint_labels": True
            }
        )
        
        # ë”ë¯¸ ì´ë¯¸ì§€ í…ì„œ ìƒì„±
        dummy_image = torch.randn(1, 3, 512, 512)
        
        # ì²˜ë¦¬ ì‹¤í–‰
        result = await step.process(dummy_image)
        
        # ê²°ê³¼ í™•ì¸
        if result["success"]:
            print("âœ… ì²˜ë¦¬ ì„±ê³µ!")
            print(f"ğŸ“Š ê°ì§€ëœ í‚¤í¬ì¸íŠ¸: {result['details']['keypoints_detected']}/18")
            print(f"ğŸ¨ ìŠ¤ì¼ˆë ˆí†¤ ì´ë¯¸ì§€: {'ìˆìŒ' if result['details']['result_image'] else 'ì—†ìŒ'}")
            print(f"ğŸ” í‚¤í¬ì¸íŠ¸ ì´ë¯¸ì§€: {'ìˆìŒ' if result['details']['keypoints_image'] else 'ì—†ìŒ'}")
            print(f"ğŸ† í¬ì¦ˆ í’ˆì§ˆ: {result['details']['pose_quality']}")
            print(f"ğŸ“ í¬ì¦ˆ íƒ€ì…: {result['details']['pose_type']}")
        else:
            print(f"âŒ ì²˜ë¦¬ ì‹¤íŒ¨: {result.get('message', 'Unknown error')}")
        
        # ì •ë¦¬
        await step.cleanup()
        print("ğŸ§¹ ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì™„ë£Œ")
        
    except Exception as e:
        print(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")

def test_pose_config_compatibility():
    """í¬ì¦ˆ ì„¤ì • í˜¸í™˜ì„± í…ŒìŠ¤íŠ¸"""
    print("ğŸ§ª í¬ì¦ˆ ì„¤ì • í˜¸í™˜ì„± í…ŒìŠ¤íŠ¸ ì‹œì‘")
    
    try:
        # PipelineManagerê°€ ì „ë‹¬í•  ìˆ˜ ìˆëŠ” ëª¨ë“  íŒŒë¼ë¯¸í„° í…ŒìŠ¤íŠ¸
        test_params = {
            'device': 'cpu',
            'optimization_enabled': True,
            'device_type': 'cpu',
            'memory_gb': 16.0,
            'is_m3_max': False,
            'quality_level': 'balanced',
            'model_type': 'openpose',
            'processing_mode': 'production',
            'enable_gpu_acceleration': False,
            'unknown_param': 'should_be_ignored'  # ì•Œ ìˆ˜ ì—†ëŠ” íŒŒë¼ë¯¸í„°
        }
        
        # ì„¤ì • ìƒì„± í…ŒìŠ¤íŠ¸
        config = PoseEstimationConfig(**{k: v for k, v in test_params.items() 
                                      if k in PoseEstimationConfig.__dataclass_fields__})
        print("âœ… ì„¤ì • ìƒì„± ì„±ê³µ")
        print(f"   - ìµœì í™”: {config.optimization_enabled}")
        print(f"   - í’ˆì§ˆ: {config.quality_level}")
        print(f"   - ë””ë°”ì´ìŠ¤: {config.device}")
        
        # Step ìƒì„± í…ŒìŠ¤íŠ¸
        step = PoseEstimationStep(config=config)
        print("âœ… Step ìƒì„± ì„±ê³µ")
        print(f"   - ì´ˆê¸°í™” ìƒíƒœ: {step.is_initialized}")
        print(f"   - Logger ì¡´ì¬: {hasattr(step, 'logger') and step.logger is not None}")
        
        return True
        
    except Exception as e:
        print(f"âŒ í˜¸í™˜ì„± í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        return False

if __name__ == "__main__":
    # í˜¸í™˜ì„± í…ŒìŠ¤íŠ¸ ë¨¼ì € ì‹¤í–‰
    if test_pose_config_compatibility():
        print("\n" + "="*50)
        # ì‹œê°í™” í…ŒìŠ¤íŠ¸ ì‹¤í–‰
        asyncio.run(test_pose_estimation_with_visualization())
    else:
        print("âŒ ê¸°ë³¸ í˜¸í™˜ì„± í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨")

# ëª¨ë“ˆ ë¡œë”© í™•ì¸
logger = logging.getLogger(__name__)
logger.info("âœ… Step 02 Pose Estimation ëª¨ë“ˆ ë¡œë“œ ì™„ë£Œ - ì™„ì „ ìˆ˜ì •ëœ ë²„ì „")
logger.info("ğŸ”— BaseStepMixin ì™„ì „ ì—°ë™ìœ¼ë¡œ logger ì†ì„± ëˆ„ë½ ë¬¸ì œ í•´ê²°")
logger.info("ğŸ”— ModelLoader ì¸í„°í˜ì´ìŠ¤ ì™„ë²½ ì—°ë™ìœ¼ë¡œ ì‹¤ì œ AI ëª¨ë¸ ì‘ë™")
logger.info("ğŸ¨ OpenPose 18 í‚¤í¬ì¸íŠ¸ + ìŠ¤ì¼ˆë ˆí†¤ ì‹œê°í™” ê¸°ëŠ¥ í¬í•¨")