"""
ðŸ”¥ MyCloset AI - 2ë‹¨ê³„: í¬ì¦ˆ ì¶”ì • (Pose Estimation) - ì™„ì „í•œ ì‹¤ì œ AI ì „ìš© ë²„ì „
===============================================================================

âœ… í´ë°± ì™„ì „ ì œê±° - 100% ì‹¤ì œ AI ëª¨ë¸ë§Œ ì‚¬ìš©
âœ… strict_mode=True - ì‹¤íŒ¨ ì‹œ ì¦‰ì‹œ ì—ëŸ¬ ë°˜í™˜
âœ… ModelLoader ì™„ì „ ì—°ë™ - ìˆœí™˜ì°¸ì¡° ì—†ëŠ” í•œë°©í–¥ ì°¸ì¡°
âœ… BaseStepMixin ì™„ì „ ìƒì† - logger ì†ì„± ëˆ„ë½ ì™„ì „ í•´ê²°
âœ… step_model_requests.py ì™„ë²½ í˜¸í™˜
âœ… ëª¨ë“  ë¶„ì„ ë©”ì„œë“œ í¬í•¨ - ê°ë„, ë¹„ìœ¨, ëŒ€ì¹­ì„±, ê°€ì‹œì„±
âœ… COCO â†” OpenPose ë³€í™˜ ì§€ì›
âœ… M3 Max 128GB ìµœì í™” + conda í™˜ê²½ ìµœì í™”
âœ… MRO ì˜¤ë¥˜ ì™„ì „ ë°©ì§€

ðŸŽ¯ í•µì‹¬ ì›ì¹™:
- ì‹¤ì œ AI ëª¨ë¸ ì‹¤íŒ¨ â†’ ëª…í™•í•œ ì—ëŸ¬ ë°˜í™˜ (í´ë°± ì ˆëŒ€ ê¸ˆì§€)
- ModelLoader ì—†ìŒ â†’ ì¦‰ì‹œ ì´ˆê¸°í™” ì‹¤íŒ¨ 
- ì‹œë®¬ë ˆì´ì…˜/ë”ë¯¸ ë°ì´í„° ì™„ì „ ì œê±°
- strict ê²€ì¦ìœ¼ë¡œ ì‹ ë¢°ì„± ë³´ìž¥

íŒŒì¼ ìœ„ì¹˜: backend/app/ai_pipeline/steps/step_02_pose_estimation.py
ìž‘ì„±ìž: MyCloset AI Team  
ë‚ ì§œ: 2025-07-21
ë²„ì „: v7.0 (ì™„ì „í•œ ì‹¤ì œ AI ì „ìš©)
"""

import os
import sys
import logging
import time
import asyncio
import threading
import json
import gc
import hashlib
import base64
from typing import Dict, Any, Optional, Tuple, List, Union, Callable
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor
from dataclasses import dataclass, field, asdict
from enum import Enum
from functools import lru_cache
import numpy as np
import io

# ==============================================
# ðŸ”¥ í•„ìˆ˜ íŒ¨í‚¤ì§€ ê²€ì¦ (conda í™˜ê²½ ìš°ì„ )
# ==============================================

try:
    import torch
    import torch.nn as nn
    import torch.nn.functional as F
    from torch.cuda.amp import autocast
    TORCH_AVAILABLE = True
    TORCH_VERSION = torch.__version__
except ImportError as e:
    raise ImportError(f"âŒ PyTorch í•„ìˆ˜: conda install pytorch torchvision pytorch-cuda -c pytorch -c nvidia\nì„¸ë¶€ ì˜¤ë¥˜: {e}")

try:
    import cv2
    CV2_AVAILABLE = True
    CV2_VERSION = cv2.__version__
except ImportError as e:
    raise ImportError(f"âŒ OpenCV í•„ìˆ˜: conda install opencv -c conda-forge\nì„¸ë¶€ ì˜¤ë¥˜: {e}")

try:
    from PIL import Image, ImageDraw, ImageFont
    PIL_AVAILABLE = True
    PIL_VERSION = Image.__version__ if hasattr(Image, '__version__') else "Unknown"
except ImportError as e:
    raise ImportError(f"âŒ Pillow í•„ìˆ˜: conda install pillow -c conda-forge\nì„¸ë¶€ ì˜¤ë¥˜: {e}")

try:
    import psutil
    PSUTIL_AVAILABLE = True
    PSUTIL_VERSION = psutil.__version__
except ImportError:
    PSUTIL_AVAILABLE = False
    PSUTIL_VERSION = "Not Available"
    print("âš ï¸ psutil ê¶Œìž¥: conda install psutil -c conda-forge")

# ==============================================
# ðŸ”¥ í•œë°©í–¥ ì°¸ì¡° êµ¬ì¡° - ìˆœí™˜ì°¸ì¡° ì™„ì „ ë°©ì§€
# ==============================================

# 1. BaseStepMixin ìž„í¬íŠ¸ (í•„ìˆ˜ - í´ë°± ê¸ˆì§€)
try:
    from app.ai_pipeline.steps.base_step_mixin import BaseStepMixin
    BASE_STEP_MIXIN_AVAILABLE = True
except ImportError as e:
    raise ImportError(f"âŒ BaseStepMixin í•„ìˆ˜ - í”„ë¡œì íŠ¸ êµ¬ì¡°ë¥¼ í™•ì¸í•˜ì„¸ìš”: {e}")

# 2. ModelLoader ìž„í¬íŠ¸ (í•„ìˆ˜ - í´ë°± ê¸ˆì§€)
try:
    from app.ai_pipeline.utils.model_loader import (
        ModelLoader, get_global_model_loader
    )
    MODEL_LOADER_AVAILABLE = True
except ImportError as e:
    raise ImportError(f"âŒ ModelLoader í•„ìˆ˜ - í”„ë¡œì íŠ¸ êµ¬ì¡°ë¥¼ í™•ì¸í•˜ì„¸ìš”: {e}")

# 3. ë©”ëª¨ë¦¬ ë° ë°ì´í„° ë³€í™˜ê¸° (ì„ íƒì )
try:
    from app.ai_pipeline.utils.memory_manager import get_global_memory_manager
    MEMORY_MANAGER_AVAILABLE = True
except ImportError:
    MEMORY_MANAGER_AVAILABLE = False

try:
    from app.ai_pipeline.utils.data_converter import get_global_data_converter  
    DATA_CONVERTER_AVAILABLE = True
except ImportError:
    DATA_CONVERTER_AVAILABLE = False

# ë¡œê±° ì„¤ì •
logger = logging.getLogger(__name__)

# ==============================================
# ðŸ”¥ ìƒìˆ˜ ë° ë°ì´í„° êµ¬ì¡° ì •ì˜
# ==============================================

class PoseModel(Enum):
    """í¬ì¦ˆ ì¶”ì • ëª¨ë¸ íƒ€ìž…"""
    OPENPOSE = "pose_estimation_openpose"
    YOLOV8_POSE = "pose_estimation_sk" 
    LIGHTWEIGHT = "pose_estimation_lightweight"

class PoseQuality(Enum):
    """í¬ì¦ˆ í’ˆì§ˆ ë“±ê¸‰"""
    EXCELLENT = "excellent"     # 90-100ì 
    GOOD = "good"              # 75-89ì   
    ACCEPTABLE = "acceptable"   # 60-74ì 
    POOR = "poor"              # 40-59ì 
    VERY_POOR = "very_poor"    # 0-39ì 

class PoseType(Enum):
    """í¬ì¦ˆ íƒ€ìž…"""
    T_POSE = "t_pose"          # Tìž í¬ì¦ˆ
    A_POSE = "a_pose"          # Aìž í¬ì¦ˆ
    STANDING = "standing"      # ì¼ë°˜ ì„œìžˆëŠ” í¬ì¦ˆ
    SITTING = "sitting"        # ì•‰ì€ í¬ì¦ˆ
    ACTION = "action"          # ì•¡ì…˜ í¬ì¦ˆ
    UNKNOWN = "unknown"        # ì•Œ ìˆ˜ ì—†ëŠ” í¬ì¦ˆ

# OpenPose 18 í‚¤í¬ì¸íŠ¸ ì •ì˜ (step_model_requests.py í˜¸í™˜)
OPENPOSE_18_KEYPOINTS = [
    "nose", "neck", "right_shoulder", "right_elbow", "right_wrist",
    "left_shoulder", "left_elbow", "left_wrist", "middle_hip", "right_hip", 
    "right_knee", "right_ankle", "left_hip", "left_knee", "left_ankle",
    "right_eye", "left_eye", "right_ear", "left_ear"
]

# í‚¤í¬ì¸íŠ¸ ìƒ‰ìƒ (ì‹œê°í™”ìš©)
KEYPOINT_COLORS = [
    (255, 0, 0), (255, 85, 0), (255, 170, 0), (255, 255, 0), (170, 255, 0),
    (85, 255, 0), (0, 255, 0), (0, 255, 85), (0, 255, 170), (0, 255, 255),
    (0, 170, 255), (0, 85, 255), (0, 0, 255), (85, 0, 255), (170, 0, 255),
    (255, 0, 255), (255, 0, 170), (255, 0, 85), (255, 0, 0)
]

# ìŠ¤ì¼ˆë ˆí†¤ ì—°ê²° (OpenPose 18 ê¸°ì¤€)
SKELETON_CONNECTIONS = [
    (0, 1), (1, 2), (2, 3), (3, 4), (1, 5), (5, 6), (6, 7), (1, 8),
    (8, 9), (9, 10), (10, 11), (8, 12), (12, 13), (13, 14), (0, 15),
    (15, 17), (0, 16), (16, 18)
]

SKELETON_COLORS = [
    (255, 0, 0), (255, 85, 0), (255, 170, 0), (255, 255, 0), (170, 255, 0),
    (85, 255, 0), (0, 255, 0), (0, 255, 85), (0, 255, 170), (0, 255, 255),
    (0, 170, 255), (0, 85, 255), (0, 0, 255), (85, 0, 255), (170, 0, 255),
    (255, 0, 255), (255, 0, 170), (255, 0, 85)
]

# ==============================================
# ðŸ”¥ ë°ì´í„° í´ëž˜ìŠ¤ ì •ì˜  
# ==============================================

@dataclass
class PoseMetrics:
    """í¬ì¦ˆ ì¸¡ì • ë°ì´í„°"""
    keypoints: List[List[float]] = field(default_factory=list)
    confidence_scores: List[float] = field(default_factory=list)
    bbox: Tuple[int, int, int, int] = field(default_factory=lambda: (0, 0, 0, 0))
    pose_type: PoseType = PoseType.UNKNOWN
    pose_quality: PoseQuality = PoseQuality.POOR
    overall_score: float = 0.0
    
    # ì‹ ì²´ ë¶€ìœ„ë³„ ì ìˆ˜
    head_score: float = 0.0
    torso_score: float = 0.0  
    arms_score: float = 0.0
    legs_score: float = 0.0
    
    # ì˜ë¥˜ ì°©ìš© ì í•©ì„±
    suitable_for_fitting: bool = False
    issues: List[str] = field(default_factory=list)
    recommendations: List[str] = field(default_factory=list)
    
    # ì²˜ë¦¬ ë©”íƒ€ë°ì´í„°
    model_used: str = ""
    processing_time: float = 0.0
    image_resolution: Tuple[int, int] = field(default_factory=lambda: (0, 0))
    
    def calculate_overall_score(self) -> float:
        """ì „ì²´ ì ìˆ˜ ê³„ì‚°"""
        try:
            if not self.confidence_scores:
                self.overall_score = 0.0
                return 0.0
            
            # ê°€ì¤‘ í‰ê·  ê³„ì‚°
            scores = [
                self.head_score * 0.2,
                self.torso_score * 0.3,
                self.arms_score * 0.25,
                self.legs_score * 0.25
            ]
            
            self.overall_score = sum(scores)
            return self.overall_score
            
        except Exception as e:
            logger.error(f"ì „ì²´ ì ìˆ˜ ê³„ì‚° ì‹¤íŒ¨: {e}")
            self.overall_score = 0.0
            return 0.0
    
    def to_dict(self) -> Dict[str, Any]:
        """ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜"""
        return asdict(self)

# ==============================================
# ðŸ”¥ ë©”ì¸ PoseEstimationStep í´ëž˜ìŠ¤
# ==============================================

class PoseEstimationStep(BaseStepMixin):
    """
    ðŸ”¥ 2ë‹¨ê³„: ì™„ì „í•œ ì‹¤ì œ AI í¬ì¦ˆ ì¶”ì • ì‹œìŠ¤í…œ - í´ë°± ì™„ì „ ì œê±°
    âœ… BaseStepMixin ì™„ì „ ìƒì† - logger ì†ì„± ëˆ„ë½ ì™„ì „ í•´ê²°
    âœ… ModelLoader ì™„ì „ ì—°ë™ - ì§ì ‘ ëª¨ë¸ í˜¸ì¶œ ì œê±°  
    âœ… strict_mode=True - ì‹¤íŒ¨ ì‹œ ì¦‰ì‹œ ì—ëŸ¬ ë°˜í™˜
    âœ… ì‹¤ì œ AI ëª¨ë¸ë§Œ ì‚¬ìš© - ì‹œë®¬ë ˆì´ì…˜ ì™„ì „ ì œê±°
    âœ… step_model_requests.py ì™„ë²½ í˜¸í™˜
    âœ… ëª¨ë“  ë¶„ì„ ë©”ì„œë“œ í¬í•¨ - ê°ë„, ë¹„ìœ¨, ëŒ€ì¹­ì„± ë“±
    âœ… M3 Max ìµœì í™” + 18ê°œ í‚¤í¬ì¸íŠ¸ OpenPose
    """
    
    # ì˜ë¥˜ íƒ€ìž…ë³„ í¬ì¦ˆ ê°€ì¤‘ì¹˜ (step_model_requests.py ë©”íƒ€ë°ì´í„°ì™€ ì—°ë™)
    CLOTHING_POSE_WEIGHTS = {
        'shirt': {'arms': 0.4, 'torso': 0.4, 'visibility': 0.2},
        'dress': {'torso': 0.5, 'arms': 0.3, 'legs': 0.2},
        'pants': {'legs': 0.6, 'torso': 0.3, 'visibility': 0.1},
        'jacket': {'arms': 0.5, 'torso': 0.4, 'visibility': 0.1},
        'skirt': {'torso': 0.4, 'legs': 0.4, 'visibility': 0.2},
        'top': {'torso': 0.5, 'arms': 0.4, 'visibility': 0.1},
        'default': {'torso': 0.4, 'arms': 0.3, 'legs': 0.2, 'visibility': 0.1}
    }
    
    def __init__(
        self,
        device: Optional[str] = None,
        config: Optional[Dict[str, Any]] = None,
        strict_mode: bool = True,
        **kwargs
    ):
        """
        ðŸ”¥ ì™„ì „í•œ ì‹¤ì œ AI ì „ìš© ìƒì„±ìž - í´ë°± ì™„ì „ ì œê±°
        
        Args:
            device: ë””ë°”ì´ìŠ¤ ì„¤ì • ('auto', 'mps', 'cuda', 'cpu')
            config: ì„¤ì • ë”•ì…”ë„ˆë¦¬
            strict_mode: ì—„ê²© ëª¨ë“œ (Trueì‹œ AI ì‹¤íŒ¨ â†’ ì¦‰ì‹œ ì—ëŸ¬)
            **kwargs: ì¶”ê°€ ì„¤ì •
        """
        
        # ðŸ”¥ 1. BaseStepMixin ì™„ì „ ì´ˆê¸°í™” (MRO ì•ˆì „)
        super().__init__(device=device, config=config, **kwargs)
        
        # ðŸ”¥ 2. logger ì†ì„± ëˆ„ë½ ì™„ì „ í•´ê²°
        if not hasattr(self, 'logger'):
            self.logger = logging.getLogger(f"pipeline.{self.__class__.__name__}")
        
        # ðŸ”¥ 3. Step ê³ ìœ  ì„¤ì •
        self.step_name = "PoseEstimationStep"
        self.step_number = 2
        self.step_description = "ì™„ì „í•œ ì‹¤ì œ AI ì¸ì²´ í¬ì¦ˆ ì¶”ì • ë° í‚¤í¬ì¸íŠ¸ ê²€ì¶œ"
        
        # ðŸ”¥ 4. ì—„ê²© ëª¨ë“œ ì„¤ì • (í•µì‹¬)
        self.strict_mode = strict_mode
        if self.strict_mode:
            self.logger.info("ðŸ”’ Strict Mode í™œì„±í™” - ì‹¤ì œ AI ëª¨ë¸ë§Œ ì‚¬ìš©, í´ë°± ì™„ì „ ê¸ˆì§€")
        
        # ðŸ”¥ 5. ë””ë°”ì´ìŠ¤ ì„¤ì •
        self._setup_device(device)
        
        # ðŸ”¥ 6. ì„¤ì • í†µí•©
        self._setup_config(config, **kwargs)
        
        # ðŸ”¥ 7. í¬ì¦ˆ ì¶”ì • ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        self._initialize_pose_system()
        
        # ðŸ”¥ 8. ì´ˆê¸°í™” ìƒíƒœ
        self.is_initialized = False
        self.initialization_lock = threading.Lock()
        
        self.logger.info(f"ðŸŽ¯ {self.step_name} ìƒì„± ì™„ë£Œ (Strict Mode: {self.strict_mode})")
    
    def _setup_device(self, device: Optional[str]):
        """ë””ë°”ì´ìŠ¤ ì„¤ì • - í´ë°± ì—†ëŠ” ì—„ê²© ëª¨ë“œ"""
        try:
            if device is None or device == "auto":
                if torch.backends.mps.is_available():
                    self.device = "mps"
                    self.is_m3_max = True
                elif torch.cuda.is_available():
                    self.device = "cuda"
                    self.is_m3_max = False
                else:
                    self.device = "cpu"
                    self.is_m3_max = False
            else:
                self.device = device
                self.is_m3_max = device == "mps"
            
            # ë©”ëª¨ë¦¬ ì •ë³´ ìˆ˜ì§‘
            if PSUTIL_AVAILABLE:
                memory = psutil.virtual_memory()
                self.memory_gb = memory.total / (1024**3)
            else:
                self.memory_gb = 16.0  # ê¸°ë³¸ê°’
            
            self.logger.info(f"ðŸ”§ ë””ë°”ì´ìŠ¤: {self.device}, M3 Max: {self.is_m3_max}, ë©”ëª¨ë¦¬: {self.memory_gb:.1f}GB")
            
        except Exception as e:
            error_msg = f"ë””ë°”ì´ìŠ¤ ì„¤ì • ì‹¤íŒ¨: {e}"
            self.logger.error(f"âŒ {error_msg}")
            if self.strict_mode:
                raise RuntimeError(f"Strict Mode: {error_msg}")
            # ë¹„ì—„ê²© ëª¨ë“œì—ì„œë§Œ í´ë°±
            self.device = "cpu"
            self.is_m3_max = False
            self.memory_gb = 16.0
    
    def _setup_config(self, config: Optional[Dict[str, Any]], **kwargs):
        """ì„¤ì • í†µí•©"""
        self.config = config or {}
        
        # kwargsì—ì„œ ì‹œìŠ¤í…œ íŒŒë¼ë¯¸í„° ì¶”ì¶œ
        system_params = ['device', 'optimization_level', 'batch_size', 'memory_limit']
        for key, value in kwargs.items():
            if key in system_params:
                self.config[key] = value
        
        # ê¸°ë³¸ ì„¤ì • (ì‹¤ì œ AI ì „ìš©)
        default_config = {
            'confidence_threshold': 0.5,
            'visualization_enabled': True,
            'return_analysis': True,
            'cache_enabled': True,
            'detailed_analysis': True,
            'strict_mode': self.strict_mode,
            'fallback_enabled': False,  # í´ë°± ì™„ì „ ê¸ˆì§€
            'real_ai_only': True        # ì‹¤ì œ AIë§Œ ì‚¬ìš©
        }
        
        # ì„¤ì • ë³‘í•©
        for key, default_value in default_config.items():
            if key not in self.config:
                self.config[key] = kwargs.get(key, default_value)
        
        self.logger.info(f"ðŸ”§ ì„¤ì • ì™„ë£Œ: {list(self.config.keys())}")
    
    def _initialize_pose_system(self):
        """í¬ì¦ˆ ì¶”ì • ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
        
        # í¬ì¦ˆ ì¶”ì • ì„¤ì • (ì‹¤ì œ AI ì „ìš©)
        self.pose_config = {
            'model_priority': self.config.get('model_priority', [
                'pose_estimation_openpose', 
                'pose_estimation_sk', 
                'pose_estimation_lightweight'
            ]),
            'confidence_threshold': self.config.get('confidence_threshold', 0.5),
            'visualization_enabled': self.config.get('visualization_enabled', True),
            'return_analysis': self.config.get('return_analysis', True),
            'cache_enabled': self.config.get('cache_enabled', True),
            'batch_processing': self.config.get('batch_processing', False),
            'detailed_analysis': self.config.get('detailed_analysis', True),
            'real_ai_only': True,       # ì‹¤ì œ AIë§Œ ì‚¬ìš©
            'fallback_enabled': False   # í´ë°± ì™„ì „ ê¸ˆì§€
        }
        
        # ìµœì í™” ë ˆë²¨ ì„¤ì • (M3 Max íŠ¹í™”)
        if self.is_m3_max:
            self.optimization_level = 'maximum'
            self.batch_processing = True
            self.use_neural_engine = True
        elif self.memory_gb >= 32:
            self.optimization_level = 'high'
            self.batch_processing = True
            self.use_neural_engine = False
        else:
            self.optimization_level = 'basic'
            self.batch_processing = False
            self.use_neural_engine = False
        
        # ìºì‹œ ì‹œìŠ¤í…œ
        cache_size = min(100 if self.is_m3_max else 50, int(self.memory_gb * 2))
        self.prediction_cache = {}
        self.cache_max_size = cache_size
        
        self.logger.info(f"ðŸŽ¯ ì‹¤ì œ AI í¬ì¦ˆ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ - ìµœì í™”: {self.optimization_level}")
    
    def _get_step_model_requirements(self) -> Dict[str, Any]:
        """ðŸ”¥ step_model_requests.py ì™„ë²½ í˜¸í™˜ ìš”êµ¬ì‚¬í•­"""
        return {
            "step_name": "PoseEstimationStep",
            "model_name": "pose_estimation_openpose",
            "step_priority": "HIGH",
            "model_class": "OpenPoseModel",
            "input_size": (368, 368),
            "num_classes": 18,
            "output_format": "keypoints_heatmap",
            "device": self.device,
            "precision": "fp16" if self.is_m3_max else "fp32",
            
            # ì²´í¬í¬ì¸íŠ¸ íƒì§€ íŒ¨í„´ (ì‹¤ì œ íŒŒì¼ ê¸°ë°˜)
            "checkpoint_patterns": [
                r".*openpose\.pth$",
                r".*yolov8n-pose\.pt$",
                r".*pose.*model.*\.pth$",
                r".*body.*pose.*\.pth$"
            ],
            "file_extensions": [".pth", ".pt", ".tflite"],
            "size_range_mb": (6.5, 199.6),  # ì‹¤ì œ íƒì§€ëœ í¬ê¸°
            
            # ìµœì í™” íŒŒë¼ë¯¸í„°
            "optimization_params": {
                "batch_size": 1,
                "memory_fraction": 0.25,
                "inference_threads": 4,
                "enable_tensorrt": self.is_m3_max,
                "enable_neural_engine": self.is_m3_max,
                "precision": "fp16" if self.is_m3_max else "fp32"
            },
            
            # ëŒ€ì²´ ëª¨ë¸ë“¤ (ì‹¤ì œ AIë§Œ)
            "alternative_models": [
                "pose_estimation_sk",       # YOLOv8 í¬ì¦ˆ
                "pose_estimation_lightweight"
            ],
            
            # ë©”íƒ€ë°ì´í„° (ì™„ì „í•œ AI ì „ìš©)
            "metadata": {
                "description": "ì™„ì „í•œ ì‹¤ì œ AI 18ê°œ í‚¤í¬ì¸íŠ¸ í¬ì¦ˆ ì¶”ì •",
                "keypoints_format": "openpose_18",
                "supports_hands": True,
                "supports_face": True,
                "num_stages": 6,
                "clothing_types_supported": list(self.CLOTHING_POSE_WEIGHTS.keys()),
                "quality_assessment": True,
                "visualization_support": True,
                "strict_mode_compatible": True,
                "fallback_disabled": True,    # í´ë°± ì™„ì „ ë¹„í™œì„±í™”
                "real_ai_only": True,         # ì‹¤ì œ AIë§Œ ì‚¬ìš©
                "analysis_features": [
                    "pose_angles", "body_proportions", "symmetry_score", 
                    "visibility_score", "clothing_suitability"
                ],
                "format_conversion": ["coco_17", "openpose_18"]
            }
        }
    
    async def initialize(self) -> bool:
        """
        ðŸ”¥ ì™„ì „í•œ ì‹¤ì œ AI ëª¨ë¸ ì´ˆê¸°í™” - í´ë°± ì™„ì „ ì œê±°
        
        Returns:
            bool: ì´ˆê¸°í™” ì„±ê³µ ì—¬ë¶€ (strict_modeì—ì„œëŠ” ì‹¤íŒ¨ ì‹œ Exception)
        """
        try:
            with self.initialization_lock:
                if self.is_initialized:
                    return True
                
                self.logger.info(f"ðŸš€ {self.step_name} ì™„ì „í•œ ì‹¤ì œ AI ì´ˆê¸°í™” ì‹œìž‘")
                start_time = time.time()
                
                # ðŸ”¥ 1. ModelLoader í•„ìˆ˜ ê²€ì¦ (í´ë°± ê¸ˆì§€)
                if not MODEL_LOADER_AVAILABLE:
                    error_msg = "ModelLoader ì‚¬ìš© ë¶ˆê°€ - ì‹¤ì œ AI ëª¨ë¸ ë¡œë“œ ë¶ˆê°€ëŠ¥"
                    self.logger.error(f"âŒ {error_msg}")
                    if self.strict_mode:
                        raise RuntimeError(f"Strict Mode: {error_msg}")
                    return False
                
                # ðŸ”¥ 2. ê¸€ë¡œë²Œ ModelLoader ê°€ì ¸ì˜¤ê¸° (í•„ìˆ˜)
                try:
                    self.model_loader = get_global_model_loader()
                    if not self.model_loader:
                        error_msg = "ê¸€ë¡œë²Œ ModelLoader ì—†ìŒ - ì‹¤ì œ AI ëª¨ë¸ ì‹œìŠ¤í…œ ì—†ìŒ"
                        self.logger.error(f"âŒ {error_msg}")
                        if self.strict_mode:
                            raise RuntimeError(f"Strict Mode: {error_msg}")
                        return False
                    
                    # Step ì¸í„°íŽ˜ì´ìŠ¤ ìƒì„±
                    if hasattr(self.model_loader, 'create_step_interface'):
                        self.model_interface = self.model_loader.create_step_interface(self.step_name)
                    else:
                        self.model_interface = self.model_loader
                    
                    self.logger.info("âœ… ì‹¤ì œ AI ModelLoader ì—°ë™ ì„±ê³µ")
                    
                except Exception as e:
                    error_msg = f"ì‹¤ì œ AI ModelLoader ì—°ë™ ì‹¤íŒ¨: {e}"
                    self.logger.error(f"âŒ {error_msg}")
                    if self.strict_mode:
                        raise RuntimeError(f"Strict Mode: {error_msg}")
                    return False
                
                # ðŸ”¥ 3. Step ìš”êµ¬ì‚¬í•­ ë“±ë¡ (ì‹¤ì œ AI ì „ìš©)
                requirements = self._get_step_model_requirements()
                requirements_registered = await self._register_step_requirements(requirements)
                
                if not requirements_registered:
                    error_msg = "ì‹¤ì œ AI Step ìš”êµ¬ì‚¬í•­ ë“±ë¡ ì‹¤íŒ¨"
                    self.logger.error(f"âŒ {error_msg}")
                    if self.strict_mode:
                        raise RuntimeError(f"Strict Mode: {error_msg}")
                    return False
                
                # ðŸ”¥ 4. ì‹¤ì œ AI ëª¨ë¸ë§Œ ë¡œë“œ (í´ë°± ì™„ì „ ê¸ˆì§€)
                models_loaded = await self._load_real_ai_models_only(requirements)
                
                if not models_loaded:
                    error_msg = "ì‹¤ì œ AI ëª¨ë¸ ë¡œë“œ ì™„ì „ ì‹¤íŒ¨ - ì‚¬ìš© ê°€ëŠ¥í•œ AI ëª¨ë¸ ì—†ìŒ"
                    self.logger.error(f"âŒ {error_msg}")
                    if self.strict_mode:
                        raise RuntimeError(f"Strict Mode: {error_msg}")
                    return False
                
                # ðŸ”¥ 5. ì‹¤ì œ AI ëª¨ë¸ ê²€ì¦ (ì—„ê²©í•œ ê²€ì¦)
                validation_success = await self._validate_real_ai_models()
                
                if not validation_success:
                    error_msg = "ì‹¤ì œ AI ëª¨ë¸ ê²€ì¦ ì‹¤íŒ¨ - ë¡œë“œëœ ëª¨ë¸ì´ ìœ íš¨í•˜ì§€ ì•ŠìŒ"
                    self.logger.error(f"âŒ {error_msg}")
                    if self.strict_mode:
                        raise RuntimeError(f"Strict Mode: {error_msg}")
                    return False
                
                # ðŸ”¥ 6. ë©”ëª¨ë¦¬ ìµœì í™” (AI ëª¨ë¸ ì „ìš©)
                self._apply_ai_model_optimization()
                
                # ðŸ”¥ 7. ì‹¤ì œ AI ëª¨ë¸ ì›Œë°ì—… (í•„ìˆ˜)
                warmup_success = await self._warmup_real_ai_models()
                
                if not warmup_success:
                    error_msg = "ì‹¤ì œ AI ëª¨ë¸ ì›Œë°ì—… ì‹¤íŒ¨"
                    self.logger.error(f"âŒ {error_msg}")
                    if self.strict_mode:
                        raise RuntimeError(f"Strict Mode: {error_msg}")
                    return False
                
                self.is_initialized = True
                elapsed_time = time.time() - start_time
                
                self.logger.info(f"âœ… {self.step_name} ì™„ì „í•œ ì‹¤ì œ AI ì´ˆê¸°í™” ì„±ê³µ ({elapsed_time:.2f}ì´ˆ)")
                self.logger.info(f"ðŸ¤– ë¡œë“œëœ ì‹¤ì œ AI ëª¨ë¸: {list(self.pose_models.keys())}")
                self.logger.info(f"ðŸŽ¯ í™œì„± AI ëª¨ë¸: {self.active_model}")
                self.logger.info(f"ðŸš« í´ë°± ìƒíƒœ: ì™„ì „ ë¹„í™œì„±í™”")
                
                return True
                
        except Exception as e:
            self.logger.error(f"âŒ {self.step_name} ì™„ì „í•œ ì‹¤ì œ AI ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            if self.strict_mode:
                raise  # strict_modeì—ì„œëŠ” Exception ìž¬ë°œìƒ
            return False
    
    async def _register_step_requirements(self, requirements: Dict[str, Any]) -> bool:
        """Step ìš”êµ¬ì‚¬í•­ ModelLoaderì— ë“±ë¡"""
        try:
            if hasattr(self.model_interface, 'register_step_requirements'):
                await self.model_interface.register_step_requirements(
                    step_name=requirements["step_name"],
                    requirements=requirements
                )
                self.logger.info("âœ… ì‹¤ì œ AI Step ìš”êµ¬ì‚¬í•­ ë“±ë¡ ì„±ê³µ")
                return True
            else:
                self.logger.warning("âš ï¸ ModelLoaderì— register_step_requirements ë©”ì„œë“œ ì—†ìŒ")
                return False
                
        except Exception as e:
            self.logger.error(f"âŒ ì‹¤ì œ AI Step ìš”êµ¬ì‚¬í•­ ë“±ë¡ ì‹¤íŒ¨: {e}")
            return False
    
    async def _load_real_ai_models_only(self, requirements: Dict[str, Any]) -> bool:
        """ì‹¤ì œ AI ëª¨ë¸ë§Œ ë¡œë“œ - í´ë°± ì™„ì „ ê¸ˆì§€"""
        try:
            self.pose_models = {}
            self.active_model = None
            
            self.logger.info("ðŸ§  ì‹¤ì œ AI ëª¨ë¸ë§Œ ë¡œë“œ ì‹œìž‘ (í´ë°± ì™„ì „ ê¸ˆì§€)...")
            
            # 1. ìš°ì„ ìˆœìœ„ ëª¨ë¸ ë¡œë“œ ì‹œë„
            primary_model = requirements["model_name"]
            
            try:
                model = await self._load_single_real_ai_model(primary_model)
                if model and self._is_real_ai_model(model):
                    self.pose_models[primary_model] = model
                    self.active_model = primary_model
                    self.logger.info(f"âœ… ì£¼ ì‹¤ì œ AI ëª¨ë¸ ë¡œë“œ ì„±ê³µ: {primary_model}")
                else:
                    raise ValueError(f"ì£¼ ëª¨ë¸ì´ ì‹¤ì œ AI ëª¨ë¸ì´ ì•„ë‹˜: {primary_model}")
                    
            except Exception as e:
                self.logger.error(f"âŒ ì£¼ ì‹¤ì œ AI ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
                
                # ëŒ€ì²´ ì‹¤ì œ AI ëª¨ë¸ ì‹œë„ (í´ë°± ì•„ë‹˜ - ë‹¤ë¥¸ ì‹¤ì œ AI ëª¨ë¸)
                for alt_model in requirements["alternative_models"]:
                    try:
                        model = await self._load_single_real_ai_model(alt_model)
                        if model and self._is_real_ai_model(model):
                            self.pose_models[alt_model] = model
                            self.active_model = alt_model
                            self.logger.info(f"âœ… ëŒ€ì²´ ì‹¤ì œ AI ëª¨ë¸ ë¡œë“œ ì„±ê³µ: {alt_model}")
                            break
                    except Exception as alt_e:
                        self.logger.warning(f"âš ï¸ ëŒ€ì²´ ì‹¤ì œ AI ëª¨ë¸ ì‹¤íŒ¨: {alt_model} - {alt_e}")
                        continue
            
            # ì‹¤ì œ AI ëª¨ë¸ ë¡œë“œ ê²€ì¦
            if not self.pose_models:
                self.logger.error("âŒ ëª¨ë“  ì‹¤ì œ AI ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨ - ì‚¬ìš© ê°€ëŠ¥í•œ AI ëª¨ë¸ ì—†ìŒ")
                return False
            
            # ì‹¤ì œ AI ëª¨ë¸ ìµœì í™” ì„¤ì • ì ìš©
            self._apply_real_ai_model_optimization()
            
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ ì‹¤ì œ AI ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return False
    
    async def _load_single_real_ai_model(self, model_name: str) -> Optional[Any]:
        """ë‹¨ì¼ ì‹¤ì œ AI ëª¨ë¸ ë¡œë“œ"""
        try:
            if hasattr(self.model_interface, 'get_model'):
                model = self.model_interface.get_model(model_name)
                if model and self._is_real_ai_model(model):
                    self.logger.debug(f"âœ… ì‹¤ì œ AI ëª¨ë¸ ë¡œë“œ ì„±ê³µ: {model_name}")
                    return model
                else:
                    self.logger.warning(f"âš ï¸ ì‹¤ì œ AI ëª¨ë¸ ì•„ë‹˜ ë˜ëŠ” ì—†ìŒ: {model_name}")
                    return None
            else:
                self.logger.error("âŒ ModelInterfaceì— get_model ë©”ì„œë“œ ì—†ìŒ")
                return None
                
        except Exception as e:
            self.logger.error(f"âŒ ì‹¤ì œ AI ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨ {model_name}: {e}")
            return None
    
    def _is_real_ai_model(self, model: Any) -> bool:
        """ì‹¤ì œ AI ëª¨ë¸ì¸ì§€ ê²€ì¦"""
        try:
            # ì‹¤ì œ AI ëª¨ë¸ íŠ¹ì„± ê²€ì¦
            if model is None:
                return False
            
            # PyTorch ëª¨ë¸ ê²€ì¦
            if hasattr(model, '__call__') or hasattr(model, 'forward'):
                return True
            
            # YOLOv8 ëª¨ë¸ ê²€ì¦
            if hasattr(model, 'predict'):
                return True
            
            # ê¸°íƒ€ í˜¸ì¶œ ê°€ëŠ¥í•œ ëª¨ë¸
            if callable(model):
                return True
            
            # ë”ë¯¸/ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„° ê°ì§€ ë° ê±°ë¶€
            if isinstance(model, (dict, list, str, int, float)):
                self.logger.warning(f"âš ï¸ ë”ë¯¸ ë°ì´í„° ê°ì§€ - ì‹¤ì œ AI ëª¨ë¸ ì•„ë‹˜: {type(model)}")
                return False
            
            return False
            
        except Exception as e:
            self.logger.error(f"âŒ ì‹¤ì œ AI ëª¨ë¸ ê²€ì¦ ì‹¤íŒ¨: {e}")
            return False
    
    async def _validate_real_ai_models(self) -> bool:
        """ë¡œë“œëœ ì‹¤ì œ AI ëª¨ë¸ ì—„ê²© ê²€ì¦"""
        try:
            if not self.pose_models or not self.active_model:
                self.logger.error("âŒ ê²€ì¦í•  ì‹¤ì œ AI ëª¨ë¸ ì—†ìŒ")
                return False
            
            active_model = self.pose_models.get(self.active_model)
            if not active_model:
                self.logger.error(f"âŒ í™œì„± ì‹¤ì œ AI ëª¨ë¸ ì—†ìŒ: {self.active_model}")
                return False
            
            # ì‹¤ì œ AI ëª¨ë¸ ë™ìž‘ ê²€ì¦
            if not self._is_real_ai_model(active_model):
                self.logger.error(f"âŒ ìœ íš¨í•˜ì§€ ì•Šì€ ì‹¤ì œ AI ëª¨ë¸: {self.active_model}")
                return False
            
            # ì¶”ê°€ ì‹¤ì œ AI ëª¨ë¸ íŠ¹ì„± ê²€ì¦
            model_type = type(active_model).__name__
            self.logger.info(f"ðŸ” ì‹¤ì œ AI ëª¨ë¸ íƒ€ìž… ê²€ì¦: {model_type}")
            
            # ê¸ˆì§€ëœ íƒ€ìž… ì²´í¬ (ë”ë¯¸/ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„°)
            forbidden_types = ['dict', 'list', 'str', 'int', 'float', 'NoneType']
            if model_type in forbidden_types:
                self.logger.error(f"âŒ ê¸ˆì§€ëœ ëª¨ë¸ íƒ€ìž… (ë”ë¯¸ ë°ì´í„°): {model_type}")
                return False
            
            self.logger.info(f"âœ… ì‹¤ì œ AI ëª¨ë¸ ê²€ì¦ ì„±ê³µ: {self.active_model} ({model_type})")
            return True
                
        except Exception as e:
            self.logger.error(f"âŒ ì‹¤ì œ AI ëª¨ë¸ ê²€ì¦ ì‹¤íŒ¨: {e}")
            return False
    
    def _apply_ai_model_optimization(self):
        """ì‹¤ì œ AI ëª¨ë¸ ì „ìš© ë©”ëª¨ë¦¬ ìµœì í™”"""
        try:
            if TORCH_AVAILABLE:
                if self.device == "mps":
                    torch.mps.empty_cache()
                elif self.device == "cuda":
                    torch.cuda.empty_cache()
            
            # ê°€ë¹„ì§€ ì»¬ë ‰ì…˜
            gc.collect()
            
            self.logger.info("âœ… ì‹¤ì œ AI ëª¨ë¸ ë©”ëª¨ë¦¬ ìµœì í™” ì™„ë£Œ")
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ ì‹¤ì œ AI ëª¨ë¸ ë©”ëª¨ë¦¬ ìµœì í™” ì‹¤íŒ¨: {e}")
    
    def _apply_real_ai_model_optimization(self):
        """ì‹¤ì œ AI ëª¨ë¸ ìµœì í™” ì„¤ì • ì ìš©"""
        try:
            requirements = self._get_step_model_requirements()
            optimization_params = requirements["optimization_params"]
            
            # ë””ë°”ì´ìŠ¤ë³„ ìµœì í™”
            if self.device == "mps":
                optimization_params.update({
                    "enable_neural_engine": True,
                    "memory_pool_size": min(int(self.memory_gb * 0.25), 32),
                    "optimization_level": "maximum"
                })
            elif self.device == "cuda":
                optimization_params.update({
                    "enable_tensorrt": True,
                    "cuda_optimization": True
                })
            
            self.pose_optimization_params = optimization_params
            
            # í™œì„± ì‹¤ì œ AI ëª¨ë¸ë³„ íŠ¹í™” ì„¤ì •
            if self.active_model == 'pose_estimation_openpose':
                self.target_input_size = (368, 368)
                self.output_format = "keypoints_heatmap"
                self.num_keypoints = 18
            elif 'yolov8' in self.active_model or 'sk' in self.active_model:
                self.target_input_size = (640, 640)
                self.output_format = "keypoints_tensor"
                self.num_keypoints = 17  # COCO format
            else:
                self.target_input_size = (256, 256)
                self.output_format = "keypoints_simple"
                self.num_keypoints = 17
            
            self.logger.info(f"âœ… {self.active_model} ì‹¤ì œ AI ëª¨ë¸ ìµœì í™” ì„¤ì • ì™„ë£Œ")
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ ì‹¤ì œ AI ëª¨ë¸ ìµœì í™” ì„¤ì • ì‹¤íŒ¨: {e}")
    
    async def _warmup_real_ai_models(self) -> bool:
        """ì‹¤ì œ AI ëª¨ë¸ ì›Œë°ì—… (í•„ìˆ˜)"""
        try:
            if not self.active_model or self.active_model not in self.pose_models:
                self.logger.error("âŒ ì›Œë°ì—…í•  ì‹¤ì œ AI ëª¨ë¸ ì—†ìŒ")
                if self.strict_mode:
                    raise RuntimeError("Strict Mode: ì›Œë°ì—…í•  ì‹¤ì œ AI ëª¨ë¸ ì—†ìŒ")
                return False
            
            # ë”ë¯¸ ì´ë¯¸ì§€ë¡œ ì‹¤ì œ AI ëª¨ë¸ ì›Œë°ì—…
            dummy_image = np.zeros((256, 256, 3), dtype=np.uint8)
            dummy_image_pil = Image.fromarray(dummy_image)
            
            self.logger.info(f"ðŸ”¥ {self.active_model} ì‹¤ì œ AI ëª¨ë¸ ì›Œë°ì—… ì‹œìž‘")
            
            try:
                warmup_result = await self._process_with_real_ai_model(dummy_image_pil, warmup=True)
                if warmup_result and warmup_result.get('success', False):
                    self.logger.info(f"âœ… {self.active_model} ì‹¤ì œ AI ëª¨ë¸ ì›Œë°ì—… ì„±ê³µ")
                    return True
                else:
                    raise RuntimeError(f"ì‹¤ì œ AI ëª¨ë¸ ì›Œë°ì—… ê²°ê³¼ ì‹¤íŒ¨: {warmup_result}")
            except Exception as e:
                error_msg = f"ì‹¤ì œ AI ëª¨ë¸ ì›Œë°ì—… ì‹¤íŒ¨: {e}"
                self.logger.error(f"âŒ {error_msg}")
                if self.strict_mode:
                    raise RuntimeError(f"Strict Mode: {error_msg}")
                return False
                
        except Exception as e:
            self.logger.error(f"âŒ ì‹¤ì œ AI ëª¨ë¸ ì›Œë°ì—… ì‹¤íŒ¨: {e}")
            if self.strict_mode:
                raise
            return False
    
    async def process(
        self, 
        image: Union[np.ndarray, Image.Image, str],
        clothing_type: Optional[str] = None,
        **kwargs
    ) -> Dict[str, Any]:
        """
        ðŸ”¥ ì™„ì „í•œ ì‹¤ì œ AI í¬ì¦ˆ ì¶”ì • ì²˜ë¦¬ - í´ë°± ì™„ì „ ì œê±°
        
        Args:
            image: ìž…ë ¥ ì´ë¯¸ì§€
            clothing_type: ì˜ë¥˜ íƒ€ìž… (ì„ íƒì )
            **kwargs: ì¶”ê°€ ì„¤ì •
            
        Returns:
            Dict[str, Any]: ì‹¤ì œ AI í¬ì¦ˆ ì¶”ì • ê²°ê³¼
            
        Raises:
            RuntimeError: strict_mode=Trueì—ì„œ AI ì‹¤íŒ¨ ì‹œ
        """
        try:
            # ì´ˆê¸°í™” ê²€ì¦ (ì—„ê²©)
            if not self.is_initialized:
                if not await self.initialize():
                    error_msg = "ì‹¤ì œ AI ì´ˆê¸°í™” ì‹¤íŒ¨"
                    if self.strict_mode:
                        raise RuntimeError(f"Strict Mode: {error_msg}")
                    return self._create_error_result(error_msg)
            
            start_time = time.time()
            self.logger.info(f"ðŸ§  {self.step_name} ì™„ì „í•œ ì‹¤ì œ AI ì²˜ë¦¬ ì‹œìž‘")
            
            # ðŸ”¥ 1. ì´ë¯¸ì§€ ì „ì²˜ë¦¬ (ì—„ê²© ê²€ì¦)
            processed_image = self._preprocess_image_strict(image)
            if processed_image is None:
                error_msg = "ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì‹¤íŒ¨ - ìœ íš¨í•˜ì§€ ì•Šì€ ì´ë¯¸ì§€"
                if self.strict_mode:
                    raise ValueError(f"Strict Mode: {error_msg}")
                return self._create_error_result(error_msg)
            
            # ðŸ”¥ 2. ìºì‹œ í™•ì¸ (ì„ íƒì )
            cache_key = None
            if self.pose_config['cache_enabled']:
                cache_key = self._generate_cache_key(processed_image, clothing_type)
                if cache_key in self.prediction_cache:
                    self.logger.info("ðŸ“‹ ìºì‹œì—ì„œ ì‹¤ì œ AI ê²°ê³¼ ë°˜í™˜")
                    return self.prediction_cache[cache_key]
            
            # ðŸ”¥ 3. ì™„ì „í•œ ì‹¤ì œ AI ëª¨ë¸ë¡œë§Œ í¬ì¦ˆ ì¶”ì • (í´ë°± ê¸ˆì§€)
            pose_result = await self._process_with_real_ai_model(processed_image, clothing_type, **kwargs)
            
            if not pose_result or not pose_result.get('success', False):
                error_msg = f"ì‹¤ì œ AI í¬ì¦ˆ ì¶”ì • ì™„ì „ ì‹¤íŒ¨: {pose_result.get('error', 'Unknown AI Error')}"
                self.logger.error(f"âŒ {error_msg}")
                if self.strict_mode:
                    raise RuntimeError(f"Strict Mode: {error_msg}")
                return self._create_error_result(error_msg)
            
            # ðŸ”¥ 4. ì™„ì „í•œ ê²°ê³¼ í›„ì²˜ë¦¬ (ëª¨ë“  ë¶„ì„ í¬í•¨)
            final_result = self._postprocess_complete_result(pose_result, processed_image, start_time)
            
            # ðŸ”¥ 5. ìºì‹œ ì €ìž¥
            if self.pose_config['cache_enabled'] and cache_key:
                self._save_to_cache(cache_key, final_result)
            
            processing_time = time.time() - start_time
            self.logger.info(f"âœ… {self.step_name} ì™„ì „í•œ ì‹¤ì œ AI ì²˜ë¦¬ ì„±ê³µ ({processing_time:.2f}ì´ˆ)")
            self.logger.info(f"ðŸŽ¯ AI í‚¤í¬ì¸íŠ¸ ìˆ˜: {len(final_result.get('keypoints', []))}")
            self.logger.info(f"ðŸŽ–ï¸ AI ì‹ ë¢°ë„: {final_result.get('pose_analysis', {}).get('ai_confidence', 0):.3f}")
            self.logger.info(f"ðŸ’Ž í’ˆì§ˆ ì ìˆ˜: {final_result.get('pose_analysis', {}).get('quality_score', 0):.3f}")
            
            return final_result
            
        except Exception as e:
            self.logger.error(f"âŒ {self.step_name} ì™„ì „í•œ ì‹¤ì œ AI ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            if self.strict_mode:
                raise  # strict_modeì—ì„œëŠ” Exception ìž¬ë°œìƒ
            return self._create_error_result(str(e))
    
    async def _process_with_real_ai_model(
        self, 
        image: Image.Image, 
        clothing_type: Optional[str] = None,
        warmup: bool = False,
        **kwargs
    ) -> Dict[str, Any]:
        """ì™„ì „í•œ ì‹¤ì œ AI ëª¨ë¸ì„ í†µí•œ í¬ì¦ˆ ì¶”ì • ì²˜ë¦¬ - í´ë°± ì™„ì „ ê¸ˆì§€"""
        try:
            if not self.active_model or self.active_model not in self.pose_models:
                error_msg = "í™œì„± ì‹¤ì œ AI ëª¨ë¸ ì—†ìŒ"
                self.logger.error(f"âŒ {error_msg}")
                if self.strict_mode:
                    raise RuntimeError(f"Strict Mode: {error_msg}")
                return {'success': False, 'error': error_msg}
            
            model = self.pose_models[self.active_model]
            
            # ì‹¤ì œ AI ëª¨ë¸ ìž¬ê²€ì¦
            if not self._is_real_ai_model(model):
                error_msg = f"ë¡œë“œëœ ëª¨ë¸ì´ ì‹¤ì œ AI ëª¨ë¸ì´ ì•„ë‹˜: {type(model)}"
                self.logger.error(f"âŒ {error_msg}")
                if self.strict_mode:
                    raise RuntimeError(f"Strict Mode: {error_msg}")
                return {'success': False, 'error': error_msg}
            
            self.logger.info(f"ðŸ§  {self.active_model} ì‹¤ì œ AI ëª¨ë¸ë¡œ ì¶”ë¡  ì‹œìž‘")
            
            # ì´ë¯¸ì§€ë¥¼ ì‹¤ì œ AI ëª¨ë¸ ìž…ë ¥ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
            model_input = self._prepare_real_ai_model_input(image)
            
            if model_input is None:
                error_msg = "ì‹¤ì œ AI ëª¨ë¸ ìž…ë ¥ ì¤€ë¹„ ì‹¤íŒ¨"
                if self.strict_mode:
                    raise ValueError(f"Strict Mode: {error_msg}")
                return {'success': False, 'error': error_msg}
            
            # ðŸ”¥ ì™„ì „í•œ ì‹¤ì œ AI ëª¨ë¸ ì¶”ë¡  ì‹¤í–‰ (í´ë°± ê¸ˆì§€)
            try:
                if hasattr(model, '__call__'):
                    # ì§ì ‘ í˜¸ì¶œ ê°€ëŠ¥í•œ ì‹¤ì œ AI ëª¨ë¸
                    model_output = await self._safe_real_ai_model_call(model, model_input)
                elif hasattr(model, 'predict'):
                    # predict ë©”ì„œë“œê°€ ìžˆëŠ” ì‹¤ì œ AI ëª¨ë¸
                    model_output = await self._safe_real_ai_model_predict(model, model_input)
                elif hasattr(model, 'forward'):
                    # PyTorch ì‹¤ì œ AI ëª¨ë¸
                    model_output = await self._safe_real_ai_model_forward(model, model_input)
                else:
                    error_msg = f"ì‹¤ì œ AI ëª¨ë¸ í˜¸ì¶œ ë°©ë²• ì—†ìŒ: {type(model)}"
                    if self.strict_mode:
                        raise ValueError(f"Strict Mode: {error_msg}")
                    return {'success': False, 'error': error_msg}
                
            except Exception as e:
                error_msg = f"ì‹¤ì œ AI ëª¨ë¸ ì¶”ë¡  ì‹¤íŒ¨: {e}"
                self.logger.error(f"âŒ {error_msg}")
                if self.strict_mode:
                    raise RuntimeError(f"Strict Mode: {error_msg}")
                return {'success': False, 'error': error_msg}
            
            # ì›Œë°ì—… ëª¨ë“œì¸ ê²½ìš° ê°„ë‹¨í•œ ì„±ê³µ ê²°ê³¼ ë°˜í™˜
            if warmup:
                return {"success": True, "warmup": True, "model_used": self.active_model}
            
            # ðŸ”¥ ì‹¤ì œ AI ëª¨ë¸ ì¶œë ¥ í•´ì„ (ì™„ì „í•œ ë¶„ì„)
            pose_result = self._interpret_real_ai_model_output(model_output, image.size, self.active_model)
            
            if not pose_result.get('success', False):
                error_msg = "ì‹¤ì œ AI ëª¨ë¸ ì¶œë ¥ í•´ì„ ì‹¤íŒ¨"
                if self.strict_mode:
                    raise ValueError(f"Strict Mode: {error_msg}")
                return {'success': False, 'error': error_msg}
            
            self.logger.info(f"âœ… {self.active_model} ì‹¤ì œ AI ì¶”ë¡  ì™„ì „ ì„±ê³µ")
            return pose_result
            
        except Exception as e:
            self.logger.error(f"âŒ ì‹¤ì œ AI ëª¨ë¸ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            if self.strict_mode:
                raise
            return {'success': False, 'error': str(e)}
    
    def _prepare_real_ai_model_input(self, image: Image.Image) -> Optional[Any]:
        """ì‹¤ì œ AI ëª¨ë¸ ìž…ë ¥ ì¤€ë¹„"""
        try:
            # ì´ë¯¸ì§€ë¥¼ numpy ë°°ì—´ë¡œ ë³€í™˜
            image_np = np.array(image)
            
            # ì‹¤ì œ AI ëª¨ë¸ë³„ ìž…ë ¥ í¬ê¸° ì¡°ì •
            if hasattr(self, 'target_input_size'):
                target_size = self.target_input_size
                image_resized = cv2.resize(image_np, target_size)
            else:
                image_resized = image_np
            
            # PyTorch ì‹¤ì œ AI ëª¨ë¸ì¸ ê²½ìš° í…ì„œë¡œ ë³€í™˜
            if TORCH_AVAILABLE and hasattr(self, 'active_model'):
                if 'openpose' in self.active_model or 'yolo' in self.active_model or 'sk' in self.active_model:
                    # ì •ê·œí™” ë° í…ì„œ ë³€í™˜
                    image_tensor = torch.from_numpy(image_resized).float()
                    if len(image_tensor.shape) == 3:
                        image_tensor = image_tensor.permute(2, 0, 1).unsqueeze(0)  # BHWC -> BCHW
                    image_tensor = image_tensor / 255.0  # ì •ê·œí™”
                    image_tensor = image_tensor.to(self.device)
                    return image_tensor
            
            return image_resized
            
        except Exception as e:
            self.logger.error(f"âŒ ì‹¤ì œ AI ëª¨ë¸ ìž…ë ¥ ì¤€ë¹„ ì‹¤íŒ¨: {e}")
            return None
    
    async def _safe_real_ai_model_call(self, model: Any, input_data: Any) -> Any:
        """ì•ˆì „í•œ ì‹¤ì œ AI ëª¨ë¸ í˜¸ì¶œ"""
        try:
            if asyncio.iscoroutinefunction(model.__call__):
                return await model(input_data)
            else:
                return model(input_data)
        except Exception as e:
            self.logger.error(f"âŒ ì‹¤ì œ AI ëª¨ë¸ __call__ ì‹¤íŒ¨: {e}")
            raise
    
    async def _safe_real_ai_model_predict(self, model: Any, input_data: Any) -> Any:
        """ì•ˆì „í•œ ì‹¤ì œ AI ëª¨ë¸ predict í˜¸ì¶œ"""
        try:
            if asyncio.iscoroutinefunction(model.predict):
                return await model.predict(input_data)
            else:
                return model.predict(input_data)
        except Exception as e:
            self.logger.error(f"âŒ ì‹¤ì œ AI ëª¨ë¸ predict ì‹¤íŒ¨: {e}")
            raise
    
    async def _safe_real_ai_model_forward(self, model: Any, input_data: Any) -> Any:
        """ì•ˆì „í•œ ì‹¤ì œ AI ëª¨ë¸ forward í˜¸ì¶œ"""
        try:
            with torch.no_grad():
                if asyncio.iscoroutinefunction(model.forward):
                    return await model.forward(input_data)
                else:
                    return model.forward(input_data)
        except Exception as e:
            self.logger.error(f"âŒ ì‹¤ì œ AI ëª¨ë¸ forward ì‹¤íŒ¨: {e}")
            raise
    
    def _interpret_real_ai_model_output(self, model_output: Any, image_size: Tuple[int, int], model_name: str) -> Dict[str, Any]:
        """ì‹¤ì œ AI ëª¨ë¸ ì¶œë ¥ í•´ì„"""
        try:
            if 'openpose' in model_name:
                return self._interpret_openpose_output(model_output, image_size)
            elif 'yolo' in model_name or 'sk' in model_name:
                return self._interpret_yolo_output(model_output, image_size)
            else:
                return self._interpret_generic_ai_output(model_output, image_size)
                
        except Exception as e:
            self.logger.error(f"âŒ ì‹¤ì œ AI ëª¨ë¸ ì¶œë ¥ í•´ì„ ì‹¤íŒ¨: {e}")
            return {'success': False, 'error': str(e)}
    
    def _interpret_openpose_output(self, output: Any, image_size: Tuple[int, int]) -> Dict[str, Any]:
        """OpenPose ì‹¤ì œ AI ì¶œë ¥ í•´ì„"""
        try:
            keypoints = []
            confidence_scores = []
            
            if TORCH_AVAILABLE and torch.is_tensor(output):
                output_np = output.cpu().numpy()
                
                # ížˆíŠ¸ë§µì—ì„œ í‚¤í¬ì¸íŠ¸ ì¶”ì¶œ
                if len(output_np.shape) == 4:  # [B, C, H, W]
                    output_np = output_np[0]  # ì²« ë²ˆì§¸ ë°°ì¹˜
                
                for i in range(min(output_np.shape[0], 18)):  # 18ê°œ í‚¤í¬ì¸íŠ¸ë§Œ
                    heatmap = output_np[i]
                    y, x = np.unravel_index(np.argmax(heatmap), heatmap.shape)
                    confidence = float(heatmap[y, x])
                    
                    # ì´ë¯¸ì§€ í¬ê¸°ë¡œ ìŠ¤ì¼€ì¼ë§
                    x_scaled = x * image_size[0] / heatmap.shape[1]
                    y_scaled = y * image_size[1] / heatmap.shape[0]
                    
                    keypoints.append([float(x_scaled), float(y_scaled), confidence])
                    confidence_scores.append(confidence)
            
            return {
                'keypoints': keypoints,
                'confidence_scores': confidence_scores,
                'model_used': 'openpose_real_ai',
                'success': len(keypoints) > 0,
                'ai_model_type': 'openpose'
            }
            
        except Exception as e:
            self.logger.error(f"âŒ OpenPose ì‹¤ì œ AI ì¶œë ¥ í•´ì„ ì‹¤íŒ¨: {e}")
            return {'success': False, 'error': str(e)}
    
    def _interpret_yolo_output(self, results: Any, image_size: Tuple[int, int]) -> Dict[str, Any]:
        """YOLOv8 í¬ì¦ˆ ì‹¤ì œ AI ì¶œë ¥ í•´ì„"""
        try:
            keypoints = []
            confidence_scores = []
            
            if hasattr(results, 'keypoints') and results.keypoints is not None:
                for result in results:
                    if hasattr(result, 'keypoints') and result.keypoints is not None:
                        kps = result.keypoints.data[0]  # ì²« ë²ˆì§¸ ì‚¬ëžŒ
                        for kp in kps:
                            x, y, conf = float(kp[0]), float(kp[1]), float(kp[2])
                            keypoints.append([x, y, conf])
                            confidence_scores.append(conf)
                        break
            
            # COCO 17ì„ OpenPose 18ë¡œ ë³€í™˜
            if len(keypoints) == 17:
                keypoints = self._convert_coco_to_openpose(keypoints, image_size)
                confidence_scores = [kp[2] for kp in keypoints]
            
            return {
                'keypoints': keypoints,
                'confidence_scores': confidence_scores,
                'model_used': 'yolov8_real_ai',
                'success': len(keypoints) > 0,
                'ai_model_type': 'yolov8'
            }
            
        except Exception as e:
            self.logger.error(f"âŒ YOLOv8 ì‹¤ì œ AI ì¶œë ¥ í•´ì„ ì‹¤íŒ¨: {e}")
            return {'success': False, 'error': str(e)}
    
    def _interpret_generic_ai_output(self, output: Any, image_size: Tuple[int, int]) -> Dict[str, Any]:
        """ì¼ë°˜ì ì¸ ì‹¤ì œ AI ëª¨ë¸ ì¶œë ¥ í•´ì„"""
        try:
            keypoints = []
            confidence_scores = []
            
            # ë‹¤ì–‘í•œ ì‹¤ì œ AI ì¶œë ¥ í˜•ì‹ì— ëŒ€ì‘
            if isinstance(output, (list, tuple)):
                # ë¦¬ìŠ¤íŠ¸/íŠœí”Œ í˜•íƒœì˜ í‚¤í¬ì¸íŠ¸
                for item in output:
                    if len(item) >= 3:
                        keypoints.append([float(item[0]), float(item[1]), float(item[2])])
                        confidence_scores.append(float(item[2]))
            elif isinstance(output, np.ndarray):
                # NumPy ë°°ì—´
                if len(output.shape) == 2 and output.shape[1] >= 3:
                    for i in range(min(output.shape[0], 18)):
                        keypoints.append([float(output[i, 0]), float(output[i, 1]), float(output[i, 2])])
                        confidence_scores.append(float(output[i, 2]))
            elif TORCH_AVAILABLE and torch.is_tensor(output):
                # PyTorch í…ì„œ
                output_np = output.cpu().numpy()
                return self._interpret_generic_ai_output(output_np, image_size)
            
            return {
                'keypoints': keypoints,
                'confidence_scores': confidence_scores,
                'model_used': 'generic_real_ai',
                'success': len(keypoints) > 0,
                'ai_model_type': 'generic'
            }
            
        except Exception as e:
            self.logger.error(f"âŒ ì¼ë°˜ ì‹¤ì œ AI ì¶œë ¥ í•´ì„ ì‹¤íŒ¨: {e}")
            return {'success': False, 'error': str(e)}
    
    def _convert_coco_to_openpose(self, coco_keypoints: List[List[float]], image_size: Tuple[int, int]) -> List[List[float]]:
        """COCO 17ì„ OpenPose 18ë¡œ ë³€í™˜"""
        try:
            # COCO 17 -> OpenPose 18 ë§¤í•‘
            coco_to_op_mapping = {
                0: 0,   # nose
                1: 16,  # left_eye -> left_eye
                2: 15,  # right_eye -> right_eye
                3: 18,  # left_ear -> left_ear
                4: 17,  # right_ear -> right_ear
                5: 5,   # left_shoulder -> left_shoulder
                6: 2,   # right_shoulder -> right_shoulder
                7: 6,   # left_elbow -> left_elbow
                8: 3,   # right_elbow -> right_elbow
                9: 7,   # left_wrist -> left_wrist
                10: 4,  # right_wrist -> right_wrist
                11: 12, # left_hip -> left_hip
                12: 9,  # right_hip -> right_hip
                13: 13, # left_knee -> left_knee
                14: 10, # right_knee -> right_knee
                15: 14, # left_ankle -> left_ankle
                16: 11  # right_ankle -> right_ankle
            }
            
            # OpenPose 18 í‚¤í¬ì¸íŠ¸ ì´ˆê¸°í™”
            openpose_18 = [[0.0, 0.0, 0.0] for _ in range(18)]
            
            # COCOì—ì„œ OpenPoseë¡œ ë³€í™˜
            for coco_idx, op_idx in coco_to_op_mapping.items():
                if coco_idx < len(coco_keypoints) and op_idx < 18:
                    openpose_18[op_idx] = coco_keypoints[coco_idx]
            
            # neck í‚¤í¬ì¸íŠ¸ ì¶”ì •
            left_shoulder = openpose_18[5]
            right_shoulder = openpose_18[2]
            if left_shoulder[2] > 0.3 and right_shoulder[2] > 0.3:
                neck_x = (left_shoulder[0] + right_shoulder[0]) / 2
                neck_y = (left_shoulder[1] + right_shoulder[1]) / 2
                neck_conf = min(left_shoulder[2], right_shoulder[2])
                openpose_18[1] = [neck_x, neck_y, neck_conf]
            
            # mid_hip í‚¤í¬ì¸íŠ¸ ì¶”ì •
            left_hip = openpose_18[12]
            right_hip = openpose_18[9]
            if left_hip[2] > 0.3 and right_hip[2] > 0.3:
                mid_hip_x = (left_hip[0] + right_hip[0]) / 2
                mid_hip_y = (left_hip[1] + right_hip[1]) / 2
                mid_hip_conf = min(left_hip[2], right_hip[2])
                openpose_18[8] = [mid_hip_x, mid_hip_y, mid_hip_conf]
            
            return openpose_18
            
        except Exception as e:
            self.logger.error(f"âŒ COCO to OpenPose ë³€í™˜ ì‹¤íŒ¨: {e}")
            return [[0.0, 0.0, 0.0] for _ in range(18)]
    
    def _preprocess_image_strict(self, image: Union[np.ndarray, Image.Image, str]) -> Optional[Image.Image]:
        """ì—„ê²©í•œ ì´ë¯¸ì§€ ì „ì²˜ë¦¬"""
        try:
            if isinstance(image, str):
                # íŒŒì¼ ê²½ë¡œì¸ ê²½ìš°
                if os.path.exists(image):
                    image = Image.open(image)
                else:
                    # Base64 ì¸ì½”ë”©ëœ ì´ë¯¸ì§€ì¸ ê²½ìš°
                    try:
                        image_data = base64.b64decode(image)
                        image = Image.open(io.BytesIO(image_data))
                    except Exception as e:
                        self.logger.error(f"âŒ Base64 ì´ë¯¸ì§€ ë””ì½”ë”© ì‹¤íŒ¨: {e}")
                        return None
            elif isinstance(image, np.ndarray):
                if image.size == 0:
                    self.logger.error("âŒ ë¹ˆ numpy ë°°ì—´")
                    return None
                image = Image.fromarray(image)
            elif not isinstance(image, Image.Image):
                self.logger.error(f"âŒ ì§€ì›í•˜ì§€ ì•ŠëŠ” ì´ë¯¸ì§€ íƒ€ìž…: {type(image)}")
                return None
            
            # RGB ë³€í™˜ (í•„ìˆ˜)
            if image.mode != 'RGB':
                image = image.convert('RGB')
            
            # ì´ë¯¸ì§€ í¬ê¸° ê²€ì¦
            if image.size[0] < 64 or image.size[1] < 64:
                self.logger.error(f"âŒ ì´ë¯¸ì§€ê°€ ë„ˆë¬´ ìž‘ìŒ: {image.size}")
                return None
            
            # í¬ê¸° ì¡°ì • (ì„±ëŠ¥ ìµœì í™”)
            max_size = 1024 if self.is_m3_max else 512
            if max(image.size) > max_size:
                ratio = max_size / max(image.size)
                new_size = (int(image.size[0] * ratio), int(image.size[1] * ratio))
                image = image.resize(new_size, Image.Resampling.LANCZOS)
            
            return image
            
        except Exception as e:
            self.logger.error(f"âŒ ì—„ê²©í•œ ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return None
    
    def _generate_cache_key(self, image: Image.Image, clothing_type: Optional[str]) -> str:
        """ìºì‹œ í‚¤ ìƒì„±"""
        try:
            # ì´ë¯¸ì§€ í•´ì‹œ
            image_bytes = io.BytesIO()
            image.save(image_bytes, format='JPEG', quality=50)
            image_hash = hashlib.md5(image_bytes.getvalue()).hexdigest()[:16]
            
            # ì„¤ì • í•´ì‹œ
            config_str = f"{clothing_type}_{self.active_model}_{self.pose_config['confidence_threshold']}"
            config_hash = hashlib.md5(config_str.encode()).hexdigest()[:8]
            
            return f"real_ai_pose_{image_hash}_{config_hash}"
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ ìºì‹œ í‚¤ ìƒì„± ì‹¤íŒ¨: {e}")
            return f"real_ai_pose_{int(time.time())}"
    
    def _postprocess_complete_result(self, pose_result: Dict[str, Any], image: Image.Image, start_time: float) -> Dict[str, Any]:
        """ì™„ì „í•œ ê²°ê³¼ í›„ì²˜ë¦¬ - ëª¨ë“  ë¶„ì„ í¬í•¨"""
        try:
            processing_time = time.time() - start_time
            
            # PoseMetrics ìƒì„±
            pose_metrics = PoseMetrics(
                keypoints=pose_result.get('keypoints', []),
                confidence_scores=pose_result.get('confidence_scores', []),
                model_used=pose_result.get('model_used', 'unknown'),
                processing_time=processing_time,
                image_resolution=image.size
            )
            
            # ðŸ”¥ ì™„ì „í•œ í¬ì¦ˆ ë¶„ì„ (ëª¨ë“  ë©”ì„œë“œ í¬í•¨)
            complete_pose_analysis = self._analyze_pose_quality_complete(pose_metrics)
            
            # ì‹œê°í™” ìƒì„±
            visualization = None
            if self.pose_config['visualization_enabled']:
                visualization = self._create_advanced_pose_visualization(image, pose_metrics)
            
            # ðŸ”¥ ìµœì¢… ê²°ê³¼ êµ¬ì„± (ì™„ì „í•œ ë°ì´í„°)
            result = {
                'success': pose_result.get('success', False),
                'keypoints': pose_metrics.keypoints,
                'confidence_scores': pose_metrics.confidence_scores,
                'pose_analysis': complete_pose_analysis,
                'visualization': visualization,
                'processing_time': processing_time,
                'model_used': pose_metrics.model_used,
                'image_resolution': pose_metrics.image_resolution,
                'step_info': {
                    'step_name': self.step_name,
                    'step_number': self.step_number,
                    'optimization_level': self.optimization_level,
                    'strict_mode': self.strict_mode,
                    'real_ai_model_name': self.active_model,
                    'fallback_disabled': True,
                    'ai_model_type': pose_result.get('ai_model_type', 'unknown')
                }
            }
            
            return result
            
        except Exception as e:
            self.logger.error(f"âŒ ì™„ì „í•œ ê²°ê³¼ í›„ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            if self.strict_mode:
                raise
            return self._create_error_result(str(e))
    
    def _analyze_pose_quality_complete(self, pose_metrics: PoseMetrics) -> Dict[str, Any]:
        """ì™„ì „í•œ í¬ì¦ˆ í’ˆì§ˆ ë¶„ì„ - ëª¨ë“  ë¶„ì„ ë©”ì„œë“œ í¬í•¨"""
        try:
            if not pose_metrics.keypoints:
                return {
                    'suitable_for_fitting': False,
                    'issues': ['ì‹¤ì œ AI ëª¨ë¸ì—ì„œ í¬ì¦ˆë¥¼ ê²€ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤'],
                    'recommendations': ['ë” ì„ ëª…í•œ ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í•˜ê±°ë‚˜ í¬ì¦ˆë¥¼ ëª…í™•ížˆ í•´ì£¼ì„¸ìš”'],
                    'quality_score': 0.0,
                    'ai_confidence': 0.0,
                    'real_ai_analysis': True
                }
            
            # ðŸ”¥ ì‹ ì²´ ë¶€ìœ„ë³„ ì ìˆ˜ ê³„ì‚°
            head_score = self._calculate_head_score(pose_metrics.keypoints)
            torso_score = self._calculate_torso_score(pose_metrics.keypoints)
            arms_score = self._calculate_arms_score(pose_metrics.keypoints)
            legs_score = self._calculate_legs_score(pose_metrics.keypoints)
            
            # ðŸ”¥ ì¶”ê°€ ê³ ê¸‰ ë¶„ì„ ë©”ì„œë“œë“¤
            pose_angles = self._calculate_pose_angles(pose_metrics.keypoints)
            body_proportions = self._calculate_body_proportions(pose_metrics.keypoints)
            symmetry_score = self._calculate_symmetry_score(pose_metrics.keypoints)
            visibility_score = self._calculate_visibility_score(pose_metrics.keypoints)
            major_keypoints_rate = self._calculate_major_keypoints_rate(pose_metrics.keypoints)
            
            # AI ì‹ ë¢°ë„ ê³„ì‚°
            ai_confidence = np.mean(pose_metrics.confidence_scores) if pose_metrics.confidence_scores else 0.0
            
            # ì „ì²´ ì ìˆ˜ (AI ì‹ ë¢°ë„ ë°˜ì˜ + ê³ ê¸‰ ë¶„ì„)
            base_score = (head_score * 0.2 + torso_score * 0.3 + 
                         arms_score * 0.25 + legs_score * 0.25)
            
            advanced_score = (symmetry_score * 0.2 + visibility_score * 0.3 + 
                            major_keypoints_rate * 0.5)
            
            overall_score = (base_score * 0.7 + advanced_score * 0.3) * ai_confidence
            
            # ì—„ê²©í•œ ì í•©ì„± íŒë‹¨ (AI ê¸°ë°˜ì´ë¯€ë¡œ ë” ë†’ì€ ê¸°ì¤€)
            min_score = 0.75 if self.strict_mode else 0.65
            min_confidence = 0.7 if self.strict_mode else 0.6
            suitable_for_fitting = (overall_score >= min_score and 
                                  ai_confidence >= min_confidence and
                                  major_keypoints_rate >= 0.6)
            
            # ì´ìŠˆ ë° ê¶Œìž¥ì‚¬í•­
            issues = []
            recommendations = []
            
            if ai_confidence < min_confidence:
                issues.append(f'ì‹¤ì œ AI ëª¨ë¸ì˜ ì‹ ë¢°ë„ê°€ ë‚®ìŠµë‹ˆë‹¤ ({ai_confidence:.2f} < {min_confidence})')
                recommendations.append('ì¡°ëª…ì´ ì¢‹ì€ í™˜ê²½ì—ì„œ ë‹¤ì‹œ ì´¬ì˜í•´ ì£¼ì„¸ìš”')
            
            if symmetry_score < 0.5:
                issues.append('ì‹ ì²´ ëŒ€ì¹­ì„±ì´ ë¶€ì¡±í•©ë‹ˆë‹¤')
                recommendations.append('ì •ë©´ì„ í–¥í•´ ëŒ€ì¹­ì ì¸ ìžì„¸ë¡œ ì´¬ì˜í•´ ì£¼ì„¸ìš”')
            
            if visibility_score < 0.6:
                issues.append('ì£¼ìš” í‚¤í¬ì¸íŠ¸ ê°€ì‹œì„±ì´ ë‚®ìŠµë‹ˆë‹¤')
                recommendations.append('ì „ì‹ ì´ ëª…í™•ížˆ ë³´ì´ë„ë¡ ì´¬ì˜í•´ ì£¼ì„¸ìš”')
            
            if head_score < 0.5:
                issues.append('ì–¼êµ´ ì˜ì—­ ê²€ì¶œì´ ë¶ˆë¶„ëª…í•©ë‹ˆë‹¤')
                recommendations.append('ì–¼êµ´ì´ ì •ë©´ì„ í–¥í•˜ë„ë¡ ì´¬ì˜í•´ ì£¼ì„¸ìš”')
            
            if torso_score < 0.5:
                issues.append('ìƒì²´ ì˜ì—­ì´ ë¶ˆë¶„ëª…í•©ë‹ˆë‹¤')
                recommendations.append('ìƒì²´ ì „ì²´ê°€ ë³´ì´ë„ë¡ ì´¬ì˜í•´ ì£¼ì„¸ìš”')
            
            if arms_score < 0.5:
                issues.append('íŒ”ì˜ ìœ„ì¹˜ê°€ ë¶€ì ì ˆí•©ë‹ˆë‹¤')
                recommendations.append('íŒ”ì„ ë²Œë¦¬ê±°ë‚˜ ìžì—°ìŠ¤ëŸ½ê²Œ ë‚´ë ¤ì£¼ì„¸ìš”')
            
            if legs_score < 0.5:
                issues.append('ë‹¤ë¦¬ê°€ ê°€ë ¤ì ¸ ìžˆìŠµë‹ˆë‹¤')
                recommendations.append('ì „ì‹ ì´ ë³´ì´ë„ë¡ ì´¬ì˜í•´ ì£¼ì„¸ìš”')
            
            # í¬ì¦ˆ íƒ€ìž… ê²°ì •
            pose_type = self._determine_pose_type(pose_metrics.keypoints, pose_angles)
            
            # í’ˆì§ˆ ë“±ê¸‰ ê²°ì •
            if overall_score >= 0.9:
                quality_grade = PoseQuality.EXCELLENT
            elif overall_score >= 0.75:
                quality_grade = PoseQuality.GOOD
            elif overall_score >= 0.6:
                quality_grade = PoseQuality.ACCEPTABLE
            elif overall_score >= 0.4:
                quality_grade = PoseQuality.POOR
            else:
                quality_grade = PoseQuality.VERY_POOR
            
            return {
                'suitable_for_fitting': suitable_for_fitting,
                'issues': issues,
                'recommendations': recommendations,
                'quality_score': overall_score,
                'quality_grade': quality_grade.value,
                'pose_type': pose_type.value,
                'ai_confidence': ai_confidence,
                'detailed_scores': {
                    'head': head_score,
                    'torso': torso_score,
                    'arms': arms_score,
                    'legs': legs_score,
                    'symmetry': symmetry_score,
                    'visibility': visibility_score,
                    'major_keypoints_rate': major_keypoints_rate
                },
                'pose_angles': pose_angles,
                'body_proportions': body_proportions,
                'model_performance': {
                    'model_name': pose_metrics.model_used,
                    'keypoints_detected': len([kp for kp in pose_metrics.keypoints if len(kp) > 2 and kp[2] > self.pose_config['confidence_threshold']]),
                    'avg_confidence': ai_confidence,
                    'processing_time': pose_metrics.processing_time,
                    'real_ai_model': True
                },
                'real_ai_analysis': True,
                'strict_mode': self.strict_mode
            }
            
        except Exception as e:
            self.logger.error(f"âŒ ì™„ì „í•œ í¬ì¦ˆ í’ˆì§ˆ ë¶„ì„ ì‹¤íŒ¨: {e}")
            if self.strict_mode:
                raise
            return {
                'suitable_for_fitting': False,
                'issues': ['ì™„ì „í•œ AI ë¶„ì„ ì‹¤íŒ¨'],
                'recommendations': ['ì‹¤ì œ AI ëª¨ë¸ ìƒíƒœë¥¼ í™•ì¸í•˜ê±°ë‚˜ ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”'],
                'quality_score': 0.0,
                'ai_confidence': 0.0,
                'real_ai_analysis': True
            }
    
    # =================================================================
    # ðŸ”¥ ì™„ì „í•œ ë¶„ì„ ë©”ì„œë“œë“¤ (paste.txtì—ì„œ ê°€ì ¸ì˜¨ ëª¨ë“  ê¸°ëŠ¥)
    # =================================================================
    
    def _calculate_head_score(self, keypoints: List[List[float]]) -> float:
        """ë¨¸ë¦¬ ë¶€ìœ„ ì ìˆ˜ ê³„ì‚°"""
        try:
            if len(keypoints) < 19:
                return 0.0
            
            head_indices = [0, 15, 16, 17, 18]  # nose, eyes, ears
            visible_count = sum(1 for idx in head_indices 
                              if idx < len(keypoints) and 
                              len(keypoints[idx]) > 2 and 
                              keypoints[idx][2] > self.pose_config['confidence_threshold'])
            
            return min(visible_count / 3.0, 1.0)
            
        except Exception:
            return 0.0
    
    def _calculate_torso_score(self, keypoints: List[List[float]]) -> float:
        """ìƒì²´ ì ìˆ˜ ê³„ì‚°"""
        try:
            if len(keypoints) < 19:
                return 0.0
            
            torso_indices = [1, 2, 5, 8, 9, 12]  # neck, shoulders, hips
            visible_count = sum(1 for idx in torso_indices 
                              if idx < len(keypoints) and 
                              len(keypoints[idx]) > 2 and 
                              keypoints[idx][2] > self.pose_config['confidence_threshold'])
            
            return min(visible_count / len(torso_indices), 1.0)
            
        except Exception:
            return 0.0
    
    def _calculate_arms_score(self, keypoints: List[List[float]]) -> float:
        """íŒ” ì ìˆ˜ ê³„ì‚°"""
        try:
            if len(keypoints) < 19:
                return 0.0
            
            arm_indices = [2, 3, 4, 5, 6, 7]  # shoulders, elbows, wrists
            visible_count = sum(1 for idx in arm_indices 
                              if idx < len(keypoints) and 
                              len(keypoints[idx]) > 2 and 
                              keypoints[idx][2] > self.pose_config['confidence_threshold'])
            
            return min(visible_count / len(arm_indices), 1.0)
            
        except Exception:
            return 0.0
    
    def _calculate_legs_score(self, keypoints: List[List[float]]) -> float:
        """ë‹¤ë¦¬ ì ìˆ˜ ê³„ì‚°"""
        try:
            if len(keypoints) < 19:
                return 0.0
            
            leg_indices = [9, 10, 11, 12, 13, 14]  # hips, knees, ankles
            visible_count = sum(1 for idx in leg_indices 
                              if idx < len(keypoints) and 
                              len(keypoints[idx]) > 2 and 
                              keypoints[idx][2] > self.pose_config['confidence_threshold'])
            
            return min(visible_count / len(leg_indices), 1.0)
            
        except Exception:
            return 0.0
    
    def _calculate_pose_angles(self, keypoints_18: List[List[float]]) -> Dict[str, float]:
        """í¬ì¦ˆ ê°ë„ ê³„ì‚° (ê´€ì ˆ ê°ë„)"""
        try:
            angles = {}
            confidence_threshold = self.pose_config['confidence_threshold']
            
            def calculate_angle(p1, p2, p3):
                """ì„¸ ì ìœ¼ë¡œ ê°ë„ ê³„ì‚°"""
                try:
                    if all(len(p) >= 3 and p[2] > confidence_threshold for p in [p1, p2, p3]):
                        v1 = np.array([p1[0] - p2[0], p1[1] - p2[1]])
                        v2 = np.array([p3[0] - p2[0], p3[1] - p2[1]])
                        
                        cos_angle = np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))
                        cos_angle = np.clip(cos_angle, -1.0, 1.0)
                        return float(np.degrees(np.arccos(cos_angle)))
                    return 0.0
                except Exception:
                    return 0.0
            
            if len(keypoints_18) >= 18:
                # íŒ” ê°ë„
                angles['right_elbow'] = calculate_angle(keypoints_18[2], keypoints_18[3], keypoints_18[4])
                angles['left_elbow'] = calculate_angle(keypoints_18[5], keypoints_18[6], keypoints_18[7])
                
                # ë‹¤ë¦¬ ê°ë„
                angles['right_knee'] = calculate_angle(keypoints_18[9], keypoints_18[10], keypoints_18[11])
                angles['left_knee'] = calculate_angle(keypoints_18[12], keypoints_18[13], keypoints_18[14])
                
                # ì–´ê¹¨ ê°ë„
                angles['right_shoulder'] = calculate_angle(keypoints_18[1], keypoints_18[2], keypoints_18[3])
                angles['left_shoulder'] = calculate_angle(keypoints_18[1], keypoints_18[5], keypoints_18[6])
                
                # ëª¸í†µ ê°ë„
                if all(len(kp) >= 3 and kp[2] > confidence_threshold for kp in [keypoints_18[1], keypoints_18[8]]):
                    spine_vector = np.array([keypoints_18[8][0] - keypoints_18[1][0], keypoints_18[8][1] - keypoints_18[1][1]])
                    vertical_vector = np.array([0, 1])
                    cos_spine = np.dot(spine_vector, vertical_vector) / (np.linalg.norm(spine_vector) * np.linalg.norm(vertical_vector))
                    angles['spine_vertical'] = float(np.degrees(np.arccos(np.clip(cos_spine, -1.0, 1.0))))
            
            return angles
            
        except Exception as e:
            self.logger.debug(f"í¬ì¦ˆ ê°ë„ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return {}
    
    def _calculate_body_proportions(self, keypoints_18: List[List[float]]) -> Dict[str, float]:
        """ì‹ ì²´ ë¹„ìœ¨ ê³„ì‚°"""
        try:
            proportions = {}
            confidence_threshold = self.pose_config['confidence_threshold']
            
            if len(keypoints_18) >= 18:
                def distance(p1, p2):
                    """ë‘ ì  ê°„ ê±°ë¦¬"""
                    if (len(p1) >= 3 and len(p2) >= 3 and 
                        p1[2] > confidence_threshold and p2[2] > confidence_threshold):
                        return float(np.sqrt((p1[0] - p2[0])**2 + (p1[1] - p2[1])**2))
                    return 0.0
                
                # ì£¼ìš” ê±°ë¦¬ ì¸¡ì •
                head_neck = distance(keypoints_18[0], keypoints_18[1])
                neck_hip = distance(keypoints_18[1], keypoints_18[8])
                hip_knee = distance(keypoints_18[9], keypoints_18[10])
                knee_ankle = distance(keypoints_18[10], keypoints_18[11])
                shoulder_width = distance(keypoints_18[2], keypoints_18[5])
                hip_width = distance(keypoints_18[9], keypoints_18[12])
                
                # ë¹„ìœ¨ ê³„ì‚°
                total_height = head_neck + neck_hip + hip_knee + knee_ankle
                if total_height > 0:
                    proportions['head_to_total'] = head_neck / total_height
                    proportions['torso_to_total'] = neck_hip / total_height
                    proportions['upper_leg_to_total'] = hip_knee / total_height
                    proportions['lower_leg_to_total'] = knee_ankle / total_height
                    proportions['shoulder_to_hip_ratio'] = shoulder_width / hip_width if hip_width > 0 else 0.0
                
                # í˜„ì‹¤ì„± ê²€ì¦
                proportions['is_realistic'] = (
                    0.1 <= proportions.get('head_to_total', 0) <= 0.25 and
                    0.25 <= proportions.get('torso_to_total', 0) <= 0.45 and
                    0.8 <= proportions.get('shoulder_to_hip_ratio', 0) <= 1.5
                )
            
            return proportions
            
        except Exception as e:
            self.logger.debug(f"ì‹ ì²´ ë¹„ìœ¨ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return {}
    
    def _calculate_symmetry_score(self, keypoints_18: List[List[float]]) -> float:
        """ì‹ ì²´ ëŒ€ì¹­ì„± ì ìˆ˜ ê³„ì‚°"""
        try:
            symmetry_pairs = [
                (2, 5), (3, 6), (4, 7), (9, 12), (10, 13), (11, 14), (15, 16)
            ]
            
            symmetry_scores = []
            center_x = np.mean([kp[0] for kp in keypoints_18 if len(kp) >= 3 and kp[2] > self.pose_config['confidence_threshold']])
            
            for left_idx, right_idx in symmetry_pairs:
                if (left_idx < len(keypoints_18) and right_idx < len(keypoints_18) and
                    len(keypoints_18[left_idx]) >= 3 and len(keypoints_18[right_idx]) >= 3 and
                    keypoints_18[left_idx][2] > self.pose_config['confidence_threshold'] and 
                    keypoints_18[right_idx][2] > self.pose_config['confidence_threshold']):
                    
                    left_point = keypoints_18[left_idx]
                    right_point = keypoints_18[right_idx]
                    
                    left_dist = abs(left_point[0] - center_x)
                    right_dist = abs(right_point[0] - center_x)
                    
                    if max(left_dist, right_dist) > 0:
                        symmetry = 1.0 - abs(left_dist - right_dist) / max(left_dist, right_dist)
                        symmetry_scores.append(max(0.0, symmetry))
            
            return float(np.mean(symmetry_scores)) if symmetry_scores else 0.0
            
        except Exception as e:
            self.logger.debug(f"ëŒ€ì¹­ì„± ê³„ì‚° ì‹¤íŒ¨: {e}")
            return 0.0
    
    def _calculate_visibility_score(self, keypoints_18: List[List[float]]) -> float:
        """í‚¤í¬ì¸íŠ¸ ê°€ì‹œì„± ì ìˆ˜ ê³„ì‚°"""
        try:
            if not keypoints_18 or len(keypoints_18) < 18:
                return 0.0
            
            # ì£¼ìš” í‚¤í¬ì¸íŠ¸ë³„ ê°€ì¤‘ì¹˜
            major_keypoints = {
                0: 0.1, 1: 0.15, 2: 0.1, 5: 0.1, 8: 0.15,
                9: 0.1, 12: 0.1, 10: 0.075, 13: 0.075, 11: 0.05, 14: 0.05
            }
            
            weighted_visibility = 0.0
            total_weight = 0.0
            
            for idx, weight in major_keypoints.items():
                if idx < len(keypoints_18) and len(keypoints_18[idx]) >= 3:
                    confidence = keypoints_18[idx][2]
                    weighted_visibility += confidence * weight
                    total_weight += weight
            
            return weighted_visibility / total_weight if total_weight > 0 else 0.0
            
        except Exception as e:
            self.logger.debug(f"ê°€ì‹œì„± ì ìˆ˜ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return 0.0
    
    def _calculate_major_keypoints_rate(self, keypoints_18: List[List[float]]) -> float:
        """ì£¼ìš” í‚¤í¬ì¸íŠ¸ ê²€ì¶œë¥  ê³„ì‚°"""
        try:
            major_indices = [0, 1, 2, 5, 8, 9, 10, 12, 13]
            detected_major = sum(1 for idx in major_indices 
                               if idx < len(keypoints_18) and 
                               len(keypoints_18[idx]) >= 3 and
                               keypoints_18[idx][2] > self.pose_config['confidence_threshold'])
            return detected_major / len(major_indices)
        except Exception as e:
            self.logger.debug(f"ì£¼ìš” í‚¤í¬ì¸íŠ¸ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return 0.0
    
    def _validate_and_normalize_keypoints(self, keypoints_18: List[List[float]], image_shape: Tuple[int, int]) -> List[List[float]]:
        """í‚¤í¬ì¸íŠ¸ ê²€ì¦ ë° ì •ê·œí™”"""
        try:
            h, w = image_shape[:2] if len(image_shape) >= 2 else (512, 512)
            normalized_keypoints = []
            
            for i, kp in enumerate(keypoints_18):
                if len(kp) >= 3:
                    x, y, conf = float(kp[0]), float(kp[1]), float(kp[2])
                    
                    # ì¢Œí‘œ ë²”ìœ„ ì²´í¬
                    x = max(0, min(w-1, x))
                    y = max(0, min(h-1, y))
                    
                    # ì‹ ë¢°ë„ ë²”ìœ„ ì²´í¬
                    conf = max(0.0, min(1.0, conf))
                    
                    normalized_keypoints.append([x, y, conf])
                else:
                    normalized_keypoints.append([0.0, 0.0, 0.0])
            
            # 18ê°œ í‚¤í¬ì¸íŠ¸ ë³´ìž¥
            while len(normalized_keypoints) < 18:
                normalized_keypoints.append([0.0, 0.0, 0.0])
            
            return normalized_keypoints[:18]
            
        except Exception as e:
            self.logger.error(f"í‚¤í¬ì¸íŠ¸ ì •ê·œí™” ì‹¤íŒ¨: {e}")
            return [[0.0, 0.0, 0.0] for _ in range(18)]
    
    def _determine_pose_type(self, keypoints: List[List[float]], pose_angles: Dict[str, float]) -> PoseType:
        """í¬ì¦ˆ íƒ€ìž… ê²°ì •"""
        try:
            if not keypoints or not pose_angles:
                return PoseType.UNKNOWN
            
            # T-í¬ì¦ˆ ê°ì§€ (íŒ”ì´ ìˆ˜í‰ìœ¼ë¡œ ë²Œì–´ì§„ ìƒíƒœ)
            if (pose_angles.get('right_shoulder', 0) > 160 and 
                pose_angles.get('left_shoulder', 0) > 160):
                return PoseType.T_POSE
            
            # A-í¬ì¦ˆ ê°ì§€ (íŒ”ì´ ì•½ê°„ ë²Œì–´ì§„ ìƒíƒœ)
            if (120 < pose_angles.get('right_shoulder', 0) < 160 and
                120 < pose_angles.get('left_shoulder', 0) < 160):
                return PoseType.A_POSE
            
            # ì•‰ì€ ìžì„¸ ê°ì§€ (ë¬´ë¦Žì´ ë§Žì´ êµ¬ë¶€ëŸ¬ì§„ ìƒíƒœ)
            if (pose_angles.get('right_knee', 180) < 120 and
                pose_angles.get('left_knee', 180) < 120):
                return PoseType.SITTING
            
            # ì•¡ì…˜ í¬ì¦ˆ ê°ì§€ (ë¹„ëŒ€ì¹­ì ì¸ ìžì„¸)
            elbow_diff = abs(pose_angles.get('right_elbow', 180) - pose_angles.get('left_elbow', 180))
            if elbow_diff > 60:
                return PoseType.ACTION
            
            # ê¸°ë³¸ ì„œìžˆëŠ” ìžì„¸
            return PoseType.STANDING
            
        except Exception as e:
            self.logger.debug(f"í¬ì¦ˆ íƒ€ìž… ê²°ì • ì‹¤íŒ¨: {e}")
            return PoseType.UNKNOWN
    
    def _create_advanced_pose_visualization(self, image: Image.Image, pose_metrics: PoseMetrics) -> Optional[str]:
        """ê³ ê¸‰ í¬ì¦ˆ ì‹œê°í™” ìƒì„±"""
        try:
            if not pose_metrics.keypoints:
                return None
            
            # ì´ë¯¸ì§€ ë³µì‚¬
            vis_image = image.copy()
            draw = ImageDraw.Draw(vis_image)
            
            # ì‹ ë¢°ë„ ê¸°ì¤€ìœ¼ë¡œ í‚¤í¬ì¸íŠ¸ ê·¸ë¦¬ê¸°
            confidence_threshold = self.pose_config['confidence_threshold']
            
            for i, kp in enumerate(pose_metrics.keypoints):
                if len(kp) >= 3 and kp[2] > confidence_threshold:
                    x, y = int(kp[0]), int(kp[1])
                    color = KEYPOINT_COLORS[i % len(KEYPOINT_COLORS)]
                    
                    # ì‹ ë¢°ë„ì— ë”°ë¥¸ í¬ê¸° ì¡°ì •
                    radius = int(4 + kp[2] * 6)  # 4-10 í”½ì…€
                    draw.ellipse([x-radius, y-radius, x+radius, y+radius], 
                               fill=color, outline=(255, 255, 255), width=2)
                    
                    # í‚¤í¬ì¸íŠ¸ ë²ˆí˜¸ í‘œì‹œ (ì„ íƒì )
                    if self.pose_config.get('show_keypoint_numbers', False):
                        draw.text((x+radius+2, y-radius-2), str(i), fill=(255, 255, 255))
            
            # ìŠ¤ì¼ˆë ˆí†¤ ì—°ê²°ì„  ê·¸ë¦¬ê¸°
            valid_connections = []
            for i, (start_idx, end_idx) in enumerate(SKELETON_CONNECTIONS):
                if (start_idx < len(pose_metrics.keypoints) and 
                    end_idx < len(pose_metrics.keypoints)):
                    
                    start_kp = pose_metrics.keypoints[start_idx]
                    end_kp = pose_metrics.keypoints[end_idx]
                    
                    if (len(start_kp) >= 3 and len(end_kp) >= 3 and
                        start_kp[2] > confidence_threshold and end_kp[2] > confidence_threshold):
                        
                        start_point = (int(start_kp[0]), int(start_kp[1]))
                        end_point = (int(end_kp[0]), int(end_kp[1]))
                        color = SKELETON_COLORS[i % len(SKELETON_COLORS)]
                        
                        # ì‹ ë¢°ë„ì— ë”°ë¥¸ ì„  ë‘ê»˜ ì¡°ì •
                        avg_confidence = (start_kp[2] + end_kp[2]) / 2
                        line_width = int(2 + avg_confidence * 4)  # 2-6 í”½ì…€
                        
                        draw.line([start_point, end_point], fill=color, width=line_width)
                        valid_connections.append((start_idx, end_idx))
            
            # ê³ ê¸‰ ì •ë³´ ì˜¤ë²„ë ˆì´ ì¶”ê°€
            if self.pose_config.get('show_advanced_info', True):
                self._add_advanced_info_overlay(draw, pose_metrics, valid_connections)
            
            # Base64ë¡œ ì¸ì½”ë”©
            buffer = io.BytesIO()
            vis_image.save(buffer, format='JPEG', quality=95)
            image_base64 = base64.b64encode(buffer.getvalue()).decode('utf-8')
            
            return f"data:image/jpeg;base64,{image_base64}"
            
        except Exception as e:
            self.logger.error(f"âŒ ê³ ê¸‰ í¬ì¦ˆ ì‹œê°í™” ìƒì„± ì‹¤íŒ¨: {e}")
            return None
    
    def _add_advanced_info_overlay(self, draw: ImageDraw.Draw, pose_metrics: PoseMetrics, valid_connections: List[Tuple[int, int]]):
        """ê³ ê¸‰ ì •ë³´ ì˜¤ë²„ë ˆì´ ì¶”ê°€"""
        try:
            # í°íŠ¸ ì„¤ì • (ê¸°ë³¸ í°íŠ¸ ì‚¬ìš©)
            try:
                font = ImageFont.load_default()
            except:
                font = None
            
            # í†µê³„ ì •ë³´
            detected_keypoints = len([kp for kp in pose_metrics.keypoints if len(kp) > 2 and kp[2] > self.pose_config['confidence_threshold']])
            avg_confidence = np.mean([kp[2] for kp in pose_metrics.keypoints if len(kp) > 2]) if pose_metrics.keypoints else 0.0
            
            # í…ìŠ¤íŠ¸ ì •ë³´
            info_lines = [
                f"Real AI Model: {pose_metrics.model_used}",
                f"Keypoints: {detected_keypoints}/18",
                f"AI Confidence: {avg_confidence:.3f}",
                f"Connections: {len(valid_connections)}",
                f"Processing: {pose_metrics.processing_time:.2f}s",
                f"Strict Mode: {'ON' if self.strict_mode else 'OFF'}",
                f"Fallback: DISABLED"
            ]
            
            # ë°°ê²½ ì˜ì—­
            y_offset = 10
            for i, line in enumerate(info_lines):
                text_y = y_offset + i * 22
                draw.rectangle([5, text_y-2, 250, text_y+20], fill=(0, 0, 0, 150))
                draw.text((10, text_y), line, fill=(255, 255, 255), font=font)
                
        except Exception as e:
            self.logger.debug(f"ê³ ê¸‰ ì •ë³´ ì˜¤ë²„ë ˆì´ ì¶”ê°€ ì‹¤íŒ¨: {e}")
    
    def _save_to_cache(self, cache_key: str, result: Dict[str, Any]):
        """ìºì‹œì— ê²°ê³¼ ì €ìž¥"""
        try:
            if len(self.prediction_cache) >= self.cache_max_size:
                # ì˜¤ëž˜ëœ í•­ëª© ì œê±° (FIFO)
                oldest_key = next(iter(self.prediction_cache))
                del self.prediction_cache[oldest_key]
            
            # ì‹œê°í™”ëŠ” ìºì‹œì—ì„œ ì œì™¸ (ë©”ëª¨ë¦¬ ì ˆì•½)
            cached_result = result.copy()
            cached_result['visualization'] = None
            
            self.prediction_cache[cache_key] = cached_result
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ ìºì‹œ ì €ìž¥ ì‹¤íŒ¨: {e}")
    
    def _create_error_result(self, error_message: str, processing_time: float = 0.0) -> Dict[str, Any]:
        """ì—ëŸ¬ ê²°ê³¼ ìƒì„±"""
        return {
            'success': False,
            'error': error_message,
            'keypoints': [],
            'confidence_scores': [],
            'pose_analysis': {
                'suitable_for_fitting': False,
                'issues': [error_message],
                'recommendations': ['ì‹¤ì œ AI ëª¨ë¸ ìƒíƒœë¥¼ í™•ì¸í•˜ê±°ë‚˜ ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”'],
                'quality_score': 0.0,
                'ai_confidence': 0.0,
                'real_ai_analysis': True
            },
            'visualization': None,
            'processing_time': processing_time,
            'model_used': 'error',
            'step_info': {
                'step_name': self.step_name,
                'step_number': self.step_number,
                'optimization_level': getattr(self, 'optimization_level', 'unknown'),
                'strict_mode': self.strict_mode,
                'real_ai_model_name': getattr(self, 'active_model', 'none'),
                'fallback_disabled': True
            }
        }
    
    # =================================================================
    # ðŸ”§ ìœ í‹¸ë¦¬í‹° ë©”ì„œë“œë“¤
    # =================================================================
    
    def clear_cache(self):
        """ìºì‹œ ì •ë¦¬"""
        try:
            self.prediction_cache.clear()
            self.logger.info("ðŸ“‹ ì‹¤ì œ AI ìºì‹œ ì •ë¦¬ ì™„ë£Œ")
        except Exception as e:
            self.logger.warning(f"âš ï¸ ìºì‹œ ì •ë¦¬ ì‹¤íŒ¨: {e}")
    
    def get_cache_status(self) -> Dict[str, Any]:
        """ìºì‹œ ìƒíƒœ ë°˜í™˜"""
        return {
            'cache_size': len(self.prediction_cache),
            'cache_max_size': self.cache_max_size,
            'cache_enabled': self.pose_config['cache_enabled'],
            'real_ai_cache': True
        }
    
    def get_step_info(self) -> Dict[str, Any]:
        """Step ì •ë³´ ë°˜í™˜ (step_model_requests.py ì™„ë²½ í˜¸í™˜)"""
        
        # ê¸°ë³¸ Step ì •ë³´
        base_info = {
            "step_name": self.step_name,
            "step_number": self.step_number,
            "step_description": self.step_description,
            "is_initialized": self.is_initialized,
            "device": self.device,
            "optimization_level": getattr(self, 'optimization_level', 'unknown'),
            "strict_mode": self.strict_mode
        }
        
        # ì‹¤ì œ AI ëª¨ë¸ ìƒíƒœ ì •ë³´
        model_status = {
            "loaded_models": list(getattr(self, 'pose_models', {}).keys()),
            "active_model": getattr(self, 'active_model', None),
            "model_priority": self.pose_config['model_priority'],
            "model_interface_connected": hasattr(self, 'model_interface') and self.model_interface is not None,
            "real_ai_models_only": True,  # ì‹¤ì œ AI ì „ìš©
            "fallback_disabled": True     # í´ë°± ì™„ì „ ë¹„í™œì„±í™”
        }
        
        # ì²˜ë¦¬ ì„¤ì • ì •ë³´
        processing_settings = {
            "confidence_threshold": self.pose_config['confidence_threshold'],
            "optimization_level": getattr(self, 'optimization_level', 'unknown'),
            "batch_processing": getattr(self, 'batch_processing', False),
            "cache_enabled": self.pose_config['cache_enabled'],
            "cache_status": self.get_cache_status(),
            "strict_mode_enabled": self.strict_mode,
            "real_ai_only": True          # ì‹¤ì œ AIë§Œ ì‚¬ìš©
        }
        
        # step_model_requests.py í˜¸í™˜ ì •ë³´
        step_requirements = self._get_step_model_requirements()
        
        compliance_info = {
            "step_model_requests_compliance": True,
            "required_model_name": step_requirements["model_name"],
            "step_priority": step_requirements["step_priority"],
            "target_input_size": getattr(self, 'target_input_size', step_requirements["input_size"]),
            "optimization_params": getattr(self, 'pose_optimization_params', {}),
            "checkpoint_patterns": step_requirements["checkpoint_patterns"],
            "alternative_models": step_requirements["alternative_models"],
            "strict_mode_compatible": step_requirements["metadata"]["strict_mode_compatible"],
            "fallback_disabled": step_requirements["metadata"]["fallback_disabled"]
        }
        
        # ì„±ëŠ¥ ë° ë©”íƒ€ë°ì´í„°
        performance_info = {
            "memory_gb": self.memory_gb,
            "is_m3_max": self.is_m3_max,
            "use_neural_engine": getattr(self, 'use_neural_engine', False),
            "supported_clothing_types": list(self.CLOTHING_POSE_WEIGHTS.keys()),
            "keypoints_format": getattr(self, 'num_keypoints', 18),
            "visualization_enabled": self.pose_config['visualization_enabled'],
            "fallback_disabled": True,     # í´ë°± ì™„ì „ ì œê±°
            "real_ai_only_mode": True,     # ì‹¤ì œ AIë§Œ ì‚¬ìš©
            "analysis_features": [
                "pose_angles", "body_proportions", "symmetry_score", 
                "visibility_score", "clothing_suitability", "pose_type_detection"
            ]
        }
        
        return {
            **base_info,
            "model_status": model_status,
            "processing_settings": processing_settings,
            "step_requirements_compliance": compliance_info,
            "performance_info": performance_info,
            "metadata": step_requirements["metadata"]
        }
    
    def cleanup_resources(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        try:
            # ì‹¤ì œ AI í¬ì¦ˆ ëª¨ë¸ ì •ë¦¬
            if hasattr(self, 'pose_models'):
                for model_name, model in self.pose_models.items():
                    try:
                        if hasattr(model, 'cleanup'):
                            model.cleanup()
                        elif hasattr(model, 'close'):
                            model.close()
                        elif hasattr(model, 'cpu'):
                            model.cpu()
                    except Exception as e:
                        self.logger.debug(f"ì‹¤ì œ AI ëª¨ë¸ ì •ë¦¬ ì‹¤íŒ¨ {model_name}: {e}")
                    del model
                self.pose_models.clear()
            
            # ìºì‹œ ì •ë¦¬
            self.clear_cache()
            
            # ModelLoader ì¸í„°íŽ˜ì´ìŠ¤ ì •ë¦¬
            if hasattr(self, 'model_interface') and self.model_interface:
                try:
                    if hasattr(self.model_interface, 'unload_models'):
                        self.model_interface.unload_models()
                except Exception as e:
                    self.logger.debug(f"ëª¨ë¸ ì¸í„°íŽ˜ì´ìŠ¤ ì •ë¦¬ ì‹¤íŒ¨: {e}")
            
            # ë©”ëª¨ë¦¬ ì •ë¦¬
            if TORCH_AVAILABLE:
                if self.device == "mps":
                    torch.mps.empty_cache()
                elif self.device == "cuda":
                    torch.cuda.empty_cache()
            
            gc.collect()
            
            self.logger.info("âœ… ì™„ì „í•œ ì‹¤ì œ AI PoseEstimationStep ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì™„ë£Œ")
            
        except Exception as e:
            self.logger.error(f"âŒ ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì‹¤íŒ¨: {e}")
    
    def __del__(self):
        """ì†Œë©¸ìž"""
        try:
            self.cleanup_resources()
        except Exception:
            pass

# =================================================================
# ðŸ”¥ í˜¸í™˜ì„± ì§€ì› í•¨ìˆ˜ë“¤ (ì™„ì „í•œ ì‹¤ì œ AI ì „ìš©)
# =================================================================

async def create_pose_estimation_step(
    device: str = "auto",
    config: Optional[Dict[str, Any]] = None,
    strict_mode: bool = True,
    **kwargs
) -> PoseEstimationStep:
    """
    âœ… ì™„ì „í•œ ì‹¤ì œ AI ì „ìš© Step 02 ìƒì„± í•¨ìˆ˜ - í´ë°± ì™„ì „ ì œê±°
    
    Args:
        device: ë””ë°”ì´ìŠ¤ ì„¤ì •
        config: ì„¤ì • ë”•ì…”ë„ˆë¦¬
        strict_mode: ì—„ê²© ëª¨ë“œ (Trueì‹œ AI ì‹¤íŒ¨ â†’ Exception)
        **kwargs: ì¶”ê°€ ì„¤ì •
        
    Returns:
        PoseEstimationStep: ì´ˆê¸°í™”ëœ ì‹¤ì œ AI í¬ì¦ˆ ì¶”ì • Step
        
    Raises:
        RuntimeError: strict_mode=Trueì—ì„œ ì´ˆê¸°í™” ì‹¤íŒ¨ ì‹œ
    """
    try:
        # ë””ë°”ì´ìŠ¤ ì²˜ë¦¬
        device_param = None if device == "auto" else device
        
        # config í†µí•©
        if config is None:
            config = {}
        config.update(kwargs)
        config['real_ai_only'] = True      # ì‹¤ì œ AIë§Œ ì‚¬ìš© ê°•ì œ
        config['fallback_enabled'] = False # í´ë°± ì™„ì „ ê¸ˆì§€
        
        # Step ìƒì„± ë° ì´ˆê¸°í™”
        step = PoseEstimationStep(device=device_param, config=config, strict_mode=strict_mode)
        
        # ì™„ì „í•œ ì‹¤ì œ AI ì´ˆê¸°í™” ì‹¤í–‰
        initialization_success = await step.initialize()
        
        if not initialization_success:
            error_msg = "ì™„ì „í•œ ì‹¤ì œ AI ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨"
            if strict_mode:
                raise RuntimeError(f"Strict Mode: {error_msg}")
            else:
                step.logger.warning(f"âš ï¸ {error_msg} - Step ìƒì„±ì€ ì™„ë£Œë¨ (ë¹„ì—„ê²© ëª¨ë“œ)")
        
        return step
        
    except Exception as e:
        logger.error(f"âŒ create_pose_estimation_step ì‹¤íŒ¨: {e}")
        if strict_mode:
            raise  # strict_modeì—ì„œëŠ” Exception ìž¬ë°œìƒ
        else:
            # ìµœì†Œí•œì˜ Step ìƒì„± (ë¹„ì—„ê²© ëª¨ë“œ)
            step = PoseEstimationStep(device='cpu', strict_mode=False)
            return step

def create_pose_estimation_step_sync(
    device: str = "auto",
    config: Optional[Dict[str, Any]] = None,
    strict_mode: bool = True,
    **kwargs
) -> PoseEstimationStep:
    """ðŸ”§ ë™ê¸°ì‹ ì™„ì „í•œ ì‹¤ì œ AI Step 02 ìƒì„± (ë ˆê±°ì‹œ í˜¸í™˜)"""
    try:
        try:
            loop = asyncio.get_event_loop()
        except RuntimeError:
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
        
        return loop.run_until_complete(
            create_pose_estimation_step(device, config, strict_mode, **kwargs)
        )
    except Exception as e:
        logger.error(f"âŒ create_pose_estimation_step_sync ì‹¤íŒ¨: {e}")
        if strict_mode:
            raise
        else:
            return PoseEstimationStep(device='cpu', strict_mode=False)

# =================================================================
# ðŸ”¥ ì¶”ê°€ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤ (ì™„ì „í•œ ê¸°ëŠ¥)
# =================================================================

def validate_openpose_keypoints(keypoints_18: List[List[float]]) -> bool:
    """OpenPose 18 keypoints ìœ íš¨ì„± ê²€ì¦"""
    try:
        if len(keypoints_18) != 18:
            return False
        
        for kp in keypoints_18:
            if len(kp) != 3:
                return False
            if not all(isinstance(x, (int, float)) for x in kp):
                return False
            if kp[2] < 0 or kp[2] > 1:  # ì‹ ë¢°ë„ëŠ” 0~1 ì‚¬ì´
                return False
        
        return True
        
    except Exception:
        return False

def convert_keypoints_to_coco(keypoints_18: List[List[float]]) -> List[List[float]]:
    """OpenPose 18ì„ COCO 17 í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
    try:
        # OpenPose 18 -> COCO 17 ë§¤í•‘
        op_to_coco_mapping = {
            0: 0,   # nose
            15: 1,  # right_eye -> left_eye (COCO ê´€ì )
            16: 2,  # left_eye -> right_eye
            17: 3,  # right_ear -> left_ear
            18: 4,  # left_ear -> right_ear
            2: 5,   # right_shoulder -> left_shoulder (COCO ê´€ì )
            5: 6,   # left_shoulder -> right_shoulder
            3: 7,   # right_elbow -> left_elbow
            6: 8,   # left_elbow -> right_elbow
            4: 9,   # right_wrist -> left_wrist
            7: 10,  # left_wrist -> right_wrist
            9: 11,  # right_hip -> left_hip
            12: 12, # left_hip -> right_hip
            10: 13, # right_knee -> left_knee
            13: 14, # left_knee -> right_knee
            11: 15, # right_ankle -> left_ankle
            14: 16  # left_ankle -> right_ankle
        }
        
        coco_keypoints = []
        for coco_idx in range(17):
            if coco_idx in op_to_coco_mapping.values():
                op_idx = next(k for k, v in op_to_coco_mapping.items() if v == coco_idx)
                if op_idx < len(keypoints_18):
                    coco_keypoints.append(keypoints_18[op_idx])
                else:
                    coco_keypoints.append([0.0, 0.0, 0.0])
            else:
                coco_keypoints.append([0.0, 0.0, 0.0])
        
        return coco_keypoints
        
    except Exception as e:
        logger.error(f"í‚¤í¬ì¸íŠ¸ ë³€í™˜ ì‹¤íŒ¨: {e}")
        return [[0.0, 0.0, 0.0]] * 17

def draw_pose_on_image(
    image: Union[np.ndarray, Image.Image],
    keypoints: List[List[float]],
    confidence_threshold: float = 0.5,
    keypoint_size: int = 4,
    line_width: int = 3
) -> Image.Image:
    """ì´ë¯¸ì§€ì— í¬ì¦ˆ ê·¸ë¦¬ê¸°"""
    try:
        # ì´ë¯¸ì§€ ë³€í™˜
        if isinstance(image, np.ndarray):
            pil_image = Image.fromarray(image)
        else:
            pil_image = image.copy()
        
        draw = ImageDraw.Draw(pil_image)
        
        # í‚¤í¬ì¸íŠ¸ ê·¸ë¦¬ê¸°
        for i, kp in enumerate(keypoints):
            if len(kp) >= 3 and kp[2] > confidence_threshold:
                x, y = int(kp[0]), int(kp[1])
                color = KEYPOINT_COLORS[i % len(KEYPOINT_COLORS)]
                
                # ì‹ ë¢°ë„ì— ë”°ë¥¸ í¬ê¸° ì¡°ì •
                radius = int(keypoint_size + kp[2] * 4)
                draw.ellipse([x-radius, y-radius, x+radius, y+radius], 
                           fill=color, outline=(255, 255, 255), width=2)
        
        # ìŠ¤ì¼ˆë ˆí†¤ ê·¸ë¦¬ê¸°
        for i, (start_idx, end_idx) in enumerate(SKELETON_CONNECTIONS):
            if (start_idx < len(keypoints) and end_idx < len(keypoints)):
                start_kp = keypoints[start_idx]
                end_kp = keypoints[end_idx]
                
                if (len(start_kp) >= 3 and len(end_kp) >= 3 and
                    start_kp[2] > confidence_threshold and end_kp[2] > confidence_threshold):
                    
                    start_point = (int(start_kp[0]), int(start_kp[1]))
                    end_point = (int(end_kp[0]), int(end_kp[1]))
                    color = SKELETON_COLORS[i % len(SKELETON_COLORS)]
                    
                    # ì‹ ë¢°ë„ì— ë”°ë¥¸ ì„  ë‘ê»˜
                    avg_confidence = (start_kp[2] + end_kp[2]) / 2
                    adjusted_width = int(line_width * avg_confidence)
                    
                    draw.line([start_point, end_point], fill=color, width=max(1, adjusted_width))
        
        return pil_image
        
    except Exception as e:
        logger.error(f"í¬ì¦ˆ ê·¸ë¦¬ê¸° ì‹¤íŒ¨: {e}")
        return image if isinstance(image, Image.Image) else Image.fromarray(image)

def analyze_pose_for_clothing(
    keypoints: List[List[float]],
    clothing_type: str = "default",
    confidence_threshold: float = 0.5,
    strict_analysis: bool = True
) -> Dict[str, Any]:
    """ì˜ë¥˜ë³„ í¬ì¦ˆ ì í•©ì„± ë¶„ì„ (ì™„ì „í•œ ì‹¤ì œ AI ê¸°ë°˜)"""
    try:
        if not keypoints:
            return {
                'suitable_for_fitting': False,
                'issues': ["ì™„ì „í•œ ì‹¤ì œ AI ëª¨ë¸ì—ì„œ í¬ì¦ˆë¥¼ ê²€ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤"],
                'recommendations': ["ì‹¤ì œ AI ëª¨ë¸ ìƒíƒœë¥¼ í™•ì¸í•˜ê±°ë‚˜ ë” ì„ ëª…í•œ ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í•´ ì£¼ì„¸ìš”"],
                'pose_score': 0.0,
                'ai_confidence': 0.0,
                'real_ai_based_analysis': True
            }
        
        # ì˜ë¥˜ë³„ ê°€ì¤‘ì¹˜ ê°€ì ¸ì˜¤ê¸°
        weights = PoseEstimationStep.CLOTHING_POSE_WEIGHTS.get(
            clothing_type, 
            PoseEstimationStep.CLOTHING_POSE_WEIGHTS['default']
        )
        
        # ì‹ ì²´ ë¶€ìœ„ë³„ ì ìˆ˜ ê³„ì‚°
        def calculate_body_part_score(part_indices: List[int]) -> float:
            visible_count = 0
            total_confidence = 0.0
            
            for idx in part_indices:
                if idx < len(keypoints) and len(keypoints[idx]) >= 3:
                    if keypoints[idx][2] > confidence_threshold:
                        visible_count += 1
                        total_confidence += keypoints[idx][2]
            
            if visible_count == 0:
                return 0.0
            
            return (visible_count / len(part_indices)) * (total_confidence / visible_count)
        
        # ë¶€ìœ„ë³„ ì ìˆ˜
        head_indices = [0, 15, 16, 17, 18]  # nose, eyes, ears
        torso_indices = [1, 2, 5, 8, 9, 12]  # neck, shoulders, hips
        arm_indices = [2, 3, 4, 5, 6, 7]  # shoulders, elbows, wrists
        leg_indices = [9, 10, 11, 12, 13, 14]  # hips, knees, ankles
        
        head_score = calculate_body_part_score(head_indices)
        torso_score = calculate_body_part_score(torso_indices)
        arms_score = calculate_body_part_score(arm_indices)
        legs_score = calculate_body_part_score(leg_indices)
        
        # ì‹¤ì œ AI ì‹ ë¢°ë„ ë°˜ì˜ ê°€ì¤‘ í‰ê· 
        ai_confidence = np.mean([kp[2] for kp in keypoints if len(kp) > 2]) if keypoints else 0.0
        
        pose_score = (
            torso_score * weights.get('torso', 0.4) +
            arms_score * weights.get('arms', 0.3) +
            legs_score * weights.get('legs', 0.2) +
            weights.get('visibility', 0.1) * min(head_score, 1.0)
        ) * ai_confidence  # ì‹¤ì œ AI ì‹ ë¢°ë„ ë°˜ì˜
        
        # ì—„ê²©í•œ ì í•©ì„± íŒë‹¨ (ì‹¤ì œ AI ê¸°ë°˜ì´ë¯€ë¡œ ë” ë†’ì€ ê¸°ì¤€)
        min_score = 0.8 if strict_analysis else 0.7
        min_confidence = 0.75 if strict_analysis else 0.65
        suitable_for_fitting = (pose_score >= min_score and 
                              ai_confidence >= min_confidence)
        
        # ì´ìŠˆ ë° ê¶Œìž¥ì‚¬í•­
        issues = []
        recommendations = []
        
        if ai_confidence < min_confidence:
            issues.append(f'ì‹¤ì œ AI ëª¨ë¸ì˜ ì‹ ë¢°ë„ê°€ ë‚®ìŠµë‹ˆë‹¤ ({ai_confidence:.3f} < {min_confidence})')
            recommendations.append('ì¡°ëª…ì´ ì¢‹ì€ í™˜ê²½ì—ì„œ ë” ì„ ëª…í•˜ê²Œ ë‹¤ì‹œ ì´¬ì˜í•´ ì£¼ì„¸ìš”')
        
        if torso_score < 0.5:
            issues.append(f'{clothing_type} ì°©ìš©ì— ì¤‘ìš”í•œ ìƒì²´ê°€ ë¶ˆë¶„ëª…í•©ë‹ˆë‹¤')
            recommendations.append('ìƒì²´ ì „ì²´ê°€ ë³´ì´ë„ë¡ ì´¬ì˜í•´ ì£¼ì„¸ìš”')
        
        if clothing_type in ['shirt', 'jacket', 'top'] and arms_score < 0.5:
            issues.append("íŒ”ì˜ ìœ„ì¹˜ê°€ ì˜ë¥˜ ì°©ìš© ì‹œë®¬ë ˆì´ì…˜ì— ë¶€ì ì ˆí•©ë‹ˆë‹¤")
            recommendations.append("íŒ”ì„ ë²Œë¦¬ê±°ë‚˜ ìžì—°ìŠ¤ëŸ½ê²Œ ë‚´ë ¤ì£¼ì„¸ìš”")
        
        if clothing_type in ['pants', 'dress', 'skirt'] and legs_score < 0.5:
            issues.append("ë‹¤ë¦¬ê°€ ê°€ë ¤ì ¸ ìžˆì–´ í•˜ì˜ ì°©ìš© ì‹œë®¬ë ˆì´ì…˜ì´ ì–´ë µìŠµë‹ˆë‹¤")
            recommendations.append("ì „ì‹ ì´ ë³´ì´ë„ë¡ ì´¬ì˜í•´ ì£¼ì„¸ìš”")
        
        if head_score < 0.3:
            issues.append("ì–¼êµ´ì´ ìž˜ ë³´ì´ì§€ ì•ŠìŠµë‹ˆë‹¤")
            recommendations.append("ì–¼êµ´ì´ ì •ë©´ì„ í–¥í•˜ë„ë¡ ì´¬ì˜í•´ ì£¼ì„¸ìš”")
        
        analysis = {
            'suitable_for_fitting': suitable_for_fitting,
            'issues': issues,
            'recommendations': recommendations,
            'pose_score': pose_score,
            'ai_confidence': ai_confidence,
            'detailed_scores': {
                'head': head_score,
                'torso': torso_score,
                'arms': arms_score,
                'legs': legs_score
            },
            'clothing_type': clothing_type,
            'weights_used': weights,
            'real_ai_based_analysis': True,
            'strict_analysis': strict_analysis
        }
        
        return analysis
        
    except Exception as e:
        logger.error(f"ì˜ë¥˜ë³„ í¬ì¦ˆ ë¶„ì„ ì‹¤íŒ¨: {e}")
        return {
            'suitable_for_fitting': False,
            'issues': ["ì™„ì „í•œ ì‹¤ì œ AI ê¸°ë°˜ ë¶„ì„ ì‹¤íŒ¨"],
            'recommendations': ["ì‹¤ì œ AI ëª¨ë¸ ìƒíƒœë¥¼ í™•ì¸í•˜ê±°ë‚˜ ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”"],
            'pose_score': 0.0,
            'ai_confidence': 0.0,
            'real_ai_based_analysis': True
        }

# =================================================================
# ðŸ”¥ ê°œë°œ ë° í…ŒìŠ¤íŠ¸ í•¨ìˆ˜ë“¤ (ì™„ì „í•œ ì‹¤ì œ AI ì „ìš©)
# =================================================================

async def test_complete_real_ai_pose_estimation():
    """ì™„ì „í•œ ì‹¤ì œ AI í¬ì¦ˆ ì¶”ì • í…ŒìŠ¤íŠ¸"""
    try:
        print("ðŸ”¥ ì™„ì „í•œ ì‹¤ì œ AI í¬ì¦ˆ ì¶”ì • ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸")
        print("=" * 70)
        
        # Strict Modeë¡œ ì™„ì „í•œ ì‹¤ì œ AI Step ìƒì„±
        step = await create_pose_estimation_step(
            device="auto",
            strict_mode=True,
            config={
                'confidence_threshold': 0.5,
                'visualization_enabled': True,
                'cache_enabled': True,
                'detailed_analysis': True,
                'real_ai_only': True,
                'fallback_enabled': False
            }
        )
        
        # ë”ë¯¸ ì´ë¯¸ì§€ë¡œ ì™„ì „í•œ ì‹¤ì œ AI í…ŒìŠ¤íŠ¸
        dummy_image = np.zeros((512, 512, 3), dtype=np.uint8)
        dummy_image_pil = Image.fromarray(dummy_image)
        
        print(f"ðŸ“‹ ì™„ì „í•œ ì‹¤ì œ AI Step ì •ë³´:")
        step_info = step.get_step_info()
        print(f"   ðŸŽ¯ Step: {step_info['step_name']}")
        print(f"   ðŸ¤– AI ëª¨ë¸: {step_info['model_status']['active_model']}")
        print(f"   ðŸ”’ Strict Mode: {step_info['strict_mode']}")
        print(f"   ðŸš« Fallback: {'ë¹„í™œì„±í™”' if step_info['model_status']['fallback_disabled'] else 'í™œì„±í™”'}")
        print(f"   ðŸ’Ž ì‹¤ì œ AI ì „ìš©: {step_info['processing_settings']['real_ai_only']}")
        
        # ì™„ì „í•œ ì‹¤ì œ AI ëª¨ë¸ë¡œë§Œ ì²˜ë¦¬ (í´ë°± ì™„ì „ ê¸ˆì§€)
        result = await step.process(dummy_image_pil, clothing_type="shirt")
        
        if result['success']:
            print(f"âœ… ì™„ì „í•œ ì‹¤ì œ AI í¬ì¦ˆ ì¶”ì • ì„±ê³µ")
            print(f"ðŸŽ¯ AI í‚¤í¬ì¸íŠ¸ ìˆ˜: {len(result['keypoints'])}")
            print(f"ðŸŽ–ï¸ AI ì‹ ë¢°ë„: {result['pose_analysis']['ai_confidence']:.3f}")
            print(f"ðŸ’Ž í’ˆì§ˆ ì ìˆ˜: {result['pose_analysis']['quality_score']:.3f}")
            print(f"ðŸ”¬ í¬ì¦ˆ íƒ€ìž…: {result['pose_analysis']['pose_type']}")
            print(f"ðŸ‘• ì˜ë¥˜ ì í•©ì„±: {result['pose_analysis']['suitable_for_fitting']}")
            print(f"ðŸ¤– ì‚¬ìš©ëœ AI ëª¨ë¸: {result['model_used']}")
            
            # ê³ ê¸‰ ë¶„ì„ ê²°ê³¼
            if 'pose_angles' in result['pose_analysis']:
                angles = result['pose_analysis']['pose_angles']
                print(f"ðŸ“ ê´€ì ˆ ê°ë„: {len(angles)}ê°œ ì¸¡ì •")
            
            if 'body_proportions' in result['pose_analysis']:
                proportions = result['pose_analysis']['body_proportions']
                print(f"ðŸ“ ì‹ ì²´ ë¹„ìœ¨: {len(proportions)}ê°œ ì¸¡ì •")
            
        else:
            print(f"âŒ ì™„ì „í•œ ì‹¤ì œ AI í¬ì¦ˆ ì¶”ì • ì‹¤íŒ¨: {result.get('error', 'Unknown AI Error')}")
        
        # ì •ë¦¬
        step.cleanup_resources()
        print("ðŸ§¹ ì™„ì „í•œ ì‹¤ì œ AI ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì™„ë£Œ")
        
    except Exception as e:
        print(f"âŒ ì™„ì „í•œ ì‹¤ì œ AI í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")

async def test_model_loader_integration_complete():
    """ì™„ì „í•œ ModelLoader í†µí•© í…ŒìŠ¤íŠ¸"""
    try:
        print("ðŸ¤– ì™„ì „í•œ ì‹¤ì œ AI ModelLoader í†µí•© í…ŒìŠ¤íŠ¸")
        print("=" * 70)
        
        # ModelLoader ìƒíƒœ í™•ì¸
        if not MODEL_LOADER_AVAILABLE:
            print("âŒ ModelLoaderë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            return
        
        # Global ModelLoader ê°€ì ¸ì˜¤ê¸°
        model_loader = get_global_model_loader()
        if not model_loader:
            print("âŒ Global ModelLoaderë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            return
        
        print(f"âœ… ì™„ì „í•œ ì‹¤ì œ AI ModelLoader ì‚¬ìš© ê°€ëŠ¥")
        
        # Step ìƒì„± ë° ModelLoader ì—°ë™ í™•ì¸
        step = PoseEstimationStep(device="auto", strict_mode=True)
        await step.initialize()
        
        print(f"ðŸ”— ì‹¤ì œ AI Model Interface: {step.model_interface is not None}")
        print(f"ðŸŽ¯ Active AI Model: {step.active_model}")
        print(f"ðŸ“¦ Loaded AI Models: {list(step.pose_models.keys()) if hasattr(step, 'pose_models') else []}")
        print(f"ðŸš« Fallback Status: ì™„ì „ ë¹„í™œì„±í™”")
        print(f"ðŸ’Ž Real AI Only: {step.pose_config.get('real_ai_only', False)}")
        
        # ì •ë¦¬
        step.cleanup_resources()
        
    except Exception as e:
        print(f"âŒ ì™„ì „í•œ ì‹¤ì œ AI ModelLoader í†µí•© í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")

def test_keypoint_conversion():
    """í‚¤í¬ì¸íŠ¸ ë³€í™˜ í…ŒìŠ¤íŠ¸"""
    try:
        print("ðŸ”„ í‚¤í¬ì¸íŠ¸ ë³€í™˜ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸")
        print("=" * 50)
        
        # ë”ë¯¸ OpenPose 18 í‚¤í¬ì¸íŠ¸
        openpose_keypoints = [
            [100, 50, 0.9],   # nose
            [100, 80, 0.8],   # neck
            [80, 100, 0.7],   # right_shoulder
            [70, 130, 0.6],   # right_elbow
            [60, 160, 0.5],   # right_wrist
            [120, 100, 0.7],  # left_shoulder
            [130, 130, 0.6],  # left_elbow
            [140, 160, 0.5],  # left_wrist
            [100, 200, 0.8],  # middle_hip
            [90, 200, 0.7],   # right_hip
            [85, 250, 0.6],   # right_knee
            [80, 300, 0.5],   # right_ankle
            [110, 200, 0.7],  # left_hip
            [115, 250, 0.6],  # left_knee
            [120, 300, 0.5],  # left_ankle
            [95, 40, 0.8],    # right_eye
            [105, 40, 0.8],   # left_eye
            [90, 45, 0.7],    # right_ear
            [110, 45, 0.7]    # left_ear
        ]
        
        # ìœ íš¨ì„± ê²€ì¦
        is_valid = validate_openpose_keypoints(openpose_keypoints)
        print(f"âœ… OpenPose 18 ìœ íš¨ì„±: {is_valid}")
        
        # COCO 17ë¡œ ë³€í™˜
        coco_keypoints = convert_keypoints_to_coco(openpose_keypoints)
        print(f"ðŸ”„ COCO 17 ë³€í™˜: {len(coco_keypoints)}ê°œ í‚¤í¬ì¸íŠ¸")
        
        # ì˜ë¥˜ë³„ ë¶„ì„
        analysis = analyze_pose_for_clothing(
            openpose_keypoints, 
            clothing_type="shirt",
            strict_analysis=True
        )
        print(f"ðŸ‘• ì˜ë¥˜ ì í•©ì„± ë¶„ì„:")
        print(f"   ì í•©ì„±: {analysis['suitable_for_fitting']}")
        print(f"   ì ìˆ˜: {analysis['pose_score']:.3f}")
        print(f"   AI ì‹ ë¢°ë„: {analysis['ai_confidence']:.3f}")
        
    except Exception as e:
        print(f"âŒ í‚¤í¬ì¸íŠ¸ ë³€í™˜ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")

# =================================================================
# ðŸ”¥ ëª¨ë“ˆ ìµìŠ¤í¬íŠ¸ (ì™„ì „í•œ ì‹¤ì œ AI ì „ìš©)
# =================================================================

__all__ = [
    # ðŸ”¥ ë©”ì¸ í´ëž˜ìŠ¤ (ì™„ì „í•œ ì‹¤ì œ AI ì „ìš©)
    'PoseEstimationStep',
    'PoseMetrics',
    'PoseModel',
    'PoseQuality', 
    'PoseType',
    
    # ðŸ”¥ ìƒì„± í•¨ìˆ˜ë“¤ (í´ë°± ì™„ì „ ì œê±°)
    'create_pose_estimation_step',
    'create_pose_estimation_step_sync',
    
    # ðŸ”¥ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤ (ì™„ì „í•œ ê¸°ëŠ¥)
    'validate_openpose_keypoints',
    'convert_keypoints_to_coco',
    'draw_pose_on_image',
    'analyze_pose_for_clothing',
    
    # ðŸ”¥ ìƒìˆ˜ë“¤
    'OPENPOSE_18_KEYPOINTS',
    'KEYPOINT_COLORS',
    'SKELETON_CONNECTIONS',
    'SKELETON_COLORS',
    
    # ðŸ”¥ í…ŒìŠ¤íŠ¸ í•¨ìˆ˜ë“¤
    'test_complete_real_ai_pose_estimation',
    'test_model_loader_integration_complete',
    'test_keypoint_conversion'
]

# =================================================================
# ðŸ”¥ ëª¨ë“ˆ ì´ˆê¸°í™” ë¡œê·¸ (ì™„ì „í•œ ì‹¤ì œ AI ì „ìš©)
# =================================================================

logger.info("ðŸ”¥ ì™„ì „í•œ ì‹¤ì œ AI PoseEstimationStep v7.0 ë¡œë“œ ì™„ë£Œ")
logger.info("âœ… í´ë°± ì™„ì „ ì œê±° - 100% ì‹¤ì œ AI ëª¨ë¸ë§Œ ì‚¬ìš©")
logger.info("ðŸ”’ strict_mode ì§€ì› - ì‹¤íŒ¨ ì‹œ ì¦‰ì‹œ ì—ëŸ¬ ë°˜í™˜")
logger.info("ðŸ”— BaseStepMixin ì™„ì „ ì—°ë™ - logger ì†ì„± ëˆ„ë½ ì™„ì „ í•´ê²°")
logger.info("ðŸ§  ModelLoader ì™„ë²½ ì—°ë™ - ìˆœí™˜ì°¸ì¡° ì—†ëŠ” í•œë°©í–¥ ì°¸ì¡°")
logger.info("ðŸ“‹ step_model_requests.py ì™„ë²½ í˜¸í™˜")
logger.info("ðŸ”¬ ëª¨ë“  ë¶„ì„ ë©”ì„œë“œ í¬í•¨ - ê°ë„, ë¹„ìœ¨, ëŒ€ì¹­ì„±, ê°€ì‹œì„±")
logger.info("ðŸ”„ COCO â†” OpenPose ë³€í™˜ ì§€ì›")
logger.info("ðŸŽ M3 Max 128GB ìµœì í™” + conda í™˜ê²½ ìµœì í™”")
logger.info("ðŸŽ¯ í•¨ìˆ˜ëª…/í´ëž˜ìŠ¤ëª… ì™„ì „ ìœ ì§€ - í”„ë¡ íŠ¸ì—”ë“œ í˜¸í™˜ì„± ë³´ìž¥")
logger.info("ðŸš« ì‹œë®¬ë ˆì´ì…˜/ë”ë¯¸ ë°ì´í„° ì™„ì „ ì œê±°")
logger.info("ðŸš€ ì™„ì „í•œ ì‹¤ì œ AI í¬ì¦ˆ ì¶”ì • ì‹œìŠ¤í…œ ì¤€ë¹„ ì™„ë£Œ")

# ì‹œìŠ¤í…œ ìƒíƒœ ë¡œê¹…
logger.info(f"ðŸ“Š ì‹œìŠ¤í…œ ìƒíƒœ: PyTorch={TORCH_AVAILABLE}, OpenCV={CV2_AVAILABLE}, PIL={PIL_AVAILABLE}")
logger.info(f"ðŸ”§ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë²„ì „: PyTorch={TORCH_VERSION}, OpenCV={CV2_VERSION}, PIL={PIL_VERSION}")
logger.info(f"ðŸ’¾ ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§: {'í™œì„±í™”' if PSUTIL_AVAILABLE else 'ë¹„í™œì„±í™”'}")
logger.info(f"ðŸ”— ì˜ì¡´ì„± ìƒíƒœ: ModelLoader={MODEL_LOADER_AVAILABLE}, MemoryManager={MEMORY_MANAGER_AVAILABLE}")

# =================================================================
# ðŸ”¥ ë©”ì¸ ì‹¤í–‰ë¶€ (ê°œë°œ ë° í…ŒìŠ¤íŠ¸ìš©)
# =================================================================

if __name__ == "__main__":
    # ì™„ì „í•œ ì‹¤ì œ AI í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    print("=" * 80)
    print("ðŸŽ¯ MyCloset AI Step 02 - ì™„ì „í•œ ì‹¤ì œ AI ì „ìš© ë²„ì „")
    print("=" * 80)
    
    # ë¹„ë™ê¸° í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    async def run_all_tests():
        await test_complete_real_ai_pose_estimation()
        print("\n" + "=" * 80)
        await test_model_loader_integration_complete()
        print("\n" + "=" * 80)
        test_keypoint_conversion()
    
    try:
        asyncio.run(run_all_tests())
    except Exception as e:
        print(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
    
    print("\n" + "=" * 80)
    print("âœ¨ ì™„ì „í•œ ì‹¤ì œ AI í¬ì¦ˆ ì¶”ì • ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
    print("ðŸš« í´ë°± ì™„ì „ ì œê±° - ì˜¤ì§ ì‹¤ì œ AI ëª¨ë¸ë§Œ ì‚¬ìš©")
    print("ðŸ”’ Strict Mode ì§€ì› - ì‹ ë¢°ì„± ë³´ìž¥")
    print("ðŸ”¬ ì™„ì „í•œ ë¶„ì„ ê¸°ëŠ¥ - ëª¨ë“  ë©”ì„œë“œ í¬í•¨")
    print("=" * 80)