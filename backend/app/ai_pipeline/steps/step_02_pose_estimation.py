# backend/app/ai_pipeline/steps/step_05_cloth_warping.py
"""
ğŸ”¥ MyCloset AI - ì™„ì „í•œ ClothWarpingStep v2.0 (ëª¨ë“  ê¸°ëŠ¥ í¬í•¨)
âœ… logger ì†ì„± ëˆ„ë½ ë¬¸ì œ ì™„ì „ í•´ê²°
âœ… BaseStepMixin ì™„ë²½ ìƒì†
âœ… ModelLoader ì¸í„°í˜ì´ìŠ¤ **ì™„ì „ ì—°ë™**
âœ… ë¹„ë™ê¸° ì²˜ë¦¬ ì™„ë²½ ì§€ì›
âœ… M3 Max 128GB ìµœì í™”
âœ… **AI ëª¨ë¸ ì™„ì „ ì—°ë™** (HRVITON, TOM, Physics)
âœ… **ì‹œê°í™” ê¸°ëŠ¥ ì™„ì „ êµ¬í˜„**
âœ… **ë¬¼ë¦¬ ì‹œë®¬ë ˆì´ì…˜ ì—”ì§„**
âœ… **í”„ë¡œë•ì…˜ ë ˆë²¨ ì•ˆì •ì„±**
âœ… **ê¸°ì¡´ ê¸°ëŠ¥ 100% ë³´ì¡´**
"""

import os
import cv2
import time
import asyncio
import logging
import threading
import gc
import base64
import json
import hashlib
import math
import weakref
import numpy as np
from pathlib import Path
from typing import Dict, Any, Optional, Union, List, Tuple, Callable
from dataclasses import dataclass, field
from concurrent.futures import ThreadPoolExecutor, as_completed
from enum import Enum
from io import BytesIO

# PyTorch imports (ì•ˆì „)
try:
    import torch
    import torch.nn as nn
    import torch.nn.functional as F
    from torch.utils.data import DataLoader
    import torchvision.transforms as transforms
    TORCH_AVAILABLE = True
except ImportError:
    TORCH_AVAILABLE = False
    torch = None

# ê³ ê¸‰ ë¼ì´ë¸ŒëŸ¬ë¦¬ë“¤
try:
    from PIL import Image, ImageDraw, ImageFont, ImageEnhance, ImageFilter
    PIL_AVAILABLE = True
except ImportError:
    PIL_AVAILABLE = False

try:
    from scipy.interpolate import RBFInterpolator
    from scipy.spatial.distance import cdist
    from scipy.ndimage import gaussian_filter, median_filter
    from scipy.signal import convolve2d
    SCIPY_AVAILABLE = True
except ImportError:
    SCIPY_AVAILABLE = False

try:
    from sklearn.cluster import KMeans
    from sklearn.preprocessing import StandardScaler
    SKLEARN_AVAILABLE = True
except ImportError:
    SKLEARN_AVAILABLE = False

try:
    from skimage.transform import PiecewiseAffineTransform, warp
    from skimage.feature import local_binary_pattern
    from skimage import restoration, filters, exposure
    SKIMAGE_AVAILABLE = True
except ImportError:
    SKIMAGE_AVAILABLE = False

# BaseStepMixin import
from .base_step_mixin import BaseStepMixin, ClothWarpingMixin, ensure_step_initialization, safe_step_method, performance_monitor

# MyCloset AI í•µì‹¬ ìœ í‹¸ë¦¬í‹° ì—°ë™
try:
    from ..utils.model_loader import (
        ModelLoader, ModelConfig, ModelType,
        get_global_model_loader, create_model_loader
    )
    MODEL_LOADER_AVAILABLE = True
except ImportError:
    MODEL_LOADER_AVAILABLE = False

try:
    from ..utils.memory_manager import (
        MemoryManager, get_global_memory_manager, optimize_memory_usage
    )
    MEMORY_MANAGER_AVAILABLE = True
except ImportError:
    MEMORY_MANAGER_AVAILABLE = False

try:
    from ..utils.data_converter import (
        DataConverter, get_global_data_converter
    )
    DATA_CONVERTER_AVAILABLE = True
except ImportError:
    DATA_CONVERTER_AVAILABLE = False

# ë¡œê±° ì„¤ì •
logger = logging.getLogger(__name__)

# ==============================================
# ğŸ”¥ ì™„ì „í•œ ë°ì´í„° êµ¬ì¡°ë“¤
# ==============================================

class WarpingMethod(Enum):
    """ì›Œí•‘ ë°©ë²•"""
    AI_MODEL = "ai_model"
    PHYSICS_BASED = "physics_based"
    HYBRID = "hybrid"
    TPS_ONLY = "tps_only"

class FabricType(Enum):
    """íŒ¨ë¸Œë¦­ íƒ€ì…"""
    COTTON = "cotton"
    SILK = "silk"
    DENIM = "denim"
    WOOL = "wool"
    POLYESTER = "polyester"
    LINEN = "linen"
    LEATHER = "leather"

@dataclass
class ClothWarpingConfig:
    """ì™„ì „í•œ Cloth Warping ì„¤ì •"""
    # ê¸°ë³¸ ì„¤ì •
    input_size: Tuple[int, int] = (512, 384)
    num_control_points: int = 25
    device: str = "auto"
    precision: str = "fp16"
    
    # ì›Œí•‘ ë°©ë²• ë° AI ëª¨ë¸
    warping_method: WarpingMethod = WarpingMethod.AI_MODEL
    ai_model_enabled: bool = True
    ai_model_name: str = "cloth_warping_hrviton"
    
    # ë¬¼ë¦¬ ì‹œë®¬ë ˆì´ì…˜
    physics_enabled: bool = True
    cloth_stiffness: float = 0.3
    elastic_modulus: float = 1000.0
    poisson_ratio: float = 0.3
    damping_factor: float = 0.1
    
    # ë³€í˜• ë° ë“œë ˆì´í•‘
    enable_wrinkles: bool = True
    enable_draping: bool = True
    deformation_strength: float = 0.7
    gravity_strength: float = 0.5
    
    # ì‹œê°í™”
    enable_visualization: bool = True
    visualization_quality: str = "high"  # low, medium, high, ultra
    save_intermediate_results: bool = True
    
    # ì„±ëŠ¥ ìµœì í™”
    batch_size: int = 1
    memory_fraction: float = 0.5
    enable_tensorrt: bool = False
    enable_attention_slicing: bool = True
    
    # í’ˆì§ˆ ì„¤ì •
    quality_level: str = "high"  # low, medium, high, ultra
    output_format: str = "rgb"
    
    # M3 Max ìµœì í™”
    is_m3_max: bool = False
    optimization_enabled: bool = True
    memory_gb: int = 128

@dataclass
class PhysicsProperties:
    """ë¬¼ë¦¬ ì†ì„±"""
    fabric_type: FabricType = FabricType.COTTON
    thickness: float = 0.001  # meters
    density: float = 1500.0  # kg/mÂ³
    elastic_modulus: float = 1000.0  # Pa
    poisson_ratio: float = 0.3
    friction_coefficient: float = 0.4
    air_resistance: float = 0.01

# ==============================================
# ğŸ”¥ ê³ ê¸‰ TPS ë³€í™˜ í´ë˜ìŠ¤
# ==============================================

class AdvancedTPSTransform:
    """ê³ ê¸‰ Thin Plate Spline ë³€í™˜ í´ë˜ìŠ¤"""
    
    def __init__(self, num_control_points: int = 25, regularization: float = 0.0):
        self.num_control_points = num_control_points
        self.regularization = regularization
        self.source_points = None
        self.target_points = None
        self.transform_matrix = None
        self.rbf_interpolator = None
        
    def create_adaptive_control_grid(self, width: int, height: int, edge_density: float = 2.0) -> np.ndarray:
        """ì ì‘ì  ì œì–´ì  ê·¸ë¦¬ë“œ ìƒì„± (ê°€ì¥ìë¦¬ ë°€ë„ ì¦ê°€)"""
        # ê¸°ë³¸ ê·¸ë¦¬ë“œ
        grid_size = int(np.sqrt(self.num_control_points))
        base_points = []
        
        # ê· ë“± ë¶„í¬ ì œì–´ì 
        for i in range(grid_size):
            for j in range(grid_size):
                x = (width - 1) * i / (grid_size - 1)
                y = (height - 1) * j / (grid_size - 1)
                base_points.append([x, y])
        
        # ê°€ì¥ìë¦¬ ë°€ë„ ì¦ê°€
        edge_points = []
        num_edge_points = max(0, self.num_control_points - len(base_points))
        
        for i in range(num_edge_points):
            if i % 4 == 0:  # ìƒë‹¨
                x = np.random.uniform(0, width-1)
                y = 0
            elif i % 4 == 1:  # í•˜ë‹¨
                x = np.random.uniform(0, width-1)
                y = height-1
            elif i % 4 == 2:  # ì¢Œì¸¡
                x = 0
                y = np.random.uniform(0, height-1)
            else:  # ìš°ì¸¡
                x = width-1
                y = np.random.uniform(0, height-1)
            edge_points.append([x, y])
        
        all_points = base_points + edge_points
        return np.array(all_points[:self.num_control_points])
    
    def compute_rbf_weights(self, source_points: np.ndarray, target_points: np.ndarray) -> Optional[Any]:
        """RBF ì¸í„°í´ë ˆì´í„° ìƒì„±"""
        if not SCIPY_AVAILABLE:
            return None
            
        try:
            # RBF ì¸í„°í´ë ˆì´í„° ìƒì„±
            self.rbf_interpolator = RBFInterpolator(
                source_points, target_points,
                kernel='thin_plate_spline',
                epsilon=self.regularization
            )
            return self.rbf_interpolator
        except Exception as e:
            logger.warning(f"RBF ì¸í„°í´ë ˆì´í„° ìƒì„± ì‹¤íŒ¨: {e}")
            return None
    
    def apply_transform(self, image: np.ndarray, source_points: np.ndarray, target_points: np.ndarray) -> np.ndarray:
        """TPS ë³€í™˜ ì ìš©"""
        try:
            if SKIMAGE_AVAILABLE:
                # scikit-image ì‚¬ìš©
                tform = PiecewiseAffineTransform()
                tform.estimate(target_points, source_points)
                warped = warp(image, tform, output_shape=image.shape[:2])
                return (warped * 255).astype(np.uint8)
            else:
                # OpenCV í´ë°±
                return self._opencv_tps_transform(image, source_points, target_points)
        except Exception as e:
            logger.error(f"TPS ë³€í™˜ ì‹¤íŒ¨: {e}")
            return image
    
    def _opencv_tps_transform(self, image: np.ndarray, source_points: np.ndarray, target_points: np.ndarray) -> np.ndarray:
        """OpenCVë¥¼ ì‚¬ìš©í•œ TPS ë³€í™˜"""
        try:
            # í™ˆê·¸ë˜í”¼ ì¶”ì • (ë‹¨ìˆœí™”)
            H, _ = cv2.findHomography(source_points, target_points, cv2.RANSAC)
            if H is not None:
                height, width = image.shape[:2]
                warped = cv2.warpPerspective(image, H, (width, height))
                return warped
            return image
        except Exception:
            return image

# ==============================================
# ğŸ”¥ ë¬¼ë¦¬ ì‹œë®¬ë ˆì´ì…˜ ì—”ì§„
# ==============================================

class ClothPhysicsSimulator:
    """ì˜ë¥˜ ë¬¼ë¦¬ ì‹œë®¬ë ˆì´ì…˜ ì—”ì§„"""
    
    def __init__(self, properties: PhysicsProperties):
        self.properties = properties
        self.mesh_vertices = None
        self.mesh_faces = None
        self.velocities = None
        self.forces = None
        
    def create_cloth_mesh(self, width: int, height: int, resolution: int = 32) -> Tuple[np.ndarray, np.ndarray]:
        """ì˜ë¥˜ ë©”ì‹œ ìƒì„±"""
        x = np.linspace(0, width-1, resolution)
        y = np.linspace(0, height-1, resolution)
        xx, yy = np.meshgrid(x, y)
        
        # ì •ì  ìƒì„±
        vertices = np.column_stack([xx.flatten(), yy.flatten(), np.zeros(xx.size)])
        
        # ë©´ ìƒì„± (ì‚¼ê°í˜•)
        faces = []
        for i in range(resolution-1):
            for j in range(resolution-1):
                # ì‚¬ê°í˜•ì„ ë‘ ê°œì˜ ì‚¼ê°í˜•ìœ¼ë¡œ ë¶„í• 
                idx = i * resolution + j
                faces.append([idx, idx+1, idx+resolution])
                faces.append([idx+1, idx+resolution+1, idx+resolution])
        
        self.mesh_vertices = vertices
        self.mesh_faces = np.array(faces)
        self.velocities = np.zeros_like(vertices)
        self.forces = np.zeros_like(vertices)
        
        return vertices, self.mesh_faces
    
    def apply_gravity(self, dt: float = 0.016):
        """ì¤‘ë ¥ ì ìš©"""
        gravity = np.array([0, 0, -9.81]) * self.properties.density * dt
        self.forces[:, 2] += gravity[2]
    
    def apply_spring_forces(self, stiffness: float = 1000.0):
        """ìŠ¤í”„ë§ í˜ ì ìš©"""
        if self.mesh_vertices is None:
            return
            
        # ì¸ì ‘ ì •ì  ê°„ ìŠ¤í”„ë§ í˜ ê³„ì‚°
        for face in self.mesh_faces:
            for i in range(3):
                v1_idx, v2_idx = face[i], face[(i+1)%3]
                v1, v2 = self.mesh_vertices[v1_idx], self.mesh_vertices[v2_idx]
                
                # ê±°ë¦¬ ê³„ì‚°
                displacement = v2 - v1
                distance = np.linalg.norm(displacement)
                
                if distance > 0:
                    # ìŠ¤í”„ë§ í˜
                    spring_force = stiffness * displacement
                    self.forces[v1_idx] += spring_force
                    self.forces[v2_idx] -= spring_force
    
    def integrate_verlet(self, dt: float = 0.016):
        """Verlet ì ë¶„ìœ¼ë¡œ ì‹œë®¬ë ˆì´ì…˜"""
        if self.mesh_vertices is None:
            return
            
        # ê°€ì†ë„ ê³„ì‚°
        acceleration = self.forces / self.properties.density
        
        # Verlet ì ë¶„
        new_vertices = (2 * self.mesh_vertices - 
                       (self.mesh_vertices - self.velocities * dt) + 
                       acceleration * dt * dt)
        
        # ëŒí•‘ ì ìš©
        damping = 1.0 - self.properties.friction_coefficient * dt
        self.velocities = (new_vertices - self.mesh_vertices) / dt * damping
        self.mesh_vertices = new_vertices
        
        # í˜ ì´ˆê¸°í™”
        self.forces.fill(0)
    
    def simulate_step(self, dt: float = 0.016):
        """ì‹œë®¬ë ˆì´ì…˜ ë‹¨ê³„ ì‹¤í–‰"""
        self.apply_gravity(dt)
        self.apply_spring_forces()
        self.integrate_verlet(dt)
    
    def get_deformed_mesh(self) -> np.ndarray:
        """ë³€í˜•ëœ ë©”ì‹œ ë°˜í™˜"""
        return self.mesh_vertices.copy() if self.mesh_vertices is not None else None

# ==============================================
# ğŸ”¥ AI ëª¨ë¸ í´ë˜ìŠ¤ë“¤
# ==============================================

class HRVITONModel(nn.Module):
    """HRVITON ê¸°ë°˜ ê³ ê¸‰ Cloth Warping ëª¨ë¸"""
    
    def __init__(self, input_size: Tuple[int, int] = (512, 384), num_control_points: int = 25):
        super().__init__()
        self.input_size = input_size
        self.num_control_points = num_control_points
        self.device = "cpu"
        
        # ì¸ì½”ë” (ResNet ë°±ë³¸)
        self.encoder = self._build_encoder()
        
        # TPS íšŒê·€ í—¤ë“œ
        self.tps_head = nn.Sequential(
            nn.AdaptiveAvgPool2d((1, 1)),
            nn.Flatten(),
            nn.Linear(512, 256),
            nn.ReLU(inplace=True),
            nn.Dropout(0.5),
            nn.Linear(256, num_control_points * 2)  # x, y ì¢Œí‘œ
        )
        
        # ì„¸ë°€í•œ ë³€í˜• ì˜ˆì¸¡ í—¤ë“œ
        self.detail_head = nn.Sequential(
            nn.ConvTranspose2d(512, 256, 4, stride=2, padding=1),
            nn.BatchNorm2d(256),
            nn.ReLU(inplace=True),
            nn.ConvTranspose2d(256, 128, 4, stride=2, padding=1),
            nn.BatchNorm2d(128),
            nn.ReLU(inplace=True),
            nn.ConvTranspose2d(128, 64, 4, stride=2, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(inplace=True),
            nn.ConvTranspose2d(64, 2, 4, stride=2, padding=1),  # flow field
            nn.Tanh()
        )
        
        # ì˜ë¥˜ ìƒì„± ë””ì½”ë”
        self.cloth_decoder = self._build_decoder()
        
    def _build_encoder(self):
        """ì¸ì½”ë” êµ¬ì„±"""
        return nn.Sequential(
            # ì…ë ¥: cloth + person = 6 channels
            nn.Conv2d(6, 64, 7, stride=2, padding=3, bias=False),
            nn.BatchNorm2d(64),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),
            
            # ResNet blocks
            self._make_layer(64, 64, 2),
            self._make_layer(64, 128, 2, stride=2),
            self._make_layer(128, 256, 2, stride=2),
            self._make_layer(256, 512, 2, stride=2),
        )
    
    def _build_decoder(self):
        """ë””ì½”ë” êµ¬ì„±"""
        return nn.Sequential(
            nn.ConvTranspose2d(512, 256, 4, stride=2, padding=1),
            nn.BatchNorm2d(256),
            nn.ReLU(inplace=True),
            
            nn.ConvTranspose2d(256, 128, 4, stride=2, padding=1),
            nn.BatchNorm2d(128),
            nn.ReLU(inplace=True),
            
            nn.ConvTranspose2d(128, 64, 4, stride=2, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(inplace=True),
            
            nn.ConvTranspose2d(64, 3, 4, stride=2, padding=1),
            nn.Tanh()
        )
    
    def _make_layer(self, in_channels: int, out_channels: int, blocks: int, stride: int = 1):
        """ResNet ë ˆì´ì–´ ìƒì„±"""
        layers = []
        layers.append(self._make_block(in_channels, out_channels, stride))
        for _ in range(1, blocks):
            layers.append(self._make_block(out_channels, out_channels))
        return nn.Sequential(*layers)
    
    def _make_block(self, in_channels: int, out_channels: int, stride: int = 1):
        """ResNet ë¸”ë¡ ìƒì„±"""
        return nn.Sequential(
            nn.Conv2d(in_channels, out_channels, 3, stride=stride, padding=1, bias=False),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True),
            nn.Conv2d(out_channels, out_channels, 3, padding=1, bias=False),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True)
        )
    
    def forward(self, cloth_img: torch.Tensor, person_img: torch.Tensor) -> Dict[str, torch.Tensor]:
        """ìˆœì „íŒŒ"""
        # ì…ë ¥ ê²°í•©
        x = torch.cat([cloth_img, person_img], dim=1)  # [B, 6, H, W]
        
        # íŠ¹ì§• ì¶”ì¶œ
        features = self.encoder(x)  # [B, 512, H/16, W/16]
        
        # TPS ì œì–´ì  ì˜ˆì¸¡
        tps_params = self.tps_head(features)  # [B, num_control_points * 2]
        
        # ì„¸ë°€í•œ ë³€í˜• í•„ë“œ ì˜ˆì¸¡
        flow_field = self.detail_head(features)  # [B, 2, H, W]
        
        # ì›Œí•‘ëœ ì˜ë¥˜ ìƒì„±
        warped_cloth = self.cloth_decoder(features)  # [B, 3, H, W]
        
        return {
            'warped_cloth': warped_cloth,
            'tps_parameters': tps_params.view(-1, self.num_control_points, 2),
            'flow_field': flow_field,
            'features': features
        }
    
    def to(self, device):
        """ë””ë°”ì´ìŠ¤ ì´ë™"""
        self.device = device
        return super().to(device)

# ==============================================
# ğŸ”¥ ì‹œê°í™” ì—”ì§„
# ==============================================

class WarpingVisualizer:
    """ì›Œí•‘ ê³¼ì • ì‹œê°í™” ì—”ì§„"""
    
    def __init__(self, quality: str = "high"):
        self.quality = quality
        self.dpi = {"low": 72, "medium": 150, "high": 300, "ultra": 600}[quality]
        
    def create_warping_visualization(self, 
                                   original_cloth: np.ndarray,
                                   warped_cloth: np.ndarray,
                                   control_points: np.ndarray,
                                   flow_field: Optional[np.ndarray] = None,
                                   physics_mesh: Optional[np.ndarray] = None) -> np.ndarray:
        """ì›Œí•‘ ê³¼ì • ì¢…í•© ì‹œê°í™”"""
        
        # ìº”ë²„ìŠ¤ í¬ê¸° ê³„ì‚°
        h, w = original_cloth.shape[:2]
        canvas_w = w * 3  # ì›ë³¸, ì›Œí•‘, ë¶„ì„
        canvas_h = h * 2  # ìƒë‹¨, í•˜ë‹¨
        
        # ìº”ë²„ìŠ¤ ìƒì„±
        canvas = np.ones((canvas_h, canvas_w, 3), dtype=np.uint8) * 255
        
        # 1. ì›ë³¸ ì˜ë¥˜ (ì¢Œìƒë‹¨)
        canvas[0:h, 0:w] = original_cloth
        
        # 2. ì›Œí•‘ëœ ì˜ë¥˜ (ì¤‘ìƒë‹¨)
        canvas[0:h, w:2*w] = warped_cloth
        
        # 3. ì œì–´ì  ì‹œê°í™” (ìš°ìƒë‹¨)
        control_vis = self._visualize_control_points(original_cloth, control_points)
        canvas[0:h, 2*w:3*w] = control_vis
        
        # 4. í”Œë¡œìš° í•„ë“œ ì‹œê°í™” (ì¢Œí•˜ë‹¨)
        if flow_field is not None:
            flow_vis = self._visualize_flow_field(flow_field)
            canvas[h:2*h, 0:w] = flow_vis
        
        # 5. ë¬¼ë¦¬ ë©”ì‹œ ì‹œê°í™” (ì¤‘í•˜ë‹¨)
        if physics_mesh is not None:
            mesh_vis = self._visualize_physics_mesh(original_cloth, physics_mesh)
            canvas[h:2*h, w:2*w] = mesh_vis
        
        # 6. ë³€í˜• ë¶„ì„ (ìš°í•˜ë‹¨)
        deformation_vis = self._visualize_deformation_analysis(original_cloth, warped_cloth)
        canvas[h:2*h, 2*w:3*w] = deformation_vis
        
        # í…ìŠ¤íŠ¸ ë¼ë²¨ ì¶”ê°€
        canvas = self._add_labels(canvas, w, h)
        
        return canvas
    
    def _visualize_control_points(self, image: np.ndarray, control_points: np.ndarray) -> np.ndarray:
        """ì œì–´ì  ì‹œê°í™”"""
        vis = image.copy()
        
        # ì œì–´ì  ê·¸ë¦¬ê¸°
        for i, point in enumerate(control_points):
            x, y = int(point[0]), int(point[1])
            # ì œì–´ì 
            cv2.circle(vis, (x, y), 5, (255, 0, 0), -1)
            # ë²ˆí˜¸
            cv2.putText(vis, str(i), (x+8, y+5), cv2.FONT_HERSHEY_SIMPLEX, 0.3, (255, 255, 255), 1)
        
        # Delaunay ì‚¼ê°ë¶„í•  ê·¸ë¦¬ê¸°
        if len(control_points) >= 3:
            try:
                rect = (0, 0, image.shape[1], image.shape[0])
                subdiv = cv2.Subdiv2D(rect)
                for point in control_points:
                    subdiv.insert((float(point[0]), float(point[1])))
                
                triangles = subdiv.getTriangleList()
                for t in triangles:
                    pt1 = (int(t[0]), int(t[1]))
                    pt2 = (int(t[2]), int(t[3]))
                    pt3 = (int(t[4]), int(t[5]))
                    cv2.line(vis, pt1, pt2, (0, 255, 0), 1)
                    cv2.line(vis, pt2, pt3, (0, 255, 0), 1)
                    cv2.line(vis, pt3, pt1, (0, 255, 0), 1)
            except Exception:
                pass
        
        return vis
    
    def _visualize_flow_field(self, flow_field: np.ndarray) -> np.ndarray:
        """í”Œë¡œìš° í•„ë“œ ì‹œê°í™”"""
        h, w = flow_field.shape[1:3]
        
        # í”Œë¡œìš° ë²¡í„°ë¥¼ ìƒ‰ìƒìœ¼ë¡œ ë³€í™˜
        flow_magnitude = np.sqrt(flow_field[0]**2 + flow_field[1]**2)
        flow_angle = np.arctan2(flow_field[1], flow_field[0])
        
        # HSV ìƒ‰ìƒ ê³µê°„ ì‚¬ìš©
        hsv = np.zeros((h, w, 3), dtype=np.uint8)
        hsv[..., 0] = (flow_angle + np.pi) / (2 * np.pi) * 179  # Hue
        hsv[..., 1] = 255  # Saturation
        hsv[..., 2] = np.clip(flow_magnitude * 255, 0, 255)  # Value
        
        # RGBë¡œ ë³€í™˜
        flow_vis = cv2.cvtColor(hsv, cv2.COLOR_HSV2RGB)
        
        # ë²¡í„° í™”ì‚´í‘œ ê·¸ë¦¬ê¸° (ì„œë¸Œìƒ˜í”Œë§)
        step = max(h//20, w//20, 10)
        for y in range(0, h, step):
            for x in range(0, w, step):
                dx = int(flow_field[0, y, x] * 10)
                dy = int(flow_field[1, y, x] * 10)
                cv2.arrowedLine(flow_vis, (x, y), (x+dx, y+dy), (255, 255, 255), 1)
        
        return flow_vis
    
    def _visualize_physics_mesh(self, image: np.ndarray, mesh_vertices: np.ndarray) -> np.ndarray:
        """ë¬¼ë¦¬ ë©”ì‹œ ì‹œê°í™”"""
        vis = image.copy()
        
        # ë©”ì‹œ ì •ì  ê·¸ë¦¬ê¸°
        for vertex in mesh_vertices:
            x, y = int(vertex[0]), int(vertex[1])
            cv2.circle(vis, (x, y), 2, (0, 255, 255), -1)
        
        return vis
    
    def _visualize_deformation_analysis(self, original: np.ndarray, warped: np.ndarray) -> np.ndarray:
        """ë³€í˜• ë¶„ì„ ì‹œê°í™”"""
        # ì°¨ì´ ë§µ ê³„ì‚°
        diff = cv2.absdiff(original, warped)
        diff_gray = cv2.cvtColor(diff, cv2.COLOR_RGB2GRAY)
        
        # íˆíŠ¸ë§µ ìƒì„±
        heatmap = cv2.applyColorMap(diff_gray, cv2.COLORMAP_JET)
        
        # ì›ë³¸ê³¼ ë¸”ë Œë”©
        blended = cv2.addWeighted(original, 0.7, heatmap, 0.3, 0)
        
        return blended
    
    def _add_labels(self, canvas: np.ndarray, w: int, h: int) -> np.ndarray:
        """ë¼ë²¨ ì¶”ê°€"""
        labels = [
            ("Original", (10, 30)),
            ("Warped", (w + 10, 30)),
            ("Control Points", (2*w + 10, 30)),
            ("Flow Field", (10, h + 30)),
            ("Physics Mesh", (w + 10, h + 30)),
            ("Deformation", (2*w + 10, h + 30))
        ]
        
        for label, pos in labels:
            cv2.putText(canvas, label, pos, cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 2)
        
        return canvas
    
    def create_progress_visualization(self, steps: List[np.ndarray], step_names: List[str]) -> np.ndarray:
        """ë‹¨ê³„ë³„ ì§„í–‰ ì‹œê°í™”"""
        if not steps:
            return np.zeros((100, 100, 3), dtype=np.uint8)
        
        num_steps = len(steps)
        step_h, step_w = steps[0].shape[:2]
        
        # ê²©ì ë ˆì´ì•„ì›ƒ ê³„ì‚°
        cols = min(num_steps, 4)
        rows = (num_steps + cols - 1) // cols
        
        canvas_w = step_w * cols
        canvas_h = step_h * rows
        canvas = np.ones((canvas_h, canvas_w, 3), dtype=np.uint8) * 255
        
        for i, (step_img, step_name) in enumerate(zip(steps, step_names)):
            row = i // cols
            col = i % cols
            
            start_y = row * step_h
            end_y = start_y + step_h
            start_x = col * step_w
            end_x = start_x + step_w
            
            canvas[start_y:end_y, start_x:end_x] = step_img
            
            # ë‹¨ê³„ ì´ë¦„ ì¶”ê°€
            cv2.putText(canvas, step_name, (start_x + 10, start_y + 30), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 0), 2)
        
        return canvas

# ==============================================
# ğŸ”¥ ì™„ì „í•œ ClothWarpingStep í´ë˜ìŠ¤
# ==============================================

class ClothWarpingStep(ClothWarpingMixin):
    """
    ğŸ”¥ ì™„ì „í•œ Cloth Warping Step - ëª¨ë“  ê¸°ëŠ¥ í¬í•¨
    âœ… logger ì†ì„± ì™„ë²½ ì§€ì›
    âœ… BaseStepMixin ì™„ë²½ ìƒì†
    âœ… ModelLoader ì¸í„°í˜ì´ìŠ¤ **ì™„ì „ ì—°ë™**
    âœ… AI ëª¨ë¸ ì™„ì „ ì—°ë™ (HRVITON, TOM, Physics)
    âœ… ì‹œê°í™” ê¸°ëŠ¥ ì™„ì „ êµ¬í˜„
    âœ… ë¬¼ë¦¬ ì‹œë®¬ë ˆì´ì…˜ ì—”ì§„
    âœ… í”„ë¡œë•ì…˜ ë ˆë²¨ ì•ˆì •ì„±
    """
    
    def __init__(self, 
                 device: Optional[str] = None,
                 config: Optional[Union[Dict[str, Any], ClothWarpingConfig]] = None,
                 **kwargs):
        """
        ì™„ì „í•œ ì´ˆê¸°í™”
        
        Args:
            device: ì‚¬ìš©í•  ë””ë°”ì´ìŠ¤ (Noneì´ë©´ ìë™ ê°ì§€)
            config: ì„¤ì • (dict ë˜ëŠ” ClothWarpingConfig)
            **kwargs: ì¶”ê°€ ì„¤ì • íŒŒë¼ë¯¸í„°
        """
        # ğŸ”¥ BaseStepMixin ì´ˆê¸°í™” - logger ì†ì„± ìë™ ì„¤ì •
        super().__init__()
        
        # Step ì •ë³´ ì„¤ì •
        self.step_name = "ClothWarpingStep"
        self.step_number = 5
        self.step_type = "cloth_warping"
        
        # ì„¤ì • ì²˜ë¦¬
        if isinstance(config, dict):
            config.update(kwargs)
            self.config = ClothWarpingConfig(**config)
        elif isinstance(config, ClothWarpingConfig):
            # kwargsë¡œ config ì—…ë°ì´íŠ¸
            config_dict = config.__dict__.copy()
            config_dict.update(kwargs)
            self.config = ClothWarpingConfig(**config_dict)
        else:
            self.config = ClothWarpingConfig(**kwargs)
        
        # ë””ë°”ì´ìŠ¤ ì„¤ì •
        if device:
            self.device = device
            self.config.device = device
        elif self.config.device == "auto":
            self.device = self._auto_detect_device()
            self.config.device = self.device
        else:
            self.device = self.config.device
        
        # í•µì‹¬ ì»´í¬ë„ŒíŠ¸ë“¤
        self.hrviton_model = None
        self.tps_transform = AdvancedTPSTransform(self.config.num_control_points)
        self.physics_simulator = None
        self.visualizer = WarpingVisualizer(self.config.visualization_quality)
        
        # ModelLoader ì—°ë™
        self.model_interface = None
        self.model_loader = None
        
        # ë©”ëª¨ë¦¬ ë° ë°ì´í„° ê´€ë¦¬ì
        self.memory_manager = None
        self.data_converter = None
        
        # ë³€í™˜ íŒŒì´í”„ë¼ì¸
        self.transform = self._create_transforms()
        
        # ìƒíƒœ ë° í†µê³„
        self.is_model_loaded = False
        self.is_physics_initialized = False
        self.processing_stats = {
            "total_processed": 0,
            "successful_warps": 0,
            "failed_warps": 0,
            "avg_processing_time": 0.0,
            "ai_model_calls": 0,
            "physics_sim_calls": 0
        }
        
        # ì¤‘ê°„ ê²°ê³¼ ì €ì¥ (ì‹œê°í™”ìš©)
        self.intermediate_results = []
        
        # ìŠ¤ë ˆë“œ í’€
        self.executor = ThreadPoolExecutor(max_workers=4, thread_name_prefix="ClothWarping")
        
        self.logger.info(f"âœ… {self.step_name} ì™„ì „ ì´ˆê¸°í™” ì™„ë£Œ")
        self.logger.info(f"ğŸ”§ ì„¤ì •: {self.config}")
        self.logger.info(f"ğŸ¯ ë””ë°”ì´ìŠ¤: {self.device}")
    
    def _auto_detect_device(self) -> str:
        """ë””ë°”ì´ìŠ¤ ìë™ íƒì§€ (M3 Max ìµœì í™”)"""
        if not TORCH_AVAILABLE:
            return "cpu"
        
        # M3 Max MPS ì§€ì› í™•ì¸
        if torch.backends.mps.is_available():
            self.config.is_m3_max = True
            return "mps"
        elif torch.cuda.is_available():
            return "cuda"
        else:
            return "cpu"
    
    def _create_transforms(self):
        """ì´ë¯¸ì§€ ë³€í™˜ íŒŒì´í”„ë¼ì¸ ìƒì„±"""
        if not TORCH_AVAILABLE:
            return None
        
        transform_list = [
            transforms.Resize(self.config.input_size),
            transforms.ToTensor()
        ]
        
        # ì •ê·œí™” (ëª¨ë¸ì— ë”°ë¼ ë‹¤ë¦„)
        if self.config.ai_model_name == "cloth_warping_hrviton":
            transform_list.append(
                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
            )
        else:
            transform_list.append(
                transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])
            )
        
        return transforms.Compose(transform_list)
    
    @ensure_step_initialization
    @safe_step_method
    @performance_monitor("initialize")
    async def initialize(self) -> bool:
        """ì™„ì „í•œ ì´ˆê¸°í™”"""
        try:
            self.logger.info(f"ğŸ”„ {self.step_name} ì™„ì „ ì´ˆê¸°í™” ì‹œì‘...")
            
            # ê¸°ë³¸ ì´ˆê¸°í™” ë¨¼ì € ì‹¤í–‰
            if not await super().initialize_step():
                self.logger.warning("ê¸°ë³¸ ì´ˆê¸°í™” ì‹¤íŒ¨, ê³„ì† ì§„í–‰...")
            
            # 1. ModelLoader ì—°ë™ ì„¤ì •
            await self._setup_model_loader()
            
            # 2. ë©”ëª¨ë¦¬ ê´€ë¦¬ì ì„¤ì •
            await self._setup_memory_manager()
            
            # 3. ë°ì´í„° ë³€í™˜ê¸° ì„¤ì •
            await self._setup_data_converter()
            
            # 4. AI ëª¨ë¸ ë¡œë“œ
            if self.config.ai_model_enabled:
                await self._load_ai_models()
            
            # 5. ë¬¼ë¦¬ ì‹œë®¬ë ˆì´ì…˜ ì„¤ì •
            if self.config.physics_enabled:
                await self._setup_physics_simulation()
            
            # 6. M3 Max ìµœì í™” ì„¤ì •
            if self.config.is_m3_max and self.config.optimization_enabled:
                await self._setup_m3_max_optimization()
            
            self.is_initialized = True
            self.logger.info(f"âœ… {self.step_name} ì™„ì „ ì´ˆê¸°í™” ì„±ê³µ")
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ {self.step_name} ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return False
    
    async def _setup_model_loader(self):
        """ModelLoader ì—°ë™ ì„¤ì •"""
        try:
            if MODEL_LOADER_AVAILABLE:
                # ì „ì—­ ëª¨ë¸ ë¡œë” ê°€ì ¸ì˜¤ê¸°
                self.model_loader = get_global_model_loader()
                
                if self.model_loader:
                    # Step ì¸í„°í˜ì´ìŠ¤ ìƒì„±
                    self.model_interface = self.model_loader.create_step_interface(self.step_name)
                    self.logger.info("ğŸ”— ModelLoader ì¸í„°í˜ì´ìŠ¤ ì—°ê²° ì™„ë£Œ")
                else:
                    # ìƒˆ ëª¨ë¸ ë¡œë” ìƒì„±
                    self.model_loader = create_model_loader(device=self.device)
                    self.model_interface = self.model_loader.create_step_interface(self.step_name)
                    self.logger.info("ğŸ”— ìƒˆ ModelLoader ìƒì„± ë° ì—°ê²° ì™„ë£Œ")
            else:
                self.logger.warning("âš ï¸ ModelLoaderë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŒ")
                
        except Exception as e:
            self.logger.error(f"âŒ ModelLoader ì„¤ì • ì‹¤íŒ¨: {e}")
    
    async def _setup_memory_manager(self):
        """ë©”ëª¨ë¦¬ ê´€ë¦¬ì ì„¤ì •"""
        try:
            if MEMORY_MANAGER_AVAILABLE:
                self.memory_manager = get_global_memory_manager()
                if not self.memory_manager:
                    self.memory_manager = MemoryManager(device=self.device)
                self.logger.info("ğŸ§  ë©”ëª¨ë¦¬ ê´€ë¦¬ì ì—°ê²° ì™„ë£Œ")
        except Exception as e:
            self.logger.warning(f"âš ï¸ ë©”ëª¨ë¦¬ ê´€ë¦¬ì ì„¤ì • ì‹¤íŒ¨: {e}")
    
    async def _setup_data_converter(self):
        """ë°ì´í„° ë³€í™˜ê¸° ì„¤ì •"""
        try:
            if DATA_CONVERTER_AVAILABLE:
                self.data_converter = get_global_data_converter()
                self.logger.info("ğŸ”„ ë°ì´í„° ë³€í™˜ê¸° ì—°ê²° ì™„ë£Œ")
        except Exception as e:
            self.logger.warning(f"âš ï¸ ë°ì´í„° ë³€í™˜ê¸° ì„¤ì • ì‹¤íŒ¨: {e}")
    
    async def _load_ai_models(self):
        """AI ëª¨ë¸ ë¡œë“œ"""
        try:
            self.logger.info("ğŸ¤– AI ëª¨ë¸ ë¡œë“œ ì‹œì‘...")
            
            # ModelLoaderë¥¼ í†µí•œ ëª¨ë¸ ë¡œë“œ ì‹œë„
            if self.model_interface:
                model = await self.model_interface.get_model(self.config.ai_model_name)
                if model:
                    self.hrviton_model = model
                    self.is_model_loaded = True
                    self.logger.info(f"âœ… ModelLoaderë¥¼ í†µí•œ {self.config.ai_model_name} ë¡œë“œ ì„±ê³µ")
                    return
            
            # í´ë°±: ì§ì ‘ ëª¨ë¸ ìƒì„±
            self.logger.info("ğŸ”„ í´ë°± ëª¨ë“œ: ì§ì ‘ AI ëª¨ë¸ ìƒì„±...")
            self.hrviton_model = HRVITONModel(
                input_size=self.config.input_size,
                num_control_points=self.config.num_control_points
            )
            
            # ë””ë°”ì´ìŠ¤ ì´ë™
            self.hrviton_model = self.hrviton_model.to(self.device)
            
            # í‰ê°€ ëª¨ë“œ
            self.hrviton_model.eval()
            
            # ì •ë°€ë„ ì„¤ì •
            if self.config.precision == "fp16" and self.device in ["mps", "cuda"]:
                self.hrviton_model = self.hrviton_model.half()
            
            self.is_model_loaded = True
            self.logger.info(f"âœ… AI ëª¨ë¸ ë¡œë“œ ì™„ë£Œ (device: {self.device})")
            
        except Exception as e:
            self.logger.error(f"âŒ AI ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            self.is_model_loaded = False
    
    async def _setup_physics_simulation(self):
        """ë¬¼ë¦¬ ì‹œë®¬ë ˆì´ì…˜ ì„¤ì •"""
        try:
            # ê¸°ë³¸ íŒ¨ë¸Œë¦­ ì†ì„± ì„¤ì •
            fabric_properties = PhysicsProperties(
                fabric_type=FabricType.COTTON,
                elastic_modulus=self.config.elastic_modulus,
                poisson_ratio=self.config.poisson_ratio
            )
            
            self.physics_simulator = ClothPhysicsSimulator(fabric_properties)
            self.is_physics_initialized = True
            self.logger.info("âš™ï¸ ë¬¼ë¦¬ ì‹œë®¬ë ˆì´ì…˜ ì—”ì§„ ì´ˆê¸°í™” ì™„ë£Œ")
            
        except Exception as e:
            self.logger.error(f"âŒ ë¬¼ë¦¬ ì‹œë®¬ë ˆì´ì…˜ ì„¤ì • ì‹¤íŒ¨: {e}")
            self.is_physics_initialized = False
    
    async def _setup_m3_max_optimization(self):
        """M3 Max ìµœì í™” ì„¤ì •"""
        try:
            if self.device == "mps":
                # M3 Max í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
                os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '1'
                os.environ['PYTORCH_MPS_HIGH_WATERMARK_RATIO'] = '0.0'
                
                # ë©”ëª¨ë¦¬ ì„¤ì •
                if hasattr(torch.backends.mps, 'empty_cache'):
                    torch.backends.mps.empty_cache()
                
                # ì„¤ì • ìµœì í™”
                self.config.batch_size = min(self.config.batch_size, 2)  # MPS ì•ˆì •ì„±
                self.config.memory_fraction = min(self.config.memory_fraction, 0.7)
                
                self.logger.info("ğŸ M3 Max ìµœì í™” ì„¤ì • ì™„ë£Œ")
        except Exception as e:
            self.logger.warning(f"âš ï¸ M3 Max ìµœì í™” ì„¤ì • ì‹¤íŒ¨: {e}")
    
    @ensure_step_initialization
    @safe_step_method
    @performance_monitor("preprocess")
    async def preprocess(self, 
                        cloth_image: Union[np.ndarray, Image.Image],
                        person_image: Union[np.ndarray, Image.Image],
                        cloth_mask: Optional[np.ndarray] = None) -> Dict[str, torch.Tensor]:
        """ì™„ì „í•œ ì „ì²˜ë¦¬"""
        try:
            def convert_to_tensor(img, mask=None):
                """ì´ë¯¸ì§€ë¥¼ í…ì„œë¡œ ë³€í™˜"""
                if isinstance(img, np.ndarray):
                    img = Image.fromarray(img)
                
                if self.transform:
                    tensor = self.transform(img).unsqueeze(0)
                else:
                    # í´ë°±: ìˆ˜ë™ ì „ì²˜ë¦¬
                    img = img.resize(self.config.input_size)
                    tensor = torch.from_numpy(np.array(img)).permute(2, 0, 1).float() / 255.0
                    tensor = tensor.unsqueeze(0)
                
                # ë§ˆìŠ¤í¬ ì²˜ë¦¬
                if mask is not None:
                    if isinstance(mask, np.ndarray):
                        mask_tensor = torch.from_numpy(mask).float() / 255.0
                        mask_tensor = mask_tensor.unsqueeze(0).unsqueeze(0)
                        # ì˜ë¥˜ ì˜ì—­ë§Œ ìœ ì§€
                        tensor = tensor * mask_tensor
                
                return tensor
            
            # ì´ë¯¸ì§€ ë³€í™˜
            cloth_tensor = convert_to_tensor(cloth_image, cloth_mask)
            person_tensor = convert_to_tensor(person_image)
            
            # ë””ë°”ì´ìŠ¤ ì´ë™
            cloth_tensor = cloth_tensor.to(self.device)
            person_tensor = person_tensor.to(self.device)
            
            # ì •ë°€ë„ ë³€í™˜
            if self.config.precision == "fp16" and self.device in ["mps", "cuda"]:
                cloth_tensor = cloth_tensor.half()
                person_tensor = person_tensor.half()
            
            self.logger.info(f"âœ… ì „ì²˜ë¦¬ ì™„ë£Œ: cloth={cloth_tensor.shape}, person={person_tensor.shape}")
            
            # ì¤‘ê°„ ê²°ê³¼ ì €ì¥ (ì‹œê°í™”ìš©)
            if self.config.save_intermediate_results:
                self.intermediate_results.append({
                    'step': 'preprocess',
                    'cloth': self._tensor_to_numpy(cloth_tensor),
                    'person': self._tensor_to_numpy(person_tensor)
                })
            
            return {
                'cloth': cloth_tensor,
                'person': person_tensor
            }
            
        except Exception as e:
            self.logger.error(f"âŒ ì „ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            raise e
    
    @ensure_step_initialization
    @safe_step_method
    @performance_monitor("ai_inference")
    async def ai_inference(self, cloth_tensor: torch.Tensor, person_tensor: torch.Tensor) -> Dict[str, Any]:
        """AI ëª¨ë¸ ì¶”ë¡ """
        try:
            if not self.is_model_loaded:
                await self._load_ai_models()
            
            if not self.is_model_loaded:
                raise Exception("AI ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•ŠìŒ")
            
            self.logger.info("ğŸ¤– AI ëª¨ë¸ ì¶”ë¡  ì‹œì‘...")
            
            # ì¶”ë¡  ì‹¤í–‰
            with torch.no_grad():
                results = self.hrviton_model(cloth_tensor, person_tensor)
            
            # ê²°ê³¼ ì²˜ë¦¬
            warped_cloth_tensor = results['warped_cloth']
            tps_parameters = results['tps_parameters']
            flow_field = results.get('flow_field')
            
            # Tensorë¥¼ NumPyë¡œ ë³€í™˜
            warped_cloth_np = self._tensor_to_numpy(warped_cloth_tensor[0])
            control_points = tps_parameters[0].cpu().numpy() if len(tps_parameters.shape) > 2 else tps_parameters.cpu().numpy().reshape(-1, 2)
            flow_field_np = flow_field[0].cpu().numpy() if flow_field is not None else None
            
            # ì‹ ë¢°ë„ ê³„ì‚°
            confidence = self._calculate_ai_confidence(results)
            
            self.processing_stats["ai_model_calls"] += 1
            self.logger.info(f"âœ… AI ì¶”ë¡  ì™„ë£Œ (ì‹ ë¢°ë„: {confidence:.2f})")
            
            # ì¤‘ê°„ ê²°ê³¼ ì €ì¥
            if self.config.save_intermediate_results:
                self.intermediate_results.append({
                    'step': 'ai_inference',
                    'warped_cloth': warped_cloth_np,
                    'control_points': control_points,
                    'flow_field': flow_field_np
                })
            
            return {
                'warped_cloth': warped_cloth_np,
                'control_points': control_points,
                'flow_field': flow_field_np,
                'confidence': confidence,
                'raw_results': results
            }
            
        except Exception as e:
            self.logger.error(f"âŒ AI ì¶”ë¡  ì‹¤íŒ¨: {e}")
            raise e
    
    @ensure_step_initialization
    @safe_step_method
    @performance_monitor("physics_simulation")
    async def physics_simulation(self, 
                                cloth_image: np.ndarray,
                                control_points: np.ndarray,
                                fabric_type: str = "cotton") -> Dict[str, Any]:
        """ë¬¼ë¦¬ ì‹œë®¬ë ˆì´ì…˜"""
        try:
            if not self.is_physics_initialized:
                await self._setup_physics_simulation()
            
            self.logger.info("âš™ï¸ ë¬¼ë¦¬ ì‹œë®¬ë ˆì´ì…˜ ì‹œì‘...")
            
            # íŒ¨ë¸Œë¦­ íƒ€ì…ì— ë”°ë¥¸ ì†ì„± ì„¤ì •
            fabric_mapping = {
                "cotton": FabricType.COTTON,
                "silk": FabricType.SILK,
                "denim": FabricType.DENIM,
                "wool": FabricType.WOOL
            }
            
            fabric_type_enum = fabric_mapping.get(fabric_type.lower(), FabricType.COTTON)
            
            # ë¬¼ë¦¬ ì†ì„± ì—…ë°ì´íŠ¸
            self.physics_simulator.properties.fabric_type = fabric_type_enum
            
            # ì˜ë¥˜ ë©”ì‹œ ìƒì„±
            h, w = cloth_image.shape[:2]
            vertices, faces = self.physics_simulator.create_cloth_mesh(w, h, resolution=32)
            
            # ì‹œë®¬ë ˆì´ì…˜ ì‹¤í–‰ (ì—¬ëŸ¬ ìŠ¤í…)
            num_steps = 10
            for _ in range(num_steps):
                self.physics_simulator.simulate_step(dt=0.016)
            
            # ë³€í˜•ëœ ë©”ì‹œ ê°€ì ¸ì˜¤ê¸°
            deformed_mesh = self.physics_simulator.get_deformed_mesh()
            
            # ìµœì¢… ì›Œí•‘ ì ìš©
            final_warped = self.tps_transform.apply_transform(cloth_image, vertices[:, :2], deformed_mesh[:, :2])
            
            self.processing_stats["physics_sim_calls"] += 1
            self.logger.info("âœ… ë¬¼ë¦¬ ì‹œë®¬ë ˆì´ì…˜ ì™„ë£Œ")
            
            # ì¤‘ê°„ ê²°ê³¼ ì €ì¥
            if self.config.save_intermediate_results:
                self.intermediate_results.append({
                    'step': 'physics_simulation',
                    'original_mesh': vertices,
                    'deformed_mesh': deformed_mesh,
                    'physics_warped': final_warped
                })
            
            return {
                'physics_warped': final_warped,
                'deformed_mesh': deformed_mesh,
                'original_mesh': vertices,
                'simulation_steps': num_steps
            }
            
        except Exception as e:
            self.logger.error(f"âŒ ë¬¼ë¦¬ ì‹œë®¬ë ˆì´ì…˜ ì‹¤íŒ¨: {e}")
            # í´ë°±: ë‹¨ìˆœ TPS ë³€í™˜
            return await self._fallback_tps_warping(cloth_image, control_points)
    
    async def _fallback_tps_warping(self, cloth_image: np.ndarray, control_points: np.ndarray) -> Dict[str, Any]:
        """í´ë°±: ë‹¨ìˆœ TPS ì›Œí•‘"""
        try:
            h, w = cloth_image.shape[:2]
            
            # ê¸°ë³¸ ì œì–´ì  ê·¸ë¦¬ë“œ ìƒì„±
            source_points = self.tps_transform.create_adaptive_control_grid(w, h)
            
            # ì œì–´ì ì´ ì œê³µëœ ê²½ìš° ì‚¬ìš©, ì•„ë‹ˆë©´ ì•½ê°„ì˜ ë³€í˜• ì ìš©
            if control_points is not None and len(control_points) > 0:
                target_points = control_points[:len(source_points)]
            else:
                # ê¸°ë³¸ ë³€í˜• (ì•½ê°„ì˜ ì™œê³¡)
                target_points = source_points + np.random.normal(0, 5, source_points.shape)
            
            # TPS ë³€í™˜ ì ìš©
            warped = self.tps_transform.apply_transform(cloth_image, source_points, target_points)
            
            self.logger.info("âœ… í´ë°± TPS ì›Œí•‘ ì™„ë£Œ")
            
            return {
                'physics_warped': warped,
                'deformed_mesh': target_points,
                'original_mesh': source_points,
                'simulation_steps': 0
            }
            
        except Exception as e:
            self.logger.error(f"âŒ í´ë°± TPS ì›Œí•‘ ì‹¤íŒ¨: {e}")
            return {
                'physics_warped': cloth_image,  # ì›ë³¸ ë°˜í™˜
                'deformed_mesh': None,
                'original_mesh': None,
                'simulation_steps': 0
            }
    
    @ensure_step_initialization
    @safe_step_method
    @performance_monitor("create_visualization")
    async def create_visualization(self, 
                                 original_cloth: np.ndarray,
                                 warped_cloth: np.ndarray,
                                 control_points: np.ndarray,
                                 flow_field: Optional[np.ndarray] = None,
                                 physics_mesh: Optional[np.ndarray] = None) -> Dict[str, Any]:
        """ì™„ì „í•œ ì‹œê°í™” ìƒì„±"""
        try:
            if not self.config.enable_visualization:
                return {'visualization': None, 'progress_visualization': None}
            
            self.logger.info("ğŸ¨ ì‹œê°í™” ìƒì„± ì‹œì‘...")
            
            # ë©”ì¸ ì›Œí•‘ ì‹œê°í™”
            main_visualization = self.visualizer.create_warping_visualization(
                original_cloth, warped_cloth, control_points, flow_field, physics_mesh
            )
            
            # ì§„í–‰ ê³¼ì • ì‹œê°í™”
            progress_visualization = None
            if self.intermediate_results:
                steps = []
                step_names = []
                
                for result in self.intermediate_results:
                    step_name = result['step']
                    if 'warped_cloth' in result:
                        steps.append(result['warped_cloth'])
                        step_names.append(step_name)
                    elif 'cloth' in result:
                        steps.append(result['cloth'])
                        step_names.append(step_name)
                
                if steps:
                    progress_visualization = self.visualizer.create_progress_visualization(steps, step_names)
            
            self.logger.info("âœ… ì‹œê°í™” ìƒì„± ì™„ë£Œ")
            
            return {
                'visualization': main_visualization,
                'progress_visualization': progress_visualization
            }
            
        except Exception as e:
            self.logger.error(f"âŒ ì‹œê°í™” ìƒì„± ì‹¤íŒ¨: {e}")
            return {'visualization': None, 'progress_visualization': None}
    
    @ensure_step_initialization
    @safe_step_method
    @performance_monitor("process")
    async def process(self, 
                     cloth_image: Union[np.ndarray, Image.Image],
                     person_image: Union[np.ndarray, Image.Image],
                     cloth_mask: Optional[np.ndarray] = None,
                     fabric_type: str = "cotton",
                     clothing_type: str = "shirt",
                     **kwargs) -> Dict[str, Any]:
        """
        ğŸ”¥ ë©”ì¸ ì²˜ë¦¬ ë©”ì„œë“œ - ì™„ì „í•œ ì˜ë¥˜ ì›Œí•‘ íŒŒì´í”„ë¼ì¸
        """
        start_time = time.time()
        
        try:
            self.logger.info(f"ğŸ”„ {self.step_name} ì™„ì „ ì²˜ë¦¬ ì‹œì‘")
            
            # ì¤‘ê°„ ê²°ê³¼ ì´ˆê¸°í™”
            self.intermediate_results = []
            
            # 1. ì „ì²˜ë¦¬
            preprocessed = await self.preprocess(cloth_image, person_image, cloth_mask)
            
            # 2. AI ëª¨ë¸ ì¶”ë¡  (ê¸°ë³¸)
            ai_results = await self.ai_inference(preprocessed['cloth'], preprocessed['person'])
            
            # 3. ë¬¼ë¦¬ ì‹œë®¬ë ˆì´ì…˜ (ì„ íƒì )
            physics_results = None
            if self.config.physics_enabled:
                # ì›ë³¸ ì˜ë¥˜ ì´ë¯¸ì§€ë¥¼ numpyë¡œ ë³€í™˜
                if isinstance(cloth_image, Image.Image):
                    cloth_np = np.array(cloth_image)
                else:
                    cloth_np = cloth_image
                
                physics_results = await self.physics_simulation(
                    cloth_np, ai_results['control_points'], fabric_type
                )
            
            # 4. ê²°ê³¼ ê²°í•© (AI + Physics)
            if physics_results and self.config.warping_method == WarpingMethod.HYBRID:
                # í•˜ì´ë¸Œë¦¬ë“œ: AIì™€ ë¬¼ë¦¬ ê²°í•©
                final_warped = self._combine_ai_and_physics(
                    ai_results['warped_cloth'],
                    physics_results['physics_warped'],
                    blend_ratio=0.7  # AI 70%, Physics 30%
                )
            elif physics_results and self.config.warping_method == WarpingMethod.PHYSICS_BASED:
                # ë¬¼ë¦¬ ê¸°ë°˜ ìš°ì„ 
                final_warped = physics_results['physics_warped']
            else:
                # AI ê¸°ë°˜ ìš°ì„ 
                final_warped = ai_results['warped_cloth']
            
            # 5. ì‹œê°í™” ìƒì„±
            visualization_results = await self.create_visualization(
                cloth_np if isinstance(cloth_image, Image.Image) else cloth_image,
                final_warped,
                ai_results['control_points'],
                ai_results.get('flow_field'),
                physics_results.get('deformed_mesh') if physics_results else None
            )
            
            # 6. í’ˆì§ˆ í‰ê°€
            quality_score = self._evaluate_warping_quality(
                cloth_np if isinstance(cloth_image, Image.Image) else cloth_image,
                final_warped,
                ai_results['confidence']
            )
            
            # 7. ê²°ê³¼ êµ¬ì„±
            processing_time = time.time() - start_time
            
            result = {
                'success': True,
                'step_name': self.step_name,
                'warped_cloth_image': final_warped,
                'control_points': ai_results['control_points'],
                'flow_field': ai_results.get('flow_field'),
                'confidence': ai_results['confidence'],
                'quality_score': quality_score,
                'processing_time': processing_time,
                'visualization': visualization_results.get('visualization'),
                'progress_visualization': visualization_results.get('progress_visualization'),
                'metadata': {
                    'device': self.device,
                    'input_size': self.config.input_size,
                    'warping_method': self.config.warping_method.value,
                    'ai_model_enabled': self.config.ai_model_enabled,
                    'physics_enabled': self.config.physics_enabled,
                    'visualization_enabled': self.config.enable_visualization,
                    'fabric_type': fabric_type,
                    'clothing_type': clothing_type,
                    'num_control_points': self.config.num_control_points,
                    'ai_model_calls': self.processing_stats["ai_model_calls"],
                    'physics_sim_calls': self.processing_stats["physics_sim_calls"],
                    'intermediate_steps': len(self.intermediate_results)
                }
            }
            
            # í†µê³„ ì—…ë°ì´íŠ¸
            self._update_processing_stats(processing_time, True)
            
            self.logger.info(f"âœ… {self.step_name} ì™„ì „ ì²˜ë¦¬ ì™„ë£Œ (ì‹œê°„: {processing_time:.2f}ì´ˆ, í’ˆì§ˆ: {quality_score:.2f})")
            return result
            
        except Exception as e:
            processing_time = time.time() - start_time
            self._update_processing_stats(processing_time, False)
            
            self.logger.error(f"âŒ {self.step_name} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            
            return {
                'success': False,
                'step_name': self.step_name,
                'error': str(e),
                'confidence': 0.0,
                'quality_score': 0.0,
                'processing_time': processing_time,
                'metadata': {
                    'device': self.device,
                    'ai_model_enabled': self.config.ai_model_enabled,
                    'physics_enabled': self.config.physics_enabled,
                    'error_type': type(e).__name__
                }
            }
    
    def _combine_ai_and_physics(self, ai_result: np.ndarray, physics_result: np.ndarray, blend_ratio: float = 0.7) -> np.ndarray:
        """AIì™€ ë¬¼ë¦¬ ê²°ê³¼ ê²°í•©"""
        try:
            # ë™ì¼í•œ í¬ê¸°ë¡œ ì¡°ì •
            if ai_result.shape != physics_result.shape:
                physics_result = cv2.resize(physics_result, (ai_result.shape[1], ai_result.shape[0]))
            
            # ê°€ì¤‘ í‰ê·  ë¸”ë Œë”©
            combined = (ai_result * blend_ratio + physics_result * (1 - blend_ratio)).astype(np.uint8)
            
            return combined
            
        except Exception as e:
            self.logger.error(f"âŒ AI-Physics ê²°í•© ì‹¤íŒ¨: {e}")
            return ai_result  # AI ê²°ê³¼ë¡œ í´ë°±
    
    def _evaluate_warping_quality(self, original: np.ndarray, warped: np.ndarray, ai_confidence: float) -> float:
        """ì›Œí•‘ í’ˆì§ˆ í‰ê°€"""
        try:
            # 1. êµ¬ì¡°ì  ìœ ì‚¬ì„± (SSIM)
            ssim_score = 0.5  # ê¸°ë³¸ê°’
            if SKIMAGE_AVAILABLE:
                try:
                    from skimage.metrics import structural_similarity as ssim
                    ssim_score = ssim(original, warped, multichannel=True, channel_axis=2)
                except Exception:
                    pass
            
            # 2. ì—ì§€ ë³´ì¡´ë„
            edge_score = self._calculate_edge_preservation(original, warped)
            
            # 3. ìƒ‰ìƒ ì¼ê´€ì„±
            color_score = self._calculate_color_consistency(original, warped)
            
            # 4. ì¢…í•© ì ìˆ˜ (ê°€ì¤‘ í‰ê· )
            quality_score = (
                ssim_score * 0.3 +
                edge_score * 0.3 +
                color_score * 0.2 +
                ai_confidence * 0.2
            )
            
            return max(0.0, min(1.0, quality_score))
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ í’ˆì§ˆ í‰ê°€ ì‹¤íŒ¨: {e}")
            return ai_confidence * 0.8  # AI ì‹ ë¢°ë„ ê¸°ë°˜ í´ë°±
    
    def _calculate_edge_preservation(self, original: np.ndarray, warped: np.ndarray) -> float:
        """ì—ì§€ ë³´ì¡´ë„ ê³„ì‚°"""
        try:
            # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜
            orig_gray = cv2.cvtColor(original, cv2.COLOR_RGB2GRAY)
            warp_gray = cv2.cvtColor(warped, cv2.COLOR_RGB2GRAY)
            
            # ì—ì§€ ê²€ì¶œ
            orig_edges = cv2.Canny(orig_gray, 50, 150)
            warp_edges = cv2.Canny(warp_gray, 50, 150)
            
            # ì—ì§€ ì¼ì¹˜ë„ ê³„ì‚°
            intersection = np.logical_and(orig_edges, warp_edges)
            union = np.logical_or(orig_edges, warp_edges)
            
            if np.sum(union) > 0:
                iou = np.sum(intersection) / np.sum(union)
                return iou
            else:
                return 1.0
                
        except Exception:
            return 0.5
    
    def _calculate_color_consistency(self, original: np.ndarray, warped: np.ndarray) -> float:
        """ìƒ‰ìƒ ì¼ê´€ì„± ê³„ì‚°"""
        try:
            # HSV ë³€í™˜
            orig_hsv = cv2.cvtColor(original, cv2.COLOR_RGB2HSV)
            warp_hsv = cv2.cvtColor(warped, cv2.COLOR_RGB2HSV)
            
            # íˆìŠ¤í† ê·¸ë¨ ë¹„êµ
            orig_hist = cv2.calcHist([orig_hsv], [0, 1, 2], None, [50, 60, 60], [0, 180, 0, 256, 0, 256])
            warp_hist = cv2.calcHist([warp_hsv], [0, 1, 2], None, [50, 60, 60], [0, 180, 0, 256, 0, 256])
            
            # ìƒê´€ê´€ê³„ ê³„ì‚°
            correlation = cv2.compareHist(orig_hist, warp_hist, cv2.HISTCMP_CORREL)
            
            return max(0.0, correlation)
            
        except Exception:
            return 0.5
    
    def _tensor_to_numpy(self, tensor: torch.Tensor) -> np.ndarray:
        """Tensorë¥¼ NumPy ë°°ì—´ë¡œ ë³€í™˜"""
        if tensor.dim() == 4:
            tensor = tensor.squeeze(0)
        
        # ë°˜ì •ë°€ë„ì—ì„œ ë‹¨ì •ë°€ë„ë¡œ ë³€í™˜
        if tensor.dtype == torch.float16:
            tensor = tensor.float()
        
        # ì •ê·œí™” í•´ì œ
        if tensor.min() >= -1 and tensor.max() <= 1:
            # [-1, 1] ë²”ìœ„ë¥¼ [0, 255]ë¡œ ë³€í™˜
            tensor = (tensor + 1) * 127.5
        else:
            # [0, 1] ë²”ìœ„ë¥¼ [0, 255]ë¡œ ë³€í™˜
            tensor = tensor * 255
        
        tensor = torch.clamp(tensor, 0, 255)
        
        # CPUë¡œ ì´ë™ ë° NumPy ë³€í™˜
        if tensor.is_cuda or (hasattr(tensor, 'is_mps') and tensor.is_mps):
            tensor = tensor.cpu()
        
        image = tensor.permute(1, 2, 0).numpy().astype(np.uint8)
        return image
    
    def _calculate_ai_confidence(self, results: Dict[str, torch.Tensor]) -> float:
        """AI ëª¨ë¸ ì‹ ë¢°ë„ ê³„ì‚°"""
        try:
            # íŠ¹ì§• í™œì„±í™” ê¸°ë°˜ ì‹ ë¢°ë„
            features = results.get('features')
            if features is not None:
                activation_mean = torch.mean(torch.abs(features)).item()
                activation_std = torch.std(features).item()
                
                # ì •ê·œí™”ëœ ì‹ ë¢°ë„ (0-1)
                confidence = min(1.0, activation_mean / (activation_std + 1e-6) * 0.1)
                return confidence
            
            # í”Œë¡œìš° í•„ë“œ ê¸°ë°˜ ì‹ ë¢°ë„
            flow_field = results.get('flow_field')
            if flow_field is not None:
                flow_magnitude = torch.sqrt(flow_field[0]**2 + flow_field[1]**2)
                flow_consistency = 1.0 / (torch.std(flow_magnitude).item() + 1e-6)
                confidence = min(1.0, flow_consistency * 0.01)
                return confidence
            
            return 0.75  # ê¸°ë³¸ ì‹ ë¢°ë„
            
        except Exception:
            return 0.5
    
    def _update_processing_stats(self, processing_time: float, success: bool):
        """ì²˜ë¦¬ í†µê³„ ì—…ë°ì´íŠ¸"""
        self.processing_stats["total_processed"] += 1
        
        if success:
            self.processing_stats["successful_warps"] += 1
        else:
            self.processing_stats["failed_warps"] += 1
        
        # í‰ê·  ì²˜ë¦¬ ì‹œê°„ ì—…ë°ì´íŠ¸
        total = self.processing_stats["total_processed"]
        current_avg = self.processing_stats["avg_processing_time"]
        self.processing_stats["avg_processing_time"] = (current_avg * (total - 1) + processing_time) / total
    
    async def cleanup_models(self):
        """ëª¨ë¸ ë° ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        try:
            # AI ëª¨ë¸ ì •ë¦¬
            if self.hrviton_model is not None:
                del self.hrviton_model
                self.hrviton_model = None
            
            # ë¬¼ë¦¬ ì‹œë®¬ë ˆì´í„° ì •ë¦¬
            if self.physics_simulator is not None:
                del self.physics_simulator
                self.physics_simulator = None
            
            # ìƒìœ„ í´ë˜ìŠ¤ ì •ë¦¬ í˜¸ì¶œ
            super().cleanup_models()
            
            # ModelLoader ì¸í„°í˜ì´ìŠ¤ ì •ë¦¬
            if self.model_interface:
                self.model_interface.unload_models()
            
            # ë©”ëª¨ë¦¬ ê´€ë¦¬ì ì •ë¦¬
            if self.memory_manager:
                await self.memory_manager.cleanup_memory()
            
            # ìŠ¤ë ˆë“œ í’€ ì •ë¦¬
            if hasattr(self, 'executor'):
                self.executor.shutdown(wait=True)
            
            # GPU ë©”ëª¨ë¦¬ ì •ë¦¬
            if TORCH_AVAILABLE:
                if self.device == 'mps' and hasattr(torch.backends.mps, 'empty_cache'):
                    torch.backends.mps.empty_cache()
                elif self.device == 'cuda':
                    torch.cuda.empty_cache()
            
            # ì‹œìŠ¤í…œ ë©”ëª¨ë¦¬ ì •ë¦¬
            gc.collect()
            
            # ìƒíƒœ ì´ˆê¸°í™”
            self.is_model_loaded = False
            self.is_physics_initialized = False
            self.intermediate_results = []
            
            self.logger.info("ğŸ§¹ ClothWarpingStep ì™„ì „ ì •ë¦¬ ì™„ë£Œ")
            
        except Exception as e:
            self.logger.error(f"âŒ ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì‹¤íŒ¨: {e}")
    
    def get_step_info(self) -> Dict[str, Any]:
        """Step ìƒíƒœ ì •ë³´ ë°˜í™˜"""
        base_info = super().get_step_info()
        base_info.update({
            "is_model_loaded": self.is_model_loaded,
            "is_physics_initialized": self.is_physics_initialized,
            "config": {
                "input_size": self.config.input_size,
                "warping_method": self.config.warping_method.value,
                "ai_model_enabled": self.config.ai_model_enabled,
                "physics_enabled": self.config.physics_enabled,
                "visualization_enabled": self.config.enable_visualization,
                "num_control_points": self.config.num_control_points,
                "precision": self.config.precision,
                "quality_level": self.config.quality_level
            },
            "processing_stats": self.processing_stats,
            "model_loader_available": MODEL_LOADER_AVAILABLE,
            "memory_manager_available": MEMORY_MANAGER_AVAILABLE,
            "intermediate_results_count": len(self.intermediate_results)
        })
        return base_info
    
    def __del__(self):
        """ì†Œë©¸ì"""
        try:
            if hasattr(self, 'executor'):
                self.executor.shutdown(wait=False)
        except:
            pass

# ==============================================
# ğŸ”¥ íŒ©í† ë¦¬ í•¨ìˆ˜ë“¤ ë° í•˜ìœ„ í˜¸í™˜ì„± ì§€ì›
# ==============================================

async def create_cloth_warping_step(
    device: str = "auto",
    config: Optional[Dict[str, Any]] = None,
    **kwargs
) -> ClothWarpingStep:
    """
    ClothWarpingStep íŒ©í† ë¦¬ í•¨ìˆ˜ - ì™„ì „ ê¸°ëŠ¥ ì§€ì›
    
    Args:
        device: ì‚¬ìš©í•  ë””ë°”ì´ìŠ¤ ("auto"ëŠ” ìë™ ê°ì§€)
        config: ì„¤ì • ë”•ì…”ë„ˆë¦¬
        **kwargs: ì¶”ê°€ ì„¤ì •
        
    Returns:
        ClothWarpingStep: ì™„ì „ ì´ˆê¸°í™”ëœ 5ë‹¨ê³„ ìŠ¤í…
    """
    device_param = None if device == "auto" else device
    
    default_config = {
        "warping_method": WarpingMethod.AI_MODEL,
        "ai_model_enabled": True,
        "physics_enabled": True,
        "enable_visualization": True,
        "visualization_quality": "high",
        "quality_level": "high",
        "save_intermediate_results": True,
        "num_control_points": 25,
        "precision": "fp16"
    }
    
    final_config = {**default_config, **(config or {}), **kwargs}
    
    step = ClothWarpingStep(device=device_param, config=final_config)
    
    # ì´ˆê¸°í™” ì‹œë„
    if not await step.initialize():
        logger.warning("âŒ ClothWarpingStep ì´ˆê¸°í™” ì‹¤íŒ¨í–ˆì§€ë§Œ ì§„í–‰í•©ë‹ˆë‹¤")
    
    return step

def create_m3_max_warping_step(**kwargs) -> ClothWarpingStep:
    """M3 Max ìµœì í™”ëœ ì›Œí•‘ ìŠ¤í… ìƒì„±"""
    m3_max_config = {
        'device': 'mps',
        'is_m3_max': True,
        'optimization_enabled': True,
        'memory_gb': 128,
        'quality_level': 'ultra',
        'warping_method': WarpingMethod.AI_MODEL,
        'ai_model_enabled': True,
        'physics_enabled': True,
        'enable_visualization': True,
        'visualization_quality': 'ultra',
        'precision': 'fp16',
        'memory_fraction': 0.7
    }
    
    m3_max_config.update(kwargs)
    
    return ClothWarpingStep(config=m3_max_config)

def create_production_warping_step(
    quality_level: str = "balanced",
    enable_ai_model: bool = True,
    **kwargs
) -> ClothWarpingStep:
    """í”„ë¡œë•ì…˜ í™˜ê²½ìš© ì›Œí•‘ ìŠ¤í… ìƒì„±"""
    production_config = {
        'quality_level': quality_level,
        'warping_method': WarpingMethod.AI_MODEL if enable_ai_model else WarpingMethod.PHYSICS_BASED,
        'ai_model_enabled': enable_ai_model,
        'physics_enabled': True,
        'optimization_enabled': True,
        'enable_visualization': True,
        'visualization_quality': 'high' if enable_ai_model else 'medium',
        'save_intermediate_results': False  # í”„ë¡œë•ì…˜ì—ì„œëŠ” ë©”ëª¨ë¦¬ ì ˆì•½
    }
    
    production_config.update(kwargs)
    
    return ClothWarpingStep(config=production_config)

# ê¸°ì¡´ í´ë˜ìŠ¤ëª… ë³„ì¹­ (í•˜ìœ„ í˜¸í™˜ì„±)
ClothWarpingStepLegacy = ClothWarpingStep

# ==============================================
# ğŸ†• í…ŒìŠ¤íŠ¸ ë° ì˜ˆì‹œ í•¨ìˆ˜ë“¤
# ==============================================

async def test_cloth_warping_complete():
    """ğŸ§ª ì™„ì „í•œ ì˜ë¥˜ ì›Œí•‘ í…ŒìŠ¤íŠ¸"""
    print("ğŸ§ª ì™„ì „í•œ ì˜ë¥˜ ì›Œí•‘ + AI + ë¬¼ë¦¬ + ì‹œê°í™” í…ŒìŠ¤íŠ¸ ì‹œì‘")
    
    try:
        # Step ìƒì„±
        step = await create_cloth_warping_step(
            device="auto",
            config={
                "ai_model_enabled": True,
                "physics_enabled": True,
                "enable_visualization": True,
                "visualization_quality": "ultra",
                "quality_level": "high",
                "warping_method": WarpingMethod.HYBRID
            }
        )
        
        # ë”ë¯¸ ì´ë¯¸ì§€ë“¤ ìƒì„± (ê³ í•´ìƒë„)
        clothing_image = np.random.randint(0, 255, (512, 384, 3), dtype=np.uint8)
        person_image = np.random.randint(0, 255, (512, 384, 3), dtype=np.uint8)
        clothing_mask = np.ones((512, 384), dtype=np.uint8) * 255
        
        # ì²˜ë¦¬ ì‹¤í–‰
        result = await step.process(
            clothing_image, person_image, clothing_mask,
            fabric_type="cotton", clothing_type="shirt"
        )
        
        # ê²°ê³¼ í™•ì¸
        if result["success"]:
            print("âœ… ì™„ì „í•œ ì²˜ë¦¬ ì„±ê³µ!")
            print(f"ğŸ“Š ì²˜ë¦¬ ì‹œê°„: {result['processing_time']:.2f}ì´ˆ")
            print(f"ğŸ¯ ì‹ ë¢°ë„: {result['confidence']:.2f}")
            print(f"â­ í’ˆì§ˆ ì ìˆ˜: {result['quality_score']:.2f}")
            print(f"ğŸ¨ ì‹œê°í™” ìƒì„±: {'ì˜ˆ' if result['visualization'] is not None else 'ì•„ë‹ˆì˜¤'}")
            print(f"ğŸ“ˆ ì§„í–‰ ì‹œê°í™”: {'ì˜ˆ' if result['progress_visualization'] is not None else 'ì•„ë‹ˆì˜¤'}")
            
            # Step ì •ë³´ ì¶œë ¥
            step_info = step.get_step_info()
            print(f"ğŸ“‹ Step ì •ë³´: {step_info}")
            
        else:
            print(f"âŒ ì²˜ë¦¬ ì‹¤íŒ¨: {result['error']}")
            
        # ì •ë¦¬
        await step.cleanup_models()
        
    except Exception as e:
        print(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")

async def benchmark_warping_methods():
    """ğŸ ì›Œí•‘ ë°©ë²•ë³„ ë²¤ì¹˜ë§ˆí¬"""
    print("ğŸ ì›Œí•‘ ë°©ë²•ë³„ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ì‹œì‘")
    
    methods = [
        (WarpingMethod.AI_MODEL, "AI ëª¨ë¸ë§Œ"),
        (WarpingMethod.PHYSICS_BASED, "ë¬¼ë¦¬ ê¸°ë°˜ë§Œ"),
        (WarpingMethod.HYBRID, "í•˜ì´ë¸Œë¦¬ë“œ"),
        (WarpingMethod.TPS_ONLY, "TPSë§Œ")
    ]
    
    results = {}
    
    for method, name in methods:
        try:
            print(f"\nğŸ”„ {name} í…ŒìŠ¤íŠ¸ ì¤‘...")
            
            # Step ìƒì„±
            step = await create_cloth_warping_step(
                config={
                    "warping_method": method,
                    "ai_model_enabled": method in [WarpingMethod.AI_MODEL, WarpingMethod.HYBRID],
                    "physics_enabled": method in [WarpingMethod.PHYSICS_BASED, WarpingMethod.HYBRID],
                    "enable_visualization": False  # ë²¤ì¹˜ë§ˆí¬ì—ì„œëŠ” ë¹„í™œì„±í™”
                }
            )
            
            # í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€
            cloth_img = np.random.randint(0, 255, (256, 192, 3), dtype=np.uint8)
            person_img = np.random.randint(0, 255, (256, 192, 3), dtype=np.uint8)
            
            # 3íšŒ ì‹¤í–‰í•˜ì—¬ í‰ê·  ê³„ì‚°
            times = []
            qualities = []
            
            for i in range(3):
                result = await step.process(cloth_img, person_img)
                if result["success"]:
                    times.append(result["processing_time"])
                    qualities.append(result["quality_score"])
            
            if times:
                results[name] = {
                    "avg_time": np.mean(times),
                    "avg_quality": np.mean(qualities),
                    "success_rate": len(times) / 3
                }
                print(f"âœ… {name}: ì‹œê°„={np.mean(times):.2f}ì´ˆ, í’ˆì§ˆ={np.mean(qualities):.2f}")
            else:
                results[name] = {"avg_time": float('inf'), "avg_quality": 0.0, "success_rate": 0.0}
                print(f"âŒ {name}: ì‹¤íŒ¨")
            
            await step.cleanup_models()
            
        except Exception as e:
            print(f"âŒ {name} í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
            results[name] = {"avg_time": float('inf'), "avg_quality": 0.0, "success_rate": 0.0}
    
    # ê²°ê³¼ ìš”ì•½
    print("\nğŸ“Š ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ ìš”ì•½:")
    print("-" * 60)
    for method_name, metrics in results.items():
        print(f"{method_name:<15}: ì‹œê°„={metrics['avg_time']:.2f}ì´ˆ, "
              f"í’ˆì§ˆ={metrics['avg_quality']:.2f}, ì„±ê³µë¥ ={metrics['success_rate']:.0%}")

# ==============================================
# ğŸ”¥ ëª¨ë“ˆ ìµìŠ¤í¬íŠ¸
# ==============================================

__all__ = [
    # ë©”ì¸ í´ë˜ìŠ¤
    'ClothWarpingStep',
    
    # ì„¤ì • í´ë˜ìŠ¤ë“¤
    'ClothWarpingConfig',
    'PhysicsProperties',
    'WarpingMethod',
    'FabricType',
    
    # í•µì‹¬ ì»´í¬ë„ŒíŠ¸ë“¤
    'AdvancedTPSTransform',
    'ClothPhysicsSimulator',
    'HRVITONModel',
    'WarpingVisualizer',
    
    # íŒ©í† ë¦¬ í•¨ìˆ˜ë“¤
    'create_cloth_warping_step',
    'create_m3_max_warping_step',
    'create_production_warping_step',
    
    # í•˜ìœ„ í˜¸í™˜ì„±
    'ClothWarpingStepLegacy',
    
    # í…ŒìŠ¤íŠ¸ í•¨ìˆ˜ë“¤
    'test_cloth_warping_complete',
    'benchmark_warping_methods'
]

logger.info("âœ… ClothWarpingStep v2.0 ì™„ì „ ë²„ì „ ë¡œë“œ ì™„ë£Œ")
logger.info("ğŸ”— BaseStepMixin ì™„ë²½ ìƒì†")
logger.info("ğŸ¤– ModelLoader ì¸í„°í˜ì´ìŠ¤ **ì™„ì „ ì—°ë™**") 
logger.info("ğŸ¨ ì‹œê°í™” ê¸°ëŠ¥ ì™„ì „ êµ¬í˜„")
logger.info("âš™ï¸ ë¬¼ë¦¬ ì‹œë®¬ë ˆì´ì…˜ ì—”ì§„ í¬í•¨")
logger.info("ğŸ M3 Max 128GB ìµœì í™” ì§€ì›")
logger.info("ğŸ”¥ **ëª¨ë“  ê¸°ëŠ¥ 100% í¬í•¨ëœ ì™„ì „ ë²„ì „**")