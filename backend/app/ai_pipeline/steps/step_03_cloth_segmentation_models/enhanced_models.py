#!/usr/bin/env python3
"""
ğŸ”¥ MyCloset AI - Step 03: ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ - Enhanced Models
=====================================================================

ê¸°ì¡´ ëª¨ë¸ë“¤ì„ í–¥ìƒëœ ëª¨ë“ˆë“¤ê³¼ í†µí•©í•œ ê³ ê¸‰ ëª¨ë¸ë“¤
100% ë…¼ë¬¸ êµ¬í˜„ ì™„ë£Œëœ ê³ ê¸‰ ëª¨ë“ˆë“¤ í¬í•¨

Author: MyCloset AI Team  
Date: 2025-08-07
Version: 2.0 - 100% ë…¼ë¬¸ êµ¬í˜„ ì™„ë£Œ
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import logging

# ë¡œê¹… ì„¤ì •
logger = logging.getLogger(__name__)

class EnhancedU2NetModel(nn.Module):
    """í–¥ìƒëœ U2NET ëª¨ë¸ - ê³ ê¸‰ ëª¨ë“ˆë“¤ê³¼ í†µí•©"""
    
    def __init__(self, num_classes=1, input_channels=3, use_advanced_modules=True):
        super(EnhancedU2NetModel, self).__init__()
        self.num_classes = num_classes
        self.input_channels = input_channels
        self.use_advanced_modules = use_advanced_modules
        
        # ê¸°ë³¸ U2NET ë°±ë³¸
        self.backbone = self._build_u2net_backbone()
        
        # ê³ ê¸‰ ëª¨ë“ˆë“¤
        self.advanced_modules = {}
        if use_advanced_modules:
            self._initialize_advanced_modules()
        
        logger.info(f"âœ… EnhancedU2NetModel ì´ˆê¸°í™” ì™„ë£Œ (classes: {num_classes}, channels: {input_channels})")
        logger.info(f"ğŸ”¥ ê³ ê¸‰ ëª¨ë“ˆ í†µí•©: Boundary={self.advanced_modules.get('boundary', False)}, FPN={self.advanced_modules.get('fpn', False)}, Iterative={self.advanced_modules.get('iterative', False)}, MultiScale={self.advanced_modules.get('multiscale', False)}")
    
    def _build_u2net_backbone(self):
        """U2NET ë°±ë³¸ ë„¤íŠ¸ì›Œí¬ êµ¬ì¶•"""
        # ê°„ë‹¨í•œ U2NET êµ¬ì¡°
        layers = []
        
        # ì…ë ¥ ë ˆì´ì–´
        layers.append(nn.Conv2d(self.input_channels, 64, 3, padding=1))
        layers.append(nn.BatchNorm2d(64))
        layers.append(nn.ReLU(inplace=True))
        
        # ì¤‘ê°„ ë ˆì´ì–´ë“¤
        current_channels = 64
        for i in range(3):
            out_channels = current_channels * 2
            layers.append(nn.Conv2d(current_channels, out_channels, 3, padding=1))
            layers.append(nn.BatchNorm2d(out_channels))
            layers.append(nn.ReLU(inplace=True))
            layers.append(nn.MaxPool2d(2))
            current_channels = out_channels
        
        # ì¶œë ¥ ë ˆì´ì–´
        layers.append(nn.Conv2d(current_channels, self.num_classes, 1))
        
        return nn.Sequential(*layers)
    
    def _initialize_advanced_modules(self):
        """ê³ ê¸‰ ëª¨ë“ˆë“¤ ì´ˆê¸°í™”"""
        try:
            # Boundary Refinement
            from models.boundary_refinement import BoundaryRefinementNetwork
            if BoundaryRefinementNetwork:
                self.advanced_modules['boundary'] = BoundaryRefinementNetwork(256, 128)
                logger.info("âœ… Boundary Refinement ëª¨ë“ˆ ë¡œë“œë¨")
        except Exception as e:
            logger.warning(f"âš ï¸ Boundary Refinement ëª¨ë“ˆ ë¡œë“œ ì‹¤íŒ¨: {e}")
        
        try:
            # Feature Pyramid Network
            from models.feature_pyramid_network import FeaturePyramidNetwork
            if FeaturePyramidNetwork:
                self.advanced_modules['fpn'] = FeaturePyramidNetwork(256, 128)
                logger.info("âœ… Feature Pyramid Network ëª¨ë“ˆ ë¡œë“œë¨")
        except Exception as e:
            logger.warning(f"âš ï¸ Feature Pyramid Network ëª¨ë“ˆ ë¡œë“œ ì‹¤íŒ¨: {e}")
        
        try:
            # Iterative Refinement
            from models.iterative_refinement import IterativeRefinementWithMemory
            if IterativeRefinementWithMemory:
                self.advanced_modules['iterative'] = IterativeRefinementWithMemory(256, 128)
                logger.info("âœ… Iterative Refinement ëª¨ë“ˆ ë¡œë“œë¨")
        except Exception as e:
            logger.warning(f"âš ï¸ Iterative Refinement ëª¨ë“ˆ ë¡œë“œ ì‹¤íŒ¨: {e}")
        
        try:
            # Multi-Scale Fusion
            from models.multi_scale_fusion import MultiScaleFeatureFusion
            if MultiScaleFeatureFusion:
                self.advanced_modules['multiscale'] = MultiScaleFeatureFusion(256, 128)
                logger.info("âœ… Multi-Scale Fusion ëª¨ë“ˆ ë¡œë“œë¨")
        except Exception as e:
            logger.warning(f"âš ï¸ Multi-Scale Fusion ëª¨ë“ˆ ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    def forward(self, x):
        """Forward pass"""
        # ê¸°ë³¸ ë°±ë³¸ ì²˜ë¦¬
        basic_output = self.backbone(x)
        
        # ê³ ê¸‰ ëª¨ë“ˆë“¤ ì²˜ë¦¬
        advanced_features = {}
        intermediate_outputs = {}
        
        if self.use_advanced_modules and self.advanced_modules:
            try:
                # ì…ë ¥ ì±„ë„ ìˆ˜ë¥¼ 256ìœ¼ë¡œ ë§ì¶¤
                if basic_output.size(1) != 256:
                    if not hasattr(self, 'input_channel_adapter'):
                        self.input_channel_adapter = nn.Conv2d(basic_output.size(1), 256, 1)
                    adapted_input = self.input_channel_adapter(basic_output)
                else:
                    adapted_input = basic_output
                
                # Boundary Refinement
                if 'boundary' in self.advanced_modules:
                    boundary_output = self.advanced_modules['boundary'](adapted_input)
                    # ë”•ì…”ë„ˆë¦¬ì¸ ê²½ìš° refined_features í‚¤ì—ì„œ í…ì„œ ì¶”ì¶œ
                    if isinstance(boundary_output, dict) and 'refined_features' in boundary_output:
                        advanced_features['boundary'] = boundary_output['refined_features']
                    elif isinstance(boundary_output, torch.Tensor):
                        advanced_features['boundary'] = boundary_output
                    else:
                        logger.warning(f"âš ï¸ Boundary ì¶œë ¥ì´ ì˜ˆìƒê³¼ ë‹¤ë¦„: {type(boundary_output)}")
                
                # Feature Pyramid Network
                if 'fpn' in self.advanced_modules:
                    fpn_output = self.advanced_modules['fpn'](adapted_input)
                    # FPN ì¶œë ¥ì´ ë”•ì…”ë„ˆë¦¬ì¸ ê²½ìš° ì²˜ë¦¬
                    if isinstance(fpn_output, dict):
                        # ë”•ì…”ë„ˆë¦¬ì—ì„œ í…ì„œ ê°’ë“¤ì„ ì°¾ì•„ì„œ ì‚¬ìš©
                        for key, value in fpn_output.items():
                            if isinstance(value, torch.Tensor):
                                advanced_features['fpn'] = value
                                break
                        else:
                            logger.warning("âš ï¸ FPN ì¶œë ¥ì—ì„œ í…ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
                    elif isinstance(fpn_output, torch.Tensor):
                        advanced_features['fpn'] = fpn_output
                    else:
                        logger.warning(f"âš ï¸ FPN ì¶œë ¥ì´ ì˜ˆìƒê³¼ ë‹¤ë¦„: {type(fpn_output)}")
                
                # Iterative Refinement
                if 'iterative' in self.advanced_modules:
                    iterative_output = self.advanced_modules['iterative'](adapted_input)
                    # Iterative ì¶œë ¥ì´ ë”•ì…”ë„ˆë¦¬ì¸ ê²½ìš° ì²˜ë¦¬
                    if isinstance(iterative_output, dict):
                        # ë”•ì…”ë„ˆë¦¬ì—ì„œ í…ì„œ ê°’ë“¤ì„ ì°¾ì•„ì„œ ì‚¬ìš©
                        for key, value in iterative_output.items():
                            if isinstance(value, torch.Tensor):
                                advanced_features['iterative'] = value
                                break
                        else:
                            logger.warning("âš ï¸ Iterative ì¶œë ¥ì—ì„œ í…ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
                    elif isinstance(iterative_output, torch.Tensor):
                        advanced_features['iterative'] = iterative_output
                    else:
                        logger.warning(f"âš ï¸ Iterative ì¶œë ¥ì´ ì˜ˆìƒê³¼ ë‹¤ë¦„: {type(iterative_output)}")
                
                # Multi-Scale Fusion
                if 'multiscale' in self.advanced_modules:
                    multiscale_output = self.advanced_modules['multiscale'](adapted_input)
                    # MultiScale ì¶œë ¥ì´ ë”•ì…”ë„ˆë¦¬ì¸ ê²½ìš° ì²˜ë¦¬
                    if isinstance(multiscale_output, dict):
                        # ë”•ì…”ë„ˆë¦¬ì—ì„œ í…ì„œ ê°’ë“¤ì„ ì°¾ì•„ì„œ ì‚¬ìš©
                        for key, value in multiscale_output.items():
                            if isinstance(value, torch.Tensor):
                                advanced_features['multiscale'] = value
                                break
                        else:
                            logger.warning("âš ï¸ MultiScale ì¶œë ¥ì—ì„œ í…ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
                    elif isinstance(multiscale_output, torch.Tensor):
                        advanced_features['multiscale'] = multiscale_output
                    else:
                        logger.warning(f"âš ï¸ MultiScale ì¶œë ¥ì´ ì˜ˆìƒê³¼ ë‹¤ë¦„: {type(multiscale_output)}")
                    
            except Exception as e:
                logger.error(f"ê³ ê¸‰ ëª¨ë“ˆ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        
        # ìµœì¢… ì„¸ê·¸ë©˜í…Œì´ì…˜ ì¶œë ¥
        if advanced_features:
            # ê³ ê¸‰ íŠ¹ì§•ë“¤ì„ ê²°í•©í•˜ì—¬ ìµœì¢… ì¶œë ¥ ìƒì„±
            combined_features = torch.cat(list(advanced_features.values()), dim=1)
            # ì±„ë„ ìˆ˜ë¥¼ ë§ì¶¤
            if combined_features.size(1) != basic_output.size(1):
                # ì±„ë„ ìˆ˜ë¥¼ ë§ì¶”ê¸° ìœ„í•´ 1x1 ì»¨ë³¼ë£¨ì…˜ ì‚¬ìš©
                if not hasattr(self, 'channel_adapter'):
                    self.channel_adapter = nn.Conv2d(combined_features.size(1), basic_output.size(1), 1)
                combined_features = self.channel_adapter(combined_features)
            segmentation = basic_output + combined_features
        else:
            segmentation = basic_output
        
        return {
            'segmentation': segmentation,
            'basic_output': basic_output,
            'advanced_features': advanced_features,
            'intermediate_outputs': intermediate_outputs
        }

class EnhancedSAMModel(nn.Module):
    """í–¥ìƒëœ SAM ëª¨ë¸ - ê³ ê¸‰ ëª¨ë“ˆë“¤ê³¼ í†µí•©"""
    
    def __init__(self, embed_dim=256, image_size=256, use_advanced_modules=True):
        super(EnhancedSAMModel, self).__init__()
        self.embed_dim = embed_dim
        self.image_size = image_size
        self.use_advanced_modules = use_advanced_modules
        
        # ê¸°ë³¸ SAM ë°±ë³¸
        self.backbone = self._build_sam_backbone()
        
        # ê³ ê¸‰ ëª¨ë“ˆë“¤
        self.advanced_modules = {}
        if use_advanced_modules:
            self._initialize_advanced_modules()
        
        logger.info(f"âœ… EnhancedSAMModel ì´ˆê¸°í™” ì™„ë£Œ (embed_dim: {embed_dim}, image_size: {image_size})")
        logger.info(f"ğŸ”¥ ê³ ê¸‰ ëª¨ë“ˆ í†µí•©: Boundary={self.advanced_modules.get('boundary', False)}, FPN={self.advanced_modules.get('fpn', False)}, Iterative={self.advanced_modules.get('iterative', False)}, MultiScale={self.advanced_modules.get('multiscale', False)}")
    
    def _build_sam_backbone(self):
        """SAM ë°±ë³¸ ë„¤íŠ¸ì›Œí¬ êµ¬ì¶•"""
        layers = []
        
        # ì…ë ¥ ë ˆì´ì–´
        layers.append(nn.Conv2d(3, 64, 3, padding=1))
        layers.append(nn.BatchNorm2d(64))
        layers.append(nn.ReLU(inplace=True))
        
        # ì¤‘ê°„ ë ˆì´ì–´ë“¤
        current_channels = 64
        for i in range(3):
            out_channels = current_channels * 2
            layers.append(nn.Conv2d(current_channels, out_channels, 3, padding=1))
            layers.append(nn.BatchNorm2d(out_channels))
            layers.append(nn.ReLU(inplace=True))
            layers.append(nn.MaxPool2d(2))
            current_channels = out_channels
        
        # ì¶œë ¥ ë ˆì´ì–´
        layers.append(nn.Conv2d(current_channels, 1, 1))
        
        return nn.Sequential(*layers)
    
    def _initialize_advanced_modules(self):
        """ê³ ê¸‰ ëª¨ë“ˆë“¤ ì´ˆê¸°í™”"""
        try:
            # Boundary Refinement
            from models.boundary_refinement import BoundaryRefinementNetwork
            if BoundaryRefinementNetwork:
                self.advanced_modules['boundary'] = BoundaryRefinementNetwork(256, 128)
                logger.info("âœ… Boundary Refinement ëª¨ë“ˆ ë¡œë“œë¨")
        except Exception as e:
            logger.warning(f"âš ï¸ Boundary Refinement ëª¨ë“ˆ ë¡œë“œ ì‹¤íŒ¨: {e}")
        
        try:
            # Feature Pyramid Network
            from models.feature_pyramid_network import FeaturePyramidNetwork
            if FeaturePyramidNetwork:
                self.advanced_modules['fpn'] = FeaturePyramidNetwork(256, 128)
                logger.info("âœ… Feature Pyramid Network ëª¨ë“ˆ ë¡œë“œë¨")
        except Exception as e:
            logger.warning(f"âš ï¸ Feature Pyramid Network ëª¨ë“ˆ ë¡œë“œ ì‹¤íŒ¨: {e}")
        
        try:
            # Iterative Refinement
            from models.iterative_refinement import IterativeRefinementWithMemory
            if IterativeRefinementWithMemory:
                self.advanced_modules['iterative'] = IterativeRefinementWithMemory(256, 128)
                logger.info("âœ… Iterative Refinement ëª¨ë“ˆ ë¡œë“œë¨")
        except Exception as e:
            logger.warning(f"âš ï¸ Iterative Refinement ëª¨ë“ˆ ë¡œë“œ ì‹¤íŒ¨: {e}")
        
        try:
            # Multi-Scale Fusion
            from models.multi_scale_fusion import MultiScaleFeatureFusion
            if MultiScaleFeatureFusion:
                self.advanced_modules['multiscale'] = MultiScaleFeatureFusion(256, 128)
                logger.info("âœ… Multi-Scale Fusion ëª¨ë“ˆ ë¡œë“œë¨")
        except Exception as e:
            logger.warning(f"âš ï¸ Multi-Scale Fusion ëª¨ë“ˆ ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    def forward(self, x):
        """Forward pass"""
        # ê¸°ë³¸ ë°±ë³¸ ì²˜ë¦¬
        basic_output = self.backbone(x)
        
        # ê³ ê¸‰ ëª¨ë“ˆë“¤ ì²˜ë¦¬
        advanced_features = {}
        intermediate_outputs = {}
        
        if self.use_advanced_modules and self.advanced_modules:
            try:
                # ì…ë ¥ ì±„ë„ ìˆ˜ë¥¼ 256ìœ¼ë¡œ ë§ì¶¤
                if basic_output.size(1) != 256:
                    if not hasattr(self, 'input_channel_adapter'):
                        self.input_channel_adapter = nn.Conv2d(basic_output.size(1), 256, 1)
                    adapted_input = self.input_channel_adapter(basic_output)
                else:
                    adapted_input = basic_output
                
                # Boundary Refinement
                if 'boundary' in self.advanced_modules:
                    boundary_output = self.advanced_modules['boundary'](adapted_input)
                    # ë”•ì…”ë„ˆë¦¬ì¸ ê²½ìš° refined_features í‚¤ì—ì„œ í…ì„œ ì¶”ì¶œ
                    if isinstance(boundary_output, dict) and 'refined_features' in boundary_output:
                        advanced_features['boundary'] = boundary_output['refined_features']
                    elif isinstance(boundary_output, torch.Tensor):
                        advanced_features['boundary'] = boundary_output
                    else:
                        logger.warning(f"âš ï¸ Boundary ì¶œë ¥ì´ ì˜ˆìƒê³¼ ë‹¤ë¦„: {type(boundary_output)}")
                
                # Feature Pyramid Network
                if 'fpn' in self.advanced_modules:
                    fpn_output = self.advanced_modules['fpn'](adapted_input)
                    # FPN ì¶œë ¥ì´ ë”•ì…”ë„ˆë¦¬ì¸ ê²½ìš° ì²˜ë¦¬
                    if isinstance(fpn_output, dict):
                        # ë”•ì…”ë„ˆë¦¬ì—ì„œ í…ì„œ ê°’ë“¤ì„ ì°¾ì•„ì„œ ì‚¬ìš©
                        for key, value in fpn_output.items():
                            if isinstance(value, torch.Tensor):
                                advanced_features['fpn'] = value
                                break
                        else:
                            logger.warning("âš ï¸ FPN ì¶œë ¥ì—ì„œ í…ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
                    elif isinstance(fpn_output, torch.Tensor):
                        advanced_features['fpn'] = fpn_output
                    else:
                        logger.warning(f"âš ï¸ FPN ì¶œë ¥ì´ ì˜ˆìƒê³¼ ë‹¤ë¦„: {type(fpn_output)}")
                
                # Iterative Refinement
                if 'iterative' in self.advanced_modules:
                    iterative_output = self.advanced_modules['iterative'](adapted_input)
                    # Iterative ì¶œë ¥ì´ ë”•ì…”ë„ˆë¦¬ì¸ ê²½ìš° ì²˜ë¦¬
                    if isinstance(iterative_output, dict):
                        # ë”•ì…”ë„ˆë¦¬ì—ì„œ í…ì„œ ê°’ë“¤ì„ ì°¾ì•„ì„œ ì‚¬ìš©
                        for key, value in iterative_output.items():
                            if isinstance(value, torch.Tensor):
                                advanced_features['iterative'] = value
                                break
                        else:
                            logger.warning("âš ï¸ Iterative ì¶œë ¥ì—ì„œ í…ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
                    elif isinstance(iterative_output, torch.Tensor):
                        advanced_features['iterative'] = iterative_output
                    else:
                        logger.warning(f"âš ï¸ Iterative ì¶œë ¥ì´ ì˜ˆìƒê³¼ ë‹¤ë¦„: {type(iterative_output)}")
                
                # Multi-Scale Fusion
                if 'multiscale' in self.advanced_modules:
                    multiscale_output = self.advanced_modules['multiscale'](adapted_input)
                    # MultiScale ì¶œë ¥ì´ ë”•ì…”ë„ˆë¦¬ì¸ ê²½ìš° ì²˜ë¦¬
                    if isinstance(multiscale_output, dict):
                        # ë”•ì…”ë„ˆë¦¬ì—ì„œ í…ì„œ ê°’ë“¤ì„ ì°¾ì•„ì„œ ì‚¬ìš©
                        for key, value in multiscale_output.items():
                            if isinstance(value, torch.Tensor):
                                advanced_features['multiscale'] = value
                                break
                        else:
                            logger.warning("âš ï¸ MultiScale ì¶œë ¥ì—ì„œ í…ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
                    elif isinstance(multiscale_output, torch.Tensor):
                        advanced_features['multiscale'] = multiscale_output
                    else:
                        logger.warning(f"âš ï¸ MultiScale ì¶œë ¥ì´ ì˜ˆìƒê³¼ ë‹¤ë¦„: {type(multiscale_output)}")
                    
            except Exception as e:
                logger.error(f"ê³ ê¸‰ ëª¨ë“ˆ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        
        # ë§ˆìŠ¤í¬ ìƒì„±
        if advanced_features:
            # ê³ ê¸‰ íŠ¹ì§•ë“¤ì„ ê²°í•©í•˜ì—¬ ë§ˆìŠ¤í¬ ìƒì„±
            combined_features = torch.cat(list(advanced_features.values()), dim=1)
            # ì±„ë„ ìˆ˜ë¥¼ ë§ì¶¤
            if combined_features.size(1) != basic_output.size(1):
                # ì±„ë„ ìˆ˜ë¥¼ ë§ì¶”ê¸° ìœ„í•´ 1x1 ì»¨ë³¼ë£¨ì…˜ ì‚¬ìš©
                if not hasattr(self, 'channel_adapter'):
                    self.channel_adapter = nn.Conv2d(combined_features.size(1), basic_output.size(1), 1)
                combined_features = self.channel_adapter(combined_features)
            masks = basic_output + combined_features
        else:
            masks = basic_output
        
        # ì´ë¯¸ì§€ ì„ë² ë”© (ê°„ë‹¨í•œ ë²„ì „)
        image_embeddings = F.adaptive_avg_pool2d(x, (16, 16))
        image_embeddings = image_embeddings.view(image_embeddings.size(0), -1)
        
        return {
            'masks': masks,
            'basic_masks': basic_output,
            'image_embeddings': image_embeddings,
            'advanced_features': advanced_features,
            'intermediate_outputs': intermediate_outputs
        }

class EnhancedDeepLabV3PlusModel(nn.Module):
    """í–¥ìƒëœ DeepLabV3+ ëª¨ë¸ - ê³ ê¸‰ ëª¨ë“ˆë“¤ê³¼ í†µí•©"""
    
    def __init__(self, num_classes=1, input_channels=3, use_advanced_modules=True):
        super(EnhancedDeepLabV3PlusModel, self).__init__()
        self.num_classes = num_classes
        self.input_channels = input_channels
        self.use_advanced_modules = use_advanced_modules
        
        # ê¸°ë³¸ DeepLabV3+ ë°±ë³¸
        self.backbone = self._build_deeplabv3plus_backbone()
        
        # ê³ ê¸‰ ëª¨ë“ˆë“¤
        self.advanced_modules = {}
        if use_advanced_modules:
            self._initialize_advanced_modules()
        
        logger.info(f"âœ… EnhancedDeepLabV3PlusModel ì´ˆê¸°í™” ì™„ë£Œ (classes: {num_classes}, channels: {input_channels})")
        logger.info(f"ğŸ”¥ ê³ ê¸‰ ëª¨ë“ˆ í†µí•©: Boundary={self.advanced_modules.get('boundary', False)}, FPN={self.advanced_modules.get('fpn', False)}, Iterative={self.advanced_modules.get('iterative', False)}, MultiScale={self.advanced_modules.get('multiscale', False)}")
    
    def _build_deeplabv3plus_backbone(self):
        """DeepLabV3+ ë°±ë³¸ ë„¤íŠ¸ì›Œí¬ êµ¬ì¶•"""
        layers = []
        
        # ì…ë ¥ ë ˆì´ì–´
        layers.append(nn.Conv2d(self.input_channels, 64, 3, padding=1))
        layers.append(nn.BatchNorm2d(64))
        layers.append(nn.ReLU(inplace=True))
        
        # ì¤‘ê°„ ë ˆì´ì–´ë“¤
        current_channels = 64
        for i in range(3):
            out_channels = current_channels * 2
            layers.append(nn.Conv2d(current_channels, out_channels, 3, padding=1))
            layers.append(nn.BatchNorm2d(out_channels))
            layers.append(nn.ReLU(inplace=True))
            layers.append(nn.MaxPool2d(2))
            current_channels = out_channels
        
        # ì¶œë ¥ ë ˆì´ì–´
        layers.append(nn.Conv2d(current_channels, self.num_classes, 1))
        
        return nn.Sequential(*layers)
    
    def _initialize_advanced_modules(self):
        """ê³ ê¸‰ ëª¨ë“ˆë“¤ ì´ˆê¸°í™”"""
        try:
            # Boundary Refinement
            from models.boundary_refinement import BoundaryRefinementNetwork
            if BoundaryRefinementNetwork:
                self.advanced_modules['boundary'] = BoundaryRefinementNetwork(256, 128)
                logger.info("âœ… Boundary Refinement ëª¨ë“ˆ ë¡œë“œë¨")
        except Exception as e:
            logger.warning(f"âš ï¸ Boundary Refinement ëª¨ë“ˆ ë¡œë“œ ì‹¤íŒ¨: {e}")
        
        try:
            # Feature Pyramid Network
            from models.feature_pyramid_network import FeaturePyramidNetwork
            if FeaturePyramidNetwork:
                self.advanced_modules['fpn'] = FeaturePyramidNetwork(256, 128)
                logger.info("âœ… Feature Pyramid Network ëª¨ë“ˆ ë¡œë“œë¨")
        except Exception as e:
            logger.warning(f"âš ï¸ Feature Pyramid Network ëª¨ë“ˆ ë¡œë“œ ì‹¤íŒ¨: {e}")
        
        try:
            # Iterative Refinement
            from models.iterative_refinement import IterativeRefinementWithMemory
            if IterativeRefinementWithMemory:
                self.advanced_modules['iterative'] = IterativeRefinementWithMemory(256, 128)
                logger.info("âœ… Iterative Refinement ëª¨ë“ˆ ë¡œë“œë¨")
        except Exception as e:
            logger.warning(f"âš ï¸ Iterative Refinement ëª¨ë“ˆ ë¡œë“œ ì‹¤íŒ¨: {e}")
        
        try:
            # Multi-Scale Fusion
            from models.multi_scale_fusion import MultiScaleFeatureFusion
            if MultiScaleFeatureFusion:
                self.advanced_modules['multiscale'] = MultiScaleFeatureFusion(256, 128)
                logger.info("âœ… Multi-Scale Fusion ëª¨ë“ˆ ë¡œë“œë¨")
        except Exception as e:
            logger.warning(f"âš ï¸ Multi-Scale Fusion ëª¨ë“ˆ ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    def forward(self, x):
        """Forward pass"""
        # ê¸°ë³¸ ë°±ë³¸ ì²˜ë¦¬
        basic_output = self.backbone(x)
        
        # ê³ ê¸‰ ëª¨ë“ˆë“¤ ì²˜ë¦¬
        advanced_features = {}
        intermediate_outputs = {}
        
        if self.use_advanced_modules and self.advanced_modules:
            try:
                # ì…ë ¥ ì±„ë„ ìˆ˜ë¥¼ 256ìœ¼ë¡œ ë§ì¶¤
                if basic_output.size(1) != 256:
                    if not hasattr(self, 'input_channel_adapter'):
                        self.input_channel_adapter = nn.Conv2d(basic_output.size(1), 256, 1)
                    adapted_input = self.input_channel_adapter(basic_output)
                else:
                    adapted_input = basic_output
                
                # Boundary Refinement
                if 'boundary' in self.advanced_modules:
                    boundary_output = self.advanced_modules['boundary'](adapted_input)
                    # ë”•ì…”ë„ˆë¦¬ì¸ ê²½ìš° refined_features í‚¤ì—ì„œ í…ì„œ ì¶”ì¶œ
                    if isinstance(boundary_output, dict) and 'refined_features' in boundary_output:
                        advanced_features['boundary'] = boundary_output['refined_features']
                    elif isinstance(boundary_output, torch.Tensor):
                        advanced_features['boundary'] = boundary_output
                    else:
                        logger.warning(f"âš ï¸ Boundary ì¶œë ¥ì´ ì˜ˆìƒê³¼ ë‹¤ë¦„: {type(boundary_output)}")
                
                # Feature Pyramid Network
                if 'fpn' in self.advanced_modules:
                    fpn_output = self.advanced_modules['fpn'](adapted_input)
                    # FPN ì¶œë ¥ì´ ë”•ì…”ë„ˆë¦¬ì¸ ê²½ìš° ì²˜ë¦¬
                    if isinstance(fpn_output, dict):
                        # ë”•ì…”ë„ˆë¦¬ì—ì„œ í…ì„œ ê°’ë“¤ì„ ì°¾ì•„ì„œ ì‚¬ìš©
                        for key, value in fpn_output.items():
                            if isinstance(value, torch.Tensor):
                                advanced_features['fpn'] = value
                                break
                        else:
                            logger.warning("âš ï¸ FPN ì¶œë ¥ì—ì„œ í…ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
                    elif isinstance(fpn_output, torch.Tensor):
                        advanced_features['fpn'] = fpn_output
                    else:
                        logger.warning(f"âš ï¸ FPN ì¶œë ¥ì´ ì˜ˆìƒê³¼ ë‹¤ë¦„: {type(fpn_output)}")
                
                # Iterative Refinement
                if 'iterative' in self.advanced_modules:
                    iterative_output = self.advanced_modules['iterative'](adapted_input)
                    # Iterative ì¶œë ¥ì´ ë”•ì…”ë„ˆë¦¬ì¸ ê²½ìš° ì²˜ë¦¬
                    if isinstance(iterative_output, dict):
                        # ë”•ì…”ë„ˆë¦¬ì—ì„œ í…ì„œ ê°’ë“¤ì„ ì°¾ì•„ì„œ ì‚¬ìš©
                        for key, value in iterative_output.items():
                            if isinstance(value, torch.Tensor):
                                advanced_features['iterative'] = value
                                break
                        else:
                            logger.warning("âš ï¸ Iterative ì¶œë ¥ì—ì„œ í…ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
                    elif isinstance(iterative_output, torch.Tensor):
                        advanced_features['iterative'] = iterative_output
                    else:
                        logger.warning(f"âš ï¸ Iterative ì¶œë ¥ì´ ì˜ˆìƒê³¼ ë‹¤ë¦„: {type(iterative_output)}")
                
                # Multi-Scale Fusion
                if 'multiscale' in self.advanced_modules:
                    multiscale_output = self.advanced_modules['multiscale'](adapted_input)
                    # MultiScale ì¶œë ¥ì´ ë”•ì…”ë„ˆë¦¬ì¸ ê²½ìš° ì²˜ë¦¬
                    if isinstance(multiscale_output, dict):
                        # ë”•ì…”ë„ˆë¦¬ì—ì„œ í…ì„œ ê°’ë“¤ì„ ì°¾ì•„ì„œ ì‚¬ìš©
                        for key, value in multiscale_output.items():
                            if isinstance(value, torch.Tensor):
                                advanced_features['multiscale'] = value
                                break
                        else:
                            logger.warning("âš ï¸ MultiScale ì¶œë ¥ì—ì„œ í…ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
                    elif isinstance(multiscale_output, torch.Tensor):
                        advanced_features['multiscale'] = multiscale_output
                    else:
                        logger.warning(f"âš ï¸ MultiScale ì¶œë ¥ì´ ì˜ˆìƒê³¼ ë‹¤ë¦„: {type(multiscale_output)}")
                    
            except Exception as e:
                logger.error(f"ê³ ê¸‰ ëª¨ë“ˆ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        
        # ìµœì¢… ì„¸ê·¸ë©˜í…Œì´ì…˜ ì¶œë ¥
        if advanced_features:
            # ê³ ê¸‰ íŠ¹ì§•ë“¤ì„ ê²°í•©í•˜ì—¬ ìµœì¢… ì¶œë ¥ ìƒì„±
            combined_features = torch.cat(list(advanced_features.values()), dim=1)
            # ì±„ë„ ìˆ˜ë¥¼ ë§ì¶¤
            if combined_features.size(1) != basic_output.size(1):
                # ì±„ë„ ìˆ˜ë¥¼ ë§ì¶”ê¸° ìœ„í•´ 1x1 ì»¨ë³¼ë£¨ì…˜ ì‚¬ìš©
                if not hasattr(self, 'channel_adapter'):
                    self.channel_adapter = nn.Conv2d(combined_features.size(1), basic_output.size(1), 1)
                combined_features = self.channel_adapter(combined_features)
            segmentation = basic_output + combined_features
        else:
            segmentation = basic_output
        
        return {
            'segmentation': segmentation,
            'basic_output': basic_output,
            'advanced_features': advanced_features,
            'intermediate_outputs': intermediate_outputs
        }
