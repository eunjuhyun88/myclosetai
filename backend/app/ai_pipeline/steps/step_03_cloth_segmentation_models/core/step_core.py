#!/usr/bin/env python3
"""
ðŸ”¥ MyCloset AI - Step 03: ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ - Step Core
=====================================================================

ClothSegmentationStep í´ëž˜ìŠ¤ì˜ í•µì‹¬ ê¸°ëŠ¥ë“¤

Author: MyCloset AI Team  
Date: 2025-08-01
Version: 1.0
"""

import logging
import threading
import gc
import time
from typing import Dict, Any, Optional, List, Tuple
from concurrent.futures import ThreadPoolExecutor

try:
    import numpy as np
    import cv2
    NUMPY_AVAILABLE = True
    CV2_AVAILABLE = True
except ImportError:
    NUMPY_AVAILABLE = False
    CV2_AVAILABLE = False
    np = None
    cv2 = None

try:
    import torch
    TORCH_AVAILABLE = True
except ImportError:
    TORCH_AVAILABLE = False

from ..base import BaseStepMixin
from ..config import ClothSegmentationConfig, SegmentationMethod, ClothCategory, QualityLevel

logger = logging.getLogger(__name__)

class ClothSegmentationStepCore(BaseStepMixin):
    """
    ðŸ”¥ ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ Step - í•µì‹¬ ê¸°ëŠ¥ë“¤
    
    ë¶„ë¦¬ëœ í•µì‹¬ ê¸°ëŠ¥ë“¤:
    - ì´ˆê¸°í™” ë° ì„¤ì • ê´€ë¦¬
    - ëª¨ë¸ ë¡œë”© ë° ê´€ë¦¬
    - AI ì¶”ë¡  ì‹¤í–‰
    - ê²°ê³¼ ì²˜ë¦¬ ë° ê²€ì¦
    """
    
    def __init__(self, **kwargs):
        """í•µì‹¬ ì´ˆê¸°í™”"""
        try:
            # ðŸ”¥ 1. í•„ìˆ˜ ì†ì„±ë“¤ ìš°ì„  ì´ˆê¸°í™” (ì—ëŸ¬ ë°©ì§€)
            self._initialize_critical_attributes()
            
            # ðŸ”¥ 2. BaseStepMixin ì´ˆê¸°í™” (ì•ˆì „í•œ í˜¸ì¶œ)
            try:
                super().__init__(step_name="ClothSegmentationStep", **kwargs)
            except Exception as e:
                logger.warning(f"âš ï¸ BaseStepMixin ì´ˆê¸°í™” ì‹¤íŒ¨, í´ë°± ëª¨ë“œ: {e}")
                self._fallback_initialization(**kwargs)
            
            # ðŸ”¥ 3. Cloth Segmentation íŠ¹í™” ì´ˆê¸°í™”
            self._initialize_cloth_segmentation_specifics()
            
            logger.info(f"âœ… {self.step_name} í•µì‹¬ ì´ˆê¸°í™” ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"âŒ ClothSegmentationStepCore ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self._emergency_setup(**kwargs)

    def _initialize_critical_attributes(self):
        """ì¤‘ìš” ì†ì„±ë“¤ ìš°ì„  ì´ˆê¸°í™”"""
        # Logger ë¨¼ì € ì„¤ì •
        self.logger = logging.getLogger(self.__class__.__name__)
        
        # í•„ìˆ˜ ì†ì„±ë“¤
        self.step_name = "ClothSegmentationStep"
        self.step_id = 3
        self.device = "cpu"
        self.is_initialized = False
        self.is_ready = False
        
        # ðŸ”¥ ëˆ„ë½ë˜ì—ˆë˜ ì†ì„±ë“¤ ì¶”ê°€ (ì˜¤ë¥˜ í•´ê²°)
        self.segmentation_models = {}
        self.segmentation_ready = False
        self.cloth_cache = {}
        
        # í•µì‹¬ ì»¨í…Œì´ë„ˆë“¤
        self.ai_models = {}
        self.model_paths = {}
        self.loaded_models = {}
        self.models_loading_status = {
            'deeplabv3plus': False,
            'maskrcnn': False,
            'sam_huge': False,
            'u2net_cloth': False,
            'total_loaded': 0,
            'loading_errors': []
        }
        
        # ì˜ë¥˜ ì¹´í…Œê³ ë¦¬ ì •ì˜ (ì¶”ê°€)
        self.cloth_categories = {
            0: 'background',
            1: 'shirt', 2: 't_shirt', 3: 'sweater', 4: 'hoodie',
            5: 'jacket', 6: 'coat', 7: 'dress', 8: 'skirt',
            9: 'pants', 10: 'jeans', 11: 'shorts',
            12: 'shoes', 13: 'boots', 14: 'sneakers',
            15: 'bag', 16: 'hat', 17: 'glasses', 18: 'scarf', 19: 'belt'
        }
        
        # í†µê³„ (ì¶”ê°€)
        self.ai_stats = {
            'total_processed': 0,
            'deeplabv3_calls': 0,
            'sam_calls': 0,
            'u2net_calls': 0,
            'average_confidence': 0.0
        }
        
        # ì˜ì¡´ì„± ì£¼ìž… ê´€ë ¨
        self.model_loader = None
        self.model_interface = None
        
    def _fallback_initialization(self, **kwargs):
        """BaseStepMixin ì´ˆê¸°í™” ì‹¤íŒ¨ì‹œ í´ë°±"""
        self.logger.warning("âš ï¸ í´ë°± ì´ˆê¸°í™” ëª¨ë“œ")
        self.step_name = kwargs.get('step_name', 'ClothSegmentationStep')
        self.step_id = kwargs.get('step_id', 3)
        self.device = kwargs.get('device', 'cpu')

    def _initialize_step_attributes(self):
        """Step í•„ìˆ˜ ì†ì„±ë“¤ ì´ˆê¸°í™” (BaseStepMixin í˜¸í™˜)"""
        self.ai_models = {}
        self.models_loading_status = {
            'deeplabv3plus': False,
            'maskrcnn': False,
            'sam_huge': False,
            'u2net_cloth': False,
            'total_loaded': 0,
            'loading_errors': []
        }
        self.model_interface = None
        self.loaded_models = {}
        
        # Cloth Segmentation íŠ¹í™” ì†ì„±ë“¤
        self.segmentation_models = {}
        self.segmentation_ready = False
        self.cloth_cache = {}
        
        # ì˜ë¥˜ ì¹´í…Œê³ ë¦¬ ì •ì˜
        self.cloth_categories = {category.value: category.name.lower() 
                                for category in ClothCategory}
        
        # í†µê³„
        self.ai_stats = {
            'total_processed': 0,
            'deeplabv3_calls': 0,
            'sam_calls': 0,
            'u2net_calls': 0,
            'average_confidence': 0.0
        }
    
    def _initialize_cloth_segmentation_specifics(self):
        """Cloth Segmentation íŠ¹í™” ì´ˆê¸°í™”"""
        try:
            # ì„¤ì •
            self.config = ClothSegmentationConfig()
            
            # ðŸ”§ í•µì‹¬ ì†ì„±ë“¤ ì•ˆì „ ì´ˆê¸°í™”
            if not hasattr(self, 'model_paths'):
                self.model_paths = {}
            if not hasattr(self, 'ai_models'):
                self.ai_models = {}
            
            # ì‹œìŠ¤í…œ ìµœì í™”
            self.is_m3_max = self._detect_m3_max()
            self.memory_gb = 16.0
            
            # ì„±ëŠ¥ ë° ìºì‹±
            try:
                self.executor = ThreadPoolExecutor(
                    max_workers=4 if self.is_m3_max else 2,
                    thread_name_prefix="cloth_seg"
                )
            except Exception as e:
                logger.warning(f"ThreadPoolExecutor ìƒì„± ì‹¤íŒ¨: {e}")
                self.executor = None
            
            self.segmentation_cache = {}
            self.cache_lock = threading.RLock()
            
            # ì‚¬ìš© ê°€ëŠ¥í•œ ë°©ë²• ì´ˆê¸°í™”
            self.available_methods = []
            
            logger.debug(f"âœ… {self.step_name} íŠ¹í™” ì´ˆê¸°í™” ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"âŒ Cloth Segmentation íŠ¹í™” ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            # ðŸ”§ ìµœì†Œí•œì˜ ì†ì„±ë“¤ ë³´ìž¥
            self.model_paths = {}
            self.ai_models = {}
            self.available_methods = []
    
    def _emergency_setup(self, **kwargs):
        """ê¸´ê¸‰ ì„¤ì •"""
        try:
            self.logger.warning("âš ï¸ ê¸´ê¸‰ ì„¤ì • ëª¨ë“œ")
            self.step_name = kwargs.get('step_name', 'ClothSegmentationStep')
            self.step_id = kwargs.get('step_id', 3)
            self.device = kwargs.get('device', 'cpu')
            self.is_initialized = False
            self.is_ready = False
            self.ai_models = {}
            self.model_paths = {}
            self.ai_stats = {'total_processed': 0}
            self.config = ClothSegmentationConfig()
            self.cache_lock = threading.RLock()
            self.cloth_categories = {category.value: category.name.lower() 
                                    for category in ClothCategory}
        except Exception as e:
            logger.error(f"âŒ ê¸´ê¸‰ ì„¤ì •ë„ ì‹¤íŒ¨: {e}")
            self.model_paths = {}
    
    def _detect_m3_max(self) -> bool:
        """M3 Max ê°ì§€"""
        try:
            import platform
            import subprocess
            if platform.system() == 'Darwin':
                result = subprocess.run(
                    ['sysctl', '-n', 'machdep.cpu.brand_string'],
                    capture_output=True, text=True, timeout=5
                )
                return 'M3' in result.stdout
        except:
            pass
        return False

    def initialize(self) -> bool:
        """AI ëª¨ë¸ ì´ˆê¸°í™” + ë©”ëª¨ë¦¬ ì•ˆì „ì„± ê°•í™”"""
        try:
            if self.is_initialized:
                return True
            
            # ë©”ëª¨ë¦¬ ì •ë¦¬
            gc.collect()
            
            # ë©”ëª¨ë¦¬ ì•ˆì „ì„± ì²´í¬
            try:
                import psutil
                memory_usage = psutil.virtual_memory().percent
                if memory_usage > 90:
                    logger.warning(f"âš ï¸ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ ë†’ìŠµë‹ˆë‹¤: {memory_usage}% - ì•ˆì „ ëª¨ë“œë¡œ ì „í™˜")
                    return self._fallback_initialization()
            except ImportError:
                pass
            
            logger.info(f"ðŸ”„ {self.step_name} AI ëª¨ë¸ ì´ˆê¸°í™” ì‹œìž‘...")
            
            # ðŸ”¥ 1. ëª¨ë¸ ë¡œë”© (ë©”ëª¨ë¦¬ ì•ˆì „ ëª¨ë“œ)
            try:
                logger.info("ðŸ”„ AI ëª¨ë¸ ë¡œë”© ì‹œìž‘...")
                self._load_segmentation_models_via_central_hub()
                logger.info("âœ… AI ëª¨ë¸ ë¡œë”© ì™„ë£Œ")
            except Exception as e:
                logger.error(f"âŒ AI ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e}")
                return self._fallback_initialization()
            
            # 2. ì‚¬ìš© ê°€ëŠ¥í•œ ë°©ë²• ê°ì§€
            self.available_methods = self._detect_available_methods()
            
            # 3. BaseStepMixin ì´ˆê¸°í™”
            super_initialized = super().initialize() if hasattr(super(), 'initialize') else True
            
            self.is_initialized = True
            self.is_ready = True
            self.segmentation_ready = len(self.ai_models) > 0
            
            logger.info(f"âœ… {self.step_name} ì´ˆê¸°í™” ì™„ë£Œ")
            return True
            
        except Exception as e:
            logger.error(f"âŒ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return False

    def _load_segmentation_models_via_central_hub(self):
        """Central Hubë¥¼ í†µí•œ ì„¸ê·¸ë©˜í…Œì´ì…˜ ëª¨ë¸ ë¡œë”©"""
        # ì´ ë©”ì„œë“œëŠ” model_loader_service.pyë¡œ ì´ë™ë  ì˜ˆì •
        pass

    def _detect_available_methods(self) -> List[SegmentationMethod]:
        """ì‚¬ìš© ê°€ëŠ¥í•œ ì„¸ê·¸ë©˜í…Œì´ì…˜ ë°©ë²• ê°ì§€"""
        available_methods = []
        
        # U2Net ì²´í¬
        if 'u2net_cloth' in self.ai_models:
            available_methods.append(SegmentationMethod.U2NET_CLOTH)
        
        # SAM ì²´í¬
        if 'sam_huge' in self.ai_models:
            available_methods.append(SegmentationMethod.SAM_HUGE)
        
        # DeepLabV3+ ì²´í¬
        if 'deeplabv3plus' in self.ai_models:
            available_methods.append(SegmentationMethod.DEEPLABV3_PLUS)
        
        # í•˜ì´ë¸Œë¦¬ë“œ AI (ì—¬ëŸ¬ ëª¨ë¸ì´ ìžˆì„ ë•Œ)
        if len(available_methods) > 1:
            available_methods.append(SegmentationMethod.HYBRID_AI)
        
        return available_methods

    def cleanup(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        try:
            # ìºì‹œ ì •ë¦¬
            if hasattr(self, 'segmentation_cache'):
                self.segmentation_cache.clear()
            
            # ëª¨ë¸ ì •ë¦¬
            if hasattr(self, 'ai_models'):
                for model in self.ai_models.values():
                    if hasattr(model, 'cleanup'):
                        model.cleanup()
                self.ai_models.clear()
            
            # Executor ì •ë¦¬
            if hasattr(self, 'executor') and self.executor:
                self.executor.shutdown(wait=True)
            
            # ë©”ëª¨ë¦¬ ì •ë¦¬
            gc.collect()
            if TORCH_AVAILABLE and hasattr(torch, 'mps') and torch.mps.is_available():
                torch.mps.empty_cache()
            
            logger.info(f"âœ… {self.step_name} ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"âŒ ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì‹¤íŒ¨: {e}")

    def get_status(self) -> Dict[str, Any]:
        """í˜„ìž¬ ìƒíƒœ ë°˜í™˜"""
        return {
            'step_name': self.step_name,
            'step_id': self.step_id,
            'is_initialized': self.is_initialized,
            'is_ready': self.is_ready,
            'segmentation_ready': self.segmentation_ready,
            'available_methods': [method.value for method in self.available_methods],
            'models_loaded': len(self.ai_models),
            'total_processed': self.ai_stats.get('total_processed', 0),
            'memory_usage': self._get_memory_usage()
        }

    def _get_memory_usage(self) -> Dict[str, Any]:
        """ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì •ë³´"""
        try:
            import psutil
            memory = psutil.virtual_memory()
            return {
                'total_gb': round(memory.total / (1024**3), 2),
                'available_gb': round(memory.available / (1024**3), 2),
                'used_percent': memory.percent
            }
        except ImportError:
            return {'error': 'psutil not available'}
