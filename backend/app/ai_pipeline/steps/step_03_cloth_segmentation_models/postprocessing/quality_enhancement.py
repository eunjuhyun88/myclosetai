#!/usr/bin/env python3
"""
ğŸ”¥ MyCloset AI - Step 03: ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ - Quality Enhancement
=====================================================================

í’ˆì§ˆ í–¥ìƒ ê´€ë ¨ í›„ì²˜ë¦¬ ê¸°ëŠ¥ë“¤ì„ ë¶„ë¦¬í•œ ëª¨ë“ˆ

Author: MyCloset AI Team  
Date: 2025-08-01
Version: 1.0
"""

import logging
import numpy as np
import cv2
from typing import Dict, Any, List, Tuple, Optional

logger = logging.getLogger(__name__)

def _fill_holes_and_remove_noise_advanced(self, masks: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:
    """ê³ ê¸‰ í™€ ì±„ìš°ê¸° ë° ë…¸ì´ì¦ˆ ì œê±°"""
    try:
        processed_masks = {}
        
        for mask_type, mask in masks.items():
            if mask is None or mask.size == 0:
                continue
            
            # ë…¸ì´ì¦ˆ ì œê±°
            kernel = np.ones((3, 3), np.uint8)
            mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)
            mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)
            
            # í™€ ì±„ìš°ê¸°
            contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            if contours:
                # ê°€ì¥ í° ì»¨íˆ¬ì–´ ì°¾ê¸°
                largest_contour = max(contours, key=cv2.contourArea)
                
                # í™€ ì±„ìš°ê¸°
                filled_mask = np.zeros_like(mask)
                cv2.fillPoly(filled_mask, [largest_contour], 1)
                
                # ì‘ì€ í™€ë“¤ë„ ì±„ìš°ê¸°
                filled_mask = cv2.morphologyEx(filled_mask, cv2.MORPH_CLOSE, np.ones((5, 5), np.uint8))
                
                processed_masks[mask_type] = filled_mask
            else:
                processed_masks[mask_type] = mask
        
        return processed_masks
        
    except Exception as e:
        logger.warning(f"ê³ ê¸‰ í™€ ì±„ìš°ê¸° ë° ë…¸ì´ì¦ˆ ì œê±° ì‹¤íŒ¨: {e}")
        return masks

def _evaluate_segmentation_quality(self, masks: Dict[str, np.ndarray], image: np.ndarray) -> Dict[str, float]:
    """ì„¸ê·¸ë©˜í…Œì´ì…˜ í’ˆì§ˆ í‰ê°€"""
    try:
        quality_metrics = {}
        
        for mask_type, mask in masks.items():
            if mask is None or mask.size == 0:
                quality_metrics[mask_type] = 0.0
                continue
            
            # ë©´ì  ë¹„ìœ¨
            total_pixels = mask.size
            mask_pixels = np.sum(mask)
            area_ratio = mask_pixels / total_pixels
            
            # ê²½ê³„ í’ˆì§ˆ
            edges = cv2.Canny(mask.astype(np.uint8) * 255, 50, 150)
            edge_density = np.sum(edges) / (edges.size * 255)
            
            # ì—°ê²°ì„±
            contours, _ = cv2.findContours(mask.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            connectivity_score = 1.0 / (len(contours) + 1)  # ì»¨íˆ¬ì–´ê°€ ì ì„ìˆ˜ë¡ ì¢‹ìŒ
            
            # ì›í˜•ë„ (circularity)
            if contours:
                largest_contour = max(contours, key=cv2.contourArea)
                contour_area = cv2.contourArea(largest_contour)
                contour_perimeter = cv2.arcLength(largest_contour, True)
                
                if contour_perimeter > 0:
                    circularity = 4 * np.pi * contour_area / (contour_perimeter ** 2)
                else:
                    circularity = 0.0
            else:
                circularity = 0.0
            
            # ì¢…í•© í’ˆì§ˆ ì ìˆ˜
            quality_score = (
                area_ratio * 0.3 +
                (1 - edge_density) * 0.2 +
                connectivity_score * 0.3 +
                circularity * 0.2
            )
            
            quality_metrics[mask_type] = min(quality_score, 1.0)
        
        return quality_metrics
        
    except Exception as e:
        logger.warning(f"ì„¸ê·¸ë©˜í…Œì´ì…˜ í’ˆì§ˆ í‰ê°€ ì‹¤íŒ¨: {e}")
        return {mask_type: 0.5 for mask_type in masks.keys()}

def _create_segmentation_visualizations(self, image: np.ndarray, masks: Dict[str, np.ndarray]) -> Dict[str, Any]:
    """ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‹œê°í™” ìƒì„±"""
    try:
        visualizations = {}
        
        if image is None or not masks:
            return visualizations
        
        # ì›ë³¸ ì´ë¯¸ì§€ ë³µì‚¬
        overlay_image = image.copy()
        
        # ìƒ‰ìƒ ë§¤í•‘
        colors = [
            [255, 0, 0],    # ë¹¨ê°•
            [0, 255, 0],    # ì´ˆë¡
            [0, 0, 255],    # íŒŒë‘
            [255, 255, 0],  # ë…¸ë‘
            [255, 0, 255],  # ë§ˆì  íƒ€
            [0, 255, 255]   # ì‹œì•ˆ
        ]
        
        # ë§ˆìŠ¤í¬ ì˜¤ë²„ë ˆì´ ìƒì„±
        for i, (mask_type, mask) in enumerate(masks.items()):
            if mask is not None and np.any(mask):
                color = colors[i % len(colors)]
                
                # ë§ˆìŠ¤í¬ë¥¼ 3ì±„ë„ë¡œ í™•ì¥
                mask_3d = np.stack([mask, mask, mask], axis=-1)
                
                # ìƒ‰ìƒ ì ìš©
                colored_mask = np.array(color) * mask_3d
                
                # ì•ŒíŒŒ ë¸”ë Œë”©
                alpha = 0.6
                overlay_image = overlay_image * (1 - alpha * mask_3d) + colored_mask * alpha * mask_3d
        
        visualizations['overlay'] = overlay_image.astype(np.uint8)
        
        # ê°œë³„ ë§ˆìŠ¤í¬ ì‹œê°í™”
        for mask_type, mask in masks.items():
            if mask is not None:
                visualizations[f'mask_{mask_type}'] = (mask * 255).astype(np.uint8)
        
        return visualizations
        
    except Exception as e:
        logger.warning(f"ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‹œê°í™” ìƒì„± ì‹¤íŒ¨: {e}")
        return {}

def _assess_image_quality(self, image: np.ndarray) -> Dict[str, float]:
    """ì´ë¯¸ì§€ í’ˆì§ˆ í‰ê°€"""
    try:
        quality_scores = {}
        
        if image is None:
            return {'brightness': 0.5, 'contrast': 0.5, 'sharpness': 0.5, 'noise_level': 0.5}
        
        # ë°ê¸° í‰ê°€
        if len(image.shape) == 3:
            gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
        else:
            gray = image
        
        brightness = np.mean(gray) / 255.0
        quality_scores['brightness'] = brightness
        
        # ëŒ€ë¹„ í‰ê°€
        contrast = np.std(gray) / 255.0
        quality_scores['contrast'] = contrast
        
        # ì„ ëª…ë„ í‰ê°€
        laplacian = cv2.Laplacian(gray, cv2.CV_64F)
        sharpness = np.var(laplacian) / 1000.0  # ì •ê·œí™”
        quality_scores['sharpness'] = min(sharpness, 1.0)
        
        # ë…¸ì´ì¦ˆ ë ˆë²¨ í‰ê°€
        blurred = cv2.GaussianBlur(gray, (5, 5), 0)
        noise = np.mean(np.abs(gray.astype(np.float32) - blurred.astype(np.float32))) / 255.0
        quality_scores['noise_level'] = min(noise, 1.0)
        
        return quality_scores
        
    except Exception as e:
        logger.warning(f"ì´ë¯¸ì§€ í’ˆì§ˆ í‰ê°€ ì‹¤íŒ¨: {e}")
        return {'brightness': 0.5, 'contrast': 0.5, 'sharpness': 0.5, 'noise_level': 0.5}

def _normalize_lighting(self, image: np.ndarray) -> np.ndarray:
    """ì¡°ëª… ì •ê·œí™”"""
    try:
        if image is None:
            return image
        
        # LAB ìƒ‰ê³µê°„ìœ¼ë¡œ ë³€í™˜
        if len(image.shape) == 3:
            lab = cv2.cvtColor(image, cv2.COLOR_RGB2LAB)
        else:
            # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ì¸ ê²½ìš° 3ì±„ë„ë¡œ í™•ì¥
            lab = cv2.cvtColor(cv2.cvtColor(image, cv2.COLOR_GRAY2RGB), cv2.COLOR_RGB2LAB)
        
        # L ì±„ë„ ì •ê·œí™”
        l_channel = lab[:, :, 0]
        
        # íˆìŠ¤í† ê·¸ë¨ í‰í™œí™”
        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
        l_channel_normalized = clahe.apply(l_channel)
        
        # ì •ê·œí™”ëœ L ì±„ë„ë¡œ êµì²´
        lab[:, :, 0] = l_channel_normalized
        
        # RGBë¡œ ë³€í™˜
        normalized_image = cv2.cvtColor(lab, cv2.COLOR_LAB2RGB)
        
        return normalized_image
        
    except Exception as e:
        logger.warning(f"ì¡°ëª… ì •ê·œí™” ì‹¤íŒ¨: {e}")
        return image

def _correct_colors(self, image: np.ndarray) -> np.ndarray:
    """ìƒ‰ìƒ ë³´ì •"""
    try:
        if image is None:
            return image
        
        # ìƒ‰ìƒ ë³´ì •ì„ ìœ„í•œ ê°„ë‹¨í•œ ë°©ë²•
        # í™”ì´íŠ¸ ë°¸ëŸ°ìŠ¤ ì ìš©
        if len(image.shape) == 3:
            # ê° ì±„ë„ì˜ í‰ê· ê°’ ê³„ì‚°
            means = np.mean(image, axis=(0, 1))
            
            # í™”ì´íŠ¸ ë°¸ëŸ°ìŠ¤ ì ìš©
            max_mean = np.max(means)
            if max_mean > 0:
                white_balanced = image * (max_mean / means)
                white_balanced = np.clip(white_balanced, 0, 255).astype(np.uint8)
                return white_balanced
        
        return image
        
    except Exception as e:
        logger.warning(f"ìƒ‰ìƒ ë³´ì • ì‹¤íŒ¨: {e}")
        return image
