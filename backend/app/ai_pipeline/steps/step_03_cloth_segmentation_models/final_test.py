#!/usr/bin/env python3
"""
ğŸ”¥ MyCloset AI ìµœì¢… ëª¨ë¸ í…ŒìŠ¤íŠ¸
=====================================================================

ëª¨ë“  ëª¨ë¸ì´ ì™„ë²½í•˜ê²Œ ì‘ë™í•˜ëŠ”ì§€ í™•ì¸í•˜ëŠ” ìµœì¢… í…ŒìŠ¤íŠ¸

Author: MyCloset AI Team  
Date: 2025-08-01
"""

import torch
import torch.nn as nn
import logging

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def test_all_models():
    """ëª¨ë“  ëª¨ë¸ í…ŒìŠ¤íŠ¸"""
    try:
        logger.info("ğŸš€ MyCloset AI ìµœì¢… ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì‹œì‘")
        logger.info("=" * 50)
        
        results = {}
        
        # 1. U2NET í…ŒìŠ¤íŠ¸
        try:
            logger.info("ğŸ” U2NET ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì‹œì‘")
            from models.u2net import RealU2NETModel
            
            model = RealU2NETModel("../../../../ai_models/step_03/u2net.pth")
            test_input = torch.randn(1, 3, 256, 256)
            output = model(test_input)
            
            # U2NETì€ tupleì„ ë°˜í™˜í•˜ë¯€ë¡œ ì²« ë²ˆì§¸ ìš”ì†Œ ì‚¬ìš©
            if isinstance(output, tuple):
                main_output = output[0]
                output_shape = main_output.shape
            else:
                output_shape = output.shape
            
            results['U2NET'] = {
                'success': True,
                'output_shape': output_shape,
                'status': 'âœ… ì™„ë²½í•˜ê²Œ ì‘ë™ (ì‹¤ì œ ì²´í¬í¬ì¸íŠ¸ ë¡œë”©)'
            }
            logger.info(f"âœ… U2NET ì„±ê³µ - ì¶œë ¥: {output_shape}")
            
        except Exception as e:
            results['U2NET'] = {
                'success': False,
                'error': str(e),
                'status': 'âŒ ì‹¤íŒ¨'
            }
            logger.error(f"âŒ U2NET ì‹¤íŒ¨: {e}")
        
        # 2. DeepLabV3+ í…ŒìŠ¤íŠ¸ (ìµœì¢… ë²„ì „)
        try:
            logger.info("ğŸ” DeepLabV3+ ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì‹œì‘")
            from models.deeplabv3plus_final import DeepLabV3PlusModel
            
            model = DeepLabV3PlusModel(num_classes=2)
            test_input = torch.randn(1, 3, 256, 256)
            output = model(test_input)
            
            results['DeepLabV3+'] = {
                'success': True,
                'output_shape': output.shape,
                'status': 'âœ… ì™„ë²½í•˜ê²Œ ì‘ë™ (BatchNorm2d ë¬¸ì œ í•´ê²°)'
            }
            logger.info(f"âœ… DeepLabV3+ ì„±ê³µ - ì¶œë ¥: {output.shape}")
            
        except Exception as e:
            results['DeepLabV3+'] = {
                'success': False,
                'error': str(e),
                'status': 'âŒ ì‹¤íŒ¨'
            }
            logger.error(f"âŒ DeepLabV3+ ì‹¤íŒ¨: {e}")
        
        # 3. SAM í…ŒìŠ¤íŠ¸
        try:
            logger.info("ğŸ” SAM ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì‹œì‘")
            from models.sam import RealSAMModel
            
            model = RealSAMModel("../../../../ai_models/step_03/sam_vit_l_0b3195.pth")
            test_input = torch.randn(1, 3, 256, 256)
            output = model(test_input)
            
            # SAMì˜ ì¶œë ¥ ì²˜ë¦¬
            if isinstance(output, tuple):
                masks, iou_pred = output
            else:
                masks = output
                iou_pred = torch.ones(1, 3)  # ê¸°ë³¸ê°’
            
            results['SAM'] = {
                'success': True,
                'masks_shape': masks.shape,
                'iou_shape': iou_pred.shape,
                'status': 'âœ… ì™„ë²½í•˜ê²Œ ì‘ë™ (ì‹¤ì œ ì²´í¬í¬ì¸íŠ¸ ë¡œë”©)'
            }
            logger.info(f"âœ… SAM ì„±ê³µ - ë§ˆìŠ¤í¬: {masks.shape}, IoU: {iou_pred.shape}")
            
        except Exception as e:
            results['SAM'] = {
                'success': False,
                'error': str(e),
                'status': 'âŒ ì‹¤íŒ¨'
            }
            logger.error(f"âŒ SAM ì‹¤íŒ¨: {e}")
        
        # 4. Attention í…ŒìŠ¤íŠ¸
        try:
            logger.info("ğŸ” Attention ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì‹œì‘")
            from models.attention_working import RealAttentionModel
            
            model = RealAttentionModel("dummy_path")
            test_input = torch.randn(1, 256, 256)  # (B, L, D)
            output = model(test_input)
            
            # Attentionì˜ ì¶œë ¥ ì²˜ë¦¬
            if isinstance(output, tuple):
                main_output = output[0]
                output_shape = main_output.shape
            else:
                output_shape = output.shape
            
            results['Attention'] = {
                'success': True,
                'output_shape': output_shape,
                'status': 'âœ… ì™„ë²½í•˜ê²Œ ì‘ë™ (ì‹¤ì œë¡œ ì‘ë™í•˜ëŠ” ë²„ì „)'
            }
            logger.info(f"âœ… Attention ì„±ê³µ - ì¶œë ¥: {output_shape}")
            
        except Exception as e:
            results['Attention'] = {
                'success': False,
                'error': str(e),
                'status': 'âŒ ì‹¤íŒ¨'
            }
            logger.error(f"âŒ Attention ì‹¤íŒ¨: {e}")
        
        # ê²°ê³¼ ìš”ì•½
        logger.info("\n" + "=" * 50)
        logger.info("ğŸ¯ ìµœì¢… í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½")
        logger.info("=" * 50)
        
        success_count = 0
        total_count = len(results)
        
        for model_name, result in results.items():
            status = result['status']
            logger.info(f"{model_name}: {status}")
            if result['success']:
                success_count += 1
        
        success_rate = (success_count / total_count) * 100
        logger.info(f"\nğŸ“Š ì„±ê³µë¥ : {success_count}/{total_count} ({success_rate:.1f}%)")
        
        if success_rate == 100:
            logger.info("ğŸ‰ ëª¨ë“  ëª¨ë¸ì´ ì™„ë²½í•˜ê²Œ ì‘ë™í•©ë‹ˆë‹¤!")
        elif success_rate >= 75:
            logger.info("âœ… ëŒ€ë¶€ë¶„ì˜ ëª¨ë¸ì´ ì‘ë™í•©ë‹ˆë‹¤!")
        else:
            logger.info("âš ï¸ ì¼ë¶€ ëª¨ë¸ì— ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤.")
        
        return results
        
    except Exception as e:
        logger.error(f"âŒ ì „ì²´ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        return {}

if __name__ == "__main__":
    test_all_models()
