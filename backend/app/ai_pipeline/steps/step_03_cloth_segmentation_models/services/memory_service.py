#!/usr/bin/env python3
"""
ğŸ”¥ MyCloset AI - Step 03: ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ - Memory Service
=====================================================================

ë©”ëª¨ë¦¬ ê´€ë¦¬ë¥¼ ìœ„í•œ ì „ìš© ì„œë¹„ìŠ¤

Author: MyCloset AI Team  
Date: 2025-08-01
Version: 1.0
"""

import logging
import gc
from typing import Dict, Any, Optional
import numpy as np

try:
    import torch
    TORCH_AVAILABLE = True
except ImportError:
    TORCH_AVAILABLE = False

logger = logging.getLogger(__name__)

class MemoryService:
    """ë©”ëª¨ë¦¬ ê´€ë¦¬ ì„œë¹„ìŠ¤"""
    
    def __init__(self, config: Optional[Dict[str, Any]] = None):
        """ì´ˆê¸°í™”"""
        self.config = config or {}
        self.logger = logging.getLogger(f"{__name__}.MemoryService")
        self.memory_stats = {}
        
    def cleanup_memory(self) -> bool:
        """ë©”ëª¨ë¦¬ ì •ë¦¬"""
        try:
            # Python GC ì •ë¦¬
            gc.collect()
            
            # PyTorch ë©”ëª¨ë¦¬ ì •ë¦¬
            if TORCH_AVAILABLE:
                if torch.cuda.is_available():
                    torch.cuda.empty_cache()
                elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
                    torch.mps.empty_cache()
            
            self.logger.info("âœ… ë©”ëª¨ë¦¬ ì •ë¦¬ ì™„ë£Œ")
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ ë©”ëª¨ë¦¬ ì •ë¦¬ ì‹¤íŒ¨: {e}")
            return False
    
    def get_memory_usage(self) -> Dict[str, Any]:
        """ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ê°€ì ¸ì˜¤ê¸°"""
        try:
            memory_info = {}
            
            # Python ë©”ëª¨ë¦¬ ì •ë³´
            import psutil
            process = psutil.Process()
            memory_info['python_memory'] = {
                'rss': process.memory_info().rss / 1024 / 1024,  # MB
                'vms': process.memory_info().vms / 1024 / 1024,  # MB
            }
            
            # PyTorch ë©”ëª¨ë¦¬ ì •ë³´
            if TORCH_AVAILABLE:
                if torch.cuda.is_available():
                    memory_info['cuda_memory'] = {
                        'allocated': torch.cuda.memory_allocated() / 1024 / 1024,  # MB
                        'cached': torch.cuda.memory_reserved() / 1024 / 1024,  # MB
                    }
                elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
                    memory_info['mps_memory'] = {
                        'available': 'MPS memory info not available'
                    }
            
            return memory_info
            
        except Exception as e:
            self.logger.error(f"âŒ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {}
    
    def optimize_memory(self) -> bool:
        """ë©”ëª¨ë¦¬ ìµœì í™”"""
        try:
            # 1. ë¶ˆí•„ìš”í•œ ê°ì²´ ì •ë¦¬
            gc.collect()
            
            # 2. PyTorch ë©”ëª¨ë¦¬ ìµœì í™”
            if TORCH_AVAILABLE:
                if torch.cuda.is_available():
                    torch.cuda.empty_cache()
                    torch.cuda.synchronize()
                elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
                    torch.mps.empty_cache()
            
            # 3. NumPy ë©”ëª¨ë¦¬ ìµœì í™”
            if hasattr(np, 'get_include'):
                # NumPy ë©”ëª¨ë¦¬ ìµœì í™” (ê°€ëŠ¥í•œ ê²½ìš°)
                pass
            
            self.logger.info("âœ… ë©”ëª¨ë¦¬ ìµœì í™” ì™„ë£Œ")
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ ë©”ëª¨ë¦¬ ìµœì í™” ì‹¤íŒ¨: {e}")
            return False
    
    def monitor_memory(self) -> Dict[str, Any]:
        """ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§"""
        try:
            memory_stats = self.get_memory_usage()
            
            # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë¶„ì„
            if 'python_memory' in memory_stats:
                rss_mb = memory_stats['python_memory']['rss']
                if rss_mb > 1000:  # 1GB ì´ìƒ
                    self.logger.warning(f"âš ï¸ ë†’ì€ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {rss_mb:.1f}MB")
            
            return memory_stats
            
        except Exception as e:
            self.logger.error(f"âŒ ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§ ì‹¤íŒ¨: {e}")
            return {}
