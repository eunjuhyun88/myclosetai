#!/usr/bin/env python3
"""
ğŸ”¥ MyCloset AI - Step 03: ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ - Model Loader Service
=====================================================================

ëª¨ë¸ ë¡œë”© ë° ê´€ë¦¬ ì„œë¹„ìŠ¤

Author: MyCloset AI Team  
Date: 2025-08-01
Version: 1.0
"""

import logging
import os
import gc
from typing import Dict, Any, Optional, List
from pathlib import Path

try:
    import torch
    TORCH_AVAILABLE = True
except ImportError:
    TORCH_AVAILABLE = False

try:
    import numpy as np
    NUMPY_AVAILABLE = True
except ImportError:
    NUMPY_AVAILABLE = False

from ..config import SegmentationMethod, ClothCategory, QualityLevel
from ..models import RealDeepLabV3PlusModel, RealU2NETModel, RealSAMModel

logger = logging.getLogger(__name__)

class ModelLoaderService:
    """
    ğŸ”¥ ëª¨ë¸ ë¡œë”© ë° ê´€ë¦¬ ì„œë¹„ìŠ¤
    
    ë¶„ë¦¬ëœ ê¸°ëŠ¥ë“¤:
    - ëª¨ë¸ ê²½ë¡œ ê°ì§€ ë° ê´€ë¦¬
    - ëª¨ë¸ ë¡œë”© ë° ì´ˆê¸°í™”
    - ëª¨ë¸ ìƒíƒœ ê´€ë¦¬
    - ë©”ëª¨ë¦¬ ì•ˆì „ì„± ë³´ì¥
    """
    
    def __init__(self, device: str = "cpu"):
        """ì´ˆê¸°í™”"""
        self.device = device
        self.logger = logging.getLogger(f"{__name__}.ModelLoaderService")
        self.model_paths = {}
        self.loaded_models = {}
        self.models_loading_status = {
            'deeplabv3plus': False,
            'maskrcnn': False,
            'sam_huge': False,
            'u2net_cloth': False,
            'total_loaded': 0,
            'loading_errors': []
        }
        
    def load_segmentation_models(self, model_paths: Optional[Dict[str, str]] = None) -> Dict[str, Any]:
        """ì„¸ê·¸ë©˜í…Œì´ì…˜ ëª¨ë¸ë“¤ì„ ë¡œë”©"""
        try:
            self.logger.info("ğŸ”„ ì„¸ê·¸ë©˜í…Œì´ì…˜ ëª¨ë¸ ë¡œë”© ì‹œì‘...")
            
            # ëª¨ë¸ ê²½ë¡œ ì„¤ì •
            if model_paths:
                self.model_paths = model_paths
            else:
                self._detect_model_paths()
            
            # ê° ëª¨ë¸ ë¡œë”©
            models_loaded = {}
            
            # U2Net ëª¨ë¸ ë¡œë”©
            if 'u2net_cloth' in self.model_paths:
                try:
                    u2net_model = self._load_u2net_model()
                    if u2net_model:
                        models_loaded['u2net_cloth'] = u2net_model
                        self.models_loading_status['u2net_cloth'] = True
                        self.models_loading_status['total_loaded'] += 1
                        self.logger.info("âœ… U2Net ëª¨ë¸ ë¡œë”© ì™„ë£Œ")
                except Exception as e:
                    self.logger.error(f"âŒ U2Net ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e}")
                    self.models_loading_status['loading_errors'].append(f"u2net_cloth: {e}")
            
            # SAM ëª¨ë¸ ë¡œë”©
            if 'sam_huge' in self.model_paths:
                try:
                    sam_model = self._load_sam_model()
                    if sam_model:
                        models_loaded['sam_huge'] = sam_model
                        self.models_loading_status['sam_huge'] = True
                        self.models_loading_status['total_loaded'] += 1
                        self.logger.info("âœ… SAM ëª¨ë¸ ë¡œë”© ì™„ë£Œ")
                except Exception as e:
                    self.logger.error(f"âŒ SAM ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e}")
                    self.models_loading_status['loading_errors'].append(f"sam_huge: {e}")
            
            # DeepLabV3+ ëª¨ë¸ ë¡œë”©
            if 'deeplabv3plus' in self.model_paths:
                try:
                    deeplabv3_model = self._load_deeplabv3plus_model()
                    if deeplabv3_model:
                        models_loaded['deeplabv3plus'] = deeplabv3_model
                        self.models_loading_status['deeplabv3plus'] = True
                        self.models_loading_status['total_loaded'] += 1
                        self.logger.info("âœ… DeepLabV3+ ëª¨ë¸ ë¡œë”© ì™„ë£Œ")
                except Exception as e:
                    self.logger.error(f"âŒ DeepLabV3+ ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e}")
                    self.models_loading_status['loading_errors'].append(f"deeplabv3plus: {e}")
            
            self.loaded_models = models_loaded
            self.logger.info(f"âœ… ì„¸ê·¸ë©˜í…Œì´ì…˜ ëª¨ë¸ ë¡œë”© ì™„ë£Œ: {len(models_loaded)}ê°œ")
            
            return models_loaded
            
        except Exception as e:
            self.logger.error(f"âŒ ì„¸ê·¸ë©˜í…Œì´ì…˜ ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e}")
            return {}

    def _detect_model_paths(self):
        """ëª¨ë¸ ê²½ë¡œ ê°ì§€"""
        try:
            # ê¸°ë³¸ ëª¨ë¸ ê²½ë¡œë“¤
            base_paths = [
                "models/",
                "backend/models/",
                "backend/app/ai_pipeline/models/",
                "backend/app/ai_pipeline/steps/03_cloth_segmentation/models/"
            ]
            
            # ê° ëª¨ë¸ë³„ ê²½ë¡œ ê°ì§€
            model_paths = {}
            
            # U2Net ê²½ë¡œ ê°ì§€
            u2net_paths = [
                "u2net_cloth.pth",
                "u2net_cloth_model.pth",
                "u2net_cloth_weights.pth"
            ]
            
            for base_path in base_paths:
                for u2net_path in u2net_paths:
                    full_path = os.path.join(base_path, u2net_path)
                    if os.path.exists(full_path):
                        model_paths['u2net_cloth'] = full_path
                        break
                if 'u2net_cloth' in model_paths:
                    break
            
            # SAM ê²½ë¡œ ê°ì§€
            sam_paths = [
                "sam_huge.pth",
                "sam_huge_model.pth",
                "sam_huge_weights.pth"
            ]
            
            for base_path in base_paths:
                for sam_path in sam_paths:
                    full_path = os.path.join(base_path, sam_path)
                    if os.path.exists(full_path):
                        model_paths['sam_huge'] = full_path
                        break
                if 'sam_huge' in model_paths:
                    break
            
            # DeepLabV3+ ê²½ë¡œ ê°ì§€
            deeplabv3_paths = [
                "deeplabv3plus.pth",
                "deeplabv3plus_model.pth",
                "deeplabv3plus_weights.pth"
            ]
            
            for base_path in base_paths:
                for deeplabv3_path in deeplabv3_paths:
                    full_path = os.path.join(base_path, deeplabv3_path)
                    if os.path.exists(full_path):
                        model_paths['deeplabv3plus'] = full_path
                        break
                if 'deeplabv3plus' in model_paths:
                    break
            
            self.model_paths = model_paths
            self.logger.info(f"âœ… ëª¨ë¸ ê²½ë¡œ ê°ì§€ ì™„ë£Œ: {len(model_paths)}ê°œ")
            
        except Exception as e:
            self.logger.error(f"âŒ ëª¨ë¸ ê²½ë¡œ ê°ì§€ ì‹¤íŒ¨: {e}")
            self.model_paths = {}

    def _load_u2net_model(self) -> Optional[RealU2NETModel]:
        """U2Net ëª¨ë¸ ë¡œë”©"""
        try:
            if 'u2net_cloth' not in self.model_paths:
                self.logger.warning("âš ï¸ U2Net ëª¨ë¸ ê²½ë¡œê°€ ì—†ìŠµë‹ˆë‹¤")
                return None
            
            model_path = self.model_paths['u2net_cloth']
            self.logger.info(f"ğŸ”„ U2Net ëª¨ë¸ ë¡œë”© ì¤‘: {model_path}")
            
            model = RealU2NETModel(model_path=model_path, device=self.device)
            if model.load():
                self.logger.info("âœ… U2Net ëª¨ë¸ ë¡œë”© ì„±ê³µ")
                return model
            else:
                self.logger.error("âŒ U2Net ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨")
                return None
                
        except Exception as e:
            self.logger.error(f"âŒ U2Net ëª¨ë¸ ë¡œë”© ì¤‘ ì˜¤ë¥˜: {e}")
            return None

    def _load_sam_model(self) -> Optional[RealSAMModel]:
        """SAM ëª¨ë¸ ë¡œë”©"""
        try:
            if 'sam_huge' not in self.model_paths:
                self.logger.warning("âš ï¸ SAM ëª¨ë¸ ê²½ë¡œê°€ ì—†ìŠµë‹ˆë‹¤")
                return None
            
            model_path = self.model_paths['sam_huge']
            self.logger.info(f"ğŸ”„ SAM ëª¨ë¸ ë¡œë”© ì¤‘: {model_path}")
            
            model = RealSAMModel(model_path=model_path, device=self.device)
            if model.load():
                self.logger.info("âœ… SAM ëª¨ë¸ ë¡œë”© ì„±ê³µ")
                return model
            else:
                self.logger.error("âŒ SAM ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨")
                return None
                
        except Exception as e:
            self.logger.error(f"âŒ SAM ëª¨ë¸ ë¡œë”© ì¤‘ ì˜¤ë¥˜: {e}")
            return None

    def _load_deeplabv3plus_model(self) -> Optional[RealDeepLabV3PlusModel]:
        """DeepLabV3+ ëª¨ë¸ ë¡œë”©"""
        try:
            if 'deeplabv3plus' not in self.model_paths:
                self.logger.warning("âš ï¸ DeepLabV3+ ëª¨ë¸ ê²½ë¡œê°€ ì—†ìŠµë‹ˆë‹¤")
                return None
            
            model_path = self.model_paths['deeplabv3plus']
            self.logger.info(f"ğŸ”„ DeepLabV3+ ëª¨ë¸ ë¡œë”© ì¤‘: {model_path}")
            
            model = RealDeepLabV3PlusModel(model_path=model_path, device=self.device)
            if model.load():
                self.logger.info("âœ… DeepLabV3+ ëª¨ë¸ ë¡œë”© ì„±ê³µ")
                return model
            else:
                self.logger.error("âŒ DeepLabV3+ ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨")
                return None
                
        except Exception as e:
            self.logger.error(f"âŒ DeepLabV3+ ëª¨ë¸ ë¡œë”© ì¤‘ ì˜¤ë¥˜: {e}")
            return None

    def get_loaded_models(self) -> Dict[str, Any]:
        """ë¡œë”©ëœ ëª¨ë¸ë“¤ ë°˜í™˜"""
        return self.loaded_models

    def get_loading_status(self) -> Dict[str, Any]:
        """ë¡œë”© ìƒíƒœ ë°˜í™˜"""
        return self.models_loading_status

    def get_model_paths(self) -> Dict[str, str]:
        """ëª¨ë¸ ê²½ë¡œë“¤ ë°˜í™˜"""
        return self.model_paths

    def reload_models(self) -> bool:
        """ëª¨ë¸ë“¤ ì¬ë¡œë”©"""
        try:
            self.logger.info("ğŸ”„ ëª¨ë¸ ì¬ë¡œë”© ì‹œì‘...")
            
            # ê¸°ì¡´ ëª¨ë¸ë“¤ ì •ë¦¬
            self.cleanup_models()
            
            # ëª¨ë¸ë“¤ ë‹¤ì‹œ ë¡œë”©
            models_loaded = self.load_segmentation_models()
            
            success = len(models_loaded) > 0
            if success:
                self.logger.info("âœ… ëª¨ë¸ ì¬ë¡œë”© ì™„ë£Œ")
            else:
                self.logger.warning("âš ï¸ ëª¨ë¸ ì¬ë¡œë”© ì‹¤íŒ¨")
            
            return success
            
        except Exception as e:
            self.logger.error(f"âŒ ëª¨ë¸ ì¬ë¡œë”© ì‹¤íŒ¨: {e}")
            return False

    def cleanup_models(self):
        """ëª¨ë¸ë“¤ ì •ë¦¬"""
        try:
            # ë¡œë”©ëœ ëª¨ë¸ë“¤ ì •ë¦¬
            for model_name, model in self.loaded_models.items():
                if hasattr(model, 'cleanup'):
                    model.cleanup()
                elif hasattr(model, 'cpu'):
                    model.cpu()
            
            self.loaded_models.clear()
            
            # ë©”ëª¨ë¦¬ ì •ë¦¬
            gc.collect()
            if TORCH_AVAILABLE and hasattr(torch, 'mps') and torch.mps.is_available():
                torch.mps.empty_cache()
            
            self.logger.info("âœ… ëª¨ë¸ ì •ë¦¬ ì™„ë£Œ")
            
        except Exception as e:
            self.logger.error(f"âŒ ëª¨ë¸ ì •ë¦¬ ì‹¤íŒ¨: {e}")

    def get_available_models(self) -> List[str]:
        """ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ë“¤ ë°˜í™˜"""
        return list(self.loaded_models.keys())

    def is_model_loaded(self, model_name: str) -> bool:
        """íŠ¹ì • ëª¨ë¸ì´ ë¡œë”©ë˜ì—ˆëŠ”ì§€ í™•ì¸"""
        return model_name in self.loaded_models

    def get_model_info(self, model_name: str) -> Dict[str, Any]:
        """íŠ¹ì • ëª¨ë¸ ì •ë³´ ë°˜í™˜"""
        if model_name not in self.loaded_models:
            return {}
        
        model = self.loaded_models[model_name]
        info = {
            'name': model_name,
            'loaded': True,
            'device': getattr(model, 'device', self.device),
            'model_type': type(model).__name__
        }
        
        # ëª¨ë¸ë³„ ì¶”ê°€ ì •ë³´
        if hasattr(model, 'get_model_info'):
            info.update(model.get_model_info())
        
        return info
