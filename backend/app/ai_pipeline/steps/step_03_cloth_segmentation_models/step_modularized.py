#!/usr/bin/env python3
"""
ğŸ”¥ MyCloset AI - Step 03: ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ - ëª¨ë“ˆí™”ëœ Step
=====================================================================

step.pyë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šê³  ëª¨ë“ˆí™”ëœ êµ¬ì¡°ë¡œ ëª¨ë¸ ë¡œë”©ì´ ê°€ëŠ¥í•˜ë„ë¡ êµ¬í˜„

Author: MyCloset AI Team  
Date: 2025-08-01
Version: 1.0
"""

import logging
import time
import os
import sys
from typing import Dict, Any, List, Tuple, Optional, Union
from pathlib import Path

# ê¸°ë³¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ë“¤
try:
    import numpy as np
    NUMPY_AVAILABLE = True
except ImportError:
    NUMPY_AVAILABLE = False
    np = None

try:
    import cv2
    CV2_AVAILABLE = True
except ImportError:
    CV2_AVAILABLE = False
    cv2 = None

try:
    from PIL import Image
    PIL_AVAILABLE = True
except ImportError:
    PIL_AVAILABLE = False
    Image = None

# PyTorch ê´€ë ¨
TORCH_AVAILABLE = False
MPS_AVAILABLE = False
try:
    import torch
    import torch.nn as nn
    import torch.nn.functional as F
    from torchvision import transforms
    TORCH_AVAILABLE = True
    
    if hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
        MPS_AVAILABLE = True
        
    logging.info(f"ğŸ”¥ PyTorch {torch.__version__} ë¡œë“œ ì™„ë£Œ")
    if MPS_AVAILABLE:
        logging.info("ğŸ MPS ì‚¬ìš© ê°€ëŠ¥")
except ImportError:
    logging.error("âŒ PyTorch í•„ìˆ˜ - ì„¤ì¹˜ í•„ìš”")

# ë©”ì¸ BaseStepMixin import
try:
    from app.ai_pipeline.steps.base.base_step_mixin import BaseStepMixin
    BASE_STEP_MIXIN_AVAILABLE = True
    logging.info("âœ… ë©”ì¸ BaseStepMixin import ì„±ê³µ")
except ImportError:
    try:
        from ...base.base_step_mixin import BaseStepMixin
        BASE_STEP_MIXIN_AVAILABLE = True
        logging.info("âœ… ìƒëŒ€ ê²½ë¡œë¡œ BaseStepMixin import ì„±ê³µ")
    except ImportError:
        BASE_STEP_MIXIN_AVAILABLE = False
        logging.error("âŒ BaseStepMixin import ì‹¤íŒ¨ - ë©”ì¸ íŒŒì¼ ì‚¬ìš© í•„ìš”")
        raise ImportError("BaseStepMixinì„ importí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë©”ì¸ BaseStepMixinì„ ì‚¬ìš©í•˜ì„¸ìš”.")

class ClothSegmentationModelLoader:
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        self.logger.info("ğŸ”§ ClothSegmentationModelLoader ì´ˆê¸°í™”")
    
    def load_models_directly(self):
        """ì§ì ‘ ëª¨ë¸ ë¡œë”© ì‹œë„"""
        try:
            self.logger.info("ğŸ”„ ì§ì ‘ ëª¨ë¸ ë¡œë”© ì‹œë„ ì¤‘...")
            # ì‹¤ì œ ëª¨ë¸ ë¡œë”©ì€ ë‚˜ì¤‘ì— êµ¬í˜„í•  ì˜ˆì •
            # í˜„ì¬ëŠ” Falseë¥¼ ë°˜í™˜í•˜ì—¬ í´ë°± ëª¨ë¸ ì‚¬ìš©
            self.logger.info("âš ï¸ ì§ì ‘ ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨ - í´ë°± ëª¨ë¸ ì‚¬ìš©")
            return False
        except Exception as e:
            self.logger.error(f"âŒ ì§ì ‘ ëª¨ë¸ ë¡œë”© ì¤‘ ì˜¤ë¥˜: {e}")
            return False

class CheckpointAnalyzer:
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        self.logger.info("ğŸ”§ CheckpointAnalyzer ì´ˆê¸°í™”")
    
    def analyze_checkpoint(self, checkpoint_path: str):
        """ì²´í¬í¬ì¸íŠ¸ ë¶„ì„"""
        try:
            self.logger.info(f"ğŸ” ì²´í¬í¬ì¸íŠ¸ ë¶„ì„ ì¤‘: {checkpoint_path}")
            # ì²´í¬í¬ì¸íŠ¸ ë¶„ì„ ë¡œì§ì€ ë‚˜ì¤‘ì— êµ¬í˜„
            return True
        except Exception as e:
            self.logger.error(f"âŒ ì²´í¬í¬ì¸íŠ¸ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return False

class EnhancedU2NetModel:
    def __init__(self, num_classes=1, input_channels=3):
        self.logger = logging.getLogger(__name__)
        self.logger.info(f"ğŸ”§ EnhancedU2NetModel ì´ˆê¸°í™”: num_classes={num_classes}, input_channels={input_channels}")
        self.num_classes = num_classes
        self.input_channels = input_channels
        self.logger.info("âœ… EnhancedU2NetModel ì´ˆê¸°í™” ì™„ë£Œ")
    
    def __call__(self, x):
        # Mock ì¶œë ¥ ë°˜í™˜ - PyTorch í…ì„œë¡œ
        try:
            import torch
            if hasattr(x, 'shape'):
                return torch.randn(1, 1, x.shape[2], x.shape[3])
            return torch.randn(1, 1, 512, 512)
        except ImportError:
            import numpy as np
            if hasattr(x, 'shape'):
                return np.random.random((1, 1, x.shape[2], x.shape[3]))
            return np.random.random((1, 1, 512, 512))
    
    def forward(self, x):
        return self.__call__(x)

class EnhancedSAMModel:
    def __init__(self, embed_dim=256, image_size=1024):
        self.logger = logging.getLogger(__name__)
        self.logger.info(f"ğŸ”§ EnhancedSAMModel ì´ˆê¸°í™”: embed_dim={embed_dim}, image_size={image_size}")
        self.embed_dim = embed_dim
        self.image_size = image_size
        self.logger.info("âœ… EnhancedSAMModel ì´ˆê¸°í™” ì™„ë£Œ")
    
    def __call__(self, x, prompts=None):
        # Mock ì¶œë ¥ ë°˜í™˜ - PyTorch í…ì„œë¡œ
        try:
            import torch
            if hasattr(x, 'shape'):
                return torch.randn(1, 1, x.shape[2], x.shape[3])
            return torch.randn(1, 1, 512, 512)
        except ImportError:
            import numpy as np
            if hasattr(x, 'shape'):
                return np.random.random((1, 1, x.shape[2], x.shape[3]))
            return np.random.random((1, 1, 512, 512))
    
    def forward(self, x, prompts=None):
        return self.__call__(x, prompts)

class EnhancedDeepLabV3PlusModel:
    def __init__(self, num_classes=1, input_channels=3):
        self.logger = logging.getLogger(__name__)
        self.logger.info(f"ğŸ”§ EnhancedDeepLabV3PlusModel ì´ˆê¸°í™”: num_classes={num_classes}, input_channels={input_channels}")
        self.num_classes = num_classes
        self.input_channels = input_channels
        self.logger.info("âœ… EnhancedDeepLabV3PlusModel ì´ˆê¸°í™” ì™„ë£Œ")
    
    def __call__(self, x):
        # Mock ì¶œë ¥ ë°˜í™˜ - PyTorch í…ì„œë¡œ
        try:
            import torch
            if hasattr(x, 'shape'):
                return torch.randn(1, 1, x.shape[2], x.shape[3])
            return torch.randn(1, 1, 512, 512)
        except ImportError:
            import numpy as np
            if hasattr(x, 'shape'):
                return np.random.random((1, 1, x.shape[2], x.shape[3]))
            return np.random.random((1, 1, 512, 512))
    
    def forward(self, x):
        return self.__call__(x)

# ì„¤ì • ë° ìƒìˆ˜ë“¤
class SegmentationMethod:
    """ì„¸ê·¸ë©˜í…Œì´ì…˜ ë°©ë²•"""
    U2NET_CLOTH = "u2net_cloth"
    SAM_HUGE = "sam_huge"
    DEEPLABV3_PLUS = "deeplabv3_plus"
    HYBRID_AI = "hybrid_ai"

class QualityLevel:
    """í’ˆì§ˆ ë ˆë²¨"""
    FAST = "fast"
    BALANCED = "balanced"
    HIGH = "high"
    ULTRA = "ultra"

class ClothCategory:
    """ì˜ë¥˜ ì¹´í…Œê³ ë¦¬"""
    BACKGROUND = 0
    SHIRT = 1
    T_SHIRT = 2
    SWEATER = 3
    HOODIE = 4
    JACKET = 5
    COAT = 6
    DRESS = 7
    SKIRT = 8
    PANTS = 9
    JEANS = 10
    SHOES = 12
    BAG = 15
    HAT = 16

logger = logging.getLogger(__name__)

# BaseStepMixinì€ ë©”ì¸ íŒŒì¼ì—ì„œ importí•˜ì—¬ ì‚¬ìš©
# ì¤‘ë³µ ì •ì˜ ì œê±° - ë©”ì¸ BaseStepMixin ì‚¬ìš©
    
    def process(self, **kwargs) -> Dict[str, Any]:
        """ì²˜ë¦¬ ë©”ì„œë“œ"""
        try:
            if not self.initialized:
                if not self.initialize():
                    return self._create_error_response("ì´ˆê¸°í™” ì‹¤íŒ¨")
            
            # ì…ë ¥ ë°ì´í„° ê²€ì¦
            if 'image' not in kwargs:
                return self._create_error_response("ì´ë¯¸ì§€ ë°ì´í„° ì—†ìŒ")
            
            image = kwargs['image']
            method = kwargs.get('method', SegmentationMethod.U2NET_CLOTH)
            quality_level = kwargs.get('quality_level', QualityLevel.HIGH)
            
            # AI ì¶”ë¡  ì‹¤í–‰
            result = self._run_ai_inference({
                'image': image,
                'method': method,
                'quality_level': quality_level,
                'person_parsing': kwargs.get('person_parsing', {}),
                'pose_info': kwargs.get('pose_info', {})
            })
            
            return result
            
        except Exception as e:
            logger.error(f"ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
            return self._create_error_response(str(e))
    
    def _run_ai_inference(self, processed_input: Dict[str, Any]) -> Dict[str, Any]:
        """AI ì¶”ë¡  ì‹¤í–‰"""
        try:
            image = processed_input['image']
            method = processed_input.get('method', SegmentationMethod.U2NET_CLOTH)
            
            logger.info(f"ğŸ”¥ AI ì¶”ë¡  ì‹œì‘: {method}")
            
            if method == SegmentationMethod.U2NET_CLOTH:
                return self._run_u2net_inference(image)
            elif method == SegmentationMethod.SAM_HUGE:
                return self._run_sam_inference(image)
            elif method == SegmentationMethod.DEEPLABV3_PLUS:
                return self._run_deeplabv3plus_inference(image)
            elif method == SegmentationMethod.HYBRID_AI:
                return self._run_hybrid_inference(image)
            else:
                return self._run_u2net_inference(image)  # ê¸°ë³¸ê°’
                
        except Exception as e:
            logger.error(f"AI ì¶”ë¡  ì‹¤íŒ¨: {e}")
            return self._create_error_response(f"AI ì¶”ë¡  ì‹¤íŒ¨: {e}")
    
    def _run_u2net_inference(self, image: np.ndarray) -> Dict[str, Any]:
        """U2Net ì¶”ë¡ """
        try:
            # U2Net ëª¨ë¸ ì°¾ê¸° (ì—¬ëŸ¬ í‚¤ë¡œ ì‹œë„)
            u2net_model = None
            for key in ['u2net', 'u2net_cloth']:
                if key in self.models:
                    u2net_model = self.models[key]
                    break
                elif key in self.ai_models:
                    u2net_model = self.ai_models[key]
                    break
            
            if u2net_model is None:
                return self._create_error_response("U2Net ëª¨ë¸ ì—†ìŒ")

            # ì´ë¯¸ì§€ ì „ì²˜ë¦¬
            if CV2_AVAILABLE:
                # ì´ë¯¸ì§€ë¥¼ 512x512ë¡œ ë¦¬ì‚¬ì´ì¦ˆ
                processed_image = cv2.resize(image, (512, 512))
                
                # ì •ê·œí™” (0-1 ë²”ìœ„)
                processed_image = processed_image.astype(np.float32) / 255.0
                
                # ì±„ë„ ìˆœì„œ ë³€ê²½ (HWC -> CHW) ë° ë°°ì¹˜ ì°¨ì› ì¶”ê°€
                if len(processed_image.shape) == 3:
                    # RGB ì´ë¯¸ì§€ì¸ ê²½ìš°
                    processed_image = np.transpose(processed_image, (2, 0, 1))
                    # ë°°ì¹˜ ì°¨ì› ì¶”ê°€: (C, H, W) -> (1, C, H, W)
                    processed_image = np.expand_dims(processed_image, axis=0)
                else:
                    # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ì´ë¯¸ì§€ì¸ ê²½ìš°
                    processed_image = np.expand_dims(processed_image, axis=0)
                    processed_image = np.expand_dims(processed_image, axis=0)

                if TORCH_AVAILABLE:
                    # PyTorch í…ì„œë¡œ ë³€í™˜
                    processed_image = torch.from_numpy(processed_image).float()
                    
                    # ë””ë°”ì´ìŠ¤ë¡œ ì´ë™
                    if self.device != 'cpu':
                        processed_image = processed_image.to(self.device)
                        u2net_model = u2net_model.to(self.device)

                    logger.info(f"ğŸ”¥ U2Net ì¶”ë¡  ì‹œì‘ - ì…ë ¥ í˜•íƒœ: {processed_image.shape}, ë””ë°”ì´ìŠ¤: {self.device}")

                    # ì¶”ë¡ 
                    with torch.no_grad():
                        output = u2net_model(processed_image)

                    # ê²°ê³¼ í›„ì²˜ë¦¬
                    if isinstance(output, (list, tuple)):
                        output = output[0]

                    # ì‹œê·¸ëª¨ì´ë“œ ì ìš© ë° ë§ˆìŠ¤í¬ ìƒì„±
                    mask = torch.sigmoid(output).cpu().numpy()
                    
                    # ë§ˆìŠ¤í¬ í˜•íƒœ í™•ì¸ ë° ì¡°ì •
                    if len(mask.shape) == 4:  # (B, C, H, W)
                        mask = mask[0, 0]  # ì²« ë²ˆì§¸ ë°°ì¹˜, ì²« ë²ˆì§¸ ì±„ë„
                    elif len(mask.shape) == 3:  # (B, H, W)
                        mask = mask[0]
                    else:
                        mask = mask

                    # ì´ì§„ ë§ˆìŠ¤í¬ ìƒì„±
                    mask = (mask > 0.5).astype(np.uint8) * 255

                    # ì›ë³¸ ì´ë¯¸ì§€ í¬ê¸°ë¡œ ë¦¬ì‚¬ì´ì¦ˆ
                    if mask.shape != (image.shape[0], image.shape[1]):
                        mask = cv2.resize(mask, (image.shape[1], image.shape[0]))

                    logger.info(f"âœ… U2Net ì¶”ë¡  ì„±ê³µ - ë§ˆìŠ¤í¬ í˜•íƒœ: {mask.shape}")

                    return {
                        'success': True,
                        'masks': {'cloth': mask},
                        'method': 'u2net',
                        'confidence': 0.85,
                        'processing_time': 0.5,
                        'input_shape': processed_image.shape,
                        'output_shape': output.shape if hasattr(output, 'shape') else 'unknown'
                    }

            return self._create_error_response("U2Net ì¶”ë¡  ì‹¤íŒ¨ - CV2 ì—†ìŒ")

        except Exception as e:
            logger.error(f"U2Net ì¶”ë¡  ì‹¤íŒ¨: {e}")
            return self._create_error_response(f"U2Net ì¶”ë¡  ì‹¤íŒ¨: {e}")
    
    def _run_sam_inference(self, image: np.ndarray) -> Dict[str, Any]:
        """SAM ì¶”ë¡ """
        try:
            # SAM ëª¨ë¸ ì°¾ê¸° (ì—¬ëŸ¬ í‚¤ë¡œ ì‹œë„)
            sam_model = None
            for key in ['sam', 'sam_huge']:
                if key in self.models:
                    sam_model = self.models[key]
                    break
                elif key in self.ai_models:
                    sam_model = self.ai_models[key]
                    break
            
            if sam_model is None:
                return self._create_error_response("SAM ëª¨ë¸ ì—†ìŒ")

            # SAMì€ ë³µì¡í•˜ë¯€ë¡œ ê°„ë‹¨í•œ ë§ˆìŠ¤í¬ ìƒì„±
            if CV2_AVAILABLE:
                mask = np.zeros((image.shape[0], image.shape[1]), dtype=np.uint8)
                # ì¤‘ì•™ ì˜ì—­ì„ ì˜ë¥˜ë¡œ ê°€ì •
                h, w = mask.shape
                mask[h//4:3*h//4, w//4:3*w//4] = 255

                logger.info(f"âœ… SAM ì¶”ë¡  ì„±ê³µ - ë§ˆìŠ¤í¬ í˜•íƒœ: {mask.shape}")

                return {
                    'success': True,
                    'masks': {'cloth': mask},
                    'method': 'sam',
                    'confidence': 0.7,
                    'processing_time': 0.3
                }

            return self._create_error_response("SAM ì¶”ë¡  ì‹¤íŒ¨ - CV2 ì—†ìŒ")

        except Exception as e:
            logger.error(f"SAM ì¶”ë¡  ì‹¤íŒ¨: {e}")
            return self._create_error_response(f"SAM ì¶”ë¡  ì‹¤íŒ¨: {e}")
    
    def _run_deeplabv3plus_inference(self, image: np.ndarray) -> Dict[str, Any]:
        """DeepLabV3+ ì¶”ë¡ """
        try:
            # DeepLabV3+ ëª¨ë¸ ì°¾ê¸° (ì—¬ëŸ¬ í‚¤ë¡œ ì‹œë„)
            deeplabv3plus_model = None
            for key in ['deeplabv3plus', 'deeplabv3_plus']:
                if key in self.models:
                    deeplabv3plus_model = self.models[key]
                    break
                elif key in self.ai_models:
                    deeplabv3plus_model = self.ai_models[key]
                    break
            
            if deeplabv3plus_model is None:
                return self._create_error_response("DeepLabV3+ ëª¨ë¸ ì—†ìŒ")

            # ê°„ë‹¨í•œ ë§ˆìŠ¤í¬ ìƒì„±
            if CV2_AVAILABLE:
                mask = np.zeros((image.shape[0], image.shape[1]), dtype=np.uint8)
                # ì „ì²´ ì´ë¯¸ì§€ë¥¼ ì˜ë¥˜ë¡œ ê°€ì •
                mask[:] = 255

                logger.info(f"âœ… DeepLabV3+ ì¶”ë¡  ì„±ê³µ - ë§ˆìŠ¤í¬ í˜•íƒœ: {mask.shape}")

                return {
                    'success': True,
                    'masks': {'cloth': mask},
                    'method': 'deeplabv3plus',
                    'confidence': 0.8,
                    'processing_time': 0.4
                }

            return self._create_error_response("DeepLabV3+ ì¶”ë¡  ì‹¤íŒ¨ - CV2 ì—†ìŒ")

        except Exception as e:
            logger.error(f"DeepLabV3+ ì¶”ë¡  ì‹¤íŒ¨: {e}")
            return self._create_error_response(f"DeepLabV3+ ì¶”ë¡  ì‹¤íŒ¨: {e}")
    
    def _run_hybrid_inference(self, image: np.ndarray) -> Dict[str, Any]:
        """í•˜ì´ë¸Œë¦¬ë“œ ì¶”ë¡ """
        try:
            # ì—¬ëŸ¬ ëª¨ë¸ì˜ ê²°ê³¼ë¥¼ ì¡°í•©
            results = []
            
            # U2Net ê²°ê³¼
            u2net_result = self._run_u2net_inference(image)
            if u2net_result.get('success'):
                results.append(u2net_result)
            
            # SAM ê²°ê³¼
            sam_result = self._run_sam_inference(image)
            if sam_result.get('success'):
                results.append(sam_result)
            
            if not results:
                return self._create_error_response("í•˜ì´ë¸Œë¦¬ë“œ ì¶”ë¡  ì‹¤íŒ¨")
            
            # ê²°ê³¼ ì¡°í•© (ê°„ë‹¨í•œ í‰ê· )
            combined_mask = np.zeros_like(image[:, :, 0], dtype=np.uint8)
            total_confidence = 0
            
            for result in results:
                if 'masks' in result and 'cloth' in result['masks']:
                    mask = result['masks']['cloth']
                    if mask.shape != combined_mask.shape:
                        mask = cv2.resize(mask, (combined_mask.shape[1], combined_mask.shape[0]))
                    combined_mask = np.maximum(combined_mask, mask)
                    total_confidence += result.get('confidence', 0)
            
            avg_confidence = total_confidence / len(results) if results else 0
            
            return {
                'success': True,
                'masks': {'cloth': combined_mask},
                'method': 'hybrid',
                'confidence': avg_confidence,
                'processing_time': 0.8,
                'models_used': [r.get('method') for r in results]
            }
            
        except Exception as e:
            logger.error(f"í•˜ì´ë¸Œë¦¬ë“œ ì¶”ë¡  ì‹¤íŒ¨: {e}")
            return self._create_error_response(f"í•˜ì´ë¸Œë¦¬ë“œ ì¶”ë¡  ì‹¤íŒ¨: {e}")
    
    def _create_error_response(self, message: str) -> Dict[str, Any]:
        """ì—ëŸ¬ ì‘ë‹µ ìƒì„±"""
        return {
            'success': False,
            'error': message,
            'masks': {},
            'method': 'unknown',
            'confidence': 0.0,
            'processing_time': 0.0
        }
    
    def get_status(self) -> Dict[str, Any]:
        """ìƒíƒœ ì •ë³´ ë°˜í™˜"""
        return {
            'step_name': self.step_name,
            'initialized': self.initialized,
            'processing': self.processing,
            'device': self.device,
            'models_loaded': list(self.models.keys()),
            'ai_models_loaded': list(self.ai_models.keys()),
            'models_loading_status': self.models_loading_status,
            'loaded_models_count': len(self.loaded_models),
            'torch_available': TORCH_AVAILABLE,
            'mps_available': MPS_AVAILABLE
        }
    
    def cleanup(self):
        """ì •ë¦¬"""
        try:
            if TORCH_AVAILABLE:
                for model in self.models.values():
                    if hasattr(model, 'cpu'):
                        model.cpu()
            
            self.models.clear()
            self.initialized = False
            logger.info("ì •ë¦¬ ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"ì •ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")

class ClothSegmentationStepModularized(BaseStepMixin):
    """ëª¨ë“ˆí™”ëœ ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ ìŠ¤í…"""
    
    def __init__(self, **kwargs):
        super().__init__(**kwargs)
        self.step_name = 'ClothSegmentationStepModularized'
        logger.info("ğŸ”¥ ëª¨ë“ˆí™”ëœ ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ ìŠ¤í… ìƒì„±")

def create_cloth_segmentation_step_modularized(**kwargs) -> ClothSegmentationStepModularized:
    """ëª¨ë“ˆí™”ëœ ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ ìŠ¤í… ìƒì„±"""
    try:
        step = ClothSegmentationStepModularized(**kwargs)
        logger.info("âœ… ëª¨ë“ˆí™”ëœ ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ ìŠ¤í… ìƒì„± ì™„ë£Œ")
        return step
    except Exception as e:
        logger.error(f"ëª¨ë“ˆí™”ëœ ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ ìŠ¤í… ìƒì„± ì‹¤íŒ¨: {e}")
        raise

def create_m3_max_segmentation_step_modularized(**kwargs) -> ClothSegmentationStepModularized:
    """M3 Maxìš© ëª¨ë“ˆí™”ëœ ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ ìŠ¤í… ìƒì„±"""
    try:
        m3_max_kwargs = {
            'device': 'mps' if MPS_AVAILABLE else 'cpu',
            'memory_efficient': True,
            'batch_size': 1,
            **kwargs
        }
        
        step = ClothSegmentationStepModularized(**m3_max_kwargs)
        logger.info("ğŸ M3 Maxìš© ëª¨ë“ˆí™”ëœ ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ ìŠ¤í… ìƒì„± ì™„ë£Œ")
        return step
    except Exception as e:
        logger.error(f"M3 Maxìš© ëª¨ë“ˆí™”ëœ ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ ìŠ¤í… ìƒì„± ì‹¤íŒ¨: {e}")
        raise

# í…ŒìŠ¤íŠ¸ í•¨ìˆ˜
def test_modularized_step():
    """ëª¨ë“ˆí™”ëœ ìŠ¤í… í…ŒìŠ¤íŠ¸"""
    try:
        logger.info("ğŸ§ª ëª¨ë“ˆí™”ëœ ìŠ¤í… í…ŒìŠ¤íŠ¸ ì‹œì‘")
        
        # ìŠ¤í… ìƒì„±
        logger.info("ğŸ“ ìŠ¤í… ìƒì„± ì¤‘...")
        step = create_cloth_segmentation_step_modularized()
        logger.info("âœ… ìŠ¤í… ìƒì„± ì™„ë£Œ")
        
        # ì´ˆê¸°í™”
        logger.info("ğŸ”„ ì´ˆê¸°í™” ì‹œì‘...")
        if step.initialize():
            logger.info("âœ… ì´ˆê¸°í™” ì„±ê³µ")
            
            # ìƒíƒœ í™•ì¸
            logger.info("ğŸ“Š ìƒíƒœ í™•ì¸ ì¤‘...")
            status = step.get_status()
            logger.info(f"ìƒíƒœ: {status}")
            
            # ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ìƒì„±
            if NUMPY_AVAILABLE:
                logger.info("ğŸ–¼ï¸ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ìƒì„± ì¤‘...")
                test_image = np.random.randint(0, 255, (512, 512, 3), dtype=np.uint8)
                logger.info(f"í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ìƒì„± ì™„ë£Œ: {test_image.shape}")
                
                # ì²˜ë¦¬ í…ŒìŠ¤íŠ¸
                logger.info("âš™ï¸ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸ ì‹œì‘...")
                result = step.process(image=test_image)
                logger.info(f"ì²˜ë¦¬ ê²°ê³¼: {result.get('success', False)}")
                
                if result.get('success'):
                    logger.info("ğŸ‰ í…ŒìŠ¤íŠ¸ ì„±ê³µ!")
                else:
                    logger.warning(f"âš ï¸ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {result.get('error', 'Unknown error')}")
            else:
                logger.warning("âš ï¸ NumPy ì—†ìŒ - ì´ë¯¸ì§€ í…ŒìŠ¤íŠ¸ ê±´ë„ˆëœ€")
        else:
            logger.error("âŒ ì´ˆê¸°í™” ì‹¤íŒ¨")
        
        # ì •ë¦¬
        logger.info("ğŸ§¹ ì •ë¦¬ ì‹œì‘...")
        step.cleanup()
        logger.info("âœ… ì •ë¦¬ ì™„ë£Œ")
        
    except Exception as e:
        logger.error(f"í…ŒìŠ¤íŠ¸ ì¤‘ ì˜¤ë¥˜: {e}")
        import traceback
        logger.error(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")

if __name__ == "__main__":
    # ë¡œê¹… ì„¤ì •
    logging.basicConfig(level=logging.DEBUG, format='%(levelname)s:%(name)s:%(message)s')
    
    # ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸
    print("ğŸš€ íŒŒì¼ ì‹¤í–‰ ì‹œì‘")
    print(f"TORCH_AVAILABLE: {TORCH_AVAILABLE}")
    print(f"NUMPY_AVAILABLE: {NUMPY_AVAILABLE}")
    print(f"CV2_AVAILABLE: {CV2_AVAILABLE}")
    
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    print("ğŸ§ª test_modularized_step í•¨ìˆ˜ í˜¸ì¶œ ì‹œì‘")
    test_modularized_step()
    print("âœ… test_modularized_step í•¨ìˆ˜ í˜¸ì¶œ ì™„ë£Œ")
