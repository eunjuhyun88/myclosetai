#!/usr/bin/env python3
"""
ðŸ”¥ MyCloset AI - Step 03: ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ - Preprocessing
=====================================================================

ì „ì²˜ë¦¬ ê´€ë ¨ í•¨ìˆ˜ë“¤ì„ ë¶„ë¦¬í•œ ëª¨ë“ˆ

Author: MyCloset AI Team  
Date: 2025-08-01
Version: 1.0
"""

import numpy as np
import cv2
from typing import Dict, Any, List, Tuple, Optional
import logging

logger = logging.getLogger(__name__)

def assess_image_quality(image: np.ndarray) -> Dict[str, float]:
    """
    ì´ë¯¸ì§€ í’ˆì§ˆ í‰ê°€
    
    Args:
        image: ìž…ë ¥ ì´ë¯¸ì§€
        
    Returns:
        í’ˆì§ˆ ì ìˆ˜ë“¤
    """
    try:
        # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜
        if len(image.shape) == 3:
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        else:
            gray = image
        
        # 1. ë°ê¸° í‰ê°€
        brightness = np.mean(gray)
        brightness_score = min(1.0, brightness / 128.0)
        
        # 2. ëŒ€ë¹„ í‰ê°€
        contrast = np.std(gray)
        contrast_score = min(1.0, contrast / 50.0)
        
        # 3. ì„ ëª…ë„ í‰ê°€ (Laplacian variance)
        laplacian = cv2.Laplacian(gray, cv2.CV_64F)
        sharpness = np.var(laplacian)
        sharpness_score = min(1.0, sharpness / 500.0)
        
        # 4. ë…¸ì´ì¦ˆ í‰ê°€
        noise = np.mean(np.abs(cv2.GaussianBlur(gray, (5, 5), 0) - gray))
        noise_score = max(0.0, 1.0 - noise / 10.0)
        
        # 5. ì „ì²´ í’ˆì§ˆ ì ìˆ˜
        overall_quality = (brightness_score + contrast_score + sharpness_score + noise_score) / 4
        
        return {
            'brightness': brightness_score,
            'contrast': contrast_score,
            'sharpness': sharpness_score,
            'noise': noise_score,
            'overall_quality': overall_quality
        }
        
    except Exception as e:
        logger.error(f"ì´ë¯¸ì§€ í’ˆì§ˆ í‰ê°€ ì‹¤íŒ¨: {e}")
        return {
            'brightness': 0.5,
            'contrast': 0.5,
            'sharpness': 0.5,
            'noise': 0.5,
            'overall_quality': 0.5
        }


def normalize_lighting(image: np.ndarray) -> np.ndarray:
    """
    ì¡°ëª… ì •ê·œí™”
    
    Args:
        image: ìž…ë ¥ ì´ë¯¸ì§€
        
    Returns:
        ì •ê·œí™”ëœ ì´ë¯¸ì§€
    """
    try:
        # LAB ìƒ‰ê³µê°„ìœ¼ë¡œ ë³€í™˜
        lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)
        
        # L ì±„ë„ ì¶”ì¶œ
        l_channel = lab[:, :, 0]
        
        # CLAHE ì ìš©
        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
        l_channel_normalized = clahe.apply(l_channel)
        
        # ì •ê·œí™”ëœ L ì±„ë„ë¡œ êµì²´
        lab[:, :, 0] = l_channel_normalized
        
        # BGRë¡œ ë³€í™˜
        normalized_image = cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)
        
        return normalized_image
        
    except Exception as e:
        logger.error(f"ì¡°ëª… ì •ê·œí™” ì‹¤íŒ¨: {e}")
        return image


def correct_colors(image: np.ndarray) -> np.ndarray:
    """
    ìƒ‰ìƒ ë³´ì •
    
    Args:
        image: ìž…ë ¥ ì´ë¯¸ì§€
        
    Returns:
        ë³´ì •ëœ ì´ë¯¸ì§€
    """
    try:
        # ìƒ‰ì˜¨ë„ ë³´ì • (ìžë™ í™”ì´íŠ¸ ë°¸ëŸ°ìŠ¤)
        # 1. ê·¸ë ˆì´ ì›”ë“œ ê°€ì •
        b, g, r = cv2.split(image)
        
        # ê° ì±„ë„ì˜ í‰ê·  ê³„ì‚°
        b_mean = np.mean(b)
        g_mean = np.mean(g)
        r_mean = np.mean(r)
        
        # ê·¸ë ˆì´ ì›”ë“œ ê°€ì •ì— ë”°ë¥¸ ìŠ¤ì¼€ì¼ íŒ©í„°
        gray_mean = (b_mean + g_mean + r_mean) / 3
        b_scale = gray_mean / b_mean if b_mean > 0 else 1.0
        g_scale = gray_mean / g_mean if g_mean > 0 else 1.0
        r_scale = gray_mean / r_mean if r_mean > 0 else 1.0
        
        # ìŠ¤ì¼€ì¼ë§ ì ìš©
        b_corrected = np.clip(b * b_scale, 0, 255).astype(np.uint8)
        g_corrected = np.clip(g * g_scale, 0, 255).astype(np.uint8)
        r_corrected = np.clip(r * r_scale, 0, 255).astype(np.uint8)
        
        # ì±„ë„ í•©ì¹˜ê¸°
        corrected_image = cv2.merge([b_corrected, g_corrected, r_corrected])
        
        return corrected_image
        
    except Exception as e:
        logger.error(f"ìƒ‰ìƒ ë³´ì • ì‹¤íŒ¨: {e}")
        return image


def determine_quality_level(processed_input: Dict[str, Any], quality_scores: Dict[str, float]) -> str:
    """
    í’ˆì§ˆ ë ˆë²¨ ê²°ì •
    
    Args:
        processed_input: ì²˜ë¦¬ëœ ìž…ë ¥
        quality_scores: í’ˆì§ˆ ì ìˆ˜ë“¤
        
    Returns:
        í’ˆì§ˆ ë ˆë²¨
    """
    try:
        overall_quality = quality_scores.get('overall_quality', 0.5)
        
        # í’ˆì§ˆ ë ˆë²¨ ê²°ì •
        if overall_quality >= 0.8:
            return 'ultra'
        elif overall_quality >= 0.6:
            return 'high'
        elif overall_quality >= 0.4:
            return 'balanced'
        else:
            return 'fast'
            
    except Exception as e:
        logger.error(f"í’ˆì§ˆ ë ˆë²¨ ê²°ì • ì‹¤íŒ¨: {e}")
        return 'balanced'
