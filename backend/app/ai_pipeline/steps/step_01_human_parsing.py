# backend/app/ai_pipeline/steps/step_01_human_parsing.py
"""
1ë‹¨ê³„: ì¸ì²´ íŒŒì‹± (Human Parsing) - M3 Max ìµœì í™” ë²„ì „
- Graphonomy ëª¨ë¸ ê¸°ë°˜ 20ê°œ ë¶€ìœ„ ë¶„í• 
- M3 Max Neural Engine í™œìš© ìµœì í™”
- ë©”ëª¨ë¦¬ íš¨ìœ¨ì  ì²˜ë¦¬ ë° ì‹¤ì‹œê°„ ìºì‹±
- ê¸°ì¡´ AI íŒŒì´í”„ë¼ì¸ êµ¬ì¡°ì™€ ì™„ë²½ í˜¸í™˜
"""

import os
import logging
import time
import asyncio
from typing import Dict, Any, Optional, Tuple, List
import numpy as np
import torch
import torch.nn.functional as F
from PIL import Image
import cv2
from concurrent.futures import ThreadPoolExecutor

# ê¸°ì¡´ ìœ í‹¸ë¦¬í‹° import
from ..utils.model_loader import ModelLoader
from ..utils.memory_manager import MemoryManager
from ..utils.data_converter import DataConverter

# Apple Metal Performance Shaders ì§€ì›
try:
    import torch.backends.mps
    MPS_AVAILABLE = torch.backends.mps.is_available()
except ImportError:
    MPS_AVAILABLE = False

# CoreML ì§€ì› (ì„ íƒì‚¬í•­)
try:
    import coremltools as ct
    COREML_AVAILABLE = True
except ImportError:
    COREML_AVAILABLE = False

logger = logging.getLogger(__name__)

class HumanParsingStep:
    """1ë‹¨ê³„: ì¸ì²´ íŒŒì‹± - M3 Max ìµœì í™”"""
    
    # LIP (Look Into Person) ë°ì´í„°ì…‹ ê¸°ë°˜ 20ê°œ ë¶€ìœ„ ë¼ë²¨
    BODY_PARTS = {
        0: "Background",
        1: "Hat", 2: "Hair", 3: "Glove", 4: "Sunglasses",
        5: "Upper-clothes", 6: "Dress", 7: "Coat", 8: "Socks",
        9: "Pants", 10: "Jumpsuits", 11: "Scarf", 12: "Skirt",
        13: "Face", 14: "Left-arm", 15: "Right-arm",
        16: "Left-leg", 17: "Right-leg", 18: "Left-shoe", 19: "Right-shoe"
    }
    
    # ì˜ë¥˜ ì¹´í…Œê³ ë¦¬ ë§¤í•‘ (ë‹¤ìŒ ë‹¨ê³„ë“¤ì„ ìœ„í•œ)
    CLOTHING_CATEGORIES = {
        "upper": [5, 7],      # Upper-clothes, Coat
        "lower": [9, 12],     # Pants, Skirt
        "dress": [6],         # Dress
        "full_body": [10],    # Jumpsuits
        "accessories": [1, 3, 4, 8, 11, 18, 19]  # Hat, Glove, etc.
    }
    
    def __init__(self, model_loader: ModelLoader, device: str, config: Dict[str, Any] = None):
        """
        Args:
            model_loader: ëª¨ë¸ ë¡œë” ì¸ìŠ¤í„´ìŠ¤ (ê¸°ì¡´ íŒŒì´í”„ë¼ì¸ í˜¸í™˜)
            device: ì‚¬ìš©í•  ë””ë°”ì´ìŠ¤ ('cpu', 'cuda', 'mps')
            config: ì„¤ì • ë”•ì…”ë„ˆë¦¬
        """
        self.model_loader = model_loader
        self.memory_manager = MemoryManager(device)
        self.data_converter = DataConverter()
        
        # M3 Max ìµœì í™” ì„¤ì •
        self.device = self._get_optimal_device(device)
        self.use_coreml = config.get('use_coreml', True) and COREML_AVAILABLE
        self.enable_quantization = config.get('enable_quantization', True)
        
        # ëª¨ë¸ ì„¤ì •
        self.input_size = config.get('input_size', (512, 512))
        self.num_classes = config.get('num_classes', 20)
        self.model_name = config.get('model_name', 'graphonomy')
        self.model_path = config.get('model_path', 'ai_models/checkpoints/human_parsing')
        
        # ì „ì²˜ë¦¬ íŒŒë¼ë¯¸í„° (ImageNet í‘œì¤€)
        self.mean = np.array([0.485, 0.456, 0.406])
        self.std = np.array([0.229, 0.224, 0.225])
        
        # ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤
        self.pytorch_model = None
        self.coreml_model = None
        self.is_initialized = False
        
        # ì„±ëŠ¥ ìµœì í™”
        self.batch_size = config.get('batch_size', 1)
        self.cache_size = config.get('cache_size', 50)
        self.result_cache = {}
        
        # ë³‘ë ¬ ì²˜ë¦¬
        self.executor = ThreadPoolExecutor(max_workers=4)
        
        # ì„±ëŠ¥ í†µê³„
        self.stats = {
            "total_inferences": 0,
            "average_time": 0.0,
            "cache_hits": 0,
            "model_switches": 0
        }
        
        logger.info(f"ğŸ¯ 1ë‹¨ê³„ ì¸ì²´ íŒŒì‹± ì´ˆê¸°í™” - ë””ë°”ì´ìŠ¤: {self.device}")
    
    def _get_optimal_device(self, preferred_device: str) -> str:
        """M3 Maxì— ìµœì í™”ëœ ë””ë°”ì´ìŠ¤ ì„ íƒ"""
        if preferred_device == "mps" and MPS_AVAILABLE:
            logger.info("ğŸš€ Apple Metal Performance Shaders í™œì„±í™”")
            return "mps"
        elif preferred_device == "cuda" and torch.cuda.is_available():
            return "cuda"
        else:
            return "cpu"
    
    async def initialize(self) -> bool:
        """ëª¨ë¸ ì´ˆê¸°í™” (ë¹„ë™ê¸°)"""
        try:
            logger.info("ğŸ”„ 1ë‹¨ê³„: ì¸ì²´ íŒŒì‹± ëª¨ë¸ ë¡œë“œ ì¤‘...")
            
            # CoreML ëª¨ë¸ ìš°ì„  ë¡œë“œ
            if self.use_coreml:
                coreml_loaded = await self._load_coreml_model()
                if coreml_loaded:
                    logger.info("âœ… CoreML ëª¨ë¸ ë¡œë“œ ì„±ê³µ (Neural Engine ê°€ì†)")
            
            # PyTorch ëª¨ë¸ ë¡œë“œ (ë°±ì—… ë˜ëŠ” ë³‘í–‰)
            pytorch_loaded = await self._load_pytorch_model()
            
            if not (self.coreml_model or self.pytorch_model):
                raise RuntimeError("ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")
            
            # ëª¨ë¸ ì›Œë°ì—…
            await self._warmup_models()
            
            self.is_initialized = True
            logger.info("âœ… 1ë‹¨ê³„ ì¸ì²´ íŒŒì‹± ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ 1ë‹¨ê³„ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            self.is_initialized = False
            return False
    
    async def _load_coreml_model(self) -> bool:
        """CoreML ëª¨ë¸ ë¡œë“œ (Neural Engine í™œìš©)"""
        coreml_path = os.path.join(self.model_path, "human_parser_optimized.mlpackage")
        
        if not COREML_AVAILABLE:
            logger.warning("âš ï¸ CoreML ì§€ì› ì•ˆë¨")
            return False
        
        if os.path.exists(coreml_path):
            try:
                def _load_coreml():
                    return ct.models.MLModel(coreml_path)
                
                loop = asyncio.get_event_loop()
                self.coreml_model = await loop.run_in_executor(self.executor, _load_coreml)
                return True
                
            except Exception as e:
                logger.warning(f"âš ï¸ CoreML ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        else:
            logger.info("ğŸ“¦ CoreML ëª¨ë¸ ì—†ìŒ - PyTorch ìš°ì„  ì‚¬ìš©")
        
        return False
    
    async def _load_pytorch_model(self) -> bool:
        """PyTorch ëª¨ë¸ ë¡œë“œ"""
        try:
            # ëª¨ë¸ ë¡œë”ë¥¼ í†µí•œ ë¡œë“œ (ê¸°ì¡´ íŒŒì´í”„ë¼ì¸ í˜¸í™˜)
            model_config = {
                "model_type": "human_parsing",
                "model_name": self.model_name,
                "num_classes": self.num_classes,
                "input_size": self.input_size
            }
            
            # ì‹¤ì œ Graphonomy ëª¨ë¸ì´ ìˆë‹¤ë©´ ë¡œë“œ, ì—†ë‹¤ë©´ ë°ëª¨ ëª¨ë¸ ìƒì„±
            try:
                self.pytorch_model = await self.model_loader.load_model(
                    "human_parsing", 
                    self.model_path
                )
            except FileNotFoundError:
                logger.warning("âš ï¸ Graphonomy ëª¨ë¸ ì—†ìŒ - ë°ëª¨ ëª¨ë¸ ìƒì„±")
                self.pytorch_model = self._create_demo_model()
            
            # ë””ë°”ì´ìŠ¤ë¡œ ì´ë™
            self.pytorch_model = self.pytorch_model.to(self.device)
            
            # M3 Max ìµœì í™”
            if self.device == "mps":
                # MPS ìµœì í™”
                self.pytorch_model = self._optimize_for_mps(self.pytorch_model)
            elif self.enable_quantization and self.device == "cpu":
                # CPU ì–‘ìí™”
                self.pytorch_model = self._quantize_model(self.pytorch_model)
            
            self.pytorch_model.eval()
            return True
            
        except Exception as e:
            logger.error(f"âŒ PyTorch ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return False
    
    def _create_demo_model(self):
        """ë°ëª¨ìš© ê²½ëŸ‰ ì¸ì²´ íŒŒì‹± ëª¨ë¸"""
        
        class EfficientHumanParser(torch.nn.Module):
            """MobileNet ê¸°ë°˜ ê²½ëŸ‰ ì¸ì²´ íŒŒì‹± ëª¨ë¸"""
            
            def __init__(self, num_classes=20):
                super().__init__()
                
                # Efficient backbone (MobileNetV3 ìŠ¤íƒ€ì¼)
                self.backbone = torch.nn.Sequential(
                    # Initial conv
                    torch.nn.Conv2d(3, 32, 3, stride=2, padding=1, bias=False),
                    torch.nn.BatchNorm2d(32),
                    torch.nn.ReLU(inplace=True),
                    
                    # Inverted residual blocks
                    self._make_inverted_block(32, 64, 3, 2, 1),
                    self._make_inverted_block(64, 64, 3, 1, 2),
                    self._make_inverted_block(64, 128, 5, 2, 2),
                    self._make_inverted_block(128, 128, 5, 1, 3),
                    self._make_inverted_block(128, 256, 3, 2, 3),
                    self._make_inverted_block(256, 256, 3, 1, 2),
                )
                
                # Feature Pyramid Network (FPN) ìŠ¤íƒ€ì¼ ë””ì½”ë”
                self.decoder = torch.nn.ModuleList([
                    torch.nn.ConvTranspose2d(256, 128, 4, stride=2, padding=1),
                    torch.nn.ConvTranspose2d(128, 64, 4, stride=2, padding=1),
                    torch.nn.ConvTranspose2d(64, 32, 4, stride=2, padding=1),
                    torch.nn.ConvTranspose2d(32, num_classes, 4, stride=2, padding=1)
                ])
                
                # í™œì„±í™” í•¨ìˆ˜
                self.relu = torch.nn.ReLU(inplace=True)
                
            def _make_inverted_block(self, in_ch, out_ch, kernel_size, stride, repeat):
                layers = []
                for i in range(repeat):
                    s = stride if i == 0 else 1
                    layers.extend([
                        torch.nn.Conv2d(in_ch, out_ch, kernel_size, s, kernel_size//2, bias=False),
                        torch.nn.BatchNorm2d(out_ch),
                        torch.nn.ReLU(inplace=True)
                    ])
                    in_ch = out_ch
                return torch.nn.Sequential(*layers)
            
            def forward(self, x):
                # Encoder
                features = self.backbone(x)
                
                # Decoder
                out = features
                for decoder_layer in self.decoder:
                    out = self.relu(decoder_layer(out))
                
                # ìµœì¢… í¬ê¸° ë§ì¶¤
                out = F.interpolate(out, size=x.shape[2:], mode='bilinear', align_corners=False)
                
                return out
        
        return EfficientHumanParser(self.num_classes)
    
    def _optimize_for_mps(self, model):
        """M3 Max MPS ìµœì í™”"""
        # MPSì— ìµœì í™”ëœ ì„¤ì • ì ìš©
        if hasattr(model, 'eval'):
            model.eval()
        
        # Mixed precisionì„ ìœ„í•œ ì¤€ë¹„ (M3 MaxëŠ” FP16 ì§€ì›)
        for param in model.parameters():
            param.requires_grad_(False)
        
        return model
    
    def _quantize_model(self, model):
        """ëª¨ë¸ ì–‘ìí™” (ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±)"""
        try:
            quantized_model = torch.quantization.quantize_dynamic(
                model, 
                {torch.nn.Linear, torch.nn.Conv2d}, 
                dtype=torch.qint8
            )
            logger.info("âœ… ëª¨ë¸ ì–‘ìí™” ì™„ë£Œ")
            return quantized_model
        except Exception as e:
            logger.warning(f"âš ï¸ ì–‘ìí™” ì‹¤íŒ¨: {e}")
            return model
    
    async def _warmup_models(self):
        """ëª¨ë¸ ì›Œë°ì—… (ì²« ì¶”ë¡  ìµœì í™”)"""
        logger.info("ğŸ”¥ 1ë‹¨ê³„ ëª¨ë¸ ì›Œë°ì—… ì¤‘...")
        
        try:
            # ë”ë¯¸ ì…ë ¥ ìƒì„±
            dummy_input = torch.randn(1, 3, *self.input_size)
            
            # PyTorch ëª¨ë¸ ì›Œë°ì—…
            if self.pytorch_model:
                dummy_input = dummy_input.to(self.device)
                with torch.no_grad():
                    _ = self.pytorch_model(dummy_input)
            
            # CoreML ëª¨ë¸ ì›Œë°ì—…
            if self.coreml_model:
                dummy_np = dummy_input.cpu().numpy()
                _ = self.coreml_model.predict({"input": dummy_np})
            
            logger.info("âœ… 1ë‹¨ê³„ ì›Œë°ì—… ì™„ë£Œ")
            
        except Exception as e:
            logger.warning(f"âš ï¸ ì›Œë°ì—… ì¤‘ ì˜¤ë¥˜: {e}")
    
    async def process(self, person_image_tensor: torch.Tensor) -> Dict[str, Any]:
        """
        1ë‹¨ê³„: ì¸ì²´ íŒŒì‹± ì²˜ë¦¬ (ë¹„ë™ê¸°)
        
        Args:
            person_image_tensor: ì…ë ¥ ì´ë¯¸ì§€ í…ì„œ [1, 3, H, W]
            
        Returns:
            Dict[str, Any]: {
                "parsing_map": np.ndarray,           # íŒŒì‹± ë§µ (H, W)
                "body_masks": Dict[str, np.ndarray], # ë¶€ìœ„ë³„ ë§ˆìŠ¤í¬
                "clothing_regions": Dict[str, Any],  # ì˜ë¥˜ ì˜ì—­ ì •ë³´
                "confidence": float,                 # ì „ì²´ ì‹ ë¢°ë„
                "processing_time": float,            # ì²˜ë¦¬ ì‹œê°„
                "step_info": Dict[str, Any]         # ë‹¨ê³„ ì •ë³´
            }
        """
        if not self.is_initialized:
            raise RuntimeError("1ë‹¨ê³„ ëª¨ë¸ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        start_time = time.time()
        
        try:
            # ìºì‹œ í™•ì¸
            cache_key = self._get_cache_key(person_image_tensor)
            if cache_key in self.result_cache:
                self.stats["cache_hits"] += 1
                logger.info("ğŸ’¾ 1ë‹¨ê³„: ìºì‹œì—ì„œ ê²°ê³¼ ë°˜í™˜")
                cached_result = self.result_cache[cache_key].copy()
                cached_result["from_cache"] = True
                return cached_result
            
            # ì…ë ¥ ì „ì²˜ë¦¬
            preprocessed_tensor = await self._preprocess_input(person_image_tensor)
            
            # ëª¨ë¸ ì¶”ë¡ 
            parsing_output = await self._run_inference(preprocessed_tensor)
            
            # í›„ì²˜ë¦¬ ë° ê²°ê³¼ ìƒì„±
            result = await self._postprocess_result(
                parsing_output, 
                person_image_tensor.shape[2:],
                start_time
            )
            
            # ìºì‹œ ì €ì¥
            self._update_cache(cache_key, result)
            
            # í†µê³„ ì—…ë°ì´íŠ¸
            self._update_stats(time.time() - start_time)
            
            logger.info(f"âœ… 1ë‹¨ê³„ ì™„ë£Œ - {result['processing_time']:.3f}ì´ˆ")
            
            return result
            
        except Exception as e:
            logger.error(f"âŒ 1ë‹¨ê³„ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            raise
    
    async def _preprocess_input(self, image_tensor: torch.Tensor) -> torch.Tensor:
        """ì…ë ¥ ì „ì²˜ë¦¬"""
        def _preprocess():
            # í¬ê¸° ì¡°ì •
            if image_tensor.shape[2:] != self.input_size:
                resized = F.interpolate(
                    image_tensor, 
                    size=self.input_size, 
                    mode='bilinear', 
                    align_corners=False
                )
            else:
                resized = image_tensor
            
            # ì •ê·œí™” (0-1 ë²”ìœ„ ê°€ì •)
            if resized.max() > 1.0:
                resized = resized / 255.0
            
            # ImageNet ì •ê·œí™”
            mean = torch.tensor(self.mean).view(1, 3, 1, 1)
            std = torch.tensor(self.std).view(1, 3, 1, 1)
            
            if self.device != "cpu":
                mean = mean.to(self.device)
                std = std.to(self.device)
            
            normalized = (resized - mean) / std
            
            return normalized.to(self.device)
        
        loop = asyncio.get_event_loop()
        return await loop.run_in_executor(self.executor, _preprocess)
    
    async def _run_inference(self, input_tensor: torch.Tensor) -> torch.Tensor:
        """ëª¨ë¸ ì¶”ë¡  ì‹¤í–‰"""
        # CoreML ëª¨ë¸ ìš°ì„  ì‚¬ìš© (Neural Engine ê°€ì†)
        if self.coreml_model:
            try:
                def _coreml_inference():
                    input_np = input_tensor.cpu().numpy()
                    result = self.coreml_model.predict({"input": input_np})
                    # CoreML ì¶œë ¥ í‚¤ëŠ” ëª¨ë¸ì— ë”°ë¼ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ
                    output_key = list(result.keys())[0]
                    return torch.from_numpy(result[output_key]).to(self.device)
                
                loop = asyncio.get_event_loop()
                output = await loop.run_in_executor(self.executor, _coreml_inference)
                logger.debug("ğŸš€ CoreML ì¶”ë¡  ì™„ë£Œ")
                return output
                
            except Exception as e:
                logger.warning(f"âš ï¸ CoreML ì¶”ë¡  ì‹¤íŒ¨, PyTorchë¡œ ì „í™˜: {e}")
                self.stats["model_switches"] += 1
        
        # PyTorch ëª¨ë¸ ì‚¬ìš©
        if self.pytorch_model:
            with torch.no_grad():
                output = self.pytorch_model(input_tensor)
                logger.debug("ğŸ”¥ PyTorch ì¶”ë¡  ì™„ë£Œ")
                return output
        
        raise RuntimeError("ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")
    
    async def _postprocess_result(self, output: torch.Tensor, original_size: Tuple[int, int], 
                                 start_time: float) -> Dict[str, Any]:
        """ê²°ê³¼ í›„ì²˜ë¦¬"""
        def _postprocess():
            # í™•ë¥ ì„ í´ë˜ìŠ¤ ì¸ë±ìŠ¤ë¡œ ë³€í™˜
            parsing_map = torch.argmax(output, dim=1).squeeze().cpu().numpy()
            
            # ì›ë³¸ í¬ê¸°ë¡œ ë³µì›
            if parsing_map.shape != original_size:
                parsing_map = cv2.resize(
                    parsing_map.astype(np.uint8),
                    (original_size[1], original_size[0]),
                    interpolation=cv2.INTER_NEAREST
                )
            
            # ë…¸ì´ì¦ˆ ì œê±° (ëª¨í´ë¡œì§€ ì—°ì‚°)
            kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))
            parsing_map = cv2.morphologyEx(parsing_map, cv2.MORPH_CLOSE, kernel)
            parsing_map = cv2.morphologyEx(parsing_map, cv2.MORPH_OPEN, kernel)
            
            return parsing_map
        
        loop = asyncio.get_event_loop()
        parsing_map = await loop.run_in_executor(self.executor, _postprocess)
        
        # ë¶€ìœ„ë³„ ë§ˆìŠ¤í¬ ìƒì„±
        body_masks = self._create_body_masks(parsing_map)
        
        # ì˜ë¥˜ ì˜ì—­ ë¶„ì„
        clothing_regions = self._analyze_clothing_regions(parsing_map)
        
        # ì‹ ë¢°ë„ ê³„ì‚°
        confidence = self._calculate_confidence(output)
        
        processing_time = time.time() - start_time
        
        return {
            "parsing_map": parsing_map.astype(np.uint8),
            "body_masks": body_masks,
            "clothing_regions": clothing_regions,
            "confidence": float(confidence),
            "body_parts_detected": self._get_detected_parts(parsing_map),
            "processing_time": processing_time,
            "step_info": {
                "step_name": "human_parsing",
                "step_number": 1,
                "model_used": "CoreML" if self.coreml_model else "PyTorch",
                "device": self.device,
                "input_size": self.input_size,
                "num_classes": self.num_classes
            },
            "from_cache": False
        }
    
    def _create_body_masks(self, parsing_map: np.ndarray) -> Dict[str, np.ndarray]:
        """ì‹ ì²´ ë¶€ìœ„ë³„ ë§ˆìŠ¤í¬ ìƒì„±"""
        body_masks = {}
        
        for part_id, part_name in self.BODY_PARTS.items():
            if part_id == 0:  # ë°°ê²½ ì œì™¸
                continue
            
            mask = (parsing_map == part_id).astype(np.uint8)
            if mask.sum() > 0:
                # í‚¤ ì´ë¦„ ì •ê·œí™”
                key_name = part_name.lower().replace('-', '_').replace(' ', '_')
                body_masks[key_name] = mask
        
        return body_masks
    
    def _analyze_clothing_regions(self, parsing_map: np.ndarray) -> Dict[str, Any]:
        """ì˜ë¥˜ ì˜ì—­ ë¶„ì„ (ë‹¤ìŒ ë‹¨ê³„ë“¤ì„ ìœ„í•œ)"""
        analysis = {
            "categories_detected": [],
            "coverage_ratio": {},
            "bounding_boxes": {},
            "dominant_category": None
        }
        
        total_pixels = parsing_map.size
        max_coverage = 0.0
        
        for category, part_ids in self.CLOTHING_CATEGORIES.items():
            category_mask = np.zeros_like(parsing_map, dtype=bool)
            
            for part_id in part_ids:
                category_mask |= (parsing_map == part_id)
            
            if category_mask.sum() > 0:
                coverage = category_mask.sum() / total_pixels
                
                analysis["categories_detected"].append(category)
                analysis["coverage_ratio"][category] = coverage
                analysis["bounding_boxes"][category] = self._get_bounding_box(category_mask)
                
                if coverage > max_coverage:
                    max_coverage = coverage
                    analysis["dominant_category"] = category
        
        return analysis
    
    def _calculate_confidence(self, output: torch.Tensor) -> float:
        """ì „ì²´ ì‹ ë¢°ë„ ê³„ì‚°"""
        max_probs = torch.max(F.softmax(output, dim=1), dim=1)[0]
        confidence = torch.mean(max_probs).item()
        return confidence
    
    def _get_detected_parts(self, parsing_map: np.ndarray) -> Dict[str, Any]:
        """ê°ì§€ëœ ì‹ ì²´ ë¶€ìœ„ ì •ë³´"""
        detected_parts = {}
        
        for part_id, part_name in self.BODY_PARTS.items():
            if part_id == 0:
                continue
            
            mask = (parsing_map == part_id)
            pixel_count = mask.sum()
            
            if pixel_count > 0:
                key_name = part_name.lower().replace('-', '_').replace(' ', '_')
                detected_parts[key_name] = {
                    "pixel_count": int(pixel_count),
                    "percentage": float(pixel_count / parsing_map.size * 100),
                    "bounding_box": self._get_bounding_box(mask),
                    "part_id": part_id
                }
        
        return detected_parts
    
    def _get_bounding_box(self, mask: np.ndarray) -> Dict[str, int]:
        """ë°”ìš´ë”© ë°•ìŠ¤ ê³„ì‚°"""
        coords = np.where(mask)
        if len(coords[0]) == 0:
            return {"x": 0, "y": 0, "width": 0, "height": 0}
        
        y_min, y_max = coords[0].min(), coords[0].max()
        x_min, x_max = coords[1].min(), coords[1].max()
        
        return {
            "x": int(x_min),
            "y": int(y_min),
            "width": int(x_max - x_min),
            "height": int(y_max - y_min)
        }
    
    def _get_cache_key(self, tensor: torch.Tensor) -> str:
        """ìºì‹œ í‚¤ ìƒì„±"""
        tensor_hash = hash(tensor.cpu().numpy().tobytes())
        return f"step01_{tensor_hash}_{self.input_size[0]}x{self.input_size[1]}"
    
    def _update_cache(self, key: str, result: Dict[str, Any]):
        """ê²°ê³¼ ìºì‹± (LRU ë°©ì‹)"""
        if len(self.result_cache) >= self.cache_size:
            # ê°€ì¥ ì˜¤ë˜ëœ í•­ëª© ì œê±°
            oldest_key = next(iter(self.result_cache))
            del self.result_cache[oldest_key]
        
        # ìºì‹œì— ì €ì¥í•  ë•ŒëŠ” ë¬´ê±°ìš´ ë°ì´í„°ëŠ” ë³µì‚¬ë³¸ ìƒì„±
        cached_result = {
            k: v.copy() if isinstance(v, (np.ndarray, dict)) else v 
            for k, v in result.items()
        }
        self.result_cache[key] = cached_result
    
    def _update_stats(self, processing_time: float):
        """ì„±ëŠ¥ í†µê³„ ì—…ë°ì´íŠ¸"""
        self.stats["total_inferences"] += 1
        current_avg = self.stats["average_time"]
        new_avg = (current_avg * (self.stats["total_inferences"] - 1) + 
                  processing_time) / self.stats["total_inferences"]
        self.stats["average_time"] = new_avg
    
    def get_clothing_mask(self, parsing_map: np.ndarray, category: str) -> np.ndarray:
        """íŠ¹ì • ì˜ë¥˜ ì¹´í…Œê³ ë¦¬ì˜ í†µí•© ë§ˆìŠ¤í¬ ë°˜í™˜ (ë‹¤ìŒ ë‹¨ê³„ë“¤ì„ ìœ„í•œ)"""
        if category not in self.CLOTHING_CATEGORIES:
            raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì¹´í…Œê³ ë¦¬: {category}")
        
        combined_mask = np.zeros_like(parsing_map, dtype=np.uint8)
        
        for part_id in self.CLOTHING_CATEGORIES[category]:
            combined_mask |= (parsing_map == part_id).astype(np.uint8)
        
        return combined_mask
    
    def visualize_parsing(self, parsing_map: np.ndarray) -> np.ndarray:
        """íŒŒì‹± ê²°ê³¼ ì‹œê°í™” (ë””ë²„ê¹…ìš©)"""
        # 20ê°œ ë¶€ìœ„ë³„ ìƒ‰ìƒ ë§¤í•‘
        colors = np.array([
            [0, 0, 0],       # 0: Background
            [128, 0, 0],     # 1: Hat
            [255, 0, 0],     # 2: Hair
            [0, 85, 0],      # 3: Glove
            [170, 0, 51],    # 4: Sunglasses
            [255, 85, 0],    # 5: Upper-clothes
            [0, 0, 85],      # 6: Dress
            [0, 119, 221],   # 7: Coat
            [85, 85, 0],     # 8: Socks
            [0, 85, 85],     # 9: Pants
            [85, 51, 0],     # 10: Jumpsuits
            [52, 86, 128],   # 11: Scarf
            [0, 128, 0],     # 12: Skirt
            [0, 0, 255],     # 13: Face
            [51, 170, 221],  # 14: Left-arm
            [0, 255, 255],   # 15: Right-arm
            [85, 255, 170],  # 16: Left-leg
            [170, 255, 85],  # 17: Right-leg
            [255, 255, 0],   # 18: Left-shoe
            [255, 170, 0]    # 19: Right-shoe
        ])
        
        colored_parsing = colors[parsing_map]
        return colored_parsing.astype(np.uint8)
    
    async def get_step_stats(self) -> Dict[str, Any]:
        """1ë‹¨ê³„ ì„±ëŠ¥ í†µê³„ ë°˜í™˜"""
        return {
            "step_name": "human_parsing",
            "step_number": 1,
            "performance": self.stats,
            "cache_size": len(self.result_cache),
            "device": self.device,
            "models_available": {
                "pytorch": self.pytorch_model is not None,
                "coreml": self.coreml_model is not None
            },
            "memory_usage": await self.memory_manager.get_usage_stats(),
            "configuration": {
                "input_size": self.input_size,
                "num_classes": self.num_classes,
                "cache_limit": self.cache_size,
                "use_quantization": self.enable_quantization
            }
        }
    
    async def cleanup(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        logger.info("ğŸ§¹ 1ë‹¨ê³„: ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì¤‘...")
        
        # ëª¨ë¸ ì •ë¦¬
        if self.pytorch_model:
            del self.pytorch_model
            self.pytorch_model = None
        
        if self.coreml_model:
            del self.coreml_model
            self.coreml_model = None
        
        # ìºì‹œ ì •ë¦¬
        self.result_cache.clear()
        
        # ìŠ¤ë ˆë“œ í’€ ì •ë¦¬
        self.executor.shutdown(wait=True)
        
        # ë©”ëª¨ë¦¬ ì •ë¦¬
        await self.memory_manager.cleanup()
        
        if self.device == "mps":
            torch.mps.empty_cache()
        elif self.device == "cuda":
            torch.cuda.empty_cache()
        
        self.is_initialized = False
        logger.info("âœ… 1ë‹¨ê³„ ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì™„ë£Œ")


# íŒ©í† ë¦¬ í•¨ìˆ˜ (ê¸°ì¡´ íŒŒì´í”„ë¼ì¸ í˜¸í™˜)
async def create_human_parsing_step(
    model_loader: ModelLoader, 
    device: str = "auto",
    config: Dict[str, Any] = None
) -> HumanParsingStep:
    """1ë‹¨ê³„ ì¸ì²´ íŒŒì‹± ìŠ¤í… ìƒì„±"""
    
    if device == "auto":
        # M3 Max ìë™ ê°ì§€
        if MPS_AVAILABLE:
            device = "mps"
        elif torch.cuda.is_available():
            device = "cuda"
        else:
            device = "cpu"
    
    default_config = {
        "use_coreml": True,
        "enable_quantization": True,
        "input_size": (512, 512),
        "num_classes": 20,
        "cache_size": 50,
        "batch_size": 1,
        "model_name": "graphonomy",
        "model_path": "ai_models/checkpoints/human_parsing"
    }
    
    final_config = {**default_config, **(config or {})}
    
    step = HumanParsingStep(model_loader, device, final_config)
    
    if not await step.initialize():
        raise RuntimeError("1ë‹¨ê³„ ì¸ì²´ íŒŒì‹± ì´ˆê¸°í™” ì‹¤íŒ¨")
    
    return step


# í…ŒìŠ¤íŠ¸ ì½”ë“œ
if __name__ == "__main__":
    import asyncio
    from ..utils.model_loader import ModelLoader
    
    async def test_human_parsing():
        """1ë‹¨ê³„ í…ŒìŠ¤íŠ¸"""
        logger.info("ğŸ§ª 1ë‹¨ê³„ ì¸ì²´ íŒŒì‹± í…ŒìŠ¤íŠ¸ ì‹œì‘")
        
        # ëª¨ë¸ ë¡œë” ì´ˆê¸°í™”
        model_loader = ModelLoader()
        
        # 1ë‹¨ê³„ ìƒì„±
        step1 = await create_human_parsing_step(model_loader)
        
        # í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ìƒì„±
        test_image = torch.randn(1, 3, 512, 512)
        
        # ì²˜ë¦¬
        result = await step1.process(test_image)
        
        # ê²°ê³¼ í™•ì¸
        print(f"âœ… ì²˜ë¦¬ ì™„ë£Œ - ì†Œìš”ì‹œê°„: {result['processing_time']:.3f}ì´ˆ")
        print(f"ğŸ¯ ì‹ ë¢°ë„: {result['confidence']:.3f}")
        print(f"ğŸ‘¤ ê°ì§€ëœ ë¶€ìœ„: {len(result['body_parts_detected'])}ê°œ")
        print(f"ğŸ‘• ì˜ë¥˜ ì¹´í…Œê³ ë¦¬: {result['clothing_regions']['categories_detected']}")
        
        # í†µê³„ í™•ì¸
        stats = await step1.get_step_stats()
        print(f"ğŸ“Š ì„±ëŠ¥ í†µê³„: {stats['performance']}")
        
        # ì •ë¦¬
        await step1.cleanup()
        
        logger.info("âœ… 1ë‹¨ê³„ í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
    
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    asyncio.run(test_human_parsing())