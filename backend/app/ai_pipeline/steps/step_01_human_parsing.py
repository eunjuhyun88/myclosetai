"""
1ë‹¨ê³„: ì¸ì²´ íŒŒì‹± (Human Parsing) - 20ê°œ ë¶€ìœ„ ë¶„í• 
Graphonomy ë˜ëŠ” Self-Correction for Human Parsing ëª¨ë¸ ì‚¬ìš©
"""
import os
import logging
import time
from typing import Dict, Any, Optional, Tuple
import numpy as np
import torch
import torch.nn.functional as F
from PIL import Image
import cv2

# Graphonomy ëª¨ë¸ ê´€ë ¨ ì„í¬íŠ¸ (ì‹¤ì œ êµ¬í˜„ ì‹œ í•„ìš”)
try:
    # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” Graphonomy ë ˆí¬ì§€í† ë¦¬ì˜ ëª¨ë“ˆë“¤ì„ ì„í¬íŠ¸
    # from models.graphonomy import Graphonomy
    # from utils.transforms import get_affine_transform
    pass
except ImportError:
    logging.warning("Graphonomy ëª¨ë“ˆì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë°ëª¨ ëª¨ë“œë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤.")

logger = logging.getLogger(__name__)

class HumanParsingStep:
    """ì¸ì²´ íŒŒì‹± ìŠ¤í… - 20ê°œ ì‹ ì²´ ë¶€ìœ„ ë¶„í• """
    
    # LIP (Look Into Person) ë°ì´í„°ì…‹ ê¸°ë°˜ 20ê°œ ë¶€ìœ„ ë¼ë²¨
    BODY_PARTS = {
        0: "Background",
        1: "Hat",
        2: "Hair", 
        3: "Glove",
        4: "Sunglasses",
        5: "Upper-clothes",
        6: "Dress",
        7: "Coat",
        8: "Socks",
        9: "Pants",
        10: "Jumpsuits",
        11: "Scarf",
        12: "Skirt",
        13: "Face",
        14: "Left-arm",
        15: "Right-arm",
        16: "Left-leg",
        17: "Right-leg",
        18: "Left-shoe",
        19: "Right-shoe"
    }
    
    def __init__(self, model_loader, device: str, config: Dict[str, Any] = None):
        """
        Args:
            model_loader: ëª¨ë¸ ë¡œë” ì¸ìŠ¤í„´ìŠ¤
            device: ì‚¬ìš©í•  ë””ë°”ì´ìŠ¤ ('cpu', 'cuda', 'mps')
            config: ì„¤ì • ë”•ì…”ë„ˆë¦¬
        """
        self.model_loader = model_loader
        self.device = device
        self.config = config or {}
        
        # ê¸°ë³¸ ì„¤ì •
        self.input_size = self.config.get('input_size', (512, 512))
        self.num_classes = self.config.get('num_classes', 20)
        self.model_name = self.config.get('model_name', 'graphonomy')
        
        # ëª¨ë¸ ê´€ë ¨
        self.model = None
        self.is_initialized = False
        
        # ì „ì²˜ë¦¬ ì„¤ì •
        self.mean = np.array([0.485, 0.456, 0.406])
        self.std = np.array([0.229, 0.224, 0.225])
        
        logger.info(f"ğŸ¯ ì¸ì²´ íŒŒì‹± ìŠ¤í… ì´ˆê¸°í™” - ë””ë°”ì´ìŠ¤: {device}, ì…ë ¥ í¬ê¸°: {self.input_size}")
    
    async def initialize(self) -> bool:
        """ëª¨ë¸ ì´ˆê¸°í™”"""
        try:
            logger.info("ğŸ”„ ì¸ì²´ íŒŒì‹± ëª¨ë¸ ë¡œë“œ ì¤‘...")
            
            # ëª¨ë¸ íŒŒì¼ ê²½ë¡œ ì„¤ì •
            model_path = self._get_model_path()
            
            if os.path.exists(model_path):
                # ì‹¤ì œ ëª¨ë¸ ë¡œë“œ
                self.model = await self._load_real_model(model_path)
            else:
                logger.warning(f"âš ï¸ ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {model_path}")
                # ë°ëª¨ìš© ëª¨ë¸ ìƒì„±
                self.model = self._create_demo_model()
            
            # ëª¨ë¸ì„ ë””ë°”ì´ìŠ¤ë¡œ ì´ë™ ë° ìµœì í™”
            self.model = self.model_loader.optimize_model(self.model, 'human_parsing')
            
            # í‰ê°€ ëª¨ë“œë¡œ ì„¤ì •
            self.model.eval()
            
            self.is_initialized = True
            logger.info("âœ… ì¸ì²´ íŒŒì‹± ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ ì¸ì²´ íŒŒì‹± ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            self.is_initialized = False
            return False
    
    def _get_model_path(self) -> str:
        """ëª¨ë¸ íŒŒì¼ ê²½ë¡œ ë°˜í™˜"""
        # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ë‹¤ìš´ë¡œë“œëœ ëª¨ë¸ ê²½ë¡œ
        model_dir = self.config.get('model_dir', 'app/models/ai_models/graphonomy')
        model_file = self.config.get('model_file', 'graphonomy_universal.pth')
        return os.path.join(model_dir, model_file)
    
    async def _load_real_model(self, model_path: str):
        """ì‹¤ì œ Graphonomy ëª¨ë¸ ë¡œë“œ"""
        try:
            # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” Graphonomy ëª¨ë¸ ë¡œë“œ
            # model = Graphonomy(num_classes=self.num_classes)
            # checkpoint = torch.load(model_path, map_location=self.device)
            # model.load_state_dict(checkpoint['state_dict'])
            
            # í˜„ì¬ëŠ” ë°ëª¨ìš© ëª¨ë¸ ë°˜í™˜
            return self._create_demo_model()
            
        except Exception as e:
            logger.error(f"ì‹¤ì œ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return self._create_demo_model()
    
    def _create_demo_model(self):
        """ë°ëª¨ìš© ì„¸ê·¸ë©˜í…Œì´ì…˜ ëª¨ë¸ ìƒì„±"""
        class DemoHumanParsingModel(torch.nn.Module):
            def __init__(self, num_classes=20):
                super().__init__()
                # ê°„ë‹¨í•œ CNN ì•„í‚¤í…ì²˜
                self.backbone = torch.nn.Sequential(
                    torch.nn.Conv2d(3, 64, 3, padding=1),
                    torch.nn.ReLU(),
                    torch.nn.Conv2d(64, 128, 3, padding=1),
                    torch.nn.ReLU(),
                    torch.nn.MaxPool2d(2),
                    torch.nn.Conv2d(128, 256, 3, padding=1),
                    torch.nn.ReLU(),
                    torch.nn.MaxPool2d(2),
                    torch.nn.Conv2d(256, 512, 3, padding=1),
                    torch.nn.ReLU(),
                )
                
                self.decoder = torch.nn.Sequential(
                    torch.nn.ConvTranspose2d(512, 256, 4, stride=2, padding=1),
                    torch.nn.ReLU(),
                    torch.nn.ConvTranspose2d(256, 128, 4, stride=2, padding=1),
                    torch.nn.ReLU(),
                    torch.nn.Conv2d(128, num_classes, 1)
                )
            
            def forward(self, x):
                features = self.backbone(x)
                output = self.decoder(features)
                return F.interpolate(output, size=x.shape[2:], mode='bilinear', align_corners=False)
        
        return DemoHumanParsingModel(self.num_classes).to(self.device)
    
    def process(self, person_image_tensor: torch.Tensor) -> Dict[str, Any]:
        """
        ì¸ì²´ íŒŒì‹± ì²˜ë¦¬
        
        Args:
            person_image_tensor: ì‚¬ìš©ì ì´ë¯¸ì§€ í…ì„œ [1, 3, H, W]
            
        Returns:
            ì²˜ë¦¬ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        if not self.is_initialized:
            raise RuntimeError("ì¸ì²´ íŒŒì‹± ëª¨ë¸ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        start_time = time.time()
        
        try:
            # ì…ë ¥ ì „ì²˜ë¦¬
            input_tensor = self._preprocess_image(person_image_tensor)
            
            # ëª¨ë¸ ì¶”ë¡ 
            with torch.no_grad():
                parsing_output = self.model(input_tensor)
                
                # í™•ë¥ ì„ í´ë˜ìŠ¤ ì¸ë±ìŠ¤ë¡œ ë³€í™˜
                parsing_map = torch.argmax(parsing_output, dim=1).squeeze().cpu().numpy()
            
            # í›„ì²˜ë¦¬
            parsing_result = self._postprocess_parsing(parsing_map, person_image_tensor.shape[2:])
            
            # ì‹ ì²´ ë¶€ìœ„ë³„ ë§ˆìŠ¤í¬ ìƒì„±
            body_masks = self._create_body_masks(parsing_map)
            
            # ì‹ ë¢°ë„ ê³„ì‚°
            confidence = self._calculate_confidence(parsing_output)
            
            processing_time = time.time() - start_time
            
            result = {
                "parsing_map": parsing_map.astype(np.uint8),
                "body_masks": body_masks,
                "confidence": float(confidence),
                "body_parts_detected": self._get_detected_parts(parsing_map),
                "processing_time": processing_time,
                "input_size": self.input_size,
                "num_classes": self.num_classes
            }
            
            logger.info(f"âœ… ì¸ì²´ íŒŒì‹± ì™„ë£Œ - ì²˜ë¦¬ì‹œê°„: {processing_time:.3f}ì´ˆ, ì‹ ë¢°ë„: {confidence:.3f}")
            
            return result
            
        except Exception as e:
            logger.error(f"âŒ ì¸ì²´ íŒŒì‹± ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            raise
    
    def _preprocess_image(self, image_tensor: torch.Tensor) -> torch.Tensor:
        """ì´ë¯¸ì§€ ì „ì²˜ë¦¬"""
        # í¬ê¸° ì¡°ì •
        if image_tensor.shape[2:] != self.input_size:
            image_tensor = F.interpolate(
                image_tensor, 
                size=self.input_size, 
                mode='bilinear', 
                align_corners=False
            )
        
        # ì •ê·œí™” (0-1 ë²”ìœ„ë¼ê³  ê°€ì •)
        if image_tensor.max() > 1.0:
            image_tensor = image_tensor / 255.0
        
        # ImageNet ì •ê·œí™”
        mean = torch.tensor(self.mean).view(1, 3, 1, 1).to(self.device)
        std = torch.tensor(self.std).view(1, 3, 1, 1).to(self.device)
        
        normalized = (image_tensor - mean) / std
        
        return normalized
    
    def _postprocess_parsing(self, parsing_map: np.ndarray, original_size: Tuple[int, int]) -> np.ndarray:
        """íŒŒì‹± ê²°ê³¼ í›„ì²˜ë¦¬"""
        # ì›ë³¸ í¬ê¸°ë¡œ ë³µì›
        if parsing_map.shape != original_size:
            parsing_map = cv2.resize(
                parsing_map.astype(np.uint8), 
                (original_size[1], original_size[0]), 
                interpolation=cv2.INTER_NEAREST
            )
        
        # ì‘ì€ ë…¸ì´ì¦ˆ ì œê±° (ëª¨í´ë¡œì§€ ì—°ì‚°)
        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))
        parsing_map = cv2.morphologyEx(parsing_map, cv2.MORPH_CLOSE, kernel)
        parsing_map = cv2.morphologyEx(parsing_map, cv2.MORPH_OPEN, kernel)
        
        return parsing_map
    
    def _create_body_masks(self, parsing_map: np.ndarray) -> Dict[str, np.ndarray]:
        """ì‹ ì²´ ë¶€ìœ„ë³„ ë§ˆìŠ¤í¬ ìƒì„±"""
        body_masks = {}
        
        for part_id, part_name in self.BODY_PARTS.items():
            if part_id == 0:  # ë°°ê²½ ì œì™¸
                continue
            
            mask = (parsing_map == part_id).astype(np.uint8)
            if mask.sum() > 0:  # í•´ë‹¹ ë¶€ìœ„ê°€ ê°ì§€ëœ ê²½ìš°ë§Œ ì¶”ê°€
                body_masks[part_name.lower().replace('-', '_')] = mask
        
        return body_masks
    
    def _calculate_confidence(self, parsing_output: torch.Tensor) -> float:
        """íŒŒì‹± ê²°ê³¼ ì‹ ë¢°ë„ ê³„ì‚°"""
        # ìµœëŒ€ í™•ë¥ ê°’ë“¤ì˜ í‰ê· ìœ¼ë¡œ ì‹ ë¢°ë„ ê³„ì‚°
        max_probs = torch.max(F.softmax(parsing_output, dim=1), dim=1)[0]
        confidence = torch.mean(max_probs).item()
        
        return confidence
    
    def _get_detected_parts(self, parsing_map: np.ndarray) -> Dict[str, Any]:
        """ê°ì§€ëœ ì‹ ì²´ ë¶€ìœ„ ì •ë³´"""
        detected_parts = {}
        
        for part_id, part_name in self.BODY_PARTS.items():
            if part_id == 0:  # ë°°ê²½ ì œì™¸
                continue
            
            mask = (parsing_map == part_id)
            pixel_count = mask.sum()
            
            if pixel_count > 0:
                # ë¶€ìœ„ë³„ í†µê³„
                detected_parts[part_name.lower().replace('-', '_')] = {
                    "pixel_count": int(pixel_count),
                    "percentage": float(pixel_count / parsing_map.size * 100),
                    "bounding_box": self._get_bounding_box(mask)
                }
        
        return detected_parts
    
    def _get_bounding_box(self, mask: np.ndarray) -> Dict[str, int]:
        """ë§ˆìŠ¤í¬ì˜ ë°”ìš´ë”© ë°•ìŠ¤ ê³„ì‚°"""
        coords = np.where(mask)
        if len(coords[0]) == 0:
            return {"x": 0, "y": 0, "width": 0, "height": 0}
        
        y_min, y_max = coords[0].min(), coords[0].max()
        x_min, x_max = coords[1].min(), coords[1].max()
        
        return {
            "x": int(x_min),
            "y": int(y_min), 
            "width": int(x_max - x_min),
            "height": int(y_max - y_min)
        }
    
    def get_body_part_mask(self, parsing_map: np.ndarray, part_names: list) -> np.ndarray:
        """íŠ¹ì • ì‹ ì²´ ë¶€ìœ„ë“¤ì˜ í†µí•© ë§ˆìŠ¤í¬ ë°˜í™˜"""
        combined_mask = np.zeros_like(parsing_map, dtype=np.uint8)
        
        for part_name in part_names:
            # ë¶€ìœ„ ì´ë¦„ìœ¼ë¡œ ID ì°¾ê¸°
            for part_id, name in self.BODY_PARTS.items():
                if name.lower().replace('-', '_') == part_name.lower():
                    combined_mask |= (parsing_map == part_id).astype(np.uint8)
                    break
        
        return combined_mask
    
    def visualize_parsing(self, parsing_map: np.ndarray) -> np.ndarray:
        """íŒŒì‹± ê²°ê³¼ ì‹œê°í™”"""
        # ì»¬ëŸ¬ë§µ ì •ì˜ (ê° ë¶€ìœ„ë³„ ìƒ‰ìƒ)
        colors = np.array([
            [0, 0, 0],       # 0: Background
            [128, 0, 0],     # 1: Hat
            [255, 0, 0],     # 2: Hair
            [0, 85, 0],      # 3: Glove
            [170, 0, 51],    # 4: Sunglasses
            [255, 85, 0],    # 5: Upper-clothes
            [0, 0, 85],      # 6: Dress
            [0, 119, 221],   # 7: Coat
            [85, 85, 0],     # 8: Socks
            [0, 85, 85],     # 9: Pants
            [85, 51, 0],     # 10: Jumpsuits
            [52, 86, 128],   # 11: Scarf
            [0, 128, 0],     # 12: Skirt
            [0, 0, 255],     # 13: Face
            [51, 170, 221],  # 14: Left-arm
            [0, 255, 255],   # 15: Right-arm
            [85, 255, 170],  # 16: Left-leg
            [170, 255, 85],  # 17: Right-leg
            [255, 255, 0],   # 18: Left-shoe
            [255, 170, 0]    # 19: Right-shoe
        ])
        
        # íŒŒì‹± ë§µì„ ì»¬ëŸ¬ ì´ë¯¸ì§€ë¡œ ë³€í™˜
        colored_parsing = colors[parsing_map]
        
        return colored_parsing.astype(np.uint8)
    
    async def get_model_info(self) -> Dict[str, Any]:
        """ëª¨ë¸ ì •ë³´ ë°˜í™˜"""
        return {
            "model_name": self.model_name,
            "input_size": self.input_size,
            "num_classes": self.num_classes,
            "device": self.device,
            "initialized": self.is_initialized,
            "body_parts": list(self.BODY_PARTS.values()),
            "model_parameters": sum(p.numel() for p in self.model.parameters()) if self.model else 0
        }
    
    async def cleanup(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        if self.model:
            del self.model
            self.model = None
        
        self.is_initialized = False
        logger.info("ğŸ§¹ ì¸ì²´ íŒŒì‹± ìŠ¤í… ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì™„ë£Œ")