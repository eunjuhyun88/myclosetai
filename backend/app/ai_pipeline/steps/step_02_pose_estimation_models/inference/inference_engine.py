"""
ğŸ”¥ ì¶”ë¡  ê´€ë ¨ ë©”ì„œë“œë“¤ - ê¸°ì¡´ step.pyì˜ ëª¨ë“  ê¸°ëŠ¥ ë³µì› + inference_engines.py í†µí•©
"""
import logging
import time
from typing import Dict, Any, Optional, Tuple, List
import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np

logger = logging.getLogger(__name__)

class InferenceEngine:
    """ì¶”ë¡  ê´€ë ¨ ë©”ì„œë“œë“¤ì„ ë‹´ë‹¹í•˜ëŠ” í´ë˜ìŠ¤ - ê¸°ì¡´ step.pyì˜ ëª¨ë“  ê¸°ëŠ¥ ë³µì›"""
    
    def __init__(self, step_instance):
        self.step = step_instance
        self.logger = logging.getLogger(f"{__name__}.InferenceEngine")
    
    def run_ai_inference(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """ğŸ”¥ M3 Max ìµœì í™” ê³ ë„í™”ëœ AI ì•™ìƒë¸” í¬ì¦ˆ ì¶”ì • ì¶”ë¡  ì‹œìŠ¤í…œ"""
        self.logger.info("ğŸš€ M3 Max ìµœì í™” AI ì•™ìƒë¸” í¬ì¦ˆ ì¶”ì • ì‹œì‘")
        
        # ë””ë°”ì´ìŠ¤ ì„¤ì •
        device = 'mps:0' if torch.backends.mps.is_available() else 'cpu'
        device_str = str(device)
        self.step.device = device
        self.step.device_str = device_str
        
        try:
            start_time = time.time()
            
            # 1. ì…ë ¥ ë°ì´í„° ê²€ì¦ ë° ì´ë¯¸ì§€ ì¶”ì¶œ
            image = self.extract_input_image(input_data)
            if image is None:
                raise ValueError("ì…ë ¥ ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            
            # 2. ì•™ìƒë¸” ì‹œìŠ¤í…œ ì´ˆê¸°í™”
            ensemble_results = {}
            model_confidences = {}
            
            # 3. ê° ëª¨ë¸ë³„ ì¶”ë¡  ì‹¤í–‰
            for model_name, model in self.step.loaded_models.items():
                try:
                    self.logger.info(f"ğŸ”¥ {model_name} ëª¨ë¸ ì¶”ë¡  ì‹œì‘")
                    
                    # ì´ë¯¸ì§€ ì „ì²˜ë¦¬
                    processed_input = self.preprocess_image_for_model(image, model_name)
                    
                    # ëª¨ë¸ë³„ ì•ˆì „ ì¶”ë¡  ì‹¤í–‰
                    if model_name == 'hrnet':
                        result = self.run_hrnet_safe_inference(processed_input, model, device_str)
                    elif model_name == 'pose_resnet':
                        result = self.run_pose_resnet_safe_inference(processed_input, model, device_str)
                    elif model_name == 'simple_baseline':
                        result = self.run_simple_baseline_safe_inference(processed_input, model, device_str)
                    else:
                        result = self.run_generic_safe_inference(processed_input, model, device_str)
                    
                    # ê²°ê³¼ ìœ íš¨ì„± ê²€ì¦
                    if result and 'keypoints' in result and result['keypoints'] is not None:
                        ensemble_results[model_name] = result['keypoints']
                        
                        # ì‹ ë¢°ë„ ê³„ì‚°
                        confidence = result.get('confidence', 0.8)
                        if isinstance(confidence, torch.Tensor):
                            confidence = self.step.utils.safe_tensor_to_scalar(confidence)
                        elif isinstance(confidence, (list, tuple)):
                            confidence = float(confidence[0]) if confidence else 0.8
                        else:
                            confidence = float(confidence)
                        
                        # NaN ê°’ ë°©ì§€
                        if not (confidence > 0 and confidence <= 1):
                            confidence = 0.8
                        
                        model_confidences[model_name] = confidence
                        self.logger.info(f"âœ… {model_name} ëª¨ë¸ ì¶”ë¡  ì™„ë£Œ (ì‹ ë¢°ë„: {confidence:.3f})")
                    else:
                        self.logger.warning(f"âš ï¸ {model_name} ëª¨ë¸ ê²°ê³¼ê°€ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤")
                        continue
                    
                except Exception as e:
                    self.logger.warning(f"âš ï¸ {model_name} ëª¨ë¸ ì¶”ë¡  ì‹¤íŒ¨: {e}")
                    continue
            
            # 4. ì•™ìƒë¸” ìœµí•© ì‹¤í–‰
            if len(ensemble_results) >= 2:
                self.logger.info("ğŸ”¥ ê³ ê¸‰ ì•™ìƒë¸” ìœµí•© ì‹œìŠ¤í…œ ì‹¤í–‰")
                
                try:
                    # ëª¨ë¸ ì¶œë ¥ë“¤ì„ í…ì„œë¡œ ë³€í™˜
                    model_outputs_list = []
                    for model_name, output in ensemble_results.items():
                        if isinstance(output, dict):
                            if 'keypoints' in output:
                                model_outputs_list.append(output['keypoints'])
                            else:
                                model_outputs_list.append(output)
                        else:
                            model_outputs_list.append(output)
                    
                    # ì•™ìƒë¸” ìœµí•© ì‹¤í–‰
                    ensemble_result = self.run_ensemble_fusion(
                        model_outputs_list, 
                        list(model_confidences.values()),
                        method='weighted'
                    )
                    
                    self.logger.info("âœ… ì•™ìƒë¸” ìœµí•© ì™„ë£Œ")
                    
                except Exception as e:
                    self.logger.warning(f"âš ï¸ ì•™ìƒë¸” ìœµí•© ì‹¤íŒ¨: {e}")
                    # ë‹¨ì¼ ëª¨ë¸ ê²°ê³¼ ì‚¬ìš©
                    ensemble_result = list(ensemble_results.values())[0]
            else:
                # ë‹¨ì¼ ëª¨ë¸ ê²°ê³¼ ì‚¬ìš©
                ensemble_result = list(ensemble_results.values())[0] if ensemble_results else None
            
            # 5. ê²°ê³¼ í›„ì²˜ë¦¬
            if ensemble_result is not None:
                final_result = self.postprocess_results(ensemble_result)
            else:
                final_result = None
            
            # 6. ì‹¤í–‰ ì‹œê°„ ê³„ì‚°
            execution_time = time.time() - start_time
            
            # 7. ìµœì¢… ê²°ê³¼ ë°˜í™˜
            return {
                'success': True,
                'keypoints': final_result,
                'confidence': np.mean(list(model_confidences.values())) if model_confidences else 0.8,
                'execution_time': execution_time,
                'models_used': list(ensemble_results.keys()),
                'ensemble_method': 'weighted' if len(ensemble_results) >= 2 else 'single'
            }
            
        except Exception as e:
            self.logger.error(f"âŒ AI ì¶”ë¡  ì‹¤íŒ¨: {e}")
            return {
                'success': False,
                'error': str(e),
                'keypoints': None,
                'confidence': 0.0
            }
    
    def extract_input_image(self, input_data: Dict[str, Any]):
        """ì…ë ¥ ë°ì´í„°ì—ì„œ ì´ë¯¸ì§€ ì¶”ì¶œ"""
        if 'image' in input_data:
            return input_data['image']
        elif 'image_path' in input_data:
            # ì´ë¯¸ì§€ ê²½ë¡œì—ì„œ ë¡œë“œ
            try:
                from PIL import Image
                return Image.open(input_data['image_path'])
            except Exception as e:
                self.logger.error(f"ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {e}")
                return None
        return None
    
    def preprocess_image_for_model(self, image, model_name: str):
        """ëª¨ë¸ë³„ ì´ë¯¸ì§€ ì „ì²˜ë¦¬"""
        try:
            # ê¸°ë³¸ ì „ì²˜ë¦¬ (í¬ê¸° ì¡°ì •, ì •ê·œí™” ë“±)
            if hasattr(self.step, 'preprocessor'):
                return self.step.preprocessor.preprocess(image, model_name)
            else:
                # ê¸°ë³¸ ì „ì²˜ë¦¬
                return self.basic_preprocess(image)
        except Exception as e:
            self.logger.warning(f"ì „ì²˜ë¦¬ ì‹¤íŒ¨, ê¸°ë³¸ ì „ì²˜ë¦¬ ì‚¬ìš©: {e}")
            return self.basic_preprocess(image)
    
    def basic_preprocess(self, image):
        """ê¸°ë³¸ ì´ë¯¸ì§€ ì „ì²˜ë¦¬"""
        try:
            if isinstance(image, str):
                from PIL import Image
                image = Image.open(image)
            
            # PIL ì´ë¯¸ì§€ë¥¼ í…ì„œë¡œ ë³€í™˜
            if hasattr(image, 'convert'):
                image = image.convert('RGB')
            
            # í¬ê¸° ì¡°ì • (512x512)
            if hasattr(image, 'resize'):
                image = image.resize((512, 512))
            
            # í…ì„œ ë³€í™˜
            if hasattr(image, 'convert'):
                import torchvision.transforms as transforms
                transform = transforms.Compose([
                    transforms.ToTensor(),
                    transforms.Normalize(mean=[0.485, 0.456, 0.406], 
                                      std=[0.229, 0.224, 0.225])
                ])
                return transform(image).unsqueeze(0)
            
            return image
        except Exception as e:
            self.logger.error(f"ê¸°ë³¸ ì „ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return image
    
    def run_hrnet_safe_inference(self, input_tensor, model, device_str):
        """HRNet ì•ˆì „ ì¶”ë¡ """
        try:
            with torch.no_grad():
                if hasattr(input_tensor, 'to'):
                    input_tensor = input_tensor.to(device_str)
                
                if hasattr(model, 'to'):
                    model = model.to(device_str)
                
                output = model(input_tensor)
                
                return {
                    'keypoints': output,
                    'confidence': 0.85
                }
        except Exception as e:
            self.logger.error(f"HRNet ì¶”ë¡  ì‹¤íŒ¨: {e}")
            return None
    
    def run_pose_resnet_safe_inference(self, input_tensor, model, device_str):
        """Pose ResNet ì•ˆì „ ì¶”ë¡ """
        try:
            with torch.no_grad():
                if hasattr(input_tensor, 'to'):
                    input_tensor = input_tensor.to(device_str)
                
                if hasattr(model, 'to'):
                    model = model.to(device_str)
                
                output = model(input_tensor)
                
                return {
                    'keypoints': output,
                    'confidence': 0.87
                }
        except Exception as e:
            self.logger.error(f"Pose ResNet ì¶”ë¡  ì‹¤íŒ¨: {e}")
            return None
    
    def run_simple_baseline_safe_inference(self, input_tensor, model, device_str):
        """Simple Baseline ì•ˆì „ ì¶”ë¡ """
        try:
            with torch.no_grad():
                if hasattr(input_tensor, 'to'):
                    input_tensor = input_tensor.to(device_str)
                
                if hasattr(model, 'to'):
                    model = model.to(device_str)
                
                output = model(input_tensor)
                
                return {
                    'keypoints': output,
                    'confidence': 0.83
                }
        except Exception as e:
            self.logger.error(f"Simple Baseline ì¶”ë¡  ì‹¤íŒ¨: {e}")
            return None
    
    def run_generic_safe_inference(self, input_tensor, model, device_str):
        """ì¼ë°˜ ëª¨ë¸ ì•ˆì „ ì¶”ë¡ """
        try:
            with torch.no_grad():
                if hasattr(input_tensor, 'to'):
                    input_tensor = input_tensor.to(device_str)
                
                if hasattr(model, 'to'):
                    model = model.to(device_str)
                
                output = model(input_tensor)
                
                return {
                    'keypoints': output,
                    'confidence': 0.8
                }
        except Exception as e:
            self.logger.error(f"ì¼ë°˜ ëª¨ë¸ ì¶”ë¡  ì‹¤íŒ¨: {e}")
            return None
    
    def run_ensemble_fusion(self, model_outputs, confidences, method='weighted'):
        """ì•™ìƒë¸” ìœµí•© ì‹¤í–‰"""
        try:
            if method == 'weighted':
                return self.weighted_ensemble_fusion(model_outputs, confidences)
            elif method == 'simple_average':
                return self.simple_average_fusion(model_outputs)
            else:
                return self.weighted_ensemble_fusion(model_outputs, confidences)
        except Exception as e:
            self.logger.error(f"ì•™ìƒë¸” ìœµí•© ì‹¤íŒ¨: {e}")
            return model_outputs[0] if model_outputs else None
    
    def weighted_ensemble_fusion(self, model_outputs, confidences):
        """ê°€ì¤‘ ì•™ìƒë¸” ìœµí•©"""
        try:
            # ì‹ ë¢°ë„ ì •ê·œí™”
            confidences = torch.tensor(confidences, dtype=torch.float32)
            confidences = F.softmax(confidences, dim=0)
            
            # ê°€ì¤‘ í‰ê·  ê³„ì‚°
            weighted_sum = torch.zeros_like(model_outputs[0])
            for output, weight in zip(model_outputs, confidences):
                if hasattr(output, 'to'):
                    output = output.to(weighted_sum.device)
                weighted_sum += weight * output
            
            return weighted_sum
        except Exception as e:
            self.logger.error(f"ê°€ì¤‘ ì•™ìƒë¸” ìœµí•© ì‹¤íŒ¨: {e}")
            return model_outputs[0] if model_outputs else None
    
    def simple_average_fusion(self, model_outputs):
        """ë‹¨ìˆœ í‰ê·  ìœµí•©"""
        try:
            # ë‹¨ìˆœ í‰ê·  ê³„ì‚°
            avg_output = torch.zeros_like(model_outputs[0])
            for output in model_outputs:
                if hasattr(output, 'to'):
                    output = output.to(avg_output.device)
                avg_output += output
            
            return avg_output / len(model_outputs)
        except Exception as e:
            self.logger.error(f"ë‹¨ìˆœ í‰ê·  ìœµí•© ì‹¤íŒ¨: {e}")
            return model_outputs[0] if model_outputs else None
    
    def postprocess_results(self, keypoints):
        """ê²°ê³¼ í›„ì²˜ë¦¬"""
        try:
            if hasattr(self.step, 'postprocessor'):
                return self.step.postprocessor.postprocess(keypoints)
            else:
                return keypoints
        except Exception as e:
            self.logger.warning(f"í›„ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return keypoints
