#!/usr/bin/env python3
"""
ğŸ”¥ MyCloset AI - Step 02: Pose Estimation Quality Enhancement
=============================================================

ğŸ¯ í¬ì¦ˆ ì¶”ì • ê²°ê³¼ í’ˆì§ˆ í–¥ìƒ
âœ… í‚¤í¬ì¸íŠ¸ ì •ì œ ë° ë³´ê°„
âœ… ìì„¸ ì¼ê´€ì„± ê°œì„ 
âœ… ë…¸ì´ì¦ˆ ì œê±° ë° ìŠ¤ë¬´ë”©
"""

import logging
from typing import Dict, List, Optional, Union, Any, Tuple
from dataclasses import dataclass
import numpy as np

# PyTorch import ì‹œë„
try:
    import torch
    TORCH_AVAILABLE = True
except ImportError:
    TORCH_AVAILABLE = False
    torch = None

logger = logging.getLogger(__name__)

@dataclass
class EnhancementConfig:
    """í’ˆì§ˆ í–¥ìƒ ì„¤ì •"""
    smoothing_factor: float = 0.8
    interpolation_threshold: float = 0.3
    consistency_check: bool = True
    noise_reduction: bool = True
    temporal_window: int = 5

class QualityEnhancement:
    """
    ğŸ”¥ í¬ì¦ˆ ì¶”ì • í’ˆì§ˆ í–¥ìƒ ì‹œìŠ¤í…œ
    
    í¬ì¦ˆ ì¶”ì • ê²°ê³¼ì˜ í’ˆì§ˆì„ í–¥ìƒì‹œí‚¤ê³  ì¼ê´€ì„±ì„ ê°œì„ í•©ë‹ˆë‹¤.
    """
    
    def __init__(self, config: EnhancementConfig = None):
        self.config = config or EnhancementConfig()
        self.logger = logging.getLogger(__name__)
        
        # ì‹œê°„ì  ë²„í¼ (í’ˆì§ˆ í–¥ìƒìš©)
        self.temporal_buffer = []
        self.max_buffer_size = self.config.temporal_window
        
        self.logger.info("ğŸ¯ í¬ì¦ˆ ì¶”ì • í’ˆì§ˆ í–¥ìƒ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
    
    def enhance_pose_quality(self, keypoints: Union[torch.Tensor, np.ndarray],
                           confidences: Optional[Union[torch.Tensor, np.ndarray]] = None) -> Dict[str, Any]:
        """
        í¬ì¦ˆ í’ˆì§ˆ í–¥ìƒ
        
        Args:
            keypoints: í‚¤í¬ì¸íŠ¸ ì¢Œí‘œ (B, N, 3) - (x, y, confidence)
            confidences: ì‹ ë¢°ë„ ì ìˆ˜ (B, N)
        
        Returns:
            í–¥ìƒëœ ê²°ê³¼
        """
        try:
            # numpyë¡œ ë³€í™˜
            if TORCH_AVAILABLE and isinstance(keypoints, torch.Tensor):
                keypoints_np = keypoints.detach().cpu().numpy()
            else:
                keypoints_np = np.array(keypoints)
            
            if confidences is not None:
                if TORCH_AVAILABLE and isinstance(confidences, torch.Tensor):
                    confidences_np = confidences.detach().cpu().numpy()
                else:
                    confidences_np = np.array(confidences)
            else:
                # í‚¤í¬ì¸íŠ¸ì—ì„œ ì‹ ë¢°ë„ ì¶”ì¶œ
                confidences_np = keypoints_np[:, :, 2] if keypoints_np.shape[-1] == 3 else np.ones(keypoints_np.shape[:2])
            
            # 1ë‹¨ê³„: ë…¸ì´ì¦ˆ ì œê±°
            if self.config.noise_reduction:
                cleaned_keypoints = self._reduce_noise(keypoints_np, confidences_np)
            else:
                cleaned_keypoints = keypoints_np
            
            # 2ë‹¨ê³„: ì¼ê´€ì„± ê²€ì‚¬ ë° ê°œì„ 
            if self.config.consistency_check:
                consistent_keypoints = self._improve_consistency(cleaned_keypoints, confidences_np)
            else:
                consistent_keypoints = cleaned_keypoints
            
            # 3ë‹¨ê³„: ì‹œê°„ì  ìŠ¤ë¬´ë”©
            smoothed_keypoints = self._temporal_smoothing(consistent_keypoints)
            
            # 4ë‹¨ê³„: ë‚®ì€ ì‹ ë¢°ë„ í‚¤í¬ì¸íŠ¸ ë³´ê°„
            interpolated_keypoints = self._interpolate_low_confidence(smoothed_keypoints, confidences_np)
            
            # ì‹œê°„ì  ë²„í¼ ì—…ë°ì´íŠ¸
            self._update_temporal_buffer(interpolated_keypoints)
            
            # ìµœì¢… í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°
            final_quality = self._calculate_final_quality(interpolated_keypoints, confidences_np)
            
            result = {
                'enhanced_keypoints': interpolated_keypoints,
                'original_keypoints': keypoints_np,
                'confidences': confidences_np,
                'quality_score': final_quality,
                'enhancement_applied': {
                    'noise_reduction': self.config.noise_reduction,
                    'consistency_improvement': self.config.consistency_check,
                    'temporal_smoothing': True,
                    'interpolation': True
                }
            }
            
            self.logger.info(f"âœ… í¬ì¦ˆ í’ˆì§ˆ í–¥ìƒ ì™„ë£Œ (í’ˆì§ˆ ì ìˆ˜: {final_quality:.3f})")
            return result
            
        except Exception as e:
            self.logger.error(f"âŒ í¬ì¦ˆ í’ˆì§ˆ í–¥ìƒ ì‹¤íŒ¨: {e}")
            return {
                'enhanced_keypoints': keypoints_np if 'keypoints_np' in locals() else np.zeros((1, 17, 3)),
                'original_keypoints': keypoints_np if 'keypoints_np' in locals() else np.zeros((1, 17, 3)),
                'confidences': confidences_np if 'confidences_np' in locals() else np.zeros((1, 17)),
                'quality_score': 0.0,
                'error': str(e)
            }
    
    def _reduce_noise(self, keypoints: np.ndarray, confidences: np.ndarray) -> np.ndarray:
        """ë…¸ì´ì¦ˆ ì œê±°"""
        cleaned = keypoints.copy()
        
        # ë‚®ì€ ì‹ ë¢°ë„ í‚¤í¬ì¸íŠ¸ì— ëŒ€í•´ ì´ì „ í”„ë ˆì„ ê°’ ì‚¬ìš©
        low_confidence_mask = confidences < self.config.interpolation_threshold
        
        if self.temporal_buffer:
            prev_keypoints = self.temporal_buffer[-1]
            for batch_idx in range(keypoints.shape[0]):
                for kp_idx in range(keypoints.shape[1]):
                    if low_confidence_mask[batch_idx, kp_idx]:
                        if prev_keypoints.shape[0] > batch_idx and prev_keypoints.shape[1] > kp_idx:
                            cleaned[batch_idx, kp_idx] = prev_keypoints[batch_idx, kp_idx]
        
        return cleaned
    
    def _improve_consistency(self, keypoints: np.ndarray, confidences: np.ndarray) -> np.ndarray:
        """ì¼ê´€ì„± ê°œì„ """
        consistent = keypoints.copy()
        
        # í‚¤í¬ì¸íŠ¸ ê°„ì˜ ê±°ë¦¬ ì¼ê´€ì„± ê²€ì‚¬
        for batch_idx in range(keypoints.shape[0]):
            batch_keypoints = keypoints[batch_idx]
            batch_confidences = confidences[batch_idx]
            
            # ìœ íš¨í•œ í‚¤í¬ì¸íŠ¸ë§Œ ì„ íƒ
            valid_mask = batch_confidences > self.config.interpolation_threshold
            if np.sum(valid_mask) < 2:
                continue
            
            valid_keypoints = batch_keypoints[valid_mask]
            
            # í‚¤í¬ì¸íŠ¸ ê°„ì˜ ê±°ë¦¬ ê³„ì‚°
            distances = []
            for i in range(len(valid_keypoints)):
                for j in range(i + 1, len(valid_keypoints)):
                    dist = np.linalg.norm(valid_keypoints[i][:2] - valid_keypoints[j][:2])
                    distances.append(dist)
            
            if distances:
                mean_distance = np.mean(distances)
                std_distance = np.std(distances)
                
                # ë¹„ì •ìƒì ìœ¼ë¡œ ë¨¼ ê±°ë¦¬ì¸ í‚¤í¬ì¸íŠ¸ ë³´ì •
                for i, dist in enumerate(distances):
                    if abs(dist - mean_distance) > 2 * std_distance:
                        # í•´ë‹¹ í‚¤í¬ì¸íŠ¸ë¥¼ í‰ê·  ìœ„ì¹˜ë¡œ ë³´ì •
                        if self.temporal_buffer:
                            prev_keypoints = self.temporal_buffer[-1]
                            if prev_keypoints.shape[0] > batch_idx:
                                consistent[batch_idx, i] = prev_keypoints[batch_idx, i]
        
        return consistent
    
    def _temporal_smoothing(self, keypoints: np.ndarray) -> np.ndarray:
        """ì‹œê°„ì  ìŠ¤ë¬´ë”©"""
        if not self.temporal_buffer:
            return keypoints
        
        smoothed = keypoints.copy()
        smoothing_factor = self.config.smoothing_factor
        
        for batch_idx in range(keypoints.shape[0]):
            for kp_idx in range(keypoints.shape[1]):
                # ì´ì „ í”„ë ˆì„ë“¤ì˜ ê°€ì¤‘ í‰ê· 
                weighted_sum = np.zeros_like(keypoints[batch_idx, kp_idx])
                total_weight = 0.0
                
                for frame_idx, prev_keypoints in enumerate(self.temporal_buffer):
                    if prev_keypoints.shape[0] > batch_idx and prev_keypoints.shape[1] > kp_idx:
                        weight = smoothing_factor ** (len(self.temporal_buffer) - frame_idx)
                        weighted_sum += weight * prev_keypoints[batch_idx, kp_idx]
                        total_weight += weight
                
                if total_weight > 0:
                    smoothed[batch_idx, kp_idx] = weighted_sum / total_weight
        
        return smoothed
    
    def _interpolate_low_confidence(self, keypoints: np.ndarray, confidences: np.ndarray) -> np.ndarray:
        """ë‚®ì€ ì‹ ë¢°ë„ í‚¤í¬ì¸íŠ¸ ë³´ê°„"""
        interpolated = keypoints.copy()
        
        for batch_idx in range(keypoints.shape[0]):
            for kp_idx in range(keypoints.shape[1]):
                if confidences[batch_idx, kp_idx] < self.config.interpolation_threshold:
                    # ì´ì „ í”„ë ˆì„ ê°’ìœ¼ë¡œ ë³´ê°„
                    if self.temporal_buffer:
                        prev_keypoints = self.temporal_buffer[-1]
                        if prev_keypoints.shape[0] > batch_idx and prev_keypoints.shape[1] > kp_idx:
                            interpolated[batch_idx, kp_idx] = prev_keypoints[batch_idx, kp_idx]
        
        return interpolated
    
    def _update_temporal_buffer(self, keypoints: np.ndarray):
        """ì‹œê°„ì  ë²„í¼ ì—…ë°ì´íŠ¸"""
        self.temporal_buffer.append(keypoints.copy())
        
        # ë²„í¼ í¬ê¸° ì œí•œ
        if len(self.temporal_buffer) > self.max_buffer_size:
            self.temporal_buffer.pop(0)
    
    def _calculate_final_quality(self, keypoints: np.ndarray, confidences: np.ndarray) -> float:
        """ìµœì¢… í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°"""
        try:
            # ì‹ ë¢°ë„ ì ìˆ˜
            confidence_score = np.mean(confidences)
            
            # í‚¤í¬ì¸íŠ¸ ë¶„í¬ ì ìˆ˜
            distribution_score = self._calculate_distribution_score(keypoints)
            
            # ì¼ê´€ì„± ì ìˆ˜
            consistency_score = self._calculate_consistency_score(keypoints)
            
            # ì¢…í•© í’ˆì§ˆ ì ìˆ˜
            final_score = (
                0.4 * confidence_score +
                0.3 * distribution_score +
                0.3 * consistency_score
            )
            
            return float(np.clip(final_score, 0.0, 1.0))
            
        except Exception as e:
            self.logger.warning(f"í’ˆì§ˆ ì ìˆ˜ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return 0.0
    
    def _calculate_distribution_score(self, keypoints: np.ndarray) -> float:
        """ë¶„í¬ ì ìˆ˜ ê³„ì‚°"""
        try:
            # í‚¤í¬ì¸íŠ¸ë“¤ì´ ë„ˆë¬´ ì§‘ì¤‘ë˜ì§€ ì•Šì•˜ëŠ”ì§€ í™•ì¸
            batch_scores = []
            
            for batch_idx in range(keypoints.shape[0]):
                batch_keypoints = keypoints[batch_idx]
                
                # í‚¤í¬ì¸íŠ¸ ê°„ì˜ ê±°ë¦¬ ê³„ì‚°
                distances = []
                for i in range(batch_keypoints.shape[0]):
                    for j in range(i + 1, batch_keypoints.shape[0]):
                        dist = np.linalg.norm(batch_keypoints[i][:2] - batch_keypoints[j][:2])
                        distances.append(dist)
                
                if distances:
                    distances = np.array(distances)
                    # ì ì ˆí•œ ê±°ë¦¬ ë²”ìœ„ ë‚´ì— ìˆëŠ” ë¹„ìœ¨
                    good_distances = np.sum((distances > 10) & (distances < 200))
                    distribution_score = good_distances / len(distances) if len(distances) > 0 else 0.0
                    batch_scores.append(distribution_score)
            
            return float(np.mean(batch_scores)) if batch_scores else 0.0
            
        except Exception:
            return 0.0
    
    def _calculate_consistency_score(self, keypoints: np.ndarray) -> float:
        """ì¼ê´€ì„± ì ìˆ˜ ê³„ì‚°"""
        try:
            if not self.temporal_buffer:
                return 0.5  # ê¸°ë³¸ê°’
            
            # ì´ì „ í”„ë ˆì„ê³¼ì˜ ì¼ê´€ì„±
            prev_keypoints = self.temporal_buffer[-1]
            consistency_scores = []
            
            for batch_idx in range(min(keypoints.shape[0], prev_keypoints.shape[0])):
                batch_consistency = []
                for kp_idx in range(min(keypoints.shape[1], prev_keypoints.shape[1])):
                    current_kp = keypoints[batch_idx, kp_idx][:2]
                    prev_kp = prev_keypoints[batch_idx, kp_idx][:2]
                    
                    # í‚¤í¬ì¸íŠ¸ ì´ë™ ê±°ë¦¬
                    movement = np.linalg.norm(current_kp - prev_kp)
                    
                    # ì ì ˆí•œ ì´ë™ ê±°ë¦¬ì¸ì§€ í™•ì¸ (ë„ˆë¬´ í¬ê±°ë‚˜ ì‘ì§€ ì•ŠìŒ)
                    if 1.0 <= movement <= 50.0:
                        batch_consistency.append(1.0)
                    else:
                        batch_consistency.append(max(0.0, 1.0 - movement / 100.0))
                
                if batch_consistency:
                    consistency_scores.append(np.mean(batch_consistency))
            
            return float(np.mean(consistency_scores)) if consistency_scores else 0.5
            
        except Exception:
            return 0.5
    
    def reset_temporal_state(self):
        """ì‹œê°„ì  ìƒíƒœ ì´ˆê¸°í™”"""
        self.temporal_buffer.clear()
        self.logger.info("âœ… ì‹œê°„ì  ìƒíƒœ ì´ˆê¸°í™” ì™„ë£Œ")
    
    def get_config(self) -> EnhancementConfig:
        """í˜„ì¬ ì„¤ì • ë°˜í™˜"""
        return self.config
    
    def update_config(self, new_config: EnhancementConfig):
        """ì„¤ì • ì—…ë°ì´íŠ¸"""
        self.config = new_config
        self.logger.info("âœ… í’ˆì§ˆ í–¥ìƒ ì„¤ì • ì—…ë°ì´íŠ¸ ì™„ë£Œ")

# ê¸°ë³¸ í’ˆì§ˆ í–¥ìƒ ì‹œìŠ¤í…œ ìƒì„± í•¨ìˆ˜
def create_pose_estimation_quality_enhancement(config: EnhancementConfig = None) -> QualityEnhancement:
    """í¬ì¦ˆ ì¶”ì • í’ˆì§ˆ í–¥ìƒ ì‹œìŠ¤í…œ ìƒì„±"""
    return QualityEnhancement(config)

if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì½”ë“œ
    logging.basicConfig(level=logging.INFO)
    
    # í’ˆì§ˆ í–¥ìƒ ì‹œìŠ¤í…œ ìƒì„±
    enhancer = create_pose_estimation_quality_enhancement()
    
    # í…ŒìŠ¤íŠ¸ ë°ì´í„°
    test_keypoints = np.random.rand(1, 17, 3)  # 1ê°œ ë°°ì¹˜, 17ê°œ í‚¤í¬ì¸íŠ¸, (x, y, conf)
    test_confidences = np.random.rand(1, 17)
    
    # í’ˆì§ˆ í–¥ìƒ ìˆ˜í–‰
    result = enhancer.enhance_pose_quality(test_keypoints, test_confidences)
    
    print(f"í’ˆì§ˆ í–¥ìƒ ê²°ê³¼: {result['quality_score']:.3f}")
    print(f"ì ìš©ëœ í–¥ìƒ ê¸°ë²•: {result['enhancement_applied']}")
