"""
ğŸ”¥ Pose Estimation ì‹œê°í™” ì‹œìŠ¤í…œ
=================================

í¬ì¦ˆ ì¶”ì • ê²°ê³¼ë¥¼ ìœ„í•œ ì™„ì „í•œ ì‹œê°í™” ê¸°ëŠ¥:
1. ì›ë³¸ ì´ë¯¸ì§€ì™€ í¬ì¦ˆ ê²°ê³¼ ë¹„êµ
2. í‚¤í¬ì¸íŠ¸ ë° ìŠ¤ì¼ˆë ˆí†¤ ì‹œê°í™”
3. ì „ì²˜ë¦¬ ê³¼ì • ì‹œê°í™”
4. í¬ì¦ˆ í’ˆì§ˆ ë¶„ì„ ì‹œê°í™”
5. ì¸í„°ë™í‹°ë¸Œ ì‹œê°í™”

Author: MyCloset AI Team
Date: 2025-01-27
Version: 1.0 (ì™„ì „ êµ¬í˜„)
"""

import cv2
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.patches as patches
from matplotlib.colors import ListedColormap
import seaborn as sns
from typing import Dict, Any, Optional, Tuple, List, Union
import logging
from PIL import Image
import torch
import os

logger = logging.getLogger(__name__)

class PoseEstimationVisualizer:
    """í¬ì¦ˆ ì¶”ì • ê²°ê³¼ ì‹œê°í™” ì‹œìŠ¤í…œ"""
    
    def __init__(self, save_dir: str = "./visualization_results"):
        self.save_dir = save_dir
        # ë””ë ‰í† ë¦¬ ìë™ ìƒì„±
        os.makedirs(self.save_dir, exist_ok=True)
        self.logger = logging.getLogger(f"{__name__}.PoseEstimationVisualizer")
        
        # COCO-17 í‚¤í¬ì¸íŠ¸ ì •ì˜
        self.coco_keypoints = {
            0: "nose", 1: "left_eye", 2: "right_eye", 3: "left_ear", 4: "right_ear",
            5: "left_shoulder", 6: "right_shoulder", 7: "left_elbow", 8: "right_elbow",
            9: "left_wrist", 10: "right_wrist", 11: "left_hip", 12: "right_hip",
            13: "left_knee", 14: "right_knee", 15: "left_ankle", 16: "right_ankle"
        }
        
        # ìŠ¤ì¼ˆë ˆí†¤ ì—°ê²° (COCO-17)
        self.skeleton_connections = [
            (0, 1), (0, 2), (1, 3), (2, 4),  # ë¨¸ë¦¬
            (5, 6), (5, 7), (7, 9), (6, 8), (8, 10),  # ìƒì²´
            (5, 11), (6, 12), (11, 12),  # ëª¸í†µ
            (11, 13), (13, 15), (12, 14), (14, 16)  # í•˜ì²´
        ]
        
        # í‚¤í¬ì¸íŠ¸ ìƒ‰ìƒ
        self.keypoint_colors = {
            'head': [255, 0, 0],      # ë¹¨ê°•
            'torso': [0, 255, 0],     # ì´ˆë¡
            'arms': [0, 0, 255],      # íŒŒë‘
            'legs': [255, 255, 0]     # ë…¸ë‘
        }
        
        # ì‹œê°í™” í†µê³„
        self.visualization_stats = {
            'images_visualized': 0,
            'pose_visualized': 0,
            'comparisons_created': 0,
            'quality_analyses': 0
        }
    
    def visualize_preprocessing_pipeline(self, 
                                       original_image: np.ndarray,
                                       preprocessing_result: Dict[str, Any],
                                       save_path: Optional[str] = None) -> str:
        """ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì‹œê°í™”"""
        try:
            self.visualization_stats['images_visualized'] += 1
            self.logger.info("ğŸ”¥ í¬ì¦ˆ ì¶”ì • ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì‹œê°í™” ì‹œì‘")
            
            # ì´ë¯¸ì§€ ì¤€ë¹„
            processed_image = preprocessing_result['processed_image']
            alignment_info = preprocessing_result['alignment_info']
            
            # ì‹œê°í™” ìƒì„±
            fig, axes = plt.subplots(2, 3, figsize=(18, 12))
            fig.suptitle('Pose Estimation Preprocessing Pipeline', fontsize=16, fontweight='bold')
            
            # 1. ì›ë³¸ ì´ë¯¸ì§€
            axes[0, 0].imshow(cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB))
            axes[0, 0].set_title('Original Image', fontweight='bold')
            axes[0, 0].axis('off')
            
            # ì¸ì²´ ê°ì§€ ë°•ìŠ¤ í‘œì‹œ
            if alignment_info['human_detected']:
                bbox = alignment_info['bbox']
                rect = patches.Rectangle(
                    (bbox[0], bbox[1]), bbox[2]-bbox[0], bbox[3]-bbox[1],
                    linewidth=3, edgecolor='red', facecolor='none'
                )
                axes[0, 0].add_patch(rect)
                axes[0, 0].text(bbox[0], bbox[1]-10, f"Human: {alignment_info['confidence']:.2f}", 
                               color='red', fontweight='bold', fontsize=10)
            
            # 2. í¬ë¡­ëœ ì´ë¯¸ì§€
            axes[0, 1].imshow(cv2.cvtColor(processed_image, cv2.COLOR_BGR2RGB))
            axes[0, 1].set_title(f'Pose-Aligned ({alignment_info["aligned_size"][1]}x{alignment_info["aligned_size"][0]})', 
                                fontweight='bold')
            axes[0, 1].axis('off')
            
            # 3. í¬ì¦ˆ ì •ë ¬ ì •ë³´
            info_text = f"""
Pose Alignment Info:
â€¢ Target Size: {preprocessing_result['target_size']}
â€¢ Mode: {preprocessing_result['mode']}
â€¢ Human Detected: {alignment_info['human_detected']}
â€¢ Confidence: {alignment_info['confidence']:.3f}
â€¢ Pose Centered: {alignment_info['pose_centered']}
â€¢ Original Size: {alignment_info['original_size'][1]}x{alignment_info['original_size'][0]}
â€¢ Aligned Size: {alignment_info['aligned_size'][1]}x{alignment_info['aligned_size'][0]}
            """
            axes[0, 2].text(0.1, 0.9, info_text, transform=axes[0, 2].transAxes, 
                           fontsize=9, verticalalignment='top', fontfamily='monospace',
                           bbox=dict(boxstyle="round,pad=0.3", facecolor="lightblue"))
            axes[0, 2].set_title('Alignment Information', fontweight='bold')
            axes[0, 2].axis('off')
            
            # 4. í¬ì¦ˆ íŒŒë¼ë¯¸í„°
            pose_params = preprocessing_result['pose_params']
            params_text = f"""
Pose Parameters:
â€¢ Joint Enhancement: {pose_params['joint_enhancement']}
â€¢ Background Removal: {pose_params['background_removal']}
â€¢ Pose Normalization: {pose_params['pose_normalization']}
â€¢ Lighting Correction: {pose_params['lighting_correction']}
            """
            axes[1, 0].text(0.1, 0.9, params_text, transform=axes[1, 0].transAxes, 
                           fontsize=9, verticalalignment='top', fontfamily='monospace',
                           bbox=dict(boxstyle="round,pad=0.3", facecolor="lightgreen"))
            axes[1, 0].set_title('Pose Parameters', fontweight='bold')
            axes[1, 0].axis('off')
            
            # 5. í’ˆì§ˆ í–¥ìƒ ë¹„êµ
            if preprocessing_result['mode'] == 'advanced':
                # ì›ë³¸ê³¼ í–¥ìƒëœ ì´ë¯¸ì§€ ë¹„êµ
                axes[1, 1].imshow(cv2.cvtColor(processed_image, cv2.COLOR_BGR2RGB))
                axes[1, 1].set_title('Enhanced for Pose Estimation', fontweight='bold')
                axes[1, 1].axis('off')
            else:
                axes[1, 1].text(0.5, 0.5, 'Basic Mode\n(No Enhancement)', 
                               transform=axes[1, 1].transAxes, ha='center', va='center',
                               fontsize=12, fontweight='bold')
                axes[1, 1].axis('off')
            
            # 6. ì²˜ë¦¬ í†µê³„
            stats_text = f"""
Processing Stats:
â€¢ Images Processed: {self.visualization_stats['images_visualized']}
â€¢ Pose Visualized: {self.visualization_stats['pose_visualized']}
â€¢ Comparisons Created: {self.visualization_stats['comparisons_created']}
â€¢ Quality Analyses: {self.visualization_stats['quality_analyses']}
            """
            axes[1, 2].text(0.1, 0.9, stats_text, transform=axes[1, 2].transAxes, 
                           fontsize=9, verticalalignment='top', fontfamily='monospace',
                           bbox=dict(boxstyle="round,pad=0.3", facecolor="lightyellow"))
            axes[1, 2].set_title('Processing Stats', fontweight='bold')
            axes[1, 2].axis('off')
            
            plt.tight_layout()
            
            # ì €ì¥
            if save_path is None:
                save_path = f"{self.save_dir}/pose_preprocessing_pipeline_{self.visualization_stats['images_visualized']:03d}.png"
            
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            plt.close()
            
            self.logger.info(f"âœ… í¬ì¦ˆ ì¶”ì • ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì‹œê°í™” ì™„ë£Œ: {save_path}")
            return save_path
            
        except Exception as e:
            self.logger.error(f"âŒ í¬ì¦ˆ ì¶”ì • ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì‹œê°í™” ì‹¤íŒ¨: {e}")
            return ""
    
    def visualize_pose_result(self, 
                             original_image: np.ndarray,
                             pose_keypoints: Union[np.ndarray, torch.Tensor],
                             confidence_scores: Optional[np.ndarray] = None,
                             save_path: Optional[str] = None) -> str:
        """í¬ì¦ˆ ì¶”ì • ê²°ê³¼ ì‹œê°í™”"""
        try:
            self.visualization_stats['pose_visualized'] += 1
            self.logger.info("ğŸ”¥ í¬ì¦ˆ ì¶”ì • ê²°ê³¼ ì‹œê°í™” ì‹œì‘")
            
            # í…ì„œë¥¼ NumPyë¡œ ë³€í™˜
            if isinstance(pose_keypoints, torch.Tensor):
                pose_keypoints = pose_keypoints.detach().cpu().numpy()
            
            # ë°°ì¹˜ ì°¨ì› ì œê±°
            if len(pose_keypoints.shape) == 3:
                pose_keypoints = pose_keypoints[0]  # [B, N, 2] -> [N, 2]
            
            # ì‹ ë¢°ë„ ì ìˆ˜ ì¤€ë¹„
            if confidence_scores is None:
                confidence_scores = np.ones(pose_keypoints.shape[0])
            elif isinstance(confidence_scores, torch.Tensor):
                confidence_scores = confidence_scores.detach().cpu().numpy()
            
            # ì‹œê°í™” ìƒì„±
            fig, axes = plt.subplots(2, 3, figsize=(18, 12))
            fig.suptitle('Pose Estimation Results', fontsize=16, fontweight='bold')
            
            # 1. ì›ë³¸ ì´ë¯¸ì§€ + í‚¤í¬ì¸íŠ¸
            axes[0, 0].imshow(cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB))
            self._draw_keypoints(axes[0, 0], pose_keypoints, confidence_scores)
            axes[0, 0].set_title('Original + Keypoints', fontweight='bold')
            axes[0, 0].axis('off')
            
            # 2. ìŠ¤ì¼ˆë ˆí†¤ ì‹œê°í™”
            axes[0, 1].imshow(cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB))
            self._draw_skeleton(axes[0, 1], pose_keypoints, confidence_scores)
            axes[0, 1].set_title('Skeleton Visualization', fontweight='bold')
            axes[0, 1].axis('off')
            
            # 3. ì‹ ë¢°ë„ íˆíŠ¸ë§µ
            confidence_map = self._create_confidence_heatmap(pose_keypoints, confidence_scores, original_image.shape[:2])
            axes[0, 2].imshow(confidence_map, cmap='hot', alpha=0.7)
            axes[0, 2].set_title('Confidence Heatmap', fontweight='bold')
            axes[0, 2].axis('off')
            
            # 4. í‚¤í¬ì¸íŠ¸ë³„ ì‹ ë¢°ë„
            valid_keypoints = confidence_scores > 0.1
            if np.any(valid_keypoints):
                valid_indices = np.where(valid_keypoints)[0]
                valid_confidences = confidence_scores[valid_keypoints]
                valid_names = [self.coco_keypoints.get(i, f"KP_{i}") for i in valid_indices]
                
                axes[1, 0].bar(range(len(valid_confidences)), valid_confidences)
                axes[1, 0].set_title('Keypoint Confidence Scores', fontweight='bold')
                axes[1, 0].set_xlabel('Keypoint')
                axes[1, 0].set_ylabel('Confidence')
                axes[1, 0].set_xticks(range(len(valid_names)))
                axes[1, 0].set_xticklabels(valid_names, rotation=45, ha='right')
                axes[1, 0].set_ylim(0, 1)
            else:
                axes[1, 0].text(0.5, 0.5, 'No valid keypoints detected', 
                               transform=axes[1, 0].transAxes, ha='center', va='center',
                               fontsize=12, fontweight='bold')
                axes[1, 0].set_title('Keypoint Confidence Scores', fontweight='bold')
                axes[1, 0].axis('off')
            
            # 5. í¬ì¦ˆ í’ˆì§ˆ ë¶„ì„
            quality_metrics = self._calculate_pose_quality(pose_keypoints, confidence_scores)
            quality_text = f"""
Pose Quality Metrics:
â€¢ Overall Score: {quality_metrics['overall_score']:.3f}
â€¢ Symmetry Score: {quality_metrics['symmetry_score']:.3f}
â€¢ Confidence Score: {quality_metrics['confidence_score']:.3f}
â€¢ Coverage Score: {quality_metrics['coverage_score']:.3f}
â€¢ Valid Keypoints: {quality_metrics['valid_keypoints']}/{len(pose_keypoints)}
            """
            axes[1, 1].text(0.1, 0.9, quality_text, transform=axes[1, 1].transAxes, 
                           fontsize=9, verticalalignment='top', fontfamily='monospace',
                           bbox=dict(boxstyle="round,pad=0.3", facecolor="lightgreen"))
            axes[1, 1].set_title('Pose Quality Analysis', fontweight='bold')
            axes[1, 1].axis('off')
            
            # 6. í¬ì¦ˆ ë¶„ë¥˜
            pose_category = self._classify_pose(pose_keypoints, confidence_scores)
            category_text = f"""
Pose Classification:
â€¢ Category: {pose_category['category']}
â€¢ Confidence: {pose_category['confidence']:.3f}
â€¢ Description: {pose_category['description']}
â€¢ Key Features: {', '.join(pose_category['key_features'])}
            """
            axes[1, 2].text(0.1, 0.9, category_text, transform=axes[1, 2].transAxes, 
                           fontsize=9, verticalalignment='top', fontfamily='monospace',
                           bbox=dict(boxstyle="round,pad=0.3", facecolor="lightblue"))
            axes[1, 2].set_title('Pose Classification', fontweight='bold')
            axes[1, 2].axis('off')
            
            plt.tight_layout()
            
            # ì €ì¥
            if save_path is None:
                save_path = f"{self.save_dir}/pose_result_{self.visualization_stats['pose_visualized']:03d}.png"
            
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            plt.close()
            
            self.logger.info(f"âœ… í¬ì¦ˆ ì¶”ì • ê²°ê³¼ ì‹œê°í™” ì™„ë£Œ: {save_path}")
            return save_path
            
        except Exception as e:
            self.logger.error(f"âŒ í¬ì¦ˆ ì¶”ì • ê²°ê³¼ ì‹œê°í™” ì‹¤íŒ¨: {e}")
            return ""
    
    def _draw_keypoints(self, ax, keypoints: np.ndarray, confidence_scores: np.ndarray):
        """í‚¤í¬ì¸íŠ¸ ê·¸ë¦¬ê¸°"""
        try:
            for i, (kp, conf) in enumerate(zip(keypoints, confidence_scores)):
                if conf > 0.1:  # ì‹ ë¢°ë„ ì„ê³„ê°’
                    x, y = kp[0], kp[1]
                    
                    # í‚¤í¬ì¸íŠ¸ íƒ€ì…ì— ë”°ë¥¸ ìƒ‰ìƒ ì„ íƒ
                    if i in [0, 1, 2, 3, 4]:  # ë¨¸ë¦¬
                        color = self.keypoint_colors['head']
                    elif i in [5, 6, 11, 12]:  # ëª¸í†µ
                        color = self.keypoint_colors['torso']
                    elif i in [7, 8, 9, 10]:  # íŒ”
                        color = self.keypoint_colors['arms']
                    else:  # ë‹¤ë¦¬
                        color = self.keypoint_colors['legs']
                    
                    # í‚¤í¬ì¸íŠ¸ ê·¸ë¦¬ê¸°
                    ax.scatter(x, y, c=[np.array(color)/255], s=100, alpha=0.8, edgecolors='white', linewidth=2)
                    
                    # í‚¤í¬ì¸íŠ¸ ë²ˆí˜¸ í‘œì‹œ
                    ax.text(x+5, y+5, str(i), fontsize=8, fontweight='bold', 
                           color='white', bbox=dict(boxstyle="round,pad=0.2", facecolor="black", alpha=0.7))
                    
        except Exception as e:
            self.logger.warning(f"í‚¤í¬ì¸íŠ¸ ê·¸ë¦¬ê¸° ì‹¤íŒ¨: {e}")
    
    def _draw_skeleton(self, ax, keypoints: np.ndarray, confidence_scores: np.ndarray):
        """ìŠ¤ì¼ˆë ˆí†¤ ê·¸ë¦¬ê¸°"""
        try:
            for connection in self.skeleton_connections:
                start_idx, end_idx = connection
                
                # ë‘ í‚¤í¬ì¸íŠ¸ ëª¨ë‘ ìœ íš¨í•œ ê²½ìš°ì—ë§Œ ì—°ê²°
                if (confidence_scores[start_idx] > 0.1 and 
                    confidence_scores[end_idx] > 0.1):
                    
                    start_kp = keypoints[start_idx]
                    end_kp = keypoints[end_idx]
                    
                    # ì—°ê²°ì„  ê·¸ë¦¬ê¸°
                    ax.plot([start_kp[0], end_kp[0]], [start_kp[1], end_kp[1]], 
                           color='red', linewidth=2, alpha=0.8)
                    
        except Exception as e:
            self.logger.warning(f"ìŠ¤ì¼ˆë ˆí†¤ ê·¸ë¦¬ê¸° ì‹¤íŒ¨: {e}")
    
    def _create_confidence_heatmap(self, keypoints: np.ndarray, confidence_scores: np.ndarray, 
                                  image_shape: Tuple[int, int]) -> np.ndarray:
        """ì‹ ë¢°ë„ íˆíŠ¸ë§µ ìƒì„±"""
        try:
            heatmap = np.zeros(image_shape[:2], dtype=np.float32)
            
            for kp, conf in zip(keypoints, confidence_scores):
                if conf > 0.1:
                    x, y = int(kp[0]), int(kp[1])
                    if 0 <= x < image_shape[1] and 0 <= y < image_shape[0]:
                        # ê°€ìš°ì‹œì•ˆ ì»¤ë„ë¡œ ì‹ ë¢°ë„ ë¶„ì‚°
                        y_coords, x_coords = np.ogrid[:image_shape[0], :image_shape[1]]
                        dist_sq = (x_coords - x)**2 + (y_coords - y)**2
                        gaussian = np.exp(-dist_sq / (2 * 20**2))  # í‘œì¤€í¸ì°¨ 20
                        heatmap += gaussian * conf
            
            return heatmap
            
        except Exception as e:
            self.logger.warning(f"ì‹ ë¢°ë„ íˆíŠ¸ë§µ ìƒì„± ì‹¤íŒ¨: {e}")
            return np.zeros(image_shape[:2], dtype=np.float32)
    
    def _calculate_pose_quality(self, keypoints: np.ndarray, confidence_scores: np.ndarray) -> Dict[str, float]:
        """í¬ì¦ˆ í’ˆì§ˆ ê³„ì‚°"""
        try:
            # ìœ íš¨í•œ í‚¤í¬ì¸íŠ¸ ìˆ˜
            valid_mask = confidence_scores > 0.1
            valid_count = np.sum(valid_mask)
            
            # ì „ì²´ ì‹ ë¢°ë„ ì ìˆ˜
            confidence_score = np.mean(confidence_scores[valid_mask]) if valid_count > 0 else 0.0
            
            # ëŒ€ì¹­ì„± ì ìˆ˜ (ì¢Œìš° ëŒ€ì¹­ í‚¤í¬ì¸íŠ¸ ë¹„êµ)
            symmetry_pairs = [(1, 2), (3, 4), (5, 6), (7, 8), (9, 10), (11, 12), (13, 14), (15, 16)]
            symmetry_score = 0.0
            valid_pairs = 0
            
            for left, right in symmetry_pairs:
                if (left < len(keypoints) and right < len(keypoints) and
                    confidence_scores[left] > 0.1 and confidence_scores[right] > 0.1):
                    
                    # Yì¶• ê¸°ì¤€ ëŒ€ì¹­ì„± ê³„ì‚°
                    left_y = keypoints[left][1]
                    right_y = keypoints[right][1]
                    y_diff = abs(left_y - right_y)
                    
                    # ëŒ€ì¹­ì„± ì ìˆ˜ (ì°¨ì´ê°€ ì‘ì„ìˆ˜ë¡ ë†’ì€ ì ìˆ˜)
                    pair_score = max(0, 1 - y_diff / 50)  # 50í”½ì…€ ì°¨ì´ë¥¼ 0ì ìœ¼ë¡œ
                    symmetry_score += pair_score
                    valid_pairs += 1
            
            symmetry_score = symmetry_score / valid_pairs if valid_pairs > 0 else 0.0
            
            # ì»¤ë²„ë¦¬ì§€ ì ìˆ˜ (í‚¤í¬ì¸íŠ¸ê°€ ì´ë¯¸ì§€ ì „ì²´ì— ë¶„ì‚°ë˜ì–´ ìˆëŠ”ì§€)
            if valid_count > 0:
                valid_keypoints = keypoints[valid_mask]
                x_range = np.max(valid_keypoints[:, 0]) - np.min(valid_keypoints[:, 0])
                y_range = np.max(valid_keypoints[:, 1]) - np.min(valid_keypoints[:, 1])
                
                # ì´ë¯¸ì§€ í¬ê¸° ëŒ€ë¹„ í‚¤í¬ì¸íŠ¸ ë¶„ì‚°ë„
                coverage_score = min(1.0, (x_range + y_range) / 200)  # 200í”½ì…€ì„ ìµœëŒ€ê°’ìœ¼ë¡œ
            else:
                coverage_score = 0.0
            
            # ì „ì²´ ì ìˆ˜ (ê°€ì¤‘ í‰ê· )
            overall_score = (confidence_score * 0.4 + 
                           symmetry_score * 0.3 + 
                           coverage_score * 0.3)
            
            return {
                'overall_score': overall_score,
                'symmetry_score': symmetry_score,
                'confidence_score': confidence_score,
                'coverage_score': coverage_score,
                'valid_keypoints': valid_count
            }
            
        except Exception as e:
            self.logger.warning(f"í¬ì¦ˆ í’ˆì§ˆ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return {
                'overall_score': 0.0,
                'symmetry_score': 0.0,
                'confidence_score': 0.0,
                'coverage_score': 0.0,
                'valid_keypoints': 0
            }
    
    def _classify_pose(self, keypoints: np.ndarray, confidence_scores: np.ndarray) -> Dict[str, Any]:
        """í¬ì¦ˆ ë¶„ë¥˜"""
        try:
            valid_mask = confidence_scores > 0.1
            valid_count = np.sum(valid_mask)
            
            if valid_count < 5:
                return {
                    'category': 'Insufficient',
                    'confidence': 0.0,
                    'description': 'Too few keypoints detected',
                    'key_features': ['Low detection count']
                }
            
            # ì£¼ìš” í‚¤í¬ì¸íŠ¸ ì¶”ì¶œ
            if valid_mask[5] and valid_mask[6]:  # ì–´ê¹¨
                shoulder_width = abs(keypoints[5][0] - keypoints[6][0])
            else:
                shoulder_width = 0
            
            if valid_mask[11] and valid_mask[12]:  # ì—‰ë©ì´
                hip_width = abs(keypoints[11][0] - keypoints[12][0])
            else:
                hip_width = 0
            
            if valid_mask[13] and valid_mask[14]:  # ë¬´ë¦
                knee_width = abs(keypoints[13][0] - keypoints[14][0])
            else:
                knee_width = 0
            
            # í¬ì¦ˆ ë¶„ë¥˜
            if shoulder_width > 0 and hip_width > 0:
                if shoulder_width > hip_width * 1.2:
                    category = 'Standing'
                    description = 'Person standing with arms extended'
                    key_features = ['Extended arms', 'Upright posture']
                elif hip_width > shoulder_width * 1.2:
                    category = 'Sitting'
                    description = 'Person sitting or crouching'
                    key_features = ['Lower body spread', 'Compressed upper body']
                else:
                    category = 'Neutral'
                    description = 'Person in neutral standing position'
                    key_features = ['Balanced proportions', 'Natural stance']
            else:
                category = 'Partial'
                description = 'Partial pose detection'
                key_features = ['Limited keypoints', 'Incomplete detection']
            
            # ë¶„ë¥˜ ì‹ ë¢°ë„
            classification_confidence = min(1.0, valid_count / 17)  # 17ê°œ í‚¤í¬ì¸íŠ¸ ê¸°ì¤€
            
            return {
                'category': category,
                'confidence': classification_confidence,
                'description': description,
                'key_features': key_features
            }
            
        except Exception as e:
            self.logger.warning(f"í¬ì¦ˆ ë¶„ë¥˜ ì‹¤íŒ¨: {e}")
            return {
                'category': 'Unknown',
                'confidence': 0.0,
                'description': 'Classification failed',
                'key_features': ['Error in classification']
            }
    
    def create_comparison_visualization(self, 
                                      original_image: np.ndarray,
                                      preprocessing_result: Dict[str, Any],
                                      pose_result: Dict[str, Any],
                                      save_path: Optional[str] = None) -> str:
        """ì „ì²´ íŒŒì´í”„ë¼ì¸ ë¹„êµ ì‹œê°í™”"""
        try:
            self.visualization_stats['comparisons_created'] += 1
            self.logger.info("ğŸ”¥ ì „ì²´ í¬ì¦ˆ ì¶”ì • íŒŒì´í”„ë¼ì¸ ë¹„êµ ì‹œê°í™” ì‹œì‘")
            
            # ì‹œê°í™” ìƒì„±
            fig, axes = plt.subplots(2, 4, figsize=(20, 10))
            fig.suptitle('Complete Pose Estimation Pipeline', fontsize=18, fontweight='bold')
            
            # 1. ì›ë³¸ ì´ë¯¸ì§€
            axes[0, 0].imshow(cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB))
            axes[0, 0].set_title('Original', fontweight='bold')
            axes[0, 0].axis('off')
            
            # 2. ì „ì²˜ë¦¬ëœ ì´ë¯¸ì§€
            processed_img = preprocessing_result['processed_image']
            axes[0, 1].imshow(cv2.cvtColor(processed_img, cv2.COLOR_BGR2RGB))
            axes[0, 1].set_title('Preprocessed', fontweight='bold')
            axes[0, 1].axis('off')
            
            # 3. í¬ì¦ˆ ê²°ê³¼
            if 'keypoints' in pose_result:
                axes[0, 2].imshow(cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB))
                self._draw_keypoints(axes[0, 2], pose_result['keypoints'], pose_result.get('confidence_scores', np.ones(17)))
                axes[0, 2].set_title('Pose Detection', fontweight='bold')
                axes[0, 2].axis('off')
            
            # 4. ìµœì¢… ê²°ê³¼ (ìŠ¤ì¼ˆë ˆí†¤)
            if 'keypoints' in pose_result:
                axes[0, 3].imshow(cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB))
                self._draw_skeleton(axes[0, 3], pose_result['keypoints'], pose_result.get('confidence_scores', np.ones(17)))
                axes[0, 3].set_title('Final Skeleton', fontweight='bold')
                axes[0, 3].axis('off')
            
            # 5. ì „ì²˜ë¦¬ ì •ë³´
            info_text = f"""
Preprocessing Info:
â€¢ Target Size: {preprocessing_result['target_size']}
â€¢ Mode: {preprocessing_result['mode']}
â€¢ Human Detected: {preprocessing_result['alignment_info']['human_detected']}
â€¢ Pose Centered: {preprocessing_result['alignment_info']['pose_centered']}
            """
            axes[1, 0].text(0.1, 0.9, info_text, transform=axes[1, 0].transAxes, 
                           fontsize=9, verticalalignment='top', fontfamily='monospace',
                           bbox=dict(boxstyle="round,pad=0.3", facecolor="lightblue"))
            axes[1, 0].set_title('Preprocessing Info', fontweight='bold')
            axes[1, 0].axis('off')
            
            # 6. í¬ì¦ˆ í’ˆì§ˆ
            if 'keypoints' in pose_result:
                quality_metrics = self._calculate_pose_quality(
                    pose_result['keypoints'], 
                    pose_result.get('confidence_scores', np.ones(17))
                )
                quality_text = f"""
Pose Quality:
â€¢ Overall Score: {quality_metrics['overall_score']:.3f}
â€¢ Symmetry: {quality_metrics['symmetry_score']:.3f}
â€¢ Confidence: {quality_metrics['confidence_score']:.3f}
â€¢ Coverage: {quality_metrics['coverage_score']:.3f}
                """
            else:
                quality_text = "Pose data not available"
            
            axes[1, 1].text(0.1, 0.9, quality_text, transform=axes[1, 1].transAxes, 
                           fontsize=9, verticalalignment='top', fontfamily='monospace',
                           bbox=dict(boxstyle="round,pad=0.3", facecolor="lightgreen"))
            axes[1, 1].set_title('Pose Quality', fontweight='bold')
            axes[1, 1].axis('off')
            
            # 7. í¬ì¦ˆ ë¶„ë¥˜
            if 'keypoints' in pose_result:
                pose_category = self._classify_pose(
                    pose_result['keypoints'], 
                    pose_result.get('confidence_scores', np.ones(17))
                )
                category_text = f"""
Pose Classification:
â€¢ Category: {pose_category['category']}
â€¢ Confidence: {pose_category['confidence']:.3f}
â€¢ Description: {pose_category['description']}
                """
            else:
                category_text = "Pose data not available"
            
            axes[1, 2].text(0.1, 0.9, category_text, transform=axes[1, 2].transAxes, 
                           fontsize=9, verticalalignment='top', fontfamily='monospace',
                           bbox=dict(boxstyle="round,pad=0.3", facecolor="lightyellow"))
            axes[1, 2].set_title('Pose Classification', fontweight='bold')
            axes[1, 2].axis('off')
            
            # 8. ì²˜ë¦¬ í†µê³„
            stats_text = f"""
Processing Stats:
â€¢ Images Processed: {self.visualization_stats['images_visualized']}
â€¢ Pose Visualized: {self.visualization_stats['pose_visualized']}
â€¢ Comparisons Created: {self.visualization_stats['comparisons_created']}
â€¢ Quality Analyses: {self.visualization_stats['quality_analyses']}
            """
            axes[1, 3].text(0.1, 0.9, stats_text, transform=axes[1, 3].transAxes, 
                           fontsize=9, verticalalignment='top', fontfamily='monospace',
                           bbox=dict(boxstyle="round,pad=0.3", facecolor="lightcoral"))
            axes[1, 3].set_title('Processing Stats', fontweight='bold')
            axes[1, 3].axis('off')
            
            plt.tight_layout()
            
            # ì €ì¥
            if save_path is None:
                save_path = f"{self.save_dir}/complete_pose_pipeline_{self.visualization_stats['comparisons_created']:03d}.png"
            
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            plt.close()
            
            self.logger.info(f"âœ… ì „ì²´ í¬ì¦ˆ ì¶”ì • íŒŒì´í”„ë¼ì¸ ë¹„êµ ì‹œê°í™” ì™„ë£Œ: {save_path}")
            return save_path
            
        except Exception as e:
            self.logger.error(f"âŒ ì „ì²´ í¬ì¦ˆ ì¶”ì • íŒŒì´í”„ë¼ì¸ ë¹„êµ ì‹œê°í™” ì‹¤íŒ¨: {e}")
            return ""
    
    def get_visualization_stats(self) -> Dict[str, Any]:
        """ì‹œê°í™” í†µê³„ ë°˜í™˜"""
        return self.visualization_stats.copy()
    
    def reset_stats(self):
        """í†µê³„ ì´ˆê¸°í™”"""
        self.visualization_stats = {
            'images_visualized': 0,
            'pose_visualized': 0,
            'comparisons_created': 0,
            'quality_analyses': 0
        }
