"""
ğŸ”¥ ì•™ìƒë¸” í”„ë¡œì„¸ì„œ
==================

í›„ì²˜ë¦¬ë¥¼ ìœ„í•œ ì•™ìƒë¸” ì‹œìŠ¤í…œ:
1. ë‹¤ì¤‘ ë©”íŠ¸ë¦­ í†µí•©
2. í’ˆì§ˆ ì ìˆ˜ ì•™ìƒë¸”
3. ì‹ ë¢°ë„ ê¸°ë°˜ ê°€ì¤‘ì¹˜
4. ì•™ìƒë¸” ìµœì í™”

Author: MyCloset AI Team
Date: 2025-08-14
Version: 1.0
"""

import logging
import numpy as np
from typing import Dict, Any, Optional, List, Tuple
from abc import ABC, abstractmethod

logger = logging.getLogger(__name__)

class EnsembleMethod(ABC):
    """ì•™ìƒë¸” ë°©ë²• ê¸°ë³¸ í´ë˜ìŠ¤"""
    
    def __init__(self, name: str):
        self.name = name
        self.logger = logging.getLogger(f"{__name__}.{self.__class__.__name__}")
    
    @abstractmethod
    def combine(self, metrics: Dict[str, float], weights: Optional[Dict[str, float]] = None) -> float:
        """ë©”íŠ¸ë¦­ ê²°í•©"""
        pass
    
    def get_method_info(self) -> Dict[str, Any]:
        """ë©”ì„œë“œ ì •ë³´ ë°˜í™˜"""
        return {
            'name': self.name,
            'description': self.__doc__ or f"{self.name} ì•™ìƒë¸” ë°©ë²•",
            'type': self.__class__.__name__
        }

class SimpleAverageEnsemble(EnsembleMethod):
    """ë‹¨ìˆœ í‰ê·  ì•™ìƒë¸”"""
    
    def __init__(self):
        super().__init__("SimpleAverage")
    
    def combine(self, metrics: Dict[str, float], weights: Optional[Dict[str, float]] = None) -> float:
        """ë‹¨ìˆœ í‰ê· ìœ¼ë¡œ ë©”íŠ¸ë¦­ ê²°í•©"""
        try:
            if not metrics:
                return 0.0
            
            values = list(metrics.values())
            return float(np.mean(values))
            
        except Exception as e:
            self.logger.error(f"âŒ ë‹¨ìˆœ í‰ê·  ì•™ìƒë¸” ì‹¤íŒ¨: {e}")
            return 0.0

class WeightedAverageEnsemble(EnsembleMethod):
    """ê°€ì¤‘ í‰ê·  ì•™ìƒë¸”"""
    
    def __init__(self):
        super().__init__("WeightedAverage")
    
    def combine(self, metrics: Dict[str, float], weights: Optional[Dict[str, float]] = None) -> float:
        """ê°€ì¤‘ í‰ê· ìœ¼ë¡œ ë©”íŠ¸ë¦­ ê²°í•©"""
        try:
            if not metrics:
                return 0.0
            
            if weights is None:
                # ê· ë“± ê°€ì¤‘ì¹˜
                weights = {key: 1.0 for key in metrics.keys()}
            
            # ê°€ì¤‘ì¹˜ ì •ê·œí™”
            total_weight = sum(weights.values())
            if total_weight == 0:
                return 0.0
            
            normalized_weights = {key: weight / total_weight for key, weight in weights.items()}
            
            # ê°€ì¤‘ í‰ê·  ê³„ì‚°
            weighted_sum = sum(metrics[key] * normalized_weights[key] for key in metrics.keys())
            
            return float(weighted_sum)
            
        except Exception as e:
            self.logger.error(f"âŒ ê°€ì¤‘ í‰ê·  ì•™ìƒë¸” ì‹¤íŒ¨: {e}")
            return 0.0

class QualityBasedEnsemble(EnsembleMethod):
    """í’ˆì§ˆ ê¸°ë°˜ ì•™ìƒë¸”"""
    
    def __init__(self):
        super().__init__("QualityBased")
    
    def combine(self, metrics: Dict[str, float], weights: Optional[Dict[str, float]] = None) -> float:
        """í’ˆì§ˆ ê¸°ë°˜ìœ¼ë¡œ ë©”íŠ¸ë¦­ ê²°í•©"""
        try:
            if not metrics:
                return 0.0
            
            # ê° ë©”íŠ¸ë¦­ì˜ í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°
            quality_scores = {}
            
            for metric_name, value in metrics.items():
                quality_score = self._calculate_quality_score(metric_name, value)
                quality_scores[metric_name] = quality_score
            
            # í’ˆì§ˆ ì ìˆ˜ë¥¼ ê°€ì¤‘ì¹˜ë¡œ ì‚¬ìš©
            total_quality = sum(quality_scores.values())
            if total_quality == 0:
                return 0.0
            
            normalized_weights = {key: score / total_quality for key, score in quality_scores.items()}
            
            # í’ˆì§ˆ ê¸°ë°˜ ê°€ì¤‘ í‰ê·  ê³„ì‚°
            weighted_sum = sum(metrics[key] * normalized_weights[key] for key in metrics.keys())
            
            return float(weighted_sum)
            
        except Exception as e:
            self.logger.error(f"âŒ í’ˆì§ˆ ê¸°ë°˜ ì•™ìƒë¸” ì‹¤íŒ¨: {e}")
            return 0.0
    
    def _calculate_quality_score(self, metric_name: str, value: float) -> float:
        """ë©”íŠ¸ë¦­ë³„ í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°"""
        try:
            if metric_name == 'psnr':
                # PSNR: ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ (20dB ì´ìƒì´ ì¢‹ìŒ)
                return max(0.0, min(1.0, value / 40.0))
            elif metric_name == 'ssim':
                # SSIM: 0~1 ë²”ìœ„, ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ
                return max(0.0, min(1.0, value))
            elif metric_name == 'contrast':
                # ëŒ€ë¹„: 1.0 ê·¼ì²˜ê°€ ì¢‹ìŒ
                if value < 0.5 or value > 2.0:
                    return 0.0
                elif value < 0.8 or value > 1.5:
                    return 0.5
                else:
                    return 1.0
            elif metric_name == 'sharpness':
                # ì„ ëª…ë„: 1.0 ê·¼ì²˜ê°€ ì¢‹ìŒ
                if value < 0.5 or value > 2.0:
                    return 0.0
                elif value < 0.8 or value > 1.5:
                    return 0.5
                else:
                    return 1.0
            elif metric_name == 'color_balance':
                # ìƒ‰ìƒ ê· í˜•: 1.0 ê·¼ì²˜ê°€ ì¢‹ìŒ
                if value < 0.8 or value > 1.3:
                    return 0.0
                elif value < 0.9 or value > 1.2:
                    return 0.5
                else:
                    return 1.0
            else:
                # ì•Œ ìˆ˜ ì—†ëŠ” ë©”íŠ¸ë¦­ì€ ê¸°ë³¸ê°’
                return 0.5
                
        except Exception as e:
            self.logger.error(f"âŒ í’ˆì§ˆ ì ìˆ˜ ê³„ì‚° ì‹¤íŒ¨: {metric_name} - {e}")
            return 0.5

class ConfidenceBasedEnsemble(EnsembleMethod):
    """ì‹ ë¢°ë„ ê¸°ë°˜ ì•™ìƒë¸”"""
    
    def __init__(self):
        super().__init__("ConfidenceBased")
    
    def combine(self, metrics: Dict[str, float], weights: Optional[Dict[str, float]] = None) -> float:
        """ì‹ ë¢°ë„ ê¸°ë°˜ìœ¼ë¡œ ë©”íŠ¸ë¦­ ê²°í•©"""
        try:
            if not metrics:
                return 0.0
            
            # ê° ë©”íŠ¸ë¦­ì˜ ì‹ ë¢°ë„ ê³„ì‚°
            confidence_scores = {}
            
            for metric_name, value in metrics.items():
                confidence = self._calculate_confidence(metric_name, value)
                confidence_scores[metric_name] = confidence
            
            # ì‹ ë¢°ë„ë¥¼ ê°€ì¤‘ì¹˜ë¡œ ì‚¬ìš©
            total_confidence = sum(confidence_scores.values())
            if total_confidence == 0:
                return 0.0
            
            normalized_weights = {key: confidence / total_confidence for key, confidence in confidence_scores.items()}
            
            # ì‹ ë¢°ë„ ê¸°ë°˜ ê°€ì¤‘ í‰ê·  ê³„ì‚°
            weighted_sum = sum(metrics[key] * normalized_weights[key] for key in metrics.keys())
            
            return float(weighted_sum)
            
        except Exception as e:
            self.logger.error(f"âŒ ì‹ ë¢°ë„ ê¸°ë°˜ ì•™ìƒë¸” ì‹¤íŒ¨: {e}")
            return 0.0
    
    def _calculate_confidence(self, metric_name: str, value: float) -> float:
        """ë©”íŠ¸ë¦­ë³„ ì‹ ë¢°ë„ ê³„ì‚°"""
        try:
            if metric_name == 'psnr':
                # PSNR: 30dB ì´ìƒì´ ë†’ì€ ì‹ ë¢°ë„
                if value >= 30:
                    return 1.0
                elif value >= 25:
                    return 0.8
                elif value >= 20:
                    return 0.6
                else:
                    return 0.3
            elif metric_name == 'ssim':
                # SSIM: 0.9 ì´ìƒì´ ë†’ì€ ì‹ ë¢°ë„
                if value >= 0.9:
                    return 1.0
                elif value >= 0.8:
                    return 0.8
                elif value >= 0.7:
                    return 0.6
                else:
                    return 0.3
            elif metric_name in ['contrast', 'sharpness', 'color_balance']:
                # ê°œì„ ë„ ë©”íŠ¸ë¦­: 1.0 ê·¼ì²˜ê°€ ë†’ì€ ì‹ ë¢°ë„
                if 0.9 <= value <= 1.1:
                    return 1.0
                elif 0.8 <= value <= 1.2:
                    return 0.8
                elif 0.7 <= value <= 1.3:
                    return 0.6
                else:
                    return 0.3
            else:
                # ì•Œ ìˆ˜ ì—†ëŠ” ë©”íŠ¸ë¦­ì€ ê¸°ë³¸ ì‹ ë¢°ë„
                return 0.5
                
        except Exception as e:
            self.logger.error(f"âŒ ì‹ ë¢°ë„ ê³„ì‚° ì‹¤íŒ¨: {metric_name} - {e}")
            return 0.5

class EnsembleProcessor:
    """ì•™ìƒë¸” í”„ë¡œì„¸ì„œ"""
    
    def __init__(self):
        self.logger = logging.getLogger(f"{__name__}.EnsembleProcessor")
        
        # ì‚¬ìš© ê°€ëŠ¥í•œ ì•™ìƒë¸” ë°©ë²•ë“¤
        self.ensemble_methods = {
            'simple_average': SimpleAverageEnsemble(),
            'weighted_average': WeightedAverageEnsemble(),
            'quality_based': QualityBasedEnsemble(),
            'confidence_based': ConfidenceBasedEnsemble()
        }
        
        # ì•™ìƒë¸” í†µê³„
        self.ensemble_stats = {
            'total_ensembles': 0,
            'successful_ensembles': 0,
            'failed_ensembles': 0,
            'method_usage': {}
        }
    
    def get_available_methods(self) -> List[str]:
        """ì‚¬ìš© ê°€ëŠ¥í•œ ì•™ìƒë¸” ë°©ë²• ëª©ë¡ ë°˜í™˜"""
        return list(self.ensemble_methods.keys())
    
    def get_method_info(self, method_name: str) -> Optional[Dict[str, Any]]:
        """ì•™ìƒë¸” ë°©ë²• ì •ë³´ ë°˜í™˜"""
        try:
            if method_name not in self.ensemble_methods:
                return None
            
            return self.ensemble_methods[method_name].get_method_info()
            
        except Exception as e:
            self.logger.error(f"âŒ ì•™ìƒë¸” ë°©ë²• ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {method_name} - {e}")
            return None
    
    def combine_metrics(self, 
                       metrics: Dict[str, float],
                       method: str = 'quality_based',
                       weights: Optional[Dict[str, float]] = None) -> Optional[float]:
        """ë©”íŠ¸ë¦­ ì•™ìƒë¸” ê²°í•©"""
        try:
            if method not in self.ensemble_methods:
                self.logger.error(f"âŒ ì•Œ ìˆ˜ ì—†ëŠ” ì•™ìƒë¸” ë°©ë²•: {method}")
                return None
            
            self.logger.info(f"ğŸš€ {method} ì•™ìƒë¸” ì‹œì‘")
            
            # ì•™ìƒë¸” ì‹¤í–‰
            ensemble_method = self.ensemble_methods[method]
            result = ensemble_method.combine(metrics, weights)
            
            # í†µê³„ ì—…ë°ì´íŠ¸
            self._update_ensemble_stats(method, True)
            
            self.logger.info(f"âœ… {method} ì•™ìƒë¸” ì™„ë£Œ: {result:.4f}")
            return result
            
        except Exception as e:
            self.logger.error(f"âŒ {method} ì•™ìƒë¸” ì‹¤íŒ¨: {e}")
            self._update_ensemble_stats(method, False)
            return None
    
    def combine_with_multiple_methods(self, 
                                    metrics: Dict[str, float],
                                    methods: List[str] = None,
                                    weights: Optional[Dict[str, float]] = None) -> Dict[str, float]:
        """ì—¬ëŸ¬ ë°©ë²•ìœ¼ë¡œ ë©”íŠ¸ë¦­ ê²°í•©"""
        try:
            if methods is None:
                methods = list(self.ensemble_methods.keys())
            
            self.logger.info(f"ğŸš€ ë‹¤ì¤‘ ë°©ë²• ì•™ìƒë¸” ì‹œì‘: {methods}")
            
            results = {}
            
            for method in methods:
                if method in self.ensemble_methods:
                    result = self.combine_metrics(metrics, method, weights)
                    if result is not None:
                        results[method] = result
            
            # ìµœì¢… í†µí•© ê²°ê³¼ (í’ˆì§ˆ ê¸°ë°˜ ë°©ë²• ì‚¬ìš©)
            if results:
                final_result = self.combine_metrics(results, 'quality_based')
                results['final_ensemble'] = final_result
            
            self.logger.info(f"âœ… ë‹¤ì¤‘ ë°©ë²• ì•™ìƒë¸” ì™„ë£Œ: {len(results)}ê°œ ë°©ë²•")
            return results
            
        except Exception as e:
            self.logger.error(f"âŒ ë‹¤ì¤‘ ë°©ë²• ì•™ìƒë¸” ì‹¤íŒ¨: {e}")
            return {}
    
    def optimize_weights(self, 
                        metrics: Dict[str, float],
                        target_score: float = 1.0,
                        method: str = 'weighted_average') -> Dict[str, float]:
        """ê°€ì¤‘ì¹˜ ìµœì í™”"""
        try:
            self.logger.info(f"ğŸš€ ê°€ì¤‘ì¹˜ ìµœì í™” ì‹œì‘: {method}")
            
            if method != 'weighted_average':
                self.logger.warning(f"âš ï¸ ê°€ì¤‘ì¹˜ ìµœì í™”ëŠ” weighted_average ë°©ë²•ì—ì„œë§Œ ì§€ì›ë©ë‹ˆë‹¤.")
                return None
            
            # ê°„ë‹¨í•œ ê°€ì¤‘ì¹˜ ìµœì í™” (ê·¸ë¦¬ë“œ ì„œì¹˜)
            best_weights = None
            best_score = float('inf')
            
            # ê°€ì¤‘ì¹˜ ë²”ìœ„ ì„¤ì • (0.1 ~ 2.0)
            weight_range = np.arange(0.1, 2.1, 0.1)
            
            for w1 in weight_range:
                for w2 in weight_range:
                    for w3 in weight_range:
                        for w4 in weight_range:
                            for w5 in weight_range:
                                # ê°€ì¤‘ì¹˜ ì •ê·œí™”
                                weights = {
                                    'psnr': w1, 'ssim': w2, 'contrast': w3,
                                    'sharpness': w4, 'color_balance': w5
                                }
                                
                                # ì•™ìƒë¸” ì‹¤í–‰
                                result = self.combine_metrics(metrics, method, weights)
                                
                                if result is not None:
                                    # ëª©í‘œ ì ìˆ˜ì™€ì˜ ì°¨ì´ ê³„ì‚°
                                    score_diff = abs(result - target_score)
                                    
                                    if score_diff < best_score:
                                        best_score = score_diff
                                        best_weights = weights.copy()
            
            if best_weights is not None:
                self.logger.info(f"âœ… ê°€ì¤‘ì¹˜ ìµœì í™” ì™„ë£Œ: ìµœì  ì ìˆ˜ ì°¨ì´ = {best_score:.4f}")
                return best_weights
            else:
                self.logger.warning("âš ï¸ ê°€ì¤‘ì¹˜ ìµœì í™” ì‹¤íŒ¨")
                return None
                
        except Exception as e:
            self.logger.error(f"âŒ ê°€ì¤‘ì¹˜ ìµœì í™” ì‹¤íŒ¨: {e}")
            return None
    
    def add_custom_method(self, method_name: str, method: EnsembleMethod):
        """ì‚¬ìš©ì ì •ì˜ ì•™ìƒë¸” ë°©ë²• ì¶”ê°€"""
        try:
            if method_name in self.ensemble_methods:
                self.logger.warning(f"âš ï¸ ì•™ìƒë¸” ë°©ë²• {method_name}ì´ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤. ë®ì–´ì”ë‹ˆë‹¤.")
            
            self.ensemble_methods[method_name] = method
            self.logger.info(f"âœ… ì‚¬ìš©ì ì •ì˜ ì•™ìƒë¸” ë°©ë²• ì¶”ê°€: {method_name}")
            
        except Exception as e:
            self.logger.error(f"âŒ ì‚¬ìš©ì ì •ì˜ ì•™ìƒë¸” ë°©ë²• ì¶”ê°€ ì‹¤íŒ¨: {method_name} - {e}")
    
    def remove_method(self, method_name: str) -> bool:
        """ì•™ìƒë¸” ë°©ë²• ì œê±°"""
        try:
            if method_name not in self.ensemble_methods:
                self.logger.warning(f"âš ï¸ ì•™ìƒë¸” ë°©ë²• {method_name}ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
                return False
            
            del self.ensemble_methods[method_name]
            self.logger.info(f"âœ… ì•™ìƒë¸” ë°©ë²• ì œê±°: {method_name}")
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ ì•™ìƒë¸” ë°©ë²• ì œê±° ì‹¤íŒ¨: {method_name} - {e}")
            return False
    
    def _update_ensemble_stats(self, method: str, success: bool):
        """ì•™ìƒë¸” í†µê³„ ì—…ë°ì´íŠ¸"""
        try:
            self.ensemble_stats['total_ensembles'] += 1
            
            if success:
                self.ensemble_stats['successful_ensembles'] += 1
            else:
                self.ensemble_stats['failed_ensembles'] += 1
            
            # ë°©ë²•ë³„ ì‚¬ìš© í†µê³„
            if method not in self.ensemble_stats['method_usage']:
                self.ensemble_stats['method_usage'][method] = {'total': 0, 'successful': 0, 'failed': 0}
            
            self.ensemble_stats['method_usage'][method]['total'] += 1
            if success:
                self.ensemble_stats['method_usage'][method]['successful'] += 1
            else:
                self.ensemble_stats['method_usage'][method]['failed'] += 1
                
        except Exception as e:
            self.logger.error(f"âŒ ì•™ìƒë¸” í†µê³„ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
    
    def get_ensemble_stats(self) -> Dict[str, Any]:
        """ì•™ìƒë¸” í†µê³„ ë°˜í™˜"""
        return self.ensemble_stats.copy()
    
    def reset_ensemble_stats(self):
        """ì•™ìƒë¸” í†µê³„ ì´ˆê¸°í™”"""
        self.ensemble_stats = {
            'total_ensembles': 0,
            'successful_ensembles': 0,
            'failed_ensembles': 0,
            'method_usage': {}
        }
