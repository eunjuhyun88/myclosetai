"""
ğŸ”¥ í›„ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ í”„ë¡œì„¸ì„œ
=============================

í›„ì²˜ë¦¬ë¥¼ ìœ„í•œ ì™„ì „í•œ íŒŒì´í”„ë¼ì¸ ì‹œìŠ¤í…œ:
1. í’ˆì§ˆ í–¥ìƒ íŒŒì´í”„ë¼ì¸
2. ê²°ê³¼ ìµœì í™” íŒŒì´í”„ë¼ì¸
3. í’ˆì§ˆ ê²€ì¦ íŒŒì´í”„ë¼ì¸
4. ì•™ìƒë¸” í›„ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸

Author: MyCloset AI Team
Date: 2025-08-14
Version: 1.0
"""

import logging
import time
from typing import Dict, Any, Optional, List, Tuple
import numpy as np
import cv2

logger = logging.getLogger(__name__)

class PostProcessingPipeline:
    """í›„ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸"""
    
    def __init__(self):
        self.logger = logging.getLogger(f"{__name__}.PostProcessingPipeline")
        
        # íŒŒì´í”„ë¼ì¸ í†µê³„
        self.pipeline_stats = {
            'total_pipelines': 0,
            'successful_pipelines': 0,
            'failed_pipelines': 0,
            'average_pipeline_time': 0.0,
            'pipeline_types': {}
        }
        
        # íŒŒì´í”„ë¼ì¸ ë‹¨ê³„ ì •ì˜
        self.pipeline_steps = {
            'quality_enhancement': [
                'noise_reduction',
                'sharpness_enhancement',
                'contrast_enhancement',
                'color_balance'
            ],
            'result_optimization': [
                'brightness_optimization',
                'color_optimization',
                'gamma_correction',
                'final_tuning'
            ],
            'quality_validation': [
                'metric_calculation',
                'quality_assessment',
                'result_validation',
                'performance_analysis'
            ]
        }
    
    def run_quality_enhancement_pipeline(self, image: np.ndarray, config: Dict[str, Any] = None) -> Dict[str, Any]:
        """í’ˆì§ˆ í–¥ìƒ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
        try:
            start_time = time.time()
            self.logger.info("ğŸš€ í’ˆì§ˆ í–¥ìƒ íŒŒì´í”„ë¼ì¸ ì‹œì‘")
            
            if config is None:
                config = self._get_default_enhancement_config()
            
            # íŒŒì´í”„ë¼ì¸ ë‹¨ê³„ë³„ ì‹¤í–‰
            result = self._execute_pipeline_steps(image, self.pipeline_steps['quality_enhancement'], config)
            
            # íŒŒì´í”„ë¼ì¸ í†µê³„ ì—…ë°ì´íŠ¸
            pipeline_time = time.time() - start_time
            self._update_pipeline_stats('quality_enhancement', True, pipeline_time)
            
            self.logger.info(f"âœ… í’ˆì§ˆ í–¥ìƒ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ ({pipeline_time:.2f}s)")
            return result
            
        except Exception as e:
            self.logger.error(f"âŒ í’ˆì§ˆ í–¥ìƒ íŒŒì´í”„ë¼ì¸ ì‹¤íŒ¨: {e}")
            self._update_pipeline_stats('quality_enhancement', False, 0.0)
            raise
    
    def run_result_optimization_pipeline(self, image: np.ndarray, config: Dict[str, Any] = None) -> Dict[str, Any]:
        """ê²°ê³¼ ìµœì í™” íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
        try:
            start_time = time.time()
            self.logger.info("ğŸš€ ê²°ê³¼ ìµœì í™” íŒŒì´í”„ë¼ì¸ ì‹œì‘")
            
            if config is None:
                config = self._get_default_optimization_config()
            
            # íŒŒì´í”„ë¼ì¸ ë‹¨ê³„ë³„ ì‹¤í–‰
            result = self._execute_pipeline_steps(image, self.pipeline_steps['result_optimization'], config)
            
            # íŒŒì´í”„ë¼ì¸ í†µê³„ ì—…ë°ì´íŠ¸
            pipeline_time = time.time() - start_time
            self._update_pipeline_stats('result_optimization', True, pipeline_time)
            
            self.logger.info(f"âœ… ê²°ê³¼ ìµœì í™” íŒŒì´í”„ë¼ì¸ ì™„ë£Œ ({pipeline_time:.2f}s)")
            return result
            
        except Exception as e:
            self.logger.error(f"âŒ ê²°ê³¼ ìµœì í™” íŒŒì´í”„ë¼ì¸ ì‹¤íŒ¨: {e}")
            self._update_pipeline_stats('result_optimization', False, 0.0)
            raise
    
    def run_quality_validation_pipeline(self, original_image: np.ndarray, processed_image: np.ndarray) -> Dict[str, Any]:
        """í’ˆì§ˆ ê²€ì¦ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
        try:
            start_time = time.time()
            self.logger.info("ğŸš€ í’ˆì§ˆ ê²€ì¦ íŒŒì´í”„ë¼ì¸ ì‹œì‘")
            
            # í’ˆì§ˆ ë©”íŠ¸ë¦­ ê³„ì‚°
            quality_metrics = self._calculate_comprehensive_quality_metrics(original_image, processed_image)
            
            # í’ˆì§ˆ í‰ê°€
            quality_assessment = self._assess_quality(quality_metrics)
            
            # ê²°ê³¼ ê²€ì¦
            validation_result = self._validate_results(quality_metrics, quality_assessment)
            
            # ì„±ëŠ¥ ë¶„ì„
            performance_analysis = self._analyze_performance(quality_metrics)
            
            result = {
                'quality_metrics': quality_metrics,
                'quality_assessment': quality_assessment,
                'validation_result': validation_result,
                'performance_analysis': performance_analysis
            }
            
            # íŒŒì´í”„ë¼ì¸ í†µê³„ ì—…ë°ì´íŠ¸
            pipeline_time = time.time() - start_time
            self._update_pipeline_stats('quality_validation', True, pipeline_time)
            
            self.logger.info(f"âœ… í’ˆì§ˆ ê²€ì¦ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ ({pipeline_time:.2f}s)")
            return result
            
        except Exception as e:
            self.logger.error(f"âŒ í’ˆì§ˆ ê²€ì¦ íŒŒì´í”„ë¼ì¸ ì‹¤íŒ¨: {e}")
            self._update_pipeline_stats('quality_validation', False, 0.0)
            raise
    
    def _execute_pipeline_steps(self, image: np.ndarray, steps: List[str], config: Dict[str, Any]) -> Dict[str, Any]:
        """íŒŒì´í”„ë¼ì¸ ë‹¨ê³„ë³„ ì‹¤í–‰"""
        try:
            current_image = image.copy()
            step_results = {}
            
            for step in steps:
                self.logger.info(f"ğŸ“‹ íŒŒì´í”„ë¼ì¸ ë‹¨ê³„ ì‹¤í–‰: {step}")
                
                if step == 'noise_reduction':
                    current_image = self._apply_noise_reduction(current_image, config.get('noise_reduction', {}))
                elif step == 'sharpness_enhancement':
                    current_image = self._apply_sharpness_enhancement(current_image, config.get('sharpness_enhancement', {}))
                elif step == 'contrast_enhancement':
                    current_image = self._apply_contrast_enhancement(current_image, config.get('contrast_enhancement', {}))
                elif step == 'color_balance':
                    current_image = self._apply_color_balance(current_image, config.get('color_balance', {}))
                elif step == 'brightness_optimization':
                    current_image = self._apply_brightness_optimization(current_image, config.get('brightness_optimization', {}))
                elif step == 'color_optimization':
                    current_image = self._apply_color_optimization(current_image, config.get('color_optimization', {}))
                elif step == 'gamma_correction':
                    current_image = self._apply_gamma_correction(current_image, config.get('gamma_correction', {}))
                elif step == 'final_tuning':
                    current_image = self._apply_final_tuning(current_image, config.get('final_tuning', {}))
                
                step_results[step] = current_image.copy()
            
            return {
                'final_result': current_image,
                'step_results': step_results,
                'pipeline_steps': steps
            }
            
        except Exception as e:
            self.logger.error(f"âŒ íŒŒì´í”„ë¼ì¸ ë‹¨ê³„ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            raise
    
    def _apply_noise_reduction(self, image: np.ndarray, config: Dict[str, Any]) -> np.ndarray:
        """ë…¸ì´ì¦ˆ ì œê±° ì ìš©"""
        try:
            # Non-local Means Denoising
            denoised = cv2.fastNlMeansDenoisingColored(
                image, 
                None, 
                config.get('h', 10),
                config.get('hColor', 10),
                config.get('templateWindowSize', 7),
                config.get('searchWindowSize', 21)
            )
            
            # Bilateral Filter ì¶”ê°€ ì ìš©
            denoised = cv2.bilateralFilter(
                denoised,
                config.get('d', 9),
                config.get('sigmaColor', 75),
                config.get('sigmaSpace', 75)
            )
            
            return denoised
            
        except Exception as e:
            self.logger.error(f"âŒ ë…¸ì´ì¦ˆ ì œê±° ì ìš© ì‹¤íŒ¨: {e}")
            return image
    
    def _apply_sharpness_enhancement(self, image: np.ndarray, config: Dict[str, Any]) -> np.ndarray:
        """ì„ ëª…ë„ í–¥ìƒ ì ìš©"""
        try:
            # Unsharp Masking
            gaussian = cv2.GaussianBlur(image, (0, 0), config.get('sigma', 2.0))
            sharpened = cv2.addWeighted(
                image, 
                config.get('alpha', 1.5), 
                gaussian, 
                config.get('beta', -0.5), 
                0
            )
            
            # ì¶”ê°€ ì„ ëª…ë„ í–¥ìƒ
            kernel = np.array([[-1,-1,-1], [-1,9,-1], [-1,-1,-1]])
            sharpened = cv2.filter2D(sharpened, -1, kernel)
            
            return sharpened
            
        except Exception as e:
            self.logger.error(f"âŒ ì„ ëª…ë„ í–¥ìƒ ì ìš© ì‹¤íŒ¨: {e}")
            return image
    
    def _apply_contrast_enhancement(self, image: np.ndarray, config: Dict[str, Any]) -> np.ndarray:
        """ëŒ€ë¹„ í–¥ìƒ ì ìš©"""
        try:
            # LAB ìƒ‰ê³µê°„ìœ¼ë¡œ ë³€í™˜
            lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)
            l, a, b = cv2.split(lab)
            
            # CLAHE ì ìš© (L ì±„ë„)
            clahe = cv2.createCLAHE(
                clipLimit=config.get('clipLimit', 3.0),
                tileGridSize=tuple(config.get('tileGridSize', [8, 8]))
            )
            l = clahe.apply(l)
            
            # ì±„ë„ í•©ì¹˜ê¸°
            enhanced = cv2.merge([l, a, b])
            enhanced = cv2.cvtColor(enhanced, cv2.COLOR_LAB2BGR)
            
            return enhanced
            
        except Exception as e:
            self.logger.error(f"âŒ ëŒ€ë¹„ í–¥ìƒ ì ìš© ì‹¤íŒ¨: {e}")
            return image
    
    def _apply_color_balance(self, image: np.ndarray, config: Dict[str, Any]) -> np.ndarray:
        """ìƒ‰ìƒ ê· í˜• ì¡°ì • ì ìš©"""
        try:
            # ìƒ‰ìƒ ê· í˜• ì¡°ì •
            balanced = cv2.convertScaleAbs(
                image, 
                alpha=config.get('alpha', 1.1), 
                beta=config.get('beta', 5)
            )
            
            # ê°ë§ˆ ë³´ì •
            gamma = config.get('gamma', 1.1)
            invGamma = 1.0 / gamma
            table = np.array([((i / 255.0) ** invGamma) * 255 for i in np.arange(0, 256)]).astype("uint8")
            balanced = cv2.LUT(balanced, table)
            
            return balanced
            
        except Exception as e:
            self.logger.error(f"âŒ ìƒ‰ìƒ ê· í˜• ì¡°ì • ì ìš© ì‹¤íŒ¨: {e}")
            return image
    
    def _apply_brightness_optimization(self, image: np.ndarray, config: Dict[str, Any]) -> np.ndarray:
        """ë°ê¸° ìµœì í™” ì ìš©"""
        try:
            # ë°ê¸° ì¡°ì •
            optimized = cv2.convertScaleAbs(
                image,
                alpha=config.get('alpha', 1.0),
                beta=config.get('beta', 10)
            )
            
            return optimized
            
        except Exception as e:
            self.logger.error(f"âŒ ë°ê¸° ìµœì í™” ì ìš© ì‹¤íŒ¨: {e}")
            return image
    
    def _apply_color_optimization(self, image: np.ndarray, config: Dict[str, Any]) -> np.ndarray:
        """ìƒ‰ìƒ ìµœì í™” ì ìš©"""
        try:
            # ìƒ‰ìƒ ì±„ë„ë³„ ì¡°ì •
            b, g, r = cv2.split(image)
            
            # ê° ì±„ë„ì— ëŒ€í•œ ê°€ì¤‘ì¹˜ ì ìš©
            b = cv2.convertScaleAbs(b, alpha=config.get('blue_alpha', 1.0))
            g = cv2.convertScaleAbs(g, alpha=config.get('green_alpha', 1.0))
            r = cv2.convertScaleAbs(r, alpha=config.get('red_alpha', 1.0))
            
            optimized = cv2.merge([b, g, r])
            return optimized
            
        except Exception as e:
            self.logger.error(f"âŒ ìƒ‰ìƒ ìµœì í™” ì ìš© ì‹¤íŒ¨: {e}")
            return image
    
    def _apply_gamma_correction(self, image: np.ndarray, config: Dict[str, Any]) -> np.ndarray:
        """ê°ë§ˆ ë³´ì • ì ìš©"""
        try:
            gamma = config.get('gamma', 1.1)
            invGamma = 1.0 / gamma
            table = np.array([((i / 255.0) ** invGamma) * 255 for i in np.arange(0, 256)]).astype("uint8")
            corrected = cv2.LUT(image, table)
            
            return corrected
            
        except Exception as e:
            self.logger.error(f"âŒ ê°ë§ˆ ë³´ì • ì ìš© ì‹¤íŒ¨: {e}")
            return image
    
    def _apply_final_tuning(self, image: np.ndarray, config: Dict[str, Any]) -> np.ndarray:
        """ìµœì¢… íŠœë‹ ì ìš©"""
        try:
            # ìµœì¢… í’ˆì§ˆ ì¡°ì •
            tuned = image.copy()
            
            # ì•½ê°„ì˜ ë¸”ëŸ¬ë¡œ ë…¸ì´ì¦ˆ ì œê±°
            if config.get('final_blur', False):
                tuned = cv2.GaussianBlur(tuned, (3, 3), 0.5)
            
            # ìµœì¢… ìƒ‰ìƒ ì¡°ì •
            tuned = cv2.convertScaleAbs(
                tuned,
                alpha=config.get('final_alpha', 1.0),
                beta=config.get('final_beta', 0)
            )
            
            return tuned
            
        except Exception as e:
            self.logger.error(f"âŒ ìµœì¢… íŠœë‹ ì ìš© ì‹¤íŒ¨: {e}")
            return image
    
    def _calculate_comprehensive_quality_metrics(self, original: np.ndarray, processed: np.ndarray) -> Dict[str, float]:
        """ì¢…í•© í’ˆì§ˆ ë©”íŠ¸ë¦­ ê³„ì‚°"""
        try:
            metrics = {}
            
            # PSNR ê³„ì‚°
            mse = np.mean((original.astype(float) - processed.astype(float)) ** 2)
            if mse == 0:
                metrics['psnr'] = float('inf')
            else:
                metrics['psnr'] = 20 * np.log10(255.0 / np.sqrt(mse))
            
            # SSIM ê³„ì‚°
            metrics['ssim'] = self._calculate_ssim(original, processed)
            
            # ëŒ€ë¹„ ê°œì„ ë„
            original_contrast = np.std(original)
            processed_contrast = np.std(processed)
            metrics['contrast_improvement'] = processed_contrast / original_contrast if original_contrast > 0 else 1.0
            
            # ì„ ëª…ë„ ê°œì„ ë„
            original_sharpness = self._calculate_sharpness(original)
            processed_sharpness = self._calculate_sharpness(processed)
            metrics['sharpness_improvement'] = processed_sharpness / original_sharpness if original_sharpness > 0 else 1.0
            
            return metrics
            
        except Exception as e:
            self.logger.error(f"âŒ ì¢…í•© í’ˆì§ˆ ë©”íŠ¸ë¦­ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return {'psnr': 0.0, 'ssim': 0.0, 'contrast_improvement': 1.0, 'sharpness_improvement': 1.0}
    
    def _calculate_ssim(self, img1: np.ndarray, img2: np.ndarray) -> float:
        """SSIM ê³„ì‚°"""
        try:
            mu1 = np.mean(img1)
            mu2 = np.mean(img2)
            sigma1 = np.std(img1)
            sigma2 = np.std(img2)
            sigma12 = np.mean((img1 - mu1) * (img2 - mu2))
            
            c1 = (0.01 * 255) ** 2
            c2 = (0.03 * 255) ** 2
            
            ssim = ((2 * mu1 * mu2 + c1) * (2 * sigma12 + c2)) / \
                   ((mu1 ** 2 + mu2 ** 2 + c1) * (sigma1 ** 2 + sigma2 ** 2 + c2))
            
            return float(ssim)
            
        except Exception as e:
            self.logger.error(f"âŒ SSIM ê³„ì‚° ì‹¤íŒ¨: {e}")
            return 0.0
    
    def _calculate_sharpness(self, image: np.ndarray) -> float:
        """ì„ ëª…ë„ ê³„ì‚°"""
        try:
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
            laplacian = cv2.Laplacian(gray, cv2.CV_64F)
            return np.var(laplacian)
            
        except Exception as e:
            self.logger.error(f"âŒ ì„ ëª…ë„ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return 0.0
    
    def _assess_quality(self, quality_metrics: Dict[str, float]) -> Dict[str, Any]:
        """í’ˆì§ˆ í‰ê°€"""
        try:
            assessment = {}
            
            # PSNR í‰ê°€
            psnr = quality_metrics.get('psnr', 0)
            if psnr > 30:
                assessment['psnr_grade'] = 'Excellent'
            elif psnr > 25:
                assessment['psnr_grade'] = 'Good'
            elif psnr > 20:
                assessment['psnr_grade'] = 'Fair'
            else:
                assessment['psnr_grade'] = 'Poor'
            
            # SSIM í‰ê°€
            ssim = quality_metrics.get('ssim', 0)
            if ssim > 0.9:
                assessment['ssim_grade'] = 'Excellent'
            elif ssim > 0.8:
                assessment['ssim_grade'] = 'Good'
            elif ssim > 0.7:
                assessment['ssim_grade'] = 'Fair'
            else:
                assessment['ssim_grade'] = 'Poor'
            
            # ì¢…í•© ë“±ê¸‰
            if assessment.get('psnr_grade') == 'Excellent' and assessment.get('ssim_grade') == 'Excellent':
                assessment['overall_grade'] = 'A+'
            elif assessment.get('psnr_grade') in ['Excellent', 'Good'] and assessment.get('ssim_grade') in ['Excellent', 'Good']:
                assessment['overall_grade'] = 'A'
            elif assessment.get('psnr_grade') in ['Good', 'Fair'] and assessment.get('ssim_grade') in ['Good', 'Fair']:
                assessment['overall_grade'] = 'B'
            else:
                assessment['overall_grade'] = 'C'
            
            return assessment
            
        except Exception as e:
            self.logger.error(f"âŒ í’ˆì§ˆ í‰ê°€ ì‹¤íŒ¨: {e}")
            return {'overall_grade': 'Unknown'}
    
    def _validate_results(self, quality_metrics: Dict[str, float], quality_assessment: Dict[str, Any]) -> Dict[str, Any]:
        """ê²°ê³¼ ê²€ì¦"""
        try:
            validation = {
                'is_valid': True,
                'warnings': [],
                'recommendations': []
            }
            
            # PSNR ê²€ì¦
            psnr = quality_metrics.get('psnr', 0)
            if psnr < 20:
                validation['warnings'].append("PSNRì´ ë„ˆë¬´ ë‚®ìŠµë‹ˆë‹¤. í’ˆì§ˆ í–¥ìƒì´ í•„ìš”í•©ë‹ˆë‹¤.")
                validation['is_valid'] = False
            
            # SSIM ê²€ì¦
            ssim = quality_metrics.get('ssim', 0)
            if ssim < 0.7:
                validation['warnings'].append("SSIMì´ ë„ˆë¬´ ë‚®ìŠµë‹ˆë‹¤. êµ¬ì¡°ì  ìœ ì‚¬ì„±ì´ ë¶€ì¡±í•©ë‹ˆë‹¤.")
                validation['is_valid'] = False
            
            # ê°œì„ ë„ ê²€ì¦
            contrast_improvement = quality_metrics.get('contrast_improvement', 1.0)
            if contrast_improvement < 0.8:
                validation['warnings'].append("ëŒ€ë¹„ ê°œì„ ë„ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.")
                validation['recommendations'].append("ëŒ€ë¹„ í–¥ìƒ íŒŒë¼ë¯¸í„°ë¥¼ ì¡°ì •í•´ë³´ì„¸ìš”.")
            
            sharpness_improvement = quality_metrics.get('sharpness_improvement', 1.0)
            if sharpness_improvement < 0.8:
                validation['warnings'].append("ì„ ëª…ë„ ê°œì„ ë„ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.")
                validation['recommendations'].append("ì„ ëª…ë„ í–¥ìƒ íŒŒë¼ë¯¸í„°ë¥¼ ì¡°ì •í•´ë³´ì„¸ìš”.")
            
            return validation
            
        except Exception as e:
            self.logger.error(f"âŒ ê²°ê³¼ ê²€ì¦ ì‹¤íŒ¨: {e}")
            return {'is_valid': False, 'warnings': ['ê²€ì¦ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.'], 'recommendations': []}
    
    def _analyze_performance(self, quality_metrics: Dict[str, float]) -> Dict[str, Any]:
        """ì„±ëŠ¥ ë¶„ì„"""
        try:
            analysis = {
                'performance_score': 0.0,
                'strengths': [],
                'weaknesses': [],
                'improvement_areas': []
            }
            
            # ì„±ëŠ¥ ì ìˆ˜ ê³„ì‚°
            psnr_score = min(quality_metrics.get('psnr', 0) / 40.0, 1.0)  # 40dB ì´ìƒì„ ë§Œì 
            ssim_score = quality_metrics.get('ssim', 0)
            contrast_score = min(quality_metrics.get('contrast_improvement', 1.0), 1.5) / 1.5
            sharpness_score = min(quality_metrics.get('sharpness_improvement', 1.0), 1.5) / 1.5
            
            performance_score = (psnr_score + ssim_score + contrast_score + sharpness_score) / 4.0
            analysis['performance_score'] = performance_score
            
            # ê°•ì  ë¶„ì„
            if psnr_score > 0.8:
                analysis['strengths'].append("ë†’ì€ PSNRë¡œ ìš°ìˆ˜í•œ í’ˆì§ˆ")
            if ssim_score > 0.9:
                analysis['strengths'].append("ë†’ì€ SSIMìœ¼ë¡œ êµ¬ì¡°ì  ìœ ì‚¬ì„± ìš°ìˆ˜")
            if contrast_score > 0.9:
                analysis['strengths'].append("ëŒ€ë¹„ ê°œì„  íš¨ê³¼ ìš°ìˆ˜")
            if sharpness_score > 0.9:
                analysis['strengths'].append("ì„ ëª…ë„ ê°œì„  íš¨ê³¼ ìš°ìˆ˜")
            
            # ì•½ì  ë¶„ì„
            if psnr_score < 0.6:
                analysis['weaknesses'].append("PSNRì´ ë‚®ì•„ í’ˆì§ˆ ê°œì„  í•„ìš”")
            if ssim_score < 0.8:
                analysis['weaknesses'].append("SSIMì´ ë‚®ì•„ êµ¬ì¡°ì  ìœ ì‚¬ì„± ê°œì„  í•„ìš”")
            if contrast_score < 0.8:
                analysis['weaknesses'].append("ëŒ€ë¹„ ê°œì„  íš¨ê³¼ ë¶€ì¡±")
            if sharpness_score < 0.8:
                analysis['weaknesses'].append("ì„ ëª…ë„ ê°œì„  íš¨ê³¼ ë¶€ì¡±")
            
            # ê°œì„  ì˜ì—­
            if psnr_score < 0.7:
                analysis['improvement_areas'].append("ë…¸ì´ì¦ˆ ì œê±° ë° í’ˆì§ˆ í–¥ìƒ")
            if ssim_score < 0.8:
                analysis['improvement_areas'].append("êµ¬ì¡°ì  ë³´ì¡´ ê°•í™”")
            if contrast_score < 0.8:
                analysis['improvement_areas'].append("ëŒ€ë¹„ í–¥ìƒ íŒŒë¼ë¯¸í„° ì¡°ì •")
            if sharpness_score < 0.8:
                analysis['improvement_areas'].append("ì„ ëª…ë„ í–¥ìƒ íŒŒë¼ë¯¸í„° ì¡°ì •")
            
            return analysis
            
        except Exception as e:
            self.logger.error(f"âŒ ì„±ëŠ¥ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {'performance_score': 0.0, 'strengths': [], 'weaknesses': [], 'improvement_areas': []}
    
    def _get_default_enhancement_config(self) -> Dict[str, Any]:
        """ê¸°ë³¸ í–¥ìƒ ì„¤ì • ë°˜í™˜"""
        return {
            'noise_reduction': {'h': 10, 'hColor': 10, 'templateWindowSize': 7, 'searchWindowSize': 21, 'd': 9, 'sigmaColor': 75, 'sigmaSpace': 75},
            'sharpness_enhancement': {'sigma': 2.0, 'alpha': 1.5, 'beta': -0.5},
            'contrast_enhancement': {'clipLimit': 3.0, 'tileGridSize': [8, 8]},
            'color_balance': {'alpha': 1.1, 'beta': 5, 'gamma': 1.1}
        }
    
    def _get_default_optimization_config(self) -> Dict[str, Any]:
        """ê¸°ë³¸ ìµœì í™” ì„¤ì • ë°˜í™˜"""
        return {
            'brightness_optimization': {'alpha': 1.0, 'beta': 10},
            'color_optimization': {'blue_alpha': 1.0, 'green_alpha': 1.0, 'red_alpha': 1.0},
            'gamma_correction': {'gamma': 1.1},
            'final_tuning': {'final_blur': False, 'final_alpha': 1.0, 'final_beta': 0}
        }
    
    def _update_pipeline_stats(self, pipeline_type: str, success: bool, pipeline_time: float):
        """íŒŒì´í”„ë¼ì¸ í†µê³„ ì—…ë°ì´íŠ¸"""
        try:
            self.pipeline_stats['total_pipelines'] += 1
            
            if success:
                self.pipeline_stats['successful_pipelines'] += 1
                
                # í‰ê·  íŒŒì´í”„ë¼ì¸ ì‹œê°„ ì—…ë°ì´íŠ¸
                total_successful = self.pipeline_stats['successful_pipelines']
                current_avg = self.pipeline_stats['average_pipeline_time']
                new_avg = (current_avg * (total_successful - 1) + pipeline_time) / total_successful
                self.pipeline_stats['average_pipeline_time'] = new_avg
            else:
                self.pipeline_stats['failed_pipelines'] += 1
            
            # íŒŒì´í”„ë¼ì¸ íƒ€ì…ë³„ í†µê³„
            if pipeline_type not in self.pipeline_stats['pipeline_types']:
                self.pipeline_stats['pipeline_types'][pipeline_type] = {'total': 0, 'successful': 0, 'failed': 0}
            
            self.pipeline_stats['pipeline_types'][pipeline_type]['total'] += 1
            if success:
                self.pipeline_stats['pipeline_types'][pipeline_type]['successful'] += 1
            else:
                self.pipeline_stats['pipeline_types'][pipeline_type]['failed'] += 1
                
        except Exception as e:
            self.logger.error(f"âŒ íŒŒì´í”„ë¼ì¸ í†µê³„ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
    
    def get_pipeline_stats(self) -> Dict[str, Any]:
        """íŒŒì´í”„ë¼ì¸ í†µê³„ ë°˜í™˜"""
        return self.pipeline_stats.copy()
    
    def reset_pipeline_stats(self):
        """íŒŒì´í”„ë¼ì¸ í†µê³„ ì´ˆê¸°í™”"""
        self.pipeline_stats = {
            'total_pipelines': 0,
            'successful_pipelines': 0,
            'failed_pipelines': 0,
            'average_pipeline_time': 0.0,
            'pipeline_types': {}
        }
