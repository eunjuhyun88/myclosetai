# backend/app/ai_pipeline/steps/base_step_mixin.py
"""
ğŸ”¥ BaseStepMixin v16.0 - ìˆœí™˜ì°¸ì¡° ì™„ì „ í•´ê²° + í†µí•© ì˜ì¡´ì„± ì£¼ì…
================================================================

âœ… TYPE_CHECKING íŒ¨í„´ìœ¼ë¡œ ìˆœí™˜ì°¸ì¡° ì™„ì „ ë°©ì§€
âœ… í†µí•©ëœ ì˜ì¡´ì„± ì£¼ì… ì¸í„°í˜ì´ìŠ¤
âœ… ëª¨ë“  Step í´ë˜ìŠ¤ í˜¸í™˜ì„± ë³´ì¥
âœ… ì´ˆê¸°í™” ë¡œì§ í‘œì¤€í™”
âœ… í”„ë¡œë•ì…˜ ë ˆë²¨ ì•ˆì •ì„±

Author: MyCloset AI Team
Date: 2025-07-24
Version: 16.0 (Circular Reference Complete Solution)
"""

import os
import gc
import time
import asyncio
import logging
import threading
import traceback
import weakref
from pathlib import Path
from typing import Dict, Any, Optional, Tuple, List, Union, Callable, Type, TYPE_CHECKING
from dataclasses import dataclass, field
from abc import ABC, abstractmethod
from functools import wraps
from contextlib import asynccontextmanager

# ğŸ”¥ TYPE_CHECKINGìœ¼ë¡œ ìˆœí™˜ì°¸ì¡° ì™„ì „ ë°©ì§€
if TYPE_CHECKING:
    from ..utils.model_loader import ModelLoader, StepModelInterface
    from ..factories.step_factory import StepFactory
    from ..utils.memory_manager import MemoryManager
    from ..utils.data_converter import DataConverter
    from ..core.di_container import DIContainer

# ==============================================
# ğŸ”¥ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì•ˆì „ import
# ==============================================

# PyTorch ì•ˆì „ import
TORCH_AVAILABLE = False
MPS_AVAILABLE = False
try:
    import torch
    import torch.nn as nn
    import torch.nn.functional as F
    TORCH_AVAILABLE = True
    
    if hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
        MPS_AVAILABLE = True
except ImportError:
    torch = None

# PIL ì•ˆì „ import
PIL_AVAILABLE = False
try:
    from PIL import Image
    PIL_AVAILABLE = True
except ImportError:
    Image = None

# NumPy ì•ˆì „ import
NUMPY_AVAILABLE = False
try:
    import numpy as np
    NUMPY_AVAILABLE = True
except ImportError:
    np = None

# ==============================================
# ğŸ”¥ ì˜ì¡´ì„± ì£¼ì… ì¸í„°í˜ì´ìŠ¤ (ì¶”ìƒí™”)
# ==============================================

class IModelProvider(ABC):
    """ëª¨ë¸ ì œê³µì ì¸í„°í˜ì´ìŠ¤"""
    
    @abstractmethod
    def get_model(self, model_name: str) -> Optional[Any]:
        """ëª¨ë¸ ê°€ì ¸ì˜¤ê¸°"""
        pass
    
    @abstractmethod
    async def get_model_async(self, model_name: str) -> Optional[Any]:
        """ë¹„ë™ê¸° ëª¨ë¸ ê°€ì ¸ì˜¤ê¸°"""
        pass
    
    @abstractmethod
    def is_model_available(self, model_name: str) -> bool:
        """ëª¨ë¸ ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€"""
        pass

class IMemoryManager(ABC):
    """ë©”ëª¨ë¦¬ ê´€ë¦¬ì ì¸í„°í˜ì´ìŠ¤"""
    
    @abstractmethod
    def optimize_memory(self, aggressive: bool = False) -> Dict[str, Any]:
        """ë©”ëª¨ë¦¬ ìµœì í™”"""
        pass
    
    @abstractmethod
    async def optimize_memory_async(self, aggressive: bool = False) -> Dict[str, Any]:
        """ë¹„ë™ê¸° ë©”ëª¨ë¦¬ ìµœì í™”"""
        pass

class IDataConverter(ABC):
    """ë°ì´í„° ë³€í™˜ê¸° ì¸í„°í˜ì´ìŠ¤"""
    
    @abstractmethod
    def convert_data(self, data: Any, target_format: str) -> Any:
        """ë°ì´í„° ë³€í™˜"""
        pass

# ==============================================
# ğŸ”¥ ì„¤ì • í´ë˜ìŠ¤
# ==============================================

@dataclass
class StepConfig:
    """í†µí•© Step ì„¤ì •"""
    step_name: str = "BaseStep"
    step_id: int = 0
    device: str = "auto"
    use_fp16: bool = True
    batch_size: int = 1
    confidence_threshold: float = 0.8
    auto_memory_cleanup: bool = True
    auto_warmup: bool = True
    optimization_enabled: bool = True
    quality_level: str = "balanced"
    strict_mode: bool = False
    
    # ì˜ì¡´ì„± ì„¤ì •
    auto_inject_dependencies: bool = True
    require_model_loader: bool = True
    require_memory_manager: bool = False
    require_data_converter: bool = False

@dataclass
class DependencyStatus:
    """ì˜ì¡´ì„± ìƒíƒœ ì¶”ì """
    model_loader: bool = False
    step_interface: bool = False
    memory_manager: bool = False
    data_converter: bool = False
    di_container: bool = False
    base_initialized: bool = False
    custom_initialized: bool = False

# ==============================================
# ğŸ”¥ í†µí•© ì˜ì¡´ì„± ê´€ë¦¬ì
# ==============================================

class UnifiedDependencyManager:
    """í†µí•© ì˜ì¡´ì„± ê´€ë¦¬ì (ìˆœí™˜ì°¸ì¡° ë°©ì§€)"""
    
    def __init__(self, step_name: str):
        self.step_name = step_name
        self.logger = logging.getLogger(f"DependencyManager.{step_name}")
        
        # ì˜ì¡´ì„± ì €ì¥
        self.dependencies: Dict[str, Any] = {}
        self.dependency_status = DependencyStatus()
        
        # ë™ê¸°í™”
        self._lock = threading.RLock()
        
        # ìë™ ì£¼ì… í”Œë˜ê·¸
        self._auto_injection_attempted = False
    
    def inject_model_loader(self, model_loader: 'ModelLoader') -> bool:
        """ModelLoader ì˜ì¡´ì„± ì£¼ì…"""
        try:
            with self._lock:
                self.dependencies['model_loader'] = model_loader
                self.dependency_status.model_loader = True
                
                # Step ì¸í„°í˜ì´ìŠ¤ ìƒì„±
                if hasattr(model_loader, 'create_step_interface'):
                    interface = model_loader.create_step_interface(self.step_name)
                    self.dependencies['step_interface'] = interface
                    self.dependency_status.step_interface = True
                
                self.logger.info("âœ… ModelLoader ì˜ì¡´ì„± ì£¼ì… ì™„ë£Œ")
                return True
        except Exception as e:
            self.logger.error(f"âŒ ModelLoader ì£¼ì… ì‹¤íŒ¨: {e}")
            return False
    
    def inject_memory_manager(self, memory_manager: 'MemoryManager') -> bool:
        """MemoryManager ì˜ì¡´ì„± ì£¼ì…"""
        try:
            with self._lock:
                self.dependencies['memory_manager'] = memory_manager
                self.dependency_status.memory_manager = True
                self.logger.info("âœ… MemoryManager ì˜ì¡´ì„± ì£¼ì… ì™„ë£Œ")
                return True
        except Exception as e:
            self.logger.error(f"âŒ MemoryManager ì£¼ì… ì‹¤íŒ¨: {e}")
            return False
    
    def inject_data_converter(self, data_converter: 'DataConverter') -> bool:
        """DataConverter ì˜ì¡´ì„± ì£¼ì…"""
        try:
            with self._lock:
                self.dependencies['data_converter'] = data_converter
                self.dependency_status.data_converter = True
                self.logger.info("âœ… DataConverter ì˜ì¡´ì„± ì£¼ì… ì™„ë£Œ")
                return True
        except Exception as e:
            self.logger.error(f"âŒ DataConverter ì£¼ì… ì‹¤íŒ¨: {e}")
            return False
    
    def inject_di_container(self, di_container: 'DIContainer') -> bool:
        """DI Container ì˜ì¡´ì„± ì£¼ì…"""
        try:
            with self._lock:
                self.dependencies['di_container'] = di_container
                self.dependency_status.di_container = True
                self.logger.info("âœ… DI Container ì˜ì¡´ì„± ì£¼ì… ì™„ë£Œ")
                return True
        except Exception as e:
            self.logger.error(f"âŒ DI Container ì£¼ì… ì‹¤íŒ¨: {e}")
            return False
    
    def get_dependency(self, name: str) -> Optional[Any]:
        """ì˜ì¡´ì„± ì¡°íšŒ"""
        with self._lock:
            return self.dependencies.get(name)
    
    def check_required_dependencies(self, config: StepConfig) -> bool:
        """í•„ìˆ˜ ì˜ì¡´ì„± í™•ì¸"""
        if config.require_model_loader and not self.dependency_status.model_loader:
            return False
        if config.require_memory_manager and not self.dependency_status.memory_manager:
            return False
        if config.require_data_converter and not self.dependency_status.data_converter:
            return False
        return True
    
    def auto_inject_dependencies(self) -> bool:
        """ìë™ ì˜ì¡´ì„± ì£¼ì… (ë™ì  import ì‚¬ìš©)"""
        if self._auto_injection_attempted:
            return True
        
        self._auto_injection_attempted = True
        success_count = 0
        
        try:
            # ModelLoader ìë™ ì£¼ì…
            if not self.dependency_status.model_loader:
                model_loader = self._get_global_model_loader()
                if model_loader:
                    self.inject_model_loader(model_loader)
                    success_count += 1
            
            # MemoryManager ìë™ ì£¼ì…
            if not self.dependency_status.memory_manager:
                memory_manager = self._get_global_memory_manager()
                if memory_manager:
                    self.inject_memory_manager(memory_manager)
                    success_count += 1
            
            self.logger.info(f"ğŸ”„ ìë™ ì˜ì¡´ì„± ì£¼ì… ì™„ë£Œ: {success_count}ê°œ")
            return success_count > 0
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ ìë™ ì˜ì¡´ì„± ì£¼ì… ì‹¤íŒ¨: {e}")
            return False
    
    def _get_global_model_loader(self) -> Optional['ModelLoader']:
        """ModelLoader ë™ì  import (ìˆœí™˜ì°¸ì¡° ë°©ì§€)"""
        try:
            import importlib
            module = importlib.import_module('app.ai_pipeline.utils.model_loader')
            get_global = getattr(module, 'get_global_model_loader', None)
            if get_global:
                return get_global()
        except Exception as e:
            self.logger.debug(f"ModelLoader ìë™ ì£¼ì… ì‹¤íŒ¨: {e}")
        return None
    
    def _get_global_memory_manager(self) -> Optional['MemoryManager']:
        """MemoryManager ë™ì  import (ìˆœí™˜ì°¸ì¡° ë°©ì§€)"""
        try:
            import importlib
            module = importlib.import_module('app.ai_pipeline.utils.memory_manager')
            get_global = getattr(module, 'get_global_memory_manager', None)
            if get_global:
                return get_global()
        except Exception as e:
            self.logger.debug(f"MemoryManager ìë™ ì£¼ì… ì‹¤íŒ¨: {e}")
        return None

# ==============================================
# ğŸ”¥ BaseStepMixin v16.0 - ì™„ì „ í†µí•© ë²„ì „
# ==============================================

class BaseStepMixin:
    """
    ğŸ”¥ BaseStepMixin v16.0 - ìˆœí™˜ì°¸ì¡° ì™„ì „ í•´ê²° + í†µí•© ì˜ì¡´ì„± ì£¼ì…
    
    âœ… TYPE_CHECKING íŒ¨í„´ìœ¼ë¡œ ìˆœí™˜ì°¸ì¡° ë°©ì§€
    âœ… í†µí•©ëœ ì˜ì¡´ì„± ì£¼ì… ì¸í„°í˜ì´ìŠ¤
    âœ… ëª¨ë“  Step í´ë˜ìŠ¤ í˜¸í™˜ì„± ë³´ì¥
    âœ… ì´ˆê¸°í™” ë¡œì§ í‘œì¤€í™”
    """
    
    def __init__(self, **kwargs):
        """í†µí•© ì´ˆê¸°í™”"""
        try:
            # ê¸°ë³¸ ì„¤ì •
            self.config = self._create_config(**kwargs)
            self.step_name = kwargs.get('step_name', self.__class__.__name__)
            self.step_id = kwargs.get('step_id', 0)
            
            # Logger ì„¤ì •
            self.logger = logging.getLogger(f"pipeline.steps.{self.step_name}")
            if not self.logger.handlers:
                handler = logging.StreamHandler()
                formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
                handler.setFormatter(formatter)
                self.logger.addHandler(handler)
                self.logger.setLevel(logging.INFO)
            
            # í†µí•© ì˜ì¡´ì„± ê´€ë¦¬ì
            self.dependency_manager = UnifiedDependencyManager(self.step_name)
            
            # ìƒíƒœ í”Œë˜ê·¸ë“¤
            self.is_initialized = False
            self.is_ready = False
            self.has_model = False
            self.model_loaded = False
            self.warmup_completed = False
            
            # ì‹œìŠ¤í…œ ì •ë³´
            self.device = self._resolve_device(self.config.device)
            self.is_m3_max = self._detect_m3_max()
            self.memory_gb = self._get_memory_info()
            
            # ì„±ëŠ¥ ë©”íŠ¸ë¦­
            self.performance_metrics = {
                'process_count': 0,
                'total_process_time': 0.0,
                'average_process_time': 0.0,
                'error_count': 0,
                'success_count': 0,
                'cache_hits': 0
            }
            
            # í˜¸í™˜ì„±ì„ ìœ„í•œ ì†ì„±ë“¤
            self.model_loader = None
            self.model_interface = None
            self.memory_manager = None
            self.data_converter = None
            self.di_container = None
            
            # ìë™ ì˜ì¡´ì„± ì£¼ì… (ì„¤ì •ëœ ê²½ìš°)
            if self.config.auto_inject_dependencies:
                self.dependency_manager.auto_inject_dependencies()
            
            self.logger.info(f"âœ… {self.step_name} BaseStepMixin v16.0 ì´ˆê¸°í™” ì™„ë£Œ")
            
        except Exception as e:
            self._emergency_setup(e)
    
    def _create_config(self, **kwargs) -> StepConfig:
        """ì„¤ì • ìƒì„±"""
        config = StepConfig()
        for key, value in kwargs.items():
            if hasattr(config, key):
                setattr(config, key, value)
        return config
    
    def _emergency_setup(self, error: Exception):
        """ê¸´ê¸‰ ì„¤ì •"""
        self.step_name = getattr(self, 'step_name', self.__class__.__name__)
        self.logger = logging.getLogger("emergency")
        self.device = "cpu"
        self.is_initialized = False
        self.logger.error(f"ğŸš¨ {self.step_name} ê¸´ê¸‰ ì´ˆê¸°í™”: {error}")
    
    # ==============================================
    # ğŸ”¥ í†µí•© ì˜ì¡´ì„± ì£¼ì… ì¸í„°í˜ì´ìŠ¤
    # ==============================================
    
    def set_model_loader(self, model_loader: 'ModelLoader'):
        """ModelLoader ì˜ì¡´ì„± ì£¼ì… (í‘œì¤€ ì¸í„°í˜ì´ìŠ¤)"""
        success = self.dependency_manager.inject_model_loader(model_loader)
        if success:
            self.model_loader = model_loader
            self.model_interface = self.dependency_manager.get_dependency('step_interface')
            self.has_model = True
            self.model_loaded = True
    
    def set_memory_manager(self, memory_manager: 'MemoryManager'):
        """MemoryManager ì˜ì¡´ì„± ì£¼ì… (í‘œì¤€ ì¸í„°í˜ì´ìŠ¤)"""
        success = self.dependency_manager.inject_memory_manager(memory_manager)
        if success:
            self.memory_manager = memory_manager
    
    def set_data_converter(self, data_converter: 'DataConverter'):
        """DataConverter ì˜ì¡´ì„± ì£¼ì… (í‘œì¤€ ì¸í„°í˜ì´ìŠ¤)"""
        success = self.dependency_manager.inject_data_converter(data_converter)
        if success:
            self.data_converter = data_converter
    
    def set_di_container(self, di_container: 'DIContainer'):
        """DI Container ì˜ì¡´ì„± ì£¼ì… (í‘œì¤€ ì¸í„°í˜ì´ìŠ¤)"""
        success = self.dependency_manager.inject_di_container(di_container)
        if success:
            self.di_container = di_container
    
    # ==============================================
    # ğŸ”¥ í•µì‹¬ ê¸°ëŠ¥ ë©”ì„œë“œë“¤
    # ==============================================
    
    def get_model(self, model_name: Optional[str] = None) -> Optional[Any]:
        """ëª¨ë¸ ê°€ì ¸ì˜¤ê¸° (í†µí•© ì¸í„°í˜ì´ìŠ¤)"""
        try:
            # Step Interface ìš°ì„  ì‚¬ìš©
            step_interface = self.dependency_manager.get_dependency('step_interface')
            if step_interface and hasattr(step_interface, 'get_model_sync'):
                return step_interface.get_model_sync(model_name or "default")
            
            # ModelLoader ì§ì ‘ ì‚¬ìš©
            model_loader = self.dependency_manager.get_dependency('model_loader')
            if model_loader and hasattr(model_loader, 'load_model'):
                return model_loader.load_model(model_name or "default")
            
            self.logger.warning("âš ï¸ ëª¨ë¸ ì œê³µìê°€ ì£¼ì…ë˜ì§€ ì•ŠìŒ")
            return None
            
        except Exception as e:
            self.logger.error(f"âŒ ëª¨ë¸ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {e}")
            return None
    
    async def get_model_async(self, model_name: Optional[str] = None) -> Optional[Any]:
        """ë¹„ë™ê¸° ëª¨ë¸ ê°€ì ¸ì˜¤ê¸° (í†µí•© ì¸í„°í˜ì´ìŠ¤)"""
        try:
            # Step Interface ìš°ì„  ì‚¬ìš©
            step_interface = self.dependency_manager.get_dependency('step_interface')
            if step_interface and hasattr(step_interface, 'get_model_async'):
                return await step_interface.get_model_async(model_name or "default")
            
            # ModelLoader ì§ì ‘ ì‚¬ìš©
            model_loader = self.dependency_manager.get_dependency('model_loader')
            if model_loader and hasattr(model_loader, 'load_model_async'):
                return await model_loader.load_model_async(model_name or "default")
            
            self.logger.warning("âš ï¸ ëª¨ë¸ ì œê³µìê°€ ì£¼ì…ë˜ì§€ ì•ŠìŒ")
            return None
            
        except Exception as e:
            self.logger.error(f"âŒ ë¹„ë™ê¸° ëª¨ë¸ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {e}")
            return None
    
    def optimize_memory(self, aggressive: bool = False) -> Dict[str, Any]:
        """ë©”ëª¨ë¦¬ ìµœì í™” (í†µí•© ì¸í„°í˜ì´ìŠ¤)"""
        try:
            # ì£¼ì…ëœ MemoryManager ìš°ì„  ì‚¬ìš©
            memory_manager = self.dependency_manager.get_dependency('memory_manager')
            if memory_manager and hasattr(memory_manager, 'optimize_memory'):
                return memory_manager.optimize_memory(aggressive=aggressive)
            
            # ë‚´ì¥ ë©”ëª¨ë¦¬ ìµœì í™”
            return self._builtin_memory_optimize(aggressive)
            
        except Exception as e:
            self.logger.error(f"âŒ ë©”ëª¨ë¦¬ ìµœì í™” ì‹¤íŒ¨: {e}")
            return {"success": False, "error": str(e)}
    
    async def optimize_memory_async(self, aggressive: bool = False) -> Dict[str, Any]:
        """ë¹„ë™ê¸° ë©”ëª¨ë¦¬ ìµœì í™” (í†µí•© ì¸í„°í˜ì´ìŠ¤)"""
        try:
            # ì£¼ì…ëœ MemoryManager ìš°ì„  ì‚¬ìš©
            memory_manager = self.dependency_manager.get_dependency('memory_manager')
            if memory_manager and hasattr(memory_manager, 'optimize_memory_async'):
                return await memory_manager.optimize_memory_async(aggressive=aggressive)
            
            # ë™ê¸° ë©”ëª¨ë¦¬ ìµœì í™”ë¥¼ ë¹„ë™ê¸°ë¡œ ì‹¤í–‰
            loop = asyncio.get_event_loop()
            return await loop.run_in_executor(None, self._builtin_memory_optimize, aggressive)
            
        except Exception as e:
            self.logger.error(f"âŒ ë¹„ë™ê¸° ë©”ëª¨ë¦¬ ìµœì í™” ì‹¤íŒ¨: {e}")
            return {"success": False, "error": str(e)}
    
    # ==============================================
    # ğŸ”¥ í‘œì¤€í™”ëœ ì´ˆê¸°í™” ë° ì›Œë°ì—…
    # ==============================================
    
    def initialize(self) -> bool:
        """í‘œì¤€í™”ëœ ì´ˆê¸°í™”"""
        try:
            if self.is_initialized:
                return True
            
            # í•„ìˆ˜ ì˜ì¡´ì„± í™•ì¸
            if not self.dependency_manager.check_required_dependencies(self.config):
                if self.config.strict_mode:
                    raise RuntimeError("í•„ìˆ˜ ì˜ì¡´ì„±ì´ ì£¼ì…ë˜ì§€ ì•ŠìŒ")
                else:
                    self.logger.warning("âš ï¸ ì¼ë¶€ ì˜ì¡´ì„±ì´ ëˆ„ë½ë¨")
            
            # ì´ˆê¸°í™” ìƒíƒœ ì„¤ì •
            self.dependency_manager.dependency_status.base_initialized = True
            self.is_initialized = True
            
            self.logger.info(f"âœ… {self.step_name} í‘œì¤€í™”ëœ ì´ˆê¸°í™” ì™„ë£Œ")
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return False
    
    async def initialize_async(self) -> bool:
        """ë¹„ë™ê¸° ì´ˆê¸°í™”"""
        try:
            loop = asyncio.get_event_loop()
            return await loop.run_in_executor(None, self.initialize)
        except Exception as e:
            self.logger.error(f"âŒ ë¹„ë™ê¸° ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return False
    
    def warmup(self) -> Dict[str, Any]:
        """í‘œì¤€í™”ëœ ì›Œë°ì—…"""
        try:
            if self.warmup_completed:
                return {'success': True, 'message': 'ì´ë¯¸ ì›Œë°ì—… ì™„ë£Œë¨', 'cached': True}
            
            self.logger.info(f"ğŸ”¥ {self.step_name} í‘œì¤€í™”ëœ ì›Œë°ì—… ì‹œì‘...")
            start_time = time.time()
            results = []
            
            # 1. ë©”ëª¨ë¦¬ ì›Œë°ì—…
            try:
                memory_result = self.optimize_memory()
                results.append('memory_success' if memory_result.get('success') else 'memory_failed')
            except:
                results.append('memory_failed')
            
            # 2. ëª¨ë¸ ì›Œë°ì—…
            try:
                test_model = self.get_model("warmup_test")
                results.append('model_success' if test_model else 'model_skipped')
            except:
                results.append('model_failed')
            
            # 3. ë””ë°”ì´ìŠ¤ ì›Œë°ì—…
            try:
                if TORCH_AVAILABLE:
                    test_tensor = torch.randn(10, 10)
                    if self.device != 'cpu':
                        test_tensor = test_tensor.to(self.device)
                    _ = torch.matmul(test_tensor, test_tensor.t())
                    results.append('device_success')
                else:
                    results.append('device_skipped')
            except:
                results.append('device_failed')
            
            duration = time.time() - start_time
            success_count = sum(1 for r in results if 'success' in r)
            overall_success = success_count > 0
            
            if overall_success:
                self.warmup_completed = True
                self.is_ready = True
            
            self.logger.info(f"ğŸ”¥ í‘œì¤€í™”ëœ ì›Œë°ì—… ì™„ë£Œ: {success_count}/{len(results)} ì„±ê³µ ({duration:.2f}ì´ˆ)")
            
            return {
                "success": overall_success,
                "duration": duration,
                "results": results,
                "success_count": success_count,
                "total_count": len(results)
            }
            
        except Exception as e:
            self.logger.error(f"âŒ ì›Œë°ì—… ì‹¤íŒ¨: {e}")
            return {"success": False, "error": str(e)}
    
    async def warmup_async(self) -> Dict[str, Any]:
        """ë¹„ë™ê¸° ì›Œë°ì—…"""
        try:
            loop = asyncio.get_event_loop()
            return await loop.run_in_executor(None, self.warmup)
        except Exception as e:
            self.logger.error(f"âŒ ë¹„ë™ê¸° ì›Œë°ì—… ì‹¤íŒ¨: {e}")
            return {"success": False, "error": str(e)}
    
    # ==============================================
    # ğŸ”¥ ìƒíƒœ ë° ì •ë¦¬ ë©”ì„œë“œë“¤
    # ==============================================
    
    def get_status(self) -> Dict[str, Any]:
        """í†µí•© ìƒíƒœ ì¡°íšŒ"""
        try:
            return {
                'step_name': self.step_name,
                'step_id': self.step_id,
                'is_initialized': self.is_initialized,
                'is_ready': self.is_ready,
                'has_model': self.has_model,
                'model_loaded': self.model_loaded,
                'warmup_completed': self.warmup_completed,
                'device': self.device,
                'is_m3_max': self.is_m3_max,
                'memory_gb': self.memory_gb,
                'dependencies': {
                    'model_loader': self.dependency_manager.dependency_status.model_loader,
                    'step_interface': self.dependency_manager.dependency_status.step_interface,
                    'memory_manager': self.dependency_manager.dependency_status.memory_manager,
                    'data_converter': self.dependency_manager.dependency_status.data_converter,
                    'di_container': self.dependency_manager.dependency_status.di_container,
                },
                'performance_metrics': self.performance_metrics,
                'config': self.config.__dict__,
                'version': '16.0-unified',
                'timestamp': time.time()
            }
        except Exception as e:
            self.logger.error(f"âŒ ìƒíƒœ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {'error': str(e), 'version': '16.0-unified'}
    
    async def cleanup(self) -> Dict[str, Any]:
        """í‘œì¤€í™”ëœ ì •ë¦¬"""
        try:
            self.logger.info(f"ğŸ§¹ {self.step_name} í‘œì¤€í™”ëœ ì •ë¦¬ ì‹œì‘...")
            
            # ë©”ëª¨ë¦¬ ì •ë¦¬
            cleanup_result = await self.optimize_memory_async(aggressive=True)
            
            # ìƒíƒœ ë¦¬ì…‹
            self.is_ready = False
            self.warmup_completed = False
            self.has_model = False
            self.model_loaded = False
            
            # ì˜ì¡´ì„± í•´ì œ (ì°¸ì¡°ë§Œ ì œê±°)
            self.model_loader = None
            self.model_interface = None
            self.memory_manager = None
            self.data_converter = None
            self.di_container = None
            
            self.logger.info(f"âœ… {self.step_name} í‘œì¤€í™”ëœ ì •ë¦¬ ì™„ë£Œ")
            
            return {
                "success": True,
                "cleanup_result": cleanup_result,
                "step_name": self.step_name,
                "version": "16.0-unified"
            }
        except Exception as e:
            self.logger.error(f"âŒ ì •ë¦¬ ì‹¤íŒ¨: {e}")
            return {"success": False, "error": str(e)}
    
    # ==============================================
    # ğŸ”¥ ë‚´ë¶€ ìœ í‹¸ë¦¬í‹° ë©”ì„œë“œë“¤
    # ==============================================
    
    def _resolve_device(self, device: str) -> str:
        """ë””ë°”ì´ìŠ¤ í•´ê²°"""
        if device == "auto":
            if TORCH_AVAILABLE:
                if MPS_AVAILABLE:
                    return "mps"
                elif torch.cuda.is_available():
                    return "cuda"
            return "cpu"
        return device
    
    def _detect_m3_max(self) -> bool:
        """M3 Max ê°ì§€"""
        try:
            import platform
            import subprocess
            if platform.system() == 'Darwin':
                result = subprocess.run(
                    ['sysctl', '-n', 'machdep.cpu.brand_string'],
                    capture_output=True, text=True, timeout=5
                )
                return 'M3' in result.stdout
        except:
            pass
        return False
    
    def _get_memory_info(self) -> float:
        """ë©”ëª¨ë¦¬ ì •ë³´ ì¡°íšŒ"""
        try:
            import psutil
            memory = psutil.virtual_memory()
            return memory.total / 1024**3
        except:
            return 16.0
    
    def _builtin_memory_optimize(self, aggressive: bool = False) -> Dict[str, Any]:
        """ë‚´ì¥ ë©”ëª¨ë¦¬ ìµœì í™”"""
        try:
            results = []
            
            # Python GC
            before = len(gc.get_objects()) if hasattr(gc, 'get_objects') else 0
            gc.collect()
            after = len(gc.get_objects()) if hasattr(gc, 'get_objects') else 0
            results.append(f"Python GC: {before - after}ê°œ ê°ì²´ í•´ì œ")
            
            # PyTorch ë©”ëª¨ë¦¬ ì •ë¦¬
            if TORCH_AVAILABLE:
                if self.device == "cuda" and torch.cuda.is_available():
                    torch.cuda.empty_cache()
                    results.append("CUDA ìºì‹œ ì •ë¦¬")
                elif self.device == "mps" and MPS_AVAILABLE:
                    try:
                        if hasattr(torch.mps, 'empty_cache'):
                            torch.mps.empty_cache()
                        results.append("MPS ìºì‹œ ì •ë¦¬")
                    except:
                        results.append("MPS ìºì‹œ ì •ë¦¬ ì‹œë„")
            
            # M3 Max íŠ¹ë³„ ìµœì í™”
            if self.is_m3_max and aggressive:
                for _ in range(3):
                    gc.collect()
                results.append("M3 Max í†µí•© ë©”ëª¨ë¦¬ ìµœì í™”")
            
            return {
                "success": True,
                "results": results,
                "device": self.device,
                "is_m3_max": self.is_m3_max,
                "source": "builtin"
            }
            
        except Exception as e:
            return {"success": False, "error": str(e), "source": "builtin"}

# ==============================================
# ğŸ”¥ Stepë³„ íŠ¹í™” Mixinë“¤
# ==============================================

class HumanParsingMixin(BaseStepMixin):
    """Step 1: Human Parsing íŠ¹í™” Mixin"""
    
    def __init__(self, **kwargs):
        kwargs.setdefault('step_name', 'HumanParsingStep')
        kwargs.setdefault('step_id', 1)
        super().__init__(**kwargs)
        
        self.num_classes = 20
        self.parsing_categories = [
            'background', 'hat', 'hair', 'glove', 'sunglasses', 'upperclothes',
            'dress', 'coat', 'socks', 'pants', 'jumpsuits', 'scarf', 'skirt',
            'face', 'left_arm', 'right_arm', 'left_leg', 'right_leg', 'left_shoe', 'right_shoe'
        ]

class PoseEstimationMixin(BaseStepMixin):
    """Step 2: Pose Estimation íŠ¹í™” Mixin"""
    
    def __init__(self, **kwargs):
        kwargs.setdefault('step_name', 'PoseEstimationStep')
        kwargs.setdefault('step_id', 2)
        super().__init__(**kwargs)
        
        self.num_keypoints = 18
        self.keypoint_names = [
            'nose', 'neck', 'right_shoulder', 'right_elbow', 'right_wrist',
            'left_shoulder', 'left_elbow', 'left_wrist', 'right_hip', 'right_knee',
            'right_ankle', 'left_hip', 'left_knee', 'left_ankle', 'right_eye',
            'left_eye', 'right_ear', 'left_ear'
        ]

class ClothSegmentationMixin(BaseStepMixin):
    """Step 3: Cloth Segmentation íŠ¹í™” Mixin"""
    
    def __init__(self, **kwargs):
        kwargs.setdefault('step_name', 'ClothSegmentationStep')
        kwargs.setdefault('step_id', 3)
        super().__init__(**kwargs)
        
        self.segmentation_methods = ['traditional', 'u2net', 'deeplab', 'auto', 'hybrid']

class GeometricMatchingMixin(BaseStepMixin):
    """Step 4: Geometric Matching íŠ¹í™” Mixin"""
    
    def __init__(self, **kwargs):
        kwargs.setdefault('step_name', 'GeometricMatchingStep')
        kwargs.setdefault('step_id', 4)
        super().__init__(**kwargs)
        
        self.matching_methods = ['thin_plate_spline', 'affine', 'perspective', 'flow_based']

class ClothWarpingMixin(BaseStepMixin):
    """Step 5: Cloth Warping íŠ¹í™” Mixin"""
    
    def __init__(self, **kwargs):
        kwargs.setdefault('step_name', 'ClothWarpingStep')
        kwargs.setdefault('step_id', 5)
        super().__init__(**kwargs)

class VirtualFittingMixin(BaseStepMixin):
    """Step 6: Virtual Fitting íŠ¹í™” Mixin"""
    
    def __init__(self, **kwargs):
        kwargs.setdefault('step_name', 'VirtualFittingStep')
        kwargs.setdefault('step_id', 6)
        super().__init__(**kwargs)
        
        self.fitting_modes = ['standard', 'high_quality', 'fast', 'experimental']

class PostProcessingMixin(BaseStepMixin):
    """Step 7: Post Processing íŠ¹í™” Mixin"""
    
    def __init__(self, **kwargs):
        kwargs.setdefault('step_name', 'PostProcessingStep')
        kwargs.setdefault('step_id', 7)
        super().__init__(**kwargs)
        
        self.processing_methods = ['super_resolution', 'denoising', 'color_correction', 'sharpening']

class QualityAssessmentMixin(BaseStepMixin):
    """Step 8: Quality Assessment íŠ¹í™” Mixin"""
    
    def __init__(self, **kwargs):
        kwargs.setdefault('step_name', 'QualityAssessmentStep')
        kwargs.setdefault('step_id', 8)
        super().__init__(**kwargs)
        
        self.assessment_criteria = ['perceptual_quality', 'technical_quality', 'aesthetic_quality']

# ==============================================
# ğŸ”¥ í¸ì˜ í•¨ìˆ˜ë“¤
# ==============================================

def create_step_mixin(step_name: str, step_id: int, **kwargs) -> BaseStepMixin:
    """í†µí•© BaseStepMixin ì¸ìŠ¤í„´ìŠ¤ ìƒì„±"""
    kwargs.update({'step_name': step_name, 'step_id': step_id})
    return BaseStepMixin(**kwargs)

def create_human_parsing_step(**kwargs) -> HumanParsingMixin:
    """Human Parsing Step ìƒì„±"""
    return HumanParsingMixin(**kwargs)

def create_pose_estimation_step(**kwargs) -> PoseEstimationMixin:
    """Pose Estimation Step ìƒì„±"""
    return PoseEstimationMixin(**kwargs)

def create_cloth_segmentation_step(**kwargs) -> ClothSegmentationMixin:
    """Cloth Segmentation Step ìƒì„±"""
    return ClothSegmentationMixin(**kwargs)

def create_geometric_matching_step(**kwargs) -> GeometricMatchingMixin:
    """Geometric Matching Step ìƒì„±"""
    return GeometricMatchingMixin(**kwargs)

def create_cloth_warping_step(**kwargs) -> ClothWarpingMixin:
    """Cloth Warping Step ìƒì„±"""
    return ClothWarpingMixin(**kwargs)

def create_virtual_fitting_step(**kwargs) -> VirtualFittingMixin:
    """Virtual Fitting Step ìƒì„±"""
    return VirtualFittingMixin(**kwargs)

def create_post_processing_step(**kwargs) -> PostProcessingMixin:
    """Post Processing Step ìƒì„±"""
    return PostProcessingMixin(**kwargs)

def create_quality_assessment_step(**kwargs) -> QualityAssessmentMixin:
    """Quality Assessment Step ìƒì„±"""
    return QualityAssessmentMixin(**kwargs)

# ==============================================
# ğŸ”¥ Export
# ==============================================

__all__ = [
    # ë©”ì¸ í´ë˜ìŠ¤ë“¤
    'BaseStepMixin',
    'UnifiedDependencyManager',
    'StepConfig',
    'DependencyStatus',
    
    # ì¸í„°í˜ì´ìŠ¤ë“¤
    'IModelProvider',
    'IMemoryManager',
    'IDataConverter',
    
    # Stepë³„ íŠ¹í™” Mixinë“¤
    'HumanParsingMixin',
    'PoseEstimationMixin',
    'ClothSegmentationMixin',
    'GeometricMatchingMixin',
    'ClothWarpingMixin',
    'VirtualFittingMixin',
    'PostProcessingMixin',
    'QualityAssessmentMixin',
    
    # í¸ì˜ í•¨ìˆ˜ë“¤
    'create_step_mixin',
    'create_human_parsing_step',
    'create_pose_estimation_step',
    'create_cloth_segmentation_step',
    'create_geometric_matching_step',
    'create_cloth_warping_step',
    'create_virtual_fitting_step',
    'create_post_processing_step',
    'create_quality_assessment_step',
    
    # ìƒìˆ˜ë“¤
    'TORCH_AVAILABLE',
    'MPS_AVAILABLE',
    'NUMPY_AVAILABLE',
    'PIL_AVAILABLE'
]

# ëª¨ë“ˆ ë¡œë“œ ì™„ë£Œ
logger = logging.getLogger(__name__)
logger.info("=" * 80)
logger.info("ğŸ”¥ BaseStepMixin v16.0 - ìˆœí™˜ì°¸ì¡° ì™„ì „ í•´ê²° + í†µí•© ì˜ì¡´ì„± ì£¼ì…")
logger.info("=" * 80)
logger.info("âœ… TYPE_CHECKING íŒ¨í„´ìœ¼ë¡œ ìˆœí™˜ì°¸ì¡° ì™„ì „ ë°©ì§€")
logger.info("âœ… í†µí•©ëœ ì˜ì¡´ì„± ì£¼ì… ì¸í„°í˜ì´ìŠ¤")
logger.info("âœ… ëª¨ë“  Step í´ë˜ìŠ¤ í˜¸í™˜ì„± ë³´ì¥")
logger.info("âœ… ì´ˆê¸°í™” ë¡œì§ í‘œì¤€í™”")
logger.info("âœ… UnifiedDependencyManager ë„ì…")
logger.info("âœ… ìë™ ì˜ì¡´ì„± ì£¼ì… ì‹œìŠ¤í…œ")
logger.info("âœ… í”„ë¡œë•ì…˜ ë ˆë²¨ ì•ˆì •ì„±")
logger.info("=" * 80)