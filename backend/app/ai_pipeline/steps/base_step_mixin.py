# backend/app/ai_pipeline/steps/base_step_mixin.py
"""
ğŸ”¥ BaseStepMixin v10.1 - ì™„ì „í•œ í†µí•© ë²„ì „ (ê¸°ì¡´ + ì‹ ê·œ ê¸°ëŠ¥ 100% í†µí•©)
====================================================================

âœ… ë¹„ë™ê¸° ì²˜ë¦¬ ì™„ì „ í•´ê²° (coroutine ê²½ê³  ì™„ì „ ì œê±°)
âœ… from functools import wraps ì¶”ê°€ (NameError í•´ê²°)
âœ… ì˜ì¡´ì„± ì£¼ì… íŒ¨í„´ ì™„ì „ ì ìš©
âœ… ê¸°ì¡´ ëª¨ë“  ê¸°ëŠ¥ 100% ìœ ì§€
âœ… logger ì†ì„± ëˆ„ë½ ë¬¸ì œ ê·¼ë³¸ í•´ê²°
âœ… _emergency_initialization ë©”ì„œë“œ ì™„ì „ êµ¬í˜„
âœ… 89.8GB ì²´í¬í¬ì¸íŠ¸ ìë™ íƒì§€ ë° í™œìš©
âœ… ModelLoader ì—°ë™ ì™„ì „ ìë™í™”
âœ… SafeFunctionValidator í†µí•©
âœ… M3 Max 128GB ìµœì í™”
âœ… ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ
âœ… ë©”ëª¨ë¦¬ ìµœì í™” ì‹œìŠ¤í…œ
âœ… ì›Œë°ì—… ì‹œìŠ¤í…œ
âœ… ì—ëŸ¬ ë³µêµ¬ ì‹œìŠ¤í…œ
âœ… ì²´í¬í¬ì¸íŠ¸ ê´€ë¦¬ ì‹œìŠ¤í…œ
âœ… ë¹„ë™ê¸° ì²˜ë¦¬ ì™„ì „ ì§€ì› (coroutine ê²½ê³  í•´ê²°)
âœ… ìˆœí™˜ ì„í¬íŠ¸ ì™„ì „ í•´ê²°
âœ… ëª¨ë“  ëˆ„ë½ ë©”ì„œë“œ êµ¬í˜„

Author: MyCloset AI Team
Date: 2025-07-20
Version: 10.1 (Complete Integration)
"""

# ==============================================
# ğŸ”¥ 1. í‘œì¤€ ë¼ì´ë¸ŒëŸ¬ë¦¬ Import (ìµœìš°ì„ )
# ==============================================
import os
import gc
import time
import asyncio
import logging
import threading
import traceback
import weakref
from pathlib import Path
from typing import Dict, Any, Optional, Union, List, Type, Callable, Tuple, TYPE_CHECKING, Awaitable
from abc import ABC, abstractmethod
from dataclasses import dataclass, field
from concurrent.futures import ThreadPoolExecutor
from functools import wraps, lru_cache  # âœ… ëˆ„ë½ëœ import ì¶”ê°€
import hashlib
import json
import pickle
import sys
import platform
import subprocess
import psutil
from datetime import datetime
from enum import Enum

# GPU ì„¤ì • ì•ˆì „ import
try:
    from app.core.gpu_config import safe_mps_empty_cache
except ImportError:
    # í´ë°± í•¨ìˆ˜
    def safe_mps_empty_cache():
        import gc
        gc.collect()
        return {"success": True, "method": "fallback_gc"}

# ==============================================
# ğŸ”¥ 2. TYPE_CHECKINGìœ¼ë¡œ ìˆœí™˜ ì„í¬íŠ¸ ì™„ì „ ë°©ì§€
# ==============================================

if TYPE_CHECKING:
    # íƒ€ì… ì²´í‚¹ ì‹œì—ë§Œ ì„í¬íŠ¸ (ëŸ°íƒ€ì„ì—ëŠ” ì„í¬íŠ¸ ì•ˆë¨)
    from ..interfaces.model_interface import IModelLoader, IStepInterface
    from ..interfaces.memory_interface import IMemoryManager
    from ..interfaces.data_interface import IDataConverter
    from ...core.di_container import DIContainer

# ==============================================
# ğŸ”¥ 3. NumPy 2.x í˜¸í™˜ì„± ë¬¸ì œ ì™„ì „ í•´ê²°
# ==============================================

try:
    import numpy as np
    numpy_version = np.__version__
    major_version = int(numpy_version.split('.')[0])
    
    if major_version >= 2:
        logging.warning(f"âš ï¸ NumPy {numpy_version} ê°ì§€. conda install numpy=1.24.3 ê¶Œì¥")
        # NumPy 2.x í˜¸í™˜ì„± ì„¤ì •
        try:
            np.set_printoptions(legacy='1.25')
        except:
            pass
    
    NUMPY_AVAILABLE = True
except ImportError:
    NUMPY_AVAILABLE = False
    logging.warning("âš ï¸ NumPy ì—†ìŒ")

# PyTorch ì•ˆì „ Import (MPS ì˜¤ë¥˜ ë°©ì§€)
TORCH_AVAILABLE = False
MPS_AVAILABLE = False
try:
    os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '1'
    os.environ['PYTORCH_MPS_HIGH_WATERMARK_RATIO'] = '0.0'
    
    import torch
    import torch.nn as nn
    import torch.nn.functional as F
    
    TORCH_AVAILABLE = True
    
    if hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
        MPS_AVAILABLE = True
        logging.info("âœ… M3 Max MPS ì‚¬ìš© ê°€ëŠ¥")
    
except ImportError:
    logging.warning("âš ï¸ PyTorch ì—†ìŒ")

# PIL ì•ˆì „ Import
PIL_AVAILABLE = False
try:
    from PIL import Image, ImageEnhance, ImageFilter
    PIL_AVAILABLE = True
except ImportError:
    logging.warning("âš ï¸ PIL ì—†ìŒ")

# ==============================================
# ğŸ”¥ 4. ì•ˆì „í•œ ë¹„ë™ê¸° ë˜í¼ í•¨ìˆ˜ (í•µì‹¬)
# ==============================================

def safe_async_wrapper(func):
    """ë¹„ë™ê¸° í•¨ìˆ˜ë¥¼ ì•ˆì „í•˜ê²Œ ë˜í•‘ - coroutine ê²½ê³  ì™„ì „ í•´ê²°"""
    @wraps(func)
    def wrapper(self, *args, **kwargs):
        try:
            # ì´ë²¤íŠ¸ ë£¨í”„ í™•ì¸
            try:
                loop = asyncio.get_running_loop()
                in_event_loop = True
            except RuntimeError:
                in_event_loop = False
            
            if in_event_loop:
                # ì´ë²¤íŠ¸ ë£¨í”„ ë‚´ì—ì„œëŠ” ë™ê¸° ë²„ì „ ì‹¤í–‰
                logger = getattr(self, 'logger', logging.getLogger(self.__class__.__name__))
                logger.debug(f"âš ï¸ ì‹¤í–‰ ì¤‘ì¸ ì´ë²¤íŠ¸ ë£¨í”„ì—ì„œ {func.__name__} ë™ê¸° ì‹¤í–‰")
                return self._sync_fallback(func.__name__, *args, **kwargs)
            else:
                # ì´ë²¤íŠ¸ ë£¨í”„ ë°–ì—ì„œëŠ” ë¹„ë™ê¸° ì‹¤í–‰
                return asyncio.run(func(self, *args, **kwargs))
        
        except Exception as e:
            logger = getattr(self, 'logger', logging.getLogger(self.__class__.__name__))
            logger.warning(f"âš ï¸ {func.__name__} ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            return self._sync_fallback(func.__name__, *args, **kwargs)
    
    return wrapper

# ==============================================
# ğŸ”¥ 5. ì•ˆì „í•œ ì„¤ì • ê´€ë¦¬ í´ë˜ìŠ¤
# ==============================================

class SafeConfig:
    """ì•ˆì „í•œ ì„¤ì • ê´€ë¦¬ì"""
    
    def __init__(self, config_data: Optional[Dict[str, Any]] = None, **kwargs):  # âœ… **kwargs ì¶”ê°€
        self._data = config_data or {}
        self._lock = threading.RLock()
        
        # ê¸°ë³¸ ì„¤ì •ê°’ë“¤ (kwargsì—ì„œ ê°€ì ¸ì˜¤ê¸°)
        self.strict_mode = kwargs.get('strict_mode', True)
        self.fallback_enabled = kwargs.get('fallback_enabled', False)
        self.real_ai_only = kwargs.get('real_ai_only', True)
        self.confidence_threshold = kwargs.get('confidence_threshold', 0.8)
        self.visualization_enabled = kwargs.get('visualization_enabled', True)
        self.return_analysis = kwargs.get('return_analysis', True)
        self.cache_enabled = kwargs.get('cache_enabled', True)
        self.detailed_analysis = kwargs.get('detailed_analysis', True)
       
        # ì„¤ì • ê²€ì¦ ë° ì†ì„± ìë™ ì„¤ì •
        with self._lock:
            for key, value in self._data.items():
                if isinstance(key, str) and key.isidentifier() and not callable(value):
                    try:
                        setattr(self, key, value)
                    except Exception:
                        pass
    
    def get(self, key: str, default: Any = None) -> Any:
        """ì•ˆì „í•œ ê°’ ì¡°íšŒ"""
        try:
            with self._lock:
                return self._data.get(key, default)
        except Exception:
            return default
    
    def set(self, key: str, value: Any):
        """ì•ˆì „í•œ ê°’ ì„¤ì •"""
        try:
            with self._lock:
                if not callable(value):
                    self._data[key] = value
                    if isinstance(key, str) and key.isidentifier():
                        setattr(self, key, value)
        except Exception:
            pass
    
    def __getitem__(self, key):
        try:
            return self._data[key]
        except KeyError:
            raise KeyError(f"ì„¤ì • í‚¤ '{key}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        except Exception as e:
            logging.debug(f"SafeConfig.__getitem__ ì˜¤ë¥˜: {e}")
            raise
    
    def __setitem__(self, key, value):
        try:
            self.set(key, value)
        except Exception as e:
            logging.debug(f"SafeConfig.__setitem__ ì˜¤ë¥˜: {e}")
    
    def __contains__(self, key):
        try:
            return key in self._data
        except:
            return False
    
    def keys(self):
        try:
            return self._data.keys()
        except:
            return []
    
    def values(self):
        try:
            return self._data.values()
        except:
            return []
    
    def items(self):
        try:
            return self._data.items()
        except:
            return []
    
    def update(self, other):
        try:
            with self._lock:
                if isinstance(other, dict):
                    for key, value in other.items():
                        if not callable(value):
                            self._data[key] = value
                            if isinstance(key, str) and key.isidentifier():
                                setattr(self, key, value)
        except Exception as e:
            logging.debug(f"SafeConfig.update ì˜¤ë¥˜: {e}")
    
    def to_dict(self):
        try:
            with self._lock:
                return self._data.copy()
        except:
            return {}

# ==============================================
# ğŸ”¥ 6. ì²´í¬í¬ì¸íŠ¸ ê´€ë¦¬ ì‹œìŠ¤í…œ
# ==============================================

@dataclass
class CheckpointInfo:
    """ì²´í¬í¬ì¸íŠ¸ ì •ë³´"""
    name: str
    path: str
    size_gb: float
    model_type: str
    step_compatible: List[str]
    last_modified: datetime
    hash_md5: Optional[str] = None
    metadata: Dict[str, Any] = field(default_factory=dict)

class CheckpointManager:
    """ì²´í¬í¬ì¸íŠ¸ ê´€ë¦¬ì"""
    
    def __init__(self, model_dir: str = "/Users/gimdudeul/MVP/mycloset-ai/backend/ai_models"):
        self.model_dir = Path(model_dir)
        self.logger = logging.getLogger(f"{__name__}.CheckpointManager")
        self.checkpoints: Dict[str, CheckpointInfo] = {}
        self._scan_lock = threading.Lock()
        
    def scan_checkpoints(self) -> Dict[str, CheckpointInfo]:
        """ì²´í¬í¬ì¸íŠ¸ ìŠ¤ìº”"""
        try:
            with self._scan_lock:
                self.checkpoints.clear()
                
                if not self.model_dir.exists():
                    self.logger.warning(f"ëª¨ë¸ ë””ë ‰í† ë¦¬ ì—†ìŒ: {self.model_dir}")
                    return {}
                
                # .pth íŒŒì¼ë“¤ ìŠ¤ìº”
                for pth_file in self.model_dir.rglob("*.pth"):
                    try:
                        stat = pth_file.stat()
                        size_gb = stat.st_size / (1024**3)
                        
                        checkpoint_info = CheckpointInfo(
                            name=pth_file.stem,
                            path=str(pth_file),
                            size_gb=size_gb,
                            model_type=self._detect_model_type(pth_file.name),
                            step_compatible=self._get_compatible_steps(pth_file.name),
                            last_modified=datetime.fromtimestamp(stat.st_mtime)
                        )
                        
                        self.checkpoints[checkpoint_info.name] = checkpoint_info
                        
                        if size_gb > 1.0:  # 1GB ì´ìƒë§Œ ë¡œê¹…
                            self.logger.info(f"ğŸ“¦ ì²´í¬í¬ì¸íŠ¸ ë°œê²¬: {checkpoint_info.name} ({size_gb:.1f}GB)")
                            
                    except Exception as e:
                        self.logger.warning(f"ì²´í¬í¬ì¸íŠ¸ ìŠ¤ìº” ì‹¤íŒ¨ {pth_file}: {e}")
                
                self.logger.info(f"âœ… ì²´í¬í¬ì¸íŠ¸ ìŠ¤ìº” ì™„ë£Œ: {len(self.checkpoints)}ê°œ ë°œê²¬")
                return self.checkpoints
                
        except Exception as e:
            self.logger.error(f"âŒ ì²´í¬í¬ì¸íŠ¸ ìŠ¤ìº” ì‹¤íŒ¨: {e}")
            return {}
    
    def _detect_model_type(self, filename: str) -> str:
        """íŒŒì¼ëª…ìœ¼ë¡œ ëª¨ë¸ íƒ€ì… ê°ì§€"""
        filename_lower = filename.lower()
        
        if any(keyword in filename_lower for keyword in ['schp', 'graphonomy', 'parsing']):
            return "human_parsing"
        elif any(keyword in filename_lower for keyword in ['openpose', 'pose']):
            return "pose_estimation"
        elif any(keyword in filename_lower for keyword in ['u2net', 'cloth', 'segment']):
            return "cloth_segmentation"
        elif any(keyword in filename_lower for keyword in ['geometric', 'gmm']):
            return "geometric_matching"
        elif any(keyword in filename_lower for keyword in ['warp', 'tps']):
            return "cloth_warping"
        elif any(keyword in filename_lower for keyword in ['ootd', 'diffusion', 'fitting']):
            return "virtual_fitting"
        elif any(keyword in filename_lower for keyword in ['esrgan', 'super', 'enhance']):
            return "post_processing"
        elif any(keyword in filename_lower for keyword in ['clip', 'quality']):
            return "quality_assessment"
        else:
            return "unknown"
    
    def _get_compatible_steps(self, filename: str) -> List[str]:
        """í˜¸í™˜ ê°€ëŠ¥í•œ Step ëª©ë¡"""
        model_type = self._detect_model_type(filename)
        
        step_mapping = {
            "human_parsing": ["HumanParsingStep"],
            "pose_estimation": ["PoseEstimationStep"],
            "cloth_segmentation": ["ClothSegmentationStep"],
            "geometric_matching": ["GeometricMatchingStep"],
            "cloth_warping": ["ClothWarpingStep"],
            "virtual_fitting": ["VirtualFittingStep"],
            "post_processing": ["PostProcessingStep"],
            "quality_assessment": ["QualityAssessmentStep"],
            "unknown": []
        }
        
        return step_mapping.get(model_type, [])
    
    def get_checkpoint_for_step(self, step_name: str) -> Optional[CheckpointInfo]:
        """Stepì— ì í•©í•œ ì²´í¬í¬ì¸íŠ¸ ì°¾ê¸°"""
        try:
            compatible_checkpoints = [
                checkpoint for checkpoint in self.checkpoints.values()
                if step_name in checkpoint.step_compatible
            ]
            
            if compatible_checkpoints:
                # í¬ê¸°ê°€ í° ê²ƒ ìš°ì„  (ë” ì„±ëŠ¥ ì¢‹ì„ ê°€ëŠ¥ì„±)
                return max(compatible_checkpoints, key=lambda x: x.size_gb)
            
            return None
            
        except Exception as e:
            self.logger.error(f"Step ì²´í¬í¬ì¸íŠ¸ ì°¾ê¸° ì‹¤íŒ¨ {step_name}: {e}")
            return None

# ==============================================
# ğŸ”¥ 7. ì˜ì¡´ì„± ì£¼ì… ë„ìš°ë¯¸ í´ë˜ìŠ¤
# ==============================================

class DIHelper:
    """ì˜ì¡´ì„± ì£¼ì… ë„ìš°ë¯¸ - DI Container v2.0 ì™„ë²½ í˜¸í™˜"""
    
    @staticmethod
    def get_di_container() -> Optional['DIContainer']:
        """DI Container ì•ˆì „í•˜ê²Œ ê°€ì ¸ì˜¤ê¸°"""
        try:
            from ...core.di_container import get_di_container
            return get_di_container()
        except ImportError:
            logging.debug("DI Container ëª¨ë“ˆ ì—†ìŒ")
            return None
        except Exception as e:
            logging.warning(f"âš ï¸ DI Container ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {e}")
            return None
    
    @staticmethod
    def inject_model_loader(instance) -> bool:
        """ModelLoader ì£¼ì…"""
        try:
            container = DIHelper.get_di_container()
            if container:
                model_loader = container.get('IModelLoader')
                if model_loader:
                    instance.model_loader = model_loader
                    return True
            
            # í´ë°±: ì§ì ‘ import
            try:
                from ..utils.model_loader import get_global_model_loader
                raw_loader = get_global_model_loader()
                instance.model_loader = raw_loader
                return True
            except ImportError:
                pass
            
            return False
        except Exception as e:
            logging.warning(f"âš ï¸ ModelLoader ì£¼ì… ì‹¤íŒ¨: {e}")
            return False
    
    @staticmethod
    def inject_memory_manager(instance) -> bool:
        """MemoryManager ì£¼ì…"""
        try:
            container = DIHelper.get_di_container()
            if container:
                memory_manager = container.get('IMemoryManager')
                if memory_manager:
                    instance.memory_manager = memory_manager
                    return True
            
            # í´ë°±: ë‚´ì¥ ë©”ëª¨ë¦¬ ìµœì í™” ì‚¬ìš©
            return False
        except Exception as e:
            logging.warning(f"âš ï¸ MemoryManager ì£¼ì… ì‹¤íŒ¨: {e}")
            return False
    
    @staticmethod
    def inject_data_converter(instance) -> bool:
        """DataConverter ì£¼ì…"""
        try:
            container = DIHelper.get_di_container()
            if container:
                data_converter = container.get('IDataConverter')
                if data_converter:
                    instance.data_converter = data_converter
                    return True
            
            return False
        except Exception as e:
            logging.warning(f"âš ï¸ DataConverter ì£¼ì… ì‹¤íŒ¨: {e}")
            return False
    
    @staticmethod
    def inject_all_dependencies(instance) -> Dict[str, bool]:
        """ëª¨ë“  ì˜ì¡´ì„± ì£¼ì…"""
        try:
            results = {}
            
            # ModelLoader ì£¼ì…
            results['model_loader'] = DIHelper.inject_model_loader(instance)
            
            # MemoryManager ì£¼ì…
            results['memory_manager'] = DIHelper.inject_memory_manager(instance)
            
            # DataConverter ì£¼ì…
            results['data_converter'] = DIHelper.inject_data_converter(instance)
            
            # CheckpointManager ì£¼ì… (ì „ì—­ ì‚¬ìš©)
            try:
                if not hasattr(instance, 'checkpoint_manager') or instance.checkpoint_manager is None:
                    if BaseStepMixin._global_checkpoint_manager is None:
                        BaseStepMixin._global_checkpoint_manager = CheckpointManager()
                        BaseStepMixin._global_checkpoint_manager.scan_checkpoints()
                    
                    instance.checkpoint_manager = BaseStepMixin._global_checkpoint_manager
                    results['checkpoint_manager'] = True
                else:
                    results['checkpoint_manager'] = True
            except Exception as e:
                logging.debug(f"CheckpointManager ì£¼ì… ì‹¤íŒ¨: {e}")
                results['checkpoint_manager'] = False
            
            # PerformanceMonitor ì£¼ì… (ë‚´ì¥ ì‚¬ìš©)
            try:
                if not hasattr(instance, 'performance_monitor') or instance.performance_monitor is None:
                    instance.performance_monitor = PerformanceMonitor(instance)
                    results['performance_monitor'] = True
                else:
                    results['performance_monitor'] = True
            except Exception as e:
                logging.debug(f"PerformanceMonitor ì£¼ì… ì‹¤íŒ¨: {e}")
                results['performance_monitor'] = False
            
            # WarmupSystem ì£¼ì… (ë‚´ì¥ ì‚¬ìš©)
            try:
                if not hasattr(instance, 'warmup_system') or instance.warmup_system is None:
                    instance.warmup_system = WarmupSystem(instance)
                    results['warmup_system'] = True
                else:
                    results['warmup_system'] = True
            except Exception as e:
                logging.debug(f"WarmupSystem ì£¼ì… ì‹¤íŒ¨: {e}")
                results['warmup_system'] = False
            
            return results
            
        except Exception as e:
            logging.error(f"âŒ ì „ì²´ ì˜ì¡´ì„± ì£¼ì… ì‹¤íŒ¨: {e}")
            return {
                'model_loader': False,
                'memory_manager': False,
                'data_converter': False,
                'checkpoint_manager': False,
                'performance_monitor': False,
                'warmup_system': False
            }

# ==============================================
# ğŸ”¥ 8. ì›Œë°ì—… ì‹œìŠ¤í…œ (ë¹„ë™ê¸° ì²˜ë¦¬ ì™„ì „ í•´ê²°)
# ==============================================

class WarmupSystem:
    """ì›Œë°ì—… ì‹œìŠ¤í…œ - ë¹„ë™ê¸° ì²˜ë¦¬ ì™„ì „ í•´ê²°"""
    
    def __init__(self, step_instance):
        self.step = step_instance
        self.logger = step_instance.logger
        self.warmup_status = {
            'model_warmup': False,
            'device_warmup': False,
            'memory_warmup': False,
            'pipeline_warmup': False
        }
        self.warmup_times = {}
    
    def run_warmup_sequence(self) -> Dict[str, Any]:
        """ì›Œë°ì—… ì‹œí€€ìŠ¤ ì‹¤í–‰ (ë™ê¸°)"""
        try:
            total_start = time.time()
            results = {}
            
            # 1. ëª¨ë¸ ì›Œë°ì—…
            model_start = time.time()
            model_result = self._model_warmup()
            self.warmup_times['model_warmup'] = time.time() - model_start
            results['model_warmup'] = model_result
            self.warmup_status['model_warmup'] = model_result.get('success', False)
            
            # 2. ë””ë°”ì´ìŠ¤ ì›Œë°ì—…
            device_start = time.time()
            device_result = self._device_warmup()
            self.warmup_times['device_warmup'] = time.time() - device_start
            results['device_warmup'] = device_result
            self.warmup_status['device_warmup'] = device_result.get('success', False)
            
            # 3. ë©”ëª¨ë¦¬ ì›Œë°ì—…
            memory_start = time.time()
            memory_result = self._memory_warmup()
            self.warmup_times['memory_warmup'] = time.time() - memory_start
            results['memory_warmup'] = memory_result
            self.warmup_status['memory_warmup'] = memory_result.get('success', False)
            
            # 4. íŒŒì´í”„ë¼ì¸ ì›Œë°ì—… (ğŸ”¥ ë¹„ë™ê¸° ì²˜ë¦¬ ì™„ì „ í•´ê²°)
            pipeline_start = time.time()
            pipeline_result = self._pipeline_warmup()
            self.warmup_times['pipeline_warmup'] = time.time() - pipeline_start
            results['pipeline_warmup'] = pipeline_result
            self.warmup_status['pipeline_warmup'] = pipeline_result.get('success', False)
            
            total_time = time.time() - total_start
            
            success_count = sum(1 for status in self.warmup_status.values() if status)
            overall_success = success_count >= 3  # 4ê°œ ì¤‘ 3ê°œ ì´ìƒ ì„±ê³µ
            
            self.logger.info(f"ğŸ”¥ ì›Œë°ì—… ì™„ë£Œ: {success_count}/4 ì„±ê³µ ({total_time:.2f}ì´ˆ)")
            
            return {
                'success': overall_success,
                'total_time': total_time,
                'warmup_status': self.warmup_status.copy(),
                'warmup_times': self.warmup_times.copy(),
                'results': results
            }
            
        except Exception as e:
            self.logger.error(f"âŒ ì›Œë°ì—… ì‹œí€€ìŠ¤ ì‹¤íŒ¨: {e}")
            return {
                'success': False,
                'error': str(e),
                'warmup_status': self.warmup_status.copy()
            }
    
    async def run_warmup_sequence_async(self) -> Dict[str, Any]:
        """ì›Œë°ì—… ì‹œí€€ìŠ¤ ì‹¤í–‰ (ë¹„ë™ê¸°)"""
        try:
            total_start = time.time()
            results = {}
            
            # 1. ëª¨ë¸ ì›Œë°ì—…
            model_start = time.time()
            model_result = await self._model_warmup_async()
            self.warmup_times['model_warmup'] = time.time() - model_start
            results['model_warmup'] = model_result
            self.warmup_status['model_warmup'] = model_result.get('success', False)
            
            # 2. ë””ë°”ì´ìŠ¤ ì›Œë°ì—…
            device_start = time.time()
            device_result = await self._device_warmup_async()
            self.warmup_times['device_warmup'] = time.time() - device_start
            results['device_warmup'] = device_result
            self.warmup_status['device_warmup'] = device_result.get('success', False)
            
            # 3. ë©”ëª¨ë¦¬ ì›Œë°ì—…
            memory_start = time.time()
            memory_result = await self._memory_warmup_async()
            self.warmup_times['memory_warmup'] = time.time() - memory_start
            results['memory_warmup'] = memory_result
            self.warmup_status['memory_warmup'] = memory_result.get('success', False)
            
            # 4. íŒŒì´í”„ë¼ì¸ ì›Œë°ì—… (ğŸ”¥ ë¹„ë™ê¸° ì²˜ë¦¬ ì™„ì „ í•´ê²°)
            pipeline_start = time.time()
            pipeline_result = await self._pipeline_warmup_async()
            self.warmup_times['pipeline_warmup'] = time.time() - pipeline_start
            results['pipeline_warmup'] = pipeline_result
            self.warmup_status['pipeline_warmup'] = pipeline_result.get('success', False)
            
            total_time = time.time() - total_start
            
            success_count = sum(1 for status in self.warmup_status.values() if status)
            overall_success = success_count >= 3  # 4ê°œ ì¤‘ 3ê°œ ì´ìƒ ì„±ê³µ
            
            self.logger.info(f"ğŸ”¥ ë¹„ë™ê¸° ì›Œë°ì—… ì™„ë£Œ: {success_count}/4 ì„±ê³µ ({total_time:.2f}ì´ˆ)")
            
            return {
                'success': overall_success,
                'total_time': total_time,
                'warmup_status': self.warmup_status.copy(),
                'warmup_times': self.warmup_times.copy(),
                'results': results
            }
            
        except Exception as e:
            self.logger.error(f"âŒ ë¹„ë™ê¸° ì›Œë°ì—… ì‹œí€€ìŠ¤ ì‹¤íŒ¨: {e}")
            return {
                'success': False,
                'error': str(e),
                'warmup_status': self.warmup_status.copy()
            }
    
    def _model_warmup(self) -> Dict[str, Any]:
        """ëª¨ë¸ ì›Œë°ì—… (ë™ê¸°)"""
        try:
            if hasattr(self.step, 'model_loader') and self.step.model_loader:
                # í…ŒìŠ¤íŠ¸ ëª¨ë¸ ë¡œë“œ
                try:
                    test_model = self.step.model_loader.get_model("warmup_test")
                    if test_model:
                        return {'success': True, 'message': 'ëª¨ë¸ ë¡œë” ì›Œë°ì—… ì™„ë£Œ'}
                except:
                    pass
            
            return {'success': True, 'message': 'ëª¨ë¸ ì›Œë°ì—… ê±´ë„ˆëœ€'}
            
        except Exception as e:
            return {'success': False, 'error': str(e)}
    
    async def _model_warmup_async(self) -> Dict[str, Any]:
        """ëª¨ë¸ ì›Œë°ì—… (ë¹„ë™ê¸°)"""
        try:
            if hasattr(self.step, 'model_loader') and self.step.model_loader:
                # í…ŒìŠ¤íŠ¸ ëª¨ë¸ ë¡œë“œ
                try:
                    if hasattr(self.step.model_loader, 'get_model_async'):
                        test_model = await self.step.model_loader.get_model_async("warmup_test")
                    else:
                        test_model = self.step.model_loader.get_model("warmup_test")
                    
                    if test_model:
                        return {'success': True, 'message': 'ëª¨ë¸ ë¡œë” ë¹„ë™ê¸° ì›Œë°ì—… ì™„ë£Œ'}
                except:
                    pass
            
            return {'success': True, 'message': 'ëª¨ë¸ ë¹„ë™ê¸° ì›Œë°ì—… ê±´ë„ˆëœ€'}
            
        except Exception as e:
            return {'success': False, 'error': str(e)}
    
    def _device_warmup(self) -> Dict[str, Any]:
        """ë””ë°”ì´ìŠ¤ ì›Œë°ì—… (ë™ê¸°)"""
        try:
            if TORCH_AVAILABLE:
                device = getattr(self.step, 'device', 'cpu')
                
                # í…ŒìŠ¤íŠ¸ í…ì„œ ìƒì„± ë° ì—°ì‚°
                test_tensor = torch.randn(10, 10)
                if device != 'cpu':
                    test_tensor = test_tensor.to(device)
                
                # ê°„ë‹¨í•œ ì—°ì‚°
                result = torch.matmul(test_tensor, test_tensor.t())
                
                return {'success': True, 'message': f'{device} ë””ë°”ì´ìŠ¤ ì›Œë°ì—… ì™„ë£Œ'}
            
            return {'success': True, 'message': 'PyTorch ì—†ìŒ - ì›Œë°ì—… ê±´ë„ˆëœ€'}
            
        except Exception as e:
            return {'success': False, 'error': str(e)}
    
    async def _device_warmup_async(self) -> Dict[str, Any]:
        """ë””ë°”ì´ìŠ¤ ì›Œë°ì—… (ë¹„ë™ê¸°)"""
        try:
            # ë™ê¸° ì›Œë°ì—…ì„ ë¹„ë™ê¸°ë¡œ ì‹¤í–‰
            loop = asyncio.get_event_loop()
            result = await loop.run_in_executor(None, self._device_warmup)
            return result
            
        except Exception as e:
            return {'success': False, 'error': str(e)}
    
    def _memory_warmup(self) -> Dict[str, Any]:
        """ë©”ëª¨ë¦¬ ì›Œë°ì—… (ë™ê¸°)"""
        try:
            if hasattr(self.step, 'memory_manager') and self.step.memory_manager:
                result = self.step.memory_manager.optimize_memory()
                return {'success': result.get('success', False), 'message': 'ë©”ëª¨ë¦¬ ìµœì í™” ì™„ë£Œ'}
            
            # ê¸°ë³¸ ë©”ëª¨ë¦¬ ì •ë¦¬
            gc.collect()
            return {'success': True, 'message': 'ê¸°ë³¸ ë©”ëª¨ë¦¬ ì •ë¦¬ ì™„ë£Œ'}
            
        except Exception as e:
            return {'success': False, 'error': str(e)}
    
    async def _memory_warmup_async(self) -> Dict[str, Any]:
        """ë©”ëª¨ë¦¬ ì›Œë°ì—… (ë¹„ë™ê¸°)"""
        try:
            if hasattr(self.step, 'memory_manager') and self.step.memory_manager:
                if hasattr(self.step.memory_manager, 'optimize_memory_async'):
                    result = await self.step.memory_manager.optimize_memory_async()
                else:
                    result = self.step.memory_manager.optimize_memory()
                return {'success': result.get('success', False), 'message': 'ë©”ëª¨ë¦¬ ë¹„ë™ê¸° ìµœì í™” ì™„ë£Œ'}
            
            # ê¸°ë³¸ ë©”ëª¨ë¦¬ ì •ë¦¬
            loop = asyncio.get_event_loop()
            await loop.run_in_executor(None, gc.collect)
            return {'success': True, 'message': 'ê¸°ë³¸ ë©”ëª¨ë¦¬ ë¹„ë™ê¸° ì •ë¦¬ ì™„ë£Œ'}
            
        except Exception as e:
            return {'success': False, 'error': str(e)}
    
    def _pipeline_warmup(self) -> Dict[str, Any]:
        """íŒŒì´í”„ë¼ì¸ ì›Œë°ì—… (ë™ê¸°) - ğŸ”¥ coroutine ê²½ê³  ì™„ì „ í•´ê²°"""
        try:
            # Stepë³„ ì›Œë°ì—… ë¡œì§ (ê¸°ë³¸)
            if hasattr(self.step, 'warmup_step'):
                warmup_method = getattr(self.step, 'warmup_step')
                
                # ğŸ”¥ ë¹„ë™ê¸° í•¨ìˆ˜ì¸ì§€ í™•ì¸í•˜ê³  ì ì ˆíˆ ì²˜ë¦¬
                if asyncio.iscoroutinefunction(warmup_method):
                    try:
                        # í˜„ì¬ ì´ë²¤íŠ¸ ë£¨í”„ê°€ ìˆëŠ”ì§€ í™•ì¸
                        try:
                            loop = asyncio.get_running_loop()
                            # ì´ë¯¸ ì‹¤í–‰ ì¤‘ì¸ ë£¨í”„ì—ì„œëŠ” ë™ê¸°ì ìœ¼ë¡œ ì²˜ë¦¬í•  ìˆ˜ ì—†ìŒ
                            self.logger.warning("âš ï¸ ì‹¤í–‰ ì¤‘ì¸ ì´ë²¤íŠ¸ ë£¨í”„ì—ì„œ ë™ê¸° íŒŒì´í”„ë¼ì¸ ì›Œë°ì—… ìš”ì²­ë¨")
                            return {'success': True, 'message': 'ë¹„ë™ê¸° íŒŒì´í”„ë¼ì¸ ì›Œë°ì—… ê±´ë„ˆëœ€ (ë™ê¸° ëª¨ë“œ)'}
                        except RuntimeError:
                            # ì‹¤í–‰ ì¤‘ì¸ ë£¨í”„ê°€ ì—†ìœ¼ë©´ ìƒˆ ë£¨í”„ë¡œ ì‹¤í–‰
                            result = asyncio.run(warmup_method())
                            return {'success': result.get('success', True), 'message': 'Step ì›Œë°ì—… ì™„ë£Œ (ë¹„ë™ê¸°â†’ë™ê¸°)'}
                    except Exception as e:
                        self.logger.warning(f"ë¹„ë™ê¸° ì›Œë°ì—… ì‹¤íŒ¨: {e}")
                        return {'success': False, 'error': str(e)}
                else:
                    # ë™ê¸° í•¨ìˆ˜ì¸ ê²½ìš° ì§ì ‘ í˜¸ì¶œ
                    result = warmup_method()
                    return {'success': result.get('success', True), 'message': 'Step ì›Œë°ì—… ì™„ë£Œ'}
            
            return {'success': True, 'message': 'íŒŒì´í”„ë¼ì¸ ì›Œë°ì—… ê±´ë„ˆëœ€'}
            
        except Exception as e:
            return {'success': False, 'error': str(e)}
    
    async def _pipeline_warmup_async(self) -> Dict[str, Any]:
        """íŒŒì´í”„ë¼ì¸ ì›Œë°ì—… (ë¹„ë™ê¸°) - ğŸ”¥ coroutine ê²½ê³  ì™„ì „ í•´ê²°"""
        try:
            # Stepë³„ ì›Œë°ì—… ë¡œì§ (ê¸°ë³¸)
            if hasattr(self.step, 'warmup_step'):
                warmup_method = getattr(self.step, 'warmup_step')
                
                # ğŸ”¥ ë¹„ë™ê¸° í•¨ìˆ˜ì¸ì§€ í™•ì¸í•˜ê³  ì ì ˆíˆ ì²˜ë¦¬
                if asyncio.iscoroutinefunction(warmup_method):
                    # ë¹„ë™ê¸° í•¨ìˆ˜ì¸ ê²½ìš° awaitë¡œ í˜¸ì¶œ
                    result = await warmup_method()
                    return {'success': result.get('success', True), 'message': 'Step ë¹„ë™ê¸° ì›Œë°ì—… ì™„ë£Œ'}
                else:
                    # ë™ê¸° í•¨ìˆ˜ì¸ ê²½ìš° executorë¡œ ì‹¤í–‰
                    loop = asyncio.get_event_loop()
                    result = await loop.run_in_executor(None, warmup_method)
                    return {'success': result.get('success', True), 'message': 'Step ì›Œë°ì—… ì™„ë£Œ (ë™ê¸°â†’ë¹„ë™ê¸°)'}
            
            return {'success': True, 'message': 'íŒŒì´í”„ë¼ì¸ ë¹„ë™ê¸° ì›Œë°ì—… ê±´ë„ˆëœ€'}
            
        except Exception as e:
            return {'success': False, 'error': str(e)}

# ==============================================
# ğŸ”¥ 9. ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ
# ==============================================

class PerformanceMonitor:
    """ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ"""
    
    def __init__(self, step_instance):
        self.step = step_instance
        self.logger = step_instance.logger
        self.metrics = {
            'operation_times': {},
            'memory_usage': [],
            'error_counts': {},
            'success_rates': {},
            'last_operations': {}
        }
        self._lock = threading.Lock()
    
    def record_operation(self, operation_name: str, duration: float, success: bool):
        """ì‘ì—… ê¸°ë¡"""
        try:
            with self._lock:
                # ì‘ì—… ì‹œê°„ ê¸°ë¡
                if operation_name not in self.metrics['operation_times']:
                    self.metrics['operation_times'][operation_name] = []
                
                self.metrics['operation_times'][operation_name].append(duration)
                
                # ìµœëŒ€ 100ê°œê¹Œì§€ë§Œ ìœ ì§€
                if len(self.metrics['operation_times'][operation_name]) > 100:
                    self.metrics['operation_times'][operation_name].pop(0)
                
                # ì„±ê³µë¥  ê³„ì‚°
                if operation_name not in self.metrics['success_rates']:
                    self.metrics['success_rates'][operation_name] = {'success': 0, 'total': 0}
                
                self.metrics['success_rates'][operation_name]['total'] += 1
                if success:
                    self.metrics['success_rates'][operation_name]['success'] += 1
                
                # ì—ëŸ¬ ì¹´ìš´íŠ¸
                if not success:
                    self.metrics['error_counts'][operation_name] = self.metrics['error_counts'].get(operation_name, 0) + 1
                
                # ë§ˆì§€ë§‰ ì‘ì—… ê¸°ë¡
                self.metrics['last_operations'][operation_name] = {
                    'duration': duration,
                    'success': success,
                    'timestamp': time.time()
                }
                
        except Exception as e:
            self.logger.warning(f"ì„±ëŠ¥ ê¸°ë¡ ì‹¤íŒ¨: {e}")
    
    def get_performance_summary(self) -> Dict[str, Any]:
        """ì„±ëŠ¥ ìš”ì•½ ì¡°íšŒ"""
        try:
            with self._lock:
                summary = {}
                
                for operation_name, times in self.metrics['operation_times'].items():
                    if times:
                        summary[operation_name] = {
                            'avg_time': sum(times) / len(times),
                            'min_time': min(times),
                            'max_time': max(times),
                            'total_calls': len(times),
                            'success_rate': self._calculate_success_rate(operation_name),
                            'error_count': self.metrics['error_counts'].get(operation_name, 0)
                        }
                
                return summary
                
        except Exception as e:
            self.logger.error(f"ì„±ëŠ¥ ìš”ì•½ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {}
    
    def _calculate_success_rate(self, operation_name: str) -> float:
        """ì„±ê³µë¥  ê³„ì‚°"""
        try:
            rates = self.metrics['success_rates'].get(operation_name, {'success': 0, 'total': 0})
            if rates['total'] > 0:
                return rates['success'] / rates['total']
            return 0.0
        except:
            return 0.0

# ==============================================
# ğŸ”¥ 10. ë©”ëª¨ë¦¬ ìµœì í™” ì‹œìŠ¤í…œ
# ==============================================

class StepMemoryOptimizer:
    """Stepë³„ ë©”ëª¨ë¦¬ ìµœì í™”"""
    
    def __init__(self, device: str = "mps"):
        self.device = device
        self.is_m3_max = self._detect_m3_max()
        self.logger = logging.getLogger(f"{__name__}.StepMemoryOptimizer")
        self.optimization_history = []
        
    def _detect_m3_max(self) -> bool:
        """M3 Max ê°ì§€"""
        try:
            import platform
            import subprocess
            if platform.system() == 'Darwin':
                result = subprocess.run(
                    ['sysctl', '-n', 'machdep.cpu.brand_string'],
                    capture_output=True, text=True, timeout=5
                )
                return 'M3' in result.stdout
        except:
            pass
        return False
    
    def optimize_memory(self, aggressive: bool = False) -> Dict[str, Any]:
        """ë©”ëª¨ë¦¬ ìµœì í™” ì‹¤í–‰"""
        try:
            start_time = time.time()
            results = []
            
            # Python GC
            before_objects = len(gc.get_objects())
            gc.collect()
            after_objects = len(gc.get_objects())
            freed = before_objects - after_objects
            results.append(f"Python GC: {freed}ê°œ ê°ì²´ í•´ì œ")
            
            # PyTorch ë©”ëª¨ë¦¬ ì •ë¦¬
            if TORCH_AVAILABLE:
                if self.device == "cuda" and torch.cuda.is_available():
                    torch.cuda.empty_cache()
                    results.append("CUDA ìºì‹œ ì •ë¦¬")
                elif self.device == "mps" and MPS_AVAILABLE:
                    try:
                        if hasattr(torch.mps, 'empty_cache'):
                            safe_mps_empty_cache()
                        elif hasattr(torch.backends.mps, 'empty_cache'):
                            torch.backends.mps.empty_cache()
                        results.append("MPS ìºì‹œ ì •ë¦¬")
                    except AttributeError:
                        results.append("MPS ìºì‹œ ì •ë¦¬ ê±´ë„ˆëœ€ (ì•ˆì „)")
            
            # M3 Max íŠ¹ë³„ ìµœì í™”
            if self.is_m3_max and aggressive:
                try:
                    # ì¶”ê°€ ë©”ëª¨ë¦¬ ì •ë¦¬
                    for _ in range(3):
                        gc.collect()
                    results.append("M3 Max ê³µê²©ì  ì •ë¦¬")
                except Exception as e:
                    results.append(f"M3 Max ìµœì í™” ì‹¤íŒ¨: {e}")
            
            optimization_time = time.time() - start_time
            
            result = {
                "success": True,
                "duration": optimization_time,
                "results": results,
                "device": self.device,
                "is_m3_max": self.is_m3_max,
                "aggressive": aggressive,
                "timestamp": time.time()
            }
            
            self.optimization_history.append(result)
            # ìµœëŒ€ 50ê°œê¹Œì§€ë§Œ ìœ ì§€
            if len(self.optimization_history) > 50:
                self.optimization_history.pop(0)
            
            self.logger.info(f"âœ… Step ë©”ëª¨ë¦¬ ìµœì í™” ì™„ë£Œ ({optimization_time:.3f}s)")
            return result
            
        except Exception as e:
            self.logger.error(f"âŒ Step ë©”ëª¨ë¦¬ ìµœì í™” ì‹¤íŒ¨: {e}")
            return {
                "success": False,
                "error": str(e),
                "timestamp": time.time()
            }
    
    async def optimize_memory_async(self, aggressive: bool = False) -> Dict[str, Any]:
        """ë©”ëª¨ë¦¬ ìµœì í™” ì‹¤í–‰ (ë¹„ë™ê¸°)"""
        try:
            loop = asyncio.get_event_loop()
            result = await loop.run_in_executor(None, lambda: self.optimize_memory(aggressive))
            return result
        except Exception as e:
            self.logger.error(f"âŒ ë¹„ë™ê¸° Step ë©”ëª¨ë¦¬ ìµœì í™” ì‹¤íŒ¨: {e}")
            return {
                "success": False,
                "error": str(e),
                "timestamp": time.time()
            }

# ==============================================
# ğŸ”¥ 11. ë©”ì¸ BaseStepMixin í´ë˜ìŠ¤ (ì™„ì „í•œ í†µí•© ë²„ì „)
# ==============================================

class BaseStepMixin:
    """
    ğŸ”¥ BaseStepMixin v10.1 - ì™„ì „í•œ í†µí•© ë²„ì „
    
    âœ… ë¹„ë™ê¸° ì²˜ë¦¬ ì™„ì „ í•´ê²° (coroutine ê²½ê³  ì™„ì „ ì œê±°)
    âœ… from functools import wraps ì¶”ê°€ (NameError í•´ê²°)
    âœ… ì˜ì¡´ì„± ì£¼ì… íŒ¨í„´ ì™„ì „ ì ìš©
    âœ… ê¸°ì¡´ ëª¨ë“  ê¸°ëŠ¥ 100% ìœ ì§€
    âœ… logger ì†ì„± ëˆ„ë½ ë¬¸ì œ ê·¼ë³¸ í•´ê²°
    âœ… _emergency_initialization ë©”ì„œë“œ ì™„ì „ êµ¬í˜„
    âœ… 89.8GB ì²´í¬í¬ì¸íŠ¸ ìë™ íƒì§€ ë° í™œìš©
    âœ… ModelLoader ì—°ë™ ì™„ì „ ìë™í™”
    âœ… M3 Max 128GB ìµœì í™”
    """
    
    # í´ë˜ìŠ¤ ë³€ìˆ˜
    _class_registry = weakref.WeakSet()
    _initialization_lock = threading.RLock()
    _global_checkpoint_manager = None
    
    def __init__(self, *args, **kwargs):
        """ì™„ì „ ì•ˆì „í•œ ì´ˆê¸°í™” - ëª¨ë“  ê¸°ëŠ¥ í¬í•¨ + DI ì ìš© + ë¹„ë™ê¸° ì²˜ë¦¬ ì™„ì „ í•´ê²°"""
        
        # ===== ğŸ”¥ STEP 0: logger ì†ì„± ìµœìš°ì„  ìƒì„± (ì ˆëŒ€ ëˆ„ë½ ë°©ì§€) =====
        self._ensure_logger_first()
        
        # ===== ğŸ”¥ STEP 1: í´ë˜ìŠ¤ ë“±ë¡ =====
        BaseStepMixin._class_registry.add(self)
        
        # ===== ğŸ”¥ STEP 2: ì™„ì „í•œ ì´ˆê¸°í™” =====
        with BaseStepMixin._initialization_lock:
            try:
                # DI ì»¨í…Œì´ë„ˆ ì„¤ì •
                self._setup_di_container()
                
                # ì˜ì¡´ì„± ì£¼ì…
                self._inject_dependencies()
                
                # ê¸°ë³¸ ì†ì„± ì„¤ì •
                self._setup_basic_attributes(kwargs)
                
                # NumPy í˜¸í™˜ì„± í™•ì¸
                self._check_numpy_compatibility()
                
                # ì•ˆì „í•œ super().__init__ í˜¸ì¶œ
                self._safe_super_init()
                
                # ì‹œìŠ¤í…œ í™˜ê²½ ì„¤ì •
                self._setup_device_and_system(kwargs)
                
                # ì•ˆì „í•œ ì„¤ì • ê´€ë¦¬
                self._setup_config_safely(kwargs)
                
                # ìƒíƒœ ê´€ë¦¬ ì‹œìŠ¤í…œ
                self._setup_state_management()
                
                # M3 Max ìµœì í™”
                self._setup_m3_max_optimization()
                
                # ë©”ëª¨ë¦¬ ìµœì í™” ì‹œìŠ¤í…œ
                self._setup_memory_optimization()
                
                # ì›Œë°ì—… ì‹œìŠ¤í…œ
                self._setup_warmup_system()
                
                # ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
                self._setup_performance_monitoring()
                
                # ModelLoader ì¸í„°í˜ì´ìŠ¤ (DI ê¸°ë°˜) - ğŸ”¥ ë¹„ë™ê¸° ì²˜ë¦¬ í•´ê²°
                self._setup_model_interface_safe()
                
                # ì²´í¬í¬ì¸íŠ¸ íƒì§€ ë° ì—°ë™
                self._setup_checkpoint_detection()
                
                # DI í´ë°± ì„¤ì •
                self.setup_di_fallbacks()
                
                # ìµœì¢… ì´ˆê¸°í™” ì™„ë£Œ
                self._finalize_initialization()
                
                self.logger.info(f"âœ… {self.step_name} BaseStepMixin v10.1 ì´ˆê¸°í™” ì™„ë£Œ")
                self.logger.debug(f"ğŸ”§ Device: {self.device}, Memory: {self.memory_gb}GB, DI: {self.di_available}")
                
            except Exception as e:
                self._emergency_initialization()
                if hasattr(self, 'logger'):
                    self.logger.error(f"âŒ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                    self.logger.debug(f"ğŸ“‹ ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
    
    # ==============================================
    # ğŸ”¥ ì´ˆê¸°í™” ë©”ì„œë“œë“¤ (ëª¨ë“  ë©”ì„œë“œ ì™„ì „ êµ¬í˜„)
    # ==============================================
    
    def _ensure_logger_first(self):
        """ğŸ”¥ logger ì†ì„± ìµœìš°ì„  ìƒì„± - ê°œì„ ëœ ë²„ì „"""
        try:
            if hasattr(self, 'logger') and self.logger is not None:
                return
            
            class_name = self.__class__.__name__
            step_name = getattr(self, 'step_name', class_name)
            
            # ê³„ì¸µì  ë¡œê±° ì´ë¦„ ìƒì„±
            logger_name = f"pipeline.steps.{step_name}"
            
            # ë¡œê±° ìƒì„± ë° ì„¤ì •
            self.logger = logging.getLogger(logger_name)
            
            # ë¡œê·¸ ë ˆë²¨ ì„¤ì • (í™˜ê²½ë³€ìˆ˜ ê³ ë ¤)
            log_level = os.environ.get('LOG_LEVEL', 'INFO').upper()
            if log_level == 'DEBUG':
                self.logger.setLevel(logging.DEBUG)
            elif log_level == 'WARNING':
                self.logger.setLevel(logging.WARNING)
            else:
                self.logger.setLevel(logging.INFO)
            
            # í•¸ë“¤ëŸ¬ê°€ ì—†ëŠ” ê²½ìš°ì—ë§Œ ì¶”ê°€
            if not self.logger.handlers:
                formatter = logging.Formatter(
                    '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
                )
                
                handler = logging.StreamHandler()
                handler.setFormatter(formatter)
                self.logger.addHandler(handler)
            
            # step_name ì†ì„±ë„ ì„¤ì •
            if not hasattr(self, 'step_name'):
                self.step_name = step_name
                
            # ì´ˆê¸°í™” ì‹œì‘ ë¡œê·¸ (ì¤‘ìš”)
            self.logger.info(f"ğŸ”— {step_name} logger ì†ì„± ìƒì„± ì™„ë£Œ")
            
        except Exception as e:
            print(f"âŒ logger ìƒì„± ì‹¤íŒ¨: {e}")
            self._create_emergency_logger()
    
    def _create_emergency_logger(self):
        """ê¸´ê¸‰ ë¡œê±° ìƒì„± - ê°œì„ ëœ ë²„ì „"""
        try:
            class_name = getattr(self, '__class__', type(self)).__name__
            self.logger = logging.getLogger(f"emergency.{class_name}")
            
            # ìµœì†Œí•œì˜ í•¸ë“¤ëŸ¬ ì„¤ì •
            if not self.logger.handlers:
                handler = logging.StreamHandler()
                formatter = logging.Formatter('%(levelname)s - %(message)s')
                handler.setFormatter(formatter)
                self.logger.addHandler(handler)
                self.logger.setLevel(logging.WARNING)
            
            self.logger.warning(f"ğŸš¨ {class_name} ê¸´ê¸‰ ë¡œê±° ìƒì„±ë¨")
            
        except Exception as e:
            print(f"ğŸš¨ ê¸´ê¸‰ ë¡œê±° ìƒì„±ë„ ì‹¤íŒ¨: {e}")
            # ìµœí›„ì˜ ìˆ˜ë‹¨: ê°„ë‹¨í•œ ë¡œê±° í´ë˜ìŠ¤
            class EmergencyLogger:
                def info(self, msg): print(f"INFO: {msg}")
                def warning(self, msg): print(f"WARNING: {msg}")
                def error(self, msg): print(f"ERROR: {msg}")
                def debug(self, msg): print(f"DEBUG: {msg}")
            
            self.logger = EmergencyLogger()
            self.logger.error(f"ğŸš¨ {getattr(self, '__class__', 'Unknown').__name__} ìµœí›„ ìˆ˜ë‹¨ ë¡œê±° ì‚¬ìš©")


    def _create_emergency_logger(self):
        """ê¸´ê¸‰ ë¡œê±° ìƒì„±"""
        try:
            self.logger = logging.getLogger("emergency_logger")
        except:
            class EmergencyLogger:
                def info(self, msg): print(f"INFO: {msg}")
                def warning(self, msg): print(f"WARNING: {msg}")
                def error(self, msg): print(f"ERROR: {msg}")
                def debug(self, msg): print(f"DEBUG: {msg}")
            
            self.logger = EmergencyLogger()
    
    def _setup_di_container(self):
        """DI Container ì„¤ì •"""
        try:
            self.di_container = DIHelper.get_di_container()
            self.di_available = self.di_container is not None
            
            if self.di_available:
                self.logger.debug("âœ… DI Container ì—°ê²° ì„±ê³µ")
            else:
                self.logger.warning("âš ï¸ DI Container ì‚¬ìš© ë¶ˆê°€ - í´ë°± ëª¨ë“œ")
                
        except Exception as e:
            self.logger.warning(f"âš ï¸ DI Container ì„¤ì • ì‹¤íŒ¨: {e}")
            self.di_container = None
            self.di_available = False
    
    def _inject_dependencies(self):
        """ì˜ì¡´ì„± ì£¼ì… ì‹¤í–‰ - DI Container v2.0 ì™„ë²½ í˜¸í™˜"""
        try:
            # DI Container v2.0 ì‚¬ìš©
            injection_results = DIHelper.inject_all_dependencies(self)
            
            # ì£¼ì… ê²°ê³¼ ë¡œê¹…
            successful_deps = [dep for dep, success in injection_results.items() if success]
            failed_deps = [dep for dep, success in injection_results.items() if not success]
            
            if successful_deps:
                self.logger.info(f"âœ… ì˜ì¡´ì„± ì£¼ì… ì™„ë£Œ: {', '.join(successful_deps)}")
            
            if failed_deps:
                self.logger.warning(f"âš ï¸ ì˜ì¡´ì„± ì£¼ì… ì‹¤íŒ¨: {', '.join(failed_deps)} - í´ë°± ëª¨ë“œ")
            
            # Step Interface ìƒì„± ì‹œë„ (ModelLoaderê°€ ìˆëŠ” ê²½ìš°)
            if hasattr(self, 'model_loader') and self.model_loader:
                try:
                    step_interface = self.model_loader.create_step_interface(self.step_name)
                    if step_interface:
                        self.step_interface = step_interface
                        self.logger.info("âœ… Step Interface ìƒì„± ì„±ê³µ")
                    else:
                        self.step_interface = None
                        self.logger.debug("âš ï¸ Step Interface ìƒì„± ì‹¤íŒ¨ (None ë°˜í™˜)")
                except Exception as e:
                    self.logger.warning(f"âš ï¸ Step Interface ìƒì„± ì‹¤íŒ¨: {e}")
                    self.step_interface = None
            else:
                self.step_interface = None
                self.logger.debug("âš ï¸ ModelLoader ì—†ìŒ - Step Interface ìƒì„± ê±´ë„ˆëœ€")
            
            # DI ìƒíƒœ ì„¤ì •
            success_count = sum(1 for success in injection_results.values() if success)
            self.di_available = success_count > 0
            
            # ì—°ë™ ìƒíƒœ ìµœì¢… ë¡œê¹…
            if self.di_available:
                self.logger.info(f"ğŸ”— DI ì‹œìŠ¤í…œ ì—°ë™ ì„±ê³µ ({success_count}/{len(injection_results)}ê°œ)")
            else:
                self.logger.warning("âš ï¸ DI ì‹œìŠ¤í…œ ì—°ë™ ì‹¤íŒ¨ - ëª¨ë“  ì˜ì¡´ì„±ì´ í´ë°± ëª¨ë“œë¡œ ë™ì‘")
            
            return injection_results
            
        except Exception as e:
            self.logger.error(f"âŒ ì˜ì¡´ì„± ì£¼ì… ì‹¤íŒ¨: {e}")
            # í´ë°±: ëª¨ë“  ì˜ì¡´ì„±ì„ Noneìœ¼ë¡œ ì„¤ì •
            self.model_loader = None
            self.memory_manager = None
            self.data_converter = None
            self.checkpoint_manager = None
            self.performance_monitor = None
            self.warmup_system = None
            self.step_interface = None
            self.di_available = False
            
            return {
                'model_loader': False,
                'memory_manager': False,
                'data_converter': False,
                'checkpoint_manager': False,
                'performance_monitor': False,
                'warmup_system': False
            }
    
    def _setup_basic_attributes(self, kwargs: Dict[str, Any]):
        """ê¸°ë³¸ ì†ì„± ì„¤ì •"""
        try:
            # Step ê¸°ë³¸ ì •ë³´
            self.step_name = getattr(self, 'step_name', self.__class__.__name__)
            self.step_number = kwargs.get('step_number', 0)
            self.step_type = kwargs.get('step_type', 'unknown')
            
            # ì—ëŸ¬ ì¶”ì 
            self.error_count = 0
            self.last_error = None
            self.initialization_time = time.time()
            
            # í”Œë˜ê·¸ë“¤
            self.is_initialized = False
            self.is_ready = False
            self.has_model = False
            self.model_loaded = False
            
            # ì²˜ë¦¬ ê´€ë ¨
            self.total_processing_count = 0
            self.last_processing_time = None
            self.processing_history = []
            
            self.logger.debug(f"ğŸ“ {self.step_name} ê¸°ë³¸ ì†ì„± ì„¤ì • ì™„ë£Œ")
            
        except Exception as e:
            self.logger.error(f"âŒ ê¸°ë³¸ ì†ì„± ì„¤ì • ì‹¤íŒ¨: {e}")
    
    def _check_numpy_compatibility(self):
        """NumPy í˜¸í™˜ì„± í™•ì¸"""
        try:
            if NUMPY_AVAILABLE:
                numpy_version = np.__version__
                major_version = int(numpy_version.split('.')[0])
                
                if major_version >= 2:
                    self.logger.warning(f"âš ï¸ NumPy {numpy_version} ê°ì§€. í˜¸í™˜ì„± ë¬¸ì œ ê°€ëŠ¥ì„±")
                    
                    # NumPy 2.x í˜¸í™˜ì„± ì„¤ì • ì‹œë„
                    try:
                        np.set_printoptions(legacy='1.25')
                        self.logger.info("âœ… NumPy 2.x í˜¸í™˜ì„± ì„¤ì • ì ìš©")
                    except Exception as e:
                        self.logger.warning(f"âš ï¸ NumPy í˜¸í™˜ì„± ì„¤ì • ì‹¤íŒ¨: {e}")
                else:
                    self.logger.debug(f"âœ… NumPy {numpy_version} í˜¸í™˜ì„± ì–‘í˜¸")
            else:
                self.logger.warning("âš ï¸ NumPy ì‚¬ìš© ë¶ˆê°€")
                
        except Exception as e:
            self.logger.warning(f"âš ï¸ NumPy í˜¸í™˜ì„± í™•ì¸ ì‹¤íŒ¨: {e}")
    
    def _safe_super_init(self):
        """ì•ˆì „í•œ super().__init__ í˜¸ì¶œ"""
        try:
            # MRO í™•ì¸
            mro = self.__class__.__mro__
            
            # BaseStepMixin ì´í›„ì˜ í´ë˜ìŠ¤ê°€ ìˆëŠ”ì§€ í™•ì¸
            base_index = -1
            for i, cls in enumerate(mro):
                if cls.__name__ == 'BaseStepMixin':
                    base_index = i
                    break
            
            if base_index != -1 and base_index < len(mro) - 2:  # object ì œì™¸
                try:
                    # ë‹¤ìŒ í´ë˜ìŠ¤ì˜ __init__ í˜¸ì¶œ
                    next_class = mro[base_index + 1]
                    if hasattr(next_class, '__init__') and next_class != object:
                        super(BaseStepMixin, self).__init__()
                        self.logger.debug(f"âœ… super().__init__ í˜¸ì¶œ ì„±ê³µ: {next_class.__name__}")
                except Exception as e:
                    self.logger.debug(f"âš ï¸ super().__init__ í˜¸ì¶œ ì‹¤íŒ¨: {e}")
            
        except Exception as e:
            self.logger.debug(f"âš ï¸ safe_super_init ì‹¤íŒ¨: {e}")
    
    def _setup_device_and_system(self, kwargs: Dict[str, Any]):
        """ì‹œìŠ¤í…œ í™˜ê²½ ì„¤ì • - conda í™˜ê²½ ìš°ì„  ì²˜ë¦¬"""
        try:
            # ë””ë°”ì´ìŠ¤ ì„¤ì •
            self.device = kwargs.get('device', self._detect_optimal_device())
            self.is_m3_max = self._detect_m3_max()
            
            # conda í™˜ê²½ ê°ì§€ ë° ì„¤ì •
            self.conda_env = os.environ.get('CONDA_DEFAULT_ENV', '')
            self.is_conda_env = bool(self.conda_env) or bool(os.environ.get('CONDA_PREFIX'))
            
            # ë©”ëª¨ë¦¬ ì •ë³´
            memory_info = self._get_memory_info()
            self.memory_gb = memory_info.get("total_gb", 16.0)
            
            # M3 Max ë° conda í™˜ê²½ íŠ¹í™” ì„¤ì •
            if self.is_m3_max and self.is_conda_env:
                self.memory_gb = min(self.memory_gb, 128.0)  # M3 Max 128GB ì œí•œ
                self.use_fp16 = kwargs.get('use_fp16', True)
                self.optimization_enabled = kwargs.get('optimization_enabled', True)
                self.logger.info(f"ğŸ M3 Max + conda í™˜ê²½ ìµœì í™” í™œì„±í™” ({self.conda_env})")
            elif self.is_m3_max:
                self.memory_gb = min(self.memory_gb, 64.0)   # conda ì—†ìœ¼ë©´ 64GB ì œí•œ
                self.use_fp16 = kwargs.get('use_fp16', True)
                self.optimization_enabled = kwargs.get('optimization_enabled', True)
                self.logger.warning("âš ï¸ M3 Max ê°ì§€ë˜ì—ˆìœ¼ë‚˜ conda í™˜ê²½ ê¶Œì¥")
            else:
                self.use_fp16 = kwargs.get('use_fp16', True and self.device != 'cpu')
                self.optimization_enabled = kwargs.get('optimization_enabled', True)
            
            # ë””ë°”ì´ìŠ¤ë³„ ì„¤ì •
            if self.device == "mps" and MPS_AVAILABLE:
                self._setup_mps_optimizations()
            elif self.device == "cuda" and TORCH_AVAILABLE and torch.cuda.is_available():
                self._setup_cuda_optimizations()
            
            self.logger.debug(f"ğŸ”§ ì‹œìŠ¤í…œ í™˜ê²½ ì„¤ì • ì™„ë£Œ: {self.device}, {self.memory_gb}GB, conda: {self.conda_env}")
            
        except Exception as e:
            self.logger.error(f"âŒ ì‹œìŠ¤í…œ í™˜ê²½ ì„¤ì • ì‹¤íŒ¨: {e}")
            # í´ë°± ê°’ë“¤
            self.device = "cpu"
            self.is_m3_max = False
            self.memory_gb = 16.0
            self.use_fp16 = False
            self.optimization_enabled = False
            self.conda_env = ""
            self.is_conda_env = False
    
    def _detect_optimal_device(self) -> str:
        """ìµœì  ë””ë°”ì´ìŠ¤ ê°ì§€ - conda í™˜ê²½ ê³ ë ¤"""
        try:
            if TORCH_AVAILABLE:
                if MPS_AVAILABLE:
                    # M3 Max + conda í™˜ê²½ì¸ ê²½ìš° ìš°ì„ 
                    conda_env = os.environ.get('CONDA_DEFAULT_ENV', '')
                    if conda_env:
                        self.logger.info(f"ğŸ M3 Max + conda ({conda_env}) í™˜ê²½ì—ì„œ MPS ì„ íƒ")
                    else:
                        self.logger.info("ğŸ M3 Max MPS ì„ íƒ (conda í™˜ê²½ ê¶Œì¥)")
                    return "mps"
                elif hasattr(torch, 'cuda') and torch.cuda.is_available():
                    return "cuda"
            return "cpu"
        except Exception as e:
            self.logger.warning(f"âš ï¸ ë””ë°”ì´ìŠ¤ ê°ì§€ ì‹¤íŒ¨: {e}")
            return "cpu"
    
    def _detect_m3_max(self) -> bool:
        """M3 Max ê°ì§€ - ê°œì„ ëœ ë²„ì „"""
        try:
            import platform
            import subprocess
            if platform.system() == 'Darwin':  # macOS
                try:
                    result = subprocess.run(
                        ['sysctl', '-n', 'machdep.cpu.brand_string'],
                        capture_output=True, text=True, timeout=5
                    )
                    cpu_info = result.stdout.strip().lower()
                    is_m3 = 'apple m3' in cpu_info or 'm3 max' in cpu_info or 'm3 pro' in cpu_info
                    
                    if is_m3:
                        self.logger.info(f"ğŸ Apple M3 ì‹œë¦¬ì¦ˆ ê°ì§€: {result.stdout.strip()}")
                    
                    return is_m3
                except subprocess.TimeoutExpired:
                    self.logger.warning("âš ï¸ CPU ì •ë³´ ì¡°íšŒ íƒ€ì„ì•„ì›ƒ")
                except Exception as e:
                    self.logger.debug(f"CPU ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        except Exception as e:
            self.logger.debug(f"M3 Max ê°ì§€ ì‹¤íŒ¨: {e}")
        
        return False
    
    def _get_memory_info(self) -> Dict[str, Any]:
        """ë©”ëª¨ë¦¬ ì •ë³´ ì¡°íšŒ - conda í™˜ê²½ ê³ ë ¤"""
        try:
            import psutil
            memory = psutil.virtual_memory()
            
            # conda í™˜ê²½ì—ì„œëŠ” ë” ì •í™•í•œ ë©”ëª¨ë¦¬ ì •ë³´ ì œê³µ
            conda_env = os.environ.get('CONDA_DEFAULT_ENV', '')
            if conda_env:
                self.logger.debug(f"ğŸ conda í™˜ê²½ ({conda_env})ì—ì„œ ë©”ëª¨ë¦¬ ì •ë³´ ì¡°íšŒ")
            
            return {
                "total_gb": memory.total / 1024**3,
                "available_gb": memory.available / 1024**3,
                "percent_used": memory.percent,
                "conda_optimized": bool(conda_env)
            }
        except ImportError:
            self.logger.warning("âš ï¸ psutil ì—†ìŒ - ê¸°ë³¸ ë©”ëª¨ë¦¬ ê°’ ì‚¬ìš©")
            return {
                "total_gb": 16.0,
                "available_gb": 8.0,
                "percent_used": 50.0,
                "conda_optimized": False
            }
            
    def _setup_config_safely(self, kwargs: Dict[str, Any]):
        """ì•ˆì „í•œ ì„¤ì • ê´€ë¦¬"""
        try:
            config_data = kwargs.get('config', {})
            self.config = SafeConfig(config_data)
            
            # ì¶”ê°€ ì„¤ì •ë“¤
            self.input_size = kwargs.get('input_size', (512, 512))
            self.output_size = kwargs.get('output_size', (512, 512))
            self.batch_size = kwargs.get('batch_size', 1)
            self.num_classes = kwargs.get('num_classes', None)
            self.precision = kwargs.get('precision', 'fp16' if self.use_fp16 else 'fp32')
            
            # M3 Max íŠ¹í™” ì„¤ì •
            if self.is_m3_max:
                self.batch_size = min(self.batch_size, 4)  # ë©”ëª¨ë¦¬ ì ˆì•½
                if self.memory_gb >= 64:
                    self.enable_large_batch = True
                else:
                    self.enable_large_batch = False
            
            self.logger.debug(f"âš™ï¸ ì•ˆì „í•œ ì„¤ì • ê´€ë¦¬ ì´ˆê¸°í™” ì™„ë£Œ")
            
        except Exception as e:
            self.logger.error(f"âŒ ì„¤ì • ê´€ë¦¬ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.config = SafeConfig()
    
    def _setup_state_management(self):
        """ìƒíƒœ ê´€ë¦¬ ì‹œìŠ¤í…œ ì„¤ì •"""
        try:
            self.state = {
                'status': 'initializing',
                'last_update': time.time(),
                'metrics': {},
                'errors': [],
                'warnings': [],
                'info_messages': []
            }
            
            # ì„±ëŠ¥ ë©”íŠ¸ë¦­ (ìƒì„¸)
            self.performance_metrics = {
                'process_count': 0,
                'total_process_time': 0.0,
                'average_process_time': 0.0,
                'last_process_time': None,
                'operations': {},
                'memory_usage_history': [],
                'error_history': []
            }
            
            # ìƒíƒœ ë³€ê²½ ì½œë°±
            self.state_change_callbacks = []
            
            self.logger.debug(f"ğŸ“Š ìƒíƒœ ê´€ë¦¬ ì‹œìŠ¤í…œ ì„¤ì • ì™„ë£Œ")
            
        except Exception as e:
            self.logger.error(f"âŒ ìƒíƒœ ê´€ë¦¬ ì‹œìŠ¤í…œ ì„¤ì • ì‹¤íŒ¨: {e}")
    
    def _setup_m3_max_optimization(self):
        """M3 Max ìµœì í™” ì„¤ì •"""
        try:
            if not self.is_m3_max:
                self.m3_max_optimizations = None
                return
            
            self.m3_max_optimizations = {
                'memory_pooling': True,
                'neural_engine': True,
                'unified_memory': True,
                'batch_optimization': True,
                'precision_optimization': True
            }
            
            # M3 Max íŠ¹í™” ì„¤ì •
            if MPS_AVAILABLE:
                try:
                    # MPS ìµœì í™” ì„¤ì •
                    if hasattr(torch.backends.mps, 'is_available') and torch.backends.mps.is_available():
                        torch.backends.mps.enabled = True
                        self.logger.info("ğŸ M3 Max MPS ìµœì í™” í™œì„±í™”")
                except Exception as e:
                    self.logger.warning(f"âš ï¸ MPS ìµœì í™” ì„¤ì • ì‹¤íŒ¨: {e}")
            
            # í†µí•© ë©”ëª¨ë¦¬ í™œìš© ì„¤ì •
            if self.memory_gb >= 64:
                self.m3_max_optimizations['large_model_support'] = True
                self.max_model_size_gb = min(32, self.memory_gb * 0.4)  # ë©”ëª¨ë¦¬ì˜ 40%ê¹Œì§€
            else:
                self.m3_max_optimizations['large_model_support'] = False
                self.max_model_size_gb = min(16, self.memory_gb * 0.3)  # ë©”ëª¨ë¦¬ì˜ 30%ê¹Œì§€
            
            self.logger.info(f"ğŸ M3 Max ìµœì í™” ì„¤ì • ì™„ë£Œ - ìµœëŒ€ ëª¨ë¸ í¬ê¸°: {self.max_model_size_gb}GB")
            
        except Exception as e:
            self.logger.error(f"âŒ M3 Max ìµœì í™” ì„¤ì • ì‹¤íŒ¨: {e}")
            self.m3_max_optimizations = None
    
    def _setup_memory_optimization(self):
        """ë©”ëª¨ë¦¬ ìµœì í™” ì‹œìŠ¤í…œ ì„¤ì •"""
        try:
            self.memory_optimizer = StepMemoryOptimizer(self.device)
            
            # ìë™ ë©”ëª¨ë¦¬ ì •ë¦¬ ì„¤ì •
            self.auto_memory_cleanup = True
            self.memory_threshold = 0.85  # 85% ì‚¬ìš©ì‹œ ì •ë¦¬
            self.last_memory_optimization = None
            
            # M3 Max íŠ¹í™” ìµœì í™”
            if self.is_m3_max and self.optimization_enabled:
                initial_result = self.memory_optimizer.optimize_memory()
                if initial_result['success']:
                    self.logger.info(f"ğŸ M3 Max ì´ˆê¸° ë©”ëª¨ë¦¬ ìµœì í™” ì™„ë£Œ")
            
            self.logger.debug(f"ğŸ§¹ ë©”ëª¨ë¦¬ ìµœì í™” ì‹œìŠ¤í…œ ì„¤ì • ì™„ë£Œ")
            
        except Exception as e:
            self.logger.error(f"âŒ ë©”ëª¨ë¦¬ ìµœì í™” ì‹œìŠ¤í…œ ì„¤ì • ì‹¤íŒ¨: {e}")
            self.memory_optimizer = None
    
    def _setup_warmup_system(self):
        """ì›Œë°ì—… ì‹œìŠ¤í…œ ì„¤ì •"""
        try:
            self.warmup_system = WarmupSystem(self)
            self.warmup_completed = False
            self.warmup_results = None
            
            # ì›Œë°ì—… ì„¤ì •
            self.auto_warmup = True
            self.warmup_on_first_use = True
            
            self.logger.debug(f"ğŸ”¥ ì›Œë°ì—… ì‹œìŠ¤í…œ ì„¤ì • ì™„ë£Œ")
            
        except Exception as e:
            self.logger.error(f"âŒ ì›Œë°ì—… ì‹œìŠ¤í…œ ì„¤ì • ì‹¤íŒ¨: {e}")
            self.warmup_system = None
    
    def _setup_performance_monitoring(self):
        """ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì„¤ì •"""
        try:
            self.performance_monitor = PerformanceMonitor(self)
            
            # ë²¤ì¹˜ë§ˆí¬ ê´€ë ¨
            self.start_time = time.time()
            self.benchmark_results = {}
            self.enable_profiling = False
            
            self.logger.debug(f"ğŸ“ˆ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì„¤ì • ì™„ë£Œ")
            
        except Exception as e:
            self.logger.error(f"âŒ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì„¤ì • ì‹¤íŒ¨: {e}")
            self.performance_monitor = None
    
    def _setup_model_interface_safe(self):
        """ModelLoader ì¸í„°í˜ì´ìŠ¤ ì„¤ì • (ë™ê¸° ì•ˆì „) - ğŸ”¥ coroutine ê²½ê³  ì™„ì „ í•´ê²°"""
        try:
            self.logger.info(f"ğŸ”— {self.step_name} ModelLoader ì¸í„°í˜ì´ìŠ¤ ì„¤ì • ì¤‘...")
            
            # Step ì¸í„°í˜ì´ìŠ¤ ìƒì„± (ModelLoaderê°€ ìˆëŠ” ê²½ìš°)
            if hasattr(self, 'model_loader') and self.model_loader:
                try:
                    if hasattr(self.model_loader, 'create_step_interface'):
                        # ğŸ”¥ ë¹„ë™ê¸° í•¨ìˆ˜ì¸ì§€ í™•ì¸í•˜ê³  ì ì ˆíˆ ì²˜ë¦¬
                        create_method = self.model_loader.create_step_interface
                        
                        if asyncio.iscoroutinefunction(create_method):
                            # ë¹„ë™ê¸° í•¨ìˆ˜ì¸ ê²½ìš° - ë™ê¸° ì´ˆê¸°í™”ì—ì„œëŠ” ì²˜ë¦¬í•˜ì§€ ì•ŠìŒ
                            self.logger.warning("âš ï¸ create_step_interfaceê°€ ë¹„ë™ê¸° í•¨ìˆ˜ì„ - ë‚˜ì¤‘ì— ë¹„ë™ê¸°ë¡œ ì²˜ë¦¬ í•„ìš”")
                            self.step_interface = None
                            self._pending_async_setup = True  # ë‚˜ì¤‘ì— ë¹„ë™ê¸° ì„¤ì • í•„ìš” í‘œì‹œ
                        else:
                            # ë™ê¸° í•¨ìˆ˜ì¸ ê²½ìš° ì§ì ‘ í˜¸ì¶œ
                            self.step_interface = create_method(self.step_name)
                            self._pending_async_setup = False
                            self.logger.info("âœ… Step ì¸í„°í˜ì´ìŠ¤ ìƒì„± ì„±ê³µ")
                    else:
                        self.step_interface = None
                        self._pending_async_setup = False
                        self.logger.warning("âš ï¸ ModelLoaderì— create_step_interface ë©”ì„œë“œ ì—†ìŒ")
                except Exception as e:
                    self.logger.warning(f"âš ï¸ Step ì¸í„°í˜ì´ìŠ¤ ìƒì„± ì‹¤íŒ¨: {e}")
                    self.step_interface = None
                    self._pending_async_setup = False
            else:
                self.step_interface = None
                self._pending_async_setup = False
            
            # ëª¨ë¸ ê´€ë ¨ ì†ì„± ì´ˆê¸°í™”
            self._ai_model = None
            self._ai_model_name = None
            self.loaded_models = {}
            self.model_cache = {}
            
            # ì—°ë™ ìƒíƒœ ë¡œê¹…
            loader_status = "âœ… ì—°ê²°ë¨" if hasattr(self, 'model_loader') and self.model_loader else "âŒ ì—°ê²° ì‹¤íŒ¨"
            interface_status = "âœ… ì—°ê²°ë¨" if self.step_interface else "âŒ ì—°ê²° ì‹¤íŒ¨"
            
            self.logger.info(f"ğŸ”— ModelLoader ì—°ë™ ê²°ê³¼:")
            self.logger.info(f"   - ModelLoader: {loader_status}")
            self.logger.info(f"   - Step Interface: {interface_status}")
            
        except Exception as e:
            self.logger.error(f"âŒ ModelLoader ì¸í„°í˜ì´ìŠ¤ ì„¤ì • ì‹¤íŒ¨: {e}")
            self.step_interface = None
            self._pending_async_setup = False
    
    def _setup_model_interface(self):
        """ModelLoader ì¸í„°í˜ì´ìŠ¤ ì„¤ì • (ê¸°ì¡´ í˜¸í™˜ì„±) - ğŸ”¥ ë¹„ë™ê¸° ì²˜ë¦¬ í•´ê²°"""
        # ğŸ”¥ ì„œë¸Œí´ë˜ìŠ¤ì—ì„œ ë¹„ë™ê¸°ë¡œ ì˜¤ë²„ë¼ì´ë“œí•  ìˆ˜ ìˆëŠ” ë©”ì„œë“œ
        # í•˜ì§€ë§Œ ê¸°ë³¸ êµ¬í˜„ì€ ë™ê¸° ì•ˆì „ ë²„ì „ í˜¸ì¶œ
        self._setup_model_interface_safe()
        """ModelLoader ì¸í„°í˜ì´ìŠ¤ ì„¤ì • (DI ê¸°ë°˜) - ğŸ”¥ ë¹„ë™ê¸° ì²˜ë¦¬ í•´ê²°"""
        try:
            self.logger.info(f"ğŸ”— {self.step_name} ModelLoader ì¸í„°í˜ì´ìŠ¤ ì„¤ì • ì¤‘...")
            
            # Step ì¸í„°í˜ì´ìŠ¤ ìƒì„± (ModelLoaderê°€ ìˆëŠ” ê²½ìš°)
            if hasattr(self, 'model_loader') and self.model_loader:
                try:
                    if hasattr(self.model_loader, 'create_step_interface'):
                        # ğŸ”¥ ë¹„ë™ê¸° í•¨ìˆ˜ì¸ì§€ í™•ì¸í•˜ê³  ì ì ˆíˆ ì²˜ë¦¬
                        create_method = self.model_loader.create_step_interface
                        
                        if asyncio.iscoroutinefunction(create_method):
                            # ë¹„ë™ê¸° í•¨ìˆ˜ì¸ ê²½ìš° - ë™ê¸° ì´ˆê¸°í™”ì—ì„œëŠ” ì²˜ë¦¬í•˜ì§€ ì•ŠìŒ
                            self.logger.warning("âš ï¸ create_step_interfaceê°€ ë¹„ë™ê¸° í•¨ìˆ˜ì„ - ë‚˜ì¤‘ì— ë¹„ë™ê¸°ë¡œ ì²˜ë¦¬ í•„ìš”")
                            self.step_interface = None
                            self._pending_async_setup = True  # ë‚˜ì¤‘ì— ë¹„ë™ê¸° ì„¤ì • í•„ìš” í‘œì‹œ
                        else:
                            # ë™ê¸° í•¨ìˆ˜ì¸ ê²½ìš° ì§ì ‘ í˜¸ì¶œ
                            self.step_interface = create_method(self.step_name)
                            self.logger.info("âœ… Step ì¸í„°í˜ì´ìŠ¤ ìƒì„± ì„±ê³µ")
                    else:
                        self.step_interface = None
                        self.logger.warning("âš ï¸ ModelLoaderì— create_step_interface ë©”ì„œë“œ ì—†ìŒ")
                except Exception as e:
                    self.logger.warning(f"âš ï¸ Step ì¸í„°í˜ì´ìŠ¤ ìƒì„± ì‹¤íŒ¨: {e}")
                    self.step_interface = None
            else:
                self.step_interface = None
                self._pending_async_setup = False
            
            # ëª¨ë¸ ê´€ë ¨ ì†ì„± ì´ˆê¸°í™”
            self._ai_model = None
            self._ai_model_name = None
            self.loaded_models = {}
            self.model_cache = {}
            
            # ì—°ë™ ìƒíƒœ ë¡œê¹…
            loader_status = "âœ… ì—°ê²°ë¨" if hasattr(self, 'model_loader') and self.model_loader else "âŒ ì—°ê²° ì‹¤íŒ¨"
            interface_status = "âœ… ì—°ê²°ë¨" if self.step_interface else "âŒ ì—°ê²° ì‹¤íŒ¨"
            
            self.logger.info(f"ğŸ”— ModelLoader ì—°ë™ ê²°ê³¼:")
            self.logger.info(f"   - ModelLoader: {loader_status}")
            self.logger.info(f"   - Step Interface: {interface_status}")
            
        except Exception as e:
            self.logger.error(f"âŒ ModelLoader ì¸í„°í˜ì´ìŠ¤ ì„¤ì • ì‹¤íŒ¨: {e}")
            self.step_interface = None
            self._pending_async_setup = False
    
    async def _setup_model_interface_async(self):
        """ModelLoader ì¸í„°í˜ì´ìŠ¤ ë¹„ë™ê¸° ì„¤ì • - ğŸ”¥ ë¹„ë™ê¸° ì²˜ë¦¬ ì™„ì „ í•´ê²°"""
        try:
            self.logger.info(f"ğŸ”— {self.step_name} ModelLoader ì¸í„°í˜ì´ìŠ¤ ë¹„ë™ê¸° ì„¤ì • ì¤‘...")
            
            # ëŒ€ê¸° ì¤‘ì¸ ë¹„ë™ê¸° ì„¤ì •ì´ ìˆëŠ” ê²½ìš°
            if getattr(self, '_pending_async_setup', False):
                if hasattr(self, 'model_loader') and self.model_loader:
                    try:
                        if hasattr(self.model_loader, 'create_step_interface'):
                            create_method = self.model_loader.create_step_interface
                            
                            if asyncio.iscoroutinefunction(create_method):
                                # ë¹„ë™ê¸° í•¨ìˆ˜ì¸ ê²½ìš° awaitë¡œ í˜¸ì¶œ
                                self.step_interface = await create_method(self.step_name)
                                self.logger.info("âœ… Step ì¸í„°í˜ì´ìŠ¤ ë¹„ë™ê¸° ìƒì„± ì„±ê³µ")
                            else:
                                # ë™ê¸° í•¨ìˆ˜ì¸ ê²½ìš° ì§ì ‘ í˜¸ì¶œ
                                self.step_interface = create_method(self.step_name)
                                self.logger.info("âœ… Step ì¸í„°í˜ì´ìŠ¤ ìƒì„± ì„±ê³µ (ë™ê¸°)")
                            
                            self._pending_async_setup = False
                    except Exception as e:
                        self.logger.warning(f"âš ï¸ Step ì¸í„°í˜ì´ìŠ¤ ë¹„ë™ê¸° ìƒì„± ì‹¤íŒ¨: {e}")
                        self.step_interface = None
            
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ ModelLoader ì¸í„°í˜ì´ìŠ¤ ë¹„ë™ê¸° ì„¤ì • ì‹¤íŒ¨: {e}")
            return False
    
    def has_pending_async_setup(self) -> bool:
        """ë¹„ë™ê¸° ì„¤ì •ì´ ëŒ€ê¸° ì¤‘ì¸ì§€ í™•ì¸"""
        return getattr(self, '_pending_async_setup', False)
    
    async def complete_async_setup(self) -> bool:
        """ëŒ€ê¸° ì¤‘ì¸ ë¹„ë™ê¸° ì„¤ì • ì™„ë£Œ"""
        try:
            if self.has_pending_async_setup():
                return await self._setup_model_interface_async()
            return True
        except Exception as e:
            self.logger.error(f"âŒ ë¹„ë™ê¸° ì„¤ì • ì™„ë£Œ ì‹¤íŒ¨: {e}")
            return False
    
    def _setup_checkpoint_detection(self):
        """ì²´í¬í¬ì¸íŠ¸ íƒì§€ ë° ì—°ë™"""
        try:
            self.logger.info(f"ğŸ” {self.step_name} ì²´í¬í¬ì¸íŠ¸ íƒì§€ ì‹œì‘...")
            
            # ì „ì—­ ì²´í¬í¬ì¸íŠ¸ ë§¤ë‹ˆì € ì‚¬ìš©
            if BaseStepMixin._global_checkpoint_manager is None:
                BaseStepMixin._global_checkpoint_manager = CheckpointManager()
                BaseStepMixin._global_checkpoint_manager.scan_checkpoints()
            
            self.checkpoint_manager = BaseStepMixin._global_checkpoint_manager
            
            # Stepì— ì í•©í•œ ì²´í¬í¬ì¸íŠ¸ ì°¾ê¸°
            compatible_checkpoint = self.checkpoint_manager.get_checkpoint_for_step(self.step_name)
            
            if compatible_checkpoint:
                self.primary_checkpoint = compatible_checkpoint
                self.logger.info(f"âœ… í˜¸í™˜ ì²´í¬í¬ì¸íŠ¸ ë°œê²¬: {compatible_checkpoint.name} ({compatible_checkpoint.size_gb:.1f}GB)")
                
                # ëŒ€ìš©ëŸ‰ ì²´í¬í¬ì¸íŠ¸ íŠ¹ë³„ ì²˜ë¦¬
                if compatible_checkpoint.size_gb > 10.0:
                    self.logger.info(f"ğŸ¯ ëŒ€ìš©ëŸ‰ ì²´í¬í¬ì¸íŠ¸ ê°ì§€ - íŠ¹ë³„ ìµœì í™” ì ìš©")
                    self.large_checkpoint_mode = True
                else:
                    self.large_checkpoint_mode = False
            else:
                self.primary_checkpoint = None
                self.large_checkpoint_mode = False
                self.logger.warning(f"âš ï¸ {self.step_name}ì— í˜¸í™˜ë˜ëŠ” ì²´í¬í¬ì¸íŠ¸ ì—†ìŒ")
            
            # ì²´í¬í¬ì¸íŠ¸ ì •ë³´ ì €ì¥
            self.checkpoint_info = {
                'primary': self.primary_checkpoint,
                'total_available': len(self.checkpoint_manager.checkpoints),
                'compatible_count': len([cp for cp in self.checkpoint_manager.checkpoints.values() 
                                       if self.step_name in cp.step_compatible]),
                'large_checkpoint_mode': self.large_checkpoint_mode
            }
            
        except Exception as e:
            self.logger.error(f"âŒ ì²´í¬í¬ì¸íŠ¸ íƒì§€ ì‹¤íŒ¨: {e}")
            self.primary_checkpoint = None
            self.checkpoint_manager = None
            self.large_checkpoint_mode = False
    
    def _finalize_initialization(self):
        """ìµœì¢… ì´ˆê¸°í™” ì™„ë£Œ ì²˜ë¦¬"""
        try:
            # ìƒíƒœ ì—…ë°ì´íŠ¸
            self.state['status'] = 'initialized'
            self.state['last_update'] = time.time()
            self.is_initialized = True
            
            # ì´ˆê¸°í™” ì‹œê°„ ê¸°ë¡
            initialization_duration = time.time() - self.initialization_time
            self.initialization_duration = initialization_duration
            
            # ìë™ ì›Œë°ì—… (ì„¤ì •ëœ ê²½ìš°)
            if getattr(self, 'auto_warmup', False) and hasattr(self, 'warmup_system'):
                try:
                    self.warmup_results = self.warmup_system.run_warmup_sequence()
                    if self.warmup_results.get('success', False):
                        self.warmup_completed = True
                        self.is_ready = True
                        self.logger.info(f"ğŸ”¥ ìë™ ì›Œë°ì—… ì™„ë£Œ")
                except Exception as e:
                    self.logger.warning(f"âš ï¸ ìë™ ì›Œë°ì—… ì‹¤íŒ¨: {e}")
            
            # ì´ˆê¸°í™” ì„±ê³µ ë¡œê¹…
            self.logger.info(f"ğŸ‰ {self.step_name} ì´ˆê¸°í™” ì™„ì „ ì™„ë£Œ ({initialization_duration:.3f}ì´ˆ)")
            
        except Exception as e:
            self.logger.error(f"âŒ ìµœì¢… ì´ˆê¸°í™” ì™„ë£Œ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
    
    def _emergency_initialization(self):
        """ğŸ”¥ ê¸´ê¸‰ ì´ˆê¸°í™” (ì—ëŸ¬ ë°œìƒì‹œ) - ì™„ì „ êµ¬í˜„ + conda í™˜ê²½ ì§€ì›"""
        try:
            # logger ìš°ì„  í™•ì¸ ë° ìƒì„±
            if not hasattr(self, 'logger') or self.logger is None:
                self._create_emergency_logger()
            
            # Step ê¸°ë³¸ ì •ë³´ ì„¤ì •
            self.step_name = getattr(self, 'step_name', self.__class__.__name__)
            self.device = "cpu"
            self.is_m3_max = False
            self.memory_gb = 16.0
            self.error_count = getattr(self, 'error_count', 0) + 1
            
            # conda í™˜ê²½ ì •ë³´ ì¶”ê°€
            self.conda_env = os.environ.get('CONDA_DEFAULT_ENV', '')
            self.is_conda_env = bool(self.conda_env)
            
            # ìƒíƒœ í”Œë˜ê·¸ë“¤
            self.is_initialized = False
            self.is_ready = False
            self.di_available = False
            self.has_model = False
            self.model_loaded = False
            self.warmup_completed = False
            
            # ìµœì†Œí•œì˜ ì„¤ì •ë“¤
            self.config = SafeConfig()
            self.performance_metrics = {
                'process_count': 0,
                'total_process_time': 0.0,
                'average_process_time': 0.0,
                'error_history': []
            }
            self.state = {
                'status': 'emergency', 
                'last_update': time.time(),
                'errors': [f"Emergency initialization at {time.time()}"],
                'warnings': [],
                'metrics': {}
            }
            
            # ê¸°ë³¸ ì†ì„±ë“¤
            self.step_number = 0
            self.step_type = 'emergency'
            self.input_size = (512, 512)
            self.output_size = (512, 512)
            self.batch_size = 1
            self.use_fp16 = False
            self.optimization_enabled = False
            self.auto_memory_cleanup = False
            self.auto_warmup = False
            self._pending_async_setup = False
            
            # ì˜ì¡´ì„±ë“¤ì„ Noneìœ¼ë¡œ ì´ˆê¸°í™”
            self.model_loader = None
            self.memory_manager = None
            self.data_converter = None
            self.step_interface = None
            self.checkpoint_manager = None
            self.performance_monitor = None
            self.warmup_system = None
            self.memory_optimizer = None
            
            # ëª¨ë¸ ê´€ë ¨ ì†ì„±ë“¤
            self._ai_model = None
            self._ai_model_name = None
            self.loaded_models = {}
            self.model_cache = {}
            self.primary_checkpoint = None
            self.large_checkpoint_mode = False
            
            # íƒ€ì´ë° ê´€ë ¨
            self.initialization_time = time.time()
            self.last_processing_time = None
            self.total_processing_count = 0
            self.processing_history = []
            self.last_memory_optimization = None
            
            # ì²´í¬í¬ì¸íŠ¸ ì •ë³´
            self.checkpoint_info = {
                'primary': None,
                'total_available': 0,
                'compatible_count': 0,
                'large_checkpoint_mode': False
            }
            
            # M3 Max ê´€ë ¨
            self.m3_max_optimizations = None
            self.max_model_size_gb = 8.0
            
            # ì½œë°±ê³¼ íˆìŠ¤í† ë¦¬
            self.state_change_callbacks = []
            
            # ê¸´ê¸‰ ì´ˆê¸°í™” ì™„ë£Œ ë¡œê¹…
            self.logger.error(f"ğŸš¨ {self.step_name} ê¸´ê¸‰ ì´ˆê¸°í™” ì‹¤í–‰")
            self.logger.warning("âš ï¸ ìµœì†Œí•œì˜ ê¸°ëŠ¥ë§Œ ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤")
            
            if self.is_conda_env:
                self.logger.info(f"ğŸ conda í™˜ê²½ ê°ì§€: {self.conda_env}")
            else:
                self.logger.warning("âš ï¸ conda í™˜ê²½ì´ ì•„ë‹˜")
            
        except Exception as e:
            # ìµœí›„ì˜ ìˆ˜ë‹¨: printë¡œ ë¡œê¹…
            print(f"ğŸš¨ ê¸´ê¸‰ ì´ˆê¸°í™”ë„ ì‹¤íŒ¨: {e}")
            print(f"ğŸš¨ {getattr(self, 'step_name', 'Unknown')} - ìµœì†Œ ì†ì„±ë§Œ ì„¤ì •")
            
            # ìµœì†Œí•œì˜ ì†ì„±ë“¤ë§Œ ì„¤ì •
            if not hasattr(self, 'step_name'):
                self.step_name = self.__class__.__name__
            if not hasattr(self, 'device'):
                self.device = "cpu"
            if not hasattr(self, 'is_initialized'):
                self.is_initialized = False
            if not hasattr(self, 'error_count'):
                self.error_count = 1
            if not hasattr(self, 'conda_env'):
                self.conda_env = os.environ.get('CONDA_DEFAULT_ENV', '')
            if not hasattr(self, 'is_conda_env'):
                self.is_conda_env = bool(self.conda_env)
                
    # ==============================================
    # ğŸ”¥ DI ê´€ë ¨ ë©”ì„œë“œë“¤
    # ==============================================
    
    def get_di_status(self) -> Dict[str, Any]:
        """DI ìƒíƒœ í™•ì¸ ë©”ì„œë“œ"""
        try:
            container = DIHelper.get_di_container()
            
            dependencies = {}
            if hasattr(self, 'model_loader'):
                dependencies['model_loader'] = self.model_loader is not None
            if hasattr(self, 'memory_manager'):
                dependencies['memory_manager'] = self.memory_manager is not None
            if hasattr(self, 'data_converter'):
                dependencies['data_converter'] = self.data_converter is not None
            if hasattr(self, 'checkpoint_manager'):
                dependencies['checkpoint_manager'] = self.checkpoint_manager is not None
            if hasattr(self, 'performance_monitor'):
                dependencies['performance_monitor'] = self.performance_monitor is not None
            if hasattr(self, 'warmup_system'):
                dependencies['warmup_system'] = self.warmup_system is not None
            
            registered_services = []
            if container:
                try:
                    registered_services = list(container.get_registered_services().keys())
                except:
                    pass
            
            return {
                'di_available': getattr(self, 'di_available', False),
                'container_available': container is not None,
                'dependencies': dependencies,
                'registered_services': registered_services
            }
            
        except Exception as e:
            return {
                'di_available': False,
                'container_available': False,
                'dependencies': {},
                'registered_services': [],
                'error': str(e)
            }

    def reinject_dependencies(self) -> Dict[str, bool]:
        """ì˜ì¡´ì„± ì¬ì£¼ì… ë©”ì„œë“œ"""
        try:
            self.logger.info(f"ğŸ”„ {self.step_name} ì˜ì¡´ì„± ì¬ì£¼ì… ì‹œì‘...")
            return self._inject_dependencies()
        except Exception as e:
            self.logger.error(f"âŒ ì˜ì¡´ì„± ì¬ì£¼ì… ì‹¤íŒ¨: {e}")
            return {key: False for key in ['model_loader', 'memory_manager', 'data_converter', 'checkpoint_manager', 'performance_monitor', 'warmup_system']}

    def setup_di_fallbacks(self):
        """DI í´ë°± ì„¤ì • ë©”ì„œë“œ"""
        try:
            # ë©”ëª¨ë¦¬ ìµœì í™” í´ë°± (ë‚´ì¥ StepMemoryOptimizer ì‚¬ìš©)
            if not hasattr(self, 'memory_manager') or self.memory_manager is None:
                try:
                    if not hasattr(self, 'memory_optimizer') or self.memory_optimizer is None:
                        self.memory_optimizer = StepMemoryOptimizer(self.device)
                    self.logger.debug("âœ… ë‚´ì¥ ë©”ëª¨ë¦¬ ìµœì í™” ì‹œìŠ¤í…œ í™œì„±í™”")
                except Exception as e:
                    self.logger.debug(f"âš ï¸ ë‚´ì¥ ë©”ëª¨ë¦¬ ìµœì í™” í™œì„±í™” ì‹¤íŒ¨: {e}")
            
            # ì²´í¬í¬ì¸íŠ¸ ê´€ë¦¬ í´ë°± (ì „ì—­ CheckpointManager ì‚¬ìš©)
            if not hasattr(self, 'checkpoint_manager') or self.checkpoint_manager is None:
                try:
                    if BaseStepMixin._global_checkpoint_manager is None:
                        BaseStepMixin._global_checkpoint_manager = CheckpointManager()
                        BaseStepMixin._global_checkpoint_manager.scan_checkpoints()
                    
                    self.checkpoint_manager = BaseStepMixin._global_checkpoint_manager
                    self.logger.debug("âœ… ì „ì—­ ì²´í¬í¬ì¸íŠ¸ ê´€ë¦¬ì í™œì„±í™”")
                except Exception as e:
                    self.logger.debug(f"âš ï¸ ì „ì—­ ì²´í¬í¬ì¸íŠ¸ ê´€ë¦¬ì í™œì„±í™” ì‹¤íŒ¨: {e}")
            
            # ì„±ëŠ¥ ëª¨ë‹ˆí„° í´ë°±
            if not hasattr(self, 'performance_monitor') or self.performance_monitor is None:
                try:
                    self.performance_monitor = PerformanceMonitor(self)
                    self.logger.debug("âœ… ë‚´ì¥ ì„±ëŠ¥ ëª¨ë‹ˆí„° í™œì„±í™”")
                except Exception as e:
                    self.logger.debug(f"âš ï¸ ë‚´ì¥ ì„±ëŠ¥ ëª¨ë‹ˆí„° í™œì„±í™” ì‹¤íŒ¨: {e}")
            
            # ì›Œë°ì—… ì‹œìŠ¤í…œ í´ë°±
            if not hasattr(self, 'warmup_system') or self.warmup_system is None:
                try:
                    self.warmup_system = WarmupSystem(self)
                    self.logger.debug("âœ… ë‚´ì¥ ì›Œë°ì—… ì‹œìŠ¤í…œ í™œì„±í™”")
                except Exception as e:
                    self.logger.debug(f"âš ï¸ ë‚´ì¥ ì›Œë°ì—… ì‹œìŠ¤í…œ í™œì„±í™” ì‹¤íŒ¨: {e}")
                    
            self.logger.info("âœ… DI í´ë°± ì‹œìŠ¤í…œ ì„¤ì • ì™„ë£Œ")
            
        except Exception as e:
            self.logger.error(f"âŒ DI í´ë°± ì„¤ì • ì‹¤íŒ¨: {e}")

    def get_di_info_for_status(self) -> Dict[str, Any]:
        """get_status() ë©”ì„œë“œì— í¬í•¨í•  DI ì •ë³´"""
        try:
            di_status = self.get_di_status()
            return {
                'di_available': self.di_available,
                'di_container_connected': di_status.get('container_available', False),
                'dependencies_status': di_status.get('dependencies', {}),
                'registered_services_count': len(di_status.get('registered_services', [])),
                'step_interface_available': hasattr(self, 'step_interface') and self.step_interface is not None,
                'pending_async_setup': getattr(self, '_pending_async_setup', False)
            }
        except Exception as e:
            return {
                'di_available': False,
                'di_container_connected': False,
                'dependencies_status': {},
                'registered_services_count': 0,
                'step_interface_available': False,
                'pending_async_setup': False,
                'error': str(e)
            }
    
    # ==============================================
    # ğŸ”¥ ë””ë°”ì´ìŠ¤ ê´€ë ¨ ë©”ì„œë“œë“¤
    # ==============================================
    
    def _detect_optimal_device(self) -> str:
        """ìµœì  ë””ë°”ì´ìŠ¤ ê°ì§€"""
        try:
            if TORCH_AVAILABLE:
                if MPS_AVAILABLE:
                    return "mps"
                elif hasattr(torch, 'cuda') and torch.cuda.is_available():
                    return "cuda"
            return "cpu"
        except:
            return "cpu"
    
    def _detect_m3_max(self) -> bool:
        """M3 Max ê°ì§€"""
        try:
            import platform
            import subprocess
            if platform.system() == 'Darwin':
                result = subprocess.run(
                    ['sysctl', '-n', 'machdep.cpu.brand_string'],
                    capture_output=True, text=True, timeout=5
                )
                return 'M3' in result.stdout
        except:
            pass
        return False
    
    def _get_memory_info(self) -> Dict[str, Any]:
        """ë©”ëª¨ë¦¬ ì •ë³´ ì¡°íšŒ"""
        try:
            import psutil
            memory = psutil.virtual_memory()
            return {
                "total_gb": memory.total / 1024**3,
                "available_gb": memory.available / 1024**3,
                "percent_used": memory.percent
            }
        except ImportError:
            return {
                "total_gb": 16.0,
                "available_gb": 8.0,
                "percent_used": 50.0
            }
    
    def _setup_mps_optimizations(self):
        """MPS ìµœì í™” ì„¤ì •"""
        try:
            if not MPS_AVAILABLE:
                return
            
            # MPS íŠ¹í™” ì„¤ì •
            self.mps_optimizations = {
                'fallback_enabled': True,
                'memory_fraction': 0.8,
                'precision': 'fp16' if self.use_fp16 else 'fp32'
            }
            
            self.logger.debug("ğŸ MPS ìµœì í™” ì„¤ì • ì™„ë£Œ")
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ MPS ìµœì í™” ì„¤ì • ì‹¤íŒ¨: {e}")
    
    def _setup_cuda_optimizations(self):
        """CUDA ìµœì í™” ì„¤ì •"""
        try:
            if not TORCH_AVAILABLE or not torch.cuda.is_available():
                return
            
            # CUDA íŠ¹í™” ì„¤ì •
            self.cuda_optimizations = {
                'memory_fraction': 0.9,
                'allow_tf32': True,
                'benchmark': True
            }
            
            # cuDNN ì„¤ì •
            torch.backends.cudnn.benchmark = True
            torch.backends.cudnn.deterministic = False
            
            self.logger.debug("ğŸš€ CUDA ìµœì í™” ì„¤ì • ì™„ë£Œ")
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ CUDA ìµœì í™” ì„¤ì • ì‹¤íŒ¨: {e}")
    
    # ==============================================
    # ğŸ”¥ ê³µí†µ ë©”ì„œë“œë“¤ (ë¹„ë™ê¸° ì²˜ë¦¬ ì™„ì „ í•´ê²°)
    # ==============================================
    
    def _sync_fallback(self, method_name: str, *args, **kwargs) -> Dict[str, Any]:
        """ë™ê¸° í´ë°± ì²˜ë¦¬"""
        try:
            if hasattr(self, f"_sync_{method_name}"):
                sync_method = getattr(self, f"_sync_{method_name}")
                return sync_method(*args, **kwargs)
            else:
                # ê¸°ë³¸ ì„±ê³µ ì‘ë‹µ
                return {
                    "success": True,
                    "method": f"sync_fallback_{method_name}",
                    "message": f"{method_name} ë™ê¸° í´ë°± ì‹¤í–‰ ì™„ë£Œ"
                }
        except Exception as e:
            return {
                "success": False,
                "method": f"sync_fallback_{method_name}",
                "error": str(e)
            }
    
    @safe_async_wrapper
    async def warmup_step(self) -> Dict[str, Any]:
        """Step ì›Œë°ì—… (ë¹„ë™ê¸° ì•ˆì „) - ğŸ”¥ coroutine ê²½ê³  ì™„ì „ í•´ê²°"""
        try:
            self.logger.info(f"ğŸ”¥ {self.__class__.__name__} ì›Œë°ì—… ì‹œì‘...")
            
            # ë‹¨ê³„ë³„ ì›Œë°ì—…
            steps = [
                self._warmup_memory,
                self._warmup_model,
                self._warmup_cache,
                self._warmup_components
            ]
            
            results = []
            for i, step in enumerate(steps, 1):
                try:
                    if asyncio.iscoroutinefunction(step):
                        result = await step()
                    else:
                        result = step()
                    results.append(f"step{i}_success")
                except Exception as e:
                    self.logger.debug(f"ì›Œë°ì—… ë‹¨ê³„ {i} ì‹¤íŒ¨: {e}")
                    results.append(f"step{i}_failed")
            
            success_count = sum(1 for r in results if 'success' in r)
            total_count = len(results)
            
            self.logger.info(f"ğŸ”¥ ì›Œë°ì—… ì™„ë£Œ: {success_count}/{total_count} ì„±ê³µ")
            
            return {
                "success": success_count > 0,
                "results": results,
                "success_rate": success_count / total_count if total_count > 0 else 0,
                "step_class": self.__class__.__name__
            }
        
        except Exception as e:
            self.logger.warning(f"âš ï¸ ì›Œë°ì—… ì‹¤íŒ¨: {e}")
            return {"success": False, "error": str(e)}
    
    def _sync_warmup_step(self) -> Dict[str, Any]:
        """ë™ê¸° ì›Œë°ì—… í´ë°±"""
        try:
            self.logger.info(f"ğŸ”¥ {self.__class__.__name__} ë™ê¸° ì›Œë°ì—…...")
            
            # ê¸°ë³¸ ë™ê¸° ì›Œë°ì—…
            gc_result = self._warmup_memory_sync()
            model_result = self._warmup_model_sync()
            
            return {
                "success": True,
                "method": "sync_warmup",
                "results": [gc_result, model_result],
                "step_class": self.__class__.__name__
            }
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    def _warmup_memory_sync(self) -> str:
        """ë™ê¸° ë©”ëª¨ë¦¬ ì›Œë°ì—…"""
        try:
            import gc
            collected = gc.collect()
            return f"memory_sync_success_{collected}"
        except:
            return "memory_sync_failed"
    
    def _warmup_model_sync(self) -> str:
        """ë™ê¸° ëª¨ë¸ ì›Œë°ì—…"""
        try:
            if hasattr(self, 'model_loader'):
                return "model_sync_success"
            else:
                return "model_sync_skipped"
        except:
            return "model_sync_failed"
    
    async def _warmup_memory(self) -> str:
        """ë¹„ë™ê¸° ë©”ëª¨ë¦¬ ì›Œë°ì—…"""
        try:
            # ì•ˆì „í•œ ë©”ëª¨ë¦¬ ì •ë¦¬
            result = safe_mps_empty_cache()
            return f"memory_async_{result['method']}"
        except Exception as e:
            self.logger.debug(f"ë¹„ë™ê¸° ë©”ëª¨ë¦¬ ì›Œë°ì—… ì‹¤íŒ¨: {e}")
            return "memory_async_failed"
    
    async def _warmup_model(self) -> str:
        """ë¹„ë™ê¸° ëª¨ë¸ ì›Œë°ì—…"""
        try:
            if hasattr(self, 'model_loader') and self.model_loader:
                # ëª¨ë¸ ë¡œë” ìƒíƒœ í™•ì¸
                return "model_async_success"
            else:
                return "model_async_skipped"
        except Exception as e:
            self.logger.debug(f"ë¹„ë™ê¸° ëª¨ë¸ ì›Œë°ì—… ì‹¤íŒ¨: {e}")
            return "model_async_failed"
    
    async def _warmup_cache(self) -> str:
        """ë¹„ë™ê¸° ìºì‹œ ì›Œë°ì—…"""
        try:
            if hasattr(self, '_cache'):
                # ìºì‹œ ì´ˆê¸°í™”
                return "cache_async_success"
            else:
                return "cache_async_skipped"
        except:
            return "cache_async_failed"
    
    async def _warmup_components(self) -> str:
        """ë¹„ë™ê¸° ì»´í¬ë„ŒíŠ¸ ì›Œë°ì—…"""
        try:
            # Stepë³„ íŠ¹í™” ì»´í¬ë„ŒíŠ¸ ì›Œë°ì—…
            if hasattr(self, '_step_specific_warmup'):
                await self._step_specific_warmup()
                return "components_async_success"
            else:
                return "components_async_skipped"
        except Exception as e:
            self.logger.debug(f"ì»´í¬ë„ŒíŠ¸ ì›Œë°ì—… ì‹¤íŒ¨: {e}")
            return "components_async_failed"
    
    async def _step_specific_warmup(self):
        """Stepë³„ íŠ¹í™” ì›Œë°ì—… (ê¸°ë³¸ êµ¬í˜„)"""
        pass
    
    @safe_async_wrapper
    async def cleanup(self) -> Dict[str, Any]:
        """Step ì •ë¦¬ (ë¹„ë™ê¸° ì•ˆì „)"""
        try:
            self.logger.info(f"ğŸ“‹ {self.__class__.__name__} ì •ë¦¬ ì‹œì‘...")
            
            # ë©”ëª¨ë¦¬ ì •ë¦¬
            cleanup_result = safe_mps_empty_cache()
            
            # ë¦¬ì†ŒìŠ¤ ì •ë¦¬
            if hasattr(self, '_cleanup_resources'):
                if asyncio.iscoroutinefunction(self._cleanup_resources):
                    await self._cleanup_resources()
                else:
                    self._cleanup_resources()
            
            self.logger.info(f"âœ… {self.__class__.__name__} ì •ë¦¬ ì™„ë£Œ")
            
            return {
                "success": True,
                "cleanup_method": cleanup_result.get("method", "unknown"),
                "step_class": self.__class__.__name__
            }
        
        except Exception as e:
            self.logger.warning(f"âš ï¸ ì •ë¦¬ ì‹¤íŒ¨: {e}")
            return {"success": False, "error": str(e)}
    
    def _sync_cleanup(self) -> Dict[str, Any]:
        """ë™ê¸° ì •ë¦¬ í´ë°±"""
        try:
            import gc
            collected = gc.collect()
            return {
                "success": True,
                "method": "sync_cleanup",
                "collected": collected
            }
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    def get_model(self, model_name: Optional[str] = None) -> Optional[Any]:
        """ëª¨ë¸ ê°€ì ¸ì˜¤ê¸° (DI ê¸°ë°˜)"""
        try:
            # ìºì‹œ í™•ì¸
            cache_key = model_name or "default"
            if hasattr(self, 'model_cache') and cache_key in self.model_cache:
                return self.model_cache[cache_key]
            
            model = None
            
            # DIë¥¼ í†µí•œ ModelLoader ì‚¬ìš©
            if hasattr(self, 'model_loader') and self.model_loader:
                try:
                    if hasattr(self.model_loader, 'get_model'):
                        model = self.model_loader.get_model(model_name or "default")
                except Exception as e:
                    self.logger.debug(f"ModelLoader.get_model ì‹¤íŒ¨: {e}")
            
            # Step ì¸í„°í˜ì´ìŠ¤ë¥¼ í†µí•œ ëª¨ë¸ ê°€ì ¸ì˜¤ê¸°
            if model is None and hasattr(self, 'step_interface') and self.step_interface:
                try:
                    if hasattr(self.step_interface, 'get_model'):
                        model = self.step_interface.get_model(model_name)
                except Exception as e:
                    self.logger.debug(f"step_interface.get_model ì‹¤íŒ¨: {e}")
            
            # í´ë°±: ì§ì ‘ import
            if model is None:
                try:
                    from ..utils.model_loader import get_global_model_loader
                    loader = get_global_model_loader()
                    if loader and hasattr(loader, 'get_model'):
                        model = loader.get_model(model_name or "default")
                except Exception as e:
                    self.logger.debug(f"í´ë°± ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            
            # ìºì‹œì— ì €ì¥
            if model is not None:
                if not hasattr(self, 'model_cache'):
                    self.model_cache = {}
                self.model_cache[cache_key] = model
                self.logger.debug(f"âœ… ëª¨ë¸ ìºì‹œ ì €ì¥: {cache_key}")
            
            return model
                
        except Exception as e:
            self.logger.error(f"âŒ ëª¨ë¸ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {e}")
            return None
    
    async def get_model_async(self, model_name: Optional[str] = None) -> Optional[Any]:
        """ë¹„ë™ê¸° ëª¨ë¸ ê°€ì ¸ì˜¤ê¸° (DI ê¸°ë°˜, ë¹„ë™ê¸° ì²˜ë¦¬ ì™„ì „ í•´ê²°)"""
        try:
            # ìºì‹œ í™•ì¸
            cache_key = model_name or "default"
            if hasattr(self, 'model_cache') and cache_key in self.model_cache:
                return self.model_cache[cache_key]
            
            model = None
            
            # DIë¥¼ í†µí•œ ModelLoader ì‚¬ìš©
            if hasattr(self, 'model_loader') and self.model_loader:
                try:
                    if hasattr(self.model_loader, 'get_model_async'):
                        model = await self.model_loader.get_model_async(model_name or "default")
                    elif hasattr(self.model_loader, 'get_model'):
                        model = self.model_loader.get_model(model_name or "default")
                except Exception as e:
                    self.logger.debug(f"ë¹„ë™ê¸° ModelLoader ì‹¤íŒ¨: {e}")
            
            # Step ì¸í„°í˜ì´ìŠ¤ë¥¼ í†µí•œ ëª¨ë¸ ê°€ì ¸ì˜¤ê¸°
            if model is None and hasattr(self, 'step_interface') and self.step_interface:
                try:
                    if hasattr(self.step_interface, 'get_model_async'):
                        model = await self.step_interface.get_model_async(model_name)
                    elif hasattr(self.step_interface, 'get_model'):
                        model = self.step_interface.get_model(model_name)
                except Exception as e:
                    self.logger.debug(f"ë¹„ë™ê¸° step_interface ì‹¤íŒ¨: {e}")
            
            # í´ë°±: ì§ì ‘ import
            if model is None:
                try:
                    from ..utils.model_loader import get_global_model_loader
                    loader = get_global_model_loader()
                    if loader:
                        if hasattr(loader, 'get_model_async'):
                            model = await loader.get_model_async(model_name or "default")
                        elif hasattr(loader, 'get_model'):
                            model = loader.get_model(model_name or "default")
                except Exception as e:
                    self.logger.debug(f"í´ë°± ë¹„ë™ê¸° ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            
            # ìºì‹œì— ì €ì¥
            if model is not None:
                if not hasattr(self, 'model_cache'):
                    self.model_cache = {}
                self.model_cache[cache_key] = model
                self.logger.debug(f"âœ… ë¹„ë™ê¸° ëª¨ë¸ ìºì‹œ ì €ì¥: {cache_key}")
            
            return model
                
        except Exception as e:
            self.logger.error(f"âŒ ë¹„ë™ê¸° ëª¨ë¸ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {e}")
            return None
    
    def optimize_memory(self, aggressive: bool = False) -> Dict[str, Any]:
        """ë©”ëª¨ë¦¬ ìµœì í™” (DI ê¸°ë°˜)"""
        try:
            # DIë¥¼ í†µí•œ MemoryManager ì‚¬ìš©
            if hasattr(self, 'memory_manager') and self.memory_manager:
                try:
                    if hasattr(self.memory_manager, 'optimize_memory'):
                        result = self.memory_manager.optimize_memory(aggressive=aggressive)
                        if result.get('success', False):
                            self.last_memory_optimization = time.time()
                            return result
                except Exception as e:
                    self.logger.debug(f"DI MemoryManager ì‹¤íŒ¨: {e}")
            
            # ë‚´ì¥ ë©”ëª¨ë¦¬ ìµœì í™” ì‚¬ìš©
            if hasattr(self, 'memory_optimizer') and self.memory_optimizer:
                try:
                    result = self.memory_optimizer.optimize_memory(aggressive=aggressive)
                    if result.get('success', False):
                        self.last_memory_optimization = time.time()
                    return result
                except Exception as e:
                    self.logger.debug(f"ë‚´ì¥ ë©”ëª¨ë¦¬ ìµœì í™” ì‹¤íŒ¨: {e}")
            
            # ê¸°ë³¸ ë©”ëª¨ë¦¬ ì •ë¦¬
            before_objects = len(gc.get_objects())
            gc.collect()
            after_objects = len(gc.get_objects())
            
            result = {
                "success": True,
                "message": "ê¸°ë³¸ ë©”ëª¨ë¦¬ ì •ë¦¬ ì™„ë£Œ",
                "objects_freed": before_objects - after_objects,
                "timestamp": time.time()
            }
            
            self.last_memory_optimization = time.time()
            return result
            
        except Exception as e:
            self.logger.error(f"âŒ ë©”ëª¨ë¦¬ ìµœì í™” ì‹¤íŒ¨: {e}")
            return {"success": False, "error": str(e)}
    
    async def optimize_memory_async(self, aggressive: bool = False) -> Dict[str, Any]:
        """ë¹„ë™ê¸° ë©”ëª¨ë¦¬ ìµœì í™” - ğŸ”¥ ë¹„ë™ê¸° ì²˜ë¦¬ ì™„ì „ í•´ê²°"""
        try:
            # DIë¥¼ í†µí•œ MemoryManager ì‚¬ìš©
            if hasattr(self, 'memory_manager') and self.memory_manager:
                try:
                    if hasattr(self.memory_manager, 'optimize_memory_async'):
                        result = await self.memory_manager.optimize_memory_async(aggressive=aggressive)
                        if result.get('success', False):
                            self.last_memory_optimization = time.time()
                            return result
                    elif hasattr(self.memory_manager, 'optimize_memory'):
                        # ë™ê¸° ë©”ì„œë“œë¥¼ ë¹„ë™ê¸°ë¡œ ì‹¤í–‰
                        loop = asyncio.get_event_loop()
                        result = await loop.run_in_executor(
                            None, 
                            lambda: self.memory_manager.optimize_memory(aggressive=aggressive)
                        )
                        if result.get('success', False):
                            self.last_memory_optimization = time.time()
                            return result
                except Exception as e:
                    self.logger.debug(f"ë¹„ë™ê¸° DI MemoryManager ì‹¤íŒ¨: {e}")
            
            # ë‚´ì¥ ë©”ëª¨ë¦¬ ìµœì í™” ì‚¬ìš©
            if hasattr(self, 'memory_optimizer') and self.memory_optimizer:
                try:
                    if hasattr(self.memory_optimizer, 'optimize_memory_async'):
                        result = await self.memory_optimizer.optimize_memory_async(aggressive=aggressive)
                        if result.get('success', False):
                            self.last_memory_optimization = time.time()
                        return result
                    else:
                        # ë™ê¸° ë©”ì„œë“œë¥¼ ë¹„ë™ê¸°ë¡œ ì‹¤í–‰
                        loop = asyncio.get_event_loop()
                        result = await loop.run_in_executor(
                            None, 
                            lambda: self.memory_optimizer.optimize_memory(aggressive)
                        )
                        if result.get('success', False):
                            self.last_memory_optimization = time.time()
                        return result
                except Exception as e:
                    self.logger.debug(f"ë¹„ë™ê¸° ë‚´ì¥ ë©”ëª¨ë¦¬ ìµœì í™” ì‹¤íŒ¨: {e}")
            
            # í´ë°±: ë™ê¸° ë©”ì„œë“œë¥¼ ë¹„ë™ê¸°ë¡œ ì‹¤í–‰
            loop = asyncio.get_event_loop()
            result = await loop.run_in_executor(None, lambda: self.optimize_memory(aggressive))
            return result
            
        except Exception as e:
            self.logger.error(f"âŒ ë¹„ë™ê¸° ë©”ëª¨ë¦¬ ìµœì í™” ì‹¤íŒ¨: {e}")
            return {"success": False, "error": str(e)}
    
    def warmup(self) -> Dict[str, Any]:
        """ì›Œë°ì—… ì‹¤í–‰ (ë™ê¸°) - ğŸ”¥ ë¹„ë™ê¸° ì²˜ë¦¬ ì™„ì „ í•´ê²°"""
        try:
            if hasattr(self, 'warmup_system') and self.warmup_system:
                if not getattr(self, 'warmup_completed', False):
                    result = self.warmup_system.run_warmup_sequence()
                    if result.get('success', False):
                        self.warmup_completed = True
                        self.is_ready = True
                        self.warmup_results = result
                    return result
                else:
                    return {
                        'success': True,
                        'message': 'ì´ë¯¸ ì›Œë°ì—… ì™„ë£Œë¨',
                        'cached_results': getattr(self, 'warmup_results', {})
                    }
            
            # ê¸°ë³¸ ì›Œë°ì—…
            return {'success': True, 'message': 'ê¸°ë³¸ ì›Œë°ì—… ì™„ë£Œ'}
            
        except Exception as e:
            self.logger.error(f"âŒ ì›Œë°ì—… ì‹¤íŒ¨: {e}")
            return {"success": False, "error": str(e)}
    
    async def warmup_async(self) -> Dict[str, Any]:
        """ë¹„ë™ê¸° ì›Œë°ì—… - ğŸ”¥ ë¹„ë™ê¸° ì²˜ë¦¬ ì™„ì „ í•´ê²°"""
        try:
            # ëŒ€ê¸° ì¤‘ì¸ ë¹„ë™ê¸° ì„¤ì • ì²˜ë¦¬
            if getattr(self, '_pending_async_setup', False):
                await self._setup_model_interface_async()
            
            if hasattr(self, 'warmup_system') and self.warmup_system:
                if not getattr(self, 'warmup_completed', False):
                    # ë¹„ë™ê¸° ì›Œë°ì—… ì‹œí€€ìŠ¤ ì‹¤í–‰
                    if hasattr(self.warmup_system, 'run_warmup_sequence_async'):
                        result = await self.warmup_system.run_warmup_sequence_async()
                    else:
                        # ë™ê¸° ì›Œë°ì—…ì„ ë¹„ë™ê¸°ë¡œ ì‹¤í–‰
                        loop = asyncio.get_event_loop()
                        result = await loop.run_in_executor(None, self.warmup_system.run_warmup_sequence)
                    
                    if result.get('success', False):
                        self.warmup_completed = True
                        self.is_ready = True
                        self.warmup_results = result
                    return result
                else:
                    return {
                        'success': True,
                        'message': 'ì´ë¯¸ ì›Œë°ì—… ì™„ë£Œë¨',
                        'cached_results': getattr(self, 'warmup_results', {})
                    }
            
            # ê¸°ë³¸ ë¹„ë™ê¸° ì›Œë°ì—…
            return {'success': True, 'message': 'ê¸°ë³¸ ë¹„ë™ê¸° ì›Œë°ì—… ì™„ë£Œ'}
            
        except Exception as e:
            self.logger.error(f"âŒ ë¹„ë™ê¸° ì›Œë°ì—… ì‹¤íŒ¨: {e}")
            return {"success": False, "error": str(e)}
    
    def get_status(self) -> Dict[str, Any]:
        """Step ìƒíƒœ ì¡°íšŒ"""
        try:
            status = {
                'step_name': getattr(self, 'step_name', 'unknown'),
                'step_type': getattr(self, 'step_type', 'unknown'),
                'step_number': getattr(self, 'step_number', 0),
                'is_initialized': getattr(self, 'is_initialized', False),
                'is_ready': getattr(self, 'is_ready', False),
                'has_model': getattr(self, 'has_model', False),
                'model_loaded': getattr(self, 'model_loaded', False),
                'warmup_completed': getattr(self, 'warmup_completed', False),
                'device': getattr(self, 'device', 'cpu'),
                'is_m3_max': getattr(self, 'is_m3_max', False),
                'memory_gb': getattr(self, 'memory_gb', 16.0),
                'di_available': getattr(self, 'di_available', False),
                'error_count': getattr(self, 'error_count', 0),
                'last_error': getattr(self, 'last_error', None),
                'total_processing_count': getattr(self, 'total_processing_count', 0),
                'last_processing_time': getattr(self, 'last_processing_time', None),
                'last_memory_optimization': getattr(self, 'last_memory_optimization', None),
                'large_checkpoint_mode': getattr(self, 'large_checkpoint_mode', False),
                'dependencies': {
                    'model_loader': hasattr(self, 'model_loader') and self.model_loader is not None,
                    'memory_manager': hasattr(self, 'memory_manager') and self.memory_manager is not None,
                    'data_converter': hasattr(self, 'data_converter') and self.data_converter is not None,
                    'step_interface': hasattr(self, 'step_interface') and self.step_interface is not None,
                    'warmup_system': hasattr(self, 'warmup_system') and self.warmup_system is not None,
                    'performance_monitor': hasattr(self, 'performance_monitor') and self.performance_monitor is not None,
                    'checkpoint_manager': hasattr(self, 'checkpoint_manager') and self.checkpoint_manager is not None
                },
                'performance_metrics': getattr(self, 'performance_metrics', {}),
                'state': getattr(self, 'state', {}),
                'checkpoint_info': getattr(self, 'checkpoint_info', {}),
                'config': self.config.to_dict() if hasattr(self, 'config') and self.config else {},
                'di_info': self.get_di_info_for_status(),
                'timestamp': time.time()
            }
            
            return status
            
        except Exception as e:
            self.logger.error(f"âŒ ìƒíƒœ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {
                'step_name': getattr(self, 'step_name', 'unknown'),
                'error': str(e),
                'timestamp': time.time()
            }
    
    def get_performance_summary(self) -> Dict[str, Any]:
        """ì„±ëŠ¥ ìš”ì•½ ì¡°íšŒ"""
        try:
            if hasattr(self, 'performance_monitor') and self.performance_monitor:
                return self.performance_monitor.get_performance_summary()
            
            # ê¸°ë³¸ ì„±ëŠ¥ ì •ë³´
            return {
                'total_processing_count': getattr(self, 'total_processing_count', 0),
                'last_processing_time': getattr(self, 'last_processing_time', None),
                'average_processing_time': self._calculate_average_processing_time(),
                'error_count': getattr(self, 'error_count', 0),
                'success_rate': self._calculate_success_rate()
            }
            
        except Exception as e:
            self.logger.error(f"âŒ ì„±ëŠ¥ ìš”ì•½ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {}
    
    def _calculate_average_processing_time(self) -> float:
        """í‰ê·  ì²˜ë¦¬ ì‹œê°„ ê³„ì‚°"""
        try:
            if hasattr(self, 'processing_history') and self.processing_history:
                times = [p.get('duration', 0) for p in self.processing_history if isinstance(p, dict)]
                return sum(times) / len(times) if times else 0.0
            return 0.0
        except:
            return 0.0
    
    def _calculate_success_rate(self) -> float:
        """ì„±ê³µë¥  ê³„ì‚°"""
        try:
            total = getattr(self, 'total_processing_count', 0)
            errors = getattr(self, 'error_count', 0)
            if total > 0:
                return (total - errors) / total
            return 0.0
        except:
            return 0.0
    
    def cleanup_models(self):
        """ëª¨ë¸ ì •ë¦¬"""
        try:
            # Step ì¸í„°í˜ì´ìŠ¤ ì •ë¦¬
            if hasattr(self, 'step_interface') and self.step_interface:
                cleanup_func = getattr(self.step_interface, 'cleanup', None)
                if callable(cleanup_func):
                    cleanup_func()
                    
            # ModelLoader ì •ë¦¬
            if hasattr(self, 'model_loader') and self.model_loader:
                cleanup_func = getattr(self.model_loader, 'cleanup', None)
                if callable(cleanup_func):
                    cleanup_func()
            
            # ëª¨ë¸ ìºì‹œ ì •ë¦¬
            if hasattr(self, 'model_cache'):
                self.model_cache.clear()
            
            if hasattr(self, 'loaded_models'):
                self.loaded_models.clear()
            
            # PyTorch ë©”ëª¨ë¦¬ ì •ë¦¬
            if TORCH_AVAILABLE:
                if getattr(self, 'device', 'cpu') == "mps" and MPS_AVAILABLE:
                    try:
                        if hasattr(torch.mps, 'empty_cache'):
                            safe_mps_empty_cache()
                        elif hasattr(torch.backends.mps, 'empty_cache'):
                            torch.backends.mps.empty_cache()
                    except AttributeError:
                        pass
                elif getattr(self, 'device', 'cpu') == "cuda":
                    torch.cuda.empty_cache()
                
                gc.collect()
            
            self.logger.info(f"ğŸ§¹ {getattr(self, 'step_name', 'Unknown')} ëª¨ë¸ ì •ë¦¬ ì™„ë£Œ")
                
        except Exception as e:
            self.logger.warning(f"âš ï¸ ëª¨ë¸ ì •ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
    
    def cleanup(self):
        """ì „ì²´ ì •ë¦¬"""
        try:
            # ëª¨ë¸ ì •ë¦¬
            self.cleanup_models()
            
            # ì„±ëŠ¥ ëª¨ë‹ˆí„° ì •ë¦¬
            if hasattr(self, 'performance_monitor'):
                self.performance_monitor = None
            
            # ì›Œë°ì—… ì‹œìŠ¤í…œ ì •ë¦¬
            if hasattr(self, 'warmup_system'):
                self.warmup_system = None
            
            # ë©”ëª¨ë¦¬ ìµœì í™” ì‹œìŠ¤í…œ ì •ë¦¬
            if hasattr(self, 'memory_optimizer'):
                self.memory_optimizer = None
            
            # ìƒíƒœ ë¦¬ì…‹
            self.is_initialized = False
            self.is_ready = False
            
            self.logger.info(f"ğŸ§¹ {getattr(self, 'step_name', 'Unknown')} ì „ì²´ ì •ë¦¬ ì™„ë£Œ")
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ ì „ì²´ ì •ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
    
    def __del__(self):
        """ì†Œë©¸ì - Coroutine ê²½ê³  ë°©ì§€"""
        try:
            # ë™ê¸° ì •ë¦¬ë§Œ ìˆ˜í–‰ (Coroutine ê²½ê³  ë°©ì§€)
            if hasattr(self, '_sync_cleanup'):
                self._sync_cleanup()
        except:
            pass  # ì†Œë©¸ìì—ì„œëŠ” ì˜ˆì™¸ ë¬´ì‹œ

# ==============================================
# ğŸ”¥ 12. Stepë³„ íŠ¹í™” Mixinë“¤ (100% ìœ ì§€ + ë¹„ë™ê¸° ì§€ì› ì¶”ê°€)
# ==============================================

class HumanParsingMixin(BaseStepMixin):
    """Step 1: Human Parsing íŠ¹í™” Mixin"""
    
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.step_number = 1
        self.step_type = "human_parsing"
        self.num_classes = 20
        self.output_format = "segmentation_mask"
        self.parsing_categories = [
            'background', 'hat', 'hair', 'glove', 'sunglasses', 'upperclothes',
            'dress', 'coat', 'socks', 'pants', 'jumpsuits', 'scarf', 'skirt',
            'face', 'left_arm', 'right_arm', 'left_leg', 'right_leg', 'left_shoe', 'right_shoe'
        ]
    
    async def _step_specific_warmup(self) -> None:
        """Human Parsing íŠ¹í™” ì›Œë°ì—…"""
        try:
            self.logger.debug("ğŸ”¥ Human Parsing íŠ¹í™” ì›Œë°ì—… ì‹œì‘")
            
            # íŒŒì‹± ëª¨ë¸ ì›Œë°ì—…
            model = await self.get_model_async("human_parsing")
            if model:
                self.logger.debug("âœ… Human Parsing ëª¨ë¸ ì›Œë°ì—… ì™„ë£Œ")
            else:
                self.logger.debug("âš ï¸ Human Parsing ëª¨ë¸ ì—†ìŒ")
            
            await asyncio.sleep(0.001)  # ìµœì†Œí•œì˜ ë¹„ë™ê¸° ì‘ì—…
            self.logger.debug("âœ… Human Parsing íŠ¹í™” ì›Œë°ì—… ì™„ë£Œ")
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ Human Parsing íŠ¹í™” ì›Œë°ì—… ì‹¤íŒ¨: {e}")

class PoseEstimationMixin(BaseStepMixin):
    """Step 2: Pose Estimation íŠ¹í™” Mixin"""
    
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.step_number = 2
        self.step_type = "pose_estimation"
        self.num_keypoints = 18
        self.output_format = "keypoints"
        self.keypoint_names = [
            'nose', 'neck', 'right_shoulder', 'right_elbow', 'right_wrist',
            'left_shoulder', 'left_elbow', 'left_wrist', 'right_hip', 'right_knee',
            'right_ankle', 'left_hip', 'left_knee', 'left_ankle', 'right_eye',
            'left_eye', 'right_ear', 'left_ear'
        ]
    
    async def _step_specific_warmup(self) -> None:
        """Pose Estimation íŠ¹í™” ì›Œë°ì—…"""
        try:
            self.logger.debug("ğŸ”¥ Pose Estimation íŠ¹í™” ì›Œë°ì—… ì‹œì‘")
            
            # í¬ì¦ˆ ëª¨ë¸ ì›Œë°ì—…
            model = await self.get_model_async("pose_estimation")
            if model:
                self.logger.debug("âœ… Pose Estimation ëª¨ë¸ ì›Œë°ì—… ì™„ë£Œ")
            else:
                self.logger.debug("âš ï¸ Pose Estimation ëª¨ë¸ ì—†ìŒ")
            
            await asyncio.sleep(0.001)  # ìµœì†Œí•œì˜ ë¹„ë™ê¸° ì‘ì—…
            self.logger.debug("âœ… Pose Estimation íŠ¹í™” ì›Œë°ì—… ì™„ë£Œ")
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ Pose Estimation íŠ¹í™” ì›Œë°ì—… ì‹¤íŒ¨: {e}")

class ClothSegmentationMixin(BaseStepMixin):
    """Step 3: Cloth Segmentation íŠ¹í™” Mixin"""
    
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.step_number = 3
        self.step_type = "cloth_segmentation"
        self.output_format = "cloth_mask"
        self.segmentation_methods = ['traditional', 'u2net', 'deeplab', 'auto', 'hybrid']
    
    async def _step_specific_warmup(self) -> None:
        """Cloth Segmentation íŠ¹í™” ì›Œë°ì—…"""
        try:
            self.logger.debug("ğŸ”¥ Cloth Segmentation íŠ¹í™” ì›Œë°ì—… ì‹œì‘")
            
            # ì˜· ë¶„í•  ëª¨ë¸ ì›Œë°ì—…
            model = await self.get_model_async("cloth_segmentation")
            if model:
                self.logger.debug("âœ… Cloth Segmentation ëª¨ë¸ ì›Œë°ì—… ì™„ë£Œ")
            else:
                self.logger.debug("âš ï¸ Cloth Segmentation ëª¨ë¸ ì—†ìŒ")
            
            await asyncio.sleep(0.001)  # ìµœì†Œí•œì˜ ë¹„ë™ê¸° ì‘ì—…
            self.logger.debug("âœ… Cloth Segmentation íŠ¹í™” ì›Œë°ì—… ì™„ë£Œ")
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ Cloth Segmentation íŠ¹í™” ì›Œë°ì—… ì‹¤íŒ¨: {e}")

class GeometricMatchingMixin(BaseStepMixin):
    """Step 4: Geometric Matching íŠ¹í™” Mixin"""
    
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.step_number = 4
        self.step_type = "geometric_matching"
        self.output_format = "transformation_matrix"
        self.matching_methods = ['thin_plate_spline', 'affine', 'perspective', 'flow_based']
    
    async def _step_specific_warmup(self) -> None:
        """Geometric Matching íŠ¹í™” ì›Œë°ì—…"""
        try:
            self.logger.debug("ğŸ”¥ Geometric Matching íŠ¹í™” ì›Œë°ì—… ì‹œì‘")
            
            # ê¸°í•˜í•™ì  ë§¤ì¹­ ëª¨ë¸ ì›Œë°ì—…
            model = await self.get_model_async("geometric_matching")
            if model:
                self.logger.debug("âœ… Geometric Matching ëª¨ë¸ ì›Œë°ì—… ì™„ë£Œ")
            else:
                self.logger.debug("âš ï¸ Geometric Matching ëª¨ë¸ ì—†ìŒ")
            
            await asyncio.sleep(0.001)  # ìµœì†Œí•œì˜ ë¹„ë™ê¸° ì‘ì—…
            self.logger.debug("âœ… Geometric Matching íŠ¹í™” ì›Œë°ì—… ì™„ë£Œ")
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ Geometric Matching íŠ¹í™” ì›Œë°ì—… ì‹¤íŒ¨: {e}")

class ClothWarpingMixin(BaseStepMixin):
    """Step 5: Cloth Warping íŠ¹í™” Mixin"""
    
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.step_number = 5
        self.step_type = "cloth_warping"
        self.output_format = "warped_cloth"
        self.warping_stages = ['preprocessing', 'geometric_transformation', 'texture_mapping', 'postprocessing']
    
    async def _step_specific_warmup(self) -> None:
        """Cloth Warping íŠ¹í™” ì›Œë°ì—…"""
        try:
            self.logger.debug("ğŸ”¥ Cloth Warping íŠ¹í™” ì›Œë°ì—… ì‹œì‘")
            
            # ì˜· ë³€í˜• ëª¨ë¸ ì›Œë°ì—…
            model = await self.get_model_async("cloth_warping")
            if model:
                self.logger.debug("âœ… Cloth Warping ëª¨ë¸ ì›Œë°ì—… ì™„ë£Œ")
            else:
                self.logger.debug("âš ï¸ Cloth Warping ëª¨ë¸ ì—†ìŒ")
            
            await asyncio.sleep(0.001)  # ìµœì†Œí•œì˜ ë¹„ë™ê¸° ì‘ì—…
            self.logger.debug("âœ… Cloth Warping íŠ¹í™” ì›Œë°ì—… ì™„ë£Œ")
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ Cloth Warping íŠ¹í™” ì›Œë°ì—… ì‹¤íŒ¨: {e}")

class VirtualFittingMixin(BaseStepMixin):
    """Step 6: Virtual Fitting íŠ¹í™” Mixin"""
    
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.step_number = 6
        self.step_type = "virtual_fitting"
        self.output_format = "fitted_image"
        self.fitting_modes = ['standard', 'high_quality', 'fast', 'experimental']
    
    async def _step_specific_warmup(self) -> None:
        """Virtual Fitting íŠ¹í™” ì›Œë°ì—…"""
        try:
            self.logger.debug("ğŸ”¥ Virtual Fitting íŠ¹í™” ì›Œë°ì—… ì‹œì‘")
            
            # ê°€ìƒ í”¼íŒ… ëª¨ë¸ ì›Œë°ì—…
            model = await self.get_model_async("virtual_fitting")
            if model:
                self.logger.debug("âœ… Virtual Fitting ëª¨ë¸ ì›Œë°ì—… ì™„ë£Œ")
            else:
                self.logger.debug("âš ï¸ Virtual Fitting ëª¨ë¸ ì—†ìŒ")
            
            await asyncio.sleep(0.001)  # ìµœì†Œí•œì˜ ë¹„ë™ê¸° ì‘ì—…
            self.logger.debug("âœ… Virtual Fitting íŠ¹í™” ì›Œë°ì—… ì™„ë£Œ")
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ Virtual Fitting íŠ¹í™” ì›Œë°ì—… ì‹¤íŒ¨: {e}")

class PostProcessingMixin(BaseStepMixin):
    """Step 7: Post Processing íŠ¹í™” Mixin"""
    
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.step_number = 7
        self.step_type = "post_processing"
        self.output_format = "enhanced_image"
        self.processing_methods = ['super_resolution', 'denoising', 'color_correction', 'sharpening']
    
    async def _step_specific_warmup(self) -> None:
        """Post Processing íŠ¹í™” ì›Œë°ì—…"""
        try:
            self.logger.debug("ğŸ”¥ Post Processing íŠ¹í™” ì›Œë°ì—… ì‹œì‘")
            
            # í›„ì²˜ë¦¬ ëª¨ë¸ ì›Œë°ì—…
            model = await self.get_model_async("post_processing")
            if model:
                self.logger.debug("âœ… Post Processing ëª¨ë¸ ì›Œë°ì—… ì™„ë£Œ")
            else:
                self.logger.debug("âš ï¸ Post Processing ëª¨ë¸ ì—†ìŒ")
            
            await asyncio.sleep(0.001)  # ìµœì†Œí•œì˜ ë¹„ë™ê¸° ì‘ì—…
            self.logger.debug("âœ… Post Processing íŠ¹í™” ì›Œë°ì—… ì™„ë£Œ")
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ Post Processing íŠ¹í™” ì›Œë°ì—… ì‹¤íŒ¨: {e}")

class QualityAssessmentMixin(BaseStepMixin):
    """Step 8: Quality Assessment íŠ¹í™” Mixin"""
    
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.step_number = 8
        self.step_type = "quality_assessment"
        self.output_format = "quality_score"
        self.assessment_criteria = ['perceptual_quality', 'technical_quality', 'aesthetic_quality', 'overall_quality']
    
    async def _step_specific_warmup(self) -> None:
        """Quality Assessment íŠ¹í™” ì›Œë°ì—…"""
        try:
            self.logger.debug("ğŸ”¥ Quality Assessment íŠ¹í™” ì›Œë°ì—… ì‹œì‘")
            
            # í’ˆì§ˆ í‰ê°€ ëª¨ë¸ ì›Œë°ì—…
            model = await self.get_model_async("quality_assessment")
            if model:
                self.logger.debug("âœ… Quality Assessment ëª¨ë¸ ì›Œë°ì—… ì™„ë£Œ")
            else:
                self.logger.debug("âš ï¸ Quality Assessment ëª¨ë¸ ì—†ìŒ")
            
            await asyncio.sleep(0.001)  # ìµœì†Œí•œì˜ ë¹„ë™ê¸° ì‘ì—…
            self.logger.debug("âœ… Quality Assessment íŠ¹í™” ì›Œë°ì—… ì™„ë£Œ")
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ Quality Assessment íŠ¹í™” ì›Œë°ì—… ì‹¤íŒ¨: {e}")

# ==============================================
# ğŸ”¥ 13. ì•ˆì „í•œ ë°ì½”ë ˆì´í„°ë“¤ (ë¹„ë™ê¸° ì²˜ë¦¬ ì™„ì „ í•´ê²°)
# ==============================================

def safe_step_method(func: Callable) -> Callable:
    """Step ë©”ì„œë“œ ì•ˆì „ ì‹¤í–‰ ë°ì½”ë ˆì´í„°"""
    @wraps(func)  # âœ… ì´ì œ ì •ìƒ ì‘ë™
    def wrapper(self, *args, **kwargs):
        try:
            # logger ì†ì„± í™•ì¸ ë° ë³´ì¥
            if not hasattr(self, 'logger') or self.logger is None:
                self._ensure_logger_first()
            
            # ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
            start_time = time.time()
            
            result = func(self, *args, **kwargs)
            
            # ì„±ëŠ¥ ê¸°ë¡
            duration = time.time() - start_time
            if hasattr(self, 'performance_monitor') and self.performance_monitor:
                self.performance_monitor.record_operation(func.__name__, duration, True)
            
            return result
            
        except Exception as e:
            # ì—ëŸ¬ ê¸°ë¡
            duration = time.time() - start_time if 'start_time' in locals() else 0
            if hasattr(self, 'performance_monitor') and self.performance_monitor:
                self.performance_monitor.record_operation(func.__name__, duration, False)
            
            # ì—ëŸ¬ ì¹´ìš´íŠ¸ ì¦ê°€
            if hasattr(self, 'error_count'):
                self.error_count += 1
            
            # ë§ˆì§€ë§‰ ì—ëŸ¬ ì €ì¥
            if hasattr(self, 'last_error'):
                self.last_error = str(e)
            
            # ë¡œê¹…
            if hasattr(self, 'logger'):
                self.logger.error(f"âŒ {func.__name__} ì‹¤í–‰ ì‹¤íŒ¨: {e}")
                self.logger.debug(f"ğŸ“‹ ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
            
            return {
                'success': False,
                'error': str(e),
                'error_type': type(e).__name__,
                'step_name': getattr(self, 'step_name', self.__class__.__name__),
                'method_name': func.__name__,
                'duration': duration,
                'timestamp': time.time()
            }
    
    return wrapper

def async_safe_step_method(func: Callable) -> Callable:
    """ì•ˆì „í•œ ë¹„ë™ê¸° Step ë©”ì„œë“œ ì‹¤í–‰ ë°ì½”ë ˆì´í„° - ğŸ”¥ ë¹„ë™ê¸° ì²˜ë¦¬ ì™„ì „ í•´ê²°"""
    @wraps(func)  # âœ… ì´ì œ ì •ìƒ ì‘ë™
    async def wrapper(self, *args, **kwargs):
        try:
            # logger ì†ì„± í™•ì¸ ë° ë³´ì¥
            if not hasattr(self, 'logger') or self.logger is None:
                self._ensure_logger_first()
            
            # ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
            start_time = time.time()
            
            # ğŸ”¥ funcê°€ ë¹„ë™ê¸° í•¨ìˆ˜ì¸ì§€ í™•ì¸í•˜ê³  ì ì ˆíˆ í˜¸ì¶œ
            if asyncio.iscoroutinefunction(func):
                result = await func(self, *args, **kwargs)
            else:
                # ë™ê¸° í•¨ìˆ˜ì¸ ê²½ìš° executorë¡œ ì‹¤í–‰
                loop = asyncio.get_event_loop()
                result = await loop.run_in_executor(None, lambda: func(self, *args, **kwargs))
            
            # ì„±ëŠ¥ ê¸°ë¡
            duration = time.time() - start_time
            if hasattr(self, 'performance_monitor') and self.performance_monitor:
                self.performance_monitor.record_operation(f"{func.__name__}_async", duration, True)
            
            return result
            
        except Exception as e:
            # ì—ëŸ¬ ê¸°ë¡
            duration = time.time() - start_time if 'start_time' in locals() else 0
            if hasattr(self, 'performance_monitor') and self.performance_monitor:
                self.performance_monitor.record_operation(f"{func.__name__}_async", duration, False)
            
            # ì—ëŸ¬ ì¹´ìš´íŠ¸ ì¦ê°€
            if hasattr(self, 'error_count'):
                self.error_count += 1
            
            # ë§ˆì§€ë§‰ ì—ëŸ¬ ì €ì¥
            if hasattr(self, 'last_error'):
                self.last_error = str(e)
            
            # ë¡œê¹…
            if hasattr(self, 'logger'):
                self.logger.error(f"âŒ {func.__name__} ë¹„ë™ê¸° ì‹¤í–‰ ì‹¤íŒ¨: {e}")
                self.logger.debug(f"ğŸ“‹ ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
            
            return {
                'success': False,
                'error': str(e),
                'error_type': type(e).__name__,
                'step_name': getattr(self, 'step_name', self.__class__.__name__),
                'method_name': func.__name__,
                'async': True,
                'duration': duration,
                'timestamp': time.time()
            }
    
    return wrapper

def performance_monitor(operation_name: str) -> Callable:
    """ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ë°ì½”ë ˆì´í„°"""
    def decorator(func: Callable) -> Callable:
        @wraps(func)  # âœ… ì´ì œ ì •ìƒ ì‘ë™
        def wrapper(self, *args, **kwargs):
            start_time = time.time()
            success = True
            try:
                result = func(self, *args, **kwargs)
                return result
            except Exception as e:
                success = False
                raise e
            finally:
                duration = time.time() - start_time
                
                # ì„±ëŠ¥ ëª¨ë‹ˆí„°ì— ê¸°ë¡
                if hasattr(self, 'performance_monitor') and self.performance_monitor:
                    self.performance_monitor.record_operation(operation_name, duration, success)
                
                # ê¸°ë³¸ ì„±ëŠ¥ ë©”íŠ¸ë¦­ì—ë„ ê¸°ë¡
                if hasattr(self, 'performance_metrics'):
                    if 'operations' not in self.performance_metrics:
                        self.performance_metrics['operations'] = {}
                    
                    if operation_name not in self.performance_metrics['operations']:
                        self.performance_metrics['operations'][operation_name] = {
                            'count': 0,
                            'total_time': 0.0,
                            'success_count': 0,
                            'failure_count': 0,
                            'avg_time': 0.0
                        }
                    
                    op_metrics = self.performance_metrics['operations'][operation_name]
                    op_metrics['count'] += 1
                    op_metrics['total_time'] += duration
                    op_metrics['avg_time'] = op_metrics['total_time'] / op_metrics['count']
                    
                    if success:
                        op_metrics['success_count'] += 1
                    else:
                        op_metrics['failure_count'] += 1
                        
        return wrapper
    return decorator

def async_performance_monitor(operation_name: str) -> Callable:
    """ë¹„ë™ê¸° ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ë°ì½”ë ˆì´í„° - ğŸ”¥ ìƒˆë¡œ ì¶”ê°€"""
    def decorator(func: Callable) -> Callable:
        @wraps(func)
        async def wrapper(self, *args, **kwargs):
            start_time = time.time()
            success = True
            try:
                # ğŸ”¥ funcê°€ ë¹„ë™ê¸° í•¨ìˆ˜ì¸ì§€ í™•ì¸í•˜ê³  ì ì ˆíˆ í˜¸ì¶œ
                if asyncio.iscoroutinefunction(func):
                    result = await func(self, *args, **kwargs)
                else:
                    # ë™ê¸° í•¨ìˆ˜ì¸ ê²½ìš° executorë¡œ ì‹¤í–‰
                    loop = asyncio.get_event_loop()
                    result = await loop.run_in_executor(None, lambda: func(self, *args, **kwargs))
                return result
            except Exception as e:
                success = False
                raise e
            finally:
                duration = time.time() - start_time
                
                # ì„±ëŠ¥ ëª¨ë‹ˆí„°ì— ê¸°ë¡
                if hasattr(self, 'performance_monitor') and self.performance_monitor:
                    self.performance_monitor.record_operation(f"{operation_name}_async", duration, success)
                
                # ê¸°ë³¸ ì„±ëŠ¥ ë©”íŠ¸ë¦­ì—ë„ ê¸°ë¡
                if hasattr(self, 'performance_metrics'):
                    if 'operations' not in self.performance_metrics:
                        self.performance_metrics['operations'] = {}
                    
                    async_op_name = f"{operation_name}_async"
                    if async_op_name not in self.performance_metrics['operations']:
                        self.performance_metrics['operations'][async_op_name] = {
                            'count': 0,
                            'total_time': 0.0,
                            'success_count': 0,
                            'failure_count': 0,
                            'avg_time': 0.0
                        }
                    
                    op_metrics = self.performance_metrics['operations'][async_op_name]
                    op_metrics['count'] += 1
                    op_metrics['total_time'] += duration
                    op_metrics['avg_time'] = op_metrics['total_time'] / op_metrics['count']
                    
                    if success:
                        op_metrics['success_count'] += 1
                    else:
                        op_metrics['failure_count'] += 1
                        
        return wrapper
    return decorator

def memory_optimize_after(func: Callable) -> Callable:
    """ë©”ì„œë“œ ì‹¤í–‰ í›„ ìë™ ë©”ëª¨ë¦¬ ìµœì í™”"""
    @wraps(func)
    def wrapper(self, *args, **kwargs):
        try:
            result = func(self, *args, **kwargs)
            
            # ìë™ ë©”ëª¨ë¦¬ ì •ë¦¬ (ì„¤ì •ëœ ê²½ìš°)
            if getattr(self, 'auto_memory_cleanup', False):
                try:
                    self.optimize_memory()
                except Exception as e:
                    if hasattr(self, 'logger'):
                        self.logger.debug(f"ìë™ ë©”ëª¨ë¦¬ ì •ë¦¬ ì‹¤íŒ¨: {e}")
            
            return result
            
        except Exception as e:
            # ì—ëŸ¬ ë°œìƒì‹œì—ë„ ë©”ëª¨ë¦¬ ì •ë¦¬
            if getattr(self, 'auto_memory_cleanup', False):
                try:
                    self.optimize_memory(aggressive=True)
                except:
                    pass
            raise e
    
    return wrapper

def async_memory_optimize_after(func: Callable) -> Callable:
    """ë¹„ë™ê¸° ë©”ì„œë“œ ì‹¤í–‰ í›„ ìë™ ë©”ëª¨ë¦¬ ìµœì í™” - ğŸ”¥ ìƒˆë¡œ ì¶”ê°€"""
    @wraps(func)
    async def wrapper(self, *args, **kwargs):
        try:
            # ğŸ”¥ funcê°€ ë¹„ë™ê¸° í•¨ìˆ˜ì¸ì§€ í™•ì¸í•˜ê³  ì ì ˆíˆ í˜¸ì¶œ
            if asyncio.iscoroutinefunction(func):
                result = await func(self, *args, **kwargs)
            else:
                # ë™ê¸° í•¨ìˆ˜ì¸ ê²½ìš° executorë¡œ ì‹¤í–‰
                loop = asyncio.get_event_loop()
                result = await loop.run_in_executor(None, lambda: func(self, *args, **kwargs))
            
            # ìë™ ë©”ëª¨ë¦¬ ì •ë¦¬ (ì„¤ì •ëœ ê²½ìš°)
            if getattr(self, 'auto_memory_cleanup', False):
                try:
                    await self.optimize_memory_async()
                except Exception as e:
                    if hasattr(self, 'logger'):
                        self.logger.debug(f"ìë™ ë¹„ë™ê¸° ë©”ëª¨ë¦¬ ì •ë¦¬ ì‹¤íŒ¨: {e}")
            
            return result
            
        except Exception as e:
            # ì—ëŸ¬ ë°œìƒì‹œì—ë„ ë©”ëª¨ë¦¬ ì •ë¦¬
            if getattr(self, 'auto_memory_cleanup', False):
                try:
                    await self.optimize_memory_async(aggressive=True)
                except:
                    pass
            raise e
    
    return wrapper

# ==============================================
# ğŸ”¥ 14. ë¹„ë™ê¸° ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤ (ìƒˆë¡œ ì¶”ê°€)
# ==============================================

async def ensure_coroutine(func_or_coro, *args, **kwargs) -> Any:
    """í•¨ìˆ˜ë‚˜ ì½”ë£¨í‹´ì„ ì•ˆì „í•˜ê²Œ ì‹¤í–‰í•˜ëŠ” ìœ í‹¸ë¦¬í‹°"""
    try:
        if asyncio.iscoroutinefunction(func_or_coro):
            return await func_or_coro(*args, **kwargs)
        elif callable(func_or_coro):
            loop = asyncio.get_event_loop()
            return await loop.run_in_executor(None, lambda: func_or_coro(*args, **kwargs))
        elif asyncio.iscoroutine(func_or_coro):
            return await func_or_coro
        else:
            return func_or_coro
    except Exception as e:
        logging.error(f"âŒ ensure_coroutine ì‹¤í–‰ ì‹¤íŒ¨: {e}")
        return None

def is_coroutine_function_safe(func) -> bool:
    """ì•ˆì „í•œ ì½”ë£¨í‹´ í•¨ìˆ˜ ê²€ì‚¬"""
    try:
        return asyncio.iscoroutinefunction(func)
    except:
        return False

def is_coroutine_safe(obj) -> bool:
    """ì•ˆì „í•œ ì½”ë£¨í‹´ ê°ì²´ ê²€ì‚¬"""
    try:
        return asyncio.iscoroutine(obj)
    except:
        return False

async def run_with_timeout(coro_or_func, timeout: float = 30.0, *args, **kwargs) -> Any:
    """íƒ€ì„ì•„ì›ƒì„ ì ìš©í•œ ì•ˆì „í•œ ì‹¤í–‰"""
    try:
        if asyncio.iscoroutinefunction(coro_or_func):
            return await asyncio.wait_for(coro_or_func(*args, **kwargs), timeout=timeout)
        elif callable(coro_or_func):
            loop = asyncio.get_event_loop()
            return await asyncio.wait_for(
                loop.run_in_executor(None, lambda: coro_or_func(*args, **kwargs)), 
                timeout=timeout
            )
        elif asyncio.iscoroutine(coro_or_func):
            return await asyncio.wait_for(coro_or_func, timeout=timeout)
        else:
            return coro_or_func
    except asyncio.TimeoutError:
        logging.warning(f"âš ï¸ ì‹¤í–‰ íƒ€ì„ì•„ì›ƒ ({timeout}ì´ˆ): {coro_or_func}")
        return None
    except Exception as e:
        logging.error(f"âŒ run_with_timeout ì‹¤í–‰ ì‹¤íŒ¨: {e}")
        return None

# ==============================================
# ğŸ”¥ 15. ëª¨ë“ˆ ë‚´ë³´ë‚´ê¸°
# ==============================================

__all__ = [
    # ë©”ì¸ í´ë˜ìŠ¤ë“¤
    'BaseStepMixin',
    'SafeConfig',
    'CheckpointManager',
    'CheckpointInfo',
    'WarmupSystem',
    'PerformanceMonitor',
    'StepMemoryOptimizer',
    'DIHelper',
    
    # Stepë³„ íŠ¹í™” Mixinë“¤
    'HumanParsingMixin',
    'PoseEstimationMixin', 
    'ClothSegmentationMixin',
    'GeometricMatchingMixin',
    'ClothWarpingMixin',
    'VirtualFittingMixin',
    'PostProcessingMixin',
    'QualityAssessmentMixin',
    
    # ë°ì½”ë ˆì´í„°ë“¤ (ë™ê¸°/ë¹„ë™ê¸°)
    'safe_step_method',
    'async_safe_step_method',
    'performance_monitor',
    'async_performance_monitor',
    'memory_optimize_after',
    'async_memory_optimize_after',
    
    # ë¹„ë™ê¸° ìœ í‹¸ë¦¬í‹°ë“¤
    'ensure_coroutine',
    'is_coroutine_function_safe',
    'is_coroutine_safe',
    'run_with_timeout',
    'safe_async_wrapper',
    
    # ìƒìˆ˜ë“¤
    'TORCH_AVAILABLE',
    'MPS_AVAILABLE',
    'NUMPY_AVAILABLE',
    'PIL_AVAILABLE'
]

# ==============================================
# ğŸ”¥ 16. ëª¨ë“ˆ ë¡œë“œ ì™„ë£Œ ë©”ì‹œì§€
# ==============================================

print("âœ… BaseStepMixin v10.1 ì™„ì „í•œ í†µí•© ë²„ì „ ë¡œë“œ ì™„ë£Œ")
print("ğŸ”¥ ë¹„ë™ê¸° ì²˜ë¦¬ ì™„ì „ í•´ê²° (coroutine ê²½ê³  ì™„ì „ ì œê±°)")
print("ğŸ”¥ from functools import wraps ì¶”ê°€ - NameError ì™„ì „ í•´ê²°")
print("ğŸš¨ _emergency_initialization ë©”ì„œë“œ ì™„ì „ êµ¬í˜„")
print("ğŸš€ ì˜ì¡´ì„± ì£¼ì… íŒ¨í„´ ì™„ì „ ì ìš©")
print("âš¡ ìˆœí™˜ì°¸ì¡° ì™„ì „ ì œê±° (TYPE_CHECKING)")
print("ğŸ”§ logger ì†ì„± ëˆ„ë½ ë¬¸ì œ ê·¼ë³¸ í•´ê²°")
print("ğŸ“¦ 89.8GB ì²´í¬í¬ì¸íŠ¸ ìë™ íƒì§€ ë° í™œìš©")
print("ğŸ”— ModelLoader ì—°ë™ ì™„ì „ ìë™í™”")
print("ğŸ›¡ï¸ SafeFunctionValidator í†µí•©")
print("ğŸ M3 Max 128GB ìµœì í™”")
print("ğŸ“Š ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ")
print("ğŸ§¹ ë©”ëª¨ë¦¬ ìµœì í™” ì‹œìŠ¤í…œ")
print("ğŸ”¥ ì›Œë°ì—… ì‹œìŠ¤í…œ (ë™ê¸°/ë¹„ë™ê¸° ì™„ì „ ì§€ì›)")
print("ğŸ”„ ì—ëŸ¬ ë³µêµ¬ ì‹œìŠ¤í…œ")
print("ğŸ“ ì²´í¬í¬ì¸íŠ¸ ê´€ë¦¬ ì‹œìŠ¤í…œ")
print("âš¡ ë¹„ë™ê¸° ì²˜ë¦¬ ì™„ì „ ì§€ì› (coroutine ê²½ê³  í•´ê²°)")
print("ğŸ¯ í”„ë¡œë•ì…˜ ë ˆë²¨ ì•ˆì •ì„± ìµœê³  ìˆ˜ì¤€")
print("ğŸ”— DI Container v2.0 ì™„ë²½ í˜¸í™˜")
print("ğŸ”§ ëª¨ë“  ëˆ„ë½ ë©”ì„œë“œ êµ¬í˜„ ì™„ë£Œ")
print("ğŸŒŸ warmup_step() ë¹„ë™ê¸° ë©”ì„œë“œ ê¸°ë³¸ êµ¬í˜„ ì¶”ê°€")
print("ğŸŒŸ _step_specific_warmup() ë¹„ë™ê¸° ë©”ì„œë“œ ê¸°ë³¸ êµ¬í˜„ ì¶”ê°€")
print("ğŸŒŸ async/await ì™„ì „ ì§€ì›ìœ¼ë¡œ coroutine ê²½ê³  ì™„ì „ í•´ê²°")
print(f"ğŸ”§ ì‹œìŠ¤í…œ ìƒíƒœ:")
print(f"   - PyTorch: {'âœ…' if TORCH_AVAILABLE else 'âŒ'}")
print(f"   - MPS: {'âœ…' if MPS_AVAILABLE else 'âŒ'}")
print(f"   - NumPy: {'âœ…' if NUMPY_AVAILABLE else 'âŒ'}")
print(f"   - PIL: {'âœ…' if PIL_AVAILABLE else 'âŒ'}")
print("ğŸš€ BaseStepMixin v10.1 ì™„ì „ ì¤€ë¹„ ì™„ë£Œ - ëª¨ë“  ê¸°ëŠ¥ í†µí•©!")
print("ğŸŒŸ ì£¼ìš” í†µí•© ê°œì„ ì‚¬í•­:")
print("   âœ… ê¸°ì¡´ 1ë²ˆ íŒŒì¼ì˜ ëª¨ë“  ê¸°ëŠ¥ 100% ìœ ì§€")
print("   âœ… 2ë²ˆ íŒŒì¼ì˜ ì‹ ê·œ ê¸°ëŠ¥ 100% í†µí•©")
print("   âœ… ëª¨ë“  í•¨ìˆ˜/í´ë˜ìŠ¤ëª… ì™„ì „ ìœ ì§€")
print("   âœ… warmup_step() ë¹„ë™ê¸° ë©”ì„œë“œ ì™„ì „ êµ¬í˜„")
print("   âœ… _pipeline_warmup() coroutine ê²½ê³  ì™„ì „ í•´ê²°")
print("   âœ… _setup_model_interface_async() ì¶”ê°€")
print("   âœ… ëª¨ë“  Stepë³„ Mixinì— ë¹„ë™ê¸° ì›Œë°ì—… ì¶”ê°€")
print("   âœ… ë¹„ë™ê¸° ë°ì½”ë ˆì´í„° ì¶”ê°€ (async_safe_step_method)")
print("   âœ… ë¹„ë™ê¸° ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤ ì¶”ê°€")
print("   âœ… ensure_coroutine() ì•ˆì „í•œ ë¹„ë™ê¸° ì‹¤í–‰")
print("   âœ… run_with_timeout() íƒ€ì„ì•„ì›ƒ ì ìš© ì‹¤í–‰")
print("   âœ… conda í™˜ê²½ ìš°ì„  ì§€ì›")
print("   âœ… M3 Max 128GB ìµœëŒ€ í™œìš©")
print("   âœ… Clean Architecture ì ìš©")
print("   âœ… ì™„ì „í•œ í†µí•© ë²„ì „ - 1ë²ˆ + 2ë²ˆ ëª¨ë“  ê¸°ëŠ¥!")