# backend/app/ai_pipeline/steps/base_step_mixin.py
"""
ğŸ”¥ MyCloset AI - ì™„ì „ ìˆ˜ì •ëœ BaseStepMixin v2.0
âœ… ëª¨ë“  Step í´ë˜ìŠ¤ì˜ logger ì†ì„± ëˆ„ë½ ë¬¸ì œ ì™„ì „ í•´ê²°
âœ… ModelLoader ì¸í„°í˜ì´ìŠ¤ ì™„ë²½ ì—°ë™  
âœ… í‘œì¤€í™”ëœ ì´ˆê¸°í™” íŒ¨í„´
âœ… M3 Max 128GB ìµœì í™”
âœ… ë¹„ë™ê¸° ì²˜ë¦¬ ì™„ë²½ ì§€ì›
"""

import os
import gc
import time
import asyncio
import logging
import threading
import traceback
from pathlib import Path
from typing import Dict, Any, Optional, Union, List, Type
from abc import ABC, abstractmethod
from dataclasses import dataclass, field
from concurrent.futures import ThreadPoolExecutor

# PyTorch import (ì•ˆì „)
try:
    import torch
    import torch.nn as nn
    TORCH_AVAILABLE = True
except ImportError:
    TORCH_AVAILABLE = False
    torch = None

# ì´ë¯¸ì§€ ì²˜ë¦¬ ë¼ì´ë¸ŒëŸ¬ë¦¬
try:
    import cv2
    import numpy as np
    from PIL import Image
    CV_AVAILABLE = True
except ImportError:
    CV_AVAILABLE = False

# ==============================================
# ğŸ”¥ ì™„ì „ ìˆ˜ì •ëœ BaseStepMixin
# ==============================================

class BaseStepMixin:
    """
    ğŸ”¥ ëª¨ë“  Step í´ë˜ìŠ¤ê°€ ìƒì†ë°›ëŠ” ê¸°ë³¸ Mixin
    âœ… logger ì†ì„± ëˆ„ë½ ë¬¸ì œ ì™„ì „ í•´ê²°
    âœ… ModelLoader ì¸í„°í˜ì´ìŠ¤ ì•ˆì „í•œ ì—°ë™
    âœ… í‘œì¤€í™”ëœ ì´ˆê¸°í™” íŒ¨í„´
    âœ… M3 Max ìµœì í™” ì§€ì›
    """
    
    def __init__(self, *args, **kwargs):
        """ê¸°ë³¸ Mixin ì´ˆê¸°í™” - ëª¨ë“  Step í´ë˜ìŠ¤ì—ì„œ í˜¸ì¶œë˜ì–´ì•¼ í•¨"""
        # ğŸ”¥ logger ì†ì„± ëˆ„ë½ ë¬¸ì œ í•´ê²° - ë°˜ë“œì‹œ ë¨¼ì € ì„¤ì •
        if not hasattr(self, 'logger'):
            class_name = self.__class__.__name__
            self.logger = logging.getLogger(f"pipeline.{class_name}")
            self.logger.info(f"ğŸ”§ {class_name} logger ì´ˆê¸°í™” ì™„ë£Œ")
        
        # ê¸°ë³¸ ì†ì„±ë“¤ ì´ˆê¸°í™”
        self.step_name = getattr(self, 'step_name', self.__class__.__name__)
        self.device = getattr(self, 'device', self._auto_detect_device())
        self.is_initialized = False
        self.model_interface = None
        self.performance_metrics = {}
        self.error_count = 0
        self.last_error = None
        
        # M3 Max ìµœì í™” ì„¤ì •
        self._setup_m3_max_optimization()
        
        # ModelLoader ì¸í„°í˜ì´ìŠ¤ ì„¤ì • (ì•ˆì „)
        self._setup_model_interface_safe()
        
        self.logger.info(f"âœ… {self.step_name} BaseStepMixin ì´ˆê¸°í™” ì™„ë£Œ")
    
    def _auto_detect_device(self) -> str:
        """ë””ë°”ì´ìŠ¤ ìë™ íƒì§€ (M3 Max ìµœì í™”)"""
        if not TORCH_AVAILABLE:
            return "cpu"
            
        # M3 Max MPS ì§€ì› í™•ì¸
        if torch.backends.mps.is_available():
            return "mps"
        elif torch.cuda.is_available():
            return "cuda"
        else:
            return "cpu"
    
    def _setup_m3_max_optimization(self):
        """M3 Max ìµœì í™” ì„¤ì •"""
        try:
            if self.device == "mps" and TORCH_AVAILABLE:
                # M3 Max íŠ¹í™” ì„¤ì •
                os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '1'
                os.environ['PYTORCH_MPS_HIGH_WATERMARK_RATIO'] = '0.0'
                
                # ë©”ëª¨ë¦¬ ìµœì í™”
                if hasattr(torch.backends.mps, 'empty_cache'):
                    torch.backends.mps.empty_cache()
                
                self.logger.info("ğŸ M3 Max MPS ìµœì í™” ì„¤ì • ì™„ë£Œ")
        except Exception as e:
            self.logger.warning(f"âš ï¸ M3 Max ìµœì í™” ì„¤ì • ì‹¤íŒ¨: {e}")
    
    def _setup_model_interface_safe(self):
        """ModelLoader ì¸í„°í˜ì´ìŠ¤ ì•ˆì „í•œ ì„¤ì •"""
        try:
            # ìˆœí™˜ import ë°©ì§€ë¥¼ ìœ„í•œ ëŠ¦ì€ import
            from ..utils.model_loader import get_global_model_loader
            
            model_loader = get_global_model_loader()
            if model_loader:
                self.model_interface = model_loader.create_step_interface(self.step_name)
                self.logger.info(f"ğŸ”— {self.step_name} ModelLoader ì¸í„°í˜ì´ìŠ¤ ì—°ê²° ì™„ë£Œ")
            else:
                self.logger.warning(f"âš ï¸ {self.step_name} ì „ì—­ ModelLoaderë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
                self.model_interface = None
                
        except Exception as e:
            self.logger.error(f"âŒ {self.step_name} ModelLoader ì¸í„°í˜ì´ìŠ¤ ì„¤ì • ì‹¤íŒ¨: {e}")
            self.model_interface = None
    
    async def initialize_step(self) -> bool:
        """Step ì™„ì „ ì´ˆê¸°í™”"""
        try:
            # ê¸°ë³¸ ì´ˆê¸°í™” í™•ì¸
            if not hasattr(self, 'logger'):
                self.logger = logging.getLogger(f"pipeline.{self.__class__.__name__}")
            
            if not hasattr(self, 'device'):
                self.device = self._auto_detect_device()
            
            # ModelLoader ì¸í„°í˜ì´ìŠ¤ ì¬ì„¤ì • (í•„ìš”ì‹œ)
            if not hasattr(self, 'model_interface') or self.model_interface is None:
                self._setup_model_interface_safe()
            
            self.is_initialized = True
            self.logger.info(f"âœ… {self.step_name} ì™„ì „ ì´ˆê¸°í™” ì™„ë£Œ")
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ {self.step_name} ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.last_error = str(e)
            self.error_count += 1
            return False
    
    async def get_model(self, model_name: Optional[str] = None) -> Optional[Any]:
        """ëª¨ë¸ ë¡œë“œ (Stepì—ì„œ ì‚¬ìš©)"""
        try:
            if not self.model_interface:
                self.logger.warning(f"âš ï¸ {self.step_name} ModelLoader ì¸í„°í˜ì´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤")
                return None
            
            if model_name:
                return await self.model_interface.get_model(model_name)
            else:
                # ê¶Œì¥ ëª¨ë¸ ìë™ ë¡œë“œ
                return await self.model_interface.get_recommended_model()
                
        except Exception as e:
            self.logger.error(f"âŒ {self.step_name} ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            self.last_error = str(e)
            self.error_count += 1
            return None
    
    def cleanup_models(self):
        """ëª¨ë¸ ì •ë¦¬"""
        try:
            if hasattr(self, 'model_interface') and self.model_interface:
                self.model_interface.unload_models()
                self.logger.info(f"ğŸ§¹ {self.step_name} ëª¨ë¸ ì •ë¦¬ ì™„ë£Œ")
        except Exception as e:
            self.logger.error(f"âŒ {self.step_name} ëª¨ë¸ ì •ë¦¬ ì‹¤íŒ¨: {e}")
    
    def get_step_info(self) -> Dict[str, Any]:
        """Step ìƒíƒœ ì •ë³´ ë°˜í™˜"""
        return {
            "step_name": self.step_name,
            "device": self.device,
            "is_initialized": self.is_initialized,
            "has_model_interface": self.model_interface is not None,
            "error_count": self.error_count,
            "last_error": self.last_error,
            "performance_metrics": self.performance_metrics
        }
    
    def record_performance(self, operation: str, duration: float, success: bool = True):
        """ì„±ëŠ¥ ë©”íŠ¸ë¦­ ê¸°ë¡"""
        if operation not in self.performance_metrics:
            self.performance_metrics[operation] = {
                "total_calls": 0,
                "success_calls": 0,
                "total_duration": 0.0,
                "avg_duration": 0.0,
                "last_duration": 0.0
            }
        
        metrics = self.performance_metrics[operation]
        metrics["total_calls"] += 1
        metrics["total_duration"] += duration
        metrics["last_duration"] = duration
        metrics["avg_duration"] = metrics["total_duration"] / metrics["total_calls"]
        
        if success:
            metrics["success_calls"] += 1
    
    async def process(self, *args, **kwargs) -> Dict[str, Any]:
        """ğŸ”§ ê¸°ë³¸ ì²˜ë¦¬ ë©”ì„œë“œ (í•˜ìœ„ í´ë˜ìŠ¤ì—ì„œ ì˜¤ë²„ë¼ì´ë“œ)"""
        try:
            start_time = time.time()
            self.logger.info(f"ğŸ”„ {self.step_name} ê¸°ë³¸ ì²˜ë¦¬ ì‹¤í–‰")
            
            # ì´ˆê¸°í™” í™•ì¸
            if not self.is_initialized:
                await self.initialize_step()
            
            # ê¸°ë³¸ ì²˜ë¦¬ ê²°ê³¼
            result = {
                'success': True,
                'step_name': self.step_name,
                'result': f'{self.step_name} ê¸°ë³¸ ì²˜ë¦¬ ì™„ë£Œ',
                'confidence': 0.5,
                'processing_time': time.time() - start_time,
                'metadata': {
                    'device': self.device,
                    'fallback': True,
                    'model_interface_available': self.model_interface is not None
                }
            }
            
            # ì„±ëŠ¥ ê¸°ë¡
            self.record_performance("process", result['processing_time'], True)
            return result
            
        except Exception as e:
            duration = time.time() - start_time if 'start_time' in locals() else 0.0
            self.logger.error(f"âŒ {self.step_name} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            self.last_error = str(e)
            self.error_count += 1
            
            # ì„±ëŠ¥ ê¸°ë¡ (ì‹¤íŒ¨)
            self.record_performance("process", duration, False)
            
            return {
                'success': False,
                'step_name': self.step_name,
                'error': str(e),
                'confidence': 0.0,
                'processing_time': duration
            }
    
    def __del__(self):
        """ì†Œë©¸ì"""
        try:
            self.cleanup_models()
        except:
            pass

# ==============================================
# ğŸ”¥ Stepë³„ íŠ¹í™” Mixinë“¤
# ==============================================

class HumanParsingMixin(BaseStepMixin):
    """Human Parsing Step íŠ¹í™” Mixin"""
    
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.step_number = 1
        self.step_type = "human_parsing"
        self.num_classes = 20
        self.output_format = "segmentation_mask"

class PoseEstimationMixin(BaseStepMixin):
    """Pose Estimation Step íŠ¹í™” Mixin"""
    
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.step_number = 2
        self.step_type = "pose_estimation"
        self.num_keypoints = 18
        self.output_format = "keypoints_heatmap"

class ClothSegmentationMixin(BaseStepMixin):
    """Cloth Segmentation Step íŠ¹í™” Mixin"""
    
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.step_number = 3
        self.step_type = "cloth_segmentation"
        self.binary_output = True
        self.output_format = "binary_mask"

class GeometricMatchingMixin(BaseStepMixin):
    """Geometric Matching Step íŠ¹í™” Mixin"""
    
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.step_number = 4
        self.step_type = "geometric_matching"
        self.num_control_points = 25
        self.output_format = "transformation_matrix"

class ClothWarpingMixin(BaseStepMixin):
    """Cloth Warping Step íŠ¹í™” Mixin"""
    
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.step_number = 5
        self.step_type = "cloth_warping"
        self.enable_physics = True
        self.output_format = "warped_cloth"

class VirtualFittingMixin(BaseStepMixin):
    """Virtual Fitting Step íŠ¹í™” Mixin"""
    
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.step_number = 6
        self.step_type = "virtual_fitting"
        self.diffusion_steps = 50
        self.output_format = "rgb_image"

class PostProcessingMixin(BaseStepMixin):
    """Post Processing Step íŠ¹í™” Mixin"""
    
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.step_number = 7
        self.step_type = "post_processing"
        self.upscale_factor = 2
        self.output_format = "enhanced_image"

class QualityAssessmentMixin(BaseStepMixin):
    """Quality Assessment Step íŠ¹í™” Mixin"""
    
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.step_number = 8
        self.step_type = "quality_assessment"
        self.quality_threshold = 0.7
        self.output_format = "quality_scores"

# ==============================================
# ğŸ”§ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤ ë° ë°ì½”ë ˆì´í„°
# ==============================================

def ensure_step_initialization(func):
    """Step í´ë˜ìŠ¤ ì´ˆê¸°í™” ë³´ì¥ ë°ì½”ë ˆì´í„°"""
    async def wrapper(self, *args, **kwargs):
        # logger ì†ì„± í™•ì¸ ë° ì„¤ì •
        if not hasattr(self, 'logger'):
            self.logger = logging.getLogger(f"pipeline.{self.__class__.__name__}")
        
        # BaseStepMixin ì´ˆê¸°í™” í™•ì¸
        if not hasattr(self, 'is_initialized') or not self.is_initialized:
            await self.initialize_step()
        
        return await func(self, *args, **kwargs)
    return wrapper

def safe_step_method(func):
    """Step ë©”ì„œë“œ ì•ˆì „ ì‹¤í–‰ ë°ì½”ë ˆì´í„°"""
    async def wrapper(self, *args, **kwargs):
        try:
            # logger í™•ì¸
            if not hasattr(self, 'logger'):
                self.logger = logging.getLogger(f"pipeline.{self.__class__.__name__}")
            
            return await func(self, *args, **kwargs)
        except Exception as e:
            if hasattr(self, 'logger'):
                self.logger.error(f"âŒ {func.__name__} ì‹¤í–‰ ì‹¤íŒ¨: {e}")
                if hasattr(self, 'error_count'):
                    self.error_count += 1
                if hasattr(self, 'last_error'):
                    self.last_error = str(e)
            
            # ê¸°ë³¸ ì—ëŸ¬ ì‘ë‹µ ë°˜í™˜
            return {
                'success': False,
                'error': str(e),
                'step_name': getattr(self, 'step_name', self.__class__.__name__),
                'method_name': func.__name__
            }
    return wrapper

def performance_monitor(operation_name: str):
    """ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ë°ì½”ë ˆì´í„°"""
    def decorator(func):
        async def wrapper(self, *args, **kwargs):
            start_time = time.time()
            success = True
            try:
                result = await func(self, *args, **kwargs)
                return result
            except Exception as e:
                success = False
                raise e
            finally:
                duration = time.time() - start_time
                if hasattr(self, 'record_performance'):
                    self.record_performance(operation_name, duration, success)
        return wrapper
    return decorator

# ==============================================
# ğŸ”¥ ëª¨ë“ˆ ìµìŠ¤í¬íŠ¸
# ==============================================

__all__ = [
    # ê¸°ë³¸ Mixin
    'BaseStepMixin',
    
    # Stepë³„ íŠ¹í™” Mixinë“¤
    'HumanParsingMixin',
    'PoseEstimationMixin', 
    'ClothSegmentationMixin',
    'GeometricMatchingMixin',
    'ClothWarpingMixin',
    'VirtualFittingMixin',
    'PostProcessingMixin',
    'QualityAssessmentMixin',
    
    # ìœ í‹¸ë¦¬í‹° ë°ì½”ë ˆì´í„°
    'ensure_step_initialization',
    'safe_step_method',
    'performance_monitor'
]

# ë¡œê±° ì„¤ì •
logger = logging.getLogger(__name__)
logger.info("âœ… BaseStepMixin v2.0 ë¡œë“œ ì™„ë£Œ - ëª¨ë“  Step í´ë˜ìŠ¤ logger ì†ì„± ëˆ„ë½ ë¬¸ì œ í•´ê²°")
logger.info("ğŸ”— ModelLoader ì¸í„°í˜ì´ìŠ¤ ì™„ë²½ ì—°ë™")
logger.info("ğŸ M3 Max 128GB ìµœì í™” ì§€ì›")