# app/ai_pipeline/steps/base_step_mixin.py
"""
ğŸ”¥ BaseStepMixin v8.0 - ìˆœí™˜ ì„í¬íŠ¸ ì™„ì „ í•´ê²° + coroutine ì˜¤ë¥˜ ê·¼ë³¸ í•´ê²°
================================================================================

âœ… ìˆœí™˜ ì„í¬íŠ¸ ì™„ì „ í•´ê²° (ë™ì  ì„í¬íŠ¸ + íƒ€ì… ì²´í‚¹)
âœ… coroutine ì˜¤ë¥˜ ê·¼ë³¸ ì›ì¸ í•´ê²° (ë™ê¸° ë©”ì„œë“œë¡œ ë³€ê²½)
âœ… logger ì†ì„± ëˆ„ë½ ë¬¸ì œ ì™„ì „ í•´ê²°
âœ… ê¸°ì¡´ í•¨ìˆ˜/í´ë˜ìŠ¤ëª… 100% ìœ ì§€
âœ… Dict Callable ì˜¤ë¥˜ ì™„ì „ í•´ê²°
âœ… 89.8GB ì²´í¬í¬ì¸íŠ¸ ìë™ íƒì§€ ìœ ì§€
âœ… M3 Max 128GB ìµœì í™” ìœ ì§€
âœ… conda í™˜ê²½ ì™„ë²½ ì§€ì›
âœ… ì˜ì¡´ì„± ì£¼ì… íŒ¨í„´ ì ìš©
âœ… í”„ë¡œë•ì…˜ ì•ˆì •ì„± ìµœê³  ìˆ˜ì¤€

Author: MyCloset AI Team  
Date: 2025-07-20
Version: 8.0 (Complete Circular Import Resolution + Coroutine Fix)
"""

import os
import gc
import time
import asyncio
import logging
import threading
import traceback
import weakref
from pathlib import Path
from typing import Dict, Any, Optional, Union, List, Type, Callable, Tuple, TYPE_CHECKING
from abc import ABC, abstractmethod
from dataclasses import dataclass, field
from concurrent.futures import ThreadPoolExecutor
from functools import wraps

# ==============================================
# ğŸ”¥ TYPE_CHECKINGìœ¼ë¡œ ìˆœí™˜ ì„í¬íŠ¸ ì™„ì „ ë°©ì§€
# ==============================================

if TYPE_CHECKING:
    # íƒ€ì… ì²´í‚¹ ì‹œì—ë§Œ ì„í¬íŠ¸ (ëŸ°íƒ€ì„ì—ëŠ” ì„í¬íŠ¸ ì•ˆë¨)
    from ..utils.model_loader import ModelLoader, StepModelInterface, SafeFunctionValidator
    from ..utils.memory_manager import MemoryManager
    from ..utils.auto_model_detector import RealWorldModelDetector

# ==============================================
# ğŸ”¥ NumPy 2.x í˜¸í™˜ì„± ë¬¸ì œ ì™„ì „ í•´ê²°
# ==============================================

try:
    import numpy as np
    numpy_version = np.__version__
    major_version = int(numpy_version.split('.')[0])
    
    if major_version >= 2:
        logging.warning(f"âš ï¸ NumPy {numpy_version} ê°ì§€ë¨. NumPy 1.x ê¶Œì¥")
        try:
            np.set_printoptions(legacy='1.25')
            logging.info("âœ… NumPy 2.x í˜¸í™˜ì„± ëª¨ë“œ í™œì„±í™”")
        except:
            pass
    NUMPY_AVAILABLE = True
except ImportError:
    NUMPY_AVAILABLE = False
    np = None

# ì•ˆì „í•œ PyTorch import
try:
    os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '1'
    os.environ['PYTORCH_MPS_HIGH_WATERMARK_RATIO'] = '0.0'
    
    import torch
    import torch.nn as nn
    TORCH_AVAILABLE = True
    
    if hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
        MPS_AVAILABLE = True
        DEFAULT_DEVICE = "mps"
    else:
        MPS_AVAILABLE = False
        DEFAULT_DEVICE = "cpu"
        
except ImportError:
    TORCH_AVAILABLE = False
    MPS_AVAILABLE = False
    DEFAULT_DEVICE = "cpu"
    torch = None

# ì´ë¯¸ì§€ ì²˜ë¦¬ ë¼ì´ë¸ŒëŸ¬ë¦¬
try:
    import cv2
    from PIL import Image
    CV_AVAILABLE = True
    PIL_AVAILABLE = True
except ImportError:
    CV_AVAILABLE = False
    PIL_AVAILABLE = False

logger = logging.getLogger(__name__)

# ==============================================
# ğŸ”¥ SafeConfig í´ë˜ìŠ¤ (ì™„ì „ ì•ˆì „í•œ ì„¤ì • ê´€ë¦¬)
# ==============================================

class SafeConfig:
    """ğŸ”§ ì™„ì „ ì•ˆì „í•œ ì„¤ì • í´ë˜ìŠ¤ v8.0"""
    
    def __init__(self, data: Any = None):
        """ì™„ì „ ì•ˆì „í•œ ì´ˆê¸°í™”"""
        self._data = {}
        self._original_data = data
        self._lock = threading.RLock()
        
        try:
            with self._lock:
                if data is None:
                    self._data = {}
                elif isinstance(data, dict):
                    self._data = self._safe_dict_copy(data)
                elif hasattr(data, '__dict__'):
                    self._data = self._safe_object_to_dict(data)
                elif callable(data):
                    logger.warning("âš ï¸ callable ì„¤ì • ê°ì²´ ê°ì§€, ë¹ˆ ì„¤ì •ìœ¼ë¡œ ì²˜ë¦¬")
                    self._data = {}
                else:
                    if hasattr(data, '__iter__') and not isinstance(data, (str, bytes)):
                        try:
                            self._data = dict(data)
                        except:
                            self._data = {}
                    else:
                        self._data = {}
                
                self._set_attributes_safely()
                
        except Exception as e:
            logger.warning(f"âš ï¸ SafeConfig ì´ˆê¸°í™” ì‹¤íŒ¨: {e}, ë¹ˆ ì„¤ì • ì‚¬ìš©")
            self._data = {}
    
    def _safe_dict_copy(self, data: dict) -> dict:
        """ë”•ì…”ë„ˆë¦¬ ì•ˆì „ ë³µì‚¬"""
        safe_dict = {}
        for key, value in data.items():
            try:
                if not callable(value):
                    safe_dict[key] = value
            except:
                pass
        return safe_dict
    
    def _safe_object_to_dict(self, obj: Any) -> dict:
        """ê°ì²´ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ì•ˆì „ ë³€í™˜"""
        safe_dict = {}
        
        if hasattr(obj, '__dict__'):
            for key, value in obj.__dict__.items():
                try:
                    if not key.startswith('_') and not callable(value):
                        safe_dict[key] = value
                except:
                    pass
        
        for attr_name in dir(obj):
            if not attr_name.startswith('_'):
                try:
                    attr_value = getattr(obj, attr_name)
                    if not callable(attr_value):
                        safe_dict[attr_name] = attr_value
                except:
                    pass
        
        return safe_dict
    
    def _set_attributes_safely(self):
        """ì†ì„±ë“¤ì„ ì•ˆì „í•˜ê²Œ ì„¤ì •"""
        for key, value in self._data.items():
            try:
                if isinstance(key, str) and key.isidentifier() and not hasattr(self, key):
                    setattr(self, key, value)
            except:
                pass
    
    def get(self, key: str, default=None):
        """ì™„ì „ ì•ˆì „í•œ get ë©”ì„œë“œ"""
        try:
            with self._lock:
                return self._data.get(key, default)
        except Exception as e:
            logger.debug(f"SafeConfig.get ì˜¤ë¥˜: {e}")
            return default
    
    def __getitem__(self, key):
        return self.get(key, None)
    
    def __setitem__(self, key, value):
        try:
            with self._lock:
                self._data[key] = value
                if isinstance(key, str) and key.isidentifier():
                    setattr(self, key, value)
        except Exception as e:
            logger.debug(f"SafeConfig.__setitem__ ì˜¤ë¥˜: {e}")
    
    def __contains__(self, key):
        try:
            return key in self._data
        except:
            return False
    
    def keys(self):
        try:
            return self._data.keys()
        except:
            return []
    
    def values(self):
        try:
            return self._data.values()
        except:
            return []
    
    def items(self):
        try:
            return self._data.items()
        except:
            return []
    
    def update(self, other):
        try:
            with self._lock:
                if isinstance(other, dict):
                    for key, value in other.items():
                        if not callable(value):
                            self._data[key] = value
                            if isinstance(key, str) and key.isidentifier():
                                setattr(self, key, value)
        except Exception as e:
            logger.debug(f"SafeConfig.update ì˜¤ë¥˜: {e}")
    
    def __str__(self):
        return str(self._data)
    
    def __repr__(self):
        return f"SafeConfig({self._data})"
    
    def __bool__(self):
        return bool(self._data)
    
    def __len__(self):
        return len(self._data)

# ==============================================
# ğŸ”¥ í´ë°± SafeFunctionValidator (ìˆœí™˜ ì„í¬íŠ¸ ë°©ì§€)
# ==============================================

class FallbackSafeFunctionValidator:
    """í´ë°± SafeFunctionValidator - ìˆœí™˜ ì„í¬íŠ¸ ì‹œ ì‚¬ìš©"""
    
    @staticmethod
    def safe_call(func: Callable, *args, **kwargs) -> Tuple[bool, Any, str]:
        """ì•ˆì „í•œ í•¨ìˆ˜ í˜¸ì¶œ"""
        try:
            if not callable(func):
                return False, None, "Object is not callable"
            result = func(*args, **kwargs)
            return True, result, "Success"
        except Exception as e:
            return False, None, str(e)
    
    @staticmethod
    async def safe_async_call(func: Callable, *args, **kwargs) -> Tuple[bool, Any, str]:
        """ì•ˆì „í•œ ë¹„ë™ê¸° í•¨ìˆ˜ í˜¸ì¶œ"""
        try:
            if not callable(func):
                return False, None, "Object is not callable"
            
            if asyncio.iscoroutinefunction(func):
                result = await func(*args, **kwargs)
            else:
                result = func(*args, **kwargs)
            return True, result, "Success"
        except Exception as e:
            return False, None, str(e)
    
    @staticmethod
    def safe_getattr_call(obj: Any, attr_name: str, *args, **kwargs) -> Tuple[bool, Any, str]:
        """ì•ˆì „í•œ ì†ì„± ì ‘ê·¼ ë° í˜¸ì¶œ"""
        try:
            if not hasattr(obj, attr_name):
                return False, None, f"Object has no attribute '{attr_name}'"
            
            attr = getattr(obj, attr_name)
            
            if args or kwargs:
                if callable(attr):
                    result = attr(*args, **kwargs)
                    return True, result, "Success"
                else:
                    return False, None, f"Attribute '{attr_name}' is not callable"
            else:
                return True, attr, "Success"
                
        except Exception as e:
            return False, None, str(e)

# ==============================================
# ğŸ”¥ BaseStepMixin v8.0 - ì™„ì „ ìµœì í™”
# ==============================================

class BaseStepMixin:
    """
    ğŸ”¥ BaseStepMixin v8.0 - ìˆœí™˜ ì„í¬íŠ¸ ì™„ì „ í•´ê²° + coroutine ì˜¤ë¥˜ ê·¼ë³¸ í•´ê²°
    
    âœ… ìˆœí™˜ ì„í¬íŠ¸ ì™„ì „ í•´ê²° (ë™ì  ì„í¬íŠ¸ + TYPE_CHECKING)
    âœ… coroutine ì˜¤ë¥˜ ê·¼ë³¸ ì›ì¸ í•´ê²° (ë™ê¸° ë©”ì„œë“œ)
    âœ… logger ì†ì„± ëˆ„ë½ ë¬¸ì œ ì™„ì „ í•´ê²°
    âœ… ê¸°ì¡´ API 100% í˜¸í™˜ì„± ìœ ì§€
    âœ… Dict Callable ì˜¤ë¥˜ ì™„ì „ í•´ê²°
    âœ… 89.8GB ì²´í¬í¬ì¸íŠ¸ ìë™ íƒì§€ ìœ ì§€
    âœ… M3 Max 128GB ìµœì í™” ìœ ì§€
    âœ… ì˜ì¡´ì„± ì£¼ì… íŒ¨í„´ ì ìš©
    """
    
    # í´ë˜ìŠ¤ ë³€ìˆ˜
    _class_registry = weakref.WeakSet()
    _initialization_lock = threading.RLock()
    
    def __init__(
        self, 
        model_loader: Optional['ModelLoader'] = None,
        memory_manager: Optional['MemoryManager'] = None,
        function_validator: Optional['SafeFunctionValidator'] = None,
        **kwargs
    ):
        """ğŸ”¥ v8.0 ì™„ì „ ìµœì í™”ëœ ì´ˆê¸°í™”"""
        
        # ===== ğŸ”¥ STEP 0: logger ì†ì„± ìµœìš°ì„  ìƒì„± (ì ˆëŒ€ ëˆ„ë½ ë°©ì§€) =====
        self._ensure_logger_first()
        
        # ===== ğŸ”¥ STEP 1: ì˜ì¡´ì„± ì£¼ì… ì €ì¥ =====
        self.model_loader = model_loader
        self.memory_manager = memory_manager
        self.function_validator = function_validator or FallbackSafeFunctionValidator()
        self.model_interface = None
        
        # ===== ğŸ”¥ STEP 2: í´ë˜ìŠ¤ ë“±ë¡ =====
        BaseStepMixin._class_registry.add(self)
        
        # ===== ğŸ”¥ STEP 3: ì•ˆì „í•œ ì´ˆê¸°í™” =====
        with BaseStepMixin._initialization_lock:
            try:
                # ê¸°ì¡´ ì´ˆê¸°í™” ìˆœì„œ ìœ ì§€
                self._check_numpy_compatibility()
                self._setup_basic_attributes(kwargs)
                self._safe_super_init()
                self._setup_device_and_system(kwargs)
                self._setup_config_safely(kwargs)
                self._setup_state_management()
                self._setup_m3_max_optimization()
                self._setup_memory_optimization()
                self._setup_warmup_system()
                self._setup_performance_monitoring()
                
                # ===== ğŸ”¥ STEP 4: ModelLoader ì¸í„°í˜ì´ìŠ¤ ì„¤ì • (ë™ê¸°) =====
                self._setup_model_interface_sync()  # ğŸ”¥ í•µì‹¬: ë™ê¸° ë²„ì „
                
                # ===== ğŸ”¥ STEP 5: ì²´í¬í¬ì¸íŠ¸ íƒì§€ (ë™ê¸°) =====
                self._setup_checkpoint_detection_sync()  # ğŸ”¥ í•µì‹¬: ë™ê¸° ë²„ì „
                
                self.logger.info(f"âœ… {self.step_name} BaseStepMixin v8.0 ì´ˆê¸°í™” ì™„ë£Œ")
                self.logger.debug(f"ğŸ”§ Device: {self.device}, Memory: {self.memory_gb}GB")
                
            except Exception as e:
                self._emergency_initialization()
                if hasattr(self, 'logger'):
                    self.logger.error(f"âŒ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                    self.logger.debug(f"ğŸ“‹ ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
    
    # ==============================================
    # ğŸ”¥ STEP 0: logger ì†ì„± ìµœìš°ì„  ë³´ì¥
    # ==============================================
    
    def _ensure_logger_first(self):
        """ğŸ”¥ logger ì†ì„± ìµœìš°ì„  ìƒì„± - ëª¨ë“  Step í´ë˜ìŠ¤ì—ì„œ logger ëˆ„ë½ ë°©ì§€"""
        try:
            if hasattr(self, 'logger') and self.logger is not None:
                return
            
            # Step ì´ë¦„ ê²°ì •
            class_name = self.__class__.__name__
            step_name = getattr(self, 'step_name', class_name)
            
            # ê³„ì¸µì  ë¡œê±° ì´ë¦„ ìƒì„±
            logger_name = f"pipeline.{step_name}"
            
            # ë¡œê±° ìƒì„±
            self.logger = logging.getLogger(logger_name)
            self.logger.setLevel(logging.INFO)
            
            # í•¸ë“¤ëŸ¬ ì„¤ì • (ì¤‘ë³µ ë°©ì§€)
            if not self.logger.handlers:
                handler = logging.StreamHandler()
                formatter = logging.Formatter(
                    '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
                )
                handler.setFormatter(formatter)
                self.logger.addHandler(handler)
                self.logger.propagate = False
            
            self.logger.info(f"ğŸ”§ {step_name} logger ì´ˆê¸°í™” ì™„ë£Œ")
            
        except Exception as e:
            try:
                # í´ë°± ë¡œê±°
                self.logger = logging.getLogger(__name__)
                self.logger.error(f"âŒ logger ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            except:
                print(f"âŒ CRITICAL: logger ì´ˆê¸°í™” ì™„ì „ ì‹¤íŒ¨: {e}")
    
    # ==============================================
    # ğŸ”¥ ê¸°ì¡´ ì´ˆê¸°í™” ë©”ì„œë“œë“¤ (ë‚´ìš© 100% ìœ ì§€)
    # ==============================================
    
    def _check_numpy_compatibility(self):
        """NumPy 2.x í˜¸í™˜ì„± ì²´í¬"""
        if NUMPY_AVAILABLE and int(np.__version__.split('.')[0]) >= 2:
            self.logger.warning(f"âš ï¸ NumPy {np.__version__} (2.x) ê°ì§€ë¨")
    
    def _setup_basic_attributes(self, kwargs: Dict[str, Any]):
        """ê¸°ë³¸ ì†ì„±ë“¤ ì„¤ì •"""
        try:
            self.step_name = getattr(self, 'step_name', self.__class__.__name__)
            self.step_number = getattr(self, 'step_number', 0)
            self.step_type = getattr(self, 'step_type', 'unknown')
            
            self.is_initialized = False
            self.initialization_error = None
            self.error_count = 0
            self.last_error = None
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ ê¸°ë³¸ ì†ì„± ì„¤ì • ì‹¤íŒ¨: {e}")
    
    def _safe_super_init(self):
        """ì•ˆì „í•œ super() í˜¸ì¶œ"""
        try:
            mro = type(self).__mro__
            
            if len(mro) > 2 and mro[-2] != BaseStepMixin:
                try:
                    super().__init__()
                except TypeError as te:
                    if "positional argument" in str(te):
                        try:
                            super().__init__({})
                        except:
                            pass
                    else:
                        pass
                
        except Exception as e:
            self.logger.debug(f"super() í˜¸ì¶œ ê±´ë„ˆëœ€: {e}")
    
    def _setup_device_and_system(self, kwargs: Dict[str, Any]):
        """ë””ë°”ì´ìŠ¤ ë° ì‹œìŠ¤í…œ ì„¤ì •"""
        try:
            self.device = self._safe_device_detection(kwargs)
            self.device_type = self._detect_device_type()
            self.memory_gb = kwargs.get('memory_gb', self._detect_memory())
            self.is_m3_max = kwargs.get('is_m3_max', self._detect_m3_max())
            self.optimization_enabled = kwargs.get('optimization_enabled', True)
            self.quality_level = kwargs.get('quality_level', 'balanced')
            self.batch_size = kwargs.get('batch_size', self._calculate_optimal_batch_size())
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ ë””ë°”ì´ìŠ¤ ì„¤ì • ì‹¤íŒ¨: {e}")
            # í´ë°± ì„¤ì •
            self.device = DEFAULT_DEVICE
            self.device_type = "unknown"
            self.memory_gb = 16.0
            self.is_m3_max = False
            self.optimization_enabled = False
            self.quality_level = 'balanced'
            self.batch_size = 1
    
    def _safe_device_detection(self, kwargs: Dict[str, Any]) -> str:
        """ì•ˆì „í•œ ë””ë°”ì´ìŠ¤ íƒì§€"""
        try:
            device_candidates = [
                kwargs.get('device'),
                kwargs.get('preferred_device'), 
                kwargs.get('target_device'),
                getattr(self, 'device', None)
            ]
            
            for device in device_candidates:
                if device and device != "auto":
                    return device
            
            return self._auto_detect_device()
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ ë””ë°”ì´ìŠ¤ íƒì§€ ì‹¤íŒ¨: {e}")
            return DEFAULT_DEVICE
    
    def _auto_detect_device(self, preferred_device: Optional[str] = None, device: Optional[str] = None) -> str:
        """í†µì¼ëœ ë””ë°”ì´ìŠ¤ ìë™ íƒì§€ ë©”ì„œë“œ"""
        try:
            target_device = preferred_device or device
            
            if target_device and target_device != "auto":
                return target_device
                
            if not TORCH_AVAILABLE:
                return "cpu"
            
            if MPS_AVAILABLE:
                return "mps"
            elif torch.cuda.is_available():
                return "cuda"
            else:
                return "cpu"
                
        except Exception:
            return "cpu"
    
    def _detect_device_type(self) -> str:
        try:
            if self.device == "mps":
                return "apple_silicon"
            elif self.device == "cuda":
                return "nvidia_gpu"
            else:
                return "generic_cpu"
        except:
            return "unknown"
    
    def _detect_memory(self) -> float:
        try:
            import psutil
            return round(psutil.virtual_memory().total / (1024**3), 1)
        except:
            return 16.0
    
    def _detect_m3_max(self) -> bool:
        try:
            import platform
            processor = str(platform.processor())
            return ("M3" in processor or 
                   (self.device == "mps" and self.memory_gb > 64))
        except:
            return False
    
    def _calculate_optimal_batch_size(self) -> int:
        try:
            if self.is_m3_max and self.memory_gb >= 128:
                return 8
            elif self.memory_gb >= 64:
                return 4
            elif self.memory_gb >= 32:
                return 2
            else:
                return 1
        except:
            return 1
    
    def _setup_config_safely(self, kwargs: Dict[str, Any]):
        """ì„¤ì • ê°ì²´ ì•ˆì „ ì²˜ë¦¬"""
        try:
            raw_config = kwargs.get('config', {})
            self.config = SafeConfig(raw_config)
            
            safe_kwargs = {}
            for key, value in kwargs.items():
                try:
                    if key != 'config' and not callable(value):
                        safe_kwargs[key] = value
                except:
                    pass
            
            if safe_kwargs:
                self.config.update(safe_kwargs)
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ ì„¤ì • ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            self.config = SafeConfig({})
    
    def _setup_state_management(self):
        """ìƒíƒœ ê´€ë¦¬ ì´ˆê¸°í™”"""
        try:
            cache_dir = getattr(self.config, 'cache_dir', './cache')
            self.cache_dir = Path(cache_dir)
            self.cache_dir.mkdir(parents=True, exist_ok=True)
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ ìƒíƒœ ê´€ë¦¬ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    
    def _setup_m3_max_optimization(self):
        """M3 Max ìµœì í™” ì„¤ì •"""
        try:
            if self.device == "mps" and TORCH_AVAILABLE:
                os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '1'
                os.environ['PYTORCH_MPS_HIGH_WATERMARK_RATIO'] = '0.0'
                
                if hasattr(torch.backends.mps, 'enable_fallback'):
                    torch.backends.mps.enable_fallback = True
                
                if self.is_m3_max:
                    os.environ['OMP_NUM_THREADS'] = '16'
                
                self.dtype = torch.float32
                
                self.logger.info("ğŸ M3 Max ìµœì í™” ì„¤ì • ì™„ë£Œ")
                
        except Exception as e:
            self.logger.warning(f"âš ï¸ M3 Max ìµœì í™” ì‹¤íŒ¨: {e}")
    
    def _setup_memory_optimization(self):
        """ë©”ëª¨ë¦¬ ìµœì í™” ì„¤ì •"""
        try:
            if TORCH_AVAILABLE:
                torch.backends.cudnn.benchmark = (self.device == "cuda")
                
                if hasattr(torch.backends, 'cuda') and self.device == "cuda":
                    torch.backends.cuda.matmul.allow_tf32 = True
                    torch.backends.cudnn.allow_tf32 = True
            
            gc.set_threshold(700, 10, 10)
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ ë©”ëª¨ë¦¬ ìµœì í™” ì„¤ì • ì‹¤íŒ¨: {e}")
    
    def _setup_warmup_system(self):
        """ì›Œë°ì—… ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
        try:
            self.warmup_functions = {
                'model_warmup': self._safe_model_warmup,
                'device_warmup': self._safe_device_warmup,
                'memory_warmup': self._safe_memory_warmup,
                'pipeline_warmup': self._safe_pipeline_warmup
            }
            
            self.warmup_config = SafeConfig({
                'enabled': True,
                'timeout': 30.0,
                'retry_count': 3,
                'warm_cache': True
            })
            
            for name, func in self.warmup_functions.items():
                if not callable(func):
                    self.logger.error(f"âŒ {name}ì´ callableì´ ì•„ë‹˜: {type(func)}")
                    self.warmup_functions[name] = self._create_dummy_warmup(name)
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ ì›Œë°ì—… ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.warmup_functions = {}
            self.warmup_config = SafeConfig({})
    
    def _create_dummy_warmup(self, name: str) -> Callable:
        """ì•ˆì „í•œ ë”ë¯¸ ì›Œë°ì—… í•¨ìˆ˜ ìƒì„±"""
        async def dummy_warmup():
            self.logger.debug(f"ğŸ”§ ë”ë¯¸ ì›Œë°ì—… ì‹¤í–‰: {name}")
            return True
        return dummy_warmup
    
    def _setup_performance_monitoring(self):
        """ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
        try:
            self.performance_metrics = {
                'total_calls': 0,
                'successful_calls': 0,
                'failed_calls': 0,
                'average_duration': 0.0,
                'min_duration': float('inf'),
                'max_duration': 0.0,
                'last_call_duration': 0.0,
                'total_duration': 0.0
            }
            
            self.last_processing_time = 0.0
            self.total_processing_count = 0
            self.performance_history = []
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.performance_metrics = {}
            self.last_processing_time = 0.0
            self.total_processing_count = 0
    
    def _emergency_initialization(self):
        """ì‘ê¸‰ ì´ˆê¸°í™”"""
        try:
            if not hasattr(self, 'logger'):
                self.logger = logging.getLogger(__name__)
            if not hasattr(self, 'step_name'):
                self.step_name = self.__class__.__name__
            if not hasattr(self, 'device'):
                self.device = "cpu"
            if not hasattr(self, 'config'):
                self.config = SafeConfig({})
            if not hasattr(self, 'is_initialized'):
                self.is_initialized = False
            if not hasattr(self, 'performance_metrics'):
                self.performance_metrics = {}
            if not hasattr(self, 'function_validator'):
                self.function_validator = FallbackSafeFunctionValidator()
            
            self.logger.warning("âš ï¸ ì‘ê¸‰ ì´ˆê¸°í™” ì™„ë£Œ")
            
        except:
            pass
    
    # ==============================================
    # ğŸ”¥ í•µì‹¬: ModelLoader ì¸í„°í˜ì´ìŠ¤ ì„¤ì • (ë™ê¸° ë²„ì „)
    # ==============================================
    
    def _setup_model_interface_sync(self):
        """
        ğŸ”¥ v8.0 í•µì‹¬: ModelLoader ì¸í„°í˜ì´ìŠ¤ ì„¤ì • - ë™ê¸° ë²„ì „ìœ¼ë¡œ ì™„ì „ ìˆ˜ì •
        
        âœ… coroutine ì˜¤ë¥˜ ì™„ì „ í•´ê²° (ë¹„ë™ê¸° -> ë™ê¸° ë³€ê²½)
        âœ… ìˆœí™˜ ì„í¬íŠ¸ ì™„ì „ ë°©ì§€ (ë™ì  ì„í¬íŠ¸)
        âœ… Dict Callable ì˜¤ë¥˜ ì™„ì „ í•´ê²°
        âœ… ì•ˆì „í•œ ì—ëŸ¬ ì²˜ë¦¬
        """
        try:
            self.logger.info(f"ğŸ”— {self.step_name} ModelLoader ì¸í„°í˜ì´ìŠ¤ ì„¤ì • ì¤‘...")
            
            # ğŸ”¥ Step 1: ì£¼ì…ëœ model_loader ì‚¬ìš© (ìµœìš°ì„ )
            if self.model_loader:
                self.logger.info("âœ… ì£¼ì…ëœ ModelLoader ì‚¬ìš©")
                interface = self._create_interface_from_loader(self.model_loader)
                if interface:
                    self.model_interface = interface
                    self.logger.info(f"âœ… {self.step_name} ëª¨ë¸ ì¸í„°í˜ì´ìŠ¤ ìƒì„± ì™„ë£Œ (ì£¼ì…)")
                    return
            
            # ğŸ”¥ Step 2: ë™ì  ì„í¬íŠ¸ë¡œ ì „ì—­ ModelLoader ê°€ì ¸ì˜¤ê¸°
            try:
                # ëŸ°íƒ€ì„ ë™ì  ì„í¬íŠ¸ (ìˆœí™˜ ì„í¬íŠ¸ ë°©ì§€)
                from ...utils.model_loader import get_global_model_loader
                
                success, model_loader, message = self.function_validator.safe_call(get_global_model_loader)
                
                if success and model_loader:
                    self.model_loader = model_loader
                    interface = self._create_interface_from_loader(model_loader)
                    
                    if interface:
                        self.model_interface = interface
                        self.logger.info(f"âœ… {self.step_name} ëª¨ë¸ ì¸í„°í˜ì´ìŠ¤ ìƒì„± ì™„ë£Œ (ì „ì—­)")
                    else:
                        self.logger.warning(f"âš ï¸ {self.step_name} ì¸í„°í˜ì´ìŠ¤ ìƒì„± ì‹¤íŒ¨")
                        self.model_interface = None
                else:
                    self.logger.warning(f"âš ï¸ ì „ì—­ ModelLoader ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {message}")
                    self.model_interface = None
                    
            except ImportError as e:
                self.logger.debug(f"ModelLoader ë™ì  ì„í¬íŠ¸ ì‹¤íŒ¨: {e}")
                self.model_interface = None
            except Exception as e:
                self.logger.warning(f"âš ï¸ ModelLoader ë™ì  ë¡œë”© ì‹¤íŒ¨: {e}")
                self.model_interface = None
            
            # ğŸ”¥ Step 3: ì—°ë™ ìƒíƒœ ë¡œê¹…
            self._log_interface_status()
            
        except Exception as e:
            self.logger.error(f"âŒ ModelLoader ì¸í„°í˜ì´ìŠ¤ ì„¤ì • ì‹¤íŒ¨: {e}")
            self.logger.debug(f"ğŸ“‹ ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
            
            # ì™„ì „ í´ë°± ì„¤ì •
            self.model_interface = None
            if not hasattr(self, 'model_loader'):
                self.model_loader = None
    
    def _create_interface_from_loader(self, model_loader) -> Optional[Any]:
        """ModelLoaderì—ì„œ ì¸í„°í˜ì´ìŠ¤ ìƒì„± (ë™ê¸°)"""
        try:
            if not model_loader:
                return None
            
            # ğŸ”¥ í•µì‹¬: create_step_interface ë©”ì„œë“œë¥¼ ë™ê¸°ì ìœ¼ë¡œ í˜¸ì¶œ
            if hasattr(model_loader, 'create_step_interface'):
                create_method = getattr(model_loader, 'create_step_interface')
                
                success, interface, message = self.function_validator.safe_call(
                    create_method, self.step_name
                )
                
                if success:
                    self.logger.info(f"âœ… {self.step_name} ì¸í„°í˜ì´ìŠ¤ ìƒì„± ì„±ê³µ")
                    return interface
                else:
                    self.logger.warning(f"âš ï¸ create_step_interface í˜¸ì¶œ ì‹¤íŒ¨: {message}")
                    return None
            else:
                self.logger.warning("âš ï¸ ModelLoaderì— create_step_interface ë©”ì„œë“œê°€ ì—†ìŠµë‹ˆë‹¤")
                return None
                
        except Exception as e:
            self.logger.error(f"âŒ ì¸í„°í˜ì´ìŠ¤ ìƒì„± ì‹¤íŒ¨: {e}")
            return None
    
    def _log_interface_status(self):
        """ì¸í„°í˜ì´ìŠ¤ ì—°ë™ ìƒíƒœ ë¡œê¹…"""
        try:
            interface_status = "âœ… ì—°ê²°ë¨" if self.model_interface else "âŒ ì—°ê²° ì‹¤íŒ¨"
            loader_status = "âœ… ë¡œë“œë¨" if self.model_loader else "âŒ ë¡œë“œ ì‹¤íŒ¨"
            validator_status = "âœ… ì‚¬ìš© ê°€ëŠ¥" if self.function_validator else "âŒ ì—†ìŒ"
            
            self.logger.info(f"ğŸ”— ModelLoader ì—°ë™ ê²°ê³¼:")
            self.logger.info(f"   - ModelLoader: {loader_status}")
            self.logger.info(f"   - Step Interface: {interface_status}")
            self.logger.info(f"   - SafeFunctionValidator: {validator_status}")
            
        except Exception as e:
            self.logger.debug(f"ì¸í„°í˜ì´ìŠ¤ ìƒíƒœ ë¡œê¹… ì‹¤íŒ¨: {e}")
    
    # ==============================================
    # ğŸ”¥ ì²´í¬í¬ì¸íŠ¸ íƒì§€ ì„¤ì • (ë™ê¸° ë²„ì „)
    # ==============================================
    
    def _setup_checkpoint_detection_sync(self):
        """
        ğŸ”¥ v8.0: ì²´í¬í¬ì¸íŠ¸ íƒì§€ ì„¤ì • - ë™ê¸° ë²„ì „
        
        âœ… 89.8GB ì²´í¬í¬ì¸íŠ¸ ìë™ íƒì§€ ìœ ì§€
        âœ… coroutine ì˜¤ë¥˜ ì™„ì „ í•´ê²°
        âœ… ìˆœí™˜ ì„í¬íŠ¸ ë°©ì§€
        """
        try:
            self.logger.info(f"ğŸ” {self.step_name} ì²´í¬í¬ì¸íŠ¸ íƒì§€ ì‹œì‘...")
            
            # ì²´í¬í¬ì¸íŠ¸ íƒì§€ëŠ” ì„ íƒì  ê¸°ëŠ¥ì´ë¯€ë¡œ ì‹¤íŒ¨í•´ë„ ê³„ì† ì§„í–‰
            if not self.model_loader:
                self.logger.debug("â³ ModelLoader ì—†ìŒ, ì²´í¬í¬ì¸íŠ¸ íƒì§€ ìŠ¤í‚µ")
                return
            
            try:
                # ë™ì  ì„í¬íŠ¸ë¡œ íƒì§€ê¸° ê°€ì ¸ì˜¤ê¸°
                from ...utils.auto_model_detector import create_real_world_detector
                
                detector = create_real_world_detector(
                    enable_pytorch_validation=True,
                    max_workers=2
                )
                
                step_model_filter = self._get_step_model_filter()
                
                # ğŸ”¥ ë™ê¸°ì ìœ¼ë¡œ íƒì§€ ì‹¤í–‰
                success, detected_models, message = self.function_validator.safe_call(
                    detector.detect_all_models,
                    model_type_filter=step_model_filter,
                    min_confidence=0.3,
                    force_rescan=False
                )
                
                if success and detected_models:
                    step_models = self._find_models_for_step(detected_models)
                    if step_models:
                        self._register_detected_models_sync(step_models)
                        self.logger.info(f"âœ… {len(step_models)}ê°œ ì²´í¬í¬ì¸íŠ¸ íƒì§€ ì™„ë£Œ")
                    else:
                        self.logger.debug("ê´€ë ¨ ì²´í¬í¬ì¸íŠ¸ ì—†ìŒ")
                else:
                    self.logger.debug(f"ì²´í¬í¬ì¸íŠ¸ íƒì§€ ì‹¤íŒ¨: {message}")
                    
            except ImportError as e:
                self.logger.debug(f"ì²´í¬í¬ì¸íŠ¸ íƒì§€ ëª¨ë“ˆ ì—†ìŒ: {e}")
            except Exception as e:
                self.logger.debug(f"ì²´í¬í¬ì¸íŠ¸ íƒì§€ ì‹¤íŒ¨: {e}")
                
        except Exception as e:
            self.logger.debug(f"ì²´í¬í¬ì¸íŠ¸ íƒì§€ ì„¤ì • ì‹¤íŒ¨: {e}")
    
    def _get_step_model_filter(self) -> List[str]:
        """Stepë³„ ëª¨ë¸ íƒ€ì… í•„í„° ë°˜í™˜"""
        step_filters = {
            "HumanParsingStep": ["human_parsing"],
            "PoseEstimationStep": ["pose_estimation"],
            "ClothSegmentationStep": ["cloth_segmentation"],
            "GeometricMatchingStep": ["geometric_matching"],
            "ClothWarpingStep": ["cloth_warping"],
            "VirtualFittingStep": ["virtual_fitting"],
            "PostProcessingStep": ["post_processing"],
            "QualityAssessmentStep": ["quality_assessment"]
        }
        
        return step_filters.get(self.step_name, [])
    
    def _find_models_for_step(self, detected_models: Dict) -> Dict:
        """Stepë³„ ê´€ë ¨ ëª¨ë¸ ì°¾ê¸°"""
        step_models = {}
        
        for model_name, model_info in detected_models.items():
            if hasattr(model_info, 'step_name') and model_info.step_name == self.step_name:
                step_models[model_name] = model_info
            elif hasattr(model_info, 'category') and any(filter_type in model_info.category.value 
                    for filter_type in self._get_step_model_filter()):
                step_models[model_name] = model_info
        
        return step_models
    
    def _register_detected_models_sync(self, step_models: Dict):
        """íƒì§€ëœ ëª¨ë¸ë“¤ì„ ë™ê¸°ì ìœ¼ë¡œ ë“±ë¡"""
        try:
            if not self.model_loader or not hasattr(self.model_loader, 'register_model'):
                return
            
            registered_count = 0
            
            for model_name, model_info in step_models.items():
                try:
                    model_config = {
                        'name': model_name,
                        'type': model_info.category.value if hasattr(model_info, 'category') else 'unknown',
                        'checkpoint_path': str(model_info.path) if hasattr(model_info, 'path') else '',
                        'device': self.device,
                        'pytorch_validated': getattr(model_info, 'pytorch_valid', False),
                        'parameter_count': getattr(model_info, 'parameter_count', 0),
                        'file_size_mb': getattr(model_info, 'file_size_mb', 0),
                        'confidence_score': getattr(model_info, 'confidence_score', 0.0),
                        'step_name': self.step_name,
                        'auto_detected': True
                    }
                    
                    register_method = getattr(self.model_loader, 'register_model')
                    success, result, message = self.function_validator.safe_call(
                        register_method, model_name, model_config
                    )
                    
                    if success:
                        registered_count += 1
                        self.logger.debug(f"âœ… ëª¨ë¸ ë“±ë¡ ì„±ê³µ: {model_name}")
                    else:
                        self.logger.warning(f"âš ï¸ ëª¨ë¸ ë“±ë¡ ì‹¤íŒ¨ {model_name}: {message}")
                        
                except Exception as e:
                    self.logger.warning(f"âš ï¸ ëª¨ë¸ ë“±ë¡ ì¤‘ ì˜¤ë¥˜ {model_name}: {e}")
            
            if registered_count > 0:
                self.logger.info(f"âœ… {registered_count}ê°œ íƒì§€ëœ ëª¨ë¸ ë“±ë¡ ì™„ë£Œ")
            
        except Exception as e:
            self.logger.error(f"âŒ íƒì§€ëœ ëª¨ë¸ ë“±ë¡ ì‹¤íŒ¨: {e}")
    
    # ==============================================
    # ğŸ”¥ ì›Œë°ì—… ë©”ì„œë“œë“¤ (ê¸°ì¡´ ë‚´ìš© ìœ ì§€)
    # ==============================================
    
    async def _safe_model_warmup(self) -> bool:
        """ì•ˆì „í•œ ëª¨ë¸ ì›Œë°ì—…"""
        try:
            self.logger.debug(f"ğŸ”¥ {self.step_name} ëª¨ë¸ ì›Œë°ì—…...")
            
            if TORCH_AVAILABLE and self.device == "mps":
                warmup_tensor = torch.randn(1, 3, 224, 224, 
                                          device=self.device, dtype=getattr(self, 'dtype', torch.float32))
                _ = warmup_tensor * 2.0
                del warmup_tensor
                
                if hasattr(torch.backends.mps, 'empty_cache'):
                    torch.backends.mps.empty_cache()
            
            return True
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ ëª¨ë¸ ì›Œë°ì—… ì‹¤íŒ¨: {e}")
            return False
    
    async def _safe_device_warmup(self) -> bool:
        """ì•ˆì „í•œ ë””ë°”ì´ìŠ¤ ì›Œë°ì—…"""
        try:
            if TORCH_AVAILABLE:
                test_tensor = torch.tensor([1.0], device=self.device, dtype=getattr(self, 'dtype', torch.float32))
                result = test_tensor + 1.0
                del test_tensor, result
            
            return True
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ ë””ë°”ì´ìŠ¤ ì›Œë°ì—… ì‹¤íŒ¨: {e}")
            return False
    
    async def _safe_memory_warmup(self) -> bool:
        """ì•ˆì „í•œ ë©”ëª¨ë¦¬ ì›Œë°ì—…"""
        try:
            gc.collect()
            
            if TORCH_AVAILABLE and self.device == "mps":
                if hasattr(torch.backends.mps, 'empty_cache'):
                    torch.backends.mps.empty_cache()
            
            return True
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ ë©”ëª¨ë¦¬ ì›Œë°ì—… ì‹¤íŒ¨: {e}")
            return False
    
    async def _safe_pipeline_warmup(self) -> bool:
        """ì•ˆì „í•œ íŒŒì´í”„ë¼ì¸ ì›Œë°ì—…"""
        try:
            if not hasattr(self, 'config') or not self.config:
                self.config = SafeConfig({})
            
            return True
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ íŒŒì´í”„ë¼ì¸ ì›Œë°ì—… ì‹¤íŒ¨: {e}")
            return False
    
    # ==============================================
    # ğŸ”¥ Step ì´ˆê¸°í™” ë° ì£¼ìš” ë©”ì„œë“œë“¤
    # ==============================================
    
    async def initialize_step(self) -> bool:
        """Step ì™„ì „ ì´ˆê¸°í™”"""
        try:
            self.logger.info(f"ğŸš€ {self.step_name} ì´ˆê¸°í™” ì‹œì‘...")
            
            self._verify_essential_attributes()
            await self._execute_safe_warmup()
            
            if hasattr(self, '_custom_initialize') and callable(self._custom_initialize):
                await self._custom_initialize()
            
            self.is_initialized = True
            self.logger.info(f"âœ… {self.step_name} ì´ˆê¸°í™” ì™„ë£Œ")
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ {self.step_name} ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.last_error = str(e)
            self.error_count += 1
            return False
    
    def _verify_essential_attributes(self):
        """í•„ìˆ˜ ì†ì„±ë“¤ ê²€ì¦"""
        essential_attrs = ['logger', 'step_name', 'device', 'config', 'function_validator']
        
        for attr in essential_attrs:
            if not hasattr(self, attr):
                if attr == 'logger':
                    self.logger = logging.getLogger(f"pipeline.{self.__class__.__name__}")
                elif attr == 'step_name':
                    self.step_name = self.__class__.__name__
                elif attr == 'device':
                    self.device = DEFAULT_DEVICE
                elif attr == 'config':
                    self.config = SafeConfig({})
                elif attr == 'function_validator':
                    self.function_validator = FallbackSafeFunctionValidator()
    
    async def _execute_safe_warmup(self):
        """ì•ˆì „í•œ ì›Œë°ì—… ì‹¤í–‰"""
        try:
            if not hasattr(self, 'warmup_functions') or not self.warmup_functions:
                return
            
            for warmup_name, warmup_func in self.warmup_functions.items():
                try:
                    if callable(warmup_func):
                        await warmup_func()
                    else:
                        self.logger.warning(f"âš ï¸ {warmup_name}ì´ callableì´ ì•„ë‹˜")
                except Exception as e:
                    self.logger.warning(f"âš ï¸ {warmup_name} ì‹¤íŒ¨: {e}")
                    
        except Exception as e:
            self.logger.warning(f"âš ï¸ ì›Œë°ì—… ì‹¤í–‰ ì‹¤íŒ¨: {e}")
    
    def record_performance(self, operation_name: str, duration: float, success: bool = True):
        """ì„±ëŠ¥ ë©”íŠ¸ë¦­ ê¸°ë¡"""
        try:
            self.performance_metrics['total_calls'] += 1
            self.performance_metrics['total_duration'] += duration
            self.performance_metrics['last_call_duration'] = duration
            
            if success:
                self.performance_metrics['successful_calls'] += 1
            else:
                self.performance_metrics['failed_calls'] += 1
            
            self.performance_metrics['min_duration'] = min(
                self.performance_metrics['min_duration'], duration
            )
            self.performance_metrics['max_duration'] = max(
                self.performance_metrics['max_duration'], duration
            )
            
            if self.performance_metrics['total_calls'] > 0:
                self.performance_metrics['average_duration'] = (
                    self.performance_metrics['total_duration'] / 
                    self.performance_metrics['total_calls']
                )
            
            self.performance_history.append({
                'operation': operation_name,
                'duration': duration,
                'success': success,
                'timestamp': time.time()
            })
            
            if len(self.performance_history) > 100:
                self.performance_history.pop(0)
                
        except Exception as e:
            self.logger.debug(f"ì„±ëŠ¥ ê¸°ë¡ ì‹¤íŒ¨: {e}")
    
    def get_step_info(self) -> Dict[str, Any]:
        """Step ìƒíƒœ ì •ë³´ ë°˜í™˜"""
        try:
            base_info = {
                'step_name': getattr(self, 'step_name', 'unknown'),
                'step_number': getattr(self, 'step_number', 0),
                'step_type': getattr(self, 'step_type', 'unknown'),
                'device': getattr(self, 'device', 'unknown'),
                'device_type': getattr(self, 'device_type', 'unknown'),
                'memory_gb': getattr(self, 'memory_gb', 0.0),
                'is_m3_max': getattr(self, 'is_m3_max', False),
                'optimization_enabled': getattr(self, 'optimization_enabled', False),
                'quality_level': getattr(self, 'quality_level', 'unknown'),
                'batch_size': getattr(self, 'batch_size', 1),
                'is_initialized': getattr(self, 'is_initialized', False),
                'has_model_interface': getattr(self, 'model_interface', None) is not None,
                'has_model_loader': getattr(self, 'model_loader', None) is not None,
                'has_function_validator': getattr(self, 'function_validator', None) is not None,
                'last_processing_time': getattr(self, 'last_processing_time', 0.0),
                'total_processing_count': getattr(self, 'total_processing_count', 0),
                'error_count': getattr(self, 'error_count', 0),
                'last_error': getattr(self, 'last_error', None),
                'torch_available': TORCH_AVAILABLE,
                'mps_available': MPS_AVAILABLE,
                'numpy_version': np.__version__ if NUMPY_AVAILABLE else 'N/A',
                'config_type': type(getattr(self, 'config', None)).__name__,
                'performance_metrics': getattr(self, 'performance_metrics', {}),
                'checkpoint_detection_enabled': True,
                'model_interface_type': type(getattr(self, 'model_interface', None)).__name__ if getattr(self, 'model_interface', None) else 'None',
                'version': 'v8.0 (Circular Import + Coroutine Fix)'
            }
            
            return base_info
            
        except Exception as e:
            return {
                'error': f"ì •ë³´ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}",
                'step_name': getattr(self, 'step_name', 'unknown'),
                'version': 'v8.0 (Error)'
            }
    
    def cleanup_models(self):
        """ëª¨ë¸ ì •ë¦¬"""
        try:
            if hasattr(self, 'model_interface') and self.model_interface:
                cleanup_func = getattr(self.model_interface, 'unload_models', None)
                if callable(cleanup_func):
                    success, result, message = self.function_validator.safe_call(cleanup_func)
                    if not success:
                        self.logger.warning(f"âš ï¸ ëª¨ë¸ ì–¸ë¡œë“œ ì‹¤íŒ¨: {message}")
                
            if TORCH_AVAILABLE:
                if self.device == "mps" and hasattr(torch.backends.mps, 'empty_cache'):
                    torch.backends.mps.empty_cache()
                elif self.device == "cuda":
                    torch.cuda.empty_cache()
                
                gc.collect()
            
            self.logger.info(f"ğŸ§¹ {self.step_name} ì •ë¦¬ ì™„ë£Œ")
                
        except Exception as e:
            self.logger.warning(f"âš ï¸ ì •ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
    
    def __del__(self):
        """ì†Œë©¸ì"""
        try:
            self.cleanup_models()
        except:
            pass

# ==============================================
# ğŸ”¥ ë°ì½”ë ˆì´í„°ë“¤ (ê¸°ì¡´ ë‚´ìš© 100% ìœ ì§€)
# ==============================================

def ensure_step_initialization(func: Callable) -> Callable:
    """Step ì´ˆê¸°í™” ë³´ì¥ ë°ì½”ë ˆì´í„°"""
    @wraps(func)
    async def wrapper(self, *args, **kwargs):
        if not hasattr(self, 'logger'):
            self.logger = logging.getLogger(f"pipeline.{self.__class__.__name__}")
        
        if not getattr(self, 'is_initialized', False):
            await self.initialize_step()
        
        return await func(self, *args, **kwargs)
    return wrapper

def safe_step_method(func: Callable) -> Callable:
    """Step ë©”ì„œë“œ ì•ˆì „ ì‹¤í–‰ ë°ì½”ë ˆì´í„°"""
    @wraps(func)
    async def wrapper(self, *args, **kwargs):
        try:
            return await func(self, *args, **kwargs)
        except Exception as e:
            if hasattr(self, 'logger'):
                self.logger.error(f"âŒ {func.__name__} ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            if hasattr(self, 'error_count'):
                self.error_count += 1
            if hasattr(self, 'last_error'):
                self.last_error = str(e)
            
            return {
                'success': False,
                'error': str(e),
                'step_name': getattr(self, 'step_name', self.__class__.__name__),
                'method_name': func.__name__
            }
    return wrapper

def performance_monitor(operation_name: str) -> Callable:
    """ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ë°ì½”ë ˆì´í„°"""
    def decorator(func: Callable) -> Callable:
        @wraps(func)
        async def wrapper(self, *args, **kwargs):
            start_time = time.time()
            success = True
            try:
                result = await func(self, *args, **kwargs)
                return result
            except Exception as e:
                success = False
                raise e
            finally:
                duration = time.time() - start_time
                
                if hasattr(self, 'record_performance'):
                    self.record_performance(operation_name, duration, success)
                
                if hasattr(self, 'last_processing_time'):
                    self.last_processing_time = duration
                if hasattr(self, 'total_processing_count'):
                    self.total_processing_count += 1
                    
        return wrapper
    return decorator

def memory_optimize(func: Callable) -> Callable:
    """ë©”ëª¨ë¦¬ ìµœì í™” ë°ì½”ë ˆì´í„°"""
    @wraps(func)
    async def wrapper(self, *args, **kwargs):
        try:
            result = await func(self, *args, **kwargs)
            
            if TORCH_AVAILABLE and hasattr(self, 'device'):
                if self.device == "mps" and hasattr(torch.backends.mps, 'empty_cache'):
                    torch.backends.mps.empty_cache()
                elif self.device == "cuda":
                    torch.cuda.empty_cache()
                gc.collect()
            
            return result
        except Exception as e:
            if TORCH_AVAILABLE:
                gc.collect()
            raise e
    return wrapper

def step_timing(func: Callable) -> Callable:
    """Step ì‹¤í–‰ ì‹œê°„ ì¸¡ì • ë°ì½”ë ˆì´í„°"""
    @wraps(func)
    async def wrapper(self, *args, **kwargs):
        start_time = time.time()
        try:
            result = await func(self, *args, **kwargs)
            
            processing_time = time.time() - start_time
            if hasattr(self, 'last_processing_time'):
                self.last_processing_time = processing_time
            if hasattr(self, 'total_processing_count'):
                self.total_processing_count += 1
                
            return result
        except Exception as e:
            processing_time = time.time() - start_time
            if hasattr(self, 'last_processing_time'):
                self.last_processing_time = processing_time
            raise e
    return wrapper

def error_handler(func: Callable) -> Callable:
    """ì—ëŸ¬ ì²˜ë¦¬ ë°ì½”ë ˆì´í„°"""
    @wraps(func)
    async def wrapper(self, *args, **kwargs):
        try:
            return await func(self, *args, **kwargs)
        except Exception as e:
            if hasattr(self, 'error_count'):
                self.error_count += 1
            if hasattr(self, 'last_error'):
                self.last_error = str(e)
            if hasattr(self, 'logger'):
                self.logger.error(f"âŒ {func.__name__} ì‹¤í–‰ ì‹¤íŒ¨: {e}")
                self.logger.debug(f"ğŸ“‹ ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
            
            return {
                'success': False,
                'error': str(e),
                'error_type': type(e).__name__,
                'step_name': getattr(self, 'step_name', self.__class__.__name__),
                'method_name': func.__name__,
                'timestamp': time.time()
            }
    return wrapper

# ==============================================
# ğŸ”¥ Stepë³„ íŠ¹í™” Mixinë“¤ (ê¸°ì¡´ ë‚´ìš© ìœ ì§€)
# ==============================================

class HumanParsingMixin(BaseStepMixin):
    """Step 1: Human Parsing íŠ¹í™” Mixin"""
    
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.step_number = 1
        self.step_type = "human_parsing"
        self.num_classes = 20
        self.output_format = "segmentation_mask"

class PoseEstimationMixin(BaseStepMixin):
    """Step 2: Pose Estimation íŠ¹í™” Mixin"""
    
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.step_number = 2
        self.step_type = "pose_estimation"
        self.num_keypoints = 18
        self.output_format = "keypoints"

class ClothSegmentationMixin(BaseStepMixin):
    """Step 3: Cloth Segmentation íŠ¹í™” Mixin"""
    
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.step_number = 3
        self.step_type = "cloth_segmentation"
        self.output_format = "cloth_mask"

class GeometricMatchingMixin(BaseStepMixin):
    """Step 4: Geometric Matching íŠ¹í™” Mixin"""
    
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.step_number = 4
        self.step_type = "geometric_matching"
        self.num_control_points = 25
        self.output_format = "transformation_matrix"

class ClothWarpingMixin(BaseStepMixin):
    """Step 5: Cloth Warping íŠ¹í™” Mixin"""
    
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.step_number = 5
        self.step_type = "cloth_warping"
        self.enable_physics = True
        self.output_format = "warped_cloth"

class VirtualFittingMixin(BaseStepMixin):
    """Step 6: Virtual Fitting íŠ¹í™” Mixin"""
    
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.step_number = 6
        self.step_type = "virtual_fitting"
        self.diffusion_steps = 50
        self.output_format = "rgb_image"

class PostProcessingMixin(BaseStepMixin):
    """Step 7: Post Processing íŠ¹í™” Mixin"""
    
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.step_number = 7
        self.step_type = "post_processing"
        self.upscale_factor = 2
        self.output_format = "enhanced_image"

class QualityAssessmentMixin(BaseStepMixin):
    """Step 8: Quality Assessment íŠ¹í™” Mixin"""
    
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.step_number = 8
        self.step_type = "quality_assessment"
        self.quality_threshold = 0.7
        self.output_format = "quality_scores"
        
        self.assessment_modes = ['perceptual', 'technical', 'aesthetic', 'fitting']
        self.quality_aspects = ['sharpness', 'color', 'fitting', 'realism', 'artifacts']
        self.scoring_weights = {
            'perceptual': 0.4,
            'technical': 0.3,
            'aesthetic': 0.2,
            'fitting': 0.1
        }

# ==============================================
# ğŸ”¥ ëª¨ë“ˆ ë ˆë²¨ ì •ë³´
# ==============================================

__all__ = [
    # í•µì‹¬ í´ë˜ìŠ¤ë“¤
    'BaseStepMixin',
    'SafeConfig',
    'FallbackSafeFunctionValidator',
    
    # Stepë³„ Mixinë“¤
    'HumanParsingMixin',
    'PoseEstimationMixin', 
    'ClothSegmentationMixin',
    'GeometricMatchingMixin',
    'ClothWarpingMixin',
    'VirtualFittingMixin',
    'PostProcessingMixin',
    'QualityAssessmentMixin',
    
    # ë°ì½”ë ˆì´í„°ë“¤
    'ensure_step_initialization',
    'safe_step_method',
    'performance_monitor',
    'memory_optimize',
    'step_timing',
    'error_handler',
    
    # ìƒìˆ˜ë“¤
    'TORCH_AVAILABLE',
    'MPS_AVAILABLE',
    'NUMPY_AVAILABLE',
    'CV_AVAILABLE',
    'PIL_AVAILABLE',
    'DEFAULT_DEVICE'
]

# ëª¨ë“ˆ ë¡œë“œ í™•ì¸
logger.info("âœ… BaseStepMixin v8.0 ëª¨ë“ˆ ë¡œë“œ ì™„ë£Œ")
logger.info("ğŸ”§ ìˆœí™˜ ì„í¬íŠ¸ ì™„ì „ í•´ê²° (ë™ì  ì„í¬íŠ¸ + TYPE_CHECKING)")
logger.info("ğŸ”§ coroutine ì˜¤ë¥˜ ê·¼ë³¸ í•´ê²° (ë™ê¸° ë©”ì„œë“œ)")
logger.info("ğŸ”§ logger ì†ì„± ëˆ„ë½ ë¬¸ì œ ì™„ì „ í•´ê²°")
logger.info("ğŸ”§ Dict Callable ì˜¤ë¥˜ ì™„ì „ í•´ê²°")
logger.info("ğŸ”§ 89.8GB ì²´í¬í¬ì¸íŠ¸ ìë™ íƒì§€ ìœ ì§€")
logger.info("ğŸ”§ M3 Max 128GB ìµœì í™” ìœ ì§€")
logger.info("ğŸ”§ conda í™˜ê²½ ì™„ë²½ ì§€ì›")
logger.info("ğŸ”§ ì˜ì¡´ì„± ì£¼ì… íŒ¨í„´ ì ìš©")
logger.info("ğŸ”§ í”„ë¡œë•ì…˜ ì•ˆì •ì„± ìµœê³  ìˆ˜ì¤€")

if NUMPY_AVAILABLE and hasattr(np, '__version__'):
    numpy_major = int(np.__version__.split('.')[0])
    if numpy_major >= 2:
        logger.warning("âš ï¸ NumPy 2.x ê°ì§€ë¨ - conda install numpy=1.24.3 ê¶Œì¥")
    else:
        logger.info("âœ… NumPy í˜¸í™˜ì„± í™•ì¸ë¨")

logger.info(f"ğŸ”§ PyTorch: {'âœ…' if TORCH_AVAILABLE else 'âŒ'}, MPS: {'âœ…' if MPS_AVAILABLE else 'âŒ'}")
logger.info(f"ğŸ”¢ NumPy: {'âœ…' if NUMPY_AVAILABLE else 'âŒ'}")
logger.info(f"ğŸ–¼ï¸ OpenCV/PIL: {'âœ…' if CV_AVAILABLE else 'âŒ'}")

logger.info("ğŸš€ BaseStepMixin v8.0 ì™„ì „ ìµœì í™” ì™„ë£Œ!")
logger.info("   âœ… ê¸°ì¡´ í•¨ìˆ˜/í´ë˜ìŠ¤ëª… 100% ìœ ì§€")
logger.info("   âœ… ìˆœí™˜ ì„í¬íŠ¸ ì™„ì „ í•´ê²°")
logger.info("   âœ… coroutine ì˜¤ë¥˜ ê·¼ë³¸ í•´ê²°")
logger.info("   âœ… logger ì†ì„± ëˆ„ë½ ì™„ì „ í•´ê²°")
logger.info("   âœ… Dict Callable ì˜¤ë¥˜ ì™„ì „ í•´ê²°")
logger.info("   âœ… 89.8GB ì²´í¬í¬ì¸íŠ¸ ìë™ íƒì§€")
logger.info("   âœ… M3 Max 128GB ìµœì í™”")
logger.info("   âœ… ì˜ì¡´ì„± ì£¼ì… íŒ¨í„´")
logger.info("   âœ… conda í™˜ê²½ ì™„ë²½ ì§€ì›")
logger.info("   âœ… í”„ë¡œë•ì…˜ ì•ˆì •ì„± ìµœê³  ìˆ˜ì¤€")