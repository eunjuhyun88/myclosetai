# app/ai_pipeline/steps/base_step_mixin.py
"""
ğŸ”¥ MyCloset AI - BaseStepMixin v2.2 - ì´ˆê¸°í™” ë¬¸ì œ ì™„ì „ í•´ê²°
âœ… object.__init__() íŒŒë¼ë¯¸í„° ë¬¸ì œ í•´ê²°
âœ… ë‹¤ì¤‘ ìƒì† ì•ˆì „í•œ ì²˜ë¦¬ 
âœ… logger ì†ì„± ëˆ„ë½ ë¬¸ì œ ì™„ì „ í•´ê²°
âœ… _auto_detect_device() device ì¸ì ì˜¤ë¥˜ ì™„ì „ í•´ê²°
âœ… ModelLoader ì¸í„°í˜ì´ìŠ¤ ì™„ë²½ ì—°ë™
âœ… M3 Max 128GB ìµœì í™”
"""

import os
import gc
import time
import asyncio
import logging
import threading
import traceback
from pathlib import Path
from typing import Dict, Any, Optional, Union, List, Type
from abc import ABC, abstractmethod
from dataclasses import dataclass, field
from concurrent.futures import ThreadPoolExecutor

# PyTorch import (ì•ˆì „)
try:
    import torch
    import torch.nn as nn
    TORCH_AVAILABLE = True
except ImportError:
    TORCH_AVAILABLE = False
    torch = None

# ì´ë¯¸ì§€ ì²˜ë¦¬ ë¼ì´ë¸ŒëŸ¬ë¦¬
try:
    import cv2
    import numpy as np
    from PIL import Image
    CV_AVAILABLE = True
except ImportError:
    CV_AVAILABLE = False

# ==============================================
# ğŸ”¥ ì™„ì „ ìˆ˜ì •ëœ BaseStepMixin v2.2 - ì´ˆê¸°í™” ë¬¸ì œ í•´ê²°
# ==============================================

class BaseStepMixin:
    """
    ğŸ”¥ ëª¨ë“  Step í´ë˜ìŠ¤ê°€ ìƒì†ë°›ëŠ” ê¸°ë³¸ Mixin - ì´ˆê¸°í™” ë¬¸ì œ ì™„ì „ í•´ê²°
    âœ… object.__init__() íŒŒë¼ë¯¸í„° ë¬¸ì œ ì™„ì „ í•´ê²°
    âœ… logger ì†ì„± ëˆ„ë½ ë¬¸ì œ ì™„ì „ í•´ê²°
    âœ… _auto_detect_device() ì¸ì ì—†ì´ í˜¸ì¶œ ê°€ëŠ¥
    âœ… ModelLoader ì¸í„°í˜ì´ìŠ¤ ì•ˆì „í•œ ì—°ë™
    âœ… í‘œì¤€í™”ëœ ì´ˆê¸°í™” íŒ¨í„´
    âœ… M3 Max ìµœì í™” ì§€ì›
    """
    
    def __init__(self, *args, **kwargs):
        """
        ğŸ”¥ ê¸°ë³¸ Mixin ì´ˆê¸°í™” - ë‹¤ì¤‘ ìƒì† ì•ˆì „ ì²˜ë¦¬
        
        ì´ ë©”ì„œë“œëŠ” ëª¨ë“  Step í´ë˜ìŠ¤ì—ì„œ í˜¸ì¶œë˜ì–´ì•¼ í•¨
        """
        # ğŸ”¥ ë‹¤ì¤‘ ìƒì† ì‹œ ì•ˆì „í•œ super() í˜¸ì¶œ
        try:
            # kwargsì—ì„œ BaseStepMixinì´ ëª¨ë¥´ëŠ” íŒŒë¼ë¯¸í„°ë“¤ í•„í„°ë§
            base_kwargs = {}
            
            # ì•Œë ¤ì§„ íŒŒë¼ë¯¸í„°ë“¤ë§Œ ì „ë‹¬
            known_params = {
                'device', 'quality_level', 'device_type', 'memory_gb', 
                'is_m3_max', 'optimization_enabled', 'batch_size'
            }
            
            # ë‹¤ë¥¸ í´ë˜ìŠ¤ë“¤ì´ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” íŒŒë¼ë¯¸í„°ë“¤ì€ ìœ ì§€
            for key, value in kwargs.items():
                if key not in known_params:
                    base_kwargs[key] = value
            
            # ì•ˆì „í•œ super() í˜¸ì¶œ - íŒŒë¼ë¯¸í„° ì—†ì´
            super().__init__()
            
        except TypeError as e:
            # super().__init__()ì´ íŒŒë¼ë¯¸í„°ë¥¼ ë°›ì§€ ì•ŠëŠ” ê²½ìš° (object í´ë˜ìŠ¤)
            # ì´ ê²½ìš°ëŠ” ì •ìƒì´ë¯€ë¡œ ë¬´ì‹œ
            pass
        
        # ğŸ”¥ logger ì†ì„± ëˆ„ë½ ë¬¸ì œ í•´ê²° - ë°˜ë“œì‹œ ë¨¼ì € ì„¤ì •
        if not hasattr(self, 'logger'):
            class_name = self.__class__.__name__
            self.logger = logging.getLogger(f"pipeline.{class_name}")
            self.logger.info(f"ğŸ”§ {class_name} logger ì´ˆê¸°í™” ì™„ë£Œ")
        
        # ê¸°ë³¸ ì†ì„±ë“¤ ì´ˆê¸°í™” - device ì¸ì ì—†ì´ ì•ˆì „í•˜ê²Œ í˜¸ì¶œ
        self.step_name = getattr(self, 'step_name', self.__class__.__name__)
        
        # ğŸ”¥ device ì„¤ì • - Step í´ë˜ìŠ¤ë³„ ì•ˆì „í•œ ì²˜ë¦¬
        if not hasattr(self, 'device'):
            # kwargsì—ì„œ device íŒŒë¼ë¯¸í„° í™•ì¸
            device_from_kwargs = kwargs.get('device', kwargs.get('preferred_device', 'auto'))
            try:
                self.device = self._auto_detect_device(device_from_kwargs)
            except TypeError:
                # Step í´ë˜ìŠ¤ì—ì„œ ì¸ìë¥¼ ìš”êµ¬í•˜ëŠ” ê²½ìš° ê¸°ë³¸ê°’ ì „ë‹¬
                self.device = "mps" if TORCH_AVAILABLE and torch.backends.mps.is_available() else "cpu"
                self.logger.info(f"ğŸ”§ ê¸°ë³¸ ë””ë°”ì´ìŠ¤ ì„¤ì •: {self.device}")
        
        # ğŸ”¥ ê¸°ë³¸ ì†ì„±ë“¤ ì•ˆì „í•˜ê²Œ ì´ˆê¸°í™”
        if not hasattr(self, 'is_initialized'):
            self.is_initialized = False
        if not hasattr(self, 'model_interface'):
            self.model_interface = None
        if not hasattr(self, 'performance_metrics'):
            self.performance_metrics = {}
        if not hasattr(self, 'error_count'):
            self.error_count = 0
        if not hasattr(self, 'last_error'):
            self.last_error = None
        
        # M3 Max ìµœì í™” ì„¤ì •
        self._setup_m3_max_optimization()
        
        # ModelLoader ì¸í„°í˜ì´ìŠ¤ ì„¤ì • (ì•ˆì „)
        self._setup_model_interface_safe()
        
        self.logger.info(f"âœ… {self.step_name} BaseStepMixin v2.2 ì´ˆê¸°í™” ì™„ë£Œ")
    
    def _auto_detect_device(self, preferred_device: Optional[str] = None, device: Optional[str] = None) -> str:
        """ğŸ”¥ ë””ë°”ì´ìŠ¤ ìë™ íƒì§€ - ëª¨ë“  Step í´ë˜ìŠ¤ì™€ í˜¸í™˜ (M3 Max ìµœì í™”)"""
        try:
            # device ë˜ëŠ” preferred_device ì¤‘ í•˜ë‚˜ë¼ë„ ì£¼ì–´ì§„ ê²½ìš° ìš°ì„  ì‚¬ìš©
            target_device = device or preferred_device
            if target_device and target_device != "auto":
                if hasattr(self, 'logger'):
                    self.logger.info(f"ğŸ¯ ì§€ì •ëœ ë””ë°”ì´ìŠ¤ ì‚¬ìš©: {target_device}")
                return target_device
            
            if not TORCH_AVAILABLE:
                if hasattr(self, 'logger'):
                    self.logger.warning("âš ï¸ PyTorch ì—†ìŒ, CPU ì‚¬ìš©")
                return "cpu"
                
            # M3 Max MPS ì§€ì› í™•ì¸ (ìµœìš°ì„ )
            if torch.backends.mps.is_available():
                if hasattr(self, 'logger'):
                    self.logger.info("ğŸ M3 Max MPS ë””ë°”ì´ìŠ¤ ê°ì§€")
                return "mps"
            elif torch.cuda.is_available():
                if hasattr(self, 'logger'):
                    self.logger.info("ğŸ”¥ CUDA ë””ë°”ì´ìŠ¤ ê°ì§€")
                return "cuda"
            else:
                if hasattr(self, 'logger'):
                    self.logger.info("ğŸ’» CPU ë””ë°”ì´ìŠ¤ ì‚¬ìš©")
                return "cpu"
                
        except Exception as e:
            if hasattr(self, 'logger'):
                self.logger.error(f"âŒ ë””ë°”ì´ìŠ¤ íƒì§€ ì‹¤íŒ¨: {e}, CPU ì‚¬ìš©")
            return "cpu"
    
    def _setup_m3_max_optimization(self):
        """M3 Max ìµœì í™” ì„¤ì •"""
        try:
            if getattr(self, 'device', 'cpu') == "mps" and TORCH_AVAILABLE:
                # M3 Max íŠ¹í™” ì„¤ì •
                os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '1'
                os.environ['PYTORCH_MPS_HIGH_WATERMARK_RATIO'] = '0.0'
                
                # ë©”ëª¨ë¦¬ ìµœì í™”
                if hasattr(torch.backends.mps, 'empty_cache'):
                    torch.backends.mps.empty_cache()
                
                if hasattr(self, 'logger'):
                    self.logger.info("ğŸ M3 Max MPS ìµœì í™” ì„¤ì • ì™„ë£Œ")
        except Exception as e:
            if hasattr(self, 'logger'):
                self.logger.warning(f"âš ï¸ M3 Max ìµœì í™” ì„¤ì • ì‹¤íŒ¨: {e}")
    
    def _setup_model_interface_safe(self):
        """ModelLoader ì¸í„°í˜ì´ìŠ¤ ì•ˆì „í•œ ì„¤ì •"""
        try:
            # ìˆœí™˜ import ë°©ì§€ë¥¼ ìœ„í•œ ëŠ¦ì€ import
            from ..utils.model_loader import get_global_model_loader
            
            model_loader = get_global_model_loader()
            if model_loader:
                self.model_interface = model_loader.create_step_interface(self.step_name)
                if hasattr(self, 'logger'):
                    self.logger.info(f"ğŸ”— {self.step_name} ModelLoader ì¸í„°í˜ì´ìŠ¤ ì—°ê²° ì™„ë£Œ")
            else:
                if hasattr(self, 'logger'):
                    self.logger.warning(f"âš ï¸ {self.step_name} ì „ì—­ ModelLoaderë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
                self.model_interface = None
                
        except Exception as e:
            if hasattr(self, 'logger'):
                self.logger.error(f"âŒ {self.step_name} ModelLoader ì¸í„°í˜ì´ìŠ¤ ì„¤ì • ì‹¤íŒ¨: {e}")
            self.model_interface = None
    
    async def initialize_step(self) -> bool:
        """Step ì™„ì „ ì´ˆê¸°í™”"""
        try:
            # ê¸°ë³¸ ì´ˆê¸°í™” í™•ì¸
            if not hasattr(self, 'logger'):
                self.logger = logging.getLogger(f"pipeline.{self.__class__.__name__}")
            
            if not hasattr(self, 'device'):
                self.device = self._auto_detect_device()  # ğŸ”¥ ì¸ì ì—†ì´ í˜¸ì¶œ
            
            # ModelLoader ì¸í„°í˜ì´ìŠ¤ ì¬ì„¤ì • (í•„ìš”ì‹œ)
            if not hasattr(self, 'model_interface') or self.model_interface is None:
                self._setup_model_interface_safe()
            
            self.is_initialized = True
            self.logger.info(f"âœ… {self.step_name} ì™„ì „ ì´ˆê¸°í™” ì™„ë£Œ")
            return True
            
        except Exception as e:
            if hasattr(self, 'logger'):
                self.logger.error(f"âŒ {self.step_name} ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.last_error = str(e)
            self.error_count += 1
            return False
    
    async def get_model(self, model_name: Optional[str] = None) -> Optional[Any]:
        """ëª¨ë¸ ë¡œë“œ (Stepì—ì„œ ì‚¬ìš©)"""
        try:
            if not self.model_interface:
                if hasattr(self, 'logger'):
                    self.logger.warning(f"âš ï¸ {self.step_name} ModelLoader ì¸í„°í˜ì´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤")
                return None
            
            if model_name:
                return await self.model_interface.get_model(model_name)
            else:
                # ê¶Œì¥ ëª¨ë¸ ìë™ ë¡œë“œ
                return await self.model_interface.get_recommended_model()
                
        except Exception as e:
            if hasattr(self, 'logger'):
                self.logger.error(f"âŒ {self.step_name} ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            self.last_error = str(e)
            self.error_count += 1
            return None
    
    def cleanup_models(self):
        """ëª¨ë¸ ì •ë¦¬"""
        try:
            if hasattr(self, 'model_interface') and self.model_interface:
                self.model_interface.unload_models()
                if hasattr(self, 'logger'):
                    self.logger.info(f"ğŸ§¹ {self.step_name} ëª¨ë¸ ì •ë¦¬ ì™„ë£Œ")
        except Exception as e:
            if hasattr(self, 'logger'):
                self.logger.error(f"âŒ {self.step_name} ëª¨ë¸ ì •ë¦¬ ì‹¤íŒ¨: {e}")
    
    def get_step_info(self) -> Dict[str, Any]:
        """Step ìƒíƒœ ì •ë³´ ë°˜í™˜"""
        return {
            "step_name": getattr(self, 'step_name', self.__class__.__name__),
            "device": getattr(self, 'device', 'unknown'),
            "is_initialized": getattr(self, 'is_initialized', False),
            "has_model_interface": getattr(self, 'model_interface', None) is not None,
            "error_count": getattr(self, 'error_count', 0),
            "last_error": getattr(self, 'last_error', None),
            "performance_metrics": getattr(self, 'performance_metrics', {})
        }
    
    def record_performance(self, operation: str, duration: float, success: bool = True):
        """ì„±ëŠ¥ ë©”íŠ¸ë¦­ ê¸°ë¡"""
        if not hasattr(self, 'performance_metrics'):
            self.performance_metrics = {}
            
        if operation not in self.performance_metrics:
            self.performance_metrics[operation] = {
                "total_calls": 0,
                "success_calls": 0,
                "total_duration": 0.0,
                "avg_duration": 0.0,
                "last_duration": 0.0
            }
        
        metrics = self.performance_metrics[operation]
        metrics["total_calls"] += 1
        metrics["total_duration"] += duration
        metrics["last_duration"] = duration
        metrics["avg_duration"] = metrics["total_duration"] / metrics["total_calls"]
        
        if success:
            metrics["success_calls"] += 1
    
    async def process(self, *args, **kwargs) -> Dict[str, Any]:
        """ğŸ”§ ê¸°ë³¸ ì²˜ë¦¬ ë©”ì„œë“œ (í•˜ìœ„ í´ë˜ìŠ¤ì—ì„œ ì˜¤ë²„ë¼ì´ë“œ)"""
        try:
            start_time = time.time()
            if hasattr(self, 'logger'):
                self.logger.info(f"ğŸ”„ {self.step_name} ê¸°ë³¸ ì²˜ë¦¬ ì‹¤í–‰")
            
            # ì´ˆê¸°í™” í™•ì¸
            if not getattr(self, 'is_initialized', False):
                await self.initialize_step()
            
            # ê¸°ë³¸ ì²˜ë¦¬ ê²°ê³¼
            result = {
                'success': True,
                'step_name': getattr(self, 'step_name', self.__class__.__name__),
                'result': f'{getattr(self, "step_name", self.__class__.__name__)} ê¸°ë³¸ ì²˜ë¦¬ ì™„ë£Œ',
                'confidence': 0.5,
                'processing_time': time.time() - start_time,
                'metadata': {
                    'device': getattr(self, 'device', 'unknown'),
                    'fallback': True,
                    'model_interface_available': getattr(self, 'model_interface', None) is not None
                }
            }
            
            # ì„±ëŠ¥ ê¸°ë¡
            self.record_performance("process", result['processing_time'], True)
            return result
            
        except Exception as e:
            duration = time.time() - start_time if 'start_time' in locals() else 0.0
            if hasattr(self, 'logger'):
                self.logger.error(f"âŒ {getattr(self, 'step_name', self.__class__.__name__)} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            
            if hasattr(self, 'last_error'):
                self.last_error = str(e)
            if hasattr(self, 'error_count'):
                self.error_count += 1
            
            # ì„±ëŠ¥ ê¸°ë¡ (ì‹¤íŒ¨)
            self.record_performance("process", duration, False)
            
            return {
                'success': False,
                'step_name': getattr(self, 'step_name', self.__class__.__name__),
                'error': str(e),
                'confidence': 0.0,
                'processing_time': duration
            }
    
    def __del__(self):
        """ì†Œë©¸ì"""
        try:
            self.cleanup_models()
        except:
            pass

# ==============================================
# ğŸ”¥ Stepë³„ íŠ¹í™” Mixinë“¤ - ì•ˆì „í•œ ì´ˆê¸°í™”
# ==============================================

class HumanParsingMixin(BaseStepMixin):
    """Human Parsing Step íŠ¹í™” Mixin"""
    
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.step_number = 1
        self.step_type = "human_parsing"
        self.num_classes = 20
        self.output_format = "segmentation_mask"

class PoseEstimationMixin(BaseStepMixin):
    """Pose Estimation Step íŠ¹í™” Mixin"""
    
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.step_number = 2
        self.step_type = "pose_estimation"
        self.num_keypoints = 18
        self.output_format = "keypoints_heatmap"

class ClothSegmentationMixin(BaseStepMixin):
    """Cloth Segmentation Step íŠ¹í™” Mixin"""
    
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.step_number = 3
        self.step_type = "cloth_segmentation"
        self.binary_output = True
        self.output_format = "binary_mask"

class GeometricMatchingMixin(BaseStepMixin):
    """Geometric Matching Step íŠ¹í™” Mixin"""
    
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.step_number = 4
        self.step_type = "geometric_matching"
        self.num_control_points = 25
        self.output_format = "transformation_matrix"

class ClothWarpingMixin(BaseStepMixin):
    """Cloth Warping Step íŠ¹í™” Mixin"""
    
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.step_number = 5
        self.step_type = "cloth_warping"
        self.enable_physics = True
        self.output_format = "warped_cloth"

class VirtualFittingMixin(BaseStepMixin):
    """Virtual Fitting Step íŠ¹í™” Mixin"""
    
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.step_number = 6
        self.step_type = "virtual_fitting"
        self.diffusion_steps = 50
        self.output_format = "rgb_image"

class PostProcessingMixin(BaseStepMixin):
    """Post Processing Step íŠ¹í™” Mixin"""
    
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.step_number = 7
        self.step_type = "post_processing"
        self.upscale_factor = 2
        self.output_format = "enhanced_image"

class QualityAssessmentMixin(BaseStepMixin):
    """Quality Assessment Step íŠ¹í™” Mixin"""
    
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.step_number = 8
        self.step_type = "quality_assessment"
        self.quality_threshold = 0.7
        self.output_format = "quality_scores"

# ==============================================
# ğŸ”§ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤ ë° ë°ì½”ë ˆì´í„°
# ==============================================

def ensure_step_initialization(func):
    """Step í´ë˜ìŠ¤ ì´ˆê¸°í™” ë³´ì¥ ë°ì½”ë ˆì´í„°"""
    async def wrapper(self, *args, **kwargs):
        # logger ì†ì„± í™•ì¸ ë° ì„¤ì •
        if not hasattr(self, 'logger'):
            self.logger = logging.getLogger(f"pipeline.{self.__class__.__name__}")
        
        # BaseStepMixin ì´ˆê¸°í™” í™•ì¸
        if not hasattr(self, 'is_initialized') or not self.is_initialized:
            await self.initialize_step()
        
        return await func(self, *args, **kwargs)
    return wrapper

def safe_step_method(func):
    """Step ë©”ì„œë“œ ì•ˆì „ ì‹¤í–‰ ë°ì½”ë ˆì´í„°"""
    async def wrapper(self, *args, **kwargs):
        try:
            # logger í™•ì¸
            if not hasattr(self, 'logger'):
                self.logger = logging.getLogger(f"pipeline.{self.__class__.__name__}")
            
            return await func(self, *args, **kwargs)
        except Exception as e:
            if hasattr(self, 'logger'):
                self.logger.error(f"âŒ {func.__name__} ì‹¤í–‰ ì‹¤íŒ¨: {e}")
                if hasattr(self, 'error_count'):
                    self.error_count += 1
                if hasattr(self, 'last_error'):
                    self.last_error = str(e)
            
            # ê¸°ë³¸ ì—ëŸ¬ ì‘ë‹µ ë°˜í™˜
            return {
                'success': False,
                'error': str(e),
                'step_name': getattr(self, 'step_name', self.__class__.__name__),
                'method_name': func.__name__
            }
    return wrapper

def performance_monitor(operation_name: str):
    """ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ë°ì½”ë ˆì´í„°"""
    def decorator(func):
        async def wrapper(self, *args, **kwargs):
            start_time = time.time()
            success = True
            try:
                result = await func(self, *args, **kwargs)
                return result
            except Exception as e:
                success = False
                raise e
            finally:
                duration = time.time() - start_time
                if hasattr(self, 'record_performance'):
                    self.record_performance(operation_name, duration, success)
        return wrapper
    return decorator

# ==============================================
# ğŸ”¥ ëª¨ë“ˆ ìµìŠ¤í¬íŠ¸
# ==============================================

__all__ = [
    # ê¸°ë³¸ Mixin
    'BaseStepMixin',
    
    # Stepë³„ íŠ¹í™” Mixinë“¤
    'HumanParsingMixin',
    'PoseEstimationMixin', 
    'ClothSegmentationMixin',
    'GeometricMatchingMixin',
    'ClothWarpingMixin',
    'VirtualFittingMixin',
    'PostProcessingMixin',
    'QualityAssessmentMixin',
    
    # ìœ í‹¸ë¦¬í‹° ë°ì½”ë ˆì´í„°
    'ensure_step_initialization',
    'safe_step_method',
    'performance_monitor'
]

# ë¡œê±° ì„¤ì •
logger = logging.getLogger(__name__)
logger.info("âœ… BaseStepMixin v2.2 ë¡œë“œ ì™„ë£Œ - ì´ˆê¸°í™” ë¬¸ì œ ì™„ì „ í•´ê²°")
logger.info("ğŸ”— ModelLoader ì¸í„°í˜ì´ìŠ¤ ì™„ë²½ ì—°ë™")
logger.info("ğŸ M3 Max 128GB ìµœì í™” ì§€ì›")