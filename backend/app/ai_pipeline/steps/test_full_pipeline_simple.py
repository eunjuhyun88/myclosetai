#!/usr/bin/env python3
"""
ğŸ”¥ MyCloset AI - ì „ì²´ íŒŒì´í”„ë¼ì¸ ê°„ë‹¨í•œ í†µí•© í…ŒìŠ¤íŠ¸
==================================================

ê° Stepì˜ ê¸°ë³¸ ê¸°ëŠ¥ì„ í…ŒìŠ¤íŠ¸í•˜ê³  ì „ì²´ ì›Œí¬í”Œë¡œìš°ë¥¼ ê²€ì¦í•©ë‹ˆë‹¤.
"""

import os
import sys
import logging
from pathlib import Path

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def test_step_01_human_parsing():
    """Step 01: Human Parsing í…ŒìŠ¤íŠ¸"""
    print("\nğŸ” Step 01: Human Parsing í…ŒìŠ¤íŠ¸")
    print("=" * 50)
    
    try:
        # U2Net ëª¨ë¸ í…ŒìŠ¤íŠ¸
        sys.path.append('step_01_human_parsing_models/models')
        from human_parsing_u2net import U2Net
        
        model = U2Net()
        print("âœ… U2Net ëª¨ë¸ ì´ˆê¸°í™” ì„±ê³µ")
        
        # ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ìƒì„±
        import numpy as np
        import torch
        test_image = np.zeros((512, 512, 3), dtype=np.uint8)
        input_tensor = torch.from_numpy(test_image).permute(2, 0, 1).unsqueeze(0).float() / 255.0
        
        with torch.no_grad():
            output = model(input_tensor)
            print(f"âœ… U2Net ì¶”ë¡  ì„±ê³µ: {output[0].shape}")
        
        return True
        
    except Exception as e:
        print(f"âŒ Step 01 í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        return False

def test_step_02_pose_estimation():
    """Step 02: Pose Estimation í…ŒìŠ¤íŠ¸"""
    print("\nğŸ” Step 02: Pose Estimation í…ŒìŠ¤íŠ¸")
    print("=" * 50)
    
    try:
        # HRNet Pose ëª¨ë¸ í…ŒìŠ¤íŠ¸
        sys.path.append('step_02_pose_estimation_models/models')
        from pose_estimation_models import HRNetPoseModel
        
        model = HRNetPoseModel()
        print("âœ… HRNet Pose ëª¨ë¸ ì´ˆê¸°í™” ì„±ê³µ")
        
        # ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ìƒì„±
        import numpy as np
        import torch
        test_image = np.zeros((256, 256, 3), dtype=np.uint8)
        input_tensor = torch.from_numpy(test_image).permute(2, 0, 1).unsqueeze(0).float() / 255.0
        
        with torch.no_grad():
            output = model(input_tensor)
            print(f"âœ… HRNet Pose ì¶”ë¡  ì„±ê³µ: {output.shape}")
        
        return True
        
    except Exception as e:
        print(f"âŒ Step 02 í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        return False

def test_step_03_cloth_segmentation():
    """Step 03: Cloth Segmentation í…ŒìŠ¤íŠ¸"""
    print("\nğŸ” Step 03: Cloth Segmentation í…ŒìŠ¤íŠ¸")
    print("=" * 50)
    
    try:
        # SAM ëª¨ë¸ í…ŒìŠ¤íŠ¸
        sys.path.append('step_03_cloth_segmentation_models/models')
        from cloth_segmentation_sam import SAMModel
        
        model = SAMModel()
        print("âœ… SAM ëª¨ë¸ ì´ˆê¸°í™” ì„±ê³µ")
        
        # ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ìƒì„± (ë” ì‘ì€ í¬ê¸°ë¡œ)
        import numpy as np
        import torch
        test_image = np.zeros((512, 512, 3), dtype=np.uint8)
        
        # numpyë¥¼ tensorë¡œ ë³€í™˜
        input_tensor = torch.from_numpy(test_image).permute(2, 0, 1).unsqueeze(0).float() / 255.0
        
        # SAM ì¶”ë¡  (segment_clothing ë©”ì„œë“œ ì‚¬ìš©) - íƒ€ì„ì•„ì›ƒ ì„¤ì •
        import signal
        
        def timeout_handler(signum, frame):
            raise TimeoutError("SAM ì¶”ë¡ ì´ ë„ˆë¬´ ì˜¤ë˜ ê±¸ë¦½ë‹ˆë‹¤")
        
        signal.signal(signal.SIGALRM, timeout_handler)
        signal.alarm(30)  # 30ì´ˆ íƒ€ì„ì•„ì›ƒ
        
        try:
            with torch.no_grad():
                masks = model.segment_clothing(input_tensor)
                print(f"âœ… SAM ì˜·ê° ì„¸ê·¸ë©˜í…Œì´ì…˜ ì„±ê³µ: {masks.shape}")
        finally:
            signal.alarm(0)  # íƒ€ì„ì•„ì›ƒ í•´ì œ
        
        return True
        
    except Exception as e:
        print(f"âŒ Step 03 í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        return False

def test_step_04_geometric_matching():
    """Step 04: Geometric Matching í…ŒìŠ¤íŠ¸"""
    print("\nğŸ” Step 04: Geometric Matching í…ŒìŠ¤íŠ¸")
    print("=" * 50)
    
    try:
        # GMM ëª¨ë¸ í…ŒìŠ¤íŠ¸
        sys.path.append('step_04_geometric_matching_models/models')
        from geometric_models import GMMModel
        
        model = GMMModel()
        print("âœ… GMM ëª¨ë¸ ì´ˆê¸°í™” ì„±ê³µ")
        
        # ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±
        import numpy as np
        import torch
        person_image = np.zeros((512, 384, 3), dtype=np.uint8)
        cloth_image = np.zeros((512, 384, 3), dtype=np.uint8)
        
        # numpyë¥¼ tensorë¡œ ë³€í™˜
        person_tensor = torch.from_numpy(person_image).permute(2, 0, 1).unsqueeze(0).float() / 255.0
        cloth_tensor = torch.from_numpy(cloth_image).permute(2, 0, 1).unsqueeze(0).float() / 255.0
        
        with torch.no_grad():
            result = model.match_geometrically(person_tensor, cloth_tensor)
            print(f"âœ… GMM ê¸°í•˜í•™ì  ë§¤ì¹­ ì„±ê³µ: {type(result)}")
        
        return True
        
    except Exception as e:
        print(f"âŒ Step 04 í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        return False

def test_step_05_cloth_warping():
    """Step 05: Cloth Warping í…ŒìŠ¤íŠ¸"""
    print("\nğŸ” Step 05: Cloth Warping í…ŒìŠ¤íŠ¸")
    print("=" * 50)
    
    try:
        # RAFT Warping ëª¨ë¸ í…ŒìŠ¤íŠ¸ (ìƒëŒ€ import ë¬¸ì œ ì—†ëŠ” ëª¨ë¸)
        sys.path.append('step_05_cloth_warping_models/models')
        from raft_warping_model import RAFTWarpingModel
        
        model = RAFTWarpingModel()
        print("âœ… RAFT Warping ëª¨ë¸ ì´ˆê¸°í™” ì„±ê³µ")
        
        # ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±
        import numpy as np
        import torch
        cloth_image = np.zeros((512, 384, 3), dtype=np.uint8)
        person_image = np.zeros((512, 384, 3), dtype=np.uint8)
        
        # numpyë¥¼ tensorë¡œ ë³€í™˜
        cloth_tensor = torch.from_numpy(cloth_image).permute(2, 0, 1).unsqueeze(0).float() / 255.0
        person_tensor = torch.from_numpy(person_image).permute(2, 0, 1).unsqueeze(0).float() / 255.0
        
        with torch.no_grad():
            result = model.warp_clothing(person_tensor, cloth_tensor)
            print(f"âœ… RAFT Warping ì„±ê³µ: {result.shape}")
        
        return True
        
    except Exception as e:
        print(f"âŒ Step 05 í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        return False

def test_step_06_virtual_fitting():
    """Step 06: Virtual Fitting í…ŒìŠ¤íŠ¸"""
    print("\nğŸ” Step 06: Virtual Fitting í…ŒìŠ¤íŠ¸")
    print("=" * 50)
    
    try:
        # OOTD ëª¨ë¸ í…ŒìŠ¤íŠ¸
        sys.path.append('step_06_virtual_fitting_models/models')
        from ootd_model import OOTDModel
        
        model = OOTDModel()
        print("âœ… OOTD ëª¨ë¸ ì´ˆê¸°í™” ì„±ê³µ")
        
        # ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±
        import numpy as np
        import torch
        person_image = np.zeros((512, 384, 3), dtype=np.uint8)
        cloth_image = np.zeros((512, 384, 3), dtype=np.uint8)
        
        # numpyë¥¼ tensorë¡œ ë³€í™˜
        person_tensor = torch.from_numpy(person_image).permute(2, 0, 1).unsqueeze(0).float() / 255.0
        cloth_tensor = torch.from_numpy(cloth_image).permute(2, 0, 1).unsqueeze(0).float() / 255.0
        
        with torch.no_grad():
            result = model.virtual_try_on(person_tensor, cloth_tensor)
            print(f"âœ… OOTD ê°€ìƒ í”¼íŒ… ì„±ê³µ: {result.shape}")
        
        return True
        
    except Exception as e:
        print(f"âŒ Step 06 í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        return False

def test_step_07_post_processing():
    """Step 07: Post Processing í…ŒìŠ¤íŠ¸"""
    print("\nğŸ” Step 07: Post Processing í…ŒìŠ¤íŠ¸")
    print("=" * 50)
    
    try:
        # RealESRGAN ëª¨ë¸ í…ŒìŠ¤íŠ¸
        sys.path.append('step_07_post_processing_models/models')
        from realesrgan_model import RRDBNet
        
        model = RRDBNet()
        print("âœ… RealESRGAN ëª¨ë¸ ì´ˆê¸°í™” ì„±ê³µ")
        
        # ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±
        import numpy as np
        import torch
        test_image = np.zeros((512, 512, 3), dtype=np.uint8)
        input_tensor = torch.from_numpy(test_image).permute(2, 0, 1).unsqueeze(0).float() / 255.0
        
        with torch.no_grad():
            enhanced = model(input_tensor)
            print(f"âœ… RealESRGAN í–¥ìƒ ì„±ê³µ: {enhanced.shape}")
        
        return True
        
    except Exception as e:
        print(f"âŒ Step 07 í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        return False

def test_step_08_quality_assessment():
    """Step 08: Quality Assessment í…ŒìŠ¤íŠ¸"""
    print("\nğŸ” Step 08: Quality Assessment í…ŒìŠ¤íŠ¸")
    print("=" * 50)
    
    try:
        # Quality Assessment ëª¨ë¸ í…ŒìŠ¤íŠ¸
        sys.path.append('step_08_quality_assessment_models/models')
        from quality_assessor import QualityAssessorWrapper
        
        model = QualityAssessorWrapper()
        print("âœ… Quality Assessment ëª¨ë¸ ì´ˆê¸°í™” ì„±ê³µ")
        
        # ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±
        import numpy as np
        import torch
        test_image = np.zeros((512, 512, 3), dtype=np.uint8)
        input_tensor = torch.from_numpy(test_image).permute(2, 0, 1).unsqueeze(0).float() / 255.0
        
        with torch.no_grad():
            quality_score = model.assess_quality(input_tensor)
            print(f"âœ… Quality Assessment ì„±ê³µ: {type(quality_score)}")
        
        return True
        
    except Exception as e:
        print(f"âŒ Step 08 í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        return False

def test_step_09_final_output():
    """Step 09: Final Output í…ŒìŠ¤íŠ¸"""
    print("\nğŸ” Step 09: Final Output í…ŒìŠ¤íŠ¸")
    print("=" * 50)
    
    try:
        # Final Output Generator ëª¨ë¸ í…ŒìŠ¤íŠ¸
        sys.path.append('step_09_final_output_models/models')
        from final_output_models import FinalOutputModel
        
        model = FinalOutputModel()
        print("âœ… Final Output Generator ëª¨ë¸ ì´ˆê¸°í™” ì„±ê³µ")
        
        # ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±
        import numpy as np
        import torch
        test_image = np.zeros((512, 512, 3), dtype=np.uint8)
        input_tensor = torch.from_numpy(test_image).permute(2, 0, 1).unsqueeze(0).float() / 255.0
        
        # ë”ë¯¸ í…ìŠ¤íŠ¸ ì…ë ¥ ìƒì„±
        dummy_text = torch.zeros(1, 768)  # ê°„ë‹¨í•œ í…ìŠ¤íŠ¸ ì„ë² ë”©
        
        with torch.no_grad():
            output = model.generate_output(input_tensor, dummy_text)
            print(f"âœ… Final Output Generator ì„±ê³µ: {type(output)}")
        
        return True
        
    except Exception as e:
        print(f"âŒ Step 09 í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        return False

def main():
    """ë©”ì¸ í…ŒìŠ¤íŠ¸ í•¨ìˆ˜"""
    print("ğŸ”¥ MyCloset AI - ì „ì²´ íŒŒì´í”„ë¼ì¸ ê°„ë‹¨í•œ í†µí•© í…ŒìŠ¤íŠ¸")
    print("=" * 70)
    
    # PyTorch import
    try:
        import torch
        print(f"âœ… PyTorch ë²„ì „: {torch.__version__}")
    except ImportError:
        print("âŒ PyTorch import ì‹¤íŒ¨")
        return
    
    # ê° Step í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    test_results = {}
    
    test_results['step_01'] = test_step_01_human_parsing()
    test_results['step_02'] = test_step_02_pose_estimation()
    test_results['step_03'] = test_step_03_cloth_segmentation()
    test_results['step_04'] = test_step_04_geometric_matching()
    test_results['step_05'] = test_step_05_cloth_warping()
    test_results['step_06'] = test_step_06_virtual_fitting()
    test_results['step_07'] = test_step_07_post_processing()
    test_results['step_08'] = test_step_08_quality_assessment()
    test_results['step_09'] = test_step_09_final_output()
    
    # ê²°ê³¼ ìš”ì•½
    print("\n" + "=" * 70)
    print("ğŸ¯ ì „ì²´ íŒŒì´í”„ë¼ì¸ í†µí•© í…ŒìŠ¤íŠ¸ ê²°ê³¼")
    print("=" * 70)
    
    success_count = 0
    for step, result in test_results.items():
        status = "âœ… ì„±ê³µ" if result else "âŒ ì‹¤íŒ¨"
        print(f"{step:15}: {status}")
        if result:
            success_count += 1
    
    print(f"\nğŸ“Š ìµœì¢… ê²°ê³¼: {success_count}/9 ì„±ê³µ")
    
    if success_count == 9:
        print("ğŸ‰ ëª¨ë“  Stepsê°€ ì •ìƒì ìœ¼ë¡œ ì‘ë™í•©ë‹ˆë‹¤!")
    elif success_count >= 6:
        print("ğŸ‘ ëŒ€ë¶€ë¶„ì˜ Stepsê°€ ì •ìƒì ìœ¼ë¡œ ì‘ë™í•©ë‹ˆë‹¤.")
    else:
        print("âš ï¸ ì¼ë¶€ Stepsì— ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤.")
    
    print(f"\nğŸš€ MyCloset AI íŒŒì´í”„ë¼ì¸ ì¤€ë¹„ ìƒíƒœ: {success_count/9*100:.1f}%")

if __name__ == "__main__":
    main()
