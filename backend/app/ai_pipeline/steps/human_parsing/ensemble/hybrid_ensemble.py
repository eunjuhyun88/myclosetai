"""
ğŸ”¥ Hybrid Ensemble ëª¨ë“ˆ
======================

í•˜ì´ë¸Œë¦¬ë“œ ì•™ìƒë¸” ì‹œìŠ¤í…œ êµ¬í˜„

Author: MyCloset AI Team
Date: 2025-08-07
Version: 1.0
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
from typing import Dict, Any, List


class HybridEnsembleModule(nn.Module):
    """í•˜ì´ë¸Œë¦¬ë“œ ì•™ìƒë¸” ëª¨ë“ˆ (ë‹¤ì¤‘ ëª¨ë¸ ê²°í•©)"""
    
    def __init__(self, num_classes=20, num_models=3, hidden_dim=256):
        super().__init__()
        self.num_classes = num_classes
        self.num_models = num_models
        self.hidden_dim = hidden_dim
        
        # MPS ë””ë°”ì´ìŠ¤ ê°ì§€ ë° íƒ€ì… ì„¤ì •
        self.device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')
        self.dtype = torch.float32  # MPSì—ì„œëŠ” float32 ì‚¬ìš©
        
        # ì•™ìƒë¸” ê°€ì¤‘ì¹˜ í•™ìŠµ ë„¤íŠ¸ì›Œí¬ (MPS íƒ€ì… ì¼ê´€ì„±)
        self.weight_learner = nn.Sequential(
            nn.Conv2d(num_classes * num_models, hidden_dim, 3, padding=1),
            nn.BatchNorm2d(hidden_dim),
            nn.ReLU(inplace=True),
            nn.Conv2d(hidden_dim, hidden_dim // 2, 3, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv2d(hidden_dim // 2, num_models, 1),
            nn.Softmax(dim=1)
        ).to(device=self.device, dtype=self.dtype)
        
        # Confidence ê¸°ë°˜ ê°€ì¤‘ì¹˜ ì¡°ì • (MPS íƒ€ì… ì¼ê´€ì„±)
        self.confidence_adapter = nn.Sequential(
            nn.Conv2d(num_models, hidden_dim // 4, 3, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv2d(hidden_dim // 4, num_models, 1),
            nn.Sigmoid()
        ).to(device=self.device, dtype=self.dtype)
        
        # ê³µê°„ì  ì¼ê´€ì„± ê²€ì‚¬ (MPS íƒ€ì… ì¼ê´€ì„±)
        self.spatial_consistency = nn.Sequential(
            nn.Conv2d(num_classes * num_models, hidden_dim // 2, 3, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv2d(hidden_dim // 2, num_models, 1),
            nn.Sigmoid()
        ).to(device=self.device, dtype=self.dtype)
        
        # ìµœì¢… ìœµí•© ë„¤íŠ¸ì›Œí¬ (MPS íƒ€ì… ì¼ê´€ì„±)
        self.final_fusion = nn.Sequential(
            nn.Conv2d(num_classes * num_models, hidden_dim, 3, padding=1),
            nn.BatchNorm2d(hidden_dim),
            nn.ReLU(inplace=True),
            nn.Conv2d(hidden_dim, hidden_dim // 2, 3, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv2d(hidden_dim // 2, num_classes, 1)
        ).to(device=self.device, dtype=self.dtype)
        
        # ë¶ˆí™•ì‹¤ì„± ì •ëŸ‰í™” (MPS íƒ€ì… ì¼ê´€ì„±)
        self.uncertainty_estimator = nn.Sequential(
            nn.Conv2d(num_classes * num_models, hidden_dim // 2, 3, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv2d(hidden_dim // 2, 1, 1),
            nn.Sigmoid()
        ).to(device=self.device, dtype=self.dtype)
    
    def forward(self, model_outputs, confidences):
        """
        í•˜ì´ë¸Œë¦¬ë“œ ì•™ìƒë¸” ìˆœì „íŒŒ (MPS íƒ€ì… ì¼ê´€ì„± ìœ ì§€)
        
        Args:
            model_outputs: ëª¨ë¸ ì¶œë ¥ ë¦¬ìŠ¤íŠ¸ (ê°ê° B, num_classes, H, W)
            confidences: ì‹ ë¢°ë„ ë§µ ë¦¬ìŠ¤íŠ¸ (ê°ê° B, 1, H, W)
        
        Returns:
            ensemble_result: ì•™ìƒë¸” ê²°ê³¼
        """
        # MPS íƒ€ì… ì¼ê´€ì„± ìœ ì§€
        unified_outputs = []
        for output in model_outputs:
            if hasattr(output, 'to'):
                output = output.to(device=self.device, dtype=self.dtype)
            unified_outputs.append(output)
        
        unified_confidences = []
        for conf in confidences:
            if hasattr(conf, 'to'):
                conf = conf.to(device=self.device, dtype=self.dtype)
            unified_confidences.append(conf)
        
        batch_size, _, height, width = unified_outputs[0].shape
        
        # 1. ëª¨ë“  ëª¨ë¸ ì¶œë ¥ì„ ì±„ë„ ì°¨ì›ìœ¼ë¡œ ê²°í•©
        concatenated_outputs = torch.cat(unified_outputs, dim=1)
        
        # 2. í•™ìŠµëœ ê°€ì¤‘ì¹˜ ê³„ì‚°
        learned_weights = self.weight_learner(concatenated_outputs)
        
        # 3. ì‹ ë¢°ë„ ê¸°ë°˜ ê°€ì¤‘ì¹˜ ì¡°ì •
        confidence_tensor = torch.cat(unified_confidences, dim=1)
        confidence_adjusted_weights = self.confidence_adapter(confidence_tensor)
        
        # 4. ê³µê°„ì  ì¼ê´€ì„± ê²€ì‚¬
        spatial_weights = self.spatial_consistency(concatenated_outputs)
        
        # 5. ìµœì¢… ê°€ì¤‘ì¹˜ ê³„ì‚° (ì„¸ ê°€ì§€ ê°€ì¤‘ì¹˜ì˜ ì¡°í•©)
        final_weights = (learned_weights + confidence_adjusted_weights + spatial_weights) / 3.0
        
        # 6. ê°€ì¤‘ í‰ê·  ì•™ìƒë¸”
        weighted_outputs = []
        for i, output in enumerate(model_outputs):
            weight = final_weights[:, i:i+1, :, :]
            weighted_outputs.append(output * weight)
        
        ensemble_output = sum(weighted_outputs)
        
        # 7. ìµœì¢… ìœµí•© ë„¤íŠ¸ì›Œí¬ ì ìš©
        final_ensemble = self.final_fusion(concatenated_outputs)
        
        # 8. ë¶ˆí™•ì‹¤ì„± ì •ëŸ‰í™”
        uncertainty = self.uncertainty_estimator(concatenated_outputs)
        
        # 9. ê²°ê³¼ ì¡°í•© (ê°€ì¤‘ í‰ê·  + ìœµí•© ë„¤íŠ¸ì›Œí¬)
        final_output = ensemble_output + final_ensemble
        
        return {
            'ensemble_output': final_output,
            'weighted_ensemble': ensemble_output,
            'fused_ensemble': final_ensemble,
            'ensemble_weights': final_weights,
            'uncertainty': uncertainty,
            'model_confidences': confidences,
            'spatial_consistency': spatial_weights
        }
