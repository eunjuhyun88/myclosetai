"""
ğŸ”¥ Processing Utils
==================

ì´ë¯¸ì§€ ì²˜ë¦¬ ë° ìœ í‹¸ë¦¬í‹° ë©”ì„œë“œë“¤

Author: MyCloset AI Team
Date: 2025-08-07
Version: 1.0
"""

import torch
import torch.nn.functional as F
import numpy as np
import cv2
from typing import Dict, Any, Optional, Tuple, List
import logging


class ProcessingUtils:
    """ì´ë¯¸ì§€ ì²˜ë¦¬ ìœ í‹¸ë¦¬í‹° í´ë˜ìŠ¤"""
    
    def __init__(self, device: str = 'cpu'):
        self.device = device
        self.logger = logging.getLogger(__name__)
    
    def preprocess_image(self, image, device: str = None, mode: str = 'advanced'):
        """ì´ë¯¸ì§€ ì „ì²˜ë¦¬"""
        try:
            if device is None:
                device = self.device
            
            # NumPy ë°°ì—´ë¡œ ë³€í™˜
            if hasattr(image, 'convert'):  # PIL Image
                image_np = np.array(image.convert('RGB'))
            elif hasattr(image, 'shape'):  # NumPy ë°°ì—´
                image_np = image
            else:
                raise ValueError("ì§€ì›í•˜ì§€ ì•ŠëŠ” ì´ë¯¸ì§€ íƒ€ì…")
            
            # ì´ë¯¸ì§€ ì •ê·œí™”
            if image_np.dtype != np.float32:
                image_np = image_np.astype(np.float32) / 255.0
            
            # í…ì„œë¡œ ë³€í™˜
            if len(image_np.shape) == 3:
                image_tensor = torch.from_numpy(image_np).permute(2, 0, 1).unsqueeze(0)
            else:
                image_tensor = torch.from_numpy(image_np).unsqueeze(0).unsqueeze(0)
            
            # ë””ë°”ì´ìŠ¤ë¡œ ì´ë™
            image_tensor = image_tensor.to(device)
            
            # ê³ ê¸‰ ì „ì²˜ë¦¬
            if mode == 'advanced':
                image_tensor = self._apply_advanced_preprocessing(image_tensor)
            
            return image_tensor
            
        except Exception as e:
            self.logger.error(f"âŒ ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            # ê¸°ë³¸ ì „ì²˜ë¦¬
            return self._create_default_tensor(device)
    
    def _apply_advanced_preprocessing(self, image_tensor):
        """ê³ ê¸‰ ì „ì²˜ë¦¬ ì ìš©"""
        try:
            # ì •ê·œí™”
            mean = torch.tensor([0.485, 0.456, 0.406]).view(1, 3, 1, 1).to(image_tensor.device)
            std = torch.tensor([0.229, 0.224, 0.225]).view(1, 3, 1, 1).to(image_tensor.device)
            
            image_tensor = (image_tensor - mean) / std
            
            return image_tensor
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ ê³ ê¸‰ ì „ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return image_tensor
    
    def _create_default_tensor(self, device):
        """ê¸°ë³¸ í…ì„œ ìƒì„±"""
        return torch.randn(1, 3, 512, 512).to(device)
    
    def postprocess_result(self, inference_result: Dict[str, Any], original_image, model_type: str = 'graphonomy') -> Dict[str, Any]:
        """ì¶”ë¡  ê²°ê³¼ í›„ì²˜ë¦¬"""
        try:
            # íŒŒì‹± ë§µ ì¶”ì¶œ
            parsing_pred = inference_result.get('parsing_pred')
            if parsing_pred is None:
                self.logger.warning("âš ï¸ íŒŒì‹± ì˜ˆì¸¡ ê²°ê³¼ê°€ ì—†ìŒ")
                return self._create_fallback_result()
            
            # í…ì„œë¥¼ NumPyë¡œ ë³€í™˜
            if isinstance(parsing_pred, torch.Tensor):
                parsing_map = parsing_pred.detach().cpu().numpy()
            else:
                parsing_map = np.array(parsing_pred)
            
            # ì°¨ì› ì •ë¦¬
            if len(parsing_map.shape) == 4:  # [B, C, H, W] -> [H, W]
                parsing_map = parsing_map[0]  # ë°°ì¹˜ ì°¨ì› ì œê±°
                if parsing_map.shape[0] > 1:  # ì±„ë„ì´ ì—¬ëŸ¬ ê°œì¸ ê²½ìš°
                    parsing_map = np.argmax(parsing_map, axis=0)  # ìµœëŒ€ê°’ ì¸ë±ìŠ¤
            elif len(parsing_map.shape) == 3:  # [B, H, W] -> [H, W]
                parsing_map = parsing_map[0]
            
            # ì‹ ë¢°ë„ ê³„ì‚°
            confidence = inference_result.get('confidence', 0.8)
            
            # í’ˆì§ˆ ë©”íŠ¸ë¦­ ê³„ì‚°
            quality_metrics = self._calculate_quality_metrics(parsing_map)
            
            return {
                'parsing_map': parsing_map,
                'confidence': confidence,
                'quality_metrics': quality_metrics,
                'model_type': model_type
            }
            
        except Exception as e:
            self.logger.error(f"âŒ í›„ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return self._create_fallback_result()
    
    def _create_fallback_result(self):
        """í´ë°± ê²°ê³¼ ìƒì„±"""
        return {
            'parsing_map': np.zeros((512, 512), dtype=np.uint8),
            'confidence': 0.5,
            'quality_metrics': {'overall_quality': 0.5},
            'model_type': 'fallback'
        }
    
    def _calculate_quality_metrics(self, parsing_map: np.ndarray) -> Dict[str, float]:
        """í’ˆì§ˆ ë©”íŠ¸ë¦­ ê³„ì‚°"""
        try:
            # ê¸°ë³¸ í’ˆì§ˆ ë©”íŠ¸ë¦­
            unique_labels = len(np.unique(parsing_map))
            mean_intensity = np.mean(parsing_map)
            std_intensity = np.std(parsing_map)
            
            # ì „ì²´ í’ˆì§ˆ ì ìˆ˜
            overall_quality = min(1.0, (unique_labels / 20.0) * 0.5 + (mean_intensity / 255.0) * 0.3 + (std_intensity / 50.0) * 0.2)
            
            return {
                'overall_quality': overall_quality,
                'unique_labels': unique_labels,
                'mean_intensity': mean_intensity,
                'std_intensity': std_intensity
            }
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ í’ˆì§ˆ ë©”íŠ¸ë¦­ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return {'overall_quality': 0.5}
    
    def standardize_channels(self, tensor: torch.Tensor, target_channels: int = 20) -> torch.Tensor:
        """ì±„ë„ ìˆ˜ í‘œì¤€í™” (ê·¼ë³¸ì  í•´ê²°)"""
        try:
            # ğŸ”¥ ì…ë ¥ ê²€ì¦
            if tensor is None:
                self.logger.warning("âš ï¸ í…ì„œê°€ Noneì…ë‹ˆë‹¤.")
                return torch.zeros((1, target_channels, 512, 512), device='cpu', dtype=torch.float32)
            
            # ğŸ”¥ ì°¨ì› ê²€ì¦
            if len(tensor.shape) != 4:
                self.logger.warning(f"âš ï¸ í…ì„œ ì°¨ì›ì´ 4ê°€ ì•„ë‹˜: {tensor.shape}")
                if len(tensor.shape) == 3:
                    # ë°°ì¹˜ ì°¨ì› ì¶”ê°€
                    tensor = tensor.unsqueeze(0)
                elif len(tensor.shape) == 2:
                    # ë°°ì¹˜ì™€ ì±„ë„ ì°¨ì› ì¶”ê°€
                    tensor = tensor.unsqueeze(0).unsqueeze(0)
                else:
                    return torch.zeros((1, target_channels, 512, 512), device=tensor.device, dtype=tensor.dtype)
            
            # ğŸ”¥ ì±„ë„ ìˆ˜ í‘œì¤€í™”
            if tensor.shape[1] == target_channels:
                return tensor
            elif tensor.shape[1] > target_channels:
                # ğŸ”¥ ì±„ë„ ìˆ˜ê°€ ë§ìœ¼ë©´ ì•ìª½ ì±„ë„ë§Œ ì‚¬ìš©
                return tensor[:, :target_channels, :, :]
            else:
                # ğŸ”¥ ì±„ë„ ìˆ˜ê°€ ì ìœ¼ë©´ íŒ¨ë”©
                padding = torch.zeros(
                    tensor.shape[0], 
                    target_channels - tensor.shape[1], 
                    tensor.shape[2], 
                    tensor.shape[3],
                    device=tensor.device,
                    dtype=tensor.dtype
                )
                return torch.cat([tensor, padding], dim=1)
        except Exception as e:
            self.logger.warning(f"âš ï¸ ì±„ë„ ìˆ˜ í‘œì¤€í™” ì‹¤íŒ¨: {e}")
            # ê¸°ë³¸ê°’ ë°˜í™˜
            return torch.zeros((1, target_channels, 512, 512), device='cpu', dtype=torch.float32)
    
    def calculate_ensemble_uncertainty(self, ensemble_results: Dict[str, torch.Tensor]) -> float:
        """ì•™ìƒë¸” ë¶ˆí™•ì‹¤ì„± ê³„ì‚°"""
        try:
            if not ensemble_results:
                return 0.5
            
            # ğŸ”¥ 1. ê° ëª¨ë¸ì˜ ì˜ˆì¸¡ì„ í…ì„œë¡œ ë³€í™˜
            predictions = []
            for model_name, result in ensemble_results.items():
                try:
                    if isinstance(result, torch.Tensor):
                        pred = result
                    elif isinstance(result, dict):
                        pred = result.get('parsing_pred', result.get('output', None))
                    else:
                        continue
                    
                    if pred is not None and pred.dim() == 4:
                        # ì†Œí”„íŠ¸ë§¥ìŠ¤ ì ìš©
                        pred_probs = F.softmax(pred, dim=1)
                        predictions.append(pred_probs)
                        
                except Exception as e:
                    self.logger.warning(f"âš ï¸ {model_name} ì˜ˆì¸¡ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                    continue
            
            if len(predictions) < 2:
                return 0.5
            
            # ğŸ”¥ 2. ì˜ˆì¸¡ í‰ê·  ê³„ì‚°
            mean_prediction = torch.stack(predictions).mean(dim=0)
            
            # ğŸ”¥ 3. ë¶„ì‚° ê³„ì‚° (ë¶ˆí™•ì‹¤ì„± ì¸¡ì •)
            variance = torch.stack(predictions).var(dim=0)
            
            # ğŸ”¥ 4. í‰ê·  ë¶„ì‚°ì„ ë¶ˆí™•ì‹¤ì„±ìœ¼ë¡œ ì‚¬ìš©
            uncertainty = torch.mean(variance).item()
            
            # ğŸ”¥ 5. ì •ê·œí™” (0~1 ë²”ìœ„)
            uncertainty = min(1.0, uncertainty * 10.0)  # ìŠ¤ì¼€ì¼ë§
            
            return uncertainty
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ ì•™ìƒë¸” ë¶ˆí™•ì‹¤ì„± ê³„ì‚° ì‹¤íŒ¨: {e}")
            return 0.5
    
    def calibrate_ensemble_confidence(self, model_confidences: Dict[str, float], uncertainty: float) -> float:
        """ì•™ìƒë¸” ì‹ ë¢°ë„ ë³´ì •"""
        if not model_confidences:
            return 0.0
        
        # ê¸°ë³¸ ì‹ ë¢°ë„ (ê°€ì¤‘ í‰ê· ) - ì‹œí€€ìŠ¤ ì˜¤ë¥˜ ë°©ì§€
        try:
            # ê°’ë“¤ì´ ìˆ«ìì¸ì§€ í™•ì¸í•˜ê³  ë³€í™˜
            confidence_values = []
            for key, value in model_confidences.items():
                try:
                    if isinstance(value, (list, tuple)):
                        # ì‹œí€€ìŠ¤ì¸ ê²½ìš° ì²« ë²ˆì§¸ ê°’ ì‚¬ìš©
                        if value:
                            confidence_values.append(float(value[0]))
                        else:
                            confidence_values.append(0.5)
                    elif isinstance(value, (int, float)):
                        confidence_values.append(float(value))
                    elif isinstance(value, np.ndarray):
                        # numpy ë°°ì—´ì¸ ê²½ìš° ì²« ë²ˆì§¸ ê°’ ì‚¬ìš©
                        confidence_values.append(float(value.flatten()[0]))
                    else:
                        # ê¸°íƒ€ íƒ€ì…ì€ 0.5ë¡œ ì„¤ì •
                        confidence_values.append(0.5)
                except Exception as e:
                    self.logger.warning(f"âš ï¸ ì‹ ë¢°ë„ ê°’ ë³€í™˜ ì‹¤íŒ¨ ({key}): {e}")
                    confidence_values.append(0.5)
            
            if not confidence_values:
                return 0.5
            
            weights = np.array(confidence_values)
            base_confidence = np.average(weights, weights=weights)
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ ì‹ ë¢°ë„ ë³´ì • ì‹¤íŒ¨: {e}")
            # í´ë°±: ë‹¨ìˆœ í‰ê· 
            base_confidence = 0.8
        
        # ë¶ˆí™•ì‹¤ì„±ì— ë”°ë¥¸ ë³´ì •
        uncertainty_penalty = uncertainty * 0.5  # ë¶ˆí™•ì‹¤ì„± í˜ë„í‹°
        calibrated_confidence = max(0.0, min(1.0, base_confidence - uncertainty_penalty))
        
        return calibrated_confidence
    
    def memory_efficient_resize(self, image, target_size):
        """ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì¸ ë¦¬ì‚¬ì´ì¦ˆ"""
        try:
            if isinstance(image, torch.Tensor):
                # í…ì„œ ë¦¬ì‚¬ì´ì¦ˆ
                return F.interpolate(image.unsqueeze(0), size=target_size, mode='bilinear', align_corners=False).squeeze(0)
            elif isinstance(image, np.ndarray):
                # NumPy ë°°ì—´ ë¦¬ì‚¬ì´ì¦ˆ
                return cv2.resize(image, target_size, interpolation=cv2.INTER_LINEAR)
            else:
                return image
        except Exception as e:
            self.logger.warning(f"âš ï¸ ë¦¬ì‚¬ì´ì¦ˆ ì‹¤íŒ¨: {e}")
            return image
    
    def normalize_lighting(self, image):
        """ì¡°ëª… ì •ê·œí™”"""
        try:
            if isinstance(image, np.ndarray):
                # íˆìŠ¤í† ê·¸ë¨ í‰í™œí™”
                if len(image.shape) == 3:
                    # ì»¬ëŸ¬ ì´ë¯¸ì§€
                    lab = cv2.cvtColor(image, cv2.COLOR_RGB2LAB)
                    lab[:, :, 0] = cv2.equalizeHist(lab[:, :, 0])
                    return cv2.cvtColor(lab, cv2.COLOR_LAB2RGB)
                else:
                    # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ì´ë¯¸ì§€
                    return cv2.equalizeHist(image)
            else:
                return image
        except Exception as e:
            self.logger.warning(f"âš ï¸ ì¡°ëª… ì •ê·œí™” ì‹¤íŒ¨: {e}")
            return image
    
    def correct_colors(self, image):
        """ìƒ‰ìƒ ë³´ì •"""
        try:
            if isinstance(image, np.ndarray) and len(image.shape) == 3:
                # ìƒ‰ìƒ ë³´ì • (ê°„ë‹¨í•œ ê°ë§ˆ ë³´ì •)
                gamma = 1.1
                inv_gamma = 1.0 / gamma
                table = np.array([((i / 255.0) ** inv_gamma) * 255 for i in np.arange(0, 256)]).astype("uint8")
                return cv2.LUT(image, table)
            else:
                return image
        except Exception as e:
            self.logger.warning(f"âš ï¸ ìƒ‰ìƒ ë³´ì • ì‹¤íŒ¨: {e}")
            return image
