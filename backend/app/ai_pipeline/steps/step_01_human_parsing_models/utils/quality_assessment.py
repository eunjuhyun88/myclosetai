"""
ğŸ”¥ Human Parsing í’ˆì§ˆ í‰ê°€ ì‹œìŠ¤í…œ
================================

Human Parsing ê²°ê³¼ì˜ í’ˆì§ˆì„ í‰ê°€í•˜ê³  ê°œì„  ë°©í–¥ì„ ì œì‹œ

Author: MyCloset AI Team
Date: 2025-08-15
Version: 1.0
"""

import logging
import torch
import numpy as np
from typing import Dict, Any, List, Tuple
import cv2
from scipy import ndimage

logger = logging.getLogger(__name__)

class HumanParsingQualityAssessment:
    """Human Parsing í’ˆì§ˆ í‰ê°€ ë° ê°œì„  ì‹œìŠ¤í…œ"""
    
    def __init__(self):
        self.logger = logging.getLogger(f"{__name__}.QualityAssessment")
        self.quality_metrics = {
            'boundary_consistency': 0.0,
            'semantic_coherence': 0.0,
            'spatial_continuity': 0.0,
            'confidence_reliability': 0.0,
            'overall_quality': 0.0
        }
    
    def assess_quality(self, parsing_result: Dict[str, Any]) -> Dict[str, Any]:
        """
        Human Parsing ê²°ê³¼ì˜ í’ˆì§ˆì„ ì¢…í•©ì ìœ¼ë¡œ í‰ê°€
        
        Args:
            parsing_result: íŒŒì‹± ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
            
        Returns:
            quality_report: í’ˆì§ˆ í‰ê°€ ë¦¬í¬íŠ¸
        """
        try:
            self.logger.info("ğŸ” Human Parsing í’ˆì§ˆ í‰ê°€ ì‹œì‘")
            
            # ê¸°ë³¸ í’ˆì§ˆ ë©”íŠ¸ë¦­ ê³„ì‚°
            quality_scores = self._calculate_quality_metrics(parsing_result)
            
            # ê°œì„  ì œì•ˆ ìƒì„±
            improvement_suggestions = self._generate_improvement_suggestions(quality_scores)
            
            # ìµœì¢… í’ˆì§ˆ ë¦¬í¬íŠ¸ ìƒì„±
            quality_report = {
                'quality_scores': quality_scores,
                'improvement_suggestions': improvement_suggestions,
                'overall_quality': quality_scores['overall_quality'],
                'quality_level': self._get_quality_level(quality_scores['overall_quality']),
                'assessment_timestamp': str(np.datetime64('now'))
            }
            
            self.logger.info(f"âœ… í’ˆì§ˆ í‰ê°€ ì™„ë£Œ - ì „ì²´ í’ˆì§ˆ: {quality_scores['overall_quality']:.3f}")
            return quality_report
            
        except Exception as e:
            self.logger.error(f"âŒ í’ˆì§ˆ í‰ê°€ ì‹¤íŒ¨: {e}")
            return {
                'quality_scores': self.quality_metrics,
                'error': str(e),
                'overall_quality': 0.0
            }
    
    def _calculate_quality_metrics(self, parsing_result: Dict[str, Any]) -> Dict[str, float]:
        """í’ˆì§ˆ ë©”íŠ¸ë¦­ ê³„ì‚°"""
        try:
            # ê²½ê³„ ì¼ê´€ì„± í‰ê°€
            boundary_consistency = self._assess_boundary_consistency(parsing_result)
            
            # ì˜ë¯¸ì  ì¼ê´€ì„± í‰ê°€
            semantic_coherence = self._assess_semantic_coherence(parsing_result)
            
            # ê³µê°„ì  ì—°ì†ì„± í‰ê°€
            spatial_continuity = self._assess_spatial_continuity(parsing_result)
            
            # ì‹ ë¢°ë„ í‰ê°€
            confidence_reliability = self._assess_confidence_reliability(parsing_result)
            
            # ì „ì²´ í’ˆì§ˆ ì ìˆ˜ ê³„ì‚° (ê°€ì¤‘ í‰ê· )
            overall_quality = (
                boundary_consistency * 0.3 +
                semantic_coherence * 0.3 +
                spatial_continuity * 0.2 +
                confidence_reliability * 0.2
            )
            
            return {
                'boundary_consistency': boundary_consistency,
                'semantic_coherence': semantic_coherence,
                'spatial_continuity': spatial_continuity,
                'confidence_reliability': confidence_reliability,
                'overall_quality': overall_quality
            }
            
        except Exception as e:
            self.logger.warning(f"í’ˆì§ˆ ë©”íŠ¸ë¦­ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return self.quality_metrics
    
    def _assess_boundary_consistency(self, parsing_result: Dict[str, Any]) -> float:
        """ê²½ê³„ ì¼ê´€ì„± í‰ê°€"""
        try:
            if 'parsing_map' not in parsing_result:
                return 0.5
            
            parsing_map = parsing_result['parsing_map']
            
            # í…ì„œë¥¼ numpyë¡œ ë³€í™˜
            if torch.is_tensor(parsing_map):
                parsing_map = parsing_map.detach().cpu().numpy()
            
            # ê²½ê³„ ê²€ì¶œ
            boundaries = self._extract_boundaries(parsing_map)
            
            # ê²½ê³„ì˜ ì¼ê´€ì„± í‰ê°€
            boundary_consistency = self._calculate_boundary_consistency(boundaries)
            
            return min(1.0, max(0.0, boundary_consistency))
            
        except Exception as e:
            self.logger.warning(f"ê²½ê³„ ì¼ê´€ì„± í‰ê°€ ì‹¤íŒ¨: {e}")
            return 0.5
    
    def _assess_semantic_coherence(self, parsing_result: Dict[str, Any]) -> float:
        """ì˜ë¯¸ì  ì¼ê´€ì„± í‰ê°€"""
        try:
            if 'parsing_map' not in parsing_result:
                return 0.5
            
            parsing_map = parsing_result['parsing_map']
            
            # í…ì„œë¥¼ numpyë¡œ ë³€í™˜
            if torch.is_tensor(parsing_map):
                parsing_map = parsing_map.detach().cpu().numpy()
            
            # ì˜ë¯¸ì  ì¼ê´€ì„± ê³„ì‚°
            semantic_coherence = self._calculate_semantic_coherence(parsing_map)
            
            return min(1.0, max(0.0, semantic_coherence))
            
        except Exception as e:
            self.logger.warning(f"ì˜ë¯¸ì  ì¼ê´€ì„± í‰ê°€ ì‹¤íŒ¨: {e}")
            return 0.5
    
    def _assess_spatial_continuity(self, parsing_result: Dict[str, Any]) -> float:
        """ê³µê°„ì  ì—°ì†ì„± í‰ê°€"""
        try:
            if 'parsing_map' not in parsing_result:
                return 0.5
            
            parsing_map = parsing_result['parsing_map']
            
            # í…ì„œë¥¼ numpyë¡œ ë³€í™˜
            if torch.is_tensor(parsing_map):
                parsing_map = parsing_map.detach().cpu().numpy()
            
            # ê³µê°„ì  ì—°ì†ì„± ê³„ì‚°
            spatial_continuity = self._calculate_spatial_continuity(parsing_map)
            
            return min(1.0, max(0.0, spatial_continuity))
            
        except Exception as e:
            self.logger.warning(f"ê³µê°„ì  ì—°ì†ì„± í‰ê°€ ì‹¤íŒ¨: {e}")
            return 0.5
    
    def _assess_confidence_reliability(self, parsing_result: Dict[str, Any]) -> float:
        """ì‹ ë¢°ë„ í‰ê°€"""
        try:
            if 'confidence' not in parsing_result:
                return 0.5
            
            confidence = parsing_result['confidence']
            
            # í…ì„œë¥¼ numpyë¡œ ë³€í™˜
            if torch.is_tensor(confidence):
                confidence = confidence.detach().cpu().numpy()
            
            # ì‹ ë¢°ë„ ì‹ ë¢°ì„± ê³„ì‚°
            confidence_reliability = self._calculate_confidence_reliability(confidence)
            
            return min(1.0, max(0.0, confidence_reliability))
            
        except Exception as e:
            self.logger.warning(f"ì‹ ë¢°ë„ í‰ê°€ ì‹¤íŒ¨: {e}")
            return 0.5
    
    def _extract_boundaries(self, parsing_map: np.ndarray) -> np.ndarray:
        """íŒŒì‹± ë§µì—ì„œ ê²½ê³„ ì¶”ì¶œ"""
        try:
            # ê° í´ë˜ìŠ¤ë³„ë¡œ ê²½ê³„ ê²€ì¶œ
            boundaries = np.zeros_like(parsing_map, dtype=np.uint8)
            
            for class_id in np.unique(parsing_map):
                if class_id == 0:  # ë°°ê²½ ì œì™¸
                    continue
                
                class_mask = (parsing_map == class_id).astype(np.uint8)
                class_boundaries = cv2.Canny(class_mask, 50, 150)
                boundaries = np.logical_or(boundaries, class_boundaries)
            
            return boundaries.astype(np.uint8)
            
        except Exception as e:
            self.logger.warning(f"ê²½ê³„ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return np.zeros_like(parsing_map, dtype=np.uint8)
    
    def _calculate_boundary_consistency(self, boundaries: np.ndarray) -> float:
        """ê²½ê³„ ì¼ê´€ì„± ê³„ì‚°"""
        try:
            if boundaries.sum() == 0:
                return 0.5
            
            # ê²½ê³„ì˜ ì—°ì†ì„± ê³„ì‚°
            kernel = np.ones((3, 3), np.uint8)
            dilated = cv2.dilate(boundaries, kernel, iterations=1)
            eroded = cv2.erode(boundaries, kernel, iterations=1)
            
            # ê²½ê³„ì˜ ì¼ê´€ì„± ì ìˆ˜
            consistency_score = np.sum(boundaries) / np.sum(dilated)
            
            return float(consistency_score)
            
        except Exception as e:
            self.logger.warning(f"ê²½ê³„ ì¼ê´€ì„± ê³„ì‚° ì‹¤íŒ¨: {e}")
            return 0.5
    
    def _calculate_semantic_coherence(self, parsing_map: np.ndarray) -> float:
        """ì˜ë¯¸ì  ì¼ê´€ì„± ê³„ì‚°"""
        try:
            # ê° í´ë˜ìŠ¤ì˜ ì—°ê²°ì„± ê³„ì‚°
            coherence_scores = []
            
            for class_id in np.unique(parsing_map):
                if class_id == 0:  # ë°°ê²½ ì œì™¸
                    continue
                
                class_mask = (parsing_map == class_id).astype(np.uint8)
                
                # ì—°ê²°ëœ ì»´í¬ë„ŒíŠ¸ ìˆ˜ ê³„ì‚°
                num_components, _ = cv2.connectedComponents(class_mask)
                
                # ë‹¨ì¼ ì»´í¬ë„ŒíŠ¸ì¼ìˆ˜ë¡ ì¼ê´€ì„± ë†’ìŒ
                if num_components == 1:
                    coherence_scores.append(1.0)
                else:
                    coherence_scores.append(1.0 / num_components)
            
            if not coherence_scores:
                return 0.5
            
            return np.mean(coherence_scores)
            
        except Exception as e:
            self.logger.warning(f"ì˜ë¯¸ì  ì¼ê´€ì„± ê³„ì‚° ì‹¤íŒ¨: {e}")
            return 0.5
    
    def _calculate_spatial_continuity(self, parsing_map: np.ndarray) -> float:
        """ê³µê°„ì  ì—°ì†ì„± ê³„ì‚°"""
        try:
            # ê³µê°„ì  ì—°ì†ì„± ê³„ì‚° (ëª¨í´ë¡œì§€ ì—°ì‚° ì‚¬ìš©)
            kernel = np.ones((5, 5), np.uint8)
            
            continuity_scores = []
            
            for class_id in np.unique(parsing_map):
                if class_id == 0:  # ë°°ê²½ ì œì™¸
                    continue
                
                class_mask = (parsing_map == class_id).astype(np.uint8)
                
                # ëª¨í´ë¡œì§€ ì—°ì‚°ìœ¼ë¡œ ì—°ì†ì„± í‰ê°€
                opened = cv2.morphologyEx(class_mask, cv2.MORPH_OPEN, kernel)
                closed = cv2.morphologyEx(class_mask, cv2.MORPH_CLOSE, kernel)
                
                # ì›ë³¸ê³¼ì˜ ìœ ì‚¬ë„ ê³„ì‚°
                similarity = np.sum(opened == class_mask) / class_mask.size
                continuity_scores.append(similarity)
            
            if not continuity_scores:
                return 0.5
            
            return np.mean(continuity_scores)
            
        except Exception as e:
            self.logger.warning(f"ê³µê°„ì  ì—°ì†ì„± ê³„ì‚° ì‹¤íŒ¨: {e}")
            return 0.5
    
    def _calculate_confidence_reliability(self, confidence: np.ndarray) -> float:
        """ì‹ ë¢°ë„ ì‹ ë¢°ì„± ê³„ì‚°"""
        try:
            if confidence.size == 0:
                return 0.5
            
            # ì‹ ë¢°ë„ ë¶„í¬ì˜ ì¼ê´€ì„± ê³„ì‚°
            confidence_std = np.std(confidence)
            confidence_mean = np.mean(confidence)
            
            # í‘œì¤€í¸ì°¨ê°€ ì‘ì„ìˆ˜ë¡ ì‹ ë¢°ë„ê°€ ì¼ê´€ì 
            if confidence_mean == 0:
                return 0.5
            
            cv_score = confidence_std / confidence_mean  # ë³€ë™ê³„ìˆ˜
            reliability = max(0, 1 - cv_score)
            
            return min(1.0, max(0.0, reliability))
            
        except Exception as e:
            self.logger.warning(f"ì‹ ë¢°ë„ ì‹ ë¢°ì„± ê³„ì‚° ì‹¤íŒ¨: {e}")
            return 0.5
    
    def _generate_improvement_suggestions(self, quality_scores: Dict[str, float]) -> List[str]:
        """í’ˆì§ˆ ê°œì„  ì œì•ˆ ìƒì„±"""
        suggestions = []
        
        if quality_scores['boundary_consistency'] < 0.7:
            suggestions.append("ê²½ê³„ ì¼ê´€ì„± ê°œì„ : ê²½ê³„ ê²€ì¶œ ì•Œê³ ë¦¬ì¦˜ ê°•í™” í•„ìš”")
        
        if quality_scores['semantic_coherence'] < 0.7:
            suggestions.append("ì˜ë¯¸ì  ì¼ê´€ì„± ê°œì„ : í´ë˜ìŠ¤ë³„ ì—°ê²°ì„± ê°•í™” í•„ìš”")
        
        if quality_scores['spatial_continuity'] < 0.7:
            suggestions.append("ê³µê°„ì  ì—°ì†ì„± ê°œì„ : ëª¨í´ë¡œì§€ í›„ì²˜ë¦¬ ê°•í™” í•„ìš”")
        
        if quality_scores['confidence_reliability'] < 0.7:
            suggestions.append("ì‹ ë¢°ë„ ì‹ ë¢°ì„± ê°œì„ : ì‹ ë¢°ë„ ê³„ì‚° ë°©ì‹ ê°œì„  í•„ìš”")
        
        if not suggestions:
            suggestions.append("í˜„ì¬ í’ˆì§ˆì´ ì–‘í˜¸í•©ë‹ˆë‹¤. ì¶”ê°€ ê°œì„ ì´ í•„ìš”í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        
        return suggestions
    
    def _get_quality_level(self, overall_quality: float) -> str:
        """ì „ì²´ í’ˆì§ˆ ìˆ˜ì¤€ íŒì •"""
        if overall_quality >= 0.9:
            return "Excellent"
        elif overall_quality >= 0.8:
            return "Good"
        elif overall_quality >= 0.7:
            return "Fair"
        elif overall_quality >= 0.6:
            return "Poor"
        else:
            return "Very Poor"
