"""
ğŸ”¥ Memory Efficient Ensemble System
==================================

ë©”ëª¨ë¦¬ íš¨ìœ¨ì  ì•™ìƒë¸” ì‹œìŠ¤í…œ

Author: MyCloset AI Team
Date: 2025-08-07
Version: 1.0
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
from typing import Dict, Any, List, Optional


class MemoryEfficientEnsembleSystem(nn.Module):
    """ë©”ëª¨ë¦¬ íš¨ìœ¨ì  ì•™ìƒë¸” ì‹œìŠ¤í…œ"""
    
    def __init__(self, num_classes=20, ensemble_models=None, hidden_dim=None, config=None):
        super().__init__()
        self.num_classes = num_classes
        self.ensemble_models = ensemble_models or []
        self.hidden_dim = hidden_dim or 256
        self.config = config
        
        # MPS ë””ë°”ì´ìŠ¤ ê°ì§€ ë° íƒ€ì… ì„¤ì •
        self.device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')
        self.dtype = torch.float32  # MPSì—ì„œëŠ” float32 ì‚¬ìš©
        
        # ë©”ëª¨ë¦¬ íš¨ìœ¨ì  ì•™ìƒë¸” ë„¤íŠ¸ì›Œí¬ (MPS íƒ€ì… ì¼ê´€ì„±)
        self.ensemble_net = nn.Sequential(
            nn.Conv2d(num_classes * len(self.ensemble_models) if self.ensemble_models else num_classes, 
                     self.hidden_dim, 3, padding=1),
            nn.BatchNorm2d(self.hidden_dim),
            nn.ReLU(inplace=True),
            nn.Conv2d(self.hidden_dim, self.hidden_dim // 2, 3, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv2d(self.hidden_dim // 2, num_classes, 1)
        ).to(device=self.device, dtype=self.dtype)
        
        # ê°€ì¤‘ì¹˜ í•™ìŠµ ë„¤íŠ¸ì›Œí¬ (MPS íƒ€ì… ì¼ê´€ì„±)
        self.weight_learner = nn.Sequential(
            nn.Conv2d(num_classes * len(self.ensemble_models) if self.ensemble_models else num_classes, 
                     self.hidden_dim // 2, 3, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv2d(self.hidden_dim // 2, len(self.ensemble_models) if self.ensemble_models else 1, 1),
            nn.Softmax(dim=1)
        ).to(device=self.device, dtype=self.dtype)
        
        # ë¶ˆí™•ì‹¤ì„± ì •ëŸ‰í™” (MPS íƒ€ì… ì¼ê´€ì„±)
        self.uncertainty_estimator = nn.Sequential(
            nn.Conv2d(num_classes * len(self.ensemble_models) if self.ensemble_models else num_classes, 
                     self.hidden_dim // 4, 3, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv2d(self.hidden_dim // 4, 1, 1),
            nn.Sigmoid()
        ).to(device=self.device, dtype=self.dtype)
        
        # ë©”ëª¨ë¦¬ ìµœì í™” ì„¤ì •
        self.memory_optimization = {
            'gradient_checkpointing': True,
            'mixed_precision': True,
            'tensor_cores': True,
            'memory_efficient_attention': True
        }
        
        self._init_weights()
    
    def _init_weights(self):
        """ê°€ì¤‘ì¹˜ ì´ˆê¸°í™”"""
        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')
                if m.bias is not None:
                    nn.init.constant_(m.bias, 0)
            elif isinstance(m, nn.BatchNorm2d):
                nn.init.constant_(m.weight, 1)
                nn.init.constant_(m.bias, 0)
    
    def _standardize_tensor_sizes(self, tensors, target_size=None):
        """í…ì„œ í¬ê¸° í‘œì¤€í™” (MPS íƒ€ì… ì¼ê´€ì„± ìœ ì§€)"""
        if not tensors:
            return tensors
        
        if target_size is None:
            # ì²« ë²ˆì§¸ í…ì„œì˜ í¬ê¸°ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì„¤ì •
            target_size = tensors[0].shape[2:]
        
        standardized_tensors = []
        for tensor in tensors:
            # MPS íƒ€ì… ì¼ê´€ì„± í™•ì¸
            if hasattr(tensor, 'device') and str(tensor.device).startswith('mps'):
                # MPS ë””ë°”ì´ìŠ¤ì˜ ê²½ìš° float32ë¡œ í†µì¼
                if tensor.dtype != torch.float32:
                    tensor = tensor.to(torch.float32)
            
            if tensor.shape[2:] != target_size:
                # ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì¸ ë¦¬ì‚¬ì´ì§•
                tensor = F.interpolate(
                    tensor, size=target_size, 
                    mode='bilinear', align_corners=False
                )
            standardized_tensors.append(tensor)
        
        return standardized_tensors
    
    def _standardize_channels(self, tensor, target_channels=20):
        """ì±„ë„ ìˆ˜ í‘œì¤€í™” (MPS íƒ€ì… ì¼ê´€ì„± ìœ ì§€)"""
        current_channels = tensor.shape[1]
        
        # MPS íƒ€ì… ì¼ê´€ì„± í™•ì¸
        if hasattr(tensor, 'device') and str(tensor.device).startswith('mps'):
            # MPS ë””ë°”ì´ìŠ¤ì˜ ê²½ìš° float32ë¡œ í†µì¼
            if tensor.dtype != torch.float32:
                tensor = tensor.to(torch.float32)
            target_dtype = torch.float32
        else:
            target_dtype = tensor.dtype
        
        if current_channels == target_channels:
            return tensor
        elif current_channels > target_channels:
            # ì±„ë„ ìˆ˜ ì¤„ì´ê¸°
            return tensor[:, :target_channels, :, :]
        else:
            # ì±„ë„ ìˆ˜ ëŠ˜ë¦¬ê¸° (íŒ¨ë”©)
            padding = torch.zeros(
                tensor.shape[0], target_channels - current_channels,
                tensor.shape[2], tensor.shape[3],
                device=tensor.device, dtype=target_dtype  # ëª…ì‹œì ìœ¼ë¡œ íƒ€ì… ì§€ì •
            )
            return torch.cat([tensor, padding], dim=1)
    
    def forward(self, model_outputs, model_confidences=None):
        """
        ë©”ëª¨ë¦¬ íš¨ìœ¨ì  ì•™ìƒë¸” ìˆœì „íŒŒ
        
        Args:
            model_outputs: ëª¨ë¸ ì¶œë ¥ ë¦¬ìŠ¤íŠ¸
            model_confidences: ëª¨ë¸ ì‹ ë¢°ë„ ë¦¬ìŠ¤íŠ¸ (ì„ íƒì‚¬í•­)
        
        Returns:
            ensemble_result: ì•™ìƒë¸” ê²°ê³¼
        """
        if not model_outputs:
            return None
        
        # 0. MPS íƒ€ì… ì¼ê´€ì„± ìœ ì§€ (ê°•í™”ëœ ë²„ì „)
        # ëª¨ë“  í…ì„œë¥¼ ë™ì¼í•œ ë””ë°”ì´ìŠ¤ì™€ íƒ€ì…ìœ¼ë¡œ í†µì¼
        unified_outputs = []
        for output in model_outputs:
            if hasattr(output, 'to'):
                # ëª¨ë“  í…ì„œë¥¼ MPS ë””ë°”ì´ìŠ¤ì˜ float32ë¡œ í†µì¼
                output = output.to(device=self.device, dtype=self.dtype)
            unified_outputs.append(output)
        
        # 1. í…ì„œ í¬ê¸° í‘œì¤€í™”
        standardized_outputs = self._standardize_tensor_sizes(unified_outputs)
        
        # 2. ì±„ë„ ìˆ˜ í‘œì¤€í™”
        standardized_outputs = [self._standardize_channels(output, self.num_classes) 
                              for output in standardized_outputs]
        
        # 3. ëª¨ë“  ì¶œë ¥ì„ ì±„ë„ ì°¨ì›ìœ¼ë¡œ ê²°í•©
        concatenated_outputs = torch.cat(standardized_outputs, dim=1)
        
        # 4. ë©”ëª¨ë¦¬ íš¨ìœ¨ì  ì•™ìƒë¸” ì ìš©
        if self.memory_optimization['gradient_checkpointing']:
            # ê·¸ë˜ë””ì–¸íŠ¸ ì²´í¬í¬ì¸íŒ…ìœ¼ë¡œ ë©”ëª¨ë¦¬ ì ˆì•½
            ensemble_output = torch.utils.checkpoint.checkpoint(
                self.ensemble_net, concatenated_outputs
            )
        else:
            ensemble_output = self.ensemble_net(concatenated_outputs)
        
        # 5. ê°€ì¤‘ì¹˜ í•™ìŠµ
        learned_weights = self.weight_learner(concatenated_outputs)
        
        # 6. ë¶ˆí™•ì‹¤ì„± ì •ëŸ‰í™”
        uncertainty = self.uncertainty_estimator(concatenated_outputs)
        
        # 7. ê°€ì¤‘ í‰ê·  ì•™ìƒë¸” (ë©”ëª¨ë¦¬ íš¨ìœ¨ì )
        weighted_sum = torch.zeros_like(standardized_outputs[0])
        for i, output in enumerate(standardized_outputs):
            weight = learned_weights[:, i:i+1, :, :]
            weighted_sum += output * weight
        
        # 8. ìµœì¢… ê²°ê³¼ ì¡°í•©
        final_output = ensemble_output + weighted_sum
        
        return {
            'ensemble_output': final_output,
            'weighted_ensemble': weighted_sum,
            'learned_ensemble': ensemble_output,
            'ensemble_weights': learned_weights,
            'uncertainty': uncertainty,
            'num_models': len(standardized_outputs),
            'memory_optimization': self.memory_optimization
        }
