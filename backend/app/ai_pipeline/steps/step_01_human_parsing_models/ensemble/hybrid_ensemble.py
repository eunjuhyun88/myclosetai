"""
ğŸ”¥ Hybrid Ensemble ëª¨ë“ˆ
======================

í•˜ì´ë¸Œë¦¬ë“œ ì•™ìƒë¸” ì‹œìŠ¤í…œ êµ¬í˜„

Author: MyCloset AI Team
Date: 2025-08-07
Version: 1.0
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
from typing import Dict, Any, List


class HybridEnsembleModule(nn.Module):
    """í•˜ì´ë¸Œë¦¬ë“œ ì•™ìƒë¸” ëª¨ë“ˆ (ë‹¤ì¤‘ ëª¨ë¸ ê²°í•©)"""
    
    def __init__(self, num_classes=20, num_models=3, hidden_dim=256):
        super().__init__()
        self.num_classes = num_classes
        self.num_models = num_models
        self.hidden_dim = hidden_dim
        
        # MPS ë””ë°”ì´ìŠ¤ ê°ì§€ ë° íƒ€ì… ì„¤ì •
        self.device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')
        self.dtype = torch.float32  # MPSì—ì„œëŠ” float32 ì‚¬ìš©
        
        # ì•™ìƒë¸” ê°€ì¤‘ì¹˜ í•™ìŠµ ë„¤íŠ¸ì›Œí¬ (MPS íƒ€ì… ì¼ê´€ì„±)
        self.weight_learner = nn.Sequential(
            nn.Conv2d(num_classes * num_models, hidden_dim, 3, padding=1),
            nn.BatchNorm2d(hidden_dim),
            nn.ReLU(inplace=True),
            nn.Conv2d(hidden_dim, hidden_dim // 2, 3, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv2d(hidden_dim // 2, num_models, 1),
            nn.Softmax(dim=1)
        ).to(device=self.device, dtype=self.dtype)
        
        # Confidence ê¸°ë°˜ ê°€ì¤‘ì¹˜ ì¡°ì • (MPS íƒ€ì… ì¼ê´€ì„±)
        self.confidence_adapter = nn.Sequential(
            nn.Conv2d(num_models, hidden_dim // 4, 3, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv2d(hidden_dim // 4, num_models, 1),
            nn.Sigmoid()
        ).to(device=self.device, dtype=self.dtype)
        
        # ê³µê°„ì  ì¼ê´€ì„± ê²€ì‚¬ (MPS íƒ€ì… ì¼ê´€ì„±)
        self.spatial_consistency = nn.Sequential(
            nn.Conv2d(num_classes * num_models, hidden_dim // 2, 3, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv2d(hidden_dim // 2, num_models, 1),
            nn.Sigmoid()
        ).to(device=self.device, dtype=self.dtype)
        
        # ìµœì¢… ìœµí•© ë„¤íŠ¸ì›Œí¬ (MPS íƒ€ì… ì¼ê´€ì„±)
        self.final_fusion = nn.Sequential(
            nn.Conv2d(num_classes * num_models, hidden_dim, 3, padding=1),
            nn.BatchNorm2d(hidden_dim),
            nn.ReLU(inplace=True),
            nn.Conv2d(hidden_dim, hidden_dim // 2, 3, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv2d(hidden_dim // 2, num_classes, 1)
        ).to(device=self.device, dtype=self.dtype)
        
        # ë¶ˆí™•ì‹¤ì„± ì •ëŸ‰í™” (MPS íƒ€ì… ì¼ê´€ì„±)
        self.uncertainty_estimator = nn.Sequential(
            nn.Conv2d(num_classes * num_models, hidden_dim // 2, 3, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv2d(hidden_dim // 2, 1, 1),
            nn.Sigmoid()
        ).to(device=self.device, dtype=self.dtype)
    
    def forward(self, model_outputs, confidences):
        """
        í•˜ì´ë¸Œë¦¬ë“œ ì•™ìƒë¸” ìˆœì „íŒŒ (MPS íƒ€ì… ì¼ê´€ì„± ìœ ì§€)
        
        Args:
            model_outputs: ëª¨ë¸ ì¶œë ¥ ë¦¬ìŠ¤íŠ¸ (ê°ê° B, num_classes, H, W)
            confidences: ì‹ ë¢°ë„ ë§µ ë¦¬ìŠ¤íŠ¸ (ê°ê° B, 1, H, W)
        
        Returns:
            ensemble_result: ì•™ìƒë¸” ê²°ê³¼
        """
        # MPS íƒ€ì… ì¼ê´€ì„± ìœ ì§€
        unified_outputs = []
        for output in model_outputs:
            if hasattr(output, 'to'):
                output = output.to(device=self.device, dtype=self.dtype)
            unified_outputs.append(output)
        
        unified_confidences = []
        for conf in confidences:
            if hasattr(conf, 'to'):
                conf = conf.to(device=self.device, dtype=self.dtype)
            unified_confidences.append(conf)
        
        batch_size, _, height, width = unified_outputs[0].shape
        
        # 1. ëª¨ë“  ëª¨ë¸ ì¶œë ¥ì„ ì±„ë„ ì°¨ì›ìœ¼ë¡œ ê²°í•©
        concatenated_outputs = torch.cat(unified_outputs, dim=1)
        
        # 2. í•™ìŠµëœ ê°€ì¤‘ì¹˜ ê³„ì‚°
        learned_weights = self.weight_learner(concatenated_outputs)
        
        # 3. ì‹ ë¢°ë„ ê¸°ë°˜ ê°€ì¤‘ì¹˜ ì¡°ì •
        confidence_tensor = torch.cat(unified_confidences, dim=1)
        confidence_adjusted_weights = self.confidence_adapter(confidence_tensor)
        
        # 4. ê³µê°„ì  ì¼ê´€ì„± ê²€ì‚¬
        spatial_weights = self.spatial_consistency(concatenated_outputs)
        
        # 5. ìµœì¢… ê°€ì¤‘ì¹˜ ê³„ì‚° (ì„¸ ê°€ì§€ ê°€ì¤‘ì¹˜ì˜ ì¡°í•©)
        final_weights = (learned_weights + confidence_adjusted_weights + spatial_weights) / 3.0
        
        # 6. ê°€ì¤‘ í‰ê·  ì•™ìƒë¸”
        weighted_outputs = []
        for i, output in enumerate(model_outputs):
            weight = final_weights[:, i:i+1, :, :]
            weighted_outputs.append(output * weight)
        
        ensemble_output = sum(weighted_outputs)
        
        # 7. ìµœì¢… ìœµí•© ë„¤íŠ¸ì›Œí¬ ì ìš©
        final_ensemble = self.final_fusion(concatenated_outputs)
        
        # 8. ë¶ˆí™•ì‹¤ì„± ì •ëŸ‰í™”
        uncertainty = self.uncertainty_estimator(concatenated_outputs)
        
        # 9. ê²°ê³¼ ì¡°í•© (ê°€ì¤‘ í‰ê·  + ìœµí•© ë„¤íŠ¸ì›Œí¬)
        final_output = ensemble_output + final_ensemble
        
        return {
            'ensemble_output': final_output,
            'weighted_ensemble': ensemble_output,
            'fused_ensemble': final_ensemble,
            'ensemble_weights': final_weights,
            'uncertainty': uncertainty,
            'model_confidences': confidences,
            'spatial_consistency': spatial_weights
        }


class HumanParsingEnsembleSystem:
    """Human Parsing ì•™ìƒë¸” ì‹œìŠ¤í…œ"""
    
    def __init__(self, ensemble_methods=None):
        self.ensemble_methods = ensemble_methods or ['weighted_average', 'confidence_based', 'spatial_consistency']
        self.hybrid_module = HybridEnsembleModule()
    
    def run_ensemble(self, results, method='weighted_average'):
        """
        ì•™ìƒë¸” ë°©ë²•ì— ë”°ë¼ ê²°ê³¼ë¥¼ ê²°í•©
        
        Args:
            results: ëª¨ë¸ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
            method: ì•™ìƒë¸” ë°©ë²•
        
        Returns:
            ensemble_result: ì•™ìƒë¸”ëœ ê²°ê³¼
        """
        if method == 'weighted_average':
            return self._weighted_average_ensemble(results)
        elif method == 'confidence_based':
            return self._confidence_based_ensemble(results)
        elif method == 'spatial_consistency':
            return self._spatial_consistency_ensemble(results)
        else:
            return self._default_ensemble(results)
    
    def _weighted_average_ensemble(self, results):
        """ê°€ì¤‘ í‰ê·  ì•™ìƒë¸”"""
        if not results:
            return None
        
        # ëª¨ë“  ê²°ê³¼ë¥¼ ë™ì¼í•œ í˜•íƒœë¡œ ë³€í™˜
        processed_results = []
        for result in results:
            if isinstance(result, dict) and 'parsing_map' in result:
                processed_results.append(result['parsing_map'])
            elif hasattr(result, 'shape'):
                processed_results.append(result)
            else:
                continue
        
        if not processed_results:
            return None
        
        # ê°€ì¤‘ í‰ê·  ê³„ì‚°
        ensemble_result = torch.stack(processed_results).mean(dim=0)
        return {'ensemble_result': ensemble_result, 'method': 'weighted_average'}
    
    def _confidence_based_ensemble(self, results):
        """ì‹ ë¢°ë„ ê¸°ë°˜ ì•™ìƒë¸”"""
        if not results:
            return None
        
        # ì‹ ë¢°ë„ ì •ë³´ ì¶”ì¶œ
        confidence_results = []
        for result in results:
            if isinstance(result, dict):
                if 'confidence' in result:
                    confidence_results.append((result['parsing_map'], result['confidence']))
                elif 'parsing_map' in result:
                    confidence_results.append((result['parsing_map'], 1.0))
            else:
                confidence_results.append((result, 1.0))
        
        if not confidence_results:
            return None
        
        # ì‹ ë¢°ë„ ê°€ì¤‘ í‰ê· 
        total_weight = sum(conf for _, conf in confidence_results)
        if total_weight == 0:
            return None
        
        weighted_sum = sum(result * conf for result, conf in confidence_results)
        ensemble_result = weighted_sum / total_weight
        
        return {'ensemble_result': ensemble_result, 'method': 'confidence_based'}
    
    def _spatial_consistency_ensemble(self, results):
        """ê³µê°„ ì¼ê´€ì„± ê¸°ë°˜ ì•™ìƒë¸”"""
        if not results:
            return None
        
        # ê³µê°„ ì¼ê´€ì„± ê²€ì‚¬
        processed_results = []
        for result in results:
            if isinstance(result, dict) and 'parsing_map' in result:
                processed_results.append(result['parsing_map'])
            elif hasattr(result, 'shape'):
                processed_results.append(result)
            else:
                continue
        
        if not processed_results:
            return None
        
        # ê³µê°„ ì¼ê´€ì„± ê³„ì‚°
        ensemble_result = torch.stack(processed_results).mean(dim=0)
        
        # ê³µê°„ ì¼ê´€ì„± ì ìˆ˜ ê³„ì‚°
        consistency_score = self._calculate_spatial_consistency(processed_results)
        
        return {
            'ensemble_result': ensemble_result, 
            'method': 'spatial_consistency',
            'consistency_score': consistency_score
        }
    
    def _default_ensemble(self, results):
        """ê¸°ë³¸ ì•™ìƒë¸” (ì²« ë²ˆì§¸ ê²°ê³¼ ë°˜í™˜)"""
        if not results:
            return None
        
        first_result = results[0]
        if isinstance(first_result, dict) and 'parsing_map' in first_result:
            return {'ensemble_result': first_result['parsing_map'], 'method': 'default'}
        elif hasattr(first_result, 'shape'):
            return {'ensemble_result': first_result, 'method': 'default'}
        else:
            return {'ensemble_result': first_result, 'method': 'default'}
    
    def _calculate_spatial_consistency(self, results):
        """ê³µê°„ ì¼ê´€ì„± ì ìˆ˜ ê³„ì‚°"""
        if len(results) < 2:
            return 1.0
        
        # ê²°ê³¼ ê°„ì˜ í‰ê·  ì°¨ì´ ê³„ì‚°
        total_diff = 0
        count = 0
        
        for i in range(len(results)):
            for j in range(i + 1, len(results)):
                diff = torch.abs(results[i] - results[j]).mean()
                total_diff += diff.item()
                count += 1
        
        if count == 0:
            return 1.0
        
        avg_diff = total_diff / count
        # ì¼ê´€ì„± ì ìˆ˜ (0~1, ë†’ì„ìˆ˜ë¡ ì¼ê´€ì„± ì¢‹ìŒ)
        consistency_score = max(0, 1 - avg_diff)
        
        return consistency_score
