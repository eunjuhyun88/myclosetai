#!/usr/bin/env python3
"""
ğŸ”¥ MyCloset AI - Common Imports for AI Pipeline Steps
=====================================================

AI pipeline step íŒŒì¼ë“¤ì—ì„œ ê³µí†µìœ¼ë¡œ ì‚¬ìš©ë˜ëŠ” import ë¸”ë¡ë“¤ì„ ì •ë¦¬í•œ ìœ í‹¸ë¦¬í‹° ëª¨ë“ˆì…ë‹ˆë‹¤.
ê° step íŒŒì¼ì—ì„œ ì´ ëª¨ë“ˆì„ importí•˜ì—¬ ì¤‘ë³µëœ import ì½”ë“œë¥¼ ì œê±°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

Author: MyCloset AI Team
Date: 2025-07-31
Version: 1.0
"""

# ==============================================
# ğŸ”¥ í‘œì¤€ ë¼ì´ë¸ŒëŸ¬ë¦¬ imports
# ==============================================
import os
import sys
import gc
import time
import asyncio
import logging
import threading
import traceback
import hashlib
import json
import base64
import math
import warnings

from pathlib import Path
from typing import Dict, Any, Optional, Tuple, List, Union, Callable, TYPE_CHECKING
from dataclasses import dataclass, field
from enum import Enum, IntEnum
from io import BytesIO
from concurrent.futures import ThreadPoolExecutor
from functools import lru_cache, wraps
from contextlib import asynccontextmanager

# ==============================================
# ğŸ”¥ í†µí•©ëœ ì—ëŸ¬ ì²˜ë¦¬ ì‹œìŠ¤í…œ import
# ==============================================
try:
    from app.core.exceptions import (
        MyClosetAIException,
        MockDataDetectionError, 
        DataQualityError, 
        ModelInferenceError,
        ModelLoadingError,
        ImageProcessingError,
        DataValidationError,
        ConfigurationError,
        error_tracker,
        detect_mock_data,
        log_detailed_error,
        create_mock_data_diagnosis_response,
        track_exception,
        get_error_summary,
        create_exception_response,
        convert_to_mycloset_exception,
        ErrorCodes
    )
    EXCEPTIONS_AVAILABLE = True
except ImportError:
    EXCEPTIONS_AVAILABLE = False
    logger = logging.getLogger(__name__)
    logger.warning("í†µí•© ì—ëŸ¬ ì²˜ë¦¬ ì‹œìŠ¤í…œì„ importí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ ì—ëŸ¬ ì²˜ë¦¬ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.")

# ==============================================
# ğŸ”¥ Mock Data Diagnostic System import
# ==============================================
try:
    from app.core.mock_data_diagnostic import (
        MockDataDiagnostic,
        diagnose_step_data,
        get_diagnostic_summary,
        diagnostic_decorator
    )
    MOCK_DIAGNOSTIC_AVAILABLE = True
except ImportError:
    MOCK_DIAGNOSTIC_AVAILABLE = False

# ==============================================
# ğŸ”¥ Central Hub DI Container ì•ˆì „ import (ìˆœí™˜ì°¸ì¡° ë°©ì§€)
# ==============================================
if TYPE_CHECKING:
    from app.core.di_container import CentralHubDIContainer
    from app.ai_pipeline.utils.model_loader import ModelLoader
    from app.ai_pipeline.steps.base_step_mixin import BaseStepMixin

def _get_central_hub_container():
    """Central Hub DI Container ì•ˆì „í•œ ë™ì  í•´ê²°"""
    try:
        import importlib
        module = importlib.import_module('app.core.di_container')
        get_global_fn = getattr(module, 'get_global_container', None)
        if get_global_fn:
            return get_global_fn()
        return None
    except ImportError:
        return None
    except Exception:
        return None

def get_base_step_mixin_class():
    """BaseStepMixin í´ë˜ìŠ¤ë¥¼ ë™ì ìœ¼ë¡œ ê°€ì ¸ì˜¤ê¸° (ìˆœí™˜ì°¸ì¡° ë°©ì§€)"""
    try:
        import importlib
        module = importlib.import_module('.base_step_mixin', package='app.ai_pipeline.steps')
        return getattr(module, 'BaseStepMixin', None)
    except ImportError:
        try:
            # í´ë°±: ìƒëŒ€ ê²½ë¡œ
            from .base_step_mixin import BaseStepMixin
            return BaseStepMixin
        except ImportError:
            logging.getLogger(__name__).error("âŒ BaseStepMixin ë™ì  import ì‹¤íŒ¨")
            return None

# ==============================================
# ğŸ”¥ AI/ML ë¼ì´ë¸ŒëŸ¬ë¦¬ imports (ì„ íƒì )
# ==============================================

# NumPy í•„ìˆ˜
try:
    import numpy as np
    NUMPY_AVAILABLE = True
except ImportError:
    NUMPY_AVAILABLE = False
    np = None

# PyTorch í•„ìˆ˜ (MPS ì§€ì›)
try:
    import torch
    import torch.nn as nn
    import torch.nn.functional as F
    from torch.utils.data import DataLoader
    from torchvision import transforms
    TORCH_AVAILABLE = True
    MPS_AVAILABLE = hasattr(torch.backends, 'mps') and torch.backends.mps.is_available()
except ImportError:
    TORCH_AVAILABLE = False
    MPS_AVAILABLE = False
    torch = None
    nn = None
    F = None
    DataLoader = None
    transforms = None

# PIL í•„ìˆ˜
try:
    from PIL import Image, ImageFilter, ImageEnhance
    PIL_AVAILABLE = True
except ImportError:
    PIL_AVAILABLE = False
    Image = None
    ImageFilter = None
    ImageEnhance = None

# OpenCV ì„ íƒì‚¬í•­
try:
    import cv2
    CV2_AVAILABLE = True
except ImportError:
    CV2_AVAILABLE = False
    cv2 = None
    
# SciPy ì„ íƒì‚¬í•­
try:
    import scipy
    import scipy.ndimage as ndimage  # í™€ ì±„ìš°ê¸°ì—ì„œ ì‚¬ìš©
    SCIPY_AVAILABLE = True
except ImportError:
    SCIPY_AVAILABLE = False
    scipy = None
    ndimage = None

# DenseCRF ê³ ê¸‰ í›„ì²˜ë¦¬ (ì„ íƒì‚¬í•­)
try:
    import pydensecrf.densecrf as dcrf
    from pydensecrf.utils import unary_from_softmax
    DENSECRF_AVAILABLE = True
except ImportError:
    DENSECRF_AVAILABLE = False
    dcrf = None
    unary_from_softmax = None

# Scikit-image ê³ ê¸‰ ì´ë¯¸ì§€ ì²˜ë¦¬ (ì„ íƒì‚¬í•­)
try:
    from skimage import measure, morphology, segmentation, filters
    SKIMAGE_AVAILABLE = True
except ImportError:
    SKIMAGE_AVAILABLE = False
    measure = None
    morphology = None
    segmentation = None
    filters = None

# ==============================================
# ğŸ”¥ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
# ==============================================

def detect_m3_max() -> bool:
    """M3 Max ì¹©ì…‹ ê°ì§€"""
    try:
        import platform
        import subprocess
        
        if platform.system() != "Darwin":
            return False
            
        # M3 Max ê°ì§€
        result = subprocess.run(['sysctl', '-n', 'machdep.cpu.brand_string'], 
                              capture_output=True, text=True)
        if result.returncode == 0:
            brand = result.stdout.strip().lower()
            return 'm3 max' in brand or 'm3 pro' in brand or 'm3' in brand
            
        return False
    except Exception:
        return False

def get_available_libraries() -> Dict[str, bool]:
    """ì‚¬ìš© ê°€ëŠ¥í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ëª©ë¡ ë°˜í™˜"""
    return {
        'numpy': NUMPY_AVAILABLE,
        'torch': TORCH_AVAILABLE,
        'mps': MPS_AVAILABLE,
        'pil': PIL_AVAILABLE,
        'cv2': CV2_AVAILABLE,
        'scipy': SCIPY_AVAILABLE,
        'densecrf': DENSECRF_AVAILABLE,
        'skimage': SKIMAGE_AVAILABLE,
        'exceptions': EXCEPTIONS_AVAILABLE,
        'mock_diagnostic': MOCK_DIAGNOSTIC_AVAILABLE
    }

def log_library_status(logger: logging.Logger):
    """ë¼ì´ë¸ŒëŸ¬ë¦¬ ìƒíƒœë¥¼ ë¡œê·¸ì— ì¶œë ¥"""
    libraries = get_available_libraries()
    logger.info("ğŸ“š ì‚¬ìš© ê°€ëŠ¥í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ìƒíƒœ:")
    for lib, available in libraries.items():
        status = "âœ…" if available else "âŒ"
        logger.info(f"  {status} {lib}")

# ==============================================
# ğŸ”¥ ê³µí†µ ìƒìˆ˜ë“¤
# ==============================================

# ë””ë°”ì´ìŠ¤ ìƒìˆ˜
DEVICE_CPU = "cpu"
DEVICE_CUDA = "cuda"
DEVICE_MPS = "mps"

# ê¸°ë³¸ ì„¤ì •ê°’ë“¤
DEFAULT_INPUT_SIZE = (512, 512)
DEFAULT_CONFIDENCE_THRESHOLD = 0.7
DEFAULT_QUALITY_THRESHOLD = 0.8

# ì—ëŸ¬ ë©”ì‹œì§€ í…œí”Œë¦¿
ERROR_TEMPLATES = {
    'model_loading': "ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {model_name}",
    'inference': "ì¶”ë¡  ì‹¤íŒ¨: {step_name}",
    'preprocessing': "ì „ì²˜ë¦¬ ì‹¤íŒ¨: {step_name}",
    'postprocessing': "í›„ì²˜ë¦¬ ì‹¤íŒ¨: {step_name}",
    'validation': "ë°ì´í„° ê²€ì¦ ì‹¤íŒ¨: {step_name}"
} 