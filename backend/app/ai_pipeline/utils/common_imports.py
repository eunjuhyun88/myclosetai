#!/usr/bin/env python3
"""
ğŸ”¥ MyCloset AI - Unified Common Imports for ALL AI Pipeline Steps
=================================================================

ëª¨ë“  AI pipeline step íŒŒì¼ë“¤ì—ì„œ ê³µí†µìœ¼ë¡œ ì‚¬ìš©ë˜ëŠ” import ë¸”ë¡ë“¤ì„ ì™„ì „íˆ í†µí•©í•œ ëª¨ë“ˆì…ë‹ˆë‹¤.
ì´ ëª¨ë“ˆ í•˜ë‚˜ë§Œ importí•˜ë©´ ëª¨ë“  Stepì—ì„œ í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ì™€ ìœ í‹¸ë¦¬í‹°ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ì‚¬ìš©ë²•:
    from app.ai_pipeline.utils.common_imports import *
    
    ë˜ëŠ”
    
    from app.ai_pipeline.utils.common_imports import (
        torch, nn, F, transforms, Image, np, cv2,
        TORCH_AVAILABLE, MPS_AVAILABLE, PIL_AVAILABLE,
        MyClosetAIException, track_exception, ErrorCodes
    )

Author: MyCloset AI Team
Date: 2025-08-03
Version: 2.0 (Unified for All Steps)
"""

# ==============================================
# ğŸ”¥ 1ë‹¨ê³„: í‘œì¤€ ë¼ì´ë¸ŒëŸ¬ë¦¬ imports (Python ëª¨ë²” ì‚¬ë¡€ ìˆœì„œ)
# ==============================================

import os
import sys
import gc
import time
import asyncio
import logging
import threading
import traceback
import hashlib
import json
import base64
import math
import warnings
import weakref
import uuid
import subprocess
import platform
from datetime import datetime, timedelta

from pathlib import Path
from typing import Dict, Any, Optional, Tuple, List, Union, Callable, TYPE_CHECKING, Set
from dataclasses import dataclass, field
from enum import Enum, IntEnum
from io import BytesIO, StringIO
from concurrent.futures import ThreadPoolExecutor, as_completed
from functools import lru_cache, wraps, partial
from contextlib import asynccontextmanager, contextmanager
from collections import defaultdict, deque
from itertools import chain

# ==============================================
# ğŸ”¥ 2ë‹¨ê³„: í™˜ê²½ ê°ì§€ ë° ë””ë°”ì´ìŠ¤ ì„¤ì • (ìµœìš°ì„ )
# ==============================================

def detect_m3_max() -> bool:
    """M3 Max ì¹©ì…‹ ê°ì§€"""
    try:
        if platform.system() != "Darwin":
            return False
        result = subprocess.run(['sysctl', '-n', 'machdep.cpu.brand_string'], 
                              capture_output=True, text=True, timeout=5)
        if result.returncode == 0:
            brand = result.stdout.strip().lower()
            return any(chip in brand for chip in ['m3 max', 'm3 pro', 'm3', 'm2 max', 'm2 pro', 'm1 max'])
        return False
    except Exception:
        return False

def detect_conda_env() -> Dict[str, Any]:
    """Conda í™˜ê²½ ê°ì§€"""
    try:
        conda_env = os.environ.get('CONDA_DEFAULT_ENV', 'unknown')
        conda_prefix = os.environ.get('CONDA_PREFIX', '')
        in_conda = 'CONDA_DEFAULT_ENV' in os.environ
        
        # ë©”ëª¨ë¦¬ ê°ì§€
        memory_gb = 16.0
        try:
            if platform.system() == "Darwin":
                result = subprocess.run(['sysctl', '-n', 'hw.memsize'], 
                                      capture_output=True, text=True, timeout=5)
                if result.returncode == 0:
                    memory_bytes = int(result.stdout.strip())
                    memory_gb = memory_bytes / (1024**3)
        except:
            pass
        
        return {
            'in_conda': in_conda,
            'conda_env': conda_env,
            'conda_prefix': conda_prefix,
            'is_target_env': conda_env in ['myclosetlast', 'mycloset-ai-clean'],
            'memory_gb': memory_gb
        }
    except Exception:
        return {
            'in_conda': False,
            'conda_env': 'unknown',
            'conda_prefix': '',
            'is_target_env': False,
            'memory_gb': 16.0
        }

# í™˜ê²½ ì •ë³´ ì „ì—­ ë³€ìˆ˜
IS_M3_MAX = detect_m3_max()
CONDA_INFO = detect_conda_env()
MEMORY_GB = CONDA_INFO['memory_gb']

# ==============================================
# ğŸ”¥ 3ë‹¨ê³„: AI/ML ë¼ì´ë¸ŒëŸ¬ë¦¬ imports (ê°€ìš©ì„± ë³€ìˆ˜ ë¨¼ì € ì •ì˜)
# ==============================================

# âœ… ê°€ìš©ì„± ë³€ìˆ˜ë“¤ì„ ë¨¼ì € ì´ˆê¸°í™” (ë§¤ìš° ì¤‘ìš”!)
TORCH_AVAILABLE = False
MPS_AVAILABLE = False
CUDA_AVAILABLE = False
PIL_AVAILABLE = False
NUMPY_AVAILABLE = False
CV2_AVAILABLE = False
SCIPY_AVAILABLE = False
SKIMAGE_AVAILABLE = False
DENSECRF_AVAILABLE = False
MEDIAPIPE_AVAILABLE = False
ULTRALYTICS_AVAILABLE = False
TRANSFORMERS_AVAILABLE = False
SAM_AVAILABLE = False
SAFETENSORS_AVAILABLE = False

# ë””ë°”ì´ìŠ¤ ë° í™˜ê²½
DEVICE = "cpu"
TORCH_VERSION = "unknown"

# ==============================================
# NumPy (í•„ìˆ˜ - ëª¨ë“  Stepì—ì„œ ì‚¬ìš©)
# ==============================================
try:
    import numpy as np
    NUMPY_AVAILABLE = True
    print("âœ… NumPy ë¡œë“œ ì™„ë£Œ")
except ImportError as e:
    print(f"âŒ NumPy import ì‹¤íŒ¨: {e}")
    np = None

# ==============================================
# PyTorch (í•„ìˆ˜ - ëª¨ë“  AI Stepì—ì„œ ì‚¬ìš©)
# ==============================================
try:
    import torch
    import torch.nn as nn
    import torch.nn.functional as F
    from torch.utils.data import DataLoader
    from torch.cuda.amp import autocast
    import torchvision.transforms as transforms
    from torchvision.transforms.functional import resize, to_pil_image, to_tensor
    
    TORCH_AVAILABLE = True
    TORCH_VERSION = torch.__version__
    
    # ë””ë°”ì´ìŠ¤ ìë™ ê°ì§€
    if hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
        MPS_AVAILABLE = True
        DEVICE = "mps"
        # M3 Max ìµœì í™”
        if IS_M3_MAX:
            os.environ['PYTORCH_MPS_HIGH_WATERMARK_RATIO'] = '0.0'
            os.environ['TORCH_MPS_PREFER_METAL'] = '1'
            try:
                torch.mps.set_per_process_memory_fraction(0.7)
            except:
                pass
    elif torch.cuda.is_available():
        CUDA_AVAILABLE = True
        DEVICE = "cuda"
    else:
        DEVICE = "cpu"
        
    print(f"âœ… PyTorch {TORCH_VERSION} ë¡œë“œ ì™„ë£Œ, ë””ë°”ì´ìŠ¤: {DEVICE}")
    if MPS_AVAILABLE:
        print("ğŸ MPS ì‚¬ìš© ê°€ëŠ¥")
    if CUDA_AVAILABLE:
        print("ğŸ”¥ CUDA ì‚¬ìš© ê°€ëŠ¥")
        
except ImportError as e:
    print(f"âŒ PyTorch import ì‹¤íŒ¨: {e}")
    torch = None
    nn = None
    F = None
    transforms = None
    DataLoader = None
    autocast = None

# ==============================================
# PIL (í•„ìˆ˜ - ëª¨ë“  ì´ë¯¸ì§€ ì²˜ë¦¬ Stepì—ì„œ ì‚¬ìš©)
# ==============================================
try:
    from PIL import Image, ImageEnhance, ImageFilter, ImageDraw, ImageFont, ImageOps
    PIL_AVAILABLE = True
    print("âœ… PIL ë¡œë“œ ì™„ë£Œ")
except ImportError as e:
    print(f"âŒ PIL import ì‹¤íŒ¨: {e}")
    Image = None

# ==============================================
# OpenCV (ì¤‘ìš” - ëŒ€ë¶€ë¶„ Stepì—ì„œ ì‚¬ìš©)
# ==============================================
try:
    import cv2
    CV2_AVAILABLE = True
    print("âœ… OpenCV ë¡œë“œ ì™„ë£Œ")
except ImportError:
    print("âš ï¸ OpenCV ì—†ìŒ - ì¼ë¶€ ê¸°ëŠ¥ ì œí•œ")
    cv2 = None

# ==============================================
# SciPy (ê³ ê¸‰ í›„ì²˜ë¦¬ìš©)
# ==============================================
try:
    import scipy
    from scipy import ndimage
    from scipy.ndimage import gaussian_filter, median_filter
    from scipy.signal import convolve2d
    from scipy.optimize import curve_fit
    SCIPY_AVAILABLE = True
    print("âœ… SciPy ë¡œë“œ ì™„ë£Œ")
except ImportError:
    print("âš ï¸ SciPy ì—†ìŒ - ê³ ê¸‰ í›„ì²˜ë¦¬ ì œí•œ")
    scipy = None
    ndimage = None

# ==============================================
# Scikit-image (ê³ ê¸‰ ì´ë¯¸ì§€ ì²˜ë¦¬)
# ==============================================
try:
    from skimage import measure, morphology, segmentation, filters, restoration, exposure
    from skimage.metrics import structural_similarity as ssim
    SKIMAGE_AVAILABLE = True
    print("âœ… scikit-image ë¡œë“œ ì™„ë£Œ")
except ImportError:
    print("âš ï¸ scikit-image ì—†ìŒ - ì¼ë¶€ ì´ë¯¸ì§€ ì²˜ë¦¬ ì œí•œ")
    measure = None
    morphology = None
    segmentation = None
    filters = None

# ==============================================
# DenseCRF (CRF í›„ì²˜ë¦¬ìš©)
# ==============================================
try:
    import pydensecrf.densecrf as dcrf
    from pydensecrf.utils import unary_from_softmax
    DENSECRF_AVAILABLE = True
    print("âœ… DenseCRF ë¡œë“œ ì™„ë£Œ")
except ImportError:
    print("âš ï¸ DenseCRF ì—†ìŒ - CRF í›„ì²˜ë¦¬ ì œí•œ")
    dcrf = None
    unary_from_softmax = None

# ==============================================
# MediaPipe (Pose Estimationìš©)
# ==============================================
try:
    import mediapipe as mp
    MEDIAPIPE_AVAILABLE = True
    print("âœ… MediaPipe ë¡œë“œ ì™„ë£Œ")
except ImportError:
    print("âš ï¸ MediaPipe ì—†ìŒ - Pose Estimation ì¼ë¶€ ì œí•œ")
    mp = None

# ==============================================
# Ultralytics YOLO (Pose Estimationìš©)
# ==============================================
try:
    from ultralytics import YOLO
    ULTRALYTICS_AVAILABLE = True
    print("âœ… Ultralytics YOLO ë¡œë“œ ì™„ë£Œ")
except ImportError:
    print("âš ï¸ Ultralytics ì—†ìŒ - YOLO ê¸°ë°˜ ê¸°ëŠ¥ ì œí•œ")
    YOLO = None

# ==============================================
# Transformers (ì¼ë¶€ Stepì—ì„œ ì‚¬ìš©)
# ==============================================
try:
    from transformers import AutoModel, AutoTokenizer, AutoProcessor
    TRANSFORMERS_AVAILABLE = True
    print("âœ… Transformers ë¡œë“œ ì™„ë£Œ")
except ImportError:
    print("âš ï¸ Transformers ì—†ìŒ - ì¼ë¶€ ëª¨ë¸ ì œí•œ")
    AutoModel = None
    AutoTokenizer = None

# ==============================================
# Segment Anything Model (SAM)
# ==============================================
try:
    import segment_anything as sam
    SAM_AVAILABLE = True
    print("âœ… SAM ë¡œë“œ ì™„ë£Œ")
except ImportError:
    print("âš ï¸ SAM ì—†ìŒ - Segment Anything ê¸°ëŠ¥ ì œí•œ")
    sam = None

# ==============================================
# SafeTensors (ëª¨ë¸ ë¡œë”©ìš©)
# ==============================================
try:
    import safetensors.torch as st
    SAFETENSORS_AVAILABLE = True
    print("âœ… SafeTensors ë¡œë“œ ì™„ë£Œ")
except ImportError:
    print("âš ï¸ SafeTensors ì—†ìŒ - ì¼ë¶€ ëª¨ë¸ ë¡œë”© ì œí•œ")
    st = None

# ==============================================
# ğŸ”¥ 4ë‹¨ê³„: í”„ë¡œì íŠ¸ ë‚´ë¶€ ëª¨ë“ˆ imports (ì—ëŸ¬ ì²˜ë¦¬ í¬í•¨)
# ==============================================

# âœ… ì—ëŸ¬ ì²˜ë¦¬ ì‹œìŠ¤í…œ ê°€ìš©ì„± ë³€ìˆ˜
EXCEPTIONS_AVAILABLE = False
MOCK_DIAGNOSTIC_AVAILABLE = False

# ==============================================
# í†µí•©ëœ ì—ëŸ¬ ì²˜ë¦¬ ì‹œìŠ¤í…œ
# ==============================================
try:
    from app.core.exceptions import (
        MyClosetAIException,
        MockDataDetectionError, 
        DataQualityError, 
        ModelInferenceError,
        ModelLoadingError,
        ImageProcessingError,
        DataValidationError,
        ConfigurationError,
        error_tracker,
        detect_mock_data,
        log_detailed_error,
        create_mock_data_diagnosis_response,
        track_exception,
        get_error_summary,
        create_exception_response,
        convert_to_mycloset_exception,
        ErrorCodes
    )
    EXCEPTIONS_AVAILABLE = True
    print("âœ… í†µí•© ì—ëŸ¬ ì²˜ë¦¬ ì‹œìŠ¤í…œ ë¡œë“œ ì™„ë£Œ")
except ImportError:
    print("âš ï¸ í†µí•© ì—ëŸ¬ ì²˜ë¦¬ ì‹œìŠ¤í…œ ì—†ìŒ - ê¸°ë³¸ ì—ëŸ¬ ì²˜ë¦¬ë§Œ ì‚¬ìš©")
    # í´ë°± í´ë˜ìŠ¤ë“¤
    class MyClosetAIException(Exception):
        pass
    class MockDataDetectionError(Exception):
        pass
    class DataQualityError(Exception):
        pass
    class ModelInferenceError(Exception):
        pass
    class ModelLoadingError(Exception):
        pass
    class ImageProcessingError(Exception):
        pass
    class DataValidationError(Exception):
        pass
    class ConfigurationError(Exception):
        pass
    
    # í´ë°± í•¨ìˆ˜ë“¤
    def detect_mock_data(data):
        return {'is_mock': False}
    def track_exception(error, context, step_id):
        pass
    def log_detailed_error(error, context, step_id):
        pass
    def create_exception_response(error, step_name, step_id, session_id):
        return {'success': False, 'error': str(error)}
    def convert_to_mycloset_exception(error, context):
        return MyClosetAIException(str(error))
    
    class ErrorCodes:
        DATA_VALIDATION_FAILED = "DATA_VALIDATION_FAILED"
        MODEL_LOADING_FAILED = "MODEL_LOADING_FAILED"
        AI_INFERENCE_FAILED = "AI_INFERENCE_FAILED"
        CONFIGURATION_ERROR = "CONFIGURATION_ERROR"

# ==============================================
# Mock Data Diagnostic System
# ==============================================
try:
    from app.core.mock_diagnostic import (
        MockDataDiagnostic,
        diagnose_step_data,
        get_diagnostic_summary,
        diagnostic_decorator
    )
    MOCK_DIAGNOSTIC_AVAILABLE = True
    print("âœ… Mock ì§„ë‹¨ ì‹œìŠ¤í…œ ë¡œë“œ ì™„ë£Œ")
except ImportError:
    print("âš ï¸ Mock ì§„ë‹¨ ì‹œìŠ¤í…œ ì—†ìŒ")
    # í´ë°± í´ë˜ìŠ¤ì™€ í•¨ìˆ˜ë“¤
    class MockDataDiagnostic:
        pass
    def diagnose_step_data(data):
        return {'is_mock': False}
    def get_diagnostic_summary():
        return {}
    def diagnostic_decorator(func):
        return func

# ==============================================
# ğŸ”¥ 5ë‹¨ê³„: Central Hub DI Container ì•ˆì „ import (ìˆœí™˜ì°¸ì¡° ë°©ì§€)
# ==============================================

if TYPE_CHECKING:
    from app.core.di_container import CentralHubDIContainer
    from app.ai_pipeline.utils.model_loader import ModelLoader
    from app.ai_pipeline.steps.base_step_mixin import BaseStepMixin

def _get_central_hub_container():
    """Central Hub DI Container ì•ˆì „í•œ ë™ì  í•´ê²°"""
    try:
        import importlib
        module = importlib.import_module('app.core.di_container')
        get_global_fn = getattr(module, 'get_global_container', None)
        if get_global_fn:
            return get_global_fn()
        return None
    except ImportError:
        return None
    except Exception:
        return None

def get_base_step_mixin_class():
    """BaseStepMixin í´ë˜ìŠ¤ë¥¼ ë™ì ìœ¼ë¡œ ê°€ì ¸ì˜¤ê¸° (ìˆœí™˜ì°¸ì¡° ë°©ì§€)"""
    try:
        import importlib
        module = importlib.import_module('.base_step_mixin', package='app.ai_pipeline.steps')
        return getattr(module, 'BaseStepMixin', None)
    except ImportError:
        try:
            # í´ë°±: ìƒëŒ€ ê²½ë¡œ
            from .base_step_mixin import BaseStepMixin
            return BaseStepMixin
        except ImportError:
            logging.getLogger(__name__).error("âŒ BaseStepMixin ë™ì  import ì‹¤íŒ¨")
            return None

def _inject_dependencies_safe(step_instance):
    """Central Hub DI Containerë¥¼ í†µí•œ ì•ˆì „í•œ ì˜ì¡´ì„± ì£¼ì…"""
    try:
        container = _get_central_hub_container()
        if container and hasattr(container, 'inject_to_step'):
            return container.inject_to_step(step_instance)
        return 0
    except Exception:
        return 0

def _get_service_from_central_hub(service_key: str):
    """Central Hubë¥¼ í†µí•œ ì•ˆì „í•œ ì„œë¹„ìŠ¤ ì¡°íšŒ"""
    try:
        container = _get_central_hub_container()
        if container:
            return container.get(service_key)
        return None
    except Exception:
        return None

# ==============================================
# ğŸ”¥ 6ë‹¨ê³„: ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
# ==============================================

def get_available_libraries() -> Dict[str, bool]:
    """ì‚¬ìš© ê°€ëŠ¥í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ëª©ë¡ ë°˜í™˜"""
    return {
        'numpy': NUMPY_AVAILABLE,
        'torch': TORCH_AVAILABLE,
        'mps': MPS_AVAILABLE,
        'cuda': CUDA_AVAILABLE,
        'pil': PIL_AVAILABLE,
        'cv2': CV2_AVAILABLE,
        'scipy': SCIPY_AVAILABLE,
        'densecrf': DENSECRF_AVAILABLE,
        'skimage': SKIMAGE_AVAILABLE,
        'mediapipe': MEDIAPIPE_AVAILABLE,
        'ultralytics': ULTRALYTICS_AVAILABLE,
        'transformers': TRANSFORMERS_AVAILABLE,
        'sam': SAM_AVAILABLE,
        'safetensors': SAFETENSORS_AVAILABLE,
        'exceptions': EXCEPTIONS_AVAILABLE,
        'mock_diagnostic': MOCK_DIAGNOSTIC_AVAILABLE
    }

def log_library_status(logger: logging.Logger):
    """ë¼ì´ë¸ŒëŸ¬ë¦¬ ìƒíƒœë¥¼ ë¡œê·¸ì— ì¶œë ¥"""
    libraries = get_available_libraries()
    logger.info("ğŸ“š ì‚¬ìš© ê°€ëŠ¥í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ìƒíƒœ:")
    for lib, available in libraries.items():
        status = "âœ…" if available else "âŒ"
        logger.info(f"  {status} {lib}")

def safe_copy(obj: Any) -> Any:
    """ì•ˆì „í•œ ë³µì‚¬ í•¨ìˆ˜ - DetailedDataSpec ì—ëŸ¬ í•´ê²°"""
    try:
        # ê¸°ë³¸ íƒ€ì…ë“¤ì€ ê·¸ëŒ€ë¡œ ë°˜í™˜
        if obj is None or isinstance(obj, (bool, int, float, str)):
            return obj
        
        # ë¦¬ìŠ¤íŠ¸ë‚˜ íŠœí”Œ
        elif isinstance(obj, (list, tuple)):
            return type(obj)(safe_copy(item) for item in obj)
        
        # ë”•ì…”ë„ˆë¦¬
        elif isinstance(obj, dict):
            return {key: safe_copy(value) for key, value in obj.items()}
        
        # ì§‘í•©
        elif isinstance(obj, set):
            return {safe_copy(item) for item in obj}
        
        # copy ëª¨ë“ˆ ì‚¬ìš© ê°€ëŠ¥í•œ ê²½ìš°
        else:
            try:
                import copy
                return copy.deepcopy(obj)
            except:
                try:
                    import copy
                    return copy.copy(obj)
                except:
                    # ë³µì‚¬í•  ìˆ˜ ì—†ëŠ” ê²½ìš° ì›ë³¸ ë°˜í™˜ (ì˜ˆ: í•¨ìˆ˜, í´ë˜ìŠ¤ ë“±)
                    return obj
                    
    except Exception:
        # ëª¨ë“  ì‹¤íŒ¨ ì¼€ì´ìŠ¤ì—ì„œ ì›ë³¸ ë°˜í™˜
        return obj

def optimize_memory():
    """ë©”ëª¨ë¦¬ ìµœì í™” (M3 Max íŠ¹í™”)"""
    try:
        # Python GC
        gc.collect()
        
        # PyTorch ë©”ëª¨ë¦¬ ì •ë¦¬
        if TORCH_AVAILABLE:
            if MPS_AVAILABLE:
                try:
                    torch.mps.empty_cache()
                    if hasattr(torch.mps, 'synchronize'):
                        torch.mps.synchronize()
                except:
                    pass
            elif CUDA_AVAILABLE:
                try:
                    torch.cuda.empty_cache()
                except:
                    pass
                    
    except Exception:
        pass

def get_optimal_device():
    """ìµœì  ë””ë°”ì´ìŠ¤ ë°˜í™˜"""
    if TORCH_AVAILABLE:
        if MPS_AVAILABLE and IS_M3_MAX:
            return "mps"
        elif CUDA_AVAILABLE:
            return "cuda"
    return "cpu"

# ==============================================
# ğŸ”¥ 7ë‹¨ê³„: ê³µí†µ ìƒìˆ˜ë“¤
# ==============================================

# ë””ë°”ì´ìŠ¤ ìƒìˆ˜
DEVICE_CPU = "cpu"
DEVICE_CUDA = "cuda"
DEVICE_MPS = "mps"

# ê¸°ë³¸ ì„¤ì •ê°’ë“¤
DEFAULT_INPUT_SIZE = (512, 512)
DEFAULT_CONFIDENCE_THRESHOLD = 0.7
DEFAULT_QUALITY_THRESHOLD = 0.8
DEFAULT_BATCH_SIZE = 1

# Step ì •ë³´
STEP_NAMES = [
    "HumanParsingStep",
    "PoseEstimationStep", 
    "ClothSegmentationStep",
    "GeometricMatchingStep",
    "ClothWarpingStep",
    "VirtualFittingStep",
    "PostProcessingStep",
    "QualityAssessmentStep"
]

# ì—ëŸ¬ ë©”ì‹œì§€ í…œí”Œë¦¿
ERROR_TEMPLATES = {
    'model_loading': "ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {model_name}",
    'inference': "ì¶”ë¡  ì‹¤íŒ¨: {step_name}",
    'preprocessing': "ì „ì²˜ë¦¬ ì‹¤íŒ¨: {step_name}",
    'postprocessing': "í›„ì²˜ë¦¬ ì‹¤íŒ¨: {step_name}",
    'validation': "ë°ì´í„° ê²€ì¦ ì‹¤íŒ¨: {step_name}",
    'torch_unavailable': "PyTorchê°€ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {error}",
    'device_error': "ë””ë°”ì´ìŠ¤ ì„¤ì • ì˜¤ë¥˜: {device}"
}

# COCO Keypoints (Pose Estimationìš©)
COCO_KEYPOINTS = [
    "nose", "left_eye", "right_eye", "left_ear", "right_ear",
    "left_shoulder", "right_shoulder", "left_elbow", "right_elbow",
    "left_wrist", "right_wrist", "left_hip", "right_hip",
    "left_knee", "right_knee", "left_ankle", "right_ankle"
]

# Human Parsing Classes (20 classes)
HUMAN_PARSING_CLASSES = {
    0: 'background', 1: 'hat', 2: 'hair', 3: 'glove', 4: 'sunglasses',
    5: 'upper_clothes', 6: 'dress', 7: 'coat', 8: 'socks', 9: 'pants',
    10: 'torso_skin', 11: 'scarf', 12: 'skirt', 13: 'face',
    14: 'left_arm', 15: 'right_arm', 16: 'left_leg', 17: 'right_leg',
    18: 'left_shoe', 19: 'right_shoe'
}

# ==============================================
# ğŸ”¥ 8ë‹¨ê³„: ì´ˆê¸°í™” ë° í™˜ê²½ ì •ë³´ ì¶œë ¥
# ==============================================

# í™˜ê²½ ì •ë³´ ì¶œë ¥
print(f"ğŸ”¥ MyCloset AI - Common Imports v2.0 ì´ˆê¸°í™” ì™„ë£Œ!")
print(f"ğŸ–¥ï¸ í™˜ê²½: M3 Max={IS_M3_MAX}, conda={CONDA_INFO['conda_env']}")
print(f"ğŸ¯ ë””ë°”ì´ìŠ¤: {DEVICE}, PyTorch={TORCH_AVAILABLE}, ë©”ëª¨ë¦¬={MEMORY_GB:.1f}GB")
print(f"ğŸ“š ë¼ì´ë¸ŒëŸ¬ë¦¬: PIL={PIL_AVAILABLE}, CV2={CV2_AVAILABLE}, SciPy={SCIPY_AVAILABLE}")

# ì „ì—­ìœ¼ë¡œ ì‚¬ìš© ê°€ëŠ¥í•˜ë„ë¡ ì„¤ì •
globals()['safe_copy'] = safe_copy

# ==============================================
# ğŸ”¥ 9ë‹¨ê³„: __all__ ì •ì˜ (ëª…ì‹œì  export)
# ==============================================

__all__ = [
    # í‘œì¤€ ë¼ì´ë¸ŒëŸ¬ë¦¬
    'os', 'sys', 'gc', 'time', 'asyncio', 'logging', 'threading', 'traceback',
    'hashlib', 'json', 'base64', 'math', 'warnings', 'weakref', 'uuid',
    'subprocess', 'platform', 'datetime', 'timedelta',
    'Path', 'Dict', 'Any', 'Optional', 'Tuple', 'List', 'Union', 'Callable', 'TYPE_CHECKING', 'Set',
    'dataclass', 'field', 'Enum', 'IntEnum', 'BytesIO', 'StringIO', 'ThreadPoolExecutor',
    'lru_cache', 'wraps', 'partial', 'asynccontextmanager', 'contextmanager',
    'defaultdict', 'deque', 'chain',
    
    # AI/ML ë¼ì´ë¸ŒëŸ¬ë¦¬
    'np', 'torch', 'nn', 'F', 'DataLoader', 'autocast', 'transforms',
    'resize', 'to_pil_image', 'to_tensor',
    'Image', 'ImageEnhance', 'ImageFilter', 'ImageDraw', 'ImageFont', 'ImageOps',
    'cv2', 'scipy', 'ndimage', 'gaussian_filter', 'median_filter', 'convolve2d',
    'measure', 'morphology', 'segmentation', 'filters', 'restoration', 'exposure', 'ssim',
    'dcrf', 'unary_from_softmax', 'mp', 'YOLO', 'AutoModel', 'AutoTokenizer', 'sam', 'st',
    
    # ê°€ìš©ì„± ë³€ìˆ˜ë“¤
    'TORCH_AVAILABLE', 'MPS_AVAILABLE', 'CUDA_AVAILABLE', 'PIL_AVAILABLE', 'NUMPY_AVAILABLE',
    'CV2_AVAILABLE', 'SCIPY_AVAILABLE', 'SKIMAGE_AVAILABLE', 'DENSECRF_AVAILABLE',
    'MEDIAPIPE_AVAILABLE', 'ULTRALYTICS_AVAILABLE', 'TRANSFORMERS_AVAILABLE',
    'SAM_AVAILABLE', 'SAFETENSORS_AVAILABLE', 'EXCEPTIONS_AVAILABLE', 'MOCK_DIAGNOSTIC_AVAILABLE',
    
    # í™˜ê²½ ë³€ìˆ˜
    'IS_M3_MAX', 'CONDA_INFO', 'MEMORY_GB', 'DEVICE', 'TORCH_VERSION',
    
    # ì—ëŸ¬ ì²˜ë¦¬ ì‹œìŠ¤í…œ
    'MyClosetAIException', 'MockDataDetectionError', 'DataQualityError', 'ModelInferenceError',
    'ModelLoadingError', 'ImageProcessingError', 'DataValidationError', 'ConfigurationError',
    'error_tracker', 'detect_mock_data', 'log_detailed_error', 'create_mock_data_diagnosis_response',
    'track_exception', 'get_error_summary', 'create_exception_response', 'convert_to_mycloset_exception',
    'ErrorCodes',
    
    # Mock ì§„ë‹¨ ì‹œìŠ¤í…œ
    'MockDataDiagnostic', 'diagnose_step_data', 'get_diagnostic_summary', 'diagnostic_decorator',
    
    # Central Hub í•¨ìˆ˜ë“¤
    '_get_central_hub_container', 'get_base_step_mixin_class', '_inject_dependencies_safe',
    '_get_service_from_central_hub',
    
    # ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
    'detect_m3_max', 'detect_conda_env', 'get_available_libraries', 'log_library_status',
    'safe_copy', 'optimize_memory', 'get_optimal_device',
    
    # ê³µí†µ ìƒìˆ˜ë“¤
    'DEVICE_CPU', 'DEVICE_CUDA', 'DEVICE_MPS',
    'DEFAULT_INPUT_SIZE', 'DEFAULT_CONFIDENCE_THRESHOLD', 'DEFAULT_QUALITY_THRESHOLD', 'DEFAULT_BATCH_SIZE',
    'STEP_NAMES', 'ERROR_TEMPLATES', 'COCO_KEYPOINTS', 'HUMAN_PARSING_CLASSES'
]