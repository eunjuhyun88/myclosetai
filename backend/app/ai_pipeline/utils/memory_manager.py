# app/ai_pipeline/utils/memory_manager.py
"""
ğŸ”¥ MyCloset AI - DI ì™„ì „ í†µí•© ë©”ëª¨ë¦¬ ê´€ë¦¬ ì‹œìŠ¤í…œ v9.0
================================================================================
âœ… CircularReferenceFreeDIContainer ì™„ì „ ì—°ë™
âœ… DI íŒ¨í„´ìœ¼ë¡œ ì˜ì¡´ì„± ì£¼ì… ì§€ì›
âœ… BaseStepMixinê³¼ ì™„ë²½ í˜¸í™˜
âœ… ìˆœí™˜ì°¸ì¡° ì™„ì „ ë°©ì§€
âœ… ê¸°ì¡´ í´ë˜ìŠ¤ëª…/í•¨ìˆ˜ëª… 100% ìœ ì§€
âœ… DeviceManager í´ë˜ìŠ¤ ì™„ì „ êµ¬í˜„
âœ… setup_mps_compatibility ë©”ì„œë“œ êµ¬í˜„
âœ… RuntimeWarning: coroutine ì™„ì „ í•´ê²°
âœ… object dict can't be used in 'await' expression ì™„ì „ í•´ê²°
âœ… optimize_startup ë©”ì„œë“œ ì™„ì „ ë™ê¸°í™”
âœ… conda í™˜ê²½ ë©”ëª¨ë¦¬ ìµœì í™” í•¨ìˆ˜ ì™„ì „ ìˆ˜ì •
âœ… Mock í´ë°± êµ¬í˜„ì²´ í¬í•¨
âœ… M3 Max 128GB + conda í™˜ê²½ ì™„ì „ ìµœì í™”
âœ… ëª¨ë“  ë¹„ë™ê¸° ì˜¤ë¥˜ í•´ê²°
âœ… í”„ë¡œë•ì…˜ ë ˆë²¨ ì•ˆì •ì„±
âœ… main.py import ì˜¤ë¥˜ ì™„ì „ í•´ê²°
================================================================================
Author: MyCloset AI Team
Date: 2025-07-30
Version: 9.0 (DI Integration)
"""

import os
import gc
import threading
import time
import logging
import asyncio
import weakref
import platform
from typing import Dict, Any, Optional, Callable, List, Union, Tuple, TYPE_CHECKING, Protocol
from dataclasses import dataclass, field
from contextlib import contextmanager, asynccontextmanager
from functools import wraps, lru_cache
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor
from abc import ABC, abstractmethod

# ğŸ”¥ DI Container ì„í¬íŠ¸ (ìˆœí™˜ì°¸ì¡° ë°©ì§€)
if TYPE_CHECKING:
    # íƒ€ì… íŒíŒ…ìš© ì„í¬íŠ¸ (ëŸ°íƒ€ì„ì—ëŠ” ì‹¤í–‰ë˜ì§€ ì•ŠìŒ)
    from ..core.di_container import CircularReferenceFreeDIContainer
else:
    # ëŸ°íƒ€ì„ì—ëŠ” ë™ì  ì„í¬íŠ¸
    pass

# ê° íŒŒì¼ì— ì¶”ê°€í•  ê°œì„ ëœ ì½”ë“œ
import time
import threading

try:
    from app.core.gpu_config import safe_mps_empty_cache
except ImportError:
    # í´ë°± í•¨ìˆ˜
    def safe_mps_empty_cache():
        import gc
        gc.collect()
        return {"success": True, "method": "fallback_gc"}
    
# ==============================================
# ğŸ”¥ ì¡°ê±´ë¶€ ì„í¬íŠ¸ (ìˆœí™˜ì°¸ì¡° ë°©ì§€)
# ==============================================

# psutil ì„ íƒì  ì„í¬íŠ¸
try:
    import psutil
    PSUTIL_AVAILABLE = True
except ImportError:
    PSUTIL_AVAILABLE = False
    psutil = None

# PyTorch ì„ íƒì  ì„í¬íŠ¸
try:
    import torch
    TORCH_AVAILABLE = True
    TORCH_VERSION = torch.__version__
except ImportError:
    TORCH_AVAILABLE = False
    torch = None
    TORCH_VERSION = "not_available"

# NumPy ì„ íƒì  ì„í¬íŠ¸
try:
    import numpy as np
    NUMPY_AVAILABLE = True
except ImportError:
    NUMPY_AVAILABLE = False
    np = None

logger = logging.getLogger(__name__)

# ==============================================
# ğŸ”¥ DI ê´€ë ¨ ì¸í„°í˜ì´ìŠ¤ ë° í”„ë¡œí† ì½œ
# ==============================================

class IMemoryManager(Protocol):
    """MemoryManager ì¸í„°í˜ì´ìŠ¤ (DIìš©)"""
    
    def optimize_memory(self, aggressive: bool = False) -> Dict[str, Any]:
        """ë©”ëª¨ë¦¬ ìµœì í™”"""
        ...
    
    def optimize_startup(self, aggressive: bool = False) -> Dict[str, Any]:
        """ì‹œì‘ ì‹œ ë©”ëª¨ë¦¬ ìµœì í™”"""
        ...
    
    def cleanup_memory(self, aggressive: bool = False) -> Dict[str, Any]:
        """ë©”ëª¨ë¦¬ ì •ë¦¬"""
        ...
    
    def get_memory_stats(self) -> Any:
        """ë©”ëª¨ë¦¬ í†µê³„ ì¡°íšŒ"""
        ...
    
    def check_memory_pressure(self) -> Dict[str, Any]:
        """ë©”ëª¨ë¦¬ ì••ë°• ìƒíƒœ í™•ì¸"""
        ...

class IDeviceManager(Protocol):
    """DeviceManager ì¸í„°í˜ì´ìŠ¤ (DIìš©)"""
    
    def setup_mps_compatibility(self) -> bool:
        """MPS í˜¸í™˜ì„± ì„¤ì •"""
        ...
    
    def get_device(self) -> str:
        """í˜„ì¬ ë””ë°”ì´ìŠ¤ ë°˜í™˜"""
        ...
    
    def optimize_memory(self) -> None:
        """ë©”ëª¨ë¦¬ ìµœì í™”"""
        ...

class IDependencyInjectable(ABC):
    """DI ì£¼ì… ê°€ëŠ¥í•œ ì»´í¬ë„ŒíŠ¸ ì¸í„°í˜ì´ìŠ¤"""
    
    @abstractmethod
    def set_di_container(self, di_container: Any) -> None:
        """DI Container ì„¤ì •"""
        pass
    
    @abstractmethod
    def resolve_dependencies(self) -> bool:
        """ì˜ì¡´ì„± í•´ê²°"""
        pass
    
    @abstractmethod
    def get_dependency_status(self) -> Dict[str, Any]:
        """ì˜ì¡´ì„± ìƒíƒœ ì¡°íšŒ"""
        pass

# ==============================================
# ğŸ”¥ ì‹œìŠ¤í…œ ì •ë³´ ìºì‹± (í•œë²ˆë§Œ ì‹¤í–‰)
# ==============================================

@lru_cache(maxsize=1)
def _get_system_info() -> Dict[str, Any]:
    """ì‹œìŠ¤í…œ ì •ë³´ ìºì‹œ (M3 Max ê°ì§€ í¬í•¨)"""
    try:
        system_info = {
            "platform": platform.system(),
            "machine": platform.machine(),
            "cpu_count": os.cpu_count() or 4,
            "python_version": ".".join(map(str, platform.python_version_tuple()[:2])),
            "conda_env": os.environ.get('CONDA_DEFAULT_ENV', 'base'),
            "in_conda": 'CONDA_PREFIX' in os.environ,
            "torch_available": TORCH_AVAILABLE,
            "torch_version": TORCH_VERSION
        }
        
        # M3 Max ê°ì§€
        is_m3_max = False
        if platform.system() == 'Darwin' and platform.machine() == 'arm64':
            try:
                import subprocess
                result = subprocess.run(['sysctl', '-n', 'machdep.cpu.brand_string'], 
                                      capture_output=True, text=True, timeout=3)
                cpu_info = result.stdout.strip()
                is_m3_max = 'M3' in cpu_info and ('Max' in cpu_info or 'Pro' in cpu_info)
            except:
                pass
        
        system_info["is_m3_max"] = is_m3_max
        
        # ë©”ëª¨ë¦¬ ì •ë³´
        if PSUTIL_AVAILABLE:
            memory_gb = round(psutil.virtual_memory().total / (1024**3))
            system_info["memory_gb"] = memory_gb
        else:
            # M3 Max ê¸°ë³¸ê°’
            system_info["memory_gb"] = 128 if is_m3_max else 16
        
        # ë””ë°”ì´ìŠ¤ ê°ì§€
        device = "cpu"
        if TORCH_AVAILABLE:
            if torch.backends.mps.is_available():
                device = "mps"
            elif torch.cuda.is_available():
                device = "cuda"
        
        system_info["device"] = device
        
        return system_info
        
    except Exception as e:
        logger.warning(f"ì‹œìŠ¤í…œ ì •ë³´ ê°ì§€ ì‹¤íŒ¨: {e}")
        return {
            "platform": "unknown",
            "machine": "unknown", 
            "is_m3_max": False,
            "device": "cpu",
            "cpu_count": 4,
            "memory_gb": 16,
            "python_version": "3.8",
            "conda_env": "base",
            "in_conda": False,
            "torch_available": False,
            "torch_version": "not_available"
        }

# ì „ì—­ ì‹œìŠ¤í…œ ì •ë³´
SYSTEM_INFO = _get_system_info()

# ==============================================
# ğŸ”¥ ë°ì´í„° êµ¬ì¡° ì •ì˜
# ==============================================

@dataclass
class MemoryStats:
    """ë©”ëª¨ë¦¬ í†µê³„ ì •ë³´"""
    cpu_percent: float
    cpu_available_gb: float
    cpu_used_gb: float
    cpu_total_gb: float
    gpu_allocated_gb: float = 0.0
    gpu_reserved_gb: float = 0.0
    gpu_total_gb: float = 0.0
    swap_used_gb: float = 0.0
    cache_size_mb: float = 0.0
    process_memory_mb: float = 0.0
    m3_optimizations: Dict[str, Any] = field(default_factory=dict)

@dataclass
class MemoryConfig:
    """ë©”ëª¨ë¦¬ ê´€ë¦¬ ì„¤ì •"""
    device: str = "auto"
    memory_limit_gb: float = 16.0
    warning_threshold: float = 0.75
    critical_threshold: float = 0.9
    auto_cleanup: bool = True
    monitoring_interval: float = 30.0
    enable_caching: bool = True
    optimization_enabled: bool = True
    m3_max_features: bool = False

# ==============================================
# ğŸ”¥ DI í†µí•© DeviceManager í´ë˜ìŠ¤
# ==============================================

class DeviceManager(IDependencyInjectable):
    """
    ğŸ”¥ DI ì™„ì „ í†µí•© DeviceManager í´ë˜ìŠ¤
    âœ… CircularReferenceFreeDIContainer ì—°ë™
    âœ… ì˜ì¡´ì„± ì£¼ì… ì§€ì›
    âœ… setup_mps_compatibility ë©”ì„œë“œ í¬í•¨
    âœ… main.py import ì˜¤ë¥˜ ì™„ì „ í•´ê²°
    âœ… M3 Max íŠ¹í™” ìµœì í™”
    """
    
    def __init__(self, di_container: Optional[Any] = None):
        """ë””ë°”ì´ìŠ¤ ê´€ë¦¬ì ì´ˆê¸°í™” (DI ì§€ì›)"""
        self.device = self._detect_optimal_device()
        self.is_mps_available = False
        self.is_cuda_available = False
        self.logger = logging.getLogger("DeviceManager")
        
        # ğŸ”¥ DI Container ì„¤ì •
        self._di_container: Optional[Any] = None
        self._dependencies_resolved = False
        self._dependency_status = {
            'di_container': False,
            'memory_manager': False,
            'initialized': False
        }
        
        # ìŠ¤ë ˆë“œ ì•ˆì „ì„±
        self._lock = threading.RLock()
        
        self._init_device_info()
        
        # DI Container ì„¤ì • (ì´ˆê¸°í™” í›„)
        if di_container is not None:
            self.set_di_container(di_container)
        
        self.logger.debug(f"ğŸ® DI DeviceManager ì´ˆê¸°í™” ì™„ë£Œ - ë””ë°”ì´ìŠ¤: {self.device}")
    
    # ==============================================
    # ğŸ”¥ DI ì¸í„°í˜ì´ìŠ¤ êµ¬í˜„
    # ==============================================

    def set_di_container(self, di_container: Any) -> None:
        """DI Container ì„¤ì •"""
        try:
            with self._lock:
                self._di_container = di_container
                self._dependency_status['di_container'] = True
                
                # DI Containerì— ìì‹ ì„ ë“±ë¡
                if hasattr(di_container, 'register'):
                    di_container.register('device_manager', self, singleton=True)
                    di_container.register('IDeviceManager', self, singleton=True)
                
                self.logger.info("âœ… DeviceManager DI Container ì„¤ì • ì™„ë£Œ")
                
                # ì˜ì¡´ì„± í•´ê²° ì‹œë„
                self.resolve_dependencies()
                
        except Exception as e:
            self.logger.error(f"âŒ DeviceManager DI Container ì„¤ì • ì‹¤íŒ¨: {e}")

    def resolve_dependencies(self) -> bool:
        """ì˜ì¡´ì„± í•´ê²°"""
        try:
            with self._lock:
                if not self._di_container:
                    self.logger.warning("âš ï¸ DI Containerê°€ ì„¤ì •ë˜ì§€ ì•ŠìŒ")
                    return False
                
                resolved_count = 0
                
                # MemoryManager í•´ê²° (ì„ íƒì )
                try:
                    memory_manager = self._di_container.get('memory_manager')
                    if memory_manager:
                        self.memory_manager = memory_manager
                        self._dependency_status['memory_manager'] = True
                        resolved_count += 1
                        self.logger.debug("âœ… DeviceManager MemoryManager ì˜ì¡´ì„± í•´ê²°")
                except Exception as e:
                    self.logger.debug(f"DeviceManager MemoryManager í•´ê²° ì‹¤íŒ¨: {e}")
                
                self._dependencies_resolved = resolved_count >= 0  # DeviceManagerëŠ” í•„ìˆ˜ ì˜ì¡´ì„± ì—†ìŒ
                self.logger.info(f"ğŸ”— DeviceManager ì˜ì¡´ì„± í•´ê²° ì™„ë£Œ: {resolved_count}ê°œ")
                
                return self._dependencies_resolved
                
        except Exception as e:
            self.logger.error(f"âŒ DeviceManager ì˜ì¡´ì„± í•´ê²° ì‹¤íŒ¨: {e}")
            return False

    def get_dependency_status(self) -> Dict[str, Any]:
        """ì˜ì¡´ì„± ìƒíƒœ ì¡°íšŒ"""
        with self._lock:
            return {
                'class_name': self.__class__.__name__,
                'dependencies_resolved': self._dependencies_resolved,
                'dependency_status': dict(self._dependency_status),
                'di_container_available': self._di_container is not None,
                'device_info': {
                    'device': self.device,
                    'is_mps_available': self.is_mps_available,
                    'is_cuda_available': self.is_cuda_available,
                    'torch_available': TORCH_AVAILABLE
                },
                'system_info': SYSTEM_INFO
            }

    # ==============================================
    # ğŸ”¥ ê¸°ì¡´ ë©”ì„œë“œë“¤ (DI ìµœì í™” ì¶”ê°€)
    # ==============================================
    
    def _detect_optimal_device(self) -> str:
        """ìµœì  ë””ë°”ì´ìŠ¤ ê°ì§€"""
        try:
            if not TORCH_AVAILABLE:
                return "cpu"
            
            # M3 Max MPS ìš°ì„ 
            if hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
                self.is_mps_available = True
                return "mps"
            
            # CUDA í™•ì¸
            elif torch.cuda.is_available():
                self.is_cuda_available = True
                return "cuda"
            
            # CPU í´ë°±
            return "cpu"
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ ë””ë°”ì´ìŠ¤ ê°ì§€ ì‹¤íŒ¨: {e}")
            return "cpu"
    
    def _init_device_info(self):
        """ë””ë°”ì´ìŠ¤ ì •ë³´ ì´ˆê¸°í™”"""
        try:
            if not TORCH_AVAILABLE:
                return
            
            if self.device == "mps":
                # M3 Max ìµœì í™”
                self._setup_mps_optimization()
                
            elif self.device == "cuda":
                # CUDA ìµœì í™”
                if hasattr(torch.backends, 'cudnn'):
                    torch.backends.cudnn.benchmark = True
                
            self._dependency_status['initialized'] = True
                
        except Exception as e:
            self.logger.warning(f"âš ï¸ ë””ë°”ì´ìŠ¤ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    
    def _setup_mps_optimization(self):
        """MPS ìµœì í™” ì„¤ì •"""
        try:
            # M3 Max í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
            os.environ.update({
                'PYTORCH_MPS_HIGH_WATERMARK_RATIO': '0.0',
                'PYTORCH_MPS_LOW_WATERMARK_RATIO': '0.0',
                'METAL_DEVICE_WRAPPER_TYPE': '1',
                'METAL_PERFORMANCE_SHADERS_ENABLED': '1',
                'PYTORCH_MPS_PREFER_METAL': '1',
                'PYTORCH_ENABLE_MPS_FALLBACK': '1'
            })
            
            # ìŠ¤ë ˆë“œ ìµœì í™”
            if TORCH_AVAILABLE:
                torch.set_num_threads(min(16, SYSTEM_INFO["cpu_count"]))
            
            self.logger.debug("ğŸ MPS ìµœì í™” ì„¤ì • ì™„ë£Œ")
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ MPS ìµœì í™” ì‹¤íŒ¨: {e}")
    
    def setup_mps_compatibility(self):
        """
        ğŸ”¥ MPS í˜¸í™˜ì„± ì„¤ì • (main.pyì—ì„œ ìš”êµ¬í•˜ëŠ” í•µì‹¬ ë©”ì„œë“œ)
        âœ… import ì˜¤ë¥˜ ì™„ì „ í•´ê²°
        âœ… DI ìµœì í™” ì¶”ê°€
        """
        try:
            if not TORCH_AVAILABLE:
                self.logger.warning("âš ï¸ PyTorch ì—†ìŒ - MPS í˜¸í™˜ì„± ì„¤ì • ê±´ë„ˆëœ€")
                return False
            
            if not self.is_mps_available:
                self.logger.info("â„¹ï¸ MPS ì‚¬ìš© ë¶ˆê°€ - í˜¸í™˜ì„± ì„¤ì • ê±´ë„ˆëœ€")
                return False
            
            self.logger.info("ğŸ MPS í˜¸í™˜ì„± ì„¤ì • ì‹œì‘...")
            
            # 1. MPS ë©”ëª¨ë¦¬ ì •ë¦¬
            if hasattr(torch.mps, 'empty_cache'):
                safe_mps_empty_cache()
                self.logger.debug("âœ… MPS ë©”ëª¨ë¦¬ ì •ë¦¬ ì™„ë£Œ")
            
            # 2. MPS í™˜ê²½ ë³€ìˆ˜ ì¬ì„¤ì •
            self._setup_mps_optimization()
            
            # 3. MPS ë™ê¸°í™”
            if hasattr(torch.mps, 'synchronize'):
                try:
                    torch.mps.synchronize()
                    self.logger.debug("âœ… MPS ë™ê¸°í™” ì™„ë£Œ")
                except Exception as e:
                    self.logger.warning(f"âš ï¸ MPS ë™ê¸°í™” ì‹¤íŒ¨: {e}")
            
            # 4. í…ŒìŠ¤íŠ¸ í…ì„œ ìƒì„± (MPS ì‘ë™ í™•ì¸)
            try:
                test_tensor = torch.tensor([1.0], device='mps')
                test_result = test_tensor + 1
                self.logger.debug("âœ… MPS ì‘ë™ í™•ì¸ ì™„ë£Œ")
                del test_tensor, test_result
            except Exception as e:
                self.logger.warning(f"âš ï¸ MPS ì‘ë™ í™•ì¸ ì‹¤íŒ¨: {e}")
                return False
            
            # 5. DIë¥¼ í†µí•œ ë©”ëª¨ë¦¬ ìµœì í™” (ì„ íƒì )
            if hasattr(self, 'memory_manager') and self.memory_manager:
                try:
                    self.memory_manager.optimize_memory()
                    self.logger.debug("âœ… DI MemoryManagerë¥¼ í†µí•œ ìµœì í™” ì™„ë£Œ")
                except Exception:
                    pass  # ë©”ëª¨ë¦¬ ê´€ë¦¬ì ìµœì í™” ì‹¤íŒ¨ëŠ” ë¬´ì‹œ
            
            self.logger.info("âœ… MPS í˜¸í™˜ì„± ì„¤ì • ì™„ë£Œ")
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ MPS í˜¸í™˜ì„± ì„¤ì • ì‹¤íŒ¨: {e}")
            return False
    
    def get_device(self) -> str:
        """í˜„ì¬ ë””ë°”ì´ìŠ¤ ë°˜í™˜"""
        return self.device
    
    def get_device_info(self) -> Dict[str, Any]:
        """ë””ë°”ì´ìŠ¤ ì •ë³´ ë°˜í™˜"""
        try:
            info = {
                "device": self.device,
                "is_mps_available": self.is_mps_available,
                "is_cuda_available": self.is_cuda_available,
                "torch_available": TORCH_AVAILABLE,
                "torch_version": TORCH_VERSION,
                "system_info": SYSTEM_INFO,
                "di_integrated": self._di_container is not None,
                "dependencies_resolved": self._dependencies_resolved
            }
            
            if TORCH_AVAILABLE and self.device == "cuda":
                info.update({
                    "cuda_device_count": torch.cuda.device_count(),
                    "cuda_current_device": torch.cuda.current_device(),
                    "cuda_device_name": torch.cuda.get_device_name(0) if torch.cuda.device_count() > 0 else "N/A"
                })
            
            return info
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ ë””ë°”ì´ìŠ¤ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {"device": self.device, "error": str(e)}
    
    def optimize_memory(self):
        """ë©”ëª¨ë¦¬ ìµœì í™” (DI í†µí•©)"""
        try:
            # Python ê°€ë¹„ì§€ ì»¬ë ‰ì…˜
            gc.collect()
            
            if not TORCH_AVAILABLE:
                return
            
            if self.device == "mps":
                try:
                    if hasattr(torch.mps, 'synchronize'):
                        torch.mps.synchronize()
                    if hasattr(torch.mps, 'empty_cache'):
                        safe_mps_empty_cache()
                    self.logger.debug("âœ… MPS ë©”ëª¨ë¦¬ ìµœì í™” ì™„ë£Œ")
                except Exception as e:
                    self.logger.warning(f"âš ï¸ MPS ë©”ëª¨ë¦¬ ìµœì í™” ì‹¤íŒ¨: {e}")
                    
            elif self.device == "cuda":
                try:
                    torch.cuda.empty_cache()
                    torch.cuda.synchronize()
                    self.logger.debug("âœ… CUDA ë©”ëª¨ë¦¬ ìµœì í™” ì™„ë£Œ")
                except Exception as e:
                    self.logger.warning(f"âš ï¸ CUDA ë©”ëª¨ë¦¬ ìµœì í™” ì‹¤íŒ¨: {e}")
            
            # DIë¥¼ í†µí•œ ì¶”ê°€ ë©”ëª¨ë¦¬ ìµœì í™”
            if hasattr(self, 'memory_manager') and self.memory_manager:
                try:
                    self.memory_manager.optimize_memory()
                    self.logger.debug("âœ… DI MemoryManager ì¶”ê°€ ìµœì í™” ì™„ë£Œ")
                except Exception:
                    pass
                    
        except Exception as e:
            self.logger.warning(f"âš ï¸ ë©”ëª¨ë¦¬ ìµœì í™” ì‹¤íŒ¨: {e}")
    
    def get_memory_info(self) -> Dict[str, Any]:
        """ë©”ëª¨ë¦¬ ì •ë³´ ë°˜í™˜"""
        try:
            info = {
                'device': self.device,
                'allocated': 0,
                'cached': 0,
                'total': 0,
                'di_integrated': self._di_container is not None
            }
            
            if not TORCH_AVAILABLE:
                return info
            
            if self.device == "cuda" and torch.cuda.is_available():
                info.update({
                    'allocated': torch.cuda.memory_allocated(),
                    'cached': torch.cuda.memory_reserved(),
                    'total': torch.cuda.get_device_properties(0).total_memory
                })
            elif self.device == "mps":
                # MPSëŠ” ì •í™•í•œ ë©”ëª¨ë¦¬ ì •ë³´ë¥¼ ì œê³µí•˜ì§€ ì•Šìœ¼ë¯€ë¡œ ì¶”ì •ê°’ ì‚¬ìš©
                info.update({
                    'allocated': 2 * 1024**3,  # 2GB ì¶”ì •
                    'cached': 1 * 1024**3,     # 1GB ì¶”ì •
                    'total': SYSTEM_INFO["memory_gb"] * 1024**3
                })
            
            return info
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ ë©”ëª¨ë¦¬ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {
                'device': self.device,
                'allocated': 0,
                'cached': 0,
                'total': 0,
                'error': str(e)
            }
    
    def is_available(self) -> bool:
        """ë””ë°”ì´ìŠ¤ ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€"""
        try:
            if not TORCH_AVAILABLE:
                return False
            
            if self.device == "mps":
                return torch.backends.mps.is_available()
            elif self.device == "cuda":
                return torch.cuda.is_available()
            else:
                return True  # CPUëŠ” í•­ìƒ ì‚¬ìš© ê°€ëŠ¥
                
        except Exception:
            return False

# ==============================================
# ğŸ”¥ DI í†µí•© MemoryManager í´ë˜ìŠ¤
# ==============================================

class MemoryManager(IDependencyInjectable):
    """
    ğŸ”¥ DI ì™„ì „ í†µí•© ë©”ëª¨ë¦¬ ê´€ë¦¬ì
    âœ… CircularReferenceFreeDIContainer ì—°ë™
    âœ… ì˜ì¡´ì„± ì£¼ì… ì§€ì›
    âœ… GitHub êµ¬ì¡°ì™€ ì™„ë²½ í˜¸í™˜
    âœ… M3 Max 128GB + conda ì™„ì „ í™œìš©
    âœ… ëª¨ë“  async/await ì˜¤ë¥˜ í•´ê²°
    âœ… ê¸°ì¡´ ì¸í„°í˜ì´ìŠ¤ 100% ìœ ì§€
    """
    
    def __init__(
        self,
        device: Optional[str] = None,
        config: Optional[Dict[str, Any]] = None,
        di_container: Optional[Any] = None,
        **kwargs
    ):
        """ë©”ëª¨ë¦¬ ê´€ë¦¬ì ì´ˆê¸°í™” (DI ì§€ì›)"""
        
        # 1. ë””ë°”ì´ìŠ¤ ìë™ ê°ì§€
        self.device = device or SYSTEM_INFO["device"]
        
        # 2. ì„¤ì • êµ¬ì„±
        config_dict = config or {}
        config_dict.update(kwargs)
        
        # MemoryConfig ìƒì„±ì„ ìœ„í•œ í•„í„°ë§
        memory_config_fields = {
            'device', 'memory_limit_gb', 'warning_threshold', 'critical_threshold',
            'auto_cleanup', 'monitoring_interval', 'enable_caching', 'optimization_enabled', 'm3_max_features'
        }
        memory_config_args = {k: v for k, v in config_dict.items() if k in memory_config_fields}
        
        # M3 Max íŠ¹í™” ì„¤ì •
        if SYSTEM_INFO["is_m3_max"]:
            memory_config_args.setdefault("memory_limit_gb", SYSTEM_INFO["memory_gb"] * 0.8)
            memory_config_args.setdefault("m3_max_features", True)
        
        self.config = MemoryConfig(**memory_config_args)
        
        # 3. ê¸°ë³¸ ì†ì„±
        self.step_name = self.__class__.__name__
        self.logger = logging.getLogger(f"memory.{self.step_name}")
        
        # ğŸ”¥ DI Container ì„¤ì •
        self._di_container: Optional[Any] = None
        self._dependencies_resolved = False
        self._dependency_status = {
            'di_container': False,
            'device_manager': False,
            'data_converter': False,
            'initialized': False
        }
        
        # ìŠ¤ë ˆë“œ ì•ˆì „ì„±
        self._lock = threading.RLock()
        
        # 4. ì‹œìŠ¤í…œ íŒŒë¼ë¯¸í„°
        self.memory_gb = SYSTEM_INFO["memory_gb"]
        self.is_m3_max = SYSTEM_INFO["is_m3_max"]
        self.optimization_enabled = self.config.optimization_enabled
        
        # 5. ë©”ëª¨ë¦¬ ê´€ë¦¬ ì†ì„±
        if PSUTIL_AVAILABLE:
            total_memory = psutil.virtual_memory().total / 1024**3
            self.memory_limit_gb = total_memory * 0.8
        else:
            self.memory_limit_gb = self.config.memory_limit_gb
        
        # 6. ìƒíƒœ ì´ˆê¸°í™”
        self.is_initialized = False
        self._initialize_components()
        
        # 7. DI Container ì„¤ì • (ì´ˆê¸°í™” í›„)
        if di_container is not None:
            self.set_di_container(di_container)
        
        self.logger.debug(f"ğŸ¯ DI MemoryManager ì´ˆê¸°í™” - ë””ë°”ì´ìŠ¤: {self.device}, ë©”ëª¨ë¦¬: {self.memory_gb}GB")

    # ==============================================
    # ğŸ”¥ DI ì¸í„°í˜ì´ìŠ¤ êµ¬í˜„
    # ==============================================

    def set_di_container(self, di_container: Any) -> None:
        """DI Container ì„¤ì •"""
        try:
            with self._lock:
                self._di_container = di_container
                self._dependency_status['di_container'] = True
                
                # DI Containerì— ìì‹ ì„ ë“±ë¡
                if hasattr(di_container, 'register'):
                    di_container.register('memory_manager', self, singleton=True)
                    di_container.register('IMemoryManager', self, singleton=True)
                
                self.logger.info("âœ… MemoryManager DI Container ì„¤ì • ì™„ë£Œ")
                
                # ì˜ì¡´ì„± í•´ê²° ì‹œë„
                self.resolve_dependencies()
                
        except Exception as e:
            self.logger.error(f"âŒ MemoryManager DI Container ì„¤ì • ì‹¤íŒ¨: {e}")

    def resolve_dependencies(self) -> bool:
        """ì˜ì¡´ì„± í•´ê²°"""
        try:
            with self._lock:
                if not self._di_container:
                    self.logger.warning("âš ï¸ DI Containerê°€ ì„¤ì •ë˜ì§€ ì•ŠìŒ")
                    return False
                
                resolved_count = 0
                
                # DeviceManager í•´ê²° (ì„ íƒì )
                try:
                    device_manager = self._di_container.get('device_manager')
                    if device_manager:
                        self.device_manager = device_manager
                        self._dependency_status['device_manager'] = True
                        resolved_count += 1
                        self.logger.debug("âœ… MemoryManager DeviceManager ì˜ì¡´ì„± í•´ê²°")
                except Exception as e:
                    self.logger.debug(f"MemoryManager DeviceManager í•´ê²° ì‹¤íŒ¨: {e}")
                
                # DataConverter í•´ê²° (ì„ íƒì )
                try:
                    data_converter = self._di_container.get('data_converter')
                    if data_converter:
                        self.data_converter = data_converter
                        self._dependency_status['data_converter'] = True
                        resolved_count += 1
                        self.logger.debug("âœ… MemoryManager DataConverter ì˜ì¡´ì„± í•´ê²°")
                except Exception as e:
                    self.logger.debug(f"MemoryManager DataConverter í•´ê²° ì‹¤íŒ¨: {e}")
                
                self._dependencies_resolved = resolved_count >= 0  # MemoryManagerëŠ” í•„ìˆ˜ ì˜ì¡´ì„± ì—†ìŒ
                self.logger.info(f"ğŸ”— MemoryManager ì˜ì¡´ì„± í•´ê²° ì™„ë£Œ: {resolved_count}ê°œ")
                
                return self._dependencies_resolved
                
        except Exception as e:
            self.logger.error(f"âŒ MemoryManager ì˜ì¡´ì„± í•´ê²° ì‹¤íŒ¨: {e}")
            return False

    def get_dependency_status(self) -> Dict[str, Any]:
        """ì˜ì¡´ì„± ìƒíƒœ ì¡°íšŒ"""
        with self._lock:
            return {
                'class_name': self.__class__.__name__,
                'dependencies_resolved': self._dependencies_resolved,
                'dependency_status': dict(self._dependency_status),
                'di_container_available': self._di_container is not None,
                'memory_config': {
                    'device': self.device,
                    'memory_gb': self.memory_gb,
                    'is_m3_max': self.is_m3_max,
                    'optimization_enabled': self.optimization_enabled
                },
                'system_info': SYSTEM_INFO
            }

    # ==============================================
    # ğŸ”¥ ê¸°ì¡´ ë©”ì„œë“œë“¤ (DI ìµœì í™” ì¶”ê°€)
    # ==============================================

    def _initialize_components(self):
        """êµ¬ì„± ìš”ì†Œ ì´ˆê¸°í™”"""
        try:
            # ë©”ëª¨ë¦¬ í†µê³„
            self.stats_history = []
            self.max_history_length = 100
            
            # ìºì‹œ ì‹œìŠ¤í…œ
            self.tensor_cache = {}
            self.image_cache = {}
            self.model_cache = {}
            self.cache_priority = {}
            
            # ëª¨ë‹ˆí„°ë§
            self.monitoring_active = False
            self.monitoring_thread = None
            
            # M3 Max íŠ¹í™” ì†ì„± ì´ˆê¸°í™”
            if self.is_m3_max:
                self.precision_mode = 'float16'  # M3 Maxì—ì„œ float16 ì‚¬ìš©
                self.memory_pools = {}
                self.optimal_batch_sizes = {}
                
                # M3 Max ìµœì í™” ìˆ˜í–‰
                if self.optimization_enabled:
                    self._optimize_for_m3_max()
            else:
                self.precision_mode = 'float32'
            
            # ì´ˆê¸°í™” ì™„ë£Œ
            self.is_initialized = True
            self._dependency_status['initialized'] = True
            
            self.logger.debug(f"ğŸ§  MemoryManager êµ¬ì„± ìš”ì†Œ ì´ˆê¸°í™” ì™„ë£Œ")
            
        except Exception as e:
            self.logger.error(f"âŒ êµ¬ì„± ìš”ì†Œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            # ìµœì†Œí•œì˜ ì´ˆê¸°í™”
            self.tensor_cache = {}
            self.is_initialized = True

    def optimize_startup(self, aggressive: bool = False) -> Dict[str, Any]:
        """
        ğŸš€ ì‹œìŠ¤í…œ ì‹œì‘ ì‹œ ë©”ëª¨ë¦¬ ìµœì í™” (ì™„ì „ ë™ê¸°í™” + DI í†µí•©)
        âœ… ëª¨ë“  async/await ì˜¤ë¥˜ ì™„ì „ í•´ê²°
        âœ… RuntimeWarning ì™„ì „ í•´ê²°
        âœ… DIë¥¼ í†µí•œ ì¶”ê°€ ìµœì í™”
        """
        try:
            start_time = time.time()
            startup_results = []
            
            self.logger.info("ğŸš€ ì‹œìŠ¤í…œ ì‹œì‘ ë©”ëª¨ë¦¬ ìµœì í™” ì‹œì‘ (DI í†µí•©)")
            
            # 1. ê¸°ë³¸ ë©”ëª¨ë¦¬ ìµœì í™” ì‹¤í–‰ (ë™ê¸° ë°©ì‹)
            try:
                optimize_result = self._synchronous_optimize_memory()
                if optimize_result.get('success', False):
                    startup_results.append("ê¸°ë³¸ ë©”ëª¨ë¦¬ ìµœì í™” ì™„ë£Œ")
                else:
                    startup_results.append("ê¸°ë³¸ ë©”ëª¨ë¦¬ ìµœì í™” ì‹¤íŒ¨")
            except Exception as e:
                startup_results.append(f"ê¸°ë³¸ ë©”ëª¨ë¦¬ ìµœì í™” ì˜¤ë¥˜: {e}")
            
            # 2. DIë¥¼ í†µí•œ ì¶”ê°€ ìµœì í™”
            try:
                if hasattr(self, 'device_manager') and self.device_manager:
                    self.device_manager.optimize_memory()
                    startup_results.append("DI DeviceManager ìµœì í™” ì™„ë£Œ")
                
                if hasattr(self, 'data_converter') and self.data_converter:
                    # DataConverterì— ë©”ëª¨ë¦¬ ìµœì í™”ê°€ ìˆë‹¤ë©´ í˜¸ì¶œ
                    if hasattr(self.data_converter, 'optimize_memory'):
                        self.data_converter.optimize_memory()
                    startup_results.append("DI DataConverter ìµœì í™” ì™„ë£Œ")
            except Exception as e:
                startup_results.append(f"DI ì¶”ê°€ ìµœì í™” ì‹¤íŒ¨: {e}")
            
            # 3. ì‹œìŠ¤í…œ ì‹œì‘ íŠ¹í™” ìµœì í™”
            try:
                # Python ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ ê°•í™”
                collected = 0
                for gen in range(3):
                    collected += gc.collect()
                startup_results.append(f"ì‹œì‘ ì‹œ ê°€ë¹„ì§€ ì»¬ë ‰ì…˜: {collected}ê°œ ê°ì²´")
                
                # M3 Max íŠ¹í™” ì‹œì‘ ìµœì í™”
                if self.is_m3_max:
                    self._optimize_m3_max_startup()
                    startup_results.append("M3 Max ì‹œì‘ ìµœì í™” ì™„ë£Œ")
                
                # conda í™˜ê²½ íŠ¹í™” ì„¤ì • (ë™ê¸° ë°©ì‹)
                if SYSTEM_INFO.get("in_conda", False):
                    conda_result = setup_conda_memory_optimization()
                    if conda_result:
                        startup_results.append("conda í™˜ê²½ ìµœì í™” ì™„ë£Œ")
                    else:
                        startup_results.append("conda í™˜ê²½ ìµœì í™” ì‹¤íŒ¨")
                
            except Exception as e:
                startup_results.append(f"ì‹œì‘ íŠ¹í™” ìµœì í™” ì‹¤íŒ¨: {e}")
            
            # 4. ë©”ëª¨ë¦¬ ìƒíƒœ ì²´í¬
            try:
                stats = self.get_memory_stats()
                available_ratio = stats.cpu_available_gb / max(1.0, stats.cpu_total_gb)
                startup_results.append(f"ë©”ëª¨ë¦¬ ê°€ìš©ë¥ : {available_ratio:.1%}")
            except Exception as e:
                startup_results.append(f"ë©”ëª¨ë¦¬ ìƒíƒœ í™•ì¸ ì‹¤íŒ¨: {e}")
            
            startup_time = time.time() - start_time
            
            self.logger.info(f"âœ… ì‹œìŠ¤í…œ ì‹œì‘ ë©”ëª¨ë¦¬ ìµœì í™” ì™„ë£Œ ({startup_time:.2f}ì´ˆ)")
            
            return {
                "success": True,
                "message": "ì‹œìŠ¤í…œ ì‹œì‘ ë©”ëª¨ë¦¬ ìµœì í™” ì™„ë£Œ (DI í†µí•©)",
                "startup_time": startup_time,
                "startup_results": startup_results,
                "device": self.device,
                "is_m3_max": self.is_m3_max,
                "conda_optimized": SYSTEM_INFO.get("in_conda", False),
                "di_integrated": self._di_container is not None,
                "dependencies_resolved": self._dependencies_resolved,
                "timestamp": time.time()
            }
            
        except Exception as e:
            self.logger.error(f"âŒ ì‹œìŠ¤í…œ ì‹œì‘ ë©”ëª¨ë¦¬ ìµœì í™” ì‹¤íŒ¨: {e}")
            return {
                "success": False,
                "error": str(e),
                "message": "ì‹œìŠ¤í…œ ì‹œì‘ ë©”ëª¨ë¦¬ ìµœì í™” ì‹¤íŒ¨",
                "device": self.device,
                "di_integrated": self._di_container is not None,
                "timestamp": time.time()
            }
    
    def _synchronous_optimize_memory(self) -> Dict[str, Any]:
        """ë™ê¸° ë©”ëª¨ë¦¬ ìµœì í™” (await ì‚¬ìš© ì•ˆí•¨ + DI í†µí•©)"""
        try:
            start_time = time.time()
            optimization_results = []
            
            # 1. ë©”ëª¨ë¦¬ ì •ë¦¬ ìˆ˜í–‰
            cleanup_result = self.cleanup_memory(aggressive=False)
            optimization_results.append(f"ë©”ëª¨ë¦¬ ì •ë¦¬: {cleanup_result.get('success', False)}")
            
            # 2. M3 Max íŠ¹í™” ìµœì í™” (ë™ê¸°)
            if self.is_m3_max:
                m3_result = self._optimize_m3_max_memory_sync()
                optimization_results.append(f"M3 Max ìµœì í™”: {m3_result}")
            
            # 3. ìºì‹œ ìµœì í™”
            cache_stats = self._optimize_cache_system()
            optimization_results.append(f"ìºì‹œ ìµœì í™”: {cache_stats}")
            
            # 4. DIë¥¼ í†µí•œ ì¶”ê°€ ìµœì í™”
            if self._di_container:
                try:
                    # DeviceManagerë¥¼ í†µí•œ ì¶”ê°€ ìµœì í™”
                    if hasattr(self, 'device_manager') and self.device_manager:
                        self.device_manager.optimize_memory()
                        optimization_results.append("DI DeviceManager ìµœì í™” ì™„ë£Œ")
                except Exception as e:
                    optimization_results.append(f"DI ìµœì í™” ì‹¤íŒ¨: {str(e)[:50]}")
            
            # 5. ë©”ëª¨ë¦¬ ì••ë°• ìƒíƒœ í™•ì¸
            pressure_info = self.check_memory_pressure()
            optimization_results.append(f"ë©”ëª¨ë¦¬ ì••ë°•: {pressure_info.get('status', 'unknown')}")
            
            optimization_time = time.time() - start_time
            
            return {
                "success": True,
                "message": "ë©”ëª¨ë¦¬ ìµœì í™” ì™„ë£Œ (DI í†µí•©)",
                "optimization_time": optimization_time,
                "optimization_results": optimization_results,
                "device": self.device,
                "m3_max_optimized": self.is_m3_max,
                "di_integrated": self._di_container is not None,
                "timestamp": time.time()
            }
            
        except Exception as e:
            self.logger.error(f"âŒ ë™ê¸° ë©”ëª¨ë¦¬ ìµœì í™” ì‹¤íŒ¨: {e}")
            return {
                "success": False,
                "error": str(e),
                "device": self.device,
                "timestamp": time.time()
            }
    
    def _optimize_m3_max_memory_sync(self):
        """M3 Max íŠ¹í™” ë©”ëª¨ë¦¬ ìµœì í™” (ë™ê¸° ë²„ì „)"""
        try:
            if not self.is_m3_max:
                return False
            
            # M3 Max ìµœì í™” ì‹¤í–‰
            if hasattr(self, '_optimize_for_m3_max'):
                self._optimize_for_m3_max()
            
            # M3 Max MPS ìºì‹œ ì •ë¦¬
            if TORCH_AVAILABLE and torch.backends.mps.is_available():
                if hasattr(torch.mps, 'empty_cache'):
                    safe_mps_empty_cache()
            
            return True
        
        except Exception as e:
            self.logger.warning(f"âš ï¸ M3 Max ë©”ëª¨ë¦¬ ìµœì í™” ì‹¤íŒ¨: {e}")
            return False
    
    def _optimize_m3_max_startup(self):
        """M3 Max ì‹œì‘ ì‹œ íŠ¹í™” ìµœì í™”"""
        try:
            if not self.is_m3_max:
                return
            
            # M3 Max ì‹œì‘ ì‹œ í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
            startup_env = {
                'PYTORCH_MPS_HIGH_WATERMARK_RATIO': '0.0',
                'PYTORCH_MPS_LOW_WATERMARK_RATIO': '0.0',
                'PYTORCH_ENABLE_MPS_FALLBACK': '1',
                'METAL_PERFORMANCE_SHADERS_ENABLED': '1'
            }
            
            os.environ.update(startup_env)
            
            # PyTorch MPS ì‚¬ì „ ì›Œë°ì—…
            if TORCH_AVAILABLE and torch.backends.mps.is_available():
                try:
                    # MPS ìºì‹œ ì‚¬ì „ ì •ë¦¬
                    if hasattr(torch.mps, 'empty_cache'):
                        safe_mps_empty_cache()
                    
                    # ìŠ¤ë ˆë“œ ìˆ˜ ìµœì í™”
                    torch.set_num_threads(min(16, SYSTEM_INFO["cpu_count"]))
                    
                except Exception as e:
                    self.logger.warning(f"âš ï¸ M3 Max MPS ì›Œë°ì—… ì‹¤íŒ¨: {e}")
            
            self.logger.debug("ğŸ M3 Max ì‹œì‘ ìµœì í™” ì™„ë£Œ")
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ M3 Max ì‹œì‘ ìµœì í™” ì‹¤íŒ¨: {e}")

    def _optimize_for_m3_max(self):
        """ğŸ M3 Max Neural Engine + conda ìµœì í™”"""
        try:
            if not self.is_m3_max:
                return False
                
            self.logger.debug("ğŸ M3 Max ìµœì í™” ì‹œì‘")
            optimizations = []
            
            # 1. PyTorch MPS ë°±ì—”ë“œ ìµœì í™”
            if TORCH_AVAILABLE and torch.backends.mps.is_available():
                try:
                    # MPS ë©”ëª¨ë¦¬ ì •ë¦¬
                    if hasattr(torch.mps, 'empty_cache'):
                        safe_mps_empty_cache()
                        optimizations.append("MPS cache clearing")
                    
                    # M3 Max í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
                    os.environ.update({
                        'PYTORCH_MPS_HIGH_WATERMARK_RATIO': '0.0',
                        'PYTORCH_MPS_LOW_WATERMARK_RATIO': '0.0',
                        'METAL_DEVICE_WRAPPER_TYPE': '1',
                        'METAL_PERFORMANCE_SHADERS_ENABLED': '1',
                        'PYTORCH_MPS_PREFER_METAL': '1',
                        'PYTORCH_ENABLE_MPS_FALLBACK': '1'
                    })
                    optimizations.append("MPS environment optimization")
                    
                    # ìŠ¤ë ˆë“œ ìµœì í™”
                    torch.set_num_threads(min(16, SYSTEM_INFO["cpu_count"]))
                    optimizations.append(f"Thread optimization ({torch.get_num_threads()} threads)")
                    
                except Exception as e:
                    self.logger.warning(f"âš ï¸ MPS ìµœì í™” ì¼ë¶€ ì‹¤íŒ¨: {e}")
            
            # 2. ë©”ëª¨ë¦¬ í’€ ìµœì í™”
            self._setup_m3_memory_pools()
            optimizations.append("Memory pool optimization")
            
            # 3. ë°°ì¹˜ í¬ê¸° ìµœì í™”
            self._optimize_batch_sizes()
            optimizations.append("Batch size optimization")
            
            # 4. conda í™˜ê²½ íŠ¹í™” ìµœì í™”
            if SYSTEM_INFO["in_conda"]:
                self._setup_conda_optimizations()
                optimizations.append("Conda environment optimization")
            
            self.logger.info("âœ… M3 Max ìµœì í™” ì™„ë£Œ")
            for opt in optimizations:
                self.logger.debug(f"   - {opt}")
            
            return True
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ M3 Max ìµœì í™” ì‹¤íŒ¨: {e}")
            return False

    def _setup_m3_memory_pools(self):
        """M3 Max ë©”ëª¨ë¦¬ í’€ ì„¤ì •"""
        try:
            # 128GB ê¸°ì¤€ ë©”ëª¨ë¦¬ í’€ ìµœì í™”
            pool_size_gb = self.memory_gb * 0.8
            
            self.memory_pools = {
                "model_cache": pool_size_gb * 0.4,      # 40% - ëª¨ë¸ ìºì‹œ
                "inference": pool_size_gb * 0.3,        # 30% - ì¶”ë¡  ì‘ì—…
                "preprocessing": pool_size_gb * 0.2,    # 20% - ì „ì²˜ë¦¬
                "buffer": pool_size_gb * 0.1            # 10% - ë²„í¼
            }
            
            self.logger.debug(f"ğŸ M3 Max ë©”ëª¨ë¦¬ í’€ ì„¤ì •: {pool_size_gb:.1f}GB")
                
        except Exception as e:
            self.logger.warning(f"âš ï¸ M3 ë©”ëª¨ë¦¬ í’€ ì„¤ì • ì‹¤íŒ¨: {e}")

    def _optimize_batch_sizes(self):
        """M3 Max ë°°ì¹˜ í¬ê¸° ìµœì í™”"""
        try:
            if self.is_m3_max:
                # M3 Max 128GB ê¸°ì¤€ ìµœì  ë°°ì¹˜ í¬ê¸°
                self.optimal_batch_sizes = {
                    "human_parsing": 16,
                    "pose_estimation": 20,
                    "cloth_segmentation": 12,
                    "virtual_fitting": 8,
                    "super_resolution": 4
                }
            else:
                # ì¼ë°˜ ì‹œìŠ¤í…œ ë°°ì¹˜ í¬ê¸°
                self.optimal_batch_sizes = {
                    "human_parsing": 4,
                    "pose_estimation": 6,
                    "cloth_segmentation": 3,
                    "virtual_fitting": 2,
                    "super_resolution": 1
                }
            
            self.logger.debug(f"âš™ï¸ ë°°ì¹˜ í¬ê¸° ìµœì í™” ì™„ë£Œ")
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ ë°°ì¹˜ í¬ê¸° ìµœì í™” ì‹¤íŒ¨: {e}")

    def _setup_conda_optimizations(self):
        """conda í™˜ê²½ íŠ¹í™” ìµœì í™”"""
        try:
            if not SYSTEM_INFO["in_conda"]:
                return
            
            # NumPy ìµœì í™”
            if NUMPY_AVAILABLE:
                os.environ['OMP_NUM_THREADS'] = str(min(8, SYSTEM_INFO["cpu_count"]))
                os.environ['MKL_NUM_THREADS'] = str(min(8, SYSTEM_INFO["cpu_count"]))
                
            self.logger.debug("âœ… conda í™˜ê²½ ìµœì í™” ì„¤ì • ì™„ë£Œ")
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ conda ìµœì í™” ì‹¤íŒ¨: {e}")

    def optimize(self) -> Dict[str, Any]:
        """
        ë©”ëª¨ë¦¬ ìµœì í™” (optimize_memoryì˜ ë³„ì¹­ + DI í†µí•©)
        
        VirtualFittingStepê³¼ ë‹¤ë¥¸ Stepë“¤ì—ì„œ í˜¸ì¶œë˜ëŠ” í‘œì¤€ ì¸í„°í˜ì´ìŠ¤
        """
        return self.optimize_memory()
    
    async def optimize_async(self) -> Dict[str, Any]:
        """
        ë¹„ë™ê¸° ë©”ëª¨ë¦¬ ìµœì í™” (í˜¸í™˜ì„± + DI í†µí•©)
        """
        try:
            import asyncio
            loop = asyncio.get_event_loop()
            # ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰ (blocking ì‘ì—…)
            result = await loop.run_in_executor(None, self.optimize_memory)
            self.logger.debug("âœ… ë¹„ë™ê¸° ë©”ëª¨ë¦¬ ìµœì í™” ì™„ë£Œ")
            return result
        except Exception as e:
            self.logger.error(f"âŒ ë¹„ë™ê¸° ë©”ëª¨ë¦¬ ìµœì í™” ì‹¤íŒ¨: {e}")
            return {
                "success": False,
                "error": str(e),
                "method": "async_fallback"
            }
    
    def get_memory_status(self) -> Dict[str, Any]:
        """
        ë©”ëª¨ë¦¬ ìƒíƒœ ì¡°íšŒ (Stepë“¤ì—ì„œ ì‚¬ìš© + DI í†µí•©)
        """
        try:
            stats = self.get_memory_stats()
            return {
                "total_optimizations": getattr(self, 'optimization_count', 0),
                "device": self.device,
                "is_m3_max": self.is_m3_max,
                "cpu_used_gb": stats.cpu_used_gb,
                "cpu_available_gb": stats.cpu_available_gb,
                "gpu_allocated_gb": stats.gpu_allocated_gb,
                "last_optimization": getattr(self, 'last_optimization_time', None),
                "available": True,
                "di_integrated": self._di_container is not None,
                "dependencies_resolved": self._dependencies_resolved
            }
        except Exception as e:
            return {
                "error": str(e),
                "available": False,
                "di_integrated": self._di_container is not None
            }
    
    def cleanup(self) -> bool:
        """
        ë©”ëª¨ë¦¬ ë§¤ë‹ˆì € ì •ë¦¬ (Stepë“¤ì—ì„œ ì‚¬ìš© + DI í†µí•©)
        """
        try:
            # ë§ˆì§€ë§‰ ìµœì í™” ì‹¤í–‰
            result = self.optimize_memory()
            
            # í†µê³„ ë¦¬ì…‹
            if hasattr(self, 'optimization_count'):
                self.optimization_count = 0
            
            # DIë¥¼ í†µí•œ ì¶”ê°€ ì •ë¦¬
            if hasattr(self, 'device_manager') and self.device_manager:
                try:
                    self.device_manager.optimize_memory()
                except Exception:
                    pass
            
            self.logger.debug("âœ… DI MemoryManager ì •ë¦¬ ì™„ë£Œ")
            return result.get('success', True)
            
        except Exception as e:
            self.logger.error(f"âŒ DI MemoryManager ì •ë¦¬ ì‹¤íŒ¨: {e}")
            return False
    
    def cleanup_memory(self, aggressive: bool = False) -> Dict[str, Any]:
        """ğŸ§¹ ë©”ëª¨ë¦¬ ì •ë¦¬ (DI ìµœì í™”)"""
        try:
            start_time = time.time()
            
            # 1. Python ê°€ë¹„ì§€ ì»¬ë ‰ì…˜
            collected_objects = 0
            for _ in range(3):
                collected = gc.collect()
                collected_objects += collected
            
            # 2. ìºì‹œ ì •ë¦¬
            cache_cleared = 0
            if hasattr(self, 'tensor_cache'):
                cache_cleared += len(self.tensor_cache)
                if aggressive:
                    self.clear_cache(aggressive=True)
                else:
                    self._evict_low_priority_cache()
            
            # 3. PyTorch ë©”ëª¨ë¦¬ ì •ë¦¬
            if TORCH_AVAILABLE:
                try:
                    if self.device == "mps" and torch.backends.mps.is_available():
                        # M3 Max MPS ë©”ëª¨ë¦¬ ì •ë¦¬
                        if hasattr(torch.mps, 'empty_cache'):
                            safe_mps_empty_cache()
                        
                        # MPS ë™ê¸°í™”
                        if hasattr(torch.mps, 'synchronize'):
                            torch.mps.synchronize()
                        
                        # ê³µê²©ì  ì •ë¦¬ ì‹œ M3 Max íŠ¹í™” ì •ë¦¬
                        if aggressive and self.is_m3_max:
                            self._aggressive_m3_cleanup()
                        
                    elif self.device == "cuda" and torch.cuda.is_available():
                        torch.cuda.empty_cache()
                        if aggressive:
                            torch.cuda.synchronize()
                        
                except Exception as e:
                    self.logger.warning(f"âš ï¸ GPU ë©”ëª¨ë¦¬ ì •ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
            
            # 4. DIë¥¼ í†µí•œ ì¶”ê°€ ì •ë¦¬
            if self._di_container:
                try:
                    if hasattr(self, 'device_manager') and self.device_manager:
                        self.device_manager.optimize_memory()
                except Exception:
                    pass  # DI ì¶”ê°€ ì •ë¦¬ ì‹¤íŒ¨ëŠ” ë¬´ì‹œ
            
            cleanup_time = time.time() - start_time
            
            # ê²°ê³¼ ë°˜í™˜
            return {
                "success": True,
                "cleanup_time": cleanup_time,
                "collected_objects": collected_objects,
                "cache_cleared": cache_cleared,
                "aggressive": aggressive,
                "device": self.device,
                "m3_optimized": self.is_m3_max,
                "di_integrated": self._di_container is not None
            }
            
        except Exception as e:
            self.logger.error(f"âŒ ë©”ëª¨ë¦¬ ì •ë¦¬ ì‹¤íŒ¨: {e}")
            return {
                "success": False,
                "error": str(e),
                "device": self.device
            }

    def optimize_memory(self) -> Dict[str, Any]:
        """
        ğŸ”¥ ë©”ëª¨ë¦¬ ìµœì í™” (ì™„ì „ ë™ê¸°í™” + DI í†µí•©)
        âœ… ëª¨ë“  async/await ì˜¤ë¥˜ í•´ê²°
        âœ… VirtualFittingStep í˜¸í™˜ì„± ìœ ì§€
        âœ… DIë¥¼ í†µí•œ ì¶”ê°€ ìµœì í™”
        """
        try:
            start_time = time.time()
            optimization_results = []
            
            # 1. ë©”ëª¨ë¦¬ ì •ë¦¬ ìˆ˜í–‰
            cleanup_result = self.cleanup_memory(aggressive=False)
            optimization_results.append(f"ë©”ëª¨ë¦¬ ì •ë¦¬: {cleanup_result.get('success', False)}")
            
            # 2. M3 Max íŠ¹í™” ìµœì í™”
            if self.is_m3_max:
                m3_result = self._optimize_m3_max_memory_sync()
                optimization_results.append(f"M3 Max ìµœì í™”: {m3_result}")
            
            # 3. ìºì‹œ ìµœì í™”
            cache_stats = self._optimize_cache_system()
            optimization_results.append(f"ìºì‹œ ìµœì í™”: {cache_stats}")
            
            # 4. DIë¥¼ í†µí•œ ì¶”ê°€ ìµœì í™”
            if self._di_container:
                try:
                    # DeviceManagerë¥¼ í†µí•œ ë©”ëª¨ë¦¬ ìµœì í™”
                    if hasattr(self, 'device_manager') and self.device_manager:
                        self.device_manager.optimize_memory()
                        optimization_results.append("DI DeviceManager ìµœì í™” ì™„ë£Œ")
                    
                    # DataConverterë¥¼ í†µí•œ ë©”ëª¨ë¦¬ ìµœì í™” (ìˆë‹¤ë©´)
                    if hasattr(self, 'data_converter') and self.data_converter:
                        if hasattr(self.data_converter, 'optimize_memory'):
                            self.data_converter.optimize_memory()
                            optimization_results.append("DI DataConverter ìµœì í™” ì™„ë£Œ")
                
                except Exception as e:
                    optimization_results.append(f"DI ì¶”ê°€ ìµœì í™” ì‹¤íŒ¨: {str(e)[:50]}")
            
            # 5. ë©”ëª¨ë¦¬ ì••ë°• ìƒíƒœ í™•ì¸
            pressure_info = self.check_memory_pressure()
            optimization_results.append(f"ë©”ëª¨ë¦¬ ì••ë°•: {pressure_info.get('status', 'unknown')}")
            
            optimization_time = time.time() - start_time
            
            return {
                "success": True,
                "message": "ë©”ëª¨ë¦¬ ìµœì í™” ì™„ë£Œ (DI í†µí•©)",
                "optimization_time": optimization_time,
                "optimization_results": optimization_results,
                "device": self.device,
                "m3_max_optimized": self.is_m3_max,
                "di_integrated": self._di_container is not None,
                "dependencies_resolved": self._dependencies_resolved,
                "timestamp": time.time()
            }
            
        except Exception as e:
            self.logger.error(f"âŒ ë©”ëª¨ë¦¬ ìµœì í™” ì‹¤íŒ¨: {e}")
            return {
                "success": False,
                "error": str(e),
                "device": self.device,
                "timestamp": time.time()
            }

    def _optimize_cache_system(self) -> str:
        """ìºì‹œ ì‹œìŠ¤í…œ ìµœì í™”"""
        try:
            # ìºì‹œ í¬ê¸° ì²´í¬
            total_cache_size = 0
            cache_counts = {}
            
            for cache_name in ['tensor_cache', 'image_cache', 'model_cache']:
                if hasattr(self, cache_name):
                    cache = getattr(self, cache_name)
                    size = len(cache)
                    total_cache_size += size
                    cache_counts[cache_name] = size
            
            # ìºì‹œê°€ ë„ˆë¬´ í´ ê²½ìš° ì •ë¦¬
            if total_cache_size > 100:  # ìºì‹œ í•­ëª©ì´ 100ê°œ ì´ìƒ
                self._evict_low_priority_cache()
                return f"ìºì‹œ ì •ë¦¬ë¨ (ì´ì „: {total_cache_size}ê°œ)"
            
            return f"ì •ìƒ ({total_cache_size}ê°œ í•­ëª©)"
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ ìºì‹œ ìµœì í™” ì‹¤íŒ¨: {e}")
            return "ìµœì í™” ì‹¤íŒ¨"
    
    def _aggressive_m3_cleanup(self):
        """ê³µê²©ì  M3 Max ë©”ëª¨ë¦¬ ì •ë¦¬"""
        try:
            # ëª¨ë“  ìºì‹œ í´ë¦¬ì–´
            for cache_name in ['tensor_cache', 'image_cache', 'model_cache']:
                if hasattr(self, cache_name):
                    getattr(self, cache_name).clear()
            
            # ë°˜ë³µ ê°€ë¹„ì§€ ì»¬ë ‰ì…˜
            for _ in range(5):
                gc.collect()
            
            # PyTorch MPS ìºì‹œ ì •ë¦¬
            if TORCH_AVAILABLE and hasattr(torch.mps, 'empty_cache'):
                safe_mps_empty_cache()
            
            self.logger.debug("ğŸ ê³µê²©ì  M3 Max ë©”ëª¨ë¦¬ ì •ë¦¬ ì™„ë£Œ")
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ ê³µê²©ì  ë©”ëª¨ë¦¬ ì •ë¦¬ ì‹¤íŒ¨: {e}")

    def get_memory_stats(self) -> MemoryStats:
        """í˜„ì¬ ë©”ëª¨ë¦¬ ìƒíƒœ ì¡°íšŒ (DI í†µí•©)"""
        try:
            # CPU ë©”ëª¨ë¦¬
            if PSUTIL_AVAILABLE:
                memory = psutil.virtual_memory()
                cpu_percent = memory.percent
                cpu_total_gb = memory.total / 1024**3
                cpu_used_gb = memory.used / 1024**3
                cpu_available_gb = memory.available / 1024**3
                swap_used_gb = psutil.swap_memory().used / 1024**3
                
                # í”„ë¡œì„¸ìŠ¤ ë©”ëª¨ë¦¬
                try:
                    process = psutil.Process()
                    process_memory_mb = process.memory_info().rss / 1024**2
                except:
                    process_memory_mb = 0.0
            else:
                cpu_percent = 50.0
                cpu_total_gb = self.memory_gb
                cpu_used_gb = self.memory_gb * 0.5
                cpu_available_gb = self.memory_gb * 0.5
                swap_used_gb = 0.0
                process_memory_mb = 0.0
            
            # GPU ë©”ëª¨ë¦¬
            gpu_allocated_gb = 0.0
            gpu_reserved_gb = 0.0
            gpu_total_gb = 0.0
            
            if TORCH_AVAILABLE:
                try:
                    if self.device == "cuda" and torch.cuda.is_available():
                        gpu_allocated_gb = torch.cuda.memory_allocated() / 1024**3
                        gpu_reserved_gb = torch.cuda.memory_reserved() / 1024**3
                        gpu_total_gb = torch.cuda.get_device_properties(0).total_memory / 1024**3
                    elif self.device == "mps" and torch.backends.mps.is_available():
                        # MPS ë©”ëª¨ë¦¬ ì •ë³´ (ì¶”ì •)
                        gpu_allocated_gb = 2.0
                        gpu_total_gb = self.memory_gb  # M3 Max í†µí•© ë©”ëª¨ë¦¬
                except Exception:
                    pass
            
            # ìºì‹œ í¬ê¸°
            cache_size_mb = 0.0
            try:
                for cache_name in ['tensor_cache', 'image_cache', 'model_cache']:
                    if hasattr(self, cache_name):
                        cache = getattr(self, cache_name)
                        cache_size_mb += len(str(cache)) / 1024**2
            except:
                pass
            
            # M3 ìµœì í™” ì •ë³´ (DI í†µí•©)
            m3_optimizations = {}
            if self.is_m3_max:
                m3_optimizations = {
                    "memory_pools": getattr(self, 'memory_pools', {}),
                    "batch_sizes": getattr(self, 'optimal_batch_sizes', {}),
                    "precision_mode": self.precision_mode,
                    "conda_optimized": SYSTEM_INFO["in_conda"],
                    "di_integrated": self._di_container is not None,
                    "dependencies_resolved": self._dependencies_resolved
                }
            
            return MemoryStats(
                cpu_percent=cpu_percent,
                cpu_available_gb=cpu_available_gb,
                cpu_used_gb=cpu_used_gb,
                cpu_total_gb=cpu_total_gb,
                gpu_allocated_gb=gpu_allocated_gb,
                gpu_reserved_gb=gpu_reserved_gb,
                gpu_total_gb=gpu_total_gb,
                swap_used_gb=swap_used_gb,
                cache_size_mb=cache_size_mb,
                process_memory_mb=process_memory_mb,
                m3_optimizations=m3_optimizations
            )
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ ë©”ëª¨ë¦¬ ìƒíƒœ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return MemoryStats(
                cpu_percent=0.0,
                cpu_available_gb=8.0,
                cpu_used_gb=8.0,
                cpu_total_gb=16.0
            )

    def check_memory_pressure(self) -> Dict[str, Any]:
        """ë©”ëª¨ë¦¬ ì••ë°• ìƒíƒœ ì²´í¬ (DI í†µí•©)"""
        try:
            stats = self.get_memory_stats()
            
            cpu_usage_ratio = stats.cpu_used_gb / max(1.0, stats.cpu_total_gb)
            gpu_usage_ratio = stats.gpu_allocated_gb / max(1.0, stats.gpu_total_gb)
            
            status = "normal"
            if cpu_usage_ratio > 0.9 or gpu_usage_ratio > 0.9:
                status = "critical"
            elif cpu_usage_ratio > 0.75 or gpu_usage_ratio > 0.75:
                status = "warning"
            
            return {
                "status": status,
                "cpu_usage_ratio": cpu_usage_ratio,
                "gpu_usage_ratio": gpu_usage_ratio,
                "cache_size_mb": stats.cache_size_mb,
                "recommendations": self._get_cleanup_recommendations(stats),
                "di_integrated": self._di_container is not None,
                "dependencies_available": {
                    "device_manager": hasattr(self, 'device_manager'),
                    "data_converter": hasattr(self, 'data_converter')
                }
            }
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ ë©”ëª¨ë¦¬ ì••ë°• ì²´í¬ ì‹¤íŒ¨: {e}")
            return {"status": "unknown", "error": str(e)}

    def _get_cleanup_recommendations(self, stats: MemoryStats) -> List[str]:
        """ì •ë¦¬ ê¶Œì¥ì‚¬í•­ (DI í†µí•©)"""
        recommendations = []
        
        try:
            cpu_ratio = stats.cpu_used_gb / max(1.0, stats.cpu_total_gb)
            
            if cpu_ratio > 0.8:
                recommendations.append("CPU ë©”ëª¨ë¦¬ ì •ë¦¬ ê¶Œì¥")
            
            if stats.gpu_allocated_gb > 10.0:
                recommendations.append("GPU ë©”ëª¨ë¦¬ ì •ë¦¬ ê¶Œì¥")
            
            if stats.cache_size_mb > 1000:
                recommendations.append("ìºì‹œ ì •ë¦¬ ê¶Œì¥")
            
            if self.is_m3_max and cpu_ratio > 0.7:
                recommendations.append("M3 Max ìµœì í™” ì¬ì‹¤í–‰ ê¶Œì¥")
            
            # DI í†µí•© ê¶Œì¥ì‚¬í•­
            if self._di_container:
                if hasattr(self, 'device_manager'):
                    recommendations.append("DI DeviceManager ë©”ëª¨ë¦¬ ìµœì í™” í™œìš© ê°€ëŠ¥")
                if hasattr(self, 'data_converter'):
                    recommendations.append("DI DataConverter ë©”ëª¨ë¦¬ ìµœì í™” í™œìš© ê°€ëŠ¥")
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ ê¶Œì¥ì‚¬í•­ ìƒì„± ì‹¤íŒ¨: {e}")
        
        return recommendations

    def clear_cache(self, aggressive: bool = False):
        """ìºì‹œ ì •ë¦¬ (DI ìµœì í™”)"""
        try:
            with self._lock:
                if aggressive:
                    # ì „ì²´ ìºì‹œ ì‚­ì œ
                    for cache_name in ['tensor_cache', 'image_cache', 'model_cache', 'cache_priority']:
                        if hasattr(self, cache_name):
                            getattr(self, cache_name).clear()
                    
                    # DIë¥¼ í†µí•œ ì¶”ê°€ ìºì‹œ ì •ë¦¬
                    if hasattr(self, 'data_converter') and self.data_converter:
                        if hasattr(self.data_converter, 'clear_cache'):
                            self.data_converter.clear_cache(aggressive=True)
                    
                    self.logger.debug("ğŸ§¹ ì „ì²´ ìºì‹œ ì •ë¦¬ ì™„ë£Œ (DI í†µí•©)")
                else:
                    # ì„ íƒì  ìºì‹œ ì •ë¦¬
                    self._evict_low_priority_cache()
                    self.logger.debug("ğŸ§¹ ì„ íƒì  ìºì‹œ ì •ë¦¬ ì™„ë£Œ")
        except Exception as e:
            self.logger.warning(f"âš ï¸ ìºì‹œ ì •ë¦¬ ì‹¤íŒ¨: {e}")

    def _evict_low_priority_cache(self):
        """ë‚®ì€ ìš°ì„ ìˆœìœ„ ìºì‹œ ì œê±°"""
        try:
            if not hasattr(self, 'cache_priority') or not self.cache_priority:
                return
            
            # ìš°ì„ ìˆœìœ„ ê¸°ì¤€ ì •ë ¬
            sorted_items = sorted(self.cache_priority.items(), key=lambda x: x[1])
            
            # í•˜ìœ„ 20% ì œê±°
            num_to_remove = max(1, len(sorted_items) // 5)
            for key, _ in sorted_items[:num_to_remove]:
                for cache_name in ['tensor_cache', 'image_cache', 'model_cache']:
                    if hasattr(self, cache_name):
                        getattr(self, cache_name).pop(key, None)
                self.cache_priority.pop(key, None)
            
            self.logger.debug(f"ğŸ—‘ï¸ ë‚®ì€ ìš°ì„ ìˆœìœ„ ìºì‹œ {num_to_remove}ê°œ ì œê±°")
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ ìºì‹œ ì œê±° ì‹¤íŒ¨: {e}")

    # ============================================
    # ğŸ”¥ ë¹„ë™ê¸° ì¸í„°í˜ì´ìŠ¤ (ì•ˆì „í•œ ë˜í¼ + DI í†µí•©)
    # ============================================

    async def initialize(self) -> bool:
        """ë©”ëª¨ë¦¬ ê´€ë¦¬ì ë¹„ë™ê¸° ì´ˆê¸°í™” (DI í†µí•©)"""
        try:
            # M3 Max ìµœì í™” ì„¤ì • (ë™ê¸°ë¡œ ì‹¤í–‰)
            if self.is_m3_max and self.optimization_enabled:
                loop = asyncio.get_event_loop()
                await loop.run_in_executor(None, self._optimize_for_m3_max)
            
            # DIë¥¼ í†µí•œ ì˜ì¡´ì„± í•´ê²°
            if self._di_container:
                loop = asyncio.get_event_loop()
                await loop.run_in_executor(None, self.resolve_dependencies)
            
            self.logger.debug(f"âœ… DI MemoryManager ë¹„ë™ê¸° ì´ˆê¸°í™” ì™„ë£Œ")
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ DI MemoryManager ë¹„ë™ê¸° ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return False

    async def cleanup(self):
        """ë¹„ë™ê¸° ë©”ëª¨ë¦¬ ì •ë¦¬ (DI í†µí•©)"""
        try:
            loop = asyncio.get_event_loop()
            await loop.run_in_executor(None, self.cleanup_memory, True)
        except Exception as e:
            self.logger.warning(f"âš ï¸ ë¹„ë™ê¸° ë©”ëª¨ë¦¬ ì •ë¦¬ ì‹¤íŒ¨: {e}")

    def get_usage(self) -> Dict[str, Any]:
        """ë™ê¸° ì‚¬ìš©ëŸ‰ ì¡°íšŒ (í•˜ìœ„ í˜¸í™˜ + DI í†µí•©)"""
        try:
            stats = self.get_memory_stats()
            return {
                "cpu_percent": stats.cpu_percent,
                "cpu_used_gb": stats.cpu_used_gb,
                "cpu_total_gb": stats.cpu_total_gb,
                "gpu_allocated_gb": stats.gpu_allocated_gb,
                "gpu_total_gb": stats.gpu_total_gb,
                "cache_size_mb": stats.cache_size_mb,
                "device": self.device,
                "is_m3_max": self.is_m3_max,
                "di_integrated": self._di_container is not None,
                "dependencies_resolved": self._dependencies_resolved
            }
        except Exception as e:
            self.logger.warning(f"âš ï¸ ì‚¬ìš©ëŸ‰ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {"error": str(e)}

    def __del__(self):
        """ì†Œë©¸ì"""
        try:
            if hasattr(self, 'monitoring_active'):
                self.monitoring_active = False
            if hasattr(self, 'tensor_cache'):
                self.clear_cache(aggressive=True)
        except:
            pass

# ==============================================
# ğŸ”¥ DI í†µí•© MemoryManagerAdapter í´ë˜ìŠ¤
# ==============================================

class MemoryManagerAdapter(IDependencyInjectable):
    """
    ğŸ”¥ DI ì™„ì „ í†µí•© MemoryManagerAdapter í´ë˜ìŠ¤
    âœ… CircularReferenceFreeDIContainer ì—°ë™
    âœ… ì˜ì¡´ì„± ì£¼ì… ì§€ì›
    âœ… optimize_memory ë©”ì„œë“œ ì™„ì „ êµ¬í˜„
    âœ… VirtualFittingStep í˜¸í™˜ì„± 100%
    âœ… ëª¨ë“  async/await ì˜¤ë¥˜ í•´ê²°
    """
    
    def __init__(self, base_manager: Optional[MemoryManager] = None, device: str = "auto", di_container: Optional[Any] = None, **kwargs):
        """MemoryManagerAdapter ì´ˆê¸°í™” (DI ì§€ì›)"""
        try:
            # ë² ì´ìŠ¤ ë§¤ë‹ˆì € ì„¤ì •
            if base_manager is None:
                self._base_manager = MemoryManager(device=device, di_container=di_container, **kwargs)
            else:
                self._base_manager = base_manager
                # ê¸°ì¡´ ë² ì´ìŠ¤ ë§¤ë‹ˆì €ì— DI Container ì„¤ì •
                if di_container and hasattr(self._base_manager, 'set_di_container'):
                    self._base_manager.set_di_container(di_container)
            
            # ì†ì„± ì´ˆê¸°í™”
            self.device = self._base_manager.device
            self.is_m3_max = self._base_manager.is_m3_max
            self.memory_gb = self._base_manager.memory_gb
            self.logger = logging.getLogger("MemoryManagerAdapter")
            
            # ğŸ”¥ DI Container ì„¤ì •
            self._di_container: Optional[Any] = di_container
            self._dependencies_resolved = False
            self._dependency_status = {
                'di_container': di_container is not None,
                'base_manager': True,
                'initialized': False
            }
            
            # ìŠ¤ë ˆë“œ ì•ˆì „ì„±
            self._lock = threading.RLock()
            
            # ì–´ëŒ‘í„° ê³ ìœ  ì†ì„±
            self.adapter_initialized = True
            self.optimization_cache = {}
            self.last_optimization_time = 0
            
            # DI Container ì„¤ì • (ì´ˆê¸°í™” í›„)
            if di_container is not None:
                self.set_di_container(di_container)
            
            self.logger.debug(f"âœ… DI MemoryManagerAdapter ì´ˆê¸°í™” ì™„ë£Œ - ë””ë°”ì´ìŠ¤: {self.device}")
            
        except Exception as e:
            self.logger.error(f"âŒ DI MemoryManagerAdapter ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            # ìµœì†Œí•œì˜ ì´ˆê¸°í™”
            self._base_manager = MemoryManager(device="cpu")
            self.device = "cpu"
            self.is_m3_max = False
            self.memory_gb = 16
            self.logger = logging.getLogger("MemoryManagerAdapter")

    # ==============================================
    # ğŸ”¥ DI ì¸í„°í˜ì´ìŠ¤ êµ¬í˜„
    # ==============================================

    def set_di_container(self, di_container: Any) -> None:
        """DI Container ì„¤ì •"""
        try:
            with self._lock:
                self._di_container = di_container
                self._dependency_status['di_container'] = True
                
                # ë² ì´ìŠ¤ ë§¤ë‹ˆì €ì—ë„ DI Container ì„¤ì •
                if hasattr(self._base_manager, 'set_di_container'):
                    self._base_manager.set_di_container(di_container)
                
                # DI Containerì— ìì‹ ì„ ë“±ë¡
                if hasattr(di_container, 'register'):
                    di_container.register('memory_adapter', self, singleton=True)
                    di_container.register('IMemoryManagerAdapter', self, singleton=True)
                
                self.logger.info("âœ… MemoryManagerAdapter DI Container ì„¤ì • ì™„ë£Œ")
                
                # ì˜ì¡´ì„± í•´ê²° ì‹œë„
                self.resolve_dependencies()
                
        except Exception as e:
            self.logger.error(f"âŒ MemoryManagerAdapter DI Container ì„¤ì • ì‹¤íŒ¨: {e}")

    def resolve_dependencies(self) -> bool:
        """ì˜ì¡´ì„± í•´ê²°"""
        try:
            with self._lock:
                if not self._di_container:
                    self.logger.warning("âš ï¸ DI Containerê°€ ì„¤ì •ë˜ì§€ ì•ŠìŒ")
                    return False
                
                resolved_count = 0
                
                # ë² ì´ìŠ¤ ë§¤ë‹ˆì €ì˜ ì˜ì¡´ì„± í•´ê²°
                if hasattr(self._base_manager, 'resolve_dependencies'):
                    try:
                        if self._base_manager.resolve_dependencies():
                            resolved_count += 1
                            self.logger.debug("âœ… MemoryManagerAdapter ë² ì´ìŠ¤ ë§¤ë‹ˆì € ì˜ì¡´ì„± í•´ê²°")
                    except Exception as e:
                        self.logger.debug(f"ë² ì´ìŠ¤ ë§¤ë‹ˆì € ì˜ì¡´ì„± í•´ê²° ì‹¤íŒ¨: {e}")
                
                self._dependencies_resolved = resolved_count >= 0  # ì–´ëŒ‘í„°ëŠ” í•„ìˆ˜ ì˜ì¡´ì„± ì—†ìŒ
                self._dependency_status['initialized'] = True
                
                self.logger.info(f"ğŸ”— MemoryManagerAdapter ì˜ì¡´ì„± í•´ê²° ì™„ë£Œ: {resolved_count}ê°œ")
                
                return self._dependencies_resolved
                
        except Exception as e:
            self.logger.error(f"âŒ MemoryManagerAdapter ì˜ì¡´ì„± í•´ê²° ì‹¤íŒ¨: {e}")
            return False

    def get_dependency_status(self) -> Dict[str, Any]:
        """ì˜ì¡´ì„± ìƒíƒœ ì¡°íšŒ"""
        with self._lock:
            base_status = {}
            if hasattr(self._base_manager, 'get_dependency_status'):
                try:
                    base_status = self._base_manager.get_dependency_status()
                except Exception:
                    pass
            
            return {
                'class_name': self.__class__.__name__,
                'dependencies_resolved': self._dependencies_resolved,
                'dependency_status': dict(self._dependency_status),
                'di_container_available': self._di_container is not None,
                'base_manager_status': base_status,
                'adapter_info': {
                    'device': self.device,
                    'is_m3_max': self.is_m3_max,
                    'memory_gb': self.memory_gb,
                    'adapter_initialized': self.adapter_initialized
                }
            }

    # ==============================================
    # ğŸ”¥ í•µì‹¬ ë©”ì„œë“œë“¤ (DI ìµœì í™”)
    # ==============================================

    def optimize_startup(self, aggressive: bool = False) -> Dict[str, Any]:
        """
        ğŸš€ MemoryManagerAdapterìš© optimize_startup (ì™„ì „ ë™ê¸°í™” + DI í†µí•©)
        âœ… VirtualFittingStep í˜¸í™˜ì„± ë³´ì¥
        âœ… ëª¨ë“  async/await ì˜¤ë¥˜ í•´ê²°
        âœ… DIë¥¼ í†µí•œ ì¶”ê°€ ìµœì í™”
        """
        try:
            # ê¸°ë³¸ ë§¤ë‹ˆì €ì˜ optimize_startup ì‹œë„
            if hasattr(self._base_manager, 'optimize_startup'):
                try:
                    result = self._base_manager.optimize_startup(aggressive)
                    result["adapter"] = True
                    result["di_integrated"] = self._di_container is not None
                    return result
                except Exception as e:
                    self.logger.warning(f"âš ï¸ ê¸°ë³¸ ë§¤ë‹ˆì € optimize_startup ì‹¤íŒ¨: {e}")
            
            # í´ë°±: optimize_memory ì‚¬ìš©
            if hasattr(self, 'optimize_memory'):
                try:
                    result = self.optimize_memory(aggressive)
                    result.update({
                        "adapter": True,
                        "fallback_mode": "optimize_memory",
                        "message": "startup ìµœì í™”ë¥¼ optimize_memoryë¡œ ëŒ€ì²´",
                        "di_integrated": self._di_container is not None
                    })
                    return result
                except Exception as e:
                    self.logger.warning(f"âš ï¸ í´ë°± optimize_memory ì‹¤íŒ¨: {e}")
            
            # ìµœì¢… í´ë°±: ê¸°ë³¸ ì‹œì‘ ìµœì í™”
            return self._basic_startup_optimization(aggressive)
            
        except Exception as e:
            self.logger.error(f"âŒ MemoryManagerAdapter optimize_startup ì‹¤íŒ¨: {e}")
            return {
                "success": False,
                "error": str(e),
                "adapter": True,
                "di_integrated": self._di_container is not None,
                "timestamp": time.time()
            }
    
    def _basic_startup_optimization(self, aggressive: bool = False) -> Dict[str, Any]:
        """ê¸°ë³¸ ì‹œì‘ ìµœì í™” (ìµœì¢… í´ë°± + DI í†µí•©)"""
        try:
            startup_results = []
            
            # ê¸°ë³¸ ê°€ë¹„ì§€ ì»¬ë ‰ì…˜
            collected = gc.collect()
            startup_results.append(f"ê¸°ë³¸ GC: {collected}ê°œ ê°ì²´")
            
            # PyTorch ë©”ëª¨ë¦¬ ì •ë¦¬ (ê°€ëŠ¥í•œ ê²½ìš°)
            if TORCH_AVAILABLE:
                try:
                    if hasattr(torch.mps, 'empty_cache') and torch.backends.mps.is_available():
                        safe_mps_empty_cache()
                        startup_results.append("MPS ìºì‹œ ì •ë¦¬")
                    elif hasattr(torch.cuda, 'empty_cache') and torch.cuda.is_available():
                        torch.cuda.empty_cache()
                        startup_results.append("CUDA ìºì‹œ ì •ë¦¬")
                except Exception as e:
                    startup_results.append(f"GPU ìºì‹œ ì •ë¦¬ ì‹¤íŒ¨: {e}")
            
            # DIë¥¼ í†µí•œ ì¶”ê°€ ìµœì í™”
            if self._di_container:
                try:
                    # ë‹¤ë¥¸ ì˜ì¡´ì„±ë“¤ì„ í†µí•œ ìµœì í™” ì‹œë„
                    device_manager = self._di_container.get('device_manager')
                    if device_manager and hasattr(device_manager, 'optimize_memory'):
                        device_manager.optimize_memory()
                        startup_results.append("DI DeviceManager ìµœì í™”")
                except Exception as e:
                    startup_results.append(f"DI ìµœì í™” ì‹¤íŒ¨: {str(e)[:50]}")
            
            return {
                "success": True,
                "message": "ê¸°ë³¸ ì‹œì‘ ìµœì í™” ì™„ë£Œ (DI í†µí•©)",
                "startup_results": startup_results,
                "adapter": True,
                "fallback": True,
                "di_integrated": self._di_container is not None,
                "timestamp": time.time()
            }
            
        except Exception as e:
            return {
                "success": False,
                "error": str(e),
                "adapter": True,
                "fallback": True,
                "di_integrated": self._di_container is not None,
                "timestamp": time.time()
            }

    def optimize_memory(self, aggressive: bool = False, **kwargs) -> Dict[str, Any]:
        """
        ğŸ”¥ VirtualFittingStepì—ì„œ í•„ìš”í•œ í•µì‹¬ optimize_memory ë©”ì„œë“œ (DI í†µí•©)
        âœ… ì™„ì „ ë™ê¸°í™”ë¡œ ëª¨ë“  async/await ì˜¤ë¥˜ í•´ê²°
        âœ… AttributeError ì™„ì „ í•´ê²°
        âœ… DIë¥¼ í†µí•œ ì¶”ê°€ ìµœì í™”
        """
        try:
            start_time = time.time()
            optimization_results = []
            
            # ì¤‘ë³µ ìµœì í™” ë°©ì§€ (5ì´ˆ ë‚´ ì¬í˜¸ì¶œ ë°©ì§€)
            if (start_time - self.last_optimization_time) < 5.0:
                return {
                    "success": True,
                    "message": "ìµœê·¼ ìµœì í™” ì™„ë£Œ (ìºì‹œë¨)",
                    "cached": True,
                    "device": self.device,
                    "di_integrated": self._di_container is not None,
                    "timestamp": start_time
                }
            
            # 1. ê¸°ë³¸ ë©”ëª¨ë¦¬ ê´€ë¦¬ìì˜ optimize_memory í˜¸ì¶œ ì‹œë„
            if hasattr(self._base_manager, 'optimize_memory'):
                try:
                    base_result = self._base_manager.optimize_memory()
                    optimization_results.append("ê¸°ë³¸ ë©”ëª¨ë¦¬ ìµœì í™” ì™„ë£Œ")
                    
                    # ì„±ê³µí•œ ê²½ìš° ë°”ë¡œ ë°˜í™˜
                    if base_result.get("success", False):
                        self.last_optimization_time = start_time
                        return {
                            **base_result,
                            "adapter": True,
                            "optimization_results": optimization_results,
                            "device": self.device,
                            "di_integrated": self._di_container is not None,
                            "timestamp": start_time
                        }
                        
                except Exception as e:
                    self.logger.warning(f"âš ï¸ ê¸°ë³¸ ìµœì í™” ì‹¤íŒ¨, í´ë°± ëª¨ë“œ ì‚¬ìš©: {e}")
            
            # 2. í´ë°±: cleanup_memory ê¸°ë°˜ ìµœì í™”
            cleanup_result = self._base_manager.cleanup_memory(aggressive=aggressive)
            optimization_results.append(f"ë©”ëª¨ë¦¬ ì •ë¦¬: {cleanup_result.get('success', False)}")
            
            # 3. ì–´ëŒ‘í„° íŠ¹í™” ìµœì í™” (DI í†µí•©)
            adapter_optimizations = self._run_adapter_optimizations(aggressive)
            optimization_results.extend(adapter_optimizations)
            
            # 4. M3 Max íŠ¹í™” ìµœì í™” (ë™ê¸°)
            if self.is_m3_max:
                m3_optimizations = self._run_m3_max_optimizations_sync()
                optimization_results.extend(m3_optimizations)
            
            # 5. DIë¥¼ í†µí•œ ì¶”ê°€ ìµœì í™”
            if self._di_container:
                di_optimizations = self._run_di_optimizations()
                optimization_results.extend(di_optimizations)
            
            # 6. ìµœì¢… ë©”ëª¨ë¦¬ ìƒíƒœ í™•ì¸
            final_stats = self._base_manager.get_memory_stats()
            
            optimization_time = time.time() - start_time
            self.last_optimization_time = start_time
            
            # ìµœì í™” ê²°ê³¼ ìºì‹±
            result = {
                "success": True,
                "message": "MemoryManagerAdapter ë©”ëª¨ë¦¬ ìµœì í™” ì™„ë£Œ (DI í†µí•©)",
                "optimization_time": optimization_time,
                "optimization_results": optimization_results,
                "cleanup_result": cleanup_result,
                "final_memory_stats": {
                    "cpu_used_gb": final_stats.cpu_used_gb,
                    "cpu_available_gb": final_stats.cpu_available_gb,
                    "gpu_allocated_gb": final_stats.gpu_allocated_gb,
                    "cache_size_mb": final_stats.cache_size_mb
                },
                "device": self.device,
                "is_m3_max": self.is_m3_max,
                "adapter": True,
                "aggressive": aggressive,
                "di_integrated": self._di_container is not None,
                "dependencies_resolved": self._dependencies_resolved,
                "timestamp": start_time
            }
            
            self.optimization_cache = result
            self.logger.debug("âœ… DI MemoryManagerAdapter ë©”ëª¨ë¦¬ ìµœì í™” ì™„ë£Œ")
            return result
            
        except Exception as e:
            self.logger.error(f"âŒ DI MemoryManagerAdapter ìµœì í™” ì‹¤íŒ¨: {e}")
            return {
                "success": False,
                "error": str(e),
                "adapter": True,
                "device": self.device,
                "di_integrated": self._di_container is not None,
                "timestamp": time.time()
            }

    def _run_di_optimizations(self) -> List[str]:
        """DIë¥¼ í†µí•œ ì¶”ê°€ ìµœì í™”"""
        optimizations = []
        
        try:
            if not self._di_container:
                return optimizations
            
            # DeviceManagerë¥¼ í†µí•œ ìµœì í™”
            try:
                device_manager = self._di_container.get('device_manager')
                if device_manager and hasattr(device_manager, 'optimize_memory'):
                    device_manager.optimize_memory()
                    optimizations.append("DI DeviceManager ìµœì í™”")
            except Exception as e:
                optimizations.append(f"DI DeviceManager ìµœì í™” ì‹¤íŒ¨: {str(e)[:30]}")
            
            # DataConverterë¥¼ í†µí•œ ìµœì í™”
            try:
                data_converter = self._di_container.get('data_converter')
                if data_converter and hasattr(data_converter, 'optimize_memory'):
                    data_converter.optimize_memory()
                    optimizations.append("DI DataConverter ìµœì í™”")
            except Exception as e:
                optimizations.append(f"DI DataConverter ìµœì í™” ì‹¤íŒ¨: {str(e)[:30]}")
            
            return optimizations
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ DI ìµœì í™” ì‹¤íŒ¨: {e}")
            return ["DI ìµœì í™” ì‹¤íŒ¨"]

    def optimize(self, aggressive: bool = False) -> Dict[str, Any]:
        """
        ë©”ëª¨ë¦¬ ìµœì í™” (optimize_memoryì˜ ë³„ì¹­) - MemoryManagerAdapterìš©
        """
        return self.optimize_memory(aggressive=aggressive)
    
    async def optimize_async(self, aggressive: bool = False) -> Dict[str, Any]:
        """
        ë¹„ë™ê¸° ë©”ëª¨ë¦¬ ìµœì í™” - MemoryManagerAdapterìš© (DI í†µí•©)
        """
        try:
            import asyncio
            loop = asyncio.get_event_loop()
            result = await loop.run_in_executor(None, self.optimize_memory, aggressive)
            return result
        except Exception as e:
            self.logger.error(f"âŒ MemoryManagerAdapter ë¹„ë™ê¸° ìµœì í™” ì‹¤íŒ¨: {e}")
            return {
                "success": False,
                "error": str(e),
                "adapter": True,
                "di_integrated": self._di_container is not None
            }
    
    def get_memory_status(self) -> Dict[str, Any]:
        """
        ë©”ëª¨ë¦¬ ìƒíƒœ ì¡°íšŒ - MemoryManagerAdapterìš© (DI í†µí•©)
        """
        try:
            base_status = self._base_manager.get_memory_status()
            base_status.update({
                "adapter": True,
                "adapter_type": "MemoryManagerAdapter",
                "base_manager_type": type(self._base_manager).__name__,
                "di_integrated": self._di_container is not None,
                "dependencies_resolved": self._dependencies_resolved
            })
            return base_status
        except Exception as e:
            return {
                "error": str(e),
                "adapter": True,
                "available": False,
                "di_integrated": self._di_container is not None
            }
    
    def cleanup(self) -> bool:
        """
        ë©”ëª¨ë¦¬ ë§¤ë‹ˆì € ì •ë¦¬ - MemoryManagerAdapterìš© (DI í†µí•©)
        """
        try:
            # ê¸°ë³¸ ë§¤ë‹ˆì € ì •ë¦¬
            result = self._base_manager.cleanup()
            
            # ì–´ëŒ‘í„° ìºì‹œ ì •ë¦¬
            if hasattr(self, 'optimization_cache'):
                self.optimization_cache.clear()
            
            # DIë¥¼ í†µí•œ ì¶”ê°€ ì •ë¦¬
            if self._di_container:
                try:
                    device_manager = self._di_container.get('device_manager')
                    if device_manager and hasattr(device_manager, 'optimize_memory'):
                        device_manager.optimize_memory()
                except Exception:
                    pass
            
            self.logger.debug("âœ… DI MemoryManagerAdapter ì •ë¦¬ ì™„ë£Œ")
            return result
            
        except Exception as e:
            self.logger.error(f"âŒ DI MemoryManagerAdapter ì •ë¦¬ ì‹¤íŒ¨: {e}")
            return False

    def _run_adapter_optimizations(self, aggressive: bool = False) -> List[str]:
        """ì–´ëŒ‘í„° íŠ¹í™” ìµœì í™” (ë™ê¸° + DI í†µí•©)"""
        optimizations = []
        
        try:
            # 1. ìºì‹œ ì •ë¦¬
            if hasattr(self._base_manager, 'clear_cache'):
                self._base_manager.clear_cache(aggressive=aggressive)
                optimizations.append("ì–´ëŒ‘í„° ìºì‹œ ì •ë¦¬")
            
            # 2. ê°€ë¹„ì§€ ì»¬ë ‰ì…˜
            collected = gc.collect()
            optimizations.append(f"ê°€ë¹„ì§€ ì»¬ë ‰ì…˜: {collected}ê°œ ê°ì²´")
            
            # 3. PyTorch ë©”ëª¨ë¦¬ ì •ë¦¬
            if TORCH_AVAILABLE:
                try:
                    if self.device == "mps" and torch.backends.mps.is_available():
                        if hasattr(torch.mps, 'empty_cache'):
                            safe_mps_empty_cache()
                            optimizations.append("MPS ìºì‹œ ì •ë¦¬")
                    elif self.device == "cuda" and torch.cuda.is_available():
                        torch.cuda.empty_cache()
                        optimizations.append("CUDA ìºì‹œ ì •ë¦¬")
                except Exception as e:
                    optimizations.append(f"GPU ìºì‹œ ì •ë¦¬ ì‹¤íŒ¨: {str(e)[:50]}")
            
            return optimizations
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ ì–´ëŒ‘í„° ìµœì í™” ì‹¤íŒ¨: {e}")
            return ["ì–´ëŒ‘í„° ìµœì í™” ì‹¤íŒ¨"]

    def _run_m3_max_optimizations_sync(self) -> List[str]:
        """M3 Max íŠ¹í™” ìµœì í™” (ë™ê¸° ë²„ì „ + DI í†µí•©)"""
        optimizations = []
        
        try:
            if not self.is_m3_max:
                return optimizations
            
            # M3 Max íŠ¹í™” ë¡œì§ (ë™ê¸°)
            if hasattr(self._base_manager, '_optimize_for_m3_max'):
                self._base_manager._optimize_for_m3_max()
                optimizations.append("M3 Max Neural Engine ìµœì í™”")
            
            # MPS íŠ¹í™” ì •ë¦¬
            if TORCH_AVAILABLE and torch.backends.mps.is_available():
                if hasattr(torch.mps, 'empty_cache'):
                    safe_mps_empty_cache()
                optimizations.append("M3 Max MPS ìºì‹œ ì •ë¦¬")
            
            # ë©”ëª¨ë¦¬ ì••ë°• ì™„í™”
            if hasattr(self._base_manager, '_aggressive_m3_cleanup'):
                self._base_manager._aggressive_m3_cleanup()
                optimizations.append("M3 Max ê³µê²©ì  ë©”ëª¨ë¦¬ ì •ë¦¬")
            
            return optimizations
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ M3 Max ìµœì í™” ì‹¤íŒ¨: {e}")
            return ["M3 Max ìµœì í™” ì‹¤íŒ¨"]

    # ============================================
    # ğŸ”¥ ìœ„ì„ ë©”ì„œë“œë“¤ (ëª¨ë“  í•„ìš”í•œ ë©”ì„œë“œ ìœ„ì„ + DI í†µí•©)
    # ============================================

    def get_memory_stats(self) -> MemoryStats:
        """ë©”ëª¨ë¦¬ í†µê³„ (ìœ„ì„)"""
        try:
            return self._base_manager.get_memory_stats()
        except Exception as e:
            self.logger.warning(f"âš ï¸ ë©”ëª¨ë¦¬ í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return MemoryStats(
                cpu_percent=50.0,
                cpu_available_gb=8.0,
                cpu_used_gb=8.0,
                cpu_total_gb=16.0
            )
    
    def cleanup_memory(self, aggressive: bool = False) -> Dict[str, Any]:
        """ë©”ëª¨ë¦¬ ì •ë¦¬ (ìœ„ì„)"""
        try:
            result = self._base_manager.cleanup_memory(aggressive)
            result["adapter"] = True
            result["di_integrated"] = self._di_container is not None
            return result
        except Exception as e:
            self.logger.warning(f"âš ï¸ ë©”ëª¨ë¦¬ ì •ë¦¬ ì‹¤íŒ¨: {e}")
            return {
                "success": False,
                "error": str(e),
                "adapter": True,
                "device": self.device,
                "di_integrated": self._di_container is not None
            }
    
    def check_memory_pressure(self) -> Dict[str, Any]:
        """ë©”ëª¨ë¦¬ ì••ë°• í™•ì¸ (ìœ„ì„)"""
        try:
            result = self._base_manager.check_memory_pressure()
            result["adapter"] = True
            result["di_integrated"] = self._di_container is not None
            return result
        except Exception as e:
            self.logger.warning(f"âš ï¸ ë©”ëª¨ë¦¬ ì••ë°• í™•ì¸ ì‹¤íŒ¨: {e}")
            return {
                "status": "unknown",
                "error": str(e),
                "adapter": True,
                "di_integrated": self._di_container is not None
            }
    
    def clear_cache(self, aggressive: bool = False):
        """ìºì‹œ ì •ë¦¬ (ìœ„ì„)"""
        try:
            return self._base_manager.clear_cache(aggressive)
        except Exception as e:
            self.logger.warning(f"âš ï¸ ìºì‹œ ì •ë¦¬ ì‹¤íŒ¨: {e}")

    def get_usage(self) -> Dict[str, Any]:
        """ë™ê¸° ì‚¬ìš©ëŸ‰ ì¡°íšŒ (ìœ„ì„)"""
        try:
            result = self._base_manager.get_usage()
            result["adapter"] = True
            result["di_integrated"] = self._di_container is not None
            return result
        except Exception as e:
            self.logger.warning(f"âš ï¸ ì‚¬ìš©ëŸ‰ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {
                "error": str(e), 
                "adapter": True,
                "di_integrated": self._di_container is not None
            }

    def __getattr__(self, name):
        """ë‹¤ë¥¸ ëª¨ë“  ì†ì„±/ë©”ì„œë“œëŠ” ê¸°ë³¸ ê´€ë¦¬ìë¡œ ìœ„ì„"""
        try:
            return getattr(self._base_manager, name)
        except AttributeError:
            self.logger.warning(f"âš ï¸ ì†ì„± '{name}'ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ")
            raise AttributeError(f"'{self.__class__.__name__}' object has no attribute '{name}'")

    def __del__(self):
        """ì†Œë©¸ì"""
        try:
            if hasattr(self, '_base_manager') and self._base_manager:
                if hasattr(self._base_manager, '__del__'):
                    self._base_manager.__del__()
        except:
            pass

# ==============================================
# ğŸ”¥ DI í†µí•© GPUMemoryManager í´ë˜ìŠ¤
# ==============================================

class GPUMemoryManager(MemoryManager):
    """
    ğŸ”¥ DI í†µí•© GPU ë©”ëª¨ë¦¬ ê´€ë¦¬ì (ê¸°ì¡´ í´ë˜ìŠ¤ëª… ìœ ì§€)
    âœ… í˜„ì¬ êµ¬ì¡°ì™€ ì™„ë²½ í˜¸í™˜
    âœ… ê¸°ì¡´ ì½”ë“œì˜ GPUMemoryManager ì‚¬ìš© ìœ ì§€
    âœ… main.py import ì˜¤ë¥˜ ì™„ì „ í•´ê²°
    âœ… DI ì§€ì› ì¶”ê°€
    """
    
    def __init__(self, device=None, memory_limit_gb=None, di_container: Optional[Any] = None, **kwargs):
        """GPU ë©”ëª¨ë¦¬ ê´€ë¦¬ì ì´ˆê¸°í™” (ê¸°ì¡´ ì‹œê·¸ë‹ˆì²˜ ìœ ì§€ + DI ì§€ì›)"""
        
        # ê¸°ë³¸ê°’ ì„¤ì •
        if device is None:
            device = SYSTEM_INFO["device"]
        if memory_limit_gb is None:
            memory_limit_gb = SYSTEM_INFO["memory_gb"] * 0.8 if SYSTEM_INFO["is_m3_max"] else 16.0
        
        super().__init__(device=device, memory_limit_gb=memory_limit_gb, di_container=di_container, **kwargs)
        self.logger = logging.getLogger("GPUMemoryManager")
        
        # ê¸°ì¡´ ì†ì„± í˜¸í™˜ì„± ìœ ì§€
        self.memory_limit_gb = memory_limit_gb
        
        self.logger.debug(f"ğŸ® DI GPUMemoryManager ì´ˆê¸°í™” - {device} ({memory_limit_gb:.1f}GB)")

    def clear_cache(self):
        """ë©”ëª¨ë¦¬ ì •ë¦¬ (ê¸°ì¡´ ë©”ì„œë“œ ì‹œê·¸ë‹ˆì²˜ ìœ ì§€ + DI ìµœì í™”)"""
        try:
            # ë¶€ëª¨ í´ë˜ìŠ¤ì˜ ë©”ëª¨ë¦¬ ì •ë¦¬ í˜¸ì¶œ
            result = self.cleanup_memory(aggressive=False)
            
            # PyTorch GPU ìºì‹œ ì •ë¦¬
            if TORCH_AVAILABLE:
                if self.device == "mps" and torch.backends.mps.is_available():
                    if hasattr(torch.mps, 'empty_cache'):
                        safe_mps_empty_cache()
                elif self.device == "cuda" and torch.cuda.is_available():
                    torch.cuda.empty_cache()
            
            # DIë¥¼ í†µí•œ ì¶”ê°€ ì •ë¦¬
            if hasattr(self, 'device_manager') and self.device_manager:
                try:
                    self.device_manager.optimize_memory()
                except Exception:
                    pass
            
            self.logger.debug("ğŸ§¹ DI GPU ìºì‹œ ì •ë¦¬ ì™„ë£Œ")
            return result
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ GPU ìºì‹œ ì •ë¦¬ ì‹¤íŒ¨: {e}")
            return {"success": False, "error": str(e)}

    def check_memory_usage(self):
        """ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í™•ì¸ (ê¸°ì¡´ ë©”ì„œë“œëª… ìœ ì§€ + DI í†µí•©)"""
        try:
            stats = self.get_memory_stats()
            
            # ê¸°ì¡´ ë¡œì§ê³¼ í˜¸í™˜
            if PSUTIL_AVAILABLE:
                memory = psutil.virtual_memory()
                used_gb = memory.used / (1024**3)
                if used_gb > self.memory_limit_gb * 0.9:
                    self.logger.warning(f"âš ï¸ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë†’ìŒ: {used_gb:.1f}GB")
                    self.clear_cache()
            
            return {
                "cpu_used_gb": stats.cpu_used_gb,
                "cpu_total_gb": stats.cpu_total_gb,
                "gpu_allocated_gb": stats.gpu_allocated_gb,
                "device": self.device,
                "is_m3_max": self.is_m3_max,
                "memory_limit_gb": self.memory_limit_gb,
                "di_integrated": self._di_container is not None,
                "dependencies_resolved": self._dependencies_resolved
            }
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í™•ì¸ ì‹¤íŒ¨: {e}")
            return {"error": str(e)}

# ==============================================
# ğŸ”¥ DI ì „ìš© íŒ©í† ë¦¬ í•¨ìˆ˜ë“¤
# ==============================================

def create_di_memory_manager(
    device: str = "auto",
    di_container: Optional[Any] = None,
    **kwargs
) -> MemoryManager:
    """DI ì§€ì› ë©”ëª¨ë¦¬ ê´€ë¦¬ì ìƒì„±"""
    if device == "auto":
        device = SYSTEM_INFO["device"]
    
    # DI Container ìë™ í•´ê²°
    if di_container is None:
        try:
            from ..core.di_container import get_global_container
            di_container = get_global_container()
        except ImportError:
            logger.warning("âš ï¸ DI Containerë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ, ê¸°ë³¸ ëª¨ë“œë¡œ ì‹¤í–‰")
    
    return MemoryManager(device=device, di_container=di_container, **kwargs)

def create_di_device_manager(
    di_container: Optional[Any] = None
) -> DeviceManager:
    """DI ì§€ì› ë””ë°”ì´ìŠ¤ ê´€ë¦¬ì ìƒì„±"""
    # DI Container ìë™ í•´ê²°
    if di_container is None:
        try:
            from ..core.di_container import get_global_container
            di_container = get_global_container()
        except ImportError:
            logger.warning("âš ï¸ DI Containerë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ, ê¸°ë³¸ ëª¨ë“œë¡œ ì‹¤í–‰")
    
    return DeviceManager(di_container=di_container)

def create_di_memory_adapter(
    device: str = "auto",
    di_container: Optional[Any] = None,
    **kwargs
) -> MemoryManagerAdapter:
    """DI ì§€ì› ë©”ëª¨ë¦¬ ì–´ëŒ‘í„° ìƒì„±"""
    # DI Container ìë™ í•´ê²°
    if di_container is None:
        try:
            from ..core.di_container import get_global_container
            di_container = get_global_container()
        except ImportError:
            logger.warning("âš ï¸ DI Containerë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ, ê¸°ë³¸ ëª¨ë“œë¡œ ì‹¤í–‰")
    
    base_manager = create_di_memory_manager(device=device, di_container=di_container, **kwargs)
    return MemoryManagerAdapter(base_manager=base_manager, di_container=di_container)

# ==============================================
# ğŸ”¥ ì „ì—­ DI ì¸ìŠ¤í„´ìŠ¤ ê´€ë¦¬
# ==============================================

# ì „ì—­ DI ì§€ì› ì¸ìŠ¤í„´ìŠ¤ë“¤
_global_di_memory_manager: Optional[MemoryManager] = None
_global_di_device_manager: Optional[DeviceManager] = None
_global_di_memory_adapter: Optional[MemoryManagerAdapter] = None
_global_di_container_ref: Optional[Any] = None
_di_memory_lock = threading.RLock()

def get_global_di_memory_manager(di_container: Optional[Any] = None, **kwargs) -> MemoryManager:
    """ì „ì—­ DI ë©”ëª¨ë¦¬ ê´€ë¦¬ì ë°˜í™˜"""
    global _global_di_memory_manager, _global_di_container_ref
    
    with _di_memory_lock:
        # DI Container ë³€ê²½ ê°ì§€
        if di_container is not None and di_container != _global_di_container_ref:
            _global_di_memory_manager = None
            _global_di_container_ref = di_container
        
        if _global_di_memory_manager is None:
            _global_di_memory_manager = create_di_memory_manager(di_container=di_container, **kwargs)
            _global_di_container_ref = di_container
    
    return _global_di_memory_manager

def get_global_di_device_manager(di_container: Optional[Any] = None) -> DeviceManager:
    """ì „ì—­ DI ë””ë°”ì´ìŠ¤ ê´€ë¦¬ì ë°˜í™˜"""
    global _global_di_device_manager, _global_di_container_ref
    
    with _di_memory_lock:
        # DI Container ë³€ê²½ ê°ì§€
        if di_container is not None and di_container != _global_di_container_ref:
            _global_di_device_manager = None
            _global_di_container_ref = di_container
        
        if _global_di_device_manager is None:
            _global_di_device_manager = create_di_device_manager(di_container=di_container)
            _global_di_container_ref = di_container
    
    return _global_di_device_manager

def get_global_di_memory_adapter(di_container: Optional[Any] = None, **kwargs) -> MemoryManagerAdapter:
    """ì „ì—­ DI ë©”ëª¨ë¦¬ ì–´ëŒ‘í„° ë°˜í™˜"""
    global _global_di_memory_adapter, _global_di_container_ref
    
    with _di_memory_lock:
        # DI Container ë³€ê²½ ê°ì§€
        if di_container is not None and di_container != _global_di_container_ref:
            _global_di_memory_adapter = None
            _global_di_container_ref = di_container
        
        if _global_di_memory_adapter is None:
            _global_di_memory_adapter = create_di_memory_adapter(di_container=di_container, **kwargs)
            _global_di_container_ref = di_container
    
    return _global_di_memory_adapter

# ==============================================
# ğŸ”¥ ê¸°ì¡´ í•¨ìˆ˜ë“¤ (DI ì§€ì› ì¶”ê°€ + í•˜ìœ„ í˜¸í™˜ì„±)
# ==============================================

# ì „ì—­ ë©”ëª¨ë¦¬ ê´€ë¦¬ì ì¸ìŠ¤í„´ìŠ¤ (ì‹±ê¸€í†¤)
_global_memory_manager = None
_global_gpu_memory_manager = None
_global_adapter = None
_global_device_manager = None
_manager_lock = threading.Lock()

def get_memory_manager(**kwargs) -> MemoryManager:
    """ì „ì—­ ë©”ëª¨ë¦¬ ê´€ë¦¬ì ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜ (DI ìë™ ì ìš©)"""
    global _global_memory_manager
    
    with _manager_lock:
        if _global_memory_manager is None:
            # DI ì§€ì› ë²„ì „ìœ¼ë¡œ ìƒì„±
            try:
                from ..core.di_container import get_global_container
                di_container = get_global_container()
                _global_memory_manager = MemoryManager(di_container=di_container, **kwargs)
            except ImportError:
                # DI Container ì—†ì´ë„ ë™ì‘
                _global_memory_manager = MemoryManager(**kwargs)
        return _global_memory_manager

def get_global_memory_manager(**kwargs) -> MemoryManager:
    """ì „ì—­ ë©”ëª¨ë¦¬ ê´€ë¦¬ì ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜ (ë³„ì¹­ + DI ìë™ ì ìš©)"""
    return get_memory_manager(**kwargs)

def get_device_manager(**kwargs) -> DeviceManager:
    """
    ğŸ”¥ DeviceManager ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜ (main.pyì—ì„œ ìš”êµ¬í•˜ëŠ” í•µì‹¬ í•¨ìˆ˜ + DI ì§€ì›)
    âœ… import ì˜¤ë¥˜ ì™„ì „ í•´ê²°
    âœ… setup_mps_compatibility ë©”ì„œë“œ í¬í•¨
    âœ… DI ìë™ ì ìš©
    """
    global _global_device_manager
    
    with _manager_lock:
        if _global_device_manager is None:
            # DI ì§€ì› ë²„ì „ìœ¼ë¡œ ìƒì„±
            try:
                from ..core.di_container import get_global_container
                di_container = get_global_container()
                _global_device_manager = DeviceManager(di_container=di_container)
            except ImportError:
                # DI Container ì—†ì´ë„ ë™ì‘
                _global_device_manager = DeviceManager()
            
            logger.info(f"âœ… DI DeviceManager ì´ˆê¸°í™” ì™„ë£Œ - ë””ë°”ì´ìŠ¤: {_global_device_manager.device}")
        return _global_device_manager

def get_memory_adapter(device: str = "auto", **kwargs) -> MemoryManagerAdapter:
    """VirtualFittingStepìš© ì–´ëŒ‘í„° ë°˜í™˜ (DI ìë™ ì ìš©)"""
    global _global_adapter
    
    try:
        with _manager_lock:
            if _global_adapter is None:
                # DI ì§€ì› ë²„ì „ìœ¼ë¡œ ìƒì„±
                try:
                    from ..core.di_container import get_global_container
                    di_container = get_global_container()
                    base_manager = get_memory_manager(device=device, **kwargs)
                    _global_adapter = MemoryManagerAdapter(base_manager, di_container=di_container)
                except ImportError:
                    # DI Container ì—†ì´ë„ ë™ì‘
                    base_manager = get_memory_manager(device=device, **kwargs)
                    _global_adapter = MemoryManagerAdapter(base_manager)
                
                logger.info(f"âœ… DI ë©”ëª¨ë¦¬ ì–´ëŒ‘í„° ì´ˆê¸°í™” - ë””ë°”ì´ìŠ¤: {device}")
            return _global_adapter
    except Exception as e:
        logger.error(f"âŒ ë©”ëª¨ë¦¬ ì–´ëŒ‘í„° ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        # í´ë°± ì–´ëŒ‘í„° ìƒì„±
        fallback_manager = MemoryManager(device="cpu")
        return MemoryManagerAdapter(fallback_manager)


def create_memory_manager(device: str = "auto", **kwargs) -> MemoryManager:
        """ë©”ëª¨ë¦¬ ê´€ë¦¬ì íŒ©í† ë¦¬ í•¨ìˆ˜ (DI ìë™ ì ìš©)"""
        try:
            if device == "auto":
                device = SYSTEM_INFO["device"]
            
            # DI Container ìë™ í•´ê²°
            di_container = None
            try:
                from ..core.di_container import get_global_container
                di_container = get_global_container()
            except ImportError:
                pass
            
            logger.debug(f"ğŸ“¦ DI MemoryManager ìƒì„± - ë””ë°”ì´ìŠ¤: {device}")
            manager = MemoryManager(device=device, di_container=di_container, **kwargs)
            return manager
        except Exception as e:
            logger.warning(f"âš ï¸ MemoryManager ìƒì„± ì‹¤íŒ¨: {e}")
            # ì‹¤íŒ¨ ì‹œì—ë„ ê¸°ë³¸ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜
            return MemoryManager(device="cpu")
        
def get_step_memory_manager(step_name: str, **kwargs) -> Union[MemoryManager, MemoryManagerAdapter]:
    """
    ğŸ”¥ Stepë³„ ë©”ëª¨ë¦¬ ê´€ë¦¬ì ë°˜í™˜ (main.pyì—ì„œ ìš”êµ¬í•˜ëŠ” í•µì‹¬ í•¨ìˆ˜ + DI í†µí•©)
    âœ… ê¸°ì¡´ í•¨ìˆ˜ëª… ì™„ì „ ìœ ì§€
    âœ… __init__.pyì—ì„œ exportë˜ëŠ” í•µì‹¬ í•¨ìˆ˜
    âœ… import ì˜¤ë¥˜ ì™„ì „ í•´ê²°
    âœ… VirtualFittingStepìš© MemoryManagerAdapter ì§€ì›
    âœ… DI ìë™ ì ìš©
    """
    try:
        # Stepë³„ íŠ¹í™” ì„¤ì • (GitHub 8ë‹¨ê³„ íŒŒì´í”„ë¼ì¸ ê¸°ì¤€)
        step_configs = {
            "HumanParsingStep": {"memory_limit_gb": 8.0, "optimization_enabled": True},
            "PoseEstimationStep": {"memory_limit_gb": 6.0, "optimization_enabled": True},
            "ClothSegmentationStep": {"memory_limit_gb": 4.0, "optimization_enabled": True},
            "GeometricMatchingStep": {"memory_limit_gb": 6.0, "optimization_enabled": True},
            "ClothWarpingStep": {"memory_limit_gb": 8.0, "optimization_enabled": True},
            "VirtualFittingStep": {"memory_limit_gb": 16.0, "optimization_enabled": True},
            "PostProcessingStep": {"memory_limit_gb": 8.0, "optimization_enabled": True},
            "QualityAssessmentStep": {"memory_limit_gb": 4.0, "optimization_enabled": True}
        }
        
        # M3 Maxì—ì„œëŠ” ë” í° ë©”ëª¨ë¦¬ í• ë‹¹
        if SYSTEM_INFO["is_m3_max"]:
            for config in step_configs.values():
                config["memory_limit_gb"] *= 2  # M3 Maxì—ì„œ 2ë°° ë©”ëª¨ë¦¬ í• ë‹¹
        
        # Stepë³„ ì„¤ì • ì ìš©
        step_config = step_configs.get(step_name, {"memory_limit_gb": 8.0})
        final_kwargs = kwargs.copy()
        final_kwargs.update(step_config)
        
        # DI Container ìë™ í•´ê²°
        di_container = None
        try:
            from ..core.di_container import get_global_container
            di_container = get_global_container()
        except ImportError:
            pass
        
        # ë©”ëª¨ë¦¬ ê´€ë¦¬ì ìƒì„±
        base_manager = MemoryManager(di_container=di_container, **final_kwargs)
        base_manager.step_name = step_name
        base_manager.logger = logging.getLogger(f"memory.{step_name}")
        
        # VirtualFittingStepì¸ ê²½ìš° ì–´ëŒ‘í„° ë°˜í™˜
        if step_name == "VirtualFittingStep":
            adapter = MemoryManagerAdapter(base_manager, di_container=di_container)
            logger.debug(f"ğŸ“ {step_name} DI MemoryManagerAdapter ìƒì„± ì™„ë£Œ")
            return adapter
        else:
            logger.debug(f"ğŸ“ {step_name} DI ë©”ëª¨ë¦¬ ê´€ë¦¬ì ìƒì„± ì™„ë£Œ")
            return base_manager
        
    except Exception as e:
        logger.warning(f"âš ï¸ {step_name} ë©”ëª¨ë¦¬ ê´€ë¦¬ì ìƒì„± ì‹¤íŒ¨: {e}")
        # í´ë°±: ê¸°ë³¸ ë©”ëª¨ë¦¬ ê´€ë¦¬ì ë°˜í™˜
        base_manager = MemoryManager(**kwargs)
        if step_name == "VirtualFittingStep":
            return MemoryManagerAdapter(base_manager)
        return base_manager
    

def create_optimized_memory_manager(
    device: str = "auto",
    memory_gb: float = None,
    is_m3_max: bool = None,
    optimization_enabled: bool = True,
    di_container: Optional[Any] = None
) -> MemoryManager:
    """ìµœì í™”ëœ ë©”ëª¨ë¦¬ ê´€ë¦¬ì ìƒì„± (DI ì§€ì›)"""
    
    # ê¸°ë³¸ê°’ ì„¤ì •
    if device == "auto":
        device = SYSTEM_INFO["device"]
    if memory_gb is None:
        memory_gb = SYSTEM_INFO["memory_gb"]
    if is_m3_max is None:
        is_m3_max = SYSTEM_INFO["is_m3_max"]
    
    # DI Container ìë™ í•´ê²°
    if di_container is None:
        try:
            from ..core.di_container import get_global_container
            di_container = get_global_container()
        except ImportError:
            pass
    
    return MemoryManager(
        device=device,
        memory_gb=memory_gb,
        is_m3_max=is_m3_max,
        optimization_enabled=optimization_enabled,
        auto_cleanup=True,
        enable_caching=True,
        di_container=di_container
    )

def initialize_global_memory_manager(device: str = None, **kwargs) -> MemoryManager:
    """ì „ì—­ ë©”ëª¨ë¦¬ ê´€ë¦¬ì ì´ˆê¸°í™” (DI ìë™ ì ìš©)"""
    global _global_memory_manager
    
    try:
        with _manager_lock:
            if _global_memory_manager is None:
                if device is None:
                    device = SYSTEM_INFO["device"]
                
                # DI Container ìë™ í•´ê²°
                di_container = None
                try:
                    from ..core.di_container import get_global_container
                    di_container = get_global_container()
                except ImportError:
                    pass
                
                _global_memory_manager = MemoryManager(device=device, di_container=di_container, **kwargs)
                logger.info(f"âœ… ì „ì—­ DI ë©”ëª¨ë¦¬ ê´€ë¦¬ì ì´ˆê¸°í™” ì™„ë£Œ - ë””ë°”ì´ìŠ¤: {device}")
            return _global_memory_manager
    except Exception as e:
        logger.warning(f"âš ï¸ ì „ì—­ ë©”ëª¨ë¦¬ ê´€ë¦¬ì ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        # ê¸°ë³¸ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
        _global_memory_manager = MemoryManager(device="cpu")
        return _global_memory_manager

def optimize_memory_usage(device: str = None, aggressive: bool = False) -> Dict[str, Any]:
    """ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ìµœì í™” - ë™ê¸° í•¨ìˆ˜ (DI í†µí•©)"""
    try:
        manager = get_memory_manager(device=device or "auto")
        
        # ìµœì í™” ì „ ìƒíƒœ
        before_stats = manager.get_memory_stats()
        
        # ë©”ëª¨ë¦¬ ì •ë¦¬
        result = manager.cleanup_memory(aggressive=aggressive)
        
        # ìµœì í™” í›„ ìƒíƒœ
        after_stats = manager.get_memory_stats()
        
        # ê²°ê³¼ ê³„ì‚°
        freed_cpu = max(0, before_stats.cpu_used_gb - after_stats.cpu_used_gb)
        freed_gpu = max(0, before_stats.gpu_allocated_gb - after_stats.gpu_allocated_gb)
        freed_cache = max(0, before_stats.cache_size_mb - after_stats.cache_size_mb)
        
        result.update({
            "freed_memory": {
                "cpu_gb": freed_cpu,
                "gpu_gb": freed_gpu,
                "cache_mb": freed_cache
            },
            "before": {
                "cpu_used_gb": before_stats.cpu_used_gb,
                "gpu_allocated_gb": before_stats.gpu_allocated_gb,
                "cache_size_mb": before_stats.cache_size_mb
            },
            "after": {
                "cpu_used_gb": after_stats.cpu_used_gb,
                "gpu_allocated_gb": after_stats.gpu_allocated_gb,
                "cache_size_mb": after_stats.cache_size_mb
            },
            "di_integrated": getattr(manager, '_di_container', None) is not None
        })
        
        logger.info(f"ğŸ§¹ ë©”ëª¨ë¦¬ ìµœì í™” ì™„ë£Œ - CPU: {freed_cpu:.2f}GB, GPU: {freed_gpu:.2f}GB")
        return result
        
    except Exception as e:
        logger.warning(f"âš ï¸ ë©”ëª¨ë¦¬ ìµœì í™” ì‹¤íŒ¨: {e}")
        return {
            "success": False,
            "error": str(e),
            "device": device or "unknown"
        }

# ==============================================
# ğŸ”¥ í¸ì˜ í•¨ìˆ˜ë“¤ (ëª¨ë“  async ì˜¤ë¥˜ í•´ê²° + DI í†µí•©)
# ==============================================

def optimize_memory() -> Dict[str, Any]:
    """ë©”ëª¨ë¦¬ ìµœì í™” (ë™ê¸°í™” + DI ìë™ ì ìš©)"""
    try:
        manager = get_memory_manager()
        return manager.optimize_memory()
    except Exception as e:
        logger.warning(f"âš ï¸ ë©”ëª¨ë¦¬ ìµœì í™” ì‹¤íŒ¨: {e}")
        return {"success": False, "error": str(e)}

def check_memory():
    """ë©”ëª¨ë¦¬ ìƒíƒœ í™•ì¸ (DI ìë™ ì ìš©)"""
    try:
        manager = get_memory_manager()
        return manager.check_memory_pressure()
    except Exception as e:
        logger.warning(f"âš ï¸ ë©”ëª¨ë¦¬ ìƒíƒœ í™•ì¸ ì‹¤íŒ¨: {e}")
        return {"status": "unknown", "error": str(e)}

def check_memory_available(min_gb: float = 1.0) -> bool:
    """ì‚¬ìš© ê°€ëŠ¥í•œ ë©”ëª¨ë¦¬ í™•ì¸ (DI ìë™ ì ìš©)"""
    try:
        manager = get_memory_manager()
        stats = manager.get_memory_stats()
        return stats.cpu_available_gb >= min_gb
    except Exception as e:
        logger.warning(f"âš ï¸ ë©”ëª¨ë¦¬ í™•ì¸ ì‹¤íŒ¨: {e}")
        return True  # í™•ì¸ ì‹¤íŒ¨ ì‹œ true ë°˜í™˜

def get_memory_info() -> Dict[str, Any]:
    """ë©”ëª¨ë¦¬ ì •ë³´ ì¡°íšŒ (DI í†µí•©)"""
    try:
        manager = get_memory_manager()
        stats = manager.get_memory_stats()
        return {
            "device": manager.device,
            "cpu_total_gb": stats.cpu_total_gb,
            "cpu_available_gb": stats.cpu_available_gb,
            "cpu_used_gb": stats.cpu_used_gb,
            "gpu_total_gb": stats.gpu_total_gb,
            "gpu_allocated_gb": stats.gpu_allocated_gb,
            "is_m3_max": manager.is_m3_max,
            "memory_gb": manager.memory_gb,
            "conda_env": SYSTEM_INFO["in_conda"],
            "di_integrated": getattr(manager, '_di_container', None) is not None,
            "dependencies_resolved": getattr(manager, '_dependencies_resolved', False)
        }
    except Exception as e:
        logger.warning(f"âš ï¸ ë©”ëª¨ë¦¬ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return {"error": str(e)}

# ==============================================
# ğŸ”¥ ë°ì½”ë ˆì´í„° (async ì˜¤ë¥˜ í•´ê²° + DI í†µí•©)
# ==============================================

def memory_efficient(clear_before: bool = True, clear_after: bool = True):
    """ë©”ëª¨ë¦¬ íš¨ìœ¨ì  ì‹¤í–‰ ë°ì½”ë ˆì´í„° (DI ìë™ ì ìš©)"""
    def decorator(func):
        @wraps(func)
        def sync_wrapper(*args, **kwargs):
            manager = get_memory_manager()
            if clear_before:
                manager.cleanup_memory()
            try:
                result = func(*args, **kwargs)
                return result
            finally:
                if clear_after:
                    manager.cleanup_memory()
        
        # í•¨ìˆ˜ê°€ ì½”ë£¨í‹´ì¸ì§€ í™•ì¸
        if asyncio.iscoroutinefunction(func):
            @wraps(func)
            async def async_wrapper(*args, **kwargs):
                manager = get_memory_manager()
                if clear_before:
                    loop = asyncio.get_event_loop()
                    await loop.run_in_executor(None, manager.cleanup_memory)
                try:
                    result = await func(*args, **kwargs)
                    return result
                finally:
                    if clear_after:
                        loop = asyncio.get_event_loop()
                        await loop.run_in_executor(None, manager.cleanup_memory)
            return async_wrapper
        else:
            return sync_wrapper
    return decorator

# ==============================================
# ğŸ”¥ conda í™˜ê²½ íŠ¹í™” í•¨ìˆ˜ë“¤ (ì˜¤ë¥˜ ì™„ì „ í•´ê²° + DI í†µí•©)
# ==============================================

def setup_conda_memory_optimization() -> bool:
    """
    conda í™˜ê²½ ë©”ëª¨ë¦¬ ìµœì í™” ì„¤ì • (ì™„ì „ ë™ê¸°í™” + DI í†µí•©)
    âœ… object dict can't be used in 'await' expression ì™„ì „ í•´ê²°
    âœ… DIë¥¼ í†µí•œ ì¶”ê°€ ìµœì í™”
    """
    try:
        if not SYSTEM_INFO["in_conda"]:
            logger.warning("âš ï¸ conda í™˜ê²½ì´ ì•„ë‹™ë‹ˆë‹¤")
            return False
        
        optimizations = []
        
        # 1. NumPy/MKL ìŠ¤ë ˆë“œ ìµœì í™”
        if NUMPY_AVAILABLE:
            optimal_threads = min(8, SYSTEM_INFO["cpu_count"])
            os.environ['OMP_NUM_THREADS'] = str(optimal_threads)
            os.environ['MKL_NUM_THREADS'] = str(optimal_threads)
            os.environ['NUMEXPR_NUM_THREADS'] = str(optimal_threads)
            optimizations.append(f"NumPy/MKL ìŠ¤ë ˆë“œ: {optimal_threads}")
        
        # 2. PyTorch ì„¤ì •
        if TORCH_AVAILABLE:
            torch.set_num_threads(min(16, SYSTEM_INFO["cpu_count"]))
            optimizations.append(f"PyTorch ìŠ¤ë ˆë“œ: {torch.get_num_threads()}")
        
        # 3. M3 Max íŠ¹í™” ì„¤ì •
        if SYSTEM_INFO["is_m3_max"]:
            os.environ.update({
                'PYTORCH_MPS_HIGH_WATERMARK_RATIO': '0.0',
                'PYTORCH_MPS_LOW_WATERMARK_RATIO': '0.0',
                'PYTORCH_ENABLE_MPS_FALLBACK': '1'
            })
            optimizations.append("M3 Max MPS ìµœì í™”")
        
        # 4. DIë¥¼ í†µí•œ ì¶”ê°€ ìµœì í™”
        try:
            from ..core.di_container import get_global_container
            di_container = get_global_container()
            
            # DeviceManagerë¥¼ í†µí•œ ìµœì í™”
            device_manager = di_container.get('device_manager')
            if device_manager and hasattr(device_manager, 'optimize_memory'):
                device_manager.optimize_memory()
                optimizations.append("DI DeviceManager conda ìµœì í™”")
            
            # MemoryManagerë¥¼ í†µí•œ ìµœì í™”
            memory_manager = di_container.get('memory_manager')
            if memory_manager and hasattr(memory_manager, 'optimize_memory'):
                memory_manager.optimize_memory()
                optimizations.append("DI MemoryManager conda ìµœì í™”")
                
        except ImportError:
            pass  # DI Container ì—†ì´ë„ ë™ì‘
        except Exception as e:
            optimizations.append(f"DI conda ìµœì í™” ì‹¤íŒ¨: {str(e)[:30]}")
        
        logger.info("âœ… conda í™˜ê²½ ë©”ëª¨ë¦¬ ìµœì í™” ì„¤ì • ì™„ë£Œ (DI í†µí•©)")
        for opt in optimizations:
            logger.debug(f"   - {opt}")
        
        return True
        
    except Exception as e:
        logger.warning(f"âš ï¸ conda ë©”ëª¨ë¦¬ ìµœì í™” ì‹¤íŒ¨: {e}")
        return False

def get_conda_memory_recommendations() -> List[str]:
    """conda í™˜ê²½ ë©”ëª¨ë¦¬ ìµœì í™” ê¶Œì¥ì‚¬í•­ (DI í†µí•©)"""
    recommendations = []
    
    try:
        if not SYSTEM_INFO["in_conda"]:
            recommendations.append("conda í™˜ê²½ ì‚¬ìš© ê¶Œì¥")
            return recommendations
        
        # í˜„ì¬ ìƒíƒœ í™•ì¸
        current_threads = os.environ.get('OMP_NUM_THREADS', 'auto')
        if current_threads == 'auto':
            recommendations.append("OMP_NUM_THREADS ì„¤ì • ê¶Œì¥")
        
        if TORCH_AVAILABLE:
            current_torch_threads = torch.get_num_threads()
            optimal_threads = min(16, SYSTEM_INFO["cpu_count"])
            if current_torch_threads != optimal_threads:
                recommendations.append(f"PyTorch ìŠ¤ë ˆë“œ ìˆ˜ ìµœì í™” ({current_torch_threads} â†’ {optimal_threads})")
        
        if SYSTEM_INFO["is_m3_max"]:
            mps_ratio = os.environ.get('PYTORCH_MPS_HIGH_WATERMARK_RATIO')
            if mps_ratio != '0.0':
                recommendations.append("M3 Max MPS ë©”ëª¨ë¦¬ ë¹„ìœ¨ ìµœì í™” ê¶Œì¥")
        
        # DI ê´€ë ¨ ê¶Œì¥ì‚¬í•­
        try:
            from ..core.di_container import get_global_container
            di_container = get_global_container()
            
            # DIë¥¼ í†µí•œ ìµœì í™” ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
            memory_manager = di_container.get('memory_manager')
            if memory_manager:
                recommendations.append("DI MemoryManagerë¥¼ í†µí•œ conda ìµœì í™” í™œìš© ê°€ëŠ¥")
                
        except ImportError:
            recommendations.append("DI Container ì„¤ì •ìœ¼ë¡œ ì¶”ê°€ ìµœì í™” ê°€ëŠ¥")
        except Exception:
            pass
        
        if not recommendations:
            recommendations.append("conda í™˜ê²½ ìµœì í™” ìƒíƒœ ì–‘í˜¸ (DI í†µí•©)")
        
        return recommendations
        
    except Exception as e:
        logger.warning(f"âš ï¸ conda ê¶Œì¥ì‚¬í•­ ìƒì„± ì‹¤íŒ¨: {e}")
        return ["conda ìµœì í™” ìƒíƒœ í™•ì¸ ë¶ˆê°€"]

def create_conda_optimized_manager(step_name: str = "default", **kwargs) -> Union[MemoryManager, MemoryManagerAdapter]:
    """conda í™˜ê²½ ìµœì í™”ëœ ë©”ëª¨ë¦¬ ê´€ë¦¬ì ìƒì„± (DI í†µí•©)"""
    try:
        # conda ìµœì í™” ë¨¼ì € ì„¤ì •
        setup_conda_memory_optimization()
        
        # DI Container ìë™ í•´ê²°
        di_container = None
        try:
            from ..core.di_container import get_global_container
            di_container = get_global_container()
        except ImportError:
            pass
        
        # Stepë³„ ì„¤ì •
        if step_name == "VirtualFittingStep":
            base_manager = create_optimized_memory_manager(
                memory_gb=SYSTEM_INFO["memory_gb"],
                optimization_enabled=True,
                di_container=di_container,
                **kwargs
            )
            return MemoryManagerAdapter(base_manager, di_container=di_container)
        else:
            return create_optimized_memory_manager(
                memory_gb=SYSTEM_INFO["memory_gb"],
                optimization_enabled=True,
                di_container=di_container,
                **kwargs
            )
        
    except Exception as e:
        logger.warning(f"âš ï¸ conda ìµœì í™” ê´€ë¦¬ì ìƒì„± ì‹¤íŒ¨: {e}")
        # í´ë°±
        base_manager = MemoryManager(device="cpu")
        if step_name == "VirtualFittingStep":
            return MemoryManagerAdapter(base_manager)
        return base_manager

# ==============================================
# ğŸ”¥ ì§„ë‹¨ ë° ë””ë²„ê¹… í•¨ìˆ˜ë“¤ (DI í†µí•©)
# ==============================================

def diagnose_memory_issues() -> Dict[str, Any]:
    """ë©”ëª¨ë¦¬ ë¬¸ì œ ì§„ë‹¨ (DI í†µí•©)"""
    try:
        diagnosis = {
            "system_info": SYSTEM_INFO,
            "memory_status": {},
            "issues": [],
            "recommendations": [],
            "di_status": {}
        }
        
        # ë©”ëª¨ë¦¬ ìƒíƒœ í™•ì¸
        manager = get_memory_manager()
        stats = manager.get_memory_stats()
        
        diagnosis["memory_status"] = {
            "cpu_usage_ratio": stats.cpu_used_gb / max(1.0, stats.cpu_total_gb),
            "gpu_usage_ratio": stats.gpu_allocated_gb / max(1.0, stats.gpu_total_gb),
            "cache_size_mb": stats.cache_size_mb,
            "available_gb": stats.cpu_available_gb
        }
        
        # DI ìƒíƒœ í™•ì¸
        diagnosis["di_status"] = {
            "di_integrated": getattr(manager, '_di_container', None) is not None,
            "dependencies_resolved": getattr(manager, '_dependencies_resolved', False)
        }
        
        if hasattr(manager, 'get_dependency_status'):
            try:
                diagnosis["di_status"]["dependency_details"] = manager.get_dependency_status()
            except Exception:
                pass
        
        # ë¬¸ì œ ê°ì§€
        cpu_ratio = diagnosis["memory_status"]["cpu_usage_ratio"]
        if cpu_ratio > 0.9:
            diagnosis["issues"].append("CPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ 90%ë¥¼ ì´ˆê³¼")
            diagnosis["recommendations"].append("aggressive ë©”ëª¨ë¦¬ ì •ë¦¬ ì‹¤í–‰")
        elif cpu_ratio > 0.75:
            diagnosis["issues"].append("CPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ 75%ë¥¼ ì´ˆê³¼")
            diagnosis["recommendations"].append("ì¼ë°˜ ë©”ëª¨ë¦¬ ì •ë¦¬ ì‹¤í–‰")
        
        if stats.cache_size_mb > 1000:
            diagnosis["issues"].append("ìºì‹œ í¬ê¸°ê°€ 1GBë¥¼ ì´ˆê³¼")
            diagnosis["recommendations"].append("ìºì‹œ ì •ë¦¬ ì‹¤í–‰")
        
        # conda í™˜ê²½ í™•ì¸
        if not SYSTEM_INFO["in_conda"]:
            diagnosis["issues"].append("conda í™˜ê²½ì´ ì•„ë‹˜")
            diagnosis["recommendations"].append("conda í™˜ê²½ ì‚¬ìš© ê¶Œì¥")
        
        # PyTorch í™•ì¸
        if not TORCH_AVAILABLE:
            diagnosis["issues"].append("PyTorch ì—†ìŒ")
            diagnosis["recommendations"].append("conda install pytorch ì‹¤í–‰")
        
        # DI ê´€ë ¨ ê¶Œì¥ì‚¬í•­
        if not diagnosis["di_status"]["di_integrated"]:
            diagnosis["recommendations"].append("DI Container í†µí•©ìœ¼ë¡œ ì¶”ê°€ ìµœì í™” ê°€ëŠ¥")
        elif diagnosis["di_status"]["di_integrated"] and not diagnosis["di_status"]["dependencies_resolved"]:
            diagnosis["recommendations"].append("DI ì˜ì¡´ì„± í•´ê²° í•„ìš”")
        
        return diagnosis
        
    except Exception as e:
        return {
            "error": str(e),
            "system_info": SYSTEM_INFO,
            "recommendations": ["ì‹œìŠ¤í…œ ì¬ì‹œì‘ ê¶Œì¥"]
        }

def print_memory_report():
    """ë©”ëª¨ë¦¬ ìƒíƒœ ë¦¬í¬íŠ¸ ì¶œë ¥ (DI í†µí•©)"""
    try:
        print("\n" + "="*80)
        print("ğŸ”¥ MyCloset AI - DI í†µí•© ë©”ëª¨ë¦¬ ìƒíƒœ ë¦¬í¬íŠ¸")
        print("="*80)
        
        # ì‹œìŠ¤í…œ ì •ë³´
        print(f"ğŸ”§ ì‹œìŠ¤í…œ: {SYSTEM_INFO['platform']} / {SYSTEM_INFO['device']}")
        print(f"ğŸ M3 Max: {'âœ…' if SYSTEM_INFO['is_m3_max'] else 'âŒ'}")
        print(f"ğŸ conda: {'âœ…' if SYSTEM_INFO['in_conda'] else 'âŒ'} ({SYSTEM_INFO['conda_env']})")
        print(f"ğŸ”¥ PyTorch: {'âœ…' if TORCH_AVAILABLE else 'âŒ'} ({TORCH_VERSION})")
        
        # DI ìƒíƒœ
        manager = get_memory_manager()
        di_integrated = getattr(manager, '_di_container', None) is not None
        dependencies_resolved = getattr(manager, '_dependencies_resolved', False)
        print(f"ğŸ”— DI í†µí•©: {'âœ…' if di_integrated else 'âŒ'}")
        if di_integrated:
            print(f"ğŸ”— ì˜ì¡´ì„± í•´ê²°: {'âœ…' if dependencies_resolved else 'âŒ'}")
        
        # ë©”ëª¨ë¦¬ ìƒíƒœ
        stats = manager.get_memory_stats()
        
        print(f"\nğŸ’¾ ë©”ëª¨ë¦¬ ìƒíƒœ:")
        print(f"   CPU: {stats.cpu_used_gb:.1f}GB / {stats.cpu_total_gb:.1f}GB ({stats.cpu_percent:.1f}%)")
        print(f"   GPU: {stats.gpu_allocated_gb:.1f}GB / {stats.gpu_total_gb:.1f}GB")
        print(f"   ìºì‹œ: {stats.cache_size_mb:.1f}MB")
        print(f"   ì‚¬ìš© ê°€ëŠ¥: {stats.cpu_available_gb:.1f}GB")
        
        # ì••ë°• ìƒíƒœ
        pressure = manager.check_memory_pressure()
        status_emoji = {"normal": "âœ…", "warning": "âš ï¸", "critical": "âŒ"}.get(pressure["status"], "â“")
        print(f"\nğŸš¨ ì••ë°• ìƒíƒœ: {status_emoji} {pressure['status']}")
        
        # DI ì˜ì¡´ì„± ì •ë³´
        if di_integrated and hasattr(manager, 'get_dependency_status'):
            try:
                dep_status = manager.get_dependency_status()
                print(f"\nğŸ”— DI ì˜ì¡´ì„± ìƒíƒœ:")
                dep_info = dep_status.get('dependency_status', {})
                for dep_name, status in dep_info.items():
                    status_emoji = "âœ…" if status else "âŒ"
                    print(f"   {dep_name}: {status_emoji}")
            except Exception:
                pass
        
        # ê¶Œì¥ì‚¬í•­
        if pressure.get("recommendations"):
            print(f"\nğŸ“‹ ê¶Œì¥ì‚¬í•­:")
            for rec in pressure["recommendations"]:
                print(f"   - {rec}")
        
        # conda ê¶Œì¥ì‚¬í•­
        conda_recs = get_conda_memory_recommendations()
        if conda_recs and conda_recs[0] != "conda í™˜ê²½ ìµœì í™” ìƒíƒœ ì–‘í˜¸ (DI í†µí•©)":
            print(f"\nğŸ conda ê¶Œì¥ì‚¬í•­:")
            for rec in conda_recs:
                print(f"   - {rec}")
        
        print("="*80 + "\n")
        
    except Exception as e:
        print(f"âŒ ë©”ëª¨ë¦¬ ë¦¬í¬íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}")

# ==============================================
# ğŸ”¥ ëª¨ë“ˆ ìµìŠ¤í¬íŠ¸ (DI í•¨ìˆ˜ë“¤ ì¶”ê°€)
# ==============================================

__all__ = [
    # ğŸ”¥ ê¸°ì¡´ í´ë˜ìŠ¤ëª… ì™„ì „ ìœ ì§€ (DI ì§€ì› ì¶”ê°€)
    'DeviceManager',             # âœ… main.pyì—ì„œ í•„ìš”í•œ í•µì‹¬ í´ë˜ìŠ¤ + DI ì§€ì›
    'MemoryManager',             # âœ… DI ì™„ì „ í†µí•©
    'MemoryManagerAdapter',      # âœ… VirtualFittingStep í˜¸í™˜ìš© ì™„ì „ êµ¬í˜„ + DI ì§€ì›
    'GPUMemoryManager',          # âœ… í˜„ì¬ êµ¬ì¡°ì—ì„œ ì‚¬ìš© + DI ì§€ì›
    'MemoryStats',
    'MemoryConfig',
    
    # ğŸ”¥ DI ì¸í„°í˜ì´ìŠ¤ë“¤
    'IMemoryManager',
    'IDeviceManager',
    'IDependencyInjectable',
    
    # ğŸ”¥ ê¸°ì¡´ í•¨ìˆ˜ëª… ì™„ì „ ìœ ì§€ (DI ìë™ ì ìš©)
    'get_device_manager',        # âœ… main.pyì—ì„œ í•„ìš”í•œ í•µì‹¬ í•¨ìˆ˜ + DI ìë™ ì ìš©
    'get_memory_manager',        # âœ… DI ìë™ ì ìš©
    'get_global_memory_manager', # âœ… DI ìë™ ì ìš©
    'get_step_memory_manager',   # âœ… main.pyì—ì„œ í•„ìš”í•œ í•µì‹¬ í•¨ìˆ˜ + DI ìë™ ì ìš©
    'get_memory_adapter',        # âœ… VirtualFittingStep ì „ìš© + DI ìë™ ì ìš©
    'create_memory_manager',     # âœ… DI ìë™ ì ìš©
    'create_optimized_memory_manager', # âœ… DI ì§€ì› ì¶”ê°€
    'initialize_global_memory_manager', # âœ… DI ìë™ ì ìš©
    'optimize_memory_usage',     # âœ… DI í†µí•©
    'optimize_memory',          # âœ… ì™„ì „ ë™ê¸°í™” + DI ìë™ ì ìš©
    'check_memory',             # âœ… DI ìë™ ì ìš©
    'check_memory_available',   # âœ… DI ìë™ ì ìš©
    'get_memory_info',          # âœ… DI í†µí•©
    'memory_efficient',         # âœ… DI ìë™ ì ìš©
    
    # ğŸ”§ conda í™˜ê²½ íŠ¹í™” í•¨ìˆ˜ë“¤ (DI í†µí•©)
    'setup_conda_memory_optimization', # âœ… DI í†µí•©
    'get_conda_memory_recommendations', # âœ… DI í†µí•©
    'create_conda_optimized_manager',   # âœ… DI í†µí•©
    'diagnose_memory_issues',          # âœ… DI í†µí•©
    'print_memory_report',             # âœ… DI í†µí•©
    
    # ğŸ”¥ DI ì „ìš© í•¨ìˆ˜ë“¤
    'create_di_memory_manager',
    'create_di_device_manager',
    'create_di_memory_adapter',
    'get_global_di_memory_manager',
    'get_global_di_device_manager',
    'get_global_di_memory_adapter',
    
    # ğŸ”§ ì‹œìŠ¤í…œ ì •ë³´
    'SYSTEM_INFO',
    'TORCH_AVAILABLE',
    'PSUTIL_AVAILABLE',
    'NUMPY_AVAILABLE'
]

# ==============================================
# ğŸ”¥ ëª¨ë“ˆ ë¡œë“œ ì™„ë£Œ (DI í†µí•© ë²„ì „)
# ==============================================

# í™˜ê²½ ì •ë³´ ë¡œê¹… (INFO ë ˆë²¨ë¡œ ì¤‘ìš” ì •ë³´ë§Œ)
logger.info("âœ… DI ì™„ì „ í†µí•© MemoryManager v9.0 ë¡œë“œ ì™„ë£Œ")
logger.info("ğŸ”— CircularReferenceFreeDIContainer ì—°ë™ ì™„ë£Œ")
logger.info(f"ğŸ”§ ì‹œìŠ¤í…œ: {SYSTEM_INFO['platform']} / {SYSTEM_INFO['device']}")

if SYSTEM_INFO["is_m3_max"]:
    logger.info(f"ğŸ M3 Max ê°ì§€ - {SYSTEM_INFO['memory_gb']}GB ë©”ëª¨ë¦¬")

if SYSTEM_INFO["in_conda"]:
    logger.info(f"ğŸ conda í™˜ê²½: {SYSTEM_INFO['conda_env']}")

logger.debug("ğŸ”— ì£¼ìš” í´ë˜ìŠ¤: DeviceManager, MemoryManager, MemoryManagerAdapter, GPUMemoryManager (ëª¨ë‘ DI ì§€ì›)")
logger.debug("ğŸ”— ì£¼ìš” í•¨ìˆ˜: get_device_manager, get_step_memory_manager, get_memory_adapter (ëª¨ë‘ DI ìë™ ì ìš©)")
logger.debug("âš¡ M3 Max + conda í™˜ê²½ ì™„ì „ ìµœì í™” + DI í†µí•©")
logger.debug("ğŸ”§ ëª¨ë“  async/await ì˜¤ë¥˜ ì™„ì „ í•´ê²°")
logger.debug("ğŸ¯ DeviceManager.setup_mps_compatibility ë©”ì„œë“œ ì™„ì „ êµ¬í˜„ + DI ì§€ì›")
logger.debug("ğŸ”€ ìˆœí™˜ì°¸ì¡° ì™„ì „ ë°©ì§€ + DI Container ì—°ë™")
logger.debug("ğŸ›¡ï¸ Mock í´ë°± êµ¬í˜„ì²´ í¬í•¨")

# M3 Max + conda ì¡°í•© í™•ì¸
if SYSTEM_INFO["is_m3_max"] and SYSTEM_INFO["in_conda"]:
    logger.info("ğŸš€ M3 Max + conda + DI ìµœê³  ì„±ëŠ¥ ëª¨ë“œ í™œì„±í™”")

# conda í™˜ê²½ ìµœì í™” ìë™ ì„¤ì •
if SYSTEM_INFO["in_conda"]:
    try:
        setup_conda_memory_optimization()
        logger.debug("âœ… conda í™˜ê²½ ë©”ëª¨ë¦¬ ìµœì í™” ìë™ ì„¤ì • ì™„ë£Œ (DI í†µí•©)")
    except Exception as e:
        logger.debug(f"âš ï¸ conda ìë™ ìµœì í™” ê±´ë„ˆëœ€: {e}")

logger.info("ğŸ¯ main.py import ì˜¤ë¥˜ ì™„ì „ í•´ê²° + DI í†µí•©:")
logger.info("   - DeviceManager í´ë˜ìŠ¤ ì™„ì „ êµ¬í˜„ + DI ì§€ì› âœ…")
logger.info("   - setup_mps_compatibility ë©”ì„œë“œ í¬í•¨ + DI ìµœì í™” âœ…")
logger.info("   - get_device_manager í•¨ìˆ˜ ì œê³µ + DI ìë™ ì ìš© âœ…")
logger.info("   - RuntimeWarning: coroutine ì™„ì „ í•´ê²° âœ…")
logger.info("   - object dict can't be used in 'await' expression ì™„ì „ í•´ê²° âœ…")
logger.info("   - CircularReferenceFreeDIContainer ì™„ì „ ì—°ë™ âœ…")
logger.info("   - ìˆœí™˜ì°¸ì¡° ì™„ì „ ë°©ì§€ + ì˜ì¡´ì„± ì£¼ì… ì§€ì› âœ…")
logger.info("   - Mock í´ë°± êµ¬í˜„ì²´ í¬í•¨ âœ…")

logger.info("ğŸ”¥ DI í†µí•© ì™„ë£Œ:")
logger.info("   - ëª¨ë“  í´ë˜ìŠ¤ê°€ IDependencyInjectable êµ¬í˜„ âœ…")
logger.info("   - DI Container ìë™ í•´ê²° ë° ë“±ë¡ âœ…")
logger.info("   - ì˜ì¡´ì„± ì£¼ì… ë° í•´ê²° ì‹œìŠ¤í…œ ì™„ì „ êµ¬í˜„ âœ…")
logger.info("   - ê¸°ì¡´ ì¸í„°í˜ì´ìŠ¤ 100% í˜¸í™˜ì„± ìœ ì§€ âœ…")
logger.info("   - Stepë³„ DI ìë™ ì ìš© âœ…")