# app/ai_pipeline/utils/data_converter.py
"""
ë°ì´í„° ë³€í™˜ê¸° - M3 Max ìµœì í™” ì´ë¯¸ì§€/í…ì„œ ë³€í™˜ (ìµœì  ìƒì„±ì íŒ¨í„´ ì ìš©)
ë‹¨ìˆœí•¨ + í¸ì˜ì„± + í™•ì¥ì„± + ì¼ê´€ì„±
"""

import io
import logging
import time
import base64
from typing import Dict, Any, Optional, Union, List, Tuple
import numpy as np
from pathlib import Path

# PIL import
try:
    from PIL import Image, ImageEnhance, ImageFilter, ImageOps
    PIL_AVAILABLE = True
except ImportError:
    PIL_AVAILABLE = False
    Image = None

# OpenCV import
try:
    import cv2
    CV2_AVAILABLE = True
except ImportError:
    CV2_AVAILABLE = False
    cv2 = None

# PyTorch import
try:
    import torch
    import torchvision.transforms as transforms
    import torchvision.transforms.functional as TF
    TORCH_AVAILABLE = True
except ImportError:
    TORCH_AVAILABLE = False
    torch = None
    transforms = None
    TF = None

logger = logging.getLogger(__name__)

class DataConverter:
    """
    ğŸ M3 Max ìµœì í™” ë°ì´í„° ë³€í™˜ê¸°
    âœ… ìµœì  ìƒì„±ì íŒ¨í„´ ì ìš© - ì´ë¯¸ì§€/í…ì„œ ë³€í™˜ ë° ì²˜ë¦¬
    """
    
    def __init__(
        self,
        device: Optional[str] = None,  # ğŸ”¥ ìµœì  íŒ¨í„´: Noneìœ¼ë¡œ ìë™ ê°ì§€
        config: Optional[Dict[str, Any]] = None,
        **kwargs  # ğŸš€ í™•ì¥ì„±: ë¬´ì œí•œ ì¶”ê°€ íŒŒë¼ë¯¸í„°
    ):
        """
        âœ… ìµœì  ìƒì„±ì - ë°ì´í„° ë³€í™˜ê¸° íŠ¹í™”

        Args:
            device: ì‚¬ìš©í•  ë””ë°”ì´ìŠ¤ (None=ìë™ê°ì§€, 'cpu', 'cuda', 'mps')
            config: ë°ì´í„° ë³€í™˜ ì„¤ì • ë”•ì…”ë„ˆë¦¬
            **kwargs: í™•ì¥ íŒŒë¼ë¯¸í„°ë“¤
                - device_type: str = "auto"
                - memory_gb: float = 16.0  
                - is_m3_max: bool = False
                - optimization_enabled: bool = True
                - quality_level: str = "balanced"
                - default_size: Tuple[int, int] = (512, 512)  # ê¸°ë³¸ ì´ë¯¸ì§€ í¬ê¸°
                - interpolation: str = "bilinear"  # ë³´ê°„ ë°©ë²•
                - normalize_mean: List[float] = [0.485, 0.456, 0.406]  # ì •ê·œí™” í‰ê· 
                - normalize_std: List[float] = [0.229, 0.224, 0.225]  # ì •ê·œí™” í‘œì¤€í¸ì°¨
                - use_gpu_acceleration: bool = True  # GPU ê°€ì† ì‚¬ìš©
                - batch_processing: bool = True  # ë°°ì¹˜ ì²˜ë¦¬
                - memory_efficient: bool = True  # ë©”ëª¨ë¦¬ íš¨ìœ¨ì  ì²˜ë¦¬
                - quality_preservation: bool = True  # í’ˆì§ˆ ë³´ì¡´
        """
        # 1. ğŸ’¡ ì§€ëŠ¥ì  ë””ë°”ì´ìŠ¤ ìë™ ê°ì§€
        self.device = self._auto_detect_device(device)

        # 2. ğŸ“‹ ê¸°ë³¸ ì„¤ì •
        self.config = config or {}
        self.step_name = self.__class__.__name__
        self.logger = logging.getLogger(f"utils.{self.step_name}")

        # 3. ğŸ”§ í‘œì¤€ ì‹œìŠ¤í…œ íŒŒë¼ë¯¸í„° ì¶”ì¶œ (ì¼ê´€ì„±)
        self.device_type = kwargs.get('device_type', 'auto')
        self.memory_gb = kwargs.get('memory_gb', 16.0)
        self.is_m3_max = kwargs.get('is_m3_max', self._detect_m3_max())
        self.optimization_enabled = kwargs.get('optimization_enabled', True)
        self.quality_level = kwargs.get('quality_level', 'balanced')

        # 4. âš™ï¸ ë°ì´í„° ë³€í™˜ê¸° íŠ¹í™” íŒŒë¼ë¯¸í„°
        self.default_size = tuple(kwargs.get('default_size', (512, 512)))
        self.interpolation = kwargs.get('interpolation', 'bilinear')
        self.normalize_mean = kwargs.get('normalize_mean', [0.485, 0.456, 0.406])
        self.normalize_std = kwargs.get('normalize_std', [0.229, 0.224, 0.225])
        self.use_gpu_acceleration = kwargs.get('use_gpu_acceleration', self.device != 'cpu')
        self.batch_processing = kwargs.get('batch_processing', True)
        self.memory_efficient = kwargs.get('memory_efficient', True)
        self.quality_preservation = kwargs.get('quality_preservation', True)

        # 5. ğŸ M3 Max íŠ¹í™” ì„¤ì •
        if self.is_m3_max:
            self.use_gpu_acceleration = True  # M3 MaxëŠ” í•­ìƒ GPU ê°€ì†
            self.batch_processing = True  # ë°°ì¹˜ ì²˜ë¦¬ ìµœì í™”
            self.memory_efficient = False  # 128GB ë©”ëª¨ë¦¬ì´ë¯€ë¡œ í’ˆì§ˆ ìš°ì„ 

        # 6. âš™ï¸ ìŠ¤í…ë³„ íŠ¹í™” íŒŒë¼ë¯¸í„°ë¥¼ configì— ë³‘í•©
        self._merge_step_specific_config(kwargs)

        # 7. âœ… ìƒíƒœ ì´ˆê¸°í™”
        self.is_initialized = False

        # 8. ğŸ¯ ê¸°ì¡´ í´ë˜ìŠ¤ë³„ ê³ ìœ  ì´ˆê¸°í™” ë¡œì§ ì‹¤í–‰
        self._initialize_step_specific()

        self.logger.info(f"ğŸ¯ {self.step_name} ì´ˆê¸°í™” - ë””ë°”ì´ìŠ¤: {self.device}")

    def _auto_detect_device(self, preferred_device: Optional[str]) -> str:
        """ğŸ’¡ ì§€ëŠ¥ì  ë””ë°”ì´ìŠ¤ ìë™ ê°ì§€"""
        if preferred_device:
            return preferred_device

        if not TORCH_AVAILABLE:
            return 'cpu'

        try:
            if torch.backends.mps.is_available():
                return 'mps'  # M3 Max ìš°ì„ 
            elif torch.cuda.is_available():
                return 'cuda'  # NVIDIA GPU
            else:
                return 'cpu'  # í´ë°±
        except:
            return 'cpu'

    def _detect_m3_max(self) -> bool:
        """ğŸ M3 Max ì¹© ìë™ ê°ì§€"""
        try:
            import platform
            import subprocess

            if platform.system() == 'Darwin':  # macOS
                # M3 Max ê°ì§€ ë¡œì§
                result = subprocess.run(['sysctl', '-n', 'machdep.cpu.brand_string'], 
                                      capture_output=True, text=True)
                return 'M3' in result.stdout
        except:
            pass
        return False

    def _merge_step_specific_config(self, kwargs: Dict[str, Any]):
        """âš™ï¸ ìŠ¤í…ë³„ íŠ¹í™” ì„¤ì • ë³‘í•©"""
        # ì‹œìŠ¤í…œ íŒŒë¼ë¯¸í„° ì œì™¸í•˜ê³  ëª¨ë“  kwargsë¥¼ configì— ë³‘í•©
        system_params = {
            'device_type', 'memory_gb', 'is_m3_max', 
            'optimization_enabled', 'quality_level',
            'default_size', 'interpolation', 'normalize_mean', 'normalize_std',
            'use_gpu_acceleration', 'batch_processing', 'memory_efficient', 'quality_preservation'
        }

        for key, value in kwargs.items():
            if key not in system_params:
                self.config[key] = value

    def _initialize_step_specific(self):
        """ğŸ¯ ê¸°ì¡´ ì´ˆê¸°í™” ë¡œì§ ì™„ì „ ìœ ì§€"""
        # ë³€í™˜ íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™”
        self._init_transforms()
        
        # í†µê³„ ì¶”ì 
        self._conversion_stats = {
            "total_conversions": 0,
            "total_time": 0.0,
            "format_counts": {},
            "error_count": 0
        }
        
        self.logger.info(f"ğŸ”„ ë°ì´í„° ë³€í™˜ê¸° ì´ˆê¸°í™” - {self.device} (í¬ê¸°: {self.default_size})")
        
        # ì´ˆê¸°í™” ì™„ë£Œ
        self.is_initialized = True

    def _init_transforms(self):
        """ë³€í™˜ íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™”"""
        self.transforms = {}
        
        if TORCH_AVAILABLE:
            # ë³´ê°„ ë°©ë²• ë§¤í•‘
            interpolation_map = {
                'bilinear': transforms.InterpolationMode.BILINEAR if hasattr(transforms, 'InterpolationMode') else 'bilinear',
                'nearest': transforms.InterpolationMode.NEAREST if hasattr(transforms, 'InterpolationMode') else 'nearest',
                'bicubic': transforms.InterpolationMode.BICUBIC if hasattr(transforms, 'InterpolationMode') else 'bicubic'
            }
            
            interpolation_mode = interpolation_map.get(self.interpolation, 'bilinear')
            
            # ê¸°ë³¸ ë³€í™˜ íŒŒì´í”„ë¼ì¸
            self.transforms['default'] = transforms.Compose([
                transforms.Resize(self.default_size, interpolation=interpolation_mode),
                transforms.ToTensor()
            ])
            
            # ì •ê·œí™” ë³€í™˜
            self.transforms['normalized'] = transforms.Compose([
                transforms.Resize(self.default_size, interpolation=interpolation_mode),
                transforms.ToTensor(),
                transforms.Normalize(mean=self.normalize_mean, std=self.normalize_std)
            ])
            
            # ê³ í’ˆì§ˆ ë³€í™˜ (M3 Max ìµœì í™”)
            if self.is_m3_max and self.quality_preservation:
                self.transforms['high_quality'] = transforms.Compose([
                    transforms.Resize(self.default_size, interpolation=interpolation_mode),
                    transforms.ToTensor()
                ])

    async def initialize(self) -> bool:
        """ë°ì´í„° ë³€í™˜ê¸° ì´ˆê¸°í™”"""
        try:
            # ë¼ì´ë¸ŒëŸ¬ë¦¬ ê°€ìš©ì„± í™•ì¸
            available_libs = []
            if PIL_AVAILABLE:
                available_libs.append("PIL")
            if CV2_AVAILABLE:
                available_libs.append("OpenCV")
            if TORCH_AVAILABLE:
                available_libs.append("PyTorch")
            
            self.logger.info(f"ğŸ“š ì‚¬ìš© ê°€ëŠ¥í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬: {', '.join(available_libs)}")
            
            # M3 Max ìµœì í™” ì„¤ì •
            if self.is_m3_max and self.optimization_enabled:
                await self._apply_m3_max_optimizations()
            
            # ë³€í™˜ í…ŒìŠ¤íŠ¸
            test_result = await self._test_conversions()
            if not test_result:
                self.logger.warning("âš ï¸ ë³€í™˜ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨, ì¼ë¶€ ê¸°ëŠ¥ì´ ì œí•œë  ìˆ˜ ìˆìŠµë‹ˆë‹¤")
            
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ ë°ì´í„° ë³€í™˜ê¸° ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return False

    async def _apply_m3_max_optimizations(self):
        """M3 Max íŠ¹í™” ìµœì í™” ì ìš©"""
        try:
            optimizations = []
            
            # 1. ê³ í•´ìƒë„ ì²˜ë¦¬ í™œì„±í™”
            if self.default_size[0] < 1024:
                self.default_size = (1024, 1024)
                optimizations.append("High resolution processing")
            
            # 2. ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± ì¡°ì • (128GB ë©”ëª¨ë¦¬)
            self.memory_efficient = False  # í’ˆì§ˆ ìš°ì„ 
            optimizations.append("Quality-first processing")
            
            # 3. MPS ë°±ì—”ë“œ ìµœì í™”
            if TORCH_AVAILABLE and torch.backends.mps.is_available():
                optimizations.append("MPS backend optimization")
            
            if optimizations:
                self.logger.info(f"ğŸ M3 Max ìµœì í™” ì ìš©: {', '.join(optimizations)}")
                
        except Exception as e:
            self.logger.warning(f"âš ï¸ M3 Max ìµœì í™” ì‹¤íŒ¨: {e}")

    async def _test_conversions(self) -> bool:
        """ë³€í™˜ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸"""
        try:
            if PIL_AVAILABLE:
                # ë”ë¯¸ ì´ë¯¸ì§€ ìƒì„± ë° ë³€í™˜ í…ŒìŠ¤íŠ¸
                test_image = Image.new('RGB', (256, 256), color='red')
                tensor_result = self.image_to_tensor(test_image)
                if tensor_result is not None:
                    self.logger.info("âœ… ì´ë¯¸ì§€ â†’ í…ì„œ ë³€í™˜ í…ŒìŠ¤íŠ¸ í†µê³¼")
                    return True
                    
        except Exception as e:
            self.logger.error(f"âŒ ë³€í™˜ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
            
        return False

    def image_to_tensor(
        self,
        image: Union[Image.Image, np.ndarray, str, bytes],
        size: Optional[Tuple[int, int]] = None,
        normalize: bool = False,
        **kwargs
    ) -> Optional[torch.Tensor]:
        """ì´ë¯¸ì§€ë¥¼ í…ì„œë¡œ ë³€í™˜"""
        if not TORCH_AVAILABLE:
            self.logger.error("âŒ PyTorchê°€ ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ")
            return None
            
        try:
            start_time = time.time()
            
            # ì´ë¯¸ì§€ ì „ì²˜ë¦¬
            pil_image = self._to_pil_image(image)
            if pil_image is None:
                return None
            
            # í¬ê¸° ì„¤ì •
            target_size = size or self.default_size
            
            # ë³€í™˜ íŒŒì´í”„ë¼ì¸ ì„ íƒ
            if normalize:
                transform = self.transforms.get('normalized')
            elif self.is_m3_max and self.quality_preservation:
                transform = self.transforms.get('high_quality')
            else:
                transform = self.transforms.get('default')
            
            if transform is None:
                # í´ë°± ë³€í™˜
                if hasattr(pil_image, 'resize'):
                    pil_image = pil_image.resize(target_size)
                tensor = TF.to_tensor(pil_image) if TF else None
            else:
                tensor = transform(pil_image)
            
            if tensor is None:
                return None
            
            # ë°°ì¹˜ ì°¨ì› ì¶”ê°€
            if tensor.dim() == 3:
                tensor = tensor.unsqueeze(0)
            
            # ë””ë°”ì´ìŠ¤ë¡œ ì´ë™
            if self.use_gpu_acceleration and self.device != 'cpu':
                tensor = tensor.to(self.device)
            
            # í†µê³„ ì—…ë°ì´íŠ¸
            processing_time = time.time() - start_time
            self._update_stats('image_to_tensor', processing_time)
            
            self.logger.debug(f"ğŸ”„ ì´ë¯¸ì§€â†’í…ì„œ ë³€í™˜ ì™„ë£Œ: {tensor.shape} ({processing_time:.3f}s)")
            return tensor
            
        except Exception as e:
            self.logger.error(f"âŒ ì´ë¯¸ì§€â†’í…ì„œ ë³€í™˜ ì‹¤íŒ¨: {e}")
            self._conversion_stats["error_count"] += 1
            return None

    def tensor_to_image(
        self,
        tensor: torch.Tensor,
        denormalize: bool = False,
        format: str = "PIL"
    ) -> Optional[Union[Image.Image, np.ndarray]]:
        """í…ì„œë¥¼ ì´ë¯¸ì§€ë¡œ ë³€í™˜"""
        if not TORCH_AVAILABLE:
            self.logger.error("âŒ PyTorchê°€ ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ")
            return None
            
        try:
            start_time = time.time()
            
            # í…ì„œ ì „ì²˜ë¦¬
            if tensor.dim() == 4:
                tensor = tensor.squeeze(0)  # ë°°ì¹˜ ì°¨ì› ì œê±°
            
            if tensor.dim() != 3:
                raise ValueError(f"Invalid tensor dimensions: {tensor.shape}")
            
            # CPUë¡œ ì´ë™
            if tensor.device != torch.device('cpu'):
                tensor = tensor.cpu()
            
            # ì—­ì •ê·œí™”
            if denormalize:
                tensor = self._denormalize_tensor(tensor)
            
            # [0, 1] ë²”ìœ„ë¡œ í´ë¨í•‘
            tensor = torch.clamp(tensor, 0, 1)
            
            # PIL ì´ë¯¸ì§€ë¡œ ë³€í™˜
            if TF:
                pil_image = TF.to_pil_image(tensor)
            else:
                # í´ë°±: numpyë¥¼ í†µí•œ ë³€í™˜
                array = tensor.permute(1, 2, 0).numpy()
                array = (array * 255).astype(np.uint8)
                if PIL_AVAILABLE:
                    pil_image = Image.fromarray(array)
                else:
                    return array if format == "numpy" else None
            
            # ì¶œë ¥ í˜•ì‹ì— ë”°ë¥¸ ë³€í™˜
            if format.lower() == "pil":
                result = pil_image
            elif format.lower() == "numpy":
                result = np.array(pil_image)
            elif format.lower() == "cv2" and CV2_AVAILABLE:
                result = cv2.cvtColor(np.array(pil_image), cv2.COLOR_RGB2BGR)
            else:
                result = pil_image  # ê¸°ë³¸ê°’
            
            # í†µê³„ ì—…ë°ì´íŠ¸
            processing_time = time.time() - start_time
            self._update_stats('tensor_to_image', processing_time)
            
            self.logger.debug(f"ğŸ”„ í…ì„œâ†’ì´ë¯¸ì§€ ë³€í™˜ ì™„ë£Œ: {format} ({processing_time:.3f}s)")
            return result
            
        except Exception as e:
            self.logger.error(f"âŒ í…ì„œâ†’ì´ë¯¸ì§€ ë³€í™˜ ì‹¤íŒ¨: {e}")
            self._conversion_stats["error_count"] += 1
            return None

    def _to_pil_image(self, image_input: Union[Image.Image, np.ndarray, str, bytes]) -> Optional[Image.Image]:
        """ë‹¤ì–‘í•œ ì…ë ¥ì„ PIL ì´ë¯¸ì§€ë¡œ ë³€í™˜"""
        try:
            if not PIL_AVAILABLE:
                return None
                
            # ì´ë¯¸ PIL ì´ë¯¸ì§€ì¸ ê²½ìš°
            if isinstance(image_input, Image.Image):
                return image_input.convert('RGB')
            
            # NumPy ë°°ì—´ì¸ ê²½ìš°
            elif isinstance(image_input, np.ndarray):
                if image_input.ndim == 3:
                    return Image.fromarray(image_input.astype(np.uint8)).convert('RGB')
                elif image_input.ndim == 2:
                    return Image.fromarray(image_input.astype(np.uint8)).convert('RGB')
            
            # íŒŒì¼ ê²½ë¡œì¸ ê²½ìš°
            elif isinstance(image_input, (str, Path)):
                path = Path(image_input)
                if path.exists():
                    return Image.open(path).convert('RGB')
            
            # Base64 ë¬¸ìì—´ì¸ ê²½ìš°
            elif isinstance(image_input, str) and image_input.startswith('data:image'):
                # Data URL íŒŒì‹±
                header, data = image_input.split(',', 1)
                image_data = base64.b64decode(data)
                return Image.open(io.BytesIO(image_data)).convert('RGB')
            
            # ë°”ì´íŠ¸ ë°ì´í„°ì¸ ê²½ìš°
            elif isinstance(image_input, bytes):
                return Image.open(io.BytesIO(image_input)).convert('RGB')
            
            else:
                self.logger.error(f"âŒ ì§€ì›ë˜ì§€ ì•ŠëŠ” ì´ë¯¸ì§€ í˜•ì‹: {type(image_input)}")
                return None
                
        except Exception as e:
            self.logger.error(f"âŒ PIL ì´ë¯¸ì§€ ë³€í™˜ ì‹¤íŒ¨: {e}")
            return None

    def _denormalize_tensor(self, tensor: torch.Tensor) -> torch.Tensor:
        """ì •ê·œí™”ëœ í…ì„œë¥¼ ì—­ì •ê·œí™”"""
        try:
            if TORCH_AVAILABLE:
                # í‰ê· ê³¼ í‘œì¤€í¸ì°¨ë¥¼ í…ì„œë¡œ ë³€í™˜
                mean = torch.tensor(self.normalize_mean).view(-1, 1, 1)
                std = torch.tensor(self.normalize_std).view(-1, 1, 1)
                
                # ì—­ì •ê·œí™”: tensor * std + mean
                denormalized = tensor * std + mean
                return denormalized
            else:
                return tensor
                
        except Exception as e:
            self.logger.error(f"âŒ ì—­ì •ê·œí™” ì‹¤íŒ¨: {e}")
            return tensor

    def batch_convert_images(
        self,
        images: List[Union[Image.Image, np.ndarray, str]],
        target_format: str = "tensor",
        **kwargs
    ) -> List[Optional[Any]]:
        """ë°°ì¹˜ ì´ë¯¸ì§€ ë³€í™˜"""
        try:
            start_time = time.time()
            results = []
            
            for i, image in enumerate(images):
                try:
                    if target_format.lower() == "tensor":
                        result = self.image_to_tensor(image, **kwargs)
                    elif target_format.lower() == "pil":
                        result = self._to_pil_image(image)
                    elif target_format.lower() == "numpy":
                        pil_img = self._to_pil_image(image)
                        result = np.array(pil_img) if pil_img else None
                    else:
                        result = None
                        
                    results.append(result)
                    
                except Exception as e:
                    self.logger.error(f"âŒ ë°°ì¹˜ ë³€í™˜ ì‹¤íŒ¨ (ì¸ë±ìŠ¤ {i}): {e}")
                    results.append(None)
            
            processing_time = time.time() - start_time
            success_count = sum(1 for r in results if r is not None)
            
            self.logger.info(f"ğŸ“¦ ë°°ì¹˜ ë³€í™˜ ì™„ë£Œ: {success_count}/{len(images)} ì„±ê³µ ({processing_time:.3f}s)")
            
            return results
            
        except Exception as e:
            self.logger.error(f"âŒ ë°°ì¹˜ ë³€í™˜ ì‹¤íŒ¨: {e}")
            return [None] * len(images)

    def resize_image(
        self,
        image: Union[Image.Image, np.ndarray],
        size: Tuple[int, int],
        method: str = "bilinear",
        preserve_aspect_ratio: bool = False
    ) -> Optional[Union[Image.Image, np.ndarray]]:
        """ì´ë¯¸ì§€ í¬ê¸° ì¡°ì •"""
        try:
            if isinstance(image, np.ndarray):
                if CV2_AVAILABLE:
                    # OpenCV ì‚¬ìš©
                    if method == "bilinear":
                        interpolation = cv2.INTER_LINEAR
                    elif method == "nearest":
                        interpolation = cv2.INTER_NEAREST
                    elif method == "bicubic":
                        interpolation = cv2.INTER_CUBIC
                    else:
                        interpolation = cv2.INTER_LINEAR
                    
                    if preserve_aspect_ratio:
                        size = self._calculate_aspect_ratio_size(image.shape[:2][::-1], size)
                    
                    resized = cv2.resize(image, size, interpolation=interpolation)
                    return resized
                else:
                    # PIL í´ë°±
                    if PIL_AVAILABLE:
                        pil_image = Image.fromarray(image)
                        return self.resize_image(pil_image, size, method, preserve_aspect_ratio)
                    
            elif PIL_AVAILABLE and isinstance(image, Image.Image):
                # PIL ì‚¬ìš©
                if preserve_aspect_ratio:
                    size = self._calculate_aspect_ratio_size(image.size, size)
                
                if method == "bilinear":
                    resample = Image.BILINEAR
                elif method == "nearest":
                    resample = Image.NEAREST
                elif method == "bicubic":
                    resample = Image.BICUBIC
                else:
                    resample = Image.BILINEAR
                
                return image.resize(size, resample)
            
            return None
            
        except Exception as e:
            self.logger.error(f"âŒ ì´ë¯¸ì§€ í¬ê¸° ì¡°ì • ì‹¤íŒ¨: {e}")
            return None

    def _calculate_aspect_ratio_size(
        self,
        original_size: Tuple[int, int],
        target_size: Tuple[int, int]
    ) -> Tuple[int, int]:
        """ì¢…íš¡ë¹„ë¥¼ ìœ ì§€í•˜ëŠ” í¬ê¸° ê³„ì‚°"""
        orig_w, orig_h = original_size
        target_w, target_h = target_size
        
        # ì¢…íš¡ë¹„ ê³„ì‚°
        aspect_ratio = orig_w / orig_h
        
        # íƒ€ê²Ÿ í¬ê¸°ì— ë§ëŠ” í¬ê¸° ê³„ì‚°
        if target_w / target_h > aspect_ratio:
            # ë†’ì´ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì¡°ì •
            new_h = target_h
            new_w = int(target_h * aspect_ratio)
        else:
            # ë„ˆë¹„ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì¡°ì •
            new_w = target_w
            new_h = int(target_w / aspect_ratio)
        
        return (new_w, new_h)

    def normalize_image(
        self,
        image: Union[Image.Image, np.ndarray, torch.Tensor],
        mean: Optional[List[float]] = None,
        std: Optional[List[float]] = None
    ) -> Optional[torch.Tensor]:
        """ì´ë¯¸ì§€ ì •ê·œí™”"""
        try:
            # ê¸°ë³¸ê°’ ì„¤ì •
            mean = mean or self.normalize_mean
            std = std or self.normalize_std
            
            # í…ì„œë¡œ ë³€í™˜
            if isinstance(image, torch.Tensor):
                tensor = image
            else:
                tensor = self.image_to_tensor(image, normalize=False)
                
            if tensor is None:
                return None
            
            # ì •ê·œí™” ì ìš©
            if TORCH_AVAILABLE:
                normalize_transform = transforms.Normalize(mean=mean, std=std)
                normalized_tensor = normalize_transform(tensor.squeeze(0))
                
                # ë°°ì¹˜ ì°¨ì› ë‹¤ì‹œ ì¶”ê°€
                if normalized_tensor.dim() == 3:
                    normalized_tensor = normalized_tensor.unsqueeze(0)
                
                return normalized_tensor
            
            return tensor
            
        except Exception as e:
            self.logger.error(f"âŒ ì´ë¯¸ì§€ ì •ê·œí™” ì‹¤íŒ¨: {e}")
            return None

    def image_to_base64(
        self,
        image: Union[Image.Image, np.ndarray],
        format: str = "PNG",
        quality: int = 95
    ) -> Optional[str]:
        """ì´ë¯¸ì§€ë¥¼ Base64 ë¬¸ìì—´ë¡œ ë³€í™˜"""
        try:
            # PIL ì´ë¯¸ì§€ë¡œ ë³€í™˜
            pil_image = self._to_pil_image(image)
            if pil_image is None:
                return None
            
            # ë°”ì´íŠ¸ ë²„í¼ì— ì €ì¥
            buffer = io.BytesIO()
            
            if format.upper() == "JPEG":
                pil_image.save(buffer, format=format, quality=quality)
            else:
                pil_image.save(buffer, format=format)
            
            # Base64 ì¸ì½”ë”©
            image_data = buffer.getvalue()
            base64_string = base64.b64encode(image_data).decode('utf-8')
            
            # Data URL í˜•ì‹ìœ¼ë¡œ ë°˜í™˜
            mime_type = f"image/{format.lower()}"
            return f"data:{mime_type};base64,{base64_string}"
            
        except Exception as e:
            self.logger.error(f"âŒ Base64 ë³€í™˜ ì‹¤íŒ¨: {e}")
            return None

    def _update_stats(self, operation: str, processing_time: float):
        """ë³€í™˜ í†µê³„ ì—…ë°ì´íŠ¸"""
        try:
            self._conversion_stats["total_conversions"] += 1
            self._conversion_stats["total_time"] += processing_time
            
            if operation not in self._conversion_stats["format_counts"]:
                self._conversion_stats["format_counts"][operation] = 0
            self._conversion_stats["format_counts"][operation] += 1
            
        except Exception:
            pass  # í†µê³„ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨ëŠ” ë¬´ì‹œ

    def get_conversion_stats(self) -> Dict[str, Any]:
        """ë³€í™˜ í†µê³„ ì¡°íšŒ"""
        stats = self._conversion_stats.copy()
        
        if stats["total_conversions"] > 0:
            stats["average_time"] = stats["total_time"] / stats["total_conversions"]
        else:
            stats["average_time"] = 0.0
            
        return stats

    async def get_step_info(self) -> Dict[str, Any]:
        """ë°ì´í„° ë³€í™˜ê¸° ì •ë³´ ë°˜í™˜"""
        return {
            "step_name": self.step_name,
            "device": self.device,
            "device_type": self.device_type,
            "memory_gb": self.memory_gb,
            "is_m3_max": self.is_m3_max,
            "optimization_enabled": self.optimization_enabled,
            "quality_level": self.quality_level,
            "initialized": self.is_initialized,
            "config_keys": list(self.config.keys()),
            "specialized_features": {
                "default_size": self.default_size,
                "interpolation": self.interpolation,
                "use_gpu_acceleration": self.use_gpu_acceleration,
                "batch_processing": self.batch_processing,
                "memory_efficient": self.memory_efficient,
                "quality_preservation": self.quality_preservation
            },
            "library_support": {
                "PIL": PIL_AVAILABLE,
                "OpenCV": CV2_AVAILABLE,
                "PyTorch": TORCH_AVAILABLE
            },
            "conversion_stats": self.get_conversion_stats()
        }

# í¸ì˜ í•¨ìˆ˜ë“¤ (í•˜ìœ„ í˜¸í™˜ì„±)
def create_data_converter(
    default_size: Tuple[int, int] = (512, 512),
    device: str = "mps",
    **kwargs
) -> DataConverter:
    """ë°ì´í„° ë³€í™˜ê¸° ìƒì„± (í•˜ìœ„ í˜¸í™˜)"""
    return DataConverter(
        device=device,
        default_size=default_size,
        **kwargs
    )

# ì „ì—­ ë°ì´í„° ë³€í™˜ê¸° (ì„ íƒì )
_global_data_converter: Optional[DataConverter] = None

def get_global_data_converter() -> Optional[DataConverter]:
    """ì „ì—­ ë°ì´í„° ë³€í™˜ê¸° ë°˜í™˜"""
    global _global_data_converter
    return _global_data_converter

def initialize_global_data_converter(**kwargs) -> DataConverter:
    """ì „ì—­ ë°ì´í„° ë³€í™˜ê¸° ì´ˆê¸°í™”"""
    global _global_data_converter
    _global_data_converter = DataConverter(**kwargs)
    return _global_data_converter

# ë¹ ë¥¸ ë³€í™˜ í•¨ìˆ˜ë“¤ (í¸ì˜ì„±)
def quick_image_to_tensor(image: Union[Image.Image, np.ndarray], size: Tuple[int, int] = (512, 512)) -> Optional[torch.Tensor]:
    """ë¹ ë¥¸ ì´ë¯¸ì§€â†’í…ì„œ ë³€í™˜"""
    converter = get_global_data_converter()
    if converter is None:
        converter = DataConverter(default_size=size)
    return converter.image_to_tensor(image, size=size)

def quick_tensor_to_image(tensor: torch.Tensor) -> Optional[Image.Image]:
    """ë¹ ë¥¸ í…ì„œâ†’ì´ë¯¸ì§€ ë³€í™˜"""
    converter = get_global_data_converter()
    if converter is None:
        converter = DataConverter()
    return converter.tensor_to_image(tensor)

# ëª¨ë“ˆ ìµìŠ¤í¬íŠ¸
__all__ = [
    'DataConverter',
    'create_data_converter',
    'get_global_data_converter',
    'initialize_global_data_converter',
    'quick_image_to_tensor',
    'quick_tensor_to_image'
]