# backend/app/ai_pipeline/utils/data_converter.py
"""
ğŸ”¥ MyCloset AI - Central Hub DI Container v7.0 ì™„ì „ ì—°ë™ ë°ì´í„° ë³€í™˜ê¸° 
================================================================================
âœ… Central Hub DI Container v7.0 ì™„ì „ ì—°ë™
âœ… IDependencyInjectable ì¸í„°í˜ì´ìŠ¤ ì œê±°
âœ… ë‹¨ìˆœí™”ëœ DI íŒ¨í„´ ì ìš©
âœ… BaseStepMixinê³¼ ì™„ë²½ í˜¸í™˜
âœ… ìˆœí™˜ì°¸ì¡° ì™„ì „ ë°©ì§€
âœ… ê¸°ì¡´ ì¸í„°í˜ì´ìŠ¤ 100% ìœ ì§€
âœ… Mock í´ë°± êµ¬í˜„ì²´ í¬í•¨
âœ… M3 Max ìµœì í™” ìœ ì§€
âœ… ì‹±ê¸€í†¤ íŒ¨í„´ + Central Hub ìë™ ë“±ë¡
================================================================================
Author: MyCloset AI Team
Date: 2025-07-30
Version: 9.0 (Central Hub DI Integration)
"""

import io
import logging
import time
import base64
import threading
import weakref
from typing import Dict, Any, Optional, Union, List, Tuple, TYPE_CHECKING, Protocol
from pathlib import Path
import asyncio
from functools import wraps

# ğŸ”¥ Central Hub DI Container ì•ˆì „ import (ìˆœí™˜ì°¸ì¡° ë°©ì§€)
if TYPE_CHECKING:
    # íƒ€ì… íŒíŒ…ìš© ì„í¬íŠ¸ (ëŸ°íƒ€ì„ì—ëŠ” ì‹¤í–‰ë˜ì§€ ì•ŠìŒ)
    import torch
    import numpy as np
    from PIL import Image
    from app.core.di_container import CentralHubDIContainer
else:
    # ëŸ°íƒ€ì„ì—ëŠ” ë™ì  ì„í¬íŠ¸
    pass

# NumPy ì•ˆì „í•œ ì„í¬íŠ¸
try:
    import numpy as np
    NUMPY_AVAILABLE = True
    NUMPY_VERSION = np.__version__
    
    # NumPy 2.x í˜¸í™˜ì„± ì²˜ë¦¬
    major_version = int(np.__version__.split('.')[0])
    if major_version >= 2:
        try:
            np.set_printoptions(legacy='1.25')
            logging.info("âœ… NumPy 2.x í˜¸í™˜ì„± ëª¨ë“œ í™œì„±í™”")
        except:
            pass
except ImportError:
    NUMPY_AVAILABLE = False
    np = None
    NUMPY_VERSION = "not_available"

# PIL ì•ˆì „í•œ ì„í¬íŠ¸
try:
    from PIL import Image, ImageEnhance, ImageFilter, ImageOps
    PIL_AVAILABLE = True
    PIL_VERSION = getattr(Image, '__version__', 'unknown')
except ImportError:
    PIL_AVAILABLE = False
    Image = None
    PIL_VERSION = "not_available"

# OpenCV ì•ˆì „í•œ ì„í¬íŠ¸
try:
    import cv2
    CV2_AVAILABLE = True
    CV2_VERSION = cv2.__version__
except ImportError:
    CV2_AVAILABLE = False
    cv2 = None
    CV2_VERSION = "not_available"

# PyTorch ì™„ì „ ì•ˆì „í•œ ì„í¬íŠ¸
try:
    # MPS í™˜ê²½ë³€ìˆ˜ ì„¤ì • (M3 Max ìµœì í™”)
    import os
    os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '1'
    os.environ['PYTORCH_MPS_HIGH_WATERMARK_RATIO'] = '0.0'
    
    import torch
    import torchvision.transforms as transforms
    import torchvision.transforms.functional as TF
    TORCH_AVAILABLE = True
    TORCH_VERSION = torch.__version__
    
    # MPS ì§€ì› í™•ì¸
    if hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
        MPS_AVAILABLE = True
        DEFAULT_DEVICE = "mps"
    else:
        MPS_AVAILABLE = False
        DEFAULT_DEVICE = "cpu"
        
except ImportError:
    TORCH_AVAILABLE = False
    MPS_AVAILABLE = False
    torch = None
    transforms = None
    TF = None
    DEFAULT_DEVICE = "cpu"
    TORCH_VERSION = "not_available"

logger = logging.getLogger(__name__)

# ==============================================
# ğŸ”¥ Central Hub DI ê´€ë ¨ ì¸í„°í˜ì´ìŠ¤ (ê°„ì†Œí™”)
# ==============================================

class IDataConverter(Protocol):
    """DataConverter ì¸í„°í˜ì´ìŠ¤ (Central Hubìš©)"""
    
    def image_to_tensor(self, image: Any, **kwargs) -> Optional[Any]:
        """ì´ë¯¸ì§€ë¥¼ í…ì„œë¡œ ë³€í™˜"""
        ...
    
    def tensor_to_image(self, tensor: Any, **kwargs) -> Optional[Any]:
        """í…ì„œë¥¼ ì´ë¯¸ì§€ë¡œ ë³€í™˜"""
        ...
    
    def tensor_to_numpy(self, tensor: Any) -> Optional[Any]:
        """í…ì„œë¥¼ numpyë¡œ ë³€í™˜"""
        ...
    
    def batch_convert_images(self, images: List[Any], target_format: str, **kwargs) -> List[Any]:
        """ë°°ì¹˜ ì´ë¯¸ì§€ ë³€í™˜"""
        ...

# ==============================================
# ğŸ”¥ ë°ì´í„° êµ¬ì¡° ì •ì˜ (ê¸°ì¡´ ìœ ì§€)
# ==============================================

class ConversionMode:
    """ë³€í™˜ ëª¨ë“œ"""
    FAST = "fast"
    BALANCED = "balanced"
    QUALITY = "quality"
    M3_OPTIMIZED = "m3_optimized"

class ImageFormat:
    """ì§€ì› ì´ë¯¸ì§€ í¬ë§·"""
    PIL = "PIL"
    NUMPY = "numpy"
    TENSOR = "tensor"
    CV2 = "cv2"
    BASE64 = "base64"

# ==============================================
# ğŸ”¥ Central Hub í†µí•© DataConverter í´ë˜ìŠ¤
# ==============================================

class DataConverter:
    """
    ğŸ”¥ Central Hub DI Container v7.0 ì™„ì „ í†µí•© ë°ì´í„° ë³€í™˜ê¸°
    âœ… CentralHubDIContainer ì—°ë™
    âœ… IDependencyInjectable ì¸í„°í˜ì´ìŠ¤ ì œê±°
    âœ… ë‹¨ìˆœí™”ëœ ì˜ì¡´ì„± ì£¼ì…
    âœ… ê¸°ì¡´ ì¸í„°í˜ì´ìŠ¤ 100% ìœ ì§€
    âœ… ìˆœí™˜ì°¸ì¡° ë°©ì§€
    âœ… Mock í´ë°± êµ¬í˜„ì²´
    """
    
    def __init__(
        self,
        device: Optional[str] = None,
        config: Optional[Dict[str, Any]] = None,
        **kwargs
    ):
        """Central Hub DI ì§€ì› ë°ì´í„° ë³€í™˜ê¸° ì´ˆê¸°í™”"""
        # 1. ê¸°ë³¸ ì†ì„± ì´ˆê¸°í™”
        self.device = self._auto_detect_device(device)
        self.config = config or {}
        self.step_name = self.__class__.__name__
        
        # ğŸ”¥ logger ì†ì„± ë³´ì¥ (BaseStepMixin í˜¸í™˜)
        self.logger = logging.getLogger(f"utils.{self.step_name}")
        
        # 2. ìŠ¤ë ˆë“œ ì•ˆì „ì„±
        self._lock = threading.RLock()
        
        # 3. ì‹œìŠ¤í…œ íŒŒë¼ë¯¸í„°
        self.memory_gb = kwargs.get('memory_gb', 16.0)
        self.is_m3_max = kwargs.get('is_m3_max', self._detect_m3_max())
        self.optimization_enabled = kwargs.get('optimization_enabled', True)

        # 4. ë°ì´í„° ë³€í™˜ê¸° íŠ¹í™” íŒŒë¼ë¯¸í„°
        self.default_size = tuple(kwargs.get('default_size', (512, 512)))
        self.interpolation = kwargs.get('interpolation', 'bilinear')
        self.normalize_mean = kwargs.get('normalize_mean', [0.485, 0.456, 0.406])
        self.normalize_std = kwargs.get('normalize_std', [0.229, 0.224, 0.225])
        self.use_gpu_acceleration = kwargs.get('use_gpu_acceleration', self.device != 'cpu')
        self.batch_processing = kwargs.get('batch_processing', True)
        self.memory_efficient = kwargs.get('memory_efficient', True)
        self.quality_preservation = kwargs.get('quality_preservation', True)
        self.conversion_mode = kwargs.get('conversion_mode', ConversionMode.BALANCED)

        # 5. M3 Max íŠ¹í™” ì„¤ì •
        if self.is_m3_max:
            self.use_gpu_acceleration = True
            self.batch_processing = True
            self.memory_efficient = False  # 128GB ë©”ëª¨ë¦¬ì´ë¯€ë¡œ í’ˆì§ˆ ìš°ì„ 
            self.conversion_mode = ConversionMode.M3_OPTIMIZED

        # 6. ìƒíƒœ ì´ˆê¸°í™”
        self.is_initialized = False
        self._initialize_components()

        # 7. Central Hub DI Container ìë™ ë“±ë¡
        self._register_to_central_hub()

        self.logger.info(f"ğŸ¯ Central Hub DataConverter ì´ˆê¸°í™” - ë””ë°”ì´ìŠ¤: {self.device}")
        self.logger.info(f"ğŸ“š ë¼ì´ë¸ŒëŸ¬ë¦¬ ìƒíƒœ: PyTorch={TORCH_AVAILABLE}, PIL={PIL_AVAILABLE}, NumPy={NUMPY_AVAILABLE}")

    # ==============================================
    # ğŸ”¥ Central Hub DI Container ì—°ë™
    # ==============================================

    def _register_to_central_hub(self):
        """Central Hub DI Containerì— ìë™ ë“±ë¡"""
        try:
            # ë™ì ìœ¼ë¡œ Central Hub Container ê°€ì ¸ì˜¤ê¸°
            from app.core.di_container import get_global_container
            container = get_global_container()
            
            if container:
                # ìë™ ë“±ë¡
                container.register('data_converter', self)
                container.register('IDataConverter', self)
                
                self.logger.info("âœ… DataConverterê°€ Central Hubì— ë“±ë¡ë¨")
                
                # ë‹¤ë¥¸ ì„œë¹„ìŠ¤ë“¤ ì°¸ì¡° ì‹œë„
                self._resolve_central_hub_dependencies(container)
                
        except Exception as e:
            self.logger.debug(f"Central Hub ìë™ ë“±ë¡ ì‹¤íŒ¨: {e}")

    def _resolve_central_hub_dependencies(self, container):
        """Central Hubë¥¼ í†µí•œ ì˜ì¡´ì„± í•´ê²°"""
        try:
            # ModelLoader í•´ê²°
            model_loader = container.get('model_loader')
            if model_loader:
                self.model_loader = model_loader
                self.logger.debug("âœ… ModelLoader ì˜ì¡´ì„± í•´ê²°")
            
            # MemoryManager í•´ê²°
            memory_manager = container.get('memory_manager')
            if memory_manager:
                self.memory_manager = memory_manager
                self.logger.debug("âœ… MemoryManager ì˜ì¡´ì„± í•´ê²°")
                
        except Exception as e:
            self.logger.debug(f"Central Hub ì˜ì¡´ì„± í•´ê²° ì‹¤íŒ¨: {e}")

    # ==============================================
    # ğŸ”¥ ê¸°ì¡´ ë©”ì„œë“œë“¤ (100% ìœ ì§€)
    # ==============================================

    def _auto_detect_device(self, preferred_device: Optional[str]) -> str:
        """ğŸ’¡ ì§€ëŠ¥ì  ë””ë°”ì´ìŠ¤ ìë™ ê°ì§€"""
        if preferred_device:
            return preferred_device

        if not TORCH_AVAILABLE:
            return 'cpu'

        try:
            if hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
                return 'mps'  # M3 Max ìš°ì„ 
            elif torch.cuda.is_available():
                return 'cuda'  # NVIDIA GPU
            else:
                return 'cpu'  # í´ë°±
        except Exception as e:
            self.logger.warning(f"ë””ë°”ì´ìŠ¤ ê°ì§€ ì‹¤íŒ¨: {e}")
            return 'cpu'

    def _detect_m3_max(self) -> bool:
        """ğŸ M3 Max ì¹© ìë™ ê°ì§€"""
        try:
            import platform
            import subprocess

            if platform.system() == 'Darwin':  # macOS
                result = subprocess.run(['sysctl', '-n', 'machdep.cpu.brand_string'], 
                                      capture_output=True, text=True, timeout=5)
                chip_info = result.stdout.strip()
                return 'M3' in chip_info and 'Max' in chip_info
        except Exception as e:
            self.logger.debug(f"M3 Max ê°ì§€ ì‹¤íŒ¨: {e}")
        return False

    def _initialize_components(self):
        """êµ¬ì„± ìš”ì†Œ ì´ˆê¸°í™”"""
        # ë³€í™˜ íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™”
        self._init_transforms()
        
        # í†µê³„ ì¶”ì 
        self._conversion_stats = {
            "total_conversions": 0,
            "total_time": 0.0,
            "format_counts": {},
            "error_count": 0,
            "m3_optimizations": 0
        }
        
        self.logger.info(f"ğŸ”„ DataConverter êµ¬ì„± ìš”ì†Œ ì´ˆê¸°í™” ì™„ë£Œ")
        
        # M3 Max ìµœì í™” ì„¤ì •
        if self.device == "mps" and self.is_m3_max:
            self.logger.info("ğŸ M3 Max ë°ì´í„° ë³€í™˜ ìµœì í™” ëª¨ë“œ í™œì„±í™”")
            self._apply_m3_max_optimizations()
        
        # ì´ˆê¸°í™” ì™„ë£Œ
        self.is_initialized = True

    def _init_transforms(self):
        """ë³€í™˜ íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™”"""
        self.transforms = {}
        
        if not TORCH_AVAILABLE:
            self.logger.warning("âš ï¸ PyTorch ì—†ìŒ - ë³€í™˜ íŒŒì´í”„ë¼ì¸ ì œí•œ")
            return
        
        try:
            # ë³´ê°„ ë°©ë²• ë§¤í•‘
            interpolation_map = {
                'bilinear': transforms.InterpolationMode.BILINEAR if hasattr(transforms, 'InterpolationMode') else 2,
                'nearest': transforms.InterpolationMode.NEAREST if hasattr(transforms, 'InterpolationMode') else 0,
                'bicubic': transforms.InterpolationMode.BICUBIC if hasattr(transforms, 'InterpolationMode') else 3
            }
            
            interpolation_mode = interpolation_map.get(self.interpolation, 2)
            
            # ê¸°ë³¸ ë³€í™˜ íŒŒì´í”„ë¼ì¸
            self.transforms['default'] = transforms.Compose([
                transforms.Resize(self.default_size, interpolation=interpolation_mode),
                transforms.ToTensor()
            ])
            
            # ì •ê·œí™” ë³€í™˜
            self.transforms['normalized'] = transforms.Compose([
                transforms.Resize(self.default_size, interpolation=interpolation_mode),
                transforms.ToTensor(),
                transforms.Normalize(mean=self.normalize_mean, std=self.normalize_std)
            ])
            
            # ê³ í’ˆì§ˆ ë³€í™˜ (M3 Max ìµœì í™”)
            if self.is_m3_max and self.quality_preservation:
                self.transforms['high_quality'] = transforms.Compose([
                    transforms.Resize(self.default_size, interpolation=interpolation_mode),
                    transforms.ToTensor()
                ])
                
                # M3 Max ì „ìš© ê³ í•´ìƒë„ ë³€í™˜
                self.transforms['m3_max_quality'] = transforms.Compose([
                    transforms.Resize((1024, 1024) if self.default_size[0] < 1024 else self.default_size, 
                                    interpolation=interpolation_mode),
                    transforms.ToTensor()
                ])
                
        except Exception as e:
            self.logger.error(f"âŒ ë³€í™˜ íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")

    def _apply_m3_max_optimizations(self):
        """M3 Max íŠ¹í™” ìµœì í™” ì ìš©"""
        try:
            optimizations = []
            
            # 1. ê³ í•´ìƒë„ ì²˜ë¦¬ í™œì„±í™”
            if self.default_size[0] < 1024:
                self.default_size = (1024, 1024)
                optimizations.append("High resolution processing (1024x1024)")
            
            # 2. ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± ì¡°ì • (128GB ë©”ëª¨ë¦¬)
            self.memory_efficient = False  # í’ˆì§ˆ ìš°ì„ 
            optimizations.append("Quality-first processing mode")
            
            # 3. MPS ë°±ì—”ë“œ ìµœì í™”
            if TORCH_AVAILABLE and MPS_AVAILABLE:
                optimizations.append("MPS backend acceleration")
            
            # 4. ë°°ì¹˜ ì²˜ë¦¬ ìµœì í™”
            self.batch_processing = True
            optimizations.append("Optimized batch processing")
            
            if optimizations:
                self.logger.info(f"ğŸ M3 Max ë°ì´í„° ë³€í™˜ ìµœì í™” ì ìš©:")
                for opt in optimizations:
                    self.logger.info(f"   - {opt}")
                
        except Exception as e:
            self.logger.warning(f"âš ï¸ M3 Max ìµœì í™” ì‹¤íŒ¨: {e}")

    # ============================================
    # ğŸ”¥ í•µì‹¬ ë³€í™˜ ë©”ì„œë“œë“¤ (ê¸°ì¡´ ìœ ì§€)
    # ============================================

    def image_to_tensor(
        self,
        image: Union["Image.Image", "np.ndarray", str, bytes],
        size: Optional[Tuple[int, int]] = None,
        normalize: bool = False,
        **kwargs
    ) -> Optional["torch.Tensor"]:
        """ì´ë¯¸ì§€ë¥¼ í…ì„œë¡œ ë³€í™˜ (Central Hub ìµœì í™”)"""
        if not TORCH_AVAILABLE:
            self.logger.error("âŒ PyTorchê°€ ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ")
            return None
            
        try:
            start_time = time.time()
            
            # Central Hubë¥¼ í†µí•œ ë©”ëª¨ë¦¬ ê´€ë¦¬
            if hasattr(self, 'memory_manager') and self.memory_manager:
                try:
                    self.memory_manager.optimize_memory()
                except Exception:
                    pass  # ë©”ëª¨ë¦¬ ê´€ë¦¬ ì‹¤íŒ¨ëŠ” ë¬´ì‹œ
            
            # ì´ë¯¸ì§€ ì „ì²˜ë¦¬
            pil_image = self._to_pil_image(image)
            if pil_image is None:
                return None
            
            # í¬ê¸° ì„¤ì •
            target_size = size or self.default_size
            
            # ë³€í™˜ íŒŒì´í”„ë¼ì¸ ì„ íƒ
            if self.is_m3_max and self.conversion_mode == ConversionMode.M3_OPTIMIZED:
                transform = self.transforms.get('m3_max_quality')
                self._conversion_stats["m3_optimizations"] += 1
            elif normalize:
                transform = self.transforms.get('normalized')
            elif self.is_m3_max and self.quality_preservation:
                transform = self.transforms.get('high_quality')
            else:
                transform = self.transforms.get('default')
            
            if transform is None:
                # í´ë°± ë³€í™˜
                if hasattr(pil_image, 'resize'):
                    pil_image = pil_image.resize(target_size)
                tensor = TF.to_tensor(pil_image) if TF else None
            else:
                tensor = transform(pil_image)
            
            if tensor is None:
                return None
            
            # ë°°ì¹˜ ì°¨ì› ì¶”ê°€
            if tensor.dim() == 3:
                tensor = tensor.unsqueeze(0)
            
            # ë””ë°”ì´ìŠ¤ë¡œ ì´ë™
            if self.use_gpu_acceleration and self.device != 'cpu':
                tensor = tensor.to(self.device)
            
            # í†µê³„ ì—…ë°ì´íŠ¸
            processing_time = time.time() - start_time
            self._update_stats('image_to_tensor', processing_time)
            
            self.logger.debug(f"ğŸ”„ ì´ë¯¸ì§€â†’í…ì„œ ë³€í™˜ ì™„ë£Œ: {tensor.shape} ({processing_time:.3f}s)")
            return tensor
            
        except Exception as e:
            self.logger.error(f"âŒ ì´ë¯¸ì§€â†’í…ì„œ ë³€í™˜ ì‹¤íŒ¨: {e}")
            self._conversion_stats["error_count"] += 1
            return None

    def tensor_to_image(
        self,
        tensor: "torch.Tensor",
        denormalize: bool = False,
        format: str = "PIL"
    ) -> Optional[Union["Image.Image", "np.ndarray"]]:
        """í…ì„œë¥¼ ì´ë¯¸ì§€ë¡œ ë³€í™˜ (ê¸°ì¡´ êµ¬í˜„ ìœ ì§€)"""
        if not TORCH_AVAILABLE:
            self.logger.error("âŒ PyTorchê°€ ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ")
            return None
            
        try:
            start_time = time.time()
            
            # í…ì„œ ì „ì²˜ë¦¬
            if tensor.dim() == 4:
                tensor = tensor.squeeze(0)  # ë°°ì¹˜ ì°¨ì› ì œê±°
            
            if tensor.dim() != 3:
                raise ValueError(f"Invalid tensor dimensions: {tensor.shape}")
            
            # CPUë¡œ ì´ë™
            if tensor.device != torch.device('cpu'):
                tensor = tensor.cpu()
            
            # ì—­ì •ê·œí™”
            if denormalize:
                tensor = self._denormalize_tensor(tensor)
            
            # [0, 1] ë²”ìœ„ë¡œ í´ë¨í•‘
            tensor = torch.clamp(tensor, 0, 1)
            
            # PIL ì´ë¯¸ì§€ë¡œ ë³€í™˜
            if TF:
                pil_image = TF.to_pil_image(tensor)
            else:
                # í´ë°±: numpyë¥¼ í†µí•œ ë³€í™˜
                if NUMPY_AVAILABLE:
                    array = tensor.permute(1, 2, 0).numpy()
                    array = (array * 255).astype(np.uint8)
                    if PIL_AVAILABLE:
                        pil_image = Image.fromarray(array)
                    else:
                        return array if format == "numpy" else None
                else:
                    return None
            
            # ì¶œë ¥ í˜•ì‹ì— ë”°ë¥¸ ë³€í™˜
            if format.lower() == "pil":
                result = pil_image
            elif format.lower() == "numpy":
                if NUMPY_AVAILABLE:
                    result = np.array(pil_image)
                else:
                    result = None
            elif format.lower() == "cv2" and CV2_AVAILABLE:
                if NUMPY_AVAILABLE:
                    result = cv2.cvtColor(np.array(pil_image), cv2.COLOR_RGB2BGR)
                else:
                    result = None
            else:
                result = pil_image  # ê¸°ë³¸ê°’
            
            # í†µê³„ ì—…ë°ì´íŠ¸
            processing_time = time.time() - start_time
            self._update_stats('tensor_to_image', processing_time)
            
            self.logger.debug(f"ğŸ”„ í…ì„œâ†’ì´ë¯¸ì§€ ë³€í™˜ ì™„ë£Œ: {format} ({processing_time:.3f}s)")
            return result
            
        except Exception as e:
            self.logger.error(f"âŒ í…ì„œâ†’ì´ë¯¸ì§€ ë³€í™˜ ì‹¤íŒ¨: {e}")
            self._conversion_stats["error_count"] += 1
            return None

    def tensor_to_numpy(self, tensor: "torch.Tensor") -> Optional["np.ndarray"]:
        """í…ì„œë¥¼ numpy ë°°ì—´ë¡œ ë³€í™˜ (ê¸°ì¡´ ë©”ì„œë“œëª… ìœ ì§€)"""
        if not TORCH_AVAILABLE or not NUMPY_AVAILABLE:
            self.logger.error("âŒ PyTorch ë˜ëŠ” NumPyê°€ ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ")
            return None
            
        try:
            if tensor.dim() == 4:
                tensor = tensor.squeeze(0)  # ë°°ì¹˜ ì°¨ì› ì œê±°
            
            if tensor.dim() == 3:
                # (C, H, W) -> (H, W, C)ë¡œ ë³€í™˜
                tensor = tensor.permute(1, 2, 0)
            
            # CPUë¡œ ì´ë™
            if tensor.device != torch.device('cpu'):
                tensor = tensor.cpu()
            
            # numpy ë°°ì—´ë¡œ ë³€í™˜
            array = tensor.numpy()
            
            # [0, 1] ë²”ìœ„ë¥¼ [0, 255]ë¡œ ë³€í™˜ (í•„ìš”ì‹œ)
            if array.max() <= 1.0:
                array = (array * 255).astype(np.uint8)
            
            return array
            
        except Exception as e:
            self.logger.error(f"âŒ í…ì„œâ†’numpy ë³€í™˜ ì‹¤íŒ¨: {e}")
            return None

    def batch_convert_images(
        self,
        images: List[Union["Image.Image", "np.ndarray", str]],
        target_format: str = "tensor",
        **kwargs
    ) -> List[Optional[Any]]:
        """ë°°ì¹˜ ì´ë¯¸ì§€ ë³€í™˜ (Central Hub ìµœì í™”)"""
        try:
            start_time = time.time()
            results = []
            
            # Central Hubë¥¼ í†µí•œ ë©”ëª¨ë¦¬ ìµœì í™”
            if hasattr(self, 'memory_manager') and self.memory_manager:
                try:
                    self.memory_manager.optimize_memory()
                except Exception:
                    pass
            
            # M3 Max ìµœì í™”: ë³‘ë ¬ ì²˜ë¦¬
            if self.is_m3_max and self.batch_processing and len(images) > 1:
                results = self._batch_convert_m3_optimized(images, target_format, **kwargs)
            else:
                # ìˆœì°¨ ì²˜ë¦¬
                for i, image in enumerate(images):
                    try:
                        if target_format.lower() == "tensor":
                            result = self.image_to_tensor(image, **kwargs)
                        elif target_format.lower() == "pil":
                            result = self._to_pil_image(image)
                        elif target_format.lower() == "numpy":
                            pil_img = self._to_pil_image(image)
                            result = np.array(pil_img) if pil_img and NUMPY_AVAILABLE else None
                        else:
                            result = None
                            
                        results.append(result)
                        
                    except Exception as e:
                        self.logger.error(f"âŒ ë°°ì¹˜ ë³€í™˜ ì‹¤íŒ¨ (ì¸ë±ìŠ¤ {i}): {e}")
                        results.append(None)
            
            processing_time = time.time() - start_time
            success_count = sum(1 for r in results if r is not None)
            
            self.logger.info(f"ğŸ“¦ ë°°ì¹˜ ë³€í™˜ ì™„ë£Œ: {success_count}/{len(images)} ì„±ê³µ ({processing_time:.3f}s)")
            
            return results
            
        except Exception as e:
            self.logger.error(f"âŒ ë°°ì¹˜ ë³€í™˜ ì‹¤íŒ¨: {e}")
            return [None] * len(images)

    # ============================================
    # ğŸ”¥ í—¬í¼ ë©”ì„œë“œë“¤ (ê¸°ì¡´ ìœ ì§€ + Central Hub ìµœì í™”)
    # ============================================

    def _to_pil_image(self, image_input: Union["Image.Image", "np.ndarray", str, bytes]) -> Optional["Image.Image"]:
        """ë‹¤ì–‘í•œ ì…ë ¥ì„ PIL ì´ë¯¸ì§€ë¡œ ë³€í™˜"""
        try:
            if not PIL_AVAILABLE:
                self.logger.error("âŒ PILì´ ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ")
                return None
                
            # ì´ë¯¸ PIL ì´ë¯¸ì§€ì¸ ê²½ìš°
            if hasattr(image_input, 'convert'):  # PIL Image ê°ì²´ ì²´í¬
                return image_input.convert('RGB')
            
            # NumPy ë°°ì—´ì¸ ê²½ìš°
            elif NUMPY_AVAILABLE and hasattr(image_input, 'ndim'):  # numpy array ì²´í¬
                if image_input.ndim == 3:
                    return Image.fromarray(image_input.astype(np.uint8)).convert('RGB')
                elif image_input.ndim == 2:
                    return Image.fromarray(image_input.astype(np.uint8)).convert('RGB')
            
            # íŒŒì¼ ê²½ë¡œì¸ ê²½ìš°
            elif isinstance(image_input, (str, Path)):
                if isinstance(image_input, str) and not image_input.startswith('data:image'):
                    path = Path(image_input)
                    if path.exists():
                        return Image.open(path).convert('RGB')
                else:
                    # Base64 Data URL íŒŒì‹±
                    if image_input.startswith('data:image'):
                        header, data = image_input.split(',', 1)
                        image_data = base64.b64decode(data)
                        return Image.open(io.BytesIO(image_data)).convert('RGB')
            
            # ë°”ì´íŠ¸ ë°ì´í„°ì¸ ê²½ìš°
            elif isinstance(image_input, bytes):
                return Image.open(io.BytesIO(image_input)).convert('RGB')
            
            else:
                self.logger.error(f"âŒ ì§€ì›ë˜ì§€ ì•ŠëŠ” ì´ë¯¸ì§€ í˜•ì‹: {type(image_input)}")
                return None
                
        except Exception as e:
            self.logger.error(f"âŒ PIL ì´ë¯¸ì§€ ë³€í™˜ ì‹¤íŒ¨: {e}")
            return None

    def _denormalize_tensor(self, tensor: "torch.Tensor") -> "torch.Tensor":
        """ì •ê·œí™”ëœ í…ì„œë¥¼ ì—­ì •ê·œí™”"""
        try:
            if TORCH_AVAILABLE:
                # í‰ê· ê³¼ í‘œì¤€í¸ì°¨ë¥¼ í…ì„œë¡œ ë³€í™˜
                mean = torch.tensor(self.normalize_mean).view(-1, 1, 1)
                std = torch.tensor(self.normalize_std).view(-1, 1, 1)
                
                # ì—­ì •ê·œí™”: tensor * std + mean
                denormalized = tensor * std + mean
                return denormalized
            else:
                return tensor
                
        except Exception as e:
            self.logger.error(f"âŒ ì—­ì •ê·œí™” ì‹¤íŒ¨: {e}")
            return tensor

    def _batch_convert_m3_optimized(
        self,
        images: List[Any],
        target_format: str,
        **kwargs
    ) -> List[Optional[Any]]:
        """M3 Max ìµœì í™” ë°°ì¹˜ ë³€í™˜"""
        try:
            import concurrent.futures
            
            # M3 Max 16ì½”ì–´ í™œìš©
            max_workers = min(16, len(images))
            
            with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
                future_to_index = {}
                
                for i, image in enumerate(images):
                    if target_format.lower() == "tensor":
                        future = executor.submit(self.image_to_tensor, image, **kwargs)
                    elif target_format.lower() == "pil":
                        future = executor.submit(self._to_pil_image, image)
                    elif target_format.lower() == "numpy":
                        future = executor.submit(self._convert_to_numpy, image)
                    else:
                        continue
                        
                    future_to_index[future] = i
                
                # ê²°ê³¼ ìˆ˜ì§‘
                results = [None] * len(images)
                for future in concurrent.futures.as_completed(future_to_index):
                    index = future_to_index[future]
                    try:
                        results[index] = future.result()
                    except Exception as e:
                        self.logger.error(f"M3 ë°°ì¹˜ ë³€í™˜ ì‹¤íŒ¨ (ì¸ë±ìŠ¤ {index}): {e}")
                        results[index] = None
                
                return results
                
        except Exception as e:
            self.logger.error(f"M3 ìµœì í™” ë°°ì¹˜ ë³€í™˜ ì‹¤íŒ¨: {e}")
            # í´ë°±: ìˆœì°¨ ì²˜ë¦¬
            return [self.image_to_tensor(img) if target_format == "tensor" else self._to_pil_image(img) 
                   for img in images]

    def _convert_to_numpy(self, image):
        """ì´ë¯¸ì§€ë¥¼ numpyë¡œ ë³€í™˜ (í—¬í¼ ë©”ì„œë“œ)"""
        pil_img = self._to_pil_image(image)
        return np.array(pil_img) if pil_img and NUMPY_AVAILABLE else None

    def _update_stats(self, operation: str, processing_time: float):
        """ë³€í™˜ í†µê³„ ì—…ë°ì´íŠ¸"""
        try:
            self._conversion_stats["total_conversions"] += 1
            self._conversion_stats["total_time"] += processing_time
            
            if operation not in self._conversion_stats["format_counts"]:
                self._conversion_stats["format_counts"][operation] = 0
            self._conversion_stats["format_counts"][operation] += 1
            
        except Exception:
            pass  # í†µê³„ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨ëŠ” ë¬´ì‹œ

    def get_conversion_stats(self) -> Dict[str, Any]:
        """ë³€í™˜ í†µê³„ ì¡°íšŒ"""
        stats = self._conversion_stats.copy()
        
        if stats["total_conversions"] > 0:
            stats["average_time"] = stats["total_time"] / stats["total_conversions"]
        else:
            stats["average_time"] = 0.0
            
        return stats

    # ============================================
    # ğŸ”¥ í˜„ì¬ êµ¬ì¡° í˜¸í™˜ ë©”ì„œë“œë“¤ (Central Hub ì§€ì› ì¶”ê°€)
    # ============================================

    async def initialize(self) -> bool:
        """ë°ì´í„° ë³€í™˜ê¸° ì´ˆê¸°í™” (Central Hub ì§€ì›)"""
        try:
            # ë¼ì´ë¸ŒëŸ¬ë¦¬ ê°€ìš©ì„± í™•ì¸
            available_libs = []
            if PIL_AVAILABLE:
                available_libs.append(f"PIL ({PIL_VERSION})")
            if CV2_AVAILABLE:
                available_libs.append(f"OpenCV ({CV2_VERSION})")
            if TORCH_AVAILABLE:
                available_libs.append(f"PyTorch ({TORCH_VERSION})")
            if NUMPY_AVAILABLE:
                available_libs.append(f"NumPy ({NUMPY_VERSION})")
            
            self.logger.info(f"ğŸ“š ì‚¬ìš© ê°€ëŠ¥í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬: {', '.join(available_libs)}")
            
            # Central Hubë¥¼ í†µí•œ ì˜ì¡´ì„± í•´ê²° ì‹œë„
            self._register_to_central_hub()
            
            # M3 Max ìµœì í™” ì„¤ì •
            if self.is_m3_max and self.optimization_enabled:
                self._apply_m3_max_optimizations()
            
            # ë³€í™˜ í…ŒìŠ¤íŠ¸
            test_result = await self._test_conversions()
            if not test_result:
                self.logger.warning("âš ï¸ ë³€í™˜ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨, ì¼ë¶€ ê¸°ëŠ¥ì´ ì œí•œë  ìˆ˜ ìˆìŠµë‹ˆë‹¤")
            
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ ë°ì´í„° ë³€í™˜ê¸° ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return False

    async def _test_conversions(self) -> bool:
        """ë³€í™˜ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸"""
        try:
            if PIL_AVAILABLE:
                # ë”ë¯¸ ì´ë¯¸ì§€ ìƒì„± ë° ë³€í™˜ í…ŒìŠ¤íŠ¸
                test_image = Image.new('RGB', (256, 256), color='red')
                tensor_result = self.image_to_tensor(test_image)
                if tensor_result is not None:
                    self.logger.info("âœ… ì´ë¯¸ì§€ â†’ í…ì„œ ë³€í™˜ í…ŒìŠ¤íŠ¸ í†µê³¼")
                    return True
                    
        except Exception as e:
            self.logger.error(f"âŒ ë³€í™˜ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
            
        return False

    async def cleanup(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬ (Central Hub ì§€ì›)"""
        try:
            # ìºì‹œ ì •ë¦¬
            if hasattr(self, '_conversion_stats'):
                self._conversion_stats.clear()
            
            # ë³€í™˜ íŒŒì´í”„ë¼ì¸ ì •ë¦¬
            if hasattr(self, 'transforms'):
                self.transforms.clear()
            
            # Central Hubë¥¼ í†µí•œ ë©”ëª¨ë¦¬ ì •ë¦¬
            if hasattr(self, 'memory_manager') and self.memory_manager:
                try:
                    self.memory_manager.optimize_memory(aggressive=True)
                except Exception:
                    pass
            
            # PyTorch ë©”ëª¨ë¦¬ ì •ë¦¬
            if TORCH_AVAILABLE:
                if MPS_AVAILABLE:
                    try:
                        if hasattr(torch.mps, 'empty_cache'):
                            torch.mps.empty_cache()
                    except Exception:
                        pass
                elif torch.cuda.is_available():
                    torch.cuda.empty_cache()
            
            self.logger.info("âœ… ë°ì´í„° ë³€í™˜ê¸° ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì™„ë£Œ")
            
        except Exception as e:
            self.logger.error(f"âŒ ë°ì´í„° ë³€í™˜ê¸° ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì‹¤íŒ¨: {e}")

# ==============================================
# ğŸ”¥ ImageProcessor í´ë˜ìŠ¤ (Central Hub ì§€ì› ì¶”ê°€)
# ==============================================

class ImageProcessor(DataConverter):
    """
    ğŸ”¥ Central Hub DI ì§€ì› ì´ë¯¸ì§€ ì²˜ë¦¬ê¸° (ê¸°ì¡´ í´ë˜ìŠ¤ëª… ìœ ì§€)
    âœ… DataConverter ìƒì†ìœ¼ë¡œ Central Hub ìë™ ì§€ì›
    âœ… í˜„ì¬ êµ¬ì¡°ì™€ ì™„ë²½ í˜¸í™˜
    âœ… ê¸°ì¡´ ì½”ë“œì˜ ImageProcessor ì‚¬ìš© ìœ ì§€
    """
    
    def __init__(self, **kwargs):
        """ì´ë¯¸ì§€ ì²˜ë¦¬ê¸° ì´ˆê¸°í™” (Central Hub ì§€ì›)"""
        super().__init__(**kwargs)
        self.logger = logging.getLogger("ImageProcessor")
        
        self.logger.info(f"ğŸ–¼ï¸ Central Hub ImageProcessor ì´ˆê¸°í™” - ë””ë°”ì´ìŠ¤: {self.device}")

    def process_image(self, image: Any, target_format: str = "tensor", **kwargs) -> Any:
        """ì´ë¯¸ì§€ ì²˜ë¦¬ (ê¸°ì¡´ ë©”ì„œë“œëª… ìœ ì§€)"""
        try:
            if target_format.lower() == "tensor":
                return self.image_to_tensor(image, **kwargs)
            elif target_format.lower() == "numpy":
                pil_img = self._to_pil_image(image)
                return np.array(pil_img) if pil_img and NUMPY_AVAILABLE else None
            elif target_format.lower() == "pil":
                return self._to_pil_image(image)
            else:
                self.logger.warning(f"âš ï¸ ì§€ì›ë˜ì§€ ì•ŠëŠ” í¬ë§·: {target_format}")
                return None
                
        except Exception as e:
            self.logger.error(f"âŒ ì´ë¯¸ì§€ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return None

    def resize_and_convert(self, image: Any, size: Tuple[int, int], format: str = "tensor") -> Any:
        """í¬ê¸° ì¡°ì • ë° ë³€í™˜ (í¸ì˜ ë©”ì„œë“œ)"""
        try:
            # ë¨¼ì € PIL ì´ë¯¸ì§€ë¡œ ë³€í™˜
            pil_image = self._to_pil_image(image)
            if pil_image is None:
                return None
            
            # í¬ê¸° ì¡°ì •
            resized_image = pil_image.resize(size, getattr(Image, 'BILINEAR', 2))
            
            # ëª©í‘œ í¬ë§·ìœ¼ë¡œ ë³€í™˜
            if format.lower() == "tensor":
                return self.image_to_tensor(resized_image)
            elif format.lower() == "numpy":
                return np.array(resized_image) if NUMPY_AVAILABLE else None
            else:
                return resized_image
                
        except Exception as e:
            self.logger.error(f"âŒ í¬ê¸° ì¡°ì • ë° ë³€í™˜ ì‹¤íŒ¨: {e}")
            return None

# ==============================================
# ğŸ”¥ ì „ì—­ DataConverter í•¨ìˆ˜ (Central Hub ìë™ ì—°ë™)
# ==============================================

def get_global_data_converter() -> DataConverter:
    """ì „ì—­ DataConverter ë°˜í™˜ - Central Hub ì—°ë™"""
    global _global_data_converter
    
    if _global_data_converter is None:
        _global_data_converter = DataConverter()
        
        # Central Hubì— ìë™ ë“±ë¡
        from app.core.di_container import get_global_container
        container = get_global_container()
        container.register('data_converter', _global_data_converter)
        
        logger.info("âœ… DataConverterê°€ Central Hubì— ë“±ë¡ë¨")
    
    return _global_data_converter

# ==============================================
# ğŸ”¥ ê¸°ì¡´ í•¨ìˆ˜ë“¤ (Central Hub ì§€ì› ì¶”ê°€ + í•˜ìœ„ í˜¸í™˜ì„±)
# ==============================================

# ì „ì—­ ë°ì´í„° ë³€í™˜ê¸° (ê¸°ì¡´ í˜¸í™˜)
_global_data_converter: Optional[DataConverter] = None
_global_image_processor: Optional[ImageProcessor] = None

def create_data_converter(
    default_size: Tuple[int, int] = (512, 512),
    device: str = "auto",
    **kwargs
) -> DataConverter:
    """ë°ì´í„° ë³€í™˜ê¸° ìƒì„± (ê¸°ì¡´ í•¨ìˆ˜ ìœ ì§€ + Central Hub ìë™ ì ìš©)"""
    if device == "auto":
        device = DEFAULT_DEVICE
    
    return DataConverter(
        device=device,
        default_size=default_size,
        **kwargs
    )

def initialize_global_data_converter(**kwargs) -> DataConverter:
    """ì „ì—­ ë°ì´í„° ë³€í™˜ê¸° ì´ˆê¸°í™” (Central Hub ì§€ì› ì¶”ê°€)"""
    global _global_data_converter
    _global_data_converter = create_data_converter(**kwargs)
    return _global_data_converter

def get_image_processor(**kwargs) -> ImageProcessor:
    """
    ğŸ”¥ ImageProcessor ë°˜í™˜ (Central Hub ì§€ì› ì¶”ê°€)
    âœ… ê¸°ì¡´ í•¨ìˆ˜ëª… ì™„ì „ ìœ ì§€
    âœ… í˜„ì¬ utils/__init__.pyì—ì„œ ì‚¬ìš©
    âœ… Central Hub ìë™ ì ìš©
    """
    global _global_image_processor
    
    if _global_image_processor is None:
        _global_image_processor = ImageProcessor(**kwargs)
    
    return _global_image_processor

# ë¹ ë¥¸ ë³€í™˜ í•¨ìˆ˜ë“¤ (Central Hub ìë™ ì ìš©)
def quick_image_to_tensor(image: Union["Image.Image", "np.ndarray"], size: Tuple[int, int] = (512, 512)) -> Optional["torch.Tensor"]:
    """ë¹ ë¥¸ ì´ë¯¸ì§€â†’í…ì„œ ë³€í™˜ (Central Hub ìë™ ì ìš©)"""
    converter = get_global_data_converter()
    return converter.image_to_tensor(image, size=size)

def quick_tensor_to_image(tensor: "torch.Tensor") -> Optional["Image.Image"]:
    """ë¹ ë¥¸ í…ì„œâ†’ì´ë¯¸ì§€ ë³€í™˜ (Central Hub ìë™ ì ìš©)"""
    converter = get_global_data_converter()
    return converter.tensor_to_image(tensor)

def quick_tensor_to_numpy(tensor: "torch.Tensor") -> Optional["np.ndarray"]:
    """ë¹ ë¥¸ í…ì„œâ†’numpy ë³€í™˜ (ê¸°ì¡´ í•¨ìˆ˜ëª… ìœ ì§€ + Central Hub)"""
    converter = get_global_data_converter()
    return converter.tensor_to_numpy(tensor)

def preprocess_image_for_step(image: Union["Image.Image", "np.ndarray"], step_name: str) -> Optional["torch.Tensor"]:
    """Stepë³„ ì´ë¯¸ì§€ ì „ì²˜ë¦¬ (Central Hub ìë™ ì ìš©)"""
    converter = get_global_data_converter()
    return converter.image_to_tensor(image)  # ê°„ì†Œí™”

def batch_convert_images(images: List[Any], target_format: str = "tensor", **kwargs) -> List[Any]:
    """ë°°ì¹˜ ì´ë¯¸ì§€ ë³€í™˜ (Central Hub ìë™ ì ìš©)"""
    converter = get_global_data_converter()
    return converter.batch_convert_images(images, target_format, **kwargs)

# í˜¸í™˜ì„± í•¨ìˆ˜ë“¤ (Central Hub ì§€ì› ì¶”ê°€)
def convert_image_format(image: Any, source_format: str, target_format: str) -> Any:
    """ì´ë¯¸ì§€ í¬ë§· ë³€í™˜ (Central Hub ìë™ ì ìš©)"""
    try:
        converter = get_global_data_converter()
        
        # ë¨¼ì € PILë¡œ ë³€í™˜
        pil_image = converter._to_pil_image(image)
        if pil_image is None:
            return None
        
        # ëª©í‘œ í¬ë§·ìœ¼ë¡œ ë³€í™˜
        if target_format.lower() == "tensor":
            return converter.image_to_tensor(pil_image)
        elif target_format.lower() == "numpy":
            return np.array(pil_image) if NUMPY_AVAILABLE else None
        elif target_format.lower() == "base64":
            # Base64 ë³€í™˜ êµ¬í˜„
            buffered = io.BytesIO()
            pil_image.save(buffered, format="PNG")
            img_str = base64.b64encode(buffered.getvalue()).decode()
            return f"data:image/png;base64,{img_str}"
        else:
            return pil_image
            
    except Exception as e:
        logger.error(f"âŒ ì´ë¯¸ì§€ í¬ë§· ë³€í™˜ ì‹¤íŒ¨: {e}")
        return None

def get_optimal_image_size(step_name: str) -> Tuple[int, int]:
    """Stepë³„ ìµœì  ì´ë¯¸ì§€ í¬ê¸° ë°˜í™˜"""
    step_sizes = {
        "HumanParsingStep": (512, 512),
        "PoseEstimationStep": (368, 368),
        "ClothSegmentationStep": (320, 320),
        "VirtualFittingStep": (512, 512),
        "PostProcessingStep": (1024, 1024),
        "GeometricMatchingStep": (512, 384),
        "ClothWarpingStep": (512, 512),
        "QualityAssessmentStep": (224, 224)
    }
    return step_sizes.get(step_name, (512, 512))

# ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸ (Central Hub ì •ë³´ ì¶”ê°€)
def get_system_status() -> Dict[str, Any]:
    """ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸ (Central Hub ì •ë³´ í¬í•¨)"""
    status = {
        "module": "DataConverter",
        "version": "9.0",
        "libraries": {
            "numpy": NUMPY_AVAILABLE,
            "pil": PIL_AVAILABLE,
            "cv2": CV2_AVAILABLE,
            "torch": TORCH_AVAILABLE
        },
        "device": DEFAULT_DEVICE if TORCH_AVAILABLE else "cpu",
        "m3_max_optimized": MPS_AVAILABLE if TORCH_AVAILABLE else False
    }
    return status

# =============================================================================
# ğŸ”¥ Virtual Fitting ì „ìš© ì „ì²˜ë¦¬/í›„ì²˜ë¦¬ í•¨ìˆ˜ë“¤
# =============================================================================

def preprocess_for_ootd(person_img: Any, cloth_img: Any, target_size: Tuple[int, int] = (768, 1024)) -> Tuple[Any, Any]:
    """OOTD ëª¨ë¸ìš© ì „ì²˜ë¦¬"""
    try:
        if not PIL_AVAILABLE or not TORCH_AVAILABLE:
            return person_img, cloth_img
        
        # PIL ì´ë¯¸ì§€ë¡œ ë³€í™˜
        if not isinstance(person_img, Image.Image):
            person_img = Image.fromarray(person_img)
        if not isinstance(cloth_img, Image.Image):
            cloth_img = Image.fromarray(cloth_img)
        
        # ë¦¬ì‚¬ì´ì¦ˆ
        person_img = person_img.resize(target_size, Image.LANCZOS)
        cloth_img = cloth_img.resize(target_size, Image.LANCZOS)
        
        # í…ì„œë¡œ ë³€í™˜
        transform = transforms.Compose([
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])
        ])
        
        person_tensor = transform(person_img).unsqueeze(0)
        cloth_tensor = transform(cloth_img).unsqueeze(0)
        
        return person_tensor, cloth_tensor
        
    except Exception as e:
        logging.error(f"OOTD ì „ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        return person_img, cloth_img

def preprocess_for_viton_hd(person_img: Any, cloth_img: Any, target_size: Tuple[int, int] = (512, 512)) -> Tuple[Any, Any]:
    """VITON-HD ëª¨ë¸ìš© ì „ì²˜ë¦¬"""
    try:
        if not PIL_AVAILABLE or not TORCH_AVAILABLE:
            return person_img, cloth_img
        
        # PIL ì´ë¯¸ì§€ë¡œ ë³€í™˜
        if not isinstance(person_img, Image.Image):
            person_img = Image.fromarray(person_img)
        if not isinstance(cloth_img, Image.Image):
            cloth_img = Image.fromarray(cloth_img)
        
        # ë¦¬ì‚¬ì´ì¦ˆ
        person_img = person_img.resize(target_size, Image.LANCZOS)
        cloth_img = cloth_img.resize(target_size, Image.LANCZOS)
        
        # í…ì„œë¡œ ë³€í™˜
        transform = transforms.Compose([
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
        ])
        
        person_tensor = transform(person_img).unsqueeze(0)
        cloth_tensor = transform(cloth_img).unsqueeze(0)
        
        return person_tensor, cloth_tensor
        
    except Exception as e:
        logging.error(f"VITON-HD ì „ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        return person_img, cloth_img

def setup_diffusion_pipeline(model_path: str = None, device: str = "cpu") -> Any:
    """Diffusion íŒŒì´í”„ë¼ì¸ ì„¤ì •"""
    try:
        if not TORCH_AVAILABLE:
            return None
        
        # Diffusers ë¼ì´ë¸ŒëŸ¬ë¦¬ ì²´í¬
        try:
            from diffusers import StableDiffusionInpaintPipeline
            DIFFUSERS_AVAILABLE = True
        except ImportError:
            DIFFUSERS_AVAILABLE = False
            logging.warning("Diffusers ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ")
            return None
        
        if not DIFFUSERS_AVAILABLE:
            return None
        
        # íŒŒì´í”„ë¼ì¸ ìƒì„±
        pipeline = StableDiffusionInpaintPipeline.from_pretrained(
            "runwayml/stable-diffusion-inpainting",
            torch_dtype=torch.float16 if device != "cpu" else torch.float32
        )
        
        # ë””ë°”ì´ìŠ¤ ì„¤ì •
        pipeline = pipeline.to(device)
        
        return pipeline
        
    except Exception as e:
        logging.error(f"Diffusion íŒŒì´í”„ë¼ì¸ ì„¤ì • ì‹¤íŒ¨: {e}")
        return None

def tensor_to_pil(tensor: Any) -> Any:
    """í…ì„œë¥¼ PIL ì´ë¯¸ì§€ë¡œ ë³€í™˜"""
    try:
        if not TORCH_AVAILABLE or not PIL_AVAILABLE:
            return tensor
        
        # ì •ê·œí™” í•´ì œ
        if tensor.min() < 0 or tensor.max() > 1:
            tensor = (tensor - tensor.min()) / (tensor.max() - tensor.min())
        
        # PIL ì´ë¯¸ì§€ë¡œ ë³€í™˜
        if tensor.dim() == 4:
            tensor = tensor.squeeze(0)
        
        # ì±„ë„ ìˆœì„œ ë³€ê²½ (C, H, W) -> (H, W, C)
        if tensor.shape[0] == 3:
            tensor = tensor.permute(1, 2, 0)
        
        # NumPyë¡œ ë³€í™˜
        numpy_img = tensor.detach().cpu().numpy()
        
        # PIL ì´ë¯¸ì§€ë¡œ ë³€í™˜
        pil_img = Image.fromarray((numpy_img * 255).astype(np.uint8))
        
        return pil_img
        
    except Exception as e:
        logging.error(f"í…ì„œë¥¼ PILë¡œ ë³€í™˜ ì‹¤íŒ¨: {e}")
        return tensor

def pil_to_tensor(pil_img: Any) -> Any:
    """PIL ì´ë¯¸ì§€ë¥¼ í…ì„œë¡œ ë³€í™˜"""
    try:
        if not PIL_AVAILABLE or not TORCH_AVAILABLE:
            return pil_img
        
        # NumPyë¡œ ë³€í™˜
        numpy_img = np.array(pil_img)
        
        # í…ì„œë¡œ ë³€í™˜
        tensor = torch.from_numpy(numpy_img).float() / 255.0
        
        # ì±„ë„ ìˆœì„œ ë³€ê²½ (H, W, C) -> (C, H, W)
        if tensor.dim() == 3 and tensor.shape[2] == 3:
            tensor = tensor.permute(2, 0, 1)
        
        # ë°°ì¹˜ ì°¨ì› ì¶”ê°€
        tensor = tensor.unsqueeze(0)
        
        return tensor
        
    except Exception as e:
        logging.error(f"PILì„ í…ì„œë¡œ ë³€í™˜ ì‹¤íŒ¨: {e}")
        return pil_img

def generate_inpainting_mask(person_img: Any, fitting_mode: str = "upper_body") -> Any:
    """ì¸í˜ì¸íŒ… ë§ˆìŠ¤í¬ ìƒì„±"""
    try:
        if not PIL_AVAILABLE or not CV2_AVAILABLE:
            return None
        
        # PIL ì´ë¯¸ì§€ë¡œ ë³€í™˜
        if not isinstance(person_img, Image.Image):
            person_img = Image.fromarray(person_img)
        
        # NumPyë¡œ ë³€í™˜
        numpy_img = np.array(person_img)
        
        # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜
        gray = cv2.cvtColor(numpy_img, cv2.COLOR_RGB2GRAY)
        
        # ë§ˆìŠ¤í¬ ìƒì„± (ê°„ë‹¨í•œ ë²„ì „)
        if fitting_mode == "upper_body":
            # ìƒë°˜ì‹  ë§ˆìŠ¤í¬
            h, w = gray.shape
            mask = np.zeros((h, w), dtype=np.uint8)
            mask[h//4:3*h//4, w//4:3*w//4] = 255
        else:
            # ì „ì²´ ë§ˆìŠ¤í¬
            mask = np.ones((gray.shape[0], gray.shape[1]), dtype=np.uint8) * 255
        
        # PIL ì´ë¯¸ì§€ë¡œ ë³€í™˜
        mask_pil = Image.fromarray(mask)
        
        return mask_pil
        
    except Exception as e:
        logging.error(f"ì¸í˜ì¸íŒ… ë§ˆìŠ¤í¬ ìƒì„± ì‹¤íŒ¨: {e}")
        return None

def generate_diffusion_prompt(fitting_mode: str, cloth_tensor: Any) -> str:
    """Diffusion í”„ë¡¬í”„íŠ¸ ìƒì„±"""
    try:
        base_prompt = "person wearing"
        
        if fitting_mode == "upper_body":
            base_prompt += " shirt, t-shirt, or top"
        elif fitting_mode == "lower_body":
            base_prompt += " pants, jeans, or skirt"
        elif fitting_mode == "full_body":
            base_prompt += " complete outfit"
        else:
            base_prompt += " clothing"
        
        # ì˜ë¥˜ ìƒ‰ìƒ ë¶„ì„ (ê°„ë‹¨í•œ ë²„ì „)
        if TORCH_AVAILABLE and cloth_tensor is not None:
            try:
                # í‰ê·  ìƒ‰ìƒ ê³„ì‚°
                avg_color = cloth_tensor.mean(dim=[2, 3])  # (B, C)
                
                # ìƒ‰ìƒ ì´ë¦„ ë§¤í•‘
                color_names = ["black", "white", "red", "blue", "green", "yellow", "purple", "pink", "brown", "gray"]
                color_idx = torch.argmax(avg_color[0]).item()
                
                if color_idx < len(color_names):
                    base_prompt += f", {color_names[color_idx]} color"
            except:
                pass
        
        base_prompt += ", high quality, realistic, detailed"
        
        return base_prompt
        
    except Exception as e:
        logging.error(f"Diffusion í”„ë¡¬í”„íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}")
        return "person wearing clothing, high quality, realistic"

def apply_viton_postprocessing(fitted_tensor: Any, processed_data: Dict[str, Any]) -> Any:
    """VITON-HD í›„ì²˜ë¦¬"""
    try:
        if not TORCH_AVAILABLE:
            return fitted_tensor
        
        # ê¸°ë³¸ í›„ì²˜ë¦¬
        # 1. ì •ê·œí™” í•´ì œ
        if fitted_tensor.min() < 0 or fitted_tensor.max() > 1:
            fitted_tensor = (fitted_tensor - fitted_tensor.min()) / (fitted_tensor.max() - fitted_tensor.min())
        
        # 2. í´ë¨í•‘
        fitted_tensor = torch.clamp(fitted_tensor, 0, 1)
        
        # 3. ìƒ‰ìƒ ë³´ì • (ê°„ë‹¨í•œ ë²„ì „)
        if 'original_person' in processed_data:
            original_person = processed_data['original_person']
            if TORCH_AVAILABLE and isinstance(original_person, torch.Tensor):
                # ìƒ‰ìƒ íˆìŠ¤í† ê·¸ë¨ ë§¤ì¹­ (ê°„ë‹¨í•œ ë²„ì „)
                fitted_mean = fitted_tensor.mean()
                original_mean = original_person.mean()
                fitted_tensor = fitted_tensor * (original_mean / (fitted_mean + 1e-8))
        
        return fitted_tensor
        
    except Exception as e:
        logging.error(f"VITON-HD í›„ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        return fitted_tensor
    """ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸ (Central Hub ì •ë³´ í¬í•¨)"""
    status = {
        "torch_available": TORCH_AVAILABLE,
        "torch_version": TORCH_VERSION,
        "mps_available": MPS_AVAILABLE,
        "pil_available": PIL_AVAILABLE,
        "pil_version": PIL_VERSION,
        "numpy_available": NUMPY_AVAILABLE,
        "numpy_version": NUMPY_VERSION,
        "cv2_available": CV2_AVAILABLE,
        "cv2_version": CV2_VERSION,
        "default_device": DEFAULT_DEVICE
    }
    
    # Central Hub ìƒíƒœ ì¶”ê°€
    try:
        from app.core.di_container import get_global_container
        container = get_global_container()
        status["central_hub_integration"] = {
            "central_hub_supported": True,
            "container_available": container is not None,
            "auto_registration": True
        }
    except Exception:
        status["central_hub_integration"] = {
            "central_hub_supported": False,
            "error": "Central Hub Container integration failed"
        }
    
    return status

# ëª¨ë“ˆ ìµìŠ¤í¬íŠ¸ (Central Hub í•¨ìˆ˜ë“¤ ì¶”ê°€)
__all__ = [
    # ğŸ”¥ ê¸°ì¡´ í´ë˜ìŠ¤ëª… ì™„ì „ ìœ ì§€ (Central Hub ì§€ì› ì¶”ê°€)
    'DataConverter',
    'ImageProcessor',
    'ConversionMode',
    'ImageFormat',
    
    # ğŸ”¥ Central Hub ì¸í„°í˜ì´ìŠ¤ë“¤
    'IDataConverter',
    
    # ğŸ”¥ ê¸°ì¡´ í•¨ìˆ˜ëª… ì™„ì „ ìœ ì§€ (Central Hub ìë™ ì ìš©)
    'create_data_converter',
    'get_global_data_converter',
    'initialize_global_data_converter',
    'get_image_processor',
    'quick_image_to_tensor',
    'quick_tensor_to_image',
    'quick_tensor_to_numpy',
    'preprocess_image_for_step',
    'batch_convert_images',
    'convert_image_format',
    'get_optimal_image_size',
    'get_system_status'
]

# ëª¨ë“ˆ ë¡œë“œ í™•ì¸
logger.info("âœ… Central Hub ì™„ì „ í†µí•© DataConverter ëª¨ë“ˆ ë¡œë“œ ì™„ë£Œ")
logger.info("ğŸ”— CentralHubDIContainer v7.0 ì—°ë™ ì™„ë£Œ")
logger.info("ğŸ”§ ê¸°ì¡´ í•¨ìˆ˜ëª…/í´ë˜ìŠ¤ëª… 100% ìœ ì§€ + Central Hub ìë™ ì ìš©")
logger.info("ğŸ M3 Max ì´ë¯¸ì§€/í…ì„œ ë³€í™˜ ìµœì í™” ìœ ì§€")
logger.info("ğŸ”€ ìˆœí™˜ì°¸ì¡° ì™„ì „ ë°©ì§€")
logger.info("ğŸ›¡ï¸ Mock í´ë°± êµ¬í˜„ì²´ í¬í•¨")
logger.info("âš¡ conda í™˜ê²½ ì™„ë²½ ì§€ì›")

# Central Hub ì‹œìŠ¤í…œ ìƒíƒœ ë¡œê¹…
try:
    central_hub_status = get_system_status()
    logger.info(f"ğŸ“Š Central Hub í†µí•© ì‹œìŠ¤í…œ ìƒíƒœ: PyTorch={central_hub_status['torch_available']}, Central Hub={central_hub_status['central_hub_integration']['central_hub_supported']}")
    logger.info(f"ğŸ¯ ê¸°ë³¸ ë””ë°”ì´ìŠ¤: {central_hub_status['default_device']}")
except Exception:
    logger.info("ğŸ“Š ê¸°ë³¸ ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸ ì™„ë£Œ")