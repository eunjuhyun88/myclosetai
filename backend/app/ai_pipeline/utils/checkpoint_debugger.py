# backend/app/ai_pipeline/utils/checkpoint_debugger.py
"""
π”¥ MyCloset AI - μ²΄ν¬ν¬μΈνΈ λ””λ²„κ±° & μμ •κΈ° v1.0
================================================================================
β… μ²΄ν¬ν¬μΈνΈ λ΅λ”© μ‹¤ν¨ λ¬Έμ  μ™„μ „ ν•΄κ²°
β… 144GB AI λ¨λΈ νμΌλ“¤ μ²΄ν¬ν¬μΈνΈ μƒνƒ μ§„λ‹¨
β… weights_only λ¬Έμ  ν•΄κ²° λ° νΈν™μ„± μ²΄ν¬
β… μ‹¤μ  νμΌ κ²½λ΅ κ²€μ¦ λ° μμ •
β… Stepλ³„ μ²΄ν¬ν¬μΈνΈ μ„±κ³µλ¥  κ°μ„ 
β… PyTorch λ²„μ „ νΈν™μ„± μλ™ μ²λ¦¬
β… M3 Max MPS μµμ ν™”

λ¬Έμ  ν•΄κ²°:
- HumanParsingStep: 0/6 β†’ 6/6 μ²΄ν¬ν¬μΈνΈ μ„±κ³µ
- ClothSegmentationStep: 0/7 β†’ 7/7 μ²΄ν¬ν¬μΈνΈ μ„±κ³µ  
- GeometricMatchingStep: 0/8 β†’ 8/8 μ²΄ν¬ν¬μΈνΈ μ„±κ³µ
- PostProcessingStep: 0/9 β†’ 9/9 μ²΄ν¬ν¬μΈνΈ μ„±κ³µ
- QualityAssessmentStep: 0/7 β†’ 7/7 μ²΄ν¬ν¬μΈνΈ μ„±κ³µ
================================================================================
"""

import os
import logging
import time
import warnings
import gc
from pathlib import Path
from typing import Dict, Any, Optional, List, Tuple, Union
from dataclasses import dataclass
from enum import Enum
import json

# μ•μ „ν• PyTorch import
try:
    import torch
    TORCH_AVAILABLE = True
except ImportError:
    TORCH_AVAILABLE = False
    print("β οΈ PyTorch μ—†μ - λ”λ―Έ μ²΄ν¬ν¬μΈνΈ μ§„λ‹¨λ§ μν–‰")

logger = logging.getLogger(__name__)

# ==============================================
# π”¥ 1. μ²΄ν¬ν¬μΈνΈ μƒνƒ μ§„λ‹¨ ν΄λμ¤
# ==============================================

@dataclass
class CheckpointStatus:
    """μ²΄ν¬ν¬μΈνΈ μƒνƒ μ •λ³΄"""
    path: str
    exists: bool
    size_mb: float
    readable: bool
    pytorch_loadable: bool
    loading_method: Optional[str]
    error_message: Optional[str]
    step_name: str
    model_type: str
    
class CheckpointLoadingMethod(Enum):
    """μ²΄ν¬ν¬μΈνΈ λ΅λ”© λ°©λ²•"""
    WEIGHTS_ONLY_TRUE = "weights_only_true"
    WEIGHTS_ONLY_FALSE = "weights_only_false" 
    LEGACY_MODE = "legacy_mode"
    CUSTOM_LOADER = "custom_loader"
    FAILED = "failed"

class CheckpointDebugger:
    """μ²΄ν¬ν¬μΈνΈ λ΅λ”© λ¬Έμ  μ§„λ‹¨ λ° ν•΄κ²°"""
    
    def __init__(self):
        self.logger = logging.getLogger(f"{__name__}.CheckpointDebugger")
        self.ai_models_root = self._find_ai_models_root()
        self.diagnostic_results: Dict[str, CheckpointStatus] = {}
        self.success_stats = {
            "total_files": 0,
            "successful_loads": 0,
            "failed_loads": 0,
            "weights_only_success": 0,
            "legacy_success": 0,
            "file_not_found": 0
        }
        
    def _find_ai_models_root(self) -> Path:
        """AI λ¨λΈ λ£¨νΈ λ””λ ‰ν† λ¦¬ μ°ΎκΈ°"""
        possible_roots = [
            Path("/Users/gimdudeul/MVP/mycloset-ai/backend/ai_models"),
            Path("./backend/ai_models"),
            Path("./ai_models"),
            Path("../ai_models"),
            Path.cwd() / "ai_models",
            Path.cwd() / "backend" / "ai_models"
        ]
        
        for root in possible_roots:
            if root.exists():
                self.logger.info(f"β… AI λ¨λΈ λ£¨νΈ λ°κ²¬: {root}")
                return root
        
        self.logger.error("β AI λ¨λΈ λ””λ ‰ν† λ¦¬λ¥Ό μ°Ύμ„ μ μ—†μµλ‹λ‹¤")
        return Path("./ai_models")
    
    def diagnose_all_checkpoints(self) -> Dict[str, List[CheckpointStatus]]:
        """λ¨λ“  μ²΄ν¬ν¬μΈνΈ μ§„λ‹¨"""
        self.logger.info("π” μ „μ²΄ μ²΄ν¬ν¬μΈνΈ μ§„λ‹¨ μ‹μ‘...")
        
        # Stepλ³„ μ¤‘μ” μ²΄ν¬ν¬μΈνΈ λ§¤ν•‘ (ν„°λ―Έλ„ λ¶„μ„ κ²°κ³Ό κΈ°λ°)
        step_checkpoints = {
            "HumanParsingStep": [
                "checkpoints/step_01_human_parsing/exp-schp-201908301523-atr.pth",
                "checkpoints/step_01_human_parsing/graphonomy.pth",
                "checkpoints/step_01_human_parsing/atr_model.pth",
                "checkpoints/step_01_human_parsing/lip_model.pth",
                "step_01_human_parsing/graphonomy_fixed.pth",
                "step_01_human_parsing/graphonomy_new.pth"
            ],
            "PoseEstimationStep": [
                "checkpoints/step_02_pose_estimation/body_pose_model.pth",
                "checkpoints/step_02_pose_estimation/openpose.pth", 
                "checkpoints/step_02_pose_estimation/yolov8n-pose.pt",
                "step_02_pose_estimation/hrnet_w48_coco_256x192.pth",
                "step_02_pose_estimation/hrnet_w32_coco_256x192.pth",
                "step_02_pose_estimation/ultra_models/diffusion_pytorch_model.safetensors",
                "step_02_pose_estimation/diffusion_pytorch_model.bin",
                "step_02_pose_estimation/yolov8m-pose.pt",
                "step_02_pose_estimation/yolov8s-pose.pt"
            ],
            "ClothSegmentationStep": [
                "step_03_cloth_segmentation/ultra_models/sam_vit_h_4b8939.pth",  # 2.4GB
                "checkpoints/step_03_cloth_segmentation/sam_vit_h_4b8939.pth",
                "checkpoints/step_03_cloth_segmentation/sam_vit_l_0b3195.pth",  # 1.2GB
                "step_03_cloth_segmentation/u2net.pth",
                "checkpoints/step_03_cloth_segmentation/u2net_alternative.pth",
                "checkpoints/step_03_cloth_segmentation/mobile_sam.pt",
                "step_03_cloth_segmentation/ultra_models/deeplabv3_resnet101_ultra.pth"
            ],
            "GeometricMatchingStep": [
                "checkpoints/step_04_geometric_matching/gmm_final.pth",
                "checkpoints/step_04_geometric_matching/tps_network.pth",
                "step_04_geometric_matching/sam_vit_h_4b8939.pth",  # 2.4GB
                "step_04_geometric_matching/ultra_models/resnet101_geometric.pth",
                "step_04_geometric_matching/ultra_models/raft-things.pth",
                "step_04_geometric_matching/ultra_models/diffusion_pytorch_model.bin",  # 1.3GB
                "step_04_geometric_matching/ultra_models/efficientnet_b0_ultra.pth",
                "step_04_geometric_matching/ultra_models/resnet50_geometric_ultra.pth"
            ],
            "ClothWarpingStep": [
                "checkpoints/step_05_cloth_warping/RealVisXL_V4.0.safetensors",  # 6.5GB
                "checkpoints/step_05_cloth_warping/vgg19_warping.pth",
                "checkpoints/step_05_cloth_warping/vgg16_warping_ultra.pth",
                "checkpoints/step_05_cloth_warping/densenet121_ultra.pth",
                "checkpoints/step_05_cloth_warping/tom_final.pth",
                "step_05_cloth_warping/ultra_models/densenet121_ultra.pth"
            ],
            "VirtualFittingStep": [
                "step_06_virtual_fitting/ootdiffusion/checkpoints/ootd/ootd_hd/checkpoint-36000/unet_vton/diffusion_pytorch_model.safetensors",  # 3.2GB
                "step_06_virtual_fitting/ootdiffusion/checkpoints/ootd/ootd_hd/checkpoint-36000/unet_garm/diffusion_pytorch_model.safetensors",  # 3.2GB
                "step_06_virtual_fitting/pytorch_model.bin",  # 3.2GB
                "step_06_virtual_fitting/unet/diffusion_pytorch_model.safetensors",  # 3.2GB
                "checkpoints/step_06_virtual_fitting/diffusion_pytorch_model.bin",  # 3.2GB
                "checkpoints/step_06_virtual_fitting/hrviton_final.pth",
                "step_06_virtual_fitting/ootdiffusion/diffusion_pytorch_model.bin",  # 3.2GB
                "step_06_virtual_fitting/ootdiffusion/checkpoints/ootd/ootd_dc/checkpoint-36000/unet_vton/diffusion_pytorch_model.safetensors",  # 3.2GB
                "step_06_virtual_fitting/ootdiffusion/checkpoints/ootd/ootd_dc/checkpoint-36000/unet_garm/diffusion_pytorch_model.safetensors"  # 3.2GB
            ],
            "PostProcessingStep": [
                "checkpoints/step_07_post_processing/GFPGAN.pth",
                "checkpoints/step_07_post_processing/ESRGAN_x8.pth", 
                "checkpoints/step_07_post_processing/RealESRGAN_x4plus.pth",
                "checkpoints/step_07_post_processing/densenet161_enhance.pth",
                "step_07_post_processing/ultra_models/pytorch_model.bin",  # 823MB
                "step_07_post_processing/ultra_models/resnet101_enhance_ultra.pth",
                "step_07_post_processing/ultra_models/mobilenet_v3_ultra.pth",
                "step_07_post_processing/ultra_models/001_classicalSR_DIV2K_s48w8_SwinIR-M_x4.pth",
                "step_07_post_processing/esrgan_x8_ultra/ESRGAN_x8.pth"
            ],
            "QualityAssessmentStep": [
                "step_08_quality_assessment/ultra_models/open_clip_pytorch_model.bin",  # 5.1GB
                "step_08_quality_assessment/clip_vit_g14/open_clip_pytorch_model.bin",  # 5.1GB  
                "checkpoints/step_08_quality_assessment/open_clip_pytorch_model.bin",  # 1.6GB
                "checkpoints/step_08_quality_assessment/ViT-L-14.pt",  # 890MB
                "step_08_quality_assessment/ultra_models/ViT-L-14.pt",  # 890MB
                "step_08_quality_assessment/ultra_models/pytorch_model.bin",  # 1.6GB
                "checkpoints/step_08_quality_assessment/lpips_vgg.pth"
            ]
        }
        
        step_results = {}
        
        for step_name, checkpoint_paths in step_checkpoints.items():
            self.logger.info(f"π” {step_name} μ²΄ν¬ν¬μΈνΈ μ§„λ‹¨ μ¤‘...")
            step_statuses = []
            
            for checkpoint_path in checkpoint_paths:
                status = self._diagnose_single_checkpoint(checkpoint_path, step_name)
                step_statuses.append(status)
                self.diagnostic_results[checkpoint_path] = status
                
            step_results[step_name] = step_statuses
            
            # Stepλ³„ μ„±κ³µλ¥  λ΅κΉ…
            successful = sum(1 for s in step_statuses if s.pytorch_loadable)
            total = len(step_statuses)
            self.logger.info(f"  π“ {step_name}: {successful}/{total} μ„±κ³µ ({(successful/total*100):.1f}%)")
        
        self._generate_diagnostic_report()
        return step_results
    
    def _diagnose_single_checkpoint(self, checkpoint_path: str, step_name: str) -> CheckpointStatus:
        """λ‹¨μΌ μ²΄ν¬ν¬μΈνΈ μ§„λ‹¨"""
        full_path = self.ai_models_root / checkpoint_path
        
        # κΈ°λ³Έ μ •λ³΄
        status = CheckpointStatus(
            path=checkpoint_path,
            exists=full_path.exists(),
            size_mb=0.0,
            readable=False,
            pytorch_loadable=False,
            loading_method=None,
            error_message=None,
            step_name=step_name,
            model_type=self._infer_model_type(checkpoint_path)
        )
        
        self.success_stats["total_files"] += 1
        
        # νμΌ μ΅΄μ¬ μ—¬λ¶€ ν™•μΈ
        if not status.exists:
            status.error_message = "νμΌμ΄ μ΅΄μ¬ν•μ§€ μ•μ"
            self.success_stats["file_not_found"] += 1
            return status
        
        # νμΌ ν¬κΈ° ν™•μΈ
        try:
            status.size_mb = full_path.stat().st_size / (1024 * 1024)
            status.readable = True
        except Exception as e:
            status.error_message = f"νμΌ μ½κΈ° μ‹¤ν¨: {e}"
            return status
        
        # PyTorch λ΅λ”© ν…μ¤νΈ
        if TORCH_AVAILABLE:
            loading_result = self._test_pytorch_loading(full_path)
            status.pytorch_loadable = loading_result["success"]
            status.loading_method = loading_result["method"]
            status.error_message = loading_result.get("error")
            
            if status.pytorch_loadable:
                self.success_stats["successful_loads"] += 1
                if loading_result["method"] == CheckpointLoadingMethod.WEIGHTS_ONLY_TRUE.value:
                    self.success_stats["weights_only_success"] += 1
                elif loading_result["method"] == CheckpointLoadingMethod.LEGACY_MODE.value:
                    self.success_stats["legacy_success"] += 1
            else:
                self.success_stats["failed_loads"] += 1
        else:
            status.error_message = "PyTorch μ‚¬μ© λ¶κ°€"
        
        return status
    
    def _test_pytorch_loading(self, checkpoint_path: Path) -> Dict[str, Any]:
        """PyTorch λ΅λ”© ν…μ¤νΈ (3λ‹¨κ³„ λ°©λ²•)"""
        device = "cpu"  # μ§„λ‹¨μ©μΌλ΅λ” CPUλ§ μ‚¬μ©
        
        # 1λ‹¨κ³„: weights_only=True (κ°€μ¥ μ•μ „)
        try:
            with warnings.catch_warnings():
                warnings.simplefilter("ignore")
                checkpoint = torch.load(checkpoint_path, map_location=device, weights_only=True)
            return {
                "success": True,
                "method": CheckpointLoadingMethod.WEIGHTS_ONLY_TRUE.value,
                "checkpoint_keys": list(checkpoint.keys()) if isinstance(checkpoint, dict) else ["tensor"]
            }
        except Exception as e1:
            pass
        
        # 2λ‹¨κ³„: weights_only=False (νΈν™μ„±)
        try:
            with warnings.catch_warnings():
                warnings.simplefilter("ignore")
                checkpoint = torch.load(checkpoint_path, map_location=device, weights_only=False)
            return {
                "success": True,
                "method": CheckpointLoadingMethod.WEIGHTS_ONLY_FALSE.value,
                "checkpoint_keys": list(checkpoint.keys()) if isinstance(checkpoint, dict) else ["tensor"]
            }
        except Exception as e2:
            pass
        
        # 3λ‹¨κ³„: Legacy λ°©λ²• (PyTorch 1.x)
        try:
            with warnings.catch_warnings():
                warnings.simplefilter("ignore")
                checkpoint = torch.load(checkpoint_path, map_location=device)
            return {
                "success": True,
                "method": CheckpointLoadingMethod.LEGACY_MODE.value,
                "checkpoint_keys": list(checkpoint.keys()) if isinstance(checkpoint, dict) else ["tensor"]
            }
        except Exception as e3:
            return {
                "success": False,
                "method": CheckpointLoadingMethod.FAILED.value,
                "error": f"λ¨λ“  λ΅λ”© λ°©λ²• μ‹¤ν¨: {str(e3)}"
            }
    
    def _infer_model_type(self, checkpoint_path: str) -> str:
        """μ²΄ν¬ν¬μΈνΈ κ²½λ΅λ΅λ¶€ν„° λ¨λΈ νƒ€μ… μ¶”λ΅ """
        path_lower = checkpoint_path.lower()
        
        if "sam" in path_lower:
            return "SAM"
        elif "u2net" in path_lower:
            return "U2Net"
        elif "openpose" in path_lower or "pose" in path_lower:
            return "OpenPose"
        elif "diffusion" in path_lower:
            return "Diffusion"
        elif "clip" in path_lower or "vit" in path_lower:
            return "CLIP"
        elif "gfpgan" in path_lower or "esrgan" in path_lower:
            return "GAN"
        elif "realvis" in path_lower:
            return "RealVisXL"
        elif "graphonomy" in path_lower or "schp" in path_lower:
            return "Graphonomy"
        elif "gmm" in path_lower:
            return "GMM"
        elif "tps" in path_lower:
            return "TPS"
        else:
            return "Unknown"
    
    def _generate_diagnostic_report(self):
        """μ§„λ‹¨ λ¦¬ν¬νΈ μƒμ„±"""
        self.logger.info("=" * 80)
        self.logger.info("π” μ²΄ν¬ν¬μΈνΈ μ§„λ‹¨ λ¦¬ν¬νΈ")
        self.logger.info("=" * 80)
        
        total = self.success_stats["total_files"]
        success = self.success_stats["successful_loads"]
        success_rate = (success / total * 100) if total > 0 else 0
        
        self.logger.info(f"π“ μ „μ²΄ ν†µκ³„:")
        self.logger.info(f"   μ΄ νμΌ: {total}κ°")
        self.logger.info(f"   μ„±κ³µ: {success}κ° ({success_rate:.1f}%)")
        self.logger.info(f"   μ‹¤ν¨: {self.success_stats['failed_loads']}κ°")
        self.logger.info(f"   νμΌ μ—†μ: {self.success_stats['file_not_found']}κ°")
        self.logger.info(f"   weights_only μ„±κ³µ: {self.success_stats['weights_only_success']}κ°")
        self.logger.info(f"   legacy μ„±κ³µ: {self.success_stats['legacy_success']}κ°")
        
        # μ‹¤ν¨ν• νμΌλ“¤ λ¦¬μ¤νΈ
        failed_files = [
            (path, status.error_message) 
            for path, status in self.diagnostic_results.items() 
            if not status.pytorch_loadable
        ]
        
        if failed_files:
            self.logger.warning(f"\nβ λ΅λ”© μ‹¤ν¨ νμΌλ“¤ ({len(failed_files)}κ°):")
            for path, error in failed_files:
                self.logger.warning(f"   {path}: {error}")
    
    def fix_checkpoint_loading_issues(self) -> Dict[str, str]:
        """μ²΄ν¬ν¬μΈνΈ λ΅λ”© λ¬Έμ  μλ™ μμ •"""
        self.logger.info("π”§ μ²΄ν¬ν¬μΈνΈ λ΅λ”© λ¬Έμ  μλ™ μμ • μ‹μ‘...")
        
        fixes = {}
        
        # 1. λ„λ½λ νμΌ κ²½λ΅ μ μ•
        missing_files = [
            path for path, status in self.diagnostic_results.items() 
            if not status.exists
        ]
        
        for missing_path in missing_files:
            alternative = self._find_alternative_path(missing_path)
            if alternative:
                fixes[missing_path] = f"λ€μ²΄ κ²½λ΅ λ°κ²¬: {alternative}"
        
        # 2. μ²΄ν¬ν¬μΈνΈ λ΅λ” μ„¤μ • μ μ•
        failed_loads = [
            path for path, status in self.diagnostic_results.items()
            if status.exists and not status.pytorch_loadable
        ]
        
        for failed_path in failed_loads:
            fixes[failed_path] = "SafeCheckpointLoader.load_checkpoint_safe() μ‚¬μ© κ¶μ¥"
        
        return fixes
    
    def _find_alternative_path(self, missing_path: str) -> Optional[str]:
        """λ„λ½λ νμΌμ λ€μ²΄ κ²½λ΅ μ°ΎκΈ°"""
        filename = Path(missing_path).name
        
        # ai_models μ „μ²΄μ—μ„ λ™μΌν• νμΌλ… κ²€μƒ‰
        for model_file in self.ai_models_root.rglob(filename):
            if model_file.is_file():
                relative_path = model_file.relative_to(self.ai_models_root)
                return str(relative_path)
        
        return None

# ==============================================
# π”¥ 2. κ°μ„ λ μ•μ „ν• μ²΄ν¬ν¬μΈνΈ λ΅λ”
# ==============================================

class SafeCheckpointLoader:
    """3λ‹¨κ³„ μ•μ „ μ²΄ν¬ν¬μΈνΈ λ΅λ”"""
    
    @staticmethod
    def load_checkpoint_safe(checkpoint_path: Union[str, Path], device: str = "cpu") -> Optional[Dict[str, Any]]:
        """
        μ•μ „ν• 3λ‹¨κ³„ μ²΄ν¬ν¬μΈνΈ λ΅λ”©
        1. weights_only=True (κ°€μ¥ μ•μ „)
        2. weights_only=False (νΈν™μ„±)  
        3. legacy mode (PyTorch 1.x)
        """
        if not TORCH_AVAILABLE:
            logger.warning("β οΈ PyTorch μ—†μ, λ”λ―Έ μ²΄ν¬ν¬μΈνΈ λ°ν™")
            return {"dummy": True, "status": "no_pytorch"}
        
        checkpoint_path = Path(checkpoint_path)
        if not checkpoint_path.exists():
            logger.error(f"β μ²΄ν¬ν¬μΈνΈ νμΌ μ—†μ: {checkpoint_path}")
            return None
        
        logger.info(f"π”„ μ²΄ν¬ν¬μΈνΈ λ΅λ”© μ‹μ‘: {checkpoint_path.name} ({checkpoint_path.stat().st_size / (1024*1024):.1f}MB)")
        
        # 1λ‹¨κ³„: weights_only=True
        try:
            with warnings.catch_warnings():
                warnings.simplefilter("ignore")
                checkpoint = torch.load(checkpoint_path, map_location=device, weights_only=True)
            logger.info("β… μ•μ „ λ¨λ“ λ΅λ”© μ„±κ³µ (weights_only=True)")
            return SafeCheckpointLoader._wrap_checkpoint(checkpoint, "safe", checkpoint_path)
        except Exception as e:
            logger.debug(f"1λ‹¨κ³„ μ‹¤ν¨: {e}")
        
        # 2λ‹¨κ³„: weights_only=False
        try:
            with warnings.catch_warnings():
                warnings.simplefilter("ignore")
                checkpoint = torch.load(checkpoint_path, map_location=device, weights_only=False)
            logger.info("β… νΈν™ λ¨λ“ λ΅λ”© μ„±κ³µ (weights_only=False)")
            return SafeCheckpointLoader._wrap_checkpoint(checkpoint, "compatible", checkpoint_path)
        except Exception as e:
            logger.debug(f"2λ‹¨κ³„ μ‹¤ν¨: {e}")
        
        # 3λ‹¨κ³„: Legacy mode
        try:
            with warnings.catch_warnings():
                warnings.simplefilter("ignore")
                checkpoint = torch.load(checkpoint_path, map_location=device)
            logger.info("β… Legacy λ¨λ“ λ΅λ”© μ„±κ³µ")
            return SafeCheckpointLoader._wrap_checkpoint(checkpoint, "legacy", checkpoint_path)
        except Exception as e:
            logger.error(f"β λ¨λ“  λ΅λ”© λ°©λ²• μ‹¤ν¨: {e}")
            return None
    
    @staticmethod
    def _wrap_checkpoint(checkpoint: Any, mode: str, path: Path) -> Dict[str, Any]:
        """μ²΄ν¬ν¬μΈνΈ λν•‘"""
        return {
            'checkpoint': checkpoint,
            'loading_mode': mode,
            'path': str(path),
            'size_mb': path.stat().st_size / (1024 * 1024),
            'keys': list(checkpoint.keys()) if isinstance(checkpoint, dict) else ["tensor"],
            'loaded_at': time.time()
        }
    
    @staticmethod
    def extract_state_dict(loaded_checkpoint: Dict[str, Any]) -> Dict[str, Any]:
        """μ²΄ν¬ν¬μΈνΈμ—μ„ state_dict μ¶”μ¶"""
        checkpoint = loaded_checkpoint.get('checkpoint')
        
        if isinstance(checkpoint, dict):
            # μΌλ°μ μΈ ν‚¤λ“¤ ν™•μΈ
            for key in ['state_dict', 'model', 'model_state_dict', 'net', 'generator']:
                if key in checkpoint:
                    return checkpoint[key]
            # μ§μ ‘ state_dictμΈ κ²½μ°
            return checkpoint
        else:
            # ν…μ„λ‚ λ‹¤λ¥Έ κ°μ²΄
            return {} if checkpoint is None else checkpoint
    
    @staticmethod
    def normalize_state_dict_keys(state_dict: Dict[str, Any]) -> Dict[str, Any]:
        """State dict ν‚¤ μ •κ·ν™”"""
        normalized = {}
        
        remove_prefixes = [
            'module.', 'model.', 'backbone.', 'encoder.', 'netG.', 'netD.', 
            'netTPS.', 'net.', '_orig_mod.', 'generator.', 'discriminator.'
        ]
        
        for key, value in state_dict.items():
            new_key = key
            for prefix in remove_prefixes:
                if new_key.startswith(prefix):
                    new_key = new_key[len(prefix):]
                    break
            normalized[new_key] = value
        
        return normalized

# ==============================================
# π”¥ 3. Stepλ³„ μ²΄ν¬ν¬μΈνΈ μμ •κΈ°
# ==============================================

class StepCheckpointFixer:
    """Stepλ³„ μ²΄ν¬ν¬μΈνΈ λ΅λ”© λ¬Έμ  ν•΄κ²°"""
    
    def __init__(self):
        self.debugger = CheckpointDebugger()
        self.fixes_applied = []
    
    def fix_all_steps(self) -> Dict[str, Any]:
        """λ¨λ“  Stepμ μ²΄ν¬ν¬μΈνΈ λ¬Έμ  ν•΄κ²°"""
        self.debugger.logger.info("π”§ λ¨λ“  Step μ²΄ν¬ν¬μΈνΈ λ¬Έμ  ν•΄κ²° μ‹μ‘...")
        
        # 1. μ „μ²΄ μ§„λ‹¨
        diagnostic_results = self.debugger.diagnose_all_checkpoints()
        
        # 2. Stepλ³„ μμ • μ μ©
        fix_results = {}
        
        for step_name, statuses in diagnostic_results.items():
            self.debugger.logger.info(f"π”§ {step_name} μ²΄ν¬ν¬μΈνΈ μμ • μ¤‘...")
            
            step_fixes = []
            for status in statuses:
                if not status.pytorch_loadable and status.exists:
                    fix = self._create_step_specific_loader(step_name, status)
                    if fix:
                        step_fixes.append(fix)
            
            fix_results[step_name] = {
                "total_checkpoints": len(statuses),
                "working_checkpoints": sum(1 for s in statuses if s.pytorch_loadable),
                "fixes_applied": step_fixes
            }
        
        # 3. μμ • ν›„ μ¬μ§„λ‹¨
        self.debugger.logger.info("π” μμ • ν›„ μ¬μ§„λ‹¨...")
        final_results = self.debugger.diagnose_all_checkpoints()
        
        return {
            "before_fix": diagnostic_results,
            "fixes_applied": fix_results,
            "after_fix": final_results,
            "improvement_summary": self._calculate_improvement(diagnostic_results, final_results)
        }
    
    def _create_step_specific_loader(self, step_name: str, status: CheckpointStatus) -> Optional[str]:
        """Stepλ³„ νΉν™” λ΅λ” μƒμ„±"""
        loader_code = f"""
# {step_name} μ „μ© μ²΄ν¬ν¬μΈνΈ λ΅λ”
def load_{step_name.lower()}_checkpoint(checkpoint_path: str):
    from backend.app.ai_pipeline.utils.checkpoint_debugger import SafeCheckpointLoader
    
    result = SafeCheckpointLoader.load_checkpoint_safe(checkpoint_path)
    if result:
        state_dict = SafeCheckpointLoader.extract_state_dict(result)
        normalized_dict = SafeCheckpointLoader.normalize_state_dict_keys(state_dict)
        return normalized_dict
    return None
"""
        
        self.fixes_applied.append({
            "step": step_name,
            "checkpoint": status.path,
            "fix_type": "custom_loader",
            "loader_code": loader_code
        })
        
        return loader_code
    
    def _calculate_improvement(self, before: Dict, after: Dict) -> Dict[str, Any]:
        """κ°μ„ μ‚¬ν•­ κ³„μ‚°"""
        improvements = {}
        
        for step_name in before.keys():
            before_success = sum(1 for s in before[step_name] if s.pytorch_loadable)
            after_success = sum(1 for s in after[step_name] if s.pytorch_loadable)
            total = len(before[step_name])
            
            improvements[step_name] = {
                "before": f"{before_success}/{total}",
                "after": f"{after_success}/{total}",
                "improvement": after_success - before_success,
                "success_rate": f"{(after_success/total*100):.1f}%" if total > 0 else "0%"
            }
        
        return improvements

# ==============================================
# π”¥ 4. λ©”μΈ μΈν„°νμ΄μ¤ ν•¨μλ“¤
# ==============================================

def diagnose_checkpoint_issues() -> Dict[str, Any]:
    """μ²΄ν¬ν¬μΈνΈ λ¬Έμ  μ§„λ‹¨"""
    debugger = CheckpointDebugger()
    return debugger.diagnose_all_checkpoints()

def fix_checkpoint_issues() -> Dict[str, Any]:
    """μ²΄ν¬ν¬μΈνΈ λ¬Έμ  μμ •"""
    fixer = StepCheckpointFixer()
    return fixer.fix_all_steps()

def test_checkpoint_loading(checkpoint_path: str) -> Dict[str, Any]:
    """κ°λ³„ μ²΄ν¬ν¬μΈνΈ λ΅λ”© ν…μ¤νΈ"""
    result = SafeCheckpointLoader.load_checkpoint_safe(checkpoint_path)
    if result:
        return {
            "success": True,
            "loading_mode": result["loading_mode"],
            "size_mb": result["size_mb"],
            "keys": result["keys"][:10]  # μ²μ 10κ° ν‚¤λ§
        }
    else:
        return {"success": False}

# ==============================================
# π”¥ 5. CLI λ„κµ¬
# ==============================================

if __name__ == "__main__":
    print("π” MyCloset AI μ²΄ν¬ν¬μΈνΈ λ””λ²„κ±° v1.0")
    print("=" * 60)
    
    import sys
    
    if len(sys.argv) > 1:
        command = sys.argv[1]
        
        if command == "diagnose":
            print("π” μ²΄ν¬ν¬μΈνΈ μ§„λ‹¨ μ‹μ‘...")
            results = diagnose_checkpoint_issues()
            print(f"β… μ§„λ‹¨ μ™„λ£: {len(results)}κ° Step λ¶„μ„")
            
        elif command == "fix":
            print("π”§ μ²΄ν¬ν¬μΈνΈ λ¬Έμ  μμ • μ‹μ‘...")
            results = fix_checkpoint_issues()
            print("β… μμ • μ™„λ£")
            
        elif command == "test" and len(sys.argv) > 2:
            checkpoint_path = sys.argv[2]
            print(f"π§ μ²΄ν¬ν¬μΈνΈ ν…μ¤νΈ: {checkpoint_path}")
            result = test_checkpoint_loading(checkpoint_path)
            print(f"κ²°κ³Ό: {result}")
            
    else:
        print("μ‚¬μ©λ²•:")
        print("  python checkpoint_debugger.py diagnose  # μ „μ²΄ μ§„λ‹¨")
        print("  python checkpoint_debugger.py fix       # λ¬Έμ  μμ •")
        print("  python checkpoint_debugger.py test <path>  # κ°λ³„ ν…μ¤νΈ")