# app/ai_pipeline/utils/dynamic_model_detector.py
"""
ğŸ” MyCloset AI - ë™ì  ëª¨ë¸ íƒì§€ê¸° v2.0
âœ… ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ ìë™ íƒì§€
âœ… íŒŒì¼ëª…, í¬ê¸°, ë‚´ìš© ê¸°ë°˜ ëª¨ë¸ íƒ€ì… ì¶”ë¡ 
âœ… Stepë³„ ìµœì  ëª¨ë¸ ìë™ ë§¤í•‘
âœ… M3 Max 128GB ìµœì í™”
âœ… ì‹¤ì‹œê°„ íŒŒì¼ ì‹œìŠ¤í…œ ëª¨ë‹ˆí„°ë§
"""

import os
import re
import json
import time
import hashlib
import logging
import threading
from pathlib import Path
from typing import Dict, List, Optional, Tuple, Any, Set
from dataclasses import dataclass, field
from enum import Enum
from concurrent.futures import ThreadPoolExecutor
import sqlite3

# PyTorch import (ì•ˆì „)
try:
    import torch
    TORCH_AVAILABLE = True
except ImportError:
    TORCH_AVAILABLE = False

try:
    import numpy as np
    from PIL import Image
    IMAGING_AVAILABLE = True
except ImportError:
    IMAGING_AVAILABLE = False

logger = logging.getLogger(__name__)

# ==============================================
# ğŸ” ëª¨ë¸ íƒì§€ ë°ì´í„° êµ¬ì¡°
# ==============================================

class ModelCategory(Enum):
    """ëª¨ë¸ ì¹´í…Œê³ ë¦¬"""
    HUMAN_PARSING = "human_parsing"
    POSE_ESTIMATION = "pose_estimation"
    CLOTH_SEGMENTATION = "cloth_segmentation"
    GEOMETRIC_MATCHING = "geometric_matching"
    CLOTH_WARPING = "cloth_warping"
    VIRTUAL_FITTING = "virtual_fitting"
    POST_PROCESSING = "post_processing"
    QUALITY_ASSESSMENT = "quality_assessment"
    AUXILIARY = "auxiliary"
    UNKNOWN = "unknown"

class ModelFormat(Enum):
    """ëª¨ë¸ í¬ë§·"""
    PYTORCH = "pytorch"
    SAFETENSORS = "safetensors"
    ONNX = "onnx"
    DIFFUSERS = "diffusers"
    TRANSFORMERS = "transformers"
    UNKNOWN = "unknown"

@dataclass
class DetectedModelFile:
    """íƒì§€ëœ ëª¨ë¸ íŒŒì¼ ì •ë³´"""
    file_path: Path
    file_name: str
    file_size_mb: float
    category: ModelCategory
    format: ModelFormat
    confidence_score: float
    step_assignment: str
    priority: int
    pytorch_valid: bool = False
    parameter_count: int = 0
    architecture_info: Dict[str, Any] = field(default_factory=dict)
    metadata: Dict[str, Any] = field(default_factory=dict)
    last_modified: float = 0.0
    checksum: str = ""

# ==============================================
# ğŸ” Stepë³„ ëª¨ë¸ íŒ¨í„´ ì •ì˜
# ==============================================

STEP_MODEL_PATTERNS = {
    "step_01_human_parsing": {
        "category": ModelCategory.HUMAN_PARSING,
        "file_patterns": [
            r".*human.*parsing.*\.(pth|pt|bin)$",
            r".*schp.*atr.*\.(pth|pt)$",
            r".*graphonomy.*\.(pth|pt)$",
            r".*atr.*model.*\.(pth|pt)$",
            r".*lip.*parsing.*\.(pth|pt)$",
            r".*segmentation.*human.*\.(pth|pt)$"
        ],
        "size_range": (50, 500),  # MB
        "priority": 1,
        "required": True
    },
    
    "step_02_pose_estimation": {
        "category": ModelCategory.POSE_ESTIMATION,
        "file_patterns": [
            r".*openpose.*\.(pth|pt|bin)$",
            r".*pose.*model.*\.(pth|pt)$",
            r".*body.*pose.*\.(pth|pt)$",
            r".*coco.*pose.*\.(pth|pt)$",
            r".*hrnet.*pose.*\.(pth|pt)$",
            r".*keypoint.*\.(pth|pt)$"
        ],
        "size_range": (10, 1000),  # MB
        "priority": 1,
        "required": True
    },
    
    "step_03_cloth_segmentation": {
        "category": ModelCategory.CLOTH_SEGMENTATION,
        "file_patterns": [
            r".*u2net.*\.(pth|pt)$",
            r".*cloth.*segmentation.*\.(pth|pt)$",
            r".*segmentation.*cloth.*\.(pth|pt)$",
            r".*u2netp.*\.(pth|pt)$",
            r".*sam.*vit.*\.(pth|pt|bin)$",
            r".*mask.*generation.*\.(pth|pt)$"
        ],
        "size_range": (50, 3000),  # MB (SAM ëª¨ë¸ì€ í¼)
        "priority": 2,
        "required": True
    },
    
    "step_04_geometric_matching": {
        "category": ModelCategory.GEOMETRIC_MATCHING,
        "file_patterns": [
            r".*geometric.*matching.*\.(pth|pt)$",
            r".*gmm.*\.(pth|pt)$",
            r".*tps.*transformation.*\.(pth|pt)$",
            r".*tps.*network.*\.(pth|pt)$",
            r".*geometric.*\.(pth|pt)$"
        ],
        "size_range": (10, 200),  # MB
        "priority": 3,
        "required": False
    },
    
    "step_05_cloth_warping": {
        "category": ModelCategory.CLOTH_WARPING,
        "file_patterns": [
            r".*cloth.*warping.*\.(pth|pt)$",
            r".*warping.*net.*\.(pth|pt)$",
            r".*tom.*final.*\.(pth|pt)$",
            r".*viton.*\.(pth|pt)$",
            r".*warp.*\.(pth|pt)$"
        ],
        "size_range": (50, 500),  # MB
        "priority": 3,
        "required": False
    },
    
    "step_06_virtual_fitting": {
        "category": ModelCategory.VIRTUAL_FITTING,
        "file_patterns": [
            r".*ootd.*diffusion.*\.(pth|pt|bin|safetensors)$",
            r".*stable.*diffusion.*\.(pth|pt|bin|safetensors)$",
            r".*unet.*\.(pth|pt|bin|safetensors)$",
            r".*hr.*viton.*\.(pth|pt)$",
            r".*viton.*hd.*\.(pth|pt)$",
            r".*diffusion.*\.(pth|pt|bin|safetensors)$"
        ],
        "size_range": (500, 8000),  # MB (í° ëª¨ë¸ë“¤)
        "priority": 1,
        "required": True
    },
    
    "step_07_post_processing": {
        "category": ModelCategory.POST_PROCESSING,
        "file_patterns": [
            r".*super.*resolution.*\.(pth|pt)$",
            r".*esrgan.*\.(pth|pt)$",
            r".*real.*esrgan.*\.(pth|pt)$",
            r".*sr.*resnet.*\.(pth|pt)$",
            r".*denoise.*\.(pth|pt)$"
        ],
        "size_range": (5, 200),  # MB
        "priority": 4,
        "required": False
    },
    
    "step_08_quality_assessment": {
        "category": ModelCategory.QUALITY_ASSESSMENT,
        "file_patterns": [
            r".*clip.*vit.*\.(pth|pt|bin)$",
            r".*quality.*assessment.*\.(pth|pt)$",
            r".*similarity.*\.(pth|pt)$",
            r".*lpips.*\.(pth|pt)$"
        ],
        "size_range": (50, 1000),  # MB
        "priority": 4,
        "required": False
    }
}

# ==============================================
# ğŸ” ë™ì  ëª¨ë¸ íƒì§€ê¸° í´ë˜ìŠ¤
# ==============================================

class DynamicModelDetector:
    """ì‹¤ì œ íŒŒì¼ ì‹œìŠ¤í…œ ê¸°ë°˜ ë™ì  ëª¨ë¸ íƒì§€ê¸°"""
    
    def __init__(self, search_paths: List[Path] = None):
        self.logger = logging.getLogger(f"{__name__}.DynamicDetector")
        
        # íƒìƒ‰ ê²½ë¡œ ì„¤ì •
        self.search_paths = search_paths or [
            Path("ai_models"),
            Path("checkpoints"),
            Path("models"),
            Path("./"),  # í˜„ì¬ ë””ë ‰í† ë¦¬
        ]
        
        # íƒì§€ ê²°ê³¼ ì €ì¥
        self.detected_models: Dict[str, DetectedModelFile] = {}
        self.scan_results: Dict[str, Any] = {}
        self.last_scan_time = 0.0
        
        # ìºì‹œ ë°ì´í„°ë² ì´ìŠ¤
        self.cache_db_path = Path("model_detection_cache.db")
        self._init_cache_db()
        
        # ìŠ¤ë ˆë“œ ë™ê¸°í™”
        self._lock = threading.RLock()
        
        self.logger.info(f"ğŸ” DynamicModelDetector ì´ˆê¸°í™” - íƒìƒ‰ ê²½ë¡œ: {len(self.search_paths)}ê°œ")
    
    def _init_cache_db(self):
        """ìºì‹œ ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”"""
        try:
            with sqlite3.connect(self.cache_db_path) as conn:
                conn.execute("""
                    CREATE TABLE IF NOT EXISTS model_cache (
                        file_path TEXT PRIMARY KEY,
                        file_name TEXT,
                        file_size_mb REAL,
                        category TEXT,
                        format TEXT,
                        confidence_score REAL,
                        step_assignment TEXT,
                        priority INTEGER,
                        pytorch_valid BOOLEAN,
                        parameter_count INTEGER,
                        last_modified REAL,
                        checksum TEXT,
                        scan_time REAL
                    )
                """)
                conn.commit()
            self.logger.debug("âœ… ëª¨ë¸ ìºì‹œ DB ì´ˆê¸°í™” ì™„ë£Œ")
        except Exception as e:
            self.logger.warning(f"âš ï¸ ìºì‹œ DB ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    
    def scan_all_models(self, force_rescan: bool = False) -> Dict[str, DetectedModelFile]:
        """ëª¨ë“  ê²½ë¡œì—ì„œ ëª¨ë¸ íŒŒì¼ íƒì§€"""
        try:
            with self._lock:
                start_time = time.time()
                
                # ìºì‹œëœ ê²°ê³¼ í™•ì¸
                if not force_rescan and time.time() - self.last_scan_time < 3600:  # 1ì‹œê°„ ìºì‹œ
                    self.logger.info("ğŸ“¦ ìºì‹œëœ ìŠ¤ìº” ê²°ê³¼ ì‚¬ìš©")
                    return self.detected_models
                
                self.logger.info("ğŸ” ì „ì²´ ëª¨ë¸ íŒŒì¼ ìŠ¤ìº” ì‹œì‘...")
                
                # ëª¨ë“  ê²½ë¡œì—ì„œ íŒŒì¼ ìˆ˜ì§‘
                all_files = []
                for search_path in self.search_paths:
                    if search_path.exists():
                        files = self._collect_model_files(search_path)
                        all_files.extend(files)
                        self.logger.debug(f"ğŸ“ {search_path}: {len(files)}ê°œ íŒŒì¼ ë°œê²¬")
                
                self.logger.info(f"ğŸ“Š ì´ {len(all_files)}ê°œ í›„ë³´ íŒŒì¼ ë°œê²¬")
                
                # ë³‘ë ¬ ë¶„ì„
                with ThreadPoolExecutor(max_workers=4) as executor:
                    futures = {executor.submit(self._analyze_model_file, file_path): file_path 
                              for file_path in all_files}
                    
                    analyzed_count = 0
                    for future in futures:
                        try:
                            detected_model = future.result()
                            if detected_model:
                                self.detected_models[str(detected_model.file_path)] = detected_model
                                analyzed_count += 1
                        except Exception as e:
                            file_path = futures[future]
                            self.logger.warning(f"âš ï¸ íŒŒì¼ ë¶„ì„ ì‹¤íŒ¨ {file_path}: {e}")
                
                # Stepë³„ ìµœì  ëª¨ë¸ ì„ íƒ
                self._assign_optimal_models()
                
                # ìºì‹œ ì—…ë°ì´íŠ¸
                self._update_cache()
                
                self.last_scan_time = time.time()
                scan_duration = time.time() - start_time
                
                self.logger.info(
                    f"âœ… ëª¨ë¸ ìŠ¤ìº” ì™„ë£Œ: {analyzed_count}ê°œ ë¶„ì„, "
                    f"{len(self.detected_models)}ê°œ ìœ íš¨ ëª¨ë¸, {scan_duration:.2f}ì´ˆ"
                )
                
                return self.detected_models
                
        except Exception as e:
            self.logger.error(f"âŒ ëª¨ë¸ ìŠ¤ìº” ì‹¤íŒ¨: {e}")
            return {}
    
    def _collect_model_files(self, search_path: Path) -> List[Path]:
        """íŠ¹ì • ê²½ë¡œì—ì„œ ëª¨ë¸ íŒŒì¼ ìˆ˜ì§‘"""
        model_files = []
        
        try:
            # ì§€ì›í•˜ëŠ” í™•ì¥ì
            model_extensions = {'.pth', '.pt', '.bin', '.safetensors', '.onnx'}
            
            for file_path in search_path.rglob('*'):
                if (file_path.is_file() and 
                    file_path.suffix.lower() in model_extensions and
                    file_path.stat().st_size > 1024 * 1024):  # 1MB ì´ìƒ
                    model_files.append(file_path)
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ íŒŒì¼ ìˆ˜ì§‘ ì‹¤íŒ¨ {search_path}: {e}")
        
        return model_files
    
    def _analyze_model_file(self, file_path: Path) -> Optional[DetectedModelFile]:
        """ê°œë³„ ëª¨ë¸ íŒŒì¼ ë¶„ì„"""
        try:
            # ê¸°ë³¸ ì •ë³´ ìˆ˜ì§‘
            file_size_mb = file_path.stat().st_size / (1024 * 1024)
            last_modified = file_path.stat().st_mtime
            
            # íŒŒì¼ëª…ìœ¼ë¡œ ì¹´í…Œê³ ë¦¬ ì¶”ë¡ 
            category, confidence, step = self._classify_by_filename(file_path.name)
            
            # í¬ë§· ê°ì§€
            format_type = self._detect_format(file_path)
            
            # PyTorch ìœ íš¨ì„± ê²€ì¦ (ê°€ëŠ¥í•œ ê²½ìš°)
            pytorch_valid, param_count, arch_info = self._validate_pytorch_model(file_path)
            
            # ì²´í¬ì„¬ ê³„ì‚° (ì‘ì€ íŒŒì¼ë§Œ)
            checksum = ""
            if file_size_mb < 100:  # 100MB ë¯¸ë§Œë§Œ
                checksum = self._calculate_checksum(file_path)
            
            # ìš°ì„ ìˆœìœ„ ê³„ì‚°
            priority = self._calculate_priority(category, confidence, file_size_mb, pytorch_valid)
            
            detected_model = DetectedModelFile(
                file_path=file_path,
                file_name=file_path.name,
                file_size_mb=file_size_mb,
                category=category,
                format=format_type,
                confidence_score=confidence,
                step_assignment=step,
                priority=priority,
                pytorch_valid=pytorch_valid,
                parameter_count=param_count,
                architecture_info=arch_info,
                last_modified=last_modified,
                checksum=checksum
            )
            
            self.logger.debug(f"ğŸ“Š ë¶„ì„ ì™„ë£Œ: {file_path.name} -> {category.value} (ì‹ ë¢°ë„: {confidence:.2f})")
            return detected_model
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ íŒŒì¼ ë¶„ì„ ì‹¤íŒ¨ {file_path}: {e}")
            return None
    
    def _classify_by_filename(self, filename: str) -> Tuple[ModelCategory, float, str]:
        """íŒŒì¼ëª…ìœ¼ë¡œ ëª¨ë¸ ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜"""
        filename_lower = filename.lower()
        
        best_match = ModelCategory.UNKNOWN
        best_confidence = 0.0
        best_step = "unknown"
        
        for step_name, step_info in STEP_MODEL_PATTERNS.items():
            for pattern in step_info["file_patterns"]:
                if re.search(pattern, filename_lower):
                    confidence = 0.8 + (0.2 if step_info["required"] else 0.0)
                    if confidence > best_confidence:
                        best_match = step_info["category"]
                        best_confidence = confidence
                        best_step = step_name
        
        # ë³´ì¡° íŒ¨í„´ë“¤
        auxiliary_patterns = {
            r"clip.*vit": (ModelCategory.AUXILIARY, 0.7, "auxiliary"),
            r"resnet": (ModelCategory.AUXILIARY, 0.6, "auxiliary"),
            r"vgg": (ModelCategory.AUXILIARY, 0.6, "auxiliary"),
        }
        
        for pattern, (category, confidence, step) in auxiliary_patterns.items():
            if re.search(pattern, filename_lower) and confidence > best_confidence:
                best_match = category
                best_confidence = confidence
                best_step = step
        
        return best_match, best_confidence, best_step
    
    def _detect_format(self, file_path: Path) -> ModelFormat:
        """íŒŒì¼ í¬ë§· ê°ì§€"""
        suffix = file_path.suffix.lower()
        
        format_map = {
            '.pth': ModelFormat.PYTORCH,
            '.pt': ModelFormat.PYTORCH,
            '.bin': ModelFormat.PYTORCH,  # ì¼ë°˜ì ìœ¼ë¡œ PyTorch
            '.safetensors': ModelFormat.SAFETENSORS,
            '.onnx': ModelFormat.ONNX
        }
        
        return format_map.get(suffix, ModelFormat.UNKNOWN)
    
    def _validate_pytorch_model(self, file_path: Path) -> Tuple[bool, int, Dict[str, Any]]:
        """PyTorch ëª¨ë¸ ìœ íš¨ì„± ê²€ì¦"""
        if not TORCH_AVAILABLE:
            return False, 0, {}
        
        try:
            # ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì¸ ë¡œë”©
            checkpoint = torch.load(file_path, map_location='cpu', weights_only=True)
            
            # state_dict ì¶”ì¶œ
            if isinstance(checkpoint, dict):
                if 'state_dict' in checkpoint:
                    state_dict = checkpoint['state_dict']
                elif 'model' in checkpoint:
                    state_dict = checkpoint['model']
                else:
                    state_dict = checkpoint
            else:
                return False, 0, {}
            
            # íŒŒë¼ë¯¸í„° ê°œìˆ˜ ê³„ì‚°
            param_count = sum(p.numel() for p in state_dict.values() if isinstance(p, torch.Tensor))
            
            # ì•„í‚¤í…ì²˜ ì •ë³´ ì¶”ì¶œ
            arch_info = {
                'total_parameters': param_count,
                'layer_count': len(state_dict),
                'has_conv_layers': any('conv' in key.lower() for key in state_dict.keys()),
                'has_linear_layers': any('linear' in key.lower() or 'fc' in key.lower() for key in state_dict.keys()),
                'has_norm_layers': any('norm' in key.lower() or 'bn' in key.lower() for key in state_dict.keys())
            }
            
            return True, param_count, arch_info
            
        except Exception as e:
            self.logger.debug(f"PyTorch ê²€ì¦ ì‹¤íŒ¨ {file_path.name}: {e}")
            return False, 0, {}
    
    def _calculate_checksum(self, file_path: Path) -> str:
        """íŒŒì¼ ì²´í¬ì„¬ ê³„ì‚°"""
        try:
            hash_md5 = hashlib.md5()
            with open(file_path, "rb") as f:
                for chunk in iter(lambda: f.read(4096), b""):
                    hash_md5.update(chunk)
            return hash_md5.hexdigest()
        except Exception:
            return ""
    
    def _calculate_priority(self, category: ModelCategory, confidence: float, 
                           size_mb: float, pytorch_valid: bool) -> int:
        """ëª¨ë¸ ìš°ì„ ìˆœìœ„ ê³„ì‚°"""
        base_priority = 10
        
        # ì¹´í…Œê³ ë¦¬ë³„ ìš°ì„ ìˆœìœ„
        category_priorities = {
            ModelCategory.HUMAN_PARSING: 1,
            ModelCategory.VIRTUAL_FITTING: 1,
            ModelCategory.POSE_ESTIMATION: 2,
            ModelCategory.CLOTH_SEGMENTATION: 2,
            ModelCategory.CLOTH_WARPING: 3,
            ModelCategory.GEOMETRIC_MATCHING: 3,
            ModelCategory.POST_PROCESSING: 4,
            ModelCategory.QUALITY_ASSESSMENT: 4,
            ModelCategory.AUXILIARY: 5,
            ModelCategory.UNKNOWN: 10
        }
        
        priority = category_priorities.get(category, 10)
        
        # ì‹ ë¢°ë„ë¡œ ì¡°ì •
        if confidence > 0.8:
            priority -= 1
        elif confidence < 0.5:
            priority += 2
        
        # PyTorch ìœ íš¨ì„±ìœ¼ë¡œ ì¡°ì •
        if pytorch_valid:
            priority -= 1
        else:
            priority += 1
        
        # ì ì ˆí•œ í¬ê¸° ë²”ìœ„ì— ìˆìœ¼ë©´ ìš°ì„ ìˆœìœ„ í–¥ìƒ
        if 50 <= size_mb <= 1000:
            priority -= 1
        
        return max(1, priority)
    
    def _assign_optimal_models(self):
        """Stepë³„ ìµœì  ëª¨ë¸ í• ë‹¹"""
        try:
            step_assignments = {}
            
            for model_path, model_info in self.detected_models.items():
                step = model_info.step_assignment
                
                if step not in step_assignments:
                    step_assignments[step] = []
                
                step_assignments[step].append(model_info)
            
            # ê° Stepë³„ë¡œ ìµœì  ëª¨ë¸ ì„ íƒ
            for step, models in step_assignments.items():
                if not models:
                    continue
                
                # ìš°ì„ ìˆœìœ„ì™€ ì‹ ë¢°ë„ë¡œ ì •ë ¬
                sorted_models = sorted(models, 
                                     key=lambda m: (m.priority, -m.confidence_score, -m.file_size_mb))
                
                # ìµœê³  ìš°ì„ ìˆœìœ„ ëª¨ë¸ì„ ì£¼ ëª¨ë¸ë¡œ ì„¤ì •
                if sorted_models:
                    primary_model = sorted_models[0]
                    primary_model.metadata['is_primary'] = True
                    
                    self.logger.info(f"ğŸ¯ {step} ìµœì  ëª¨ë¸: {primary_model.file_name} "
                                   f"(ìš°ì„ ìˆœìœ„: {primary_model.priority}, "
                                   f"ì‹ ë¢°ë„: {primary_model.confidence_score:.2f})")
            
        except Exception as e:
            self.logger.error(f"âŒ ìµœì  ëª¨ë¸ í• ë‹¹ ì‹¤íŒ¨: {e}")
    
    def _update_cache(self):
        """ìºì‹œ ë°ì´í„°ë² ì´ìŠ¤ ì—…ë°ì´íŠ¸"""
        try:
            with sqlite3.connect(self.cache_db_path) as conn:
                # ê¸°ì¡´ ë°ì´í„° ì‚­ì œ
                conn.execute("DELETE FROM model_cache")
                
                # ìƒˆ ë°ì´í„° ì‚½ì…
                for model_info in self.detected_models.values():
                    conn.execute("""
                        INSERT INTO model_cache VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                    """, (
                        str(model_info.file_path),
                        model_info.file_name,
                        model_info.file_size_mb,
                        model_info.category.value,
                        model_info.format.value,
                        model_info.confidence_score,
                        model_info.step_assignment,
                        model_info.priority,
                        model_info.pytorch_valid,
                        model_info.parameter_count,
                        model_info.last_modified,
                        model_info.checksum,
                        time.time()
                    ))
                
                conn.commit()
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ ìºì‹œ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
    
    def get_step_models(self, step_name: str) -> List[DetectedModelFile]:
        """íŠ¹ì • Stepì˜ ëª¨ë¸ë“¤ ë°˜í™˜"""
        return [model for model in self.detected_models.values() 
                if model.step_assignment == step_name]
    
    def get_primary_model(self, step_name: str) -> Optional[DetectedModelFile]:
        """Stepì˜ ì£¼ ëª¨ë¸ ë°˜í™˜"""
        step_models = self.get_step_models(step_name)
        primary_models = [m for m in step_models if m.metadata.get('is_primary', False)]
        
        if primary_models:
            return primary_models[0]
        elif step_models:
            return sorted(step_models, key=lambda m: (m.priority, -m.confidence_score))[0]
        else:
            return None
    
    def generate_model_mapping(self) -> Dict[str, str]:
        """ModelLoaderìš© ëª¨ë¸ ë§¤í•‘ ìƒì„±"""
        mapping = {}
        
        for step_name in STEP_MODEL_PATTERNS.keys():
            primary_model = self.get_primary_model(step_name)
            if primary_model:
                mapping[step_name] = str(primary_model.file_path)
                
                # ë³„ì¹­ë“¤ë„ ì¶”ê°€
                base_name = step_name.replace("step_", "").replace("_", "")
                mapping[base_name] = str(primary_model.file_path)
                mapping[primary_model.file_name.replace('.pth', '')] = str(primary_model.file_path)
        
        return mapping
    
    def get_detection_summary(self) -> Dict[str, Any]:
        """íƒì§€ ê²°ê³¼ ìš”ì•½"""
        summary = {
            'total_models': len(self.detected_models),
            'by_category': {},
            'by_step': {},
            'by_format': {},
            'total_size_gb': sum(m.file_size_mb for m in self.detected_models.values()) / 1024,
            'pytorch_valid_count': sum(1 for m in self.detected_models.values() if m.pytorch_valid),
            'scan_time': self.last_scan_time
        }
        
        for model in self.detected_models.values():
            # ì¹´í…Œê³ ë¦¬ë³„
            cat = model.category.value
            summary['by_category'][cat] = summary['by_category'].get(cat, 0) + 1
            
            # Stepë³„
            step = model.step_assignment
            summary['by_step'][step] = summary['by_step'].get(step, 0) + 1
            
            # í¬ë§·ë³„
            fmt = model.format.value
            summary['by_format'][fmt] = summary['by_format'].get(fmt, 0) + 1
        
        return summary

# ==============================================
# ğŸ” í¸ì˜ í•¨ìˆ˜ë“¤
# ==============================================

def create_dynamic_detector(search_paths: List[Path] = None) -> DynamicModelDetector:
    """ë™ì  ëª¨ë¸ íƒì§€ê¸° ìƒì„±"""
    return DynamicModelDetector(search_paths)

def quick_model_scan(search_paths: List[Path] = None) -> Dict[str, str]:
    """ë¹ ë¥¸ ëª¨ë¸ ìŠ¤ìº” ë° ë§¤í•‘ ë°˜í™˜"""
    detector = create_dynamic_detector(search_paths)
    detector.scan_all_models()
    return detector.generate_model_mapping()

def find_step_model(step_name: str, search_paths: List[Path] = None) -> Optional[str]:
    """íŠ¹ì • Stepì˜ ëª¨ë¸ ê²½ë¡œ ì°¾ê¸°"""
    detector = create_dynamic_detector(search_paths)
    detector.scan_all_models()
    primary_model = detector.get_primary_model(step_name)
    return str(primary_model.file_path) if primary_model else None

# ëª¨ë“ˆ ìµìŠ¤í¬íŠ¸
__all__ = [
    'DynamicModelDetector',
    'DetectedModelFile',
    'ModelCategory',
    'ModelFormat',
    'create_dynamic_detector',
    'quick_model_scan',
    'find_step_model',
    'STEP_MODEL_PATTERNS'
]