# backend/app/ai_pipeline/utils/image_processing.py
"""
ğŸ–¼ï¸ MyCloset AI - ì´ë¯¸ì§€ ì²˜ë¦¬ í•¨ìˆ˜ë“¤ (ìˆœí™˜ì°¸ì¡° ë°©ì§€ ë²„ì „) - ì™„ì „íŒ
=========================================================
âœ… model_loader.pyì—ì„œ ë¶„ë¦¬ëœ ì´ë¯¸ì§€ ì²˜ë¦¬ í•¨ìˆ˜ë“¤
âœ… ìˆœí™˜ì°¸ì¡° ì™„ì „ ë°©ì§€ - ë…ë¦½ì ì¸ ëª¨ë“ˆ
âœ… PIL, OpenCV, NumPy ê¸°ë°˜ ì´ë¯¸ì§€ ì²˜ë¦¬
âœ… PyTorch í…ì„œ ë³€í™˜ ì§€ì›
âœ… M3 Max 128GB ìµœì í™”
âœ… conda í™˜ê²½ ì™„ë²½ ì§€ì›
âœ… ê¸°ì¡´ í•¨ìˆ˜ëª… 100% ìœ ì§€
âœ… ëª¨ë“  ê¸°ëŠ¥ ì™„ì „ êµ¬í˜„ - ì˜ë¦° ë¶€ë¶„ ì—†ìŒ

Author: MyCloset AI Team
Date: 2025-07-21
Version: 1.0 (Separated from model_loader.py - Complete)
"""

import io
import logging
import base64
import tempfile
import os
import uuid
import math
from typing import Dict, Any, Optional, Tuple, List, Union
from pathlib import Path

# ì¡°ê±´ë¶€ ì„í¬íŠ¸ (ì•ˆì „í•œ ì²˜ë¦¬)
try:
    import numpy as np
    NUMPY_AVAILABLE = True
    logger = logging.getLogger(__name__)
    logger.info("âœ… NumPy ì‚¬ìš© ê°€ëŠ¥")
    
    # NumPy 2.x í˜¸í™˜ì„± ì²˜ë¦¬
    major_version = int(np.__version__.split('.')[0])
    if major_version >= 2:
        logger.warning(f"âš ï¸ NumPy {np.__version__} ê°ì§€ë¨. NumPy 1.x ê¶Œì¥")
        logger.warning("ğŸ”§ í•´ê²°ë°©ë²•: conda install numpy=1.24.3 -y --force-reinstall")
except ImportError as e:
    NUMPY_AVAILABLE = False
    np = None
    logger = logging.getLogger(__name__)
    logger.warning(f"âš ï¸ NumPy ì—†ìŒ: {e}")

try:
    from PIL import Image, ImageEnhance, ImageFilter, ImageDraw, ImageFont
    PIL_AVAILABLE = True
    logger.info("âœ… PIL/Pillow ì‚¬ìš© ê°€ëŠ¥")
except ImportError as e:
    PIL_AVAILABLE = False
    logger.warning(f"âš ï¸ PIL/Pillow ì—†ìŒ: {e}")

try:
    import cv2
    CV2_AVAILABLE = True
    logger.info("âœ… OpenCV ì‚¬ìš© ê°€ëŠ¥")
except ImportError as e:
    CV2_AVAILABLE = False
    logger.warning(f"âš ï¸ OpenCV ì—†ìŒ: {e}")

try:
    import torch
    import torch.nn.functional as F
    TORCH_AVAILABLE = True
    logger.info("âœ… PyTorch ì‚¬ìš© ê°€ëŠ¥")
except ImportError as e:
    TORCH_AVAILABLE = False
    torch = None
    logger.warning(f"âš ï¸ PyTorch ì—†ìŒ: {e}")

# ==============================================
# ğŸ”¥ ê¸°ë³¸ ì´ë¯¸ì§€ ì „ì²˜ë¦¬ í•¨ìˆ˜ë“¤
# ==============================================

def preprocess_image(
    image: Union[str, 'Image.Image', 'np.ndarray'],
    target_size: Tuple[int, int] = (512, 512),
    device: str = "mps",
    normalize: bool = True,
    to_tensor: bool = True
) -> Any:
    """
    ì´ë¯¸ì§€ ì „ì²˜ë¦¬ í•¨ìˆ˜ - ì™„ì „ êµ¬í˜„
    
    Args:
        image: ì…ë ¥ ì´ë¯¸ì§€ (íŒŒì¼ ê²½ë¡œ, PIL Image, numpy array)
        target_size: íƒ€ê²Ÿ í¬ê¸° (width, height)
        device: ë””ë°”ì´ìŠ¤ ("mps", "cuda", "cpu")
        normalize: ì •ê·œí™” ì—¬ë¶€ (0-1 ë²”ìœ„ë¡œ)
        to_tensor: PyTorch tensorë¡œ ë³€í™˜ ì—¬ë¶€
    
    Returns:
        ì „ì²˜ë¦¬ëœ ì´ë¯¸ì§€ (tensor ë˜ëŠ” numpy array)
    """
    try:
        logger.debug(f"ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì‹œì‘: {type(image)}, íƒ€ê²Ÿ í¬ê¸°: {target_size}")
        
        # 1. ì´ë¯¸ì§€ ë¡œë“œ ë° ë³€í™˜
        if isinstance(image, (str, Path)):
            # íŒŒì¼ ê²½ë¡œì¸ ê²½ìš°
            if PIL_AVAILABLE:
                try:
                    image = Image.open(image).convert('RGB')
                    logger.debug("âœ… PILë¡œ ì´ë¯¸ì§€ ë¡œë“œ ì„±ê³µ")
                except Exception as e:
                    logger.error(f"âŒ PIL ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {e}")
                    if CV2_AVAILABLE and NUMPY_AVAILABLE:
                        image = cv2.imread(str(image))
                        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
                        logger.debug("âœ… OpenCVë¡œ ì´ë¯¸ì§€ ë¡œë“œ ì„±ê³µ")
                    else:
                        raise ImportError("ì´ë¯¸ì§€ ë¡œë“œë¥¼ ìœ„í•´ PIL ë˜ëŠ” OpenCVê°€ í•„ìš”í•©ë‹ˆë‹¤")
            else:
                raise ImportError("ì´ë¯¸ì§€ ë¡œë“œë¥¼ ìœ„í•´ PILì´ í•„ìš”í•©ë‹ˆë‹¤")
        
        # 2. PIL Image ì²˜ë¦¬
        if hasattr(image, 'size'):  # PIL Image
            width, height = image.size
            channels = len(image.getbands())
            bytes_per_pixel = 1 if image.mode == 'L' else 3 if image.mode == 'RGB' else 4
            total_bytes = width * height * bytes_per_pixel
        elif NUMPY_AVAILABLE and hasattr(image, 'nbytes'):  # NumPy array
            total_bytes = image.nbytes
        elif TORCH_AVAILABLE and hasattr(image, 'element_size'):  # PyTorch tensor
            total_bytes = image.numel() * image.element_size()
        else:
            total_bytes = 0
        
        usage.update({
            "bytes": total_bytes,
            "mb": total_bytes / (1024 * 1024),
            "gb": total_bytes / (1024 * 1024 * 1024)
        })
        
        logger.debug(f"ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¶”ì •: {usage['mb']:.2f} MB")
        return usage
        
    except Exception as e:
        logger.error(f"âŒ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¶”ì • ì‹¤íŒ¨: {e}")
        return {"bytes": 0, "mb": 0, "gb": 0, "error": str(e)}

def optimize_image_memory(image: Any, target_size: Optional[Tuple[int, int]] = None, 
                         quality: int = 85, format: str = "JPEG") -> Any:
    """ì´ë¯¸ì§€ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ìµœì í™”"""
    try:
        if not PIL_AVAILABLE:
            logger.warning("âš ï¸ PIL í•„ìš”, ì›ë³¸ ë°˜í™˜")
            return image
        
        # PIL Imageë¡œ ë³€í™˜
        if hasattr(image, 'save'):  # ì´ë¯¸ PIL Image
            pil_image = image
        elif NUMPY_AVAILABLE and hasattr(image, 'shape'):  # NumPy array
            pil_image = Image.fromarray(image.astype(np.uint8))
        elif TORCH_AVAILABLE and hasattr(image, 'cpu'):  # PyTorch tensor
            pil_image = tensor_to_pil(image)
        else:
            logger.warning("âš ï¸ ì§€ì›í•˜ì§€ ì•ŠëŠ” ì´ë¯¸ì§€ íƒ€ì…")
            return image
        
        # í¬ê¸° ì¡°ì •
        if target_size:
            pil_image = pil_image.resize(target_size, Image.Resampling.LANCZOS)
            logger.debug(f"í¬ê¸° ì¡°ì •: {target_size}")
        
        # ìƒ‰ìƒ ëª¨ë“œ ìµœì í™”
        if pil_image.mode == 'RGBA' and format.upper() == 'JPEG':
            # JPEGëŠ” íˆ¬ëª…ë„ë¥¼ ì§€ì›í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ RGBë¡œ ë³€í™˜
            background = Image.new('RGB', pil_image.size, (255, 255, 255))
            background.paste(pil_image, mask=pil_image.split()[-1])
            pil_image = background
        elif pil_image.mode not in ['RGB', 'L']:
            pil_image = pil_image.convert('RGB')
        
        # ì••ì¶• ì ìš©
        buffer = io.BytesIO()
        pil_image.save(buffer, format=format, quality=quality, optimize=True)
        buffer.seek(0)
        optimized_image = Image.open(buffer)
        
        logger.debug(f"âœ… ì´ë¯¸ì§€ ë©”ëª¨ë¦¬ ìµœì í™” ì™„ë£Œ: format={format}, quality={quality}")
        return optimized_image
        
    except Exception as e:
        logger.error(f"âŒ ì´ë¯¸ì§€ ë©”ëª¨ë¦¬ ìµœì í™” ì‹¤íŒ¨: {e}")
        return image

# ==============================================
# ğŸ”¥ ì´ë¯¸ì§€ ë³€í™˜ ë° í¬ë§· í•¨ìˆ˜ë“¤
# ==============================================

def convert_image_format(image: Any, target_format: str = "RGB") -> Any:
    """ì´ë¯¸ì§€ í¬ë§· ë³€í™˜"""
    try:
        if not PIL_AVAILABLE:
            logger.warning("âš ï¸ PIL í•„ìš”, ì›ë³¸ ë°˜í™˜")
            return image
        
        # PIL Imageë¡œ ë³€í™˜
        if hasattr(image, 'save'):  # ì´ë¯¸ PIL Image
            pil_image = image
        elif NUMPY_AVAILABLE and hasattr(image, 'shape'):  # NumPy array
            pil_image = Image.fromarray(image.astype(np.uint8))
        elif TORCH_AVAILABLE and hasattr(image, 'cpu'):  # PyTorch tensor
            pil_image = tensor_to_pil(image)
        else:
            logger.warning("âš ï¸ ì§€ì›í•˜ì§€ ì•ŠëŠ” ì´ë¯¸ì§€ íƒ€ì…")
            return image
        
        # í¬ë§· ë³€í™˜
        if pil_image.mode != target_format:
            converted = pil_image.convert(target_format)
            logger.debug(f"âœ… í¬ë§· ë³€í™˜ ì™„ë£Œ: {pil_image.mode} â†’ {target_format}")
            return converted
        else:
            logger.debug(f"ì´ë¯¸ {target_format} í¬ë§·ì„")
            return pil_image
            
    except Exception as e:
        logger.error(f"âŒ ì´ë¯¸ì§€ í¬ë§· ë³€í™˜ ì‹¤íŒ¨: {e}")
        return image

def save_image(image: Any, filepath: str, format: str = None, quality: int = 95, **kwargs) -> bool:
    """ì´ë¯¸ì§€ íŒŒì¼ë¡œ ì €ì¥"""
    try:
        if not PIL_AVAILABLE:
            logger.error("âŒ PIL í•„ìš”í•¨")
            return False
        
        # PIL Imageë¡œ ë³€í™˜
        if hasattr(image, 'save'):  # ì´ë¯¸ PIL Image
            pil_image = image
        elif NUMPY_AVAILABLE and hasattr(image, 'shape'):  # NumPy array
            if image.dtype != np.uint8:
                if image.max() <= 1.0:
                    image = (image * 255).astype(np.uint8)
                else:
                    image = np.clip(image, 0, 255).astype(np.uint8)
            pil_image = Image.fromarray(image)
        elif TORCH_AVAILABLE and hasattr(image, 'cpu'):  # PyTorch tensor
            pil_image = tensor_to_pil(image)
        else:
            logger.error(f"âŒ ì§€ì›í•˜ì§€ ì•ŠëŠ” ì´ë¯¸ì§€ íƒ€ì…: {type(image)}")
            return False
        
        # í¬ë§· ìë™ ê°ì§€
        if format is None:
            format = Path(filepath).suffix.upper().lstrip('.')
            if format == 'JPG':
                format = 'JPEG'
        
        # RGB ëª¨ë“œ í™•ì¸ (JPEGëŠ” íˆ¬ëª…ë„ ì§€ì› ì•ˆí•¨)
        if format.upper() == 'JPEG' and pil_image.mode in ['RGBA', 'LA']:
            background = Image.new('RGB', pil_image.size, (255, 255, 255))
            if pil_image.mode == 'RGBA':
                background.paste(pil_image, mask=pil_image.split()[-1])
            else:
                background.paste(pil_image)
            pil_image = background
        
        # ë””ë ‰í† ë¦¬ ìƒì„±
        Path(filepath).parent.mkdir(parents=True, exist_ok=True)
        
        # ì €ì¥
        save_kwargs = {'format': format, **kwargs}
        if format.upper() in ['JPEG', 'WEBP']:
            save_kwargs['quality'] = quality
            save_kwargs['optimize'] = True
        
        pil_image.save(filepath, **save_kwargs)
        
        logger.debug(f"âœ… ì´ë¯¸ì§€ ì €ì¥ ì™„ë£Œ: {filepath} ({format})")
        return True
        
    except Exception as e:
        logger.error(f"âŒ ì´ë¯¸ì§€ ì €ì¥ ì‹¤íŒ¨: {e}")
        return False

def load_image(filepath: str, target_format: str = "RGB") -> Any:
    """ì´ë¯¸ì§€ íŒŒì¼ ë¡œë“œ"""
    try:
        if not PIL_AVAILABLE:
            logger.error("âŒ PIL í•„ìš”í•¨")
            return None
        
        if not Path(filepath).exists():
            logger.error(f"âŒ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ: {filepath}")
            return None
        
        # ì´ë¯¸ì§€ ë¡œë“œ
        pil_image = Image.open(filepath)
        
        # í¬ë§· ë³€í™˜
        if target_format and pil_image.mode != target_format:
            pil_image = pil_image.convert(target_format)
        
        logger.debug(f"âœ… ì´ë¯¸ì§€ ë¡œë“œ ì™„ë£Œ: {filepath} ({pil_image.size}, {pil_image.mode})")
        return pil_image
        
    except Exception as e:
        logger.error(f"âŒ ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None

# ==============================================
# ğŸ”¥ ì´ë¯¸ì§€ ì‹œê°í™” ë° ë””ë²„ê¹… í•¨ìˆ˜ë“¤
# ==============================================

def create_image_grid(images: List[Any], grid_size: Optional[Tuple[int, int]] = None, 
                     padding: int = 2, background_color: Tuple[int, int, int] = (255, 255, 255)) -> Any:
    """ì´ë¯¸ì§€ë“¤ì„ ê²©ìë¡œ ë°°ì—´"""
    try:
        if not PIL_AVAILABLE or not images:
            logger.warning("âš ï¸ PIL í•„ìš”í•˜ê±°ë‚˜ ì´ë¯¸ì§€ê°€ ì—†ìŒ")
            return None
        
        # ê²©ì í¬ê¸° ê³„ì‚°
        if grid_size is None:
            grid_cols = int(math.ceil(math.sqrt(len(images))))
            grid_rows = int(math.ceil(len(images) / grid_cols))
            grid_size = (grid_rows, grid_cols)
        else:
            grid_rows, grid_cols = grid_size
        
        # PIL Imageë¡œ ë³€í™˜
        pil_images = []
        for img in images:
            if hasattr(img, 'save'):  # ì´ë¯¸ PIL Image
                pil_images.append(img)
            elif NUMPY_AVAILABLE and hasattr(img, 'shape'):  # NumPy array
                pil_images.append(Image.fromarray(img.astype(np.uint8)))
            elif TORCH_AVAILABLE and hasattr(img, 'cpu'):  # PyTorch tensor
                pil_images.append(tensor_to_pil(img))
            else:
                logger.warning(f"âš ï¸ ì§€ì›í•˜ì§€ ì•ŠëŠ” ì´ë¯¸ì§€ íƒ€ì…: {type(img)}")
                continue
        
        if not pil_images:
            logger.warning("âš ï¸ ë³€í™˜ ê°€ëŠ¥í•œ ì´ë¯¸ì§€ê°€ ì—†ìŒ")
            return None
        
        # ëª¨ë“  ì´ë¯¸ì§€ë¥¼ ê°™ì€ í¬ê¸°ë¡œ ì¡°ì •
        max_width = max(img.width for img in pil_images)
        max_height = max(img.height for img in pil_images)
        
        resized_images = []
        for img in pil_images:
            resized = img.resize((max_width, max_height), Image.Resampling.LANCZOS)
            resized_images.append(resized)
        
        # ê²©ì ì´ë¯¸ì§€ ìƒì„±
        grid_width = grid_cols * max_width + (grid_cols + 1) * padding
        grid_height = grid_rows * max_height + (grid_rows + 1) * padding
        
        grid_image = Image.new('RGB', (grid_width, grid_height), background_color)
        
        # ì´ë¯¸ì§€ë“¤ ë°°ì¹˜
        for i, img in enumerate(resized_images):
            if i >= grid_rows * grid_cols:
                break
            
            row = i // grid_cols
            col = i % grid_cols
            
            x = col * (max_width + padding) + padding
            y = row * (max_height + padding) + padding
            
            grid_image.paste(img, (x, y))
        
        logger.debug(f"âœ… ì´ë¯¸ì§€ ê²©ì ìƒì„± ì™„ë£Œ: {grid_size}, {len(resized_images)}ê°œ ì´ë¯¸ì§€")
        return grid_image
        
    except Exception as e:
        logger.error(f"âŒ ì´ë¯¸ì§€ ê²©ì ìƒì„± ì‹¤íŒ¨: {e}")
        return None

def add_text_to_image(image: Any, text: str, position: Tuple[int, int] = (10, 10), 
                     font_size: int = 20, color: Tuple[int, int, int] = (0, 0, 0)) -> Any:
    """ì´ë¯¸ì§€ì— í…ìŠ¤íŠ¸ ì¶”ê°€"""
    try:
        if not PIL_AVAILABLE:
            logger.warning("âš ï¸ PIL í•„ìš”, ì›ë³¸ ë°˜í™˜")
            return image
        
        # PIL Imageë¡œ ë³€í™˜
        if hasattr(image, 'save'):  # ì´ë¯¸ PIL Image
            pil_image = image.copy()
        elif NUMPY_AVAILABLE and hasattr(image, 'shape'):  # NumPy array
            pil_image = Image.fromarray(image.astype(np.uint8))
        elif TORCH_AVAILABLE and hasattr(image, 'cpu'):  # PyTorch tensor
            pil_image = tensor_to_pil(image)
        else:
            logger.warning("âš ï¸ ì§€ì›í•˜ì§€ ì•ŠëŠ” ì´ë¯¸ì§€ íƒ€ì…")
            return image
        
        # ë“œë¡œì‰ ê°ì²´ ìƒì„±
        draw = ImageDraw.Draw(pil_image)
        
        # í°íŠ¸ ì„¤ì • (ê¸°ë³¸ í°íŠ¸ ì‚¬ìš©)
        try:
            font = ImageFont.truetype("arial.ttf", font_size)
        except:
            try:
                font = ImageFont.load_default()
            except:
                font = None
        
        # í…ìŠ¤íŠ¸ ì¶”ê°€
        draw.text(position, text, fill=color, font=font)
        
        logger.debug(f"âœ… í…ìŠ¤íŠ¸ ì¶”ê°€ ì™„ë£Œ: '{text}' at {position}")
        return pil_image
        
    except Exception as e:
        logger.error(f"âŒ í…ìŠ¤íŠ¸ ì¶”ê°€ ì‹¤íŒ¨: {e}")
        return image

def create_comparison_image(image1: Any, image2: Any, labels: Tuple[str, str] = ("Original", "Processed")) -> Any:
    """ë‘ ì´ë¯¸ì§€ë¥¼ ë¹„êµí•˜ëŠ” ì´ë¯¸ì§€ ìƒì„±"""
    try:
        if not PIL_AVAILABLE:
            logger.warning("âš ï¸ PIL í•„ìš”")
            return None
        
        # PIL Imageë¡œ ë³€í™˜
        def to_pil(img):
            if hasattr(img, 'save'):  # ì´ë¯¸ PIL Image
                return img
            elif NUMPY_AVAILABLE and hasattr(img, 'shape'):  # NumPy array
                return Image.fromarray(img.astype(np.uint8))
            elif TORCH_AVAILABLE and hasattr(img, 'cpu'):  # PyTorch tensor
                return tensor_to_pil(img)
            else:
                return None
        
        pil1 = to_pil(image1)
        pil2 = to_pil(image2)
        
        if pil1 is None or pil2 is None:
            logger.warning("âš ï¸ ì´ë¯¸ì§€ ë³€í™˜ ì‹¤íŒ¨")
            return None
        
        # ê°™ì€ í¬ê¸°ë¡œ ì¡°ì •
        max_width = max(pil1.width, pil2.width)
        max_height = max(pil1.height, pil2.height)
        
        pil1 = pil1.resize((max_width, max_height), Image.Resampling.LANCZOS)
        pil2 = pil2.resize((max_width, max_height), Image.Resampling.LANCZOS)
        
        # ë¹„êµ ì´ë¯¸ì§€ ìƒì„± (ì¢Œìš° ë°°ì¹˜)
        padding = 20
        text_height = 30
        
        comparison_width = max_width * 2 + padding * 3
        comparison_height = max_height + text_height + padding * 2
        
        comparison = Image.new('RGB', (comparison_width, comparison_height), (255, 255, 255))
        
        # ì´ë¯¸ì§€ë“¤ ë°°ì¹˜
        comparison.paste(pil1, (padding, text_height + padding))
        comparison.paste(pil2, (max_width + padding * 2, text_height + padding))
        
        # ë¼ë²¨ ì¶”ê°€
        comparison = add_text_to_image(comparison, labels[0], (padding, 5), font_size=20)
        comparison = add_text_to_image(comparison, labels[1], (max_width + padding * 2, 5), font_size=20)
        
        logger.debug(f"âœ… ë¹„êµ ì´ë¯¸ì§€ ìƒì„± ì™„ë£Œ: {labels}")
        return comparison
        
    except Exception as e:
        logger.error(f"âŒ ë¹„êµ ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨: {e}")
        return None

# ==============================================
# ğŸ”¥ Stepë³„ íŠ¹í™” ì²˜ë¦¬ í•¨ìˆ˜ë“¤
# ==============================================

def postprocess_human_parsing(output: Any, num_classes: int = 20, 
                             colormap: Optional[List[Tuple[int, int, int]]] = None) -> Any:
    """ì¸ì²´ íŒŒì‹± ê²°ê³¼ í›„ì²˜ë¦¬ (ì»¬ëŸ¬ë§µ ì ìš©)"""
    try:
        if not NUMPY_AVAILABLE:
            logger.warning("âš ï¸ NumPy í•„ìš”")
            return output
        
        # ì¶œë ¥ì„ numpy arrayë¡œ ë³€í™˜
        if TORCH_AVAILABLE and hasattr(output, 'cpu'):
            pred = output.cpu().numpy()
        elif hasattr(output, 'shape'):
            pred = output
        else:
            logger.warning("âš ï¸ ì§€ì›í•˜ì§€ ì•ŠëŠ” ì¶œë ¥ íƒ€ì…")
            return output
        
        # ì°¨ì› ì¡°ì •
        if pred.ndim == 4:  # (N, C, H, W)
            pred = pred.squeeze(0)
        if pred.ndim == 3:  # (C, H, W)
            pred = np.argmax(pred, axis=0)
        
        # ê¸°ë³¸ ì»¬ëŸ¬ë§µ ìƒì„±
        if colormap is None:
            colormap = []
            for i in range(num_classes):
                # HSV ìƒ‰ê³µê°„ì—ì„œ ê· ë“±í•˜ê²Œ ë¶„í¬ëœ ìƒ‰ìƒ ìƒì„±
                hue = int(i * 360 / num_classes)
                if i == 0:  # ë°°ê²½ì€ ê²€ì€ìƒ‰
                    colormap.append((0, 0, 0))
                else:
                    # HSV to RGB ë³€í™˜ (ê°„ë‹¨í•œ ë²„ì „)
                    c = 255
                    x = int(c * (1 - abs((hue / 60) % 2 - 1)))
                    if 0 <= hue < 60:
                        rgb = (c, x, 0)
                    elif 60 <= hue < 120:
                        rgb = (x, c, 0)
                    elif 120 <= hue < 180:
                        rgb = (0, c, x)
                    elif 180 <= hue < 240:
                        rgb = (0, x, c)
                    elif 240 <= hue < 300:
                        rgb = (x, 0, c)
                    else:
                        rgb = (c, 0, x)
                    colormap.append(rgb)
        
        # ì»¬ëŸ¬ë§µ ì ìš©
        height, width = pred.shape
        colored = np.zeros((height, width, 3), dtype=np.uint8)
        
        for class_id in range(min(num_classes, len(colormap))):
            mask = (pred == class_id)
            colored[mask] = colormap[class_id]
        
        logger.debug(f"âœ… ì¸ì²´ íŒŒì‹± í›„ì²˜ë¦¬ ì™„ë£Œ: {num_classes}ê°œ í´ë˜ìŠ¤")
        return colored
        
    except Exception as e:
        logger.error(f"âŒ ì¸ì²´ íŒŒì‹± í›„ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        return output

def postprocess_pose_keypoints(output: Any, confidence_threshold: float = 0.3) -> Dict[str, Any]:
    """í¬ì¦ˆ í‚¤í¬ì¸íŠ¸ í›„ì²˜ë¦¬"""
    try:
        result = {
            "keypoints": [],
            "connections": [],
            "valid_keypoints": 0,
            "confidence_scores": []
        }
        
        if not NUMPY_AVAILABLE:
            logger.warning("âš ï¸ NumPy í•„ìš”")
            return result
        
        # OpenPose í‚¤í¬ì¸íŠ¸ ì—°ê²° ì •ë³´ (COCO í¬ë§·)
        connections = [
            (0, 1), (1, 2), (2, 3), (3, 4),     # ë¨¸ë¦¬
            (1, 5), (5, 6), (6, 7),             # ì™¼íŒ”
            (1, 8), (8, 9), (9, 10),            # ì˜¤ë¥¸íŒ”
            (1, 11), (11, 12), (12, 13),        # ì™¼ë‹¤ë¦¬
            (1, 14), (14, 15), (15, 16)         # ì˜¤ë¥¸ë‹¤ë¦¬
        ]
        
        # ì¶œë ¥ì„ numpy arrayë¡œ ë³€í™˜
        if TORCH_AVAILABLE and hasattr(output, 'cpu'):
            heatmaps = output.cpu().numpy()
        elif hasattr(output, 'shape'):
            heatmaps = output
        else:
            logger.warning("âš ï¸ ì§€ì›í•˜ì§€ ì•ŠëŠ” ì¶œë ¥ íƒ€ì…")
            return result
        
        # ì°¨ì› ì¡°ì •
        if heatmaps.ndim == 4:  # (N, C, H, W)
            heatmaps = heatmaps.squeeze(0)
        
        num_keypoints = min(heatmaps.shape[0], 18)  # OpenPose 18 í‚¤í¬ì¸íŠ¸
        height, width = heatmaps.shape[1], heatmaps.shape[2]
        
        # ê° í‚¤í¬ì¸íŠ¸ ìœ„ì¹˜ ì°¾ê¸°
        keypoints = []
        confidence_scores = []
        
        for i in range(num_keypoints):
            heatmap = heatmaps[i]
            
            # ìµœëŒ€ê°’ ìœ„ì¹˜ ì°¾ê¸°
            max_val = np.max(heatmap)
            if max_val > confidence_threshold:
                max_idx = np.unravel_index(np.argmax(heatmap), heatmap.shape)
                y, x = max_idx
                
                # ì´ë¯¸ì§€ ì¢Œí‘œë¡œ ë³€í™˜
                keypoints.append((x, y, max_val))
                confidence_scores.append(max_val)
            else:
                keypoints.append((0, 0, 0))
                confidence_scores.append(0.0)
        
        # ìœ íš¨í•œ ì—°ê²°ë§Œ í•„í„°ë§
        valid_connections = []
        for conn in connections:
            if (conn[0] < len(keypoints) and conn[1] < len(keypoints) and 
                keypoints[conn[0]][2] > confidence_threshold and 
                keypoints[conn[1]][2] > confidence_threshold):
                valid_connections.append(conn)
        
        result.update({
            "keypoints": keypoints,
            "connections": valid_connections,
            "valid_keypoints": sum(1 for kp in keypoints if kp[2] > confidence_threshold),
            "confidence_scores": confidence_scores
        })
        
        logger.debug(f"âœ… í¬ì¦ˆ í‚¤í¬ì¸íŠ¸ í›„ì²˜ë¦¬ ì™„ë£Œ: {result['valid_keypoints']}ê°œ ìœ íš¨ í‚¤í¬ì¸íŠ¸")
        return result
        
    except Exception as e:
        logger.error(f"âŒ í¬ì¦ˆ í‚¤í¬ì¸íŠ¸ í›„ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        return result

def create_pose_visualization(image: Any, keypoints_result: Dict[str, Any]) -> Any:
    """í¬ì¦ˆ í‚¤í¬ì¸íŠ¸ ì‹œê°í™”"""
    try:
        if not PIL_AVAILABLE:
            logger.warning("âš ï¸ PIL í•„ìš”")
            return image
        
        # PIL Imageë¡œ ë³€í™˜
        if hasattr(image, 'save'):  # ì´ë¯¸ PIL Image
            vis_image = image.copy()
        elif NUMPY_AVAILABLE and hasattr(image, 'shape'):  # NumPy array
            vis_image = Image.fromarray(image.astype(np.uint8))
        elif TORCH_AVAILABLE and hasattr(image, 'cpu'):  # PyTorch tensor
            vis_image = tensor_to_pil(image)
        else:
            logger.warning("âš ï¸ ì§€ì›í•˜ì§€ ì•ŠëŠ” ì´ë¯¸ì§€ íƒ€ì…")
            return image
        
        draw = ImageDraw.Draw(vis_image)
        
        keypoints = keypoints_result.get("keypoints", [])
        connections = keypoints_result.get("connections", [])
        
        # ì—°ê²°ì„  ê·¸ë¦¬ê¸°
        for conn in connections:
            if conn[0] < len(keypoints) and conn[1] < len(keypoints):
                pt1 = keypoints[conn[0]]
                pt2 = keypoints[conn[1]]
                
                if pt1[2] > 0 and pt2[2] > 0:  # ìœ íš¨í•œ í‚¤í¬ì¸íŠ¸ë“¤ë§Œ
                    draw.line([pt1[0], pt1[1], pt2[0], pt2[1]], fill=(0, 255, 0), width=3)
        
        # í‚¤í¬ì¸íŠ¸ ê·¸ë¦¬ê¸°
        for i, (x, y, conf) in enumerate(keypoints):
            if conf > 0:
                # ì‹ ë¢°ë„ì— ë”°ë¥¸ ìƒ‰ìƒ ê²°ì •
                color = (255, int(255 * conf), 0)  # ë¹¨ê°•-ë…¸ë‘ ê·¸ë¼ë°ì´ì…˜
                radius = 5
                
                # ì› ê·¸ë¦¬ê¸°
                draw.ellipse([x-radius, y-radius, x+radius, y+radius], fill=color, outline=(0, 0, 0))
        
        logger.debug("âœ… í¬ì¦ˆ ì‹œê°í™” ì™„ë£Œ")
        return vis_image
        
    except Exception as e:
        logger.error(f"âŒ í¬ì¦ˆ ì‹œê°í™” ì‹¤íŒ¨: {e}")
        return image

# ==============================================
# ğŸ”¥ ëª¨ë“ˆ ì •ë³´ ë° ë‚´ë³´ë‚´ê¸°
# ==============================================

__version__ = "1.0.0"
__author__ = "MyCloset AI Team"
__description__ = "ì´ë¯¸ì§€ ì²˜ë¦¬ í•¨ìˆ˜ë“¤ - model_loader.pyì—ì„œ ë¶„ë¦¬ (ì™„ì „íŒ)"

__all__ = [
    # ê¸°ë³¸ ì „ì²˜ë¦¬ í•¨ìˆ˜ë“¤
    'preprocess_image',
    'postprocess_segmentation',
    
    # íŠ¹í™” ì „ì²˜ë¦¬ í•¨ìˆ˜ë“¤
    'preprocess_pose_input',
    'preprocess_human_parsing_input',
    'preprocess_cloth_segmentation_input',
    'preprocess_virtual_fitting_input',
    
    # ì´ë¯¸ì§€ ë³€í™˜ í•¨ìˆ˜ë“¤
    'tensor_to_pil',
    'pil_to_tensor',
    'resize_image',
    'normalize_image',
    'denormalize_image',
    'create_batch',
    
    # Base64 ë³€í™˜ í•¨ìˆ˜ë“¤
    'image_to_base64',
    'base64_to_image',
    'numpy_to_base64',
    'base64_to_numpy',
    
    # ì´ë¯¸ì§€ í’ˆì§ˆ í–¥ìƒ í•¨ìˆ˜ë“¤
    'enhance_image_contrast',
    'enhance_image_brightness',
    'enhance_image_sharpness',
    'enhance_image_color',
    'apply_gaussian_blur',
    'apply_unsharp_mask',
    'apply_edge_enhance',
    
    # ê³ ê¸‰ ì²˜ë¦¬ í•¨ìˆ˜ë“¤
    'apply_clahe_enhancement',
    'remove_background_simple',
    'detect_dominant_colors',
    'calculate_image_similarity',
    
    # ê²€ì¦ ë° ë¶„ì„ í•¨ìˆ˜ë“¤
    'validate_image_format',
    'get_image_statistics',
    'detect_image_artifacts',
    
    # ë©”ëª¨ë¦¬ ê´€ë¦¬ í•¨ìˆ˜ë“¤
    'cleanup_image_memory',
    'estimate_memory_usage',
    'optimize_image_memory',
    
    # ì´ë¯¸ì§€ ë³€í™˜ ë° í¬ë§· í•¨ìˆ˜ë“¤
    'convert_image_format',
    'save_image',
    'load_image',
    
    # ì‹œê°í™” ë° ë””ë²„ê¹… í•¨ìˆ˜ë“¤
    'create_image_grid',
    'add_text_to_image',
    'create_comparison_image',
    
    # Stepë³„ íŠ¹í™” ì²˜ë¦¬ í•¨ìˆ˜ë“¤
    'postprocess_human_parsing',
    'postprocess_pose_keypoints',
    'create_pose_visualization',
    
    # ìƒìˆ˜ë“¤
    'NUMPY_AVAILABLE',
    'PIL_AVAILABLE',
    'CV2_AVAILABLE',
    'TORCH_AVAILABLE'
]

logger.info(f"ğŸ–¼ï¸ ì´ë¯¸ì§€ ì²˜ë¦¬ ëª¨ë“ˆ v{__version__} ë¡œë“œ ì™„ë£Œ (ì™„ì „íŒ)")
logger.info(f"ğŸ“¦ ì‚¬ìš© ê°€ëŠ¥í•œ í•¨ìˆ˜: {len(__all__)}ê°œ")
logger.info(f"âš¡ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì§€ì›:")
logger.info(f"   - NumPy: {'âœ…' if NUMPY_AVAILABLE else 'âŒ'}")
logger.info(f"   - PIL/Pillow: {'âœ…' if PIL_AVAILABLE else 'âŒ'}")
logger.info(f"   - OpenCV: {'âœ…' if CV2_AVAILABLE else 'âŒ'}")
logger.info(f"   - PyTorch: {'âœ…' if TORCH_AVAILABLE else 'âŒ'}")

# ==============================================
# ğŸ”¥ ì‚¬ìš© ì˜ˆì‹œ (ì£¼ì„)
# ==============================================

"""
ğŸ¯ ì‚¬ìš© ì˜ˆì‹œ:

# 1. ê¸°ë³¸ ì´ë¯¸ì§€ ì „ì²˜ë¦¬
from backend.app.ai_pipeline.utils.image_processing import preprocess_image

processed = preprocess_image(
    image='path/to/image.jpg',
    target_size=(512, 512),
    normalize=True,
    to_tensor=True
)

# 2. ì„¸ê·¸ë©˜í…Œì´ì…˜ í›„ì²˜ë¦¬
from backend.app.ai_pipeline.utils.image_processing import postprocess_segmentation

binary_mask = postprocess_segmentation(model_output, threshold=0.5)

# 3. í…ì„œ â†” PIL ë³€í™˜
from backend.app.ai_pipeline.utils.image_processing import tensor_to_pil, pil_to_tensor

pil_image = tensor_to_pil(tensor)
tensor = pil_to_tensor(pil_image, device='mps')

# 4. Base64 ë³€í™˜
from backend.app.ai_pipeline.utils.image_processing import image_to_base64, base64_to_image

base64_str = image_to_base64(image, format='JPEG', quality=95)
image = base64_to_image(base64_str)

# 5. ë°°ì¹˜ ìƒì„±
from backend.app.ai_pipeline.utils.image_processing import create_batch

batch_tensor = create_batch([image1, image2, image3], device='mps')

# 6. ì´ë¯¸ì§€ í–¥ìƒ
from backend.app.ai_pipeline.utils.image_processing import enhance_image_contrast

enhanced = enhance_image_contrast(image, factor=1.2)

# 7. ê³ ê¸‰ ì²˜ë¦¬
from backend.app.ai_pipeline.utils.image_processing import apply_clahe_enhancement, detect_dominant_colors

enhanced = apply_clahe_enhancement(image, clip_limit=2.0)
colors = detect_dominant_colors(image, k=5)

# 8. Stepë³„ íŠ¹í™” ì²˜ë¦¬
from backend.app.ai_pipeline.utils.image_processing import postprocess_human_parsing, create_pose_visualization

colored_parsing = postprocess_human_parsing(parsing_output, num_classes=20)
pose_vis = create_pose_visualization(image, keypoints_result)

# 9. ì´ë¯¸ì§€ ì €ì¥ ë° ë¡œë“œ
from backend.app.ai_pipeline.utils.image_processing import save_image, load_image

save_image(image, 'output.jpg', quality=95)
loaded_image = load_image('input.jpg', target_format='RGB')

# 10. ì‹œê°í™”
from backend.app.ai_pipeline.utils.image_processing import create_image_grid, create_comparison_image

grid = create_image_grid([img1, img2, img3, img4], grid_size=(2, 2))
comparison = create_comparison_image(original, processed, ('Before', 'After'))
"""image, 'resize'):  # PIL Image
            logger.debug("PIL Image ì²˜ë¦¬ ì¤‘...")
            image = image.resize(target_size, Image.Resampling.LANCZOS if hasattr(Image, 'Resampling') else Image.LANCZOS)
            
            if NUMPY_AVAILABLE:
                img_array = np.array(image).astype(np.float32)
                logger.debug(f"PIL â†’ NumPy ë³€í™˜: {img_array.shape}")
            else:
                # NumPy ì—†ëŠ” ê²½ìš° ìˆ˜ë™ ë³€í™˜
                width, height = image.size
                img_array = []
                for y in range(height):
                    row = []
                    for x in range(width):
                        pixel = image.getpixel((x, y))
                        if isinstance(pixel, int):  # ê·¸ë ˆì´ìŠ¤ì¼€ì¼
                            row.append([pixel, pixel, pixel])
                        else:  # RGB
                            row.append(list(pixel))
                    img_array.append(row)
                logger.debug("PIL â†’ ë¦¬ìŠ¤íŠ¸ ë³€í™˜ ì™„ë£Œ")
        
        # 3. OpenCV/NumPy ì²˜ë¦¬
        elif CV2_AVAILABLE and NUMPY_AVAILABLE and hasattr(image, 'shape'):  # OpenCV/numpy array
            logger.debug(f"OpenCV/NumPy ë°°ì—´ ì²˜ë¦¬ ì¤‘: {image.shape}")
            if len(image.shape) == 3 and image.shape[2] == 3:
                # RGB ì´ë¯¸ì§€
                img_array = cv2.resize(image, target_size).astype(np.float32)
            elif len(image.shape) == 2:
                # ê·¸ë ˆì´ìŠ¤ì¼€ì¼
                img_array = cv2.resize(image, target_size)
                img_array = np.stack([img_array] * 3, axis=-1).astype(np.float32)
            else:
                raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì´ë¯¸ì§€ í˜•íƒœ: {image.shape}")
        
        # 4. í´ë°± ì²˜ë¦¬
        else:
            logger.warning("âš ï¸ í´ë°± ì²˜ë¦¬ - ê¸°ë³¸ í¬ê¸°ì˜ ì œë¡œ ë°°ì—´ ìƒì„±")
            if NUMPY_AVAILABLE:
                img_array = np.zeros((target_size[1], target_size[0], 3), dtype=np.float32)
            else:
                img_array = [[[0.0, 0.0, 0.0] for _ in range(target_size[0])] for _ in range(target_size[1])]
        
        # 5. ì •ê·œí™”
        if normalize:
            logger.debug("ì´ë¯¸ì§€ ì •ê·œí™” ì ìš©")
            if NUMPY_AVAILABLE and hasattr(img_array, 'dtype'):
                if img_array.max() > 1.0:
                    img_array = img_array / 255.0
            elif isinstance(img_array, list):
                # ë¦¬ìŠ¤íŠ¸ í˜•íƒœì¸ ê²½ìš°
                for i, row in enumerate(img_array):
                    for j, pixel in enumerate(row):
                        img_array[i][j] = [p/255.0 if p > 1.0 else p for p in pixel]
        
        # 6. PyTorch tensor ë³€í™˜
        if to_tensor and TORCH_AVAILABLE:
            logger.debug("PyTorch í…ì„œë¡œ ë³€í™˜")
            if NUMPY_AVAILABLE and hasattr(img_array, 'shape'):
                # numpy array â†’ tensor
                img_tensor = torch.from_numpy(img_array).permute(2, 0, 1).unsqueeze(0)  # NHWC â†’ NCHW
                img_tensor = img_tensor.to(device)
                logger.debug(f"âœ… í…ì„œ ë³€í™˜ ì™„ë£Œ: {img_tensor.shape}, device: {device}")
                return img_tensor
            else:
                # ë¦¬ìŠ¤íŠ¸ â†’ tensor
                if isinstance(img_array, list):
                    height = len(img_array)
                    width = len(img_array[0]) if height > 0 else target_size[0]
                    channels = len(img_array[0][0]) if height > 0 and width > 0 else 3
                    
                    tensor_data = torch.zeros(1, channels, height, width)
                    for h in range(height):
                        for w in range(width):
                            for c in range(channels):
                                if h < len(img_array) and w < len(img_array[h]) and c < len(img_array[h][w]):
                                    tensor_data[0, c, h, w] = img_array[h][w][c]
                    
                    tensor_data = tensor_data.to(device)
                    logger.debug(f"âœ… ë¦¬ìŠ¤íŠ¸â†’í…ì„œ ë³€í™˜ ì™„ë£Œ: {tensor_data.shape}")
                    return tensor_data
        
        # 7. NumPy ë°°ì—´ ë˜ëŠ” ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜
        logger.debug(f"ìµœì¢… ë°˜í™˜: {type(img_array)}")
        return img_array
            
    except Exception as e:
        logger.error(f"âŒ ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        # í´ë°±: ê¸°ë³¸ í¬ê¸°ì˜ ì œë¡œ ë°ì´í„°
        if to_tensor and TORCH_AVAILABLE:
            return torch.zeros(1, 3, target_size[1], target_size[0], device=device)
        elif NUMPY_AVAILABLE:
            return np.zeros((target_size[1], target_size[0], 3), dtype=np.float32)
        else:
            return [[[0.0, 0.0, 0.0] for _ in range(target_size[0])] for _ in range(target_size[1])]

def postprocess_segmentation(output: Any, threshold: float = 0.5) -> Any:
    """
    ì„¸ê·¸ë©˜í…Œì´ì…˜ ê²°ê³¼ í›„ì²˜ë¦¬ í•¨ìˆ˜ - ì™„ì „ êµ¬í˜„
    
    Args:
        output: ëª¨ë¸ ì¶œë ¥ (tensor, numpy array, ë˜ëŠ” ë¦¬ìŠ¤íŠ¸)
        threshold: ì´ì§„í™” ì„ê³„ê°’
    
    Returns:
        í›„ì²˜ë¦¬ëœ ë§ˆìŠ¤í¬ (0-255 ê°’ì˜ ì´ë¯¸ì§€)
    """
    try:
        logger.debug(f"ì„¸ê·¸ë©˜í…Œì´ì…˜ í›„ì²˜ë¦¬ ì‹œì‘: {type(output)}")
        
        # 1. PyTorch tensor ì²˜ë¦¬
        if TORCH_AVAILABLE and hasattr(output, 'cpu'):
            output_np = output.cpu().numpy()
            logger.debug("PyTorch í…ì„œ â†’ NumPy ë³€í™˜")
        elif TORCH_AVAILABLE and hasattr(output, 'detach'):
            output_np = output.detach().cpu().numpy()
            logger.debug("PyTorch í…ì„œ (gradient) â†’ NumPy ë³€í™˜")
        elif NUMPY_AVAILABLE and hasattr(output, 'shape'):
            output_np = output
            logger.debug("NumPy ë°°ì—´ ì‚¬ìš©")
        else:
            # ë¦¬ìŠ¤íŠ¸ë‚˜ ê¸°íƒ€ í˜•íƒœ
            output_np = output
            logger.debug("ë¦¬ìŠ¤íŠ¸/ê¸°íƒ€ í˜•íƒœ ì²˜ë¦¬")
        
        # 2. ì°¨ì› ì¡°ì •
        if NUMPY_AVAILABLE and hasattr(output_np, 'shape'):
            logger.debug(f"ì›ë³¸ shape: {output_np.shape}")
            
            # ë°°ì¹˜ ì°¨ì› ì œê±°
            if output_np.ndim == 4:  # (N, C, H, W)
                output_np = output_np.squeeze(0)
                logger.debug(f"ë°°ì¹˜ ì°¨ì› ì œê±°: {output_np.shape}")
            
            if output_np.ndim == 3:  # (C, H, W)
                if output_np.shape[0] == 1:  # ë‹¨ì¼ ì±„ë„
                    output_np = output_np.squeeze(0)
                    logger.debug(f"ì±„ë„ ì°¨ì› ì œê±°: {output_np.shape}")
                else:  # ë‹¤ì¤‘ ì±„ë„ì¸ ê²½ìš° ì²« ë²ˆì§¸ ì±„ë„ ì‚¬ìš©
                    output_np = output_np[0]
                    logger.debug(f"ì²« ë²ˆì§¸ ì±„ë„ ì„ íƒ: {output_np.shape}")
            
            # 3. ì´ì§„í™” ì ìš©
            binary_mask = (output_np > threshold).astype(np.uint8) * 255
            logger.debug(f"ì´ì§„í™” ì™„ë£Œ: {binary_mask.shape}, ê°’ ë²”ìœ„: {binary_mask.min()}-{binary_mask.max()}")
            
            return binary_mask
        
        else:
            # NumPy ì—†ëŠ” ê²½ìš° ë¦¬ìŠ¤íŠ¸ ì²˜ë¦¬
            logger.debug("ë¦¬ìŠ¤íŠ¸ ê¸°ë°˜ í›„ì²˜ë¦¬")
            
            def process_value(val):
                if isinstance(val, (list, tuple)):
                    # ì¤‘ì²© êµ¬ì¡°ì¸ ê²½ìš° ì¬ê·€ì ìœ¼ë¡œ ì²˜ë¦¬
                    return [process_value(v) for v in val]
                else:
                    # ë‹¨ì¼ ê°’ ì²˜ë¦¬
                    return 255 if float(val) > threshold else 0
            
            if isinstance(output, (list, tuple)):
                # ì¤‘ì²© ë¦¬ìŠ¤íŠ¸ êµ¬ì¡° ì²˜ë¦¬
                if len(output) > 0 and isinstance(output[0], (list, tuple)):
                    # 2D ì´ìƒ êµ¬ì¡°
                    if len(output[0]) > 0 and isinstance(output[0][0], (list, tuple)):
                        # 3D êµ¬ì¡° (ì²« ë²ˆì§¸ ì±„ë„ ì‚¬ìš©)
                        output = output[0] if isinstance(output[0][0], (list, tuple)) else output
                    
                    result = [[255 if float(pixel) > threshold else 0 for pixel in row] for row in output]
                    logger.debug("2D ë¦¬ìŠ¤íŠ¸ í›„ì²˜ë¦¬ ì™„ë£Œ")
                    return result
                else:
                    # 1D êµ¬ì¡°
                    result = [255 if float(val) > threshold else 0 for val in output]
                    logger.debug("1D ë¦¬ìŠ¤íŠ¸ í›„ì²˜ë¦¬ ì™„ë£Œ")
                    return result
            else:
                # ë‹¨ì¼ ê°’
                result = 255 if float(output) > threshold else 0
                logger.debug("ë‹¨ì¼ ê°’ í›„ì²˜ë¦¬ ì™„ë£Œ")
                return result
            
    except Exception as e:
        logger.error(f"âŒ ì„¸ê·¸ë©˜í…Œì´ì…˜ í›„ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        # í´ë°±: ê¸°ë³¸ í¬ê¸°ì˜ ì œë¡œ ë§ˆìŠ¤í¬
        if NUMPY_AVAILABLE:
            return np.zeros((512, 512), dtype=np.uint8)
        else:
            return [[0 for _ in range(512)] for _ in range(512)]

# ==============================================
# ğŸ”¥ íŠ¹í™”ëœ ì „ì²˜ë¦¬ í•¨ìˆ˜ë“¤
# ==============================================

def preprocess_pose_input(image: Any, target_size: Tuple[int, int] = (368, 368)) -> Any:
    """í¬ì¦ˆ ì¶”ì •ìš© ì´ë¯¸ì§€ ì „ì²˜ë¦¬"""
    return preprocess_image(image, target_size, normalize=True, to_tensor=True)

def preprocess_human_parsing_input(image: Any, target_size: Tuple[int, int] = (512, 512)) -> Any:
    """ì¸ì²´ íŒŒì‹±ìš© ì´ë¯¸ì§€ ì „ì²˜ë¦¬"""
    return preprocess_image(image, target_size, normalize=True, to_tensor=True)

def preprocess_cloth_segmentation_input(image: Any, target_size: Tuple[int, int] = (320, 320)) -> Any:
    """ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ìš© ì´ë¯¸ì§€ ì „ì²˜ë¦¬"""
    return preprocess_image(image, target_size, normalize=True, to_tensor=True)

def preprocess_virtual_fitting_input(person_img: Any, cloth_img: Any, target_size: Tuple[int, int] = (512, 512)) -> Tuple[Any, Any]:
    """ê°€ìƒ í”¼íŒ…ìš© ì´ë¯¸ì§€ ì „ì²˜ë¦¬"""
    person_tensor = preprocess_image(person_img, target_size, normalize=True, to_tensor=True)
    cloth_tensor = preprocess_image(cloth_img, target_size, normalize=True, to_tensor=True)
    return person_tensor, cloth_tensor

# ==============================================
# ğŸ”¥ ì´ë¯¸ì§€ ë³€í™˜ í•¨ìˆ˜ë“¤
# ==============================================

def tensor_to_pil(tensor: Any) -> Any:
    """
    í…ì„œë¥¼ PIL ì´ë¯¸ì§€ë¡œ ë³€í™˜
    
    Args:
        tensor: PyTorch tensor (C, H, W) ë˜ëŠ” (N, C, H, W)
    
    Returns:
        PIL Image ë˜ëŠ” numpy array
    """
    try:
        logger.debug(f"í…ì„œâ†’PIL ë³€í™˜ ì‹œì‘: {type(tensor)}")
        
        if not TORCH_AVAILABLE:
            logger.warning("âš ï¸ PyTorch ì—†ìŒ, ì›ë³¸ ë°˜í™˜")
            return tensor
        
        # tensor ì²˜ë¦¬
        if hasattr(tensor, 'dim'):
            logger.debug(f"í…ì„œ ì°¨ì›: {tensor.dim()}, í¬ê¸°: {tensor.shape}")
            
            if tensor.dim() == 4:  # (N, C, H, W)
                tensor = tensor.squeeze(0)
                logger.debug(f"ë°°ì¹˜ ì°¨ì› ì œê±°: {tensor.shape}")
            
            if tensor.dim() == 3:  # (C, H, W)
                tensor = tensor.permute(1, 2, 0)  # (H, W, C)
                logger.debug(f"ì°¨ì› ìˆœì„œ ë³€ê²½: {tensor.shape}")
            
            # CPUë¡œ ì´ë™
            if hasattr(tensor, 'cpu'):
                tensor = tensor.cpu()
                logger.debug("CPUë¡œ ì´ë™")
            
            # numpy ë³€í™˜
            if hasattr(tensor, 'numpy'):
                tensor_np = tensor.numpy()
                logger.debug("NumPy ë³€í™˜ ì™„ë£Œ")
            elif hasattr(tensor, 'detach'):
                tensor_np = tensor.detach().numpy()
                logger.debug("Detach í›„ NumPy ë³€í™˜ ì™„ë£Œ")
            else:
                tensor_np = tensor
        else:
            tensor_np = tensor
        
        # ê°’ ë²”ìœ„ ì¡°ì •
        if NUMPY_AVAILABLE and hasattr(tensor_np, 'dtype'):
            logger.debug(f"ê°’ ë²”ìœ„ ì¡°ì •: dtype={tensor_np.dtype}, ë²”ìœ„={tensor_np.min():.3f}-{tensor_np.max():.3f}")
            
            if tensor_np.dtype != np.uint8:
                # 0-1 ë²”ìœ„ë¥¼ 0-255ë¡œ ë³€í™˜
                if tensor_np.max() <= 1.0:
                    tensor_np = (tensor_np * 255).astype(np.uint8)
                    logger.debug("0-1 â†’ 0-255 ë³€í™˜")
                else:
                    tensor_np = np.clip(tensor_np, 0, 255).astype(np.uint8)
                    logger.debug("í´ë¦¬í•‘ í›„ uint8 ë³€í™˜")
        
        # PIL Image ìƒì„±
        if PIL_AVAILABLE:
            try:
                if NUMPY_AVAILABLE and hasattr(tensor_np, 'shape'):
                    if len(tensor_np.shape) == 3 and tensor_np.shape[2] == 3:
                        pil_image = Image.fromarray(tensor_np, 'RGB')
                        logger.debug("âœ… PIL RGB ì´ë¯¸ì§€ ìƒì„± ì™„ë£Œ")
                        return pil_image
                    elif len(tensor_np.shape) == 2:
                        pil_image = Image.fromarray(tensor_np, 'L')
                        logger.debug("âœ… PIL ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ì´ë¯¸ì§€ ìƒì„± ì™„ë£Œ")
                        return pil_image
                    else:
                        logger.warning(f"âš ï¸ ì§€ì›í•˜ì§€ ì•ŠëŠ” shape: {tensor_np.shape}")
                        return tensor_np
                else:
                    # NumPy ì—†ëŠ” ê²½ìš° ê¸°ë³¸ ì²˜ë¦¬
                    logger.debug("NumPy ì—†ìŒ, ì›ë³¸ ë°˜í™˜")
                    return tensor_np
            except Exception as e:
                logger.error(f"âŒ PIL ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨: {e}")
                return tensor_np
        else:
            logger.warning("âš ï¸ PIL ì—†ìŒ, NumPy ë°°ì—´ ë°˜í™˜")
            return tensor_np
            
    except Exception as e:
        logger.error(f"âŒ tensorâ†’PIL ë³€í™˜ ì‹¤íŒ¨: {e}")
        return None

def pil_to_tensor(image: Any, device: str = "mps") -> Any:
    """
    PIL ì´ë¯¸ì§€ë¥¼ í…ì„œë¡œ ë³€í™˜
    
    Args:
        image: PIL Image ë˜ëŠ” numpy array
        device: ëŒ€ìƒ ë””ë°”ì´ìŠ¤
    
    Returns:
        PyTorch tensor (N, C, H, W)
    """
    try:
        logger.debug(f"PILâ†’í…ì„œ ë³€í™˜ ì‹œì‘: {type(image)}")
        
        if not TORCH_AVAILABLE:
            logger.warning("âš ï¸ PyTorch ì—†ìŒ, ì›ë³¸ ë°˜í™˜")
            return image
        
        # PIL Image ì²˜ë¦¬
        if hasattr(image, 'size'):  # PIL Image
            width, height = image.size
            logger.debug(f"PIL ì´ë¯¸ì§€ í¬ê¸°: {width}x{height}")
            
            if NUMPY_AVAILABLE:
                img_array = np.array(image).astype(np.float32) / 255.0
                
                if len(img_array.shape) == 3:  # RGB
                    tensor = torch.from_numpy(img_array).permute(2, 0, 1).unsqueeze(0)  # (H,W,C) â†’ (N,C,H,W)
                else:  # ê·¸ë ˆì´ìŠ¤ì¼€ì¼
                    tensor = torch.from_numpy(img_array).unsqueeze(0).unsqueeze(0)  # (H,W) â†’ (N,C,H,W)
                
                tensor = tensor.to(device)
                logger.debug(f"âœ… PILâ†’í…ì„œ ë³€í™˜ ì™„ë£Œ: {tensor.shape}, device: {device}")
                return tensor
            else:
                # NumPy ì—†ëŠ” ê²½ìš° ìˆ˜ë™ ë³€í™˜
                if image.mode == 'RGB':
                    channels = 3
                elif image.mode == 'L':
                    channels = 1
                else:
                    channels = 3
                    image = image.convert('RGB')
                
                tensor = torch.zeros(1, channels, height, width, device=device)
                
                for y in range(height):
                    for x in range(width):
                        pixel = image.getpixel((x, y))
                        if isinstance(pixel, int):  # ê·¸ë ˆì´ìŠ¤ì¼€ì¼
                            tensor[0, 0, y, x] = pixel / 255.0
                        else:  # RGB
                            for c, val in enumerate(pixel[:channels]):
                                tensor[0, c, y, x] = val / 255.0
                
                logger.debug(f"âœ… ìˆ˜ë™ PILâ†’í…ì„œ ë³€í™˜ ì™„ë£Œ: {tensor.shape}")
                return tensor
        
        # numpy array ì²˜ë¦¬
        elif NUMPY_AVAILABLE and hasattr(image, 'shape'):
            logger.debug(f"NumPy ë°°ì—´ ì²˜ë¦¬: {image.shape}")
            
            img_array = image.astype(np.float32)
            if img_array.max() > 1.0:
                img_array = img_array / 255.0
            
            if len(image.shape) == 3:  # (H, W, C)
                tensor = torch.from_numpy(img_array).permute(2, 0, 1).unsqueeze(0)
            elif len(image.shape) == 2:  # (H, W) ê·¸ë ˆì´ìŠ¤ì¼€ì¼
                tensor = torch.from_numpy(img_array).unsqueeze(0).unsqueeze(0)  # (1, 1, H, W)
            else:
                raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ë°°ì—´ ì°¨ì›: {image.shape}")
            
            tensor = tensor.to(device)
            logger.debug(f"âœ… NumPyâ†’í…ì„œ ë³€í™˜ ì™„ë£Œ: {tensor.shape}")
            return tensor
        
        # í´ë°±: ê¸°ë³¸ í…ì„œ
        logger.warning("âš ï¸ ë³€í™˜ ì‹¤íŒ¨, ê¸°ë³¸ í…ì„œ ë°˜í™˜")
        return torch.zeros(1, 3, 512, 512, device=device)
            
    except Exception as e:
        logger.error(f"âŒ PILâ†’tensor ë³€í™˜ ì‹¤íŒ¨: {e}")
        if TORCH_AVAILABLE:
            return torch.zeros(1, 3, 512, 512, device=device)
        else:
            return None

# ==============================================
# ğŸ”¥ ì´ë¯¸ì§€ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
# ==============================================

def resize_image(image: Any, target_size: Tuple[int, int]) -> Any:
    """ì´ë¯¸ì§€ í¬ê¸° ì¡°ì •"""
    try:
        logger.debug(f"ì´ë¯¸ì§€ í¬ê¸° ì¡°ì •: {type(image)} â†’ {target_size}")
        
        if hasattr(image, 'resize'):  # PIL Image
            resized = image.resize(target_size, Image.Resampling.LANCZOS if hasattr(Image, 'Resampling') else Image.LANCZOS)
            logger.debug("âœ… PIL í¬ê¸° ì¡°ì • ì™„ë£Œ")
            return resized
        elif CV2_AVAILABLE and NUMPY_AVAILABLE and hasattr(image, 'shape'):
            resized = cv2.resize(image, target_size)
            logger.debug("âœ… OpenCV í¬ê¸° ì¡°ì • ì™„ë£Œ")
            return resized
        else:
            # ê¸°ë³¸ ì²˜ë¦¬ (í¬ê¸° ì¡°ì • ì—†ì´ ë°˜í™˜)
            logger.warning("âš ï¸ í¬ê¸° ì¡°ì • ë¶ˆê°€, ì›ë³¸ ë°˜í™˜")
            return image
    except Exception as e:
        logger.error(f"âŒ ì´ë¯¸ì§€ í¬ê¸° ì¡°ì • ì‹¤íŒ¨: {e}")
        return image

def normalize_image(image: Any, mean: Tuple[float, float, float] = (0.485, 0.456, 0.406), 
                   std: Tuple[float, float, float] = (0.229, 0.224, 0.225)) -> Any:
    """ì´ë¯¸ì§€ ì •ê·œí™” (ImageNet ê¸°ë³¸ê°’)"""
    try:
        logger.debug(f"ì´ë¯¸ì§€ ì •ê·œí™”: mean={mean}, std={std}")
        
        if TORCH_AVAILABLE and hasattr(image, 'dim'):
            # PyTorch tensor
            image_normalized = image.clone()
            if image_normalized.dim() == 4:  # (N, C, H, W)
                for i in range(3):
                    image_normalized[:, i, :, :] = (image_normalized[:, i, :, :] - mean[i]) / std[i]
            elif image_normalized.dim() == 3:  # (C, H, W)
                for i in range(3):
                    image_normalized[i, :, :] = (image_normalized[i, :, :] - mean[i]) / std[i]
            logger.debug("âœ… PyTorch í…ì„œ ì •ê·œí™” ì™„ë£Œ")
            return image_normalized
        elif NUMPY_AVAILABLE and hasattr(image, 'shape'):
            # numpy array
            image_normalized = image.astype(np.float32).copy()
            if len(image.shape) == 4:  # (N, H, W, C)
                for i in range(3):
                    image_normalized[:, :, :, i] = (image_normalized[:, :, :, i] - mean[i]) / std[i]
            elif len(image.shape) == 3:  # (H, W, C)
                for i in range(3):
                    image_normalized[:, :, i] = (image_normalized[:, :, i] - mean[i]) / std[i]
            logger.debug("âœ… NumPy ë°°ì—´ ì •ê·œí™” ì™„ë£Œ")
            return image_normalized
        else:
            logger.warning("âš ï¸ ì •ê·œí™” ì§€ì›í•˜ì§€ ì•ŠëŠ” íƒ€ì…, ì›ë³¸ ë°˜í™˜")
            return image
    except Exception as e:
        logger.error(f"âŒ ì´ë¯¸ì§€ ì •ê·œí™” ì‹¤íŒ¨: {e}")
        return image

def denormalize_image(image: Any, mean: Tuple[float, float, float] = (0.485, 0.456, 0.406), 
                     std: Tuple[float, float, float] = (0.229, 0.224, 0.225)) -> Any:
    """ì´ë¯¸ì§€ ì—­ì •ê·œí™”"""
    try:
        logger.debug(f"ì´ë¯¸ì§€ ì—­ì •ê·œí™”: mean={mean}, std={std}")
        
        if TORCH_AVAILABLE and hasattr(image, 'dim'):
            # PyTorch tensor
            image_denormalized = image.clone()
            if image_denormalized.dim() == 4:  # (N, C, H, W)
                for i in range(3):
                    image_denormalized[:, i, :, :] = image_denormalized[:, i, :, :] * std[i] + mean[i]
            elif image_denormalized.dim() == 3:  # (C, H, W)
                for i in range(3):
                    image_denormalized[i, :, :] = image_denormalized[i, :, :] * std[i] + mean[i]
            logger.debug("âœ… PyTorch í…ì„œ ì—­ì •ê·œí™” ì™„ë£Œ")
            return image_denormalized
        elif NUMPY_AVAILABLE and hasattr(image, 'shape'):
            # numpy array
            image_denormalized = image.astype(np.float32).copy()
            if len(image.shape) == 4:  # (N, H, W, C)
                for i in range(3):
                    image_denormalized[:, :, :, i] = image_denormalized[:, :, :, i] * std[i] + mean[i]
            elif len(image.shape) == 3:  # (H, W, C)
                for i in range(3):
                    image_denormalized[:, :, i] = image_denormalized[:, :, i] * std[i] + mean[i]
            logger.debug("âœ… NumPy ë°°ì—´ ì—­ì •ê·œí™” ì™„ë£Œ")
            return image_denormalized
        else:
            logger.warning("âš ï¸ ì—­ì •ê·œí™” ì§€ì›í•˜ì§€ ì•ŠëŠ” íƒ€ì…, ì›ë³¸ ë°˜í™˜")
            return image
    except Exception as e:
        logger.error(f"âŒ ì´ë¯¸ì§€ ì—­ì •ê·œí™” ì‹¤íŒ¨: {e}")
        return image

def create_batch(images: List[Any], device: str = "mps") -> Any:
    """ì´ë¯¸ì§€ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°°ì¹˜ë¡œ ë³€í™˜"""
    try:
        logger.debug(f"ë°°ì¹˜ ìƒì„±: {len(images)}ê°œ ì´ë¯¸ì§€ â†’ device: {device}")
        
        if not images:
            logger.warning("âš ï¸ ë¹ˆ ì´ë¯¸ì§€ ë¦¬ìŠ¤íŠ¸, ê¸°ë³¸ í…ì„œ ë°˜í™˜")
            if TORCH_AVAILABLE:
                return torch.zeros(1, 3, 512, 512, device=device)
            else:
                return []
        
        if TORCH_AVAILABLE:
            # ëª¨ë“  ì´ë¯¸ì§€ë¥¼ tensorë¡œ ë³€í™˜
            tensors = []
            for i, img in enumerate(images):
                logger.debug(f"ì´ë¯¸ì§€ {i+1}/{len(images)} ì²˜ë¦¬ ì¤‘...")
                
                if hasattr(img, 'dim'):  # ì´ë¯¸ tensor
                    if img.dim() == 3:  # (C, H, W)
                        tensors.append(img.unsqueeze(0))
                    else:
                        tensors.append(img)
                else:
                    # PIL ë˜ëŠ” numpy â†’ tensor
                    tensor = pil_to_tensor(img, device)
                    tensors.append(tensor)
            
            # ë°°ì¹˜ë¡œ ê²°í•©
            if tensors:
                batch = torch.cat(tensors, dim=0)
                batch = batch.to(device)
                logger.debug(f"âœ… ë°°ì¹˜ ìƒì„± ì™„ë£Œ: {batch.shape}")
                return batch
            else:
                logger.warning("âš ï¸ í…ì„œ ë³€í™˜ ì‹¤íŒ¨, ê¸°ë³¸ í…ì„œ ë°˜í™˜")
                return torch.zeros(1, 3, 512, 512, device=device)
        else:
            logger.warning("âš ï¸ PyTorch ì—†ìŒ, ì›ë³¸ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜")
            return images
            
    except Exception as e:
        logger.error(f"âŒ ë°°ì¹˜ ìƒì„± ì‹¤íŒ¨: {e}")
        if TORCH_AVAILABLE:
            return torch.zeros(len(images) if images else 1, 3, 512, 512, device=device)
        else:
            return images

# ==============================================
# ğŸ”¥ Base64 ë³€í™˜ í•¨ìˆ˜ë“¤
# ==============================================

def image_to_base64(image: Any, format: str = "JPEG", quality: int = 95) -> str:
    """ì´ë¯¸ì§€ë¥¼ Base64 ë¬¸ìì—´ë¡œ ë³€í™˜"""
    try:
        logger.debug(f"ì´ë¯¸ì§€â†’Base64 ë³€í™˜: format={format}, quality={quality}")
        
        if not PIL_AVAILABLE:
            logger.error("âŒ PIL í•„ìš”í•¨")
            return ""
        
        # PIL Imageë¡œ ë³€í™˜
        if hasattr(image, 'save'):  # ì´ë¯¸ PIL Image
            pil_image = image
        elif NUMPY_AVAILABLE and hasattr(image, 'shape'):  # NumPy array
            if image.dtype != np.uint8:
                if image.max() <= 1.0:
                    image = (image * 255).astype(np.uint8)
                else:
                    image = np.clip(image, 0, 255).astype(np.uint8)
            pil_image = Image.fromarray(image)
        elif TORCH_AVAILABLE and hasattr(image, 'cpu'):  # PyTorch tensor
            pil_image = tensor_to_pil(image)
        else:
            logger.error(f"âŒ ì§€ì›í•˜ì§€ ì•ŠëŠ” ì´ë¯¸ì§€ íƒ€ì…: {type(image)}")
            return ""
        
        # RGB ëª¨ë“œë¡œ ë³€í™˜
        if pil_image.mode != 'RGB':
            pil_image = pil_image.convert('RGB')
        
        # Base64 ë³€í™˜
        buffer = io.BytesIO()
        pil_image.save(buffer, format=format, quality=quality)
        img_str = base64.b64encode(buffer.getvalue()).decode()
        
        logger.debug(f"âœ… Base64 ë³€í™˜ ì™„ë£Œ: {len(img_str)} ë¬¸ì")
        return img_str
        
    except Exception as e:
        logger.error(f"âŒ ì´ë¯¸ì§€â†’Base64 ë³€í™˜ ì‹¤íŒ¨: {e}")
        return ""

def base64_to_image(base64_str: str) -> Any:
    """Base64 ë¬¸ìì—´ì„ ì´ë¯¸ì§€ë¡œ ë³€í™˜"""
    try:
        logger.debug(f"Base64â†’ì´ë¯¸ì§€ ë³€í™˜: {len(base64_str)} ë¬¸ì")
        
        if not PIL_AVAILABLE:
            logger.error("âŒ PIL í•„ìš”í•¨")
            return None
        
        # Base64 ë””ì½”ë”©
        img_data = base64.b64decode(base64_str)
        img_buffer = io.BytesIO(img_data)
        pil_image = Image.open(img_buffer).convert('RGB')
        
        logger.debug(f"âœ… Base64â†’ì´ë¯¸ì§€ ë³€í™˜ ì™„ë£Œ: {pil_image.size}")
        return pil_image
        
    except Exception as e:
        logger.error(f"âŒ Base64â†’ì´ë¯¸ì§€ ë³€í™˜ ì‹¤íŒ¨: {e}")
        return None

def numpy_to_base64(array: 'np.ndarray', format: str = "JPEG", quality: int = 95) -> str:
    """NumPy ë°°ì—´ì„ Base64ë¡œ ë³€í™˜"""
    try:
        if not NUMPY_AVAILABLE:
            logger.error("âŒ NumPy í•„ìš”í•¨")
            return ""
        
        return image_to_base64(array, format, quality)
        
    except Exception as e:
        logger.error(f"âŒ NumPyâ†’Base64 ë³€í™˜ ì‹¤íŒ¨: {e}")
        return ""

def base64_to_numpy(base64_str: str) -> Any:
    """Base64ë¥¼ NumPy ë°°ì—´ë¡œ ë³€í™˜"""
    try:
        if not NUMPY_AVAILABLE:
            logger.error("âŒ NumPy í•„ìš”í•¨")
            return None
        
        pil_image = base64_to_image(base64_str)
        if pil_image:
            return np.array(pil_image)
        else:
            return None
            
    except Exception as e:
        logger.error(f"âŒ Base64â†’NumPy ë³€í™˜ ì‹¤íŒ¨: {e}")
        return None

# ==============================================
# ğŸ”¥ ì´ë¯¸ì§€ í’ˆì§ˆ í–¥ìƒ í•¨ìˆ˜ë“¤
# ==============================================

def enhance_image_contrast(image: Any, factor: float = 1.2) -> Any:
    """ì´ë¯¸ì§€ ëŒ€ë¹„ í–¥ìƒ"""
    try:
        if PIL_AVAILABLE and hasattr(image, 'save'):
            enhancer = ImageEnhance.Contrast(image)
            enhanced = enhancer.enhance(factor)
            logger.debug(f"âœ… ëŒ€ë¹„ í–¥ìƒ ì™„ë£Œ: factor={factor}")
            return enhanced
        else:
            logger.warning("âš ï¸ PIL ì´ë¯¸ì§€ê°€ ì•„ë‹˜, ì›ë³¸ ë°˜í™˜")
            return image
    except Exception as e:
        logger.error(f"âŒ ëŒ€ë¹„ í–¥ìƒ ì‹¤íŒ¨: {e}")
        return image

def enhance_image_brightness(image: Any, factor: float = 1.1) -> Any:
    """ì´ë¯¸ì§€ ë°ê¸° í–¥ìƒ"""
    try:
        if PIL_AVAILABLE and hasattr(image, 'save'):
            enhancer = ImageEnhance.Brightness(image)
            enhanced = enhancer.enhance(factor)
            logger.debug(f"âœ… ë°ê¸° í–¥ìƒ ì™„ë£Œ: factor={factor}")
            return enhanced
        else:
            logger.warning("âš ï¸ PIL ì´ë¯¸ì§€ê°€ ì•„ë‹˜, ì›ë³¸ ë°˜í™˜")
            return image
    except Exception as e:
        logger.error(f"âŒ ë°ê¸° í–¥ìƒ ì‹¤íŒ¨: {e}")
        return image

def enhance_image_sharpness(image: Any, factor: float = 1.1) -> Any:
    """ì´ë¯¸ì§€ ì„ ëª…ë„ í–¥ìƒ"""
    try:
        if PIL_AVAILABLE and hasattr(image, 'save'):
            enhancer = ImageEnhance.Sharpness(image)
            enhanced = enhancer.enhance(factor)
            logger.debug(f"âœ… ì„ ëª…ë„ í–¥ìƒ ì™„ë£Œ: factor={factor}")
            return enhanced
        else:
            logger.warning("âš ï¸ PIL ì´ë¯¸ì§€ê°€ ì•„ë‹˜, ì›ë³¸ ë°˜í™˜")
            return image
    except Exception as e:
        logger.error(f"âŒ ì„ ëª…ë„ í–¥ìƒ ì‹¤íŒ¨: {e}")
        return image

def enhance_image_color(image: Any, factor: float = 1.1) -> Any:
    """ì´ë¯¸ì§€ ìƒ‰ìƒ í–¥ìƒ"""
    try:
        if PIL_AVAILABLE and hasattr(image, 'save'):
            enhancer = ImageEnhance.Color(image)
            enhanced = enhancer.enhance(factor)
            logger.debug(f"âœ… ìƒ‰ìƒ í–¥ìƒ ì™„ë£Œ: factor={factor}")
            return enhanced
        else:
            logger.warning("âš ï¸ PIL ì´ë¯¸ì§€ê°€ ì•„ë‹˜, ì›ë³¸ ë°˜í™˜")
            return image
    except Exception as e:
        logger.error(f"âŒ ìƒ‰ìƒ í–¥ìƒ ì‹¤íŒ¨: {e}")
        return image

def apply_gaussian_blur(image: Any, radius: float = 1.0) -> Any:
    """ê°€ìš°ì‹œì•ˆ ë¸”ëŸ¬ ì ìš©"""
    try:
        if PIL_AVAILABLE and hasattr(image, 'save'):
            blurred = image.filter(ImageFilter.GaussianBlur(radius=radius))
            logger.debug(f"âœ… ê°€ìš°ì‹œì•ˆ ë¸”ëŸ¬ ì ìš© ì™„ë£Œ: radius={radius}")
            return blurred
        else:
            logger.warning("âš ï¸ PIL ì´ë¯¸ì§€ê°€ ì•„ë‹˜, ì›ë³¸ ë°˜í™˜")
            return image
    except Exception as e:
        logger.error(f"âŒ ê°€ìš°ì‹œì•ˆ ë¸”ëŸ¬ ì ìš© ì‹¤íŒ¨: {e}")
        return image

def apply_unsharp_mask(image: Any, radius: float = 2.0, percent: int = 150, threshold: int = 3) -> Any:
    """ì–¸ìƒ¤í”„ ë§ˆìŠ¤í¬ ì ìš© (ì„ ëª…ë„ í–¥ìƒ)"""
    try:
        if PIL_AVAILABLE and hasattr(image, 'save'):
            # PILì˜ UnsharpMask í•„í„° ì‚¬ìš©
            unsharp = image.filter(ImageFilter.UnsharpMask(radius=radius, percent=percent, threshold=threshold))
            logger.debug(f"âœ… ì–¸ìƒ¤í”„ ë§ˆìŠ¤í¬ ì ìš© ì™„ë£Œ: radius={radius}, percent={percent}")
            return unsharp
        else:
            logger.warning("âš ï¸ PIL ì´ë¯¸ì§€ê°€ ì•„ë‹˜, ì›ë³¸ ë°˜í™˜")
            return image
    except Exception as e:
        logger.error(f"âŒ ì–¸ìƒ¤í”„ ë§ˆìŠ¤í¬ ì ìš© ì‹¤íŒ¨: {e}")
        return image

def apply_edge_enhance(image: Any, factor: float = 1.0) -> Any:
    """ì—£ì§€ ê°•í™” í•„í„° ì ìš©"""
    try:
        if PIL_AVAILABLE and hasattr(image, 'save'):
            # EDGE_ENHANCE í•„í„° ì ìš©
            if factor > 1.0:
                edge_enhanced = image.filter(ImageFilter.EDGE_ENHANCE_MORE)
            else:
                edge_enhanced = image.filter(ImageFilter.EDGE_ENHANCE)
            logger.debug(f"âœ… ì—£ì§€ ê°•í™” ì™„ë£Œ: factor={factor}")
            return edge_enhanced
        else:
            logger.warning("âš ï¸ PIL ì´ë¯¸ì§€ê°€ ì•„ë‹˜, ì›ë³¸ ë°˜í™˜")
            return image
    except Exception as e:
        logger.error(f"âŒ ì—£ì§€ ê°•í™” ì‹¤íŒ¨: {e}")
        return image

# ==============================================
# ğŸ”¥ ê³ ê¸‰ ì´ë¯¸ì§€ ì²˜ë¦¬ í•¨ìˆ˜ë“¤
# ==============================================

def apply_clahe_enhancement(image: Any, clip_limit: float = 2.0, tile_grid_size: Tuple[int, int] = (8, 8)) -> Any:
    """CLAHE (Contrast Limited Adaptive Histogram Equalization) ì ìš©"""
    try:
        if not CV2_AVAILABLE or not NUMPY_AVAILABLE:
            logger.warning("âš ï¸ OpenCV/NumPy í•„ìš”, ì›ë³¸ ë°˜í™˜")
            return image
        
        # PIL Imageë¥¼ numpy arrayë¡œ ë³€í™˜
        if hasattr(image, 'save'):  # PIL Image
            img_array = np.array(image)
        elif hasattr(image, 'shape'):  # numpy array
            img_array = image
        else:
            logger.warning("âš ï¸ ì§€ì›í•˜ì§€ ì•ŠëŠ” ì´ë¯¸ì§€ íƒ€ì…")
            return image
        
        # CLAHE ê°ì²´ ìƒì„±
        clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=tile_grid_size)
        
        # ì»¬ëŸ¬ ì´ë¯¸ì§€ì¸ ê²½ìš° LAB ê³µê°„ì—ì„œ ì²˜ë¦¬
        if len(img_array.shape) == 3:
            lab = cv2.cvtColor(img_array, cv2.COLOR_RGB2LAB)
            lab[:, :, 0] = clahe.apply(lab[:, :, 0])  # L ì±„ë„ì—ë§Œ ì ìš©
            enhanced = cv2.cvtColor(lab, cv2.COLOR_LAB2RGB)
        else:
            # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ì´ë¯¸ì§€
            enhanced = clahe.apply(img_array)
        
        # PIL Imageë¡œ ë³€í™˜í•˜ì—¬ ë°˜í™˜
        if PIL_AVAILABLE:
            return Image.fromarray(enhanced)
        else:
            return enhanced
            
    except Exception as e:
        logger.error(f"âŒ CLAHE ì ìš© ì‹¤íŒ¨: {e}")
        return image

def remove_background_simple(image: Any, threshold: int = 240) -> Any:
    """ê°„ë‹¨í•œ ë°°ê²½ ì œê±° (í°ìƒ‰ ë°°ê²½ ê°€ì •)"""
    try:
        if not NUMPY_AVAILABLE:
            logger.warning("âš ï¸ NumPy í•„ìš”, ì›ë³¸ ë°˜í™˜")
            return image
        
        # PIL Imageë¥¼ numpy arrayë¡œ ë³€í™˜
        if hasattr(image, 'save'):  # PIL Image
            img_array = np.array(image)
        elif hasattr(image, 'shape'):  # numpy array
            img_array = image.copy()
        else:
            logger.warning("âš ï¸ ì§€ì›í•˜ì§€ ì•ŠëŠ” ì´ë¯¸ì§€ íƒ€ì…")
            return image
        
        # ì•ŒíŒŒ ì±„ë„ ì¶”ê°€ (RGBA)
        if len(img_array.shape) == 3 and img_array.shape[2] == 3:
            # RGBì—ì„œ RGBAë¡œ ë³€í™˜
            alpha_channel = np.ones((img_array.shape[0], img_array.shape[1]), dtype=img_array.dtype) * 255
            img_rgba = np.dstack((img_array, alpha_channel))
            
            # í°ìƒ‰ ë°°ê²½ì„ íˆ¬ëª…í•˜ê²Œ ë§Œë“¤ê¸°
            white_pixels = np.all(img_array >= threshold, axis=2)
            img_rgba[white_pixels, 3] = 0  # ì•ŒíŒŒê°’ì„ 0ìœ¼ë¡œ (íˆ¬ëª…)
            
            # PIL Imageë¡œ ë³€í™˜
            if PIL_AVAILABLE:
                return Image.fromarray(img_rgba, 'RGBA')
            else:
                return img_rgba
        else:
            logger.warning("âš ï¸ RGB ì´ë¯¸ì§€ê°€ ì•„ë‹˜")
            return image
            
    except Exception as e:
        logger.error(f"âŒ ë°°ê²½ ì œê±° ì‹¤íŒ¨: {e}")
        return image

def detect_dominant_colors(image: Any, k: int = 5) -> List[Tuple[int, int, int]]:
    """ì´ë¯¸ì§€ì—ì„œ ì£¼ìš” ìƒ‰ìƒ ì¶”ì¶œ (K-means í´ëŸ¬ìŠ¤í„°ë§)"""
    try:
        if not NUMPY_AVAILABLE:
            logger.warning("âš ï¸ NumPy í•„ìš”")
            return []
        
        # PIL Imageë¥¼ numpy arrayë¡œ ë³€í™˜
        if hasattr(image, 'save'):  # PIL Image
            img_array = np.array(image)
        elif hasattr(image, 'shape'):  # numpy array
            img_array = image
        else:
            logger.warning("âš ï¸ ì§€ì›í•˜ì§€ ì•ŠëŠ” ì´ë¯¸ì§€ íƒ€ì…")
            return []
        
        # ì´ë¯¸ì§€ë¥¼ 1ì°¨ì›ìœ¼ë¡œ ë³€í™˜
        if len(img_array.shape) == 3:
            pixels = img_array.reshape((-1, 3))
        else:
            logger.warning("âš ï¸ ì»¬ëŸ¬ ì´ë¯¸ì§€ê°€ ì•„ë‹˜")
            return []
        
        # ê°„ë‹¨í•œ ìƒ‰ìƒ ë¶„ì„ (K-means ëŒ€ì‹  íˆìŠ¤í† ê·¸ë¨ ê¸°ë°˜)
        unique_colors, counts = np.unique(pixels.view(np.dtype((np.void, pixels.dtype.itemsize * pixels.shape[1]))), 
                                        return_counts=True)
        
        # ìƒìœ„ kê°œ ìƒ‰ìƒ ì¶”ì¶œ
        top_indices = np.argsort(counts)[-k:][::-1]
        dominant_colors = []
        
        for idx in top_indices:
            color_bytes = unique_colors[idx].view(pixels.dtype).reshape(pixels.shape[1])
            dominant_colors.append(tuple(color_bytes.astype(int)))
        
        logger.debug(f"âœ… ì£¼ìš” ìƒ‰ìƒ {k}ê°œ ì¶”ì¶œ ì™„ë£Œ")
        return dominant_colors
        
    except Exception as e:
        logger.error(f"âŒ ì£¼ìš” ìƒ‰ìƒ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
        return []

def calculate_image_similarity(image1: Any, image2: Any, method: str = "mse") -> float:
    """ë‘ ì´ë¯¸ì§€ ê°„ì˜ ìœ ì‚¬ë„ ê³„ì‚°"""
    try:
        if not NUMPY_AVAILABLE:
            logger.warning("âš ï¸ NumPy í•„ìš”")
            return 0.0
        
        # ì´ë¯¸ì§€ë“¤ì„ numpy arrayë¡œ ë³€í™˜
        def to_array(img):
            if hasattr(img, 'save'):  # PIL Image
                return np.array(img)
            elif hasattr(img, 'shape'):  # numpy array
                return img
            else:
                return None
        
        arr1 = to_array(image1)
        arr2 = to_array(image2)
        
        if arr1 is None or arr2 is None:
            logger.warning("âš ï¸ ì´ë¯¸ì§€ ë³€í™˜ ì‹¤íŒ¨")
            return 0.0
        
        # í¬ê¸° ë§ì¶”ê¸°
        if arr1.shape != arr2.shape:
            # ë” ì‘ì€ í¬ê¸°ë¡œ ë§ì¶¤
            min_height = min(arr1.shape[0], arr2.shape[0])
            min_width = min(arr1.shape[1], arr2.shape[1])
            arr1 = arr1[:min_height, :min_width]
            arr2 = arr2[:min_height, :min_width]
        
        # ìœ ì‚¬ë„ ê³„ì‚°
        if method == "mse":
            # Mean Squared Error (ë‚®ì„ìˆ˜ë¡ ìœ ì‚¬)
            mse = np.mean((arr1.astype(float) - arr2.astype(float)) ** 2)
            # 0-1 ë²”ìœ„ë¡œ ì •ê·œí™” (1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ìœ ì‚¬)
            similarity = 1.0 / (1.0 + mse / 255.0)
        elif method == "cosine":
            # ì½”ì‚¬ì¸ ìœ ì‚¬ë„
            arr1_flat = arr1.flatten().astype(float)
            arr2_flat = arr2.flatten().astype(float)
            
            dot_product = np.dot(arr1_flat, arr2_flat)
            norm1 = np.linalg.norm(arr1_flat)
            norm2 = np.linalg.norm(arr2_flat)
            
            if norm1 == 0 or norm2 == 0:
                similarity = 0.0
            else:
                similarity = dot_product / (norm1 * norm2)
        else:
            logger.warning(f"âš ï¸ ì§€ì›í•˜ì§€ ì•ŠëŠ” ìœ ì‚¬ë„ ë°©ë²•: {method}")
            return 0.0
        
        logger.debug(f"âœ… ì´ë¯¸ì§€ ìœ ì‚¬ë„ ê³„ì‚° ì™„ë£Œ: {similarity:.3f} ({method})")
        return float(similarity)
        
    except Exception as e:
        logger.error(f"âŒ ì´ë¯¸ì§€ ìœ ì‚¬ë„ ê³„ì‚° ì‹¤íŒ¨: {e}")
        return 0.0

# ==============================================
# ğŸ”¥ ì´ë¯¸ì§€ ê²€ì¦ ë° ë¶„ì„ í•¨ìˆ˜ë“¤
# ==============================================

def validate_image_format(image: Any) -> Dict[str, Any]:
    """ì´ë¯¸ì§€ í¬ë§· ë° ì†ì„± ê²€ì¦"""
    try:
        result = {
            "valid": False,
            "type": str(type(image)),
            "format": None,
            "size": None,
            "mode": None,
            "channels": None,
            "dtype": None,
            "memory_usage_mb": 0.0
        }
        
        if hasattr(image, 'size'):  # PIL Image
            result.update({
                "valid": True,
                "format": "PIL",
                "size": image.size,
                "mode": image.mode,
                "channels": len(image.getbands()),
                "memory_usage_mb": (image.size[0] * image.size[1] * len(image.getbands())) / (1024 * 1024)
            })
        elif NUMPY_AVAILABLE and hasattr(image, 'shape'):  # NumPy array
            memory_mb = image.nbytes / (1024 * 1024) if hasattr(image, 'nbytes') else 0.0
            result.update({
                "valid": True,
                "format": "NumPy",
                "size": (image.shape[1], image.shape[0]) if len(image.shape) >= 2 else image.shape,
                "channels": image.shape[2] if len(image.shape) == 3 else 1,
                "dtype": str(image.dtype),
                "memory_usage_mb": memory_mb
            })
        elif TORCH_AVAILABLE and hasattr(image, 'shape'):  # PyTorch tensor
            memory_mb = (image.numel() * image.element_size()) / (1024 * 1024) if hasattr(image, 'numel') else 0.0
            result.update({
                "valid": True,
                "format": "PyTorch",
                "size": (image.shape[-1], image.shape[-2]) if len(image.shape) >= 2 else image.shape,
                "channels": image.shape[-3] if len(image.shape) >= 3 else 1,
                "dtype": str(image.dtype),
                "memory_usage_mb": memory_mb
            })
        
        logger.debug(f"ì´ë¯¸ì§€ ê²€ì¦ ê²°ê³¼: {result}")
        return result
        
    except Exception as e:
        logger.error(f"âŒ ì´ë¯¸ì§€ ê²€ì¦ ì‹¤íŒ¨: {e}")
        return {"valid": False, "error": str(e)}

def get_image_statistics(image: Any) -> Dict[str, Any]:
    """ì´ë¯¸ì§€ í†µê³„ ì •ë³´"""
    try:
        stats = {"error": None}
        
        if NUMPY_AVAILABLE and hasattr(image, 'shape'):
            if hasattr(image, 'cpu'):  # PyTorch tensor
                array = image.cpu().numpy()
            else:
                array = image
            
            stats.update({
                "mean": float(np.mean(array)),
                "std": float(np.std(array)),
                "min": float(np.min(array)),
                "max": float(np.max(array)),
                "median": float(np.median(array)),
                "shape": array.shape,
                "unique_values": int(len(np.unique(array))),
                "zero_ratio": float(np.mean(array == 0))
            })
        elif hasattr(image, 'size'):  # PIL Image
            if NUMPY_AVAILABLE:
                array = np.array(image)
                stats.update({
                    "mean": float(np.mean(array)),
                    "std": float(np.std(array)),
                    "min": float(np.min(array)),
                    "max": float(np.max(array)),
                    "median": float(np.median(array)),
                    "size": image.size,
                    "mode": image.mode,
                    "unique_values": int(len(np.unique(array)))
                })
        
        logger.debug(f"ì´ë¯¸ì§€ í†µê³„: {stats}")
        return stats
        
    except Exception as e:
        logger.error(f"âŒ ì´ë¯¸ì§€ í†µê³„ ê³„ì‚° ì‹¤íŒ¨: {e}")
        return {"error": str(e)}

def detect_image_artifacts(image: Any) -> Dict[str, Any]:
    """ì´ë¯¸ì§€ ì•„í‹°íŒ©íŠ¸ ê°ì§€"""
    try:
        artifacts = {
            "noise_level": 0.0,
            "blur_level": 0.0,
            "compression_artifacts": False,
            "over_saturation": False,
            "under_exposure": False,
            "over_exposure": False
        }
        
        if not NUMPY_AVAILABLE:
            logger.warning("âš ï¸ NumPy í•„ìš”")
            return artifacts
        
        # PIL Imageë¥¼ numpy arrayë¡œ ë³€í™˜
        if hasattr(image, 'save'):  # PIL Image
            img_array = np.array(image)
        elif hasattr(image, 'shape'):  # numpy array
            img_array = image
        else:
            return artifacts
        
        # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ë¡œ ë³€í™˜
        if len(img_array.shape) == 3:
            gray = np.mean(img_array, axis=2)
        else:
            gray = img_array
        
        # ë…¸ì´ì¦ˆ ë ˆë²¨ ì¶”ì • (Laplacian variance ì‚¬ìš©)
        if CV2_AVAILABLE:
            laplacian_var = cv2.Laplacian(gray.astype(np.uint8), cv2.CV_64F).var()
            artifacts["noise_level"] = float(laplacian_var / 1000.0)  # ì •ê·œí™”
        
        # ë¸”ëŸ¬ ë ˆë²¨ ì¶”ì •
        if CV2_AVAILABLE:
            blur_score = cv2.Laplacian(gray.astype(np.uint8), cv2.CV_64F).var()
            artifacts["blur_level"] = float(1.0 - min(blur_score / 1000.0, 1.0))
        
        # ë…¸ì¶œ ë¬¸ì œ ê°ì§€
        mean_brightness = np.mean(gray)
        artifacts["under_exposure"] = mean_brightness < 50
        artifacts["over_exposure"] = mean_brightness > 200
        
        # ê³¼í¬í™” ê°ì§€
        if len(img_array.shape) == 3:
            max_values = np.max(img_array, axis=2)
            artifacts["over_saturation"] = np.mean(max_values >= 250) > 0.1
        
        logger.debug(f"ì•„í‹°íŒ©íŠ¸ ê°ì§€ ê²°ê³¼: {artifacts}")
        return artifacts
        
    except Exception as e:
        logger.error(f"âŒ ì•„í‹°íŒ©íŠ¸ ê°ì§€ ì‹¤íŒ¨: {e}")
        return {"error": str(e)}

# ==============================================
# ğŸ”¥ ë©”ëª¨ë¦¬ ê´€ë¦¬ í•¨ìˆ˜ë“¤
# ==============================================

def cleanup_image_memory():
    """ì´ë¯¸ì§€ ì²˜ë¦¬ ê´€ë ¨ ë©”ëª¨ë¦¬ ì •ë¦¬"""
    try:
        logger.debug("ì´ë¯¸ì§€ ë©”ëª¨ë¦¬ ì •ë¦¬ ì‹œì‘")
        
        # Python garbage collection
        import gc
        collected = gc.collect()
        logger.debug(f"Python GC: {collected}ê°œ ê°ì²´ ìˆ˜ì§‘")
        
        # PyTorch ìºì‹œ ì •ë¦¬
        if TORCH_AVAILABLE:
            if hasattr(torch, 'cuda') and torch.cuda.is_available():
                torch.cuda.empty_cache()
                logger.debug("CUDA ìºì‹œ ì •ë¦¬ ì™„ë£Œ")
            
            if hasattr(torch, 'mps') and hasattr(torch.mps, 'empty_cache'):
                try:
                    torch.mps.empty_cache()
                    logger.debug("MPS ìºì‹œ ì •ë¦¬ ì™„ë£Œ")
                except:
                    pass
        
        logger.info("âœ… ì´ë¯¸ì§€ ë©”ëª¨ë¦¬ ì •ë¦¬ ì™„ë£Œ")
        return True
        
    except Exception as e:
        logger.error(f"âŒ ì´ë¯¸ì§€ ë©”ëª¨ë¦¬ ì •ë¦¬ ì‹¤íŒ¨: {e}")
        return False

def estimate_memory_usage(image: Any) -> Dict[str, float]:
    """ì´ë¯¸ì§€ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¶”ì •"""
    try:
        usage = {"bytes": 0, "mb": 0, "gb": 0, "error": None}
        
        if hasattr(