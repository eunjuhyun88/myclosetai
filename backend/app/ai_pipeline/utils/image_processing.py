#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸ–¼ï¸ MyCloset AI - ì´ë¯¸ì§€ ì²˜ë¦¬ ëª¨ë“ˆ (ì™„ì „í•œ Python êµ¬ì¡°)
===========================================================
âœ… ì˜¬ë°”ë¥¸ Python êµ¬ì¡°ë¡œ ì™„ì „ ì¬êµ¬ì„±
âœ… í•¨ìˆ˜ë“¤ì„ ë…¼ë¦¬ì  ìˆœì„œë¡œ ë°°ì¹˜
âœ… ëª¨ë“  ê¸°ëŠ¥ ì™„ì „ êµ¬í˜„ (ì˜ë¦° ë¶€ë¶„ ì—†ìŒ)
âœ… conda í™˜ê²½ & M3 Max ìµœì í™”
âœ… ìˆœí™˜ì°¸ì¡° ì™„ì „ ë°©ì§€
âœ… íƒ€ì… íŒíŒ… ë° ë¬¸ì„œí™” ì™„ë£Œ

Author: MyCloset AI Team
Date: 2025-07-21
Version: 2.0 (Complete Restructure)
"""

# =============================================================================
# ğŸ”¥ 1. í‘œì¤€ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸
# =============================================================================
import io
import os
import sys
import logging
import base64
import tempfile
import uuid
import math
from typing import Dict, Any, Optional, Tuple, List, Union, Callable
from pathlib import Path
from abc import ABC, abstractmethod

# =============================================================================
# ğŸ”¥ 2. ì„œë“œíŒŒí‹° ë¼ì´ë¸ŒëŸ¬ë¦¬ ì¡°ê±´ë¶€ ì„í¬íŠ¸ (ì•ˆì „í•œ ì²˜ë¦¬)
# =============================================================================

# ë¡œê±° ì„¤ì • (ìµœìš°ì„ )
logger = logging.getLogger(__name__)

# NumPy ì•ˆì „ ì„í¬íŠ¸
try:
    import numpy as np
    NUMPY_AVAILABLE = True
    logger.info("âœ… NumPy ì‚¬ìš© ê°€ëŠ¥")
    
    # NumPy 2.x í˜¸í™˜ì„± ì²´í¬
    numpy_version = tuple(map(int, np.__version__.split('.')[:2]))
    if numpy_version >= (2, 0):
        logger.warning(f"âš ï¸ NumPy {np.__version__} ê°ì§€ - 1.x ê¶Œì¥")
        logger.warning("ğŸ”§ í•´ê²°ë°©ë²•: conda install numpy=1.24.3 -y --force-reinstall")
        
except ImportError as e:
    NUMPY_AVAILABLE = False
    np = None
    logger.warning(f"âš ï¸ NumPy ì—†ìŒ: {e}")

# PIL/Pillow ì•ˆì „ ì„í¬íŠ¸
try:
    from PIL import Image, ImageEnhance, ImageFilter, ImageDraw, ImageFont
    PIL_AVAILABLE = True
    logger.info("âœ… PIL/Pillow ì‚¬ìš© ê°€ëŠ¥")
except ImportError as e:
    PIL_AVAILABLE = False
    Image = None
    logger.warning(f"âš ï¸ PIL/Pillow ì—†ìŒ: {e}")

# OpenCV ì•ˆì „ ì„í¬íŠ¸
try:
    import cv2
    CV2_AVAILABLE = True
    logger.info("âœ… OpenCV ì‚¬ìš© ê°€ëŠ¥")
except ImportError as e:
    CV2_AVAILABLE = False
    cv2 = None
    logger.warning(f"âš ï¸ OpenCV ì—†ìŒ: {e}")

# PyTorch ì•ˆì „ ì„í¬íŠ¸
try:
    import torch
    import torch.nn.functional as F
    TORCH_AVAILABLE = True
    logger.info("âœ… PyTorch ì‚¬ìš© ê°€ëŠ¥")
    
    # M3 Max MPS ì²´í¬
    if hasattr(torch, 'mps') and torch.mps.is_available():
        logger.info("ğŸš€ M3 Max MPS ê°€ì† ì‚¬ìš© ê°€ëŠ¥")
except ImportError as e:
    TORCH_AVAILABLE = False
    torch = None
    F = None
    logger.warning(f"âš ï¸ PyTorch ì—†ìŒ: {e}")

# =============================================================================
# ğŸ”¥ 3. ìƒìˆ˜ ë° ì„¤ì •
# =============================================================================

# ê¸°ë³¸ ì„¤ì •ê°’
DEFAULT_IMAGE_SIZE = (512, 512)
DEFAULT_DEVICE = "mps" if TORCH_AVAILABLE and hasattr(torch, 'mps') and torch.mps.is_available() else "cpu"
DEFAULT_DTYPE = torch.float16 if TORCH_AVAILABLE else None

# ì§€ì›ë˜ëŠ” ì´ë¯¸ì§€ í¬ë§·
SUPPORTED_FORMATS = ['JPEG', 'PNG', 'WEBP', 'BMP', 'TIFF']
SUPPORTED_EXTENSIONS = ['.jpg', '.jpeg', '.png', '.webp', '.bmp', '.tiff']

# ë©”ëª¨ë¦¬ ìµœì í™” ì„¤ì •
MAX_IMAGE_SIZE = (2048, 2048)  # M3 Max ê¸°ì¤€ ìµœëŒ€ ê¶Œì¥ í¬ê¸°
MEMORY_THRESHOLD_MB = 500  # ë©”ëª¨ë¦¬ ì„ê³„ê°’

# =============================================================================
# ğŸ”¥ 4. ê¸°ë³¸ í—¬í¼ í•¨ìˆ˜ë“¤ (ê°€ì¥ ê¸°ì´ˆì ì¸ ê²ƒë“¤)
# =============================================================================

def _ensure_numpy() -> bool:
    """NumPy ê°€ìš©ì„± í™•ì¸"""
    if not NUMPY_AVAILABLE:
        logger.error("âŒ NumPyê°€ í•„ìš”í•©ë‹ˆë‹¤. conda install numpy=1.24.3")
        return False
    return True

def _ensure_pil() -> bool:
    """PIL ê°€ìš©ì„± í™•ì¸"""
    if not PIL_AVAILABLE:
        logger.error("âŒ PIL/Pillowê°€ í•„ìš”í•©ë‹ˆë‹¤. conda install pillow")
        return False
    return True

def _ensure_torch() -> bool:
    """PyTorch ê°€ìš©ì„± í™•ì¸"""
    if not TORCH_AVAILABLE:
        logger.error("âŒ PyTorchê°€ í•„ìš”í•©ë‹ˆë‹¤. conda install pytorch")
        return False
    return True

def _get_optimal_device() -> str:
    """ìµœì  ë””ë°”ì´ìŠ¤ ìë™ ì„ íƒ"""
    if TORCH_AVAILABLE:
        if hasattr(torch, 'mps') and torch.mps.is_available():
            return "mps"  # M3 Max
        elif torch.cuda.is_available():
            return "cuda"
    return "cpu"

def _validate_image_input(image: Any) -> bool:
    """ì´ë¯¸ì§€ ì…ë ¥ ê²€ì¦"""
    if image is None:
        return False
    
    # PIL Image
    if hasattr(image, 'size') and hasattr(image, 'mode'):
        return True
    
    # NumPy array
    if NUMPY_AVAILABLE and isinstance(image, np.ndarray):
        return len(image.shape) >= 2
    
    # PyTorch tensor
    if TORCH_AVAILABLE and torch.is_tensor(image):
        return len(image.shape) >= 2
    
    # íŒŒì¼ ê²½ë¡œ
    if isinstance(image, (str, Path)):
        return Path(image).exists()
    
    return False

# =============================================================================
# ğŸ”¥ 5. í•µì‹¬ ì´ë¯¸ì§€ ì²˜ë¦¬ í•¨ìˆ˜ë“¤ (ì˜¬ë°”ë¥¸ ìˆœì„œ)
# =============================================================================

def load_image(filepath: Union[str, Path], target_format: str = "RGB") -> Optional[Any]:
    """
    ì´ë¯¸ì§€ íŒŒì¼ ë¡œë“œ
    
    Args:
        filepath: ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ
        target_format: íƒ€ê²Ÿ í¬ë§· ('RGB', 'RGBA', 'L')
    
    Returns:
        PIL Image ë˜ëŠ” None
    """
    try:
        if not _ensure_pil():
            return None
        
        filepath = Path(filepath)
        if not filepath.exists():
            logger.error(f"âŒ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ: {filepath}")
            return None
        
        # í™•ì¥ì ì²´í¬
        if filepath.suffix.lower() not in SUPPORTED_EXTENSIONS:
            logger.warning(f"âš ï¸ ì§€ì›í•˜ì§€ ì•ŠëŠ” í™•ì¥ì: {filepath.suffix}")
        
        # ì´ë¯¸ì§€ ë¡œë“œ
        image = Image.open(filepath)
        
        # í¬ë§· ë³€í™˜
        if target_format and image.mode != target_format:
            if target_format == 'RGB' and image.mode == 'RGBA':
                # íˆ¬ëª…ë„ê°€ ìˆëŠ” ê²½ìš° í°ìƒ‰ ë°°ê²½ìœ¼ë¡œ í•©ì„±
                background = Image.new('RGB', image.size, (255, 255, 255))
                background.paste(image, mask=image.split()[-1] if image.mode == 'RGBA' else None)
                image = background
            else:
                image = image.convert(target_format)
        
        logger.debug(f"âœ… ì´ë¯¸ì§€ ë¡œë“œ ì™„ë£Œ: {filepath} ({image.size}, {image.mode})")
        return image
        
    except Exception as e:
        logger.error(f"âŒ ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None

def save_image(image: Any, filepath: Union[str, Path], 
              format: str = None, quality: int = 95, **kwargs) -> bool:
    """
    ì´ë¯¸ì§€ íŒŒì¼ë¡œ ì €ì¥
    
    Args:
        image: ì €ì¥í•  ì´ë¯¸ì§€ (PIL, numpy, tensor)
        filepath: ì €ì¥ ê²½ë¡œ
        format: ì €ì¥ í¬ë§· (ìë™ ê°ì§€ ê°€ëŠ¥)
        quality: JPEG í’ˆì§ˆ (1-100)
        **kwargs: ì¶”ê°€ ì €ì¥ ì˜µì…˜
    
    Returns:
        ì €ì¥ ì„±ê³µ ì—¬ë¶€
    """
    try:
        if not _ensure_pil():
            return False
        
        filepath = Path(filepath)
        
        # PIL Imageë¡œ ë³€í™˜
        pil_image = convert_to_pil(image)
        if pil_image is None:
            logger.error(f"âŒ PIL ì´ë¯¸ì§€ ë³€í™˜ ì‹¤íŒ¨: {type(image)}")
            return False
        
        # í¬ë§· ìë™ ê°ì§€
        if format is None:
            format = filepath.suffix.upper().lstrip('.')
            if format == 'JPG':
                format = 'JPEG'
        
        # RGB ëª¨ë“œ í™•ì¸ (JPEGëŠ” íˆ¬ëª…ë„ ì§€ì› ì•ˆí•¨)
        if format.upper() == 'JPEG' and pil_image.mode in ['RGBA', 'LA']:
            background = Image.new('RGB', pil_image.size, (255, 255, 255))
            if pil_image.mode == 'RGBA':
                background.paste(pil_image, mask=pil_image.split()[-1])
            else:
                background.paste(pil_image)
            pil_image = background
        
        # ë””ë ‰í† ë¦¬ ìƒì„±
        filepath.parent.mkdir(parents=True, exist_ok=True)
        
        # ì €ì¥ ì˜µì…˜ ì„¤ì •
        save_kwargs = {'format': format, **kwargs}
        if format.upper() in ['JPEG', 'WEBP']:
            save_kwargs['quality'] = quality
            save_kwargs['optimize'] = True
        
        # ì €ì¥ ì‹¤í–‰
        pil_image.save(filepath, **save_kwargs)
        
        logger.debug(f"âœ… ì´ë¯¸ì§€ ì €ì¥ ì™„ë£Œ: {filepath} ({format})")
        return True
        
    except Exception as e:
        logger.error(f"âŒ ì´ë¯¸ì§€ ì €ì¥ ì‹¤íŒ¨: {e}")
        return False

def convert_to_pil(image: Any) -> Optional[Any]:
    """
    ë‹¤ì–‘í•œ ì´ë¯¸ì§€ íƒ€ì…ì„ PIL Imageë¡œ ë³€í™˜
    
    Args:
        image: ë³€í™˜í•  ì´ë¯¸ì§€ (numpy, tensor, PIL ë“±)
    
    Returns:
        PIL Image ë˜ëŠ” None
    """
    try:
        if not _ensure_pil():
            return None
        
        # ì´ë¯¸ PIL Imageì¸ ê²½ìš°
        if hasattr(image, 'save') and hasattr(image, 'size'):
            return image
        
        # NumPy arrayì¸ ê²½ìš°
        if NUMPY_AVAILABLE and isinstance(image, np.ndarray):
            # ë°ì´í„° íƒ€ì… ì •ê·œí™”
            if image.dtype != np.uint8:
                if image.max() <= 1.0:
                    image = (image * 255).astype(np.uint8)
                else:
                    image = np.clip(image, 0, 255).astype(np.uint8)
            
            # ì°¨ì›ì— ë”°ë¥¸ ì²˜ë¦¬
            if len(image.shape) == 3:
                if image.shape[2] == 3:
                    return Image.fromarray(image, 'RGB')
                elif image.shape[2] == 4:
                    return Image.fromarray(image, 'RGBA')
                elif image.shape[2] == 1:
                    return Image.fromarray(image.squeeze(), 'L')
            elif len(image.shape) == 2:
                return Image.fromarray(image, 'L')
        
        # PyTorch tensorì¸ ê²½ìš°
        if TORCH_AVAILABLE and torch.is_tensor(image):
            return tensor_to_pil(image)
        
        # íŒŒì¼ ê²½ë¡œì¸ ê²½ìš°
        if isinstance(image, (str, Path)):
            return load_image(image)
        
        logger.warning(f"âš ï¸ ì§€ì›í•˜ì§€ ì•ŠëŠ” ì´ë¯¸ì§€ íƒ€ì…: {type(image)}")
        return None
        
    except Exception as e:
        logger.error(f"âŒ PIL ë³€í™˜ ì‹¤íŒ¨: {e}")
        return None

def convert_to_numpy(image: Any) -> Optional[np.ndarray]:
    """
    ë‹¤ì–‘í•œ ì´ë¯¸ì§€ íƒ€ì…ì„ NumPy arrayë¡œ ë³€í™˜
    
    Args:
        image: ë³€í™˜í•  ì´ë¯¸ì§€
    
    Returns:
        NumPy array ë˜ëŠ” None
    """
    try:
        if not _ensure_numpy():
            return None
        
        # ì´ë¯¸ NumPy arrayì¸ ê²½ìš°
        if isinstance(image, np.ndarray):
            return image
        
        # PIL Imageì¸ ê²½ìš°
        if hasattr(image, 'size') and hasattr(image, 'mode'):
            return np.array(image)
        
        # PyTorch tensorì¸ ê²½ìš°
        if TORCH_AVAILABLE and torch.is_tensor(image):
            # CPUë¡œ ì´ë™ í›„ numpy ë³€í™˜
            if image.is_cuda or (hasattr(image, 'is_mps') and image.is_mps):
                image = image.cpu()
            
            # ì°¨ì› ì¡°ì •
            if image.dim() == 4:  # (N, C, H, W)
                image = image.squeeze(0)
            if image.dim() == 3:  # (C, H, W)
                image = image.permute(1, 2, 0)  # (H, W, C)
            
            # detach í›„ numpy ë³€í™˜
            if hasattr(image, 'detach'):
                image = image.detach()
            
            return image.numpy()
        
        # íŒŒì¼ ê²½ë¡œì¸ ê²½ìš°
        if isinstance(image, (str, Path)):
            pil_image = load_image(image)
            if pil_image:
                return np.array(pil_image)
        
        logger.warning(f"âš ï¸ ì§€ì›í•˜ì§€ ì•ŠëŠ” ì´ë¯¸ì§€ íƒ€ì…: {type(image)}")
        return None
        
    except Exception as e:
        logger.error(f"âŒ NumPy ë³€í™˜ ì‹¤íŒ¨: {e}")
        return None

def tensor_to_pil(tensor: torch.Tensor) -> Optional[Any]:
    """
    PyTorch tensorë¥¼ PIL Imageë¡œ ë³€í™˜
    
    Args:
        tensor: PyTorch tensor (C,H,W) ë˜ëŠ” (N,C,H,W)
    
    Returns:
        PIL Image ë˜ëŠ” None
    """
    try:
        if not _ensure_torch() or not _ensure_pil():
            return None
        
        if not torch.is_tensor(tensor):
            logger.error("âŒ PyTorch tensorê°€ ì•„ë‹™ë‹ˆë‹¤")
            return None
        
        # ì°¨ì› ì¡°ì •
        if tensor.dim() == 4:  # (N, C, H, W)
            tensor = tensor.squeeze(0)
            
        if tensor.dim() == 3:  # (C, H, W)
            tensor = tensor.permute(1, 2, 0)  # (H, W, C)
        
        # CPUë¡œ ì´ë™
        if tensor.is_cuda or (hasattr(tensor, 'is_mps') and tensor.is_mps):
            tensor = tensor.cpu()
        
        # detach ë° numpy ë³€í™˜
        if hasattr(tensor, 'detach'):
            tensor = tensor.detach()
        
        array = tensor.numpy()
        
        # ê°’ ë²”ìœ„ ì¡°ì • (0-1 â†’ 0-255)
        if array.dtype != np.uint8:
            if array.max() <= 1.0:
                array = (array * 255).astype(np.uint8)
            else:
                array = np.clip(array, 0, 255).astype(np.uint8)
        
        # PIL Image ìƒì„±
        if len(array.shape) == 3:
            if array.shape[2] == 3:
                return Image.fromarray(array, 'RGB')
            elif array.shape[2] == 1:
                return Image.fromarray(array.squeeze(), 'L')
            elif array.shape[2] == 4:
                return Image.fromarray(array, 'RGBA')
        elif len(array.shape) == 2:
            return Image.fromarray(array, 'L')
        
        logger.error(f"âŒ ì§€ì›í•˜ì§€ ì•ŠëŠ” í…ì„œ í˜•íƒœ: {array.shape}")
        return None
        
    except Exception as e:
        logger.error(f"âŒ tensorâ†’PIL ë³€í™˜ ì‹¤íŒ¨: {e}")
        return None

def pil_to_tensor(image: Any, device: str = None, normalize: bool = True) -> Optional[torch.Tensor]:
    """
    PIL Imageë¥¼ PyTorch tensorë¡œ ë³€í™˜
    
    Args:
        image: PIL Image ë˜ëŠ” ë³€í™˜ ê°€ëŠ¥í•œ ì´ë¯¸ì§€
        device: íƒ€ê²Ÿ ë””ë°”ì´ìŠ¤
        normalize: 0-1 ë²”ìœ„ë¡œ ì •ê·œí™” ì—¬ë¶€
    
    Returns:
        PyTorch tensor (N,C,H,W) ë˜ëŠ” None
    """
    try:
        if not _ensure_torch():
            return None
        
        if device is None:
            device = _get_optimal_device()
        
        # PIL Imageë¡œ ë³€í™˜
        pil_image = convert_to_pil(image)
        if pil_image is None:
            return None
        
        # NumPy arrayë¡œ ë³€í™˜
        array = np.array(pil_image).astype(np.float32)
        
        # ì •ê·œí™”
        if normalize and array.max() > 1.0:
            array = array / 255.0
        
        # ì°¨ì› ì¡°ì •
        if len(array.shape) == 2:  # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ (H, W)
            array = np.expand_dims(array, axis=-1)  # (H, W, 1)
        
        if len(array.shape) == 3:  # (H, W, C)
            # (H, W, C) â†’ (C, H, W) â†’ (1, C, H, W)
            tensor = torch.from_numpy(array).permute(2, 0, 1).unsqueeze(0)
        else:
            logger.error(f"âŒ ì§€ì›í•˜ì§€ ì•ŠëŠ” ë°°ì—´ í˜•íƒœ: {array.shape}")
            return None
        
        # ë””ë°”ì´ìŠ¤ë¡œ ì´ë™
        tensor = tensor.to(device)
        
        logger.debug(f"âœ… PILâ†’tensor ë³€í™˜ ì™„ë£Œ: {tensor.shape}, device: {device}")
        return tensor
        
    except Exception as e:
        logger.error(f"âŒ PILâ†’tensor ë³€í™˜ ì‹¤íŒ¨: {e}")
        return None

# =============================================================================
# ğŸ”¥ 6. ì´ë¯¸ì§€ í¬ê¸° ë° í˜•íƒœ ì¡°ì • í•¨ìˆ˜ë“¤
# =============================================================================

def resize_image(image: Any, target_size: Tuple[int, int], 
                keep_aspect_ratio: bool = True, 
                resample_method: str = "LANCZOS") -> Optional[Any]:
    """
    ì´ë¯¸ì§€ í¬ê¸° ì¡°ì •
    
    Args:
        image: ì…ë ¥ ì´ë¯¸ì§€
        target_size: íƒ€ê²Ÿ í¬ê¸° (width, height)
        keep_aspect_ratio: ë¹„ìœ¨ ìœ ì§€ ì—¬ë¶€
        resample_method: ë¦¬ìƒ˜í”Œë§ ë°©ë²•
    
    Returns:
        í¬ê¸° ì¡°ì •ëœ ì´ë¯¸ì§€
    """
    try:
        pil_image = convert_to_pil(image)
        if pil_image is None:
            return None
        
        original_size = pil_image.size
        
        # ë¹„ìœ¨ ìœ ì§€í•˜ë©´ì„œ í¬ê¸° ì¡°ì •
        if keep_aspect_ratio:
            # íƒ€ê²Ÿ í¬ê¸°ì— ë§ê²Œ ë¹„ìœ¨ ê³„ì‚°
            scale = min(target_size[0] / original_size[0], 
                       target_size[1] / original_size[1])
            
            new_size = (int(original_size[0] * scale), 
                       int(original_size[1] * scale))
            
            # í¬ê¸° ì¡°ì •
            resample = getattr(Image.Resampling, resample_method, Image.Lanczos)
            resized = pil_image.resize(new_size, resample)
            
            # íŒ¨ë”© ì¶”ê°€ (ì¤‘ì•™ ë°°ì¹˜)
            if new_size != target_size:
                # ìƒˆ ì´ë¯¸ì§€ ìƒì„± (ê²€ì€ìƒ‰ ë°°ê²½)
                padded = Image.new(pil_image.mode, target_size, (0, 0, 0))
                
                # ì¤‘ì•™ì— ë°°ì¹˜
                offset = ((target_size[0] - new_size[0]) // 2,
                         (target_size[1] - new_size[1]) // 2)
                padded.paste(resized, offset)
                
                return padded
            else:
                return resized
        else:
            # ë¹„ìœ¨ ë¬´ì‹œí•˜ê³  í¬ê¸° ì¡°ì •
            resample = getattr(Image.Resampling, resample_method, Image.Lanczos)
            return pil_image.resize(target_size, resample)
        
    except Exception as e:
        logger.error(f"âŒ ì´ë¯¸ì§€ í¬ê¸° ì¡°ì • ì‹¤íŒ¨: {e}")
        return image

def crop_image(image: Any, bbox: Tuple[int, int, int, int]) -> Optional[Any]:
    """
    ì´ë¯¸ì§€ í¬ë¡­
    
    Args:
        image: ì…ë ¥ ì´ë¯¸ì§€
        bbox: í¬ë¡­ ì˜ì—­ (left, top, right, bottom)
    
    Returns:
        í¬ë¡­ëœ ì´ë¯¸ì§€
    """
    try:
        pil_image = convert_to_pil(image)
        if pil_image is None:
            return None
        
        # í¬ë¡­ ì˜ì—­ ê²€ì¦
        width, height = pil_image.size
        left, top, right, bottom = bbox
        
        left = max(0, min(left, width))
        top = max(0, min(top, height))
        right = max(left, min(right, width))
        bottom = max(top, min(bottom, height))
        
        # í¬ë¡­ ì‹¤í–‰
        cropped = pil_image.crop((left, top, right, bottom))
        
        logger.debug(f"âœ… ì´ë¯¸ì§€ í¬ë¡­ ì™„ë£Œ: {bbox} â†’ {cropped.size}")
        return cropped
        
    except Exception as e:
        logger.error(f"âŒ ì´ë¯¸ì§€ í¬ë¡­ ì‹¤íŒ¨: {e}")
        return image

def pad_image(image: Any, padding: Union[int, Tuple[int, int, int, int]], 
             fill_color: Tuple[int, int, int] = (0, 0, 0)) -> Optional[Any]:
    """
    ì´ë¯¸ì§€ íŒ¨ë”© ì¶”ê°€
    
    Args:
        image: ì…ë ¥ ì´ë¯¸ì§€
        padding: íŒ¨ë”© í¬ê¸° (ì „ì²´) ë˜ëŠ” (left, top, right, bottom)
        fill_color: íŒ¨ë”© ìƒ‰ìƒ
    
    Returns:
        íŒ¨ë”©ì´ ì¶”ê°€ëœ ì´ë¯¸ì§€
    """
    try:
        pil_image = convert_to_pil(image)
        if pil_image is None:
            return None
        
        # íŒ¨ë”© ê°’ ì •ê·œí™”
        if isinstance(padding, int):
            padding = (padding, padding, padding, padding)
        elif len(padding) == 2:
            padding = (padding[0], padding[1], padding[0], padding[1])
        
        left, top, right, bottom = padding
        
        # ìƒˆ í¬ê¸° ê³„ì‚°
        old_width, old_height = pil_image.size
        new_width = old_width + left + right
        new_height = old_height + top + bottom
        
        # ìƒˆ ì´ë¯¸ì§€ ìƒì„±
        padded = Image.new(pil_image.mode, (new_width, new_height), fill_color)
        
        # ì›ë³¸ ì´ë¯¸ì§€ ë¶™ì´ê¸°
        padded.paste(pil_image, (left, top))
        
        logger.debug(f"âœ… ì´ë¯¸ì§€ íŒ¨ë”© ì™„ë£Œ: {padding}")
        return padded
        
    except Exception as e:
        logger.error(f"âŒ ì´ë¯¸ì§€ íŒ¨ë”© ì‹¤íŒ¨: {e}")
        return image

# =============================================================================
# ğŸ”¥ 7. ì´ë¯¸ì§€ ì •ê·œí™” ë° ì „ì²˜ë¦¬ í•¨ìˆ˜ë“¤
# =============================================================================

def normalize_image(image: Any, mean: Tuple[float, float, float] = (0.485, 0.456, 0.406), 
                   std: Tuple[float, float, float] = (0.229, 0.224, 0.225)) -> Optional[Any]:
    """
    ì´ë¯¸ì§€ ì •ê·œí™” (ImageNet í‘œì¤€)
    
    Args:
        image: ì…ë ¥ ì´ë¯¸ì§€
        mean: í‰ê· ê°’ (ì±„ë„ë³„)
        std: í‘œì¤€í¸ì°¨ (ì±„ë„ë³„)
    
    Returns:
        ì •ê·œí™”ëœ ì´ë¯¸ì§€
    """
    try:
        if TORCH_AVAILABLE and torch.is_tensor(image):
            # PyTorch tensor ì •ê·œí™”
            normalized = image.clone().float()
            
            if normalized.dim() == 4:  # (N, C, H, W)
                for i in range(min(3, normalized.shape[1])):
                    normalized[:, i, :, :] = (normalized[:, i, :, :] - mean[i]) / std[i]
            elif normalized.dim() == 3:  # (C, H, W)
                for i in range(min(3, normalized.shape[0])):
                    normalized[i, :, :] = (normalized[i, :, :] - mean[i]) / std[i]
            
            return normalized
            
        elif NUMPY_AVAILABLE:
            # NumPy array ì •ê·œí™”
            array = convert_to_numpy(image)
            if array is None:
                return None
            
            normalized = array.astype(np.float32) / 255.0  # 0-1 ì •ê·œí™”
            
            # ImageNet ì •ê·œí™” ì ìš©
            if len(normalized.shape) == 3 and normalized.shape[2] >= 3:
                for i in range(3):
                    normalized[:, :, i] = (normalized[:, :, i] - mean[i]) / std[i]
            
            return normalized
        
        logger.warning("âš ï¸ ì •ê·œí™”ë¥¼ ìœ„í•´ PyTorch ë˜ëŠ” NumPyê°€ í•„ìš”í•©ë‹ˆë‹¤")
        return image
        
    except Exception as e:
        logger.error(f"âŒ ì´ë¯¸ì§€ ì •ê·œí™” ì‹¤íŒ¨: {e}")
        return image

def denormalize_image(image: Any, mean: Tuple[float, float, float] = (0.485, 0.456, 0.406), 
                     std: Tuple[float, float, float] = (0.229, 0.224, 0.225)) -> Optional[Any]:
    """
    ì´ë¯¸ì§€ ì—­ì •ê·œí™”
    
    Args:
        image: ì •ê·œí™”ëœ ì´ë¯¸ì§€
        mean: ì›ë˜ í‰ê· ê°’
        std: ì›ë˜ í‘œì¤€í¸ì°¨
    
    Returns:
        ì—­ì •ê·œí™”ëœ ì´ë¯¸ì§€
    """
    try:
        if TORCH_AVAILABLE and torch.is_tensor(image):
            # PyTorch tensor ì—­ì •ê·œí™”
            denormalized = image.clone().float()
            
            if denormalized.dim() == 4:  # (N, C, H, W)
                for i in range(min(3, denormalized.shape[1])):
                    denormalized[:, i, :, :] = denormalized[:, i, :, :] * std[i] + mean[i]
            elif denormalized.dim() == 3:  # (C, H, W)
                for i in range(min(3, denormalized.shape[0])):
                    denormalized[i, :, :] = denormalized[i, :, :] * std[i] + mean[i]
            
            # 0-1 ë²”ìœ„ë¡œ í´ë¦¬í•‘
            denormalized = torch.clamp(denormalized, 0, 1)
            return denormalized
            
        elif NUMPY_AVAILABLE:
            # NumPy array ì—­ì •ê·œí™”
            array = convert_to_numpy(image)
            if array is None:
                return None
            
            denormalized = array.copy().astype(np.float32)
            
            # ImageNet ì—­ì •ê·œí™” ì ìš©
            if len(denormalized.shape) == 3 and denormalized.shape[2] >= 3:
                for i in range(3):
                    denormalized[:, :, i] = denormalized[:, :, i] * std[i] + mean[i]
            
            # 0-1 ë²”ìœ„ë¡œ í´ë¦¬í•‘ í›„ 0-255ë¡œ ë³€í™˜
            denormalized = np.clip(denormalized, 0, 1) * 255
            return denormalized.astype(np.uint8)
        
        logger.warning("âš ï¸ ì—­ì •ê·œí™”ë¥¼ ìœ„í•´ PyTorch ë˜ëŠ” NumPyê°€ í•„ìš”í•©ë‹ˆë‹¤")
        return image
        
    except Exception as e:
        logger.error(f"âŒ ì´ë¯¸ì§€ ì—­ì •ê·œí™” ì‹¤íŒ¨: {e}")
        return image

def preprocess_image(image: Any, target_size: Tuple[int, int] = DEFAULT_IMAGE_SIZE,
                    device: str = None, normalize: bool = True, 
                    to_tensor: bool = True) -> Optional[Any]:
    """
    í†µí•© ì´ë¯¸ì§€ ì „ì²˜ë¦¬ í•¨ìˆ˜
    
    Args:
        image: ì…ë ¥ ì´ë¯¸ì§€ (íŒŒì¼ê²½ë¡œ, PIL, numpy, tensor)
        target_size: íƒ€ê²Ÿ í¬ê¸° (width, height)
        device: ë””ë°”ì´ìŠ¤ ("mps", "cuda", "cpu")
        normalize: ì •ê·œí™” ì—¬ë¶€
        to_tensor: tensorë¡œ ë³€í™˜ ì—¬ë¶€
    
    Returns:
        ì „ì²˜ë¦¬ëœ ì´ë¯¸ì§€
    """
    try:
        logger.debug(f"ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì‹œì‘: {type(image)} â†’ {target_size}")
        
        if device is None:
            device = _get_optimal_device()
        
        # 1. ì´ë¯¸ì§€ ë¡œë“œ/ë³€í™˜
        if isinstance(image, (str, Path)):
            pil_image = load_image(image)
        else:
            pil_image = convert_to_pil(image)
        
        if pil_image is None:
            logger.error("âŒ ì´ë¯¸ì§€ ë¡œë“œ/ë³€í™˜ ì‹¤íŒ¨")
            return None
        
        # 2. í¬ê¸° ì¡°ì •
        if pil_image.size != target_size:
            pil_image = resize_image(pil_image, target_size, keep_aspect_ratio=True)
        
        # 3. RGB ë³€í™˜
        if pil_image.mode != 'RGB':
            pil_image = pil_image.convert('RGB')
        
        # 4. tensor ë³€í™˜ ì—¬ë¶€ì— ë”°ë¥¸ ì²˜ë¦¬
        if to_tensor:
            if not _ensure_torch():
                logger.warning("âš ï¸ PyTorch ì—†ìŒ, NumPy array ë°˜í™˜")
                array = np.array(pil_image).astype(np.float32)
                if normalize:
                    array = array / 255.0
                return array
            
            # tensorë¡œ ë³€í™˜
            tensor = pil_to_tensor(pil_image, device, normalize)
            if tensor is None:
                logger.error("âŒ tensor ë³€í™˜ ì‹¤íŒ¨")
                return None
            
            logger.debug(f"âœ… ì „ì²˜ë¦¬ ì™„ë£Œ: {tensor.shape}, device: {device}")
            return tensor
        else:
            # PIL ë˜ëŠ” numpyë¡œ ë°˜í™˜
            if normalize:
                array = np.array(pil_image).astype(np.float32) / 255.0
                return array
            else:
                return pil_image
                
    except Exception as e:
        logger.error(f"âŒ ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        return None

# =============================================================================
# ğŸ”¥ 8. Base64 ë³€í™˜ í•¨ìˆ˜ë“¤
# =============================================================================

def image_to_base64(image: Any, format: str = "JPEG", quality: int = 95) -> str:
    """
    ì´ë¯¸ì§€ë¥¼ Base64 ë¬¸ìì—´ë¡œ ë³€í™˜
    
    Args:
        image: ì…ë ¥ ì´ë¯¸ì§€
        format: ì €ì¥ í¬ë§·
        quality: ì••ì¶• í’ˆì§ˆ
    
    Returns:
        Base64 ë¬¸ìì—´
    """
    try:
        if not _ensure_pil():
            return ""
        
        pil_image = convert_to_pil(image)
        if pil_image is None:
            logger.error("âŒ PIL ë³€í™˜ ì‹¤íŒ¨")
            return ""
        
        # RGB ë³€í™˜ (JPEG í˜¸í™˜ì„±)
        if format.upper() == 'JPEG' and pil_image.mode in ['RGBA', 'LA']:
            background = Image.new('RGB', pil_image.size, (255, 255, 255))
            if pil_image.mode == 'RGBA':
                background.paste(pil_image, mask=pil_image.split()[-1])
            else:
                background.paste(pil_image)
            pil_image = background
        
        # Base64 ë³€í™˜
        buffer = io.BytesIO()
        save_kwargs = {'format': format}
        if format.upper() in ['JPEG', 'WEBP']:
            save_kwargs['quality'] = quality
            save_kwargs['optimize'] = True
        
        pil_image.save(buffer, **save_kwargs)
        img_str = base64.b64encode(buffer.getvalue()).decode()
        
        logger.debug(f"âœ… Base64 ë³€í™˜ ì™„ë£Œ: {len(img_str)} ë¬¸ì")
        return img_str
        
    except Exception as e:
        logger.error(f"âŒ Base64 ë³€í™˜ ì‹¤íŒ¨: {e}")
        return ""

def base64_to_image(base64_str: str) -> Optional[Any]:
    """
    Base64 ë¬¸ìì—´ì„ ì´ë¯¸ì§€ë¡œ ë³€í™˜
    
    Args:
        base64_str: Base64 ë¬¸ìì—´
    
    Returns:
        PIL Image ë˜ëŠ” None
    """
    try:
        if not _ensure_pil():
            return None
        
        # Base64 ë””ì½”ë”©
        img_data = base64.b64decode(base64_str)
        img_buffer = io.BytesIO(img_data)
        pil_image = Image.open(img_buffer)
        
        # RGB ë³€í™˜
        if pil_image.mode != 'RGB':
            pil_image = pil_image.convert('RGB')
        
        logger.debug(f"âœ… Base64â†’ì´ë¯¸ì§€ ë³€í™˜ ì™„ë£Œ: {pil_image.size}")
        return pil_image
        
    except Exception as e:
        logger.error(f"âŒ Base64â†’ì´ë¯¸ì§€ ë³€í™˜ ì‹¤íŒ¨: {e}")
        return None

# =============================================================================
# ğŸ”¥ 9. ì´ë¯¸ì§€ í›„ì²˜ë¦¬ í•¨ìˆ˜ë“¤
# =============================================================================

def postprocess_segmentation(output: Any, threshold: float = 0.5) -> Optional[Any]:
    """
    ì„¸ê·¸ë©˜í…Œì´ì…˜ ê²°ê³¼ í›„ì²˜ë¦¬
    
    Args:
        output: ëª¨ë¸ ì¶œë ¥ (í™•ë¥  ë§µ)
        threshold: ì´ì§„í™” ì„ê³„ê°’
    
    Returns:
        ì´ì§„ ë§ˆìŠ¤í¬ (0-255)
    """
    try:
        logger.debug(f"ì„¸ê·¸ë©˜í…Œì´ì…˜ í›„ì²˜ë¦¬ ì‹œì‘: {type(output)}")
        
        # PyTorch tensor ì²˜ë¦¬
        if TORCH_AVAILABLE and torch.is_tensor(output):
            # CPUë¡œ ì´ë™
            if output.is_cuda or (hasattr(output, 'is_mps') and output.is_mps):
                output = output.cpu()
            
            # numpy ë³€í™˜
            if hasattr(output, 'detach'):
                output_np = output.detach().numpy()
            else:
                output_np = output.numpy()
        else:
            output_np = convert_to_numpy(output)
        
        if output_np is None:
            logger.error("âŒ NumPy ë³€í™˜ ì‹¤íŒ¨")
            return None
        
        # ì°¨ì› ì¡°ì •
        if output_np.ndim == 4:  # (N, C, H, W)
            output_np = output_np.squeeze(0)
        
        if output_np.ndim == 3:  # (C, H, W)
            if output_np.shape[0] == 1:
                output_np = output_np.squeeze(0)
            else:
                # ë‹¤ì¤‘ í´ë˜ìŠ¤ì¸ ê²½ìš° argmax
                output_np = np.argmax(output_np, axis=0)
                # ë°°ê²½(0) ì œì™¸í•œ ì˜ì—­ì„ 1ë¡œ ì„¤ì •
                output_np = (output_np > 0).astype(np.float32)
        
        # ì´ì§„í™”
        if output_np.dtype != np.uint8:
            binary_mask = (output_np > threshold).astype(np.uint8) * 255
        else:
            binary_mask = (output_np > int(threshold * 255)).astype(np.uint8) * 255
        
        logger.debug(f"âœ… í›„ì²˜ë¦¬ ì™„ë£Œ: {binary_mask.shape}, ë²”ìœ„: {binary_mask.min()}-{binary_mask.max()}")
        return binary_mask
        
    except Exception as e:
        logger.error(f"âŒ ì„¸ê·¸ë©˜í…Œì´ì…˜ í›„ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        return None

def postprocess_pose_keypoints(output: Any, confidence_threshold: float = 0.3) -> Dict[str, Any]:
    """
    í¬ì¦ˆ í‚¤í¬ì¸íŠ¸ í›„ì²˜ë¦¬
    
    Args:
        output: íˆíŠ¸ë§µ ì¶œë ¥ (C, H, W)
        confidence_threshold: ì‹ ë¢°ë„ ì„ê³„ê°’
    
    Returns:
        í‚¤í¬ì¸íŠ¸ ì •ë³´ ë”•ì…”ë„ˆë¦¬
    """
    try:
        result = {
            "keypoints": [],
            "connections": [],
            "valid_keypoints": 0,
            "confidence_scores": []
        }
        
        if not _ensure_numpy():
            return result
        
        # NumPyë¡œ ë³€í™˜
        if TORCH_AVAILABLE and torch.is_tensor(output):
            if output.is_cuda or (hasattr(output, 'is_mps') and output.is_mps):
                output = output.cpu()
            heatmaps = output.detach().numpy()
        else:
            heatmaps = convert_to_numpy(output)
        
        if heatmaps is None:
            return result
        
        # ì°¨ì› ì¡°ì •
        if heatmaps.ndim == 4:  # (N, C, H, W)
            heatmaps = heatmaps.squeeze(0)
        
        num_keypoints = min(heatmaps.shape[0], 18)  # COCO 18ê°œ í‚¤í¬ì¸íŠ¸
        height, width = heatmaps.shape[1], heatmaps.shape[2]
        
        # ê° í‚¤í¬ì¸íŠ¸ ìœ„ì¹˜ ì°¾ê¸°
        keypoints = []
        confidence_scores = []
        
        for i in range(num_keypoints):
            heatmap = heatmaps[i]
            
            # ìµœëŒ€ê°’ ìœ„ì¹˜ ì°¾ê¸°
            max_val = np.max(heatmap)
            if max_val > confidence_threshold:
                max_idx = np.unravel_index(np.argmax(heatmap), heatmap.shape)
                y, x = max_idx
                
                keypoints.append((int(x), int(y), float(max_val)))
                confidence_scores.append(float(max_val))
            else:
                keypoints.append((0, 0, 0.0))
                confidence_scores.append(0.0)
        
        # COCO í‚¤í¬ì¸íŠ¸ ì—°ê²° ì •ì˜
        connections = [
            (0, 1), (1, 2), (2, 3), (3, 4),     # ë¨¸ë¦¬
            (1, 5), (5, 6), (6, 7),             # ì™¼íŒ”
            (1, 8), (8, 9), (9, 10),            # ì˜¤ë¥¸íŒ”
            (1, 11), (11, 12), (12, 13),        # ì™¼ë‹¤ë¦¬
            (1, 14), (14, 15), (15, 16)         # ì˜¤ë¥¸ë‹¤ë¦¬
        ]
        
        # ìœ íš¨í•œ ì—°ê²°ë§Œ í•„í„°ë§
        valid_connections = []
        for conn in connections:
            if (conn[0] < len(keypoints) and conn[1] < len(keypoints) and 
                keypoints[conn[0]][2] > confidence_threshold and 
                keypoints[conn[1]][2] > confidence_threshold):
                valid_connections.append(conn)
        
        result.update({
            "keypoints": keypoints,
            "connections": valid_connections,
            "valid_keypoints": sum(1 for kp in keypoints if kp[2] > confidence_threshold),
            "confidence_scores": confidence_scores
        })
        
        logger.debug(f"âœ… í¬ì¦ˆ í›„ì²˜ë¦¬ ì™„ë£Œ: {result['valid_keypoints']}ê°œ ìœ íš¨ í‚¤í¬ì¸íŠ¸")
        return result
        
    except Exception as e:
        logger.error(f"âŒ í¬ì¦ˆ í›„ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        return result

# =============================================================================
# ğŸ”¥ 10. ì´ë¯¸ì§€ í’ˆì§ˆ í–¥ìƒ í•¨ìˆ˜ë“¤
# =============================================================================

def enhance_image_contrast(image: Any, factor: float = 1.2) -> Optional[Any]:
    """ì´ë¯¸ì§€ ëŒ€ë¹„ í–¥ìƒ"""
    try:
        if not _ensure_pil():
            return image
        
        pil_image = convert_to_pil(image)
        if pil_image is None:
            return image
        
        enhancer = ImageEnhance.Contrast(pil_image)
        enhanced = enhancer.enhance(factor)
        
        logger.debug(f"âœ… ëŒ€ë¹„ í–¥ìƒ: factor={factor}")
        return enhanced
        
    except Exception as e:
        logger.error(f"âŒ ëŒ€ë¹„ í–¥ìƒ ì‹¤íŒ¨: {e}")
        return image

def enhance_image_brightness(image: Any, factor: float = 1.1) -> Optional[Any]:
    """ì´ë¯¸ì§€ ë°ê¸° í–¥ìƒ"""
    try:
        if not _ensure_pil():
            return image
        
        pil_image = convert_to_pil(image)
        if pil_image is None:
            return image
        
        enhancer = ImageEnhance.Brightness(pil_image)
        enhanced = enhancer.enhance(factor)
        
        logger.debug(f"âœ… ë°ê¸° í–¥ìƒ: factor={factor}")
        return enhanced
        
    except Exception as e:
        logger.error(f"âŒ ë°ê¸° í–¥ìƒ ì‹¤íŒ¨: {e}")
        return image

def enhance_image_sharpness(image: Any, factor: float = 1.1) -> Optional[Any]:
    """ì´ë¯¸ì§€ ì„ ëª…ë„ í–¥ìƒ"""
    try:
        if not _ensure_pil():
            return image
        
        pil_image = convert_to_pil(image)
        if pil_image is None:
            return image
        
        enhancer = ImageEnhance.Sharpness(pil_image)
        enhanced = enhancer.enhance(factor)
        
        logger.debug(f"âœ… ì„ ëª…ë„ í–¥ìƒ: factor={factor}")
        return enhanced
        
    except Exception as e:
        logger.error(f"âŒ ì„ ëª…ë„ í–¥ìƒ ì‹¤íŒ¨: {e}")
        return image

def apply_gaussian_blur(image: Any, radius: float = 1.0) -> Optional[Any]:
    """ê°€ìš°ì‹œì•ˆ ë¸”ëŸ¬ ì ìš©"""
    try:
        if not _ensure_pil():
            return image
        
        pil_image = convert_to_pil(image)
        if pil_image is None:
            return image
        
        blurred = pil_image.filter(ImageFilter.GaussianBlur(radius=radius))
        
        logger.debug(f"âœ… ê°€ìš°ì‹œì•ˆ ë¸”ëŸ¬: radius={radius}")
        return blurred
        
    except Exception as e:
        logger.error(f"âŒ ê°€ìš°ì‹œì•ˆ ë¸”ëŸ¬ ì‹¤íŒ¨: {e}")
        return image

# =============================================================================
# ğŸ”¥ 11. ê³ ê¸‰ ì´ë¯¸ì§€ ì²˜ë¦¬ í•¨ìˆ˜ë“¤
# =============================================================================

def apply_clahe_enhancement(image: Any, clip_limit: float = 2.0, 
                           tile_grid_size: Tuple[int, int] = (8, 8)) -> Optional[Any]:
    """CLAHE (ëŒ€ë¹„ ì œí•œ ì ì‘ íˆìŠ¤í† ê·¸ë¨ í‰í™œí™”) ì ìš©"""
    try:
        if not CV2_AVAILABLE or not _ensure_numpy():
            logger.warning("âš ï¸ OpenCV ë˜ëŠ” NumPy í•„ìš”")
            return image
        
        array = convert_to_numpy(image)
        if array is None:
            return image
        
        # CLAHE ê°ì²´ ìƒì„±
        clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=tile_grid_size)
        
        # ì»¬ëŸ¬ ì´ë¯¸ì§€ì¸ ê²½ìš° LAB ê³µê°„ì—ì„œ ì²˜ë¦¬
        if len(array.shape) == 3 and array.shape[2] == 3:
            # RGB â†’ LAB ë³€í™˜
            lab = cv2.cvtColor(array, cv2.COLOR_RGB2LAB)
            lab[:, :, 0] = clahe.apply(lab[:, :, 0])  # L ì±„ë„ì—ë§Œ ì ìš©
            enhanced = cv2.cvtColor(lab, cv2.COLOR_LAB2RGB)
        elif len(array.shape) == 2:
            # ê·¸ë ˆì´ìŠ¤ì¼€ì¼
            enhanced = clahe.apply(array)
        else:
            logger.warning("âš ï¸ ì§€ì›í•˜ì§€ ì•ŠëŠ” ì´ë¯¸ì§€ í˜•íƒœ")
            return image
        
        # PIL Imageë¡œ ë³€í™˜
        if _ensure_pil():
            return Image.fromarray(enhanced)
        else:
            return enhanced
            
    except Exception as e:
        logger.error(f"âŒ CLAHE ì ìš© ì‹¤íŒ¨: {e}")
        return image

def detect_dominant_colors(image: Any, k: int = 5) -> List[Tuple[int, int, int]]:
    """ì´ë¯¸ì§€ì—ì„œ ì£¼ìš” ìƒ‰ìƒ kê°œ ì¶”ì¶œ"""
    try:
        if not _ensure_numpy():
            return []
        
        array = convert_to_numpy(image)
        if array is None or len(array.shape) != 3:
            return []
        
        # í”½ì…€ì„ 1ì°¨ì›ìœ¼ë¡œ ë³€í™˜
        pixels = array.reshape((-1, 3))
        
        # ê³ ìœ  ìƒ‰ìƒê³¼ ê°œìˆ˜ ê³„ì‚°
        unique_colors, counts = np.unique(
            pixels.view(np.dtype((np.void, pixels.dtype.itemsize * pixels.shape[1]))), 
            return_counts=True
        )
        
        # ìƒìœ„ kê°œ ìƒ‰ìƒ ì¶”ì¶œ
        top_indices = np.argsort(counts)[-k:][::-1]
        dominant_colors = []
        
        for idx in top_indices:
            color_bytes = unique_colors[idx].view(pixels.dtype).reshape(pixels.shape[1])
            dominant_colors.append(tuple(color_bytes.astype(int)))
        
        logger.debug(f"âœ… ì£¼ìš” ìƒ‰ìƒ {k}ê°œ ì¶”ì¶œ ì™„ë£Œ")
        return dominant_colors
        
    except Exception as e:
        logger.error(f"âŒ ì£¼ìš” ìƒ‰ìƒ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
        return []

def calculate_image_similarity(image1: Any, image2: Any, method: str = "mse") -> float:
    """ë‘ ì´ë¯¸ì§€ ê°„ì˜ ìœ ì‚¬ë„ ê³„ì‚°"""
    try:
        if not _ensure_numpy():
            return 0.0
        
        # ì´ë¯¸ì§€ë“¤ì„ numpy arrayë¡œ ë³€í™˜
        arr1 = convert_to_numpy(image1)
        arr2 = convert_to_numpy(image2)
        
        if arr1 is None or arr2 is None:
            return 0.0
        
        # í¬ê¸° ë§ì¶”ê¸° (ë” ì‘ì€ í¬ê¸°ë¡œ)
        if arr1.shape != arr2.shape:
            min_h = min(arr1.shape[0], arr2.shape[0])
            min_w = min(arr1.shape[1], arr2.shape[1])
            
            if len(arr1.shape) == 3:
                arr1 = arr1[:min_h, :min_w, :]
                arr2 = arr2[:min_h, :min_w, :]
            else:
                arr1 = arr1[:min_h, :min_w]
                arr2 = arr2[:min_h, :min_w]
        
        # ìœ ì‚¬ë„ ê³„ì‚°
        if method == "mse":
            # Mean Squared Error (ë‚®ì„ìˆ˜ë¡ ìœ ì‚¬)
            mse = np.mean((arr1.astype(float) - arr2.astype(float)) ** 2)
            similarity = 1.0 / (1.0 + mse / 255.0)
        elif method == "cosine":
            # ì½”ì‚¬ì¸ ìœ ì‚¬ë„
            arr1_flat = arr1.flatten().astype(float)
            arr2_flat = arr2.flatten().astype(float)
            
            dot_product = np.dot(arr1_flat, arr2_flat)
            norm1 = np.linalg.norm(arr1_flat)
            norm2 = np.linalg.norm(arr2_flat)
            
            if norm1 == 0 or norm2 == 0:
                similarity = 0.0
            else:
                similarity = dot_product / (norm1 * norm2)
        else:
            logger.warning(f"âš ï¸ ì§€ì›í•˜ì§€ ì•ŠëŠ” ìœ ì‚¬ë„ ë°©ë²•: {method}")
            return 0.0
        
        logger.debug(f"âœ… ì´ë¯¸ì§€ ìœ ì‚¬ë„: {similarity:.3f} ({method})")
        return float(similarity)
        
    except Exception as e:
        logger.error(f"âŒ ì´ë¯¸ì§€ ìœ ì‚¬ë„ ê³„ì‚° ì‹¤íŒ¨: {e}")
        return 0.0

# =============================================================================
# ğŸ”¥ 12. ì‹œê°í™” ë° ë””ë²„ê¹… í•¨ìˆ˜ë“¤
# =============================================================================

def create_image_grid(images: List[Any], grid_size: Optional[Tuple[int, int]] = None, 
                     padding: int = 2, background_color: Tuple[int, int, int] = (255, 255, 255)) -> Optional[Any]:
    """ì´ë¯¸ì§€ë“¤ì„ ê²©ìë¡œ ë°°ì—´"""
    try:
        if not _ensure_pil() or not images:
            return None
        
        # ê²©ì í¬ê¸° ìë™ ê³„ì‚°
        if grid_size is None:
            grid_cols = int(math.ceil(math.sqrt(len(images))))
            grid_rows = int(math.ceil(len(images) / grid_cols))
        else:
            grid_rows, grid_cols = grid_size
        
        # ëª¨ë“  ì´ë¯¸ì§€ë¥¼ PILë¡œ ë³€í™˜
        pil_images = []
        for img in images:
            pil_img = convert_to_pil(img)
            if pil_img:
                pil_images.append(pil_img)
        
        if not pil_images:
            return None
        
        # ìµœëŒ€ í¬ê¸° ê³„ì‚°
        max_width = max(img.width for img in pil_images)
        max_height = max(img.height for img in pil_images)
        
        # ëª¨ë“  ì´ë¯¸ì§€ë¥¼ ê°™ì€ í¬ê¸°ë¡œ ì¡°ì •
        resized_images = []
        for img in pil_images:
            resized = img.resize((max_width, max_height), Image.Resampling.LANCZOS)
            resized_images.append(resized)
        
        # ê²©ì ì´ë¯¸ì§€ ìƒì„±
        grid_width = grid_cols * max_width + (grid_cols + 1) * padding
        grid_height = grid_rows * max_height + (grid_rows + 1) * padding
        
        grid_image = Image.new('RGB', (grid_width, grid_height), background_color)
        
        # ì´ë¯¸ì§€ë“¤ ë°°ì¹˜
        for i, img in enumerate(resized_images):
            if i >= grid_rows * grid_cols:
                break
            
            row = i // grid_cols
            col = i % grid_cols
            
            x = col * (max_width + padding) + padding
            y = row * (max_height + padding) + padding
            
            grid_image.paste(img, (x, y))
        
        logger.debug(f"âœ… ì´ë¯¸ì§€ ê²©ì ìƒì„±: {grid_size}, {len(resized_images)}ê°œ")
        return grid_image
        
    except Exception as e:
        logger.error(f"âŒ ì´ë¯¸ì§€ ê²©ì ìƒì„± ì‹¤íŒ¨: {e}")
        return None

def add_text_to_image(image: Any, text: str, position: Tuple[int, int] = (10, 10), 
                     font_size: int = 20, color: Tuple[int, int, int] = (0, 0, 0)) -> Optional[Any]:
    """ì´ë¯¸ì§€ì— í…ìŠ¤íŠ¸ ì¶”ê°€"""
    try:
        if not _ensure_pil():
            return image
        
        pil_image = convert_to_pil(image)
        if pil_image is None:
            return image
        
        # ë³µì‚¬ë³¸ ìƒì„±
        result = pil_image.copy()
        draw = ImageDraw.Draw(result)
        
        # í°íŠ¸ ì„¤ì •
        try:
            # ì‹œìŠ¤í…œ í°íŠ¸ ì‹œë„
            font = ImageFont.truetype("arial.ttf", font_size)
        except:
            try:
                font = ImageFont.load_default()
            except:
                font = None
        
        # í…ìŠ¤íŠ¸ ì¶”ê°€
        draw.text(position, text, fill=color, font=font)
        
        logger.debug(f"âœ… í…ìŠ¤íŠ¸ ì¶”ê°€: '{text}' at {position}")
        return result
        
    except Exception as e:
        logger.error(f"âŒ í…ìŠ¤íŠ¸ ì¶”ê°€ ì‹¤íŒ¨: {e}")
        return image

def create_comparison_image(image1: Any, image2: Any, 
                          labels: Tuple[str, str] = ("Original", "Processed")) -> Optional[Any]:
    """ë‘ ì´ë¯¸ì§€ë¥¼ ë‚˜ë€íˆ ë¹„êµí•˜ëŠ” ì´ë¯¸ì§€ ìƒì„±"""
    try:
        if not _ensure_pil():
            return None
        
        pil1 = convert_to_pil(image1)
        pil2 = convert_to_pil(image2)
        
        if pil1 is None or pil2 is None:
            return None
        
        # ê°™ì€ í¬ê¸°ë¡œ ì¡°ì •
        max_width = max(pil1.width, pil2.width)
        max_height = max(pil1.height, pil2.height)
        
        pil1 = pil1.resize((max_width, max_height), Image.Resampling.LANCZOS)
        pil2 = pil2.resize((max_width, max_height), Image.Resampling.LANCZOS)
        
        # ë¹„êµ ì´ë¯¸ì§€ ìƒì„±
        padding = 20
        text_height = 30
        
        comparison_width = max_width * 2 + padding * 3
        comparison_height = max_height + text_height + padding * 2
        
        comparison = Image.new('RGB', (comparison_width, comparison_height), (255, 255, 255))
        
        # ì´ë¯¸ì§€ë“¤ ë°°ì¹˜
        comparison.paste(pil1, (padding, text_height + padding))
        comparison.paste(pil2, (max_width + padding * 2, text_height + padding))
        
        # ë¼ë²¨ ì¶”ê°€
        comparison = add_text_to_image(comparison, labels[0], (padding, 5))
        comparison = add_text_to_image(comparison, labels[1], (max_width + padding * 2, 5))
        
        logger.debug(f"âœ… ë¹„êµ ì´ë¯¸ì§€ ìƒì„±: {labels}")
        return comparison
        
    except Exception as e:
        logger.error(f"âŒ ë¹„êµ ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨: {e}")
        return None

# =============================================================================
# ğŸ”¥ 13. ë©”ëª¨ë¦¬ ê´€ë¦¬ ë° ìµœì í™” í•¨ìˆ˜ë“¤
# =============================================================================

def cleanup_image_memory() -> bool:
    """ì´ë¯¸ì§€ ì²˜ë¦¬ ê´€ë ¨ ë©”ëª¨ë¦¬ ì •ë¦¬"""
    try:
        logger.debug("ì´ë¯¸ì§€ ë©”ëª¨ë¦¬ ì •ë¦¬ ì‹œì‘")
        
        # Python garbage collection
        import gc
        collected = gc.collect()
        
        # PyTorch ìºì‹œ ì •ë¦¬
        if TORCH_AVAILABLE:
            if hasattr(torch, 'cuda') and torch.cuda.is_available():
                torch.cuda.empty_cache()
                logger.debug("CUDA ìºì‹œ ì •ë¦¬")
            
            if hasattr(torch, 'mps') and hasattr(torch.mps, 'empty_cache'):
                try:
                    torch.mps.empty_cache()
                    logger.debug("MPS ìºì‹œ ì •ë¦¬")
                except:
                    pass
        
        logger.info(f"âœ… ë©”ëª¨ë¦¬ ì •ë¦¬ ì™„ë£Œ: {collected}ê°œ ê°ì²´ ìˆ˜ì§‘")
        return True
        
    except Exception as e:
        logger.error(f"âŒ ë©”ëª¨ë¦¬ ì •ë¦¬ ì‹¤íŒ¨: {e}")
        return False

def estimate_memory_usage(image: Any) -> Dict[str, float]:
    """ì´ë¯¸ì§€ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¶”ì •"""
    try:
        usage = {"bytes": 0, "mb": 0, "gb": 0}
        
        if hasattr(image, 'size') and hasattr(image, 'mode'):  # PIL Image
            width, height = image.size
            channels = len(image.getbands())
            bytes_per_pixel = 1 if image.mode == 'L' else 3 if image.mode == 'RGB' else 4
            total_bytes = width * height * bytes_per_pixel
            
        elif NUMPY_AVAILABLE and hasattr(image, 'nbytes'):  # NumPy array
            total_bytes = image.nbytes
            
        elif TORCH_AVAILABLE and torch.is_tensor(image):  # PyTorch tensor
            total_bytes = image.numel() * image.element_size()
            
        else:
            logger.warning("âš ï¸ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ê³„ì‚° ë¶ˆê°€")
            return usage
        
        usage.update({
            "bytes": total_bytes,
            "mb": total_bytes / (1024 * 1024),
            "gb": total_bytes / (1024 * 1024 * 1024)
        })
        
        logger.debug(f"ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {usage['mb']:.2f} MB")
        return usage
        
    except Exception as e:
        logger.error(f"âŒ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ê³„ì‚° ì‹¤íŒ¨: {e}")
        return {"bytes": 0, "mb": 0, "gb": 0, "error": str(e)}

def optimize_image_memory(image: Any, target_size: Optional[Tuple[int, int]] = None, 
                         quality: int = 85) -> Optional[Any]:
    """ì´ë¯¸ì§€ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ìµœì í™”"""
    try:
        if not _ensure_pil():
            return image
        
        pil_image = convert_to_pil(image)
        if pil_image is None:
            return image
        
        # í¬ê¸° ì¡°ì •
        if target_size and pil_image.size != target_size:
            pil_image = resize_image(pil_image, target_size, keep_aspect_ratio=True)
        
        # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì²´í¬
        memory_usage = estimate_memory_usage(pil_image)
        
        # ì„ê³„ê°’ ì´ˆê³¼ì‹œ ì••ì¶• ì ìš©
        if memory_usage['mb'] > MEMORY_THRESHOLD_MB:
            # JPEG ì••ì¶• ì ìš©
            buffer = io.BytesIO()
            if pil_image.mode == 'RGBA':
                # íˆ¬ëª…ë„ ì œê±°
                background = Image.new('RGB', pil_image.size, (255, 255, 255))
                background.paste(pil_image, mask=pil_image.split()[-1])
                pil_image = background
            
            pil_image.save(buffer, format='JPEG', quality=quality, optimize=True)
            buffer.seek(0)
            pil_image = Image.open(buffer)
            
            logger.debug(f"âœ… ë©”ëª¨ë¦¬ ìµœì í™” ì ìš©: quality={quality}")
        
        return pil_image
        
    except Exception as e:
        logger.error(f"âŒ ë©”ëª¨ë¦¬ ìµœì í™” ì‹¤íŒ¨: {e}")
        return image

def validate_image_format(image: Any) -> Dict[str, Any]:
    """ì´ë¯¸ì§€ í¬ë§· ë° ì†ì„± ê²€ì¦"""
    try:
        result = {
            "valid": False,
            "type": str(type(image)),
            "format": None,
            "size": None,
            "mode": None,
            "channels": None,
            "dtype": None,
            "memory_usage_mb": 0.0
        }
        
        if hasattr(image, 'size') and hasattr(image, 'mode'):  # PIL Image
            memory_usage = estimate_memory_usage(image)
            result.update({
                "valid": True,
                "format": "PIL",
                "size": image.size,
                "mode": image.mode,
                "channels": len(image.getbands()),
                "memory_usage_mb": memory_usage['mb']
            })
            
        elif NUMPY_AVAILABLE and isinstance(image, np.ndarray):  # NumPy array
            memory_usage = estimate_memory_usage(image)
            result.update({
                "valid": True,
                "format": "NumPy",
                "size": (image.shape[1], image.shape[0]) if len(image.shape) >= 2 else image.shape,
                "channels": image.shape[2] if len(image.shape) == 3 else 1,
                "dtype": str(image.dtype),
                "memory_usage_mb": memory_usage['mb']
            })
            
        elif TORCH_AVAILABLE and torch.is_tensor(image):  # PyTorch tensor
            memory_usage = estimate_memory_usage(image)
            result.update({
                "valid": True,
                "format": "PyTorch",
                "size": (image.shape[-1], image.shape[-2]) if len(image.shape) >= 2 else image.shape,
                "channels": image.shape[-3] if len(image.shape) >= 3 else 1,
                "dtype": str(image.dtype),
                "memory_usage_mb": memory_usage['mb']
            })
        
        logger.debug(f"ì´ë¯¸ì§€ ê²€ì¦: {result}")
        return result
        
    except Exception as e:
        logger.error(f"âŒ ì´ë¯¸ì§€ ê²€ì¦ ì‹¤íŒ¨: {e}")
        return {"valid": False, "error": str(e)}

# =============================================================================
# ğŸ”¥ 14. Stepë³„ íŠ¹í™” ì²˜ë¦¬ í•¨ìˆ˜ë“¤
# =============================================================================

def preprocess_pose_input(image: Any, target_size: Tuple[int, int] = (368, 368)) -> Optional[Any]:
    """í¬ì¦ˆ ì¶”ì •ìš© ì´ë¯¸ì§€ ì „ì²˜ë¦¬"""
    return preprocess_image(image, target_size, normalize=True, to_tensor=True)

def preprocess_human_parsing_input(image: Any, target_size: Tuple[int, int] = (512, 512)) -> Optional[Any]:
    """ì¸ì²´ íŒŒì‹±ìš© ì´ë¯¸ì§€ ì „ì²˜ë¦¬"""
    return preprocess_image(image, target_size, normalize=True, to_tensor=True)

def preprocess_cloth_segmentation_input(image: Any, target_size: Tuple[int, int] = (320, 320)) -> Optional[Any]:
    """ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ìš© ì´ë¯¸ì§€ ì „ì²˜ë¦¬"""
    return preprocess_image(image, target_size, normalize=True, to_tensor=True)

def preprocess_virtual_fitting_input(person_img: Any, cloth_img: Any, 
                                   target_size: Tuple[int, int] = (512, 512)) -> Tuple[Optional[Any], Optional[Any]]:
    """ê°€ìƒ í”¼íŒ…ìš© ì´ë¯¸ì§€ ì „ì²˜ë¦¬"""
    person_tensor = preprocess_image(person_img, target_size, normalize=True, to_tensor=True)
    cloth_tensor = preprocess_image(cloth_img, target_size, normalize=True, to_tensor=True)
    return person_tensor, cloth_tensor

def postprocess_human_parsing(output: Any, num_classes: int = 20, 
                             colormap: Optional[List[Tuple[int, int, int]]] = None) -> Optional[Any]:
    """ì¸ì²´ íŒŒì‹± ê²°ê³¼ í›„ì²˜ë¦¬ (ì»¬ëŸ¬ë§µ ì ìš©)"""
    try:
        if not _ensure_numpy():
            return output
        
        # ì¶œë ¥ì„ numpy arrayë¡œ ë³€í™˜
        if TORCH_AVAILABLE and torch.is_tensor(output):
            if output.is_cuda or (hasattr(output, 'is_mps') and output.is_mps):
                output = output.cpu()
            pred = output.detach().numpy()
        else:
            pred = convert_to_numpy(output)
        
        if pred is None:
            return output
        
        # ì°¨ì› ì¡°ì •
        if pred.ndim == 4:  # (N, C, H, W)
            pred = pred.squeeze(0)
        if pred.ndim == 3:  # (C, H, W)
            pred = np.argmax(pred, axis=0)
        
        # ê¸°ë³¸ ì»¬ëŸ¬ë§µ ìƒì„±
        if colormap is None:
            colormap = []
            for i in range(num_classes):
                if i == 0:  # ë°°ê²½ì€ ê²€ì€ìƒ‰
                    colormap.append((0, 0, 0))
                else:
                    # HSV ìƒ‰ê³µê°„ì—ì„œ ê· ë“± ë¶„í¬
                    hue = int(i * 360 / num_classes)
                    # ê°„ë‹¨í•œ HSV to RGB ë³€í™˜
                    c, x = 255, int(255 * (1 - abs((hue / 60) % 2 - 1)))
                    if 0 <= hue < 60: rgb = (c, x, 0)
                    elif 60 <= hue < 120: rgb = (x, c, 0)
                    elif 120 <= hue < 180: rgb = (0, c, x)
                    elif 180 <= hue < 240: rgb = (0, x, c)
                    elif 240 <= hue < 300: rgb = (x, 0, c)
                    else: rgb = (c, 0, x)
                    colormap.append(rgb)
        
        # ì»¬ëŸ¬ë§µ ì ìš©
        height, width = pred.shape
        colored = np.zeros((height, width, 3), dtype=np.uint8)
        
        for class_id in range(min(num_classes, len(colormap))):
            mask = (pred == class_id)
            colored[mask] = colormap[class_id]
        
        logger.debug(f"âœ… ì¸ì²´ íŒŒì‹± í›„ì²˜ë¦¬ ì™„ë£Œ: {num_classes}ê°œ í´ë˜ìŠ¤")
        return colored
        
    except Exception as e:
        logger.error(f"âŒ ì¸ì²´ íŒŒì‹± í›„ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        return output

def create_pose_visualization(image: Any, keypoints_result: Dict[str, Any]) -> Optional[Any]:
    """í¬ì¦ˆ í‚¤í¬ì¸íŠ¸ ì‹œê°í™”"""
    try:
        if not _ensure_pil():
            return image
        
        pil_image = convert_to_pil(image)
        if pil_image is None:
            return image
        
        # ë³µì‚¬ë³¸ ìƒì„±
        vis_image = pil_image.copy()
        draw = ImageDraw.Draw(vis_image)
        
        keypoints = keypoints_result.get("keypoints", [])
        connections = keypoints_result.get("connections", [])
        
        # ì—°ê²°ì„  ê·¸ë¦¬ê¸°
        for conn in connections:
            if conn[0] < len(keypoints) and conn[1] < len(keypoints):
                pt1 = keypoints[conn[0]]
                pt2 = keypoints[conn[1]]
                
                if pt1[2] > 0 and pt2[2] > 0:  # ìœ íš¨í•œ í‚¤í¬ì¸íŠ¸ë“¤ë§Œ
                    draw.line([pt1[0], pt1[1], pt2[0], pt2[1]], 
                             fill=(0, 255, 0), width=3)
        
        # í‚¤í¬ì¸íŠ¸ ê·¸ë¦¬ê¸°
        for i, (x, y, conf) in enumerate(keypoints):
            if conf > 0:
                # ì‹ ë¢°ë„ì— ë”°ë¥¸ ìƒ‰ìƒ
                color = (255, int(255 * conf), 0)
                radius = 5
                
                # ì› ê·¸ë¦¬ê¸°
                draw.ellipse([x-radius, y-radius, x+radius, y+radius], 
                           fill=color, outline=(0, 0, 0), width=2)
        
        logger.debug("âœ… í¬ì¦ˆ ì‹œê°í™” ì™„ë£Œ")
        return vis_image
        
    except Exception as e:
        logger.error(f"âŒ í¬ì¦ˆ ì‹œê°í™” ì‹¤íŒ¨: {e}")
        return image

# =============================================================================
# ğŸ”¥ 15. ë°°ì¹˜ ì²˜ë¦¬ í•¨ìˆ˜ë“¤
# =============================================================================

def create_batch(images: List[Any], device: str = None) -> Optional[Any]:
    """ì´ë¯¸ì§€ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°°ì¹˜ í…ì„œë¡œ ë³€í™˜"""
    try:
        if not _ensure_torch() or not images:
            return None
        
        if device is None:
            device = _get_optimal_device()
        
        tensors = []
        for i, img in enumerate(images):
            if torch.is_tensor(img):
                tensor = img
                if tensor.dim() == 3:  # (C, H, W)
                    tensor = tensor.unsqueeze(0)  # (1, C, H, W)
            else:
                tensor = pil_to_tensor(img, device, normalize=True)
                if tensor is None:
                    continue
            
            tensors.append(tensor)
        
        if not tensors:
            return None
        
        # ë°°ì¹˜ë¡œ ê²°í•©
        batch = torch.cat(tensors, dim=0).to(device)
        
        logger.debug(f"âœ… ë°°ì¹˜ ìƒì„±: {batch.shape}, device: {device}")
        return batch
        
    except Exception as e:
        logger.error(f"âŒ ë°°ì¹˜ ìƒì„± ì‹¤íŒ¨: {e}")
        return None

def split_batch(batch: torch.Tensor) -> List[torch.Tensor]:
    """ë°°ì¹˜ í…ì„œë¥¼ ê°œë³„ í…ì„œë“¤ë¡œ ë¶„í• """
    try:
        if not TORCH_AVAILABLE or not torch.is_tensor(batch):
            return []
        
        if batch.dim() != 4:  # (N, C, H, W)
            logger.warning("âš ï¸ 4ì°¨ì› ë°°ì¹˜ í…ì„œê°€ ì•„ë‹™ë‹ˆë‹¤")
            return []
        
        tensors = [batch[i:i+1] for i in range(batch.shape[0])]
        
        logger.debug(f"âœ… ë°°ì¹˜ ë¶„í• : {len(tensors)}ê°œ í…ì„œ")
        return tensors
        
    except Exception as e:
        logger.error(f"âŒ ë°°ì¹˜ ë¶„í•  ì‹¤íŒ¨: {e}")
        return []

# =============================================================================
# ğŸ”¥ 16. ëª¨ë“ˆ ì •ë³´ ë° ë‚´ë³´ë‚´ê¸°
# =============================================================================

__version__ = "2.0.0"
__author__ = "MyCloset AI Team"
__description__ = "ì™„ì „í•œ ì´ë¯¸ì§€ ì²˜ë¦¬ ëª¨ë“ˆ - ì˜¬ë°”ë¥¸ Python êµ¬ì¡°"

# ëª¨ë“  ê³µê°œ í•¨ìˆ˜ë“¤
__all__ = [
    # ê¸°ë³¸ ì´ë¯¸ì§€ I/O
    'load_image',
    'save_image',
    
    # ì´ë¯¸ì§€ ë³€í™˜
    'convert_to_pil',
    'convert_to_numpy',
    'tensor_to_pil',
    'pil_to_tensor',
    
    # í¬ê¸° ë° í˜•íƒœ ì¡°ì •
    'resize_image',
    'crop_image',
    'pad_image',
    
    # ì •ê·œí™” ë° ì „ì²˜ë¦¬
    'normalize_image',
    'denormalize_image',
    'preprocess_image',
    
    # Base64 ë³€í™˜
    'image_to_base64',
    'base64_to_image',
    
    # í›„ì²˜ë¦¬
    'postprocess_segmentation',
    'postprocess_pose_keypoints',
    'postprocess_human_parsing',
    
    # í’ˆì§ˆ í–¥ìƒ
    'enhance_image_contrast',
    'enhance_image_brightness',
    'enhance_image_sharpness',
    'apply_gaussian_blur',
    
    # ê³ ê¸‰ ì²˜ë¦¬
    'apply_clahe_enhancement',
    'detect_dominant_colors',
    'calculate_image_similarity',
    
    # ì‹œê°í™”
    'create_image_grid',
    'add_text_to_image',
    'create_comparison_image',
    'create_pose_visualization',
    
    # ë©”ëª¨ë¦¬ ê´€ë¦¬
    'cleanup_image_memory',
    'estimate_memory_usage',
    'optimize_image_memory',
    'validate_image_format',
    
    # Stepë³„ íŠ¹í™”
    'preprocess_pose_input',
    'preprocess_human_parsing_input',
    'preprocess_cloth_segmentation_input',
    'preprocess_virtual_fitting_input',
    
    # ë°°ì¹˜ ì²˜ë¦¬
    'create_batch',
    'split_batch',
    
    # ìœ í‹¸ë¦¬í‹°
    '_get_optimal_device',
    '_validate_image_input',
    
    # ìƒìˆ˜
    'DEFAULT_IMAGE_SIZE',
    'DEFAULT_DEVICE',
    'SUPPORTED_FORMATS',
    'SUPPORTED_EXTENSIONS',
    'NUMPY_AVAILABLE',
    'PIL_AVAILABLE',
    'CV2_AVAILABLE',
    'TORCH_AVAILABLE'
]

# ì´ˆê¸°í™” ë¡œê·¸
logger.info(f"ğŸ–¼ï¸ ì´ë¯¸ì§€ ì²˜ë¦¬ ëª¨ë“ˆ v{__version__} ë¡œë“œ ì™„ë£Œ")
logger.info(f"ğŸ“¦ ì‚¬ìš© ê°€ëŠ¥í•œ í•¨ìˆ˜: {len(__all__)}ê°œ")
logger.info(f"ğŸ”§ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì§€ì› ìƒíƒœ:")
logger.info(f"   - NumPy: {'âœ…' if NUMPY_AVAILABLE else 'âŒ'}")
logger.info(f"   - PIL/Pillow: {'âœ…' if PIL_AVAILABLE else 'âŒ'}")
logger.info(f"   - OpenCV: {'âœ…' if CV2_AVAILABLE else 'âŒ'}")
logger.info(f"   - PyTorch: {'âœ…' if TORCH_AVAILABLE else 'âŒ'}")
logger.info(f"ğŸš€ ìµœì  ë””ë°”ì´ìŠ¤: {_get_optimal_device()}")

# =============================================================================
# ğŸ”¥ 17. ì‚¬ìš© ì˜ˆì‹œ (ì£¼ì„ìœ¼ë¡œ ë¬¸ì„œí™”)
# =============================================================================

"""
ğŸ¯ ì‚¬ìš© ì˜ˆì‹œ:

# 1. ê¸°ë³¸ ì´ë¯¸ì§€ ì²˜ë¦¬
from backend.app.ai_pipeline.utils.image_processing import (
    load_image, save_image, preprocess_image, postprocess_segmentation
)

# ì´ë¯¸ì§€ ë¡œë“œ ë° ì „ì²˜ë¦¬
image = load_image('input.jpg')
processed = preprocess_image(image, target_size=(512, 512), to_tensor=True)

# ì„¸ê·¸ë©˜í…Œì´ì…˜ í›„ì²˜ë¦¬
mask = postprocess_segmentation(model_output, threshold=0.5)

# 2. ì´ë¯¸ì§€ ë³€í™˜
from backend.app.ai_pipeline.utils.image_processing import (
    tensor_to_pil, pil_to_tensor, convert_to_numpy
)

pil_image = tensor_to_pil(tensor)
tensor = pil_to_tensor(pil_image, device='mps')
array = convert_to_numpy(image)

# 3. Base64 ë³€í™˜
from backend.app.ai_pipeline.utils.image_processing import (
    image_to_base64, base64_to_image
)

base64_str = image_to_base64(image, format='JPEG', quality=95)
image = base64_to_image(base64_str)

# 4. ë°°ì¹˜ ì²˜ë¦¬
from backend.app.ai_pipeline.utils.image_processing import create_batch

batch_tensor = create_batch([img1, img2, img3], device='mps')

# 5. ì´ë¯¸ì§€ í–¥ìƒ
from backend.app.ai_pipeline.utils.image_processing import (
    enhance_image_contrast, apply_clahe_enhancement
)

enhanced = enhance_image_contrast(image, factor=1.2)
clahe_enhanced = apply_clahe_enhancement(image, clip_limit=2.0)

# 6. Stepë³„ íŠ¹í™” ì²˜ë¦¬
from backend.app.ai_pipeline.utils.image_processing import (
    preprocess_pose_input, postprocess_human_parsing, create_pose_visualization
)

pose_input = preprocess_pose_input(image, target_size=(368, 368))
colored_parsing = postprocess_human_parsing(parsing_output, num_classes=20)
pose_vis = create_pose_visualization(image, keypoints_result)

# 7. ì‹œê°í™”
from backend.app.ai_pipeline.utils.image_processing import (
    create_image_grid, create_comparison_image, add_text_to_image
)

grid = create_image_grid([img1, img2, img3, img4], grid_size=(2, 2))
comparison = create_comparison_image(original, processed, ('Before', 'After'))
labeled = add_text_to_image(image, 'MyCloset AI', position=(10, 10))

# 8. ë©”ëª¨ë¦¬ ê´€ë¦¬
from backend.app.ai_pipeline.utils.image_processing import (
    cleanup_image_memory, estimate_memory_usage, optimize_image_memory
)

memory_info = estimate_memory_usage(image)
optimized = optimize_image_memory(image, target_size=(512, 512))
cleanup_image_memory()
"""