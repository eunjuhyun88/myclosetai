# app/ai_pipeline/utils/model_loader.py
"""
ğŸ M3 Max ìµœì í™” ì‹¤ì œ AI ëª¨ë¸ ë¡œë” - ìš°ë¦¬ êµ¬ì¡°ì— ìµœì í™”
- ìµœì  ìƒì„±ì íŒ¨í„´ ì ìš©
- 8ë‹¨ê³„ íŒŒì´í”„ë¼ì¸ì— í•„ìš”í•œ ëª¨ë“  ì‹¤ì œ AI ëª¨ë¸ë“¤
- M3 Max MPS ìµœì í™”
- ë©”ëª¨ë¦¬ íš¨ìœ¨ì  ëª¨ë¸ ë¡œë”©
"""

import os
import logging
import time
import threading
import asyncio
from pathlib import Path
from typing import Dict, Any, Optional, Union, List, Type, Callable
from abc import ABC, abstractmethod
import json
import pickle
from dataclasses import dataclass, field
from enum import Enum
import gc

# PyTorch import (ì•ˆì „)
try:
    import torch
    import torch.nn as nn
    import torch.nn.functional as F
    TORCH_AVAILABLE = True
except ImportError:
    TORCH_AVAILABLE = False
    torch = None
    nn = None

# ì»´í“¨í„° ë¹„ì „ ë¼ì´ë¸ŒëŸ¬ë¦¬ë“¤
try:
    import cv2
    import numpy as np
    from PIL import Image, ImageEnhance
    CV_AVAILABLE = True
except ImportError:
    CV_AVAILABLE = False

# ì™¸ë¶€ AI ë¼ì´ë¸ŒëŸ¬ë¦¬ë“¤ (ì„ íƒì )
try:
    import mediapipe as mp
    MEDIAPIPE_AVAILABLE = True
except ImportError:
    MEDIAPIPE_AVAILABLE = False

try:
    from transformers import AutoModel, AutoTokenizer
    TRANSFORMERS_AVAILABLE = True
except ImportError:
    TRANSFORMERS_AVAILABLE = False

try:
    from diffusers import StableDiffusionPipeline, UNet2DConditionModel
    DIFFUSERS_AVAILABLE = True
except ImportError:
    DIFFUSERS_AVAILABLE = False

try:
    import onnxruntime as ort
    ONNX_AVAILABLE = True
except ImportError:
    ONNX_AVAILABLE = False

try:
    import coremltools as ct
    COREML_AVAILABLE = True
except ImportError:
    COREML_AVAILABLE = False

# ìµœì  ìƒì„±ì ë² ì´ìŠ¤ í´ë˜ìŠ¤
class OptimalStepConstructor(ABC):
    """ìµœì í™”ëœ ìƒì„±ì íŒ¨í„´ ë² ì´ìŠ¤ í´ë˜ìŠ¤"""

    def __init__(
        self,
        device: Optional[str] = None,
        config: Optional[Dict[str, Any]] = None,
        **kwargs
    ):
        # 1. ì§€ëŠ¥ì  ë””ë°”ì´ìŠ¤ ìë™ ê°ì§€
        self.device = self._auto_detect_device(device)
        
        # 2. ê¸°ë³¸ ì„¤ì •
        self.config = config or {}
        self.step_name = self.__class__.__name__
        self.logger = logging.getLogger(f"utils.{self.step_name}")
        
        # 3. í‘œì¤€ ì‹œìŠ¤í…œ íŒŒë¼ë¯¸í„° ì¶”ì¶œ
        self.device_type = kwargs.get('device_type', 'auto')
        self.memory_gb = kwargs.get('memory_gb', 16.0)
        self.is_m3_max = kwargs.get('is_m3_max', self._detect_m3_max())
        self.optimization_enabled = kwargs.get('optimization_enabled', True)
        self.quality_level = kwargs.get('quality_level', 'balanced')
        
        # 4. ìŠ¤í…ë³„ íŠ¹í™” íŒŒë¼ë¯¸í„°ë¥¼ configì— ë³‘í•©
        self._merge_step_specific_config(kwargs)
        
        # 5. ìƒíƒœ ì´ˆê¸°í™”
        self.is_initialized = False

    def _auto_detect_device(self, preferred_device: Optional[str]) -> str:
        """ì§€ëŠ¥ì  ë””ë°”ì´ìŠ¤ ìë™ ê°ì§€"""
        if preferred_device:
            return preferred_device

        if not TORCH_AVAILABLE:
            return 'cpu'

        try:
            if torch.backends.mps.is_available():
                return 'mps'
            elif torch.cuda.is_available():
                return 'cuda'
            else:
                return 'cpu'
        except:
            return 'cpu'

    def _detect_m3_max(self) -> bool:
        """M3 Max ì¹© ìë™ ê°ì§€"""
        try:
            import platform
            import subprocess

            if platform.system() == 'Darwin':
                result = subprocess.run(['sysctl', '-n', 'machdep.cpu.brand_string'], 
                                      capture_output=True, text=True)
                return 'M3' in result.stdout
        except:
            pass
        return False

    def _merge_step_specific_config(self, kwargs: Dict[str, Any]):
        """ìŠ¤í…ë³„ íŠ¹í™” ì„¤ì • ë³‘í•©"""
        system_params = {
            'device_type', 'memory_gb', 'is_m3_max', 
            'optimization_enabled', 'quality_level'
        }

        for key, value in kwargs.items():
            if key not in system_params:
                self.config[key] = value

# ëª¨ë¸ íƒ€ì… enum
class ModelType(Enum):
    """AI ëª¨ë¸ íƒ€ì…"""
    HUMAN_PARSING = "human_parsing"  # Graphonomy, PGN
    POSE_ESTIMATION = "pose_estimation"  # OpenPose, MediaPipe
    CLOTH_SEGMENTATION = "cloth_segmentation"  # U2Net, SAM
    GEOMETRIC_MATCHING = "geometric_matching"  # TPS, GMM
    CLOTH_WARPING = "cloth_warping"  # HR-VITON, PF-AFN
    VIRTUAL_FITTING = "virtual_fitting"  # OOTD, DreamPose
    DIFFUSION = "diffusion"  # Stable Diffusion ê¸°ë°˜
    SEGMENTATION = "segmentation"  # ì¼ë°˜ ì„¸ê·¸ë©˜í…Œì´ì…˜

@dataclass
class ModelConfig:
    """ëª¨ë¸ ì„¤ì • ì •ë³´"""
    name: str
    model_type: ModelType
    model_class: str
    checkpoint_path: Optional[str] = None
    config_path: Optional[str] = None
    device: str = "auto"
    precision: str = "fp16"  # fp16, fp32, int8
    optimization_level: str = "balanced"  # fast, balanced, quality
    cache_enabled: bool = True
    input_size: tuple = (512, 512)
    num_classes: Optional[int] = None
    metadata: Dict[str, Any] = field(default_factory=dict)
    
    def __post_init__(self):
        if isinstance(self.model_type, str):
            self.model_type = ModelType(self.model_type)

# ==============================================
# 8ë‹¨ê³„ íŒŒì´í”„ë¼ì¸ì— í•„ìš”í•œ ì‹¤ì œ AI ëª¨ë¸ë“¤
# ==============================================

class GraphonomyModel(nn.Module):
    """Graphonomy ì¸ì²´ íŒŒì‹± ëª¨ë¸ - Step 01"""
    
    def __init__(self, num_classes=20, backbone='resnet101'):
        super().__init__()
        self.num_classes = num_classes
        self.backbone_name = backbone
        
        # ResNet ë°±ë³¸ êµ¬ì„±
        self.backbone = self._build_backbone()
        
        # ASPP (Atrous Spatial Pyramid Pooling)
        self.aspp = self._build_aspp()
        
        # ë¶„ë¥˜ í—¤ë“œ
        self.classifier = nn.Conv2d(256, num_classes, kernel_size=1)
        
        # ë³´ì¡° ë¶„ë¥˜ê¸° (í›ˆë ¨ì‹œ)
        self.aux_classifier = nn.Conv2d(1024, num_classes, kernel_size=1)
        
    def _build_backbone(self):
        """ResNet ë°±ë³¸ êµ¬ì„±"""
        try:
            import torchvision.models as models
            if self.backbone_name == 'resnet101':
                backbone = models.resnet101(pretrained=True)
            else:
                backbone = models.resnet50(pretrained=True)
                
            # Atrous convolutionì„ ìœ„í•œ stride ìˆ˜ì •
            backbone.layer3[0].conv2.stride = (1, 1)
            backbone.layer3[0].downsample[0].stride = (1, 1)
            backbone.layer4[0].conv2.stride = (1, 1)
            backbone.layer4[0].downsample[0].stride = (1, 1)
            
            # Dilation ì ìš©
            for module in backbone.layer3[1:]:
                module.conv2.dilation = (2, 2)
                module.conv2.padding = (2, 2)
            for module in backbone.layer4:
                module.conv2.dilation = (4, 4)
                module.conv2.padding = (4, 4)
                
            return nn.Sequential(*list(backbone.children())[:-2])
        except ImportError:
            # torchvision ì—†ëŠ” ê²½ìš° ê°„ë‹¨í•œ ë°±ë³¸
            return nn.Sequential(
                nn.Conv2d(3, 64, 7, 2, 3),
                nn.BatchNorm2d(64),
                nn.ReLU(inplace=True),
                nn.MaxPool2d(3, 2, 1),
                nn.Conv2d(64, 256, 3, 1, 1),
                nn.BatchNorm2d(256),
                nn.ReLU(inplace=True),
                nn.Conv2d(256, 512, 3, 1, 1),
                nn.BatchNorm2d(512),
                nn.ReLU(inplace=True),
                nn.Conv2d(512, 1024, 3, 1, 1),
                nn.BatchNorm2d(1024),
                nn.ReLU(inplace=True),
                nn.Conv2d(1024, 2048, 3, 1, 1),
                nn.BatchNorm2d(2048),
                nn.ReLU(inplace=True)
            )
    
    def _build_aspp(self):
        """ASPP ëª¨ë“ˆ êµ¬ì„±"""
        return nn.ModuleList([
            nn.Sequential(
                nn.Conv2d(2048, 256, 1, bias=False),
                nn.BatchNorm2d(256),
                nn.ReLU(inplace=True)
            ),
            nn.Sequential(
                nn.Conv2d(2048, 256, 3, padding=6, dilation=6, bias=False),
                nn.BatchNorm2d(256),
                nn.ReLU(inplace=True)
            ),
            nn.Sequential(
                nn.Conv2d(2048, 256, 3, padding=12, dilation=12, bias=False),
                nn.BatchNorm2d(256),
                nn.ReLU(inplace=True)
            ),
            nn.Sequential(
                nn.Conv2d(2048, 256, 3, padding=18, dilation=18, bias=False),
                nn.BatchNorm2d(256),
                nn.ReLU(inplace=True)
            ),
            nn.Sequential(
                nn.AdaptiveAvgPool2d((1, 1)),
                nn.Conv2d(2048, 256, 1, bias=False),
                nn.BatchNorm2d(256),
                nn.ReLU(inplace=True)
            )
        ])
    
    def forward(self, x):
        input_size = x.size()[2:]
        
        # ë°±ë³¸ í†µê³¼
        features = self.backbone(x)
        
        # ASPP ì ìš©
        aspp_outputs = []
        for aspp_layer in self.aspp[:-1]:
            aspp_outputs.append(aspp_layer(features))
        
        # Global average pooling
        global_feat = self.aspp[-1](features)
        global_feat = F.interpolate(global_feat, size=features.size()[2:], 
                                   mode='bilinear', align_corners=False)
        aspp_outputs.append(global_feat)
        
        # íŠ¹ì§• ìœµí•©
        fused = torch.cat(aspp_outputs, dim=1)
        
        # ìµœì¢… ë¶„ë¥˜
        output = self.classifier(fused)
        output = F.interpolate(output, size=input_size, mode='bilinear', align_corners=False)
        
        return output

class OpenPoseModel(nn.Module):
    """OpenPose í¬ì¦ˆ ì¶”ì • ëª¨ë¸ - Step 02"""
    
    def __init__(self, num_keypoints=18):
        super().__init__()
        self.num_keypoints = num_keypoints
        
        # VGG-19 ë°±ë³¸
        self.backbone = self._build_vgg_backbone()
        
        # 6ë‹¨ê³„ ë°˜ë³µ ì²˜ë¦¬
        self.stages = nn.ModuleList()
        for i in range(6):
            if i == 0:
                # ì²« ë²ˆì§¸ ìŠ¤í…Œì´ì§€
                stage = nn.ModuleDict({
                    'paf': self._build_initial_stage(38),  # 19 limbs * 2 (x,y)
                    'heatmap': self._build_initial_stage(19)  # 18 keypoints + 1 background
                })
            else:
                # í›„ì† ìŠ¤í…Œì´ì§€
                stage = nn.ModuleDict({
                    'paf': self._build_refinement_stage(38),
                    'heatmap': self._build_refinement_stage(19)
                })
            self.stages.append(stage)
    
    def _build_vgg_backbone(self):
        """VGG-19 ë°±ë³¸ êµ¬ì„±"""
        try:
            import torchvision.models as models
            vgg = models.vgg19(pretrained=True).features
            # Conv4_4ê¹Œì§€ë§Œ ì‚¬ìš©
            return nn.Sequential(*list(vgg.children())[:23])
        except ImportError:
            # VGG ëŒ€ì²´ ë°±ë³¸
            return nn.Sequential(
                nn.Conv2d(3, 64, 3, 1, 1), nn.ReLU(inplace=True),
                nn.Conv2d(64, 64, 3, 1, 1), nn.ReLU(inplace=True),
                nn.MaxPool2d(2, 2),
                nn.Conv2d(64, 128, 3, 1, 1), nn.ReLU(inplace=True),
                nn.Conv2d(128, 128, 3, 1, 1), nn.ReLU(inplace=True),
                nn.MaxPool2d(2, 2),
                nn.Conv2d(128, 256, 3, 1, 1), nn.ReLU(inplace=True),
                nn.Conv2d(256, 256, 3, 1, 1), nn.ReLU(inplace=True),
                nn.Conv2d(256, 256, 3, 1, 1), nn.ReLU(inplace=True),
                nn.Conv2d(256, 256, 3, 1, 1), nn.ReLU(inplace=True),
                nn.MaxPool2d(2, 2),
                nn.Conv2d(256, 512, 3, 1, 1), nn.ReLU(inplace=True),
                nn.Conv2d(512, 512, 3, 1, 1), nn.ReLU(inplace=True)
            )
    
    def _build_initial_stage(self, output_channels):
        """ì´ˆê¸° ìŠ¤í…Œì´ì§€ êµ¬ì„±"""
        return nn.Sequential(
            nn.Conv2d(512, 256, 3, 1, 1), nn.ReLU(inplace=True),
            nn.Conv2d(256, 256, 3, 1, 1), nn.ReLU(inplace=True),
            nn.Conv2d(256, 256, 3, 1, 1), nn.ReLU(inplace=True),
            nn.Conv2d(256, 512, 1, 1, 0), nn.ReLU(inplace=True),
            nn.Conv2d(512, output_channels, 1, 1, 0)
        )
    
    def _build_refinement_stage(self, output_channels):
        """ê°œì„  ìŠ¤í…Œì´ì§€ êµ¬ì„±"""
        return nn.Sequential(
            nn.Conv2d(512 + 38 + 19, 128, 7, 1, 3), nn.ReLU(inplace=True),
            nn.Conv2d(128, 128, 7, 1, 3), nn.ReLU(inplace=True),
            nn.Conv2d(128, 128, 7, 1, 3), nn.ReLU(inplace=True),
            nn.Conv2d(128, 128, 7, 1, 3), nn.ReLU(inplace=True),
            nn.Conv2d(128, 128, 7, 1, 3), nn.ReLU(inplace=True),
            nn.Conv2d(128, 128, 1, 1, 0), nn.ReLU(inplace=True),
            nn.Conv2d(128, output_channels, 1, 1, 0)
        )
    
    def forward(self, x):
        # ë°±ë³¸ íŠ¹ì§• ì¶”ì¶œ
        features = self.backbone(x)
        
        stage_outputs = []
        
        for i, stage in enumerate(self.stages):
            if i == 0:
                # ì²« ë²ˆì§¸ ìŠ¤í…Œì´ì§€
                paf = stage['paf'](features)
                heatmap = stage['heatmap'](features)
            else:
                # ì´ì „ ê²°ê³¼ì™€ íŠ¹ì§• ê²°í•©
                combined = torch.cat([features, prev_paf, prev_heatmap], dim=1)
                paf = stage['paf'](combined)
                heatmap = stage['heatmap'](combined)
            
            stage_outputs.append((paf, heatmap))
            prev_paf, prev_heatmap = paf, heatmap
        
        return stage_outputs

class U2NetModel(nn.Module):
    """UÂ²-Net ì„¸ê·¸ë©˜í…Œì´ì…˜ ëª¨ë¸ - Step 03"""
    
    def __init__(self, in_ch=3, out_ch=1):
        super().__init__()
        
        # ì¸ì½”ë” (6ë‹¨ê³„ RSU ë¸”ë¡)
        self.stage1 = RSU7(in_ch, 32, 64)
        self.pool12 = nn.MaxPool2d(2, stride=2, ceil_mode=True)
        
        self.stage2 = RSU6(64, 32, 128)
        self.pool23 = nn.MaxPool2d(2, stride=2, ceil_mode=True)
        
        self.stage3 = RSU5(128, 64, 256)
        self.pool34 = nn.MaxPool2d(2, stride=2, ceil_mode=True)
        
        self.stage4 = RSU4(256, 128, 512)
        self.pool45 = nn.MaxPool2d(2, stride=2, ceil_mode=True)
        
        self.stage5 = RSU4F(512, 256, 512)
        self.pool56 = nn.MaxPool2d(2, stride=2, ceil_mode=True)
        
        self.stage6 = RSU4F(512, 256, 512)
        
        # ë””ì½”ë”
        self.stage5d = RSU4F(1024, 256, 512)
        self.stage4d = RSU4(1024, 128, 256)
        self.stage3d = RSU5(512, 64, 128)
        self.stage2d = RSU6(256, 32, 64)
        self.stage1d = RSU7(128, 16, 64)
        
        # ì‚¬ì´ë“œ ì¶œë ¥ë“¤
        self.side1 = nn.Conv2d(64, out_ch, 3, padding=1)
        self.side2 = nn.Conv2d(64, out_ch, 3, padding=1)
        self.side3 = nn.Conv2d(128, out_ch, 3, padding=1)
        self.side4 = nn.Conv2d(256, out_ch, 3, padding=1)
        self.side5 = nn.Conv2d(512, out_ch, 3, padding=1)
        self.side6 = nn.Conv2d(512, out_ch, 3, padding=1)
        
        # ìµœì¢… ìœµí•©
        self.outconv = nn.Conv2d(6 * out_ch, out_ch, 1)
    
    def forward(self, x):
        hx = x
        
        # ì¸ì½”ë”
        hx1 = self.stage1(hx)
        hx = self.pool12(hx1)
        
        hx2 = self.stage2(hx)
        hx = self.pool23(hx2)
        
        hx3 = self.stage3(hx)
        hx = self.pool34(hx3)
        
        hx4 = self.stage4(hx)
        hx = self.pool45(hx4)
        
        hx5 = self.stage5(hx)
        hx = self.pool56(hx5)
        
        hx6 = self.stage6(hx)
        
        # ë””ì½”ë”
        hx6up = F.interpolate(hx6, size=hx5.shape[2:], mode='bilinear', align_corners=False)
        hx5d = self.stage5d(torch.cat((hx6up, hx5), 1))
        
        hx5dup = F.interpolate(hx5d, size=hx4.shape[2:], mode='bilinear', align_corners=False)
        hx4d = self.stage4d(torch.cat((hx5dup, hx4), 1))
        
        hx4dup = F.interpolate(hx4d, size=hx3.shape[2:], mode='bilinear', align_corners=False)
        hx3d = self.stage3d(torch.cat((hx4dup, hx3), 1))
        
        hx3dup = F.interpolate(hx3d, size=hx2.shape[2:], mode='bilinear', align_corners=False)
        hx2d = self.stage2d(torch.cat((hx3dup, hx2), 1))
        
        hx2dup = F.interpolate(hx2d, size=hx1.shape[2:], mode='bilinear', align_corners=False)
        hx1d = self.stage1d(torch.cat((hx2dup, hx1), 1))
        
        # ì‚¬ì´ë“œ ì¶œë ¥ë“¤
        d1 = self.side1(hx1d)
        d2 = self.side2(hx2d)
        d2 = F.interpolate(d2, size=x.shape[2:], mode='bilinear', align_corners=False)
        d3 = self.side3(hx3d)
        d3 = F.interpolate(d3, size=x.shape[2:], mode='bilinear', align_corners=False)
        d4 = self.side4(hx4d)
        d4 = F.interpolate(d4, size=x.shape[2:], mode='bilinear', align_corners=False)
        d5 = self.side5(hx5d)
        d5 = F.interpolate(d5, size=x.shape[2:], mode='bilinear', align_corners=False)
        d6 = self.side6(hx6)
        d6 = F.interpolate(d6, size=x.shape[2:], mode='bilinear', align_corners=False)
        
        # ìµœì¢… ìœµí•©
        d0 = self.outconv(torch.cat((d1, d2, d3, d4, d5, d6), 1))
        
        return torch.sigmoid(d0), torch.sigmoid(d1), torch.sigmoid(d2), torch.sigmoid(d3), torch.sigmoid(d4), torch.sigmoid(d5), torch.sigmoid(d6)

# RSU ë¸”ë¡ë“¤ (UÂ²-Net êµ¬ì„± ìš”ì†Œ)
class RSU7(nn.Module):
    def __init__(self, in_ch=3, mid_ch=12, out_ch=3):
        super(RSU7, self).__init__()
        self.rebnconvin = REBNCONV(in_ch, out_ch, dirate=1)
        self.rebnconv1 = REBNCONV(out_ch, mid_ch, dirate=1)
        self.pool1 = nn.MaxPool2d(2, stride=2, ceil_mode=True)
        self.rebnconv2 = REBNCONV(mid_ch, mid_ch, dirate=1)
        self.pool2 = nn.MaxPool2d(2, stride=2, ceil_mode=True)
        self.rebnconv3 = REBNCONV(mid_ch, mid_ch, dirate=1)
        self.pool3 = nn.MaxPool2d(2, stride=2, ceil_mode=True)
        self.rebnconv4 = REBNCONV(mid_ch, mid_ch, dirate=1)
        self.pool4 = nn.MaxPool2d(2, stride=2, ceil_mode=True)
        self.rebnconv5 = REBNCONV(mid_ch, mid_ch, dirate=1)
        self.pool5 = nn.MaxPool2d(2, stride=2, ceil_mode=True)
        self.rebnconv6 = REBNCONV(mid_ch, mid_ch, dirate=1)
        self.rebnconv7 = REBNCONV(mid_ch, mid_ch, dirate=2)
        self.rebnconv6d = REBNCONV(mid_ch*2, mid_ch, dirate=1)
        self.rebnconv5d = REBNCONV(mid_ch*2, mid_ch, dirate=1)
        self.rebnconv4d = REBNCONV(mid_ch*2, mid_ch, dirate=1)
        self.rebnconv3d = REBNCONV(mid_ch*2, mid_ch, dirate=1)
        self.rebnconv2d = REBNCONV(mid_ch*2, mid_ch, dirate=1)
        self.rebnconv1d = REBNCONV(mid_ch*2, out_ch, dirate=1)

    def forward(self, x):
        hx = x
        hxin = self.rebnconvin(hx)
        hx1 = self.rebnconv1(hxin)
        hx = self.pool1(hx1)
        hx2 = self.rebnconv2(hx)
        hx = self.pool2(hx2)
        hx3 = self.rebnconv3(hx)
        hx = self.pool3(hx3)
        hx4 = self.rebnconv4(hx)
        hx = self.pool4(hx4)
        hx5 = self.rebnconv5(hx)
        hx = self.pool5(hx5)
        hx6 = self.rebnconv6(hx)
        hx7 = self.rebnconv7(hx6)
        hx6d = self.rebnconv6d(torch.cat((hx7, hx6), 1))
        hx6dup = F.interpolate(hx6d, size=hx5.shape[2:], mode='bilinear', align_corners=False)
        hx5d = self.rebnconv5d(torch.cat((hx6dup, hx5), 1))
        hx5dup = F.interpolate(hx5d, size=hx4.shape[2:], mode='bilinear', align_corners=False)
        hx4d = self.rebnconv4d(torch.cat((hx5dup, hx4), 1))
        hx4dup = F.interpolate(hx4d, size=hx3.shape[2:], mode='bilinear', align_corners=False)
        hx3d = self.rebnconv3d(torch.cat((hx4dup, hx3), 1))
        hx3dup = F.interpolate(hx3d, size=hx2.shape[2:], mode='bilinear', align_corners=False)
        hx2d = self.rebnconv2d(torch.cat((hx3dup, hx2), 1))
        hx2dup = F.interpolate(hx2d, size=hx1.shape[2:], mode='bilinear', align_corners=False)
        hx1d = self.rebnconv1d(torch.cat((hx2dup, hx1), 1))
        return hx1d + hxin

class RSU6(nn.Module):
    def __init__(self, in_ch=3, mid_ch=12, out_ch=3):
        super(RSU6, self).__init__()
        self.rebnconvin = REBNCONV(in_ch, out_ch, dirate=1)
        self.rebnconv1 = REBNCONV(out_ch, mid_ch, dirate=1)
        self.pool1 = nn.MaxPool2d(2, stride=2, ceil_mode=True)
        self.rebnconv2 = REBNCONV(mid_ch, mid_ch, dirate=1)
        self.pool2 = nn.MaxPool2d(2, stride=2, ceil_mode=True)
        self.rebnconv3 = REBNCONV(mid_ch, mid_ch, dirate=1)
        self.pool3 = nn.MaxPool2d(2, stride=2, ceil_mode=True)
        self.rebnconv4 = REBNCONV(mid_ch, mid_ch, dirate=1)
        self.pool4 = nn.MaxPool2d(2, stride=2, ceil_mode=True)
        self.rebnconv5 = REBNCONV(mid_ch, mid_ch, dirate=1)
        self.rebnconv6 = REBNCONV(mid_ch, mid_ch, dirate=2)
        self.rebnconv5d = REBNCONV(mid_ch*2, mid_ch, dirate=1)
        self.rebnconv4d = REBNCONV(mid_ch*2, mid_ch, dirate=1)
        self.rebnconv3d = REBNCONV(mid_ch*2, mid_ch, dirate=1)
        self.rebnconv2d = REBNCONV(mid_ch*2, mid_ch, dirate=1)
        self.rebnconv1d = REBNCONV(mid_ch*2, out_ch, dirate=1)

    def forward(self, x):
        hx = x
        hxin = self.rebnconvin(hx)
        hx1 = self.rebnconv1(hxin)
        hx = self.pool1(hx1)
        hx2 = self.rebnconv2(hx)
        hx = self.pool2(hx2)
        hx3 = self.rebnconv3(hx)
        hx = self.pool3(hx3)
        hx4 = self.rebnconv4(hx)
        hx = self.pool4(hx4)
        hx5 = self.rebnconv5(hx)
        hx6 = self.rebnconv6(hx5)
        hx5d = self.rebnconv5d(torch.cat((hx6, hx5), 1))
        hx5dup = F.interpolate(hx5d, size=hx4.shape[2:], mode='bilinear', align_corners=False)
        hx4d = self.rebnconv4d(torch.cat((hx5dup, hx4), 1))
        hx4dup = F.interpolate(hx4d, size=hx3.shape[2:], mode='bilinear', align_corners=False)
        hx3d = self.rebnconv3d(torch.cat((hx4dup, hx3), 1))
        hx3dup = F.interpolate(hx3d, size=hx2.shape[2:], mode='bilinear', align_corners=False)
        hx2d = self.rebnconv2d(torch.cat((hx3dup, hx2), 1))
        hx2dup = F.interpolate(hx2d, size=hx1.shape[2:], mode='bilinear', align_corners=False)
        hx1d = self.rebnconv1d(torch.cat((hx2dup, hx1), 1))
        return hx1d + hxin

class RSU5(nn.Module):
    def __init__(self, in_ch=3, mid_ch=12, out_ch=3):
        super(RSU5, self).__init__()
        self.rebnconvin = REBNCONV(in_ch, out_ch, dirate=1)
        self.rebnconv1 = REBNCONV(out_ch, mid_ch, dirate=1)
        self.pool1 = nn.MaxPool2d(2, stride=2, ceil_mode=True)
        self.rebnconv2 = REBNCONV(mid_ch, mid_ch, dirate=1)
        self.pool2 = nn.MaxPool2d(2, stride=2, ceil_mode=True)
        self.rebnconv3 = REBNCONV(mid_ch, mid_ch, dirate=1)
        self.pool3 = nn.MaxPool2d(2, stride=2, ceil_mode=True)
        self.rebnconv4 = REBNCONV(mid_ch, mid_ch, dirate=1)
        self.rebnconv5 = REBNCONV(mid_ch, mid_ch, dirate=2)
        self.rebnconv4d = REBNCONV(mid_ch*2, mid_ch, dirate=1)
        self.rebnconv3d = REBNCONV(mid_ch*2, mid_ch, dirate=1)
        self.rebnconv2d = REBNCONV(mid_ch*2, mid_ch, dirate=1)
        self.rebnconv1d = REBNCONV(mid_ch*2, out_ch, dirate=1)

    def forward(self, x):
        hx = x
        hxin = self.rebnconvin(hx)
        hx1 = self.rebnconv1(hxin)
        hx = self.pool1(hx1)
        hx2 = self.rebnconv2(hx)
        hx = self.pool2(hx2)
        hx3 = self.rebnconv3(hx)
        hx = self.pool3(hx3)
        hx4 = self.rebnconv4(hx)
        hx5 = self.rebnconv5(hx4)
        hx4d = self.rebnconv4d(torch.cat((hx5, hx4), 1))
        hx4dup = F.interpolate(hx4d, size=hx3.shape[2:], mode='bilinear', align_corners=False)
        hx3d = self.rebnconv3d(torch.cat((hx4dup, hx3), 1))
        hx3dup = F.interpolate(hx3d, size=hx2.shape[2:], mode='bilinear', align_corners=False)
        hx2d = self.rebnconv2d(torch.cat((hx3dup, hx2), 1))
        hx2dup = F.interpolate(hx2d, size=hx1.shape[2:], mode='bilinear', align_corners=False)
        hx1d = self.rebnconv1d(torch.cat((hx2dup, hx1), 1))
        return hx1d + hxin

class RSU4(nn.Module):
    def __init__(self, in_ch=3, mid_ch=12, out_ch=3):
        super(RSU4, self).__init__()
        self.rebnconvin = REBNCONV(in_ch, out_ch, dirate=1)
        self.rebnconv1 = REBNCONV(out_ch, mid_ch, dirate=1)
        self.pool1 = nn.MaxPool2d(2, stride=2, ceil_mode=True)
        self.rebnconv2 = REBNCONV(mid_ch, mid_ch, dirate=1)
        self.pool2 = nn.MaxPool2d(2, stride=2, ceil_mode=True)
        self.rebnconv3 = REBNCONV(mid_ch, mid_ch, dirate=1)
        self.rebnconv4 = REBNCONV(mid_ch, mid_ch, dirate=2)
        self.rebnconv3d = REBNCONV(mid_ch*2, mid_ch, dirate=1)
        self.rebnconv2d = REBNCONV(mid_ch*2, mid_ch, dirate=1)
        self.rebnconv1d = REBNCONV(mid_ch*2, out_ch, dirate=1)

    def forward(self, x):
        hx = x
        hxin = self.rebnconvin(hx)
        hx1 = self.rebnconv1(hxin)
        hx = self.pool1(hx1)
        hx2 = self.rebnconv2(hx)
        hx = self.pool2(hx2)
        hx3 = self.rebnconv3(hx)
        hx4 = self.rebnconv4(hx3)
        hx3d = self.rebnconv3d(torch.cat((hx4, hx3), 1))
        hx3dup = F.interpolate(hx3d, size=hx2.shape[2:], mode='bilinear', align_corners=False)
        hx2d = self.rebnconv2d(torch.cat((hx3dup, hx2), 1))
        hx2dup = F.interpolate(hx2d, size=hx1.shape[2:], mode='bilinear', align_corners=False)
        hx1d = self.rebnconv1d(torch.cat((hx2dup, hx1), 1))
        return hx1d + hxin

class RSU4F(nn.Module):
    def __init__(self, in_ch=3, mid_ch=12, out_ch=3):
        super(RSU4F, self).__init__()
        self.rebnconvin = REBNCONV(in_ch, out_ch, dirate=1)
        self.rebnconv1 = REBNCONV(out_ch, mid_ch, dirate=1)
        self.rebnconv2 = REBNCONV(mid_ch, mid_ch, dirate=2)
        self.rebnconv3 = REBNCONV(mid_ch, mid_ch, dirate=4)
        self.rebnconv4 = REBNCONV(mid_ch, mid_ch, dirate=8)
        self.rebnconv3d = REBNCONV(mid_ch*2, mid_ch, dirate=4)
        self.rebnconv2d = REBNCONV(mid_ch*2, mid_ch, dirate=2)
        self.rebnconv1d = REBNCONV(mid_ch*2, out_ch, dirate=1)

    def forward(self, x):
        hx = x
        hxin = self.rebnconvin(hx)
        hx1 = self.rebnconv1(hxin)
        hx2 = self.rebnconv2(hx1)
        hx3 = self.rebnconv3(hx2)
        hx4 = self.rebnconv4(hx3)
        hx3d = self.rebnconv3d(torch.cat((hx4, hx3), 1))
        hx2d = self.rebnconv2d(torch.cat((hx3d, hx2), 1))
        hx1d = self.rebnconv1d(torch.cat((hx2d, hx1), 1))
        return hx1d + hxin

class REBNCONV(nn.Module):
    def __init__(self, in_ch=3, out_ch=3, dirate=1):
        super(REBNCONV, self).__init__()
        self.conv_s1 = nn.Conv2d(in_ch, out_ch, 3, padding=1*dirate, dilation=1*dirate)
        self.bn_s1 = nn.BatchNorm2d(out_ch)
        self.relu_s1 = nn.ReLU(inplace=True)

    def forward(self, x):
        hx = self.relu_s1(self.bn_s1(self.conv_s1(x)))
        return hx

class GeometricMatchingModel(nn.Module):
    """ê¸°í•˜í•™ì  ë§¤ì¹­ ëª¨ë¸ - Step 04"""
    
    def __init__(self, feature_size=256):
        super().__init__()
        self.feature_size = feature_size
        
        # íŠ¹ì§• ì¶”ì¶œ ë„¤íŠ¸ì›Œí¬
        self.feature_extractor = self._build_feature_extractor()
        
        # ìƒê´€ê´€ê³„ ê³„ì‚°
        self.correlation = self._build_correlation_layer()
        
        # íšŒê·€ ë„¤íŠ¸ì›Œí¬
        self.regression = self._build_regression_network()
        
    def _build_feature_extractor(self):
        """íŠ¹ì§• ì¶”ì¶œ ë„¤íŠ¸ì›Œí¬"""
        return nn.Sequential(
            nn.Conv2d(3, 64, 3, 1, 1), nn.BatchNorm2d(64), nn.ReLU(inplace=True),
            nn.Conv2d(64, 64, 3, 1, 1), nn.BatchNorm2d(64), nn.ReLU(inplace=True),
            nn.MaxPool2d(2, 2),
            nn.Conv2d(64, 128, 3, 1, 1), nn.BatchNorm2d(128), nn.ReLU(inplace=True),
            nn.Conv2d(128, 128, 3, 1, 1), nn.BatchNorm2d(128), nn.ReLU(inplace=True),
            nn.MaxPool2d(2, 2),
            nn.Conv2d(128, 256, 3, 1, 1), nn.BatchNorm2d(256), nn.ReLU(inplace=True),
            nn.Conv2d(256, 256, 3, 1, 1), nn.BatchNorm2d(256), nn.ReLU(inplace=True),
            nn.Conv2d(256, 256, 3, 1, 1), nn.BatchNorm2d(256), nn.ReLU(inplace=True),
            nn.MaxPool2d(2, 2),
            nn.Conv2d(256, 512, 3, 1, 1), nn.BatchNorm2d(512), nn.ReLU(inplace=True),
            nn.Conv2d(512, 512, 3, 1, 1), nn.BatchNorm2d(512), nn.ReLU(inplace=True),
            nn.Conv2d(512, 256, 3, 1, 1), nn.BatchNorm2d(256), nn.ReLU(inplace=True)
        )
    
    def _build_correlation_layer(self):
        """ìƒê´€ê´€ê³„ ê³„ì‚° ë ˆì´ì–´"""
        return nn.Sequential(
            nn.Conv2d(256, 128, 3, 1, 1), nn.BatchNorm2d(128), nn.ReLU(inplace=True),
            nn.Conv2d(128, 64, 3, 1, 1), nn.BatchNorm2d(64), nn.ReLU(inplace=True),
            nn.Conv2d(64, 1, 1, 1, 0), nn.Sigmoid()
        )
    
    def _build_regression_network(self):
        """íšŒê·€ ë„¤íŠ¸ì›Œí¬"""
        return nn.Sequential(
            nn.AdaptiveAvgPool2d((8, 8)),
            nn.Flatten(),
            nn.Linear(64, 256), nn.ReLU(inplace=True), nn.Dropout(0.5),
            nn.Linear(256, 128), nn.ReLU(inplace=True), nn.Dropout(0.5),
            nn.Linear(128, 18)  # 6ê°œ TPS ì œì–´ì  * 3 (x, y, confidence)
        )
    
    def forward(self, source_img, target_img):
        # íŠ¹ì§• ì¶”ì¶œ
        source_feat = self.feature_extractor(source_img)
        target_feat = self.feature_extractor(target_img)
        
        # ìƒê´€ê´€ê³„ ê³„ì‚°
        correlation_map = self.correlation(torch.cat([source_feat, target_feat], dim=1))
        
        # TPS íŒŒë¼ë¯¸í„° íšŒê·€
        tps_params = self.regression(correlation_map)
        
        return {
            'correlation_map': correlation_map,
            'tps_params': tps_params.view(-1, 6, 3),  # [batch, 6_points, (x,y,conf)]
            'source_features': source_feat,
            'target_features': target_feat
        }

class HRVITONModel(nn.Module):
    """HR-VITON ê°€ìƒ í”¼íŒ… ëª¨ë¸ - Step 06"""
    
    def __init__(self, input_nc=3, output_nc=3, ngf=64):
        super().__init__()
        
        # ìƒì„±ê¸° ë„¤íŠ¸ì›Œí¬
        self.generator = self._build_generator(input_nc, output_nc, ngf)
        
        # ì–´í…ì…˜ ëª¨ë“ˆ
        self.attention = self._build_attention_module()
        
        # ìœµí•© ëª¨ë“ˆ
        self.fusion = self._build_fusion_module()
    
    def _build_generator(self, input_nc, output_nc, ngf):
        """ìƒì„±ê¸° ë„¤íŠ¸ì›Œí¬ êµ¬ì„±"""
        return nn.Sequential(
            # ì¸ì½”ë”
            nn.Conv2d(input_nc, ngf, 7, 1, 3), nn.InstanceNorm2d(ngf), nn.ReLU(True),
            nn.Conv2d(ngf, ngf*2, 3, 2, 1), nn.InstanceNorm2d(ngf*2), nn.ReLU(True),
            nn.Conv2d(ngf*2, ngf*4, 3, 2, 1), nn.InstanceNorm2d(ngf*4), nn.ReLU(True),
            
            # ResNet ë¸”ë¡ë“¤
            *[ResnetBlock(ngf*4) for _ in range(9)],
            
            # ë””ì½”ë”
            nn.ConvTranspose2d(ngf*4, ngf*2, 3, 2, 1, 1), nn.InstanceNorm2d(ngf*2), nn.ReLU(True),
            nn.ConvTranspose2d(ngf*2, ngf, 3, 2, 1, 1), nn.InstanceNorm2d(ngf), nn.ReLU(True),
            nn.Conv2d(ngf, output_nc, 7, 1, 3), nn.Tanh()
        )
    
    def _build_attention_module(self):
        """ì–´í…ì…˜ ëª¨ë“ˆ"""
        return nn.Sequential(
            nn.Conv2d(6, 64, 3, 1, 1), nn.ReLU(True),
            nn.Conv2d(64, 32, 3, 1, 1), nn.ReLU(True),
            nn.Conv2d(32, 1, 1, 1, 0), nn.Sigmoid()
        )
    
    def _build_fusion_module(self):
        """ìœµí•© ëª¨ë“ˆ"""
        return nn.Sequential(
            nn.Conv2d(6, 64, 3, 1, 1), nn.ReLU(True),
            nn.Conv2d(64, 32, 3, 1, 1), nn.ReLU(True),
            nn.Conv2d(32, 3, 3, 1, 1), nn.Tanh()
        )
    
    def forward(self, person_img, cloth_img, person_parse=None):
        # ê¸°ë³¸ ìƒì„±
        input_concat = torch.cat([person_img, cloth_img], dim=1)
        generated = self.generator(input_concat)
        
        # ì–´í…ì…˜ ë§µ ê³„ì‚°
        attention_map = self.attention(input_concat)
        
        # ì–´í…ì…˜ ì ìš© ìœµí•©
        attended_result = generated * attention_map + person_img * (1 - attention_map)
        
        # ì¶”ê°€ ìœµí•©
        final_result = self.fusion(torch.cat([attended_result, cloth_img], dim=1))
        
        return {
            'generated_image': final_result,
            'attention_map': attention_map,
            'intermediate': generated
        }

class ResnetBlock(nn.Module):
    """ResNet ë¸”ë¡"""
    def __init__(self, dim, use_dropout=False):
        super().__init__()
        self.conv_block = self._build_conv_block(dim, use_dropout)

    def _build_conv_block(self, dim, use_dropout):
        layers = []
        layers += [nn.Conv2d(dim, dim, 3, 1, 1), nn.InstanceNorm2d(dim), nn.ReLU(True)]
        if use_dropout:
            layers += [nn.Dropout(0.5)]
        layers += [nn.Conv2d(dim, dim, 3, 1, 1), nn.InstanceNorm2d(dim)]
        return nn.Sequential(*layers)

    def forward(self, x):
        return x + self.conv_block(x)

# ==============================================
# ëª¨ë¸ ë¡œë” í´ë˜ìŠ¤
# ==============================================

class ModelLoader(OptimalStepConstructor):
    """
    ğŸ M3 Max ìµœì í™” ì‹¤ì œ AI ëª¨ë¸ ë¡œë”
    8ë‹¨ê³„ íŒŒì´í”„ë¼ì¸ì— í•„ìš”í•œ ëª¨ë“  ëª¨ë¸ ì§€ì›
    """
    
    def __init__(
        self,
        device: Optional[str] = None,
        config: Optional[Dict[str, Any]] = None,
        **kwargs
    ):
        """
        âœ… ìµœì  ìƒì„±ì - ëª¨ë¸ ë¡œë” íŠ¹í™”

        Args:
            device: ì‚¬ìš©í•  ë””ë°”ì´ìŠ¤ (None=ìë™ê°ì§€, 'cpu', 'cuda', 'mps')
            config: ëª¨ë¸ ë¡œë” ì„¤ì • ë”•ì…”ë„ˆë¦¬
            **kwargs: í™•ì¥ íŒŒë¼ë¯¸í„°ë“¤
                - model_cache_dir: str = "./models/ai_models"  # ëª¨ë¸ ìºì‹œ ë””ë ‰í† ë¦¬
                - use_fp16: bool = True  # FP16 ì‚¬ìš© ì—¬ë¶€
                - max_cached_models: int = 10  # ìµœëŒ€ ìºì‹œ ëª¨ë¸ ìˆ˜
                - lazy_loading: bool = True  # ì§€ì—° ë¡œë”©
                - coreml_optimization: bool = True  # CoreML ìµœì í™” (M3 Max)
                - auto_quantization: bool = False  # ìë™ ì–‘ìí™”
                - memory_mapping: bool = True  # ë©”ëª¨ë¦¬ ë§¤í•‘
        """
        super().__init__(device=device, config=config, **kwargs)
        
        # ëª¨ë¸ ë¡œë” íŠ¹í™” ì„¤ì •
        self.model_cache_dir = Path(kwargs.get('model_cache_dir', './models/ai_models'))
        self.use_fp16 = kwargs.get('use_fp16', True and self.device != 'cpu')
        self.max_cached_models = kwargs.get('max_cached_models', 10)
        self.lazy_loading = kwargs.get('lazy_loading', True)
        self.coreml_optimization = kwargs.get('coreml_optimization', self.is_m3_max and COREML_AVAILABLE)
        self.auto_quantization = kwargs.get('auto_quantization', False)
        self.memory_mapping = kwargs.get('memory_mapping', True)
        
        # ë‚´ë¶€ ìƒíƒœ
        self._lock = threading.RLock()
        self._loaded_models: Dict[str, Any] = {}
        self._model_configs: Dict[str, ModelConfig] = {}
        self._model_registry: Dict[str, Dict[str, Any]] = {}
        self._load_times: Dict[str, float] = {}
        self._fallback_models: Dict[str, Any] = {}
        
        # ìºì‹œ ë””ë ‰í† ë¦¬ ìƒì„±
        self.model_cache_dir.mkdir(parents=True, exist_ok=True)
        
        # M3 Max íŠ¹í™” ì„¤ì •
        if self.is_m3_max:
            self.use_fp16 = True  # M3 MaxëŠ” FP16 ìµœì í™”
            if COREML_AVAILABLE:
                self.logger.info("ğŸ CoreML ìµœì í™” í™œì„±í™”ë¨")
        
        # ì‹¤ì œ ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬ ì´ˆê¸°í™”
        self._initialize_model_registry()
        
        self.logger.info(f"ğŸ“¦ ì‹¤ì œ AI ëª¨ë¸ ë¡œë” ì´ˆê¸°í™” - {self.device} (FP16: {self.use_fp16})")
        
        # ì´ˆê¸°í™” ì™„ë£Œ
        self.is_initialized = True

    def _initialize_model_registry(self):
        """ì‹¤ì œ AI ëª¨ë¸ë“¤ ë“±ë¡"""
        models_config = {
            # Step 01: Human Parsing
            "human_parsing_graphonomy": ModelConfig(
                name="human_parsing_graphonomy",
                model_type=ModelType.HUMAN_PARSING,
                model_class="GraphonomyModel",
                checkpoint_path=str(self.model_cache_dir / "graphonomy" / "inference.pth"),
                input_size=(512, 512),
                num_classes=20
            ),
            
            # Step 02: Pose Estimation  
            "pose_estimation_openpose": ModelConfig(
                name="pose_estimation_openpose", 
                model_type=ModelType.POSE_ESTIMATION,
                model_class="OpenPoseModel",
                checkpoint_path=str(self.model_cache_dir / "openpose" / "pose_model.pth"),
                input_size=(368, 368),
                num_classes=18
            ),
            
            # Step 03: Cloth Segmentation
            "cloth_segmentation_u2net": ModelConfig(
                name="cloth_segmentation_u2net",
                model_type=ModelType.CLOTH_SEGMENTATION, 
                model_class="U2NetModel",
                checkpoint_path=str(self.model_cache_dir / "u2net" / "u2net.pth"),
                input_size=(320, 320)
            ),
            
            # Step 04: Geometric Matching
            "geometric_matching_gmm": ModelConfig(
                name="geometric_matching_gmm",
                model_type=ModelType.GEOMETRIC_MATCHING,
                model_class="GeometricMatchingModel", 
                checkpoint_path=str(self.model_cache_dir / "hr_viton" / "gmm_final.pth"),
                input_size=(512, 384)
            ),
            
            # Step 05: Cloth Warping (HR-VITONì˜ TOM)
            "cloth_warping_tom": ModelConfig(
                name="cloth_warping_tom",
                model_type=ModelType.CLOTH_WARPING,
                model_class="HRVITONModel",
                checkpoint_path=str(self.model_cache_dir / "hr_viton" / "tom_final.pth"),
                input_size=(512, 384)
            ),
            
            # Step 06: Virtual Fitting (ì™„ì „í•œ HR-VITON)
            "virtual_fitting_hrviton": ModelConfig(
                name="virtual_fitting_hrviton",
                model_type=ModelType.VIRTUAL_FITTING,
                model_class="HRVITONModel",
                checkpoint_path=str(self.model_cache_dir / "hr_viton" / "final.pth"),
                input_size=(512, 384)
            ),
            
            # OOTD ëŒ€ì²´ ëª¨ë¸
            "virtual_fitting_ootd": ModelConfig(
                name="virtual_fitting_ootd",
                model_type=ModelType.DIFFUSION,
                model_class="StableDiffusionPipeline",
                checkpoint_path=str(self.model_cache_dir / "ootd"),
                input_size=(512, 512)
            )
        }
        
        # ëª¨ë¸ ë“±ë¡
        for name, config in models_config.items():
            self.register_model(name, config)

    def register_model(
        self,
        name: str,
        model_config: Union[ModelConfig, Dict[str, Any]],
        loader_func: Optional[Callable] = None
    ) -> bool:
        """ëª¨ë¸ ë“±ë¡"""
        try:
            with self._lock:
                # ModelConfig ê°ì²´ë¡œ ë³€í™˜
                if isinstance(model_config, dict):
                    model_config = ModelConfig(name=name, **model_config)
                elif not isinstance(model_config, ModelConfig):
                    raise ValueError(f"Invalid model_config type: {type(model_config)}")
                
                # ë””ë°”ì´ìŠ¤ ì„¤ì • ìë™ ê°ì§€
                if model_config.device == "auto":
                    model_config.device = self.device
                
                # ë“±ë¡ ì •ë³´ ì €ì¥
                self._model_configs[name] = model_config
                self._model_registry[name] = {
                    "config": model_config,
                    "loader_func": loader_func,
                    "registered_at": time.time(),
                    "loaded": False,
                    "load_count": 0
                }
                
                self.logger.info(f"ğŸ“ ì‹¤ì œ AI ëª¨ë¸ ë“±ë¡: {name} ({model_config.model_type.value})")
                return True
                
        except Exception as e:
            self.logger.error(f"âŒ ëª¨ë¸ ë“±ë¡ ì‹¤íŒ¨ {name}: {e}")
            return False

    async def load_model(
        self,
        name: str,
        force_reload: bool = False,
        **kwargs
    ) -> Optional[Any]:
        """ì‹¤ì œ AI ëª¨ë¸ ë¡œë“œ"""
        try:
            with self._lock:
                # ì´ë¯¸ ë¡œë“œëœ ëª¨ë¸ í™•ì¸
                if name in self._loaded_models and not force_reload:
                    self._model_registry[name]["load_count"] += 1
                    self.logger.info(f"ğŸ“¦ ìºì‹œëœ ëª¨ë¸ ë°˜í™˜: {name}")
                    return self._loaded_models[name]
                
                # ëª¨ë¸ ì„¤ì • í™•ì¸
                if name not in self._model_registry:
                    self.logger.warning(f"âš ï¸ ë“±ë¡ë˜ì§€ ì•Šì€ ëª¨ë¸: {name}, ëŒ€ì²´ ëª¨ë¸ ë¡œë“œ ì‹œë„")
                    return await self._load_fallback_model(name)
                
                start_time = time.time()
                model_info = self._model_registry[name]
                model_config = model_info["config"]
                
                self.logger.info(f"ğŸ“¦ ì‹¤ì œ AI ëª¨ë¸ ë¡œë”© ì‹œì‘: {name} ({model_config.model_type.value})")
                
                # ë©”ëª¨ë¦¬ ì••ë°• í™•ì¸ ë° ì •ë¦¬
                await self._check_memory_and_cleanup()
                
                # ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
                model = await self._create_model_instance(model_config, **kwargs)
                
                if model is None:
                    self.logger.warning(f"âš ï¸ ëª¨ë¸ ìƒì„± ì‹¤íŒ¨, ëŒ€ì²´ ëª¨ë¸ ë¡œë“œ: {name}")
                    return await self._load_fallback_model(name)
                
                # ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ
                await self._load_checkpoint(model, model_config)
                
                # ë””ë°”ì´ìŠ¤ë¡œ ì´ë™
                if hasattr(model, 'to'):
                    model = model.to(self.device)
                
                # M3 Max ìµœì í™” ì ìš©
                if self.is_m3_max and self.optimization_enabled:
                    model = await self._apply_m3_max_optimization(model, model_config)
                
                # FP16 ìµœì í™”
                if self.use_fp16 and hasattr(model, 'half') and self.device != 'cpu':
                    try:
                        model = model.half()
                    except Exception as e:
                        self.logger.warning(f"âš ï¸ FP16 ë³€í™˜ ì‹¤íŒ¨: {e}")
                
                # í‰ê°€ ëª¨ë“œ
                if hasattr(model, 'eval'):
                    model.eval()
                
                # ìºì‹œì— ì €ì¥
                self._loaded_models[name] = model
                self._load_times[name] = time.time() - start_time
                
                # ë ˆì§€ìŠ¤íŠ¸ë¦¬ ì—…ë°ì´íŠ¸
                model_info["loaded"] = True
                model_info["load_count"] += 1
                model_info["last_loaded"] = time.time()
                
                load_time = self._load_times[name]
                self.logger.info(f"âœ… ì‹¤ì œ AI ëª¨ë¸ ë¡œë”© ì™„ë£Œ: {name} ({load_time:.2f}s)")
                
                return model
                
        except Exception as e:
            self.logger.error(f"âŒ ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨ {name}: {e}")
            # ëŒ€ì²´ ëª¨ë¸ ì‹œë„
            return await self._load_fallback_model(name)

    async def _create_model_instance(
        self,
        model_config: ModelConfig,
        **kwargs
    ) -> Optional[Any]:
        """ì‹¤ì œ AI ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±"""
        try:
            model_class = model_config.model_class
            
            if model_class == "GraphonomyModel":
                return GraphonomyModel(
                    num_classes=model_config.num_classes or 20,
                    backbone='resnet101'
                )
            
            elif model_class == "OpenPoseModel":
                return OpenPoseModel(
                    num_keypoints=model_config.num_classes or 18
                )
            
            elif model_class == "U2NetModel":
                return U2NetModel(in_ch=3, out_ch=1)
            
            elif model_class == "GeometricMatchingModel":
                return GeometricMatchingModel(feature_size=256)
            
            elif model_class == "HRVITONModel":
                return HRVITONModel(input_nc=3, output_nc=3, ngf=64)
            
            elif model_class == "StableDiffusionPipeline":
                return await self._create_diffusion_model(model_config)
            
            else:
                self.logger.warning(f"âš ï¸ ì§€ì›í•˜ì§€ ì•ŠëŠ” ëª¨ë¸ í´ë˜ìŠ¤: {model_class}")
                return None
                
        except Exception as e:
            self.logger.error(f"âŒ ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ì‹¤íŒ¨: {e}")
            return None

    async def _create_diffusion_model(self, model_config: ModelConfig):
        """Diffusion ëª¨ë¸ ìƒì„± (OOTD ë“±)"""
        try:
            if DIFFUSERS_AVAILABLE:
                from diffusers import StableDiffusionPipeline
                
                # ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œê°€ ìˆìœ¼ë©´ ë¡œì»¬ì—ì„œ ë¡œë“œ
                if model_config.checkpoint_path and Path(model_config.checkpoint_path).exists():
                    pipeline = StableDiffusionPipeline.from_pretrained(
                        model_config.checkpoint_path,
                        torch_dtype=torch.float16 if self.use_fp16 else torch.float32,
                        safety_checker=None,
                        requires_safety_checker=False
                    )
                else:
                    # Hugging Faceì—ì„œ ë¡œë“œ
                    pipeline = StableDiffusionPipeline.from_pretrained(
                        "runwayml/stable-diffusion-v1-5",
                        torch_dtype=torch.float16 if self.use_fp16 else torch.float32,
                        safety_checker=None,
                        requires_safety_checker=False
                    )
                
                return pipeline
            else:
                self.logger.warning("âš ï¸ Diffusers ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì—†ì–´ì„œ ê¸°ë³¸ ëª¨ë¸ ìƒì„±")
                return None
                
        except Exception as e:
            self.logger.error(f"âŒ Diffusion ëª¨ë¸ ìƒì„± ì‹¤íŒ¨: {e}")
            return None

    async def _load_checkpoint(self, model: Any, model_config: ModelConfig):
        """ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ"""
        if not model_config.checkpoint_path:
            self.logger.info(f"ğŸ“ ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œ ì—†ìŒ: {model_config.name}")
            return
            
        checkpoint_path = Path(model_config.checkpoint_path)
        
        if not checkpoint_path.exists():
            self.logger.warning(f"âš ï¸ ì²´í¬í¬ì¸íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ: {checkpoint_path}")
            return
        
        try:
            # PyTorch ëª¨ë¸ì¸ ê²½ìš°
            if hasattr(model, 'load_state_dict'):
                state_dict = torch.load(checkpoint_path, map_location=self.device, weights_only=True)
                
                # state_dict ì •ë¦¬
                if isinstance(state_dict, dict) and 'state_dict' in state_dict:
                    state_dict = state_dict['state_dict']
                elif isinstance(state_dict, dict) and 'model' in state_dict:
                    state_dict = state_dict['model']
                
                # í‚¤ ì´ë¦„ ì •ë¦¬ (module. ì œê±° ë“±)
                cleaned_state_dict = {}
                for key, value in state_dict.items():
                    new_key = key.replace('module.', '') if key.startswith('module.') else key
                    cleaned_state_dict[new_key] = value
                
                model.load_state_dict(cleaned_state_dict, strict=False)
                self.logger.info(f"âœ… ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ ì™„ë£Œ: {checkpoint_path}")
            
            # Diffusion íŒŒì´í”„ë¼ì¸ì¸ ê²½ìš°ëŠ” ì´ë¯¸ from_pretrainedì—ì„œ ì²˜ë¦¬ë¨
            else:
                self.logger.info(f"ğŸ“ ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ ê±´ë„ˆëœ€ (íŒŒì´í”„ë¼ì¸): {model_config.name}")
                
        except Exception as e:
            self.logger.warning(f"âš ï¸ ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ ì‹¤íŒ¨: {e}")

    async def _apply_m3_max_optimization(self, model: Any, model_config: ModelConfig) -> Any:
        """M3 Max íŠ¹í™” ëª¨ë¸ ìµœì í™”"""
        try:
            optimizations_applied = []
            
            # 1. MPS ë””ë°”ì´ìŠ¤ ìµœì í™”
            if self.device == 'mps' and hasattr(model, 'to'):
                optimizations_applied.append("MPS device optimization")
            
            # 2. ë©”ëª¨ë¦¬ ìµœì í™” (64GB+ M3 Max)
            if self.memory_gb >= 64:
                optimizations_applied.append("High memory optimization")
            
            # 3. CoreML ì»´íŒŒì¼ ì¤€ë¹„ (ê°€ëŠ¥í•œ ê²½ìš°)
            if (COREML_AVAILABLE and 
                hasattr(model, 'eval') and 
                model_config.model_type in [ModelType.HUMAN_PARSING, ModelType.CLOTH_SEGMENTATION]):
                optimizations_applied.append("CoreML compilation ready")
            
            # 4. Metal Performance Shaders ìµœì í™”
            if self.device == 'mps':
                try:
                    # PyTorch MPS ìµœì í™” ì„¤ì •
                    if hasattr(torch.backends.mps, 'set_per_process_memory_fraction'):
                        torch.backends.mps.set_per_process_memory_fraction(0.8)
                    optimizations_applied.append("Metal Performance Shaders")
                except:
                    pass
            
            if optimizations_applied:
                self.logger.info(f"ğŸ M3 Max ëª¨ë¸ ìµœì í™” ì ìš©: {', '.join(optimizations_applied)}")
            
            return model
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ M3 Max ëª¨ë¸ ìµœì í™” ì‹¤íŒ¨: {e}")
            return model

    async def _load_fallback_model(self, model_name: str) -> Optional[Any]:
        """ëŒ€ì²´ ëª¨ë¸ ë¡œë“œ (MediaPipe, RemBG ë“±)"""
        try:
            # ì´ë¯¸ ë¡œë“œëœ ëŒ€ì²´ ëª¨ë¸ì´ ìˆìœ¼ë©´ ë°˜í™˜
            if model_name in self._fallback_models:
                return self._fallback_models[model_name]
            
            fallback_model = None
            
            # ëª¨ë¸ íƒ€ì…ë³„ ëŒ€ì²´ ëª¨ë¸
            if "pose" in model_name.lower() or "pose_estimation" in model_name:
                fallback_model = self._load_mediapipe_pose()
                
            elif "parsing" in model_name.lower() or "human_parsing" in model_name:
                fallback_model = self._load_mediapipe_selfie()
                
            elif "segmentation" in model_name.lower() or "cloth_segmentation" in model_name:
                fallback_model = self._load_rembg_model()
                
            elif "matching" in model_name.lower() or "geometric" in model_name:
                fallback_model = self._create_simple_matching_model()
                
            elif "warping" in model_name.lower() or "fitting" in model_name or "viton" in model_name:
                fallback_model = self._create_simple_generation_model(model_name)
            
            else:
                fallback_model = self._create_dummy_model(model_name)
            
            if fallback_model:
                self._fallback_models[model_name] = fallback_model
                self.logger.info(f"âœ… ëŒ€ì²´ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {model_name}")
            
            return fallback_model
            
        except Exception as e:
            self.logger.error(f"âŒ ëŒ€ì²´ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return self._create_dummy_model(model_name)

    def _load_mediapipe_pose(self):
        """MediaPipe Pose ëª¨ë¸"""
        try:
            if MEDIAPIPE_AVAILABLE:
                return mp.solutions.pose.Pose(
                    static_image_mode=True,
                    model_complexity=2,
                    enable_segmentation=True,
                    min_detection_confidence=0.5
                )
            else:
                return self._create_dummy_model("pose_estimation")
        except Exception as e:
            self.logger.warning(f"âš ï¸ MediaPipe Pose ë¡œë“œ ì‹¤íŒ¨: {e}")
            return self._create_dummy_model("pose_estimation")

    def _load_mediapipe_selfie(self):
        """MediaPipe Selfie Segmentation"""
        try:
            if MEDIAPIPE_AVAILABLE:
                return mp.solutions.selfie_segmentation.SelfieSegmentation(
                    model_selection=1
                )
            else:
                return self._create_dummy_model("human_parsing")
        except Exception as e:
            self.logger.warning(f"âš ï¸ MediaPipe Selfie ë¡œë“œ ì‹¤íŒ¨: {e}")
            return self._create_dummy_model("human_parsing")

    def _load_rembg_model(self):
        """RemBG ë°°ê²½ ì œê±° ëª¨ë¸"""
        try:
            # rembg ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ìˆìœ¼ë©´ ì‚¬ìš©
            try:
                from rembg import new_session
                return new_session("u2net")
            except ImportError:
                # ì—†ìœ¼ë©´ ê°„ë‹¨í•œ ì„¸ê·¸ë©˜í…Œì´ì…˜ ëª¨ë¸
                return self._create_simple_segmentation_model()
        except Exception as e:
            self.logger.warning(f"âš ï¸ RemBG ë¡œë“œ ì‹¤íŒ¨: {e}")
            return self._create_simple_segmentation_model()

    def _create_simple_segmentation_model(self):
        """ê°„ë‹¨í•œ ì„¸ê·¸ë©˜í…Œì´ì…˜ ëª¨ë¸"""
        class SimpleSegmentationModel(nn.Module):
            def __init__(self):
                super().__init__()
                self.encoder = nn.Sequential(
                    nn.Conv2d(3, 64, 3, 1, 1), nn.ReLU(inplace=True),
                    nn.Conv2d(64, 128, 3, 2, 1), nn.ReLU(inplace=True),
                    nn.Conv2d(128, 256, 3, 2, 1), nn.ReLU(inplace=True),
                )
                self.decoder = nn.Sequential(
                    nn.ConvTranspose2d(256, 128, 4, 2, 1), nn.ReLU(inplace=True),
                    nn.ConvTranspose2d(128, 64, 4, 2, 1), nn.ReLU(inplace=True),
                    nn.Conv2d(64, 1, 3, 1, 1), nn.Sigmoid()
                )
            
            def forward(self, x):
                features = self.encoder(x)
                output = self.decoder(features)
                return output
        
        model = SimpleSegmentationModel()
        if TORCH_AVAILABLE:
            model = model.to(self.device)
        return model

    def _create_simple_matching_model(self):
        """ê°„ë‹¨í•œ ê¸°í•˜í•™ì  ë§¤ì¹­ ëª¨ë¸"""
        class SimpleMatchingModel(nn.Module):
            def __init__(self):
                super().__init__()
                self.feature_net = nn.Sequential(
                    nn.Conv2d(3, 64, 3, 1, 1), nn.ReLU(inplace=True),
                    nn.Conv2d(64, 128, 3, 2, 1), nn.ReLU(inplace=True),
                    nn.AdaptiveAvgPool2d((8, 8)),
                    nn.Flatten(),
                    nn.Linear(128 * 64, 256), nn.ReLU(inplace=True),
                    nn.Linear(256, 18)  # 6ê°œ ì œì–´ì  * 3
                )
            
            def forward(self, source_img, target_img=None):
                if target_img is not None:
                    # ë‘ ì´ë¯¸ì§€ë¥¼ ê²°í•©
                    combined = torch.cat([source_img, target_img], dim=1)
                    combined = nn.functional.interpolate(combined, size=(256, 256), mode='bilinear')
                    # ì²« 3ì±„ë„ë§Œ ì‚¬ìš©
                    combined = combined[:, :3]
                else:
                    combined = source_img
                
                tps_params = self.feature_net(combined)
                return {
                    'tps_params': tps_params.view(-1, 6, 3),
                    'correlation_map': torch.ones(combined.shape[0], 1, 64, 64).to(combined.device)
                }
        
        model = SimpleMatchingModel()
        if TORCH_AVAILABLE:
            model = model.to(self.device)
        return model

    def _create_simple_generation_model(self, model_name: str):
        """ê°„ë‹¨í•œ ìƒì„± ëª¨ë¸"""
        class SimpleGenerationModel(nn.Module):
            def __init__(self, model_name: str):
                super().__init__()
                self.model_name = model_name
                
                # U-Net ìŠ¤íƒ€ì¼ ìƒì„±ê¸°
                self.encoder = nn.Sequential(
                    nn.Conv2d(6, 64, 3, 1, 1), nn.ReLU(inplace=True),
                    nn.Conv2d(64, 128, 3, 2, 1), nn.ReLU(inplace=True),
                    nn.Conv2d(128, 256, 3, 2, 1), nn.ReLU(inplace=True),
                    nn.Conv2d(256, 512, 3, 2, 1), nn.ReLU(inplace=True)
                )
                
                self.decoder = nn.Sequential(
                    nn.ConvTranspose2d(512, 256, 4, 2, 1), nn.ReLU(inplace=True),
                    nn.ConvTranspose2d(256, 128, 4, 2, 1), nn.ReLU(inplace=True),
                    nn.ConvTranspose2d(128, 64, 4, 2, 1), nn.ReLU(inplace=True),
                    nn.Conv2d(64, 3, 3, 1, 1), nn.Tanh()
                )
                
                # ì–´í…ì…˜ ëª¨ë“ˆ
                self.attention = nn.Sequential(
                    nn.Conv2d(6, 32, 3, 1, 1), nn.ReLU(inplace=True),
                    nn.Conv2d(32, 1, 1, 1, 0), nn.Sigmoid()
                )
            
            def forward(self, person_img, cloth_img, **kwargs):
                # ì…ë ¥ ê²°í•©
                combined_input = torch.cat([person_img, cloth_img], dim=1)
                
                # ìƒì„±
                features = self.encoder(combined_input)
                generated = self.decoder(features)
                
                # ì–´í…ì…˜ ì ìš©
                attention_map = self.attention(combined_input)
                
                # ìµœì¢… ê²°ê³¼
                result = generated * attention_map + person_img * (1 - attention_map)
                
                return {
                    'generated_image': result,
                    'attention_map': attention_map,
                    'warped_cloth': cloth_img,  # ê°„ë‹¨í•œ ê²½ìš°
                    'intermediate': generated
                }
        
        model = SimpleGenerationModel(model_name)
        if TORCH_AVAILABLE:
            model = model.to(self.device)
        return model

    def _create_dummy_model(self, model_name: str):
        """ë”ë¯¸ ëª¨ë¸ ìƒì„±"""
        class DummyModel:
            def __init__(self, name: str):
                self.name = name
                self.device_type = "dummy"
            
            def __call__(self, *args, **kwargs):
                return {
                    "result": f"dummy_output_{self.name}",
                    "success": True,
                    "model_type": "dummy"
                }
            
            def forward(self, *args, **kwargs):
                return self(*args, **kwargs)
            
            def to(self, device):
                return self
            
            def eval(self):
                return self
            
            def half(self):
                return self
        
        return DummyModel(model_name)

    async def _check_memory_and_cleanup(self):
        """ë©”ëª¨ë¦¬ í™•ì¸ ë° ì •ë¦¬"""
        try:
            # ìºì‹œëœ ëª¨ë¸ ìˆ˜ í™•ì¸
            if len(self._loaded_models) >= self.max_cached_models:
                await self._cleanup_least_used_models()
            
            # ê°€ë¹„ì§€ ì»¬ë ‰ì…˜
            gc.collect()
            
            # ë””ë°”ì´ìŠ¤ë³„ ë©”ëª¨ë¦¬ ì •ë¦¬
            if self.device == 'cuda' and torch.cuda.is_available():
                torch.cuda.empty_cache()
            elif self.device == 'mps' and torch.backends.mps.is_available():
                try:
                    if hasattr(torch.backends.mps, 'empty_cache'):
                        torch.backends.mps.empty_cache()
                    else:
                        gc.collect()  # PyTorch 2.2.2 í˜¸í™˜ì„±
                except:
                    gc.collect()
                    
        except Exception as e:
            self.logger.warning(f"âš ï¸ ë©”ëª¨ë¦¬ ì •ë¦¬ ì‹¤íŒ¨: {e}")

    async def _cleanup_least_used_models(self, keep_count: int = 5):
        """ì‚¬ìš©ëŸ‰ì´ ì ì€ ëª¨ë¸ ì •ë¦¬"""
        try:
            # ì‚¬ìš© ë¹ˆë„ìˆœìœ¼ë¡œ ì •ë ¬
            sorted_models = sorted(
                self._model_registry.items(),
                key=lambda x: x[1].get("load_count", 0)
            )
            
            cleanup_count = len(self._loaded_models) - keep_count
            cleaned_models = []
            
            for name, _ in sorted_models[:cleanup_count]:
                if name in self._loaded_models:
                    del self._loaded_models[name]
                    self._model_registry[name]["loaded"] = False
                    cleaned_models.append(name)
            
            if cleaned_models:
                self.logger.info(f"ğŸ§¹ ëª¨ë¸ ìºì‹œ ì •ë¦¬: {len(cleaned_models)}ê°œ ëª¨ë¸ í•´ì œ")
                
        except Exception as e:
            self.logger.error(f"âŒ ëª¨ë¸ ì •ë¦¬ ì‹¤íŒ¨: {e}")

    def unload_model(self, name: str) -> bool:
        """ëª¨ë¸ ì–¸ë¡œë“œ"""
        try:
            with self._lock:
                if name in self._loaded_models:
                    del self._loaded_models[name]
                    if name in self._model_registry:
                        self._model_registry[name]["loaded"] = False
                    self.logger.info(f"ğŸ—‘ï¸ ëª¨ë¸ ì–¸ë¡œë“œ: {name}")
                    return True
                return False
                
        except Exception as e:
            self.logger.error(f"âŒ ëª¨ë¸ ì–¸ë¡œë“œ ì‹¤íŒ¨ {name}: {e}")
            return False

    def get_model_info(self, name: str) -> Optional[Dict[str, Any]]:
        """ëª¨ë¸ ì •ë³´ ì¡°íšŒ"""
        with self._lock:
            if name not in self._model_registry:
                return None
                
            info = self._model_registry[name].copy()
            info["is_loaded"] = name in self._loaded_models
            info["load_time"] = self._load_times.get(name, 0)
            info["is_fallback"] = name in self._fallback_models
            
            return info

    def list_models(self) -> Dict[str, Dict[str, Any]]:
        """ë“±ë¡ëœ ëª¨ë¸ ëª©ë¡"""
        with self._lock:
            result = {}
            for name, info in self._model_registry.items():
                result[name] = {
                    "name": name,
                    "model_type": info["config"].model_type.value,
                    "model_class": info["config"].model_class,
                    "device": info["config"].device,
                    "loaded": name in self._loaded_models,
                    "load_count": info.get("load_count", 0),
                    "load_time": self._load_times.get(name, 0),
                    "checkpoint_path": info["config"].checkpoint_path,
                    "input_size": info["config"].input_size
                }
            return result

    def get_memory_usage(self) -> Dict[str, Any]:
        """ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¡°íšŒ"""
        try:
            usage = {
                "loaded_models": len(self._loaded_models),
                "fallback_models": len(self._fallback_models),
                "device": self.device
            }
            
            if self.device == "cuda" and torch.cuda.is_available():
                usage.update({
                    "allocated_gb": torch.cuda.memory_allocated() / 1024**3,
                    "cached_gb": torch.cuda.memory_reserved() / 1024**3
                })
            elif self.device == "mps":
                try:
                    import psutil
                    process = psutil.Process()
                    usage.update({
                        "process_memory_gb": process.memory_info().rss / 1024**3,
                        "system_memory_percent": psutil.virtual_memory().percent
                    })
                except ImportError:
                    usage["memory_info"] = "psutil not available"
            else:
                usage["memory_info"] = "cpu mode"
                
            return usage
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {"error": str(e)}

    async def initialize(self) -> bool:
        """ëª¨ë¸ ë¡œë” ì´ˆê¸°í™”"""
        try:
            # ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œ í™•ì¸
            missing_checkpoints = []
            for name, info in self._model_registry.items():
                config = info["config"]
                if config.checkpoint_path:
                    checkpoint_path = Path(config.checkpoint_path)
                    if not checkpoint_path.exists():
                        missing_checkpoints.append(name)
            
            if missing_checkpoints:
                self.logger.warning(f"âš ï¸ ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ì´ ì—†ëŠ” ëª¨ë¸ë“¤: {missing_checkpoints}")
                self.logger.info("ğŸ“ í•´ë‹¹ ëª¨ë¸ë“¤ì€ ëŒ€ì²´ ëª¨ë¸ë¡œ ë¡œë“œë©ë‹ˆë‹¤")
            
            # M3 Max ìµœì í™” ì„¤ì •
            if self.coreml_optimization and COREML_AVAILABLE:
                self.logger.info("ğŸ CoreML ìµœì í™” ì„¤ì • ì™„ë£Œ")
            
            self.logger.info(f"âœ… ì‹¤ì œ AI ëª¨ë¸ ë¡œë” ì´ˆê¸°í™” ì™„ë£Œ - {len(self._model_registry)}ê°œ ëª¨ë¸ ë“±ë¡ë¨")
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ ëª¨ë¸ ë¡œë” ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return False

    async def get_step_info(self) -> Dict[str, Any]:
        """ëª¨ë¸ ë¡œë” ì •ë³´ ë°˜í™˜"""
        return {
            "step_name": self.step_name,
            "device": self.device,
            "device_type": self.device_type,
            "memory_gb": self.memory_gb,
            "is_m3_max": self.is_m3_max,
            "optimization_enabled": self.optimization_enabled,
            "quality_level": self.quality_level,
            "initialized": self.is_initialized,
            "config_keys": list(self.config.keys()),
            "specialized_features": {
                "use_fp16": self.use_fp16,
                "coreml_optimization": self.coreml_optimization,
                "lazy_loading": self.lazy_loading,
                "auto_quantization": self.auto_quantization,
                "memory_mapping": self.memory_mapping,
                "max_cached_models": self.max_cached_models
            },
            "model_stats": {
                "registered_models": len(self._model_registry),
                "loaded_models": len(self._loaded_models),
                "fallback_models": len(self._fallback_models),
                "total_load_count": sum(info.get("load_count", 0) for info in self._model_registry.values()),
                "average_load_time": sum(self._load_times.values()) / len(self._load_times) if self._load_times else 0
            },
            "library_availability": {
                "torch": TORCH_AVAILABLE,
                "opencv": CV_AVAILABLE,
                "mediapipe": MEDIAPIPE_AVAILABLE,
                "transformers": TRANSFORMERS_AVAILABLE,
                "diffusers": DIFFUSERS_AVAILABLE,
                "onnx": ONNX_AVAILABLE,
                "coreml": COREML_AVAILABLE
            }
        }

# ==============================================
# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
# ==============================================

def preprocess_image(image: Union[np.ndarray, Image.Image], target_size: tuple, normalize: bool = True) -> torch.Tensor:
    """ì´ë¯¸ì§€ ì „ì²˜ë¦¬"""
    try:
        if not CV_AVAILABLE:
            raise ImportError("OpenCV not available")
            
        if isinstance(image, np.ndarray):
            if image.shape[2] == 4:  # RGBA
                image = cv2.cvtColor(image, cv2.COLOR_RGBA2RGB)
            elif len(image.shape) == 3 and image.shape[2] == 3:
                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            image = Image.fromarray(image)
        elif not isinstance(image, Image.Image):
            raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì´ë¯¸ì§€ íƒ€ì…: {type(image)}")
        
        # ë¦¬ì‚¬ì´ì¦ˆ
        image = image.resize(target_size, Image.Resampling.LANCZOS)
        
        # í…ì„œ ë³€í™˜
        image_array = np.array(image).astype(np.float32)
        image_tensor = torch.from_numpy(image_array).permute(2, 0, 1) / 255.0
        
        # ì •ê·œí™”
        if normalize:
            mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)
            std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)
            image_tensor = (image_tensor - mean) / std
        
        return image_tensor.unsqueeze(0)
        
    except Exception as e:
        logging.error(f"ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        # ë”ë¯¸ í…ì„œ ë°˜í™˜
        return torch.randn(1, 3, target_size[1], target_size[0])

def postprocess_segmentation(output: torch.Tensor, original_size: tuple, threshold: float = 0.5) -> np.ndarray:
    """ì„¸ê·¸ë©˜í…Œì´ì…˜ í›„ì²˜ë¦¬"""
    try:
        if not CV_AVAILABLE:
            raise ImportError("OpenCV not available")
            
        if output.dim() == 4:
            output = output.squeeze(0)
        
        # í™•ë¥ ì„ í´ë˜ìŠ¤ë¡œ ë³€í™˜
        if output.shape[0] > 1:
            output = torch.argmax(output, dim=0)
        else:
            output = (output > threshold).float()
        
        # CPUë¡œ ì´ë™ ë° numpy ë³€í™˜
        output = output.cpu().numpy().astype(np.uint8)
        
        # ì›ë³¸ í¬ê¸°ë¡œ ë¦¬ì‚¬ì´ì¦ˆ
        if output.shape != original_size[::-1]:
            output = cv2.resize(output, original_size, interpolation=cv2.INTER_NEAREST)
        
        return output
        
    except Exception as e:
        logging.error(f"ì„¸ê·¸ë©˜í…Œì´ì…˜ í›„ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        return np.zeros(original_size[::-1], dtype=np.uint8)

def postprocess_pose(output: torch.Tensor, original_size: tuple, confidence_threshold: float = 0.3) -> Dict[str, Any]:
    """í¬ì¦ˆ ì¶”ì • í›„ì²˜ë¦¬"""
    try:
        if isinstance(output, (list, tuple)):
            # OpenPose ìŠ¤íƒ€ì¼ ì¶œë ¥ (PAF, heatmaps)
            pafs, heatmaps = output[-1]  # ë§ˆì§€ë§‰ ìŠ¤í…Œì´ì§€ ê²°ê³¼ ì‚¬ìš©
        else:
            heatmaps = output
            pafs = None
        
        # í‚¤í¬ì¸íŠ¸ ì¶”ì¶œ
        keypoints = []
        if heatmaps.dim() == 4:
            heatmaps = heatmaps.squeeze(0)
        
        for i in range(heatmaps.shape[0] - 1):  # ë°°ê²½ ì œì™¸
            heatmap = heatmaps[i].cpu().numpy()
            
            # ìµœëŒ€ê°’ ìœ„ì¹˜ ì°¾ê¸°
            y, x = np.unravel_index(np.argmax(heatmap), heatmap.shape)
            confidence = heatmap[y, x]
            
            if confidence > confidence_threshold:
                # ì›ë³¸ ì´ë¯¸ì§€ í¬ê¸°ë¡œ ìŠ¤ì¼€ì¼ë§
                x_scaled = int(x * original_size[0] / heatmap.shape[1])
                y_scaled = int(y * original_size[1] / heatmap.shape[0])
                keypoints.append([x_scaled, y_scaled, confidence])
            else:
                keypoints.append([0, 0, 0])
        
        return {
            'keypoints': keypoints,
            'pafs': pafs.cpu().numpy() if pafs is not None else None,
            'heatmaps': heatmaps.cpu().numpy()
        }
        
    except Exception as e:
        logging.error(f"í¬ì¦ˆ ì¶”ì • í›„ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        return {'keypoints': [], 'pafs': None, 'heatmaps': None}

# ==============================================
# í¸ì˜ í•¨ìˆ˜ë“¤ (í•˜ìœ„ í˜¸í™˜ì„±)
# ==============================================

def create_model_loader(
    device: str = "mps",
    use_fp16: bool = True,
    **kwargs
) -> ModelLoader:
    """ëª¨ë¸ ë¡œë” ìƒì„± (í•˜ìœ„ í˜¸í™˜)"""
    return ModelLoader(
        device=device,
        use_fp16=use_fp16,
        **kwargs
    )

# ì „ì—­ ëª¨ë¸ ë¡œë” (ì„ íƒì )
_global_model_loader: Optional[ModelLoader] = None

def get_global_model_loader() -> Optional[ModelLoader]:
    """ì „ì—­ ëª¨ë¸ ë¡œë” ë°˜í™˜"""
    global _global_model_loader
    return _global_model_loader

def initialize_global_model_loader(**kwargs) -> ModelLoader:
    """ì „ì—­ ëª¨ë¸ ë¡œë” ì´ˆê¸°í™”"""
    global _global_model_loader
    _global_model_loader = ModelLoader(**kwargs)
    return _global_model_loader

async def load_model_async(model_name: str, config: Optional[ModelConfig] = None) -> Optional[Any]:
    """ë¹„ë™ê¸° ëª¨ë¸ ë¡œë“œ"""
    try:
        loader = get_global_model_loader()
        if loader is None:
            loader = initialize_global_model_loader()
        return await loader.load_model(model_name)
    except Exception as e:
        logging.error(f"ë¹„ë™ê¸° ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None

def load_model_sync(model_name: str, config: Optional[ModelConfig] = None) -> Optional[Any]:
    """ë™ê¸° ëª¨ë¸ ë¡œë“œ"""
    try:
        loader = get_global_model_loader()
        if loader is None:
            loader = initialize_global_model_loader()
        # ë™ê¸° ë²„ì „ì—ì„œëŠ” asyncio ì‚¬ìš©
        import asyncio
        return asyncio.run(loader.load_model(model_name))
    except Exception as e:
        logging.error(f"ë™ê¸° ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None

def cleanup_global_loader():
    """ì „ì—­ ë¡œë” ì •ë¦¬"""
    global _global_model_loader
    if _global_model_loader:
        try:
            import asyncio
            asyncio.run(_global_model_loader._check_memory_and_cleanup())
        except:
            pass
        _global_model_loader = None

# ëª¨ë“ˆ ë ˆë²¨ì—ì„œ ì •ë¦¬ í•¨ìˆ˜ ë“±ë¡
import atexit
atexit.register(cleanup_global_loader)

# ëª¨ë“ˆ ìµìŠ¤í¬íŠ¸
__all__ = [
    'ModelLoader',
    'ModelConfig', 
    'ModelType',
    'OptimalStepConstructor',
    'GraphonomyModel',
    'OpenPoseModel', 
    'U2NetModel',
    'GeometricMatchingModel',
    'HRVITONModel',
    'create_model_loader',
    'get_global_model_loader',
    'initialize_global_model_loader',
    'load_model_async',
    'load_model_sync',
    'preprocess_image',
    'postprocess_segmentation',
    'postprocess_pose'
]