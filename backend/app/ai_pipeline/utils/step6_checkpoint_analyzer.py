#!/usr/bin/env python3
"""
π”¥ Step 6 Virtual Fitting μ²΄ν¬ν¬μΈνΈ λ¶„μ„ λ° λ΅λ”© μ‹μ¤ν…
=======================================================

β… Step 3, 4 ν¨ν„΄ κΈ°λ° μ²΄ν¬ν¬μΈνΈ λ¶„μ„
β… OOTD, VITON-HD, Stable Diffusion μ²΄ν¬ν¬μΈνΈ λ¶„μ„
β… μ²΄ν¬ν¬μΈνΈ μμ • λ° ν‚¤ λ§¤ν•‘
β… μ•μ „ν• λ¨λΈ λ΅λ”© μ‹μ¤ν…
β… Mock ν΄λ°± μ‹μ¤ν…

Author: MyCloset AI Team
Date: 2025-08-08
Version: 1.0
"""

import os
import logging
import torch
import numpy as np
from typing import Dict, Any, Optional, List, Tuple
from pathlib import Path

logger = logging.getLogger(__name__)

class Step6CheckpointAnalyzer:
    """Step 6 μ²΄ν¬ν¬μΈνΈ λ¶„μ„κΈ°"""
    
    def __init__(self):
        self.logger = logging.getLogger(f"{__name__}.Step6CheckpointAnalyzer")
        self.analyzed_checkpoints = {}
        self.fixed_checkpoints = {}
    
    def analyze_checkpoint_structure(self, checkpoint_path: str) -> Dict[str, Any]:
        """μ²΄ν¬ν¬μΈνΈ κµ¬μ΅° λ¶„μ„"""
        try:
            self.logger.info(f"π” μ²΄ν¬ν¬μΈνΈ κµ¬μ΅° λ¶„μ„: {checkpoint_path}")
            
            if checkpoint_path.endswith('.safetensors'):
                from safetensors.torch import load_file
                checkpoint = load_file(checkpoint_path)
            else:
                checkpoint = torch.load(checkpoint_path, map_location='cpu', weights_only=False)
            
            if 'state_dict' in checkpoint:
                state_dict = checkpoint['state_dict']
            else:
                state_dict = checkpoint
            
            # ν‚¤ ν¨ν„΄ λ¶„μ„
            key_patterns = {}
            for key in state_dict.keys():
                prefix = key.split('.')[0] if '.' in key else key
                if prefix not in key_patterns:
                    key_patterns[prefix] = []
                key_patterns[prefix].append(key)
            
            # ν•νƒ λ¶„μ„
            shape_analysis = {}
            for key, tensor in state_dict.items():
                shape_analysis[key] = list(tensor.shape)
            
            analysis_result = {
                'total_keys': len(state_dict),
                'key_patterns': key_patterns,
                'shape_analysis': shape_analysis,
                'sample_keys': list(state_dict.keys())[:10],
                'file_size_mb': os.path.getsize(checkpoint_path) / (1024 * 1024),
                'is_safetensors': checkpoint_path.endswith('.safetensors')
            }
            
            self.analyzed_checkpoints[checkpoint_path] = analysis_result
            self.logger.info(f"β… μ²΄ν¬ν¬μΈνΈ λ¶„μ„ μ™„λ£: {analysis_result['total_keys']}κ° ν‚¤")
            
            return analysis_result
            
        except Exception as e:
            self.logger.error(f"β μ²΄ν¬ν¬μΈνΈ λ¶„μ„ μ‹¤ν¨: {e}")
            return {'error': str(e)}
    
    def validate_checkpoint(self, checkpoint_path: str, model_type: str) -> Dict[str, Any]:
        """μ²΄ν¬ν¬μΈνΈ μ ν¨μ„± κ²€μ‚¬"""
        try:
            self.logger.info(f"π” μ²΄ν¬ν¬μΈνΈ μ ν¨μ„± κ²€μ‚¬: {checkpoint_path}")
            
            # νμΌ μ΅΄μ¬ ν™•μΈ
            if not os.path.exists(checkpoint_path):
                return {'is_valid': False, 'errors': ['νμΌμ΄ μ΅΄μ¬ν•μ§€ μ•μµλ‹λ‹¤']}
            
            # νμΌ ν¬κΈ° ν™•μΈ
            file_size = os.path.getsize(checkpoint_path)
            if file_size < 1024:  # 1KB λ―Έλ§
                return {'is_valid': False, 'errors': ['νμΌμ΄ λ„λ¬΄ μ‘μµλ‹λ‹¤']}
            
            # μ²΄ν¬ν¬μΈνΈ λ΅λ”© μ‹λ„
            try:
                if checkpoint_path.endswith('.safetensors'):
                    from safetensors.torch import load_file
                    checkpoint = load_file(checkpoint_path)
                else:
                    checkpoint = torch.load(checkpoint_path, map_location='cpu', weights_only=False)
                
                if 'state_dict' in checkpoint:
                    state_dict = checkpoint['state_dict']
                else:
                    state_dict = checkpoint
                
                # κΈ°λ³Έ μ ν¨μ„± κ²€μ‚¬
                if not isinstance(state_dict, dict):
                    return {'is_valid': False, 'errors': ['state_dictκ°€ λ”•μ…”λ„λ¦¬κ°€ μ•„λ‹™λ‹λ‹¤']}
                
                if len(state_dict) == 0:
                    return {'is_valid': False, 'errors': ['state_dictκ°€ λΉ„μ–΄μμµλ‹λ‹¤']}
                
                # λ¨λΈλ³„ νΉμ • κ²€μ‚¬
                model_specific_errors = self._validate_model_specific(checkpoint_path, state_dict, model_type)
                if model_specific_errors:
                    return {'is_valid': False, 'errors': model_specific_errors}
                
                return {'is_valid': True, 'errors': []}
                
            except Exception as e:
                return {'is_valid': False, 'errors': [f'μ²΄ν¬ν¬μΈνΈ λ΅λ”© μ‹¤ν¨: {e}']}
                
        except Exception as e:
            self.logger.error(f"β μ²΄ν¬ν¬μΈνΈ μ ν¨μ„± κ²€μ‚¬ μ‹¤ν¨: {e}")
            return {'is_valid': False, 'errors': [str(e)]}
    
    def _validate_model_specific(self, checkpoint_path: str, state_dict: Dict, model_type: str) -> List[str]:
        """λ¨λΈλ³„ νΉμ • μ ν¨μ„± κ²€μ‚¬"""
        errors = []
        
        if model_type == "ootd":
            # OOTD λ¨λΈ κ²€μ‚¬
            required_patterns = ['time_embedding', 'encoder', 'decoder', 'bottleneck']
            found_patterns = []
            for key in state_dict.keys():
                for pattern in required_patterns:
                    if pattern in key:
                        found_patterns.append(pattern)
                        break
            
            if len(found_patterns) < 2:
                errors.append(f"OOTD λ¨λΈ ν¨ν„΄ λ¶€μ΅±: {found_patterns}")
        
        elif model_type == "viton_hd":
            # VITON-HD λ¨λΈ κ²€μ‚¬
            required_patterns = ['geometric_matcher', 'tryon_generator', 'refinement_net']
            found_patterns = []
            for key in state_dict.keys():
                for pattern in required_patterns:
                    if pattern in key:
                        found_patterns.append(pattern)
                        break
            
            if len(found_patterns) < 1:
                errors.append(f"VITON-HD λ¨λΈ ν¨ν„΄ λ¶€μ΅±: {found_patterns}")
        
        elif model_type == "stable_diffusion":
            # Stable Diffusion λ¨λΈ κ²€μ‚¬
            required_patterns = ['unet', 'vae', 'text_encoder']
            found_patterns = []
            for key in state_dict.keys():
                for pattern in required_patterns:
                    if pattern in key:
                        found_patterns.append(pattern)
                        break
            
            if len(found_patterns) < 1:
                errors.append(f"Stable Diffusion λ¨λΈ ν¨ν„΄ λ¶€μ΅±: {found_patterns}")
        
        return errors

class Step6CheckpointFixer:
    """Step 6 μ²΄ν¬ν¬μΈνΈ μμ •κΈ°"""
    
    def __init__(self):
        self.logger = logging.getLogger(f"{__name__}.Step6CheckpointFixer")
    
    def fix_checkpoint(self, checkpoint_path: str, model_type: str) -> Optional[Dict]:
        """μ²΄ν¬ν¬μΈνΈ μμ •"""
        try:
            self.logger.info(f"π”§ μ²΄ν¬ν¬μΈνΈ μμ • μ‹λ„: {checkpoint_path}")
            
            # μ²΄ν¬ν¬μΈνΈ λ΅λ”©
            if checkpoint_path.endswith('.safetensors'):
                from safetensors.torch import load_file
                checkpoint = load_file(checkpoint_path)
            else:
                checkpoint = torch.load(checkpoint_path, map_location='cpu', weights_only=False)
            
            if 'state_dict' in checkpoint:
                state_dict = checkpoint['state_dict']
            else:
                state_dict = checkpoint
            
            # λ¨λΈλ³„ μμ • μ μ©
            fixed_state_dict = self._apply_model_specific_fixes(state_dict, model_type)
            
            if fixed_state_dict:
                self.logger.info(f"β… μ²΄ν¬ν¬μΈνΈ μμ • μ™„λ£: {len(fixed_state_dict)}κ° ν‚¤")
                return fixed_state_dict
            else:
                self.logger.warning("β οΈ μ²΄ν¬ν¬μΈνΈ μμ • μ‹¤ν¨")
                return None
                
        except Exception as e:
            self.logger.error(f"β μ²΄ν¬ν¬μΈνΈ μμ • μ‹¤ν¨: {e}")
            return None
    
    def _apply_model_specific_fixes(self, state_dict: Dict, model_type: str) -> Optional[Dict]:
        """λ¨λΈλ³„ νΉμ • μμ • μ μ©"""
        try:
            if model_type == "ootd":
                return self._fix_ootd_checkpoint(state_dict)
            elif model_type == "viton_hd":
                return self._fix_viton_hd_checkpoint(state_dict)
            elif model_type == "stable_diffusion":
                return self._fix_stable_diffusion_checkpoint(state_dict)
            else:
                return state_dict
                
        except Exception as e:
            self.logger.error(f"β λ¨λΈλ³„ μμ • μ‹¤ν¨: {e}")
            return None
    
    def _fix_ootd_checkpoint(self, state_dict: Dict) -> Dict:
        """OOTD μ²΄ν¬ν¬μΈνΈ μμ •"""
        fixed_state_dict = {}
        
        # ν‚¤ λ§¤ν•‘ κ·μΉ™
        key_mappings = {
            'model.': '',
            'unet.': '',
            'diffusion.': '',
            'time_embedding.': 'time_embedding.',
            'encoder_blocks.': 'encoder_blocks.',
            'decoder_blocks.': 'decoder_blocks.',
            'bottleneck_': 'bottleneck_',
            'cross_attention.': 'cross_attention.',
            'cloth_encoder.': 'cloth_encoder.',
            'output_conv.': 'output_conv.'
        }
        
        for key, value in state_dict.items():
            new_key = key
            for old_prefix, new_prefix in key_mappings.items():
                if key.startswith(old_prefix):
                    new_key = key.replace(old_prefix, new_prefix, 1)
                    break
            
            fixed_state_dict[new_key] = value
        
        return fixed_state_dict
    
    def _fix_viton_hd_checkpoint(self, state_dict: Dict) -> Dict:
        """VITON-HD μ²΄ν¬ν¬μΈνΈ μμ •"""
        fixed_state_dict = {}
        
        # ν‚¤ λ§¤ν•‘ κ·μΉ™
        key_mappings = {
            'model.': '',
            'viton.': '',
            'hrviton.': '',
            'geometric_matcher.': 'geometric_matcher.',
            'tryon_generator.': 'tryon_generator.',
            'refinement_net.': 'refinement_net.',
            'feature_extractor.': 'geometric_matcher.feature_extractor.',
            'flow_predictor.': 'geometric_matcher.flow_predictor.',
            'upsample.': 'geometric_matcher.upsample.'
        }
        
        for key, value in state_dict.items():
            new_key = key
            for old_prefix, new_prefix in key_mappings.items():
                if key.startswith(old_prefix):
                    new_key = key.replace(old_prefix, new_prefix, 1)
                    break
            
            fixed_state_dict[new_key] = value
        
        return fixed_state_dict
    
    def _fix_stable_diffusion_checkpoint(self, state_dict: Dict) -> Dict:
        """Stable Diffusion μ²΄ν¬ν¬μΈνΈ μμ •"""
        fixed_state_dict = {}
        
        # ν‚¤ λ§¤ν•‘ κ·μΉ™
        key_mappings = {
            'model.': '',
            'unet.': '',
            'diffusion.': '',
            'vae.': 'vae_encoder.',
            'text_encoder.': 'text_encoder.',
            'noise_scheduler.': 'noise_scheduler.',
            'controlnet.': 'controlnet.',
            'lora_adapter.': 'lora_adapter.'
        }
        
        for key, value in state_dict.items():
            new_key = key
            for old_prefix, new_prefix in key_mappings.items():
                if key.startswith(old_prefix):
                    new_key = key.replace(old_prefix, new_prefix, 1)
                    break
            
            fixed_state_dict[new_key] = value
        
        return fixed_state_dict

class Step6ModelLoader:
    """Step 6 λ¨λΈ λ΅λ”"""
    
    def __init__(self):
        self.logger = logging.getLogger(f"{__name__}.Step6ModelLoader")
        self.analyzer = Step6CheckpointAnalyzer()
        self.fixer = Step6CheckpointFixer()
        self.loaded_models = {}
    
    def load_ootd_model(self, device='cpu'):
        """OOTD λ¨λΈ λ΅λ”©"""
        try:
            from ..steps.step_06_virtual_fitting import OOTDDiffusionModel
            
            self.logger.info("π”„ OOTD λ¨λΈ λ΅λ”© μ‹μ‘")
            
            # μ²΄ν¬ν¬μΈνΈ κ²½λ΅λ“¤
            checkpoint_paths = [
                "ai_models/step_06_virtual_fitting/ootd_3.2gb.pth",
                "ai_models/step_06_virtual_fitting/ootd_checkpoint.pth",
                "ai_models/checkpoints/step_06_virtual_fitting/ootd_checkpoint.pth"
            ]
            
            for checkpoint_path in checkpoint_paths:
                if os.path.exists(checkpoint_path):
                    self.logger.info(f"π”„ OOTD μ²΄ν¬ν¬μΈνΈ λ¶„μ„: {checkpoint_path}")
                    
                    # μ²΄ν¬ν¬μΈνΈ λ¶„μ„
                    analysis = self.analyzer.analyze_checkpoint_structure(checkpoint_path)
                    if 'error' in analysis:
                        self.logger.warning(f"β οΈ μ²΄ν¬ν¬μΈνΈ λ¶„μ„ μ‹¤ν¨: {analysis['error']}")
                        continue
                    
                    # μ²΄ν¬ν¬μΈνΈ μ ν¨μ„± κ²€μ‚¬
                    validation = self.analyzer.validate_checkpoint(checkpoint_path, "ootd")
                    if not validation['is_valid']:
                        self.logger.warning(f"β οΈ μ²΄ν¬ν¬μΈνΈ μ ν¨μ„± κ²€μ‚¬ μ‹¤ν¨: {validation['errors']}")
                        
                        # μ²΄ν¬ν¬μΈνΈ μμ • μ‹λ„
                        fixed_checkpoint = self.fixer.fix_checkpoint(checkpoint_path, "ootd")
                        if fixed_checkpoint:
                            self.logger.info("β… μ²΄ν¬ν¬μΈνΈ μμ • μ™„λ£")
                        else:
                            self.logger.warning("β οΈ μ²΄ν¬ν¬μΈνΈ μμ • μ‹¤ν¨")
                            continue
                    else:
                        # μ›λ³Έ μ²΄ν¬ν¬μΈνΈ μ‚¬μ©
                        if checkpoint_path.endswith('.safetensors'):
                            from safetensors.torch import load_file
                            fixed_checkpoint = load_file(checkpoint_path)
                        else:
                            checkpoint = torch.load(checkpoint_path, map_location='cpu', weights_only=False)
                            if 'state_dict' in checkpoint:
                                fixed_checkpoint = checkpoint['state_dict']
                            else:
                                fixed_checkpoint = checkpoint
                    
                    # λ¨λΈ μƒμ„± λ° κ°€μ¤‘μΉ λ΅λ”©
                    model = OOTDDiffusionModel()
                    model.load_state_dict(fixed_checkpoint, strict=False)
                    model.to(device)
                    model.eval()
                    
                    self.logger.info(f"β… OOTD λ¨λΈ λ΅λ”© μ™„λ£: {checkpoint_path}")
                    self.loaded_models['ootd'] = model
                    return model
            
            self.logger.error("β OOTD μ²΄ν¬ν¬μΈνΈλ¥Ό μ°Ύμ„ μ μ—†μµλ‹λ‹¤")
            return None
            
        except Exception as e:
            self.logger.error(f"β OOTD λ¨λΈ λ΅λ”© μ‹¤ν¨: {e}")
            return None
    
    def load_viton_hd_model(self, device='cpu'):
        """VITON-HD λ¨λΈ λ΅λ”©"""
        try:
            from ..steps.step_06_virtual_fitting import VITONHDModel
            
            self.logger.info("π”„ VITON-HD λ¨λΈ λ΅λ”© μ‹μ‘")
            
            # μ²΄ν¬ν¬μΈνΈ κ²½λ΅λ“¤
            checkpoint_paths = [
                "ai_models/step_06_virtual_fitting/viton_hd_2.1gb.pth",
                "ai_models/step_06_virtual_fitting/hrviton_final.pth",
                "ai_models/checkpoints/step_06_virtual_fitting/hrviton_final.pth"
            ]
            
            for checkpoint_path in checkpoint_paths:
                if os.path.exists(checkpoint_path):
                    self.logger.info(f"π”„ VITON-HD μ²΄ν¬ν¬μΈνΈ λ¶„μ„: {checkpoint_path}")
                    
                    # μ²΄ν¬ν¬μΈνΈ λ¶„μ„
                    analysis = self.analyzer.analyze_checkpoint_structure(checkpoint_path)
                    if 'error' in analysis:
                        self.logger.warning(f"β οΈ μ²΄ν¬ν¬μΈνΈ λ¶„μ„ μ‹¤ν¨: {analysis['error']}")
                        continue
                    
                    # μ²΄ν¬ν¬μΈνΈ μ ν¨μ„± κ²€μ‚¬
                    validation = self.analyzer.validate_checkpoint(checkpoint_path, "viton_hd")
                    if not validation['is_valid']:
                        self.logger.warning(f"β οΈ μ²΄ν¬ν¬μΈνΈ μ ν¨μ„± κ²€μ‚¬ μ‹¤ν¨: {validation['errors']}")
                        
                        # μ²΄ν¬ν¬μΈνΈ μμ • μ‹λ„
                        fixed_checkpoint = self.fixer.fix_checkpoint(checkpoint_path, "viton_hd")
                        if fixed_checkpoint:
                            self.logger.info("β… μ²΄ν¬ν¬μΈνΈ μμ • μ™„λ£")
                        else:
                            self.logger.warning("β οΈ μ²΄ν¬ν¬μΈνΈ μμ • μ‹¤ν¨")
                            continue
                    else:
                        # μ›λ³Έ μ²΄ν¬ν¬μΈνΈ μ‚¬μ©
                        if checkpoint_path.endswith('.safetensors'):
                            from safetensors.torch import load_file
                            fixed_checkpoint = load_file(checkpoint_path)
                        else:
                            checkpoint = torch.load(checkpoint_path, map_location='cpu', weights_only=False)
                            if 'state_dict' in checkpoint:
                                fixed_checkpoint = checkpoint['state_dict']
                            else:
                                fixed_checkpoint = checkpoint
                    
                    # λ¨λΈ μƒμ„± λ° κ°€μ¤‘μΉ λ΅λ”©
                    model = VITONHDModel()
                    model.load_state_dict(fixed_checkpoint, strict=False)
                    model.to(device)
                    model.eval()
                    
                    self.logger.info(f"β… VITON-HD λ¨λΈ λ΅λ”© μ™„λ£: {checkpoint_path}")
                    self.loaded_models['viton_hd'] = model
                    return model
            
            self.logger.error("β VITON-HD μ²΄ν¬ν¬μΈνΈλ¥Ό μ°Ύμ„ μ μ—†μµλ‹λ‹¤")
            return None
            
        except Exception as e:
            self.logger.error(f"β VITON-HD λ¨λΈ λ΅λ”© μ‹¤ν¨: {e}")
            return None
    
    def load_stable_diffusion_model(self, device='cpu'):
        """Stable Diffusion λ¨λΈ λ΅λ”©"""
        try:
            from ..steps.step_06_virtual_fitting import StableDiffusionNeuralNetwork
            
            self.logger.info("π”„ Stable Diffusion λ¨λΈ λ΅λ”© μ‹μ‘")
            
            # μ²΄ν¬ν¬μΈνΈ κ²½λ΅λ“¤
            checkpoint_paths = [
                "ai_models/step_06_virtual_fitting/stable_diffusion_4.8gb.pth",
                "ai_models/checkpoints/stable_diffusion_4.8gb.pth"
            ]
            
            for checkpoint_path in checkpoint_paths:
                if os.path.exists(checkpoint_path):
                    self.logger.info(f"π”„ Stable Diffusion μ²΄ν¬ν¬μΈνΈ λ¶„μ„: {checkpoint_path}")
                    
                    # μ²΄ν¬ν¬μΈνΈ λ¶„μ„
                    analysis = self.analyzer.analyze_checkpoint_structure(checkpoint_path)
                    if 'error' in analysis:
                        self.logger.warning(f"β οΈ μ²΄ν¬ν¬μΈνΈ λ¶„μ„ μ‹¤ν¨: {analysis['error']}")
                        continue
                    
                    # μ²΄ν¬ν¬μΈνΈ μ ν¨μ„± κ²€μ‚¬
                    validation = self.analyzer.validate_checkpoint(checkpoint_path, "stable_diffusion")
                    if not validation['is_valid']:
                        self.logger.warning(f"β οΈ μ²΄ν¬ν¬μΈνΈ μ ν¨μ„± κ²€μ‚¬ μ‹¤ν¨: {validation['errors']}")
                        
                        # μ²΄ν¬ν¬μΈνΈ μμ • μ‹λ„
                        fixed_checkpoint = self.fixer.fix_checkpoint(checkpoint_path, "stable_diffusion")
                        if fixed_checkpoint:
                            self.logger.info("β… μ²΄ν¬ν¬μΈνΈ μμ • μ™„λ£")
                        else:
                            self.logger.warning("β οΈ μ²΄ν¬ν¬μΈνΈ μμ • μ‹¤ν¨")
                            continue
                    else:
                        # μ›λ³Έ μ²΄ν¬ν¬μΈνΈ μ‚¬μ©
                        if checkpoint_path.endswith('.safetensors'):
                            from safetensors.torch import load_file
                            fixed_checkpoint = load_file(checkpoint_path)
                        else:
                            checkpoint = torch.load(checkpoint_path, map_location='cpu', weights_only=False)
                            if 'state_dict' in checkpoint:
                                fixed_checkpoint = checkpoint['state_dict']
                            else:
                                fixed_checkpoint = checkpoint
                    
                    # λ¨λΈ μƒμ„± λ° κ°€μ¤‘μΉ λ΅λ”©
                    model = StableDiffusionNeuralNetwork()
                    model.load_state_dict(fixed_checkpoint, strict=False)
                    model.to(device)
                    model.eval()
                    
                    self.logger.info(f"β… Stable Diffusion λ¨λΈ λ΅λ”© μ™„λ£: {checkpoint_path}")
                    self.loaded_models['stable_diffusion'] = model
                    return model
            
            self.logger.error("β Stable Diffusion μ²΄ν¬ν¬μΈνΈλ¥Ό μ°Ύμ„ μ μ—†μµλ‹λ‹¤")
            return None
            
        except Exception as e:
            self.logger.error(f"β Stable Diffusion λ¨λΈ λ΅λ”© μ‹¤ν¨: {e}")
            return None

# μ „μ—­ μΈμ¤ν„΄μ¤
step6_model_loader = Step6ModelLoader()

def get_step6_model_loader():
    """Step 6 λ¨λΈ λ΅λ” μΈμ¤ν„΄μ¤ λ°ν™"""
    return step6_model_loader
