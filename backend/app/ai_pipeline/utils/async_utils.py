# backend/app/ai_pipeline/utils/async_utils.py
"""
ğŸ”„ MyCloset AI - ë¹„ë™ê¸° ìœ í‹¸ë¦¬í‹° ì‹œìŠ¤í…œ v1.0
==============================================
âœ… ë¹„ë™ê¸° ì‘ì—… ê´€ë¦¬ ë° ìŠ¤ì¼€ì¤„ë§
âœ… ë™ì‹œì„± ì œì–´ ë° ì œí•œ
âœ… ì‘ì—… í ë° ë°°ì¹˜ ì²˜ë¦¬
âœ… ë¹„ë™ê¸° ì»¨í…ìŠ¤íŠ¸ ê´€ë¦¬
âœ… ìˆœí™˜ì°¸ì¡° ë°©ì§€ - ë…ë¦½ì  ëª¨ë“ˆ
âœ… conda í™˜ê²½ ìš°ì„  ì§€ì›

Author: MyCloset AI Team
Date: 2025-07-21
Version: 1.0 (ë¶„ë¦¬ëœ ë¹„ë™ê¸° ìœ í‹¸ë¦¬í‹° ì‹œìŠ¤í…œ)
"""

import asyncio
import logging
import time
import threading
import weakref
from typing import Any, Dict, List, Optional, Callable, Union, Coroutine, Awaitable
from dataclasses import dataclass, field
from enum import Enum
from functools import wraps
from concurrent.futures import ThreadPoolExecutor, Future
from contextlib import asynccontextmanager
from collections import deque, defaultdict

logger = logging.getLogger(__name__)

# ==============================================
# ğŸ”¥ 1. ë¹„ë™ê¸° ì‘ì—… ê´€ë ¨ ì—´ê±°í˜•
# ==============================================

class TaskPriority(Enum):
    """ì‘ì—… ìš°ì„ ìˆœìœ„"""
    LOW = 1
    NORMAL = 2
    HIGH = 3
    CRITICAL = 4

class TaskStatus(Enum):
    """ì‘ì—… ìƒíƒœ"""
    PENDING = "pending"
    RUNNING = "running"
    COMPLETED = "completed"
    FAILED = "failed"
    CANCELLED = "cancelled"

class ConcurrencyStrategy(Enum):
    """ë™ì‹œì„± ì „ëµ"""
    UNLIMITED = "unlimited"
    LIMITED = "limited"
    SEMAPHORE = "semaphore"
    QUEUE = "queue"

# ==============================================
# ğŸ”¥ 2. ë¹„ë™ê¸° ì‘ì—… ë°ì´í„° êµ¬ì¡°
# ==============================================

@dataclass
class AsyncTask:
    """ë¹„ë™ê¸° ì‘ì—… ì •ë³´"""
    id: str
    name: str
    coro: Coroutine
    priority: TaskPriority = TaskPriority.NORMAL
    timeout: Optional[float] = None
    retry_count: int = 0
    max_retries: int = 3
    status: TaskStatus = TaskStatus.PENDING
    created_at: float = field(default_factory=time.time)
    started_at: Optional[float] = None
    completed_at: Optional[float] = None
    result: Any = None
    error: Optional[Exception] = None
    metadata: Dict[str, Any] = field(default_factory=dict)

@dataclass
class ConcurrencyConfig:
    """ë™ì‹œì„± ì„¤ì •"""
    max_concurrent_tasks: int = 10
    max_workers: int = 4
    strategy: ConcurrencyStrategy = ConcurrencyStrategy.LIMITED
    enable_task_queue: bool = True
    queue_size: int = 100
    default_timeout: float = 300.0  # 5ë¶„
    enable_retries: bool = True
    max_retries: int = 3
    retry_delay: float = 1.0

# ==============================================
# ğŸ”¥ 3. ë¹„ë™ê¸° ì‘ì—… ìŠ¤ì¼€ì¤„ëŸ¬
# ==============================================

class AsyncTaskScheduler:
    """ë¹„ë™ê¸° ì‘ì—… ìŠ¤ì¼€ì¤„ëŸ¬"""
    
    def __init__(self, config: Optional[ConcurrencyConfig] = None):
        self.config = config or ConcurrencyConfig()
        self.logger = logging.getLogger(f"{__name__}.AsyncTaskScheduler")
        
        # ì‘ì—… ê´€ë¦¬
        self.tasks: Dict[str, AsyncTask] = {}
        self.task_queue = deque()
        self.running_tasks: Dict[str, asyncio.Task] = {}
        
        # ë™ì‹œì„± ì œì–´
        self.semaphore = asyncio.Semaphore(self.config.max_concurrent_tasks)
        self.task_counter = 0
        
        # ìŠ¤ë ˆë“œ í’€
        self.thread_pool = ThreadPoolExecutor(max_workers=self.config.max_workers)
        
        # í†µê³„
        self.stats = {
            "total_tasks": 0,
            "completed_tasks": 0,
            "failed_tasks": 0,
            "cancelled_tasks": 0,
            "average_execution_time": 0.0
        }
        
        # ë½
        self._lock = asyncio.Lock()
        self._running = False
        
        self.logger.info(f"ğŸ”„ ë¹„ë™ê¸° ì‘ì—… ìŠ¤ì¼€ì¤„ëŸ¬ ì´ˆê¸°í™”: {self.config.strategy.value}")
    
    async def schedule_task(
        self,
        coro: Coroutine,
        name: Optional[str] = None,
        priority: TaskPriority = TaskPriority.NORMAL,
        timeout: Optional[float] = None,
        max_retries: Optional[int] = None
    ) -> str:
        """ì‘ì—… ìŠ¤ì¼€ì¤„ë§"""
        # ì—ëŸ¬ ì»¨í…ìŠ¤íŠ¸ ì¤€ë¹„
        error_context = {
            'task_name': name or f"async_task_{self.task_counter + 1}",
            'priority': priority.value,
            'timeout': timeout or self.config.default_timeout,
            'max_retries': max_retries or self.config.max_retries,
            'scheduler_running': self._running,
            'total_tasks': self.stats["total_tasks"],
            'running_tasks': len(self.running_tasks),
            'queue_size': len(self.task_queue)
        }
        
        try:
            async with self._lock:
                self.task_counter += 1
                task_id = f"task_{self.task_counter}_{int(time.time())}"
                
                task = AsyncTask(
                    id=task_id,
                    name=name or f"async_task_{self.task_counter}",
                    coro=coro,
                    priority=priority,
                    timeout=timeout or self.config.default_timeout,
                    max_retries=max_retries or self.config.max_retries
                )
                
                self.tasks[task_id] = task
                self.stats["total_tasks"] += 1
                
                # ìš°ì„ ìˆœìœ„ ê¸°ë°˜ íì— ì¶”ê°€
                self._add_to_queue(task)
                
                self.logger.debug(f"ğŸ“ ì‘ì—… ìŠ¤ì¼€ì¤„ë§: {task_id} ({task.name})")
                
                # ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘
                if not self._running:
                    asyncio.create_task(self._run_scheduler())
                
                return task_id
                
        except Exception as e:
            # exceptions.pyì˜ ì»¤ìŠ¤í…€ ì˜ˆì™¸ë¡œ ë³€í™˜
            from app.core.exceptions import (
                convert_to_mycloset_exception,
                PipelineError,
                ConfigurationError
            )
            
            # ì—ëŸ¬ íƒ€ì…ë³„ ì»¤ìŠ¤í…€ ì˜ˆì™¸ ë³€í™˜
            if isinstance(e, (ValueError, TypeError)):
                custom_error = ConfigurationError(
                    f"ì‘ì—… ìŠ¤ì¼€ì¤„ë§ ì¤‘ ì„¤ì • ì˜¤ë¥˜: {e}",
                    "TASK_SCHEDULING_CONFIG_ERROR",
                    error_context
                )
            else:
                custom_error = PipelineError(
                    f"ì‘ì—… ìŠ¤ì¼€ì¤„ë§ ì‹¤íŒ¨: {e}",
                    "TASK_SCHEDULING_FAILED",
                    error_context
                )
            
            self.logger.error(f"âŒ ì‘ì—… ìŠ¤ì¼€ì¤„ë§ ì‹¤íŒ¨: {custom_error}")
            raise custom_error
    
    def _add_to_queue(self, task: AsyncTask):
        """ìš°ì„ ìˆœìœ„ ê¸°ë°˜ íì— ì‘ì—… ì¶”ê°€"""
        # ìš°ì„ ìˆœìœ„ì— ë”°ë¼ ì ì ˆí•œ ìœ„ì¹˜ì— ì‚½ì…
        inserted = False
        for i, queued_task in enumerate(self.task_queue):
            if task.priority.value > queued_task.priority.value:
                self.task_queue.insert(i, task)
                inserted = True
                break
        
        if not inserted:
            self.task_queue.append(task)
    
    async def _run_scheduler(self):
        """ìŠ¤ì¼€ì¤„ëŸ¬ ì‹¤í–‰"""
        try:
            self._running = True
            
            while self.task_queue or self.running_tasks:
                # ìƒˆ ì‘ì—… ì‹œì‘
                await self._start_pending_tasks()
                
                # ì™„ë£Œëœ ì‘ì—… ì •ë¦¬
                await self._cleanup_completed_tasks()
                
                # ì ì‹œ ëŒ€ê¸°
                await asyncio.sleep(0.1)
                
        except Exception as e:
            self.logger.error(f"âŒ ìŠ¤ì¼€ì¤„ëŸ¬ ì‹¤í–‰ ì˜¤ë¥˜: {e}")
        finally:
            self._running = False
    
    async def _start_pending_tasks(self):
        """ëŒ€ê¸° ì¤‘ì¸ ì‘ì—…ë“¤ ì‹œì‘"""
        try:
            while (self.task_queue and 
                   len(self.running_tasks) < self.config.max_concurrent_tasks):
                
                task = self.task_queue.popleft()
                
                # ë™ì‹œì„± ì œì–´
                if self.config.strategy == ConcurrencyStrategy.SEMAPHORE:
                    await self.semaphore.acquire()
                
                # ì‘ì—… ì‹œì‘
                asyncio_task = asyncio.create_task(self._execute_task(task))
                self.running_tasks[task.id] = asyncio_task
                
                task.status = TaskStatus.RUNNING
                task.started_at = time.time()
                
                self.logger.debug(f"ğŸš€ ì‘ì—… ì‹œì‘: {task.id}")
                
        except Exception as e:
            self.logger.error(f"âŒ ì‘ì—… ì‹œì‘ ì˜¤ë¥˜: {e}")
    
    async def _execute_task(self, task: AsyncTask):
        """ì‘ì—… ì‹¤í–‰"""
        # ì—ëŸ¬ ì»¨í…ìŠ¤íŠ¸ ì¤€ë¹„
        error_context = {
            'task_id': task.id,
            'task_name': task.name,
            'priority': task.priority.value,
            'timeout': task.timeout,
            'retry_count': task.retry_count,
            'max_retries': task.max_retries,
            'strategy': self.config.strategy.value,
            'started_at': task.started_at
        }
        
        try:
            # íƒ€ì„ì•„ì›ƒ ì„¤ì •
            if task.timeout:
                result = await asyncio.wait_for(task.coro, timeout=task.timeout)
            else:
                result = await task.coro
            
            # ì„±ê³µ ì²˜ë¦¬
            task.result = result
            task.status = TaskStatus.COMPLETED
            task.completed_at = time.time()
            
            self.stats["completed_tasks"] += 1
            self._update_average_execution_time(task)
            
            self.logger.debug(f"âœ… ì‘ì—… ì™„ë£Œ: {task.id}")
            
        except asyncio.TimeoutError as e:
            # íƒ€ì„ì•„ì›ƒ ì²˜ë¦¬
            from app.core.exceptions import TimeoutError as MyClosetTimeoutError
            
            task.error = MyClosetTimeoutError(
                f"ì‘ì—… íƒ€ì„ì•„ì›ƒ: {task.id}",
                "TASK_EXECUTION_TIMEOUT",
                error_context
            )
            await self._handle_task_failure(task)
            
        except Exception as e:
            # ì˜¤ë¥˜ ì²˜ë¦¬
            from app.core.exceptions import (
                convert_to_mycloset_exception,
                PipelineError,
                ModelInferenceError
            )
            
            # ì—ëŸ¬ íƒ€ì…ë³„ ì»¤ìŠ¤í…€ ì˜ˆì™¸ ë³€í™˜
            if isinstance(e, (ValueError, TypeError)):
                task.error = PipelineError(
                    f"ì‘ì—… ì‹¤í–‰ ì¤‘ ë°ì´í„° ì˜¤ë¥˜: {e}",
                    "TASK_EXECUTION_DATA_ERROR",
                    error_context
                )
            elif isinstance(e, (OSError, IOError)):
                task.error = PipelineError(
                    f"ì‘ì—… ì‹¤í–‰ ì¤‘ ì‹œìŠ¤í…œ ì˜¤ë¥˜: {e}",
                    "TASK_EXECUTION_SYSTEM_ERROR",
                    error_context
                )
            else:
                task.error = convert_to_mycloset_exception(e, error_context)
            
            await self._handle_task_failure(task)
            
        finally:
            # ì •ë¦¬
            if self.config.strategy == ConcurrencyStrategy.SEMAPHORE:
                self.semaphore.release()
    
    async def _handle_task_failure(self, task: AsyncTask):
        """ì‘ì—… ì‹¤íŒ¨ ì²˜ë¦¬"""
        # ì—ëŸ¬ ì»¨í…ìŠ¤íŠ¸ ì¤€ë¹„
        error_context = {
            'task_id': task.id,
            'task_name': task.name,
            'retry_count': task.retry_count,
            'max_retries': task.max_retries,
            'enable_retries': self.config.enable_retries,
            'retry_delay': self.config.retry_delay,
            'original_error': str(task.error) if task.error else None,
            'error_type': type(task.error).__name__ if task.error else None
        }
        
        try:
            task.retry_count += 1
            
            if (self.config.enable_retries and 
                task.retry_count <= task.max_retries):
                
                # ì¬ì‹œë„
                self.logger.warning(f"âš ï¸ ì‘ì—… ì¬ì‹œë„: {task.id} ({task.retry_count}/{task.max_retries})")
                
                # ì¬ì‹œë„ ì§€ì—°
                await asyncio.sleep(self.config.retry_delay)
                
                # íì— ë‹¤ì‹œ ì¶”ê°€
                task.status = TaskStatus.PENDING
                self._add_to_queue(task)
                
            else:
                # ìµœëŒ€ ì¬ì‹œë„ ì´ˆê³¼ ë˜ëŠ” ì¬ì‹œë„ ë¹„í™œì„±í™”
                task.status = TaskStatus.FAILED
                task.completed_at = time.time()
                self.stats["failed_tasks"] += 1
                
                # exceptions.pyì˜ ì»¤ìŠ¤í…€ ì˜ˆì™¸ë¡œ ë³€í™˜
                from app.core.exceptions import (
                    convert_to_mycloset_exception,
                    PipelineError,
                    ModelInferenceError
                )
                
                # ì›ë³¸ ì—ëŸ¬ê°€ ì´ë¯¸ ì»¤ìŠ¤í…€ ì˜ˆì™¸ì¸ ê²½ìš° ê·¸ëŒ€ë¡œ ì‚¬ìš©
                if hasattr(task.error, 'error_code'):
                    final_error = task.error
                else:
                    # ì¼ë°˜ ì˜ˆì™¸ë¥¼ ì»¤ìŠ¤í…€ ì˜ˆì™¸ë¡œ ë³€í™˜
                    final_error = PipelineError(
                        f"ì‘ì—… ìµœì¢… ì‹¤íŒ¨: {task.id}",
                        "TASK_FINAL_FAILURE",
                        error_context
                    )
                
                self.logger.error(f"âŒ ì‘ì—… ì‹¤íŒ¨: {task.id} - {final_error}")
                
        except Exception as e:
            # ì‹¤íŒ¨ ì²˜ë¦¬ ì¤‘ ë°œìƒí•œ ì—ëŸ¬
            from app.core.exceptions import PipelineError
            
            failure_error = PipelineError(
                f"ì‘ì—… ì‹¤íŒ¨ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}",
                "TASK_FAILURE_HANDLING_ERROR",
                error_context
            )
            
            self.logger.error(f"âŒ ì‘ì—… ì‹¤íŒ¨ ì²˜ë¦¬ ì˜¤ë¥˜: {failure_error}")
            
            # ì›ë³¸ ì‘ì—…ì„ ì‹¤íŒ¨ë¡œ í‘œì‹œ
            task.status = TaskStatus.FAILED
            task.completed_at = time.time()
            self.stats["failed_tasks"] += 1
    
    async def _cleanup_completed_tasks(self):
        """ì™„ë£Œëœ ì‘ì—… ì •ë¦¬"""
        try:
            completed_task_ids = []
            
            for task_id, asyncio_task in self.running_tasks.items():
                if asyncio_task.done():
                    completed_task_ids.append(task_id)
            
            for task_id in completed_task_ids:
                del self.running_tasks[task_id]
                
        except Exception as e:
            self.logger.error(f"âŒ ì‘ì—… ì •ë¦¬ ì˜¤ë¥˜: {e}")
    
    def _update_average_execution_time(self, task: AsyncTask):
        """í‰ê·  ì‹¤í–‰ ì‹œê°„ ì—…ë°ì´íŠ¸"""
        if task.started_at and task.completed_at:
            execution_time = task.completed_at - task.started_at
            current_avg = self.stats["average_execution_time"]
            completed_count = self.stats["completed_tasks"]
            
            self.stats["average_execution_time"] = (
                (current_avg * (completed_count - 1) + execution_time) / completed_count
            )
    
    async def wait_for_task(self, task_id: str, timeout: Optional[float] = None) -> Any:
        """íŠ¹ì • ì‘ì—… ì™„ë£Œ ëŒ€ê¸°"""
        # ì—ëŸ¬ ì»¨í…ìŠ¤íŠ¸ ì¤€ë¹„
        error_context = {
            'task_id': task_id,
            'timeout': timeout,
            'task_exists': task_id in self.tasks,
            'total_tasks': len(self.tasks),
            'running_tasks': len(self.running_tasks)
        }
        
        try:
            if task_id not in self.tasks:
                from app.core.exceptions import DataValidationError
                raise DataValidationError(
                    f"ì‘ì—…ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {task_id}",
                    "TASK_NOT_FOUND",
                    error_context
                )
            
            task = self.tasks[task_id]
            start_time = time.time()
            
            # ì—ëŸ¬ ì»¨í…ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸
            error_context.update({
                'task_name': task.name,
                'task_status': task.status.value,
                'task_priority': task.priority.value
            })
            
            while task.status in [TaskStatus.PENDING, TaskStatus.RUNNING]:
                if timeout and (time.time() - start_time) > timeout:
                    from app.core.exceptions import TimeoutError as MyClosetTimeoutError
                    raise MyClosetTimeoutError(
                        f"ì‘ì—… ëŒ€ê¸° íƒ€ì„ì•„ì›ƒ: {task_id}",
                        "TASK_WAIT_TIMEOUT",
                        error_context
                    )
                
                await asyncio.sleep(0.1)
            
            if task.status == TaskStatus.COMPLETED:
                return task.result
            elif task.status == TaskStatus.FAILED:
                # ì‹¤íŒ¨í•œ ì‘ì—…ì˜ ì—ëŸ¬ë¥¼ ê·¸ëŒ€ë¡œ ì „íŒŒ
                if task.error:
                    raise task.error
                else:
                    from app.core.exceptions import PipelineError
                    raise PipelineError(
                        f"ì‘ì—…ì´ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {task_id}",
                        "TASK_FAILED",
                        error_context
                    )
            elif task.status == TaskStatus.CANCELLED:
                from app.core.exceptions import PipelineError
                raise PipelineError(
                    f"ì‘ì—…ì´ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤: {task_id}",
                    "TASK_CANCELLED",
                    error_context
                )
            
        except Exception as e:
            # ì´ë¯¸ ì»¤ìŠ¤í…€ ì˜ˆì™¸ì¸ ê²½ìš° ê·¸ëŒ€ë¡œ ì „íŒŒ
            if hasattr(e, 'error_code'):
                self.logger.error(f"âŒ ì‘ì—… ëŒ€ê¸° ì‹¤íŒ¨ {task_id}: {e}")
                raise
            
            # ì¼ë°˜ ì˜ˆì™¸ë¥¼ ì»¤ìŠ¤í…€ ì˜ˆì™¸ë¡œ ë³€í™˜
            from app.core.exceptions import (
                convert_to_mycloset_exception,
                PipelineError
            )
            
            custom_error = convert_to_mycloset_exception(e, error_context)
            self.logger.error(f"âŒ ì‘ì—… ëŒ€ê¸° ì‹¤íŒ¨ {task_id}: {custom_error}")
            raise custom_error
    
    async def cancel_task(self, task_id: str) -> bool:
        """ì‘ì—… ì·¨ì†Œ"""
        try:
            if task_id not in self.tasks:
                return False
            
            task = self.tasks[task_id]
            
            # ì‹¤í–‰ ì¤‘ì¸ ì‘ì—… ì·¨ì†Œ
            if task_id in self.running_tasks:
                asyncio_task = self.running_tasks[task_id]
                asyncio_task.cancel()
                del self.running_tasks[task_id]
            
            # íì—ì„œ ì œê±°
            self.task_queue = deque([t for t in self.task_queue if t.id != task_id])
            
            task.status = TaskStatus.CANCELLED
            task.completed_at = time.time()
            self.stats["cancelled_tasks"] += 1
            
            self.logger.info(f"ğŸš« ì‘ì—… ì·¨ì†Œ: {task_id}")
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ ì‘ì—… ì·¨ì†Œ ì‹¤íŒ¨ {task_id}: {e}")
            return False
    
    def get_task_status(self, task_id: str) -> Optional[Dict[str, Any]]:
        """ì‘ì—… ìƒíƒœ ì¡°íšŒ"""
        try:
            if task_id not in self.tasks:
                return None
            
            task = self.tasks[task_id]
            
            return {
                "id": task.id,
                "name": task.name,
                "status": task.status.value,
                "priority": task.priority.value,
                "retry_count": task.retry_count,
                "created_at": task.created_at,
                "started_at": task.started_at,
                "completed_at": task.completed_at,
                "execution_time": (
                    task.completed_at - task.started_at 
                    if task.started_at and task.completed_at 
                    else None
                ),
                "error": str(task.error) if task.error else None,
                "metadata": task.metadata
            }
            
        except Exception as e:
            self.logger.error(f"âŒ ì‘ì—… ìƒíƒœ ì¡°íšŒ ì‹¤íŒ¨ {task_id}: {e}")
            return None
    
    def get_scheduler_stats(self) -> Dict[str, Any]:
        """ìŠ¤ì¼€ì¤„ëŸ¬ í†µê³„"""
        try:
            return {
                **self.stats,
                "pending_tasks": len(self.task_queue),
                "running_tasks": len(self.running_tasks),
                "total_managed_tasks": len(self.tasks),
                "scheduler_running": self._running,
                "config": {
                    "max_concurrent_tasks": self.config.max_concurrent_tasks,
                    "strategy": self.config.strategy.value,
                    "enable_retries": self.config.enable_retries
                }
            }
        except Exception as e:
            return {"error": str(e)}
    
    async def shutdown(self):
        """ìŠ¤ì¼€ì¤„ëŸ¬ ì¢…ë£Œ"""
        try:
            self.logger.info("ğŸ”„ ìŠ¤ì¼€ì¤„ëŸ¬ ì¢…ë£Œ ì‹œì‘")
            
            # ëŒ€ê¸° ì¤‘ì¸ ì‘ì—…ë“¤ ì·¨ì†Œ
            while self.task_queue:
                task = self.task_queue.popleft()
                task.status = TaskStatus.CANCELLED
                self.stats["cancelled_tasks"] += 1
            
            # ì‹¤í–‰ ì¤‘ì¸ ì‘ì—…ë“¤ ì·¨ì†Œ
            for task_id, asyncio_task in self.running_tasks.items():
                asyncio_task.cancel()
                self.tasks[task_id].status = TaskStatus.CANCELLED
                self.stats["cancelled_tasks"] += 1
            
            # ëª¨ë“  ì‘ì—… ì™„ë£Œ ëŒ€ê¸°
            if self.running_tasks:
                await asyncio.gather(*self.running_tasks.values(), return_exceptions=True)
            
            # ìŠ¤ë ˆë“œ í’€ ì¢…ë£Œ
            self.thread_pool.shutdown(wait=True)
            
            self._running = False
            self.logger.info("âœ… ìŠ¤ì¼€ì¤„ëŸ¬ ì¢…ë£Œ ì™„ë£Œ")
            
        except Exception as e:
            self.logger.error(f"âŒ ìŠ¤ì¼€ì¤„ëŸ¬ ì¢…ë£Œ ì‹¤íŒ¨: {e}")

# ==============================================
# ğŸ”¥ 4. ë¹„ë™ê¸° ë°°ì¹˜ ì²˜ë¦¬ê¸°
# ==============================================

class AsyncBatchProcessor:
    """ë¹„ë™ê¸° ë°°ì¹˜ ì²˜ë¦¬ê¸°"""
    
    def __init__(
        self,
        batch_size: int = 10,
        max_concurrent_batches: int = 3,
        flush_interval: float = 5.0
    ):
        self.batch_size = batch_size
        self.max_concurrent_batches = max_concurrent_batches
        self.flush_interval = flush_interval
        self.logger = logging.getLogger(f"{__name__}.AsyncBatchProcessor")
        
        # ë°°ì¹˜ ê´€ë¦¬
        self.pending_items = []
        self.processing_batches = {}
        self.batch_counter = 0
        
        # ë™ì‹œì„± ì œì–´
        self.semaphore = asyncio.Semaphore(max_concurrent_batches)
        
        # ìë™ í”ŒëŸ¬ì‹œ
        self._flush_task = None
        self._shutdown = False
        
        # í†µê³„
        self.stats = {
            "total_items": 0,
            "processed_items": 0,
            "failed_items": 0,
            "total_batches": 0,
            "processed_batches": 0,
            "failed_batches": 0
        }
        
        self._lock = asyncio.Lock()
        
        self.logger.info(f"ğŸ“¦ ë°°ì¹˜ ì²˜ë¦¬ê¸° ì´ˆê¸°í™”: batch_size={batch_size}")
    
    async def add_item(self, item: Any, metadata: Optional[Dict] = None) -> str:
        """ì•„ì´í…œ ì¶”ê°€"""
        # ì—ëŸ¬ ì»¨í…ìŠ¤íŠ¸ ì¤€ë¹„
        error_context = {
            'item_type': type(item).__name__,
            'metadata': metadata or {},
            'batch_size': self.batch_size,
            'pending_items': len(self.pending_items),
            'processing_batches': len(self.processing_batches),
            'shutdown': self._shutdown
        }
        
        try:
            async with self._lock:
                item_id = f"item_{len(self.pending_items)}_{int(time.time())}"
                
                self.pending_items.append({
                    "id": item_id,
                    "data": item,
                    "metadata": metadata or {},
                    "added_at": time.time()
                })
                
                self.stats["total_items"] += 1
                
                # ë°°ì¹˜ í¬ê¸°ì— ë„ë‹¬í•˜ë©´ ì¦‰ì‹œ ì²˜ë¦¬
                if len(self.pending_items) >= self.batch_size:
                    await self._flush_batch()
                
                # ìë™ í”ŒëŸ¬ì‹œ ìŠ¤ì¼€ì¤„ë§
                if self._flush_task is None and not self._shutdown:
                    self._flush_task = asyncio.create_task(self._auto_flush())
                
                return item_id
                
        except Exception as e:
            # exceptions.pyì˜ ì»¤ìŠ¤í…€ ì˜ˆì™¸ë¡œ ë³€í™˜
            from app.core.exceptions import (
                convert_to_mycloset_exception,
                PipelineError,
                DataValidationError
            )
            
            # ì—ëŸ¬ íƒ€ì…ë³„ ì»¤ìŠ¤í…€ ì˜ˆì™¸ ë³€í™˜
            if isinstance(e, (ValueError, TypeError)):
                custom_error = DataValidationError(
                    f"ì•„ì´í…œ ì¶”ê°€ ì¤‘ ë°ì´í„° ì˜¤ë¥˜: {e}",
                    "BATCH_ITEM_DATA_ERROR",
                    error_context
                )
            else:
                custom_error = PipelineError(
                    f"ì•„ì´í…œ ì¶”ê°€ ì‹¤íŒ¨: {e}",
                    "BATCH_ITEM_ADD_FAILED",
                    error_context
                )
            
            self.logger.error(f"âŒ ì•„ì´í…œ ì¶”ê°€ ì‹¤íŒ¨: {custom_error}")
            raise custom_error
    
    async def _flush_batch(self):
        """ë°°ì¹˜ í”ŒëŸ¬ì‹œ"""
        try:
            if not self.pending_items:
                return
            
            # ë°°ì¹˜ ìƒì„±
            self.batch_counter += 1
            batch_id = f"batch_{self.batch_counter}"
            
            batch_items = self.pending_items[:self.batch_size]
            self.pending_items = self.pending_items[self.batch_size:]
            
            self.stats["total_batches"] += 1
            
            # ë¹„ë™ê¸°ë¡œ ë°°ì¹˜ ì²˜ë¦¬
            asyncio.create_task(self._process_batch(batch_id, batch_items))
            
            self.logger.debug(f"ğŸ“¦ ë°°ì¹˜ í”ŒëŸ¬ì‹œ: {batch_id} ({len(batch_items)}ê°œ ì•„ì´í…œ)")
            
        except Exception as e:
            self.logger.error(f"âŒ ë°°ì¹˜ í”ŒëŸ¬ì‹œ ì‹¤íŒ¨: {e}")
    
    async def _process_batch(self, batch_id: str, items: List[Dict]):
        """ë°°ì¹˜ ì²˜ë¦¬"""
        # ì—ëŸ¬ ì»¨í…ìŠ¤íŠ¸ ì¤€ë¹„
        error_context = {
            'batch_id': batch_id,
            'item_count': len(items),
            'batch_size': self.batch_size,
            'max_concurrent_batches': self.max_concurrent_batches,
            'processing_batches': len(self.processing_batches)
        }
        
        try:
            async with self.semaphore:
                self.processing_batches[batch_id] = {
                    "items": items,
                    "started_at": time.time(),
                    "status": "processing"
                }
                
                # ì‹¤ì œ ë°°ì¹˜ ì²˜ë¦¬ (ì˜¤ë²„ë¼ì´ë“œ í•„ìš”)
                results = await self._process_batch_items(items)
                
                # ê²°ê³¼ ì²˜ë¦¬
                successful_count = sum(1 for r in results if r.get("success", False))
                failed_count = len(results) - successful_count
                
                self.stats["processed_items"] += successful_count
                self.stats["failed_items"] += failed_count
                self.stats["processed_batches"] += 1
                
                # ë°°ì¹˜ ì™„ë£Œ
                self.processing_batches[batch_id]["status"] = "completed"
                self.processing_batches[batch_id]["completed_at"] = time.time()
                self.processing_batches[batch_id]["results"] = results
                
                self.logger.debug(f"âœ… ë°°ì¹˜ ì²˜ë¦¬ ì™„ë£Œ: {batch_id} (ì„±ê³µ: {successful_count}, ì‹¤íŒ¨: {failed_count})")
                
        except Exception as e:
            # exceptions.pyì˜ ì»¤ìŠ¤í…€ ì˜ˆì™¸ë¡œ ë³€í™˜
            from app.core.exceptions import (
                convert_to_mycloset_exception,
                PipelineError,
                ModelInferenceError
            )
            
            # ì—ëŸ¬ íƒ€ì…ë³„ ì»¤ìŠ¤í…€ ì˜ˆì™¸ ë³€í™˜
            if isinstance(e, (ValueError, TypeError)):
                custom_error = PipelineError(
                    f"ë°°ì¹˜ ì²˜ë¦¬ ì¤‘ ë°ì´í„° ì˜¤ë¥˜: {e}",
                    "BATCH_PROCESSING_DATA_ERROR",
                    error_context
                )
            elif isinstance(e, (OSError, IOError)):
                custom_error = PipelineError(
                    f"ë°°ì¹˜ ì²˜ë¦¬ ì¤‘ ì‹œìŠ¤í…œ ì˜¤ë¥˜: {e}",
                    "BATCH_PROCESSING_SYSTEM_ERROR",
                    error_context
                )
            else:
                custom_error = convert_to_mycloset_exception(e, error_context)
            
            self.logger.error(f"âŒ ë°°ì¹˜ ì²˜ë¦¬ ì‹¤íŒ¨ {batch_id}: {custom_error}")
            
            self.stats["failed_batches"] += 1
            self.stats["failed_items"] += len(items)
            
            if batch_id in self.processing_batches:
                self.processing_batches[batch_id]["status"] = "failed"
                self.processing_batches[batch_id]["error"] = str(custom_error)
    
    async def _process_batch_items(self, items: List[Dict]) -> List[Dict]:
        """ë°°ì¹˜ ì•„ì´í…œ ì²˜ë¦¬ (ì˜¤ë²„ë¼ì´ë“œ í•„ìš”)"""
        # ê¸°ë³¸ êµ¬í˜„: ëª¨ë“  ì•„ì´í…œì„ ì„±ê³µìœ¼ë¡œ ì²˜ë¦¬
        results = []
        for item in items:
            results.append({
                "item_id": item["id"],
                "success": True,
                "result": f"processed_{item['id']}",
                "processing_time": 0.1
            })
        
        # ì²˜ë¦¬ ì‹œë®¬ë ˆì´ì…˜
        await asyncio.sleep(0.1)
        
        return results
    
    async def _auto_flush(self):
        """ìë™ í”ŒëŸ¬ì‹œ"""
        try:
            while not self._shutdown:
                await asyncio.sleep(self.flush_interval)
                
                async with self._lock:
                    if self.pending_items:
                        await self._flush_batch()
                
        except asyncio.CancelledError:
            pass
        except Exception as e:
            self.logger.error(f"âŒ ìë™ í”ŒëŸ¬ì‹œ ì˜¤ë¥˜: {e}")
        finally:
            self._flush_task = None
    
    async def flush_all(self):
        """ëª¨ë“  ëŒ€ê¸° ì¤‘ì¸ ì•„ì´í…œ í”ŒëŸ¬ì‹œ"""
        try:
            async with self._lock:
                while self.pending_items:
                    await self._flush_batch()
                    
        except Exception as e:
            self.logger.error(f"âŒ ì „ì²´ í”ŒëŸ¬ì‹œ ì‹¤íŒ¨: {e}")
    
    def get_stats(self) -> Dict[str, Any]:
        """í†µê³„ ì¡°íšŒ"""
        return {
            **self.stats,
            "pending_items": len(self.pending_items),
            "processing_batches": len(self.processing_batches),
            "batch_size": self.batch_size,
            "max_concurrent_batches": self.max_concurrent_batches
        }
    
    async def shutdown(self):
        """ë°°ì¹˜ ì²˜ë¦¬ê¸° ì¢…ë£Œ"""
        try:
            self.logger.info("ğŸ“¦ ë°°ì¹˜ ì²˜ë¦¬ê¸° ì¢…ë£Œ ì‹œì‘")
            
            self._shutdown = True
            
            # ìë™ í”ŒëŸ¬ì‹œ ì¤‘ë‹¨
            if self._flush_task:
                self._flush_task.cancel()
                try:
                    await self._flush_task
                except asyncio.CancelledError:
                    pass
            
            # ë‚¨ì€ ì•„ì´í…œ ì²˜ë¦¬
            await self.flush_all()
            
            # ì§„í–‰ ì¤‘ì¸ ë°°ì¹˜ ì™„ë£Œ ëŒ€ê¸°
            while self.processing_batches:
                await asyncio.sleep(0.1)
                # ì™„ë£Œëœ ë°°ì¹˜ ì •ë¦¬
                completed_batches = [
                    batch_id for batch_id, batch_info in self.processing_batches.items()
                    if batch_info["status"] in ["completed", "failed"]
                ]
                for batch_id in completed_batches:
                    del self.processing_batches[batch_id]
            
            self.logger.info("âœ… ë°°ì¹˜ ì²˜ë¦¬ê¸° ì¢…ë£Œ ì™„ë£Œ")
            
        except Exception as e:
            self.logger.error(f"âŒ ë°°ì¹˜ ì²˜ë¦¬ê¸° ì¢…ë£Œ ì‹¤íŒ¨: {e}")

# ==============================================
# ğŸ”¥ 5. ë¹„ë™ê¸° ì»¨í…ìŠ¤íŠ¸ ê´€ë¦¬ìë“¤
# ==============================================

@asynccontextmanager
async def async_timeout(timeout: float):
    """ë¹„ë™ê¸° íƒ€ì„ì•„ì›ƒ ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì €"""
    try:
        async with asyncio.timeout(timeout):
            yield
    except asyncio.TimeoutError:
        logger.warning(f"â° ë¹„ë™ê¸° ì‘ì—… íƒ€ì„ì•„ì›ƒ: {timeout}ì´ˆ")
        raise

@asynccontextmanager
async def async_retry(max_retries: int = 3, delay: float = 1.0, backoff: float = 2.0):
    """ë¹„ë™ê¸° ì¬ì‹œë„ ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì €"""
    for attempt in range(max_retries + 1):
        try:
            yield attempt
            break
        except Exception as e:
            if attempt == max_retries:
                logger.error(f"âŒ ìµœëŒ€ ì¬ì‹œë„ ì´ˆê³¼: {max_retries}")
                raise
            
            wait_time = delay * (backoff ** attempt)
            logger.warning(f"âš ï¸ ì¬ì‹œë„ {attempt + 1}/{max_retries + 1}: {wait_time:.1f}ì´ˆ í›„ ì¬ì‹œë„")
            await asyncio.sleep(wait_time)

@asynccontextmanager
async def async_concurrency_limit(semaphore: asyncio.Semaphore):
    """ë¹„ë™ê¸° ë™ì‹œì„± ì œí•œ ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì €"""
    await semaphore.acquire()
    try:
        yield
    finally:
        semaphore.release()

# ==============================================
# ğŸ”¥ 6. ë¹„ë™ê¸° ë°ì½”ë ˆì´í„°ë“¤
# ==============================================

def async_retry_decorator(max_retries: int = 3, delay: float = 1.0, backoff: float = 2.0):
    """ë¹„ë™ê¸° ì¬ì‹œë„ ë°ì½”ë ˆì´í„°"""
    def decorator(func):
        @wraps(func)
        async def wrapper(*args, **kwargs):
            for attempt in range(max_retries + 1):
                try:
                    return await func(*args, **kwargs)
                except Exception as e:
                    if attempt == max_retries:
                        logger.error(f"âŒ {func.__name__} ìµœëŒ€ ì¬ì‹œë„ ì´ˆê³¼: {max_retries}")
                        raise
                    
                    wait_time = delay * (backoff ** attempt)
                    logger.warning(f"âš ï¸ {func.__name__} ì¬ì‹œë„ {attempt + 1}/{max_retries + 1}: {wait_time:.1f}ì´ˆ í›„")
                    await asyncio.sleep(wait_time)
            
        return wrapper
    return decorator

def async_timeout_decorator(timeout: float):
    """ë¹„ë™ê¸° íƒ€ì„ì•„ì›ƒ ë°ì½”ë ˆì´í„°"""
    def decorator(func):
        @wraps(func)
        async def wrapper(*args, **kwargs):
            try:
                return await asyncio.wait_for(func(*args, **kwargs), timeout=timeout)
            except asyncio.TimeoutError:
                logger.error(f"â° {func.__name__} íƒ€ì„ì•„ì›ƒ: {timeout}ì´ˆ")
                raise
        
        return wrapper
    return decorator

def async_rate_limit(calls_per_second: float):
    """ë¹„ë™ê¸° ì†ë„ ì œí•œ ë°ì½”ë ˆì´í„°"""
    min_interval = 1.0 / calls_per_second
    last_called = {}
    
    def decorator(func):
        @wraps(func)
        async def wrapper(*args, **kwargs):
            func_key = f"{func.__module__}.{func.__name__}"
            now = time.time()
            
            if func_key in last_called:
                elapsed = now - last_called[func_key]
                if elapsed < min_interval:
                    sleep_time = min_interval - elapsed
                    await asyncio.sleep(sleep_time)
            
            last_called[func_key] = time.time()
            return await func(*args, **kwargs)
        
        return wrapper
    return decorator

# ==============================================
# ğŸ”¥ 7. ë¹„ë™ê¸° ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
# ==============================================

async def gather_with_limit(
    *coros: Awaitable,
    limit: int = 10,
    return_exceptions: bool = False
) -> List[Any]:
    """ì œí•œëœ ë™ì‹œì„±ìœ¼ë¡œ ì—¬ëŸ¬ ì½”ë£¨í‹´ ì‹¤í–‰"""
    # ì—ëŸ¬ ì»¨í…ìŠ¤íŠ¸ ì¤€ë¹„
    error_context = {
        'coro_count': len(coros),
        'limit': limit,
        'return_exceptions': return_exceptions
    }
    
    try:
        semaphore = asyncio.Semaphore(limit)
        
        async def limited_coro(coro):
            async with semaphore:
                return await coro
        
        limited_coros = [limited_coro(coro) for coro in coros]
        return await asyncio.gather(*limited_coros, return_exceptions=return_exceptions)
        
    except Exception as e:
        # exceptions.pyì˜ ì»¤ìŠ¤í…€ ì˜ˆì™¸ë¡œ ë³€í™˜
        from app.core.exceptions import (
            convert_to_mycloset_exception,
            PipelineError
        )
        
        custom_error = convert_to_mycloset_exception(e, error_context)
        logger.error(f"âŒ gather_with_limit ì‹¤íŒ¨: {custom_error}")
        raise custom_error

async def run_with_timeout(coro: Awaitable, timeout: float, default=None):
    """íƒ€ì„ì•„ì›ƒê³¼ í•¨ê»˜ ì½”ë£¨í‹´ ì‹¤í–‰"""
    # ì—ëŸ¬ ì»¨í…ìŠ¤íŠ¸ ì¤€ë¹„
    error_context = {
        'timeout': timeout,
        'default_value': default,
        'coro_type': type(coro).__name__
    }
    
    try:
        return await asyncio.wait_for(coro, timeout=timeout)
    except asyncio.TimeoutError:
        # íƒ€ì„ì•„ì›ƒì€ ì •ìƒì ì¸ ìƒí™©ì´ë¯€ë¡œ ê²½ê³ ë§Œ ë¡œê¹…
        logger.warning(f"â° ì½”ë£¨í‹´ íƒ€ì„ì•„ì›ƒ: {timeout}ì´ˆ")
        return default
    except Exception as e:
        # ê¸°íƒ€ ì˜ˆì™¸ëŠ” ì»¤ìŠ¤í…€ ì˜ˆì™¸ë¡œ ë³€í™˜
        from app.core.exceptions import (
            convert_to_mycloset_exception,
            PipelineError
        )
        
        custom_error = convert_to_mycloset_exception(e, error_context)
        logger.error(f"âŒ run_with_timeout ì‹¤íŒ¨: {custom_error}")
        raise custom_error

async def retry_async(
    coro_factory: Callable[[], Awaitable],
    max_retries: int = 3,
    delay: float = 1.0,
    backoff: float = 2.0,
    exceptions: Tuple = (Exception,)
) -> Any:
    """ë¹„ë™ê¸° í•¨ìˆ˜ ì¬ì‹œë„"""
    # ì—ëŸ¬ ì»¨í…ìŠ¤íŠ¸ ì¤€ë¹„
    error_context = {
        'max_retries': max_retries,
        'delay': delay,
        'backoff': backoff,
        'exceptions': [exc.__name__ for exc in exceptions]
    }
    
    for attempt in range(max_retries + 1):
        try:
            return await coro_factory()
        except exceptions as e:
            if attempt == max_retries:
                # ìµœëŒ€ ì¬ì‹œë„ ì´ˆê³¼ ì‹œ ì»¤ìŠ¤í…€ ì˜ˆì™¸ë¡œ ë³€í™˜
                from app.core.exceptions import (
                    convert_to_mycloset_exception,
                    PipelineError
                )
                
                error_context['final_attempt'] = attempt
                error_context['final_error'] = str(e)
                
                custom_error = convert_to_mycloset_exception(e, error_context)
                logger.error(f"âŒ retry_async ìµœëŒ€ ì¬ì‹œë„ ì´ˆê³¼: {custom_error}")
                raise custom_error
            
            wait_time = delay * (backoff ** attempt)
            logger.warning(f"âš ï¸ ì¬ì‹œë„ {attempt + 1}/{max_retries + 1}: {wait_time:.1f}ì´ˆ í›„")
            await asyncio.sleep(wait_time)

async def async_map(
    func: Callable,
    items: List[Any],
    max_concurrency: int = 10
) -> List[Any]:
    """ë¹„ë™ê¸° ë§µ í•¨ìˆ˜"""
    semaphore = asyncio.Semaphore(max_concurrency)
    
    async def process_item(item):
        async with semaphore:
            if asyncio.iscoroutinefunction(func):
                return await func(item)
            else:
                return func(item)
    
    tasks = [process_item(item) for item in items]
    return await asyncio.gather(*tasks)

async def async_filter(
    predicate: Callable,
    items: List[Any],
    max_concurrency: int = 10
) -> List[Any]:
    """ë¹„ë™ê¸° í•„í„° í•¨ìˆ˜"""
    semaphore = asyncio.Semaphore(max_concurrency)
    
    async def check_item(item):
        async with semaphore:
            if asyncio.iscoroutinefunction(predicate):
                return await predicate(item), item
            else:
                return predicate(item), item
    
    tasks = [check_item(item) for item in items]
    results = await asyncio.gather(*tasks)
    
    return [item for passed, item in results if passed]

# ==============================================
# ğŸ”¥ 8. ë¹„ë™ê¸° ì‘ì—… í’€
# ==============================================

class AsyncWorkerPool:
    """ë¹„ë™ê¸° ì‘ì—…ì í’€"""
    
    def __init__(self, worker_count: int = 5, queue_size: int = 100):
        self.worker_count = worker_count
        self.queue = asyncio.Queue(maxsize=queue_size)
        self.workers = []
        self.running = False
        self.logger = logging.getLogger(f"{__name__}.AsyncWorkerPool")
        
        # í†µê³„
        self.stats = {
            "tasks_processed": 0,
            "tasks_failed": 0,
            "active_workers": 0
        }
    
    async def start(self):
        """ì‘ì—…ì í’€ ì‹œì‘"""
        if self.running:
            return
        
        self.running = True
        self.workers = []
        
        for i in range(self.worker_count):
            worker = asyncio.create_task(self._worker(f"worker_{i}"))
            self.workers.append(worker)
        
        self.logger.info(f"ğŸ”„ ì‘ì—…ì í’€ ì‹œì‘: {self.worker_count}ê°œ ì‘ì—…ì")
    
    async def _worker(self, worker_name: str):
        """ì‘ì—…ì ë£¨í”„"""
        self.stats["active_workers"] += 1
        
        try:
            while self.running:
                try:
                    # ì‘ì—… ëŒ€ê¸° (íƒ€ì„ì•„ì›ƒ í¬í•¨)
                    task_data = await asyncio.wait_for(
                        self.queue.get(), 
                        timeout=1.0
                    )
                    
                    # ì‘ì—… ì‹¤í–‰
                    await self._execute_task(worker_name, task_data)
                    
                except asyncio.TimeoutError:
                    # íƒ€ì„ì•„ì›ƒì€ ì •ìƒ (íê°€ ë¹„ì–´ìˆìŒ)
                    continue
                except Exception as e:
                    self.logger.error(f"âŒ {worker_name} ì˜¤ë¥˜: {e}")
                    self.stats["tasks_failed"] += 1
                    
        finally:
            self.stats["active_workers"] -= 1
            self.logger.debug(f"ğŸ”„ {worker_name} ì¢…ë£Œ")
    
    async def _execute_task(self, worker_name: str, task_data: Dict):
        """ì‘ì—… ì‹¤í–‰"""
        try:
            func = task_data["func"]
            args = task_data.get("args", ())
            kwargs = task_data.get("kwargs", {})
            callback = task_data.get("callback")
            
            # í•¨ìˆ˜ ì‹¤í–‰
            if asyncio.iscoroutinefunction(func):
                result = await func(*args, **kwargs)
            else:
                result = func(*args, **kwargs)
            
            # ì½œë°± ì‹¤í–‰
            if callback:
                if asyncio.iscoroutinefunction(callback):
                    await callback(result)
                else:
                    callback(result)
            
            self.stats["tasks_processed"] += 1
            self.logger.debug(f"âœ… {worker_name} ì‘ì—… ì™„ë£Œ")
            
        except Exception as e:
            self.logger.error(f"âŒ {worker_name} ì‘ì—… ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            self.stats["tasks_failed"] += 1
            
            # ì—ëŸ¬ ì½œë°±
            error_callback = task_data.get("error_callback")
            if error_callback:
                try:
                    if asyncio.iscoroutinefunction(error_callback):
                        await error_callback(e)
                    else:
                        error_callback(e)
                except Exception:
                    pass
    
    async def submit(
        self,
        func: Callable,
        *args,
        callback: Optional[Callable] = None,
        error_callback: Optional[Callable] = None,
        **kwargs
    ):
        """ì‘ì—… ì œì¶œ"""
        task_data = {
            "func": func,
            "args": args,
            "kwargs": kwargs,
            "callback": callback,
            "error_callback": error_callback
        }
        
        await self.queue.put(task_data)
    
    def submit_nowait(
        self,
        func: Callable,
        *args,
        callback: Optional[Callable] = None,
        error_callback: Optional[Callable] = None,
        **kwargs
    ):
        """ì‘ì—… ì¦‰ì‹œ ì œì¶œ (ë¸”ë¡œí‚¹ ì—†ìŒ)"""
        task_data = {
            "func": func,
            "args": args,
            "kwargs": kwargs,
            "callback": callback,
            "error_callback": error_callback
        }
        
        try:
            self.queue.put_nowait(task_data)
            return True
        except asyncio.QueueFull:
            return False
    
    def get_stats(self) -> Dict[str, Any]:
        """í†µê³„ ì¡°íšŒ"""
        return {
            **self.stats,
            "queue_size": self.queue.qsize(),
            "worker_count": self.worker_count,
            "running": self.running
        }
    
    async def stop(self):
        """ì‘ì—…ì í’€ ì¤‘ì§€"""
        self.running = False
        
        # ëª¨ë“  ì‘ì—…ì ì™„ë£Œ ëŒ€ê¸°
        if self.workers:
            await asyncio.gather(*self.workers, return_exceptions=True)
        
        self.logger.info("âœ… ì‘ì—…ì í’€ ì¤‘ì§€ ì™„ë£Œ")

# ==============================================
# ğŸ”¥ 9. ì „ì—­ ë¹„ë™ê¸° ê´€ë¦¬ì
# ==============================================

class GlobalAsyncManager:
    """ì „ì—­ ë¹„ë™ê¸° ê´€ë¦¬ì"""
    
    def __init__(self):
        self.scheduler = None
        self.worker_pool = None
        self.batch_processor = None
        self.logger = logging.getLogger(f"{__name__}.GlobalAsyncManager")
        
        # ì„¤ì •
        self.concurrency_config = ConcurrencyConfig()
        
        # ìƒíƒœ
        self.initialized = False
    
    async def initialize(
        self,
        concurrency_config: Optional[ConcurrencyConfig] = None,
        worker_count: int = 5,
        batch_size: int = 10
    ):
        """ë¹„ë™ê¸° ê´€ë¦¬ì ì´ˆê¸°í™”"""
        try:
            if self.initialized:
                return
            
            self.concurrency_config = concurrency_config or ConcurrencyConfig()
            
            # ìŠ¤ì¼€ì¤„ëŸ¬ ì´ˆê¸°í™”
            self.scheduler = AsyncTaskScheduler(self.concurrency_config)
            
            # ì‘ì—…ì í’€ ì´ˆê¸°í™”
            self.worker_pool = AsyncWorkerPool(worker_count)
            await self.worker_pool.start()
            
            # ë°°ì¹˜ ì²˜ë¦¬ê¸° ì´ˆê¸°í™”
            self.batch_processor = AsyncBatchProcessor(batch_size)
            
            self.initialized = True
            self.logger.info("ğŸ”„ ì „ì—­ ë¹„ë™ê¸° ê´€ë¦¬ì ì´ˆê¸°í™” ì™„ë£Œ")
            
        except Exception as e:
            self.logger.error(f"âŒ ë¹„ë™ê¸° ê´€ë¦¬ì ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            raise
    
    async def shutdown(self):
        """ë¹„ë™ê¸° ê´€ë¦¬ì ì¢…ë£Œ"""
        try:
            if not self.initialized:
                return
            
            # ê° ì»´í¬ë„ŒíŠ¸ ì¢…ë£Œ
            if self.scheduler:
                await self.scheduler.shutdown()
            
            if self.worker_pool:
                await self.worker_pool.stop()
            
            if self.batch_processor:
                await self.batch_processor.shutdown()
            
            self.initialized = False
            self.logger.info("âœ… ì „ì—­ ë¹„ë™ê¸° ê´€ë¦¬ì ì¢…ë£Œ ì™„ë£Œ")
            
        except Exception as e:
            self.logger.error(f"âŒ ë¹„ë™ê¸° ê´€ë¦¬ì ì¢…ë£Œ ì‹¤íŒ¨: {e}")

# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
_global_async_manager: Optional[GlobalAsyncManager] = None
_manager_lock = threading.Lock()

def get_global_async_manager() -> GlobalAsyncManager:
    """ì „ì—­ ë¹„ë™ê¸° ê´€ë¦¬ì ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    global _global_async_manager
    
    with _manager_lock:
        if _global_async_manager is None:
            _global_async_manager = GlobalAsyncManager()
        
        return _global_async_manager

async def initialize_async_system(
    concurrency_config: Optional[ConcurrencyConfig] = None,
    worker_count: int = 5,
    batch_size: int = 10
):
    """ë¹„ë™ê¸° ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
    manager = get_global_async_manager()
    await manager.initialize(concurrency_config, worker_count, batch_size)

async def shutdown_async_system():
    """ë¹„ë™ê¸° ì‹œìŠ¤í…œ ì¢…ë£Œ"""
    manager = get_global_async_manager()
    await manager.shutdown()

# ==============================================
# ğŸ”¥ 10. ëª¨ë“ˆ ë‚´ë³´ë‚´ê¸°
# ==============================================

__all__ = [
    # í•µì‹¬ í´ë˜ìŠ¤ë“¤
    'AsyncTaskScheduler',
    'AsyncBatchProcessor',
    'AsyncWorkerPool',
    'GlobalAsyncManager',
    
    # ì„¤ì • í´ë˜ìŠ¤ë“¤
    'AsyncTask',
    'ConcurrencyConfig',
    'TaskPriority',
    'TaskStatus',
    'ConcurrencyStrategy',
    
    # ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì €ë“¤
    'async_timeout',
    'async_retry',
    'async_concurrency_limit',
    
    # ë°ì½”ë ˆì´í„°ë“¤
    'async_retry_decorator',
    'async_timeout_decorator',
    'async_rate_limit',
    
    # ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
    'gather_with_limit',
    'run_with_timeout',
    'retry_async',
    'async_map',
    'async_filter',
    
    # ì „ì—­ í•¨ìˆ˜ë“¤
    'get_global_async_manager',
    'initialize_async_system',
    'shutdown_async_system'
]

logger.info("âœ… ë¹„ë™ê¸° ìœ í‹¸ë¦¬í‹° ì‹œìŠ¤í…œ v1.0 ë¡œë“œ ì™„ë£Œ")
logger.info("ğŸ”„ ë¹„ë™ê¸° ì‘ì—… ê´€ë¦¬ ë° ìŠ¤ì¼€ì¤„ë§")
logger.info("âš¡ ë™ì‹œì„± ì œì–´ ë° ì œí•œ")
logger.info("ğŸ“¦ ì‘ì—… í ë° ë°°ì¹˜ ì²˜ë¦¬")
logger.info("ğŸ¯ ë¹„ë™ê¸° ì»¨í…ìŠ¤íŠ¸ ê´€ë¦¬")
logger.info("ğŸ”— ìˆœí™˜ì°¸ì¡° ë°©ì§€ - ë…ë¦½ì  ëª¨ë“ˆ")