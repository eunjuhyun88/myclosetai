
import torch
import warnings

# PyTorch 2.7+ í˜¸í™˜ì„± íŒ¨ì¹˜
_original_load = torch.load

def patched_load(f, map_location=None, pickle_module=None, **kwargs):
    """3ë‹¨ê³„ ì•ˆì „ ë¡œë”© + MPS float64 ë¬¸ì œ í•´ê²°"""
    try:
        # 1ë‹¨ê³„: weights_only=True
        checkpoint = _original_load(f, map_location=map_location, weights_only=True, **kwargs)
    except Exception:
        try:
            # 2ë‹¨ê³„: weights_only=False  
            warnings.warn("Using weights_only=False for legacy model compatibility")
            checkpoint = _original_load(f, map_location=map_location, weights_only=False, **kwargs)
        except Exception:
            # 3ë‹¨ê³„: ê¸°ë³¸ ë¡œë”©
            checkpoint = _original_load(f, map_location=map_location, **kwargs)
    
    # ğŸ”¥ MPS ë””ë°”ì´ìŠ¤ì—ì„œ float64 â†’ float32 ë³€í™˜
    if map_location == 'mps' or (hasattr(map_location, 'type') and map_location.type == 'mps'):
        checkpoint = _convert_mps_tensors_to_float32(checkpoint)
    
    return checkpoint

def _convert_mps_tensors_to_float32(checkpoint):
    """MPSìš© ì²´í¬í¬ì¸íŠ¸ í…ì„œ ë³€í™˜"""
    def convert_tensor(tensor):
        if hasattr(tensor, 'dtype') and tensor.dtype == torch.float64:
            return tensor.to(torch.float32)
        return tensor
    
    def recursive_convert(obj):
        if torch.is_tensor(obj):
            return convert_tensor(obj)
        elif isinstance(obj, dict):
            return {key: recursive_convert(value) for key, value in obj.items()}
        elif isinstance(obj, (list, tuple)):
            return type(obj)(recursive_convert(item) for item in obj)
        else:
            return obj
    
    try:
        return recursive_convert(checkpoint)
    except Exception:
        return checkpoint


# íŒ¨ì¹˜ ì ìš©
torch.load = patched_load
