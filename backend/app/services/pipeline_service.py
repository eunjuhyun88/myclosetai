"""
app/services/pipeline_service.py - ì„œë¹„ìŠ¤ ë ˆì´ì–´ (ë¦¬íŒ©í† ë§)

âœ… RealAIPipelineProcessorë¥¼ ì„œë¹„ìŠ¤ ë ˆì´ì–´ë¡œ ë¶„ë¦¬
âœ… ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ ì¤‘ì‹¬í™”
âœ… API ë ˆì´ì–´ì™€ AI ì²˜ë¦¬ ë ˆì´ì–´ ë¶„ë¦¬
âœ… ëª…í™•í•œ ì±…ì„ ë¶„ë¦¬
âœ… í”„ë¡ íŠ¸ì—”ë“œ í˜¸í™˜ì„± 100% ìœ ì§€
"""

import logging
import asyncio
import time
from typing import Dict, Any, Optional, List
import numpy as np
import torch
from PIL import Image
from fastapi import UploadFile

# AI íŒŒì´í”„ë¼ì¸ ì»´í¬ë„ŒíŠ¸ import
from app.ai_pipeline.pipeline_manager import PipelineManager
from app.ai_pipeline.steps.step_01_human_parsing import HumanParsingStep
from app.ai_pipeline.steps.step_02_pose_estimation import PoseEstimationStep
from app.ai_pipeline.steps.step_03_cloth_segmentation import ClothSegmentationStep
from app.ai_pipeline.steps.step_04_geometric_matching import GeometricMatchingStep
from app.ai_pipeline.steps.step_05_cloth_warping import ClothWarpingStep
from app.ai_pipeline.steps.step_06_virtual_fitting import VirtualFittingStep
from app.ai_pipeline.steps.step_07_post_processing import PostProcessingStep
from app.ai_pipeline.steps.step_08_quality_assessment import QualityAssessmentStep

# ìœ í‹¸ë¦¬í‹°ë“¤
try:
    from app.ai_pipeline.utils.model_loader import ModelLoader
    from app.ai_pipeline.utils.memory_manager import MemoryManager
    from app.ai_pipeline.utils.data_converter import DataConverter
    UTILS_AVAILABLE = True
except ImportError as e:
    logging.warning(f"AI Pipeline Utils import ì‹¤íŒ¨: {e}")
    UTILS_AVAILABLE = False

# ìŠ¤í‚¤ë§ˆ
try:
    from app.models.schemas import BodyMeasurements, ClothingType, ProcessingStatus
    SCHEMAS_AVAILABLE = True
except ImportError:
    SCHEMAS_AVAILABLE = False
    # í´ë°± ìŠ¤í‚¤ë§ˆ
    class BodyMeasurements:
        def __init__(self, height: float, weight: float, **kwargs):
            self.height = height
            self.weight = weight
            for k, v in kwargs.items():
                setattr(self, k, v)

# ë¡œê¹… ì„¤ì •
logger = logging.getLogger(__name__)

def get_optimal_device() -> str:
    """ìµœì  ë””ë°”ì´ìŠ¤ ì„ íƒ"""
    try:
        if hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
            return "mps"
        elif torch.cuda.is_available():
            return "cuda"
        else:
            return "cpu"
    except Exception as e:
        logger.warning(f"ë””ë°”ì´ìŠ¤ ê°ì§€ ì‹¤íŒ¨: {e}")
        return "cpu"

def optimize_device_memory(device: str):
    """ë””ë°”ì´ìŠ¤ë³„ ë©”ëª¨ë¦¬ ìµœì í™”"""
    try:
        if device == "mps":
            torch.mps.empty_cache()
        elif device == "cuda":
            torch.cuda.empty_cache()
        else:
            import gc
            gc.collect()
    except Exception as e:
        logger.warning(f"ë©”ëª¨ë¦¬ ìµœì í™” ì‹¤íŒ¨: {e}")

# ============================================================================
# ğŸ”§ ì„œë¹„ìŠ¤ ë ˆì´ì–´ - í•µì‹¬ ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§
# ============================================================================

class PipelineService:
    """
    íŒŒì´í”„ë¼ì¸ ì„œë¹„ìŠ¤ ë ˆì´ì–´
    - ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ ì¤‘ì‹¬í™”
    - API ë ˆì´ì–´ì™€ AI ì²˜ë¦¬ ë ˆì´ì–´ ë¶„ë¦¬
    - ì—ëŸ¬ ì²˜ë¦¬ ë° ìƒíƒœ ê´€ë¦¬
    - ë¡œê¹… ë° ëª¨ë‹ˆí„°ë§
    """
    
    def __init__(self, device: Optional[str] = None):
        """ì„œë¹„ìŠ¤ ì´ˆê¸°í™”"""
        self.device = device or get_optimal_device()
        self.logger = logging.getLogger(f"services.{self.__class__.__name__}")
        
        # íŒŒì´í”„ë¼ì¸ ë§¤ë‹ˆì €
        self.pipeline_manager: Optional[PipelineManager] = None
        
        # AI ë‹¨ê³„ë“¤
        self.ai_steps: Dict[str, Any] = {}
        
        # ìœ í‹¸ë¦¬í‹°ë“¤
        self.utils: Dict[str, Any] = {}
        
        # ìƒíƒœ ê´€ë¦¬
        self.initialized = False
        self.processing_sessions = {}
        self.model_load_status = {}
        
        self.logger.info(f"ğŸ”§ PipelineService ì´ˆê¸°í™” - Device: {self.device}")
    
    async def initialize(self) -> bool:
        """ì„œë¹„ìŠ¤ ì´ˆê¸°í™”"""
        try:
            if self.initialized:
                return True
            
            self.logger.info("ğŸš€ PipelineService ì´ˆê¸°í™” ì‹œì‘...")
            
            # 1. ë©”ëª¨ë¦¬ ìµœì í™”
            optimize_device_memory(self.device)
            
            # 2. íŒŒì´í”„ë¼ì¸ ë§¤ë‹ˆì € ì´ˆê¸°í™”
            await self._initialize_pipeline_manager()
            
            # 3. AI ë‹¨ê³„ë“¤ ì´ˆê¸°í™”
            await self._initialize_ai_steps()
            
            # 4. ìœ í‹¸ë¦¬í‹° ì´ˆê¸°í™”
            await self._initialize_utilities()
            
            # 5. ìƒíƒœ í™•ì¸
            await self._check_initialization_status()
            
            self.initialized = True
            self.logger.info("âœ… PipelineService ì´ˆê¸°í™” ì™„ë£Œ!")
            
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ PipelineService ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            raise
    
    async def _initialize_pipeline_manager(self):
        """íŒŒì´í”„ë¼ì¸ ë§¤ë‹ˆì € ì´ˆê¸°í™”"""
        try:
            self.pipeline_manager = PipelineManager(device=self.device)
            
            if hasattr(self.pipeline_manager, 'initialize'):
                await self.pipeline_manager.initialize()
            
            self.logger.info("âœ… PipelineManager ì´ˆê¸°í™” ì™„ë£Œ")
            
        except Exception as e:
            self.logger.error(f"âŒ PipelineManager ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            raise
    
    async def _initialize_ai_steps(self):
        """AI ë‹¨ê³„ë“¤ ì´ˆê¸°í™”"""
        try:
            step_classes = {
                "step_01": HumanParsingStep,
                "step_02": PoseEstimationStep,
                "step_03": ClothSegmentationStep,
                "step_04": GeometricMatchingStep,
                "step_05": ClothWarpingStep,
                "step_06": VirtualFittingStep,
                "step_07": PostProcessingStep,
                "step_08": QualityAssessmentStep
            }
            
            for step_name, step_class in step_classes.items():
                try:
                    step_instance = step_class(device=self.device)
                    
                    if hasattr(step_instance, 'initialize'):
                        await step_instance.initialize()
                    
                    self.ai_steps[step_name] = step_instance
                    self.logger.info(f"âœ… {step_name} ì´ˆê¸°í™” ì™„ë£Œ")
                    
                except Exception as e:
                    self.logger.error(f"âŒ {step_name} ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                    # ê°œë³„ Step ì‹¤íŒ¨ëŠ” ì „ì²´ ì´ˆê¸°í™”ë¥¼ ì¤‘ë‹¨ì‹œí‚¤ì§€ ì•ŠìŒ
                    continue
            
            self.logger.info(f"âœ… AI Steps ì´ˆê¸°í™” ì™„ë£Œ: {len(self.ai_steps)}/8")
            
        except Exception as e:
            self.logger.error(f"âŒ AI Steps ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            raise
    
    async def _initialize_utilities(self):
        """ìœ í‹¸ë¦¬í‹° ì´ˆê¸°í™”"""
        try:
            if UTILS_AVAILABLE:
                self.utils = {
                    'model_loader': ModelLoader(device=self.device),
                    'memory_manager': MemoryManager(device=self.device),
                    'data_converter': DataConverter()
                }
                self.logger.info("âœ… AI Pipeline Utils ì´ˆê¸°í™” ì™„ë£Œ")
            else:
                self.logger.warning("âš ï¸ AI Pipeline Utils ë¶ˆê°€ìš©")
                
        except Exception as e:
            self.logger.error(f"âŒ ìœ í‹¸ë¦¬í‹° ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            # ìœ í‹¸ë¦¬í‹° ì‹¤íŒ¨ëŠ” ì „ì²´ ì´ˆê¸°í™”ë¥¼ ì¤‘ë‹¨ì‹œí‚¤ì§€ ì•ŠìŒ
            self.utils = {}
    
    async def _check_initialization_status(self):
        """ì´ˆê¸°í™” ìƒíƒœ í™•ì¸"""
        try:
            for step_name, step_instance in self.ai_steps.items():
                if hasattr(step_instance, 'is_model_loaded'):
                    self.model_load_status[step_name] = step_instance.is_model_loaded()
                else:
                    self.model_load_status[step_name] = True
            
            self.logger.info(f"ğŸ“Š ëª¨ë¸ ë¡œë“œ ìƒíƒœ: {self.model_load_status}")
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ ìƒíƒœ í™•ì¸ ì‹¤íŒ¨: {e}")
    
    # ========================================================================
    # ğŸ¯ í•µì‹¬ ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ ë©”ì„œë“œë“¤
    # ========================================================================
    
    async def process_step(self, step_id: int, inputs: Dict[str, Any]) -> Dict[str, Any]:
        """
        ê°œë³„ ë‹¨ê³„ ì²˜ë¦¬ (í†µí•© ì¸í„°í˜ì´ìŠ¤)
        
        Args:
            step_id: ë‹¨ê³„ ë²ˆí˜¸ (1-8)
            inputs: ì…ë ¥ ë°ì´í„° ë”•ì…”ë„ˆë¦¬
            
        Returns:
            Dict: ì²˜ë¦¬ ê²°ê³¼
        """
        start_time = time.time()
        
        try:
            # ì„œë¹„ìŠ¤ ì´ˆê¸°í™” í™•ì¸
            if not self.initialized:
                await self.initialize()
            
            # ë©”ëª¨ë¦¬ ìµœì í™”
            optimize_device_memory(self.device)
            
            # ë‹¨ê³„ë³„ ì²˜ë¦¬
            if step_id == 1:
                return await self._process_step_1(inputs)
            elif step_id == 2:
                return await self._process_step_2(inputs)
            elif step_id == 3:
                return await self._process_step_3(inputs)
            elif step_id == 4:
                return await self._process_step_4(inputs)
            elif step_id == 5:
                return await self._process_step_5(inputs)
            elif step_id == 6:
                return await self._process_step_6(inputs)
            elif step_id == 7:
                return await self._process_step_7(inputs)
            elif step_id == 8:
                return await self._process_step_8(inputs)
            else:
                raise ValueError(f"ì§€ì›ë˜ì§€ ì•ŠëŠ” ë‹¨ê³„ ID: {step_id}")
                
        except Exception as e:
            self.logger.error(f"âŒ Step {step_id} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return {
                "success": False,
                "error": str(e),
                "step_id": step_id,
                "processing_time": time.time() - start_time,
                "device": self.device
            }
    
    async def _process_step_1(self, inputs: Dict[str, Any]) -> Dict[str, Any]:
        """1ë‹¨ê³„: ì´ë¯¸ì§€ ì—…ë¡œë“œ ê²€ì¦"""
        start_time = time.time()
        
        try:
            person_image = inputs.get("person_image")
            clothing_image = inputs.get("clothing_image")
            
            if not person_image or not clothing_image:
                raise ValueError("person_imageì™€ clothing_imageê°€ í•„ìš”í•©ë‹ˆë‹¤")
            
            # íŒŒì¼ ê²€ì¦
            person_validation = await self._validate_image_file(person_image, "person")
            clothing_validation = await self._validate_image_file(clothing_image, "clothing")
            
            if not person_validation["valid"] or not clothing_validation["valid"]:
                return {
                    "success": False,
                    "error": "íŒŒì¼ ê²€ì¦ ì‹¤íŒ¨",
                    "details": {
                        "person_error": person_validation.get("error"),
                        "clothing_error": clothing_validation.get("error")
                    },
                    "step_id": 1,
                    "processing_time": time.time() - start_time,
                    "device": self.device
                }
            
            # ì´ë¯¸ì§€ í’ˆì§ˆ ë¶„ì„
            person_img = await self._load_and_preprocess_image(person_image)
            clothing_img = await self._load_and_preprocess_image(clothing_image)
            
            person_quality = await self._analyze_image_quality(person_img, "person")
            clothing_quality = await self._analyze_image_quality(clothing_img, "clothing")
            
            processing_time = time.time() - start_time
            
            return {
                "success": True,
                "message": "ì´ë¯¸ì§€ ì—…ë¡œë“œ ê²€ì¦ ì™„ë£Œ",
                "step_id": 1,
                "processing_time": processing_time,
                "confidence": min(person_quality["confidence"], clothing_quality["confidence"]),
                "device": self.device,
                "details": {
                    "person_analysis": person_quality,
                    "clothing_analysis": clothing_quality,
                    "ready_for_next_step": True
                }
            }
            
        except Exception as e:
            self.logger.error(f"âŒ Step 1 ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return {
                "success": False,
                "error": str(e),
                "step_id": 1,
                "processing_time": time.time() - start_time,
                "device": self.device
            }
    
    async def _process_step_3(self, inputs: Dict[str, Any]) -> Dict[str, Any]:
        """3ë‹¨ê³„: ì¸ê°„ íŒŒì‹±"""
        start_time = time.time()
        
        try:
            person_image = inputs.get("person_image")
            if not person_image:
                raise ValueError("person_imageê°€ í•„ìš”í•©ë‹ˆë‹¤")
            
            # ì´ë¯¸ì§€ ë¡œë“œ
            person_img = await self._load_and_preprocess_image(person_image)
            person_array = np.array(person_img)
            
            # AI ì¸ê°„ íŒŒì‹± ì²˜ë¦¬
            if "step_01" in self.ai_steps:
                parsing_result = await self.ai_steps["step_01"].process(person_array)
                
                return {
                    "success": True,
                    "message": "ì¸ê°„ íŒŒì‹± ì™„ë£Œ",
                    "step_id": 3,
                    "processing_time": time.time() - start_time,
                    "device": self.device,
                    "details": {
                        "detected_segments": parsing_result.get("detected_segments", []),
                        "confidence": parsing_result.get("confidence", 0.0),
                        "processing_method": "HumanParsingStep"
                    }
                }
            else:
                raise RuntimeError("HumanParsingStepì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
                
        except Exception as e:
            self.logger.error(f"âŒ Step 3 ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return {
                "success": False,
                "error": str(e),
                "step_id": 3,
                "processing_time": time.time() - start_time,
                "device": self.device
            }
    
    async def _process_step_7(self, inputs: Dict[str, Any]) -> Dict[str, Any]:
        """7ë‹¨ê³„: ê°€ìƒ í”¼íŒ…"""
        start_time = time.time()
        
        try:
            person_image = inputs.get("person_image")
            clothing_image = inputs.get("clothing_image")
            clothing_type = inputs.get("clothing_type", "auto_detect")
            
            if not person_image or not clothing_image:
                raise ValueError("person_imageì™€ clothing_imageê°€ í•„ìš”í•©ë‹ˆë‹¤")
            
            # ì´ë¯¸ì§€ ë¡œë“œ
            person_img = await self._load_and_preprocess_image(person_image)
            clothing_img = await self._load_and_preprocess_image(clothing_image)
            person_array = np.array(person_img)
            clothing_array = np.array(clothing_img)
            
            # AI ê°€ìƒ í”¼íŒ… ì²˜ë¦¬
            if "step_06" in self.ai_steps:
                fitting_result = await self.ai_steps["step_06"].process(
                    person_array, clothing_array, clothing_type=clothing_type
                )
                
                return {
                    "success": True,
                    "message": "ê°€ìƒ í”¼íŒ… ì™„ë£Œ",
                    "step_id": 7,
                    "processing_time": time.time() - start_time,
                    "device": self.device,
                    "details": {
                        "clothing_type": clothing_type,
                        "fitting_quality": fitting_result.get("quality", 0.0),
                        "confidence": fitting_result.get("confidence", 0.0),
                        "processing_method": "VirtualFittingStep"
                    }
                }
            else:
                raise RuntimeError("VirtualFittingStepì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
                
        except Exception as e:
            self.logger.error(f"âŒ Step 7 ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return {
                "success": False,
                "error": str(e),
                "step_id": 7,
                "processing_time": time.time() - start_time,
                "device": self.device
            }
    
    async def process_full_pipeline(
        self, 
        person_image: UploadFile, 
        clothing_image: UploadFile, 
        options: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """ì „ì²´ íŒŒì´í”„ë¼ì¸ ì²˜ë¦¬"""
        start_time = time.time()
        
        try:
            # ì„œë¹„ìŠ¤ ì´ˆê¸°í™” í™•ì¸
            if not self.initialized:
                await self.initialize()
            
            # íŒŒì´í”„ë¼ì¸ ë§¤ë‹ˆì €ë¥¼ í†µí•œ ì „ì²´ ì²˜ë¦¬
            if self.pipeline_manager:
                # ì´ë¯¸ì§€ ë¡œë“œ
                person_img = await self._load_and_preprocess_image(person_image)
                clothing_img = await self._load_and_preprocess_image(clothing_image)
                
                # íŒŒì´í”„ë¼ì¸ ë§¤ë‹ˆì € í˜¸ì¶œ
                result = await self.pipeline_manager.process_complete_virtual_fitting(
                    person_img, clothing_img, options or {}
                )
                
                return {
                    "success": True,
                    "message": "ì „ì²´ íŒŒì´í”„ë¼ì¸ ì²˜ë¦¬ ì™„ë£Œ",
                    "processing_time": time.time() - start_time,
                    "device": self.device,
                    "result": result
                }
            else:
                raise RuntimeError("PipelineManagerê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
                
        except Exception as e:
            self.logger.error(f"âŒ ì „ì²´ íŒŒì´í”„ë¼ì¸ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return {
                "success": False,
                "error": str(e),
                "processing_time": time.time() - start_time,
                "device": self.device
            }
    
    # ========================================================================
    # ğŸ”§ í—¬í¼ ë©”ì„œë“œë“¤
    # ========================================================================
    
    async def _validate_image_file(self, file: UploadFile, file_type: str) -> Dict[str, Any]:
        """ì´ë¯¸ì§€ íŒŒì¼ ê²€ì¦"""
        try:
            max_size = 50 * 1024 * 1024  # 50MB
            if hasattr(file, 'size') and file.size and file.size > max_size:
                return {
                    "valid": False,
                    "error": f"{file_type} ì´ë¯¸ì§€ê°€ 50MBë¥¼ ì´ˆê³¼í•©ë‹ˆë‹¤"
                }
            
            allowed_types = ["image/jpeg", "image/jpg", "image/png", "image/webp"]
            if file.content_type not in allowed_types:
                return {
                    "valid": False,
                    "error": f"{file_type} ì´ë¯¸ì§€: ì§€ì›ë˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹"
                }
            
            return {"valid": True}
            
        except Exception as e:
            return {
                "valid": False,
                "error": f"íŒŒì¼ ê²€ì¦ ì¤‘ ì˜¤ë¥˜: {str(e)}"
            }
    
    async def _load_and_preprocess_image(self, file: UploadFile) -> Image.Image:
        """ì´ë¯¸ì§€ ë¡œë“œ ë° ì „ì²˜ë¦¬"""
        from io import BytesIO
        
        content = await file.read()
        await file.seek(0)
        image = Image.open(BytesIO(content)).convert('RGB')
        return image.resize((512, 512), Image.Resampling.LANCZOS)
    
    async def _analyze_image_quality(self, image: Image.Image, image_type: str) -> Dict[str, Any]:
        """ì´ë¯¸ì§€ í’ˆì§ˆ ë¶„ì„"""
        try:
            import cv2
            
            # ê¸°ë³¸ í’ˆì§ˆ ë¶„ì„
            width, height = image.size
            cv_image = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)
            gray = cv2.cvtColor(cv_image, cv2.COLOR_BGR2GRAY)
            sharpness = cv2.Laplacian(gray, cv2.CV_64F).var()
            brightness = np.mean(cv_image)
            
            # í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°
            quality_score = min(1.0, sharpness / 1000.0 + brightness / 255.0) / 2
            
            return {
                "confidence": quality_score,
                "quality_metrics": {
                    "sharpness": min(1.0, sharpness / 1000.0),
                    "brightness": brightness / 255.0,
                    "resolution": f"{width}x{height}"
                },
                "recommendations": [
                    f"ì´ë¯¸ì§€ í’ˆì§ˆ: {'ìš°ìˆ˜' if quality_score > 0.8 else 'ì–‘í˜¸' if quality_score > 0.6 else 'ê°œì„  í•„ìš”'}",
                    f"í•´ìƒë„: {width}x{height}"
                ]
            }
            
        except Exception as e:
            self.logger.error(f"ì´ë¯¸ì§€ í’ˆì§ˆ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {
                "confidence": 0.7,
                "quality_metrics": {"error": str(e)},
                "recommendations": ["ê¸°ë³¸ í’ˆì§ˆ ë¶„ì„ ì ìš©ë¨"]
            }
    
    async def cleanup(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        try:
            self.logger.info("ğŸ§¹ PipelineService ì •ë¦¬ ì‹œì‘...")
            
            # AI ë‹¨ê³„ë“¤ ì •ë¦¬
            for step_name, step in self.ai_steps.items():
                try:
                    if hasattr(step, 'cleanup'):
                        await step.cleanup()
                except Exception as e:
                    self.logger.warning(f"âš ï¸ {step_name} ì •ë¦¬ ì‹¤íŒ¨: {e}")
            
            # íŒŒì´í”„ë¼ì¸ ë§¤ë‹ˆì € ì •ë¦¬
            if self.pipeline_manager and hasattr(self.pipeline_manager, 'cleanup'):
                try:
                    await self.pipeline_manager.cleanup()
                except Exception as e:
                    self.logger.warning(f"âš ï¸ íŒŒì´í”„ë¼ì¸ ë§¤ë‹ˆì € ì •ë¦¬ ì‹¤íŒ¨: {e}")
            
            # ë©”ëª¨ë¦¬ ì •ë¦¬
            optimize_device_memory(self.device)
            
            self.initialized = False
            self.logger.info("âœ… PipelineService ì •ë¦¬ ì™„ë£Œ")
            
        except Exception as e:
            self.logger.error(f"âŒ ì •ë¦¬ ì‹¤íŒ¨: {e}")
    
    def get_status(self) -> Dict[str, Any]:
        """ì„œë¹„ìŠ¤ ìƒíƒœ ë°˜í™˜"""
        return {
            "initialized": self.initialized,
            "device": self.device,
            "pipeline_manager": self.pipeline_manager is not None,
            "ai_steps_loaded": len(self.ai_steps),
            "ai_steps": list(self.ai_steps.keys()),
            "model_load_status": self.model_load_status,
            "utils_available": len(self.utils) > 0,
            "processing_sessions": len(self.processing_sessions),
            "service_type": "PipelineService"
        }


# ============================================================================
# ğŸ¯ ì‹±ê¸€í†¤ ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤
# ============================================================================

_pipeline_service_instance: Optional[PipelineService] = None

async def get_pipeline_service() -> PipelineService:
    """PipelineService ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    global _pipeline_service_instance
    
    if _pipeline_service_instance is None:
        _pipeline_service_instance = PipelineService()
        await _pipeline_service_instance.initialize()
        logger.info("âœ… PipelineService ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ")
    
    return _pipeline_service_instance


# ============================================================================
# ğŸ‰ EXPORT
# ============================================================================

__all__ = ["PipelineService", "get_pipeline_service"]