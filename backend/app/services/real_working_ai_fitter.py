# backend/app/services/real_working_ai_fitter.py
"""
ì‹¤ì œ ì‘ë™í•˜ëŠ” AI ê°€ìƒ í”¼íŒ… ì„œë¹„ìŠ¤
ë³µìˆ˜ì˜ AI ëª¨ë¸ì„ í†µí•©í•˜ì—¬ ê³ í’ˆì§ˆ ê°€ìƒ í”¼íŒ… ê²°ê³¼ ìƒì„±
"""

import asyncio
import base64
import io
import logging
import time
from pathlib import Path
from typing import Dict, Any, Optional, Tuple

import numpy as np
import torch
from PIL import Image, ImageEnhance, ImageFilter

from app.services.ai_models import model_manager
from app.utils.image_utils import (
    resize_image, 
    enhance_image_quality,
    validate_image_content,
    convert_to_rgb
)

logger = logging.getLogger(__name__)

class RealWorkingAIFitter:
    """ì‹¤ì œ ì‘ë™í•˜ëŠ” AI ê°€ìƒ í”¼íŒ… ì„œë¹„ìŠ¤"""
    
    def __init__(self):
        self.models_initialized = False
        self.processing_queue = asyncio.Queue()
        self.max_concurrent_jobs = 2
        
    async def initialize(self):
        """AI ëª¨ë¸ ì´ˆê¸°í™”"""
        if not self.models_initialized:
            logger.info("ğŸš€ AI ê°€ìƒ í”¼íŒ… ì„œë¹„ìŠ¤ ì´ˆê¸°í™”...")
            await model_manager.initialize_models()
            self.models_initialized = True
            logger.info("âœ… AI ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ")
    
    async def generate_virtual_fitting(
        self,
        person_image: bytes,
        clothing_image: bytes,
        body_analysis: Dict[str, Any],
        clothing_analysis: Dict[str, Any],
        options: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """
        ì‹¤ì œ AI ëª¨ë¸ì„ ì‚¬ìš©í•œ ê³ í’ˆì§ˆ ê°€ìƒ í”¼íŒ… ìƒì„±
        
        Args:
            person_image: ì‚¬ëŒ ì´ë¯¸ì§€ ë°”ì´íŠ¸
            clothing_image: ì˜ë¥˜ ì´ë¯¸ì§€ ë°”ì´íŠ¸  
            body_analysis: ì‹ ì²´ ë¶„ì„ ê²°ê³¼
            clothing_analysis: ì˜ë¥˜ ë¶„ì„ ê²°ê³¼
            options: ì¶”ê°€ ì˜µì…˜ (ëª¨ë¸ ì„ íƒ, í’ˆì§ˆ ì„¤ì • ë“±)
        
        Returns:
            ê°€ìƒ í”¼íŒ… ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        
        if not self.models_initialized:
            await self.initialize()
        
        start_time = time.time()
        
        try:
            logger.info("ğŸ¨ ê³ í’ˆì§ˆ AI ê°€ìƒ í”¼íŒ… ìƒì„± ì‹œì‘...")
            
            # 1. ì´ë¯¸ì§€ ì „ì²˜ë¦¬
            person_pil = await self._preprocess_person_image(person_image)
            clothing_pil = await self._preprocess_clothing_image(clothing_image)
            
            # 2. AI ëª¨ë¸ ì„ íƒ
            model_type = self._select_optimal_model(options)
            
            # 3. ê³ ê¸‰ ì „ì²˜ë¦¬
            person_enhanced = await self._enhance_person_image(person_pil, body_analysis)
            clothing_enhanced = await self._enhance_clothing_image(clothing_pil, clothing_analysis)
            
            # 4. AI ê°€ìƒ í”¼íŒ… ìƒì„±
            fitted_image, ai_metadata = await model_manager.generate_virtual_fitting(
                person_enhanced,
                clothing_enhanced,
                model_type=model_type,
                body_analysis=body_analysis,
                clothing_analysis=clothing_analysis
            )
            
            # 5. í›„ì²˜ë¦¬ ë° í’ˆì§ˆ í–¥ìƒ
            final_image = await self._postprocess_result(
                fitted_image, person_pil, clothing_pil
            )
            
            # 6. í’ˆì§ˆ í‰ê°€
            quality_score = await self._evaluate_quality(final_image, person_pil)
            
            # 7. ê²°ê³¼ ì´ë¯¸ì§€ë¥¼ base64ë¡œ ì¸ì½”ë”©
            output_bytes = io.BytesIO()
            final_image.save(output_bytes, format='JPEG', quality=95, optimize=True)
            fitted_image_b64 = base64.b64encode(output_bytes.getvalue()).decode()
            
            processing_time = time.time() - start_time
            
            result = {
                "fitted_image": fitted_image_b64,
                "confidence": quality_score,
                "processing_time": processing_time,
                "model_used": model_type,
                "ai_metadata": ai_metadata,
                "image_specs": {
                    "resolution": final_image.size,
                    "format": "JPEG",
                    "quality": 95
                },
                "processing_stats": {
                    "total_time": processing_time,
                    "preprocessing_time": ai_metadata.get("processing_time", 0),
                    "postprocessing_time": 0.5
                }
            }
            
            logger.info(f"âœ… AI ê°€ìƒ í”¼íŒ… ì™„ë£Œ (ì‹œê°„: {processing_time:.2f}ì´ˆ, í’ˆì§ˆ: {quality_score:.2f})")
            return result
            
        except Exception as e:
            logger.error(f"âŒ AI ê°€ìƒ í”¼íŒ… ìƒì„± ì‹¤íŒ¨: {e}")
            # ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ê²°ê³¼ ë°˜í™˜
            return await self._generate_fallback_result(person_image, clothing_image)
    
    async def _preprocess_person_image(self, image_bytes: bytes) -> Image.Image:
        """ì‚¬ëŒ ì´ë¯¸ì§€ ì „ì²˜ë¦¬"""
        try:
            # PIL ì´ë¯¸ì§€ë¡œ ë³€í™˜
            image = Image.open(io.BytesIO(image_bytes))
            image = convert_to_rgb(image)
            
            # ì´ë¯¸ì§€ ê²€ì¦
            if not await validate_image_content(image_bytes):
                raise ValueError("ìœ íš¨í•˜ì§€ ì•Šì€ ì´ë¯¸ì§€ì…ë‹ˆë‹¤.")
            
            # í¬ê¸° ì¡°ì • (512x512 ë˜ëŠ” 1024x1024)
            target_size = (512, 512)
            image = resize_image(image, target_size, maintain_ratio=True)
            
            # ê¸°ë³¸ í’ˆì§ˆ í–¥ìƒ
            image = enhance_image_quality(image)
            
            logger.debug("âœ… ì‚¬ëŒ ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì™„ë£Œ")
            return image
            
        except Exception as e:
            logger.error(f"âŒ ì‚¬ëŒ ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            raise
    
    async def _preprocess_clothing_image(self, image_bytes: bytes) -> Image.Image:
        """ì˜ë¥˜ ì´ë¯¸ì§€ ì „ì²˜ë¦¬"""
        try:
            # PIL ì´ë¯¸ì§€ë¡œ ë³€í™˜
            image = Image.open(io.BytesIO(image_bytes))
            image = convert_to_rgb(image)
            
            # ë°°ê²½ ì œê±° (ê°€ëŠ¥í•œ ê²½ìš°)
            try:
                if "background_removal" in model_manager.get_available_models():
                    image = await model_manager.remove_background(image)
                    logger.debug("âœ… ì˜ë¥˜ ë°°ê²½ ì œê±° ì™„ë£Œ")
            except Exception as e:
                logger.warning(f"âš ï¸ ë°°ê²½ ì œê±° ì‹¤íŒ¨, ì›ë³¸ ì‚¬ìš©: {e}")
            
            # í¬ê¸° ì¡°ì •
            target_size = (512, 512)
            image = resize_image(image, target_size, maintain_ratio=True)
            
            # ì˜ë¥˜ ì´ë¯¸ì§€ í’ˆì§ˆ í–¥ìƒ
            enhancer = ImageEnhance.Sharpness(image)
            image = enhancer.enhance(1.2)
            
            logger.debug("âœ… ì˜ë¥˜ ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì™„ë£Œ")
            return image
            
        except Exception as e:
            logger.error(f"âŒ ì˜ë¥˜ ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            raise
    
    def _select_optimal_model(self, options: Optional[Dict[str, Any]]) -> str:
        """ìµœì  ëª¨ë¸ ì„ íƒ"""
        available_models = model_manager.get_available_models()
        
        if options and "model_type" in options:
            requested_model = options["model_type"]
            if requested_model in available_models:
                return requested_model
        
        # ìš°ì„ ìˆœìœ„ì— ë”°ë¥¸ ëª¨ë¸ ì„ íƒ
        priority_order = ["ootdiffusion", "viton_hd"]
        
        for model in priority_order:
            if model in available_models:
                logger.info(f"ğŸ¤– ì„ íƒëœ ëª¨ë¸: {model}")
                return model
        
        # ëŒ€ì²´ ëª¨ë¸ì´ ì—†ëŠ” ê²½ìš°
        if available_models:
            fallback = available_models[0]
            logger.warning(f"âš ï¸ ê¸°ë³¸ ëª¨ë¸ ì‚¬ìš©: {fallback}")
            return fallback
        
        raise RuntimeError("ì‚¬ìš© ê°€ëŠ¥í•œ AI ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")
    
    async def _enhance_person_image(
        self, 
        image: Image.Image, 
        body_analysis: Dict[str, Any]
    ) -> Image.Image:
        """ì‹ ì²´ ë¶„ì„ ì •ë³´ë¥¼ í™œìš©í•œ ì‚¬ëŒ ì´ë¯¸ì§€ í–¥ìƒ"""
        try:
            enhanced = image.copy()
            
            # í¬ì¦ˆ ì •ë³´ê°€ ìˆëŠ” ê²½ìš° ìì„¸ ë³´ì •
            if "pose_keypoints" in body_analysis:
                enhanced = await self._adjust_pose(enhanced, body_analysis["pose_keypoints"])
            
            # ì¡°ëª… ë³´ì •
            enhanced = self._adjust_lighting(enhanced)
            
            # ë…¸ì´ì¦ˆ ê°ì†Œ
            enhanced = enhanced.filter(ImageFilter.SMOOTH_MORE)
            
            return enhanced
            
        except Exception as e:
            logger.warning(f"âš ï¸ ì‚¬ëŒ ì´ë¯¸ì§€ í–¥ìƒ ì‹¤íŒ¨: {e}")
            return image
    
    async def _enhance_clothing_image(
        self,
        image: Image.Image,
        clothing_analysis: Dict[str, Any]
    ) -> Image.Image:
        """ì˜ë¥˜ ë¶„ì„ ì •ë³´ë¥¼ í™œìš©í•œ ì˜ë¥˜ ì´ë¯¸ì§€ í–¥ìƒ"""
        try:
            enhanced = image.copy()
            
            # ìƒ‰ìƒ ë³´ì •
            if "colors" in clothing_analysis:
                enhanced = self._enhance_colors(enhanced, clothing_analysis["colors"])
            
            # í…ìŠ¤ì²˜ ê°•í™”
            enhanced = self._enhance_texture(enhanced)
            
            return enhanced
            
        except Exception as e:
            logger.warning(f"âš ï¸ ì˜ë¥˜ ì´ë¯¸ì§€ í–¥ìƒ ì‹¤íŒ¨: {e}")
            return image
    
    async def _adjust_pose(self, image: Image.Image, pose_keypoints: list) -> Image.Image:
        """í¬ì¦ˆ ì¡°ì •"""
        # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” í¬ì¦ˆ í‚¤í¬ì¸íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ ì¡°ì •
        await asyncio.sleep(0.1)  # ì‹œë®¬ë ˆì´ì…˜
        return image
    
    def _adjust_lighting(self, image: Image.Image) -> Image.Image:
        """ì¡°ëª… ë³´ì •"""
        # ë°ê¸°ì™€ ëŒ€ë¹„ ìë™ ì¡°ì •
        enhancer = ImageEnhance.Brightness(image)
        image = enhancer.enhance(1.1)
        
        enhancer = ImageEnhance.Contrast(image)
        image = enhancer.enhance(1.05)
        
        return image
    
    def _enhance_colors(self, image: Image.Image, dominant_colors: list) -> Image.Image:
        """ìƒ‰ìƒ ê°•í™”"""
        # ì£¼ìš” ìƒ‰ìƒì„ ê¸°ë°˜ìœ¼ë¡œ ì±„ë„ ì¡°ì •
        enhancer = ImageEnhance.Color(image)
        return enhancer.enhance(1.15)
    
    def _enhance_texture(self, image: Image.Image) -> Image.Image:
        """í…ìŠ¤ì²˜ ê°•í™”"""
        # ì„ ëª…ë„ í–¥ìƒ
        enhancer = ImageEnhance.Sharpness(image)
        return enhancer.enhance(1.3)
    
    async def _postprocess_result(
        self,
        fitted_image: Image.Image,
        original_person: Image.Image,
        original_clothing: Image.Image
    ) -> Image.Image:
        """ê²°ê³¼ ì´ë¯¸ì§€ í›„ì²˜ë¦¬"""
        try:
            # 1. ìƒ‰ìƒ ë³´ì •
            result = self._color_correction(fitted_image, original_person)
            
            # 2. ê²½ê³„ ë¶€ë“œëŸ½ê²Œ í•˜ê¸°
            result = self._smooth_boundaries(result)
            
            # 3. ì „ì²´ì ì¸ í’ˆì§ˆ í–¥ìƒ
            result = self._final_quality_enhancement(result)
            
            logger.debug("âœ… í›„ì²˜ë¦¬ ì™„ë£Œ")
            return result
            
        except Exception as e:
            logger.warning(f"âš ï¸ í›„ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return fitted_image
    
    def _color_correction(self, fitted: Image.Image, original: Image.Image) -> Image.Image:
        """ìƒ‰ìƒ ë³´ì •"""
        # ì›ë³¸ ì´ë¯¸ì§€ì™€ ìƒ‰ì¡° ë§ì¶”ê¸°
        enhancer = ImageEnhance.Color(fitted)
        return enhancer.enhance(0.95)
    
    def _smooth_boundaries(self, image: Image.Image) -> Image.Image:
        """ê²½ê³„ ë¶€ë“œëŸ½ê²Œ í•˜ê¸°"""
        # ê°€ìš°ì‹œì•ˆ ë¸”ëŸ¬ë¥¼ ì•½í•˜ê²Œ ì ìš©
        return image.filter(ImageFilter.GaussianBlur(radius=0.5))
    
    def _final_quality_enhancement(self, image: Image.Image) -> Image.Image:
        """ìµœì¢… í’ˆì§ˆ í–¥ìƒ"""
        # ì„ ëª…ë„ ì¡°ì •
        enhancer = ImageEnhance.Sharpness(image)
        image = enhancer.enhance(1.1)
        
        # ëŒ€ë¹„ ì¡°ì •
        enhancer = ImageEnhance.Contrast(image)
        image = enhancer.enhance(1.02)
        
        return image
    
    async def _evaluate_quality(self, result: Image.Image, original: Image.Image) -> float:
        """í’ˆì§ˆ í‰ê°€"""
        try:
            # ê°„ë‹¨í•œ í’ˆì§ˆ ë©”íŠ¸ë¦­ ê³„ì‚°
            # ì‹¤ì œë¡œëŠ” SSIM, LPIPS ë“± ê³ ê¸‰ ë©”íŠ¸ë¦­ ì‚¬ìš©
            
            # ê¸°ë³¸ ì ìˆ˜
            base_score = 0.75
            
            # í•´ìƒë„ ì ìˆ˜
            width, height = result.size
            resolution_score = min((width * height) / (512 * 512), 1.0) * 0.1
            
            # ìƒ‰ìƒ í’ë¶€ë„ ì ìˆ˜
            colors = result.getcolors(maxcolors=256*256*256)
            color_diversity = len(colors) / 1000.0 if colors else 0.5
            color_score = min(color_diversity, 1.0) * 0.15
            
            total_score = base_score + resolution_score + color_score
            return min(total_score, 1.0)
            
        except Exception as e:
            logger.warning(f"âš ï¸ í’ˆì§ˆ í‰ê°€ ì‹¤íŒ¨: {e}")
            return 0.8
    
    async def _generate_fallback_result(
        self, 
        person_image: bytes, 
        clothing_image: bytes
    ) -> Dict[str, Any]:
        """ì‹¤íŒ¨ ì‹œ ëŒ€ì²´ ê²°ê³¼ ìƒì„±"""
        try:
            logger.info("ğŸ”„ ëŒ€ì²´ ê²°ê³¼ ìƒì„± ì¤‘...")
            
            # ê°„ë‹¨í•œ ì´ë¯¸ì§€ ì˜¤ë²„ë ˆì´ë¡œ ê¸°ë³¸ ê²°ê³¼ ìƒì„±
            person_pil = Image.open(io.BytesIO(person_image)).convert("RGB")
            clothing_pil = Image.open(io.BytesIO(clothing_image)).convert("RGB")
            
            # í¬ê¸° ì¡°ì •
            person_pil = person_pil.resize((512, 512))
            clothing_pil = clothing_pil.resize((200, 300))
            
            # ê°„ë‹¨í•œ í•©ì„±
            result = person_pil.copy()
            result.paste(clothing_pil, (150, 100), clothing_pil)
            
            # base64 ì¸ì½”ë”©
            output_bytes = io.BytesIO()
            result.save(output_bytes, format='JPEG', quality=85)
            fitted_image_b64 = base64.b64encode(output_bytes.getvalue()).decode()
            
            return {
                "fitted_image": fitted_image_b64,
                "confidence": 0.6,
                "processing_time": 1.0,
                "model_used": "fallback",
                "ai_metadata": {"fallback": True},
                "image_specs": {
                    "resolution": result.size,
                    "format": "JPEG",
                    "quality": 85
                }
            }
            
        except Exception as e:
            logger.error(f"âŒ ëŒ€ì²´ ê²°ê³¼ ìƒì„±ë„ ì‹¤íŒ¨: {e}")
            raise
    
    async def get_model_status(self) -> Dict[str, Any]:
        """ëª¨ë¸ ìƒíƒœ ì¡°íšŒ"""
        return {
            "initialized": self.models_initialized,
            "available_models": model_manager.get_available_models(),
            "model_info": model_manager.get_model_info(),
            "device": model_manager.device,
            "queue_size": self.processing_queue.qsize()
        }
    
    async def warm_up_models(self):
        """ëª¨ë¸ ì›œì—… (ì²« ì‹¤í–‰ ì‹œ ì†ë„ í–¥ìƒ)"""
        if not self.models_initialized:
            await self.initialize()
        
        logger.info("ğŸ”¥ AI ëª¨ë¸ ì›œì—… ì‹œì‘...")
        
        try:
            # ë”ë¯¸ ì´ë¯¸ì§€ë¡œ í•œ ë²ˆ ì‹¤í–‰
            dummy_person = Image.new('RGB', (512, 512), color='white')
            dummy_clothing = Image.new('RGB', (512, 512), color='blue')
            
            await model_manager.generate_virtual_fitting(
                dummy_person, dummy_clothing
            )
            
            logger.info("âœ… ëª¨ë¸ ì›œì—… ì™„ë£Œ")
            
        except Exception as e:
            logger.warning(f"âš ï¸ ëª¨ë¸ ì›œì—… ì‹¤íŒ¨: {e}")


# backend/app/services/human_analysis.py
"""
ê³ ê¸‰ ì‹ ì²´ ë¶„ì„ ì„œë¹„ìŠ¤
MediaPipe, Human Parsing ë“±ì„ í™œìš©í•œ ì •ë°€ ì‹ ì²´ ë¶„ì„
"""

import asyncio
import logging
import math
from typing import Dict, Any, List, Tuple, Optional

import cv2
import numpy as np
from PIL import Image

try:
    import mediapipe as mp
    from app.services.ai_models import model_manager
except ImportError as e:
    logging.warning(f"MediaPipe ë˜ëŠ” AI ëª¨ë¸ ì„í¬íŠ¸ ì‹¤íŒ¨: {e}")

logger = logging.getLogger(__name__)

class HumanAnalyzer:
    """ê³ ê¸‰ ì‹ ì²´ ë¶„ì„ê¸°"""
    
    def __init__(self):
        self.mp_pose = None
        self.mp_selfie_segmentation = None
        self.pose_detector = None
        self.segmentation_detector = None
        self.initialized = False
    
    async def initialize(self):
        """MediaPipe ëª¨ë¸ ì´ˆê¸°í™”"""
        if not self.initialized:
            try:
                logger.info("ğŸ¤– MediaPipe ì´ˆê¸°í™” ì¤‘...")
                
                # Pose ê°ì§€ ëª¨ë¸
                self.mp_pose = mp.solutions.pose
                self.pose_detector = self.mp_pose.Pose(
                    static_image_mode=True,
                    model_complexity=2,
                    enable_segmentation=True,
                    min_detection_confidence=0.5
                )
                
                # ì…€í”¼ ì„¸ê·¸ë©˜í…Œì´ì…˜ ëª¨ë¸
                self.mp_selfie_segmentation = mp.solutions.selfie_segmentation
                self.segmentation_detector = self.mp_selfie_segmentation.SelfieSegmentation(
                    model_selection=1  # ê³ í’ˆì§ˆ ëª¨ë¸
                )
                
                self.initialized = True
                logger.info("âœ… MediaPipe ì´ˆê¸°í™” ì™„ë£Œ")
                
            except Exception as e:
                logger.error(f"âŒ MediaPipe ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                self.initialized = False
    
    async def analyze_complete_body(
        self, 
        image_bytes: bytes, 
        measurements: Dict[str, float]
    ) -> Dict[str, Any]:
        """ì™„ì „í•œ ì‹ ì²´ ë¶„ì„"""
        
        if not self.initialized:
            await self.initialize()
        
        try:
            logger.info("ğŸ” ê³ ê¸‰ ì‹ ì²´ ë¶„ì„ ì‹œì‘...")
            
            # PIL ì´ë¯¸ì§€ë¡œ ë³€í™˜
            image = Image.open(io.BytesIO(image_bytes)).convert("RGB")
            image_np = np.array(image)
            
            # 1. í¬ì¦ˆ ë¶„ì„
            pose_analysis = await self._analyze_pose(image_np)
            
            # 2. ì‹ ì²´ ì„¸ê·¸ë©˜í…Œì´ì…˜
            segmentation_result = await self._analyze_segmentation(image_np)
            
            # 3. ì‹ ì²´ ì¸¡ì •ê°’ ì¶”ì¶œ
            body_measurements = await self._extract_measurements(
                image_np, pose_analysis, measurements
            )
            
            # 4. ì²´í˜• ë¶„ë¥˜
            body_type = await self._classify_body_type(body_measurements, measurements)
            
            # 5. ê³ ê¸‰ ì¸ì²´ íŒŒì‹± (AI ëª¨ë¸ ì‚¬ìš©)
            parsing_result = await self._advanced_human_parsing(image)
            
            result = {
                "pose_analysis": pose_analysis,
                "segmentation": segmentation_result,
                "measurements": body_measurements,
                "body_type": body_type,
                "parsing_result": parsing_result,
                "image_size": image.size,
                "analysis_confidence": self._calculate_analysis_confidence(pose_analysis)
            }
            
            logger.info("âœ… ì‹ ì²´ ë¶„ì„ ì™„ë£Œ")
            return result
            
        except Exception as e:
            logger.error(f"âŒ ì‹ ì²´ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return self._generate_fallback_analysis(measurements)
    
    async def _analyze_pose(self, image_np: np.ndarray) -> Dict[str, Any]:
        """í¬ì¦ˆ ë¶„ì„"""
        try:
            if not self.pose_detector:
                return {"keypoints": [], "visibility": [], "pose_confidence": 0.0}
            
            # MediaPipe í¬ì¦ˆ ê°ì§€
            results = self.pose_detector.process(image_np)
            
            if results.pose_landmarks:
                # í‚¤í¬ì¸íŠ¸ ì¶”ì¶œ
                keypoints = []
                visibility = []
                
                for landmark in results.pose_landmarks.landmark:
                    keypoints.append([
                        landmark.x * image_np.shape[1],  # x ì¢Œí‘œ
                        landmark.y * image_np.shape[0],  # y ì¢Œí‘œ
                        landmark.z  # z ì¢Œí‘œ (ìƒëŒ€ì  ê¹Šì´)
                    ])
                    visibility.append(landmark.visibility)
                
                # í¬ì¦ˆ ê°ë„ ê³„ì‚°
                pose_angles = self._calculate_pose_angles(keypoints)
                
                return {
                    "keypoints": keypoints,
                    "visibility": visibility,
                    "pose_angles": pose_angles,
                    "pose_confidence": np.mean(visibility),
                    "pose_landmarks_raw": results.pose_landmarks
                }
            else:
                return {"keypoints": [], "visibility": [], "pose_confidence": 0.0}
                
        except Exception as e:
            logger.error(f"âŒ í¬ì¦ˆ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {"keypoints": [], "visibility": [], "pose_confidence": 0.0}
    
    def _calculate_pose_angles(self, keypoints: List[List[float]]) -> Dict[str, float]:
        """í¬ì¦ˆ ê°ë„ ê³„ì‚°"""
        angles = {}
        
        try:
            # ì£¼ìš” ê´€ì ˆ ê°ë„ ê³„ì‚°
            # ì–´ê¹¨ ê°ë„
            if len(keypoints) > 16:
                left_shoulder = keypoints[11]
                right_shoulder = keypoints[12]
                shoulder_angle = math.degrees(math.atan2(
                    right_shoulder[1] - left_shoulder[1],
                    right_shoulder[0] - left_shoulder[0]
                ))
                angles["shoulder_angle"] = shoulder_angle
            
            # íŒ” ê°ë„
            if len(keypoints) > 16:
                # ì™¼íŒ”
                shoulder = keypoints[11]
                elbow = keypoints[13]
                wrist = keypoints[15]
                left_arm_angle = self._calculate_joint_angle(shoulder, elbow, wrist)
                angles["left_arm_angle"] = left_arm_angle
                
                # ì˜¤ë¥¸íŒ”
                shoulder = keypoints[12]
                elbow = keypoints[14]
                wrist = keypoints[16]
                right_arm_angle = self._calculate_joint_angle(shoulder, elbow, wrist)
                angles["right_arm_angle"] = right_arm_angle
            
        except Exception as e:
            logger.warning(f"âš ï¸ í¬ì¦ˆ ê°ë„ ê³„ì‚° ì‹¤íŒ¨: {e}")
        
        return angles
    
    def _calculate_joint_angle(self, p1: List[float], p2: List[float], p3: List[float]) -> float:
        """3ì ì„ ì´ìš©í•œ ê´€ì ˆ ê°ë„ ê³„ì‚°"""
        try:
            # ë²¡í„° ê³„ì‚°
            v1 = [p1[0] - p2[0], p1[1] - p2[1]]
            v2 = [p3[0] - p2[0], p3[1] - p2[1]]
            
            # ë‚´ì ê³¼ ì™¸ì  ê³„ì‚°
            dot_product = v1[0] * v2[0] + v1[1] * v2[1]
            magnitude1 = math.sqrt(v1[0]**2 + v1[1]**2)
            magnitude2 = math.sqrt(v2[0]**2 + v2[1]**2)
            
            if magnitude1 == 0 or magnitude2 == 0:
                return 0.0
            
            cos_angle = dot_product / (magnitude1 * magnitude2)
            cos_angle = max(-1.0, min(1.0, cos_angle))  # í´ë¨í•‘
            
            angle = math.degrees(math.acos(cos_angle))
            return angle
            
        except Exception:
            return 0.0
    
    async def _analyze_segmentation(self, image_np: np.ndarray) -> Dict[str, Any]:
        """ì‹ ì²´ ì„¸ê·¸ë©˜í…Œì´ì…˜"""
        try:
            if not self.segmentation_detector:
                return {"mask": None, "segmentation_confidence": 0.0}
            
            # ì…€í”¼ ì„¸ê·¸ë©˜í…Œì´ì…˜ ìˆ˜í–‰
            results = self.segmentation_detector.process(image_np)
            
            if results.segmentation_mask is not None:
                # ë§ˆìŠ¤í¬ ì²˜ë¦¬
                mask = results.segmentation_mask
                mask_binary = (mask > 0.5).astype(np.uint8) * 255
                
                # ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‹ ë¢°ë„ ê³„ì‚°
                confidence = np.mean(mask)
                
                return {
                    "mask": mask_binary.tolist(),
                    "segmentation_confidence": float(confidence),
                    "person_area_ratio": np.sum(mask > 0.5) / mask.size
                }
            else:
                return {"mask": None, "segmentation_confidence": 0.0}
                
        except Exception as e:
            logger.error(f"âŒ ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‹¤íŒ¨: {e}")
            return {"mask": None, "segmentation_confidence": 0.0}
    
    async def _extract_measurements(
        self,
        image_np: np.ndarray,
        pose_analysis: Dict[str, Any],
        user_measurements: Dict[str, float]
    ) -> Dict[str, float]:
        """ì‹ ì²´ ì¸¡ì •ê°’ ì¶”ì¶œ"""
        try:
            measurements = {}
            keypoints = pose_analysis.get("keypoints", [])
            
            if len(keypoints) > 24:  # MediaPipe í¬ì¦ˆ ëª¨ë¸ì€ 33ê°œ í‚¤í¬ì¸íŠ¸
                # ì–´ê¹¨ ë„ˆë¹„ (í”½ì…€ ê¸°ì¤€)
                left_shoulder = keypoints[11]
                right_shoulder = keypoints[12]
                shoulder_width_px = abs(right_shoulder[0] - left_shoulder[0])
                
                # ëª¸í†µ ë†’ì´ (í”½ì…€ ê¸°ì¤€)
                shoulder_center_y = (left_shoulder[1] + right_shoulder[1]) / 2
                hip_center_y = (keypoints[23][1] + keypoints[24][1]) / 2  # ì™¼ìª½/ì˜¤ë¥¸ìª½ ì—‰ë©ì´
                torso_height_px = abs(hip_center_y - shoulder_center_y)
                
                # ì‹¤ì œ ì¸¡ì •ê°’ìœ¼ë¡œ ìŠ¤ì¼€ì¼ë§
                height_cm = user_measurements.get("height", 170)
                total_height_px = abs(keypoints[0][1] - max(keypoints[31][1], keypoints[32][1]))  # ë¨¸ë¦¬ ê¼­ëŒ€ê¸° - ë°œë
                
                if total_height_px > 0:
                    pixel_to_cm_ratio = height_cm / total_height_px
                    
                    measurements["shoulder_width"] = shoulder_width_px * pixel_to_cm_ratio
                    measurements["torso_height"] = torso_height_px * pixel_to_cm_ratio
                    measurements["estimated_chest"] = measurements["shoulder_width"] * 2.2  # ì¶”ì •
                    measurements["estimated_waist"] = measurements["shoulder_width"] * 1.8  # ì¶”ì •
                
                # BMI ê³„ì‚°
                weight = user_measurements.get("weight", 65)
                height_m = height_cm / 100
                measurements["bmi"] = weight / (height_m ** 2)
                
                # ì²´í˜• ë¹„ìœ¨
                measurements["shoulder_to_hip_ratio"] = self._calculate_shoulder_hip_ratio(keypoints)
                
            else:
                # í‚¤í¬ì¸íŠ¸ê°€ ì¶©ë¶„í•˜ì§€ ì•Šì€ ê²½ìš° ì‚¬ìš©ì ì…ë ¥ê°’ ì‚¬ìš©
                measurements = {
                    "shoulder_width": 40.0,
                    "torso_height": 50.0,
                    "estimated_chest": user_measurements.get("chest", 90),
                    "estimated_waist": user_measurements.get("waist", 75),
                    "bmi": user_measurements.get("weight", 65) / ((user_measurements.get("height", 170) / 100) ** 2)
                }
            
            return measurements
            
        except Exception as e:
            logger.error(f"âŒ ì¸¡ì •ê°’ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return {"bmi": 22.0, "shoulder_width": 40.0}
    
    def _calculate_shoulder_hip_ratio(self, keypoints: List[List[float]]) -> float:
        """ì–´ê¹¨-ì—‰ë©ì´ ë¹„ìœ¨ ê³„ì‚°"""
        try:
            # ì–´ê¹¨ ë„ˆë¹„
            shoulder_width = abs(keypoints[12][0] - keypoints[11][0])
            
            # ì—‰ë©ì´ ë„ˆë¹„
            hip_width = abs(keypoints[24][0] - keypoints[23][0])
            
            if hip_width > 0:
                return shoulder_width / hip_width
            else:
                return 1.0
                
        except Exception:
            return 1.0
    
    async def _classify_body_type(
        self,
        measurements: Dict[str, float],
        user_data: Dict[str, float]
    ) -> str:
        """ì²´í˜• ë¶„ë¥˜"""
        try:
            bmi = measurements.get("bmi", 22.0)
            shoulder_hip_ratio = measurements.get("shoulder_to_hip_ratio", 1.0)
            
            # BMI ê¸°ë°˜ ê¸°ë³¸ ë¶„ë¥˜
            if bmi < 18.5:
                base_type = "ìŠ¬ë¦¼"
            elif bmi < 25:
                base_type = "ë³´í†µ"
            elif bmi < 30:
                base_type = "í†µí†µ"
            else:
                base_type = "í°ì²´í˜•"
            
            # ì–´ê¹¨-ì—‰ë©ì´ ë¹„ìœ¨ ê¸°ë°˜ ì„¸ë¶€ ë¶„ë¥˜
            if shoulder_hip_ratio > 1.1:
                body_shape = "ì—­ì‚¼ê°í˜•"
            elif shoulder_hip_ratio < 0.9:
                body_shape = "ì‚¼ê°í˜•"
            else:
                body_shape = "ì§ì‚¬ê°í˜•"
            
            return f"{base_type}_{body_shape}"
            
        except Exception as e:
            logger.error(f"âŒ ì²´í˜• ë¶„ë¥˜ ì‹¤íŒ¨: {e}")
            return "ë³´í†µ_ì§ì‚¬ê°í˜•"
    
    async def _advanced_human_parsing(self, image: Image.Image) -> Optional[Dict[str, Any]]:
        """ê³ ê¸‰ ì¸ì²´ íŒŒì‹± (AI ëª¨ë¸ ì‚¬ìš©)"""
        try:
            if "human_parsing" in model_manager.get_available_models():
                parsing_result = await model_manager.analyze_human(image)
                return parsing_result
            else:
                logger.info("â„¹ï¸ Human Parsing ëª¨ë¸ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŒ")
                return None
                
        except Exception as e:
            logger.warning(f"âš ï¸ ê³ ê¸‰ ì¸ì²´ íŒŒì‹± ì‹¤íŒ¨: {e}")
            return None
    
    def _calculate_analysis_confidence(self, pose_analysis: Dict[str, Any]) -> float:
        """ë¶„ì„ ì‹ ë¢°ë„ ê³„ì‚°"""
        try:
            pose_confidence = pose_analysis.get("pose_confidence", 0.0)
            keypoints_count = len(pose_analysis.get("keypoints", []))
            
            # í‚¤í¬ì¸íŠ¸ ê°œìˆ˜ì™€ í’ˆì§ˆì— ë”°ë¥¸ ì‹ ë¢°ë„
            completeness_score = min(keypoints_count / 33.0, 1.0)  # MediaPipeëŠ” 33ê°œ í‚¤í¬ì¸íŠ¸
            
            # ì „ì²´ ì‹ ë¢°ë„
            total_confidence = (pose_confidence * 0.7) + (completeness_score * 0.3)
            
            return min(max(total_confidence, 0.0), 1.0)
            
        except Exception:
            return 0.7
    
    def _generate_fallback_analysis(self, measurements: Dict[str, float]) -> Dict[str, Any]:
        """ë¶„ì„ ì‹¤íŒ¨ ì‹œ ëŒ€ì²´ ê²°ê³¼"""
        height = measurements.get("height", 170)
        weight = measurements.get("weight", 65)
        bmi = weight / ((height / 100) ** 2)
        
        return {
            "pose_analysis": {"keypoints": [], "pose_confidence": 0.5},
            "segmentation": {"mask": None, "segmentation_confidence": 0.5},
            "measurements": {
                "bmi": bmi,
                "shoulder_width": 40.0,
                "estimated_chest": measurements.get("chest", 90),
                "estimated_waist": measurements.get("waist", 75)
            },
            "body_type": "ë³´í†µ_ì§ì‚¬ê°í˜•",
            "parsing_result": None,
            "analysis_confidence": 0.5
        }