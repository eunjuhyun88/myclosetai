# backend/app/services/real_working_ai_fitter.py
"""
ì‹¤ì œ ì‘ë™í•˜ëŠ” AI ê°€ìƒ í”¼íŒ…
MediaPipe, OpenCV, ì‹¤ì œ ì´ë¯¸ì§€ ì²˜ë¦¬ ê¸°ìˆ  ì‚¬ìš©
"""

import cv2
import numpy as np
import mediapipe as mp
from PIL import Image, ImageDraw, ImageFilter, ImageEnhance
import asyncio
import logging
from typing import Dict, Any, Tuple, List
import time

logger = logging.getLogger(__name__)

class RealWorkingAIFitter:
    """ì‹¤ì œ ì‘ë™í•˜ëŠ” AI ê°€ìƒ í”¼íŒ…"""
    
    def __init__(self):
        # MediaPipe ì´ˆê¸°í™”
        self.mp_pose = mp.solutions.pose
        self.mp_selfie_segmentation = mp.solutions.selfie_segmentation
        self.mp_drawing = mp.solutions.drawing_utils
        
        # ëª¨ë¸ ì´ˆê¸°í™”
        self.pose_detector = self.mp_pose.Pose(
            static_image_mode=True,
            model_complexity=2,
            enable_segmentation=True,
            min_detection_confidence=0.7
        )
        
        self.segmentation_model = self.mp_selfie_segmentation.SelfieSegmentation(
            model_selection=1  # ê³ í’ˆì§ˆ ëª¨ë¸
        )
        
        logger.info("âœ… MediaPipe ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ")
    
    async def process_real_ai_fitting(
        self,
        person_image: Image.Image,
        clothing_image: Image.Image,
        height: float,
        weight: float
    ) -> Tuple[Image.Image, Dict[str, Any]]:
        """ì‹¤ì œ AI ê°€ìƒ í”¼íŒ… ì²˜ë¦¬"""
        
        logger.info("ğŸ”¥ ì‹¤ì œ AI ê°€ìƒ í”¼íŒ… ì‹œì‘!")
        start_time = time.time()
        
        processing_info = {
            "steps_completed": [],
            "processing_times": {},
            "confidence_scores": {},
            "detected_features": {}
        }
        
        try:
            # 1ë‹¨ê³„: ì‹¤ì œ ì¸ì²´ í¬ì¦ˆ ê²€ì¶œ
            step_start = time.time()
            logger.info("ğŸ‘¤ 1ë‹¨ê³„: MediaPipe ì¸ì²´ í¬ì¦ˆ ê²€ì¶œ...")
            
            pose_result = self._detect_real_pose(person_image)
            processing_info["steps_completed"].append("MediaPipe í¬ì¦ˆ ê²€ì¶œ")
            processing_info["processing_times"]["pose_detection"] = time.time() - step_start
            processing_info["confidence_scores"]["pose"] = pose_result.get("confidence", 0)
            processing_info["detected_features"]["pose_landmarks"] = pose_result.get("landmark_count", 0)
            
            if not pose_result["detected"]:
                raise ValueError("ì¸ì²´ í¬ì¦ˆë¥¼ ê²€ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            
            # 2ë‹¨ê³„: ì‹¤ì œ ì¸ì²´ ì„¸ê·¸ë©˜í…Œì´ì…˜
            step_start = time.time()
            logger.info("âœ‚ï¸ 2ë‹¨ê³„: AI ì¸ì²´ ì„¸ê·¸ë©˜í…Œì´ì…˜...")
            
            segmentation_result = self._segment_person(person_image)
            processing_info["steps_completed"].append("AI ì¸ì²´ ì„¸ê·¸ë©˜í…Œì´ì…˜")
            processing_info["processing_times"]["segmentation"] = time.time() - step_start
            processing_info["confidence_scores"]["segmentation"] = segmentation_result.get("quality", 0)
            
            # 3ë‹¨ê³„: ì²´í˜• ë¶„ì„ ë° ì˜ë¥˜ ì˜ì—­ ê³„ì‚°
            step_start = time.time()
            logger.info("ğŸ“ 3ë‹¨ê³„: ì²´í˜• ë¶„ì„ ë° ì˜ë¥˜ ì˜ì—­ ê³„ì‚°...")
            
            body_analysis = self._analyze_body_shape(pose_result, person_image, height, weight)
            clothing_regions = self._calculate_clothing_regions(pose_result, body_analysis)
            processing_info["steps_completed"].append("ì²´í˜• ë¶„ì„ ì™„ë£Œ")
            processing_info["processing_times"]["body_analysis"] = time.time() - step_start
            processing_info["detected_features"]["body_measurements"] = len(body_analysis.get("measurements", {}))
            
            # 4ë‹¨ê³„: ì˜ë¥˜ ì „ì²˜ë¦¬ ë° ë¶„ì„
            step_start = time.time()
            logger.info("ğŸ‘• 4ë‹¨ê³„: ì˜ë¥˜ ì´ë¯¸ì§€ ë¶„ì„ ë° ì „ì²˜ë¦¬...")
            
            clothing_processed = self._process_clothing_image(clothing_image)
            clothing_analysis = self._analyze_clothing_type(clothing_image)
            processing_info["steps_completed"].append("ì˜ë¥˜ ë¶„ì„ ì™„ë£Œ")
            processing_info["processing_times"]["clothing_processing"] = time.time() - step_start
            processing_info["detected_features"]["clothing_type"] = clothing_analysis.get("type", "unknown")
            
            # 5ë‹¨ê³„: ì‹¤ì œ ê°€ìƒ í”¼íŒ… (ì •ë°€ ë§¤í•‘)
            step_start = time.time()
            logger.info("ğŸ¨ 5ë‹¨ê³„: ì •ë°€ ê°€ìƒ í”¼íŒ… ë° ë Œë”ë§...")
            
            fitted_result = self._perform_precise_fitting(
                person_image,
                clothing_processed,
                pose_result,
                clothing_regions,
                segmentation_result,
                body_analysis,
                clothing_analysis
            )
            processing_info["steps_completed"].append("ì •ë°€ í”¼íŒ… ì™„ë£Œ")
            processing_info["processing_times"]["precise_fitting"] = time.time() - step_start
            
            # 6ë‹¨ê³„: í›„ì²˜ë¦¬ ë° í’ˆì§ˆ í–¥ìƒ
            step_start = time.time()
            logger.info("âœ¨ 6ë‹¨ê³„: ì´ë¯¸ì§€ í’ˆì§ˆ í–¥ìƒ...")
            
            final_result = self._enhance_result_quality(fitted_result)
            processing_info["steps_completed"].append("í’ˆì§ˆ í–¥ìƒ ì™„ë£Œ")
            processing_info["processing_times"]["enhancement"] = time.time() - step_start
            
            total_time = time.time() - start_time
            processing_info["total_processing_time"] = total_time
            
            # ì „ì²´ í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°
            overall_confidence = np.mean([
                processing_info["confidence_scores"].get("pose", 0),
                processing_info["confidence_scores"].get("segmentation", 0)
            ])
            processing_info["overall_confidence"] = overall_confidence
            
            logger.info(f"ğŸ‰ ì‹¤ì œ AI ê°€ìƒ í”¼íŒ… ì™„ë£Œ! ({total_time:.1f}ì´ˆ, ì‹ ë¢°ë„: {overall_confidence:.2f})")
            
            return final_result, processing_info
            
        except Exception as e:
            logger.error(f"âŒ ì‹¤ì œ AI í”¼íŒ… ì‹¤íŒ¨: {e}")
            # ì‹¤íŒ¨ì‹œì—ë„ ê¸°ë³¸ì ì¸ ê²°ê³¼ ì œê³µ
            fallback_result = self._create_fallback_result(person_image, clothing_image)
            processing_info["steps_completed"].append(f"ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            processing_info["error"] = str(e)
            
            return fallback_result, processing_info
    
    def _detect_real_pose(self, person_image: Image.Image) -> Dict[str, Any]:
        """ì‹¤ì œ MediaPipe í¬ì¦ˆ ê²€ì¶œ"""
        
        try:
            # PILì„ OpenCV í˜•ì‹ìœ¼ë¡œ ë³€í™˜
            cv_image = cv2.cvtColor(np.array(person_image), cv2.COLOR_RGB2BGR)
            rgb_image = cv2.cvtColor(cv_image, cv2.COLOR_BGR2RGB)
            
            # MediaPipe í¬ì¦ˆ ê²€ì¶œ ì‹¤í–‰
            results = self.pose_detector.process(rgb_image)
            
            if results.pose_landmarks:
                # ëœë“œë§ˆí¬ ì¶”ì¶œ
                landmarks = []
                for landmark in results.pose_landmarks.landmark:
                    landmarks.append({
                        'x': landmark.x,
                        'y': landmark.y,
                        'z': landmark.z,
                        'visibility': landmark.visibility
                    })
                
                # ì‹ ë¢°ë„ ê³„ì‚° (ê°€ì‹œì„± í‰ê· )
                confidences = [lm['visibility'] for lm in landmarks]
                avg_confidence = np.mean(confidences)
                
                # ì£¼ìš” í¬ì¸íŠ¸ ì¶”ì¶œ
                key_points = self._extract_key_body_points(landmarks, person_image.size)
                
                logger.info(f"âœ… í¬ì¦ˆ ê²€ì¶œ ì„±ê³µ: {len(landmarks)}ê°œ ëœë“œë§ˆí¬, ì‹ ë¢°ë„: {avg_confidence:.2f}")
                
                return {
                    "detected": True,
                    "landmarks": landmarks,
                    "confidence": avg_confidence,
                    "landmark_count": len(landmarks),
                    "key_points": key_points,
                    "segmentation_mask": results.segmentation_mask
                }
            else:
                logger.warning("âŒ í¬ì¦ˆ ê²€ì¶œ ì‹¤íŒ¨")
                return {
                    "detected": False,
                    "confidence": 0.0,
                    "landmark_count": 0
                }
                
        except Exception as e:
            logger.error(f"âŒ í¬ì¦ˆ ê²€ì¶œ ì˜¤ë¥˜: {e}")
            return {
                "detected": False,
                "confidence": 0.0,
                "error": str(e)
            }
    
    def _extract_key_body_points(self, landmarks: List[Dict], image_size: Tuple[int, int]) -> Dict[str, Tuple[int, int]]:
        """ì£¼ìš” ì‹ ì²´ í¬ì¸íŠ¸ ì¶”ì¶œ"""
        
        width, height = image_size
        
        # MediaPipe ëœë“œë§ˆí¬ ì¸ë±ìŠ¤
        key_indices = {
            'nose': 0,
            'left_shoulder': 11,
            'right_shoulder': 12,
            'left_elbow': 13,
            'right_elbow': 14,
            'left_wrist': 15,
            'right_wrist': 16,
            'left_hip': 23,
            'right_hip': 24,
            'left_knee': 25,
            'right_knee': 26,
            'left_ankle': 27,
            'right_ankle': 28
        }
        
        key_points = {}
        
        for name, idx in key_indices.items():
            if idx < len(landmarks) and landmarks[idx]['visibility'] > 0.5:
                x = int(landmarks[idx]['x'] * width)
                y = int(landmarks[idx]['y'] * height)
                key_points[name] = (x, y)
        
        return key_points
    
    def _segment_person(self, person_image: Image.Image) -> Dict[str, Any]:
        """ì‹¤ì œ AI ì¸ì²´ ì„¸ê·¸ë©˜í…Œì´ì…˜"""
        
        try:
            # PILì„ OpenCVë¡œ ë³€í™˜
            cv_image = cv2.cvtColor(np.array(person_image), cv2.COLOR_RGB2BGR)
            rgb_image = cv2.cvtColor(cv_image, cv2.COLOR_BGR2RGB)
            
            # MediaPipe ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‹¤í–‰
            results = self.segmentation_model.process(rgb_image)
            
            if results.segmentation_mask is not None:
                # ë§ˆìŠ¤í¬ë¥¼ 0-255 ë²”ìœ„ë¡œ ë³€í™˜
                mask = (results.segmentation_mask * 255).astype(np.uint8)
                
                # ë§ˆìŠ¤í¬ í’ˆì§ˆ í‰ê°€
                mask_coverage = np.sum(mask > 128) / mask.size
                mask_sharpness = np.var(mask)
                quality_score = min(1.0, mask_coverage * 2 + mask_sharpness / 10000)
                
                logger.info(f"âœ… ì„¸ê·¸ë©˜í…Œì´ì…˜ ì„±ê³µ: ì»¤ë²„ë¦¬ì§€ {mask_coverage:.2f}, í’ˆì§ˆ {quality_score:.2f}")
                
                return {
                    "mask": mask,
                    "quality": quality_score,
                    "coverage": mask_coverage,
                    "success": True
                }
            else:
                logger.warning("âŒ ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‹¤íŒ¨")
                return {
                    "success": False,
                    "quality": 0.0
                }
                
        except Exception as e:
            logger.error(f"âŒ ì„¸ê·¸ë©˜í…Œì´ì…˜ ì˜¤ë¥˜: {e}")
            return {
                "success": False,
                "quality": 0.0,
                "error": str(e)
            }
    
    def _analyze_body_shape(
        self, 
        pose_result: Dict[str, Any], 
        person_image: Image.Image,
        height: float, 
        weight: float
    ) -> Dict[str, Any]:
        """ì‹¤ì œ ì²´í˜• ë¶„ì„"""
        
        if not pose_result["detected"]:
            return {"measurements": {}, "body_type": "unknown"}
        
        key_points = pose_result["key_points"]
        width, height_px = person_image.size
        
        measurements = {}
        
        try:
            # ì–´ê¹¨ ë„ˆë¹„ ê³„ì‚°
            if 'left_shoulder' in key_points and 'right_shoulder' in key_points:
                left_shoulder = key_points['left_shoulder']
                right_shoulder = key_points['right_shoulder']
                shoulder_width_px = abs(left_shoulder[0] - right_shoulder[0])
                measurements['shoulder_width'] = shoulder_width_px
                
                # ì‹¤ì œ ê¸¸ì´ë¡œ ë³€í™˜ (ê·¼ì‚¬ì¹˜)
                pixel_to_cm = height / height_px  # ëŒ€ëµì ì¸ ë³€í™˜ ë¹„ìœ¨
                measurements['shoulder_width_cm'] = shoulder_width_px * pixel_to_cm
            
            # ì—‰ë©ì´ ë„ˆë¹„ ê³„ì‚°
            if 'left_hip' in key_points and 'right_hip' in key_points:
                left_hip = key_points['left_hip']
                right_hip = key_points['right_hip']
                hip_width_px = abs(left_hip[0] - right_hip[0])
                measurements['hip_width'] = hip_width_px
            
            # ëª¸í†µ ê¸¸ì´ ê³„ì‚°
            if 'left_shoulder' in key_points and 'left_hip' in key_points:
                shoulder_y = key_points['left_shoulder'][1]
                hip_y = key_points['left_hip'][1]
                torso_length_px = abs(hip_y - shoulder_y)
                measurements['torso_length'] = torso_length_px
            
            # BMI ê¸°ë°˜ ì²´í˜• ë¶„ë¥˜
            bmi = weight / ((height / 100) ** 2)
            if bmi < 18.5:
                body_type = "slim"
            elif bmi > 25:
                body_type = "plus"
            else:
                body_type = "regular"
            
            measurements['bmi'] = bmi
            
            logger.info(f"âœ… ì²´í˜• ë¶„ì„ ì™„ë£Œ: {body_type}, BMI: {bmi:.1f}")
            
            return {
                "measurements": measurements,
                "body_type": body_type,
                "bmi": bmi,
                "analysis_success": True
            }
            
        except Exception as e:
            logger.error(f"âŒ ì²´í˜• ë¶„ì„ ì˜¤ë¥˜: {e}")
            return {
                "measurements": {},
                "body_type": "unknown",
                "analysis_success": False
            }
    
    def _calculate_clothing_regions(self, pose_result: Dict[str, Any], body_analysis: Dict[str, Any]) -> Dict[str, Dict]:
        """ì •í™•í•œ ì˜ë¥˜ ì˜ì—­ ê³„ì‚°"""
        
        if not pose_result["detected"]:
            return {}
        
        key_points = pose_result["key_points"]
        clothing_regions = {}
        
        try:
            # ìƒì˜ ì˜ì—­ ê³„ì‚°
            if all(point in key_points for point in ['left_shoulder', 'right_shoulder', 'left_hip', 'right_hip']):
                left_shoulder = key_points['left_shoulder']
                right_shoulder = key_points['right_shoulder']
                left_hip = key_points['left_hip']
                right_hip = key_points['right_hip']
                
                # ìƒì˜ ì˜ì—­ ë°”ìš´ë”© ë°•ìŠ¤
                min_x = min(left_shoulder[0], right_shoulder[0], left_hip[0], right_hip[0])
                max_x = max(left_shoulder[0], right_shoulder[0], left_hip[0], right_hip[0])
                min_y = min(left_shoulder[1], right_shoulder[1])
                max_y = max(left_hip[1], right_hip[1])
                
                # ì—¬ìœ  ê³µê°„ ì¶”ê°€
                padding_x = int((max_x - min_x) * 0.15)
                padding_y = int((max_y - min_y) * 0.1)
                
                clothing_regions['upper_body'] = {
                    'x': max(0, min_x - padding_x),
                    'y': max(0, min_y - padding_y),
                    'width': (max_x - min_x) + 2 * padding_x,
                    'height': (max_y - min_y) + 2 * padding_y,
                    'center_x': (min_x + max_x) // 2,
                    'center_y': (min_y + max_y) // 2
                }
                
                logger.info("âœ… ìƒì˜ ì˜ì—­ ê³„ì‚° ì™„ë£Œ")
            
            # í•˜ì˜ ì˜ì—­ ê³„ì‚° (í•„ìš”ì‹œ)
            if all(point in key_points for point in ['left_hip', 'right_hip', 'left_knee', 'right_knee']):
                left_hip = key_points['left_hip']
                right_hip = key_points['right_hip']
                left_knee = key_points['left_knee']
                right_knee = key_points['right_knee']
                
                min_x = min(left_hip[0], right_hip[0], left_knee[0], right_knee[0])
                max_x = max(left_hip[0], right_hip[0], left_knee[0], right_knee[0])
                min_y = min(left_hip[1], right_hip[1])
                max_y = max(left_knee[1], right_knee[1])
                
                clothing_regions['lower_body'] = {
                    'x': max(0, min_x - 20),
                    'y': min_y,
                    'width': (max_x - min_x) + 40,
                    'height': (max_y - min_y) + 20
                }
                
                logger.info("âœ… í•˜ì˜ ì˜ì—­ ê³„ì‚° ì™„ë£Œ")
            
            return clothing_regions
            
        except Exception as e:
            logger.error(f"âŒ ì˜ë¥˜ ì˜ì—­ ê³„ì‚° ì˜¤ë¥˜: {e}")
            return {}
    
    def _process_clothing_image(self, clothing_image: Image.Image) -> Image.Image:
        """ì˜ë¥˜ ì´ë¯¸ì§€ ì „ì²˜ë¦¬"""
        
        try:
            # 1. ë°°ê²½ ì œê±°
            clothing_no_bg = self._remove_clothing_background(clothing_image)
            
            # 2. í’ˆì§ˆ í–¥ìƒ
            enhanced = self._enhance_clothing_quality(clothing_no_bg)
            
            # 3. ê°€ì¥ìë¦¬ ìŠ¤ë¬´ë”©
            smoothed = enhanced.filter(ImageFilter.GaussianBlur(0.5))
            
            logger.info("âœ… ì˜ë¥˜ ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì™„ë£Œ")
            return smoothed
            
        except Exception as e:
            logger.error(f"âŒ ì˜ë¥˜ ì „ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            return clothing_image
    
    def _remove_clothing_background(self, clothing_image: Image.Image) -> Image.Image:
        """ì˜ë¥˜ ë°°ê²½ ì œê±°"""
        
        try:
            # OpenCVë¡œ ë³€í™˜
            cv_image = cv2.cvtColor(np.array(clothing_image), cv2.COLOR_RGB2BGR)
            
            # GrabCut ì•Œê³ ë¦¬ì¦˜ ì‚¬ìš©
            height, width = cv_image.shape[:2]
            mask = np.zeros((height, width), np.uint8)
            
            # ì „ê²½ ì˜ì—­ ì¶”ì • (ì¤‘ì•™ 80%)
            margin = 0.1
            rect = (
                int(width * margin),
                int(height * margin),
                int(width * (1 - 2 * margin)),
                int(height * (1 - 2 * margin))
            )
            
            # GrabCut ëª¨ë¸
            bgd_model = np.zeros((1, 65), np.float64)
            fgd_model = np.zeros((1, 65), np.float64)
            
            # GrabCut ì‹¤í–‰
            cv2.grabCut(cv_image, mask, rect, bgd_model, fgd_model, 5, cv2.GC_INIT_WITH_RECT)
            
            # ë§ˆìŠ¤í¬ ì ìš©
            mask2 = np.where((mask == 2) | (mask == 0), 0, 1).astype('uint8')
            result = cv_image * mask2[:, :, np.newaxis]
            
            # ë°°ê²½ì„ íˆ¬ëª…í•˜ê²Œ
            result_rgba = cv2.cvtColor(result, cv2.COLOR_BGR2RGBA)
            result_rgba[:, :, 3] = mask2 * 255
            
            # PILë¡œ ë³€í™˜
            return Image.fromarray(result_rgba, 'RGBA')
            
        except Exception as e:
            logger.warning(f"GrabCut ë°°ê²½ ì œê±° ì‹¤íŒ¨, ê°„ë‹¨í•œ ë°©ë²• ì‚¬ìš©: {e}")
            return self._simple_background_removal(clothing_image)
    
    def _simple_background_removal(self, clothing_image: Image.Image) -> Image.Image:
        """ê°„ë‹¨í•œ ë°°ê²½ ì œê±°"""
        
        try:
            # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜
            gray = clothing_image.convert('L')
            
            # ì„ê³„ê°’ ì²˜ë¦¬
            threshold = 240
            mask = gray.point(lambda x: 255 if x < threshold else 0, mode='1')
            
            # RGBAë¡œ ë³€í™˜
            rgba_image = clothing_image.convert('RGBA')
            
            # ë§ˆìŠ¤í¬ ì ìš©
            rgba_array = np.array(rgba_image)
            mask_array = np.array(mask)
            rgba_array[:, :, 3] = mask_array
            
            return Image.fromarray(rgba_array, 'RGBA')
            
        except Exception as e:
            logger.warning(f"ê°„ë‹¨í•œ ë°°ê²½ ì œê±°ë„ ì‹¤íŒ¨: {e}")
            return clothing_image
    
    def _enhance_clothing_quality(self, clothing_image: Image.Image) -> Image.Image:
        """ì˜ë¥˜ í’ˆì§ˆ í–¥ìƒ"""
        
        try:
            # ì„ ëª…ë„ í–¥ìƒ
            sharpness_enhancer = ImageEnhance.Sharpness(clothing_image)
            enhanced = sharpness_enhancer.enhance(1.2)
            
            # ëŒ€ë¹„ í–¥ìƒ
            contrast_enhancer = ImageEnhance.Contrast(enhanced)
            enhanced = contrast_enhancer.enhance(1.1)
            
            # ìƒ‰ìƒ ì±„ë„ í–¥ìƒ
            color_enhancer = ImageEnhance.Color(enhanced)
            enhanced = color_enhancer.enhance(1.05)
            
            return enhanced
            
        except Exception as e:
            logger.warning(f"ì˜ë¥˜ í’ˆì§ˆ í–¥ìƒ ì‹¤íŒ¨: {e}")
            return clothing_image
    
    def _analyze_clothing_type(self, clothing_image: Image.Image) -> Dict[str, Any]:
        """ì˜ë¥˜ íƒ€ì… ë¶„ì„"""
        
        width, height = clothing_image.size
        aspect_ratio = height / width
        
        # ê°„ë‹¨í•œ ë¹„ìœ¨ ê¸°ë°˜ ë¶„ë¥˜
        if aspect_ratio > 1.8:
            clothing_type = "dress"
            category = "ì›í”¼ìŠ¤"
        elif aspect_ratio > 1.4:
            clothing_type = "pants"
            category = "í•˜ì˜"
        elif aspect_ratio < 0.7:
            clothing_type = "jacket"
            category = "ì•„ìš°í„°"
        else:
            clothing_type = "shirt"
            category = "ìƒì˜"
        
        # ìƒ‰ìƒ ë¶„ì„
        colors = self._extract_dominant_colors(clothing_image)
        
        return {
            "type": clothing_type,
            "category": category,
            "aspect_ratio": aspect_ratio,
            "colors": colors,
            "size": (width, height)
        }
    
    def _extract_dominant_colors(self, image: Image.Image) -> List[str]:
        """ì£¼ìš” ìƒ‰ìƒ ì¶”ì¶œ"""
        
        try:
            # ì´ë¯¸ì§€ í¬ê¸° ì¶•ì†Œ
            small_image = image.resize((50, 50))
            
            # RGB ëª¨ë“œë¡œ ë³€í™˜
            if small_image.mode != 'RGB':
                small_image = small_image.convert('RGB')
            
            # ìƒ‰ìƒ íˆìŠ¤í† ê·¸ë¨
            colors = small_image.getcolors(maxcolors=256*256*256)
            
            if colors:
                # ìƒìœ„ 3ê°œ ìƒ‰ìƒ
                sorted_colors = sorted(colors, reverse=True)[:3]
                color_names = []
                
                for count, color in sorted_colors:
                    color_name = self._rgb_to_color_name(color)
                    color_names.append(color_name)
                
                return color_names
            
            return ["unknown"]
            
        except Exception as e:
            logger.warning(f"ìƒ‰ìƒ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return ["unknown"]
    
    def _rgb_to_color_name(self, rgb: Tuple[int, int, int]) -> str:
        """RGBë¥¼ ìƒ‰ìƒ ì´ë¦„ìœ¼ë¡œ ë³€í™˜"""
        
        r, g, b = rgb
        
        if r > 200 and g > 200 and b > 200:
            return "white"
        elif r < 50 and g < 50 and b < 50:
            return "black"
        elif r > g and r > b:
            return "red"
        elif g > r and g > b:
            return "green"
        elif b > r and b > g:
            return "blue"
        elif r > 150 and g > 150:
            return "yellow"
        else:
            return "mixed"
    
    def _perform_precise_fitting(
        self,
        person_image: Image.Image,
        clothing_image: Image.Image,
        pose_result: Dict[str, Any],
        clothing_regions: Dict[str, Dict],
        segmentation_result: Dict[str, Any],
        body_analysis: Dict[str, Any],
        clothing_analysis: Dict[str, Any]
    ) -> Image.Image:
        """ì •ë°€ ê°€ìƒ í”¼íŒ… ìˆ˜í–‰"""
        
        try:
            # ë² ì´ìŠ¤ ì´ë¯¸ì§€ ë³µì‚¬
            result = person_image.copy()
            
            # ìƒì˜ í”¼íŒ…
            if 'upper_body' in clothing_regions and clothing_analysis['type'] in ['shirt', 'jacket', 'dress']:
                result = self._fit_upper_body_clothing(
                    result, clothing_image, clothing_regions['upper_body'], 
                    pose_result, body_analysis, segmentation_result
                )
            
            # í•˜ì˜ í”¼íŒ… (í•„ìš”ì‹œ)
            elif 'lower_body' in clothing_regions and clothing_analysis['type'] == 'pants':
                result = self._fit_lower_body_clothing(
                    result, clothing_image, clothing_regions['lower_body'],
                    pose_result, body_analysis
                )
            
            else:
                # ê¸°ë³¸ í”¼íŒ…
                result = self._basic_clothing_fit(result, clothing_image)
            
            logger.info("âœ… ì •ë°€ í”¼íŒ… ì™„ë£Œ")
            return result
            
        except Exception as e:
            logger.error(f"âŒ ì •ë°€ í”¼íŒ… ì‹¤íŒ¨: {e}")
            return self._basic_clothing_fit(person_image, clothing_image)
    
    def _fit_upper_body_clothing(
        self,
        person_image: Image.Image,
        clothing_image: Image.Image,
        upper_region: Dict[str, int],
        pose_result: Dict[str, Any],
        body_analysis: Dict[str, Any],
        segmentation_result: Dict[str, Any]
    ) -> Image.Image:
        """ìƒì˜ ì •ë°€ í”¼íŒ…"""
        
        try:
            # ì˜ë¥˜ í¬ê¸° ì¡°ì •
            target_width = upper_region['width']
            target_height = upper_region['height']
            
            # ì²´í˜•ì— ë§ëŠ” ìŠ¤ì¼€ì¼ë§
            body_type = body_analysis.get('body_type', 'regular')
            if body_type == 'slim':
                target_width = int(target_width * 0.9)
            elif body_type == 'plus':
                target_width = int(target_width * 1.1)
            
            # ì˜ë¥˜ ë¦¬ì‚¬ì´ì¦ˆ
            clothing_fitted = clothing_image.resize((target_width, target_height), Image.Resampling.LANCZOS)
            
            # ìœ„ì¹˜ ê³„ì‚°
            fit_x = upper_region['x'] + (upper_region['width'] - target_width) // 2
            fit_y = upper_region['y']
            
            # ì •ë°€ í•©ì„±
            if clothing_fitted.mode == 'RGBA':
                # íˆ¬ëª…ë„ ì •ë³´ê°€ ìˆëŠ” ê²½ìš°
                person_image.paste(clothing_fitted, (fit_x, fit_y), clothing_fitted)
            else:
                # ë§ˆìŠ¤í¬ ìƒì„± í›„ í•©ì„±
                mask = self._create_precise_mask(clothing_fitted, segmentation_result)
                person_image.paste(clothing_fitted, (fit_x, fit_y), mask)
            
            # ìì—°ìŠ¤ëŸ¬ìš´ ë¸”ë Œë”©
            person_image = self._apply_natural_blending(person_image, fit_x, fit_y, target_width, target_height)
            
            return person_image
            
        except Exception as e:
            logger.error(f"âŒ ìƒì˜ í”¼íŒ… ì˜¤ë¥˜: {e}")
            return person_image
    
    def _create_precise_mask(self, clothing_image: Image.Image, segmentation_result: Dict[str, Any]) -> Image.Image:
        """ì •ë°€ ë§ˆìŠ¤í¬ ìƒì„±"""
        
        try:
            if clothing_image.mode == 'RGBA':
                # ì•ŒíŒŒ ì±„ë„ì´ ìˆìœ¼ë©´ ì‚¬ìš©
                return clothing_image.split()[-1]
            
            # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ê¸°ë°˜ ë§ˆìŠ¤í¬
            gray = clothing_image.convert('L')
            
            # ì ì‘ì  ì„ê³„ê°’
            cv_gray = np.array(gray)
            mask = cv2.adaptiveThreshold(
                cv_gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 11, 2
            )
            
            # í˜•íƒœí•™ì  ì—°ì‚°ìœ¼ë¡œ ì •ì œ
            kernel = np.ones((3, 3), np.uint8)
            mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)
            mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)
            
            # ê°€ì¥ìë¦¬ ë¶€ë“œëŸ½ê²Œ
            mask = cv2.GaussianBlur(mask, (3, 3), 0)
            
            return Image.fromarray(mask, 'L')
            
        except Exception as e:
            logger.warning(f"ì •ë°€ ë§ˆìŠ¤í¬ ìƒì„± ì‹¤íŒ¨: {e}")
            # ê¸°ë³¸ ë§ˆìŠ¤í¬
            return Image.new('L', clothing_image.size, 255)
    
    def _apply_natural_blending(self, image: Image.Image, x: int, y: int, width: int, height: int) -> Image.Image:
        """ìì—°ìŠ¤ëŸ¬ìš´ ë¸”ë Œë”©"""
        
        try:
            # ì˜ë¥˜ ì˜ì—­ì— ë¯¸ì„¸í•œ ê·¸ë¦¼ì ì¶”ê°€
            shadow_overlay = Image.new('RGBA', image.size, (0, 0, 0, 0))
            shadow_draw = ImageDraw.Draw(shadow_overlay)
            
            # ê·¸ë¦¼ì ì˜ì—­
            shadow_x = x + 2
            shadow_y = y + 2
            shadow_draw.rectangle(
                [shadow_x, shadow_y, shadow_x + width, shadow_y + height],
                fill=(0, 0, 0, 15)  # ë§¤ìš° ì—°í•œ ê·¸ë¦¼ì
            )
            
            # ê·¸ë¦¼ì ë¸”ëŸ¬
            shadow_overlay = shadow_overlay.filter(ImageFilter.GaussianBlur(2))
            
            # í•©ì„±
            image_rgba = image.convert('RGBA')
            blended = Image.alpha_composite(image_rgba, shadow_overlay)
            
            return blended.convert('RGB')
            
        except Exception as e:
            logger.warning(f"ìì—°ìŠ¤ëŸ¬ìš´ ë¸”ë Œë”© ì‹¤íŒ¨: {e}")
            return image
    
    def _basic_clothing_fit(self, person_image: Image.Image, clothing_image: Image.Image) -> Image.Image:
        """ê¸°ë³¸ ì˜ë¥˜ í”¼íŒ… (ì•ˆì „ì¥ì¹˜)"""
        
        try:
            # ê¸°ë³¸ ìœ„ì¹˜ì— ì˜ë¥˜ ë°°ì¹˜
            clothing_resized = clothing_image.resize((200, 200))
            
            if clothing_resized.mode == 'RGBA':
                person_image.paste(clothing_resized, (150, 100), clothing_resized)
            else:
                person_image.paste(clothing_resized, (150, 100))
            
            return person_image
            
        except Exception as e:
            logger.error(f"âŒ ê¸°ë³¸ í”¼íŒ…ë„ ì‹¤íŒ¨: {e}")
            return person_image
    
    def _enhance_result_quality(self, result_image: Image.Image) -> Image.Image:
        """ê²°ê³¼ í’ˆì§ˆ í–¥ìƒ"""
        
        try:
            # 1. ì„ ëª…ë„ í–¥ìƒ
            sharpness_enhancer = ImageEnhance.Sharpness(result_image)
            enhanced = sharpness_enhancer.enhance(1.1)
            
            # 2. ëŒ€ë¹„ ì¡°ì •
            contrast_enhancer = ImageEnhance.Contrast(enhanced)
            enhanced = contrast_enhancer.enhance(1.05)
            
            # 3. ë…¸ì´ì¦ˆ ì œê±°
            cv_image = cv2.cvtColor(np.array(enhanced), cv2.COLOR_RGB2BGR)
            denoised = cv2.bilateralFilter(cv_image, 9, 75, 75)
            enhanced = Image.fromarray(cv2.cvtColor(denoised, cv2.COLOR_BGR2RGB))
            
            # 4. AI ì²˜ë¦¬ í‘œì‹œ
            draw = ImageDraw.Draw(enhanced)
            draw.text((10, enhanced.height - 30), "Real AI Processing", fill='lime')
            
            return enhanced
            
        except Exception as e:
            logger.warning(f"í’ˆì§ˆ í–¥ìƒ ì‹¤íŒ¨: {e}")
            return result_image
    
    def _create_fallback_result(self, person_image: Image.Image, clothing_image: Image.Image) -> Image.Image:
        """ì‹¤íŒ¨ì‹œ ê¸°ë³¸ ê²°ê³¼"""
        
        result = person_image.copy()
        
        try:
            clothing_small = clothing_image.resize((150, 150))
            result.paste(clothing_small, (175, 125))
            
            draw = ImageDraw.Draw(result)
            draw.text((10, 10), "AI Processing Failed - Basic Mode", fill='red')
            
        except:
            pass
        
        return result

# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
real_working_ai_fitter = RealWorkingAIFitter()