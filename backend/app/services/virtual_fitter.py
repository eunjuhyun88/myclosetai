# backend/app/services/virtual_fitter.py
"""
ğŸ”¥ ì‹¤ì œ ë™ì‘í•˜ëŠ” MyCloset AI ê°€ìƒ í”¼íŒ… ì‹œìŠ¤í…œ
M3 Max 128GB ë©”ëª¨ë¦¬ ìµœì í™” ë²„ì „
"""

import torch
from PIL import Image, ImageDraw, ImageFont, ImageFilter, ImageOps
import numpy as np
import asyncio
import cv2
import time
import os
import base64
import io
import mediapipe as mp
from typing import Optional, Dict, Any, Tuple, List
import logging
import uuid
from datetime import datetime
import json

from app.core.gpu_config import gpu_config, DEVICE, MODEL_CONFIG

logger = logging.getLogger(__name__)

class RealVirtualFitter:
    """
    ğŸ½ ì‹¤ì œ ë™ì‘í•˜ëŠ” MyCloset AI ê°€ìƒ í”¼íŒ… ì‹œìŠ¤í…œ
    
    M3 Max 128GB ë©”ëª¨ë¦¬ë¥¼ í™œìš©í•œ ê³ ì„±ëŠ¥ ë²„ì „
    - MediaPipeë¥¼ ì´ìš©í•œ ì‹¤ì œ ì¸ì²´ ë¶„ì„
    - OpenCV ê¸°ë°˜ ì‹¤ì œ ì´ë¯¸ì§€ ì²˜ë¦¬
    - Metal Performance Shaders í™œìš©
    """
    
    def __init__(self):
        self.device = DEVICE
        self.model_config = MODEL_CONFIG
        self.sessions = {}  # ì„¸ì…˜ ê´€ë¦¬
        
        # MediaPipe ì´ˆê¸°í™”
        self.mp_pose = mp.solutions.pose
        self.mp_drawing = mp.solutions.drawing_utils
        self.mp_selfie_segmentation = mp.solutions.selfie_segmentation
        
        # ëª¨ë¸ ì´ˆê¸°í™”
        self.pose_detector = None
        self.segmentation_model = None
        self.models_loaded = False
        
        # ì„±ëŠ¥ ì„¤ì • (M3 Max ìµœì í™”)
        self.max_image_size = (1024, 1024)  # M3 MaxëŠ” ë” í° ì´ë¯¸ì§€ ì²˜ë¦¬ ê°€ëŠ¥
        self.processing_timeout = 60
        
        logger.info(f"ğŸš€ RealVirtualFitter ì´ˆê¸°í™” ì™„ë£Œ - ë””ë°”ì´ìŠ¤: {self.device}")
        
    async def initialize_models(self):
        """ì‹¤ì œ AI ëª¨ë¸ ì´ˆê¸°í™”"""
        try:
            logger.info("ğŸ¤– ì‹¤ì œ AI ëª¨ë¸ë“¤ ì´ˆê¸°í™” ì¤‘...")
            
            # MediaPipe Pose ì´ˆê¸°í™”
            self.pose_detector = self.mp_pose.Pose(
                static_image_mode=True,
                model_complexity=2,  # ìµœê³  í’ˆì§ˆ
                enable_segmentation=True,
                min_detection_confidence=0.7,
                min_tracking_confidence=0.5
            )
            
            # MediaPipe Selfie Segmentation ì´ˆê¸°í™”
            self.segmentation_model = self.mp_selfie_segmentation.SelfieSegmentation(
                model_selection=1  # ê³ ì •ë°€ ëª¨ë¸
            )
            
            # GPU ë©”ëª¨ë¦¬ ìµœì í™”
            gpu_config.optimize_memory()
            
            self.models_loaded = True
            logger.info("âœ… ì‹¤ì œ AI ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ")
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.models_loaded = False
            return False
    
    def _preprocess_image(self, image: Image.Image) -> Image.Image:
        """ì´ë¯¸ì§€ ì „ì²˜ë¦¬ (M3 Max ìµœì í™”)"""
        try:
            # RGB ëª¨ë“œë¡œ ë³€í™˜
            if image.mode != 'RGB':
                image = image.convert('RGB')
            
            # ì´ë¯¸ì§€ ë°©í–¥ ìë™ ìˆ˜ì •
            image = ImageOps.exif_transpose(image)
            
            # í¬ê¸° ì¡°ì • (M3 MaxëŠ” ë” í° ì´ë¯¸ì§€ ì²˜ë¦¬ ê°€ëŠ¥)
            width, height = image.size
            max_width, max_height = self.max_image_size
            
            if width > max_width or height > max_height:
                ratio = min(max_width / width, max_height / height)
                new_size = (int(width * ratio), int(height * ratio))
                image = image.resize(new_size, Image.Resampling.LANCZOS)
                logger.info(f"ì´ë¯¸ì§€ í¬ê¸° ì¡°ì •: {(width, height)} -> {new_size}")
            
            # ì´ë¯¸ì§€ í’ˆì§ˆ í–¥ìƒ
            image = self._enhance_image_quality(image)
            
            return image
            
        except Exception as e:
            logger.error(f"ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return image
    
    def _enhance_image_quality(self, image: Image.Image) -> Image.Image:
        """ì´ë¯¸ì§€ í’ˆì§ˆ í–¥ìƒ"""
        try:
            # ìƒ¤í”„ë‹ í•„í„° ì ìš©
            enhanced = image.filter(ImageFilter.UnsharpMask(radius=1, percent=100, threshold=3))
            
            # ìƒ‰ìƒ ë³´ì •
            enhanced = ImageOps.autocontrast(enhanced, cutoff=1)
            
            return enhanced
            
        except Exception as e:
            logger.warning(f"ì´ë¯¸ì§€ í’ˆì§ˆ í–¥ìƒ ì‹¤íŒ¨: {e}")
            return image
    
    async def analyze_human_pose(self, person_image: Image.Image) -> Dict[str, Any]:
        """ì‹¤ì œ MediaPipeë¥¼ ì‚¬ìš©í•œ ì¸ì²´ ë¶„ì„"""
        try:
            if not self.models_loaded:
                await self.initialize_models()
            
            logger.info("ğŸ‘¤ ì‹¤ì œ MediaPipe ì¸ì²´ ë¶„ì„ ì‹œì‘...")
            
            # PILì„ OpenCV í˜•ì‹ìœ¼ë¡œ ë³€í™˜
            cv_image = cv2.cvtColor(np.array(person_image), cv2.COLOR_RGB2BGR)
            
            # MediaPipeë¡œ í¬ì¦ˆ ê°ì§€
            results = self.pose_detector.process(cv2.cvtColor(cv_image, cv2.COLOR_BGR2RGB))
            
            analysis = {
                "pose_detected": False,
                "landmarks": [],
                "segmentation_mask": None,
                "body_measurements": {},
                "confidence": 0.0
            }
            
            if results.pose_landmarks:
                analysis["pose_detected"] = True
                analysis["confidence"] = 0.9
                
                # ëœë“œë§ˆí¬ ì¢Œí‘œ ì¶”ì¶œ
                landmarks = []
                for idx, landmark in enumerate(results.pose_landmarks.landmark):
                    landmarks.append({
                        "id": idx,
                        "x": landmark.x,
                        "y": landmark.y,
                        "z": landmark.z,
                        "visibility": landmark.visibility
                    })
                
                analysis["landmarks"] = landmarks
                
                # ì‹ ì²´ ì¸¡ì •ê°’ ê³„ì‚°
                analysis["body_measurements"] = self._calculate_body_measurements(
                    landmarks, person_image.size
                )
                
                # ì„¸ê·¸ë©˜í…Œì´ì…˜ ë§ˆìŠ¤í¬ ìƒì„±
                if results.segmentation_mask is not None:
                    analysis["segmentation_mask"] = results.segmentation_mask
                
                logger.info("âœ… MediaPipe ì¸ì²´ ë¶„ì„ ì™„ë£Œ")
            else:
                logger.warning("âš ï¸ ì¸ì²´ í¬ì¦ˆ ê°ì§€ ì‹¤íŒ¨")
            
            return analysis
            
        except Exception as e:
            logger.error(f"âŒ ì¸ì²´ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {"pose_detected": False, "confidence": 0.0}
    
    def _calculate_body_measurements(self, landmarks: List[Dict], image_size: Tuple[int, int]) -> Dict[str, Any]:
        """ëœë“œë§ˆí¬ë¥¼ ì´ìš©í•œ ì‹¤ì œ ì‹ ì²´ ì¸¡ì •"""
        try:
            width, height = image_size
            measurements = {}
            
            # ì£¼ìš” í¬ì¸íŠ¸ë“¤ (MediaPipe í¬ì¦ˆ ëœë“œë§ˆí¬ ì¸ë±ìŠ¤)
            NOSE = 0
            LEFT_SHOULDER = 11
            RIGHT_SHOULDER = 12
            LEFT_ELBOW = 13
            RIGHT_ELBOW = 14
            LEFT_WRIST = 15
            RIGHT_WRIST = 16
            LEFT_HIP = 23
            RIGHT_HIP = 24
            LEFT_KNEE = 25
            RIGHT_KNEE = 26
            LEFT_ANKLE = 27
            RIGHT_ANKLE = 28
            
            if len(landmarks) >= 33:  # MediaPipeëŠ” 33ê°œ í¬ì¸íŠ¸
                # ì–´ê¹¨ ë„ˆë¹„ ê³„ì‚°
                left_shoulder = landmarks[LEFT_SHOULDER]
                right_shoulder = landmarks[RIGHT_SHOULDER]
                shoulder_width = abs(left_shoulder["x"] - right_shoulder["x"]) * width
                
                # ëª¸í†µ ê¸¸ì´ ê³„ì‚°
                torso_length = abs((left_shoulder["y"] + right_shoulder["y"]) / 2 - 
                                 (landmarks[LEFT_HIP]["y"] + landmarks[RIGHT_HIP]["y"]) / 2) * height
                
                # íŒ” ê¸¸ì´ ê³„ì‚°
                arm_length = (
                    np.sqrt((left_shoulder["x"] - landmarks[LEFT_WRIST]["x"])**2 + 
                           (left_shoulder["y"] - landmarks[LEFT_WRIST]["y"])**2) * 
                    max(width, height)
                )
                
                # ë‹¤ë¦¬ ê¸¸ì´ ê³„ì‚°
                leg_length = abs(landmarks[LEFT_HIP]["y"] - landmarks[LEFT_ANKLE]["y"]) * height
                
                measurements = {
                    "shoulder_width": shoulder_width,
                    "torso_length": torso_length,
                    "arm_length": arm_length,
                    "leg_length": leg_length,
                    "body_height_ratio": leg_length / height if height > 0 else 0.5,
                    "shoulder_center": {
                        "x": (left_shoulder["x"] + right_shoulder["x"]) / 2 * width,
                        "y": (left_shoulder["y"] + right_shoulder["y"]) / 2 * height
                    }
                }
                
                logger.info(f"ğŸ“ ì‹ ì²´ ì¸¡ì • ì™„ë£Œ: ì–´ê¹¨ë„ˆë¹„={shoulder_width:.1f}px")
            
            return measurements
            
        except Exception as e:
            logger.error(f"ì‹ ì²´ ì¸¡ì • ì‹¤íŒ¨: {e}")
            return {}
    
    async def segment_clothing(self, clothing_image: Image.Image) -> Dict[str, Any]:
        """ì‹¤ì œ ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜"""
        try:
            logger.info("ğŸ‘• ì˜ë¥˜ ë¶„ì„ ë° ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‹œì‘...")
            
            # OpenCVë¡œ ë³€í™˜
            cv_image = cv2.cvtColor(np.array(clothing_image), cv2.COLOR_RGB2BGR)
            
            # ë°°ê²½ ì œê±° (GrabCut ì•Œê³ ë¦¬ì¦˜ ì‚¬ìš©)
            mask = np.zeros(cv_image.shape[:2], np.uint8)
            
            # ì „ê²½/ë°°ê²½ ëª¨ë¸ì„ ìœ„í•œ ë°°ì—´
            bgd_model = np.zeros((1, 65), np.float64)
            fgd_model = np.zeros((1, 65), np.float64)
            
            # ì´ë¯¸ì§€ ì¤‘ì•™ ì˜ì—­ì„ ì „ê²½ìœ¼ë¡œ ê°€ì •
            height, width = cv_image.shape[:2]
            rect = (width//8, height//8, width*3//4, height*3//4)
            
            # GrabCut ì‹¤í–‰
            cv2.grabCut(cv_image, mask, rect, bgd_model, fgd_model, 5, cv2.GC_INIT_WITH_RECT)
            
            # ë§ˆìŠ¤í¬ í›„ì²˜ë¦¬
            mask2 = np.where((mask == 2) | (mask == 0), 0, 1).astype('uint8')
            
            # ì˜ë¥˜ ì˜ì—­ë§Œ ì¶”ì¶œ
            clothing_masked = cv_image * mask2[:, :, np.newaxis]
            
            # PILë¡œ ë³€í™˜
            clothing_segmented = Image.fromarray(cv2.cvtColor(clothing_masked, cv2.COLOR_BGR2RGB))
            
            # ì˜ë¥˜ íƒ€ì… ë¶„ì„
            clothing_type = self._analyze_clothing_type(clothing_image)
            
            # ìƒ‰ìƒ ë¶„ì„
            dominant_colors = self._extract_dominant_colors(clothing_image)
            
            analysis = {
                "segmented_clothing": clothing_segmented,
                "mask": mask2,
                "clothing_type": clothing_type,
                "dominant_colors": dominant_colors,
                "confidence": 0.85
            }
            
            logger.info(f"âœ… ì˜ë¥˜ ë¶„ì„ ì™„ë£Œ: {clothing_type}")
            return analysis
            
        except Exception as e:
            logger.error(f"âŒ ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‹¤íŒ¨: {e}")
            return {
                "segmented_clothing": clothing_image,
                "clothing_type": "unknown",
                "confidence": 0.0
            }
    
    def _analyze_clothing_type(self, clothing_image: Image.Image) -> str:
        """ì˜ë¥˜ íƒ€ì… ë¶„ì„ (í˜•íƒœ ê¸°ë°˜)"""
        try:
            width, height = clothing_image.size
            aspect_ratio = height / width
            
            # ì˜ë¥˜ íƒ€ì… ë¶„ë¥˜
            if aspect_ratio > 1.8:
                return "dress"
            elif aspect_ratio > 1.4:
                return "pants"
            elif aspect_ratio < 0.7:
                return "jacket"
            elif aspect_ratio < 1.2:
                return "shirt"
            else:
                return "top"
                
        except Exception as e:
            logger.warning(f"ì˜ë¥˜ íƒ€ì… ë¶„ì„ ì‹¤íŒ¨: {e}")
            return "unknown"
    
    def _extract_dominant_colors(self, image: Image.Image, k: int = 3) -> List[Tuple[int, int, int]]:
        """ì£¼ìš” ìƒ‰ìƒ ì¶”ì¶œ (K-means í´ëŸ¬ìŠ¤í„°ë§)"""
        try:
            # ì´ë¯¸ì§€ë¥¼ NumPy ë°°ì—´ë¡œ ë³€í™˜
            img_array = np.array(image)
            img_array = img_array.reshape((-1, 3))
            
            # K-means í´ëŸ¬ìŠ¤í„°ë§
            from sklearn.cluster import KMeans
            
            kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)
            kmeans.fit(img_array)
            
            # ì¤‘ì‹¬ì ë“¤ì„ ìƒ‰ìƒìœ¼ë¡œ ë°˜í™˜
            colors = kmeans.cluster_centers_.astype(int)
            
            return [tuple(color) for color in colors]
            
        except Exception as e:
            logger.warning(f"ìƒ‰ìƒ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return [(128, 128, 128)]  # ê¸°ë³¸ íšŒìƒ‰
    
    async def real_virtual_fitting(
        self,
        person_image: Image.Image,
        clothing_image: Image.Image,
        height: float,
        weight: float,
        session_id: Optional[str] = None
    ) -> Dict[str, Any]:
        """ğŸ”¥ ì‹¤ì œ ê°€ìƒ í”¼íŒ… ì‹¤í–‰"""
        
        if not session_id:
            session_id = str(uuid.uuid4())
        
        start_time = time.time()
        
        logger.info(f"ğŸ”¥ ì‹¤ì œ ê°€ìƒ í”¼íŒ… ì‹œì‘ (ì„¸ì…˜: {session_id})")
        
        # ì„¸ì…˜ ì •ë³´ ì €ì¥
        self.sessions[session_id] = {
            "start_time": start_time,
            "status": "processing",
            "steps": []
        }
        
        try:
            # ì´ë¯¸ì§€ ì „ì²˜ë¦¬
            person_processed = self._preprocess_image(person_image)
            clothing_processed = self._preprocess_image(clothing_image)
            
            # 1ë‹¨ê³„: ì¸ì²´ ë¶„ì„
            self._update_session_step(session_id, "ì¸ì²´ ë¶„ì„", "processing")
            body_analysis = await self.analyze_human_pose(person_processed)
            self._update_session_step(session_id, "ì¸ì²´ ë¶„ì„", "completed")
            
            if not body_analysis["pose_detected"]:
                logger.warning("âš ï¸ ì¸ì²´ í¬ì¦ˆë¥¼ ê°ì§€í•  ìˆ˜ ì—†ì–´ ê¸°ë³¸ ëª¨ë“œë¡œ ì „í™˜")
                result = await self._fallback_fitting(person_processed, clothing_processed)
                return self._create_response(result, session_id, start_time, fallback=True)
            
            # 2ë‹¨ê³„: ì˜ë¥˜ ë¶„ì„
            self._update_session_step(session_id, "ì˜ë¥˜ ë¶„ì„", "processing")
            clothing_analysis = await self.segment_clothing(clothing_processed)
            self._update_session_step(session_id, "ì˜ë¥˜ ë¶„ì„", "completed")
            
            # 3ë‹¨ê³„: ê°€ìƒ í”¼íŒ… ì‹¤í–‰
            self._update_session_step(session_id, "ê°€ìƒ í”¼íŒ…", "processing")
            fitted_result = await self._execute_fitting(
                person_processed, 
                clothing_analysis, 
                body_analysis,
                height,
                weight
            )
            self._update_session_step(session_id, "ê°€ìƒ í”¼íŒ…", "completed")
            
            # 4ë‹¨ê³„: í›„ì²˜ë¦¬
            self._update_session_step(session_id, "í’ˆì§ˆ í–¥ìƒ", "processing")
            final_result = self._post_process_result(fitted_result)
            self._update_session_step(session_id, "í’ˆì§ˆ í–¥ìƒ", "completed")
            
            # ê²°ê³¼ ë°˜í™˜
            return self._create_response(final_result, session_id, start_time)
            
        except Exception as e:
            logger.error(f"âŒ ê°€ìƒ í”¼íŒ… ì‹¤íŒ¨: {e}")
            self._update_session_step(session_id, "ì˜¤ë¥˜", "error")
            
            # ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ëª¨ë“œ
            fallback_result = await self._fallback_fitting(person_image, clothing_image)
            return self._create_response(fallback_result, session_id, start_time, error=str(e))
    
    def _update_session_step(self, session_id: str, step_name: str, status: str):
        """ì„¸ì…˜ ë‹¨ê³„ ì—…ë°ì´íŠ¸"""
        if session_id in self.sessions:
            self.sessions[session_id]["steps"].append({
                "name": step_name,
                "status": status,
                "timestamp": time.time()
            })
    
    async def _execute_fitting(
        self,
        person_image: Image.Image,
        clothing_analysis: Dict[str, Any],
        body_analysis: Dict[str, Any],
        height: float,
        weight: float
    ) -> Image.Image:
        """ì‹¤ì œ ê°€ìƒ í”¼íŒ… ì‹¤í–‰"""
        try:
            result = person_image.copy()
            clothing_image = clothing_analysis["segmented_clothing"]
            clothing_type = clothing_analysis["clothing_type"]
            
            # ì‹ ì²´ ì¸¡ì •ê°’ ê°€ì ¸ì˜¤ê¸°
            measurements = body_analysis.get("body_measurements", {})
            
            if measurements:
                # ì •í™•í•œ ìœ„ì¹˜ ê³„ì‚°
                fit_position = self._calculate_precise_fit_position(
                    person_image.size,
                    measurements,
                    clothing_type,
                    height,
                    weight
                )
                
                # ì˜ë¥˜ í¬ê¸° ì¡°ì •
                fitted_clothing = self._resize_clothing_to_body(
                    clothing_image,
                    fit_position,
                    measurements
                )
                
                # ìì—°ìŠ¤ëŸ¬ìš´ í•©ì„±
                result = self._blend_clothing_naturally(
                    result,
                    fitted_clothing,
                    fit_position,
                    body_analysis
                )
                
            else:
                # ì¸¡ì •ê°’ì´ ì—†ìœ¼ë©´ ê¸°ë³¸ ë°©ì‹
                result = await self._fallback_fitting(person_image, clothing_image)
            
            logger.info("âœ… ê°€ìƒ í”¼íŒ… ì‹¤í–‰ ì™„ë£Œ")
            return result
            
        except Exception as e:
            logger.error(f"âŒ ê°€ìƒ í”¼íŒ… ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            return person_image
    
    def _calculate_precise_fit_position(
        self,
        image_size: Tuple[int, int],
        measurements: Dict[str, Any],
        clothing_type: str,
        height: float,
        weight: float
    ) -> Dict[str, Any]:
        """ì •ë°€í•œ í”¼íŒ… ìœ„ì¹˜ ê³„ì‚°"""
        try:
            width, height = image_size
            
            # BMI ê³„ì‚°
            bmi = weight / ((height / 100) ** 2)
            
            # ì–´ê¹¨ ì¤‘ì‹¬ì  ê¸°ì¤€
            shoulder_center = measurements.get("shoulder_center", {"x": width//2, "y": height//4})
            shoulder_width = measurements.get("shoulder_width", width * 0.3)
            torso_length = measurements.get("torso_length", height * 0.4)
            
            # ì˜ë¥˜ íƒ€ì…ë³„ ìœ„ì¹˜ ì¡°ì •
            if clothing_type in ["shirt", "top", "jacket"]:
                # ìƒì˜
                clothing_width = int(shoulder_width * 1.2)  # ì–´ê¹¨ë³´ë‹¤ ì•½ê°„ ë„“ê²Œ
                clothing_height = int(torso_length * 0.8)   # ëª¸í†µ ê¸¸ì´ì˜ 80%
                
                x = int(shoulder_center["x"] - clothing_width // 2)
                y = int(shoulder_center["y"] - clothing_height * 0.1)  # ì–´ê¹¨ ì•½ê°„ ì•„ë˜
                
            elif clothing_type == "dress":
                # ì›í”¼ìŠ¤
                clothing_width = int(shoulder_width * 1.3)
                clothing_height = int(torso_length * 1.8)
                
                x = int(shoulder_center["x"] - clothing_width // 2)
                y = int(shoulder_center["y"])
                
            elif clothing_type == "pants":
                # í•˜ì˜
                hip_y = shoulder_center["y"] + torso_length
                clothing_width = int(shoulder_width * 1.1)
                clothing_height = int(measurements.get("leg_length", height * 0.5))
                
                x = int(shoulder_center["x"] - clothing_width // 2)
                y = int(hip_y)
                
            else:
                # ê¸°ë³¸ê°’
                clothing_width = int(shoulder_width * 1.2)
                clothing_height = int(torso_length)
                x = int(shoulder_center["x"] - clothing_width // 2)
                y = int(shoulder_center["y"])
            
            # ê²½ê³„ ê²€ì‚¬
            x = max(0, min(x, width - clothing_width))
            y = max(0, min(y, height - clothing_height))
            
            return {
                "x": x,
                "y": y,
                "width": clothing_width,
                "height": clothing_height,
                "clothing_type": clothing_type,
                "bmi": bmi
            }
            
        except Exception as e:
            logger.error(f"ìœ„ì¹˜ ê³„ì‚° ì‹¤íŒ¨: {e}")
            # ê¸°ë³¸ ìœ„ì¹˜ ë°˜í™˜
            width, height = image_size
            return {
                "x": width // 4,
                "y": height // 4,
                "width": width // 2,
                "height": height // 2,
                "clothing_type": clothing_type,
                "bmi": 22.0
            }
    
    def _resize_clothing_to_body(
        self,
        clothing_image: Image.Image,
        fit_position: Dict[str, Any],
        measurements: Dict[str, Any]
    ) -> Image.Image:
        """ì‹ ì²´ì— ë§ê²Œ ì˜ë¥˜ í¬ê¸° ì¡°ì •"""
        try:
            # ê¸°ë³¸ ë¦¬ì‚¬ì´ì¦ˆ
            resized = clothing_image.resize(
                (fit_position["width"], fit_position["height"]),
                Image.Resampling.LANCZOS
            )
            
            # ì²´í˜•ì— ë”°ë¥¸ ì¶”ê°€ ì¡°ì •
            bmi = fit_position.get("bmi", 22.0)
            
            if bmi < 18.5:  # ë§ˆë¥¸ ì²´í˜•
                # ì„¸ë¡œë¡œ ì•½ê°„ ëŠ˜ë¦¬ê¸°
                new_height = int(fit_position["height"] * 1.05)
                new_width = int(fit_position["width"] * 0.95)
                resized = resized.resize((new_width, new_height), Image.Resampling.LANCZOS)
                
            elif bmi > 25:  # í†µí†µí•œ ì²´í˜•
                # ê°€ë¡œë¡œ ì•½ê°„ ëŠ˜ë¦¬ê¸°
                new_width = int(fit_position["width"] * 1.1)
                new_height = int(fit_position["height"] * 0.95)
                resized = resized.resize((new_width, new_height), Image.Resampling.LANCZOS)
            
            # ìì—°ìŠ¤ëŸ¬ìš´ ê³¡ë¥  íš¨ê³¼ ì¶”ê°€
            resized = self._add_fabric_drape(resized)
            
            return resized
            
        except Exception as e:
            logger.error(f"ì˜ë¥˜ í¬ê¸° ì¡°ì • ì‹¤íŒ¨: {e}")
            return clothing_image.resize(
                (fit_position["width"], fit_position["height"]),
                Image.Resampling.LANCZOS
            )
    
    def _add_fabric_drape(self, clothing_image: Image.Image) -> Image.Image:
        """ì²œì˜ ìì—°ìŠ¤ëŸ¬ìš´ ë“œë ˆì´í”„ íš¨ê³¼"""
        try:
            # OpenCVë¡œ ë³€í™˜
            cv_image = cv2.cvtColor(np.array(clothing_image), cv2.COLOR_RGB2BGR)
            
            # ë¯¸ì„¸í•œ ì›¨ì´ë¸Œ íš¨ê³¼
            rows, cols = cv_image.shape[:2]
            
            # ì‚¬ì¸íŒŒë¥¼ ì´ìš©í•œ ìì—°ìŠ¤ëŸ¬ìš´ ì™œê³¡
            map_x = np.zeros((rows, cols), np.float32)
            map_y = np.zeros((rows, cols), np.float32)
            
            for i in range(rows):
                for j in range(cols):
                    # ë¯¸ì„¸í•œ ì›¨ì´ë¸Œ íš¨ê³¼
                    offset_x = 2 * np.sin(2 * np.pi * i / 180)
                    offset_y = 1 * np.sin(2 * np.pi * j / 100)
                    
                    map_x[i, j] = j + offset_x
                    map_y[i, j] = i + offset_y
            
            # ì™œê³¡ ì ìš©
            draped = cv2.remap(cv_image, map_x, map_y, cv2.INTER_LINEAR)
            
            # PILë¡œ ë³€í™˜
            return Image.fromarray(cv2.cvtColor(draped, cv2.COLOR_BGR2RGB))
            
        except Exception as e:
            logger.warning(f"ë“œë ˆì´í”„ íš¨ê³¼ ì‹¤íŒ¨: {e}")
            return clothing_image
    
    def _blend_clothing_naturally(
        self,
        person_image: Image.Image,
        clothing_image: Image.Image,
        fit_position: Dict[str, Any],
        body_analysis: Dict[str, Any]
    ) -> Image.Image:
        """ìì—°ìŠ¤ëŸ¬ìš´ ì˜ë¥˜ í•©ì„±"""
        try:
            result = person_image.copy()
            
            # ê·¸ë¦¼ì íš¨ê³¼ ë¨¼ì € ì¶”ê°€
            shadow = self._create_realistic_shadow(clothing_image, fit_position)
            if shadow:
                try:
                    result.paste(shadow, 
                               (fit_position["x"] + 2, fit_position["y"] + 2), 
                               shadow)
                except:
                    pass
            
            # ì˜ë¥˜ ì•ŒíŒŒ ë§ˆìŠ¤í¬ ìƒì„±
            alpha_mask = self._create_alpha_mask(clothing_image)
            
            # ì˜ë¥˜ í•©ì„±
            try:
                if clothing_image.mode == 'RGBA':
                    result.paste(clothing_image, 
                               (fit_position["x"], fit_position["y"]), 
                               clothing_image)
                else:
                    result.paste(clothing_image, 
                               (fit_position["x"], fit_position["y"]), 
                               alpha_mask)
            except Exception as paste_error:
                logger.warning(f"ë§ˆìŠ¤í¬ ë¶™ì—¬ë„£ê¸° ì‹¤íŒ¨: {paste_error}")
                result.paste(clothing_image, (fit_position["x"], fit_position["y"]))
            
            return result
            
        except Exception as e:
            logger.error(f"ì˜ë¥˜ í•©ì„± ì‹¤íŒ¨: {e}")
            return person_image
    
    def _create_alpha_mask(self, clothing_image: Image.Image) -> Image.Image:
        """ì•ŒíŒŒ ë§ˆìŠ¤í¬ ìƒì„±"""
        try:
            # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ë¡œ ë³€í™˜
            gray = clothing_image.convert('L')
            
            # ê°€ì¥ìë¦¬ í˜ì´ë“œ íš¨ê³¼
            mask = gray.copy()
            width, height = mask.size
            
            # ê°€ì¥ìë¦¬ë¥¼ ë¶€ë“œëŸ½ê²Œ
            fade_pixels = min(width, height) // 20
            
            pixels = mask.load()
            for y in range(height):
                for x in range(width):
                    edge_dist = min(x, y, width-x-1, height-y-1)
                    if edge_dist < fade_pixels:
                        alpha = int(255 * (edge_dist / fade_pixels))
                        current_alpha = pixels[x, y]
                        pixels[x, y] = min(current_alpha, alpha)
            
            return mask
            
        except Exception as e:
            logger.warning(f"ì•ŒíŒŒ ë§ˆìŠ¤í¬ ìƒì„± ì‹¤íŒ¨: {e}")
            return clothing_image.convert('L')
    
    def _create_realistic_shadow(self, clothing_image: Image.Image, fit_position: Dict[str, Any]) -> Optional[Image.Image]:
        """í˜„ì‹¤ì ì¸ ê·¸ë¦¼ì íš¨ê³¼ ìƒì„±"""
        try:
            # ê·¸ë¦¼ììš© ì´ë¯¸ì§€ ìƒì„±
            shadow = Image.new('RGBA', clothing_image.size, (0, 0, 0, 0))
            
            # ì˜ë¥˜ í˜•íƒœë¥¼ ë”°ë¥¸ ê·¸ë¦¼ì ìƒì„±
            gray = clothing_image.convert('L')
            
            # ê·¸ë¦¼ì ë°ì´í„° ìƒì„±
            shadow_data = []
            for pixel in gray.getdata():
                if pixel > 50:  # ë°°ê²½ì´ ì•„ë‹Œ ë¶€ë¶„
                    shadow_data.append((0, 0, 0, 80))  # ë°˜íˆ¬ëª… ê²€ì€ìƒ‰
                else:
                    shadow_data.append((0, 0, 0, 0))   # íˆ¬ëª…
            
            shadow.putdata(shadow_data)
            
            # ë¸”ëŸ¬ íš¨ê³¼ë¡œ ë¶€ë“œëŸ¬ìš´ ê·¸ë¦¼ì
            shadow = shadow.filter(ImageFilter.GaussianBlur(radius=3))
            
            return shadow
            
        except Exception as e:
            logger.warning(f"ê·¸ë¦¼ì ìƒì„± ì‹¤íŒ¨: {e}")
            return None
    
    def _post_process_result(self, result_image: Image.Image) -> Image.Image:
        """ê²°ê³¼ ì´ë¯¸ì§€ í›„ì²˜ë¦¬"""
        try:
            # ìƒ‰ìƒ ë³´ì •
            enhanced = ImageOps.autocontrast(result_image, cutoff=0.5)
            
            # ì„ ëª…ë„ í–¥ìƒ
            enhanced = enhanced.filter(ImageFilter.UnsharpMask(radius=1, percent=120, threshold=3))
            
            # ì•½ê°„ì˜ ì±„ë„ í–¥ìƒ
            from PIL import ImageEnhance
            enhancer = ImageEnhance.Color(enhanced)
            enhanced = enhancer.enhance(1.1)
            
            # ì›Œí„°ë§ˆí¬ ì¶”ê°€
            enhanced = self._add_watermark(enhanced, "MyCloset AI - Real Fitting")
            
            return enhanced
            
        except Exception as e:
            logger.warning(f"í›„ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return result_image
    
    def _add_watermark(self, image: Image.Image, text: str) -> Image.Image:
        """ì›Œí„°ë§ˆí¬ ì¶”ê°€"""
        try:
            draw = ImageDraw.Draw(image)
            
            # í°íŠ¸ ì„¤ì •
            try:
                font = ImageFont.truetype("/System/Library/Fonts/Arial.ttf", 14)
            except:
                font = ImageFont.load_default()
            
            # í…ìŠ¤íŠ¸ ìœ„ì¹˜ (ì˜¤ë¥¸ìª½ í•˜ë‹¨)
            text_bbox = draw.textbbox((0, 0), text, font=font)
            text_width = text_bbox[2] - text_bbox[0]
            text_height = text_bbox[3] - text_bbox[1]
            
            x = image.width - text_width - 10
            y = image.height - text_height - 10
            
            # ë°˜íˆ¬ëª… ë°°ê²½
            draw.rectangle([x-3, y-3, x+text_width+3, y+text_height+3], 
                          fill=(0, 0, 0, 100))
            
            # í…ìŠ¤íŠ¸
            draw.text((x, y), text, fill=(255, 255, 255), font=font)
            
            return image
            
        except Exception as e:
            logger.warning(f"ì›Œí„°ë§ˆí¬ ì¶”ê°€ ì‹¤íŒ¨: {e}")
            return image
    
    async def _fallback_fitting(self, person_image: Image.Image, clothing_image: Image.Image) -> Image.Image:
        """ê¸°ë³¸ í”¼íŒ… ëª¨ë“œ (í¬ì¦ˆ ê°ì§€ ì‹¤íŒ¨ ì‹œ)"""
        try:
            logger.info("ğŸ”„ ê¸°ë³¸ í”¼íŒ… ëª¨ë“œ ì‹¤í–‰")
            
            result = person_image.copy()
            
            # ì•ˆì „í•œ í¬ê¸° ê³„ì‚°
            person_width, person_height = person_image.size
            clothing_size = min(person_width, person_height) // 3
            
            # ì˜ë¥˜ í¬ê¸° ì¡°ì •
            clothing_resized = clothing_image.resize((clothing_size, clothing_size), Image.Resampling.LANCZOS)
            
            # ì¤‘ì•™ ìƒë‹¨ì— ë°°ì¹˜
            x = (person_width - clothing_size) // 2
            y = person_height // 4
            
            # ê°„ë‹¨í•œ í•©ì„±
            result.paste(clothing_resized, (x, y))
            
            # ê¸°ë³¸ ëª¨ë“œ í‘œì‹œ
            draw = ImageDraw.Draw(result)
            draw.text((10, 10), "Basic Fitting Mode", fill='white')
            
            return result
            
        except Exception as e:
            logger.error(f"ê¸°ë³¸ í”¼íŒ… ì‹¤íŒ¨: {e}")
            return person_image
    
    def _create_response(
        self,
        result_image: Image.Image,
        session_id: str,
        start_time: float,
        fallback: bool = False,
        error: Optional[str] = None
    ) -> Dict[str, Any]:
        """ì‘ë‹µ ìƒì„±"""
        try:
            # ì´ë¯¸ì§€ë¥¼ base64ë¡œ ì¸ì½”ë”©
            buffer = io.BytesIO()
            result_image.save(buffer, format='JPEG', quality=95)
            img_base64 = base64.b64encode(buffer.getvalue()).decode()
            
            processing_time = time.time() - start_time
            
            # ì„¸ì…˜ ì™„ë£Œ ì²˜ë¦¬
            if session_id in self.sessions:
                self.sessions[session_id]["status"] = "completed"
                self.sessions[session_id]["processing_time"] = processing_time
            
            response = {
                "success": True,
                "session_id": session_id,
                "fitted_image": img_base64,
                "processing_time": processing_time,
                "confidence": 0.9 if not fallback else 0.6,
                "mode": "fallback" if fallback else "advanced",
                "device_info": {
                    "device": self.device,
                    "models_loaded": self.models_loaded
                },
                "steps_completed": len(self.sessions.get(session_id, {}).get("steps", [])),
                "timestamp": datetime.now().isoformat()
            }
            
            if error:
                response["warning"] = f"ì¼ë¶€ ê¸°ëŠ¥ì—ì„œ ì˜¤ë¥˜ ë°œìƒ: {error}"
            
            return response
            
        except Exception as e:
            logger.error(f"ì‘ë‹µ ìƒì„± ì‹¤íŒ¨: {e}")
            return {
                "success": False,
                "error": str(e),
                "session_id": session_id
            }
    
    def get_session_status(self, session_id: str) -> Dict[str, Any]:
        """ì„¸ì…˜ ìƒíƒœ ì¡°íšŒ"""
        if session_id in self.sessions:
            return self.sessions[session_id]
        else:
            return {"error": "Session not found"}
    
    def cleanup_old_sessions(self, max_age_hours: int = 24):
        """ì˜¤ë˜ëœ ì„¸ì…˜ ì •ë¦¬"""
        try:
            current_time = time.time()
            max_age_seconds = max_age_hours * 3600
            
            sessions_to_remove = []
            for session_id, session_data in self.sessions.items():
                if current_time - session_data["start_time"] > max_age_seconds:
                    sessions_to_remove.append(session_id)
            
            for session_id in sessions_to_remove:
                del self.sessions[session_id]
            
            if sessions_to_remove:
                logger.info(f"ğŸ§¹ {len(sessions_to_remove)}ê°œ ì˜¤ë˜ëœ ì„¸ì…˜ ì •ë¦¬ ì™„ë£Œ")
                
        except Exception as e:
            logger.error(f"ì„¸ì…˜ ì •ë¦¬ ì‹¤íŒ¨: {e}")
    
    def get_system_status(self) -> Dict[str, Any]:
        """ì‹œìŠ¤í…œ ìƒíƒœ ë°˜í™˜"""
        return {
            "models_loaded": self.models_loaded,
            "device": self.device,
            "active_sessions": len(self.sessions),
            "max_image_size": self.max_image_size,
            "device_info": gpu_config.get_device_info(),
            "memory_usage": gpu_config.get_model_config()
        }

# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
real_virtual_fitter = RealVirtualFitter()