# backend/app/services/virtual_fitter.py
import torch
from PIL import Image, ImageDraw, ImageFont, ImageFilter
import numpy as np
import asyncio
import cv2
from typing import Optional, Dict, Any
import logging
import os
import random
from datetime import datetime

from app.core.gpu_config import DEVICE, MODEL_CONFIG

logger = logging.getLogger(__name__)

class VirtualFitter:
    def __init__(self):
        self.models_loaded = False
        self.demo_mode = True
        self.device = DEVICE
        self.model_config = MODEL_CONFIG
        
        # ì§€ì›í•˜ëŠ” ëª¨ë¸ íƒ€ì…ë“¤
        self.supported_models = {
            "demo": "ë°ëª¨ ëª¨ë“œ (ë¹ ë¥¸ í•©ì„±)",
            "ootd": "OOTDiffusion (ê³ í’ˆì§ˆ)",
            "viton": "VITON-HD (ì‹¤ì‹œê°„)",
            "acgpn": "ACGPN (ì •ë°€ í”¼íŒ…)"
        }
        
    async def initialize_models(self):
        """AI ëª¨ë¸ ì´ˆê¸°í™”"""
        try:
            logger.info("ğŸ¤– AI ëª¨ë¸ ì´ˆê¸°í™” ì‹œì‘...")
            
            # ëª¨ë¸ ë¡œë”© ì‹œë®¬ë ˆì´ì…˜ (ì‹¤ì œë¡œëŠ” ëª¨ë¸ íŒŒì¼ ë¡œë“œ)
            await asyncio.sleep(2)
            
            # ì‹¤ì œ ëª¨ë¸ë“¤ì´ ì¤€ë¹„ë˜ë©´ ì—¬ê¸°ì„œ ë¡œë“œ
            # self.ootd_model = self._load_ootd_model()
            # self.viton_model = self._load_viton_model()
            
            self.models_loaded = True
            logger.info("âœ… AI ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"âŒ ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.demo_mode = True
            self.models_loaded = False
    
    async def demo_fitting(
        self, 
        person_image: Image.Image, 
        clothing_image: Image.Image,
        height: float,
        weight: float
    ) -> Image.Image:
        """ë°ëª¨ ê°€ìƒ í”¼íŒ… (ê³ ê¸‰ í•©ì„± ë²„ì „)"""
        try:
            logger.info("ğŸ­ ë°ëª¨ ê°€ìƒ í”¼íŒ… ì‹œì‘")
            
            # 1. ê¸°ë³¸ ì„¤ì •
            result = person_image.copy()
            draw = ImageDraw.Draw(result)
            
            # 2. ì˜ë¥˜ ìœ„ì¹˜ ê³„ì‚° (ì²´í˜• ê¸°ë°˜)
            person_width, person_height = person_image.size
            clothing_position = self._calculate_clothing_position(
                person_width, person_height, height, weight
            )
            
            # 3. ì˜ë¥˜ ì´ë¯¸ì§€ ë³€í˜•
            transformed_clothing = self._transform_clothing_for_body(
                clothing_image, clothing_position, height, weight
            )
            
            # 4. ìì—°ìŠ¤ëŸ¬ìš´ í•©ì„±
            result = self._blend_clothing_naturally(
                result, transformed_clothing, clothing_position
            )
            
            # 5. í›„ì²˜ë¦¬ íš¨ê³¼
            result = self._apply_post_effects(result)
            
            # 6. ì›Œí„°ë§ˆí¬ ì¶”ê°€
            result = self._add_watermark(result, "MyCloset AI Demo")
            
            logger.info("âœ… ë°ëª¨ í”¼íŒ… ì™„ë£Œ")
            return result
            
        except Exception as e:
            logger.error(f"âŒ ë°ëª¨ í”¼íŒ… ì˜¤ë¥˜: {e}")
            # ê¸°ë³¸ í•©ì„±ìœ¼ë¡œ ëŒ€ì²´
            return self._basic_overlay(person_image, clothing_image)
    
    def _calculate_clothing_position(
        self, 
        person_width: int, 
        person_height: int, 
        height: float, 
        weight: float
    ) -> Dict[str, Any]:
        """ì²´í˜•ì— ë”°ë¥¸ ì˜ë¥˜ ìœ„ì¹˜ ê³„ì‚°"""
        
        # BMI ê³„ì‚°
        bmi = weight / ((height / 100) ** 2)
        
        # ì²´í˜•ì— ë”°ë¥¸ ìŠ¤ì¼€ì¼ë§
        if bmi < 18.5:
            scale_factor = 0.85  # ë§ˆë¥¸ ì²´í˜•
        elif bmi > 25:
            scale_factor = 1.15  # í†µí†µí•œ ì²´í˜•
        else:
            scale_factor = 1.0   # ë³´í†µ ì²´í˜•
        
        # ì˜ë¥˜ ìœ„ì¹˜ ë° í¬ê¸°
        clothing_width = int(person_width * 0.6 * scale_factor)
        clothing_height = int(person_height * 0.4 * scale_factor)
        
        # ìƒì˜ ìœ„ì¹˜ (ê°€ìŠ´ ë¶€ë¶„)
        x_position = (person_width - clothing_width) // 2
        y_position = int(person_height * 0.25)  # ìƒì²´ 25% ì§€ì 
        
        return {
            "x": x_position,
            "y": y_position,
            "width": clothing_width,
            "height": clothing_height,
            "scale_factor": scale_factor,
            "bmi": bmi
        }
    
    def _transform_clothing_for_body(
        self, 
        clothing_image: Image.Image, 
        position: Dict[str, Any],
        height: float,
        weight: float
    ) -> Image.Image:
        """ì²´í˜•ì— ë§ê²Œ ì˜ë¥˜ ë³€í˜•"""
        
        # 1. ê¸°ë³¸ ë¦¬ì‚¬ì´ì¦ˆ
        resized = clothing_image.resize(
            (position["width"], position["height"]), 
            Image.Resampling.LANCZOS
        )
        
        # 2. ì²´í˜•ì— ë”°ë¥¸ ì™œê³¡ íš¨ê³¼
        bmi = position["bmi"]
        
        if bmi < 18.5:
            # ë§ˆë¥¸ ì²´í˜•: ì•½ê°„ ìˆ˜ì§ìœ¼ë¡œ ëŠ˜ë¦¼
            resized = resized.resize(
                (int(position["width"] * 0.95), int(position["height"] * 1.05)),
                Image.Resampling.LANCZOS
            )
        elif bmi > 25:
            # í†µí†µí•œ ì²´í˜•: ì•½ê°„ ìˆ˜í‰ìœ¼ë¡œ ëŠ˜ë¦¼
            resized = resized.resize(
                (int(position["width"] * 1.05), int(position["height"] * 0.95)),
                Image.Resampling.LANCZOS
            )
        
        # 3. ìì—°ìŠ¤ëŸ¬ìš´ ê³¡ë¥  íš¨ê³¼ ì¶”ê°€
        resized = self._add_fabric_curve(resized)
        
        return resized
    
    def _add_fabric_curve(self, clothing_image: Image.Image) -> Image.Image:
        """ì²œì˜ ìì—°ìŠ¤ëŸ¬ìš´ ê³¡ë¥  íš¨ê³¼"""
        try:
            # OpenCVë¡œ ë³€í™˜
            cv_image = cv2.cvtColor(np.array(clothing_image), cv2.COLOR_RGB2BGR)
            
            # ì•½ê°„ì˜ barrel distortion íš¨ê³¼
            height, width = cv_image.shape[:2]
            
            # ì™œê³¡ ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„±
            map_x = np.zeros((height, width), dtype=np.float32)
            map_y = np.zeros((height, width), dtype=np.float32)
            
            center_x, center_y = width // 2, height // 2
            
            for y in range(height):
                for x in range(width):
                    # ì¤‘ì‹¬ìœ¼ë¡œë¶€í„°ì˜ ê±°ë¦¬
                    dx = x - center_x
                    dy = y - center_y
                    r = np.sqrt(dx*dx + dy*dy)
                    
                    # ì•½í•œ barrel distortion
                    factor = 1 + 0.00002 * r * r
                    
                    map_x[y, x] = center_x + dx * factor
                    map_y[y, x] = center_y + dy * factor
            
            # ì™œê³¡ ì ìš©
            curved = cv2.remap(cv_image, map_x, map_y, cv2.INTER_LINEAR)
            
            # PILë¡œ ë³€í™˜
            return Image.fromarray(cv2.cvtColor(curved, cv2.COLOR_BGR2RGB))
            
        except Exception as e:
            logger.warning(f"ê³¡ë¥  íš¨ê³¼ ì‹¤íŒ¨: {e}")
            return clothing_image
    
    def _blend_clothing_naturally(
        self, 
        person_image: Image.Image, 
        clothing_image: Image.Image, 
        position: Dict[str, Any]
    ) -> Image.Image:
        """ìì—°ìŠ¤ëŸ¬ìš´ ì˜ë¥˜ í•©ì„±"""
        
        # 1. ì•ŒíŒŒ ë¸”ë Œë”©ì„ ìœ„í•œ ë§ˆìŠ¤í¬ ìƒì„±
        mask = self._create_blending_mask(clothing_image)
        
        # 2. ê·¸ë¦¼ì íš¨ê³¼ ì¶”ê°€
        shadow = self._create_shadow_effect(clothing_image)
        person_image.paste(shadow, 
                          (position["x"] + 3, position["y"] + 3), 
                          shadow)
        
        # 3. ì˜ë¥˜ í•©ì„±
        person_image.paste(clothing_image, 
                          (position["x"], position["y"]), 
                          mask)
        
        return person_image
    
    def _create_blending_mask(self, clothing_image: Image.Image) -> Image.Image:
        """ë¸”ë Œë”©ìš© ë§ˆìŠ¤í¬ ìƒì„±"""
        # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ë¡œ ë³€í™˜
        gray = clothing_image.convert('L')
        
        # ê°€ì¥ìë¦¬ í˜ì´ë“œ íš¨ê³¼
        mask = gray.copy()
        
        # ê°€ì¥ìë¦¬ë¥¼ ì ì§„ì ìœ¼ë¡œ íˆ¬ëª…í•˜ê²Œ
        width, height = mask.size
        for y in range(height):
            for x in range(width):
                # ê°€ì¥ìë¦¬ë¡œë¶€í„°ì˜ ê±°ë¦¬
                edge_dist = min(x, y, width-x-1, height-y-1)
                fade_zone = 10  # í˜ì´ë“œ ì˜ì—­ í¬ê¸°
                
                if edge_dist < fade_zone:
                    # ê°€ì¥ìë¦¬ì¼ìˆ˜ë¡ íˆ¬ëª…í•˜ê²Œ
                    alpha = int(255 * (edge_dist / fade_zone))
                    current_alpha = mask.getpixel((x, y))
                    new_alpha = min(current_alpha, alpha)
                    mask.putpixel((x, y), new_alpha)
        
        return mask
    
    def _create_shadow_effect(self, clothing_image: Image.Image) -> Image.Image:
        """ê·¸ë¦¼ì íš¨ê³¼ ìƒì„±"""
        # ê·¸ë¦¼ììš© ì´ë¯¸ì§€ ìƒì„±
        shadow = clothing_image.convert('RGBA')
        
        # ì–´ë‘¡ê²Œ ë§Œë“¤ê¸°
        shadow_data = []
        for pixel in shadow.getdata():
            if pixel[3] > 0:  # íˆ¬ëª…í•˜ì§€ ì•Šì€ í”½ì…€
                # ì–´ë‘¡ê²Œ ë§Œë“¤ê³  íˆ¬ëª…ë„ ì¡°ì •
                shadow_data.append((30, 30, 30, 100))
            else:
                shadow_data.append((0, 0, 0, 0))
        
        shadow.putdata(shadow_data)
        
        # ë¸”ëŸ¬ íš¨ê³¼ ì¶”ê°€
        shadow = shadow.filter(ImageFilter.GaussianBlur(radius=2))
        
        return shadow
    
    def _apply_post_effects(self, image: Image.Image) -> Image.Image:
        """í›„ì²˜ë¦¬ íš¨ê³¼ ì ìš©"""
        
        # 1. ì•½ê°„ì˜ ìƒ‰ìƒ ë³´ì •
        enhanced = image.copy()
        
        # 2. ë¯¸ì„¸í•œ ë…¸ì´ì¦ˆ ì¶”ê°€ (ìì—°ìŠ¤ëŸ¬ì›€)
        enhanced = self._add_subtle_noise(enhanced)
        
        # 3. ì•½ê°„ì˜ ìƒ¤í”„ë‹
        enhanced = enhanced.filter(ImageFilter.UnsharpMask(radius=1, percent=50))
        
        return enhanced
    
    def _add_subtle_noise(self, image: Image.Image) -> Image.Image:
        """ë¯¸ì„¸í•œ ë…¸ì´ì¦ˆ ì¶”ê°€"""
        try:
            # NumPy ë°°ì—´ë¡œ ë³€í™˜
            img_array = np.array(image)
            
            # ê°€ìš°ì‹œì•ˆ ë…¸ì´ì¦ˆ ìƒì„±
            noise = np.random.normal(0, 2, img_array.shape)
            
            # ë…¸ì´ì¦ˆ ì¶”ê°€
            noisy = img_array + noise
            noisy = np.clip(noisy, 0, 255).astype(np.uint8)
            
            return Image.fromarray(noisy)
            
        except Exception as e:
            logger.warning(f"ë…¸ì´ì¦ˆ ì¶”ê°€ ì‹¤íŒ¨: {e}")
            return image
    
    def _add_watermark(self, image: Image.Image, text: str) -> Image.Image:
        """ì›Œí„°ë§ˆí¬ ì¶”ê°€"""
        try:
            draw = ImageDraw.Draw(image)
            
            # ê¸°ë³¸ í°íŠ¸ ì‚¬ìš©
            try:
                # ì‹œìŠ¤í…œ í°íŠ¸ ì‹œë„
                font = ImageFont.truetype("/System/Library/Fonts/Arial.ttf", 16)
            except:
                font = ImageFont.load_default()
            
            # í…ìŠ¤íŠ¸ ìœ„ì¹˜ (ì˜¤ë¥¸ìª½ í•˜ë‹¨)
            text_width = draw.textlength(text, font=font)
            x = image.width - text_width - 10
            y = image.height - 30
            
            # ë°°ê²½ ë°•ìŠ¤
            draw.rectangle([x-5, y-5, x+text_width+5, y+20], 
                          fill=(0, 0, 0, 128))
            
            # í…ìŠ¤íŠ¸
            draw.text((x, y), text, fill=(255, 255, 255), font=font)
            
            return image
            
        except Exception as e:
            logger.warning(f"ì›Œí„°ë§ˆí¬ ì¶”ê°€ ì‹¤íŒ¨: {e}")
            return image
    
    def _basic_overlay(
        self, 
        person_image: Image.Image, 
        clothing_image: Image.Image
    ) -> Image.Image:
        """ê¸°ë³¸ ì˜¤ë²„ë ˆì´ (ë°±ì—…ìš©)"""
        result = person_image.copy()
        
        # ê°„ë‹¨í•œ í•©ì„±
        clothing_resized = clothing_image.resize((200, 200))
        result.paste(clothing_resized, (150, 100))
        
        # í…ìŠ¤íŠ¸ ì¶”ê°€
        draw = ImageDraw.Draw(result)
        draw.text((10, 10), "Basic Demo Mode", fill='white')
        
        return result
    
    async def ai_fitting(
        self,
        person_image: Image.Image,
        clothing_image: Image.Image,
        height: float,
        weight: float,
        model_type: str
    ) -> Image.Image:
        """ì‹¤ì œ AI ëª¨ë¸ í”¼íŒ… (ì¶”í›„ êµ¬í˜„)"""
        
        logger.info(f"ğŸ¤– AI í”¼íŒ… ëª¨ë¸: {model_type}")
        
        if model_type == "ootd":
            return await self._ootd_fitting(person_image, clothing_image, height, weight)
        elif model_type == "viton":
            return await self._viton_fitting(person_image, clothing_image, height, weight)
        elif model_type == "acgpn":
            return await self._acgpn_fitting(person_image, clothing_image, height, weight)
        else:
            # ë°ëª¨ ëª¨ë“œë¡œ ëŒ€ì²´
            return await self.demo_fitting(person_image, clothing_image, height, weight)
    
    async def _ootd_fitting(
        self,
        person_image: Image.Image,
        clothing_image: Image.Image,
        height: float,
        weight: float
    ) -> Image.Image:
        """OOTDiffusion ëª¨ë¸ ì‚¬ìš© (ë¯¸êµ¬í˜„)"""
        
        # TODO: ì‹¤ì œ OOTDiffusion ëª¨ë¸ ë¡œì§
        # í˜„ì¬ëŠ” ê³ ê¸‰ ë°ëª¨ë¡œ ëŒ€ì²´
        logger.info("ğŸ”„ OOTDiffusion ëª¨ë¸ (ë°ëª¨ ëª¨ë“œ)")
        
        # ì²˜ë¦¬ ì‹œê°„ ì‹œë®¬ë ˆì´ì…˜
        await asyncio.sleep(3)
        
        return await self.demo_fitting(person_image, clothing_image, height, weight)
    
    async def _viton_fitting(
        self,
        person_image: Image.Image,
        clothing_image: Image.Image,
        height: float,
        weight: float
    ) -> Image.Image:
        """VITON-HD ëª¨ë¸ ì‚¬ìš© (ë¯¸êµ¬í˜„)"""
        
        # TODO: ì‹¤ì œ VITON-HD ëª¨ë¸ ë¡œì§
        logger.info("ğŸ”„ VITON-HD ëª¨ë¸ (ë°ëª¨ ëª¨ë“œ)")
        
        # ì²˜ë¦¬ ì‹œê°„ ì‹œë®¬ë ˆì´ì…˜
        await asyncio.sleep(2)
        
        return await self.demo_fitting(person_image, clothing_image, height, weight)
    
    async def _acgpn_fitting(
        self,
        person_image: Image.Image,
        clothing_image: Image.Image,
        height: float,
        weight: float
    ) -> Image.Image:
        """ACGPN ëª¨ë¸ ì‚¬ìš© (ë¯¸êµ¬í˜„)"""
        
        # TODO: ì‹¤ì œ ACGPN ëª¨ë¸ ë¡œì§
        logger.info("ğŸ”„ ACGPN ëª¨ë¸ (ë°ëª¨ ëª¨ë“œ)")
        
        # ì²˜ë¦¬ ì‹œê°„ ì‹œë®¬ë ˆì´ì…˜
        await asyncio.sleep(4)
        
        return await self.demo_fitting(person_image, clothing_image, height, weight)
    
    def get_model_status(self) -> Dict[str, Any]:
        """ëª¨ë¸ ìƒíƒœ ë°˜í™˜"""
        return {
            "models_loaded": self.models_loaded,
            "demo_mode": self.demo_mode,
            "device": self.device,
            "supported_models": self.supported_models,
            "current_config": self.model_config
        }