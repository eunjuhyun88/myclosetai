# backend/app/services/step_implementations.py
"""
ğŸ”¥ MyCloset AI Step Implementations - ì‹¤ì œ Step í´ë˜ìŠ¤ ë¸Œë¦¿ì§€ v6.0
================================================================================

âœ… ì˜¬ë°”ë¥¸ ì—­í• : ai_pipeline/steps/step_XX.py í´ë˜ìŠ¤ë“¤ê³¼ì˜ ë¸Œë¦¿ì§€
âœ… ì‹¤ì œ AI ëª¨ë¸ ì—°ë™: ê° Step í´ë˜ìŠ¤ê°€ ë‹´ë‹¹ (ModelLoader + UnifiedDependencyManager)
âœ… step_implementations.py: Step ì¸ìŠ¤í„´ìŠ¤ ê´€ë¦¬ ë° í˜¸ì¶œë§Œ ë‹´ë‹¹
âœ… BaseStepMixin ì™„ì „ í˜¸í™˜ì„±
âœ… ê¸°ì¡´ API 100% ìœ ì§€
âœ… ìˆœí™˜ì°¸ì¡° ì™„ì „ ë°©ì§€

ì˜¬ë°”ë¥¸ êµ¬ì¡°:
step_routes.py â†’ step_service.py â†’ step_implementations.py â†’ ai_pipeline/steps/step_XX.py
                                                              â†“
                                                         ModelLoader + ì‹¤ì œ AI ëª¨ë¸

Author: MyCloset AI Team  
Date: 2025-07-26
Version: 6.0 (ì˜¬ë°”ë¥¸ ë¸Œë¦¿ì§€ êµ¬ì¡°)
"""

import logging
import asyncio
import time
import threading
import uuid
import base64
import json
import gc
import importlib
import traceback
import weakref
import os
import sys
from typing import Dict, Any, Optional, List, Union, Tuple, Type, TYPE_CHECKING
from datetime import datetime
from pathlib import Path
from io import BytesIO
from abc import ABC, abstractmethod
from dataclasses import dataclass, field
from enum import Enum
from functools import wraps
from concurrent.futures import ThreadPoolExecutor

# ì•ˆì „í•œ íƒ€ì… íŒíŒ…
if TYPE_CHECKING:
    from fastapi import UploadFile
    import torch
    import numpy as np
    from PIL import Image

# ==============================================
# ğŸ”¥ ë¡œê¹… ì„¤ì •
# ==============================================
logger = logging.getLogger(__name__)

# ==============================================
# ğŸ”¥ ì‹¤ì œ Step í´ë˜ìŠ¤ ë§¤í•‘ import
# ==============================================

try:
    from .unified_step_mapping import (
        REAL_STEP_CLASS_MAPPING,
        SERVICE_CLASS_MAPPING,
        SERVICE_TO_STEP_MAPPING,
        STEP_TO_SERVICE_MAPPING,
        SERVICE_NAME_TO_STEP_CLASS,
        STEP_CLASS_TO_SERVICE_NAME,
        RealStepSignature,
        REAL_STEP_SIGNATURES,
        StepFactory,
        setup_conda_optimization,
        validate_step_compatibility,
        get_all_available_steps,
        get_all_available_services,
        get_system_compatibility_info,
        create_step_data_mapper
    )
    REAL_MAPPING_AVAILABLE = True
    logger.info("âœ… ì‹¤ì œ Step í´ë˜ìŠ¤ ë§¤í•‘ import ì„±ê³µ")
except ImportError as e:
    REAL_MAPPING_AVAILABLE = False
    logger.error(f"âŒ ì‹¤ì œ Step í´ë˜ìŠ¤ ë§¤í•‘ import ì‹¤íŒ¨: {e}")
    # í´ë°±ìš© ë”ë¯¸ ë°ì´í„°
    REAL_STEP_CLASS_MAPPING = {
        1: "Step01HumanParsing", 2: "Step02PoseEstimation", 3: "Step03ClothSegmentation", 
        4: "Step04GeometricMatching", 5: "Step05ClothWarping", 6: "Step06VirtualFitting",
        7: "Step07PostProcessing", 8: "Step08QualityAssessment"
    }
    REAL_STEP_SIGNATURES = {}

# ==============================================
# ğŸ”¥ ì•ˆì „í•œ Import ì‹œìŠ¤í…œ
# ==============================================

# PyTorch import
try:
    import torch
    TORCH_AVAILABLE = True
    
    if torch.backends.mps.is_available():
        DEVICE = "mps"
        IS_M3_MAX = True
    elif torch.cuda.is_available():
        DEVICE = "cuda"
        IS_M3_MAX = False
    else:
        DEVICE = "cpu"
        IS_M3_MAX = False
except ImportError:
    TORCH_AVAILABLE = False
    DEVICE = "cpu"
    IS_M3_MAX = False

# NumPy import
try:
    import numpy as np
    NUMPY_AVAILABLE = True
except ImportError:
    NUMPY_AVAILABLE = False

# PIL import
try:
    from PIL import Image
    PIL_AVAILABLE = True
except ImportError:
    PIL_AVAILABLE = False

# BaseStepMixin import (í•µì‹¬!)
try:
    from ..ai_pipeline.steps.base_step_mixin import BaseStepMixin
    BASE_STEP_MIXIN_AVAILABLE = True
    logger.info("âœ… BaseStepMixin import ì„±ê³µ")
except ImportError:
    BASE_STEP_MIXIN_AVAILABLE = False
    logger.warning("âš ï¸ BaseStepMixin import ì‹¤íŒ¨")
    
    class BaseStepMixin:
        def __init__(self, **kwargs):
            self.logger = logging.getLogger(self.__class__.__name__)
            self.device = kwargs.get('device', 'cpu')
            self.is_initialized = False
        
        def initialize(self):
            self.is_initialized = True
            return True
        
        def cleanup(self):
            pass

# ìŠ¤í‚¤ë§ˆ import
try:
    from ..models.schemas import BodyMeasurements
    SCHEMAS_AVAILABLE = True
    logger.info("âœ… ìŠ¤í‚¤ë§ˆ import ì„±ê³µ")
except ImportError:
    SCHEMAS_AVAILABLE = False
    logger.warning("âš ï¸ ìŠ¤í‚¤ë§ˆ import ì‹¤íŒ¨")
    
    @dataclass
    class BodyMeasurements:
        height: float
        weight: float
        chest: Optional[float] = None
        waist: Optional[float] = None
        hips: Optional[float] = None

# ==============================================
# ğŸ”¥ ì‹¤ì œ Step í´ë˜ìŠ¤ ë™ì  ë¡œë”© ì‹œìŠ¤í…œ
# ==============================================

class RealStepClassLoader:
    """ì‹¤ì œ ai_pipeline/steps/step_XX.py í´ë˜ìŠ¤ ë™ì  ë¡œë”©"""
    
    def __init__(self):
        self.logger = logging.getLogger(f"{__name__}.RealStepClassLoader")
        self.loaded_classes: Dict[int, Type] = {}
        self.import_cache: Dict[int, str] = {}
        self._lock = threading.RLock()
        
        # Stepë³„ import ê²½ë¡œ ë§¤í•‘
        self.step_import_paths = {
            1: "app.ai_pipeline.steps.step_01_human_parsing",
            2: "app.ai_pipeline.steps.step_02_pose_estimation", 
            3: "app.ai_pipeline.steps.step_03_cloth_segmentation",
            4: "app.ai_pipeline.steps.step_04_geometric_matching",
            5: "app.ai_pipeline.steps.step_05_cloth_warping",
            6: "app.ai_pipeline.steps.step_06_virtual_fitting",
            7: "app.ai_pipeline.steps.step_07_post_processing",
            8: "app.ai_pipeline.steps.step_08_quality_assessment"
        }
        
        # Stepë³„ í´ë˜ìŠ¤ëª… ë§¤í•‘
        self.step_class_names = {
            1: "Step01HumanParsing",
            2: "Step02PoseEstimation",
            3: "Step03ClothSegmentation", 
            4: "Step04GeometricMatching",
            5: "Step05ClothWarping",
            6: "Step06VirtualFitting",
            7: "Step07PostProcessing",
            8: "Step08QualityAssessment"
        }
    
    def load_step_class(self, step_id: int) -> Optional[Type]:
        """ì‹¤ì œ Step í´ë˜ìŠ¤ ë™ì  ë¡œë”©"""
        try:
            with self._lock:
                # ìºì‹œ í™•ì¸
                if step_id in self.loaded_classes:
                    return self.loaded_classes[step_id]
                
                # import ê²½ë¡œ í™•ì¸
                import_path = self.step_import_paths.get(step_id)
                class_name = self.step_class_names.get(step_id)
                
                if not import_path or not class_name:
                    self.logger.error(f"Step {step_id}ì˜ import ì •ë³´ ì—†ìŒ")
                    return None
                
                # ë™ì  import ì‹œë„
                step_class = self._try_import_step_class(import_path, class_name, step_id)
                
                if step_class:
                    self.loaded_classes[step_id] = step_class
                    self.import_cache[step_id] = import_path
                    self.logger.info(f"âœ… Step {step_id} í´ë˜ìŠ¤ ë¡œë”© ì„±ê³µ: {class_name}")
                    return step_class
                else:
                    self.logger.error(f"âŒ Step {step_id} í´ë˜ìŠ¤ ë¡œë”© ì‹¤íŒ¨: {class_name}")
                    return None
                    
        except Exception as e:
            self.logger.error(f"âŒ Step {step_id} í´ë˜ìŠ¤ ë¡œë”© ì˜ˆì™¸: {e}")
            return None
    
    def _try_import_step_class(self, import_path: str, class_name: str, step_id: int) -> Optional[Type]:
        """ë‹¤ì–‘í•œ import ê²½ë¡œë¡œ Step í´ë˜ìŠ¤ ì‹œë„"""
        import_attempts = [
            import_path,  # ê¸°ë³¸ ê²½ë¡œ
            import_path.replace('app.', ''),  # app. ì œê±°
            f"ai_pipeline.steps.step_{step_id:02d}",  # ê°„ë‹¨í•œ ê²½ë¡œ
            f"backend.app.ai_pipeline.steps.step_{step_id:02d}_{class_name.lower().replace('step0', '').replace('step', '')}"  # í’€ ê²½ë¡œ
        ]
        
        for attempt_path in import_attempts:
            try:
                self.logger.debug(f"Step {step_id} import ì‹œë„: {attempt_path}")
                
                # ëª¨ë“ˆ import
                module = importlib.import_module(attempt_path)
                
                # í´ë˜ìŠ¤ ì¡°íšŒ
                if hasattr(module, class_name):
                    step_class = getattr(module, class_name)
                    
                    # í´ë˜ìŠ¤ ê²€ì¦
                    if self._validate_step_class(step_class, step_id, class_name):
                        self.logger.info(f"âœ… Step {step_id} í´ë˜ìŠ¤ import ì„±ê³µ: {attempt_path}.{class_name}")
                        return step_class
                    else:
                        self.logger.warning(f"âš ï¸ Step {step_id} í´ë˜ìŠ¤ ê²€ì¦ ì‹¤íŒ¨: {class_name}")
                        continue
                else:
                    self.logger.debug(f"Step {step_id} í´ë˜ìŠ¤ {class_name}ë¥¼ {attempt_path}ì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŒ")
                    continue
                    
            except ImportError as e:
                self.logger.debug(f"Step {step_id} import ì‹¤íŒ¨ ({attempt_path}): {e}")
                continue
            except Exception as e:
                self.logger.warning(f"Step {step_id} import ì˜ˆì™¸ ({attempt_path}): {e}")
                continue
        
        return None
    
    def _validate_step_class(self, step_class: Type, step_id: int, class_name: str) -> bool:
        """Step í´ë˜ìŠ¤ ê²€ì¦"""
        try:
            # ê¸°ë³¸ ê²€ì‚¬
            if not step_class:
                return False
            
            # í•„ìˆ˜ ë©”ì„œë“œ í™•ì¸
            required_methods = ['process']
            for method in required_methods:
                if not hasattr(step_class, method):
                    self.logger.warning(f"âš ï¸ {class_name}ì— í•„ìˆ˜ ë©”ì„œë“œ {method} ì—†ìŒ")
                    return False
            
            # BaseStepMixin ìƒì† í™•ì¸ (ì„ íƒì )
            try:
                mro = [cls.__name__ for cls in step_class.__mro__]
                if 'BaseStepMixin' in mro:
                    self.logger.debug(f"âœ… {class_name} BaseStepMixin ìƒì† í™•ì¸")
                else:
                    self.logger.debug(f"â„¹ï¸ {class_name} BaseStepMixin ë¯¸ìƒì† (ì„ íƒì )")
            except:
                pass
            
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ {class_name} í´ë˜ìŠ¤ ê²€ì¦ ì‹¤íŒ¨: {e}")
            return False
    
    def get_loaded_classes_info(self) -> Dict[str, Any]:
        """ë¡œë”©ëœ í´ë˜ìŠ¤ ì •ë³´"""
        with self._lock:
            return {
                "loaded_classes": {
                    step_id: {
                        "class_name": cls.__name__,
                        "import_path": self.import_cache.get(step_id, "unknown"),
                        "module": cls.__module__
                    }
                    for step_id, cls in self.loaded_classes.items()
                },
                "total_loaded": len(self.loaded_classes),
                "available_steps": list(self.step_import_paths.keys())
            }

# ==============================================
# ğŸ”¥ Step êµ¬í˜„ì²´ ë¸Œë¦¿ì§€ í´ë˜ìŠ¤
# ==============================================

class StepImplementationBridge:
    """ê°œë³„ Step í´ë˜ìŠ¤ì™€ì˜ ë¸Œë¦¿ì§€"""
    
    def __init__(self, step_id: int, step_class: Type, **config):
        self.step_id = step_id
        self.step_class = step_class
        self.config = config
        self.logger = logging.getLogger(f"{__name__}.StepBridge.{step_id}")
        
        # Step ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
        self.step_instance = None
        self.is_initialized = False
        self._lock = threading.RLock()
        
        # ì„±ëŠ¥ ë©”íŠ¸ë¦­
        self.total_requests = 0
        self.successful_requests = 0
        self.failed_requests = 0
        self.processing_times = []
        
        self.logger.info(f"âœ… Step {step_id} ë¸Œë¦¿ì§€ ìƒì„±: {step_class.__name__}")
    
    def initialize(self) -> bool:
        """Step ì¸ìŠ¤í„´ìŠ¤ ì´ˆê¸°í™”"""
        try:
            if self.is_initialized and self.step_instance:
                return True
            
            with self._lock:
                # Step ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
                step_config = {
                    'step_id': self.step_id,
                    'step_name': f"Step{self.step_id:02d}",
                    'device': self.config.get('device', DEVICE),
                    **self.config
                }
                
                self.logger.info(f"ğŸ”„ Step {self.step_id} ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ì¤‘...")
                self.step_instance = self.step_class(**step_config)
                
                # Step ì´ˆê¸°í™” í˜¸ì¶œ
                if hasattr(self.step_instance, 'initialize'):
                    success = self.step_instance.initialize()
                    if not success:
                        self.logger.error(f"âŒ Step {self.step_id} ì´ˆê¸°í™” ì‹¤íŒ¨")
                        return False
                
                self.is_initialized = True
                self.logger.info(f"âœ… Step {self.step_id} ë¸Œë¦¿ì§€ ì´ˆê¸°í™” ì™„ë£Œ")
                return True
                
        except Exception as e:
            self.logger.error(f"âŒ Step {self.step_id} ë¸Œë¦¿ì§€ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return False
    
    async def process(self, *args, **kwargs) -> Dict[str, Any]:
        """Step ì²˜ë¦¬ (ì‹¤ì œ Step í´ë˜ìŠ¤ì˜ process í˜¸ì¶œ)"""
        start_time = time.time()
        
        try:
            with self._lock:
                self.total_requests += 1
            
            # ì´ˆê¸°í™” í™•ì¸
            if not self.is_initialized:
                if not self.initialize():
                    raise Exception(f"Step {self.step_id} ì´ˆê¸°í™” ì‹¤íŒ¨")
            
            if not self.step_instance:
                raise Exception(f"Step {self.step_id} ì¸ìŠ¤í„´ìŠ¤ ì—†ìŒ")
            
            # ì‹¤ì œ Step í´ë˜ìŠ¤ì˜ process ë©”ì„œë“œ í˜¸ì¶œ
            self.logger.debug(f"ğŸ”„ Step {self.step_id} ì‹¤ì œ ì²˜ë¦¬ ì‹œì‘...")
            
            if asyncio.iscoroutinefunction(self.step_instance.process):
                result = await self.step_instance.process(*args, **kwargs)
            else:
                result = self.step_instance.process(*args, **kwargs)
            
            # ì²˜ë¦¬ ì‹œê°„ ê¸°ë¡
            processing_time = time.time() - start_time
            self.processing_times.append(processing_time)
            
            # ê²°ê³¼ ê²€ì¦ ë° í¬ë§·
            if isinstance(result, dict):
                if 'success' not in result:
                    result['success'] = True
                
                if 'details' not in result:
                    result['details'] = {}
                
                # ë¸Œë¦¿ì§€ ë©”íƒ€ë°ì´í„° ì¶”ê°€
                result['details'].update({
                    'step_id': self.step_id,
                    'step_class': self.step_class.__name__,
                    'processing_time': processing_time,
                    'bridge_mode': True,
                    'real_ai_processing': True,
                    'timestamp': datetime.now().isoformat()
                })
            else:
                # dictê°€ ì•„ë‹Œ ê²°ê³¼ë¥¼ dictë¡œ ë³€í™˜
                result = {
                    'success': True,
                    'result': result,
                    'details': {
                        'step_id': self.step_id,
                        'step_class': self.step_class.__name__,
                        'processing_time': processing_time,
                        'bridge_mode': True,
                        'real_ai_processing': True,
                        'timestamp': datetime.now().isoformat()
                    }
                }
            
            with self._lock:
                self.successful_requests += 1
            
            self.logger.info(f"âœ… Step {self.step_id} ì²˜ë¦¬ ì™„ë£Œ ({processing_time:.2f}ì´ˆ)")
            return result
            
        except Exception as e:
            with self._lock:
                self.failed_requests += 1
            
            processing_time = time.time() - start_time
            self.logger.error(f"âŒ Step {self.step_id} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            
            return {
                'success': False,
                'error': str(e),
                'details': {
                    'step_id': self.step_id,
                    'step_class': self.step_class.__name__ if self.step_class else 'Unknown',
                    'processing_time': processing_time,
                    'bridge_mode': True,
                    'error_type': type(e).__name__,
                    'timestamp': datetime.now().isoformat()
                }
            }
    
    def cleanup(self):
        """Step ì¸ìŠ¤í„´ìŠ¤ ì •ë¦¬"""
        try:
            if self.step_instance and hasattr(self.step_instance, 'cleanup'):
                self.step_instance.cleanup()
            
            self.step_instance = None
            self.is_initialized = False
            
            self.logger.info(f"âœ… Step {self.step_id} ë¸Œë¦¿ì§€ ì •ë¦¬ ì™„ë£Œ")
            
        except Exception as e:
            self.logger.error(f"âŒ Step {self.step_id} ë¸Œë¦¿ì§€ ì •ë¦¬ ì‹¤íŒ¨: {e}")
    
    def get_metrics(self) -> Dict[str, Any]:
        """ë¸Œë¦¿ì§€ ë©”íŠ¸ë¦­"""
        with self._lock:
            avg_time = sum(self.processing_times) / len(self.processing_times) if self.processing_times else 0
            
            return {
                'step_id': self.step_id,
                'step_class': self.step_class.__name__ if self.step_class else 'Unknown',
                'is_initialized': self.is_initialized,
                'total_requests': self.total_requests,
                'successful_requests': self.successful_requests,
                'failed_requests': self.failed_requests,
                'success_rate': self.successful_requests / max(self.total_requests, 1),
                'average_processing_time': avg_time,
                'has_step_instance': self.step_instance is not None
            }

# ==============================================
# ğŸ”¥ ì‹¤ì œ Step êµ¬í˜„ì²´ ê´€ë¦¬ì (ë¸Œë¦¿ì§€ ë²„ì „)
# ==============================================

class RealStepImplementationManager:
    """ì‹¤ì œ Step í´ë˜ìŠ¤ë“¤ê³¼ì˜ ë¸Œë¦¿ì§€ ê´€ë¦¬ì"""
    
    def __init__(self):
        self.logger = logging.getLogger(f"{__name__}.RealStepImplementationManager")
        self.class_loader = RealStepClassLoader()
        self.step_bridges: Dict[int, StepImplementationBridge] = {}
        self._lock = threading.RLock()
        
        # ì‹œìŠ¤í…œ ìƒíƒœ
        if REAL_MAPPING_AVAILABLE:
            self.system_info = get_system_compatibility_info()
        else:
            self.system_info = {"total_steps": 8, "total_services": 8}
        
        # ì „ì²´ ë§¤ë‹ˆì € ë©”íŠ¸ë¦­
        self.total_requests = 0
        self.successful_requests = 0
        self.failed_requests = 0
        self.start_time = datetime.now()
        
        # conda í™˜ê²½ ìµœì í™”
        if REAL_MAPPING_AVAILABLE:
            setup_conda_optimization()
        
        self.logger.info("âœ… RealStepImplementationManager ì´ˆê¸°í™” ì™„ë£Œ (ë¸Œë¦¿ì§€ ëª¨ë“œ)")
        self.logger.info(f"ğŸ“Š ì§€ì› Step: {self.system_info.get('total_steps', 8)}ê°œ")
    
    def get_step_bridge(self, step_id: int, **config) -> Optional[StepImplementationBridge]:
        """Step ë¸Œë¦¿ì§€ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
        with self._lock:
            # ìºì‹œ í™•ì¸
            if step_id in self.step_bridges:
                return self.step_bridges[step_id]
            
            # Step í´ë˜ìŠ¤ ë¡œë”©
            step_class = self.class_loader.load_step_class(step_id)
            if not step_class:
                self.logger.error(f"âŒ Step {step_id} í´ë˜ìŠ¤ ë¡œë”© ì‹¤íŒ¨")
                return None
            
            # ë¸Œë¦¿ì§€ ìƒì„±
            try:
                bridge = StepImplementationBridge(step_id, step_class, **config)
                if bridge.initialize():
                    self.step_bridges[step_id] = bridge
                    self.logger.info(f"âœ… Step {step_id} ë¸Œë¦¿ì§€ ìƒì„± ì™„ë£Œ")
                    return bridge
                else:
                    self.logger.error(f"âŒ Step {step_id} ë¸Œë¦¿ì§€ ì´ˆê¸°í™” ì‹¤íŒ¨")
                    return None
                    
            except Exception as e:
                self.logger.error(f"âŒ Step {step_id} ë¸Œë¦¿ì§€ ìƒì„± ì‹¤íŒ¨: {e}")
                return None
    
    async def process_step(self, step_id: int, *args, **kwargs) -> Dict[str, Any]:
        """Step ì²˜ë¦¬ (ë¸Œë¦¿ì§€ë¥¼ í†µí•œ ì‹¤ì œ Step í´ë˜ìŠ¤ í˜¸ì¶œ)"""
        try:
            with self._lock:
                self.total_requests += 1
            
            # Step ë¸Œë¦¿ì§€ ì¡°íšŒ
            bridge = self.get_step_bridge(step_id)
            if not bridge:
                with self._lock:
                    self.failed_requests += 1
                return {
                    "success": False,
                    "error": f"Step {step_id} ë¸Œë¦¿ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ",
                    "step_id": step_id,
                    "bridge_mode": True,
                    "timestamp": datetime.now().isoformat()
                }
            
            # ì‹¤ì œ Step ì²˜ë¦¬
            result = await bridge.process(*args, **kwargs)
            
            # ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
            with self._lock:
                if result.get("success", False):
                    self.successful_requests += 1
                else:
                    self.failed_requests += 1
            
            return result
            
        except Exception as e:
            with self._lock:
                self.failed_requests += 1
            
            self.logger.error(f"âŒ Step {step_id} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return {
                "success": False,
                "error": str(e),
                "step_id": step_id,
                "bridge_mode": True,
                "error_type": type(e).__name__,
                "timestamp": datetime.now().isoformat()
            }
    
    def get_all_metrics(self) -> Dict[str, Any]:
        """ëª¨ë“  ë¸Œë¦¿ì§€ ë©”íŠ¸ë¦­ ë°˜í™˜"""
        with self._lock:
            bridge_metrics = {}
            for step_id, bridge in self.step_bridges.items():
                bridge_metrics[f"step_{step_id}"] = bridge.get_metrics()
            
            return {
                "manager_version": "6.0_bridge_mode",
                "total_requests": self.total_requests,
                "successful_requests": self.successful_requests,
                "failed_requests": self.failed_requests,
                "success_rate": self.successful_requests / max(self.total_requests, 1),
                "uptime_seconds": (datetime.now() - self.start_time).total_seconds(),
                "real_mapping_available": REAL_MAPPING_AVAILABLE,
                "system_compatibility": self.system_info,
                "architecture": "Step í´ë˜ìŠ¤ ë¸Œë¦¿ì§€ (ai_pipeline/steps/step_XX.py ì—°ë™)",
                "ai_model_responsibility": "ê° Step í´ë˜ìŠ¤ê°€ ModelLoader + AI ëª¨ë¸ ë‹´ë‹¹",
                "bridge_responsibility": "Step ì¸ìŠ¤í„´ìŠ¤ ê´€ë¦¬ ë° í˜¸ì¶œë§Œ ë‹´ë‹¹",
                "basestepmixin_integration": BASE_STEP_MIXIN_AVAILABLE,
                "conda_optimization": 'CONDA_DEFAULT_ENV' in os.environ,
                "loaded_classes": self.class_loader.get_loaded_classes_info(),
                "active_bridges": len(self.step_bridges),
                "bridge_metrics": bridge_metrics
            }
    
    def cleanup_all_bridges(self):
        """ëª¨ë“  ë¸Œë¦¿ì§€ ì •ë¦¬"""
        try:
            with self._lock:
                for step_id, bridge in self.step_bridges.items():
                    try:
                        bridge.cleanup()
                        self.logger.info(f"âœ… Step {step_id} ë¸Œë¦¿ì§€ ì •ë¦¬ ì™„ë£Œ")
                    except Exception as e:
                        self.logger.warning(f"âš ï¸ Step {step_id} ë¸Œë¦¿ì§€ ì •ë¦¬ ì‹¤íŒ¨: {e}")
                
                self.step_bridges.clear()
            
            # ë©”ëª¨ë¦¬ ì •ë¦¬
            if TORCH_AVAILABLE:
                if DEVICE == "mps" and IS_M3_MAX:
                    if hasattr(torch.mps, 'empty_cache'):
                        torch.mps.empty_cache()
                elif DEVICE == "cuda":
                    torch.cuda.empty_cache()
            
            gc.collect()
            
            self.logger.info("âœ… ëª¨ë“  Step ë¸Œë¦¿ì§€ ì •ë¦¬ ì™„ë£Œ")
        except Exception as e:
            self.logger.error(f"âŒ Step ë¸Œë¦¿ì§€ ì •ë¦¬ ì‹¤íŒ¨: {e}")

# ==============================================
# ğŸ”¥ ì‹±ê¸€í†¤ ê´€ë¦¬ì ì¸ìŠ¤í„´ìŠ¤
# ==============================================

_real_step_implementation_manager_instance: Optional[RealStepImplementationManager] = None
_manager_lock = threading.RLock()

def get_step_implementation_manager() -> RealStepImplementationManager:
    """RealStepImplementationManager ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    global _real_step_implementation_manager_instance
    
    with _manager_lock:
        if _real_step_implementation_manager_instance is None:
            _real_step_implementation_manager_instance = RealStepImplementationManager()
            logger.info("âœ… RealStepImplementationManager ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ì™„ë£Œ")
    
    return _real_step_implementation_manager_instance

async def get_step_implementation_manager_async() -> RealStepImplementationManager:
    """RealStepImplementationManager ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜ - ë¹„ë™ê¸° ë²„ì „"""
    return get_step_implementation_manager()

def cleanup_step_implementation_manager():
    """RealStepImplementationManager ì •ë¦¬"""
    global _real_step_implementation_manager_instance
    
    with _manager_lock:
        if _real_step_implementation_manager_instance:
            _real_step_implementation_manager_instance.cleanup_all_bridges()
            _real_step_implementation_manager_instance = None
            logger.info("ğŸ§¹ RealStepImplementationManager ì •ë¦¬ ì™„ë£Œ")

# ==============================================
# ğŸ”¥ í¸ì˜ í•¨ìˆ˜ë“¤ (ê¸°ì¡´ API 100% í˜¸í™˜)
# ==============================================

async def process_human_parsing_implementation(
    person_image,
    enhance_quality: bool = True,
    session_id: Optional[str] = None,
    **kwargs
) -> Dict[str, Any]:
    """ì¸ê°„ íŒŒì‹± êµ¬í˜„ì²´ ì²˜ë¦¬ - ai_pipeline/steps/step_01_human_parsing.py í˜¸ì¶œ"""
    manager = get_step_implementation_manager()
    return await manager.process_step(
        1, person_image=person_image, enhance_quality=enhance_quality, session_id=session_id, **kwargs
    )

async def process_pose_estimation_implementation(
    image,
    clothing_type: str = "shirt",
    detection_confidence: float = 0.5,
    session_id: Optional[str] = None,
    **kwargs
) -> Dict[str, Any]:
    """í¬ì¦ˆ ì¶”ì • êµ¬í˜„ì²´ ì²˜ë¦¬ - ai_pipeline/steps/step_02_pose_estimation.py í˜¸ì¶œ"""
    manager = get_step_implementation_manager()
    return await manager.process_step(
        2, image=image, clothing_type=clothing_type, detection_confidence=detection_confidence, session_id=session_id, **kwargs
    )

async def process_cloth_segmentation_implementation(
    image,
    clothing_type: str = "shirt",
    quality_level: str = "medium",
    session_id: Optional[str] = None,
    **kwargs
) -> Dict[str, Any]:
    """ì˜ë¥˜ ë¶„í•  êµ¬í˜„ì²´ ì²˜ë¦¬ - ai_pipeline/steps/step_03_cloth_segmentation.py í˜¸ì¶œ"""
    manager = get_step_implementation_manager()
    return await manager.process_step(
        3, image=image, clothing_type=clothing_type, quality_level=quality_level, session_id=session_id, **kwargs
    )

async def process_geometric_matching_implementation(
    person_image,
    clothing_image,
    pose_keypoints=None,
    body_mask=None,
    clothing_mask=None,
    matching_precision: str = "high",
    session_id: Optional[str] = None,
    **kwargs
) -> Dict[str, Any]:
    """ê¸°í•˜í•™ì  ë§¤ì¹­ êµ¬í˜„ì²´ ì²˜ë¦¬ - ai_pipeline/steps/step_04_geometric_matching.py í˜¸ì¶œ"""
    manager = get_step_implementation_manager()
    return await manager.process_step(
        4, person_image=person_image, clothing_image=clothing_image, pose_keypoints=pose_keypoints, 
        body_mask=body_mask, clothing_mask=clothing_mask, matching_precision=matching_precision, 
        session_id=session_id, **kwargs
    )

async def process_cloth_warping_implementation(
    cloth_image,
    person_image,
    cloth_mask=None,
    fabric_type: str = "cotton",
    clothing_type: str = "shirt",
    session_id: Optional[str] = None,
    **kwargs
) -> Dict[str, Any]:
    """ì˜ë¥˜ ì›Œí•‘ êµ¬í˜„ì²´ ì²˜ë¦¬ - ai_pipeline/steps/step_05_cloth_warping.py í˜¸ì¶œ"""
    manager = get_step_implementation_manager()
    return await manager.process_step(
        5, cloth_image=cloth_image, person_image=person_image, cloth_mask=cloth_mask, 
        fabric_type=fabric_type, clothing_type=clothing_type, session_id=session_id, **kwargs
    )

async def process_virtual_fitting_implementation(
    person_image,
    cloth_image,
    pose_data=None,
    cloth_mask=None,
    fitting_quality: str = "high",
    session_id: Optional[str] = None,
    **kwargs
) -> Dict[str, Any]:
    """ê°€ìƒ í”¼íŒ… êµ¬í˜„ì²´ ì²˜ë¦¬ - ai_pipeline/steps/step_06_virtual_fitting.py í˜¸ì¶œ (í•µì‹¬!)"""
    manager = get_step_implementation_manager()
    return await manager.process_step(
        6, person_image=person_image, cloth_image=cloth_image, pose_data=pose_data, 
        cloth_mask=cloth_mask, fitting_quality=fitting_quality, session_id=session_id, **kwargs
    )

async def process_post_processing_implementation(
    fitted_image,
    enhancement_level: str = "medium",
    session_id: Optional[str] = None,
    **kwargs
) -> Dict[str, Any]:
    """í›„ì²˜ë¦¬ êµ¬í˜„ì²´ ì²˜ë¦¬ - ai_pipeline/steps/step_07_post_processing.py í˜¸ì¶œ"""
    manager = get_step_implementation_manager()
    return await manager.process_step(
        7, fitted_image=fitted_image, enhancement_level=enhancement_level, session_id=session_id, **kwargs
    )

async def process_quality_assessment_implementation(
    final_image,
    analysis_depth: str = "comprehensive",
    session_id: Optional[str] = None,
    **kwargs
) -> Dict[str, Any]:
    """í’ˆì§ˆ í‰ê°€ êµ¬í˜„ì²´ ì²˜ë¦¬ - ai_pipeline/steps/step_08_quality_assessment.py í˜¸ì¶œ"""
    manager = get_step_implementation_manager()
    return await manager.process_step(
        8, final_image=final_image, analysis_depth=analysis_depth, session_id=session_id, **kwargs
    )

# ==============================================
# ğŸ”¥ ìƒíƒœ ë° ê°€ìš©ì„± ì •ë³´
# ==============================================

STEP_IMPLEMENTATIONS_AVAILABLE = True

def get_implementation_availability_info() -> Dict[str, Any]:
    """ì‹¤ì œ Step êµ¬í˜„ì²´ ê°€ìš©ì„± ì •ë³´ ë°˜í™˜"""
    return {
        "step_implementations_available": STEP_IMPLEMENTATIONS_AVAILABLE,
        "architecture": "Step í´ë˜ìŠ¤ ë¸Œë¦¿ì§€ (ai_pipeline/steps/step_XX.py ì—°ë™)",
        "version": "6.0_bridge_mode",
        "api_compatibility": "100%",
        "real_mapping_available": REAL_MAPPING_AVAILABLE,
        "real_step_implementation": True,
        "basestepmixin_integration": BASE_STEP_MIXIN_AVAILABLE,
        "step_class_mappings": REAL_STEP_CLASS_MAPPING,
        "total_steps_supported": len(REAL_STEP_CLASS_MAPPING),
        "real_step_classes_integrated": True,
        "ai_model_responsibility": "ê° Step í´ë˜ìŠ¤ê°€ ModelLoader + AI ëª¨ë¸ ë‹´ë‹¹",
        "bridge_responsibility": "Step ì¸ìŠ¤í„´ìŠ¤ ê´€ë¦¬ ë° í˜¸ì¶œë§Œ ë‹´ë‹¹",
        "conda_optimization": 'CONDA_DEFAULT_ENV' in os.environ,
        "device_optimization": f"{DEVICE}_optimized",
        "production_ready": True,
        "correct_architecture": True,
        "step_classes_location": "ai_pipeline/steps/step_XX.py",
        "ai_models_location": "ê° Step í´ë˜ìŠ¤ ë‚´ë¶€ (ModelLoader ì‚¬ìš©)",
        "bridge_pattern": {
            "step_routes.py": "API ì—”ë“œí¬ì¸íŠ¸",
            "step_service.py": "DI ê¸°ë°˜ ì„œë¹„ìŠ¤ ë§¤ë‹ˆì €",
            "step_implementations.py": "Step í´ë˜ìŠ¤ ë¸Œë¦¿ì§€ (ì´ íŒŒì¼)",
            "ai_pipeline/steps/step_XX.py": "ì‹¤ì œ AI ëª¨ë¸ + ì²˜ë¦¬ ë¡œì§"
        }
    }

# ==============================================
# ğŸ”¥ conda í™˜ê²½ ìµœì í™” í•¨ìˆ˜ë“¤
# ==============================================

def setup_conda_step_implementations():
    """conda í™˜ê²½ì—ì„œ Step êµ¬í˜„ì²´ ìµœì í™” ì„¤ì •"""
    try:
        conda_env = os.environ.get('CONDA_DEFAULT_ENV')
        if conda_env:
            logger.info(f"ğŸ conda í™˜ê²½ ê°ì§€: {conda_env}")
            
            # PyTorch conda ìµœì í™”
            if TORCH_AVAILABLE:
                # MPS ìµœì í™” (M3 Max)
                if DEVICE == "mps":
                    if hasattr(torch.backends.mps, 'empty_cache'):
                        torch.backends.mps.empty_cache()
                    logger.info("ğŸ M3 Max MPS ìµœì í™” í™œì„±í™”")
                
                # CPU ìŠ¤ë ˆë“œ ìµœì í™”
                cpu_count = os.cpu_count()
                torch.set_num_threads(max(1, cpu_count // 2))
                logger.info(f"ğŸ§µ PyTorch ìŠ¤ë ˆë“œ ìµœì í™”: {torch.get_num_threads()}/{cpu_count}")
            
            # í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
            os.environ['OMP_NUM_THREADS'] = str(max(1, os.cpu_count() // 2))
            os.environ['MKL_NUM_THREADS'] = str(max(1, os.cpu_count() // 2))
            
            return True
    except Exception as e:
        logger.warning(f"âš ï¸ conda ìµœì í™” ì„¤ì • ì‹¤íŒ¨: {e}")
        return False

def validate_conda_environment():
    """conda í™˜ê²½ ê²€ì¦"""
    try:
        conda_env = os.environ.get('CONDA_DEFAULT_ENV')
        if not conda_env:
            logger.warning("âš ï¸ conda í™˜ê²½ì´ í™œì„±í™”ë˜ì§€ ì•ŠìŒ")
            return False
        
        # í•„ìˆ˜ íŒ¨í‚¤ì§€ í™•ì¸
        required_packages = ['numpy', 'pillow']
        missing_packages = []
        
        if not NUMPY_AVAILABLE:
            missing_packages.append('numpy')
        if not PIL_AVAILABLE:
            missing_packages.append('pillow')
        
        if missing_packages:
            logger.warning(f"âš ï¸ conda í™˜ê²½ì— ëˆ„ë½ëœ íŒ¨í‚¤ì§€: {missing_packages}")
            return False
        
        logger.info(f"âœ… conda í™˜ê²½ ê²€ì¦ ì™„ë£Œ: {conda_env}")
        return True
        
    except Exception as e:
        logger.error(f"âŒ conda í™˜ê²½ ê²€ì¦ ì‹¤íŒ¨: {e}")
        return False

# ==============================================
# ğŸ”¥ ëª¨ë“ˆ Export
# ==============================================

__all__ = [
    # ë©”ì¸ í´ë˜ìŠ¤ë“¤
    "RealStepImplementationManager",
    "StepImplementationBridge",
    "RealStepClassLoader",
    
    # ê´€ë¦¬ì í•¨ìˆ˜ë“¤
    "get_step_implementation_manager",
    "get_step_implementation_manager_async",
    "cleanup_step_implementation_manager",
    
    # í¸ì˜ í•¨ìˆ˜ë“¤ (ai_pipeline/steps/step_XX.py í˜¸ì¶œ)
    "process_human_parsing_implementation",
    "process_pose_estimation_implementation",
    "process_cloth_segmentation_implementation",
    "process_geometric_matching_implementation",
    "process_cloth_warping_implementation",
    "process_virtual_fitting_implementation",
    "process_post_processing_implementation",
    "process_quality_assessment_implementation",
    
    # ìœ í‹¸ë¦¬í‹°
    "get_implementation_availability_info",
    "setup_conda_step_implementations",
    "validate_conda_environment",
    
    # ìŠ¤í‚¤ë§ˆ
    "BodyMeasurements",
    
    # ìƒìˆ˜
    "STEP_IMPLEMENTATIONS_AVAILABLE"
]

# í˜¸í™˜ì„±ì„ ìœ„í•œ ë³„ì¹­
StepImplementationManager = RealStepImplementationManager

# ==============================================
# ğŸ”¥ ëª¨ë“ˆ ë¡œë“œ ì™„ë£Œ ë©”ì‹œì§€
# ==============================================

logger.info("ğŸ”¥ Step Implementations v6.0 ë¡œë“œ ì™„ë£Œ (ì˜¬ë°”ë¥¸ ë¸Œë¦¿ì§€ êµ¬ì¡°)!")
logger.info("âœ… ì˜¬ë°”ë¥¸ ì•„í‚¤í…ì²˜:")
logger.info("   step_routes.py â†’ step_service.py â†’ step_implementations.py â†’ ai_pipeline/steps/step_XX.py")
logger.info("âœ… step_implementations.py ì—­í• : Step í´ë˜ìŠ¤ ë¸Œë¦¿ì§€ (ì¸ìŠ¤í„´ìŠ¤ ê´€ë¦¬ + í˜¸ì¶œ)")
logger.info("âœ… AI ëª¨ë¸ ì²˜ë¦¬: ê° ai_pipeline/steps/step_XX.pyì—ì„œ ModelLoader ì‚¬ìš©")
logger.info("âœ… ìˆœí™˜ì°¸ì¡° ì™„ì „ ë°©ì§€: ë‹¨ë°©í–¥ ì˜ì¡´ì„± êµ¬ì¡°")
logger.info("âœ… ê¸°ì¡´ API 100% í˜¸í™˜: ëª¨ë“  í•¨ìˆ˜ëª…/ì‹œê·¸ë‹ˆì²˜ ìœ ì§€")

logger.info(f"ğŸ“Š ì‹œìŠ¤í…œ ìƒíƒœ:")
logger.info(f"   - ì‹¤ì œ ë§¤í•‘: {'âœ…' if REAL_MAPPING_AVAILABLE else 'âŒ'}")
logger.info(f"   - PyTorch: {'âœ…' if TORCH_AVAILABLE else 'âŒ'}")
logger.info(f"   - BaseStepMixin: {'âœ…' if BASE_STEP_MIXIN_AVAILABLE else 'âŒ'}")
logger.info(f"   - Device: {DEVICE}")
logger.info(f"   - conda í™˜ê²½: {'âœ…' if 'CONDA_DEFAULT_ENV' in os.environ else 'âŒ'}")

logger.info("ğŸ¯ Step í´ë˜ìŠ¤ ë¡œë”©:")
for step_id, class_name in REAL_STEP_CLASS_MAPPING.items():
    logger.info(f"   - Step {step_id}: {class_name}")

# conda í™˜ê²½ ìµœì í™” ìë™ ì‹¤í–‰
if 'CONDA_DEFAULT_ENV' in os.environ:
    setup_conda_step_implementations()
    if validate_conda_environment():
        logger.info("ğŸ conda í™˜ê²½ ìë™ ìµœì í™” ë° ê²€ì¦ ì™„ë£Œ!")
    else:
        logger.warning("âš ï¸ conda í™˜ê²½ ê²€ì¦ ì‹¤íŒ¨!")

# ì´ˆê¸° ë©”ëª¨ë¦¬ ìµœì í™”
try:
    if TORCH_AVAILABLE:
        if DEVICE == "mps" and IS_M3_MAX:
            if hasattr(torch.mps, 'empty_cache'):
                torch.mps.empty_cache()
        elif DEVICE == "cuda":
            torch.cuda.empty_cache()
    
    gc.collect()
    logger.info(f"ğŸ’¾ {DEVICE} ì´ˆê¸° ë©”ëª¨ë¦¬ ìµœì í™” ì™„ë£Œ!")
except Exception as e:
    logger.warning(f"âš ï¸ ì´ˆê¸° ë©”ëª¨ë¦¬ ìµœì í™” ì‹¤íŒ¨: {e}")

logger.info("ğŸ‰ Step Implementations v6.0 ì™„ì „ ì¤€ë¹„ ì™„ë£Œ!")
logger.info("ğŸš€ ì˜¬ë°”ë¥¸ ë¸Œë¦¿ì§€ êµ¬ì¡°ë¡œ ì‹¤ì œ AI Step í´ë˜ìŠ¤ë“¤ê³¼ ì—°ë™!")
logger.info("ğŸ’¯ ai_pipeline/steps/step_XX.pyì—ì„œ ì‹¤ì œ AI ëª¨ë¸ ì²˜ë¦¬!")