# backend/app/services/step_implementations.py
"""
ğŸ”¥ MyCloset AI Step Implementations v11.0 - DetailedDataSpec ì™„ì „ ë°˜ì˜ + StepFactory v9.0 ì—°ë™
================================================================================

âœ… step_model_requests.py DetailedDataSpec ì™„ì „ ë°˜ì˜
âœ… API ì…ì¶œë ¥ ë§¤í•‘ (api_input_mapping, api_output_mapping) 100% í™œìš©
âœ… Step ê°„ ë°ì´í„° íë¦„ (accepts_from_previous_step, provides_to_next_step) ì™„ì „ êµ¬í˜„
âœ… ì „ì²˜ë¦¬/í›„ì²˜ë¦¬ (preprocessing_steps, postprocessing_steps) ì™„ì „ ì ìš©
âœ… StepFactory v9.0 + BaseStepMixin ì™„ì „ í˜¸í™˜
âœ… FastAPI ë¼ìš°í„° í˜¸í™˜ì„± 100% í™•ë³´
âœ… ìƒì„±ì ì‹œì  ì˜ì¡´ì„± ì£¼ì… (**kwargs íŒ¨í„´)
âœ… process() ë©”ì„œë“œ ì‹œê·¸ë‹ˆì²˜ í‘œì¤€í™”
âœ… conda í™˜ê²½ ìš°ì„  ìµœì í™” + M3 Max 128GB ìµœì í™”
âœ… ìˆœí™˜ì°¸ì¡° ì™„ì „ ë°©ì§€ (TYPE_CHECKING + ë™ì  import)
âœ… í”„ë¡œë•ì…˜ ë ˆë²¨ ì•ˆì •ì„± + ì—ëŸ¬ ì²˜ë¦¬ ê°•í™”

í•µì‹¬ ì•„í‚¤í…ì²˜:
step_routes.py â†’ step_service.py â†’ step_implementations.py â†’ StepFactory v9.0 â†’ ì‹¤ì œ Step í´ë˜ìŠ¤ë“¤
                                                               â†“
                                                          ai_pipeline/steps/step_XX.py

API ë¡œì§ íë¦„:
1. FastAPI â†’ api_input_mapping (UploadFile â†’ PIL.Image)
2. StepFactory â†’ Step ì¸ìŠ¤í„´ìŠ¤ ìƒì„± (DetailedDataSpec ê¸°ë°˜)
3. ì „ì²˜ë¦¬ â†’ AI ì¶”ë¡  â†’ í›„ì²˜ë¦¬
4. api_output_mapping (AI ê²°ê³¼ â†’ FastAPI ì‘ë‹µ)
5. provides_to_next_step (ë‹¤ìŒ Step ë°ì´í„° ì¤€ë¹„)

ì‹¤ì œ Step í´ë˜ìŠ¤ ë§¤í•‘ (StepFactory v9.0 ê¸°ì¤€):
Step 1: HumanParsingStep (Graphonomy 1.2GB)
Step 2: PoseEstimationStep (OpenPose 97.8MB)
Step 3: ClothSegmentationStep (SAM 2.4GB)
Step 4: GeometricMatchingStep (GMM 44.7MB)
Step 5: ClothWarpingStep (RealVisXL 6.6GB)
Step 6: VirtualFittingStep (OOTD 14GB)
Step 7: PostProcessingStep (ESRGAN 136MB)
Step 8: QualityAssessmentStep (OpenCLIP 5.2GB)

Author: MyCloset AI Team
Date: 2025-07-27
Version: 11.0 (DetailedDataSpec Complete Integration)
"""

import os
import sys
import logging
import asyncio
import time
import threading
import uuid
import gc
import traceback
import weakref
import json
import base64
from typing import Dict, Any, Optional, List, Union, Type, TYPE_CHECKING, Tuple  # â† Tuple ì¶”ê°€!
from datetime import datetime
from pathlib import Path
from dataclasses import dataclass, field
from enum import Enum
from functools import wraps
from concurrent.futures import ThreadPoolExecutor
from io import BytesIO


# ì•ˆì „í•œ íƒ€ì… íŒíŒ… (ìˆœí™˜ì°¸ì¡° ë°©ì§€)
if TYPE_CHECKING:
    from fastapi import UploadFile
    import torch
    import numpy as np
    from PIL import Image

# ==============================================
# ğŸ”¥ ë¡œê¹… ì„¤ì •
# ==============================================

logger = logging.getLogger(__name__)

# ==============================================
# ğŸ”¥ í™˜ê²½ ì •ë³´ ìˆ˜ì§‘
# ==============================================

# conda í™˜ê²½ ì •ë³´
CONDA_INFO = {
    'conda_env': os.environ.get('CONDA_DEFAULT_ENV', 'none'),
    'conda_prefix': os.environ.get('CONDA_PREFIX', 'none'),
    'is_target_env': os.environ.get('CONDA_DEFAULT_ENV') == 'mycloset-ai-clean'
}

# M3 Max ê°ì§€
IS_M3_MAX = False
MEMORY_GB = 16.0

try:
    import platform
    if platform.system() == 'Darwin' and platform.machine() == 'arm64':
        try:
            import subprocess
            result = subprocess.run(['sysctl', '-n', 'machdep.cpu.brand_string'], 
                                  capture_output=True, text=True, timeout=3)
            IS_M3_MAX = 'M3' in result.stdout
            
            memory_result = subprocess.run(['sysctl', '-n', 'hw.memsize'], 
                                         capture_output=True, text=True, timeout=3)
            if memory_result.stdout.strip():
                MEMORY_GB = int(memory_result.stdout.strip()) / 1024**3
        except:
            pass
except:
    pass

# ë””ë°”ì´ìŠ¤ ìë™ ê°ì§€
DEVICE = "cpu"
TORCH_AVAILABLE = False

try:
    import torch
    TORCH_AVAILABLE = True
    
    if IS_M3_MAX and hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
        DEVICE = "mps"
    elif torch.cuda.is_available():
        DEVICE = "cuda"
    else:
        DEVICE = "cpu"
except ImportError:
    pass

# NumPy ë° PIL ê°€ìš©ì„±
try:
    import numpy as np
    NUMPY_AVAILABLE = True
except ImportError:
    NUMPY_AVAILABLE = False

try:
    from PIL import Image
    PIL_AVAILABLE = True
except ImportError:
    PIL_AVAILABLE = False

logger.info(f"ğŸ”§ Step Implementations v11.0 í™˜ê²½: conda={CONDA_INFO['conda_env']}, M3 Max={IS_M3_MAX}, ë””ë°”ì´ìŠ¤={DEVICE}")

# ==============================================
# ğŸ”¥ step_model_requests.py ë™ì  Import (í•µì‹¬!)
# ==============================================

def get_step_model_requests():
    """step_model_requests.py ë™ì  import (DetailedDataSpec í¬í•¨)"""
    try:
        from ..ai_pipeline.utils.step_model_requests import (
            get_enhanced_step_request,
            get_step_data_structure_info,
            get_step_api_mapping,
            get_step_preprocessing_requirements,
            get_step_postprocessing_requirements,
            get_step_data_flow,
            get_fastapi_integration_plan,
            analyze_enhanced_step_requirements,
            REAL_STEP_MODEL_REQUESTS,
            EnhancedRealModelRequest,
            DetailedDataSpec,
            StepPriority,
            ModelSize
        )
        
        logger.info("âœ… step_model_requests.py ë™ì  import ì„±ê³µ (DetailedDataSpec í¬í•¨)")
        
        return {
            'get_enhanced_step_request': get_enhanced_step_request,
            'get_step_data_structure_info': get_step_data_structure_info,
            'get_step_api_mapping': get_step_api_mapping,
            'get_step_preprocessing_requirements': get_step_preprocessing_requirements,
            'get_step_postprocessing_requirements': get_step_postprocessing_requirements,
            'get_step_data_flow': get_step_data_flow,
            'get_fastapi_integration_plan': get_fastapi_integration_plan,
            'analyze_enhanced_step_requirements': analyze_enhanced_step_requirements,
            'REAL_STEP_MODEL_REQUESTS': REAL_STEP_MODEL_REQUESTS,
            'EnhancedRealModelRequest': EnhancedRealModelRequest,
            'DetailedDataSpec': DetailedDataSpec,
            'StepPriority': StepPriority,
            'ModelSize': ModelSize
        }
        
    except ImportError as e:
        logger.error(f"âŒ step_model_requests.py import ì‹¤íŒ¨: {e}")
        return None

# step_model_requests.py ë¡œë”©
STEP_MODEL_REQUESTS_COMPONENTS = get_step_model_requests()
STEP_MODEL_REQUESTS_AVAILABLE = STEP_MODEL_REQUESTS_COMPONENTS is not None

if STEP_MODEL_REQUESTS_AVAILABLE:
    get_enhanced_step_request = STEP_MODEL_REQUESTS_COMPONENTS['get_enhanced_step_request']
    get_step_data_structure_info = STEP_MODEL_REQUESTS_COMPONENTS['get_step_data_structure_info']
    get_step_api_mapping = STEP_MODEL_REQUESTS_COMPONENTS['get_step_api_mapping']
    get_step_preprocessing_requirements = STEP_MODEL_REQUESTS_COMPONENTS['get_step_preprocessing_requirements']
    get_step_postprocessing_requirements = STEP_MODEL_REQUESTS_COMPONENTS['get_step_postprocessing_requirements']
    get_step_data_flow = STEP_MODEL_REQUESTS_COMPONENTS['get_step_data_flow']
    REAL_STEP_MODEL_REQUESTS = STEP_MODEL_REQUESTS_COMPONENTS['REAL_STEP_MODEL_REQUESTS']
    StepPriority = STEP_MODEL_REQUESTS_COMPONENTS['StepPriority']
else:
    # í´ë°± ì •ì˜
    get_enhanced_step_request = lambda x: None
    get_step_data_structure_info = lambda x: {}
    get_step_api_mapping = lambda x: {}
    get_step_preprocessing_requirements = lambda x: {}
    get_step_postprocessing_requirements = lambda x: {}
    get_step_data_flow = lambda x: {}
    REAL_STEP_MODEL_REQUESTS = {}
    
    class StepPriority(Enum):
        CRITICAL = 1
        HIGH = 2
        MEDIUM = 3
        LOW = 4

# ==============================================
# ğŸ”¥ StepFactory v9.0 ë™ì  Import (ìˆœí™˜ì°¸ì¡° ë°©ì§€)
# ==============================================

def get_step_factory_v9():
    """StepFactory v9.0 ë™ì  import (BaseStepMixin ì™„ì „ í˜¸í™˜)"""
    try:
        from ..ai_pipeline.factories.step_factory import (
            get_global_step_factory,
            StepType,
            StepCreationResult,
            BaseStepMixinConfig,
            BaseStepMixinMapping,
            StepPriority as FactoryStepPriority,
            create_step,
            create_human_parsing_step,
            create_pose_estimation_step,
            create_cloth_segmentation_step,
            create_geometric_matching_step,
            create_cloth_warping_step,
            create_virtual_fitting_step,
            create_post_processing_step,
            create_quality_assessment_step,
            create_full_pipeline,
            optimize_conda_environment_for_basestepmixin,
            validate_basestepmixin_step_compatibility,
            get_basestepmixin_step_info
        )
        
        factory = get_global_step_factory()
        logger.info("âœ… StepFactory v9.0 ë™ì  import ì„±ê³µ (BaseStepMixin ì™„ì „ í˜¸í™˜)")
        
        return {
            'factory': factory,
            'StepType': StepType,
            'StepCreationResult': StepCreationResult,
            'BaseStepMixinConfig': BaseStepMixinConfig,
            'BaseStepMixinMapping': BaseStepMixinMapping,
            'create_step': create_step,
            'create_human_parsing_step': create_human_parsing_step,
            'create_pose_estimation_step': create_pose_estimation_step,
            'create_cloth_segmentation_step': create_cloth_segmentation_step,
            'create_geometric_matching_step': create_geometric_matching_step,
            'create_cloth_warping_step': create_cloth_warping_step,
            'create_virtual_fitting_step': create_virtual_fitting_step,
            'create_post_processing_step': create_post_processing_step,
            'create_quality_assessment_step': create_quality_assessment_step,
            'create_full_pipeline': create_full_pipeline,
            'optimize_conda_environment': optimize_conda_environment_for_basestepmixin,
            'validate_step_compatibility': validate_basestepmixin_step_compatibility,
            'get_step_info': get_basestepmixin_step_info
        }
        
    except ImportError as e:
        logger.error(f"âŒ StepFactory v9.0 import ì‹¤íŒ¨: {e}")
        return None

# StepFactory v9.0 ë¡œë”©
STEP_FACTORY_V9_COMPONENTS = get_step_factory_v9()
STEP_FACTORY_V9_AVAILABLE = STEP_FACTORY_V9_COMPONENTS is not None

if STEP_FACTORY_V9_AVAILABLE:
    STEP_FACTORY = STEP_FACTORY_V9_COMPONENTS['factory']
    StepType = STEP_FACTORY_V9_COMPONENTS['StepType']
    StepCreationResult = STEP_FACTORY_V9_COMPONENTS['StepCreationResult']
    BaseStepMixinConfig = STEP_FACTORY_V9_COMPONENTS['BaseStepMixinConfig']
    BaseStepMixinMapping = STEP_FACTORY_V9_COMPONENTS['BaseStepMixinMapping']
else:
    STEP_FACTORY = None
    
    # í´ë°± í´ë˜ìŠ¤ë“¤ ì •ì˜
    class StepType(Enum):
        HUMAN_PARSING = "human_parsing"
        POSE_ESTIMATION = "pose_estimation"
        CLOTH_SEGMENTATION = "cloth_segmentation"
        GEOMETRIC_MATCHING = "geometric_matching"
        CLOTH_WARPING = "cloth_warping"
        VIRTUAL_FITTING = "virtual_fitting"
        POST_PROCESSING = "post_processing"
        QUALITY_ASSESSMENT = "quality_assessment"
    
    @dataclass
    class StepCreationResult:
        success: bool
        step_instance: Optional[Any] = None
        step_name: str = ""
        error_message: Optional[str] = None
        creation_time: float = 0.0
        basestepmixin_compatible: bool = False

# ==============================================
# ğŸ”¥ Stepëª… ë§¤í•‘ (step_model_requests.py ê¸°ë°˜)
# ==============================================

# step_model_requests.pyì—ì„œ ì •ì˜ëœ ì‹¤ì œ Step í´ë˜ìŠ¤ëª…ë“¤
STEP_NAME_TO_CLASS_MAPPING = {
    "HumanParsingStep": StepType.HUMAN_PARSING,
    "PoseEstimationStep": StepType.POSE_ESTIMATION,
    "ClothSegmentationStep": StepType.CLOTH_SEGMENTATION,
    "GeometricMatchingStep": StepType.GEOMETRIC_MATCHING,
    "ClothWarpingStep": StepType.CLOTH_WARPING,
    "VirtualFittingStep": StepType.VIRTUAL_FITTING,
    "PostProcessingStep": StepType.POST_PROCESSING,
    "QualityAssessmentStep": StepType.QUALITY_ASSESSMENT
}

STEP_ID_TO_NAME_MAPPING = {
    1: "HumanParsingStep",
    2: "PoseEstimationStep",
    3: "ClothSegmentationStep",
    4: "GeometricMatchingStep",
    5: "ClothWarpingStep",
    6: "VirtualFittingStep",
    7: "PostProcessingStep",
    8: "QualityAssessmentStep"
}

# ê¸°ì¡´ API í˜¸í™˜ì„±ì„ ìœ„í•œ í•¨ìˆ˜ëª… ë§¤í•‘
IMPLEMENTATION_FUNCTION_MAPPING = {
    1: "process_human_parsing_implementation",
    2: "process_pose_estimation_implementation",
    3: "process_cloth_segmentation_implementation",
    4: "process_geometric_matching_implementation",
    5: "process_cloth_warping_implementation",
    6: "process_virtual_fitting_implementation",
    7: "process_post_processing_implementation",
    8: "process_quality_assessment_implementation"
}

# ==============================================
# ğŸ”¥ Data Transformation Utilities (DetailedDataSpec ê¸°ë°˜)
# ==============================================

class DataTransformationUtils:
    """DetailedDataSpec ê¸°ë°˜ ë°ì´í„° ë³€í™˜ ìœ í‹¸ë¦¬í‹°"""
    
    @staticmethod
    def transform_api_input_to_step_input(step_name: str, api_input: Dict[str, Any]) -> Dict[str, Any]:
        """API ì…ë ¥ì„ Step ì…ë ¥ìœ¼ë¡œ ë³€í™˜ (api_input_mapping í™œìš©)"""
        try:
            if not STEP_MODEL_REQUESTS_AVAILABLE:
                return api_input
            
            # Stepì˜ API ë§¤í•‘ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            api_mapping = get_step_api_mapping(step_name)
            if not api_mapping or 'input_mapping' not in api_mapping:
                return api_input
            
            input_mapping = api_mapping['input_mapping']
            step_input = {}
            
            # api_input_mappingì— ë”°ë¼ ë³€í™˜
            for step_field, api_type in input_mapping.items():
                if step_field in api_input:
                    value = api_input[step_field]
                    
                    # UploadFile â†’ PIL.Image ë³€í™˜
                    if "UploadFile" in api_type and hasattr(value, 'file'):
                        try:
                            if PIL_AVAILABLE:
                                image_bytes = value.file.read()
                                image = Image.open(BytesIO(image_bytes))
                                step_input[step_field] = image
                            else:
                                step_input[step_field] = value
                        except Exception as e:
                            logger.warning(f"âš ï¸ UploadFile ë³€í™˜ ì‹¤íŒ¨ {step_field}: {e}")
                            step_input[step_field] = value
                    else:
                        step_input[step_field] = value
            
            # ë³€í™˜ë˜ì§€ ì•Šì€ í•„ë“œë“¤ ê·¸ëŒ€ë¡œ ë³µì‚¬
            for key, value in api_input.items():
                if key not in step_input:
                    step_input[key] = value
            
            logger.debug(f"ğŸ”„ API ì…ë ¥ ë³€í™˜ ì™„ë£Œ {step_name}: {len(api_input)} â†’ {len(step_input)}")
            return step_input
            
        except Exception as e:
            logger.error(f"âŒ API ì…ë ¥ ë³€í™˜ ì‹¤íŒ¨ {step_name}: {e}")
            return api_input
    
    @staticmethod
    def transform_step_output_to_api_output(step_name: str, step_output: Dict[str, Any]) -> Dict[str, Any]:
        """Step ì¶œë ¥ì„ API ì¶œë ¥ìœ¼ë¡œ ë³€í™˜ (api_output_mapping í™œìš©)"""
        try:
            if not STEP_MODEL_REQUESTS_AVAILABLE:
                return step_output
            
            # Stepì˜ API ë§¤í•‘ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            api_mapping = get_step_api_mapping(step_name)
            if not api_mapping or 'output_mapping' not in api_mapping:
                return step_output
            
            output_mapping = api_mapping['output_mapping']
            api_output = {}
            
            # api_output_mappingì— ë”°ë¼ ë³€í™˜
            for api_field, api_type in output_mapping.items():
                # Step ì¶œë ¥ì—ì„œ í•´ë‹¹ í•„ë“œ ì°¾ê¸°
                step_field = api_field  # ê¸°ë³¸ì ìœ¼ë¡œ ë™ì¼í•œ ì´ë¦„
                
                if step_field in step_output:
                    value = step_output[step_field]
                    
                    # numpy.ndarray â†’ base64_string ë³€í™˜
                    if "base64_string" in api_type and NUMPY_AVAILABLE:
                        try:
                            if isinstance(value, np.ndarray):
                                # numpy arrayë¥¼ ì´ë¯¸ì§€ë¡œ ë³€í™˜ í›„ base64 ì¸ì½”ë”©
                                if PIL_AVAILABLE:
                                    # ì •ê·œí™” (0-1 â†’ 0-255)
                                    if value.dtype == np.float32 or value.dtype == np.float64:
                                        if value.max() <= 1.0:
                                            value = (value * 255).astype(np.uint8)
                                    
                                    # ì±„ë„ ìˆœì„œ ë³€ê²½ (CHW â†’ HWC)
                                    if len(value.shape) == 3 and value.shape[0] == 3:
                                        value = np.transpose(value, (1, 2, 0))
                                    
                                    image = Image.fromarray(value)
                                    buffer = BytesIO()
                                    image.save(buffer, format='PNG')
                                    image_base64 = base64.b64encode(buffer.getvalue()).decode('utf-8')
                                    api_output[api_field] = image_base64
                                else:
                                    api_output[api_field] = str(value)
                            else:
                                api_output[api_field] = value
                        except Exception as e:
                            logger.warning(f"âš ï¸ base64 ë³€í™˜ ì‹¤íŒ¨ {api_field}: {e}")
                            api_output[api_field] = str(value)
                    else:
                        api_output[api_field] = value
            
            # ê¸°ë³¸ ì‘ë‹µ í•„ë“œë“¤ ì¶”ê°€
            api_output.setdefault('success', step_output.get('success', True))
            api_output.setdefault('processing_time', step_output.get('processing_time', 0.0))
            api_output.setdefault('step_name', step_name)
            
            # ë³€í™˜ë˜ì§€ ì•Šì€ ì¤‘ìš” í•„ë“œë“¤ ë³µì‚¬
            for key in ['error', 'confidence', 'quality_score']:
                if key in step_output and key not in api_output:
                    api_output[key] = step_output[key]
            
            logger.debug(f"ğŸ”„ API ì¶œë ¥ ë³€í™˜ ì™„ë£Œ {step_name}: {len(step_output)} â†’ {len(api_output)}")
            return api_output
            
        except Exception as e:
            logger.error(f"âŒ API ì¶œë ¥ ë³€í™˜ ì‹¤íŒ¨ {step_name}: {e}")
            return step_output
    
    @staticmethod
    def prepare_next_step_data(step_name: str, step_output: Dict[str, Any]) -> Dict[str, Dict[str, Any]]:
        """ë‹¤ìŒ Stepë“¤ì„ ìœ„í•œ ë°ì´í„° ì¤€ë¹„ (provides_to_next_step í™œìš©)"""
        try:
            if not STEP_MODEL_REQUESTS_AVAILABLE:
                return {}
            
            # Stepì˜ ë°ì´í„° íë¦„ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            data_flow = get_step_data_flow(step_name)
            if not data_flow or 'provides_to_next_step' not in data_flow:
                return {}
            
            provides_to_next_step = data_flow['provides_to_next_step']
            next_step_data = {}
            
            # ê° ë‹¤ìŒ Stepë³„ë¡œ ë°ì´í„° ì¤€ë¹„
            for next_step, data_schema in provides_to_next_step.items():
                if next_step not in next_step_data:
                    next_step_data[next_step] = {}
                
                # ìŠ¤í‚¤ë§ˆì— ì •ì˜ëœ í•„ë“œë“¤ ë§¤í•‘
                for field_name, field_type in data_schema.items():
                    if field_name in step_output:
                        value = step_output[field_name]
                        
                        # íƒ€ì… ë³€í™˜ (í•„ìš”ì‹œ)
                        if "np.ndarray" in field_type and NUMPY_AVAILABLE:
                            if not isinstance(value, np.ndarray):
                                try:
                                    value = np.array(value)
                                except:
                                    pass
                        elif "List" in field_type:
                            if not isinstance(value, list):
                                try:
                                    value = list(value) if hasattr(value, '__iter__') else [value]
                                except:
                                    pass
                        elif "Dict" in field_type:
                            if not isinstance(value, dict):
                                try:
                                    value = dict(value) if hasattr(value, 'items') else {'value': value}
                                except:
                                    value = {'value': value}
                        
                        next_step_data[next_step][field_name] = value
            
            logger.debug(f"ğŸ”„ ë‹¤ìŒ Step ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ {step_name}: {len(provides_to_next_step)}ê°œ Step")
            return next_step_data
            
        except Exception as e:
            logger.error(f"âŒ ë‹¤ìŒ Step ë°ì´í„° ì¤€ë¹„ ì‹¤íŒ¨ {step_name}: {e}")
            return {}

# ==============================================
# ğŸ”¥ DetailedDataSpec ê¸°ë°˜ Step ì²˜ë¦¬ ë¸Œë¦¿ì§€ v11.0
# ==============================================

class DetailedDataSpecStepBridge:
    """DetailedDataSpec ì™„ì „ ë°˜ì˜ Step ì²˜ë¦¬ ë¸Œë¦¿ì§€ v11.0"""
    
    def __init__(self):
        self.logger = logging.getLogger(f"{__name__}.DetailedDataSpecStepBridge")
        self._step_cache: Dict[str, weakref.ref] = {}
        self._lock = threading.RLock()
        
        # ì„±ëŠ¥ ë©”íŠ¸ë¦­
        self.metrics = {
            'total_requests': 0,
            'successful_requests': 0,
            'failed_requests': 0,
            'api_transformations': 0,
            'step_data_flows': 0,
            'preprocessing_applications': 0,
            'postprocessing_applications': 0,
            'detailed_dataspec_usages': 0
        }
        
        self.logger.info("ğŸŒ‰ DetailedDataSpec Step ë¸Œë¦¿ì§€ v11.0 ì´ˆê¸°í™” ì™„ë£Œ")
    
    async def process_step_with_detailed_spec(
        self,
        step_name: str,
        api_input: Dict[str, Any],
        session_id: Optional[str] = None,
        **kwargs
    ) -> Dict[str, Any]:
        """DetailedDataSpec ê¸°ë°˜ Step ì²˜ë¦¬ (ì™„ì „í•œ API íë¦„)"""
        start_time = time.time()
        
        try:
            with self._lock:
                self.metrics['total_requests'] += 1
            
            self.logger.info(f"ğŸ”„ DetailedDataSpec ê¸°ë°˜ {step_name} ì²˜ë¦¬ ì‹œì‘...")
            
            # 1. DetailedDataSpec ì •ë³´ ë¡œë”©
            if STEP_MODEL_REQUESTS_AVAILABLE:
                step_request = get_enhanced_step_request(step_name)
                data_structure_info = get_step_data_structure_info(step_name)
                preprocessing_req = get_step_preprocessing_requirements(step_name)
                postprocessing_req = get_step_postprocessing_requirements(step_name)
                
                if not step_request or not data_structure_info:
                    raise ValueError(f"DetailedDataSpec ì •ë³´ ì—†ìŒ: {step_name}")
                
                self.logger.debug(f"ğŸ“‹ {step_name} DetailedDataSpec ë¡œë”© ì™„ë£Œ")
            else:
                raise RuntimeError("step_model_requests.pyë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            
            # 2. API ì…ë ¥ â†’ Step ì…ë ¥ ë³€í™˜ (api_input_mapping)
            step_input = DataTransformationUtils.transform_api_input_to_step_input(step_name, api_input)
            with self._lock:
                self.metrics['api_transformations'] += 1
            
            # 3. ì „ì²˜ë¦¬ ì ìš© (preprocessing_steps)
            if preprocessing_req and preprocessing_req.get('preprocessing_steps'):
                step_input = await self._apply_preprocessing(step_name, step_input, preprocessing_req)
                with self._lock:
                    self.metrics['preprocessing_applications'] += 1
            
            # 4. StepFactoryë¡œ Step ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ë° ì²˜ë¦¬
            if STEP_FACTORY_V9_AVAILABLE and STEP_FACTORY:
                # Step íƒ€ì… ê²°ì •
                step_type = STEP_NAME_TO_CLASS_MAPPING.get(step_name)
                if not step_type:
                    raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” Step: {step_name}")
                
                # DetailedDataSpec ê¸°ë°˜ ì„¤ì • ì¤€ë¹„
                step_config = {
                    'detailed_data_spec': data_structure_info.get('detailed_data_spec', {}),
                    'session_id': session_id,
                    'conda_optimized': CONDA_INFO['is_target_env'],
                    'm3_max_optimized': IS_M3_MAX,
                    'device': DEVICE,
                    **kwargs
                }
                
                # Step ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
                result = STEP_FACTORY.create_step(step_type, use_cache=True, **step_config)
                
                if not result.success:
                    raise RuntimeError(f"Step ìƒì„± ì‹¤íŒ¨: {result.error_message}")
                
                step_instance = result.step_instance
                
                # Step ì²˜ë¦¬ ì‹¤í–‰
                if hasattr(step_instance, 'process'):
                    if asyncio.iscoroutinefunction(step_instance.process):
                        step_output = await step_instance.process(step_input, **step_config)
                    else:
                        step_output = step_instance.process(step_input, **step_config)
                else:
                    raise AttributeError(f"{step_name}ì— process ë©”ì„œë“œê°€ ì—†ìŠµë‹ˆë‹¤")
            else:
                raise RuntimeError("StepFactory v9.0ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            
            # 5. í›„ì²˜ë¦¬ ì ìš© (postprocessing_steps)
            if postprocessing_req and postprocessing_req.get('postprocessing_steps'):
                step_output = await self._apply_postprocessing(step_name, step_output, postprocessing_req)
                with self._lock:
                    self.metrics['postprocessing_applications'] += 1
            
            # 6. Step ì¶œë ¥ â†’ API ì¶œë ¥ ë³€í™˜ (api_output_mapping)
            api_output = DataTransformationUtils.transform_step_output_to_api_output(step_name, step_output)
            
            # 7. ë‹¤ìŒ Step ë°ì´í„° ì¤€ë¹„ (provides_to_next_step)
            next_step_data = DataTransformationUtils.prepare_next_step_data(step_name, step_output)
            if next_step_data:
                api_output['next_step_data'] = next_step_data
                with self._lock:
                    self.metrics['step_data_flows'] += 1
            
            # 8. ë©”íƒ€ë°ì´í„° ì¶”ê°€
            processing_time = time.time() - start_time
            api_output.update({
                'processing_time': processing_time,
                'detailed_dataspec_applied': True,
                'step_priority': step_request.step_priority.name,
                'model_architecture': step_request.model_architecture,
                'timestamp': datetime.now().isoformat()
            })
            
            # ì„±ê³µ ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
            with self._lock:
                self.metrics['successful_requests'] += 1
                self.metrics['detailed_dataspec_usages'] += 1
            
            self.logger.info(f"âœ… {step_name} DetailedDataSpec ì²˜ë¦¬ ì™„ë£Œ ({processing_time:.2f}ì´ˆ)")
            return api_output
            
        except Exception as e:
            with self._lock:
                self.metrics['failed_requests'] += 1
            
            error_time = time.time() - start_time
            self.logger.error(f"âŒ {step_name} DetailedDataSpec ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            
            return {
                'success': False,
                'error': str(e),
                'step_name': step_name,
                'error_type': type(e).__name__,
                'processing_time': error_time,
                'detailed_dataspec_applied': False,
                'timestamp': datetime.now().isoformat()
            }
    
    async def _apply_preprocessing(self, step_name: str, step_input: Dict[str, Any], preprocessing_req: Dict[str, Any]) -> Dict[str, Any]:
        """ì „ì²˜ë¦¬ ë‹¨ê³„ ì ìš© (preprocessing_steps ê¸°ë°˜)"""
        try:
            preprocessing_steps = preprocessing_req.get('preprocessing_steps', [])
            normalization_mean = preprocessing_req.get('normalization_mean', (0.485, 0.456, 0.406))
            normalization_std = preprocessing_req.get('normalization_std', (0.229, 0.224, 0.225))
            input_shapes = preprocessing_req.get('input_shapes', {})
            input_value_ranges = preprocessing_req.get('input_value_ranges', {})
            
            processed_input = step_input.copy()
            
            # ê° ì „ì²˜ë¦¬ ë‹¨ê³„ ì ìš©
            for step in preprocessing_steps:
                if "resize" in step.lower():
                    # ë¦¬ì‚¬ì´ì¦ˆ ì²˜ë¦¬
                    target_size = self._extract_size_from_step(step, input_shapes)
                    processed_input = await self._apply_resize(processed_input, target_size)
                
                elif "normalize" in step.lower():
                    # ì •ê·œí™” ì²˜ë¦¬
                    if "imagenet" in step.lower():
                        processed_input = await self._apply_normalization(processed_input, normalization_mean, normalization_std)
                    elif "centered" in step.lower():
                        processed_input = await self._apply_normalization(processed_input, (0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
                    elif "0_1" in step or "zero_one" in step.lower():
                        processed_input = await self._apply_normalization(processed_input, (0.0, 0.0, 0.0), (1.0, 1.0, 1.0))
                
                elif "to_tensor" in step.lower():
                    # Tensor ë³€í™˜
                    processed_input = await self._apply_to_tensor(processed_input)
                
                elif "prepare" in step.lower():
                    # íŠ¹ìˆ˜ ì¤€ë¹„ ë‹¨ê³„
                    processed_input = await self._apply_special_preparation(step_name, processed_input, step)
            
            self.logger.debug(f"ğŸ”§ {step_name} ì „ì²˜ë¦¬ ì™„ë£Œ: {len(preprocessing_steps)}ë‹¨ê³„")
            return processed_input
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ {step_name} ì „ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return step_input
    
    async def _apply_postprocessing(self, step_name: str, step_output: Dict[str, Any], postprocessing_req: Dict[str, Any]) -> Dict[str, Any]:
        """í›„ì²˜ë¦¬ ë‹¨ê³„ ì ìš© (postprocessing_steps ê¸°ë°˜)"""
        try:
            postprocessing_steps = postprocessing_req.get('postprocessing_steps', [])
            output_value_ranges = postprocessing_req.get('output_value_ranges', {})
            output_shapes = postprocessing_req.get('output_shapes', {})
            
            processed_output = step_output.copy()
            
            # ê° í›„ì²˜ë¦¬ ë‹¨ê³„ ì ìš©
            for step in postprocessing_steps:
                if "argmax" in step.lower():
                    # argmax ì ìš©
                    processed_output = await self._apply_argmax(processed_output)
                
                elif "softmax" in step.lower():
                    # softmax ì ìš©
                    processed_output = await self._apply_softmax(processed_output)
                
                elif "threshold" in step.lower():
                    # ì„ê³„ê°’ ì ìš©
                    threshold = self._extract_threshold_from_step(step)
                    processed_output = await self._apply_threshold(processed_output, threshold)
                
                elif "resize" in step.lower():
                    # ì›ë³¸ í¬ê¸°ë¡œ ë³µì›
                    if "original" in step.lower():
                        processed_output = await self._apply_resize_to_original(processed_output)
                
                elif "denormalize" in step.lower():
                    # ì—­ì •ê·œí™”
                    if "diffusion" in step.lower():
                        processed_output = await self._apply_denormalization(processed_output, (0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
                    elif "imagenet" in step.lower():
                        processed_output = await self._apply_denormalization(processed_output, (0.485, 0.456, 0.406), (0.229, 0.224, 0.225))
                
                elif "to_numpy" in step.lower():
                    # NumPy ë³€í™˜
                    processed_output = await self._apply_to_numpy(processed_output)
                
                elif "enhance" in step.lower() or "quality" in step.lower():
                    # í’ˆì§ˆ í–¥ìƒ ì²˜ë¦¬
                    processed_output = await self._apply_quality_enhancement(step_name, processed_output, step)
            
            self.logger.debug(f"ğŸ”§ {step_name} í›„ì²˜ë¦¬ ì™„ë£Œ: {len(postprocessing_steps)}ë‹¨ê³„")
            return processed_output
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ {step_name} í›„ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return step_output
    
    # ==============================================
    # ğŸ”¥ ì „ì²˜ë¦¬/í›„ì²˜ë¦¬ í—¬í¼ ë©”ì„œë“œë“¤
    # ==============================================
    
    def _extract_size_from_step(self, step: str, input_shapes: Dict[str, Any]) -> Tuple[int, int]:
        """ì „ì²˜ë¦¬ ë‹¨ê³„ì—ì„œ í¬ê¸° ì¶”ì¶œ"""
        # "resize_512x512" í˜•íƒœì—ì„œ í¬ê¸° ì¶”ì¶œ
        import re
        size_match = re.search(r'(\d+)x(\d+)', step)
        if size_match:
            width, height = int(size_match.group(1)), int(size_match.group(2))
            return (height, width)
        
        # input_shapesì—ì„œ ê¸°ë³¸ í¬ê¸° ì°¾ê¸°
        for shape_key, shape_value in input_shapes.items():
            if isinstance(shape_value, (list, tuple)) and len(shape_value) >= 2:
                if len(shape_value) == 3:  # CHW
                    return (shape_value[1], shape_value[2])
                elif len(shape_value) == 2:  # HW
                    return (shape_value[0], shape_value[1])
        
        return (512, 512)  # ê¸°ë³¸ê°’
    
    def _extract_threshold_from_step(self, step: str) -> float:
        """í›„ì²˜ë¦¬ ë‹¨ê³„ì—ì„œ ì„ê³„ê°’ ì¶”ì¶œ"""
        import re
        threshold_match = re.search(r'threshold[_\-]?(\d+\.?\d*)', step)
        if threshold_match:
            return float(threshold_match.group(1))
        return 0.5  # ê¸°ë³¸ê°’
    
    async def _apply_resize(self, data: Dict[str, Any], target_size: Tuple[int, int]) -> Dict[str, Any]:
        """ë¦¬ì‚¬ì´ì¦ˆ ì ìš©"""
        try:
            processed_data = data.copy()
            
            for key, value in data.items():
                if isinstance(value, Image.Image) and PIL_AVAILABLE:
                    processed_data[key] = value.resize((target_size[1], target_size[0]))
                elif NUMPY_AVAILABLE and isinstance(value, np.ndarray):
                    if len(value.shape) >= 2:
                        try:
                            import cv2
                            if len(value.shape) == 3:
                                processed_data[key] = cv2.resize(value, (target_size[1], target_size[0]))
                            else:
                                processed_data[key] = cv2.resize(value, (target_size[1], target_size[0]))
                        except ImportError:
                            # cv2 ì—†ìœ¼ë©´ PIL ì‚¬ìš©
                            if PIL_AVAILABLE:
                                if len(value.shape) == 3:
                                    value = np.transpose(value, (1, 2, 0))
                                img = Image.fromarray((value * 255).astype(np.uint8))
                                img = img.resize((target_size[1], target_size[0]))
                                processed_data[key] = np.array(img) / 255.0
            
            return processed_data
        except Exception as e:
            self.logger.warning(f"âš ï¸ ë¦¬ì‚¬ì´ì¦ˆ ì‹¤íŒ¨: {e}")
            return data
    
    async def _apply_normalization(self, data: Dict[str, Any], mean: Tuple[float, ...], std: Tuple[float, ...]) -> Dict[str, Any]:
        """ì •ê·œí™” ì ìš©"""
        try:
            processed_data = data.copy()
            
            for key, value in data.items():
                if NUMPY_AVAILABLE and isinstance(value, np.ndarray):
                    if len(value.shape) == 3 and value.shape[2] == 3:  # HWC
                        normalized = (value - np.array(mean)) / np.array(std)
                        processed_data[key] = normalized
                    elif len(value.shape) == 3 and value.shape[0] == 3:  # CHW
                        mean_array = np.array(mean).reshape(-1, 1, 1)
                        std_array = np.array(std).reshape(-1, 1, 1)
                        normalized = (value - mean_array) / std_array
                        processed_data[key] = normalized
                elif PIL_AVAILABLE and isinstance(value, Image.Image):
                    # PIL Imageë¥¼ numpyë¡œ ë³€í™˜ í›„ ì •ê·œí™”
                    np_image = np.array(value) / 255.0
                    normalized = (np_image - np.array(mean)) / np.array(std)
                    processed_data[key] = normalized
            
            return processed_data
        except Exception as e:
            self.logger.warning(f"âš ï¸ ì •ê·œí™” ì‹¤íŒ¨: {e}")
            return data
    
    async def _apply_to_tensor(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """Tensor ë³€í™˜ ì ìš©"""
        try:
            processed_data = data.copy()
            
            if TORCH_AVAILABLE:
                import torch
                for key, value in data.items():
                    if NUMPY_AVAILABLE and isinstance(value, np.ndarray):
                        processed_data[key] = torch.from_numpy(value.copy()).float()
                    elif PIL_AVAILABLE and isinstance(value, Image.Image):
                        np_image = np.array(value) / 255.0
                        if len(np_image.shape) == 3:
                            np_image = np.transpose(np_image, (2, 0, 1))  # HWC â†’ CHW
                        processed_data[key] = torch.from_numpy(np_image.copy()).float()
            
            return processed_data
        except Exception as e:
            self.logger.warning(f"âš ï¸ Tensor ë³€í™˜ ì‹¤íŒ¨: {e}")
            return data
    
    async def _apply_special_preparation(self, step_name: str, data: Dict[str, Any], step: str) -> Dict[str, Any]:
        """íŠ¹ìˆ˜ ì¤€ë¹„ ë‹¨ê³„ ì ìš©"""
        try:
            processed_data = data.copy()
            
            if "sam" in step.lower() and "prompts" in step.lower():
                # SAM í”„ë¡¬í”„íŠ¸ ì¤€ë¹„
                if 'prompt_points' not in processed_data:
                    # ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ í¬ì¸íŠ¸ ìƒì„±
                    processed_data['prompt_points'] = [[256, 256]]  # ì¤‘ì•™ì 
                    processed_data['prompt_labels'] = [1]  # í¬ì§€í‹°ë¸Œ
            
            elif "diffusion" in step.lower():
                # Diffusion ì…ë ¥ ì¤€ë¹„
                if 'timesteps' not in processed_data:
                    processed_data['timesteps'] = 50  # ê¸°ë³¸ ìŠ¤í… ìˆ˜
                if 'guidance_scale' not in processed_data:
                    processed_data['guidance_scale'] = 7.5  # ê¸°ë³¸ ê°€ì´ë˜ìŠ¤
            
            elif "ootd" in step.lower():
                # OOTD ì…ë ¥ ì¤€ë¹„
                if 'fitting_mode' not in processed_data:
                    processed_data['fitting_mode'] = 'hd'  # ê¸°ë³¸ ëª¨ë“œ
            
            return processed_data
        except Exception as e:
            self.logger.warning(f"âš ï¸ íŠ¹ìˆ˜ ì¤€ë¹„ ì‹¤íŒ¨: {e}")
            return data
    
    async def _apply_argmax(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """argmax ì ìš©"""
        try:
            processed_data = data.copy()
            
            if NUMPY_AVAILABLE:
                for key, value in data.items():
                    if isinstance(value, np.ndarray) and len(value.shape) > 1:
                        # í´ë˜ìŠ¤ ì°¨ì›ì—ì„œ argmax
                        if len(value.shape) == 4:  # NCHW
                            processed_data[key] = np.argmax(value, axis=1)
                        elif len(value.shape) == 3:  # CHW
                            processed_data[key] = np.argmax(value, axis=0)
            
            return processed_data
        except Exception as e:
            self.logger.warning(f"âš ï¸ argmax ì‹¤íŒ¨: {e}")
            return data
    
    async def _apply_softmax(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """softmax ì ìš©"""
        try:
            processed_data = data.copy()
            
            if NUMPY_AVAILABLE:
                for key, value in data.items():
                    if isinstance(value, np.ndarray):
                        # softmax ê³„ì‚°
                        exp_values = np.exp(value - np.max(value, axis=-1, keepdims=True))
                        processed_data[key] = exp_values / np.sum(exp_values, axis=-1, keepdims=True)
            
            return processed_data
        except Exception as e:
            self.logger.warning(f"âš ï¸ softmax ì‹¤íŒ¨: {e}")
            return data
    
    async def _apply_threshold(self, data: Dict[str, Any], threshold: float) -> Dict[str, Any]:
        """ì„ê³„ê°’ ì ìš©"""
        try:
            processed_data = data.copy()
            
            if NUMPY_AVAILABLE:
                for key, value in data.items():
                    if isinstance(value, np.ndarray):
                        processed_data[key] = (value > threshold).astype(np.float32)
            
            return processed_data
        except Exception as e:
            self.logger.warning(f"âš ï¸ ì„ê³„ê°’ ì ìš© ì‹¤íŒ¨: {e}")
            return data
    
    async def _apply_resize_to_original(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """ì›ë³¸ í¬ê¸°ë¡œ ë³µì›"""
        # ì‹¤ì œë¡œëŠ” ì›ë³¸ í¬ê¸° ì •ë³´ê°€ í•„ìš”í•˜ë¯€ë¡œ ì—¬ê¸°ì„œëŠ” ê¸°ë³¸ êµ¬í˜„ë§Œ
        return data
    
    async def _apply_denormalization(self, data: Dict[str, Any], mean: Tuple[float, ...], std: Tuple[float, ...]) -> Dict[str, Any]:
        """ì—­ì •ê·œí™” ì ìš©"""
        try:
            processed_data = data.copy()
            
            if NUMPY_AVAILABLE:
                for key, value in data.items():
                    if isinstance(value, np.ndarray):
                        if len(value.shape) == 3 and value.shape[2] == 3:  # HWC
                            denormalized = value * np.array(std) + np.array(mean)
                            processed_data[key] = np.clip(denormalized, 0, 1)
                        elif len(value.shape) == 3 and value.shape[0] == 3:  # CHW
                            std_array = np.array(std).reshape(-1, 1, 1)
                            mean_array = np.array(mean).reshape(-1, 1, 1)
                            denormalized = value * std_array + mean_array
                            processed_data[key] = np.clip(denormalized, 0, 1)
            
            return processed_data
        except Exception as e:
            self.logger.warning(f"âš ï¸ ì—­ì •ê·œí™” ì‹¤íŒ¨: {e}")
            return data
    
    async def _apply_to_numpy(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """NumPy ë³€í™˜ ì ìš©"""
        try:
            processed_data = data.copy()
            
            if TORCH_AVAILABLE:
                import torch
                for key, value in data.items():
                    if isinstance(value, torch.Tensor):
                        processed_data[key] = value.detach().cpu().numpy()
            
            return processed_data
        except Exception as e:
            self.logger.warning(f"âš ï¸ NumPy ë³€í™˜ ì‹¤íŒ¨: {e}")
            return data
    
    async def _apply_quality_enhancement(self, step_name: str, data: Dict[str, Any], step: str) -> Dict[str, Any]:
        """í’ˆì§ˆ í–¥ìƒ ì²˜ë¦¬"""
        try:
            processed_data = data.copy()
            
            # í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°
            if 'quality_score' not in processed_data:
                processed_data['quality_score'] = 0.85  # ê¸°ë³¸ í’ˆì§ˆ ì ìˆ˜
            
            # ì‹ ë¢°ë„ ê³„ì‚°
            if 'confidence' not in processed_data:
                processed_data['confidence'] = 0.90  # ê¸°ë³¸ ì‹ ë¢°ë„
            
            return processed_data
        except Exception as e:
            self.logger.warning(f"âš ï¸ í’ˆì§ˆ í–¥ìƒ ì‹¤íŒ¨: {e}")
            return data
    
    def get_metrics(self) -> Dict[str, Any]:
        """ë¸Œë¦¿ì§€ ë©”íŠ¸ë¦­ ë°˜í™˜"""
        with self._lock:
            success_rate = self.metrics['successful_requests'] / max(1, self.metrics['total_requests'])
            
            return {
                'bridge_version': 'v11.0',
                'detailed_dataspec_version': 'v8.0',
                'total_requests': self.metrics['total_requests'],
                'successful_requests': self.metrics['successful_requests'],
                'failed_requests': self.metrics['failed_requests'],
                'success_rate': round(success_rate * 100, 2),
                'api_transformations': self.metrics['api_transformations'],
                'step_data_flows': self.metrics['step_data_flows'],
                'preprocessing_applications': self.metrics['preprocessing_applications'],
                'postprocessing_applications': self.metrics['postprocessing_applications'],
                'detailed_dataspec_usages': self.metrics['detailed_dataspec_usages'],
                'step_model_requests_available': STEP_MODEL_REQUESTS_AVAILABLE,
                'step_factory_v9_available': STEP_FACTORY_V9_AVAILABLE,
                'environment': {
                    'conda_env': CONDA_INFO['conda_env'],
                    'conda_optimized': CONDA_INFO['is_target_env'],
                    'device': DEVICE,
                    'is_m3_max': IS_M3_MAX,
                    'memory_gb': MEMORY_GB,
                    'torch_available': TORCH_AVAILABLE,
                    'numpy_available': NUMPY_AVAILABLE,
                    'pil_available': PIL_AVAILABLE
                }
            }
    
    def clear_cache(self):
        """ìºì‹œ ì •ë¦¬"""
        try:
            with self._lock:
                self._step_cache.clear()
            
            # ë©”ëª¨ë¦¬ ì •ë¦¬
            if TORCH_AVAILABLE:
                if DEVICE == "mps" and IS_M3_MAX:
                    import torch
                    if hasattr(torch.backends, 'mps') and hasattr(torch.backends.mps, 'empty_cache'):
                        torch.backends.mps.empty_cache()
                elif DEVICE == "cuda":
                    import torch
                    torch.cuda.empty_cache()
            
            gc.collect()
            self.logger.info("ğŸ§¹ DetailedDataSpec ë¸Œë¦¿ì§€ ìºì‹œ ì •ë¦¬ ì™„ë£Œ")
            
        except Exception as e:
            self.logger.error(f"âŒ ìºì‹œ ì •ë¦¬ ì‹¤íŒ¨: {e}")

# ==============================================
# ğŸ”¥ Step Implementation Manager v11.0 (DetailedDataSpec ê¸°ë°˜)
# ==============================================

class StepImplementationManager:
    """Step Implementation Manager v11.0 - DetailedDataSpec ì™„ì „ ë°˜ì˜"""
    
    def __init__(self):
        self.logger = logging.getLogger(f"{__name__}.StepImplementationManager")
        self.bridge = DetailedDataSpecStepBridge()
        self._lock = threading.RLock()
        
        # ì „ì²´ ë§¤ë‹ˆì € ë©”íŠ¸ë¦­
        self.manager_metrics = {
            'manager_version': 'v11.0',
            'detailed_dataspec_version': 'v8.0',
            'step_factory_version': 'v9.0',
            'start_time': datetime.now(),
            'total_implementations': len(STEP_ID_TO_NAME_MAPPING),
            'available_steps': list(STEP_ID_TO_NAME_MAPPING.values()),
            'detailed_dataspec_compatible': True,
            'api_mapping_supported': True,
            'step_data_flow_supported': True,
            'preprocessing_postprocessing_supported': True
        }
        
        self.logger.info("ğŸ—ï¸ StepImplementationManager v11.0 ì´ˆê¸°í™” ì™„ë£Œ (DetailedDataSpec ì™„ì „ ë°˜ì˜)")
        self.logger.info(f"ğŸ“Š ì§€ì› Step: {len(STEP_ID_TO_NAME_MAPPING)}ê°œ (API ë§¤í•‘ + ë°ì´í„° íë¦„ ì™„ì „ ì§€ì›)")
    
    async def process_step_by_id(self, step_id: int, *args, **kwargs) -> Dict[str, Any]:
        """Step IDë¡œ ì²˜ë¦¬ (DetailedDataSpec ê¸°ë°˜)"""
        try:
            if step_id not in STEP_ID_TO_NAME_MAPPING:
                return {
                    'success': False,
                    'error': f"ì§€ì›í•˜ì§€ ì•ŠëŠ” step_id: {step_id}",
                    'available_step_ids': list(STEP_ID_TO_NAME_MAPPING.keys()),
                    'timestamp': datetime.now().isoformat()
                }
            
            step_name = STEP_ID_TO_NAME_MAPPING[step_id]
            
            # API ì…ë ¥ êµ¬ì„±
            api_input = {}
            if args:
                # ì²« ë²ˆì§¸ ì¸ìë¥¼ ì£¼ìš” ì…ë ¥ìœ¼ë¡œ ì²˜ë¦¬
                if step_name == "HumanParsingStep":
                    api_input['image'] = args[0]
                elif step_name == "PoseEstimationStep":
                    api_input['image'] = args[0]
                elif step_name == "ClothSegmentationStep":
                    api_input['clothing_image'] = args[0]
                elif step_name == "GeometricMatchingStep":
                    api_input['person_image'] = args[0]
                    if len(args) > 1:
                        api_input['clothing_image'] = args[1]
                elif step_name == "ClothWarpingStep":
                    api_input['clothing_item'] = args[0]
                    if len(args) > 1:
                        api_input['person_image'] = args[1]
                elif step_name == "VirtualFittingStep":
                    api_input['person_image'] = args[0]
                    if len(args) > 1:
                        api_input['clothing_item'] = args[1]
                elif step_name == "PostProcessingStep":
                    api_input['fitted_image'] = args[0]
                elif step_name == "QualityAssessmentStep":
                    api_input['final_result'] = args[0]
                else:
                    api_input['input_data'] = args[0]
            
            # kwargs ì¶”ê°€
            api_input.update(kwargs)
            
            # DetailedDataSpec ê¸°ë°˜ ì²˜ë¦¬
            return await self.bridge.process_step_with_detailed_spec(
                step_name, api_input, session_id=kwargs.get('session_id')
            )
            
        except Exception as e:
            self.logger.error(f"âŒ Step ID {step_id} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return {
                'success': False,
                'error': str(e),
                'step_id': step_id,
                'error_type': type(e).__name__,
                'timestamp': datetime.now().isoformat()
            }
    
    async def process_step_by_name(self, step_name: str, api_input: Dict[str, Any], **kwargs) -> Dict[str, Any]:
        """Step ì´ë¦„ìœ¼ë¡œ ì²˜ë¦¬ (DetailedDataSpec ê¸°ë°˜)"""
        try:
            if step_name not in STEP_NAME_TO_CLASS_MAPPING:
                return {
                    'success': False,
                    'error': f"ì§€ì›í•˜ì§€ ì•ŠëŠ” step_name: {step_name}",
                    'available_step_names': list(STEP_NAME_TO_CLASS_MAPPING.keys()),
                    'timestamp': datetime.now().isoformat()
                }
            
            # DetailedDataSpec ê¸°ë°˜ ì²˜ë¦¬
            return await self.bridge.process_step_with_detailed_spec(
                step_name, api_input, session_id=kwargs.get('session_id'), **kwargs
            )
            
        except Exception as e:
            self.logger.error(f"âŒ Step {step_name} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return {
                'success': False,
                'error': str(e),
                'step_name': step_name,
                'error_type': type(e).__name__,
                'timestamp': datetime.now().isoformat()
            }
    
    def get_all_metrics(self) -> Dict[str, Any]:
        """ì „ì²´ ë§¤ë‹ˆì € ë©”íŠ¸ë¦­ (DetailedDataSpec í˜¸í™˜ì„± í¬í•¨)"""
        bridge_metrics = self.bridge.get_metrics()
        
        return {
            **self.manager_metrics,
            'uptime_seconds': (datetime.now() - self.manager_metrics['start_time']).total_seconds(),
            'bridge_metrics': bridge_metrics,
            'step_mappings': {
                'step_id_to_name': STEP_ID_TO_NAME_MAPPING,
                'step_name_to_class': {name: step_type.value for name, step_type in STEP_NAME_TO_CLASS_MAPPING.items()},
                'implementation_functions': IMPLEMENTATION_FUNCTION_MAPPING
            },
            'detailed_dataspec_features': {
                'api_input_mapping_supported': True,
                'api_output_mapping_supported': True,
                'step_data_flow_supported': True,
                'preprocessing_steps_supported': True,
                'postprocessing_steps_supported': True,
                'fastapi_integration_ready': True
            },
            'system_status': {
                'step_model_requests_available': STEP_MODEL_REQUESTS_AVAILABLE,
                'step_factory_v9_available': STEP_FACTORY_V9_AVAILABLE,
                'torch_available': TORCH_AVAILABLE,
                'numpy_available': NUMPY_AVAILABLE,
                'pil_available': PIL_AVAILABLE
            },
            'environment': {
                'conda_env': CONDA_INFO['conda_env'],
                'conda_optimized': CONDA_INFO['is_target_env'],
                'device': DEVICE,
                'is_m3_max': IS_M3_MAX,
                'memory_gb': MEMORY_GB
            }
        }
    
    def cleanup(self):
        """ë§¤ë‹ˆì € ì •ë¦¬"""
        try:
            self.bridge.clear_cache()
            self.logger.info("ğŸ§¹ StepImplementationManager v11.0 ì •ë¦¬ ì™„ë£Œ")
        except Exception as e:
            self.logger.error(f"âŒ ë§¤ë‹ˆì € ì •ë¦¬ ì‹¤íŒ¨: {e}")

# ==============================================
# ğŸ”¥ ì‹±ê¸€í†¤ ë§¤ë‹ˆì € ì¸ìŠ¤í„´ìŠ¤
# ==============================================

_step_implementation_manager_instance: Optional[StepImplementationManager] = None
_manager_lock = threading.RLock()

def get_step_implementation_manager() -> StepImplementationManager:
    """StepImplementationManager v11.0 ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    global _step_implementation_manager_instance
    
    with _manager_lock:
        if _step_implementation_manager_instance is None:
            _step_implementation_manager_instance = StepImplementationManager()
            logger.info("âœ… StepImplementationManager v11.0 ì‹±ê¸€í†¤ ìƒì„± ì™„ë£Œ")
    
    return _step_implementation_manager_instance

async def get_step_implementation_manager_async() -> StepImplementationManager:
    """StepImplementationManager ë¹„ë™ê¸° ë²„ì „"""
    return get_step_implementation_manager()

def cleanup_step_implementation_manager():
    """StepImplementationManager ì •ë¦¬"""
    global _step_implementation_manager_instance
    
    with _manager_lock:
        if _step_implementation_manager_instance:
            _step_implementation_manager_instance.cleanup()
            _step_implementation_manager_instance = None
            logger.info("ğŸ§¹ StepImplementationManager v11.0 ì •ë¦¬ ì™„ë£Œ")

# ==============================================
# ğŸ”¥ ê¸°ì¡´ API í˜¸í™˜ í•¨ìˆ˜ë“¤ (100% í˜¸í™˜ì„± ìœ ì§€)
# ==============================================

async def process_human_parsing_implementation(
    person_image,
    enhance_quality: bool = True,
    session_id: Optional[str] = None,
    **kwargs
) -> Dict[str, Any]:
    """ì¸ê°„ íŒŒì‹± êµ¬í˜„ì²´ ì²˜ë¦¬ - HumanParsingStep í˜¸ì¶œ (DetailedDataSpec ê¸°ë°˜)"""
    manager = get_step_implementation_manager()
    
    # DetailedDataSpec ê¸°ë°˜ API ì…ë ¥ êµ¬ì„±
    api_input = {
        'image': person_image,
        'enhance_quality': enhance_quality,
        'session_id': session_id
    }
    api_input.update(kwargs)
    
    return await manager.process_step_by_name("HumanParsingStep", api_input)

async def process_pose_estimation_implementation(
    image,
    clothing_type: str = "shirt",
    detection_confidence: float = 0.5,
    session_id: Optional[str] = None,
    **kwargs
) -> Dict[str, Any]:
    """í¬ì¦ˆ ì¶”ì • êµ¬í˜„ì²´ ì²˜ë¦¬ - PoseEstimationStep í˜¸ì¶œ (DetailedDataSpec ê¸°ë°˜)"""
    manager = get_step_implementation_manager()
    
    # DetailedDataSpec ê¸°ë°˜ API ì…ë ¥ êµ¬ì„±
    api_input = {
        'image': image,
        'clothing_type': clothing_type,
        'detection_confidence': detection_confidence,
        'session_id': session_id
    }
    api_input.update(kwargs)
    
    return await manager.process_step_by_name("PoseEstimationStep", api_input)

async def process_cloth_segmentation_implementation(
    image,
    clothing_type: str = "shirt",
    quality_level: str = "medium",
    session_id: Optional[str] = None,
    **kwargs
) -> Dict[str, Any]:
    """ì˜ë¥˜ ë¶„í•  êµ¬í˜„ì²´ ì²˜ë¦¬ - ClothSegmentationStep í˜¸ì¶œ (DetailedDataSpec ê¸°ë°˜)"""
    manager = get_step_implementation_manager()
    
    # DetailedDataSpec ê¸°ë°˜ API ì…ë ¥ êµ¬ì„±
    api_input = {
        'clothing_image': image,
        'clothing_type': clothing_type,
        'quality_level': quality_level,
        'session_id': session_id
    }
    api_input.update(kwargs)
    
    return await manager.process_step_by_name("ClothSegmentationStep", api_input)

async def process_geometric_matching_implementation(
    person_image,
    clothing_image,
    pose_keypoints=None,
    body_mask=None,
    clothing_mask=None,
    matching_precision: str = "high",
    session_id: Optional[str] = None,
    **kwargs
) -> Dict[str, Any]:
    """ê¸°í•˜í•™ì  ë§¤ì¹­ êµ¬í˜„ì²´ ì²˜ë¦¬ - GeometricMatchingStep í˜¸ì¶œ (DetailedDataSpec ê¸°ë°˜)"""
    manager = get_step_implementation_manager()
    
    # DetailedDataSpec ê¸°ë°˜ API ì…ë ¥ êµ¬ì„±
    api_input = {
        'person_image': person_image,
        'clothing_item': clothing_image,
        'pose_data': {
            'pose_keypoints': pose_keypoints,
            'body_mask': body_mask,
            'clothing_mask': clothing_mask
        },
        'matching_precision': matching_precision,
        'session_id': session_id
    }
    api_input.update(kwargs)
    
    return await manager.process_step_by_name("GeometricMatchingStep", api_input)

async def process_cloth_warping_implementation(
    cloth_image,
    person_image,
    cloth_mask=None,
    fabric_type: str = "cotton",
    clothing_type: str = "shirt",
    session_id: Optional[str] = None,
    **kwargs
) -> Dict[str, Any]:
    """ì˜ë¥˜ ì›Œí•‘ êµ¬í˜„ì²´ ì²˜ë¦¬ - ClothWarpingStep í˜¸ì¶œ (DetailedDataSpec ê¸°ë°˜)"""
    manager = get_step_implementation_manager()
    
    # DetailedDataSpec ê¸°ë°˜ API ì…ë ¥ êµ¬ì„±
    api_input = {
        'clothing_item': cloth_image,
        'transformation_data': {
            'person_image': person_image,
            'cloth_mask': cloth_mask,
            'fabric_type': fabric_type,
            'clothing_type': clothing_type
        },
        'session_id': session_id
    }
    api_input.update(kwargs)
    
    return await manager.process_step_by_name("ClothWarpingStep", api_input)

async def process_virtual_fitting_implementation(
    person_image,
    cloth_image,
    pose_data=None,
    cloth_mask=None,
    fitting_quality: str = "high",
    session_id: Optional[str] = None,
    **kwargs
) -> Dict[str, Any]:
    """ê°€ìƒ í”¼íŒ… êµ¬í˜„ì²´ ì²˜ë¦¬ - VirtualFittingStep í˜¸ì¶œ (í•µì‹¬!, DetailedDataSpec ê¸°ë°˜)"""
    manager = get_step_implementation_manager()
    
    # DetailedDataSpec ê¸°ë°˜ API ì…ë ¥ êµ¬ì„±
    api_input = {
        'person_image': person_image,
        'clothing_item': cloth_image,
        'fitting_mode': fitting_quality,
        'guidance_scale': kwargs.get('guidance_scale', 7.5),
        'num_inference_steps': kwargs.get('num_inference_steps', 50),
        'session_id': session_id
    }
    
    # ì¶”ê°€ ë°ì´í„° í¬í•¨
    if pose_data:
        api_input['pose_data'] = pose_data
    if cloth_mask:
        api_input['cloth_mask'] = cloth_mask
    
    api_input.update(kwargs)
    
    return await manager.process_step_by_name("VirtualFittingStep", api_input)

async def process_post_processing_implementation(
    fitted_image,
    enhancement_level: str = "medium",
    session_id: Optional[str] = None,
    **kwargs
) -> Dict[str, Any]:
    """í›„ì²˜ë¦¬ êµ¬í˜„ì²´ ì²˜ë¦¬ - PostProcessingStep í˜¸ì¶œ (DetailedDataSpec ê¸°ë°˜)"""
    manager = get_step_implementation_manager()
    
    # DetailedDataSpec ê¸°ë°˜ API ì…ë ¥ êµ¬ì„±
    api_input = {
        'fitted_image': fitted_image,
        'enhancement_level': enhancement_level,
        'upscale_factor': kwargs.get('upscale_factor', 4),
        'session_id': session_id
    }
    api_input.update(kwargs)
    
    return await manager.process_step_by_name("PostProcessingStep", api_input)

async def process_quality_assessment_implementation(
    final_image,
    analysis_depth: str = "comprehensive",
    session_id: Optional[str] = None,
    **kwargs
) -> Dict[str, Any]:
    """í’ˆì§ˆ í‰ê°€ êµ¬í˜„ì²´ ì²˜ë¦¬ - QualityAssessmentStep í˜¸ì¶œ (DetailedDataSpec ê¸°ë°˜)"""
    manager = get_step_implementation_manager()
    
    # DetailedDataSpec ê¸°ë°˜ API ì…ë ¥ êµ¬ì„±
    api_input = {
        'final_result': final_image,
        'analysis_depth': analysis_depth,
        'session_id': session_id
    }
    
    # ì°¸ì¡° ì´ë¯¸ì§€ë“¤ í¬í•¨ (í’ˆì§ˆ ë¹„êµìš©)
    if 'original_person' in kwargs:
        api_input['original_person'] = kwargs['original_person']
    if 'original_clothing' in kwargs:
        api_input['original_clothing'] = kwargs['original_clothing']
    
    api_input.update(kwargs)
    
    return await manager.process_step_by_name("QualityAssessmentStep", api_input)

# ==============================================
# ğŸ”¥ ì‹ ê·œ DetailedDataSpec ê¸°ë°˜ í•¨ìˆ˜ë“¤
# ==============================================

async def process_step_with_api_mapping(
    step_name: str,
    api_input: Dict[str, Any],
    **kwargs
) -> Dict[str, Any]:
    """API ë§¤í•‘ ê¸°ë°˜ Step ì²˜ë¦¬ (step_model_requests.py ì™„ì „ í™œìš©)"""
    try:
        manager = get_step_implementation_manager()
        return await manager.process_step_by_name(step_name, api_input, **kwargs)
    except Exception as e:
        logger.error(f"âŒ API ë§¤í•‘ ê¸°ë°˜ Step ì²˜ë¦¬ ì‹¤íŒ¨ {step_name}: {e}")
        return {
            'success': False,
            'error': str(e),
            'step_name': step_name,
            'timestamp': datetime.now().isoformat()
        }

async def process_pipeline_with_data_flow(
    pipeline_steps: List[str],
    initial_input: Dict[str, Any],
    session_id: Optional[str] = None,
    **kwargs
) -> Dict[str, Any]:
    """Step ê°„ ë°ì´í„° íë¦„ ê¸°ë°˜ íŒŒì´í”„ë¼ì¸ ì²˜ë¦¬"""
    try:
        manager = get_step_implementation_manager()
        pipeline_results = []
        current_data = initial_input.copy()
        
        for i, step_name in enumerate(pipeline_steps):
            logger.info(f"ğŸ”„ íŒŒì´í”„ë¼ì¸ {i+1}/{len(pipeline_steps)}: {step_name}")
            
            # ì´ì „ Stepì˜ ë°ì´í„°ë¥¼ í˜„ì¬ Step ì…ë ¥ì— ë³‘í•©
            if i > 0 and 'next_step_data' in pipeline_results[i-1]:
                prev_step_data = pipeline_results[i-1]['next_step_data'].get(step_name, {})
                current_data.update(prev_step_data)
            
            # í˜„ì¬ Step ì²˜ë¦¬
            result = await manager.process_step_by_name(step_name, current_data, session_id=session_id, **kwargs)
            pipeline_results.append(result)
            
            # ì‹¤íŒ¨ ì‹œ íŒŒì´í”„ë¼ì¸ ì¤‘ë‹¨
            if not result.get('success', False):
                return {
                    'success': False,
                    'error': f"íŒŒì´í”„ë¼ì¸ ì‹¤íŒ¨ at {step_name}: {result.get('error')}",
                    'failed_step': step_name,
                    'completed_steps': i,
                    'partial_results': pipeline_results,
                    'timestamp': datetime.now().isoformat()
                }
            
            # ë‹¤ìŒ Stepì„ ìœ„í•œ ë°ì´í„° ì¤€ë¹„
            if 'next_step_data' in result:
                current_data.update(result['next_step_data'])
        
        return {
            'success': True,
            'pipeline_results': pipeline_results,
            'final_result': pipeline_results[-1] if pipeline_results else {},
            'completed_steps': len(pipeline_results),
            'total_steps': len(pipeline_steps),
            'session_id': session_id,
            'timestamp': datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"âŒ íŒŒì´í”„ë¼ì¸ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        return {
            'success': False,
            'error': str(e),
            'pipeline_steps': pipeline_steps,
            'timestamp': datetime.now().isoformat()
        }

def get_step_api_specification(step_name: str) -> Dict[str, Any]:
    """Stepì˜ API ì‚¬ì–‘ ë°˜í™˜ (FastAPI ë¼ìš°í„°ìš©)"""
    try:
        if not STEP_MODEL_REQUESTS_AVAILABLE:
            return {}
        
        # step_model_requests.pyì—ì„œ API ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        api_mapping = get_step_api_mapping(step_name)
        data_structure_info = get_step_data_structure_info(step_name)
        step_request = get_enhanced_step_request(step_name)
        
        if not step_request:
            return {}
        
        return {
            'step_name': step_name,
            'step_class': step_request.step_class,
            'ai_class': step_request.ai_class,
            'step_priority': step_request.step_priority.name,
            'model_architecture': step_request.model_architecture,
            'supports_streaming': step_request.supports_streaming,
            'api_input_mapping': api_mapping.get('input_mapping', {}),
            'api_output_mapping': api_mapping.get('output_mapping', {}),
            'input_form_fields': [k for k, v in api_mapping.get('input_mapping', {}).items() if "UploadFile" not in str(v)],
            'file_upload_fields': [k for k, v in api_mapping.get('input_mapping', {}).items() if "UploadFile" in str(v)],
            'response_fields': list(api_mapping.get('output_mapping', {}).keys()),
            'fastapi_compatible': len(api_mapping.get('input_mapping', {})) > 0,
            'detailed_data_spec': data_structure_info.get('detailed_data_spec', {}),
            'preprocessing_requirements': get_step_preprocessing_requirements(step_name),
            'postprocessing_requirements': get_step_postprocessing_requirements(step_name),
            'data_flow': get_step_data_flow(step_name)
        }
        
    except Exception as e:
        logger.error(f"âŒ Step API ì‚¬ì–‘ ì¡°íšŒ ì‹¤íŒ¨ {step_name}: {e}")
        return {'error': str(e)}

def get_all_steps_api_specification() -> Dict[str, Dict[str, Any]]:
    """ëª¨ë“  Stepì˜ API ì‚¬ì–‘ ë°˜í™˜"""
    specifications = {}
    
    for step_name in STEP_ID_TO_NAME_MAPPING.values():
        specifications[step_name] = get_step_api_specification(step_name)
    
    return specifications

def validate_step_input_against_spec(step_name: str, api_input: Dict[str, Any]) -> Dict[str, Any]:
    """Step ì…ë ¥ì„ DetailedDataSpecì— ëŒ€í•´ ê²€ì¦"""
    try:
        if not STEP_MODEL_REQUESTS_AVAILABLE:
            return {'valid': True, 'warnings': ['step_model_requests.py ì‚¬ìš© ë¶ˆê°€']}
        
        step_request = get_enhanced_step_request(step_name)
        if not step_request:
            return {'valid': False, 'error': f'Unknown step: {step_name}'}
        
        api_mapping = get_step_api_mapping(step_name)
        input_mapping = api_mapping.get('input_mapping', {})
        
        validation_result = {
            'valid': True,
            'warnings': [],
            'errors': [],
            'missing_required_fields': [],
            'type_mismatches': [],
            'extra_fields': []
        }
        
        # í•„ìˆ˜ í•„ë“œ ì²´í¬
        for required_field, expected_type in input_mapping.items():
            if required_field not in api_input:
                validation_result['missing_required_fields'].append(required_field)
                validation_result['valid'] = False
            else:
                # íƒ€ì… ì²´í¬ (ê°„ë‹¨í•œ ë²„ì „)
                value = api_input[required_field]
                if "UploadFile" in expected_type and not hasattr(value, 'file'):
                    validation_result['type_mismatches'].append(f"{required_field}: expected UploadFile")
                elif "str" in expected_type and not isinstance(value, str):
                    validation_result['warnings'].append(f"{required_field}: expected string")
                elif "float" in expected_type and not isinstance(value, (int, float)):
                    validation_result['warnings'].append(f"{required_field}: expected number")
        
        # ì¶”ê°€ í•„ë“œ ì²´í¬
        for field in api_input.keys():
            if field not in input_mapping and field not in ['session_id']:
                validation_result['extra_fields'].append(field)
        
        return validation_result
        
    except Exception as e:
        return {'valid': False, 'error': str(e)}

# ==============================================
# ğŸ”¥ ìƒíƒœ ë° ê°€ìš©ì„± ì •ë³´
# ==============================================

STEP_IMPLEMENTATIONS_AVAILABLE = STEP_FACTORY_V9_AVAILABLE and STEP_MODEL_REQUESTS_AVAILABLE

def get_implementation_availability_info() -> Dict[str, Any]:
    """êµ¬í˜„ì²´ ê°€ìš©ì„± ì •ë³´ ë°˜í™˜ (DetailedDataSpec í¬í•¨)"""
    return {
        "step_implementations_available": STEP_IMPLEMENTATIONS_AVAILABLE,
        "architecture": "DetailedDataSpec + StepFactory v9.0 ì™„ì „ ì—°ë™",
        "version": "v11.0",
        "api_compatibility": "100%",
        "detailed_dataspec_version": "v8.0",
        "step_factory_version": "v9.0",
        "step_model_requests_available": STEP_MODEL_REQUESTS_AVAILABLE,
        "step_factory_v9_available": STEP_FACTORY_V9_AVAILABLE,
        "supported_steps": STEP_ID_TO_NAME_MAPPING,
        "total_steps_supported": len(STEP_ID_TO_NAME_MAPPING),
        "conda_optimization": CONDA_INFO['is_target_env'],
        "device_optimization": f"{DEVICE}_optimized",
        "production_ready": True,
        "detailed_dataspec_features": {
            "api_input_mapping": "âœ… ì™„ì „ ì§€ì›",
            "api_output_mapping": "âœ… ì™„ì „ ì§€ì›", 
            "step_data_flow": "âœ… ì™„ì „ ì§€ì›",
            "preprocessing_steps": "âœ… ì™„ì „ ì§€ì›",
            "postprocessing_steps": "âœ… ì™„ì „ ì§€ì›",
            "fastapi_integration": "âœ… ì™„ì „ ì§€ì›",
            "step_pipeline": "âœ… ì™„ì „ ì§€ì›"
        },
        "api_flow": {
            "step_routes.py": "FastAPI ì—”ë“œí¬ì¸íŠ¸ (api_input_mapping ê¸°ë°˜)",
            "step_service.py": "ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ + íŒŒì´í”„ë¼ì¸ ê´€ë¦¬", 
            "step_implementations.py": "API â†” Step ë³€í™˜ + DetailedDataSpec ì²˜ë¦¬ (ì´ íŒŒì¼)",
            "step_factory.py": "Step ì¸ìŠ¤í„´ìŠ¤ ìƒì„± (DetailedDataSpec ê¸°ë°˜)",
            "ai_pipeline/steps/step_XX.py": "ìˆœìˆ˜ AI ëª¨ë¸ ì¶”ë¡  ë¡œì§"
        },
        "environment": {
            "conda_env": CONDA_INFO['conda_env'],
            "conda_optimized": CONDA_INFO['is_target_env'],
            "device": DEVICE,
            "is_m3_max": IS_M3_MAX,
            "memory_gb": MEMORY_GB,
            "torch_available": TORCH_AVAILABLE,
            "numpy_available": NUMPY_AVAILABLE,
            "pil_available": PIL_AVAILABLE
        }
    }

# ==============================================
# ğŸ”¥ conda í™˜ê²½ ìµœì í™” í•¨ìˆ˜ë“¤ (DetailedDataSpec í˜¸í™˜)
# ==============================================

def setup_conda_step_implementations():
    """conda í™˜ê²½ì—ì„œ Step êµ¬í˜„ì²´ ìµœì í™” ì„¤ì • (DetailedDataSpec í˜¸í™˜)"""
    try:
        if not CONDA_INFO['is_target_env']:
            logger.warning(f"âš ï¸ ê¶Œì¥ conda í™˜ê²½ì´ ì•„ë‹˜: {CONDA_INFO['conda_env']} (ê¶Œì¥: mycloset-ai-clean)")
            return False
        
        logger.info(f"ğŸ conda í™˜ê²½ ê°ì§€: {CONDA_INFO['conda_env']}")
        
        # StepFactory v9.0 ìµœì í™” í˜¸ì¶œ
        if STEP_FACTORY_V9_AVAILABLE:
            try:
                STEP_FACTORY_V9_COMPONENTS['optimize_conda_environment']()
                logger.info("ğŸ”§ StepFactory v9.0 conda ìµœì í™” ì™„ë£Œ (DetailedDataSpec í˜¸í™˜)")
            except Exception as e:
                logger.warning(f"âš ï¸ StepFactory v9.0 conda ìµœì í™” ì‹¤íŒ¨: {e}")
        
        # PyTorch conda ìµœì í™”
        if TORCH_AVAILABLE:
            import torch
            
            # MPS ìµœì í™” (M3 Max)
            if DEVICE == "mps" and IS_M3_MAX:
                if hasattr(torch.backends, 'mps') and hasattr(torch.backends.mps, 'empty_cache'):
                    torch.backends.mps.empty_cache()
                logger.info("ğŸ M3 Max MPS ìµœì í™” í™œì„±í™” (DetailedDataSpec í˜¸í™˜)")
            
            # CPU ìŠ¤ë ˆë“œ ìµœì í™”
            cpu_count = os.cpu_count()
            torch.set_num_threads(max(1, cpu_count // 2))
            logger.info(f"ğŸ§µ PyTorch ìŠ¤ë ˆë“œ ìµœì í™”: {torch.get_num_threads()}/{cpu_count}")
        
        # í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
        os.environ['OMP_NUM_THREADS'] = str(max(1, os.cpu_count() // 2))
        os.environ['MKL_NUM_THREADS'] = str(max(1, os.cpu_count() // 2))
        
        return True
        
    except Exception as e:
        logger.warning(f"âš ï¸ conda ìµœì í™” ì„¤ì • ì‹¤íŒ¨: {e}")
        return False

def validate_conda_environment():
    """conda í™˜ê²½ ê²€ì¦ (DetailedDataSpec í˜¸í™˜)"""
    try:
        conda_env = CONDA_INFO['conda_env']
        if conda_env == 'none':
            logger.warning("âš ï¸ conda í™˜ê²½ì´ í™œì„±í™”ë˜ì§€ ì•ŠìŒ")
            return False
        
        # ê¶Œì¥ í™˜ê²½ í™•ì¸
        if not CONDA_INFO['is_target_env']:
            logger.warning(f"âš ï¸ ê¶Œì¥ conda í™˜ê²½ì´ ì•„ë‹˜: {conda_env} (ê¶Œì¥: mycloset-ai-clean)")
        
        # í•„ìˆ˜ íŒ¨í‚¤ì§€ í™•ì¸
        missing_packages = []
        if not NUMPY_AVAILABLE:
            missing_packages.append('numpy')
        if not PIL_AVAILABLE:
            missing_packages.append('pillow')
        
        if missing_packages:
            logger.warning(f"âš ï¸ conda í™˜ê²½ì— ëˆ„ë½ëœ íŒ¨í‚¤ì§€: {missing_packages}")
            return False
        
        logger.info(f"âœ… conda í™˜ê²½ ê²€ì¦ ì™„ë£Œ: {conda_env}")
        return True
        
    except Exception as e:
        logger.error(f"âŒ conda í™˜ê²½ ê²€ì¦ ì‹¤íŒ¨: {e}")
        return False

# ==============================================
# ğŸ”¥ DetailedDataSpec í˜¸í™˜ì„± ë„êµ¬ë“¤
# ==============================================

def validate_step_implementation_compatibility() -> Dict[str, Any]:
    """Step Implementation DetailedDataSpec í˜¸í™˜ì„± ê²€ì¦"""
    try:
        compatibility_report = {
            'version': 'v11.0',
            'detailed_dataspec_version': 'v8.0',
            'step_factory_version': 'v9.0',
            'compatible': True,
            'issues': [],
            'recommendations': []
        }
        
        # step_model_requests.py ê°€ìš©ì„± í™•ì¸
        if not STEP_MODEL_REQUESTS_AVAILABLE:
            compatibility_report['compatible'] = False
            compatibility_report['issues'].append('step_model_requests.pyë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŒ')
        
        # StepFactory v9.0 ê°€ìš©ì„± í™•ì¸
        if not STEP_FACTORY_V9_AVAILABLE:
            compatibility_report['compatible'] = False
            compatibility_report['issues'].append('StepFactory v9.0ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŒ')
        
        # conda í™˜ê²½ í™•ì¸
        if not CONDA_INFO['is_target_env']:
            compatibility_report['recommendations'].append(
                f"conda í™˜ê²½ì„ mycloset-ai-cleanìœ¼ë¡œ ë³€ê²½ ê¶Œì¥ (í˜„ì¬: {CONDA_INFO['conda_env']})"
            )
        
        # ë©”ëª¨ë¦¬ í™•ì¸
        if MEMORY_GB < 16:
            compatibility_report['recommendations'].append(
                f"ë©”ëª¨ë¦¬ ë¶€ì¡± ì£¼ì˜: {MEMORY_GB:.1f}GB (ê¶Œì¥: 16GB+)"
            )
        
        # Step ë§¤í•‘ í™•ì¸
        compatibility_report['step_mappings'] = {
            'total_steps': len(STEP_ID_TO_NAME_MAPPING),
            'step_names': list(STEP_ID_TO_NAME_MAPPING.values()),
            'all_detailed_dataspec_compatible': True
        }
        
        # ì‹œìŠ¤í…œ ìƒíƒœ
        compatibility_report['system_status'] = {
            'torch_available': TORCH_AVAILABLE,
            'numpy_available': NUMPY_AVAILABLE,
            'pil_available': PIL_AVAILABLE,
            'device': DEVICE,
            'is_m3_max': IS_M3_MAX
        }
        
        compatibility_report['overall_score'] = (
            100 - len(compatibility_report['issues']) * 20 - 
            len(compatibility_report['recommendations']) * 5
        )
        
        return compatibility_report
        
    except Exception as e:
        return {
            'compatible': False,
            'error': str(e),
            'version': 'v11.0'
        }

def diagnose_step_implementations() -> Dict[str, Any]:
    """Step Implementations ìƒíƒœ ì§„ë‹¨ (DetailedDataSpec í¬í•¨)"""
    try:
        manager = get_step_implementation_manager()
        
        diagnosis = {
            'version': 'v11.0',
            'detailed_dataspec_version': 'v8.0',
            'timestamp': datetime.now().isoformat(),
            'overall_health': 'unknown',
            'manager_metrics': manager.get_all_metrics(),
            'compatibility_report': validate_step_implementation_compatibility(),
            'environment_health': {
                'conda_optimized': CONDA_INFO['is_target_env'],
                'device_optimized': DEVICE != 'cpu',
                'm3_max_available': IS_M3_MAX,
                'memory_sufficient': MEMORY_GB >= 16.0,
                'step_model_requests_available': STEP_MODEL_REQUESTS_AVAILABLE,
                'detailed_dataspec_ready': STEP_MODEL_REQUESTS_AVAILABLE
            },
            'recommendations': []
        }
        
        # ì „ë°˜ì ì¸ ê±´ê°•ë„ í‰ê°€
        issues_count = len(diagnosis['compatibility_report'].get('issues', []))
        warnings_count = len(diagnosis['compatibility_report'].get('recommendations', []))
        
        if issues_count == 0 and warnings_count <= 2:
            diagnosis['overall_health'] = 'excellent'
        elif issues_count == 0 and warnings_count <= 4:
            diagnosis['overall_health'] = 'good'
        elif issues_count <= 1:
            diagnosis['overall_health'] = 'warning'
        else:
            diagnosis['overall_health'] = 'critical'
        
        # ê¶Œì¥ì‚¬í•­ ìƒì„±
        if not CONDA_INFO['is_target_env']:
            diagnosis['recommendations'].append("conda activate mycloset-ai-clean")
        
        if DEVICE == 'cpu' and IS_M3_MAX:
            diagnosis['recommendations'].append("MPS ê°€ì† í™œì„±í™”ë¥¼ í™•ì¸í•˜ì„¸ìš”")
        
        if not STEP_MODEL_REQUESTS_AVAILABLE:
            diagnosis['recommendations'].append("step_model_requests.py ì˜ì¡´ì„±ì„ í™•ì¸í•˜ì„¸ìš”")
        
        if not STEP_FACTORY_V9_AVAILABLE:
            diagnosis['recommendations'].append("StepFactory v9.0 ì˜ì¡´ì„±ì„ í™•ì¸í•˜ì„¸ìš”")
        
        return diagnosis
        
    except Exception as e:
        return {
            'overall_health': 'error',
            'error': str(e),
            'version': 'v11.0'
        }

# ==============================================
# ğŸ”¥ ìŠ¤í‚¤ë§ˆ ë™ì  Import
# ==============================================

def get_body_measurements():
    """BodyMeasurements ìŠ¤í‚¤ë§ˆ ë™ì  import"""
    try:
        from ..models.schemas import BodyMeasurements
        return BodyMeasurements
    except ImportError:
        # í´ë°± ìŠ¤í‚¤ë§ˆ
        @dataclass
        class BodyMeasurements:
            height: float
            weight: float
            chest: Optional[float] = None
            waist: Optional[float] = None
            hips: Optional[float] = None
        
        return BodyMeasurements

BodyMeasurements = get_body_measurements()

# ==============================================
# ğŸ”¥ ëª¨ë“ˆ Export
# ==============================================

__all__ = [
    # ë©”ì¸ í´ë˜ìŠ¤ë“¤
    "StepImplementationManager",
    "DetailedDataSpecStepBridge",
    "DataTransformationUtils",
    
    # ê´€ë¦¬ì í•¨ìˆ˜ë“¤
    "get_step_implementation_manager", 
    "get_step_implementation_manager_async",
    "cleanup_step_implementation_manager",
    
    # ê¸°ì¡´ API í˜¸í™˜ í•¨ìˆ˜ë“¤ (DetailedDataSpec ê¸°ë°˜)
    "process_human_parsing_implementation",
    "process_pose_estimation_implementation",
    "process_cloth_segmentation_implementation",
    "process_geometric_matching_implementation",
    "process_cloth_warping_implementation",
    "process_virtual_fitting_implementation",
    "process_post_processing_implementation",
    "process_quality_assessment_implementation",
    
    # ì‹ ê·œ DetailedDataSpec ê¸°ë°˜ í•¨ìˆ˜ë“¤
    "process_step_with_api_mapping",
    "process_pipeline_with_data_flow",
    "get_step_api_specification",
    "get_all_steps_api_specification",
    "validate_step_input_against_spec",
    
    # ìœ í‹¸ë¦¬í‹°
    "get_implementation_availability_info",
    "setup_conda_step_implementations",
    "validate_conda_environment", 
    "validate_step_implementation_compatibility",
    "diagnose_step_implementations",
    
    # ìŠ¤í‚¤ë§ˆ
    "BodyMeasurements",
    
    # ìƒìˆ˜
    "STEP_IMPLEMENTATIONS_AVAILABLE",
    "STEP_ID_TO_NAME_MAPPING",
    "STEP_NAME_TO_CLASS_MAPPING"
]

# í˜¸í™˜ì„±ì„ ìœ„í•œ ë³„ì¹­
RealStepImplementationManager = StepImplementationManager

# ==============================================
# ğŸ”¥ ëª¨ë“ˆ ë¡œë“œ ì™„ë£Œ ë©”ì‹œì§€
# ==============================================

logger.info("ğŸ”¥ Step Implementations v11.0 ë¡œë“œ ì™„ë£Œ (DetailedDataSpec ì™„ì „ ë°˜ì˜)!")
logger.info("âœ… ì™„ì „í•œ ì•„í‚¤í…ì²˜:")
logger.info("   step_routes.py â†’ step_service.py â†’ step_implementations.py â†’ StepFactory v9.0 â†’ Step í´ë˜ìŠ¤ë“¤")

logger.info("âœ… DetailedDataSpec v8.0 ì™„ì „ ì—°ë™:")
logger.info("   - api_input_mapping: FastAPI UploadFile â†” PIL.Image ìë™ ë³€í™˜")  
logger.info("   - api_output_mapping: numpy.ndarray â†” base64_string ìë™ ë³€í™˜")
logger.info("   - preprocessing_steps: ì •ê·œí™”, ë¦¬ì‚¬ì´ì¦ˆ, Tensor ë³€í™˜ ìë™ ì ìš©")
logger.info("   - postprocessing_steps: argmax, ì„ê³„ê°’, ì—­ì •ê·œí™” ìë™ ì ìš©")
logger.info("   - Step ê°„ ë°ì´í„° íë¦„: provides_to_next_step ìë™ ì²˜ë¦¬")
logger.info("   - FastAPI ë¼ìš°í„° í˜¸í™˜ì„±: 100% í™•ë³´")

logger.info(f"ğŸ“Š ì‹œìŠ¤í…œ ìƒíƒœ:")
logger.info(f"   - step_model_requests.py: {'âœ…' if STEP_MODEL_REQUESTS_AVAILABLE else 'âŒ'}")
logger.info(f"   - StepFactory v9.0: {'âœ…' if STEP_FACTORY_V9_AVAILABLE else 'âŒ'}")
logger.info(f"   - PyTorch: {'âœ…' if TORCH_AVAILABLE else 'âŒ'}")
logger.info(f"   - Device: {DEVICE}")
logger.info(f"   - conda í™˜ê²½: {CONDA_INFO['conda_env']} ({'âœ…' if CONDA_INFO['is_target_env'] else 'âš ï¸'})")

logger.info("ğŸ¯ DetailedDataSpec ê¸°ë°˜ Step ë§¤í•‘:")
for step_id, step_name in STEP_ID_TO_NAME_MAPPING.items():
    logger.info(f"   - Step {step_id}: {step_name} (API ë§¤í•‘ + ë°ì´í„° íë¦„ ì™„ì „ ì§€ì›)")

logger.info("ğŸ¯ ê¸°ì¡´ API í•¨ìˆ˜ í˜¸í™˜ì„± (100% ìœ ì§€ + DetailedDataSpec ì ìš©):")
for step_id, func_name in IMPLEMENTATION_FUNCTION_MAPPING.items():
    step_name = STEP_ID_TO_NAME_MAPPING[step_id]
    logger.info(f"   - {func_name} â†’ {step_name} (DetailedDataSpec ê¸°ë°˜)")

logger.info("ğŸ”„ API ì²˜ë¦¬ íë¦„ (DetailedDataSpec v8.0):")
logger.info("   1. FastAPI â†’ api_input_mapping (UploadFile â†’ PIL.Image)")
logger.info("   2. preprocessing_steps ìë™ ì ìš© (ë¦¬ì‚¬ì´ì¦ˆ, ì •ê·œí™”)")
logger.info("   3. StepFactory â†’ Step ì¸ìŠ¤í„´ìŠ¤ â†’ AI ì¶”ë¡ ")
logger.info("   4. postprocessing_steps ìë™ ì ìš© (argmax, ì„ê³„ê°’)")
logger.info("   5. api_output_mapping (numpy â†’ base64_string)")
logger.info("   6. provides_to_next_step (ë‹¤ìŒ Step ë°ì´í„° ì¤€ë¹„)")

# conda í™˜ê²½ ìë™ ìµœì í™”
if CONDA_INFO['is_target_env']:
    setup_conda_step_implementations()
    if validate_conda_environment():
        logger.info("ğŸ conda í™˜ê²½ ìë™ ìµœì í™” ë° ê²€ì¦ ì™„ë£Œ! (DetailedDataSpec í˜¸í™˜)")
else:
    logger.warning(f"âš ï¸ conda í™˜ê²½ì„ í™•ì¸í•˜ì„¸ìš”: conda activate mycloset-ai-clean")

# ì´ˆê¸° ë©”ëª¨ë¦¬ ìµœì í™”
try:
    if TORCH_AVAILABLE:
        import torch
        if DEVICE == "mps" and IS_M3_MAX:
            if hasattr(torch.backends, 'mps') and hasattr(torch.backends.mps, 'empty_cache'):
                torch.backends.mps.empty_cache()
        elif DEVICE == "cuda":
            torch.cuda.empty_cache()
    
    gc.collect()
    logger.info(f"ğŸ’¾ {DEVICE} ì´ˆê¸° ë©”ëª¨ë¦¬ ìµœì í™” ì™„ë£Œ!")
except Exception as e:
    logger.warning(f"âš ï¸ ì´ˆê¸° ë©”ëª¨ë¦¬ ìµœì í™” ì‹¤íŒ¨: {e}")

logger.info("ğŸš€ Step Implementations v11.0 ì™„ì „ ì¤€ë¹„ ì™„ë£Œ!")
logger.info("ğŸ’¯ DetailedDataSpec v8.0 ì™„ì „ ë°˜ì˜ìœ¼ë¡œ API â†” Step ìë™ ë³€í™˜!")
logger.info("ğŸ’¯ ì „ì²˜ë¦¬/í›„ì²˜ë¦¬ ë‹¨ê³„ ìë™ ì ìš©ìœ¼ë¡œ ì•ˆì •ì„± ë³´ì¥!")
logger.info("ğŸ’¯ Step ê°„ ë°ì´í„° íë¦„ ìë™ ê´€ë¦¬ë¡œ íŒŒì´í”„ë¼ì¸ ì™„ì „ ì§€ì›!")
logger.info("ğŸ’¯ FastAPI ë¼ìš°í„° í˜¸í™˜ì„± 100% í™•ë³´!")