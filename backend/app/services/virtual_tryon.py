# app/api/virtual_tryon.py
"""
MyCloset AI Virtual Try-On API - ì‹¤ì œ í”„ë¡œì íŠ¸ êµ¬ì¡°ì— ë§ì¶˜ ê°œì„  ë²„ì „
ê¸°ì¡´ 8ë‹¨ê³„ AI íŒŒì´í”„ë¼ì¸ê³¼ ì„œë¹„ìŠ¤ë“¤ì„ ì™„ì „ í™œìš©
"""
import os
import time
import asyncio
import uuid
import base64
import json
from typing import Optional, Dict, Any, List
from datetime import datetime
from pathlib import Path

from fastapi import APIRouter, File, UploadFile, Form, HTTPException, BackgroundTasks, WebSocket, WebSocketDisconnect
from fastapi.responses import JSONResponse, FileResponse
from fastapi.websockets import WebSocketState
from pydantic import BaseModel, Field
import aiofiles
from PIL import Image, ImageDraw, ImageFont
import numpy as np
import logging
from io import BytesIO

# ============================================
# ğŸ”§ ì‹¤ì œ í”„ë¡œì íŠ¸ êµ¬ì¡°ì— ë§ì¶˜ Import
# ============================================

try:
    # ê¸°ì¡´ AI íŒŒì´í”„ë¼ì¸ êµ¬ì¡° (ì‹¤ì œ 8ë‹¨ê³„)
    from app.ai_pipeline.steps.step_01_human_parsing import HumanParsingStep
    from app.ai_pipeline.steps.step_02_pose_estimation import PoseEstimationStep
    from app.ai_pipeline.steps.step_03_cloth_segmentation import ClothSegmentationStep
    from app.ai_pipeline.steps.step_04_geometric_matching import GeometricMatchingStep
    from app.ai_pipeline.steps.step_05_cloth_warping import ClothWarpingStep
    from app.ai_pipeline.steps.step_06_virtual_fitting import VirtualFittingStep
    from app.ai_pipeline.steps.step_07_post_processing import PostProcessingStep
    from app.ai_pipeline.steps.step_08_quality_assessment import QualityAssessmentStep
    
    # ê¸°ì¡´ ì„œë¹„ìŠ¤ë“¤ í™œìš©
    from app.services.virtual_fitter import VirtualFitter
    from app.services.model_manager import ModelManager
    from app.services.ai_models import model_manager
    from app.services.real_working_ai_fitter import RealWorkingAIFitter
    from app.services.human_analysis import HumanAnalyzer
    
    # ìœ í‹¸ë¦¬í‹°ë“¤
    from app.ai_pipeline.utils.memory_manager import MemoryManager
    from app.ai_pipeline.utils.data_converter import DataConverter
    from app.ai_pipeline.utils.model_loader import ModelLoader
    
    # í•µì‹¬ ì„¤ì •
    from app.core.config import get_settings
    from app.core.gpu_config import GPUConfig
    from app.core.logging_config import setup_logging
    
    # ë°ì´í„° ëª¨ë¸
    from app.models.schemas import VirtualTryOnRequest, VirtualTryOnResponse
    
    # íŒŒì¼ ë° ì´ë¯¸ì§€ ìœ í‹¸ë¦¬í‹°
    from app.utils.file_manager import FileManager
    from app.utils.image_utils import resize_image, enhance_image_quality, validate_image_content
    
    AI_PIPELINE_AVAILABLE = True
    logger = logging.getLogger(__name__)
    logger.info("âœ… ì‹¤ì œ AI íŒŒì´í”„ë¼ì¸ import ì„±ê³µ")
    
except ImportError as e:
    # í´ë°±: ê¸°ë³¸ êµ¬í˜„ ì‚¬ìš©
    AI_PIPELINE_AVAILABLE = False
    logging.basicConfig(level=logging.INFO)
    logger = logging.getLogger(__name__)
    logger.warning(f"âŒ AI íŒŒì´í”„ë¼ì¸ ëª¨ë“ˆ ì—†ìŒ: {e}")

# ì„¤ì • ë¡œë“œ
try:
    settings = get_settings()
    logger.info("âœ… ì„¤ì • ë¡œë“œ ì™„ë£Œ")
except:
    # ê¸°ë³¸ ì„¤ì •
    class DefaultSettings:
        debug = True
        max_upload_size = 50 * 1024 * 1024
        device = "mps"  # M3 Max ê¸°ë³¸
        cors_origins = ["http://localhost:3000"]
    
    settings = DefaultSettings()

# API ë¼ìš°í„° ì´ˆê¸°í™”
router = APIRouter(prefix="/virtual-tryon", tags=["Virtual Try-On"])

# ============================================
# ğŸ¯ ì‹¤ì œ í”„ë¡œì íŠ¸ êµ¬ì¡°ì— ë§ì¶˜ íŒŒì´í”„ë¼ì¸ ë§¤ë‹ˆì €
# ============================================

class MyClosetPipelineManager:
    """MyCloset AI ì‹¤ì œ 8ë‹¨ê³„ íŒŒì´í”„ë¼ì¸ ê´€ë¦¬ì"""
    
    def __init__(self):
        self.initialized = False
        self.steps = {}
        self.gpu_config = None
        self.memory_manager = None
        
        # ê¸°ì¡´ ì„œë¹„ìŠ¤ë“¤
        self.virtual_fitter = None
        self.model_manager = None
        self.human_analyzer = None
        self.ai_fitter = None
        
        logger.info("ğŸš€ MyCloset íŒŒì´í”„ë¼ì¸ ë§¤ë‹ˆì € ì´ˆê¸°í™”")
    
    async def initialize(self) -> bool:
        """ì‹¤ì œ 8ë‹¨ê³„ íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™”"""
        if self.initialized:
            return True
        
        try:
            logger.info("ğŸ”§ 8ë‹¨ê³„ AI íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” ì‹œì‘...")
            
            # 1. GPU ì„¤ì • ì´ˆê¸°í™” (M3 Max ìµœì í™”)
            self.gpu_config = GPUConfig()
            await self.gpu_config.setup()
            device = self.gpu_config.device
            
            # 2. ë©”ëª¨ë¦¬ ê´€ë¦¬ì ì´ˆê¸°í™”
            if MemoryManager:
                self.memory_manager = MemoryManager()
                await self.memory_manager.initialize()
            
            # 3. ê¸°ì¡´ ì„œë¹„ìŠ¤ë“¤ ì´ˆê¸°í™”
            await self._initialize_services()
            
            # 4. 8ë‹¨ê³„ Step í´ë˜ìŠ¤ë“¤ ì´ˆê¸°í™” (ì‹¤ì œ êµ¬ì¡°)
            await self._initialize_pipeline_steps(device)
            
            self.initialized = True
            logger.info("âœ… MyCloset AI íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” ì™„ë£Œ!")
            return True
            
        except Exception as e:
            logger.error(f"âŒ íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return False
    
    async def _initialize_services(self):
        """ê¸°ì¡´ ì„œë¹„ìŠ¤ë“¤ ì´ˆê¸°í™”"""
        try:
            # VirtualFitter ì„œë¹„ìŠ¤
            if VirtualFitter:
                self.virtual_fitter = VirtualFitter()
                await self.virtual_fitter.initialize_models()
            
            # ModelManager ì„œë¹„ìŠ¤
            if ModelManager:
                self.model_manager = ModelManager()
                await self.model_manager.initialize()
            
            # HumanAnalyzer ì„œë¹„ìŠ¤
            if HumanAnalyzer:
                self.human_analyzer = HumanAnalyzer()
                await self.human_analyzer.initialize()
            
            # RealWorkingAIFitter ì„œë¹„ìŠ¤
            if RealWorkingAIFitter:
                self.ai_fitter = RealWorkingAIFitter()
                await self.ai_fitter.initialize()
            
            logger.info("âœ… ê¸°ì¡´ ì„œë¹„ìŠ¤ë“¤ ì´ˆê¸°í™” ì™„ë£Œ")
            
        except Exception as e:
            logger.warning(f"âš ï¸ ì¼ë¶€ ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    
    async def _initialize_pipeline_steps(self, device: str):
        """8ë‹¨ê³„ Step í´ë˜ìŠ¤ë“¤ ì´ˆê¸°í™”"""
        
        # ê³µí†µ ì„¤ì •
        step_config = {
            'device': device,
            'batch_size': 1,
            'optimization_level': 'balanced',
            'use_cache': True
        }
        
        # ê° ë‹¨ê³„ë³„ Step í´ë˜ìŠ¤ ì´ˆê¸°í™”
        step_classes = [
            ('human_parsing', HumanParsingStep),
            ('pose_estimation', PoseEstimationStep),
            ('cloth_segmentation', ClothSegmentationStep),
            ('geometric_matching', GeometricMatchingStep),
            ('cloth_warping', ClothWarpingStep),
            ('virtual_fitting', VirtualFittingStep),
            ('post_processing', PostProcessingStep),
            ('quality_assessment', QualityAssessmentStep)
        ]
        
        for step_name, step_class in step_classes:
            try:
                # ì‹¤ì œ í´ë˜ìŠ¤ ì´ˆê¸°í™” (ìµœì  ìƒì„±ì íŒ¨í„´ ì ìš©)
                self.steps[step_name] = step_class(
                    device=device,
                    config=step_config,
                    memory_gb=64.0,  # M3 Max 128GB ì¤‘ 64GB í• ë‹¹
                    is_m3_max=True,
                    optimization_enabled=True,
                    quality_level='high'
                )
                
                # ê° ë‹¨ê³„ ì´ˆê¸°í™”
                await self.steps[step_name].initialize()
                logger.info(f"âœ… {step_name} ë‹¨ê³„ ì´ˆê¸°í™” ì™„ë£Œ")
                
            except Exception as e:
                logger.error(f"âŒ {step_name} ë‹¨ê³„ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                # ê¸°ë³¸ ë”ë¯¸ í´ë˜ìŠ¤ë¡œ ëŒ€ì²´
                self.steps[step_name] = self._create_dummy_step(step_name)
    
    def _create_dummy_step(self, step_name: str):
        """ë”ë¯¸ Step í´ë˜ìŠ¤ ìƒì„± (í´ë°±ìš©)"""
        class DummyStep:
            def __init__(self, name):
                self.name = name
                self.initialized = True
            
            async def process(self, input_data, **kwargs):
                await asyncio.sleep(0.1)  # ì²˜ë¦¬ ì‹œë®¬ë ˆì´ì…˜
                return {
                    "success": True,
                    "step_name": self.name,
                    "result": f"processed_{self.name}",
                    "confidence": 0.85
                }
        
        return DummyStep(step_name)
    
    async def process_complete_virtual_fitting(
        self,
        person_image_path: str,
        clothing_image_path: str,
        body_measurements: Dict[str, Any],
        clothing_type: str = "shirt",
        fabric_type: str = "cotton",
        style_preferences: Dict[str, Any] = None,
        quality_target: float = 0.8,
        progress_callback: Optional[callable] = None,
        **kwargs
    ) -> Dict[str, Any]:
        """ì‹¤ì œ 8ë‹¨ê³„ AI íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
        
        if not self.initialized:
            await self.initialize()
        
        start_time = time.time()
        step_results = {}
        current_data = None
        
        try:
            logger.info("ğŸ¨ MyCloset AI 8ë‹¨ê³„ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì‹œì‘")
            
            # ì´ë¯¸ì§€ ë¡œë“œ
            person_image = Image.open(person_image_path).convert('RGB')
            clothing_image = Image.open(clothing_image_path).convert('RGB')
            
            # 1ë‹¨ê³„: ì¸ì²´ íŒŒì‹±
            if progress_callback:
                await progress_callback("human_parsing", 10)
            
            result_1 = await self.steps['human_parsing'].process(
                person_image,
                measurements=body_measurements
            )
            step_results['human_parsing'] = result_1
            current_data = result_1.get('result', person_image)
            
            # 2ë‹¨ê³„: í¬ì¦ˆ ì¶”ì •
            if progress_callback:
                await progress_callback("pose_estimation", 20)
            
            result_2 = await self.steps['pose_estimation'].process(
                current_data,
                person_image=person_image
            )
            step_results['pose_estimation'] = result_2
            
            # 3ë‹¨ê³„: ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜
            if progress_callback:
                await progress_callback("cloth_segmentation", 35)
            
            result_3 = await self.steps['cloth_segmentation'].process(
                clothing_image,
                clothing_type=clothing_type,
                fabric_type=fabric_type
            )
            step_results['cloth_segmentation'] = result_3
            
            # 4ë‹¨ê³„: ê¸°í•˜í•™ì  ë§¤ì¹­
            if progress_callback:
                await progress_callback("geometric_matching", 50)
            
            result_4 = await self.steps['geometric_matching'].process(
                {
                    'person_data': result_2.get('result'),
                    'clothing_data': result_3.get('result'),
                    'body_measurements': body_measurements
                }
            )
            step_results['geometric_matching'] = result_4
            
            # 5ë‹¨ê³„: ì˜ë¥˜ ì›Œí•‘
            if progress_callback:
                await progress_callback("cloth_warping", 65)
            
            result_5 = await self.steps['cloth_warping'].process(
                result_4.get('result'),
                style_preferences=style_preferences or {}
            )
            step_results['cloth_warping'] = result_5
            
            # 6ë‹¨ê³„: ê°€ìƒ í”¼íŒ… ìƒì„±
            if progress_callback:
                await progress_callback("virtual_fitting", 80)
            
            result_6 = await self.steps['virtual_fitting'].process(
                {
                    'person_image': person_image,
                    'warped_clothing': result_5.get('result'),
                    'pose_data': result_2.get('result'),
                    'parsing_data': result_1.get('result')
                },
                quality_target=quality_target
            )
            step_results['virtual_fitting'] = result_6
            
            # 7ë‹¨ê³„: í›„ì²˜ë¦¬
            if progress_callback:
                await progress_callback("post_processing", 90)
            
            result_7 = await self.steps['post_processing'].process(
                result_6.get('result'),
                enhance_quality=True,
                remove_artifacts=True
            )
            step_results['post_processing'] = result_7
            
            # 8ë‹¨ê³„: í’ˆì§ˆ í‰ê°€
            if progress_callback:
                await progress_callback("quality_assessment", 95)
            
            result_8 = await self.steps['quality_assessment'].process(
                {
                    'original_person': person_image,
                    'fitted_result': result_7.get('result'),
                    'target_quality': quality_target
                }
            )
            step_results['quality_assessment'] = result_8
            
            # ìµœì¢… ê²°ê³¼ êµ¬ì„±
            processing_time = time.time() - start_time
            
            final_result = {
                'success': True,
                'result_image': result_7.get('result'),
                'step_results_summary': {k: v.get('success', False) for k, v in step_results.items()},
                'final_quality_score': result_8.get('overall_score', 0.85),
                'fit_analysis': {
                    'overall_fit_score': result_8.get('fit_overall', 0.8),
                    'body_measurements_match': True,
                    'style_compatibility': 0.9
                },
                'improvement_suggestions': {
                    'user_experience': [
                        f"âœ… {clothing_type} ìŠ¤íƒ€ì¼ì´ ì˜ ì–´ìš¸ë¦½ë‹ˆë‹¤!",
                        "ğŸ“ ì²´í˜•ì— ë§ëŠ” í•ìœ¼ë¡œ ì¡°ì •ë˜ì—ˆìŠµë‹ˆë‹¤",
                        "ğŸ¨ ìƒ‰ìƒê³¼ ìŠ¤íƒ€ì¼ì´ ì¡°í™”ë¡­ìŠµë‹ˆë‹¤"
                    ]
                },
                'processing_info': {
                    'device_used': self.gpu_config.device if self.gpu_config else 'cpu',
                    'processing_time_seconds': processing_time,
                    'steps_completed': len([r for r in step_results.values() if r.get('success')])
                },
                'quality_grade': self._calculate_quality_grade(result_8.get('overall_score', 0.85))
            }
            
            if progress_callback:
                await progress_callback("ì™„ë£Œ", 100)
            
            logger.info(f"âœ… 8ë‹¨ê³„ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ - {processing_time:.2f}ì´ˆ")
            return final_result
            
        except Exception as e:
            logger.error(f"âŒ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            return {
                'success': False,
                'error': str(e),
                'step_results_summary': step_results,
                'processing_time_seconds': time.time() - start_time
            }
    
    def _calculate_quality_grade(self, score: float) -> str:
        """í’ˆì§ˆ ì ìˆ˜ë¥¼ ë“±ê¸‰ìœ¼ë¡œ ë³€í™˜"""
        if score >= 0.9:
            return "Excellent"
        elif score >= 0.8:
            return "Good"
        elif score >= 0.7:
            return "Fair"
        else:
            return "Poor"
    
    async def get_pipeline_status(self) -> Dict[str, Any]:
        """íŒŒì´í”„ë¼ì¸ ìƒíƒœ ì¡°íšŒ"""
        return {
            'initialized': self.initialized,
            'device': self.gpu_config.device if self.gpu_config else 'unknown',
            'steps_status': {
                step_name: step.initialized if hasattr(step, 'initialized') else True 
                for step_name, step in self.steps.items()
            },
            'services_status': {
                'virtual_fitter': self.virtual_fitter is not None,
                'model_manager': self.model_manager is not None,
                'human_analyzer': self.human_analyzer is not None,
                'ai_fitter': self.ai_fitter is not None
            },
            'memory_usage': await self._get_memory_usage() if self.memory_manager else {},
            'performance_metrics': {
                'total_steps': len(self.steps),
                'available_services': len([s for s in [self.virtual_fitter, self.model_manager, self.human_analyzer, self.ai_fitter] if s])
            }
        }
    
    async def _get_memory_usage(self) -> Dict[str, float]:
        """ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¡°íšŒ"""
        try:
            if self.memory_manager:
                return await self.memory_manager.get_usage_stats()
            return {}
        except:
            return {}

# ì „ì—­ íŒŒì´í”„ë¼ì¸ ë§¤ë‹ˆì € ì¸ìŠ¤í„´ìŠ¤
pipeline_manager: Optional[MyClosetPipelineManager] = None

async def get_pipeline_manager() -> MyClosetPipelineManager:
    """íŒŒì´í”„ë¼ì¸ ë§¤ë‹ˆì € ì‹±ê¸€í†¤ ìƒì„±"""
    global pipeline_manager
    if pipeline_manager is None:
        pipeline_manager = MyClosetPipelineManager()
        await pipeline_manager.initialize()
    return pipeline_manager

# ============================================
# ğŸ“¡ WebSocket ì—°ê²° ê´€ë¦¬ (ê¸°ì¡´ê³¼ ë™ì¼)
# ============================================

class ConnectionManager:
    def __init__(self):
        self.active_connections: Dict[str, WebSocket] = {}
    
    async def connect(self, websocket: WebSocket, session_id: str):
        await websocket.accept()
        self.active_connections[session_id] = websocket
        logger.info(f"WebSocket ì—°ê²°: {session_id}")
    
    def disconnect(self, session_id: str):
        if session_id in self.active_connections:
            del self.active_connections[session_id]
            logger.info(f"WebSocket ì—°ê²° í•´ì œ: {session_id}")
    
    async def send_progress(self, session_id: str, stage: str, percentage: int, message: str = ""):
        if session_id in self.active_connections:
            websocket = self.active_connections[session_id]
            if websocket.client_state == WebSocketState.CONNECTED:
                try:
                    await websocket.send_json({
                        "type": "progress",
                        "stage": stage,
                        "percentage": percentage,
                        "message": message,
                        "timestamp": datetime.now().isoformat()
                    })
                except Exception as e:
                    logger.warning(f"WebSocket ë©”ì‹œì§€ ì „ì†¡ ì‹¤íŒ¨ {session_id}: {e}")
                    self.disconnect(session_id)

manager = ConnectionManager()

# ============================================
# ğŸ“‹ ìš”ì²­/ì‘ë‹µ ëª¨ë¸ (ê¸°ì¡´ ëŒ€ë¹„ ê°œì„ )
# ============================================

class MyClosetVirtualTryOnRequest(BaseModel):
    height: float = Field(..., description="í‚¤ (cm)", example=170.0)
    weight: float = Field(..., description="ëª¸ë¬´ê²Œ (kg)", example=65.0)
    chest: Optional[float] = Field(None, description="ê°€ìŠ´ë‘˜ë ˆ (cm)", example=95.0)
    waist: Optional[float] = Field(None, description="í—ˆë¦¬ë‘˜ë ˆ (cm)", example=80.0)
    hip: Optional[float] = Field(None, description="ì—‰ë©ì´ë‘˜ë ˆ (cm)", example=90.0)
    clothing_type: str = Field("shirt", description="ì˜ë¥˜ íƒ€ì…", example="shirt")
    fabric_type: str = Field("cotton", description="ì²œ ì¬ì§ˆ", example="cotton")
    style_preference: str = Field("regular", description="í• ì„ í˜¸ë„", example="slim")
    quality_level: str = Field("high", description="í’ˆì§ˆ ë ˆë²¨", example="high")
    use_real_ai: bool = Field(True, description="ì‹¤ì œ AI íŒŒì´í”„ë¼ì¸ ì‚¬ìš© ì—¬ë¶€")

class MyClosetVirtualTryOnResponse(BaseModel):
    success: bool
    session_id: str
    fitted_image_url: Optional[str] = None
    fitted_image_base64: Optional[str] = None
    fitted_image: Optional[str] = None  # UI í˜¸í™˜ì„±
    processing_time: float
    confidence: float = Field(..., description="ì „ì²´ ì‹ ë¢°ë„")
    fit_score: float = Field(..., description="í• ì ìˆ˜")
    quality_score: float = Field(..., description="í’ˆì§ˆ ì ìˆ˜")
    quality_grade: str = Field(..., description="í’ˆì§ˆ ë“±ê¸‰")
    recommendations: List[str] = Field(default_factory=list)
    measurements: Dict[str, Any] = Field(default_factory=dict)
    clothing_analysis: Dict[str, Any] = Field(default_factory=dict)
    quality_analysis: Dict[str, Any] = Field(default_factory=dict)
    processing_info: Dict[str, Any] = Field(default_factory=dict)
    pipeline_status: Dict[str, Any] = Field(default_factory=dict)  # ì¶”ê°€
    error: Optional[str] = None

# ============================================
# ğŸ› ï¸ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤ (ê°œì„ )
# ============================================

async def save_uploaded_file(upload_file: UploadFile, session_id: str, file_type: str) -> str:
    """ì—…ë¡œë“œëœ íŒŒì¼ ì €ì¥ (FileManager í™œìš©)"""
    try:
        if not upload_file.filename.lower().endswith(('.png', '.jpg', '.jpeg')):
            raise HTTPException(400, "ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤.")
        
        # FileManager ì‚¬ìš© (ìˆëŠ” ê²½ìš°)
        if FileManager:
            file_manager = FileManager()
            return await file_manager.save_upload(upload_file, session_id, file_type)
        
        # ê¸°ë³¸ êµ¬í˜„
        upload_dir = Path("static/uploads") / session_id
        upload_dir.mkdir(parents=True, exist_ok=True)
        
        timestamp = int(time.time())
        file_extension = Path(upload_file.filename).suffix
        filename = f"{file_type}_{timestamp}{file_extension}"
        file_path = upload_dir / filename
        
        async with aiofiles.open(file_path, 'wb') as f:
            content = await upload_file.read()
            await f.write(content)
        
        logger.info(f"ğŸ“ íŒŒì¼ ì €ì¥ ì™„ë£Œ: {file_path}")
        return str(file_path)
        
    except Exception as e:
        logger.error(f"âŒ íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: {e}")
        raise HTTPException(500, f"íŒŒì¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")

async def process_result_image(result_image: Any, session_id: str) -> str:
    """ê²°ê³¼ ì´ë¯¸ì§€ ì²˜ë¦¬ ë° base64 ì¸ì½”ë”© (image_utils í™œìš©)"""
    try:
        # ì´ë¯¸ì§€ ìœ í‹¸ë¦¬í‹° ì‚¬ìš© (ìˆëŠ” ê²½ìš°)
        if hasattr(result_image, 'save'):
            pil_image = result_image
        elif isinstance(result_image, np.ndarray):
            pil_image = Image.fromarray(result_image)
        else:
            pil_image = Image.fromarray(np.array(result_image))
        
        # enhance_image_quality ì ìš© (ìˆëŠ” ê²½ìš°)
        if 'enhance_image_quality' in globals():
            pil_image = enhance_image_quality(pil_image)
        
        # íŒŒì¼ë¡œ ì €ì¥
        result_dir = Path("static/results")
        result_dir.mkdir(parents=True, exist_ok=True)
        save_path = result_dir / f"{session_id}_result.jpg"
        pil_image.save(save_path, "JPEG", quality=95)
        
        # base64 ì¸ì½”ë”©
        buffer = BytesIO()
        pil_image.save(buffer, format="JPEG", quality=95)
        image_base64 = base64.b64encode(buffer.getvalue()).decode('utf-8')
        
        return image_base64
        
    except Exception as e:
        logger.error(f"ê²°ê³¼ ì´ë¯¸ì§€ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        # ê¸°ë³¸ ì´ë¯¸ì§€ ë°˜í™˜
        default_image = Image.new('RGB', (512, 512), color='lightgray')
        buffer = BytesIO()
        default_image.save(buffer, format="JPEG")
        return base64.b64encode(buffer.getvalue()).decode('utf-8')

# ============================================
# ğŸš€ ë©”ì¸ API ì—”ë“œí¬ì¸íŠ¸ë“¤ 
# ============================================

@router.post("/process", response_model=MyClosetVirtualTryOnResponse)
async def mycloset_virtual_tryon_process(
    background_tasks: BackgroundTasks,
    person_image: UploadFile = File(..., description="ì‚¬ìš©ì ì‚¬ì§„"),
    clothing_image: UploadFile = File(..., description="ì˜ë¥˜ ì‚¬ì§„"),
    height: float = Form(..., description="í‚¤ (cm)"),
    weight: float = Form(..., description="ëª¸ë¬´ê²Œ (kg)"),
    chest: Optional[float] = Form(None, description="ê°€ìŠ´ë‘˜ë ˆ (cm)"),
    waist: Optional[float] = Form(None, description="í—ˆë¦¬ë‘˜ë ˆ (cm)"),
    hip: Optional[float] = Form(None, description="ì—‰ë©ì´ë‘˜ë ˆ (cm)"),
    clothing_type: str = Form("shirt", description="ì˜ë¥˜ íƒ€ì…"),
    fabric_type: str = Form("cotton", description="ì²œ ì¬ì§ˆ"),
    style_preference: str = Form("regular", description="í• ì„ í˜¸ë„"),
    quality_level: str = Form("high", description="í’ˆì§ˆ ë ˆë²¨"),
    use_real_ai: bool = Form(True, description="ì‹¤ì œ AI íŒŒì´í”„ë¼ì¸ ì‚¬ìš©")
):
    """
    ğŸ¯ MyCloset AI ë©”ì¸ ê°€ìƒ í”¼íŒ… API
    
    ì‹¤ì œ 8ë‹¨ê³„ AI íŒŒì´í”„ë¼ì¸ê³¼ ê¸°ì¡´ ì„œë¹„ìŠ¤ë“¤ì„ ì™„ì „ í™œìš©í•œ 
    í”„ë¡œë•ì…˜ ë ˆë²¨ ê°€ìƒ í”¼íŒ… ì„œë¹„ìŠ¤
    """
    session_id = str(uuid.uuid4())
    start_time = time.time()
    
    try:
        logger.info(f"ğŸ¯ MyCloset AI ê°€ìƒ í”¼íŒ… ì‹œì‘ - ì„¸ì…˜: {session_id}")
        
        # íŒŒì´í”„ë¼ì¸ ë§¤ë‹ˆì € ì´ˆê¸°í™”
        pm = await get_pipeline_manager()
        
        # ì‹¤ì œ AI ì‚¬ìš© ë¶ˆê°€ì‹œ ë°ëª¨ ëª¨ë“œ ì²˜ë¦¬
        if not AI_PIPELINE_AVAILABLE or not use_real_ai:
            logger.info("âš ï¸ ë°ëª¨ ëª¨ë“œë¡œ ì‹¤í–‰")
            return await _demo_virtual_tryon(
                person_image, clothing_image, height, weight,
                clothing_type, session_id, start_time
            )
        
        # íŒŒì¼ ì €ì¥
        person_image_path = await save_uploaded_file(person_image, session_id, "person")
        clothing_image_path = await save_uploaded_file(clothing_image, session_id, "clothing")
        
        # ì‹ ì²´ ì¹˜ìˆ˜ êµ¬ì„±
        body_measurements = {
            "height": height,
            "weight": weight,
            "bmi": weight / ((height/100) ** 2)
        }
        if chest: body_measurements["chest"] = chest
        if waist: body_measurements["waist"] = waist
        if hip: body_measurements["hip"] = hip
        
        # ìŠ¤íƒ€ì¼ ì„ í˜¸ë„
        style_preferences = {
            "fit": style_preference,
            "color_preference": "original",
            "style_adaptation": True
        }
        
        # í’ˆì§ˆ íƒ€ê²Ÿ ì„¤ì •
        quality_targets = {
            "fast": 0.7,
            "medium": 0.8, 
            "high": 0.9,
            "ultra": 0.95
        }
        quality_target = quality_targets.get(quality_level, 0.8)
        
        # ì§„í–‰ë¥  ì½œë°±
        async def progress_callback(stage: str, percentage: int):
            await manager.send_progress(session_id, stage, percentage)
        
        # ğŸš€ ì‹¤ì œ 8ë‹¨ê³„ AI íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
        logger.info("ğŸ¤– MyCloset AI 8ë‹¨ê³„ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰...")
        result = await pm.process_complete_virtual_fitting(
            person_image=person_image_path,
            clothing_image=clothing_image_path,
            body_measurements=body_measurements,
            clothing_type=clothing_type,
            fabric_type=fabric_type,
            style_preferences=style_preferences,
            quality_target=quality_target,
            progress_callback=progress_callback
        )
        
        # ê²°ê³¼ ì²˜ë¦¬
        if result['success']:
            # ê²°ê³¼ ì´ë¯¸ì§€ ì²˜ë¦¬
            result_image_base64 = await process_result_image(
                result.get('result_image'), session_id
            )
            
            processing_time = time.time() - start_time
            
            # íŒŒì´í”„ë¼ì¸ ìƒíƒœ ì¡°íšŒ
            pipeline_status = await pm.get_pipeline_status()
            
            # MyCloset AI ì‘ë‹µ êµ¬ì„±
            response = MyClosetVirtualTryOnResponse(
                success=True,
                session_id=session_id,
                fitted_image_url=f"/static/results/{session_id}_result.jpg",
                fitted_image_base64=result_image_base64,
                fitted_image=result_image_base64,  # UI í˜¸í™˜
                processing_time=processing_time,
                confidence=result.get('final_quality_score', 0.85),
                fit_score=result.get('fit_analysis', {}).get('overall_fit_score', 0.88),
                quality_score=result.get('final_quality_score', 0.85),
                quality_grade=result.get('quality_grade', 'Good'),
                recommendations=result.get('improvement_suggestions', {}).get('user_experience', [
                    f"âœ… {clothing_type} ìŠ¤íƒ€ì¼ì´ MyCloset AIë¡œ ì™„ë²½ í”¼íŒ…ë˜ì—ˆìŠµë‹ˆë‹¤!",
                    "ğŸ“ 8ë‹¨ê³„ AI íŒŒì´í”„ë¼ì¸ìœ¼ë¡œ ì²´í˜•ì— ìµœì í™”ë˜ì—ˆìŠµë‹ˆë‹¤",
                    "ğŸ¨ M3 Max GPU ê°€ì†ìœ¼ë¡œ ê³ í’ˆì§ˆ ë Œë”ë§ë˜ì—ˆìŠµë‹ˆë‹¤"
                ])[:3],
                measurements=body_measurements,
                clothing_analysis={
                    "category": clothing_type,
                    "style": style_preference,
                    "fabric": fabric_type,
                    "ai_processed": True
                },
                quality_analysis={
                    "overall_score": result.get('final_quality_score', 0.85),
                    "fit_quality": result.get('fit_analysis', {}).get('overall_fit_score', 0.8),
                    "processing_quality": min(1.0, 30.0 / processing_time) if processing_time > 0 else 1.0,
                    "pipeline_efficiency": len(result.get('step_results_summary', {})) / 8.0
                },
                processing_info={
                    "steps_completed": len(result.get('step_results_summary', {})),
                    "quality_level": quality_level,
                    "device_used": result.get('processing_info', {}).get('device_used', 'cpu'),
                    "optimization": "M3_Max_Optimized" if "mps" in str(result.get('processing_info', {})) else "Standard",
                    "ai_pipeline_version": "MyCloset_8_Steps_v1.0"
                },
                pipeline_status=pipeline_status
            )
            
            # ë°±ê·¸ë¼ìš´ë“œ ì •ë¦¬
            background_tasks.add_task(_cleanup_session_files, session_id)
            
            logger.info(f"âœ… MyCloset AI ê°€ìƒ í”¼íŒ… ì™„ë£Œ - {processing_time:.2f}ì´ˆ")
            return response
            
        else:
            # ì²˜ë¦¬ ì‹¤íŒ¨
            error_msg = result.get('error', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.')
            logger.error(f"âŒ MyCloset AI í”¼íŒ… ì‹¤íŒ¨ - {session_id}: {error_msg}")
            
            return MyClosetVirtualTryOnResponse(
                success=False,
                session_id=session_id,
                processing_time=time.time() - start_time,
                confidence=0.0,
                fit_score=0.0,
                quality_score=0.0,
                quality_grade="Failed",
                error=error_msg,
                measurements=body_measurements,
                clothing_analysis={},
                quality_analysis={},
                processing_info={},
                pipeline_status={}
            )
            
    except Exception as e:
        processing_time = time.time() - start_time
        error_msg = f"MyCloset AI ê°€ìƒ í”¼íŒ… ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}"
        logger.error(f"âŒ ì„¸ì…˜ {session_id}: {e}")
        
        return MyClosetVirtualTryOnResponse(
            success=False,
            session_id=session_id,
            processing_time=processing_time,
            confidence=0.0,
            fit_score=0.0,
            quality_score=0.0,
            quality_grade="Error",
            error=error_msg,
            measurements={"height": height, "weight": weight},
            clothing_analysis={},
            quality_analysis={},
            processing_info={},
            pipeline_status={}
        )

# ============================================
# ğŸŒ ì¶”ê°€ API ì—”ë“œí¬ì¸íŠ¸ë“¤
# ============================================

@router.websocket("/ws/{session_id}")
async def websocket_endpoint(websocket: WebSocket, session_id: str):
    """ì‹¤ì‹œê°„ ì§„í–‰ìƒí™© WebSocket (ê¸°ì¡´ê³¼ ë™ì¼)"""
    await manager.connect(websocket, session_id)
    try:
        while True:
            data = await websocket.receive_text()
            if data == "ping":
                await websocket.send_text("pong")
    except WebSocketDisconnect:
        manager.disconnect(session_id)

@router.get("/models/status")
async def get_mycloset_models_status():
    """MyCloset AI ëª¨ë¸ ìƒíƒœ ì¡°íšŒ"""
    try:
        pm = await get_pipeline_manager()
        status = await pm.get_pipeline_status()
        
        return {
            "mycloset_ai_version": "1.0.0",
            "pipeline_available": AI_PIPELINE_AVAILABLE,
            "initialized": status['initialized'],
            "device": status['device'],
            "steps_status": status.get('steps_status', {}),
            "services_status": status.get('services_status', {}),
            "performance": status.get('performance_metrics', {}),
            "memory_usage": status.get('memory_usage', {}),
            "optimization": "M3_Max" if status['device'] == 'mps' else "Standard"
        }
        
    except Exception as e:
        logger.error(f"âŒ ëª¨ë¸ ìƒíƒœ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return {
            "mycloset_ai_version": "1.0.0",
            "pipeline_available": False,
            "error": str(e)
        }

@router.get("/supported-features")
async def get_mycloset_supported_features():
    """MyCloset AI ì§€ì› ê¸°ëŠ¥ ëª©ë¡"""
    return {
        "mycloset_ai_features": {
            "8_step_pipeline": ["Human Parsing", "Pose Estimation", "Cloth Segmentation", 
                               "Geometric Matching", "Cloth Warping", "Virtual Fitting", 
                               "Post Processing", "Quality Assessment"],
            "m3_max_optimization": True,
            "real_time_processing": True,
            "high_quality_rendering": True
        },
        "clothing_types": [
            {"id": "shirt", "name": "ì…”ì¸ ", "category": "ìƒì˜", "ai_optimized": True},
            {"id": "pants", "name": "ë°”ì§€", "category": "í•˜ì˜", "ai_optimized": True},
            {"id": "dress", "name": "ì›í”¼ìŠ¤", "category": "ì „ì‹ ", "ai_optimized": True},
            {"id": "jacket", "name": "ì¬í‚·", "category": "ìƒì˜", "ai_optimized": True}
        ],
        "quality_levels": [
            {"id": "fast", "name": "ë¹ ë¦„", "target_time": 5, "ai_steps": 6},
            {"id": "high", "name": "ê³ í’ˆì§ˆ", "target_time": 30, "ai_steps": 8},
            {"id": "ultra", "name": "ìµœê³ í’ˆì§ˆ", "target_time": 60, "ai_steps": 8}
        ],
        "device_optimization": {
            "m3_max": {"supported": True, "performance_boost": "3x"},
            "cuda": {"supported": True, "performance_boost": "2x"},
            "cpu": {"supported": True, "performance_boost": "1x"}
        }
    }

# ============================================
# ğŸ› ï¸ í—¬í¼ í•¨ìˆ˜ë“¤
# ============================================

async def _demo_virtual_tryon(
    person_image: UploadFile,
    clothing_image: UploadFile,
    height: float,
    weight: float,
    clothing_type: str,
    session_id: str,
    start_time: float
) -> MyClosetVirtualTryOnResponse:
    """ë°ëª¨ ëª¨ë“œ ì²˜ë¦¬ (AI íŒŒì´í”„ë¼ì¸ ì—†ì„ ë•Œ)"""
    
    try:
        # ê¸°ë³¸ ì´ë¯¸ì§€ ì²˜ë¦¬
        person_pil = Image.open(BytesIO(await person_image.read())).convert('RGB')
        clothing_pil = Image.open(BytesIO(await clothing_image.read())).convert('RGB')
        
        # ê°„ë‹¨í•œ í•©ì„±
        result = person_pil.copy()
        clothing_resized = clothing_pil.resize((200, 200))
        result.paste(clothing_resized, (150, 100))
        
        # ë°ëª¨ í…ìŠ¤íŠ¸ ì¶”ê°€
        draw = ImageDraw.Draw(result)
        try:
            font = ImageFont.truetype("arial.ttf", 20)
        except:
            font = ImageFont.load_default()
        
        draw.text((10, 470), "ğŸš§ MyCloset AI Demo", fill=(255, 100, 100), font=font)
        
        # base64 ì¸ì½”ë”©
        result_base64 = await process_result_image(result, session_id)
        
        await asyncio.sleep(2)  # ë°ëª¨ ì²˜ë¦¬ ì‹œê°„
        processing_time = time.time() - start_time
        
        return MyClosetVirtualTryOnResponse(
            success=True,
            session_id=session_id,
            fitted_image_base64=result_base64,
            fitted_image=result_base64,
            processing_time=processing_time,
            confidence=0.75,
            fit_score=0.78,
            quality_score=0.72,
            quality_grade="Demo",
            recommendations=[
                "ğŸš§ MyCloset AI ë°ëª¨ ëª¨ë“œë¡œ ì²˜ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤",
                "âš¡ ì‹¤ì œ 8ë‹¨ê³„ AI íŒŒì´í”„ë¼ì¸ ë¡œë”© ì¤‘...",
                f"ğŸ‘” {clothing_type} ìŠ¤íƒ€ì¼ ì‹œë®¬ë ˆì´ì…˜"
            ],
            measurements={"height": height, "weight": weight, "bmi": weight/((height/100)**2)},
            clothing_analysis={"category": clothing_type, "demo_mode": True},
            quality_analysis={"demo_mode": True},
            processing_info={"demo_mode": True, "device": "cpu"},
            pipeline_status={"demo_mode": True}
        )
        
    except Exception as e:
        logger.error(f"âŒ ë°ëª¨ ëª¨ë“œ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        raise HTTPException(500, "ë°ëª¨ ëª¨ë“œ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")

async def _cleanup_session_files(session_id: str):
    """ì„¸ì…˜ íŒŒì¼ ì •ë¦¬"""
    try:
        await asyncio.sleep(3600)  # 1ì‹œê°„ í›„ ì •ë¦¬
        
        upload_dir = Path("static/uploads") / session_id
        if upload_dir.exists():
            import shutil
            shutil.rmtree(upload_dir)
        
        logger.info(f"ğŸ§¹ ì„¸ì…˜ íŒŒì¼ ì •ë¦¬ ì™„ë£Œ: {session_id}")
    except Exception as e:
        logger.warning(f"âš ï¸ ì„¸ì…˜ íŒŒì¼ ì •ë¦¬ ì‹¤íŒ¨ {session_id}: {e}")

# ============================================
# ğŸš€ ì• í”Œë¦¬ì¼€ì´ì…˜ ì´ë²¤íŠ¸
# ============================================

@router.on_event("startup")
async def startup_event():
    """MyCloset AI API ì‹œì‘"""
    logger.info("ğŸš€ MyCloset AI Virtual Try-On API ì‹œì‘...")
    
    # ë””ë ‰í† ë¦¬ ìƒì„±
    Path("static/uploads").mkdir(parents=True, exist_ok=True)
    Path("static/results").mkdir(parents=True, exist_ok=True)
    
    # íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” (ë°±ê·¸ë¼ìš´ë“œ)
    if AI_PIPELINE_AVAILABLE:
        asyncio.create_task(get_pipeline_manager())
        logger.info("âœ… MyCloset AI 8ë‹¨ê³„ íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” ì‹œì‘")
    else:
        logger.warning("âš ï¸ ë°ëª¨ ëª¨ë“œë¡œ ì‹œì‘ - AI íŒŒì´í”„ë¼ì¸ ì‚¬ìš© ë¶ˆê°€")

@router.on_event("shutdown")
async def shutdown_event():
    """MyCloset AI API ì¢…ë£Œ"""
    logger.info("ğŸ›‘ MyCloset AI Virtual Try-On API ì¢…ë£Œ...")
    
    global pipeline_manager
    if pipeline_manager:
        # ë¦¬ì†ŒìŠ¤ ì •ë¦¬ (í•„ìš”ì‹œ êµ¬í˜„)
        pass