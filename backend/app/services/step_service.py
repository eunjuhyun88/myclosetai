# backend/app/services/step_service_manager.py
"""
ðŸ”¥ StepServiceManager v16.0 - Central Hub DI Container v7.0 ì™„ì „ ì—°ë™
================================================================================

í•µì‹¬ ìˆ˜ì • ì‚¬í•­:
âœ… Central Hub DI Container v7.0 ì™„ì „ ì—°ë™ - ì¤‘ì•™ í—ˆë¸Œ íŒ¨í„´ ì ìš©
âœ… ìˆœí™˜ì°¸ì¡° ì™„ì „ í•´ê²° - TYPE_CHECKING + ì§€ì—° import ì™„ë²½ ì ìš©
âœ… ë‹¨ë°©í–¥ ì˜ì¡´ì„± ê·¸ëž˜í”„ - DI Containerë§Œì„ í†µí•œ ì˜ì¡´ì„± ì£¼ìž…
âœ… StepFactory v11.2ì™€ ì™„ì „ í˜¸í™˜
âœ… BaseStepMixin v20.0ì˜ Central Hub ê¸°ë°˜ êµ¬ì¡° ë°˜ì˜
âœ… ê¸°ì¡´ API 100% í˜¸í™˜ì„± ìœ ì§€
âœ… ì ì§„ì  ë§ˆì´ê·¸ë ˆì´ì…˜ ì§€ì› (Central Hub ì—†ì´ë„ ë™ìž‘)
âœ… ìžë™ ì˜ì¡´ì„± ì£¼ìž…ìœ¼ë¡œ ê°œë°œìž íŽ¸ì˜ì„± í–¥ìƒ
âœ… Central Hub ê¸°ë°˜ í†µí•© ë©”íŠ¸ë¦­ ë° ëª¨ë‹ˆí„°ë§

êµ¬ì¡°:
step_routes.py â†’ StepServiceManager v16.0 â†’ Central Hub DI Container v7.0 â†’ StepFactory v11.2 â†’ BaseStepMixin v20.0 â†’ ì‹¤ì œ AI ëª¨ë¸

Author: MyCloset AI Team
Date: 2025-08-01
Version: 16.0 (Central Hub DI Container Integration)
"""

import os
import sys
import logging
import asyncio
import time
import threading
import uuid
import gc
import json
import traceback
import weakref
import base64
import importlib.util
import hashlib
from typing import Dict, Any, Optional, Union, List, TYPE_CHECKING, Callable, Tuple
from datetime import datetime, timedelta
from dataclasses import dataclass, field
from enum import Enum
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor
from contextlib import asynccontextmanager
from collections import defaultdict, deque
import socket

# ==============================================
# ðŸ”¥ Central Hub DI Container ì•ˆì „ import (ìˆœí™˜ì°¸ì¡° ë°©ì§€)
# ==============================================

def _get_central_hub_container():
    """Central Hub DI Container ì•ˆì „í•œ ë™ì  í•´ê²°"""
    try:
        import importlib
        module = importlib.import_module('app.core.di_container')
        get_global_fn = getattr(module, 'get_global_container', None)
        if get_global_fn:
            return get_global_fn()
        return None
    except ImportError:
        return None
    except Exception:
        return None

def _get_service_from_central_hub(service_key: str):
    """Central Hubë¥¼ í†µí•œ ì•ˆì „í•œ ì„œë¹„ìŠ¤ ì¡°íšŒ"""
    try:
        container = _get_central_hub_container()
        if container:
            return container.get(service_key)
        return None
    except Exception:
        return None

def _inject_dependencies_to_step_safe(step_instance):
    """Central Hubë¥¼ í†µí•œ ì•ˆì „í•œ Step ì˜ì¡´ì„± ì£¼ìž…"""
    try:
        container = _get_central_hub_container()
        if container and hasattr(container, 'inject_to_step'):
            return container.inject_to_step(step_instance)
        return 0
    except Exception:
        return 0

# ==============================================
# ðŸ”¥ TYPE_CHECKINGìœ¼ë¡œ ìˆœí™˜ì°¸ì¡° ì™„ì „ ë°©ì§€
# ==============================================

if TYPE_CHECKING:
    # íƒ€ìž… ì²´í‚¹ ì‹œì—ë§Œ import (ìˆœí™˜ì°¸ì¡° ë°©ì§€)
    from ..ai_pipeline.factories.step_factory import (
        StepFactory, CentralHubStepMapping, CentralHubStepConfig, 
        CentralHubStepCreationResult, StepType
    )
    from ..ai_pipeline.steps.base_step_mixin import BaseStepMixin
    from ..ai_pipeline.interface.step_interface import DetailedDataSpecConfig
    from app.core.di_container import CentralHubDIContainer
    from fastapi import UploadFile
    import torch
    import numpy as np
    from PIL import Image
else:
    # ëŸ°íƒ€ìž„ì—ëŠ” Anyë¡œ ì²˜ë¦¬
    StepFactory = Any
    CentralHubStepMapping = Any
    CentralHubStepConfig = Any
    CentralHubStepCreationResult = Any
    StepType = Any
    BaseStepMixin = Any
    DetailedDataSpecConfig = Any
    CentralHubDIContainer = Any

# ==============================================
# ðŸ”¥ ë¡œê¹… ì„¤ì •
# ==============================================

logger = logging.getLogger(__name__)

# ==============================================
# ðŸ”¥ í™˜ê²½ ì •ë³´ ìˆ˜ì§‘ (Central Hub ê¸°ë°˜)
# ==============================================

# conda í™˜ê²½ ì •ë³´
CONDA_INFO = {
    'conda_env': os.environ.get('CONDA_DEFAULT_ENV', 'none'),
    'conda_prefix': os.environ.get('CONDA_PREFIX', 'none'),
    'is_target_env': os.environ.get('CONDA_DEFAULT_ENV') == 'mycloset-ai-clean'
}

# M3 Max ê°ì§€
IS_M3_MAX = False
MEMORY_GB = 16.0

try:
    import platform
    if platform.system() == 'Darwin' and platform.machine() == 'arm64':
        try:
            import subprocess
            result = subprocess.run(['sysctl', '-n', 'machdep.cpu.brand_string'], 
                                  capture_output=True, text=True, timeout=3)
            IS_M3_MAX = 'M3' in result.stdout
            
            memory_result = subprocess.run(['sysctl', '-n', 'hw.memsize'], 
                                         capture_output=True, text=True, timeout=3)
            if memory_result.stdout.strip():
                MEMORY_GB = int(memory_result.stdout.strip()) / 1024**3
        except:
            pass
except:
    pass

# ë””ë°”ì´ìŠ¤ ìžë™ ê°ì§€
DEVICE = "cpu"
TORCH_AVAILABLE = False

try:
    import torch
    TORCH_AVAILABLE = True
    
    if IS_M3_MAX and hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
        DEVICE = "mps"
    elif torch.cuda.is_available():
        DEVICE = "cuda"
    else:
        DEVICE = "cpu"
except ImportError:
    pass

# NumPy ë° PIL ê°€ìš©ì„±
try:
    import numpy as np
    NUMPY_AVAILABLE = True
except ImportError:
    NUMPY_AVAILABLE = False

try:
    from PIL import Image
    PIL_AVAILABLE = True
except ImportError:
    PIL_AVAILABLE = False

logger.info(f"ðŸ”§ StepServiceManager v16.0 í™˜ê²½: conda={CONDA_INFO['conda_env']}, M3 Max={IS_M3_MAX}, ë””ë°”ì´ìŠ¤={DEVICE}")

# ==============================================
# ðŸ”¥ StepFactory ë™ì  Import (ìˆœí™˜ì°¸ì¡° ë°©ì§€)
# ==============================================
def get_step_factory() -> Optional[Any]:
    """StepFactory ë™ì  import - ë””ë ‰í† ë¦¬ êµ¬ì¡° í†µì¼"""
    try:
        # âœ… ì‹¤ì œ ì¡´ìž¬í•˜ëŠ” ë””ë ‰í† ë¦¬ ê²½ë¡œë“¤ ìš°ì„  (factories vs factory)
        import_paths = [
            # factories ë””ë ‰í† ë¦¬ (í˜„ìž¬ ì‹¤ì œ ìœ„ì¹˜)
            "backend.app.ai_pipeline.factories.step_factory",
            "app.ai_pipeline.factories.step_factory", 
            "ai_pipeline.factories.step_factory",
            
            # factory ë””ë ‰í† ë¦¬ (ë ˆê±°ì‹œ)
            "backend.app.ai_pipeline.factory.step_factory",
            "app.ai_pipeline.factory.step_factory",
            "ai_pipeline.factory.step_factory",
            
            # ì„œë¹„ìŠ¤ ê²½ë¡œ
            "backend.app.services.unified_step_mapping",
            "app.services.unified_step_mapping",
            "services.unified_step_mapping",
            
            # ì§ì ‘ ê²½ë¡œ
            "step_factory"
        ]
        
        for import_path in import_paths:
            try:
                import importlib
                module = importlib.import_module(import_path)
                
                if hasattr(module, 'StepFactory'):
                    StepFactory = getattr(module, 'StepFactory')
                    
                    # ì „ì—­ íŒ©í† ë¦¬ í•¨ìˆ˜ í™œìš©
                    if hasattr(module, 'get_global_step_factory'):
                        try:
                            factory_instance = module.get_global_step_factory()
                            if factory_instance:
                                logger.info(f"âœ… StepFactory ì „ì—­ ì¸ìŠ¤í„´ìŠ¤ ë¡œë“œ: {import_path}")
                                return factory_instance
                        except Exception as e:
                            logger.debug(f"ì „ì—­ íŒ©í† ë¦¬ ìƒì„± ì‹¤íŒ¨: {e}")
                    
                    # ì§ì ‘ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
                    try:
                        factory_instance = StepFactory()
                        logger.info(f"âœ… StepFactory ì¸ìŠ¤í„´ìŠ¤ ìƒì„±: {import_path}")
                        return factory_instance
                    except Exception as e:
                        logger.debug(f"ì§ì ‘ ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ì‹¤íŒ¨: {e}")
                        
            except ImportError as e:
                logger.debug(f"Import ì‹¤íŒ¨ {import_path}: {e}")
                continue
            except Exception as e:
                logger.debug(f"Import ì˜¤ë¥˜ {import_path}: {e}")
                continue
        
        logger.error("âŒ StepFactory import ì™„ì „ ì‹¤íŒ¨ - ëª¨ë“  ê²½ë¡œ ì‹œë„")
        return None
        
    except Exception as e:
        logger.error(f"âŒ StepFactory import ì˜¤ë¥˜: {e}")
        return None

# ðŸ”¥ AutoModelDetector import ì˜¤ë¥˜ í•´ê²°
def get_auto_model_detector():
    """AutoModelDetector ì•ˆì „í•œ import"""
    try:
        # AutoModelDetector import ì‹œë„
        detector_paths = [
            "backend.app.ai_pipeline.utils.auto_model_detector",
            "app.ai_pipeline.utils.auto_model_detector",
            "ai_pipeline.utils.auto_model_detector",
            "backend.app.ai_pipeline.auto_detector", 
            "app.ai_pipeline.auto_detector",
            "ai_pipeline.auto_detector"
        ]
        
        for path in detector_paths:
            try:
                import importlib
                module = importlib.import_module(path)
                
                if hasattr(module, 'AutoModelDetector'):
                    AutoModelDetector = getattr(module, 'AutoModelDetector')
                    detector_instance = AutoModelDetector()
                    logger.info(f"âœ… AutoModelDetector ë¡œë”© ì„±ê³µ: {path}")
                    return detector_instance
                    
            except ImportError:
                continue
            except Exception as e:
                logger.debug(f"AutoModelDetector ë¡œë”© ì‹¤íŒ¨: {e}")
                continue
        
        logger.warning("âš ï¸ AutoModelDetector import ì‹¤íŒ¨, Mock ì‚¬ìš©")
        
        # Mock AutoModelDetector
        class MockAutoModelDetector:
            def __init__(self):
                self.is_mock = True
                
            def detect_models(self):
                return []
                
            def get_model_info(self, model_name):
                return {}
        
        return MockAutoModelDetector()
        
    except Exception as e:
        logger.error(f"âŒ AutoModelDetector ë¡œë”© ì˜¤ë¥˜: {e}")
        return None

# ðŸ”¥ ê°œì„ ëœ StepFactory ì»´í¬ë„ŒíŠ¸ ë¡œë”©
def _get_step_factory_components():
    """StepFactory ì»´í¬ë„ŒíŠ¸ë“¤ ì•ˆì „ ë¡œë”© - ë””ë ‰í† ë¦¬ êµ¬ì¡° í†µì¼"""
    components = {
        'StepFactory': None,
        'create_step': None,
        'StepType': None,
        'available': False,
        'version': 'unknown',
        'import_path': None
    }
    
    try:
        step_factory = get_step_factory()
        if step_factory:
            # StepFactory ëª¨ë“ˆì—ì„œ ì»´í¬ë„ŒíŠ¸ë“¤ ì¶”ì¶œ
            factory_module = sys.modules.get(step_factory.__class__.__module__)
            if factory_module:
                components.update({
                    'StepFactory': getattr(factory_module, 'StepFactory', None),
                    'create_step': getattr(factory_module, 'create_step', None),
                    'StepType': getattr(factory_module, 'StepType', None),
                    'create_virtual_fitting_step': getattr(factory_module, 'create_virtual_fitting_step', None),
                    'get_global_step_factory': getattr(factory_module, 'get_global_step_factory', None),
                    'available': True,
                    'factory_instance': step_factory,
                    'import_path': factory_module.__name__,
                    'version': getattr(factory_module, '__version__', 'v11.2')
                })
                logger.info(f"âœ… StepFactory ì»´í¬ë„ŒíŠ¸ ë¡œë”© ì„±ê³µ: {factory_module.__name__}")
                
                # StepFactory í†µê³„ ì •ë³´ ì¶”ê°€
                if hasattr(step_factory, 'get_statistics'):
                    try:
                        stats = step_factory.get_statistics()
                        components['statistics'] = stats
                        components['github_compatibility'] = stats.get('github_compatibility', {})
                    except Exception as e:
                        logger.debug(f"StepFactory í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            else:
                logger.warning("âš ï¸ StepFactory ëª¨ë“ˆì„ ì°¾ì„ ìˆ˜ ì—†ìŒ")
    
    except Exception as e:
        logger.warning(f"âš ï¸ StepFactory ì»´í¬ë„ŒíŠ¸ ë¡œë”© ì‹¤íŒ¨: {e}")
    
    return components

# ì „ì—­ StepFactory ì»´í¬ë„ŒíŠ¸ ë¡œë”© (ê°œì„ ë¨)
STEP_FACTORY_COMPONENTS = _get_step_factory_components()
STEP_FACTORY_AVAILABLE = STEP_FACTORY_COMPONENTS.get('available', False)

# AutoModelDetector ë¡œë”©
AUTO_MODEL_DETECTOR = get_auto_model_detector()
AUTO_MODEL_DETECTOR_AVAILABLE = AUTO_MODEL_DETECTOR is not None and not getattr(AUTO_MODEL_DETECTOR, 'is_mock', False)

logger.info(f"ðŸ”§ StepFactory ìƒíƒœ: {'âœ…' if STEP_FACTORY_AVAILABLE else 'âŒ'}")
logger.info(f"ðŸ”§ AutoModelDetector ìƒíƒœ: {'âœ…' if AUTO_MODEL_DETECTOR_AVAILABLE else 'âš ï¸ Mock'}")

if STEP_FACTORY_AVAILABLE:
    logger.info(f"   - Import ê²½ë¡œ: {STEP_FACTORY_COMPONENTS.get('import_path', 'unknown')}")
    logger.info(f"   - ë²„ì „: {STEP_FACTORY_COMPONENTS.get('version', 'unknown')}")
# ==============================================
# ðŸ”¥ í”„ë¡œì íŠ¸ í‘œì¤€ ë°ì´í„° êµ¬ì¡° (í˜¸í™˜ì„± ìœ ì§€)
# ==============================================

class ProcessingMode(Enum):
    """ì²˜ë¦¬ ëª¨ë“œ"""
    FAST = "fast"
    BALANCED = "balanced"
    HIGH_QUALITY = "high_quality"
    EXPERIMENTAL = "experimental"
    BATCH = "batch"
    STREAMING = "streaming"

class ServiceStatus(Enum):
    """ì„œë¹„ìŠ¤ ìƒíƒœ"""
    INACTIVE = "inactive"
    INITIALIZING = "initializing"
    ACTIVE = "active"
    ERROR = "error"
    MAINTENANCE = "maintenance"
    BUSY = "busy"
    SUSPENDED = "suspended"

class ProcessingPriority(Enum):
    """ì²˜ë¦¬ ìš°ì„ ìˆœìœ„"""
    LOW = 1
    NORMAL = 2
    HIGH = 3
    URGENT = 4
    CRITICAL = 5

@dataclass
class BodyMeasurements:
    height: float
    weight: float
    chest: Optional[float] = None
    waist: Optional[float] = None
    hips: Optional[float] = None
    bmi: Optional[float] = None
    
    def to_dict(self) -> Dict[str, Any]:
        return {
            "height": self.height,
            "weight": self.weight,
            "chest": self.chest,
            "waist": self.waist,
            "hips": self.hips,
            "bmi": self.bmi
        }
        
    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> 'BodyMeasurements':
        return cls(**data)

@dataclass
class ProcessingRequest:
    """ì²˜ë¦¬ ìš”ì²­ ë°ì´í„° êµ¬ì¡°"""
    request_id: str
    session_id: str
    step_id: int
    priority: ProcessingPriority = ProcessingPriority.NORMAL
    inputs: Dict[str, Any] = field(default_factory=dict)
    metadata: Dict[str, Any] = field(default_factory=dict)
    created_at: datetime = field(default_factory=datetime.now)
    timeout: float = 300.0
    
    def to_dict(self) -> Dict[str, Any]:
        return {
            "request_id": self.request_id,
            "session_id": self.session_id,
            "step_id": self.step_id,
            "priority": self.priority.value,
            "inputs": self.inputs,
            "metadata": self.metadata,
            "created_at": self.created_at.isoformat(),
            "timeout": self.timeout
        }

@dataclass
class ProcessingResult:
    """ì²˜ë¦¬ ê²°ê³¼ ë°ì´í„° êµ¬ì¡°"""
    request_id: str
    session_id: str
    step_id: int
    success: bool
    result: Dict[str, Any] = field(default_factory=dict)
    error: Optional[str] = None
    processing_time: float = 0.0
    completed_at: datetime = field(default_factory=datetime.now)
    confidence: float = 0.0
    
    def to_dict(self) -> Dict[str, Any]:
        return {
            "request_id": self.request_id,
            "session_id": self.session_id,
            "step_id": self.step_id,
            "success": self.success,
            "result": self.result,
            "error": self.error,
            "processing_time": self.processing_time,
            "completed_at": self.completed_at.isoformat(),
            "confidence": self.confidence
        }

# ==============================================
# ðŸ”¥ StepServiceManager v16.0 (Central Hub DI Container ì™„ì „ ì—°ë™)
# ==============================================

class StepServiceManager:
    """
    ðŸ”¥ StepServiceManager v16.0 - Central Hub DI Container v7.0 ì™„ì „ ì—°ë™
    
    í•µì‹¬ ë³€ê²½ì‚¬í•­:
    - Central Hub DI Container v7.0 ì™„ì „ ì—°ë™
    - ìˆœí™˜ì°¸ì¡° ì™„ì „ í•´ê²° (TYPE_CHECKING + ì§€ì—° import)
    - ë‹¨ë°©í–¥ ì˜ì¡´ì„± ê·¸ëž˜í”„ (Central Hub íŒ¨í„´)
    - StepFactory v11.2ì™€ ì™„ì „ í˜¸í™˜
    - BaseStepMixin v20.0ì˜ Central Hub ê¸°ë°˜ êµ¬ì¡° ë°˜ì˜
    - ìžë™ ì˜ì¡´ì„± ì£¼ìž…ìœ¼ë¡œ ê°œë°œìž íŽ¸ì˜ì„± í–¥ìƒ
    - ê¸°ì¡´ API 100% í˜¸í™˜ì„± ìœ ì§€
    """
    
    def __init__(self):
        """StepServiceManager v16.0 Central Hub ê¸°ë°˜ ì´ˆê¸°í™”"""
        self.logger = logging.getLogger(f"{__name__}.StepServiceManager")
        
        # Central Hub Container ì—°ê²°
        self.central_hub_container = self._get_central_hub_container()
        
        # StepFactory Central Hub ê¸°ë°˜ ì—°ë™
        self.step_factory = self._get_step_factory_from_central_hub()
        
        # ìƒíƒœ ê´€ë¦¬
        self.status = ServiceStatus.INACTIVE
        self.processing_mode = ProcessingMode.HIGH_QUALITY
        
        # ì„±ëŠ¥ ë©”íŠ¸ë¦­
        self.total_requests = 0
        self.successful_requests = 0
        self.failed_requests = 0
        self.processing_times = []
        self.last_error = None
        
        # ìŠ¤ë ˆë“œ ì•ˆì „ì„±
        self._lock = threading.RLock()
        
        # ì‹œìž‘ ì‹œê°„
        self.start_time = datetime.now()
        
        # ì„¸ì…˜ ì €ìž¥ì†Œ (ê°„ë‹¨í•œ ë©”ëª¨ë¦¬ ê¸°ë°˜)
        self.sessions = {}
        
        # Central Hub ë©”íŠ¸ë¦­
        self.central_hub_metrics = {
            'total_step_creations': 0,
            'successful_step_creations': 0,
            'failed_step_creations': 0,
            'central_hub_injections': 0,
            'ai_processing_calls': 0,
            'data_conversions': 0,
            'checkpoint_validations': 0
        }
        
        # Central Hub ìµœì í™” ì •ë³´
        self.central_hub_optimization = {
            'conda_env': CONDA_INFO['conda_env'],
            'is_mycloset_env': CONDA_INFO['is_target_env'],
            'device': DEVICE,
            'is_m3_max': IS_M3_MAX,
            'memory_gb': MEMORY_GB,
            'central_hub_available': self.central_hub_container is not None,
            'step_factory_available': self.step_factory is not None
        }
        
        self.logger.info(f"ðŸ”¥ StepServiceManager v16.0 ì´ˆê¸°í™” ì™„ë£Œ (Central Hub DI Container ì—°ë™)")
        self.logger.info(f"ðŸŽ¯ Central Hub: {'âœ…' if self.central_hub_container else 'âŒ'}")
        self.logger.info(f"ðŸŽ¯ StepFactory: {'âœ…' if self.step_factory else 'âŒ'}")
    
    def _get_central_hub_container(self):
        """Central Hub DI Container ì•ˆì „í•œ ë™ì  í•´ê²°"""
        try:
            container = _get_central_hub_container()
            if container:
                self.logger.info("âœ… Central Hub DI Container ì—°ê²° ì„±ê³µ")
            else:
                self.logger.warning("âš ï¸ Central Hub DI Container ì—°ê²° ì‹¤íŒ¨")
            return container
        except Exception as e:
            self.logger.warning(f"âš ï¸ Central Hub DI Container ì—°ê²° ì˜¤ë¥˜: {e}")
            return None
    
    def _get_step_factory_from_central_hub(self):
        """Central Hubë¥¼ í†µí•œ StepFactory ì¡°íšŒ"""
        try:
            # Central Hubë¥¼ í†µí•œ ì¡°íšŒ ì‹œë„
            if self.central_hub_container:
                step_factory = self.central_hub_container.get('step_factory')
                if step_factory:
                    self.logger.info("âœ… StepFactory Central Hubì—ì„œ ì¡°íšŒ ì„±ê³µ")
                    return step_factory
            
            # í´ë°±: ì§ì ‘ ì¡°íšŒ
            step_factory = get_step_factory()
            if step_factory:
                self.logger.info("âœ… StepFactory ì§ì ‘ ì¡°íšŒ ì„±ê³µ")
                
                # Central Hubì— ë“±ë¡ ì‹œë„
                if self.central_hub_container:
                    try:
                        self.central_hub_container.register('step_factory', step_factory, singleton=True)
                        self.logger.info("âœ… StepFactory Central Hubì— ë“±ë¡ ì„±ê³µ")
                    except Exception as e:
                        self.logger.debug(f"StepFactory Central Hub ë“±ë¡ ì‹¤íŒ¨: {e}")
            
            return step_factory
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ StepFactory ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return None
    
    def _ensure_central_hub_connection(self) -> bool:
        """Central Hub ì—°ê²° ë³´ìž¥"""
        if not self.central_hub_container:
            self.central_hub_container = self._get_central_hub_container()
        
        return self.central_hub_container is not None
    
    async def initialize(self) -> bool:
        """ì„œë¹„ìŠ¤ ì´ˆê¸°í™” (Central Hub ê¸°ë°˜)"""
        # ì—ëŸ¬ ì»¨í…ìŠ¤íŠ¸ ì¤€ë¹„
        error_context = {
            'service_version': 'v16.0',
            'central_hub_available': self.central_hub_container is not None,
            'step_factory_available': self.step_factory is not None,
            'conda_env': CONDA_INFO['conda_env'],
            'device': DEVICE,
            'memory_gb': MEMORY_GB
        }
        
        try:
            self.status = ServiceStatus.INITIALIZING
            self.logger.info("ðŸš€ StepServiceManager v16.0 ì´ˆê¸°í™” ì‹œìž‘... (Central Hub ê¸°ë°˜)")
            
            # Central Hub ì—°ê²° í™•ì¸
            if not self._ensure_central_hub_connection():
                self.logger.warning("âš ï¸ Central Hub ì—†ì´ ì œí•œëœ ê¸°ëŠ¥ìœ¼ë¡œ ë™ìž‘")
                error_context['central_hub_connection_failed'] = True
            
            # M3 Max ë©”ëª¨ë¦¬ ìµœì í™”
            await self._optimize_memory()
            
            # Central Hub ìƒíƒœ í™•ì¸
            if self.central_hub_container:
                try:
                    # Central Hub í†µê³„ ì¡°íšŒ
                    if hasattr(self.central_hub_container, 'get_stats'):
                        hub_stats = self.central_hub_container.get_stats()
                        self.logger.info(f"ðŸ“Š Central Hub ìƒíƒœ: {hub_stats}")
                        error_context['central_hub_stats'] = hub_stats
                    
                    # Central Hub ë©”ëª¨ë¦¬ ìµœì í™”
                    if hasattr(self.central_hub_container, 'optimize_memory'):
                        optimization_result = self.central_hub_container.optimize_memory()
                        self.logger.info(f"ðŸ’¾ Central Hub ë©”ëª¨ë¦¬ ìµœì í™”: {optimization_result}")
                        error_context['central_hub_optimization'] = optimization_result
                    
                except Exception as e:
                    self.logger.warning(f"âš ï¸ Central Hub ìƒíƒœ í™•ì¸ ì‹¤íŒ¨: {e}")
                    error_context['central_hub_status_check_failed'] = str(e)
            
            # StepFactory ê²€ì¦
            if self.step_factory:
                try:
                    # StepFactory í†µê³„ ì¡°íšŒ
                    if hasattr(self.step_factory, 'get_statistics'):
                        factory_stats = self.step_factory.get_statistics()
                        self.logger.info(f"ðŸ“Š StepFactory ìƒíƒœ: {factory_stats}")
                        error_context['step_factory_stats'] = factory_stats
                    
                except Exception as e:
                    self.logger.warning(f"âš ï¸ StepFactory ìƒíƒœ í™•ì¸ ì‹¤íŒ¨: {e}")
                    error_context['step_factory_status_check_failed'] = str(e)
            
            self.status = ServiceStatus.ACTIVE
            self.logger.info("âœ… StepServiceManager v16.0 ì´ˆê¸°í™” ì™„ë£Œ (Central Hub ê¸°ë°˜)")
            
            return True
            
        except Exception as e:
            self.status = ServiceStatus.ERROR
            self.last_error = str(e)
            
            # exceptions.pyì˜ ì»¤ìŠ¤í…€ ì˜ˆì™¸ë¡œ ë³€í™˜
            from app.core.exceptions import (
                convert_to_mycloset_exception,
                ConfigurationError,
                PipelineError
            )
            
            # ì—ëŸ¬ íƒ€ìž…ë³„ ì»¤ìŠ¤í…€ ì˜ˆì™¸ ë³€í™˜
            if isinstance(e, (ValueError, TypeError)):
                custom_error = ConfigurationError(
                    f"ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì¤‘ ì„¤ì • ì˜¤ë¥˜: {e}",
                    "SERVICE_INITIALIZATION_CONFIG_ERROR",
                    error_context
                )
            elif isinstance(e, (ImportError, ModuleNotFoundError)):
                custom_error = ConfigurationError(
                    f"ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì¤‘ ëª¨ë“ˆ ì˜¤ë¥˜: {e}",
                    "SERVICE_INITIALIZATION_MODULE_ERROR",
                    error_context
                )
            else:
                custom_error = PipelineError(
                    f"ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}",
                    "SERVICE_INITIALIZATION_FAILED",
                    error_context
                )
            
            self.logger.error(f"âŒ StepServiceManager v16.0 ì´ˆê¸°í™” ì‹¤íŒ¨: {custom_error}")
            return False
    
    async def _optimize_memory(self):
        """ë©”ëª¨ë¦¬ ìµœì í™” (Central Hub ê¸°ë°˜)"""
        try:
            # Python GC
            gc.collect()
            
            # Central Hub ë©”ëª¨ë¦¬ ìµœì í™”
            if self.central_hub_container and hasattr(self.central_hub_container, 'optimize_memory'):
                optimization_result = self.central_hub_container.optimize_memory()
                self.logger.debug(f"Central Hub ë©”ëª¨ë¦¬ ìµœì í™”: {optimization_result}")
            
            # M3 Max MPS ë©”ëª¨ë¦¬ ì •ë¦¬
            if TORCH_AVAILABLE and IS_M3_MAX:
                import torch
                if hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
                    if hasattr(torch.backends.mps, 'empty_cache'):
                        torch.backends.mps.empty_cache()
                        self.logger.debug("ðŸŽ M3 Max MPS ë©”ëª¨ë¦¬ ì •ë¦¬ ì™„ë£Œ")
            
            # CUDA ë©”ëª¨ë¦¬ ì •ë¦¬
            elif TORCH_AVAILABLE and DEVICE == "cuda":
                import torch
                torch.cuda.empty_cache()
                self.logger.debug("ðŸ”¥ CUDA ë©”ëª¨ë¦¬ ì •ë¦¬ ì™„ë£Œ")
                
        except Exception as e:
            self.logger.debug(f"ë©”ëª¨ë¦¬ ìµœì í™” ì‹¤íŒ¨ (ë¬´ì‹œ): {e}")
    
    # ==============================================
    # ðŸ”¥ Step ìƒì„± ë° ì²˜ë¦¬ (Central Hub ê¸°ë°˜)
    # ==============================================
    
    async def _create_step_instance(self, step_type: Union[str, int], **kwargs) -> Tuple[bool, Optional[Any], str]:
        """Central Hubë¥¼ í†µí•œ Step ì¸ìŠ¤í„´ìŠ¤ ìƒì„±"""
        # ì—ëŸ¬ ì»¨í…ìŠ¤íŠ¸ ì¤€ë¹„
        error_context = {
            'step_type': step_type,
            'step_factory_available': self.step_factory is not None,
            'central_hub_available': self.central_hub_container is not None,
            'kwargs_keys': list(kwargs.keys()),
            'total_step_creations': self.central_hub_metrics['total_step_creations']
        }
        
        try:
            if not self.step_factory:
                # exceptions.pyì˜ ì»¤ìŠ¤í…€ ì˜ˆì™¸ ì‚¬ìš©
                from app.core.exceptions import ConfigurationError
                raise ConfigurationError(
                    "StepFactory ì‚¬ìš© ë¶ˆê°€",
                    "STEP_FACTORY_NOT_AVAILABLE",
                    error_context
                )
            
            # StepFactoryë¥¼ í†µí•œ Step ìƒì„±
            if hasattr(self.step_factory, 'create_step'):
                creation_result = self.step_factory.create_step(step_type, **kwargs)
                
                if hasattr(creation_result, 'success') and creation_result.success:
                    step_instance = creation_result.step_instance
                    
                    # Central Hub ì¶”ê°€ ì˜ì¡´ì„± ì£¼ìž…
                    additional_injections = 0
                    if self.central_hub_container:
                        additional_injections = _inject_dependencies_to_step_safe(step_instance)
                    
                    # Central Hub ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
                    with self._lock:
                        self.central_hub_metrics['total_step_creations'] += 1
                        self.central_hub_metrics['successful_step_creations'] += 1
                        self.central_hub_metrics['central_hub_injections'] += additional_injections
                    
                    return True, step_instance, f"Central Hub Step ìƒì„± ì„±ê³µ: {creation_result.step_name} (ì£¼ìž…: {additional_injections})"
                else:
                    error_msg = getattr(creation_result, 'error_message', 'Step ìƒì„± ì‹¤íŒ¨')
                    with self._lock:
                        self.central_hub_metrics['total_step_creations'] += 1
                        self.central_hub_metrics['failed_step_creations'] += 1
                    
                    # exceptions.pyì˜ ì»¤ìŠ¤í…€ ì˜ˆì™¸ ì‚¬ìš©
                    from app.core.exceptions import ModelLoadingError
                    raise ModelLoadingError(
                        f"Step ìƒì„± ì‹¤íŒ¨: {error_msg}",
                        "STEP_CREATION_FAILED",
                        error_context
                    )
            
            # exceptions.pyì˜ ì»¤ìŠ¤í…€ ì˜ˆì™¸ ì‚¬ìš©
            from app.core.exceptions import ConfigurationError
            raise ConfigurationError(
                "StepFactory create_step ë©”ì„œë“œ ì—†ìŒ",
                "STEP_FACTORY_METHOD_NOT_FOUND",
                error_context
            )
            
        except Exception as e:
            with self._lock:
                self.central_hub_metrics['total_step_creations'] += 1
                self.central_hub_metrics['failed_step_creations'] += 1
            
            # exceptions.pyì˜ ì»¤ìŠ¤í…€ ì˜ˆì™¸ë¡œ ë³€í™˜
            from app.core.exceptions import (
                convert_to_mycloset_exception,
                ModelLoadingError,
                ConfigurationError
            )
            
            # ì—ëŸ¬ íƒ€ìž…ë³„ ì»¤ìŠ¤í…€ ì˜ˆì™¸ ë³€í™˜
            if isinstance(e, (ModelLoadingError, ConfigurationError)):
                # ì´ë¯¸ ì»¤ìŠ¤í…€ ì˜ˆì™¸ì¸ ê²½ìš° ê·¸ëŒ€ë¡œ ì‚¬ìš©
                custom_error = e
            elif isinstance(e, (ValueError, TypeError)):
                custom_error = ConfigurationError(
                    f"Step ìƒì„± ì¤‘ ì„¤ì • ì˜¤ë¥˜: {e}",
                    "STEP_CREATION_CONFIG_ERROR",
                    error_context
                )
            elif isinstance(e, (ImportError, ModuleNotFoundError)):
                custom_error = ConfigurationError(
                    f"Step ìƒì„± ì¤‘ ëª¨ë“ˆ ì˜¤ë¥˜: {e}",
                    "STEP_CREATION_MODULE_ERROR",
                    error_context
                )
            else:
                custom_error = ModelLoadingError(
                    f"Step ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ì‹¤íŒ¨: {e}",
                    "STEP_INSTANCE_CREATION_FAILED",
                    error_context
                )
            
            self.logger.error(f"âŒ Central Hub Step ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ì˜¤ë¥˜: {custom_error}")
            return False, None, str(custom_error)
    
    async def _process_step_with_central_hub(
        self, 
        step_type: Union[str, int], 
        input_data: Dict[str, Any],
        **kwargs
    ) -> Dict[str, Any]:
        """Central Hubë¥¼ í†µí•œ Step ì²˜ë¦¬"""
        request_id = kwargs.get('request_id', f"req_{uuid.uuid4().hex[:8]}")
        start_time = time.time()
        
        # ì—ëŸ¬ ì»¨í…ìŠ¤íŠ¸ ì¤€ë¹„
        error_context = {
            'step_type': step_type,
            'request_id': request_id,
            'input_data_keys': list(input_data.keys()) if input_data else [],
            'central_hub_available': self.central_hub_container is not None,
            'step_factory_available': self.step_factory is not None
        }
        
        try:
            # Step ì¸ìŠ¤í„´ìŠ¤ ìƒì„± (Central Hub ê¸°ë°˜)
            success, step_instance, message = await self._create_step_instance(step_type, **kwargs)
            
            if not success or not step_instance:
                # exceptions.pyì˜ ì»¤ìŠ¤í…€ ì˜ˆì™¸ ì‚¬ìš©
                from app.core.exceptions import ModelLoadingError
                raise ModelLoadingError(
                    f"Central Hub Step ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ì‹¤íŒ¨: {message}",
                    "STEP_INSTANCE_CREATION_FAILED",
                    error_context
                )
            
            # BaseStepMixin v20.0ì˜ process ë©”ì„œë“œ í˜¸ì¶œ
            if hasattr(step_instance, 'process'):
                # Central Hub ê¸°ë°˜ AI ì¶”ë¡  ì‹¤í–‰
                if asyncio.iscoroutinefunction(step_instance.process):
                    step_result = await step_instance.process(**input_data)
                else:
                    step_result = step_instance.process(**input_data)
                
                processing_time = time.time() - start_time
                
                # Central Hub ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
                with self._lock:
                    self.central_hub_metrics['ai_processing_calls'] += 1
                    if hasattr(step_instance, 'api_input_mapping'):
                        self.central_hub_metrics['data_conversions'] += 1
                    if hasattr(step_instance, 'model_loader'):
                        self.central_hub_metrics['checkpoint_validations'] += 1
                
                # ê²°ê³¼ í¬ë§·íŒ…
                if isinstance(step_result, dict):
                    step_result.update({
                        "step_type": step_type,
                        "request_id": request_id,
                        "processing_time": processing_time,
                        "central_hub_used": True,
                        "central_hub_version": "v7.0",
                        "step_factory_version": "v11.2",
                        "base_step_mixin_version": "v20.0",
                        "timestamp": datetime.now().isoformat()
                    })
                else:
                    step_result = {
                        "success": True,
                        "result": step_result,
                        "step_type": step_type,
                        "request_id": request_id,
                        "processing_time": processing_time,
                        "central_hub_used": True,
                        "timestamp": datetime.now().isoformat()
                    }
                
                return step_result
            else:
                # exceptions.pyì˜ ì»¤ìŠ¤í…€ ì˜ˆì™¸ ì‚¬ìš©
                from app.core.exceptions import ConfigurationError
                raise ConfigurationError(
                    "Step ì¸ìŠ¤í„´ìŠ¤ì— process ë©”ì„œë“œ ì—†ìŒ",
                    "STEP_PROCESS_METHOD_NOT_FOUND",
                    error_context
                )
                
        except Exception as e:
            # exceptions.pyì˜ ì»¤ìŠ¤í…€ ì˜ˆì™¸ë¡œ ë³€í™˜
            from app.core.exceptions import (
                convert_to_mycloset_exception,
                create_exception_response,
                PipelineError,
                ModelInferenceError
            )
            
            # ì—ëŸ¬ íƒ€ìž…ë³„ ì»¤ìŠ¤í…€ ì˜ˆì™¸ ë³€í™˜
            if isinstance(e, (ValueError, TypeError)):
                custom_error = PipelineError(
                    f"Central Hub Step ì²˜ë¦¬ ì¤‘ ë°ì´í„° ì˜¤ë¥˜: {e}",
                    "STEP_PROCESSING_DATA_ERROR",
                    error_context
                )
            elif isinstance(e, (OSError, IOError)):
                custom_error = PipelineError(
                    f"Central Hub Step ì²˜ë¦¬ ì¤‘ ì‹œìŠ¤í…œ ì˜¤ë¥˜: {e}",
                    "STEP_PROCESSING_SYSTEM_ERROR",
                    error_context
                )
            else:
                custom_error = convert_to_mycloset_exception(e, error_context)
            
            self.logger.error(f"âŒ Central Hub Step ì²˜ë¦¬ ì‹¤íŒ¨: {custom_error}")
            
            # í‘œì¤€í™”ëœ ì—ëŸ¬ ì‘ë‹µ ìƒì„±
            error_response = create_exception_response(
                custom_error, 
                f"Step_{step_type}", 
                step_type,
                request_id
            )
            
            # ì¶”ê°€ ì •ë³´ ì„¤ì •
            error_response.update({
                "step_type": step_type,
                "request_id": request_id,
                "processing_time": time.time() - start_time,
                "central_hub_used": self.central_hub_container is not None,
                "timestamp": datetime.now().isoformat()
            })
            
            return error_response
    
    async def process_step_by_name(self, step_name: str, api_input: Dict[str, Any], **kwargs) -> Dict[str, Any]:
        """Central Hub ê¸°ë°˜ Step ì²˜ë¦¬ (ê¸°ì¡´ API í˜¸í™˜)"""
        try:
            # 1. Central Hubë¥¼ í†µí•œ Step ìƒì„± (ìžë™ ì˜ì¡´ì„± ì£¼ìž…)
            if self.step_factory:
                step_type = self._get_step_type_from_name(step_name)
                creation_result = await self._create_step_instance(step_type, **kwargs)
                
                if not creation_result[0]:
                    return {'success': False, 'error': creation_result[2]}
                
                step_instance = creation_result[1]
                
                # 2. Central Hub ì¶”ê°€ ì˜ì¡´ì„± ì£¼ìž… í™•ì¸
                additional_injections = 0
                if self.central_hub_container:
                    additional_injections = _inject_dependencies_to_step_safe(step_instance)
                
                # 3. DetailedDataSpec ê¸°ë°˜ ë°ì´í„° ë³€í™˜ (BaseStepMixin v20.0 ìžë™ ì²˜ë¦¬)
                if hasattr(step_instance, 'convert_api_input_to_step_input'):
                    converted_input = await step_instance.convert_api_input_to_step_input(api_input)
                else:
                    converted_input = api_input
                
                # 4. AI ì¶”ë¡  ì‹¤í–‰
                if asyncio.iscoroutinefunction(step_instance.process):
                    step_output = await step_instance.process(**converted_input)
                else:
                    step_output = step_instance.process(**converted_input)
                
                # 5. API ì‘ë‹µ ë³€í™˜
                if hasattr(step_instance, 'convert_step_output_to_api_response'):
                    if asyncio.iscoroutinefunction(step_instance.convert_step_output_to_api_response):
                        api_response = await step_instance.convert_step_output_to_api_response(step_output)
                    else:
                        api_response = step_instance.convert_step_output_to_api_response(step_output)
                else:
                    api_response = step_output
                
                return {
                    'success': True,
                    'result': api_response,
                    'step_name': step_name,
                    'central_hub_injections': additional_injections,
                    'processing_time': step_output.get('processing_time', 0),
                    'central_hub_used': True
                }
            else:
                return {'success': False, 'error': 'StepFactory not available'}
                
        except Exception as e:
            return {'success': False, 'error': str(e), 'central_hub_used': self.central_hub_container is not None}

    def process_step_by_name_sync(self, step_name: str, api_input: Dict[str, Any], **kwargs) -> Dict[str, Any]:
        """Central Hub ê¸°ë°˜ Step ì´ë¦„ìœ¼ë¡œ ì²˜ë¦¬ (ë™ê¸° ë²„ì „)"""
        try:
            # 1. Central Hubë¥¼ í†µí•œ Step ìƒì„± (ìžë™ ì˜ì¡´ì„± ì£¼ìž…)
            if self.step_factory:
                step_type = self._get_step_type_from_name(step_name)
                
                # ì™„ì „ ë™ê¸°ì ìœ¼ë¡œ Step ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
                # _create_step_instanceëŠ” asyncì´ë¯€ë¡œ ë™ê¸° ëž˜í¼ ì‚¬ìš©
                creation_result = self._create_step_instance_sync(step_type, **kwargs)
                
                if not creation_result[0]:
                    return {'success': False, 'error': creation_result[2]}
                
                step_instance = creation_result[1]
                
                # 2. Central Hub ì¶”ê°€ ì˜ì¡´ì„± ì£¼ìž… í™•ì¸
                additional_injections = 0
                if self.central_hub_container:
                    additional_injections = _inject_dependencies_to_step_safe(step_instance)
                
                # 3. DetailedDataSpec ê¸°ë°˜ ë°ì´í„° ë³€í™˜ (ì™„ì „ ë™ê¸°ì ìœ¼ë¡œ)
                if hasattr(step_instance, 'convert_api_input_to_step_input'):
                    # convert_api_input_to_step_inputì´ asyncì¸ì§€ í™•ì¸í•˜ê³  ì ì ˆížˆ ì²˜ë¦¬
                    import inspect
                    if inspect.iscoroutinefunction(step_instance.convert_api_input_to_step_input):
                        # async í•¨ìˆ˜ì¸ ê²½ìš° ë™ê¸° ëž˜í¼ ì‚¬ìš©
                        converted_input = self._run_async_method_sync(step_instance.convert_api_input_to_step_input, api_input)
                    else:
                        # ë™ê¸° í•¨ìˆ˜ì¸ ê²½ìš° ì§ì ‘ í˜¸ì¶œ
                        converted_input = step_instance.convert_api_input_to_step_input(api_input)
                else:
                    converted_input = api_input
                
                # 4. AI ì¶”ë¡  ì‹¤í–‰ (ë™ê¸°ì ìœ¼ë¡œ)
                step_output = step_instance.process(**converted_input)
                
                # 5. API ì‘ë‹µ ë³€í™˜ (ë™ê¸°ì ìœ¼ë¡œ)
                if hasattr(step_instance, 'convert_step_output_to_api_response'):
                    api_response = step_instance.convert_step_output_to_api_response(step_output)
                else:
                    api_response = step_output
                
                return {
                    'success': True,
                    'result': api_response,
                    'step_name': step_name,
                    'central_hub_injections': additional_injections,
                    'processing_time': step_output.get('processing_time', 0),
                    'central_hub_used': True
                }
            else:
                return {'success': False, 'error': 'StepFactory not available'}
                
        except Exception as e:
            return {'success': False, 'error': str(e), 'central_hub_used': self.central_hub_container is not None}
    
    def _create_step_instance_sync(self, step_type: Union[str, int], **kwargs) -> Tuple[bool, Optional[Any], str]:
        """ë™ê¸°ì ìœ¼ë¡œ Step ì¸ìŠ¤í„´ìŠ¤ ìƒì„±"""
        try:
            import asyncio
            import concurrent.futures
            
            def run_async_creation():
                try:
                    return asyncio.run(self._create_step_instance(step_type, **kwargs))
                except Exception as e:
                    return (False, None, str(e))
            
            with concurrent.futures.ThreadPoolExecutor() as executor:
                future = executor.submit(run_async_creation)
                return future.result(timeout=30)  # 30ì´ˆ íƒ€ìž„ì•„ì›ƒ
        except Exception as e:
            return (False, None, str(e))
    
    def _run_async_method_sync(self, async_method, *args, **kwargs):
        """ë™ê¸°ì ìœ¼ë¡œ async ë©”ì„œë“œ ì‹¤í–‰"""
        try:
            import asyncio
            import concurrent.futures
            
            def run_async_method():
                try:
                    return asyncio.run(async_method(*args, **kwargs))
                except Exception as e:
                    self.logger.error(f"âŒ Async ë©”ì„œë“œ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
                    return None
            
            with concurrent.futures.ThreadPoolExecutor() as executor:
                future = executor.submit(run_async_method)
                return future.result(timeout=30)  # 30ì´ˆ íƒ€ìž„ì•„ì›ƒ
        except Exception as e:
            self.logger.error(f"âŒ Async ë©”ì„œë“œ ëž˜í•‘ ì‹¤íŒ¨: {e}")
            return None
    
    def _get_step_type_from_name(self, step_name: str) -> str:
        """Step ì´ë¦„ì—ì„œ íƒ€ìž… ì¶”ì¶œ (StepFactory í˜¸í™˜)"""
        step_mapping = {
            'human_parsing': 'human_parsing',
            'pose_estimation': 'pose_estimation',
            'clothing_analysis': 'cloth_segmentation',
            'cloth_segmentation': 'cloth_segmentation',
            'geometric_matching': 'geometric_matching',
            'virtual_fitting': 'virtual_fitting',
            'cloth_warping': 'cloth_warping',
            'post_processing': 'post_processing',
            'quality_assessment': 'quality_assessment',
            'result_analysis': 'quality_assessment',
            'measurementsvalidation': 'measurements_validation',  # Step 2 ì¶”ê°€
            'measurements_validation': 'measurements_validation'  # Step 2 ì¶”ê°€
        }
        
        for key, value in step_mapping.items():
            if key in step_name.lower():
                return value
        
        # ë” ì •í™•í•œ ë§¤í•‘ì„ ìœ„í•´ step_nameì„ ì§ì ‘ í™•ì¸
        step_name_lower = step_name.lower()
        if 'measurements' in step_name_lower or 'validation' in step_name_lower:
            return 'measurements_validation'
        elif 'human' in step_name_lower or 'parsing' in step_name_lower:
            return 'human_parsing'
        elif 'pose' in step_name_lower:
            return 'pose_estimation'
        elif 'clothing' in step_name_lower or 'segmentation' in step_name_lower:
            return 'cloth_segmentation'
        elif 'geometric' in step_name_lower or 'matching' in step_name_lower:
            return 'geometric_matching'
        elif 'warping' in step_name_lower:
            return 'cloth_warping'
        elif 'virtual' in step_name_lower or 'fitting' in step_name_lower:
            return 'virtual_fitting'
        elif 'post' in step_name_lower:
            return 'post_processing'
        elif 'quality' in step_name_lower or 'assessment' in step_name_lower:
            return 'quality_assessment'
        
        return 'human_parsing'  # ê¸°ë³¸ê°’
    
    def validate_dependencies(self) -> Dict[str, Any]:
        """Central Hub ê¸°ë°˜ ì˜ì¡´ì„± ê²€ì¦"""
        try:
            validation_result = {
                'success': True,
                'central_hub_connected': self.central_hub_container is not None,
                'services_available': {},
                'step_factory_ready': self.step_factory is not None,
                'version': 'v16.0'
            }
            
            # Central Hub ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸
            if self.central_hub_container:
                core_services = ['model_loader', 'memory_manager', 'data_converter']
                for service_key in core_services:
                    service = self.central_hub_container.get(service_key)
                    validation_result['services_available'][service_key] = service is not None
                
                # Central Hub í†µê³„ ì¶”ê°€
                if hasattr(self.central_hub_container, 'get_stats'):
                    validation_result['central_hub_stats'] = self.central_hub_container.get_stats()
            
            # ì „ì²´ ì„±ê³µ ì—¬ë¶€ íŒì •
            validation_result['success'] = (
                validation_result['central_hub_connected'] and
                validation_result['step_factory_ready'] and
                all(validation_result['services_available'].values())
            )
            
            return validation_result
            
        except Exception as e:
            return {
                'success': False,
                'error': str(e),
                'central_hub_connected': False,
                'version': 'v16.0'
            }
    
    def get_metrics(self) -> Dict[str, Any]:
        """Central Hub í†µí•© ë©”íŠ¸ë¦­"""
        try:
            base_metrics = {
                'version': 'StepServiceManager v16.0 (Central Hub Integration)',
                'central_hub_integrated': True,
                'uptime_seconds': (datetime.now() - self.start_time).total_seconds(),
                'total_requests': self.total_requests,
                'successful_requests': self.successful_requests,
                'failed_requests': self.failed_requests,
                'success_rate': (self.successful_requests / max(1, self.total_requests)) * 100,
                'average_processing_time': sum(self.processing_times) / max(1, len(self.processing_times))
            }
            
            # Central Hub í†µê³„ í†µí•©
            if self.central_hub_container and hasattr(self.central_hub_container, 'get_stats'):
                central_hub_stats = self.central_hub_container.get_stats()
                base_metrics['central_hub_stats'] = central_hub_stats
            
            # StepFactory í†µê³„ í†µí•©
            if self.step_factory and hasattr(self.step_factory, 'get_statistics'):
                step_factory_stats = self.step_factory.get_statistics()
                base_metrics['step_factory_stats'] = step_factory_stats
            
            # Central Hub ë©”íŠ¸ë¦­ ì¶”ê°€
            base_metrics['central_hub_metrics'] = self.central_hub_metrics.copy()
            
            return base_metrics
            
        except Exception as e:
            return {
                'error': str(e),
                'version': 'StepServiceManager v16.0 (Central Hub Integration Error)'
            }
    
    async def cleanup(self):
        """Central Hub ê¸°ë°˜ ì •ë¦¬"""
        try:
            self.logger.info("ðŸ§¹ StepServiceManager v16.0 Central Hub ê¸°ë°˜ ì •ë¦¬ ì‹œìž‘...")
            
            # StepFactory ìºì‹œ ì •ë¦¬
            if self.step_factory and hasattr(self.step_factory, 'clear_cache'):
                self.step_factory.clear_cache()
            
            # Central Hub ë©”ëª¨ë¦¬ ìµœì í™”
            if self.central_hub_container and hasattr(self.central_hub_container, 'optimize_memory'):
                optimization_result = self.central_hub_container.optimize_memory()
                self.logger.info(f"Central Hub ë©”ëª¨ë¦¬ ìµœì í™”: {optimization_result}")
            
            # ì„¸ì…˜ ì •ë¦¬
            self.sessions.clear()
            
            self.logger.info("âœ… StepServiceManager v16.0 Central Hub ê¸°ë°˜ ì •ë¦¬ ì™„ë£Œ")
            
        except Exception as e:
            self.logger.error(f"âŒ Central Hub ê¸°ë°˜ ì •ë¦¬ ì‹¤íŒ¨: {e}")
    
    def _create_fallback_step_service(self, step_name: str):
        """Central Hub ì‹¤íŒ¨ ì‹œ í´ë°± ì„œë¹„ìŠ¤"""
        return {
            'success': False,
            'error': 'Central Hub not available',
            'fallback_used': True,
            'step_name': step_name,
            'recommendation': 'Check Central Hub DI Container status'
        }
    
    # ==============================================
    # ðŸ”¥ ê¸°ì¡´ 8ë‹¨ê³„ AI íŒŒì´í”„ë¼ì¸ API (100% ìœ ì§€í•˜ë©´ì„œ Central Hub í™œìš©)
    # ==============================================
    
    async def process_step_1_upload_validation(
        self,
        person_image: Any,
        clothing_image: Any, 
        session_id: Optional[str] = None
    ) -> Dict[str, Any]:
        """1ë‹¨ê³„: ì´ë¯¸ì§€ ì—…ë¡œë“œ ê²€ì¦ (Central Hub ê¸°ë°˜)"""
        request_id = f"step1_{uuid.uuid4().hex[:8]}"
        start_time = time.time()
        
        try:
            with self._lock:
                self.total_requests += 1
            
            if session_id is None:
                session_id = f"session_{uuid.uuid4().hex[:8]}"
            
            # ì„¸ì…˜ì— ì´ë¯¸ì§€ ì €ìž¥
            self.sessions[session_id] = {
                'person_image': person_image,
                'clothing_image': clothing_image,
                'created_at': datetime.now(),
                'central_hub_session': True
            }
            
            processing_time = time.time() - start_time
            
            result = {
                "success": True,
                "message": "ì´ë¯¸ì§€ ì—…ë¡œë“œ ê²€ì¦ ì™„ë£Œ (Central Hub ê¸°ë°˜)",
                "step_id": 1,
                "step_name": "Upload Validation",
                "session_id": session_id,
                "request_id": request_id,
                "processing_time": processing_time,
                "central_hub_used": self.central_hub_container is not None,
                "timestamp": datetime.now().isoformat()
            }
            
            with self._lock:
                self.successful_requests += 1
                self.processing_times.append(processing_time)
            
            return result
            
        except Exception as e:
            with self._lock:
                self.failed_requests += 1
                self.last_error = str(e)
            
            self.logger.error(f"âŒ Step 1 ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return {
                "success": False,
                "error": str(e),
                "step_id": 1,
                "step_name": "Upload Validation",
                "session_id": session_id,
                "request_id": request_id,
                "central_hub_used": self.central_hub_container is not None,
                "timestamp": datetime.now().isoformat()
            }
    
    async def process_step_2_measurements_validation(
        self,
        measurements: Union[BodyMeasurements, Dict[str, Any]],
        session_id: Optional[str] = None
    ) -> Dict[str, Any]:
        """2ë‹¨ê³„: ì‹ ì²´ ì¸¡ì •ê°’ ê²€ì¦ (Central Hub ê¸°ë°˜)"""
        request_id = f"step2_{uuid.uuid4().hex[:8]}"
        start_time = time.time()
        
        try:
            with self._lock:
                self.total_requests += 1
            
            # ì¸¡ì •ê°’ ì²˜ë¦¬
            if isinstance(measurements, dict):
                measurements_dict = measurements
            else:
                measurements_dict = measurements.to_dict() if hasattr(measurements, 'to_dict') else dict(measurements)
            
            # BMI ê³„ì‚°
            height = measurements_dict.get("height", 0)
            weight = measurements_dict.get("weight", 0)
            
            if height > 0 and weight > 0:
                height_m = height / 100.0
                bmi = round(weight / (height_m ** 2), 2)
                measurements_dict["bmi"] = bmi
            else:
                raise ValueError("ì˜¬ë°”ë¥´ì§€ ì•Šì€ í‚¤ ë˜ëŠ” ëª¸ë¬´ê²Œ")
            
            # ì„¸ì…˜ì— ì¸¡ì •ê°’ ì €ìž¥
            if session_id and session_id in self.sessions:
                self.sessions[session_id]['measurements'] = measurements_dict
                self.sessions[session_id]['bmi_calculated'] = True
            
            processing_time = time.time() - start_time
            
            result = {
                "success": True,
                "message": "ì‹ ì²´ ì¸¡ì •ê°’ ê²€ì¦ ì™„ë£Œ (Central Hub ê¸°ë°˜)",
                "step_id": 2,
                "step_name": "Measurements Validation",
                "session_id": session_id,
                "request_id": request_id,
                "processing_time": processing_time,
                "measurements_bmi": bmi,
                "measurements": measurements_dict,
                "central_hub_used": self.central_hub_container is not None,
                "timestamp": datetime.now().isoformat()
            }
            
            with self._lock:
                self.successful_requests += 1
                self.processing_times.append(processing_time)
            
            return result
            
        except Exception as e:
            with self._lock:
                self.failed_requests += 1
                self.last_error = str(e)
            
            self.logger.error(f"âŒ Step 2 ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return {
                "success": False,
                "error": str(e),
                "step_id": 2,
                "step_name": "Measurements Validation",
                "session_id": session_id,
                "request_id": request_id,
                "central_hub_used": self.central_hub_container is not None,
                "timestamp": datetime.now().isoformat()
            }
    
    async def process_step_3_human_parsing(
        self,
        session_id: str,
        enhance_quality: bool = True
    ) -> Dict[str, Any]:
        """3ë‹¨ê³„: ì¸ê°„ íŒŒì‹± (Central Hub â†’ StepFactory â†’ HumanParsingStep)"""
        request_id = f"step3_{uuid.uuid4().hex[:8]}"
        
        try:
            with self._lock:
                self.total_requests += 1
            
            # SessionManagerë¥¼ í†µí•´ ì„¸ì…˜ì—ì„œ ì´ë¯¸ì§€ ê°€ì ¸ì˜¤ê¸°
            session_manager = _get_session_manager()
            if not session_manager:
                raise ValueError("SessionManagerë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            
            session_status = await session_manager.get_session_status(session_id)
            if session_status.get('status') != 'found':
                raise ValueError(f"ì„¸ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {session_id}")
            
            # ì„¸ì…˜ì—ì„œ ì´ë¯¸ì§€ ê°€ì ¸ì˜¤ê¸°
            session_data = session_status.get('data', {})
            person_image_info = session_data.get('person_image_info', {})
            
            if not person_image_info:
                raise ValueError("person_image ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤")
            
            # ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œì—ì„œ ì´ë¯¸ì§€ ë¡œë“œ
            person_image_path = session_data.get('person_image', {}).get('path')
            if not person_image_path:
                raise ValueError("person_image ê²½ë¡œê°€ ì—†ìŠµë‹ˆë‹¤")
            
            # PIL Imageë¡œ ë¡œë“œ
            try:
                from PIL import Image
                person_image = Image.open(person_image_path)
            except Exception as e:
                raise ValueError(f"ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {e}")
            
            self.logger.info(f"ðŸ§  Step 3 Central Hub â†’ HumanParsingStep ì²˜ë¦¬ ì‹œìž‘: {session_id}")
            
            # Central Hubë¥¼ í†µí•œ HumanParsingStep ì²˜ë¦¬
            input_data = {
                'person_image': person_image,
                'enhance_quality': enhance_quality,
                'session_id': session_id
            }
            
            result = await self._process_step_with_central_hub(
                step_type=1,  # HUMAN_PARSING
                input_data=input_data,
                request_id=request_id
            )
            
            # ê²°ê³¼ ì—…ë°ì´íŠ¸
            result.update({
                "step_id": 3,
                "step_name": "Human Parsing",
                "session_id": session_id,
                "message": "ì¸ê°„ íŒŒì‹± ì™„ë£Œ (Central Hub â†’ HumanParsingStep)"
            })
            
            # SessionManagerë¥¼ í†µí•´ ì„¸ì…˜ì— ê²°ê³¼ ì €ìž¥
            if session_manager:
                await session_manager.update_session(session_id, {
                    'human_parsing_result': result
                })
            
            if result.get('success', False):
                with self._lock:
                    self.successful_requests += 1
                    self.processing_times.append(result.get('processing_time', 0))
            else:
                with self._lock:
                    self.failed_requests += 1
                    self.last_error = result.get('error')
            
            return result
            
        except Exception as e:
            with self._lock:
                self.failed_requests += 1
                self.last_error = str(e)
            
            self.logger.error(f"âŒ Step 3 Central Hub ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return {
                "success": False,
                "error": str(e),
                "step_id": 3,
                "step_name": "Human Parsing",
                "session_id": session_id,
                "request_id": request_id,
                "central_hub_used": self.central_hub_container is not None,
                "timestamp": datetime.now().isoformat()
            }
    
    async def process_step_4_pose_estimation(
        self, 
        session_id: str, 
        detection_confidence: float = 0.5,
        clothing_type: str = "shirt"
    ) -> Dict[str, Any]:
        """4ë‹¨ê³„: í¬ì¦ˆ ì¶”ì • (Central Hub â†’ StepFactory â†’ PoseEstimationStep)"""
        request_id = f"step4_{uuid.uuid4().hex[:8]}"
        
        try:
            with self._lock:
                self.total_requests += 1
            
            # SessionManagerë¥¼ í†µí•´ ì„¸ì…˜ì—ì„œ ì´ë¯¸ì§€ ê°€ì ¸ì˜¤ê¸°
            session_manager = _get_session_manager()
            if not session_manager:
                raise ValueError("SessionManagerë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            
            session_status = await session_manager.get_session_status(session_id)
            if session_status.get('status') != 'found':
                raise ValueError(f"ì„¸ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {session_id}")
            
            # ì„¸ì…˜ì—ì„œ ì´ë¯¸ì§€ ê°€ì ¸ì˜¤ê¸°
            session_data = session_status.get('data', {})
            person_image_info = session_data.get('person_image_info', {})
            
            if not person_image_info:
                raise ValueError("person_image ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤")
            
            # ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œì—ì„œ ì´ë¯¸ì§€ ë¡œë“œ
            person_image_path = session_data.get('person_image', {}).get('path')
            if not person_image_path:
                raise ValueError("person_image ê²½ë¡œê°€ ì—†ìŠµë‹ˆë‹¤")
            
            # PIL Imageë¡œ ë¡œë“œ
            try:
                from PIL import Image
                person_image = Image.open(person_image_path)
            except Exception as e:
                raise ValueError(f"ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {e}")
            
            self.logger.info(f"ðŸ§  Step 4 Central Hub â†’ PoseEstimationStep ì²˜ë¦¬ ì‹œìž‘: {session_id}")
            
            # Central Hubë¥¼ í†µí•œ PoseEstimationStep ì²˜ë¦¬
            input_data = {
                'image': person_image,
                'clothing_type': clothing_type,
                'detection_confidence': detection_confidence,
                'session_id': session_id
            }
            
            result = await self._process_step_with_central_hub(
                step_type=2,  # POSE_ESTIMATION
                input_data=input_data,
                request_id=request_id
            )
            
            # ê²°ê³¼ ì—…ë°ì´íŠ¸
            result.update({
                "step_id": 4,
                "step_name": "Pose Estimation",
                "session_id": session_id,
                "message": "í¬ì¦ˆ ì¶”ì • ì™„ë£Œ (Central Hub â†’ PoseEstimationStep)"
            })
            
            # ì„¸ì…˜ì— ê²°ê³¼ ì €ìž¥
            self.sessions[session_id]['pose_estimation_result'] = result
            
            if result.get('success', False):
                with self._lock:
                    self.successful_requests += 1
                    self.processing_times.append(result.get('processing_time', 0))
            else:
                with self._lock:
                    self.failed_requests += 1
                    self.last_error = result.get('error')
            
            return result
            
        except Exception as e:
            with self._lock:
                self.failed_requests += 1
                self.last_error = str(e)
            
            self.logger.error(f"âŒ Step 4 Central Hub ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return {
                "success": False,
                "error": str(e),
                "step_id": 4,
                "step_name": "Pose Estimation",
                "session_id": session_id,
                "request_id": request_id,
                "central_hub_used": self.central_hub_container is not None,
                "timestamp": datetime.now().isoformat()
            }
    
    async def process_step_5_clothing_analysis(
        self,
        session_id: str,
        analysis_detail: str = "medium",
        clothing_type: str = "shirt"
    ) -> Dict[str, Any]:
        """5ë‹¨ê³„: ì˜ë¥˜ ë¶„ì„ (Central Hub â†’ StepFactory â†’ ClothSegmentationStep)"""
        request_id = f"step5_{uuid.uuid4().hex[:8]}"
        
        try:
            with self._lock:
                self.total_requests += 1
            
            # ì„¸ì…˜ì—ì„œ ì´ë¯¸ì§€ ê°€ì ¸ì˜¤ê¸°
            if session_id not in self.sessions:
                raise ValueError(f"ì„¸ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {session_id}")
            
            clothing_image = self.sessions[session_id].get('clothing_image')
            if clothing_image is None:
                raise ValueError("clothing_imageê°€ ì—†ìŠµë‹ˆë‹¤")
            
            self.logger.info(f"ðŸ§  Step 5 Central Hub â†’ ClothSegmentationStep ì²˜ë¦¬ ì‹œìž‘: {session_id}")
            
            # Central Hubë¥¼ í†µí•œ ClothSegmentationStep ì²˜ë¦¬
            input_data = {
                'image': clothing_image,
                'clothing_type': clothing_type,
                'quality_level': analysis_detail,
                'session_id': session_id
            }
            
            result = await self._process_step_with_central_hub(
                step_type=3,  # CLOTH_SEGMENTATION
                input_data=input_data,
                request_id=request_id
            )
            
            # ê²°ê³¼ ì—…ë°ì´íŠ¸
            result.update({
                "step_id": 5,
                "step_name": "Clothing Analysis",
                "session_id": session_id,
                "message": "ì˜ë¥˜ ë¶„ì„ ì™„ë£Œ (Central Hub â†’ ClothSegmentationStep)"
            })
            
            # ì„¸ì…˜ì— ê²°ê³¼ ì €ìž¥
            self.sessions[session_id]['clothing_analysis_result'] = result
            
            if result.get('success', False):
                with self._lock:
                    self.successful_requests += 1
                    self.processing_times.append(result.get('processing_time', 0))
            else:
                with self._lock:
                    self.failed_requests += 1
                    self.last_error = result.get('error')
            
            return result
            
        except Exception as e:
            with self._lock:
                self.failed_requests += 1
                self.last_error = str(e)
            
            self.logger.error(f"âŒ Step 5 Central Hub ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return {
                "success": False,
                "error": str(e),
                "step_id": 5,
                "step_name": "Clothing Analysis",
                "session_id": session_id,
                "request_id": request_id,
                "central_hub_used": self.central_hub_container is not None,
                "timestamp": datetime.now().isoformat()
            }
    
    async def process_step_6_geometric_matching(
        self,
        session_id: str,
        matching_precision: str = "high"
    ) -> Dict[str, Any]:
        """6ë‹¨ê³„: ê¸°í•˜í•™ì  ë§¤ì¹­ (Central Hub â†’ StepFactory â†’ GeometricMatchingStep)"""
        request_id = f"step6_{uuid.uuid4().hex[:8]}"
        
        try:
            with self._lock:
                self.total_requests += 1
            
            # ì„¸ì…˜ì—ì„œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
            if session_id not in self.sessions:
                raise ValueError(f"ì„¸ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {session_id}")
            
            session_data = self.sessions[session_id]
            person_image = session_data.get('person_image')
            clothing_image = session_data.get('clothing_image')
            
            if not person_image or not clothing_image:
                raise ValueError("person_image ë˜ëŠ” clothing_imageê°€ ì—†ìŠµë‹ˆë‹¤")
            
            self.logger.info(f"ðŸ§  Step 6 Central Hub â†’ GeometricMatchingStep ì²˜ë¦¬ ì‹œìž‘: {session_id}")
            
            # Central Hubë¥¼ í†µí•œ GeometricMatchingStep ì²˜ë¦¬
            input_data = {
                'person_image': person_image,
                'clothing_image': clothing_image,
                'matching_precision': matching_precision,
                'session_id': session_id
            }
            
            result = await self._process_step_with_central_hub(
                step_type=4,  # GEOMETRIC_MATCHING
                input_data=input_data,
                request_id=request_id
            )
            
            # ê²°ê³¼ ì—…ë°ì´íŠ¸
            result.update({
                "step_id": 6,
                "step_name": "Geometric Matching",
                "session_id": session_id,
                "message": "ê¸°í•˜í•™ì  ë§¤ì¹­ ì™„ë£Œ (Central Hub â†’ GeometricMatchingStep)"
            })
            
            # ì„¸ì…˜ì— ê²°ê³¼ ì €ìž¥
            self.sessions[session_id]['geometric_matching_result'] = result
            
            if result.get('success', False):
                with self._lock:
                    self.successful_requests += 1
                    self.processing_times.append(result.get('processing_time', 0))
            else:
                with self._lock:
                    self.failed_requests += 1
                    self.last_error = result.get('error')
            
            return result
            
        except Exception as e:
            with self._lock:
                self.failed_requests += 1
                self.last_error = str(e)
            
            self.logger.error(f"âŒ Step 6 Central Hub ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return {
                "success": False,
                "error": str(e),
                "step_id": 6,
                "step_name": "Geometric Matching",
                "session_id": session_id,
                "request_id": request_id,
                "central_hub_used": self.central_hub_container is not None,
                "timestamp": datetime.now().isoformat()
            }
    
    async def process_step_7_virtual_fitting(
        self,
        session_id: str,
        fitting_quality: str = "high"
    ) -> Dict[str, Any]:
        """7ë‹¨ê³„: ê°€ìƒ í”¼íŒ… (Central Hub â†’ StepFactory â†’ VirtualFittingStep) â­ í•µì‹¬"""
        request_id = f"step7_{uuid.uuid4().hex[:8]}"
        
        # ì—ëŸ¬ ì»¨í…ìŠ¤íŠ¸ ì¤€ë¹„
        error_context = {
            'step_id': 7,
            'step_name': 'Virtual Fitting',
            'session_id': session_id,
            'request_id': request_id,
            'fitting_quality': fitting_quality,
            'central_hub_available': self.central_hub_container is not None,
            'step_factory_available': self.step_factory is not None,
            'device': DEVICE
        }
        
        try:
            with self._lock:
                self.total_requests += 1
            
            # ì„¸ì…˜ì—ì„œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
            if session_id not in self.sessions:
                # exceptions.pyì˜ ì»¤ìŠ¤í…€ ì˜ˆì™¸ ì‚¬ìš©
                from app.core.exceptions import SessionError
                raise SessionError(
                    f"ì„¸ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {session_id}",
                    "SESSION_NOT_FOUND",
                    error_context
                )
            
            session_data = self.sessions[session_id]
            person_image = session_data.get('person_image')
            clothing_image = session_data.get('clothing_image')
            
            if not person_image or not clothing_image:
                # exceptions.pyì˜ ì»¤ìŠ¤í…€ ì˜ˆì™¸ ì‚¬ìš©
                from app.core.exceptions import DataValidationError
                raise DataValidationError(
                    "person_image ë˜ëŠ” clothing_imageê°€ ì—†ìŠµë‹ˆë‹¤",
                    "MISSING_IMAGE_DATA",
                    error_context
                )
            
            self.logger.info(f"ðŸ§  Step 7 Central Hub â†’ VirtualFittingStep ì²˜ë¦¬ ì‹œìž‘: {session_id} â­ í•µì‹¬!")
            
            # Central Hubë¥¼ í†µí•œ VirtualFittingStep ì²˜ë¦¬ â­ í•µì‹¬
            input_data = {
                'person_image': person_image,
                'clothing_image': clothing_image,
                'fitting_quality': fitting_quality,
                'session_id': session_id,
                
                # VirtualFittingStep íŠ¹í™” ì„¤ì •
                'fitting_mode': "hd",
                'guidance_scale': 7.5,
                'num_inference_steps': 50
            }
            
            result = await self._process_step_with_central_hub(
                step_type=6,  # VIRTUAL_FITTING â­ í•µì‹¬!
                input_data=input_data,
                request_id=request_id
            )
            
            # fitted_image í™•ì¸
            fitted_image = result.get('fitted_image')
            if not fitted_image and result.get('success', False):
                self.logger.warning("âš ï¸ VirtualFittingStepì—ì„œ fitted_imageê°€ ì—†ìŒ")
                error_context['fitted_image_missing'] = True
            
            # ê²°ê³¼ ì—…ë°ì´íŠ¸
            result.update({
                "step_id": 7,
                "step_name": "Virtual Fitting",
                "session_id": session_id,
                "message": "ê°€ìƒ í”¼íŒ… ì™„ë£Œ (Central Hub â†’ VirtualFittingStep) â­ í•µì‹¬",
                "fit_score": result.get('confidence', 0.95),
                "device": DEVICE,
                "virtual_fitting_core_step": True,  # â­ í•µì‹¬ ë‹¨ê³„ í‘œì‹œ
                "ootd_diffusion_used": True  # OOTD Diffusion ì‚¬ìš©
            })
            
            # ì„¸ì…˜ì— ê²°ê³¼ ì €ìž¥
            self.sessions[session_id]['virtual_fitting_result'] = result
            
            if result.get('success', False):
                with self._lock:
                    self.successful_requests += 1
                    self.processing_times.append(result.get('processing_time', 0))
                
                self.logger.info(f"âœ… Step 7 (VirtualFittingStep) Central Hub ì²˜ë¦¬ ì™„ë£Œ: {result.get('processing_time', 0):.2f}ì´ˆ â­")
            else:
                with self._lock:
                    self.failed_requests += 1
                    self.last_error = result.get('error')
            
            return result
            
        except Exception as e:
            with self._lock:
                self.failed_requests += 1
                self.last_error = str(e)
            
            # exceptions.pyì˜ ì»¤ìŠ¤í…€ ì˜ˆì™¸ë¡œ ë³€í™˜
            from app.core.exceptions import (
                convert_to_mycloset_exception,
                create_exception_response,
                VirtualFittingError,
                ModelInferenceError
            )
            
            # ì—ëŸ¬ íƒ€ìž…ë³„ ì»¤ìŠ¤í…€ ì˜ˆì™¸ ë³€í™˜
            if isinstance(e, (ValueError, TypeError)):
                custom_error = DataValidationError(
                    f"ê°€ìƒ í”¼íŒ… ì¤‘ ë°ì´í„° ì˜¤ë¥˜: {e}",
                    "VIRTUAL_FITTING_DATA_ERROR",
                    error_context
                )
            elif isinstance(e, (OSError, IOError)):
                custom_error = VirtualFittingError(
                    f"ê°€ìƒ í”¼íŒ… ì¤‘ ì‹œìŠ¤í…œ ì˜¤ë¥˜: {e}",
                    "VIRTUAL_FITTING_SYSTEM_ERROR",
                    error_context
                )
            else:
                custom_error = convert_to_mycloset_exception(e, error_context)
            
            self.logger.error(f"âŒ Step 7 (VirtualFittingStep) Central Hub ì²˜ë¦¬ ì‹¤íŒ¨: {custom_error}")
            
            # í‘œì¤€í™”ëœ ì—ëŸ¬ ì‘ë‹µ ìƒì„±
            error_response = create_exception_response(
                custom_error, 
                "Virtual Fitting", 
                7,
                session_id
            )
            
            # ì¶”ê°€ ì •ë³´ ì„¤ì •
            error_response.update({
                "step_id": 7,
                "step_name": "Virtual Fitting",
                "session_id": session_id,
                "request_id": request_id,
                "central_hub_used": self.central_hub_container is not None,
                "timestamp": datetime.now().isoformat()
            })
            
            return error_response
    
    async def process_step_8_result_analysis(
        self,
        session_id: str,
        analysis_depth: str = "comprehensive"
    ) -> Dict[str, Any]:
        """8ë‹¨ê³„: ê²°ê³¼ ë¶„ì„ (Central Hub â†’ StepFactory â†’ QualityAssessmentStep)"""
        request_id = f"step8_{uuid.uuid4().hex[:8]}"
        
        try:
            with self._lock:
                self.total_requests += 1
            
            # ì„¸ì…˜ì—ì„œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
            if session_id not in self.sessions:
                raise ValueError(f"ì„¸ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {session_id}")
            
            session_data = self.sessions[session_id]
            virtual_fitting_result = session_data.get('virtual_fitting_result')
            
            if not virtual_fitting_result:
                raise ValueError("ê°€ìƒ í”¼íŒ… ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤")
            
            fitted_image = virtual_fitting_result.get('fitted_image')
            if not fitted_image:
                raise ValueError("fitted_imageê°€ ì—†ìŠµë‹ˆë‹¤")
            
            self.logger.info(f"ðŸ§  Step 8 Central Hub â†’ QualityAssessmentStep ì²˜ë¦¬ ì‹œìž‘: {session_id}")
            
            # Central Hubë¥¼ í†µí•œ QualityAssessmentStep ì²˜ë¦¬
            input_data = {
                'final_image': fitted_image,
                'analysis_depth': analysis_depth,
                'session_id': session_id
            }
            
            result = await self._process_step_with_central_hub(
                step_type=8,  # QUALITY_ASSESSMENT
                input_data=input_data,
                request_id=request_id
            )
            
            # ê²°ê³¼ ì—…ë°ì´íŠ¸
            result.update({
                "step_id": 8,
                "step_name": "Result Analysis",
                "session_id": session_id,
                "message": "ê²°ê³¼ ë¶„ì„ ì™„ë£Œ (Central Hub â†’ QualityAssessmentStep)"
            })
            
            # ì„¸ì…˜ì— ê²°ê³¼ ì €ìž¥
            self.sessions[session_id]['result_analysis'] = result
            
            if result.get('success', False):
                with self._lock:
                    self.successful_requests += 1
                    self.processing_times.append(result.get('processing_time', 0))
            else:
                with self._lock:
                    self.failed_requests += 1
                    self.last_error = result.get('error')
            
            return result
            
        except Exception as e:
            with self._lock:
                self.failed_requests += 1
                self.last_error = str(e)
            
            self.logger.error(f"âŒ Step 8 Central Hub ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return {
                "success": False,
                "error": str(e),
                "step_id": 8,
                "step_name": "Result Analysis",
                "session_id": session_id,
                "request_id": request_id,
                "central_hub_used": self.central_hub_container is not None,
                "timestamp": datetime.now().isoformat()
            }
    
    # ==============================================
    # ðŸ”¥ ì¶”ê°€ Step ì²˜ë¦¬ ë©”ì„œë“œë“¤ (Central Hub ê¸°ë°˜) - ê¸°ì¡´ íŒŒì¼ì—ì„œ ëˆ„ë½ëœ ê¸°ëŠ¥ë“¤
    # ==============================================
    
    async def process_step_9_cloth_warping(
        self,
        session_id: str,
        warping_method: str = "tps"
    ) -> Dict[str, Any]:
        """9ë‹¨ê³„: ì˜ë¥˜ ì›Œí•‘ (Central Hub â†’ StepFactory â†’ ClothWarpingStep)"""
        request_id = f"step9_{uuid.uuid4().hex[:8]}"
        
        try:
            with self._lock:
                self.total_requests += 1
            
            # ì„¸ì…˜ì—ì„œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
            if session_id not in self.sessions:
                raise ValueError(f"ì„¸ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {session_id}")
            
            session_data = self.sessions[session_id]
            clothing_image = session_data.get('clothing_image')
            pose_data = session_data.get('pose_estimation_result', {})
            
            if not clothing_image:
                raise ValueError("clothing_imageê°€ ì—†ìŠµë‹ˆë‹¤")
            
            self.logger.info(f"ðŸ§  Step 9 Central Hub â†’ ClothWarpingStep ì²˜ë¦¬ ì‹œìž‘: {session_id}")
            
            # Central Hubë¥¼ í†µí•œ ClothWarpingStep ì²˜ë¦¬
            input_data = {
                'clothing_image': clothing_image,
                'pose_data': pose_data,
                'warping_method': warping_method,
                'session_id': session_id
            }
            
            result = await self._process_step_with_central_hub(
                step_type=5,  # CLOTH_WARPING
                input_data=input_data,
                request_id=request_id
            )
            
            # ê²°ê³¼ ì—…ë°ì´íŠ¸
            result.update({
                "step_id": 9,
                "step_name": "Cloth Warping",
                "session_id": session_id,
                "message": "ì˜ë¥˜ ì›Œí•‘ ì™„ë£Œ (Central Hub â†’ ClothWarpingStep)"
            })
            
            # ì„¸ì…˜ì— ê²°ê³¼ ì €ìž¥
            self.sessions[session_id]['cloth_warping_result'] = result
            
            if result.get('success', False):
                with self._lock:
                    self.successful_requests += 1
                    self.processing_times.append(result.get('processing_time', 0))
            else:
                with self._lock:
                    self.failed_requests += 1
                    self.last_error = result.get('error')
            
            return result
            
        except Exception as e:
            with self._lock:
                self.failed_requests += 1
                self.last_error = str(e)
            
            self.logger.error(f"âŒ Step 9 Central Hub ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return {
                "success": False,
                "error": str(e),
                "step_id": 9,
                "step_name": "Cloth Warping",
                "session_id": session_id,
                "request_id": request_id,
                "central_hub_used": self.central_hub_container is not None,
                "timestamp": datetime.now().isoformat()
            }
    
    async def process_step_10_post_processing(
        self,
        session_id: str,
        enhancement_level: str = "high"
    ) -> Dict[str, Any]:
        """10ë‹¨ê³„: í›„ì²˜ë¦¬ (Central Hub â†’ StepFactory â†’ PostProcessingStep)"""
        request_id = f"step10_{uuid.uuid4().hex[:8]}"
        
        try:
            with self._lock:
                self.total_requests += 1
            
            # ì„¸ì…˜ì—ì„œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
            if session_id not in self.sessions:
                raise ValueError(f"ì„¸ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {session_id}")
            
            session_data = self.sessions[session_id]
            virtual_fitting_result = session_data.get('virtual_fitting_result')
            
            if not virtual_fitting_result:
                raise ValueError("ê°€ìƒ í”¼íŒ… ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤")
            
            fitted_image = virtual_fitting_result.get('fitted_image')
            if not fitted_image:
                raise ValueError("fitted_imageê°€ ì—†ìŠµë‹ˆë‹¤")
            
            self.logger.info(f"ðŸ§  Step 10 Central Hub â†’ PostProcessingStep ì²˜ë¦¬ ì‹œìž‘: {session_id}")
            
            # Central Hubë¥¼ í†µí•œ PostProcessingStep ì²˜ë¦¬
            input_data = {
                'fitted_image': fitted_image,
                'enhancement_level': enhancement_level,
                'session_id': session_id
            }
            
            result = await self._process_step_with_central_hub(
                step_type=7,  # POST_PROCESSING
                input_data=input_data,
                request_id=request_id
            )
            
            # ê²°ê³¼ ì—…ë°ì´íŠ¸
            result.update({
                "step_id": 10,
                "step_name": "Post Processing",
                "session_id": session_id,
                "message": "í›„ì²˜ë¦¬ ì™„ë£Œ (Central Hub â†’ PostProcessingStep)"
            })
            
            # ì„¸ì…˜ì— ê²°ê³¼ ì €ìž¥
            self.sessions[session_id]['post_processing_result'] = result
            
            if result.get('success', False):
                with self._lock:
                    self.successful_requests += 1
                    self.processing_times.append(result.get('processing_time', 0))
            else:
                with self._lock:
                    self.failed_requests += 1
                    self.last_error = result.get('error')
            
            return result
            
        except Exception as e:
            with self._lock:
                self.failed_requests += 1
                self.last_error = str(e)
            
            self.logger.error(f"âŒ Step 10 Central Hub ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return {
                "success": False,
                "error": str(e),
                "step_id": 10,
                "step_name": "Post Processing",
                "session_id": session_id,
                "request_id": request_id,
                "central_hub_used": self.central_hub_container is not None,
                "timestamp": datetime.now().isoformat()
            }
    
    # ==============================================
    # ðŸ”¥ ë¡œê¹… ë° ëª¨ë‹ˆí„°ë§ ë©”ì„œë“œë“¤ (Central Hub ê¸°ë°˜) - ê¸°ì¡´ íŒŒì¼ ê¸°ëŠ¥ ë³µì›
    # ==============================================
    
    def get_recent_logs(self, limit: int = 100) -> Dict[str, Any]:
        """ìµœê·¼ ë¡œê·¸ ì¡°íšŒ (Central Hub ê¸°ë°˜)"""
        try:
            # ì‹¤ì œ ë¡œê·¸ íŒŒì¼ì—ì„œ ì½ê¸° ì‹œë„
            logs = []
            
            # ë©”ëª¨ë¦¬ ê¸°ë°˜ ë¡œê·¸ (ê°„ë‹¨í•œ êµ¬í˜„)
            if hasattr(self, '_recent_logs'):
                logs = self._recent_logs[-limit:]
            else:
                logs = [
                    {
                        "timestamp": datetime.now().isoformat(),
                        "level": "INFO",
                        "message": "StepServiceManager v16.0 ì‹¤í–‰ ì¤‘ (Central Hub ê¸°ë°˜)",
                        "component": "StepServiceManager",
                        "central_hub_used": self.central_hub_container is not None
                    }
                ]
            
            return {
                "logs": logs,
                "total_logs": len(logs),
                "limit": limit,
                "central_hub_integrated": True,
                "timestamp": datetime.now().isoformat()
            }
            
        except Exception as e:
            return {
                "error": str(e),
                "timestamp": datetime.now().isoformat()
            }
    
    def set_log_level(self, level: Union[str, int]) -> Dict[str, Any]:
        """ë¡œê·¸ ë ˆë²¨ ì„¤ì • (Central Hub ê¸°ë°˜)"""
        try:
            if isinstance(level, str):
                level = getattr(logging, level.upper())
            
            old_level = self.logger.level
            self.logger.setLevel(level)
            
            return {
                "success": True,
                "old_level": old_level,
                "new_level": level,
                "central_hub_integrated": True,
                "timestamp": datetime.now().isoformat()
            }
            
        except Exception as e:
            return {
                "success": False,
                "error": str(e),
                "current_level": self.logger.level,
                "timestamp": datetime.now().isoformat()
            }
    
    # ==============================================
    # ðŸ”¥ í…ŒìŠ¤íŠ¸ ë° ê°œë°œ ì§€ì› ë©”ì„œë“œë“¤ (Central Hub ê¸°ë°˜) - ê¸°ì¡´ íŒŒì¼ ê¸°ëŠ¥ ë³µì›
    # ==============================================
    
    async def run_system_test(self) -> Dict[str, Any]:
        """ì‹œìŠ¤í…œ ì „ì²´ í…ŒìŠ¤íŠ¸ (Central Hub ê¸°ë°˜)"""
        test_start = time.time()
        test_results = {
            "overall_success": False,
            "tests": {},
            "errors": [],
            "warnings": []
        }
        
        try:
            # 1. ì´ˆê¸°í™” í…ŒìŠ¤íŠ¸
            test_results["tests"]["initialization"] = {
                "success": self.status == ServiceStatus.ACTIVE,
                "message": f"ì„œë¹„ìŠ¤ ìƒíƒœ: {self.status.value}"
            }
            
            # 2. Central Hub í…ŒìŠ¤íŠ¸
            central_hub_test = {
                "success": self.central_hub_container is not None,
                "message": f"Central Hub: {'ì‚¬ìš© ê°€ëŠ¥' if self.central_hub_container else 'ì‚¬ìš© ë¶ˆê°€'}"
            }
            test_results["tests"]["central_hub"] = central_hub_test
            
            # 3. StepFactory í…ŒìŠ¤íŠ¸
            step_factory_test = {
                "success": self.step_factory is not None,
                "message": f"StepFactory: {'ì‚¬ìš© ê°€ëŠ¥' if self.step_factory else 'ì‚¬ìš© ë¶ˆê°€'}"
            }
            test_results["tests"]["step_factory"] = step_factory_test
            
            # 4. ë©”ëª¨ë¦¬ í…ŒìŠ¤íŠ¸
            memory_test = {
                "success": MEMORY_GB >= 16.0,
                "message": f"ë©”ëª¨ë¦¬: {MEMORY_GB:.1f}GB"
            }
            test_results["tests"]["memory"] = memory_test
            
            # 5. conda í™˜ê²½ í…ŒìŠ¤íŠ¸
            conda_test = {
                "success": CONDA_INFO['is_target_env'],
                "message": f"conda í™˜ê²½: {CONDA_INFO['conda_env']}"
            }
            test_results["tests"]["conda_environment"] = conda_test
            
            # 6. ë¼ì´ë¸ŒëŸ¬ë¦¬ í…ŒìŠ¤íŠ¸
            library_test = {
                "success": TORCH_AVAILABLE and NUMPY_AVAILABLE and PIL_AVAILABLE,
                "message": f"ë¼ì´ë¸ŒëŸ¬ë¦¬: PyTorch={TORCH_AVAILABLE}, NumPy={NUMPY_AVAILABLE}, PIL={PIL_AVAILABLE}"
            }
            test_results["tests"]["libraries"] = library_test
            
            # 7. ê°„ë‹¨í•œ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸ (ëª¨ì˜ ë°ì´í„°)
            try:
                mock_measurements = {"height": 170, "weight": 65}
                mock_session = f"test_{uuid.uuid4().hex[:8]}"
                
                validation_result = await self.process_step_2_measurements_validation(
                    measurements=mock_measurements,
                    session_id=mock_session
                )
                
                processing_test = {
                    "success": validation_result.get("success", False),
                    "message": f"ì¸¡ì •ê°’ ê²€ì¦ í…ŒìŠ¤íŠ¸: {'ì„±ê³µ' if validation_result.get('success') else 'ì‹¤íŒ¨'}"
                }
                
                # í…ŒìŠ¤íŠ¸ ì„¸ì…˜ ì •ë¦¬
                if mock_session in self.sessions:
                    del self.sessions[mock_session]
                    
            except Exception as e:
                processing_test = {
                    "success": False,
                    "message": f"ì²˜ë¦¬ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(e)}"
                }
            
            test_results["tests"]["processing"] = processing_test
            
            # ì „ì²´ ì„±ê³µ ì—¬ë¶€ íŒë‹¨
            all_critical_tests_passed = all([
                test_results["tests"]["initialization"]["success"],
                test_results["tests"]["central_hub"]["success"],
                test_results["tests"]["libraries"]["success"]
            ])
            
            test_results["overall_success"] = all_critical_tests_passed
            
            # ê²½ê³  ë° ì˜¤ë¥˜ ìˆ˜ì§‘
            for test_name, test_result in test_results["tests"].items():
                if not test_result["success"]:
                    if test_name in ["initialization", "central_hub", "libraries"]:
                        test_results["errors"].append(f"{test_name}: {test_result['message']}")
                    else:
                        test_results["warnings"].append(f"{test_name}: {test_result['message']}")
            
            test_results["total_time"] = time.time() - test_start
            test_results["central_hub_integration"] = True
            test_results["timestamp"] = datetime.now().isoformat()
            
            return test_results
            
        except Exception as e:
            test_results["overall_success"] = False
            test_results["error"] = str(e)
            test_results["total_time"] = time.time() - test_start
            test_results["timestamp"] = datetime.now().isoformat()
            return test_results
    
    def generate_debug_info(self) -> Dict[str, Any]:
        """ë””ë²„ê·¸ ì •ë³´ ìƒì„± (Central Hub ê¸°ë°˜)"""
        try:
            debug_info = {
                "service_info": {
                    "version": "v16.0_central_hub_integration",
                    "status": self.status.value,
                    "processing_mode": self.processing_mode.value,
                    "uptime_seconds": (datetime.now() - self.start_time).total_seconds()
                },
                
                "performance_summary": {
                    "total_requests": self.total_requests,
                    "successful_requests": self.successful_requests,
                    "failed_requests": self.failed_requests,
                    "success_rate": (self.successful_requests / max(1, self.total_requests)) * 100,
                    "average_processing_time": sum(self.processing_times) / max(1, len(self.processing_times))
                },
                
                "environment_info": {
                    "conda_env": CONDA_INFO['conda_env'],
                    "conda_optimized": CONDA_INFO['is_target_env'],
                    "device": DEVICE,
                    "is_m3_max": IS_M3_MAX,
                    "memory_gb": MEMORY_GB,
                    "torch_available": TORCH_AVAILABLE
                },
                
                "central_hub_integration": {
                    "central_hub_available": self.central_hub_container is not None,
                    "step_factory_available": self.step_factory is not None,
                    "automatic_dependency_injection": self.central_hub_container is not None,
                    "circular_reference_free": True,
                    "single_source_of_truth": self.central_hub_container is not None
                },
                
                "active_sessions": {
                    "count": len(self.sessions),
                    "session_ids": list(self.sessions.keys())
                },
                
                "central_hub_metrics": self.central_hub_metrics.copy(),
                
                "memory_usage": {
                    "current_mb": self._get_memory_usage(),
                    "session_memory_mb": sum(sys.getsizeof(data) for data in self.sessions.values()) / 1024 / 1024
                },
                
                "last_error": self.last_error,
                "timestamp": datetime.now().isoformat()
            }
            
            # Central Hub í†µê³„ ì¶”ê°€
            if self.central_hub_container and hasattr(self.central_hub_container, 'get_stats'):
                try:
                    debug_info["central_hub_stats"] = self.central_hub_container.get_stats()
                except Exception as e:
                    debug_info["central_hub_stats_error"] = str(e)
            
            # StepFactory í†µê³„ ì¶”ê°€
            if self.step_factory and hasattr(self.step_factory, 'get_statistics'):
                try:
                    debug_info["step_factory_stats"] = self.step_factory.get_statistics()
                except Exception as e:
                    debug_info["step_factory_stats_error"] = str(e)
            
            return debug_info
            
        except Exception as e:
            return {
                "error": str(e),
                "timestamp": datetime.now().isoformat()
            }
    # ==============================================
    
    async def process_complete_virtual_fitting(
        self,
        person_image: Any,
        clothing_image: Any,
        measurements: Union[BodyMeasurements, Dict[str, Any]],
        **kwargs
    ) -> Dict[str, Any]:
        """ì™„ì „í•œ 8ë‹¨ê³„ ê°€ìƒ í”¼íŒ… íŒŒì´í”„ë¼ì¸ (Central Hub ê¸°ë°˜)"""
        session_id = f"complete_{uuid.uuid4().hex[:12]}"
        request_id = f"complete_{uuid.uuid4().hex[:8]}"
        start_time = time.time()
        
        # ì—ëŸ¬ ì»¨í…ìŠ¤íŠ¸ ì¤€ë¹„
        error_context = {
            'session_id': session_id,
            'request_id': request_id,
            'person_image_type': type(person_image).__name__,
            'clothing_image_type': type(clothing_image).__name__,
            'measurements_type': type(measurements).__name__,
            'central_hub_available': self.central_hub_container is not None,
            'step_factory_available': self.step_factory is not None,
            'kwargs_keys': list(kwargs.keys())
        }
        
        try:
            with self._lock:
                self.total_requests += 1
            
            self.logger.info(f"ðŸš€ ì™„ì „í•œ 8ë‹¨ê³„ Central Hub íŒŒì´í”„ë¼ì¸ ì‹œìž‘: {session_id}")
            
            # Central Hubì˜ ì „ì²´ íŒŒì´í”„ë¼ì¸ ì²˜ë¦¬ ì‹œë„
            if self.step_factory and hasattr(self.step_factory, 'create_full_pipeline'):
                try:
                    pipeline_input = {
                        'person_image': person_image,
                        'clothing_image': clothing_image,
                        'measurements': measurements,
                        'session_id': session_id
                    }
                    pipeline_input.update(kwargs)
                    
                    # StepFactoryì˜ ì „ì²´ íŒŒì´í”„ë¼ì¸ ì²˜ë¦¬
                    pipeline_result = await self.step_factory.create_full_pipeline(**pipeline_input)
                    
                    if pipeline_result and pipeline_result.get('success', False):
                        total_time = time.time() - start_time
                        
                        # ê°€ìƒ í”¼íŒ… ê²°ê³¼ ì¶”ì¶œ
                        fitted_image = pipeline_result.get('fitted_image')
                        fit_score = pipeline_result.get('fit_score', 0.95)
                        
                        with self._lock:
                            self.successful_requests += 1
                            self.processing_times.append(total_time)
                        
                        return {
                            "success": True,
                            "message": "ì™„ì „í•œ 8ë‹¨ê³„ Central Hub íŒŒì´í”„ë¼ì¸ ì™„ë£Œ",
                            "session_id": session_id,
                            "request_id": request_id,
                            "processing_time": total_time,
                            "fitted_image": fitted_image,
                            "fit_score": fit_score,
                            "confidence": fit_score,
                            "details": pipeline_result,
                            "central_hub_pipeline_used": True,
                            "timestamp": datetime.now().isoformat()
                        }
                except Exception as e:
                    self.logger.warning(f"âš ï¸ Central Hub ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤íŒ¨, ê°œë³„ Step ì²˜ë¦¬: {e}")
                    error_context['full_pipeline_failed'] = str(e)
            
            # í´ë°±: ê°œë³„ Step ì²˜ë¦¬
            self.logger.info("ðŸ”„ Central Hub ê°œë³„ Step íŒŒì´í”„ë¼ì¸ ì²˜ë¦¬")
            
            # 1-2ë‹¨ê³„: ì—…ë¡œë“œ ë° ì¸¡ì •ê°’ ê²€ì¦
            step1_result = await self.process_step_1_upload_validation(
                person_image, clothing_image, session_id
            )
            if not step1_result.get("success", False):
                return step1_result
            
            step2_result = await self.process_step_2_measurements_validation(
                measurements, session_id
            )
            if not step2_result.get("success", False):
                return step2_result
            
            # 3-8ë‹¨ê³„: Central Hub ê¸°ë°˜ AI íŒŒì´í”„ë¼ì¸ ì²˜ë¦¬
            pipeline_steps = [
                (3, self.process_step_3_human_parsing, {"session_id": session_id}),
                (4, self.process_step_4_pose_estimation, {"session_id": session_id}),
                (5, self.process_step_5_clothing_analysis, {"session_id": session_id}),
                (6, self.process_step_6_geometric_matching, {"session_id": session_id}),
                (7, self.process_step_7_virtual_fitting, {"session_id": session_id}),  # â­ í•µì‹¬ VirtualFittingStep
                (8, self.process_step_8_result_analysis, {"session_id": session_id}),
            ]
            
            step_results = {}
            step_successes = 0
            step_failures = []
            
            for step_id, step_func, step_kwargs in pipeline_steps:
                try:
                    step_result = await step_func(**step_kwargs)
                    step_results[f"step_{step_id}"] = step_result
                    
                    if step_result.get("success", False):
                        step_successes += 1
                        self.logger.info(f"âœ… Central Hub Step {step_id} ì„±ê³µ")
                    else:
                        step_failures.append(f"Step {step_id}: {step_result.get('error', 'Unknown error')}")
                        self.logger.warning(f"âš ï¸ Central Hub Step {step_id} ì‹¤íŒ¨í•˜ì§€ë§Œ ê³„ì† ì§„í–‰")
                        
                except Exception as e:
                    step_failures.append(f"Step {step_id}: {str(e)}")
                    self.logger.error(f"âŒ Central Hub Step {step_id} ì˜¤ë¥˜: {e}")
                    step_results[f"step_{step_id}"] = {"success": False, "error": str(e)}
            
            # ìµœì¢… ê²°ê³¼ ìƒì„±
            total_time = time.time() - start_time
            
            # ê°€ìƒ í”¼íŒ… ê²°ê³¼ ì¶”ì¶œ (Step 7 = VirtualFittingStep)
            virtual_fitting_result = step_results.get("step_7", {})
            fitted_image = virtual_fitting_result.get("fitted_image")
            fit_score = virtual_fitting_result.get("fit_score", 0.95)
            
            if not fitted_image:
                # exceptions.pyì˜ ì»¤ìŠ¤í…€ ì˜ˆì™¸ ì‚¬ìš©
                from app.core.exceptions import VirtualFittingError
                raise VirtualFittingError(
                    "Central Hub ê°œë³„ Step íŒŒì´í”„ë¼ì¸ì—ì„œ fitted_image ìƒì„± ì‹¤íŒ¨",
                    "FITTED_IMAGE_GENERATION_FAILED",
                    error_context
                )
            
            # ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
            with self._lock:
                self.successful_requests += 1
                self.processing_times.append(total_time)
            
            return {
                "success": True,
                "message": "ì™„ì „í•œ 8ë‹¨ê³„ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ (Central Hub ê°œë³„ Step)",
                "session_id": session_id,
                "request_id": request_id,
                "processing_time": total_time,
                "fitted_image": fitted_image,
                "fit_score": fit_score,
                "confidence": fit_score,
                "details": {
                    "total_steps": 8,
                    "successful_steps": step_successes,
                    "failed_steps": step_failures,
                    "central_hub_available": self.central_hub_container is not None,
                    "individual_step_processing": True,
                    "step_results": step_results
                },
                "central_hub_individual_steps_used": True,
                "timestamp": datetime.now().isoformat()
            }
            
        except Exception as e:
            with self._lock:
                self.failed_requests += 1
                self.last_error = str(e)
            
            # exceptions.pyì˜ ì»¤ìŠ¤í…€ ì˜ˆì™¸ë¡œ ë³€í™˜
            from app.core.exceptions import (
                convert_to_mycloset_exception,
                create_exception_response,
                VirtualFittingError,
                PipelineError
            )
            
            # ì—ëŸ¬ íƒ€ìž…ë³„ ì»¤ìŠ¤í…€ ì˜ˆì™¸ ë³€í™˜
            if isinstance(e, (ValueError, TypeError)):
                custom_error = PipelineError(
                    f"ì™„ì „í•œ íŒŒì´í”„ë¼ì¸ ì²˜ë¦¬ ì¤‘ ë°ì´í„° ì˜¤ë¥˜: {e}",
                    "COMPLETE_PIPELINE_DATA_ERROR",
                    error_context
                )
            elif isinstance(e, (OSError, IOError)):
                custom_error = PipelineError(
                    f"ì™„ì „í•œ íŒŒì´í”„ë¼ì¸ ì²˜ë¦¬ ì¤‘ ì‹œìŠ¤í…œ ì˜¤ë¥˜: {e}",
                    "COMPLETE_PIPELINE_SYSTEM_ERROR",
                    error_context
                )
            else:
                custom_error = convert_to_mycloset_exception(e, error_context)
            
            self.logger.error(f"âŒ ì™„ì „í•œ Central Hub íŒŒì´í”„ë¼ì¸ ì‹¤íŒ¨: {custom_error}")
            
            # í‘œì¤€í™”ëœ ì—ëŸ¬ ì‘ë‹µ ìƒì„±
            error_response = create_exception_response(
                custom_error, 
                "Complete Virtual Fitting Pipeline", 
                -1,  # ì „ì²´ íŒŒì´í”„ë¼ì¸
                session_id
            )
            
            # ì¶”ê°€ ì •ë³´ ì„¤ì •
            error_response.update({
                "session_id": session_id,
                "request_id": request_id,
                "processing_time": time.time() - start_time,
                "central_hub_available": self.central_hub_container is not None,
                "timestamp": datetime.now().isoformat()
            })
            
            return error_response
    
    # ==============================================
    # ðŸ”¥ ì¼ê´„ ì²˜ë¦¬ ë° ë°°ì¹˜ ì²˜ë¦¬ ë©”ì„œë“œë“¤ (Central Hub ê¸°ë°˜)
    # ==============================================
    
    async def process_batch_virtual_fitting(
        self,
        batch_requests: List[Dict[str, Any]],
        batch_id: Optional[str] = None,
        max_concurrent: int = 3
    ) -> Dict[str, Any]:
        """ì¼ê´„ ê°€ìƒ í”¼íŒ… ì²˜ë¦¬ (Central Hub ê¸°ë°˜)"""
        if batch_id is None:
            batch_id = f"batch_{uuid.uuid4().hex[:8]}"
        
        start_time = time.time()
        
        try:
            with self._lock:
                self.total_requests += len(batch_requests)
            
            self.logger.info(f"ðŸš€ ì¼ê´„ ê°€ìƒ í”¼íŒ… ì²˜ë¦¬ ì‹œìž‘: {len(batch_requests)}ê°œ ìš”ì²­ (batch_id: {batch_id})")
            
            # ë™ì‹œ ì²˜ë¦¬ ì œí•œ
            semaphore = asyncio.Semaphore(max_concurrent)
            
            async def process_single_request(request_data: Dict[str, Any], index: int):
                async with semaphore:
                    try:
                        session_id = f"{batch_id}_session_{index}"
                        result = await self.process_complete_virtual_fitting(
                            person_image=request_data.get('person_image'),
                            clothing_image=request_data.get('clothing_image'),
                            measurements=request_data.get('measurements'),
                            session_id=session_id,
                            **request_data.get('options', {})
                        )
                        result['batch_index'] = index
                        result['batch_id'] = batch_id
                        return result
                    except Exception as e:
                        return {
                            "success": False,
                            "error": str(e),
                            "batch_index": index,
                            "batch_id": batch_id,
                            "central_hub_used": self.central_hub_container is not None,
                            "timestamp": datetime.now().isoformat()
                        }
            
            # ëª¨ë“  ìš”ì²­ ë¹„ë™ê¸° ì²˜ë¦¬
            tasks = [
                process_single_request(request_data, index)
                for index, request_data in enumerate(batch_requests)
            ]
            
            results = await asyncio.gather(*tasks, return_exceptions=True)
            
            # ê²°ê³¼ ì§‘ê³„
            successful_results = [r for r in results if isinstance(r, dict) and r.get('success', False)]
            failed_results = [r for r in results if isinstance(r, dict) and not r.get('success', False)]
            exception_results = [r for r in results if isinstance(r, Exception)]
            
            total_time = time.time() - start_time
            
            with self._lock:
                self.successful_requests += len(successful_results)
                self.failed_requests += len(failed_results) + len(exception_results)
            
            return {
                "success": True,
                "batch_id": batch_id,
                "total_requests": len(batch_requests),
                "successful_requests": len(successful_results),
                "failed_requests": len(failed_results) + len(exception_results),
                "success_rate": len(successful_results) / len(batch_requests) * 100,
                "total_processing_time": total_time,
                "average_processing_time": total_time / len(batch_requests),
                "results": results,
                "successful_results": successful_results,
                "failed_results": failed_results + [{"error": str(e)} for e in exception_results],
                "central_hub_used": self.central_hub_container is not None,
                "timestamp": datetime.now().isoformat()
            }
            
        except Exception as e:
            self.logger.error(f"âŒ ì¼ê´„ ê°€ìƒ í”¼íŒ… ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return {
                "success": False,
                "error": str(e),
                "batch_id": batch_id,
                "total_requests": len(batch_requests),
                "central_hub_used": self.central_hub_container is not None,
                "timestamp": datetime.now().isoformat()
            }
    
    async def process_scheduled_virtual_fitting(
        self,
        schedule_data: Dict[str, Any],
        schedule_id: Optional[str] = None
    ) -> Dict[str, Any]:
        """ì˜ˆì•½ëœ ê°€ìƒ í”¼íŒ… ì²˜ë¦¬ (Central Hub ê¸°ë°˜)"""
        if schedule_id is None:
            schedule_id = f"schedule_{uuid.uuid4().hex[:8]}"
        
        try:
            # ì˜ˆì•½ ì‹œê°„ í™•ì¸
            scheduled_time = schedule_data.get('scheduled_time')
            if scheduled_time:
                scheduled_datetime = datetime.fromisoformat(scheduled_time)
                current_time = datetime.now()
                
                if scheduled_datetime > current_time:
                    delay_seconds = (scheduled_datetime - current_time).total_seconds()
                    self.logger.info(f"â° ì˜ˆì•½ëœ ì²˜ë¦¬ ëŒ€ê¸° ì¤‘: {delay_seconds:.1f}ì´ˆ í›„ ì‹¤í–‰ (schedule_id: {schedule_id})")
                    await asyncio.sleep(delay_seconds)
            
            # ì‹¤ì œ ì²˜ë¦¬ ì‹¤í–‰
            result = await self.process_complete_virtual_fitting(
                person_image=schedule_data.get('person_image'),
                clothing_image=schedule_data.get('clothing_image'),
                measurements=schedule_data.get('measurements'),
                **schedule_data.get('options', {})
            )
            
            result.update({
                "schedule_id": schedule_id,
                "scheduled_processing": True,
                "actual_execution_time": datetime.now().isoformat(),
                "central_hub_used": self.central_hub_container is not None
            })
            
            return result
            
        except Exception as e:
            self.logger.error(f"âŒ ì˜ˆì•½ëœ ê°€ìƒ í”¼íŒ… ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return {
                "success": False,
                "error": str(e),
                "schedule_id": schedule_id,
                "central_hub_used": self.central_hub_container is not None,
                "timestamp": datetime.now().isoformat()
            }
    
    # ==============================================
    # ðŸ”¥ ì›¹ì†Œì¼“ ë° ì‹¤ì‹œê°„ ì²˜ë¦¬ ë©”ì„œë“œë“¤ (Central Hub ê¸°ë°˜)
    # ==============================================
    
    async def process_virtual_fitting_with_progress(
        self,
        person_image: Any,
        clothing_image: Any,
        measurements: Union[BodyMeasurements, Dict[str, Any]],
        progress_callback: Optional[Callable[[Dict[str, Any]], None]] = None,
        **kwargs
    ) -> Dict[str, Any]:
        """ì§„í–‰ë¥  ì½œë°±ê³¼ í•¨ê»˜ ê°€ìƒ í”¼íŒ… ì²˜ë¦¬ (Central Hub ê¸°ë°˜)"""
        session_id = f"progress_{uuid.uuid4().hex[:8]}"
        start_time = time.time()
        
        try:
            if progress_callback:
                await progress_callback({
                    "step": "initialization",
                    "progress": 0,
                    "message": "ê°€ìƒ í”¼íŒ… ì´ˆê¸°í™” ì¤‘... (Central Hub ê¸°ë°˜)",
                    "session_id": session_id,
                    "central_hub_used": self.central_hub_container is not None
                })
            
            # 1-2ë‹¨ê³„: ê²€ì¦
            step1_result = await self.process_step_1_upload_validation(
                person_image, clothing_image, session_id
            )
            
            if progress_callback:
                await progress_callback({
                    "step": "upload_validation",
                    "progress": 10,
                    "message": "ì´ë¯¸ì§€ ì—…ë¡œë“œ ê²€ì¦ ì™„ë£Œ (Central Hub ê¸°ë°˜)",
                    "session_id": session_id
                })
            
            if not step1_result.get("success", False):
                return step1_result
            
            step2_result = await self.process_step_2_measurements_validation(
                measurements, session_id
            )
            
            if progress_callback:
                await progress_callback({
                    "step": "measurements_validation", 
                    "progress": 20,
                    "message": "ì‹ ì²´ ì¸¡ì •ê°’ ê²€ì¦ ì™„ë£Œ (Central Hub ê¸°ë°˜)",
                    "session_id": session_id
                })
            
            if not step2_result.get("success", False):
                return step2_result
            
            # 3-8ë‹¨ê³„: Central Hub ê¸°ë°˜ AI íŒŒì´í”„ë¼ì¸
            pipeline_steps = [
                (3, self.process_step_3_human_parsing, 30, "ì¸ê°„ íŒŒì‹± ì²˜ë¦¬ ì¤‘... (Central Hub)"),
                (4, self.process_step_4_pose_estimation, 40, "í¬ì¦ˆ ì¶”ì • ì²˜ë¦¬ ì¤‘... (Central Hub)"),
                (5, self.process_step_5_clothing_analysis, 50, "ì˜ë¥˜ ë¶„ì„ ì²˜ë¦¬ ì¤‘... (Central Hub)"),
                (6, self.process_step_6_geometric_matching, 60, "ê¸°í•˜í•™ì  ë§¤ì¹­ ì²˜ë¦¬ ì¤‘... (Central Hub)"),
                (7, self.process_step_7_virtual_fitting, 80, "ê°€ìƒ í”¼íŒ… ì²˜ë¦¬ ì¤‘... (Central Hub - í•µì‹¬ ë‹¨ê³„)"),
                (8, self.process_step_8_result_analysis, 95, "ê²°ê³¼ ë¶„ì„ ì²˜ë¦¬ ì¤‘... (Central Hub)")
            ]
            
            step_results = {}
            
            for step_id, step_func, progress, message in pipeline_steps:
                if progress_callback:
                    await progress_callback({
                        "step": f"step_{step_id}",
                        "progress": progress,
                        "message": message,
                        "session_id": session_id
                    })
                
                step_result = await step_func(session_id=session_id)
                step_results[f"step_{step_id}"] = step_result
                
                if not step_result.get("success", False):
                    if progress_callback:
                        await progress_callback({
                            "step": f"step_{step_id}_failed",
                            "progress": progress,
                            "message": f"Central Hub Step {step_id} ì‹¤íŒ¨: {step_result.get('error', 'Unknown error')}",
                            "session_id": session_id,
                            "error": True
                        })
                    return step_result
            
            # ì™„ë£Œ
            if progress_callback:
                await progress_callback({
                    "step": "completed",
                    "progress": 100,
                    "message": "ê°€ìƒ í”¼íŒ… ì™„ë£Œ! (Central Hub ê¸°ë°˜)",
                    "session_id": session_id
                })
            
            # ìµœì¢… ê²°ê³¼ ìƒì„±
            virtual_fitting_result = step_results.get("step_7", {})
            fitted_image = virtual_fitting_result.get("fitted_image")
            fit_score = virtual_fitting_result.get("fit_score", 0.95)
            
            total_time = time.time() - start_time
            
            return {
                "success": True,
                "message": "ì§„í–‰ë¥  ì¶”ì ê³¼ í•¨ê»˜ ê°€ìƒ í”¼íŒ… ì™„ë£Œ (Central Hub ê¸°ë°˜)",
                "session_id": session_id,
                "processing_time": total_time,
                "fitted_image": fitted_image,
                "fit_score": fit_score,
                "confidence": fit_score,
                "step_results": step_results,
                "progress_tracking_enabled": True,
                "central_hub_used": self.central_hub_container is not None,
                "timestamp": datetime.now().isoformat()
            }
            
        except Exception as e:
            if progress_callback:
                await progress_callback({
                    "step": "error",
                    "progress": -1,
                    "message": f"Central Hub ì˜¤ë¥˜ ë°œìƒ: {str(e)}",
                    "session_id": session_id,
                    "error": True
                })
            
            self.logger.error(f"âŒ ì§„í–‰ë¥  ì¶”ì  ê°€ìƒ í”¼íŒ… ì‹¤íŒ¨: {e}")
            return {
                "success": False,
                "error": str(e),
                "session_id": session_id,
                "processing_time": time.time() - start_time,
                "central_hub_used": self.central_hub_container is not None,
                "timestamp": datetime.now().isoformat()
            }
    
    # ==============================================
    # ðŸ”¥ ì„¸ì…˜ ê´€ë¦¬ ë° ìºì‹œ ë©”ì„œë“œë“¤ (Central Hub ê¸°ë°˜)
    # ==============================================
    
    def get_session_info(self, session_id: str) -> Dict[str, Any]:
        """ì„¸ì…˜ ì •ë³´ ì¡°íšŒ (Central Hub ê¸°ë°˜)"""
        try:
            if session_id not in self.sessions:
                return {
                    "exists": False,
                    "error": f"ì„¸ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {session_id}"
                }
            
            session_data = self.sessions[session_id]
            current_time = datetime.now()
            created_at = session_data.get('created_at', current_time)
            
            return {
                "exists": True,
                "session_id": session_id,
                "created_at": created_at.isoformat(),
                "age_seconds": (current_time - created_at).total_seconds(),
                "has_person_image": 'person_image' in session_data,
                "has_clothing_image": 'clothing_image' in session_data,
                "has_measurements": 'measurements' in session_data,
                "completed_steps": [
                    key for key in session_data.keys() 
                    if key.endswith('_result') and session_data[key].get('success', False)
                ],
                "data_keys": list(session_data.keys()),
                "memory_size_bytes": sys.getsizeof(session_data),
                "central_hub_session": session_data.get('central_hub_session', False)
            }
            
        except Exception as e:
            return {
                "exists": False,
                "error": str(e),
                "session_id": session_id
            }
    
    def clear_session(self, session_id: str) -> Dict[str, Any]:
        """íŠ¹ì • ì„¸ì…˜ ì •ë¦¬ (Central Hub ê¸°ë°˜)"""
        try:
            if session_id not in self.sessions:
                return {
                    "success": False,
                    "error": f"ì„¸ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {session_id}"
                }
            
            session_data = self.sessions[session_id]
            memory_size = sys.getsizeof(session_data)
            
            del self.sessions[session_id]
            
            return {
                "success": True,
                "session_id": session_id,
                "memory_freed_bytes": memory_size,
                "central_hub_cleanup": True,
                "timestamp": datetime.now().isoformat()
            }
            
        except Exception as e:
            return {
                "success": False,
                "error": str(e),
                "session_id": session_id
            }
    
    def clear_all_sessions(self) -> Dict[str, Any]:
        """ëª¨ë“  ì„¸ì…˜ ì •ë¦¬ (Central Hub ê¸°ë°˜)"""
        try:
            session_count = len(self.sessions)
            total_memory = sum(sys.getsizeof(data) for data in self.sessions.values())
            
            self.sessions.clear()
            
            # Central Hub ë©”ëª¨ë¦¬ ìµœì í™”
            if self.central_hub_container and hasattr(self.central_hub_container, 'optimize_memory'):
                optimization_result = self.central_hub_container.optimize_memory()
                self.logger.debug(f"Central Hub ë©”ëª¨ë¦¬ ìµœì í™”: {optimization_result}")
            
            return {
                "success": True,
                "sessions_cleared": session_count,
                "memory_freed_bytes": total_memory,
                "central_hub_optimized": True,
                "timestamp": datetime.now().isoformat()
            }
            
        except Exception as e:
            return {
                "success": False,
                "error": str(e),
                "timestamp": datetime.now().isoformat()
            }
    
    def get_all_sessions_info(self) -> Dict[str, Any]:
        """ëª¨ë“  ì„¸ì…˜ ì •ë³´ ì¡°íšŒ (Central Hub ê¸°ë°˜)"""
        try:
            sessions_info = {}
            total_memory = 0
            current_time = datetime.now()
            
            for session_id, session_data in self.sessions.items():
                created_at = session_data.get('created_at', current_time)
                memory_size = sys.getsizeof(session_data)
                total_memory += memory_size
                
                sessions_info[session_id] = {
                    "created_at": created_at.isoformat(),
                    "age_seconds": (current_time - created_at).total_seconds(),
                    "memory_size_bytes": memory_size,
                    "data_keys": list(session_data.keys()),
                    "central_hub_session": session_data.get('central_hub_session', False)
                }
            
            return {
                "total_sessions": len(self.sessions),
                "total_memory_bytes": total_memory,
                "sessions": sessions_info,
                "central_hub_management": True,
                "timestamp": datetime.now().isoformat()
            }
            
        except Exception as e:
            return {
                "error": str(e),
                "timestamp": datetime.now().isoformat()
            }
    
    # ==============================================
    # ðŸ”¥ ë©”ëª¨ë¦¬ ë° ì„±ëŠ¥ ê´€ë¦¬ ë©”ì„œë“œë“¤ (Central Hub ê¸°ë°˜)
    # ==============================================
    
    async def optimize_memory_usage(self, force_cleanup: bool = False) -> Dict[str, Any]:
        """ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ìµœì í™” (Central Hub ê¸°ë°˜)"""
        try:
            memory_before = self._get_memory_usage()
            
            # ì˜¤ëž˜ëœ ì„¸ì…˜ ì •ë¦¬
            current_time = datetime.now()
            old_sessions = []
            
            for session_id, session_data in list(self.sessions.items()):
                session_age = (current_time - session_data.get('created_at', current_time)).total_seconds()
                if session_age > 3600 or force_cleanup:  # 1ì‹œê°„ ì´ìƒ ëœ ì„¸ì…˜
                    old_sessions.append(session_id)
                    del self.sessions[session_id]
            
            # Central Hub ë©”ëª¨ë¦¬ ìµœì í™”
            central_hub_optimization = {}
            if self.central_hub_container and hasattr(self.central_hub_container, 'optimize_memory'):
                central_hub_optimization = self.central_hub_container.optimize_memory()
                self.logger.info(f"ðŸ’¾ Central Hub ë©”ëª¨ë¦¬ ìµœì í™”: {central_hub_optimization}")
            
            # StepFactory ìºì‹œ ì •ë¦¬
            step_factory_cleanup = False
            if self.step_factory and hasattr(self.step_factory, 'clear_cache'):
                self.step_factory.clear_cache()
                step_factory_cleanup = True
                self.logger.info("ðŸ—‘ï¸ StepFactory ìºì‹œ ì •ë¦¬ ì™„ë£Œ")
            
            # M3 Max ë©”ëª¨ë¦¬ ìµœì í™”
            await self._optimize_memory()
            
            memory_after = self._get_memory_usage()
            memory_saved = memory_before - memory_after
            
            return {
                "success": True,
                "memory_before_mb": memory_before,
                "memory_after_mb": memory_after,
                "memory_saved_mb": memory_saved,
                "sessions_cleaned": len(old_sessions),
                "force_cleanup": force_cleanup,
                "central_hub_optimized": bool(central_hub_optimization),
                "central_hub_optimization_details": central_hub_optimization,
                "step_factory_cache_cleared": step_factory_cleanup,
                "timestamp": datetime.now().isoformat()
            }
            
        except Exception as e:
            self.logger.error(f"âŒ ë©”ëª¨ë¦¬ ìµœì í™” ì‹¤íŒ¨: {e}")
            return {
                "success": False,
                "error": str(e),
                "timestamp": datetime.now().isoformat()
            }
    
    def _get_memory_usage(self) -> float:
        """í˜„ìž¬ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¡°íšŒ (MB)"""
        try:
            import psutil
            process = psutil.Process()
            return process.memory_info().rss / 1024 / 1024
        except ImportError:
            return 0.0
        except Exception:
            return 0.0
    
    async def get_performance_metrics(self) -> Dict[str, Any]:
        """ì„±ëŠ¥ ë©”íŠ¸ë¦­ ìƒì„¸ ì¡°íšŒ (Central Hub ê¸°ë°˜)"""
        try:
            with self._lock:
                metrics = {
                    "service_metrics": {
                        "total_requests": self.total_requests,
                        "successful_requests": self.successful_requests,
                        "failed_requests": self.failed_requests,
                        "success_rate": (self.successful_requests / max(1, self.total_requests)) * 100,
                        "average_processing_time": sum(self.processing_times) / max(1, len(self.processing_times)),
                        "min_processing_time": min(self.processing_times) if self.processing_times else 0,
                        "max_processing_time": max(self.processing_times) if self.processing_times else 0,
                        "last_error": self.last_error
                    },
                    
                    "central_hub_metrics": self.central_hub_metrics.copy(),
                    
                    "session_metrics": {
                        "active_sessions": len(self.sessions),
                        "session_ages": self._get_session_ages(),
                        "memory_usage_mb": self._get_memory_usage()
                    },
                    
                    "system_metrics": {
                        "status": self.status.value,
                        "processing_mode": self.processing_mode.value,
                        "uptime_seconds": (datetime.now() - self.start_time).total_seconds(),
                        "device": DEVICE,
                        "conda_optimized": CONDA_INFO['is_target_env'],
                        "m3_max_optimized": IS_M3_MAX
                    },
                    
                    "central_hub_info": {
                        "available": self.central_hub_container is not None,
                        "step_factory_available": self.step_factory is not None,
                        "version": "v7.0"
                    },
                    
                    "timestamp": datetime.now().isoformat()
                }
            
            # Central Hub í†µê³„ ì¶”ê°€
            if self.central_hub_container and hasattr(self.central_hub_container, 'get_stats'):
                try:
                    central_hub_stats = self.central_hub_container.get_stats()
                    metrics["central_hub_stats"] = central_hub_stats
                except Exception as e:
                    metrics["central_hub_stats"] = {"error": str(e)}
            
            # StepFactory í†µê³„ ì¶”ê°€
            if self.step_factory and hasattr(self.step_factory, 'get_statistics'):
                try:
                    step_factory_stats = self.step_factory.get_statistics()
                    metrics["step_factory_stats"] = step_factory_stats
                except Exception as e:
                    metrics["step_factory_stats"] = {"error": str(e)}
            
            return metrics
            
        except Exception as e:
            self.logger.error(f"âŒ ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {
                "error": str(e),
                "timestamp": datetime.now().isoformat()
            }
    
    def _get_session_ages(self) -> List[float]:
        """ì„¸ì…˜ ë‚˜ì´ ëª©ë¡ (ì´ˆ ë‹¨ìœ„)"""
        try:
            current_time = datetime.now()
            ages = []
            for session_data in self.sessions.values():
                created_at = session_data.get('created_at', current_time)
                age = (current_time - created_at).total_seconds()
                ages.append(age)
            return ages
        except Exception:
            return []
    
    # ==============================================
    # ðŸ”¥ ì„¤ì • ë° êµ¬ì„± ê´€ë¦¬ ë©”ì„œë“œë“¤ (Central Hub ê¸°ë°˜)
    # ==============================================
    
    def update_processing_mode(self, mode: Union[ProcessingMode, str]) -> Dict[str, Any]:
        """ì²˜ë¦¬ ëª¨ë“œ ì—…ë°ì´íŠ¸ (Central Hub ê¸°ë°˜)"""
        try:
            if isinstance(mode, str):
                mode = ProcessingMode(mode)
            
            old_mode = self.processing_mode
            self.processing_mode = mode
            
            self.logger.info(f"ðŸ”§ ì²˜ë¦¬ ëª¨ë“œ ë³€ê²½: {old_mode.value} â†’ {mode.value}")
            
            return {
                "success": True,
                "old_mode": old_mode.value,
                "new_mode": mode.value,
                "central_hub_integrated": True,
                "timestamp": datetime.now().isoformat()
            }
            
        except Exception as e:
            return {
                "success": False,
                "error": str(e),
                "current_mode": self.processing_mode.value,
                "timestamp": datetime.now().isoformat()
            }
    
    def get_configuration(self) -> Dict[str, Any]:
        """í˜„ìž¬ êµ¬ì„± ì¡°íšŒ (Central Hub ê¸°ë°˜)"""
        return {
            "service_status": self.status.value,
            "processing_mode": self.processing_mode.value,
            "central_hub_optimization": self.central_hub_optimization,
            "central_hub_available": self.central_hub_container is not None,
            "step_factory_available": self.step_factory is not None,
            "device": DEVICE,
            "conda_info": CONDA_INFO,
            "is_m3_max": IS_M3_MAX,
            "memory_gb": MEMORY_GB,
            "torch_available": TORCH_AVAILABLE,
            "numpy_available": NUMPY_AVAILABLE,
            "pil_available": PIL_AVAILABLE,
            "version": "v16.0_central_hub_integration",
            "timestamp": datetime.now().isoformat()
        }
    
    def validate_configuration(self) -> Dict[str, Any]:
        """êµ¬ì„± ê²€ì¦ (Central Hub ê¸°ë°˜)"""
        try:
            validation_result = {
                "valid": True,
                "warnings": [],
                "errors": [],
                "checks": {}
            }
            
            # Central Hub ê²€ì¦
            validation_result["checks"]["central_hub_available"] = self.central_hub_container is not None
            if not self.central_hub_container:
                validation_result["warnings"].append("Central Hub DI Container ì‚¬ìš© ë¶ˆê°€")
            
            # StepFactory ê²€ì¦
            validation_result["checks"]["step_factory_available"] = self.step_factory is not None
            if not self.step_factory:
                validation_result["errors"].append("StepFactory ì‚¬ìš© ë¶ˆê°€")
                validation_result["valid"] = False
            
            # conda í™˜ê²½ ê²€ì¦
            validation_result["checks"]["conda_optimized"] = CONDA_INFO['is_target_env']
            if not CONDA_INFO['is_target_env']:
                validation_result["warnings"].append("conda mycloset-ai-clean í™˜ê²½ì´ ì•„ë‹˜")
            
            # ë©”ëª¨ë¦¬ ê²€ì¦
            validation_result["checks"]["memory_sufficient"] = MEMORY_GB >= 16.0
            if MEMORY_GB < 16.0:
                validation_result["warnings"].append(f"ë©”ëª¨ë¦¬ ë¶€ì¡±: {MEMORY_GB:.1f}GB < 16GB")
            
            # ë¼ì´ë¸ŒëŸ¬ë¦¬ ê²€ì¦
            validation_result["checks"]["required_libraries"] = TORCH_AVAILABLE and NUMPY_AVAILABLE and PIL_AVAILABLE
            if not (TORCH_AVAILABLE and NUMPY_AVAILABLE and PIL_AVAILABLE):
                validation_result["errors"].append("í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ëˆ„ë½")
                validation_result["valid"] = False
            
            return validation_result
            
        except Exception as e:
            return {
                "valid": False,
                "error": str(e),
                "timestamp": datetime.now().isoformat()
            }
    
    # ==============================================
    # ðŸ”¥ ëª¨ë‹ˆí„°ë§ ë° ìƒíƒœ ì¡°íšŒ ë©”ì„œë“œë“¤ (Central Hub ê¸°ë°˜)
    # ==============================================
    
    async def health_check(self) -> Dict[str, Any]:
        """í—¬ìŠ¤ ì²´í¬ (Central Hub ê¸°ë°˜)"""
        try:
            # Central Hub ìƒíƒœ í™•ì¸
            central_hub_health = {
                "available": self.central_hub_container is not None,
                "services_count": 0,
                "statistics": {}
            }
            
            if self.central_hub_container:
                try:
                    if hasattr(self.central_hub_container, 'get_stats'):
                        central_hub_health["statistics"] = self.central_hub_container.get_stats()
                    
                    # í•µì‹¬ ì„œë¹„ìŠ¤ í™•ì¸
                    core_services = ['model_loader', 'memory_manager', 'data_converter']
                    available_services = 0
                    for service_key in core_services:
                        if self.central_hub_container.get(service_key):
                            available_services += 1
                    central_hub_health["services_count"] = available_services
                except Exception as e:
                    central_hub_health["error"] = str(e)
            
            # StepFactory ìƒíƒœ í™•ì¸
            step_factory_health = {
                "available": self.step_factory is not None,
                "statistics": {}
            }
            
            if self.step_factory:
                try:
                    if hasattr(self.step_factory, 'get_statistics'):
                        step_factory_health["statistics"] = self.step_factory.get_statistics()
                except Exception as e:
                    step_factory_health["error"] = str(e)
            
            health_status = {
                "healthy": (
                    self.status == ServiceStatus.ACTIVE and 
                    self.central_hub_container is not None and
                    self.step_factory is not None
                ),
                "status": self.status.value,
                "central_hub_health": central_hub_health,
                "step_factory_health": step_factory_health,
                "device": DEVICE,
                "conda_env": CONDA_INFO['conda_env'],
                "conda_optimized": CONDA_INFO['is_target_env'],
                "is_m3_max": IS_M3_MAX,
                "torch_available": TORCH_AVAILABLE,
                "components_status": {
                    "central_hub": self.central_hub_container is not None,
                    "step_factory": self.step_factory is not None,
                    "memory_management": True,
                    "session_management": True,
                    "device_acceleration": DEVICE != "cpu"
                },
                "version": "v16.0_central_hub_integration",
                "timestamp": datetime.now().isoformat()
            }
            
            return health_status
            
        except Exception as e:
            return {
                "healthy": False,
                "error": str(e),
                "central_hub_available": self.central_hub_container is not None,
                "timestamp": datetime.now().isoformat()
            }
    
    def get_status(self) -> Dict[str, Any]:
        """ì„œë¹„ìŠ¤ ìƒíƒœ ì¡°íšŒ (Central Hub ê¸°ë°˜)"""
        with self._lock:
            central_hub_status = {}
            if self.central_hub_container:
                try:
                    if hasattr(self.central_hub_container, 'get_stats'):
                        central_hub_stats = self.central_hub_container.get_stats()
                        central_hub_status = {
                            "available": True,
                            "version": "v7.0",
                            "type": "central_hub_di_container",
                            "statistics": central_hub_stats
                        }
                    else:
                        central_hub_status = {
                            "available": True,
                            "version": "v7.0",
                            "type": "central_hub_di_container"
                        }
                except Exception as e:
                    central_hub_status = {"available": False, "error": str(e)}
            else:
                central_hub_status = {"available": False, "reason": "not_connected"}
            
            step_factory_status = {}
            if self.step_factory:
                try:
                    if hasattr(self.step_factory, 'get_statistics'):
                        factory_stats = self.step_factory.get_statistics()
                        step_factory_status = {
                            "available": True,
                            "version": "v11.2",
                            "statistics": factory_stats
                        }
                    else:
                        step_factory_status = {
                            "available": True,
                            "version": "v11.2"
                        }
                except Exception as e:
                    step_factory_status = {"available": False, "error": str(e)}
            else:
                step_factory_status = {"available": False, "reason": "not_imported"}
            
            return {
                "status": self.status.value,
                "processing_mode": self.processing_mode.value,
                "total_requests": self.total_requests,
                "successful_requests": self.successful_requests,
                "failed_requests": self.failed_requests,
                "central_hub": central_hub_status,
                "step_factory": step_factory_status,
                "active_sessions": len(self.sessions),
                "version": "v16.0_central_hub_integration",
                "uptime_seconds": (datetime.now() - self.start_time).total_seconds(),
                "last_error": self.last_error,
                "timestamp": datetime.now().isoformat()
            }
    
    def get_supported_features(self) -> Dict[str, bool]:
        """ì§€ì›ë˜ëŠ” ê¸°ëŠ¥ ëª©ë¡ (Central Hub ê¸°ë°˜)"""
        return {
            "8_step_ai_pipeline": True,
            "central_hub_di_container_v7_0": self.central_hub_container is not None,
            "step_factory_v11_2": self.step_factory is not None,
            "automatic_dependency_injection": self.central_hub_container is not None,
            "api_mapping_support": True,
            "step_data_flow_support": True,
            "preprocessing_support": True,
            "postprocessing_support": True,
            "fastapi_integration": True,
            "memory_optimization": True,
            "session_management": True,
            "health_monitoring": True,
            "conda_optimization": CONDA_INFO['is_target_env'],
            "m3_max_optimization": IS_M3_MAX,
            "gpu_acceleration": DEVICE != "cpu",
            "step_pipeline_processing": self.step_factory is not None,
            "production_level_stability": True,
            "batch_processing": True,
            "scheduled_processing": True,
            "progress_tracking": True,
            "websocket_support": True,
            "real_time_processing": True,
            "circular_reference_free": True,
            "single_source_of_truth": self.central_hub_container is not None,
            "dependency_inversion": self.central_hub_container is not None
        }
    
    # ==============================================
    # ðŸ”¥ í†µê³„ ë° ë¶„ì„ ë©”ì„œë“œë“¤ (Central Hub ê¸°ë°˜)
    # ==============================================
    
    def get_usage_statistics(self, time_window_hours: int = 24) -> Dict[str, Any]:
        """ì‚¬ìš© í†µê³„ ì¡°íšŒ (Central Hub ê¸°ë°˜)"""
        try:
            current_time = datetime.now()
            window_start = current_time - timedelta(hours=time_window_hours)
            
            # ê°„ë‹¨í•œ í†µê³„ (ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ë” ì •êµí•œ ì‹œê³„ì—´ ë°ì´í„° í•„ìš”)
            statistics = {
                "time_window": {
                    "start": window_start.isoformat(),
                    "end": current_time.isoformat(),
                    "duration_hours": time_window_hours
                },
                
                "request_statistics": {
                    "total_requests": self.total_requests,
                    "successful_requests": self.successful_requests,
                    "failed_requests": self.failed_requests,
                    "success_rate": (self.successful_requests / max(1, self.total_requests)) * 100
                },
                
                "performance_statistics": {
                    "average_processing_time": sum(self.processing_times) / max(1, len(self.processing_times)),
                    "min_processing_time": min(self.processing_times) if self.processing_times else 0,
                    "max_processing_time": max(self.processing_times) if self.processing_times else 0,
                    "total_processing_time": sum(self.processing_times)
                },
                
                "central_hub_statistics": {
                    "total_step_creations": self.central_hub_metrics['total_step_creations'],
                    "successful_step_creations": self.central_hub_metrics['successful_step_creations'],
                    "central_hub_injections": self.central_hub_metrics['central_hub_injections'],
                    "ai_processing_calls": self.central_hub_metrics['ai_processing_calls']
                },
                
                "session_statistics": {
                    "current_active_sessions": len(self.sessions),
                    "average_session_age": sum(self._get_session_ages()) / max(1, len(self.sessions))
                },
                
                "central_hub_integration": {
                    "central_hub_available": self.central_hub_container is not None,
                    "step_factory_available": self.step_factory is not None,
                    "automatic_dependency_injection": self.central_hub_container is not None
                },
                
                "timestamp": datetime.now().isoformat()
            }
            
            return statistics
            
        except Exception as e:
            return {
                "error": str(e),
                "timestamp": datetime.now().isoformat()
            }
    
    def export_metrics_csv(self) -> str:
        """ë©”íŠ¸ë¦­ì„ CSV í˜•ì‹ìœ¼ë¡œ ë‚´ë³´ë‚´ê¸° (Central Hub ê¸°ë°˜)"""
        try:
            import csv
            from io import StringIO
            
            output = StringIO()
            writer = csv.writer(output)
            
            # í—¤ë”
            writer.writerow([
                "timestamp", "total_requests", "successful_requests", "failed_requests",
                "success_rate", "average_processing_time", "active_sessions", "memory_mb",
                "central_hub_available", "central_hub_injections", "ai_processing_calls"
            ])
            
            # ë°ì´í„°
            writer.writerow([
                datetime.now().isoformat(),
                self.total_requests,
                self.successful_requests,
                self.failed_requests,
                (self.successful_requests / max(1, self.total_requests)) * 100,
                sum(self.processing_times) / max(1, len(self.processing_times)),
                len(self.sessions),
                self._get_memory_usage(),
                self.central_hub_container is not None,
                self.central_hub_metrics['central_hub_injections'],
                self.central_hub_metrics['ai_processing_calls']
            ])
            
            return output.getvalue()
            
        except Exception as e:
            return f"CSV ë‚´ë³´ë‚´ê¸° ì‹¤íŒ¨: {str(e)}"
    
    def reset_metrics(self, confirm: bool = False) -> Dict[str, Any]:
        """ë©”íŠ¸ë¦­ ë¦¬ì…‹ (Central Hub ê¸°ë°˜)"""
        if not confirm:
            return {
                "success": False,
                "message": "ë©”íŠ¸ë¦­ ë¦¬ì…‹ì„ ìœ„í•´ì„œëŠ” confirm=True íŒŒë¼ë¯¸í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤",
                "warning": "ì´ ìž‘ì—…ì€ ëª¨ë“  í†µê³„ ë°ì´í„°ë¥¼ ì‚­ì œí•©ë‹ˆë‹¤"
            }
        
        try:
            with self._lock:
                old_stats = {
                    "total_requests": self.total_requests,
                    "successful_requests": self.successful_requests,
                    "failed_requests": self.failed_requests,
                    "processing_times_count": len(self.processing_times),
                    "central_hub_metrics": self.central_hub_metrics.copy()
                }
                
                # ë©”íŠ¸ë¦­ ë¦¬ì…‹
                self.total_requests = 0
                self.successful_requests = 0
                self.failed_requests = 0
                self.processing_times = []
                self.last_error = None
                
                # Central Hub ë©”íŠ¸ë¦­ ë¦¬ì…‹
                for key in self.central_hub_metrics:
                    self.central_hub_metrics[key] = 0
                
                # ì‹œìž‘ ì‹œê°„ ë¦¬ì…‹
                self.start_time = datetime.now()
            
            return {
                "success": True,
                "message": "ëª¨ë“  ë©”íŠ¸ë¦­ì´ ë¦¬ì…‹ë˜ì—ˆìŠµë‹ˆë‹¤ (Central Hub í¬í•¨)",
                "old_stats": old_stats,
                "reset_timestamp": datetime.now().isoformat()
            }
            
        except Exception as e:
            return {
                "success": False,
                "error": str(e),
                "timestamp": datetime.now().isoformat()
            }
    
    # ==============================================
    # ðŸ”¥ ì „ì²´ ë©”íŠ¸ë¦­ ì¡°íšŒ (Central Hub ì™„ì „ í†µí•©)
    # ==============================================
    
    def get_all_metrics(self) -> Dict[str, Any]:
        """ëª¨ë“  ë©”íŠ¸ë¦­ ì¡°íšŒ (Central Hub ì™„ì „ í†µí•©)"""
        try:
            with self._lock:
                avg_processing_time = (
                    sum(self.processing_times) / len(self.processing_times)
                    if self.processing_times else 0.0
                )
                
                success_rate = (
                    self.successful_requests / self.total_requests * 100
                    if self.total_requests > 0 else 0.0
                )
            
            # Central Hub ë©”íŠ¸ë¦­
            central_hub_metrics = {}
            if self.central_hub_container and hasattr(self.central_hub_container, 'get_stats'):
                try:
                    central_hub_metrics = self.central_hub_container.get_stats()
                except Exception as e:
                    central_hub_metrics = {"error": str(e), "available": False}
            
            # StepFactory ë©”íŠ¸ë¦­
            step_factory_metrics = {}
            if self.step_factory and hasattr(self.step_factory, 'get_statistics'):
                try:
                    step_factory_metrics = self.step_factory.get_statistics()
                except Exception as e:
                    step_factory_metrics = {"error": str(e), "available": False}
            
            return {
                "service_status": self.status.value,
                "processing_mode": self.processing_mode.value,
                "total_requests": self.total_requests,
                "successful_requests": self.successful_requests,
                "failed_requests": self.failed_requests,
                "success_rate": success_rate,
                "average_processing_time": avg_processing_time,
                "last_error": self.last_error,
                
                # ðŸ”¥ Central Hub DI Container í†µí•© ì •ë³´
                "central_hub": {
                    "available": self.central_hub_container is not None,
                    "version": "v7.0",
                    "type": "central_hub_di_container",
                    "metrics": central_hub_metrics,
                    "total_step_creations": self.central_hub_metrics['total_step_creations'],
                    "successful_step_creations": self.central_hub_metrics['successful_step_creations'],
                    "failed_step_creations": self.central_hub_metrics['failed_step_creations'],
                    "central_hub_injections": self.central_hub_metrics['central_hub_injections'],
                    "ai_processing_calls": self.central_hub_metrics['ai_processing_calls'],
                    "data_conversions": self.central_hub_metrics['data_conversions'],
                    "checkpoint_validations": self.central_hub_metrics['checkpoint_validations'],
                    "step_success_rate": (
                        self.central_hub_metrics['successful_step_creations'] / 
                        max(1, self.central_hub_metrics['total_step_creations']) * 100
                    )
                },
                
                # StepFactory ì •ë³´
                "step_factory": {
                    "available": self.step_factory is not None,
                    "version": "v11.2",
                    "metrics": step_factory_metrics
                },
                
                # Central Hub ê¸°ë°˜ 8ë‹¨ê³„ Step ë§¤í•‘ (ì¶”ê°€ 9-10ë‹¨ê³„ í¬í•¨)
                "supported_steps": {
                    "step_1_upload_validation": "ê¸°ë³¸ ê²€ì¦ + Central Hub",
                    "step_2_measurements_validation": "ê¸°ë³¸ ê²€ì¦ + Central Hub",
                    "step_3_human_parsing": "Central Hub â†’ StepFactory â†’ HumanParsingStep",
                    "step_4_pose_estimation": "Central Hub â†’ StepFactory â†’ PoseEstimationStep",
                    "step_5_clothing_analysis": "Central Hub â†’ StepFactory â†’ ClothSegmentationStep",
                    "step_6_geometric_matching": "Central Hub â†’ StepFactory â†’ GeometricMatchingStep",
                    "step_7_virtual_fitting": "Central Hub â†’ StepFactory â†’ VirtualFittingStep â­",
                    "step_8_result_analysis": "Central Hub â†’ StepFactory â†’ QualityAssessmentStep",
                    "step_9_cloth_warping": "Central Hub â†’ StepFactory â†’ ClothWarpingStep",
                    "step_10_post_processing": "Central Hub â†’ StepFactory â†’ PostProcessingStep",
                    "complete_pipeline": "Central Hub ì „ì²´ íŒŒì´í”„ë¼ì¸",
                    "batch_processing": True,
                    "scheduled_processing": True,
                    "progress_tracking": True
                },
                
                # í™˜ê²½ ì •ë³´ (Central Hub ìµœì í™”)
                "environment": {
                    "conda_env": CONDA_INFO['conda_env'],
                    "conda_optimized": CONDA_INFO['is_target_env'],
                    "device": DEVICE,
                    "is_m3_max": IS_M3_MAX,
                    "memory_gb": MEMORY_GB,
                    "torch_available": TORCH_AVAILABLE,
                    "numpy_available": NUMPY_AVAILABLE,
                    "pil_available": PIL_AVAILABLE,
                    "central_hub_available": self.central_hub_container is not None
                },
                
                # êµ¬ì¡° ì •ë³´
                "architecture": {
                    "service_version": "v16.0_central_hub_integration",
                    "central_hub_version": "v7.0",
                    "step_factory_version": "v11.2",
                    "base_step_mixin_version": "v20.0",
                    "flow": "step_routes.py â†’ StepServiceManager v16.0 â†’ Central Hub DI Container v7.0 â†’ StepFactory v11.2 â†’ BaseStepMixin v20.0 â†’ ì‹¤ì œ AI ëª¨ë¸",
                    "circular_reference_free": True,
                    "single_source_of_truth": True,
                    "dependency_inversion": True,
                    "production_ready": True
                },
                
                "uptime_seconds": (datetime.now() - self.start_time).total_seconds(),
                
                # í•µì‹¬ íŠ¹ì§• (Central Hub ê¸°ë°˜)
                "key_features": [
                    "Central Hub DI Container v7.0 ì™„ì „ ì—°ë™",
                    "ìˆœí™˜ì°¸ì¡° ì™„ì „ í•´ê²° (TYPE_CHECKING + ì§€ì—° import)",
                    "ë‹¨ë°©í–¥ ì˜ì¡´ì„± ê·¸ëž˜í”„ (Central Hub íŒ¨í„´)",
                    "Single Source of Truth - ëª¨ë“  ì„œë¹„ìŠ¤ëŠ” Central Hubë¥¼ ê±°ì¹¨",
                    "Dependency Inversion - ìƒìœ„ ëª¨ë“ˆì´ í•˜ìœ„ ëª¨ë“ˆì„ ì œì–´",
                    "ìžë™ ì˜ì¡´ì„± ì£¼ìž…ìœ¼ë¡œ ê°œë°œìž íŽ¸ì˜ì„± í–¥ìƒ",
                    "ê¸°ì¡´ API 100% í˜¸í™˜ì„± ìœ ì§€",
                    "ì ì§„ì  ë§ˆì´ê·¸ë ˆì´ì…˜ ì§€ì› (Central Hub ì—†ì´ë„ ë™ìž‘)",
                    "Central Hub ê¸°ë°˜ í†µí•© ë©”íŠ¸ë¦­ ë° ëª¨ë‹ˆí„°ë§",
                    "StepFactory v11.2ì™€ ì™„ì „ í˜¸í™˜",
                    "BaseStepMixin v20.0ì˜ Central Hub ê¸°ë°˜ êµ¬ì¡° ë°˜ì˜",
                    "conda í™˜ê²½ + M3 Max í•˜ë“œì›¨ì–´ ìµœì í™”",
                    "FastAPI ë¼ìš°í„° ì™„ì „ í˜¸í™˜",
                    "ì„¸ì…˜ ê¸°ë°˜ ì²˜ë¦¬",
                    "ë©”ëª¨ë¦¬ íš¨ìœ¨ì  ê´€ë¦¬",
                    "ì‹¤ì‹œê°„ í—¬ìŠ¤ ëª¨ë‹ˆí„°ë§",
                    "í”„ë¡œë•ì…˜ ë ˆë²¨ ì•ˆì •ì„±",
                    "ì¼ê´„ ì²˜ë¦¬ (Batch Processing)",
                    "ì˜ˆì•½ ì²˜ë¦¬ (Scheduled Processing)", 
                    "ì§„í–‰ë¥  ì¶”ì  (Progress Tracking)",
                    "WebSocket ì§€ì› ì¤€ë¹„",
                    "ì‹¤ì‹œê°„ ì²˜ë¦¬ ì§€ì›"
                ],
                
                "timestamp": datetime.now().isoformat()
            }
            
        except Exception as e:
            self.logger.error(f"âŒ ë©”íŠ¸ë¦­ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {
                "error": str(e),
                "version": "v16.0_central_hub_integration",
                "central_hub_available": self.central_hub_container is not None,
                "timestamp": datetime.now().isoformat()
            }


# ==============================================
# ðŸ”¥ ì‹±ê¸€í†¤ ê´€ë¦¬ (Central Hub ê¸°ë°˜)
# ==============================================

# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤ë“¤
_global_manager: Optional[StepServiceManager] = None
_manager_lock = threading.RLock()

def get_step_service_manager() -> StepServiceManager:
    """ì „ì—­ StepServiceManager ë°˜í™˜ (Central Hub ê¸°ë°˜)"""
    global _global_manager
    
    with _manager_lock:
        if _global_manager is None:
            _global_manager = StepServiceManager()
            logger.info("âœ… ì „ì—­ StepServiceManager v16.0 ìƒì„± ì™„ë£Œ (Central Hub ê¸°ë°˜)")
    
    return _global_manager

async def get_step_service_manager_async() -> StepServiceManager:
    """ì „ì—­ StepServiceManager ë°˜í™˜ (ë¹„ë™ê¸°, ì´ˆê¸°í™” í¬í•¨, Central Hub ê¸°ë°˜)"""
    manager = get_step_service_manager()
    
    if manager.status == ServiceStatus.INACTIVE:
        await manager.initialize()
        logger.info("âœ… StepServiceManager v16.0 ìžë™ ì´ˆê¸°í™” ì™„ë£Œ (Central Hub ê¸°ë°˜)")
    
    return manager

async def cleanup_step_service_manager():
    """ì „ì—­ StepServiceManager ì •ë¦¬ (Central Hub ê¸°ë°˜)"""
    global _global_manager
    
    with _manager_lock:
        if _global_manager:
            await _global_manager.cleanup()
            _global_manager = None
            logger.info("ðŸ§¹ ì „ì—­ StepServiceManager v16.0 ì •ë¦¬ ì™„ë£Œ (Central Hub ê¸°ë°˜)")

def reset_step_service_manager():
    """ì „ì—­ StepServiceManager ë¦¬ì…‹ (Central Hub ê¸°ë°˜)"""
    global _global_manager
    
    with _manager_lock:
        _global_manager = None
        
    logger.info("ðŸ”„ ì „ì—­ StepServiceManager v16.0 ë¦¬ì…‹ ì™„ë£Œ (Central Hub ê¸°ë°˜)")

# ==============================================
# ðŸ”¥ ê¸°ì¡´ í˜¸í™˜ì„± ë³„ì¹­ë“¤ (API í˜¸í™˜ì„± ìœ ì§€)
# ==============================================

# ê¸°ì¡´ API í˜¸í™˜ì„±ì„ ìœ„í•œ ë³„ì¹­ë“¤
def get_pipeline_service_sync() -> StepServiceManager:
    """íŒŒì´í”„ë¼ì¸ ì„œë¹„ìŠ¤ ë°˜í™˜ (ë™ê¸°) - ê¸°ì¡´ í˜¸í™˜ì„±"""
    return get_step_service_manager()

async def get_pipeline_service() -> StepServiceManager:
    """íŒŒì´í”„ë¼ì¸ ì„œë¹„ìŠ¤ ë°˜í™˜ (ë¹„ë™ê¸°) - ê¸°ì¡´ í˜¸í™˜ì„±"""
    return await get_step_service_manager_async()

def get_pipeline_manager_service() -> StepServiceManager:
    """íŒŒì´í”„ë¼ì¸ ë§¤ë‹ˆì € ì„œë¹„ìŠ¤ ë°˜í™˜ - ê¸°ì¡´ í˜¸í™˜ì„±"""
    return get_step_service_manager()

async def get_unified_service_manager() -> StepServiceManager:
    """í†µí•© ì„œë¹„ìŠ¤ ë§¤ë‹ˆì € ë°˜í™˜ - ê¸°ì¡´ í˜¸í™˜ì„±"""
    return await get_step_service_manager_async()

def get_unified_service_manager_sync() -> StepServiceManager:
    """í†µí•© ì„œë¹„ìŠ¤ ë§¤ë‹ˆì € ë°˜í™˜ (ë™ê¸°) - ê¸°ì¡´ í˜¸í™˜ì„±"""
    return get_step_service_manager()

# í´ëž˜ìŠ¤ ë³„ì¹­ë“¤
PipelineService = StepServiceManager
ServiceBodyMeasurements = BodyMeasurements
UnifiedStepServiceManager = StepServiceManager
StepService = StepServiceManager

# ==============================================
# ðŸ”¥ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤ (Central Hub ê¸°ë°˜)
# ==============================================

def get_service_availability_info() -> Dict[str, Any]:
    """ì„œë¹„ìŠ¤ ê°€ìš©ì„± ì •ë³´ (Central Hub ê¸°ë°˜)"""
    
    # Central Hub ê°€ìš©ì„± í™•ì¸
    central_hub_container = _get_central_hub_container()
    central_hub_availability = {}
    if central_hub_container:
        try:
            if hasattr(central_hub_container, 'get_stats'):
                hub_stats = central_hub_container.get_stats()
                central_hub_availability = {
                    "available": True,
                    "version": "v7.0",
                    "type": "central_hub_di_container",
                    "statistics": hub_stats
                }
            else:
                central_hub_availability = {
                    "available": True,
                    "version": "v7.0",
                    "type": "central_hub_di_container"
                }
        except Exception as e:
            central_hub_availability = {"available": False, "error": str(e)}
    else:
        central_hub_availability = {"available": False, "reason": "not_connected"}
    
    # StepFactory ê°€ìš©ì„± í™•ì¸
    step_factory = get_step_factory()
    step_factory_availability = {}
    if step_factory:
        try:
            if hasattr(step_factory, 'get_statistics'):
                factory_stats = step_factory.get_statistics()
                step_factory_availability = {
                    "available": True,
                    "version": "v11.2",
                    "statistics": factory_stats
                }
            else:
                step_factory_availability = {
                    "available": True,
                    "version": "v11.2"
                }
        except Exception as e:
            step_factory_availability = {"available": False, "error": str(e)}
    else:
        step_factory_availability = {"available": False, "reason": "not_imported"}
    
    return {
        "step_service_available": True,
        "central_hub_available": central_hub_container is not None,
        "step_factory_available": step_factory is not None,
        "services_available": True,
        "architecture": "StepServiceManager v16.0 â†’ Central Hub DI Container v7.0 â†’ StepFactory v11.2 â†’ BaseStepMixin v20.0 â†’ ì‹¤ì œ AI ëª¨ë¸",
        "version": "v16.0_central_hub_integration",
        
        # Central Hub ì •ë³´
        "central_hub_info": central_hub_availability,
        
        # StepFactory ì •ë³´
        "step_factory_info": step_factory_availability,
        
        # Central Hub ê¸°ë°˜ 8ë‹¨ê³„ Step ë§¤í•‘
        "step_mappings": {
            f"step_{step_id}": {
                "name": step_name,
                "available": step_factory is not None,
                "central_hub_based": True,
                "automatic_dependency_injection": central_hub_container is not None,
                "production_ready": True
            }
            for step_id, step_name in {
                1: "Upload Validation",
                2: "Measurements Validation", 
                3: "Human Parsing",
                4: "Pose Estimation",
                5: "Clothing Analysis",
                6: "Geometric Matching",
                7: "Virtual Fitting",
                8: "Result Analysis"
            }.items()
        },
        
        # Central Hub ì‹¤ì œ ê¸°ëŠ¥ ì§€ì›
        "complete_features": {
            "central_hub_di_container_v7_0": central_hub_container is not None,
            "step_factory_v11_2_integration": step_factory is not None,
            "automatic_dependency_injection": central_hub_container is not None,
            "circular_reference_free": True,
            "single_source_of_truth": central_hub_container is not None,
            "dependency_inversion": central_hub_container is not None,
            "api_mapping_support": True,
            "step_data_flow_support": True,
            "preprocessing_postprocessing": True,
            "fastapi_integration": True,
            "memory_optimization": True,
            "session_management": True,
            "health_monitoring": True,
            "conda_optimization": CONDA_INFO['is_target_env'],
            "m3_max_optimization": IS_M3_MAX,
            "gpu_acceleration": DEVICE != "cpu",
            "production_level_stability": True
        },
        
        # Central Hub ê¸°ë°˜ 8ë‹¨ê³„ íŒŒì´í”„ë¼ì¸ (ì¶”ê°€ 9-10ë‹¨ê³„ í¬í•¨)
        "ai_pipeline_steps": {
            "step_1_upload_validation": "ê¸°ë³¸ ê²€ì¦ (Central Hub ê¸°ë°˜)",
            "step_2_measurements_validation": "ê¸°ë³¸ ê²€ì¦ (Central Hub ê¸°ë°˜)",
            "step_3_human_parsing": "Central Hub â†’ StepFactory â†’ HumanParsingStep",
            "step_4_pose_estimation": "Central Hub â†’ StepFactory â†’ PoseEstimationStep",
            "step_5_clothing_analysis": "Central Hub â†’ StepFactory â†’ ClothSegmentationStep",
            "step_6_geometric_matching": "Central Hub â†’ StepFactory â†’ GeometricMatchingStep",
            "step_7_virtual_fitting": "Central Hub â†’ StepFactory â†’ VirtualFittingStep â­",
            "step_8_result_analysis": "Central Hub â†’ StepFactory â†’ QualityAssessmentStep",
            "step_9_cloth_warping": "Central Hub â†’ StepFactory â†’ ClothWarpingStep",
            "step_10_post_processing": "Central Hub â†’ StepFactory â†’ PostProcessingStep",
            "complete_pipeline": "Central Hub ì „ì²´ íŒŒì´í”„ë¼ì¸",
            "batch_processing": "ì¼ê´„ ê°€ìƒ í”¼íŒ… ì²˜ë¦¬ (Central Hub ê¸°ë°˜)",
            "scheduled_processing": "ì˜ˆì•½ëœ ê°€ìƒ í”¼íŒ… ì²˜ë¦¬ (Central Hub ê¸°ë°˜)",
            "progress_tracking": "ì§„í–‰ë¥  ì¶”ì  ê°€ìƒ í”¼íŒ… (Central Hub ê¸°ë°˜)"
        },
        
        # API í˜¸í™˜ì„± (ëª¨ë“  ê¸°ì¡´ ë©”ì„œë“œ í¬í•¨)
        "api_compatibility": {
            "process_step_1_upload_validation": True,
            "process_step_2_measurements_validation": True,
            "process_step_3_human_parsing": True,
            "process_step_4_pose_estimation": True,
            "process_step_5_clothing_analysis": True,
            "process_step_6_geometric_matching": True,
            "process_step_7_virtual_fitting": True,
            "process_step_8_result_analysis": True,
            "process_step_9_cloth_warping": True,  # ì¶”ê°€ ê¸°ëŠ¥
            "process_step_10_post_processing": True,  # ì¶”ê°€ ê¸°ëŠ¥
            "process_complete_virtual_fitting": True,
            "process_batch_virtual_fitting": True,
            "process_scheduled_virtual_fitting": True,
            "process_virtual_fitting_with_progress": True,
            "process_step_by_name": True,
            "validate_dependencies": True,
            "get_step_service_manager": True,
            "get_pipeline_service": True,
            "cleanup_step_service_manager": True,
            "health_check": True,
            "get_all_metrics": True,
            "get_recent_logs": True,  # ì¶”ê°€ ê¸°ëŠ¥
            "set_log_level": True,  # ì¶”ê°€ ê¸°ëŠ¥
            "run_system_test": True,  # ì¶”ê°€ ê¸°ëŠ¥
            "generate_debug_info": True,  # ì¶”ê°€ ê¸°ëŠ¥
            "optimize_memory_usage": True,
            "get_performance_metrics": True,
            "update_processing_mode": True,
            "get_configuration": True,
            "validate_configuration": True,
            "get_usage_statistics": True,
            "export_metrics_csv": True,
            "reset_metrics": True,
            "existing_function_names_preserved": True
        },
        
        # ì‹œìŠ¤í…œ ì •ë³´
        "system_info": {
            "conda_environment": CONDA_INFO['is_target_env'],
            "conda_env_name": CONDA_INFO['conda_env'],
            "device": DEVICE,
            "is_m3_max": IS_M3_MAX,
            "memory_gb": MEMORY_GB,
            "torch_available": TORCH_AVAILABLE,
            "python_version": sys.version,
            "platform": sys.platform,
            "central_hub_optimized": central_hub_container is not None
        },
        
        # í•µì‹¬ íŠ¹ì§• (Central Hub ê¸°ë°˜)
        "key_features": [
            "Central Hub DI Container v7.0 ì™„ì „ ì—°ë™",
            "ìˆœí™˜ì°¸ì¡° ì™„ì „ í•´ê²° (TYPE_CHECKING + ì§€ì—° import)",
            "ë‹¨ë°©í–¥ ì˜ì¡´ì„± ê·¸ëž˜í”„ (Central Hub íŒ¨í„´)",
            "Single Source of Truth - ëª¨ë“  ì„œë¹„ìŠ¤ëŠ” Central Hubë¥¼ ê±°ì¹¨",
            "Dependency Inversion - ìƒìœ„ ëª¨ë“ˆì´ í•˜ìœ„ ëª¨ë“ˆì„ ì œì–´",
            "ìžë™ ì˜ì¡´ì„± ì£¼ìž…ìœ¼ë¡œ ê°œë°œìž íŽ¸ì˜ì„± í–¥ìƒ",
            "ê¸°ì¡´ API 100% í˜¸í™˜ì„± ìœ ì§€",
            "ì ì§„ì  ë§ˆì´ê·¸ë ˆì´ì…˜ ì§€ì› (Central Hub ì—†ì´ë„ ë™ìž‘)",
            "Central Hub ê¸°ë°˜ í†µí•© ë©”íŠ¸ë¦­ ë° ëª¨ë‹ˆí„°ë§",
            "StepFactory v11.2ì™€ ì™„ì „ í˜¸í™˜",
            "BaseStepMixin v20.0ì˜ Central Hub ê¸°ë°˜ êµ¬ì¡° ë°˜ì˜",
            "conda í™˜ê²½ + M3 Max ìµœì í™”",
            "FastAPI ë¼ìš°í„° ì™„ì „ í˜¸í™˜",
            "í”„ë¡œë•ì…˜ ë ˆë²¨ ì•ˆì •ì„±",
            "ìŠ¤ë ˆë“œ ì•ˆì „ì„±",
            "ì‹¤ì‹œê°„ í—¬ìŠ¤ ëª¨ë‹ˆí„°ë§",
            "ì¼ê´„ ì²˜ë¦¬ (Batch Processing)",
            "ì˜ˆì•½ ì²˜ë¦¬ (Scheduled Processing)", 
            "ì§„í–‰ë¥  ì¶”ì  (Progress Tracking)",
            "WebSocket ì§€ì› ì¤€ë¹„",
            "ì‹¤ì‹œê°„ ì²˜ë¦¬ ì§€ì›"
        ]
    }

def format_api_response(
    success: bool,
    message: str,
    step_name: str,
    step_id: int,
    processing_time: float,
    session_id: Optional[str] = None,
    request_id: Optional[str] = None,
    confidence: Optional[float] = None,
    details: Optional[Dict[str, Any]] = None,
    error: Optional[str] = None,
    result_image: Optional[str] = None,
    fitted_image: Optional[str] = None,
    fit_score: Optional[float] = None,
    recommendations: Optional[List[str]] = None
) -> Dict[str, Any]:
    """API ì‘ë‹µ í˜•ì‹í™” (Central Hub ê¸°ë°˜)"""
    central_hub_container = _get_central_hub_container()
    
    response = {
        "success": success,
        "message": message,
        "step_name": step_name,
        "step_id": step_id,
        "session_id": session_id,
        "request_id": request_id,
        "processing_time": processing_time,
        "confidence": confidence or (0.85 + step_id * 0.02),
        "timestamp": datetime.now().isoformat(),
        "details": details or {},
        "error": error,
        "result_image": result_image,
        "fitted_image": fitted_image,
        "fit_score": fit_score,
        "recommendations": recommendations or [],
        "central_hub_used": central_hub_container is not None
    }
    
    # Central Hub ì •ë³´ ì¶”ê°€
    if central_hub_container:
        response["step_implementation_info"] = {
            "central_hub_version": "v7.0",
            "step_factory_version": "v11.2",
            "base_step_mixin_version": "v20.0",
            "automatic_dependency_injection": True,
            "circular_reference_free": True,
            "single_source_of_truth": True
        }
    
    return response

# ==============================================
# ðŸ”¥ ì§„ë‹¨ ë° ê²€ì¦ í•¨ìˆ˜ë“¤ (Central Hub ê¸°ë°˜)
# ==============================================

def diagnose_central_hub_service() -> Dict[str, Any]:
    """Central Hub ì „ì²´ ì‹œìŠ¤í…œ ì§„ë‹¨"""
    try:
        diagnosis = {
            "version": "v16.0_central_hub_integration",
            "timestamp": datetime.now().isoformat(),
            "overall_health": "unknown",
            
            # Central Hub ê²€ì¦
            "central_hub_validation": {
                "available": False,
                "version": "v7.0",
                "statistics": {},
                "services_count": 0
            },
            
            # StepFactory ê²€ì¦
            "step_factory_validation": {
                "available": False,
                "version": "v11.2",
                "statistics": {}
            },
            
            # í™˜ê²½ ê±´ê°•ë„
            "environment_health": {
                "conda_optimized": CONDA_INFO['is_target_env'],
                "conda_env_name": CONDA_INFO['conda_env'],
                "device_optimized": DEVICE != 'cpu',
                "device": DEVICE,
                "m3_max_available": IS_M3_MAX,
                "memory_sufficient": MEMORY_GB >= 16.0,
                "memory_gb": MEMORY_GB,
                "all_libraries_available": TORCH_AVAILABLE and NUMPY_AVAILABLE and PIL_AVAILABLE
            },
            
            # Central Hub ì»´í”Œë¼ì´ì–¸ìŠ¤
            "central_hub_compliance": {
                "circular_reference_free": True,
                "single_source_of_truth": False,
                "dependency_inversion": False,
                "automatic_dependency_injection": False,
                "api_compatibility_maintained": True,
                "function_names_preserved": True,
                "production_ready": True
            }
        }
        
        # Central Hub ê²€ì¦
        central_hub_container = _get_central_hub_container()
        if central_hub_container:
            diagnosis["central_hub_validation"]["available"] = True
            diagnosis["central_hub_compliance"]["single_source_of_truth"] = True
            diagnosis["central_hub_compliance"]["dependency_inversion"] = True
            diagnosis["central_hub_compliance"]["automatic_dependency_injection"] = True
            
            try:
                if hasattr(central_hub_container, 'get_stats'):
                    diagnosis["central_hub_validation"]["statistics"] = central_hub_container.get_stats()
                
                # í•µì‹¬ ì„œë¹„ìŠ¤ í™•ì¸
                core_services = ['model_loader', 'memory_manager', 'data_converter']
                available_services = 0
                for service_key in core_services:
                    if central_hub_container.get(service_key):
                        available_services += 1
                diagnosis["central_hub_validation"]["services_count"] = available_services
            except Exception as e:
                diagnosis["central_hub_validation"]["error"] = str(e)
        
        # StepFactory ê²€ì¦
        step_factory = get_step_factory()
        if step_factory:
            diagnosis["step_factory_validation"]["available"] = True
            try:
                if hasattr(step_factory, 'get_statistics'):
                    diagnosis["step_factory_validation"]["statistics"] = step_factory.get_statistics()
            except Exception as e:
                diagnosis["step_factory_validation"]["error"] = str(e)
        
        # ì „ë°˜ì ì¸ ê±´ê°•ë„ í‰ê°€
        health_score = 0
        
        # Central Hub ê²€ì¦ (40ì )
        if diagnosis["central_hub_validation"]["available"]:
            health_score += 20
        if diagnosis["central_hub_compliance"]["automatic_dependency_injection"]:
            health_score += 20
        
        # StepFactory ê²€ì¦ (20ì )
        if diagnosis["step_factory_validation"]["available"]:
            health_score += 20
        
        # í™˜ê²½ ìµœì í™” (40ì )
        if CONDA_INFO['is_target_env']:
            health_score += 10
        if DEVICE != 'cpu':
            health_score += 10
        if MEMORY_GB >= 16.0:
            health_score += 10
        if TORCH_AVAILABLE and NUMPY_AVAILABLE and PIL_AVAILABLE:
            health_score += 10
        
        if health_score >= 90:
            diagnosis['overall_health'] = 'excellent'
        elif health_score >= 70:
            diagnosis['overall_health'] = 'good'
        elif health_score >= 50:
            diagnosis['overall_health'] = 'warning'
        else:
            diagnosis['overall_health'] = 'critical'
        
        diagnosis['health_score'] = health_score
        
        return diagnosis
        
    except Exception as e:
        return {
            "overall_health": "error",
            "error": str(e),
            "version": "v16.0_central_hub_integration"
        }

def validate_central_hub_mappings() -> Dict[str, Any]:
    """Central Hub Step ë§¤í•‘ ê²€ì¦"""
    try:
        validation_result = {
            "valid": True,
            "errors": [],
            "warnings": [],
            "central_hub_available": False,
            "step_factory_available": False,
            "validation_details": {}
        }
        
        # Central Hub í™•ì¸
        central_hub_container = _get_central_hub_container()
        validation_result["central_hub_available"] = central_hub_container is not None
        
        if not central_hub_container:
            validation_result["warnings"].append("Central Hub DI Containerê°€ ì—†ìŠµë‹ˆë‹¤")
        
        # StepFactory í™•ì¸
        step_factory = get_step_factory()
        validation_result["step_factory_available"] = step_factory is not None
        
        if not step_factory:
            validation_result["errors"].append("StepFactoryê°€ ì‚¬ìš© ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤")
            validation_result["valid"] = False
        
        # ê°€ìƒ í”¼íŒ… Step íŠ¹ë³„ ê²€ì¦ (7ë‹¨ê³„ê°€ í•µì‹¬)
        if step_factory:
            try:
                # ìž„ì‹œ VirtualFittingStep ìƒì„± ì‹œë„
                if hasattr(step_factory, 'create_step'):
                    test_result = step_factory.create_step(6)  # VIRTUAL_FITTING
                    if hasattr(test_result, 'success') and test_result.success:
                        validation_result["validation_details"]["virtual_fitting_available"] = True
                    else:
                        validation_result["warnings"].append("VirtualFittingStep ìƒì„± í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨")
                        validation_result["validation_details"]["virtual_fitting_available"] = False
            except Exception as e:
                validation_result["warnings"].append(f"VirtualFittingStep í…ŒìŠ¤íŠ¸ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        
        validation_result["validation_details"] = {
            "central_hub_connected": validation_result["central_hub_available"],
            "step_factory_ready": validation_result["step_factory_available"],
            "automatic_dependency_injection": validation_result["central_hub_available"],
            "circular_reference_free": True,
            "single_source_of_truth": validation_result["central_hub_available"]
        }
        
        return validation_result
        
    except Exception as e:
        return {
            "valid": False,
            "error": str(e),
            "central_hub_available": False,
            "step_factory_available": False
        }

# í˜¸í™˜ì„± ë³„ì¹­ë“¤ (ê¸°ì¡´ ì½”ë“œ í˜¸í™˜ì„±)
diagnose_github_step_service = diagnose_central_hub_service
validate_github_step_mappings = validate_central_hub_mappings
diagnose_step_factory_service = diagnose_central_hub_service
validate_step_factory_mappings = validate_central_hub_mappings

def safe_mps_empty_cache():
    """ì•ˆì „í•œ M3 Max MPS ìºì‹œ ì •ë¦¬"""
    try:
        if TORCH_AVAILABLE and IS_M3_MAX:
            import torch
            if hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
                if hasattr(torch.backends.mps, 'empty_cache'):
                    torch.backends.mps.empty_cache()
                    logger.debug("ðŸŽ M3 Max MPS ìºì‹œ ì •ë¦¬ ì™„ë£Œ")
    except Exception as e:
        logger.debug(f"MPS ìºì‹œ ì •ë¦¬ ì‹¤íŒ¨ (ë¬´ì‹œ): {e}")

def optimize_conda_memory():
    """conda í™˜ê²½ ë©”ëª¨ë¦¬ ìµœì í™” (Central Hub ê¸°ë°˜)"""
    try:
        # Python GC
        gc.collect()
        
        # Central Hub ë©”ëª¨ë¦¬ ìµœì í™”
        central_hub_container = _get_central_hub_container()
        if central_hub_container and hasattr(central_hub_container, 'optimize_memory'):
            optimization_result = central_hub_container.optimize_memory()
            logger.debug(f"ðŸ’¾ Central Hub ë©”ëª¨ë¦¬ ìµœì í™”: {optimization_result}")
        
        # M3 Max MPS ë©”ëª¨ë¦¬ ì •ë¦¬
        safe_mps_empty_cache()
        
        # CUDA ë©”ëª¨ë¦¬ ì •ë¦¬
        if TORCH_AVAILABLE and DEVICE == "cuda":
            import torch
            torch.cuda.empty_cache()
            
        logger.debug("ðŸ’¾ conda ë©”ëª¨ë¦¬ ìµœì í™” ì™„ë£Œ")
    except Exception as e:
        logger.debug(f"conda ë©”ëª¨ë¦¬ ìµœì í™” ì‹¤íŒ¨ (ë¬´ì‹œ): {e}")

# ==============================================
# ðŸ”¥ Export ëª©ë¡ (ê¸°ì¡´ í˜¸í™˜ì„± ì™„ì „ ìœ ì§€)
# ==============================================

__all__ = [
    # ë©”ì¸ í´ëž˜ìŠ¤ë“¤ (ê¸°ì¡´ í˜¸í™˜ì„± ìœ ì§€)
    "StepServiceManager",
    
    # ë°ì´í„° êµ¬ì¡°ë“¤ (ê¸°ì¡´ í˜¸í™˜ì„± ìœ ì§€)
    "ProcessingMode",
    "ServiceStatus", 
    "ProcessingPriority",
    "BodyMeasurements",
    "ProcessingRequest",
    "ProcessingResult",
    
    # ì‹±ê¸€í†¤ í•¨ìˆ˜ë“¤ (ê¸°ì¡´ í˜¸í™˜ì„± ìœ ì§€)
    "get_step_service_manager",
    "get_step_service_manager_async", 
    "get_pipeline_service",
    "get_pipeline_service_sync",
    "get_pipeline_manager_service",
    "get_unified_service_manager",
    "get_unified_service_manager_sync",
    "cleanup_step_service_manager",
    "reset_step_service_manager",
    
    # ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤ (ê¸°ì¡´ í˜¸í™˜ì„± ìœ ì§€)
    "get_service_availability_info",
    "format_api_response",
    "safe_mps_empty_cache",
    "optimize_conda_memory",
    
    # ì§„ë‹¨ í•¨ìˆ˜ë“¤ (Central Hub ê¸°ë°˜)
    "diagnose_central_hub_service",
    "validate_central_hub_mappings",
    "diagnose_github_step_service",  # í˜¸í™˜ì„± ë³„ì¹­
    "validate_github_step_mappings",  # í˜¸í™˜ì„± ë³„ì¹­
    "diagnose_step_factory_service",  # í˜¸í™˜ì„± ë³„ì¹­
    "validate_step_factory_mappings",  # í˜¸í™˜ì„± ë³„ì¹­
    
    # í˜¸í™˜ì„± ë³„ì¹­ë“¤ (ê¸°ì¡´ í˜¸í™˜ì„± ìœ ì§€)
    "PipelineService",
    "ServiceBodyMeasurements",
    "UnifiedStepServiceManager",
    "StepService"
]

# ==============================================
# ðŸ”¥ ì´ˆê¸°í™” ë° ìµœì í™” (Central Hub ê¸°ë°˜)
# ==============================================

# conda í™˜ê²½ í™•ì¸ ë° ê¶Œìž¥
conda_status = "âœ…" if CONDA_INFO['is_target_env'] else "âš ï¸"
logger.info(f"{conda_status} conda í™˜ê²½: {CONDA_INFO['conda_env']}")

if not CONDA_INFO['is_target_env']:
    logger.warning("âš ï¸ conda í™˜ê²½ ê¶Œìž¥: conda activate mycloset-ai-clean")

# Central Hub ìƒíƒœ í™•ì¸
central_hub_container = _get_central_hub_container()
central_hub_status = "âœ…" if central_hub_container else "âŒ"
logger.info(f"{central_hub_status} Central Hub DI Container: {'ì‚¬ìš© ê°€ëŠ¥' if central_hub_container else 'ì‚¬ìš© ë¶ˆê°€'}")

if central_hub_container:
    try:
        if hasattr(central_hub_container, 'get_stats'):
            hub_stats = central_hub_container.get_stats()
            logger.info(f"ðŸ“Š Central Hub í†µê³„: {hub_stats}")
        
        # í•µì‹¬ ì„œë¹„ìŠ¤ í™•ì¸
        core_services = ['model_loader', 'memory_manager', 'data_converter']
        for service_key in core_services:
            service = central_hub_container.get(service_key)
            status = "âœ…" if service else "âŒ"
            logger.info(f"   {status} {service_key}")
    except Exception as e:
        logger.warning(f"âš ï¸ Central Hub í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {e}")

# StepFactory ìƒíƒœ í™•ì¸
step_factory = get_step_factory()
step_factory_status = "âœ…" if step_factory else "âŒ"
logger.info(f"{step_factory_status} StepFactory: {'ì‚¬ìš© ê°€ëŠ¥' if step_factory else 'ì‚¬ìš© ë¶ˆê°€'}")

if step_factory:
    try:
        if hasattr(step_factory, 'get_statistics'):
            factory_stats = step_factory.get_statistics()
            logger.info(f"ðŸ“Š StepFactory í†µê³„: {factory_stats}")
    except Exception as e:
        logger.warning(f"âš ï¸ StepFactory í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {e}")

# ==============================================
# ðŸ”¥ ì™„ë£Œ ë©”ì‹œì§€
# ==============================================

logger.info("ðŸ”¥ StepServiceManager v16.0 - Central Hub DI Container v7.0 ì™„ì „ ì—°ë™ ë¡œë“œ ì™„ë£Œ!")
logger.info(f"âœ… Central Hub: {'ì—°ë™ ì™„ë£Œ' if central_hub_container else 'ì‚¬ìš© ë¶ˆê°€'}")
logger.info(f"âœ… StepFactory: {'ì—°ë™ ì™„ë£Œ' if step_factory else 'ì‚¬ìš© ë¶ˆê°€'}")
logger.info("âœ… Central Hub DI Container v7.0 ì™„ì „ ì—°ë™")
logger.info("âœ… ìˆœí™˜ì°¸ì¡° ì™„ì „ í•´ê²° (TYPE_CHECKING + ì§€ì—° import)")
logger.info("âœ… ë‹¨ë°©í–¥ ì˜ì¡´ì„± ê·¸ëž˜í”„ (Central Hub íŒ¨í„´)")
logger.info("âœ… ê¸°ì¡´ 8ë‹¨ê³„ AI íŒŒì´í”„ë¼ì¸ API 100% ìœ ì§€")
logger.info("âœ… ëª¨ë“  í•¨ìˆ˜ëª…/í´ëž˜ìŠ¤ëª…/ë©”ì„œë“œëª… ì™„ì „ ë³´ì¡´")

logger.info("ðŸŽ¯ ìƒˆë¡œìš´ ì•„í‚¤í…ì²˜:")
logger.info("   step_routes.py â†’ StepServiceManager v16.0 â†’ Central Hub DI Container v7.0 â†’ StepFactory v11.2 â†’ BaseStepMixin v20.0 â†’ ì‹¤ì œ AI ëª¨ë¸")

logger.info("ðŸŽ¯ ê¸°ì¡´ API 100% í˜¸í™˜ (ì™„ì „ ë³´ì¡´):")
logger.info("   - process_step_1_upload_validation")
logger.info("   - process_step_2_measurements_validation") 
logger.info("   - process_step_3_human_parsing")
logger.info("   - process_step_4_pose_estimation")
logger.info("   - process_step_5_clothing_analysis")
logger.info("   - process_step_6_geometric_matching")
logger.info("   - process_step_7_virtual_fitting â­")
logger.info("   - process_step_8_result_analysis")
logger.info("   - process_complete_virtual_fitting")
logger.info("   - process_step_by_name")
logger.info("   - validate_dependencies")
logger.info("   - get_step_service_manager, get_pipeline_service ë“± ëª¨ë“  í•¨ìˆ˜")

logger.info("ðŸŽ¯ Central Hub ì²˜ë¦¬ íë¦„:")
logger.info("   1. StepServiceManager v16.0: ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ + ì„¸ì…˜ ê´€ë¦¬")
logger.info("   2. Central Hub DI Container v7.0: ì¤‘ì•™ ì§‘ì¤‘ì‹ ì˜ì¡´ì„± ê´€ë¦¬ + ìžë™ ì£¼ìž…")
logger.info("   3. StepFactory v11.2: Step ì¸ìŠ¤í„´ìŠ¤ ìƒì„±")
logger.info("   4. BaseStepMixin v20.0: Central Hub ê¸°ë°˜ ì˜ì¡´ì„± ê´€ë¦¬")
logger.info("   5. ì‹¤ì œ AI ëª¨ë¸: ì‹¤ì œ AI ì¶”ë¡ ")

logger.info("ðŸŽ¯ Central Hub í•µì‹¬ íŠ¹ì§•:")
logger.info("   - Single Source of Truth: ëª¨ë“  ì„œë¹„ìŠ¤ëŠ” Central Hubë¥¼ ê±°ì¹¨")
logger.info("   - Dependency Inversion: ìƒìœ„ ëª¨ë“ˆì´ í•˜ìœ„ ëª¨ë“ˆì„ ì œì–´")
logger.info("   - Zero Circular Reference: ìˆœí™˜ì°¸ì¡° ì›ì²œ ì°¨ë‹¨")
logger.info("   - Automatic Dependency Injection: ìžë™ ì˜ì¡´ì„± ì£¼ìž…")

# conda í™˜ê²½ ìžë™ ìµœì í™”
if CONDA_INFO['is_target_env']:
    optimize_conda_memory()
    logger.info("ðŸ conda í™˜ê²½ ìžë™ ìµœì í™” ì™„ë£Œ!")

    # Central Hub ë©”ëª¨ë¦¬ ìµœì í™” í™œìš©
    if central_hub_container and hasattr(central_hub_container, 'optimize_memory'):
        try:
            optimize_result = central_hub_container.optimize_memory()
            logger.info(f"ðŸ—ï¸ Central Hub ë©”ëª¨ë¦¬ ìµœì í™”: {optimize_result}")
        except Exception as e:
            logger.debug(f"Central Hub ë©”ëª¨ë¦¬ ìµœì í™” ì‹¤íŒ¨ (ë¬´ì‹œ): {e}")
else:
    logger.warning(f"âš ï¸ conda í™˜ê²½ì„ í™•ì¸í•˜ì„¸ìš”: conda activate mycloset-ai-clean")

# ì´ˆê¸° ë©”ëª¨ë¦¬ ìµœì í™” (M3 Max)
safe_mps_empty_cache()
gc.collect()
logger.info(f"ðŸ’¾ {DEVICE} ì´ˆê¸° ë©”ëª¨ë¦¬ ìµœì í™” ì™„ë£Œ!")

logger.info("=" * 80)
logger.info("ðŸš€ STEP SERVICE MANAGER v16.0 WITH CENTRAL HUB DI CONTAINER v7.0 READY! ðŸš€")
logger.info("=" * 80)