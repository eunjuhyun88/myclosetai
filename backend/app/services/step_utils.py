# backend/app/services/step_utils.py
"""
ğŸ› ï¸ MyCloset AI Step Utils Layer v2.0 - ì™„ì „í•œ ìœ í‹¸ë¦¬í‹° ë ˆì´ì–´
================================================================

âœ… unified_step_mapping.py ì™„ì „ í™œìš© - ì„¸ íŒŒì¼ í†µí•© ì§€ì›
âœ… BaseStepMixin ì™„ë²½ í˜¸í™˜ - logger ì†ì„± ë° ì´ˆê¸°í™” ê³¼ì •
âœ… ModelLoader ì™„ì „ ì—°ë™ - 89.8GB ì²´í¬í¬ì¸íŠ¸ í™œìš©
âœ… ì‹¤ì œ Step í´ë˜ìŠ¤ë“¤ê³¼ 100% í˜¸í™˜ - HumanParsingStep ë“±
âœ… step_service.py + step_implementations.py ê³µí†µ ì§€ì›
âœ… SessionManager, DI Container ì™„ì „ ì—°ë™
âœ… ì—ëŸ¬ ì²˜ë¦¬ ë° ë³µêµ¬ ì‹œìŠ¤í…œ
âœ… ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ë° ë©”ëª¨ë¦¬ ê´€ë¦¬
âœ… M3 Max 128GB ìµœì í™” + conda í™˜ê²½ ìš°ì„ 
âœ… ìˆœí™˜ì°¸ì¡° ì™„ì „ ë°©ì§€ - ë‹¨ë°©í–¥ ì˜ì¡´ì„±
âœ… í”„ë¡œë•ì…˜ ë ˆë²¨ ì•ˆì •ì„±

êµ¬ì¡°: step_service.py + step_implementations.py â†’ step_utils.py â†’ BaseStepMixin + AI Steps

Author: MyCloset AI Team
Date: 2025-07-21
Version: 2.0 (Complete Utils Layer)
"""

import logging
import asyncio
import time
import threading
import uuid
import base64
import json
import gc
import os
import sys
import weakref
import importlib
from typing import Dict, Any, Optional, List, Union, Tuple, Type, Callable, TYPE_CHECKING
from datetime import datetime
from pathlib import Path
from io import BytesIO
from dataclasses import dataclass, field
from functools import wraps, lru_cache
from enum import Enum
from concurrent.futures import ThreadPoolExecutor
from contextlib import asynccontextmanager

# ì•ˆì „í•œ íƒ€ì… íŒíŒ…
if TYPE_CHECKING:
    from fastapi import UploadFile
    import torch
    import numpy as np
    from PIL import Image

# ==============================================
# ğŸ”¥ í†µí•© ë§¤í•‘ ì‹œìŠ¤í…œ import (í•µì‹¬!)
# ==============================================

# í†µí•© ë§¤í•‘ ì„¤ì •
try:
    from .unified_step_mapping import (
        UNIFIED_STEP_CLASS_MAPPING,
        UNIFIED_SERVICE_CLASS_MAPPING,
        SERVICE_TO_STEP_MAPPING,
        STEP_TO_SERVICE_MAPPING,
        SERVICE_ID_TO_STEP_ID,
        STEP_ID_TO_SERVICE_ID,
        UnifiedStepSignature,
        UNIFIED_STEP_SIGNATURES,
        StepFactoryHelper,
        validate_step_compatibility,
        setup_conda_optimization,
        get_step_id_by_service_id,
        get_service_id_by_step_id,
        get_all_available_steps,
        get_all_available_services,
        get_system_compatibility_info
    )
    UNIFIED_MAPPING_AVAILABLE = True
    logger = logging.getLogger(__name__)
    logger.info("âœ… í†µí•© ë§¤í•‘ ì‹œìŠ¤í…œ import ì„±ê³µ")
except ImportError as e:
    UNIFIED_MAPPING_AVAILABLE = False
    logger = logging.getLogger(__name__)
    logger.error(f"âŒ í†µí•© ë§¤í•‘ ì‹œìŠ¤í…œ import ì‹¤íŒ¨: {e}")
    raise ImportError("í†µí•© ë§¤í•‘ ì‹œìŠ¤í…œì´ í•„ìš”í•©ë‹ˆë‹¤. unified_step_mapping.pyë¥¼ í™•ì¸í•˜ì„¸ìš”.")

# ==============================================
# ğŸ”¥ ì•ˆì „í•œ Import ì‹œìŠ¤í…œ
# ==============================================

# NumPy import
try:
    import numpy as np
    NUMPY_AVAILABLE = True
except ImportError:
    NUMPY_AVAILABLE = False

# PIL import
try:
    from PIL import Image
    PIL_AVAILABLE = True
except ImportError:
    PIL_AVAILABLE = False

# PyTorch import
try:
    import torch
    TORCH_AVAILABLE = True
    
    if torch.backends.mps.is_available():
        DEVICE = "mps"
        IS_M3_MAX = True
    elif torch.cuda.is_available():
        DEVICE = "cuda"
        IS_M3_MAX = False
    else:
        DEVICE = "cpu"
        IS_M3_MAX = False
except ImportError:
    TORCH_AVAILABLE = False
    DEVICE = "cpu"
    IS_M3_MAX = False

# DI Container import
try:
    from ..core.di_container import DIContainer, get_di_container
    DI_CONTAINER_AVAILABLE = True
    logger.info("âœ… DI Container import ì„±ê³µ")
except ImportError:
    DI_CONTAINER_AVAILABLE = False
    logger.warning("âš ï¸ DI Container import ì‹¤íŒ¨")
    
    class DIContainer:
        def __init__(self):
            self._services = {}
        
        def get(self, service_name: str) -> Any:
            return self._services.get(service_name)
        
        def register(self, service_name: str, service: Any):
            self._services[service_name] = service
    
    def get_di_container() -> DIContainer:
        return DIContainer()

# Session Manager import
try:
    from ..core.session_manager import SessionManager, get_session_manager
    SESSION_MANAGER_AVAILABLE = True
    logger.info("âœ… Session Manager import ì„±ê³µ")
except ImportError:
    SESSION_MANAGER_AVAILABLE = False
    logger.warning("âš ï¸ Session Manager import ì‹¤íŒ¨")
    
    class SessionManager:
        def __init__(self):
            self.sessions = {}
        
        async def get_session_images(self, session_id: str):
            return None, None
        
        async def store_session_data(self, session_id: str, data: Dict[str, Any]):
            pass
    
    def get_session_manager() -> SessionManager:
        return SessionManager()

# ModelLoader import (í•µì‹¬!)
try:
    from ..ai_pipeline.utils.model_loader import ModelLoader, get_global_model_loader
    MODEL_LOADER_AVAILABLE = True
    logger.info("âœ… ModelLoader import ì„±ê³µ")
except ImportError:
    MODEL_LOADER_AVAILABLE = False
    logger.warning("âš ï¸ ModelLoader import ì‹¤íŒ¨")
    
    class ModelLoader:
        def create_step_interface(self, step_name: str):
            return None
        
        def load_model(self, model_name: str):
            return None
    
    def get_global_model_loader() -> Optional[ModelLoader]:
        return None

# ìŠ¤í‚¤ë§ˆ import
try:
    from ..models.schemas import BodyMeasurements
    SCHEMAS_AVAILABLE = True
    logger.info("âœ… ìŠ¤í‚¤ë§ˆ import ì„±ê³µ")
except ImportError:
    SCHEMAS_AVAILABLE = False
    logger.warning("âš ï¸ ìŠ¤í‚¤ë§ˆ import ì‹¤íŒ¨")
    
    @dataclass
    class BodyMeasurements:
        height: float
        weight: float
        chest: Optional[float] = None
        waist: Optional[float] = None
        hips: Optional[float] = None

# ==============================================
# ğŸ”¥ ì—ëŸ¬ ì •ì˜ ë° í•¸ë“¤ë§ ì‹œìŠ¤í…œ
# ==============================================

class StepUtilsError(Exception):
    """Step Utils ê¸°ë³¸ ì—ëŸ¬"""
    pass

class SessionError(StepUtilsError):
    """ì„¸ì…˜ ê´€ë ¨ ì—ëŸ¬"""
    pass

class ImageProcessingError(StepUtilsError):
    """ì´ë¯¸ì§€ ì²˜ë¦¬ ì—ëŸ¬"""
    pass

class MemoryError(StepUtilsError):
    """ë©”ëª¨ë¦¬ ê´€ë¦¬ ì—ëŸ¬"""
    pass

class StepInstanceError(StepUtilsError):
    """Step ì¸ìŠ¤í„´ìŠ¤ ì—ëŸ¬"""
    pass

class StepErrorHandler:
    """í†µí•© ì—ëŸ¬ í•¸ë“¤ëŸ¬"""
    
    def __init__(self):
        self.logger = logging.getLogger(f"{__name__}.StepErrorHandler")
        self.error_counts = {}
        self.recovery_strategies = {}
        self._lock = threading.RLock()
    
    def handle_error(self, error: Exception, context: Dict[str, Any] = None) -> Dict[str, Any]:
        """ì—ëŸ¬ ì²˜ë¦¬ ë° ë³µêµ¬ ì „ëµ"""
        try:
            with self._lock:
                error_type = type(error).__name__
                self.error_counts[error_type] = self.error_counts.get(error_type, 0) + 1
                
                error_info = {
                    "error_type": error_type,
                    "error_message": str(error),
                    "error_count": self.error_counts[error_type],
                    "context": context or {},
                    "timestamp": datetime.now().isoformat(),
                    "recovery_suggested": False,
                    "recovery_strategy": None
                }
                
                # ë³µêµ¬ ì „ëµ ê²°ì •
                if isinstance(error, SessionError):
                    error_info.update({
                        "recovery_suggested": True,
                        "recovery_strategy": "session_reload"
                    })
                elif isinstance(error, ImageProcessingError):
                    error_info.update({
                        "recovery_suggested": True,
                        "recovery_strategy": "image_fallback"
                    })
                elif isinstance(error, MemoryError):
                    error_info.update({
                        "recovery_suggested": True,
                        "recovery_strategy": "memory_cleanup"
                    })
                elif isinstance(error, StepInstanceError):
                    error_info.update({
                        "recovery_suggested": True,
                        "recovery_strategy": "instance_recreate"
                    })
                
                self.logger.error(f"âŒ ì—ëŸ¬ ì²˜ë¦¬: {error_type} - {str(error)}")
                if error_info["recovery_suggested"]:
                    self.logger.info(f"ğŸ”§ ë³µêµ¬ ì „ëµ: {error_info['recovery_strategy']}")
                
                return error_info
                
        except Exception as e:
            self.logger.error(f"âŒ ì—ëŸ¬ í•¸ë“¤ëŸ¬ ìì²´ ì˜¤ë¥˜: {e}")
            return {
                "error_type": "ErrorHandlerFailure",
                "error_message": str(e),
                "original_error": str(error),
                "recovery_suggested": False
            }
        
    
    def get_error_summary(self) -> Dict[str, Any]:
        """ì—ëŸ¬ ìš”ì•½"""
        with self._lock:
            return {
                "total_errors": sum(self.error_counts.values()),
                "error_types": dict(self.error_counts),
                "most_common_error": max(self.error_counts.items(), key=lambda x: x[1]) if self.error_counts else None
            }
# backend/app/services/step_utils.py ë˜ëŠ” ê´€ë ¨ íŒŒì¼ì— ì¶”ê°€

def safe_mps_empty_cache():
    """M3 Max MPS ìºì‹œ ì•ˆì „ ì •ë¦¬"""
    try:
        import torch
        import gc
        
        # ì¼ë°˜ ê°€ë¹„ì§€ ì»¬ë ‰ì…˜
        gc.collect()
        
        # M3 Max MPS ìºì‹œ ì •ë¦¬ ì‹œë„
        if hasattr(torch, 'mps') and torch.mps.is_available():
            try:
                # PyTorch 2.1+ ë°©ì‹
                if hasattr(torch.mps, 'empty_cache'):
                    torch.mps.empty_cache()
                    return {"success": True, "method": "torch.mps.empty_cache"}
                
                # PyTorch 2.0 ë°©ì‹
                elif hasattr(torch.backends.mps, 'empty_cache'):
                    torch.backends.mps.empty_cache()
                    return {"success": True, "method": "torch.backends.mps.empty_cache"}
                
                # ë™ê¸°í™”ë§Œ ìˆ˜í–‰
                elif hasattr(torch.mps, 'synchronize'):
                    torch.mps.synchronize()
                    return {"success": True, "method": "torch.mps.synchronize"}
                
            except (AttributeError, RuntimeError) as e:
                # MPS ìºì‹œ ì •ë¦¬ ì‹¤íŒ¨ ì‹œ ì¼ë°˜ ì •ë¦¬ë§Œ
                return {"success": True, "method": "gc_only", "warning": str(e)}
        
        # CUDA ì‚¬ìš© ì‹œ
        elif hasattr(torch, 'cuda') and torch.cuda.is_available():
            torch.cuda.empty_cache()
            return {"success": True, "method": "cuda_empty_cache"}
        
        # CPUë§Œ ì‚¬ìš© ì‹œ
        return {"success": True, "method": "gc_only"}
        
    except Exception as e:
        # ëª¨ë“  ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ë§Œ
        import gc
        gc.collect()
        return {"success": True, "method": "fallback_gc", "error": str(e)}

# MemoryHelper í´ë˜ìŠ¤ ìˆ˜ì •
class MemoryHelper:
    @staticmethod
    def optimize_memory():
        """ë©”ëª¨ë¦¬ ìµœì í™” - conda í™˜ê²½ ê³ ë ¤"""
        try:
            result = safe_mps_empty_cache()
            if result["success"]:
                return result
            else:
                raise MemoryError(f"ë©”ëª¨ë¦¬ ìµœì í™” ì‹¤íŒ¨: {result.get('error', 'Unknown')}")
        except Exception as e:
            # í´ë°±: ê¸°ë³¸ ê°€ë¹„ì§€ ì»¬ë ‰ì…˜
            import gc
            gc.collect()
            return {"success": True, "method": "fallback", "warning": str(e)}

# StepErrorHandler í´ë˜ìŠ¤ì— ì¶”ê°€
class StepErrorHandler:
    @staticmethod
    def handle_memory_error(error):
        """ë©”ëª¨ë¦¬ ì˜¤ë¥˜ ì²˜ë¦¬"""
        try:
            # ì•ˆì „í•œ ë©”ëª¨ë¦¬ ì •ë¦¬
            result = safe_mps_empty_cache()
            return {
                "handled": True,
                "method": result.get("method", "unknown"),
                "original_error": str(error)
            }
        except Exception as e:
            return {
                "handled": False,
                "error": str(e),
                "original_error": str(error)
            }
# ì „ì—­ ì—ëŸ¬ í•¸ë“¤ëŸ¬
_global_error_handler: Optional[StepErrorHandler] = None
_error_handler_lock = threading.RLock()

def get_error_handler() -> StepErrorHandler:
    """ì „ì—­ ì—ëŸ¬ í•¸ë“¤ëŸ¬ ë°˜í™˜"""
    global _global_error_handler
    
    with _error_handler_lock:
        if _global_error_handler is None:
            _global_error_handler = StepErrorHandler()
    
    return _global_error_handler

def handle_error(self, error: Exception, context: Dict[str, Any] = None) -> Dict[str, Any]:
    """ì—ëŸ¬ ì²˜ë¦¬ ë©”ì„œë“œ (ëˆ„ë½ëœ ë©”ì„œë“œ ì¶”ê°€)"""
    try:
        import traceback
        from datetime import datetime
        
        context = context or {}
        error_info = {
            "error_type": type(error).__name__,
            "error_message": str(error),
            "timestamp": datetime.now().isoformat(),
            "context": context,
            "traceback": traceback.format_exc() if hasattr(traceback, 'format_exc') else None
        }
        
        # ë¡œê¹…
        if hasattr(self, 'logger'):
            self.logger.error(f"âŒ ì—ëŸ¬ ì²˜ë¦¬: {error_info['error_type']}: {error_info['error_message']}")
        
        return error_info
        
    except Exception as e:
        # ìµœí›„ì˜ í´ë°±
        return {
            "error_type": "ErrorHandlerFailure",
            "error_message": f"ì—ëŸ¬ í•¸ë“¤ëŸ¬ ìì²´ ì‹¤íŒ¨: {str(e)}",
            "original_error": str(error),
            "timestamp": datetime.now().isoformat() if 'datetime' in locals() else "unknown",
            "context": context
        }
# ==============================================
# ğŸ”¥ ì„¸ì…˜ ê´€ë¦¬ í—¬í¼ (í†µí•© ë²„ì „)
# ==============================================

class SessionHelper:
    """í†µí•© ì„¸ì…˜ ê´€ë¦¬ í—¬í¼ - step_service.py + step_implementations.py ê³µí†µ ì§€ì›"""
    
    def __init__(self, session_manager: Optional[SessionManager] = None):
        self.session_manager = session_manager or (get_session_manager() if SESSION_MANAGER_AVAILABLE else SessionManager())
        self.logger = logging.getLogger(f"{__name__}.SessionHelper")
        self.session_cache = {}
        self._lock = threading.RLock()
    
    async def load_session_images(self, session_id: str) -> Tuple[Optional['Image.Image'], Optional['Image.Image']]:
        """ì„¸ì…˜ì—ì„œ ì´ë¯¸ì§€ ë¡œë“œ (ìºì‹± ì§€ì›)"""
        try:
            if not session_id:
                raise SessionError("session_idê°€ í•„ìš”í•©ë‹ˆë‹¤")
            
            # ìºì‹œ í™•ì¸
            with self._lock:
                if session_id in self.session_cache:
                    cached_data = self.session_cache[session_id]
                    if (time.time() - cached_data['timestamp']) < 300:  # 5ë¶„ ìºì‹œ
                        self.logger.debug(f"ì„¸ì…˜ ìºì‹œ íˆíŠ¸: {session_id}")
                        return cached_data['person_image'], cached_data['clothing_image']
            
            # ì„¸ì…˜ ë§¤ë‹ˆì €ì—ì„œ ë¡œë“œ
            person_img, clothing_img = await self.session_manager.get_session_images(session_id)
            
            # ì´ë¯¸ì§€ ê²€ì¦
            if person_img is None and clothing_img is None:
                self.logger.warning(f"âš ï¸ ì„¸ì…˜ {session_id}ì—ì„œ ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
                return None, None
            
            # ìºì‹œì— ì €ì¥
            with self._lock:
                self.session_cache[session_id] = {
                    'person_image': person_img,
                    'clothing_image': clothing_img,
                    'timestamp': time.time()
                }
                
                # ìºì‹œ í¬ê¸° ì œí•œ (ìµœëŒ€ 20ê°œ)
                if len(self.session_cache) > 20:
                    oldest_key = min(self.session_cache.keys(), 
                                   key=lambda k: self.session_cache[k]['timestamp'])
                    del self.session_cache[oldest_key]
            
            self.logger.debug(f"âœ… ì„¸ì…˜ ì´ë¯¸ì§€ ë¡œë“œ ì„±ê³µ: {session_id}")
            return person_img, clothing_img
            
        except Exception as e:
            error_handler = get_error_handler()
            error_info = error_handler.handle_error(
                SessionError(f"ì„¸ì…˜ ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {str(e)}"),
                {"session_id": session_id}
            )
            self.logger.error(f"âŒ ì„¸ì…˜ ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return None, None
    
    async def store_session_data(self, session_id: str, data: Dict[str, Any]) -> bool:
        """ì„¸ì…˜ ë°ì´í„° ì €ì¥"""
        try:
            if not session_id:
                raise SessionError("session_idê°€ í•„ìš”í•©ë‹ˆë‹¤")
            
            await self.session_manager.store_session_data(session_id, data)
            self.logger.debug(f"âœ… ì„¸ì…˜ ë°ì´í„° ì €ì¥ ì„±ê³µ: {session_id}")
            return True
            
        except Exception as e:
            error_handler = get_error_handler()
            error_handler.handle_error(
                SessionError(f"ì„¸ì…˜ ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {str(e)}"),
                {"session_id": session_id, "data_keys": list(data.keys()) if data else []}
            )
            self.logger.error(f"âŒ ì„¸ì…˜ ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {e}")
            return False
    
    def clear_session_cache(self, session_id: Optional[str] = None):
        """ì„¸ì…˜ ìºì‹œ ì •ë¦¬"""
        try:
            with self._lock:
                if session_id:
                    self.session_cache.pop(session_id, None)
                    self.logger.debug(f"ì„¸ì…˜ ìºì‹œ ì •ë¦¬: {session_id}")
                else:
                    self.session_cache.clear()
                    self.logger.debug("ëª¨ë“  ì„¸ì…˜ ìºì‹œ ì •ë¦¬")
        except Exception as e:
            self.logger.warning(f"ì„¸ì…˜ ìºì‹œ ì •ë¦¬ ì‹¤íŒ¨: {e}")
    
    def get_session_stats(self) -> Dict[str, Any]:
        """ì„¸ì…˜ í†µê³„"""
        with self._lock:
            return {
                "cached_sessions": len(self.session_cache),
                "session_manager_available": SESSION_MANAGER_AVAILABLE,
                "cache_enabled": True
            }

# ì „ì—­ ì„¸ì…˜ í—¬í¼
_global_session_helper: Optional[SessionHelper] = None
_session_helper_lock = threading.RLock()

def get_session_helper() -> SessionHelper:
    """ì „ì—­ ì„¸ì…˜ í—¬í¼ ë°˜í™˜"""
    global _global_session_helper
    
    with _session_helper_lock:
        if _global_session_helper is None:
            _global_session_helper = SessionHelper()
    
    return _global_session_helper

# ==============================================
# ğŸ”¥ ì´ë¯¸ì§€ ì²˜ë¦¬ í—¬í¼ (í†µí•© ë²„ì „)
# ==============================================

class ImageHelper:
    """í†µí•© ì´ë¯¸ì§€ ì²˜ë¦¬ í—¬í¼ - PIL, NumPy, Base64 ë“± ì§€ì›"""
    
    def __init__(self):
        self.logger = logging.getLogger(f"{__name__}.ImageHelper")
        self.supported_formats = ['JPEG', 'PNG', 'RGB', 'RGBA']
        self.max_image_size = (2048, 2048)  # ìµœëŒ€ ì´ë¯¸ì§€ í¬ê¸°
        self.min_image_size = (64, 64)      # ìµœì†Œ ì´ë¯¸ì§€ í¬ê¸°
    
    def validate_image_content(self, content: bytes, file_type: str) -> Dict[str, Any]:
        """ì´ë¯¸ì§€ íŒŒì¼ ë‚´ìš© ê²€ì¦ (step_service.py + step_implementations.py ê³µí†µ)"""
        try:
            if len(content) == 0:
                return {"valid": False, "error": f"{file_type} ì´ë¯¸ì§€: ë¹ˆ íŒŒì¼ì…ë‹ˆë‹¤"}
            
            if len(content) > 50 * 1024 * 1024:  # 50MB
                return {"valid": False, "error": f"{file_type} ì´ë¯¸ì§€ê°€ 50MBë¥¼ ì´ˆê³¼í•©ë‹ˆë‹¤"}
            
            if PIL_AVAILABLE:
                try:
                    img = Image.open(BytesIO(content))
                    img.verify()
                    
                    # í¬ê¸° ê²€ì¦
                    img = Image.open(BytesIO(content))  # verify() í›„ ë‹¤ì‹œ ì—´ê¸°
                    width, height = img.size
                    
                    if width < self.min_image_size[0] or height < self.min_image_size[1]:
                        return {
                            "valid": False, 
                            "error": f"{file_type} ì´ë¯¸ì§€: ë„ˆë¬´ ì‘ìŠµë‹ˆë‹¤ (ìµœì†Œ {self.min_image_size[0]}x{self.min_image_size[1]})"
                        }
                    
                    if width > self.max_image_size[0] or height > self.max_image_size[1]:
                        return {
                            "valid": False,
                            "error": f"{file_type} ì´ë¯¸ì§€: ë„ˆë¬´ í½ë‹ˆë‹¤ (ìµœëŒ€ {self.max_image_size[0]}x{self.max_image_size[1]})"
                        }
                    
                    # ìƒ‰ìƒ ëª¨ë“œ ê²€ì¦
                    if img.mode not in ['RGB', 'RGBA', 'L']:
                        return {
                            "valid": False,
                            "error": f"{file_type} ì´ë¯¸ì§€: ì§€ì›ë˜ì§€ ì•ŠëŠ” ìƒ‰ìƒ ëª¨ë“œ ({img.mode})"
                        }
                    
                    return {
                        "valid": True,
                        "size": len(content),
                        "format": img.format,
                        "dimensions": (width, height),
                        "mode": img.mode,
                        "file_type": file_type
                    }
                    
                except Exception as e:
                    return {"valid": False, "error": f"{file_type} ì´ë¯¸ì§€ê°€ ì†ìƒë˜ì—ˆìŠµë‹ˆë‹¤: {str(e)}"}
            else:
                # PIL ì—†ëŠ” ê²½ìš° ê¸°ë³¸ ê²€ì¦
                return {
                    "valid": True,
                    "size": len(content),
                    "format": "unknown",
                    "dimensions": (0, 0),
                    "mode": "unknown",
                    "file_type": file_type
                }
            
        except Exception as e:
            error_handler = get_error_handler()
            error_handler.handle_error(
                ImageProcessingError(f"ì´ë¯¸ì§€ ê²€ì¦ ì‹¤íŒ¨: {str(e)}"),
                {"file_type": file_type, "content_size": len(content) if content else 0}
            )
            return {"valid": False, "error": f"íŒŒì¼ ê²€ì¦ ì¤‘ ì˜¤ë¥˜: {str(e)}"}
    
    def convert_image_to_base64(self, image: Union['Image.Image', 'np.ndarray'], format: str = "JPEG", quality: int = 90) -> str:
        """ì´ë¯¸ì§€ë¥¼ Base64ë¡œ ë³€í™˜"""
        try:
            if not PIL_AVAILABLE:
                self.logger.warning("PIL ì—†ìŒ - Base64 ë³€í™˜ ë¶ˆê°€")
                return ""
            
            # NumPy ë°°ì—´ì„ PIL Imageë¡œ ë³€í™˜
            if NUMPY_AVAILABLE and isinstance(image, np.ndarray):
                if image.dtype != np.uint8:
                    image = (image * 255).astype(np.uint8)
                image = Image.fromarray(image)
            
            # PIL Image ì²˜ë¦¬
            if hasattr(image, 'save'):
                # RGB ëª¨ë“œë¡œ ë³€í™˜ (JPEGëŠ” RGBA ì§€ì› ì•ˆí•¨)
                if format.upper() == 'JPEG' and image.mode == 'RGBA':
                    # í°ìƒ‰ ë°°ê²½ìœ¼ë¡œ RGBA â†’ RGB ë³€í™˜
                    rgb_image = Image.new('RGB', image.size, (255, 255, 255))
                    rgb_image.paste(image, mask=image.split()[-1] if len(image.split()) == 4 else None)
                    image = rgb_image
                
                buffer = BytesIO()
                image.save(buffer, format=format, quality=quality, optimize=True)
                return base64.b64encode(buffer.getvalue()).decode('utf-8')
            else:
                self.logger.error("ì§€ì›ë˜ì§€ ì•ŠëŠ” ì´ë¯¸ì§€ íƒ€ì…")
                return ""
                
        except Exception as e:
            error_handler = get_error_handler()
            error_handler.handle_error(
                ImageProcessingError(f"Base64 ë³€í™˜ ì‹¤íŒ¨: {str(e)}"),
                {"format": format, "quality": quality}
            )
            self.logger.error(f"âŒ ì´ë¯¸ì§€ Base64 ë³€í™˜ ì‹¤íŒ¨: {e}")
            return ""
    
    def convert_base64_to_image(self, base64_str: str) -> Optional['Image.Image']:
        """Base64ë¥¼ PIL Imageë¡œ ë³€í™˜"""
        try:
            if not PIL_AVAILABLE:
                self.logger.warning("PIL ì—†ìŒ - Base64 ë³€í™˜ ë¶ˆê°€")
                return None
            
            # Base64 ë””ì½”ë”©
            image_data = base64.b64decode(base64_str)
            image = Image.open(BytesIO(image_data))
            
            # RGB ëª¨ë“œë¡œ ë³€í™˜
            if image.mode != 'RGB':
                image = image.convert('RGB')
            
            return image
            
        except Exception as e:
            error_handler = get_error_handler()
            error_handler.handle_error(
                ImageProcessingError(f"Base64 â†’ Image ë³€í™˜ ì‹¤íŒ¨: {str(e)}"),
                {"base64_length": len(base64_str) if base64_str else 0}
            )
            self.logger.error(f"âŒ Base64 â†’ Image ë³€í™˜ ì‹¤íŒ¨: {e}")
            return None
    
    def resize_image_with_aspect_ratio(self, image: 'Image.Image', target_size: Tuple[int, int], maintain_ratio: bool = True) -> 'Image.Image':
        """ë¹„ìœ¨ ìœ ì§€í•˜ë©´ì„œ ì´ë¯¸ì§€ í¬ê¸° ì¡°ì •"""
        try:
            if not PIL_AVAILABLE:
                return image
            
            if maintain_ratio:
                image.thumbnail(target_size, Image.Resampling.LANCZOS)
                
                # ì¤‘ì•™ ì •ë ¬ì„ ìœ„í•œ íŒ¨ë”©
                new_image = Image.new('RGB', target_size, (255, 255, 255))
                paste_x = (target_size[0] - image.width) // 2
                paste_y = (target_size[1] - image.height) // 2
                new_image.paste(image, (paste_x, paste_y))
                
                return new_image
            else:
                return image.resize(target_size, Image.Resampling.LANCZOS)
                
        except Exception as e:
            error_handler = get_error_handler()
            error_handler.handle_error(
                ImageProcessingError(f"ì´ë¯¸ì§€ í¬ê¸° ì¡°ì • ì‹¤íŒ¨: {str(e)}"),
                {"target_size": target_size, "maintain_ratio": maintain_ratio}
            )
            self.logger.error(f"âŒ ì´ë¯¸ì§€ í¬ê¸° ì¡°ì • ì‹¤íŒ¨: {e}")
            return image
    
    def create_dummy_image(self, size: Tuple[int, int] = (512, 512), color: Tuple[int, int, int] = (200, 200, 200), text: Optional[str] = None) -> Optional['Image.Image']:
        """ë”ë¯¸ ì´ë¯¸ì§€ ìƒì„± (í…ŒìŠ¤íŠ¸ìš©)"""
        try:
            if not PIL_AVAILABLE:
                return None
            
            image = Image.new('RGB', size, color)
            
            if text:
                try:
                    from PIL import ImageDraw, ImageFont
                    draw = ImageDraw.Draw(image)
                    # ê¸°ë³¸ í°íŠ¸ ì‚¬ìš©
                    font_size = min(size) // 20
                    try:
                        font = ImageFont.truetype("arial.ttf", font_size)
                    except:
                        font = ImageFont.load_default()
                    
                    # í…ìŠ¤íŠ¸ ì¤‘ì•™ ì •ë ¬
                    text_bbox = draw.textbbox((0, 0), text, font=font)
                    text_width = text_bbox[2] - text_bbox[0]
                    text_height = text_bbox[3] - text_bbox[1]
                    
                    text_x = (size[0] - text_width) // 2
                    text_y = (size[1] - text_height) // 2
                    
                    draw.text((text_x, text_y), text, fill=(0, 0, 0), font=font)
                except ImportError:
                    pass  # ImageDraw/ImageFont ì—†ìœ¼ë©´ í…ìŠ¤íŠ¸ ì—†ì´
            
            return image
            
        except Exception as e:
            self.logger.error(f"âŒ ë”ë¯¸ ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨: {e}")
            return None
    
    def get_image_stats(self) -> Dict[str, Any]:
        """ì´ë¯¸ì§€ í—¬í¼ í†µê³„"""
        return {
            "pil_available": PIL_AVAILABLE,
            "numpy_available": NUMPY_AVAILABLE,
            "supported_formats": self.supported_formats,
            "max_image_size": self.max_image_size,
            "min_image_size": self.min_image_size
        }

# ì „ì—­ ì´ë¯¸ì§€ í—¬í¼
_global_image_helper: Optional[ImageHelper] = None
_image_helper_lock = threading.RLock()

def get_image_helper() -> ImageHelper:
    """ì „ì—­ ì´ë¯¸ì§€ í—¬í¼ ë°˜í™˜"""
    global _global_image_helper
    
    with _image_helper_lock:
        if _global_image_helper is None:
            _global_image_helper = ImageHelper()
    
    return _global_image_helper

# ==============================================
# ğŸ”¥ ë©”ëª¨ë¦¬ ê´€ë¦¬ í—¬í¼ (M3 Max 128GB ìµœì í™”)
# ==============================================

class MemoryHelper:
    """í†µí•© ë©”ëª¨ë¦¬ ê´€ë¦¬ í—¬í¼ - M3 Max 128GB + conda í™˜ê²½ ìµœì í™”"""
    
    def __init__(self):
        self.logger = logging.getLogger(f"{__name__}.MemoryHelper")
        self.memory_stats = {
            'cleanup_count': 0,
            'last_cleanup': None,
            'optimization_count': 0
        }
        self._lock = threading.RLock()
        
        # conda í™˜ê²½ ìµœì í™” ìë™ ì‹¤í–‰
        self.setup_conda_memory_optimization()
    
    def setup_conda_memory_optimization(self):
        """conda í™˜ê²½ ìš°ì„  ë©”ëª¨ë¦¬ ìµœì í™”"""
        try:
            if 'CONDA_DEFAULT_ENV' in os.environ:
                conda_env = os.environ['CONDA_DEFAULT_ENV']
                self.logger.info(f"ğŸ conda í™˜ê²½ ê°ì§€: {conda_env}")
                
                # conda í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
                os.environ['OMP_NUM_THREADS'] = str(max(1, os.cpu_count() // 2))
                os.environ['MKL_NUM_THREADS'] = str(max(1, os.cpu_count() // 2))
                os.environ['NUMEXPR_NUM_THREADS'] = str(max(1, os.cpu_count() // 2))
                
                if TORCH_AVAILABLE:
                    # PyTorch conda ìµœì í™”
                    torch.set_num_threads(max(1, os.cpu_count() // 2))
                    
                    # M3 Max ë©”ëª¨ë¦¬ ìµœì í™”
                    if IS_M3_MAX:
                        torch.backends.mps.empty_cache()
                        self.logger.info("ğŸ M3 Max MPS ë©”ëª¨ë¦¬ ìµœì í™” í™œì„±í™”")
                
                self.logger.info("âœ… conda í™˜ê²½ ë©”ëª¨ë¦¬ ìµœì í™” ì™„ë£Œ")
            else:
                self.logger.info("ğŸ conda í™˜ê²½ ì•„ë‹˜ - ê¸°ë³¸ ë©”ëª¨ë¦¬ ìµœì í™” ì‚¬ìš©")
                
        except Exception as e:
            self.logger.warning(f"âš ï¸ conda ë©”ëª¨ë¦¬ ìµœì í™” ì‹¤íŒ¨: {e}")
    
    def optimize_device_memory(self, device: str):
        """ë””ë°”ì´ìŠ¤ë³„ ë©”ëª¨ë¦¬ ìµœì í™”"""
        try:
            with self._lock:
                if TORCH_AVAILABLE:
                    if device == "mps" and IS_M3_MAX:
                        # M3 Max MPS ìµœì í™”
                        if hasattr(torch.mps, 'empty_cache'):
                            safe_mps_empty_cache()
                        if hasattr(torch.mps, 'synchronize'):
                            torch.mps.synchronize()
                        self.logger.debug("âœ… M3 Max MPS ë©”ëª¨ë¦¬ ìµœì í™”")
                        
                    elif device == "cuda":
                        # CUDA ìµœì í™”
                        torch.cuda.empty_cache()
                        if torch.cuda.is_available():
                            torch.cuda.synchronize()
                        self.logger.debug("âœ… CUDA ë©”ëª¨ë¦¬ ìµœì í™”")
                    
                    elif device == "cpu":
                        # CPU ë©”ëª¨ë¦¬ ìµœì í™”
                        gc.collect()
                        self.logger.debug("âœ… CPU ë©”ëª¨ë¦¬ ìµœì í™”")
                
                # Python ê°€ë¹„ì§€ ì»¬ë ‰ì…˜
                collected = gc.collect()
                
                self.memory_stats['optimization_count'] += 1
                self.logger.debug(f"âœ… {device} ë©”ëª¨ë¦¬ ìµœì í™” ì™„ë£Œ (GC: {collected})")
                
        except Exception as e:
            error_handler = get_error_handler()
            error_handler.handle_error(
                MemoryError(f"ë©”ëª¨ë¦¬ ìµœì í™” ì‹¤íŒ¨: {str(e)}"),
                {"device": device}
            )
            self.logger.warning(f"âš ï¸ ë©”ëª¨ë¦¬ ìµœì í™” ì‹¤íŒ¨: {e}")
    
    def cleanup_memory(self, force: bool = False):
        """ê°•ì œ ë©”ëª¨ë¦¬ ì •ë¦¬"""
        try:
            with self._lock:
                # ìºì‹œ ì •ë¦¬
                if hasattr(self, '_cache'):
                    self._cache.clear()
                
                # ë””ë°”ì´ìŠ¤ë³„ ì •ë¦¬
                if TORCH_AVAILABLE:
                    if IS_M3_MAX and torch.backends.mps.is_available():
                        safe_mps_empty_cache()
                    elif torch.cuda.is_available():
                        torch.cuda.empty_cache()
                
                # Python ë©”ëª¨ë¦¬ ì •ë¦¬
                collected = gc.collect()
                
                self.memory_stats['cleanup_count'] += 1
                self.memory_stats['last_cleanup'] = datetime.now()
                
                self.logger.info(f"ğŸ§¹ ë©”ëª¨ë¦¬ ì •ë¦¬ ì™„ë£Œ (GC: {collected}, ê°•ì œ: {force})")
                
        except Exception as e:
            self.logger.error(f"âŒ ë©”ëª¨ë¦¬ ì •ë¦¬ ì‹¤íŒ¨: {e}")
    
    def get_memory_info(self) -> Dict[str, Any]:
        """ë©”ëª¨ë¦¬ ì •ë³´ ì¡°íšŒ"""
        try:
            import psutil
            
            memory = psutil.virtual_memory()
            
            memory_info = {
                "total_gb": round(memory.total / (1024**3), 2),
                "available_gb": round(memory.available / (1024**3), 2),
                "used_gb": round(memory.used / (1024**3), 2),
                "percent": memory.percent,
                "is_m3_max": IS_M3_MAX,
                "device": DEVICE,
                "conda_env": os.environ.get('CONDA_DEFAULT_ENV'),
                "torch_available": TORCH_AVAILABLE
            }
            
            # PyTorch ë©”ëª¨ë¦¬ ì •ë³´
            if TORCH_AVAILABLE:
                if IS_M3_MAX and torch.backends.mps.is_available():
                    # M3 Max MPS ì •ë³´ëŠ” ì œí•œì 
                    memory_info["mps_available"] = True
                elif torch.cuda.is_available():
                    memory_info.update({
                        "cuda_memory_allocated": torch.cuda.memory_allocated(),
                        "cuda_memory_reserved": torch.cuda.memory_reserved(),
                        "cuda_memory_cached": torch.cuda.memory_cached()
                    })
            
            memory_info.update(self.memory_stats)
            return memory_info
            
        except ImportError:
            # psutil ì—†ëŠ” ê²½ìš° ê¸°ë³¸ ì •ë³´
            return {
                "total_gb": 128.0 if IS_M3_MAX else 16.0,
                "is_m3_max": IS_M3_MAX,
                "device": DEVICE,
                "torch_available": TORCH_AVAILABLE,
                "conda_env": os.environ.get('CONDA_DEFAULT_ENV'),
                **self.memory_stats
            }
        except Exception as e:
            self.logger.error(f"ë©”ëª¨ë¦¬ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {"error": str(e), **self.memory_stats}
    
    @asynccontextmanager
    async def memory_context(self, cleanup_after: bool = True):
        """ë©”ëª¨ë¦¬ ê´€ë¦¬ ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì €"""
        try:
            # ì§„ì… ì‹œ ìµœì í™”
            self.optimize_device_memory(DEVICE)
            yield
        finally:
            # ì¢…ë£Œ ì‹œ ì •ë¦¬
            if cleanup_after:
                self.cleanup_memory()

# ì „ì—­ ë©”ëª¨ë¦¬ í—¬í¼
_global_memory_helper: Optional[MemoryHelper] = None
_memory_helper_lock = threading.RLock()

def get_memory_helper() -> MemoryHelper:
    """ì „ì—­ ë©”ëª¨ë¦¬ í—¬í¼ ë°˜í™˜"""
    global _global_memory_helper
    
    with _memory_helper_lock:
        if _global_memory_helper is None:
            _global_memory_helper = MemoryHelper()
    
    return _global_memory_helper

# ==============================================
# ğŸ”¥ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ
# ==============================================

@dataclass
class PerformanceMetrics:
    """ì„±ëŠ¥ ë©”íŠ¸ë¦­"""
    operation_name: str
    start_time: float
    end_time: Optional[float] = None
    duration: Optional[float] = None
    success: bool = True
    error_message: Optional[str] = None
    memory_before: Optional[float] = None
    memory_after: Optional[float] = None
    additional_data: Dict[str, Any] = field(default_factory=dict)

class PerformanceMonitor:
    """ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ - step_service.py + step_implementations.py ê³µí†µ"""
    
    def __init__(self):
        self.logger = logging.getLogger(f"{__name__}.PerformanceMonitor")
        self.metrics: List[PerformanceMetrics] = []
        self.operation_stats = {}
        self._lock = threading.RLock()
        self.max_metrics = 1000  # ìµœëŒ€ ë©”íŠ¸ë¦­ ê°œìˆ˜
    
    @asynccontextmanager
    async def monitor_operation(self, operation_name: str, **additional_data):
        """ì‘ì—… ëª¨ë‹ˆí„°ë§ ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì €"""
        metric = PerformanceMetrics(
            operation_name=operation_name,
            start_time=time.time(),
            additional_data=additional_data
        )
        
        # ë©”ëª¨ë¦¬ ì •ë³´ ìˆ˜ì§‘ (ê°€ëŠ¥í•œ ê²½ìš°)
        try:
            memory_helper = get_memory_helper()
            memory_info = memory_helper.get_memory_info()
            metric.memory_before = memory_info.get('used_gb', 0)
        except Exception:
            pass
        
        try:
            yield metric
            metric.success = True
        except Exception as e:
            metric.success = False
            metric.error_message = str(e)
            raise
        finally:
            # ì¢…ë£Œ ì²˜ë¦¬
            metric.end_time = time.time()
            metric.duration = metric.end_time - metric.start_time
            
            # ë©”ëª¨ë¦¬ ì •ë³´ ìˆ˜ì§‘ (ì¢…ë£Œ ì‹œ)
            try:
                memory_helper = get_memory_helper()
                memory_info = memory_helper.get_memory_info()
                metric.memory_after = memory_info.get('used_gb', 0)
            except Exception:
                pass
            
            self._record_metric(metric)
    
    def _record_metric(self, metric: PerformanceMetrics):
        """ë©”íŠ¸ë¦­ ê¸°ë¡"""
        try:
            with self._lock:
                self.metrics.append(metric)
                
                # ë©”íŠ¸ë¦­ ìˆ˜ ì œí•œ
                if len(self.metrics) > self.max_metrics:
                    self.metrics.pop(0)
                
                # í†µê³„ ì—…ë°ì´íŠ¸
                if metric.operation_name not in self.operation_stats:
                    self.operation_stats[metric.operation_name] = {
                        'total_count': 0,
                        'success_count': 0,
                        'error_count': 0,
                        'total_duration': 0.0,
                        'min_duration': float('inf'),
                        'max_duration': 0.0,
                        'avg_duration': 0.0
                    }
                
                stats = self.operation_stats[metric.operation_name]
                stats['total_count'] += 1
                
                if metric.success:
                    stats['success_count'] += 1
                else:
                    stats['error_count'] += 1
                
                if metric.duration is not None:
                    stats['total_duration'] += metric.duration
                    stats['min_duration'] = min(stats['min_duration'], metric.duration)
                    stats['max_duration'] = max(stats['max_duration'], metric.duration)
                    stats['avg_duration'] = stats['total_duration'] / stats['total_count']
                
                self.logger.debug(f"ğŸ“Š ì„±ëŠ¥ ê¸°ë¡: {metric.operation_name} - {metric.duration:.3f}s (ì„±ê³µ: {metric.success})")
                
        except Exception as e:
            self.logger.warning(f"ì„±ëŠ¥ ë©”íŠ¸ë¦­ ê¸°ë¡ ì‹¤íŒ¨: {e}")
    
    def get_operation_stats(self, operation_name: Optional[str] = None) -> Dict[str, Any]:
        """ì‘ì—… í†µê³„ ì¡°íšŒ"""
        with self._lock:
            if operation_name:
                return self.operation_stats.get(operation_name, {})
            else:
                return dict(self.operation_stats)
    
    def get_recent_metrics(self, count: int = 10, operation_name: Optional[str] = None) -> List[Dict[str, Any]]:
        """ìµœê·¼ ë©”íŠ¸ë¦­ ì¡°íšŒ"""
        with self._lock:
            filtered_metrics = self.metrics
            
            if operation_name:
                filtered_metrics = [m for m in self.metrics if m.operation_name == operation_name]
            
            recent = filtered_metrics[-count:] if count > 0 else filtered_metrics
            
            return [
                {
                    'operation_name': m.operation_name,
                    'duration': m.duration,
                    'success': m.success,
                    'error_message': m.error_message,
                    'memory_before': m.memory_before,
                    'memory_after': m.memory_after,
                    'timestamp': m.start_time,
                    'additional_data': m.additional_data
                }
                for m in recent
            ]
    
    def get_performance_summary(self) -> Dict[str, Any]:
        """ì„±ëŠ¥ ìš”ì•½"""
        with self._lock:
            total_operations = len(self.metrics)
            successful_operations = sum(1 for m in self.metrics if m.success)
            
            return {
                "total_operations": total_operations,
                "successful_operations": successful_operations,
                "error_rate": (total_operations - successful_operations) / max(total_operations, 1),
                "operation_types": len(self.operation_stats),
                "operation_stats": dict(self.operation_stats),
                "memory_monitoring": True,
                "max_metrics_stored": self.max_metrics
            }
    
    def clear_metrics(self, operation_name: Optional[str] = None):
        """ë©”íŠ¸ë¦­ ì •ë¦¬"""
        with self._lock:
            if operation_name:
                self.metrics = [m for m in self.metrics if m.operation_name != operation_name]
                self.operation_stats.pop(operation_name, None)
                self.logger.info(f"ğŸ“Š {operation_name} ë©”íŠ¸ë¦­ ì •ë¦¬ ì™„ë£Œ")
            else:
                self.metrics.clear()
                self.operation_stats.clear()
                self.logger.info("ğŸ“Š ëª¨ë“  ë©”íŠ¸ë¦­ ì •ë¦¬ ì™„ë£Œ")

# ì „ì—­ ì„±ëŠ¥ ëª¨ë‹ˆí„°
_global_performance_monitor: Optional[PerformanceMonitor] = None
_performance_monitor_lock = threading.RLock()

def get_performance_monitor() -> PerformanceMonitor:
    """ì „ì—­ ì„±ëŠ¥ ëª¨ë‹ˆí„° ë°˜í™˜"""
    global _global_performance_monitor
    
    with _performance_monitor_lock:
        if _global_performance_monitor is None:
            _global_performance_monitor = PerformanceMonitor()
    
    return _global_performance_monitor

# ==============================================
# ğŸ”¥ Step ë°ì´í„° ì¤€ë¹„ í—¬í¼ (ì‹œê·¸ë‹ˆì²˜ ê¸°ë°˜)
# ==============================================

class StepDataPreparer:
    """Stepë³„ ë™ì  ë°ì´í„° ì¤€ë¹„ - í†µí•© ì‹œê·¸ë‹ˆì²˜ ê¸°ë°˜"""
    
    def __init__(self):
        self.logger = logging.getLogger(f"{__name__}.StepDataPreparer")
        self.session_helper = get_session_helper()
        self.image_helper = get_image_helper()
    
    async def prepare_step_data(
        self, 
        step_id: int, 
        inputs: Dict[str, Any]
    ) -> Tuple[Tuple, Dict[str, Any]]:
        """Stepë³„ ë™ì  ë°ì´í„° ì¤€ë¹„ - í†µí•© ì‹œê·¸ë‹ˆì²˜ ê¸°ë°˜ ìë™ ë§¤í•‘"""
        try:
            # í†µí•© ì‹œê·¸ë‹ˆì²˜ ì¡°íšŒ
            step_class_name = UNIFIED_STEP_CLASS_MAPPING.get(step_id)
            if not step_class_name:
                raise ValueError(f"Step {step_id}ì— ëŒ€í•œ í´ë˜ìŠ¤ ë§¤í•‘ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ")
            
            signature = UNIFIED_STEP_SIGNATURES.get(step_class_name)
            if not signature:
                raise ValueError(f"Step {step_id} ({step_class_name})ì— ëŒ€í•œ ì‹œê·¸ë‹ˆì²˜ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
            
            # ì„¸ì…˜ì—ì„œ ì´ë¯¸ì§€ ë¡œë“œ
            session_id = inputs.get("session_id")
            person_img, clothing_img = await self.session_helper.load_session_images(session_id)
            
            args = []
            kwargs = {}
            
            # í•„ìˆ˜ ì¸ì ì¤€ë¹„ (í†µí•© ì‹œê·¸ë‹ˆì²˜ ê¸°ë°˜)
            for arg_name in signature.required_args:
                if arg_name in ["person_image", "image"] and step_id in [1, 2]:  # HumanParsing, PoseEstimation
                    if person_img is None:
                        raise ValueError(f"Step {step_id} ({step_class_name}): person_image ë¡œë“œ ì‹¤íŒ¨")
                    args.append(person_img)
                    
                elif arg_name == "image" and step_id == 3:  # ClothSegmentation
                    if clothing_img is None:
                        raise ValueError(f"Step {step_id} ({step_class_name}): clothing_image ë¡œë“œ ì‹¤íŒ¨")
                    args.append(clothing_img)
                    
                elif arg_name in ["person_image", "cloth_image", "clothing_image"]:
                    if "person" in arg_name:
                        if person_img is None:
                            raise ValueError(f"Step {step_id} ({step_class_name}): person_image ë¡œë“œ ì‹¤íŒ¨")
                        args.append(person_img)
                    else:
                        if clothing_img is None:
                            raise ValueError(f"Step {step_id} ({step_class_name}): clothing_image ë¡œë“œ ì‹¤íŒ¨")
                        args.append(clothing_img)
                        
                elif arg_name == "fitted_image":
                    fitted_image = inputs.get("fitted_image", person_img)
                    if fitted_image is None:
                        raise ValueError(f"Step {step_id} ({step_class_name}): fitted_image ë¡œë“œ ì‹¤íŒ¨")
                    args.append(fitted_image)
                    
                elif arg_name == "final_image":
                    final_image = inputs.get("final_image", person_img)
                    if final_image is None:
                        raise ValueError(f"Step {step_id} ({step_class_name}): final_image ë¡œë“œ ì‹¤íŒ¨")
                    args.append(final_image)
                    
                elif arg_name == "measurements":
                    measurements = inputs.get("measurements")
                    if measurements is None:
                        raise ValueError(f"Step {step_id} ({step_class_name}): measurements ë¡œë“œ ì‹¤íŒ¨")
                    args.append(measurements)
                    
                else:
                    # ê¸°íƒ€ í•„ìˆ˜ ì¸ìë“¤
                    if arg_name in inputs:
                        args.append(inputs[arg_name])
                    else:
                        raise ValueError(f"Step {step_id} ({step_class_name}): í•„ìˆ˜ ì¸ì {arg_name} ì—†ìŒ")
            
            # í•„ìˆ˜ kwargs ì¤€ë¹„ (í†µí•© ì‹œê·¸ë‹ˆì²˜ ê¸°ë°˜)
            for kwarg_name in signature.required_kwargs:
                if kwarg_name == "clothing_type":
                    kwargs[kwarg_name] = inputs.get("clothing_type", "shirt")
                elif kwarg_name == "quality_level":
                    kwargs[kwarg_name] = inputs.get("quality_level", "medium")
                else:
                    if kwarg_name in inputs:
                        kwargs[kwarg_name] = inputs[kwarg_name]
                    else:
                        # ê¸°ë³¸ê°’ ì œê³µ
                        default_values = {
                            "detection_confidence": 0.5,
                            "matching_precision": "high",
                            "fabric_type": "cotton",
                            "fitting_quality": "high",
                            "enhancement_level": "medium",
                            "analysis_depth": "comprehensive"
                        }
                        kwargs[kwarg_name] = default_values.get(kwarg_name, "default")
            
            # ì„ íƒì  kwargs ì¤€ë¹„ (í†µí•© ì‹œê·¸ë‹ˆì²˜ ê¸°ë°˜)
            for kwarg_name in signature.optional_kwargs:
                if kwarg_name in inputs:
                    kwargs[kwarg_name] = inputs[kwarg_name]
                elif kwarg_name == "session_id":
                    kwargs[kwarg_name] = session_id
                elif kwarg_name == "enhance_quality":
                    kwargs[kwarg_name] = inputs.get("enhance_quality", True)
            
            self.logger.debug(
                f"âœ… Step {step_id} ({step_class_name}) ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ: "
                f"args={len(args)}, kwargs={list(kwargs.keys())}"
            )
            
            return tuple(args), kwargs
            
        except Exception as e:
            self.logger.error(f"âŒ Step {step_id} ë°ì´í„° ì¤€ë¹„ ì‹¤íŒ¨: {e}")
            raise
    
    def validate_step_inputs(self, step_id: int, inputs: Dict[str, Any]) -> Dict[str, Any]:
        """Step ì…ë ¥ê°’ ê²€ì¦"""
        try:
            step_class_name = UNIFIED_STEP_CLASS_MAPPING.get(step_id)
            signature = UNIFIED_STEP_SIGNATURES.get(step_class_name) if step_class_name else None
            
            validation_result = {
                "valid": True,
                "errors": [],
                "warnings": [],
                "step_id": step_id,
                "step_class_name": step_class_name
            }
            
            if not signature:
                validation_result["valid"] = False
                validation_result["errors"].append(f"Step {step_id} ì‹œê·¸ë‹ˆì²˜ ì—†ìŒ")
                return validation_result
            
            # í•„ìˆ˜ ì¸ì ê²€ì¦
            missing_args = []
            for arg_name in signature.required_args:
                if arg_name not in ["person_image", "cloth_image", "clothing_image", "image", "fitted_image", "final_image"]:
                    if arg_name not in inputs:
                        missing_args.append(arg_name)
            
            if missing_args:
                validation_result["valid"] = False
                validation_result["errors"].append(f"í•„ìˆ˜ ì¸ì ëˆ„ë½: {missing_args}")
            
            # í•„ìˆ˜ kwargs ê²€ì¦
            missing_kwargs = []
            for kwarg_name in signature.required_kwargs:
                if kwarg_name not in inputs:
                    missing_kwargs.append(kwarg_name)
            
            if missing_kwargs:
                validation_result["warnings"].append(f"í•„ìˆ˜ kwargs ëˆ„ë½ (ê¸°ë³¸ê°’ ì‚¬ìš©): {missing_kwargs}")
            
            # ì„¸ì…˜ ID ê²€ì¦
            if not inputs.get("session_id"):
                validation_result["valid"] = False
                validation_result["errors"].append("session_id í•„ìš”")
            
            return validation_result
            
        except Exception as e:
            return {
                "valid": False,
                "errors": [f"ì…ë ¥ê°’ ê²€ì¦ ì‹¤íŒ¨: {str(e)}"],
                "step_id": step_id
            }

# ì „ì—­ ë°ì´í„° ì¤€ë¹„ì
_global_step_data_preparer: Optional[StepDataPreparer] = None
_data_preparer_lock = threading.RLock()

def get_step_data_preparer() -> StepDataPreparer:
    """ì „ì—­ ë°ì´í„° ì¤€ë¹„ì ë°˜í™˜"""
    global _global_step_data_preparer
    
    with _data_preparer_lock:
        if _global_step_data_preparer is None:
            _global_step_data_preparer = StepDataPreparer()
    
    return _global_step_data_preparer

# ==============================================
# ğŸ”¥ í†µí•© ìœ í‹¸ë¦¬í‹° ë§¤ë‹ˆì € (ëª¨ë“  í—¬í¼ í†µí•©)
# ==============================================

class UtilsManager:
    """í†µí•© ìœ í‹¸ë¦¬í‹° ë§¤ë‹ˆì € - ëª¨ë“  í—¬í¼ë“¤ì„ í†µí•© ê´€ë¦¬"""
    
    def __init__(self, di_container: Optional[DIContainer] = None):
        self.di_container = di_container or get_di_container()
        self.logger = logging.getLogger(f"{__name__}.UtilsManager")
        
        # í—¬í¼ë“¤ ì´ˆê¸°í™”
        self.error_handler = get_error_handler()
        self.session_helper = get_session_helper()
        self.image_helper = get_image_helper()
        self.memory_helper = get_memory_helper()
        self.performance_monitor = get_performance_monitor()
        self.step_data_preparer = get_step_data_preparer()
        
        # ìƒíƒœ ê´€ë¦¬
        self.initialized = False
        self.start_time = datetime.now()
        
        # conda í™˜ê²½ ìµœì í™”
        setup_conda_optimization()
        
        self.logger.info("âœ… UtilsManager ì´ˆê¸°í™” ì™„ë£Œ")
    
    async def initialize(self) -> bool:
        """ìœ í‹¸ë¦¬í‹° ë§¤ë‹ˆì € ì´ˆê¸°í™”"""
        try:
            # ë©”ëª¨ë¦¬ ìµœì í™”
            self.memory_helper.optimize_device_memory(DEVICE)
            
            # ì„¸ì…˜ í—¬í¼ ì„¤ì •
            if hasattr(self.session_helper, 'session_manager') and SESSION_MANAGER_AVAILABLE:
                self.logger.info("âœ… ì„¸ì…˜ ë§¤ë‹ˆì € ì—°ë™ í™•ì¸")
            
            self.initialized = True
            self.logger.info("âœ… UtilsManager ì´ˆê¸°í™” ì™„ë£Œ")
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ UtilsManager ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return False
    
    def get_unified_stats(self) -> Dict[str, Any]:
        """í†µí•© ìœ í‹¸ë¦¬í‹° í†µê³„"""
        try:
            return {
                "utils_manager": {
                    "initialized": self.initialized,
                    "uptime_seconds": (datetime.now() - self.start_time).total_seconds(),
                    "di_container_available": DI_CONTAINER_AVAILABLE
                },
                "error_handler": self.error_handler.get_error_summary(),
                "session_helper": self.session_helper.get_session_stats(),
                "image_helper": self.image_helper.get_image_stats(),
                "memory_helper": self.memory_helper.get_memory_info(),
                "performance_monitor": self.performance_monitor.get_performance_summary(),
                "system_info": {
                    "unified_mapping_available": UNIFIED_MAPPING_AVAILABLE,
                    "torch_available": TORCH_AVAILABLE,
                    "pil_available": PIL_AVAILABLE,
                    "numpy_available": NUMPY_AVAILABLE,
                    "session_manager_available": SESSION_MANAGER_AVAILABLE,
                    "model_loader_available": MODEL_LOADER_AVAILABLE,
                    "device": DEVICE,
                    "is_m3_max": IS_M3_MAX,
                    "conda_env": os.environ.get('CONDA_DEFAULT_ENV'),
                    "conda_optimized": 'CONDA_DEFAULT_ENV' in os.environ
                },
                "unified_mapping_info": get_system_compatibility_info() if UNIFIED_MAPPING_AVAILABLE else {}
            }
            
        except Exception as e:
            self.logger.error(f"í†µí•© í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {"error": str(e)}
    
    async def cleanup_all(self):
        """ëª¨ë“  ìœ í‹¸ë¦¬í‹° ì •ë¦¬"""
        try:
            # ì„±ëŠ¥ ëª¨ë‹ˆí„° ì •ë¦¬
            self.performance_monitor.clear_metrics()
            
            # ì„¸ì…˜ ìºì‹œ ì •ë¦¬
            self.session_helper.clear_session_cache()
            
            # ë©”ëª¨ë¦¬ ì •ë¦¬
            self.memory_helper.cleanup_memory(force=True)
            
            self.initialized = False
            self.logger.info("âœ… UtilsManager ì •ë¦¬ ì™„ë£Œ")
            
        except Exception as e:
            self.logger.error(f"âŒ UtilsManager ì •ë¦¬ ì‹¤íŒ¨: {e}")

# ì „ì—­ ìœ í‹¸ë¦¬í‹° ë§¤ë‹ˆì €
_global_utils_manager: Optional[UtilsManager] = None
_utils_manager_lock = threading.RLock()

def get_utils_manager(di_container: Optional[DIContainer] = None) -> UtilsManager:
    """ì „ì—­ ìœ í‹¸ë¦¬í‹° ë§¤ë‹ˆì € ë°˜í™˜"""
    global _global_utils_manager
    
    with _utils_manager_lock:
        if _global_utils_manager is None:
            _global_utils_manager = UtilsManager(di_container)
    
    return _global_utils_manager

async def get_utils_manager_async(di_container: Optional[DIContainer] = None) -> UtilsManager:
    """ë¹„ë™ê¸° ìœ í‹¸ë¦¬í‹° ë§¤ë‹ˆì € ë°˜í™˜"""
    manager = get_utils_manager(di_container)
    if not manager.initialized:
        await manager.initialize()
    return manager

# ==============================================
# ğŸ”¥ ê³µê°œ ì¸í„°í˜ì´ìŠ¤ ë° í¸ì˜ í•¨ìˆ˜ë“¤
# ==============================================

# í¸ì˜ í•¨ìˆ˜ë“¤ (step_service.py + step_implementations.pyì—ì„œ ì§ì ‘ ì‚¬ìš©)
async def load_session_images(session_id: str) -> Tuple[Optional['Image.Image'], Optional['Image.Image']]:
    """ì„¸ì…˜ ì´ë¯¸ì§€ ë¡œë“œ (í¸ì˜ í•¨ìˆ˜)"""
    session_helper = get_session_helper()
    return await session_helper.load_session_images(session_id)

def validate_image_content(content: bytes, file_type: str) -> Dict[str, Any]:
    """ì´ë¯¸ì§€ ê²€ì¦ (í¸ì˜ í•¨ìˆ˜)"""
    image_helper = get_image_helper()
    return image_helper.validate_image_content(content, file_type)

def convert_image_to_base64(image: Union['Image.Image', 'np.ndarray'], format: str = "JPEG") -> str:
    """Base64 ë³€í™˜ (í¸ì˜ í•¨ìˆ˜)"""
    image_helper = get_image_helper()
    return image_helper.convert_image_to_base64(image, format)

def optimize_memory(device: str = None):
    """ë©”ëª¨ë¦¬ ìµœì í™” (í¸ì˜ í•¨ìˆ˜)"""
    memory_helper = get_memory_helper()
    memory_helper.optimize_device_memory(device or DEVICE)

async def prepare_step_data(step_id: int, inputs: Dict[str, Any]) -> Tuple[Tuple, Dict[str, Any]]:
    """Step ë°ì´í„° ì¤€ë¹„ (í¸ì˜ í•¨ìˆ˜)"""
    data_preparer = get_step_data_preparer()
    return await data_preparer.prepare_step_data(step_id, inputs)

@asynccontextmanager
async def monitor_performance(operation_name: str, **additional_data):
    """ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ (í¸ì˜ í•¨ìˆ˜)"""
    performance_monitor = get_performance_monitor()
    async with performance_monitor.monitor_operation(operation_name, **additional_data) as metric:
        yield metric

def handle_step_error(error: Exception, context: Dict[str, Any] = None) -> Dict[str, Any]:
    """ì—ëŸ¬ ì²˜ë¦¬ (í¸ì˜ í•¨ìˆ˜)"""
    error_handler = get_error_handler()
    return error_handler.handle_error(error, context)

# ==============================================
# ğŸ”¥ ëª¨ë“ˆ Export
# ==============================================

__all__ = [
    # í—¬í¼ í´ë˜ìŠ¤ë“¤
    "SessionHelper",
    "ImageHelper", 
    "MemoryHelper",
    "PerformanceMonitor",
    "StepDataPreparer",
    "StepErrorHandler",
    "UtilsManager",
    
    # ì „ì—­ ì¸ìŠ¤í„´ìŠ¤ í•¨ìˆ˜ë“¤
    "get_session_helper",
    "get_image_helper",
    "get_memory_helper", 
    "get_performance_monitor",
    "get_step_data_preparer",
    "get_error_handler",
    "get_utils_manager",
    "get_utils_manager_async",
    
    # í¸ì˜ í•¨ìˆ˜ë“¤
    "load_session_images",
    "validate_image_content",
    "convert_image_to_base64",
    "optimize_memory",
    "prepare_step_data",
    "monitor_performance",
    "handle_step_error",
    
    # ì—ëŸ¬ í´ë˜ìŠ¤ë“¤
    "StepUtilsError",
    "SessionError",
    "ImageProcessingError", 
    "MemoryError",
    "StepInstanceError",
    
    # ë°ì´í„° í´ë˜ìŠ¤ë“¤
    "PerformanceMetrics",
    "BodyMeasurements",
    
    # í†µí•© ë§¤í•‘ ì‹œìŠ¤í…œ re-export
    "UNIFIED_STEP_CLASS_MAPPING",
    "UNIFIED_SERVICE_CLASS_MAPPING",
    "SERVICE_TO_STEP_MAPPING",
    "STEP_TO_SERVICE_MAPPING",
    "SERVICE_ID_TO_STEP_ID",
    "STEP_ID_TO_SERVICE_ID",
    "UnifiedStepSignature",
    "UNIFIED_STEP_SIGNATURES",
    "StepFactoryHelper",
    "setup_conda_optimization",
    "validate_step_compatibility",
    "get_step_id_by_service_id",
    "get_service_id_by_step_id",
    "get_all_available_steps",
    "get_all_available_services",
    "get_system_compatibility_info",
    
    # ì‹œìŠ¤í…œ ì •ë³´
    "TORCH_AVAILABLE",
    "PIL_AVAILABLE", 
    "NUMPY_AVAILABLE",
    "DI_CONTAINER_AVAILABLE",
    "SESSION_MANAGER_AVAILABLE",
    "MODEL_LOADER_AVAILABLE",
    "UNIFIED_MAPPING_AVAILABLE",
    "DEVICE",
    "IS_M3_MAX"
]

# ==============================================
# ğŸ”¥ ëª¨ë“ˆ ë¡œë“œ ì™„ë£Œ ë©”ì‹œì§€
# ==============================================

logger.info("âœ… Step Utils Layer v2.0 ë¡œë“œ ì™„ë£Œ!")
logger.info("ğŸ› ï¸ Complete Utility Layer for Step Services")
logger.info("ğŸ”— unified_step_mapping.py ì™„ì „ í™œìš© - ì„¸ íŒŒì¼ í†µí•© ì§€ì›")
logger.info("ğŸ¤– BaseStepMixin ì™„ë²½ í˜¸í™˜ - logger ì†ì„± ë° ì´ˆê¸°í™” ê³¼ì •")
logger.info("ğŸ’¾ ModelLoader ì™„ì „ ì—°ë™ - 89.8GB ì²´í¬í¬ì¸íŠ¸ í™œìš©")
logger.info("ğŸ”§ ì‹¤ì œ Step í´ë˜ìŠ¤ë“¤ê³¼ 100% í˜¸í™˜ - HumanParsingStep ë“±")
logger.info("ğŸ—ï¸ step_service.py + step_implementations.py ê³µí†µ ì§€ì›")
logger.info("ğŸ“Š SessionManager, DI Container ì™„ì „ ì—°ë™")
logger.info("ğŸ›¡ï¸ ì—ëŸ¬ ì²˜ë¦¬ ë° ë³µêµ¬ ì‹œìŠ¤í…œ")
logger.info("ğŸ“ˆ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ë° ë©”ëª¨ë¦¬ ê´€ë¦¬")
logger.info("ğŸ M3 Max 128GB ìµœì í™” + conda í™˜ê²½ ìš°ì„ ")
logger.info("âš¡ ìˆœí™˜ì°¸ì¡° ì™„ì „ ë°©ì§€ - ë‹¨ë°©í–¥ ì˜ì¡´ì„±")
logger.info("ğŸš€ í”„ë¡œë•ì…˜ ë ˆë²¨ ì•ˆì •ì„±")

logger.info(f"ğŸ“Š ì‹œìŠ¤í…œ ìƒíƒœ:")
logger.info(f"   - í†µí•© ë§¤í•‘: {'âœ…' if UNIFIED_MAPPING_AVAILABLE else 'âŒ'}")
logger.info(f"   - PyTorch: {'âœ…' if TORCH_AVAILABLE else 'âŒ'}")
logger.info(f"   - PIL: {'âœ…' if PIL_AVAILABLE else 'âŒ'}")
logger.info(f"   - NumPy: {'âœ…' if NUMPY_AVAILABLE else 'âŒ'}")
logger.info(f"   - DI Container: {'âœ…' if DI_CONTAINER_AVAILABLE else 'âŒ'}")
logger.info(f"   - Session Manager: {'âœ…' if SESSION_MANAGER_AVAILABLE else 'âŒ'}")
logger.info(f"   - ModelLoader: {'âœ…' if MODEL_LOADER_AVAILABLE else 'âŒ'}")
logger.info(f"   - Device: {DEVICE}")
logger.info(f"   - conda í™˜ê²½: {'âœ…' if 'CONDA_DEFAULT_ENV' in os.environ else 'âŒ'}")

logger.info("ğŸ”§ ì œê³µë˜ëŠ” í—¬í¼ë“¤:")
logger.info("   - SessionHelper: ì„¸ì…˜ ê´€ë¦¬ ë° ì´ë¯¸ì§€ ë¡œë“œ")
logger.info("   - ImageHelper: ì´ë¯¸ì§€ ê²€ì¦, ë³€í™˜, ì²˜ë¦¬")
logger.info("   - MemoryHelper: M3 Max ë©”ëª¨ë¦¬ ìµœì í™”")
logger.info("   - PerformanceMonitor: ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§")
logger.info("   - StepDataPreparer: Stepë³„ ë°ì´í„° ì¤€ë¹„")
logger.info("   - StepErrorHandler: ì—ëŸ¬ ì²˜ë¦¬ ë° ë³µêµ¬")
logger.info("   - UtilsManager: ëª¨ë“  í—¬í¼ í†µí•© ê´€ë¦¬")

logger.info("ğŸ¯ í¸ì˜ í•¨ìˆ˜ë“¤:")
logger.info("   - load_session_images(): ì„¸ì…˜ ì´ë¯¸ì§€ ë¡œë“œ")
logger.info("   - validate_image_content(): ì´ë¯¸ì§€ ê²€ì¦")
logger.info("   - convert_image_to_base64(): Base64 ë³€í™˜")
logger.info("   - optimize_memory(): ë©”ëª¨ë¦¬ ìµœì í™”")
logger.info("   - prepare_step_data(): Step ë°ì´í„° ì¤€ë¹„")
logger.info("   - monitor_performance(): ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§")
logger.info("   - handle_step_error(): ì—ëŸ¬ ì²˜ë¦¬")

logger.info(f"ğŸ”— í†µí•© ë§¤í•‘ ì •ë³´:")
if UNIFIED_MAPPING_AVAILABLE:
    logger.info(f"   - Step í´ë˜ìŠ¤: {len(UNIFIED_STEP_CLASS_MAPPING)}ê°œ")
    logger.info(f"   - Service í´ë˜ìŠ¤: {len(UNIFIED_SERVICE_CLASS_MAPPING)}ê°œ")
    logger.info(f"   - Step ì‹œê·¸ë‹ˆì²˜: {len(UNIFIED_STEP_SIGNATURES)}ê°œ")
    
    # Step í´ë˜ìŠ¤ ë§¤í•‘ ì¶œë ¥
    for step_id, step_class_name in UNIFIED_STEP_CLASS_MAPPING.items():
        service_id = STEP_ID_TO_SERVICE_ID.get(step_id, 0)
        service_name = UNIFIED_SERVICE_CLASS_MAPPING.get(service_id, "N/A")
        logger.info(f"   - Step {step_id:02d} ({step_class_name}) â†” Service {service_id} ({service_name})")

logger.info("ğŸ¯ Step Utils Layer ì¤€ë¹„ ì™„ë£Œ!")
logger.info("ğŸ—ï¸ step_service.py + step_implementations.py ì™„ë²½ ì§€ì›!")
logger.info("ğŸ¤– BaseStepMixin + ModelLoader + ì‹¤ì œ Step í´ë˜ìŠ¤ ì™„ì „ ì—°ë™!")

# conda í™˜ê²½ ìµœì í™” ìë™ ì‹¤í–‰
if 'CONDA_DEFAULT_ENV' in os.environ:
    setup_conda_optimization()
    logger.info("ğŸ conda í™˜ê²½ ìë™ ìµœì í™” ì™„ë£Œ!")

# ì´ˆê¸° ë©”ëª¨ë¦¬ ìµœì í™”
try:
    memory_helper = get_memory_helper()
    memory_helper.optimize_device_memory(DEVICE)
    logger.info(f"ğŸ’¾ {DEVICE} ì´ˆê¸° ë©”ëª¨ë¦¬ ìµœì í™” ì™„ë£Œ!")
except Exception as e:
    logger.warning(f"âš ï¸ ì´ˆê¸° ë©”ëª¨ë¦¬ ìµœì í™” ì‹¤íŒ¨: {e}")

# ì „ì—­ ìœ í‹¸ë¦¬í‹° ë§¤ë‹ˆì € ì´ˆê¸°í™” (ë™ê¸°ì ìœ¼ë¡œ)
try:
    utils_manager = get_utils_manager()
    logger.info("âœ… ì „ì—­ UtilsManager ì´ˆê¸°í™” ì™„ë£Œ!")
except Exception as e:
    logger.warning(f"âš ï¸ ì „ì—­ UtilsManager ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")

logger.info("ğŸš€ Step Utils Layer v2.0 ì™„ì „ ì¤€ë¹„ ì™„ë£Œ! ğŸš€")