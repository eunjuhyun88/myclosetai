#!/usr/bin/env python3
"""
Step 5ì™€ Step 6 ì²´í¬í¬ì¸íŠ¸ ë¶„ì„ ë„êµ¬
"""

import os
import sys
import torch
import json
import numpy as np
from pathlib import Path
from typing import Dict, Any, List, Optional

def analyze_checkpoint(checkpoint_path: str) -> Dict[str, Any]:
    """ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ì„ ë¶„ì„í•©ë‹ˆë‹¤."""
    try:
        if not os.path.exists(checkpoint_path):
            return {"error": f"íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ: {checkpoint_path}"}
        
        file_size = os.path.getsize(checkpoint_path) / (1024 * 1024)  # MB
        
        # PyTorch ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ ì‹œë„
        try:
            checkpoint = torch.load(checkpoint_path, map_location='cpu')
            
            if isinstance(checkpoint, dict):
                # state_dict í˜•íƒœ
                keys = list(checkpoint.keys())
                total_params = sum(p.numel() for p in checkpoint.values() if hasattr(p, 'numel'))
                
                return {
                    "type": "state_dict",
                    "file_size_mb": round(file_size, 2),
                    "keys": keys,
                    "num_keys": len(keys),
                    "total_params": total_params,
                    "sample_keys": keys[:10] if len(keys) > 10 else keys
                }
            elif hasattr(checkpoint, 'state_dict'):
                # ëª¨ë¸ ê°ì²´
                state_dict = checkpoint.state_dict()
                keys = list(state_dict.keys())
                total_params = sum(p.numel() for p in state_dict.values())
                
                return {
                    "type": "model_object",
                    "file_size_mb": round(file_size, 2),
                    "keys": keys,
                    "num_keys": len(keys),
                    "total_params": total_params,
                    "sample_keys": keys[:10] if len(keys) > 10 else keys
                }
            else:
                return {
                    "type": "unknown",
                    "file_size_mb": round(file_size, 2),
                    "checkpoint_type": str(type(checkpoint))
                }
                
        except Exception as e:
            return {
                "error": f"PyTorch ë¡œë“œ ì‹¤íŒ¨: {str(e)}",
                "file_size_mb": round(file_size, 2)
            }
            
    except Exception as e:
        return {"error": f"ë¶„ì„ ì‹¤íŒ¨: {str(e)}"}

def find_checkpoint_files(directory: str) -> List[str]:
    """ë””ë ‰í† ë¦¬ì—ì„œ ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ë“¤ì„ ì°¾ìŠµë‹ˆë‹¤."""
    checkpoint_files = []
    if os.path.exists(directory):
        for root, dirs, files in os.walk(directory):
            for file in files:
                if file.endswith(('.pth', '.ckpt', '.safetensors')):
                    checkpoint_files.append(os.path.join(root, file))
    return checkpoint_files

def analyze_step5_checkpoints():
    """Step 5 ì²´í¬í¬ì¸íŠ¸ë“¤ì„ ë¶„ì„í•©ë‹ˆë‹¤."""
    print("ğŸ” Step 5 ì²´í¬í¬ì¸íŠ¸ ë¶„ì„ ì‹œì‘...")
    
    step5_path = "ai_models/step_05"
    checkpoint_files = find_checkpoint_files(step5_path)
    
    if not checkpoint_files:
        print("âš ï¸ Step 5 ë””ë ‰í† ë¦¬ì—ì„œ ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return {}
    
    results = {}
    
    for checkpoint_path in checkpoint_files:
        checkpoint_name = os.path.basename(checkpoint_path)
        print(f"\nğŸ“ ë¶„ì„ ì¤‘: {checkpoint_name}")
        
        result = analyze_checkpoint(checkpoint_path)
        results[checkpoint_name] = result
        
        if "error" in result:
            print(f"âŒ {result['error']}")
        else:
            print(f"âœ… íƒ€ì…: {result['type']}")
            print(f"ğŸ“Š í¬ê¸°: {result['file_size_mb']}MB")
            print(f"ğŸ”‘ í‚¤ ê°œìˆ˜: {result['num_keys']}")
            if 'sample_keys' in result:
                print(f"ğŸ”‘ ìƒ˜í”Œ í‚¤: {result['sample_keys'][:3]}")
    
    return results

def analyze_step6_checkpoints():
    """Step 6 ì²´í¬í¬ì¸íŠ¸ë“¤ì„ ë¶„ì„í•©ë‹ˆë‹¤."""
    print("\nğŸ” Step 6 ì²´í¬í¬ì¸íŠ¸ ë¶„ì„ ì‹œì‘...")
    
    step6_path = "ai_models/step_06_virtual_fitting"
    checkpoint_files = find_checkpoint_files(step6_path)
    
    if not checkpoint_files:
        print("âš ï¸ Step 6 ë””ë ‰í† ë¦¬ì—ì„œ ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return {}
    
    results = {}
    
    for checkpoint_path in checkpoint_files[:10]:  # ì²˜ìŒ 10ê°œë§Œ
        checkpoint_name = os.path.basename(checkpoint_path)
        print(f"\nğŸ“ ë¶„ì„ ì¤‘: {checkpoint_name}")
        
        result = analyze_checkpoint(checkpoint_path)
        results[checkpoint_name] = result
        
        if "error" in result:
            print(f"âŒ {result['error']}")
        else:
            print(f"âœ… íƒ€ì…: {result['type']}")
            print(f"ğŸ“Š í¬ê¸°: {result['file_size_mb']}MB")
            print(f"ğŸ”‘ í‚¤ ê°œìˆ˜: {result['num_keys']}")
            if 'sample_keys' in result:
                print(f"ğŸ”‘ ìƒ˜í”Œ í‚¤: {result['sample_keys'][:3]}")
    
    return results

def analyze_safetensors():
    """SafeTensors íŒŒì¼ë“¤ì„ ë¶„ì„í•©ë‹ˆë‹¤."""
    print("\nğŸ” SafeTensors íŒŒì¼ ë¶„ì„ ì‹œì‘...")
    
    step6_path = "ai_models/step_06_virtual_fitting/ootdiffusion"
    
    try:
        from safetensors import safe_open
        
        safetensor_files = []
        for root, dirs, files in os.walk(step6_path):
            for file in files:
                if file.endswith('.safetensors'):
                    safetensor_files.append(os.path.join(root, file))
        
        if not safetensor_files:
            print("âš ï¸ SafeTensors íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return {}
        
        results = {}
        
        for file_path in safetensor_files[:5]:  # ì²˜ìŒ 5ê°œë§Œ
            print(f"\nğŸ“ ë¶„ì„ ì¤‘: {os.path.basename(file_path)}")
            
            try:
                with safe_open(file_path, framework="pt", device="cpu") as f:
                    metadata = f.metadata()
                    tensor_names = f.keys()
                    
                    file_size = os.path.getsize(file_path) / (1024 * 1024)
                    
                    result = {
                        "type": "safetensors",
                        "file_size_mb": round(file_size, 2),
                        "num_tensors": len(tensor_names),
                        "tensor_names": list(tensor_names)[:10],
                        "metadata": metadata
                    }
                    
                    results[os.path.basename(file_path)] = result
                    
                    print(f"âœ… íƒ€ì…: safetensors")
                    print(f"ğŸ“Š í¬ê¸°: {result['file_size_mb']}MB")
                    print(f"ğŸ”‘ í…ì„œ ê°œìˆ˜: {result['num_tensors']}")
                    print(f"ğŸ”‘ ìƒ˜í”Œ í…ì„œ: {result['tensor_names'][:3]}")
                    
            except Exception as e:
                print(f"âŒ SafeTensors ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
                results[os.path.basename(file_path)] = {"error": str(e)}
                
    except ImportError:
        print("âš ï¸ SafeTensors ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ")
        return {}
    
    return results

def main():
    """ë©”ì¸ ë¶„ì„ í•¨ìˆ˜"""
    print("ğŸš€ Step 5 & Step 6 ì²´í¬í¬ì¸íŠ¸ ë¶„ì„ ë„êµ¬")
    print("=" * 50)
    
    # Step 5 ë¶„ì„
    step5_results = analyze_step5_checkpoints()
    
    # Step 6 ë¶„ì„  
    step6_results = analyze_step6_checkpoints()
    
    # SafeTensors ë¶„ì„
    safetensor_results = analyze_safetensors()
    
    # ê²°ê³¼ ì €ì¥
    all_results = {
        "step5": step5_results,
        "step6": step6_results,
        "safetensors": safetensor_results
    }
    
    with open("step5_step6_checkpoint_analysis.json", "w", encoding="utf-8") as f:
        json.dump(all_results, f, indent=2, ensure_ascii=False)
    
    print(f"\nğŸ“Š ë¶„ì„ ì™„ë£Œ! ê²°ê³¼ê°€ step5_step6_checkpoint_analysis.jsonì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    # ìš”ì•½ ì¶œë ¥
    print("\nğŸ“‹ ë¶„ì„ ìš”ì•½:")
    print(f"Step 5 ì²´í¬í¬ì¸íŠ¸: {len(step5_results)}ê°œ")
    print(f"Step 6 ì²´í¬í¬ì¸íŠ¸: {len(step6_results)}ê°œ") 
    print(f"SafeTensors íŒŒì¼: {len(safetensor_results)}ê°œ")

if __name__ == "__main__":
    main()
