{
  "timestamp": 1753894271.252482,
  "debug_version": "4.0",
  "system_analysis": {
    "cpu_info": {
      "physical_cores": 16,
      "logical_cores": 16,
      "usage_percent": 4.7,
      "architecture": "arm64",
      "processor": "arm",
      "is_apple_silicon": true
    },
    "memory_info": {
      "total_gb": 128.0,
      "available_gb": 68.13876342773438,
      "used_gb": 49.15199279785156,
      "usage_percent": 46.8,
      "sufficient_for_ai": true
    },
    "pytorch_info": {
      "available": true,
      "version": "2.7.1",
      "cuda_available": false,
      "cuda_version": null,
      "mps_available": true,
      "device_count": 0
    },
    "project_structure": {
      "project_root": "/Users/gimdudeul/MVP/mycloset-ai",
      "backend_exists": true,
      "frontend_exists": true,
      "ai_models_dir": "/Users/gimdudeul/MVP/mycloset-ai/backend/ai_models",
      "ai_models_size_gb": 171.33390284702182,
      "step_modules": [
        "step_06_virtual_fitting",
        "step_05_cloth_warping",
        "step_04_geometric_matching",
        "step_03_cloth_segmentation",
        "step_02_pose_estimation",
        "step_08_quality_assessment",
        "step_01_human_parsing",
        "step_07_post_processing"
      ]
    },
    "dependencies_status": {
      "torch": true,
      "torchvision": true,
      "numpy": true,
      "PIL": true,
      "cv2": true,
      "transformers": true,
      "safetensors": true
    },
    "recommendations": {
      "is_m3_max": true,
      "memory_sufficient": true,
      "recommended_device": "mps"
    }
  },
  "step_analyses": {
    "HumanParsingStep": {
      "basic_info": {
        "step_name": "HumanParsingStep",
        "step_id": 1,
        "module_path": "app.ai_pipeline.steps.step_01_human_parsing",
        "class_name": "HumanParsingStep"
      },
      "import_analysis": {
        "success": true,
        "time": 1.8567290306091309,
        "errors": []
      },
      "class_analysis": {
        "found": true,
        "is_base_step_mixin": true,
        "has_process_method": true,
        "has_initialize_method": true
      },
      "instance_analysis": {
        "created": true,
        "dependencies": {
          "device": "mps",
          "strict_mode": false
        },
        "errors": []
      },
      "initialization": {
        "success": true,
        "time": 0.0003991127014160156,
        "errors": []
      },
      "ai_models": {
        "detected": [
          "graphonomy_fixed.pth",
          "graphonomy_new.pth",
          "deeplab_resnet101.pth",
          "fcn_resnet101_ultra.pth",
          "pytorch_model.bin",
          "pytorch_model.bin"
        ],
        "total_size_gb": 0.9860186707228422,
        "checkpoint_count": 6,
        "successful_checkpoints": 0
      },
      "performance": {
        "memory_footprint_mb": 0.0,
        "health_score": 90.0
      },
      "status": "success"
    },
    "PoseEstimationStep": {
      "basic_info": {
        "step_name": "PoseEstimationStep",
        "step_id": 2,
        "module_path": "app.ai_pipeline.steps.step_02_pose_estimation",
        "class_name": "PoseEstimationStep"
      },
      "import_analysis": {
        "success": true,
        "time": 5.0067901611328125e-06,
        "errors": []
      },
      "class_analysis": {
        "found": true,
        "is_base_step_mixin": true,
        "has_process_method": true,
        "has_initialize_method": true
      },
      "instance_analysis": {
        "created": true,
        "dependencies": {
          "device": "mps",
          "strict_mode": false
        },
        "errors": []
      },
      "initialization": {
        "success": true,
        "time": 0.11531186103820801,
        "errors": []
      },
      "ai_models": {
        "detected": [
          "yolov8s-pose.pt",
          "diffusion_pytorch_model.fp16.safetensors",
          "diffusion_pytorch_model.safetensors",
          "diffusion_pytorch_model.fp16.bin",
          "diffusion_pytorch_model.bin"
        ],
        "total_size_gb": 4.059839207679033,
        "checkpoint_count": 5,
        "successful_checkpoints": 3
      },
      "performance": {
        "memory_footprint_mb": 0.0,
        "health_score": 100.0
      },
      "status": "success"
    },
    "ClothSegmentationStep": {
      "basic_info": {
        "step_name": "ClothSegmentationStep",
        "step_id": 3,
        "module_path": "app.ai_pipeline.steps.step_03_cloth_segmentation",
        "class_name": "ClothSegmentationStep"
      },
      "import_analysis": {
        "success": true,
        "time": 6.198883056640625e-06,
        "errors": []
      },
      "class_analysis": {
        "found": true,
        "is_base_step_mixin": true,
        "has_process_method": true,
        "has_initialize_method": true
      },
      "instance_analysis": {
        "created": true,
        "dependencies": {
          "device": "mps",
          "strict_mode": false
        },
        "errors": []
      },
      "initialization": {
        "success": true,
        "time": 0.0001690387725830078,
        "errors": []
      },
      "ai_models": {
        "detected": [
          "u2net.pth",
          "sam_vit_h_4b8939.pth",
          "deeplabv3_resnet101_ultra.pth",
          "mobile_sam.pt",
          "mobile_sam.pt",
          "pytorch_model.bin",
          "pytorch_model.bin"
        ],
        "total_size_gb": 5.282956561073661,
        "checkpoint_count": 7,
        "successful_checkpoints": 0
      },
      "performance": {
        "memory_footprint_mb": 0.0,
        "health_score": 90.0
      },
      "status": "success"
    },
    "GeometricMatchingStep": {
      "basic_info": {
        "step_name": "GeometricMatchingStep",
        "step_id": 4,
        "module_path": "app.ai_pipeline.steps.step_04_geometric_matching",
        "class_name": "GeometricMatchingStep"
      },
      "import_analysis": {
        "success": true,
        "time": 8.821487426757812e-06,
        "errors": []
      },
      "class_analysis": {
        "found": true,
        "is_base_step_mixin": true,
        "has_process_method": true,
        "has_initialize_method": true
      },
      "instance_analysis": {
        "created": true,
        "dependencies": {
          "device": "mps",
          "strict_mode": false
        },
        "errors": []
      },
      "initialization": {
        "success": true,
        "time": 0.39511561393737793,
        "errors": []
      },
      "ai_models": {
        "detected": [
          "raft-things.pth",
          "sam_vit_h_4b8939.pth",
          "resnet101_geometric.pth",
          "resnet50_geometric_ultra.pth",
          "efficientnet_b0_ultra.pth",
          "RealESRGAN_x4plus.pth",
          "raft-things.pth",
          "raft-chairs.pth",
          "raft-kitti.pth",
          "raft-sintel.pth"
        ],
        "total_size_gb": 0.792038531973958,
        "checkpoint_count": 10,
        "successful_checkpoints": 0
      },
      "performance": {
        "memory_footprint_mb": 0.0,
        "health_score": 90.0
      },
      "status": "success"
    },
    "ClothWarpingStep": {
      "basic_info": {
        "step_name": "ClothWarpingStep",
        "step_id": 5,
        "module_path": "app.ai_pipeline.steps.step_05_cloth_warping",
        "class_name": "ClothWarpingStep"
      },
      "import_analysis": {
        "success": true,
        "time": 4.0531158447265625e-06,
        "errors": []
      },
      "class_analysis": {
        "found": true,
        "is_base_step_mixin": true,
        "has_process_method": true,
        "has_initialize_method": true
      },
      "instance_analysis": {
        "created": true,
        "dependencies": {
          "device": "mps",
          "strict_mode": false
        },
        "errors": []
      },
      "initialization": {
        "success": true,
        "time": 0.4684610366821289,
        "errors": []
      },
      "ai_models": {
        "detected": [
          "RealESRGAN_x4plus.pth",
          "vgg19_warping.pth",
          "vgg16_warping_ultra.pth",
          "densenet121_ultra.pth",
          "model.fp16.safetensors",
          "diffusion_pytorch_model.bin"
        ],
        "total_size_gb": 4.91190049238503,
        "checkpoint_count": 6,
        "successful_checkpoints": 1
      },
      "performance": {
        "memory_footprint_mb": 0.0,
        "health_score": 100.0
      },
      "status": "success"
    },
    "VirtualFittingStep": {
      "basic_info": {
        "step_name": "VirtualFittingStep",
        "step_id": 6,
        "module_path": "app.ai_pipeline.steps.step_06_virtual_fitting",
        "class_name": "VirtualFittingStep"
      },
      "import_analysis": {
        "success": true,
        "time": 8.821487426757812e-06,
        "errors": []
      },
      "class_analysis": {
        "found": true,
        "is_base_step_mixin": true,
        "has_process_method": true,
        "has_initialize_method": true
      },
      "instance_analysis": {
        "created": true,
        "dependencies": {
          "device": "mps",
          "strict_mode": false
        },
        "errors": []
      },
      "initialization": {
        "success": true,
        "time": 5.798722982406616,
        "errors": []
      },
      "ai_models": {
        "detected": [
          "body_pose_model.pth",
          "exp-schp-201908301523-atr.pth",
          "diffusion_pytorch_model.safetensors",
          "diffusion_pytorch_model.safetensors",
          "diffusion_pytorch_model.safetensors",
          "diffusion_pytorch_model.safetensors",
          "diffusion_pytorch_model.safetensors",
          "diffusion_pytorch_model.safetensors",
          "pytorch_model.bin"
        ],
        "total_size_gb": 22.906142168678343,
        "checkpoint_count": 9,
        "successful_checkpoints": 6
      },
      "performance": {
        "memory_footprint_mb": 0.0,
        "health_score": 100.0
      },
      "status": "success"
    },
    "PostProcessingStep": {
      "basic_info": {
        "step_name": "PostProcessingStep",
        "step_id": 7,
        "module_path": "app.ai_pipeline.steps.step_07_post_processing",
        "class_name": "PostProcessingStep"
      },
      "import_analysis": {
        "success": true,
        "time": 5.245208740234375e-06,
        "errors": []
      },
      "class_analysis": {
        "found": true,
        "is_base_step_mixin": true,
        "has_process_method": true,
        "has_initialize_method": true
      },
      "instance_analysis": {
        "created": true,
        "dependencies": {
          "device": "mps",
          "strict_mode": false
        },
        "errors": []
      },
      "initialization": {
        "success": true,
        "time": 1.498840093612671,
        "errors": []
      },
      "ai_models": {
        "detected": [
          "ESRGAN_x8.pth",
          "densenet161_enhance.pth",
          "mobilenet_v3_ultra.pth",
          "resnet101_enhance_ultra.pth",
          "RealESRGAN_x2plus.pth",
          "001_classicalSR_DIV2K_s48w8_SwinIR-M_x4.pth",
          "RealESRGAN_x4plus.pth",
          "pytorch_model.bin",
          "pytorch_model.bin"
        ],
        "total_size_gb": 2.215636385604739,
        "checkpoint_count": 9,
        "successful_checkpoints": 0
      },
      "performance": {
        "memory_footprint_mb": 0.0,
        "health_score": 90.0
      },
      "status": "success"
    },
    "QualityAssessmentStep": {
      "basic_info": {
        "step_name": "QualityAssessmentStep",
        "step_id": 8,
        "module_path": "app.ai_pipeline.steps.step_08_quality_assessment",
        "class_name": "QualityAssessmentStep"
      },
      "import_analysis": {
        "success": true,
        "time": 5.7220458984375e-06,
        "errors": []
      },
      "class_analysis": {
        "found": true,
        "is_base_step_mixin": true,
        "has_process_method": true,
        "has_initialize_method": true
      },
      "instance_analysis": {
        "created": true,
        "dependencies": {
          "device": "mps",
          "strict_mode": false
        },
        "errors": []
      },
      "initialization": {
        "success": true,
        "time": 0.059034109115600586,
        "errors": []
      },
      "ai_models": {
        "detected": [
          "clip_vit_b32.pth",
          "ViT-B-32.pt",
          "ViT-L-14.pt",
          "pytorch_model.bin",
          "open_clip_pytorch_model.bin",
          "open_clip_pytorch_model.bin",
          "pytorch_model.bin"
        ],
        "total_size_gb": 14.10200430918485,
        "checkpoint_count": 7,
        "successful_checkpoints": 0
      },
      "performance": {
        "memory_footprint_mb": 0.0,
        "health_score": 90.0
      },
      "status": "success"
    }
  },
  "overall_summary": {
    "steps": {
      "total": 8,
      "successful": 8,
      "success_rate": 100.0
    },
    "models": {
      "total_detected": 59,
      "total_size_gb": 55.256536327302456,
      "successful_checkpoints": 10,
      "total_checkpoints": 59,
      "checkpoint_success_rate": 16.94915254237288
    },
    "health": {
      "average_score": 93.75,
      "system_ready": true,
      "ai_ready": true
    }
  },
  "critical_issues": [],
  "recommendations": [
    "💾 메모리 최적화: 55.3GB 모델 - 배치 크기 조정 및 캐싱 전략 필요",
    "🔧 PyTorch 호환성: 2개 체크포인트에서 weights_only 문제 - PyTorch 업데이트 필요"
  ],
  "performance_metrics": {
    "total_analysis_time_seconds": 33.35351490974426,
    "average_step_analysis_time": 1.2741033434867859,
    "system_analysis_efficiency": "efficient",
    "memory_usage_peak_gb": 1.425750732421875
  }
}