#!/usr/bin/env python3
"""
ëŒ€ì•ˆ graphonomy íŒŒì¼ ì°¾ê¸° ë° í…ŒìŠ¤íŠ¸
"""

import os
from pathlib import Path
import torch

def find_alternative_graphonomy():
    """ë‹¤ë¥¸ graphonomy ê´€ë ¨ íŒŒì¼ë“¤ ì°¾ê¸°"""
    print("ğŸ” ëŒ€ì•ˆ graphonomy íŒŒì¼ ì°¾ê¸°")
    print("=" * 50)
    
    current_dir = Path.cwd()
    ai_models_dir = current_dir / "ai_models"
    
    # graphonomy ê´€ë ¨ ëª¨ë“  íŒŒì¼ ì°¾ê¸°
    graphonomy_files = []
    
    if ai_models_dir.exists():
        # ë‹¤ì–‘í•œ ì´ë¦„ìœ¼ë¡œ ê²€ìƒ‰
        search_patterns = [
            "*graphonomy*",
            "*parsing*",
            "*schp*",
            "*human*parsing*",
            "*lip*",
            "*atr*"
        ]
        
        for pattern in search_patterns:
            for file_path in ai_models_dir.rglob(pattern):
                if file_path.is_file() and file_path.suffix in ['.pth', '.bin', '.safetensors']:
                    graphonomy_files.append(file_path)
    
    # ì¤‘ë³µ ì œê±° ë° í¬ê¸° ì •ë³´ ì¶”ê°€
    unique_files = {}
    for file_path in graphonomy_files:
        key = str(file_path.resolve())
        if key not in unique_files:
            size_mb = file_path.stat().st_size / (1024**2)
            unique_files[key] = {
                'path': file_path,
                'size_mb': size_mb
            }
    
    # í¬ê¸°ë³„ë¡œ ì •ë ¬
    sorted_files = sorted(unique_files.values(), key=lambda x: x['size_mb'], reverse=True)
    
    print(f"ğŸ“Š ë°œê²¬ëœ íŒŒì¼ë“¤ ({len(sorted_files)}ê°œ):")
    for i, file_info in enumerate(sorted_files[:10]):  # ìƒìœ„ 10ê°œë§Œ
        file_path = file_info['path']
        size_mb = file_info['size_mb']
        
        # íŒŒì¼ ìƒíƒœ í™•ì¸
        status = "ğŸ”¥ ëŒ€í˜•" if size_mb > 100 else "ğŸ“¦ ì¤‘í˜•" if size_mb > 10 else "ğŸ“„ ì†Œí˜•"
        
        print(f"   {i+1}. {file_path.name}")
        print(f"      ê²½ë¡œ: {file_path}")
        print(f"      í¬ê¸°: {size_mb:.1f}MB {status}")
        
        # ë¡œë”© í…ŒìŠ¤íŠ¸
        if size_mb > 10:  # 10MB ì´ìƒë§Œ í…ŒìŠ¤íŠ¸
            test_result = test_file_loading(file_path)
            print(f"      ë¡œë”©: {test_result}")
        
        print()
    
    # ê¶Œì¥ì‚¬í•­ ì œì‹œ
    print("ğŸ’¡ ê¶Œì¥ì‚¬í•­:")
    
    # ê°€ì¥ í° íŒŒì¼ì´ í˜„ì¬ ë¬¸ì œ íŒŒì¼ì¸ì§€ í™•ì¸
    if sorted_files:
        largest_file = sorted_files[0]
        if "graphonomy.pth" in str(largest_file['path']):
            print("   1. í˜„ì¬ íŒŒì¼ì´ ì†ìƒëœ ê²ƒ ê°™ìŠµë‹ˆë‹¤")
            
            # ë‘ ë²ˆì§¸ë¡œ í° íŒŒì¼ ì°¾ê¸°
            for file_info in sorted_files[1:]:
                if file_info['size_mb'] > 100:
                    alternative_path = file_info['path']
                    print(f"   2. ëŒ€ì•ˆ íŒŒì¼ ì‚¬ìš© ê¶Œì¥: {alternative_path.name}")
                    print(f"      â†’ ì´ íŒŒì¼ì„ graphonomy.pthë¡œ ë³µì‚¬í•˜ì„¸ìš”")
                    
                    # ë³µì‚¬ ëª…ë ¹ì–´ ì œì‹œ
                    source = alternative_path
                    target = current_dir / "ai_models" / "step_01_human_parsing" / "graphonomy_backup.pth"
                    print(f"   3. ë³µì‚¬ ëª…ë ¹ì–´:")
                    print(f"      cp '{source}' '{target}'")
                    break
            
        print("   4. ë˜ëŠ” ì˜¨ë¼ì¸ì—ì„œ ìƒˆë¡œìš´ graphonomy.pth ë‹¤ìš´ë¡œë“œ")
        print("      - Hugging Face: https://huggingface.co/models?search=graphonomy")
        print("      - GitHub: https://github.com/Engineering-Course/LIP_SSL")
    
    return sorted_files

def test_file_loading(file_path: Path) -> str:
    """íŒŒì¼ ë¡œë”© í…ŒìŠ¤íŠ¸"""
    try:
        # ë¹ ë¥¸ í—¤ë” ì²´í¬
        with open(file_path, 'rb') as f:
            header = f.read(100)
        
        # ZIP í˜•ì‹ í™•ì¸
        if header.startswith(b'PK'):
            return "âœ… ZIP í˜•ì‹ (PyTorch í‘œì¤€)"
        elif b'torch' in header[:50]:
            return "âœ… Torch í˜•ì‹"
        elif header.startswith(b'\x80'):
            return "âœ… Pickle í˜•ì‹"
        else:
            return "â“ ì•Œ ìˆ˜ ì—†ëŠ” í˜•ì‹"
            
    except Exception as e:
        return f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}"

if __name__ == "__main__":
    find_alternative_graphonomy()