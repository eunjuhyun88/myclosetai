#!/usr/bin/env python3
"""
ğŸ” Auto Detector ë””ë²„ê¹… ìŠ¤í¬ë¦½íŠ¸
ì™œ 923ê°œ ëª¨ë¸ì´ ìˆëŠ”ë° ëª» ì°¾ëŠ”ì§€ ì •í™•í•œ ì›ì¸ íŒŒì•…
"""

import os
import sys
from pathlib import Path

# í”„ë¡œì íŠ¸ ê²½ë¡œ ì„¤ì • (í˜„ì¬ ìœ„ì¹˜ ê³ ë ¤)
current_dir = Path.cwd()
if current_dir.name == "backend":
    # backend ë””ë ‰í† ë¦¬ ì•ˆì—ì„œ ì‹¤í–‰í•œ ê²½ìš°
    project_root = current_dir.parent
    sys.path.insert(0, str(current_dir))
else:
    # í”„ë¡œì íŠ¸ ë£¨íŠ¸ì—ì„œ ì‹¤í–‰í•œ ê²½ìš°
    project_root = current_dir
    sys.path.insert(0, str(project_root / "backend"))

print(f"ğŸ“ í˜„ì¬ ìœ„ì¹˜: {current_dir}")
print(f"ğŸ“ í”„ë¡œì íŠ¸ ë£¨íŠ¸: {project_root}")

def debug_search_paths():
    """Auto Detector ê²€ìƒ‰ ê²½ë¡œ ë””ë²„ê¹…"""
    
    print("ğŸ” Auto Detector ê²€ìƒ‰ ê²½ë¡œ ë””ë²„ê¹…")
    print("=" * 50)
    
    # ì˜ˆìƒ ê²€ìƒ‰ ê²½ë¡œë“¤
    backend_dir = project_root / "backend"
    
    expected_paths = [
        backend_dir / "ai_models",
        backend_dir / "ai_models" / "checkpoints", 
        backend_dir / "app" / "ai_pipeline" / "models",
        backend_dir / "app" / "models",
        backend_dir / "checkpoints",
        backend_dir / "models",
        backend_dir / "weights",
        backend_dir.parent / "ai_models",
        Path.home() / ".cache" / "huggingface" / "hub",
    ]
    
    print("ğŸ“‚ Auto Detectorê°€ ê²€ìƒ‰í•  ê²½ë¡œë“¤:")
    for i, path in enumerate(expected_paths, 1):
        exists = "âœ…" if path.exists() else "âŒ"
        if path.exists():
            file_count = len(list(path.rglob("*.pth")))
            print(f"   {i:2d}. {exists} {path} ({file_count}ê°œ .pth íŒŒì¼)")
        else:
            print(f"   {i:2d}. {exists} {path} (ê²½ë¡œ ì—†ìŒ)")
    
    return expected_paths

def debug_actual_auto_detector():
    """ì‹¤ì œ Auto Detector ì‹¤í–‰í•´ë³´ê¸°"""
    
    print("\nğŸ¤– ì‹¤ì œ Auto Detector ì‹¤í–‰ í…ŒìŠ¤íŠ¸")
    print("=" * 50)
    
    try:
        # Auto Detector import
        from backend.app.ai_pipeline.utils.auto_model_detector import RealWorldModelDetector
        
        print("âœ… Auto Detector import ì„±ê³µ")
        
        # ë””ë²„ê·¸ ëª¨ë“œë¡œ ì‹¤í–‰
        detector = RealWorldModelDetector(
            enable_deep_scan=True,
            enable_pytorch_validation=False,  # ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ ë¹„í™œì„±í™”
            max_workers=1
        )
        
        print(f"âœ… Auto Detector ì´ˆê¸°í™” ì„±ê³µ")
        print(f"   ê²€ìƒ‰ ê²½ë¡œ ìˆ˜: {len(detector.search_paths)}")
        
        # ê²€ìƒ‰ ê²½ë¡œ ì¶œë ¥
        print("\nğŸ” ì‹¤ì œ ê²€ìƒ‰ ê²½ë¡œ:")
        for i, path in enumerate(detector.search_paths, 1):
            exists = "âœ…" if path.exists() else "âŒ"
            if path.exists():
                file_count = len(list(path.rglob("*.pth")))
                print(f"   {i:2d}. {exists} {path} ({file_count}ê°œ .pth)")
            else:
                print(f"   {i:2d}. {exists} {path} (ì—†ìŒ)")
        
        # ì‹¤ì œ íƒì§€ ì‹¤í–‰
        print("\nğŸ”„ ëª¨ë¸ íƒì§€ ì‹¤í–‰ ì¤‘...")
        detected_models = detector.detect_all_models(
            force_rescan=True,
            min_confidence=0.1,  # ë‚®ì€ ì„ê³„ê°’
            enable_detailed_analysis=False
        )
        
        if detected_models:
            print(f"ğŸ‰ íƒì§€ ì„±ê³µ: {len(detected_models)}ê°œ ëª¨ë¸ ë°œê²¬!")
            
            # ìƒìœ„ 10ê°œ ëª¨ë¸ ì¶œë ¥
            print("\nğŸ“‹ íƒì§€ëœ ëª¨ë¸ë“¤ (ìƒìœ„ 10ê°œ):")
            for i, (name, model) in enumerate(list(detected_models.items())[:10], 1):
                print(f"   {i:2d}. {name}")
                print(f"       ğŸ“ {model.path}")
                print(f"       ğŸ“Š {model.file_size_mb:.1f}MB")
                print(f"       ğŸ¯ {model.step_name}")
                print("")
        else:
            print("âŒ ëª¨ë¸ì„ í•˜ë‚˜ë„ ì°¾ì§€ ëª»í•¨!")
            
            # ì›ì¸ ë¶„ì„
            print("\nğŸ” ì›ì¸ ë¶„ì„:")
            print("1. ê²€ìƒ‰ ê²½ë¡œ ë¬¸ì œì¸ì§€ í™•ì¸...")
            
            # ìˆ˜ë™ìœ¼ë¡œ í™•ì¸
            manual_search_path = project_root / "backend/app/ai_pipeline/models/checkpoints"
            if manual_search_path.exists():
                manual_files = list(manual_search_path.rglob("*.pth"))
                print(f"   âœ… ìˆ˜ë™ ê²€ìƒ‰: {len(manual_files)}ê°œ .pth íŒŒì¼ ë°œê²¬")
                
                if manual_files:
                    print("   ğŸ“‹ ì²« 5ê°œ íŒŒì¼:")
                    for file in manual_files[:5]:
                        print(f"      ğŸ“„ {file.name} ({file.stat().st_size / 1024 / 1024:.1f}MB)")
            else:
                print("   âŒ ìˆ˜ë™ ê²€ìƒ‰ ê²½ë¡œë„ ì—†ìŒ")
        
        return detected_models
        
    except ImportError as e:
        print(f"âŒ Auto Detector import ì‹¤íŒ¨: {e}")
        return None
    except Exception as e:
        print(f"âŒ Auto Detector ì‹¤í–‰ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        return None

def debug_model_files_directly():
    """ëª¨ë¸ íŒŒì¼ë“¤ ì§ì ‘ í™•ì¸"""
    
    print("\nğŸ“ ëª¨ë¸ íŒŒì¼ ì§ì ‘ í™•ì¸")
    print("=" * 50)
    
    # ì•Œë ¤ì§„ ëª¨ë¸ ìœ„ì¹˜
    model_locations = [
        project_root / "backend/app/ai_pipeline/models/checkpoints",
        project_root / "backend/app/ai_pipeline/models/ai_models/checkpoints",
        project_root / "backend/ai_models/checkpoints",
        project_root / "ai_models",
    ]
    
    total_files = 0
    
    for location in model_locations:
        if location.exists():
            pth_files = list(location.rglob("*.pth"))
            safetensors_files = list(location.rglob("*.safetensors"))
            bin_files = list(location.rglob("*.bin"))
            
            file_count = len(pth_files) + len(safetensors_files) + len(bin_files)
            total_files += file_count
            
            print(f"ğŸ“‚ {location}")
            print(f"   ğŸ“„ .pth: {len(pth_files)}ê°œ")
            print(f"   ğŸ“„ .safetensors: {len(safetensors_files)}ê°œ") 
            print(f"   ğŸ“„ .bin: {len(bin_files)}ê°œ")
            print(f"   ğŸ“Š ì´í•©: {file_count}ê°œ")
            
            if file_count > 0:
                # Stepë³„ ë¶„ì„
                step_dirs = [d for d in location.iterdir() if d.is_dir() and d.name.startswith('step_')]
                if step_dirs:
                    print(f"   ğŸ“ Step ë””ë ‰í† ë¦¬: {len(step_dirs)}ê°œ")
                    for step_dir in step_dirs[:3]:  # ìƒìœ„ 3ê°œë§Œ
                        step_files = len(list(step_dir.rglob("*.pth")))
                        print(f"      ğŸ“ {step_dir.name}: {step_files}ê°œ íŒŒì¼")
            print("")
    
    print(f"ğŸ¯ ì´ ë°œê²¬ëœ ëª¨ë¸ íŒŒì¼: {total_files}ê°œ")
    
    return total_files

def debug_auto_detector_filters():
    """Auto Detector í•„í„° ì„¤ì • í™•ì¸"""
    
    print("\nğŸ”§ Auto Detector í•„í„° ì„¤ì • í™•ì¸")
    print("=" * 50)
    
    try:
        from backend.app.ai_pipeline.utils.auto_model_detector import RealWorldModelDetector
        
        # í•„í„° ì—†ì´ ëª¨ë“  íŒŒì¼ íƒì§€
        detector = RealWorldModelDetector(
            enable_deep_scan=True,
            enable_pytorch_validation=False,
            max_workers=1
        )
        
        # ë‚´ë¶€ ë©”ì„œë“œ ì§ì ‘ í˜¸ì¶œ
        search_path = project_root / "backend/app/ai_pipeline/models/checkpoints"
        
        if hasattr(detector, '_scan_path_for_enhanced_models'):
            print(f"ğŸ” ì§ì ‘ ê²½ë¡œ ìŠ¤ìº”: {search_path}")
            
            # ëª¨ë“  ì¹´í…Œê³ ë¦¬ í—ˆìš©
            from backend.app.ai_pipeline.utils.auto_model_detector import ModelCategory
            all_categories = list(ModelCategory)
            
            results = detector._scan_path_for_enhanced_models(
                model_type="all",
                pattern_info=None,
                search_path=search_path,
                categories_filter=all_categories,
                min_confidence=0.0,  # ìµœì†Œ ì„ê³„ê°’
                enable_detailed_analysis=False
            )
            
            print(f"ğŸ“Š ì§ì ‘ ìŠ¤ìº” ê²°ê³¼: {len(results)}ê°œ ëª¨ë¸")
            
            for name, model in list(results.items())[:5]:
                print(f"   ğŸ“„ {name}: {model.path}")
        
        else:
            print("âŒ _scan_path_for_enhanced_models ë©”ì„œë“œ ì—†ìŒ")
            
    except Exception as e:
        print(f"âŒ í•„í„° ë””ë²„ê¹… ì‹¤íŒ¨: {e}")

def suggest_fixes():
    """ë¬¸ì œ í•´ê²° ë°©ì•ˆ ì œì‹œ"""
    
    print("\nğŸ’¡ ë¬¸ì œ í•´ê²° ë°©ì•ˆ")
    print("=" * 50)
    
    print("ğŸ”§ ê°€ëŠ¥í•œ ì›ì¸ë“¤:")
    print("1. Auto Detector í•„í„°ê°€ ë„ˆë¬´ ì—„ê²©í•¨")
    print("2. íŒŒì¼ ê¶Œí•œ ë¬¸ì œ")
    print("3. íŒŒì¼ ì´ë¦„ íŒ¨í„´ ë§¤ì¹­ ì‹¤íŒ¨")
    print("4. PyTorch ê²€ì¦ ê³¼ì •ì—ì„œ ì˜¤ë¥˜")
    print("5. ë©”ëª¨ë¦¬ ë¶€ì¡±ìœ¼ë¡œ ìŠ¤ìº” ì¤‘ë‹¨")
    
    print("\nğŸš€ ì¦‰ì‹œ ì‹œë„í•  í•´ê²°ì±…:")
    print("1. Auto Detector ê°•ì œ ì¬ìŠ¤ìº”:")
    print("   detector.detect_all_models(force_rescan=True, min_confidence=0.0)")
    
    print("\n2. ì§ì ‘ ëª¨ë¸ ë“±ë¡:")
    print("   ModelLoaderì— ìˆ˜ë™ìœ¼ë¡œ ëª¨ë¸ ê²½ë¡œ ë“±ë¡")
    
    print("\n3. í™˜ê²½ ë³€ìˆ˜ ì„¤ì •:")
    print("   export AI_MODELS_ROOT=/path/to/models")

def main():
    """ë©”ì¸ ë””ë²„ê¹… í•¨ìˆ˜"""
    
    print("ğŸ” MyCloset AI Auto Detector ë””ë²„ê¹…")
    print("=" * 60)
    print("923ê°œ ëª¨ë¸ì´ ìˆëŠ”ë° ì™œ ëª» ì°¾ëŠ”ì§€ ì›ì¸ íŒŒì•…")
    print("")
    
    # 1. ê²€ìƒ‰ ê²½ë¡œ í™•ì¸
    debug_search_paths()
    
    # 2. ëª¨ë¸ íŒŒì¼ ì§ì ‘ í™•ì¸
    total_files = debug_model_files_directly()
    
    if total_files > 0:
        # 3. Auto Detector ì‹¤ì œ ì‹¤í–‰
        detected = debug_actual_auto_detector()
        
        # 4. í•„í„° ì„¤ì • í™•ì¸
        if not detected:
            debug_auto_detector_filters()
        
        # 5. í•´ê²° ë°©ì•ˆ ì œì‹œ
        suggest_fixes()
    else:
        print("âŒ ëª¨ë¸ íŒŒì¼ì„ ì „í˜€ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")
        print("tree backend/app/ai_pipeline/models ëª…ë ¹ìœ¼ë¡œ í™•ì¸í•˜ì„¸ìš”.")

if __name__ == "__main__":
    main()