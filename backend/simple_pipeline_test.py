# simple_pipeline_test.py
"""
ê°„ë‹¨í•œ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸ - ìµœì  ìƒì„±ì íŒ¨í„´ ì ìš©
ì‹¤ì œ ë‹¤ìš´ë¡œë“œëœ ëª¨ë¸ë“¤ë¡œ ê¸°ë³¸ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸
"""

import os
import sys
import time
import json
import logging
from pathlib import Path
from typing import Dict, Any, Optional, List
import numpy as np
from PIL import Image
import torch

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')
logger = logging.getLogger(__name__)

class SimpleModelTester:
    """ê°„ë‹¨í•œ ëª¨ë¸ í…ŒìŠ¤í„°"""
    
    def __init__(self):
        self.base_dir = Path("ai_models/checkpoints")
        self.models = {}
        self.test_results = {}
        
        # í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ìƒì„± (ë”ë¯¸)
        self.test_image = self._create_test_image()
        
    def _create_test_image(self) -> Image.Image:
        """í…ŒìŠ¤íŠ¸ìš© ë”ë¯¸ ì´ë¯¸ì§€ ìƒì„±"""
        # 512x512 RGB ì´ë¯¸ì§€ ìƒì„±
        image_array = np.random.randint(0, 255, (512, 512, 3), dtype=np.uint8)
        return Image.fromarray(image_array)
    
    def test_segformer_human_parsing(self) -> bool:
        """Segformer ì¸ì²´ íŒŒì‹± í…ŒìŠ¤íŠ¸"""
        try:
            print("\nğŸ¯ Segformer ì¸ì²´ íŒŒì‹± í…ŒìŠ¤íŠ¸...")
            
            model_path = self.base_dir / "step_01_human_parsing/segformer_b2_clothes"
            if not model_path.exists():
                logger.warning("Segformer ëª¨ë¸ ì—†ìŒ")
                return False
            
            from transformers import SegformerImageProcessor, SegformerForSemanticSegmentation
            
            # ëª¨ë¸ ë¡œë”©
            processor = SegformerImageProcessor.from_pretrained(str(model_path))
            model = SegformerForSemanticSegmentation.from_pretrained(str(model_path))
            
            # ì¶”ë¡  í…ŒìŠ¤íŠ¸
            inputs = processor(images=self.test_image, return_tensors="pt")
            
            with torch.no_grad():
                outputs = model(**inputs)
                logits = outputs.logits
            
            logger.info(f"âœ… ì¶œë ¥ í˜•íƒœ: {logits.shape}")
            logger.info("âœ… Segformer ì¸ì²´ íŒŒì‹±: í†µê³¼")
            
            self.models['human_parsing'] = {
                'status': 'ready',
                'type': 'segformer_b2',
                'output_shape': str(logits.shape)
            }
            return True
            
        except Exception as e:
            logger.error(f"âŒ Segformer í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
            self.models['human_parsing'] = {'status': 'failed', 'error': str(e)}
            return False
    
    def test_u2net_onnx(self) -> bool:
        """UÂ²-Net ONNX í…ŒìŠ¤íŠ¸"""
        try:
            print("\nğŸ¯ UÂ²-Net ONNX í…ŒìŠ¤íŠ¸...")
            
            model_path = self.base_dir / "step_03_cloth_segmentation/u2net.onnx"
            if not model_path.exists():
                logger.warning("UÂ²-Net ONNX ëª¨ë¸ ì—†ìŒ")
                return False
            
            try:
                import onnxruntime as ort
            except ImportError:
                logger.warning("onnxruntime ì—†ìŒ, íŒŒì¼ë§Œ í™•ì¸")
                size_mb = model_path.stat().st_size / (1024**2)
                logger.info(f"âœ… íŒŒì¼ ì¡´ì¬: {size_mb:.1f}MB")
                self.models['cloth_segmentation'] = {
                    'status': 'file_only',
                    'type': 'u2net_onnx',
                    'size_mb': f"{size_mb:.1f}"
                }
                return True
            
            # ONNX ëª¨ë¸ ë¡œë”©
            session = ort.InferenceSession(str(model_path))
            
            # ì…ë ¥ ì •ë³´ í™•ì¸
            input_name = session.get_inputs()[0].name
            input_shape = session.get_inputs()[0].shape
            
            logger.info(f"ONNX ì…ë ¥: {input_name}, shape: {input_shape}")
            logger.info("âœ… UÂ²-Net ONNX ë¡œë“œ ì„±ê³µ")
            
            self.models['cloth_segmentation'] = {
                'status': 'ready',
                'type': 'u2net_onnx',
                'input_shape': str(input_shape)
            }
            return True
            
        except Exception as e:
            logger.error(f"âŒ UÂ²-Net ONNX í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
            self.models['cloth_segmentation'] = {'status': 'failed', 'error': str(e)}
            return False
    
    def test_mediapipe_pose(self) -> bool:
        """MediaPipe í¬ì¦ˆ í…ŒìŠ¤íŠ¸"""
        try:
            print("\nğŸ¯ MediaPipe í¬ì¦ˆ í…ŒìŠ¤íŠ¸...")
            
            model_path = self.base_dir / "step_02_pose_estimation/pose_landmarker.task"
            if not model_path.exists():
                logger.warning("MediaPipe ëª¨ë¸ ì—†ìŒ")
                return False
            
            # íŒŒì¼ í¬ê¸° í™•ì¸
            size_mb = model_path.stat().st_size / (1024**2)
            logger.info(f"MediaPipe ëª¨ë¸ í¬ê¸°: {size_mb:.1f}MB")
            
            # MediaPipe ë¼ì´ë¸ŒëŸ¬ë¦¬ í™•ì¸
            try:
                import mediapipe as mp
                logger.info("âœ… MediaPipe ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš© ê°€ëŠ¥")
                
                # ê¸°ë³¸ í…ŒìŠ¤íŠ¸ (ì‹¤ì œ ì´ˆê¸°í™”ëŠ” ë³µì¡í•˜ë¯€ë¡œ íŒŒì¼ í™•ì¸ë§Œ)
                self.models['pose_estimation'] = {
                    'status': 'ready',
                    'type': 'mediapipe_pose',
                    'size_mb': f"{size_mb:.1f}"
                }
            except ImportError:
                logger.info("MediaPipe ë¼ì´ë¸ŒëŸ¬ë¦¬ ì—†ìŒ, íŒŒì¼ë§Œ í™•ì¸")
                self.models['pose_estimation'] = {
                    'status': 'file_only',
                    'type': 'mediapipe_pose',
                    'size_mb': f"{size_mb:.1f}"
                }
            
            logger.info("âœ… MediaPipe í¬ì¦ˆ ëª¨ë¸ ì •ìƒ")
            return True
            
        except Exception as e:
            logger.error(f"âŒ MediaPipe í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
            self.models['pose_estimation'] = {'status': 'failed', 'error': str(e)}
            return False
    
    def test_real_esrgan(self) -> bool:
        """Real-ESRGAN í…ŒìŠ¤íŠ¸"""
        try:
            print("\nğŸ¯ Real-ESRGAN í…ŒìŠ¤íŠ¸...")
            
            model_path = self.base_dir / "step_07_post_processing/RealESRGAN_x4plus.pth"
            if not model_path.exists():
                logger.warning("Real-ESRGAN ëª¨ë¸ ì—†ìŒ")
                return False
            
            # PyTorch ì²´í¬í¬ì¸íŠ¸ ë¡œë”© í…ŒìŠ¤íŠ¸
            checkpoint = torch.load(model_path, map_location='cpu', weights_only=True)
            
            if isinstance(checkpoint, dict):
                logger.info(f"Real-ESRGAN ì²´í¬í¬ì¸íŠ¸ í‚¤: {len(checkpoint)} ê°œ")
            
            logger.info("âœ… Real-ESRGAN ë¡œë“œ ì„±ê³µ")
            
            self.models['post_processing'] = {
                'status': 'ready',
                'type': 'real_esrgan_x4',
                'checkpoint_keys': len(checkpoint) if isinstance(checkpoint, dict) else 'unknown'
            }
            return True
            
        except Exception as e:
            logger.error(f"âŒ Real-ESRGAN í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
            self.models['post_processing'] = {'status': 'failed', 'error': str(e)}
            return False
    
    def test_clip_safe(self) -> bool:
        """CLIP ì•ˆì „ ë²„ì „ í…ŒìŠ¤íŠ¸"""
        try:
            print("\nğŸ¯ CLIP ëª¨ë¸ í…ŒìŠ¤íŠ¸...")
            
            model_path = self.base_dir / "shared_encoder/clip-vit-base-patch32"
            if not model_path.exists():
                logger.warning("CLIP ëª¨ë¸ ì—†ìŒ")
                return False
            
            # safetensors íŒŒì¼ í™•ì¸
            safetensors_files = list(model_path.glob("*.safetensors"))
            config_files = list(model_path.glob("config.json"))
            
            if safetensors_files and config_files:
                logger.info(f"âœ… CLIP safetensors: {len(safetensors_files)}ê°œ íŒŒì¼")
                logger.info(f"âœ… CLIP ì„¤ì •: {len(config_files)}ê°œ íŒŒì¼")
                
                # Transformersë¡œ ë¡œë”© ì‹œë„ (safetensors ìš°ì„ )
                try:
                    from transformers import CLIPModel, CLIPProcessor
                    
                    processor = CLIPProcessor.from_pretrained(str(model_path))
                    # safetensorsë§Œ ì‚¬ìš©í•˜ë„ë¡ ì„¤ì •í•˜ê±°ë‚˜ ëª¨ë¸ ë¡œë”© ìŠ¤í‚µ
                    logger.info("âœ… CLIP í”„ë¡œì„¸ì„œ ë¡œë“œ ì„±ê³µ")
                    
                    self.models['shared_encoder'] = {
                        'status': 'ready',
                        'type': 'clip_vit_b32_safe',
                        'safetensors_files': len(safetensors_files)
                    }
                    return True
                    
                except Exception as loading_error:
                    logger.warning(f"âš ï¸ CLIP ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {loading_error}")
                    logger.info("âœ… CLIP íŒŒì¼ë“¤ì€ ì •ìƒ (ë¡œë”© ë¬¸ì œ)")
                    
                    self.models['shared_encoder'] = {
                        'status': 'file_only',
                        'type': 'clip_vit_b32_safe',
                        'safetensors_files': len(safetensors_files),
                        'note': 'loading_issue'
                    }
                    return True
            else:
                logger.warning("safetensors ë˜ëŠ” config íŒŒì¼ ì—†ìŒ")
                return False
                
        except Exception as e:
            logger.error(f"âŒ CLIP í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
            self.models['shared_encoder'] = {'status': 'failed', 'error': str(e)}
            return False
    
    def test_yolov8_pose(self) -> bool:
        """YOLOv8 í¬ì¦ˆ í…ŒìŠ¤íŠ¸ (ëŒ€ì²´ ëª¨ë¸)"""
        try:
            print("\nğŸ¯ YOLOv8 í¬ì¦ˆ í…ŒìŠ¤íŠ¸...")
            
            model_path = self.base_dir / "step_02_pose_estimation/yolov8n-pose.pt"
            if not model_path.exists():
                logger.info("YOLOv8 í¬ì¦ˆ ëª¨ë¸ ì—†ìŒ (ì„ íƒì‚¬í•­)")
                return False
            
            # íŒŒì¼ í¬ê¸° í™•ì¸
            size_mb = model_path.stat().st_size / (1024**2)
            logger.info(f"YOLOv8 í¬ì¦ˆ í¬ê¸°: {size_mb:.1f}MB")
            
            # ê¸°ë³¸ PyTorch ë¡œë”© í…ŒìŠ¤íŠ¸
            try:
                checkpoint = torch.load(model_path, map_location='cpu', weights_only=True)
                logger.info("âœ… YOLOv8 í¬ì¦ˆ ë¡œë“œ ì„±ê³µ")
                
                self.models['pose_estimation_yolo'] = {
                    'status': 'ready',
                    'type': 'yolov8n_pose',
                    'size_mb': f"{size_mb:.1f}"
                }
                return True
                
            except:
                # weights_only=Falseë¡œ ì¬ì‹œë„
                checkpoint = torch.load(model_path, map_location='cpu')
                logger.info("âœ… YOLOv8 í¬ì¦ˆ ë¡œë“œ ì„±ê³µ (legacy)")
                
                self.models['pose_estimation_yolo'] = {
                    'status': 'ready',
                    'type': 'yolov8n_pose',
                    'size_mb': f"{size_mb:.1f}",
                    'note': 'legacy_format'
                }
                return True
            
        except Exception as e:
            logger.warning(f"âš ï¸ YOLOv8 í¬ì¦ˆ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
            return False
    
    def run_all_tests(self) -> Dict[str, Any]:
        """ëª¨ë“  í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        print("ğŸš€ ê°„ë‹¨í•œ ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì‹œì‘")
        print("=" * 40)
        
        tests = [
            ("Segformer ì¸ì²´ íŒŒì‹±", self.test_segformer_human_parsing),
            ("UÂ²-Net ONNX", self.test_u2net_onnx),
            ("MediaPipe í¬ì¦ˆ", self.test_mediapipe_pose),
            ("Real-ESRGAN", self.test_real_esrgan),
            ("CLIP", self.test_clip_safe),
            ("YOLOv8 í¬ì¦ˆ", self.test_yolov8_pose)
        ]
        
        passed = 0
        
        for test_name, test_func in tests:
            print("\n" + "=" * 30)
            result = test_func()
            if result:
                passed += 1
                logger.info(f"âœ… {test_name}: í†µê³¼")
            else:
                logger.warning(f"âŒ {test_name}: ì‹¤íŒ¨")
        
        print("\n" + "=" * 40)
        print("ğŸ‰ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
        print(f"âœ… í†µê³¼: {passed}/{len(tests)} ({passed/len(tests)*100:.1f}%)")
        
        print("\nğŸ“Š ìƒì„¸ ê²°ê³¼:")
        for model_name, model_info in self.models.items():
            status_emoji = "âœ…" if model_info['status'] == 'ready' else "âš ï¸" if model_info['status'] == 'file_only' else "âŒ"
            print(f"   {model_name}: {status_emoji} {model_info['status']}")
        
        # ê²°ê³¼ ì €ì¥
        result_summary = {
            "test_date": time.strftime("%Y-%m-%d %H:%M:%S"),
            "passed_tests": passed,
            "total_tests": len(tests),
            "success_rate": f"{passed/len(tests)*100:.1f}%",
            "models": self.models
        }
        
        with open("model_test_results.json", 'w', encoding='utf-8') as f:
            json.dump(result_summary, f, indent=2, ensure_ascii=False)
        
        print("\nğŸ“‹ ë‹¤ìŒ ë‹¨ê³„:")
        if passed >= 3:
            print("ğŸš€ ì¶©ë¶„í•œ ëª¨ë¸ì´ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤!")
            print("   python -m app.main  # ì„œë²„ ì‹¤í–‰")
        else:
            print("âš ï¸ ì¶”ê°€ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ê¶Œì¥:")
            print("   python final_complete_model_downloader.py")
        
        return result_summary


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    tester = SimpleModelTester()
    results = tester.run_all_tests()
    
    return results


if __name__ == "__main__":
    main()