#!/usr/bin/env python3
"""
MyCloset AI í”„ë¡œì íŠ¸ êµ¬ì¡° ë¶„ì„ ë° ìˆ˜ì • ìŠ¤í¬ë¦½íŠ¸
====================================================

ì»´í“¨í„° ìŠ¤í™ì— ë§ì¶°ì„œ ì œì•ˆí•˜ê³ , ì‹¤ì œ GitHub êµ¬ì¡°ë¥¼ íŒŒì•…í•œ í›„
í•˜ë‚˜ì”© ìˆ˜ì •í•  í•­ëª©ë“¤ì„ ë¶„ì„í•©ë‹ˆë‹¤.

Author: MyCloset AI Team
Date: 2025-07-16
"""

import os
import sys
import json
import yaml
from pathlib import Path
from typing import Dict, List, Optional, Tuple, Any
import subprocess
import shutil
from datetime import datetime
import platform

class ProjectStructureAnalyzer:
    """í”„ë¡œì íŠ¸ êµ¬ì¡° ë¶„ì„ ë° ìˆ˜ì • ì œì•ˆ í´ë˜ìŠ¤"""
    
    def __init__(self, project_root: str = "."):
        self.project_root = Path(project_root).resolve()
        self.backend_root = self.project_root / "backend"
        self.analysis_report = {}
        self.required_structure = self._get_required_structure()
        self.system_info = self._get_system_info()
        
    def _get_system_info(self) -> Dict[str, Any]:
        """ì‹œìŠ¤í…œ ì •ë³´ ìˆ˜ì§‘"""
        try:
            # CPU ì •ë³´
            cpu_info = platform.processor()
            if "M3" in cpu_info or "Apple" in cpu_info:
                cpu_type = "Apple Silicon M3"
                gpu_type = "Apple M3 Max GPU"
                optimization = "MPS"
            else:
                cpu_type = cpu_info
                gpu_type = "Unknown"
                optimization = "CPU/CUDA"
            
            # Python ë²„ì „
            python_version = f"{sys.version_info.major}.{sys.version_info.minor}.{sys.version_info.micro}"
            
            # ë©”ëª¨ë¦¬ ì •ë³´ (ëŒ€ëµì )
            try:
                import psutil
                memory_gb = round(psutil.virtual_memory().total / (1024**3))
            except ImportError:
                memory_gb = "Unknown"
            
            return {
                "platform": platform.system(),
                "cpu": cpu_type,
                "gpu": gpu_type,
                "optimization": optimization,
                "python_version": python_version,
                "memory_gb": memory_gb,
                "architecture": platform.machine()
            }
        except Exception as e:
            return {"error": str(e)}
    
    def _get_required_structure(self) -> Dict[str, Any]:
        """í•„ìš”í•œ í”„ë¡œì íŠ¸ êµ¬ì¡° ì •ì˜"""
        return {
            "backend": {
                "directories": {
                    "app": {
                        "api": ["__init__.py", "pipeline_routes.py", "health.py", "models.py"],
                        "core": ["__init__.py", "config.py", "gpu_config.py", "logging_config.py", "model_paths.py"],
                        "models": ["__init__.py", "schemas.py", "ootd_model.py"],
                        "services": ["__init__.py", "ai_models.py", "model_manager.py", "virtual_fitter.py", 
                                   "human_analysis.py", "cloth_analysis.py"],
                        "utils": ["__init__.py", "file_manager.py", "image_utils.py"],
                        "ai_pipeline": {
                            "steps": ["__init__.py", "step_01_human_parsing.py", "step_02_pose_estimation.py",
                                    "step_03_cloth_segmentation.py", "step_04_geometric_matching.py",
                                    "step_05_cloth_warping.py", "step_06_virtual_fitting.py",
                                    "step_07_post_processing.py", "step_08_quality_assessment.py"],
                            "utils": ["__init__.py", "memory_manager.py", "data_converter.py", "model_loader.py"]
                        }
                    },
                    "ai_models": {
                        "checkpoints": {},
                        "configs": ["models_config.yaml"],
                        "clip-vit-base-patch32": ["config.json", "model.safetensors"]
                    },
                    "static": {
                        "uploads": [".gitkeep"],
                        "results": [".gitkeep"]
                    },
                    "tests": ["__init__.py", "test_api.py", "test_models.py"],
                    "scripts": {
                        "test": ["test_final_models.py", "simple_model_test.py"],
                        "utils": ["check_imports.py"],
                        "download": ["model_downloader.py"]
                    },
                    "logs": [".gitkeep"]
                },
                "files": ["requirements.txt", "run_server.py", "Makefile", "README.md", ".env.example"]
            },
            "frontend": {
                "directories": {
                    "src": {
                        "components": {
                            "ui": [],
                            "features": []
                        },
                        "pages": [],
                        "hooks": [],
                        "types": [],
                        "utils": []
                    },
                    "public": []
                },
                "files": ["package.json", "tsconfig.json", "vite.config.ts", "index.html"]
            }
        }
    
    def analyze_current_structure(self) -> Dict[str, Any]:
        """í˜„ì¬ í”„ë¡œì íŠ¸ êµ¬ì¡° ë¶„ì„"""
        print("ğŸ” í”„ë¡œì íŠ¸ êµ¬ì¡° ë¶„ì„ ì‹œì‘...")
        print("=" * 60)
        
        current_structure = {}
        missing_items = []
        existing_items = []
        problematic_items = []
        
        # ë°±ì—”ë“œ êµ¬ì¡° ë¶„ì„
        backend_analysis = self._analyze_backend()
        current_structure["backend"] = backend_analysis
        
        # í”„ë¡ íŠ¸ì—”ë“œ êµ¬ì¡° ë¶„ì„ (ìˆëŠ” ê²½ìš°)
        frontend_analysis = self._analyze_frontend()
        current_structure["frontend"] = frontend_analysis
        
        # AI ëª¨ë¸ ë¶„ì„
        ai_models_analysis = self._analyze_ai_models()
        current_structure["ai_models"] = ai_models_analysis
        
        # ëˆ„ë½ í•­ëª© ë° ë¬¸ì œ í•­ëª© ì‹ë³„
        missing_items, problematic_items = self._identify_issues()
        
        return {
            "system_info": self.system_info,
            "current_structure": current_structure,
            "missing_items": missing_items,
            "problematic_items": problematic_items,
            "analysis_timestamp": datetime.now().isoformat()
        }
    
    def _analyze_backend(self) -> Dict[str, Any]:
        """ë°±ì—”ë“œ êµ¬ì¡° ë¶„ì„"""
        backend_info = {
            "exists": self.backend_root.exists(),
            "directories": {},
            "files": {},
            "critical_issues": []
        }
        
        if not self.backend_root.exists():
            backend_info["critical_issues"].append("backend ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŒ")
            return backend_info
        
        # ì£¼ìš” ë””ë ‰í† ë¦¬ í™•ì¸
        key_dirs = ["app", "ai_models", "static", "tests", "scripts", "logs"]
        for dir_name in key_dirs:
            dir_path = self.backend_root / dir_name
            backend_info["directories"][dir_name] = {
                "exists": dir_path.exists(),
                "contents": list(dir_path.iterdir()) if dir_path.exists() else []
            }
        
        # ì£¼ìš” íŒŒì¼ í™•ì¸
        key_files = ["requirements.txt", "run_server.py", "Makefile", "README.md"]
        for file_name in key_files:
            file_path = self.backend_root / file_name
            backend_info["files"][file_name] = {
                "exists": file_path.exists(),
                "size": file_path.stat().st_size if file_path.exists() else 0
            }
        
        # app ë””ë ‰í† ë¦¬ ì„¸ë¶€ ë¶„ì„
        if (self.backend_root / "app").exists():
            backend_info["app_structure"] = self._analyze_app_structure()
        
        return backend_info
    
    def _analyze_app_structure(self) -> Dict[str, Any]:
        """app ë””ë ‰í† ë¦¬ êµ¬ì¡° ì„¸ë¶€ ë¶„ì„"""
        app_root = self.backend_root / "app"
        app_structure = {
            "api": self._analyze_directory(app_root / "api"),
            "core": self._analyze_directory(app_root / "core"),
            "models": self._analyze_directory(app_root / "models"),
            "services": self._analyze_directory(app_root / "services"),
            "utils": self._analyze_directory(app_root / "utils"),
            "ai_pipeline": self._analyze_directory(app_root / "ai_pipeline")
        }
        return app_structure
    
    def _analyze_directory(self, dir_path: Path) -> Dict[str, Any]:
        """ë””ë ‰í† ë¦¬ ë¶„ì„"""
        if not dir_path.exists():
            return {"exists": False, "files": [], "subdirs": []}
        
        files = [f.name for f in dir_path.iterdir() if f.is_file()]
        subdirs = [d.name for d in dir_path.iterdir() if d.is_dir()]
        
        return {
            "exists": True,
            "files": files,
            "subdirs": subdirs,
            "total_files": len(files),
            "python_files": len([f for f in files if f.endswith('.py')])
        }
    
    def _analyze_frontend(self) -> Dict[str, Any]:
        """í”„ë¡ íŠ¸ì—”ë“œ êµ¬ì¡° ë¶„ì„"""
        frontend_root = self.project_root / "frontend"
        return {
            "exists": frontend_root.exists(),
            "package_json": (frontend_root / "package.json").exists() if frontend_root.exists() else False,
            "src_exists": (frontend_root / "src").exists() if frontend_root.exists() else False
        }
    
    def _analyze_ai_models(self) -> Dict[str, Any]:
        """AI ëª¨ë¸ êµ¬ì¡° ë¶„ì„"""
        ai_models_root = self.backend_root / "ai_models"
        
        if not ai_models_root.exists():
            return {"exists": False, "critical": "AI ëª¨ë¸ ë””ë ‰í† ë¦¬ ëˆ„ë½"}
        
        models_info = {
            "exists": True,
            "clip_model": self._check_clip_model(),
            "checkpoints": self._analyze_directory(ai_models_root / "checkpoints"),
            "ootdiffusion": self._check_ootdiffusion(),
            "stable_diffusion": self._check_stable_diffusion(),
            "total_size_gb": self._calculate_models_size()
        }
        
        return models_info
    
    def _check_clip_model(self) -> Dict[str, Any]:
        """CLIP ëª¨ë¸ í™•ì¸"""
        clip_path = self.backend_root / "ai_models" / "clip-vit-base-patch32"
        if not clip_path.exists():
            return {"exists": False, "issue": "CLIP ëª¨ë¸ ë””ë ‰í† ë¦¬ ì—†ìŒ"}
        
        required_files = ["config.json", "model.safetensors"]
        existing_files = [f.name for f in clip_path.iterdir() if f.is_file()]
        
        return {
            "exists": True,
            "required_files": required_files,
            "existing_files": existing_files,
            "complete": all(f in existing_files for f in required_files)
        }
    
    def _check_ootdiffusion(self) -> Dict[str, Any]:
        """OOTDiffusion ëª¨ë¸ í™•ì¸"""
        ootd_paths = [
            self.backend_root / "ai_models" / "OOTDiffusion",
            self.backend_root / "ai_models" / "oot_diffusion",
            self.backend_root / "ai_models" / "checkpoints" / "ootdiffusion"
        ]
        
        for path in ootd_paths:
            if path.exists():
                return {"exists": True, "path": str(path)}
        
        return {"exists": False, "checked_paths": [str(p) for p in ootd_paths]}
    
    def _check_stable_diffusion(self) -> Dict[str, Any]:
        """Stable Diffusion ëª¨ë¸ í™•ì¸"""
        sd_path = self.backend_root / "ai_models" / "checkpoints" / "stable-diffusion-v1-5"
        return {"exists": sd_path.exists(), "path": str(sd_path)}
    
    def _calculate_models_size(self) -> float:
        """ëª¨ë¸ ì´ í¬ê¸° ê³„ì‚° (GB)"""
        ai_models_path = self.backend_root / "ai_models"
        if not ai_models_path.exists():
            return 0.0
        
        total_size = 0
        for root, dirs, files in os.walk(ai_models_path):
            for file in files:
                file_path = Path(root) / file
                try:
                    total_size += file_path.stat().st_size
                except (OSError, FileNotFoundError):
                    pass
        
        return round(total_size / (1024**3), 2)
    
    def _identify_issues(self) -> Tuple[List[Dict], List[Dict]]:
        """ëˆ„ë½ í•­ëª© ë° ë¬¸ì œ í•­ëª© ì‹ë³„"""
        missing_items = []
        problematic_items = []
        
        # í•„ìˆ˜ íŒŒì¼ í™•ì¸
        critical_files = [
            ("backend/app/__init__.py", "ì•± íŒ¨í‚¤ì§€ ì´ˆê¸°í™”"),
            ("backend/app/api/pipeline_routes.py", "í•µì‹¬ API ë¼ìš°íŠ¸"),
            ("backend/app/models/schemas.py", "ë°ì´í„° ìŠ¤í‚¤ë§ˆ"),
            ("backend/app/services/model_manager.py", "ëª¨ë¸ ê´€ë¦¬ì"),
            ("backend/run_server.py", "ì„œë²„ ì‹¤í–‰ íŒŒì¼"),
            ("backend/requirements.txt", "ì˜ì¡´ì„± ëª©ë¡")
        ]
        
        for file_path, description in critical_files:
            full_path = self.project_root / file_path
            if not full_path.exists():
                missing_items.append({
                    "type": "critical_file",
                    "path": file_path,
                    "description": description,
                    "priority": "HIGH"
                })
        
        # ëª¨ë¸ íŒŒì¼ í™•ì¸
        model_checks = [
            ("backend/ai_models/clip-vit-base-patch32/model.safetensors", "CLIP ëª¨ë¸"),
            ("backend/ai_models/checkpoints", "AI ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ ë””ë ‰í† ë¦¬")
        ]
        
        for model_path, description in model_checks:
            full_path = self.project_root / model_path
            if not full_path.exists():
                missing_items.append({
                    "type": "model_file",
                    "path": model_path,
                    "description": description,
                    "priority": "MEDIUM"
                })
        
        return missing_items, problematic_items
    
    def generate_fixes(self) -> Dict[str, List[str]]:
        """ìˆ˜ì • ë°©ì•ˆ ìƒì„±"""
        analysis = self.analyze_current_structure()
        fixes = {
            "immediate": [],  # ì¦‰ì‹œ ìˆ˜ì • ê°€ëŠ¥
            "download_required": [],  # ë‹¤ìš´ë¡œë“œ í•„ìš”
            "manual_review": []  # ìˆ˜ë™ ê²€í†  í•„ìš”
        }
        
        # ì¦‰ì‹œ ìˆ˜ì • ê°€ëŠ¥í•œ í•­ëª©ë“¤
        for item in analysis["missing_items"]:
            if item["type"] == "critical_file":
                if item["path"].endswith("__init__.py"):
                    fixes["immediate"].append(f"touch {item['path']}")
                elif "schemas.py" in item["path"]:
                    fixes["immediate"].append(f"ìƒì„±: {item['path']} - ë°ì´í„° ìŠ¤í‚¤ë§ˆ íŒŒì¼")
                elif "pipeline_routes.py" in item["path"]:
                    fixes["manual_review"].append(f"ê²€í†  í•„ìš”: {item['path']} - API ë¼ìš°íŠ¸ ë³µêµ¬")
            
            elif item["type"] == "model_file":
                if "clip" in item["path"].lower():
                    fixes["download_required"].append("CLIP ëª¨ë¸ ë‹¤ìš´ë¡œë“œ í•„ìš”")
                else:
                    fixes["download_required"].append(f"ëª¨ë¸ ë‹¤ìš´ë¡œë“œ: {item['description']}")
        
        return fixes
    
    def create_fix_script(self, output_file: str = "fix_project_structure.sh") -> str:
        """ìˆ˜ì • ìŠ¤í¬ë¦½íŠ¸ ìƒì„±"""
        analysis = self.analyze_current_structure()
        fixes = self.generate_fixes()
        
        script_content = f"""#!/bin/bash
# MyCloset AI í”„ë¡œì íŠ¸ êµ¬ì¡° ìˆ˜ì • ìŠ¤í¬ë¦½íŠ¸
# ìƒì„±ì¼: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
# ì‹œìŠ¤í…œ: {self.system_info.get('platform', 'Unknown')} / {self.system_info.get('cpu', 'Unknown')}

set -e  # ì˜¤ë¥˜ ì‹œ ìŠ¤í¬ë¦½íŠ¸ ì¤‘ë‹¨

echo "ğŸ”§ MyCloset AI í”„ë¡œì íŠ¸ êµ¬ì¡° ìˆ˜ì • ì‹œì‘..."
echo "=================================================="

# ìƒ‰ìƒ ì •ì˜
RED='\\033[0;31m'
GREEN='\\033[0;32m'
YELLOW='\\033[1;33m'
BLUE='\\033[0;34m'
NC='\\033[0m' # No Color

log_info() {{ echo -e "${{BLUE}}â„¹ï¸  $1${{NC}}"; }}
log_success() {{ echo -e "${{GREEN}}âœ… $1${{NC}}"; }}
log_warning() {{ echo -e "${{YELLOW}}âš ï¸  $1${{NC}}"; }}
log_error() {{ echo -e "${{RED}}âŒ $1${{NC}}"; }}

# 1. í•„ìˆ˜ ë””ë ‰í† ë¦¬ ìƒì„±
log_info "Step 1: í•„ìˆ˜ ë””ë ‰í† ë¦¬ ìƒì„±"
mkdir -p backend/app/{{api,core,models,services,utils}}
mkdir -p backend/app/ai_pipeline/{{steps,utils}}
mkdir -p backend/{{ai_models,static,tests,scripts,logs}}
mkdir -p backend/static/{{uploads,results}}
mkdir -p backend/scripts/{{test,utils,download}}

# .gitkeep íŒŒì¼ ìƒì„±
touch backend/static/uploads/.gitkeep
touch backend/static/results/.gitkeep
touch backend/logs/.gitkeep

log_success "ë””ë ‰í† ë¦¬ êµ¬ì¡° ìƒì„± ì™„ë£Œ"

# 2. í•„ìˆ˜ __init__.py íŒŒì¼ ìƒì„±
log_info "Step 2: Python íŒ¨í‚¤ì§€ ì´ˆê¸°í™” íŒŒì¼ ìƒì„±"
"""

        # __init__.py íŒŒì¼ë“¤ ìƒì„±
        init_files = [
            "backend/app/__init__.py",
            "backend/app/api/__init__.py",
            "backend/app/core/__init__.py",
            "backend/app/models/__init__.py",
            "backend/app/services/__init__.py",
            "backend/app/utils/__init__.py",
            "backend/app/ai_pipeline/__init__.py",
            "backend/app/ai_pipeline/steps/__init__.py",
            "backend/app/ai_pipeline/utils/__init__.py",
            "backend/tests/__init__.py"
        ]
        
        for init_file in init_files:
            script_content += f'touch {init_file}\n'
        
        script_content += f"""
log_success "__init__.py íŒŒì¼ë“¤ ìƒì„± ì™„ë£Œ"

# 3. ì‹œìŠ¤í…œë³„ ìµœì í™” ì„¤ì •
log_info "Step 3: ì‹œìŠ¤í…œ ìµœì í™” ì„¤ì •"
"""

        # ì‹œìŠ¤í…œë³„ ì„¤ì •
        if "M3" in self.system_info.get("cpu", ""):
            script_content += """
# M3 Max ìµœì í™” ì„¤ì •
export PYTORCH_ENABLE_MPS_FALLBACK=1
export PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0
log_success "M3 Max GPU ìµœì í™” ì„¤ì • ì™„ë£Œ"
"""
        else:
            script_content += """
# ì¼ë°˜ ì‹œìŠ¤í…œ ì„¤ì •
export CUDA_VISIBLE_DEVICES=0
log_info "CUDA ì„¤ì • ì™„ë£Œ"
"""

        script_content += f"""
# 4. ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì²´í¬
log_info "Step 4: AI ëª¨ë¸ ìƒíƒœ í™•ì¸"

if [ ! -f "backend/ai_models/clip-vit-base-patch32/model.safetensors" ]; then
    log_warning "CLIP ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤. ë‹¤ìš´ë¡œë“œê°€ í•„ìš”í•©ë‹ˆë‹¤."
    echo "ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ CLIP ëª¨ë¸ì„ ë‹¤ìš´ë¡œë“œí•˜ì„¸ìš”:"
    echo "python3 -c \\"from transformers import CLIPModel, CLIPProcessor; model = CLIPModel.from_pretrained('openai/clip-vit-base-patch32'); model.save_pretrained('./backend/ai_models/clip-vit-base-patch32')\\"" 
else
    log_success "CLIP ëª¨ë¸ í™•ì¸ë¨"
fi

# 5. ê¶Œí•œ ì„¤ì •
log_info "Step 5: íŒŒì¼ ê¶Œí•œ ì„¤ì •"
chmod +x backend/run_server.py 2>/dev/null || log_warning "run_server.py ê¶Œí•œ ì„¤ì • ì‹¤íŒ¨"
chmod +x backend/scripts/test/*.py 2>/dev/null || log_info "í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ ê¶Œí•œ ì„¤ì •"

log_success "í”„ë¡œì íŠ¸ êµ¬ì¡° ìˆ˜ì • ì™„ë£Œ!"
echo ""
echo "ğŸ“Š ìˆ˜ì • ì™„ë£Œ ìƒíƒœ:"
echo "=================================="
"""

        # ìˆ˜ì • ì™„ë£Œ í›„ ìƒíƒœ ìš”ì•½
        for category, items in fixes.items():
            if items:
                category_name = {
                    "immediate": "ì¦‰ì‹œ ìˆ˜ì •ë¨",
                    "download_required": "ë‹¤ìš´ë¡œë“œ í•„ìš”", 
                    "manual_review": "ìˆ˜ë™ ê²€í†  í•„ìš”"
                }[category]
                
                script_content += f'echo "ğŸ“‹ {category_name}:"\n'
                for item in items:
                    script_content += f'echo "   - {item}"\n'

        script_content += """
echo ""
echo "ğŸš€ ë‹¤ìŒ ë‹¨ê³„:"
echo "1. python3 backend/scripts/test/test_final_models.py  # ëª¨ë¸ í…ŒìŠ¤íŠ¸"
echo "2. python3 backend/run_server.py  # ì„œë²„ ì‹œì‘"
echo "3. ë¸Œë¼ìš°ì €ì—ì„œ http://localhost:8000 ì ‘ì†"
"""
        
        # ìŠ¤í¬ë¦½íŠ¸ íŒŒì¼ ìƒì„±
        script_path = self.project_root / output_file
        with open(script_path, 'w', encoding='utf-8') as f:
            f.write(script_content)
        
        # ì‹¤í–‰ ê¶Œí•œ ë¶€ì—¬
        os.chmod(script_path, 0o755)
        
        return str(script_path)
    
    def print_analysis_report(self) -> None:
        """ë¶„ì„ ë³´ê³ ì„œ ì¶œë ¥"""
        analysis = self.analyze_current_structure()
        
        print(f"ğŸ” MyCloset AI í”„ë¡œì íŠ¸ êµ¬ì¡° ë¶„ì„ ë³´ê³ ì„œ")
        print("=" * 60)
        print(f"ğŸ“… ë¶„ì„ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"ğŸ’» ì‹œìŠ¤í…œ: {self.system_info.get('platform')} / {self.system_info.get('cpu')}")
        print(f"ğŸ”§ ìµœì í™”: {self.system_info.get('optimization')}")
        print()
        
        # ë°±ì—”ë“œ ìƒíƒœ
        backend = analysis["current_structure"]["backend"]
        print("ğŸ—ï¸ ë°±ì—”ë“œ êµ¬ì¡° ìƒíƒœ:")
        print(f"   âœ… ë°±ì—”ë“œ ì¡´ì¬: {'ì˜ˆ' if backend['exists'] else 'âŒ ì•„ë‹ˆì˜¤'}")
        
        if backend["exists"]:
            for dir_name, info in backend["directories"].items():
                status = "âœ…" if info["exists"] else "âŒ"
                print(f"   {status} {dir_name}/: {'ì¡´ì¬' if info['exists'] else 'ëˆ„ë½'}")
        
        # AI ëª¨ë¸ ìƒíƒœ
        ai_models = analysis["current_structure"]["ai_models"]
        print("\nğŸ¤– AI ëª¨ë¸ ìƒíƒœ:")
        if ai_models["exists"]:
            print(f"   âœ… AI ëª¨ë¸ ë””ë ‰í† ë¦¬: ì¡´ì¬")
            print(f"   ğŸ“Š ì´ í¬ê¸°: {ai_models['total_size_gb']} GB")
            
            clip = ai_models["clip_model"]
            if clip["exists"]:
                status = "âœ… ì™„ì „" if clip["complete"] else "âš ï¸ ë¶ˆì™„ì „"
                print(f"   {status} CLIP ëª¨ë¸: {len(clip['existing_files'])}ê°œ íŒŒì¼")
            else:
                print(f"   âŒ CLIP ëª¨ë¸: ëˆ„ë½")
        else:
            print(f"   âŒ AI ëª¨ë¸ ë””ë ‰í† ë¦¬: ëˆ„ë½")
        
        # ëˆ„ë½ í•­ëª©
        missing = analysis["missing_items"]
        if missing:
            print(f"\nâš ï¸ ëˆ„ë½ëœ ì¤‘ìš” í•­ëª© ({len(missing)}ê°œ):")
            for item in missing:
                priority_icon = {"HIGH": "ğŸ”´", "MEDIUM": "ğŸŸ¡", "LOW": "ğŸŸ¢"}
                icon = priority_icon.get(item["priority"], "ğŸ”¹")
                print(f"   {icon} {item['description']}")
                print(f"      ê²½ë¡œ: {item['path']}")
        else:
            print("\nâœ… ëª¨ë“  í•„ìˆ˜ í•­ëª©ì´ ì¡´ì¬í•©ë‹ˆë‹¤!")
        
        # ìˆ˜ì • ë°©ì•ˆ
        fixes = self.generate_fixes()
        print(f"\nğŸ”§ ìˆ˜ì • ë°©ì•ˆ:")
        for category, items in fixes.items():
            if items:
                category_names = {
                    "immediate": "ì¦‰ì‹œ ìˆ˜ì • ê°€ëŠ¥",
                    "download_required": "ë‹¤ìš´ë¡œë“œ í•„ìš”",
                    "manual_review": "ìˆ˜ë™ ê²€í†  í•„ìš”"
                }
                print(f"   ğŸ“‹ {category_names[category]} ({len(items)}ê°œ):")
                for item in items[:3]:  # ìµœëŒ€ 3ê°œë§Œ í‘œì‹œ
                    print(f"      â€¢ {item}")
                if len(items) > 3:
                    print(f"      ... ì™¸ {len(items)-3}ê°œ")
        
        print("\n" + "=" * 60)
        print("ğŸ’¡ ë‹¤ìŒ ë‹¨ê³„ ê¶Œì¥ì‚¬í•­:")
        print("1. ./fix_project_structure.sh ì‹¤í–‰ìœ¼ë¡œ ìë™ ìˆ˜ì •")
        print("2. AI ëª¨ë¸ ë‹¤ìš´ë¡œë“œ (í•„ìš”ì‹œ)")
        print("3. python backend/scripts/test/test_final_models.py ë¡œ í…ŒìŠ¤íŠ¸")
        print("4. python backend/run_server.py ë¡œ ì„œë²„ ì‹œì‘")
        
    def save_analysis_json(self, output_file: str = "project_analysis.json") -> str:
        """ë¶„ì„ ê²°ê³¼ë¥¼ JSONìœ¼ë¡œ ì €ì¥"""
        analysis = self.analyze_current_structure()
        
        json_path = self.project_root / output_file
        with open(json_path, 'w', encoding='utf-8') as f:
            json.dump(analysis, f, indent=2, ensure_ascii=False, default=str)
        
        return str(json_path)

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸš€ MyCloset AI í”„ë¡œì íŠ¸ êµ¬ì¡° ë¶„ì„ê¸°")
    print("=" * 60)
    
    # í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì°¾ê¸°
    current_dir = Path.cwd()
    project_root = current_dir
    
    # backend ë””ë ‰í† ë¦¬ê°€ ìˆëŠ” ê³³ì„ í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¡œ ì„¤ì •
    if (current_dir / "backend").exists():
        project_root = current_dir
    elif (current_dir.parent / "backend").exists():
        project_root = current_dir.parent
    elif (current_dir / "mycloset-ai" / "backend").exists():
        project_root = current_dir / "mycloset-ai"
    
    print(f"ğŸ“ í”„ë¡œì íŠ¸ ë£¨íŠ¸: {project_root}")
    
    # ë¶„ì„ê¸° ì´ˆê¸°í™”
    analyzer = ProjectStructureAnalyzer(str(project_root))
    
    # ë¶„ì„ ì‹¤í–‰
    analyzer.print_analysis_report()
    
    # JSON ë³´ê³ ì„œ ì €ì¥
    json_file = analyzer.save_analysis_json()
    print(f"\nğŸ’¾ ìƒì„¸ ë¶„ì„ ê²°ê³¼ ì €ì¥: {json_file}")
    
    # ìˆ˜ì • ìŠ¤í¬ë¦½íŠ¸ ìƒì„±
    script_file = analyzer.create_fix_script()
    print(f"ğŸ”§ ìˆ˜ì • ìŠ¤í¬ë¦½íŠ¸ ìƒì„±: {script_file}")
    
    print(f"\nâœ¨ ë¶„ì„ ì™„ë£Œ! ìˆ˜ì •ì„ ìœ„í•´ ë‹¤ìŒ ëª…ë ¹ì–´ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”:")
    print(f"   chmod +x {script_file}")
    print(f"   ./{script_file}")

if __name__ == "__main__":
    main()