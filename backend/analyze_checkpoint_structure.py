#!/usr/bin/env python3
"""
μ²΄ν¬ν¬μΈνΈ νμΌμ μ „μ²΄ κµ¬μ΅° λ¶„μ„ μ¤ν¬λ¦½νΈ
"""

import torch
import os
import sys
from collections import defaultdict

def analyze_checkpoint_structure(checkpoint_path):
    """μ²΄ν¬ν¬μΈνΈ νμΌμ κµ¬μ΅°λ¥Ό λ¶„μ„ν•©λ‹λ‹¤."""

    print("=" * 80)
    print("π” μ²΄ν¬ν¬μΈνΈ κµ¬μ΅° λ¶„μ„ μ‹μ‘")
    print("=" * 80)

    if not os.path.exists(checkpoint_path):
        print(f"β μ²΄ν¬ν¬μΈνΈ νμΌμ΄ μ΅΄μ¬ν•μ§€ μ•μµλ‹λ‹¤: {checkpoint_path}")
        return

    try:
        # μ²΄ν¬ν¬μΈνΈ λ΅λ”©
        print(f"π“ μ²΄ν¬ν¬μΈνΈ λ΅λ”©: {checkpoint_path}")
        checkpoint = torch.load(checkpoint_path, map_location='cpu')

        print(f"β… μ²΄ν¬ν¬μΈνΈ λ΅λ”© μ„±κ³µ: {type(checkpoint)}")

        # μ²΄ν¬ν¬μΈνΈ κµ¬μ΅° λ¶„μ„
        if isinstance(checkpoint, dict):
            print(f"π“ μ²΄ν¬ν¬μΈνΈ ν‚¤: {list(checkpoint.keys())}")

            # state_dictκ°€ μλ”μ§€ ν™•μΈ
            if 'state_dict' in checkpoint:
                checkpoint = checkpoint['state_dict']
                print("β… state_dict ν‚¤μ—μ„ μ²΄ν¬ν¬μΈνΈ μ¶”μ¶")

            print(f"β… state_dict μ¶”μ¶ μ„±κ³µ: {len(checkpoint.keys())}κ° ν‚¤")

            # μ „μ²΄ ν‚¤λ¥Ό μΉ΄ν…κ³ λ¦¬λ³„λ΅ λ¶„λ¥
            categories = {
                'backbone': [],
                'edge': [],
                'context_encoding': [],
                'decoder': [],
                'other': []
            }

            for key in sorted(checkpoint.keys()):
                tensor_shape = checkpoint[key].shape
                print(f"  - {key}: {tensor_shape}")
                
                if 'backbone' in key:
                    categories['backbone'].append((key, tensor_shape))
                elif 'edge' in key:
                    categories['edge'].append((key, tensor_shape))
                elif 'context_encoding' in key:
                    categories['context_encoding'].append((key, tensor_shape))
                elif 'decoder' in key:
                    categories['decoder'].append((key, tensor_shape))
                else:
                    categories['other'].append((key, tensor_shape))

            print("\n" + "=" * 60)
            print("π“ μΉ΄ν…κ³ λ¦¬λ³„ λ¶„μ„")
            print("=" * 60)

            for category, items in categories.items():
                if items:
                    print(f"\nπ” {category.upper()} λ¨λ“ ({len(items)}κ°):")
                    for key, shape in items:
                        print(f"  - {key}: {shape}")

            # Edge λ¨λ“ μƒμ„Έ λ¶„μ„
            if categories['edge']:
                print(f"\nπ” EDGE λ¨λ“ μƒμ„Έ λ¶„μ„:")
                edge_structure = defaultdict(list)
                for key, shape in categories['edge']:
                    if 'conv' in key and '.weight' in key:
                        # Conv2d weight shape: [out_channels, in_channels, kH, kW]
                        out_channels = shape[0]
                        in_channels = shape[1]
                        kernel_size = f"{shape[2]}x{shape[3]}"
                        conv_name = key.split('.')[1]
                        edge_structure[conv_name].append(f"Conv2d({in_channels}, {out_channels}, {kernel_size})")

                print("  π“ Edge λ¨λ“ μ”μ•½:")
                for conv_name, details in edge_structure.items():
                    print(f"    {conv_name}: {', '.join(details)}")

            # Backbone λ¨λ“ μƒμ„Έ λ¶„μ„
            if categories['backbone']:
                print(f"\nπ” BACKBONE λ¨λ“ μƒμ„Έ λ¶„μ„:")
                backbone_structure = defaultdict(list)
                for key, shape in categories['backbone']:
                    if 'conv' in key and '.weight' in key:
                        out_channels = shape[0]
                        in_channels = shape[1]
                        kernel_size = f"{shape[2]}x{shape[3]}"
                        conv_name = key.split('.')[1]
                        backbone_structure[conv_name].append(f"Conv2d({in_channels}, {out_channels}, {kernel_size})")

                print("  π“ Backbone λ¨λ“ μ”μ•½:")
                for conv_name, details in backbone_structure.items():
                    print(f"    {conv_name}: {', '.join(details)}")

        else:
            print("β οΈ μ²΄ν¬ν¬μΈνΈκ°€ λ”•μ…”λ„λ¦¬ ν•νƒκ°€ μ•„λ‹™λ‹λ‹¤. μ§μ ‘ κµ¬μ΅°λ¥Ό ν™•μΈν•΄μ•Ό ν•©λ‹λ‹¤.")

    except Exception as e:
        print(f"β μ²΄ν¬ν¬μΈνΈ λ¶„μ„ μ¤‘ μ¤λ¥ λ°μƒ: {e}")
        import traceback
        traceback.print_exc()

    print("=" * 80)
    print("β… μ²΄ν¬ν¬μΈνΈ κµ¬μ΅° λ¶„μ„ μ™„λ£")
    print("=" * 80)

if __name__ == "__main__":
    # μ‹¤μ  μ²΄ν¬ν¬μΈνΈ νμΌ κ²½λ΅
    checkpoint_file_path = "ai_models/Self-Correction-Human-Parsing/exp-schp-201908261155-atr.pth"
    analyze_checkpoint_structure(checkpoint_file_path) 