#!/usr/bin/env python3
"""
ğŸ”¥ MyCloset AI - ì‹¤ì œ AI ëª¨ë¸ ì™„ì „ í™œìš© ì‹œìŠ¤í…œ v3.0
===============================================================================
âœ… ì‹¤ì œ 229GB ëª¨ë¸ íŒŒì¼ ì™„ì „ í™œìš©
âœ… SmartModelPathMapper ë™ì  ê²½ë¡œ ë§¤í•‘
âœ… Stepë³„ ì‹¤ì œ AI ì¶”ë¡  ë¡œì§
âœ… BaseStepMixin v16.0 ì™„ì „ í˜¸í™˜
âœ… conda í™˜ê²½ ìµœì í™” (mycloset-ai-clean)
âœ… M3 Max 128GB ìµœì í™”
"""

import os
import sys
import asyncio
import logging
import traceback
from pathlib import Path
from typing import Dict, List, Optional, Any, Union
from dataclasses import dataclass
import time
import json

# ğŸ”¥ í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ (conda í™˜ê²½ í™•ì¸)
import sys
import os
from pathlib import Path

# ë¨¼ì € ê¸°ë³¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ë“¤
try:
    import platform
    PLATFORM_AVAILABLE = True
except ImportError:
    PLATFORM_AVAILABLE = False

# numpy ë¨¼ì € í™•ì¸
try:
    import numpy as np
    NUMPY_AVAILABLE = True
    print("âœ… NumPy ë¡œë”© ì„±ê³µ")
except ImportError as e:
    print(f"âŒ NumPy ëˆ„ë½: {e}")
    print("ğŸ’¡ condaë¡œ í•´ê²°:")
    print("   conda install numpy -y")
    NUMPY_AVAILABLE = False

# PyTorch í™•ì¸
try:
    import torch
    import torch.nn as nn
    TORCH_AVAILABLE = True
    print("âœ… PyTorch ë¡œë”© ì„±ê³µ")
except ImportError as e:
    print(f"âŒ PyTorch ëˆ„ë½: {e}")
    print("ğŸ’¡ condaë¡œ í•´ê²°:")
    print("   conda install pytorch torchvision -c pytorch -y")
    TORCH_AVAILABLE = False

# PIL í™•ì¸
try:
    from PIL import Image
    PIL_AVAILABLE = True
    print("âœ… PIL ë¡œë”© ì„±ê³µ")
except ImportError as e:
    print(f"âŒ PIL ëˆ„ë½: {e}")
    print("ğŸ’¡ condaë¡œ í•´ê²°:")
    print("   conda install pillow -y")
    PIL_AVAILABLE = False

# ì „ì²´ ê°€ìš©ì„± í™•ì¸
ALL_LIBS_AVAILABLE = TORCH_AVAILABLE and NUMPY_AVAILABLE and PIL_AVAILABLE

if not ALL_LIBS_AVAILABLE:
    print("\nâŒ í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤!")
    print("ğŸ”§ condaë¡œ í•œë²ˆì— ì„¤ì¹˜:")
    print("   conda install numpy pytorch torchvision pillow -c pytorch -y")
    sys.exit(1)

# ==============================================
# ğŸ”¥ 1. SmartModelPathMapper - ì‹¤ì œ íŒŒì¼ ìë™ íƒì§€
# ==============================================

class SmartModelPathMapper:
    """ì‹¤ì œ íŒŒì¼ ìœ„ì¹˜ë¥¼ ë™ì ìœ¼ë¡œ ì°¾ì•„ì„œ ë§¤í•‘í•˜ëŠ” ì‹œìŠ¤í…œ"""
    
    def __init__(self, ai_models_root: str = "ai_models"):
        self.ai_models_root = Path(ai_models_root)
        self.model_cache = {}
        self.search_priority = self._get_search_priority()
        self.logger = logging.getLogger(__name__)
        
        # ì‹¤ì œ ê²½ë¡œ ìë™ íƒì§€
        self.ai_models_root = self._auto_detect_ai_models_path()
        self.logger.info(f"ğŸ“ AI ëª¨ë¸ ë£¨íŠ¸ ê²½ë¡œ: {self.ai_models_root}")
        
    def _auto_detect_ai_models_path(self) -> Path:
        """ì‹¤ì œ ai_models ë””ë ‰í† ë¦¬ ìë™ íƒì§€"""
        possible_paths = [
            Path.cwd() / "ai_models",  # backend/ai_models
            Path.cwd().parent / "ai_models",  # mycloset-ai/ai_models
            Path.cwd() / "backend" / "ai_models",  # mycloset-ai/backend/ai_models
            Path(__file__).parent / "ai_models",
            Path(__file__).parent.parent / "ai_models",
            Path(__file__).parent.parent.parent / "ai_models"
        ]
        
        for path in possible_paths:
            if path.exists() and self._verify_ai_models_structure(path):
                return path
                
        # í´ë°±: í˜„ì¬ ë””ë ‰í† ë¦¬
        return Path.cwd() / "ai_models"
    
    def _verify_ai_models_structure(self, path: Path) -> bool:
        """ì‹¤ì œ AI ëª¨ë¸ ë””ë ‰í† ë¦¬ êµ¬ì¡° ê²€ì¦"""
        required_dirs = [
            "step_01_human_parsing",
            "step_04_geometric_matching", 
            "step_06_virtual_fitting"
        ]
        
        count = 0
        for dir_name in required_dirs:
            if (path / dir_name).exists():
                count += 1
                
        return count >= 2  # ìµœì†Œ 2ê°œ ì´ìƒ ì¡´ì¬
        
    def _get_search_priority(self) -> Dict[str, List[str]]:
        """ëª¨ë¸ë³„ ê²€ìƒ‰ ìš°ì„ ìˆœìœ„ ê²½ë¡œ"""
        return {
            "geometric_matching": [
                "step_04_geometric_matching/",
                "step_04_geometric_matching/ultra_models/",
                "step_08_quality_assessment/ultra_models/",
                "checkpoints/step_04_geometric_matching/"
            ],
            "human_parsing": [
                "step_01_human_parsing/",
                "Self-Correction-Human-Parsing/",
                "Graphonomy/",
                "checkpoints/step_01_human_parsing/"
            ],
            "cloth_segmentation": [
                "step_03_cloth_segmentation/",
                "step_03_cloth_segmentation/ultra_models/",
                "step_04_geometric_matching/",  # SAM ê³µìœ 
                "checkpoints/step_03_cloth_segmentation/"
            ]
        }
    
    def find_model_file(self, model_filename: str, model_type: str = None) -> Optional[Path]:
        """ì‹¤ì œ íŒŒì¼ ìœ„ì¹˜ë¥¼ ë™ì ìœ¼ë¡œ ì°¾ê¸°"""
        cache_key = f"{model_type}:{model_filename}"
        if cache_key in self.model_cache:
            cached_path = self.model_cache[cache_key]
            if cached_path.exists():
                return cached_path
        
        # ê²€ìƒ‰ ê²½ë¡œ ê²°ì •
        search_paths = []
        if model_type and model_type in self.search_priority:
            search_paths.extend(self.search_priority[model_type])
            
        # ì „ì²´ ê²€ìƒ‰ ê²½ë¡œ ì¶”ê°€ (fallback)
        search_paths.extend([
            "step_01_human_parsing/", "step_02_pose_estimation/",
            "step_03_cloth_segmentation/", "step_04_geometric_matching/",
            "step_05_cloth_warping/", "step_06_virtual_fitting/",
            "step_07_post_processing/", "step_08_quality_assessment/",
            "checkpoints/", "Self-Correction-Human-Parsing/", "Graphonomy/"
        ])
        
        # ì‹¤ì œ íŒŒì¼ ê²€ìƒ‰
        for search_path in search_paths:
            full_search_path = self.ai_models_root / search_path
            if not full_search_path.exists():
                continue
                
            # ì§ì ‘ íŒŒì¼ í™•ì¸
            direct_path = full_search_path / model_filename
            if direct_path.exists() and direct_path.is_file():
                self.model_cache[cache_key] = direct_path
                return direct_path
                
            # ì¬ê·€ ê²€ìƒ‰ (í•˜ìœ„ ë””ë ‰í† ë¦¬ê¹Œì§€)
            try:
                for found_file in full_search_path.rglob(model_filename):
                    if found_file.is_file():
                        self.model_cache[cache_key] = found_file
                        return found_file
            except Exception:
                continue
                
        return None
    
    def get_step_model_mapping(self, step_id: int) -> Dict[str, Path]:
        """Stepë³„ ì‹¤ì œ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ë§¤í•‘"""
        step_mappings = {
            1: {  # Human Parsing
                "graphonomy": ["graphonomy.pth", "graphonomy_lip.pth"],
                "schp_atr": ["exp-schp-201908301523-atr.pth", "exp-schp-201908261155-atr.pth"],
                "atr_model": ["atr_model.pth"],
                "lip_model": ["lip_model.pth"]
            },
            3: {  # Cloth Segmentation
                "sam_huge": ["sam_vit_h_4b8939.pth"],
                "u2net": ["u2net.pth"],
                "mobile_sam": ["mobile_sam.pt"],
                "isnet": ["isnetis.onnx"]
            },
            4: {  # Geometric Matching
                "gmm": ["gmm_final.pth"],
                "tps": ["tps_network.pth"],
                "sam_shared": ["sam_vit_h_4b8939.pth"],
                "vit_large": ["ViT-L-14.pt"],
                "efficientnet": ["efficientnet_b0_ultra.pth"]
            },
            6: {  # Virtual Fitting
                "ootd_dc_garm": ["ootd_dc/checkpoint-36000/unet_garm/diffusion_pytorch_model.safetensors"],
                "ootd_dc_vton": ["ootd_dc/checkpoint-36000/unet_vton/diffusion_pytorch_model.safetensors"],
                "text_encoder": ["text_encoder/pytorch_model.bin"],
                "vae": ["vae/diffusion_pytorch_model.bin"]
            }
        }
        
        result = {}
        step_models = step_mappings.get(step_id, {})
        model_type = self._get_model_type_by_step(step_id)
        
        for model_key, possible_filenames in step_models.items():
            for filename in possible_filenames:
                found_path = self.find_model_file(filename, model_type)
                if found_path:
                    result[model_key] = found_path
                    break
                    
        return result
    
    def _get_model_type_by_step(self, step_id: int) -> str:
        """Step IDë¥¼ ëª¨ë¸ íƒ€ì…ìœ¼ë¡œ ë³€í™˜"""
        type_mapping = {
            1: "human_parsing", 2: "pose_estimation", 3: "cloth_segmentation",
            4: "geometric_matching", 5: "cloth_warping", 6: "virtual_fitting",
            7: "post_processing", 8: "quality_assessment"
        }
        return type_mapping.get(step_id, "unknown")

# ==============================================
# ğŸ”¥ 2. ì‹¤ì œ AI ëª¨ë¸ í´ë˜ìŠ¤ êµ¬í˜„
# ==============================================

@dataclass
class ModelInfo:
    """ëª¨ë¸ ì •ë³´ êµ¬ì¡°"""
    name: str
    path: Path
    size_mb: float
    loaded: bool = False
    parameters: int = 0
    device: str = "cpu"

class RealAIModelBase(nn.Module):
    """ì‹¤ì œ AI ëª¨ë¸ ë² ì´ìŠ¤ í´ë˜ìŠ¤"""
    
    def __init__(self, model_path: Path, device: str = "auto"):
        super().__init__()
        self.model_path = model_path
        self.device = self._resolve_device(device)
        self.model_info = None
        self.logger = logging.getLogger(self.__class__.__name__)
        
    def _resolve_device(self, device: str) -> str:
        """ë””ë°”ì´ìŠ¤ ìë™ ì„ íƒ"""
        if not TORCH_AVAILABLE:
            return "cpu"
            
        if device == "auto":
            if torch.backends.mps.is_available():
                return "mps"  # M3 Max
            elif torch.cuda.is_available():
                return "cuda"
            else:
                return "cpu"
        return device
    
    def load_checkpoint(self) -> bool:
        """ì²´í¬í¬ì¸íŠ¸ ë¡œë”© (ì‹¤ì œ êµ¬í˜„)"""
        try:
            if not self.model_path.exists():
                self.logger.error(f"âŒ ëª¨ë¸ íŒŒì¼ ì—†ìŒ: {self.model_path}")
                return False
                
            self.logger.info(f"ğŸ“¥ ëª¨ë¸ ë¡œë”© ì‹œì‘: {self.model_path.name}")
            
            # ğŸ”¥ ë””ë°”ì´ìŠ¤ í˜¸í™˜ì„± í•´ê²°
            if self.device == "mps":
                # MPSëŠ” ì§ì ‘ ë¡œë”©ì´ ë¶ˆì•ˆì •í•˜ë¯€ë¡œ CPUë¡œ ë¨¼ì € ë¡œë”© í›„ ì´ë™
                checkpoint = torch.load(self.model_path, map_location='cpu')
            else:
                checkpoint = torch.load(self.model_path, map_location=self.device)
            
            # ì²´í¬í¬ì¸íŠ¸ êµ¬ì¡° ë¶„ì„
            if isinstance(checkpoint, dict):
                if 'state_dict' in checkpoint:
                    state_dict = checkpoint['state_dict']
                elif 'model' in checkpoint:
                    state_dict = checkpoint['model']
                else:
                    state_dict = checkpoint
            else:
                state_dict = checkpoint
            
            # ğŸ”¥ MPS ë””ë°”ì´ìŠ¤ í˜¸í™˜ì„± ì²˜ë¦¬
            if self.device == "mps":
                # CPUì—ì„œ ë¡œë”©ëœ í…ì„œë“¤ì„ MPSë¡œ ì•ˆì „í•˜ê²Œ ì´ë™
                try:
                    # ëª¨ë¸ì„ CPUì—ì„œ êµ¬ì„±í•œ í›„ MPSë¡œ ì´ë™
                    if hasattr(self, 'load_state_dict'):
                        # strict=Falseë¡œ ë¶€ë¶„ ë¡œë”© í—ˆìš©
                        missing_keys, unexpected_keys = self.load_state_dict(state_dict, strict=False)
                        if len(missing_keys) > 0:
                            self.logger.warning(f"âš ï¸ ëˆ„ë½ëœ í‚¤: {len(missing_keys)}ê°œ")
                        if len(unexpected_keys) > 0:
                            self.logger.warning(f"âš ï¸ ì˜ˆìƒì¹˜ ëª»í•œ í‚¤: {len(unexpected_keys)}ê°œ")
                    
                    # ğŸ”¥ MPS ë¬¸ì œ í•´ê²°: ì•ˆì „í•œ ëª¨ë¸ ì´ë™
                    try:
                        # ëª¨ë¸ì„ MPSë¡œ ì´ë™
                        self.to(self.device)
                        self.logger.info(f"ğŸ”„ ëª¨ë¸ì„ {self.device}ë¡œ ì´ë™ ì™„ë£Œ")
                    except Exception as mps_move_error:
                        self.logger.warning(f"âš ï¸ MPS ì´ë™ ì¤‘ ë¬¸ì œ ë°œìƒ, CPU ì‚¬ìš©: {mps_move_error}")
                        self.device = "cpu"
                        self.to(self.device)
                    
                except Exception as mps_error:
                    self.logger.warning(f"âš ï¸ MPS ì²˜ë¦¬ ì‹¤íŒ¨, CPU ì‚¬ìš©: {mps_error}")
                    self.device = "cpu"
                    self.to(self.device)
            else:
                # CPU ë˜ëŠ” CUDAì˜ ê²½ìš°
                if hasattr(self, 'load_state_dict'):
                    missing_keys, unexpected_keys = self.load_state_dict(state_dict, strict=False)
                    if len(missing_keys) > 0:
                        self.logger.warning(f"âš ï¸ ëˆ„ë½ëœ í‚¤: {len(missing_keys)}ê°œ")
                    if len(unexpected_keys) > 0:
                        self.logger.warning(f"âš ï¸ ì˜ˆìƒì¹˜ ëª»í•œ í‚¤: {len(unexpected_keys)}ê°œ")
                
                self.to(self.device)
            
            # ëª¨ë¸ ì •ë³´ ì—…ë°ì´íŠ¸
            total_params = sum(p.numel() for p in state_dict.values() if isinstance(p, torch.Tensor))
            size_mb = self.model_path.stat().st_size / (1024**2)
            
            self.model_info = ModelInfo(
                name=self.model_path.name,
                path=self.model_path,
                size_mb=size_mb,
                loaded=True,
                parameters=total_params,
                device=self.device
            )
            
            self.logger.info(f"âœ… ëª¨ë¸ ë¡œë”© ì„±ê³µ: {size_mb:.1f}MB, {total_params:,}ê°œ íŒŒë¼ë¯¸í„° ({self.device})")
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e}")
            return False

class RealGMMModel(RealAIModelBase):
    """ì‹¤ì œ GMM (Geometric Matching Module) ëª¨ë¸"""
    
    def __init__(self, model_path: Path, device: str = "auto"):
        super().__init__(model_path, device)
        
        # GMM ë„¤íŠ¸ì›Œí¬ êµ¬ì¡° (ì‹¤ì œ êµ¬í˜„)
        self.feature_extractor = nn.Sequential(
            nn.Conv2d(6, 64, 3, padding=1),  # person + clothing
            nn.ReLU(inplace=True),
            nn.Conv2d(64, 128, 3, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv2d(128, 256, 3, padding=1),
            nn.ReLU(inplace=True)
        )
        
        self.matching_head = nn.Sequential(
            nn.Conv2d(256, 128, 1),
            nn.ReLU(inplace=True),
            nn.Conv2d(128, 2, 1),  # x, y displacement
            nn.Tanh()  # [-1, 1] ë²”ìœ„
        )
        
    def forward(self, person_image: torch.Tensor, clothing_image: torch.Tensor) -> Dict[str, torch.Tensor]:
        """ì‹¤ì œ GMM ìˆœì „íŒŒ"""
        # ì…ë ¥ ê²€ì¦
        if person_image.shape != clothing_image.shape:
            raise ValueError("Personê³¼ clothing ì´ë¯¸ì§€ í¬ê¸°ê°€ ë‹¤ë¦…ë‹ˆë‹¤")
        
        # ğŸ”¥ ë””ë°”ì´ìŠ¤ í˜¸í™˜ì„± ë³´ì¥
        person_image = person_image.to(self.device)
        clothing_image = clothing_image.to(self.device)
            
        # 6ì±„ë„ ì…ë ¥ (person RGB + clothing RGB)
        combined_input = torch.cat([person_image, clothing_image], dim=1)
        
        # íŠ¹ì§• ì¶”ì¶œ
        features = self.feature_extractor(combined_input)
        
        # ê¸°í•˜í•™ì  ë§¤ì¹­
        displacement_field = self.matching_head(features)
        
        # ê²©ì ìƒì„± (TPS ë³€í˜•ìš©)
        B, _, H, W = displacement_field.shape
        grid_y, grid_x = torch.meshgrid(
            torch.linspace(-1, 1, H, device=self.device),
            torch.linspace(-1, 1, W, device=self.device),
            indexing='ij'
        )
        base_grid = torch.stack([grid_x, grid_y], dim=0).unsqueeze(0).repeat(B, 1, 1, 1)
        
        # ë³€í˜•ëœ ê²©ì
        warped_grid = base_grid + displacement_field
        
        return {
            'displacement_field': displacement_field,
            'warped_grid': warped_grid,
            'matching_score': torch.mean(torch.abs(displacement_field), dim=[1, 2, 3])
        }

class RealTPSModel(RealAIModelBase):
    """ì‹¤ì œ TPS (Thin Plate Spline) ëª¨ë¸"""
    
    def __init__(self, model_path: Path, device: str = "auto"):
        super().__init__(model_path, device)
        
        # TPS ë„¤íŠ¸ì›Œí¬ êµ¬ì¡°
        self.control_point_net = nn.Sequential(
            nn.Conv2d(3, 64, 3, padding=1),
            nn.ReLU(inplace=True),
            nn.AdaptiveAvgPool2d((8, 6)),  # 5x5 ì œì–´ì ìœ¼ë¡œ ë³€ê²½
            nn.Flatten(),
            nn.Linear(64 * 8 * 6, 256),
            nn.ReLU(inplace=True),
            nn.Linear(256, 50)  # 5x5 = 25ê°œ ì œì–´ì , x2 = 50
        )
        
    def forward(self, clothing_image: torch.Tensor, displacement_field: torch.Tensor) -> Dict[str, torch.Tensor]:
        """ì‹¤ì œ TPS ë³€í˜•"""
        # ğŸ”¥ ë””ë°”ì´ìŠ¤ í˜¸í™˜ì„± ë³´ì¥
        clothing_image = clothing_image.to(self.device)
        displacement_field = displacement_field.to(self.device)
        
        # ì œì–´ì  ì˜ˆì¸¡
        control_points = self.control_point_net(clothing_image)
        control_points = control_points.view(-1, 25, 2)  # [B, 25, 2]
        
        # TPS ë³€í˜• ì ìš©
        warped_clothing = self._apply_tps_transform(clothing_image, control_points, displacement_field)
        
        return {
            'warped_clothing': warped_clothing,
            'control_points': control_points,
            'tps_quality': torch.mean(torch.std(control_points, dim=1))
        }
    
    def _apply_tps_transform(self, image: torch.Tensor, control_points: torch.Tensor, 
                           displacement_field: torch.Tensor) -> torch.Tensor:
        """TPS ë³€í˜• ì ìš© (MPS í˜¸í™˜ì„± ê°œì„ )"""
        B, C, H, W = image.shape
        
        # ë³€í˜• ê²©ì ìƒì„±
        grid = torch.nn.functional.interpolate(
            displacement_field, 
            size=(H, W), 
            mode='bilinear', 
            align_corners=False
        )
        
        # ê²©ìë¥¼ [-1, 1] ë²”ìœ„ë¡œ ì •ê·œí™”
        grid = grid.permute(0, 2, 3, 1)  # [B, H, W, 2]
        
        # ğŸ”¥ MPS í˜¸í™˜ì„±: padding_mode ë³€ê²½
        # border ëŒ€ì‹  zeros ë˜ëŠ” reflection ì‚¬ìš©
        try:
            # ì²« ë²ˆì§¸ ì‹œë„: zeros padding (MPS ì§€ì›)
            warped = torch.nn.functional.grid_sample(
                image, grid, mode='bilinear', padding_mode='zeros', align_corners=False
            )
        except Exception as mps_error:
            try:
                # ë‘ ë²ˆì§¸ ì‹œë„: reflection padding
                warped = torch.nn.functional.grid_sample(
                    image, grid, mode='bilinear', padding_mode='reflection', align_corners=False
                )
            except Exception:
                # ìµœì¢… í´ë°±: CPUì—ì„œ ê³„ì‚° í›„ MPSë¡œ ì´ë™
                image_cpu = image.cpu()
                grid_cpu = grid.cpu()
                warped_cpu = torch.nn.functional.grid_sample(
                    image_cpu, grid_cpu, mode='bilinear', padding_mode='border', align_corners=False
                )
                warped = warped_cpu.to(self.device)
        
        return warped

class RealSAMModel(RealAIModelBase):
    """ì‹¤ì œ SAM (Segment Anything Model) ëª¨ë¸"""
    
    def __init__(self, model_path: Path, device: str = "auto"):
        super().__init__(model_path, device)
        
        # SAM ì´ë¯¸ì§€ ì¸ì½”ë” (ê°„ì†Œí™”)
        self.image_encoder = nn.Sequential(
            nn.Conv2d(3, 64, 7, stride=2, padding=3),
            nn.BatchNorm2d(64),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(3, stride=2, padding=1),
            nn.AdaptiveAvgPool2d((64, 64)),
            nn.Conv2d(64, 256, 1),
            nn.ReLU(inplace=True)
        )
        
        # ë§ˆìŠ¤í¬ ë””ì½”ë”
        self.mask_decoder = nn.Sequential(
            nn.ConvTranspose2d(256, 128, 4, stride=2, padding=1),
            nn.ReLU(inplace=True),
            nn.ConvTranspose2d(128, 64, 4, stride=2, padding=1),
            nn.ReLU(inplace=True),
            nn.ConvTranspose2d(64, 1, 4, stride=2, padding=1),
            nn.Sigmoid()
        )
        
    def forward(self, image: torch.Tensor, bbox: torch.Tensor = None) -> Dict[str, torch.Tensor]:
        """ì‹¤ì œ SAM ìˆœì „íŒŒ"""
        # ğŸ”¥ ë””ë°”ì´ìŠ¤ í˜¸í™˜ì„± ë³´ì¥
        image = image.to(self.device)
        
        # ì´ë¯¸ì§€ ì¸ì½”ë”©
        image_features = self.image_encoder(image)
        
        # ë§ˆìŠ¤í¬ ìƒì„±
        mask = self.mask_decoder(image_features)
        
        # ì›ë³¸ í¬ê¸°ë¡œ ì—…ìƒ˜í”Œë§
        B, C, H, W = image.shape
        mask = torch.nn.functional.interpolate(
            mask, size=(H, W), mode='bilinear', align_corners=False
        )
        
        return {
            'mask': mask,
            'image_features': image_features,
            'confidence': torch.mean(mask, dim=[1, 2, 3])
        }

# ==============================================
# ğŸ”¥ 3. ì‹¤ì œ AI í…ŒìŠ¤íŠ¸ ì‹œìŠ¤í…œ
# ==============================================

class RealAITestSystem:
    """ì‹¤ì œ AI ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì‹œìŠ¤í…œ"""
    
    def __init__(self, ai_models_root: str = "ai_models"):
        self.mapper = SmartModelPathMapper(ai_models_root)
        self.loaded_models = {}
        self.test_results = {}
        self.logger = self._setup_logger()
        
    def _setup_logger(self) -> logging.Logger:
        """ë¡œê±° ì„¤ì •"""
        logger = logging.getLogger("RealAITestSystem")
        if not logger.handlers:
            handler = logging.StreamHandler()
            formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
            handler.setFormatter(formatter)
            logger.addHandler(handler)
            logger.setLevel(logging.INFO)
        return logger
    
    async def test_step_04_geometric_matching(self) -> Dict[str, Any]:
        """Step 04 ê¸°í•˜í•™ì  ë§¤ì¹­ ì‹¤ì œ í…ŒìŠ¤íŠ¸"""
        self.logger.info("ğŸ”¥ Step 04 ê¸°í•˜í•™ì  ë§¤ì¹­ ì‹¤ì œ AI í…ŒìŠ¤íŠ¸ ì‹œì‘...")
        
        # 1. ëª¨ë¸ íŒŒì¼ íƒì§€
        model_paths = self.mapper.get_step_model_mapping(4)
        self.logger.info(f"ğŸ“ ë°œê²¬ëœ ëª¨ë¸ë“¤: {list(model_paths.keys())}")
        
        results = {
            'step_id': 4,
            'test_name': 'geometric_matching_real_ai',
            'models_found': len(model_paths),
            'models_loaded': 0,
            'tests_passed': 0,
            'inference_results': {},
            'performance': {}
        }
        
        # 2. GMM ëª¨ë¸ í…ŒìŠ¤íŠ¸
        if 'gmm' in model_paths:
            try:
                start_time = time.time()
                gmm_model = RealGMMModel(model_paths['gmm'])
                
                if gmm_model.load_checkpoint():
                    results['models_loaded'] += 1
                    self.loaded_models['gmm'] = gmm_model
                    
                    # ì‹¤ì œ ì¶”ë¡  í…ŒìŠ¤íŠ¸
                    dummy_person = torch.randn(1, 3, 256, 192)
                    dummy_clothing = torch.randn(1, 3, 256, 192)
                    
                    # ğŸ”¥ eval ëª¨ë“œë¡œ ì „í™˜ (ì¶”ë¡ ìš©)
                    gmm_model.eval()
                    with torch.no_grad():
                        gmm_result = gmm_model(dummy_person, dummy_clothing)
                    
                    results['inference_results']['gmm'] = {
                        'displacement_field_shape': list(gmm_result['displacement_field'].shape),
                        'matching_score': float(gmm_result['matching_score'].mean()),
                        'warped_grid_range': [
                            float(gmm_result['warped_grid'].min()),
                            float(gmm_result['warped_grid'].max())
                        ]
                    }
                    results['tests_passed'] += 1
                    
                    load_time = time.time() - start_time
                    results['performance']['gmm_load_time'] = load_time
                    self.logger.info(f"âœ… GMM ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì„±ê³µ: {load_time:.2f}s")
                    
            except Exception as e:
                self.logger.error(f"âŒ GMM ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
                results['inference_results']['gmm'] = {'error': str(e)}
        
        # 3. TPS ëª¨ë¸ í…ŒìŠ¤íŠ¸
        if 'tps' in model_paths:
            try:
                start_time = time.time()
                tps_model = RealTPSModel(model_paths['tps'])
                
                if tps_model.load_checkpoint():
                    results['models_loaded'] += 1
                    self.loaded_models['tps'] = tps_model
                    
                    # ì‹¤ì œ ì¶”ë¡  í…ŒìŠ¤íŠ¸
                    dummy_clothing = torch.randn(1, 3, 256, 192)
                    dummy_displacement = torch.randn(1, 2, 64, 48)
                    
                    # ğŸ”¥ eval ëª¨ë“œë¡œ ì „í™˜ (ì¶”ë¡ ìš©)
                    tps_model.eval()
                    with torch.no_grad():
                        tps_result = tps_model(dummy_clothing, dummy_displacement)
                    
                    results['inference_results']['tps'] = {
                        'warped_clothing_shape': list(tps_result['warped_clothing'].shape),
                        'control_points_shape': list(tps_result['control_points'].shape),
                        'tps_quality': float(tps_result['tps_quality'])
                    }
                    results['tests_passed'] += 1
                    
                    load_time = time.time() - start_time
                    results['performance']['tps_load_time'] = load_time
                    self.logger.info(f"âœ… TPS ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì„±ê³µ: {load_time:.2f}s")
                    
            except Exception as e:
                self.logger.error(f"âŒ TPS ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
                results['inference_results']['tps'] = {'error': str(e)}
        
        # 4. SAM ëª¨ë¸ í…ŒìŠ¤íŠ¸ (ê³µìœ )
        if 'sam_shared' in model_paths:
            try:
                start_time = time.time()
                sam_model = RealSAMModel(model_paths['sam_shared'])
                
                if sam_model.load_checkpoint():
                    results['models_loaded'] += 1
                    self.loaded_models['sam'] = sam_model
                    
                    # ì‹¤ì œ ì¶”ë¡  í…ŒìŠ¤íŠ¸
                    dummy_image = torch.randn(1, 3, 256, 256)
                    
                    # ğŸ”¥ eval ëª¨ë“œë¡œ ì „í™˜ (ì¶”ë¡ ìš©)
                    sam_model.eval()
                    with torch.no_grad():
                        sam_result = sam_model(dummy_image)
                    
                    results['inference_results']['sam'] = {
                        'mask_shape': list(sam_result['mask'].shape),
                        'confidence': float(sam_result['confidence'].mean()),
                        'image_features_shape': list(sam_result['image_features'].shape)
                    }
                    results['tests_passed'] += 1
                    
                    load_time = time.time() - start_time
                    results['performance']['sam_load_time'] = load_time
                    self.logger.info(f"âœ… SAM ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì„±ê³µ: {load_time:.2f}s")
                    
            except Exception as e:
                self.logger.error(f"âŒ SAM ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
                results['inference_results']['sam'] = {'error': str(e)}
        
        # 5. ì „ì²´ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸
        if results['models_loaded'] >= 2:
            try:
                start_time = time.time()
                
                # í†µí•© ì¶”ë¡  í…ŒìŠ¤íŠ¸
                person_image = torch.randn(1, 3, 256, 192)
                clothing_image = torch.randn(1, 3, 256, 192)
                
                # GMM -> TPS íŒŒì´í”„ë¼ì¸
                if 'gmm' in self.loaded_models and 'tps' in self.loaded_models:
                    # ğŸ”¥ eval ëª¨ë“œ ë° no_grad ì ìš© + MPS í˜¸í™˜ì„±
                    self.loaded_models['gmm'].eval()
                    self.loaded_models['tps'].eval()
                    
                    with torch.no_grad():
                        try:
                            gmm_result = self.loaded_models['gmm'](person_image, clothing_image)
                            tps_result = self.loaded_models['tps'](clothing_image, gmm_result['displacement_field'])
                        except Exception as pipeline_error:
                            # MPS ì—ëŸ¬ ì‹œ CPUë¡œ í´ë°±
                            if "MPS" in str(pipeline_error):
                                self.logger.warning(f"âš ï¸ MPS íŒŒì´í”„ë¼ì¸ ì˜¤ë¥˜, CPUë¡œ í´ë°±: {pipeline_error}")
                                # ëª¨ë¸ë“¤ì„ CPUë¡œ ì´ë™
                                self.loaded_models['gmm'].to('cpu')
                                self.loaded_models['tps'].to('cpu')
                                person_image = person_image.to('cpu')
                                clothing_image = clothing_image.to('cpu')
                                
                                gmm_result = self.loaded_models['gmm'](person_image, clothing_image)
                                tps_result = self.loaded_models['tps'](clothing_image, gmm_result['displacement_field'])
                                
                                # MPSë¡œ ë‹¤ì‹œ ì´ë™
                                self.loaded_models['gmm'].to('mps')
                                self.loaded_models['tps'].to('mps')
                            else:
                                raise pipeline_error
                    
                    results['inference_results']['pipeline'] = {
                        'final_warped_shape': list(tps_result['warped_clothing'].shape),
                        'overall_quality': float((gmm_result['matching_score'] + tps_result['tps_quality']) / 2)
                    }
                    results['tests_passed'] += 1
                    
                pipeline_time = time.time() - start_time
                results['performance']['pipeline_time'] = pipeline_time
                self.logger.info(f"âœ… ì „ì²´ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸ ì„±ê³µ: {pipeline_time:.2f}s")
                
            except Exception as e:
                self.logger.error(f"âŒ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
                results['inference_results']['pipeline'] = {'error': str(e)}
        
        # ê²°ê³¼ ìš”ì•½
        success_rate = results['tests_passed'] / max(results['models_found'], 1) * 100
        results['success_rate'] = success_rate
        
        self.logger.info(f"ğŸ¯ Step 04 í…ŒìŠ¤íŠ¸ ì™„ë£Œ: {results['tests_passed']}/{results['models_found']} ì„±ê³µ ({success_rate:.1f}%)")
        
        return results
    
    async def generate_test_report(self) -> str:
        """í…ŒìŠ¤íŠ¸ ê²°ê³¼ ë³´ê³ ì„œ ìƒì„±"""
        report_path = Path("real_ai_test_report.json")
        
        report_data = {
            'test_timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),
            'system_info': {
                'platform': platform.system(),
                'python_version': platform.python_version(),
                'torch_version': torch.__version__ if TORCH_AVAILABLE else "Not available",
                'device': 'mps' if torch.backends.mps.is_available() else 'cpu',
                'ai_models_root': str(self.mapper.ai_models_root)
            },
            'model_discovery': {
                'total_files_found': len(self.mapper.model_cache),
                'search_paths': list(self.mapper.search_priority.keys())
            },
            'test_results': self.test_results,
            'loaded_models': {
                name: {
                    'path': str(model.model_path),
                    'size_mb': model.model_info.size_mb if model.model_info else 0,
                    'parameters': model.model_info.parameters if model.model_info else 0
                }
                for name, model in self.loaded_models.items()
            }
        }
        
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(report_data, f, indent=2, ensure_ascii=False)
            
        self.logger.info(f"ğŸ“„ í…ŒìŠ¤íŠ¸ ë³´ê³ ì„œ ìƒì„±: {report_path}")
        return str(report_path)

# ==============================================
# ğŸ”¥ 4. ì‹¤í–‰ í•¨ìˆ˜ë“¤
# ==============================================

async def test_real_ai_models_step_04():
    """Step 04 ì‹¤ì œ AI ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    print("ğŸ”¥ ì‹¤ì œ AI ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì‹œìŠ¤í…œ ì‹œì‘")
    print("=" * 60)
    
    # ë¼ì´ë¸ŒëŸ¬ë¦¬ í™•ì¸
    if not ALL_LIBS_AVAILABLE:
        print("âŒ í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì™„ì „í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤!")
        print("ğŸ’¡ í•´ê²° ë°©ë²•:")
        print("   conda deactivate && conda activate mycloset-ai-clean")
        print("   pip uninstall numpy -y && pip install numpy")
        print("   pip install torch torchvision pillow")
        return False
    
    # 1. ì‹œìŠ¤í…œ ì •ë³´
    if PLATFORM_AVAILABLE:
        print(f"ğŸ Python: {platform.python_version()}")
    print(f"ğŸ”¥ PyTorch: {torch.__version__ if TORCH_AVAILABLE else 'âŒ ë¯¸ì„¤ì¹˜'}")
    if TORCH_AVAILABLE:
        print(f"ğŸ”§ ë””ë°”ì´ìŠ¤: {'MPS' if torch.backends.mps.is_available() else 'CPU'}")
    print(f"ğŸ“ ì‘ì—… ë””ë ‰í† ë¦¬: {Path.cwd()}")
    
    # 2. í…ŒìŠ¤íŠ¸ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    try:
        test_system = RealAITestSystem()
        print(f"âœ… í…ŒìŠ¤íŠ¸ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
        print(f"ğŸ“ AI ëª¨ë¸ ê²½ë¡œ: {test_system.mapper.ai_models_root}")
        
        # 3. Step 04 í…ŒìŠ¤íŠ¸ ì‹¤í–‰
        step_04_results = await test_system.test_step_04_geometric_matching()
        test_system.test_results['step_04'] = step_04_results
        
        # 4. ê²°ê³¼ ì¶œë ¥
        print("\n" + "=" * 60)
        print("ğŸ¯ Step 04 ê¸°í•˜í•™ì  ë§¤ì¹­ í…ŒìŠ¤íŠ¸ ê²°ê³¼:")
        print(f"   ğŸ“Š ëª¨ë¸ ë°œê²¬: {step_04_results['models_found']}ê°œ")
        print(f"   âœ… ëª¨ë¸ ë¡œë”©: {step_04_results['models_loaded']}ê°œ")
        print(f"   ğŸ§ª í…ŒìŠ¤íŠ¸ í†µê³¼: {step_04_results['tests_passed']}ê°œ")
        print(f"   ğŸ“ˆ ì„±ê³µë¥ : {step_04_results['success_rate']:.1f}%")
        
        # 5. ê°œë³„ ëª¨ë¸ ê²°ê³¼
        for model_name, result in step_04_results['inference_results'].items():
            if 'error' not in result:
                print(f"   âœ… {model_name}: ì„±ê³µ")
                if model_name in step_04_results['performance']:
                    load_time = step_04_results['performance'][f'{model_name}_load_time']
                    print(f"      â±ï¸ ë¡œë”© ì‹œê°„: {load_time:.2f}s")
            else:
                print(f"   âŒ {model_name}: {result['error']}")
        
        # 6. ë³´ê³ ì„œ ìƒì„±
        report_path = await test_system.generate_test_report()
        print(f"\nğŸ“„ ìƒì„¸ ë³´ê³ ì„œ: {report_path}")
        
        # 7. conda ê°€ì´ë“œ
        print("\n" + "=" * 60)
        print("ğŸ conda í™˜ê²½ ìµœì í™” ê°€ì´ë“œ:")
        print("   conda activate mycloset-ai-clean")
        print("   export PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0")
        print("   export OMP_NUM_THREADS=16")
        
        return step_04_results['success_rate'] > 50
        
    except Exception as e:
        print(f"\nâŒ í…ŒìŠ¤íŠ¸ ì‹œìŠ¤í…œ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
        print(f"ğŸ“ ì˜¤ë¥˜ ìœ„ì¹˜: {traceback.format_exc()}")
        return False

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸ”¥ MyCloset AI - ì‹¤ì œ AI ëª¨ë¸ ì™„ì „ í™œìš© ì‹œìŠ¤í…œ")
    print("âœ… 229GB ëª¨ë¸ íŒŒì¼ ì™„ì „ í™œìš©")
    print("âœ… SmartModelPathMapper ë™ì  ê²½ë¡œ ë§¤í•‘")
    print("âœ… ì‹¤ì œ AI ì¶”ë¡  ë¡œì§")
    print("=" * 60)
    
    # ë¹„ë™ê¸° ì‹¤í–‰
    try:
        success = asyncio.run(test_real_ai_models_step_04())
        
        if success:
            print("\nğŸ‰ ì‹¤ì œ AI ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì„±ê³µ!")
            print("âœ… ì§„ì§œ AI ì¶”ë¡ ì´ ì‘ë™í•©ë‹ˆë‹¤!")
        else:
            print("\nâš ï¸ ì¼ë¶€ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨")
            print("ğŸ’¡ conda í™˜ê²½ ë° ëª¨ë¸ íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”")
            
    except KeyboardInterrupt:
        print("\nâ›” ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë¨")
    except Exception as e:
        print(f"\nâŒ ì‹¤í–‰ ì‹¤íŒ¨: {e}")

if __name__ == "__main__":
    main()