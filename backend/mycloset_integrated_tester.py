#!/usr/bin/env python3
"""
ğŸ”¥ MyCloset AI - ì™„ì „ ì‹¤ì „ í†µí•© í…ŒìŠ¤í„° v2.0
================================================================================
âœ… ì‹¤ì œ 229GB AI ëª¨ë¸ íŒŒì¼ ê²€ì¦
âœ… í”„ë¡œì íŠ¸ì˜ ModelLoader v5.1 & StepFactory v11.0 ì™„ì „ í™œìš©
âœ… step_interface.py v5.2 í˜¸í™˜ì„± ì™„ì „ í…ŒìŠ¤íŠ¸
âœ… ì‹¤ì œ ì²´í¬í¬ì¸íŠ¸ ë¡œë”© + ì¶”ë¡  ê²€ì¦
âœ… BaseStepMixin v19.2 í‘œì¤€ ì¤€ìˆ˜ í™•ì¸
âœ… ì‹¤ì œ AI íŒŒì´í”„ë¼ì¸ end-to-end í…ŒìŠ¤íŠ¸
âœ… M3 Max 128GB ë©”ëª¨ë¦¬ ìµœì í™” ê²€ì¦
âœ… ì‹¤ì œ í”„ë¡œë•ì…˜ í™˜ê²½ ì‹œë®¬ë ˆì´ì…˜
âœ… ìƒì„¸í•œ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ & ë””ë²„ê¹…
================================================================================
"""

import os
import sys
import time
import gc
import warnings
import threading
import asyncio
import psutil
import hashlib
from pathlib import Path
from typing import Dict, Any, Optional, List, Tuple
from dataclasses import dataclass, field
from enum import Enum
import logging
from concurrent.futures import ThreadPoolExecutor
import traceback
import json

# MyCloset AI í”„ë¡œì íŠ¸ ê²½ë¡œ ìë™ ì„¤ì •
PROJECT_ROOT = Path(__file__).parent
BACKEND_ROOT = None

# í”„ë¡œì íŠ¸ êµ¬ì¡° ìë™ ê°ì§€
possible_roots = [
    Path("/Users/gimdudeul/MVP/mycloset-ai/backend"),
    PROJECT_ROOT / "backend",
    Path.cwd() / "backend",
    Path.cwd(),
]

for root in possible_roots:
    if root.exists() and (root / "app").exists():
        BACKEND_ROOT = root
        sys.path.insert(0, str(root))
        break

if not BACKEND_ROOT:
    print("âŒ MyCloset AI ë°±ì—”ë“œ ë£¨íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
    sys.exit(1)

print(f"ğŸ”§ ë°±ì—”ë“œ ë£¨íŠ¸: {BACKEND_ROOT}")
print(f"ğŸ”§ AI ëª¨ë¸ ì˜ˆìƒ ê²½ë¡œ: {BACKEND_ROOT / 'ai_models'}")

# ê²½ê³  ë° ë¡œê¹… ì„¤ì •
warnings.filterwarnings("ignore")
os.environ["TOKENIZERS_PARALLELISM"] = "false"
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')

class TestLevel(Enum):
    BASIC = "basic"          # ê¸°ë³¸ ì´ˆê¸°í™”ë§Œ
    STANDARD = "standard"    # ëª¨ë“  ëª¨ë¸ ë¡œë”©
    FULL = "full"           # ì¶”ë¡ ê¹Œì§€ í¬í•¨
    PRODUCTION = "production" # ì‹¤ì œ í”„ë¡œë•ì…˜ í™˜ê²½

class TestStatus(Enum):
    SUCCESS = "âœ…"
    FAILED = "âŒ"
    WARNING = "âš ï¸"
    LOADING = "â³"
    SKIPPED = "â­ï¸"
    PARTIAL = "ğŸ”¶"

@dataclass
class DetailedTestResult:
    name: str
    status: TestStatus
    message: str
    load_time: float = 0.0
    memory_mb: float = 0.0
    cpu_usage: float = 0.0
    details: Dict[str, Any] = field(default_factory=dict)
    error_trace: Optional[str] = None
    recommendations: List[str] = field(default_factory=list)

@dataclass 
class SystemInfo:
    cpu_count: int
    memory_total_gb: float
    memory_available_gb: float
    memory_used_gb: float
    python_version: str
    platform: str
    conda_env: Optional[str]
    pytorch_version: Optional[str]
    device_info: Dict[str, Any]

class MyClosetAdvancedTester:
    """MyCloset AI ì™„ì „ ì‹¤ì „ í†µí•© í…ŒìŠ¤í„°"""
    
    def __init__(self, test_level: TestLevel = TestLevel.STANDARD):
        self.test_level = test_level
        self.results: List[DetailedTestResult] = []
        self.system_info = self._collect_system_info()
        self.start_time = time.time()
        
        # ì»´í¬ë„ŒíŠ¸ë“¤
        self.model_loader = None
        self.step_factory = None
        self.step_instances = {}
        self.loaded_models = {}
        
        # í†µê³„
        self.total_models_tested = 0
        self.successful_models = 0
        self.total_memory_used = 0.0
        self.peak_memory_usage = 0.0
        
        print("ğŸš€ MyCloset AI ì™„ì „ ì‹¤ì „ í†µí•© í…ŒìŠ¤í„° v2.0 ì‹œì‘")
        print("=" * 80)
        self._print_system_info()
        
    def _collect_system_info(self) -> SystemInfo:
        """ì‹œìŠ¤í…œ ì •ë³´ ìˆ˜ì§‘"""
        try:
            memory = psutil.virtual_memory()
            
            # conda í™˜ê²½ í™•ì¸
            conda_env = os.environ.get('CONDA_DEFAULT_ENV')
            
            # PyTorch ë²„ì „ í™•ì¸
            pytorch_version = None
            try:
                import torch
                pytorch_version = torch.__version__
                device_info = {
                    'pytorch_available': True,
                    'cuda_available': torch.cuda.is_available(),
                    'mps_available': torch.backends.mps.is_available() if hasattr(torch.backends, 'mps') else False,
                    'device_count': torch.cuda.device_count() if torch.cuda.is_available() else 0
                }
            except ImportError:
                device_info = {'pytorch_available': False}
            
            return SystemInfo(
                cpu_count=psutil.cpu_count(),
                memory_total_gb=memory.total / (1024**3),
                memory_available_gb=memory.available / (1024**3),
                memory_used_gb=memory.used / (1024**3),
                python_version=sys.version.split()[0],
                platform=sys.platform,
                conda_env=conda_env,
                pytorch_version=pytorch_version,
                device_info=device_info
            )
        except Exception as e:
            print(f"âš ï¸ ì‹œìŠ¤í…œ ì •ë³´ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            return SystemInfo(0, 0, 0, 0, "unknown", "unknown", None, None, {})
    
    def _print_system_info(self):
        """ì‹œìŠ¤í…œ ì •ë³´ ì¶œë ¥"""
        info = self.system_info
        print(f"ğŸ’» ì‹œìŠ¤í…œ ì •ë³´:")
        print(f"   CPU: {info.cpu_count}ì½”ì–´")
        print(f"   ë©”ëª¨ë¦¬: {info.memory_total_gb:.1f}GB (ì‚¬ìš©: {info.memory_used_gb:.1f}GB, ì‚¬ìš©ê°€ëŠ¥: {info.memory_available_gb:.1f}GB)")
        print(f"   Python: {info.python_version}")
        print(f"   conda: {info.conda_env or 'N/A'}")
        print(f"   PyTorch: {info.pytorch_version or 'N/A'}")
        
        if info.device_info.get('pytorch_available'):
            print(f"   CUDA: {'âœ…' if info.device_info.get('cuda_available') else 'âŒ'}")
            print(f"   MPS: {'âœ…' if info.device_info.get('mps_available') else 'âŒ'}")
        
        print(f"   í…ŒìŠ¤íŠ¸ ë ˆë²¨: {self.test_level.value.upper()}")
        print()
    
    def _monitor_memory(self) -> float:
        """í˜„ì¬ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§ (MB)"""
        try:
            process = psutil.Process()
            memory_mb = process.memory_info().rss / (1024 * 1024)
            self.peak_memory_usage = max(self.peak_memory_usage, memory_mb)
            return memory_mb
        except:
            return 0.0
    
    def test_system_requirements(self) -> DetailedTestResult:
        """ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­ ê²€ì¦"""
        print("ğŸ” ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­ ê²€ì¦ ì¤‘...")
        start_time = time.time()
        memory_before = self._monitor_memory()
        
        try:
            issues = []
            recommendations = []
            
            # ë©”ëª¨ë¦¬ ê²€ì¦ (ìµœì†Œ 8GB ê¶Œì¥)
            if self.system_info.memory_total_gb < 8:
                issues.append(f"ë©”ëª¨ë¦¬ ë¶€ì¡±: {self.system_info.memory_total_gb:.1f}GB (ìµœì†Œ 8GB ê¶Œì¥)")
                recommendations.append("ë” ë§ì€ ë©”ëª¨ë¦¬ê°€ ìˆëŠ” ì‹œìŠ¤í…œ ì‚¬ìš© ê¶Œì¥")
            
            # conda í™˜ê²½ ê²€ì¦
            if not self.system_info.conda_env:
                issues.append("conda í™˜ê²½ì´ í™œì„±í™”ë˜ì§€ ì•ŠìŒ")
                recommendations.append("conda activate mycloset-ai-clean ì‹¤í–‰")
            elif self.system_info.conda_env not in ['mycloset-ai-clean', 'mycloset-ai']:
                issues.append(f"ê¶Œì¥ë˜ì§€ ì•ŠëŠ” conda í™˜ê²½: {self.system_info.conda_env}")
                recommendations.append("mycloset-ai-clean í™˜ê²½ ì‚¬ìš© ê¶Œì¥")
            
            # PyTorch ê²€ì¦
            if not self.system_info.pytorch_version:
                issues.append("PyTorchê°€ ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ")
                recommendations.append("pip install torch torchvision ì‹¤í–‰")
            
            # AI ëª¨ë¸ ë””ë ‰í† ë¦¬ ê²€ì¦
            ai_models_path = BACKEND_ROOT / "ai_models"
            if not ai_models_path.exists():
                issues.append("ai_models ë””ë ‰í† ë¦¬ê°€ ì—†ìŒ")
                recommendations.append("AI ëª¨ë¸ íŒŒì¼ë“¤ì„ ë‹¤ìš´ë¡œë“œí•˜ê³  ì˜¬ë°”ë¥¸ ìœ„ì¹˜ì— ë°°ì¹˜")
            
            load_time = time.time() - start_time
            memory_after = self._monitor_memory()
            
            if not issues:
                return DetailedTestResult(
                    "ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­",
                    TestStatus.SUCCESS,
                    "ëª¨ë“  ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­ ì¶©ì¡±",
                    load_time,
                    memory_after - memory_before,
                    details={'issues_found': 0}
                )
            else:
                return DetailedTestResult(
                    "ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­",
                    TestStatus.WARNING if len(issues) <= 2 else TestStatus.FAILED,
                    f"{len(issues)}ê°œ ë¬¸ì œ ë°œê²¬",
                    load_time,
                    memory_after - memory_before,
                    details={'issues': issues},
                    recommendations=recommendations
                )
                
        except Exception as e:
            return DetailedTestResult(
                "ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­",
                TestStatus.FAILED,
                f"ê²€ì¦ ì˜¤ë¥˜: {str(e)[:50]}",
                time.time() - start_time,
                error_trace=traceback.format_exc()
            )
    
    def test_model_loader_initialization(self) -> DetailedTestResult:
        """ModelLoader v5.1 ì´ˆê¸°í™” í…ŒìŠ¤íŠ¸"""
        print("ğŸ”§ ModelLoader v5.1 ì´ˆê¸°í™” í…ŒìŠ¤íŠ¸ ì¤‘...")
        start_time = time.time()
        memory_before = self._monitor_memory()
        
        try:
            # ModelLoader ê°€ì ¸ì˜¤ê¸°
            from app.ai_pipeline.utils.model_loader import get_global_model_loader, ModelLoader
            
            # ê¸€ë¡œë²Œ ë¡œë” ì´ˆê¸°í™”
            self.model_loader = get_global_model_loader()
            
            if not self.model_loader:
                return DetailedTestResult(
                    "ModelLoader v5.1 ì´ˆê¸°í™”",
                    TestStatus.FAILED,
                    "ê¸€ë¡œë²Œ ë¡œë” ë°˜í™˜ê°’ì´ None",
                    time.time() - start_time,
                    recommendations=["ModelLoader ì„¤ì • í™•ì¸"]
                )
            
            # ì†ì„± ê²€ì¦
            required_attrs = ['load_model', 'device', 'model_cache_dir']
            missing_attrs = [attr for attr in required_attrs if not hasattr(self.model_loader, attr)]
            
            # ì˜ì¡´ì„± ì£¼ì… ì»¨í…Œì´ë„ˆ ê²€ì¦
            di_integration = {}
            if hasattr(self.model_loader, 'validate_di_container_integration'):
                try:
                    di_integration = self.model_loader.validate_di_container_integration()
                except Exception as e:
                    di_integration = {'error': str(e)}
            
            load_time = time.time() - start_time
            memory_after = self._monitor_memory()
            
            details = {
                'loader_type': type(self.model_loader).__name__,
                'device': getattr(self.model_loader, 'device', 'unknown'),
                'missing_attributes': missing_attrs,
                'di_integration': di_integration,
                'cache_dir_exists': hasattr(self.model_loader, 'model_cache_dir') and 
                                  Path(self.model_loader.model_cache_dir).exists() if hasattr(self.model_loader, 'model_cache_dir') else False
            }
            
            if missing_attrs:
                return DetailedTestResult(
                    "ModelLoader v5.1 ì´ˆê¸°í™”",
                    TestStatus.PARTIAL,
                    f"ì¼ë¶€ ì†ì„± ëˆ„ë½: {missing_attrs}",
                    load_time,
                    memory_after - memory_before,
                    details=details,
                    recommendations=["ModelLoader í´ë˜ìŠ¤ êµ¬í˜„ í™•ì¸"]
                )
            
            return DetailedTestResult(
                "ModelLoader v5.1 ì´ˆê¸°í™”",
                TestStatus.SUCCESS,
                f"ì´ˆê¸°í™” ì™„ë£Œ (ë””ë°”ì´ìŠ¤: {details['device']})",
                load_time,
                memory_after - memory_before,
                details=details
            )
            
        except ImportError as e:
            return DetailedTestResult(
                "ModelLoader v5.1 ì´ˆê¸°í™”",
                TestStatus.FAILED,
                f"import ì‹¤íŒ¨: {str(e)[:50]}",
                time.time() - start_time,
                error_trace=traceback.format_exc(),
                recommendations=["app.ai_pipeline.utils.model_loader ëª¨ë“ˆ ê²½ë¡œ í™•ì¸"]
            )
        except Exception as e:
            return DetailedTestResult(
                "ModelLoader v5.1 ì´ˆê¸°í™”",
                TestStatus.FAILED,
                f"ì´ˆê¸°í™” ì˜¤ë¥˜: {str(e)[:50]}",
                time.time() - start_time,
                error_trace=traceback.format_exc()
            )
    
    def test_step_factory_initialization(self) -> DetailedTestResult:
        """StepFactory v11.0 ì´ˆê¸°í™” í…ŒìŠ¤íŠ¸"""
        print("ğŸ­ StepFactory v11.0 ì´ˆê¸°í™” í…ŒìŠ¤íŠ¸ ì¤‘...")
        start_time = time.time()
        memory_before = self._monitor_memory()
        
        try:
            from app.services.step_factory import StepFactory
            
            self.step_factory = StepFactory()
            
            if not self.step_factory:
                return DetailedTestResult(
                    "StepFactory v11.0 ì´ˆê¸°í™”",
                    TestStatus.FAILED,
                    "StepFactory ìƒì„± ì‹¤íŒ¨",
                    time.time() - start_time
                )
            
            # í•„ìˆ˜ ë©”ì„œë“œ ê²€ì¦
            required_methods = ['create_step', 'get_available_steps']
            missing_methods = [method for method in required_methods 
                             if not hasattr(self.step_factory, method)]
            
            # Step íƒ€ì… ëª©ë¡ í™•ì¸
            available_steps = []
            if hasattr(self.step_factory, 'get_available_steps'):
                try:
                    available_steps = self.step_factory.get_available_steps()
                except Exception as e:
                    available_steps = [f"ì˜¤ë¥˜: {e}"]
            
            load_time = time.time() - start_time
            memory_after = self._monitor_memory()
            
            details = {
                'factory_type': type(self.step_factory).__name__,
                'missing_methods': missing_methods,
                'available_steps': available_steps[:10],  # ì²˜ìŒ 10ê°œë§Œ
                'total_available_steps': len(available_steps) if isinstance(available_steps, list) else 0
            }
            
            if missing_methods:
                return DetailedTestResult(
                    "StepFactory v11.0 ì´ˆê¸°í™”",
                    TestStatus.PARTIAL,
                    f"ì¼ë¶€ ë©”ì„œë“œ ëˆ„ë½: {missing_methods}",
                    load_time,
                    memory_after - memory_before,
                    details=details
                )
            
            return DetailedTestResult(
                "StepFactory v11.0 ì´ˆê¸°í™”",
                TestStatus.SUCCESS,
                f"ì´ˆê¸°í™” ì™„ë£Œ ({len(available_steps)}ê°œ Step ì‚¬ìš© ê°€ëŠ¥)",
                load_time,
                memory_after - memory_before,
                details=details
            )
            
        except ImportError as e:
            return DetailedTestResult(
                "StepFactory v11.0 ì´ˆê¸°í™”",
                TestStatus.FAILED,
                f"import ì‹¤íŒ¨: {str(e)[:50]}",
                time.time() - start_time,
                error_trace=traceback.format_exc(),
                recommendations=["app.services.step_factory ëª¨ë“ˆ ê²½ë¡œ í™•ì¸"]
            )
        except Exception as e:
            return DetailedTestResult(
                "StepFactory v11.0 ì´ˆê¸°í™”",
                TestStatus.FAILED,
                f"ì´ˆê¸°í™” ì˜¤ë¥˜: {str(e)[:50]}",
                time.time() - start_time,
                error_trace=traceback.format_exc()
            )
    
    def test_core_model_loading(self) -> List[DetailedTestResult]:
        """í•µì‹¬ AI ëª¨ë¸ ë¡œë”© í…ŒìŠ¤íŠ¸"""
        print("ğŸ§  í•µì‹¬ AI ëª¨ë¸ ë¡œë”© í…ŒìŠ¤íŠ¸ ì¤‘...")
        
        # ì‹¤ì œ í”„ë¡œì íŠ¸ì—ì„œ ê²€ì¦ëœ í•µì‹¬ ëª¨ë¸ë“¤
        core_models = {
            # Human Parsing (Step 01) - 170.5MB ê²€ì¦ë¨
            "graphonomy": {
                "expected_size_mb": 170.5,
                "step_type": "step_01_human_parsing",
                "critical": True
            },
            # Cloth Segmentation (Step 03) - 2445.7MB + 38.8MB ê²€ì¦ë¨  
            "sam_vit_h_4b8939": {
                "expected_size_mb": 2445.7,
                "step_type": "step_03_cloth_segmentation", 
                "critical": True
            },
            "u2net_alternative": {
                "expected_size_mb": 38.8,
                "step_type": "step_03_cloth_segmentation",
                "critical": False
            },
            # Cloth Warping (Step 05) - 6616.6MB ê²€ì¦ë¨
            "RealVisXL_V4.0": {
                "expected_size_mb": 6616.6,
                "step_type": "step_05_cloth_warping",
                "critical": True
            },
            # Virtual Fitting (Step 06) - 3278.9MB ê²€ì¦ë¨ 
            "diffusion_unet_vton": {
                "expected_size_mb": 3278.9,
                "step_type": "step_06_virtual_fitting",
                "critical": True
            }
        }
        
        results = []
        
        if not self.model_loader:
            results.append(DetailedTestResult(
                "ëª¨ë¸ ë¡œë”© (ì „ì²´)",
                TestStatus.FAILED,
                "ModelLoaderê°€ ì´ˆê¸°í™”ë˜ì§€ ì•ŠìŒ",
                0.0,
                recommendations=["ModelLoader ì´ˆê¸°í™” ë¨¼ì € ì‹¤í–‰"]
            ))
            return results
        
        for model_name, config in core_models.items():
            print(f"  â³ {model_name} ë¡œë”© ì¤‘... (ì˜ˆìƒ: {config['expected_size_mb']:.1f}MB)")
            start_time = time.time()
            memory_before = self._monitor_memory()
            
            try:
                # ëª¨ë¸ ë¡œë”©
                model = self.model_loader.load_model(model_name)
                
                load_time = time.time() - start_time
                memory_after = self._monitor_memory()
                memory_used = memory_after - memory_before
                
                if model is None:
                    # ë¡œë”© ì‹¤íŒ¨
                    result = DetailedTestResult(
                        f"ëª¨ë¸ ë¡œë”©: {model_name}",
                        TestStatus.FAILED,
                        "ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨ (None ë°˜í™˜)",
                        load_time,
                        memory_used,
                        details={
                            'model_name': model_name,
                            'expected_size_mb': config['expected_size_mb'],
                            'step_type': config['step_type'],
                            'critical': config['critical']
                        },
                        recommendations=[
                            f"ai_models/{config['step_type']} ë””ë ‰í† ë¦¬ í™•ì¸",
                            "ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ ì¬ë‹¤ìš´ë¡œë“œ"
                        ]
                    )
                    print(f"    âŒ {model_name} ë¡œë”© ì‹¤íŒ¨")
                else:
                    # ë¡œë”© ì„±ê³µ - ì„¸ë¶€ ê²€ì¦
                    model_size_mb = 0.0
                    has_checkpoint = False
                    model_type = "Unknown"
                    
                    # ëª¨ë¸ í¬ê¸° í™•ì¸
                    if hasattr(model, 'memory_usage_mb'):
                        model_size_mb = model.memory_usage_mb
                    elif hasattr(model, 'get_memory_usage'):
                        model_size_mb = model.get_memory_usage()
                    
                    # ì²´í¬í¬ì¸íŠ¸ ë°ì´í„° í™•ì¸
                    if hasattr(model, 'checkpoint_data'):
                        has_checkpoint = model.checkpoint_data is not None
                    elif hasattr(model, 'get_checkpoint_data'):
                        checkpoint_data = model.get_checkpoint_data()
                        has_checkpoint = checkpoint_data is not None
                    
                    # ëª¨ë¸ íƒ€ì… í™•ì¸
                    if hasattr(model, 'model_type'):
                        model_type = model.model_type
                    else:
                        model_type = type(model).__name__
                    
                    # í¬ê¸° ê²€ì¦
                    size_diff_pct = abs(model_size_mb - config['expected_size_mb']) / config['expected_size_mb'] * 100 if config['expected_size_mb'] > 0 else 0
                    size_ok = size_diff_pct < 20  # 20% ì˜¤ì°¨ í—ˆìš©
                    
                    self.loaded_models[model_name] = model
                    self.total_models_tested += 1
                    if size_ok and has_checkpoint:
                        self.successful_models += 1
                    
                    details = {
                        'model_name': model_name,
                        'model_type': model_type,
                        'actual_size_mb': model_size_mb,
                        'expected_size_mb': config['expected_size_mb'],
                        'size_difference_pct': size_diff_pct,
                        'has_checkpoint': has_checkpoint,
                        'step_type': config['step_type'],
                        'critical': config['critical'],
                        'loader_method': getattr(model, 'load_method', 'unknown') if hasattr(model, 'load_method') else 'unknown'
                    }
                    
                    # ê²°ê³¼ íŒì •
                    if has_checkpoint and size_ok:
                        status = TestStatus.SUCCESS
                        message = f"ë¡œë”© ì™„ë£Œ ({model_size_mb:.1f}MB, ì²´í¬í¬ì¸íŠ¸ âœ…)"
                        print(f"    âœ… {model_name} ë¡œë”© ì„±ê³µ ({model_size_mb:.1f}MB)")
                    elif has_checkpoint and not size_ok:
                        status = TestStatus.WARNING
                        message = f"ë¡œë”©ë¨ but í¬ê¸° ì°¨ì´ ({model_size_mb:.1f}MB vs {config['expected_size_mb']:.1f}MB)"
                        print(f"    âš ï¸ {model_name} í¬ê¸° ë¶ˆì¼ì¹˜")
                    elif not has_checkpoint:
                        status = TestStatus.PARTIAL
                        message = f"ë©”íƒ€ë°ì´í„°ë§Œ ë¡œë”©ë¨ (ì²´í¬í¬ì¸íŠ¸ âŒ)"
                        print(f"    ğŸ”¶ {model_name} ë¶€ë¶„ ë¡œë”©")
                    else:
                        status = TestStatus.FAILED
                        message = "ì•Œ ìˆ˜ ì—†ëŠ” ìƒíƒœ"
                        print(f"    â“ {model_name} ì•Œ ìˆ˜ ì—†ëŠ” ìƒíƒœ")
                    
                    recommendations = []
                    if not has_checkpoint:
                        recommendations.append("ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ ê²½ë¡œ ë° ê¶Œí•œ í™•ì¸")
                    if not size_ok:
                        recommendations.append("ëª¨ë¸ íŒŒì¼ ì™„ì „ì„± ê²€ì¦ (ë‹¤ì‹œ ë‹¤ìš´ë¡œë“œ)")
                    
                    result = DetailedTestResult(
                        f"ëª¨ë¸ ë¡œë”©: {model_name}",
                        status,
                        message,
                        load_time,
                        memory_used,
                        details=details,
                        recommendations=recommendations
                    )
                
                results.append(result)
                
            except Exception as e:
                load_time = time.time() - start_time
                memory_after = self._monitor_memory()
                
                result = DetailedTestResult(
                    f"ëª¨ë¸ ë¡œë”©: {model_name}",
                    TestStatus.FAILED,
                    f"ë¡œë”© ì˜¤ë¥˜: {str(e)[:50]}",
                    load_time,
                    memory_after - memory_before,
                    details={
                        'model_name': model_name,
                        'error_type': type(e).__name__,
                        'step_type': config['step_type']
                    },
                    error_trace=traceback.format_exc(),
                    recommendations=[
                        "ì˜ì¡´ì„± íŒ¨í‚¤ì§€ ì„¤ì¹˜ í™•ì¸ (torch, torchvision)",
                        "ëª¨ë¸ íŒŒì¼ ì¡´ì¬ ë° ê¶Œí•œ í™•ì¸"
                    ]
                )
                results.append(result)
                print(f"    âŒ {model_name} ë¡œë”© ì˜¤ë¥˜: {e}")
        
        return results
    
    def test_step_pipeline_creation(self) -> List[DetailedTestResult]:
        """Step íŒŒì´í”„ë¼ì¸ ìƒì„± í…ŒìŠ¤íŠ¸"""
        print("ğŸ”„ Step íŒŒì´í”„ë¼ì¸ ìƒì„± í…ŒìŠ¤íŠ¸ ì¤‘...")
        
        # í•µì‹¬ Stepë“¤ 
        core_steps = [
            "step_01_human_parsing",
            "step_02_pose_estimation", 
            "step_03_cloth_segmentation",
            "step_05_cloth_warping",
            "step_06_virtual_fitting"
        ]
        
        results = []
        
        if not self.step_factory:
            results.append(DetailedTestResult(
                "Step íŒŒì´í”„ë¼ì¸ (ì „ì²´)",
                TestStatus.FAILED,
                "StepFactoryê°€ ì´ˆê¸°í™”ë˜ì§€ ì•ŠìŒ",
                0.0,
                recommendations=["StepFactory ì´ˆê¸°í™” ë¨¼ì € ì‹¤í–‰"]
            ))
            return results
        
        for step_name in core_steps:
            print(f"  â³ {step_name} ìƒì„± ì¤‘...")
            start_time = time.time()
            memory_before = self._monitor_memory()
            
            try:
                # Step ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
                step_instance = self.step_factory.create_step(step_name)
                
                load_time = time.time() - start_time
                memory_after = self._monitor_memory()
                memory_used = memory_after - memory_before
                
                if step_instance is None:
                    result = DetailedTestResult(
                        f"Step ìƒì„±: {step_name}",
                        TestStatus.FAILED,
                        "Step ìƒì„± ì‹¤íŒ¨ (None ë°˜í™˜)",
                        load_time,
                        memory_used,
                        recommendations=[
                            f"{step_name} í´ë˜ìŠ¤ êµ¬í˜„ í™•ì¸",
                            "step_implementations.py ëª¨ë“ˆ í™•ì¸"
                        ]
                    )
                    print(f"    âŒ {step_name} ìƒì„± ì‹¤íŒ¨")
                else:
                    # Step ì„¸ë¶€ ê²€ì¦
                    step_type = type(step_instance).__name__
                    has_model_loader = hasattr(step_instance, 'model_loader') and step_instance.model_loader is not None
                    has_process_method = hasattr(step_instance, 'process')
                    has_initialize = hasattr(step_instance, 'initialize')
                    
                    # ì´ˆê¸°í™” ì‹œë„
                    initialized = False
                    if has_initialize:
                        try:
                            if asyncio.iscoroutinefunction(step_instance.initialize):
                                # ë¹„ë™ê¸° ì´ˆê¸°í™”ëŠ” ìŠ¤í‚µ
                                initialized = True
                            else:
                                step_instance.initialize()
                                initialized = True
                        except Exception as init_e:
                            initialized = False
                    
                    self.step_instances[step_name] = step_instance
                    
                    details = {
                        'step_name': step_name,
                        'step_type': step_type,
                        'has_model_loader': has_model_loader,
                        'has_process_method': has_process_method,
                        'has_initialize': has_initialize,
                        'initialized': initialized
                    }
                    
                    # ê²°ê³¼ íŒì •
                    if has_model_loader and has_process_method and initialized:
                        status = TestStatus.SUCCESS
                        message = f"ìƒì„± ì™„ë£Œ (ModelLoader: âœ…, Process: âœ…)"
                        print(f"    âœ… {step_name} ìƒì„± ì„±ê³µ")
                    elif has_process_method:
                        status = TestStatus.PARTIAL
                        message = f"ë¶€ë¶„ ìƒì„± (ModelLoader: {'âœ…' if has_model_loader else 'âŒ'})"
                        print(f"    ğŸ”¶ {step_name} ë¶€ë¶„ ìƒì„±")
                    else:
                        status = TestStatus.WARNING
                        message = f"ìƒì„±ë¨ but í•„ìˆ˜ ë©”ì„œë“œ ëˆ„ë½"
                        print(f"    âš ï¸ {step_name} ë©”ì„œë“œ ëˆ„ë½")
                    
                    recommendations = []
                    if not has_model_loader:
                        recommendations.append("ModelLoader ì˜ì¡´ì„± ì£¼ì… í™•ì¸")
                    if not has_process_method:
                        recommendations.append("process() ë©”ì„œë“œ êµ¬í˜„ í™•ì¸")
                    if not initialized:
                        recommendations.append("ì´ˆê¸°í™” ë¡œì§ í™•ì¸")
                    
                    result = DetailedTestResult(
                        f"Step ìƒì„±: {step_name}",
                        status,
                        message,
                        load_time,
                        memory_used,
                        details=details,
                        recommendations=recommendations
                    )
                
                results.append(result)
                
            except Exception as e:
                load_time = time.time() - start_time
                memory_after = self._monitor_memory()
                
                result = DetailedTestResult(
                    f"Step ìƒì„±: {step_name}",
                    TestStatus.FAILED,
                    f"ìƒì„± ì˜¤ë¥˜: {str(e)[:50]}",
                    load_time,
                    memory_after - memory_before,
                    details={
                        'step_name': step_name,
                        'error_type': type(e).__name__
                    },
                    error_trace=traceback.format_exc(),
                    recommendations=[
                        f"{step_name} í´ë˜ìŠ¤ ì˜ì¡´ì„± í™•ì¸",
                        "BaseStepMixin ìƒì† êµ¬ì¡° í™•ì¸"
                    ]
                )
                results.append(result)
                print(f"    âŒ {step_name} ìƒì„± ì˜¤ë¥˜: {e}")
        
        return results
    
    def test_inference_simulation(self) -> List[DetailedTestResult]:
        """AI ì¶”ë¡  ì‹œë®¬ë ˆì´ì…˜ í…ŒìŠ¤íŠ¸ (í”„ë¡œë•ì…˜ ë ˆë²¨ë§Œ)"""
        if self.test_level != TestLevel.PRODUCTION:
            return []
        
        print("ğŸ§ª AI ì¶”ë¡  ì‹œë®¬ë ˆì´ì…˜ í…ŒìŠ¤íŠ¸ ì¤‘...")
        
        results = []
        test_data = {
            "image_url": "test_image.jpg",
            "cloth_url": "test_cloth.jpg", 
            "user_id": "test_user",
            "session_id": "test_session"
        }
        
        for step_name, step_instance in self.step_instances.items():
            if not hasattr(step_instance, 'process'):
                continue
                
            print(f"  â³ {step_name} ì¶”ë¡  ì‹œë®¬ë ˆì´ì…˜...")
            start_time = time.time()
            memory_before = self._monitor_memory()
            
            try:
                # process ë©”ì„œë“œ í˜¸ì¶œ ì‹œë®¬ë ˆì´ì…˜
                if asyncio.iscoroutinefunction(step_instance.process):
                    # ë¹„ë™ê¸°ëŠ” ìŠ¤í‚µ
                    result = DetailedTestResult(
                        f"ì¶”ë¡ : {step_name}",
                        TestStatus.SKIPPED,
                        "ë¹„ë™ê¸° ë©”ì„œë“œ (ìŠ¤í‚µë¨)",
                        time.time() - start_time,
                        0
                    )
                else:
                    inference_result = step_instance.process(test_data)
                    
                    load_time = time.time() - start_time
                    memory_after = self._monitor_memory()
                    memory_used = memory_after - memory_before
                    
                    if inference_result:
                        result = DetailedTestResult(
                            f"ì¶”ë¡ : {step_name}",
                            TestStatus.SUCCESS,
                            f"ì¶”ë¡  ì„±ê³µ ({load_time:.2f}s)",
                            load_time,
                            memory_used,
                            details={
                                'result_keys': list(inference_result.keys()) if isinstance(inference_result, dict) else [],
                                'result_type': type(inference_result).__name__
                            }
                        )
                        print(f"    âœ… {step_name} ì¶”ë¡  ì„±ê³µ")
                    else:
                        result = DetailedTestResult(
                            f"ì¶”ë¡ : {step_name}",
                            TestStatus.FAILED,
                            "ì¶”ë¡  ê²°ê³¼ ì—†ìŒ",
                            load_time,
                            memory_used
                        )
                        print(f"    âŒ {step_name} ì¶”ë¡  ê²°ê³¼ ì—†ìŒ")
                
                results.append(result)
                
            except Exception as e:
                load_time = time.time() - start_time
                memory_after = self._monitor_memory()
                
                result = DetailedTestResult(
                    f"ì¶”ë¡ : {step_name}",
                    TestStatus.FAILED,
                    f"ì¶”ë¡  ì˜¤ë¥˜: {str(e)[:50]}",
                    load_time,
                    memory_after - memory_before,
                    error_trace=traceback.format_exc()
                )
                results.append(result)
                print(f"    âŒ {step_name} ì¶”ë¡  ì˜¤ë¥˜: {e}")
        
        return results
    
    def run_comprehensive_test(self) -> Dict[str, Any]:
        """í¬ê´„ì  í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        print(f"ğŸš€ MyCloset AI í¬ê´„ì  í…ŒìŠ¤íŠ¸ ì‹¤í–‰ (ë ˆë²¨: {self.test_level.value})")
        print("=" * 80)
        
        all_results = []
        
        # 1. ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­ ê²€ì¦
        print("\nğŸ“‹ 1ë‹¨ê³„: ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­ ê²€ì¦")
        system_result = self.test_system_requirements()
        all_results.append(system_result)
        self.results.append(system_result)
        
        # 2. ModelLoader ì´ˆê¸°í™”
        print("\nğŸ”§ 2ë‹¨ê³„: ModelLoader v5.1 ì´ˆê¸°í™”")
        loader_result = self.test_model_loader_initialization()
        all_results.append(loader_result)
        self.results.append(loader_result)
        
        # 3. StepFactory ì´ˆê¸°í™”  
        print("\nğŸ­ 3ë‹¨ê³„: StepFactory v11.0 ì´ˆê¸°í™”")
        factory_result = self.test_step_factory_initialization()
        all_results.append(factory_result)
        self.results.append(factory_result)
        
        # 4. í•µì‹¬ ëª¨ë¸ ë¡œë”© (STANDARD ì´ìƒ)
        if self.test_level in [TestLevel.STANDARD, TestLevel.FULL, TestLevel.PRODUCTION]:
            print("\nğŸ§  4ë‹¨ê³„: í•µì‹¬ AI ëª¨ë¸ ë¡œë”©")
            model_results = self.test_core_model_loading()
            all_results.extend(model_results)
            self.results.extend(model_results)
        
        # 5. Step íŒŒì´í”„ë¼ì¸ ìƒì„± (STANDARD ì´ìƒ)
        if self.test_level in [TestLevel.STANDARD, TestLevel.FULL, TestLevel.PRODUCTION]:
            print("\nğŸ”„ 5ë‹¨ê³„: Step íŒŒì´í”„ë¼ì¸ ìƒì„±")
            step_results = self.test_step_pipeline_creation()
            all_results.extend(step_results)
            self.results.extend(step_results)
        
        # 6. ì¶”ë¡  ì‹œë®¬ë ˆì´ì…˜ (PRODUCTIONë§Œ)
        if self.test_level == TestLevel.PRODUCTION:
            print("\nğŸ§ª 6ë‹¨ê³„: AI ì¶”ë¡  ì‹œë®¬ë ˆì´ì…˜")
            inference_results = self.test_inference_simulation()
            all_results.extend(inference_results)
            self.results.extend(inference_results)
        
        # ì´ ì‹¤í–‰ ì‹œê°„
        total_time = time.time() - self.start_time
        
        # ë©”ëª¨ë¦¬ ì •ë¦¬
        gc.collect()
        
        # ê²°ê³¼ ë¦¬í¬íŠ¸ ìƒì„±
        self._generate_comprehensive_report(total_time)
        
        return {
            'test_level': self.test_level.value,
            'total_tests': len(all_results),
            'total_time': total_time,
            'system_info': self.system_info,
            'results': all_results,
            'statistics': self._calculate_statistics()
        }
    
    def _calculate_statistics(self) -> Dict[str, Any]:
        """í…ŒìŠ¤íŠ¸ í†µê³„ ê³„ì‚°"""
        if not self.results:
            return {}
        
        status_counts = {}
        for status in TestStatus:
            status_counts[status.name.lower()] = sum(1 for r in self.results if r.status == status)
        
        total_load_time = sum(r.load_time for r in self.results)
        total_memory_used = sum(r.memory_mb for r in self.results)
        
        return {
            'total_tests': len(self.results),
            'status_counts': status_counts,
            'success_rate': (status_counts.get('success', 0) / len(self.results)) * 100,
            'total_load_time': total_load_time,
            'avg_load_time': total_load_time / len(self.results) if self.results else 0,
            'total_memory_used_mb': total_memory_used,
            'peak_memory_usage_mb': self.peak_memory_usage,
            'models_tested': self.total_models_tested,
            'successful_models': self.successful_models,
            'model_success_rate': (self.successful_models / self.total_models_tested * 100) if self.total_models_tested > 0 else 0
        }
    
    def _generate_comprehensive_report(self, total_time: float):
        """í¬ê´„ì  ê²°ê³¼ ë¦¬í¬íŠ¸ ìƒì„±"""
        print("\n" + "=" * 80)
        print("ğŸ“Š MyCloset AI ì™„ì „ ì‹¤ì „ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ë¦¬í¬íŠ¸")
        print("=" * 80)
        
        stats = self._calculate_statistics()
        
        # ì´ í†µê³„
        print(f"ğŸ¯ ì´ í†µê³„:")
        print(f"   í…ŒìŠ¤íŠ¸ ë ˆë²¨: {self.test_level.value.upper()}")
        print(f"   ì´ í…ŒìŠ¤íŠ¸: {stats['total_tests']}ê°œ")
        print(f"   ì´ ì‹¤í–‰ì‹œê°„: {total_time:.2f}ì´ˆ")
        print(f"   ì„±ê³µë¥ : {stats['success_rate']:.1f}%")
        print(f"   í”¼í¬ ë©”ëª¨ë¦¬: {stats['peak_memory_usage_mb']:.1f}MB")
        
        # ìƒíƒœë³„ í†µê³„
        print(f"\nğŸ“ˆ ìƒíƒœë³„ í†µê³„:")
        for status_name, count in stats['status_counts'].items():
            if count > 0:
                emoji = {'success': 'âœ…', 'failed': 'âŒ', 'warning': 'âš ï¸', 'partial': 'ğŸ”¶', 'skipped': 'â­ï¸'}.get(status_name, 'â“')
                print(f"   {emoji} {status_name.upper()}: {count}ê°œ")
        
        # ëª¨ë¸ í†µê³„
        if self.total_models_tested > 0:
            print(f"\nğŸ§  AI ëª¨ë¸ í†µê³„:")
            print(f"   í…ŒìŠ¤íŠ¸ëœ ëª¨ë¸: {stats['models_tested']}ê°œ")
            print(f"   ì„±ê³µí•œ ëª¨ë¸: {stats['successful_models']}ê°œ")
            print(f"   ëª¨ë¸ ì„±ê³µë¥ : {stats['model_success_rate']:.1f}%")
            print(f"   í‰ê·  ë¡œë”© ì‹œê°„: {stats['avg_load_time']:.2f}ì´ˆ/ëª¨ë¸")
        
        # ìƒì„¸ ê²°ê³¼ (ì„±ê³µ/ì‹¤íŒ¨ë§Œ)
        print(f"\nğŸ“‹ ìƒì„¸ ê²°ê³¼:")
        
        success_results = [r for r in self.results if r.status == TestStatus.SUCCESS]
        if success_results:
            print(f"  âœ… ì„±ê³µí•œ í…ŒìŠ¤íŠ¸ ({len(success_results)}ê°œ):")
            for result in success_results:
                time_info = f"({result.load_time:.2f}s)" if result.load_time > 0 else ""
                memory_info = f"[{result.memory_mb:.1f}MB]" if result.memory_mb > 0 else ""
                print(f"     â€¢ {result.name}: {result.message} {time_info} {memory_info}")
        
        failed_results = [r for r in self.results if r.status == TestStatus.FAILED]
        if failed_results:
            print(f"  âŒ ì‹¤íŒ¨í•œ í…ŒìŠ¤íŠ¸ ({len(failed_results)}ê°œ):")
            for result in failed_results:
                print(f"     â€¢ {result.name}: {result.message}")
                if result.recommendations:
                    for rec in result.recommendations[:2]:  # ìµœëŒ€ 2ê°œ ê¶Œì¥ì‚¬í•­
                        print(f"       â†’ {rec}")
        
        warning_results = [r for r in self.results if r.status in [TestStatus.WARNING, TestStatus.PARTIAL]]
        if warning_results:
            print(f"  âš ï¸ ì£¼ì˜/ë¶€ë¶„ ì„±ê³µ ({len(warning_results)}ê°œ):")
            for result in warning_results:
                print(f"     â€¢ {result.name}: {result.message}")
        
        # ìµœì¢… ê²°ë¡  ë° ê¶Œì¥ì‚¬í•­
        print(f"\nğŸ¯ ìµœì¢… ê²°ë¡ :")
        
        if stats['success_rate'] >= 90:
            print("   ğŸš€ MyCloset AI ì‹œìŠ¤í…œì´ ì™„ë²½í•˜ê²Œ ì‘ë™í•©ë‹ˆë‹¤!")
            print("   ğŸŒŸ í”„ë¡œë•ì…˜ í™˜ê²½ì—ì„œ ì‚¬ìš©í•  ì¤€ë¹„ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
        elif stats['success_rate'] >= 70:
            print("   âœ… MyCloset AI ì‹œìŠ¤í…œì´ ì •ìƒì ìœ¼ë¡œ ì‘ë™í•©ë‹ˆë‹¤!")
            print("   ğŸ”§ ì¼ë¶€ ìµœì í™” ì—¬ì§€ê°€ ìˆì§€ë§Œ ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤.")
        elif stats['success_rate'] >= 50:
            print("   âš ï¸ MyCloset AI ì‹œìŠ¤í…œì— ì¼ë¶€ ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤.")
            print("   ğŸ› ï¸ ì‹¤íŒ¨í•œ ì»´í¬ë„ŒíŠ¸ë“¤ì„ ìˆ˜ì • í›„ ì‚¬ìš©í•˜ì„¸ìš”.")
        else:
            print("   âŒ MyCloset AI ì‹œìŠ¤í…œì— ì‹¬ê°í•œ ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤.")
            print("   ğŸš¨ í™˜ê²½ ì„¤ì • ë° ì˜ì¡´ì„±ì„ ì „ë©´ ì ê²€í•´ì•¼ í•©ë‹ˆë‹¤.")
        
        # êµ¬ì²´ì  ê¶Œì¥ì‚¬í•­
        all_recommendations = []
        for result in self.results:
            all_recommendations.extend(result.recommendations)
        
        unique_recommendations = list(set(all_recommendations))
        if unique_recommendations:
            print(f"\nğŸ’¡ ì£¼ìš” ê¶Œì¥ì‚¬í•­:")
            for i, rec in enumerate(unique_recommendations[:5], 1):  # ìµœëŒ€ 5ê°œ
                print(f"   {i}. {rec}")
        
        print("=" * 80)

def quick_diagnostic():
    """ë¹ ë¥¸ ì§„ë‹¨ (30ì´ˆ ì´ë‚´)"""
    print("âš¡ MyCloset AI ë¹ ë¥¸ ì§„ë‹¨ ì‹¤í–‰...")
    
    tester = MyClosetAdvancedTester(TestLevel.BASIC)
    
    # ê¸°ë³¸ ì»´í¬ë„ŒíŠ¸ë§Œ í…ŒìŠ¤íŠ¸
    system_result = tester.test_system_requirements()
    loader_result = tester.test_model_loader_initialization()
    
    success_count = sum(1 for r in [system_result, loader_result] if r.status == TestStatus.SUCCESS)
    
    if success_count == 2:
        print("âœ… ê¸°ë³¸ ì‹œìŠ¤í…œ ì •ìƒ - ì „ì²´ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ê°€ëŠ¥")
        return True
    else:
        print("âŒ ê¸°ë³¸ ì‹œìŠ¤í…œ ë¬¸ì œ ìˆìŒ - í™˜ê²½ ì„¤ì • í™•ì¸ í•„ìš”")
        return False

def standard_test():
    """í‘œì¤€ í…ŒìŠ¤íŠ¸ (5ë¶„ ì´ë‚´)"""
    print("ğŸ” MyCloset AI í‘œì¤€ í…ŒìŠ¤íŠ¸ ì‹¤í–‰...")
    tester = MyClosetAdvancedTester(TestLevel.STANDARD)
    return tester.run_comprehensive_test()

def full_production_test():
    """ì™„ì „ í”„ë¡œë•ì…˜ í…ŒìŠ¤íŠ¸ (10ë¶„+)"""
    print("ğŸš€ MyCloset AI ì™„ì „ í”„ë¡œë•ì…˜ í…ŒìŠ¤íŠ¸ ì‹¤í–‰...")
    tester = MyClosetAdvancedTester(TestLevel.PRODUCTION)
    return tester.run_comprehensive_test()

def main():
    """ë©”ì¸ ì‹¤í–‰"""
    print("ğŸ”¥ MyCloset AI ì™„ì „ ì‹¤ì „ í†µí•© í…ŒìŠ¤í„° v2.0")
    print("=" * 60)
    print("í…ŒìŠ¤íŠ¸ ë ˆë²¨ì„ ì„ íƒí•˜ì„¸ìš”:")
    print("1. ë¹ ë¥¸ ì§„ë‹¨ (30ì´ˆ) - ê¸°ë³¸ ì»´í¬ë„ŒíŠ¸ë§Œ")
    print("2. í‘œì¤€ í…ŒìŠ¤íŠ¸ (5ë¶„) - ëª¨ë“  ëª¨ë¸ ë¡œë”©") 
    print("3. ì™„ì „ í…ŒìŠ¤íŠ¸ (10ë¶„+) - ì¶”ë¡ ê¹Œì§€ í¬í•¨")
    
    choice = input("ì„ íƒ (1/2/3): ").strip()
    
    if choice == "1":
        return quick_diagnostic()
    elif choice == "3":
        return full_production_test()
    else:
        return standard_test()

if __name__ == "__main__":
    main()