#!/bin/bash
# create_missing_pipeline_modules.sh
# 8ë‹¨ê³„ AI íŒŒì´í”„ë¼ì¸ì˜ ëˆ„ë½ëœ ì˜ì¡´ì„± ëª¨ë“ˆë“¤ì„ ìƒì„±

echo "ðŸ”§ ëˆ„ë½ëœ AI íŒŒì´í”„ë¼ì¸ ëª¨ë“ˆë“¤ ìƒì„± ì¤‘..."
echo "================================================"

# 1. utils ëª¨ë“ˆë“¤ ìƒì„±
echo "ðŸ“¦ Utils ëª¨ë“ˆ ìƒì„± ì¤‘..."
mkdir -p app/ai_pipeline/utils

# memory_manager.py
cat > app/ai_pipeline/utils/memory_manager.py << 'MEMORY_EOF'
"""
GPU ë©”ëª¨ë¦¬ ë§¤ë‹ˆì € - M3 Max ìµœì í™”
"""

import torch
import psutil
import logging
from typing import Dict, Optional

class GPUMemoryManager:
    """GPU ë©”ëª¨ë¦¬ ê´€ë¦¬ í´ëž˜ìŠ¤"""
    
    def __init__(self, device: str = "mps", memory_limit_gb: float = 16.0):
        self.device = device
        self.memory_limit_gb = memory_limit_gb
        self.logger = logging.getLogger(__name__)
        
    def clear_cache(self):
        """ë©”ëª¨ë¦¬ ìºì‹œ ì •ë¦¬"""
        if self.device == "mps":
            try:
                torch.mps.empty_cache()
            except:
                pass
        elif self.device == "cuda":
            torch.cuda.empty_cache()
    
    def check_memory_usage(self) -> Dict[str, float]:
        """ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í™•ì¸"""
        memory_info = {}
        
        # ì‹œìŠ¤í…œ ë©”ëª¨ë¦¬
        memory_info["system_memory_gb"] = psutil.virtual_memory().used / (1024**3)
        
        # GPU ë©”ëª¨ë¦¬ (ê°€ëŠ¥í•œ ê²½ìš°)
        if self.device == "mps":
            try:
                memory_info["mps_memory_gb"] = torch.mps.current_allocated_memory() / (1024**3)
            except:
                memory_info["mps_memory_gb"] = 0.0
        
        return memory_info
MEMORY_EOF

# model_loader.py
cat > app/ai_pipeline/utils/model_loader.py << 'LOADER_EOF'
"""
ëª¨ë¸ ë¡œë” - ë™ì  ëª¨ë¸ ë¡œë”© ë° ê´€ë¦¬
"""

import torch
import logging
from typing import Dict, Any, Optional

class ModelLoader:
    """AI ëª¨ë¸ ë¡œë”"""
    
    def __init__(self, device: str = "mps", use_fp16: bool = True):
        self.device = device
        self.use_fp16 = use_fp16
        self.models = {}
        self.logger = logging.getLogger(__name__)
    
    def load_model(self, model_name: str, model_path: Optional[str] = None) -> Any:
        """ëª¨ë¸ ë¡œë“œ (ë”ë¯¸ êµ¬í˜„)"""
        if model_name not in self.models:
            # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ëª¨ë¸ íŒŒì¼ì„ ë¡œë“œ
            self.models[model_name] = f"dummy_model_{model_name}"
            self.logger.info(f"ëª¨ë¸ ë¡œë“œë¨: {model_name}")
        
        return self.models[model_name]
    
    def unload_model(self, model_name: str):
        """ëª¨ë¸ ì–¸ë¡œë“œ"""
        if model_name in self.models:
            del self.models[model_name]
            self.logger.info(f"ëª¨ë¸ ì–¸ë¡œë“œë¨: {model_name}")
LOADER_EOF

# data_converter.py
cat > app/ai_pipeline/utils/data_converter.py << 'CONVERTER_EOF'
"""
ë°ì´í„° ë³€í™˜ê¸° - ì´ë¯¸ì§€/í…ì„œ ë³€í™˜
"""

import torch
import numpy as np
from PIL import Image
import torchvision.transforms as transforms
from typing import Union

class DataConverter:
    """ë°ì´í„° í˜•ì‹ ë³€í™˜ í´ëž˜ìŠ¤"""
    
    def __init__(self):
        self.transform = transforms.Compose([
            transforms.Resize((512, 512)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
        ])
    
    def image_to_tensor(self, image: Image.Image, size: int = 512) -> torch.Tensor:
        """PIL Imageë¥¼ Tensorë¡œ ë³€í™˜"""
        if isinstance(image, np.ndarray):
            image = Image.fromarray(image)
        
        # í¬ê¸° ì¡°ì • ë° ì •ê·œí™”
        transform = transforms.Compose([
            transforms.Resize((size, size)),
            transforms.ToTensor(),
        ])
        
        tensor = transform(image).unsqueeze(0)  # ë°°ì¹˜ ì°¨ì› ì¶”ê°€
        return tensor
    
    def tensor_to_numpy(self, tensor: torch.Tensor) -> np.ndarray:
        """Tensorë¥¼ NumPy ë°°ì—´ë¡œ ë³€í™˜"""
        if tensor.dim() == 4:  # ë°°ì¹˜ ì°¨ì› ì œê±°
            tensor = tensor.squeeze(0)
        
        # [-1, 1] -> [0, 255] ë³€í™˜
        tensor = torch.clamp(tensor, 0, 1)
        numpy_array = tensor.permute(1, 2, 0).cpu().numpy()
        return (numpy_array * 255).astype(np.uint8)
    
    def numpy_to_tensor(self, array: np.ndarray, device: str = "mps") -> torch.Tensor:
        """NumPy ë°°ì—´ì„ Tensorë¡œ ë³€í™˜"""
        if array.dtype == np.uint8:
            array = array.astype(np.float32) / 255.0
        
        tensor = torch.from_numpy(array).permute(2, 0, 1).unsqueeze(0)
        return tensor.to(device)
CONVERTER_EOF

# 2. ê° ë‹¨ê³„ ëª¨ë“ˆë“¤ ìƒì„±
echo "ðŸ—ï¸ 8ë‹¨ê³„ íŒŒì´í”„ë¼ì¸ ëª¨ë“ˆ ìƒì„± ì¤‘..."
mkdir -p app/ai_pipeline/steps

# __init__.py íŒŒì¼ë“¤
touch app/ai_pipeline/__init__.py
touch app/ai_pipeline/utils/__init__.py
touch app/ai_pipeline/steps/__init__.py

# Step 1: Human Parsing
cat > app/ai_pipeline/steps/step_01_human_parsing.py << 'STEP1_EOF'
"""
1ë‹¨ê³„: ì¸ì²´ íŒŒì‹± (Human Parsing)
20ê°œ ë¶€ìœ„ë¡œ ì¸ì²´ ë¶„í• 
"""

import asyncio
import torch
import numpy as np
from typing import Any

class HumanParsingStep:
    """ì¸ì²´ íŒŒì‹± ë‹¨ê³„"""
    
    def __init__(self, config, device, model_loader):
        self.config = config
        self.device = device
        self.model_loader = model_loader
        self.model = None
    
    async def process(self, person_tensor: torch.Tensor) -> torch.Tensor:
        """ì¸ì²´ íŒŒì‹± ì²˜ë¦¬"""
        # ë”ë¯¸ êµ¬í˜„ - ì‹¤ì œë¡œëŠ” Graphonomy ëª¨ë¸ ì‚¬ìš©
        await asyncio.sleep(0.5)  # ì²˜ë¦¬ ì‹œë®¬ë ˆì´ì…˜
        
        # ë”ë¯¸ ì„¸ê·¸ë©˜í…Œì´ì…˜ ë§ˆìŠ¤í¬ ìƒì„±
        batch_size, channels, height, width = person_tensor.shape
        dummy_mask = torch.zeros(batch_size, 20, height, width)  # 20ê°œ ë¶€ìœ„
        
        return dummy_mask.to(self.device)
    
    async def warmup(self, dummy_input: torch.Tensor):
        """ì›Œë°ì—…"""
        await self.process(dummy_input)
STEP1_EOF

# Step 2: Pose Estimation
cat > app/ai_pipeline/steps/step_02_pose_estimation.py << 'STEP2_EOF'
"""
2ë‹¨ê³„: í¬ì¦ˆ ì¶”ì • (Pose Estimation)
18ê°œ í‚¤í¬ì¸íŠ¸ ê²€ì¶œ
"""

import asyncio
import torch
import numpy as np

class PoseEstimationStep:
    """í¬ì¦ˆ ì¶”ì • ë‹¨ê³„"""
    
    def __init__(self, config, device, model_loader):
        self.config = config
        self.device = device
        self.model_loader = model_loader
    
    async def process(self, person_tensor: torch.Tensor) -> torch.Tensor:
        """í¬ì¦ˆ ì¶”ì • ì²˜ë¦¬"""
        await asyncio.sleep(0.4)
        
        # ë”ë¯¸ í‚¤í¬ì¸íŠ¸ ìƒì„± (18ê°œ í‚¤í¬ì¸íŠ¸)
        batch_size = person_tensor.shape[0]
        dummy_keypoints = torch.randn(batch_size, 18, 3)  # [x, y, confidence]
        
        return dummy_keypoints.to(self.device)
    
    async def warmup(self, dummy_input: torch.Tensor):
        await self.process(dummy_input)
STEP2_EOF

# Step 3: Cloth Segmentation
cat > app/ai_pipeline/steps/step_03_cloth_segmentation.py << 'STEP3_EOF'
"""
3ë‹¨ê³„: ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜
ì˜ë¥˜ ì˜ì—­ ë¶„í•  ë° ë°°ê²½ ì œê±°
"""

import asyncio
import torch

class ClothSegmentationStep:
    """ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ ë‹¨ê³„"""
    
    def __init__(self, config, device, model_loader):
        self.config = config
        self.device = device
        self.model_loader = model_loader
    
    async def process(self, cloth_tensor: torch.Tensor) -> torch.Tensor:
        """ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ ì²˜ë¦¬"""
        await asyncio.sleep(0.3)
        
        # ë”ë¯¸ ì˜ë¥˜ ë§ˆìŠ¤í¬ ìƒì„±
        batch_size, channels, height, width = cloth_tensor.shape
        dummy_mask = torch.ones(batch_size, 1, height, width)
        
        return dummy_mask.to(self.device)
    
    async def warmup(self, dummy_input: torch.Tensor):
        await self.process(dummy_input)
STEP3_EOF

# Steps 4-8 (ê°„ì†Œí™”ëœ ë²„ì „)
for step_num in {4..8}; do
    step_names=("" "" "" "" "geometric_matching" "cloth_warping" "virtual_fitting" "post_processing" "quality_assessment")
    step_name=${step_names[$step_num]}
    
    cat > app/ai_pipeline/steps/step_0${step_num}_${step_name}.py << STEP_EOF
"""
${step_num}ë‹¨ê³„: ${step_name}
"""

import asyncio
import torch

class $(echo ${step_name} | sed 's/_/ /g' | sed 's/\b\w/\U&/g' | sed 's/ //g')Step:
    """${step_name} ë‹¨ê³„"""
    
    def __init__(self, config, device, model_loader=None):
        self.config = config
        self.device = device
        self.model_loader = model_loader
    
    async def process(self, input_data) -> torch.Tensor:
        """${step_name} ì²˜ë¦¬"""
        await asyncio.sleep(0.3)
        
        if isinstance(input_data, dict):
            # ë³µí•© ìž…ë ¥ì˜ ê²½ìš° ì²« ë²ˆì§¸ í…ì„œ ì‚¬ìš©
            first_key = list(input_data.keys())[0]
            sample_tensor = input_data[first_key]
            if hasattr(sample_tensor, 'shape'):
                return torch.randn_like(sample_tensor).to(self.device)
            else:
                return torch.randn(1, 3, 512, 512).to(self.device)
        else:
            return torch.randn_like(input_data).to(self.device)
    
    async def warmup(self, dummy_input):
        await self.process(dummy_input)
STEP_EOF
done

# 3. __init__.py íŒŒì¼ë“¤ì— ìž„í¬íŠ¸ ì¶”ê°€
cat > app/ai_pipeline/steps/__init__.py << 'STEPS_INIT_EOF'
"""
AI íŒŒì´í”„ë¼ì¸ ë‹¨ê³„ë“¤
"""

from .step_01_human_parsing import HumanParsingStep
from .step_02_pose_estimation import PoseEstimationStep
from .step_03_cloth_segmentation import ClothSegmentationStep
from .step_04_geometric_matching import GeometricMatchingStep
from .step_05_cloth_warping import ClothWarpingStep
from .step_06_virtual_fitting import VirtualFittingStep
from .step_07_post_processing import PostProcessingStep
from .step_08_quality_assessment import QualityAssessmentStep

__all__ = [
    'HumanParsingStep',
    'PoseEstimationStep', 
    'ClothSegmentationStep',
    'GeometricMatchingStep',
    'ClothWarpingStep',
    'VirtualFittingStep',
    'PostProcessingStep',
    'QualityAssessmentStep'
]
STEPS_INIT_EOF

cat > app/ai_pipeline/utils/__init__.py << 'UTILS_INIT_EOF'
"""
AI íŒŒì´í”„ë¼ì¸ ìœ í‹¸ë¦¬í‹°
"""

from .memory_manager import GPUMemoryManager
from .model_loader import ModelLoader
from .data_converter import DataConverter

__all__ = ['GPUMemoryManager', 'ModelLoader', 'DataConverter']
UTILS_INIT_EOF

# 4. í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜
echo "ðŸ“¦ í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì¤‘..."
pip install torchvision pillow

echo "âœ… ëˆ„ë½ëœ ëª¨ë“ˆë“¤ ìƒì„± ì™„ë£Œ!"
echo ""
echo "ðŸš€ ì„œë²„ ì‹¤í–‰ í…ŒìŠ¤íŠ¸..."
python run_server.py