#!/usr/bin/env python3
"""
π” μ²΄ν¬ν¬μΈνΈ λ΅λ”© λ””λ²„κΉ… μ¤ν¬λ¦½νΈ
================================================================================
β… λ‹¨κ³„λ³„ λ””λ²„κΉ…
β… μ‹¤μ  νμΌ μ΅΄μ¬ ν™•μΈ
β… μ²΄ν¬ν¬μΈνΈ λ¶„μ„ ν…μ¤νΈ
β… λ¨λΈ λ΅λ”© ν…μ¤νΈ
================================================================================
"""

import os
import sys
import time
from pathlib import Path

# ν”„λ΅μ νΈ κ²½λ΅ μ„¤μ •
current_file = Path(__file__).resolve()
backend_root = current_file.parent
sys.path.insert(0, str(backend_root))
sys.path.insert(0, str(backend_root / "app"))

def check_ai_models_directory():
    """AI λ¨λΈ λ””λ ‰ν† λ¦¬ ν™•μΈ"""
    print("π” AI λ¨λΈ λ””λ ‰ν† λ¦¬ ν™•μΈ...")
    
    ai_models_root = backend_root / "ai_models"
    print(f"   κ²½λ΅: {ai_models_root}")
    print(f"   μ΅΄μ¬: {ai_models_root.exists()}")
    
    if ai_models_root.exists():
        # ν•μ„ λ””λ ‰ν† λ¦¬ ν™•μΈ
        subdirs = [d for d in ai_models_root.iterdir() if d.is_dir()]
        print(f"   ν•μ„ λ””λ ‰ν† λ¦¬ μ: {len(subdirs)}")
        
        for subdir in subdirs[:5]:  # μ²μ 5κ°λ§
            print(f"     - {subdir.name}")
            
            # μ²΄ν¬ν¬μΈνΈ νμΌ ν™•μΈ
            checkpoint_files = list(subdir.glob("*.pth")) + list(subdir.glob("*.pt")) + list(subdir.glob("*.safetensors"))
            print(f"       μ²΄ν¬ν¬μΈνΈ νμΌ: {len(checkpoint_files)}κ°")
            
            for file in checkpoint_files[:3]:  # μ²μ 3κ°λ§
                size_mb = file.stat().st_size / (1024 * 1024)
                print(f"         - {file.name} ({size_mb:.1f}MB)")
    
    return ai_models_root.exists()

def test_checkpoint_analysis():
    """μ²΄ν¬ν¬μΈνΈ λ¶„μ„ ν…μ¤νΈ"""
    print("\nπ” μ²΄ν¬ν¬μΈνΈ λ¶„μ„ ν…μ¤νΈ...")
    
    try:
        from app.ai_pipeline.utils.model_loader import analyze_checkpoint
        
        # μ²΄ν¬ν¬μΈνΈ νμΌ μ°ΎκΈ°
        ai_models_root = backend_root / "ai_models"
        checkpoint_files = []
        
        for pattern in ["*.pth", "*.pt", "*.safetensors"]:
            checkpoint_files.extend(ai_models_root.rglob(pattern))
        
        if not checkpoint_files:
            print("   β μ²΄ν¬ν¬μΈνΈ νμΌμ„ μ°Ύμ„ μ μ—†μµλ‹λ‹¤")
            return False
        
        # μ²« λ²μ§Έ νμΌλ΅ ν…μ¤νΈ
        test_file = checkpoint_files[0]
        print(f"   ν…μ¤νΈ νμΌ: {test_file}")
        print(f"   νμΌ ν¬κΈ°: {test_file.stat().st_size / (1024 * 1024):.1f}MB")
        
        # μ²΄ν¬ν¬μΈνΈ λ¶„μ„
        print("   π“ μ²΄ν¬ν¬μΈνΈ λ¶„μ„ μ¤‘...")
        analysis = analyze_checkpoint(test_file)
        
        if analysis:
            print("   β… λ¶„μ„ μ„±κ³µ!")
            print(f"     νλΌλ―Έν„° μ: {analysis.get('total_params', 0):,}")
            print(f"     λ μ΄μ–΄ μ: {analysis.get('layer_count', 0)}")
            print(f"     μ•„ν‚¤ν…μ²: {analysis.get('architecture_type', 'Unknown')}")
            return True
        else:
            print("   β λ¶„μ„ μ‹¤ν¨")
            return False
            
    except Exception as e:
        print(f"   β λ¶„μ„ μ¤λ¥: {e}")
        return False

def test_model_loader_creation():
    """Model Loader μƒμ„± ν…μ¤νΈ"""
    print("\nπ” Model Loader μƒμ„± ν…μ¤νΈ...")
    
    try:
        from app.ai_pipeline.utils.model_loader import get_model_loader_v6
        
        print("   π€ Model Loader μƒμ„± μ¤‘...")
        model_loader = get_model_loader_v6(device="auto")
        
        if model_loader:
            print("   β… Model Loader μƒμ„± μ„±κ³µ!")
            print(f"     λ””λ°”μ΄μ¤: {model_loader.device}")
            return True
        else:
            print("   β Model Loader μƒμ„± μ‹¤ν¨")
            return False
            
    except Exception as e:
        print(f"   β Model Loader μƒμ„± μ¤λ¥: {e}")
        return False

def test_simple_model_loading():
    """κ°„λ‹¨ν• λ¨λΈ λ΅λ”© ν…μ¤νΈ"""
    print("\nπ” κ°„λ‹¨ν• λ¨λΈ λ΅λ”© ν…μ¤νΈ...")
    
    try:
        from app.ai_pipeline.utils.model_loader import load_model_for_step
        
        # μ²΄ν¬ν¬μΈνΈ νμΌ μ°ΎκΈ°
        ai_models_root = backend_root / "ai_models"
        checkpoint_files = []
        
        for pattern in ["*.pth", "*.pt", "*.safetensors"]:
            checkpoint_files.extend(ai_models_root.rglob(pattern))
        
        if not checkpoint_files:
            print("   β μ²΄ν¬ν¬μΈνΈ νμΌμ„ μ°Ύμ„ μ μ—†μµλ‹λ‹¤")
            return False
        
        # μ²« λ²μ§Έ νμΌλ΅ ν…μ¤νΈ
        test_file = checkpoint_files[0]
        model_name = test_file.stem
        
        # Step νƒ€μ… μ¶”μ •
        step_type = "human_parsing"  # κΈ°λ³Έκ°’
        if "pose" in test_file.name.lower():
            step_type = "pose_estimation"
        elif "segmentation" in test_file.name.lower():
            step_type = "cloth_segmentation"
        elif "geometric" in test_file.name.lower():
            step_type = "geometric_matching"
        elif "warping" in test_file.name.lower():
            step_type = "cloth_warping"
        elif "fitting" in test_file.name.lower():
            step_type = "virtual_fitting"
        
        print(f"   ν…μ¤νΈ νμΌ: {test_file}")
        print(f"   λ¨λΈλ…: {model_name}")
        print(f"   Step νƒ€μ…: {step_type}")
        
        # λ¨λΈ λ΅λ”©
        print("   π”„ λ¨λΈ λ΅λ”© μ¤‘...")
        start_time = time.time()
        
        model = load_model_for_step(
            step_type=step_type,
            model_name=model_name,
            checkpoint_path=str(test_file)
        )
        
        load_time = time.time() - start_time
        
        if model is not None:
            print(f"   β… λ΅λ”© μ„±κ³µ! ({load_time:.2f}μ΄)")
            print(f"     λ¨λΈ νƒ€μ…: {type(model).__name__}")
            
            # κ°„λ‹¨ν• μ¶”λ΅  ν…μ¤νΈ
            try:
                import torch
                dummy_input = torch.randn(1, 3, 256, 256)
                with torch.no_grad():
                    output = model(dummy_input)
                print(f"     μ¶”λ΅  μ„±κ³µ: {output.shape}")
            except Exception as e:
                print(f"     μ¶”λ΅  μ‹¤ν¨: {e}")
            
            return True
        else:
            print("   β λ΅λ”© μ‹¤ν¨")
            return False
            
    except Exception as e:
        print(f"   β λ΅λ”© μ¤λ¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_dynamic_model_creator():
    """DynamicModelCreator ν…μ¤νΈ"""
    print("\nπ” DynamicModelCreator ν…μ¤νΈ...")
    
    try:
        from app.ai_pipeline.utils.model_loader import DynamicModelCreator
        
        creator = DynamicModelCreator()
        
        # μ²΄ν¬ν¬μΈνΈ νμΌ μ°ΎκΈ°
        ai_models_root = backend_root / "ai_models"
        checkpoint_files = []
        
        for pattern in ["*.pth", "*.pt", "*.safetensors"]:
            checkpoint_files.extend(ai_models_root.rglob(pattern))
        
        if not checkpoint_files:
            print("   β μ²΄ν¬ν¬μΈνΈ νμΌμ„ μ°Ύμ„ μ μ—†μµλ‹λ‹¤")
            return False
        
        # μ²« λ²μ§Έ νμΌλ΅ ν…μ¤νΈ
        test_file = checkpoint_files[0]
        step_type = "human_parsing"
        
        print(f"   ν…μ¤νΈ νμΌ: {test_file}")
        
        model = creator.create_model_from_checkpoint(
            checkpoint_path=test_file,
            step_type=step_type,
            device="auto"
        )
        
        if model is not None:
            print("   β… DynamicModelCreator μ„±κ³µ!")
            print(f"     λ¨λΈ νƒ€μ…: {type(model).__name__}")
            return True
        else:
            print("   β DynamicModelCreator μ‹¤ν¨")
            return False
            
    except Exception as e:
        print(f"   β DynamicModelCreator μ¤λ¥: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    print("π” μ²΄ν¬ν¬μΈνΈ λ΅λ”© λ””λ²„κΉ…")
    print("="*80)
    
    # 1. AI λ¨λΈ λ””λ ‰ν† λ¦¬ ν™•μΈ
    dir_exists = check_ai_models_directory()
    
    if not dir_exists:
        print("β AI λ¨λΈ λ””λ ‰ν† λ¦¬κ°€ μ΅΄μ¬ν•μ§€ μ•μµλ‹λ‹¤")
        sys.exit(1)
    
    # 2. μ²΄ν¬ν¬μΈνΈ λ¶„μ„ ν…μ¤νΈ
    analysis_success = test_checkpoint_analysis()
    
    # 3. Model Loader μƒμ„± ν…μ¤νΈ
    loader_success = test_model_loader_creation()
    
    # 4. κ°„λ‹¨ν• λ¨λΈ λ΅λ”© ν…μ¤νΈ
    loading_success = test_simple_model_loading()
    
    # 5. DynamicModelCreator ν…μ¤νΈ
    creator_success = test_dynamic_model_creator()
    
    # κ²°κ³Ό μ”μ•½
    print("\n" + "="*80)
    print("π“ λ””λ²„κΉ… κ²°κ³Ό μ”μ•½")
    print("="*80)
    print(f"AI λ¨λΈ λ””λ ‰ν† λ¦¬: {'β…' if dir_exists else 'β'}")
    print(f"μ²΄ν¬ν¬μΈνΈ λ¶„μ„: {'β…' if analysis_success else 'β'}")
    print(f"Model Loader μƒμ„±: {'β…' if loader_success else 'β'}")
    print(f"λ¨λΈ λ΅λ”©: {'β…' if loading_success else 'β'}")
    print(f"DynamicModelCreator: {'β…' if creator_success else 'β'}")
    
    if all([dir_exists, analysis_success, loader_success, loading_success, creator_success]):
        print("\nπ‰ λ¨λ“  ν…μ¤νΈ μ„±κ³µ!")
    else:
        print("\nβ οΈ μΌλ¶€ ν…μ¤νΈ μ‹¤ν¨ - λ¬Έμ κ°€ μλ” λ‹¨κ³„λ¥Ό ν™•μΈν•μ„Έμ”")
