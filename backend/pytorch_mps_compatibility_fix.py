#!/usr/bin/env python3
"""
PyTorch 2.1.2 MPS í˜¸í™˜ì„± ìˆ˜ì • íŒ¨ì¹˜
M3 Max í™˜ê²½ì—ì„œ torch.backends.mps.empty_cache() ì˜¤ë¥˜ í•´ê²°
"""

import os
import sys
import logging
from pathlib import Path
from typing import Dict, List, Tuple, Any
import re

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s | %(levelname)s | %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout),
        logging.FileHandler('pytorch_mps_fix.log')
    ]
)
logger = logging.getLogger(__name__)

class MPSCompatibilityFixer:
    """PyTorch 2.1.2 MPS í˜¸í™˜ì„± ìˆ˜ì •ê¸°"""
    
    def __init__(self, project_root: str = None):
        self.project_root = Path(project_root) if project_root else Path(".")
        self.backend_root = self.project_root / "backend"
        self.fixed_files = []
        self.backup_files = []
        
        # ìˆ˜ì •í•  íŒŒì¼ë“¤ (ìš°ì„ ìˆœìœ„ ìˆœ)
        self.target_files = [
            "app/core/gpu_config.py",
            "app/services/model_manager.py", 
            "app/ai_pipeline/utils/memory_manager.py",
            "app/ai_pipeline/pipeline_manager.py",
            "app/api/pipeline_routes.py",
            "app/ai_pipeline/steps/step_08_quality_assessment.py"
        ]
        
        # íŒ¨ì¹˜ íŒ¨í„´ë“¤
        self.patch_patterns = [
            # torch.backends.mps.empty_cache() â†’ torch.mps.empty_cache()
            (
                r'torch\.backends\.mps\.empty_cache\(\)',
                'torch.mps.empty_cache() if hasattr(torch.mps, "empty_cache") else None'
            ),
            # if hasattr(torch.backends.mps, 'empty_cache') â†’ if hasattr(torch.mps, 'empty_cache')
            (
                r'hasattr\(torch\.backends\.mps,\s*[\'"]empty_cache[\'"]?\)',
                'hasattr(torch.mps, "empty_cache")'
            ),
            # torch.backends.mps.is_available() â†’ torch.backends.mps.is_available()  (ìœ ì§€)
            # torch.mps.synchronize() ì¶”ê°€ ì§€ì›
        ]
        
    def create_backup(self, file_path: Path) -> bool:
        """íŒŒì¼ ë°±ì—… ìƒì„±"""
        try:
            backup_path = file_path.with_suffix(f"{file_path.suffix}.backup_mps_fix")
            if backup_path.exists():
                logger.info(f"ğŸ”„ ê¸°ì¡´ ë°±ì—… íŒŒì¼ ë®ì–´ì“°ê¸°: {backup_path}")
            
            backup_path.write_text(file_path.read_text(encoding='utf-8'))
            self.backup_files.append(str(backup_path))
            logger.info(f"ğŸ’¾ ë°±ì—… ìƒì„±: {backup_path}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ ë°±ì—… ìƒì„± ì‹¤íŒ¨ {file_path}: {e}")
            return False
    
    def generate_mps_compatibility_code(self) -> str:
        """MPS í˜¸í™˜ì„± ì½”ë“œ ìƒì„±"""
        return '''
def safe_mps_empty_cache():
    """PyTorch 2.1.2 í˜¸í™˜ MPS ë©”ëª¨ë¦¬ ì •ë¦¬"""
    try:
        import torch
        if hasattr(torch.mps, 'empty_cache'):
            torch.mps.empty_cache()
            return True
        elif hasattr(torch.mps, 'synchronize'):
            torch.mps.synchronize()
            return True
        else:
            import gc
            gc.collect()
            return False
    except Exception as e:
        logger.warning(f"MPS ë©”ëª¨ë¦¬ ì •ë¦¬ ì‹¤íŒ¨: {e}")
        return False
'''
    
    def fix_gpu_config_file(self, file_path: Path) -> bool:
        """gpu_config.py ìˆ˜ì •"""
        try:
            content = file_path.read_text(encoding='utf-8')
            
            # ê¸°ì¡´ ì˜ëª»ëœ íŒ¨í„´ ìˆ˜ì •
            fixes = [
                # torch.backends.mps.empty_cache() ìˆ˜ì •
                (
                    r'torch\.backends\.mps\.empty_cache\(\)',
                    'torch.mps.empty_cache()'
                ),
                # hasattr ì²´í¬ ìˆ˜ì •
                (
                    r'hasattr\(torch\.backends\.mps,\s*[\'"]empty_cache[\'"]?\)',
                    'hasattr(torch.mps, "empty_cache")'
                ),
                # í˜¸í™˜ì„± ì²´í¬ ë¡œì§ ê°œì„ 
                (
                    r'elif hasattr\(torch\.backends\.mps, \'empty_cache\'\):.*?torch\.backends\.mps\.empty_cache\(\)',
                    '''elif hasattr(torch.mps, 'empty_cache'):
                        torch.mps.empty_cache()
                        result["method"] = "mps_empty_cache"
                        logger.info("âœ… torch.mps.empty_cache() ì‹¤í–‰ ì™„ë£Œ")'''
                )
            ]
            
            modified = False
            for pattern, replacement in fixes:
                if re.search(pattern, content):
                    content = re.sub(pattern, replacement, content)
                    modified = True
            
            if modified:
                file_path.write_text(content, encoding='utf-8')
                logger.info(f"âœ… GPU Config ìˆ˜ì • ì™„ë£Œ: {file_path}")
                return True
            else:
                logger.info(f"â„¹ï¸ GPU Config ìˆ˜ì • ë¶ˆí•„ìš”: {file_path}")
                return False
                
        except Exception as e:
            logger.error(f"âŒ GPU Config ìˆ˜ì • ì‹¤íŒ¨ {file_path}: {e}")
            return False
    
    def fix_model_manager_file(self, file_path: Path) -> bool:
        """model_manager.py ìˆ˜ì •"""
        try:
            content = file_path.read_text(encoding='utf-8')
            
            # ê¸°ì¡´ ì˜ëª»ëœ íŒ¨í„´ë“¤ ìˆ˜ì •
            fixes = [
                # torch.backends.mps.empty_cache() ìˆ˜ì •
                (
                    r'torch\.backends\.mps\.empty_cache\(\)',
                    '''if hasattr(torch.mps, 'empty_cache'):
                        torch.mps.empty_cache()
                    elif hasattr(torch.mps, 'synchronize'):
                        torch.mps.synchronize()'''
                ),
                # hasattr ì²´í¬ ìˆ˜ì •
                (
                    r'if hasattr\(torch\.backends\.mps,\s*[\'"]empty_cache[\'"]?\):.*?torch\.backends\.mps\.empty_cache\(\)',
                    '''if hasattr(torch.mps, 'empty_cache'):
                        torch.mps.empty_cache()
                        logger.info("âœ… MPS ìºì‹œ ì •ë¦¬ ì™„ë£Œ")'''
                ),
                # ì •ë³´ ë¡œê·¸ ìˆ˜ì •
                (
                    r'logger\.info\("â„¹ï¸ MPS empty_cache ë¯¸ì§€ì› \(PyTorch 2\.5\.1\)"\)',
                    'logger.info("â„¹ï¸ MPS empty_cache ë¯¸ì§€ì› (PyTorch 2.1.2)")'
                )
            ]
            
            modified = False
            for pattern, replacement in fixes:
                if re.search(pattern, content):
                    content = re.sub(pattern, replacement, content, flags=re.DOTALL)
                    modified = True
            
            if modified:
                file_path.write_text(content, encoding='utf-8')
                logger.info(f"âœ… Model Manager ìˆ˜ì • ì™„ë£Œ: {file_path}")
                return True
            else:
                logger.info(f"â„¹ï¸ Model Manager ìˆ˜ì • ë¶ˆí•„ìš”: {file_path}")
                return False
                
        except Exception as e:
            logger.error(f"âŒ Model Manager ìˆ˜ì • ì‹¤íŒ¨ {file_path}: {e}")
            return False
    
    def fix_memory_manager_file(self, file_path: Path) -> bool:
        """memory_manager.py ìˆ˜ì •"""
        try:
            content = file_path.read_text(encoding='utf-8')
            
            # MPS ë©”ëª¨ë¦¬ ì •ë¦¬ ë¶€ë¶„ ìˆ˜ì •
            fixes = [
                # torch.mps.empty_cache() í˜¸í™˜ì„± ì²´í¬
                (
                    r'if hasattr\(torch\.mps,\s*[\'"]empty_cache[\'"]?\):.*?torch\.mps\.empty_cache\(\)',
                    '''if hasattr(torch.mps, 'empty_cache'):
                        torch.mps.empty_cache()
                    elif hasattr(torch.mps, 'synchronize'):
                        torch.mps.synchronize()'''
                ),
                # ì˜ˆì™¸ ì²˜ë¦¬ ê°œì„ 
                (
                    r'except:.*?pass',
                    '''except Exception as e:
                    logger.warning(f"MPS ë©”ëª¨ë¦¬ ì •ë¦¬ ì‹¤íŒ¨: {e}")'''
                )
            ]
            
            modified = False
            for pattern, replacement in fixes:
                if re.search(pattern, content):
                    content = re.sub(pattern, replacement, content, flags=re.DOTALL)
                    modified = True
            
            if modified:
                file_path.write_text(content, encoding='utf-8')
                logger.info(f"âœ… Memory Manager ìˆ˜ì • ì™„ë£Œ: {file_path}")
                return True
            else:
                logger.info(f"â„¹ï¸ Memory Manager ìˆ˜ì • ë¶ˆí•„ìš”: {file_path}")
                return False
                
        except Exception as e:
            logger.error(f"âŒ Memory Manager ìˆ˜ì • ì‹¤íŒ¨ {file_path}: {e}")
            return False
    
    def fix_pipeline_manager_file(self, file_path: Path) -> bool:
        """pipeline_manager.py ìˆ˜ì •"""
        try:
            content = file_path.read_text(encoding='utf-8')
            
            # torch.mps.empty_cache() ì§ì ‘ í˜¸ì¶œ ìˆ˜ì •
            fixes = [
                (
                    r'torch\.mps\.empty_cache\(\)',
                    '''if hasattr(torch.mps, 'empty_cache'):
                torch.mps.empty_cache()
            elif hasattr(torch.mps, 'synchronize'):
                torch.mps.synchronize()'''
                ),
                # hasattr ì²´í¬ ìˆ˜ì •
                (
                    r'if hasattr\(torch\.backends,\s*[\'"]mps[\'"]?\).*?torch\.mps\.empty_cache\(\)',
                    '''if hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
                if hasattr(torch.mps, 'empty_cache'):
                    torch.mps.empty_cache()
                elif hasattr(torch.mps, 'synchronize'):
                    torch.mps.synchronize()'''
                )
            ]
            
            modified = False
            for pattern, replacement in fixes:
                if re.search(pattern, content):
                    content = re.sub(pattern, replacement, content, flags=re.DOTALL)
                    modified = True
            
            if modified:
                file_path.write_text(content, encoding='utf-8')
                logger.info(f"âœ… Pipeline Manager ìˆ˜ì • ì™„ë£Œ: {file_path}")
                return True
            else:
                logger.info(f"â„¹ï¸ Pipeline Manager ìˆ˜ì • ë¶ˆí•„ìš”: {file_path}")
                return False
                
        except Exception as e:
            logger.error(f"âŒ Pipeline Manager ìˆ˜ì • ì‹¤íŒ¨ {file_path}: {e}")
            return False
    
    def fix_pipeline_routes_file(self, file_path: Path) -> bool:
        """pipeline_routes.py ìˆ˜ì •"""
        try:
            content = file_path.read_text(encoding='utf-8')
            
            # torch.mp ê´€ë ¨ ìˆ˜ì •
            fixes = [
                (
                    r'torch\.mp',
                    'torch.mps'
                ),
                # ë©”ëª¨ë¦¬ ì •ë¦¬ ë¡œì§ ê°œì„ 
                (
                    r'if pipeline\.device == \'mps\'.*?torch\.backends\.mps\.is_available\(\):.*?torch\.mp',
                    '''if pipeline.device == 'mps' and torch.backends.mps.is_available():
                if hasattr(torch.mps, 'empty_cache'):
                    torch.mps.empty_cache()
                elif hasattr(torch.mps, 'synchronize'):
                    torch.mps.synchronize()'''
                )
            ]
            
            modified = False
            for pattern, replacement in fixes:
                if re.search(pattern, content):
                    content = re.sub(pattern, replacement, content, flags=re.DOTALL)
                    modified = True
            
            if modified:
                file_path.write_text(content, encoding='utf-8')
                logger.info(f"âœ… Pipeline Routes ìˆ˜ì • ì™„ë£Œ: {file_path}")
                return True
            else:
                logger.info(f"â„¹ï¸ Pipeline Routes ìˆ˜ì • ë¶ˆí•„ìš”: {file_path}")
                return False
                
        except Exception as e:
            logger.error(f"âŒ Pipeline Routes ìˆ˜ì • ì‹¤íŒ¨ {file_path}: {e}")
            return False
    
    def fix_quality_assessment_file(self, file_path: Path) -> bool:
        """step_08_quality_assessment.py ìˆ˜ì •"""
        try:
            content = file_path.read_text(encoding='utf-8')
            
            # MPS ë©”ëª¨ë¦¬ ì •ë¦¬ ë¶€ë¶„ ìˆ˜ì •
            fixes = [
                # torch.backends.mps.empty_cache() ìˆ˜ì •
                (
                    r'if hasattr\(torch\.backends\.mps,\s*[\'"]empty_cache[\'"]?\):.*?torch\.backends\.mps\.empty_cache\(\)',
                    '''if hasattr(torch.mps, 'empty_cache'):
                        torch.mps.empty_cache()'''
                ),
                # torch.mps.synchronize() ì¶”ê°€ ì§€ì›
                (
                    r'elif hasattr\(torch\.mps,\s*[\'"]synchronize[\'"]?\):.*?torch\.mps\.synchronize\(\)',
                    '''elif hasattr(torch.mps, 'synchronize'):
                        torch.mps.synchronize()'''
                )
            ]
            
            modified = False
            for pattern, replacement in fixes:
                if re.search(pattern, content):
                    content = re.sub(pattern, replacement, content, flags=re.DOTALL)
                    modified = True
            
            if modified:
                file_path.write_text(content, encoding='utf-8')
                logger.info(f"âœ… Quality Assessment ìˆ˜ì • ì™„ë£Œ: {file_path}")
                return True
            else:
                logger.info(f"â„¹ï¸ Quality Assessment ìˆ˜ì • ë¶ˆí•„ìš”: {file_path}")
                return False
                
        except Exception as e:
            logger.error(f"âŒ Quality Assessment ìˆ˜ì • ì‹¤íŒ¨ {file_path}: {e}")
            return False
    
    def create_mps_utility_module(self) -> bool:
        """MPS ìœ í‹¸ë¦¬í‹° ëª¨ë“ˆ ìƒì„±"""
        try:
            utils_dir = self.backend_root / "app" / "utils"
            utils_dir.mkdir(exist_ok=True)
            
            mps_utils_path = utils_dir / "mps_utils.py"
            
            mps_utils_content = '''"""
MPS ìœ í‹¸ë¦¬í‹° ëª¨ë“ˆ - PyTorch 2.1.2 í˜¸í™˜
M3 Max í™˜ê²½ì—ì„œ ì•ˆì „í•œ MPS ë©”ëª¨ë¦¬ ê´€ë¦¬
"""

import logging
import gc
from typing import Dict, Any, Optional
import torch

logger = logging.getLogger(__name__)

class MPSMemoryManager:
    """M3 Max MPS ë©”ëª¨ë¦¬ ê´€ë¦¬ì"""
    
    def __init__(self):
        self.is_available = torch.backends.mps.is_available()
        self.supports_empty_cache = hasattr(torch.mps, 'empty_cache')
        self.supports_synchronize = hasattr(torch.mps, 'synchronize')
        
        logger.info(f"ğŸ MPS ë©”ëª¨ë¦¬ ê´€ë¦¬ì ì´ˆê¸°í™”")
        logger.info(f"   - MPS ì‚¬ìš© ê°€ëŠ¥: {self.is_available}")
        logger.info(f"   - empty_cache ì§€ì›: {self.supports_empty_cache}")
        logger.info(f"   - synchronize ì§€ì›: {self.supports_synchronize}")
    
    def safe_empty_cache(self) -> Dict[str, Any]:
        """ì•ˆì „í•œ MPS ë©”ëª¨ë¦¬ ì •ë¦¬"""
        result = {
            "success": False,
            "method": "none",
            "message": "MPS ì‚¬ìš© ë¶ˆê°€"
        }
        
        if not self.is_available:
            return result
        
        try:
            if self.supports_empty_cache:
                torch.mps.empty_cache()
                result.update({
                    "success": True,
                    "method": "mps_empty_cache",
                    "message": "torch.mps.empty_cache() ì‹¤í–‰ ì™„ë£Œ"
                })
                logger.info("âœ… torch.mps.empty_cache() ì‹¤í–‰ ì™„ë£Œ")
                
            elif self.supports_synchronize:
                torch.mps.synchronize()
                result.update({
                    "success": True,
                    "method": "mps_synchronize",
                    "message": "torch.mps.synchronize() ì‹¤í–‰ ì™„ë£Œ"
                })
                logger.info("âœ… torch.mps.synchronize() ì‹¤í–‰ ì™„ë£Œ")
                
            else:
                gc.collect()
                result.update({
                    "success": True,
                    "method": "gc_collect",
                    "message": "ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ìœ¼ë¡œ ëŒ€ì²´"
                })
                logger.info("âœ… ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ìœ¼ë¡œ ë©”ëª¨ë¦¬ ì •ë¦¬")
            
            return result
            
        except Exception as e:
            result.update({
                "success": False,
                "method": "error",
                "message": f"MPS ë©”ëª¨ë¦¬ ì •ë¦¬ ì‹¤íŒ¨: {e}"
            })
            logger.error(f"âŒ MPS ë©”ëª¨ë¦¬ ì •ë¦¬ ì‹¤íŒ¨: {e}")
            return result
    
    def get_compatibility_info(self) -> Dict[str, Any]:
        """MPS í˜¸í™˜ì„± ì •ë³´ ì¡°íšŒ"""
        return {
            "pytorch_version": torch.__version__,
            "mps_available": self.is_available,
            "mps_built": torch.backends.mps.is_built(),
            "empty_cache_support": self.supports_empty_cache,
            "synchronize_support": self.supports_synchronize,
            "recommended_method": (
                "mps_empty_cache" if self.supports_empty_cache 
                else "mps_synchronize" if self.supports_synchronize 
                else "gc_collect"
            )
        }

# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
_mps_manager = None

def get_mps_manager() -> MPSMemoryManager:
    """ì „ì—­ MPS ê´€ë¦¬ì ë°˜í™˜"""
    global _mps_manager
    if _mps_manager is None:
        _mps_manager = MPSMemoryManager()
    return _mps_manager

def safe_mps_empty_cache() -> Dict[str, Any]:
    """ì•ˆì „í•œ MPS ë©”ëª¨ë¦¬ ì •ë¦¬ (í•¨ìˆ˜í˜• ì¸í„°í˜ì´ìŠ¤)"""
    return get_mps_manager().safe_empty_cache()

def get_mps_compatibility_info() -> Dict[str, Any]:
    """MPS í˜¸í™˜ì„± ì •ë³´ ì¡°íšŒ (í•¨ìˆ˜í˜• ì¸í„°í˜ì´ìŠ¤)"""
    return get_mps_manager().get_compatibility_info()
'''
            
            mps_utils_path.write_text(mps_utils_content, encoding='utf-8')
            logger.info(f"âœ… MPS ìœ í‹¸ë¦¬í‹° ëª¨ë“ˆ ìƒì„±: {mps_utils_path}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ MPS ìœ í‹¸ë¦¬í‹° ëª¨ë“ˆ ìƒì„± ì‹¤íŒ¨: {e}")
            return False
    
    def run_fix(self) -> Dict[str, Any]:
        """ì „ì²´ ìˆ˜ì • ì‹¤í–‰"""
        logger.info("ğŸ”§ PyTorch 2.1.2 MPS í˜¸í™˜ì„± ìˆ˜ì • ì‹œì‘")
        
        results = {
            "success": False,
            "fixed_files": [],
            "failed_files": [],
            "backup_files": [],
            "total_files": len(self.target_files)
        }
        
        # íŒŒì¼ë³„ ìˆ˜ì • í•¨ìˆ˜ ë§¤í•‘
        fix_functions = {
            "app/core/gpu_config.py": self.fix_gpu_config_file,
            "app/services/model_manager.py": self.fix_model_manager_file,
            "app/ai_pipeline/utils/memory_manager.py": self.fix_memory_manager_file,
            "app/ai_pipeline/pipeline_manager.py": self.fix_pipeline_manager_file,
            "app/api/pipeline_routes.py": self.fix_pipeline_routes_file,
            "app/ai_pipeline/steps/step_08_quality_assessment.py": self.fix_quality_assessment_file
        }
        
        # ê° íŒŒì¼ ìˆ˜ì •
        for file_path_str in self.target_files:
            file_path = self.backend_root / file_path_str
            
            if not file_path.exists():
                logger.warning(f"âš ï¸ íŒŒì¼ ì—†ìŒ: {file_path}")
                results["failed_files"].append(file_path_str)
                continue
            
            # ë°±ì—… ìƒì„±
            if not self.create_backup(file_path):
                results["failed_files"].append(file_path_str)
                continue
            
            # íŒŒì¼ ìˆ˜ì •
            fix_function = fix_functions.get(file_path_str)
            if fix_function:
                if fix_function(file_path):
                    results["fixed_files"].append(file_path_str)
                else:
                    results["failed_files"].append(file_path_str)
            else:
                logger.warning(f"âš ï¸ ìˆ˜ì • í•¨ìˆ˜ ì—†ìŒ: {file_path_str}")
                results["failed_files"].append(file_path_str)
        
        # MPS ìœ í‹¸ë¦¬í‹° ëª¨ë“ˆ ìƒì„±
        if self.create_mps_utility_module():
            results["fixed_files"].append("app/utils/mps_utils.py")
        
        # ê²°ê³¼ ì§‘ê³„
        results["backup_files"] = self.backup_files
        results["success"] = len(results["failed_files"]) == 0
        
        logger.info(f"ğŸ‰ ìˆ˜ì • ì™„ë£Œ: {len(results['fixed_files'])}/{results['total_files']}")
        logger.info(f"âœ… ì„±ê³µ: {results['fixed_files']}")
        if results["failed_files"]:
            logger.warning(f"âŒ ì‹¤íŒ¨: {results['failed_files']}")
        
        return results
    
    def rollback(self) -> bool:
        """ë°±ì—…ì—ì„œ ë¡¤ë°±"""
        try:
            logger.info("ğŸ”„ ë¡¤ë°± ì‹œì‘")
            
            for backup_file_str in self.backup_files:
                backup_path = Path(backup_file_str)
                if not backup_path.exists():
                    continue
                
                original_path = backup_path.with_suffix('')
                original_path.write_text(backup_path.read_text(encoding='utf-8'))
                logger.info(f"ğŸ”„ ë¡¤ë°±: {original_path}")
            
            logger.info("âœ… ë¡¤ë°± ì™„ë£Œ")
            return True
            
        except Exception as e:
            logger.error(f"âŒ ë¡¤ë°± ì‹¤íŒ¨: {e}")
            return False

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    try:
        # í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì°¾ê¸°
        current_dir = Path.cwd()
        project_root = current_dir
        
        # backend ë””ë ‰í† ë¦¬ ì°¾ê¸°
        if not (project_root / "backend").exists():
            if "backend" in str(current_dir):
                project_root = current_dir.parent
            else:
                logger.error("âŒ backend ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                return False
        
        # ìˆ˜ì • ì‹¤í–‰
        fixer = MPSCompatibilityFixer(project_root)
        results = fixer.run_fix()
        
        # ê²°ê³¼ ì¶œë ¥
        print("\n" + "="*60)
        print("ğŸ‰ PyTorch 2.1.2 MPS í˜¸í™˜ì„± ìˆ˜ì • ì™„ë£Œ!")
        print("="*60)
        print(f"âœ… ì„±ê³µ: {len(results['fixed_files'])}/{results['total_files']}")
        print(f"ğŸ“ ìˆ˜ì •ëœ íŒŒì¼: {results['fixed_files']}")
        
        if results['failed_files']:
            print(f"âŒ ì‹¤íŒ¨í•œ íŒŒì¼: {results['failed_files']}")
        
        print(f"ğŸ’¾ ë°±ì—… íŒŒì¼: {len(results['backup_files'])}ê°œ")
        print("\nğŸš€ ì´ì œ ì„œë²„ë¥¼ ë‹¤ì‹œ ì‹œì‘í•´ì£¼ì„¸ìš”:")
        print("   cd backend && python app/main.py")
        
        return results['success']
        
    except Exception as e:
        logger.error(f"âŒ ìˆ˜ì • ë„êµ¬ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)