#!/usr/bin/env python3
"""ê¸°ë³¸ Virtual Try-On êµ¬í˜„"""

import cv2
import numpy as np
import mediapipe as mp
from typing import Dict, Optional

class BasicVirtualTryOn:
    def __init__(self):
        # MediaPipe ì´ˆê¸°í™”
        self.mp_pose = mp.solutions.pose
        self.pose = self.mp_pose.Pose(
            static_image_mode=True,
            model_complexity=2,
            enable_segmentation=True,
            min_detection_confidence=0.5
        )
        print("âœ… Virtual Try-On ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ")
    
    def create_test_images(self):
        """í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ìƒì„±"""
        import os
        os.makedirs("data/test", exist_ok=True)
        
        # ì‚¬ëŒ ì´ë¯¸ì§€ (ë”ë¯¸)
        person = np.ones((600, 400, 3), dtype=np.uint8) * 200
        cv2.rectangle(person, (150, 100), (250, 400), (100, 100, 100), -1)
        cv2.putText(person, "PERSON", (140, 50), 
                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0), 2)
        cv2.imwrite("data/test/person.jpg", person)
        
        # ì˜ë¥˜ ì´ë¯¸ì§€ (ë”ë¯¸)
        cloth = np.ones((300, 300, 3), dtype=np.uint8) * 255
        cv2.rectangle(cloth, (50, 50), (250, 250), (0, 100, 200), -1)
        cv2.putText(cloth, "SHIRT", (100, 30), 
                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0), 2)
        cv2.imwrite("data/test/cloth.jpg", cloth)
        
        print("âœ… í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ìƒì„± ì™„ë£Œ!")
        return "data/test/person.jpg", "data/test/cloth.jpg"
    
    def process(self, person_path: str, cloth_path: str) -> Optional[np.ndarray]:
        """ê°€ìƒ í”¼íŒ… ì²˜ë¦¬"""
        # ì´ë¯¸ì§€ ë¡œë“œ
        person_img = cv2.imread(person_path)
        cloth_img = cv2.imread(cloth_path)
        
        if person_img is None or cloth_img is None:
            print("âŒ ì´ë¯¸ì§€ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            return None
        
        print("ğŸ”„ ê°€ìƒ í”¼íŒ… ì²˜ë¦¬ ì¤‘...")
        
        # ê°„ë‹¨í•œ ì˜¤ë²„ë ˆì´ (ì‹¤ì œë¡œëŠ” ë” ë³µì¡í•œ ì²˜ë¦¬ í•„ìš”)
        h, w = person_img.shape[:2]
        
        # ì˜ë¥˜ í¬ê¸° ì¡°ì •
        cloth_resized = cv2.resize(cloth_img, (200, 250))
        
        # ìœ„ì¹˜ ê³„ì‚° (ê°€ìŠ´ ì¤‘ì•™)
        x = w // 2 - 100
        y = 120
        
        # ê²°ê³¼ ì´ë¯¸ì§€ ìƒì„±
        result = person_img.copy()
        
        # ì˜ë¥˜ ì˜¤ë²„ë ˆì´
        roi = result[y:y+250, x:x+200]
        alpha = 0.8
        blended = cv2.addWeighted(roi, 1-alpha, cloth_resized, alpha, 0)
        result[y:y+250, x:x+200] = blended
        
        return result

# í…ŒìŠ¤íŠ¸ ì‹¤í–‰
if __name__ == "__main__":
    print("ğŸš€ Virtual Try-On í…ŒìŠ¤íŠ¸ ì‹œì‘")
    
    model = BasicVirtualTryOn()
    
    # í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ìƒì„±
    person_path, cloth_path = model.create_test_images()
    
    # ì²˜ë¦¬
    result = model.process(person_path, cloth_path)
    
    if result is not None:
        # ê²°ê³¼ ì €ì¥
        import os
        os.makedirs("results", exist_ok=True)
        cv2.imwrite("results/test_result.jpg", result)
        print("âœ… ì™„ë£Œ! results/test_result.jpg í™•ì¸í•˜ì„¸ìš”")
        
        # ë¹„êµ ì´ë¯¸ì§€ ìƒì„±
        person = cv2.imread(person_path)
        cloth = cv2.imread(cloth_path)
        cloth_display = cv2.resize(cloth, (200, 300))
        
        # ê°€ë¡œë¡œ ë‚˜ì—´
        comparison = np.hstack([
            cv2.resize(person, (300, 400)),
            np.ones((400, 50, 3), dtype=np.uint8) * 255,
            cv2.copyMakeBorder(cloth_display, 50, 50, 50, 50, 
                             cv2.BORDER_CONSTANT, value=[255,255,255]),
            np.ones((400, 50, 3), dtype=np.uint8) * 255,
            cv2.resize(result, (300, 400))
        ])
        
        cv2.imwrite("results/comparison.jpg", comparison)
        print("ğŸ“Š ë¹„êµ ì´ë¯¸ì§€: results/comparison.jpg")
