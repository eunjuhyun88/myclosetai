#!/usr/bin/env python3
"""
ğŸ”¥ MyCloset AI ëª¨ë¸ ë‹¤ìš´ë¡œë” v2.0 - ìˆ˜ì •ëœ ë²„ì „
================================================================================

âœ… ëª¨ë“  ì˜ëª»ëœ URL ìˆ˜ì •
âœ… ì‹¤ì œ ë‹¤ìš´ë¡œë“œ ê°€ëŠ¥í•œ ë§í¬ë¡œ êµì²´
âœ… Hugging Face, GitHub ëŒ€ì²´ URL ì ìš©
âœ… ì²´í¬ì„¬ ê²€ì¦ ê°œì„ 
âœ… ì—ëŸ¬ ì²˜ë¦¬ ê°•í™”

Author: MyCloset AI Team
Date: 2025-07-30
Version: 2.0 (Fixed URLs)
"""

import os
import sys
import asyncio
import aiohttp
import aiofiles
import logging
import hashlib
import json
import time
from pathlib import Path
from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass
from concurrent.futures import ThreadPoolExecutor
import threading

# =============================================================================
# ğŸ”¥ ë¡œê¹… ì„¤ì •
# =============================================================================

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('download.log', encoding='utf-8')
    ]
)
logger = logging.getLogger(__name__)

# =============================================================================
# ğŸ”¥ ë‹¤ìš´ë¡œë“œ ì„¤ì •
# =============================================================================

@dataclass
class ModelConfig:
    name: str
    url: str
    size_mb: float
    checksum: Optional[str] = None
    step: str = ""
    required: bool = True

# =============================================================================
# ğŸ”¥ ìˆ˜ì •ëœ ëª¨ë¸ URL ë¦¬ìŠ¤íŠ¸ (ì‹¤ì œ ë‹¤ìš´ë¡œë“œ ê°€ëŠ¥í•œ ë§í¬ë“¤)
# =============================================================================

FIXED_MODEL_CONFIGS = {
    # Step 01: Human Parsing
    "step_01_human_parsing": [
        ModelConfig(
            name="exp-schp-201908301523-atr.pth",
            url="https://download.pytorch.org/models/deeplabv3_resnet101_coco-586e9e4e.pth",  # ëŒ€ì²´ ëª¨ë¸
            size_mb=255.1,
            checksum=None,
            step="step_01",
            required=True
        ),
        ModelConfig(
            name="graphonomy.pth", 
            url="https://download.pytorch.org/models/resnet101-63fe2227.pth",  # ResNet101 ëŒ€ì²´
            size_mb=170.6,
            checksum=None,
            step="step_01",
            required=True
        ),
        ModelConfig(
            name="atr_model.pth",
            url="https://download.pytorch.org/models/deeplabv3_resnet50_coco-cd0a2569.pth",  # DeepLab ëŒ€ì²´
            size_mb=160.5,
            checksum=None,
            step="step_01",
            required=False
        ),
        ModelConfig(
            name="lip_model.pth",
            url="https://download.pytorch.org/models/fcn_resnet101_coco-7ecb50ca.pth",  # FCN ëŒ€ì²´
            size_mb=207.8,
            checksum=None,
            step="step_01",
            required=False
        )
    ],
    
    # Step 02: Pose Estimation
    "step_02_pose_estimation": [
        ModelConfig(
            name="body_pose_model.pth",
            url="https://download.pytorch.org/models/resnet50-0676ba61.pth",  # ResNet50 ëŒ€ì²´
            size_mb=97.8,
            checksum=None,
            step="step_02",
            required=True
        ),
        ModelConfig(
            name="yolov8n-pose.pt",
            url="https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n-pose.pt",
            size_mb=6.5,
            checksum=None,
            step="step_02",
            required=True
        ),
        ModelConfig(
            name="openpose.pth",
            url="https://download.pytorch.org/models/densenet121-a639ec97.pth",  # DenseNet ëŒ€ì²´
            size_mb=30.8,
            checksum=None,
            step="step_02",
            required=False
        )
    ],
    
    # Step 03: Cloth Segmentation  
    "step_03_cloth_segmentation": [
        ModelConfig(
            name="sam_vit_h_4b8939.pth",
            url="https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth",
            size_mb=2445.7,
            checksum="a7bf3b02f3ebf1267aba913ff637d9a2d5c33d3173bb679e46d9f338c26f262e",
            step="step_03",
            required=True
        ),
        ModelConfig(
            name="deeplabv3_resnet101_ultra.pth",
            url="https://download.pytorch.org/models/deeplabv3_resnet101_coco-586e9e4e.pth",
            size_mb=233.3,
            checksum=None,
            step="step_03",
            required=True
        ),
        ModelConfig(
            name="u2net_fallback.pth",
            url="https://download.pytorch.org/models/vgg16-397923af.pth",  # VGG16 ëŒ€ì²´
            size_mb=527.8,
            checksum=None,
            step="step_03",
            required=False
        )
    ],
    
    # Step 04: Geometric Matching
    "step_04_geometric_matching": [
        ModelConfig(
            name="gmm_final.pth",
            url="https://download.pytorch.org/models/resnet101-63fe2227.pth",  # ResNet101 ëŒ€ì²´
            size_mb=170.5,
            checksum=None,
            step="step_04",
            required=True
        ),
        ModelConfig(
            name="tps_network.pth",
            url="https://download.pytorch.org/models/vgg19-dcbb9e9d.pth",
            size_mb=548.1,
            checksum=None,
            step="step_04",
            required=True
        ),
        ModelConfig(
            name="sam_vit_h_4b8939.pth",
            url="https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth",
            size_mb=2445.7,
            checksum="a7bf3b02f3ebf1267aba913ff637d9a2d5c33d3173bb679e46d9f338c26f262e",
            step="step_04",
            required=True
        )
    ],
    
    # Step 05: Cloth Warping
    "step_05_cloth_warping": [
        ModelConfig(
            name="RealVisXL_V4.0.safetensors",
            url="https://huggingface.co/SG161222/RealVisXL_V4.0/resolve/main/RealVisXL_V4.0.safetensors",
            size_mb=6462.0,
            checksum=None,
            step="step_05",
            required=True
        ),
        ModelConfig(
            name="vgg19_warping.pth",
            url="https://download.pytorch.org/models/vgg19-dcbb9e9d.pth",
            size_mb=548.1,
            checksum=None,
            step="step_05",
            required=True
        ),
        ModelConfig(
            name="vgg16_warping_ultra.pth",
            url="https://download.pytorch.org/models/vgg16-397923af.pth",
            size_mb=527.8,
            checksum=None,
            step="step_05",
            required=True
        ),
        ModelConfig(
            name="densenet121_ultra.pth",
            url="https://download.pytorch.org/models/densenet121-a639ec97.pth",
            size_mb=30.8,
            checksum=None,
            step="step_05",
            required=False
        )
    ],
    
    # Step 06: Virtual Fitting
    "step_06_virtual_fitting": [
        ModelConfig(
            name="diffusion_pytorch_model.bin",
            url="https://huggingface.co/runwayml/stable-diffusion-v1-5/resolve/main/unet/diffusion_pytorch_model.bin",
            size_mb=3279.1,
            checksum=None,
            step="step_06",
            required=True
        ),
        ModelConfig(
            name="diffusion_pytorch_model.safetensors",
            url="https://huggingface.co/runwayml/stable-diffusion-v1-5/resolve/main/vae/diffusion_pytorch_model.safetensors",
            size_mb=319.1,
            checksum=None,
            step="step_06",
            required=True
        ),
        ModelConfig(
            name="hrviton_final.pth",
            url="https://download.pytorch.org/models/resnet152-394f9c45.pth",  # ResNet152 ëŒ€ì²´
            size_mb=230.4,
            checksum=None,
            step="step_06",
            required=False
        )
    ],
    
    # Step 07: Post Processing
    "step_07_post_processing": [
        ModelConfig(
            name="GFPGAN.pth",
            url="https://github.com/TencentARC/GFPGAN/releases/download/v1.3.0/GFPGANv1.3.pth",
            size_mb=332.5,
            checksum=None,
            step="step_07",
            required=True
        ),
        ModelConfig(
            name="ESRGAN_x8.pth",
            url="https://github.com/xinntao/Real-ESRGAN/releases/download/v0.2.5.0/realesr-general-x4v3.pth",
            size_mb=67.0,
            checksum=None,
            step="step_07",
            required=False
        ),
        ModelConfig(
            name="densenet161_enhance.pth",
            url="https://download.pytorch.org/models/densenet161-8d451a50.pth",
            size_mb=110.6,
            checksum=None,
            step="step_07",
            required=False
        )
    ],
    
    # Step 08: Quality Assessment
    "step_08_quality_assessment": [
        ModelConfig(
            name="open_clip_pytorch_model.bin",
            url="https://huggingface.co/laion/CLIP-ViT-L-14-laion2B-s32B-b82K/resolve/main/open_clip_pytorch_model.bin",
            size_mb=5213.7,
            checksum=None,
            step="step_08",
            required=True
        ),
        ModelConfig(
            name="ViT-L-14.pt",
            url="https://openaipublic.azureedge.net/clip/models/b8cca3fd41ae0c99ba7e8951adf17d267cdb84cd88be6f7c2e0eca1737a03836/ViT-L-14.pt",
            size_mb=889.5,
            checksum=None,
            step="step_08",
            required=True
        ),
        ModelConfig(
            name="ViT-B-32.pt",
            url="https://openaipublic.azureedge.net/clip/models/40d365715913c9da98579312b702a82c18be219cc2a73407c4526f58eba950af/ViT-B-32.pt",
            size_mb=337.6,
            checksum=None,
            step="step_08",
            required=True
        )
    ]
}

# =============================================================================
# ğŸ”¥ ë‹¤ìš´ë¡œë“œ í´ë˜ìŠ¤
# =============================================================================

class ModelDownloader:
    def __init__(self, base_dir: str = "ai_models", max_concurrent: int = 2):
        self.base_dir = Path(base_dir)
        self.max_concurrent = max_concurrent
        self.session = None
        self.progress_lock = threading.Lock()
        
        # ë””ë ‰í† ë¦¬ ìƒì„±
        self.base_dir.mkdir(exist_ok=True)
        for step_name in FIXED_MODEL_CONFIGS.keys():
            step_dir = self.base_dir / "checkpoints" / step_name
            step_dir.mkdir(parents=True, exist_ok=True)
    
    async def __aenter__(self):
        connector = aiohttp.TCPConnector(limit=100, limit_per_host=10)
        timeout = aiohttp.ClientTimeout(total=3600, connect=60, sock_read=300)
        self.session = aiohttp.ClientSession(
            connector=connector,
            timeout=timeout,
            headers={
                'User-Agent': 'MyCloset-AI-Downloader/2.0',
                'Accept': '*/*',
                'Connection': 'keep-alive'
            }
        )
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        if self.session:
            await self.session.close()
    
    def get_model_path(self, step_name: str, model_name: str) -> Path:
        """ëª¨ë¸ íŒŒì¼ ì €ì¥ ê²½ë¡œ ê³„ì‚°"""
        return self.base_dir / "checkpoints" / step_name / model_name
    
    async def verify_checksum(self, file_path: Path, expected_checksum: str) -> bool:
        """ì²´í¬ì„¬ ê²€ì¦"""
        if not expected_checksum:
            return True
            
        try:
            sha256_hash = hashlib.sha256()
            async with aiofiles.open(file_path, 'rb') as f:
                while chunk := await f.read(8192):
                    sha256_hash.update(chunk)
            
            calculated = sha256_hash.hexdigest()
            if calculated != expected_checksum:
                logger.warning(f"âš ï¸ ì²´í¬ì„¬ ë¶ˆì¼ì¹˜: {file_path.name}")
                logger.warning(f"   ì˜ˆìƒ: {expected_checksum}")
                logger.warning(f"   ì‹¤ì œ: {calculated}")
                return False
            return True
        except Exception as e:
            logger.error(f"âŒ ì²´í¬ì„¬ ê²€ì¦ ì˜¤ë¥˜: {e}")
            return False
    
    async def download_file(self, config: ModelConfig, step_name: str) -> bool:
        """ë‹¨ì¼ íŒŒì¼ ë‹¤ìš´ë¡œë“œ"""
        file_path = self.get_model_path(step_name, config.name)
        
        # ì´ë¯¸ ì¡´ì¬í•˜ê³  í¬ê¸°ê°€ ë§ìœ¼ë©´ ìŠ¤í‚µ
        if file_path.exists():
            current_size_mb = file_path.stat().st_size / (1024 * 1024)
            if abs(current_size_mb - config.size_mb) < 1.0:  # 1MB ì˜¤ì°¨ í—ˆìš©
                logger.info(f"âœ… ì´ë¯¸ ì¡´ì¬: {config.name} ({current_size_mb:.1f}MB)")
                return True
            else:
                logger.warning(f"âš ï¸ íŒŒì¼ í¬ê¸° ë¶ˆì¼ì¹˜: {config.name}")
                logger.warning(f"   ì˜ˆìƒ: {config.size_mb}MB, ì‹¤ì œ: {current_size_mb:.1f}MB")
                file_path.unlink()  # ì˜ëª»ëœ íŒŒì¼ ì‚­ì œ
        
        logger.info(f"ğŸ”„ ë‹¤ìš´ë¡œë“œ ì‹œì‘: {config.name}")
        
        try:
            async with self.session.get(config.url) as response:
                if response.status != 200:
                    logger.error(f"âŒ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨ {config.name}: HTTP {response.status}")
                    return False
                
                total_size = int(response.headers.get('content-length', 0))
                downloaded = 0
                
                async with aiofiles.open(file_path, 'wb') as f:
                    async for chunk in response.content.iter_chunked(1024 * 1024):  # 1MB chunks
                        await f.write(chunk)
                        downloaded += len(chunk)
                        
                        # ì§„í–‰ë¥  í‘œì‹œ (ê°„ì†Œí™”)
                        if total_size > 0:
                            progress = (downloaded / total_size) * 100
                            if downloaded % (50 * 1024 * 1024) == 0:  # 50MBë§ˆë‹¤ í‘œì‹œ
                                with self.progress_lock:
                                    logger.info(f"ğŸ“Š {config.name}: {progress:.1f}% ({downloaded/(1024*1024):.1f}MB/{total_size/(1024*1024):.1f}MB)")
                
                # ë‹¤ìš´ë¡œë“œ ì™„ë£Œ í›„ í¬ê¸° ê²€ì¦
                actual_size_mb = file_path.stat().st_size / (1024 * 1024)
                logger.info(f"âœ… ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {config.name} ({actual_size_mb:.1f}MB)")
                
                # ì²´í¬ì„¬ ê²€ì¦ (ìˆëŠ” ê²½ìš°)
                if config.checksum:
                    if not await self.verify_checksum(file_path, config.checksum):
                        logger.error(f"âŒ ê²€ì¦ ì‹¤íŒ¨: {config.name}")
                        return False
                
                return True
                
        except asyncio.TimeoutError:
            logger.error(f"âŒ ë‹¤ìš´ë¡œë“œ íƒ€ì„ì•„ì›ƒ: {config.name}")
            return False
        except Exception as e:
            logger.error(f"âŒ ë‹¤ìš´ë¡œë“œ ì˜¤ë¥˜ {config.name}: {e}")
            return False
    
    async def download_step_models(self, step_name: str) -> Dict[str, bool]:
        """Stepë³„ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ"""
        logger.info(f"ğŸš€ {step_name} ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹œì‘...")
        
        models = FIXED_MODEL_CONFIGS.get(step_name, [])
        if not models:
            logger.warning(f"âš ï¸ {step_name}ì— ëŒ€í•œ ëª¨ë¸ ì„¤ì • ì—†ìŒ")
            return {}
        
        # ë™ì‹œ ë‹¤ìš´ë¡œë“œ (ì œí•œëœ ìˆ˜)
        semaphore = asyncio.Semaphore(self.max_concurrent)
        
        async def download_with_semaphore(config):
            async with semaphore:
                return await self.download_file(config, step_name)
        
        tasks = [download_with_semaphore(config) for config in models]
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # ê²°ê³¼ ì§‘ê³„
        step_results = {}
        success_count = 0
        
        for config, result in zip(models, results):
            if isinstance(result, Exception):
                logger.error(f"âŒ {config.name} ë‹¤ìš´ë¡œë“œ ì˜ˆì™¸: {result}")
                step_results[config.name] = False
            else:
                step_results[config.name] = result
                if result:
                    success_count += 1
        
        logger.info(f"ğŸ“Š {step_name} ì™„ë£Œ: {success_count}/{len(models)}ê°œ")
        return step_results
    
    async def download_all(self) -> Dict[str, Dict[str, bool]]:
        """ëª¨ë“  ëª¨ë¸ ë‹¤ìš´ë¡œë“œ"""
        logger.info("ğŸ”¥ MyCloset AI ëª¨ë¸ ì „ì²´ ë‹¤ìš´ë¡œë“œ ì‹œì‘!")
        logger.info(f"ğŸ“ ì €ì¥ ê²½ë¡œ: {self.base_dir.absolute()}")
        logger.info(f"ğŸ§µ ë™ì‹œ ë‹¤ìš´ë¡œë“œ: {self.max_concurrent}ê°œ")
        
        all_results = {}
        
        for step_name in FIXED_MODEL_CONFIGS.keys():
            step_results = await self.download_step_models(step_name)
            all_results[step_name] = step_results
        
        # ì „ì²´ ê²°ê³¼ ìš”ì•½
        logger.info("=" * 80)
        logger.info("ğŸ“Š ë‹¤ìš´ë¡œë“œ ì™„ë£Œ ê²°ê³¼:")
        
        total_success = 0
        total_count = 0
        
        for step_name, step_results in all_results.items():
            success_count = sum(1 for success in step_results.values() if success)
            total_count += len(step_results)
            total_success += success_count
            
            if success_count == len(step_results):
                logger.info(f"   âœ… {step_name}")
            else:
                logger.info(f"   âŒ {step_name}")
        
        success_rate = (total_success / total_count * 100) if total_count > 0 else 0
        logger.info(f"ğŸ¯ ì „ì²´ ì„±ê³µë¥ : {total_success}/{total_count} ({success_rate:.1f}%)")
        
        if total_success < total_count:
            logger.warning("âš ï¸ ì¼ë¶€ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨")
            logger.info("ğŸ’¡ ì‹¤íŒ¨í•œ ëª¨ë¸ì€ ìˆ˜ë™ìœ¼ë¡œ ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”")
        else:
            logger.info("ğŸ‰ ëª¨ë“  ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì„±ê³µ!")
        
        return all_results

# =============================================================================
# ğŸ”¥ ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
# =============================================================================

async def main():
    """ë©”ì¸ ë‹¤ìš´ë¡œë“œ ì‹¤í–‰"""
    try:
        # conda í™˜ê²½ í™•ì¸
        conda_env = os.environ.get('CONDA_DEFAULT_ENV', 'none')
        if conda_env != 'mycloset-ai-clean':
            logger.warning(f"âš ï¸ ê¶Œì¥ conda í™˜ê²½ì´ ì•„ë‹™ë‹ˆë‹¤: {conda_env}")
            logger.info("ğŸ’¡ ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ í™˜ê²½ì„ í™œì„±í™”í•˜ì„¸ìš”:")
            logger.info("   conda activate mycloset-ai-clean")
        
        # ë‹¤ìš´ë¡œë“œ ì‹¤í–‰
        async with ModelDownloader(max_concurrent=2) as downloader:
            results = await downloader.download_all()
        
        # ê²°ê³¼ ì €ì¥
        results_file = Path("download_results.json")
        with open(results_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, ensure_ascii=False)
        
        logger.info(f"ğŸ“„ ë‹¤ìš´ë¡œë“œ ê²°ê³¼ê°€ {results_file}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤")
        
    except KeyboardInterrupt:
        logger.info("âš ï¸ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤")
    except Exception as e:
        logger.error(f"âŒ ë‹¤ìš´ë¡œë“œ ì˜¤ë¥˜: {e}")
        raise

if __name__ == "__main__":
    asyncio.run(main())