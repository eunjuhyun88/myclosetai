#!/usr/bin/env python3
"""
ğŸ”¥ MyCloset AI - ìœ íš¨í•œ ë§í¬ ê¸°ë°˜ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ìŠ¤í¬ë¦½íŠ¸ v4.0
================================================================================
âœ… ì‹¤ì œ ì‘ë™í•˜ëŠ” ë‹¤ìš´ë¡œë“œ ë§í¬ë§Œ ì‚¬ìš©
âœ… í—ˆê¹…í˜ì´ìŠ¤, GitHub Releases, ê³µì‹ ì €ì¥ì†Œ ìš°ì„ 
âœ… ë‹¤ì¤‘ ë¯¸ëŸ¬ ì„œë²„ ì§€ì›
âœ… íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ ì‚¬ì „ ê²€ì¦
âœ… ì•ˆì „í•œ ëŒ€ì²´ íŒŒì¼ í™œìš©
================================================================================
"""

import os
import sys
import requests
import hashlib
from pathlib import Path
from typing import Dict, List, Optional, Tuple, Set
import logging
from tqdm import tqdm
import json
import shutil
import time

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    datefmt='%H:%M:%S'
)
logger = logging.getLogger(__name__)

class WorkingModelDownloader:
    def __init__(self, ai_models_dir: str = "ai_models"):
        self.ai_models_dir = Path(ai_models_dir)
        
        # ì‹¤ì œ ì‘ë™í•˜ëŠ” ë‹¤ìš´ë¡œë“œ ì •ë³´ (2025ë…„ 7ì›” ê²€ì¦ëœ ë§í¬ë“¤)
        self.working_models = {
            # 1. U2-Net ëª¨ë¸ - ì—¬ëŸ¬ ì‘ë™í•˜ëŠ” ì†ŒìŠ¤
            "u2net.pth": {
                "primary_paths": [
                    "ai_models/u2net.pth",
                    "ai_models/checkpoints/step_03_cloth_segmentation/u2net.pth"
                ],
                "download_sources": [
                    {
                        "url": "https://huggingface.co/skytnt/u2net/resolve/main/u2net.pth",
                        "description": "HuggingFace U2Net (ê²€ì¦ë¨)",
                        "expected_size_mb": 176.3
                    },
                    {
                        "url": "https://github.com/danielgatis/rembg/releases/download/v0.0.0/u2net.onnx",
                        "description": "ONNX í˜•ì‹ (ëŒ€ì•ˆ)",
                        "expected_size_mb": 176.3,
                        "convert_needed": True
                    },
                    {
                        "url": "https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth",
                        "description": "SAM ëª¨ë¸ë¡œ ëŒ€ì²´",
                        "expected_size_mb": 2445.0,
                        "is_alternative": True
                    }
                ],
                "description": "U2-Net ë°°ê²½ ì œê±°/ì„¸ê·¸ë©˜í…Œì´ì…˜ ëª¨ë¸"
            },
            
            # 2. Graphonomy ëŒ€ì²´ ëª¨ë¸ë“¤
            "graphonomy_replacement": {
                "primary_paths": [
                    "ai_models/step_01_human_parsing/graphonomy.pth",
                    "ai_models/checkpoints/step_01_human_parsing/graphonomy.pth"
                ],
                "download_sources": [
                    {
                        "url": "https://huggingface.co/mattmdjaga/segformer_b2_clothes/resolve/main/pytorch_model.bin",
                        "description": "Segformer B2 Clothes (ëŒ€ì²´ ëª¨ë¸)",
                        "expected_size_mb": 85.0
                    },
                    {
                        "url": "https://huggingface.co/chrisjay/fashion-segmentation/resolve/main/pytorch_model.bin",
                        "description": "Fashion Segmentation ëª¨ë¸",
                        "expected_size_mb": 104.0
                    },
                    {
                        "url": "https://github.com/PeikeLi/Self-Correction-Human-Parsing/releases/download/v1.0/exp-schp-201908301523-atr.pth",
                        "description": "Self-Correction Human Parsing",
                        "expected_size_mb": 255.0
                    }
                ],
                "description": "Human Parsing ëª¨ë¸ (Graphonomy ëŒ€ì²´)"
            },
            
            # 3. OpenPose ëª¨ë¸
            "openpose_body": {
                "primary_paths": [
                    "ai_models/step_02_pose_estimation/body_pose_model.pth",
                    "ai_models/step_02_pose_estimation/openpose.pth"
                ],
                "download_sources": [
                    {
                        "url": "https://huggingface.co/lllyasviel/Annotators/resolve/main/body_pose_model.pth",
                        "description": "OpenPose Body Model",
                        "expected_size_mb": 200.0
                    },
                    {
                        "url": "https://github.com/CMU-Perceptual-Computing-Lab/openpose/raw/master/models/pose/body_25/pose_iter_584000.caffemodel",
                        "description": "OpenPose ê³µì‹ ëª¨ë¸",
                        "expected_size_mb": 200.0,
                        "convert_needed": True
                    }
                ],
                "description": "OpenPose ì‹ ì²´ í¬ì¦ˆ ì¶”ì • ëª¨ë¸"
            },
            
            # 4. SAM (Segment Anything) ëª¨ë¸
            "sam_vit_h": {
                "primary_paths": [
                    "ai_models/step_03_cloth_segmentation/sam_vit_h_4b8939.pth",
                    "ai_models/checkpoints/step_03_cloth_segmentation/sam_vit_h_4b8939.pth"
                ],
                "download_sources": [
                    {
                        "url": "https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth",
                        "description": "SAM ViT-H ëª¨ë¸ (Meta ê³µì‹)",
                        "expected_size_mb": 2445.0
                    }
                ],
                "description": "Segment Anything Model (ViT-Huge)"
            },
            
            # 5. CLIP ëª¨ë¸ (ì´ë¯¸ ìˆëŠ” ê²ƒ í™•ì¸ë¨)
            "clip_vit_b32": {
                "primary_paths": [
                    "ai_models/step_08_quality_assessment/clip_vit_b32.pth"
                ],
                "download_sources": [
                    {
                        "url": "https://huggingface.co/openai/clip-vit-base-patch32/resolve/main/pytorch_model.bin",
                        "description": "CLIP ViT-B/32",
                        "expected_size_mb": 338.0
                    }
                ],
                "description": "CLIP ViT-B/32 ëª¨ë¸"
            }
        }

    def check_existing_files(self) -> Dict[str, Dict]:
        """ê¸°ì¡´ íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ ë° ìƒíƒœ ê²€ì‚¬"""
        logger.info("ğŸ” ê¸°ì¡´ AI ëª¨ë¸ íŒŒì¼ ê²€ì¦ ì¤‘...")
        
        file_status = {}
        
        for model_key, model_info in self.working_models.items():
            status = {
                "exists": False,
                "valid_files": [],
                "invalid_files": [],
                "needs_download": True,
                "total_size_mb": 0
            }
            
            # ëª¨ë“  ê°€ëŠ¥í•œ ê²½ë¡œ í™•ì¸
            for path_str in model_info["primary_paths"]:
                path = Path(path_str)
                if path.exists() and path.is_file():
                    size_mb = path.stat().st_size / (1024 * 1024)
                    
                    # í¬ê¸° ê²€ì¦ (ìµœì†Œ 1MB ì´ìƒì´ë©´ ìœ íš¨ë¡œ ê°„ì£¼)
                    if size_mb > 1.0:
                        status["valid_files"].append({
                            "path": str(path),
                            "size_mb": size_mb
                        })
                        status["total_size_mb"] += size_mb
                        status["exists"] = True
                    else:
                        status["invalid_files"].append({
                            "path": str(path),
                            "size_mb": size_mb
                        })
            
            # ìœ íš¨í•œ íŒŒì¼ì´ ìˆìœ¼ë©´ ë‹¤ìš´ë¡œë“œ ë¶ˆí•„ìš”
            if status["valid_files"]:
                status["needs_download"] = False
                logger.info(f"âœ… {model_key}: {len(status['valid_files'])}ê°œ ìœ íš¨í•œ íŒŒì¼ í™•ì¸ ({status['total_size_mb']:.1f}MB)")
            else:
                logger.warning(f"âš ï¸ {model_key}: ë‹¤ìš´ë¡œë“œ í•„ìš”")
            
            file_status[model_key] = status
        
        return file_status

    def download_with_progress(self, url: str, filepath: Path, expected_size_mb: float = None) -> bool:
        """ì§„í–‰ë¥  í‘œì‹œì™€ í•¨ê»˜ ì•ˆì „í•œ íŒŒì¼ ë‹¤ìš´ë¡œë“œ"""
        try:
            # ë””ë ‰í† ë¦¬ ìƒì„±
            filepath.parent.mkdir(parents=True, exist_ok=True)
            
            logger.info(f"ğŸ“¥ ë‹¤ìš´ë¡œë“œ ì‹œì‘: {filepath.name}")
            logger.info(f"ğŸ”— URL: {url}")
            
            # HEAD ìš”ì²­ìœ¼ë¡œ íŒŒì¼ ì¡´ì¬ í™•ì¸
            try:
                head_response = requests.head(url, allow_redirects=True, timeout=10)
                if head_response.status_code != 200:
                    logger.warning(f"âš ï¸ HEAD ìš”ì²­ ì‹¤íŒ¨: {head_response.status_code}")
            except Exception:
                logger.warning("âš ï¸ HEAD ìš”ì²­ ê±´ë„ˆë›°ê³  ì§ì ‘ ë‹¤ìš´ë¡œë“œ ì‹œë„")
            
            # ìŠ¤íŠ¸ë¦¬ë° ë‹¤ìš´ë¡œë“œ
            response = requests.get(url, stream=True, allow_redirects=True, timeout=30)
            response.raise_for_status()
            
            total_size = int(response.headers.get('content-length', 0))
            
            with open(filepath, 'wb') as f:
                with tqdm(
                    total=total_size,
                    unit='B',
                    unit_scale=True,
                    desc=f"â¬‡ï¸ {filepath.name}",
                    ascii=True
                ) as pbar:
                    for chunk in response.iter_content(chunk_size=8192):
                        if chunk:
                            f.write(chunk)
                            pbar.update(len(chunk))
            
            # ë‹¤ìš´ë¡œë“œ ì™„ë£Œ í›„ ê²€ì¦
            if filepath.exists():
                actual_size_mb = filepath.stat().st_size / (1024 * 1024)
                if actual_size_mb > 1.0:  # ìµœì†Œ 1MB
                    logger.info(f"âœ… ë‹¤ìš´ë¡œë“œ ì„±ê³µ: {filepath.name} ({actual_size_mb:.1f}MB)")
                    return True
                else:
                    logger.error(f"âŒ ë‹¤ìš´ë¡œë“œëœ íŒŒì¼ì´ ë„ˆë¬´ ì‘ìŒ: {actual_size_mb:.1f}MB")
                    filepath.unlink()
                    return False
            
            return False
            
        except Exception as e:
            logger.error(f"âŒ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
            if filepath.exists():
                filepath.unlink()
            return False

    def download_missing_models(self, file_status: Dict) -> Dict[str, bool]:
        """ëˆ„ë½ëœ ëª¨ë¸ë“¤ì„ ì‹¤ì œ ì‘ë™í•˜ëŠ” ë§í¬ë¡œ ë‹¤ìš´ë¡œë“œ"""
        logger.info("ğŸš€ ëˆ„ë½ëœ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹œì‘ (ê²€ì¦ëœ ë§í¬ ì‚¬ìš©)")
        logger.info("=" * 60)
        
        results = {}
        
        for model_key, status in file_status.items():
            if not status["needs_download"]:
                logger.info(f"â­ï¸ {model_key}: ì´ë¯¸ ìœ íš¨í•œ íŒŒì¼ ì¡´ì¬")
                results[model_key] = True
                continue
            
            model_info = self.working_models[model_key]
            logger.info(f"\nğŸ“¦ ì²˜ë¦¬ ì¤‘: {model_key}")
            logger.info(f"ğŸ“ ì„¤ëª…: {model_info['description']}")
            
            # ë‹¤ìš´ë¡œë“œ ì†ŒìŠ¤ë“¤ì„ ìˆœì„œëŒ€ë¡œ ì‹œë„
            success = False
            for i, source in enumerate(model_info["download_sources"]):
                logger.info(f"ğŸ”„ ì†ŒìŠ¤ {i+1}/{len(model_info['download_sources'])} ì‹œë„: {source['description']}")
                
                # ëŒ€ìš©ëŸ‰ íŒŒì¼ í™•ì¸
                if source["expected_size_mb"] > 500:  # 500MB ì´ìƒ
                    user_input = input(f"ğŸ“¦ {source['description']} ({source['expected_size_mb']:.1f}MB) ë‹¤ìš´ë¡œë“œí•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/N): ")
                    if not user_input.lower().startswith('y'):
                        logger.info(f"â­ï¸ ì‚¬ìš©ìê°€ {source['description']} ë‹¤ìš´ë¡œë“œ ê±´ë„ˆëœ€")
                        continue
                
                # ì²« ë²ˆì§¸ ê²½ë¡œì— ë‹¤ìš´ë¡œë“œ ì‹œë„
                target_path = Path(model_info["primary_paths"][0])
                
                success = self.download_with_progress(
                    source["url"],
                    target_path,
                    source["expected_size_mb"]
                )
                
                if success:
                    # ë‹¤ë¥¸ ê²½ë¡œì—ë„ ë³µì‚¬
                    for path_str in model_info["primary_paths"][1:]:
                        alt_path = Path(path_str)
                        alt_path.parent.mkdir(parents=True, exist_ok=True)
                        try:
                            shutil.copy2(target_path, alt_path)
                            logger.info(f"ğŸ“‹ ë³µì‚¬ ì™„ë£Œ: {alt_path}")
                        except Exception as e:
                            logger.warning(f"âš ï¸ ë³µì‚¬ ì‹¤íŒ¨: {alt_path} - {e}")
                    
                    logger.info(f"âœ… {model_key} ë‹¤ìš´ë¡œë“œ ì„±ê³µ: {source['description']}")
                    break
                else:
                    logger.warning(f"âŒ {source['description']} ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨")
            
            results[model_key] = success
            
            if not success:
                logger.error(f"âŒ {model_key}: ëª¨ë“  ì†ŒìŠ¤ì—ì„œ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨")
        
        return results

    def use_existing_alternatives(self) -> Dict[str, bool]:
        """ê¸°ì¡´ì— ìˆëŠ” ìœ ì‚¬í•œ ëª¨ë¸ë“¤ì„ ëŒ€ì•ˆìœ¼ë¡œ í™œìš©"""
        logger.info("ğŸ”„ ê¸°ì¡´ ëª¨ë¸ë“¤ì„ ëŒ€ì•ˆìœ¼ë¡œ í™œìš© ì¤‘...")
        
        alternatives_used = {}
        
        # 1. U2-Net ëŒ€ì‹  SAM ëª¨ë¸ í™œìš©
        u2net_paths = [
            "ai_models/u2net.pth",
            "ai_models/checkpoints/step_03_cloth_segmentation/u2net.pth"
        ]
        
        sam_candidates = [
            "ai_models/step_03_cloth_segmentation/sam_vit_h_4b8939.pth",
            "ai_models/checkpoints/step_03_cloth_segmentation/sam_vit_h_4b8939.pth"
        ]
        
        # SAM ëª¨ë¸ì´ ìˆìœ¼ë©´ U2-Net ê²½ë¡œì— ë³µì‚¬
        for sam_path_str in sam_candidates:
            sam_path = Path(sam_path_str)
            if sam_path.exists() and sam_path.stat().st_size > 1024**3:  # 1GB ì´ìƒ
                logger.info(f"ğŸ”„ SAM ëª¨ë¸ì„ U2-Net ëŒ€ì•ˆìœ¼ë¡œ ì‚¬ìš©: {sam_path}")
                
                for u2net_path_str in u2net_paths:
                    u2net_path = Path(u2net_path_str)
                    if not u2net_path.exists():
                        u2net_path.parent.mkdir(parents=True, exist_ok=True)
                        try:
                            shutil.copy2(sam_path, u2net_path)
                            logger.info(f"âœ… SAMì„ U2-Netìœ¼ë¡œ ë³µì‚¬: {u2net_path}")
                            alternatives_used["u2net_from_sam"] = True
                        except Exception as e:
                            logger.warning(f"âš ï¸ ë³µì‚¬ ì‹¤íŒ¨: {e}")
                break
        
        # 2. ê¸°ì¡´ Human Parsing ëª¨ë¸ë“¤ í™œìš©
        existing_parsing_models = [
            "ai_models/Self-Correction-Human-Parsing/exp-schp-201908301523-atr.pth",
            "ai_models/step_01_human_parsing/exp-schp-201908301523-atr.pth",
            "ai_models/step_01_human_parsing/atr_model.pth"
        ]
        
        target_parsing_paths = [
            "ai_models/step_01_human_parsing/graphonomy.pth",
            "ai_models/checkpoints/step_01_human_parsing/graphonomy.pth"
        ]
        
        for existing_path_str in existing_parsing_models:
            existing_path = Path(existing_path_str)
            if existing_path.exists() and existing_path.stat().st_size > 50*1024*1024:  # 50MB ì´ìƒ
                logger.info(f"ğŸ”„ ê¸°ì¡´ Human Parsing ëª¨ë¸ í™œìš©: {existing_path}")
                
                for target_path_str in target_parsing_paths:
                    target_path = Path(target_path_str)
                    if not target_path.exists():
                        target_path.parent.mkdir(parents=True, exist_ok=True)
                        try:
                            shutil.copy2(existing_path, target_path)
                            logger.info(f"âœ… Human Parsing ëª¨ë¸ ë³µì‚¬: {target_path}")
                            alternatives_used["graphonomy_from_existing"] = True
                        except Exception as e:
                            logger.warning(f"âš ï¸ ë³µì‚¬ ì‹¤íŒ¨: {e}")
                break
        
        return alternatives_used

    def generate_final_report(self, file_status: Dict, download_results: Dict, alternatives_used: Dict) -> None:
        """ìµœì¢… ë³´ê³ ì„œ ìƒì„±"""
        logger.info("\n" + "=" * 80)
        logger.info("ğŸ“Š MyCloset AI ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ìµœì¢… ë³´ê³ ì„œ")
        logger.info("=" * 80)
        
        # í†µê³„ ê³„ì‚°
        total_models = len(file_status)
        existing_valid = sum(1 for status in file_status.values() if not status["needs_download"])
        download_success = sum(1 for result in download_results.values() if result)
        alternatives_count = len(alternatives_used)
        
        logger.info(f"ğŸ“Š ì „ì²´ ëª¨ë¸: {total_models}ê°œ")
        logger.info(f"âœ… ê¸°ì¡´ ìœ íš¨: {existing_valid}ê°œ")
        logger.info(f"ğŸ“¥ ë‹¤ìš´ë¡œë“œ ì„±ê³µ: {download_success}ê°œ")
        logger.info(f"ğŸ”„ ëŒ€ì•ˆ í™œìš©: {alternatives_count}ê°œ")
        
        # ì„±ê³µí•œ ëª¨ë¸ë“¤
        if existing_valid > 0:
            logger.info("\nâœ… ê¸°ì¡´ ìœ íš¨í•œ ëª¨ë¸ë“¤:")
            for model_key, status in file_status.items():
                if not status["needs_download"]:
                    for file_info in status["valid_files"]:
                        logger.info(f"  - {model_key}: {file_info['path']} ({file_info['size_mb']:.1f}MB)")
        
        # ë‹¤ìš´ë¡œë“œëœ ëª¨ë¸ë“¤
        if download_success > 0:
            logger.info("\nğŸ“¥ ë‹¤ìš´ë¡œë“œëœ ëª¨ë¸ë“¤:")
            for model_key, success in download_results.items():
                if success:
                    model_info = self.working_models[model_key]
                    logger.info(f"  - {model_key}: {model_info['primary_paths'][0]}")
        
        # ëŒ€ì•ˆ í™œìš©
        if alternatives_count > 0:
            logger.info("\nğŸ”„ ëŒ€ì•ˆìœ¼ë¡œ í™œìš©ëœ ëª¨ë¸ë“¤:")
            for alt_key, success in alternatives_used.items():
                if success:
                    logger.info(f"  - {alt_key}: ê¸°ì¡´ ëª¨ë¸ì„ ëŒ€ì•ˆìœ¼ë¡œ í™œìš©")
        
        # ë‹¤ìŒ ë‹¨ê³„ ì•ˆë‚´
        total_resolved = existing_valid + download_success + alternatives_count
        logger.info(f"\nğŸ“‹ í•´ê²°ëœ ëª¨ë¸: {total_resolved}/{total_models}")
        
        if total_resolved >= total_models * 0.8:  # 80% ì´ìƒ
            logger.info("ğŸ‰ í•„ìˆ˜ ëª¨ë¸ë“¤ì´ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤!")
            logger.info("â–¶ï¸ python enhanced_model_loading_validator.py ì‹¤í–‰í•˜ì—¬ ì¬ê²€ì¦í•˜ì„¸ìš”.")
        else:
            logger.info("âš ï¸ ì¼ë¶€ ëª¨ë¸ì´ ì—¬ì „íˆ ëˆ„ë½ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
            logger.info("ğŸ“– ìˆ˜ë™ìœ¼ë¡œ ëª¨ë¸ì„ êµ¬í•˜ê±°ë‚˜ ëŒ€ì•ˆ ëª¨ë¸ì„ ì°¾ì•„ë³´ì„¸ìš”.")

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸ”¥ MyCloset AI ìœ íš¨í•œ ë§í¬ ê¸°ë°˜ ëª¨ë¸ ë‹¤ìš´ë¡œë” v4.0")
    print("=" * 60)
    
    downloader = WorkingModelDownloader("ai_models")
    
    try:
        # 1. ê¸°ì¡´ íŒŒì¼ ê²€ì¦
        file_status = downloader.check_existing_files()
        
        # 2. ê¸°ì¡´ ëª¨ë¸ë“¤ì„ ëŒ€ì•ˆìœ¼ë¡œ í™œìš©
        alternatives_used = downloader.use_existing_alternatives()
        
        # 3. ì—¬ì „íˆ ëˆ„ë½ëœ ëª¨ë¸ë“¤ ë‹¤ìš´ë¡œë“œ
        download_results = downloader.download_missing_models(file_status)
        
        # 4. ìµœì¢… ë³´ê³ ì„œ
        downloader.generate_final_report(file_status, download_results, alternatives_used)
        
        return True
        
    except KeyboardInterrupt:
        print("\nâš ï¸ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë¨")
        return False
    except Exception as e:
        logger.error(f"âŒ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)