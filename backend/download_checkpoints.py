#!/usr/bin/env python3
"""
Conda í™˜ê²½ìš© ì‹¤ì œ AI ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ ë‹¤ìš´ë¡œë” (ìµœì¢… ë²„ì „)
í´ë°± ëª¨ë¸ ì—†ìŒ - ê²€ì¦ëœ ì‹¤ì œ ëª¨ë¸ë“¤ë§Œ ë‹¤ìš´ë¡œë“œ

ì‚¬ìš©ë²•:
    cd backend
    conda activate mycloset-ai
    python download_real_models_conda.py
"""

import os
import sys
import logging
import time
import subprocess
from pathlib import Path
from typing import Dict, List, Optional, Tuple
import requests
from tqdm import tqdm
import json

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s | %(levelname)s | %(message)s',
    datefmt='%H:%M:%S'
)
logger = logging.getLogger(__name__)

class CondaRealModelDownloader:
    """Conda í™˜ê²½ìš© ì‹¤ì œ AI ëª¨ë¸ ë‹¤ìš´ë¡œë” (í´ë°± ì—†ìŒ)"""
    
    def __init__(self):
        # í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ìë™ ê°ì§€
        current_path = Path(__file__).parent
        if current_path.name == "scripts":
            self.project_root = current_path.parent
        else:
            self.project_root = current_path
            
        # AI ëª¨ë¸ ì €ì¥ ê²½ë¡œë¥¼ ê¸°ì¡´ MyCloset AI êµ¬ì¡°ì— ë§ì¶¤
        self.models_dir = self.project_root / "ai_models"
        self.checkpoints_dir = self.models_dir / "checkpoints"
        
        # ë””ë ‰í† ë¦¬ ìƒì„±
        self.checkpoints_dir.mkdir(parents=True, exist_ok=True)
        
        # ì‹¤ì œ ê²€ì¦ëœ ëª¨ë¸ë“¤ë§Œ (100% ë™ì‘ ë³´ì¥)
        self.real_models = {
            "ootdiffusion": {
                "name": "OOTDiffusion",
                "description": "ìµœì‹  ì‹¤ì œ ê°€ìƒ í”¼íŒ… ëª¨ë¸",
                "method": "huggingface_git",
                "repo_id": "levihsu/OOTDiffusion",
                "local_dir": "ootdiffusion_hf",
                "size_gb": 8.5,
                "priority": 1,
                "verified": True,
                "essential_files": ["checkpoints", "configs"]
            },
            "human_parsing_atr": {
                "name": "ATR Human Parsing",
                "description": "ì‹¤ì œ ì¸ì²´ ë¶„í•  ëª¨ë¸ (ATR ë°ì´í„°ì…‹)",
                "method": "direct_download",
                "urls": [
                    "https://github.com/PeikeLi/Self-Correction-Human-Parsing/releases/download/checkpoints/exp-schp-201908301523-atr.pth"
                ],
                "backup_urls": [
                    "https://huggingface.co/mattmdjaga/human_parsing/resolve/main/exp-schp-201908301523-atr.pth",
                    "https://drive.google.com/uc?id=1k4dllHpu0bdx38J7H28rVVLpU-kOHmnH&confirm=t"
                ],
                "local_dir": "human_parsing",
                "filename": "exp-schp-201908301523-atr.pth",
                "size_gb": 0.178,
                "priority": 2,
                "verified": True
            },
            "u2net_portrait": {
                "name": "U2Net Portrait Segmentation",
                "description": "ì‹¤ì œ ë°°ê²½ ì œê±° ëª¨ë¸",
                "method": "direct_download",
                "urls": [
                    "https://github.com/xuebinqin/U-2-Net/releases/download/v1.0/u2net_portrait.pth"
                ],
                "backup_urls": [
                    "https://drive.google.com/uc?id=1ao1ovG1Qtx4b7EoskHXmi2E9rp5CHLcZ&confirm=t"
                ],
                "local_dir": "u2net",
                "filename": "u2net_portrait.pth",
                "size_gb": 0.176,
                "priority": 3,
                "verified": True
            },
            "mediapipe_pose": {
                "name": "MediaPipe Pose Landmarker",
                "description": "Google ê³µì‹ í¬ì¦ˆ ì¶”ì • ëª¨ë¸",
                "method": "direct_download",
                "urls": [
                    "https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_heavy/float16/1/pose_landmarker_heavy.task"
                ],
                "local_dir": "mediapipe",
                "filename": "pose_landmarker_heavy.task",
                "size_gb": 0.029,
                "priority": 4,
                "verified": True
            },
            "segment_anything": {
                "name": "Segment Anything Model (SAM)",
                "description": "Meta ê³µì‹ ì„¸ê·¸ë©˜í…Œì´ì…˜ ëª¨ë¸",
                "method": "direct_download",
                "urls": [
                    "https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth"
                ],
                "local_dir": "sam",
                "filename": "sam_vit_h_4b8939.pth",
                "size_gb": 2.56,
                "priority": 5,
                "verified": True
            },
            "stable_diffusion_inpaint": {
                "name": "Stable Diffusion Inpainting",
                "description": "ì‹¤ì œ ì´ë¯¸ì§€ ì¸í˜ì¸íŒ… ëª¨ë¸",
                "method": "huggingface_download",
                "repo_id": "runwayml/stable-diffusion-inpainting",
                "local_dir": "stable_diffusion_inpaint",
                "size_gb": 5.21,
                "priority": 6,
                "verified": True,
                "essential_files": ["unet", "vae", "text_encoder", "safety_checker"]
            }
        }
    
    def check_conda_environment(self) -> bool:
        """Conda í™˜ê²½ í™•ì¸"""
        logger.info("ğŸ Conda í™˜ê²½ í™•ì¸ ì¤‘...")
        
        conda_env = os.environ.get('CONDA_DEFAULT_ENV')
        if not conda_env:
            logger.error("âŒ Conda í™˜ê²½ì´ í™œì„±í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            logger.info("ğŸ’¡ ì‹¤í–‰: conda activate mycloset-ai")
            return False
        
        logger.info(f"âœ… í˜„ì¬ Conda í™˜ê²½: {conda_env}")
        
        # Python ê²½ë¡œ í™•ì¸
        python_path = sys.executable
        if "conda" in python_path.lower() or "miniforge" in python_path.lower():
            logger.info(f"âœ… Python ê²½ë¡œ: {python_path}")
        else:
            logger.warning(f"âš ï¸ Python ê²½ë¡œê°€ Conda í™˜ê²½ì´ ì•„ë‹ ìˆ˜ ìˆìŠµë‹ˆë‹¤: {python_path}")
        
        return True
    
    def install_conda_dependencies(self) -> bool:
        """Conda í™˜ê²½ì—ì„œ í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜"""
        logger.info("ğŸ“¦ Conda í™˜ê²½ì—ì„œ í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì¤‘...")
        
        # Condaë¡œ ì„¤ì¹˜í•  íŒ¨í‚¤ì§€ë“¤
        conda_packages = [
            ("git", "conda-forge"),
            ("git-lfs", "conda-forge"),
            ("curl", "conda-forge"),
            ("wget", "conda-forge")
        ]
        
        # Pipë¡œ ì„¤ì¹˜í•  íŒ¨í‚¤ì§€ë“¤
        pip_packages = [
            "huggingface_hub",
            "gdown>=4.7.1",
            "requests>=2.28.0",
            "tqdm>=4.64.0"
        ]
        
        # Conda íŒ¨í‚¤ì§€ ì„¤ì¹˜
        for package, channel in conda_packages:
            try:
                subprocess.run([
                    "conda", "install", "-c", channel, package, "-y", "--quiet"
                ], check=True, capture_output=True, text=True)
                logger.info(f"âœ… {package}: Condaë¡œ ì„¤ì¹˜ ì™„ë£Œ")
            except subprocess.CalledProcessError as e:
                logger.warning(f"âš ï¸ {package}: Conda ì„¤ì¹˜ ì‹¤íŒ¨, ì‹œìŠ¤í…œ ë²„ì „ ì‚¬ìš©")
        
        # Pip íŒ¨í‚¤ì§€ ì„¤ì¹˜
        for package in pip_packages:
            try:
                # ì´ë¯¸ ì„¤ì¹˜ëœì§€ í™•ì¸
                pkg_name = package.split(">=")[0].split("==")[0].replace("-", "_")
                __import__(pkg_name)
                logger.info(f"âœ… {package}: ì´ë¯¸ ì„¤ì¹˜ë¨")
            except ImportError:
                try:
                    subprocess.run([
                        sys.executable, "-m", "pip", "install", package, "--quiet"
                    ], check=True, capture_output=True)
                    logger.info(f"âœ… {package}: pipë¡œ ì„¤ì¹˜ ì™„ë£Œ")
                except subprocess.CalledProcessError as e:
                    logger.error(f"âŒ {package}: ì„¤ì¹˜ ì‹¤íŒ¨ - {e}")
                    return False
        
        # Git LFS ì´ˆê¸°í™”
        try:
            subprocess.run(["git", "lfs", "install"], check=True, capture_output=True)
            logger.info("âœ… Git LFS ì´ˆê¸°í™” ì™„ë£Œ")
        except subprocess.CalledProcessError:
            logger.warning("âš ï¸ Git LFS ì´ˆê¸°í™” ì‹¤íŒ¨ (ì„ íƒì‚¬í•­)")
        
        return True
    
    def download_with_progress(self, url: str, filepath: Path, retries: int = 3) -> bool:
        """ì§„í–‰ë¥ ê³¼ ì¬ì‹œë„ ê¸°ëŠ¥ì´ ìˆëŠ” ë‹¤ìš´ë¡œë“œ"""
        for attempt in range(retries):
            try:
                # í—¤ë” ì„¤ì • (ì¼ë¶€ ì„œë²„ì—ì„œ User-Agent í•„ìš”)
                headers = {
                    'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36'
                }
                
                response = requests.get(url, stream=True, headers=headers, timeout=30)
                response.raise_for_status()
                
                total_size = int(response.headers.get('content-length', 0))
                
                # ì„ì‹œ íŒŒì¼ì— ë‹¤ìš´ë¡œë“œ
                temp_filepath = filepath.with_suffix(filepath.suffix + '.tmp')
                
                with open(temp_filepath, 'wb') as f, tqdm(
                    desc=f"ğŸ“¥ {filepath.name}",
                    total=total_size,
                    unit='B',
                    unit_scale=True,
                    unit_divisor=1024,
                ) as pbar:
                    for chunk in response.iter_content(chunk_size=8192):
                        if chunk:
                            f.write(chunk)
                            pbar.update(len(chunk))
                
                # ë‹¤ìš´ë¡œë“œ ì™„ë£Œ ì‹œ ì„ì‹œ íŒŒì¼ì„ ìµœì¢… íŒŒì¼ë¡œ ì´ë™
                temp_filepath.rename(filepath)
                return True
                
            except Exception as e:
                logger.warning(f"âš ï¸ ë‹¤ìš´ë¡œë“œ ì‹œë„ {attempt + 1}/{retries} ì‹¤íŒ¨: {e}")
                if attempt < retries - 1:
                    time.sleep(2 ** attempt)  # ì§€ìˆ˜ ë°±ì˜¤í”„
                    continue
                else:
                    logger.error(f"âŒ ëª¨ë“  ë‹¤ìš´ë¡œë“œ ì‹œë„ ì‹¤íŒ¨: {url}")
                    return False
        
        return False
    
    def download_huggingface_model(self, model_info: Dict) -> bool:
        """Hugging Faceì—ì„œ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ"""
        try:
            from huggingface_hub import snapshot_download
            
            local_path = self.checkpoints_dir / model_info["local_dir"]
            repo_id = model_info["repo_id"]
            
            # ì´ë¯¸ ì¡´ì¬í•˜ê³  íŒŒì¼ì´ ìˆìœ¼ë©´ ìŠ¤í‚µ
            if local_path.exists() and any(local_path.iterdir()):
                logger.info(f"âœ… {model_info['name']} ì´ë¯¸ ì¡´ì¬í•¨")
                return True
            
            logger.info(f"ğŸ“¥ {model_info['name']} ë‹¤ìš´ë¡œë“œ ì‹œì‘...")
            logger.info(f"   ì €ì¥ì†Œ: {repo_id}")
            logger.info(f"   í¬ê¸°: ~{model_info['size_gb']:.1f}GB")
            
            # ë‹¤ìš´ë¡œë“œ ì‹œì‘ ì‹œê°„ ê¸°ë¡
            start_time = time.time()
            
            # Hugging Faceì—ì„œ ë‹¤ìš´ë¡œë“œ
            snapshot_download(
                repo_id=repo_id,
                local_dir=str(local_path),
                resume_download=True,
                local_dir_use_symlinks=False,
                # Git LFS íŒŒì¼ë„ í¬í•¨
                force_download=False,
                # ì§„í–‰ë¥  í‘œì‹œ
                tqdm_class=tqdm
            )
            
            end_time = time.time()
            duration = end_time - start_time
            
            logger.info(f"âœ… {model_info['name']} ë‹¤ìš´ë¡œë“œ ì™„ë£Œ! ({duration/60:.1f}ë¶„)")
            return True
            
        except Exception as e:
            logger.error(f"âŒ {model_info['name']} Hugging Face ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
            return False
    
    def download_huggingface_git(self, model_info: Dict) -> bool:
        """Git LFSë¡œ Hugging Face ì €ì¥ì†Œ í´ë¡ """
        try:
            local_path = self.checkpoints_dir / model_info["local_dir"]
            repo_id = model_info["repo_id"]
            repo_url = f"https://huggingface.co/{repo_id}"
            
            # ì´ë¯¸ ì¡´ì¬í•˜ê³  íŒŒì¼ì´ ìˆìœ¼ë©´ ìŠ¤í‚µ
            if local_path.exists() and any(local_path.iterdir()):
                logger.info(f"âœ… {model_info['name']} ì´ë¯¸ ì¡´ì¬í•¨")
                return True
            
            logger.info(f"ğŸ“¥ {model_info['name']} Git í´ë¡  ì‹œì‘...")
            logger.info(f"   ì €ì¥ì†Œ: {repo_url}")
            logger.info(f"   í¬ê¸°: ~{model_info['size_gb']:.1f}GB")
            
            start_time = time.time()
            
            # Git í´ë¡  (shallow cloneìœ¼ë¡œ ì†ë„ í–¥ìƒ)
            subprocess.run([
                "git", "clone", "--depth=1", "--single-branch", repo_url, str(local_path)
            ], check=True, capture_output=True, text=True)
            
            # LFS íŒŒì¼ ë‹¤ìš´ë¡œë“œ
            subprocess.run([
                "git", "lfs", "pull"
            ], cwd=str(local_path), check=True, capture_output=True, text=True)
            
            end_time = time.time()
            duration = end_time - start_time
            
            logger.info(f"âœ… {model_info['name']} Git í´ë¡  ì™„ë£Œ! ({duration/60:.1f}ë¶„)")
            return True
            
        except subprocess.CalledProcessError as e:
            logger.error(f"âŒ {model_info['name']} Git í´ë¡  ì‹¤íŒ¨: {e}")
            return False
    
    def download_direct_model(self, model_info: Dict) -> bool:
        """ì§ì ‘ URLì—ì„œ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ (ì—¬ëŸ¬ ë°±ì—… URL ì§€ì›)"""
        local_path = self.checkpoints_dir / model_info["local_dir"]
        local_path.mkdir(parents=True, exist_ok=True)
        
        filepath = local_path / model_info["filename"]
        
        # ì´ë¯¸ ì¡´ì¬í•˜ê³  í¬ê¸°ê°€ 1MB ì´ìƒì´ë©´ ìŠ¤í‚µ
        if filepath.exists() and filepath.stat().st_size > 1024 * 1024:
            logger.info(f"âœ… {model_info['name']} ì´ë¯¸ ì¡´ì¬í•¨")
            return True
        
        logger.info(f"ğŸ“¥ {model_info['name']} ë‹¤ìš´ë¡œë“œ ì‹œì‘...")
        logger.info(f"   í¬ê¸°: ~{model_info['size_gb']:.3f}GB")
        
        # ëª¨ë“  URL ì‹œë„ (ê¸°ë³¸ URL + ë°±ì—… URL)
        all_urls = model_info["urls"]
        if "backup_urls" in model_info:
            all_urls.extend(model_info["backup_urls"])
        
        for i, url in enumerate(all_urls, 1):
            logger.info(f"ğŸ”— ì‹œë„ {i}/{len(all_urls)}: {url[:50]}...")
            
            # Google Drive íŠ¹ë³„ ì²˜ë¦¬
            if "google.com" in url or "drive.google.com" in url:
                try:
                    import gdown
                    success = gdown.download(url, str(filepath), quiet=False)
                    if success and filepath.exists() and filepath.stat().st_size > 1024:
                        logger.info(f"âœ… {model_info['name']} Google Drive ë‹¤ìš´ë¡œë“œ ì™„ë£Œ!")
                        return True
                except Exception as e:
                    logger.warning(f"âš ï¸ Google Drive ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
                    continue
            else:
                # ì¼ë°˜ HTTP ë‹¤ìš´ë¡œë“œ
                if self.download_with_progress(url, filepath):
                    if filepath.exists() and filepath.stat().st_size > 1024:
                        logger.info(f"âœ… {model_info['name']} ë‹¤ìš´ë¡œë“œ ì™„ë£Œ!")
                        return True
                
                # ì‹¤íŒ¨ ì‹œ ì„ì‹œ íŒŒì¼ ì‚­ì œ
                if filepath.exists():
                    filepath.unlink()
        
        logger.error(f"âŒ {model_info['name']} ëª¨ë“  URL ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨")
        return False
    
    def verify_model(self, model_key: str, model_info: Dict) -> Tuple[bool, float]:
        """ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ê²€ì¦"""
        local_path = self.checkpoints_dir / model_info["local_dir"]
        
        if not local_path.exists():
            return False, 0.0
        
        # ì´ íŒŒì¼ í¬ê¸° ê³„ì‚°
        total_size = 0
        file_count = 0
        
        for file_path in local_path.rglob("*"):
            if file_path.is_file():
                total_size += file_path.stat().st_size
                file_count += 1
        
        size_gb = total_size / (1024**3)
        
        # ê²€ì¦ ê¸°ì¤€ (ë” ì—„ê²©í•˜ê²Œ)
        expected_size = model_info["size_gb"]
        min_size = max(expected_size * 0.8, 0.001)  # ìµœì†Œ 80% ë˜ëŠ” 1MB
        
        # í•„ìˆ˜ íŒŒì¼ í™•ì¸ (ìˆëŠ” ê²½ìš°)
        essential_files_found = True
        if "essential_files" in model_info:
            for pattern in model_info["essential_files"]:
                if not list(local_path.glob(f"**/{pattern}*")):
                    essential_files_found = False
                    break
        
        if size_gb >= min_size and file_count > 0 and essential_files_found:
            return True, size_gb
        else:
            return False, size_gb
    
    def show_model_selection(self) -> List[str]:
        """ëª¨ë¸ ì„ íƒ ë©”ë‰´ í‘œì‹œ"""
        print("\nğŸ¤– Conda í™˜ê²½ ì‹¤ì œ AI ëª¨ë¸ ë‹¤ìš´ë¡œë“œ")
        print("=" * 60)
        print("âœ… í´ë°± ì—†ìŒ - ê²€ì¦ëœ ì‹¤ì œ ëª¨ë¸ë§Œ ë‹¤ìš´ë¡œë“œ")
        print("=" * 60)
        
        print("\nğŸ“‹ ê²€ì¦ëœ ì‹¤ì œ ëª¨ë¸ë“¤:")
        for i, (key, info) in enumerate(self.real_models.items(), 1):
            local_path = self.checkpoints_dir / info["local_dir"]
            verified, actual_size = self.verify_model(key, info)
            
            if verified:
                status = f"âœ… ë‹¤ìš´ë¡œë“œë¨ ({actual_size:.1f}GB)"
            else:
                status = "âŒ í•„ìš”"
            
            print(f"{i}. {info['name']} ({info['size_gb']:.1f}GB) - {status}")
            print(f"   {info['description']}")
        
        total_size = sum(info["size_gb"] for info in self.real_models.values())
        print(f"\nğŸ“Š ì „ì²´ í¬ê¸°: {total_size:.1f}GB")
        print(f"ğŸ“ ì €ì¥ ìœ„ì¹˜: {self.checkpoints_dir}")
        
        print("\nğŸ¯ ì¶”ì²œ ì„ íƒ:")
        print("  í•„ìˆ˜ (8.9GB): 1,2,3,4 (OOTDiffusion + Human Parsing + U2Net + MediaPipe)")
        print("  í‘œì¤€ (11.5GB): 1,2,3,4,5 (+ Segment Anything)")
        print("  ì™„ì „ (16.7GB): all (ëª¨ë“  ëª¨ë¸)")
        
        selection = input("\në‹¤ìš´ë¡œë“œí•  ëª¨ë¸ ë²ˆí˜¸ (ì‰¼í‘œë¡œ êµ¬ë¶„, ì˜ˆ: 1,2,3,4): ").strip()
        
        if not selection:
            return []
        
        if selection.lower() == 'all':
            return list(self.real_models.keys())
        
        try:
            indices = [int(x.strip()) for x in selection.split(',') if x.strip()]
            model_keys = []
            for i in indices:
                if 1 <= i <= len(self.real_models):
                    model_keys.append(list(self.real_models.keys())[i-1])
            return model_keys
        except (ValueError, IndexError):
            logger.error("âŒ ì˜ëª»ëœ ì„ íƒì…ë‹ˆë‹¤.")
            return []
    
    def download_selected_models(self, model_keys: List[str]) -> Dict[str, bool]:
        """ì„ íƒëœ ëª¨ë¸ë“¤ ë‹¤ìš´ë¡œë“œ"""
        if not model_keys:
            logger.error("âŒ ì„ íƒëœ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")
            return {}
        
        results = {}
        total_size = sum(self.real_models[k]["size_gb"] for k in model_keys)
        
        print(f"\nğŸ“Š ë‹¤ìš´ë¡œë“œ ê³„íš:")
        print(f"   ëª¨ë¸ ìˆ˜: {len(model_keys)}ê°œ")
        print(f"   ì´ í¬ê¸°: {total_size:.1f}GB")
        print(f"   ì˜ˆìƒ ì‹œê°„: {total_size * 1.5:.0f}ë¶„ (100Mbps ê¸°ì¤€)")
        
        confirm = input("\nì‹¤ì œ ëª¨ë¸ë“¤ì„ ë‹¤ìš´ë¡œë“œí•˜ì‹œê² ìŠµë‹ˆê¹Œ? [y/N]: ").strip().lower()
        if confirm not in ['y', 'yes']:
            logger.info("âŒ ë‹¤ìš´ë¡œë“œ ì·¨ì†Œë¨")
            return {}
        
        print("\nğŸš€ ì‹¤ì œ AI ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹œì‘!")
        print("=" * 60)
        
        # ìš°ì„ ìˆœìœ„ ìˆœìœ¼ë¡œ ì •ë ¬
        sorted_models = sorted(
            [(k, self.real_models[k]) for k in model_keys],
            key=lambda x: x[1]["priority"]
        )
        
        total_start_time = time.time()
        
        for i, (model_key, model_info) in enumerate(sorted_models, 1):
            print(f"\n[{i}/{len(sorted_models)}] {model_info['name']}")
            print(f"ğŸ“‹ {model_info['description']}")
            
            try:
                start_time = time.time()
                
                # ë‹¤ìš´ë¡œë“œ ë°©ë²•ì— ë”°ë¼ ë¶„ê¸°
                if model_info["method"] == "huggingface_download":
                    success = self.download_huggingface_model(model_info)
                elif model_info["method"] == "huggingface_git":
                    success = self.download_huggingface_git(model_info)
                elif model_info["method"] == "direct_download":
                    success = self.download_direct_model(model_info)
                else:
                    logger.error(f"âŒ ì§€ì›í•˜ì§€ ì•ŠëŠ” ë‹¤ìš´ë¡œë“œ ë°©ë²•: {model_info['method']}")
                    success = False
                
                end_time = time.time()
                duration = end_time - start_time
                
                if success:
                    # ê²€ì¦
                    verified, actual_size = self.verify_model(model_key, model_info)
                    if verified:
                        logger.info(f"ğŸ‰ {model_info['name']} ê²€ì¦ ì™„ë£Œ! ({duration/60:.1f}ë¶„, {actual_size:.1f}GB)")
                        results[model_key] = True
                    else:
                        logger.error(f"âŒ {model_info['name']} ê²€ì¦ ì‹¤íŒ¨ ({actual_size:.1f}GB)")
                        results[model_key] = False
                else:
                    results[model_key] = False
                    
            except KeyboardInterrupt:
                logger.info("\nâ¹ ì‚¬ìš©ìê°€ ë‹¤ìš´ë¡œë“œë¥¼ ì¤‘ë‹¨í–ˆìŠµë‹ˆë‹¤")
                break
            except Exception as e:
                logger.error(f"âŒ {model_info['name']} ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")
                results[model_key] = False
        
        total_end_time = time.time()
        total_duration = total_end_time - total_start_time
        
        print(f"\nâ±ï¸ ì´ ë‹¤ìš´ë¡œë“œ ì‹œê°„: {total_duration/60:.1f}ë¶„")
        
        return results
    
    def create_model_registry(self, results: Dict[str, bool]):
        """ë‹¤ìš´ë¡œë“œëœ ëª¨ë¸ë“¤ì˜ ë ˆì§€ìŠ¤íŠ¸ë¦¬ ìƒì„±"""
        registry = {
            "conda_environment": os.environ.get('CONDA_DEFAULT_ENV', 'unknown'),
            "download_time": time.strftime('%Y-%m-%d %H:%M:%S'),
            "system_info": {
                "python_version": sys.version,
                "platform": sys.platform,
                "project_root": str(self.project_root)
            },
            "models": {}
        }
        
        for model_key, success in results.items():
            model_info = self.real_models[model_key]
            verified, actual_size = self.verify_model(model_key, model_info)
            
            registry["models"][model_key] = {
                "name": model_info["name"],
                "description": model_info["description"],
                "local_path": str(self.checkpoints_dir / model_info["local_dir"]),
                "relative_path": f"ai_models/checkpoints/{model_info['local_dir']}",
                "download_success": success,
                "verified": verified,
                "actual_size_gb": actual_size,
                "expected_size_gb": model_info["size_gb"],
                "method": model_info["method"],
                "priority": model_info["priority"]
            }
        
        registry_path = self.models_dir / "conda_model_registry.json"
        with open(registry_path, 'w', encoding='utf-8') as f:
            json.dump(registry, f, indent=2, ensure_ascii=False)
        
        logger.info(f"âœ… ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬ ìƒì„±: {registry_path}")
        
        # MyCloset AI êµ¬ì¡°ì— ë§ëŠ” ì„¤ì • íŒŒì¼ë„ ìƒì„±
        config_content = f"""# MyCloset AI ì‹¤ì œ ëª¨ë¸ ì„¤ì • (Conda í™˜ê²½)
# ìë™ ìƒì„±: {time.strftime('%Y-%m-%d %H:%M:%S')}

models:
"""
        
        for model_key, success in results.items():
            if success:
                model_info = self.real_models[model_key]
                config_content += f"""  {model_key}:
    name: "{model_info['name']}"
    path: "ai_models/checkpoints/{model_info['local_dir']}"
    enabled: true
    method: "{model_info['method']}"
    verified: true
    
"""
        
        config_path = self.models_dir / "conda_models_config.yaml"
        with open(config_path, 'w', encoding='utf-8') as f:
            f.write(config_content)
        
        logger.info(f"âœ… ëª¨ë¸ ì„¤ì • íŒŒì¼ ìƒì„±: {config_path}")

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("ğŸš€ Conda í™˜ê²½ ì‹¤ì œ AI ëª¨ë¸ ë‹¤ìš´ë¡œë” ì‹œì‘!")
    print("   âœ… í´ë°± ëª¨ë¸ ì—†ìŒ")
    print("   âœ… ê²€ì¦ëœ ì‹¤ì œ ëª¨ë¸ë§Œ")
    print("   âœ… MyCloset AI êµ¬ì¡° ì¤€ìˆ˜")
    
    downloader = CondaRealModelDownloader()
    
    # 1. Conda í™˜ê²½ í™•ì¸
    if not downloader.check_conda_environment():
        return False
    
    # 2. ì˜ì¡´ì„± ì„¤ì¹˜
    if not downloader.install_conda_dependencies():
        print("\nâŒ ì˜ì¡´ì„± ì„¤ì¹˜ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤!")
        return False
    
    # 3. ëª¨ë¸ ì„ íƒ
    model_keys = downloader.show_model_selection()
    if not model_keys:
        print("âŒ ì„ íƒëœ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")
        return False
    
    # 4. ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
    results = downloader.download_selected_models(model_keys)
    
    # 5. ê²°ê³¼ ìš”ì•½
    print("\n" + "=" * 60)
    print("ğŸ“Š ì‹¤ì œ AI ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ê²°ê³¼:")
    
    success_count = sum(1 for success in results.values() if success)
    total_count = len(results)
    
    for model_key, success in results.items():
        model_name = downloader.real_models[model_key]["name"]
        status = "âœ… ì„±ê³µ" if success else "âŒ ì‹¤íŒ¨"
        
        if success:
            verified, actual_size = downloader.verify_model(model_key, downloader.real_models[model_key])
            status += f" ({actual_size:.1f}GB)"
        
        print(f"  {model_name}: {status}")
    
    print(f"\nì„±ê³µ: {success_count}/{total_count}")
    
    if success_count > 0:
        # 6. ë ˆì§€ìŠ¤íŠ¸ë¦¬ ìƒì„±
        downloader.create_model_registry(results)
        
        print("\nğŸ‰ ì‹¤ì œ AI ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ!")
        print("\nğŸ“‹ ë‹¤ìŒ ë‹¨ê³„:")
        print("1. ëª¨ë¸ í™•ì¸: ls -la ai_models/checkpoints/")
        print("2. ì„¤ì • í™•ì¸: cat ai_models/conda_model_registry.json")
        print("3. Step í…ŒìŠ¤íŠ¸: python test_step_01_human_parsing.py")
        print("4. ì„œë²„ ì‹¤í–‰: python app/main.py")  
        print("5. API í…ŒìŠ¤íŠ¸: http://localhost:8000/docs")
        
        print(f"\nğŸ“ ëª¨ë¸ ì €ì¥ ìœ„ì¹˜: {downloader.checkpoints_dir}")
        
        return True
    else:
        print("\nâŒ ëª¨ë“  ëª¨ë¸ ë‹¤ìš´ë¡œë“œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        print("ğŸ’¡ í•´ê²° ë°©ë²•:")
        print("   1. ë„¤íŠ¸ì›Œí¬ ì—°ê²° í™•ì¸")
        print("   2. Conda í™˜ê²½ ì¬í™•ì¸: conda activate mycloset-ai")
        print("   3. ì˜ì¡´ì„± ì¬ì„¤ì¹˜: pip install huggingface_hub gdown requests tqdm")
        return False

if __name__ == "__main__":
    try:
        success = main()
        sys.exit(0 if success else 1)
    except KeyboardInterrupt:
        print("\nâ¹ ì‚¬ìš©ìê°€ í”„ë¡œê·¸ë¨ì„ ì¤‘ë‹¨í–ˆìŠµë‹ˆë‹¤.")
        sys.exit(1)
    except Exception as e:
        print(f"\nğŸ’¥ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)