# ğŸ”¥ Step íŒŒì¼ë³„ AI ëª¨ë¸ ë¡œë”© ìš”êµ¬ì‚¬í•­ ë¶„ì„

## ğŸ“Š ë¶„ì„ ê°œìš”
- **ë¶„ì„ ëŒ€ìƒ**: 8ê°œ Step íŒŒì¼
- **ë¶„ì„ ëª©ì **: ì‹¤ì œ AI ëª¨ë¸ ë¡œë”© ë° ì¶”ë¡  ìš”êµ¬ì‚¬í•­ íŒŒì•…
- **ë¶„ì„ ê¸°ì¤€**: ModelLoaderë¥¼ í†µí•œ ì‹¤ì œ ì²´í¬í¬ì¸íŠ¸ ë¡œë”©

## ğŸ¯ Stepë³„ ëª¨ë¸ ë¡œë”© ìš”êµ¬ì‚¬í•­

### Step 01: Human Parsing (ì¸ê°„ íŒŒì‹±)
#### ìš”êµ¬í•˜ëŠ” ëª¨ë¸ë“¤:
1. **Graphonomy ëª¨ë¸**:
   - `model_name`: 'human_parsing_schp' (1173MB)
   - `step_name`: 'HumanParsingStep'
   - `model_type`: 'human_parsing'
   - **ì‹¤ì œ íŒŒì¼ë“¤**:
     - `graphonomy_fixed.pth` (267MB)
     - `graphonomy_new.pth` (109MB)
     - `pytorch_model.bin` (109MB)
     - `exp-schp-201908261155-atr.pth` (SCHP ATR)

2. **U2Net ëª¨ë¸**:
   - `model_name`: 'u2net.pth' (40MB)
   - `step_name`: 'HumanParsingStep'
   - `model_type`: 'cloth_segmentation'
   - **ì‹¤ì œ íŒŒì¼**: `u2net.pth` (528MB)

#### ë¡œë”© ë°©ì‹:
```python
# Central Hubë¥¼ í†µí•œ ë¡œë”©
model_request = {
    'model_name': 'human_parsing_schp',
    'step_name': 'HumanParsingStep',
    'device': self.device,
    'model_type': 'human_parsing'
}
loaded_model = model_loader.load_model(**model_request)
```

### Step 02: Pose Estimation (í¬ì¦ˆ ì¶”ì •)
#### ìš”êµ¬í•˜ëŠ” ëª¨ë¸ë“¤:
1. **HRNet ëª¨ë¸ë“¤**:
   - `hrnet_w48_coco_384x288.pth` (243MB)
   - `hrnet_w48_coco_256x192.pth` (243MB)
   - `hrnet_w32_coco_256x192.pth` (109MB)

2. **OpenPose ëª¨ë¸**:
   - `body_pose_model.pth` (98MB)

3. **YOLOv8 ëª¨ë¸**:
   - `yolov8m-pose.pt` (51MB)

4. **Diffusion ëª¨ë¸**:
   - `diffusion_pytorch_model.bin` (1.3GB)
   - `diffusion_pytorch_model.fp16.bin` (689MB)

#### ë¡œë”© ë°©ì‹:
```python
# ê° ëª¨ë¸ë³„ ê°œë³„ ë¡œë”©
mediapipe_model.load_model()
yolo_model.load_model()
openpose_model.load_model()
hrnet_model.load_model()
```

### Step 03: Cloth Segmentation (ì˜ë¥˜ ë¶„í• )
#### ìš”êµ¬í•˜ëŠ” ëª¨ë¸ë“¤:
1. **SAM ëª¨ë¸ë“¤**:
   - `sam_vit_h_4b8939.pth` (2.4GB)
   - `sam_vit_l_0b3195.pth` (1.2GB)
   - `mobile_sam.pt` (358MB)

2. **U2Net ëª¨ë¸**:
   - `u2net.pth` (528MB)

3. **DeepLabV3+ ëª¨ë¸**:
   - `deeplabv3_resnet101_coco.pth` (233MB)
   - `deeplabv3_resnet101_ultra.pth` (233MB)

#### ë¡œë”© ë°©ì‹:
```python
# ModelLoaderë¥¼ í†µí•œ ë¡œë”©
model_path = self.model_loader.get_model_path('deeplabv3_resnet101_ultra', step_name='step_03_cloth_segmentation')
model_path = self.model_loader.get_model_path('sam_vit_h_4b8939', step_name='step_03_cloth_segmentation')
model_path = self.model_loader.get_model_path('u2net', step_name='step_03_cloth_segmentation')
```

### Step 04: Geometric Matching (ê¸°í•˜í•™ì  ë§¤ì¹­)
#### ìš”êµ¬í•˜ëŠ” ëª¨ë¸ë“¤:
1. **GMM ëª¨ë¸**:
   - `gmm_final.pth` (1.3GB)

2. **TPS ëª¨ë¸**:
   - `tps_network.pth` (548MB)

3. **RAFT ëª¨ë¸**:
   - `raft-things.pth` (548MB)

4. **SAM ëª¨ë¸**:
   - `sam_vit_h_4b8939.pth` (2.4GB)

#### ë¡œë”© ë°©ì‹:
```python
# ModelLoaderë¥¼ í†µí•œ ì§ì ‘ ë¡œë”©
gmm_real_model = self.model_loader.load_model("gmm_final")
tps_real_model = self.model_loader.load_model("tps_network")
raft_real_model = self.model_loader.load_model("raft-things")
sam_real_model = self.model_loader.load_model("sam_vit_h_4b8939")
```

### Step 05: Cloth Warping (ì˜ë¥˜ ë³€í˜•)
#### ìš”êµ¬í•˜ëŠ” ëª¨ë¸ë“¤:
1. **TPS Transformation**:
   - `tps_transformation.pth` (470MB)

2. **VITON-HD Warping**:
   - `viton_hd_warping.pth` (1.3GB)

3. **DPT Hybrid MiDaS**:
   - `dpt_hybrid_midas.pth` (470MB)

4. **VGG19 Warping**:
   - `vgg19_warping.pth` (548MB)

5. **DenseNet121 Ultra**:
   - `densenet121_ultra.pth` (31MB)

#### ë¡œë”© ë°©ì‹:
```python
# ModelLoaderë¥¼ í†µí•œ ë¡œë”©
tps_real_model = self.model_loader.load_model("tps_transformation")
viton_real_model = self.model_loader.load_model("viton_hd_warping")
dpt_real_model = self.model_loader.load_model("dpt_hybrid_midas")
vgg_real_model = self.model_loader.load_model("vgg19_warping")
densenet_real_model = self.model_loader.load_model("densenet121_ultra")
```

### Step 06: Virtual Fitting (ê°€ìƒ í”¼íŒ…)
#### ìš”êµ¬í•˜ëŠ” ëª¨ë¸ë“¤:
1. **OOTD ëª¨ë¸**:
   - `ootd_checkpoint.pth` (3.2GB)
   - `ootd_3.2gb.pth` (3.2GB)

2. **VITON-HD ëª¨ë¸**:
   - `viton_hd_2.1gb.pth` (230MB)

3. **HR-VITON ëª¨ë¸**:
   - `hrviton_final.pth` (230MB)

4. **Diffusion ëª¨ë¸**:
   - `diffusion_pytorch_model.safetensors` (3.2GB)
   - `stable_diffusion_4.8gb.pth` (3.2GB)

#### ë¡œë”© ë°©ì‹:
```python
# ModelLoaderë¥¼ í†µí•œ ë¡œë”©
ootd_checkpoint = self.model_loader.load_checkpoint('ootd_checkpoint')
viton_checkpoint = self.model_loader.load_checkpoint('viton_hd_checkpoint')
diffusion_checkpoint = self.model_loader.load_checkpoint('diffusion_checkpoint')
```

### Step 07: Post Processing (í›„ì²˜ë¦¬)
#### ìš”êµ¬í•˜ëŠ” ëª¨ë¸ë“¤:
1. **RealESRGAN ëª¨ë¸ë“¤**:
   - `RealESRGAN_x4plus.pth` (64MB)
   - `RealESRGAN_x2plus.pth` (233MB)

2. **GFPGAN ëª¨ë¸**:
   - `GFPGAN.pth` (233MB)

3. **SwinIR ëª¨ë¸**:
   - `swinir_real_sr_x4_large.pth` (233MB)

#### ë¡œë”© ë°©ì‹:
```python
# ì§ì ‘ ëª¨ë¸ ë¡œë”©
self._load_models()
```

### Step 08: Quality Assessment (í’ˆì§ˆ í‰ê°€)
#### ìš”êµ¬í•˜ëŠ” ëª¨ë¸ë“¤:
1. **CLIP ëª¨ë¸ë“¤**:
   - `clip_vit_b32.pth` (233MB)
   - `ViT-B-32.pt` (233MB)
   - `ViT-L-14.pt` (233MB)

2. **LPIPS ëª¨ë¸**:
   - `lpips_alex.pth` (233MB)

3. **AlexNet ëª¨ë¸**:
   - `alex.pth` (233MB)

#### ë¡œë”© ë°©ì‹:
```python
# ModelLoaderë¥¼ í†µí•œ ë¡œë”©
model = self.model_loader.load_model(
    model_name='clip_vit_b32',
    step_name='QualityAssessmentStep',
    device=self.device
)
```

## ğŸ“ˆ ëª¨ë¸ ë¡œë”© íŒ¨í„´ ë¶„ì„

### 1. ë¡œë”© ë°©ì‹ ë¶„ë¥˜
- **Central Hub ê¸°ë°˜**: Step 01, 03, 04, 05, 06, 08
- **ì§ì ‘ ë¡œë”©**: Step 02, 07
- **í•˜ì´ë¸Œë¦¬ë“œ**: Step 01 (Central Hub + ì§ì ‘ ë¡œë”©)

### 2. ëª¨ë¸ ìš”êµ¬ì‚¬í•­
- **ì´ ëª¨ë¸ ìˆ˜**: 50+ ê°œ
- **ì´ í¬ê¸°**: ì•½ 60GB
- **ê°€ì¥ í° ëª¨ë¸**: RealVisXL_V4.0.safetensors (6.5GB)
- **ê°€ì¥ ì‘ì€ ëª¨ë¸**: ì¼ë¶€ ê²½ëŸ‰í™” ëª¨ë¸ë“¤ (31MB)

### 3. ë¡œë”© ìš°ì„ ìˆœìœ„
1. **ê³ ì„±ëŠ¥ ëª¨ë¸**: SAM ViT-H, Graphonomy, Diffusion ëª¨ë¸ë“¤
2. **ì¤‘ê°„ ì„±ëŠ¥ ëª¨ë¸**: HRNet, U2Net, GMM, VITON
3. **ê²½ëŸ‰ ëª¨ë¸**: YOLOv8, Mobile SAM, TOM

## ğŸ¯ ê²°ë¡ 

### âœ… ì‹¤ì œ AI ëª¨ë¸ ë¡œë”© ìš”êµ¬ì‚¬í•­
1. **ëª¨ë“  Stepì´ ì‹¤ì œ AI ëª¨ë¸ì„ ìš”êµ¬í•¨**: Mock ëª¨ë¸ì´ ì•„ë‹Œ ì‹¤ì œ ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ë“¤
2. **ë‹¤ì–‘í•œ ëª¨ë¸ ì•„í‚¤í…ì²˜**: CNN, Transformer, Diffusion, GAN ë“±
3. **ëŒ€ìš©ëŸ‰ ëª¨ë¸ë“¤**: 1GB ì´ìƒì˜ ëª¨ë¸ë“¤ì´ ë‹¤ìˆ˜
4. **ì‹¤ì œ ì¶”ë¡  ê°€ëŠ¥**: ëª¨ë“  ëª¨ë¸ì´ ì‹¤ì œ ì¶”ë¡ ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆëŠ” êµ¬ì¡°

### ğŸ”§ ModelLoader í˜¸í™˜ì„±
1. **Central Hub í†µí•©**: ëŒ€ë¶€ë¶„ì˜ Stepì´ Central Hubë¥¼ í†µí•œ ëª¨ë¸ ë¡œë”© ì‚¬ìš©
2. **ì²´í¬í¬ì¸íŠ¸ ê¸°ë°˜**: ì‹¤ì œ .pth, .pt, .safetensors íŒŒì¼ ë¡œë”©
3. **ë™ì  ëª¨ë¸ ìƒì„±**: ì²´í¬í¬ì¸íŠ¸ ë¶„ì„ì„ í†µí•œ ë™ì  ëª¨ë¸ ì•„í‚¤í…ì²˜ ìƒì„±
4. **ì—ëŸ¬ ì²˜ë¦¬**: ë¡œë”© ì‹¤íŒ¨ ì‹œ í´ë°± ëª¨ë¸ ìƒì„±

### ğŸ“Š ì„±ëŠ¥ ìš”êµ¬ì‚¬í•­
1. **ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±**: 60GB+ ëª¨ë¸ë“¤ì„ íš¨ìœ¨ì ìœ¼ë¡œ ê´€ë¦¬
2. **ë¡œë”© ì†ë„**: ëŒ€ìš©ëŸ‰ ëª¨ë¸ë“¤ì˜ ë¹ ë¥¸ ë¡œë”©
3. **ë™ì‹œì„±**: ì—¬ëŸ¬ ëª¨ë¸ì˜ ë™ì‹œ ë¡œë”© ì§€ì›
4. **í™•ì¥ì„±**: ìƒˆë¡œìš´ ëª¨ë¸ ì¶”ê°€ ìš©ì´ì„±

**ê²°ë¡ **: ëª¨ë“  Step íŒŒì¼ë“¤ì´ ì‹¤ì œ AI ëª¨ë¸ì„ ë¡œë”©í•´ì„œ ì¶”ë¡ í•  ìˆ˜ ìˆëŠ” ìœ íš¨í•œ ë°ì´í„°ë¥¼ ìš”êµ¬í•˜ë©°, ModelLoaderê°€ ì´ëŸ¬í•œ ìš”êµ¬ì‚¬í•­ì„ ì¶©ì¡±í•  ìˆ˜ ìˆë„ë¡ ì„¤ê³„ë˜ì–´ ìˆìŠµë‹ˆë‹¤.
