#!/usr/bin/env python3
"""
ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë¶„ì„ ìŠ¤í¬ë¦½íŠ¸
51GB ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì˜ ì›ì¸ì„ ì°¾ìŠµë‹ˆë‹¤.
"""

import psutil
import os
import sys

def analyze_memory_usage():
    """ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë¶„ì„"""
    print("ğŸ”¥ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë¶„ì„ ì‹œì‘")
    
    # ì „ì²´ ì‹œìŠ¤í…œ ë©”ëª¨ë¦¬
    memory = psutil.virtual_memory()
    print(f"\nğŸ“Š ì „ì²´ ì‹œìŠ¤í…œ ë©”ëª¨ë¦¬:")
    print(f"   - ì „ì²´: {memory.total / (1024**3):.1f}GB")
    print(f"   - ì‚¬ìš© ì¤‘: {memory.used / (1024**3):.1f}GB")
    print(f"   - ì‚¬ìš©ë¥ : {memory.percent}%")
    print(f"   - ê°€ìš©: {memory.available / (1024**3):.1f}GB")
    
    # í˜„ì¬ Python í”„ë¡œì„¸ìŠ¤ ë©”ëª¨ë¦¬
    current_process = psutil.Process(os.getpid())
    print(f"\nğŸ“Š í˜„ì¬ Python í”„ë¡œì„¸ìŠ¤:")
    print(f"   - PID: {current_process.pid}")
    print(f"   - ë©”ëª¨ë¦¬: {current_process.memory_info().rss / (1024**3):.2f}GB")
    print(f"   - ê°€ìƒ ë©”ëª¨ë¦¬: {current_process.memory_info().vms / (1024**3):.2f}GB")
    
    # ìƒìœ„ ë©”ëª¨ë¦¬ ì‚¬ìš© í”„ë¡œì„¸ìŠ¤
    print(f"\nğŸ“Š ìƒìœ„ ë©”ëª¨ë¦¬ ì‚¬ìš© í”„ë¡œì„¸ìŠ¤:")
    processes = []
    for proc in psutil.process_iter(['pid', 'name', 'memory_info', 'cmdline']):
        try:
            memory_info = proc.info['memory_info']
            if memory_info is not None:
                processes.append({
                    'pid': proc.info['pid'],
                    'name': proc.info['name'],
                    'memory_mb': memory_info.rss / (1024**2),
                    'cmdline': ' '.join(proc.info['cmdline'][:3]) if proc.info['cmdline'] else ''
                })
        except (psutil.NoSuchProcess, psutil.AccessDenied):
            continue
    
    # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ìˆœìœ¼ë¡œ ì •ë ¬
    processes.sort(key=lambda x: x['memory_mb'], reverse=True)
    
    for i, proc in enumerate(processes[:15]):
        print(f"   {i+1:2d}. {proc['name']:<20} {proc['memory_mb']:8.1f}MB (PID: {proc['pid']})")
        if proc['cmdline']:
            print(f"       â””â”€ {proc['cmdline']}")
    
    # Python í”„ë¡œì„¸ìŠ¤ë“¤
    print(f"\nğŸ“Š Python í”„ë¡œì„¸ìŠ¤ë“¤:")
    python_processes = [p for p in processes if 'python' in p['name'].lower()]
    for proc in python_processes:
        print(f"   - {proc['name']}: {proc['memory_mb']:.1f}MB (PID: {proc['pid']})")
        if proc['cmdline']:
            print(f"     â””â”€ {proc['cmdline']}")
    
    # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ í° í”„ë¡œì„¸ìŠ¤ë“¤ (1GB ì´ìƒ)
    large_processes = [p for p in processes if p['memory_mb'] > 1024]
    print(f"\nğŸ“Š ëŒ€ìš©ëŸ‰ ë©”ëª¨ë¦¬ í”„ë¡œì„¸ìŠ¤ (1GB ì´ìƒ):")
    total_large_memory = 0
    for proc in large_processes:
        memory_gb = proc['memory_mb'] / 1024
        total_large_memory += memory_gb
        print(f"   - {proc['name']}: {memory_gb:.1f}GB (PID: {proc['pid']})")
    
    print(f"\nğŸ“Š ëŒ€ìš©ëŸ‰ í”„ë¡œì„¸ìŠ¤ ì´ ë©”ëª¨ë¦¬: {total_large_memory:.1f}GB")
    
    # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë¶„ì„
    print(f"\nğŸ“Š ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë¶„ì„:")
    print(f"   - ì „ì²´ ì‚¬ìš© ì¤‘: {memory.used / (1024**3):.1f}GB")
    print(f"   - ëŒ€ìš©ëŸ‰ í”„ë¡œì„¸ìŠ¤: {total_large_memory:.1f}GB")
    print(f"   - ê¸°íƒ€ í”„ë¡œì„¸ìŠ¤: {(memory.used / (1024**3)) - total_large_memory:.1f}GB")
    
    # AI ëª¨ë¸ ê´€ë ¨ ë©”ëª¨ë¦¬ í™•ì¸
    print(f"\nğŸ“Š AI ëª¨ë¸ ê´€ë ¨ ë©”ëª¨ë¦¬ í™•ì¸:")
    try:
        import torch
        if torch.cuda.is_available():
            print(f"   - CUDA ë©”ëª¨ë¦¬ í• ë‹¹: {torch.cuda.memory_allocated() / (1024**3):.2f}GB")
            print(f"   - CUDA ë©”ëª¨ë¦¬ ìºì‹œ: {torch.cuda.memory_reserved() / (1024**3):.2f}GB")
        else:
            print(f"   - CUDA ì‚¬ìš© ë¶ˆê°€")
    except ImportError:
        print(f"   - PyTorch ë¯¸ì„¤ì¹˜")
    
    try:
        import torch.mps
        if torch.backends.mps.is_available():
            print(f"   - MPS ì‚¬ìš© ê°€ëŠ¥")
            # MPS ë©”ëª¨ë¦¬ ì •ë³´ëŠ” ì§ì ‘ì ìœ¼ë¡œ í™•ì¸í•˜ê¸° ì–´ë ¤ì›€
        else:
            print(f"   - MPS ì‚¬ìš© ë¶ˆê°€")
    except:
        print(f"   - MPS í™•ì¸ ë¶ˆê°€")

if __name__ == "__main__":
    analyze_memory_usage() 