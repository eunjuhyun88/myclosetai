#!/usr/bin/env python3
"""
ğŸ”¥ ì¢…í•© AI ëª¨ë¸ ë¶„ì„ ë° ì—…ë°ì´íŠ¸ ë„êµ¬
====================================

ëª¨ë“  AI ëª¨ë¸ íŒŒì¼ë“¤ì„ ë¶„ì„í•˜ê³  í˜¸í™˜ì„± ë¬¸ì œë¥¼ ìˆ˜ì •í•˜ëŠ” ì¢…í•© ë„êµ¬

Author: MyCloset AI Team
Date: 2025-08-08
Version: 1.0
"""

import os
import sys
import time
import logging
import traceback
import json
import shutil
from typing import Dict, Any, List, Optional, Tuple
from pathlib import Path
from dataclasses import dataclass, field
from datetime import datetime
import subprocess

# PyTorch ê´€ë ¨
try:
    import torch
    import torch.nn as nn
    TORCH_AVAILABLE = True
except ImportError:
    TORCH_AVAILABLE = False

# NumPy ê´€ë ¨
try:
    import numpy as np
    NUMPY_AVAILABLE = True
except ImportError:
    NUMPY_AVAILABLE = False

# SafeTensors ê´€ë ¨
try:
    import safetensors
    SAFETENSORS_AVAILABLE = True
except ImportError:
    SAFETENSORS_AVAILABLE = False

logger = logging.getLogger(__name__)

@dataclass
class AIModelInfo:
    """AI ëª¨ë¸ ì •ë³´"""
    path: str
    size_mb: float = 0.0
    exists: bool = False
    valid: bool = False
    structure_type: str = "unknown"
    architecture_hints: List[str] = field(default_factory=list)
    issues: List[str] = field(default_factory=list)
    recommendations: List[str] = field(default_factory=list)
    fixed: bool = False
    step_category: str = "unknown"
    model_type: str = "unknown"

class ComprehensiveAIModelAnalyzer:
    """ì¢…í•© AI ëª¨ë¸ ë¶„ì„ ë° ìˆ˜ì • ë„êµ¬"""
    
    def __init__(self, root_dir: str = "."):
        self.root_dir = Path(root_dir)
        self.models = {}
        self.analysis_results = {}
        
        # Stepë³„ ëª¨ë¸ ì¹´í…Œê³ ë¦¬ ì •ì˜
        self.step_categories = {
            'step_01': {
                'name': 'Human Parsing',
                'models': ['graphonomy', 'u2net', 'deeplabv3plus', 'hrnet'],
                'paths': [
                    'ai_models/Self-Correction-Human-Parsing/exp-schp-201908261155-atr.pth',
                    'ai_models/step_01_human_parsing/deeplabv3plus.pth',
                    'ai_models/step_03_cloth_segmentation/u2net.pth'
                ]
            },
            'step_02': {
                'name': 'Pose Estimation',
                'models': ['hrnet', 'openpose', 'yolo', 'mediapipe'],
                'paths': [
                    'ai_models/step_02_pose_estimation/hrnet_w48_coco_384x288.pth',
                    'ai_models/step_02_pose_estimation/body_pose_model.pth',
                    'ai_models/step_02_pose_estimation/yolov8n-pose.pt',
                    'ai_models/openpose.pth'
                ]
            },
            'step_03': {
                'name': 'Cloth Segmentation',
                'models': ['sam', 'u2net', 'deeplabv3', 'mobile_sam'],
                'paths': [
                    'ai_models/step_03_cloth_segmentation/sam_vit_h_4b8939.pth',
                    'ai_models/step_03_cloth_segmentation/u2net.pth',
                    'ai_models/step_03_cloth_segmentation/deeplabv3_resnet101_ultra.pth',
                    'ai_models/step_03_cloth_segmentation/mobile_sam.pt'
                ]
            },
            'step_04': {
                'name': 'Geometric Matching',
                'models': ['gmm', 'tps', 'raft', 'optical_flow'],
                'paths': [
                    'ai_models/step_04_geometric_matching/gmm_final.pth',
                    'ai_models/step_04_geometric_matching/tps_network.pth',
                    'ai_models/step_04_geometric_matching/raft-things.pth',
                    'ai_models/step_04_geometric_matching/sam_vit_h_4b8939.pth'
                ]
            },
            'step_05': {
                'name': 'Cloth Warping',
                'models': ['tom', 'viton_hd', 'tps', 'dpt', 'vgg19'],
                'paths': [
                    'ai_models/step_05_cloth_warping/tom_final.pth',
                    'ai_models/step_05_cloth_warping/viton_hd_warping.pth',
                    'ai_models/step_05_cloth_warping/tps_transformation.pth',
                    'ai_models/step_05_cloth_warping/dpt_hybrid_midas.pth',
                    'ai_models/step_05_cloth_warping/vgg19_warping.pth'
                ]
            },
            'step_06': {
                'name': 'Virtual Fitting',
                'models': ['stable_diffusion', 'ootd', 'viton_hd', 'hrviton'],
                'paths': [
                    'ai_models/step_06_virtual_fitting/stable_diffusion_4.8gb.pth',
                    'ai_models/step_06_virtual_fitting/ootd_3.2gb.pth',
                    'ai_models/step_06_virtual_fitting/viton_hd_2.1gb.pth',
                    'ai_models/step_06_virtual_fitting/hrviton_final.pth',
                    'ai_models/step_06_virtual_fitting/validated_checkpoints/ootd_checkpoint.pth'
                ]
            },
            'step_07': {
                'name': 'Post Processing',
                'models': ['real_esrgan', 'swinir', 'gfpgan', 'densenet'],
                'paths': [
                    'ai_models/step_07_post_processing/RealESRGAN_x4plus.pth',
                    'ai_models/step_07_post_processing/swinir_real_sr_x4_large.pth',
                    'ai_models/step_07_post_processing/GFPGAN.pth',
                    'ai_models/step_07_post_processing/densenet161_enhance.pth'
                ]
            },
            'step_08': {
                'name': 'Quality Assessment',
                'models': ['clip', 'lpips', 'alex', 'vit'],
                'paths': [
                    'ai_models/step_08_quality_assessment/clip_vit_b32.pth',
                    'ai_models/step_08_quality_assessment/ViT-L-14.pt',
                    'ai_models/step_08_quality_assessment/lpips_alex.pth',
                    'ai_models/step_08_quality_assessment/alex.pth'
                ]
            }
        }
        
    def find_all_ai_models(self) -> List[str]:
        """ëª¨ë“  AI ëª¨ë¸ íŒŒì¼ ì°¾ê¸°"""
        model_files = []
        
        # ë‹¤ì–‘í•œ í™•ì¥ì ê²€ìƒ‰
        extensions = ["*.pth", "*.pt", "*.safetensors", "*.ckpt", "*.bin"]
        
        for ext in extensions:
            files = list(self.root_dir.rglob(ext))
            model_files.extend([str(f) for f in files])
        
        # ì¤‘ë³µ ì œê±° ë° ì •ë ¬
        model_files = sorted(list(set(model_files)))
        
        # ë¶ˆí•„ìš”í•œ íŒŒì¼ í•„í„°ë§
        filtered_files = []
        exclude_patterns = [
            'distutils-precedence.pth',
            '__pycache__',
            '.git',
            'node_modules',
            'venv',
            'env',
            '.conda'
        ]
        
        for file_path in model_files:
            if not any(pattern in file_path for pattern in exclude_patterns):
                filtered_files.append(file_path)
        
        logger.info(f"ğŸ” ë°œê²¬ëœ AI ëª¨ë¸ íŒŒì¼: {len(filtered_files)}ê°œ")
        return filtered_files
    
    def categorize_model(self, model_path: str) -> Tuple[str, str]:
        """ëª¨ë¸ì„ Stepë³„ë¡œ ë¶„ë¥˜"""
        model_path_lower = model_path.lower()
        
        for step_key, step_info in self.step_categories.items():
            for model_name in step_info['models']:
                if model_name.lower() in model_path_lower:
                    return step_key, model_name
        
        # ê²½ë¡œ ê¸°ë°˜ ë¶„ë¥˜
        for step_key, step_info in self.step_categories.items():
            for expected_path in step_info['paths']:
                if expected_path.lower() in model_path_lower:
                    return step_key, "unknown"
        
        return "unknown", "unknown"
    
    def analyze_model(self, model_path: str) -> AIModelInfo:
        """ê°œë³„ AI ëª¨ë¸ ë¶„ì„"""
        info = AIModelInfo(path=model_path)
        
        try:
            if not Path(model_path).exists():
                info.issues.append("íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ")
                return info
            
            info.exists = True
            info.size_mb = Path(model_path).stat().st_size / (1024 * 1024)
            
            # Step ë¶„ë¥˜
            step_category, model_type = self.categorize_model(model_path)
            info.step_category = step_category
            info.model_type = model_type
            
            # ğŸ”¥ ë‹¤ì–‘í•œ ë¡œë”© ë°©ë²• ì‹œë„
            model_data = None
            loading_method = None
            
            # ë°©ë²• 1: weights_only=True (ì•ˆì „í•œ ë°©ë²•)
            try:
                model_data = torch.load(model_path, map_location='cpu', weights_only=True)
                loading_method = 'weights_only_true'
                info.recommendations.append("ì•ˆì „í•œ weights_only=Trueë¡œ ë¡œë”©ë¨")
            except Exception as e1:
                # ë°©ë²• 2: weights_only=False (ì „í†µì ì¸ ë°©ë²•)
                try:
                    model_data = torch.load(model_path, map_location='cpu', weights_only=False)
                    loading_method = 'weights_only_false'
                    info.recommendations.append("weights_only=Falseë¡œ ë¡œë”©ë¨ (ë³´ì•ˆ ì£¼ì˜)")
                except Exception as e2:
                    # ë°©ë²• 3: TorchScript ëª¨ë¸
                    try:
                        model_data = torch.jit.load(model_path, map_location='cpu')
                        loading_method = 'torchscript'
                        info.recommendations.append("TorchScript ëª¨ë¸ë¡œ ë¡œë”©ë¨")
                    except Exception as e3:
                        # ë°©ë²• 4: SafeTensors
                        if SAFETENSORS_AVAILABLE:
                            try:
                                with safetensors.safe_open(model_path, framework="pt", device="cpu") as f:
                                    keys = list(f.keys())
                                    model_data = {key: f.get_tensor(key) for key in keys}
                                loading_method = 'safetensors'
                                info.recommendations.append("SafeTensorsë¡œ ë¡œë”©ë¨")
                            except Exception as e4:
                                info.issues.append(f"ëª¨ë“  ë¡œë”© ë°©ë²• ì‹¤íŒ¨: {e4}")
                                return info
                        else:
                            info.issues.append(f"ëª¨ë“  ë¡œë”© ë°©ë²• ì‹¤íŒ¨: {e3}")
                            return info
            
            # ğŸ”¥ êµ¬ì¡° íƒ€ì… ë¶„ë¥˜ ë° ê²€ì¦
            if isinstance(model_data, dict):
                info.structure_type = 'dict'
                
                # ë‹¤ì–‘í•œ êµ¬ì¡° íƒ€ì… ì²˜ë¦¬
                if 'state_dict' in model_data:
                    # í‘œì¤€ PyTorch ëª¨ë¸
                    info.structure_type = 'state_dict'
                    state_dict = model_data['state_dict']
                    
                    # ì•„í‚¤í…ì²˜ ê°ì§€
                    info.architecture_hints = self._detect_architecture_from_keys(state_dict.keys())
                    info.valid = True
                    info.recommendations.append("í‘œì¤€ state_dict êµ¬ì¡°")
                    
                elif 'model' in model_data:
                    # ëª¨ë¸ ë˜í¼ êµ¬ì¡°
                    info.structure_type = 'model_wrapper'
                    info.valid = True
                    info.recommendations.append("ëª¨ë¸ ë˜í¼ êµ¬ì¡°")
                    
                elif 'weights' in model_data:
                    # ê°€ì¤‘ì¹˜ë§Œ ìˆëŠ” êµ¬ì¡°
                    info.structure_type = 'weights_only'
                    info.valid = True
                    info.recommendations.append("ê°€ì¤‘ì¹˜ ì „ìš© êµ¬ì¡°")
                    
                elif 'parameters' in model_data:
                    # íŒŒë¼ë¯¸í„°ë§Œ ìˆëŠ” êµ¬ì¡°
                    info.structure_type = 'parameters_only'
                    info.valid = True
                    info.recommendations.append("íŒŒë¼ë¯¸í„° ì „ìš© êµ¬ì¡°")
                    
                else:
                    # ì»¤ìŠ¤í…€ ë”•ì…”ë„ˆë¦¬ êµ¬ì¡°
                    info.structure_type = 'custom_dict'
                    
                    # ì»¤ìŠ¤í…€ êµ¬ì¡°ì—ì„œë„ íŒŒë¼ë¯¸í„° ì°¾ê¸° ì‹œë„
                    total_params = 0
                    param_keys = []
                    
                    # ğŸ”¥ ì¤‘ì²©ëœ êµ¬ì¡° ì²˜ë¦¬ (RealESRGAN ë“±)
                    def extract_tensors(obj, prefix=""):
                        nonlocal total_params, param_keys
                        if isinstance(obj, torch.Tensor):
                            total_params += obj.numel()
                            param_keys.append(prefix)
                        elif isinstance(obj, dict):
                            for key, value in obj.items():
                                new_prefix = f"{prefix}.{key}" if prefix else key
                                extract_tensors(value, new_prefix)
                    
                    extract_tensors(model_data)
                    
                    if total_params > 0:
                        info.architecture_hints = self._detect_architecture_from_keys(param_keys)
                        info.valid = True
                        info.recommendations.append("ì»¤ìŠ¤í…€ êµ¬ì¡°ì—ì„œ íŒŒë¼ë¯¸í„° ë°œê²¬")
                    else:
                        info.issues.append("íŒŒë¼ë¯¸í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
                        info.recommendations.append("ì»¤ìŠ¤í…€ êµ¬ì¡° ê²€ì¦ í•„ìš”")
                        
            elif isinstance(model_data, torch.Tensor):
                # ì§ì ‘ í…ì„œ í˜•íƒœ
                info.structure_type = 'tensor'
                info.valid = True
                info.recommendations.append("ì§ì ‘ í…ì„œ í˜•íƒœ")
                
            elif hasattr(model_data, 'state_dict'):
                # TorchScript ëª¨ë¸
                info.structure_type = 'torchscript'
                try:
                    state_dict = model_data.state_dict()
                    info.architecture_hints = self._detect_architecture_from_keys(state_dict.keys())
                    info.valid = True
                    info.recommendations.append("TorchScript ëª¨ë¸")
                except Exception as e:
                    info.issues.append(f"TorchScript state_dict ì ‘ê·¼ ì‹¤íŒ¨: {e}")
                    
            else:
                info.structure_type = str(type(model_data))
                info.issues.append(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” íƒ€ì…: {type(model_data)}")
                
        except Exception as e:
            info.issues.append(f"ëª¨ë¸ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
        
        return info
    
    def _detect_architecture_from_keys(self, keys: List[str]) -> List[str]:
        """í‚¤ ëª©ë¡ì—ì„œ ì•„í‚¤í…ì²˜ ê°ì§€"""
        hints = []
        
        # í™•ì¥ëœ ì•„í‚¤í…ì²˜ í‚¤ì›Œë“œ
        architecture_keywords = {
            'graphonomy': ['backbone', 'decoder', 'classifier', 'schp', 'hrnet'],
            'u2net': ['stage1', 'stage2', 'stage3', 'stage4', 'side', 'u2net'],
            'deeplabv3plus': ['backbone', 'decoder', 'classifier', 'aspp', 'deeplab'],
            'gmm': ['feature_extraction', 'regression', 'gmm', 'geometric', 'pretrained.model'],
            'tps': ['localization_net', 'grid_generator', 'tps', 'transformation'],
            'raft': ['feature_encoder', 'context_encoder', 'flow_head', 'raft'],
            'sam': ['image_encoder', 'prompt_encoder', 'mask_decoder', 'sam'],
            'stable_diffusion': ['unet', 'vae', 'text_encoder', 'diffusion', 'model'],
            'ootd': ['unet_vton', 'unet_garm', 'vae', 'ootd'],
            'real_esrgan': ['body', 'upsampling', 'esrgan', 'real_esrgan'],
            'swinir': ['layers', 'patch_embed', 'norm', 'swin', 'swinir'],
            'clip': ['visual', 'transformer', 'text_projection', 'clip'],
            'vit': ['cls_token', 'pos_embed', 'patch_embed', 'blocks', 'attn', 'mlp'],
            'hrnet': ['hrnet', 'stage', 'transition', 'hrnet_w'],
            'openpose': ['pose', 'body', 'hand', 'face', 'openpose'],
            'yolo': ['yolo', 'detect', 'anchor', 'yolov'],
            'mediapipe': ['mediapipe', 'landmark', 'pose'],
            'viton': ['viton', 'vton', 'warping', 'tom'],
            'dpt': ['dpt', 'depth', 'midas'],
            'efficientnet': ['efficientnet', 'efficient'],
            'resnet': ['resnet', 'residual'],
            'mobilenet': ['mobilenet', 'mobile'],
            'densenet': ['densenet', 'dense'],
            'unet': ['down_blocks', 'up_blocks', 'conv_in', 'conv_out', 'time_embedding'],
            'diffusion': ['down_blocks', 'up_blocks', 'time_embedding', 'conv_in', 'conv_out']
        }
        
        for arch_name, keywords in architecture_keywords.items():
            matches = sum(1 for keyword in keywords if any(keyword.lower() in key.lower() for key in keys))
            if matches > 0:
                hints.append(f"{arch_name} (ë§¤ì¹­: {matches}ê°œ)")
        
        return hints
    
    def analyze_all_models(self) -> Dict[str, Any]:
        """ëª¨ë“  AI ëª¨ë¸ ë¶„ì„"""
        print("ğŸ” ëª¨ë“  AI ëª¨ë¸ íŒŒì¼ ê²€ìƒ‰ ì¤‘...")
        model_files = self.find_all_ai_models()
        
        print(f"ğŸ“Š ì´ {len(model_files)}ê°œì˜ AI ëª¨ë¸ íŒŒì¼ ë°œê²¬")
        
        results = {
            'analysis_time': datetime.now().isoformat(),
            'total_models': len(model_files),
            'valid_models': 0,
            'invalid_models': 0,
            'models': {},
            'step_summary': {},
            'architecture_summary': {},
            'issues_summary': {},
            'recommendations': []
        }
        
        for i, model_path in enumerate(model_files, 1):
            print(f"ğŸ” ë¶„ì„ ì¤‘... ({i}/{len(model_files)}): {Path(model_path).name}")
            
            info = self.analyze_model(model_path)
            self.models[model_path] = info
            
            # ê²°ê³¼ ì €ì¥
            results['models'][model_path] = {
                'size_mb': info.size_mb,
                'exists': info.exists,
                'valid': info.valid,
                'structure_type': info.structure_type,
                'architecture_hints': info.architecture_hints,
                'issues': info.issues,
                'recommendations': info.recommendations,
                'step_category': info.step_category,
                'model_type': info.model_type
            }
            
            # í†µê³„ ì—…ë°ì´íŠ¸
            if info.valid:
                results['valid_models'] += 1
            else:
                results['invalid_models'] += 1
            
            # Stepë³„ ìš”ì•½
            if info.step_category not in results['step_summary']:
                results['step_summary'][info.step_category] = {
                    'total': 0,
                    'valid': 0,
                    'invalid': 0,
                    'models': []
                }
            
            results['step_summary'][info.step_category]['total'] += 1
            if info.valid:
                results['step_summary'][info.step_category]['valid'] += 1
            else:
                results['step_summary'][info.step_category]['invalid'] += 1
            
            results['step_summary'][info.step_category]['models'].append({
                'path': model_path,
                'name': Path(model_path).name,
                'valid': info.valid,
                'size_mb': info.size_mb
            })
            
            # ì•„í‚¤í…ì²˜ ìš”ì•½
            for hint in info.architecture_hints:
                arch_name = hint.split(' (')[0]
                if arch_name not in results['architecture_summary']:
                    results['architecture_summary'][arch_name] = 0
                results['architecture_summary'][arch_name] += 1
            
            # ë¬¸ì œì  ìš”ì•½
            for issue in info.issues:
                if issue not in results['issues_summary']:
                    results['issues_summary'][issue] = 0
                results['issues_summary'][issue] += 1
        
        return results
    
    def fix_model_compatibility(self, model_path: str) -> bool:
        """ëª¨ë¸ í˜¸í™˜ì„± ìˆ˜ì •"""
        if model_path not in self.models:
            print(f"âŒ ëª¨ë¸ ì •ë³´ê°€ ì—†ìŒ: {model_path}")
            return False
        
        info = self.models[model_path]
        
        if not info.exists:
            print(f"âŒ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ: {model_path}")
            return False
        
        if info.valid:
            print(f"âœ… ì´ë¯¸ ìœ íš¨í•œ ëª¨ë¸: {model_path}")
            return True
        
        print(f"ğŸ”§ í˜¸í™˜ì„± ìˆ˜ì • ì‹œë„: {model_path}")
        
        try:
            # ë°±ì—… ìƒì„±
            backup_path = f"{model_path}.backup"
            if not Path(backup_path).exists():
                shutil.copy2(model_path, backup_path)
                print(f"ğŸ“¦ ë°±ì—… ìƒì„±: {backup_path}")
            
            # ëª¨ë¸ ë¡œë”©
            model_data = None
            
            # ë‹¤ì–‘í•œ ë¡œë”© ë°©ë²• ì‹œë„
            for method in ['weights_only_true', 'weights_only_false', 'torchscript', 'safetensors']:
                try:
                    if method == 'weights_only_true':
                        model_data = torch.load(model_path, map_location='cpu', weights_only=True)
                    elif method == 'weights_only_false':
                        model_data = torch.load(model_path, map_location='cpu', weights_only=False)
                    elif method == 'torchscript':
                        model_data = torch.jit.load(model_path, map_location='cpu')
                    elif method == 'safetensors' and SAFETENSORS_AVAILABLE:
                        with safetensors.safe_open(model_path, framework="pt", device="cpu") as f:
                            keys = list(f.keys())
                            model_data = {key: f.get_tensor(key) for key in keys}
                    
                    print(f"âœ… {method}ë¡œ ë¡œë”© ì„±ê³µ")
                    break
                except Exception as e:
                    print(f"âŒ {method} ë¡œë”© ì‹¤íŒ¨: {e}")
                    continue
            
            if model_data is None:
                print(f"âŒ ëª¨ë“  ë¡œë”© ë°©ë²• ì‹¤íŒ¨")
                return False
            
            # í˜¸í™˜ì„± ìˆ˜ì •
            fixed_model = self._fix_model_structure(model_data, info)
            
            if fixed_model is not None:
                # ìˆ˜ì •ëœ ëª¨ë¸ ì €ì¥
                torch.save(fixed_model, model_path)
                print(f"âœ… í˜¸í™˜ì„± ìˆ˜ì • ì™„ë£Œ: {model_path}")
                
                # ì •ë³´ ì—…ë°ì´íŠ¸
                info.fixed = True
                info.valid = True
                info.recommendations.append("í˜¸í™˜ì„± ìˆ˜ì • ì™„ë£Œ")
                
                return True
            else:
                print(f"âŒ í˜¸í™˜ì„± ìˆ˜ì • ì‹¤íŒ¨")
                return False
                
        except Exception as e:
            print(f"âŒ í˜¸í™˜ì„± ìˆ˜ì • ì¤‘ ì˜¤ë¥˜: {e}")
            return False
    
    def _fix_model_structure(self, model_data: Any, info: AIModelInfo) -> Optional[Any]:
        """ëª¨ë¸ êµ¬ì¡° ìˆ˜ì •"""
        try:
            if isinstance(model_data, dict):
                # 1. state_dict í‚¤ ë§¤í•‘ ìˆ˜ì •
                if 'state_dict' in model_data:
                    state_dict = model_data['state_dict']
                    fixed_state_dict = self._fix_state_dict_keys(state_dict)
                    model_data['state_dict'] = fixed_state_dict
                    return model_data
                
                # 2. ì§ì ‘ ë”•ì…”ë„ˆë¦¬ì¸ ê²½ìš°
                else:
                    fixed_dict = self._fix_state_dict_keys(model_data)
                    return {'state_dict': fixed_dict}
            
            elif hasattr(model_data, 'state_dict'):
                # TorchScript ëª¨ë¸
                state_dict = model_data.state_dict()
                fixed_state_dict = self._fix_state_dict_keys(state_dict)
                return {'state_dict': fixed_state_dict}
            
            else:
                return model_data
                
        except Exception as e:
            print(f"âŒ êµ¬ì¡° ìˆ˜ì • ì¤‘ ì˜¤ë¥˜: {e}")
            return None
    
    def _fix_state_dict_keys(self, state_dict: Dict[str, Any]) -> Dict[str, Any]:
        """state_dict í‚¤ ìˆ˜ì •"""
        fixed_state_dict = {}
        
        # í‚¤ ë§¤í•‘ ê·œì¹™
        key_mappings = {
            # TPS ê´€ë ¨ í‚¤ ë§¤í•‘
            'control_points': 'tps_control_points',
            'weights': 'tps_weights', 
            'affine_params': 'tps_affine_params',
            
            # GMM ê´€ë ¨ í‚¤ ë§¤í•‘
            'pretrained.model': 'backbone',
            'feature_extraction': 'encoder',
            'regression': 'decoder',
            
            # ì¼ë°˜ì ì¸ í‚¤ ë§¤í•‘
            'module.': '',  # DataParallel ì œê±°
            'model.': '',   # ëª¨ë¸ ë˜í¼ ì œê±°
        }
        
        for key, tensor in state_dict.items():
            new_key = key
            
            # í‚¤ ë§¤í•‘ ì ìš©
            for old_pattern, new_pattern in key_mappings.items():
                if old_pattern in new_key:
                    new_key = new_key.replace(old_pattern, new_pattern)
                    break
            
            fixed_state_dict[new_key] = tensor
        
        return fixed_state_dict
    
    def generate_comprehensive_report(self) -> str:
        """ì¢…í•© ë¦¬í¬íŠ¸ ìƒì„±"""
        report = []
        report.append("ğŸ”¥ ì¢…í•© AI ëª¨ë¸ ë¶„ì„ ë¦¬í¬íŠ¸")
        report.append("=" * 80)
        report.append(f"ğŸ“… ë¶„ì„ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        report.append("")
        
        # ì „ì²´ í†µê³„
        total = len(self.models)
        valid = sum(1 for info in self.models.values() if info.valid)
        invalid = total - valid
        
        report.append(f"ğŸ“Š ì „ì²´ AI ëª¨ë¸: {total}ê°œ")
        report.append(f"âœ… ìœ íš¨í•œ ëª¨ë¸: {valid}ê°œ")
        report.append(f"âŒ ë¬´íš¨í•œ ëª¨ë¸: {invalid}ê°œ")
        report.append("")
        
        # Stepë³„ ìš”ì•½
        report.append("ğŸ¯ Stepë³„ ëª¨ë¸ í˜„í™©:")
        for step_key, step_info in self.step_categories.items():
            step_models = [info for info in self.models.values() if info.step_category == step_key]
            if step_models:
                step_valid = sum(1 for info in step_models if info.valid)
                step_invalid = len(step_models) - step_valid
                report.append(f"   {step_info['name']} ({step_key}): {len(step_models)}ê°œ (âœ…{step_valid}ê°œ, âŒ{step_invalid}ê°œ)")
        report.append("")
        
        # ì•„í‚¤í…ì²˜ë³„ ìš”ì•½
        architecture_counts = {}
        for info in self.models.values():
            for hint in info.architecture_hints:
                arch_name = hint.split(' (')[0]
                architecture_counts[arch_name] = architecture_counts.get(arch_name, 0) + 1
        
        if architecture_counts:
            report.append("ğŸ—ï¸ ì•„í‚¤í…ì²˜ë³„ ë¶„í¬:")
            for arch, count in sorted(architecture_counts.items(), key=lambda x: x[1], reverse=True):
                report.append(f"   {arch}: {count}ê°œ")
            report.append("")
        
        # ë¬¸ì œì ë³„ ìš”ì•½
        issue_counts = {}
        for info in self.models.values():
            for issue in info.issues:
                issue_counts[issue] = issue_counts.get(issue, 0) + 1
        
        if issue_counts:
            report.append("ğŸš¨ ì£¼ìš” ë¬¸ì œì :")
            for issue, count in sorted(issue_counts.items(), key=lambda x: x[1], reverse=True)[:10]:
                report.append(f"   {issue}: {count}ê°œ")
            report.append("")
        
        # ìƒì„¸ ë¶„ì„ ê²°ê³¼
        report.append("ğŸ“‹ ìƒì„¸ ë¶„ì„ ê²°ê³¼:")
        for model_path, info in self.models.items():
            status = "âœ…" if info.valid else "âŒ"
            step_name = self.step_categories.get(info.step_category, {}).get('name', info.step_category)
            report.append(f"{status} {Path(model_path).name}")
            report.append(f"   ğŸ“ í¬ê¸°: {info.size_mb:.1f}MB")
            report.append(f"   ğŸ¯ Step: {step_name}")
            report.append(f"   ğŸ—ï¸ êµ¬ì¡°: {info.structure_type}")
            
            if info.architecture_hints:
                report.append(f"   ğŸ›ï¸ ì•„í‚¤í…ì²˜: {', '.join(info.architecture_hints)}")
            
            if info.issues:
                report.append(f"   âš ï¸ ë¬¸ì œì : {', '.join(info.issues)}")
            
            if info.recommendations:
                report.append(f"   ğŸ’¡ ê¶Œì¥ì‚¬í•­: {', '.join(info.recommendations)}")
            
            report.append("")
        
        return "\n".join(report)
    
    def save_analysis_results(self, output_path: str = "comprehensive_ai_model_analysis.json"):
        """ë¶„ì„ ê²°ê³¼ ì €ì¥"""
        results = {
            'analysis_time': datetime.now().isoformat(),
            'total_models': len(self.models),
            'valid_models': sum(1 for info in self.models.values() if info.valid),
            'invalid_models': sum(1 for info in self.models.values() if not info.valid),
            'models': {}
        }
        
        for model_path, info in self.models.items():
            results['models'][model_path] = {
                'size_mb': info.size_mb,
                'exists': info.exists,
                'valid': info.valid,
                'structure_type': info.structure_type,
                'architecture_hints': info.architecture_hints,
                'issues': info.issues,
                'recommendations': info.recommendations,
                'step_category': info.step_category,
                'model_type': info.model_type,
                'fixed': info.fixed
            }
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, ensure_ascii=False)
        
        print(f"ğŸ’¾ ë¶„ì„ ê²°ê³¼ ì €ì¥: {output_path}")

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("ğŸ”¥ ì¢…í•© AI ëª¨ë¸ ë¶„ì„ ë° ì—…ë°ì´íŠ¸ ë„êµ¬")
    print("=" * 80)
    
    # ë¶„ì„ê¸° ì´ˆê¸°í™”
    analyzer = ComprehensiveAIModelAnalyzer()
    
    # 1. ëª¨ë“  AI ëª¨ë¸ ë¶„ì„
    print("\nğŸ“‹ 1ë‹¨ê³„: ëª¨ë“  AI ëª¨ë¸ ë¶„ì„")
    results = analyzer.analyze_all_models()
    
    # 2. ë¶„ì„ ê²°ê³¼ ì¶œë ¥
    print("\nğŸ“Š ë¶„ì„ ê²°ê³¼:")
    print(f"   ì´ AI ëª¨ë¸: {results['total_models']}ê°œ")
    print(f"   ìœ íš¨í•œ ëª¨ë¸: {results['valid_models']}ê°œ")
    print(f"   ë¬´íš¨í•œ ëª¨ë¸: {results['invalid_models']}ê°œ")
    
    # 3. Stepë³„ í˜„í™© ì¶œë ¥
    print("\nğŸ¯ Stepë³„ í˜„í™©:")
    for step_key, step_info in analyzer.step_categories.items():
        step_models = [info for info in analyzer.models.values() if info.step_category == step_key]
        if step_models:
            step_valid = sum(1 for info in step_models if info.valid)
            step_invalid = len(step_models) - step_valid
            print(f"   {step_info['name']}: {len(step_models)}ê°œ (âœ…{step_valid}ê°œ, âŒ{step_invalid}ê°œ)")
    
    # 4. í˜¸í™˜ì„± ìˆ˜ì • ì‹œë„
    print("\nğŸ”§ 2ë‹¨ê³„: í˜¸í™˜ì„± ìˆ˜ì • ì‹œë„")
    fixed_count = 0
    
    for model_path, info in analyzer.models.items():
        if not info.valid and info.exists:
            if analyzer.fix_model_compatibility(model_path):
                fixed_count += 1
    
    print(f"\nâœ… ìˆ˜ì • ì™„ë£Œ: {fixed_count}ê°œ")
    
    # 5. ìµœì¢… ë¦¬í¬íŠ¸ ìƒì„±
    print("\nğŸ“‹ 3ë‹¨ê³„: ìµœì¢… ë¦¬í¬íŠ¸ ìƒì„±")
    report = analyzer.generate_comprehensive_report()
    print(report)
    
    # 6. ê²°ê³¼ ì €ì¥
    analyzer.save_analysis_results()
    
    print("\nğŸ‰ ì¢…í•© AI ëª¨ë¸ ë¶„ì„ ë° ìˆ˜ì • ì™„ë£Œ!")

if __name__ == "__main__":
    main()
