#!/usr/bin/env python3
"""
π” μ²΄ν¬ν¬μΈνΈ ν‚¤ κµ¬μ΅° λ””λ²„κΉ…
================================================================================
β… μ‹¤μ  μ²΄ν¬ν¬μΈνΈ ν‚¤ κµ¬μ΅° ν™•μΈ
β… μƒμ„±λ λ¨λΈ ν‚¤ κµ¬μ΅° ν™•μΈ
β… ν‚¤ λ§¤μΉ­ λ¶„μ„
================================================================================
"""

import os
import sys
import torch
from pathlib import Path

# ν”„λ΅μ νΈ κ²½λ΅ μ„¤μ •
current_file = Path(__file__).resolve()
backend_root = current_file.parent
sys.path.insert(0, str(backend_root))
sys.path.insert(0, str(backend_root / "app"))

def debug_checkpoint_keys():
    """μ²΄ν¬ν¬μΈνΈ ν‚¤ κµ¬μ΅° λ””λ²„κΉ…"""
    print("π” μ²΄ν¬ν¬μΈνΈ ν‚¤ κµ¬μ΅° λ””λ²„κΉ…")
    print("=" * 80)
    
    try:
        # 1. μ‹¤μ  μ²΄ν¬ν¬μΈνΈ λ΅λ”©
        checkpoint_path = backend_root / "ai_models" / "openpose.pth"
        
        if not checkpoint_path.exists():
            print(f"β μ²΄ν¬ν¬μΈνΈ νμΌμ΄ μ΅΄μ¬ν•μ§€ μ•μ: {checkpoint_path}")
            return
        
        print(f"π“ μ²΄ν¬ν¬μΈνΈ: {checkpoint_path.name}")
        checkpoint = torch.load(checkpoint_path, map_location='cpu')
        
        # state_dict μ¶”μ¶
        if 'model' in checkpoint:
            state_dict = checkpoint['model']
        else:
            state_dict = checkpoint
        
        print(f"π“ μ‹¤μ  μ²΄ν¬ν¬μΈνΈ ν‚¤ μ: {len(state_dict)}")
        print("π” μ‹¤μ  μ²΄ν¬ν¬μΈνΈ ν‚¤λ“¤:")
        for key in sorted(state_dict.keys()):
            tensor = state_dict[key]
            if hasattr(tensor, 'shape'):
                print(f"   {key}: {tensor.shape}")
        
        # 2. μƒμ„±λ λ¨λΈ λ΅λ”©
        print(f"\nπ—οΈ μƒμ„±λ λ¨λΈ ν‚¤ κµ¬μ΅°:")
        from app.ai_pipeline.utils.model_architectures import OpenPoseModel
        
        model = OpenPoseModel()
        model_state_dict = model.state_dict()
        
        print(f"π“ μƒμ„±λ λ¨λΈ ν‚¤ μ: {len(model_state_dict)}")
        print("π” μƒμ„±λ λ¨λΈ ν‚¤λ“¤:")
        for key in sorted(model_state_dict.keys()):
            tensor = model_state_dict[key]
            if hasattr(tensor, 'shape'):
                print(f"   {key}: {tensor.shape}")
        
        # 3. ν‚¤ λ§¤μΉ­ λ¶„μ„
        print(f"\nπ” ν‚¤ λ§¤μΉ­ λ¶„μ„:")
        matched_keys = []
        unmatched_checkpoint_keys = []
        unmatched_model_keys = []
        
        for key in state_dict.keys():
            if key in model_state_dict:
                matched_keys.append(key)
            else:
                unmatched_checkpoint_keys.append(key)
        
        for key in model_state_dict.keys():
            if key not in state_dict:
                unmatched_model_keys.append(key)
        
        print(f"β… λ§¤μΉ­λ ν‚¤: {len(matched_keys)}κ°")
        for key in matched_keys:
            print(f"   β… {key}")
        
        print(f"β μ²΄ν¬ν¬μΈνΈμ—λ§ μλ” ν‚¤: {len(unmatched_checkpoint_keys)}κ°")
        for key in unmatched_checkpoint_keys[:5]:  # μ²μ 5κ°λ§
            print(f"   β {key}")
        
        print(f"β λ¨λΈμ—λ§ μλ” ν‚¤: {len(unmatched_model_keys)}κ°")
        for key in unmatched_model_keys[:5]:  # μ²μ 5κ°λ§
            print(f"   β {key}")
        
        # 4. λ§¤μΉ­λ¥  κ³„μ‚°
        match_rate = len(matched_keys) / len(model_state_dict) if model_state_dict else 0
        print(f"\nπ“ λ§¤μΉ­λ¥ : {match_rate:.1%} ({len(matched_keys)}/{len(model_state_dict)})")
        
        return {
            'checkpoint_keys': list(state_dict.keys()),
            'model_keys': list(model_state_dict.keys()),
            'matched_keys': matched_keys,
            'match_rate': match_rate
        }
        
    except Exception as e:
        print(f"β λ””λ²„κΉ… μ‹¤ν¨: {e}")
        return None

if __name__ == "__main__":
    debug_checkpoint_keys()
