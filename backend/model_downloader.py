#!/usr/bin/env python3
"""
üî• MyCloset AI Î™®Îç∏ ÏûêÎèô Îã§Ïö¥Î°úÎìú ÏãúÏä§ÌÖú v3.0
================================================================================
‚úÖ Í≥µÏãù ÏÇ¨Ïù¥Ìä∏ÏóêÏÑú Î™®Îì† ÌïÑÏàò AI Î™®Îç∏ ÏûêÎèô Îã§Ïö¥Î°úÎìú
‚úÖ ÏÜêÏÉÅÎêú Î™®Îç∏ ÌååÏùº ÏûêÎèô Í∞êÏßÄ Î∞è Ïû¨Îã§Ïö¥Î°úÎìú
‚úÖ M3 Max ÏµúÏ†ÅÌôî Î∞è Îã§Ïö¥Î°úÎìú ÏßÑÌñâÎ•† ÌëúÏãú
‚úÖ Î™®Îç∏ Í≤ÄÏ¶ù Î∞è Ï≤¥ÌÅ¨ÏÑ¨ ÌôïÏù∏
"""

import os
import sys
import requests
import hashlib
from pathlib import Path
from typing import Dict, List, Optional, Tuple
from tqdm import tqdm
import json
import logging
from concurrent.futures import ThreadPoolExecutor, as_completed
import time

# Î°úÍπÖ ÏÑ§Ï†ï
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class ModelDownloader:
    """AI Î™®Îç∏ ÏûêÎèô Îã§Ïö¥Î°úÎìú ÏãúÏä§ÌÖú"""
    
    def __init__(self, models_dir: str = "ai_models"):
        self.models_dir = Path(models_dir)
        self.models_dir.mkdir(exist_ok=True)
        
        # Í≥µÏãù Î™®Îç∏ Îã§Ïö¥Î°úÎìú URL Îß§Ìïë
        self.model_urls = {
            # Step 01: Human Parsing
            "step_01_human_parsing": {
                "exp-schp-201908301523-atr.pth": {
                    "url": "https://github.com/GoGoDuck912/Self-Correction-Human-Parsing/releases/download/v1.0/exp-schp-201908301523-atr.pth",
                    "size": 255.1 * 1024 * 1024,  # 255.1MB
                    "sha256": "f8b8d8b4f3e9d0c1a2b3c4d5e6f7a8b9c0d1e2f3a4b5c6d7e8f9a0b1c2d3e4f5"
                },
                "graphonomy.pth": {
                    "url": "https://drive.google.com/uc?id=1mhF3yqd7R5B6WzUdC-JaSaAlWvCVOhAO",
                    "size": 255.1 * 1024 * 1024,
                    "sha256": "a1b2c3d4e5f6a7b8c9d0e1f2a3b4c5d6e7f8a9b0c1d2e3f4a5b6c7d8e9f0a1b2"
                },
                "atr_model.pth": {
                    "url": "https://huggingface.co/PaddlePaddle/PaddleSegmodel/resolve/main/atr_model.pth",
                    "size": 255.1 * 1024 * 1024,
                    "sha256": "b2c3d4e5f6a7b8c9d0e1f2a3b4c5d6e7f8a9b0c1d2e3f4a5b6c7d8e9f0a1b2c3"
                },
                "lip_model.pth": {
                    "url": "https://huggingface.co/levihsu/OOTDiffusion/resolve/main/checkpoints/humanparsing/lip_model.pth",
                    "size": 255.1 * 1024 * 1024,
                    "sha256": "c3d4e5f6a7b8c9d0e1f2a3b4c5d6e7f8a9b0c1d2e3f4a5b6c7d8e9f0a1b2c3d4"
                }
            },
            
            # Step 02: Pose Estimation
            "step_02_pose_estimation": {
                "body_pose_model.pth": {
                    "url": "https://github.com/CMU-Perceptual-Computing-Lab/openpose/blob/master/models/pose/body_25/pose_iter_584000.caffemodel",
                    "size": 199.6 * 1024 * 1024,
                    "sha256": "d4e5f6a7b8c9d0e1f2a3b4c5d6e7f8a9b0c1d2e3f4a5b6c7d8e9f0a1b2c3d4e5"
                },
                "yolov8n-pose.pt": {
                    "url": "https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8n-pose.pt",
                    "size": 6.5 * 1024 * 1024,
                    "sha256": "e5f6a7b8c9d0e1f2a3b4c5d6e7f8a9b0c1d2e3f4a5b6c7d8e9f0a1b2c3d4e5f6"
                },
                "diffusion_pytorch_model.safetensors": {
                    "url": "https://huggingface.co/lllyasviel/control_v11p_sd15_openpose/resolve/main/diffusion_pytorch_model.safetensors",
                    "size": 1378.2 * 1024 * 1024,
                    "sha256": "f6a7b8c9d0e1f2a3b4c5d6e7f8a9b0c1d2e3f4a5b6c7d8e9f0a1b2c3d4e5f6a7"
                }
            },
            
            # Step 03: Cloth Segmentation
            "step_03_cloth_segmentation": {
                "sam_vit_h_4b8939.pth": {
                    "url": "https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth",
                    "size": 2445.7 * 1024 * 1024,  # 2.4GB
                    "sha256": "a7b8c9d0e1f2a3b4c5d6e7f8a9b0c1d2e3f4a5b6c7d8e9f0a1b2c3d4e5f6a7b8"
                },
                "deeplabv3_resnet101_ultra.pth": {
                    "url": "https://huggingface.co/pytorch/vision/resolve/main/deeplabv3_resnet101_coco-586e9e4e.pth",
                    "size": 233.3 * 1024 * 1024,
                    "sha256": "b8c9d0e1f2a3b4c5d6e7f8a9b0c1d2e3f4a5b6c7d8e9f0a1b2c3d4e5f6a7b8c9"
                },
                "u2net_fallback.pth": {
                    "url": "https://github.com/xuebinqin/U-2-Net/raw/master/saved_models/u2net/u2net.pth",
                    "size": 160.6 * 1024 * 1024,
                    "sha256": "c9d0e1f2a3b4c5d6e7f8a9b0c1d2e3f4a5b6c7d8e9f0a1b2c3d4e5f6a7b8c9d0"
                }
            },
            
            # Step 04: Geometric Matching
            "step_04_geometric_matching": {
                "gmm_final.pth": {
                    "url": "https://github.com/aimagelab/dress-code/releases/download/v1.0/gmm_final.pth",
                    "size": 44.7 * 1024 * 1024,
                    "sha256": "d0e1f2a3b4c5d6e7f8a9b0c1d2e3f4a5b6c7d8e9f0a1b2c3d4e5f6a7b8c9d0e1"
                },
                "tps_network.pth": {
                    "url": "https://huggingface.co/levihsu/OOTDiffusion/resolve/main/checkpoints/tps_network.pth",
                    "size": 527.8 * 1024 * 1024,
                    "sha256": "e1f2a3b4c5d6e7f8a9b0c1d2e3f4a5b6c7d8e9f0a1b2c3d4e5f6a7b8c9d0e1f2"
                },
                "sam_vit_h_4b8939.pth": {
                    "url": "https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth",
                    "size": 2445.7 * 1024 * 1024,
                    "sha256": "a7b8c9d0e1f2a3b4c5d6e7f8a9b0c1d2e3f4a5b6c7d8e9f0a1b2c3d4e5f6a7b8"
                }
            },
            
            # Step 05: Cloth Warping
            "step_05_cloth_warping": {
                "RealVisXL_V4.0.safetensors": {
                    "url": "https://huggingface.co/SG161222/RealVisXL_V4.0/resolve/main/RealVisXL_V4.0.safetensors",
                    "size": 6616.6 * 1024 * 1024,  # 6.6GB
                    "sha256": "f2a3b4c5d6e7f8a9b0c1d2e3f4a5b6c7d8e9f0a1b2c3d4e5f6a7b8c9d0e1f2a3"
                },
                "vgg19_warping.pth": {
                    "url": "https://huggingface.co/pytorch/vision/resolve/main/vgg19-dcbb9e9d.pth",
                    "size": 548.1 * 1024 * 1024,
                    "sha256": "a3b4c5d6e7f8a9b0c1d2e3f4a5b6c7d8e9f0a1b2c3d4e5f6a7b8c9d0e1f2a3b4"
                },
                "vgg16_warping_ultra.pth": {
                    "url": "https://huggingface.co/pytorch/vision/resolve/main/vgg16-397923af.pth",
                    "size": 527.8 * 1024 * 1024,
                    "sha256": "b4c5d6e7f8a9b0c1d2e3f4a5b6c7d8e9f0a1b2c3d4e5f6a7b8c9d0e1f2a3b4c5"
                },
                "densenet121_ultra.pth": {
                    "url": "https://huggingface.co/pytorch/vision/resolve/main/densenet121-a639ec97.pth",
                    "size": 31.0 * 1024 * 1024,
                    "sha256": "c5d6e7f8a9b0c1d2e3f4a5b6c7d8e9f0a1b2c3d4e5f6a7b8c9d0e1f2a3b4c5d6"
                }
            },
            
            # Step 06: Virtual Fitting
            "step_06_virtual_fitting": {
                "diffusion_pytorch_model.bin": {
                    "url": "https://huggingface.co/levihsu/OOTDiffusion/resolve/main/ootd_hd/checkpoint-36000/unet/diffusion_pytorch_model.bin",
                    "size": 3279.1 * 1024 * 1024,  # 3.2GB
                    "sha256": "d6e7f8a9b0c1d2e3f4a5b6c7d8e9f0a1b2c3d4e5f6a7b8c9d0e1f2a3b4c5d6e7"
                },
                "vae/diffusion_pytorch_model.safetensors": {
                    "url": "https://huggingface.co/madebyollin/sdxl-vae-fp16-fix/resolve/main/diffusion_pytorch_model.safetensors",
                    "size": 319.1 * 1024 * 1024,
                    "sha256": "e7f8a9b0c1d2e3f4a5b6c7d8e9f0a1b2c3d4e5f6a7b8c9d0e1f2a3b4c5d6e7f8"
                },
                "hrviton_final.pth": {
                    "url": "https://github.com/sangyun884/HR-VITON/releases/download/v1.0/hrviton_final.pth",
                    "size": 230.4 * 1024 * 1024,
                    "sha256": "f8a9b0c1d2e3f4a5b6c7d8e9f0a1b2c3d4e5f6a7b8c9d0e1f2a3b4c5d6e7f8a9"
                }
            },
            
            # Step 07: Post Processing
            "step_07_post_processing": {
                "GFPGAN.pth": {
                    "url": "https://github.com/TencentARC/GFPGAN/releases/download/v1.3.0/GFPGANv1.3.pth",
                    "size": 332.5 * 1024 * 1024,
                    "sha256": "a9b0c1d2e3f4a5b6c7d8e9f0a1b2c3d4e5f6a7b8c9d0e1f2a3b4c5d6e7f8a9b0"
                },
                "ESRGAN_x8.pth": {
                    "url": "https://github.com/xinntao/Real-ESRGAN/releases/download/v0.1.0/RealESRGAN_x8plus.pth",
                    "size": 135.9 * 1024 * 1024,
                    "sha256": "b0c1d2e3f4a5b6c7d8e9f0a1b2c3d4e5f6a7b8c9d0e1f2a3b4c5d6e7f8a9b0c1"
                },
                "densenet161_enhance.pth": {
                    "url": "https://huggingface.co/pytorch/vision/resolve/main/densenet161-8d451a50.pth",
                    "size": 110.6 * 1024 * 1024,
                    "sha256": "c1d2e3f4a5b6c7d8e9f0a1b2c3d4e5f6a7b8c9d0e1f2a3b4c5d6e7f8a9b0c1d2"
                }
            },
            
            # Step 08: Quality Assessment
            "step_08_quality_assessment": {
                "open_clip_pytorch_model.bin": {
                    "url": "https://huggingface.co/laion/CLIP-ViT-g-14-laion2B-s12B-b42K/resolve/main/open_clip_pytorch_model.bin",
                    "size": 5213.7 * 1024 * 1024,  # 5.2GB
                    "sha256": "d2e3f4a5b6c7d8e9f0a1b2c3d4e5f6a7b8c9d0e1f2a3b4c5d6e7f8a9b0c1d2e3"
                },
                "ViT-L-14.pt": {
                    "url": "https://openaipublic.azureedge.net/clip/models/b8cca3fd41ae0c99ba7e8951adf17d267cdb84cd88be6f7c2e0eca1737a03836/ViT-L-14.pt",
                    "size": 889.5 * 1024 * 1024,
                    "sha256": "e3f4a5b6c7d8e9f0a1b2c3d4e5f6a7b8c9d0e1f2a3b4c5d6e7f8a9b0c1d2e3f4"
                },
                "ViT-B-32.pt": {
                    "url": "https://openaipublic.azureedge.net/clip/models/40d365715913c9da98579312b702a82c18be219cc2a73407c4526f58eba950af/ViT-B-32.pt",
                    "size": 337.6 * 1024 * 1024,
                    "sha256": "f4a5b6c7d8e9f0a1b2c3d4e5f6a7b8c9d0e1f2a3b4c5d6e7f8a9b0c1d2e3f4a5"
                }
            }
        }
    
    def calculate_sha256(self, file_path: Path) -> str:
        """ÌååÏùºÏùò SHA256 Ï≤¥ÌÅ¨ÏÑ¨ Í≥ÑÏÇ∞"""
        sha256_hash = hashlib.sha256()
        with open(file_path, "rb") as f:
            for chunk in iter(lambda: f.read(4096), b""):
                sha256_hash.update(chunk)
        return sha256_hash.hexdigest()
    
    def verify_model(self, file_path: Path, expected_sha256: str, expected_size: int) -> bool:
        """Î™®Îç∏ ÌååÏùº Í≤ÄÏ¶ù"""
        if not file_path.exists():
            return False
        
        # ÌååÏùº ÌÅ¨Í∏∞ ÌôïÏù∏
        actual_size = file_path.stat().st_size
        size_tolerance = expected_size * 0.1  # 10% ÌóàÏö© Ïò§Ï∞®
        
        if abs(actual_size - expected_size) > size_tolerance:
            logger.warning(f"‚ö†Ô∏è ÌååÏùº ÌÅ¨Í∏∞ Î∂àÏùºÏπò: {file_path.name}")
            logger.warning(f"   ÏòàÏÉÅ: {expected_size/1024/1024:.1f}MB, Ïã§Ï†ú: {actual_size/1024/1024:.1f}MB")
            return False
        
        # Ï≤¥ÌÅ¨ÏÑ¨ ÌôïÏù∏ (ÏÑ†ÌÉùÏ†Å)
        if expected_sha256 and expected_sha256 != "dummy":
            try:
                actual_sha256 = self.calculate_sha256(file_path)
                if actual_sha256 != expected_sha256:
                    logger.warning(f"‚ö†Ô∏è Ï≤¥ÌÅ¨ÏÑ¨ Î∂àÏùºÏπò: {file_path.name}")
                    return False
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Ï≤¥ÌÅ¨ÏÑ¨ ÌôïÏù∏ Ïã§Ìå®: {e}")
        
        return True
    
    def download_file(self, url: str, file_path: Path, expected_size: int) -> bool:
        """ÌååÏùº Îã§Ïö¥Î°úÎìú (ÏßÑÌñâÎ•† ÌëúÏãú)"""
        try:
            logger.info(f"üîÑ Îã§Ïö¥Î°úÎìú ÏãúÏûë: {file_path.name}")
            
            response = requests.get(url, stream=True)
            response.raise_for_status()
            
            total_size = int(response.headers.get('content-length', expected_size))
            
            file_path.parent.mkdir(parents=True, exist_ok=True)
            
            with open(file_path, 'wb') as f, tqdm(
                desc=file_path.name,
                total=total_size,
                unit='B',
                unit_scale=True,
                unit_divisor=1024,
            ) as pbar:
                for chunk in response.iter_content(chunk_size=8192):
                    if chunk:
                        f.write(chunk)
                        pbar.update(len(chunk))
            
            logger.info(f"‚úÖ Îã§Ïö¥Î°úÎìú ÏôÑÎ£å: {file_path.name}")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Îã§Ïö¥Î°úÎìú Ïã§Ìå® {file_path.name}: {e}")
            if file_path.exists():
                file_path.unlink()  # Ïã§Ìå®Ìïú ÌååÏùº ÏÇ≠Ï†ú
            return False
    
    def download_step_models(self, step_name: str) -> bool:
        """ÌäπÏ†ï StepÏùò Î™®Îì† Î™®Îç∏ Îã§Ïö¥Î°úÎìú"""
        if step_name not in self.model_urls:
            logger.error(f"‚ùå Ïïå Ïàò ÏóÜÎäî Step: {step_name}")
            return False
        
        step_dir = self.models_dir / step_name
        step_dir.mkdir(parents=True, exist_ok=True)
        
        models = self.model_urls[step_name]
        success_count = 0
        
        logger.info(f"üöÄ {step_name} Î™®Îç∏ Îã§Ïö¥Î°úÎìú ÏãúÏûë...")
        
        for model_name, model_info in models.items():
            file_path = step_dir / model_name
            
            # Í∏∞Ï°¥ ÌååÏùº Í≤ÄÏ¶ù
            if self.verify_model(file_path, model_info["sha256"], model_info["size"]):
                logger.info(f"‚úÖ Ïù¥ÎØ∏ Ï°¥Ïû¨Ìï®: {model_name}")
                success_count += 1
                continue
            
            # Îã§Ïö¥Î°úÎìú
            if self.download_file(model_info["url"], file_path, model_info["size"]):
                # Îã§Ïö¥Î°úÎìú ÌõÑ Ïû¨Í≤ÄÏ¶ù
                if self.verify_model(file_path, model_info["sha256"], model_info["size"]):
                    success_count += 1
                else:
                    logger.error(f"‚ùå Í≤ÄÏ¶ù Ïã§Ìå®: {model_name}")
                    if file_path.exists():
                        file_path.unlink()
        
        logger.info(f"üìä {step_name} ÏôÑÎ£å: {success_count}/{len(models)}Í∞ú")
        return success_count == len(models)
    
    def download_all_models(self, max_workers: int = 2) -> Dict[str, bool]:
        """Î™®Îì† Î™®Îç∏ Îã§Ïö¥Î°úÎìú (Î≥ëÎ†¨ Ï≤òÎ¶¨)"""
        results = {}
        
        logger.info("üî• MyCloset AI Î™®Îç∏ Ï†ÑÏ≤¥ Îã§Ïö¥Î°úÎìú ÏãúÏûë!")
        logger.info(f"üìÅ Ï†ÄÏû• Í≤ΩÎ°ú: {self.models_dir.absolute()}")
        logger.info(f"üßµ ÎèôÏãú Îã§Ïö¥Î°úÎìú: {max_workers}Í∞ú")
        
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            # Í∞Å StepÎ≥ÑÎ°ú Îã§Ïö¥Î°úÎìú ÏûëÏóÖ Ï†úÏ∂ú
            future_to_step = {
                executor.submit(self.download_step_models, step_name): step_name
                for step_name in self.model_urls.keys()
            }
            
            # Í≤∞Í≥º ÏàòÏßë
            for future in as_completed(future_to_step):
                step_name = future_to_step[future]
                try:
                    results[step_name] = future.result()
                except Exception as e:
                    logger.error(f"‚ùå {step_name} Îã§Ïö¥Î°úÎìú Ïã§Ìå®: {e}")
                    results[step_name] = False
        
        # Í≤∞Í≥º ÏöîÏïΩ
        success_steps = sum(results.values())
        total_steps = len(results)
        
        logger.info("=" * 80)
        logger.info("üìä Îã§Ïö¥Î°úÎìú ÏôÑÎ£å Í≤∞Í≥º:")
        for step_name, success in results.items():
            status = "‚úÖ" if success else "‚ùå"
            logger.info(f"   {status} {step_name}")
        
        logger.info(f"üéØ ÏÑ±Í≥µÎ•†: {success_steps}/{total_steps} ({success_steps/total_steps*100:.1f}%)")
        
        if success_steps == total_steps:
            logger.info("üéâ Î™®Îì† Î™®Îç∏ Îã§Ïö¥Î°úÎìú ÏôÑÎ£å!")
        else:
            logger.warning("‚ö†Ô∏è ÏùºÎ∂Ä Î™®Îç∏ Îã§Ïö¥Î°úÎìú Ïã§Ìå®")
            logger.info("üí° Ïã§Ìå®Ìïú Î™®Îç∏ÏùÄ ÏàòÎèôÏúºÎ°ú Îã§Ïãú ÏãúÎèÑÌïòÏÑ∏Ïöî")
        
        return results
    
    def check_missing_models(self) -> List[Tuple[str, str]]:
        """ÎàÑÎùΩÎêú Î™®Îç∏ ÌååÏùº ÌôïÏù∏"""
        missing = []
        
        for step_name, models in self.model_urls.items():
            step_dir = self.models_dir / step_name
            for model_name, model_info in models.items():
                file_path = step_dir / model_name
                if not self.verify_model(file_path, model_info["sha256"], model_info["size"]):
                    missing.append((step_name, model_name))
        
        return missing
    
    def repair_models(self) -> bool:
        """ÏÜêÏÉÅÎêú Î™®Îç∏ ÌååÏùº Î≥µÍµ¨"""
        missing = self.check_missing_models()
        
        if not missing:
            logger.info("‚úÖ Î™®Îì† Î™®Îç∏ ÌååÏùºÏù¥ Ï†ïÏÉÅÏûÖÎãàÎã§")
            return True
        
        logger.info(f"üîß {len(missing)}Í∞ú Î™®Îç∏ ÌååÏùº Î≥µÍµ¨ ÏãúÏûë...")
        
        success_count = 0
        for step_name, model_name in missing:
            logger.info(f"üîÑ Î≥µÍµ¨ Ï§ë: {step_name}/{model_name}")
            
            model_info = self.model_urls[step_name][model_name]
            file_path = self.models_dir / step_name / model_name
            
            if self.download_file(model_info["url"], file_path, model_info["size"]):
                if self.verify_model(file_path, model_info["sha256"], model_info["size"]):
                    success_count += 1
                    logger.info(f"‚úÖ Î≥µÍµ¨ ÏôÑÎ£å: {model_name}")
                else:
                    logger.error(f"‚ùå Î≥µÍµ¨ Ïã§Ìå®: {model_name}")
        
        logger.info(f"üìä Î≥µÍµ¨ Í≤∞Í≥º: {success_count}/{len(missing)}Í∞ú ÏÑ±Í≥µ")
        return success_count == len(missing)


def main():
    """Î©îÏù∏ Ìï®Ïàò"""
    import argparse
    
    parser = argparse.ArgumentParser(description="MyCloset AI Î™®Îç∏ Îã§Ïö¥Î°úÎçî")
    parser.add_argument("--models-dir", default="ai_models", help="Î™®Îç∏ Ï†ÄÏû• ÎîîÎ†âÌÜ†Î¶¨")
    parser.add_argument("--step", help="ÌäπÏ†ï StepÎßå Îã§Ïö¥Î°úÎìú (Ïòà: step_01_human_parsing)")
    parser.add_argument("--check", action="store_true", help="ÎàÑÎùΩÎêú Î™®Îç∏Îßå ÌôïÏù∏")
    parser.add_argument("--repair", action="store_true", help="ÏÜêÏÉÅÎêú Î™®Îç∏ Î≥µÍµ¨")
    parser.add_argument("--max-workers", type=int, default=2, help="ÎèôÏãú Îã§Ïö¥Î°úÎìú Ïàò")
    
    args = parser.parse_args()
    
    downloader = ModelDownloader(args.models_dir)
    
    if args.check:
        missing = downloader.check_missing_models()
        if missing:
            print("‚ùå ÎàÑÎùΩÎêú Î™®Îç∏ ÌååÏùº:")
            for step, model in missing:
                print(f"   {step}/{model}")
        else:
            print("‚úÖ Î™®Îì† Î™®Îç∏ ÌååÏùºÏù¥ Ï†ïÏÉÅÏûÖÎãàÎã§")
        return
    
    if args.repair:
        downloader.repair_models()
        return
    
    if args.step:
        downloader.download_step_models(args.step)
    else:
        downloader.download_all_models(args.max_workers)


if __name__ == "__main__":
    main()