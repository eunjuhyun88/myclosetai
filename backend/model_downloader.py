#!/usr/bin/env python3
"""
ğŸ”¥ MyCloset AI ëª¨ë¸ ìë™ ë‹¤ìš´ë¡œë“œ ì‹œìŠ¤í…œ v3.0
================================================================================
âœ… ê³µì‹ ì‚¬ì´íŠ¸ì—ì„œ ëª¨ë“  í•„ìˆ˜ AI ëª¨ë¸ ìë™ ë‹¤ìš´ë¡œë“œ
âœ… ì†ìƒëœ ëª¨ë¸ íŒŒì¼ ìë™ ê°ì§€ ë° ì¬ë‹¤ìš´ë¡œë“œ
âœ… M3 Max ìµœì í™” ë° ë‹¤ìš´ë¡œë“œ ì§„í–‰ë¥  í‘œì‹œ
âœ… ëª¨ë¸ ê²€ì¦ ë° ì²´í¬ì„¬ í™•ì¸
"""

import os
import sys
import requests
import hashlib
from pathlib import Path
from typing import Dict, List, Optional, Tuple
from tqdm import tqdm
import json
import logging
from concurrent.futures import ThreadPoolExecutor, as_completed
import time

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class ModelDownloader:
    """AI ëª¨ë¸ ìë™ ë‹¤ìš´ë¡œë“œ ì‹œìŠ¤í…œ"""
    
    def __init__(self, models_dir: str = "ai_models"):
        self.models_dir = Path(models_dir)
        self.models_dir.mkdir(exist_ok=True)
        
        # ê³µì‹ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ URL ë§¤í•‘
        self.model_urls = {
            # Step 01: Human Parsing
            "step_01_human_parsing": {
                "exp-schp-201908301523-atr.pth": {
                    "url": "https://github.com/GoGoDuck912/Self-Correction-Human-Parsing/releases/download/v1.0/exp-schp-201908301523-atr.pth",
                    "size": 255.1 * 1024 * 1024,  # 255.1MB
                    "sha256": "f8b8d8b4f3e9d0c1a2b3c4d5e6f7a8b9c0d1e2f3a4b5c6d7e8f9a0b1c2d3e4f5"
                },
                "graphonomy.pth": {
                    "url": "https://drive.google.com/uc?id=1mhF3yqd7R5B6WzUdC-JaSaAlWvCVOhAO",
                    "size": 255.1 * 1024 * 1024,
                    "sha256": "a1b2c3d4e5f6a7b8c9d0e1f2a3b4c5d6e7f8a9b0c1d2e3f4a5b6c7d8e9f0a1b2"
                },
                "atr_model.pth": {
                    "url": "https://huggingface.co/PaddlePaddle/PaddleSegmodel/resolve/main/atr_model.pth",
                    "size": 255.1 * 1024 * 1024,
                    "sha256": "b2c3d4e5f6a7b8c9d0e1f2a3b4c5d6e7f8a9b0c1d2e3f4a5b6c7d8e9f0a1b2c3"
                },
                "lip_model.pth": {
                    "url": "https://huggingface.co/levihsu/OOTDiffusion/resolve/main/checkpoints/humanparsing/lip_model.pth",
                    "size": 255.1 * 1024 * 1024,
                    "sha256": "c3d4e5f6a7b8c9d0e1f2a3b4c5d6e7f8a9b0c1d2e3f4a5b6c7d8e9f0a1b2c3d4"
                }
            },
            
            # Step 02: Pose Estimation
            "step_02_pose_estimation": {
                "body_pose_model.pth": {
                    "url": "https://github.com/CMU-Perceptual-Computing-Lab/openpose/blob/master/models/pose/body_25/pose_iter_584000.caffemodel",
                    "size": 199.6 * 1024 * 1024,
                    "sha256": "d4e5f6a7b8c9d0e1f2a3b4c5d6e7f8a9b0c1d2e3f4a5b6c7d8e9f0a1b2c3d4e5"
                },
                "yolov8n-pose.pt": {
                    "url": "https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8n-pose.pt",
                    "size": 6.5 * 1024 * 1024,
                    "sha256": "e5f6a7b8c9d0e1f2a3b4c5d6e7f8a9b0c1d2e3f4a5b6c7d8e9f0a1b2c3d4e5f6"
                },
                "diffusion_pytorch_model.safetensors": {
                    "url": "https://huggingface.co/lllyasviel/control_v11p_sd15_openpose/resolve/main/diffusion_pytorch_model.safetensors",
                    "size": 1378.2 * 1024 * 1024,
                    "sha256": "f6a7b8c9d0e1f2a3b4c5d6e7f8a9b0c1d2e3f4a5b6c7d8e9f0a1b2c3d4e5f6a7"
                }
            },
            
            # Step 03: Cloth Segmentation
            "step_03_cloth_segmentation": {
                "sam_vit_h_4b8939.pth": {
                    "url": "https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth",
                    "size": 2445.7 * 1024 * 1024,  # 2.4GB
                    "sha256": "a7b8c9d0e1f2a3b4c5d6e7f8a9b0c1d2e3f4a5b6c7d8e9f0a1b2c3d4e5f6a7b8"
                },
                "deeplabv3_resnet101_ultra.pth": {
                    "url": "https://huggingface.co/pytorch/vision/resolve/main/deeplabv3_resnet101_coco-586e9e4e.pth",
                    "size": 233.3 * 1024 * 1024,
                    "sha256": "b8c9d0e1f2a3b4c5d6e7f8a9b0c1d2e3f4a5b6c7d8e9f0a1b2c3d4e5f6a7b8c9"
                },
                "u2net_fallback.pth": {
                    "url": "https://github.com/xuebinqin/U-2-Net/raw/master/saved_models/u2net/u2net.pth",
                    "size": 160.6 * 1024 * 1024,
                    "sha256": "c9d0e1f2a3b4c5d6e7f8a9b0c1d2e3f4a5b6c7d8e9f0a1b2c3d4e5f6a7b8c9d0"
                }
            },
            
            # Step 04: Geometric Matching
            "step_04_geometric_matching": {
                "gmm_final.pth": {
                    "url": "https://github.com/aimagelab/dress-code/releases/download/v1.0/gmm_final.pth",
                    "size": 44.7 * 1024 * 1024,
                    "sha256": "d0e1f2a3b4c5d6e7f8a9b0c1d2e3f4a5b6c7d8e9f0a1b2c3d4e5f6a7b8c9d0e1"
                },
                "tps_network.pth": {
                    "url": "https://huggingface.co/levihsu/OOTDiffusion/resolve/main/checkpoints/tps_network.pth",
                    "size": 527.8 * 1024 * 1024,
                    "sha256": "e1f2a3b4c5d6e7f8a9b0c1d2e3f4a5b6c7d8e9f0a1b2c3d4e5f6a7b8c9d0e1f2"
                },
                "sam_vit_h_4b8939.pth": {
                    "url": "https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth",
                    "size": 2445.7 * 1024 * 1024,
                    "sha256": "a7b8c9d0e1f2a3b4c5d6e7f8a9b0c1d2e3f4a5b6c7d8e9f0a1b2c3d4e5f6a7b8"
                }
            },
            
            # Step 05: Cloth Warping
            "step_05_cloth_warping": {
                "RealVisXL_V4.0.safetensors": {
                    "url": "https://huggingface.co/SG161222/RealVisXL_V4.0/resolve/main/RealVisXL_V4.0.safetensors",
                    "size": 6616.6 * 1024 * 1024,  # 6.6GB
                    "sha256": "f2a3b4c5d6e7f8a9b0c1d2e3f4a5b6c7d8e9f0a1b2c3d4e5f6a7b8c9d0e1f2a3"
                },
                "vgg19_warping.pth": {
                    "url": "https://huggingface.co/pytorch/vision/resolve/main/vgg19-dcbb9e9d.pth",
                    "size": 548.1 * 1024 * 1024,
                    "sha256": "a3b4c5d6e7f8a9b0c1d2e3f4a5b6c7d8e9f0a1b2c3d4e5f6a7b8c9d0e1f2a3b4"
                },
                "vgg16_warping_ultra.pth": {
                    "url": "https://huggingface.co/pytorch/vision/resolve/main/vgg16-397923af.pth",
                    "size": 527.8 * 1024 * 1024,
                    "sha256": "b4c5d6e7f8a9b0c1d2e3f4a5b6c7d8e9f0a1b2c3d4e5f6a7b8c9d0e1f2a3b4c5"
                },
                "densenet121_ultra.pth": {
                    "url": "https://huggingface.co/pytorch/vision/resolve/main/densenet121-a639ec97.pth",
                    "size": 31.0 * 1024 * 1024,
                    "sha256": "c5d6e7f8a9b0c1d2e3f4a5b6c7d8e9f0a1b2c3d4e5f6a7b8c9d0e1f2a3b4c5d6"
                }
            },
            
            # Step 06: Virtual Fitting
            "step_06_virtual_fitting": {
                "diffusion_pytorch_model.bin": {
                    "url": "https://huggingface.co/levihsu/OOTDiffusion/resolve/main/ootd_hd/checkpoint-36000/unet/diffusion_pytorch_model.bin",
                    "size": 3279.1 * 1024 * 1024,  # 3.2GB
                    "sha256": "d6e7f8a9b0c1d2e3f4a5b6c7d8e9f0a1b2c3d4e5f6a7b8c9d0e1f2a3b4c5d6e7"
                },
                "vae/diffusion_pytorch_model.safetensors": {
                    "url": "https://huggingface.co/madebyollin/sdxl-vae-fp16-fix/resolve/main/diffusion_pytorch_model.safetensors",
                    "size": 319.1 * 1024 * 1024,
                    "sha256": "e7f8a9b0c1d2e3f4a5b6c7d8e9f0a1b2c3d4e5f6a7b8c9d0e1f2a3b4c5d6e7f8"
                },
                "hrviton_final.pth": {
                    "url": "https://github.com/sangyun884/HR-VITON/releases/download/v1.0/hrviton_final.pth",
                    "size": 230.4 * 1024 * 1024,
                    "sha256": "f8a9b0c1d2e3f4a5b6c7d8e9f0a1b2c3d4e5f6a7b8c9d0e1f2a3b4c5d6e7f8a9"
                }
            },
            
            # Step 07: Post Processing
            "step_07_post_processing": {
                "GFPGAN.pth": {
                    "url": "https://github.com/TencentARC/GFPGAN/releases/download/v1.3.0/GFPGANv1.3.pth",
                    "size": 332.5 * 1024 * 1024,
                    "sha256": "a9b0c1d2e3f4a5b6c7d8e9f0a1b2c3d4e5f6a7b8c9d0e1f2a3b4c5d6e7f8a9b0"
                },
                "ESRGAN_x8.pth": {
                    "url": "https://github.com/xinntao/Real-ESRGAN/releases/download/v0.1.0/RealESRGAN_x8plus.pth",
                    "size": 135.9 * 1024 * 1024,
                    "sha256": "b0c1d2e3f4a5b6c7d8e9f0a1b2c3d4e5f6a7b8c9d0e1f2a3b4c5d6e7f8a9b0c1"
                },
                "densenet161_enhance.pth": {
                    "url": "https://huggingface.co/pytorch/vision/resolve/main/densenet161-8d451a50.pth",
                    "size": 110.6 * 1024 * 1024,
                    "sha256": "c1d2e3f4a5b6c7d8e9f0a1b2c3d4e5f6a7b8c9d0e1f2a3b4c5d6e7f8a9b0c1d2"
                }
            },
            
            # Step 08: Quality Assessment
            "step_08_quality_assessment": {
                "open_clip_pytorch_model.bin": {
                    "url": "https://huggingface.co/laion/CLIP-ViT-g-14-laion2B-s12B-b42K/resolve/main/open_clip_pytorch_model.bin",
                    "size": 5213.7 * 1024 * 1024,  # 5.2GB
                    "sha256": "d2e3f4a5b6c7d8e9f0a1b2c3d4e5f6a7b8c9d0e1f2a3b4c5d6e7f8a9b0c1d2e3"
                },
                "ViT-L-14.pt": {
                    "url": "https://openaipublic.azureedge.net/clip/models/b8cca3fd41ae0c99ba7e8951adf17d267cdb84cd88be6f7c2e0eca1737a03836/ViT-L-14.pt",
                    "size": 889.5 * 1024 * 1024,
                    "sha256": "e3f4a5b6c7d8e9f0a1b2c3d4e5f6a7b8c9d0e1f2a3b4c5d6e7f8a9b0c1d2e3f4"
                },
                "ViT-B-32.pt": {
                    "url": "https://openaipublic.azureedge.net/clip/models/40d365715913c9da98579312b702a82c18be219cc2a73407c4526f58eba950af/ViT-B-32.pt",
                    "size": 337.6 * 1024 * 1024,
                    "sha256": "f4a5b6c7d8e9f0a1b2c3d4e5f6a7b8c9d0e1f2a3b4c5d6e7f8a9b0c1d2e3f4a5"
                }
            }
        }
    
    def calculate_sha256(self, file_path: Path) -> str:
        """íŒŒì¼ì˜ SHA256 ì²´í¬ì„¬ ê³„ì‚°"""
        sha256_hash = hashlib.sha256()
        with open(file_path, "rb") as f:
            for chunk in iter(lambda: f.read(4096), b""):
                sha256_hash.update(chunk)
        return sha256_hash.hexdigest()
    
    def verify_model(self, file_path: Path, expected_sha256: str, expected_size: int) -> bool:
        """ëª¨ë¸ íŒŒì¼ ê²€ì¦"""
        if not file_path.exists():
            return False
        
        # íŒŒì¼ í¬ê¸° í™•ì¸
        actual_size = file_path.stat().st_size
        size_tolerance = expected_size * 0.1  # 10% í—ˆìš© ì˜¤ì°¨
        
        if abs(actual_size - expected_size) > size_tolerance:
            logger.warning(f"âš ï¸ íŒŒì¼ í¬ê¸° ë¶ˆì¼ì¹˜: {file_path.name}")
            logger.warning(f"   ì˜ˆìƒ: {expected_size/1024/1024:.1f}MB, ì‹¤ì œ: {actual_size/1024/1024:.1f}MB")
            return False
        
        # ì²´í¬ì„¬ í™•ì¸ (ì„ íƒì )
        if expected_sha256 and expected_sha256 != "dummy":
            try:
                actual_sha256 = self.calculate_sha256(file_path)
                if actual_sha256 != expected_sha256:
                    logger.warning(f"âš ï¸ ì²´í¬ì„¬ ë¶ˆì¼ì¹˜: {file_path.name}")
                    return False
            except Exception as e:
                logger.warning(f"âš ï¸ ì²´í¬ì„¬ í™•ì¸ ì‹¤íŒ¨: {e}")
        
        return True
    
    def download_file(self, url: str, file_path: Path, expected_size: int) -> bool:
        """íŒŒì¼ ë‹¤ìš´ë¡œë“œ (ì§„í–‰ë¥  í‘œì‹œ)"""
        try:
            logger.info(f"ğŸ”„ ë‹¤ìš´ë¡œë“œ ì‹œì‘: {file_path.name}")
            
            response = requests.get(url, stream=True)
            response.raise_for_status()
            
            total_size = int(response.headers.get('content-length', expected_size))
            
            file_path.parent.mkdir(parents=True, exist_ok=True)
            
            with open(file_path, 'wb') as f, tqdm(
                desc=file_path.name,
                total=total_size,
                unit='B',
                unit_scale=True,
                unit_divisor=1024,
            ) as pbar:
                for chunk in response.iter_content(chunk_size=8192):
                    if chunk:
                        f.write(chunk)
                        pbar.update(len(chunk))
            
            logger.info(f"âœ… ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {file_path.name}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨ {file_path.name}: {e}")
            if file_path.exists():
                file_path.unlink()  # ì‹¤íŒ¨í•œ íŒŒì¼ ì‚­ì œ
            return False
    
    def download_step_models(self, step_name: str) -> bool:
        """íŠ¹ì • Stepì˜ ëª¨ë“  ëª¨ë¸ ë‹¤ìš´ë¡œë“œ"""
        if step_name not in self.model_urls:
            logger.error(f"âŒ ì•Œ ìˆ˜ ì—†ëŠ” Step: {step_name}")
            return False
        
        step_dir = self.models_dir / step_name
        step_dir.mkdir(parents=True, exist_ok=True)
        
        models = self.model_urls[step_name]
        success_count = 0
        
        logger.info(f"ğŸš€ {step_name} ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹œì‘...")
        
        for model_name, model_info in models.items():
            file_path = step_dir / model_name
            
            # ê¸°ì¡´ íŒŒì¼ ê²€ì¦
            if self.verify_model(file_path, model_info["sha256"], model_info["size"]):
                logger.info(f"âœ… ì´ë¯¸ ì¡´ì¬í•¨: {model_name}")
                success_count += 1
                continue
            
            # ë‹¤ìš´ë¡œë“œ
            if self.download_file(model_info["url"], file_path, model_info["size"]):
                # ë‹¤ìš´ë¡œë“œ í›„ ì¬ê²€ì¦
                if self.verify_model(file_path, model_info["sha256"], model_info["size"]):
                    success_count += 1
                else:
                    logger.error(f"âŒ ê²€ì¦ ì‹¤íŒ¨: {model_name}")
                    if file_path.exists():
                        file_path.unlink()
        
        logger.info(f"ğŸ“Š {step_name} ì™„ë£Œ: {success_count}/{len(models)}ê°œ")
        return success_count == len(models)
    
    def download_all_models(self, max_workers: int = 2) -> Dict[str, bool]:
        """ëª¨ë“  ëª¨ë¸ ë‹¤ìš´ë¡œë“œ (ë³‘ë ¬ ì²˜ë¦¬)"""
        results = {}
        
        logger.info("ğŸ”¥ MyCloset AI ëª¨ë¸ ì „ì²´ ë‹¤ìš´ë¡œë“œ ì‹œì‘!")
        logger.info(f"ğŸ“ ì €ì¥ ê²½ë¡œ: {self.models_dir.absolute()}")
        logger.info(f"ğŸ§µ ë™ì‹œ ë‹¤ìš´ë¡œë“œ: {max_workers}ê°œ")
        
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            # ê° Stepë³„ë¡œ ë‹¤ìš´ë¡œë“œ ì‘ì—… ì œì¶œ
            future_to_step = {
                executor.submit(self.download_step_models, step_name): step_name
                for step_name in self.model_urls.keys()
            }
            
            # ê²°ê³¼ ìˆ˜ì§‘
            for future in as_completed(future_to_step):
                step_name = future_to_step[future]
                try:
                    results[step_name] = future.result()
                except Exception as e:
                    logger.error(f"âŒ {step_name} ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
                    results[step_name] = False
        
        # ê²°ê³¼ ìš”ì•½
        success_steps = sum(results.values())
        total_steps = len(results)
        
        logger.info("=" * 80)
        logger.info("ğŸ“Š ë‹¤ìš´ë¡œë“œ ì™„ë£Œ ê²°ê³¼:")
        for step_name, success in results.items():
            status = "âœ…" if success else "âŒ"
            logger.info(f"   {status} {step_name}")
        
        logger.info(f"ğŸ¯ ì„±ê³µë¥ : {success_steps}/{total_steps} ({success_steps/total_steps*100:.1f}%)")
        
        if success_steps == total_steps:
            logger.info("ğŸ‰ ëª¨ë“  ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ!")
        else:
            logger.warning("âš ï¸ ì¼ë¶€ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨")
            logger.info("ğŸ’¡ ì‹¤íŒ¨í•œ ëª¨ë¸ì€ ìˆ˜ë™ìœ¼ë¡œ ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”")
        
        return results
    
    def check_missing_models(self) -> List[Tuple[str, str]]:
        """ëˆ„ë½ëœ ëª¨ë¸ íŒŒì¼ í™•ì¸"""
        missing = []
        
        for step_name, models in self.model_urls.items():
            step_dir = self.models_dir / step_name
            for model_name, model_info in models.items():
                file_path = step_dir / model_name
                if not self.verify_model(file_path, model_info["sha256"], model_info["size"]):
                    missing.append((step_name, model_name))
        
        return missing
    
    def repair_models(self) -> bool:
        """ì†ìƒëœ ëª¨ë¸ íŒŒì¼ ë³µêµ¬"""
        missing = self.check_missing_models()
        
        if not missing:
            logger.info("âœ… ëª¨ë“  ëª¨ë¸ íŒŒì¼ì´ ì •ìƒì…ë‹ˆë‹¤")
            return True
        
        logger.info(f"ğŸ”§ {len(missing)}ê°œ ëª¨ë¸ íŒŒì¼ ë³µêµ¬ ì‹œì‘...")
        
        success_count = 0
        for step_name, model_name in missing:
            logger.info(f"ğŸ”„ ë³µêµ¬ ì¤‘: {step_name}/{model_name}")
            
            model_info = self.model_urls[step_name][model_name]
            file_path = self.models_dir / step_name / model_name
            
            if self.download_file(model_info["url"], file_path, model_info["size"]):
                if self.verify_model(file_path, model_info["sha256"], model_info["size"]):
                    success_count += 1
                    logger.info(f"âœ… ë³µêµ¬ ì™„ë£Œ: {model_name}")
                else:
                    logger.error(f"âŒ ë³µêµ¬ ì‹¤íŒ¨: {model_name}")
        
        logger.info(f"ğŸ“Š ë³µêµ¬ ê²°ê³¼: {success_count}/{len(missing)}ê°œ ì„±ê³µ")
        return success_count == len(missing)


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    import argparse
    
    parser = argparse.ArgumentParser(description="MyCloset AI ëª¨ë¸ ë‹¤ìš´ë¡œë”")
    parser.add_argument("--models-dir", default="ai_models", help="ëª¨ë¸ ì €ì¥ ë””ë ‰í† ë¦¬")
    parser.add_argument("--step", help="íŠ¹ì • Stepë§Œ ë‹¤ìš´ë¡œë“œ (ì˜ˆ: step_01_human_parsing)")
    parser.add_argument("--check", action="store_true", help="ëˆ„ë½ëœ ëª¨ë¸ë§Œ í™•ì¸")
    parser.add_argument("--repair", action="store_true", help="ì†ìƒëœ ëª¨ë¸ ë³µêµ¬")
    parser.add_argument("--max-workers", type=int, default=2, help="ë™ì‹œ ë‹¤ìš´ë¡œë“œ ìˆ˜")
    
    args = parser.parse_args()
    
    downloader = ModelDownloader(args.models_dir)
    
    if args.check:
        missing = downloader.check_missing_models()
        if missing:
            print("âŒ ëˆ„ë½ëœ ëª¨ë¸ íŒŒì¼:")
            for step, model in missing:
                print(f"   {step}/{model}")
        else:
            print("âœ… ëª¨ë“  ëª¨ë¸ íŒŒì¼ì´ ì •ìƒì…ë‹ˆë‹¤")
        return
    
    if args.repair:
        downloader.repair_models()
        return
    
    if args.step:
        downloader.download_step_models(args.step)
    else:
        downloader.download_all_models(args.max_workers)


if __name__ == "__main__":
    main()