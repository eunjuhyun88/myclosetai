#!/usr/bin/env python3
"""
π› οΈ λ¨λΈ λ΅λ”© λ¬Έμ  ν•΄κ²° μ¤ν¬λ¦½νΈ
1. PyTorch νΈν™μ„± ν¨μΉ
2. ν‚¤ λ§¤ν•‘ μ•κ³ λ¦¬μ¦ κ°μ„ 
3. μ²΄ν¬ν¬μΈνΈ κµ¬μ΅° λ¶„μ„ κ°•ν™”
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

def fix_pytorch_compatibility():
    """PyTorch νΈν™μ„± ν¨μΉ"""
    print("π”§ PyTorch νΈν™μ„± ν¨μΉ μ μ©...")
    
    try:
        import torch
        
        # PyTorch 2.7+ νΈν™μ„± ν¨μΉ
        if hasattr(torch, 'load'):
            original_load = torch.load
            
            def safe_load(*args, **kwargs):
                """μ•μ „ν• μ²΄ν¬ν¬μΈνΈ λ΅λ”©"""
                try:
                    # weights_only=Trueλ΅ μ‹λ„
                    kwargs['weights_only'] = True
                    return original_load(*args, **kwargs)
                except Exception as e1:
                    try:
                        # weights_only μ κ±°ν•κ³  λ‹¤μ‹ μ‹λ„
                        kwargs.pop('weights_only', None)
                        return original_load(*args, **kwargs)
                    except Exception as e2:
                        try:
                            # map_location='cpu'λ΅ κ°•μ  μ‹λ„
                            kwargs['map_location'] = 'cpu'
                            return original_load(*args, **kwargs)
                        except Exception as e3:
                            print(f"β οΈ μ²΄ν¬ν¬μΈνΈ λ΅λ”© μ‹¤ν¨: {e3}")
                            return None
            
            torch.load = safe_load
            print("   β… PyTorch νΈν™μ„± ν¨μΉ μ μ© μ™„λ£")
        else:
            print("   β οΈ PyTorch λ΅λ“ ν•¨μλ¥Ό μ°Ύμ„ μ μ—†μ")
            
    except Exception as e:
        print(f"   β PyTorch νΈν™μ„± ν¨μΉ μ‹¤ν¨: {e}")

def improve_key_mapping():
    """ν‚¤ λ§¤ν•‘ μ•κ³ λ¦¬μ¦ κ°μ„ """
    print("\nπ”‘ ν‚¤ λ§¤ν•‘ μ•κ³ λ¦¬μ¦ κ°μ„ ...")
    
    try:
        from app.ai_pipeline.utils.model_loader import KeyMapper
        
        # KeyMapper ν΄λμ¤μ— κ°μ„ λ λ§¤ν•‘ λ©”μ„λ“ μ¶”κ°€
        def enhanced_map_keys(self, checkpoint, target_architecture, model_state_dict):
            """κ°μ„ λ ν‚¤ λ§¤ν•‘"""
            try:
                # State dict μ¶”μ¶
                if 'state_dict' in checkpoint:
                    source_state_dict = checkpoint['state_dict']
                elif 'model' in checkpoint:
                    source_state_dict = checkpoint['model']
                else:
                    source_state_dict = checkpoint
                
                # νΌμ§€ λ§¤μΉ­μ„ μ„ν• ν‚¤ μ •κ·ν™”
                normalized_source = {}
                for key, value in source_state_dict.items():
                    # ν‚¤ μ •κ·ν™” (μ†λ¬Έμ, νΉμλ¬Έμ μ κ±°)
                    normalized_key = key.lower().replace('_', '').replace('.', '')
                    normalized_source[normalized_key] = (key, value)
                
                # νƒ€κ² λ¨λΈ ν‚¤ μ •κ·ν™”
                normalized_target = {}
                for key in model_state_dict.keys():
                    normalized_key = key.lower().replace('_', '').replace('.', '')
                    normalized_target[normalized_key] = key
                
                # λ§¤ν•‘ μν–‰
                mapped_dict = {}
                success_count = 0
                
                for norm_source_key, (orig_source_key, source_value) in normalized_source.items():
                    # μ •ν™• λ§¤μΉ­
                    if norm_source_key in normalized_target:
                        target_key = normalized_target[norm_source_key]
                        mapped_dict[target_key] = source_value
                        success_count += 1
                        continue
                    
                    # λ¶€λ¶„ λ§¤μΉ­
                    for norm_target_key, target_key in normalized_target.items():
                        if (norm_source_key in norm_target_key or 
                            norm_target_key in norm_source_key):
                            # ν…μ„ ν¬κΈ° ν™•μΈ
                            if hasattr(source_value, 'shape') and hasattr(model_state_dict[target_key], 'shape'):
                                if source_value.shape == model_state_dict[target_key].shape:
                                    mapped_dict[target_key] = source_value
                                    success_count += 1
                                    break
                
                print(f"   π“ κ°μ„ λ λ§¤ν•‘ κ²°κ³Ό: {success_count}/{len(model_state_dict)} μ„±κ³µ")
                return mapped_dict
                
            except Exception as e:
                print(f"   β κ°μ„ λ λ§¤ν•‘ μ‹¤ν¨: {e}")
                return {}
        
        # KeyMapperμ— κ°μ„ λ λ©”μ„λ“ μ¶”κ°€
        KeyMapper.enhanced_map_keys = enhanced_map_keys
        print("   β… ν‚¤ λ§¤ν•‘ μ•κ³ λ¦¬μ¦ κ°μ„  μ™„λ£")
        
    except Exception as e:
        print(f"   β ν‚¤ λ§¤ν•‘ κ°μ„  μ‹¤ν¨: {e}")

def enhance_checkpoint_analysis():
    """μ²΄ν¬ν¬μΈνΈ κµ¬μ΅° λ¶„μ„ κ°•ν™”"""
    print("\nπ” μ²΄ν¬ν¬μΈνΈ κµ¬μ΅° λ¶„μ„ κ°•ν™”...")
    
    try:
        from app.ai_pipeline.utils.model_loader import CheckpointAnalyzer
        
        def enhanced_analyze_checkpoint(self, checkpoint_path):
            """κ°•ν™”λ μ²΄ν¬ν¬μΈνΈ λ¶„μ„"""
            try:
                import torch
                
                # μ•μ „ν• λ΅λ”©
                checkpoint = torch.load(checkpoint_path, map_location='cpu', weights_only=True)
                if checkpoint is None:
                    return {}
                
                # State dict μ¶”μ¶
                if 'state_dict' in checkpoint:
                    state_dict = checkpoint['state_dict']
                elif 'model' in checkpoint:
                    state_dict = checkpoint['model']
                else:
                    state_dict = checkpoint
                
                # μƒμ„Έ λ¶„μ„
                analysis = {
                    'architecture_type': self._infer_architecture_type(state_dict, checkpoint_path),
                    'total_params': sum(tensor.numel() for tensor in state_dict.values() if hasattr(tensor, 'numel')),
                    'input_channels': self._infer_input_channels(state_dict),
                    'num_classes': self._infer_num_classes(state_dict),
                    'num_keypoints': self._infer_num_keypoints(state_dict),
                    'num_control_points': self._infer_num_control_points(state_dict),
                    'key_patterns': self._analyze_key_patterns(state_dict),
                    'layer_types': self._analyze_layer_types(state_dict),
                    'model_depth': self._estimate_model_depth(state_dict),
                    'has_batch_norm': self._has_batch_normalization(state_dict),
                    'has_attention': self._has_attention_layers(state_dict),
                    'metadata': self._extract_metadata(checkpoint)
                }
                
                print(f"   π“ κ°•ν™”λ λ¶„μ„ μ™„λ£: {analysis['total_params']:,} νλΌλ―Έν„°")
                return analysis
                
            except Exception as e:
                print(f"   β κ°•ν™”λ λ¶„μ„ μ‹¤ν¨: {e}")
                return {}
        
        # CheckpointAnalyzerμ— κ°•ν™”λ λ©”μ„λ“ μ¶”κ°€
        CheckpointAnalyzer.enhanced_analyze_checkpoint = enhanced_analyze_checkpoint
        print("   β… μ²΄ν¬ν¬μΈνΈ κµ¬μ΅° λ¶„μ„ κ°•ν™” μ™„λ£")
        
    except Exception as e:
        print(f"   β μ²΄ν¬ν¬μΈνΈ λ¶„μ„ κ°•ν™” μ‹¤ν¨: {e}")

def test_improved_loading():
    """κ°μ„ λ λ΅λ”© ν…μ¤νΈ"""
    print("\nπ§ κ°μ„ λ λ΅λ”© ν…μ¤νΈ...")
    
    try:
        from app.ai_pipeline.utils.model_loader import ModelLoader
        
        loader = ModelLoader()
        
        test_cases = [
            ('human_parsing', 'ai_models/step_01_human_parsing/graphonomy.pth'),
            ('pose_estimation', 'ai_models/step_02_pose_estimation/hrnet_w48_coco_384x288.pth'),
            ('cloth_segmentation', 'ai_models/step_03/sam.pth')
        ]
        
        for step, path in test_cases:
            if os.path.exists(path):
                print(f"\n   π”§ {step} κ°μ„ λ λ΅λ”© ν…μ¤νΈ...")
                try:
                    model = loader.load_model_for_step(step, checkpoint_path=path)
                    if model:
                        param_count = sum(p.numel() for p in model.parameters())
                        print(f"      β… λ΅λ”© μ„±κ³µ: {param_count:,} νλΌλ―Έν„°")
                    else:
                        print(f"      β λ΅λ”© μ‹¤ν¨")
                except Exception as e:
                    print(f"      β λ΅λ”© μ¤λ¥: {e}")
            else:
                print(f"   β οΈ {step}: νμΌ μ—†μ ({path})")
        
    except Exception as e:
        print(f"   β κ°μ„ λ λ΅λ”© ν…μ¤νΈ μ‹¤ν¨: {e}")

def main():
    """λ©”μΈ ν•¨μ"""
    print("π› οΈ λ¨λΈ λ΅λ”© λ¬Έμ  ν•΄κ²° μ‹μ‘...")
    print("=" * 60)
    
    # 1. PyTorch νΈν™μ„± ν¨μΉ
    fix_pytorch_compatibility()
    
    # 2. ν‚¤ λ§¤ν•‘ μ•κ³ λ¦¬μ¦ κ°μ„ 
    improve_key_mapping()
    
    # 3. μ²΄ν¬ν¬μΈνΈ κµ¬μ΅° λ¶„μ„ κ°•ν™”
    enhance_checkpoint_analysis()
    
    # 4. κ°μ„ λ λ΅λ”© ν…μ¤νΈ
    test_improved_loading()
    
    print("\n" + "=" * 60)
    print("π‰ λ¨λΈ λ΅λ”© λ¬Έμ  ν•΄κ²° μ™„λ£!")
    print("=" * 60)

if __name__ == "__main__":
    main()
