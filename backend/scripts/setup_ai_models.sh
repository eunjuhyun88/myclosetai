#!/bin/bash
# scripts/setup_ai_models.sh
# MyCloset AI ëª¨ë¸ ì™„ì „ ìë™ ì„¤ì • ìŠ¤í¬ë¦½íŠ¸

set -e  # ì—ëŸ¬ ë°œìƒ ì‹œ ì¤‘ë‹¨

# ìƒ‰ìƒ ì •ì˜
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# ë¡œê·¸ í•¨ìˆ˜ë“¤
log_info() { echo -e "${BLUE}â„¹ï¸  $1${NC}"; }
log_success() { echo -e "${GREEN}âœ… $1${NC}"; }
log_warning() { echo -e "${YELLOW}âš ï¸  $1${NC}"; }
log_error() { echo -e "${RED}âŒ $1${NC}"; }

echo "ğŸ¤– MyCloset AI ëª¨ë¸ ì™„ì „ ì„¤ì • ì‹œì‘"
echo "=================================="

# 1. í™˜ê²½ í™•ì¸
log_info "ì‹œìŠ¤í…œ í™˜ê²½ í™•ì¸ ì¤‘..."

# Python ë²„ì „ í™•ì¸
if ! command -v python3 &> /dev/null; then
    log_error "Python3ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
    exit 1
fi

PYTHON_VERSION=$(python3 --version | cut -d' ' -f2 | cut -d'.' -f1,2)
log_success "Python $PYTHON_VERSION ê°ì§€ë¨"

# GPU í™•ì¸
log_info "GPU í™˜ê²½ í™•ì¸ ì¤‘..."
if command -v nvidia-smi &> /dev/null; then
    log_success "NVIDIA GPU ê°ì§€ë¨"
    DEVICE="cuda"
elif python3 -c "import torch; print(torch.backends.mps.is_available())" 2>/dev/null | grep -q "True"; then
    log_success "Apple Silicon (MPS) ê°ì§€ë¨"
    DEVICE="mps"
else
    log_warning "GPUë¥¼ ê°ì§€í•  ìˆ˜ ì—†ìŒ. CPU ëª¨ë“œë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤."
    DEVICE="cpu"
fi

# 2. ê°€ìƒí™˜ê²½ ì„¤ì •
log_info "Python ê°€ìƒí™˜ê²½ ì„¤ì • ì¤‘..."

if [ ! -d "venv" ]; then
    python3 -m venv venv
    log_success "ê°€ìƒí™˜ê²½ ìƒì„± ì™„ë£Œ"
fi

# ê°€ìƒí™˜ê²½ í™œì„±í™”
source venv/bin/activate || {
    log_error "ê°€ìƒí™˜ê²½ í™œì„±í™” ì‹¤íŒ¨"
    exit 1
}

log_success "ê°€ìƒí™˜ê²½ í™œì„±í™”ë¨"

# 3. ê¸°ë³¸ ì˜ì¡´ì„± ì„¤ì¹˜
log_info "ê¸°ë³¸ íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì¤‘..."
pip install --upgrade pip setuptools wheel

# 4. AI ì˜ì¡´ì„± ì„¤ì¹˜
log_info "AI ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ ì¤‘... (ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)"

# PyTorch ì„¤ì¹˜ (ë””ë°”ì´ìŠ¤ë³„)
if [ "$DEVICE" = "cuda" ]; then
    log_info "CUDAìš© PyTorch ì„¤ì¹˜ ì¤‘..."
    pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
elif [ "$DEVICE" = "mps" ]; then
    log_info "Apple Siliconìš© PyTorch ì„¤ì¹˜ ì¤‘..."
    pip install torch torchvision torchaudio
else
    log_info "CPUìš© PyTorch ì„¤ì¹˜ ì¤‘..."
    pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu
fi

# ë‚˜ë¨¸ì§€ AI ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜
log_info "ì¶”ê°€ AI ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ ì¤‘..."
pip install -r requirements-ai.txt

# 5. ê¸°ë³¸ ë°±ì—”ë“œ ì˜ì¡´ì„± ì„¤ì¹˜
log_info "ë°±ì—”ë“œ ì˜ì¡´ì„± ì„¤ì¹˜ ì¤‘..."
pip install -r requirements.txt

# 6. ë””ë ‰í† ë¦¬ êµ¬ì¡° ìƒì„±
log_info "AI ëª¨ë¸ ë””ë ‰í† ë¦¬ êµ¬ì¡° ìƒì„± ì¤‘..."

mkdir -p ai_models/{checkpoints,configs,temp}
mkdir -p ai_models/checkpoints/{ootdiffusion,viton_hd,human_parsing,background_removal}
mkdir -p static/{uploads,results}
mkdir -p logs

# .gitkeep íŒŒì¼ ìƒì„±
find ai_models -type d -exec touch {}/.gitkeep \;
find static -type d -exec touch {}/.gitkeep \;
touch logs/.gitkeep

log_success "ë””ë ‰í† ë¦¬ êµ¬ì¡° ìƒì„± ì™„ë£Œ"

# 7. AI ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
log_info "AI ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹œì‘..."

if [ ! -f "scripts/download_ai_models.py" ]; then
    log_error "download_ai_models.py ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    exit 1
fi

python scripts/download_ai_models.py

# 8. ì„¤ì • íŒŒì¼ ìƒì„±
log_info "ì„¤ì • íŒŒì¼ ìƒì„± ì¤‘..."

# GPU ì„¤ì • íŒŒì¼ ìƒì„±
cat > app/core/gpu_config.py << EOF
"""
GPU ë° ë””ë°”ì´ìŠ¤ ì„¤ì •
"""
import torch

# ë””ë°”ì´ìŠ¤ ìë™ ê°ì§€
if torch.cuda.is_available():
    DEVICE = "cuda"
    print(f"ğŸš€ CUDA GPU ì‚¬ìš©: {torch.cuda.get_device_name()}")
elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
    DEVICE = "mps" 
    print("ğŸ Apple Silicon MPS ì‚¬ìš©")
else:
    DEVICE = "cpu"
    print("ğŸ’» CPU ì‚¬ìš©")

# ëª¨ë¸ ì„¤ì •
MODEL_CONFIG = {
    "device": DEVICE,
    "dtype": torch.float32 if DEVICE == "mps" else torch.float16,
    "memory_fraction": 0.8,
    "enable_attention_slicing": True,
    "enable_memory_efficient_attention": DEVICE != "mps"
}

# GPU ë©”ëª¨ë¦¬ ìµœì í™”
if DEVICE == "cuda":
    torch.backends.cudnn.benchmark = True
    torch.backends.cuda.matmul.allow_tf32 = True
elif DEVICE == "mps":
    # MPS ìµœì í™” ì„¤ì •
    torch.backends.mps.empty_cache()
EOF

# ì´ë¯¸ì§€ ìœ í‹¸ë¦¬í‹° ìƒì„±
log_info "ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ìƒì„± ì¤‘..."

cat > app/utils/image_utils.py << 'EOF'
"""
ì´ë¯¸ì§€ ì²˜ë¦¬ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
"""
import io
from typing import Tuple
from PIL import Image, ImageEnhance, ImageFilter

def resize_image(image: Image.Image, target_size: Tuple[int, int], maintain_ratio: bool = True) -> Image.Image:
    """ì´ë¯¸ì§€ í¬ê¸° ì¡°ì •"""
    if maintain_ratio:
        image.thumbnail(target_size, Image.Resampling.LANCZOS)
        
        # ì •ì‚¬ê°í˜•ìœ¼ë¡œ íŒ¨ë”©
        new_image = Image.new('RGB', target_size, (255, 255, 255))
        paste_x = (target_size[0] - image.width) // 2
        paste_y = (target_size[1] - image.height) // 2
        new_image.paste(image, (paste_x, paste_y))
        return new_image
    else:
        return image.resize(target_size, Image.Resampling.LANCZOS)

def enhance_image_quality(image: Image.Image) -> Image.Image:
    """ì´ë¯¸ì§€ í’ˆì§ˆ í–¥ìƒ"""
    # ì„ ëª…ë„ í–¥ìƒ
    enhancer = ImageEnhance.Sharpness(image)
    image = enhancer.enhance(1.1)
    
    # ëŒ€ë¹„ í–¥ìƒ
    enhancer = ImageEnhance.Contrast(image)
    image = enhancer.enhance(1.05)
    
    return image

def convert_to_rgb(image: Image.Image) -> Image.Image:
    """RGBë¡œ ë³€í™˜"""
    if image.mode != 'RGB':
        return image.convert('RGB')
    return image

async def validate_image_content(image_bytes: bytes) -> bool:
    """ì´ë¯¸ì§€ ë‚´ìš© ê²€ì¦"""
    try:
        image = Image.open(io.BytesIO(image_bytes))
        width, height = image.size
        
        # ìµœì†Œ/ìµœëŒ€ í¬ê¸° ê²€ì‚¬
        if width < 100 or height < 100:
            return False
        if width > 4096 or height > 4096:
            return False
            
        return True
    except Exception:
        return False
EOF

# 9. í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ ìƒì„±
log_info "í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ ìƒì„± ì¤‘..."

cat > scripts/test_models.py << 'EOF'
#!/usr/bin/env python3
"""
AI ëª¨ë¸ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
"""
import asyncio
import sys
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
sys.path.append(str(Path(__file__).parent.parent))

from app.services.ai_models import model_manager
from app.services.real_working_ai_fitter import RealWorkingAIFitter
from PIL import Image

async def test_models():
    print("ğŸ§ª AI ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì‹œì‘...")
    
    try:
        # 1. ëª¨ë¸ ê´€ë¦¬ì ì´ˆê¸°í™”
        await model_manager.initialize_models()
        print("âœ… ëª¨ë¸ ê´€ë¦¬ì ì´ˆê¸°í™” ì™„ë£Œ")
        
        # 2. ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ í™•ì¸
        available_models = model_manager.get_available_models()
        print(f"ğŸ“‹ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸: {available_models}")
        
        # 3. ë”ë¯¸ ì´ë¯¸ì§€ë¡œ í…ŒìŠ¤íŠ¸
        dummy_person = Image.new('RGB', (512, 512), color='white')
        dummy_clothing = Image.new('RGB', (512, 512), color='blue')
        
        if available_models:
            print("ğŸ¨ ê°€ìƒ í”¼íŒ… í…ŒìŠ¤íŠ¸ ì¤‘...")
            result_image, metadata = await model_manager.generate_virtual_fitting(
                dummy_person, dummy_clothing
            )
            print(f"âœ… ê°€ìƒ í”¼íŒ… í…ŒìŠ¤íŠ¸ ì„±ê³µ: {metadata}")
        
        # 4. AI ì„œë¹„ìŠ¤ í…ŒìŠ¤íŠ¸
        ai_fitter = RealWorkingAIFitter()
        status = await ai_fitter.get_model_status()
        print(f"ğŸ“Š AI ì„œë¹„ìŠ¤ ìƒíƒœ: {status}")
        
        print("ğŸ‰ ëª¨ë“  í…ŒìŠ¤íŠ¸ í†µê³¼!")
        
    except Exception as e:
        print(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        return False
    
    return True

if __name__ == "__main__":
    result = asyncio.run(test_models())
    sys.exit(0 if result else 1)
EOF

chmod +x scripts/test_models.py

# 10. ì„œë¹„ìŠ¤ ì‹œì‘ ìŠ¤í¬ë¦½íŠ¸ ìƒì„±
cat > scripts/start_server.sh << 'EOF'
#!/bin/bash
# AI ëª¨ë¸ ì„œë²„ ì‹œì‘ ìŠ¤í¬ë¦½íŠ¸

echo "ğŸš€ MyCloset AI ì„œë²„ ì‹œì‘..."

# ê°€ìƒí™˜ê²½ í™œì„±í™”
source venv/bin/activate

# ëª¨ë¸ í…ŒìŠ¤íŠ¸
echo "ğŸ§ª ëª¨ë¸ ìƒíƒœ í™•ì¸ ì¤‘..."
python scripts/test_models.py

if [ $? -eq 0 ]; then
    echo "âœ… ëª¨ë¸ ìƒíƒœ ì •ìƒ"
    echo "ğŸŒ ì„œë²„ ì‹œì‘ ì¤‘..."
    uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
else
    echo "âŒ ëª¨ë¸ ìƒíƒœ ì´ìƒ. ì„œë²„ ì‹œì‘ì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤."
    exit 1
fi
EOF

chmod +x scripts/start_server.sh

# 11. ìµœì¢… ê²€ì¦
log_info "ì„¤ì¹˜ ê²€ì¦ ì¤‘..."

# Python íŒ¨í‚¤ì§€ ê²€ì¦
python3 -c "
import torch
import PIL
import cv2
import numpy as np
print('âœ… í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„í¬íŠ¸ ì„±ê³µ')
print(f'PyTorch ë²„ì „: {torch.__version__}')
print(f'ë””ë°”ì´ìŠ¤: {torch.device(\"$DEVICE\")}')
"

# 12. ì™„ë£Œ ë©”ì‹œì§€
echo ""
log_success "MyCloset AI ëª¨ë¸ ì„¤ì • ì™„ë£Œ!"
echo ""
echo "ğŸ“‹ ì„¤ì¹˜ëœ êµ¬ì„±ìš”ì†Œ:"
echo "   âœ… PyTorch ($DEVICE ì§€ì›)"
echo "   âœ… Hugging Face Transformers"
echo "   âœ… Computer Vision ë¼ì´ë¸ŒëŸ¬ë¦¬ë“¤"
echo "   âœ… AI ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ìŠ¤í¬ë¦½íŠ¸"
echo "   âœ… í†µí•© ì„œë¹„ìŠ¤ í´ë˜ìŠ¤ë“¤"
echo ""
echo "ğŸš€ ë‹¤ìŒ ë‹¨ê³„:"
echo "   1. ëª¨ë¸ í…ŒìŠ¤íŠ¸: python scripts/test_models.py"
echo "   2. ì„œë²„ ì‹œì‘: ./scripts/start_server.sh"
echo "   3. API í…ŒìŠ¤íŠ¸: curl http://localhost:8000/api/models"
echo ""
echo "ğŸ“š ë¬¸ì„œ:"
echo "   - API ë¬¸ì„œ: http://localhost:8000/docs"
echo "   - ëª¨ë¸ ìƒíƒœ: http://localhost:8000/api/status"
echo ""
echo "âš ï¸  ì£¼ì˜ì‚¬í•­:"
echo "   - ì²« ì‹¤í–‰ ì‹œ ëª¨ë¸ ë‹¤ìš´ë¡œë“œë¡œ ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤"
echo "   - GPU ë©”ëª¨ë¦¬ê°€ ë¶€ì¡±í•˜ë©´ CPU ëª¨ë“œë¡œ ì „í™˜ë©ë‹ˆë‹¤"
echo "   - ì¼ë¶€ ëª¨ë¸ì€ ë³„ë„ì˜ ë¼ì´ì„¼ìŠ¤ê°€ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤"