#!/usr/bin/env python3
# backend/scripts/fix_model_paths.py
"""
ê¸°ì¡´ AI ëª¨ë¸ ê²½ë¡œë¥¼ ì¸ì‹í•˜ê³  ì„¤ì •ì„ ì—…ë°ì´íŠ¸í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸
"""

import os
import yaml
from pathlib import Path
import logging

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class ModelPathFixer:
    """ê¸°ì¡´ AI ëª¨ë¸ ê²½ë¡œ ìˆ˜ì • ë° ì„¤ì • ì—…ë°ì´íŠ¸"""
    
    def __init__(self):
        self.project_root = Path(__file__).parent.parent
        self.ai_models_dir = self.project_root / "ai_models"
        
        logger.info(f"ğŸ” AI ëª¨ë¸ ë””ë ‰í† ë¦¬: {self.ai_models_dir}")
    
    def scan_existing_models(self):
        """ê¸°ì¡´ AI ëª¨ë¸ ìŠ¤ìº”"""
        
        logger.info("ğŸ” ê¸°ì¡´ AI ëª¨ë¸ ìŠ¤ìº” ì¤‘...")
        
        found_models = {}
        
        # ì•Œë ¤ì§„ ëª¨ë¸ ì´ë¦„ë“¤
        known_models = {
            "ootdiffusion": ["OOTDiffusion", "ootdiffusion_hf"],
            "viton_hd": ["VITON-HD", "HR-VITON"],
            "graphonomy": ["Graphonomy", "Self-Correction-Human-Parsing"],
            "openpose": ["openpose"],
            "detectron2": ["detectron2"]
        }
        
        # ê° ëª¨ë¸ ë””ë ‰í† ë¦¬ í™•ì¸
        for model_key, possible_names in known_models.items():
            for name in possible_names:
                model_path = self.ai_models_dir / name
                if model_path.exists() and model_path.is_dir():
                    # ë””ë ‰í† ë¦¬ ë‚´ìš© í™•ì¸
                    files = list(model_path.glob("**/*"))
                    file_count = len([f for f in files if f.is_file()])
                    
                    if file_count > 0:
                        found_models[model_key] = {
                            "name": name,
                            "path": str(model_path),
                            "files_count": file_count,
                            "size_mb": self._get_directory_size(model_path)
                        }
                        logger.info(f"âœ… {model_key} ë°œê²¬: {name} ({file_count}ê°œ íŒŒì¼, {found_models[model_key]['size_mb']}MB)")
                        break
        
        # ì¶”ê°€ íŒŒì¼ë“¤ í™•ì¸
        additional_files = {
            "gen.pth": "VITON-HD ìƒì„± ëª¨ë¸",
            "mtviton.pth": "MT-VITON ëª¨ë¸"
        }
        
        for filename, description in additional_files.items():
            file_path = self.ai_models_dir / filename
            if file_path.exists():
                logger.info(f"âœ… ì¶”ê°€ íŒŒì¼ ë°œê²¬: {filename} ({description})")
        
        return found_models
    
    def _get_directory_size(self, path):
        """ë””ë ‰í† ë¦¬ í¬ê¸° ê³„ì‚° (MB)"""
        total_size = 0
        try:
            for file_path in path.glob("**/*"):
                if file_path.is_file():
                    total_size += file_path.stat().st_size
        except:
            pass
        return round(total_size / (1024 * 1024), 1)
    
    def create_updated_config(self, found_models):
        """ì—…ë°ì´íŠ¸ëœ ëª¨ë¸ ì„¤ì • íŒŒì¼ ìƒì„±"""
        
        logger.info("ğŸ“ ëª¨ë¸ ì„¤ì • íŒŒì¼ ì—…ë°ì´íŠ¸ ì¤‘...")
        
        config = {
            "models": {},
            "processing": {
                "image_size": 512,
                "batch_size": 1,
                "num_inference_steps": 20,
                "guidance_scale": 7.5,
                "device": "mps"  # M3 Max ê¸°ë³¸ê°’
            },
            "paths": {
                "ai_models_root": str(self.ai_models_dir),
                "cache_dir": str(self.ai_models_dir / "cache"),
                "temp_dir": str(self.ai_models_dir / "temp")
            }
        }
        
        # ë°œê²¬ëœ ëª¨ë¸ë“¤ ì„¤ì •ì— ì¶”ê°€
        for model_key, model_info in found_models.items():
            config["models"][model_key] = {
                "name": model_info["name"],
                "path": model_info["path"],
                "enabled": True,
                "device": "mps",
                "files_count": model_info["files_count"],
                "size_mb": model_info["size_mb"]
            }
        
        # ì„¤ì • íŒŒì¼ ì €ì¥
        config_path = self.ai_models_dir / "models_config_updated.yaml"
        with open(config_path, 'w') as f:
            yaml.dump(config, f, default_flow_style=False, allow_unicode=True)
        
        logger.info(f"âœ… ì—…ë°ì´íŠ¸ëœ ì„¤ì • íŒŒì¼ ì €ì¥: {config_path}")
        
        # ê¸°ì¡´ íŒŒì¼ ë°±ì—… ë° êµì²´
        old_config = self.ai_models_dir / "model_config.yaml"
        if old_config.exists():
            backup_path = self.ai_models_dir / "model_config_backup.yaml"
            old_config.rename(backup_path)
            logger.info(f"ğŸ“¦ ê¸°ì¡´ ì„¤ì • ë°±ì—…: {backup_path}")
        
        config_path.rename(old_config)
        logger.info("âœ… ìƒˆ ì„¤ì • íŒŒì¼ ì ìš© ì™„ë£Œ")
        
        return config
    
    def create_model_manager_config(self, found_models):
        """ëª¨ë¸ ë§¤ë‹ˆì €ìš© Python ì„¤ì • íŒŒì¼ ìƒì„±"""
        
        logger.info("ğŸ Python ëª¨ë¸ ë§¤ë‹ˆì € ì„¤ì • ìƒì„± ì¤‘...")
        
        # ëª¨ë¸ ë§¤ë‹ˆì €ìš© ì„¤ì • íŒŒì¼
        config_content = f'''# backend/app/core/model_paths.py
"""
AI ëª¨ë¸ ê²½ë¡œ ì„¤ì • - ìë™ ìƒì„±ë¨
ê¸°ì¡´ ë‹¤ìš´ë¡œë“œëœ ëª¨ë¸ë“¤ì˜ ì‹¤ì œ ê²½ë¡œ
"""

from pathlib import Path

# ê¸°ë³¸ ê²½ë¡œ
AI_MODELS_ROOT = Path(__file__).parent.parent.parent / "ai_models"

# ë°œê²¬ëœ ëª¨ë¸ ê²½ë¡œë“¤
MODEL_PATHS = {{
'''
        
        for model_key, model_info in found_models.items():
            config_content += f'''    "{model_key}": {{
        "name": "{model_info['name']}",
        "path": AI_MODELS_ROOT / "{model_info['name']}",
        "enabled": True,
        "files_count": {model_info['files_count']},
        "size_mb": {model_info['size_mb']}
    }},
'''
        
        config_content += '''}}

# ì¶”ê°€ íŒŒì¼ ê²½ë¡œ
ADDITIONAL_FILES = {
'''
        
        # ì¶”ê°€ íŒŒì¼ë“¤ í™•ì¸
        additional_files = ["gen.pth", "mtviton.pth"]
        for filename in additional_files:
            file_path = self.ai_models_dir / filename
            if file_path.exists():
                config_content += f'''    "{filename}": AI_MODELS_ROOT / "{filename}",
'''
        
        config_content += '''}

def get_model_path(model_key: str) -> Path:
    """ëª¨ë¸ ê²½ë¡œ ë°˜í™˜"""
    if model_key in MODEL_PATHS:
        return MODEL_PATHS[model_key]["path"]
    raise KeyError(f"Unknown model: {model_key}")

def is_model_available(model_key: str) -> bool:
    """ëª¨ë¸ ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸"""
    if model_key in MODEL_PATHS:
        return MODEL_PATHS[model_key]["path"].exists()
    return False

def get_available_models() -> list:
    """ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡ ë°˜í™˜"""
    available = []
    for key, info in MODEL_PATHS.items():
        if info["path"].exists():
            available.append(key)
    return available
'''
        
        # íŒŒì¼ ì €ì¥
        config_path = self.project_root / "app" / "core" / "model_paths.py"
        config_path.parent.mkdir(parents=True, exist_ok=True)
        
        with open(config_path, 'w') as f:
            f.write(config_content)
        
        logger.info(f"âœ… Python ëª¨ë¸ ì„¤ì • ì €ì¥: {config_path}")
    
    def test_model_access(self, found_models):
        """ëª¨ë¸ ì ‘ê·¼ í…ŒìŠ¤íŠ¸"""
        
        logger.info("ğŸ§ª ëª¨ë¸ ì ‘ê·¼ í…ŒìŠ¤íŠ¸ ì¤‘...")
        
        for model_key, model_info in found_models.items():
            model_path = Path(model_info["path"])
            
            try:
                # ë””ë ‰í† ë¦¬ ì ‘ê·¼ í…ŒìŠ¤íŠ¸
                files = list(model_path.glob("*"))
                logger.info(f"âœ… {model_key}: {len(files)}ê°œ íŒŒì¼ ì ‘ê·¼ ê°€ëŠ¥")
                
                # ì£¼ìš” íŒŒì¼ í™•ì¸
                important_files = []
                for file_path in model_path.glob("**/*"):
                    if file_path.is_file() and file_path.suffix in ['.pth', '.pt', '.safetensors', '.json', '.bin']:
                        important_files.append(file_path.name)
                        if len(important_files) >= 3:  # ì²˜ìŒ 3ê°œë§Œ í‘œì‹œ
                            break
                
                if important_files:
                    logger.info(f"   ì£¼ìš” íŒŒì¼: {', '.join(important_files[:3])}")
                
            except Exception as e:
                logger.error(f"âŒ {model_key}: ì ‘ê·¼ ì‹¤íŒ¨ - {e}")
    
    def generate_usage_guide(self, found_models):
        """ì‚¬ìš© ê°€ì´ë“œ ìƒì„±"""
        
        guide_content = f"""# AI ëª¨ë¸ ì‚¬ìš© ê°€ì´ë“œ

## ğŸ“ ë°œê²¬ëœ ëª¨ë¸ë“¤

"""
        
        for model_key, model_info in found_models.items():
            guide_content += f"""### {model_info['name']} ({model_key})
- **ê²½ë¡œ**: `{model_info['path']}`
- **íŒŒì¼ ìˆ˜**: {model_info['files_count']}ê°œ
- **í¬ê¸°**: {model_info['size_mb']}MB
- **ìƒíƒœ**: âœ… ì‚¬ìš© ê°€ëŠ¥

"""
        
        guide_content += """
## ğŸš€ ì‚¬ìš© ë°©ë²•

### Pythonì—ì„œ ëª¨ë¸ ê²½ë¡œ ì‚¬ìš©:
```python
from app.core.model_paths import get_model_path, is_model_available

# ëª¨ë¸ ê²½ë¡œ ê°€ì ¸ì˜¤ê¸°
ootd_path = get_model_path("ootdiffusion")
print(f"OOTDiffusion ê²½ë¡œ: {ootd_path}")

# ëª¨ë¸ ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
if is_model_available("ootdiffusion"):
    print("âœ… OOTDiffusion ì‚¬ìš© ê°€ëŠ¥")
```

### FastAPIì—ì„œ ì‚¬ìš©:
```python
from app.core.model_paths import MODEL_PATHS

# ëª¨ë“  ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ í™•ì¸
available_models = [key for key, info in MODEL_PATHS.items() 
                   if info["path"].exists()]
print(f"ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸: {available_models}")
```

## ğŸ”§ ë‹¤ìŒ ë‹¨ê³„

1. **ëª¨ë¸ ë¡œë” êµ¬í˜„**: `app/services/model_manager.py`
2. **ê°€ìƒ í”¼íŒ… API**: `app/api/virtual_tryon.py`
3. **GPU ìµœì í™”**: M3 Max Metal ê°€ì† í™œìš©

"""
        
        guide_path = self.ai_models_dir / "USAGE_GUIDE.md"
        with open(guide_path, 'w') as f:
            f.write(guide_content)
        
        logger.info(f"âœ… ì‚¬ìš© ê°€ì´ë“œ ìƒì„±: {guide_path}")

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    
    print("ğŸ”§ MyCloset AI - ê¸°ì¡´ ëª¨ë¸ ê²½ë¡œ ìˆ˜ì • ë„êµ¬")
    print("=" * 50)
    
    fixer = ModelPathFixer()
    
    # 1. ê¸°ì¡´ ëª¨ë¸ ìŠ¤ìº”
    found_models = fixer.scan_existing_models()
    
    if not found_models:
        logger.warning("âš ï¸ AI ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        logger.info("AI ëª¨ë¸ì„ ë¨¼ì € ë‹¤ìš´ë¡œë“œí•˜ì„¸ìš”.")
        return
    
    logger.info(f"ğŸ‰ ì´ {len(found_models)}ê°œ ëª¨ë¸ ë°œê²¬!")
    
    # 2. ì„¤ì • íŒŒì¼ ì—…ë°ì´íŠ¸
    config = fixer.create_updated_config(found_models)
    
    # 3. Python ì„¤ì • íŒŒì¼ ìƒì„±
    fixer.create_model_manager_config(found_models)
    
    # 4. ëª¨ë¸ ì ‘ê·¼ í…ŒìŠ¤íŠ¸
    fixer.test_model_access(found_models)
    
    # 5. ì‚¬ìš© ê°€ì´ë“œ ìƒì„±
    fixer.generate_usage_guide(found_models)
    
    print("\nğŸ‰ ëª¨ë¸ ê²½ë¡œ ìˆ˜ì • ì™„ë£Œ!")
    print("ğŸ“‹ ìƒì„±ëœ íŒŒì¼:")
    print("  - ai_models/model_config.yaml (ì—…ë°ì´íŠ¸ë¨)")
    print("  - app/core/model_paths.py (ìƒˆë¡œ ìƒì„±)")
    print("  - ai_models/USAGE_GUIDE.md (ì‚¬ìš© ê°€ì´ë“œ)")
    print("\nğŸš€ ë‹¤ìŒ ë‹¨ê³„:")
    print("  1. FastAPI ì„œë²„ ì‹¤í–‰: python app/main.py")
    print("  2. ëª¨ë¸ ìƒíƒœ í™•ì¸: curl http://localhost:8000/health/models")
    print("  3. AI ëª¨ë¸ ë¡œë” êµ¬í˜„")

if __name__ == "__main__":
    main()