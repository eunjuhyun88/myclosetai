#!/usr/bin/env python3
"""
ğŸ”§ ê°„ë‹¨í•œ ëª¨ë¸ í…ŒìŠ¤íŠ¸
ë‹¤ìš´ë¡œë“œëœ ëª¨ë¸ë“¤ì´ ì œëŒ€ë¡œ ë¡œë“œë˜ëŠ”ì§€ í™•ì¸
"""

import os
import sys
import logging
from pathlib import Path

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')
logger = logging.getLogger(__name__)

class SimpleModelTester:
    """ê°„ë‹¨í•œ ëª¨ë¸ í…ŒìŠ¤íŠ¸"""
    
    def __init__(self):
        self.models_dir = Path("ai_models/checkpoints")
        self.test_results = {}
        
    def test_segformer_parsing(self) -> bool:
        """Segformer ì¸ì²´ íŒŒì‹± í…ŒìŠ¤íŠ¸"""
        logger.info("ğŸ¯ Segformer ì¸ì²´ íŒŒì‹± í…ŒìŠ¤íŠ¸...")
        
        try:
            model_path = self.models_dir / "step_01_human_parsing" / "segformer_b2_clothes"
            
            if not model_path.exists():
                logger.warning("âŒ Segformer ëª¨ë¸ ì—†ìŒ")
                return False
            
            # transformers ì„¤ì¹˜ í™•ì¸
            try:
                from transformers import SegformerImageProcessor, SegformerForSemanticSegmentation
            except ImportError:
                logger.info("ğŸ“¦ transformers ì„¤ì¹˜ ì¤‘...")
                import subprocess
                subprocess.check_call([sys.executable, "-m", "pip", "install", "transformers", "torch", "torchvision"])
                from transformers import SegformerImageProcessor, SegformerForSemanticSegmentation
            
            # ëª¨ë¸ ë¡œë“œ í…ŒìŠ¤íŠ¸
            processor = SegformerImageProcessor.from_pretrained(str(model_path))
            model = SegformerForSemanticSegmentation.from_pretrained(str(model_path))
            
            logger.info("âœ… Segformer ë¡œë“œ ì„±ê³µ")
            return True
            
        except Exception as e:
            logger.error(f"âŒ Segformer í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
            return False
    
    def test_u2net_onnx(self) -> bool:
        """UÂ²-Net ONNX í…ŒìŠ¤íŠ¸"""
        logger.info("ğŸ¯ UÂ²-Net ONNX í…ŒìŠ¤íŠ¸...")
        
        try:
            model_path = self.models_dir / "step_03_cloth_segmentation" / "u2net.onnx"
            
            if not model_path.exists():
                logger.warning("âŒ UÂ²-Net ONNX ëª¨ë¸ ì—†ìŒ")
                return False
            
            # onnxruntime ì„¤ì¹˜ í™•ì¸
            try:
                import onnxruntime as ort
            except ImportError:
                logger.info("ğŸ“¦ onnxruntime ì„¤ì¹˜ ì¤‘...")
                import subprocess
                subprocess.check_call([sys.executable, "-m", "pip", "install", "onnxruntime"])
                import onnxruntime as ort
            
            # ONNX ì„¸ì…˜ ìƒì„± í…ŒìŠ¤íŠ¸
            session = ort.InferenceSession(str(model_path))
            
            # ì…ë ¥ ì •ë³´ í™•ì¸
            input_info = session.get_inputs()[0]
            logger.info(f"ONNX ì…ë ¥: {input_info.name}, shape: {input_info.shape}")
            
            logger.info("âœ… UÂ²-Net ONNX ë¡œë“œ ì„±ê³µ")
            return True
            
        except Exception as e:
            logger.error(f"âŒ UÂ²-Net ONNX í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
            return False
    
    def test_mediapipe_pose(self) -> bool:
        """MediaPipe í¬ì¦ˆ í…ŒìŠ¤íŠ¸"""
        logger.info("ğŸ¯ MediaPipe í¬ì¦ˆ í…ŒìŠ¤íŠ¸...")
        
        try:
            model_path = self.models_dir / "step_02_pose_estimation" / "pose_landmarker.task"
            
            if not model_path.exists():
                logger.warning("âŒ MediaPipe í¬ì¦ˆ ëª¨ë¸ ì—†ìŒ")
                return False
            
            # íŒŒì¼ í¬ê¸° í™•ì¸
            size_mb = model_path.stat().st_size / 1024 / 1024
            logger.info(f"MediaPipe ëª¨ë¸ í¬ê¸°: {size_mb:.1f}MB")
            
            if size_mb > 1:  # 1MB ì´ìƒì´ë©´ ì •ìƒ
                logger.info("âœ… MediaPipe í¬ì¦ˆ ëª¨ë¸ ì •ìƒ")
                return True
            else:
                logger.warning("âŒ MediaPipe ëª¨ë¸ í¬ê¸° ì´ìƒ")
                return False
            
        except Exception as e:
            logger.error(f"âŒ MediaPipe í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
            return False
    
    def test_real_esrgan(self) -> bool:
        """Real-ESRGAN í…ŒìŠ¤íŠ¸"""
        logger.info("ğŸ¯ Real-ESRGAN í…ŒìŠ¤íŠ¸...")
        
        try:
            model_path = self.models_dir / "step_07_post_processing" / "RealESRGAN_x4plus.pth"
            
            if not model_path.exists():
                logger.warning("âŒ Real-ESRGAN ëª¨ë¸ ì—†ìŒ")
                return False
            
            # PyTorch ì„¤ì¹˜ í™•ì¸
            try:
                import torch
            except ImportError:
                logger.info("ğŸ“¦ torch ì„¤ì¹˜ ì¤‘...")
                import subprocess
                subprocess.check_call([sys.executable, "-m", "pip", "install", "torch", "torchvision"])
                import torch
            
            # ëª¨ë¸ ë¡œë“œ í…ŒìŠ¤íŠ¸
            checkpoint = torch.load(model_path, map_location='cpu')
            
            if isinstance(checkpoint, dict):
                logger.info(f"Real-ESRGAN ì²´í¬í¬ì¸íŠ¸ í‚¤: {len(checkpoint)} ê°œ")
                logger.info("âœ… Real-ESRGAN ë¡œë“œ ì„±ê³µ")
                return True
            else:
                logger.warning("âŒ Real-ESRGAN ì²´í¬í¬ì¸íŠ¸ í˜•ì‹ ì´ìƒ")
                return False
            
        except Exception as e:
            logger.error(f"âŒ Real-ESRGAN í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
            return False
    
    def test_clip_model(self) -> bool:
        """CLIP ëª¨ë¸ í…ŒìŠ¤íŠ¸"""
        logger.info("ğŸ¯ CLIP ëª¨ë¸ í…ŒìŠ¤íŠ¸...")
        
        try:
            model_path = self.models_dir / "shared_encoder" / "clip-vit-base-patch32"
            
            if not model_path.exists():
                logger.warning("âŒ CLIP ëª¨ë¸ ì—†ìŒ")
                return False
            
            # transformersë¡œ CLIP í…ŒìŠ¤íŠ¸
            try:
                from transformers import CLIPProcessor, CLIPModel
            except ImportError:
                logger.info("ğŸ“¦ transformers ì„¤ì¹˜ ì¤‘...")
                import subprocess
                subprocess.check_call([sys.executable, "-m", "pip", "install", "transformers"])
                from transformers import CLIPProcessor, CLIPModel
            
            # ëª¨ë¸ ë¡œë“œ í…ŒìŠ¤íŠ¸
            model = CLIPModel.from_pretrained(str(model_path))
            processor = CLIPProcessor.from_pretrained(str(model_path))
            
            logger.info("âœ… CLIP ë¡œë“œ ì„±ê³µ")
            return True
            
        except Exception as e:
            logger.error(f"âŒ CLIP í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
            return False
    
    def run_all_tests(self):
        """ëª¨ë“  í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        print("ğŸš€ ê°„ë‹¨í•œ ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì‹œì‘")
        print("=" * 40)
        
        tests = [
            ("Segformer ì¸ì²´ íŒŒì‹±", self.test_segformer_parsing),
            ("UÂ²-Net ONNX", self.test_u2net_onnx),
            ("MediaPipe í¬ì¦ˆ", self.test_mediapipe_pose),
            ("Real-ESRGAN", self.test_real_esrgan),
            ("CLIP", self.test_clip_model)
        ]
        
        passed = 0
        total = len(tests)
        
        for test_name, test_func in tests:
            print(f"\n{'='*30}")
            
            try:
                result = test_func()
                self.test_results[test_name] = result
                
                if result:
                    passed += 1
                    logger.info(f"âœ… {test_name}: í†µê³¼")
                else:
                    logger.warning(f"âŒ {test_name}: ì‹¤íŒ¨")
                    
            except Exception as e:
                logger.error(f"ğŸ’¥ {test_name}: ì˜¤ë¥˜ - {e}")
                self.test_results[test_name] = False
        
        # ê²°ê³¼ ìš”ì•½
        success_rate = passed / total
        
        print(f"\n{'='*40}")
        print(f"ğŸ‰ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
        print(f"âœ… í†µê³¼: {passed}/{total} ({success_rate:.1%})")
        
        # ìƒì„¸ ê²°ê³¼
        print(f"\nğŸ“Š ìƒì„¸ ê²°ê³¼:")
        for test_name, result in self.test_results.items():
            status = "âœ… í†µê³¼" if result else "âŒ ì‹¤íŒ¨"
            print(f"   {test_name}: {status}")
        
        # ê¶Œì¥ì‚¬í•­
        if success_rate >= 0.8:
            print(f"\nğŸš€ ëŒ€ë¶€ë¶„ì˜ ëª¨ë¸ì´ ì •ìƒì…ë‹ˆë‹¤!")
            print(f"ğŸ“‹ ì„œë²„ë¥¼ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:")
            print(f"   python -m app.main")
        elif success_rate >= 0.5:
            print(f"\nâš ï¸ ì¼ë¶€ ëª¨ë¸ì— ë¬¸ì œê°€ ìˆì§€ë§Œ ê¸°ë³¸ ê¸°ëŠ¥ì€ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
        else:
            print(f"\nâŒ ë§ì€ ëª¨ë¸ì— ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤.")
            print(f"ëª¨ë¸ì„ ë‹¤ì‹œ ë‹¤ìš´ë¡œë“œí•˜ì„¸ìš”:")
            print(f"   python simple_model_downloader.py")
        
        return success_rate >= 0.5

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    try:
        tester = SimpleModelTester()
        success = tester.run_all_tests()
        return success
        
    except KeyboardInterrupt:
        print("\nâŒ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
        return False
    except Exception as e:
        logger.error(f"âŒ í…ŒìŠ¤íŠ¸ ì˜¤ë¥˜: {e}")
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)