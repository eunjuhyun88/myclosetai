# final_complete_model_downloader.py
"""
ğŸ”¥ ìµœì¢… ì™„ì „í•œ AI ëª¨ë¸ ë‹¤ìš´ë¡œë”
- ì²´í¬ì„¬ ë¬¸ì œ ì™„ì „ í•´ê²°
- torch ë²„ì „ í˜¸í™˜ì„± í•´ê²°
- ëˆ„ë½ëœ ëª¨ë¸ë“¤ ìë™ ì¬ì‹œë„
- M3 Max ìµœì í™”
- ì•ˆì „í•œ safetensors ì‚¬ìš©
"""

import os
import sys
import logging
import shutil
import hashlib
import requests
import subprocess
import json
import time
from pathlib import Path
from typing import Dict, List, Optional, Tuple, Union
from tqdm import tqdm
import platform

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class FinalModelDownloader:
    """ìµœì¢… ì™„ì „í•œ ëª¨ë¸ ë‹¤ìš´ë¡œë”"""
    
    def __init__(self):
        self.base_dir = Path("ai_models/checkpoints")
        self.base_dir.mkdir(parents=True, exist_ok=True)
        
        # ì‹œìŠ¤í…œ ì •ë³´
        self.is_m3_max = self._detect_apple_silicon()
        self.torch_version = self._get_torch_version()
        
        # ë‹¤ìš´ë¡œë“œ í†µê³„
        self.stats = {
            "attempted": 0,
            "successful": 0,
            "failed": 0,
            "skipped": 0
        }
        
        logger.info(f"ğŸ–¥ï¸ ì‹œìŠ¤í…œ: {'Apple Silicon (MPS)' if self.is_m3_max else 'Standard'}")
        logger.info(f"ğŸ”¥ PyTorch: {self.torch_version}")

    def _detect_apple_silicon(self) -> bool:
        """Apple Silicon ê°ì§€"""
        try:
            if platform.system() == 'Darwin':
                result = subprocess.run(['sysctl', '-n', 'machdep.cpu.brand_string'], 
                                      capture_output=True, text=True)
                return any(chip in result.stdout for chip in ['M1', 'M2', 'M3'])
        except:
            pass
        return False

    def _get_torch_version(self) -> str:
        """PyTorch ë²„ì „ í™•ì¸"""
        try:
            import torch
            return torch.__version__
        except ImportError:
            return "not_installed"

    def _check_file_integrity(self, file_path: Path, expected_size_mb: float = None) -> bool:
        """íŒŒì¼ ë¬´ê²°ì„± ê²€ì‚¬ (í¬ê¸° ê¸°ë°˜)"""
        if not file_path.exists():
            return False
        
        actual_size_mb = file_path.stat().st_size / (1024**2)
        
        if expected_size_mb is None:
            return actual_size_mb > 1.0  # ìµœì†Œ 1MB
        
        # 80% ì´ìƒì´ë©´ ì •ìƒìœ¼ë¡œ ê°„ì£¼
        return actual_size_mb >= expected_size_mb * 0.8

    def _download_with_progress(self, url: str, destination: Path, 
                              description: str, expected_size_mb: float = None) -> bool:
        """ì§„í–‰ë¥  í‘œì‹œ ë‹¤ìš´ë¡œë“œ"""
        try:
            # ì´ë¯¸ ì¡´ì¬í•˜ê³  í¬ê¸°ê°€ ë§ìœ¼ë©´ ìŠ¤í‚µ
            if self._check_file_integrity(destination, expected_size_mb):
                logger.info(f"    âœ… ì´ë¯¸ ì¡´ì¬: {destination.name}")
                return True
            
            destination.parent.mkdir(parents=True, exist_ok=True)
            
            response = requests.get(url, stream=True)
            response.raise_for_status()
            
            total_size = int(response.headers.get('content-length', 0))
            
            with open(destination, 'wb') as file:
                with tqdm(total=total_size, unit='B', unit_scale=True, desc=description) as pbar:
                    for chunk in response.iter_content(chunk_size=8192):
                        if chunk:
                            file.write(chunk)
                            pbar.update(len(chunk))
            
            # ë‹¤ìš´ë¡œë“œ í›„ ê²€ì¦
            if self._check_file_integrity(destination, expected_size_mb):
                actual_size = destination.stat().st_size / (1024**2)
                logger.info(f"    âœ… ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {actual_size:.1f}MB")
                return True
            else:
                logger.warning(f"    âš ï¸ íŒŒì¼ í¬ê¸° ë¶ˆì¼ì¹˜")
                return False
            
        except Exception as e:
            logger.error(f"    âŒ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
            return False

    def _download_huggingface_safe(self, repo_id: str, destination: Path, 
                                 description: str) -> bool:
        """ì•ˆì „í•œ HuggingFace ë‹¤ìš´ë¡œë“œ (safetensors ìš°ì„ )"""
        try:
            from huggingface_hub import snapshot_download
            
            logger.info(f"ğŸ“¥ HuggingFaceì—ì„œ {description} ë‹¤ìš´ë¡œë“œ...")
            logger.info(f"    Repository: {repo_id}")
            logger.info(f"    ì €ì¥ ìœ„ì¹˜: {destination}")
            
            # safetensors íŒŒì¼ë§Œ ë‹¤ìš´ë¡œë“œ ì‹œë„
            try:
                snapshot_download(
                    repo_id=repo_id,
                    local_dir=destination,
                    local_dir_use_symlinks=False,
                    resume_download=True,
                    allow_patterns=["*.safetensors", "*.json", "*.txt", "config.json", 
                                  "tokenizer*", "preprocessor*", "*.md", ".gitattributes"],
                    ignore_patterns=["*.bin", "*.h5", "*.msgpack"]  # ë¬¸ì œê°€ ë˜ëŠ” íŒŒì¼ë“¤ ì œì™¸
                )
                logger.info(f"âœ… {description} (safetensors) ë‹¤ìš´ë¡œë“œ ì™„ë£Œ")
                return True
            except:
                # safetensors ì‹¤íŒ¨ì‹œ ì „ì²´ ë‹¤ìš´ë¡œë“œ
                snapshot_download(
                    repo_id=repo_id,
                    local_dir=destination,
                    local_dir_use_symlinks=False,
                    resume_download=True
                )
                logger.info(f"âœ… {description} (ì „ì²´) ë‹¤ìš´ë¡œë“œ ì™„ë£Œ")
                return True
            
        except Exception as e:
            logger.error(f"âŒ HuggingFace ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
            return False

    def download_essential_models(self) -> bool:
        """í•„ìˆ˜ ëª¨ë¸ë“¤ ë‹¤ìš´ë¡œë“œ"""
        logger.info("ğŸ¯ í•„ìˆ˜ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹œì‘...")
        
        # í•µì‹¬ ëª¨ë¸ ì •ì˜ (ì‹¤ì œ ì‘ë™ í™•ì¸ëœ URLë“¤)
        essential_models = [
            {
                "name": "Segformer B2 Human Parsing",
                "description": "ì¸ì²´ íŒŒì‹± (Segformer B2)",
                "method": "huggingface",
                "repo_id": "mattmdjaga/segformer_b2_clothes",
                "destination": self.base_dir / "step_01_human_parsing" / "segformer_b2_clothes",
                "expected_size_mb": 440.0,
                "priority": 1
            },
            {
                "name": "UÂ²-Net ONNX",
                "description": "ë°°ê²½ ì œê±° (UÂ²-Net ONNX)",
                "method": "direct",
                "urls": [
                    "https://github.com/danielgatis/rembg/releases/download/v0.0.0/u2net.onnx",
                    "https://huggingface.co/skytnt/u2net/resolve/main/u2net.onnx"
                ],
                "destination": self.base_dir / "step_03_cloth_segmentation" / "u2net.onnx",
                "expected_size_mb": 176.3,
                "priority": 1
            },
            {
                "name": "MediaPipe Pose",
                "description": "í¬ì¦ˆ ì¶”ì • (MediaPipe)",
                "method": "direct",
                "urls": [
                    "https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_full/float16/latest/pose_landmarker_full.task"
                ],
                "destination": self.base_dir / "step_02_pose_estimation" / "pose_landmarker.task",
                "expected_size_mb": 9.4,
                "priority": 1
            },
            {
                "name": "Real-ESRGAN x4",
                "description": "í™”ì§ˆ ê°œì„  (Real-ESRGAN)",
                "method": "direct",
                "urls": [
                    "https://github.com/xinntao/Real-ESRGAN/releases/download/v0.1.0/RealESRGAN_x4plus.pth",
                    "https://huggingface.co/ai-forever/Real-ESRGAN/resolve/main/RealESRGAN_x4plus.pth"
                ],
                "destination": self.base_dir / "step_07_post_processing" / "RealESRGAN_x4plus.pth",
                "expected_size_mb": 67.0,
                "priority": 2
            },
            {
                "name": "CLIP ViT-B/32 (Safe)",
                "description": "íŠ¹ì„± ì¶”ì¶œ (CLIP - ì•ˆì „ ë²„ì „)",
                "method": "huggingface",
                "repo_id": "openai/clip-vit-base-patch32",
                "destination": self.base_dir / "shared_encoder" / "clip-vit-base-patch32",
                "expected_size_mb": 300.0,  # safetensorsë§Œ ë‹¤ìš´ë¡œë“œí•˜ë¯€ë¡œ ë” ì‘ìŒ
                "priority": 2
            },
            {
                "name": "YOLOv8 Pose",
                "description": "ëŒ€ì²´ í¬ì¦ˆ ì¶”ì • (YOLOv8)",
                "method": "direct",
                "urls": [
                    "https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n-pose.pt",
                    "https://huggingface.co/Ultralytics/YOLOv8/resolve/main/yolov8n-pose.pt"
                ],
                "destination": self.base_dir / "step_02_pose_estimation" / "yolov8n-pose.pt",
                "expected_size_mb": 6.5,
                "priority": 3
            },
            {
                "name": "SAM Mobile",
                "description": "ì„¸ê·¸ë©˜í…Œì´ì…˜ (MobileSAM)",
                "method": "direct",
                "urls": [
                    "https://github.com/ChaoningZhang/MobileSAM/raw/master/weights/mobile_sam.pt",
                    "https://huggingface.co/dhkim2810/MobileSAM/resolve/main/mobile_sam.pt"
                ],
                "destination": self.base_dir / "step_03_cloth_segmentation" / "mobile_sam.pt",
                "expected_size_mb": 38.8,
                "priority": 3
            }
        ]
        
        logger.info(f"ğŸ“Š ë‹¤ìš´ë¡œë“œ ì˜ˆì •: {len(essential_models)}ê°œ ëª¨ë¸")
        
        success_count = 0
        
        for i, model in enumerate(essential_models):
            logger.info(f"\n[{i+1}/{len(essential_models)}] ğŸ”¥ ìš°ì„ ìˆœìœ„ {model['priority']}")
            logger.info(f"ğŸ“¦ {model['name']} ë‹¤ìš´ë¡œë“œ...")
            logger.info(f"    ğŸ¯ {model['description']}")
            
            self.stats['attempted'] += 1
            download_success = False
            
            if model['method'] == 'huggingface':
                download_success = self._download_huggingface_safe(
                    model['repo_id'], 
                    model['destination'], 
                    model['name']
                )
            else:  # direct
                for url in model['urls']:
                    logger.info(f"    ğŸŒ ì‹œë„: {url[:60]}...")
                    download_success = self._download_with_progress(
                        url, 
                        model['destination'], 
                        model['name'],
                        model['expected_size_mb']
                    )
                    if download_success:
                        break
            
            if download_success:
                success_count += 1
                self.stats['successful'] += 1
                logger.info(f"    âœ… {model['name']}: ì™„ë£Œ")
            else:
                self.stats['failed'] += 1
                logger.warning(f"    âŒ {model['name']}: ì‹¤íŒ¨ - ê³„ì† ì§„í–‰")
        
        success_rate = (success_count / len(essential_models)) * 100
        logger.info(f"\nğŸ‰ í•„ìˆ˜ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ!")
        logger.info(f"âœ… ì„±ê³µ: {success_count}/{len(essential_models)} ({success_rate:.1f}%)")
        
        return success_count >= 4  # ìµœì†Œ 4ê°œ ì´ìƒ ì„±ê³µ

    def create_model_config(self):
        """ëª¨ë¸ ì„¤ì • íŒŒì¼ ìƒì„±"""
        config = {
            "model_base_path": str(self.base_dir),
            "system_info": {
                "is_apple_silicon": self.is_m3_max,
                "torch_version": self.torch_version,
                "platform": platform.system(),
                "created_at": time.strftime("%Y-%m-%d %H:%M:%S")
            },
            "models": {
                "step_01_human_parsing": {
                    "type": "segformer_b2",
                    "path": "step_01_human_parsing/segformer_b2_clothes",
                    "format": "huggingface_safetensors",
                    "device_compatible": ["cpu", "mps", "cuda"],
                    "status": "ready" if (self.base_dir / "step_01_human_parsing/segformer_b2_clothes").exists() else "missing"
                },
                "step_02_pose_estimation": {
                    "primary": {
                        "type": "mediapipe_pose",
                        "path": "step_02_pose_estimation/pose_landmarker.task",
                        "format": "mediapipe",
                        "device_compatible": ["cpu", "mps", "cuda"],
                        "status": "ready" if (self.base_dir / "step_02_pose_estimation/pose_landmarker.task").exists() else "missing"
                    },
                    "fallback": {
                        "type": "yolov8_pose",
                        "path": "step_02_pose_estimation/yolov8n-pose.pt",
                        "format": "pytorch",
                        "device_compatible": ["cpu", "mps", "cuda"],
                        "status": "ready" if (self.base_dir / "step_02_pose_estimation/yolov8n-pose.pt").exists() else "missing"
                    }
                },
                "step_03_cloth_segmentation": {
                    "primary": {
                        "type": "u2net_onnx",
                        "path": "step_03_cloth_segmentation/u2net.onnx",
                        "format": "onnx",
                        "device_compatible": ["cpu", "mps", "cuda"],
                        "status": "ready" if (self.base_dir / "step_03_cloth_segmentation/u2net.onnx").exists() else "missing"
                    },
                    "fallback": {
                        "type": "mobile_sam",
                        "path": "step_03_cloth_segmentation/mobile_sam.pt",
                        "format": "pytorch",
                        "device_compatible": ["cpu", "mps", "cuda"],
                        "status": "ready" if (self.base_dir / "step_03_cloth_segmentation/mobile_sam.pt").exists() else "missing"
                    }
                },
                "step_07_post_processing": {
                    "type": "real_esrgan_x4",
                    "path": "step_07_post_processing/RealESRGAN_x4plus.pth",
                    "format": "pytorch",
                    "device_compatible": ["cpu", "mps", "cuda"],
                    "status": "ready" if (self.base_dir / "step_07_post_processing/RealESRGAN_x4plus.pth").exists() else "missing"
                },
                "shared_encoder": {
                    "type": "clip_vit_b32_safe",
                    "path": "shared_encoder/clip-vit-base-patch32",
                    "format": "huggingface_safetensors",
                    "device_compatible": ["cpu", "mps", "cuda"],
                    "status": "ready" if (self.base_dir / "shared_encoder/clip-vit-base-patch32").exists() else "missing",
                    "note": "torch í˜¸í™˜ì„±ì„ ìœ„í•´ safetensorsë§Œ ì‚¬ìš©"
                }
            },
            "download_stats": self.stats
        }
        
        config_path = self.base_dir / "final_model_config.json"
        with open(config_path, 'w', encoding='utf-8') as f:
            json.dump(config, f, indent=2, ensure_ascii=False)
        
        logger.info(f"ğŸ“‹ ì„¤ì • íŒŒì¼ ìƒì„±: {config_path}")

    def verify_models(self) -> Dict[str, bool]:
        """ëª¨ë¸ íŒŒì¼ë“¤ ê²€ì¦"""
        logger.info("\nğŸ” ëª¨ë¸ ê²€ì¦")
        logger.info("=" * 30)
        
        models = {
            "ì¸ì²´ íŒŒì‹± (Segformer)": self.base_dir / "step_01_human_parsing" / "segformer_b2_clothes",
            "ë°°ê²½ ì œê±° (UÂ²-Net)": self.base_dir / "step_03_cloth_segmentation" / "u2net.onnx",
            "í¬ì¦ˆ ì¶”ì • (MediaPipe)": self.base_dir / "step_02_pose_estimation" / "pose_landmarker.task",
            "í¬ì¦ˆ ì¶”ì • (YOLOv8)": self.base_dir / "step_02_pose_estimation" / "yolov8n-pose.pt",
            "í™”ì§ˆ ê°œì„  (Real-ESRGAN)": self.base_dir / "step_07_post_processing" / "RealESRGAN_x4plus.pth",
            "íŠ¹ì„± ì¶”ì¶œ (CLIP)": self.base_dir / "shared_encoder" / "clip-vit-base-patch32",
            "ì„¸ê·¸ë©˜í…Œì´ì…˜ (MobileSAM)": self.base_dir / "step_03_cloth_segmentation" / "mobile_sam.pt"
        }
        
        results = {}
        ready_count = 0
        
        for name, path in models.items():
            if path.exists():
                if path.is_dir():
                    files = list(path.rglob('*'))
                    file_count = len([f for f in files if f.is_file()])
                    total_size = sum(f.stat().st_size for f in files if f.is_file()) / (1024**2)
                    logger.info(f"âœ… {name}: {file_count}ê°œ íŒŒì¼, {total_size:.1f}MB")
                else:
                    size = path.stat().st_size / (1024**2)
                    logger.info(f"âœ… {name}: {size:.1f}MB")
                results[name] = True
                ready_count += 1
            else:
                logger.info(f"âŒ {name}: ì—†ìŒ")
                results[name] = False
        
        logger.info(f"\nğŸ“Š ì¤€ë¹„ëœ ëª¨ë¸: {ready_count}/{len(models)}")
        return results

    def _create_simple_test_script(self):
        """ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ ìƒì„±"""
        test_script = '''#!/usr/bin/env python3
"""
ê°„ë‹¨í•œ ëª¨ë¸ í…ŒìŠ¤íŠ¸
"""
import os
import sys
from pathlib import Path

def test_models():
    """ëª¨ë¸ ë¡œë”© í…ŒìŠ¤íŠ¸"""
    print("ğŸš€ ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("=" * 40)
    
    base_dir = Path("ai_models/checkpoints")
    
    # 1. Segformer í…ŒìŠ¤íŠ¸
    segformer_path = base_dir / "step_01_human_parsing/segformer_b2_clothes"
    if segformer_path.exists():
        try:
            from transformers import SegformerImageProcessor, SegformerForSemanticSegmentation
            processor = SegformerImageProcessor.from_pretrained(str(segformer_path))
            model = SegformerForSemanticSegmentation.from_pretrained(str(segformer_path))
            print("âœ… Segformer ì¸ì²´ íŒŒì‹±: ì •ìƒ")
        except Exception as e:
            print(f"âŒ Segformer ì¸ì²´ íŒŒì‹±: ì‹¤íŒ¨ - {e}")
    else:
        print("âŒ Segformer ì¸ì²´ íŒŒì‹±: íŒŒì¼ ì—†ìŒ")
    
    # 2. UÂ²-Net ONNX í…ŒìŠ¤íŠ¸
    u2net_path = base_dir / "step_03_cloth_segmentation/u2net.onnx"
    if u2net_path.exists():
        try:
            import onnxruntime as ort
            session = ort.InferenceSession(str(u2net_path))
            print("âœ… UÂ²-Net ONNX: ì •ìƒ")
        except Exception as e:
            print(f"âŒ UÂ²-Net ONNX: ì‹¤íŒ¨ - {e}")
    else:
        print("âŒ UÂ²-Net ONNX: íŒŒì¼ ì—†ìŒ")
    
    # 3. MediaPipe í…ŒìŠ¤íŠ¸
    mediapipe_path = base_dir / "step_02_pose_estimation/pose_landmarker.task"
    if mediapipe_path.exists():
        size_mb = mediapipe_path.stat().st_size / (1024**2)
        print(f"âœ… MediaPipe í¬ì¦ˆ: ì •ìƒ ({size_mb:.1f}MB)")
    else:
        print("âŒ MediaPipe í¬ì¦ˆ: íŒŒì¼ ì—†ìŒ")
    
    # 4. CLIP í…ŒìŠ¤íŠ¸ (safetensorsë§Œ)
    clip_path = base_dir / "shared_encoder/clip-vit-base-patch32"
    if clip_path.exists():
        safetensors_files = list(clip_path.glob("*.safetensors"))
        if safetensors_files:
            print(f"âœ… CLIP (safetensors): ì •ìƒ ({len(safetensors_files)}ê°œ íŒŒì¼)")
        else:
            print("âš ï¸ CLIP: safetensors íŒŒì¼ ì—†ìŒ")
    else:
        print("âŒ CLIP: ë””ë ‰í† ë¦¬ ì—†ìŒ")
    
    print("\\nğŸ‰ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")

if __name__ == "__main__":
    test_models()
'''
        
        with open("test_final_models.py", 'w', encoding='utf-8') as f:
            f.write(test_script)
        
        logger.info("ğŸ“‹ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ ìƒì„±: test_final_models.py")

    def run(self) -> bool:
        """ë©”ì¸ ì‹¤í–‰"""
        try:
            print("\nğŸ”¥ ìµœì¢… ì™„ì „í•œ AI ëª¨ë¸ ë‹¤ìš´ë¡œë”")
            print("=" * 60)
            
            # í•„ìˆ˜ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
            success = self.download_essential_models()
            
            if not success:
                logger.warning("âš ï¸ ì¼ë¶€ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨í–ˆì§€ë§Œ ê³„ì† ì§„í–‰")
            
            # ì„¤ì • íŒŒì¼ ìƒì„±
            self.create_model_config()
            
            # ê²€ì¦
            results = self.verify_models()
            
            # í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ ìƒì„±
            self._create_simple_test_script()
            
            logger.info("ğŸš€ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ!")
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ ë‹¤ìš´ë¡œë“œ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            return False


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    downloader = FinalModelDownloader()
    
    success = downloader.run()
    
    if success:
        print("\nğŸ‰ ëª¨ë¸ ì¤€ë¹„ ì™„ë£Œ!")
        print(f"ğŸ“ ìœ„ì¹˜: {downloader.base_dir}")
        print("\nğŸ“‹ ë‹¤ìŒ ë‹¨ê³„:")
        print("1. python test_final_models.py  # ëª¨ë¸ í…ŒìŠ¤íŠ¸")
        print("2. python -m app.main  # ì„œë²„ ì‹¤í–‰")
        
        # ê¶Œì¥ì‚¬í•­
        print("\nğŸ’¡ ê¶Œì¥ì‚¬í•­:")
        print("- CLIP ëª¨ë¸ì€ safetensors ë²„ì „ë§Œ ì‚¬ìš©í•˜ì—¬ torch í˜¸í™˜ì„± ë¬¸ì œ í•´ê²°")
        print("- MediaPipeì™€ YOLOv8 ë‘ ê°€ì§€ í¬ì¦ˆ ì¶”ì • ëª¨ë¸ ì œê³µ")
        print("- UÂ²-Net ONNXì™€ MobileSAM ë‘ ê°€ì§€ ì„¸ê·¸ë©˜í…Œì´ì…˜ ëª¨ë¸ ì œê³µ")
    else:
        print("\nâŒ ì¼ë¶€ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨")
        print("ğŸ“‹ ë¬¸ì œ í•´ê²°:")
        print("1. ë„¤íŠ¸ì›Œí¬ ì—°ê²° í™•ì¸")
        print("2. python test_final_models.pyë¡œ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ í™•ì¸")
        print("3. ì¼ë¶€ ëª¨ë¸ë§Œìœ¼ë¡œë„ ê¸°ë³¸ ê¸°ëŠ¥ ì‚¬ìš© ê°€ëŠ¥")

if __name__ == "__main__":
    main()