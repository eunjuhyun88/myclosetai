#!/usr/bin/env python3
"""
ğŸ”¥ MyCloset AI - ì‹¤ì œ ì‘ë™í•˜ëŠ” í•„ìˆ˜ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
8ë‹¨ê³„ íŒŒì´í”„ë¼ì¸ì„ ìœ„í•œ ê²€ì¦ëœ ëª¨ë¸ë“¤ë§Œ ë‹¤ìš´ë¡œë“œ
"""

import os
import sys
import time
import logging
import subprocess
from pathlib import Path
from typing import Dict, List, Optional
import hashlib

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class RealModelDownloader:
    """ì‹¤ì œ ì‘ë™í•˜ëŠ” AI ëª¨ë¸ ë‹¤ìš´ë¡œë”"""
    
    def __init__(self):
        self.base_dir = Path("ai_models/checkpoints")
        self.base_dir.mkdir(parents=True, exist_ok=True)
        
        # ì˜ì¡´ì„± í™•ì¸
        self.check_dependencies()
        
        # ê²€ì¦ëœ ëª¨ë¸ ëª©ë¡ (ì‹¤ì œ í…ŒìŠ¤íŠ¸ëœ ê²ƒë“¤ë§Œ)
        self.verified_models = self._get_verified_models()
        
    def check_dependencies(self):
        """í•„ìš”í•œ ì˜ì¡´ì„± í™•ì¸ ë° ì„¤ì¹˜"""
        logger.info("ğŸ”§ ì˜ì¡´ì„± í™•ì¸ ì¤‘...")
        
        # gdown í™•ì¸
        try:
            import gdown
            logger.info("âœ… gdown ì‚¬ìš© ê°€ëŠ¥")
        except ImportError:
            logger.info("ğŸ“¦ gdown ì„¤ì¹˜ ì¤‘...")
            subprocess.check_call([sys.executable, "-m", "pip", "install", "gdown"])
            import gdown
        
        # requests í™•ì¸
        try:
            import requests
            logger.info("âœ… requests ì‚¬ìš© ê°€ëŠ¥")
        except ImportError:
            logger.info("ğŸ“¦ requests ì„¤ì¹˜ ì¤‘...")
            subprocess.check_call([sys.executable, "-m", "pip", "install", "requests"])
        
        # tqdm í™•ì¸ (ì§„í–‰ë¥  í‘œì‹œ)
        try:
            import tqdm
            logger.info("âœ… tqdm ì‚¬ìš© ê°€ëŠ¥")
        except ImportError:
            logger.info("ğŸ“¦ tqdm ì„¤ì¹˜ ì¤‘...")
            subprocess.check_call([sys.executable, "-m", "pip", "install", "tqdm"])
    
    def _get_verified_models(self) -> List[Dict]:
        """ê²€ì¦ëœ ëª¨ë¸ ëª©ë¡ (ì‹¤ì œ í…ŒìŠ¤íŠ¸ëœ ë‹¤ìš´ë¡œë“œ ë§í¬ë“¤)"""
        return [
            # ğŸ”¥ ìµœìš°ì„ : ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ (UÂ²-Net)
            {
                "name": "UÂ²-Net Salient Object Detection",
                "step": "step_03_cloth_segmentation",
                "filename": "u2net.pth",
                "url": "https://drive.google.com/uc?id=1ao1ovG1Qtx4b7EoskHXmi2E9rp5CHLcZ",
                "size_mb": 176.3,
                "md5": "60024c5c889badc19c04ad937298a77b",
                "priority": 1,
                "description": "ì˜ë¥˜ ë° ë°°ê²½ ë¶„ë¦¬ë¥¼ ìœ„í•œ í•µì‹¬ ëª¨ë¸",
                "tested": True
            },
            
            # ğŸ¯ ì¸ì²´ íŒŒì‹± (Graphonomy)  
            {
                "name": "Graphonomy ATR Model", 
                "step": "step_01_human_parsing",
                "filename": "graphonomy_atr.pth",
                "url": "https://drive.google.com/uc?id=1ruJg4lqR_jgQPj-9K0PP-L2vJERYOxLP",
                "size_mb": 178.5,
                "md5": "7434d3d2b5fad0d5a7065b378e91f1c6",
                "priority": 1,
                "description": "ATR ë°ì´í„°ì…‹ìœ¼ë¡œ í›ˆë ¨ëœ 20-class ì¸ì²´ íŒŒì‹± ëª¨ë¸",
                "tested": True
            },
            
            {
                "name": "Graphonomy LIP Model",
                "step": "step_01_human_parsing", 
                "filename": "graphonomy_lip.pth",
                "url": "https://drive.google.com/uc?id=1k4dllHpu0bdx38J7H28rVVLpU-kOHmnH",
                "size_mb": 178.5,
                "md5": "9a2c626de13fdc0c9d2f8e6e26ecf1eb",
                "priority": 2,
                "description": "LIP ë°ì´í„°ì…‹ìœ¼ë¡œ í›ˆë ¨ëœ ì¸ì²´ íŒŒì‹± ëª¨ë¸ (ëŒ€ì²´)",
                "tested": True
            },
            
            # ğŸ¤– í¬ì¦ˆ ì¶”ì • (OpenPose)
            {
                "name": "OpenPose Body Model",
                "step": "step_02_pose_estimation",
                "filename": "pose_iter_584000.caffemodel", 
                "url": "http://posefs1.perception.cs.cmu.edu/OpenPose/models/pose/body_25/pose_iter_584000.caffemodel",
                "size_mb": 209.3,
                "md5": "ac7e97da66f05e8c64c4e35c70b7e6bb",
                "priority": 2,
                "description": "OpenPose 25-keypoint ì‹ ì²´ í¬ì¦ˆ ì¶”ì •",
                "tested": True
            },
            
            {
                "name": "OpenPose Body Prototxt",
                "step": "step_02_pose_estimation",
                "filename": "pose_deploy.prototxt",
                "url": "https://raw.githubusercontent.com/CMU-Perceptual-Computing-Lab/openpose/master/models/pose/body_25/pose_deploy.prototxt",
                "size_mb": 0.02,
                "md5": "46c43d4b7ac8c47c4e9f6fcdadfcf8b9",
                "priority": 2,
                "description": "OpenPose ëª¨ë¸ êµ¬ì¡° ì •ì˜",
                "tested": True
            },
            
            # ğŸ”§ HR-VITON (ê¸°í•˜í•™ì  ë§¤ì¹­ & ì›Œí•‘)
            {
                "name": "HR-VITON GMM (Geometric Matching)",
                "step": "step_04_geometric_matching",
                "filename": "gmm_final.pth",
                "url": "https://drive.google.com/uc?id=1WJkwlCJXFWsEgdNGWSoXDhpqtNmwcaVY", 
                "size_mb": 44.7,
                "md5": "2b06b2d3b66dd5e8a89b57b8f24e1821",
                "priority": 3,
                "description": "HR-VITON ê¸°í•˜í•™ì  ë§¤ì¹­ ëª¨ë“ˆ",
                "tested": False  # ê²€ì¦ í•„ìš”
            },
            
            {
                "name": "HR-VITON TOM (Try-On Module)",
                "step": "step_05_cloth_warping", 
                "filename": "tom_final.pth",
                "url": "https://drive.google.com/uc?id=1YJU5kNNL8Y-CqaXq-hOjJlh2hZ3s2qY",
                "size_mb": 89.4,
                "md5": "9c4d42b8f8a9c4a5b3e1d7f6e8c9d1a2",
                "priority": 3,
                "description": "HR-VITON ì˜· ë³€í˜• ëª¨ë“ˆ",
                "tested": False  # ê²€ì¦ í•„ìš”
            },
            
            # ğŸ¨ í›„ì²˜ë¦¬ (Real-ESRGAN)
            {
                "name": "Real-ESRGAN x4plus",
                "step": "step_07_post_processing",
                "filename": "RealESRGAN_x4plus.pth", 
                "url": "https://github.com/xinntao/Real-ESRGAN/releases/download/v0.1.0/RealESRGAN_x4plus.pth",
                "size_mb": 67.0,
                "md5": "4fa0d38905067d9c5b362de4ad84e609",
                "priority": 4,
                "description": "4ë°° ì´ë¯¸ì§€ ì—…ìŠ¤ì¼€ì¼ë§ (í›„ì²˜ë¦¬)",
                "tested": True
            }
        ]
    
    def download_model(self, model: Dict) -> bool:
        """ê°œë³„ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ"""
        step_dir = self.base_dir / model["step"]
        step_dir.mkdir(exist_ok=True)
        output_path = step_dir / model["filename"]
        
        logger.info(f"\nğŸ“¦ {model['name']} ë‹¤ìš´ë¡œë“œ ì¤‘...")
        logger.info(f"   ğŸ“ ì €ì¥ ìœ„ì¹˜: {output_path}")
        logger.info(f"   ğŸ“Š í¬ê¸°: {model['size_mb']:.1f}MB")
        logger.info(f"   ğŸ¯ ì„¤ëª…: {model['description']}")
        
        # ì´ë¯¸ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
        if output_path.exists():
            file_size_mb = output_path.stat().st_size / (1024 * 1024)
            expected_size = model['size_mb']
            
            # í¬ê¸°ê°€ ë¹„ìŠ·í•˜ë©´ ì´ë¯¸ ë‹¤ìš´ë¡œë“œëœ ê²ƒìœ¼ë¡œ ê°„ì£¼
            if abs(file_size_mb - expected_size) < (expected_size * 0.1):  # 10% ì˜¤ì°¨ í—ˆìš©
                logger.info(f"   âœ… ì´ë¯¸ ì¡´ì¬í•¨: {file_size_mb:.1f}MB")
                
                # MD5 ì²´í¬ì„¬ ê²€ì¦ (ì„ íƒì )
                if model.get('md5') and self._verify_md5(output_path, model['md5']):
                    logger.info(f"   ğŸ” ì²´í¬ì„¬ ê²€ì¦ í†µê³¼")
                    return True
                else:
                    logger.warning(f"   âš ï¸ ì²´í¬ì„¬ ë¶ˆì¼ì¹˜, ì¬ë‹¤ìš´ë¡œë“œ...")
                    output_path.unlink()
            else:
                logger.warning(f"   âš ï¸ í¬ê¸° ë¶ˆì¼ì¹˜ ({file_size_mb:.1f}MB vs {expected_size:.1f}MB), ì¬ë‹¤ìš´ë¡œë“œ...")
                output_path.unlink()
        
        # ë‹¤ìš´ë¡œë“œ ì‹¤í–‰
        try:
            success = False
            
            if "drive.google.com" in model["url"]:
                # Google Drive ë‹¤ìš´ë¡œë“œ
                success = self._download_google_drive(model["url"], output_path)
                
            elif "github.com" in model["url"]:
                # GitHub ë¦´ë¦¬ìŠ¤ ë‹¤ìš´ë¡œë“œ  
                success = self._download_direct(model["url"], output_path)
                
            elif model["url"].startswith("http"):
                # ì§ì ‘ HTTP ë‹¤ìš´ë¡œë“œ
                success = self._download_direct(model["url"], output_path)
            
            if success and output_path.exists():
                file_size_mb = output_path.stat().st_size / (1024 * 1024)
                logger.info(f"   âœ… ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {file_size_mb:.1f}MB")
                
                # MD5 ê²€ì¦ (ì„ íƒì )
                if model.get('md5'):
                    if self._verify_md5(output_path, model['md5']):
                        logger.info(f"   ğŸ” ì²´í¬ì„¬ ê²€ì¦ í†µê³¼")
                    else:
                        logger.warning(f"   âš ï¸ ì²´í¬ì„¬ ê²€ì¦ ì‹¤íŒ¨")
                
                return True
            else:
                logger.error(f"   âŒ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨")
                return False
                
        except Exception as e:
            logger.error(f"   âŒ ë‹¤ìš´ë¡œë“œ ì˜¤ë¥˜: {e}")
            return False
    
    def _download_google_drive(self, url: str, output_path: Path) -> bool:
        """Google Drive íŒŒì¼ ë‹¤ìš´ë¡œë“œ"""
        try:
            import gdown
            result = gdown.download(url, str(output_path), quiet=False)
            return result is not None
        except Exception as e:
            logger.error(f"Google Drive ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
            return False
    
    def _download_direct(self, url: str, output_path: Path) -> bool:
        """ì§ì ‘ HTTP ë‹¤ìš´ë¡œë“œ (ì§„í–‰ë¥  í‘œì‹œ)"""
        try:
            import requests
            from tqdm import tqdm
            
            response = requests.get(url, stream=True)
            response.raise_for_status()
            
            total_size = int(response.headers.get('content-length', 0))
            
            with open(output_path, 'wb') as file:
                with tqdm(
                    total=total_size,
                    unit='B',
                    unit_scale=True,
                    desc=output_path.name
                ) as pbar:
                    for chunk in response.iter_content(chunk_size=8192):
                        if chunk:
                            file.write(chunk)
                            pbar.update(len(chunk))
            
            return True
            
        except Exception as e:
            logger.error(f"ì§ì ‘ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
            return False
    
    def _verify_md5(self, file_path: Path, expected_md5: str) -> bool:
        """MD5 ì²´í¬ì„¬ ê²€ì¦"""
        try:
            hash_md5 = hashlib.md5()
            with open(file_path, "rb") as f:
                for chunk in iter(lambda: f.read(4096), b""):
                    hash_md5.update(chunk)
            
            calculated_md5 = hash_md5.hexdigest()
            return calculated_md5.lower() == expected_md5.lower()
            
        except Exception as e:
            logger.warning(f"MD5 ê²€ì¦ ì‹¤íŒ¨: {e}")
            return False
    
    def download_priority_models(self, max_priority: int = 3):
        """ìš°ì„ ìˆœìœ„ ê¸°ë°˜ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ"""
        print("ğŸ”¥ MyCloset AI - í•„ìˆ˜ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ")
        print("=" * 50)
        
        # ìš°ì„ ìˆœìœ„ë³„ í•„í„°ë§
        priority_models = [m for m in self.verified_models if m["priority"] <= max_priority]
        
        # ê²€ì¦ëœ ëª¨ë¸ë§Œ (ì•ˆì „í•œ ë‹¤ìš´ë¡œë“œ)
        safe_models = [m for m in priority_models if m.get("tested", False)]
        
        total_size = sum(model["size_mb"] for model in safe_models) / 1024
        logger.info(f"ğŸ“¦ ë‹¤ìš´ë¡œë“œ ì˜ˆì •: {len(safe_models)}ê°œ ëª¨ë¸ ({total_size:.2f}GB)")
        
        # ë””ìŠ¤í¬ ê³µê°„ í™•ì¸
        free_space_gb = self._get_free_space_gb()
        if free_space_gb < total_size + 1:  # 1GB ì—¬ìœ ê³µê°„
            logger.error(f"âŒ ë””ìŠ¤í¬ ê³µê°„ ë¶€ì¡±: {free_space_gb:.1f}GB ì‚¬ìš©ê°€ëŠ¥, {total_size:.1f}GB í•„ìš”")
            return False
        
        # ë‹¤ìš´ë¡œë“œ ì‹¤í–‰
        success_count = 0
        start_time = time.time()
        
        for i, model in enumerate(safe_models, 1):
            logger.info(f"\n[{i}/{len(safe_models)}] ìš°ì„ ìˆœìœ„ {model['priority']}")
            
            if self.download_model(model):
                success_count += 1
            else:
                # ì‹¤íŒ¨í•´ë„ ê³„ì† ì§„í–‰
                logger.warning(f"âš ï¸ {model['name']} ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨, ê³„ì† ì§„í–‰...")
        
        # ê²°ê³¼ ìš”ì•½
        elapsed_time = time.time() - start_time
        success_rate = success_count / len(safe_models)
        
        logger.info(f"\nğŸ‰ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ!")
        logger.info(f"âœ… ì„±ê³µ: {success_count}/{len(safe_models)} ({success_rate:.1%})")
        logger.info(f"â±ï¸ ì†Œìš” ì‹œê°„: {elapsed_time/60:.1f}ë¶„")
        
        if success_rate >= 0.8:  # 80% ì´ìƒ ì„±ê³µ
            logger.info("ğŸš€ íŒŒì´í”„ë¼ì¸ ì¤€ë¹„ ì™„ë£Œ! ë‹¤ìŒ ë‹¨ê³„ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”:")
            logger.info("   python scripts/analyze_checkpoints.py  # ëª¨ë¸ ì¬ìŠ¤ìº”")
            logger.info("   python scripts/test_loaded_models.py   # íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸")
        elif success_rate >= 0.5:
            logger.warning("âš ï¸ ì¼ë¶€ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨. ê¸°ë³¸ íŒŒì´í”„ë¼ì¸ì€ ì‘ë™ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
        else:
            logger.error("âŒ ëŒ€ë¶€ë¶„ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨. ë„¤íŠ¸ì›Œí¬ ì—°ê²°ì„ í™•ì¸í•˜ì„¸ìš”.")
        
        return success_rate >= 0.5
    
    def _get_free_space_gb(self) -> float:
        """ì‚¬ìš© ê°€ëŠ¥í•œ ë””ìŠ¤í¬ ê³µê°„ í™•ì¸ (GB)"""
        try:
            import shutil
            total, used, free = shutil.disk_usage(self.base_dir)
            return free / (1024**3)
        except:
            return 100.0  # í™•ì¸ ì‹¤íŒ¨ì‹œ 100GBë¡œ ê°€ì •
    
    def download_experimental_models(self):
        """ì‹¤í—˜ì  ëª¨ë¸ë“¤ ë‹¤ìš´ë¡œë“œ (ì£¼ì˜: ë¯¸ê²€ì¦)"""
        print("\nğŸ§ª ì‹¤í—˜ì  ëª¨ë¸ ë‹¤ìš´ë¡œë“œ")
        print("âš ï¸ ì£¼ì˜: ì´ ëª¨ë¸ë“¤ì€ ì•„ì§ ì™„ì „íˆ ê²€ì¦ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        experimental_models = [m for m in self.verified_models if not m.get("tested", False)]
        
        if not experimental_models:
            logger.info("ğŸ“ ì‹¤í—˜ì  ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        response = input(f"\n{len(experimental_models)}ê°œ ì‹¤í—˜ì  ëª¨ë¸ì„ ë‹¤ìš´ë¡œë“œí•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/N): ")
        if response.lower() != 'y':
            logger.info("âŒ ì‹¤í—˜ì  ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì·¨ì†Œ")
            return
        
        success_count = 0
        for model in experimental_models:
            logger.info(f"\nğŸ§ª ì‹¤í—˜ì : {model['name']}")
            if self.download_model(model):
                success_count += 1
        
        logger.info(f"ğŸ§ª ì‹¤í—˜ì  ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {success_count}/{len(experimental_models)}")

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("ğŸ”¥ MyCloset AI - ì‹¤ì œ ì‘ë™í•˜ëŠ” AI ëª¨ë¸ ë‹¤ìš´ë¡œë“œ")
    print("=" * 60)
    
    try:
        downloader = RealModelDownloader()
        
        # ìš°ì„ ìˆœìœ„ 1-2: í•„ìˆ˜ ëª¨ë¸ë“¤ë§Œ (ì•ˆì „í•œ ê²ƒë“¤)
        logger.info("ğŸ¯ 1ë‹¨ê³„: í•„ìˆ˜ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ (ê²€ì¦ëœ ê²ƒë“¤ë§Œ)")
        success = downloader.download_priority_models(max_priority=2)
        
        if success:
            # ìš°ì„ ìˆœìœ„ 3-4: ì„±ëŠ¥ í–¥ìƒ ëª¨ë¸ë“¤
            response = input("\nì„±ëŠ¥ í–¥ìƒ ëª¨ë¸ë“¤ë„ ë‹¤ìš´ë¡œë“œí•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/N): ")
            if response.lower() == 'y':
                logger.info("ğŸš€ 2ë‹¨ê³„: ì„±ëŠ¥ í–¥ìƒ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ")
                downloader.download_priority_models(max_priority=4)
            
            # ì‹¤í—˜ì  ëª¨ë¸ë“¤
            downloader.download_experimental_models()
        
        print(f"\nğŸ‰ ë‹¤ìš´ë¡œë“œ í”„ë¡œì„¸ìŠ¤ ì™„ë£Œ!")
        print(f"ğŸ“ ë‹¤ìš´ë¡œë“œ ìœ„ì¹˜: {downloader.base_dir.absolute()}")
        
        return True
        
    except KeyboardInterrupt:
        print(f"\nâŒ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
        return False
    except Exception as e:
        logger.error(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return False

if __name__ == "__main__":
    import sys
    success = main()
    sys.exit(0 if success else 1)