#!/bin/bash
# MyCloset AI ì¦‰ì‹œ ìˆ˜ì • ìŠ¤í¬ë¦½íŠ¸ - preprocess_image í•¨ìˆ˜ ì¶”ê°€

set -e

# ìƒ‰ìƒ ì •ì˜
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m'

echo -e "${BLUE}ğŸ”§ MyCloset AI preprocess_image í•¨ìˆ˜ ëˆ„ë½ ë¬¸ì œ ì¦‰ì‹œ í•´ê²°${NC}"
echo "=================================================================="

cd backend

# 1. model_loader.py ë°±ì—…
echo -e "${YELLOW}ğŸ“‹ ë°±ì—… ìƒì„± ì¤‘...${NC}"
cp app/ai_pipeline/utils/model_loader.py app/ai_pipeline/utils/model_loader.py.backup

# 2. preprocess_image í•¨ìˆ˜ë“¤ ì¶”ê°€
echo -e "${BLUE}ğŸ”§ preprocess_image í•¨ìˆ˜ë“¤ ì¶”ê°€ ì¤‘...${NC}"

# __all__ ëª©ë¡ì— í•¨ìˆ˜ë“¤ ì¶”ê°€
python3 << 'EOF'
import re

# model_loader.py íŒŒì¼ ì½ê¸°
with open('app/ai_pipeline/utils/model_loader.py', 'r') as f:
    content = f.read()

# __all__ ë¦¬ìŠ¤íŠ¸ì— ëˆ„ë½ëœ í•¨ìˆ˜ë“¤ ì¶”ê°€
all_pattern = r'(__all__ = \[.*?)\]'

new_exports = '''
    # ì´ë¯¸ì§€ ì „ì²˜ë¦¬ í•¨ìˆ˜ë“¤ (ëˆ„ë½ëœ í•¨ìˆ˜ë“¤)
    'preprocess_image',
    'postprocess_segmentation', 
    'preprocess_pose_input',
    'preprocess_human_parsing_input',
    'preprocess_cloth_segmentation_input',
    'tensor_to_pil',
    'pil_to_tensor',
    'resize_image_with_aspect_ratio',
    'create_visualization_grid',
    'optimize_tensor_memory',
    'safe_model_forward',
'''

def replace_all(match):
    return match.group(1) + new_exports + ']'

content = re.sub(all_pattern, replace_all, content, flags=re.DOTALL)

# íŒŒì¼ ëì— í•¨ìˆ˜ë“¤ ì¶”ê°€ (logger ë©”ì‹œì§€ ì•ì—)
insert_point = content.rfind('logger.info("âœ… ModelLoader v4.3 ëª¨ë“ˆ ë¡œë“œ ì™„ë£Œ")')

if insert_point == -1:
    # íŒŒì¼ ëì— ì¶”ê°€
    insert_point = len(content)

# preprocess_image í•¨ìˆ˜ë“¤ ì½”ë“œ
functions_code = '''
# ==============================================
# ğŸ”¥ ëˆ„ë½ëœ preprocess_image í•¨ìˆ˜ë“¤ ì¶”ê°€
# ==============================================

def preprocess_image(
    image: Union[Image.Image, np.ndarray, torch.Tensor],
    target_size: Tuple[int, int] = (512, 512),
    device: str = "mps",
    normalize: bool = True,
    to_tensor: bool = True
) -> torch.Tensor:
    """
    ğŸ”¥ ì´ë¯¸ì§€ ì „ì²˜ë¦¬ í•¨ìˆ˜ - Step í´ë˜ìŠ¤ë“¤ì—ì„œ ì‚¬ìš©
    
    Args:
        image: ì…ë ¥ ì´ë¯¸ì§€ (PIL.Image, numpy array, tensor)
        target_size: ëª©í‘œ í¬ê¸° (height, width)
        device: ë””ë°”ì´ìŠ¤ ("mps", "cuda", "cpu")
        normalize: ì •ê·œí™” ì—¬ë¶€ (0-1 ë²”ìœ„ë¡œ)
        to_tensor: í…ì„œë¡œ ë³€í™˜ ì—¬ë¶€
    
    Returns:
        torch.Tensor: ì „ì²˜ë¦¬ëœ ì´ë¯¸ì§€ í…ì„œ
    """
    try:
        # 1. PIL Imageë¡œ ë³€í™˜
        if isinstance(image, torch.Tensor) if TORCH_AVAILABLE else False:
            if image.dim() == 4:
                image = image.squeeze(0)
            if image.dim() == 3 and image.shape[0] == 3:
                image = image.permute(1, 2, 0)
            image = image.cpu().numpy()
            if image.dtype != np.uint8:
                image = (image * 255).astype(np.uint8)
            image = Image.fromarray(image)
        elif isinstance(image, np.ndarray) if NUMPY_AVAILABLE else False:
            if image.ndim == 3 and image.shape[2] == 3:
                image = Image.fromarray(image.astype(np.uint8))
            else:
                image = Image.fromarray(image)
        elif not isinstance(image, Image.Image):
            logger.warning(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì´ë¯¸ì§€ íƒ€ì…: {type(image)}")
            if TORCH_AVAILABLE and to_tensor:
                return torch.randn(1, 3, target_size[0], target_size[1])
            else:
                return np.random.randn(target_size[0], target_size[1], 3).astype(np.float32)
        
        # 2. RGB ë³€í™˜
        if image.mode != 'RGB':
            image = image.convert('RGB')
        
        # 3. í¬ê¸° ì¡°ì •
        if target_size != image.size:
            image = image.resize(target_size, Image.Resampling.LANCZOS)
        
        # 4. numpy ë°°ì—´ë¡œ ë³€í™˜
        img_array = np.array(image).astype(np.float32) if NUMPY_AVAILABLE else np.zeros((target_size[0], target_size[1], 3), dtype=np.float32)
        
        # 5. ì •ê·œí™”
        if normalize:
            img_array = img_array / 255.0
        
        # 6. í…ì„œ ë³€í™˜
        if to_tensor and TORCH_AVAILABLE:
            # HWC -> CHW ë³€í™˜
            img_tensor = torch.from_numpy(img_array).permute(2, 0, 1)
            
            # ë°°ì¹˜ ì°¨ì› ì¶”ê°€
            if img_tensor.dim() == 3:
                img_tensor = img_tensor.unsqueeze(0)
            
            # ë””ë°”ì´ìŠ¤ë¡œ ì´ë™
            try:
                if device != "cpu" and torch.cuda.is_available() and device == "cuda":
                    img_tensor = img_tensor.cuda()
                elif device == "mps" and torch.backends.mps.is_available():
                    img_tensor = img_tensor.to("mps")
                else:
                    img_tensor = img_tensor.cpu()
            except Exception as e:
                logger.warning(f"ë””ë°”ì´ìŠ¤ ì´ë™ ì‹¤íŒ¨: {e}, CPU ì‚¬ìš©")
                img_tensor = img_tensor.cpu()
            
            return img_tensor
        else:
            return img_array
    
    except Exception as e:
        logger.error(f"âŒ ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        # í´ë°±: ê¸°ë³¸ í¬ê¸° ë”ë¯¸ í…ì„œ
        if TORCH_AVAILABLE and to_tensor:
            return torch.randn(1, 3, target_size[0], target_size[1])
        else:
            return np.random.randn(target_size[0], target_size[1], 3).astype(np.float32) if NUMPY_AVAILABLE else [[[]]]

def postprocess_segmentation(
    segmentation: torch.Tensor,
    original_size: Tuple[int, int],
    threshold: float = 0.5,
    smooth: bool = True
) -> np.ndarray:
    """ì„¸ê·¸ë©˜í…Œì´ì…˜ ê²°ê³¼ í›„ì²˜ë¦¬"""
    try:
        if not TORCH_AVAILABLE or not NUMPY_AVAILABLE:
            return np.zeros(original_size[::-1], dtype=np.uint8)
            
        # í…ì„œë¥¼ numpyë¡œ ë³€í™˜
        if isinstance(segmentation, torch.Tensor):
            seg_np = segmentation.detach().cpu().numpy()
        else:
            seg_np = segmentation
        
        # ë°°ì¹˜ ë° ì±„ë„ ì°¨ì› ì œê±°
        if seg_np.ndim == 4:
            seg_np = seg_np.squeeze(0)
        if seg_np.ndim == 3 and seg_np.shape[0] == 1:
            seg_np = seg_np.squeeze(0)
        
        # ì´ì§„í™”
        if threshold > 0:
            seg_np = (seg_np > threshold).astype(np.float32)
        
        # í¬ê¸° ì¡°ì •
        if seg_np.shape != original_size[::-1]:
            seg_img = Image.fromarray((seg_np * 255).astype(np.uint8))
            seg_img = seg_img.resize(original_size, Image.Resampling.LANCZOS)
            seg_np = np.array(seg_img) / 255.0
        
        # 0-255 ë²”ìœ„ë¡œ ë³€í™˜
        mask = (seg_np * 255).astype(np.uint8)
        return mask
    
    except Exception as e:
        logger.error(f"âŒ ì„¸ê·¸ë©˜í…Œì´ì…˜ í›„ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        return np.zeros(original_size[::-1], dtype=np.uint8) if NUMPY_AVAILABLE else [[]]

def preprocess_pose_input(
    image: Union[Image.Image, np.ndarray],
    input_size: Tuple[int, int] = (368, 368),
    device: str = "mps"
) -> torch.Tensor:
    """í¬ì¦ˆ ì¶”ì •ìš© ì´ë¯¸ì§€ ì „ì²˜ë¦¬"""
    return preprocess_image(image=image, target_size=input_size, device=device, normalize=True, to_tensor=True)

def preprocess_human_parsing_input(
    image: Union[Image.Image, np.ndarray],
    input_size: Tuple[int, int] = (512, 512),
    device: str = "mps"
) -> torch.Tensor:
    """ì¸ê°„ íŒŒì‹±ìš© ì´ë¯¸ì§€ ì „ì²˜ë¦¬"""
    return preprocess_image(image=image, target_size=input_size, device=device, normalize=True, to_tensor=True)

def preprocess_cloth_segmentation_input(
    image: Union[Image.Image, np.ndarray],
    input_size: Tuple[int, int] = (320, 320),
    device: str = "mps"
) -> torch.Tensor:
    """ì˜ë¥˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ìš© ì´ë¯¸ì§€ ì „ì²˜ë¦¬"""
    return preprocess_image(image=image, target_size=input_size, device=device, normalize=True, to_tensor=True)

def tensor_to_pil(tensor: torch.Tensor) -> Image.Image:
    """í…ì„œë¥¼ PIL ì´ë¯¸ì§€ë¡œ ë³€í™˜"""
    try:
        if not TORCH_AVAILABLE:
            return Image.new('RGB', (512, 512), (128, 128, 128))
            
        if tensor.dim() == 4:
            tensor = tensor.squeeze(0)
        if tensor.dim() == 3:
            tensor = tensor.permute(1, 2, 0)
        
        tensor = tensor.detach().cpu()
        
        # ì •ê·œí™”ëœ í…ì„œë¼ë©´ 0-255ë¡œ ë³€í™˜
        if tensor.max() <= 1.0:
            tensor = tensor * 255
        
        numpy_img = tensor.numpy().astype(np.uint8)
        return Image.fromarray(numpy_img)
    
    except Exception as e:
        logger.error(f"í…ì„œ->PIL ë³€í™˜ ì‹¤íŒ¨: {e}")
        return Image.new('RGB', (512, 512), (128, 128, 128))

def pil_to_tensor(image: Image.Image, device: str = "mps", normalize: bool = True) -> torch.Tensor:
    """PIL ì´ë¯¸ì§€ë¥¼ í…ì„œë¡œ ë³€í™˜"""
    return preprocess_image(image, device=device, normalize=normalize, to_tensor=True)

def resize_image_with_aspect_ratio(
    image: Image.Image,
    target_size: Tuple[int, int],
    fill_color: Tuple[int, int, int] = (0, 0, 0)
) -> Image.Image:
    """ì¢…íš¡ë¹„ ìœ ì§€í•˜ë©´ì„œ ì´ë¯¸ì§€ í¬ê¸° ì¡°ì •"""
    try:
        target_w, target_h = target_size
        original_w, original_h = image.size
        
        # ì¢…íš¡ë¹„ ê³„ì‚°
        aspect_ratio = original_w / original_h
        target_aspect_ratio = target_w / target_h
        
        if aspect_ratio > target_aspect_ratio:
            new_w = target_w
            new_h = int(target_w / aspect_ratio)
        else:
            new_h = target_h
            new_w = int(target_h * aspect_ratio)
        
        # í¬ê¸° ì¡°ì •
        resized = image.resize((new_w, new_h), Image.Resampling.LANCZOS)
        
        # ìƒˆ ì´ë¯¸ì§€ ìƒì„± ë° ì¤‘ì•™ ë°°ì¹˜
        result = Image.new('RGB', target_size, fill_color)
        paste_x = (target_w - new_w) // 2
        paste_y = (target_h - new_h) // 2
        result.paste(resized, (paste_x, paste_y))
        
        return result
    
    except Exception as e:
        logger.error(f"ì¢…íš¡ë¹„ ì¡°ì • ì‹¤íŒ¨: {e}")
        return image.resize(target_size, Image.Resampling.LANCZOS)

def create_visualization_grid(
    images: List[Image.Image],
    labels: List[str],
    grid_size: Optional[Tuple[int, int]] = None
) -> Image.Image:
    """ì—¬ëŸ¬ ì´ë¯¸ì§€ë¥¼ ê·¸ë¦¬ë“œë¡œ ë°°ì¹˜í•˜ì—¬ ì‹œê°í™”"""
    try:
        if not images:
            return Image.new('RGB', (512, 512), (128, 128, 128))
        
        num_images = len(images)
        
        if grid_size is None:
            cols = int(np.ceil(np.sqrt(num_images))) if NUMPY_AVAILABLE else 2
            rows = int(np.ceil(num_images / cols)) if NUMPY_AVAILABLE else 2
        else:
            cols, rows = grid_size
        
        # ê°œë³„ ì´ë¯¸ì§€ í¬ê¸°
        img_w, img_h = 256, 256
        
        # ì „ì²´ ê·¸ë¦¬ë“œ í¬ê¸°
        grid_w = cols * img_w + (cols - 1) * 10
        grid_h = rows * img_h + (rows - 1) * 10 + 50
        
        # ê·¸ë¦¬ë“œ ì´ë¯¸ì§€ ìƒì„±
        grid_img = Image.new('RGB', (grid_w, grid_h), (240, 240, 240))
        
        for i, (img, label) in enumerate(zip(images, labels)):
            if i >= cols * rows:
                break
            
            row = i // cols
            col = i % cols
            
            # ì´ë¯¸ì§€ í¬ê¸° ì¡°ì •
            img_resized = img.resize((img_w, img_h), Image.Resampling.LANCZOS)
            
            # ë°°ì¹˜ ìœ„ì¹˜ ê³„ì‚°
            x = col * (img_w + 10)
            y = row * (img_h + 60) + 50
            
            # ì´ë¯¸ì§€ ë¶™ì´ê¸°
            grid_img.paste(img_resized, (x, y))
        
        return grid_img
    
    except Exception as e:
        logger.error(f"ì‹œê°í™” ê·¸ë¦¬ë“œ ìƒì„± ì‹¤íŒ¨: {e}")
        return Image.new('RGB', (512, 512), (128, 128, 128))

def optimize_tensor_memory(tensor: torch.Tensor) -> torch.Tensor:
    """í…ì„œ ë©”ëª¨ë¦¬ ìµœì í™”"""
    try:
        if not TORCH_AVAILABLE:
            return tensor
        
        # ë©”ëª¨ë¦¬ ì •ë¦¬
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
        
        # MPS ìºì‹œ ì •ë¦¬
        if torch.backends.mps.is_available():
            try:
                torch.mps.empty_cache()
            except:
                pass
        
        return tensor.contiguous()
    
    except Exception as e:
        logger.warning(f"í…ì„œ ë©”ëª¨ë¦¬ ìµœì í™” ì‹¤íŒ¨: {e}")
        return tensor

def safe_model_forward(model: Any, inputs: torch.Tensor, device: str = "mps") -> torch.Tensor:
    """ì•ˆì „í•œ ëª¨ë¸ forward pass"""
    try:
        if not TORCH_AVAILABLE:
            return torch.zeros(1, 3, 512, 512)
            
        if not hasattr(model, '__call__'):
            raise ValueError("ëª¨ë¸ì´ í˜¸ì¶œ ê°€ëŠ¥í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤")
        
        # ì…ë ¥ì„ ì˜¬ë°”ë¥¸ ë””ë°”ì´ìŠ¤ë¡œ ì´ë™
        if hasattr(inputs, 'to'):
            try:
                inputs = inputs.to(device)
            except Exception as e:
                logger.warning(f"ì…ë ¥ ë””ë°”ì´ìŠ¤ ì´ë™ ì‹¤íŒ¨: {e}")
        
        # ëª¨ë¸ì„ í‰ê°€ ëª¨ë“œë¡œ
        if hasattr(model, 'eval'):
            model.eval()
        
        # ê·¸ë˜ë””ì–¸íŠ¸ ë¹„í™œì„±í™”
        with torch.no_grad():
            outputs = model(inputs)
        
        return outputs
    
    except Exception as e:
        logger.error(f"ëª¨ë¸ forward ì‹¤íŒ¨: {e}")
        # í´ë°±: ì…ë ¥ê³¼ ê°™ì€ í¬ê¸°ì˜ ë”ë¯¸ ì¶œë ¥
        if hasattr(inputs, 'shape'):
            return torch.zeros_like(inputs)
        else:
            return torch.zeros(1, 3, 512, 512)

'''

# í•¨ìˆ˜ë“¤ ì‚½ì…
new_content = content[:insert_point] + functions_code + '\n' + content[insert_point:]

# íŒŒì¼ì— ì“°ê¸°
with open('app/ai_pipeline/utils/model_loader.py', 'w') as f:
    f.write(new_content)

print("âœ… preprocess_image í•¨ìˆ˜ë“¤ ì¶”ê°€ ì™„ë£Œ")
EOF

# 3. import ëˆ„ë½ ë¬¸ì œ í•´ê²°
echo -e "${BLUE}ğŸ”§ import êµ¬ë¬¸ ì¶”ê°€ ì¤‘...${NC}"

python3 << 'EOF'
# model_loader.pyì— Union import ì¶”ê°€
with open('app/ai_pipeline/utils/model_loader.py', 'r') as f:
    content = f.read()

# typing importì— Union ì¶”ê°€ (ì—†ë‹¤ë©´)
if 'Union' not in content:
    content = content.replace(
        'from typing import Dict, Any, Optional,',
        'from typing import Dict, Any, Optional, Union,'
    )

# List import ì¶”ê°€ (ì—†ë‹¤ë©´)
if ', List,' not in content:
    content = content.replace(
        'from typing import Dict, Any, Optional, Union,',
        'from typing import Dict, Any, Optional, Union, List,'
    )

with open('app/ai_pipeline/utils/model_loader.py', 'w') as f:
    f.write(content)

print("âœ… import êµ¬ë¬¸ ì¶”ê°€ ì™„ë£Œ")
EOF

# 4. ì„œë²„ ì¬ì‹œì‘
echo -e "${YELLOW}ğŸ”„ ì„œë²„ ì¬ì‹œì‘...${NC}"

# ê¸°ì¡´ í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ
pkill -f "python.*app/main.py" 2>/dev/null || true
sleep 2

# ì„œë²„ ì¬ì‹œì‘
echo -e "${GREEN}ğŸš€ ì„œë²„ ì‹œì‘ ì¤‘...${NC}"
python app/main.py &

# ì ì‹œ ëŒ€ê¸°
sleep 5

# ì„œë²„ ìƒíƒœ í™•ì¸
echo -e "${BLUE}ğŸ“Š ì„œë²„ ìƒíƒœ í™•ì¸...${NC}"
curl -s http://localhost:8000/health | python -m json.tool || echo "ì„œë²„ ì•„ì§ ì‹œì‘ ì¤‘..."

echo -e "${GREEN}âœ… preprocess_image í•¨ìˆ˜ ëˆ„ë½ ë¬¸ì œ í•´ê²° ì™„ë£Œ!${NC}"
echo ""
echo "ğŸ“ ë‹¤ìŒ ë‹¨ê³„:"
echo "1. ë¸Œë¼ìš°ì €ì—ì„œ http://localhost:8000/docs í™•ì¸"
echo "2. curl http://localhost:8000/api/step/health í…ŒìŠ¤íŠ¸"
echo "3. ë¡œê·¸ í™•ì¸: tail -f logs/*.log"