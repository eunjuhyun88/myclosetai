# emergency_fix.py - ê¸´ê¸‰ ìˆ˜ì • ìŠ¤í¬ë¦½íŠ¸
"""
ğŸ”¥ MyCloset AI ê¸´ê¸‰ ìˆ˜ì • ìŠ¤í¬ë¦½íŠ¸
conda í™˜ê²½ì—ì„œ ì¦‰ì‹œ ì‹¤í–‰ ê°€ëŠ¥
"""

import sys
import os
import logging
from pathlib import Path

# ê²½ë¡œ ì„¤ì •
backend_path = Path("/Users/gimdudeul/MVP/mycloset-ai/backend")
app_path = backend_path / "app"
sys.path.insert(0, str(app_path))

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def fix_opencv_compatibility():
    """OpenCV cv2.data ì˜¤ë¥˜ ìˆ˜ì •"""
    try:
        import cv2
        logger.info(f"ğŸ” OpenCV ë²„ì „: {cv2.__version__}")
        
        if not hasattr(cv2, 'data'):
            logger.warning("âš ï¸ cv2.data ì†ì„±ì´ ì—†ìŒ. ìˆ˜ë™ ìƒì„±...")
            
            # conda í™˜ê²½ì—ì„œ OpenCV ë°ì´í„° ê²½ë¡œ ì°¾ê¸°
            possible_paths = [
                "/opt/homebrew/Caskroom/miniforge/base/envs/mycloset-ai/share/opencv4",
                "/opt/homebrew/Caskroom/miniforge/base/envs/mycloset-ai/lib/python3.11/site-packages/cv2/data",
                "/opt/homebrew/share/opencv4",
            ]
            
            for path_str in possible_paths:
                path = Path(path_str)
                haarcascades_path = path / "haarcascades"
                if haarcascades_path.exists():
                    # cv2.data ìˆ˜ë™ ìƒì„±
                    cv2.data = type('CVData', (), {})()
                    cv2.data.haarcascades = str(haarcascades_path)
                    logger.info(f"âœ… cv2.data ìƒì„± ì™„ë£Œ: {cv2.data.haarcascades}")
                    return True
            
            logger.error("âŒ haarcascades í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
            return False
        else:
            logger.info("âœ… cv2.data ì´ë¯¸ ì¡´ì¬")
            return True
            
    except Exception as e:
        logger.error(f"âŒ OpenCV ìˆ˜ì • ì‹¤íŒ¨: {e}")
        return False

def fix_pytorch_mps_compatibility():
    """PyTorch MPS í˜¸í™˜ì„± ìˆ˜ì •"""
    try:
        import torch
        logger.info(f"ğŸ” PyTorch ë²„ì „: {torch.__version__}")
        
        # MPS ì‚¬ìš© ê°€ëŠ¥ì„± í™•ì¸
        mps_available = hasattr(torch.backends, 'mps') and torch.backends.mps.is_available()
        logger.info(f"ğŸ MPS ì‚¬ìš© ê°€ëŠ¥: {mps_available}")
        
        if mps_available:
            # empty_cache ë©”ì„œë“œ í™•ì¸ ë° ìƒì„±
            if not hasattr(torch.backends.mps, 'empty_cache'):
                logger.warning("âš ï¸ torch.backends.mps.empty_cache ì—†ìŒ. ëŒ€ì²´ êµ¬í˜„ ìƒì„±...")
                
                def mps_empty_cache_fallback():
                    """MPS ë©”ëª¨ë¦¬ ì •ë¦¬ ëŒ€ì²´ í•¨ìˆ˜"""
                    try:
                        import gc
                        gc.collect()
                        if hasattr(torch.cuda, 'empty_cache'):
                            torch.cuda.empty_cache()
                        logger.debug("ğŸ§¹ MPS ë©”ëª¨ë¦¬ ì •ë¦¬ ì™„ë£Œ")
                    except Exception as e:
                        logger.warning(f"âš ï¸ ë©”ëª¨ë¦¬ ì •ë¦¬ ì‹¤íŒ¨: {e}")
                
                # ë©”ì„œë“œ ì¶”ê°€
                torch.backends.mps.empty_cache = mps_empty_cache_fallback
                logger.info("âœ… torch.backends.mps.empty_cache ëŒ€ì²´ êµ¬í˜„ ì¶”ê°€")
            
            # Mixed precision ì˜¤ë¥˜ ë°©ì§€
            torch.backends.mps.allow_tf32 = False
            logger.info("âœ… MPS TF32 ë¹„í™œì„±í™” - Float32 ê°•ì œ ì‚¬ìš©")
        
        # í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
        os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '1'
        os.environ['PYTORCH_MPS_HIGH_WATERMARK_RATIO'] = '0.0'
        
        # M3 Max ìµœì í™”
        torch.set_num_threads(16)
        logger.info("ğŸ M3 Max 16ì½”ì–´ ìµœì í™” ì™„ë£Œ")
        
        return True
        
    except Exception as e:
        logger.error(f"âŒ PyTorch MPS ìˆ˜ì • ì‹¤íŒ¨: {e}")
        return False

def fix_model_loader_callable():
    """ModelLoader callable ì˜¤ë¥˜ ìˆ˜ì •"""
    try:
        # ê¸°ì¡´ ModelLoader import ì‹œë„
        from ai_pipeline.utils.model_loader import ModelLoader
        
        # ì¸ìŠ¤í„´ìŠ¤ ìƒì„± í…ŒìŠ¤íŠ¸
        loader = ModelLoader()
        logger.info(f"âœ… ModelLoader ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ì„±ê³µ: {type(loader)}")
        
        # callable ë¬¸ì œ í™•ì¸
        problematic_methods = []
        for method_name in ['load_model_async', '_load_model_sync_wrapper', 'load_model']:
            if hasattr(loader, method_name):
                method = getattr(loader, method_name)
                if not callable(method):
                    problematic_methods.append((method_name, type(method)))
        
        if problematic_methods:
            logger.warning(f"âš ï¸ callableì´ ì•„ë‹Œ ë©”ì„œë“œë“¤: {problematic_methods}")
            # ê°„ë‹¨í•œ ìˆ˜ì • ì‹œë„
            for method_name, method_type in problematic_methods:
                if method_type == dict:
                    # dictë¥¼ ê°„ë‹¨í•œ í•¨ìˆ˜ë¡œ êµì²´
                    def simple_loader(*args, **kwargs):
                        return None
                    setattr(loader, method_name, simple_loader)
                    logger.info(f"âœ… {method_name} dict â†’ í•¨ìˆ˜ë¡œ ë³€í™˜")
        
        return True
        
    except Exception as e:
        logger.error(f"âŒ ModelLoader ìˆ˜ì • ì‹¤íŒ¨: {e}")
        return False

def test_imports():
    """ì£¼ìš” import í…ŒìŠ¤íŠ¸"""
    try:
        logger.info("ğŸ” í•µì‹¬ ë¼ì´ë¸ŒëŸ¬ë¦¬ import í…ŒìŠ¤íŠ¸...")
        
        import torch
        logger.info(f"âœ… PyTorch {torch.__version__}")
        
        import cv2
        logger.info(f"âœ… OpenCV {cv2.__version__}")
        
        import numpy as np
        logger.info(f"âœ… NumPy {np.__version__}")
        
        from PIL import Image
        logger.info("âœ… PIL/Pillow")
        
        import transformers
        logger.info(f"âœ… Transformers {transformers.__version__}")
        
        return True
        
    except Exception as e:
        logger.error(f"âŒ Import í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        return False

def main():
    """ë©”ì¸ ìˆ˜ì • í•¨ìˆ˜"""
    logger.info("ğŸ”¥ MyCloset AI ê¸´ê¸‰ ìˆ˜ì • ì‹œì‘...")
    
    success_count = 0
    total_fixes = 4
    
    # 1. OpenCV ìˆ˜ì •
    logger.info("1ï¸âƒ£ OpenCV í˜¸í™˜ì„± ìˆ˜ì •...")
    if fix_opencv_compatibility():
        success_count += 1
    
    # 2. PyTorch MPS ìˆ˜ì •
    logger.info("2ï¸âƒ£ PyTorch MPS í˜¸í™˜ì„± ìˆ˜ì •...")
    if fix_pytorch_mps_compatibility():
        success_count += 1
    
    # 3. ModelLoader ìˆ˜ì •
    logger.info("3ï¸âƒ£ ModelLoader callable ì˜¤ë¥˜ ìˆ˜ì •...")
    if fix_model_loader_callable():
        success_count += 1
    
    # 4. Import í…ŒìŠ¤íŠ¸
    logger.info("4ï¸âƒ£ í•µì‹¬ ë¼ì´ë¸ŒëŸ¬ë¦¬ í…ŒìŠ¤íŠ¸...")
    if test_imports():
        success_count += 1
    
    # ê²°ê³¼ ë³´ê³ 
    logger.info(f"ğŸ¯ ìˆ˜ì • ì™„ë£Œ: {success_count}/{total_fixes}")
    
    if success_count == total_fixes:
        logger.info("ğŸ‰ ëª¨ë“  ìˆ˜ì • ì„±ê³µ! ì„œë²„ë¥¼ ì¬ì‹œì‘í•˜ì„¸ìš”.")
        logger.info("ëª…ë ¹ì–´: uvicorn app.main:app --host 0.0.0.0 --port 8001 --reload")
    else:
        logger.warning(f"âš ï¸ {total_fixes - success_count}ê°œ ìˆ˜ì • ì‹¤íŒ¨. ìˆ˜ë™ í™•ì¸ í•„ìš”.")
    
    return success_count == total_fixes

if __name__ == "__main__":
    main()