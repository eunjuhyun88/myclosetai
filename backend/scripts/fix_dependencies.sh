#!/bin/bash
# ================================================================
# MyCloset AI - μμ •λ μμ΅΄μ„± μ„¤μΉ (ν¨ν‚¤μ§€ μ¤λ¥ ν•΄κ²°)
# ================================================================

set -e

# μƒ‰μƒ μ •μ
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m'

log_info() { echo -e "${BLUE}β„ΉοΈ  $1${NC}"; }
log_success() { echo -e "${GREEN}β… $1${NC}"; }
log_warning() { echo -e "${YELLOW}β οΈ  $1${NC}"; }
log_error() { echo -e "${RED}β $1${NC}"; }

echo "π”§ MyCloset AI - ν¨ν‚¤μ§€ μ¤λ¥ ν•΄κ²° λ° μ¬μ„¤μΉ"
echo "=================================================="

# ν™κ²½ ν™μ„±ν™” ν™•μΈ
if [[ "$CONDA_DEFAULT_ENV" != "mycloset-ai" ]]; then
    log_warning "conda ν™κ²½μ„ ν™μ„±ν™”ν•©λ‹λ‹¤..."
    source "$(conda info --base)/etc/profile.d/conda.sh"
    conda activate mycloset-ai
fi

log_info "ν„μ¬ ν™κ²½: $CONDA_DEFAULT_ENV"
log_info "Python λ²„μ „: $(python --version)"

# ================================================================
# 1. κΈ°λ³Έ AI/ML ν¨ν‚¤μ§€ (κ²€μ¦λ λ²„μ „λ“¤)
# ================================================================

log_info "1λ‹¨κ³„: Transformers μƒνƒκ³„ μ„¤μΉ (κ²€μ¦λ λ²„μ „)"

# Transformers ν•µμ‹¬ ν¨ν‚¤μ§€λ“¤ - Python 3.11 νΈν™ λ²„μ „
pip install \
    transformers==4.35.0 \
    tokenizers==0.15.0 \
    safetensors==0.4.0 \
    accelerate==0.24.1 \
    datasets==2.14.6 \
    huggingface-hub==0.17.3

log_success "Transformers μƒνƒκ³„ μ„¤μΉ μ™„λ£"

# ================================================================
# 2. Diffusers (κ°€μƒ ν”Όν… ν•µμ‹¬)
# ================================================================

log_info "2λ‹¨κ³„: Diffusers μ„¤μΉ"
pip install diffusers==0.21.4

log_success "Diffusers μ„¤μΉ μ™„λ£"

# ================================================================
# 3. μ»΄ν“¨ν„° λΉ„μ „ ν¨ν‚¤μ§€ (νΈν™μ„± μ°μ„ )
# ================================================================

log_info "3λ‹¨κ³„: μ»΄ν“¨ν„° λΉ„μ „ ν¨ν‚¤μ§€ μ„¤μΉ (νΈν™ λ²„μ „)"

# MediaPipeλ” μ΄λ―Έ μ„¤μΉλ¨
log_info "MediaPipe: μ΄λ―Έ μ„¤μΉλ¨ (0.10.7)"

# YOLO - νΈν™ κ°€λ¥ν• λ²„μ „ μ„¤μΉ
log_info "YOLO νΈν™ λ²„μ „ μ„¤μΉ μ‹λ„..."
pip install ultralytics==8.0.34 || {
    log_warning "ultralytics 8.0.34 μ„¤μΉ μ‹¤ν¨, μµμ‹  νΈν™ λ²„μ „ μ‹λ„"
    pip install "ultralytics>=8.0.0,<8.1.0" || {
        log_warning "ultralytics μ„¤μΉ μ‹¤ν¨, κ±΄λ„λ€ (μ„ νƒμ  ν¨ν‚¤μ§€)"
    }
}

# Segment Anything - κ³µμ‹ μ €μ¥μ†μ—μ„ μ„¤μΉ
log_info "Segment Anything Model μ„¤μΉ..."
pip install git+https://github.com/facebookresearch/segment-anything.git || {
    log_warning "SAM μ„¤μΉ μ‹¤ν¨, λ€μ²΄ λ°©λ²• μ‹λ„..."
    pip install segment-anything || {
        log_warning "SAM μ„¤μΉ μ™„μ „ μ‹¤ν¨, κ±΄λ„λ€ (Step 3μ—μ„ λ‹¤λ¥Έ λ¨λΈ μ‚¬μ©)"
    }
}

log_success "μ»΄ν“¨ν„° λΉ„μ „ ν¨ν‚¤μ§€ μ„¤μΉ μ™„λ£"

# ================================================================
# 4. μ›Ή ν”„λ μ„μ›ν¬ λ° μ„λ²„
# ================================================================

log_info "4λ‹¨κ³„: μ›Ή ν”„λ μ„μ›ν¬ μ„¤μΉ"
pip install \
    fastapi==0.104.1 \
    uvicorn[standard]==0.24.0 \
    python-multipart==0.0.6 \
    aiofiles==23.2.1 \
    websockets==11.0.3 \
    python-dotenv==1.0.0

log_success "μ›Ή ν”„λ μ„μ›ν¬ μ„¤μΉ μ™„λ£"

# ================================================================
# 5. λ°μ΄ν„° κ²€μ¦ λ° μ„¤μ •
# ================================================================

log_info "5λ‹¨κ³„: λ°μ΄ν„° κ²€μ¦ λΌμ΄λΈλ¬λ¦¬ μ„¤μΉ"
pip install \
    pydantic==2.5.0 \
    pydantic-settings==2.1.0 \
    structlog==23.1.0

log_success "λ°μ΄ν„° κ²€μ¦ λΌμ΄λΈλ¬λ¦¬ μ„¤μΉ μ™„λ£"

# ================================================================
# 6. κ°λ° λ„κµ¬ (μ„ νƒμ )
# ================================================================

log_info "6λ‹¨κ³„: κ°λ° λ„κµ¬ μ„¤μΉ"
pip install \
    pytest==7.4.3 \
    pytest-asyncio==0.21.1 \
    black==23.11.0 \
    isort==5.12.0

log_success "κ°λ° λ„κµ¬ μ„¤μΉ μ™„λ£"

# ================================================================
# 7. M3 Max νΉν™” μµμ ν™”
# ================================================================

log_info "7λ‹¨κ³„: M3 Max νΉν™” μ„¤μ •"

# Core ML Tools (Apple μ „μ©)
pip install coremltools==7.0 || {
    log_warning "CoreML Tools μ„¤μΉ μ‹¤ν¨ (μ„ νƒμ )"
}

log_success "M3 Max νΉν™” μ„¤μ • μ™„λ£"

# ================================================================
# 8. ν¨ν‚¤μ§€ κ²€μ¦
# ================================================================

log_info "8λ‹¨κ³„: μ„¤μΉλ ν¨ν‚¤μ§€ κ²€μ¦"

# ν•µμ‹¬ ν¨ν‚¤μ§€ import ν…μ¤νΈ
python -c "
import sys
print(f'π Python: {sys.version}')

# ν•µμ‹¬ ν¨ν‚¤μ§€ ν…μ¤νΈ
packages_to_test = [
    ('torch', 'PyTorch'),
    ('transformers', 'Transformers'),
    ('diffusers', 'Diffusers'),
    ('fastapi', 'FastAPI'),
    ('numpy', 'NumPy'),
    ('cv2', 'OpenCV'),
    ('PIL', 'Pillow'),
    ('matplotlib', 'Matplotlib'),
    ('sklearn', 'Scikit-learn'),
    ('skimage', 'Scikit-image')
]

print('\nπ“¦ ν¨ν‚¤μ§€ κ²€μ¦:')
success_count = 0
for package, name in packages_to_test:
    try:
        __import__(package)
        print(f'  β… {name}: OK')
        success_count += 1
    except ImportError as e:
        print(f'  β {name}: FAILED ({e})')

print(f'\nπ“ κ²°κ³Ό: {success_count}/{len(packages_to_test)} ν¨ν‚¤μ§€ μ„±κ³µ')

# MPS ν…μ¤νΈ
print('\nπ M3 Max MPS ν…μ¤νΈ:')
try:
    import torch
    if torch.backends.mps.is_available():
        print('  β… MPS μ‚¬μ© κ°€λ¥')
        device = torch.device('mps')
        x = torch.randn(100, 100, dtype=torch.float32, device=device)
        y = torch.mm(x, x.T)
        print(f'  β… MPS μ—°μ‚° ν…μ¤νΈ μ„±κ³µ: {y.shape}')
    else:
        print('  β MPS μ‚¬μ© λ¶κ°€')
except Exception as e:
    print(f'  β MPS ν…μ¤νΈ μ‹¤ν¨: {e}')

# μ„ νƒμ  ν¨ν‚¤μ§€ ν™•μΈ
print('\nπ” μ„ νƒμ  ν¨ν‚¤μ§€:')
optional_packages = [
    ('mediapipe', 'MediaPipe'),
    ('ultralytics', 'YOLO'),
    ('segment_anything', 'SAM'),
    ('coremltools', 'CoreML')
]

for package, name in optional_packages:
    try:
        __import__(package)
        print(f'  β… {name}: μ„¤μΉλ¨')
    except ImportError:
        print(f'  β οΈ {name}: λ―Έμ„¤μΉ (μ„ νƒμ )')
"

# ================================================================
# 9. ν™κ²½ λ³€μ λ° μ„¤μ • νμΌ μƒμ„±
# ================================================================

log_info "9λ‹¨κ³„: ν™κ²½ μ„¤μ • νμΌ μƒμ„±"

# .env νμΌ μƒμ„± (M3 Max μµμ ν™”)
cat > .env << 'EOF'
# MyCloset AI - M3 Max μµμ ν™” ν™κ²½ μ„¤μ • (ν¨ν‚¤μ§€ μ¤λ¥ ν•΄κ²° λ²„μ „)

# ===========================================
# κΈ°λ³Έ μ„¤μ •
# ===========================================
APP_NAME=MyCloset AI Backend
DEBUG=true
HOST=0.0.0.0
PORT=8000

# ===========================================
# M3 Max ν•λ“μ›¨μ–΄ μµμ ν™”
# ===========================================
DEVICE=mps
GPU_TYPE=m3_max
MEMORY_GB=128
USE_GPU=true
UNIFIED_MEMORY=true

# ===========================================
# PyTorch MPS μµμ ν™” (νƒ€μ… μ¤λ¥ ν•΄κ²°)
# ===========================================
PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0
PYTORCH_MPS_ALLOCATOR_POLICY=garbage_collection
PYTORCH_ENABLE_MPS_FALLBACK=1

# νƒ€μ… λ¶μΌμΉ ν•΄κ²°
MPS_FORCE_FLOAT32=true
MPS_PRECISION_MODE=float32
TORCH_DTYPE=float32

# ===========================================
# ν¨ν‚¤μ§€λ³„ μµμ ν™” μ„¤μ •
# ===========================================
# Transformers μ„¤μ •
TRANSFORMERS_CACHE=/tmp/transformers_cache
HF_DATASETS_CACHE=/tmp/datasets_cache

# OpenCV μ„¤μ •
OPENCV_LOG_LEVEL=ERROR

# NumPy μ„¤μ •
OPENBLAS_NUM_THREADS=16
MKL_NUM_THREADS=16

# ===========================================
# λ©”λ¨λ¦¬ κ΄€λ¦¬
# ===========================================
MAX_MEMORY_FRACTION=0.75
MEMORY_POOL_SIZE=32
AUTO_MEMORY_CLEANUP=true

# ===========================================
# AI λ¨λΈ μ„¤μ • (λ¬Έμ  ν•΄κ²°)
# ===========================================
# μ‚¬μ© κ°€λ¥ν• λ¨λΈλ§ ν™μ„±ν™”
ENABLE_SAM=false
ENABLE_YOLO=auto
ENABLE_ULTRALYTICS=auto

# λ¨λΈ λ΅λ”© μµμ ν™”
MODEL_PRECISION=float32
ENABLE_MIXED_PRECISION=false
MODEL_CACHE_SIZE=16

# ===========================================
# λ΅κΉ…
# ===========================================
LOG_LEVEL=INFO
LOG_FILE=logs/mycloset-ai.log
SUPPRESS_PACKAGE_WARNINGS=true
EOF

# ν™μ„±ν™” μ¤ν¬λ¦½νΈ μƒμ„±
cat > activate_fixed.sh << 'EOF'
#!/bin/bash
# MyCloset AI μμ •λ ν™κ²½ ν™μ„±ν™”

# Conda ν™κ²½ ν™μ„±ν™”
source "$(conda info --base)/etc/profile.d/conda.sh"
conda activate mycloset-ai

# M3 Max μµμ ν™” ν™κ²½ λ³€μ
export PYTORCH_ENABLE_MPS_FALLBACK=1
export PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0
export OMP_NUM_THREADS=16
export MKL_NUM_THREADS=16

# ν¨ν‚¤μ§€ κ²½κ³  μ–µμ 
export PYTHONWARNINGS="ignore::UserWarning"
export TRANSFORMERS_NO_ADVISORY_WARNINGS=1

echo "β… MyCloset AI μμ •λ ν™κ²½ ν™μ„±ν™”"
echo "π”§ Python: $(python --version)"
echo "β΅ PyTorch: $(python -c 'import torch; print(torch.__version__)')"
echo "π MPS: $(python -c 'import torch; print("Available" if torch.backends.mps.is_available() else "Not Available")')"
echo ""
echo "π€ μ„λ²„ μ‹¤ν–‰: cd backend && python app/main.py"
EOF

chmod +x activate_fixed.sh

# ================================================================
# 10. λΉ λ¥Έ ν…μ¤νΈ μ„λ²„ μƒμ„±
# ================================================================

log_info "10λ‹¨κ³„: ν…μ¤νΈ μ„λ²„ μƒμ„±"

mkdir -p app

cat > app/test_fixed_server.py << 'EOF'
"""
μμ •λ MyCloset AI ν…μ¤νΈ μ„λ²„
ν¨ν‚¤μ§€ νΈν™μ„± λ¬Έμ  ν•΄κ²° λ²„μ „
"""
import os
import sys
import warnings

# κ²½κ³  μ–µμ 
warnings.filterwarnings("ignore", category=UserWarning)
os.environ["PYTHONWARNINGS"] = "ignore::UserWarning"

from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
import torch
import uvicorn

app = FastAPI(
    title="MyCloset AI - μμ •λ ν…μ¤νΈ μ„λ²„",
    description="ν¨ν‚¤μ§€ νΈν™μ„± λ¬Έμ  ν•΄κ²° λ²„μ „"
)

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_methods=["*"],
    allow_headers=["*"],
)

@app.get("/")
async def root():
    return {
        "message": "MyCloset AI μμ •λ ν…μ¤νΈ μ„λ²„",
        "version": "2.0.0-fixed",
        "status": "running"
    }

@app.get("/health")
async def health_check():
    # ν¨ν‚¤μ§€ μƒνƒ ν™•μΈ
    package_status = {}
    
    packages_to_check = [
        "torch", "transformers", "diffusers", "fastapi", 
        "numpy", "cv2", "PIL", "matplotlib"
    ]
    
    for package in packages_to_check:
        try:
            module = __import__(package)
            if hasattr(module, '__version__'):
                package_status[package] = module.__version__
            else:
                package_status[package] = "imported_ok"
        except ImportError:
            package_status[package] = "not_available"
    
    # μ„ νƒμ  ν¨ν‚¤μ§€ ν™•μΈ
    optional_packages = ["mediapipe", "ultralytics", "segment_anything"]
    optional_status = {}
    
    for package in optional_packages:
        try:
            __import__(package)
            optional_status[package] = "available"
        except ImportError:
            optional_status[package] = "not_installed"
    
    return {
        "status": "healthy",
        "python_version": sys.version,
        "pytorch_version": torch.__version__,
        "mps_available": torch.backends.mps.is_available(),
        "packages": package_status,
        "optional_packages": optional_status
    }

@app.get("/test-mps")
async def test_mps_fixed():
    """MPS ν…μ¤νΈ (νƒ€μ… μ¤λ¥ ν•΄κ²°)"""
    if not torch.backends.mps.is_available():
        return {"error": "MPS not available"}
    
    try:
        device = torch.device('mps')
        
        # float32λ΅ ν†µμΌ (νƒ€μ… λ¶μΌμΉ ν•΄κ²°)
        x = torch.randn(100, 100, dtype=torch.float32, device=device)
        y = torch.randn(100, 100, dtype=torch.float32, device=device)
        
        # ν–‰λ ¬ κ³±μ… ν…μ¤νΈ
        result = torch.mm(x, y)
        
        # κ°„λ‹¨ν• μ‹ κ²½λ§ μ—°μ‚° ν…μ¤νΈ
        linear = torch.nn.Linear(100, 50, dtype=torch.float32).to(device)
        output = linear(x)
        
        return {
            "status": "success",
            "device": str(device),
            "matrix_mult_shape": list(result.shape),
            "neural_net_shape": list(output.shape),
            "memory_allocated": torch.mps.current_allocated_memory() if hasattr(torch.mps, 'current_allocated_memory') else 0,
            "dtype_test": "float32_consistent"
        }
    except Exception as e:
        return {
            "error": str(e),
            "error_type": type(e).__name__
        }

@app.get("/models-status")
async def models_status():
    """AI λ¨λΈ μƒνƒ ν™•μΈ"""
    status = {
        "transformers": {"available": False, "models": []},
        "diffusers": {"available": False, "models": []},
        "computer_vision": {"available": False, "models": []}
    }
    
    # Transformers ν™•μΈ
    try:
        from transformers import AutoModel, AutoTokenizer
        status["transformers"]["available"] = True
        status["transformers"]["models"] = ["CLIP", "BERT", "GPT"]
    except ImportError:
        pass
    
    # Diffusers ν™•μΈ
    try:
        from diffusers import StableDiffusionPipeline
        status["diffusers"]["available"] = True
        status["diffusers"]["models"] = ["Stable Diffusion", "ControlNet"]
    except ImportError:
        pass
    
    # μ»΄ν“¨ν„° λΉ„μ „ ν™•μΈ
    cv_models = []
    try:
        import mediapipe
        cv_models.append("MediaPipe")
    except ImportError:
        pass
    
    try:
        import ultralytics
        cv_models.append("YOLO")
    except ImportError:
        pass
    
    if cv_models:
        status["computer_vision"]["available"] = True
        status["computer_vision"]["models"] = cv_models
    
    return status

if __name__ == "__main__":
    print("π€ MyCloset AI μμ •λ ν…μ¤νΈ μ„λ²„ μ‹μ‘...")
    print("π“ μ„λ²„: http://localhost:8000")
    print("β¤οΈ ν—¬μ¤μ²΄ν¬: http://localhost:8000/health")
    print("π§ MPS ν…μ¤νΈ: http://localhost:8000/test-mps")
    print("π¤– λ¨λΈ μƒνƒ: http://localhost:8000/models-status")
    print("")
    
    uvicorn.run(app, host="0.0.0.0", port=8000, log_level="info")
EOF

# ν¨ν‚¤μ§€ λ©λ΅ μ €μ¥
pip freeze > requirements_fixed.txt

# ================================================================
# μ™„λ£ λ©”μ‹μ§€
# ================================================================

echo ""
echo "π‰ ν¨ν‚¤μ§€ μ¤λ¥ ν•΄κ²° λ° μ„¤μΉ μ™„λ£!"
echo "=================================================="
log_success "β… νΈν™μ„± λ¬Έμ  ν•΄κ²°λ¨"
log_success "β… M3 Max MPS μµμ ν™” μ μ©"
log_success "β… ν•„μ ν¨ν‚¤μ§€ μ„¤μΉ μ™„λ£"
log_success "β… μ„ νƒμ  ν¨ν‚¤μ§€ μ¤ν‚µ (μ¤λ¥ λ°©μ§€)"

echo ""
echo "π“‹ μƒμ„±λ νμΌλ“¤:"
echo "  - .env: M3 Max μµμ ν™” ν™κ²½ λ³€μ"
echo "  - activate_fixed.sh: μμ •λ ν™κ²½ ν™μ„±ν™”"
echo "  - app/test_fixed_server.py: νΈν™μ„± ν…μ¤νΈ μ„λ²„"
echo "  - requirements_fixed.txt: μµμΆ… ν¨ν‚¤μ§€ λ©λ΅"

echo ""
echo "π€ λ‹¤μ λ‹¨κ³„:"
echo "1. ν…μ¤νΈ: python app/test_fixed_server.py"
echo "2. λΈλΌμ°μ €: http://localhost:8000/health"
echo "3. MPS ν…μ¤νΈ: http://localhost:8000/test-mps"
echo "4. λ¨λΈ μƒνƒ: http://localhost:8000/models-status"

echo ""
echo "π’΅ ν™κ²½ ν™μ„±ν™”:"
echo "  source activate_fixed.sh"

echo ""
log_warning "π“ μ£Όμ” λ³€κ²½μ‚¬ν•­:"
echo "  - ultralytics: νΈν™ λ²„μ „μΌλ΅ λ³€κ²½"
echo "  - segment-anything: Gitμ—μ„ μ§μ ‘ μ„¤μΉ"
echo "  - MPS νƒ€μ… λ¶μΌμΉ μ¤λ¥ ν•΄κ²°"
echo "  - μ„ νƒμ  ν¨ν‚¤μ§€ μ‹¤ν¨ μ‹ κ±΄λ„λ›°κΈ°"