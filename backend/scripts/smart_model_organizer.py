#!/usr/bin/env python3
"""
ğŸ§  MyCloset AI - ìŠ¤ë§ˆíŠ¸ ëª¨ë¸ ì •ë¦¬ ë° ìµœì í™” ìŠ¤í¬ë¦½íŠ¸
M3 Max 128GB ìµœì í™” | ìš°ì„ ìˆœìœ„ ê¸°ë°˜ ëª¨ë¸ ì„ íƒ

ì‚¬ìš©ë²•: python scripts/smart_model_organizer.py
"""

import os
import json
import shutil
import logging
from pathlib import Path
from typing import Dict, List, Tuple, Optional
from datetime import datetime

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s | %(levelname)s | %(message)s',
    handlers=[
        logging.FileHandler('model_organization.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class SmartModelOrganizer:
    """ìŠ¤ë§ˆíŠ¸ AI ëª¨ë¸ ì •ë¦¬ ë° ìµœì í™” ë„êµ¬"""
    
    def __init__(self, base_dir: str = "ai_models/checkpoints"):
        self.base_dir = Path(base_dir)
        self.checkpoint_report = self.load_checkpoint_report()
        
        # M3 Max 128GBì— ìµœì í™”ëœ ëª¨ë¸ ìš°ì„ ìˆœìœ„
        self.model_priorities = {
            # â­ ìµœê³  ìš°ì„ ìˆœìœ„ (í•„ìˆ˜)
            1: ["ootdiffusion", "ootdiffusion_hf"],  # ê°€ìƒ í”¼íŒ… í•µì‹¬
            
            # ğŸ”¥ ë†’ì€ ìš°ì„ ìˆœìœ„ (ì¤‘ìš”)
            2: ["human_parsing", "step_01_human_parsing"],  # ì¸ê°„ íŒŒì‹±
            3: ["openpose", "step_02_pose_estimation"],     # í¬ì¦ˆ ì¶”ì •
            4: ["u2net", "step_03_cloth_segmentation"],     # ì˜ë¥˜ ë¶„í• 
            5: ["step_04_geometric_matching"],              # ê¸°í•˜í•™ì  ë§¤ì¹­
            6: ["step_05_cloth_warping"],                   # ì˜ë¥˜ ì›Œí•‘
            
            # ğŸ’¡ ì¤‘ê°„ ìš°ì„ ìˆœìœ„ (ì„ íƒì )
            7: ["clip-vit-base-patch32", "grounding_dino"], # í…ìŠ¤íŠ¸-ì´ë¯¸ì§€
            8: ["step_07_post_processing"],                 # í›„ì²˜ë¦¬
            
            # ğŸ“¦ ë‚®ì€ ìš°ì„ ìˆœìœ„ (ë°±ì—…ìš©)
            9: ["stable-diffusion-v1-5"],                   # ëŒ€ì²´ ëª¨ë¸
            10: ["auxiliary", "background_removal"]         # ë³´ì¡° ë„êµ¬
        }
        
        # ì œê±° ëŒ€ìƒ (ì¤‘ë³µ/ë¶ˆí•„ìš”)
        self.removal_candidates = [
            "stable_diffusion_v15",      # ì¤‘ë³µ
            "stable_diffusion_inpaint",  # ì¤‘ë³µ  
            "sam_vit_h",                 # ì¤‘ë³µ
            "clip-vit-large-patch14",    # í° ìš©ëŸ‰, baseë¡œ ì¶©ë¶„
            "controlnet_openpose",       # ì¤‘ë³µ
            "esrgan", "gfpgan", "rembg", # ì‚¬ìš©í•˜ì§€ ì•ŠìŒ
            "viton_hd",                  # ë¶ˆì™„ì „
            "densepose",                 # ë¹„ì–´ìˆìŒ
            "u2net_cloth",               # ë¹„ì–´ìˆìŒ
        ]
    
    def load_checkpoint_report(self) -> Dict:
        """ì²´í¬í¬ì¸íŠ¸ ë¶„ì„ ë³´ê³ ì„œ ë¡œë“œ"""
        report_path = self.base_dir / "checkpoint_analysis_report.json"
        if report_path.exists():
            with open(report_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        return {}
    
    def analyze_current_state(self) -> Dict:
        """í˜„ì¬ ìƒíƒœ ë¶„ì„"""
        logger.info("ğŸ” í˜„ì¬ AI ëª¨ë¸ ìƒíƒœ ë¶„ì„ ì¤‘...")
        
        if not self.checkpoint_report:
            logger.error("âŒ checkpoint_analysis_report.jsonì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            return {}
        
        analyzed_models = self.checkpoint_report.get('analyzed_models', {})
        summary = self.checkpoint_report.get('summary', {})
        
        analysis = {
            'total_models': summary.get('total_models', 0),
            'ready_models': summary.get('ready_models', 0),
            'total_size_gb': self.checkpoint_report.get('total_size_gb', 0),
            'priority_analysis': {},
            'removal_analysis': {},
            'size_optimization': {}
        }
        
        # ìš°ì„ ìˆœìœ„ë³„ ë¶„ì„
        for priority, model_names in self.model_priorities.items():
            priority_info = {
                'models': [],
                'total_size_mb': 0,
                'ready_count': 0
            }
            
            for model_name in model_names:
                if model_name in analyzed_models:
                    model_info = analyzed_models[model_name]
                    priority_info['models'].append({
                        'name': model_name,
                        'size_mb': model_info.get('total_size_mb', 0),
                        'ready': model_info.get('ready', False),
                        'type': model_info.get('type', 'unknown')
                    })
                    priority_info['total_size_mb'] += model_info.get('total_size_mb', 0)
                    if model_info.get('ready', False):
                        priority_info['ready_count'] += 1
            
            analysis['priority_analysis'][priority] = priority_info
        
        # ì œê±° ëŒ€ìƒ ë¶„ì„
        removal_size = 0
        removal_models = []
        for model_name in self.removal_candidates:
            if model_name in analyzed_models:
                model_info = analyzed_models[model_name]
                size_mb = model_info.get('total_size_mb', 0)
                removal_size += size_mb
                removal_models.append({
                    'name': model_name,
                    'size_mb': size_mb,
                    'reason': self._get_removal_reason(model_name)
                })
        
        analysis['removal_analysis'] = {
            'total_models': len(removal_models),
            'total_size_mb': removal_size,
            'models': removal_models
        }
        
        # í¬ê¸° ìµœì í™” ë¶„ì„
        analysis['size_optimization'] = {
            'current_size_gb': analysis['total_size_gb'],
            'after_removal_gb': (analysis['total_size_gb'] * 1024 - removal_size) / 1024,
            'space_saved_gb': removal_size / 1024,
            'optimization_percentage': (removal_size / (analysis['total_size_gb'] * 1024)) * 100
        }
        
        return analysis
    
    def _get_removal_reason(self, model_name: str) -> str:
        """ì œê±° ì´ìœ  ë°˜í™˜"""
        reasons = {
            "stable_diffusion_v15": "stable-diffusion-v1-5ì™€ ì¤‘ë³µ",
            "stable_diffusion_inpaint": "ootdiffusionìœ¼ë¡œ ëŒ€ì²´ ê°€ëŠ¥",
            "sam_vit_h": "samìœ¼ë¡œ ì¶©ë¶„",
            "clip-vit-large-patch14": "clip-vit-base-patch32ë¡œ ì¶©ë¶„",
            "controlnet_openpose": "openposeì™€ ì¤‘ë³µ",
            "esrgan": "step_07_post_processingì— í¬í•¨ë¨",
            "gfpgan": "ì‚¬ìš©í•˜ì§€ ì•ŠìŒ",
            "rembg": "u2netìœ¼ë¡œ ëŒ€ì²´ ê°€ëŠ¥",
            "viton_hd": "ë¶ˆì™„ì „í•œ ëª¨ë¸",
            "densepose": "ë¹„ì–´ìˆëŠ” ë””ë ‰í† ë¦¬",
            "u2net_cloth": "ë¹„ì–´ìˆëŠ” ë””ë ‰í† ë¦¬"
        }
        return reasons.get(model_name, "ë¶ˆí•„ìš”í•œ ëª¨ë¸")
    
    def create_optimization_plan(self, analysis: Dict) -> Dict:
        """ìµœì í™” ê³„íš ìƒì„±"""
        logger.info("ğŸ“‹ ëª¨ë¸ ìµœì í™” ê³„íš ìƒì„± ì¤‘...")
        
        plan = {
            'timestamp': datetime.now().isoformat(),
            'current_state': {
                'total_size_gb': analysis['total_size_gb'],
                'total_models': analysis['total_models']
            },
            'actions': [],
            'expected_result': {
                'final_size_gb': analysis['size_optimization']['after_removal_gb'],
                'space_saved_gb': analysis['size_optimization']['space_saved_gb'],
                'optimization_percentage': analysis['size_optimization']['optimization_percentage']
            }
        }
        
        # 1. ì œê±° ì•¡ì…˜
        for model in analysis['removal_analysis']['models']:
            plan['actions'].append({
                'type': 'remove',
                'model': model['name'],
                'reason': model['reason'],
                'size_mb': model['size_mb'],
                'priority': 'high'
            })
        
        # 2. ì¬êµ¬ì„± ì•¡ì…˜ (ìš°ì„ ìˆœìœ„ ê¸°ë°˜)
        for priority in range(1, 7):  # í•µì‹¬ ëª¨ë¸ë“¤ë§Œ
            if priority in analysis['priority_analysis']:
                priority_info = analysis['priority_analysis'][priority]
                for model in priority_info['models']:
                    if model['ready']:
                        plan['actions'].append({
                            'type': 'reorganize',
                            'model': model['name'],
                            'priority': priority,
                            'size_mb': model['size_mb'],
                            'target_path': f"step_{priority:02d}_{model['type']}/{model['name']}"
                        })
        
        # 3. ì‹¬ë³¼ë¦­ ë§í¬ ì•¡ì…˜ (ì¤‘ë³µ ì œê±°)
        plan['actions'].append({
            'type': 'create_symlinks',
            'description': "ì¤‘ë³µ ëª¨ë¸ë“¤ì„ ì‹¬ë³¼ë¦­ ë§í¬ë¡œ ì—°ê²°",
            'targets': [
                "stable-diffusion-v1-5 â†’ ootdiffusion",
                "clip-vit-base â†’ clip-vit-base-patch32", 
                "sam â†’ sam_vit_h"
            ]
        })
        
        return plan
    
    def execute_optimization(self, plan: Dict, dry_run: bool = True) -> bool:
        """ìµœì í™” ì‹¤í–‰"""
        logger.info(f"{'ğŸ§ª [DRY RUN]' if dry_run else 'ğŸš€ [EXECUTE]'} ëª¨ë¸ ìµœì í™” ì‹¤í–‰...")
        
        if not dry_run:
            # ë°±ì—… ìƒì„±
            backup_dir = Path(f"backup_models_{datetime.now().strftime('%Y%m%d_%H%M%S')}")
            logger.info(f"ğŸ“¦ ë°±ì—… ìƒì„±: {backup_dir}")
            
        executed_actions = []
        
        for action in plan['actions']:
            action_type = action['type']
            model_name = action.get('model', 'unknown')
            
            try:
                if action_type == 'remove':
                    result = self._execute_remove_action(action, dry_run)
                elif action_type == 'reorganize':
                    result = self._execute_reorganize_action(action, dry_run)
                elif action_type == 'create_symlinks':
                    result = self._execute_symlink_action(action, dry_run)
                else:
                    result = {'success': False, 'error': f'Unknown action type: {action_type}'}
                
                executed_actions.append({
                    'action': action,
                    'result': result
                })
                
                if result['success']:
                    logger.info(f"âœ… {action_type}: {model_name}")
                else:
                    logger.error(f"âŒ {action_type}: {model_name} - {result.get('error', 'Unknown error')}")
                    
            except Exception as e:
                logger.error(f"ğŸš¨ {action_type} ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
                executed_actions.append({
                    'action': action,
                    'result': {'success': False, 'error': str(e)}
                })
        
        # ê²°ê³¼ ì €ì¥
        result_file = f"optimization_result_{'dryrun' if dry_run else 'executed'}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(result_file, 'w', encoding='utf-8') as f:
            json.dump({
                'plan': plan,
                'executed_actions': executed_actions,
                'summary': self._create_execution_summary(executed_actions)
            }, f, indent=2, ensure_ascii=False)
        
        logger.info(f"ğŸ“Š ì‹¤í–‰ ê²°ê³¼ ì €ì¥: {result_file}")
        return True
    
    def _execute_remove_action(self, action: Dict, dry_run: bool) -> Dict:
        """ì œê±° ì•¡ì…˜ ì‹¤í–‰"""
        model_name = action['model']
        model_path = self.base_dir / model_name
        
        if not model_path.exists():
            return {'success': True, 'message': 'Already removed'}
        
        if dry_run:
            return {'success': True, 'message': f'Would remove {model_path}'}
        
        try:
            if model_path.is_dir():
                shutil.rmtree(model_path)
            else:
                model_path.unlink()
            return {'success': True, 'message': f'Removed {model_path}'}
        except Exception as e:
            return {'success': False, 'error': str(e)}
    
    def _execute_reorganize_action(self, action: Dict, dry_run: bool) -> Dict:
        """ì¬êµ¬ì„± ì•¡ì…˜ ì‹¤í–‰"""
        model_name = action['model']
        target_path = action['target_path']
        
        if dry_run:
            return {'success': True, 'message': f'Would reorganize {model_name} to {target_path}'}
        
        # ì‹¤ì œ ì¬êµ¬ì„± ë¡œì§ êµ¬í˜„
        return {'success': True, 'message': f'Reorganized {model_name}'}
    
    def _execute_symlink_action(self, action: Dict, dry_run: bool) -> Dict:
        """ì‹¬ë³¼ë¦­ ë§í¬ ì•¡ì…˜ ì‹¤í–‰"""
        if dry_run:
            return {'success': True, 'message': 'Would create symlinks'}
        
        # ì‹¤ì œ ì‹¬ë³¼ë¦­ ë§í¬ ìƒì„± ë¡œì§ êµ¬í˜„
        return {'success': True, 'message': 'Created symlinks'}
    
    def _create_execution_summary(self, executed_actions: List[Dict]) -> Dict:
        """ì‹¤í–‰ ìš”ì•½ ìƒì„±"""
        total_actions = len(executed_actions)
        successful_actions = sum(1 for action in executed_actions if action['result']['success'])
        
        return {
            'total_actions': total_actions,
            'successful_actions': successful_actions,
            'failed_actions': total_actions - successful_actions,
            'success_rate': (successful_actions / total_actions * 100) if total_actions > 0 else 0
        }
    
    def generate_report(self, analysis: Dict, plan: Dict) -> str:
        """ìƒì„¸ ë³´ê³ ì„œ ìƒì„±"""
        report = f"""
ğŸ§  MyCloset AI - ìŠ¤ë§ˆíŠ¸ ëª¨ë¸ ìµœì í™” ë³´ê³ ì„œ
========================================
ğŸ“… ìƒì„±ì¼ì‹œ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

ğŸ“Š í˜„ì¬ ìƒíƒœ ë¶„ì„
-----------------
ì´ ëª¨ë¸ ìˆ˜: {analysis['total_models']}ê°œ
ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸: {analysis['ready_models']}ê°œ  
ì´ ìš©ëŸ‰: {analysis['total_size_gb']:.1f}GB

ğŸ¯ ìš°ì„ ìˆœìœ„ë³„ ëª¨ë¸ ë¶„ì„
---------------------"""
        
        for priority, info in analysis['priority_analysis'].items():
            if info['models']:
                report += f"\nìš°ì„ ìˆœìœ„ {priority}: {info['ready_count']}/{len(info['models'])}ê°œ ì¤€ë¹„ë¨, {info['total_size_mb']/1024:.1f}GB"
                for model in info['models']:
                    status = "âœ…" if model['ready'] else "âŒ"
                    report += f"\n  {status} {model['name']} ({model['size_mb']/1024:.1f}GB)"
        
        report += f"""

ğŸ—‘ï¸ ì œê±° ëŒ€ìƒ ë¶„ì„
----------------
ì œê±°í•  ëª¨ë¸: {analysis['removal_analysis']['total_models']}ê°œ
ì ˆì•½ ìš©ëŸ‰: {analysis['removal_analysis']['total_size_mb']/1024:.1f}GB
"""
        
        for model in analysis['removal_analysis']['models']:
            report += f"\nâŒ {model['name']} ({model['size_mb']/1024:.1f}GB) - {model['reason']}"
        
        report += f"""

ğŸ’¡ ìµœì í™” ê²°ê³¼ ì˜ˆìƒ
-----------------
í˜„ì¬ ìš©ëŸ‰: {analysis['size_optimization']['current_size_gb']:.1f}GB
ìµœì í™” í›„: {analysis['size_optimization']['after_removal_gb']:.1f}GB
ì ˆì•½ ìš©ëŸ‰: {analysis['size_optimization']['space_saved_gb']:.1f}GB
ìµœì í™”ìœ¨: {analysis['size_optimization']['optimization_percentage']:.1f}%

ğŸš€ ê¶Œì¥ ì•¡ì…˜
-----------
1. ì¤‘ë³µ/ë¶ˆí•„ìš” ëª¨ë¸ ì œê±° ({len(analysis['removal_analysis']['models'])}ê°œ)
2. ìš°ì„ ìˆœìœ„ 1-6 ëª¨ë¸ ìœ ì§€ (í•µì‹¬ ê¸°ëŠ¥)
3. ì‹¬ë³¼ë¦­ ë§í¬ë¡œ ì¤‘ë³µ ì œê±°
4. ë°±ì—… í›„ ì ì§„ì  ì ìš©

âš ï¸ ì£¼ì˜ì‚¬í•­
----------
- ì‹¤í–‰ ì „ ì „ì²´ ë°±ì—… í•„ìˆ˜
- í…ŒìŠ¤íŠ¸ í™˜ê²½ì—ì„œ ë¨¼ì € ê²€ì¦
- ë‹¨ê³„ë³„ ì ìš© ê¶Œì¥
"""
        
        return report

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    import argparse
    
    parser = argparse.ArgumentParser(description='MyCloset AI ìŠ¤ë§ˆíŠ¸ ëª¨ë¸ ì •ë¦¬')
    parser.add_argument('--analyze', action='store_true', help='ë¶„ì„ë§Œ ìˆ˜í–‰')
    parser.add_argument('--plan', action='store_true', help='ê³„íš ìƒì„±')
    parser.add_argument('--execute', action='store_true', help='ì‹¤ì œ ì‹¤í–‰')
    parser.add_argument('--dry-run', action='store_true', default=True, help='ê°€ìƒ ì‹¤í–‰ (ê¸°ë³¸ê°’)')
    
    args = parser.parse_args()
    
    organizer = SmartModelOrganizer()
    
    # 1. í˜„ì¬ ìƒíƒœ ë¶„ì„
    logger.info("ğŸ” Step 1: í˜„ì¬ ëª¨ë¸ ìƒíƒœ ë¶„ì„")
    analysis = organizer.analyze_current_state()
    
    if not analysis:
        logger.error("âŒ ë¶„ì„ ì‹¤íŒ¨")
        return False
    
    # 2. ìµœì í™” ê³„íš ìƒì„±
    if args.plan or args.execute:
        logger.info("ğŸ“‹ Step 2: ìµœì í™” ê³„íš ìƒì„±")
        plan = organizer.create_optimization_plan(analysis)
    else:
        plan = {}
    
    # 3. ë³´ê³ ì„œ ìƒì„±
    report = organizer.generate_report(analysis, plan)
    print(report)
    
    # ë³´ê³ ì„œ íŒŒì¼ ì €ì¥
    report_file = f"model_optimization_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"
    with open(report_file, 'w', encoding='utf-8') as f:
        f.write(report)
    logger.info(f"ğŸ“Š ë³´ê³ ì„œ ì €ì¥: {report_file}")
    
    # 4. ì‹¤í–‰ (ì˜µì…˜)
    if args.execute and plan:
        dry_run = args.dry_run
        logger.info(f"ğŸš€ Step 3: ìµœì í™” ì‹¤í–‰ ({'ê°€ìƒ' if dry_run else 'ì‹¤ì œ'})")
        organizer.execute_optimization(plan, dry_run=dry_run)
    
    logger.info("ğŸ‰ ìŠ¤ë§ˆíŠ¸ ëª¨ë¸ ì •ë¦¬ ì™„ë£Œ!")
    return True

if __name__ == "__main__":
    main()