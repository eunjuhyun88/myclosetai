# scripts/download_ai_models.py
"""
ì‹¤ì œ AI ëª¨ë¸ ìë™ ë‹¤ìš´ë¡œë“œ ë° ì„¤ì • ìŠ¤í¬ë¦½íŠ¸
OOTDiffusion, VITON-HD, Graphonomy ë“± ì‹¤ì œ ëª¨ë¸ë“¤ì„ ë‹¤ìš´ë¡œë“œ
"""

import os
import requests
import subprocess
import zipfile
import gdown
from pathlib import Path
from tqdm import tqdm
import yaml
import logging
from huggingface_hub import snapshot_download, hf_hub_download
import torch

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class AIModelDownloader:
    def __init__(self, base_dir="backend"):
        self.base_dir = Path(base_dir)
        self.models_dir = self.base_dir / "ai_models"
        self.checkpoints_dir = self.models_dir / "checkpoints"
        self.configs_dir = self.models_dir / "configs"
        
        # ë””ë ‰í† ë¦¬ ìƒì„±
        self.models_dir.mkdir(exist_ok=True)
        self.checkpoints_dir.mkdir(exist_ok=True)
        self.configs_dir.mkdir(exist_ok=True)
        
        # ì‹œìŠ¤í…œ ì •ë³´
        self.device = self._detect_device()
        logger.info(f"ğŸ–¥ï¸ ê°ì§€ëœ ë””ë°”ì´ìŠ¤: {self.device}")
    
    def _detect_device(self):
        """ì‹œìŠ¤í…œ ë””ë°”ì´ìŠ¤ ê°ì§€"""
        if torch.cuda.is_available():
            return "cuda"
        elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
            return "mps"  # Apple Silicon
        else:
            return "cpu"
    
    def download_file(self, url, filepath, desc=None):
        """íŒŒì¼ ë‹¤ìš´ë¡œë“œ with ì§„í–‰ë¥  í‘œì‹œ"""
        try:
            response = requests.get(url, stream=True)
            response.raise_for_status()
            
            total_size = int(response.headers.get('content-length', 0))
            
            with open(filepath, 'wb') as file, tqdm(
                desc=desc or f"Downloading {filepath.name}",
                total=total_size,
                unit='B',
                unit_scale=True,
                unit_divisor=1024,
            ) as pbar:
                for data in response.iter_content(chunk_size=1024):
                    size = file.write(data)
                    pbar.update(size)
            
            logger.info(f"âœ… ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {filepath}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨ {filepath}: {e}")
            return False
    
    def download_ootdiffusion(self):
        """OOTDiffusion ëª¨ë¸ ë‹¤ìš´ë¡œë“œ"""
        logger.info("ğŸ¤– OOTDiffusion ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹œì‘...")
        
        ootd_dir = self.checkpoints_dir / "ootdiffusion"
        ootd_dir.mkdir(exist_ok=True)
        
        # OOTDiffusion ëª¨ë¸ URLë“¤ (Hugging Face)
        models = {
            "ootd_humanparsing_onnx.zip": "levihsu/OOTDiffusion",
            "ootd/ootd_diffusion_model.safetensors": "levihsu/OOTDiffusion", 
            "ootd/vae_ootd.safetensors": "levihsu/OOTDiffusion"
        }
        
        try:
            # Hugging Faceì—ì„œ ì§ì ‘ ë‹¤ìš´ë¡œë“œ
            logger.info("ğŸ“¥ Hugging Faceì—ì„œ OOTDiffusion ë‹¤ìš´ë¡œë“œ...")
            snapshot_download(
                repo_id="levihsu/OOTDiffusion",
                local_dir=str(ootd_dir),
                allow_patterns=["*.safetensors", "*.onnx", "*.json", "*.txt"]
            )
            
            # ì„¤ì • íŒŒì¼ ìƒì„±
            config_content = {
                "model_type": "ootdiffusion",
                "device": self.device,
                "dtype": "float32" if self.device == "mps" else "float16",
                "checkpoint_path": str(ootd_dir),
                "human_parsing_path": str(ootd_dir / "ootd_humanparsing_onnx"),
                "vae_path": str(ootd_dir / "ootd" / "vae_ootd.safetensors"),
                "enabled": True
            }
            
            config_path = self.configs_dir / "ootdiffusion.yaml"
            with open(config_path, 'w') as f:
                yaml.dump(config_content, f, default_flow_style=False)
            
            logger.info("âœ… OOTDiffusion ì„¤ì • ì™„ë£Œ")
            return True
            
        except Exception as e:
            logger.error(f"âŒ OOTDiffusion ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
            return False
    
    def download_viton_hd(self):
        """VITON-HD ëª¨ë¸ ë‹¤ìš´ë¡œë“œ"""
        logger.info("ğŸ¤– VITON-HD ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹œì‘...")
        
        viton_dir = self.checkpoints_dir / "viton_hd"
        viton_dir.mkdir(exist_ok=True)
        
        # VITON-HD GitHub í´ë¡ 
        try:
            if not (viton_dir / ".git").exists():
                logger.info("ğŸ“¥ VITON-HD GitHub í´ë¡ ...")
                subprocess.run([
                    "git", "clone", 
                    "https://github.com/shadow2496/VITON-HD.git",
                    str(viton_dir)
                ], check=True)
            
            # ì‚¬ì „ í›ˆë ¨ëœ ê°€ì¤‘ì¹˜ ë‹¤ìš´ë¡œë“œ (Google Drive)
            weights = {
                "seg_model.pth": "1mhF3_vQSVZZ5QwQlEKhNRrz5dNGSLCU4",
                "gmm_model.pth": "1euphqABryn1xQRMWpXCl7zPYKZDK9O4r", 
                "tom_model.pth": "1S2tbtdLlBR4ZFZHcNtbG9t-xn-1KoHfY"
            }
            
            for filename, file_id in weights.items():
                filepath = viton_dir / "checkpoints" / filename
                filepath.parent.mkdir(exist_ok=True)
                
                if not filepath.exists():
                    logger.info(f"ğŸ“¥ {filename} ë‹¤ìš´ë¡œë“œ ì¤‘...")
                    gdown.download(f"https://drive.google.com/uc?id={file_id}", str(filepath))
            
            # ì„¤ì • íŒŒì¼ ìƒì„±
            config_content = {
                "model_type": "viton_hd",
                "device": self.device,
                "checkpoint_path": str(viton_dir / "checkpoints"),
                "seg_model": str(viton_dir / "checkpoints" / "seg_model.pth"),
                "gmm_model": str(viton_dir / "checkpoints" / "gmm_model.pth"),
                "tom_model": str(viton_dir / "checkpoints" / "tom_model.pth"),
                "enabled": True
            }
            
            config_path = self.configs_dir / "viton_hd.yaml"
            with open(config_path, 'w') as f:
                yaml.dump(config_content, f, default_flow_style=False)
            
            logger.info("âœ… VITON-HD ì„¤ì • ì™„ë£Œ")
            return True
            
        except Exception as e:
            logger.error(f"âŒ VITON-HD ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
            return False
    
    def download_human_parsing(self):
        """ì¸ì²´ íŒŒì‹± ëª¨ë¸ ë‹¤ìš´ë¡œë“œ (Graphonomy)"""
        logger.info("ğŸ¤– Human Parsing ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹œì‘...")
        
        parsing_dir = self.checkpoints_dir / "human_parsing"
        parsing_dir.mkdir(exist_ok=True)
        
        try:
            # Self-Correction Human Parsing ë‹¤ìš´ë¡œë“œ (ë” ì •í™•í•¨)
            logger.info("ğŸ“¥ Self-Correction Human Parsing ë‹¤ìš´ë¡œë“œ...")
            
            # ATR ë°ì´í„°ì…‹ ëª¨ë¸
            atr_model_url = "https://github.com/PeikeLi/Self-Correction-Human-Parsing/releases/download/v1.0/exp-schp-201908261155-atr.pth"
            atr_path = parsing_dir / "atr_model.pth"
            
            if not atr_path.exists():
                self.download_file(atr_model_url, atr_path, "ATR Parsing Model")
            
            # LIP ë°ì´í„°ì…‹ ëª¨ë¸
            lip_model_url = "https://github.com/PeikeLi/Self-Correction-Human-Parsing/releases/download/v1.0/exp-schp-201908301523-lip.pth"
            lip_path = parsing_dir / "lip_model.pth"
            
            if not lip_path.exists():
                self.download_file(lip_model_url, lip_path, "LIP Parsing Model")
            
            # ì„¤ì • íŒŒì¼ ìƒì„±
            config_content = {
                "model_type": "human_parsing",
                "device": self.device,
                "atr_model": str(atr_path),
                "lip_model": str(lip_path),
                "input_size": [473, 473],
                "num_classes": 18,
                "enabled": True
            }
            
            config_path = self.configs_dir / "human_parsing.yaml"
            with open(config_path, 'w') as f:
                yaml.dump(config_content, f, default_flow_style=False)
            
            logger.info("âœ… Human Parsing ì„¤ì • ì™„ë£Œ")
            return True
            
        except Exception as e:
            logger.error(f"âŒ Human Parsing ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
            return False
    
    def download_background_removal(self):
        """ë°°ê²½ ì œê±° ëª¨ë¸ ë‹¤ìš´ë¡œë“œ"""
        logger.info("ğŸ¤– ë°°ê²½ ì œê±° ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹œì‘...")
        
        bg_dir = self.checkpoints_dir / "background_removal"
        bg_dir.mkdir(exist_ok=True)
        
        try:
            # U2-Net ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
            u2net_url = "https://github.com/xuebinqin/U-2-Net/releases/download/u2net/u2net.pth"
            u2net_path = bg_dir / "u2net.pth"
            
            if not u2net_path.exists():
                self.download_file(u2net_url, u2net_path, "U2-Net Model")
            
            # ì„¤ì • íŒŒì¼ ìƒì„±
            config_content = {
                "model_type": "background_removal",
                "device": self.device,
                "u2net_model": str(u2net_path),
                "input_size": [320, 320],
                "enabled": True
            }
            
            config_path = self.configs_dir / "background_removal.yaml"
            with open(config_path, 'w') as f:
                yaml.dump(config_content, f, default_flow_style=False)
            
            logger.info("âœ… ë°°ê²½ ì œê±° ëª¨ë¸ ì„¤ì • ì™„ë£Œ")
            return True
            
        except Exception as e:
            logger.error(f"âŒ ë°°ê²½ ì œê±° ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
            return False
    
    def create_master_config(self):
        """ë§ˆìŠ¤í„° ì„¤ì • íŒŒì¼ ìƒì„±"""
        master_config = {
            "system": {
                "device": self.device,
                "models_dir": str(self.models_dir),
                "checkpoints_dir": str(self.checkpoints_dir)
            },
            "models": {
                "ootdiffusion": {
                    "enabled": True,
                    "priority": 1,
                    "config_file": "ootdiffusion.yaml"
                },
                "viton_hd": {
                    "enabled": True,
                    "priority": 2,
                    "config_file": "viton_hd.yaml"
                },
                "human_parsing": {
                    "enabled": True,
                    "priority": 1,
                    "config_file": "human_parsing.yaml"
                },
                "background_removal": {
                    "enabled": True,
                    "priority": 1,
                    "config_file": "background_removal.yaml"
                }
            },
            "processing": {
                "default_model": "ootdiffusion",
                "fallback_model": "viton_hd",
                "max_image_size": 1024,
                "batch_size": 1
            }
        }
        
        master_path = self.configs_dir / "models_config.yaml"
        with open(master_path, 'w') as f:
            yaml.dump(master_config, f, default_flow_style=False)
        
        logger.info(f"âœ… ë§ˆìŠ¤í„° ì„¤ì • íŒŒì¼ ìƒì„±: {master_path}")
    
    def download_all(self):
        """ëª¨ë“  ëª¨ë¸ ë‹¤ìš´ë¡œë“œ"""
        logger.info("ğŸš€ AI ëª¨ë¸ í†µí•© ë‹¤ìš´ë¡œë“œ ì‹œì‘...")
        
        success_count = 0
        total_models = 4
        
        # 1. OOTDiffusion
        if self.download_ootdiffusion():
            success_count += 1
        
        # 2. VITON-HD  
        if self.download_viton_hd():
            success_count += 1
        
        # 3. Human Parsing
        if self.download_human_parsing():
            success_count += 1
        
        # 4. Background Removal
        if self.download_background_removal():
            success_count += 1
        
        # 5. ë§ˆìŠ¤í„° ì„¤ì • íŒŒì¼ ìƒì„±
        self.create_master_config()
        
        logger.info(f"ğŸ‰ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {success_count}/{total_models}")
        
        if success_count == total_models:
            logger.info("âœ… ëª¨ë“  AI ëª¨ë¸ì´ ì„±ê³µì ìœ¼ë¡œ ë‹¤ìš´ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤!")
            logger.info("ğŸ“ ëª¨ë¸ ìœ„ì¹˜:")
            logger.info(f"   - ì²´í¬í¬ì¸íŠ¸: {self.checkpoints_dir}")
            logger.info(f"   - ì„¤ì • íŒŒì¼: {self.configs_dir}")
        else:
            logger.warning(f"âš ï¸ ì¼ë¶€ ëª¨ë¸ ë‹¤ìš´ë¡œë“œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ({success_count}/{total_models})")
        
        return success_count == total_models

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸ¤– MyCloset AI ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹œìŠ¤í…œ")
    print("=" * 50)
    
    try:
        downloader = AIModelDownloader()
        success = downloader.download_all()
        
        if success:
            print("\nğŸ‰ ì„¤ì¹˜ ì™„ë£Œ!")
            print("\nğŸ“‹ ë‹¤ìŒ ë‹¨ê³„:")
            print("1. ì˜ì¡´ì„± ì„¤ì¹˜: pip install -r requirements-ai.txt")
            print("2. ëª¨ë¸ í…ŒìŠ¤íŠ¸: python scripts/test_models.py")
            print("3. ì„œë²„ ì‹¤í–‰: uvicorn app.main:app --reload")
        else:
            print("\nâŒ ì¼ë¶€ ëª¨ë¸ ë‹¤ìš´ë¡œë“œê°€ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
            print("ë¡œê·¸ë¥¼ í™•ì¸í•˜ê³  ìˆ˜ë™ìœ¼ë¡œ ë‹¤ìš´ë¡œë“œí•´ì£¼ì„¸ìš”.")
            
    except KeyboardInterrupt:
        print("\nğŸ›‘ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        logger.error(f"âŒ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")

if __name__ == "__main__":
    main()