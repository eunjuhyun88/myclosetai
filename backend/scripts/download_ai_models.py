#!/usr/bin/env python3
# backend/scripts/download_ai_models.py
"""
MyCloset AI - AI ëª¨ë¸ ìë™ ë‹¤ìš´ë¡œë”
M3 Max ìµœì í™” ê°€ìƒ í”¼íŒ… ì‹œìŠ¤í…œìš© ëª¨ë¸ë“¤
"""

import os
import sys
import shutil
import logging
import subprocess
from pathlib import Path
from typing import Dict, List, Optional
import requests
from tqdm import tqdm
import hashlib

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì„¤ì •
PROJECT_ROOT = Path(__file__).parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler(PROJECT_ROOT / 'logs' / 'model_download.log', mode='a')
    ]
)
logger = logging.getLogger(__name__)

class AIModelDownloader:
    """AI ëª¨ë¸ ìë™ ë‹¤ìš´ë¡œë”"""
    
    def __init__(self):
        """ë‹¤ìš´ë¡œë” ì´ˆê¸°í™”"""
        self.project_root = PROJECT_ROOT
        self.models_dir = self.project_root / "ai_models"
        self.checkpoints_dir = self.models_dir / "checkpoints"
        self.temp_dir = self.models_dir / "temp"
        
        # ë””ë ‰í† ë¦¬ ìƒì„±
        self.models_dir.mkdir(exist_ok=True)
        self.checkpoints_dir.mkdir(exist_ok=True)
        self.temp_dir.mkdir(exist_ok=True)
        
        # ëª¨ë¸ ì •ë³´ ì„¤ì •
        self.model_configs = self._setup_model_configs()
        
        logger.info(f"ğŸ“ ëª¨ë¸ ë””ë ‰í† ë¦¬: {self.models_dir}")
        logger.info(f"ğŸ’¾ ì²´í¬í¬ì¸íŠ¸ ë””ë ‰í† ë¦¬: {self.checkpoints_dir}")
    
    def _setup_model_configs(self) -> Dict:
        """ëª¨ë¸ ì„¤ì • ì •ë³´ ë°˜í™˜"""
        
        return {
            "ootdiffusion": {
                "name": "OOTDiffusion",
                "description": "ìµœì‹  ê³ í’ˆì§ˆ ê°€ìƒ í”¼íŒ… ëª¨ë¸",
                "size_gb": 4.2,
                "priority": 1,
                "huggingface_repo": "levihsu/OOTDiffusion",
                "local_path": self.checkpoints_dir / "ootdiffusion",
                "required_files": [
                    "model_index.json",
                    "unet/diffusion_pytorch_model.safetensors",
                    "vae/diffusion_pytorch_model.safetensors",
                    "text_encoder/pytorch_model.bin",
                ],
                "download_method": "huggingface"
            },
            
            "viton_hd": {
                "name": "VITON-HD",
                "description": "ê³ í•´ìƒë„ ê°€ìƒ ì‹œì°© ëª¨ë¸",
                "size_gb": 2.8,
                "priority": 2,
                "github_repo": "shadow2496/VITON-HD",
                "local_path": self.checkpoints_dir / "viton_hd",
                "required_files": [
                    "gen.pt",
                    "seg.pt",
                    "pose.pt"
                ],
                "download_method": "github"
            },
            
            "densepose": {
                "name": "DensePose",
                "description": "ì¸ì²´ íŒŒì‹± ë° ìì„¸ ì¶”ì •",
                "size_gb": 1.5,
                "priority": 3,
                "model_zoo_url": "https://dl.fbaipublicfiles.com/densepose/densepose_rcnn_R_50_FPN_s1x.pkl",
                "local_path": self.checkpoints_dir / "densepose",
                "required_files": [
                    "densepose_rcnn_R_50_FPN_s1x.pkl",
                    "config.yaml"
                ],
                "download_method": "direct"
            },
            
            "openpose": {
                "name": "OpenPose",
                "description": "ì‹¤ì‹œê°„ ìì„¸ ì¶”ì •",
                "size_gb": 0.8,
                "priority": 4,
                "models": {
                    "pose_coco": "https://storage.googleapis.com/openimages/web/pose_coco.pth",
                    "pose_body_25": "https://storage.googleapis.com/openimages/web/pose_body_25.pth",
                },
                "local_path": self.checkpoints_dir / "openpose",
                "required_files": [
                    "pose_coco.pth",
                    "pose_body_25.pth"
                ],
                "download_method": "direct"
            },
            
            "segment_anything": {
                "name": "Segment Anything (SAM)",
                "description": "ë²”ìš© ì´ë¯¸ì§€ ì„¸ê·¸ë©˜í…Œì´ì…˜",
                "size_gb": 2.4,
                "priority": 5,
                "checkpoint_url": "https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth",
                "local_path": self.checkpoints_dir / "segment_anything",
                "required_files": [
                    "sam_vit_h_4b8939.pth"
                ],
                "download_method": "direct"
            }
        }
    
    def check_dependencies(self):
        """í•„ìš”í•œ íŒ¨í‚¤ì§€ í™•ì¸ ë° ì„¤ì¹˜"""
        
        logger.info("ğŸ“¦ ì˜ì¡´ì„± íŒ¨í‚¤ì§€ í™•ì¸ ì¤‘...")
        
        required_packages = [
            "huggingface_hub",
            "transformers",
            "diffusers",
            "gitpython",
        ]
        
        missing_packages = []
        
        for package in required_packages:
            try:
                __import__(package.replace("-", "_"))
                logger.info(f"âœ… {package} ì„¤ì¹˜ë¨")
            except ImportError:
                missing_packages.append(package)
                logger.warning(f"âŒ {package} ëˆ„ë½")
        
        if missing_packages:
            logger.info(f"ğŸ“¥ ëˆ„ë½ëœ íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì¤‘: {missing_packages}")
            for package in missing_packages:
                subprocess.run([sys.executable, "-m", "pip", "install", package], 
                             check=True)
            logger.info("âœ… ì˜ì¡´ì„± ì„¤ì¹˜ ì™„ë£Œ")
    
    def download_file_with_progress(self, url: str, filepath: Path, chunk_size: int = 8192) -> bool:
        """ì§„í–‰ë¥  í‘œì‹œì™€ í•¨ê»˜ íŒŒì¼ ë‹¤ìš´ë¡œë“œ"""
        
        try:
            response = requests.get(url, stream=True)
            response.raise_for_status()
            
            total_size = int(response.headers.get('content-length', 0))
            
            with open(filepath, 'wb') as f, tqdm(
                desc=filepath.name,
                total=total_size,
                unit='iB',
                unit_scale=True,
                unit_divisor=1024,
            ) as pbar:
                for chunk in response.iter_content(chunk_size=chunk_size):
                    if chunk:
                        size = f.write(chunk)
                        pbar.update(size)
            
            logger.info(f"âœ… ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {filepath.name}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨ {filepath.name}: {e}")
            if filepath.exists():
                filepath.unlink()
            return False
    
    def verify_file_integrity(self, filepath: Path, expected_size: Optional[int] = None) -> bool:
        """íŒŒì¼ ë¬´ê²°ì„± ê²€ì¦"""
        
        if not filepath.exists():
            return False
        
        file_size = filepath.stat().st_size
        
        if expected_size and abs(file_size - expected_size) > expected_size * 0.05:  # 5% ì˜¤ì°¨ í—ˆìš©
            logger.warning(f"âš ï¸ íŒŒì¼ í¬ê¸° ë¶ˆì¼ì¹˜: {filepath.name}")
            return False
        
        logger.info(f"âœ… íŒŒì¼ ê²€ì¦ í†µê³¼: {filepath.name} ({file_size // 1024 // 1024}MB)")
        return True
    
    def download_from_huggingface(self, model_config: Dict) -> bool:
        """Hugging Faceì—ì„œ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ"""
        
        try:
            from huggingface_hub import snapshot_download
            
            repo_id = model_config["huggingface_repo"]
            local_dir = model_config["local_path"]
            
            logger.info(f"ğŸ“¥ Hugging Faceì—ì„œ ë‹¤ìš´ë¡œë“œ: {repo_id}")
            
            snapshot_download(
                repo_id=repo_id,
                local_dir=local_dir,
                local_dir_use_symlinks=False,
                resume_download=True,
            )
            
            # í•„ìˆ˜ íŒŒì¼ ì¡´ì¬ í™•ì¸
            for required_file in model_config["required_files"]:
                file_path = local_dir / required_file
                if not file_path.exists():
                    logger.error(f"âŒ í•„ìˆ˜ íŒŒì¼ ëˆ„ë½: {required_file}")
                    return False
            
            logger.info(f"âœ… {model_config['name']} ë‹¤ìš´ë¡œë“œ ì™„ë£Œ")
            return True
            
        except Exception as e:
            logger.error(f"âŒ Hugging Face ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
            return False
    
    def download_from_github(self, model_config: Dict) -> bool:
        """GitHubì—ì„œ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ"""
        
        try:
            import git
            
            repo_url = f"https://github.com/{model_config['github_repo']}.git"
            local_dir = model_config["local_path"]
            
            logger.info(f"ğŸ“¥ GitHubì—ì„œ í´ë¡ : {repo_url}")
            
            if local_dir.exists():
                shutil.rmtree(local_dir)
            
            git.Repo.clone_from(repo_url, local_dir, depth=1)
            
            logger.info(f"âœ… {model_config['name']} í´ë¡  ì™„ë£Œ")
            return True
            
        except Exception as e:
            logger.error(f"âŒ GitHub í´ë¡  ì‹¤íŒ¨: {e}")
            return False
    
    def download_direct_files(self, model_config: Dict) -> bool:
        """ì§ì ‘ URLì—ì„œ íŒŒì¼ ë‹¤ìš´ë¡œë“œ"""
        
        local_dir = model_config["local_path"]
        local_dir.mkdir(parents=True, exist_ok=True)
        
        success = True
        
        # ë‹¨ì¼ URLì¸ ê²½ìš°
        if "checkpoint_url" in model_config:
            url = model_config["checkpoint_url"]
            filename = Path(url).name
            filepath = local_dir / filename
            
            if not self.download_file_with_progress(url, filepath):
                success = False
        
        # ì—¬ëŸ¬ ëª¨ë¸ URLì¸ ê²½ìš°
        elif "models" in model_config:
            for model_name, url in model_config["models"].items():
                filename = Path(url).name
                filepath = local_dir / filename
                
                if not self.download_file_with_progress(url, filepath):
                    success = False
        
        # ë‹¨ì¼ ëª¨ë¸ URLì¸ ê²½ìš°
        elif "model_zoo_url" in model_config:
            url = model_config["model_zoo_url"]
            filename = Path(url).name
            filepath = local_dir / filename
            
            if not self.download_file_with_progress(url, filepath):
                success = False
        
        if success:
            logger.info(f"âœ… {model_config['name']} ë‹¤ìš´ë¡œë“œ ì™„ë£Œ")
        
        return success
    
    def download_model(self, model_key: str) -> bool:
        """íŠ¹ì • ëª¨ë¸ ë‹¤ìš´ë¡œë“œ"""
        
        if model_key not in self.model_configs:
            logger.error(f"âŒ ì•Œ ìˆ˜ ì—†ëŠ” ëª¨ë¸: {model_key}")
            return False
        
        model_config = self.model_configs[model_key]
        
        logger.info(f"ğŸš€ {model_config['name']} ë‹¤ìš´ë¡œë“œ ì‹œì‘...")
        logger.info(f"ğŸ“ ì„¤ëª…: {model_config['description']}")
        logger.info(f"ğŸ’¾ ì˜ˆìƒ í¬ê¸°: {model_config['size_gb']}GB")
        
        # ì´ë¯¸ ë‹¤ìš´ë¡œë“œëœ ê²½ìš° í™•ì¸
        if self.is_model_downloaded(model_key):
            logger.info(f"âœ… {model_config['name']} ì´ë¯¸ ë‹¤ìš´ë¡œë“œë¨")
            return True
        
        # ë‹¤ìš´ë¡œë“œ ë°©ë²•ì— ë”°ë¼ ì‹¤í–‰
        download_method = model_config["download_method"]
        
        if download_method == "huggingface":
            return self.download_from_huggingface(model_config)
        elif download_method == "github":
            return self.download_from_github(model_config)
        elif download_method == "direct":
            return self.download_direct_files(model_config)
        else:
            logger.error(f"âŒ ì§€ì›í•˜ì§€ ì•ŠëŠ” ë‹¤ìš´ë¡œë“œ ë°©ë²•: {download_method}")
            return False
    
    def is_model_downloaded(self, model_key: str) -> bool:
        """ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì—¬ë¶€ í™•ì¸"""
        
        model_config = self.model_configs[model_key]
        local_path = model_config["local_path"]
        
        if not local_path.exists():
            return False
        
        # í•„ìˆ˜ íŒŒì¼ ì¡´ì¬ í™•ì¸
        for required_file in model_config["required_files"]:
            file_path = local_path / required_file
            if not file_path.exists():
                return False
        
        return True
    
    def download_essential_models(self) -> bool:
        """í•„ìˆ˜ ëª¨ë¸ë“¤ ë‹¤ìš´ë¡œë“œ"""
        
        essential_models = ["ootdiffusion", "densepose", "openpose"]
        
        logger.info("ğŸ¯ í•„ìˆ˜ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹œì‘...")
        
        success_count = 0
        
        for model_key in essential_models:
            if self.download_model(model_key):
                success_count += 1
            else:
                logger.error(f"âŒ í•„ìˆ˜ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {model_key}")
        
        if success_count == len(essential_models):
            logger.info("âœ… ëª¨ë“  í•„ìˆ˜ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ")
            return True
        else:
            logger.error(f"âŒ í•„ìˆ˜ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {success_count}/{len(essential_models)}")
            return False
    
    def download_all_models(self) -> bool:
        """ëª¨ë“  ëª¨ë¸ ë‹¤ìš´ë¡œë“œ"""
        
        logger.info("ğŸŒŸ ì „ì²´ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹œì‘...")
        
        # ìš°ì„ ìˆœìœ„ ìˆœìœ¼ë¡œ ì •ë ¬
        sorted_models = sorted(
            self.model_configs.items(), 
            key=lambda x: x[1]["priority"]
        )
        
        success_count = 0
        total_size = sum(config["size_gb"] for _, config in sorted_models)
        
        logger.info(f"ğŸ“Š ì´ ë‹¤ìš´ë¡œë“œ í¬ê¸°: {total_size:.1f}GB")
        
        for model_key, model_config in sorted_models:
            if self.download_model(model_key):
                success_count += 1
        
        if success_count == len(sorted_models):
            logger.info("ğŸ‰ ëª¨ë“  ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ!")
            return True
        else:
            logger.warning(f"âš ï¸ ì¼ë¶€ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {success_count}/{len(sorted_models)}")
            return False
    
    def create_model_config_file(self):
        """ëª¨ë¸ ì„¤ì • íŒŒì¼ ìƒì„±"""
        
        import yaml
        
        config = {
            "models": {
                model_key: {
                    "name": config["name"],
                    "path": str(config["local_path"]),
                    "device": "mps",  # M3 Max ê¸°ë³¸ê°’
                    "enabled": self.is_model_downloaded(model_key)
                }
                for model_key, config in self.model_configs.items()
            },
            "processing": {
                "image_size": 512,
                "batch_size": 1,
                "num_inference_steps": 20,
                "guidance_scale": 7.5,
                "device": "mps"
            }
        }
        
        config_path = self.models_dir / "models_config.yaml"
        with open(config_path, 'w') as f:
            yaml.dump(config, f, default_flow_style=False)
        
        logger.info(f"âœ… ëª¨ë¸ ì„¤ì • íŒŒì¼ ìƒì„±: {config_path}")
    
    def get_download_status(self) -> Dict:
        """ë‹¤ìš´ë¡œë“œ ìƒíƒœ í™•ì¸"""
        
        status = {
            "total_models": len(self.model_configs),
            "downloaded": 0,
            "missing": [],
            "total_size_gb": 0,
            "downloaded_size_gb": 0,
        }
        
        for model_key, model_config in self.model_configs.items():
            status["total_size_gb"] += model_config["size_gb"]
            
            if self.is_model_downloaded(model_key):
                status["downloaded"] += 1
                status["downloaded_size_gb"] += model_config["size_gb"]
            else:
                status["missing"].append(model_key)
        
        return status
    
    def cleanup_temp_files(self):
        """ì„ì‹œ íŒŒì¼ ì •ë¦¬"""
        
        logger.info("ğŸ§¹ ì„ì‹œ íŒŒì¼ ì •ë¦¬ ì¤‘...")
        
        if self.temp_dir.exists():
            shutil.rmtree(self.temp_dir)
            self.temp_dir.mkdir()
        
        logger.info("âœ… ì„ì‹œ íŒŒì¼ ì •ë¦¬ ì™„ë£Œ")

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    
    print("ğŸ¤– MyCloset AI - AI ëª¨ë¸ ë‹¤ìš´ë¡œë”")
    print("M3 Max ìµœì í™” ê°€ìƒ í”¼íŒ… ì‹œìŠ¤í…œ")
    print("=" * 50)
    
    downloader = AIModelDownloader()
    
    # ì˜ì¡´ì„± í™•ì¸
    downloader.check_dependencies()
    
    # í˜„ì¬ ìƒíƒœ í™•ì¸
    status = downloader.get_download_status()
    print(f"\nğŸ“Š í˜„ì¬ ìƒíƒœ:")
    print(f"  ì „ì²´ ëª¨ë¸: {status['total_models']}")
    print(f"  ë‹¤ìš´ë¡œë“œë¨: {status['downloaded']}")
    print(f"  ëˆ„ë½ë¨: {len(status['missing'])}")
    print(f"  ì „ì²´ í¬ê¸°: {status['total_size_gb']:.1f}GB")
    print(f"  ë‹¤ìš´ë¡œë“œëœ í¬ê¸°: {status['downloaded_size_gb']:.1f}GB")
    
    if status['missing']:
        print(f"  ëˆ„ë½ëœ ëª¨ë¸: {', '.join(status['missing'])}")
    
    # ì‚¬ìš©ì ì„ íƒ
    print(f"\në‹¤ìš´ë¡œë“œ ì˜µì…˜:")
    print("1. í•„ìˆ˜ ëª¨ë¸ë§Œ (OOTDiffusion, DensePose, OpenPose) - 6.5GB")
    print("2. ì „ì²´ ëª¨ë¸ (ê¶Œì¥) - 11.7GB")
    print("3. ê°œë³„ ëª¨ë¸ ì„ íƒ")
    print("4. ìƒíƒœ í™•ì¸ë§Œ")
    print("0. ì¢…ë£Œ")
    
    try:
        choice = input("\nì„ íƒ (1-4, 0): ").strip()
        
        if choice == "1":
            print("\nğŸ¯ í•„ìˆ˜ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹œì‘...")
            success = downloader.download_essential_models()
            
        elif choice == "2":
            print("\nğŸŒŸ ì „ì²´ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹œì‘...")
            success = downloader.download_all_models()
            
        elif choice == "3":
            print("\nì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸:")
            for i, (key, config) in enumerate(downloader.model_configs.items(), 1):
                downloaded = "âœ…" if downloader.is_model_downloaded(key) else "âŒ"
                print(f"  {i}. {config['name']} - {config['size_gb']}GB {downloaded}")
            
            model_num = input("ë‹¤ìš´ë¡œë“œí•  ëª¨ë¸ ë²ˆí˜¸: ").strip()
            
            try:
                model_keys = list(downloader.model_configs.keys())
                selected_key = model_keys[int(model_num) - 1]
                success = downloader.download_model(selected_key)
            except (ValueError, IndexError):
                print("âŒ ì˜ëª»ëœ ë²ˆí˜¸ì…ë‹ˆë‹¤.")
                return
                
        elif choice == "4":
            print("âœ… ìƒíƒœ í™•ì¸ ì™„ë£Œ")
            return
            
        elif choice == "0":
            print("ğŸ‘‹ ë‹¤ìš´ë¡œë”ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            return
            
        else:
            print("âŒ ì˜ëª»ëœ ì„ íƒì…ë‹ˆë‹¤.")
            return
        
        # ì„¤ì • íŒŒì¼ ìƒì„±
        downloader.create_model_config_file()
        
        # ì„ì‹œ íŒŒì¼ ì •ë¦¬
        downloader.cleanup_temp_files()
        
        # ìµœì¢… ìƒíƒœ ì¶œë ¥
        final_status = downloader.get_download_status()
        print(f"\nğŸ‰ ì‘ì—… ì™„ë£Œ!")
        print(f"ğŸ“Š ìµœì¢… ìƒíƒœ: {final_status['downloaded']}/{final_status['total_models']} ëª¨ë¸")
        print(f"ğŸ’¾ ë‹¤ìš´ë¡œë“œëœ í¬ê¸°: {final_status['downloaded_size_gb']:.1f}GB")
        
        if final_status['downloaded'] > 0:
            print(f"\nâœ… ë‹¤ìŒ ë‹¨ê³„: ê°œë°œ ì„œë²„ ì‹¤í–‰")
            print(f"cd backend && python run_server.py")
        
    except KeyboardInterrupt:
        print("\n\nâš ï¸ ì‚¬ìš©ìê°€ ì·¨ì†Œí–ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        logger.error(f"âŒ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")

if __name__ == "__main__":
    main()