#!/usr/bin/env python3
# backend/scripts/detect_existing_models.py
"""
ê¸°ì¡´ì— ë‹¤ìš´ë¡œë“œëœ AI ëª¨ë¸ë“¤ì„ ê°ì§€í•˜ê³  MyCloset AI ì‹œìŠ¤í…œì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ ì„¤ì •
"""

import os
import yaml
import json
from pathlib import Path
import logging
from typing import Dict, List, Any

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class ExistingModelsDetector:
    """ê¸°ì¡´ AI ëª¨ë¸ ê°ì§€ ë° ì„¤ì • í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.project_root = Path(__file__).parent.parent
        self.ai_models_dir = self.project_root / "ai_models"
        self.detected_models = {}
        
        logger.info(f"ğŸ” AI ëª¨ë¸ ë””ë ‰í† ë¦¬: {self.ai_models_dir}")
    
    def scan_all_models(self) -> Dict[str, Any]:
        """ëª¨ë“  AI ëª¨ë¸ ìŠ¤ìº”"""
        
        logger.info("ğŸš€ AI ëª¨ë¸ ì „ì²´ ìŠ¤ìº” ì‹œì‘...")
        
        # 1. OOTDiffusion ëª¨ë¸ë“¤
        self._scan_ootdiffusion()
        
        # 2. Stable Diffusion
        self._scan_stable_diffusion()
        
        # 3. Segment Anything (SAM)
        self._scan_sam()
        
        # 4. Human Parsing & Pose Detection
        self._scan_human_parsing()
        
        # 5. CLIP
        self._scan_clip()
        
        # 6. ê¸°íƒ€ ëª¨ë¸ë“¤
        self._scan_additional_models()
        
        # 7. í†µê³„ ì¶œë ¥
        self._print_summary()
        
        return self.detected_models
    
    def _scan_ootdiffusion(self):
        """OOTDiffusion ëª¨ë¸ ìŠ¤ìº”"""
        
        logger.info("ğŸ½ OOTDiffusion ëª¨ë¸ ìŠ¤ìº” ì¤‘...")
        
        # ootdiffusion_hf ë””ë ‰í† ë¦¬ (Hugging Face ë²„ì „)
        ootd_hf_path = self.ai_models_dir / "ootdiffusion_hf"
        if ootd_hf_path.exists():
            ootd_info = {
                "name": "OOTDiffusion (Hugging Face)",
                "path": str(ootd_hf_path),
                "type": "virtual_tryon",
                "priority": 1,
                "components": {},
                "total_size_gb": 0,
                "ready": True
            }
            
            # í•˜ìœ„ ì»´í¬ë„ŒíŠ¸ ìŠ¤ìº”
            checkpoints_path = ootd_hf_path / "checkpoints" / "ootd"
            if checkpoints_path.exists():
                
                # HD ëª¨ë¸ (ê³ í•´ìƒë„)
                hd_path = checkpoints_path / "ootd_hd" / "checkpoint-36000"
                if hd_path.exists():
                    ootd_info["components"]["hd"] = {
                        "unet_vton": str(hd_path / "unet_vton"),
                        "unet_garm": str(hd_path / "unet_garm"),
                        "size_gb": 6.4  # 3.2GB x 2
                    }
                
                # DC ëª¨ë¸ (ì¼ë°˜ í’ˆì§ˆ)
                dc_path = checkpoints_path / "ootd_dc" / "checkpoint-36000"
                if dc_path.exists():
                    ootd_info["components"]["dc"] = {
                        "unet_vton": str(dc_path / "unet_vton"),
                        "unet_garm": str(dc_path / "unet_garm"),
                        "size_gb": 6.4  # 3.2GB x 2
                    }
                
                # ê³µí†µ ì»´í¬ë„ŒíŠ¸
                text_encoder = checkpoints_path / "text_encoder"
                vae = checkpoints_path / "vae"
                
                if text_encoder.exists():
                    ootd_info["components"]["text_encoder"] = str(text_encoder)
                if vae.exists():
                    ootd_info["components"]["vae"] = str(vae)
                
                ootd_info["total_size_gb"] = 13.0  # ëŒ€ëµì  í¬ê¸°
            
            self.detected_models["ootdiffusion"] = ootd_info
            logger.info(f"âœ… OOTDiffusion ë°œê²¬: HD/DC ëª¨ë“œ ì§€ì›, {ootd_info['total_size_gb']}GB")
        
        # checkpoints/ootdiffusion ë””ë ‰í† ë¦¬ë„ í™•ì¸
        checkpoints_ootd = self.ai_models_dir / "checkpoints" / "ootdiffusion"
        if checkpoints_ootd.exists():
            additional_info = {
                "name": "OOTDiffusion (Checkpoints)",
                "path": str(checkpoints_ootd),
                "type": "virtual_tryon_additional",
                "components": {
                    "openpose": str(checkpoints_ootd / "checkpoints" / "openpose"),
                    "humanparsing": str(checkpoints_ootd / "checkpoints" / "humanparsing")
                },
                "ready": True
            }
            self.detected_models["ootdiffusion_additional"] = additional_info
            logger.info("âœ… OOTDiffusion ì¶”ê°€ ì²´í¬í¬ì¸íŠ¸ ë°œê²¬")
    
    def _scan_stable_diffusion(self):
        """Stable Diffusion ëª¨ë¸ ìŠ¤ìº”"""
        
        logger.info("ğŸ¨ Stable Diffusion ëª¨ë¸ ìŠ¤ìº” ì¤‘...")
        
        sd_path = self.ai_models_dir / "checkpoints" / "stable-diffusion-v1-5"
        if sd_path.exists():
            sd_info = {
                "name": "Stable Diffusion v1.5",
                "path": str(sd_path),
                "type": "base_diffusion",
                "priority": 2,
                "components": {},
                "total_size_gb": 15.0,
                "ready": True
            }
            
            # ì£¼ìš” ì»´í¬ë„ŒíŠ¸ í™•ì¸
            components = {
                "unet": sd_path / "unet",
                "vae": sd_path / "vae", 
                "text_encoder": sd_path / "text_encoder",
                "safety_checker": sd_path / "safety_checker"
            }
            
            for comp_name, comp_path in components.items():
                if comp_path.exists():
                    sd_info["components"][comp_name] = str(comp_path)
            
            # ì „ì²´ ëª¨ë¸ íŒŒì¼ë“¤ë„ í™•ì¸
            model_files = list(sd_path.glob("*.safetensors")) + list(sd_path.glob("*.ckpt"))
            if model_files:
                sd_info["components"]["full_models"] = [str(f) for f in model_files]
            
            self.detected_models["stable_diffusion"] = sd_info
            logger.info(f"âœ… Stable Diffusion v1.5 ë°œê²¬: ì™„ì „í•œ íŒŒì´í”„ë¼ì¸, {sd_info['total_size_gb']}GB")
    
    def _scan_sam(self):
        """Segment Anything ëª¨ë¸ ìŠ¤ìº”"""
        
        logger.info("âœ‚ï¸ Segment Anything ëª¨ë¸ ìŠ¤ìº” ì¤‘...")
        
        sam_path = self.ai_models_dir / "checkpoints" / "sam"
        if sam_path.exists():
            sam_info = {
                "name": "Segment Anything (SAM)",
                "path": str(sam_path),
                "type": "segmentation",
                "priority": 3,
                "models": {},
                "total_size_gb": 2.8,
                "ready": True
            }
            
            # SAM ëª¨ë¸ë“¤ í™•ì¸
            sam_models = {
                "vit_h": sam_path / "sam_vit_h_4b8939.pth",
                "vit_b": sam_path / "sam_vit_b_01ec64.pth"
            }
            
            for model_name, model_path in sam_models.items():
                if model_path.exists():
                    size_mb = model_path.stat().st_size / (1024 * 1024)
                    sam_info["models"][model_name] = {
                        "path": str(model_path),
                        "size_mb": round(size_mb, 1)
                    }
            
            self.detected_models["sam"] = sam_info
            logger.info(f"âœ… SAM ë°œê²¬: {len(sam_info['models'])}ê°œ ëª¨ë¸, {sam_info['total_size_gb']}GB")
    
    def _scan_human_parsing(self):
        """Human Parsing ë° Pose Detection ëª¨ë¸ ìŠ¤ìº”"""
        
        logger.info("ğŸ‘¤ Human Parsing & Pose ëª¨ë¸ ìŠ¤ìº” ì¤‘...")
        
        # Graphonomy
        graphonomy_path = self.ai_models_dir / "Graphonomy"
        if graphonomy_path.exists():
            graphonomy_info = {
                "name": "Graphonomy (Human Parsing)",
                "path": str(graphonomy_path),
                "type": "human_parsing",
                "priority": 4,
                "ready": True,
                "size_gb": 0.1
            }
            self.detected_models["graphonomy"] = graphonomy_info
            logger.info("âœ… Graphonomy ë°œê²¬")
        
        # Self-Correction-Human-Parsing
        schp_path = self.ai_models_dir / "Self-Correction-Human-Parsing"
        if schp_path.exists():
            schp_info = {
                "name": "Self-Correction Human Parsing",
                "path": str(schp_path),
                "type": "human_parsing",
                "priority": 4,
                "ready": True,
                "size_gb": 0.1
            }
            self.detected_models["schp"] = schp_info
            logger.info("âœ… Self-Correction Human Parsing ë°œê²¬")
        
        # OpenPose
        openpose_path = self.ai_models_dir / "openpose"
        if openpose_path.exists():
            openpose_info = {
                "name": "OpenPose",
                "path": str(openpose_path),
                "type": "pose_estimation",
                "priority": 4,
                "ready": True,
                "size_gb": 0.2
            }
            self.detected_models["openpose"] = openpose_info
            logger.info("âœ… OpenPose ë°œê²¬")
    
    def _scan_clip(self):
        """CLIP ëª¨ë¸ ìŠ¤ìº”"""
        
        logger.info("ğŸ”— CLIP ëª¨ë¸ ìŠ¤ìº” ì¤‘...")
        
        clip_path = self.ai_models_dir / "checkpoints" / "clip-vit-large-patch14"
        if clip_path.exists():
            clip_info = {
                "name": "CLIP ViT-Large",
                "path": str(clip_path),
                "type": "vision_language",
                "priority": 5,
                "ready": True,
                "size_gb": 1.6
            }
            self.detected_models["clip"] = clip_info
            logger.info("âœ… CLIP ViT-Large ë°œê²¬")
    
    def _scan_additional_models(self):
        """ê¸°íƒ€ ì¶”ê°€ ëª¨ë¸ë“¤ ìŠ¤ìº”"""
        
        logger.info("ğŸ“¦ ì¶”ê°€ ëª¨ë¸ ìŠ¤ìº” ì¤‘...")
        
        # gen.pth (VITON-HD)
        gen_pth = self.ai_models_dir / "gen.pth"
        if gen_pth.exists() and gen_pth.stat().st_size > 1000:  # ìµœì†Œ í¬ê¸° í™•ì¸
            self.detected_models["viton_gen"] = {
                "name": "VITON-HD Generator",
                "path": str(gen_pth),
                "type": "virtual_tryon",
                "priority": 6,
                "ready": True,
                "size_mb": round(gen_pth.stat().st_size / (1024 * 1024), 1)
            }
            logger.info("âœ… VITON-HD Generator ë°œê²¬")
        
        # ResNet50 features
        resnet_path = self.ai_models_dir / "checkpoints" / "resnet50_features.pth"
        if resnet_path.exists():
            self.detected_models["resnet50"] = {
                "name": "ResNet50 Features",
                "path": str(resnet_path),
                "type": "feature_extractor",
                "priority": 7,
                "ready": True,
                "size_mb": round(resnet_path.stat().st_size / (1024 * 1024), 1)
            }
            logger.info("âœ… ResNet50 Features ë°œê²¬")
        
        # HR-VITON, VITON-HD ë””ë ‰í† ë¦¬ë“¤
        for viton_name in ["HR-VITON", "VITON-HD"]:
            viton_path = self.ai_models_dir / viton_name
            if viton_path.exists():
                self.detected_models[viton_name.lower().replace("-", "_")] = {
                    "name": viton_name,
                    "path": str(viton_path),
                    "type": "virtual_tryon",
                    "priority": 8,
                    "ready": True,
                    "size_gb": 0.1
                }
                logger.info(f"âœ… {viton_name} ë””ë ‰í† ë¦¬ ë°œê²¬")
    
    def _print_summary(self):
        """ë°œê²¬ëœ ëª¨ë¸ ìš”ì•½ ì¶œë ¥"""
        
        logger.info("\n" + "="*60)
        logger.info("ğŸ‰ AI ëª¨ë¸ ìŠ¤ìº” ì™„ë£Œ - ìš”ì•½")
        logger.info("="*60)
        
        total_models = len(self.detected_models)
        total_size = 0
        
        by_type = {}
        
        for model_key, model_info in self.detected_models.items():
            model_type = model_info.get("type", "unknown")
            size = model_info.get("total_size_gb", model_info.get("size_gb", 0))
            
            if model_type not in by_type:
                by_type[model_type] = {"count": 0, "size": 0, "models": []}
            
            by_type[model_type]["count"] += 1
            by_type[model_type]["size"] += size
            by_type[model_type]["models"].append(model_info["name"])
            
            total_size += size
        
        logger.info(f"ğŸ“Š ì´ ë°œê²¬ëœ ëª¨ë¸: {total_models}ê°œ")
        logger.info(f"ğŸ’¾ ì´ í¬ê¸°: {total_size:.1f}GB")
        logger.info("")
        
        for type_name, type_info in by_type.items():
            logger.info(f"ğŸ”¹ {type_name}: {type_info['count']}ê°œ ({type_info['size']:.1f}GB)")
            for model_name in type_info['models']:
                logger.info(f"    - {model_name}")
        
        logger.info("\nğŸš€ ë‹¤ìŒ ë‹¨ê³„: ëª¨ë¸ ì„¤ì • íŒŒì¼ ìƒì„±")
    
    def create_model_config(self) -> Dict[str, Any]:
        """ëª¨ë¸ ì„¤ì • íŒŒì¼ ìƒì„±"""
        
        logger.info("ğŸ“ ëª¨ë¸ ì„¤ì • íŒŒì¼ ìƒì„± ì¤‘...")
        
        config = {
            "models": self.detected_models,
            "system": {
                "device": "mps",  # M3 Max ê¸°ë³¸ê°’
                "batch_size": 1,
                "fp16": False,  # MPSì—ì„œëŠ” fp32 ì‚¬ìš©
                "cpu_offload": False,  # 128GB RAMì´ë¯€ë¡œ ë¹„í™œì„±í™”
            },
            "paths": {
                "ai_models_root": str(self.ai_models_dir),
                "cache_dir": str(self.ai_models_dir / "cache"),
                "temp_dir": str(self.ai_models_dir / "temp"),
                "checkpoints_dir": str(self.ai_models_dir / "checkpoints")
            },
            "virtual_tryon": {
                "default_model": "ootdiffusion",
                "image_size": 512,
                "num_inference_steps": 20,
                "guidance_scale": 7.5,
                "enable_safety_checker": True
            },
            "performance": {
                "max_memory_gb": 24,  # M3 Max GPU ë©”ëª¨ë¦¬ í•œê³„
                "enable_attention_slicing": True,
                "enable_cpu_offload": False,
                "enable_sequential_cpu_offload": False
            }
        }
        
        # YAML íŒŒì¼ë¡œ ì €ì¥
        config_path = self.ai_models_dir / "detected_models_config.yaml"
        with open(config_path, 'w') as f:
            yaml.dump(config, f, default_flow_style=False, allow_unicode=True)
        
        logger.info(f"âœ… ëª¨ë¸ ì„¤ì • íŒŒì¼ ì €ì¥: {config_path}")
        
        # ê¸°ì¡´ ì„¤ì • íŒŒì¼ ë°±ì—… ë° êµì²´
        old_config = self.ai_models_dir / "model_config.yaml"
        if old_config.exists():
            backup_path = self.ai_models_dir / "model_config_backup.yaml"
            old_config.rename(backup_path)
            logger.info(f"ğŸ“¦ ê¸°ì¡´ ì„¤ì • ë°±ì—…: {backup_path}")
        
        config_path.rename(old_config)
        logger.info("âœ… ìƒˆ ëª¨ë¸ ì„¤ì • íŒŒì¼ ì ìš© ì™„ë£Œ")
        
        return config
    
    def create_python_model_paths(self):
        """Pythonì—ì„œ ì‚¬ìš©í•  ëª¨ë¸ ê²½ë¡œ íŒŒì¼ ìƒì„±"""
        
        logger.info("ğŸ Python ëª¨ë¸ ê²½ë¡œ íŒŒì¼ ìƒì„± ì¤‘...")
        
        python_config = f'''# backend/app/core/model_paths.py
"""
AI ëª¨ë¸ ê²½ë¡œ ì„¤ì • - ìë™ ìƒì„±ë¨
ê¸°ì¡´ ë‹¤ìš´ë¡œë“œëœ ëª¨ë¸ë“¤ì˜ ì‹¤ì œ ê²½ë¡œ ë§¤í•‘
"""

from pathlib import Path
from typing import Dict, Optional, List

# ê¸°ë³¸ ê²½ë¡œ
AI_MODELS_ROOT = Path(__file__).parent.parent.parent / "ai_models"

# ë°œê²¬ëœ ëª¨ë¸ ê²½ë¡œ ë§¤í•‘
DETECTED_MODELS = {{
'''
        
        for model_key, model_info in self.detected_models.items():
            python_config += f'''    "{model_key}": {{
        "name": "{model_info['name']}",
        "path": Path("{model_info['path']}"),
        "type": "{model_info['type']}",
        "ready": {model_info['ready']},
        "priority": {model_info.get('priority', 99)}
    }},
'''
        
        python_config += '''}}

# íƒ€ì…ë³„ ëª¨ë¸ ê·¸ë£¹í•‘
def get_models_by_type(model_type: str) -> List[str]:
    """íƒ€ì…ë³„ ëª¨ë¸ ëª©ë¡ ë°˜í™˜"""
    return [key for key, info in DETECTED_MODELS.items() 
            if info["type"] == model_type and info["ready"]]

def get_virtual_tryon_models() -> List[str]:
    """ê°€ìƒ í”¼íŒ… ëª¨ë¸ ëª©ë¡"""
    return get_models_by_type("virtual_tryon")

def get_primary_ootd_path() -> Path:
    """ë©”ì¸ OOTDiffusion ê²½ë¡œ ë°˜í™˜"""
    if "ootdiffusion" in DETECTED_MODELS:
        return DETECTED_MODELS["ootdiffusion"]["path"]
    raise FileNotFoundError("OOTDiffusion ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

def get_stable_diffusion_path() -> Path:
    """Stable Diffusion ê²½ë¡œ ë°˜í™˜"""
    if "stable_diffusion" in DETECTED_MODELS:
        return DETECTED_MODELS["stable_diffusion"]["path"]
    raise FileNotFoundError("Stable Diffusion ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

def get_sam_path(model_size: str = "vit_h") -> Path:
    """SAM ëª¨ë¸ ê²½ë¡œ ë°˜í™˜"""
    if "sam" in DETECTED_MODELS:
        base_path = DETECTED_MODELS["sam"]["path"]
        if model_size == "vit_h":
            return Path(base_path) / "sam_vit_h_4b8939.pth"
        elif model_size == "vit_b":
            return Path(base_path) / "sam_vit_b_01ec64.pth"
    raise FileNotFoundError(f"SAM {model_size} ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

def is_model_available(model_key: str) -> bool:
    """ëª¨ë¸ ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸"""
    if model_key in DETECTED_MODELS:
        model_path = DETECTED_MODELS[model_key]["path"]
        return Path(model_path).exists()
    return False

def get_all_available_models() -> List[str]:
    """ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë“  ëª¨ë¸ ëª©ë¡"""
    available = []
    for key, info in DETECTED_MODELS.items():
        if info["ready"] and Path(info["path"]).exists():
            available.append(key)
    return sorted(available, key=lambda x: DETECTED_MODELS[x]["priority"])

def get_model_info(model_key: str) -> Optional[Dict]:
    """ëª¨ë¸ ì •ë³´ ë°˜í™˜"""
    return DETECTED_MODELS.get(model_key)

# ë¹ ë¥¸ ê²½ë¡œ ì ‘ê·¼
class ModelPaths:
    """ëª¨ë¸ ê²½ë¡œ ë¹ ë¥¸ ì ‘ê·¼ í´ë˜ìŠ¤"""
    
    @property
    def ootd_hf(self) -> Path:
        return get_primary_ootd_path()
    
    @property
    def stable_diffusion(self) -> Path:
        return get_stable_diffusion_path()
    
    @property
    def sam_large(self) -> Path:
        return get_sam_path("vit_h")
    
    @property
    def sam_base(self) -> Path:
        return get_sam_path("vit_b")

# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
model_paths = ModelPaths()
'''
        
        # íŒŒì¼ ì €ì¥
        python_path = self.project_root / "app" / "core" / "model_paths.py"
        python_path.parent.mkdir(parents=True, exist_ok=True)
        
        with open(python_path, 'w') as f:
            f.write(python_config)
        
        logger.info(f"âœ… Python ëª¨ë¸ ê²½ë¡œ íŒŒì¼ ì €ì¥: {python_path}")
    
    def create_usage_guide(self):
        """ì‚¬ìš© ê°€ì´ë“œ ìƒì„±"""
        
        logger.info("ğŸ“– ì‚¬ìš© ê°€ì´ë“œ ìƒì„± ì¤‘...")
        
        guide_content = f"""# ğŸ¯ MyCloset AI - ë°œê²¬ëœ ëª¨ë¸ ì‚¬ìš© ê°€ì´ë“œ

## ğŸ“Š ë°œê²¬ëœ ëª¨ë¸ í˜„í™©

ì´ **{len(self.detected_models)}ê°œ** AI ëª¨ë¸ì´ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤.

"""
        
        # ëª¨ë¸ë³„ ìƒì„¸ ì •ë³´
        for model_key, model_info in self.detected_models.items():
            guide_content += f"""### {model_info['name']} (`{model_key}`)
- **íƒ€ì…**: {model_info['type']}
- **ê²½ë¡œ**: `{model_info['path']}`
- **ìš°ì„ ìˆœìœ„**: {model_info.get('priority', 'N/A')}
- **ìƒíƒœ**: {'âœ… ì¤€ë¹„ë¨' if model_info['ready'] else 'âŒ ì¤€ë¹„ ì•ˆë¨'}
"""
            
            if 'total_size_gb' in model_info:
                guide_content += f"- **í¬ê¸°**: {model_info['total_size_gb']}GB\n"
            elif 'size_mb' in model_info:
                guide_content += f"- **í¬ê¸°**: {model_info['size_mb']}MB\n"
            
            if 'components' in model_info:
                guide_content += "- **ì»´í¬ë„ŒíŠ¸**:\n"
                for comp_name, comp_path in model_info['components'].items():
                    guide_content += f"  - {comp_name}: `{comp_path}`\n"
            
            guide_content += "\n"
        
        guide_content += """
## ğŸš€ Pythonì—ì„œ ì‚¬ìš©ë²•

### ê¸°ë³¸ ì‚¬ìš©
```python
from app.core.model_paths import model_paths, get_all_available_models

# ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë“  ëª¨ë¸ í™•ì¸
available_models = get_all_available_models()
print(f"ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸: {available_models}")

# ì£¼ìš” ëª¨ë¸ ê²½ë¡œ ì ‘ê·¼
ootd_path = model_paths.ootd_hf
sd_path = model_paths.stable_diffusion
sam_path = model_paths.sam_large
```

### ê°€ìƒ í”¼íŒ… íŒŒì´í”„ë¼ì¸
```python
from app.core.model_paths import get_primary_ootd_path, get_stable_diffusion_path

# OOTDiffusion ë¡œë“œ ì¤€ë¹„
ootd_base = get_primary_ootd_path()
sd_base = get_stable_diffusion_path()

# ì‹¤ì œ ëª¨ë¸ ë¡œë”©ì€ diffusers ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš©
from diffusers import StableDiffusionPipeline

pipeline = StableDiffusionPipeline.from_pretrained(
    str(sd_base),
    torch_dtype=torch.float32,  # M3 Max MPSìš©
    device_map="auto"
)
```

### SAM ì„¸ê·¸ë©˜í…Œì´ì…˜
```python
from app.core.model_paths import get_sam_path

# SAM ëª¨ë¸ ë¡œë“œ
sam_model_path = get_sam_path("vit_h")  # ê³ ì„±ëŠ¥
# sam_model_path = get_sam_path("vit_b")  # ê²½ëŸ‰

import torch
from segment_anything import sam_model_registry, SamPredictor

sam = sam_model_registry["vit_h"](checkpoint=str(sam_model_path))
sam.to(device="mps")  # M3 Max GPU
predictor = SamPredictor(sam)
```

## ğŸ”§ FastAPI í†µí•©

### ëª¨ë¸ ìƒíƒœ API
```python
from app.core.model_paths import DETECTED_MODELS, is_model_available

@app.get("/api/models/status")
async def get_models_status():
    status = {}
    for model_key, model_info in DETECTED_MODELS.items():
        status[model_key] = {
            "name": model_info["name"],
            "type": model_info["type"],
            "available": is_model_available(model_key),
            "ready": model_info["ready"]
        }
    return status
```

## ğŸ¯ ì¶”ì²œ ì›Œí¬í”Œë¡œìš°

1. **ê¸°ë³¸ í…ŒìŠ¤íŠ¸**: SAM ì„¸ê·¸ë©˜í…Œì´ì…˜ë¶€í„° ì‹œì‘
2. **ê°€ìƒ í”¼íŒ… êµ¬í˜„**: OOTDiffusion + Stable Diffusion
3. **ì„±ëŠ¥ ìµœì í™”**: M3 Max Metal ê°€ì† í™œìš©
4. **í”„ë¡œë•ì…˜ ë°°í¬**: ëª¨ë“  ëª¨ë¸ í†µí•©

## ğŸš¨ ì£¼ì˜ì‚¬í•­

- **M3 Max ìµœì í™”**: `torch.float32` ì‚¬ìš© (MPSì—ì„œ ì•ˆì •ì )
- **ë©”ëª¨ë¦¬ ê´€ë¦¬**: 128GB RAM í™œìš©í•˜ì—¬ CPU ì˜¤í”„ë¡œë“œ ë¹„í™œì„±í™”
- **ë°°ì¹˜ í¬ê¸°**: `batch_size=1` ê¶Œì¥ (ì´ˆê¸° ì„¤ì •)

---

ğŸ‰ **ëª¨ë“  ëª¨ë¸ì´ ì¤€ë¹„ë˜ì–´ ìˆìŠµë‹ˆë‹¤!** ë°”ë¡œ AI ê°€ìƒ í”¼íŒ… ê°œë°œì„ ì‹œì‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
"""
        
        guide_path = self.ai_models_dir / "MODELS_USAGE_GUIDE.md"
        with open(guide_path, 'w') as f:
            f.write(guide_content)
        
        logger.info(f"âœ… ì‚¬ìš© ê°€ì´ë“œ ì €ì¥: {guide_path}")

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    
    print("ğŸ” MyCloset AI - ê¸°ì¡´ AI ëª¨ë¸ ê°ì§€ ë„êµ¬")
    print("=" * 60)
    
    detector = ExistingModelsDetector()
    
    # 1. ëª¨ë“  ëª¨ë¸ ìŠ¤ìº”
    detected = detector.scan_all_models()
    
    if not detected:
        logger.warning("âš ï¸ ì‚¬ìš© ê°€ëŠ¥í•œ AI ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # 2. ì„¤ì • íŒŒì¼ ìƒì„±
    config = detector.create_model_config()
    
    # 3. Python ê²½ë¡œ íŒŒì¼ ìƒì„±
    detector.create_python_model_paths()
    
    # 4. ì‚¬ìš© ê°€ì´ë“œ ìƒì„±
    detector.create_usage_guide()
    
    print("\nğŸ‰ ëª¨ë¸ ê°ì§€ ë° ì„¤ì • ì™„ë£Œ!")
    print("\nğŸ“‹ ìƒì„±ëœ íŒŒì¼:")
    print("  - ai_models/model_config.yaml (ì—…ë°ì´íŠ¸ë¨)")
    print("  - app/core/model_paths.py (ìƒˆë¡œ ìƒì„±)")
    print("  - ai_models/MODELS_USAGE_GUIDE.md (ì‚¬ìš© ê°€ì´ë“œ)")
    
    print("\nğŸš€ ë‹¤ìŒ ë‹¨ê³„:")
    print("  1. FastAPI ì„œë²„ ì‹¤í–‰: cd backend && python app/main.py")
    print("  2. ëª¨ë¸ ìƒíƒœ í™•ì¸: curl http://localhost:8000/api/models/status")
    print("  3. ê°€ìƒ í”¼íŒ… API ê°œë°œ")
    
    print("\nğŸ’¡ ì£¼ìš” ëª¨ë¸:")
    for key, info in detected.items():
        if info.get('priority', 99) <= 3:
            print(f"  - {info['name']}: {info['type']}")

if __name__ == "__main__":
    main()