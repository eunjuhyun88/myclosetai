#!/usr/bin/env python3
"""
ğŸ”¥ ì¦‰ì‹œ ì‘ë™í•˜ëŠ” AI ëª¨ë¸ ìŠ¤ìºë„ˆ - ìˆ˜ì •ëœ ë²„ì „
==============================================

MyCloset AI í”„ë¡œì íŠ¸ êµ¬ì¡°ì— ë§ì¶° ì‹¤ì œ ëª¨ë¸ ìœ„ì¹˜ë¥¼ ì •í™•íˆ ì°¾ìŠµë‹ˆë‹¤.

ì‚¬ìš©ë²•:
    python quick_scanner.py                 # í˜„ì¬ ìœ„ì¹˜ì—ì„œ ìŠ¤ìº”
    python quick_scanner.py --organize      # ìŠ¤ìº” + ì •ë¦¬
    python quick_scanner.py --verbose       # ìƒì„¸ ì¶œë ¥
"""

import os
import sys
import json
import shutil
import time
from pathlib import Path
from typing import Dict, List, Optional, Set
from dataclasses import dataclass
from datetime import datetime
import re
import hashlib

@dataclass
class ModelInfo:
    name: str
    path: str
    size_mb: float
    framework: str
    step_candidate: str
    confidence: float
    is_valid: bool

class QuickModelScanner:
    """ì¦‰ì‹œ ì‘ë™í•˜ëŠ” ëª¨ë¸ ìŠ¤ìºë„ˆ"""
    
    def __init__(self, verbose: bool = True):
        self.verbose = verbose
        self.current_dir = Path.cwd()
        self.found_models = []
        
        # í”„ë¡œì íŠ¸ ë£¨íŠ¸ ìë™ íƒì§€
        self.project_root = self._find_project_root()
        self.ai_models_dir = self._find_ai_models_dir()
        
        print(f"ğŸ” í”„ë¡œì íŠ¸ ë£¨íŠ¸: {self.project_root}")
        print(f"ğŸ¤– AI ëª¨ë¸ ë””ë ‰í† ë¦¬: {self.ai_models_dir}")
        
        # ëª¨ë¸ í™•ì¥ì
        self.model_extensions = {
            '.pth', '.pt', '.bin', '.safetensors', '.ckpt', 
            '.h5', '.pb', '.onnx', '.pkl', '.model'
        }
        
        # MyCloset AI 8ë‹¨ê³„ íŒ¨í„´
        self.step_patterns = {
            'step_01_human_parsing': [
                'human.*pars', 'graphonomy', 'schp', 'atr', 'self.*correction'
            ],
            'step_02_pose_estimation': [
                'pose', 'openpose', 'dwpose', 'keypoint'
            ],
            'step_03_cloth_segmentation': [
                'cloth.*seg', 'u2net', 'sam', 'segment'
            ],
            'step_04_geometric_matching': [
                'geometric', 'gmm', 'matching', 'tps'
            ],
            'step_05_cloth_warping': [
                'warp', 'tom', 'viton.*warp', 'deformation'
            ],
            'step_06_virtual_fitting': [
                'virtual', 'ootdiff', 'viton', 'hrviton', 'diffusion'
            ],
            'step_07_post_processing': [
                'post.*process', 'esrgan', 'super.*resolution'
            ],
            'step_08_quality_assessment': [
                'clip', 'quality', 'assessment', 'metric'
            ]
        }
    
    def _find_project_root(self) -> Path:
        """í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì°¾ê¸°"""
        current = self.current_dir
        
        # í˜„ì¬ ë””ë ‰í† ë¦¬ê°€ mycloset-aiì¸ ê²½ìš°
        if current.name == 'mycloset-ai':
            return current
        
        # ë¶€ëª¨ ë””ë ‰í† ë¦¬ë“¤ ê²€ì‚¬
        for parent in current.parents:
            if parent.name == 'mycloset-ai':
                return parent
            # backend ë˜ëŠ” frontend ë””ë ‰í† ë¦¬ê°€ ìˆëŠ” ê³³ ì°¾ê¸°
            if (parent / 'backend').exists() and (parent / 'frontend').exists():
                return parent
        
        # ê¸°ë³¸ê°’ìœ¼ë¡œ í˜„ì¬ ë””ë ‰í† ë¦¬
        return current
    
    def _find_ai_models_dir(self) -> Optional[Path]:
        """AI ëª¨ë¸ ë””ë ‰í† ë¦¬ ì°¾ê¸°"""
        candidates = [
            self.project_root / "backend" / "ai_models",
            self.project_root / "ai_models", 
            self.current_dir / "backend" / "ai_models",
            self.current_dir / "ai_models"
        ]
        
        for candidate in candidates:
            if candidate.exists() and candidate.is_dir():
                return candidate
        
        return None
    
    def scan_models(self) -> List[ModelInfo]:
        """ëª¨ë¸ ìŠ¤ìº” ì‹¤í–‰"""
        print("ğŸš€ AI ëª¨ë¸ ìŠ¤ìº” ì‹œì‘...")
        print("=" * 60)
        
        if not self.ai_models_dir:
            print("âŒ AI ëª¨ë¸ ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            self._suggest_locations()
            return []
        
        # 1. ê¸°ë³¸ AI ëª¨ë¸ ë””ë ‰í† ë¦¬ ìŠ¤ìº”
        print(f"ğŸ“ ë©”ì¸ ë””ë ‰í† ë¦¬ ìŠ¤ìº”: {self.ai_models_dir}")
        self._scan_directory(self.ai_models_dir)
        
        # 2. ì¶”ê°€ ìœ„ì¹˜ ìŠ¤ìº”
        additional_paths = [
            self.project_root / "models",
            self.project_root / "checkpoints", 
            Path.home() / "Downloads",
            Path.home() / ".cache" / "huggingface",
            Path.home() / ".cache" / "torch"
        ]
        
        for path in additional_paths:
            if path.exists():
                print(f"ğŸ“‚ ì¶”ê°€ ìŠ¤ìº”: {path}")
                self._scan_directory(path)
        
        # 3. ê²°ê³¼ ì •ë¦¬ ë° ì¶œë ¥
        self._process_results()
        
        return self.found_models
    
    def _scan_directory(self, directory: Path, max_depth: int = 5):
        """ë””ë ‰í† ë¦¬ ìŠ¤ìº”"""
        try:
            if max_depth <= 0:
                return
            
            for item in directory.iterdir():
                if item.is_file() and item.suffix.lower() in self.model_extensions:
                    try:
                        size_mb = item.stat().st_size / (1024 * 1024)
                        if size_mb > 0.1:  # 0.1MB ì´ìƒë§Œ
                            model_info = self._analyze_model(item, size_mb)
                            if model_info:
                                self.found_models.append(model_info)
                                if self.verbose:
                                    print(f"  âœ… {item.name} ({size_mb:.1f}MB)")
                    except Exception as e:
                        if self.verbose:
                            print(f"  âš ï¸ ìŠ¤ìº” ì‹¤íŒ¨ {item.name}: {e}")
                
                elif item.is_dir() and not self._should_skip_directory(item):
                    self._scan_directory(item, max_depth - 1)
                    
        except PermissionError:
            if self.verbose:
                print(f"  âš ï¸ ê¶Œí•œ ì—†ìŒ: {directory}")
        except Exception as e:
            if self.verbose:
                print(f"  âŒ ì˜¤ë¥˜: {directory} - {e}")
    
    def _should_skip_directory(self, directory: Path) -> bool:
        """ê±´ë„ˆë›¸ ë””ë ‰í† ë¦¬ì¸ì§€ í™•ì¸"""
        skip_patterns = {
            '__pycache__', '.git', 'node_modules', '.cache',
            '.DS_Store', 'temp', 'tmp'
        }
        return directory.name in skip_patterns or directory.name.startswith('.')
    
    def _analyze_model(self, file_path: Path, size_mb: float) -> Optional[ModelInfo]:
        """ëª¨ë¸ íŒŒì¼ ë¶„ì„"""
        try:
            # í”„ë ˆì„ì›Œí¬ ë¶„ë¥˜
            framework = self._classify_framework(file_path)
            
            # Step ë¶„ë¥˜
            step_candidate, confidence = self._classify_step(file_path)
            
            # ìœ íš¨ì„± ê²€ì‚¬
            is_valid = self._validate_model(file_path, framework)
            
            return ModelInfo(
                name=file_path.name,
                path=str(file_path.absolute()),
                size_mb=size_mb,
                framework=framework,
                step_candidate=step_candidate,
                confidence=confidence,
                is_valid=is_valid
            )
            
        except Exception as e:
            if self.verbose:
                print(f"    âš ï¸ ë¶„ì„ ì‹¤íŒ¨ {file_path.name}: {e}")
            return None
    
    def _classify_framework(self, file_path: Path) -> str:
        """í”„ë ˆì„ì›Œí¬ ë¶„ë¥˜"""
        ext = file_path.suffix.lower()
        
        if ext in ['.pth', '.pt']:
            return 'pytorch'
        elif ext == '.safetensors':
            return 'safetensors'
        elif ext in ['.pb', '.h5']:
            return 'tensorflow'
        elif ext == '.onnx':
            return 'onnx'
        elif ext == '.bin':
            # ë‚´ìš©ìœ¼ë¡œ íŒë‹¨
            path_str = str(file_path).lower()
            if 'pytorch' in path_str or 'transformers' in path_str:
                return 'pytorch'
            return 'binary'
        else:
            return 'unknown'
    
    def _classify_step(self, file_path: Path) -> tuple:
        """MyCloset AI 8ë‹¨ê³„ ë¶„ë¥˜"""
        path_str = str(file_path).lower()
        name_str = file_path.name.lower()
        
        best_step = "unknown"
        best_confidence = 0.0
        
        for step_name, patterns in self.step_patterns.items():
            confidence = 0.0
            
            for pattern in patterns:
                if re.search(pattern, path_str):
                    confidence = max(confidence, 0.9)
                elif re.search(pattern, name_str):
                    confidence = max(confidence, 0.8)
                elif pattern.replace('.*', '') in path_str:
                    confidence = max(confidence, 0.6)
            
            if confidence > best_confidence:
                best_confidence = confidence
                best_step = step_name
        
        return best_step, best_confidence
    
    def _validate_model(self, file_path: Path, framework: str) -> bool:
        """ëª¨ë¸ ìœ íš¨ì„± ê²€ì‚¬"""
        try:
            if file_path.stat().st_size < 1024:  # 1KB ë¯¸ë§Œ
                return False
            
            # ê°„ë‹¨í•œ í—¤ë” ê²€ì‚¬
            with open(file_path, 'rb') as f:
                header = f.read(100)
            
            if framework == 'pytorch' and (b'PK' in header or b'\x80' in header):
                return True
            elif framework == 'safetensors' and b'{' in header:
                return True
            elif framework == 'tensorflow' and len(header) > 10:
                return True
            else:
                return True
        except:
            return False
    
    def _process_results(self):
        """ê²°ê³¼ ì²˜ë¦¬ ë° ì¶œë ¥"""
        print("\n" + "=" * 80)
        print("ğŸ¯ AI ëª¨ë¸ ìŠ¤ìº” ê²°ê³¼")
        print("=" * 80)
        
        if not self.found_models:
            print("âŒ AI ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            self._suggest_debug_steps()
            return
        
        # í†µê³„
        total_models = len(self.found_models)
        total_size = sum(m.size_mb for m in self.found_models)
        valid_models = [m for m in self.found_models if m.is_valid]
        
        print(f"ğŸ“Š ì´ ë°œê²¬: {total_models}ê°œ ëª¨ë¸")
        print(f"ğŸ’¾ ì´ í¬ê¸°: {total_size:.1f}MB ({total_size/1024:.2f}GB)")
        print(f"âœ… ìœ íš¨í•œ ëª¨ë¸: {len(valid_models)}ê°œ")
        
        # í”„ë ˆì„ì›Œí¬ë³„ ë¶„í¬
        frameworks = {}
        for model in self.found_models:
            fw = model.framework
            frameworks[fw] = frameworks.get(fw, 0) + 1
        
        print(f"\nğŸ”§ í”„ë ˆì„ì›Œí¬ë³„ ë¶„í¬:")
        for fw, count in sorted(frameworks.items(), key=lambda x: x[1], reverse=True):
            fw_size = sum(m.size_mb for m in self.found_models if m.framework == fw)
            print(f"  - {fw}: {count}ê°œ ({fw_size:.1f}MB)")
        
        # Stepë³„ ë¶„í¬ (ì‹ ë¢°ë„ 0.5 ì´ìƒ)
        steps = {}
        for model in self.found_models:
            if model.confidence >= 0.5:
                step = model.step_candidate
                steps[step] = steps.get(step, 0) + 1
        
        if steps:
            print(f"\nğŸ¯ MyCloset AI Stepë³„ ë¶„í¬:")
            step_names = {
                'step_01_human_parsing': '1ï¸âƒ£ Human Parsing',
                'step_02_pose_estimation': '2ï¸âƒ£ Pose Estimation', 
                'step_03_cloth_segmentation': '3ï¸âƒ£ Cloth Segmentation',
                'step_04_geometric_matching': '4ï¸âƒ£ Geometric Matching',
                'step_05_cloth_warping': '5ï¸âƒ£ Cloth Warping',
                'step_06_virtual_fitting': '6ï¸âƒ£ Virtual Fitting',
                'step_07_post_processing': '7ï¸âƒ£ Post Processing',
                'step_08_quality_assessment': '8ï¸âƒ£ Quality Assessment'
            }
            
            for step, count in sorted(steps.items()):
                display_name = step_names.get(step, step)
                step_size = sum(m.size_mb for m in self.found_models 
                              if m.step_candidate == step and m.confidence >= 0.5)
                print(f"  {display_name}: {count}ê°œ ({step_size:.1f}MB)")
        
        # ìƒìœ„ ëª¨ë¸ë“¤
        print(f"\nğŸ† ë°œê²¬ëœ ì£¼ìš” ëª¨ë¸ë“¤:")
        sorted_models = sorted(self.found_models, key=lambda x: x.size_mb, reverse=True)
        
        for i, model in enumerate(sorted_models[:15], 1):
            step_info = ""
            if model.confidence >= 0.5:
                step_num = model.step_candidate.split('_')[1] if '_' in model.step_candidate else '?'
                step_info = f" | ğŸ¯ Step {step_num}"
            
            confidence_icon = "ğŸŸ¢" if model.confidence >= 0.8 else "ğŸŸ¡" if model.confidence >= 0.5 else "ğŸ”´"
            validity_icon = "âœ…" if model.is_valid else "âš ï¸"
            
            print(f"  {i:2d}. {model.name}")
            print(f"      ğŸ“ {model.path}")
            print(f"      ğŸ“Š {model.size_mb:.1f}MB | {model.framework} | "
                  f"{validity_icon} | {confidence_icon} {model.confidence:.2f}{step_info}")
    
    def _suggest_debug_steps(self):
        """ë””ë²„ê·¸ ë‹¨ê³„ ì œì•ˆ"""
        print("\nğŸ” ë””ë²„ê·¸ ë‹¨ê³„:")
        print("1. ì‹¤ì œ AI ëª¨ë¸ ìœ„ì¹˜ í™•ì¸:")
        
        # í˜„ì¬ í”„ë¡œì íŠ¸ êµ¬ì¡° ì¶œë ¥
        if self.ai_models_dir and self.ai_models_dir.exists():
            print(f"   ğŸ“ AI ëª¨ë¸ ë””ë ‰í† ë¦¬ ì¡´ì¬: {self.ai_models_dir}")
            try:
                items = list(self.ai_models_dir.iterdir())
                print(f"   ğŸ“„ ë‚´ìš© ({len(items)}ê°œ):")
                for item in items[:10]:
                    if item.is_dir():
                        try:
                            sub_count = len(list(item.iterdir()))
                            print(f"     ğŸ“ {item.name}/ ({sub_count}ê°œ íŒŒì¼)")
                        except:
                            print(f"     ğŸ“ {item.name}/ (ì ‘ê·¼ ë¶ˆê°€)")
                    else:
                        size_mb = item.stat().st_size / (1024 * 1024)
                        print(f"     ğŸ“„ {item.name} ({size_mb:.1f}MB)")
                
                if len(items) > 10:
                    print(f"     ... ì™¸ {len(items) - 10}ê°œ")
            except Exception as e:
                print(f"   âŒ ë””ë ‰í† ë¦¬ ì½ê¸° ì‹¤íŒ¨: {e}")
        else:
            print(f"   âŒ AI ëª¨ë¸ ë””ë ‰í† ë¦¬ ì—†ìŒ: {self.ai_models_dir}")
        
        print("\n2. ìˆ˜ë™ í™•ì¸ ëª…ë ¹ì–´:")
        print(f"   find {self.project_root} -name '*.pth' -o -name '*.pt' -o -name '*.bin' -o -name '*.safetensors'")
        print(f"   ls -la {self.ai_models_dir}/ 2>/dev/null")
        
        print("\n3. ì˜ˆìƒ ìœ„ì¹˜ë“¤:")
        expected_locations = [
            self.project_root / "backend" / "ai_models",
            self.project_root / "ai_models",
            Path.home() / "Downloads",
            Path.home() / ".cache" / "huggingface"
        ]
        
        for location in expected_locations:
            exists = "âœ…" if location.exists() else "âŒ"
            print(f"   {exists} {location}")
    
    def _suggest_locations(self):
        """ëª¨ë¸ ìœ„ì¹˜ ì œì•ˆ"""
        print("\nğŸ’¡ AI ëª¨ë¸ ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print("\nì˜ˆìƒ ìœ„ì¹˜:")
        print("  - ./ai_models/")
        print("  - ./backend/ai_models/") 
        print("  - ~/Downloads/")
        print("  - ~/.cache/huggingface/")
        
    def generate_model_config(self, output_file: str = "model_scan_result.json"):
        """ëª¨ë¸ ì„¤ì • íŒŒì¼ ìƒì„±"""
        if not self.found_models:
            print("âŒ ì„¤ì • íŒŒì¼ì„ ìƒì„±í•  ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        config_data = {
            "scan_info": {
                "timestamp": datetime.now().isoformat(),
                "project_root": str(self.project_root),
                "ai_models_dir": str(self.ai_models_dir),
                "total_models": len(self.found_models)
            },
            "models": {}
        }
        
        for i, model in enumerate(self.found_models):
            model_key = f"model_{i+1:03d}"
            config_data["models"][model_key] = {
                "name": model.name,
                "path": model.path,
                "size_mb": model.size_mb,
                "framework": model.framework,
                "step_candidate": model.step_candidate,
                "confidence": model.confidence,
                "is_valid": model.is_valid
            }
        
        # JSON íŒŒì¼ ì €ì¥
        output_path = self.project_root / output_file
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(config_data, f, indent=2, ensure_ascii=False)
        
        print(f"\nğŸ’¾ ì„¤ì • íŒŒì¼ ì €ì¥: {output_path}")
        
        # Python ì„¤ì • íŒŒì¼ë„ ìƒì„±
        self._generate_python_config()
    
    def _generate_python_config(self):
        """Python ì„¤ì • íŒŒì¼ ìƒì„±"""
        config_content = f'''#!/usr/bin/env python3
"""
MyCloset AI ëª¨ë¸ ê²½ë¡œ ì„¤ì • - ìë™ ìƒì„±ë¨
ìƒì„± ì‹œê°„: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}
ë°œê²¬ëœ ëª¨ë¸: {len(self.found_models)}ê°œ
"""

from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸
PROJECT_ROOT = Path(__file__).parent.parent
AI_MODELS_ROOT = PROJECT_ROOT / "ai_models"

# ë°œê²¬ëœ ëª¨ë¸ ê²½ë¡œë“¤
SCANNED_MODELS = {{
'''
        
        for i, model in enumerate(self.found_models):
            safe_name = model.name.replace('.', '_').replace('-', '_')
            config_content += f'''    "{safe_name}": {{
        "name": "{model.name}",
        "path": Path("{model.path}"),
        "framework": "{model.framework}",
        "step": "{model.step_candidate}",
        "confidence": {model.confidence:.3f},
        "size_mb": {model.size_mb:.1f}
    }},
'''
        
        config_content += '''}

# Stepë³„ ëª¨ë¸ ë§¤í•‘
STEP_MODELS = {
'''
        
        # Stepë³„ ëª¨ë¸ ê·¸ë£¹í™”
        step_models = {}
        for model in self.found_models:
            if model.confidence >= 0.5:
                step = model.step_candidate
                if step not in step_models:
                    step_models[step] = []
                step_models[step].append(model.name.replace('.', '_').replace('-', '_'))
        
        for step, models in step_models.items():
            config_content += f'    "{step}": {models},\n'
        
        config_content += '''}

def get_model_path(model_name: str) -> Path:
    """ëª¨ë¸ ê²½ë¡œ ë°˜í™˜"""
    for key, info in SCANNED_MODELS.items():
        if model_name in key or model_name in info["name"]:
            return info["path"]
    raise KeyError(f"Model not found: {model_name}")

def get_step_models(step: str) -> list:
    """Stepë³„ ëª¨ë¸ ëª©ë¡"""
    return STEP_MODELS.get(step, [])

def list_available_models() -> dict:
    """ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡"""
    available = {}
    for key, info in SCANNED_MODELS.items():
        if info["path"].exists():
            available[key] = info
    return available

if __name__ == "__main__":
    print("ğŸ¤– MyCloset AI ëª¨ë¸ ì„¤ì •")
    print("=" * 40)
    available = list_available_models()
    print(f"ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸: {len(available)}ê°œ")
    
    for key, info in available.items():
        print(f"  âœ… {info['name']} ({info['framework']}, {info['size_mb']:.1f}MB)")
'''
        
        config_path = self.project_root / "model_paths_config.py"
        with open(config_path, 'w', encoding='utf-8') as f:
            f.write(config_content)
        
        print(f"ğŸ Python ì„¤ì • íŒŒì¼: {config_path}")

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    import argparse
    
    parser = argparse.ArgumentParser(description="ì¦‰ì‹œ ì‘ë™í•˜ëŠ” AI ëª¨ë¸ ìŠ¤ìºë„ˆ")
    parser.add_argument('--organize', action='store_true', help='ìŠ¤ìº” í›„ ì„¤ì • íŒŒì¼ ìƒì„±')
    parser.add_argument('--verbose', action='store_true', help='ìƒì„¸ ì¶œë ¥')
    parser.add_argument('--output', type=str, default='model_scan_result.json', help='ì¶œë ¥ íŒŒì¼ëª…')
    
    args = parser.parse_args()
    
    try:
        scanner = QuickModelScanner(verbose=args.verbose)
        models = scanner.scan_models()
        
        if args.organize and models:
            scanner.generate_model_config(args.output)
        
        print(f"\nâœ… ìŠ¤ìº” ì™„ë£Œ! ë°œê²¬ëœ ëª¨ë¸: {len(models)}ê°œ")
        return 0 if models else 1
        
    except KeyboardInterrupt:
        print("\nâ¹ï¸ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
        return 1
    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        return 1

if __name__ == "__main__":
    sys.exit(main())