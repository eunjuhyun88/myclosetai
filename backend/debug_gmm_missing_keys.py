#!/usr/bin/env python3
"""
GMM ëª¨ë¸ì˜ ë§¤ì¹­ë˜ì§€ ì•ŠëŠ” í‚¤ë“¤ì„ ë¶„ì„í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸
"""

import torch
import os
from collections import defaultdict

def analyze_gmm_missing_keys():
    """GMM ì²´í¬í¬ì¸íŠ¸ì—ì„œ ë§¤ì¹­ë˜ì§€ ì•ŠëŠ” í‚¤ë“¤ì„ ë¶„ì„"""
    
    checkpoint_path = "ai_models/step_04/gmm.pth"
    
    if not os.path.exists(checkpoint_path):
        print(f"âŒ ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {checkpoint_path}")
        return
    
    print(f"ğŸ” GMM ë§¤ì¹­ë˜ì§€ ì•ŠëŠ” í‚¤ ë¶„ì„: {checkpoint_path}")
    
    try:
        # ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ
        checkpoint = torch.load(checkpoint_path, map_location='cpu')
        
        # state_dict ì¶”ì¶œ
        if 'model' in checkpoint:
            state_dict = checkpoint['model']
        elif 'state_dict' in checkpoint:
            state_dict = checkpoint['state_dict']
        elif isinstance(checkpoint, dict):
            state_dict = checkpoint
        else:
            state_dict = checkpoint
        
        print(f"ğŸ“Š ì´ í‚¤ ìˆ˜: {len(state_dict)}")
        
        # í˜„ì¬ ëª¨ë¸ ì•„í‚¤í…ì²˜ì—ì„œ ìƒì„±ë˜ëŠ” í‚¤ë“¤
        from app.ai_pipeline.utils.model_architectures import GMMModel
        
        model = GMMModel()
        model_state_dict = model.state_dict()
        
        print(f"ğŸ—ï¸ ëª¨ë¸ì—ì„œ ìƒì„±ë˜ëŠ” í‚¤ ìˆ˜: {len(model_state_dict)}")
        
        # ë§¤ì¹­ë˜ì§€ ì•ŠëŠ” í‚¤ë“¤ ì°¾ê¸°
        checkpoint_keys = set(state_dict.keys())
        model_keys = set(model_state_dict.keys())
        
        missing_in_model = checkpoint_keys - model_keys
        extra_in_model = model_keys - checkpoint_keys
        
        print(f"\nâŒ ì²´í¬í¬ì¸íŠ¸ì— ìˆì§€ë§Œ ëª¨ë¸ì— ì—†ëŠ” í‚¤ë“¤ ({len(missing_in_model)}ê°œ):")
        for key in sorted(missing_in_model):
            print(f"   - {key}")
        
        print(f"\nâ• ëª¨ë¸ì— ìˆì§€ë§Œ ì²´í¬í¬ì¸íŠ¸ì— ì—†ëŠ” í‚¤ë“¤ ({len(extra_in_model)}ê°œ):")
        for key in sorted(extra_in_model):
            print(f"   - {key}")
        
        # ë§¤ì¹­ë¥  ê³„ì‚°
        matched_keys = checkpoint_keys & model_keys
        total_keys = len(checkpoint_keys)
        match_rate = len(matched_keys) / total_keys * 100
        
        print(f"\nğŸ“Š ë§¤ì¹­ í†µê³„:")
        print(f"   - ì´ í‚¤ ìˆ˜: {total_keys}")
        print(f"   - ë§¤ì¹­ëœ í‚¤ ìˆ˜: {len(matched_keys)}")
        print(f"   - ë§¤ì¹­ë˜ì§€ ì•Šì€ í‚¤ ìˆ˜: {len(missing_in_model)}")
        print(f"   - ë§¤ì¹­ë¥ : {match_rate:.1f}%")
        
        # ë§¤ì¹­ë˜ì§€ ì•ŠëŠ” í‚¤ë“¤ì˜ íŒ¨í„´ ë¶„ì„
        if missing_in_model:
            print(f"\nğŸ” ë§¤ì¹­ë˜ì§€ ì•ŠëŠ” í‚¤ íŒ¨í„´ ë¶„ì„:")
            pattern_count = defaultdict(int)
            for key in missing_in_model:
                parts = key.split('.')
                if len(parts) >= 2:
                    pattern = f"{parts[0]}.{parts[1]}"
                    pattern_count[pattern] += 1
            
            for pattern, count in sorted(pattern_count.items(), key=lambda x: x[1], reverse=True):
                print(f"   - {pattern}.* : {count}ê°œ")
        
    except Exception as e:
        print(f"âŒ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

if __name__ == "__main__":
    analyze_gmm_missing_keys()
