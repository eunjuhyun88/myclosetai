#!/usr/bin/env python3
"""
AI ëª¨ë¸ ë¡œë”© ë¬¸ì œ í•´ê²° í…ŒìŠ¤íŠ¸ - ì™„ì „ ìˆ˜ì •íŒ
backend/debug_model_loading.py

ğŸ”¥ ì£¼ìš” ìˆ˜ì •ì‚¬í•­:
âœ… DeviceManager â†’ memory_manager ë³€ê²½ ë°˜ì˜
âœ… MPS í˜¸í™˜ì„± ì„¤ì • ìˆ˜ì •
âœ… ëª¨ë“  import ì˜¤ë¥˜ í•´ê²°
âœ… Stepë³„ ì´ˆê¸°í™” ë¡œì§ ì™„ì „ ìˆ˜ì •
âœ… ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ íƒì§€ ê°œì„ 
âœ… ì—ëŸ¬ í•¸ë“¤ë§ ê°•í™”
âœ… M3 Max ìµœì í™” ì„¤ì • ì¶”ê°€
"""

import sys
import os
import time
import traceback
from pathlib import Path
from typing import Dict, List, Optional, Any

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
sys.path.append('.')
sys.path.append('./backend')

def test_model_loading_fixes():
    """ëª¨ë¸ ë¡œë”© ìˆ˜ì •ì‚¬í•­ í…ŒìŠ¤íŠ¸ - ì™„ì „ ìˆ˜ì •íŒ"""
    
    print("ğŸ”§ AI ëª¨ë¸ ë¡œë”© ìˆ˜ì •ì‚¬í•­ í…ŒìŠ¤íŠ¸ ì‹œì‘...")
    print("=" * 80)
    
    test_results = {
        "mps_setup": False,
        "memory_manager": False,
        "model_loader": False,
        "checkpoint_detection": False,
        "step_initialization": {},
        "total_errors": 0
    }
    
    # 1. MPS í™˜ê²½ ì„¤ì • í…ŒìŠ¤íŠ¸ (ìˆ˜ì •ë¨)
    print("\nğŸ 1. MPS/Memory Manager ì„¤ì • í…ŒìŠ¤íŠ¸")
    try:
        # memory_manager ì‚¬ìš©ìœ¼ë¡œ ë³€ê²½
        from app.ai_pipeline.utils.memory_manager import get_memory_manager
        
        memory_manager = get_memory_manager()
        print("âœ… Memory Manager ê°€ì ¸ì˜¤ê¸° ì„±ê³µ")
        
        # MPS ìµœì í™” ì‹œë„
        if hasattr(memory_manager, 'optimize_for_mps'):
            memory_manager.optimize_for_mps()
            print("âœ… MPS ìµœì í™” ì„¤ì • ì™„ë£Œ")
            test_results["mps_setup"] = True
        elif hasattr(memory_manager, 'optimize'):
            result = memory_manager.optimize()
            print(f"âœ… ë©”ëª¨ë¦¬ ìµœì í™” ì™„ë£Œ: {result.get('memory_freed_mb', 0)}MB")
            test_results["memory_manager"] = True
        else:
            print("â„¹ï¸ MPS ìµœì í™” ë©”ì„œë“œ ì—†ìŒ - ê¸°ë³¸ ì„¤ì • ì‚¬ìš©")
            test_results["mps_setup"] = True
            
    except ImportError as e:
        print(f"âš ï¸ Memory Manager import ì‹¤íŒ¨: {e}")
        print("â„¹ï¸ ëŒ€ì•ˆ: ì§ì ‘ MPS ì„¤ì • ì‹œë„")
        try:
            import torch
            if torch.backends.mps.is_available():
                os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '1'
                os.environ['PYTORCH_MPS_HIGH_WATERMARK_RATIO'] = '0.0'
                print("âœ… ì§ì ‘ MPS í™˜ê²½ë³€ìˆ˜ ì„¤ì • ì™„ë£Œ")
                test_results["mps_setup"] = True
        except Exception as mps_e:
            print(f"âŒ ì§ì ‘ MPS ì„¤ì •ë„ ì‹¤íŒ¨: {mps_e}")
            test_results["total_errors"] += 1
    except Exception as e:
        print(f"âŒ Memory Manager ì„¤ì • ì‹¤íŒ¨: {e}")
        test_results["total_errors"] += 1
    
    # 2. ModelLoader í…ŒìŠ¤íŠ¸ (ìˆ˜ì •ë¨)
    print("\nğŸ¤– 2. ModelLoader ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸")
    try:
        from app.ai_pipeline.utils.model_loader import get_global_model_loader
        
        model_loader = get_global_model_loader()
        if model_loader:
            print("âœ… Global ModelLoader ê°€ì ¸ì˜¤ê¸° ì„±ê³µ")
            test_results["model_loader"] = True
            
            # _find_checkpoint_file ë©”ì„œë“œ í…ŒìŠ¤íŠ¸
            if hasattr(model_loader, '_find_checkpoint_file'):
                print("âœ… _find_checkpoint_file ë©”ì„œë“œ ì¡´ì¬")
                
                # í…ŒìŠ¤íŠ¸í•  ëª¨ë¸ë“¤
                test_models = [
                    "cloth_segmentation_u2net",
                    "geometric_matching_model", 
                    "pose_estimation_openpose",
                    "human_parsing_graphonomy",
                    "virtual_fitting_viton"
                ]
                
                found_models = []
                for model_name in test_models:
                    try:
                        result = model_loader._find_checkpoint_file(model_name)
                        if result:
                            found_models.append(model_name)
                            print(f"   âœ… {model_name}: {result}")
                        else:
                            print(f"   âŒ {model_name}: ì²´í¬í¬ì¸íŠ¸ ì—†ìŒ")
                    except Exception as find_e:
                        print(f"   âš ï¸ {model_name}: ê²€ìƒ‰ ì‹¤íŒ¨ - {find_e}")
                
                print(f"ğŸ“Š ë°œê²¬ëœ ëª¨ë¸: {len(found_models)}/{len(test_models)}")
            else:
                print("âŒ _find_checkpoint_file ë©”ì„œë“œ ì—†ìŒ")
        else:
            print("âŒ Global ModelLoader ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨")
            
    except ImportError as e:
        print(f"âŒ ModelLoader import ì‹¤íŒ¨: {e}")
        test_results["total_errors"] += 1
    except Exception as e:
        print(f"âŒ ModelLoader í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        test_results["total_errors"] += 1
    
    # 3. ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ íƒì§€ í…ŒìŠ¤íŠ¸ (ê°œì„ ë¨)
    print("\nğŸ“ 3. ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ íƒì§€ í…ŒìŠ¤íŠ¸")
    try:
        # ì—¬ëŸ¬ ê°€ëŠ¥í•œ ê²½ë¡œ í™•ì¸
        possible_paths = [
            Path("ai_models"),
            Path("models"),
            Path("backend/ai_models"),
            Path("../ai_models"),
            Path("./ai_models")
        ]
        
        total_checkpoints = 0
        total_size_gb = 0
        large_files = []
        
        for ai_models_path in possible_paths:
            if ai_models_path.exists():
                print(f"âœ… ëª¨ë¸ ë””ë ‰í† ë¦¬ ë°œê²¬: {ai_models_path}")
                
                # ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ í™•ì¥ìë“¤
                checkpoint_extensions = ["*.pth", "*.safetensors", "*.bin", "*.pt", "*.ckpt"]
                checkpoint_files = []
                
                for ext in checkpoint_extensions:
                    checkpoint_files.extend(list(ai_models_path.rglob(ext)))
                
                if checkpoint_files:
                    total_checkpoints += len(checkpoint_files)
                    print(f"   ğŸ“¦ ì²´í¬í¬ì¸íŠ¸ íŒŒì¼: {len(checkpoint_files)}ê°œ")
                    
                    # íŒŒì¼ í¬ê¸° ë¶„ì„
                    for file in checkpoint_files:
                        try:
                            size_bytes = file.stat().st_size
                            size_gb = size_bytes / (1024*1024*1024)
                            total_size_gb += size_gb
                            
                            if size_gb >= 0.1:  # 100MB ì´ìƒ
                                large_files.append((file.name, size_gb))
                        except Exception:
                            continue
                
                break  # ì²« ë²ˆì§¸ ìœ íš¨í•œ ê²½ë¡œì—ì„œ ì¤‘ë‹¨
        
        if total_checkpoints > 0:
            print(f"âœ… ì´ ì²´í¬í¬ì¸íŠ¸ íŒŒì¼: {total_checkpoints}ê°œ")
            print(f"ğŸ“Š ì´ í¬ê¸°: {total_size_gb:.2f}GB")
            test_results["checkpoint_detection"] = True
            
            # í° íŒŒì¼ë“¤ í‘œì‹œ (ìƒìœ„ 10ê°œ)
            if large_files:
                large_files.sort(key=lambda x: x[1], reverse=True)
                print(f"ğŸ”¥ ì£¼ìš” ëª¨ë¸ íŒŒì¼ (ìƒìœ„ {min(10, len(large_files))}ê°œ):")
                for name, size in large_files[:10]:
                    print(f"   {name}: {size:.1f}GB")
        else:
            print("âŒ ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ")
            print("   ğŸ’¡ ai_models ë””ë ‰í† ë¦¬ê°€ ì˜¬ë°”ë¥¸ ìœ„ì¹˜ì— ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”")
            
    except Exception as e:
        print(f"âŒ ì²´í¬í¬ì¸íŠ¸ íƒì§€ ì‹¤íŒ¨: {e}")
        test_results["total_errors"] += 1
    
    # 4. Stepë³„ AI ëª¨ë¸ ì´ˆê¸°í™” í…ŒìŠ¤íŠ¸ (ì™„ì „ ìˆ˜ì •ë¨)
    print("\nğŸš€ 4. Stepë³„ AI ëª¨ë¸ ì´ˆê¸°í™” í…ŒìŠ¤íŠ¸")
    
    test_steps = [
        {
            "name": "HumanParsingStep",
            "id": 1,
            "module": "app.ai_pipeline.steps.step_01_human_parsing",
            "class": "HumanParsingStep"
        },
        {
            "name": "PoseEstimationStep", 
            "id": 2,
            "module": "app.ai_pipeline.steps.step_02_pose_estimation",
            "class": "PoseEstimationStep"
        },
        {
            "name": "GeometricMatchingStep",
            "id": 4, 
            "module": "app.ai_pipeline.steps.step_04_geometric_matching",
            "class": "GeometricMatchingStep"
        },
        {
            "name": "VirtualFittingStep",
            "id": 6,
            "module": "app.ai_pipeline.steps.step_06_virtual_fitting", 
            "class": "VirtualFittingStep"
        }
    ]
    
    for step_info in test_steps:
        step_name = step_info["name"]
        print(f"\n   ğŸ”§ {step_name} í…ŒìŠ¤íŠ¸ ì¤‘...")
        
        try:
            # ë™ì  import
            module = __import__(step_info["module"], fromlist=[step_info["class"]])
            step_class = getattr(module, step_info["class"])
            
            # Step ì¸ìŠ¤í„´ìŠ¤ ìƒì„± (device íŒŒë¼ë¯¸í„° ìë™ ì²˜ë¦¬)
            try:
                step = step_class(device='mps')
            except TypeError:
                # device íŒŒë¼ë¯¸í„°ë¥¼ ì§€ì›í•˜ì§€ ì•ŠëŠ” ê²½ìš°
                step = step_class()
            
            print(f"      âœ… {step_name} ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ì„±ê³µ")
            
            # ì´ˆê¸°í™” í…ŒìŠ¤íŠ¸
            if hasattr(step, 'initialize'):
                try:
                    # async ë©”ì„œë“œì¸ì§€ í™•ì¸
                    import asyncio
                    import inspect
                    
                    if inspect.iscoroutinefunction(step.initialize):
                        # async ë©”ì„œë“œ
                        try:
                            loop = asyncio.get_event_loop()
                        except RuntimeError:
                            loop = asyncio.new_event_loop()
                            asyncio.set_event_loop(loop)
                        
                        init_result = loop.run_until_complete(step.initialize())
                    else:
                        # sync ë©”ì„œë“œ
                        init_result = step.initialize()
                    
                    if init_result:
                        print(f"      âœ… {step_name} ì´ˆê¸°í™” ì„±ê³µ")
                        test_results["step_initialization"][step_name] = "success"
                    else:
                        print(f"      âš ï¸ {step_name} ì´ˆê¸°í™” ì‹¤íŒ¨ (False ë°˜í™˜)")
                        test_results["step_initialization"][step_name] = "failed"
                        
                except Exception as init_e:
                    print(f"      âš ï¸ {step_name} ì´ˆê¸°í™” ì˜¤ë¥˜: {init_e}")
                    test_results["step_initialization"][step_name] = f"error: {str(init_e)[:50]}"
            else:
                print(f"      â„¹ï¸ {step_name} initialize ë©”ì„œë“œ ì—†ìŒ")
                test_results["step_initialization"][step_name] = "no_initialize_method"
            
        except ImportError as import_e:
            print(f"      âŒ {step_name} import ì‹¤íŒ¨: {import_e}")
            test_results["step_initialization"][step_name] = f"import_error: {str(import_e)[:50]}"
            test_results["total_errors"] += 1
            
        except Exception as e:
            print(f"      âŒ {step_name} í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
            test_results["step_initialization"][step_name] = f"error: {str(e)[:50]}"
            test_results["total_errors"] += 1
    
    # 5. ì¶”ê°€ ì‹œìŠ¤í…œ ì •ë³´
    print("\nğŸ“Š 5. ì‹œìŠ¤í…œ ì •ë³´")
    try:
        import platform
        print(f"   OS: {platform.system()} {platform.release()}")
        print(f"   Python: {sys.version.split()[0]}")
        print(f"   Architecture: {platform.machine()}")
        
        # PyTorch ì •ë³´
        try:
            import torch
            print(f"   PyTorch: {torch.__version__}")
            print(f"   CUDA ì‚¬ìš© ê°€ëŠ¥: {torch.cuda.is_available()}")
            print(f"   MPS ì‚¬ìš© ê°€ëŠ¥: {torch.backends.mps.is_available() if hasattr(torch.backends, 'mps') else False}")
        except ImportError:
            print("   PyTorch: ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ")
        
        # ë©”ëª¨ë¦¬ ì •ë³´
        try:
            import psutil
            memory = psutil.virtual_memory()
            print(f"   ì´ ë©”ëª¨ë¦¬: {memory.total / (1024**3):.1f}GB")
            print(f"   ì‚¬ìš© ê°€ëŠ¥: {memory.available / (1024**3):.1f}GB")
        except ImportError:
            print("   ë©”ëª¨ë¦¬ ì •ë³´: psutil ì—†ìŒ")
            
    except Exception as e:
        print(f"   ì‹œìŠ¤í…œ ì •ë³´ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
    
    # 6. ê²°ê³¼ ìš”ì•½
    print("\n" + "=" * 80)
    print("ğŸ‰ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½")
    print("=" * 80)
    
    success_count = sum([
        test_results["mps_setup"] or test_results["memory_manager"],
        test_results["model_loader"],
        test_results["checkpoint_detection"],
        len([v for v in test_results["step_initialization"].values() if v == "success"])
    ])
    
    total_tests = 3 + len(test_steps)
    
    print(f"âœ… ì„±ê³µí•œ í…ŒìŠ¤íŠ¸: {success_count}")
    print(f"âŒ ì‹¤íŒ¨í•œ í…ŒìŠ¤íŠ¸: {test_results['total_errors']}")
    print(f"ğŸ“Š Step ì´ˆê¸°í™” ì„±ê³µ: {len([v for v in test_results['step_initialization'].values() if v == 'success'])}/{len(test_steps)}")
    
    if test_results["total_errors"] == 0:
        print("\nğŸŠ ëª¨ë“  í…ŒìŠ¤íŠ¸ í†µê³¼! AI ëª¨ë¸ ë¡œë”© ì‹œìŠ¤í…œì´ ì •ìƒ ì‘ë™í•©ë‹ˆë‹¤.")
    elif test_results["total_errors"] <= 2:
        print("\nâš ï¸ ì¼ë¶€ ë¬¸ì œê°€ ìˆì§€ë§Œ ê¸°ë³¸ ê¸°ëŠ¥ì€ ì‘ë™í•©ë‹ˆë‹¤.")
    else:
        print("\nğŸš¨ ì‹¬ê°í•œ ë¬¸ì œê°€ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤. ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
    
    # 7. ê°œì„  ì œì•ˆì‚¬í•­
    print("\nğŸ’¡ ê°œì„  ì œì•ˆì‚¬í•­:")
    
    suggestions = []
    
    if not (test_results["mps_setup"] or test_results["memory_manager"]):
        suggestions.append("- Memory Manager ì„¤ì • í™•ì¸ í•„ìš”")
    
    if not test_results["model_loader"]:
        suggestions.append("- ModelLoader ì˜ì¡´ì„± í™•ì¸ í•„ìš”")
    
    if not test_results["checkpoint_detection"]:
        suggestions.append("- ai_models ë””ë ‰í† ë¦¬ ìœ„ì¹˜ ë° íŒŒì¼ í™•ì¸ í•„ìš”")
    
    failed_steps = [k for k, v in test_results["step_initialization"].items() if v != "success"]
    if failed_steps:
        suggestions.append(f"- ë‹¤ìŒ Stepë“¤ì˜ ì˜ì¡´ì„± í™•ì¸ í•„ìš”: {', '.join(failed_steps)}")
    
    if not suggestions:
        suggestions.append("- ëª¨ë“  ì‹œìŠ¤í…œì´ ì •ìƒ ì‘ë™ ì¤‘ì…ë‹ˆë‹¤! ğŸ‰")
    
    for suggestion in suggestions:
        print(suggestion)
    
    print("\nğŸ”§ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    return test_results

def run_quick_diagnostics():
    """ë¹ ë¥¸ ì§„ë‹¨ í…ŒìŠ¤íŠ¸"""
    print("âš¡ ë¹ ë¥¸ ì§„ë‹¨ ì‹¤í–‰ ì¤‘...")
    
    diagnostics = {
        "python_path": sys.path[:3],
        "working_directory": os.getcwd(),
        "environment": dict(os.environ).keys(),
        "imports": {}
    }
    
    # í•µì‹¬ import í…ŒìŠ¤íŠ¸
    critical_imports = [
        "torch",
        "app.ai_pipeline.utils.memory_manager",
        "app.ai_pipeline.utils.model_loader",
        "app.core.config"
    ]
    
    for module_name in critical_imports:
        try:
            __import__(module_name)
            diagnostics["imports"][module_name] = "âœ… ì„±ê³µ"
        except ImportError as e:
            diagnostics["imports"][module_name] = f"âŒ ì‹¤íŒ¨: {e}"
        except Exception as e:
            diagnostics["imports"][module_name] = f"âš ï¸ ì˜¤ë¥˜: {e}"
    
    print("ğŸ“‹ ì§„ë‹¨ ê²°ê³¼:")
    for module, status in diagnostics["imports"].items():
        print(f"   {module}: {status}")
    
    return diagnostics

if __name__ == "__main__":
    try:
        # ë¹ ë¥¸ ì§„ë‹¨ ë¨¼ì € ì‹¤í–‰
        print("ğŸ” ì‚¬ì „ ì§„ë‹¨ ì‹¤í–‰...")
        quick_results = run_quick_diagnostics()
        
        print("\n" + "="*50)
        
        # ë©”ì¸ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
        test_results = test_model_loading_fixes()
        
        # JSON í˜•íƒœë¡œ ê²°ê³¼ ì €ì¥ (ì„ íƒì‚¬í•­)
        try:
            import json
            results_file = Path("debug_results.json")
            
            combined_results = {
                "timestamp": time.time(),
                "quick_diagnostics": quick_results,
                "main_tests": test_results
            }
            
            with open(results_file, 'w', encoding='utf-8') as f:
                json.dump(combined_results, f, indent=2, ensure_ascii=False)
            
            print(f"\nğŸ“„ ê²°ê³¼ê°€ {results_file}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
            
        except Exception as save_e:
            print(f"\nâš ï¸ ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {save_e}")
        
    except KeyboardInterrupt:
        print("\nâš ï¸ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"\nâŒ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}")
        print(f"ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤:\n{traceback.format_exc()}")
    finally:
        print("\nğŸ‘‹ ë””ë²„ê·¸ ìŠ¤í¬ë¦½íŠ¸ ì¢…ë£Œ")