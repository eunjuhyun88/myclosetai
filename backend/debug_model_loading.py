#!/usr/bin/env python3
"""
ğŸ” ëª¨ë¸ ë¡œë”© ë””ë²„ê¹… ìŠ¤í¬ë¦½íŠ¸
ì™œ ê°€ì¤‘ì¹˜ ë¡œë”©ì´ ë¶€ë¶„ì ìœ¼ë¡œë§Œ ë˜ëŠ”ì§€ ë¶„ì„
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

def debug_model_loading():
    """ëª¨ë¸ ë¡œë”© ë””ë²„ê¹…"""
    print("ğŸ” ëª¨ë¸ ë¡œë”© ë””ë²„ê¹… ì‹œì‘...")
    
    try:
        from app.ai_pipeline.utils.model_loader import (
            ModelLoader, 
            load_model_for_step,
            CheckpointAnalyzer,
            DynamicModelCreator
        )
        
        # 1. ì‹¤ì œ ëª¨ë¸ íŒŒì¼ ê²½ë¡œ í™•ì¸
        print("\n1ï¸âƒ£ ì‹¤ì œ ëª¨ë¸ íŒŒì¼ ê²½ë¡œ í™•ì¸...")
        
        model_paths = {
            'human_parsing': 'ai_models/step_01_human_parsing/graphonomy.pth',
            'pose_estimation': 'ai_models/step_02_pose_estimation/hrnet_w48_coco_384x288.pth',
            'cloth_segmentation': 'ai_models/step_03/sam.pth'
        }
        
        for step, path in model_paths.items():
            if os.path.exists(path):
                size = os.path.getsize(path) / (1024 * 1024)  # MB
                print(f"   âœ… {step}: {path} ({size:.1f} MB)")
            else:
                print(f"   âŒ {step}: {path} (íŒŒì¼ ì—†ìŒ)")
        
        # 2. ì²´í¬í¬ì¸íŠ¸ ë¶„ì„ í…ŒìŠ¤íŠ¸
        print("\n2ï¸âƒ£ ì²´í¬í¬ì¸íŠ¸ ë¶„ì„ í…ŒìŠ¤íŠ¸...")
        
        analyzer = CheckpointAnalyzer()
        
        for step, path in model_paths.items():
            if os.path.exists(path):
                print(f"\n   ğŸ” {step} ì²´í¬í¬ì¸íŠ¸ ë¶„ì„...")
                try:
                    analysis = analyzer.analyze_checkpoint(path)
                    print(f"      âœ… ë¶„ì„ ì„±ê³µ: {analysis.get('architecture_type', 'unknown')}")
                    print(f"      ğŸ“Š íŒŒë¼ë¯¸í„° ìˆ˜: {analysis.get('total_params', 0):,}")
                    print(f"      ğŸ—ï¸ ì•„í‚¤í…ì²˜: {analysis.get('architecture_type', 'unknown')}")
                    print(f"      ğŸ“¥ ì…ë ¥ ì±„ë„: {analysis.get('input_channels', 0)}")
                    print(f"      ğŸ¯ í´ë˜ìŠ¤ ìˆ˜: {analysis.get('num_classes', 0)}")
                except Exception as e:
                    print(f"      âŒ ë¶„ì„ ì‹¤íŒ¨: {e}")
        
        # 3. ë™ì  ëª¨ë¸ ìƒì„± í…ŒìŠ¤íŠ¸
        print("\n3ï¸âƒ£ ë™ì  ëª¨ë¸ ìƒì„± í…ŒìŠ¤íŠ¸...")
        
        creator = DynamicModelCreator()
        
        for step, path in model_paths.items():
            if os.path.exists(path):
                print(f"\n   ğŸ”§ {step} ë™ì  ëª¨ë¸ ìƒì„±...")
                try:
                    model = creator.create_model_from_checkpoint(path, step)
                    if model:
                        param_count = sum(p.numel() for p in model.parameters())
                        print(f"      âœ… ëª¨ë¸ ìƒì„± ì„±ê³µ: {param_count:,} íŒŒë¼ë¯¸í„°")
                    else:
                        print(f"      âŒ ëª¨ë¸ ìƒì„± ì‹¤íŒ¨")
                except Exception as e:
                    print(f"      âŒ ëª¨ë¸ ìƒì„± ì˜¤ë¥˜: {e}")
        
        # 4. í‚¤ ë§¤í•‘ ìƒì„¸ ë¶„ì„
        print("\n4ï¸âƒ£ í‚¤ ë§¤í•‘ ìƒì„¸ ë¶„ì„...")
        
        import torch
        
        for step, path in model_paths.items():
            if os.path.exists(path):
                print(f"\n   ğŸ”‘ {step} í‚¤ ë§¤í•‘ ë¶„ì„...")
                try:
                    # ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ
                    checkpoint = torch.load(path, map_location='cpu')
                    
                    if 'state_dict' in checkpoint:
                        state_dict = checkpoint['state_dict']
                    elif 'model' in checkpoint:
                        state_dict = checkpoint['model']
                    else:
                        state_dict = checkpoint
                    
                    print(f"      ğŸ“Š ì²´í¬í¬ì¸íŠ¸ í‚¤ ìˆ˜: {len(state_dict)}")
                    
                    # í‚¤ íŒ¨í„´ ë¶„ì„
                    key_patterns = {}
                    for key in state_dict.keys():
                        parts = key.split('.')
                        if len(parts) > 0:
                            prefix = parts[0]
                            key_patterns[prefix] = key_patterns.get(prefix, 0) + 1
                    
                    print(f"      ğŸ·ï¸ ì£¼ìš” í‚¤ íŒ¨í„´:")
                    for pattern, count in sorted(key_patterns.items(), key=lambda x: x[1], reverse=True)[:5]:
                        print(f"         - {pattern}: {count}ê°œ")
                    
                    # í…ì„œ í¬ê¸° ë¶„ì„
                    tensor_sizes = {}
                    for key, tensor in state_dict.items():
                        if hasattr(tensor, 'shape'):
                            size_str = 'x'.join(map(str, tensor.shape))
                            tensor_sizes[size_str] = tensor_sizes.get(size_str, 0) + 1
                    
                    print(f"      ğŸ“ ì£¼ìš” í…ì„œ í¬ê¸°:")
                    for size, count in sorted(tensor_sizes.items(), key=lambda x: x[1], reverse=True)[:5]:
                        print(f"         - {size}: {count}ê°œ")
                        
                except Exception as e:
                    print(f"      âŒ í‚¤ ë§¤í•‘ ë¶„ì„ ì˜¤ë¥˜: {e}")
        
        # 5. ModelLoader ì§ì ‘ í…ŒìŠ¤íŠ¸
        print("\n5ï¸âƒ£ ModelLoader ì§ì ‘ í…ŒìŠ¤íŠ¸...")
        
        loader = ModelLoader()
        
        for step in ['human_parsing', 'pose_estimation', 'cloth_segmentation']:
            print(f"\n   ğŸš€ {step} ModelLoader í…ŒìŠ¤íŠ¸...")
            try:
                model = loader.load_model_for_step(step)
                if model:
                    param_count = sum(p.numel() for p in model.parameters())
                    print(f"      âœ… ë¡œë”© ì„±ê³µ: {param_count:,} íŒŒë¼ë¯¸í„°")
                else:
                    print(f"      âŒ ë¡œë”© ì‹¤íŒ¨")
            except Exception as e:
                print(f"      âŒ ë¡œë”© ì˜¤ë¥˜: {e}")
        
        print("\nğŸ‰ ëª¨ë¸ ë¡œë”© ë””ë²„ê¹… ì™„ë£Œ!")
        
    except Exception as e:
        print(f"âŒ ë””ë²„ê¹… ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    debug_model_loading()