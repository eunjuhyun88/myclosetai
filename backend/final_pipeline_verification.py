#!/usr/bin/env python3
"""
ìµœì¢… íŒŒì´í”„ë¼ì¸ ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸
- ì‘ë™í•˜ëŠ” ëª¨ë¸ë“¤ë§Œ í…ŒìŠ¤íŠ¸
- ì‹¤ì œ ì¶”ë¡  í…ŒìŠ¤íŠ¸
"""
import sys
import logging
from pathlib import Path
import torch
from PIL import Image
import numpy as np

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def create_test_image():
    """í…ŒìŠ¤íŠ¸ìš© ì´ë¯¸ì§€ ìƒì„±"""
    # 512x512 RGB ì´ë¯¸ì§€
    image_array = np.random.randint(0, 255, (512, 512, 3), dtype=np.uint8)
    return Image.fromarray(image_array)

def test_working_pipeline():
    """ì‘ë™í•˜ëŠ” íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸"""
    print("ğŸš€ ìµœì¢… íŒŒì´í”„ë¼ì¸ ê²€ì¦")
    print("=" * 40)
    
    test_image = create_test_image()
    results = {}
    
    # 1. Segformer ì¸ì²´ íŒŒì‹± í…ŒìŠ¤íŠ¸
    try:
        print("\n1ï¸âƒ£ ì¸ì²´ íŒŒì‹± í…ŒìŠ¤íŠ¸...")
        from transformers import SegformerImageProcessor, SegformerForSemanticSegmentation
        
        model_path = "ai_models/checkpoints/step_01_human_parsing/segformer_b2_clothes"
        processor = SegformerImageProcessor.from_pretrained(model_path)
        model = SegformerForSemanticSegmentation.from_pretrained(model_path)
        
        inputs = processor(images=test_image, return_tensors="pt")
        with torch.no_grad():
            outputs = model(**inputs)
            parsing_result = outputs.logits
        
        logger.info(f"âœ… ì¸ì²´ íŒŒì‹± ì„±ê³µ: {parsing_result.shape}")
        results['human_parsing'] = True
        
    except Exception as e:
        logger.error(f"âŒ ì¸ì²´ íŒŒì‹± ì‹¤íŒ¨: {e}")
        results['human_parsing'] = False
    
    # 2. UÂ²-Net ONNX ë°°ê²½ ì œê±° í…ŒìŠ¤íŠ¸  
    try:
        print("\n2ï¸âƒ£ ë°°ê²½ ì œê±° í…ŒìŠ¤íŠ¸...")
        import onnxruntime as ort
        
        model_path = "ai_models/checkpoints/step_03_cloth_segmentation/u2net.onnx"
        session = ort.InferenceSession(model_path)
        
        # ë”ë¯¸ ì…ë ¥ìœ¼ë¡œ í…ŒìŠ¤íŠ¸
        input_name = session.get_inputs()[0].name
        dummy_input = np.random.randn(1, 3, 320, 320).astype(np.float32)
        
        outputs = session.run(None, {input_name: dummy_input})
        
        logger.info(f"âœ… ë°°ê²½ ì œê±° ì„±ê³µ: {len(outputs)} ì¶œë ¥")
        results['background_removal'] = True
        
    except Exception as e:
        logger.error(f"âŒ ë°°ê²½ ì œê±° ì‹¤íŒ¨: {e}")
        results['background_removal'] = False
    
    # 3. MediaPipe í¬ì¦ˆ ì¶”ì • (íŒŒì¼ í™•ì¸ë§Œ)
    try:
        print("\n3ï¸âƒ£ í¬ì¦ˆ ì¶”ì • í…ŒìŠ¤íŠ¸...")
        model_path = Path("ai_models/checkpoints/step_02_pose_estimation/pose_landmarker.task")
        
        if model_path.exists():
            size_mb = model_path.stat().st_size / (1024**2)
            logger.info(f"âœ… í¬ì¦ˆ ëª¨ë¸ ì¤€ë¹„ë¨: {size_mb:.1f}MB")
            results['pose_estimation'] = True
        else:
            raise FileNotFoundError("í¬ì¦ˆ ëª¨ë¸ íŒŒì¼ ì—†ìŒ")
            
    except Exception as e:
        logger.error(f"âŒ í¬ì¦ˆ ì¶”ì • ì‹¤íŒ¨: {e}")
        results['pose_estimation'] = False
    
    # 4. Real-ESRGAN í›„ì²˜ë¦¬ í…ŒìŠ¤íŠ¸
    try:
        print("\n4ï¸âƒ£ í›„ì²˜ë¦¬ í…ŒìŠ¤íŠ¸...")
        model_path = "ai_models/checkpoints/step_07_post_processing/RealESRGAN_x4plus.pth"
        
        checkpoint = torch.load(model_path, map_location='cpu', weights_only=True)
        logger.info(f"âœ… í›„ì²˜ë¦¬ ëª¨ë¸ ë¡œë”© ì„±ê³µ")
        results['post_processing'] = True
        
    except Exception as e:
        logger.error(f"âŒ í›„ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        results['post_processing'] = False
    
    # ê²°ê³¼ ìš”ì•½
    print("\n" + "=" * 40)
    print("ğŸ‰ ìµœì¢… ê²€ì¦ ê²°ê³¼")
    print("=" * 40)
    
    working_count = sum(results.values())
    total_count = len(results)
    
    for component, status in results.items():
        emoji = "âœ…" if status else "âŒ"
        print(f"{emoji} {component}: {'ì‘ë™' if status else 'ì‹¤íŒ¨'}")
    
    print(f"\nğŸ“Š ì‘ë™ë¥ : {working_count}/{total_count} ({working_count/total_count*100:.1f}%)")
    
    if working_count >= 3:
        print("\nğŸš€ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì¤€ë¹„ ì™„ë£Œ!")
        print("ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ ì„œë²„ë¥¼ ì‹œì‘í•˜ì„¸ìš”:")
        print("   python -m app.main")
    else:
        print("\nâš ï¸ ì¼ë¶€ ëª¨ë¸ ë¬¸ì œ - ê¸°ë³¸ ê¸°ëŠ¥ë§Œ ì‚¬ìš© ê°€ëŠ¥")
    
    return results

if __name__ == "__main__":
    test_working_pipeline()
