# backend/run_server.py
#!/usr/bin/env python3
"""
MyCloset AI Backend Server
M3 Max ìµœì í™” ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
"""

import sys
import os
import uvicorn
import logging
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
from dotenv import load_dotenv
load_dotenv()

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('logs/server.log', mode='a')
    ]
)

logger = logging.getLogger(__name__)

def check_environment():
    """í™˜ê²½ ì²´í¬"""
    logger.info("ğŸ” í™˜ê²½ ì²´í¬ ì‹œì‘...")
    
    # Python ë²„ì „ ì²´í¬
    python_version = sys.version_info
    if python_version < (3, 9):
        logger.error(f"âŒ Python 3.9+ í•„ìš”. í˜„ì¬: {python_version}")
        sys.exit(1)
    
    logger.info(f"âœ… Python {python_version.major}.{python_version.minor}")
    
    # í•„ìˆ˜ ë””ë ‰í† ë¦¬ ìƒì„±
    directories = [
        'static/uploads',
        'static/results', 
        'logs',
        'ai_models/checkpoints',
        'ai_models/temp'
    ]
    
    for directory in directories:
        os.makedirs(directory, exist_ok=True)
        
    logger.info("âœ… ë””ë ‰í† ë¦¬ êµ¬ì¡° í™•ì¸ ì™„ë£Œ")
    
    # GPU ì²´í¬
    try:
        import torch
        if torch.backends.mps.is_available():
            logger.info("âœ… Apple M3 Max GPU (Metal) ì‚¬ìš© ê°€ëŠ¥")
        elif torch.cuda.is_available():
            logger.info("âœ… NVIDIA GPU (CUDA) ì‚¬ìš© ê°€ëŠ¥")
        else:
            logger.info("â„¹ï¸ CPU ëª¨ë“œë¡œ ì‹¤í–‰")
    except ImportError:
        logger.warning("âš ï¸ PyTorchê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    
    # í™˜ê²½ ì²´í¬
    check_environment()
    
    # ì„¤ì •ê°’ ë¡œë“œ
    host = os.getenv('HOST', '0.0.0.0')
    port = int(os.getenv('PORT', 8000))
    debug = os.getenv('DEBUG', 'true').lower() == 'true'
    
    logger.info("ğŸš€ MyCloset AI Backend ì„œë²„ ì‹œì‘...")
    logger.info(f"ğŸ“ ì„œë²„ ì£¼ì†Œ: http://{host}:{port}")
    logger.info(f"ğŸ”§ ë””ë²„ê·¸ ëª¨ë“œ: {debug}")
    logger.info(f"ğŸ“š API ë¬¸ì„œ: http://{host}:{port}/docs")
    logger.info(f"â¤ï¸ í—¬ìŠ¤ì²´í¬: http://{host}:{port}/health")
    
    try:
        # ì„œë²„ ì‹¤í–‰
        uvicorn.run(
            "app.main:app",
            host=host,
            port=port,
            reload=debug,
            log_level="info" if debug else "warning",
            access_log=debug,
            reload_dirs=["app"] if debug else None,
            reload_excludes=["static", "logs", "ai_models"] if debug else None
        )
        
    except KeyboardInterrupt:
        logger.info("ğŸ›‘ ì„œë²„ ì¢…ë£Œ ìš”ì²­")
    except Exception as e:
        logger.error(f"âŒ ì„œë²„ ì‹¤í–‰ ì˜¤ë¥˜: {e}")
        sys.exit(1)
    finally:
        logger.info("ğŸ‘‹ MyCloset AI Backend ì„œë²„ ì¢…ë£Œ")

if __name__ == "__main__":
    main()