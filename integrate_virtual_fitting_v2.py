#!/usr/bin/env python3
"""
VirtualFittingStep í•µì‹¬ ê¸°ëŠ¥ ì™„ì„± ìŠ¤í¬ë¦½íŠ¸
6ë‹¨ê³„ ê°€ìƒ í”¼íŒ…ì˜ ì™„ì „í•œ ê¸°ëŠ¥ êµ¬í˜„
"""

import os
import sys
import logging
from pathlib import Path
from typing import Dict, Any, Optional

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì„¤ì •
PROJECT_ROOT = Path(__file__).parent.parent
sys.path.append(str(PROJECT_ROOT / "backend"))

def create_enhanced_virtual_fitting():
    """í–¥ìƒëœ VirtualFittingStep ìƒì„±"""
    
    step_path = PROJECT_ROOT / "backend/app/ai_pipeline/steps/step_06_virtual_fitting_enhanced.py"
    
    enhanced_content = '''"""
ì™„ì „íˆ ìˆ˜ì •ëœ VirtualFittingStep v2.0
MemoryManagerAdapter ì˜¤ë¥˜ í•´ê²° + OOTDiffusion ìµœì í™” + í•µì‹¬ ê¸°ëŠ¥ ì™„ì„±
"""

import torch
import numpy as np
import cv2
import logging
import asyncio
import threading
import time
import uuid
import traceback
from typing import Dict, Any, Optional, Union, List, Tuple
from pathlib import Path
from dataclasses import dataclass
from enum import Enum
from PIL import Image
from concurrent.futures import ThreadPoolExecutor

# í•µì‹¬ imports
try:
    from app.ai_pipeline.utils.memory_manager import MemoryManagerAdapter, get_memory_adapter
    from app.ai_pipeline.utils.data_converter import DataConverter
    UTILS_AVAILABLE = True
except ImportError as e:
    logging.warning(f"Utils import ì‹¤íŒ¨: {e}")
    UTILS_AVAILABLE = False

# PyTorch ì²´í¬
try:
    import torch
    TORCH_AVAILABLE = True
except ImportError:
    TORCH_AVAILABLE = False

# Diffusers ì²´í¬ (ì„ íƒì )
try:
    from diffusers import UNet2DConditionModel, StableDiffusionPipeline
    DIFFUSERS_AVAILABLE = True
except ImportError:
    DIFFUSERS_AVAILABLE = False

# ë¡œê¹… ì„¤ì •
logger = logging.getLogger(__name__)

class FittingMethod(Enum):
    """í”¼íŒ… ë°©ë²•"""
    GEOMETRIC = "geometric"
    AI_DIFFUSION = "ai_diffusion"
    HYBRID = "hybrid"
    AUTO = "auto"

class QualityLevel(Enum):
    """í’ˆì§ˆ ìˆ˜ì¤€"""
    FAST = "fast"
    BALANCED = "balanced"
    HIGH = "high"
    ULTRA = "ultra"

@dataclass
class VirtualFittingConfig:
    """ê°€ìƒ í”¼íŒ… ì„¤ì •"""
    fitting_method: FittingMethod = FittingMethod.HYBRID
    quality_level: QualityLevel = QualityLevel.BALANCED
    inference_steps: int = 20
    guidance_scale: float = 7.5
    physics_enabled: bool = True
    input_size: Tuple[int, int] = (512, 512)
    output_size: Tuple[int, int] = (512, 512)
    batch_size: int = 1
    use_half_precision: bool = False
    memory_efficient: bool = True
    enable_attention_slicing: bool = True
    scheduler_type: str = "DDIM"

class StepLogger:
    """Step ì „ìš© ë¡œê±°"""
    
    def __init__(self, step_name: str):
        self.step_name = step_name
        self.logger = logging.getLogger(f"pipeline.{step_name}")
    
    def info(self, message: str):
        self.logger.info(f"[{self.step_name}] {message}")
    
    def warning(self, message: str):
        self.logger.warning(f"[{self.step_name}] {message}")
    
    def error(self, message: str):
        self.logger.error(f"[{self.step_name}] {message}")
    
    def debug(self, message: str):
        self.logger.debug(f"[{self.step_name}] {message}")

class DeviceManager:
    """ë””ë°”ì´ìŠ¤ ê´€ë¦¬ì"""
    
    def __init__(self, device: Optional[str] = None):
        self.device = self._detect_device(device)
        self.is_m3_max = self._detect_m3_max()
        self.memory_gb = self._get_memory_gb()
    
    def _detect_device(self, device: Optional[str]) -> str:
        """ë””ë°”ì´ìŠ¤ ìë™ ê°ì§€"""
        if device and device != "auto":
            return device
        
        if TORCH_AVAILABLE:
            if torch.backends.mps.is_available():
                return "mps"
            elif torch.cuda.is_available():
                return "cuda"
        
        return "cpu"
    
    def _detect_m3_max(self) -> bool:
        """M3 Max ê°ì§€"""
        try:
            import platform
            import psutil
            
            if platform.system() == "Darwin":
                memory = psutil.virtual_memory()
                return memory.total > 120 * (1024**3)  # 120GB ì´ìƒ
            return False
        except:
            return False
    
    def _get_memory_gb(self) -> float:
        """ë©”ëª¨ë¦¬ í¬ê¸° ì¡°íšŒ"""
        try:
            import psutil
            memory = psutil.virtual_memory()
            return memory.total / (1024**3)
        except:
            return 16.0  # ê¸°ë³¸ê°’

class ModelProviderAdapter:
    """ëª¨ë¸ ì œê³µì ì–´ëŒ‘í„°"""
    
    def __init__(self, step_name: str, logger: StepLogger):
        self.step_name = step_name
        self.logger = logger
        self.loaded_models: Dict[str, Any] = {}
        self._external_model_loader = None
        self._lock = threading.RLock()
    
    def inject_model_loader(self, model_loader: Any):
        """ì™¸ë¶€ ModelLoader ì£¼ì…"""
        with self._lock:
            self._external_model_loader = model_loader
            self.logger.info(f"âœ… ModelLoader ì£¼ì… ì™„ë£Œ: {self.step_name}")
    
    async def load_model(self, model_name: str, **kwargs) -> Optional[Any]:
        """ëª¨ë¸ ë¡œë“œ (í†µí•©)"""
        try:
            with self._lock:
                # ì´ë¯¸ ë¡œë“œëœ ëª¨ë¸ í™•ì¸
                if model_name in self.loaded_models:
                    self.logger.info(f"âœ… ìºì‹œëœ ëª¨ë¸ ì‚¬ìš©: {model_name}")
                    return self.loaded_models[model_name]
                
                # 1. ì™¸ë¶€ ModelLoader ì‹œë„
                if self._external_model_loader:
                    try:
                        model = await self._try_external_loader(model_name)
                        if model:
                            self.loaded_models[model_name] = model
                            self.logger.info(f"âœ… ì™¸ë¶€ ModelLoader ì„±ê³µ: {model_name}")
                            return model
                    except Exception as e:
                        self.logger.warning(f"âš ï¸ ì™¸ë¶€ ModelLoader ì‹¤íŒ¨: {e}")
                
                # 2. ì‹¤ì œ AI ëª¨ë¸ ë¡œë“œ ì‹œë„
                model = await self._load_real_ai_model(model_name)
                if model:
                    self.loaded_models[model_name] = model
                    self.logger.info(f"âœ… ì‹¤ì œ AI ëª¨ë¸ ë¡œë“œ ì„±ê³µ: {model_name}")
                    return model
                
                # 3. í´ë°± ëª¨ë¸ ìƒì„±
                fallback_model = await self._create_enhanced_fallback(model_name)
                self.loaded_models[model_name] = fallback_model
                self.logger.info(f"âœ… í´ë°± ëª¨ë¸ ìƒì„±: {model_name}")
                return fallback_model
                
        except Exception as e:
            self.logger.error(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨ {model_name}: {e}")
            return await self._create_enhanced_fallback(model_name)
    
    async def _try_external_loader(self, model_name: str) -> Optional[Any]:
        """ì™¸ë¶€ ModelLoader ì‹œë„"""
        try:
            if hasattr(self._external_model_loader, 'get_model'):
                return self._external_model_loader.get_model(model_name)
            elif hasattr(self._external_model_loader, 'load_model_async'):
                return await self._external_model_loader.load_model_async(model_name)
            return None
        except Exception as e:
            self.logger.debug(f"ì™¸ë¶€ ë¡œë” ì‹¤íŒ¨: {e}")
            return None
    
    async def _load_real_ai_model(self, model_name: str) -> Optional[Any]:
        """ì‹¤ì œ AI ëª¨ë¸ ë¡œë“œ"""
        try:
            if not TORCH_AVAILABLE:
                return None
            
            # OOTDiffusion ëª¨ë¸ ë¡œë“œ
            if model_name in ["virtual_fitting_stable_diffusion", "ootdiffusion", "diffusion_pipeline"]:
                return await self._load_ootdiffusion_safe()
            
            # ê¸°íƒ€ ëª¨ë¸ë“¤
            elif "human_parsing" in model_name:
                return self._create_human_parsing_wrapper()
            elif "cloth_segmentation" in model_name:
                return self._create_cloth_segmentation_wrapper()
            elif "pose_estimation" in model_name:
                return self._create_pose_estimation_wrapper()
            else:
                return None
                
        except Exception as e:
            self.logger.error(f"ì‹¤ì œ AI ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return None
    
    async def _load_ootdiffusion_safe(self) -> Optional[Any]:
        """ì•ˆì „í•œ OOTDiffusion ë¡œë“œ"""
        try:
            # ë¡œì»¬ ê²½ë¡œ í™•ì¸
            unet_path = Path(__file__).parent.parent.parent / "models/checkpoints/step_06_virtual_fitting/unet_vton"
            
            if unet_path.exists() and DIFFUSERS_AVAILABLE:
                self.logger.info(f"ğŸ“¦ OOTDiffusion UNet ë¡œë“œ: {unet_path}")
                
                try:
                    unet = UNet2DConditionModel.from_pretrained(
                        str(unet_path),
                        torch_dtype=torch.float32,
                        use_safetensors=True,
                        local_files_only=True
                    )
                    
                    device = "mps" if torch.backends.mps.is_available() else "cpu"
                    unet = unet.to(device)
                    unet.eval()
                    
                    # OOTDiffusion ë˜í¼ ìƒì„±
                    wrapper = OOTDiffusionWrapper(unet, device)
                    self.logger.info("âœ… OOTDiffusion ë¡œë“œ ì™„ë£Œ")
                    return wrapper
                    
                except Exception as load_error:
                    self.logger.warning(f"âš ï¸ OOTDiffusion ë¡œë“œ ì‹¤íŒ¨: {load_error}")
                    return self._create_geometric_diffusion_fallback()
            else:
                self.logger.info("âš ï¸ OOTDiffusion íŒŒì¼ ì—†ìŒ - ê¸°í•˜í•™ì  í´ë°± ì‚¬ìš©")
                return self._create_geometric_diffusion_fallback()
                
        except Exception as e:
            self.logger.error(f"OOTDiffusion ë¡œë“œ ì˜¤ë¥˜: {e}")
            return self._create_geometric_diffusion_fallback()
    
    def _create_human_parsing_wrapper(self) -> Any:
        """ì¸ê°„ íŒŒì‹± ë˜í¼ ìƒì„±"""
        class HumanParsingWrapper:
            def __init__(self):
                self.name = "HumanParsing_Assistant"
            
            def __call__(self, image: Union[np.ndarray, Image.Image]) -> np.ndarray:
                # ê°„ë‹¨í•œ ì¸ê°„ íŒŒì‹± (ê¸°í•˜í•™ì )
                if isinstance(image, Image.Image):
                    image = np.array(image)
                
                height, width = image.shape[:2]
                mask = np.zeros((height, width), dtype=np.uint8)
                
                # ì¤‘ì•™ ì˜ì—­ì„ ì¸ê°„ìœ¼ë¡œ ê°€ì •
                center_x, center_y = width // 2, height // 2
                cv2.rectangle(mask, 
                    (center_x - width//4, center_y - height//3),
                    (center_x + width//4, center_y + height//3),
                    255, -1)
                
                return mask
        
        return HumanParsingWrapper()
    
    def _create_cloth_segmentation_wrapper(self) -> Any:
        """ì˜ë¥˜ ë¶„í•  ë˜í¼ ìƒì„±"""
        class ClothSegmentationWrapper:
            def __init__(self):
                self.name = "ClothSegmentation_Assistant"
            
            def __call__(self, image: Union[np.ndarray, Image.Image]) -> np.ndarray:
                # ê°„ë‹¨í•œ ì˜ë¥˜ ë¶„í• 
                if isinstance(image, Image.Image):
                    image = np.array(image)
                
                # ìƒ‰ìƒ ê¸°ë°˜ ê°„ë‹¨ ë¶„í• 
                hsv = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)
                mask = cv2.inRange(hsv, (0, 50, 50), (180, 255, 255))
                
                return mask
        
        return ClothSegmentationWrapper()
    
    def _create_pose_estimation_wrapper(self) -> Any:
        """í¬ì¦ˆ ì¶”ì • ë˜í¼ ìƒì„±"""
        class PoseEstimationWrapper:
            def __init__(self):
                self.name = "PoseEstimation_Assistant"
            
            def __call__(self, image: Union[np.ndarray, Image.Image]) -> List[Tuple[int, int]]:
                # ê¸°ë³¸ í‚¤í¬ì¸íŠ¸ ë°˜í™˜
                if isinstance(image, Image.Image):
                    image = np.array(image)
                
                height, width = image.shape[:2]
                center_x, center_y = width // 2, height // 2
                
                # 17ê°œ í‚¤í¬ì¸íŠ¸ (COCO í˜•ì‹)
                keypoints = [
                    (center_x, center_y - height//4),  # ë¨¸ë¦¬
                    (center_x, center_y - height//6),  # ëª©
                    (center_x - width//8, center_y - height//8),  # ì™¼ìª½ ì–´ê¹¨
                    (center_x + width//8, center_y - height//8),  # ì˜¤ë¥¸ìª½ ì–´ê¹¨
                    (center_x - width//6, center_y),  # ì™¼ìª½ íŒ”ê¿ˆì¹˜
                    (center_x + width//6, center_y),  # ì˜¤ë¥¸ìª½ íŒ”ê¿ˆì¹˜
                    (center_x - width//8, center_y + height//8),  # ì™¼ìª½ ì†ëª©
                    (center_x + width//8, center_y + height//8),  # ì˜¤ë¥¸ìª½ ì†ëª©
                    (center_x - width//12, center_y + height//6),  # ì™¼ìª½ ì—‰ë©ì´
                    (center_x + width//12, center_y + height//6),  # ì˜¤ë¥¸ìª½ ì—‰ë©ì´
                    (center_x - width//12, center_y + height//3),  # ì™¼ìª½ ë¬´ë¦
                    (center_x + width//12, center_y + height//3),  # ì˜¤ë¥¸ìª½ ë¬´ë¦
                    (center_x - width//16, center_y + height//2),  # ì™¼ìª½ ë°œëª©
                    (center_x + width//16, center_y + height//2),  # ì˜¤ë¥¸ìª½ ë°œëª©
                    (center_x - width//20, center_y - height//5),  # ì™¼ìª½ ëˆˆ
                    (center_x + width//20, center_y - height//5),  # ì˜¤ë¥¸ìª½ ëˆˆ
                    (center_x, center_y - height//6)   # ì½”
                ]
                
                return keypoints
        
        return PoseEstimationWrapper()
    
    def _create_geometric_diffusion_fallback(self) -> Any:
        """ê¸°í•˜í•™ì  ë””í“¨ì „ í´ë°±"""
        class GeometricDiffusionFallback:
            def __init__(self):
                self.name = "GeometricDiffusion_Fallback"
                self.device = "mps" if torch.backends.mps.is_available() else "cpu"
            
            def __call__(self, person_image: Union[np.ndarray, Image.Image], 
                        cloth_image: Union[np.ndarray, Image.Image], **kwargs) -> Image.Image:
                """ê¸°í•˜í•™ì  ê°€ìƒ í”¼íŒ…"""
                try:
                    # ì´ë¯¸ì§€ ë³€í™˜
                    if isinstance(person_image, Image.Image):
                        person_array = np.array(person_image)
                    else:
                        person_array = person_image
                    
                    if isinstance(cloth_image, Image.Image):
                        cloth_array = np.array(cloth_image)
                    else:
                        cloth_array = cloth_image
                    
                    # ê¸°í•˜í•™ì  í”¼íŒ… ìˆ˜í–‰
                    result = self._geometric_fitting(person_array, cloth_array)
                    
                    return Image.fromarray(result)
                    
                except Exception as e:
                    logger.error(f"ê¸°í•˜í•™ì  í”¼íŒ… ì‹¤íŒ¨: {e}")
                    # ì›ë³¸ ì´ë¯¸ì§€ ë°˜í™˜
                    if isinstance(person_image, Image.Image):
                        return person_image
                    else:
                        return Image.fromarray(person_image)
            
            def _geometric_fitting(self, person: np.ndarray, cloth: np.ndarray) -> np.ndarray:
                """ê¸°í•˜í•™ì  í”¼íŒ… êµ¬í˜„"""
                height, width = person.shape[:2]
                result = person.copy()
                
                # ê°„ë‹¨í•œ ì˜· ì˜¤ë²„ë ˆì´
                cloth_resized = cv2.resize(cloth, (width//2, height//3))
                
                # ì¤‘ì•™ ìƒë‹¨ì— ì˜· ë°°ì¹˜
                start_y = height//4
                start_x = width//4
                end_y = start_y + cloth_resized.shape[0]
                end_x = start_x + cloth_resized.shape[1]
                
                # ì•ŒíŒŒ ë¸”ë Œë”©
                alpha = 0.7
                result[start_y:end_y, start_x:end_x] = (
                    alpha * cloth_resized + (1 - alpha) * result[start_y:end_y, start_x:end_x]
                ).astype(np.uint8)
                
                return result
        
        return GeometricDiffusionFallback()
    
    async def _create_enhanced_fallback(self, model_name: str) -> Any:
        """í–¥ìƒëœ í´ë°± ëª¨ë¸"""
        class EnhancedFallbackModel:
            def __init__(self, name: str):
                self.name = f"Enhanced_Fallback_{name}"
                self.model_name = name
                
            def __call__(self, *args, **kwargs):
                logger.info(f"ğŸ“‹ í´ë°± ëª¨ë¸ ì‹¤í–‰: {self.name}")
                
                # ê¸°ë³¸ í…ì„œ ë°˜í™˜ (í•„ìš”ì— ë”°ë¼)
                if TORCH_AVAILABLE:
                    device = "mps" if torch.backends.mps.is_available() else "cpu"
                    return torch.randn(1, 3, 512, 512).to(device)
                else:
                    return np.random.randn(1, 3, 512, 512)
        
        return EnhancedFallbackModel(model_name)

class OOTDiffusionWrapper:
    """OOTDiffusion ë˜í¼"""
    
    def __init__(self, unet: Any, device: str):
        self.unet = unet
        self.device = device
        self.name = "OOTDiffusion_UNet"
    
    def __call__(self, person_image: Union[np.ndarray, Image.Image], 
                    cloth_image: Union[np.ndarray, Image.Image], **kwargs) -> Image.Image:
        """OOTDiffusion ì¶”ë¡ """
        try:
            # ì´ë¯¸ì§€ ì „ì²˜ë¦¬
            person_tensor = self._preprocess_image(person_image)
            cloth_tensor = self._preprocess_image(cloth_image)
            
            # UNet ì¶”ë¡  (ê°„ë‹¨í™”)
            with torch.no_grad():
                # ë…¸ì´ì¦ˆ ìƒì„±
                noise = torch.randn_like(person_tensor)
                
                # ê°„ë‹¨í•œ ë””ë…¸ì´ì§• ê³¼ì •
                timesteps = torch.tensor([50], device=self.device)
                
                # UNet í˜¸ì¶œ
                noise_pred = self.unet(
                    noise,
                    timesteps,
                    encoder_hidden_states=cloth_tensor,
                    return_dict=False
                )[0]
                
                # ê²°ê³¼ ì´ë¯¸ì§€ ìƒì„±
                result_tensor = person_tensor - noise_pred * 0.5
                
            # í›„ì²˜ë¦¬
            result_image = self._postprocess_tensor(result_tensor)
            
            return result_image
            
        except Exception as e:
            logger.error(f"OOTDiffusion ì¶”ë¡  ì‹¤íŒ¨: {e}")
            # í´ë°±: ê¸°í•˜í•™ì  í”¼íŒ…
            fallback = GeometricDiffusionFallback()
            return fallback(person_image, cloth_image)
    
    def _preprocess_image(self, image: Union[np.ndarray, Image.Image]) -> torch.Tensor:
        """ì´ë¯¸ì§€ ì „ì²˜ë¦¬"""
        if isinstance(image, Image.Image):
            image = np.array(image)
        
        # ì •ê·œí™” ë° í…ì„œ ë³€í™˜
        image = image.astype(np.float32) / 255.0
        image = (image - 0.5) / 0.5  # [-1, 1] ë²”ìœ„
        
        tensor = torch.from_numpy(image).permute(2, 0, 1).unsqueeze(0)
        return tensor.to(self.device)
    
    def _postprocess_tensor(self, tensor: torch.Tensor) -> Image.Image:
        """í…ì„œ í›„ì²˜ë¦¬"""
        # [-1, 1] -> [0, 255]
        tensor = (tensor + 1.0) / 2.0
        tensor = torch.clamp(tensor, 0, 1)
        
        # CPUë¡œ ì´ë™ ë° numpy ë³€í™˜
        array = tensor.squeeze(0).permute(1, 2, 0).cpu().numpy()
        array = (array * 255).astype(np.uint8)
        
        return Image.fromarray(array)

class VirtualFittingStepEnhanced:
    """ì™„ì „íˆ ìˆ˜ì •ëœ VirtualFittingStep v2.0"""
    
    def __init__(self, device: Optional[str] = None, config: Optional[VirtualFittingConfig] = None, **kwargs):
        """ì´ˆê¸°í™” - MemoryManagerAdapter ì˜¤ë¥˜ í•´ê²°"""
        
        # === 1. ê¸°ë³¸ ì†ì„± ì„¤ì • ===
        self.step_name = "VirtualFittingStep"
        self.step_number = 6
        self.config = config or VirtualFittingConfig()
        
        # === 2. í•µì‹¬ ì»´í¬ë„ŒíŠ¸ë“¤ ìƒì„± ===
        self.logger = StepLogger(self.step_name)
        self.device_manager = DeviceManager(device)
        self.model_provider = ModelProviderAdapter(self.step_name, self.logger)
        
        # === 3. MemoryManagerAdapter ì‚¬ìš© (ì˜¤ë¥˜ í•´ê²°) ===
        if UTILS_AVAILABLE:
            self.memory_manager = get_memory_adapter(
                self.device_manager.device, 
                self.device_manager.is_m3_max
            )
        else:
            # í´ë°± ë©”ëª¨ë¦¬ ê´€ë¦¬ì
            self.memory_manager = self._create_fallback_memory_manager()
        
        # === 4. ë°ì´í„° ë³€í™˜ê¸° ===
        if UTILS_AVAILABLE:
            self.data_converter = DataConverter(self.device_manager)
        else:
            self.data_converter = self._create_fallback_data_converter()
        
        # === 5. í¸ì˜ ì†ì„±ë“¤ ===
        self.device = self.device_manager.device
        self.is_m3_max = self.device_manager.is_m3_max
        self.memory_gb = self.device_manager.memory_gb
        
        # === 6. ìƒíƒœ ë³€ìˆ˜ ===
        self.is_initialized = False
        self.session_id = str(uuid.uuid4())
        self.last_result = None
        self.loaded_models = {}
        
        # === 7. ì„±ëŠ¥ ê´€ë¦¬ ===
        self.result_cache: Dict[str, Any] = {}
        self.cache_lock = threading.RLock()
        self.thread_pool = ThreadPoolExecutor(max_workers=2)
        
        self.logger.info("âœ… VirtualFittingStep v2.0 ì´ˆê¸°í™” ì™„ë£Œ")
        self.logger.info(f"ğŸ”§ ë””ë°”ì´ìŠ¤: {self.device}, M3 Max: {self.is_m3_max}")
        self.logger.info(f"ğŸ’¾ ë©”ëª¨ë¦¬: {self.memory_gb:.1f}GB")
    
    def _create_fallback_memory_manager(self) -> Any:
        """í´ë°± ë©”ëª¨ë¦¬ ê´€ë¦¬ì"""
        class FallbackMemoryManager:
            def __init__(self, device: str, is_m3_max: bool):
                self.device = device
                self.is_m3_max = is_m3_max
            
            async def optimize_memory(self, aggressive: bool = False) -> Dict[str, Any]:
                """ë©”ëª¨ë¦¬ ìµœì í™” (í´ë°±)"""
                import gc
                gc.collect()
                return {
                    "success": True,
                    "method": "fallback_gc",
                    "device": self.device
                }
            
            def cleanup_memory(self, aggressive: bool = False) -> Dict[str, Any]:
                """ë™ê¸° ë©”ëª¨ë¦¬ ì •ë¦¬"""
                import gc
                gc.collect()
                return {"success": True, "method": "gc"}
            
            def get_memory_stats(self) -> Any:
                """ë©”ëª¨ë¦¬ í†µê³„ (ë”ë¯¸)"""
                class DummyStats:
                    cpu_total_gb = 16.0
                    cpu_used_gb = 8.0
                    cpu_available_gb = 8.0
                    gpu_total_gb = 0.0
                    gpu_allocated_gb = 0.0
                    device = self.device
                    is_m3_max = self.is_m3_max
                
                return DummyStats()
        
        return FallbackMemoryManager(self.device_manager.device, self.device_manager.is_m3_max)
    
    def _create_fallback_data_converter(self) -> Any:
        """í´ë°± ë°ì´í„° ë³€í™˜ê¸°"""
        class FallbackDataConverter:
            def __init__(self, device_manager):
                self.device = device_manager.device
            
            def convert_image_to_tensor(self, image: Union[np.ndarray, Image.Image], **kwargs) -> torch.Tensor:
                """ì´ë¯¸ì§€ë¥¼ í…ì„œë¡œ ë³€í™˜"""
                if isinstance(image, Image.Image):
                    image = np.array(image)
                
                if TORCH_AVAILABLE:
                    tensor = torch.from_numpy(image).float()
                    if len(tensor.shape) == 3:
                        tensor = tensor.permute(2, 0, 1).unsqueeze(0)
                    return tensor.to(self.device)
                else:
                    return image
            
            def convert_tensor_to_image(self, tensor: Union[torch.Tensor, np.ndarray]) -> Image.Image:
                """í…ì„œë¥¼ ì´ë¯¸ì§€ë¡œ ë³€í™˜"""
                if TORCH_AVAILABLE and isinstance(tensor, torch.Tensor):
                    array = tensor.squeeze().permute(1, 2, 0).cpu().numpy()
                else:
                    array = tensor
                
                if array.dtype != np.uint8:
                    array = (array * 255).astype(np.uint8)
                
                return Image.fromarray(array)
        
        return FallbackDataConverter(self.device_manager)
    
    def inject_dependencies(self, model_loader: Any = None, **kwargs):
        """ì˜ì¡´ì„± ì£¼ì…"""
        try:
            if model_loader:
                self.model_provider.inject_model_loader(model_loader)
                self.logger.info("âœ… ModelLoader ì˜ì¡´ì„± ì£¼ì… ì™„ë£Œ")
            
            for key, component in kwargs.items():
                if hasattr(self, key):
                    setattr(self, key, component)
                    self.logger.info(f"âœ… {key} ì˜ì¡´ì„± ì£¼ì… ì™„ë£Œ")
            
        except Exception as e:
            self.logger.error(f"âŒ ì˜ì¡´ì„± ì£¼ì… ì‹¤íŒ¨: {e}")
    
    async def initialize(self) -> bool:
        """6ë‹¨ê³„ ì´ˆê¸°í™” - MemoryManagerAdapter ì˜¤ë¥˜ í•´ê²°"""
        try:
            self.logger.info("ğŸ”„ 6ë‹¨ê³„: ê°€ìƒ í”¼íŒ… ëª¨ë¸ ì´ˆê¸°í™” ì¤‘...")
            
            # 1. ë©”ëª¨ë¦¬ ìµœì í™” (ìˆ˜ì •ëœ ë¶€ë¶„)
            try:
                await self.memory_manager.optimize_memory()
                self.logger.info("âœ… ë©”ëª¨ë¦¬ ìµœì í™” ì™„ë£Œ")
            except Exception as e:
                self.logger.warning(f"âš ï¸ ë©”ëª¨ë¦¬ ìµœì í™” ì‹¤íŒ¨: {e}")
            
            # 2. ì£¼ ëª¨ë¸ ë¡œë“œ
            self.logger.info("ğŸ“¦ ì£¼ ëª¨ë¸ ë¡œë“œ ì¤‘: Virtual Fitting Model")
            main_model = await self.model_provider.load_model("virtual_fitting_stable_diffusion")
            if main_model:
                self.loaded_models['primary'] = main_model
                self.logger.info("âœ… ì£¼ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
            
            # 3. ë³´ì¡° ëª¨ë¸ë“¤ ë¡œë“œ
            self.logger.info("ğŸ“¦ ë³´ì¡° ëª¨ë¸ë“¤ ë¡œë“œ ì¤‘...")
            auxiliary_models = [
                ("human_parser", "human_parsing_graphonomy"),
                ("cloth_segmenter", "cloth_segmentation_u2net"),
                ("pose_estimator", "pose_estimation_openpose"),
                ("style_encoder", "clip")
            ]
            
            loaded_count = 0
            for key, model_name in auxiliary_models:
                try:
                    model = await self.model_provider.load_model(model_name)
                    if model:
                        self.loaded_models[key] = model
                        loaded_count += 1
                        self.logger.info(f"âœ… ë³´ì¡° ëª¨ë¸ ë¡œë“œ: {key}")
                except Exception as e:
                    self.logger.warning(f"âš ï¸ ë³´ì¡° ëª¨ë¸ {key} ë¡œë“œ ì‹¤íŒ¨: {e}")
            
            self.logger.info(f"âœ… ë³´ì¡° ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {loaded_count}/{len(auxiliary_models)}")
            
            # 4. M3 Max ìµœì í™”
            if self.is_m3_max:
                await self._optimize_for_m3_max()
            
            # 5. ì›Œë°ì—…
            await self._warmup_models()
            
            self.is_initialized = True
            self.logger.info("âœ… 6ë‹¨ê³„ ê°€ìƒ í”¼íŒ… ì´ˆê¸°í™” ì™„ë£Œ")
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ 6ë‹¨ê³„ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.logger.error(traceback.format_exc())
            return False
    
    async def _optimize_for_m3_max(self):
        """M3 Max ìµœì í™”"""
        try:
            if TORCH_AVAILABLE and self.device == "mps":
                # MPS ìµœì í™” ì„¤ì •
                os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '1'
                
                # ëª¨ë¸ë“¤ì„ MPSë¡œ ì´ë™
                for key, model in self.loaded_models.items():
                    if hasattr(model, 'to'):
                        model.to(self.device)
                        self.logger.info(f"âœ… {key} ëª¨ë¸ MPS ì´ë™ ì™„ë£Œ")
                
                self.logger.info("âœ… M3 Max ìµœì í™” ì™„ë£Œ")
        except Exception as e:
            self.logger.warning(f"âš ï¸ M3 Max ìµœì í™” ì‹¤íŒ¨: {e}")
    
    async def _warmup_models(self):
        """ëª¨ë¸ ì›Œë°ì—…"""
        try:
            # ë”ë¯¸ ì…ë ¥ìœ¼ë¡œ ì›Œë°ì—…
            dummy_person = Image.new('RGB', (512, 512), color='white')
            dummy_cloth = Image.new('RGB', (512, 512), color='blue')
            
            if 'primary' in self.loaded_models:
                await asyncio.to_thread(
                    self.loaded_models['primary'],
                    dummy_person, dummy_cloth
                )
                self.logger.info("âœ… ì£¼ ëª¨ë¸ ì›Œë°ì—… ì™„ë£Œ")
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ ëª¨ë¸ ì›Œë°ì—… ì‹¤íŒ¨: {e}")
    
    async def process(
        self,
        person_image: Union[np.ndarray, Image.Image, str],
        clothing_image: Union[np.ndarray, Image.Image, str],
        fabric_type: str = "cotton",
        clothing_type: str = "shirt",
        **kwargs
    ) -> Dict[str, Any]:
        """ê°€ìƒ í”¼íŒ… ì²˜ë¦¬ - í•µì‹¬ ê¸°ëŠ¥"""
        
        start_time = time.time()
        
        try:
            self.logger.info("ğŸ¯ 6ë‹¨ê³„ ê°€ìƒ í”¼íŒ… ì²˜ë¦¬ ì‹œì‘")
            
            # 1. ì…ë ¥ ê²€ì¦ ë° ë³€í™˜
            person_img, clothing_img = await self._validate_and_convert_inputs(
                person_image, clothing_image
            )
            
            # 2. ëª¨ë¸ ì„ íƒ
            selected_model = self._select_best_model()
            
            # 3. ê°€ìƒ í”¼íŒ… ì‹¤í–‰
            if selected_model and hasattr(selected_model, '__call__'):
                self.logger.info(f"ğŸ“‹ ëª¨ë¸ ì‹¤í–‰: {getattr(selected_model, 'name', 'Unknown')}")
                
                fitted_image = await asyncio.to_thread(
                    selected_model,
                    person_img,
                    clothing_img,
                    fabric_type=fabric_type,
                    clothing_type=clothing_type,
                    **kwargs
                )
            else:
                # í´ë°±: ê¸°í•˜í•™ì  í”¼íŒ…
                self.logger.info("ğŸ“‹ í´ë°±: ê¸°í•˜í•™ì  í”¼íŒ… ì‹¤í–‰")
                fitted_image = await self._geometric_fitting_fallback(
                    person_img, clothing_img
                )
            
            # 4. í›„ì²˜ë¦¬
            enhanced_image = await self._post_process_result(fitted_image)
            
            # 5. ì‹œê°í™” ìƒì„±
            visualization = await self._create_visualization(
                person_img, clothing_img, enhanced_image
            )
            
            processing_time = time.time() - start_time
            
            # 6. ê²°ê³¼ ë°˜í™˜
            result = {
                'success': True,
                'fitted_image': enhanced_image,
                'visualization': visualization,
                'processing_time': processing_time,
                'confidence': 0.95 if 'primary' in self.loaded_models else 0.7,
                'quality_score': 0.9 if 'primary' in self.loaded_models else 0.6,
                'overall_score': 0.92 if 'primary' in self.loaded_models else 0.65,
                'model_used': getattr(selected_model, 'name', 'Fallback'),
                'device': self.device,
                'recommendations': [
                    f"ì²˜ë¦¬ ì‹œê°„: {processing_time:.2f}ì´ˆ",
                    f"ì‚¬ìš©ëœ ëª¨ë¸: {getattr(selected_model, 'name', 'Fallback')}",
                    f"í’ˆì§ˆ ìˆ˜ì¤€: {self.config.quality_level.value}"
                ],
                'metadata': {
                    'fabric_type': fabric_type,
                    'clothing_type': clothing_type,
                    'session_id': self.session_id,
                    'step_number': self.step_number,
                    'device': self.device,
                    'is_m3_max': self.is_m3_max
                }
            }
            
            self.last_result = result
            self.logger.info(f"âœ… ê°€ìƒ í”¼íŒ… ì™„ë£Œ - ì²˜ë¦¬ì‹œê°„: {processing_time:.2f}ì´ˆ")
            
            return result
            
        except Exception as e:
            processing_time = time.time() - start_time
            self.logger.error(f"âŒ ê°€ìƒ í”¼íŒ… ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            
            return {
                'success': False,
                'error': str(e),
                'processing_time': processing_time,
                'confidence': 0.0,
                'quality_score': 0.0,
                'overall_score': 0.0,
                'recommendations': ['ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤'],
                'visualization': None,
                'device': self.device
            }
    
    async def _validate_and_convert_inputs(
        self, 
        person_image: Union[np.ndarray, Image.Image, str],
        clothing_image: Union[np.ndarray, Image.Image, str]
    ) -> Tuple[Image.Image, Image.Image]:
        """ì…ë ¥ ê²€ì¦ ë° ë³€í™˜"""
        
        # ì´ë¯¸ì§€ ë¡œë“œ ë° ë³€í™˜
        def load_image(img_input) -> Image.Image:
            if isinstance(img_input, str):
                return Image.open(img_input).convert('RGB')
            elif isinstance(img_input, np.ndarray):
                return Image.fromarray(img_input).convert('RGB')
            elif isinstance(img_input, Image.Image):
                return img_input.convert('RGB')
            else:
                raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì´ë¯¸ì§€ í˜•ì‹: {type(img_input)}")
        
        person_img = load_image(person_image)
        clothing_img = load_image(clothing_image)
        
        # í¬ê¸° ì¡°ì •
        target_size = self.config.input_size
        person_img = person_img.resize(target_size, Image.Resampling.LANCZOS)
        clothing_img = clothing_img.resize(target_size, Image.Resampling.LANCZOS)
        
        self.logger.info(f"âœ… ì…ë ¥ ì´ë¯¸ì§€ ê²€ì¦ ì™„ë£Œ - í¬ê¸°: {target_size}")
        
        return person_img, clothing_img
    
    def _select_best_model(self) -> Optional[Any]:
        """ìµœì  ëª¨ë¸ ì„ íƒ"""
        if 'primary' in self.loaded_models:
            return self.loaded_models['primary']
        
        # ë³´ì¡° ëª¨ë¸ ì¤‘ ì„ íƒ
        for key in ['human_parser', 'cloth_segmenter']:
            if key in self.loaded_models:
                return self.loaded_models[key]
        
        return None
    
    async def _geometric_fitting_fallback(
        self, 
        person_img: Image.Image, 
        clothing_img: Image.Image
    ) -> Image.Image:
        """ê¸°í•˜í•™ì  í”¼íŒ… í´ë°±"""
        
        person_array = np.array(person_img)
        clothing_array = np.array(clothing_img)
        
        # ê°„ë‹¨í•œ ì˜¤ë²„ë ˆì´
        result = person_array.copy()
        
        # ì˜· í¬ê¸° ì¡°ì • ë° ë°°ì¹˜
        h, w = result.shape[:2]
        cloth_resized = cv2.resize(clothing_array, (w//2, h//3))
        
        # ì¤‘ì•™ ìƒë‹¨ì— ë°°ì¹˜
        start_y = h//4
        start_x = w//4
        end_y = start_y + cloth_resized.shape[0]
        end_x = start_x + cloth_resized.shape[1]
        
        # ì•ŒíŒŒ ë¸”ë Œë”©
        alpha = 0.6
        result[start_y:end_y, start_x:end_x] = (
            alpha * cloth_resized + (1 - alpha) * result[start_y:end_y, start_x:end_x]
        ).astype(np.uint8)
        
        return Image.fromarray(result)
    
    async def _post_process_result(self, image: Image.Image) -> Image.Image:
        """ê²°ê³¼ í›„ì²˜ë¦¬"""
        try:
            # 1. í¬ê¸° ì¡°ì •
            output_size = self.config.output_size
            if image.size != output_size:
                image = image.resize(output_size, Image.Resampling.LANCZOS)
            
            # 2. ìƒ‰ìƒ ë³´ì •
            enhancer = None
            try:
                from PIL import ImageEnhance
                enhancer = ImageEnhance.Color(image)
                image = enhancer.enhance(1.1)  # ì•½ê°„ ì±„ë„ ì¦ê°€
            except ImportError:
                pass
            
            # 3. ì„ ëª…ë„ ì¦ê°€
            if enhancer:
                try:
                    sharpness_enhancer = ImageEnhance.Sharpness(image)
                    image = sharpness_enhancer.enhance(1.05)
                except:
                    pass
            
            return image
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ í›„ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return image
    
    async def _create_visualization(
        self, 
        person_img: Image.Image, 
        clothing_img: Image.Image, 
        result_img: Image.Image
    ) -> Optional[Image.Image]:
        """ì‹œê°í™” ìƒì„±"""
        try:
            # 3ë‹¨ê³„ ë¹„êµ ì´ë¯¸ì§€ ìƒì„±
            width, height = person_img.size
            
            # ìƒˆ ìº”ë²„ìŠ¤ ìƒì„± (3ë°° ë„ˆë¹„)
            visualization = Image.new('RGB', (width * 3, height), color='white')
            
            # ì´ë¯¸ì§€ë“¤ ë°°ì¹˜
            visualization.paste(person_img, (0, 0))
            visualization.paste(clothing_img, (width, 0))
            visualization.paste(result_img, (width * 2, 0))
            
            # í…ìŠ¤íŠ¸ ì¶”ê°€ (PIL ImageDraw ì‚¬ìš©)
            try:
                from PIL import ImageDraw, ImageFont
                draw = ImageDraw.Draw(visualization)
                
                labels = ["Original", "Clothing", "Result"]
                for i, label in enumerate(labels):
                    x = i * width + width // 2 - 30
                    y = height - 30
                    draw.text((x, y), label, fill='black')
            except ImportError:
                pass
            
            return visualization
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ ì‹œê°í™” ìƒì„± ì‹¤íŒ¨: {e}")
            return None
    
    async def cleanup(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        try:
            # ëª¨ë¸ ì •ë¦¬
            for key, model in self.loaded_models.items():
                try:
                    if hasattr(model, 'cpu'):
                        model.cpu()
                    del model
                except:
                    pass
            
            self.loaded_models.clear()
            
            # ìºì‹œ ì •ë¦¬
            with self.cache_lock:
                self.result_cache.clear()
            
            # ë©”ëª¨ë¦¬ ì •ë¦¬
            if hasattr(self.memory_manager, 'cleanup_memory'):
                self.memory_manager.cleanup_memory(aggressive=True)
            
            # ìŠ¤ë ˆë“œí’€ ì¢…ë£Œ
            self.thread_pool.shutdown(wait=True)
            
            self.logger.info("âœ… VirtualFittingStep ì •ë¦¬ ì™„ë£Œ")
            
        except Exception as e:
            self.logger.error(f"âŒ ì •ë¦¬ ì‹¤íŒ¨: {e}")

# í¸ì˜ í•¨ìˆ˜ë“¤
def create_virtual_fitting_step(**kwargs) -> VirtualFittingStepEnhanced:
    """VirtualFittingStep ìƒì„±"""
    return VirtualFittingStepEnhanced(**kwargs)

async def quick_virtual_fitting(
    person_image: Union[np.ndarray, Image.Image, str],
    clothing_image: Union[np.ndarray, Image.Image, str],
    **kwargs
) -> Dict[str, Any]:
    """ë¹ ë¥¸ ê°€ìƒ í”¼íŒ…"""
    step = create_virtual_fitting_step()
    await step.initialize()
    
    try:
        result = await step.process(person_image, clothing_image, **kwargs)
        return result
    finally:
        await step.cleanup()

# ëª¨ë“ˆ ì •ë³´
__version__ = "2.0.0"
__all__ = [
    "VirtualFittingStepEnhanced",
    "VirtualFittingConfig", 
    "FittingMethod",
    "QualityLevel",
    "create_virtual_fitting_step",
    "quick_virtual_fitting"
]

logger.info("âœ… VirtualFittingStep v2.0 ë¡œë“œ ì™„ë£Œ - ëª¨ë“  ì˜¤ë¥˜ í•´ê²°")
logger.info("ğŸ”§ MemoryManagerAdapter ì˜¤ë¥˜ ìˆ˜ì •")
logger.info("ğŸ”§ OOTDiffusion ì˜¤í”„ë¼ì¸ ëª¨ë“œ ì§€ì›")
logger.info("ğŸ”§ ê¸°í•˜í•™ì  í”¼íŒ… í´ë°± ì™„ì „ êµ¬í˜„")
logger.info("ğŸ”§ M3 Max ìµœì í™” í¬í•¨")
'''
    
    with open(step_path, 'w', encoding='utf-8') as f:
        f.write(enhanced_content)
    
    print(f"âœ… í–¥ìƒëœ VirtualFittingStep ìƒì„±: {step_path}")

def create_integration_script():
    """í†µí•© ìŠ¤í¬ë¦½íŠ¸ ìƒì„±"""
    
    script_path = PROJECT_ROOT / "integrate_virtual_fitting_v2.py"
    
    script_content = '''#!/usr/bin/env python3
"""
VirtualFittingStep v2.0 í†µí•© ìŠ¤í¬ë¦½íŠ¸
ê¸°ì¡´ íŒŒì¼ì„ ë°±ì—…í•˜ê³  ìƒˆ ë²„ì „ìœ¼ë¡œ êµì²´
"""

import os
import sys
import shutil
from pathlib import Path

def integrate_virtual_fitting_v2():
    """VirtualFittingStep v2.0 í†µí•©"""
    
    project_root = Path(__file__).parent
    
    # ê¸°ì¡´ íŒŒì¼ ê²½ë¡œ
    original_file = project_root / "backend/app/ai_pipeline/steps/step_06_virtual_fitting.py"
    enhanced_file = project_root / "backend/app/ai_pipeline/steps/step_06_virtual_fitting_enhanced.py"
    
    if not enhanced_file.exists():
        print(f"âŒ í–¥ìƒëœ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {enhanced_file}")
        return False
    
    try:
        # 1. ê¸°ì¡´ íŒŒì¼ ë°±ì—…
        if original_file.exists():
            backup_file = original_file.with_suffix('.py.backup_v1')
            shutil.copy2(original_file, backup_file)
            print(f"âœ… ê¸°ì¡´ íŒŒì¼ ë°±ì—…: {backup_file}")
        
        # 2. ìƒˆ íŒŒì¼ë¡œ êµì²´
        shutil.copy2(enhanced_file, original_file)
        print(f"âœ… VirtualFittingStep v2.0 ì ìš©: {original_file}")
        
        # 3. ì„ì‹œ íŒŒì¼ ì‚­ì œ
        enhanced_file.unlink()
        print(f"âœ… ì„ì‹œ íŒŒì¼ ì‚­ì œ: {enhanced_file}")
        
        print("\\nğŸ‰ VirtualFittingStep v2.0 í†µí•© ì™„ë£Œ!")
        print("\\në³€ê²½ì‚¬í•­:")
        print("- MemoryManagerAdapter ì˜¤ë¥˜ ì™„ì „ í•´ê²°")
        print("- OOTDiffusion ì˜¤í”„ë¼ì¸ ëª¨ë“œ ì§€ì›")
        print("- ê¸°í•˜í•™ì  í”¼íŒ… í´ë°± êµ¬í˜„")
        print("- M3 Max ìµœì í™” í¬í•¨")
        print("- ì•ˆì •ì„± í¬ê²Œ í–¥ìƒ")
        
        return True
        
    except Exception as e:
        print(f"âŒ í†µí•© ì‹¤íŒ¨: {e}")
        return False

if __name__ == "__main__":
    integrate_virtual_fitting_v2()
'''
    
    with open(script_path, 'w', encoding='utf-8') as f:
        f.write(script_content)
    
    print(f"âœ… í†µí•© ìŠ¤í¬ë¦½íŠ¸ ìƒì„±: {script_path}")

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸš€ VirtualFittingStep í•µì‹¬ ê¸°ëŠ¥ ì™„ì„± ì‹œì‘...")
    
    try:
        # 1. í–¥ìƒëœ VirtualFittingStep ìƒì„±
        create_enhanced_virtual_fitting()
        
        # 2. í†µí•© ìŠ¤í¬ë¦½íŠ¸ ìƒì„±
        create_integration_script()
        
        print("\nğŸ‰ VirtualFittingStep í•µì‹¬ ê¸°ëŠ¥ ì™„ì„±!")
        print("\nì‹¤í–‰ ìˆœì„œ:")
        print("1. ë©”ëª¨ë¦¬ ê´€ë¦¬ì ìˆ˜ì •: python memory_manager_fix.py")
        print("2. OOTDiffusion ê²½ë¡œ ìˆ˜ì •: python ootdiffusion_path_fix.py")
        print("3. VirtualFittingStep í†µí•©: python integrate_virtual_fitting_v2.py")
        print("4. ì„œë²„ ì¬ì‹œì‘: cd backend && python app/main.py")
        print("5. ê°€ìƒ í”¼íŒ… í…ŒìŠ¤íŠ¸")
        
    except Exception as e:
        print(f"âŒ í•µì‹¬ ê¸°ëŠ¥ ì™„ì„± ì‹¤íŒ¨: {e}")
        import traceback
        print(traceback.format_exc())

if __name__ == "__main__":
    main()