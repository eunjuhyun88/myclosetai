#!/usr/bin/env python3
"""
ğŸ” MyCloset AI - ì „ì²´ ì‹œìŠ¤í…œ AI ëª¨ë¸ ê²€ìƒ‰ ìŠ¤í¬ë¦½íŠ¸
macOS ì „ì²´ì—ì„œ AI ëª¨ë¸ íŒŒì¼ë“¤ì„ ì°¾ì•„ë‚´ëŠ” ê°•ë ¥í•œ ê²€ìƒ‰ ë„êµ¬

ê¸°ëŠ¥:
- ì „ì²´ ì‹œìŠ¤í…œ ìŠ¤ìº” (/, /Users, /Applications ë“±)
- íŠ¹ì • ëª¨ë¸ ê²€ìƒ‰ (unet_vton, stable-diffusion ë“±)
- í¬ê¸°/ë‚ ì§œ í•„í„°ë§
- ì¤‘ë³µ ì œê±° ë° ë¶„ì„
- ì•ˆì „í•œ ë³µì‚¬ ë° ë°°ì¹˜

ì‚¬ìš©ë²•:
python comprehensive_finder.py                           # ì „ì²´ AI ëª¨ë¸ ê²€ìƒ‰
python comprehensive_finder.py --model unet_vton         # íŠ¹ì • ëª¨ë¸ë§Œ ê²€ìƒ‰
python comprehensive_finder.py --deep-scan               # ê¹Šì€ ê²€ìƒ‰ (ì˜¤ë˜ ê±¸ë¦¼)
python comprehensive_finder.py --downloads-only          # ë‹¤ìš´ë¡œë“œ í´ë”ë§Œ
python comprehensive_finder.py --copy-best               # ìµœê³  í›„ë³´ ìë™ ë³µì‚¬
"""

import os
import sys
import hashlib
import time
import subprocess
from pathlib import Path
from typing import List, Dict, Tuple, Optional, Set
from dataclasses import dataclass, field
from collections import defaultdict
import argparse
import json

# ì•ˆì „í•œ import (conda í™˜ê²½ í˜¸í™˜)
try:
    from tqdm import tqdm
    TQDM_AVAILABLE = True
except ImportError:
    TQDM_AVAILABLE = False
    print("âš ï¸ tqdm ì—†ìŒ. ì§„í–‰ë¥  í‘œì‹œ ë¶ˆê°€")

@dataclass
class ModelCandidate:
    """ëª¨ë¸ í›„ë³´ ì •ë³´"""
    path: Path
    name: str
    size_mb: float
    model_type: str
    confidence: float
    reason: List[str] = field(default_factory=list)
    checksum: str = ""
    last_modified: float = 0.0
    file_count: int = 0
    source_category: str = "unknown"

class ComprehensiveModelFinder:
    """ì „ì²´ ì‹œìŠ¤í…œ AI ëª¨ë¸ ê²€ìƒ‰ê¸°"""
    
    def __init__(self, target_model: str = "unet_vton", deep_scan: bool = False):
        self.target_model = target_model.lower()
        self.deep_scan = deep_scan
        self.found_candidates: List[ModelCandidate] = []
        
        # AI ëª¨ë¸ í™•ì¥ìë“¤
        self.model_extensions = {
            '.pth', '.pt', '.bin', '.safetensors', '.ckpt', '.h5', 
            '.pb', '.onnx', '.tflite', '.pkl', '.pickle', '.model',
            '.weights', '.params', '.caffemodel', '.prototxt'
        }
        
        # ê²€ìƒ‰ ê²½ë¡œë“¤ (ìš°ì„ ìˆœìœ„ë³„)
        self.search_paths = self._get_comprehensive_paths()
        
        # ëª¨ë¸ë³„ ê²€ìƒ‰ íŒ¨í„´
        self.model_patterns = {
            "unet_vton": [
                "*unet*vton*", "*vton*unet*", "*unet_vton*", 
                "*ootd*unet*", "*diffusion*unet*"
            ],
            "stable_diffusion": [
                "*stable*diffusion*", "*sd*", "*runwayml*",
                "*stabilityai*", "*stable-diffusion*"
            ],
            "openpose": [
                "*openpose*", "*pose*model*", "*body*pose*"
            ],
            "u2net": [
                "*u2net*", "*background*removal*", "*salient*"
            ],
            "sam": [
                "*sam*vit*", "*segment*anything*", "*mobile*sam*"
            ],
            "clip": [
                "*clip*vit*", "*openai*clip*", "*vision*transformer*"
            ]
        }
        
        print(f"ğŸ¯ ê²€ìƒ‰ ëŒ€ìƒ: {target_model}")
        print(f"ğŸ” ê²€ìƒ‰ ëª¨ë“œ: {'ê¹Šì€ ê²€ìƒ‰' if deep_scan else 'ë¹ ë¥¸ ê²€ìƒ‰'}")
        print(f"ğŸ“ ê²€ìƒ‰ ê²½ë¡œ: {len(self.search_paths)}ê°œ")
    
    def _get_comprehensive_paths(self) -> List[Path]:
        """í¬ê´„ì  ê²€ìƒ‰ ê²½ë¡œ ëª©ë¡ ìƒì„±"""
        paths = []
        home = Path.home()
        
        # 1. ì‚¬ìš©ì ì£¼ìš” í´ë”ë“¤
        user_paths = [
            home / "Downloads",
            home / "Desktop", 
            home / "Documents",
            home / "Documents" / "AI_Models",
            home / "Documents" / "models",
            home / "Library" / "Application Support",
            home / "Applications",
        ]
        
        # 2. ê°œë°œ ê´€ë ¨ í´ë”ë“¤
        dev_paths = [
            home / "anaconda3",
            home / "miniconda3", 
            home / "miniforge3",
            home / "opt" / "homebrew",
            home / "Developer",
            home / "Projects",
            home / "GitHub",
            home / "git",
            home / "code",
            home / "workspace"
        ]
        
        # 3. ìºì‹œ í´ë”ë“¤
        cache_paths = [
            home / ".cache",
            home / ".cache" / "huggingface",
            home / ".cache" / "torch", 
            home / ".cache" / "transformers",
            home / ".cache" / "diffusers",
            home / ".torch",
            home / ".transformers_cache",
            home / ".huggingface"
        ]
        
        # 4. conda/pip í™˜ê²½ë“¤
        conda_paths = []
        if os.environ.get('CONDA_PREFIX'):
            conda_base = Path(os.environ['CONDA_PREFIX']).parent.parent
            conda_paths.extend([
                conda_base / "envs",
                conda_base / "pkgs",
                conda_base / "lib"
            ])
        
        # 5. ì‹œìŠ¤í…œ ê²½ë¡œë“¤ (deep_scanì¸ ê²½ìš°ë§Œ)
        system_paths = []
        if self.deep_scan:
            system_paths.extend([
                Path("/opt"),
                Path("/usr/local"), 
                Path("/Applications"),
                Path("/Library"),
                Path("/tmp")
            ])
        
        # 6. í˜„ì¬ í”„ë¡œì íŠ¸ ê´€ë ¨
        current_dir = Path.cwd()
        project_paths = [
            current_dir,
            current_dir.parent,
            current_dir / "models",
            current_dir / "checkpoints",
            current_dir / "ai_models"
        ]
        
        # ëª¨ë“  ê²½ë¡œ ë³‘í•©
        all_paths = user_paths + dev_paths + cache_paths + conda_paths + system_paths + project_paths
        
        # ì¡´ì¬í•˜ê³  ì ‘ê·¼ ê°€ëŠ¥í•œ ê²½ë¡œë§Œ í•„í„°ë§
        valid_paths = []
        for path in all_paths:
            try:
                if path.exists() and path.is_dir() and os.access(path, os.R_OK):
                    valid_paths.append(path)
            except (OSError, PermissionError):
                continue
        
        # ì¤‘ë³µ ì œê±°
        unique_paths = []
        seen_paths = set()
        for path in valid_paths:
            resolved = path.resolve()
            if str(resolved) not in seen_paths:
                unique_paths.append(path)
                seen_paths.add(str(resolved))
        
        return unique_paths
    
    def search_with_find_command(self, search_pattern: str, max_depth: int = 10) -> List[Path]:
        """macOS find ëª…ë ¹ì–´ë¥¼ ì‚¬ìš©í•œ ë¹ ë¥¸ ê²€ìƒ‰"""
        found_paths = []
        
        for search_path in self.search_paths:
            try:
                # find ëª…ë ¹ì–´ ì‹¤í–‰
                cmd = [
                    "find", str(search_path),
                    "-maxdepth", str(max_depth),
                    "-name", search_pattern,
                    "-type", "f", "-o", "-type", "d"
                ]
                
                result = subprocess.run(
                    cmd, 
                    capture_output=True, 
                    text=True, 
                    timeout=30
                )
                
                if result.returncode == 0:
                    for line in result.stdout.strip().split('\n'):
                        if line:
                            path = Path(line)
                            if path.exists():
                                found_paths.append(path)
                                
            except (subprocess.TimeoutExpired, subprocess.SubprocessError, OSError):
                continue
        
        return found_paths
    
    def search_with_python(self, patterns: List[str]) -> List[Path]:
        """Pythonì„ ì‚¬ìš©í•œ ì„¸ë°€í•œ ê²€ìƒ‰"""
        found_paths = []
        
        for search_path in self.search_paths:
            try:
                for pattern in patterns:
                    for path in search_path.rglob(pattern):
                        if path.exists():
                            found_paths.append(path)
            except (OSError, PermissionError):
                continue
        
        return found_paths
    
    def comprehensive_search(self) -> List[ModelCandidate]:
        """í¬ê´„ì  ëª¨ë¸ ê²€ìƒ‰"""
        print("ğŸ” í¬ê´„ì  AI ëª¨ë¸ ê²€ìƒ‰ ì‹œì‘...")
        
        candidates = []
        patterns = self.model_patterns.get(self.target_model, [f"*{self.target_model}*"])
        
        # 1. find ëª…ë ¹ì–´ë¡œ ë¹ ë¥¸ ê²€ìƒ‰
        print("âš¡ find ëª…ë ¹ì–´ë¡œ ë¹ ë¥¸ ê²€ìƒ‰...")
        all_found = []
        for pattern in patterns:
            found = self.search_with_find_command(pattern)
            all_found.extend(found)
            print(f"   íŒ¨í„´ '{pattern}': {len(found)}ê°œ ë°œê²¬")
        
        # 2. Pythonìœ¼ë¡œ ì¶”ê°€ ê²€ìƒ‰
        print("ğŸ Pythonìœ¼ë¡œ ì„¸ë°€í•œ ê²€ìƒ‰...")
        python_found = self.search_with_python(patterns)
        all_found.extend(python_found)
        print(f"   Python ê²€ìƒ‰: {len(python_found)}ê°œ ì¶”ê°€ ë°œê²¬")
        
        # 3. íŠ¹ë³„ ê²€ìƒ‰ (HuggingFace, conda ë“±)
        print("ğŸ” íŠ¹ë³„ ìœ„ì¹˜ ê²€ìƒ‰...")
        special_found = self._search_special_locations()
        all_found.extend(special_found)
        print(f"   íŠ¹ë³„ ìœ„ì¹˜: {len(special_found)}ê°œ ë°œê²¬")
        
        # ì¤‘ë³µ ì œê±°
        unique_paths = []
        seen_paths = set()
        for path in all_found:
            try:
                resolved = str(path.resolve())
                if resolved not in seen_paths:
                    unique_paths.append(path)
                    seen_paths.add(resolved)
            except OSError:
                continue
        
        print(f"âœ… ì´ {len(unique_paths)}ê°œ ê³ ìœ  ê²½ë¡œ ë°œê²¬")
        
        # 4. ê° ê²½ë¡œ ë¶„ì„
        print("ğŸ“Š í›„ë³´ ë¶„ì„ ì¤‘...")
        iterator = tqdm(unique_paths, desc="ëª¨ë¸ ë¶„ì„") if TQDM_AVAILABLE else unique_paths
        
        for path in iterator:
            if self._is_valid_candidate(path):
                candidate = self._analyze_candidate(path)
                candidates.append(candidate)
        
        # 5. ì‹ ë¢°ë„ìˆœ ì •ë ¬
        candidates.sort(key=lambda x: x.confidence, reverse=True)
        
        self.found_candidates = candidates
        print(f"ğŸ¯ ìµœì¢… {len(candidates)}ê°œ ìœ íš¨ í›„ë³´ ë°œê²¬!")
        
        return candidates
    
    def _search_special_locations(self) -> List[Path]:
        """íŠ¹ë³„ ìœ„ì¹˜ë“¤ ê²€ìƒ‰"""
        special_paths = []
        
        # HuggingFace ëª¨ë¸ë“¤
        hf_patterns = [
            "~/.cache/huggingface/hub/models--*",
            "~/.cache/huggingface/transformers/*",
            "*/huggingface_cache/models--*"
        ]
        
        for pattern in hf_patterns:
            expanded = Path(pattern).expanduser()
            try:
                if expanded.exists():
                    for path in expanded.parent.rglob(expanded.name):
                        if self.target_model in str(path).lower():
                            special_paths.append(path)
            except (OSError, PermissionError):
                continue
        
        # PyTorch Hub
        torch_hub = Path.home() / ".cache" / "torch" / "hub"
        if torch_hub.exists():
            try:
                for path in torch_hub.rglob("*"):
                    if self.target_model in str(path).lower():
                        special_paths.append(path)
            except (OSError, PermissionError):
                pass
        
        return special_paths
    
    def _is_valid_candidate(self, path: Path) -> bool:
        """ìœ íš¨í•œ í›„ë³´ì¸ì§€ íŒë‹¨"""
        try:
            if not path.exists():
                return False
            
            path_str = str(path).lower()
            name_str = path.name.lower()
            
            # ëŒ€ìƒ ëª¨ë¸ í‚¤ì›Œë“œ í¬í•¨ í™•ì¸
            if self.target_model not in path_str and self.target_model not in name_str:
                return False
            
            # ì œì™¸í•  íŒ¨í„´ë“¤
            exclude_patterns = [
                '__pycache__', '.git', '.svn', 'node_modules',
                '.DS_Store', 'Thumbs.db', '.tmp', '.temp'
            ]
            
            if any(pattern in path_str for pattern in exclude_patterns):
                return False
            
            # í´ë”ì¸ ê²½ìš°
            if path.is_dir():
                # ë‚´ë¶€ì— ëª¨ë¸ íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸
                try:
                    model_files = []
                    for ext in self.model_extensions:
                        model_files.extend(list(path.rglob(f"*{ext}")))
                    return len(model_files) > 0
                except OSError:
                    return False
            
            # íŒŒì¼ì¸ ê²½ìš°
            elif path.is_file():
                # ëª¨ë¸ íŒŒì¼ í™•ì¥ì í™•ì¸
                if path.suffix.lower() not in self.model_extensions:
                    return False
                
                # ìµœì†Œ í¬ê¸° í™•ì¸ (1MB)
                try:
                    size_mb = path.stat().st_size / (1024 * 1024)
                    return size_mb >= 1.0
                except OSError:
                    return False
            
            return False
            
        except Exception:
            return False
    
    def _analyze_candidate(self, path: Path) -> ModelCandidate:
        """í›„ë³´ ìƒì„¸ ë¶„ì„"""
        try:
            candidate = ModelCandidate(
                path=path,
                name=path.name,
                size_mb=0.0,
                model_type=self.target_model,
                confidence=0.0,
                reason=[],
                last_modified=0.0,
                file_count=0,
                source_category=self._categorize_source(path)
            )
            
            # í¬ê¸° ë° íŒŒì¼ ìˆ˜ ê³„ì‚°
            if path.is_file():
                stat = path.stat()
                candidate.size_mb = stat.st_size / (1024 * 1024)
                candidate.last_modified = stat.st_mtime
                candidate.file_count = 1
            else:
                # í´ë”ì¸ ê²½ìš°
                total_size = 0
                file_count = 0
                latest_time = 0
                
                for file_path in path.rglob("*"):
                    if file_path.is_file():
                        try:
                            stat = file_path.stat()
                            total_size += stat.st_size
                            file_count += 1
                            latest_time = max(latest_time, stat.st_mtime)
                        except OSError:
                            pass
                
                candidate.size_mb = total_size / (1024 * 1024)
                candidate.file_count = file_count
                candidate.last_modified = latest_time
            
            # ì‹ ë¢°ë„ ê³„ì‚°
            candidate.confidence = self._calculate_confidence(candidate)
            
            return candidate
            
        except Exception as e:
            return ModelCandidate(
                path=path,
                name=path.name,
                size_mb=0.0,
                model_type="error",
                confidence=0.0,
                reason=[f"ë¶„ì„ ì˜¤ë¥˜: {e}"]
            )
    
    def _categorize_source(self, path: Path) -> str:
        """ì†ŒìŠ¤ ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜"""
        path_str = str(path).lower()
        
        if "downloads" in path_str:
            return "downloads"
        elif "huggingface" in path_str or "hf_" in path_str:
            return "huggingface_cache"
        elif "torch" in path_str and "hub" in path_str:
            return "pytorch_hub"
        elif "conda" in path_str or "anaconda" in path_str or "miniconda" in path_str:
            return "conda_env"
        elif "desktop" in path_str:
            return "desktop"
        elif "documents" in path_str:
            return "documents"
        elif "applications" in path_str:
            return "applications"
        elif "cache" in path_str:
            return "cache"
        elif "git" in path_str or "github" in path_str:
            return "git_repo"
        else:
            return "other"
    
    def _calculate_confidence(self, candidate: ModelCandidate) -> float:
        """ì‹ ë¢°ë„ ì ìˆ˜ ê³„ì‚°"""
        confidence = 0.0
        
        path_str = str(candidate.path).lower()
        name_str = candidate.name.lower()
        
        # ì´ë¦„ ë§¤ì¹­ ì ìˆ˜
        if candidate.name.lower() == self.target_model:
            confidence += 1.0
            candidate.reason.append("ì •í™•í•œ ì´ë¦„ ë§¤ì¹­")
        elif self.target_model in name_str:
            confidence += 0.7
            candidate.reason.append("ì´ë¦„ì— ëŒ€ìƒ í¬í•¨")
        elif self.target_model in path_str:
            confidence += 0.5
            candidate.reason.append("ê²½ë¡œì— ëŒ€ìƒ í¬í•¨")
        
        # í¬ê¸° ì ìˆ˜
        if 100 <= candidate.size_mb <= 5000:  # 100MB-5GB
            confidence += 0.3
            candidate.reason.append("ì ì • í¬ê¸° ë²”ìœ„")
        elif candidate.size_mb > 5000:
            confidence += 0.1
            candidate.reason.append("ëŒ€ìš©ëŸ‰ ëª¨ë¸")
        elif candidate.size_mb < 10:
            confidence -= 0.2
            candidate.reason.append("í¬ê¸°ê°€ ì‘ìŒ")
        
        # ì†ŒìŠ¤ ì ìˆ˜
        source_scores = {
            "huggingface_cache": 0.3,
            "pytorch_hub": 0.2,
            "downloads": 0.2,
            "git_repo": 0.1,
            "conda_env": 0.1,
            "desktop": 0.05,
            "documents": 0.05
        }
        
        if candidate.source_category in source_scores:
            confidence += source_scores[candidate.source_category]
            candidate.reason.append(f"{candidate.source_category} ê²½ë¡œ")
        
        # ìµœì‹ ì„± ì ìˆ˜ (ìµœê·¼ 1ê°œì›” ë‚´)
        if candidate.last_modified > time.time() - (30 * 24 * 3600):
            confidence += 0.1
            candidate.reason.append("ìµœê·¼ íŒŒì¼")
        
        # íŒŒì¼ ìˆ˜ ì ìˆ˜ (í´ë”ì¸ ê²½ìš°)
        if candidate.file_count > 1:
            confidence += 0.1
            candidate.reason.append(f"{candidate.file_count}ê°œ íŒŒì¼ í¬í•¨")
        
        return round(confidence, 2)
    
    def print_results(self, limit: int = 20):
        """ê²€ìƒ‰ ê²°ê³¼ ì¶œë ¥"""
        if not self.found_candidates:
            print("âŒ í›„ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        print(f"\nğŸ” ë°œê²¬ëœ '{self.target_model}' í›„ë³´ë“¤:")
        print("=" * 100)
        
        # ì†ŒìŠ¤ë³„ í†µê³„
        source_stats = defaultdict(int)
        for candidate in self.found_candidates:
            source_stats[candidate.source_category] += 1
        
        print(f"\nğŸ“Š ì†ŒìŠ¤ë³„ ë¶„í¬:")
        for source, count in sorted(source_stats.items()):
            print(f"   {source}: {count}ê°œ")
        
        print(f"\nğŸ† ìƒìœ„ {min(limit, len(self.found_candidates))}ê°œ í›„ë³´:")
        
        for i, candidate in enumerate(self.found_candidates[:limit], 1):
            confidence_emoji = "ğŸŸ¢" if candidate.confidence >= 1.0 else "ğŸŸ¡" if candidate.confidence >= 0.5 else "ğŸ”´"
            type_emoji = "ğŸ“" if candidate.path.is_dir() else "ğŸ“„"
            
            print(f"\n{i}. {confidence_emoji} {type_emoji} {candidate.name}")
            print(f"   ğŸ“ ê²½ë¡œ: {candidate.path}")
            print(f"   ğŸ“Š ì‹ ë¢°ë„: {candidate.confidence}")
            print(f"   ğŸ’¾ í¬ê¸°: {candidate.size_mb:.1f}MB")
            print(f"   ğŸ·ï¸ ì†ŒìŠ¤: {candidate.source_category}")
            if candidate.path.is_dir():
                print(f"   ğŸ“ íŒŒì¼ ìˆ˜: {candidate.file_count}ê°œ")
            print(f"   ğŸ•’ ìˆ˜ì •ì¼: {time.strftime('%Y-%m-%d %H:%M', time.localtime(candidate.last_modified))}")
            print(f"   ğŸ’¡ ì´ìœ : {', '.join(candidate.reason)}")
    
    def save_results(self, output_file: Path):
        """ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥"""
        results = {
            "search_info": {
                "target_model": self.target_model,
                "deep_scan": self.deep_scan,
                "timestamp": time.time(),
                "total_candidates": len(self.found_candidates)
            },
            "candidates": []
        }
        
        for candidate in self.found_candidates:
            results["candidates"].append({
                "path": str(candidate.path),
                "name": candidate.name,
                "size_mb": candidate.size_mb,
                "confidence": candidate.confidence,
                "source_category": candidate.source_category,
                "file_count": candidate.file_count,
                "last_modified": candidate.last_modified,
                "reason": candidate.reason
            })
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, ensure_ascii=False)
        
        print(f"ğŸ’¾ ê²°ê³¼ ì €ì¥: {output_file}")
    
    def copy_best_candidate(self, target_dir: Path) -> bool:
        """ìµœê³  í›„ë³´ë¥¼ íƒ€ê²Ÿ ë””ë ‰í† ë¦¬ë¡œ ë³µì‚¬"""
        if not self.found_candidates:
            print("âŒ ë³µì‚¬í•  í›„ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return False
        
        best_candidate = self.found_candidates[0]
        
        print(f"ğŸ“‹ ìµœê³  í›„ë³´ ë³µì‚¬:")
        print(f"   ì›ë³¸: {best_candidate.path}")
        print(f"   ì‹ ë¢°ë„: {best_candidate.confidence}")
        print(f"   í¬ê¸°: {best_candidate.size_mb:.1f}MB")
        
        try:
            target_dir.mkdir(parents=True, exist_ok=True)
            
            if best_candidate.path.is_dir():
                target_path = target_dir / best_candidate.name
                if target_path.exists():
                    backup_path = target_dir / f"{best_candidate.name}_backup_{int(time.time())}"
                    print(f"âš ï¸ ê¸°ì¡´ í´ë” ë°±ì—…: {backup_path}")
                    target_path.rename(backup_path)
                
                import shutil
                shutil.copytree(str(best_candidate.path), str(target_path))
                print(f"âœ… í´ë” ë³µì‚¬ ì™„ë£Œ: {target_path}")
            else:
                target_path = target_dir / best_candidate.name
                if target_path.exists():
                    backup_path = target_dir / f"{best_candidate.path.stem}_backup_{int(time.time())}{best_candidate.path.suffix}"
                    print(f"âš ï¸ ê¸°ì¡´ íŒŒì¼ ë°±ì—…: {backup_path}")
                    target_path.rename(backup_path)
                
                import shutil
                shutil.copy2(str(best_candidate.path), str(target_path))
                print(f"âœ… íŒŒì¼ ë³µì‚¬ ì™„ë£Œ: {target_path}")
            
            return True
            
        except Exception as e:
            print(f"âŒ ë³µì‚¬ ì‹¤íŒ¨: {e}")
            return False

def main():
    parser = argparse.ArgumentParser(description="ì „ì²´ ì‹œìŠ¤í…œ AI ëª¨ë¸ ê²€ìƒ‰ ë„êµ¬")
    parser.add_argument("--model", default="unet_vton", help="ê²€ìƒ‰í•  ëª¨ë¸ëª…")
    parser.add_argument("--deep-scan", action="store_true", help="ê¹Šì€ ê²€ìƒ‰ í™œì„±í™”")
    parser.add_argument("--downloads-only", action="store_true", help="ë‹¤ìš´ë¡œë“œ í´ë”ë§Œ ê²€ìƒ‰")
    parser.add_argument("--copy-best", action="store_true", help="ìµœê³  í›„ë³´ ìë™ ë³µì‚¬")
    parser.add_argument("--target-dir", type=Path, help="ë³µì‚¬ ëŒ€ìƒ ë””ë ‰í† ë¦¬")
    parser.add_argument("--output", type=Path, help="ê²°ê³¼ JSON ì €ì¥ íŒŒì¼")
    parser.add_argument("--limit", type=int, default=20, help="ì¶œë ¥í•  ìµœëŒ€ í›„ë³´ ìˆ˜")
    
    args = parser.parse_args()
    
    print("ğŸ” MyCloset AI - ì „ì²´ ì‹œìŠ¤í…œ ëª¨ë¸ ê²€ìƒ‰ê¸°")
    print("=" * 60)
    
    # ê²€ìƒ‰ê¸° ì´ˆê¸°í™”
    finder = ComprehensiveModelFinder(
        target_model=args.model,
        deep_scan=args.deep_scan
    )
    
    # ë‹¤ìš´ë¡œë“œ í´ë”ë§Œ ê²€ìƒ‰í•˜ëŠ” ê²½ìš°
    if args.downloads_only:
        finder.search_paths = [
            Path.home() / "Downloads",
            Path.home() / "Desktop",
            Path.home() / "Documents" / "Downloads"
        ]
        finder.search_paths = [p for p in finder.search_paths if p.exists()]
        print(f"ğŸ“ ë‹¤ìš´ë¡œë“œ í´ë”ë§Œ ê²€ìƒ‰: {len(finder.search_paths)}ê°œ ê²½ë¡œ")
    
    # ê²€ìƒ‰ ì‹¤í–‰
    candidates = finder.comprehensive_search()
    
    # ê²°ê³¼ ì¶œë ¥
    finder.print_results(limit=args.limit)
    
    # ê²°ê³¼ ì €ì¥
    if args.output:
        finder.save_results(args.output)
    
    # ìµœê³  í›„ë³´ ë³µì‚¬
    if args.copy_best and candidates:
        if args.target_dir:
            target_dir = args.target_dir
        else:
            target_dir = Path.cwd() / "backend" / "app" / "ai_pipeline" / "models" / "checkpoints" / f"step_06_virtual_fitting"
        
        print(f"\nğŸš€ ìµœê³  í›„ë³´ë¥¼ {target_dir}ë¡œ ë³µì‚¬...")
        success = finder.copy_best_candidate(target_dir)
        
        if success:
            print("âœ… ë³µì‚¬ ì™„ë£Œ! ê²€ì¦ì„ ì‹¤í–‰í•˜ì„¸ìš”.")
            print(f"   python verify_models.py --step 6")

if __name__ == "__main__":
    main()