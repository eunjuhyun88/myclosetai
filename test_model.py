#!/usr/bin/env python3
import sys
import os
sys.path.append(os.path.dirname(__file__))

from step_03_cloth_segmentation import create_cloth_segmentation_step
import numpy as np
import torch
import cv2

def test_model():
    # ìŠ¤í… ìƒì„± ë° ì´ˆê¸°í™”
    step = create_cloth_segmentation_step()
    step.initialize()
    
    # í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ìƒì„±
    test_image = np.random.randint(0, 255, (512, 512, 3), dtype=np.uint8)
    test_image = cv2.cvtColor(test_image, cv2.COLOR_BGR2RGB)
    test_image = cv2.resize(test_image, (512, 512))
    test_image = test_image.astype(np.float32) / 255.0
    
    # U2Net ì „ì²˜ë¦¬
    test_image = (test_image - np.array([0.485, 0.456, 0.406])) / np.array([0.229, 0.224, 0.225])
    test_tensor = torch.from_numpy(test_image).permute(2, 0, 1).unsqueeze(0).float()
    test_tensor = test_tensor.to(step.device)
    
    # ëª¨ë¸ ê°€ì ¸ì˜¤ê¸°
    model = step.segmentation_models['u2net_cloth']
    model.eval()
    
    print(f"ğŸ” ëª¨ë¸ íƒ€ì…: {type(model)}")
    print(f"ğŸ” ì…ë ¥ í…ì„œ shape: {test_tensor.shape}")
    
    # ì¶”ë¡  ìˆ˜í–‰
    with torch.no_grad():
        output = model(test_tensor)
        print(f"ğŸ” U2Net ëª¨ë¸ ì¶œë ¥ shape: {output.shape}")
        print(f"ğŸ” U2Net ëª¨ë¸ ì¶œë ¥ íƒ€ì…: {type(output)}")
        print(f"ğŸ” U2Net ëª¨ë¸ ì¶œë ¥ ê°’ ë²”ìœ„: {output.min().item():.3f} - {output.max().item():.3f}")
        
        # ë§ˆìŠ¤í¬ ìƒì„±
        mask = torch.sigmoid(output).cpu().numpy()[0, 0]
        mask = (mask > 0.5).astype(np.uint8)
        print(f"ğŸ” ë§ˆìŠ¤í¬ shape: {mask.shape}")
        print(f"ğŸ” ë§ˆìŠ¤í¬ ê°’ ë²”ìœ„: {mask.min()} - {mask.max()}")
        print(f"ğŸ” ë§ˆìŠ¤í¬ í‰ê· : {np.mean(mask):.3f}")

if __name__ == "__main__":
    test_model()
