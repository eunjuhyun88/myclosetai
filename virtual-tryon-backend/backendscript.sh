# ============================================================================
# 1. requirements.txt - Python ì˜ì¡´ì„±
# ============================================================================

# FastAPI ë° ì›¹ ì„œë²„
fastapi==0.104.1
uvicorn[standard]==0.24.0
python-multipart==0.0.6

# ì´ë¯¸ì§€ ì²˜ë¦¬
Pillow==10.1.0
opencv-python==4.8.1.78
scikit-image==0.22.0

# ë”¥ëŸ¬ë‹ ë° AI
torch==2.1.0
torchvision==0.16.0
numpy==1.24.3
scipy==1.11.4
scikit-learn==1.3.2

# Computer Vision
mediapipe==0.10.7
# detectron2 ì„¤ì¹˜ëŠ” ë³„ë„ ìŠ¤í¬ë¦½íŠ¸ë¡œ (ì„ íƒì‚¬í•­)

# ë°ì´í„° ê²€ì¦
pydantic==2.5.0
pydantic-settings==2.1.0

# íŒŒì¼ ì²˜ë¦¬
aiofiles==23.2.1
python-dotenv==1.0.0

# ë¡œê¹… ë° ëª¨ë‹ˆí„°ë§
structlog==23.1.0
prometheus-client==0.19.0

# ìºì‹± (ì„ íƒì‚¬í•­)
redis==5.0.0

# ìœ í‹¸ë¦¬í‹°
tqdm==4.66.1
requests==2.31.0

# ============================================================================
# 2. requirements-dev.txt - ê°œë°œ ì˜ì¡´ì„±
# ============================================================================

# í…ŒìŠ¤íŒ…
pytest==7.4.3
pytest-asyncio==0.21.1
pytest-cov==4.1.0
httpx==0.25.2

# ì½”ë“œ í’ˆì§ˆ
black==23.11.0
flake8==6.1.0
isort==5.12.0
mypy==1.7.1

# ê°œë°œ ë„êµ¬
jupyter==1.0.0
ipython==8.17.2

# ============================================================================
# 3. .env.example - í™˜ê²½ë³€ìˆ˜ ì˜ˆì‹œ
# ============================================================================

# Application Settings
APP_NAME=MyCloset AI Backend
APP_VERSION=1.0.0
DEBUG=false
HOST=0.0.0.0
PORT=8000

# CORS Settings
CORS_ORIGINS=http://localhost:3000,http://localhost:3001,http://127.0.0.1:3000

# File Upload Settings
MAX_UPLOAD_SIZE=52428800  # 50MB
ALLOWED_EXTENSIONS=jpg,jpeg,png,webp,bmp

# AI Model Settings
DEFAULT_MODEL=ootd
USE_GPU=true
DEVICE=cuda
IMAGE_SIZE=512
MAX_WORKERS=4
BATCH_SIZE=1

# Paths (ìë™ìœ¼ë¡œ ì„¤ì •ë˜ì§€ë§Œ í•„ìš”ì‹œ ì˜¤ë²„ë¼ì´ë“œ ê°€ëŠ¥)
# PROJECT_ROOT=/app
# AI_MODELS_DIR=/app/ai_models
# STATIC_DIR=/app/static
# UPLOAD_DIR=/app/static/uploads
# RESULTS_DIR=/app/static/results
# TEMP_DIR=/app/temp
# LOGS_DIR=/app/logs

# Performance Settings
CACHE_TTL=3600

# Logging
LOG_LEVEL=INFO
LOG_FILE=

# Redis (ì„ íƒì‚¬í•­)
REDIS_URL=redis://localhost:6379/0

# ============================================================================
# 4. .gitignore
# ============================================================================

# Python
__pycache__/
*.py[cod]
*$py.class
*.so
.Python
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
share/python-wheels/
*.egg-info/
.installed.cfg
*.egg
MANIFEST

# PyInstaller
*.manifest
*.spec

# Virtual environments
env/
venv/
ENV/
env.bak/
venv.bak/
.venv/

# IDEs
.vscode/
.idea/
*.swp
*.swo
.DS_Store

# Environment variables
.env
.env.local
.env.development
.env.test
.env.production

# ì—…ë¡œë“œëœ íŒŒì¼ë“¤
static/uploads/*
static/results/*
temp/*
logs/*

# ì˜ˆì™¸: .gitkeep íŒŒì¼ë“¤ì€ ìœ ì§€
!static/uploads/.gitkeep
!static/results/.gitkeep
!temp/.gitkeep
!logs/.gitkeep

# AI ëª¨ë¸ íŒŒì¼ë“¤ (ìš©ëŸ‰ì´ í° ê²½ìš°)
*.pth
*.onnx
*.h5
*.pb
*.safetensors
ai_models/*/checkpoints/*
!ai_models/*/checkpoints/.gitkeep

# í…ŒìŠ¤íŠ¸ ë° ì»¤ë²„ë¦¬ì§€
.pytest_cache/
.coverage
htmlcov/
.tox/
.nox/

# Jupyter Notebook
.ipynb_checkpoints

# pyenv
.python-version

# ============================================================================
# 5. Dockerfile
# ============================================================================

FROM nvidia/cuda:11.8-runtime-ubuntu20.04

# í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
ENV PYTHONUNBUFFERED=1
ENV DEBIAN_FRONTEND=noninteractive
ENV PYTHONPATH=/app

# ê¸°ë³¸ íŒ¨í‚¤ì§€ ì„¤ì¹˜
RUN apt-get update && apt-get install -y \
    python3 \
    python3-pip \
    python3-dev \
    libgl1-mesa-glx \
    libglib2.0-0 \
    libsm6 \
    libxext6 \
    libxrender-dev \
    libgomp1 \
    libgstreamer1.0-0 \
    libgstreamer-plugins-base1.0-0 \
    git \
    curl \
    wget \
    && rm -rf /var/lib/apt/lists/*

# ì‘ì—… ë””ë ‰í† ë¦¬ ì„¤ì •
WORKDIR /app

# Python ì˜ì¡´ì„± ì„¤ì¹˜
COPY requirements.txt .
RUN pip3 install --no-cache-dir --upgrade pip
RUN pip3 install --no-cache-dir -r requirements.txt

# ì„ íƒì ìœ¼ë¡œ Detectron2 ì„¤ì¹˜ (GPU í™˜ê²½ì—ì„œ)
# RUN pip3 install 'git+https://github.com/facebookresearch/detectron2.git'

# ì• í”Œë¦¬ì¼€ì´ì…˜ ì½”ë“œ ë³µì‚¬
COPY . .

# í•„ìš”í•œ ë””ë ‰í† ë¦¬ ìƒì„±
RUN mkdir -p static/uploads static/results temp logs

# .gitkeep íŒŒì¼ ìƒì„±
RUN touch static/uploads/.gitkeep static/results/.gitkeep temp/.gitkeep logs/.gitkeep

# ê¶Œí•œ ì„¤ì •
RUN chmod -R 755 /app

# í¬íŠ¸ ë…¸ì¶œ
EXPOSE 8000

# í—¬ìŠ¤ì²´í¬
HEALTHCHECK --interval=30s --timeout=10s --start-period=60s --retries=3 \
    CMD curl -f http://localhost:8000/health || exit 1

# ì„œë²„ ì‹œì‘
CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000", "--workers", "1"]

# ============================================================================
# 6. docker-compose.yml
# ============================================================================

version: '3.8'

services:
  backend:
    build: .
    container_name: mycloset-backend
    ports:
      - "8000:8000"
    volumes:
      - ./static/uploads:/app/static/uploads
      - ./static/results:/app/static/results
      - ./logs:/app/logs
      - ./ai_models:/app/ai_models  # AI ëª¨ë¸ ë””ë ‰í† ë¦¬ ë§ˆìš´íŠ¸
    environment:
      - PYTHONUNBUFFERED=1
    env_file:
      - .env
    restart: unless-stopped
    depends_on:
      - redis
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  redis:
    image: redis:7-alpine
    container_name: mycloset-redis
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    restart: unless-stopped
    command: redis-server --appendonly yes

  # ì„ íƒì‚¬í•­: ëª¨ë‹ˆí„°ë§
  prometheus:
    image: prom/prometheus
    container_name: mycloset-prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml
    restart: unless-stopped

volumes:
  redis_data:

# ============================================================================
# 7. Makefile - ê°œë°œ í¸ì˜ ìŠ¤í¬ë¦½íŠ¸
# ============================================================================

.PHONY: help setup install dev-install format lint test run docker-build docker-run clean models

help:
	@echo "MyCloset AI Backend - ê°œë°œ ëª…ë ¹ì–´"
	@echo ""
	@echo "ì„¤ì • ëª…ë ¹ì–´:"
	@echo "  setup        - ê°€ìƒí™˜ê²½ ìƒì„±"
	@echo "  install      - ê¸°ë³¸ ì˜ì¡´ì„± ì„¤ì¹˜"
	@echo "  dev-install  - ê°œë°œ ì˜ì¡´ì„± ì„¤ì¹˜"
	@echo "  models       - AI ëª¨ë¸ ë‹¤ìš´ë¡œë“œ"
	@echo ""
	@echo "ê°œë°œ ëª…ë ¹ì–´:"
	@echo "  format       - ì½”ë“œ í¬ë§·íŒ…"
	@echo "  lint         - ì½”ë“œ ë¦°íŠ¸ ê²€ì‚¬"
	@echo "  test         - í…ŒìŠ¤íŠ¸ ì‹¤í–‰"
	@echo "  run          - ê°œë°œ ì„œë²„ ì‹¤í–‰"
	@echo ""
	@echo "Docker ëª…ë ¹ì–´:"
	@echo "  docker-build - Docker ì´ë¯¸ì§€ ë¹Œë“œ"
	@echo "  docker-run   - Docker ì»¨í…Œì´ë„ˆ ì‹¤í–‰"
	@echo "  docker-stop  - Docker ì»¨í…Œì´ë„ˆ ì¤‘ì§€"
	@echo ""
	@echo "ìœ í‹¸ë¦¬í‹°:"
	@echo "  clean        - ìºì‹œ íŒŒì¼ ì •ë¦¬"
	@echo "  dirs         - í•„ìš”í•œ ë””ë ‰í† ë¦¬ ìƒì„±"

# í™˜ê²½ ì„¤ì •
setup:
	python3 -m venv venv
	@echo "ê°€ìƒí™˜ê²½ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤. ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ í™œì„±í™”í•˜ì„¸ìš”:"
	@echo "source venv/bin/activate  # Linux/Mac"
	@echo "venv\\Scripts\\activate    # Windows"

install:
	pip install --upgrade pip
	pip install -r requirements.txt

dev-install: install
	pip install -r requirements-dev.txt

models:
	@echo "AI ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰..."
	python scripts/download_models.py

# ê°œë°œ ë„êµ¬
format:
	black app tests
	isort app tests

lint:
	flake8 app tests
	mypy app

test:
	pytest tests/ -v --cov=app --cov-report=html

run:
	uvicorn app.main:app --reload --host 0.0.0.0 --port 8000

# Docker
docker-build:
	docker build -t mycloset-ai-backend .

docker-run:
	docker-compose up -d

docker-stop:
	docker-compose down

docker-logs:
	docker-compose logs -f backend

# ìœ í‹¸ë¦¬í‹°
clean:
	find . -type d -name "__pycache__" -exec rm -rf {} + 2>/dev/null || true
	find . -type f -name "*.pyc" -delete 2>/dev/null || true
	rm -rf .pytest_cache .coverage htmlcov .mypy_cache
	rm -rf build dist *.egg-info

dirs:
	mkdir -p static/uploads static/results temp logs
	touch static/uploads/.gitkeep static/results/.gitkeep temp/.gitkeep logs/.gitkeep

# ============================================================================
# 8. scripts/download_models.py - ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ìŠ¤í¬ë¦½íŠ¸
# ============================================================================

"""
AI ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ìŠ¤í¬ë¦½íŠ¸
"""

import os
import requests
import subprocess
from pathlib import Path
from tqdm import tqdm
import zipfile
import tarfile

def download_file(url, destination, desc=None):
    """íŒŒì¼ ë‹¤ìš´ë¡œë“œ with ì§„í–‰ë¥  í‘œì‹œ"""
    response = requests.get(url, stream=True)
    total_size = int(response.headers.get('content-length', 0))
    
    with open(destination, 'wb') as file, tqdm(
        desc=desc,
        total=total_size,
        unit='B',
        unit_scale=True,
        unit_divisor=1024,
    ) as pbar:
        for data in response.iter_content(chunk_size=1024):
            size = file.write(data)
            pbar.update(size)

def clone_repo(repo_url, destination):
    """Git ì €ì¥ì†Œ í´ë¡ """
    if not os.path.exists(destination):
        print(f"Cloning {repo_url} to {destination}")
        subprocess.run(['git', 'clone', repo_url, destination], check=True)
    else:
        print(f"Repository already exists: {destination}")

def download_huggingface_model(model_name, destination):
    """Hugging Face ëª¨ë¸ ë‹¤ìš´ë¡œë“œ"""
    try:
        from huggingface_hub import snapshot_download
        snapshot_download(repo_id=model_name, local_dir=destination)
        print(f"Downloaded {model_name} to {destination}")
    except ImportError:
        print("huggingface_hub not installed. Skipping Hugging Face models.")

def main():
    """ë©”ì¸ ë‹¤ìš´ë¡œë“œ í•¨ìˆ˜"""
    ai_models_dir = Path("ai_models")
    ai_models_dir.mkdir(exist_ok=True)
    
    print("ğŸ¤– AI ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹œì‘...")
    
    # 1. OOTDiffusion
    ootd_dir = ai_models_dir / "OOTDiffusion"
    if not ootd_dir.exists():
        print("ğŸ“¥ OOTDiffusion ë‹¤ìš´ë¡œë“œ ì¤‘...")
        clone_repo(
            "https://github.com/levihsu/OOTDiffusion.git",
            str(ootd_dir)
        )
    
    # 2. VITON-HD
    viton_dir = ai_models_dir / "VITON-HD"
    if not viton_dir.exists():
        print("ğŸ“¥ VITON-HD ë‹¤ìš´ë¡œë“œ ì¤‘...")
        clone_repo(
            "https://github.com/shadow2496/VITON-HD.git",
            str(viton_dir)
        )
    
    # 3. Stable Diffusion (Hugging Face)
    sd_dir = ai_models_dir / "stable-diffusion-v1-5"
    if not sd_dir.exists():
        print("ğŸ“¥ Stable Diffusion v1.5 ë‹¤ìš´ë¡œë“œ ì¤‘...")
        download_huggingface_model(
            "runwayml/stable-diffusion-v1-5",
            str(sd_dir)
        )
    
    # 4. ì²´í¬í¬ì¸íŠ¸ ë””ë ‰í† ë¦¬ ìƒì„±
    checkpoint_dirs = [
        ootd_dir / "checkpoints",
        viton_dir / "checkpoints",
        ai_models_dir / "DeepFashion_Try_On" / "ACGPN_inference" / "checkpoints"
    ]
    
    for checkpoint_dir in checkpoint_dirs:
        checkpoint_dir.mkdir(parents=True, exist_ok=True)
        (checkpoint_dir / ".gitkeep").touch()
    
    print("âœ… ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ!")
    print("ğŸ“ ì°¸ê³ : ì¼ë¶€ ëª¨ë¸ì˜ ì‚¬ì „ í›ˆë ¨ëœ ê°€ì¤‘ì¹˜ëŠ” ë³„ë„ë¡œ ë‹¤ìš´ë¡œë“œí•´ì•¼ í•©ë‹ˆë‹¤.")
    print("ğŸ”— ëª¨ë¸ë³„ ë‹¤ìš´ë¡œë“œ ë§í¬:")
    print("   - OOTDiffusion: https://github.com/levihsu/OOTDiffusion#checkpoints")
    print("   - VITON-HD: https://github.com/shadow2496/VITON-HD#checkpoints")

if __name__ == "__main__":
    main()

# ============================================================================
# 9. scripts/setup.sh - ì´ˆê¸° ì„¤ì • ìŠ¤í¬ë¦½íŠ¸
# ============================================================================

#!/bin/bash

echo "ğŸš€ MyCloset AI Backend ì´ˆê¸° ì„¤ì • ì‹œì‘..."

# 1. ê°€ìƒí™˜ê²½ ìƒì„±
echo "ğŸ“¦ ê°€ìƒí™˜ê²½ ìƒì„± ì¤‘..."
python3 -m venv venv
source venv/bin/activate

# 2. ì˜ì¡´ì„± ì„¤ì¹˜
echo "ğŸ“š Python ì˜ì¡´ì„± ì„¤ì¹˜ ì¤‘..."
pip install --upgrade pip
pip install -r requirements.txt

# 3. ê°œë°œ ì˜ì¡´ì„± ì„¤ì¹˜ (ì„ íƒì‚¬í•­)
read -p "ê°œë°œ ì˜ì¡´ì„±ë„ ì„¤ì¹˜í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/N): " install_dev
if [[ $install_dev =~ ^[Yy]$ ]]; then
    pip install -r requirements-dev.txt
fi

# 4. í™˜ê²½ë³€ìˆ˜ íŒŒì¼ ì„¤ì •
if [ ! -f .env ]; then
    echo "âš™ï¸ í™˜ê²½ë³€ìˆ˜ íŒŒì¼ ìƒì„± ì¤‘..."
    cp .env.example .env
    echo "ğŸ“ .env íŒŒì¼ì„ í¸ì§‘í•˜ì—¬ ì„¤ì •ì„ ì¡°ì •í•˜ì„¸ìš”."
fi

# 5. í•„ìš”í•œ ë””ë ‰í† ë¦¬ ìƒì„±
echo "ğŸ“ ë””ë ‰í† ë¦¬ êµ¬ì¡° ìƒì„± ì¤‘..."
mkdir -p static/uploads static/results temp logs
touch static/uploads/.gitkeep static/results/.gitkeep temp/.gitkeep logs/.gitkeep

# 6. AI ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
read -p "AI ëª¨ë¸ì„ ë‹¤ìš´ë¡œë“œí•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/N): " download_models
if [[ $download_models =~ ^[Yy]$ ]]; then
    echo "ğŸ¤– AI ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì¤‘..."
    python scripts/download_models.py
fi

# 7. GPU í™•ì¸
echo "ğŸ” GPU í™•ì¸ ì¤‘..."
python -c "import torch; print(f'CUDA available: {torch.cuda.is_available()}')"

echo "âœ… ì´ˆê¸° ì„¤ì • ì™„ë£Œ!"
echo ""
echo "ğŸš€ ì„œë²„ ì‹¤í–‰ ë°©ë²•:"
echo "   make run              # ê°œë°œ ì„œë²„"
echo "   make docker-run       # Dockerë¡œ ì‹¤í–‰"
echo ""
echo "ğŸ“š ì¶”ê°€ ëª…ë ¹ì–´:"
echo "   make help             # ì „ì²´ ëª…ë ¹ì–´ ëª©ë¡"
echo "   make test             # í…ŒìŠ¤íŠ¸ ì‹¤í–‰"
echo "   make format           # ì½”ë“œ í¬ë§·íŒ…"

# ============================================================================
# 10. tests/conftest.py - í…ŒìŠ¤íŠ¸ ì„¤ì •
# ============================================================================

"""
í…ŒìŠ¤íŠ¸ ì„¤ì • íŒŒì¼
"""

import pytest
import asyncio
import tempfile
import shutil
from pathlib import Path
from fastapi.testclient import TestClient
import sys

# í…ŒìŠ¤íŠ¸ìš© ì„í¬íŠ¸
sys.path.append(str(Path(__file__).parent.parent))
from app.main import app
from app.config import settings

@pytest.fixture(scope="session")
def event_loop():
    """ì´ë²¤íŠ¸ ë£¨í”„ ì„¤ì •"""
    loop = asyncio.get_event_loop_policy().new_event_loop()
    yield loop
    loop.close()

@pytest.fixture
def client():
    """í…ŒìŠ¤íŠ¸ í´ë¼ì´ì–¸íŠ¸"""
    with TestClient(app) as test_client:
        yield test_client

@pytest.fixture
def temp_dir():
    """ì„ì‹œ ë””ë ‰í† ë¦¬"""
    temp_dir = tempfile.mkdtemp()
    yield Path(temp_dir)
    shutil.rmtree(temp_dir)

@pytest.fixture
def sample_person_image():
    """í…ŒìŠ¤íŠ¸ìš© ì‚¬ëŒ ì´ë¯¸ì§€"""
    import cv2
    import numpy as np
    
    # ê°€ì§œ ì´ë¯¸ì§€ ìƒì„± (512x512, 3ì±„ë„)
    img = np.random.randint(0, 255, (512, 512, 3), dtype=np.uint8)
    _, encoded = cv2.imencode('.jpg', img)
    return encoded.tobytes()

@pytest.fixture
def sample_clothing_image():
    """í…ŒìŠ¤íŠ¸ìš© ì˜ë¥˜ ì´ë¯¸ì§€"""
    import cv2
    import numpy as np
    
    # ê°€ì§œ ì´ë¯¸ì§€ ìƒì„± (512x512, 3ì±„ë„)
    img = np.random.randint(0, 255, (512, 512, 3), dtype=np.uint8)
    _, encoded = cv2.imencode('.jpg', img)
    return encoded.tobytes()

# ============================================================================
# 11. tests/test_api.py - API í…ŒìŠ¤íŠ¸
# ============================================================================

"""
API ì—”ë“œí¬ì¸íŠ¸ í…ŒìŠ¤íŠ¸
"""

import pytest
from fastapi.testclient import TestClient
from unittest.mock import patch, AsyncMock
import io

def test_root_endpoint(client):
    """ë£¨íŠ¸ ì—”ë“œí¬ì¸íŠ¸ í…ŒìŠ¤íŠ¸"""
    response = client.get("/")
    assert response.status_code == 200
    data = response.json()
    assert "MyCloset AI Backend" in data["message"]
    assert "available_models" in data

def test_health_check(client):
    """í—¬ìŠ¤ ì²´í¬ í…ŒìŠ¤íŠ¸"""
    response = client.get("/health")
    assert response.status_code == 200
    data = response.json()
    assert data["status"] == "healthy"
    assert data["service"] == "MyCloset AI"

def test_models_status(client):
    """ëª¨ë¸ ìƒíƒœ í™•ì¸ í…ŒìŠ¤íŠ¸"""
    response = client.get("/api/models/status")
    assert response.status_code == 200

@patch('app.services.virtual_tryon.VirtualTryOnService.process_virtual_tryon')
def test_virtual_tryon_endpoint(mock_process, client, sample_person_image, sample_clothing_image):
    """ê°€ìƒ í”¼íŒ… ì—”ë“œí¬ì¸íŠ¸ í…ŒìŠ¤íŠ¸"""
    # Mock ì‘ë‹µ ì„¤ì •
    mock_response = {
        "success": True,
        "session_id": "test-session-123",
        "result_image_url": "/static/results/test-session-123.jpg",
        "processing_time": 2.5,
        "model_used": "ootd",
        "confidence_score": 0.85,
        "recommendations": ["ì´ ì˜ë¥˜ê°€ ì˜ ì–´ìš¸ë¦½ë‹ˆë‹¤!"]
    }
    mock_process.return_value = mock_response
    
    # í…ŒìŠ¤íŠ¸ ìš”ì²­
    files = {
        "person_image": ("person.jpg", io.BytesIO(sample_person_image), "image/jpeg"),
        "clothing_image": ("clothing.jpg", io.BytesIO(sample_clothing_image), "image/jpeg")
    }
    data = {
        "height": 170.0,
        "weight": 60.0,
        "model_type": "ootd",
        "category": "upper_body",
        "quality": "high"
    }
    
    response = client.post("/api/virtual-tryon", files=files, data=data)
    assert response.status_code == 200
    
    result = response.json()
    assert result["success"] == True
    assert "session_id" in result

def test_virtual_tryon_invalid_files(client):
    """ì˜ëª»ëœ íŒŒì¼ ì—…ë¡œë“œ í…ŒìŠ¤íŠ¸"""
    files = {
        "person_image": ("test.txt", io.BytesIO(b"not an image"), "text/plain"),
        "clothing_image": ("test.txt", io.BytesIO(b"not an image"), "text/plain")
    }
    data = {
        "height": 170.0,
        "weight": 60.0
    }
    
    response = client.post("/api/virtual-tryon", files=files, data=data)
    assert response.status_code == 400

# ============================================================================
# 12. tests/test_services.py - ì„œë¹„ìŠ¤ í…ŒìŠ¤íŠ¸
# ============================================================================

"""
ì„œë¹„ìŠ¤ ë¡œì§ í…ŒìŠ¤íŠ¸
"""

import pytest
import numpy as np
from unittest.mock import patch, MagicMock
import asyncio

from app.services.virtual_tryon import VirtualTryOnService
from app.api.schemas import VirtualTryOnRequest, ModelType, ClothingCategory, QualityLevel

@pytest.mark.asyncio
async def test_virtual_tryon_service_initialization():
    """ê°€ìƒ í”¼íŒ… ì„œë¹„ìŠ¤ ì´ˆê¸°í™” í…ŒìŠ¤íŠ¸"""
    service = VirtualTryOnService()
    assert service.device is not None
    assert service.models == {}
    assert service.is_initialized == False

@pytest.mark.asyncio
async def test_preprocess_images():
    """ì´ë¯¸ì§€ ì „ì²˜ë¦¬ í…ŒìŠ¤íŠ¸"""
    service = VirtualTryOnService()
    
    # ê°€ì§œ ì´ë¯¸ì§€ ë°ì´í„° ìƒì„±
    import cv2
    fake_img = np.random.randint(0, 255, (512, 512, 3), dtype=np.uint8)
    _, person_bytes = cv2.imencode('.jpg', fake_img)
    _, clothing_bytes = cv2.imencode('.jpg', fake_img)
    
    person_img, clothing_img = await service._preprocess_images(
        person_bytes.tobytes(), 
        clothing_bytes.tobytes()
    )
    
    assert person_img.shape == (512, 512, 3)
    assert clothing_img.shape == (512, 512, 3)

@pytest.mark.asyncio
async def test_analyze_body():
    """ì‹ ì²´ ë¶„ì„ í…ŒìŠ¤íŠ¸"""
    service = VirtualTryOnService()
    
    # ê°€ì§œ ì´ë¯¸ì§€ ìƒì„±
    fake_img = np.random.randint(0, 255, (512, 512, 3), dtype=np.uint8)
    
    measurements = await service._analyze_body(fake_img, 170.0, 60.0)
    
    assert measurements.chest > 0
    assert measurements.waist > 0
    assert measurements.hip > 0
    assert 0 <= measurements.confidence <= 1

@pytest.mark.asyncio
async def test_analyze_clothing():
    """ì˜ë¥˜ ë¶„ì„ í…ŒìŠ¤íŠ¸"""
    service = VirtualTryOnService()
    
    # ê°€ì§œ ì˜ë¥˜ ì´ë¯¸ì§€ ìƒì„±
    fake_img = np.random.randint(0, 255, (512, 512, 3), dtype=np.uint8)
    
    analysis = await service._analyze_clothing(fake_img)
    
    assert analysis.category in ["shirt", "pants", "dress"]
    assert analysis.style in ["casual", "formal", "smart-casual"]
    assert len(analysis.dominant_colors) > 0
    assert 0 <= analysis.confidence <= 1

# ============================================================================
# 13. tests/test_utils.py - ìœ í‹¸ë¦¬í‹° í…ŒìŠ¤íŠ¸
# ============================================================================

"""
ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ í…ŒìŠ¤íŠ¸
"""

import pytest
import numpy as np
import cv2
from pathlib import Path
import tempfile

from app.utils.image_utils import ImageProcessor
from app.utils.file_utils import FileManager

def test_image_decode_encode():
    """ì´ë¯¸ì§€ ì¸ì½”ë”©/ë””ì½”ë”© í…ŒìŠ¤íŠ¸"""
    # í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ìƒì„±
    img = np.random.randint(0, 255, (100, 100, 3), dtype=np.uint8)
    
    # ì¸ì½”ë”©
    img_bytes = ImageProcessor.encode_image(img)
    
    # ë””ì½”ë”©
    decoded_img = ImageProcessor.decode_image(img_bytes)
    
    assert decoded_img.shape == img.shape
    assert decoded_img.dtype == img.dtype

def test_image_resize():
    """ì´ë¯¸ì§€ ë¦¬ì‚¬ì´ì¦ˆ í…ŒìŠ¤íŠ¸"""
    img = np.random.randint(0, 255, (200, 200, 3), dtype=np.uint8)
    resized = ImageProcessor.resize_image(img, (100, 100))
    
    assert resized.shape == (100, 100, 3)

def test_extract_dominant_colors():
    """ì£¼ìš” ìƒ‰ìƒ ì¶”ì¶œ í…ŒìŠ¤íŠ¸"""
    # ë‹¨ìƒ‰ ì´ë¯¸ì§€ ìƒì„±
    img = np.full((100, 100, 3), [255, 0, 0], dtype=np.uint8)  # ë¹¨ê°„ìƒ‰
    
    colors = ImageProcessor.extract_dominant_colors(img, k=1)
    
    assert len(colors) == 1
    assert len(colors[0]) == 3  # RGB

@pytest.mark.asyncio
async def test_file_manager_temp_file():
    """íŒŒì¼ ë§¤ë‹ˆì € ì„ì‹œ íŒŒì¼ í…ŒìŠ¤íŠ¸"""
    manager = FileManager()
    
    test_data = b"test data"
    filepath = await manager.create_temp_file(test_data)
    
    assert Path(filepath).exists()
    assert manager.temp_files
    
    # ì •ë¦¬
    await manager.cleanup_temp_files()
    assert not Path(filepath).exists()

def test_validate_file_extension():
    """íŒŒì¼ í™•ì¥ì ê²€ì¦ í…ŒìŠ¤íŠ¸"""
    assert FileManager.validate_file_extension("image.jpg") == True
    assert FileManager.validate_file_extension("image.png") == True
    assert FileManager.validate_file_extension("image.txt") == False
    assert FileManager.validate_file_extension("image.exe") == False

# ============================================================================
# 14. monitoring/prometheus.yml - ëª¨ë‹ˆí„°ë§ ì„¤ì •
# ============================================================================

global:
  scrape_interval: 15s
  evaluation_interval: 15s

rule_files:
  # - "first_rules.yml"
  # - "second_rules.yml"

scrape_configs:
  - job_name: 'mycloset-backend'
    static_configs:
      - targets: ['backend:8000']
    metrics_path: '/metrics'
    scrape_interval: 5s

  - job_name: 'redis'
    static_configs:
      - targets: ['redis:6379']

# ============================================================================
# 15. scripts/start_dev.sh - ê°œë°œ ì„œë²„ ì‹œì‘ ìŠ¤í¬ë¦½íŠ¸
# ============================================================================

#!/bin/bash

echo "ğŸš€ MyCloset AI ê°œë°œ ì„œë²„ ì‹œì‘..."

# ê°€ìƒí™˜ê²½ í™œì„±í™” í™•ì¸
if [[ "$VIRTUAL_ENV" == "" ]]; then
    echo "âš ï¸ ê°€ìƒí™˜ê²½ì´ í™œì„±í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
    echo "ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ í™œì„±í™”í•˜ì„¸ìš”:"
    echo "source venv/bin/activate"
    exit 1
fi

# í™˜ê²½ë³€ìˆ˜ íŒŒì¼ í™•ì¸
if [ ! -f .env ]; then
    echo "âš ï¸ .env íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. .env.exampleì„ ë³µì‚¬í•˜ì—¬ .envë¥¼ ìƒì„±í•˜ì„¸ìš”."
    cp .env.example .env
fi

# í•„ìš”í•œ ë””ë ‰í† ë¦¬ ìƒì„±
mkdir -p static/uploads static/results temp logs
touch static/uploads/.gitkeep static/results/.gitkeep temp/.gitkeep logs/.gitkeep

# AI ëª¨ë¸ ë””ë ‰í† ë¦¬ í™•ì¸
if [ ! -d "ai_models" ]; then
    echo "âš ï¸ ai_models ë””ë ‰í† ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤."
    echo "ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ ëª¨ë¸ì„ ë‹¤ìš´ë¡œë“œí•˜ì„¸ìš”:"
    echo "make models"
    
    read -p "ì§€ê¸ˆ ëª¨ë¸ì„ ë‹¤ìš´ë¡œë“œí•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/N): " download_now
    if [[ $download_now =~ ^[Yy]$ ]]; then
        python scripts/download_models.py
    fi
fi

echo "ğŸ“š Python ì˜ì¡´ì„± í™•ì¸ ì¤‘..."
pip install -r requirements.txt > /dev/null 2>&1

echo "ğŸ”„ ì„œë²„ ì‹œì‘ ì¤‘..."
echo "ğŸ“± ì„œë²„ ì£¼ì†Œ: http://localhost:8000"
echo "ğŸ“– API ë¬¸ì„œ: http://localhost:8000/docs"
echo "ğŸ” í—¬ìŠ¤ì²´í¬: http://localhost:8000/health"
echo ""
echo "ì¤‘ì§€í•˜ë ¤ë©´ Ctrl+Cë¥¼ ëˆ„ë¥´ì„¸ìš”."
echo ""

# ì„œë²„ ì‹¤í–‰
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000

# ============================================================================
# 16. scripts/production_deploy.sh - í”„ë¡œë•ì…˜ ë°°í¬ ìŠ¤í¬ë¦½íŠ¸
# ============================================================================

#!/bin/bash

echo "ğŸš€ MyCloset AI í”„ë¡œë•ì…˜ ë°°í¬ ìŠ¤í¬ë¦½íŠ¸"

# í™˜ê²½ í™•ì¸
if [ "$1" != "production" ]; then
    echo "âš ï¸ í”„ë¡œë•ì…˜ ë°°í¬ëŠ” ë‹¤ìŒê³¼ ê°™ì´ ì‹¤í–‰í•˜ì„¸ìš”:"
    echo "./scripts/production_deploy.sh production"
    exit 1
fi

echo "ğŸ”„ í”„ë¡œë•ì…˜ í™˜ê²½ ì„¤ì • ì¤‘..."

# 1. í™˜ê²½ë³€ìˆ˜ í™•ì¸
if [ ! -f .env.production ]; then
    echo "âŒ .env.production íŒŒì¼ì´ í•„ìš”í•©ë‹ˆë‹¤."
    exit 1
fi

# 2. Docker ì´ë¯¸ì§€ ë¹Œë“œ
echo "ğŸ—ï¸ Docker ì´ë¯¸ì§€ ë¹Œë“œ ì¤‘..."
docker build -t mycloset-ai-backend:latest .

# 3. ê¸°ì¡´ ì»¨í…Œì´ë„ˆ ì¤‘ì§€
echo "ğŸ›‘ ê¸°ì¡´ ì»¨í…Œì´ë„ˆ ì¤‘ì§€ ì¤‘..."
docker-compose -f docker-compose.prod.yml down

# 4. í”„ë¡œë•ì…˜ í™˜ê²½ ì‹œì‘
echo "ğŸš€ í”„ë¡œë•ì…˜ í™˜ê²½ ì‹œì‘ ì¤‘..."
docker-compose -f docker-compose.prod.yml up -d

# 5. í—¬ìŠ¤ì²´í¬
echo "ğŸ” ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸ ì¤‘..."
sleep 10

curl -f http://localhost:8000/health || {
    echo "âŒ ì„œë¹„ìŠ¤ ì‹œì‘ ì‹¤íŒ¨"
    docker-compose -f docker-compose.prod.yml logs backend
    exit 1
}

echo "âœ… í”„ë¡œë•ì…˜ ë°°í¬ ì™„ë£Œ!"
echo "ğŸ“± ì„œë¹„ìŠ¤ URL: http://your-domain.com"
echo "ğŸ“Š ëª¨ë‹ˆí„°ë§: http://your-domain.com:9090"

# ============================================================================
# 17. README.md - í”„ë¡œì íŠ¸ ë¬¸ì„œ
# ============================================================================

# MyCloset AI Backend

ğŸ½ AI ê¸°ë°˜ ê°€ìƒ í”¼íŒ… ì‹œìŠ¤í…œì˜ ë°±ì—”ë“œ ì„œë²„

## ğŸŒŸ ì£¼ìš” ê¸°ëŠ¥

- **ë‹¤ì¤‘ AI ëª¨ë¸ ì§€ì›**: OOTDiffusion, ACGPN, VITON-HD
- **ì‹¤ì‹œê°„ ê°€ìƒ í”¼íŒ…**: ê³ í’ˆì§ˆ ì´ë¯¸ì§€ ìƒì„±
- **ì‹ ì²´ ë¶„ì„**: MediaPipe ê¸°ë°˜ ìë™ ì¹˜ìˆ˜ ì¸¡ì •
- **ì˜ë¥˜ ë¶„ì„**: ìƒ‰ìƒ, ìŠ¤íƒ€ì¼, íŒ¨í„´ ìë™ ì¸ì‹
- **í• ë¶„ì„**: AI ê¸°ë°˜ ì°©ìš©ê° í‰ê°€
- **RESTful API**: FastAPI ê¸°ë°˜ ê³ ì„±ëŠ¥ API

## ğŸ—ï¸ ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜

```
MyCloset AI Backend
â”œâ”€â”€ ğŸ–¼ï¸ ì´ë¯¸ì§€ ì „ì²˜ë¦¬ (OpenCV, PIL)
â”œâ”€â”€ ğŸ¤– AI ëª¨ë¸ í†µí•©
â”‚   â”œâ”€â”€ OOTDiffusion (Diffusion Model)
â”‚   â”œâ”€â”€ ACGPN (GAN Model)
â”‚   â”œâ”€â”€ VITON-HD (High Definition)
â”‚   â””â”€â”€ Human Parsing (Detectron2)
â”œâ”€â”€ ğŸ“Š ë¶„ì„ ì—”ì§„
â”‚   â”œâ”€â”€ ì‹ ì²´ ì¹˜ìˆ˜ ì¸¡ì •
â”‚   â”œâ”€â”€ ì˜ë¥˜ ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜
â”‚   â””â”€â”€ í• ìŠ¤ì½”ì–´ ê³„ì‚°
â””â”€â”€ ğŸš€ FastAPI ì„œë²„
    â”œâ”€â”€ RESTful API
    â”œâ”€â”€ ì‹¤ì‹œê°„ ì²˜ë¦¬
    â””â”€â”€ ìë™ ë¬¸ì„œí™”
```

## ğŸš€ ë¹ ë¥¸ ì‹œì‘

### 1. í”„ë¡œì íŠ¸ í´ë¡ 

```bash
git clone https://github.com/your-username/mycloset-ai-backend.git
cd mycloset-ai-backend
```

### 2. ìë™ ì„¤ì • (ê¶Œì¥)

```bash
chmod +x scripts/setup.sh
./scripts/setup.sh
```

### 3. ìˆ˜ë™ ì„¤ì •

```bash
# ê°€ìƒí™˜ê²½ ìƒì„±
python3 -m venv venv
source venv/bin/activate  # Linux/Mac
# venv\Scripts\activate   # Windows

# ì˜ì¡´ì„± ì„¤ì¹˜
pip install -r requirements.txt

# í™˜ê²½ë³€ìˆ˜ ì„¤ì •
cp .env.example .env
# .env íŒŒì¼ì„ í¸ì§‘í•˜ì—¬ ì„¤ì • ì¡°ì •

# ë””ë ‰í† ë¦¬ êµ¬ì¡° ìƒì„±
make dirs

# AI ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
python scripts/download_models.py
```

### 4. ì„œë²„ ì‹¤í–‰

```bash
# ê°œë°œ ì„œë²„
make run
# ë˜ëŠ”
./scripts/start_dev.sh

# Dockerë¡œ ì‹¤í–‰
make docker-run
```

## ğŸ“‹ ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­

### ìµœì†Œ ìš”êµ¬ì‚¬í•­
- Python 3.9+
- 8GB RAM
- 10GB ì €ì¥ê³µê°„

### ê¶Œì¥ ìš”êµ¬ì‚¬í•­
- Python 3.11+
- NVIDIA GPU (8GB+ VRAM)
- 16GB RAM
- 50GB ì €ì¥ê³µê°„ (AI ëª¨ë¸ í¬í•¨)

## ğŸ”§ ì„¤ì •

### í™˜ê²½ë³€ìˆ˜ (.env)

```bash
# ê¸°ë³¸ ì„¤ì •
APP_NAME=MyCloset AI Backend
DEBUG=false
PORT=8000

# AI ëª¨ë¸ ì„¤ì •
DEFAULT_MODEL=ootd
USE_GPU=true
DEVICE=cuda

# ì„±ëŠ¥ ì„¤ì •
MAX_UPLOAD_SIZE=52428800  # 50MB
IMAGE_SIZE=512
MAX_WORKERS=4
```

### AI ëª¨ë¸ ì„ íƒ

```python
# API ìš”ì²­ ì‹œ ëª¨ë¸ ì§€ì •
{
  "model_type": "ootd",      # ootd, acgpn, viton-hd
  "category": "upper_body",   # upper_body, lower_body, dresses
  "quality": "high"          # low, medium, high
}
```

## ğŸ“– API ë¬¸ì„œ

### ë©”ì¸ ì—”ë“œí¬ì¸íŠ¸

#### `POST /api/virtual-tryon`

ê°€ìƒ í”¼íŒ… ì‹¤í–‰

**ìš”ì²­:**
```python
files = {
    'person_image': open('person.jpg', 'rb'),
    'clothing_image': open('clothing.jpg', 'rb')
}
data = {
    'height': 170.0,
    'weight': 60.0,
    'model_type': 'ootd',
    'category': 'upper_body'
}
```

**ì‘ë‹µ:**
```json
{
  "success": true,
  "session_id": "uuid-string",
  "result_image_url": "/static/results/uuid.jpg",
  "processing_time": 2.34,
  "confidence_score": 0.87,
  "recommendations": ["ì´ ì˜ë¥˜ê°€ ì˜ ì–´ìš¸ë¦½ë‹ˆë‹¤!"]
}
```

### ê¸°íƒ€ ì—”ë“œí¬ì¸íŠ¸

- `GET /health` - í—¬ìŠ¤ì²´í¬
- `GET /api/models/status` - AI ëª¨ë¸ ìƒíƒœ
- `POST /api/preprocess` - ì´ë¯¸ì§€ ì „ì²˜ë¦¬ë§Œ

## ğŸ§ª í…ŒìŠ¤íŠ¸

```bash
# ì „ì²´ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
make test

# íŠ¹ì • í…ŒìŠ¤íŠ¸ ì‹¤í–‰
pytest tests/test_api.py -v

# ì»¤ë²„ë¦¬ì§€ ë¦¬í¬íŠ¸
pytest --cov=app --cov-report=html
```

## ğŸ“¦ ë°°í¬

### Docker ë°°í¬

```bash
# ì´ë¯¸ì§€ ë¹Œë“œ
make docker-build

# ì»¨í…Œì´ë„ˆ ì‹¤í–‰
make docker-run

# ë¡œê·¸ í™•ì¸
make docker-logs
```

### í”„ë¡œë•ì…˜ ë°°í¬

```bash
# í”„ë¡œë•ì…˜ í™˜ê²½ ë°°í¬
./scripts/production_deploy.sh production
```

## ğŸ› ï¸ ê°œë°œ

### ì½”ë“œ ìŠ¤íƒ€ì¼

```bash
# ì½”ë“œ í¬ë§·íŒ…
make format

# ë¦°íŠ¸ ê²€ì‚¬
make lint
```

### ê°œë°œ ëª…ë ¹ì–´

```bash
make help          # ì „ì²´ ëª…ë ¹ì–´ ëª©ë¡
make run           # ê°œë°œ ì„œë²„ ì‹¤í–‰
make test          # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
make clean         # ìºì‹œ íŒŒì¼ ì •ë¦¬
```

## ğŸ“Š ì„±ëŠ¥ ìµœì í™”

### GPU ë©”ëª¨ë¦¬ ìµœì í™”

```python
# config.pyì—ì„œ ì„¤ì •
USE_GPU = True
DEVICE = "cuda"
BATCH_SIZE = 1  # GPU ë©”ëª¨ë¦¬ì— ë”°ë¼ ì¡°ì •
```

### ìºì‹± í™œìš©

```python
# Redis ìºì‹± í™œì„±í™”
REDIS_URL = "redis://localhost:6379/0"
CACHE_TTL = 3600
```

## ğŸ” ëª¨ë‹ˆí„°ë§

### ë¡œê·¸ í™•ì¸

```bash
# ì‹¤ì‹œê°„ ë¡œê·¸
tail -f logs/app.log

# Docker ë¡œê·¸
docker-compose logs -f backend
```

### ë©”íŠ¸ë¦­ìŠ¤

- Prometheus: `http://localhost:9090`
- API ë©”íŠ¸ë¦­ìŠ¤: `http://localhost:8000/metrics`

## ğŸ¤ ê¸°ì—¬í•˜ê¸°

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

## ğŸ“„ ë¼ì´ì„ ìŠ¤

ì´ í”„ë¡œì íŠ¸ëŠ” MIT ë¼ì´ì„ ìŠ¤ í•˜ì— ë°°í¬ë©ë‹ˆë‹¤. ìì„¸í•œ ë‚´ìš©ì€ `LICENSE` íŒŒì¼ì„ ì°¸ì¡°í•˜ì„¸ìš”.

## ğŸ™ ê°ì‚¬ì˜ ë§

- [OOTDiffusion](https://github.com/levihsu/OOTDiffusion)
- [VITON-HD](https://github.com/shadow2496/VITON-HD)
- [Detectron2](https://github.com/facebookresearch/detectron2)
- [MediaPipe](https://mediapipe.dev/)

## ğŸ“ ì§€ì›

- ğŸ“§ Email: support@mycloset-ai.com
- ğŸ› Issues: [GitHub Issues](https://github.com/your-username/mycloset-ai-backend/issues)
- ğŸ“– Documentation: [Full Documentation](https://docs.mycloset-ai.com)

---

ğŸ’¡ **íŒ**: ê°œë°œ í™˜ê²½ì—ì„œëŠ” `make run`ìœ¼ë¡œ ì‹œì‘í•˜ê³ , í”„ë¡œë•ì…˜ì—ì„œëŠ” Dockerë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤.