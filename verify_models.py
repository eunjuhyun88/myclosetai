#!/usr/bin/env python3
"""
ğŸ” MyCloset AI - ëª¨ë¸ ì¬ë°°ì¹˜ ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸
ì¬ë°°ì¹˜ëœ AI ëª¨ë¸ë“¤ì˜ ìƒíƒœë¥¼ ì²´í¬í•˜ê³  ë¶„ì„

ê¸°ëŠ¥:
- Stepë³„ ëª¨ë¸ íŒŒì¼ ê²€ì¦
- íŒŒì¼ ë¬´ê²°ì„± ì²´í¬ (í¬ê¸°, ì ‘ê·¼ì„±)
- ëˆ„ë½ëœ í•„ìˆ˜ ëª¨ë¸ íƒì§€
- ë°±ì—”ë“œ í˜¸í™˜ì„± ê²€ì¦
- conda í™˜ê²½ ìµœì í™”

ì‚¬ìš©ë²•:
python verify_models.py                    # ì „ì²´ ê²€ì¦
python verify_models.py --step 1          # íŠ¹ì • Stepë§Œ ê²€ì¦
python verify_models.py --detailed        # ìƒì„¸ ë¶„ì„
python verify_models.py --fix-missing     # ëˆ„ë½ëœ ëª¨ë¸ íƒì§€ ë° ì œì•ˆ
"""

import os
import sys
import hashlib
import json
import time
from pathlib import Path
from typing import Dict, List, Tuple, Optional, Set
from dataclasses import dataclass, field
from collections import defaultdict
import argparse

# ì•ˆì „í•œ import (conda í™˜ê²½ í˜¸í™˜)
try:
    from tqdm import tqdm
    TQDM_AVAILABLE = True
except ImportError:
    TQDM_AVAILABLE = False
    print("âš ï¸ tqdm ì—†ìŒ. ì§„í–‰ë¥  í‘œì‹œ ë¶ˆê°€")

try:
    import psutil
    PSUTIL_AVAILABLE = True
except ImportError:
    PSUTIL_AVAILABLE = False

@dataclass
class ModelInfo:
    """ëª¨ë¸ ì •ë³´"""
    name: str
    path: Path
    size_mb: float
    extension: str
    exists: bool
    readable: bool
    checksum: str = ""
    step: str = ""
    status: str = "unknown"
    errors: List[str] = field(default_factory=list)

@dataclass
class StepRequirement:
    """Stepë³„ í•„ìˆ˜ ëª¨ë¸ ìš”êµ¬ì‚¬í•­"""
    step_name: str
    required_models: List[str]
    optional_models: List[str]
    min_models: int
    expected_size_mb: Tuple[float, float]  # (min, max)
    description: str

class ModelVerifier:
    """AI ëª¨ë¸ ì¬ë°°ì¹˜ ê²€ì¦ê¸°"""
    
    def __init__(self, backend_dir: Optional[Path] = None):
        self.backend_dir = backend_dir or Path.cwd() / "backend"
        self.checkpoints_dir = self.backend_dir / "app" / "ai_pipeline" / "models" / "checkpoints"
        self.discovered_models: Dict[str, List[ModelInfo]] = defaultdict(list)
        self.verification_results: Dict = {}
        
        # Stepë³„ í•„ìˆ˜ ëª¨ë¸ ì •ì˜
        self.step_requirements = {
            "step_01_human_parsing": StepRequirement(
                step_name="Human Parsing",
                required_models=[
                    "exp-schp-201908301523-atr.pth",
                    "parsing_atr.onnx"
                ],
                optional_models=[
                    "graphonomy_lip.pth",
                    "densepose_rcnn_R_50_FPN_s1x.pkl",
                    "segformer_b2_clothes.pth"
                ],
                min_models=1,
                expected_size_mb=(100, 800),
                description="ì¸ì²´ íŒŒì‹± - ì‚¬ëŒì˜ ì‹ ì²´ ë¶€ìœ„ë¥¼ ì„¸ë¶„í™”í•˜ì—¬ ì¸ì‹"
            ),
            "step_02_pose_estimation": StepRequirement(
                step_name="Pose Estimation", 
                required_models=[
                    "openpose.pth",
                    "body_pose_model.pth"
                ],
                optional_models=[
                    "yolov8n-pose.pt",
                    "pose_deploy_linevec.prototxt",
                    "pose_landmark_heavy.tflite"
                ],
                min_models=1,
                expected_size_mb=(6, 400),
                description="í¬ì¦ˆ ì¶”ì • - ì‚¬ëŒì˜ ê´€ì ˆì ê³¼ ìì„¸ë¥¼ ê°ì§€"
            ),
            "step_03_cloth_segmentation": StepRequirement(
                step_name="Cloth Segmentation",
                required_models=[
                    "u2net.pth"
                ],
                optional_models=[
                    "mobile_sam.pt",
                    "sam_vit_h_4b8939.pth",
                    "cloth_segmentation.onnx"
                ],
                min_models=1,
                expected_size_mb=(38, 2500),
                description="ì˜ë¥˜ ë¶„í•  - ì˜ë¥˜ì™€ ë°°ê²½ì„ ì •í™•íˆ ë¶„ë¦¬"
            ),
            "step_04_geometric_matching": StepRequirement(
                step_name="Geometric Matching",
                required_models=[
                    "gmm_final.pth",
                    "lightweight_gmm.pth"
                ],
                optional_models=[
                    "tps_network.pth",
                    "geometric_matching.onnx"
                ],
                min_models=0,  # ì„ íƒì  ë‹¨ê³„
                expected_size_mb=(10, 200),
                description="ê¸°í•˜í•™ì  ë§¤ì¹­ - ì˜ë¥˜ì™€ ì‹ ì²´ì˜ ê¸°í•˜í•™ì  ê´€ê³„ ë¶„ì„"
            ),
            "step_05_cloth_warping": StepRequirement(
                step_name="Cloth Warping",
                required_models=[
                    "tom_final.pth"
                ],
                optional_models=[
                    "tps_final.pth",
                    "cloth_warping.pth"
                ],
                min_models=0,  # ì„ íƒì  ë‹¨ê³„
                expected_size_mb=(15, 150),
                description="ì˜ë¥˜ ë³€í˜• - ì‹ ì²´ì— ë§ê²Œ ì˜ë¥˜ í˜•íƒœ ì¡°ì •"
            ),
            "step_06_virtual_fitting": StepRequirement(
                step_name="Virtual Fitting",
                required_models=[
                    "diffusion_pytorch_model.safetensors",
                    "unet_vton",
                    "pytorch_model.bin"
                ],
                optional_models=[
                    "text_encoder",
                    "vae",
                    "scheduler"
                ],
                min_models=1,
                expected_size_mb=(500, 8000),
                description="ê°€ìƒ í”¼íŒ… - ì‹¤ì œ ì°©ìš© ëª¨ìŠµì„ ìƒì„±"
            ),
            "step_07_post_processing": StepRequirement(
                step_name="Post Processing",
                required_models=[],
                optional_models=[
                    "RealESRGAN_x4plus.pth",
                    "GFPGAN.pth",
                    "CodeFormer.pth"
                ],
                min_models=0,
                expected_size_mb=(17, 350),
                description="í›„ì²˜ë¦¬ - ì´ë¯¸ì§€ í’ˆì§ˆ í–¥ìƒ ë° ë…¸ì´ì¦ˆ ì œê±°"
            ),
            "step_08_quality_assessment": StepRequirement(
                step_name="Quality Assessment",
                required_models=[],
                optional_models=[
                    "clip-vit-base-patch32",
                    "clip-vit-large-patch14",
                    "pytorch_model.bin"
                ],
                min_models=0,
                expected_size_mb=(150, 1200),
                description="í’ˆì§ˆ í‰ê°€ - ìƒì„±ëœ ì´ë¯¸ì§€ì˜ í’ˆì§ˆì„ ìë™ í‰ê°€"
            )
        }
        
        print(f"ğŸ¯ ë°±ì—”ë“œ ë””ë ‰í† ë¦¬: {self.backend_dir}")
        print(f"ğŸ“ ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œ: {self.checkpoints_dir}")
    
    def scan_models(self) -> Dict[str, List[ModelInfo]]:
        """ì¬ë°°ì¹˜ëœ ëª¨ë¸ë“¤ ìŠ¤ìº”"""
        print("ğŸ” ì¬ë°°ì¹˜ëœ ëª¨ë¸ ìŠ¤ìº” ì‹œì‘...")
        
        if not self.checkpoints_dir.exists():
            print(f"âŒ ì²´í¬í¬ì¸íŠ¸ ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {self.checkpoints_dir}")
            return {}
        
        # Step í´ë”ë“¤ ìŠ¤ìº”
        step_folders = [d for d in self.checkpoints_dir.iterdir() if d.is_dir()]
        print(f"ğŸ“‚ ë°œê²¬ëœ Step í´ë”: {len(step_folders)}ê°œ")
        
        for step_folder in step_folders:
            step_name = step_folder.name
            print(f"  ğŸ“ {step_name}")
            
            # í´ë” ë‚´ ëª¨ë“  íŒŒì¼ ìŠ¤ìº”
            model_files = []
            for file_path in step_folder.rglob("*"):
                if file_path.is_file():
                    model_files.append(file_path)
            
            print(f"     ğŸ”¢ íŒŒì¼ ìˆ˜: {len(model_files)}ê°œ")
            
            # ModelInfo ê°ì²´ ìƒì„±
            for file_path in model_files:
                try:
                    stat = file_path.stat()
                    size_mb = stat.st_size / (1024 * 1024)
                    
                    model_info = ModelInfo(
                        name=file_path.name,
                        path=file_path,
                        size_mb=size_mb,
                        extension=file_path.suffix.lower(),
                        exists=True,
                        readable=os.access(file_path, os.R_OK),
                        step=step_name
                    )
                    
                    # ê¸°ë³¸ ê²€ì¦
                    if not model_info.readable:
                        model_info.errors.append("íŒŒì¼ ì½ê¸° ê¶Œí•œ ì—†ìŒ")
                        model_info.status = "error"
                    elif size_mb < 0.1:
                        model_info.errors.append("íŒŒì¼ í¬ê¸°ê°€ ë„ˆë¬´ ì‘ìŒ (100KB ë¯¸ë§Œ)")
                        model_info.status = "warning"
                    else:
                        model_info.status = "ok"
                    
                    self.discovered_models[step_name].append(model_info)
                    
                except (OSError, PermissionError) as e:
                    # ì ‘ê·¼í•  ìˆ˜ ì—†ëŠ” íŒŒì¼
                    model_info = ModelInfo(
                        name=file_path.name,
                        path=file_path,
                        size_mb=0.0,
                        extension=file_path.suffix.lower(),
                        exists=True,
                        readable=False,
                        step=step_name,
                        status="error",
                        errors=[f"íŒŒì¼ ì ‘ê·¼ ì˜¤ë¥˜: {e}"]
                    )
                    self.discovered_models[step_name].append(model_info)
        
        print(f"âœ… ì´ {sum(len(models) for models in self.discovered_models.values())}ê°œ ëª¨ë¸ ë°œê²¬")
        return self.discovered_models
    
    def verify_step_requirements(self) -> Dict:
        """Stepë³„ ìš”êµ¬ì‚¬í•­ ê²€ì¦"""
        print("ğŸ” Stepë³„ ìš”êµ¬ì‚¬í•­ ê²€ì¦ ì¤‘...")
        
        verification_results = {}
        
        for step_id, requirement in self.step_requirements.items():
            step_models = self.discovered_models.get(step_id, [])
            
            result = {
                "step_name": requirement.step_name,
                "description": requirement.description,
                "found_models": len(step_models),
                "total_size_mb": sum(m.size_mb for m in step_models),
                "required_models": {
                    "found": [],
                    "missing": []
                },
                "optional_models": {
                    "found": [],
                    "missing": []
                },
                "status": "unknown",
                "issues": [],
                "recommendations": []
            }
            
            # ëª¨ë¸ íŒŒì¼ëª… ëª©ë¡
            found_names = {m.name.lower() for m in step_models}
            
            # í•„ìˆ˜ ëª¨ë¸ ì²´í¬
            for req_model in requirement.required_models:
                req_lower = req_model.lower()
                found = any(req_lower in name or name in req_lower for name in found_names)
                if found:
                    result["required_models"]["found"].append(req_model)
                else:
                    result["required_models"]["missing"].append(req_model)
            
            # ì„ íƒì  ëª¨ë¸ ì²´í¬
            for opt_model in requirement.optional_models:
                opt_lower = opt_model.lower()
                found = any(opt_lower in name or name in opt_lower for name in found_names)
                if found:
                    result["optional_models"]["found"].append(opt_model)
                else:
                    result["optional_models"]["missing"].append(opt_model)
            
            # ìµœì†Œ ìš”êµ¬ì‚¬í•­ ì²´í¬
            min_met = len(step_models) >= requirement.min_models
            required_met = len(result["required_models"]["missing"]) == 0
            
            # í¬ê¸° ë²”ìœ„ ì²´í¬
            size_ok = (requirement.expected_size_mb[0] <= result["total_size_mb"] <= 
                      requirement.expected_size_mb[1] * 2)  # 2ë°°ê¹Œì§€ í—ˆìš©
            
            # ì „ì²´ ìƒíƒœ ê²°ì •
            if requirement.min_models == 0:  # ì„ íƒì  ë‹¨ê³„
                if len(step_models) == 0:
                    result["status"] = "optional_empty"
                elif min_met:
                    result["status"] = "ok"
                else:
                    result["status"] = "warning"
            else:  # í•„ìˆ˜ ë‹¨ê³„
                if required_met and min_met and size_ok:
                    result["status"] = "ok"
                elif min_met:
                    result["status"] = "warning"
                else:
                    result["status"] = "error"
            
            # ì´ìŠˆ ë° ê¶Œì¥ì‚¬í•­ ìƒì„±
            if not min_met:
                result["issues"].append(f"ìµœì†Œ {requirement.min_models}ê°œ ëª¨ë¸ í•„ìš”, í˜„ì¬ {len(step_models)}ê°œ")
            
            if result["required_models"]["missing"]:
                result["issues"].append(f"í•„ìˆ˜ ëª¨ë¸ ëˆ„ë½: {', '.join(result['required_models']['missing'])}")
                result["recommendations"].append("í•„ìˆ˜ ëª¨ë¸ì„ ë‹¤ìš´ë¡œë“œí•˜ê±°ë‚˜ ëŒ€ì²´ ëª¨ë¸ì„ ì°¾ì•„ì£¼ì„¸ìš”")
            
            if not size_ok and len(step_models) > 0:
                expected_range = f"{requirement.expected_size_mb[0]}-{requirement.expected_size_mb[1]}MB"
                result["issues"].append(f"ì˜ˆìƒ í¬ê¸° ë²”ìœ„ ë²—ì–´ë‚¨: {result['total_size_mb']:.1f}MB (ì˜ˆìƒ: {expected_range})")
            
            verification_results[step_id] = result
        
        self.verification_results = verification_results
        return verification_results
    
    def check_file_integrity(self, quick_check: bool = True) -> Dict:
        """íŒŒì¼ ë¬´ê²°ì„± ê²€ì‚¬"""
        print("ğŸ” íŒŒì¼ ë¬´ê²°ì„± ê²€ì‚¬ ì¤‘...")
        
        integrity_results = {
            "total_files": 0,
            "healthy_files": 0,
            "corrupted_files": 0,
            "inaccessible_files": 0,
            "suspicious_files": 0,
            "details": []
        }
        
        all_models = []
        for step_models in self.discovered_models.values():
            all_models.extend(step_models)
        
        iterator = tqdm(all_models, desc="ë¬´ê²°ì„± ê²€ì‚¬") if TQDM_AVAILABLE else all_models
        
        for model in iterator:
            integrity_results["total_files"] += 1
            file_result = {
                "path": str(model.path),
                "name": model.name,
                "step": model.step,
                "size_mb": model.size_mb,
                "status": "unknown",
                "issues": []
            }
            
            try:
                # íŒŒì¼ ì¡´ì¬ ë° ì ‘ê·¼ ê¶Œí•œ ì²´í¬
                if not model.path.exists():
                    file_result["status"] = "missing"
                    file_result["issues"].append("íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ")
                    integrity_results["corrupted_files"] += 1
                
                elif not model.readable:
                    file_result["status"] = "inaccessible"
                    file_result["issues"].append("íŒŒì¼ ì½ê¸° ê¶Œí•œ ì—†ìŒ")
                    integrity_results["inaccessible_files"] += 1
                
                else:
                    # íŒŒì¼ í¬ê¸° ì²´í¬
                    if model.size_mb < 0.1:
                        file_result["status"] = "suspicious"
                        file_result["issues"].append("íŒŒì¼ í¬ê¸°ê°€ ë¹„ì •ìƒì ìœ¼ë¡œ ì‘ìŒ")
                        integrity_results["suspicious_files"] += 1
                    
                    elif model.size_mb > 10000:  # 10GB ì´ˆê³¼
                        file_result["status"] = "suspicious"
                        file_result["issues"].append("íŒŒì¼ í¬ê¸°ê°€ ë¹„ì •ìƒì ìœ¼ë¡œ í¼")
                        integrity_results["suspicious_files"] += 1
                    
                    # ë¹ ë¥¸ ì²´í¬ê°€ ì•„ë‹Œ ê²½ìš° ì‹¤ì œ íŒŒì¼ ì½ê¸° í…ŒìŠ¤íŠ¸
                    elif not quick_check:
                        try:
                            with open(model.path, 'rb') as f:
                                # ì²˜ìŒê³¼ ë 1KBì”© ì½ì–´ë³´ê¸°
                                f.read(1024)
                                f.seek(-1024, 2)  # íŒŒì¼ ëì—ì„œ 1KB ì•ìœ¼ë¡œ
                                f.read(1024)
                            file_result["status"] = "healthy"
                            integrity_results["healthy_files"] += 1
                        except Exception as e:
                            file_result["status"] = "corrupted"
                            file_result["issues"].append(f"íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {e}")
                            integrity_results["corrupted_files"] += 1
                    
                    else:
                        file_result["status"] = "healthy"
                        integrity_results["healthy_files"] += 1
            
            except Exception as e:
                file_result["status"] = "error"
                file_result["issues"].append(f"ê²€ì‚¬ ì¤‘ ì˜¤ë¥˜: {e}")
                integrity_results["corrupted_files"] += 1
            
            if file_result["issues"]:  # ì´ìŠˆê°€ ìˆëŠ” íŒŒì¼ë§Œ ìƒì„¸ ê²°ê³¼ì— í¬í•¨
                integrity_results["details"].append(file_result)
        
        return integrity_results
    
    def generate_summary_report(self, detailed: bool = False) -> Dict:
        """ì¢…í•© ìš”ì•½ ë³´ê³ ì„œ ìƒì„±"""
        print("ğŸ“Š ì¢…í•© ë³´ê³ ì„œ ìƒì„± ì¤‘...")
        
        report = {
            "scan_info": {
                "timestamp": time.time(),
                "backend_dir": str(self.backend_dir),
                "checkpoints_dir": str(self.checkpoints_dir),
                "scan_time": time.strftime("%Y-%m-%d %H:%M:%S")
            },
            "overview": {
                "total_steps": len(self.step_requirements),
                "active_steps": len(self.discovered_models),
                "total_models": sum(len(models) for models in self.discovered_models.values()),
                "total_size_gb": sum(sum(m.size_mb for m in models) for models in self.discovered_models.values()) / 1024
            },
            "step_summary": {},
            "status_distribution": {
                "ok": 0,
                "warning": 0,
                "error": 0,
                "optional_empty": 0
            },
            "recommendations": [],
            "critical_issues": []
        }
        
        # Stepë³„ ìš”ì•½
        for step_id, result in self.verification_results.items():
            step_summary = {
                "name": result["step_name"],
                "status": result["status"],
                "models_count": result["found_models"],
                "size_mb": result["total_size_mb"],
                "required_found": len(result["required_models"]["found"]),
                "required_total": len(result["required_models"]["found"]) + len(result["required_models"]["missing"]),
                "issues_count": len(result["issues"])
            }
            
            report["step_summary"][step_id] = step_summary
            report["status_distribution"][result["status"]] += 1
        
        # ì „ë°˜ì  ê¶Œì¥ì‚¬í•­
        if report["status_distribution"]["error"] > 0:
            report["recommendations"].append("ğŸš¨ í•„ìˆ˜ ëª¨ë¸ì´ ëˆ„ë½ëœ Stepë“¤ì´ ìˆìŠµë‹ˆë‹¤. ì¦‰ì‹œ í•´ê²° í•„ìš”!")
        
        if report["status_distribution"]["warning"] > 0:
            report["recommendations"].append("âš ï¸ ì¼ë¶€ Stepì—ì„œ ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤.")
        
        if report["overview"]["total_models"] < 10:
            report["recommendations"].append("ğŸ’¡ ëª¨ë¸ ìˆ˜ê°€ ì ìŠµë‹ˆë‹¤. ì¶”ê°€ ëª¨ë¸ ë‹¤ìš´ë¡œë“œë¥¼ ê³ ë ¤í•´ë³´ì„¸ìš”.")
        
        if report["overview"]["total_size_gb"] < 1.0:
            report["recommendations"].append("ğŸ’¡ ëª¨ë¸ í¬ê¸°ê°€ ì‘ìŠµë‹ˆë‹¤. ê³ ì„±ëŠ¥ ëª¨ë¸ ì¶”ê°€ë¥¼ ê³ ë ¤í•´ë³´ì„¸ìš”.")
        
        # ì¤‘ìš” ì´ìŠˆ ìˆ˜ì§‘
        for step_id, result in self.verification_results.items():
            if result["status"] == "error":
                report["critical_issues"].append(f"{result['step_name']}: {', '.join(result['issues'])}")
        
        return report
    
    def print_detailed_report(self, report: Dict):
        """ìƒì„¸ ë³´ê³ ì„œ ì¶œë ¥"""
        print("\n" + "=" * 70)
        print("ğŸ¤– MyCloset AI ëª¨ë¸ ê²€ì¦ ë³´ê³ ì„œ")
        print("=" * 70)
        
        # ê°œìš”
        overview = report["overview"]
        print(f"\nğŸ“Š ì „ì²´ ê°œìš”:")
        print(f"   ğŸ“ ì´ Step ìˆ˜: {overview['total_steps']}ê°œ")
        print(f"   âœ… í™œì„± Step ìˆ˜: {overview['active_steps']}ê°œ")
        print(f"   ğŸ”¢ ì´ ëª¨ë¸ ìˆ˜: {overview['total_models']}ê°œ")
        print(f"   ğŸ’¾ ì´ í¬ê¸°: {overview['total_size_gb']:.2f}GB")
        
        # ìƒíƒœ ë¶„í¬
        status_dist = report["status_distribution"]
        print(f"\nğŸ¯ Step ìƒíƒœ ë¶„í¬:")
        print(f"   âœ… ì •ìƒ: {status_dist['ok']}ê°œ")
        print(f"   âš ï¸ ê²½ê³ : {status_dist['warning']}ê°œ")
        print(f"   âŒ ì˜¤ë¥˜: {status_dist['error']}ê°œ")
        print(f"   â­• ì„ íƒì  ë¹„ì–´ìˆìŒ: {status_dist['optional_empty']}ê°œ")
        
        # Stepë³„ ìƒì„¸ ì •ë³´
        print(f"\nğŸ“‹ Stepë³„ ìƒì„¸ í˜„í™©:")
        for step_id, result in self.verification_results.items():
            status_emoji = {
                "ok": "âœ…",
                "warning": "âš ï¸", 
                "error": "âŒ",
                "optional_empty": "â­•"
            }
            
            emoji = status_emoji.get(result["status"], "â“")
            print(f"\n{emoji} {result['step_name']} ({step_id})")
            print(f"   ğŸ“ {result['description']}")
            print(f"   ğŸ”¢ ëª¨ë¸ ìˆ˜: {result['found_models']}ê°œ")
            print(f"   ğŸ’¾ í¬ê¸°: {result['total_size_mb']:.1f}MB")
            
            if result["required_models"]["found"]:
                print(f"   âœ… í•„ìˆ˜ ëª¨ë¸: {', '.join(result['required_models']['found'])}")
            if result["required_models"]["missing"]:
                print(f"   âŒ ëˆ„ë½ í•„ìˆ˜: {', '.join(result['required_models']['missing'])}")
            if result["optional_models"]["found"]:
                print(f"   ğŸ’¡ ì„ íƒ ëª¨ë¸: {', '.join(result['optional_models']['found'])}")
            
            if result["issues"]:
                print(f"   ğŸš¨ ì´ìŠˆ:")
                for issue in result["issues"]:
                    print(f"     - {issue}")
            
            if result["recommendations"]:
                print(f"   ğŸ’¡ ê¶Œì¥ì‚¬í•­:")
                for rec in result["recommendations"]:
                    print(f"     - {rec}")
        
        # ì „ë°˜ì  ê¶Œì¥ì‚¬í•­
        if report["recommendations"]:
            print(f"\nğŸ¯ ì „ë°˜ì  ê¶Œì¥ì‚¬í•­:")
            for rec in report["recommendations"]:
                print(f"   {rec}")
        
        # ì¤‘ìš” ì´ìŠˆ
        if report["critical_issues"]:
            print(f"\nğŸš¨ ì¦‰ì‹œ í•´ê²° í•„ìš”í•œ ì´ìŠˆ:")
            for issue in report["critical_issues"]:
                print(f"   âŒ {issue}")
    
    def suggest_missing_models(self) -> Dict:
        """ëˆ„ë½ëœ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì œì•ˆ"""
        suggestions = {
            "critical_missing": [],
            "recommended_additions": [],
            "download_commands": []
        }
        
        for step_id, result in self.verification_results.items():
            if result["required_models"]["missing"]:
                for missing_model in result["required_models"]["missing"]:
                    suggestions["critical_missing"].append({
                        "step": result["step_name"],
                        "model": missing_model,
                        "priority": "high"
                    })
            
            if result["status"] in ["warning", "error"] and result["optional_models"]["missing"]:
                for missing_model in result["optional_models"]["missing"][:2]:  # ìµœëŒ€ 2ê°œë§Œ
                    suggestions["recommended_additions"].append({
                        "step": result["step_name"],
                        "model": missing_model,
                        "priority": "medium"
                    })
        
        return suggestions

def main():
    parser = argparse.ArgumentParser(description="AI ëª¨ë¸ ì¬ë°°ì¹˜ ê²€ì¦ ë„êµ¬")
    parser.add_argument("--backend-dir", type=Path, default=Path.cwd() / "backend", help="ë°±ì—”ë“œ ë””ë ‰í† ë¦¬ ê²½ë¡œ")
    parser.add_argument("--step", type=int, help="íŠ¹ì • Stepë§Œ ê²€ì¦ (1-8)")
    parser.add_argument("--detailed", action="store_true", help="ìƒì„¸ ë¶„ì„ ì‹¤í–‰")
    parser.add_argument("--fix-missing", action="store_true", help="ëˆ„ë½ëœ ëª¨ë¸ íƒì§€ ë° ì œì•ˆ")
    parser.add_argument("--integrity", action="store_true", help="íŒŒì¼ ë¬´ê²°ì„± ê²€ì‚¬")
    parser.add_argument("--output", type=Path, help="ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥")
    
    args = parser.parse_args()
    
    print("ğŸ” MyCloset AI ëª¨ë¸ ê²€ì¦ê¸° v1.0")
    print("=" * 50)
    
    # ê²€ì¦ê¸° ì´ˆê¸°í™”
    verifier = ModelVerifier(backend_dir=args.backend_dir)
    
    # ëª¨ë¸ ìŠ¤ìº”
    discovered_models = verifier.scan_models()
    if not discovered_models:
        print("âŒ ì¬ë°°ì¹˜ëœ ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print("ğŸ’¡ ë¨¼ì € search_and_relocate_models.pyë¥¼ ì‹¤í–‰í•˜ì—¬ ëª¨ë¸ì„ ì¬ë°°ì¹˜í•´ì£¼ì„¸ìš”.")
        return
    
    # Stepë³„ ìš”êµ¬ì‚¬í•­ ê²€ì¦
    verification_results = verifier.verify_step_requirements()
    
    # ì¢…í•© ë³´ê³ ì„œ ìƒì„±
    report = verifier.generate_summary_report(detailed=args.detailed)
    
    # ë³´ê³ ì„œ ì¶œë ¥
    verifier.print_detailed_report(report)
    
    # íŒŒì¼ ë¬´ê²°ì„± ê²€ì‚¬ (ìš”ì²­ëœ ê²½ìš°)
    if args.integrity:
        print("\n" + "=" * 50)
        integrity_results = verifier.check_file_integrity(quick_check=not args.detailed)
        
        print(f"ğŸ” íŒŒì¼ ë¬´ê²°ì„± ê²€ì‚¬ ê²°ê³¼:")
        print(f"   ì´ íŒŒì¼: {integrity_results['total_files']}ê°œ")
        print(f"   ì •ìƒ: {integrity_results['healthy_files']}ê°œ")
        print(f"   ì†ìƒ: {integrity_results['corrupted_files']}ê°œ")
        print(f"   ì ‘ê·¼ë¶ˆê°€: {integrity_results['inaccessible_files']}ê°œ")
        print(f"   ì˜ì‹¬ìŠ¤ëŸ¬ìš´: {integrity_results['suspicious_files']}ê°œ")
        
        if integrity_results['details']:
            print(f"\nğŸš¨ ë¬¸ì œê°€ ìˆëŠ” íŒŒì¼ë“¤:")
            for detail in integrity_results['details'][:10]:  # ìµœëŒ€ 10ê°œë§Œ í‘œì‹œ
                print(f"   âŒ {detail['name']} ({detail['step']}) - {', '.join(detail['issues'])}")
    
    # ëˆ„ë½ëœ ëª¨ë¸ ì œì•ˆ (ìš”ì²­ëœ ê²½ìš°)
    if args.fix_missing:
        print("\n" + "=" * 50)
        suggestions = verifier.suggest_missing_models()
        
        if suggestions["critical_missing"]:
            print(f"ğŸš¨ ì¦‰ì‹œ í•„ìš”í•œ ëª¨ë¸ë“¤:")
            for item in suggestions["critical_missing"]:
                print(f"   âŒ {item['step']}: {item['model']}")
        
        if suggestions["recommended_additions"]:
            print(f"\nğŸ’¡ ì¶”ê°€ ê¶Œì¥ ëª¨ë¸ë“¤:")
            for item in suggestions["recommended_additions"]:
                print(f"   âš ï¸ {item['step']}: {item['model']}")
        
        print(f"\nğŸ”§ í•´ê²° ë°©ë²•:")
        print(f"   1. HuggingFace Hubì—ì„œ í•´ë‹¹ ëª¨ë¸ë“¤ ê²€ìƒ‰")
        print(f"   2. ê³µì‹ ë¦¬í¬ì§€í† ë¦¬ì—ì„œ ë‹¤ìš´ë¡œë“œ")
        print(f"   3. ëŒ€ì²´ ëª¨ë¸ ì‚¬ìš© ê³ ë ¤")
    
    # ê²°ê³¼ ì €ì¥ (ìš”ì²­ëœ ê²½ìš°)
    if args.output:
        combined_results = {
            "verification": report,
            "models": {step: [vars(model) for model in models] 
                     for step, models in discovered_models.items()}
        }
        
        if args.integrity:
            combined_results["integrity"] = integrity_results
        
        if args.fix_missing:
            combined_results["suggestions"] = suggestions
        
        args.output.parent.mkdir(parents=True, exist_ok=True)
        with open(args.output, 'w', encoding='utf-8') as f:
            json.dump(combined_results, f, indent=2, ensure_ascii=False, default=str)
        
        print(f"\nğŸ’¾ ê²°ê³¼ ì €ì¥: {args.output}")
    
    # ìµœì¢… ê²°ë¡ 
    print("\n" + "=" * 50)
    total_errors = report["status_distribution"]["error"]
    total_warnings = report["status_distribution"]["warning"]
    
    if total_errors == 0 and total_warnings == 0:
        print("ğŸ‰ ëª¨ë“  ê²€ì¦ í†µê³¼! AI íŒŒì´í”„ë¼ì¸ì´ ì˜¬ë°”ë¥´ê²Œ êµ¬ì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")
    elif total_errors == 0:
        print(f"âœ… ê¸°ë³¸ ìš”êµ¬ì‚¬í•­ ì¶©ì¡±. {total_warnings}ê°œ ê°œì„  ê¶Œì¥ì‚¬í•­ì´ ìˆìŠµë‹ˆë‹¤.")
    else:
        print(f"âš ï¸ {total_errors}ê°œ ì¤‘ìš” ì´ìŠˆ, {total_warnings}ê°œ ê²½ê³ ê°€ ìˆìŠµë‹ˆë‹¤. í•´ê²°ì´ í•„ìš”í•©ë‹ˆë‹¤.")

if __name__ == "__main__":
    main()