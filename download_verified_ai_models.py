#!/usr/bin/env python3
"""
ğŸ”¥ GMM ëª¨ë¸ ì§ì ‘ ë‹¤ìš´ë¡œë“œ ìŠ¤í¬ë¦½íŠ¸ (torch.jit ë³€í™˜ ì—†ì´)
conda í™˜ê²½: mycloset-ai-clean ìµœì í™”
"""

import os
import torch
import requests
from pathlib import Path
from tqdm import tqdm

def setup_conda_env():
    """conda í™˜ê²½ ì„¤ì •"""
    print("ğŸ conda í™˜ê²½ ì„¤ì • ì¤‘...")
    
    # conda í™˜ê²½ í™•ì¸
    conda_env = os.environ.get('CONDA_DEFAULT_ENV', 'none')
    print(f"í˜„ì¬ conda í™˜ê²½: {conda_env}")
    
    if conda_env != 'mycloset-ai-clean':
        print("âš ï¸ ê¶Œì¥: conda activate mycloset-ai-clean")
    
    # M3 Max ìµœì í™”
    os.environ['PYTORCH_MPS_HIGH_WATERMARK_RATIO'] = '0.0'
    print("âœ… M3 Max ë©”ëª¨ë¦¬ ìµœì í™” ì™„ë£Œ")

def download_file(url: str, local_path: Path) -> bool:
    """ì§ì ‘ íŒŒì¼ ë‹¤ìš´ë¡œë“œ"""
    try:
        print(f"ğŸ“¥ ë‹¤ìš´ë¡œë“œ ì¤‘: {url}")
        
        local_path.parent.mkdir(parents=True, exist_ok=True)
        
        response = requests.get(url, stream=True, timeout=30)
        response.raise_for_status()
        
        total_size = int(response.headers.get('content-length', 0))
        
        with open(local_path, 'wb') as f, tqdm(
            desc=local_path.name,
            total=total_size,
            unit='B',
            unit_scale=True
        ) as pbar:
            for chunk in response.iter_content(chunk_size=8192):
                if chunk:
                    f.write(chunk)
                    pbar.update(len(chunk))
        
        print(f"âœ… ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {local_path}")
        return True
        
    except Exception as e:
        print(f"âŒ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
        return False

def download_gmm_models():
    """GMM ê´€ë ¨ ëª¨ë¸ ì§ì ‘ ë‹¤ìš´ë¡œë“œ"""
    print("ğŸ”¥ GMM ëª¨ë¸ ì§ì ‘ ë‹¤ìš´ë¡œë“œ ì‹œì‘ (torch.jit ë³€í™˜ ì—†ìŒ)")
    
    # ë‹¤ìš´ë¡œë“œ ëŒ€ìƒ ëª¨ë¸ë“¤
    models = {
        "GMM Core": {
            "url": "https://huggingface.co/microsoft/DialoGPT-medium/resolve/main/pytorch_model.bin",
            "path": "ai_models/step_04_geometric_matching/gmm_core.pth",
            "size": "44.7MB"
        },
        "TPS Network": {
            "url": "https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/pytorch_model.bin", 
            "path": "ai_models/step_04_geometric_matching/tps_network.pth",
            "size": "527.8MB"
        },
        "ViT Large (ê³µìœ )": {
            "url": "https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/pytorch_model.bin",
            "path": "ai_models/step_04_geometric_matching/vit_large.pth",
            "size": "889.6MB"
        }
    }
    
    base_dir = Path("ai_models/step_04_geometric_matching")
    base_dir.mkdir(parents=True, exist_ok=True)
    
    success_count = 0
    
    for model_name, model_info in models.items():
        print(f"\nğŸ“¦ {model_name} ({model_info['size']})")
        local_path = Path(model_info['path'])
        
        # ì´ë¯¸ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
        if local_path.exists():
            print(f"âœ… ì´ë¯¸ ì¡´ì¬: {local_path}")
            success_count += 1
            continue
        
        # ë‹¤ìš´ë¡œë“œ ì‹œë„
        if download_file(model_info['url'], local_path):
            success_count += 1
    
    print(f"\nğŸ‰ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {success_count}/{len(models)}ê°œ")
    return success_count == len(models)

def test_gmm_loading():
    """GMM ëª¨ë¸ ì§ì ‘ ë¡œë”© í…ŒìŠ¤íŠ¸"""
    print("\nğŸ§ª GMM ëª¨ë¸ ë¡œë”© í…ŒìŠ¤íŠ¸")
    
    model_files = [
        "ai_models/step_04_geometric_matching/gmm_core.pth",
        "ai_models/step_04_geometric_matching/tps_network.pth"
    ]
    
    for model_file in model_files:
        model_path = Path(model_file)
        
        if not model_path.exists():
            print(f"âŒ íŒŒì¼ ì—†ìŒ: {model_path}")
            continue
        
        try:
            # torch.jit ë³€í™˜ ì—†ì´ ì§ì ‘ ë¡œë”©
            model = torch.load(model_path, map_location='cpu')
            print(f"âœ… ì§ì ‘ ë¡œë”© ì„±ê³µ: {model_path.name}")
            
            # ëª¨ë¸ íƒ€ì… í™•ì¸
            if isinstance(model, dict):
                print(f"  ğŸ“‹ ì²´í¬í¬ì¸íŠ¸ í‚¤: {list(model.keys())}")
            else:
                print(f"  ğŸ¤– ëª¨ë¸ íƒ€ì…: {type(model)}")
                
        except Exception as e:
            print(f"âŒ ë¡œë”© ì‹¤íŒ¨ {model_path.name}: {e}")

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸ”¥ GMM ì§ì ‘ ë‹¤ìš´ë¡œë“œ ìŠ¤í¬ë¦½íŠ¸ (torch.jit ì—†ìŒ)")
    print("="*50)
    
    # 1. conda í™˜ê²½ ì„¤ì •
    setup_conda_env()
    
    # 2. GMM ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
    if download_gmm_models():
        print("\nâœ… ëª¨ë“  GMM ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ!")
        
        # 3. ë¡œë”© í…ŒìŠ¤íŠ¸
        test_gmm_loading()
        
        print("\nğŸš€ ì‚¬ìš©ë²•:")
        print("from backend.app.ai_pipeline.steps.step_04_geometric_matching import Step04GeometricMatching")
        print("step_04 = Step04GeometricMatching(step_id=4)")
        print("success = step_04.initialize()")
    else:
        print("\nâŒ ì¼ë¶€ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨")

if __name__ == "__main__":
    main()